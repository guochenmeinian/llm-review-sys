# Towards Editing Time Series

Baoyu Jing\({}^{*}\) 2, Shuqi Gu\({}^{*}\) 1, Tianyu Chen\({}^{1}\), Zhiyu Yang\({}^{1}\),

**Dongsheng Li\({}^{3}\), Jingrui He\({}^{2}\), Kan Ren\({}^{}\) 1**

\({}^{1}\)ShanghaiTech University, \({}^{2}\)University of Illinois at Urbana-Champaign, \({}^{3}\)Microsoft Research

Baoyu Jing and Shuqi Gu share the co-first authorship.Correspondence to Kan Ren: renkan@shanghaitech.edu.cn

 Shuqi Gu\({}^{*}\) 1, Tianyu Chen\({}^{1}\), Zhiyu Yang\({}^{1}\),

**Dongsheng Li\({}^{3}\), Jingrui He\({}^{2}\), Kan Ren\({}^{}\) 1**

\({}^{1}\)ShanghaiTech University, \({}^{2}\)University of Illinois at Urbana-Champaign, \({}^{3}\)Microsoft Research

###### Abstract

Synthesizing time series data is pivotal in modern society, aiding effective decision-making and ensuring privacy preservation in various scenarios. Time series are associated with various attributes, including trends, seasonality, and external information such as location. Recent research has predominantly focused on random unconditional synthesis or conditional synthesis. Nonetheless, these paradigms generate time series from scratch and are incapable of manipulating existing time series samples. This paper introduces a novel task, called Time Series Editing (TSE), to synthesize time series by manipulating existing time series. The objective is to modify the given time series according to the specified attributes while preserving other properties unchanged. This task is not trivial due to the inadequacy of data coverage and the intricate relationships between time series and their attributes. To address these issues, we introduce a novel diffusion model, called TEdit. The proposed TEdit is trained using a novel bootstrap learning algorithm that effectively enhances the coverage of the original data. It is also equipped with an innovative multi-resolution modeling and generation paradigm to capture the complex relationships between time series and their attributes. Experimental results demonstrate the efficacy of TEdit for editing specified attributes upon the existing time series data. The project page is at https://seqml.github.io/tse.

## 1 Introduction

Time series data analysis plays a crucial role in various modern business sectors, including climate monitoring [22; 13; 14], healthcare [12; 3; 46], urban management [43; 16; 15], and online service . Time series are derived from diverse sources with inherent characteristics, such as system configurations, alongside external influential factors like environmental status. These factors are considered _attributes_ of the time series. In many real-world scenarios, such as healthcare and urban monitoring, time series data tend to be sparse and privacy-sensitive, particularly concerning specific attributes that are rarely observed in real-world scenarios.

Synthesizing time series data has emerged as a prominent research area aimed at addressing these challenges. Existing methods for time series synthesis range from unconditional generation [47; 31] to conditional generation [39; 27; 4]. Unconditional generation produces outputs based solely on the underlying distribution of the data. Without relying on any input conditions, the generated results are highly uncontrollable. Conditional generation controls the outcomes of the generated data based on the input conditions. However, conditional generation tends to produce samples around the data mean , as demonstrated in our experiments, which could easily overlook detailed characteristics of the data, such as high-frequency patterns and local structures. Both unconditional and conditional generation paradigms synthesize time series from scratch, and they are incapable of manipulating existing samples. As a result, these paradigms are unable to answer _"what if"_ questions in time series synthesis: _given a time series, what would it become if some of its attributes are modified?_In this paper, we introduce a novel task, called **Time Series Editing (TSE)**, for sample-level time series manipulation. More specifically, our objective is to directly manipulate specific attributes of an input time series to target values while maintaining consistency in other characteristics. For instance, consider observing air quality under season conditions in different cities as shown in Fig. 1. On the left side, two example air quality time series for the spring and summer of London are illustrated. The spring one exhibits a lower amplitude with more noise, whereas the summer one features a higher amplitude with less noise. What would the resulting time series look like if we modify the season attribute of the spring one to summer while maintaining all other properties? As illustrated in Fig. 1, it could have a larger amplitude with much noise.

The task of TSE is complex due to several challenges. Firstly, the time series data distribution over the full composited attribute space is biased and may not be adequately covered, leaving gaps in our understanding, especially concerning unobservable or poorly defined attributes. For example, in climate data analysis, attributes like temperature and humidity are observable and well-defined. However, attributes like atmospheric pressure variations or localized microclimates may be challenging to observe or define accurately. Secondly, different attributes influence time series at varying resolutions. For example, trends have a global impact, while seasonality exerts a more localized influence. Modeling these multi-scale attributes and time series associations, while effectively controlling them, presents significant difficulties.

To address these challenges, we introduce a novel method called **Time Series Editor (TEdit)**, which is based on predominant generative models, specifically diffusion models . To address the data coverage issue, we propose a novel bootstrap learning algorithm, which leverages the generated data as pseudo-supervision for subsequent model learning. This algorithm helps improve the coverage of the whole attribute space and enhance the generation performance. To capture the intricate multi-scale associations between time series and attributes, we introduce a multi-resolution modeling and generation paradigm. The proposed multi-resolution paradigm can manipulate the given time series and attributes both effectively and efficiently. Our experiments, conducted on both synthetic and real-world datasets, demonstrate the effectiveness of our proposed solution. Specifically, our approach excels in generating precise time series under specified attributes, while keeping consistency in other attributes, showcasing the practical utility of our method.

In summary, our main contributions are threefold. (1) We introduce and formulate the novel task of Time Series Editing (TSE). To the best of our knowledge, this is the first work exploring editing time series according to the given attribute configuration upon the input data. (2) We propose a novel multi-resolution diffusion model, called TEdit, with a bootstrap learning algorithm, which can flexibly capture the patterns at diverse granularity and gradually improve the generation performance. (3) We conduct and release a benchmark for TSE, including synthetic data and several carefully curated real-world datasets with a comprehensive evaluation protocol, aiming to facilitate further research in the community.

Figure 1: Illustration of the time series generation paradigms. Conditional generation generates time series from scratch, which usually generates samples around the dataset mean. Time series editing allows for the manipulation of the attributes of an input time series sample, which aligns with the desired target attribute values while preserving other properties.

Background

### Time Series Generation

A time series sample \(^{L}\) is a series of \(L\) chronologically ordered sample points. Each time series sample adheres to some attributes \(_{+}^{K}\), such as trend and the cycle number, and the \(k\)-th item \(a_{k}\) corresponds to \(N_{k}\) categorical options where \(k\{1,...,K\}\). In real-world scenarios, each time series may have several attributes, e.g., the air quality time series is associated with \(K=2\) attributes: location and season. Note that, not all the attributes can be observed due to practical limitations.

Before describing the main task of the paper, we first briefly review the background of Time Series Generation. _Unconditional Time Series Generation (UTSG)_ samples the time series data \(\) upon the modeled data distribution \(p()\) such that \( p()\), of which the generation process is uncontrollable. _Conditional Time Series Generation (CTSG)_ generates the time series sample \(\) based on the conditional distribution such that \( p(|)\), where \(\) is the input condition. CTSG tends to produce data samples near the dataset mean . Both UTSG and CTSG paradigms generate time series from scratch and lack the ability to directly manipulate the existing samples.

### Conditional Diffusion Models

Diffusion models [10; 37; 38] learn to estimate and remove the random noise, which was added in the forward process onto the real-world data, through a sequence of sampling processes. Specifically, during training, random noise is gradually added to the original data sample \(_{0}=\)1 via a Gaussian Markov transition \(q(_{t}|_{t-1}):=(}_ {t-1},_{t})\), where \(t[1,T]\) indicates the diffusion step, and \(\{_{t}\}_{t=0}^{T}\) are the predetermined variance schedule. The expression of latent variable \(_{t}\) can be simplified as \(_{t}=}_{0}+} {},\ (0,),\ _{t}:=_{s=1}^{t}(1-_{s})\). The learnable component of the diffusion models is a noise estimation network \(_{}(_{t},t,)\), where \(\) denotes the additional condition such as attributes. \(_{}(_{t},t,)\) is trained by estimating the noise added to \(_{t}\):

\[_{}(_{0}):=_{}_{ {}(0,),t(1,T)}\| -_{}(_{t},t, )\|_{2}^{2}\] (1)

where \(_{0} q(_{0})\) is sampled from the real data distribution, \(_{t}\) is a noisy version of \(_{0}\).

After training, given an attribute \(\), we can generate a sample \(}_{0}\) from random noise \(}_{T}(0,)\) using \(_{}(_{t},t,)\) with a sampler, e.g., deterministic Denoising Diffusion Implicit Model (DDIM) :

\[}_{t-1} =}_{}(}_{t},t, )+}_{}(}_{t},t,)\] (2) \[_{}(}_{t},t,) =(}_{t}-}_{ }(}_{t},t,))/}\] (3)

where \(_{}(}_{t},t,)\) can be regarded as a prediction of \(\ _{0}\) at the diffusion step \(t\).

Adapting diffusion methods from the computer vision domain to the time series domain is not trivial. Time series is different from images, and it poses unique challenges for modeling and generating time series data, such as the complex multi-scale entanglement between time series and attributes.

## 3 Time Series Editing

Given a time series and its associated attributes \((,)\), a natural question arises: _"what would it become if some of its attributes are modified?"_ In our work, we take a novel perspective of directly editing the given time series with the specified attribute modifications.

In this section, we first formally formulate the problem of _Time Series Editing (TSE)_ in Sec. 3.1. Next, we present our method _Time Series Editor (TEdit)_ with the overall procedure of the diffusion model-based TSE in Sec. 3.2, the model architecture in Sec. 3.3 and the learning algorithm in Sec. 3.4.

### Problem Formulation

Recall that, each time series sample \(^{L}\) is associated with a set of attributes \(_{+}^{K}\). Each attribute \(a_{k}\) has \(N_{k}\) options, \(k\{1,...,K\}\). For example, the trend type may contain \(N_{k}=4\) valueslike linear, quadratic, exponential, and logistic. Let \((^{},^{})\) be a pair of _source time series_ and _source attributes_ to be edited, and \(^{}\) be the desired _target attributes_. Comparing \(^{}\) and \(^{}\), there are \(K_{}\) edited attributes, e.g., trend types, and \(K_{}\) preserved attributes, e.g., cycle numbers, where \(K_{}+K_{}=K\). Now, we can formally define the task as below.

**Definition 1** (Time Series Editing (TSE)): _The time series editing task is to build a function \(_{}\) to generate a target time series \(}^{}=_{}(^{},^{},^{})\) by modifying the set of \(K_{}\) edited attributes \(_{}\) and maintaining the set of \(K_{}\) preserved attributes \(_{}\) as well as other information of \(^{}\)._

### Editing with Source Modeling and Target Generation

Given a pair of source time series and attributes \((^{},^{})\), generating the target time series \(}^{}\) corresponding to the target attributes \(^{}\) entails two requirements. On one hand, the edited attributes \(_{edit}\) should be satisfied after the generation. On the other hand, the preserved attributes \(_{prsv}\) as well as other characteristics, e.g., noise, need to be maintained. Conditional generation , such as directly adopting the conditional diffusion model described in Sec. 2.2, would fail the editing task because it does not take into consideration the detail characteristics of the source time series.

In this paper, we propose a diffusion based two-stage procedure for TSE: \(_{}(^{},^{},^{ })\), which is illustrated in the upper part of Fig. 2. In the first stage, we encode both the attribute semantics  and the detail characteristics  of the source time series \(^{}_{0}\) into the latent variable \(^{}_{T}\) via the deterministic forward DDIM process :

\[^{}_{t+1}=}_{}(^{}_{t},t,^{})+}_{ }(^{}_{t},t,^{}).\] (4)

In the second stage, originating from the latent variable \(}^{}_{T}=^{}_{T}\), we gradually generate the final target time series \(}^{}_{0}\) with the consideration of the target attribute \(^{}\) via the deterministic reverse DDIM process :

\[}^{}_{t-1}=}_{}( }^{}_{t},t,^{})+}_{}(}^{}_{t},t,^{ }),\] (5)

where \(_{}\) is given in Eq. (3). Till now, we have detailed the procedure of the proposed TEdit. In the following subsections, we introduce the model architecture and the training algorithm.

### Multi-Resolution Noise Estimator

The key component of our TEdit is the noise estimator \(_{}(,t,)\) in Eqs. (4)(5). Though many diffusion model realizations have been proposed in other fields [18; 10; 37; 38; 24] and the time series domain [39; 27], we found them inefficacious in modeling and generating time series data, especially when considering attributes. Few of them consider that different attributes can influence the time series on varying scales. We argue that it is important to take into account these differences. For instance, the trend types have a global impact on time series, while the seasonality affects the time series in local areas.

In this paper, we propose a multi-resolution noise estimator. It first slices the input time series \(_{t}\) into several patch sequences of different resolutions \(r\{1,...,R\}\), where \(R\) is the total number of resolutions. Then it processes the patch sequences along with other information, e.g., attributes \(\) and diffusion step \(t\), to estimate the noise \(}_{t}^{r}\) for resolution \(r\). Finally, the estimated noise for different resolutions are mixed together to obtain the final estimated noise \(}_{t}\). An illustration is presented in Fig. 3. We elaborate on the details in the following content2.

**Patchifying.** Following , we patchify the input time series \(^{L}\), into a sequence of patch tokens \(=\{_{1},...,_{N_{p}}\}\), where \(_{i}^{L_{p}}\), \(L_{p}\) is the window size and \(N_{p}=}{L_{p}}\) is the patch number. After that, we encode them into embeddings \(}=\{}_{1},...,}_{N_{p}}\}\), where \(}_{i}^{D}\).

**Multi-Resolution Modeling and Generation.** To model multi-resolution patterns and better control the conditional generation at multiple scales, we propose a multi-patch design with various patch lengths. Specifically, as shown in the left part of Fig. 3, following the above patchifying operation, we encode the input time series \(\) into patch embedding sequences \(\{}^{r}\}_{r=1}^{R}\) of \(R\) resolutions, where \(}^{r}=\{}_{1}^{r},...,}_{N_{p}^{ r}}^{r}\}\), \(}_{i}^{r}^{D}\), \(N_{p}^{r}=^{r}}{L_{p}^{r}}\) is the patch number, \(L_{p}^{r}\) is the window size. We set the patch length as \(L_{p}^{r}=b^{r-1}\) to produce exponential receptions, where \(b_{+}\) is the base. Thereafter, the processing module operates self-attention as the Transformer  to capture the input patterns for each resolution \(r\), and it incorporates the attribute \(\) and diffusion step \(t\) information to produce the embeddings \(\{}^{r}\}_{r=1}^{R}\). The details of the processing module are presented in Appendix D.

The processed output \(\{}^{r}\}_{r=1}^{R}\) is still in the form of multi-resolution sequences. The model subsequently decodes the diffusion noise at different resolutions back into the original space and integrates the outcomes at different resolutions to produce the final noise estimation, as shown on the right side of Fig. 3. Specifically, for each \(}^{r}\), the decoder transforms it to \(}^{r}^{L}\) in the original time series space. The final estimated noise is obtained via a mixing upon the concatenation of estimated noise of different resolutions as \(}=([^{1},...,^{R}])\), where \(()\) denotes Multi-Layer Perceptron.

**Parallel Processing.** Though more effective, the proposed multi-resolution modeling and generation brings efficiency issues since it derives multiple token sequences with various sequence lengths. Iteratively processing each sequence is of low efficiency. Herein we design a novel parallelization

Figure 3: Architecture of the proposed multi-resolution noise estimator \(_{}\). We illustrate with \(R=3\) patching schema, patch length \(L_{p}^{r}=2^{r-1},r\{1,...,R\}\) and the input length \(L=8\). \(N_{p}^{r}=^{r}}{L_{p}^{r}}\) is the patch number. \(D\) is the embedding size. Please refer to Sec. 3.3 for details.

with an attention masking mechanism in the processing module in Fig. 3 to harness the parallelism of the Graphics Processing Unit (GPU). Specifically, we first concatenate the input patch embedding sequences of different resolutions into a single vector \(}=[}^{1},...,}^{R}]^{D (N_{p}^{1}+...+N_{p}^{R})}\). When calculating pair-wise self-attention scores as in the Transformer , we use a mask matrix to mask out the inter-sequence attention operations across different sequences while preserving intra-sequence attention. Please refer to Appendix D for more details.

### Bootstrap Learning Algorithm

Although any pretrained conditional diffusion model \(_{}\) can be directly used to perform editing as shown in Sec. 3.2, the pretrained model is an essentially conditional generator, which has a great ability in generating time series directly from attributes but it might be less effective in modifying the attributes of an existing time series. The simplest way to improve the model's ability is to finetune \(_{}\) via the ground-truth source \((_{0}^{},^{})\) and target \((_{0}^{},^{})\) pairs. However, the imaginary target \(_{0}^{}\), which satisfies both \(^{}\) and the details of \(_{0}^{}\) might be very rare or even does not exist in the real world. Thus, a key challenge for finetuning is how to effectively learn the information of \(_{0}^{}\).

Fortunately, the pretrained model is capable of generating some edited samples of a certain quality via \(}_{0}^{}=_{}(_{0}^{}, ^{},^{})\). An example is shown in Fig. 2. In this paper, we propose a bootstrap learning algorithm, which first _pretrains_\(_{}\) based on the noise estimation loss \(\) in Eq. (1) and then _finetunes_\(_{}\) based on \(}_{0}^{}\) with top confidence scores. Here, we briefly present the key steps of the bootstrap learning, and the full algorithm is given in Appendix E. Given a batch \((_{0}^{},^{})\), where \(_{0}^{}^{B L}\), \(^{}_{+}^{B K}\), \(B\) is the batch size, the finetuning works as follows:

* **Compose target attributes \(^{}\).** For each \((_{0}^{},^{})(_{0}^{ },^{})\), we compose the imaginary target attributes \(^{}\) based on \(^{}\) by randomly sampling values for edited attributes \(_{}\) and keeping the values of the preserved attributes \(_{}\). Then we have the tuple \((_{0}^{},^{},^{})\).
* **Generate the edited time series \(}_{0}^{}\) via \(_{}\).** An illustration is shown in the upper part of Fig. 2.
* **Self-score \(}_{0}^{}\) via \(_{}\) and keep top \(\) samples.** An illustration of the self-scoring process is shown in the lower part of Fig. 2. We first edit \(}_{0}^{}\) back to source \(}_{0}^{}=_{}(}_{0}^{},^{},^{})\). Then we use the Mean Squared Error (MSE) between \(_{0}^{}\) and \(}_{0}^{}\) to score \(}_{0}^{}\). The top \(\) samples of \(}_{0}^{}\) with the lowest MSE are selected as the bootstrap samples, denoted by \(}_{0,}^{}\).
* **Update \(_{}\) by minimizing \(_{}\).** We finetune \(_{}\) by minimizing the noise estimation loss \(\) in Eq. (1) for \(}_{0,}^{}\). Formally, we minimize \(_{}=(}_{0,}^{})\).

## 4 Experiments

In this section, we present experiments aimed at addressing the following research questions: **RQ1**: How does the proposed TEdit perform in terms of editing and preserving attributes? **RQ2**: What's the impact of bootstrap training? **RQ3**: What's the impact of multi-resolution modeling?

### Experimental Setup

**Datasets.** We collect three datasets for TSE, including one synthetic dataset and two real-world datasets. For the **Synthetic** data, each time series sample has a length of 128, and is associated with 3 attributes, where there are 4 trend types, 2 trend directions, and 4 season cycles. In addition to attributes, noise and bias are added to simulate real-world conditions. The **Air Quality** dataset contains PM2.5 time series of Beijing and London from 01/01/2017 to 31/03/2018. Each time series has a length of 168 and is affected by two attributes: 2 cities and 4 seasons. The **Motor Imagery** dataset contains the ElectroEncephaloGram (EEG) data of subjects, who were required to imagine the movements of either the tongue or the left small finger. Each sample takes a length of 150 with 2 attributes: 2 movements and 64 channel ids.

Each of the three datasets is associated with a pertaining dataset and several finetuning datasets. The pretraining datasets only contain the source time series \(^{}\) and its attributes \(^{}\). During pertaining, the noise estimator \(_{}\) is trained to denoise \(_{t}^{}\) with \(^{}\) via Eq. (1). Each finetuningdataset corresponds to a specific split of \(_{}\) and \(_{}\). For example, the Synthetic dataset has 3 attributes, and thus it has \(6=_{i=1}^{2}\) different splits, namely, finetuning datasets. Similarly, both Air Quality and Motor Imagery datasets have 2 finetuning datasets. Finetuning datasets contain the source time series \(^{}\), source attributes \(^{}\), and target attributes \(^{}\). The process of generating the target attributes mirrors the target attribute composition step in bootstrap learning. Note that for Synthetic, the target time series \(^{}\) is also available. During finetuning, we use the proposed bootstrap learning algorithm to further improve the model. More details can be found in Appendix F.

**Evaluation Metrics.** A good editor should be able to generate \(}^{}\) that aligns with each \(a_{k}^{}^{}\). The cornerstone of our evaluation is the **Contrastive Time series Attribute Pretraining (CTAP)** model, which extracts time series and attribute embeddings by learning their alignment. Our CTAP is similar to CLIP . For details of CTAP, please refer to Appendix G. Based on the CTAP model, we introduce two metrics: **CTAP score** and **Log Ratio of Target-to-Source (RaTS)**. (1) The CTAP score is similar to the CLIP-I score [23; 33], which measures the alignment between the generated time series and the real-world time series which are associated with the given attribute value \(a_{k}^{}\). Specifically, we first use the CTAP model to extract embeddings \(}_{}\), which is the embedding of \(}^{}\), and \(}_{}|a_{k}^{}\), which is the average embedding of the time series associated with \(a_{k}^{}\) in the training data. Then we calculate the cosine similarity of \(}_{}\) and \(}_{}|a_{k}^{}\), where the higher similarity indicates better alignment. (2) The RaTS score measures whether \(}^{}\) is closer to \(a_{k}^{}\) than \(^{}\). Formally, the RaTS score for a tuple (\(}^{}\), \(^{}\), \(a_{k}^{}\)) is defined as:

\[(}^{},^{},a_{k}^{ })=(^{}|}^{})} {p(a_{k}^{}|^{})}),\] (6)

where \(p(a_{k}|)\) is calculated by applying a softmax over the similarity scores of all \((_{},_{a_{k}=i})\) pairs, where \(_{}\) is the CTAP embedding of \(\), and \(_{a_{k}=i}\), \(i\{1,...,N_{k}\}\), is the CTAP embedding of the \(i\)-th possible value for the \(k\)-th attribute \(a_{k}\).

We mainly evaluate \(}^{}\) from two perspectives: _editability_ and _preservability_ for edited attributes \(_{}\) and preserved attributes \(_{}\), respectively. For the edited attributes \(_{}\), the higher RaTS and CTAP the better. For the preserved attributes \(_{}\), the higher CTAP the better. Since RaTS can take negative values, we use |RaTS| for \(_{}\), which measures the semantic divergence of \(}^{}\) from \(^{}\) w.r.t \(a_{k}\). The lower |RaTS| means the better preservability. For more details, please refer to Appendix H. In addition to the semantic level evaluations, for the synthetic data, since we have ground truth target time series, we also use Mean Square Error (MSE), Mean Absolute Error (MAE) to perform the point level evaluation.

**Compared Methods.** Since there is no existing method for TSE, we modify the popular time series diffusion model CSDI  and the recent conditional diffusion model Time Weaver  for TSE. As CSDI is unable to process attributes, we add an extra attribute encoder to incorporate attribute information. For Time Weaver, we slightly modify its attribute encoder for our settings. After pretraining the modified CSDI and Time Weaver, we use them to edit time series via the editing procedure described in Sec. 3.2. Our proposed TEdit-CSDI and TEdit-TW are implemented by incorporating core processing modules of CSDI and Time Weaver into our proposed multi-resolution noise estimator Sec. 3.3, and trained via Sec. 3.4. Architecture details are presented in Appendix D.

**Implementation Details.** For all experiments, we set the number of diffusion steps as \(T=50\), embedding size for attributes and time series as 64, and use Adam optimizer  to train the model. For pretraining, we set (batch size, learning rate) as (256, 1e-3); for finetuning, we set them as (64,1e-7) for Synethtic and (32,1e-7) for Air Quality and Motor Imagery. We conduct a grid search for the hyperparameters of the multi-resolution. Considering the balance between performance and efficiency, we chose a compromise ratio for bootstrap. Specifically, \((R,L_{p},)=(3,2,0.5)\) for Synthetic, \((3,2,0.5)\) for Air Quality, \((3,3,0.5)\) for Motor Imagery. All our experiments were conducted on a single Nvidia-A100 GPU.

### Main Results

In this section, we quantitatively evaluate the performance of comparison methods for editing and preserving attributes (**RQ1**) for all the datasets. For the edited attributes \(_{}\), we report the RaTS and CTAP scores to depict the models' ability to edit attributes. For the preserved attributes \(_{}\)we report the \(|\)RaTSl and CTAP scores to depict the models' ability to preserve attributes. For the Synthetic dataset, since we have the ground truth, we also include MSE and MAE to evaluate the overall disparity between the ground truth \(^{}\) and the generated \(}^{}\).

In Tab. 1, we present the averaged results over all the finetuning sets for each dataset. The detailed results for each finetuning sets are presented in Appendix I.1. Firstly, for the overall performance (MSE and MAE), the proposed TEdit could significantly outperform baselines. Secondly, for the edited attributes \(_{}\), TEdit-CSDI and TEdit-TW could respectively outperform CSDI and Time Weaver on RaTS and TAP, showing that \(}^{}\) generated by TEdit could better fulfill the desired target \(_{}\). Thirdly, for the preserved attributes \(_{}\), TEdit could basically maintain \(|\)RaTSl and TAP scores, which indicates TEdit is capable of preserving \(_{}\). In summary, these observations show that TEdit, including the multi-resolution and bootstrap learning, could improve the ability of conditional diffusion models to edit \(_{}\) and preserve \(_{}\).

### Ablation Study

In this subsection, we conduct ablation studies on the Synthetic and Motor datasets based on the TEdit-TW to investigate the impact of the proposed multi-resolution modeling (**RQ2**) and the bootstrap training algorithm (**RQ3**). The averaged results over all the finetuning sets are presented in Tab. 2.

Firstly, we compare TEdit-TW trained with BS (BootStrap) with TEdit-TW trained with GT (Ground Truth) on the Synthetic dataset3. For GT, we finetune TEdit-TW by minimizing MSE between the generated \(}^{}\) and the ground truth \(^{}\). It can be observed that GT performs much better than BS on the overall metrics (MSE and MAE), and it is only slightly better than BS on the attribute level metrics for both edited and preserved attributes, demonstrating that BS has a strong ability to capture the attribute semantic information. Secondly, we remove BS from TEdit-TW and compare its performance with the full TEdit-TW model. For the Synthetic dataset, BS could improve the overall scores, and maintain the performance on other attribute level metrics. For the Air dataset, BS primarily improves the scores of the edited attributes, with a trade-off in the scores of the preserved attributes. We hypothesize that there might exist some intrinsic connections between the two attributes: city and season. For the Motor dataset, BS can enhance the performance on the edited attribute while maintaining the performance on the preserved attributes. Thirdly, we investigate the contribution of MR (Multi-Resolution). For the Synthetic and Air datasets, MR could improve the scores on all metrics. For the Motor dataset, MR helps improve the scores for the edited attributes and mostly sustains the performance on the preserved attributes. These improvements highlight the effectiveness of the proposed MR.

    &  &  &  \\   &  &  &  &  &  &  &  &  &  \\  & \(\)MSE & \(\)MAE & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP \\  CSDI & 0.1789 & 0.3221 & 0.7540 & 0.5405 & 0.1439 & 0.7898 & 0.7452 & 0.1581 & 0.1705 & 0.6311 & 0.0939 & 0.4203 & 0.1597 & 0.6617 \\ Time Weaver & 0.1454 & 0.2898 & 0.9030 & 0.6943 & 0.1169 & 0.8292 & 0.8956 & 0.3266 & 0.1866 & 0.6299 & 0.0979 & 0.4168 & **0.1520** & **0.6691** \\  TEdit-CSDI & **0.1235** & **0.2606** & 0.9257 & 0.7109 & 0.1021 & 0.8553 & 0.8022 & 0.2179 & **0.1614** & **0.6529** & 0.1016 & 0.4186 & 0.1580 & 0.6654 \\ TEdit-TW & 0.1315 & 0.2722 & **1.0121** & **0.7957** & **0.0995** & **0.8622** & **0.9661** & **0.9390** & 0.1916 & 0.6274 & **0.1212** & **0.4348** & 0.1571 & 0.6621 \\   

Table 1: Averaged performance over all finetuning sets for Synthetic (left), Air (middle), and Motor (right). “Edited” and “Preserved” are the average results of all edited and preserved attributes.

    &  &  &  \\   &  &  &  &  &  &  &  &  &  \\  & \(\)MSE & \(\)MAE & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP & \(\)RaTS & \(\)CTAP \\  TEdit-TW w GT & **0.1233** & **0.2622** & **1.0165** & **0.7991** & 0.0984 & **0.8650** & - & - & - & - & - & - & - \\ TEdit-TW & 0.1315 & 0.2722 & 1.0121 & 0.7957 & 0.0995 & 0.8622 & **0.9661** & **0.9390** & 0.1916 & 0.6274 & **0.1212** & **0.4348** & 0.1571 & 0.6621 \\  w/o BS & 0.1376 & 0.2793 & 1.0127 & 0.7952 & **0.0962** & 0.8632 & 0.9524 & 0.3792 & **0.1839** & **0.6418** & 0.1113 & 0.4289 & 0.1571 & 0.6658 \\ w/o BS \& 0.1454 & 0.2898 & 0.9030 & 0.6943 & 0.1169 & 0.8292 & 0.8956 & 0.3266 & 0.1866 & 0.6299 & 0.0987 & 0.4168 & **0.1520** & **0.6691** \\   

Table 2: Ablation studies on the Synthetic, Air and Motor datasets. GT, BS and MR refer to Ground Truth source and target pairs, BootStrap and Multi-Resolution. Results are averaged over all finetuning sets. “Edited” and “Preserved” are the average results of all edited and preserved attributes.

### Extended Investigation

We further conduct an in-depth analysis of the effectiveness and efficiency of our TEdit, aiming to reveal how it works through quantitative comparison and visualization.

**Editing vs. Conditional Generation.** Although conditional generation \(}^{}=_{}(,,^{ })\) can produce time series that satisfy the specified target attribute values, it often struggles to retain sufficient details, particularly for difficult or unobservable attributes, since it generates samples from scratch. In contrast, editing \(}^{}=_{}(^{}, ^{},^{})\) is designed to modify the attributes of existing time series, and thus is able to preserve much detail information. We first quantitatively compare the two modes on the Synthetic data. The averaged MSE and MAE over all the finetuning datasets are presented in Tab. 3, which shows that editing could significantly outperform conditional generation with much better (lower) MSE and MAE scores.

We further showcase how editing and conditional generation work at the sample level. Fig. 4, plots the generated results of these two modes under. We can observe that the edited time series could better align with the target attributes, Fig. 4(a)(b), and preserve the characteristics of the source time series, e.g., bias in Fig. 4 (a). In comparison, conditional generation tends to produce smooth samples around the dataset mean. Additionally, we can also see in Fig. 4 that the MSE scores of editing are much lower than conditional generation. More visualization results can be found in Appendix I.4

**Efficiency of Multi-Resolution Generation.** Considering that multi-resolution modeling and generation brings additional efforts for processing different resolutions, as discussed in Sec. 3.3. We compare the running time of serial processing and parallel processing implementations of the multi-resolution paradigm with total resolution number \(R=3\) and patch length \(L_{p}^{r}=3^{r},r\{0,...,R-1\}\). The experiment is conducted on the Synthetic dataset with a batch size of 32. The serial processing iterative processes a single resolution at a time, whereas the parallel processing concatenates multiple resolution sequences along the length dimension and processes them simultaneously. We record the time it takes for the full noise estimator and the processing module to complete the forward diffusion process. As shown in Tab. 4, our designed parallel mechanism can significantly improve the inference efficiency.

**Bootstrap Improves the distributional coverage of the attribution space.** Fig. 5 visualizes the dimension reduced distribution of (a) the raw data, (b) the generated data and (c) the mixed data, on the Synthetic dataset using t-SNE . We can observe that the newly generated data fulfill the uncovered region of the original raw data therefore enhance the data coverage over the whole space, which explains how the bootstrap learning helps generative model training. More visualization analysis can be found in Appendix I.5.

### Sensitivity Analysis

In this subsection, we conduct sensitivity analysis to study the impacts of hyper-parameters of the multi-resolution mechanism and bootstrap learning.

   Running time (ms) & Serial processing & Parallel processing \\  Noise estimator & 11.1 & 6.0 \\ Processing module & 8.8 & 3.7 \\   

Table 4: Running time (ms) of the multi-resolution modeling and generation module, averaged over 1000 samples.

Figure 4: Case study for editing and conditional generation, under two settings: (a) editing the trend type from logistic to linear; (b) editing the trend type from linear to quadratic and the season cycles from 1 to 4.

    & &  \\  Method & Mode & MSE\(\) & MAE\(\) \\   & Cond. Gen. & 0.2581 & 0.4096 \\  & Edit & **0.1235** & **0.2606** \\   & Cond. Gen. & 0.2875 & 0.4308 \\  & Edit & **0.1315** & **0.2722** \\   

Table 3: Quantitative comparison of editing and conditional generation on the Synthetic dataset. The results are averaged over all the finetuning sets.

**Multi-resolution hyper-parameters.** We perform a sensitivity study for the hyper-parameters of the proposed multi-resolution, i.e., the patch length \(L_{p}\) and the number of resolutions \(R\), on one Synthetic finetuning set, which aims to edit trend directions while preserving other attributes. The results are presented in Fig. 6. More results on other Synthetic finetuning sets can be found in Appendix I.2.

To analyze the impact of \(R\), we fix \(L_{p}=2\) and vary \(R\). As shown in Fig. 6 (a), trend types prefer \(R=3\), whereas seasonal cycles perform better with \(R=4\). To examine the impact of \(L_{p}\), we fix \(R=3\) and vary \(L_{p}\). According to Fig. 6 (b), trend types show a preference for \(L_{p}=2\) while seasonal cycles prefer \(L_{p}=3\). Besides, we find that our proposed multi-resolution paradigm always performs better than the vanilla single resolution time-series modeling paradigms, i.e., \(L_{p}=1\) or \(R=1\), which corroborates the discussion in Sec. 3.3 that attributes may influence the time-series generation at different scales and granularities.

**Bootstrap learning hyper-parameters.** We conduct a sensitivity study on the hyper-parameters of bootstrapping, specifically the bootstrap ratio \(\) within the range \(\{0.1,0.3,0.5,0.7,0.9\}\) on a Synthetic finetuning set, which aims to edit the trend direction while preserving others. As shown in Fig. 7, the model exhibits a poor performance then the bootstrap ratio is low, e.g., 0.1. The model has a good performance with medium to high bootstrap ratios. We hypothesize that this is because tuning with only a few top samples might lead to certain mode collapse.

## 5 Conclusion

In this paper, we introduced the task of Time Series Editing (TSE), which enables controllable time series synthesis by manipulating specific attributes of the input time series while maintaining consistency in other properties. There are two major challenges of TSE. Firstly, in the real world, the distribution of time series and attributes is usually biased, and the full space might not be adequately covered. Secondly, time series and attributes exhibit complex multi-scale entanglement. To address these two challenges, we propose a novel diffusion based approach, called TEdit, which incorporates a bootstrap learning algorithm and a multi-resolution modeling and generation paradigm. Comprehensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of our proposed TEdit in generating precise time series with specified attributes. In practice, our method still has certain limitations. For example, different attributes have varying difficulty degrees to edit; attributes may have complex inter-dependencies, and some attributes may be difficult to edit without affecting others. Despite this limitation, we believe our work lays the groundwork for controllable time series synthesis, potentially benefiting applications in fields such as climate monitoring, healthcare, and urban management.

## 6 Acknowledgment

This work is supported by HPC Platform of ShanghaiTech University, Shanghai Frontiers Science Center of Human-centered Artificial Intelligence, and MoE Key Lab of Intelligent Perception and Human-Machine Collaboration. We would like to express our sincere gratitude for their valuable support and resources that contributed significantly to the success of this research.