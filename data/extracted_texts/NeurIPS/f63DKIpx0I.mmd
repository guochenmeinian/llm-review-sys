# Self-Healing Machine Learning: A Framework for Autonomous Adaptation in Real-World Environments

Paulius Rauba

University of Cambridge

pr501@cam.ac.uk

&Nabeel Seedat

University of Cambridge

ns741@cam.ac.uk

&Krzysztof Kacprzyk

University of Cambridge

kk751@cam.ac.uk

&Mihaela van der Schaar

University of Cambridge

mv472@cam.ac.uk

###### Abstract

Real-world machine learning systems often encounter model performance degradation due to distributional shifts in the underlying data generating process (DGP). Existing approaches to addressing shifts, such as concept drift adaptation, are limited by their _reason-agnostic_ nature. By choosing from a pre-defined set of actions, such methods implicitly assume that the causes of model degradation are irrelevant to what actions should be taken, limiting their ability to select appropriate adaptations. In this paper, we propose an alternative paradigm to overcome these limitations, called _self-healing machine learning_ (SHML). Contrary to previous approaches, SHML autonomously diagnoses the reason for degradation and proposes diagnosis-based corrective actions. We formalize SHML as an optimization problem over a space of adaptation actions to minimize the expected risk under the shifted DGP. We introduce a theoretical framework for self-healing systems and build an agentic self-healing solution \(\)_-LLM_ which uses large language models to perform self-diagnosis by reasoning about the structure underlying the DGP, and self-adaptation by proposing and evaluating corrective actions. Empirically, we analyze different components of \(\)-LLM to understand _why_ and _when_ it works, demonstrating the potential of self-healing ML.

## 1 Introduction

Consider the following scenario: You are tasked with monitoring the performance of a black-box model \(f\) deployed in production. After some time, you notice that the predictive performance of \(f\) has started to degrade. What would be the appropriate action \(a\) you should take to ensure that the model's performance returns to its prior performance levels: \(a_{1}\): re-train the model on a subset of the data; \(a_{2}\): change the type of the model used; \(a_{3}\): remove discovered corrupted values; \(a_{4}\): add new covariates?

Clearly, the answer to this question is "it depends". Different actions might result in different behavior of the model over time, as illustrated in Fig. 1. If we could pinpoint _why_ the performance of the model has degraded, it could help us understand _what_ actions are most promising, since we could select an action which would directly address the root cause of the problem.

Figure 1: Different adaptation strategies \(a_{1},,a_{4}\) might result in different performance after an environment change.

While we take this intuition for granted, state-of-the-art techniques for handling model degradation do not reflect this line of reasoning and rely on _pre-determined actions_, such as model retraining [1; 2; 3; 4; 5], re-using old models [1; 6; 7; 8], or other specialized methods [6; 9; 10; 11; 12]. Such approaches share a common, implicit assumption --the _reason_ for the degradation in model performance is irrelevant. We refer to this as _reason-agnostic methods_.

The practical implications of methods being _reason-agnostic_ are quite concerning. By not considering the causes for drop in performance, the corrective actions are, essentially, shots in the dark. In high-stakes applications like healthcare, finance, or policing, misguided adaptations can lead to real-world harms, such as inaccurate diagnoses, financial losses, or system failures. In some industries--such as healthcare-- this has resulted in _avoiding_ automated model retraining altogether .

We propose _self-healing machine learning_ (SHML) to overcome the limitations of reason-agnostic approaches. SHML equips ML models with the ability to diagnose the reasons for performance degradation and take targeted corrective actions. We define a _self-healing system_ as a tuple \((,f)\), where \(f\) is a black-box _model_ and \(\) is a _healing mechanism_ that can _modulate_ the behavior of \(f\). An example of \(\) modulating \(f\) is by deciding what data to use to re-train \(f\), as illustrated in our introductory example. \(\) contains four _components: monitoring, diagnosis, adaptation_, and _testing_ (Fig. 2). The goal of \(\) is to decide what actions to take in response to model degradation which are chosen based on an _adaptation policy_ that provides a mapping from diagnoses to actions. We therefore formalize the goal of \(\) as finding optimal actions under the shifted data generating process (DGP) which are sampled from an adaptation policy conditioned on a diagnosis (Sec. 3.3). In our introductory example, the optimal action is taking action \(a_{1}\) (Fig. 1). Building upon these insights, we propose the first self-healing ML algorithm, \(\)-LLM (Sec. 5) which generates diagnoses behind model degradation and suggests diagnosis-based adaptation strategies.

**Significance beyond technical contributions**. By enabling systems to autonomously diagnose and adapt to model degradation, we lay the groundwork for a new class of self-healing algorithms. We envision self-healing systems as crucial for high-stakes applications where optimal model performance is essential. We also believe this work has immediate practical relevance in high-stakes areas where model degradation is common, such as medicine [14; 15; 16; 17; 18], fraud detection  or finance .

**Contributions**. 1 We identify fundamental limitations in existing _reason-agnostic_ adaptation approaches that do not consider the reason for model degradation (Sec. 3.2). 2 We introduce the paradigm of _self-healing machine learning_ and establish a theoretical foundation for finding adaptation actions with diagnosis-guided action sampling (Sec. 3.3 - 4). 3 We propose the first self-healing ML algorithm \(\)-LLM which reasons about the causes of degradation and modulates the behavior of ML models (Sec. 5). 4 We demonstrate the viability of SHML by studying _why_ and _when_ it works (Sec. 6).

## 2 Related work

SHML is most closely related to _concept drift adaptation_ or _specialized drift handling_ methods. We provide an extended discussion on related work within each component in Appendix A.

**Concept drift adaptation.** The field of concept drift adaptation focuses on developing algorithms to maintain the performance of machine learning models in changing environments. Such algorithms are predominantly proposed within the setting of tabular data. Most common adaptation techniques are re-training models on new data [1; 2; 3; 4; 5; 21; 22; 23; 24], re-using stored models [1; 6; 7; 8; 9] or obtaining new data altogether [25; 26]. These approaches can be implicit, like continuous retraining, or explicit, based on drift detection in data or model error [5; 23; 27]. Because these approaches do not explicitly

Figure 2: Our work introduces self-healing machine learning. A healing mechanism \(\) interacts with a deployed model \(f\). \(\) contains four _components_: monitoring, diagnosis, adaptation, and testing. The overall goal of SHML is to find optimal adaptation actions to maximize the predictive performance of a model \(f\).

incorporate the reason for model degradation, we refer to them as _reason agnostic_. SHML diverges from common approaches by introducing the core idea of _diagnosing the root cause_ to search for optimal adaptation actions.

**Specialized drift handling.** Techniques have also been developed to adapt in the presence of various drift scenarios, such as sliding windows  or _adaptive classifiers_[11; 28; 29; 30; 31; 32] which "repair" concept drift . However, these methods lack an explicit diagnosis mechanism and operate under fixed decision rules, which do not incorporate the root causes of degradation into the adaptation strategy. Similarly, works that aim to understand distribution shifts [33; 34; 35] or attribute shifts to specific variables through causal mechanisms [36; 37] provide valuable insights but do not offer a comprehensive framework for adaptation. We note that some work could be in principle a part of some SHML system components (discussed in Appendix A).

## 3 Self-healing Machine Learning

This section introduces self-healing machine learning and its four components. We present the problem setting (Sec. 3.1), explain current limitations (Sec. 3.2), and outline the four stages of SHML (Sec. 3.3). NOTE: Table 1 serves as a guide for navigating the paper.

### Model degradation over time

**Preliminaries**. Let \(\) and \(\) denote the input and output spaces, respectively, and let \(_{t}\) denote the data distribution over \(\) at time step \(t[T]\). At each \(t\), we observe a batch of data \(_{t}=\{(_{t}^{(i)},y_{t}^{(i)})\}_{i=1}^{n_{t}} _{t}^{n_{t}}\), where \(n_{t}=1\) in the streaming setting and \(n_{t}>1\) in the batch setting. We will drop the superscripts where clear from context.

The goal is to learn a sequence of functions \(\{f_{t}\}_{t=1}^{T}\) that minimize the cumulative risk:

\[R(f_{1},,f_{T})_{t=1}^{T}_{(,y) _{t}}[(f_{t}(),y)]\] (1)

where \(\) is a function class and \(:_{ 0}\) is a loss function.

In the time-invariant setting where \(_{t}=\  t[T]\), the goal reduces to learning a single function \(f^{}\) that minimizes the risk \(R(f)=_{}[(f(),y)]\). When \(\) is unknown, \(f^{}\) is often approximated by minimizing the empirical risk on a training set \(\{(^{(i)},y^{(i)})\}_{i=1}^{n}^{n}\). However, when \(_{t}\) evolves over time, the optimal predictor \(f^{}_{t}_{f}_{_{t}}[(f (),y)]\) changes across time steps1. Failing to adapt \(f_{t}\) in this time-varying setting leads to model degradation, as the learned function becomes increasingly suboptimal w.r.t. the current data distribution.

### Limitations of existing approaches in adapting to changing environments

Maintaining stable model performance in the presence of a changing environment poses unique challenges. As the optimal predictor \(f^{}_{t}\) evolves over time, the estimated predictor should also adapt. Ideally, we could obtain a large batch of data \(_{t+1}=\{(_{t+1}^{(i)},y_{t+1}^{(i)})\}_{i=1}^{n_{t+1}}\) and minimize the empirical risk over this dataset. However, this is often impractical due to constraints such as (i) ground-truth labels not being immediately available ; (ii) the streaming setting, where each new batch contains only one data point ; (iii) gradual shifts, where past data remains relevant ; or (iv) the presence of corrupted data in new batches .

  
**Component** & **Definition** & **Methodological contribution** & **Experimental** & **Main practical implications** \\   &  & \)} & Sec. 6.3 & More robust models against false positive drift detection (Sec.6.3) \\  & & Eq. 5 & Def. 1, Def. 2, Prep. 2 & Sec. 6.4 & Established framework to reason about why models degrade (Sec. 4) \\
**Adaptation** & Eq. 6 & Amp. 1 & Sec. 6.5 & Targeted adaptation by identifying the root cause (Sec. 4) \\
**Testing** & Eq. 7 & Def. 3 & Sec. 6.6 & Principedied framework to evaluate actions (Sec. 6.6) \\   &  &  &  \\  & Sec. 3.3 & 5.3 & 3.2, first self-healing system (Sec. 5. ) \\   

Table 1: A summary table of self-healing machine learning and its four stages, providing links to relevant sections and serving as a navigation guide for the paper.

To address this, the research community has developed specialized methods determining the appropriate corrective actions in such drifts. As discussed in Sec. 2, these methods primarily execute pre-defined actions upon detecting a change, such as model retraining , re-using old models , or other more specialized methods . However, such methods are _reason-agnostic_, disregarding valuable information that inform better adaptation actions. Consider an illustrative example: suppose a batch of new data arrives, but due to a sensor malfunction , 80% of the labels become corrupted and are independent of the input for that batch only. Naively retraining the model on this noisy batch would degrade its performance. This is because this strategy implicitly assumes:

\[_{(,y)_{t+1}}[(f_{t+1}(),y)] <_{(,y)_{t+1}}[(f_{t}(),y)].\] (2)

where \(f_{t+1}\) is a model trained on \(_{t+1}\). Relying on this assumption results in _worse performance_ than doing nothing. Similarly, re-using old models assumes that the past data distribution is still relevant:

\[_{(,y)_{t+1}}[(f_{t-k}(),y)] <_{(,y)_{t+1}}[(f_{t}(),y)],\] (3)

for some \(k>0\). Similarly, this might result in suboptimal performance due to the nature of the shift. Each adaptation method discussed in Sec. 2 has such implicit assumptions about the model or DGP.

_By not taking into account the reason for the model degradation (such as corrupted data), the adaptation strategy is defaulting to suboptimal corrective actions._ While any adaptation strategy inherently involves some assumptions about the relationship between the predictor and the data, we would like to prioritize making _informed assumptions_. As we discuss in Sec. 3.3, a key source of such information is diagnosing _why_ the model's performance has dropped.

To address the _reason-agnostic_ nature of such adaptation methods, we propose a paradigm shift called _self-healing machine learning_ (SHML), where deployed models autonomously diagnose the reason for degradation and take _diagnosis-guided_ corrective actions.

**Takeaway**. Existing adaptation methods make implicit, pre-defined assumptions about the nature of model degradation. Neglecting its _reason_ can lead to poorly chosen actions.

### The four stages of self-healing machine learning

Self-healing machine learning is a framework for autonomously detecting, diagnosing, and correcting performance degradation in deployed ML models. It aims to maintain model performance in changing environments without constant human intervention. The motto of self-healing ML is "understanding your problem is half the solution" (and the most important half). A SHML system is defined by a tuple \(,f\), where \(f:\) is the deployed machine learning model we aim to heal (i.e., the function that makes predictions on input data), and \(\) is a healing mechanism that interacts with the environment and acts upon the model \(f\) by proposing and implementing actions, such as selecting when to retrain a model, what data to use or how to change the input data before making predictions. Thus, \(\) can _modulate_ the behavior of the deployed model \(f\).

**Self-Healing Machine Learning in a nutshell**.

Self-healing ML contains four components: monitoring, diagnosis, adaptation, and testing. After these steps, the best action is implemented on the ML model, illustrated in Fig. 2.

**I. Monitoring**. The first step is the detection of degradation, potentially due to a shift in the data distribution. We formalize this as a _monitoring_ component \(_{M}\) that takes as input the sequence of data batches \(\{_{i}\}_{i=1}^{t}\), up to time \(t\), and outputs \(s_{t}\), indicating the likelihood of model degradation. Formally,

\[_{M}:()^{*},\] (4)

where higher values of \(s_{t}\) indicate a greater likelihood of a shift.

**II. Diagnosis**. The diagnosis component \(_{D}\) detects the reason of degradation. It takes data batches \(\{_{i}\}_{i=1}^{t}\), up to time \(t\), along with any available contextual information \(c\) (e.g. background knowledge), and outputs a distribution \(()\) over a space of possible reasons \(\):

\[_{D}:()^{*} ().\] (5)

\(\) represents the finite space of possible reasons of the shift and \(\) is a stochastic vector.

**III. Adaptation**. The adaptation component is a policy \(\) that outputs a distribution over actions. Given a diagnosis vector \(\), actions \(a\) are selected from a finite space \(\) by:\[a(|),:()().\] (6)

Each action \(a\) modifies \(f\). We denote the model used at time \(t\), selected by action \(a\), as \(f_{a}^{t}\).

**IV. Testing**. The _testing_ component \(_{T}\) evaluates each action \(a\) on a relevant distribution and outputs a performance measure:

\[_{T}:.\] (7)

**Objective**. The goal of self-healing ML is to select the optimal action \(a^{*}\) that minimizes the expected loss \([(f_{t}^{a}(),y)]\) on the data distribution \(_{t}\):

\[a^{*}=*{arg\,min}_{a}_{(,y) _{t}}[(f_{t}^{a}(),y)],\] (8)

where \(:_{ 0}\) is a loss function, and \(f_{t}^{a}\) denotes the model selected by action \(a\) to be used at time \(t\). The action \(a\) is selected according to the adaptation policy \((|)\), which maps the diagnosis vector \(\) (a distribution over possible reasons for degradation) to a distribution over actions.

Suppose the following motivating example to guide the notation above.

The primary insight of SHML is that the action \(a(|)\) should be based on the diagnosis \(\), which is a distribution over possible reasons \(z\) for model degradation. In contrast, standard approaches (Sec. 3.2) assume that \(\). SHML formalizes this as an optimization problem over a space of adaptation actions--we aim to find the optimal actions to take each time the model \(f\) degrades, with these actions chosen by the policy \(\) of the self-healing system \(\) (Fig. 3). Different policies \(_{1}\) and \(_{2}\) might propose different actions in response to the same performance drop. While the diagnosis \(\) informs the policy, we do not assume it is necessarily useful. Since \(()\) is a probability distribution, it can encode no knowledge by being uniform over the diagnosis space: \((z)=|}, z\). These components and their interactions between two time points \(t\) and \(t+1\) are shown in Fig. 3.

The effectiveness of the adaptation actions depends on the diagnosis, i.e. how well can we identify the root cause. Therefore, we turn to the _diagnosis_ component next.

[style=]
**Takeaway**. SHML is a framework which selects actions based on the reason for model degradation. It contains four stages: monitoring, diagnosis, adaptation, and testing.

## 4 An analysis of the properties of self-healing diagnosis

Self-healing systems have the unique property of having a diagnosis stage. But what constitutes a good diagnosis? In this section, we analyze the properties of self-healing diagnosis and establish its connection to the performance of adaptation actions.

To effectively use diagnosis information to guide the search for adaptation actions, we require a way to quantify the usefulness of a diagnosis. We propose three desirable properties for such a measure: (i) **concentration**: it should favor diagnoses that provide more information, i.e. assign higher probabilities to fewer possible reasons; (ii) **sensitivity**: it should be sensitive to changes in the diagnosis distribution, such that small changes in probabilities would result in small changes in the measure; (iii) **maximum uncertainty**: it should reach its maximum value when the diagnosis

Figure 3: The self-healing mechanism \(\) modulates the function \(f\) via four stages. The chosen adaptation action \(a\) is implemented onto the function \(f\) at the next time step.

distribution is uniform, indicating no knowledge about the reason for degradation. Therefore, we propose using the entropy of the diagnosis vector as a useful proxy for quality which satisfies all three properties. Because entropy measures uncertainty, we refer to this as the _certainty of the diagnosis_.

**Definition 1** (Certainty of the Diagnosis).: _Let \(\) be the finite space of possible reasons for degradation and \(()\) be the diagnosis space. The certainty of a diagnosis \(()\) in a self-healing machine learning system is measured by its entropy \(()\), defined as:_

\[()=-_{z}(z)(z),\] (9)

_where \((z)\) is the probability of reason \(z\) under the distribution \(\)._

The link between diagnosis quality and adaptation performance highlights the importance of obtaining informative diagnoses in SHML. Building upon these concepts, we define the optimal diagnosis:

**Definition 2** (Optimal Diagnosis).: _The optimal diagnosis \(^{*}\) is defined as:_

\[^{*}=*{arg\,min}_{()}_{a (|)}[R(a)]\] (10)

_where \(()\) is the diagnosis space, \((|)\) is the conditional distribution over actions induced by diagnosis vector \(\), and \(R(a)\) denotes the risk of \(f_{t}^{a}\) associated with action \(a\)._

This formalizes the intuition that the best diagnosis is the one that leads to the best adaptation actions, on average. To characterize the properties of this optimal diagnosis, we introduce an assumption about the structure of the adaptation policy:

**Assumption 1** (Independent actions).: _We assume that \((|)\) has a hierarchical structure. First, a reason \(z\) is sampled according to the diagnosis \(\): \(z\). Then, an action is sampled conditioned on this reason, \(a(|z^{})\), where \(z^{}()\) such that \(z^{}(z)=1\). \((|)\) can then be described as the following mixture._

\[(a|)=_{z}(a|z^{})(z)\] (11)

\(\) _are the mixture weights and \(\{(|z^{}) z\}\) are the mixture components._

Under this hierarchical structure, we can prove a useful property of the optimal diagnosis:

**Proposition 1**.: _Under Assumption 1, the optimal diagnosis \(^{*}\) has a zero entropy, i.e., \((^{*})=0\)._

Proof in Appendix E. To ensure that the optimal diagnosis is well-defined, we also prove its existence under mild assumptions:

**Proposition 2** (Existence of Optimal Diagnosis).: _Suppose that the action space \(\) is a compact subspace of \(^{n}\) and \(R\) is continuous. Then there exists at least one optimal diagnosis \(^{*}\)._

Proof.: The expected risk \(_{a(|)}[R(a)]\) is a continuous function of \(\) by the continuity of \(R\) and the compactness of \(\). Since the diagnosis space \(()\) is also compact (being a probability simplex), the extreme value theorem guarantees the existence of a minimizer \(^{*}\). 

**Takeaway**. The existence of an optimal diagnosis establishes a foundation for designing algorithms that can accurately approximate it in practice. By identifying the underlying reasons for performance degradation, a high-quality diagnosis enables a self-healing system to take the most effective adaptation actions.

## 5 Building self-healing systems: \(\)-Llm

This section outlines the challenges of building SHML systems (Sec. 5.1), describes how LLMs can address these challenges (Sec. 5.2), and introduces the first self-healing system, \(\)-LLM (Sec. 5.3).

### Unique challenges of building self-healing systems

Implementing SHML systems (Sec. 3.3) poses unique challenges in diagnosis and adaptation.

**Challenges in diagnosis**. Discovering the reasons for model degradation poses significant practical challenges because: (i) the space of possible reasons \(\) is often poorly defined or intractable to specify exhaustively in real-world scenarios; and (ii) assigning well-calibrated probabilities to reasons for model degradation is difficult due to both the epistemic and aleatoric uncertainty that exists in real-world environments. This makes it difficult to approximate the optimal diagnosis (Def. 2).

**Challenges in adaptation**. The adaptation policy \(\) (Eq. 6) requires selecting optimal adaptation actions \(a\) based on the diagnosis \(\). This is challenging because (i) it requires reasoning about how actions interact with diagnoses; and (ii) the space of adaptation actions may be extremely large in practice, making it difficult to find the optimal action (Eq. 8).

### Language models to empower self-healing

We posit that LLMs have the potential to satisfy many of the required properties of self-healing components because of the following capabilities: (i) **Hypothesis proposers**. LLMs are known to be "phenomenal hypotheses proposers"  which are required to hypothesizing diagnoses of ML model performance degradation; (ii) **Contextual understanding**. LLMs have been pretrained with a vast corpus of information and hence have extensive prior knowledge around different contexts and settings ; (iii) **Language model agents**. Language models can work as agents within a larger system  which is required to actively interact with a deployed model, trigger and implement changes. We therefore see LLMs as capable proxies for different self-healing components.

### Design of \(\)-LLM

We instantiate the healing mechanism \(\) with an LLM \(l\), using its useful properties (Sec. 5.2) to address the practical challenges of designing SHML systems (Sec. 5.1).

\(\)**-LLM in a nutshell**.

\(\)-LLM is the first SHML algorithm that modulates the behavior of \(f\) following Fig. 3.

**I. Monitoring**. We use statistical drift detection algorithms to monitor model degradation from \(k\) previous time points . Diagnosis is triggered if a shift is detected.

**II. Diagnosis**. Upon detection, we use a pre-defined prompt template to obtain information about the dataset before and after the diagnosis. The prompt template gives us numerical insights into how the dataset has changed and includes covariate information before and after the shift, together with other numerical details. We denote this prompt as an extractor function \(:^{*}_{c}\) to obtain an information vector \(\). Using \(\) and a chain-of-thought (CoT) module with self-reflection, \(\)-LLM generates \(k\) candidate reasons for degradation \(\{_{i}\}_{i=1}^{k}(|)\) via Monte Carlo (MC) sampling with associated confidence scores. As before, this is obtained by following pre-defined prompt templates _conditioned on_ the obtained information (e.g. "_Suggest (self.n) possible reasons why the model might have failed on the basis of the issues presented_"). These candidates form an empirical diagnosis vector \(\), approximating the optimal diagnosis \(^{*}\). Table 2 illustrates diagnoses generated by \(\)-LLM.

**III. Adaptation**. Conditioned on the empirical diagnosis distribution \(\), \(\)-LLM generates \(m\) candidate adaptation actions \(\{a_{j}\}_{j=1}^{m}(|)\) via CoT-based MC sampling. This approximates sampling from \((|^{*})\) (Def. 6). The actions sampled from \(l\) are textual representations, so we use an interpreter function to execute each \(a\) on \(f\).

**IV. Testing**. The sampled actions are evaluated on an empirical dataset (Def. 7), and the empirically optimal action \(^{*}=_{j\{m\}}R(a)\) is implemented. Limited access to the shifted DGP complicates evaluating \(R(a)\), but it can be approximated with empirical data \(}_{}\) by using _a backtesting window_, _continuously incoming data_, or _historical data_ (Appendix B.4).

**Goal**. This procedure aims to approximate the optimal action (Def. 8). These actions are orchestrated by an orchestrator component in \(\)-LLM which can navigate between these steps.

  Diagnosis & Evidence & Confidence (1-1h) \\  There are outliers in the data & The maximum values for many variables in the new dataset are significantly higher than in the old dataset, suggesting & 9 \\ Incorrect data transformations between applied & The mean value for many variables in the new dataset are significantly higher than in the old dataset, suggesting the data may have been incorrectly transformed & 8 \\ There are data entry curves & The minimum value for health in the new dataset is negative, which is not possible in a real-world context & 10 \\  

Table 2: Example diagnoses suggested by \(\)-LLM. The system proposes diagnoses and suggests evidence for the diagnosis. A post-hoc relative confidence score, constructed using the “evidence” column, helps to guide which diagnoses to pay most attention to while designing adaptation policies.

Appendix B provides an extended discussion of \(\)-LLM, including the algorithm, prompts, examples, and outputs. The following table links \(\)-LLM with the theoretical framework.

## 6 Experimental viability studies

The previous sections constituted the primary contribution of our paper--establishing SHML as a framework. The goal of this section is to provide a _viability_ study by analyzing different components of SHML. We conduct six viability studies.2

**Experimental setup**. We desire to meet two properties: (i) have full control of the DGP to vary experimental parameters; and (ii) we need to benchmark against existing adaptation methods (Sec. 2) which are predominantly tabular-based. Therefore, we simulate a diabetes prediction task [49; 50; 51] based on the setup in Sec. 3.1. We predict diabetes \(Y_{t}\{0,1\}\) at each time point \(t\) for a set of \(n\) observations, generated according to a (changing) pre-specified DGP \((=1|X_{t})}{P(Y_{t}=0|X_{t})})=_{t}+_{k  K}_{t,k}X_{t,k}+_{t}\), where \(K\) includes relevant parameters such as Age or BMI, \(_{t,k}\) are time-varying covariates and \(_{t}(0,^{2})\) is a noise component. For evaluating \(\)-LLM actions, we use a _backtesting window_--a representative sample of the shifted distribution obtained after detecting the change but before deploying the adapted model (Sec. B.4). Details provided in Appendix C.

### Viability study I: Adaptation in the presence of model degradation

Setup. We aim to empirically demonstrate the limitations of existing approaches in adapting to changing environments (Sec. 3.2). We benchmark \(\)-LLM against four common drift adaptation methods: (i) _new model retraining_ on post-drift data, (ii) _partially updating_ models with new data; (iii) _Ensemble methods_ by re-using old models, and (iv) _No retraining_ of the models . At time \(t\), we introduce a sudden, single intervention by changing the DGP parameters _and_ corrupting a percentage \(\) of \(k\) columns. Table 4 shows the performance of different methods across \(\) and \(k\).

Discussion. The performance of \(f\) degrades if the corrupted columns are not handled appropriately, such as removing or inputting the corrupted data. Defaulting to standard techniques of adapting to a changed environment results in poor performance. \(\)-LLM diagnoses issues by observing that some values have drifted too much from their original values _and_ the DGP has changed. One of the proposed adaptation strategies is to remove samples which were estimated to be corrupted, and re-training the model on the remainder of the data. This results in superior performance.

Takeaway 1. Diagnosing the root cause of degradation can guide better adaptation actions.

### Viability study II: Adaptation across datasets

Setup. We aim to empirically analyze whether SHML can provide benefits across different datasets. We cover five different datasets: Airlines , Poker , Weather , Electricity , Forest Type

    &  &  \\ _Method_ & 2 & 4 & 6 & 8 & 0.01 & 0.02 & 0.05 & 0.10 & 0.20 \\  No retraining & 0.44 \(\) 0.02 & 0.44 \(\) 0.02 & 0.45 \(\) 0.02 & 0.45 \(\) 0.02 & 0.43 \(\) 0.02 & 0.44 \(\) 0.02 & 0.44 \(\) 0.02 & 0.45 \(\) 0.02 & 0.46 \(\) 0.02 \\ Partially Updating & 0.71 \(\) 0.02 & 0.69 \(\) 0.02 & 0.67 \(\) 0.02 & 0.54 \(\) 0.06 & 0.74 \(\) 0.03 & 0.72 \(\) 0.02 & 0.70 \(\) 0.02 & 0.66 \(\) 0.02 & 0.62 \(\) 0.02 \\ New model training & 0.70 \(\) 0.02 & 0.69 \(\) 0.02 & 0.67 \(\) 0.02 & 0.50 \(\) 0.02 & 0.77 \(\) 0.02 & 0.74 \(\) 0.02 & 0.69 \(\) 0.02 & 0.66 \(\) 0.02 & 0.61 \(\) 0.02 \\ Ensemble Method & 0.70 \(\) 0.02 & 0.69 \(\) 0.02 & 0.50 \(\) 0.02 & 0.77 \(\) 0.02 & 0.74 \(\) 0.02 & 0.69 \(\) 0.02 & 0.66 \(\) 0.02 & 0.61 \(\) 0.02 \\  \(\)**-LLM** & **0.93 \(\) 0.01** & **0.87 \(\) 0.01** & **0.79 \(\) 0.02** & **0.68 \(\) 0.02** & **0.95 \(\) 0.01** & **0.94 \(\) 0.01** & **0.90 \(\) 0.02** & **0.82 \(\) 0.02** & **0.70 \(\) 0.02** \\   

Table 4: Accuracy of a deployed model \(f\) upon an intervention which changes the DGP and corrupts \(\) percentage of \(k\) columns. Error represents standard deviation. \(\) is better.

  
**Component** & **Theory** & \(\)**-LLM** & **Approximation** \\  Monitoring & Monitor for degradation & Drift detection algorithm & Any detection algorithm \\ Diagnosis & Optimal diagnosis \(^{*}()\) & Empirical diagnosis via LLM \(\) & MC sampling with LLM \\ Adaptation & Sample action \(a-()\) & Sample actions via LLM \(a-t()\) & MC sampling with LLM \\ Testing & Evaluate each \(a\) on \(_{t}\) & Evaluate each \(a\) on \(_{t}\) & Any suitable dataset \\   

Table 3: A comparison of the theoretical components, their implementation, and their approximations.

. We simulate real-world unexpected degradations by assuming lagged labels and corrupting features at test time and evaluating models for different datasets (Table 5).

Discussion. Ground-truth labels are often not immediately available , a core feature of many streaming settings. We evaluate how \(\)-LLM compares to existing approaches in such scenarios. Across five datasets with different characteristics, \(\)-LLM consistently outperforms traditional adaptation methods by adapting \(f_{t}^{a}\) at each time point \(t\). Therefore, SHML's ability to identify and decorrupt features provides a robust adaptation strategy across varied data distributions and schemas.

Takeaway 2. Identifying the root cause and restoring features dacn provide consistent benefits across datasets.

### Viability study III: Monitoring

Setup. We use the same setup as experiment I and vary the drift detection threshold which influences the sensitivity of a detection system to changes in the DGP. Low values mean high sensitivity, and high values mean low sensitivity . We measure _average recovery time_ for \(\)-LLM to return recover from degradation and _post-intervention accuracy_, \(\)-LLMs average performance after intervention. Fig. 4 shows this relationship.

Discussion. Intuitively, one might expect earlier drift detection (lower threshold) to consistently yield faster recovery and higher accuracy. In reality, concept drift algorithms often struggle with false positives which can result in _worse_ model performance because of unnecessary re-training [5; 58]. Self-healing ML exhibits greater robustness to these false positives, as any action will be implemented only if it outperforms doing nothing. This contrasts with traditional systems which would automatically trigger the selected action. In Fig. 4, this represents the higher post-intervention accuracy with smaller thresholds.

Takeaway 3. SHML has greater robustness to implementing poor adaptation actions.

### Viability study IV: Diagnosis

Setup. We evaluate how well self-healing systems identify the root causes of problems. We corrupt a proportion of observations (_corruption coefficient_) by multiplying their values by a factor (_outlier factor_) and see if the \(\)-LLM detects issues related to these factors. We output a probability distribution over diagnoses of which variable is corrupted. Knowing the true corrupted variable, we measure the difference between the distributions using KL-Divergence, with lower values indicating closer matches to true corruption. A uniform diagnosis baseline represents random guessing. Fig. 5 shows these differences.

Discussion. As the _outlier factor_ and _corruption coefficient_ increase, making data issues more apparent, \(\)-LLM assigns higher probabilities to the corrupted variables. Thus, the diagnosis accuracy improves as the problem becomes more evident.

Takeaway 4. The quality of the diagnosis improves when the issues become more apparent.

Figure 4: Lower drift detection thresholds can benefit SHML.

Figure 5: KL-Divergence between estimated probabilities of which variables are corrupted, and true probabilities, based on _outlier factors_ and _corruption coefficients_. \(\) is better.

    &  &  \\ _Method_ & airlines & polar & weather & slice & covType & airlines & polar & weather & dec & covType \\  No retraining & 0.53 \(\) 0.01 & 0.48 \(\) 0.01 & 0.57 \(\) 0.05 & 0.66 \(\) 0.04 & 0.51 \(\) 0.03 & 0.53 \(\) 0.01 & 0.47 \(\) 0.01 & 0.59 \(\) 0.04 & 0.67 \(\) 0.03 & 0.58 \(\) 0.01 \\ Partially Updating & 0.53 \(\) 0.01 & 0.48 \(\) 0.01 & 0.57 \(\) 0.05 & 0.66 \(\) 0.04 & 0.51 \(\) 0.03 & 0.53 \(\) 0.01 & 0.47 \(\) 0.01 & 0.59 \(\) 0.04 & 0.67 \(\) 0.03 & 0.58 \(\) 0.01 \\ New model training & 0.54 \(\) 0.02 & 0.49 \(\) 0.01 & 0.56 \(\) 0.03 & 0.66 \(\) 0.05 & 0.51 \(\) 0.02 & 0.53 \(\) 0.02 & 0.47 \(\) 0.00 & 0.60 \(\) 0.02 & 0.67 \(\) 0.03 & 0.58 \(\) 0.02 \\ Ensemble Method & 0.51 \(\) 0.01 & 0.48 \(\) 0.01 & 0.58 \(\) 0.06 & 0.57 \(\) 0.09 & 0.52 \(\) 0.02 & 0.52 \(\) 0.01 & 0.46 \(\) 0.00 & 0.59 \(\) 0.05 & 0.65 \(\) 0.04 & 0.59 \(\) 0.01 \\  \(\)-LLM & **0.56 \(\) 0.00** & **0.70 \(\) 0.03** & **0.66 \(\) 0.02** & **0.72 \(\) 0.01** & **0.73 \(\) 0.00** & **0.56 \(\) 0.00** & **0.70 \(\) 0.03** & **0.66 \(\) 0.02** & **0.72 \(\) 0.01** & **0.73 \(\) 0.00** \\   

Table 5: Accuracy of various methods on different datasets with corrupted columns and varying corruption values. Error represents standard deviations of five runs. \(\) is better. We simulate concept drift by corrupting the test set as follows: we randomly selected \(k\) features and multiplied their values by a corruption factor \(\). \(\)-LLM identifies that the test data has been corrupted and perform a relevant transformation to _decorrupt_ the value to its original feature space at test time.

### Viability study V: Adaptation

Setup. We study the sensitivity of SHML adaptation actions by examining how well actions perform based on (i) the number of corrupted values and (ii) the size of the backtesting dataset. Fig. 6 shows this relationship.

Discussion. As more values are corrupted, adaptation actions become more concentrated and less effective. With a larger backtesting dataset, actions are more spread out. This suggests (i) action evaluation is more reliable with non-corrupted data and (ii) larger backtesting windows help in selecting better adaptations.

Takeaway 5. A large test dataset and high-quality data can improve adaptation action selection.

### Viability study VI: Testing

Setup. We study the importance of the testing component (Eq. 7) by evaluating \(\)-LLM suggested actions with and without the testing phase (backtesting window) and comparing their accuracies. Fig. 7 shows this relationship.

Discussion. Having a dataset to evaluate actions significantly improves the self-healing process. We see that better data quality results in more reliable adaptation policies.

Takeaway 6. The testing component is important to effectively evaluate the proposed actions.

### Other studies

We provide further experiments in Appendix D. Our framework shows strong performance with lower warm-start parameters and increasing benefit as data degradation becomes more severe (Sec. D.4). A component-wise ablation analysis (Sec. D.6) reveals each stage of SHML is essential. Extended benchmarks (Sec. D.5) and model agnostic evaluations (Sec. D.7) demonstrate consistent improvements across different adaptation approaches and ML architectures.

## 7 Discussion

Algorithms hold significant decision-making power in high-stakes applications, yet little has been done to ensure their optimal performance. This work presents a major leap towards that goal. By enabling systems to autonomously diagnose and adapt to new environments, we aim to create a wave of self-healing systems beneficial to both the ML community and society. Our theoretical framework (Sec. 3.3, 4) builds the foundation for the development of self-healing theory, such as optimal adaptation or diagnosis methods, and our viability study shows the potential benefits of SHML. Our largest contribution is formalizing this field--we hope to spur new theoretical developments and encourage the adoption of such systems in critical domains like medicine  and finance .

**Limitations**. SHML's success relies on accurate root cause identification and finding effective adaptation policies which could pose challenges in some complex, real-world settings (Sec. 5.1). Furthermore, the prioritization of adaptation strategies is also not trivial. Currently, \(\)-LLM primarily looks for subgroup-level issues. We see future work tackling all areas of self-healing ML: finding better diagnosis strategies, improving adaptation selection, and enabling better testing of actions in the presence of changing environments.

**Broader impact**. Because SHML could empower many _positive_ technologies, it could also be _misused_ to amplify the impact of more problematic systems, such as surveillance technologies.