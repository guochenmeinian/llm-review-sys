# A normative theory of social conflict

Sergey Shuvaev\({}^{1}\), Evgeny Amelchenko\({}^{2}\), Dmitry Smagin\({}^{3}\),

**Natalia Kudryavtseva\({}^{3}\)**, **Grigori Enikolopov\({}^{2}\)**, and **Alexei Koulakov\({}^{1}\)**

\({}^{1}\)Cold Spring Harbor Laboratory, Cold Spring Harbor, NY, USA; \({}^{2}\)Department of Anesthesiology and Center for Developmental Genetics, Stony Brook University, Stony Brook, NY, USA; \({}^{3}\)Institute of Cytology and Genetics, Siberian Branch of Russian Academy of Sciences, Novosibirsk, Russia.

koulakov@cshl.edu

###### Abstract

Social conflict is a survival mechanism yielding both normal and pathological behaviors. To understand its underlying principles, we collected behavioral and whole-brain neural data from mice advancing through stages of social conflict. We modeled the animals' interactions as a normal-form game using Bayesian inference to account for the partial observability of animals' strengths. We find that our behavioral and neural data are consistent with the first-level Theory of Mind (1-ToM) model where mice form "primary" beliefs about the strengths of all mice involved and "secondary" beliefs that estimate the beliefs of their opponents. Our model identifies the brain regions that carry the information about these beliefs and offers a framework for studies of social behaviors in partially observable settings.

## 1 Introduction

Research into conflict behavior is an established domain within cognitive science and neuroscience with a focus on exploring the origins of pathological aggression and defeat (Archer, 1988; Rosell and Siever, 2015). The broad interest in this topic is driven by the pervasive occurrence of pathologically aggressive behaviors such as school bullying and prison hostility that remain a significant societal concern. Gaining insight into the neural and behavioral foundations of conflict behavior is a crucial step toward mitigating the adverse consequences of aggression and preventing instances of hostility.

Toward this goal, the field of conflict studies has adopted an experimental approach. Researchers have monitored rodent behavior and recorded corresponding brain activity, as rodents naturally exhibit aggressive behaviors allowing experimenters to minimize additional stress for animals during data collection. This approach has yielded valuable insights into the factors that promote aggression (Archer, 1988; Wang and Anderson, 2010; Lorenz, 2005) and led to identifying brain regions affected by conflict (Aleyasin et al., 2018; Diaz and Lin, 2020; Wei et al., 2021). The studies in this field, however, rarely focused on the dynamic nature of aggressiveness in individuals, thus constraining our ability to understand and predict harmful behaviors. Here, we use behavioral data modeling to explore the strategies of aggressive behavior in individual mice over prolonged periods of time.

Our study contributes to the field as follows. We collected large-scale data on behavior and whole-brain neural activity that follows the emergence of aggression and defeat in individual mice. We also introduced a family of models to characterize the learning rules, decision-making processes, and cost functions underlying aggression. These models were applied to the observed behaviors of individual mice to identify the best-fitting model. Using that model, we described the decision-making mechanism consistent with the emergence of aggression and submissiveness. We then conducted an analysis of the neural correlates of both explicit and hidden model variables across the entire brain, thus validating the hidden dynamics of the model and linking specific brain regions to individual model variables. While similar approaches were used in theoretical and computational neuroscience, they have not been previously applied in studies of conflict.

Our findings show that behavioral and neural data describing chronic conflict aligns with the first-level Theory of Mind (1-ToM) model. According to this model, mice form "primary" beliefs about their own and their opponents' strengths along with "secondary" beliefs estimating their opponents' corresponding beliefs. These belief systems are updated with Bayes' rule based on the actions of opponents and the outcomes of aggressive encounters. We propose that, by representing Bayesian beliefs, animals in social conflict situations address the challenge of partial observability. Our model thus holds the potential for generalization to other social interactions characterized by uncertainty.

The proposed model not only provides insights into the development of pathological aggression and defeat but also offers a path toward their mitigation. The next steps will involve applying the model to newly available data and identifying the neural correlates of aggression-related variables within the brain. This will be followed by the exploration of connectivity changes between the identified brain regions, which may unveil the neural circuit governing decision-making in aggression. Ultimately, the shift from a normative to a circuit model of conflict may enable the design of policies geared toward reducing aggression in a variety of social settings.

## 2 Related work

**Behavioral biology of aggression.** Social conflict has been studied in humans, non-human primates, and mice - a model organism whose behavioral states can be manipulated. Mouse studies have investigated how social conflict leads to the formation, maintenance, and plasticity of aggressive and subordinate behavioral states in animals (Wong et al., 2016; Hashikawa et al., 2017). Such behavioral states can be modeled in the chronic social conflict paradigm where mice are allowed limited interactions over extended periods of time (Kudryavtseva, 2000; Miczek et al., 2001). Here, we use the chronic social conflict paradigm to induce various behavioral states in mice and monitor their conflict-related behaviors. As the previous studies of social conflict have shown the evolutionary preservation of its basic mechanisms (Wang and Anderson, 2010; Watanabe et al., 2017), we expect our results to be relevant to human behavior.

**Game theory.** Optimal behaviors of interacting agents are conventionally described in terms of game theory. Game theory considers rational agents developing their strategies to maximize rewards. The rewards received by the agents depend on their actions and the actions of their opponents. The acquisition of optimal strategies in games can be described by probabilities of available actions (Smith, 1982; Cressman et al., 2003). Such strategies of agents co-evolve to reinforce higher-reward actions until the rewards can't grow any further (Nash equilibrium). Game-theoretic approaches have been used in models of human and animal behaviors in multi-agent settings including agonistic interactions (Smith, 1974; Hofbauer et al., 1998; Wilson, 2000; Lorenz, 2005). Here, we use game theory to model agonistic interactions in the condition of chronic social conflict in mice.

**Beliefs and Theories of Mind.** Humans and animals in social settings have limited access to environmental variables, which can be modeled with the partially observable Markov decision process (POMDP) framework. To gain evidence about hidden variables, real-world agents may maintain probabilistic internal models of environment - the "beliefs" - based on which their actions can be considered rational, maximizing a reward function (Fahlman et al., 1983; Alefantis et al., 2021). The agents' rewards and beliefs can be inferred from their behavior using inverse control techniques that maximize the likelihood of the observed behavior based on a hidden dynamics model (Russell, 1998; Choi and Kim, 2011; Dvijotham and Todorov, 2010; Kwon et al., 2020). In biologically relevant multi-agent settings, beliefs are studied in the Theories of Mind (ToM) framework, proposing that humans and animals maintain beliefs about the beliefs of their adversaries (Baker et al., 2011) or aides (Khalvati et al., 2019). As previous studies were successful in inferring beliefs (Schmitt et al., 2017; Alefantis et al., 2021) and regressing them to neural activity in simulations (Wu et al., 2020) or low-resolution fMRI (Koster-Hale and Saxe, 2013), here we introduce a framework for the inference of beliefs in social setting and regress them to high-resolution whole-brain neural activity in mice.

**C-Fos as a whole-brain marker of neural activity.** The search for the brain regions accumulating evidence about the environment requires large-scale neural activity data. Such data can be obtained by monitoring the levels of c-Fos, an immediate early gene whose activation reflects neuronal activity (Sagar et al., 1988; Herrera and Robertson, 1996). C-Fos data lacks temporal resolution, yet it allows observing whole-brain activity at a high spatial resolution without using equipment that may affect animals' choices. Local expression of c-Fos has implicated several brain regions in agonistic interactions (Hashikawa et al., 2017; Aleyasin et al., 2018; Diaz and Lin, 2020; Wei et al., 2021). Here, we use 3D light-sheet microscopy of the c-Fos signal in whole-brain samples (Renier et al., 2016) to identify the brain-wide neural activity in animals with varying exposure to social conflict. We compare our c-Fos data to the beliefs identified based on behavior in individual mice and report the regions that may be involved in the computation of conflict-related variables in the brain.

## 3 Methods: a normative POMDP framework for social behavior modeling

The goal of this work is to build a quantitative theory for the formation of social conflict-related behavioral states in mice. In Section 3.1 we introduce a mouse behavioral paradigm where we recorded the actions leading to different behavioral states and the brain activities corresponding to these states. In Sections 3.2 to 3.4 we define a normative POMDP-based framework for studying real-world social behaviors. In this framework, the game-theory optimal actions of agents rely on their beliefs, defined as distributional estimates of the hidden variables of the environment. In Section 4 we examine hypotheses about the reward schedule, information availability, and evidence accumulation related to social conflict. We compare our results to behavioral data in Section 4.1 and to neural data in Section 4.2. We discuss our findings in Appendix A. A detailed description of the methods is provided in Appendix B. Derivations and supplementary results are provided in Appendix C.

### Running example: the chronic social conflict paradigm

Our goal was to come up with a unified behavioral model explaining various stages of social conflict. As previous experiments have mostly focused on isolated aspects of social conflict (e.g. its pathological form only), the data needed for building a unified model was not readily available, necessitating the conduct of a new experiment. To this end, we implemented the chronic social conflict paradigm (Kudryavtseva, 2000; Kudryavtseva et al., 2014), a well-established experimental paradigm for studying aggression and conflict. Within the paradigm, we focused on conventionally studied stages of social conflict, i.e. the adaptive (3 days), intermediate (10 days), and pathological (20 days) aggression/defeat (Kudryavtseva et al., 2014). For completeness, we additionally considered the reversal of pathological behaviors (after 20 days) - the standard experimental perturbation of behavior. We used the conventional experimental parameters (Kudryavtseva et al., 2014).

We conducted our experiments as follows. Pairs of weight-matched (as a proxy for being strengthened) mice were placed in cages separated by a perforated partition (Figure 1A). Once daily, the partition was removed for 10 minutes to enable agonistic interactions between mice (Figure 1B). After 3 days, mice were classified into "winning", "losing", and "neutral" (non-fighting) (Figure 1C,D). The participation of "neutral" mice in the experiment was discontinued. Afterward, each winning mouse remained in its cage, while each losing mouse was daily relocated to an unfamiliar cage with an unfamiliar winning mouse (Figure 1C). Regardless of no longer being weight-matched, mice have retained their winning or losing behavioral states, thus transitioning to the pathological regime of social conflict-related decision-making (Figure 1D). After 20 days of interactions, mice were exposed to opponents of equal behavioral state (Figure 1C). The newly formed pairs underwent two more days of agonistic interactions throughout which new win/lose relationships were established (Figure 1D). We provide more details in Appendix B.1.

Figure 1: The chronic social conflict paradigm. (A-B) Stages of a single sensory contact event. (C) Stages of a multi-day experiment. (D) Recorded actions of mice in the experiment (white: no encounter scheduled).

### Game-theory optimal actions

We build a normative POMDP model for social behaviors using the chronic social conflict paradigm. In this section, we start with an approximation where each agent has all information about itself and its opponents. In that case, we use game theory to define the optimal actions for each agent.

We formalize our behavioral paradigm as a normal form game where, on each iteration, two agents have to decide simultaneously on what action \(a\) to take. We defined the possible actions \(a\) as "attack" or "defend". Depending on the actions \(a_{1}\) and \(a_{2}\) selected by the two agents respectively, they received rewards \(r\) defined as follows. If both agents chose to "defend", no fight happened, leading to a zero reward \(r_{1}=r_{2}=0\) assigned to each agent. If both agents "attacked", the outcome of the game was defined by their strengths \(s\), an additional parameter assigned to each agent in the model. The outcome probability \(p^{win}\) was defined by the softmax rule over the strengths parameterized with the "outcome confidence" \(_{o}\):

\[p^{win}_{i}=Z^{-1}(_{o}s_{i}).\] (1)

Here and below \(Z\) denotes the normalization coefficient. Once the outcome was determined, the winning agent received a reward of \(r=+1\), and the losing agent expended a cost of \(r=-\). The reward expectation was equal to:

\[_{i}=1 p^{win}_{i}+(-)(1-p^{win}_{i})=(1+)p^{win}_{i}-.\] (2)

The cost of loss was reduced if one of the agents chose to "defend" while the other agent "attacked". In that case, the "attacking" agent always won and received the reward of \(r=+1\) while the losing agent expended the cost of \(r=-\) such that \(<\). The reward expectations were described in the payoff matrix \(_{i}\) whose rows correspond to the actions of the agent ("attack" and "defend") and columns correspond to the actions of its opponent:

\[_{i}=_{i}&1\\ -&0.\] (3)

To determine the optimal strategies in this game, we used game theory. In this approach, the goal of every participant was to maximize its expected reward \([r_{i}]\):

\[[r_{1}]=P_{1}^{T}_{1}P_{2}.\] (4)

Here the vectors \(P_{i}\) define the probabilities to "attack" \(p_{i}\) and to "defend" \(1-p_{i}\) for an agent \(i\):

\[P_{i}p_{i}\\ 1-p_{i}.\] (5)

A similar expression can be written for the expected reward of the second agent \([r_{2}]\). To maximize the rewards \([r_{i}]\), we computed their gradients with respect to the probabilities to "attack" \(p_{i}\) (an agent could only update its own policy, but not that of the opponent). We used these gradients to update the policies leading to joint maximization of the expected rewards (Figure 2A):

\[[r_{1}]}{ p_{1}}=(_{1}+ -1)p_{2}+1;\\ [r_{1}]}{ p_{2}}=(_{2}+-1)p_{1}+1.\] (6)

We provide the derivation for the equation above in Appendix C.1.1. The probabilities of actions can be only defined in the range \(0\{p_{1},p_{2}\} 1\). Their evolution \(_{i}[r_{i}]/ p_{i}\), governed by the equations above (red arrows in Figure 2A), converges to zeros or ones (blue arrows in Figure 2A) forming pure strategies (we show the lack of mixed strategies in Appendix C.1.2). To determine optimal pure strategies, we chose the strategies whose reward gradients (red arrows in Figure 2B) pointed outwards the \([0-1]\) interval for both agents. We represented the optimal policies via the tensor \(A\) of probabilities for each possible action \(a\) depending on the agent's strength \(s_{1}\) and their opponent's strength \(s_{2}\), averaging over all optimal pure strategies (Figure 2C):

\[A_{aij}=Pr(a_{1}=a|s_{1}=i,s_{2}=j).\] (7)

The resulting optimal policies in the model depended on the relative strengths of the agents (Figure 2C). We parameterized the optimal policies with the maximum relative strength of the agents \(=s_{2}-s_{1}\) at which it was still optimal to "attack". We then explored how \(\) depends on the task parameters \(\) and \(_{o}\) and found that most of these parameters' values correspond to the optimal strategy with \(=0\) ("x" in Figure 2D), i.e. to "attacking" any opponent who is weaker or equal. We describe additional details regarding the acquisition of optimal policies in Appendix B.2 and summarize the procedure in Supplementary Algorithm 1.

### Partial observability: beliefs about hidden variables

Game theory in our setting predicts a static policy, unchanging over time. Conversely, weight-matched mice in the experiment who initially attacked each other later split into always-attacking "winners" and ever-defending "losers" (Figure 1D). To account for this dynamic, we expand our model to a scenario where agents do not possess the full information about their strengths but accumulate this information over the task. In this section, we model the agents' information about strengths via beliefs - the probability distributions for an agent to belong to a certain strength category.

We used body weights \(w\) of the animals as a proxy of their strengths \(s\)(Andersson and Iwasa, 1996; Cooper et al., 2020):

\[w_{i} s_{i}.\] (8)

We modeled the animals' initial estimates of their body weights \(\) as normally distributed around true values \(w\). Under this assumption, we reconstructed the probability distributions for animals' strengths (their initial beliefs) \(B^{i} Pr(s=i|)\) using their body weights \(\) in Bayes' rule:

\[B^{i} Pr(s=i|)=(i,)}()Pr(s= i)}{Pr()},\] (9)

where \(P_{(i,)}()\) is a normal distribution probability density function representing the noise in the estimate of the animal's body weight; \(Pr()\) is the distribution of the animals' estimated body weights \(\{_{i}\}\), and \(Pr(s)\) is the distribution of their strengths \(\{s_{i}\}\). To denoise the strength distribution \(Pr(s)\), we approximated the experimentally observed body weight distribution \(Pr(w) Pr(s)\) with a normal distribution.

We consider up to four types of beliefs. The two "primary" beliefs describe the animals' estimates of their own strength and of the strength of the opponent. The two "secondary" beliefs estimate the "primary" beliefs of the opponent. The animals were expected to better estimate their own strength compared to that of their opponents. To this end, we used separate uncertainty parameters for estimating one's own strength (\(=_{1}\)) and that of an opponent (\(=_{2}\)). For the "secondary" beliefs, the uncertainties were combined (\(=^{2}+_{2}^{2}}\)). We provide the details regarding the initialization of beliefs in Appendix B.3 and summarize them in Supplementary Algorithm 2.

### Evidence accumulation: Bayesian update of beliefs

In this section, we expand our model with an update mechanism for the agents' beliefs. We update the beliefs \(B\) using Bayes' rule and the information about the actions \(a\) and outcomes \(o\) of agonistic interactions (Figure 3A).

We define the _outcome tensor_\(O_{ij}^{ab}\) as a tensor describing the probabilities of each possible outcome \(o_{1}=o\) for an agent of a strength \(s_{1}=i\) after choosing an action \(a_{1}=a\) provided that the opponent has a strength \(s_{2}=j\) and chose an action \(a_{2}=b\):

\[O_{ij}^{oab}=Pr(o_{1}=o|a_{1}=a,a_{2}=b,s_{1}=i,s_{2}=j).\] (10)

The _reward tensor_\(R_{ij}^{ab}\) describes the expected reward \([r_{1}]\) for an agent of a strength \(s_{1}=i\) after choosing an action \(a_{1}=a\) provided that the opponent has a strength \(s_{2}=j\) and chose an action

Figure 2: Game-theoretic model of the chronic social conflict paradigm. (A) Policy gradients. (B) Gradient orientations yield a pure strategy as a Nash equilibrium. (C) Optimal policy and its dependence on the relative strength. (D) Dependence of optimal policy on the model parameters.

\(a_{2}=b\). The reward expectation was based on probabilities of possible outcomes:

\[R^{ab}_{ij}=_{o}r(o,a,b)O^{oab}_{ij}.\] (11)

The _outcome-action_ and _reward-action tensors_ predicted the probability of an outcome \(o_{1}\) and expectation of a reward \(r_{1}\) assuming that the opponent's actions \(a_{2}\) are game-theory-optimal:

\[[RA]^{a}_{ijkl}_{b}R^{ab}_{ij}_{kl}(A,P_{(0, ^{2}+_{2}^{2}})})^{b}_{kl};\] (12)

\[[OA]^{oab}_{ijkl} O^{oab}_{ij}_{kl}(A,P_{(0,^{2}+_{2}^{2}})})^{b}_{kl}.\] (13)

Here the opponent's action is estimated based on the "secondary" beliefs and the estimated outcome is based on the "primary" beliefs. The convolution reflects that the opponent's action is based on the distributional belief rather than on a point estimate of the strengths. The standard deviation \(^{2}+_{2}^{2}}\) applies to the estimated opponent's estimates of both its own strength and "our" strength.

To decide on an action \(a_{1}\), an agent maximized its reward \(r_{1}\). We computed this reward by summing the reward-action tensor \([RA]^{a}_{ijkl}\) multiplied by the belief tensors \(B^{i}_{11}\), \(B^{j}_{12},B^{k}_{21}\), \(B^{l}_{22}\) reflecting the probability distributions for strengths:

\[a_{1}=_{a}_{ijkl}[RA]^{a}_{ijkl}B^{i}_{11}B^{j}_{12}B^{k}_{2 1}B^{l}_{22}.\] (14)

Here the belief tensors \(B_{11}\) and \(B_{12}\) describe the "primary" beliefs of an agent about its own strength and the strength of its opponent respectively. Likewise, the belief tensors \(B_{21}\) and \(B_{22}\) describe the "secondary" beliefs, i.e. the agent's estimate of its opponent's "primary" beliefs. The indices \(i,j,k,l\) iterate over all possible strengths, e.g. \(B^{5}_{11}=0.2\) would mean that, according to the agent's belief, the probability of its own strength to be equal to 5 constitutes 20%. To update the agents' beliefs using the observed actions and outcomes \(\{o_{1},a_{2}\}\), we used Bayes' rule individually for every element of each belief tensor \(B^{i}_{}\):

\[Pr(s_{1}=i|\{o_{1},a_{2}\})=,a_{2}\}|s_{1}=i)Pr(s_{1}=i)}{Pr( \{o_{1},a_{2}\})}.\] (15)

The probability of an outcome \(o_{1}\) and an action \(a_{2}\) for the agent of the strength \(s_{1}=i\) was derived from the outcome-action tensor \([OA]^{o_{1}a_{1}a_{2}}_{ijkl}\):

\[Pr(\{o_{1},a_{2}\}|s_{1}=i)=_{jkl}[OA]^{o_{1}a_{1}a_{2}}_{ijkl}.\] (16)

The probability for the agent to be of strength \(s_{1}=i\) was taken from the belief tensor \(B^{i}_{11}\):

\[Pr(s_{1}=i)=B^{i}_{11}.\] (17)

The marginal probability of the observation \(\{o_{1},a_{2}\}\) was defined by the outcome-action tensor \([OA]^{o_{1}a_{1}a_{2}}_{ijkl}\) scaled by the beliefs about strength \(B^{i}_{11}\), \(B^{j}_{12}\), etc. to scale the optimal actions with the probabilities of their underlying strengths:

\[Pr(\{o_{1},a_{2}\})=Pr(o_{1}|a_{2})Pr(a_{2})=_{ijkl}[OA]^{o_{1}a_{1}a_{2} }_{ijkl}B^{i}_{11}B^{j}_{12}B^{k}_{21}B^{l}_{22}.\] (18)

Figure 3: Bayesian update of beliefs in the model. (A) Belief update diagram for two mice. (B,C) Reconstructed belief dynamics for representative loser and winner mice.

Together, the four equations above formed the update rule for agent beliefs based on their observations:

\[Pr(s_{1}=i|\{o_{1},a_{2}\})=[OA]^{o_{1}a_{1}a_{2}}_{ijkl}B^{i}_{11 }B^{j}_{12}B^{k}_{21}B^{l}_{22}}{_{ijkl}[OA]^{o_{1}a_{2}}_{ijkl}B^{i}_{11}B^ {j}_{12}B^{k}_{21}B^{l}_{22}}.\] (19)

The update could proceed at an arbitrary learning rate \(\):

\[B^{i}_{11} Pr(s_{1}=i|\{o_{1},a_{2}\})+(1-)B^ {i}_{11}\] (20)

We describe additional details regarding the update procedure for the beliefs in Appendix B.4 and summarize them in Supplementary Algorithm 3.

## 4 Results: inference of animal choice mechanisms in social conflict

### Model fit and comparison

We used the framework defined above to test hypotheses about mouse social conflict-related choices. To test hypotheses against their alternatives, we optimized pairs of models on the training data (88 mice participating for 22 days). To this end, we specified a negative log-likelihood (NLL) function \(\) comparing the action probabilities predicted in our model to the mouse actions logged in the experiment:

\[=-_{mt}( Pr(a^{t}_{m})+ Pr(o^{t}_{m})).\] (21)

To fit the model parameters, we minimized the NLL regularized with the \(l_{2}\) norm of the model arguments. We chose the regularization coefficient such that it resulted in the best fits in a simulated experiment. For the real mice in the experiment, we used the data spanning all 22 days to propagate the beliefs but the NLL was only computed for the data from days 1-3 and 21-22 to avoid the impact of the repeated actions on days 4-20. We report the implementation details of the model fit in Appendix B.5 and summarize them in Supplementary Algorithm 4.

We then proceeded to compare how well different models explain the behaviors observed in our experiment. Here we follow the standard way to compare models in behavioral research that is using formal comparison criteria, such as the Akaike Information Criterion (AIC) or the Bayesian Information Criterion (BIC). Both criteria are computed as a function of the number of parameters in the model less the log-likelihood of this model to generate the original data. Most of the models that we considered have the same number of parameters, therefore, as we only evaluated the difference of AICs (or BICs) between the models, the term reflecting the number of parameters cancelled out, resulting in the difference in log-likelihoods that we present.

To compare the models, we computed the changes in the NLLs based on the predictions of the models for the testing data (114 mice participating for 3/10/20 days). We performed the t-test on the changes in NLLs for individual mice followed by the false discovery rate (FDR) correction. Our comparisons were iterative: every time a model under consideration outperformed the previous best model, it became the new best model, starting a new round of comparisons. This procedure lasted until a model under consideration could not be outperformed by any other model. We used the q-value of \(q=0.05\) as a cutoff. Below, we report the results for the final round of the comparisons. We report additional details in Appendix B.6; the results of simulated experiments are described in Appendix C.2.

#### 4.1.1 Baseline models

Here we use the conventional approach and compare our model with the standard baselines (Devaine et al., 2014; Khalvati et al., 2019). The comparison results are displayed in Figure 4. We provide detailed numerical results in Supplementary Table 7 in Appendix C.3.

First, we determined the **depth of reasoning** involved in social conflict. We found that the Bayesian model that, along with "primary" beliefs, uses "secondary" beliefs to anticipate opponents' actions (a first-order theory of mind, 1-ToM) is more consistent with the data than a model where decisions are only based on "primary" beliefs about the strengths of the contestants (0-ToM).

Second, we analyzed the **availability of information** during conflict behavior. We established that the model that endows each animal with individual beliefs explains the animals' actions in the experiment better than the model that uses "shared" beliefs available to both animals in the pair.

Third, we assessed the **flexibility of policy** during a single agonistic interaction. We show that the model where animals decide on their actions before a fight ("fixed policy") explains our data better than the model where animals adapt their actions to the opponent's actions during a fight thus converging to a different Nash equilibrium ("flexible policy"; Appendix C.1.3).

Finally, to probe the **class of algorithms** used by animals in social conflict, we compared the Bayesian belief-based model with the Rescorla-Wagner reinforcement learning model where each action ("attack", "defend") was associated with a value updated based on the rewards. Our behavioral data was insufficient to distinguish between the two algorithms; we present additional considerations based on neural data in Section 4.2.

#### 4.1.2 Ablations

To infer the **dynamics of beliefs** that best describe the animals' actions, we compared the Bayesian belief-based model ("dynamic beliefs") with two models based on fixed beliefs ("static beliefs"; equivalent to the zero learning rate) (Baker et al., 2011). We found that the "dynamic beliefs" explained the animal data better than two types of "static beliefs": "prior beliefs" identical to those used to initialize the "dynamic beliefs" model and "posterior beliefs" identical to the output of the "dynamic beliefs" model reflecting the most complete knowledge about the animals.

To test the **role of body weight** in the initial beliefs about animals' strengths, we compared the model where the beliefs were initialized using the animals' body weights with the model where the body weights were shuffled and with the model where the correct body weights were used but their prior distribution was wider than the true distribution. Our comparison shows that using the true animals' body weights and their distribution to initialize beliefs has positively affected the predictions.

#### 4.1.3 Optimal parameters

To obtain further insights into the aggressive behavior of mice, we evaluated the optimal parameters for the first-order Bayesian belief-based model. We observed a local minimum of the NLL at the parameter values \(_{1}=3 1\)g, \(_{2}=10 1\)g, \(_{o}=6 1\), \(_{a}=3 1\), \(=3 1\), \(=10 1\), and \(=0.8 0.2\). The identified parameters \(_{o}\) and \(\) correspond to the policy with \(=0\) where mice attack any opponents of equal or lower strength. The uncertainty \(_{1}\) in initial estimates of own strength has a relatively low value suggesting that mouse body weight is an informative proxy for its strength. The uncertainty \(_{2}\) in initial estimates of the opponent's strength is relatively high suggesting that the opponent's body weight carries no significant information about its estimated strength and that such strength is rather estimated based on their actions. We summarize these findings in a normative theory of social conflict in Appendix C.4.

Figure 4: Model comparison on (A) training data and (B) testing data. Here (*) indicates a significant difference between the models (FDR \(q 0.05\)), (ns) indicates a non-significant difference (FDR \(q>0.05\)), and the whiskers show the mean \(\) the standard error of the mean.

### Model correlates in the brain

To analyze the neural correlates of the model variables, based on the behavioral data, we estimated the beliefs for each mouse (Figure 5A-D). We then computed their correlations, voxel by voxel, with the c-Fos activity in the entire brain (Figure 5E). We evaluated the beliefs at the end of the experiments because the c-Fos imaging only allows collecting one brain activity snapshot per animal. To study brain activity at different stages of social conflict, we used mice with varied participation in the experiment, i.e. "winners" (\(W\)) and "losers" (\(L\)) on days 3/10/20 (subscripted in the group names in Figure 5) and also inverts (e.g. "winners" who become "losers", \(WL\)) on the day 22. We describe the details of this comparison in Appendix B.7 and summarize them in Supplementary Algorithm 5.

In the correlation analysis, we use the "primary" and "secondary" beliefs reconstructed with the 0-ToM and 1-ToM models. We found significant (cumulative FDR \(q 0.1\)) neural correlates for both types of these variables (Figure 6A-F). To analyze the representations of 0-ToM and 1-ToM beliefs, we examined the set of voxels whose activity was correlated with either 0-ToM or 1-ToM beliefs (Figure 6G), i.e. the union of the voxels correlated with the two models. We found that 77% of these voxels were correlated with the 1-ToM beliefs only, while 8% of the voxels were uniquely correlated with the 0-ToM beliefs. The remaining 15% of voxels were correlated with both 0-ToM and 1-ToM beliefs. Thus, brain activity appears to contain signatures of both 1-ToM and 0-ToM beliefs, suggesting that both models may be relevant to the animals' behavior. We describe the results of additional tests, further supporting this conclusion, at the end of this section.

We evaluated the brain regions hosting significant neural correlates of 1-ToM beliefs. We found that the "primary" beliefs about oneself and the opponents were correlated with clusters of neural activity in the median preoptic nucleus (MEPO), the periventricular hypothalamic nucleus (PV), and the parabrachial nucleus (PB). The "secondary" beliefs were correlated with neural activity in the brain regions including the medial septal nucleus (MS), the medial and lateral preoptic areas (MPO, LPO), the lateral septal nucleus (LS), the superior and inferior colliculi (SC, IC), the dentate gyrus (DG), the parabrachial nucleus (PB), the anterodorsal and median preoptic nuclei (ADP, MEPO), the periventricular hypothalamic nucleus and the dorsomedial nucleus of the hypothalamus (PV, DMH), the pallidatum (PAL), the zona incerta (ZI), the hypothammullary and tuberal nuclei (TM, TU), the pontine reticular nucleus (PRN), and the lateral hypothalamic area (LHA). Some of these regions are known for their involvement in conflict behaviors (Aleyasin et al., 2018; Diaz and Lin, 2020).

To control for **alternative explanations** of the observed neural activity, we repeated the analysis for model-unrelated variables. These variables included the body weights of the animals (used to initialize the beliefs), the outcomes of agonistic interactions, and the binary winner/loser variable. As a control, we also considered the shuffled beliefs of each type, such that we shuffled the animal identities within all groups of "winners" or "losers". Among these, we only found substantial correlates of the winner/loser variable whose presence in the brain is unsurprising. The correlates of this variable only partially overlapped with the correlates of the beliefs (Figure 6G). We further examined the neural correlates of variables reconstructed with the Rescorla-Wagner model. We found that such correlates are mostly explained by the winner/loser variable, whereas a larger portion of

Figure 5: Reconstructed beliefs for individual mice: (A) about oneself; (B) about last opponent; (C) about last opponent’s belief about oneself; (D) about last opponent’s belief about themselves. Group key: \(L_{3}\) stands for “losers” observed on day 3 etc. \(WL\) stands for “winners” who become “losers” observed on day 22 etc. (E) Belief regression to the c-Fos activity in whole-brain samples.

the 1-ToM correlates does not have an alternative explanation (Figure 6G). This result supports the relevance of the proposed ToM model for conflict-related decision-making.

## 5 Broader impact

In our model, we applied evidence accumulation approaches to the domain of game theory which studies optimal interactions between agents. This allowed us to build a theory of chronic social conflict that can be used in future works for building quantitative models of social interactions. We then used Inverse Rational Control (IRC) to model the beliefs of animals based on their behavior. Combining the IRC with evidence accumulation models limits its degrees of freedom, increases robustness, and offers an interpretation for its predictions. Finally, we used the whole-brain c-Fos data (a proxy of neuronal activity) in combination with the IRC for an unbiased search for neural correlates of reconstructed beliefs. Overall, we combine game theory, evidence accumulation models, inverse rational control, and whole-brain imaging to propose a framework for building normative models of social behaviors and grounding them in neural circuitry in the brain. All animal procedures in this work were approved by the Stony Brook University Institutional Animal Care and Use Committee in accordance with the National Institutes of Health regulations. A detailed discussion of our results including the **strengths and limitations** of our approach is provided in Appendix A.