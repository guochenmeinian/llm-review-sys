# An Information-Theoretic Perspective on

Variance-Invariance-Covariance Regularization

 Ravid Shwartz-Ziv

New York University

&Randall Balestriero

Meta AI, FAIR

&Kenji Kawaguchi

National University of Singapore

Tim G. J. Rudner

New York University

&Yann LeCun

New York University & Meta AI, FAIR

Correspondence to: ravid.shwartz.ziv@nyu.edu.

###### Abstract

Variance-Invariance-Covariance Regularization (VICReg) is a self-supervised learning (SSL) method that has shown promising results on a variety of tasks. However, the fundamental mechanisms underlying VICReg remain unexplored. In this paper, we present an information-theoretic perspective on the VICReg objective. We begin by deriving information-theoretic quantities for deterministic networks as an alternative to unrealistic stochastic network assumptions. We then relate the optimization of the VICReg objective to mutual information optimization, highlighting underlying assumptions and facilitating a constructive comparison with other SSL algorithms and derive a generalization bound for VICReg, revealing its inherent advantages for downstream tasks. Building on these results, we introduce a family of SSL methods derived from information-theoretic principles that outperform existing SSL techniques.

## 1 Introduction

Self-supervised learning (SSL) is a promising approach to extracting meaningful representations by optimizing a surrogate objective between inputs and self-generated signals. For example, Variance-Invariance-Covariance Regularization (VICReg) , a widely-used SSL algorithm employing a de-correlation mechanism, circumvents learning trivial solutions by applying variance and covariance regularization.

Once the surrogate objective is optimized, the pre-trained model can be used as a feature extractor for a variety of downstream supervised tasks such as image classification, object detection, instance segmentation, or pose estimation . Despite the promising results demonstrated by SSL methods, the theoretical underpinnings explaining their efficacy continue to be the subject of investigation .

Information theory has proved a useful tool for improving our understanding of deep neural networks (DNNs), having a significant impact on both applications in representation learning  and theoretical explorations . However, applications of information-theoretic principles to SSL have made unrealistic assumptions, making many existing information-theoretic approaches to SSL of limited use. One such assumption is to assume that the DNN to be optimized is stochastic--an assumption that is violated for the vast majority DNNs used in practice. For a comprehensive review on this topic, refer to the work by Shwartz-Ziv and LeCun .

In this paper, we examine Variance-Invariance-Covariance Regularization (VICReg), an SSL method developed for deterministic DNNs, from an information-theoretic perspective. We propose an approach that addresses the challenge of mutual information estimation in deterministic networks by transitioning the randomness from the networks to the input data--a more plausible assumption. This shift allows us to apply an information-theoretic analysis to deterministic networks. To establish a connection between the VICReg objective and information maximization, we identify and empirically validate the necessary assumptions. Building on this analysis, we describe differences between different SSL algorithms from an information-theoretic perspective and propose a new family of plug-in methods for SSL. This new family of methods leverages existing information estimators and achieves state-of-the-art predictive performance across several benchmarking tasks. Finally, we derive a generalization bound that links information optimization and the VICReg objective to downstream task performance, underscoring the advantages of VICReg.

Our key contributions are summarized as follows:

1. We introduce a novel approach for studying deterministic deep neural networks from an information-theoretic perspective by shifting the stochasticity from the networks to the inputs using the Data Distribution Hypothesis (Section 3)
2. We establish a connection between the VICReg objective and information-theoretic optimization, using this relationship to elucidate the underlying assumptions of the objective and compare it to other SSL methods (Section 4).
3. We propose a family of information-theoretic SSL methods, grounded in our analysis, that achieve state-of-the-art performance (Section 5).
4. We derive a generalization bound that directly links VICReg to downstream task generalization, further emphasizing its practical advantages over other SSL methods (Section 6).

## 2 Background & Preliminaries

We first introduce the necessary technical background for our analysis.

### Continuous Piecewise Affine (CPA) Mappings.

A rich class of functions emerges from piecewise polynomials: spline operators. In short, given a partition \(\) of a domain \(^{D}\), a spline of order \(k\) is a mapping defined by a polynomial of order \(k\) on each region \(\) with continuity constraints on the entire domain for the derivatives of order \(0,,k-1\). As we will focus on affine splines (\(k=1\)), we only define this case for clarity. A \(K\)-dimensional affine spline \(f\) produces its output via \(f()=_{}(_{}+_{})\, _{\{\}}\), with input \(^{D}\) and \(_{}^{K D}\), \(_{}^{K}\), \(\) the per-region _slope_ and _offset_ parameters respectively, with the key constraint that the entire mapping is continuous over the domain \(f^{0}(^{D})\).

Deep Neural Networks as CPA Mappings.A deep neural network (DNN) is a (non-linear) operator \(f_{}\) with parameters \(\) that map a _input_\(^{D}\) to a _prediction_\(^{K}\). The precise definitions of DNN operators can be found in Goodfellow et al. . To avoid cluttering notation, we will omit \(\) unless needed for clarity. For our analysis, we only assume that the non-linearities in the DNN are CPA mappings--as is the case with (leaky-) ReLU, absolute value, and max-pooling operators. The entire input-output mapping then becomes a CPA spline with an implicit partition \(\), the function of the weights and architecture of the network [51; 6]. For smooth nonlinearities, our results hold using a first-order Taylor approximation argument.

### Self-Supervised Learning.

SSL is a set of techniques that learn representation functions from unlabeled data, which can then be adapted to various downstream tasks. While supervised learning relies on labeled data, SSL formulates a proxy objective using self-generated signals. The challenge in SSL is to learn useful representations without labels. It aims to avoid trivial solutions where the model maps all inputs to a constant output [11; 36]. To address this, SSL utilizes several strategies. _Contrastive methods_ like SimCLR and its InfoNCE criterion learn representations by distinguishing positive and negative examples [16; 54]. In contrast, _non-contrastive_ methods apply regularization techniques to prevent the collapse [14; 17; 28].

Variance-Invariance-Covariance Regularization (VICReg).A widely used SSL method for training joint embedding architectures . Its loss objective is composed of three terms: the invariance loss, the variance loss, and the covariance loss:

* _Invariance loss:_ The invariance loss is given by the mean-squared Euclidean distance between pairs of embedding and ensures consistency between the representation of the original and augmented inputs.
* _Regularization:_ The regularization term consists of two loss terms: the **variance loss**--a hinge loss to maintain the standard deviation (over a batch) of each variable of the embedding--and the **covariance loss**, which penalizes off-diagonal coefficients of the covariance matrix of the embeddings to foster decorrelation among features.

VICReg generates two batches of embeddings, \(=[f(_{1}),,f(_{B})]\) and \(^{}=[f(^{}_{1}),,f(^{}_{B})]\), each of size \((B K)\). Here, \(_{i}\) and \(^{}_{i}\) are two distinct random augmentations of a sample \(I_{i}\). The covariance matrix \(^{K K}\) is obtained from \([,^{}]\). The VICReg loss can thus be expressed as follows:

\[=_{k=1}^{K}\!\!(\! 0,-_{k,k}+}\!+\!_{k^{} k} (_{k,k^{}})^{2}\!)}_{}+-^{}\|_{F}^{2}/N}_{}.\] (1)

### Deep Neural Networks and Information Theory

Recently, information-theoretic methods have played an essential role in advancing deep learning by developing and applying information-theoretic estimators and learning principles to DNN training [3; 9; 34; 56; 64; 65; 69; 72]. However, information-theoretic objectives for deterministic DNNs often face a common issue: the mutual information between the input and the DNN representation is infinite. This leads to ill-posed optimization problems.

Several strategies have been suggested to address this challenge. One involves using stochastic DNNs with variational bounds, where the output of the deterministic network is used as the parameters of the conditional distribution [43; 61]. Another approach, as suggested by Dubois et al. , assumes that the randomness of data augmentation among the two views is the primary source of stochasticity in the network. However, these methods assume that randomness comes from the DNN, contrary to common practice. Other research has presumed a random input but has made no assumptions about the network's representation distribution properties. Instead, it relies on general lower bounds to analyze the objective [71; 75].

## 3 Self-Supervised Learning in DNNs: An Information-Theoretic Perspective

To analyze information within deterministic networks, we first need to establish an information-theoretic perspective on SSL (Section 3.1). Subsequently, we utilize the Data Distribution Hypothesis (Section 3.2) to demonstrate its applicability to deterministic SSL networks.

### Self-Supervised Learning from an Information-Theoretic Viewpoint

Our discussion begins with the _MultiView InfoMax principle_, which aims to maximize the mutual information \(I(Z;X^{})\) between a view \(X^{}\) and the second representation \(Z\). As demonstrated in Federici et al. , we can optimize this information by employing the following lower bound:

\[I(Z,X^{})=H(Z)-H(Z|X^{}) H(Z)+_{x^{}}[ q( z|x^{})].\] (2)

Here, \(H(Z)\) represents the entropy of \(Z\). In supervised learning, the labels \(Y\) remain fixed, making the entropy term \(H(Y)\) a constant. Consequently, the optimization is solely focused on the log-loss, \(_{x^{}}[ q(z|x^{})]\), which could be either cross-entropy or square loss.

However, for joint embedding networks, a degenerate solution can emerge, where all outputs "collapse" into an undesired value . Upon examining Equation2, we observe that the entropies are not fixed and can be optimized. As a result, minimizing the log loss alone can lead the representations to collapse into a trivial solution and must be regularized.

### Understanding the Data Distribution Hypothesis

Previously, we mentioned that a naive analysis might suggest that the information in deterministic DNNs is infinite. To address this point, we investigate whether assuming a dataset is a mixture of Gaussians with non-overlapping support can provide a manageable distribution over the neural network outputs. This assumption is less restrictive compared to assuming that the neural network itself is stochastic, as it concerns the generative process of the data, not the model and training process. For a detailed discussion about the limitations of assuming stochastic networks and a comparison between stochastic networks vs stochastic input, see Appendix N. In Section 4.2, we verify that this assumption holds for real-world datasets.

The so-called manifold hypothesis allows us to treat any point as a Gaussian random variable with a low-rank covariance matrix aligned with the data's manifold tangent space , which enables us to examine the conditioning of a latent representation with respect to the mean of the observation, i.e., \(X|^{*}(;^{*},_{^{*}})\). Here, the eigenvectors of \(_{^{*}}\) align with the tangent space of the data manifold at \(^{*}\), which varies with the position of \(^{*}\) in space. In this setting, a dataset is considered a collection of distinct points \(^{*}_{n},n=1,...,N\), and the full data distribution is expressed as a sum of Gaussian densities with low-rank covariance, defined as:

\[X_{n=1}^{N}(^{*}_{n},_{^{*}_{n}})^{ {1}{(T=n)}} T(N).\] (3)

Here, \(T\) is a uniform Categorical random variable. For simplicity, we assume that the effective support of \((^{*}_{i},_{^{*}_{i}})\) do not overlap (for empirical validation of this assumption see Section 4.2). The effective support is defined as \(\{x^{D}:p(x)>\}\). We can then approximate the density function as follows:

\[p()(;^{*}_{n()},_{ ^{*}_{n()}})/N,\] (4)

where \((;.,.)\) is the Gaussian density at \(\) and \(n()=_{n}(-^{*}_{n})^{T}_{^{*}_{n}}(-^{*}_{n})\).

### Data Distribution Under the Deep Neural Network Transformation

Let us consider an affine spline operator \(f\), as illustrated in Section 2.1, which maps a space of dimension \(D\) to a space of dimension \(K\), where \(K D\). The image or the span of this mapping is expressed as follows:

\[(f)\{f():^{D}\}= _{}(;_{},_{})\] (5)

In this equation, \((;_{},_{})=\{_{}+ {b}_{}:\}\) denotes the affine transformation of region \(\) by the per-region parameters \(_{},_{}\). Of denotes the partition of the input space where \(\) resides. To practically compute the per-region affine mapping, we set \(_{}\) to the Jacobian matrix of the network at the corresponding input \(x\), and \(b\) to be defined as \(f(x)-_{}x\). Therefore, the DNN mapping composed of affine transformations on each input space partition region \(\) based on the coordinate change induced by \(_{}\) and the shift induced by \(_{}\).

When the input space is associated with a density distribution, this density is transformed by the mapping \(f\). Calculating the density of \(f(X)\) is generally intractable. However, under the disjoint support assumption from Section 3.2, we can arbitrarily increase the density's representation power by raising the number of prototypes \(N\). As a result, each Gaussian's support is contained within the region \(\) where its means lie, leading to the following theorem:

_Theorem 1_.: Given the setting of Equation (4), the unconditional DNN output density, \(Z\), can be approximated as a mixture of the affinely transformed distributions \(|^{*}_{n()}\):

\[Z_{n=1}^{N}\!_{(^{*}_{n})}^ {*}_{n}+_{(^{*}_{n})},^{T}_{(^{*}_{n})} _{^{*}_{n}}_{(^{*}_{n})}\!^{1(T=n)}\!\!,\]

where \((^{*}_{n})=^{*}_{n}\) is the partition region in which the prototype \(^{*}_{n}\) lives in.

Proof.: See Appendix B. 

In other words, Theorem 1 implies that when the input noise is small, we can simplify the conditional output density to a single Gaussian: \((Z^{}|X^{}=x_{n})((x_{n}),(x_{n}) ),\) where \((x_{n})=_{(_{n})}_{n}+_{(_{n})}\) and \((x_{n})=^{T}_{(_{n})}_{_{n}}_{( _{n})}\).

## 4 Information Optimization and the VICReg Optimization Objective

Building on our earlier discussion, we used the Data Distribution Hypothesis to model the conditional output in deterministic networks as a Gaussian mixture. This allowed us to frame the SSL training objective as maximizing the mutual information, \(I(Z;X^{})\) and \(I(Z^{};X)\).

However, in general, this mutual information is intractable. Therefore, we will use our derivation for the network's representation to obtain a tractable variational approximation using the expected loss, which we can optimize.

The computation of expected loss requires us to marginalize the stochasticity in the output. We can employ maximum likelihood estimation with a Gaussian observation model. For computing the expected loss over \(x^{}\) samples, we must marginalize the stochasticity in \(Z^{}\). This procedure implies that the conditional decoder adheres to a Gaussian distribution: \((Z|X^{}=x_{n})((x_{n}),I+(x_{n}))\).

However, calculating the expected log loss over samples of \(Z\) is challenging. We thus focus on a lower bound - the expected log loss over \(Z^{}\) samples. Utilizing Jensen's inequality, we derive the following lower bound:

\[_{x^{}}[ q(z|x^{})]_{z^{ }|x^{}}[ q(z|z^{})]=(d 2- (z-(x^{}))^{2}-(x^{})).\] (6)

Taking the expectation over \(Z\), we get

\[_{z|x}[_{z^{}|x^{}}[ q(z|z^{ })]]=(d 2-((x)-(x^{}) )^{2}-(|(x)||(x^{})|)).\] (7)

Combining all of the above, we obtain

\[I(Z;X^{}) H(Z)+ 2-_{x,x^{ }}[((x)-(x^{}))^{2}+(|(x)||(x^{} )|)].\] (8)

The full derivations are presented in Appendix A. To optimize this objective in practice, we approximate \(p(x,x^{})\) using the empirical data distribution

\[L(x_{1} x_{N},x^{}_{1} x^{}_{N}) _{i=1}^{N})||(x^{ }_{i})|)}_{}-((x _{i})-(x^{}_{i}))^{2}}_{}.\] (9)

Figure 1: **Left: The network output for SSL training is more Gaussian for small input noise**. The \(p\)-value of the normality test for different SSL models trained on ImageNet for different input noise levels. The dashed line represents the point at which the null hypothesis (Gaussian distribution) can be rejected with \(99\%\) confidence. **Right: The Gaussians around each point are not overlapping.** The plots show the \(l2\) distances between raw images for different datasets. As can be seen, the distances are largest for more complex real-world datasets.

### Variance-Invariance-Covariance Regularization: An Information-Theoretic Perspective

Next, we connect the VIRReg to our information-theoretic-based objective. The "invariance term" in Equation (9), which pushes augmentations from the same image closer together, is the same term used in the VIReg objective. However, the computation of the regularization term poses a significant challenge. Entropy estimation is a well-established problem within information theory, with Gaussian mixture densities often used for representation. Yet, the differential entropy of Gaussian mixtures lacks a closed-form solution .

A straightforward method for approximating entropy involves capturing the distribution's first two moments, which provides an upper bound on the entropy. However, minimizing an upper bound doesn't necessarily optimize the original objective. Despite reported success from minimizing an upper bound [46; 53], this approach may induce instability during the training process.

Let \(_{Z}\) denote the covariance matrix of \(Z\). We utilize the first two moments to approximate the entropy we aim to maximize. Because the invariance term appears in the same form as the original VIRReg objective, we will look only at the regularizer. Consequently, we get the approximation

\[(x_{1} x_{N},x^{}_{1} x^{}_{N})_{i=1}^ {N}(x_{1} x_{N})|}{|(x_{i})||(x^{ }_{i})|}.\] (10)

_Theorem 2_.: Assuming that the eigenvalues of \((x_{i})\) and \((x^{}_{i})\), along with the differences between the Gaussian means \((x_{i})\) and \((x^{}_{i})\), are bounded, the solution to the maximization problem

\[_{_{Z}}\{_{i=1}^{N}(x_{1} x_{N})| }{|(x_{i})||(x^{}_{i})|}\}\] (11)

involves setting \(_{Z}\) to a diagonal matrix.

Proof.: See Appendix J. 

According to Theorem 2, we can maximize Equation (10) by diagonalizing the covariance matrix and increasing its diagonal elements. This goal can be achieved by minimizing the off-diagonal elements of \(_{Z}\)-the covariance criterion of VIReg-and by maximizing the sum of the log of its diagonal elements. While this approach is straightforward and efficient, it does have a drawback: the diagonal values could tend towards zero, potentially causing instability during logarithm computations. A solution to this issue is to use an upper bound and directly compute the sum of the diagonal elements, resulting in the variance term of VIReg. This establishes the link between our information-theoretic objective and the three key components of VIReg.

### Empirical Validation of Assumptions About Data Distributions

Validating our theory, we tested if the conditional output density \(P(Z|X)\) becomes a Gaussian as input noise lessens. We used a ResNet-50 model trained with SimCLR or VIReg objectives on CIFAR-10, CIFAR-100, and ImageNet datasets. We sampled \(512\) Gaussian samples for each image from the test dataset, examining whether each sample remained Gaussian in the DNN's penultimate layer. We applied the D'Agostino and Pearson's test to ascertain the validity of this assumption .

Figure 1 (left) displays the \(p\)-value as a function of the normalized std. For low noise levels, we reject that the network's conditional output density is non-Gaussian with an \(85\%\) probability when using VIReg. However, the network output deviates from Gaussian as the input noise increases.

Next, we verified our assumption of non-overlapping effective support in the model's data distribution. We calculate the distribution of pairwise \(l_{2}\) distances between images across seven datasets: MNIST , CIFAR10, CIFAR100 , Flowers102 , Food101 , and FGVAircraft . Figure 1 (right) reveals that the pairwise distances are far from zero, even for raw pixels. This implies that we can use a small Gaussian around each point without overlap, validating our assumption as realistic.

Self-Supervised Learning Models through Information Maximization

The practical application of Equation (8) involves several key "design choices". We begin by comparing how existing SSL models have implemented it, investigating the estimators used, and discussing the implications of their assumptions. Subsequently, we introduce new methods for SSL that incorporate sophisticated estimators from the field of information theory, which outperform current approaches.

### VICReg vs. SimCLR

In order to evaluate their underlying assumptions and strategies for information maximization, we compare VICReg to contrastive SSL methods such as SimCLR along with non-contrastive methods like BYOL and SimSiam.

Contrastive Learning with SimCLR.In their work, Lee et al.  drew a connection between the SimCLR objective and the variational bound on information regarding representations by employing the von Mises-Fisher distribution. By applying our analysis for information in deterministic networks with their work, we compare the main differences between SimCLR and VICReg:

(i) **Conditional distribution:** SimCLR assumes a von Mises-Fisher distribution for the encoder, while VICReg assumes a Gaussian distribution. (ii) **Entropy estimation:** SimCLR approximated it based on the finite sum of the input samples. In contrast, VICReg estimates the entropy of \(Z\) solely based on the second moment. Developing SSL methods that integrate these two distinctions form an intriguing direction for future research.

Empirical comparison.We trained ResNet-18 on CIFAR-10 for VICReg, SimCLR, and BYOL and compared their entropies directly using the _pairwise distances_ entropy estimator. (For more details, see Appendix K.) This estimator was not directly optimized by any method and was an independent validation. The results (Figure 2), showed that entropy increased for all methods during training, with SimCLR having the lowest and VICReg the highest entropy.

### Family of alternative Entropy Estimators

Next, we suggest integrating the invariance term of current SSL methods with plug-in methods that optimize entropy.

Entropy estimators.The VICReg objective seeks to approximate the log determinant of the empirical covariance matrix through its diagonal terms. As discussed in Section 4.1, this approach has its drawbacks. An alternative is to employ different entropy estimators. The LogDet Entropy Estimator  is one such option, offering a tighter upper bound. This estimator employs the differential entropy of \(\) order with scaled noise and has been previously shown to be a tight estimator for high-dimensional features, proving robust to random noise. However, since this estimator provides an upper bound on entropy, maximizing this bound doesn't guarantee optimization of the original objective. To counteract this, we also introduce a lower bound estimator based on the _pairwise distances_ of individual mixture components . In this family, a function determining pairwise distances between component densities is designated for each member. These estimators are computationally efficient and typically straightforward to optimize. For additional entropy estimators, see Appendix F. Beyond VICReg, these methods can serve as plug-in estimators for numerous SSL algorithms. Apart from VICReg, we also conducted experiments integrating these estimators with the BYOL algorithm.

Figure 2: **VICReg has higher Entropy during training. The entropy along the training for different SSL methods. Experiments were conducted with ResNet-18 on CIFAR-10. Error bars represent one standard error over 5 trials.**

Setup.Experiments were conducted on three image datasets: CIFAR-10, CIFAR-100 , and Tiny-ImageNet . For CIFAR-10, ResNet-18  was used. In contrast, both ConvNeXt  and Vision Transformer  were used for CIFAR-100 and Tiny-ImageNet. For comparison, we examined the following SSL methods: VICReg, SimCLR, BYOL, SwAV , Barlow Twins , and MoCo . The quality of representation was assessed through linear evaluation. A detailed description of different methods can be found in Appendix H.

Results.As evidenced by Table 1, the proposed entropy estimators surpass the original SSL methods. Using a more precise entropy estimator enhances the performance of both VICReg and BYOL, compared to their initial implementations. Notably, the pairwise distance estimator, being a lower bound, achieves superior results, resonating with the theoretical preference for maximizing a true entropy's lower bound. Our findings suggest that the astute choice of entropy estimators, guided by our framework, paves the way for enhanced performance.

## 6 A Generalization Bound for Downstream Tasks

In earlier sections, we linked information theory principles with the VICReg objective. Now, we aim to extend this link to downstream generalization via a generalization bound. This connection further aligns VICReg's generalization with information maximization and implicit regularization.

Notation.Consider input points \(x\), outputs \(y^{r}\), labeled training data \(S=((x_{i},y_{i}))_{i=1}^{n}\) of size \(n\) and unlabeled training data \(=((x_{i}^{+},x_{i}^{++}))_{i=1}^{m}\) of size \(m\), where \(x_{i}^{+}\) and \(x_{i}^{++}\) share the same (unknown) label. With the unlabeled training data, we define the invariance loss

\[I_{S}(f_{})=_{i=1}^{m}\|f_{}(x_{i}^{+})-f_{}( x_{i}^{++})\|,\]

where \(f_{}\) is the trained representation on the unlabeled data \(\). We define a labeled loss \(_{x,y}(w)=\|Wf_{}(x)-y\|\) where \(w=[W]^{dr}\) is the vectorization of the matrix \(W^{r d}\). Let \(w_{S}=[W_{S}]\) be the minimum norm solution as \(W_{S}=_{W^{}}\|W^{}\|_{F}\) such that

\[W^{}*{arg\,min}_{W}_{i=1}^{n}\|Wf_{ }(x_{i})-y_{i}\|^{2}.\]

We also define the representation matrices

\[Z_{S}=[f(x_{1}),,f(x_{n})]^{d n} Z _{}=[f(x_{1}^{+}),,f(x_{m}^{+})]^{d m},\]

   &  &  &  \\  & & **ConvNetX** & **VIT** & **ConvNetX** & **VIT** \\  SimCLR & \(89.72 0.05\) & \(50.86 0.13\) & \(51.16 0.13\) & \(67.21 0.24\) & \(67.31 0.18\) \\  Barlow Twins & \(88.81 0.10\) & \(51.34 0.10\) & \(51.40 0.16\) & \(68.54 0.15\) & \(68.02 0.12\) \\  SwAV & \(89.12 0.13\) & \(50.76 0.14\) & \(51.54 0.20\) & \(68.93 0.14\) & \(67.89 0.21\) \\  MoCo & \(89.46 0.08\) & \(52.36 0.21\) & \(53.06 0.21\) & \(70.32 0.15\) & \(69.89 0.14\) \\  VICReg & \(89.32 0.09\) & \(51.02 0.26\) & \(52.12 0.25\) & \(70.09 0.20\) & \(70.12 0.17\) \\  BYOL & \(89.21 0.11\) & \(52.24 0.17\) & \(53.44 0.20\) & \(70.01 0.27\) & \(69.59 0.22\) \\   VICReg + PairDist (**ours**) & \(\) & \(52.61 0.15\) & \(53.70 0.13\) & \(71.10 0.16\) & \(70.50 0.19\) \\  VICReg + LogDet (**ours**) & \(90.27 0.08\) & \(52.91 0.17\) & \(\) & \(71.23 0.18\) & \(70.61 0.17\) \\  BYOL + PairDist (**ours**) & \(90.19 0.14\) & \(\) & \(54.33 0.21\) & \(\) & \(\) \\  BYOL + LogDet (**ours**) & \(90.11 0.16\) & \(53.19 0.25\) & \(54.67 0.27\) & \(71.20 0.21\) & \(70.79 0.26\) \\  

Table 1: **The proposed entropy estimators outperform previous methods.** CIFAR-10, CIFAR-100, and Tiny-ImageNet top-1 accuracy under linear evaluation using ResNet-18, ConvNetX and VIT as backbones. Error bars correspond to one standard error over three trials.

and the projection matrices

\[_{Z_{S}}=I-{Z_{S}}^{}(Z_{S}{Z_{S}}^{})^{}Z_{S}_{Z_{S}}=I-{Z_{S}}^{}(Z_{S}{Z_{S}}^{})^{}Z_{S}.\]

We define the label matrix \(Y_{S}=[y_{1},,y_{n}]^{}^{n r}\) and the unknown label matrix \(Y_{}=[y_{1}^{+},,y_{m}^{+}]^{}^{m r}\), where \(y_{i}^{+}\) is the unknown label of \(x_{i}^{+}\). Let \(\) be a hypothesis space of \(f_{}\). For a given hypothesis space \(\), we define the normalized Rademacher complexity

\[}_{m}()=}_{S,} [_{f}_{i=1}^{m}_{i}\|f(x_{i}^{+})-f(x_{i}^{++}) \|],\]

where \(_{1},,_{m}\) are independent uniform random variables in \(\{-1,1\}\). It is normalized such that \(}_{m}()=O(1)\) as \(m\).

### A Generalization Bound for Variance-Invariance-Covariance Regularization

Now we will show that the VICReg objective improves generalization on supervised downstream tasks. More specifically, minimizing the unlabeled invariance loss while controlling the covariance \({Z_{S}}{Z_{S}}^{}\) and the complexity of representations \(}_{m}()\) minimizes the expected _labeled loss_:

_Theorem 3_.: (Informal version). For any \(>0\), with probability at least \(1-\),

\[_{x,y}[_{x,y}(w_{S})] I_{}(f_{})+}\|_{Z_{}}Y_{}\|_{F}+}\| _{Z_{S}}Y_{}\|_{F}+}_{m}( )}{}+_{m,n},\] (12)

where \(_{m,n}=O(G+) 0\) as \(m,n\). In \(_{m,n}\), the value of \(G\) for the term decaying at the rate \(1/\) depends on the hypothesis space of \(f_{}\) and \(w\) whereas the term decaying at the rate \(1/\) is independent of any hypothesis space.

Proof.: The complete version of Theorem 3 and its proof are presented in Appendix I. 

The term \(\|_{Z_{S}}Y_{}\|_{F}\) in Theorem 3 contains the unobservable label matrix \(Y_{}\). However, we can minimize this term by using \(\|_{Z_{}}Y_{}\|_{F}\|_{Z_{} }\|_{F}\|Y_{}\|_{F}\) and by minimizing \(\|_{Z_{}}\|_{F}\). The factor \(\|_{Z_{}}\|_{F}\) is minimized when the rank of the covariance \(Z_{}{Z_{S}}^{}\) is maximized. This can be enforced by maximizing the diagonal entries while minimizing the off-diagonal entries, as is done in VICReg.

The term \(\|_{Z_{S}}Y_{}\|_{F}\) contains only observable variables, and we can directly measure the value of this term using training data. In addition, the term \(\|_{Z_{}}Y_{}\|_{F}\) is also minimized when the rank of the covariance \(Z_{S}{Z_{S}}^{}\) is maximized. Since the covariances \(Z_{S}{Z_{S}}^{}\) and \(Z_{}{Z_{}}^{}\) concentrate to each other via concentration inequalities with the error in the order of \(O(+}_{m}())\), we can also minimize the upper bound on \(\|_{Z_{}}Y_{}\|_{F}\) by maximizing the diagonal entries of \(Z_{}{Z_{}}^{}\) while minimizing its off-diagonal entries, as is done in VICReg.

Thus, VICReg can be understood as a method to minimize the generalization bound in Theorem 3 by minimizing the invariance loss while controlling the covariance to minimize the _label-agnostic_ upper bounds on \(\|_{Z_{}}Y_{}\|_{F}\) and \(\|_{Z_{}}Y_{}\|_{F}\). If we know _partial_ information about the label \(Y_{}\) of the unlabeled data, we can use it to minimize \(\|_{Z_{}}Y_{}\|_{F}\) and \(\|_{Z_{}}Y_{}\|_{F}\) directly.

### Comparison of Generalization Bounds

The SimCLR generalization bound  requires the number of labeled classes to go infinity to close the generalization gap, whereas the VICReg bound in Theorem 3 does _not_ require the number of label classes to approach infinity for the generalization gap to go to zero. This reflects that, unlike SimCLR, VICReg does not use negative pairs and thus does not use a loss function based on the implicit expectation that the labels of a negative pair are different. Another difference is that our VICReg bound improves as \(n\) increases, while the previous bound of SimCLR  does not depend on \(n\). This is because Saunshi et al.  assumes partial access to the true distribution per class for setting, which removes the importance of labeled data size \(n\) and is not assumed in our study.

Consequently, the generalization bound in Theorem 3 provides a new insight for VICReg regarding the ratio of the effects of \(m\) v.s. \(n\) through \(G+\). Finally, Theorem 3 also illuminates the advantages of VICReg over standard supervised training. That is, with standard training, the generalization bound via the Rademacher complexity requires the complexities of hypothesis spaces, \(}_{n}()/\) and \(}_{n}()/\), with respect to the size of labeled data \(n\), instead of the size of unlabeled data \(m\). Thus, Theorem 3 shows that using SSL, we can replace the complexities of hypothesis spaces in terms of \(n\) with those in terms of \(m\). Since the number of unlabeled data points is typically much larger than the number of labeled data points, this illuminates the benefit of SSL.

### Understanding Theorem 2 via Mutual Information Maximization

Theorem 3, together with the result of the previous section, shows that, for generalization in the downstream task, it is helpful to maximize the mutual information \(I(Z;X^{})\) in SSL via minimizing the invariance loss \(I_{}(f_{})\) while controlling the covariance \(Z_{}Z_{}{}^{}\). The term \(2}_{m}()/\) captures the importance of controlling the complexity of the representations \(f_{}\). To understand this term further, let us consider a discretization of the parameter space of \(\) to have finite \(||<\). Then, by Massart's Finite Class Lemma, we have that \(}_{m}() C|}\) for some constant \(C>0\). Moreover, Shwartz-Ziv  shows that we can approximate \(||\) by \(2^{I(Z;X)}\). Thus, in Theorem 3, the term \(I_{}(f_{})+}\|_{Z_{}}Y_{ }\|_{F}+}\|_{Z_{}}Y_{} \|_{F}\) corresponds to \(I(Z;X^{})\) which we want to maximize while compressing the term of \(2}_{m}()/\) which corresponds to \(I(Z;X)\)[63; 23; 66].

Although we can explicitly add regularization on the information to control \(2}_{m}()/\), it is possible that \(I(Z;X|X^{})\) and \(2}_{m}()/\) are implicitly regularized via implicit bias through design choises [29; 68; 30]. Thus, Theorem 3 connects the information-theoretic understanding of VICReg with the probabilistic guarantee on downstream generalization.

## 7 Limitations

In our paper, we proposed novel methods for SSL premised on information maximization. Although our methods demonstrated superior performance on some datasets, computational constraints precluded us from testing them on larger datasets. Furthermore, our study hinges on certain assumptions that, despite rigorous validation efforts, may not hold universally. While we strive for meticulous testing and validation, it's crucial to note that some assumptions might not be applicable in all scenarios or conditions. These limitations should be taken into account when interpreting our study's results.

## 8 Conclusions

We analyzed the Variance-Invariance-Covariance Regularization for self-supervised learning through an information-theoretic lens. By transferring the stochasticity required for an information-theoretic analysis to the input distribution, we showed how the VICReg objective can be derived from information-theoretic principles, used this perspective to highlight assumptions implicit in the VICReg objective, derived a VICReg generalization bound for downstream tasks, and related it to information maximization.

Building on these findings, we introduced a new VICReg-inspired SSL objective. Our probabilistic guarantee suggests that VICReg can be further improved for the settings of partial label information by aligning the covariance matrix with the partially observable label matrix, which opens up several avenues for future work, including the design of improved estimators for information-theoretic quantities and investigations into the suitability of different SSL methods for specific data characteristics.