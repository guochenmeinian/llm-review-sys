# Exactly Minimax-Optimal Locally Differentially Private Sampling

Hyun-Young Park

School of Electrical Engineering

KAIST

phy811@kaist.ac.kr &Shahab Asoodeh

Department of Computing and Software

McMaster University

asoodeh@mcmaster.ca &Si-Hyeon Lee

School of Electrical Engineering

KAIST

sihyeon@kaist.ac.kr

###### Abstract

The sampling problem under local differential privacy has recently been studied with potential applications to generative models, but a fundamental analysis of its privacy-utility trade-off (PUT) remains incomplete. In this work, we define the fundamental PUT of private sampling in the minimax sense, using the \(f\)-divergence between original and sampling distributions as the utility measure. We characterize the exact PUT for both finite and continuous data spaces under some mild conditions on the data distributions, and propose sampling mechanisms that are universally optimal for all \(f\)-divergences. Our numerical experiments demonstrate the superiority of our mechanisms over baselines, in terms of theoretical utilities for finite data space and of empirical utilities for continuous data space.

## 1 Introduction

Privacy leakage is a pressing concern in the realm of machine learning (ML), spurring extensive research into privacy protection techniques . Among these, local differential privacy (LDP)  stands out as a standard model and has been deployed in industry, e.g., by Google , Apple , Microsoft . In the LDP framework, individual clients randomize their data on their own devices and send it to a potentially untrusted aggregator for analysis, thus preventing the user data from being inferred. However, this perturbation inherently diminishes data utility. Consequently, the central challenge in privacy mechanism design lies in optimizing utility while preserving the desired level of privacy protection. This goal involves characterizing the optimal balance between privacy parameter and utility, referred to as the privacy-utility trade-off (PUT). The analysis of the PUT and the proposal of privacy mechanisms have been actively conducted for various settings of statistical inference and machine learning .

Most research in this field focuses on scenarios where each client has only a single data point. However, there are increasingly more applications where each client has a large local dataset with multiple data records. One can formulate the privacy requirement in these cases by assuming that clients have datasets of the same size, generated independently from an underlying distribution . This probabilistic assumption, however, restricts practical flexibility. The work  explored a scenario where clients have large datasets that may vary in size and seek to privately release another dataset that closely resembles their original dataset. In this scenario, local datasets can be represented by an empirical distribution, allowing each client to be seen as holding a probability distribution andgenerating a private sample from it. This setup, which is called _private sampling_, is the main focus of this paper.

Private sampling has recently found applications in the private fine-tuning of large language models . Additionally, private sampling is connected to the challenge of learning private generative models, a topic often explored in the central DP model . While there exist studies on private generative models within the local model , all these works assume a single data point per client. Very recently, the work  considered a setup where each client holds a probability distribution, but in a different context of query estimation.

The private sampling mechanism in  can be described as follows. Initially, given a probability distribution \(P\) representing a local dataset, the mechanism assumes a _fixed_ reference distribution. It then constructs what is termed the "relative mollifier", a closed ball centered around the reference distribution with a radius equivalent to half of the privacy budget, within the space of probability distributions. Subsequently, the mechanism computes the projection of \(P\) onto the relative mollifier, utilizing the Kullback-Leibler (KL) divergence. This projected distribution serves as the sampling distribution for generating a sample (see Section 2.3 for more details). However, this mechanism has a notable shortcoming: the sampling distribution is only locally optimal within the relative mollifier. This, in turn, implies that the optimality of the sampling distribution depends on the choice of the reference distribution. A more fundamentally intriguing goal would be to formulate and characterize the PUT without such an ambiguity in the choice of reference distribution.

In this paper, we establish the optimality of locally private sampling in the minimax sense, and identify optimal private samplers. Our primary contributions are summarized as follows:

* The fundamental PUT of private sampling is rigorously defined in terms of minimax utility, which is commonly used in the literature of private estimation . We impose some minimal assumptions on client's distributions as in  (which studies sampling under _central_ DP, a weaker privacy model than the local model ). For utility measure, we use the _\(f\)-divergence_ between the original and the sampling distributions, that includes KL divergence, total variation distance, squared Hellinger distance, and \(^{2}\)-divergence as special cases.
* We characterize the exact PUT for both finite and continuous data spaces, and present optimal sampling mechanisms achieving the PUT. Surprisingly, our mechanisms are _universally optimal_ under any choice of \(f\)-divergence for utility measure.
* We numerically demonstrate that our proposed mechanism outperforms the baseline method presented in . Specifically, for finite data spaces, we derive a closed-form expression for the utility of both our mechanism and the baseline, allowing for an exact comparison of their utilities. In the case of continuous data spaces, a closed-form expression for the baseline is not available, so we use empirical utility for the comparison. Figure 1 illustrates our proposed mechanism outputs a distribution closer to the original, than the baseline.

All codes for experiments and figures are attached as a supplementary material, and can be found at the online repository1. The instructions to reproduce the results in the paper are in Appendix H.

Figure 1: Original Gaussian ring distribution and the sampling distributions of the baseline  and our proposed mechanism for privacy budget \(=0.5\). The implementation details are in Appendix F.

## 2 Problem Formulation

### Notations and preliminaries

Notations.For a sample space \(\), let \(()\) be the set of all probability distributions on \(\). For each \(n\), let \(C(^{n})\) be the set of all continuous probability distributions on \(^{n}\). For each positive integer \(k\), let \([k]:=\{1,2,,k\}\). For a subset \(A\), \(_{A}:\{0,1\}\) denotes the indicator function, defined as \(_{A}(x)=1\) for \(x A\) and \(_{A}(x)=0\) for \(x A\). Also, for \(s_{1} s_{2}\) and \(x\), let \((x;s_{1},s_{2}):=\{s_{1},\{s_{2},x\}\}\). We refer to Appendix A for the rigorous measure-theoretic assumptions underlying the paper.

\(f\)-divergence.For a convex function \(f:(0,)\) satisfying \(f(1)=0\) and two probability distributions \(P,Q()\) on the same sample space \(\), let \(D_{f}(P\|Q)\) denote the \(f\)-divergence . The general definition of \(f\)-divergence is given in Appendix B. For \(=^{n}\) and \(P,Q(^{n})\) with \(P Q\) (that is, \(P(A)=0\) whenever \(Q(A)=0\)), it is defined as

\[D_{f}(P\|Q)=_{x:q(x)>0}q(x)f()dx,\] (1)

where \(p,q\) are pdfs of \(P,Q\), respectively, and we define \(f(0)=_{x 0^{+}}f(x)(-,]\). For finite \(\), we can replace the integral with the sum and replace \(p,q\) with \(P,Q\). Several well-known distance measures between distributions are examples of \(f\)-divergence with different convex functions. For instance, KL divergence (relative entropy), total variation distance, squared Hellinger distance, and \(^{2}\)-divergence are \(f\)-divergences with \(f(x)=x x\), \(f(x)=|x-1|/2\), \(f(x)=(1-)^{2}\), and \(f(x)=x^{2}-1\), respectively. Two important properties of general \(f\)-divergence are keys for this work. First, \(D_{f}(P\|Q) 0\), and equality holds if \(P=Q\). Furthermore, we have

\[D_{f}(P\|Q) M_{f}:=_{x 0+}f(x)+xf(1/x),\] (2)

where equality holds if \(P\) and \(Q\) are mutually singular (that is, they have disjoint supports). For a more comprehensive list of such \(f\)-divergences and their properties, we refer the readers to .

We denote the KL divergence and the total variation distance as \(D_{}(P\|Q)\) and \(D_{}(P,Q)\), respectively. We note that the total variation distance is in fact a metric on \(()\).

### System model

Suppose a client has access to a distribution \(P()\) over a sample space \(\), and wants to produce a sample in \(\) which looks like being drawn from \(P\) and to send it to a data curator. We assume that there are some constraints on the possible data distribution \(P\), so that \(P\) is restricted to be in some subset \(}()\), and both the client and the curator know \(\) and \(}\). However, it is required that a sampled element does not leak the privacy about the original distribution \(P\). For this purpose, the client and the curator agree a **private sampling mechanism \(\)**, which is a conditional distribution from \(}\) to \(\). After that, the client produces a sample following the distribution \((|P)\). To guarantee the privacy protection, we impose \(\) to satisfy the local differential privacy (LDP) .

**Definition 2.1**.: Let \(>0\). A private sampling mechanism \(\) is said to satisfy \(\)**-LDP**, or \(\) is an \(\)-LDP mechanism, if for any \(P,P^{}}\) and \(A\), we have

\[(A|P) e^{}(A|P^{}).\] (3)

For convenience, for each \(P}\), let \((P)()\) denote the distribution of \(X\) given \(P\) through \(\), that is \((P)(A)=(A|P)\) for each \(A\). In this way, we equivalently see \(\) as a function \(:}()\). Let \(_{,},}\) denote the set of all \(\)-LDP mechanisms \(:}()\).

As the utility loss of the private sampling, we use the \(f\)-divergence between the original distribution and the sampling distribution, \(D_{f}(P\|(P))\). Since the sampling procedure can be performed across many clients who may have different data distributions, we measure the utility loss of \(\) by the **worst-case \(f\)-divergence**,

\[R_{f}()=_{P}}D_{f}(P\|(P) ).\] (4)Given \(\), \(}\), \(\), and \(f\), our goal is to find the smallest possible worst-case \(f\)-divergence,

\[(,},,f)=_{ _{,},}}R_{f}(),\] (5)

and to find a mechanism \(_{,},}\) achieving it. We say that \(_{,},}\) is **optimal** for \((,},)\) under \(D_{f}\) if \(R_{f}()=(,},,f)\).

### Related work

The most closely related work to our work is . The system models are the same as this paper, except the formulation of PUT. They first _fix_ a reference probability distribution \(Q_{0}()\), and only consider mechanisms \(\) satisfying \(e^{-/2}Q_{0}(A)(A|P) e^{/2}Q_{0}(A)\) for all \(P}\) and \(A\). In other words, let \(_{,Q_{0}}=\{Q():e^{-/2}Q _{0}(A) Q(A) e^{/2}Q_{0}(A), A\}\). Then, they only consider \(\) such that \((P)_{,Q_{0}}\). Note that this guarantees \(\)-LDP. For each \(P}\), they sought to find \(Q_{,Q_{0}}\) which minimizes \(D_{}(P\|Q)\), and set this \(Q\) to be \((P)\). First, they claimed to find a closed-form expression of such a minimizer \(Q\) for finite \(\), given by

\[Q(x)=(P(x)/r_{P};e^{-/2}Q_{0}(x),e^{/2}Q_{0} (x)),\] (6)

where \(r_{P}>0\) is a constant depending on \(P\) ensuring \(_{x}Q(x)=1\). Second, they presented an algorithm, called Mollified Boosted Density Estimation (MBDE), to approximate the optimal solution for continuous \(\). However, the utility varies over the choice of reference distribution \(Q_{0}\), and they left the question of choosing a best \(Q_{0}\) to achieve the best performance in both practice and theory. Moreover, we found that the closed-form in (6) is incomplete, because for some \((P,Q_{0})\), there may be no \(r_{P}>0\) such that the RHS of (6) does not sum to one. As an example, when \(P,Q_{0}\) are point masses at different points, then we can easily see that the sum of (6) is \(e^{-/2}\) for any \(r_{P}>0\).

## 3 Main Results

### Optimal private sampling over finite space

First, we consider the finite case, where \(=[k]\) for some \(k\). A natural setup for \(}\) is that \(}=([k])\), i.e. there is no restriction on the client distribution \(P([k])\). In this case, we completely characterize the optimal worst-case \(f\)-divergence \((,},,f)\) and find an optimal private sampling mechanism. Surprisingly, for each \(k\) and \(>0\), we found a single mechanism which is universally optimal for every \(f\)-divergence.

**Theorem 3.1**.: _For each \(k\), \(>0\), and an \(f\)-divergence \(D_{f}\), we have_

\[([k],([k]),,f)=}{e^{}+ k-1}f(+k-1}{e^{}})++k-1} f(0).\] (7)

_Moreover, the mechanism \(_{k,}^{*}\) constructed as below satisfies \(\)-LDP and is optimal for \((=[k],}=([k]),)\) under any \(D_{f}\):_

\[_{k,}^{*}(x|P)=(}P(x),+k-1}) x[k],P([k]),\] (8)

_where \(r_{P}>0\) is a constant depending on \(P\) so that \(_{x=1}^{k}_{k,}^{*}(x|P)=1\). Furthermore, \(r_{P}\) can be chosen such that \(1 r_{P}(e^{}+k-1)/e^{}\)._

By definition, we have \(_{k,}^{*}(x|P)+k-1}\) for all \(x\). This also implies that \(_{k,}^{*}(x|P)=1-_{x^{}\{x \}}_{k,}^{*}(x^{}|P) 1-+k-1}=}{e^{}+k-1}\). Hence, \(+k-1}_{k,}^{*}(x|P)}{e^{}+k-1}\). This clearly implies that \(_{k,}^{*}\) satisfies \(\)-LDP.

Behaviors of the optimal mechanism.Let us observe some behaviors of the proposed mechanism with respect to the system parameters, whose formal proofs are in Appendix E. We visualize how the mechanism \(_{k,}^{*}\) works for different \(\) in Figure 2. Here, we write \(\) to mean \(([k],([k]),,f)\)for simplicity. If \(f(0)=\), then \(=\), which means that \(R_{f}()=\) for any \(\)-LDP sampling mechanism \(\). (Such a phenomenon happens for general \((,})\), whenever \(}\) contains two mutually singular distributions) Hence, from now on in this paragraph, we assume \(f(0)<\). We can observe that \(\) is decreasing in \(\) and increasing in \(k\). For a fixed \(k\), we have \( 0\) as \(\), which makes sense since \(\) corresponds to the non-private case. Also, as \( 0\), we have \(^{*}_{k,}(x|P) 1/k\) for every \(P([k])\) and \(x[k]\), that is, \(^{*}_{k,}(P)\) tends to the uniform distribution over \([k]\) for every \(P([k])\). This fact can be also observed by Figure 2.

Remarks about the constant \(r_{P}\).The value of \(r_{P}\) may not be unique, but the mechanism \(^{*}_{k,}\) does not depend on the choice of \(r_{P}\). To see this, let us fix \(P\), and let \(g_{r}(x)=(P(x),+k-1})\). Suppose that \(_{x=1}^{k}g_{r}(x)=_{x=1}^{k}g_{r^{}}(x)=1\) for \(r r^{}\). Since \(g_{r}(x) g_{r^{}}(x)\) for each \(x[k]\), the equality \(_{x=1}^{k}g_{r}(x)=_{x=1}^{k}g_{r^{}}(x)\) implies that \(g_{r}(x)=g_{r^{}}(x)\) for all \(x[k]\). Hence \(^{*}_{k,}\) is uniquely determined. Since \(r_{x=1}^{k}g_{r}(x)\) is non-increasing and continuous, we can use the bisection method to find \(r_{P}\). The 'Furthermore' part of the theorem statement precisely means that for \(r=1\) and \(r=(e^{}+k-1)/e^{}\), the value of \(_{x=1}^{k}g_{r}(x)\) is at least and at most \(1\), respectively, so that we can perform the bisection method with these two initial endpoints to find \(r\) such that \(_{x=1}^{k}g_{r}(x)=1\).

Comparison with the previous work .The expression of the optimal mechanism in (8) is similar to (6), the expression of the KL divergence projection onto \(_{,Q_{0}}\) derived by Husain et al. . Since \(+k-1}^{*}_{k,}(x|P)}{e^{}+k-1}\), we can alternatively write \(^{*}_{k,}(x|P)=(}P(x) ;+k-1},}{e^{}+k-1})\). Hence, our optimal mechanism can be viewed as an instance of a generalized version of (6), where \(Q_{0}\) is a positive measure, not necessarily a probability measure summing to one, given by \(Q_{0}(x)=}{e^{}+k-1}\). A natural question is whether \(^{*}_{k,}(P)\) is a projection of \(P\) onto \(_{,Q_{0}}\), that is \(^{*}_{k,}(P)\) is a minimizer of \(D_{}(P||Q)\) among \(Q_{,Q_{0}}\), where \(_{,Q_{0}}\) is similarly defined as in Section 2.3. As we shall discuss in Section 3.3, this statement is true --quite surprisingly-- even when we replace \(D_{}\) with any other \(f\)-divergences. However, our analysis is more involved, as we need to show the optimality of the proposed mechanism over _any other possible mechanisms_, including minimizers with respect to other choices of \(Q_{0}\). Also, in Section 5, we compare the worst-case \(f\)-divergence of our optimal mechanism with that of the mechanism proposed in  which restricts \(Q_{0}\) to be a probability distribution.

### Optimal private sampling over continuous space

Next, we consider the continuous case, where \(=^{n}\) for some \(n\). Some of the natural setups for \(}\) are (i) \(}=(^{n})\), or (ii) \(}=(^{n})\). We can also think some restrictive but still reasonable setups, such as the setups where (iii) \(}\) is the set of empirical distributions supported on some non-empty open subset of \(^{n}\), or where (iv) \(}\) is the set of continuous distributions on \([-1,1]^{n}\) having smooth pdf and zero mean. However, we show that for a general class of \(}\) including these four cases, any \(\)-LDP sampling mechanisms have the worst-case \(f\)-divergence equal to the maximum value \(M_{f}\) of the \(f\)-divergence defined in (2). In the following proposition, \(\) may be a general sample space, not necessarily \(^{n}\) or finite space. The proof is in Appendix D.

**Proposition 3.2**.: _Suppose that \(}\) contains infinitely many distributions which are pairwise mutually singular. Then, for any \(>0\), for any \(\)-LDP mechanism \(_{,},}\), and for any \(f\)-divergence, we have \(R_{f}()=M_{f}\), where \(M_{f}\) is define at (2)._

Figure 2: A visualization of the mechanism \(^{*}_{k,}\)

Hence, we need to consider sufficiently regular but practical setups for \(}\).

Our setup.In this subsection, when \(P,Q(^{n})\), the corresponding small letters \(p,q\) denote their pdfs. In this paper, we consider the case that

\[}=}_{c_{1},c_{2},h}:=\{P( ^{n}):c_{1}h(x) p(x) c_{2}h(x), x^{n}\}\] (9)

for some pre-known \(h:[0,)\) such that \(_{^{n}}h(x)dx<\) and \(c_{2}>c_{1} 0\). Some of the sampling tasks and generative models in literature  assume that the set of possible data distributions \(}\) satisfies \(}}_{c_{1},c_{2},h}\) for some \(c_{1},c_{2},h\) satisfying the aforementioned condition, hence (9) is a moderate assumption. One example is the sampling from a Gaussian mixture, which is one of the canonical sampling tasks in literature . Suppose that \(}\) consists of Gaussian mixtures, where each Gaussian has mean within a unit ball centered at the origin and has unit covariance. That is, \(}=\{_{i=1}^{k}_{i}(_{i},I_{n}):k ,_{i} 0,_{i=1}^{k}_{i}=1,\|_{i}\|  1\}\), where \(I_{n}\) is the identity matrix of size \(n n\). In this case, we can observe that \(}}_{0,1,h}\) for \(h(x)=(2)^{-n/2}(-((0,\|x\|-1))^{2}/2)\), and it can be easily shown that \(_{^{n}}h(x)<\).

Without loss of generality, we may assume the following normalization condition on \(c_{1},c_{2},h,\):

\[_{^{n}}h(x)dx=1, c_{1}<1<c_{2}, c_{2}>c_{1}^{ }.\] (10)

The reason is as follows. First, if any one of three inequalities \(_{^{n}}h(x)dx>0\), \(c_{1}_{^{n}}h(x)dx<1\), and \(c_{2}_{^{n}}h(x)dx>1\) is not satisfied, then \(}_{c_{1},c_{2},h}\) is either an empty set or a singleton that consists of a distribution having pdf \(c_{1}h(x)\) or \(c_{2}h(x)\), which makes the problem trivial. Hence we impose all of the three inequalities. Then, we can normalize \(c_{1},c_{2},h\), to make \(_{^{n}}h(x)dx=1\) and \(c_{1}<1<c_{2}\). Furthermore, if \(c_{2} e^{}c_{1}\), then for any \(P_{1},P_{2}}_{c_{1},c_{2},h}\), we have \(p_{1}(x)/p_{2}(x) c_{2}/c_{1} e^{}\), hence we can easily observe that the mechanism \(\) defined as \((P)=P\) for all \(P}_{c_{1},c_{2},h}\) satisfies \(\)-LDP and \(R_{f}()=0\), hence the problem also becomes trivial, giving \((^{n},}_{c_{1},c_{2},h},,f)=0\). Hence, we may assume (10).

Minimax utility and optimal mechanism.For the aforementioned setup, we can completely characterize \((,},,f)\) and find a mechanism which is universally optimal for every \(f\)-divergence. The formula is similar to the discrete case, with a carefully chosen clipping bound.

**Theorem 3.3**.: _For each \(c_{2}>c_{1} 0,>0\), and \(h:^{n}[0,)\) satisfying the normalization condition (10), let us define the following constants determined by \(c_{1},c_{2},\):_

\[b=-c_{1}}{(e^{}-1)(1-c_{1})+c_{2}-c_{1}}, r_{1}= {c_{1}}{b}, r_{2}=}{be^{}}.\] (11)

_Then, we have_

\[(^{n},}_{c_{1},c_{2},h},,f)= {1-r_{1}}{r_{2}-r_{1}}f(r_{2})+-1}{r_{2}-r_{1}}f(r_{1}).\] (12)

_Moreover, the mechanism \(^{*}_{c_{1},c_{2},h,}\) constructed as below satisfies \(\)-LDP and is optimal for \((=^{n},}=}_{c_{1},c_{2 },h},)\) under any \(D_{f}\):_

_For each \(P}\), \(^{*}_{c_{1},c_{2},h,}(P)=:Q\) is defined as a continuous distribution with pdf_

\[q(x)=(}p(x);bh(x),be^{}h(x) ),\] (13)

_where \(r_{P}>0\) is a constant depending on \(P\) so that \(_{^{n}}q(x)dx=1\). Furthermore, \(r_{P}\) can be chosen such that \(r_{1}<r_{P} r_{2}\)._

It is also clear that \(^{*}_{c_{1},c_{2},h,}\) satisfies \(\)-LDP. Also, we note that \(c_{1}<b<1<be^{}<c_{2}\) and \(0 r_{1}<1<r_{2}\), which is shown during the proof of Theorem 3.3 in Appendix C.

In practical scenario, it may be hard to expect \(}=}_{c_{1},c_{2},h}\) exactly, and we may only know \(}}_{c_{1},c_{2},h}\) for some \(c_{1},c_{2},h\) satisfying aforementioned conditions. In such case, we still propose to use \(^{*}_{c_{1},c_{2},h,}\), and in Section 5, we numerically show that this proposed mechanism is better than previously proposed mechanism  in terms of the worst-case \(f\)-divergence.

Behavior of the optimal mechanism.We also observe some behaviors of the proposed mechanism with respect to the system parameters, whose formal proofs are in Appendix E. Again, we write \(\) to mean \((^{n},}_{c_{1},c_{2},h},,f)\) for simplicity. For a fixed \((c_{1},c_{2})\), \(\) is decreasing in \(\). If \(c_{1}=0\) (which implies \(r_{1}=0\)) and \(f(0)=\), then \(=\), which means \(R_{f}()=\) for any \(\)-LDP sampling mechanism \(\). For the behavior at \(\) for a fixed \((c_{1},c_{2})\), if \(c_{1}>0\), then for sufficiently large \(\), we have \(c_{1}e^{} c_{2}\), so we fall in the aforementioned trivial case that \(=0\). If \(c_{1}=0\) and \(f(0)<\), then as \(\), we have \( 0\), which again corresponds to the non-private case.

Remarks on the constant \(r_{P}\).By the same reason as in the finite space case, the value of \(r_{P}\) may not be unique, but \(_{c_{1},c_{2},h,}^{*}\) does not depend on the choice of \(r_{P}\), and \(r_{P}\) can be found by the bisection method with a numerical integration of (13). Note that the continuity of \(r g_{r}(x)dx,g_{r}(x)=(p(x);bh(x),be^{ }h(x))\), follows from the dominated convergence theorem  since we assume \(_{^{n}}\), \(h(x)dx<\). The meaning of 'Furthermore' part is also similar to the finite space case, that is, the value of \( g_{r}(x)dx\) at \(r=r_{1}\) and \(r=r_{2}\) is at least and at most \(1\), respectively, so that we can perform the bisection method with initial endpoints \((r_{1},r_{2})\) (When \(r=0\), we define \(g_{r}(x)=be^{}h(x)\) whenever \(p(x)>0\) and \(g_{r}(x)=bh(x)\) whenever \(p(x)=0\)). A corner case is that when \(r_{1}=0\), the continuity of \(r g_{r}(x)dx\) does not suffice to guarantee the existence of strictly positive \(r\) such that \( g_{r}(x)dx=1\). However, in the proof, we actually show that \( g_{r_{1}}(x)dx=1\) implies \( g_{r}(x)dx=1\) for _every_\(r(r_{1},r_{2}]\), which especially implies that even when \(r_{1}=0\), there is a _strictly positive_\(r\) such that \( g_{r}(x)dx=1\). This is the reason that we state the strict inequality \(r_{1}<r_{P}\).

### Proof sketch of the theorems

The full proofs of the main theorems, Theorems 3.1 and 3.3, are presented in Appendix C. In Appendix C, we present a generalized theorem which includes Theorems 3.1 and 3.3 as special cases, where \(\) can be a general sample space and \(}\) is similarly defined as in the continuous space case. The key idea for proofs and proposed mechanisms is to focus on the behavior of \((P)\) when \(P\) is in an extreme case in \(}\). In finite space, point masses are extreme cases, and for continuous space with \(}=}_{c_{1},c_{2},h}\), the cases that \(p(x)\{c_{1}h(x),c_{2}h(x)\}\) for all \(x\) are the extreme cases. As implied by the proof, the worst-case \(f\)-divergence of the proposed optimal mechanism is attained when \(P\) is in the aforementioned extreme cases. Such an approach using extreme case is a frequently used technique in PUT analysis [55; 56; 57; 58].

Our proof consists of two parts, the achievability part and the converse part. The achievability part is to show that the worst-case \(f\)-divergence \(R_{f}(^{*})\) of our proposed mechanism \(^{*}\) is upper-bounded by the RHS of (7) or (12). The converse part is to show that \(R_{f}()\) of _any_\(\)-LDP mechanism \(\) is lower-bounded by the RHS of (7) or (12). From now, we briefly describe the proof idea of each part. Here, we omit the subscripts \((k,)\) or \((c_{1},c_{2},h,)\) for notational convenience.

Achievability part.Let \(=\{^{*}(P):P}\}\). For finite space, \(\) consists of all distributions \(Q([k])\) such that \(+k-1} Q(x)}{e^{}+k-1}\) for every \(x[k]\). For continuous space, \(\) consists of all continuous distributions \(Q(^{n})\) whose pdf \(q\) satisfies \(bh(x) q(x) be^{}h(x)\) for every \(x^{n}\).

We construct a mechanism \(^{}\) such that \(R_{f}(^{})\) is upper-bounded by the RHS of (7) or (12). The construction is as follows. First, we set a reference distribution \(()\) and a constant \(\) according to a certain rule specified in Appendix C. Then, for each given \(P\), we generate a private sample by sampling from the original \(P\) with probability \(\), and sampling from the reference distribution \(\) with probability \(1-\). In other words, we have \(^{}(P)= P+(1-)\). Our choice of \(\) and \(\) makes \(^{}(P)\) for every \(P}\), which especially implies that \(^{}\) also satisfies \(\)-LDP. Furthermore, we can find a bound on the ratio of the pmf or pdf for original distribution to that for sampling distribution. Then, invoking [59, Theorem 2.1], which bounds \(f\)-divergences given bounds on the ratio between pmf or pdfs, we show that \(R_{f}(^{})\) is upper-bounded by the RHS of (7) or (12).

Next, we demonstrate a non-trivial generalization of the main result of  that \(^{*}(P)\) is the \(f\)-divergence projection of \(P\) onto \(\) for \(P}\) and _for every \(f\)-divergence_.

**Proposition 3.4**.: _Assuming the setups of \((,},)\) in either Theorem 3.1 or 3.3, let \(^{*}\) denote the proposed mechanism \(^{*}_{k,}\) or \(^{*}_{c_{1},c_{2},h,}\). Also, let \(\) be as described above. Then, for every \(P}\) and every \(f\)-divergence \(D_{f}\), we have \(D_{f}(P\|^{*}(P))=_{Q}D_{f}(P\|Q)\)._

Notice that this proposition differs from  in that it holds for all general \(f\)-divergences (as opposed to only KL divergence) and general sample spaces, be it discrete or continuous. This result immediately yields \(D_{f}(P\|^{*}(P)) D_{f}(P\|^{ }(P))\), and hence \(R_{f}(^{*}) R_{f}(^{})()\). We remark that combining with the converse part (to be described below), it implies that the \(^{}\) is also optimal in our minimax sense. Nevertheless, \(^{*}\) outperforms \(^{}\) in that \(D_{f}(P\|^{*}(P)) D_{f}(P\|^{}(P))\) for every \(P}\).

_Remark 3.5_.: For the finite case, \(\) is the uniform distribution over \([k]\) and \(\) is taken in such a way that \(^{}\) satisfies \(\)-LDP tightly. In this case, an alternative way to implement \(^{}\) is as follows. For each given \(P\), first we sample from \(P\) to get a raw sample and then apply the \(k\)-ary randomized response  to it.

Converse part.For each extreme \(P\), let \(A_{P}\) be the "high probability set", defined as \(A_{P}=\{x:P(x)=1\}\) for finite space and \(A_{P}=\{x:p(x)=c_{2}h(x)\}\) for continuous space. Then, using the data processing inequality of \(f\)-divergence , we take a lower bound of \(D_{f}(P\|(P))\) by the \(f\)-divergence between the distributions of \(_{A_{P}}(X)\) for \(X P\) and that for \(X(P)\). Such a lower bound becomes a decreasing function of \((A_{P}|P)\) in a certain range. Then, we seek to find an upper bound on \((A_{P}|P)\) over extreme \(P\), which gives a lower bound on \(R_{f}()\). This involves a novel combinatorial argument. We perform a "packing" of \(u\) copies of \(\) by \(t\) subsets \(A_{1},,A_{t}\) with \(A_{i}=A_{P_{i}}\) for some extreme \(P_{i}\) and appropriately chosen \(t\) and \(u\). Then, we decompose the RHS of \(u=_{i=1}^{u}(|P_{i})\) by an appropriate partition of \(\) involving \(A_{i}\)'s and use the definition of \(\)-LDP to find an upper bound on \((A_{P}|P)\).

## 4 Discussions on the Proposed Mechanism

### Effect of the \(r_{p}\) approximation error

In practice, it may not be possible to find the exact value of \(r_{P}\) such that the sum or integration of the RHS of (8) or (13) is \(1\). For the case of continuous space as in Theorem 3.3, one way to implement the proposed mechanism \(^{*}_{c_{1},c_{2},h,}\) in practice is as follows. First, we fix parameters \(_{1}[0,1)\) and \(_{2} 0\) that quantify error tolerance. For a given \(P\), we define \(g_{r}(x)=(p(x);bh(x),be^{}h(x))\) and find \(r_{P}>0\) such that \(_{^{n}}g_{r_{P}}(x)dx[1-_{1},1+_{2}]\); we delineate a numerical algorithm for this task in Section 3.2 based on the bisection method and a numerical integration method. Then, we get a private sample by sampling from the distribution with pdf \((x)=g_{r_{P}}(x)/_{^{n}}g_{r_{P}}(x)dx\). For the finite case as in Theorem 3.1, we can implement in the same way, except replacing the integral with the sum.

It is important to note that \((x)[},h(x)}{1- _{1}}]\), indicating that the resulting \(^{*}_{k,}\) and \(^{*}_{c_{1},c_{2},h,}\) satisfy \((+}{1-_{1}})\)-LDP as opposed to \(\)-LDP. Thus, the above implementation yields \(\)-LDP if it is used to implement \(^{*}_{k,^{}}\) or \(^{*}_{c_{1},c_{2},h,^{}}\), with \(^{}=-}{1-_{1}}\) and sufficiently small \(_{1},_{2}\) such that \(^{}>0\).

### Continuity of the proposed mechanism

In some practical scenarios, the client may not have full access to their distribution \(P\). One example is that the client can only access to samples from \(P\). In such case, the client may first estimate the true distribution, and then perturb the estimated distribution through the optimal mechanism. The question is how the perturbation using the estimated distribution deviates from that using the true distribution. To answer this, we show that the proposed mechanism satisfies a pointwise Lipschitz property with respect to the total variation distance, and the Lipschitz constant is closely related to the factor \(r_{P}\) we introduce in Theorems 3.1 and 3.3.

**Proposition 4.1**.: _Assuming the setups of \((,},)\) in either Theorem 3.1 or 3.3, let \(^{*}\) denote the proposed mechanism \(_{k,}^{*}\) or \(_{c_{1},c_{2},h,}^{*}\). Then, for any \(P,P^{}}\), we have_

\[D_{}(^{*}(P),^{*}(P^{})) ,r_{P^{}})}D_{}(P,P^{})\] (14)

_where \(r_{P}>0\) is as in Theorem 3.1 or 3.3._

This guarantees that for each given true \(P\) and given \(>0\), whenever the approximated \(P^{}\) satisfies \(D_{}(P,P^{}) r_{P}/2\), the perturbed distribution \(^{*}(P^{})\) satisfies \(D_{}(^{*}(P),^{*}(P^{}))\). In theoretical perspective, this proposition implies that \(^{*}\) is continuous when \(}\) and \(()\) are endowed with the metric topology from the total variation distance. The proof of Proposition 4.1 is in Appendix D.

## 5 Numerical Results

In this section, we numerically compare the worst-case \(f\)-divergence of our proposed mechanism with that of the previously proposed sampling mechanism. To the best of our knowledge, the only work about the private sampling under LDP is , hence we set the baseline as the mechanism proposed in . In all the cases, we perform the comparison across three canonical \(f\)-divergences: KL divergence, total variation distance, and squared Hellinger distance, as well as across five values of \(\): 0.1, 0.5, 1, 2, and 5.

### Comparison for finite data space

In this subsection, we compare the mechanisms in the finite space, \(=[k]\) and \(}=([k])\). As mentioned in Sections 2.3 and 3.1, the baseline mechanism has a hyper-parameter, a reference probability distribution \(Q_{0}()\). We set the baseline as a generalized \(f\)-divergence projection onto the relative mollifier. That is, for each given \(f\)-divergence, we set the baseline to satisfy \((P)_{Q_{,Q_{0}}}D_{f}(P\|Q)\), where \(_{,Q_{0}}\) is defined in Section 2.3. As expected by symmetry, for any \(f\), choosing \(Q_{0}\) to be the uniform distribution minimizes the worst-case \(f\)-divergence \(R_{f}()\) among all choices of \(Q_{0}\) for the baseline. Also, even though we do not obtain the closed-form expression of \((x|P)\) for the baseline, we obtain the value of \(R_{f}()\) when \(Q_{0}\) is the uniform distribution. The proof of this fact, together with the precise value of \(R_{f}()\) for uniform \(Q_{0}\), is in Appendix F.1. Hence, we always set \(Q_{0}\) to be the uniform distribution in the result about the baseline. Since we have the precise values of \(R_{f}()\) for both our proposed mechanism and the baseline, we plot such values of \(R_{f}()\) in Figure 3. For simplicity, we only provide the plot for \(k=10\). More plots for some other \(k\)'s can be found in Appendix G. As shown by the figure, the proposed mechanism has lower worst-case \(f\)-divergence than the baseline for all choices of \(f\)-divergences and \(\) in the experiment, with significant gap in medium privacy regime \([0.5,2]\).

Figure 3: Theoretical worst-case \(f\)-divergences of proposed and previously proposed baseline mechanisms (with uniform \(Q_{0}\)) over finite space (\(k=10\))

(Left: KL divergence, Center: Total variation distance, Right: Squared Hellinger distance)

### Comparison for 1D Gaussian mixture

In this subsection, we conduct an experiment to compare the mechanisms when the client distributions are Gaussian mixtures over a real line \(=\), which is an instance of a continuous space case. We consider the case that each client has a Gaussian mixture distribution in \(\), where each Gaussian has a mean bounded by \(1\) and has a unit variance. To avoid arbitrarily large number of Gaussian distributions to be mixed, we set an upper bound \(K\) of the number of Gaussian distributions to be mixed per client. Also, to make the numerical integration tractable, we truncate the domain of the distributions to lie inside an interval \([-4,4]\). Unlike the finite space case, there is no known closed-form expression of the worst-case \(f\)-divergence for the mechanism in . The set of Gaussian mixtures is not exactly of the form \(}=}_{c_{1},c_{2},h}\), hence our proposed mechanism also does not have a known closed-form expression of the worst-case \(f\)-divergence. Hence, instead, we compare the mechanisms by an empirical worst-case \(f\)-divergence.

For an experiment, we randomly construct \(N\) Gaussian mixture distributions \(P_{1},P_{2},,P_{N}}\), where each \(P_{j}\) is generated independently according to some rules specified in Appendix F.2. After that, we plot the value of the empirical maximum \(f\)-divergence \(_{j[N]}D_{f}(P_{j}\|(P_{j}))\) for the baseline and our proposed \(\). For the baseline mechanism, we use MBDE with the same hyperparameter setup as [35, Section 5], except a slight modification of the reference distribution to consider the truncation of the domain. The implementation details are provided in Appendix F.2.

In Figure 4, we present the result for \(N=100\) and \(K=10\). We can see that the proposed mechanism has much lower worst-case \(f\)-divergence than the baseline for all choices of \(f\)-divergences and \(\).

## 6 Conclusion

In this paper, we characterized the optimal privacy-utility trade-off for the private sampling under LDP and found the optimal private sampling mechanism in terms of the minimax \(f\)-divergence between original and sampling distributions, for both finite and continuous data spaces. Compared to the previous work  based on relative mollifier with arbitrarily chosen reference distribution, our work characterizes PUT without dependency on external information other than the original distribution, and it is shown that the mechanism we found is universally optimal under any \(f\)-divergence.

For future works, there may be other \(}\) and other measures of utility more appropriate to practical scenarios, which are not handled in this paper. For example, \(f\)-divergence may be an inappropriate utility loss because it only depends on \(\)-algebra structure and does not consider additional information about geometry of \(\), such as underlying metric on \(\). Using utility measures involving the geometry, such as Wasserstein distance [62; 63; 49], may be more appropriate for some scenarios. Also, we can consider the Bayesian approach instead of the worst-case approach. Furthermore, we only consider the task of releasing a single sample per client in this paper. We may also consider the case of releasing multiple samples per client, rather than a single sample.

The limitations and broader impacts of this work are in Appendices I and J, respectively.

Figure 4: Empirical worst-case \(f\)-divergences of proposed and baseline mechanisms over 100 experiments of 1D Gaussian mixture (Left: KL divergence, Center: Total variation distance, Right: Squared Hellinger distance)