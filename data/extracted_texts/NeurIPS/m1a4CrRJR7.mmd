# Generalization Error Bounds for Two-stage Recommender Systems with Tree Structure

Jin Zhang1, Ze Liu2, Defu Lian*1, 2, 3, Enhong Chen1, 2, 3

1 School of Artificial Intelligence and Data Science, University of Science and Technology of China

2 School of Computer Science and Technology, University of Science and Technology of China

3 State Key Laboratory of Cognitive Intelligence, Hefei, Anhui, China

{jinzhang21, lz123}@mail.ustc.edu.cn, {liandefu, cheneh}@ustc.edu.cn

###### Abstract

Two-stage recommender systems play a crucial role in efficiently identifying relevant items and personalizing recommendations from a vast array of options. This paper, based on an error decomposition framework, analyzes the generalization error for two-stage recommender systems with a tree structure, which consist of an efficient tree-based retriever and a more precise yet time-consuming ranker. We use the Rademacher complexity to establish the generalization upper bound for various tree-based retrievers using beam search, as well as for different ranker models under a shifted training distribution. Both theoretical insights and practical experiments on real-world datasets indicate that increasing the branches in tree-based retrievers and harmonizing distributions across stages can enhance the generalization performance of two-stage recommender systems.

## 1 Introduction

Recommender systems play a crucial role in many online services, such as e-commerce , digital streaming , and social media , influencing consumer behavior, media consumption, and social interaction. It needs to quickly identify a few relevant items from millions or billions of options, and personalize to the dynamic needs of large numbers of users with low response latency. A widely adopted solution to this problem is the two-stage recommender system. In the first stage, a computationally efficient retriever preselects a small number of candidates from a large pool. In the second stage, a slower but more accurate ranker narrows down and reorders these candidates before presenting them to the user. In this way, a well-balanced trade-off between efficiency and accuracy is achieved that meets the demands of real-world scenarios.

The retrievers are often heterogeneous, popular choices like matrix factorization , two-tower , recurrent neural networks , and so on. In recent years, the tree-structured retriever model , which takes advantage of the tree structure, usually combined with a greedy algorithm to identify relevant items quickly, has demonstrated commendable performance and efficiency. The ranker typically uses enriched features as input, combined with a complex model, to enhance prediction accuracy. The computational costs are generally linear relative to the number of items at deployment .

Despite the practical success of two-stage models, particularly those based on tree structures, theoretical research in this area remains limited. To fill in the gap, we start from the perspective of generalization error to investigate the upper bounds of generalization error for these models to promote understanding of their generalization capabilities.

In this paper, we decompose the generalization error of two-stage models across each stage. Using Rademacher complexity as a methodological tool, our analysis encompasses a range of models prevalent in two-stage methods. This includes tree-structured retriever models employing beam search, such as linear model, multilayer perceptron, and target attention model. Besides, we give generalization error bound for ranker models under shifted training distributions. The theoretical results show that tree models with increased branches and rankers trained on harmonized distributions can improve generalization performance, and we validate these findings on real-world datasets.

To summarize, the main contributions of this work are summarized as follows:

* We are the first to analyze the learnability of tree-based retriever models in recommender systems and prove the generalization upper bound for various tree-based retrievers using beam search. Both theoretical insights and practical experiments confirm that expanding the number of branches in tree-based retrievers enhances their ability to generalize.
* We establish an error decomposition framework for analyzing generalization errors of two-stage recommender systems and theoretically derive the optimized training objectives for the ranker models within this framework.
* We prove the generalization upper bounds for different ranker models under shifted training distribution, highlighting the significant impact of disparities between training and inference data distributions on generalization errors. Theoretical and empirical findings indicate that harmonizing distributions across stages enhances the overall generalization performance of two-stage recommender systems.

The remainder of this paper is organized as follows: Section 2 provides an overview of related work, Section 3 presents the notation and background, Section 4 presents the main results and analytical techniques, and Section 5 provides the conclusion of the paper. Finally, the missing proofs and experimental settings are provided in the appendix.

## 2 Related Work

### Two-stage Recommender Systems

Two-stage recommender systems with candidate generation followed by ranking have been widely adopted in the industry, including YouTube [4; 23; 26], Linkedin , Pinterest . Some works focus more on improving candidate generation, particularly under tree structures. TDM  efficiently manages candidate retrieval in large-scale systems using a hierarchical tree-index strategy. JTM  improves on TDM by jointly optimizing the tree index structure and the user node preference prediction model. DeFoRec  extends the loss function used in TDM from a binary probability to a multi-class softmax loss. Other works, like , study off-policy learning for two-stage recommender systems, where the goal is to learn a good recommendation policy from the typically abundant logged data. This approach is possibly most related to our work in the ranker component. The main proposal of  is to modify the training objective by adding importance weights based on the ranker's probability of recommending each item. With adjustments facilitating gradient descent optimization, the authors show empirical improvements compared to a system trained without importance weighting.  propose a modification of naive bandit method deployment in two-stage recommenders that improves results by sharing inferred statistics between ranker and nominators with minimal computational overhead.  aims to provide an LLM-based two-stage recommender that uses a large language model as a ranker to improve performance.

### Theoretical Work

In this subsection, we discuss the theoretical work related to our study, as well as other theories related to two-stage models.  propose a multi-class, hierarchical data-dependent bound on the generalization error of classifiers deployed in large-scale taxonomies to explain several empirical results related to the performance of hierarchical classifiers. Our analysis of tree structure models is inspired by this work. We extend it to the search method of beam search and provide a more refined estimate for the tree model.  investigates generalization error bounds for extreme multi-class classification with minimal dependence on the class set by using multi-class Gaussian complexity to construct bounds for multi-class problem.  theoretically demonstrated that nominator count and training objectives significantly impact two-stage recommender performance and linked two-stage recommenders to Mixture-of-Experts models to show performance improvements by allowing nominators to specialize.  quantitatively assesses the asymptotic convergence properties of the two-tower model applied in two-stage recommenders toward an optimal recommender system.

## 3 Preliminaries

### Notation

We use the following notational conventions: bold lowercase and uppercase letters for vectors and matrices respectively, such as \(\) and \(\), and non-bold letters for scalars or constants, such as \(c\) and \(B\). For vectors, \(\|\|_{p}\) denotes the \(_{p}\) norm; we drop the subscript for the \(_{2}\) norm. For matrix,

\[\|\|_{p}=_{\|\|_{p}=1}\|\|_{p}\]

denotes matrix norms induced by vector \(p\)-norms. We denote the set {1, 2,..., m} by [m]. In the defined notation system, \(m\) represents the number of users or queries, \(N\) denotes the total number of items, and \(K\) is the number of items retrieved in the first stage. \(B\) indicates the number of children nodes per non-leaf node, while \(L\) specifies the number of layers in a neural network. The complete set of items is symbolized by \(\). For \(i[m]\), \(_{i}^{d}\) is the embedding vector to represent user, if we use sequence embeddings to represent the user, we denote this with a matrix \(^{(i)}\), and \(y_{i}\) is the corresponding target item. The function \(h()\) represents the prediction result for \(\).

Following previous traditional notations, in the case of hierarchical classification, the hierarchy of classes \((V,E)\) is defined in the form of a rooted tree, with a root \(\) and a parent relationship \(:V\{\} V\) where \(()\) is the parent of node \( V\{\}\), and \(E\) denotes the set of edges with parent to child orientation. \(_{k}()\) identifies nodes selected at depth \(k\) during a beam search for input \(\). For each node \( V\{\}\), we further define the set of its children \(()=\{^{} V\{\};(^ {})=v\}\). The specialized nodes at the leaf level constitute the set of target items. Finally, for each item \(y\) in \(\) we define the set of its ancestors \((y)\) defined as

\[(y)= \{v_{1},,v_{k_{y}}:v_{1}=(y),(v_{k_{y}})= ,v_{l+1}=(v_{l}),\;l\{1,,k_{y}-1\}\}.\]

### Background

#### 3.2.1 Tree Structure Retriever Model

During the retrieval stage, a tree is utilized where each leaf node represents an item. Additionally, each node in the tree has a learnable parameter vector that has the same dimensionality as the user vector. The architecture of the tree is generally determined by hierarchical clustering techniques, as shown in the studies by [29; 24].

When constructing the tree, we first need to obtain the initial item representations, which can be accomplished through various methods. The item representations can be represented by the instance-item matrix \(\{0,1\}^{m N}\). A strategy to construct item representations is by leveraging indices of positive instances. For any given item \(i\) within the item set \(\), its corresponding representation vector \(_{i}\) is defined through normalization as: \(_{i}=}_{i}/\|}_{i}\|\), where the vector \(}_{i}\{0,1\}^{m}\) signifies the \(i\)-th column of the instance-to-item matrix \(Y\), encapsulating the relationship between instances and the item \(i\). It is possible to refine the item representation by incorporating additional feature information, an enhanced formulation of \(}_{i}\) is employed, expressed as \(}_{i}=_{j=1}^{m}_{ji}_{j}\), where \(_{j}\) denotes the feature vector associated with the \(j\)-th instance. Besides, some works, like , have employed a technique of starting with a randomly initialized tree structure aligned with item categories. The learned parameters of the leaf nodes are subsequently utilized as new initial representations for the items.

After acquiring item representations, we repeatedly apply clustering algorithms, such as \(k\)-means, to form the complete tree structure. In the initial phase, all items are aggregated at the root. These items are then clustered into \(B\) categories, creating the root's child nodes. This procedure is recursively performed in each child node until each category is reduced to a single item, establishing the leaf nodes. A balanced distribution of items among the categories can lead to a more even tree structure, a practice widely utilized in applications.

During inference, the user representation \(\) starts from the root node, and the path is continually extended until a leaf node is reached, using a beam search based on the model score between the user representation and the node parameter vector. Specifically, assuming a beam size of \(K\), we maintain at most \(K\) paths during the inference process. Initially, the user representation selects the top \(K\) nodes with the highest model scores from the children of the root node, denoted as \(_{1}()\). If the number of available nodes for selection is less than \(K\), all available nodes are selected. \(_{i+1}()\) denotes the selected nodes at depth \((i+1)\) for an input \(\),

\[_{i+1}()=_{(_{i}( ))}^{K}f(,),\]

where we denote \(^{K}\) as the Top-K operator, which selects the top \(K\) nodes from the children of nodes in \(_{i}()\), denoted as \((_{i}())\) based on the highest score \(f(,)\). To avoid the problem of leaf nodes lacking children during the inference process, we extend the definition of \(()\),

\[()=\{\},\]

In this extended definition, the children of a leaf node are considered to be the leaf node itself. The set of \(K\) leaf nodes ultimately selected by this process is denoted by \(()\).

#### 3.2.2 Ranker Model

The retriever models and the ranker models are often trained independently using logged feedback data (e.g., user clicks or dwell time) generated by previous versions of the recommender system. Compared to retriever models, ranker models may utilize more contextual information to better represent the user, leading to more accurate predictions. For simplicity, in this work, we assume that both the retriever and ranker models have the same input (e.g., user interaction history sequence). The key difference is that the retriever uses a tree-structured greedy model to retrieve a subset from a large item pool, while the ranker predicts scores for each item within this subset \(()\). Finally, the item with the highest score from \(()\), as determined by the ranker, is returned as the prediction result, which we denote as \(h()\).

#### 3.2.3 Generalization Error

In the training of machine learning algorithms, we are constrained to a finite dataset for learning. Nevertheless, the resulting function must generalize effectively beyond the training sample. Thus, ensuring high probability guarantees for the difference between the loss on the training sample and the loss on the test population is of paramount importance. Generalization bounds aim to constrain this loss difference.

Mathematically, if we have a hypothesis class \(\), sample space \(\), item space \(\), loss function \(\), and distribution over the sample and item space \(\), then our generalization gap for a set of samples and items \(S=\{(},y_{i})\}_{i=1}^{m},} \), \(y_{i}\), on the hypothesis \(h\) is defined to be

\[|[(h(),y)]-_{i=1}^{m}(h( }),y_{i})|.\] (1)

Notice how if we can have this value go to 0 with high probability over all sets of samples and for all \(h\), then we can be confident that minimizing the empirical loss will not impact our generalization.

One tool that can be used to upper bound the generalization gap is the Rademacher complexity. The Rademacher complexity of a hypothesis class \(\) is defined to be

\[}_{m}()=_{}[ _{h}_{i=1}^{m}_{i}h(})],\]

where each \(_{i}\) are i.i.d. and take the value \(1\) or \(-1\) each with half probability and \(=(_{1},,_{m})\). It is well known that , if the magnitude of our loss function is bounded above by \(c\), with probability greater than \(1-\) for all \(h\), we have

\[|_{(,y)}[(h(),y)]- _{i=1}^{m}(h(}),y_{i})| 2}_{m}()+c}.\] (2)

Therefore, if we have an upper bound on the Rademacher complexity, we can have an upper bound on the generalization gap.

Theory Results

We begin by considering the two-stage error decomposition. Let \(P_{}^{}\) denote the two-stage classification error, i.e., \(P(h() y)\). \(P_{}^{}\) and \(_{}^{}\) represent the classification errors caused by the retriever and ranker, respectively. We have the following proposition:

**Proposition 4.1**.: _The probability of a classification error of the two-stage method can be decomposed as follows:_

\[P_{}^{}=P_{}^{}+_ {}^{}(K)(1-P_{}^{}),\] (3)

_where \(P_{}^{}=P(y())\) and \(_{}^{}(K)=P(h() y y ())\) with \(|()|=K\)._

In Proposition 4.1, the total generalization error of two stages is decomposed into two critical components, \(P_{}^{}\) and \(_{}^{}\). \(P_{}^{}\) captures the error when the target item isn't included in the retriever model's results, reflecting the probability that the item \(y\) doesn't appear in the set \(()\). \(_{}^{}\) refers to the error that occurs when the target item \(y\), although present in the retriever's results \(()\), is not correctly ranked by the ranker model.

Compared to a single ranker model for classification tasks, we use \(P_{}^{}(N)\) to denote the classification error, where \(N\) emphasizes that the ranker model is used for an \(N\)-class task, we have the following corollary:

**Corollary 4.2**.: _The error \(P_{}^{} P_{}^{}(N)\) if and only if the retrieval error \(P_{}^{}\) satisfies the following inequality:_

\[P_{}^{}}^{}(N)- _{}^{}(K)}{1-_{}^{}(K)}.\] (4)

Regarding inequality (4), we have two approaches to enhance its validity. One is to reduce \(P_{}^{}\) without increasing the number of retriever results. The other is to improve the ranker model while keeping the retriever unchanged, to reduce \(_{}^{}\) and thus increasing the threshold on the right side of the inequality. Furthermore, by Property 4.1, both approaches will lead to lower two-stage classification error. In the following subsections, we will analyze these two errors separately from a generalization bound perspective, revealing their relationship with the actual observed empirical errors.

### Retriever

For the model described in Sec.3.2.1, we represent the user using the vector \(}^{d}\), which can be a vector representation of a text segment, or an embedding derived from a pre-trained model that includes relevant features (If we use sequence embeddings to represent the user, we denote this with a matrix \(^{(i)}\)). We consider different user and target items to be independently and identically distributed, denoted as \((},y_{1}),,(},y_{m})\).

Following previous work , we consider the following analogous function space induced by the function space \(\):

\[_{}=\{g_{f}:(,y) _{(y)}f( ,)-\\ _{}\{f(,^{})| {v}^{}(,)\}\ |\ f\},\] (5)

where \((y)\) is the ancestors of node \(y\), \((,)\) denotes the set of candidates during beam search at the same level as node \(\), in particular, if \(d()\) represents the depth of node \(\) within the tree structure, then \((,)=(_{d()-1}())\), \(_{}\) denotes the \(K\)-th largest element in a set, \(f(,)\) represents the score function between node \(\) and input \(\). The specific formulation of the score function will be discussed in Section 4.1.1.

Compared with previous work, we extend the function space to the top-k form, as described in equation (5), we can observe the following proposition:

**Proposition 4.3**.: _For any leaf node \(y\) and user representation \(\), we have_

\[g_{f}(,y) 0 y().\]This implies that the probability of classification error is equal to the probability of occurrence of the event \(g_{f}(,y)<0\):

\[(y())=(g_{f}(,y)<0).\] (6)

For this event, we can formulate the following theorem about the Rademacher complexity of the function space \(_{}\):

**Theorem 4.4**.: _Consider a loss function \((x)\) that is monotonically decreasing, satisfies \((x 0)(x)\), and is a Lipschitz function with Lipschitz constant \(c_{}\) and an upper bound \(B_{}\). The following inequality holds with a probability of at least \(1-\):_

\[P_{}^{}_{i=1}^{m} (g_{f}(_{i},y_{i}))+4c_{}}_{m}(_{})+B_{}}.\]

Theorem 4.4 presents a general result, considering an abstracted loss function under specific conditions and the Rademacher complexity of the function space. In Section 4.1.1, we will present the upper bounds of Rademacher complexity for various specific function spaces. Regarding \((g_{f})\), it can be related to common loss functions, such as margin-based loss and cross-entropy. We will discuss the relationship between \((g_{f})\) and these commonly used loss functions in the Appendix A.

#### 4.1.1 Effect of Model Architectures

In this part, we discuss several common score models and provide upper bounds on their Rademacher complexity.

**Linear Model**. One such model is the linear model, which is widely used in text retrieval tasks . It calculates scores by taking the dot product of user vectors and node vectors, which can be expressed as follows:

\[f_{}(,)=,},\]

where \(}\) is a learnable parameter for node \(v\) in the tree model. The function space \(_{}\) is expressed as follows:

\[_{}=\{f:(,), }\ |\ \|}\|_{2} B_{0},\  V\}.\] (7)

We have the following results:

**Theorem 4.5**.: _Suppose \( i[m],\|}\|_{2} B_{x}\), then the Rademacher complexity of \(_{_{}}\) can be bounded by_

\[}_{m}(_{_{}})B_{x}}{},\]

_where \(=BN/-1}\)._

**MLP**. We consider the concatenation of the user vector and the node vector as inputs to a multilayer perceptron (MLP). This architecture is widely used in the network structures of recommender systems , which can be expressed as follows:

\[f_{}(,)=}_{L-1}_{L-2} _{1}(;}),\]

where \(}^{1 d_{L-1}}\), \((;})^{2d}\) represents the concatenation of the column vectors \(\) and \(}\), the function \(_{k}()\) is defined:

\[_{k}()=(})^{d_{k}  1},\  k[L-1].\]

The function \(\) is a Lipschitz continuous activation function with a Lipschitz constant \(c_{}\), has the property \((0)=0\) and \(}^{d_{k} d_{k-1}}\) represents the weight matrix. For the function space:

\[_{}=f:(,) f_{}(,)\ |\ \ \|}\|_{2} B_{0},\  V;\|}\|_{1} B_{1}, k[L]},\] (8)

we have the following results:

**Theorem 4.6**.: _Suppose \( i[m],\|}\|_{2} B_{x}\), then the Rademacher complexity of \(_{_{}}\) can be bounded by_

\[}_{m}(_{_{}})^{L-1}B_{1}^{L}(B_{0}+B_{x})}{}.\]

**Target Attention**. As a deep neural network architecture, target attention has achieved competitive performance in recommender systems and is widely used as a score function in tree-structured recommendations. In contrast to the previous two models, which represent a user as a single embedding vector, the model characterizes the user representation by a history sequence of items they have interacted with. In this context, we denote the matrix of item embedding vectors that the \(i\)-th user has interacted with as \(^{(i)}\),

\[^{(i)}=[_{1}^{(i)},_{2}^{(i)},...,_{T}^{(i)}]^{d T},\]

where we consider the last \(T\) recorded item interaction histories. The model uses a two-layer fully connected network to compute weights for node vectors and user-history item vectors, which can be expressed as:

\[w_{k}^{(i)}=(_{w}^{(2)}(_{w}^{(1)}[ {a}_{k}^{(i)};_{k}^{(i)}_{};_{}]) ),\]

where \(_{w}^{(1)}^{h 3d},_{w}^{(2)}^{1  h}\), and \(\) is activation function. The score function can be expressed as:

\[f_{ta}(},)=f_{mlp}(_{1}^{(i)};_{2}^{(i)};...; _{N^{}}^{(i)};}),\]

where \( j[N^{}]\),

\[_{j}^{(i)}=_{k_{j}}w_{k}^{(i)}_{k}^{(i)},\]

\(_{j}\), corresponding to different time windows, each \(_{j}\) being mutually exclusive, satisfies the following conditions:

\[_{j=1}^{N^{}}_{j}=\{1,2,,T\}.\]

For the function space:

\[_{}=f:(,) f_{}(,)\|}\|_{2} B_{0},\; V;\] (9) \[\|}\|_{1} B_{1}, k[L];\;\|_{w}^{(j)} \|_{1} B_{2}, j\{1,2\}},\]

we have the following results:

**Theorem 4.7**.: _Suppose \( i[m], k[T],\|_{k}^{(i)}\|_{2} B_{a}\), then the Rademacher complexity of \(_{_{}}\) can be bounded by_

\[}_{m}(_{_{}})^{L-1}B_{1}^{L}(B_{w}T+B_{0})}{},\]

_where \(B_{w}=c_{}^{2}B_{2}^{2}(B_{a}^{2}+B_{a}^{2}B_{0}+B_{0}B_{a})\)._

#### 4.1.2 Insights from Generalization Bound

The theorems 4.5, 4.6, and 4.7, show the effect of three different score models on their generalization. More complex models tend to have higher function space complexity. From a generalization error perspective, this represents a tradeoff between function space complexity and empirical error, as they often result in lower empirical errors. We can see that, similar to most generalization conclusions derived from Rademacher complexity, the order of the number of sample points \(m\) is \((m^{-1/2})\). This implies that as the number of samples increases, the error rate can be effectively controlled by the empirical error, resulting in a performance on the test set that is as satisfactory as on the training set.

Besides, the theoretical results reveal a relationship between model generalization capabilities with tree structure retrievers. Specifically, the generalization bound includes a term \((B/-1})\), where \(B\) represents the number of branches, suggesting that a tree with a larger number of child nodes (branches) tends to exhibit enhanced generalization performance. Intuitively, a tree with more branches will have a flatter structure. In an extreme case, when the number of branches equals the number of items, the tree structure becomes ineffective because it requires traversing all items during inference. This leads to the highest computational complexity, as the retriever model degenerates intoa ranker model that processes the entire item pool. Thus, the number of branches of a tree structure represents, to some extent, a tradeoff between efficiency and performance.

We conduct experiments on real-world datasets to study the effects of increasing the number of tree branches. In our experiments, we use the same datasets as work , specifically Mind and Movie. We adopt an improved TDM model  as the retriever model architecture and use recall as the evaluation metric, since in the retrieval stage, the focus is on whether the target item is successfully retrieved. A more detailed description of the experimental setup can be found in Appendix D. The results are presented in Figure 1. As we can see, the recall rate increases with the number of branches. Similar phenomena can be observed in other studies related to tree models .

### Ranker

In the context of training data sets \(S=\{(},y_{1}),,(},y_{m})\}\) independently and identically distributed according to distribution \(\), where each \(}^{d}\) and \(y_{i}\{1,,N\}\), we examine a subset of this data, referred to as filtered training data, given by \(S^{}=\{(_{1}^{},y_{1}^{}),,(_{m^{}} ^{},y_{m^{}}^{})\} S\). We suppose this subset is independently and identically distributed, following the distribution \(^{}\), where each \(y_{i}^{}(_{i}^{})\). The generalization error of ranker \(_{}^{}\), is defined as the expected probability of the ranking error under the distribution \(^{}\). Specifically, we have

\[_{}^{}=_{(,y)^{ }}[(f(,y)-_{j()}f(,j)<0)],\]

where we use \(f(,j)\) to denote the model score of user \(\) with respect to item \(j\) in this subsection.

To establish a relationship between the expected generalization error on distribution \(^{}\) and the empirical error measured on training data distribution \(\), we have the following theorem:

**Theorem 4.8**.: _Consider a loss function \(()\) that is monotonically decreasing, satisfies \((x 0)()\), and is a Lipschitz function with Lipschitz constant \(c_{}\) and an upper bound \(B_{}\). The following inequality holds with a probability of at least \(1-\):_

\[_{}^{}_{(,y) }|1-(,y)}{P(,y)}|+_{}\,+4c_{}N(K+1)}_{m}(_{1}( ))+B_{}},\]

_where \(_{1}()=\{x f(,y):y,f\}\)\(P\) and \(P^{}\) denote the probability density functions of \(\) and \(^{}\), respectively, and \(_{}=_{i=1}^{m}(f(},y_{i})- _{j()}f(},j))\)._

Similar to Theorem 4.4, Theorem 4.8 presents a general result. As for the abstracted loss function \(_{}\,\), we can see that \(_{}\,_{}\,=_{i=1}^ {m}(f(},y_{i})-_{j}f(},j))\), where the latter, margin-based loss, is commonly used in training. This can also be extended to other common loss functions, as discussed similarly in the Appendix A. As for the Rademacher complexity of the function space, to maintain consistency with the previous subsection, we introduce the notation \(^{}\) to denote the restriction of the function space \(\) w.r.t. \(\), specifically:

\[^{}=\{f(,v):v\} .\]

For the score function described in the subsection 4.1.1, we have the following theorem:

Figure 1: Effect of branch number on Recall@20 for Mind (left) and Movie (right)

**Theorem 4.9**.: _Suppose the conditions in Theorems 4.5, 4.6, and 4.7 hold, the Rademacher complexity of \(_{1}(^{})\) can be bounded as follows:_

\[}_{m}(_{1}(^{}_{})) }}{},\]

_where \(B_{lin}=B_{0}B_{x}\), \(B_{mlp}=2c_{}^{L-1}B_{1}^{L}(B_{0}+B_{x})\), \(B_{ta}=c_{}^{L-1}B_{1}^{L}(B_{w}T+B_{0})\)._

Besides, compared to traditional generalization bounds, Theorem 4.8 includes an additional error term induced by distributional disparities. It shows that the generalization performance of the two-stage ranker model degrades due to discrepancies between the inference distribution and training distributions. When the training distribution is aligned with the inference distribution, i.e., using the subset of the training data successfully retrieved by the retriever, the distributional disparities are minimized. This suggests that in practice, aligning the training distribution and inference distribution can enhance the model's performance.

We conduct experiments on real-world datasets to verify this. In our experiments, we use the improved TDM  as the retriever, and the DIN model , which uses the target attention structure, as the ranker. We investigate the effect of the training data distribution on the ranker performance in a fixed retriever two-stage setup. The ranker model is trained in two ways: using the original training data and using a subset of training data successfully retrieved by the retriever model. A more detailed description of the experimental setup can be found in the Appendix D. We evaluate the overall classification accuracy of the two-stage model. The results are presented in Table 1. We compared the top-1 classification accuracy (i.e., Precsion@1) of rankings produced by the ranker with different numbers of retrieval items for two methods. We can see that the Harmonized Two Stage Model (H-TS) improves performance over the original Two Stage Model (TS) on these datasets.

It is worth noting that while aligning the training distribution to the inference distribution eliminates the bias introduced by the distribution differences, it reduces the number of training samples available \(m^{}\) relative to the original number of samples \(m\). This reduction means that the upper bound of the generalization guarantee is also somewhat weakened. Consequently, the effectiveness of this adjustment method depends on the presence of a high recall retriever model. In our experiments, we found that a recall rate of more than \(10\%\) is typically required to see an improvement effect. It must ensure that there are enough training samples to maintain the generalization performance of the model.

## 5 Conclusion

In summary, our study provides a theoretical and empirical investigation into the generalization error bounds of two-stage recommender systems, particularly emphasizing tree-based retriever models. Our study uses Rademacher complexity to analyze the generalization capabilities of several commonly used models in two-stage recommender systems, highlighting how tree models with increased branches and ranker models trained on shifted distributions can affect generalization performance. The theoretical results show that as the number of branches in the tree increases, the model tends to exhibit improved generalization capabilities, effectively balancing efficiency and accuracy. In the presence of a high recall retriever model, using a harmonized distributions to train the ranker will improve performance. Furthermore, our experimental validation on real-world datasets with advanced models for both retriever and ranker stages corroborates the theoretical insights. This study deepens the understanding of generalization in tree-based two-stage models and provides a theoretical foundation for designing more effective models in two-stage recommender systems.

  Dataset & Method & K=40 & K=80 & K=120 \\   & TS & 0.6500 & 0.5970 & 0.5609 \\  & H-TS & **0.6565** & **0.6026** & **0.5644** \\   & TS & 0.3516 & 0.3457 & 0.3453 \\  & H-TS & **0.3555** & **0.3500** & **0.3488** \\  

Table 1: Comparison of classification accuracy of the two-stage model.