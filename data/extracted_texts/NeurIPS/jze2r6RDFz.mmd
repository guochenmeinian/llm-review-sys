# Generalized test utilities for long-tail performance in extreme multi-label classification

Erik Schultheis

Aalto University

Helsinki, Finland

erik.schultheis@aalto.fi

&Marek Wydmuch

Poznan University of Technology

Poznan, Poland

mwydmuch@cs.put.poznan.pl

Wojciech Kotlowski

Poznan University of Technology

Poznan, Poland

wkotlowski@cs.put.poznan.pl

&Rohit Babbar

University of Bath / Aalto University

Bath, UK / Helsinki, Finland

rb2608@bath.ac.uk

Krzysztof Dembczynski

Yahoo! Research / Poznan University of Technology

New York, USA / Poznan, Poland

krzysztof.dembczynski@yahooinc.com

###### Abstract

Extreme multi-label classification (XMLC) is the task of selecting a small subset of relevant labels from a very large set of possible labels. As such, it is characterized by long-tail labels, i.e., most labels have very few positive instances. With standard performance measures such as precision@k, a classifier can ignore tail labels and still report good performance. However, it is often argued that correct predictions in the tail are more "interesting" or "rewarding," but the community has not yet settled on a metric capturing this intuitive concept. The existing propensity-scored metrics fall short on this goal by confounding the problems of long-tail and missing labels. In this paper, we analyze generalized metrics budgeted "at k" as an alternative solution. To tackle the challenging problem of optimizing these metrics, we formulate it in the _expected test utility_ (ETU) framework, which aims to optimize the expected performance on a fixed test set. We derive optimal prediction rules and construct computationally efficient approximations with provable regret guarantees and robustness against model misspecification. Our algorithm, based on block coordinate ascent, scales effortlessly to XMLC problems and obtains promising results in terms of long-tail performance.

## 1 Introduction

Extreme multi-label classification (XMLC) is a challenging task with a wide spectrum of real-life applications, such as tagging of text documents , content annotation for multimedia search , or different type of recommendation . Because of the nature of its applications, the typical approach in XMLC is to predict exactly \(k\) labels (e.g., corresponding to \(k\) slots in the user interface) which optimize a standard performance metric such as precision or (normalized) discounted cumulative gain. Given the enormous number of labels in XMLC tasks, which can reach millions or more, it is not surprising that many of them are very sparse, and hence make the label distribution strongly long-tailed . It has been noticed that algorithms can achieve high performance on the standard metrics, but never predict any tail labels . Therefore, there is a need to developa metric that prefers "rewarding" , "diverse" , and "rare and informative"  labels over frequently-occurring head labels. Currently, the XMLC community attempts to capture this need using _propensity-scored_ performance metrics . These metrics give increased weight to tail labels, but have been derived from the perspective of missing labels, and as such they are not really solving the problem of tail labels .

In Table 1 we compare different metrics for budgeted at \(k\) predictions. We train a PLT model  on the full AmazonCat-13K dataset  and a reduced version with the \(1000\) most popular labels only. The test is performed for both models on the full set of labels. The standard metrics are only slightly perturbed by reducing the label space to the head labels. This holds even for propensity-scored precision, which decreases by just 1%-20% despite discarding over 90% of the label space. In contrast, macro measures and coverage decrease between 60% and 90% if tail labels are ignored. These results show that budgeted-at-\(k\) macro measures might be very attractive in the context of long tails. Macro-averaging treats all the labels equally important, preventing the labels with a small number of positive examples to be ignored. Furthermore, the budget of \(k\) labels "requires" the presence of long-tail labels in a compact set of predicted labels.

While we can easily use these measures to evaluate and compare different methods, we also would like to make predictions that directly optimize these metrics. The existing approaches to macro-averaged metrics consider the unconstrained case, in which label-wise optimization is possible . Each binary problem can be then solved under one of two frameworks for optimizing complex performance measures, namely _population utility_ (PU) or _expected test utility_ (ETU) . The former aims at optimizing the performance on the population level. The latter optimizes the performance directly on a given test set. Interestingly, in both frameworks the optimal solution is based on thresholding conditional label probabilities , but the resulting thresholds are different with the discrepancy diminishing with the size of the test set. The threshold tuning for PU is usually performed on a validation set , while the exact optimization for ETU is performed on a test set. It requires cubic time in a general case and quadratic time in some special cases . Approximate solutions can be obtained in linear time .

These approaches cannot be directly applied if prediction of exactly \(k\) labels for each instance is required. In such case, the optimization problems for different labels are tightly coupled through this constraint, making the final problem much more difficult. Despite the fact that optimization of complex performance metrics is a well-established problem, considered not only in binary and multi-label classification as discussed above, but also in multi-class classification , the results presented in this paper go beyond the state-of-the-art as budgeted-at-\(k\) predictions have not yet been analyzed in this context. Let us underline that the requirement of \(k\) predictions is natural for recommendation systems, in which exactly \(k\) slots are available in the user interface to display recommendations. Even in situations where this does not apply, requiring the prediction to be "at \(k\)" can be advantageous, as it prevents trivial solutions such as predicting nothing (for precision) or everything (for recall).

In this paper, we investigate optimal solutions for the class of utility functions that can be linearly decomposed over labels into binary utilities, which includes both instance-wise weighted measures and macro-averages. We solve the problem in the ETU framework which is well-suited, for example, to recommendation tasks in which recommendations for all users or items are rebuilt in regular intervals. In this case, we can first obtain probability estimates of individual labels for each instance in the test set, and then provide optimal predictions for a given metric based on these estimates. We

   Metric &  &  \\  & @1 & @3 & @5 & @1 (diff.) & @3 (diff.) & @5 (diff.) \\  Precision & 93.03 & 78.51 & 63.74 & 93.08 (+0.05\%) & 76.42 (2.66\%) & 58.21 (-8.67\%) \\ nDCG & 93.03 & 87.25 & 85.35 & 93.08 (+0.05\%) & 85.75 (-1.71\%) & 80.91 (-5.19\%) \\ PS-Precision & 49.76 & 62.63 & 70.35 & 49.07 (-1.39\%) & 57.71 (-7.84\%) & 57.41 (-18.40\%) \\  Macro-Precision & 13.28 & 32.65 & 44.16 & 4.31 (-67.54\%) & 5.28 (-83.82\%) & 4.32 (-90.21\%) \\ Macro-Recall & 1.38 & 11.06 & 30.57 & 0.47 (-65.61\%) & 2.69 (-75.71\%) & 4.10 (-86.99\%) \\ Macro-F1 & 2.26 & 14.67 & 32.84 & 0.74 (-67.37\%) & 3.10 (-78.88\%) & 3.77 (-88.51\%) \\ Coverage & 15.19 & 40.53 & 60.88 & 5.11 (-66.32\%) & 7.37 (-81.82\%) & 7.52 (-87.65\%) \\   

Table 1: Performance measures (%) on AmazonCat-13k of a classifier trained on the full set of labels and a classifier trained with only 1k head labels.

derive optimal prediction rules and construct computationally efficient approximations with provable guarantees, formally quantifying the influence of the estimation error of the label probabilities on the suboptimality of the resulting classifier. This result is expressed in the form of a regret bound [4; 30; 22; 13]. It turns out that for most metrics of interest, a small estimation error results in at most a small drop of the performance, which confirms our method is viable for applications. Our general algorithm, based on block coordinate ascent, scales effortlessly to XMLC problems and obtains promising empirical results.

## 2 Setup and notation

Let \(\) denote an input instance, and \(\{0,1\}^{m}\) the vector indicating the relevant labels, distributed according to \((|)\). We consider the prediction problem in the _expected test utility_ (ETU) framework, that is, we assume that we are given a known set of \(n\) instances \(=[_{1},,_{n}]^{}^{n}\) with unknown labels, on which we have to make predictions.1 Our goal is to assign each instance \(_{i}\) a set of exactly \(k\) (out of \(m\)) labels represented as a \(k\)-hot vector \(}_{i}_{k}\{:~{}\| \|_{1}=k\}\), and we let \(}=[}_{1},,}_{n}]^{}\) denote the entire \(n m\) prediction matrix for a set of instances \(\).

In the ETU framework, we treat \(\) as given and only make an assumption about the labeling process for the test sample: the labels \(_{i}\) corresponding to \(_{i}\) do not depend on any other instances, that is \((|)=_{i=1}^{n}(_{i}|_{i})\), where we use \(=[_{1},,_{n}]^{}^{m}\) to denote the entire label matrix. We assume the quality of predictions \(}\) is jointly evaluated against the observed labels \(\) by a _task utility_\((,})\), and define the _optimal (Bayes) prediction_\(}^{}\) as the one maximizing the _expected task utility_\(_{}\):

\[}^{}=*{argmax}_{^{n}_{ }}_{|}[(,})] *{argmax}_{^{n}_{}}_{}(})\,. \]

We consider task utilities \((,})\) that linearly decompose over labels, i.e., there exists \(^{j}\) such that

\[(,})=_{j=1}^{m}^{j}(_{:j},}_{:j} )\,. \]

We allow the functions \(^{j}\) to be non-linear themselves and different for each label \(j\). This is a large class of functions, which encompasses weighted instance-wise and macro-averaged utilities, the two groups of functions which we thoroughly analyze in the next sections.

Let us next define the binary confusion matrix \((,})\) for a vector \(\) of \(n\) ground truth labels and a corresponding vector \(}\) of binary predictions:

\[(,})(_{i=1}^{n}(1-y _{i})(1-_{i})}{_{i=1}^{n}y_{i}(1-_{i})}_{i=1}^{n}(1-y_{i})_{i}}{_{i=1}^{n}y_{i} y_{i}})\,. \]

By indexing from 0, the entry \(c_{00}\) corresponds to true negatives, \(c_{01}\) to false positives, \(c_{10}\) to false negatives, and \(c_{11}\) to true positives.We define the _multi-label confusion tensor2\(}(,}):=[(_{:1},}_{:1} ),,(_{:m},}_{:m})]\)_ being the concatenation of binary confusion matrices of all \(m\) labels.

Assuming the utility function (2) to be invariant under instance reordering, i.e., its value does not change if rows of both matrices are re-ordered using the same permutation, we can define \(\) in terms of confusion matrices, instead of ground-truth labels and predictions (shown in Appendix A.1):

\[(,})=(}(,}))=_{j=1}^ {m}^{j}((_{:j},}_{:j}))\,. \]

Finally, we assume that we have access to a _label probability estimator (LPE)_\(}()\) that estimates the marginal probability of each label given the instance, \(()=(_{1}(),,_{m}())_{|}[]\). Such an LPE can be attained by fitting a model on an additional training set of \(n^{}\) examples \((_{i},_{i})_{i=1}^{n^{}}\) using a proper composite loss function , which is a common approach in XMLC, e.g., .

Performance measures for tail labels

### Instance-wise weighted utility functions

By assigning utility (or cost) to each correct/wrong prediction for each label, we can construct an _instance-wise weighted utility_\(u_{}_{  0}\) with labels \(\) and predictions \(}\) as

\[u_{}(,})=_{j=1}^{m}w_{00}^{j}(1 -y_{j})(1-_{j})+w_{01}^{j}(1-y_{j})_{j}+w_{10}^{j}y_{j}(1-_{j})+w_{11}^{j}y_{j}_{j}\,. \]

We use \(w_{00}^{j}\), \(w_{01}^{j}\), \(w_{10}^{j}\), and \(w_{11}^{j}\) to express the utility of true negatives, false positives, false negatives, and true positives, respectively. The corresponding task loss results from summing over all instances. By interchanging the order of summation, we can see that it is of form (4):

\[(,})=_{i=1}^{n}u_{}( _{i},}_{i})=_{j=1}^{m}w_{00}^{j}c_{00}^{ j}+w_{01}^{j}c_{01}^{j}+w_{10}^{j}c_{10}^{j}+w_{11}^{j}c_{11}^{j}=_{j=1}^{m} \!^{j}((_{ j},}_{ j }))\,. \]

In other words, the instance-wise weighted utilities can be seen as _linear_ confusion-based metrics. By choosing \(w_{00}^{j}=w_{11}^{j}=m^{-1}\) and \(w_{01}^{j}=w_{10}^{j}=0\), the expression (5) reduces to the \(@k\)-variant of the _Hamming utility_. Similarly, \(w_{11}^{j}=k^{-1}\) and \(w_{00}^{j}=w_{01}^{j}=w_{10}^{j}=0\) yield precision\(@k\).

Another example is the popular _propensity-scoring_ approach , commonly used as a tail-performance metric in XMLC. Here, the weights are computed based on training data through

\[w_{11}^{j,}=k^{-1}(1+( n^{}-1)(b+1)^{a}(n^{} _{j}+b)^{-a}), \]

where \(n^{}\) is the number of training instances, \(_{j}\) is the empirical prior of label \(j\), and parameters \(a\) and \(b\) are (potentially) dataset-dependent. This form of weighting has been derived from a missing-labels perspective, so its application to tail labels is not fully justified . Also, it introduces two more hyperparameters, which makes the interpretation and comparison of its values rather difficult. It is not less heuristical than other approaches like power-law or logarithmic weighting, given by:

\[w_{11}^{j,}_{j}^{-}, w_{11}^{j,} -(_{j})\,. \]

### Macro-average of non-decomposable utilities

Macro-averaging usually concerns non-decomposable binary utilities such as the F-measure. In this case, we set up \(^{j}(,)=m^{-1}(,)\) for all labels \(j\) in (2), yielding:

\[(,})=m^{-1}_{j=1}^{m}( _{ j},}_{ j})=m^{-1}_{j=1}^{m} ((_{ j},}_{ j}) )\,. \]

By using \(_{}() c_{11}/(c_{11}+c_{01})\), this becomes _macro-precision_, for \(_{}() c_{11}/(c_{11}+c_{10})\) we get _macro-recall_, and for \(_{_{}}()(+1)c_{11}/((1+)c _{11}+^{2}c_{10}+c_{01})\) the _macro-F-measure_.

Another measure that is promising for the evaluation of long-tailed performance is _coverage_. It is sometimes used as an auxiliary measure in XMLC . This metric detects for how many different labels the classifier is able to make _at least one_ correct prediction. In our framework, this is achieved by using an indicator function on the true positives, \(_{}()[c_{11}>0]\).

## 4 Optimal predictions

Let us start with the observation that the label probabilities \(\) are sufficient to make optimal predictions. With the assumption that \((|)=_{i=1}^{n}( _{i}|_{i})\), we obtain (cf. Appendix A.2):

\[_{|}[(,})]=_{j=1}^{m}_{^{}\{0,1\}^{n}} _{i=1}^{n}_{j}(_{i})y_{i}^{}+(1-_{j}( _{i}))(1-y_{i}^{})^{j}(^{ },}_{ j})\,. \]

This equation lays out a daunting optimization task, as is requires summing over \(2^{n}\) summands \(^{}\). In case of binary classification, there exist methods to solve the problem exactly in \((n^{3})\), or in \((n^{2})\)in some special cases . By using _semi-empirical_ quantities (defined below),  provides an approximate algorithm that runs in \(O(n)\). Following this approach, we construct a semi-empirical ETU approximation. If this approximation results in a _linear_ function of the predictions, the problem decomposes over instances and can be solved easily. Otherwise, we use an algorithm that leads to locally optimal predictions. A minor modification of this algorithm can be used for coverage.

### Semi-empirical ETU approximation

Since the entries of the confusion matrix are linearly dependent, it suffices to use three independent combinations. More precisely, we parameterize the confusion matrix by the true positives \(t=c_{11}\), predicted positives \(q=c_{11}+c_{01}\), and ground-truth positives \(p=c_{11}+c_{10}\), and use \(=(t_{1},,t_{m})\), \(=(q_{1},,q_{m})\), and \(=(p_{1},,p_{m})\) to reformulate the ETU objective:

\[_{}(})=_{|}[( (,}))]=_{|}[(,,)]=_{|}_{j=1}^{m}^{j}(t_{j},q_{j},p_{j })\,. \]

In order to compute \(_{}\), one needs to take into account every possible combination of confusion-matrix values, and calculate the corresponding value of \(\), which is then averaged according to the respective probabilities. A computationally easier approach is to take the expectation over the labels first, leading to _semi-empirical_ quantities:

\[}_{|}[]\,, }_{|}[]=\,,}_{|}[]\,, \]

where \(}=\) follows because the number of predicted positives depends only on the predictions \(}\). This allows us to define the semi-empirical ETU risk

\[_{}(})(},, })_{|}[(,,)]= _{}(})\,. \]

In particular, the third argument to \(\), \(}\), is a constant that does not depend on predictions.

Note that, if \(\) is _linear_ in all arguments _depending on the random variable \(\)_, then the approximation is exact, due to the linearity of expectations. Aside from instance-wise measures, which we showed to be linear above, the approximation is also exact for the more general class of functions of the form

\[(t,q,p)=f_{}(q) t+f_{}(q)+f_{}(q) p\,. \]

An important example is macro-precision, with \(f_{}(q)=q^{-1}\) and \(f_{}=f_{}=0\). In the general case, \(_{}\) as a surrogate for \(_{}\) leads only to \((1/)\) error as will be shown in Theorem 5.2, while substantially simplifying the optimization process.

### Linear confusion-matrix measures

We start the discussion on optimization of (13) with a special case in which \(_{}\) is _linear in the prediction-dependent arguments_\(t,q\), that is, if

\[(t,q,p)=f_{}(p) t+f_{}(p) q\,, \]

i.e., both \(f_{}(p)\) and \(f_{}(p)\) depend on \(p\) only, and \(f_{}(p) p\) can be dropped as it is a constant.

Aside from instance-wise weighted utilities (cf. Appendix A.3), which are linear in all arguments, this form also holds for weights dependent on the (empirical) label priors, e.g., power law weights of the form \(f_{}(p)=p^{-}\) and \(f_{}=0\), which reduce to macro-recall for \(=1\). If one defines the weights with respect to externally determined label priors, i.e., approximations to \([y_{j}]\), which are fixed and thus independent of the test sample \(\), then the power-law metrics turn into instance-wise weighted utilities.

From (6) we know that we can reformulate the optimization problem using an instance-wise weighted utility \(u_{}\) with weights:

\[w_{11}^{j}=f_{}(p_{j})+f_{}(p_{j})\,, w_{01}^{j}=f_{ {q}}(p_{j})\,, w_{10}^{j}=0\,, w_{00}^{j}=0\,. \]

Hence, the optimal predictions can be derived for each instance \(\) separately, leading to

\[}^{*}=*{argmax}_{}_{k}} _{|}[u_{}(,})]. \]

Plugging in the definition of \(u_{}\) from (5), and collecting terms, the expected loss is of the form

\[_{|}[u_{}(,})]=_{j=1}^{m} _{|}w_{11}^{j}y_{j}_{j}+w_{01}^{j}(1-y_{j} )_{j}=_{j=1}^{m}_{j}(_{j}()f_{ }(p_{j})+f_{}(p_{j}))\,, \]

[MISSING_PAGE_FAIL:6]

### Optimization of coverage

One measure for which the ETU approximation is not exact is coverage as \(_{}(t,q,p)[t>0]\) is _nonlinear_. In this case, we can do better than Algorithm 1, by reformulating \(_{}\) for coverage as

\[_{}(})=_{}m^{-1}_ {j=1}^{m}[t_{j}>0]=1-m^{-1}_{j=1}^{m}_{i=1}^{n}( 1-_{j}(_{i})_{ij})\,, \]

and performing block coordinate ascent directly on this expression, as detailed in Appendix B.3.

## 5 Regret bounds

Computing optimal predictions relies on an access to the conditional marginal probabilities \(()\). In practice, however, \(()\) are unknown, and are replaced by the LPE \(}()\) to do inference (_plug-in_ approach). Furthermore, we replaced the ETU objective \(_{}\) with an approximation \(_{}\). As generally \(}()()\) and \(_{}_{}\), this procedure may result in sub-optimal predictions, the errors of which we would like to control.

If we are able to control the change of the utility under small changes in its arguments, we can show that the suboptimality of the plug-in predictor relative to the optimal predictor (called _\(\)-regret_) decreases with increasing test size \(n\) and decreasing probability estimation error.

To this end we assume that each \(^{j}\) is a _\(p\)-Lipschitz_ function, which allows us to bound the approximation error.

**Definition 5.1** (\(p\)-Lipschitz ).: A binary classification metric \((t,q,p)\) is said to be \(p\)-Lipschitz if

\[|(t,q,p)-(t^{},q^{},p^{})| L_{}(p)|t-t ^{}|+L_{}(p)|q-q^{}|+L_{}(p)|p-p^{}|, \]

for any \(q,q^{}\), \(p,p^{}(0,1)\), \(0 t(p,q)\), and \(0 t^{}(p^{},q^{})\). The constants \(L_{}(p),L_{}(p),L_{}(p)\) are allowed to depend on \(p\), in contrast to the standard Lipschitz functions.

As shown in Appendix C.3, most of metrics of interest satisfy \(p\)-Lipschitz assumption, including the linear confusion-matrix measures (6) with fixed weights (e.g., Hamming utility, precision), macro-recall, macro-F-measure, etc., with macro-precision and coverage being notable exceptions.

**Theorem 5.2**.: _Let each \(^{j}\) be \(p\)-Lipschitz with constants \(L_{}^{j}(p),L_{}^{j}(p),L_{}^{j}(p)\). For any \(}\) it holds:_

\[|_{}(};)-_{}( };)|}(_{j=1}^{m}(L_{}^{j}( _{j})+L_{}^{j}(_{j})))\,. \]

Thus, using \(_{}\) as a surrogate for \(_{}\) leads only to \((1/)\) error, diminishing with the test size, while substantially simplifying the optimization process.

Given a decomposable metric of the form (4), let \(}^{}\) be the plug-in prediction matrix optimizing the semi-empirical ETU with plugged-in probability estimates, \(_{}()}[],, _{}()}[]\).

**Theorem 5.3**.: _Let \(}^{}\) be defined as above. Under the assumptions of Theorem 5.2:_

\[_{}(}^{};)-_{}}^{};}B+2}{n}B_{ i=1}^{n}\|(_{i})-}(_{i})\|_{2}, \]

_where \(B_{j=1}^{m}(L_{}^{j}(_{j})+L_{ }^{j}(p_{j}))^{2}}\) is the quadratic mean of the Lipschitz constants._

A similar statement, presented in Appendix C.4, can be made for the unapproximated ETU case.

Thus, the methods described in Section 4 can be used with probability estimates replacing the true marginals, and as long as the estimator is reliable, the resulting predictions will have small \(\)-regret. This also justifies the plug-in approach used in the experiments in Section 7.

## 6 Efficient inference

The optimization algorithms introduced so far need to obtain \(_{j}(_{i})\) for _all_ labels and instances first. Then, the BCA inference is of \((nm)\) time and \((nm)\) space complexity for a single iteration. Thisis problematic in the setting of XMLC, where many methods aim to predict probabilities only for top labels in time sublinear in \(m\). Fortunately, this characteristic of XMLC algorithms can be combined with the introduced algorithms to efficiently obtain an approximate solution. Instead of predicting all \(\), we can predict probabilities only for top-\(k^{}\) labels with highest \(_{j}\), where \(k k^{} m\). For all other labels we then assume \(_{j}=0\). Under the natural assumption that \(\) is _non-decreasing_ in true positives and _non-increasing_ in predicted positives, we can leverage the sparsity and consider labels with non-zero \(_{j}\) only (using sparse vectors to represent \(}(_{i})\)) to reduce the time and space complexity to \((n(k^{}+k k))\) and \((n(k^{}+k))\), respectively. As in real-world datasets the number of relevant labels \(\|\|_{1}\) is much lower than \(m\), and most \(_{j}(_{i})\) are close to 0, with reasonably selected \(k^{}\), according to Theorem 5.3, we should only slightly increase the regret. A pseudocode for the sparse variant of Algorithm 1 can be found in Appendix D.

Alternatively, we can leverage probabilistic label trees (PLTs) , a popular approach in XMLC [35; 45; 19; 50; 7], to efficiently search for "interesting" labels. Originally, PLTs find top labels with the highest \(_{j}\). In , an \(A^{*}\)-search algorithm has been introduced for finding \(k\) labels with highest value of \(g_{j}_{j}()\), where \(g_{j}[0,)\) is a gain assigned to label \(j\). In Appendix F, we present a more general version of this procedure that can be used to efficiently obtain an exact solution of presented BCA or Greedy algorithms for some of the metrics considered in this work.

## 7 Experiments

To empirically test the introduced framework, we use popular benchmarks from the XMLC repository . We train the LightXML  model (with suggested default hyper-parameters) on provided training sets to obtain \(}\) for all test instances. We then plug these estimates into different inference strategies and report the results across the discussed measures. To run the optimization algorithm efficiently, we use \(k^{}=100\) or \(k^{}=1000\) to pre-select for each instance the top \(k^{}\) labels with the highest \(_{j}\) as described in Section 6.3

We use the following inference strategies:

* Top-K- the optimal strategy for precision\(@k\): selection of \(k\) labels with the highest \(_{j}\) (default prediction strategy in many XMLC methods).
* PS-K- the optimal strategy for propensity-scored precision\(@k\): selection of \(k\) labels with the highest \(w_{11}^{j,}_{j}\), with \(w_{11}^{j,}\) given by the empirical model of Jain et al.  (Equation 7) with values \(a\) and \(b\) recommended by the authors.
* Pow-K, Log-K- the optimal strategy for power-law and log weighted instance-wise utilities: selection of \(k\) labels with the highest \(w_{11}^{j,}_{j}\) or \(w_{11}^{j,}_{j}\). For power-law, we use \(=0.5\).
* Macro-P\({}_{}\), Macro-R\({}_{}\), Macro-F\({}_{}\), Co\({}_{}\)- the block coordinate ascent (Algorithm 1) for optimizing macro-precision, -recall, -F1, and coverage,

We expect a strategy suited for a given metric to obtain the best results on this metric. Nevertheless, this might not always be the case, as in the derivation of our algorithms, we needed to apply different types of approximation to scale them to XMLC problems. We are mainly interested in the performance on the general non-decomposable macro measures since they seem to be well-tailored to long tails, and their optimization is the most challenging. The results are presented in Table 2. Notice that in almost all cases, the specialized inference strategies are indeed the best on the measure they aim to optimize and achieve substantial gains on corresponding metrics compared to the basic Top-K inference. The other weighted strategies, PS-K, Pow-K, Log-K, usually provide a much smaller improvement over Top-K and never beat strategies designed for specific macro measures. As the reported performance depends on three things: the inherent difficulty of the data, the success of the inference algorithm, and the quality of the provided

Figure 1: Results of an inference strategy with a mixed utility on AmazonCat-13K and \(k=3\). The green line shows the results for different interpolations between two measures.

marginal probabilities, the results might diverge from expectations in some cases. In Appendix E, we provide more details and conduct further experiments to investigate the impact of randomness, stopping conditions, quality of probability estimates, and shortlisting on the results. We also present similar experiments with probabilistic label trees used as an LPE.

Unfortunately, our results show that optimization of macro-measures comes with the cost of a significant drop in performance on instance-wise measures. Ideally, we would like to improve the performance on tail labels without sacrificing too much of general performance. To achieve such a trade-off, we can use straight-forward interpolation of instance-wise precision-at-k, as it is covered by our framework, and a selected macro-measure, since the considered class of utility functions is closed under linear combinations. Such an objective can be optimized by the proposed block-coordinate algorithm without any modification. As an example, we plot in Table 7 the results of optimizing a linear combination of instance-wise precision and the macro-F1 measure: \((,})=(1-)_{}(, })+_{}(,})\), using different values of \(\). In Appendix E.5, we provide more plots for different utilities, datasets, and values of \(k\). All the plots show that the instance-vs-macro curve has a nice concave shape that dominates simple baselines. In particular, the initial significant improvement on macro-measures comes with a minor drop in instance-measures, and only if one wants to optimize more strongly for macro-measures, the drop on instance-wise measures becomes more severe.

   Inference & Instance & \(\#3\) &  &  &  &  &  \\ strategy & P & R & P & R & F1 & Cov & P & R & P & R & F1 & Cov & P & R & F1 & Cov \\   \\  Tor-K & **57.240** & **44.21** & 24.85 & 16.45 & 18.63 & 31.27 & **6.231** & **40.89** & 27.43 & 25.99 & 25.50 & 39.76 & **39.22** & **75.11** & 22.15 & 36.59 & 26.01 & 47.55 \\ PS-K & 69.01 & 41.06 & 30.12 & 23.72 & 25.08 & 40.29 & 60.77 & 59.17 & 29.10 & 29.89 & 28.17 & 44.03 & 38.98 & 74.54 & 21.36 & 38.27 & 25.78 & 49.47 \\ Pow-K & 66.35 & 38.95 & 34.09 & **23.62** & 25.92 & 42.94 & 61.11 & 58.53 & 71.01 & 28.88 & 37.25 & 28.53 & 45.48 & 34.76 & 36.07 & 20.77 & **38.85** & 25.43 & 50.33 \\ Lo-K & 71.03 & 42.09 & 30.24 & 23.90 & 22.10 & 21.20 & 37.99 & 51.97 & 53.91 & 53.82 & 28.48 & 27.76 & 22.32 & 42.06 & 27.40 & 26.00 & 37.92 & 25.83 & 48.61 \\  Macro-P\({}_{}\) & 41.13 & 24.29 & **38.78** & 16.77 & 27.63 & 20.63 & 40.60 & 31.05 & 30.33 & **38.70** & 18.46 & 21.59 & 41.66 & 18.45 & 35.65 & **23.94** & 20.28 & 21.82 & 42.89 \\ Macro-Rec\({}_{}\) & 41.47 & 24.61 & 30.36 & 22.56 & 24.37 & 3.48 & 32.82 & 37.54 & 28.97 & 32.77 & 27.05 & 49.04 & 29.80 & 57.88 & 22.19 & 38.84 & 25.99 & 52.17 \\ Macro-F1\({}_{}\) & 41.96 & 30.44 & 24.51 & 23.78 & 44.72 & 36.18 & 54.04 & 17.82 & 39.52 & **30.18** & 45.13 & 35.49 & 24.29 & 27.32 & **12.04** & 44.77 & 37.56 \\ Cov\({}_{}\) & 24.00 & 14.03 & 31.46 & 21.30 & 19.05 & **47.19** & 16.40 & 15.95 & 29.86 & 24.53 & 18.81 & **50.09** & 9.31 & 18.05 & 26.99 & 28.28 & 17.41 & **52.84** \\   \\  Tor-K & **58.10** & **43.01** & 25.71 & 11.37 & 13.83 & 33.05 & **6.881** & **79.21** & 33.92 & 31.34 & 28.28 & 52.60 & **41.27** & **89.41** & 24.63 & 51.76 & 28.84 & 68.61 \\ PS-K & 79.09 & 60.15 & 43.89 & 38.64 & 38.56 & 62.06 & 66.63 & _77.89_ & 38.41 & 45.00 & 38.34 & 65.82 & 47.50 & 89.11 & 22.56 & 58.69 & 28.59 & 74.29 \\ Pow-K & 66.25 & 50.75 & 38.18 & 46.42 & 39.26 & 67.06 & 59.64 & 38.14 & 31.56 & 54.06 & 36.70 & 19.55 & 36.37 & 39.12 & 66.06 & 46.29 & 27.27 \\ Lo-K & 75.30 & 56.79 & 41.93 & 39.22 & 56.06 & 56.47 & 52.17 & 34.40 & 36.78 & 66.71 & 68.41 & 40.66 & 88.05 & 20.39 & 55.85 & 28.91 & 73.37 \\  Macro-P\({}_{}\) & 54.97 & 41.61 & **64.27** & 29.22 & 37.56 & 76.18 & 41.53 & 49.66 & **43.81** & 30.43 & 35.99 & 76.25 & 25.32 & 57.33 & **61.84** & 33.06 & 36.08 & 78.17 \\ Macro-Rec\({}_{}\) & 47.74 & 37.11 & **43.10** & **48.82** & 34.68 & 80.87 & 38.93 & 48.26 & 25.17 & **26.87** & 33.27 & 25.97 & 26.50 & 61.99 & 17.35 & **22.83** & 23.24 & **84.84** \\ Macro-Rec\({}_{}\) & 70.61 & 53.86 & 51.95 & 42.22 & 42.87 & 87.03 & 70.91 & 52.32 & **32.08** & **29.63** & 76.33 & 28.24 & 49.51 & 35.17 & **29.81** & 81.39 \\ Cov\({}_{}\) & 4.53 & 2.29 & 34.93 & 35.16 & 15.91 & **28.70** & 3.20 & 2.63 & 29.40 & 30.95 & 14.23 & **54.30** & 21.13 & 3.36 & 19.02 & 44.28 & 10.74 & **85.40** \\   \\  Tor-K & **57.17** & **13.48** & 2.01 & 0.50 & 0.72 & 2.54 & **68.81** & **19.99** & 2.66 & 0.92 & 1.42 & 3.72 & **23.00** & **29.05** & 3.55 & 2.07 & 2.34 & 6.14 \\ PS-K & _67.95_ & _11.89_ & 3.89 & 1.47 & 1.93 & 47.62 & _1.687_ & _4.25_ & _1.807_ & 4.21 & 2.14 & 2.56 & 6.54 & 30.16 & 28.20 & 4.64 & 3.62 & 3.61 & 9.01 \\ Pow-K & _55.96_ & 9.59 & 4.49 & 2.14 & 2.59 & 6.98 & 50.12 & 1.40 & 4.83 & 3.17 & 3.87 & 5.03 & 21.27 & 25.07 & 5.00 & 3.16 & 4.47 & 1.37 \\ Lo-K & 65.20 & 11.34 & 3.40 & 1.24 & 1.66 & 4.84 & 57.74 & 16.49 & 3.74 & 1.86 & 2.25 & 5.99 & 4.32 & 24.37 & 4.24 & 3.46 & 3.37 & 8.61 \\  Macro-P\({}_{}\) & 32.36 & 5.66 & **43.23** & 3.58 & 3.81 & 32.5 & 3.86 & **9.88** & 2.86 & 3.74 & 9.82 & 2.41 & 13.62 & **0.79** & 2.98 & 3.04 \\ Macro-Rec\({}_{}\) & 13.78 & 2.

## 8 Discussion

The advantage of the ETU framework is that one can use multiple inference strategies without re-training a model. This is especially useful in cases where it is not a-priori clear which performance measure should be optimized, or predictions for different purposes are needed at the same time. On the other hand, as this framework optimizes the performance directly on a given test set, it is not designed to make predictions for single instances independently. The ETU framework has mainly been studied in the case of binary classification problems. We are not aware of any work that focuses on optimizing the complex performance metrics in the ETU framework for multi-label classification. One could try to generalize the results from binary classification, but the existing algorithms might not scale well to the extreme number of labels and they do not take the budget of \(k\) labels into account.

Our paper gives novel and non-trivial results regarding this challenging optimization problem. We have thoroughly analyzed the ETU framework for a wide class of performance metrics, derived optimal prediction rules and constructed their computationally efficient approximations with provable regret guarantees and being robust against model misspecification. Our algorithm, based on block coordinate descent, scales effortlessly to XMLC problems and obtains promising empirical results.

Overall, we identified four categories of utilities, that differ in the complexity of the optimization algorithm--whether to use instance-wise optimization as in Section 4.2, or the block coordinate-ascent (Algorithm 1)-- and the guarantees for the result--whether semi-empirical quantities (Section 4.1) lead to an optimal solution, or a suboptimal with error bounded by Theorem 5.2. These are given as follows and summarized in Table 3:

* **Fully linear**: Optimal predictions for metrics that are linear in all entries of the confusion matrix, as (6), can be solved _exactly_ in an _instance-wise_ manner. Examples are classical metrics such as instance-wise precision\(@k\), or propensity-scored precision\(@k\).
* **Linear in predictions**: _Approximately optimal_ predictions for metrics that are linear in the predictions as given in (15) can be obtained using _instance-wise_ optimization, by switching from \(_{}\) to \(_{}\). An example is macro recall\(@k\).
* **Linear in labels**: If a metric is linear in the label variables as given in (14), then \(_{}_{}\). However, the resulting combinatorial optimization problem for \(_{}\) is still complex enough, and we can solve it _only locally_. An example is macro precision\(@k\).
* **Nonlinear metrics**: If none of the above apply, we have \(_{}_{}\), and have to solve it _locally_ using _block-coordinate ascent_. This is the case of macro \(F\)-measure\(@k\), or coverage\(@k\).

The macro-averaged metrics budgeted at \(k\) are attractive for measuring the long-tail performance. Macro-averaging treats all the labels as equally important, while the budget of \(k\) predictions requires the prediction algorithm to choose the labels "wisely." We believe that this approach is substantially better than the one based on propensity-scored metrics. It is important to make the distinction between a metric used as a surrogate for training or inference, and its use as a performance metric in itself. While the former might be well justified for many metrics, the latter not necessarily as a metric might not have a clear interpretation of the calculated numbers.

Finally, the proposed framework is a plug-in approach that works on estimates of marginal probabilities and can be seamlessly applied to many existing state-of-the-art XMLC algorithms that are able to output such predictions, including XR-Transformer , CascadeXML , and algorithmic approaches for dealing with missing labels . It can also be combined with recently proposed methods that try to improve predictive performance on the tail labels by, e.g., leveraging labels features to estimate labels-correlations  or to do data augmentation and generate new training points for tail labels .

   Linear in & Approx. & Algorithm \\  \(t\), \(q\), \(p\) & No & Instance-wise \\ \(t\), \(q\) & Yes & Instance-wise \\ \(t\), \(p\) & No & Block-Coordinate \\ â€” & Yes & Block-Coordinate \\   

Table 3: Four different classes of utilities