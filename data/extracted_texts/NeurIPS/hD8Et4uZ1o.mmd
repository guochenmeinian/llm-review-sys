# An Equivalence Between Static and Dynamic Regret Minimization

Andrew Jacobsen

Universita degli Studi di Milano

Politecnico di Milano

contact@andrew-jacobsen.com

&Francesco Orabona

KAUST

francesco@orabona.com

Work done while visiting Optimal Lab at KAUST.

###### Abstract

We study the problem of dynamic regret minimization in online convex optimization, in which the objective is to minimize the difference between the cumulative loss of an algorithm and that of an arbitrary sequence of comparators. While the literature on this topic is very rich, a unifying framework for the analysis and design of these algorithms is still missing. In this paper we show that _for linear losses, dynamic regret minimization is equivalent to static regret minimization in an extended decision space_. Using this simple observation, we show that there is a frontier of lower bounds trading off penalties due to the variance of the losses and penalties due to variability of the comparator sequence, and provide a framework for achieving any of the guarantees along this frontier. As a result, we also prove for the first time that adapting to the squared path-length of an arbitrary sequence of comparators to achieve regret \(R_{T}(_{1},,_{T})(\|_{t} -_{t+1}\|^{2}})\) is impossible. However, using our framework we introduce an alternative notion of variability based on a locally-smoothed comparator sequence \(}_{1},,}_{T}\), and provide an algorithm guaranteeing dynamic regret of the form \(R_{T}(_{1},,_{T})}(\| }_{i}-}_{i+1}\|^{2}})\), while still matching in the worst case the usual path-length dependencies up to polylogarithmic terms.

## 1 Introduction

This paper introduces new techniques for _Online Convex Optimization_ (OCO), a framework for designing and analyzing algorithms which learn on-the-fly from a stream of data . Formally, consider \(T\) rounds of interaction between the learner and their environment. In each round, the learner chooses \(_{t}\) from a convex feasible set \(^{d}\), the environment reveals a \(G\)-Lipschitz convex loss function \(_{t}:\), and the learner incurs a loss of \(_{t}(_{t})\). The classic objective in this setting is to minimize the learner's _regret_ relative to any fixed benchmark \(\):

\[R_{T}():=_{t=1}^{T}(_{t}(_{t})-_{t}())\;.\]

In this paper, we study the more general problem of minimizing the learner's regret relative to any _sequence_ of benchmarks \(_{1},,_{T}\):

\[R_{T}(_{1},,_{T}):=_{t=1}^{T}(_{t}(_{t})- _{t}(_{t}))\;.\]This objective is typically referred to as _dynamic_ regret, to distinguish it from the special case where the comparator sequence is fixed \(_{1}==_{T}\) (referred to as _static_ regret). We focus in particular on the special case of _Online Linear Optimization_ (OLO), in which \(_{t}()=_{t},\) for some \(_{t}^{d}\). Note that OCO problems can always be reduced to OLO via the well-known inequality \(_{t}(_{t})-_{t}()_{t},_{t}-\) for \(_{t}_{t}(_{t})\), where \(_{t}(_{t})\) is the subdifferential set of \(_{t}\) at \(_{t}\) [see, _e.g._, 36], so throughout this paper we will focus on the OLO setting.

Intuitively, if the sequence of comparators \(_{1},,_{T}\) varies too much, it should be impossible to achieve low dynamic regret. On the other hand, we know it is possible to achieve sublinear regret if the sequence of comparators is constant, _i.e._, \(_{1}==_{T}\), because this is simply the static case. Hence, we need a way to quantify the complexity, or _variability_, of the comparator sequence. The most commonly used notion of complexity in this regard is the _path-length_ of the comparator sequence [17; 18], defined as

\[P_{T}^{\|\|}:=_{t=2}^{T}\|_{t}-_{t-1}\|\;.\]

It is possible to show that Online Gradient Descent has a dynamic regret of \(((D+P_{T}^{\|\|})G)\) in _bounded_ domains, where \(D\) is an upper bound on the diameter of the feasible set and \(G\) is the Lipschitz constant of the losses . This bound was improved to \((^{\|\|}}G)\) and shown to be minimax optimal by Zhang et al. .

Notice that the path-length bounds scale with a rather pessimistic constant of \(D=_{w,w^{}}\|-^{}\|\). A better bound would instead scale with the _squared_ path-length:

\[P_{T}^{\|\|^{2}}:=_{t=1}^{T-1}\|_{t}-_{t-1}\|^{2},\]

which can be significantly smaller2 than the penalty in the bound above: \(P_{T}^{\|\|^{2}} DP_{T}^{\|\|}\). However, guarantees scaling with \(P_{T}^{\|\|^{2}}\) are not well understood in general compared with the more common \(P_{T}^{\|\|}\) bounds, and have only been obtained by restricting the comparator sequence to \(_{t}=*{argmin}_{}\,_{t}()\) or under additional assumptions such as strong-convexity [44; 45; 7].

In this paper, we focus on the challenging case that the domain is _unbounded_, where recent works have achieved the dynamic regret \(}(}\|_{t}-_{t^{ }}\|}\,P_{T}^{\|\|}T)\) in the worst case [20; 25; 21; 47]. Of particular interest, Jacobsen and Cutkosky , Zhang et al.  achieve bounds of the form

\[R_{T}(_{1},,_{T})}(^{\|\|}_{t=1}^{T}\|_{t}\|^{2}\,\|_{t}-}\|} ),\] (1)

which avoids the pessimistic multiplicative penalty of \(_{t,t^{}}\|_{t}-_{t^{}}\|\), but results in a coupling between the gradient and variability penalties. It is unclear if it is possible to obtain a guarantee which cleanly separates the variability and variance penalties, to achieve dynamic regret scaling as \(R_{T}(_{1},,_{T})(^{\|\| ^{2}}_{t=1}^{T}\|_{t}\|^{2}})\). In fact, it is not clear in general how to reason about potential trade-offs that may result from adapting to different measures of variability.

Contributions.In this paper, we show how to reformulate the dynamic regret miniminization problem as an _equivalent_ static regret problem (Section 2). This equivalence allows us to use results for the static regret setting to prove both upper and lower bounds for dynamic regret.

In our first application of this equivalence, we show that the ideal guarantee scaling the with squared path-length \(^{\|\|^{2}}_{t=1}^{T}\|_{t}\|^{2} }\) is **not** possible in general (Section 3). We do this by proving a novel lower bound showing that there is a fundamental trade-off between the penalties incurred due to comparator variability and penalties incurred due to loss variance, leading to a new frontier of dynamic regret lower bounds.

Our second application is to provide a framework for achieving any of the variance/variability trade-offs along the lower bound frontier, up to polylogarithmic terms (Section 4). Our framework allows us to develop dynamic regret algorithms by simply choosing suitable dual-norm pairs \((,_{*})\) in the static regret problem. Along with our matching lower bound, this framework provides a concrete way to reason about different measures of comparator variability and the trade-offs they entail, and to design algorithms achieving those trade-offs.

While our lower bound demonstrates that the ideal squared path-length guarantee cannot be achieved, using our framework we show that it is possible to achieve an alternative guarantee that scales with

\[^{^{2}}(_{1},,_{T}) _{i}}_{i}^{()}-}_{i+1}^{( )}_{2}^{2},\]

where \(}_{i}^{()}\) is a _local average_ of the comparator sequence at a timescale of \(\) (see Section 4.1). Similar to \(P_{T}^{^{2}}\), this variability measure maintains the property that it matches the worst-case guarantees based on path-length up to polylogarithmic terms, _i.e._, \(_{T}^{^{2}}}( _{t,t^{}}_{t}-_{t^{}} P_{T} ^{})\). These are the first guarantees for general OCO that fully decouple the variance and variability penalties for dynamic regret without explicitly incurring pessimistic \(_{t,t^{}}_{t}-_{t^{}}\) penalties.

Related Work.Our approach is inspired by the Haar OLR algorithm of Zhang et al. . In that work, dynamic regret is approached by interpreting the comparator sequence as a high-dimensional "signal" which is decomposed into a frequency domain representation using a dictionary of features. Then, for each feature vector in the dictionary, a 1-dimensional parameter-free  algorithm is used to learn how well that feature correlates with the losses. This allows one to compete with an arbitrary comparator sequence, so long as it can be represented in terms of the chosen dictionary of features. We take a similar but slightly more general approach. Our framework also represents the comparator sequence as a high-dimensional signal, but we instead use this signal to define an _equivalent static regret problem_, a perspective that allows us design algorithms for dynamic regret by simply choosing suitable dual-norm pairs.

Other prior works in the general OCO setting have also studied various alternative forms of variability such as the temporal variability \(_{t=1}^{T-1}_{}_{t}()-_ {t+1}()\) or deviation of the comparator from a given dynamical model \(_{t=1}^{T-1}_{t}-_{t}(_{t-1})\). Alternative variance penalties have also been studied in the dynamic setting, such as the small-loss penalties \(_{t=1}^{T}_{t}(_{t})\) or gradient variation penalties \(_{t=1}^{T}_{}_{t}()- _{t+1}()\). It is also possible to achieve a smaller regret with stronger assumptions on the losses . It is important to note however that almost all prior works, with the exception of Jacobssen and Cutkosky , Luo et al.  and Zhang et al. , study dynamic regret only in the easier bounded domain setting.

There is also an often ignored connection between measures of comparator variability and the function classes studied in non-parametric regression. In particular, considering the case that the losses are \(_{t}(x)=(x-u_{t})^{2}\), then the sequence of comparators \(u_{1},,u_{T}\) with bounded path length \(C_{T}\) and bounded squared path length \((C_{T}^{})^{2}\) corresponds to the sequence with discrete total variation bounded by \(C_{T}\) and the discrete Sobolev class with bound \(C_{T}^{}\), respectively. In this setting, the minimax rates are known  and Koolen et al.  obtain the minimax regret for the Sobolev classes, while Baby and Wang  for both classes with slightly stronger assumptions. However, these results are not directly related to this paper because we consider linear losses.

Notations.We will use the following definitions and notations. The elements of a matrix \(^{n m}\) are denoted by \(A_{ij}\) for \(i=1,,n\) and \(j=1,,m\). Similarly, the elements of a vector \(^{d}\) are \(u_{i}\) for \(i=1,,d\). The Kronecker product of matrices \(^{m n}\) and \(^{p q}\) is the block matrix defined by

\[:=A_{1,1}&&A_{1,n}\\ &&\\ A_{m,1}&&A_{m,n}.\]We let \(_{t}\) denote the \(t^{}\) standard basis vector of \(^{T}\) and \(_{d}\) is the \(d d\) identity matrix. For a square matrix \(\), \(()\) is the diagonal matrix that contains the elements of the diagonal of \(\). For a positive definite matrix \(\), we define the weighted norm \(\|\|_{}:=,}\). For a matrix \(^{m n}\), we denote its Frobenius norm by \(\|\|_{F}:=^{m}_{j=1}^{n}A_{i,j}^{2}}\). The vec operator is the mapping defined by stacking the columns of a matrix \(\) in a vector. We will denote by \(\|\|_{p,p}\) the entry-wise \(p\)-norm of \(\), _i.e._, \(\|\|_{p,p}:=\|()\|_{p}\).

## 2 A dynamic-to-static reduction

In this section, we present a general reduction from dynamic regret to static regret. The key idea is to embed the comparator sequence in a high dimensional space \(^{T}\), where \(T\) is the number of rounds, so that competing with a _fixed_ comparator \(}^{T}\) in this high-dimensional space is equivalent to competing with a _sequence_ of comparators in the original space \(\). In this way, we can reduce the problem of minimizing the dynamic regret to the one of minimizing the static regret.

Our reduction is shown in Algorithm 1. We simply embed the linear losses \(_{t}\) in a high-dimensional space by setting

\[}_{t}=_{t}_{t}=(_{d}^{}, ,_{d}^{},_{t}^{},_{d}^{},,_{d }^{})^{},\] (2)

where \(_{t}^{T}\) is the \(t^{}\) standard basis vector of \(^{T}\) and \(_{d}^{d}\) denotes the vector of zeros. We pass these losses to the online learning algorithm \(\), which predicts with a vector \(}_{t}^{T}\). Finally, we set \(_{t}^{d}\) equal to the \(t^{}\) "component" of \(}_{t}\), and play \(_{t}\).

We show that the dynamic regret of the resulting algorithm will be equal to the static regret of the algorithm \(\). In particular, for any sequence \(}=(_{1},,_{T})\) in \(\) we will denote the concatenation of \(}\) into a single vector in \(^{T}\) as

\[}=_{t=1}^{T}_{t}_{t}=(_{1}^ {},,_{T}^{})^{}\.\] (3)

Then, the following proposition shows that the dynamic regret of Algorithm 1_w.r.t_ any sequence \(}=(_{1},,_{T})\) is _equal_ to the static regret of \(\)_w.r.t_\(}\).

**Proposition 1**.: _Let \(^{d}\) and let \(\) be an online learning algorithm with domain \(^{T}\). Then, for any sequence \(}=(_{1},,_{T})^{T}\), Algorithm 1 guarantees_

\[R_{T}(})=_{t=1}^{T}}_{t}, _{t}-_{t}=_{t=1}^{T}}_{t},}_{t}-}=:R_{T}^{ Seq }(})\.\]

Proof.: The proof is immediate from Equations (2) and (3). In fact, observe that the cumulative loss of the comparator sequence is precisely

\[_{t=1}^{T}}_{t},_{t}= (_{1}\\ _{T})\!,(_{1}\\ _{T})=_{t=1}^{T} _{t}_{t},_{t=1}^{T}_{t}_{t} =_{t=1}^{T}}_{t},}\.\]

We get a similar relationship for the algorithm's cumulative loss. Hence, we have \(R_{T}(})=_{t=1}^{T}}_{t}, {w}_{t}-_{t}=_{t=1}^{T}}_{t}, }_{t}-}=R_{T}^{ Seq}( })\).

**Remark 1**.: _It is important to note that the regret equivalence holds in the context of **linear losses**. However, our reduction can still be leveraged for arbitrary convex losses by first applying the standard reduction to OLO: \(_{t=1}^{T}_{t}(_{t})-_{t}(_{t})_{t=1}^{T} _{t},_{t}-_{t}=R_{T}^{}(})\) for \(_{t}_{t}(_{t})\)._

While our reduction is exceptionally simple, its utility should not be understated. Proposition 1 is a regret _equivalence_ -- we lose nothing by taking this perspective, yet it allows us to immediately apply all the usual techniques and approaches from the static regret setting. For instance, given any dual norm pair \((,_{*})\), it is well-understood how to develop algorithms which adapt simultaneously to the comparator norm \(}\) and to the gradient variance \(_{t=1}^{T}}_{t}_{*}^{2}\) to guarantee

\[R_{T}(_{1},,_{T})=R_{T}^{}(}) }(} ^{T}}_{t}_{*}^{2}} ).\]

Such algorithms are commonly referred to as "parameter-free", or "comparator adaptive", because they achieve this adaptation by completely removing the parameter that depends on the unknown comparator \(}\)[_e.g._, 26, 32, 9, 12, 20, 8, 21, 48]. In this way, we have effectively reduced the problem of minimizing dynamic regret to the problem of selecting a dual-norm pair \((,_{*})\) that meaningfully measures the "difficulty" of the sequence in \(}\) and the losses \(}_{t}\). In particular, \((,_{*})\) should be chosen with the following considerations in mind:

1. \(}\) should produce a meaningful measure of variability of the comparator sequence \(_{1},,_{T}\). For instance, we will show in Proposition 2 that the squared path-length arises from a particular weighted norm applied to \(}\).
2. \(}_{t}_{*}\) should not "blow up". Ideally \(}_{t}_{*}\) should match the magnitude of the true losses \(_{t}\) up to polylog factors.
3. \((,_{*})\) should be chosen with computational considerations in mind. For instance, to apply an FTRL-based algorithm to the losses \(}_{t}^{dT}\), efficient implementation will typically require \(_{*}\) to have sparse subgradients. In general, an ideal dual-norm pair should facilitate updating only \(( T)\) variables at a time, so as to match the \((d T)\) per-step computation enjoyed by existing dynamic regret algorithms. We will see one such example in Section 4.1.

In the next section, we show that there is in fact a fundamental trade-off between the penalties induced by the dual-norm pair \((,_{*})\), creating a tension between the first two considerations.

## 3 Lower bounds for unconstrained dynamic regret

In the static regret setting, there is a well-known trade-off between the way in which we measure the complexity of the comparator \(\) and the way in which we measure the complexity of the linear losses \(_{t}\). For example, in Online Mirror Descent  one can get a regret guarantee that depends on the maximum diameter of the feasible set with respect to a norm \(\), while the linear losses are measured using the dual norm \(_{*}\). The equivalence in Proposition 1 suggests that a similar tension exists for the dynamic regret.

Given the structure of our reduction, it makes sense to focus on the weighted norms \(_{}\) and \(_{^{-1}}\), where \(\) is a symmetric positive definite matrix. In particular, the next theorem shows that there is a fundamental trade-off between a _variability penalty_\(}_{}\) and a _variance penalty_\(G^{2}(^{-1})\) related to the losses. The proof is provided in Appendix A.1 and it is based on a lower bound to the tail of Rademacher chaos of order 2.

**Theorem 1**.: _Let the number of rounds \(T T_{0}\), where \(T_{0}\) is a universal constant. Let \(\) be an online learning algorithm, and suppose \(\) guarantees \(R_{T}(0) G_{T}\) for any sequence of linear losses \(g_{1},,g_{T}\) satisfying \(|g_{t}| G\). Let \(^{-1}^{T T}\) be any symmetric positive definite matrix, denote \(}^{-1}:=^{-1}-(^{-1})\) and \(V_{T}:=(^{-1})+\|}^{-1}\|_{F}\). Suppose that \(\|}^{-1}\|_{F}^{2}_{i}_{j}(_{ij}^{-1})^{2}\). Then, for any \(P\) satisfying \(T_{0}_{2}}}{2_{T}} T\), there is a sequence of losses \(g_{1},,g_{T}\), and \(}=(u_{1},,u_{T})^{}^{T}\) satisfying \(\|}\|_{}=\) such that we have_

\[R_{T}(u_{1},,u_{T})(G_{T}+G(^{-1})+\|}^{-1}\|_{F} _{2}^{}}}{2_{T}}]})\.\]

Let us first briefly discuss the conditions on \(\). First, note that the restriction that \(\) be positive definite and symmetric simply specifies that \(\|\|_{}\) defines a valid norm. The condition on \(\|}^{-1}\|_{F}=\|^{-1}-(^{-1} )\|_{F}\) is less straight forward to interpret, but it essentially states that the total "variance" of \(}^{-1}\) is at least as much as that of any of its columns. on a technical level this assumption leads to the restriction that \(P\) satisfies \(_{2}(}/2_{T}) T\). This is a natural restriction which encodes the fact that if \(P\) is too large relative to \(T\) (_i.e._, when \(_{2}(/2_{T}) T\)), one can ensure "low" regret by simply playing \(_{t}=\) on every round:

\[R_{T}(})=-_{t=1}^{T}_{t},_{t} _{t}\|_{t}\|G\,T G_{t}\| _{t}\|_{2}(}/2),\]

and hence the only lower bounds in such settings are trivial ones and it suffices to consider only \(P\) satisfying \((}/2) T\). We will see in Proposition 2 that the matrix that produces the squared path-length satisfies this condition, and it can be seen that symmetric matrices with equal column sums (as is the case in Proposition 3) satisfy this condition as well.

The result of Theorem 1 shows that there is a frontier of lower bounds which trade off penalties related to variability of the comparator sequence and penalties related to the variance of the subgradients. That is, one can not guarantee a small variability penalty in all situations without also accepting a large subgradient variance penalty. The next proposition shows that i) the squared path-length can be represented by a particular choice of the weighted norm \(\|}\|_{}\), and ii) the fundamental tension between \(\|}\|_{}\) and its corresponding variance penalty \((^{-1})\) prevents any algorithm from attaining the ideal variability dependence of \(\|}\|_{}=(^{T-1}\| _{t}-_{t+1}\|^{2}})\). In fact, the corresponding variance penalty is \(G^{2}(^{-1})=(G^{2}T^{2})\), resulting in a vacuous guarantee. Proof of the proposition can be found in Appendix A.2.

**Proposition 2**.: _(Adapting to Squared Path-length Requires Superlinear Regret) Define the finite-difference operator \(^{T}\) as the matrix with entries_

\[_{ij}=1&i=j\\ -1&i=j-1\\ 0&.\]

_Let \(=^{}\) and \(=_{d}\). Then, \(\) satisfies the assumptions of Theorem 1 and_

\[\|}\|_{}^{2}=\|_{T}\|_{2}^{2 }+_{t=1}^{T-1}\|_{t}-_{t+1}\|_{2}^{2}(^{-1})=\.\]

Proposition 2 shows that adapting to the squared path-length of an arbitrary comparator sequence _necessarily requires_ incurring a linear penalty, so adapting to the squared path-length is impossible without facing a vacuous guarantee. However, we will show in Section 4.1 that it is possible to adapt to a measure of variability which is similar in spirit to the squared path-length, yet only incurs a \((^{-1})=( T)\) variance penalty.

**Remark 2**.: _The matrix \(\) in Proposition 2 uniquely exposes the the squared path-length up to the bias term \(\|_{T}\|^{2}\). Such a bias term must appear because in the static regret setting, wherein \(_{1}==_{T}=\), the variability measure \(\|\|_{M}\) must still reduce to a dependence on \(\|\|\), otherwisethe guarantee would violate existing \((\|\|)\) lower bounds for static regret. More generally, we show in Appendix A.3 that any other choice of bias would similarly lead to \((^{-1})(T^{2})\), so Proposition 2 along with our lower bound in Theorem 1 are sufficient to show that adapting to squared path-length requires accepting a vacuous guarantee._

## 4 Dynamic regret for unconstrained OLO via weighted norms

So far, we've seen that there exists a frontier of lower bounds trading off a variability penalty, measured by \(\|}\|_{}\), and a loss variance penalty, measured by \((^{-1})\), and that the tension between these two quantities makes it impossible to adapt to the squared path-length of the comparator sequence without accepting a vacuous regret guarantee. A natural next question is whether there are choices of \(\) which lead to a more favorable trade-off of these two quantities. In this section, we provide a simple framework for achieving lower bounds along the frontier described by Theorem 1, and an instance which successfully achieves an improved variance/variability trade-off. The guarantees on the lower bound frontier can be achieved using any parameter-free algorithm along with the 1-dimensional reduction of Cutkosky and Orabona  to extend the algorithm to dual-norm pair \((\|\|_{},\|\|_{^{-1}})\). The generic procedure is summarized in Algorithm 2 for convenience.

``` Input 1-d Parameter-free OLO algorithm \(\), positive definite symmetric matrix \(^{dT dT}\) Initialize \(}_{1}=}_{1}=^{dT}\), \(V_{1}=0\) for\(t=1:T\)do  Get \(_{t}\) from \(\)  Play \(}_{t}=_{t}}_{t}\) and observe \(}_{t}\)  Send \(}_{t},}_{t}\) to \(\) as the \(t^{}\) loss  Set \(}_{t+1}=}_{t}-^{-1} }_{t}\)  Set \(V_{t+1}=V_{t}+\|}_{t}\|_{^{-1}}^{2}\)  Set \(}_{t+1}=}_{t+1}}{}} [1}}{\|}_{t+1} \|_{^{-1}}}]\) // (Projected) Scale-free FTRL update  end for ```

**Algorithm 2**Dynamic regret OLO through 1-dimensional reduction 

**Theorem 2**.: _Let \(^{T T}\) be a symmetric positive definite matrix, \(=_{d}\), and \(>0\). There is an algorithm \(\) such that for any \(_{1},,_{T}^{d}\) satisfying \(\|_{t}\|_{2} G\) for all \(t\) and any sequence \(}=(_{1},,_{T})^{dT}\), the dynamic regret is bounded as_

\[R_{T}(})(+\| }\|_{}[(}\|_{}}}{}+1 )}(}\|_{ }}}{})]),\]

_where \(V_{T}=_{t=1}^{T}\|}_{t}\|_{^{-1}}^{2}\) and \(=G\|^{-1}\|_{,}\)._

For the proof, we will need the following technical lemma.

**Lemma 1**.: _Let \(^{T T}\) be a symmetric positive definite matrix and let \(=_{d}\). For \(t=1,,T\), let \(_{t}^{d}\) and let \(}_{t}=_{t}_{t}\). Then, we have \(\|}_{t}\|_{}^{2}=\|_{t}\|_{ 2}^{2}S_{tt}\)._

Proof.: Using the mixed-product property \((A B)(C D)=AC BD\) and the transpose property \((A B)^{}=A^{} B^{}\) of the Kronecker product, we have that

\[}_{t},}_{t} =_{t}_{t},[ _{d}]_{t}_{t}= _{t}_{t},_{t}_{t} =(_{t}^{}_{t}^{})( _{t}_{t})\] \[=_{t}^{}_{t}_{t}^{ }_{t}=S_{tt}\|_{t}\|^{2}\.\]

Proof of Theorem 2.: Applying Proposition 1, we have \(R_{T}(})=_{t=1}^{T}}_{t}, }_{t}-}=R_{T}^{}( })\). Since \(\) is symmetric and positive definite, \((\|\|_{},\|\|_{^{-1}})\) is a valid dual-norm pair. By Lemma 1,we have \(\|}_{t}\|_{^{-1}}^{2}=\|_{t}\|_ {2}^{2}S_{tt}^{-1} G^{2}\|^{-1}\|_{,}:= ^{2}\). Hence, let \(\) be any algorithm which guarantees a parameter-free regret _w.r.t._\((\|\|,\|\|_{*})\) on losses satisfying \(\|}_{t}\|_{^{-1}}\). Note that any parameter-free algorithm can be extended to handle arbitrary dual-norm pairs by leveraging the one-dimensional reduction of Cutkosky and Orabona (2019, Section 3), that reduces the OLO problem to a unconstrained 1d problem plus an OLO problem in the unitary ball defined by the primal norm. For instance, applying Jacobsen and Cutkosky (2019, Algorithm 1) with the one-dimensional reduction one can easily show (see details in Appendix B.1)

\[R_{T}(})(+\|}\|_{}[(} \|_{}}_{T}}{}+1)} (}\|_{}}_{T}}{})]),\]

where \(V_{T}=_{t=1}^{T}\|}_{t}\|_{^{-1}}^{2}\) and \(_{T}=^{2}(_{t=1}^{T}\|}_{t}\|_{^{-1}}^{2}/^{2})(^{2}T)\). 

Note in particular that by Lemma 1, we have \(_{t=1}^{T}\|}_{t}\|_{^{-1}}^{2}=_{t= 1}^{T}S_{tt}^{-1}\|_{t}\|^{2} G_{t=1}^{T}S_{tt}^{-1}=G (^{-1})\), so this bound matches the lower bound from Section 3, up to polylogarithmic terms.3 Thus, any valid choice of \(\) will be on the lower bound frontier of Section 3.

### Trading-off Variance and Variability

Leveraging the algorithm characterized by Theorem 2, we now show that it is indeed possible to choose \(\) such that \(_{t=1}^{T}\|}_{t}\|_{^{-1}}^{2}\) is only \((_{t=1}^{T}\|_{t}\|^{2})\), in exchange for a variability penalty which is still similar in spirit to the squared path-length.

Inspired by the Haar OLR algorithm of , we apply Theorem 2 using \(=_{n}_{n}^{}\), where \(_{n}\) is the unnormalized Haar basis matrix of order \(n=_{2}T\). The Haar wavelet transform and its basis matrix are common tools in the signal processing literature; we recall the basic definitions and facts for convenience in Appendix B.2. With this choice, we have the following bounds on \(\|}\|_{}\) and \(\|}_{t}\|_{^{-1}}^{2}\). The proof can be found in Appendix B.3.

**Proposition 3**.: _Let \(n=_{2}T\) and \(_{n}\) be the unnormalized Haar basis matrix of order \(n\). For any \(\{2^{i}:i=0,,_{2}T\}\), let \(N_{}=T/\) and let \(_{1}^{()},,_{N_{}}^{()}\) be a partition of \([T]\) into intervals of length \(\). Define the average comparator in interval \(_{i}^{()}\) to be \(}_{i}^{()}=_{t_{i}^{()}} _{t}\), and define the squared path-length at time-scale \(<T\) to be_

\[(},):=_{i=1}^{N_{}/2}\|}_{2i-1}^{ ()}-}_{2i}^{()}\|_{2}^{2},\]

_and \((},T)=\|}_{1}^{(T)}\|_{2}^{2}=\| }\|_{2}^{2}\). Then, setting \(=[_{n}_{n}^{}]^{-1}\) and \(=_{d}\), we have_

\[\|}\|_{}^{2} \|}\|_{2}^{2}+_{i=0}^{ _{2}(T)}(},2^{i})\|}\|_{2}^{2}+ _{}(},),\] \[\|}_{t}\|_{^{-1}}^{2} =\|_{t}\|_{2}^{2}(1+)\;.\]

Summarizing, by applying Algorithm 1 with \(=[_{n}_{n}^{}]^{-1}\) we ensure regret

\[R_{T}(})}(}\|_{2}^{2}+_{}^{N_{}/2}\|}_{2i+1}^{( )}-}_{2i}^{()}\|_{2}^{2})_{t=1}^{T}\| _{t}\|_{2}^{2}})\;.\]

This is the first _fully decoupled_ guarantee for general dynamic regret which incurs no pessimistic multiplicative penalties of the form \(_{t,t^{}}\|_{t}-_{t^{}}\|\). That is, the terms depending on the comparators and the terms depending on the gradients appear in separate sums. Moreover, observe that this measure of variability can immediately be related to the more standard (first-order/non-squared) path-length using the local averaging lemma of Zhang et al.  (Lemma D.7). We have

\[\|}\|_{}^{2} \|}\|_{2}^{2}+T}{4}_{}_ {i=1}^{N_{}/2}\|}_{2i-1}^{()}-}_{2^{ }}^{()}\|_{2}^{2}}(^{2}+ _{}_{i=1}^{N_{}/2}\|}_{2i-1}^{()}- }_{2^{}}^{()}\|_{2})\] \[}(^{2}+_{t=1}^{T -1}\|_{t}-_{t+1}\|_{2})}(^{2}+P_{T}),\]

where \(=_{,i}\|}_{i}^{()}-}_{i+1}^{( )}\|_{i,j}\|_{i}-_{j}\|\). Thus, applying Algorithm 1 with dual-norm pair \((\|\|_{_{n}^{-}_{n}^{-}},\| \|_{_{n}_{n}^{}})\) still guarantees worst-case regret

\[R_{T}()}(\|}\|_{ _{n}^{-}_{n}^{-1}}^{T}\|}_{t}\|_{_{n}_{n}^{}}^{2}})}(}\|_{2}^{2}+P_{ T})_{t=1}^{T}\|_{t}\|_{2}^{2}}),\]

which matches the guarantees of prior works, up to polylogarithmic terms.

Importantly, with \(=_{n}^{-}_{n}^{-1}_{d}\) the dual-norm pair \((\|\|_{},\|\|_{^{-1}})\) leads to updates that can be implemented efficiently, in requiring only \(O( T)\) variables to be updated on each round. This is because the Haar basis matrices are _locally supported_ -- the columns of \(_{n}=(^{(1)}^{(T)})^ {T T}\) form an orthogonal basis with the property that for any \(t\), \([^{(i)}]_{t} 0\) for only \(1+_{2}T\) indices \(i\) (see Proposition 5). Hence, \((^{}_{d})}_{t}=(^{} I _{d})(_{t}_{t})=(^{}_{t}) _{t}\), is a block vector with only \(1+_{2}T\) active blocks, requiring that we update only \(O(d T)\) indices to maintain each of the variables needed to implement Algorithm 2. We provide the full details of this computation in Appendix B.4, which we summarize below in Proposition 4.

**Proposition 4**.: _The algorithm characterized by applying Theorem 2 with \(=[_{n}_{n}^{}]^{-1}\) can be implemented with \((d T)\) per-round computation._

## 5 Recovering Variance-Variability Coupling Guarantees

Our main focus throughout the paper has been on designing algorithms that achieve a regret bounds of the form \(R_{T}(}) O(_{1},,_{T})V(_ {1},,_{T})})\) for some functions \(f\) and \(V\), which cleanly separates the penalties associated with difficult _loss_ sequences from the penalties associated with difficult _comparator_ sequences. However, the first works to achieve unconstrained dynamic regret guarantees uncovered guarantees of a slightly different form, containing a _gradient-comparator correlation_ penalty:

\[R_{T}(})(^{T-1}\| _{t}-_{t+1}\|^{T}\|_{t}\|^{ 2}\|_{t}-}\|}_{}}),\] (4)

for some reference point \(}\). Guarantees of this form allow some degree of coupling between the variability and variance penalties. This can be appealing in certain situations. For instance, guarantees of the form above have the appealing property that the variance penalty completely disappears on any rounds where the comparator \(_{t}\) matches the reference point \(}\). This can be a very powerful property when one has _a priori_ access to a benchmark model (represented by \(}\)) which can be expected to predict well _on average_, so that we accumulate the variance penalties only when facing atypical/unexpected conditions.

The prior works achieving a coupling guarantee do so using rather mysterious means. For instance, the guarantee of Jacobsen and Cutkosky  achieves the coupling guarantee almost by coincidence, as it appears in response to a composite regularizer they add to the update to cancel out certain unstable terms in the analysis, and the analysis of Zhang et al.  recovers a guarantee of a similar form using a rather difficult analysis of the frequency-domain representation of \(}\) after projecting onto the Haar basis vectors. So far there is no unifying explanation of the principles leading to these sorts of guarantees.

Our equivalence in Proposition 1 instead shows that guarantees of the form Equation (4) can instead be understood through the lens of reward-regret duality, a standard tool used to design algorithms in the static regret setting. The reward-regret duality states that in order to guarantee regret of the form \(R_{T}() f()\) for all \(\), it suffices to design an algorithm that guarantees \(-_{t=1}^{T}_{t},_{t} f^{*}(- _{t=1}^{T}_{t})\) for any \(_{1},,_{T}\). Using Proposition 1, we immediately have the following analogous design principle for dynamic regret. Proof is deferred to Appendix C.1.

**Theorem 3**.: _Let \(_{T}:=-_{t=1}^{T}}_{t}, {}_{t}\) denote the "wealth" of an algorithm \(\) and let \((f,f^{*})\) be a Fenchel conjugate pair. Then \(\) guarantees \(_{T} f_{T}^{*}-_{t=1}^{T}}_{t}\) for any sequence \(}_{1},,}_{T}\) if and only if \(R_{T}(}) f_{T}(})\) for any sequence \(}=(_{1},,_{T})\) in \(\), where \(}=(_{1}^{},,_{T}^{})^{}\) is the concatenation of the sequence \(}\) into a vector._

So, suppose we would like to design an algorithm that guarantees for any sequence \(}=(_{1},,_{T})\) and any \(}=(_{1},,_{T})\) regret of the form

\[R_{T}(})(})V_{T}( {})},\]

for some \(f_{T}(})\) and \(V_{T}(})=V_{T}(};})\). Then, since \(=_{ 0}+b\), any such algorithm must have \(R_{T}(})(})}{2}+V_{T}(})\) for every \( 0\). So, via Proposition 1 and the the reward-regret duality of Theorem 3, we have that the desired guarantee is equivalent to guaranteeing for all \( 0\) a wealth lower bound of

\[_{t}=-_{t=1}^{T}}_{t}, }_{t}[()}{2}+V_{T}()]^{*}-}_{1:T}=^{*}-2}_{1:T}}{2}\  2 V_{T}^{*}(}_{1:T}}{2}),\]

where \(f_{T}^{*}\) and \(V_{T}^{*}\) are the Fenchel conjugates of \(f_{T}\) and \(V_{T}\) respectively, and \((f_{1}\ \ f_{2})\) denotes the _infimal convolution_ of \(f_{1}\) and \(f_{2}\):

\[(f_{1}\ \ f_{2})(z)=\{f_{1}(y)+f_{2}(z-y)\}.\]

Thus, the variance/variability coupling guarantees observed in Equation (4) can be interpreted as achieving wealth lower-bounds for potential functions involving infimal convolution.

The above discussion provides a general characterization of variance/variability coupling guarantees, though it is admittedly less clear how difficult it is to design algorithms from this perspective due to the rather complicated potential function that appears. Nonetheless, we believe that this provides a valuable perspective and insight that could be of general interest. An important direction for future work is to develop useful tools for working with potential functions of this form.

## 6 Conclusion

In this paper, we have shown a way to reduce the problem of dynamic regret minimization to the static one. We proved a novel frontier of lower bounds showing a fundamental trade-off between penalties on the comparators and penalties on the variance of the gradients. In particular, we have shown that it is not possible to achieve a guarantee that scales with \(^{T-1}\|_{t}-_{t+1}\|^{2}}\) without incurring a variance penalty of \((GT)\). We developed a simple framework for achieving guarantees along the lower bound frontier, and used it to develop the first algorithm making a non-trivial variance/variability decoupling guarantee against arbitrary comparator sequences. Our framework is simple but powerful, allowing one to fully utilize the rich literature of static regret algorithms for online learning.

We conclude by noting some directions for future work. There is a lot of exciting potential to explore different measures of variability induced by different choices of the matrix \(\), as well as going beyond weighted norms. As mentioned in Section 5, developing a useful toolset for potential functions involving infimal convolution is an important next-step for developing and understanding guarantees with a coupled variance/variability penalty, such as Equation (4). Also, our lower bound in Section 3 illustrates the variance-variability trade-off, but achieving the correct logarithmic dependencies proved to be very challenging -- many of the standard tools for proving lower bounds in unconstrained settings revolve around anti-concentration results that do not readily extend to arbitrary weighted norms and higher-dimensions. We look forward to exciting development in these future directions.