# Supplementary Material for

FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness for Semi-Supervised Learning

Zhuo Huang\({}^{1}\), Li Shen\({}^{2}\), Jun Yu\({}^{3}\), Bo Han\({}^{4}\), Tongliang Liu\({}^{1,}\)

\({}^{1}\)Sydney AI Centre, The University of Sydney; \({}^{2}\)JD Explore Academy;

\({}^{3}\)Department of Automation, University of Science and Technology of China;

\({}^{4}\)Department of Computer Science, Hong Kong Baptist University

zhua0420@uni.sydney.edu.au, mathshenli@gmail.com, harryjun@ustc.edu.cn, bhanml@comp.hkbu.edu.hk, tongliang.liu@sydney.edu.au

Corresponding to Tongliang Liu.

###### Abstract

Semi-Supervised Learning (SSL) has been an effective way to leverage abundant unlabeled data with extremely scarce labeled data. However, most SSL methods are commonly based on instance-wise consistency between different data transformations. Therefore, the label guidance on labeled data is hard to be propagated to unlabeled data. Consequently, the learning process on labeled data is much faster than on unlabeled data which is likely to fall into a local minima that does not favor unlabeled data, leading to sub-optimal generalization performance. In this paper, we propose _FlatMatch_ which minimizes a cross-sharpness measure to ensure consistent learning performance between the two datasets. Specifically, we increase the empirical risk on labeled data to obtain a worst-case model which is a failure case that needs to be enhanced. Then, by leveraging the richness of unlabeled data, we penalize the prediction difference (_i.e._, cross-sharpness) between the worst-case model and the original model so that the learning direction is beneficial to generalization on unlabeled data. Therefore, we can calibrate the learning process without being limited to insufficient label information. As a result, the mismatched learning performance can be mitigated, further enabling the effective exploitation of unlabeled data and improving SSL performance. Through comprehensive validation, we show FlatMatch achieves state-of-the-art results in many SSL settings. Our code is available at https://github.com/tmllab/2023_NeurIPS_FlatMatch.

## 1 Introduction

Training deep models  not only requires countless data but also hungers for label supervision which commonly consumes huge human laboring and unaffordable monetary costs. To ease the dependency on labeled data, semi-supervised learning (SSL)  has been one of the most effective strategies to exploit abundant unlabeled data by leveraging scarce labeled data. Traditional SSL commonly leverages unlabeled data by analyzing their manifold information. For example, semi-supervised support vector machine  finds a classifier that crosses the low-density region based on large-margin theorem and label-propagation  computes an affinity matrix in the input space to propagate the labels to their neighbor unlabeled data. Due to the computational burden of exploring manifold knowledge, recent advances in SSL benefit from sophisticated data augmentation techniques , they usually enforce predictive consistency between the original inputs and their augmented variants , meanwhile using pseudo labels  to guide the learning on unlabeled data.

However, as most of the existing methods only apply instance-wise consistency on each example with its own transformation, labeled data and unlabeled data are disconnected during training. Hence, the label guidance cannot be sufficiently propagated from the labeled set to the unlabeled set, causing the learning process on labeled data is much faster than on unlabeled data. As a result, the learning model could be misled to a local minima that cannot favor unlabeled data, leading to a non-negligible generalization mismatch. As generalization performance is closely related to the flatness of loss landscape [14; 24; 41; 51], we plot the loss landscapes of labeled data and unlabeled data using FixMatch  in Fig. 12. We have two major findings: 1) The loss landscape of labeled data is extremely sharp, but the loss curve of unlabeled data is quite flat. 2) Moreover, the optimal loss value of labeled data is much lower than that of unlabeled data. Such two intriguing discoveries reveal the essence of SSL: _The learning on scarce labeled data convergences faster with lower errors than on unlabeled data, but it is vulnerable to perturbations and has an unstable loss curvature which rapidly increases as parameters slightly vary. Therefore, the abundant unlabeled data are leveraged so that SSL models are fitted to a wider space, thus producing a flatter loss landscape and generalizing better than labeled data_. Based on the analysis, existing methods that use instance-wise consistency with mismatched generalization performance could have two non-trivial pitfalls:

* The label supervision might not be sufficiently leveraged to guide the learning process of unlabeled data.
* The richness brought by unlabeled data remains to be fully exploited to enhance the generalization performance of labeled data.

As seeking the connection in input space is quite prohibitive, we resort to exploring the parameter space and propose _FlatMatch_ which targets to encourage consistent learning performance between labeled data and unlabeled data, such that SSL models can obtain strong generalization ability without being limited by insufficient label information. Specifically, as the loss landscape on labeled data is quite unstable, we aim to mitigate this problem through applying an adversarial perturbation [24; 43; 69; 82; 83] to the model parameters so that the worst failure case can be found. Further, we enforce the worst-case model and the original model to achieve an agreement on unlabeled data via computing their prediction differences which are dubbed _cross-sharpness_. By minimizing such a cross-sharpness measure, the richness of unlabeled data can be fully utilized to calibrate the learning direction. In turn, the label information can be activated for producing accurate pseudo labels, thus successfully bridging the two datasets to enable improved SSL performance.

Figure 1: Loss landscapes of labeled data and unlabeled data obtained simultaneously from training using FixMatch  on CIFAR10 with 250 labels per class. The first row and second row show the results obtained from epoch 60 and epoch 150, respectively. The first column and second column show the 2D loss contours of labeled data and unlabeled data, respectively, and the last column shows the 1D loss curves.

Furthermore, the proposed FlatMatch is easy to implement and can be adapted to complement many popular SSL methods [10; 15; 16; 28]. Although computing the proposed cross-sharpness normally requires an additional back-propagation step, we propose an efficient strategy so that our FlatMatch can be processed without extra computational burden. Through extensive experiments and analyses on various benchmark datasets, we show that our FlatMatch achieves huge performance improvement compared to some of the most powerful approaches. Specifically, on CIFAR100 dataset with 2500 labeled examples, our FlatMatch surpasses the foremost competitor so far with 1.11% improvement. In general, our contribution can be summarized into three points:

* We identify a generalization mismatch of SSL due to the disconnection between labeled data and unlabeled data, which leads to two critical flaws that remain to be solved (Section 1).
* We propose FlatMatch which addresses these problems by penalizing a novel cross-sharpness that helps improve the generalization performance of SSL (Section 4.2).
* We reduce the computational cost of FlatMatch by designing an efficient implementation (Section 4.3).
* Extensive experiments are conducted to fully validate the performance of FlatMatch, which achieves state-of-the-art results in several scenarios (Section 5).

## 2 Related Works

SSL has been developed rapidly since the booming trend of deep learning [31; 45; 25]. We roughly introduce it through three stages, namely traditional SSL, data-augmented SSL, and open-set SSL.

**Traditional SSL:** One of the first SSL methods is Pseudo Label  which has been very effective for training neural networks in a semi-supervised manner, which relies on the gradually improved learning performance to select confident samples [73; 72]. Another classical method is Co-training  which utilizes two separate networks to enforce consistent predictions on unlabeled data so that the classification can be more accurate. Inspired by co-training, many SSL approaches are motivated to conduct consistency regularization. Temporal ensembling  proposes to leverage historical model predictions to ensemble an accurate learning target that can be used to guide the learning of the current model. Mean Teacher  further suggests such an ensemble can be operated on the model weights to produce a teacher model that can provide improved learning targets. Instead of improving the teacher model, Noisy student  finds that adding noise to the student model can also improve SSL.

**Data-Augmented SSL:** Thanks to the development of data augmentation techniques and self-supervised learning [30; 34; 68; 67], further improvements in SSL are achieved by enforcing consistency between the original data and their augmented variants. VAT  proposes to add adversarial perturbations [25; 26] to unlabeled data. By using the pseudo-label guidance to leverage such adversarial unlabeled data, the model can be more robust to strong input noises, thus showing better performance on the test set. MixMatch  employs the MixUp  technique to interpolate between the randomly shuffled examples which largely smooths the input space as well as the label space, further enhancing the generalization result. Moreover, FixMatch  is based on strong augmentation such as AutoAugment  and RandAugment  to utilize the predictions of weakly augmented data to guide the learning of strongly augmented data, which can achieve near supervised learning performance on CIFAR10. Recently, Dash , FlexMatch , and FreeMatch  advanced SSL through investigating the threshold strategy for pseudo labels. They analyze the training dynamic of SSL and design various approaches to enhance the selection of unlabeled data, which effectively boosts the SSL performance to a new level.

**Open-Set SSL:** Moreover, another branch of SSL studies the realistic scenario where unlabeled data contains out-of-distribution (OOD) data [37; 38; 32; 33; 63; 64; 62]. The common goal is to alleviate the influence of OOD such that the learning process of SSL will not be misled. Several studies propose many techniques that can achieve this goal, such as distillation , meta-learning , large-margin regularization , content-style disentanglement , and consistency regularization can also help . But in this paper, we mainly focus on the common assumption that labeled data and unlabeled are sampled independently and identically.

## 3 Preliminary: Improving Generalization via Penalizing Sharpness

Sharpness-Aware Minimization (SAM) [24; 43; 47; 69; 81] which focuses on optimizing the sharp points from parameter space so that the training model can produce a flat loss landscape. Specifically, given a set of fully-labeled data \(^{l}=\{(x_{i}^{l},y_{i}^{l})\}_{i=1}^{n}\) containing \(n\) data points \((x_{i}^{l},y_{i}^{l})\), SAM seeks to optimize a model parameterized by \(\) to fit the training dataset \(^{l}\) so that \(\) can generalize well on a test set \(^{te}\) drawn independently and identically as \(^{l}\). Such an optimization process is normally conducted via minimizing the empirical risk \(_{l}()=_{i=0}^{n}_{ce}(;g_{}( x_{i}^{l}),y_{i}^{l})\) which is realized by the cross-entropy loss \(_{ce}\) computed between the label prediction \(f^{l}=g_{}(x_{i}^{l})\) and the class label \(y_{i}^{l}\). To find the sharp points that maximally increase the empirical risk, SAM applies a weight perturbation \(\) to the model parameters \(\) and conducts the following inner maximization:

\[^{*}():=*{arg\,max}_{\|\|_{p}} _{l}(+)*{arg\,max}_{\| \|_{p}}^{}_{}_{l}()_{l}()}{\|_{ }_{l}()\|_{2}},\] (1)

where \(^{*}\) denotes the optimal perturbation which can be estimated using the gradient information of mini-batch inputs, \(\) restricts the perturbation magnitude of \(\) within a \(_{p}\)-ball, and the approximation is given by the dual norm problem .

By perturbing the original model \(\) with \(^{*}\), we can obtain the _sharpness_ measure from SAM: \(sharpness:=_{l}(+^{*})-_{l}()\) which indicates the how quickly loss changes under the worst-case model perturbation \(^{*}\). To combine the sharpness term with empirical risk minimization (ERM), the SAM objective can be differentiated as follows:

\[_{}_{l}^{SAM}:= _{}[_{l}(+^{*}( ))-_{l}()]+_{l}()_{ }_{l}(+^{*}())\] (2) \[= ())}{d}_{} _{l}()|_{+^{*}()}=_{} _{l}()|_{+^{*}()}+o(),\]

where the last second-order term \(o()\) can be discarded without significantly influencing the approximation. For detailed derivation and analysis, we refer to the original paper and related studies [1; 24; 82]. Intuitively, the gradient of SAM is computed on the worst-case point \(+^{*}\), then such a gradient is utilized to update the original parameter \(\). As a result, the model can produce a more flat loss landscape than ERM which would not change drastically, and being robust along the sharpest direction \(^{*}\) among its \(_{p}\)-norm neighbor.

Since the obtained flatness property has been demonstrated to have many benefits for generalization, such as being resistant to distribution shift [11; 39; 61], robustness against adversarial attack [69; 58], and effectiveness under label noise [24; 3; 35; 40; 77], SAM has inspired many research progresses. However, SAM is only conducted under a fully-supervised setting, and whether or how can it be leveraged to improve learning with unlabeled data is still undiscovered. Next, we carefully introduce the proposed FlatMatch which improves the generalization performance of SSL by bridging labeled data and unlabeled data with a novel cross-sharpness.

## 4 FlatMatch: Semi-Supervised Learning with Cross-Sharpness

In this section, we carefully introduce our FlatMatch. First, we describe the SSL setting in a generalized way. Then, we demonstrate a novel regularization from FlatMatch which is dubbed cross-sharpness. Finally, we explain its optimization and design an efficient implementation.

### General Semi-Supervised Learning

In SSL, we are commonly given a small set of labeled data \(^{l}=\{(x_{i}^{l},y_{i}^{l})\}_{i=1}^{n}\) containing \(n\) labeled examples \((x_{i}^{l},y_{i}^{l})\) and a large unlabeled data \(^{u}=\{x_{i}^{u}\}_{i=1}^{m}\) containing \(m\) (\(m n\)) unlabeled examples \(x_{i}^{u}\) which are drawn independently and identically. Similar to previous notations, we aim to optimize a deep model \(\) in a semi-supervised manner so that \(\) can perform well on i.i.d sampled test set \(^{te}\). The general objective for SSL is as follows:

\[_{}_{ssl}=_{}_{l}+_{u}= _{}_{i=0}^{n}_{ce}(;g_{}(x_{i}^{l}),y _{i}^{l})+_{i=0}^{m}(_{i}>)_{d}(;g _{}((x_{i}^{u})),_{i}),\] (3)where the first term is similar to Eq. 1 and denotes the empirical risk under the label supervision, the second term indicates the semi-supervised regularization for exploiting unlabeled data, the function \(_{d}()\) denotes the loss criterion for unlabeled data, such as KL-divergence or cross-entropy loss, \(()\) stands for an augmentation function that transforms the original input \(x_{i}\) to its augmented variants, \(_{i}\) represents the unsupervised learning target which can be a pseudo label or a guiding signal from a teacher model, and an indexing function \(()\) is commonly used to select the confident unlabeled data if their learning target surpasses a predefined threshold \(\). Our FlatMatch replaces the second term with a cross-sharpness regularization as described below.

### The Cross-Sharpness Regularization

The computation of cross-sharpness can be briefly illustrated in Fig. 2. Particularly, to solve the sharp loss landscape problem, as demonstrated in Section 1, we penalize the cross-sharpness regularization on each unlabeled example using a worst-case model derived from maximizing the loss on labeled data. Formally, such optimization is shown as follows:

\[_{}_{}:=_{}_{x^{ u}^{u}}_{d}(g_{}(x^{u}),g_{}(x^{u})),=+*{arg\,max}_{\|\|_{p}}_{l},\] (4)

in which \(g_{}()\) indicates the forward propagation using the parameter \(\) whose prediction result is \(f=g_{}()\), and \(\) stands for the worst-case model that maximally increases the empirical risk on labeled data. Here we drop the subscript \(i\) from each datum \(x\) for simplicity. By meaning "cross", the sharpness is not obtained by revisiting labeled data as SAM does, instead, we compute the sharpness by leveraging abundant unlabeled data to take full advantage of their generalization potential.

In detail, we leverage the original model \(\) to conduct a first propagation step as \(f^{l}=g_{}(x^{l});f^{u}=g_{}(x^{u})\), where \(f^{l}\) and \(f^{u}\) are label predictions from labeled data and unlabeled data, respectively. Then, the empirical risk on labeled data is computed as \(_{l}=_{x^{l}^{l}}_{ce}(;g_{}(x^{l }),y^{l})\). Following Eq. 1, we maximize the empirical risk \(_{l}\) to obtain the weight perturbation as \(^{*}:=_{_{l}()}{\| _{l}()\|_{2}}}\), further having the worst-case model \(=+^{*}\). Moreover, we conduct a second propagation step by passing the unlabeled data to \(\) and have \(^{u}=g_{}(x^{u})\). The second unlabeled data prediction \(^{u}\) is combined with the first prediction \(f^{u}\) obtained before to compute the cross-sharpness in Eq. 43.

**Why does crossing the sharpness work?** As shown by many theoretical signs of progress, the generalization error of SSL is largely dependent on the number of labels [5; 48]. Especially in recently proposed barely-supervised learning , the generalization error would be enormous. Although such a result may be pessimistic, unlabeled data can still be helpful. It is shown that when two distinct hypotheses on labeled data are co-regularized to achieve an agreement on unlabeled data, the generalization error can be reduced, as we quote: "The reduction is proportional to the difference between the representations of the labeled data in the two different views, where the measure of difference is determined by the unlabeled data" . Intuitively, disconnecting labeled data and unlabeled data during training may be sub-optimal. To achieve better theoretical performance, the SSL model should focus on _learning something from unlabeled data that are **not contained by labeled

Figure 2: Illustration of FlatMatch. The blue arrows and red arrows denote the learning flows related to labeled data and unlabeled data, respectively; and the black arrows indicate the computation of the worst-case model.

data_. In our FlatMatch, we can achieve this goal by enforcing \(\) and \(\), which produces the maximal loss difference on labeled data, to be consistent in classifying unlabeled data. Therefore, FlatMatch can be more effective than other instance-wise consistent methods by bridging the knowledge of labeled data and unlabeled data for training.

### Optimization and Efficient Implementation

To this end, we solve the optimization of FlatMatch by substituting \(_{u}\) in Eq. 3 with \(_{Xsharp}\) in Eq. 4:

\[:=*{arg\,min}_{}_{l}()+_ {Xsharp}(+^{*}())_{}_{l}+_{}_{Xsharp}()|_{+} _{l}()}{\|_{}_{l }()\|_{2}}.\] (5)

Particularly, the second gradient is obtained on the worst-case point \(+_{l}()}{\|_{} _{l}()\|_{2}}\), then it is applied on the original model \(\) for gradient descent. As we can see, such optimization requires an additional back-propagation on labeled data, which doubles the computational complexity. Fortunately, our FlatMatch can be implemented efficiently with no extra computational burden than the baseline stochastic gradient descent (SGD) optimizer, which is dubbed FlatMatch-e. The implementation is summarized in Algorithm 1.

```
1:Labeled dataset \(^{l}\), unlabeled dataset \(^{u}\), model \(\), memory buffer \(\) for storing historical gradients, and EMA factor \(\) for updating buffer.
2:for\(t\)do
3:ifEfficient training then
4: Compute optimal perturbation as \(^{*}=^{t}}{\|^{t}\|_{2}}\);
5:else
6: Compute gradient as \(_{}_{l}()=_{}_{x^{l}^{l}}_{cc}(;g_{}(x^{l}),y^{l})\); \(\)FlatMatch
7: Compute optimal perturbation as \(^{*}:=_{l}()}{\|_{ }_{l}()\|_{2}}\);
8: Obtain worst-case model as \(=+^{*}\);
9: Compute cross-sharpness via Eq. 4;
10: Optimizing \(\) via Eq. 5, meanwhile save the gradient \(_{}_{l}()\); \(\)Second propagation step
11: Update memory buffer as \(^{t+1}=(1-)^{t}+_{} _{l}()\); ```

**Algorithm 1** FlatMatch and FlatMatch-e

Although many efficient methods for implementing SAM have already been proposed [22; 23; 47; 83], they commonly need extra regularization or gradient decomposition, which are not harmonious to SSL and would complicate our method. In our scenario, FlatMatch has a critical difference from SAM regarding the two propagation steps: The gradients from the first step and second step are not computed on the same batch of data, _i.e._, they are crossed from labeled data to unlabeled data. Since in SSL, each labeled batch and unlabeled batch are randomly coupled, we are allowed to use the gradient computed from the last batch of labeled data to obtain the cross-sharpness from the current batch of unlabeled data. Even better, we can use exponential moving average (EMA) [30; 44; 59] to stabilize the gradient so that our cross-sharpness can be computed accurately. Next, we conduct extensive experiments to carefully validate our approach.

## 5 Experiments

In this section, we conduct extensive comparisons and analyses to evaluate the proposed FlatMatch method. We first describe the experimental setup and implementation details. Then we compare FlatMatch with many edge-cutting SSL approaches to show the effectiveness of our method. Further, we conduct an ablation study to justify our design of FlatMatch. Finally, we demonstrate the efficiency, stability, and sensitivity of FlatMatch through various analytical studies.

### Experimental Setup and Details

We follow the most common semi-supervised image classification protocols by using CIFAR10/100  SVHN , and STL10  datasets where a various number of labeled data are equally sampled from each class. Following Wang et al. , We choose Wide ResNet-28-2  for CIFAR10 and SVHN, Wide ResNet-28-8 for CIFAR100, ResNet-37-2  for STL10. All

[MISSING_PAGE_FAIL:7]

the number of labels gets smaller. When the label number reduces to only 10, the angle becomes extremely unstable and could surpass 90\({}^{}\). As a result, such a phenomenon could affect the worst-case perturbation computed by FlatMatch, which would introduce negligible noise to the training process.

However, this drawback can be properly solved by slightly augmenting the number of labels with pseudo-labeled unlabeled data. Specifically, before we start minimizing cross-sharpness, we first pre-train the backbone model with a common SSL method, such as FixMatch or FreeMatch, for 16 epochs to increase the confidence on unlabeled data. Then, we choose the most confident, _i.e._ high softmax probability, unlabeled data to be pseudo-labeled as labeled data. Different from other unlabeled data that are also trained with pseudo labels, the selected unlabeled data are fixed with their labels and act as labeled data when computing the sharpness. In this way, the cross-sharpness would be computed accurately by using both the original labeled data and augmented labeled data. Note that the augmentation with fixed labels is **only** used in the sharpness computation, when conducting the second propagation step, all unlabeled data are treated similar to general SSL strategy, such process is summarized in Algorithm 2. Under this training strategy, we dub our method as "FlatMatch (Fix label)" and show its result in Table 1. The number of fixed labeled data in CIFAR10, CIFAR100, SVHM, and STL10 is set to 500, 2500, 500, and 1000, respectively. If the number of the original labeled dataset contains enough labels, we do not add more fixed labeled data. We can see that in this scenario, our method has the best performance in all settings including the ones with 1 or 4 labels in each class, which demonstrates that using more labels can largely stabilize sharpness computation and further benefits the performance of FlatMatch, thus achieving superior results on all settings.

### Ablation Study

To carefully justify the design of our method, we compare FlatMatch with "sharp. on labeled data \(^{l}\)" and "sharp. on unlabeled data \(^{u}\)" where the former one denotes both the worst-case model \(\) and sharpness is computed on labeled data and the latter one denotes \(\) and sharpness are calculated on unlabeled data. Additionally, we compute the sharpness on the full dataset, as denoted by "sharp. on unlabeled data \(^{l}^{u}\)". Moreover, we also analyze the effect of EMA smoothing on the performance of FlatMatch-e. Specifically, we compare FlatMatch-e with setting "w/o EMA" that just uses a gradient from the last batch of labeled data to calculate our worst-case model. The ablation study is conducted using CIFAR100 with a varied number of labels, which is shown in Table 2.

First, we can see that both two choices of our method are effective. Particularly, computing sharpness only on labeled data \(^{l}\) shows smaller performance degradation than computing sharpness on unlabeled data \(^{u}\), and it even shows better results than FixMatch. Hence, we know that the sharpness of labeled data can indeed improve the performance of SSL, only having limited performance because the number of labeled data is too scarce. On the other hand, when sharpness is completely based on unlabeled data, the performance significantly drops by nearly 10% compared to "sharpness on \(^{l}\)". This is because the training process on unlabeled data contains too much noise which causes erroneous gradient computation that would hinder the effectiveness of penalizing sharpness. Furthermore, we find that "w/o EMA" shows slightly inferior performance

   Dataset &  \\  \# Label & 400 & 2500 & 10000 \\  sharp. on \(^{l}\) & 42.63\(\)0.34 & 26.85\(\)0.45 & 21.79\(\)0.24 \\ sharp. on \(^{u}\) & 49.45\(\)2.76 & 36.30\(\)2.01 & 27.05\(\)2.98 \\ sharp. on \(^{l}^{u}\) & 43.88\(\)1.64 & 27.26\(\)1.62 & 23.42\(\)1.77 \\ FlatMatch & **38.76**\(\)1.62 & **25.38**\(\)0.85 & **19.01**\(\)0.43 \\ w/o EMA & 40.64\(\)0.97 & 29.44\(\)1.56 & 23.23\(\)1.28 \\ FlatMatch-e & 38.98\(\)1.53 & 25.62\(\)0.88 & 19.78\(\)0.89 \\   

Table 2: Ablation study on CIFAR100.

to FlatMatch-e. Such degradation is consistent with the findings from Liu et al.  that the last gradient direction is distinct from the current one. As gradient descent has been conducted in the previous batch, reusing the gradient to perturb the current model might not find the perfect worst-case model on the current labeled data. Based on our observation, using EMA can stabilize the gradient can lead to accurate sharpness calculation.

### Analytical Study

In this section, we analyze the performance of FlatMatch by considering visualization, parameter sensitivity, training stability, and.efficiency.

**Loss visualization:** To show that FlatMatch can properly solve the sharp loss problem of labeled data, we train FlatMatch under the same setting as the ones demonstrated in Section 1 and plot the 2D loss contour as well as the 1D loss curve in Fig. 4. We can see that our FlatMatch can produce a much flatter loss landscape than FixMatch does in Fig. 1, where the jagged curve has been eliminated and become very smooth. Therefore, by minimizing cross-sharpness, the generalization performance on labeled data can be largely improved.

**Sensitivity analysis:** Our FlatMatch requires a hyperparameter \(\) which controls the perturbation magnitude to obtain the worst-case model. To analyze the performance sensitivity of varying \(\), we show the result on CIFAR100 in Fig. 5. We observe that small \(\) values show little impact on the test performance. However, when \(\) increases to more than 0.25, the performance would largely degrade. Moreover, among three settings with varied label numbers, we find that more numbers labels could enhance the model sensitivity against changing of \(\). For example, when changing the \(\) from 0.1to 0.25, the performance difference on 400 labels, 2500 labels, and 10000 labels are 0.05%, 1.2%, 3.42%. Generally, the optimal value for \(\) is 0.1.

**Training stability:** To validate the training stability of FlatMatch, we show the gradient norm which is an important criterion to present gradient variation in Fig. 6. We observe that the gradient norm of FlatMatch is significantly smaller than FreeMatch during the whole training phase. Therefore, minimizing the cross-sharpness can indeed improve training stability.

**Training efficiency:** We compare the training time and test accuracy of FlatMatch, FlatMatch-e, FreeMatch, FlexMatch, and FixMatch to validate the efficiency property of our method. As shown in Fig. 7, we find that despite the superior accuracy performance, FlatMatch requires more time for each iteration than the other three methods. However, the efficient variant FlatMatch-e can largely reduce the computational cost without losing too much learning performance. Hence, we can conclude that leveraging EMA for computing cross-sharpness is both effective and efficient.

## 6 Conclusion, Limitation and Broader Impact

In this paper, we propose a novel SSL method dubbed FlatMatch to address the mismatched generalization performance between labeled data and unlabeled data. By minimizing the proposed cross-sharpness regularization, FlatMatch can leverage the richness of unlabeled data to improve the generalization performance on labeled data. As a result, the supervised knowledge from labeled data can better guide SSL, and achieve improved test performance than most existing methods. Moreover, we propose an efficient implementation to reduce the computation cost. We conduct comprehensive experiments to validate our method regarding effectiveness, sensitivity, stability, and efficiency. Additionally, FlatMatch is slightly limited under barely-supervised learning due to the requirement of enough labeled data. Our method shows that SSL can be further improved by exploring generalization, which could be a potential direction in future research.

## 7 Acknowledgements

Li Shen was partially supported by STI 2030--Major Projects (2021ZD0201405). Zhuo Huang was supported by JD Technology Scholarship for Postgraduate Research in Artificial Intelligence (SC4103). Jun Yu was supported by the Natural Science Foundation of China (62276242), National Aviation Science Foundation (2022Z071078001), CAAI-Huawei MindSpore Open Fund (CAAIXSJLJ-2021-016B, CAAIXSJLJ-202-001A), Anhui Province Key Research and Development Program (202104a05020007), USTC-IAT Application Sci. & Tech. Achievement Cultivation Program (JL06521001Y), and Sci. & Tech. Innovation Special Zone (20-163-14-LZ-001-004-01). Bo Han was supported by the NSFC Young Scientists Fund (62006202), NSFC General Program (62376235), and Guangdong Basic and Applied Basic Research Foundation (2022A1515011652). Tongliang Liu was partially supported by the following Australian Research Council projects: FT220100318, DP220102121, LP220100527, LP220200949, and IC190100031.