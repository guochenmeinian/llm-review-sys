# Addressing Spatial-Temporal Heterogeneity:

General Mixed Time Series Analysis via Latent

Continuity Recovery and Alignment

 Jiawei Chen, Chunhui Zhao

State Key Laboratory of Industrial Control Technology,

College of Control Science and Engineering, Zhejiang University, China

Corresponding author: Chunhui Zhao (chhzhao@zju.edu.cn)

###### Abstract

Mixed time series (MiTS) comprising both continuous variables (CVs) and discrete variables (DVs) are frequently encountered yet under-explored in time series analysis. Essentially, CVs and DVs exhibit different temporal patterns and distribution types. Overlooking these heterogeneities would lead to insufficient and imbalanced representation learning, bringing biased results. This paper addresses the problem with two insights: 1) DVs may originate from intrinsic latent continuous variables (LCVs), which lose fine-grained information due to extrinsic discretization; 2) LCVs and CVs share similar temporal patterns and interact spatially. Considering these similarities and interactions, we propose a general MiTS analysis framework **MiTSformer**, which recovers LCVs behind DVs for sufficient and balanced spatial-temporal modeling by designing two essential inductive biases: 1) hierarchically aggregating multi-scale temporal context information to enrich the information granularity of DVs; 2) adaptively learning the aggregation processes via the adversarial guidance from CVs. Subsequently, MiTSformer captures complete spatial-temporal dependencies within and across LCVs and CVs via cascaded self- and cross-attention blocks. Empirically, MiTSformer achieves consistent SOTA on five mixed time series analysis tasks, including classification, extrinsic regression, anomaly detection, imputation, and long-term forecasting. The code is available at [https://github.com/chunhuiz/MiTSformer](https://github.com/chunhuiz/MiTSformer).

## 1 Introduction

Multivariate time series analysis is energized in various real-world applications, such as weather forecasting , activity recognition , and industrial maintenance . Empowered by deep learning, plentiful time series models have been proposed based on foundation models such as RNNs , CNNs , Transformers  and modernized MLPs . These sophisticated models have achieved increasingly remarkable performance in various time series analysis tasks, e.g., classification , forecasting , imputation  and anomaly detection .

The primary challenge in time series analysis is effectively modeling spatial-temporal patterns, including intra-variable temporal variations and inter-variable spatial correlations . So far, most current approaches naturally assume that time series data are composed solely of continuous variables, and then uniformly model spatial-temporal patterns in continuous spaces. Yet, in broad practical scenarios, the acquired data are often mixed time series (MiTS) that encompass both continuous variables (CVs) and discrete variables (DVs). Take meteorological data as an example (Fig. 1 (Left)), some sensor-derived variables are commonly recorded as CVs (e.g., temperature,humidity, and wind speed), while certain variables like cloudage and rainfall patterns are typically tracked as DVs due to measurement restrictions or distinctive nature. Up to now, mixed time series analysis is still a formidable yet under-explored problem. Essentially, MiTS presents spatial-temporal heterogeneity problems as depicted in Fig. 1 (Right). On one hand, CVs commonly encapsulate rich temporal variation information, exhibited in _autocorrelations, periodical patterns, local fluctuations_, etc, while DVs often undergo _sudden changes_ or _steady states_ due to limited value ranges, resulting in the temporal variation discrepancy between CVs and DVs that complicates temporal modeling. On the other hand, CVs generally adhere to Gaussian distributions, while DVs follow Bernoulli distributions, resulting in the distribution type discrepancy that hinders spatial correlation analysis between CVs and DVs. Neglecting these heterogeneities and equally treating mixed variables would yield insufficient and imbalanced spatial-temporal modeling problems, i.e., the model may struggle to characterize distinct temporal patterns of DVs and CVs and fail to reliably capture spatial correlations within and across DVs and CVs, posing a bottleneck for MiTS analysis.

The key to addressing the spatial-temporal heterogeneity lies in bridging the information gap between DVs and CVs. Essentially, in real-world MiTS, the observed DVs may originate from intrinsic continuous-valued factors, which are unobservable owing to extrinsic factors such as measurement limitations, storage requirements, and transmission interference. Continuing with the aforementioned meteorological example, cloud cover percentage is an intrinsically continuous variable, whose fine-grained values are hard to measure directly. In practice, discretizing it with coarse-grained discrete variable-cloudage (reflect "cloudy" or not) is sufficient for most applications and is memory-efficient. In this paper, we introduce latent continuous variables (LCVs) to describe the intrinsic continuous factors behind DVs. Given its numerically continuous nature, the LCV of cloudage, i.e., cloud cover percentage, may be spatially correlated with other observed CVs (e.g., humidity and wind speed) and exhibit similar temporal variation patterns (e.g., autocorrelation and seasonal fluctuation) with them, as both of them originate from the same meteorological system. Thereby, we can progressively recover the LCVs behind DVs by leveraging these temporal similarities and spatial interactions among CVs and LCVs. In this way, spatial-temporal dependencies of mixed variables can be completely and reliably modeled in a unified continuous numerical space, and the spatial-temporal heterogeneity problem is mitigated. Also, by bridging the mutual spatial-temporal interactions, LCVs and CVs can supply complementary information for various downstream analysis tasks.

Enlightened by the above insights, we reconcile the intrinsic tension between the two highly dependent problems - Latent Continuity Recovery and Spatial-Temporal Modeling - in one coherent and synergistic framework, **MiTSformer**, for general mixed time series analysis. By leveraging the temporal similarities and spatial interactions between LCVs and CVs, MiTSformer can gradually decipher the LCVs behind DVs and capture the complete spatial-temporal dependencies within and across LCVs and CVs. Specifically, we design a recovery network to portray LCVs behind DVs by adaptatively and hierarchically aggregating temporal contextual information. Followingly, an adversarial variable modality discrimination objective and smoothing constraints are devised to guide the learning of the recovery network, ensuring the recovered LCVs share similar temporal properties and distributions with CVs. Additionally, MiTSformer employs self-attention to learn spatial-temporal dependencies within LCVs or CVs and cross-attention to exploit those across LCVs and CVs, facilitating various downstream analysis tasks. Our contributions lie in three aspects:

1. **Novel Problem**: To the best of our knowledge, our paper pioneers the exploration of the general mixed time series analysis, which is practical and challenging. We reveal the crucial spatial-temporal heterogeneity problem, which is caused by the discrepancies in temporal variation properties and distribution types between DVs and CVs.

Figure 1: _Left_: Illustration of mixed time series. _Right_: Spatial-temporal heterogeneity problem.

2. **Customized Framework**: To solve the spatial-temporal heterogeneity problem, we propose a task-general framework MiTSformer customized for MiTS, which adaptively recovers LCVs behind DVs by leveraging the adversarial guidance of CVs and task supervisions. Moreover, MiTSformer can capture spatial-temporal dependencies within and across CVs and LCVs via self- and cross-attention blocks, thus learning sufficient and balanced spatial-temporal representations and being amenable to various mixed time series analysis tasks.
3. **Versatile Effectiveness**: Empirically, our proposed MiTSformer establishes the state-of-the-art performance on five mainstream mixed time series analysis tasks with 34 datasets covering wide-ranging real-world application domains. We believe our work makes a predominant attempt at general mixed time series analysis in practical applications.

## 2 Related Work

**General Time Series Analysis** General time series analysis aim at learning universal temporal representations by developing task-general backbones and task-specific heads for diverse tasks. To date, these methods have been designed predominantly for time series comprising continuous variables solely. As a pioneering work, TimesNet  leverages fast Fourier transform and parameter-efficient inception block to capture intra-period and inter-period variations for time series modeling. Followingly, ModernTCN  modernizes and modifies the traditional TCN by introducing larger effective receptive fields and cross-variable dependency modeling, bringing great performance and efficiency. Meanwhile, GPT2TS  leverages pre-trained language models, e.g., GPT2 , for various time series analysis tasks with task-specific fine-tuning.

Yet, most of the current works naturally assume uniformity in variable types of time series and are inapplicable for MiTS, as they lack the differentiation of distinct variable modalities. In this paper, we develop a systematic framework with delicate differentiation and deft alignment of mixed variables to support sufficient and balanced spatial-temporal modeling for general mixed time series analysis.

**Mixed Data Analysis** Previous studies have revealed the significance of mixed data analysis and made several attempts to shed light on this challenging problem. A naive solution for mixed data modeling is roughly pre-processing DVs and CVs into the same variable modality, e.g., discarding DVs or discretizing CVs by certain policies [35; 13]. However, these methods may lose vital fine-scaled information and bring errors inevitably. Towards concurrently modeling of DVs and CVs, Mixed Data RBF-ELM method  adopts a distance-based learning scheme for efficient and direct mixed data classification, while Mixed-variate Restricted Boltzmann Machine (Mv.RBM) [15; 14] construct ensembles of mixed-data Deep Belief Nets with varying depths for anomaly detection of mixed data. Another line of work treats DVs as semantic attributes of CVs and establishes the relationships between DVs and CVs by developing specific inference rules [18; 44]. More recently, researchers have utilized mixed naive Bayes models [37; 38] or variational inference  for mixed data modeling in industrial processes with different distribution priors of CVs and DVs.

However, current studies mostly focus on specific analysis tasks (e.g., designed only for classification) and may be restricted by linear, non-temporal data, or other rigorous assumptions, which are not capable of handling real-world MiTS that exhibit intricate spatial-temporal patterns. Instead, our proposed MiTSformer can model complete spatial-temporal dependencies within and across DVs and CVs and can produce task-general representations for various MiTS analysis tasks.

## 3 MiTSformer

### Problem Formulation and Motivation Analysis

**Mixed Time Series**. Given a collection of multivariate time series \(X=\{x_{1},x_{2},...,x_{p}\}\) comprising \(p\) variables with length \(T\). Among them, there are \(p-n\) continuous variables \(X^{C}=\{x_{1},x_{2},...,x_{p-n}\}^{(p-n) T}\) with continuous numerical values, and \(n\) discrete variables \(X^{D}=\{x_{p-n+1},x_{p-n+2},...,x_{n}\}^{n T}\) with discrete states. Without loss of generality, we consider the binary-valued discrete variables, whose value can be \(0\) or \(1\), i.e., \(=\{0,1\}\). Mixed time series are used as model input to support various analysis tasks, such as regression and classification.

Hampered by the spatial-temporal heterogeneity problem, directly modeling spatial-temporal dependencies of CVs and DVs without considering their discrepancies may inevitably yield non-negligiblebiases. Such research bottlenecks prompt us to exploit the underlying generation and interaction mechanism of DVs and CVs. As aforementioned, the observed DVs are potentially derived from LCVs, which undergo discretization processes due to external interferences as depicted in Fig. 2. For each DV \(x^{D}\), we adopt a corresponding LCV \(x^{LC}\) to portray its latent continuity. To reliably and completely model inherent spatial-temporal patterns within MiTS, deciphering and recovering LCVs behind DVs is indispensable. Yet, it is challenging since a single discrete state can not be directly transformed into a continuous value without proper supervision. In this study, we address this challenge by revealing and leveraging the temporal similarity and spatial interaction between LCVs and CVs:

Temporal SimilarityThe unobserved LCVs share similar temporal variation patterns (e.g., autocorrelation, periodicity, trend, etc.) with the observed CVs.

Spatial InteractionLCVs and CVs exhibit information interactions and inter-variable spatial correlations. The synergistic effect of LCVs and CVs provides complementary information for various downstream tasks.

Built upon these two insights, we design MiTSformer, which will be elaborately introduced in the following parts.

### Framework Overview

As aforementioned, there are two key steps for general MiTS analysis: 1) unifying the temporal characteristics and distribution types of DVs and CVs; 2) modeling sufficient and balanced spatial-temporal dependencies for effective representation learning. MiTSformer facilitates these two steps in a highly versatile manner with a coherent framework as depicted in Fig. 3. The overall pipeline contains two key parts: 1) _Latent Continuity Recovery_ that adaptively aggregate contextual information of DVs to recover LCVs with the adversarial alignment guidance of CVs and temporal smoothness constraints; 2) _Spatial-Temporal Attention Blocks_ that model intra- and inter-variable modality spatial-temporal dependencies with cascaded self-attention and cross-attention sub-blocks.

### Latent Continuity Recovery

Since single time points of DVs contain limited information, it is difficult to directly transform discrete states to latent continuous values. Fortunately, time series commonly present auto-correlation natures, i.e., the value of a certain time step is correlated with its adjacent ones. Specifically, for a discrete state of "1" surrounded by states "1", its latent continuous value would be relatively large, e.g., 0.9. In contrast, for a discrete state of "1" surrounded by states "0", its latent continuous value would be relatively small, e.g., 0.6. Thus, an intuitive solution for enriching the information density of a single time point of DVs is to properly leverage its adjacent context information.

Figure 3: Overall pipeline of MiTSformer. First, MiTS undergo latent continuity recovery (DVs only) and are embedded as variate tokens, which are then refined through spatial-temporal attention blocks. The acquired variate tokens are utilized both for reconstructing the original MiTS and serving various downstream tasks.

Figure 2: Connections among DVs, CVs, and LCVs.

**Contextual Aggregation Recovery Network** We convert the above insights into the model inductive bias and realize the latent continuity recovery by _adaptively and hierarchically aggregating multi-scale adjacent context information_ of DVs. Specifically, convolutional neural networks (CNNs) own an inductive bias that can aggregate receptive local information by convolutional kernels. Technically, we devise the recovery networks that receive DVs as input to generate LCVs as \(x^{LC}=(x^{D})\). As depicted in Fig. 4, the recovery network is composed of several residual dilated convolutional blocks, which employ dilated convolutional kernels along the temporal dimension to aggregate adjacent context information, and utilize residual connections to adaptively accumulate multi-scale temporal information to characterize intricate temporal patterns of LCVs. The residual dilated convolutional network is implemented by the iterative process as \(h_{i}=^{d_{i}}(h_{i-1})+h_{i-1}\), where \(h_{i}\) represents the output of the \(i\)-th residual block, \(i=1,2,,n\), \(^{d_{i}}\) denotes the convolution operation along the temporal axis to aggregate contextual information with dilation rate \(d_{i}\). The final output, \(x^{LCV}=h_{n}\), is the result after \(n\) residual blocks.

**Temporal Adjacent Smoothness Constraint**: To facilitate spatial-temporal modeling across LCVs and CVs, the recovered LCVs should be equipped with interpretable autocorrelation or trend properties, instead of "sudden changes" as DVs. To this end, we encourage the smoothness of LCVs across time with a regularization term as

\[_{}=\|(x^{D}) (x^{LC})\|_{2}^{2},=-1&1&&\\ &&&\\ &&-1&1^{(T-1) T} \]

where \(\) is the smoothness matrix and \(\) denotes the Hadamard product operation. \((x^{D})=(x^{D}_{[2:T]}-x^{D}_{[1: T-1]})\) denotes the absolute value of the first-order difference of DVs and can reflect the "_sudden change_" points (with state "1"). Overall, minimizing \(_{}\) is equivalent to minimizing \(_{t=1}^{T-1}(x^{D}_{t+1}-x^{D}_{t})(x^{LC}_{t+ 1}-x^{LC}_{t})^{2}\) by introducing the multiplication of the constant matrix \(\). Alternatively, we can adopt the K-Lipschitz continuity as smoothness constraints, where the CVs can act as guidance to determine the smoothness degree of the recovered LCVs. Empirically, we find out such design would bring similar performance.

After latent continuity recovery, raw series of \(x^{LC}\) and \(x^{C}\) are independently embedded as tokens \(^{LC}\) and \(^{C}\) through variate-wise linear projection to describe the properties of each variable.

**Adversarial Variable-Modality Discrimination**: Inspired by the temporal similarity property, the recovered LCVs should exhibit similar temporal patterns and distributions to CVs. Accordingly, we devise a variable modality discrimination objective, which is optimized in an adversarial manner as

\[*{argmin}_{_{}}(*{max}_{ _{},_{}}(_{}= [((^{C}))]+ [(1-(^{LC}))] )) \]

where \(\) denotes the variable modality discriminator. \(\) is trained to distinguish LCVs and CVs as accurately as possible, while the recovery networks are facilitated to generate LCVs with characteristics similar to CV as much as possible to confuse the discriminator. We adopt gradient reversal layer (GRL) to achieve the adversarial learning objective. In this way, we bridge the interactions between CVs and DVs and enable CVs to supply supervision signals for LCV recovery.

### Intra- and Inter-Variable-Modality Spatial-Temporal Dependency Learning

Spatial-temporal dependencies are of vital importance for time series representation learning. Specifically for MiTS, the complete spatial-temporal correlations include the ones within LCVs or CVs

Figure 4: LCV recovery with adversarial variable modality discrimination.

and the ones across LCVs and CVs, which are explicitly characterized by spatial-temporal attention blocks in MiTSformer (as shown in Fig. 5).

**Intra-Variable-Modality Self-Attention** Within each variable modality, we adopt self-attention to model their spatial-temporal dependencies as

\[}_{l}^{C}=( _{l}^{C}+([_{l}^{C}, _{l}^{C},_{l}^{C}])),\; {}_{l}^{C}=(}_{l}^{C}+ (}_{l}^{C}))\\ }_{l}^{LC}=(_{l}^ {LC}+([_{l}^{LC},_{l} ^{LC},_{l}^{LC}])),\;}_{l}^ {LC}=(}_{l}^{LC}+( }_{l}^{LC})) \]

where \(\) denotes the Multi-head Self-Attention that captures intra-variate spatial correlations by computing Softmax scores with query and key embeddings and weighted aggregating the value embeddings. \(\) denotes the feed-forward network that processes each variable token to learn intra-variate global temporal representations. \(\) denotes Layer Normalization, which is applied to individual variate tokens and has been proven effective in tackling non-stationary problems .

**Inter-Variable-Modality Cross-Attention** We adopt symmetric cross-attention sub-blocks to model the spatial-temporal interactions across LCVs and CVs as

\[_{l+1}^{C}=( }_{l}^{C}+([_{l }^{C},_{l}^{LC},_{l}^{LC}])),\; _{l+1}^{C}=(_{l+1}^{C}+(_{l+1}^{C}))\\ _{l+1}^{LC}=(_{l+1}^ {LC}+([_{l}^{LC},_{ l}^{C},_{l}^{C}])),\;_{l+1}^{LC}= (_{l+1}^{LC}+(_{l +1}^{LC})) \]

Subsequently, the acquired token embeddings \(_{L}^{LC}\) and \(_{L}^{C}\) are utilized both for 1) original MiTS reconstruction with \(_{}\) as Eq. 5, and 2) downstream tasks with task supervision loss \(_{}\), e.g., Cross Entropy loss for the classification task. See Appendix A for pipelines of each task.

**Self-Reconstruction** We devise variate-wise decoders based on MLPs to reconstruct the original DVs and CVs, which can not only provide self-supervision signals for spatial-temporal dependency learning but also guarantee the recovered LCVs retain the information of the observed DVs.

\[_{}=_{i=1}^{p-n}(_{ C}(_{L,i}^{C}),x_{i}^{C})+_{i=1}^{n}( _{LC}(_{L,i}^{LC}),x_{i}^{D}) \]

### Synergy of Latent Continuity Recovery and Downstream Tasks

Considering both latent continuity recovery and downstream analysis task, the overall optimization objective of MiTSformer is expressed as

\[_{}=_{}+_{2}_{}+_{3}_{ }}_{}+_{}}_{} \]

While seemingly separated from each other, the loss components of MiTSformer work in a collaborative fashion on two aspects: 1). **The first three self-supervision losses facilitate latent continuity recovery synergetically** to tackle the spatial-temporal heterogeneity problem. Specifically, the smoothness loss \(_{}\) favorably manifests the autocorrelation of LCVs and alleviates the sudden

Figure 5: Spatial-temporal attention blocks. _Left_: MiTS variable adjacency matrix, including the variable relationships i) _within_ CVs or LCVs and ii) _across_ CVs and LCVs; _Middle_: Intra-variable-modality self-attention for modeling spatial-temporal dependencies _within_ CVs or LCVs, and _Right_: Inter-variable-modality cross-attention for modeling those _across_ CVs and LCVs.

changes. Also, the discrimination loss \(_{}\) guarantees LCVs to be equipped with similar temporal dynamics with CVs adversarially, which guarantees a crucial condition for spatial-temporal modeling. Meanwhile, the reconstruction loss provides auxiliary self-supervision signals and constrains the LCV recovery processes to be reversible. Our experiments, particularly the ablation study displayed in Section 4.2, further justify the mutual dependency of the synergy between the three components; 2) **The latent continuity recovery losses and task loss also work collaboratively**, as reliable latent continuity recovery can bring excellent downstream task performance, while task supervision loss may, in turn, also reciprocate the recovery processes. Take MiTS classification as an example, the ideally recovered LCVs can prompt learning discriminative representations for classification, while the class label loss provides additional supervision for learning appropriate recovery functions.

## 4 Experiments

To verify the effectiveness and versatility of MiTSformer, we extensively experiment on five mainstream mixed time series analysis tasks, including _mixed time series classification, extrinsic regression, long-term forecasting, imputation, and anomaly detection_.

**Implementations** Table 1 summarizes the experiment benchmarks. For each dataset, we randomly select _half the variables_ and discretize them as DVs to generate MiTS data. More information about datasets and experimental platforms, hyperparameters and experimental configurations, and algorithm implementations can be found in Appendix A.1, A.2,A.3, respectively. The pipelines of different mixed time series analysis tasks can be found in Appendix A.5\(\)A.8.

**Baselines** We extensively compare MiTSformer with the latest and advanced models in the time series community, including CNN-based models: ModernTCN (2024), TimesNet (2023) and MICN (2023); Transformer-based models: iTransfer (2024), PatchTST (2023), Crossformer (2023), FEDformer (2022) and Pyraformer (2022); MLP-based models: LightTS (2023), DLinear (2023) and FiLM (2022). To guarantee fairness, we keep the original backbone for each method as the feature extractor, and we adopt universal task-specific heads and loss functions consistently for all methods.

### Main Results on Different Tasks

**(1) Mixed Time Series Classification** We select 10 multivariate datasets from the UEA Time Series Classification Archive  and pre-press them following . As shown in Fig. 6, MiTSformer achieves the best performance with an average accuracy of 71.9%, surpassing all powerful baselines. Besides, it can be observed that frequency-based methods FiLM and FEDformer show inferior performance, as the introduction of DVs may make it difficult to estimate the frequency reliably and yield non-negligible errors. In comparison, MiTSformer adaptively recovers and aligns the LCVs behind DVs with the guidance of both CVs and class-label supervision, thereby facilitating high-level representation learning and benefiting the classification tasks.

  Tasks & Benchmarks & Metrics & Series-length & \#Variables (\(p\)) \\  Classification & UEA (10 subsets) & Accuracy & 29\(\)1751 & 3\(\)963 \\  Extrinsic Regression & UCR (10 subsets) & MAE;RMSE & 24\(\)1140 & 4\(\)24 \\  Imputation & ETT (4 subsets), Electricity,Weather & MSE, MAE & 96 & 7\(\)321 \\  Anomaly Detection & SMD, MSL, SMAP, SWaT, PSM & Precision, Recall, F1-Score & 100 & 25\(\)55 \\  Long-term Forecasting & ETT (4 subsets), Electricity, Traffic, Weather, Exchange, ILI & MSE, MAE & 96\(\)720 \\  & & & (IL: 24\(\)60) & 7\(\) 862 \\  

Table 1: Summary of experiment benchmarks. For each dataset, we randomly select \(n= 0.5p\) variables as DVs, whose values are first MinMax normalized and then discretized into the value of 0 or 1 with the threshold 0.5 as \(((x)>0.5)\). See Table 5 for more details.

Figure 6: Classification Results (Acc \(\))

[MISSING_PAGE_FAIL:8]

Due to the missing values, the imputation task requires the model to deeply exploit the underlying temporal dependencies and spatial correlations from partial observations. According to Table 2, MiTSformer achieves the best performance on most tasks. Through the recovery of LCVs and the intra- and inter-variable modality attention mechanisms, MiTSformer can effectively bridge spatial-temporal information interactions between CVs and DVs. In this way, not only can CVs exploit useful information for self-imputation by mining temporal and spatial correlation themselves, but also DVs can provide reliable auxiliary information for more accurate imputation of CVs.

**(5) Mixed Time Series Long-term Forecasting** We follow the settings of prediction lengths and benchmarks as , including ETT , Electricity (UCI), Weather (Wetterstation), Exchange  and ILI (CDC), corresponding to different applications. We focus on forecasting both DVs and CVs.

Since CVs contain more fine-grained information granularity and can more adequately evaluate the model forecasting performance, we mainly focus on the prediction accuracy of CVs, which are summarized in Table. 3. As reported, MiTSformer presents the best performance on most tasks (76 % according to Table 16), surpassing extensive advanced MLP-based, Transformer-based and CNN-based models. In addition, recent baselines- modernTCN and Transformer present great performance due to their delicate design of global temporal receptive fields.

Figure 9: Visualization of LCV recovery. For each subfigure, the _Left_ plots the observed DVs, and the _Right_ plots the actual LCVs (red line) and recovered LCVs (black line). The grey rectangular patches denotes the area where the observed DV is “1”.

   &  &  &  &  &  &  &  &  &  &  &  &  \\  & & & & & & & & & & & & & & & & & \\  & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) & (Omni) \\  Metric & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE & MAE MSE \\  ETTm & **0.376** & **0.328** & 0.385 & 0.340 & 0.380 & 0.334 & 0.403 & 0.357 & 0.379 & 0.330 & 0.407 & 0.385 & 0.331 & 0.394 & 0.384 & 0.381 & 0.331 & 0.397 & 0.357 & 0.425 & 0.371 & 0.484 & 0.470 \\  ETTm2 & **2.365** & **0.363** & 0.361 & 0.371 & 0.376 & 0.398 & 0.368 & 0.364 & 0.367 & 0.385 & 0.528 & 0.599 & 0.529 & 0.578 & 0.512 & 0.568 & 0.376 & 0.389 & 0.386 & 0.389 & 0.386 & 0.389 & 1.732 \\  ETTm1 & **0.414** & **0.373** & 0.427 & 0.393 & 0.415 & 0.388 & 0.446 & 0.412 & 0.416 & 0.381 & 0.245 & 0.376 & 0.448 & 0.404 & 0.478 & 0.469 & 0.417 & 0.370 & 0.430 & 0.430 & 0.437 & 0.390 & 0.526 & 0.543 \\  ETTm2 & **0.440** & **0.449** & 0.442 & 0.472 & 0.442 & 0.480 & 0.453 & 0.490 & 0.440 & 0.464 & 0.917 & 1.422 & 0.692 & 1.000 & 0.729 & 1.063 & 0.675 & 0.982 & 0.450 & 0.490 & 0.476 & 0.508 & 1.304 & 2.548 \\  Weather & **0.326** & 0.268 & 0.334 & 0.279 & 0.328 & 0.269 & 0.348 & 0.290 & 0.332 & 0.276 & 0.338 & **0.287** & 0.356 & 0.278 & 0.354 & 0.277 & 0.346 & 0.274 & 0.353 & 0.291 & 0.386 & 0.322 & 0.357 & 0.274 \\  Exchange & 0.445 & 0.398 & 0.452 & 0.412 & 0.448 & 0.403 & 0.503 & 0.498 & 0.453 & 0.417 & 0.596 & 0.632 & 0.412 & 0.323 & 0.459 & 0.402 & **0.409** & **0.318** & 0.449 & 0.398 & 0.564 & 0.599 & 0.650 & 0.679 \\  ILI & **0.779** & **1.482** & 0.995 & 1.132 & 0.932 & 1.957 & 0.891 & 2.015 & 0.973 & 2.140 & 1.140 & 2.962 & 1.358 & 2.960 & 1.734 & 0.432 & 1.340 & 3.197 & 1.188 & 2.701 & 2.673 & 0.303 & 1.096 & 2.747 \\  Electric & **0.300** & **0.168** & **2.393** & 0.207 & 0.174 & 0.288 & 0.187 & 0.295 & 0.207 & 0.326 & 0.237 & 0.295 & 0.138 & 0.339 & 0.240 & 0.314 & 0.220 & 0.316 & 0.234 & 0.351 & 0.248 & 0.400 & 0.319 \\  Traffic & **0.312** & **0.499** & 3.372 & 0.590 & 0.366 & 0.635 & 0.352 & 0.803 & 0.360 & 0.603 & - & - & 0.355 & 0.692 & 0.465 & 0.824 & 0.21 & 0.742 & - & - & 0.416 & 0.774 & 0.456 & 0.945 \\  

Table 3: Long Term Forecasting of CVs. “-” denotes out of memory. See Table 16 for full results.

### Ablation Studies

To further verify the effectiveness of each key design, we conduct ablation experiments on mixed time series classification, long-term forecasting, and anomaly detection tasks. The results are summarized in Table 4, where "w/o LCVs" denotes removing \(_{}\), \(_{}\), and \(_{}\) together, and "w/o Cross-Att" denotes removing the cross-attention sub-block and adopt self-attention sub-block solely.

**Latent Continuity Recovery** The three loss terms, \(_{}\), \(_{}\), and \(_{}\) support the latent continuity recovery from different perspectives and work collaboratively. As shown in Table 4, ablating each loss term would lead to performance degradation for different tasks. Remarkably, the employment of all recovery loss functions in conjunction yields the optimal result.

**Attention Backbones** The cross-attention block is devised to bridge the information prorogation among LCVs and CVs by modeling spatial-temporal dependencies across LCVs and CVs, as LCVs and CVs provide complementary information for analysis tasks. The results in Table 4 also emphasize the importance of cross-variable-modality dependency modeling for MiTS analysis.

### Visualization and Model Investigations

**Visualization of the Recovered LCVs** To verify the interpretability of LCV recovery, we provide visualization plots in Fig. 9. We find that DVs commonly show patterns of "_sudden changes_" or "_steady states_", which are less informative for analyzing spatial-temporal correlations. Fortunately, MiTSformer not only recovers their latent fine-grained and informative temporal variation patterns but also further leverages them for spatial-temporal representation learning, thereby mitigating the spatial-temporal heterogeneity challenge and achieving superior performance.

**Additional Analysis** We analyze the model efficiency in the Appendix. B, showing MiTSformer maintains great performance and efficiency compared with most baselines. In addition, we investigate hyperparameter sensitivity in the Appendix C. The results demonstrate that (1) MiTSformer is relatively stable in the selection of odel capacity-related hyper-parameters \(d_{model}\) and number of layers \(L\); (2) MiTSformer is quite robust to the weights of loss items (i.e., \(_{1}\), \(_{1}\), and, \(_{3}\)), and moderate weights bring optimal performance.

## 5 Conclusion and Future Work

This paper focuses on a challenging yet seldomly explored problem in the time series community and provides a systematic and universal solution for mixed time series analysis. To address the spatial-temporal heterogeneity problem, we first reveal the LCVs behind DVs and try to recover them for sufficient and balanced spatial-temporal modeling. Accordingly, MiTSformer is developed as a task-general mixed time series analysis framework by leveraging the temporal similarities and spatial interactions between LCVs and CVs. MiTSformer can perform adaptive LCV recovery for DVs via the adversarial guidance of CVs as well as smooth constraints, and model complete spatial-temporal dependencies via self- and cross-attention blocks. With extensive empirical evaluations, MiTSformer shows great practicality, superiority, and versatility in five mainstream mixed time series analysis tasks. In the future, it is of interest to empower MiTSformer with advanced pre-training techniques and powerful large language models for broader applications of mixed time series.

   &  &  &  &  \\   & \(_{}\) & \(_{}\) & \(_{}\) & Cross-Att & UCR Avg. & ETTm1 & ETTm2 & ETTh1 & ETTh2 & Avg. & SMD & MSI. & SMAP & Avg. \\  MiTSformer & ✓ & ✓ & ✓ & ✓ & **7.19** & 0.415 & 0.439 & 0.442 & 0.455 & **0.488** & 87.84 & 90.63 & **89.90** \\ \(}{{o}}_{}\) & ✓ & ✓ & ✓ & ✓ & 70.1 & 0.416 & 0.440 & 0.446 & 0.459 & 0.440 & 56.56 & 83.24 & 95.70 & 88.50 \\ \(}{{o}}_{}\) & ✓ & ✗ & ✓ & ✓ & 70.7 & 0.416 & 0.437 & 0.445 & 0.463 & 0.440 & 87.58 & 82.41 & 95.73 & 88.57 \\ \(}{{o}}_{}\) & ✓ & ✓ & ✓ & ✓ & 69.7 & 0.463 & 0.478 & 0.624 & 0.509 & 0.519 & / & / & / & / \\ \(}{{o}}\) LCVs & ✗ & ✗ & ✗ & ✓ & 69.3 & 0.501 & 0.479 & 0.626 & 0.509 & 0.529 & / & / & / & / \\ \(}{{o}}\) Cross-Att & ✓ & ✓ & ✓ & ✗ & 70.2 & 0.428 & 0.442 & 0.451 & 0.461 & 0.446 & 84.92 & 84.10 & 95.79 & 88.27 \\  

Table 4: Ablation analysis. For anomaly detection tasks, we do not ablate \(_{}\), as it is needed to support anomaly criterion calculation. The corresponding results are omitted with “_l_”.