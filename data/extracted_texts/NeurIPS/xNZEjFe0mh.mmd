# Communication-Efficient Federated Group

Distributionally Robust Optimization

 Zhishuai Guo, Tianbao Yang

Department of Computer Science and Engineering

Texas A&M University

zhishguo@tamu.edu,tianbao-yang@tamu.edu

Corresponding Author

###### Abstract

Federated learning faces challenges due to the heterogeneity in data volumes and distributions at different clients, which can compromise model generalization ability to various distributions. Existing approaches to address this issue based on group distributionally robust optimization (GDRO) often lead to high communication and sample complexity. To this end, this work introduces algorithms tailored for communication-efficient Federated Group Distributionally Robust Optimization (FGDRO). Our contributions are threefold: Firstly, we introduce the FGDRO-CVaR algorithm, which optimizes the average top-K losses while reducing communication complexity to \(O(1/^{4})\), where \(\) denotes the desired precision level. Secondly, our FGDRO-KL algorithm is crafted to optimize KL regularized FGDRO, cutting communication complexity to \(O(1/^{3})\). Lastly, we propose FGDRO-KL-Adam to to utilize Adam-type local updates in FGDRO-KL, which not only maintains a communication cost of \(O(1/^{3})\) but also shows potential to surpass SGD-type local steps in practical applications. The effectiveness of our algorithms has been demonstrated on a variety of real-world tasks, including natural language processing and computer vision.

## 1 Introduction

Federated learning enables effective model training without the need to share raw data . It is essential in contexts where data privacy and ownership are paramount, such as in inter-hospital collaborations  and mobile device networks . However, clients often have data of varying volumes and distinct distributions, which poses notable challenges in maintaining generalization behavior . Generalization here refers to the model's ability to perform consistently across different clients, including those that have not participated in the training .

In this study, we tackle the issue using federated group distributionally robust optimization (FGDRO), formulated as follows:

\[_{}F():=_{_{N}}_{i=1}^{N} _{i}_{i}()-().\] (1)

Here, \(\) denotes a machine learning model, and \(N\) represents the number of clients. For each client \(i\), \(_{i}\) represents its local data distribution, and \(_{i}()=_{_{i}}(;)\) represents the loss calculated from that local distribution. \(_{N}\) denotes a \(N\)-dimensional simplex, which constrains \(_{i}p_{i}=1\). The vector \(=[_{1},...,_{N}]\) comprises the weights assigned to each of the \(N\) clients. The function \(()\) acts as a regularization term, with \(>0\) being an adjustable parameter. This framework aims to assign higher weights to machines with greater losses while discouraging substantial deviations of these weights from a specified distribution.

Our study concentrates on two particular forms of the regularization term \(\), which are well-established regularization techniques , each suited to different tasks and data distributions. Specifically, CVaR is defined as \(()=_{[0,1/K]}()\). In this scenario, \(()\) is set to 0 if each weight \(_{i}\) falls within the range of \([0,1/K]\), and is infinite otherwise. FGDRO-CVaR focuses on optimizing for worst-case scenarios or the average of the worst-case losses, making it particularly effective in high-stakes applications like healthcare and finance, where avoiding extreme losses is crucial. However, it can be sensitive to outliers or malicious client attacks. FGDRO-KL, on the other hand, uses Kullback-Leibler (KL) divergence,expressed as \(()=_{i=1}^{N}_{i}(N_{i})\). This version of \(\) penalizes deviations of the weight distribution \(\) from a uniform distribution. Fundamentally, when \(()\) is strongly convex, as in the case of KL divergence, \(F()\) can enjoy a smoothness property, while non-strongly convex \(()\) would result in non-smooth \(F()\). In contrast to CVaR, KL is a softer regularizer to promote smoother and more stable learning. Thus, it can be beneficial in scenarios where robustness to outliers or malicious clients is needed. FGDRO-KL-Adam further enhances FGDRO-KL by incorporating Adam-type updates.

Previous research addressing these optimization problems in federated learning has struggled with high communication and sample complexity issues, which are basically due to inefficient updates of \(\) on local machines. For example, Deng et al.  examined a particular case of the general formula (1) using a CVaR constraint with \(K=1\), and developed an algorithm for KL regularization as well. They update \(\) only in global communication rounds, while local steps only optimize the local loss function using stochastic gradient descent (SGD). To achieve a \(\)-stationary point or a point near to an \(\)-stationary point, where an \(\)-stationary point has a (sub)gradient \(\| F()\|^{2}^{2}\), their methods required a communication cost of \(O(1/^{12})\) and a sample complexity of \(O(1/^{16})\) on each client. For FGDRO with KL regularization,  achieves a communication cost of \(O(1/^{2})\), but it requires the use of large data batches in local update steps in order to get good approximation for the surrogate of \(\), resulting in a total sample complexity of \(O(1/^{6})\) per machine.

To overcome these limitations, this paper presents specialized algorithms FGDRO-CVaR and FGDRO-KL for FGDRO with CVaR constraint and KL regularization, respectively. Instead of dealing with the constrained primal-dual formulation in (1), we consider their equivalent forms with a compositional structure that get rid of the high-dimensional constrained variable \(\). We summarize the complexity results in Table 1.

**For FGDRO with CVaR constraint**, we are the first to consider a constraint-free equivalent form and develop a communication-efficient algorithm for it, significantly reducing communication costs, as shown in Table 1. In addition to sharing machine learning models, we only introduce an additional scalar threshold to select participants in each round, minimizing additional costs. The equivalent compositional form is a non-smooth two-level compositional function with one auxiliary variable \(s\), which works as a threshold. Only machines whose local losses are greater than \(s\) are supposed to contribute to updating the model. In this way, we can simply update the constraint-free scalar variable \(s\) locally in each client and average \(s\) in communication rounds. However, we do face challenges with non-smooth compositional optimization problems. Our first algorithm FGDRO-CVaR effectively

    & FGDRO with a CVaR constraint & FGDRO with a KL regularization \\   & Communication & Sample & Communication & Sample \\  & Complexity & Complexity & Complexity \\  DRFA  & \(O(})\) & \(O(})\) & \(O(})\) & \(O(})\) \\  DR-DSGD  & – & – & \(O(})\) & \(O(})\) \\  NDP-SONT  & \(O(})\) & \(O(})\) & \(O(})\) & \(O(})\) \\  This Work & \(O(})\) & \(O(})\) & \(O(})\) & \(O(})\) \\   

Table 1: Comparison of communication cost and sample complexity on each machine to achieve \(\)-stationary point or near to \(\)-stationary point, where \(\)-stationary point has a (sub-)gradient \(\| F()\|^{2}^{2}\). NDP-SONT denotes the naive deployment of the SONT algorithm  in a federated environment, communicating in all iterations.

addresses this issues and achieves a communication cost of \(O(1/^{4})\) and a sample complexity of \(O(1/^{8})\) on each machine.

**For FGDRO with KL regularization**, while previous literature has explored constraint-free compositional reformulations, they often require large batch sizes on each machine to estimate gradients, making this approach impractical and leading to high sample complexity. In contrast, we utilize moving averages that can work with smaller data batches while still providing accurate gradient estimates, enhancing the efficiency of our method. The equivalent compositional form we consider is a smooth three-level compositional function. In this case, the weights for the clients depend on both local loss functions and global loss functions. We use moving average estimators of these statistics and update the estimators locally. In communication rounds, in addition to averaging the model \(\), the machines will average the estimator of the global loss function. We have reduced the communication cost and the computation cost compared to the literature as presented in Table 1.

To further enhance our approach, we have developed **an adaptive algorithm for solving FGDRO with KL regularization**, named FGDRO-KL-Adam. Stochastic adaptive methods apply variable step sizes for each coordinate based on historical gradient information, often yielding better results than non-adaptive techniques, as evidenced by a wealth of research [13; 36; 49; 69]. In federated learning, while Reddi et al.  have developed a federated adaptive algorithm and shown its effectiveness in various tasks. However, it limits adaptive steps to global updates on the server, with local updates relying on standard SGD, which may lead to suboptimal results. Moreover, their method is primarily designed for Empirical Risk Minimization (ERM) and is not applicable to address compositional optimization problems. Our FGDRO-KL-Adam allows local updates to use Adam-type updates, which introduces the challenge of handling unbiased gradients, further complicated by the use and updating of the second-order moment. To this end, we update the first-order momentum and second-order momentum locally and then average them globally during communication rounds. Moreover, our analysis carefully manages the moving estimates of the first and second-order moments, ensuring that the solution provably converges.

Our FGDRO-KL-Adam enables local updates with Adam-type methods, which raises the challenge of maintaining unbiased gradients, especially with the adjustment of the second-order moment. Our analysis meticulously handles the moving estimates of both first and second-order moments to guarantee provable convergence. The first-order momentum and second-order momentum are updated locally and then averaged during communication rounds.

In summary, our paper contributes in three main areas. First, our FGDRO-CVaR algorithm greatly reduces both communication costs and sample complexity for FGDRO with CvaR constraint problems. Second, our FGDRO-KL algorithm achieves a better sample complexity while maintaining the same communication costs as the existing results. Third, our FGDRO-KL-Adam integrates adaptive step sizes with Adam-type updates, which has the potential to surpass the performance of conventional SGD-based approaches. Extensive testing on diverse real-world datasets has shown that our approach achieves superior performance while substantially reducing communication overhead.

## 2 Related Work

Federated learning has gained significant attention due to its potential to train machine learning models using data from various sources while ensuring data privacy [38; 48; 54]. Two central challenges to this field are communication cost and client heterogeneity, which have been extensively explored in the literature [63; 76; 77; 73; 62; 34; 64; 2; 31; 68; 4; 33; 35; 71; 70; 34; 18]. This section will dive into the body of literature that focuses on these specific challenges.

Non-IID Clients in Federated Learning (FL)One of the key challenges in Federated Learning (FL) is managing client heterogeneity, particularly the issue of non-IID (nonindependently and identically distributed) data across client networks. Efforts to overcome the negative implications of data diversity have led to the development of model personalization techniques [47; 10; 44; 82; 45; 43; 75; 19; 41]. However, these approaches face challenges when dealing with data from unseen or unidentifiable groups. For a comprehensive examination of the challenges and strategies concerning non-IID clients in federated learning, the readers are directed to .

Federated Group Distributionally Robust OptimizationSince Group Distributionally Robust Optimization has shown effectiveness in addressing non-iid data in centralized setting [14; 51; 12; 56],previous research has investigated Federated Group Distributionally Robust Optimization (FGDRO) to address the challenges posed by non-IID clients in federated settings [50; 11]. The DRFA algorithm  focuses on a specific instance of (2), applying a CVaR constraint on \(\) with \(K=1\). It samples machines based on updated probabilities to allow local updates, reducing the need for communication, with these probabilities managed by a central server. However, this approach results in significant communication costs of \(O(1/^{12})\) and sample complexity of \(O(1/^{16})\) per machine to achieve an \(\)-stationary point. Recent developments in  introduced algorithms for handling Group DRO with a CVaR constraint in centralized settings, but adapting these to federated learning entails substantial communication overheads of \(O(1/^{6})\). Moreover,  introduced the SCAFF-PD algorithm, which is only applicable in convex scenarios and requires the use of the complete dataset in each training round. Regarding KL regularization,  achieved a communication cost of \(O(1/^{3})\), but required the use of large data batches, resulting in a total sample complexity of \(O(1/^{6})\) per machine.  has studied FGDRO with KL regularization in a decentralized setting, which would incur a communication cost of \(O(1/^{4})\) if directly applied to a centralized federated learning setting.

Federated Adaptive AlgorithmStochastic adaptive methods for minimization in non-convex stochastic optimization have garnered significant interest in recent years [13; 36; 49; 69; 42; 84; 65; 7; 46; 25; 16; 81]. These methods, known for assigning unique step sizes to each coordinate, often outperform their non-adaptive counterparts. In federated learning, Reddi et al.  have advanced the field with an adaptive algorithm. However, their methodology predominantly applies adaptive steps at the global server level, with local updates still dependent on SGD. This could lead to suboptimal performance. Furthermore, their approach was tailored for Empirical Risk Minimization (ERM) problems and could not be applied for problems considered in this work.

## 3 Preliminaries

A function \(f\) is \(C\)-Lipschitz if \(f()-f() C\|-\|\). A differentiable function \(f\) is \(L\)-smooth if \(\| f()- f()\| L\|-\|\), where \( f()\) denotes the gradient. For a non-differentiable function \(f\), its subdifferential \( f()\) is defined as a set of all subgradients as \( f()=\{|f() f()+ ,-+o(\|-\|)\}\) as \(\). When the context is clear, we also overload the notation \( f()\) to denote one subgradient from the subdifferential set. We use \( f(;)\) or \( f(;)\) to represent an unbiased estimator of gradient or subgradient with a randomly drawn sample \(\). Additionally, a function \(f\) is \(\)-weakly convex if \(f() f()+ f(),- -\|-\|^{2}\).

For a smooth function \(f()\), \(\) is an \(\)-stationary point if \(\| f()\|^{2}^{2}\). For non-smooth functions, \(\) is an \(\)-stationary point if \(\|dist(, f())\|^{2}^{2}\), where \(dist(,S)=_{^{} S}\|-^{ }\|_{2}\) measures the distance between a point \(\) and a set \(S\). For non-smooth functions, since it is usually difficult or even impossible to find an \(\)-stationary point, we instead seek an \(\)-near stationary point.

**Definition 3.1**.: \(\) is an \(\)-near stationary point of \(f()\) if \(^{}\) such that \(\|-^{}\|_{2}\) and \(dist(, f(^{}))\).

## 4 FGDRO-CVaR

In this section, we present our algorithm designed to tackle Federated Group Distributionally Robust Optimization (FGDRO) with a CVaR constraint. This problem poses substantial challenges due to the complexity of both CVaR and simplex constraints. Typically, during local updates, individual machines do not have access to adequate information to appropriately adjust the weight vector \(\). Prior approaches, such as the one proposed by , mitigate this issue by updating \(\) during global communication rounds, but results in slower convergence rates. To this end, we reformulate the problem into an equivalent two-level compositional optimization problem without constraints:

\[_{}_{s}F(,s):=_{i=1}^{N}f(g_{i}( )-s)+s.\] (2)

where \(f()=()_{+}\) and \(g_{i}()=_{_{i}}(, )\) is a local loss and \(s\) is intended to serve as a threshold value. With \(s=_{s^{}}_{i=1}^{N}f(g_{i}()-s^{ })+s^{}\), only the \(K\) clients with the highest losses will have losses greater than \(s\)[53; 83]. During the training phase, \(K\) clients with the highest losses are expected to predominantly influence the optimization process.

The formulation (2) replaces the constrained high-dimensional vector \(\) with a single unconstrained scalar variable \(s\). However, this adjustment introduces new challenges due to the compositional structure and the non-smooth nature of the outer function \(f\). As a result, it is biased to estimate subgradient \( f(g_{i}()-s) g_{i}()\) using a batch of samples. To address this, it is common practice to create an accurate estimate of \(g_{i}()\). Specifically, we employ a moving average \(\) as our accurate estimate:

\[u_{i,t}^{r}=(1-_{1})u_{i,t-1}^{r}+_{1}(;_{i, t}^{r}).\] (3)

And then the estimators for sub-gradient of \(\) and \(s\), namely \(,v\) are computed using \(u\). It is notable that for \(s\), it is updated locally using local data and averaged between clients in communication rounds. It will converge alongside \(\) to an \(\)-near stationaty point. This is a fundamental reason why our method achieves a lower communication complexity compared to , as the latter can only update the weight variables at the server node in the communication rounds.

```
1:Initialization: \(}^{1}\), \(^{1}=0\), \(u_{i,t}^{0}=0\),
2:for\(r=1,...,R\)do
3:\(_{i,0}^{r}=}^{r}\), \(s_{i,0}^{r}=^{r}\), \(u_{i,0}^{r}=u_{0,I}^{r-1}\)
4:for\(t=1,...,I\)do
5: Each machine samples data \(_{i,t}^{r}\)
6:\(u_{i,t}^{r}=(1-_{1})u_{i,t-1}^{r}+_{1}(_{i,t-1}^{r}; _{i,t}^{r})\)
7:\(v_{i,t}^{r}=- f(u_{i,t}^{r}-s_{i,t-1}^{r})+\), and \(s_{i,t}^{r}=s_{i,t-1}^{r}-_{2}v_{i,t}^{r}\)
8:\(_{i,t}^{r}= f(u_{i,t}^{r}-s_{i,t-1}^{r})(_{i,t-1}^{r},_{i,t}^{r})\), and \(_{i,t}^{r}=_{i,t-1}^{r}-_{1}_{i,t}^{r}\)
9:endfor
10:\(}^{r+1}=_{i=1}^{N}_{i,I}^{r}\), \(^{r+1}=_{i=1}^{N}s_{i,I}^{r}\)
11:endfor
12:Output: \(}=_{i=1}^{N}_{i,t^{}}^{r}\), where \(r^{}\) and \(t^{}\) are sampled from \([1,R]\) and \([1,I]\), respectively. ```

**Algorithm 1** FGDRO-CVaR

We present the formalization of our FGDRO-CVaR method in Algorithm 1. Next, we show the convergence results of FGDRO-CVaR. We make the following assumptions regarding problem (2).

**Assumption 4.1**.: (1) \( i\) and \( D_{i}\), \((,)\) is \(C_{g}\)-Lipschitz and \(L_{g}\)-smooth. (2) \(_{_{i}}\|(;)-  g_{i}()\|^{2}^{2}\), \(_{_{i}}\|(;)-g_{i}( )\|^{2}^{2}\).

**Remark.** The first assumption about Lipschitz continuity and smoothness of \(g_{i}\) is standard in compositional optimization . The second assumption of bounded variance is also common. Assumption 4.1 leads to \(F(,s)\) being weakly convex, which is a key step in the analysis as shown in Appendix A.2

The behavior of the estimator \(u\) is examined through the following lemma.

**Lemma 4.2**.: _Under Assumption 4.1, by setting \(=O(1/(R)^{3/2})\), \(_{1}=O(1/R)\), \(I=O(R)\), Algorithm 1 ensures that_

\[\|u_{i,t}^{r}-g_{i}(}_{t}^{r})\|^{2}(1-_{1}) \|u_{i,t-1}^{r}-g_{i}(}_{t-1}^{r})\|^{2}+2_{1}^{2 }^{2}+3_{2}^{2}I^{2}C_{g}^{2}+}C_{g}^{2}\| }_{t}^{r}-}_{t-1}^{r}\|^{2}.\]

The convergence result of FGDRO-CVaR is given in the following theorem.

**Theorem 4.3**.: _Under Assumption 4.1, by setting \(=O(1/(R)^{3/2})\), \(_{1}=O(1/R)\), \(I=O(R)\) and \(=2L_{g}\), the Algorithm 1 ensures that for the output \((},)\), there exists \((^{},s^{})\) that_

\[\|dist(,F(^{},s^{}))\|^{2} 1/(\| }-^{}\|_{2}^{2}+\|-s^{}\|_{2}^{2})  O(}).\] (4)

**Remark.** The analysis has utilized Moreau envelop to address the nonsmooth issue . To achieve an \(\)-near stationary point of \(F()\), we need to set \(R=O(1/^{4})\) and \(I=O(1/^{4})\), and thus the sample complexity on each machine is \(RI=O(1/^{8})\). The total sample complexity of \(O(n/^{6})\)by  is achieved by the STORM estimator  which incurs additional memory and computational costs due to the requirement of computing gradients using two models at each iteration. Without the STORM estimator,  would exhibit a total sample complexity of \(O(n/^{8})\). When deployed in a federated setting, the complexity for each machine would be \(O(1/^{8})\), aligning with our results and demonstrating that our approach achieves a linear speed-up in terms of number of machines. Additionally, although we aggregate certain scalar variables (in FGDRO-CVaR, the scalar variable s; in FGDRO-KL and FGDRO-KL-Adam to be presented later, the scalar variable v), similar to the technique in the Remark 3.1 of , we can aggregate these variables using homomorphic encryption, ensuring that their exact values remain confidential.

## 5 FGDRO-KL

In this section, we present our FGDRO-KL algorithm for solving problem (1) with a KL regularization. Unlike the CVaR constraints that focus on the top K clients, KL regularization takes into account all clients, assigning them varying weights. Additionally, FGDRO with KL regularization is smooth, and strongly concave with respect to \(\). Nevertheless, it is subject to the simplex constraint on \(\). To address this, we use an equivalent form derived from the KKT conditions, as referenced in [56; 30]:

\[_{}F()=(_{i=1}^{N}( _{_{i}}(;)/ )).\] (5)

This formulation eliminates the constrained vector \(\), and \(F()\) is smooth since KL regularization is strongly concave . However, this formulation has a three-level composition structure and thus, using a batch of data in a three-level composition can result in biased gradient estimation. Furthermore, the gradients on one machine are depend on other machines.

Specifically, we denote \(g_{i}()=(_{_{i}}(;)/)\) and \(g()=_{i=1}^{N}g_{i}()\), with \((;_{i})=_{_{i}} (;)\), then, the gradient of \(F()\) in (5) is given by:

\[ F()=_{i=1}^{N}()} {g()}(;D_{i}).\] (6)

It is crucial to recognize that the gradient for machine \(i\), i.e., \((;_{i})\), is scaled by \(g_{i}()/g()\). This scaling indicates that machines experiencing larger loss functions exert more influence over the training process. To mitigate the biased gradient estimation, we approximate \(g_{i}()\) and \(g()\) based on moving average estimators \(u\) and \(v\). On each machine, \(u\) serves as a moving average estimator for the local loss function \((;_{i})\), with \((u_{i,t}^{r}/)\) providing a local approximation of \(g_{i}()\). \(u\) is updated and maintained locally without need for averaging during communication rounds. \(v\) estimates the global statistic \(g()\), and is updated locally but averaged during global communication rounds. Subsequently, a moving average estimator of the gradient, denoted as \(\) is constructed using \(u\) and \(v\). For specific update rules, please refer to Algorithm 2.

For analysis, we make the following assumptions regarding problem (1) with a KL regularization:

**Assumption 5.1**.: (1) \( i\) and \( D_{i}\), \(g_{i}()\) is \(C_{g}\)-Lipschitz and \(L_{g}\)-smooth. (2) \(_{_{i}}\|(;)- (;_{i})\|^{2}^{2}\), \(_{_{i}}\|(;)- (;_{i})\|^{2}^{2}\). (3) \(f\) is \(C_{f}\)-Lipschitz and \(L_{f}\)-smooth. (4) \( i\) and \( D_{i}\), \(0(;) C_{0}\), \(()\) is \(C_{}\)-Lipschitz and \(L_{}\)-smooth.

The behavior of the \(u\) and \(v\) estimators can be bounded similar to the previous section and are shown in Appendix B. The estimator \(\) for gradient can be bounded as

**Lemma 5.2**.: _Under Assumption 5.1, with proper constants \(C_{1}\) and \(G\), by setting \(=O(})\), \(_{1}=O(})\), the Algorithm 2 ensures that_

\[\|}_{t}^{r}- F(}_{t}^{r})\|^{2}(1- }{2})\|}_{t-1}^{r}- F(}_{t- 1}^{r})\|^{2}+_{3}C_{}^{2}C_{1}^{2}_{i=1}^{N} \|u_{i,t-1}^{r}-(}_{t-1}^{r};_{i})\|^{2}\]

\[+_{3}C\|_{t}^{r}-g(}_{t}^{r})\|^{2}+3\| F( }_{t-1}^{r})\|^{2}+_{3}^{2}C_{1}^{2}}{N}+2 _{3}C_{1}^{2}L_{}^{2}^{2}I^{2}G^{2}.\]The precisions of the \(u,v,\) estimators depend on each other. The idea is to get \(\|u_{i,t}^{r}-(}_{i}^{r};_{i})\|^{2}\), \(\|_{t}^{r}-g(}_{i}^{r})\|^{2}\), \(\|}_{t}^{r}- F(}_{t}^{r})\|^{2}\) and \(\| F(})\|^{2}\) jointly converge, and then we finally have the following theorem to guarantee the convergence:

**Theorem 5.3**.: _Under Assumption 5.1, by setting \(=O(})\), \(_{1}=O(})\), \(I=R^{1/3}\), Algorithm 2 ensures that_

\[\| F(})\|^{2} O(} ).\] (7)

```
1: Initialization: \(}^{1}\), \(u_{i,I}^{0}\), \(^{1}\), \(}^{1}\), \(}^{1}\)
2:for\(r=1,...,R\)do
3:\(_{i,0}^{r}=}^{r}\), \(_{i,0}^{r}=}^{r}\), \(_{i,0}^{r}=}^{r}\), \(u_{i,0}^{r}=u_{i,I}^{r-1}\), and \(v_{i,0}^{r}=^{r}\)
4:for\(t=1,...,I\)do
5: Each machine samples data \(_{i,t}^{r}\)
6:\(u_{i,t}^{r}=(1-_{1})u_{i,t-1}^{r}+_{1}(_{i,t-1}^{r}; _{i,t}^{r})\), and \(v_{i,t}^{r}=(1-_{2})v_{i,t-1}^{r}+_{2}(u_{i,t}^{r}/)\)
7:\(_{i,t}^{r}=^{r})}{v_{i,t}^{r}}(_{i,t-1}^{r};_{i,t}^{r})\), and \(_{i,t}^{r}=(1-_{3})_{i,t-1}^{r}+_{3}_{ i,t}^{r}\)
8:endfor
9:\(^{r+1}=_{i=1}^{N}_{i,I}^{r}\), \(^{r+1}=_{i=1}^{N}v_{i,I}^{r}\), and \(}^{r+1}=_{i=1}^{N}_{i,I}^{r}\)
10:endfor
11:Output: \(}=_{i=1}^{N}_{i,t^{}}^ {r^{}}\), where \(r^{}\) and \(t^{}\) are sampled from \([1,R]\) and \([1,I]\), respectively. ```

**Algorithm 2** FGDRO-KL

**Remark.** To achieve an \(\)-stationary point, i.e., \(\| F(})\|^{2}^{2}\), we need to set \(R=O(1/^{3})\), \(I=O(1/)\), \(=O(^{2})\) and \(_{1}=O(^{2})\). Compared to , our approach maintains a communication complexity of \(O(1/^{3})\), but significantly reduces the sample complexity on each machine from \(O(1/^{6})\) from \(O(1/^{4})\), requiring only a batch size of \(O(1)\) rather than a large batch size of \(O(1/^{2})\). Our results match the communication and sample complexity in , which tackles a simpler two-level compositional problem and achieved sample complexity of \(O(1/^{4})\) per machine. Considering that the sample complexity for a two-level compositional problem in a centralized setting would be \(O(n/^{4})\), our approach realizes a linear speed-up proportional to the number of machines.

FGDRO-KL-Adam

In this section, we introduce an adaptive algorithm, FGDRO-KL-Adam, to address the problem (5) with KL regularization, as detailed in Algorithm 3. This algorithm incorporates Adam-type updates at local steps, which have been shown to outperform SGD in centralized settings. While previous studies  in federated settings have implemented Adam-type updates at the global step but retained SGD for local updates, which may be sub-optimal.

Similar to Algorithm 2, \(u\) and \(v\) are used to estimate the local loss and the global function \(g()\), respectively. The variables \(\) and \(\) are updated in a manner consistent with Algorithm 2. Under Assumption 5.1, the behavior of the \(u,v,\) estimators is addressed as previously discussed.

The primary distinction in Algorithm 3 lies in its adaptive updates for the local model \(_{i,t}^{r}\). Here, \(\) serves a role akin to the first-order momentum in Adam, and we introduce \(_{i,t}^{r}\) to estimate the second-order momentum:

\[_{i,t}^{r}=(1-_{i})_{i,t-1}^{r}+_{4}_{ i,t}^{r}.\] (8)

Subsequently, the local models are updated adaptively using the formula:

\[_{i,t}^{r}=_{i,t-1}^{r}-_{i,t}^{r}}{ _{i,t}^{r}+}},\] (9)

where both the square root and division are performed element-wise.

A key step in the analysis is to address the coordinate-wise update, as in the following lemma.

**Lemma 6.1**.: _Using \(L\)-smooth of \(F\), for some proper constants \(C\) and \(G\), by setting \(=O(})\), \(_{1}=O(})\), we have_

\[F(}_{t}^{r}) F(}_{t-1}^{r})+\| F(}_{t-1}^{r})-}_{t-1}^{r}\|^{2}+ _{3}^{2}C-\| F(}_{t-1}^{r})\|^{2}.\] (10)

Finally, we show that FGDRO-KL-Adam has same convergence rate as FGDRO-KL.

**Theorem 6.2**.: _Under Assumption 5.1, by setting of \(=O(})\), \(_{1}=O(})\), and \(I=R^{1/3}\), Algorithm 3 achieves:_

\[[\| F(})\|^{2}] O( }).\] (11)

**Remark.** To achieve an \(\)-stationary point, i.e., \(\| F(})\|^{2}^{2}\), we just need to set \(R=O(1/^{3})\), \(I=O(1/)\), \(=O(^{2})\) and \(_{1}=O(^{2})\). The communication and sample complexities are the same as in Theorem 5.3. Our analysis, following the framework in , requires \(_{i,t}^{r}+}\) to be both upper and lower bounded. It is achieved by the upper bound assumption and choice of \(\), ensuring \(_{i,t}^{r}+} G+\), which is utilized similarly in . However, Guo et al.  did not cover the federated learning scenario or the compositional problems. It is important to note that we have not developed an Adam-type variant for FGDRO-CVaR. This is due to the need for accurate gradient estimation in the analysis of Adam-type updates, which is achieved using the moving estimator \(\). But in CVaR variant, the nonsmooth nature renders a moving average for subgradient \( F()\) not provably accurate.

## 7 Experiments

Datasets and Neural NetworksWe use Pile , CivilComments , Camelyon17 , iWildCam2020 , and Poverty . For Pile, we preprocess it as , for the others, we use the preprocessed version by . We utilized natural data splits where data from the same hospital, web source, location, or demographic group were placed on the same client machine. These experiments have involved with highly imbalanced number of data on clients. Data statistics are presented in the Appendix E. Additiona experiments on Cifar 10 with Dirichlet distributions over 100 clients are reported in Appendix G.

The **Pile** data set is a large language data set. We use the uncopyrighted version  which has 17 domains, and each domain is allocated to one machines. We use the GPT2 model  as implemented by  with 12 hidden layers, 12 attention heads, and 768 embeddings and hidden states. We measure the performance using worst log-perplexity and average log-perplexity of testing groups. **CivillComments** is a toxicity classification of the online comment task in diversified demographic identities. We train on four groups based on the presence of 'Black' and toxicity labels, deploying each on a separate machine, and use the DistilBERT base-uncased model  to predict toxicity. We measure the performance using worst group accuracy and average accuracy of testing groups. **Camelyon17** focuses on tumor detection from lymph node images , with data from five hospitals split into training (3), validation (1), and testing (1) sets. Training uses three machines, each processing data from one hospital, using DenseNet-121 . The **iWildCam2020** dataset consists of wildlife images from various camera traps , the dataset is split into training, validation, and testing segments. We use ResNet50  across all datasets and measure performance via Macro F1 score. The **Poverty** dataset contains geographic data aimed at predicting regional poverty levels . We use ResNet50  for our models and evaluate performance using both the Pearson correlation on the worst-performing region and the average across regions.

BaselinesWe compare our algorithms FGDRO-CVaR, FGDRO-KL, and FGDRO-KL-Adam with four baselines: FedAvg , SCAFFOLD , FedProx, FedAdam , DRFA, and DRDSGD .

We tune the initial step size in [1e-4, 1e-3, 1e-2, 1e-1]. All algorithms set the communication interval \(I=32\) unless otherwise specified. The local mini-batch sizes are set to 32. Experiments are run for 20K local iterations except for Pile, which runs for 200K iterations. The \(\) parameters of FGDRO-KL and FGDRO-KL-Adam are tuned in \([0.01,0.1,0.2,0.5]\). For each algorithm, we repeat the experiments 3 times with different random seeds and report the averaged performance. Following , our FGDRO algorithms for Pile initially train for 20K iterations to obtain domain weights, which are then fixed during subsequent training phases.

ResultsWe report the experimental results for natural language processing in Table 2 and those for computer vision in Table 3. We can see that our methods outperform the baselines in most tasks. Our

   Datasets &  &  \\  Metric & Worst Log-PPL & Average Log-PPL & Worst Acc & Average Acc \\  FedAvg & 8.085(\( 0.0012\)) & 6.785 (\( 0.0020\)) & 0.6415 (\( 0.0007\)) & 0.7635 (\( 0.0012\)) \\  SCAFFOLD & 7.975 (\( 0.0024\)) & 6.901 (\( 0.0031\)) & 0.6436 (\( 0.0016\)) & 0.7633 (\( 0.0019\)) \\  FedProx & 8.079 (\( 0.0038\)) & 6.724 (\( 0.0046\)) & 0.6430 (\( 0.0021\)) & 0.7692 (\( 0.0025\)) \\  FedAdam & 7.242 (\( 0.0048\)) & 6.479 (\( 0.0037\)) & 0.6567 (\( 0.0023\)) & 0.7664 (\( 0.0020\)) \\  DRFA & 8.014 (\( 0.0053\)) & 6.702 (\( 0.0062\)) & 0.6327 (\( 0.0019\)) & 0.7413 (\( 0.0022\)) \\  DR-DSGD & 8.023 (\( 0.0033\)) & 6.693 (\( 0.0030\)) & 0.6272 (\( 0.0006\)) & 0.7523 (\( 0.0011\)) \\  FGDRO-CVaR & 8.145 (\( 0.0039\)) & 6.907 (\( 0.0046\)) & 0.6693 (\( 0.0015\)) & 0.7571 (\( 0.0012\)) \\  FGDRO-KL & 7.932 (\( 0.0048\)) & 6.664 (\( 0.0051\)) & **0.6921** (\( 0.0016\)) & **0.7734** (\( 0.0020\)) \\  FGDRO-KL-Adam & **3.608** (\( 0.0052\)) & **2.653** (\( 0.0040\)) & 0.6628 (\( 0.0007\)) & 0.7614 (\( 0.0005\)) \\   

Table 2: Experiments on Natural Language Task. PPL is abbreviation of perplexity.

   Datasets &  &  &  \\  Metric & Acc & Macro F1 & Worst Pearson & Average Pearson \\  FedAvg & 0.8723 (\( 0.0074\)) & 0.4964 (\( 0.0125\)) & 0.7301 (\( 0.0064\)) & 0.7782 (\( 0.0077\)) \\  SCAFFOLD & 0.8851 (\( 0.0063\)) & 0.4527 (\( 0.0331\)) & 0.7292 (\( 0.0049\)) & 0.7814 (\( 0.0042\)) \\  FedProx & 0.8703 (\( 0.0157\)) & 0.3925 (\( 0.0228\)) & 0.7305 (\( 0.0063\)) & 0.7641 (\( 0.0070\)) \\  FedAdam & **0.9493** (\( 0.0122\)) & 0.3570 (\( 0.0203\)) & 0.7294 (\( 0.0058\)) & **0.8273** (\( 0.0041\)) \\  DRFA & 0.8301 (\( 0.0174\)) & 0.4200 (\( 0.0149\)) & 0.7071(\( 0.0026\)) & 0.7665 (\( 0.0023\)) \\  DR-DSGD & 0.9270 (\( 0.0095\)) & 0.3157 (\( 0.0227\)) & 0.7155 (\( 0.0063\)) & 0.7770 (\( 0.0059\)) \\   FGDRO-CVaR & 0.8667 (\( 0.0110\)) & 0.5080 (\( 0.0174\)) & 0.7443 (\( 0.0052\)) & 0.7977 (\( 0.0051\)) \\  FGDRO-KL & 0.9243 (\( 0.0129\)) & **0.5201** (\( 0.0239\)) & 0.7254 (\( 0.0066\)) & 0.7829 (\( 0.0062\)) \\  FGDRO-KL-Adam & 0.9399 (\( 0.0154\)) & 0.4489(\( 0.0205\)) & **0.7827** (\( 0.0071\)) & 0.8225 (\( 0.0060\)) \\   

Table 3: Experiments on Image Classification Taskapproaches improve worst-case performance without hurting average case performance. Furthermore, FGDRO-KL-Adam has demonstrated superior performance compared to FGDRO-KL in most cases.

Ablation StudiesHere we present some ablation study to examine some aspects of our algorithm design. First, in Figure 1(a), we vary the communication interval \(I\) in experiments on the Camelyon dataset. We can see that both our FGDRO-CVaR and FGDRO-KL-Adam algorithms can tolerate skipping a large number of communications without degrading the performance.

To demonstrate the effect of the local adaptive updates. We develop a LocalAdam algorithm (see Appendix D), which optimizes ERM using our design of using Adam steps in local updates. The results are plotted in Figure 1(b). We can see that the LocalAdam algorithm outperforms FedAdam, which uses SGD in local steps and only uses adaptive steps in global communication rounds.

## 8 Conclusions

Our algorithm provides a significant advantage in addressing federated group distributionally robust optimization while maintaining low communication and computational complexity. Furthermore, incorporating local adaptive steps has the potential to accelerate the training process beyond the capabilities of traditional approaches that employ SGD in local steps. Various experiments on natural language processing and computer vision have confirmed our theoretical results and underscored the effectiveness of our algorithms. It remains to develop a provable adaptive algorithm for FGDRO-CVaR, which is currently absent due to the non-smoothness and compositional problem structure.

## 9 Impact Statements

This paper is meant to advance the field of federated machine learning. We do not see noticeable negative impact.