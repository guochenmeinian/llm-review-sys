# Projection-Free Online Convex Optimization via Efficient Newton Iterations

Khashayar Gatmiry

MIT

gatmiry@mit.com

&Zakaria Mhammedi

MIT

mhammedi@mit.edu

###### Abstract

This paper presents new projection-free algorithms for Online Convex Optimization (OCO) over a convex domain \(^{d}\). Classical OCO algorithms (such as Online Gradient Descent) typically need to perform Euclidean projections onto the convex set \(\) to ensure feasibility of their iterates. Alternative algorithms, such as those based on the Frank-Wolfe method, swap potentially-expensive Euclidean projections onto \(\) for linear optimization over \(\). However, such algorithms have a sub-optimal regret in OCO compared to projection-based algorithms. In this paper, we look at a third type of algorithms that output approximate Newton iterates using a self-concordant barrier for the set of interest. The use of a self-concordant barrier automatically ensures feasibility without the need of projections. However, the computation of the Newton iterates requires a matrix inverse, which can still be expensive. As our main contribution, we show how the stability of the Newton iterates can be leveraged to only compute the inverse Hessian a vanishing fractions of the rounds, leading to a new efficient projection-free OCO algorithm with a state-of-the-art regret bound.

## 1 Introduction

We consider the Online Convex Optimization (OCO) problem over a convex set \(^{d}\), in which a learner (algorithm) plays a game against an adaptive adversary for \(T\) rounds. At each round \(t[T]\), the learner picks \(w_{t}\) given knowledge of the history \(_{t-1}\{(_{s},w_{s})\}_{s<t}\). Then, the adversary picks a convex loss function \(_{t}:\) with the knowledge of \(_{t-1}\) and the iterate \(w_{t}\), and the learner suffers loss \(_{t}(w_{t})\) and proceeds to the next round. The goal of the learner is to minimize the regret after \(T\) rounds:

\[_{T}(w)=_{t=1}^{T}_{t}(w_{t})-_{t=1}^{T}_{t} (w),\]

against any comparator \(w\). The aim of this paper is to design computationally-efficient (projection-free) algorithms for OCO that enjoy the optimal (up to log-factor in \(T\)) \(()\) regret.

The OCO framework captures many optimization settings relevant to machine learning applications. For example, OCO algorithms can be used in offline convex optimization as more computationally- and memory-efficient alternatives to interior-point and cutting plane methods whenever the dimension \(d\) is large [14; 16]. OCO algorithms are also often used in stochastic convex optimization, where the standard \(O()\) regret (achieved by, e.g. Online Gradient Descent) translates into the optimal \(O(1/)\) rate1 via the classical online-to-batch conversion technique [3; 37]. It has been shown that OCO algorithms can also achieve state-of-the-art accelerated rates in both the offline and stochastic optimization settings despite being designed for the more general OCO framework [6; 28]. What ismore, it has recently been shown that even non-convex (stochastic) optimization can be reduced to online linear optimization (a special case of OCO), where it is then possible to recover the best-known convergence rates for the setting .

Given the prevalent use of OCO algorithms in machine learning applications, it is important to have computationally-efficient algorithms that scale well with the dimension \(d\) of the ambient space. However, most OCO algorithms fall short of being efficient because of the need of performing (Euclidean) projections onto \(\) (potentially at each iteration) to ensure that the iterates are feasible. These projections are often inefficient, especially in high-dimensional settings with complex feasible sets. Existing projection-free OCO algorithms address this computational challenge by swapping potentially-expensive Euclidean projections for often much cheaper linear optimization or separation over the feasible set \(\). However, existing projection-free algorithms have sub-optimal regret guarantees in terms of their dependence in \(T\), or have potentially unbounded "condition numbers" for the feasible set multiplying their regret guarantee.

Contributions.In this paper, we address these computational and performance challenges by revisiting an existing (but somewhat overlooked) type of projection-free OCO algorithms. Unlike existing algorithms, our proposed method does not require linear optimization or separation over the feasible set \(\). Instead, the algorithm, Barrier-Regularized Online Newton Step (BARONS),2 uses a self-concordant barrier \(\) for the set \(\) to always output iterates that are guaranteed to be within \(\); much like interior point methods for offline optimization. In particular, our algorithm outputs Newton iterates with respect to time-varying, translated versions of \(\). The main novelty of our work is in devising a new efficient way of computing the Newton iterates without having to evaluate the inverse of the Hessian of the barrier at every iteration, which can be computationally expensive in high-dimensional settings. Our algorithm only needs to compute a full inverse of the Hessian a vanishing \(O(1/)\) fraction of the rounds. For the rest of the rounds, the computational cost is dominated by that of evaluating the gradient of the barrier \(\), which can be much cheaper than evaluating the inverse of its Hessian in many cases.

For the special case of a polytope with \(m\) constraints, we show that there is a choice of a barrier (e.g. the Lee-Sidford barrier) that when used within our algorithm, reduces the per-round computational cost to essentially \((1)\) linear-system-solves of size \(m d\). We show that this is often cheaper than performing linear optimization over \(\), which other projection-free algorithms require. More importantly, our algorithm achieves a _dimension-free_\(()\) regret bound. This improves over the existing regret bounds of projection-free algorithms over polytopes. For example, among projection-free algorithms that achieve a \(O()\) regret, the algorithms by , which require a separation/membership Oracle for \(\), have a multiplicative \(=R/r\) factor multiplying their regret bounds, where \(r,R>0\) are such that \((r)(R)\). The constant \(\), known as the _asphercity_, can in principle be arbitrarily large. Even after applying a potentially expensive pre-processing step, which would typically involve putting the set \(\) into (near-) isotropic position , \(\) can still be as large as \(d\) in the worst-case, and so the regret bounds achieved by the algorithms of  can be of order \(O(d)\); this is worse than ours by a \(d\) factor. Other projection-free algorithms based on the Frank-Wolfe method, e.g. those in , also have multiplicative condition numbers that are even less benign that the asphercity \(\). In fact, the condition numbers in the regret bounds for polytopes appearing in, e.g. , can in principle be arbitrarily large regardless of any pre-processing.

Finally, another advantage of our algorithm is that it can guarantee a sublinear regret even for non-Lipschitz losses (i.e. where the norm of the sub-gradients may be unbounded). In particular, we show that the general guarantee of BARONS implies a \(()\) regret bound for the portfolio selection problem  and a problem of linear prediction with log-loss , all while keeping the per-round computational cost under \((d^{2})\), when \(T d\). The losses in both of these problems are neither bounded or Lispchitz.

Related works.In the past decade, many projection-free OCO algorithms have been developed to address the computational shortcoming of their projection-based counter parts . Most projection-free algorithms are based on the Frank-Wolfe method and perform linear optimization (typically once per round) over \(\) instead of Euclidean projection. Under no additional assumptionsother than convexity and lipschitzness of the losses, the best-known regret bound for such algorithms scales as \(O(T^{3/4})\). While this bound is still sublinear in \(T\) and has no dependence in the dimension \(d\), it is sub-optimal compared to the \(O()\) regret bound achievable with projection-based algorithms. In the recent years, there have been improvements to this bound under additional assumptions such as when the functions are smooth and/or strongly convex [15; 18], or when the convex set \(\) is smooth and/or strongly convex [1; 23; 29; 24]. For the case where \(\) is a polytope,  presented a linear-optimization-based algorithm that enjoys a \(O()\) regret bound, where \(\) is a conditioning number for the set \(\). Unfortunately, \(\) can be large for many sets of interests as it essentially scales inversely with the minimum distance between the vertices of \(\). In this work, we achieve a _dimension-free_\(()\) regret bound without the \(\) factor.

More recently a new type of projection-free algorithms have emerged which use membership/separation oracle calls instead of linear optimization [28; 11; 24; 26]. From a computational perspective, separation-based and linear optimization-based algorithms are not really comparable, since there are sets over which separation is cheaper than linear optimization, and vice-versa. On the regret side, separation-based algorithms have been show to achieve a \(O()\) regret bound, where \(\) is the asphercity of the set \(\). Separation-based algorithms are simple, often easy to analyze, and achieve the optimal-in-\(T\) regret bound, unlike linear optimization-based algorithms. However, the multiplicative factor \(\) in their regret bounds means that a pre-conditioning step may be required to ensure it is appropriately bounded. This precondition step would involve putting the set into (near-) isotropic position ; an operation, that can cost \((d^{4})\) arithmetic operations ; and even after such a pre-processing step, \(\) can still be as large as \(d\) in the worst-case. Our algorithm has the benefit of not requiring any pre-processing step.

A third type of algorithms avoid projections by outputting Newton iterates that are guaranteed to be feasible thanks to the use of a self-concordant barrier. The first such algorithm in the context of online learning was introduced by . They presented a general recipe for using self-concordant barriers with Newton steps in online linear optimization. However, their approach falls short of being computationally-efficient as their algorithm needs to compute the inverse of the Hessian of the barrier at every iteration. Inspired by the work of ,  used damped Newton steps with quadratic terms added to the barrier to design an efficient algorithm for the classical portfolio selection problem. Closer to our work is that of  who used a similar barrier for designing an algorithm for exp-concave optimization that can be viewed as a computationally-efficient version of the Online Newton Step . Similar to our work,  also leverage the stability of the Newton iterates to avoid computing the inverse of the Hessian of the barrier at every step. However, their approach and analysis, which are tailored to the exp-concave setting do not necessarily lead to improved regret bounds in the general OCO setting we consider. In particular, their algorithm does not lead to a \(O()\) regret bound over polytopes.

Finally, for our application to polytopes, we make use of recent tools and techniques developed for solving linear programs efficiently. In particular, we make use of the Lee-Sidford barrier [20; 21; 22], which can be computed efficiently and, when used to compute Newton iterates, leads to the state-of-the-art \(()\) iteration upper-bound for solving a linear program. For the OCO setting, we show that using the Lee-Sidford barrier within our algorithm leads to a \(()\) regret bound. We also note that ideas similar to the ones we use to avoid computing the inverse of the Hessian of the barrier at every round were used to amortize computations in the context of solving linear programs (see e.g. [4; 39; 40]).

Outline.In section 2, we present our notation and relevant definitions. In Section 3, we present our algorithm and guarantees. In Section 4, we apply our results to the case of a polytope. All the proof are differed to the appendix.

## 2 Preliminaries

Throughout the paper, we let \(\) be a closed convex subset of \(^{d}\). We denote by \(\|\|\) the Euclidean norm and by \((R)^{d}\) the Euclidean ball of radius \(R>0\). We let \(\) denote the interior of \(\).

Our main algorithm, which can be viewed as an "online" counter-part to the Newton iterations , uses a self-concordant barrier over the set of interest to avoid the need of performing Euclidean projections onto \(\). Next, we present the definition of a self-concordant barrier.

Self-concordant barriers.For the rest of this section, we let \(\) be a convex compact set with non-empty interior \(\). For a twice [resp. thrice] differentiable function, we let \(^{2}f()\) [resp. \(^{3}f()\)] be the Hessian [resp. third derivative tensor] of \(f\) at \(\).

**Definition 1** (Self-concordant function).: _A convex function \(f\) is called self-concordant with constant \(M_{f} 0\), if \(f\) is \(C^{3}\) and satisfies_

* \(f(x_{k})+\) _for_ \(x_{k} x\)_; and_
* _For all_ \(x\) _and_ \(u^{d}\)_,_ \(|^{3}f(x)[u,u,u]| 2M_{f}\|u\|_{^{2}f(x)}^{3}\)_._

**Definition 2** (Self-concordant barrier).: _For \(M_{f}, 0\), we say that \(f\) is a \((M_{f},)\)-self-concordant barrier for \(\) if \(f\) is a self-concordant function over \(\) with constant \(M_{f}\) and_

\[ w, f(w)^{}^{-2}f (w) f(w).\]

Computational Oracles.We will assume that our algorithm has access to a self-concordant function over the set \(\) through the following gradient and Hessian Oracles.

**Definition 3** (Gradient Oracle).: _Given a point \(w\) and a tolerance \(>0\), the gradient Oracle \(_{}^{}()\) returns an \(\)-approximate vector \(_{w}\) of the gradient \((w)\) in the dual local norm of the Hessian:_

\[\|_{w}-(w)\|_{^{-2}(w)}.\]

_We denote by \(_{}^{}()\) the computational cost of one call to \(_{}^{}()\)._

When clear from the context, we will simply write \(_{}^{}\) and \(_{}^{}\) for \(_{}^{}()\) and \(_{}^{}()\), respectively.

**Definition 4** (Hessian Oracle).: _Given a point \(w\) and a tolerance \(>0\), the Hessian Oracle \(_{}^{}()\) returns a matrix \(H\) and its inverse \(H^{-1}\) which are \(1\) spectral approximations of the Hessian and inverse Hessian of \(\) at \(w\):_

\[(1-)^{2}(w) H(1+)^{2}(w) (1-)^{-2}(w) H^{-1}(1+ )^{-2}(w).\]

_We denote by \(_{}^{}()\) the computational cost of one call to \(_{}^{}()\)._

When clear from the context, we will simply write \(_{}^{}\) and \(_{}^{}\) for \(_{}^{}()\) and \(_{}^{}()\), respectively.

Additional notation.We use the notation \(f g\) to mean \(f Cg\) for some universal constant \(C>0\). We also write \(fg\) to mean \(f(T,d) g\). We let \(^{-2}(^{2})^{-1}\) and \(^{-1/2}\) refer to the inverse of the Hessian and the inverse of the square root of the Hessian, respectively.

## 3 Algorithm and Regret Guarantees

In this section, we construct a projection-free algorithm for Online Convex Optimization. The algorithm in question (Alg. 1) outputs approximate Newton iterates with respect to "potential functions" \((_{t})\) that take the following form:

\[_{t}(w)(w)+w^{}_{s=1}^{t-1}g_{s},\]

where \((g_{s}_{s}(w_{s}))\) are the sub-gradients of the losses \((_{s})\) at the iterates \((w_{s})\) of Algorithm 1, and \(\) is a self-concordant function over \(\). Algorithm 1 uses the the approximate gradient and Hessian Oracles of \(\) (see 2) to output iterates \((w_{t})\) approximate Newton iterates in the following sense:

\[ t[T], w_{t+1} w_{t}-^{-2}_{t+1}(w_{t}) _{t+1}(w_{t}).\] (1)

As is by now somewhat standard in the analyses of online Newton iterates of the form in (1), we will bound the regret of Algorithm 1 by showing that:* The iterates \((w_{t})\) are close (in the norm induced by the Hessian \(^{2}(w_{t})\)) to the FTRL iterates, which are given by \[w_{t}^{*}*{argmin}_{w}_{t}(w).\] (2)
* The regret of FTRL is bounded by \(O()\).

Our main contribution is an algorithm that outputs iterates \((w_{t})\) that satisfy the first bullet point (i.e. iterates that satisfy (1)) while only calling a Hessian Oracle (which is potentially computationally expensive) a \(O(1/)\) fraction of the rounds after \(T\) rounds. As we show in Section 4, for the case where \(\) is a polytope with \(m\) constraints, the algorithm achieves a \(()\) regret bound, where the per-iteration computational cost essentially reduces to a linear-system-solve involving a \(d m\) matrix. Among existing OCO algorithms that achieve a \(()\) regret bound, none can achieve this computational complexity for general polytopes with \(m\) constraints (see Section 4 for more details).

### Efficient Computation of the Newton Iterates with Barons

The key feature of BARONS (Algorithm 1) is that is uses an amortized computation of the Hessians. Namely, BARONS computes the inverse of the Hessian of the barrier \(\) only for a small fractions of the iterates \((w_{t})\). Henceforth, we refer to the iterates where the algorithm computes the full inverse of the Hessian as _landmark iterates_; these are the iterates \((u_{t})\) in Lines 13 and 16 of Algorithm 1. The idea behind this is that for a sufficiently curved3 barrier \(\), the Newton iterates with respect to \(\) are stable enough that it suffices to compute the inverse of the Hessian of \(\) at the closest landmark iterate. For example, this is what was done in  to design an efficient algorithm for exp-concave optimization.

Unlike the setting of , where it is possible to add quadratic terms to the barrier for additional stability, in our setting we cannot do that without sacrificing performance in terms of regret. Without the quadratic terms, the Newton iterates are not stable enough for our desired guarantee. Instead of adding regularization terms, BARONS takes \((1)\) Newton steps per round to get "closer" to the Newton iterate with the true Hessian matrix. This simple approach is key to the success of our approach.

In the next subsection, we give a generic guarantee for BARONS.

### Generic Regret Guarantee of Barons

In this subsection, we present a general regret and computational guarantee for BARONS under minimal assumptions on the sequence of losses and without turning the "step size" \(\). In the next subsection, we will instantiate the regret guarantee when additional assumptions on the sequence of losses are available. We now state the main guarantee of BARONS (the proof in Appendix C.1).

**Theorem 5** (Master theorem).: _Let \(\) be a self-concordant function over \(\) with constant \(M_{}>0\), and let \(b,,,>0\) and \(m_{}\) be such that \(}\), \(}\), \(=0.001\), and \(m_{}(})\). Further, let \((w_{t})\) be the iterates of Algorithm 1 with input (\(\), \(\), \(\), \(m_{}\)) and suppose that the corresponding sub-gradients \((g_{t})\) satisfy \(\|g_{t}\|_{^{-2}(w_{t})} b\), for all \(t 1\). Then, the regret of Algorithm 1 is bounded as:_

\[_{t=1}^{T}(_{t}(w_{t})-_{t}(w))(w)\ +_{t=1}^{T}g_{t}_{^{-2}(w_{t})}^{2}+ _{t=1}^{T}g_{t}_{^{-2}(w_{t})},\ \ \  w.\] (3)

_Furthermore, the computational cost of the algorithm is bounded by_

\[O((_{}^{}+d^{2}) T {1}{ M_{}}+_{}^{}(M_{ }T+M_{}_{t=1}^{T}\|g_{t}\|_{^{-2}(w_{t})} )).\]

Theorem 5 essentially shows that it is possible to achieve the same regret as FTRL, while only computing the inverse of the Hessian of \(\) at most \((M_{}T)\) number of times.

### Regret Guarantee Under Local and Euclidean Norm Bounds on the Sub-Gradients

We now instantiate the guarantee in Theorem 5 with a \((M_{},)\)-self-concordant barrier \(\) for the set \(\), with respect to which the local norms of the sub-gradients are bounded; that is, when \(\|g_{t}\|_{^{-2}(w_{t})} b\). We note that the regret bound in (36) has an additive \((w)\) which may be unbounded near the boundary of \(\). However, it is still possible to compete against comparators in \(\) by making additional assumptions on the range of the losses [27; 32]. We discuss some of these assumptions in the sequel. For the next theorem, we will state the regret bound of BARONS relative to comparators in the restricted set:

\[_{c}(1-c)\{cw^{*}\},\] (4)

where \(\) denotes the Minkowski sum, \(w^{*}_{w}(w)\), and \(c(0,1)\) is a parameter.

With this, we now state a regret bound for BARONS when the sub-gradients of the losses have bounded local norms. The proof of the next theorem is in Appendix C.2.

**Theorem 6** (Local norm bound).: _Let \(\) be an \((M_{},)\)-self-concordant barrier for \(\) and let \(c(0,1),b>0\). Further, suppose that for all \(t[T]\), \(\|g_{t}\|_{^{-2}(w_{t})} b\), where \((w_{t})\) are the iterates of BARONS with input parameters \((,,,m_{})\) such that_

\[T}},}, 0.001, m_{} (}).\] (5)

_For \(T 1\) large enough such that \(}\), \(}\), the regret of BARONS is bounded as_

\[_{T}^{}(w) b,  w_{c},\] (6)

_where \(_{c}\) is as in (4). Further, the computational complexity of BARONS in this case is bounded by_

\[O((_{}^{}+d^{2}) T }+_{}^{} M_{ }).\]

**Remark 1**.: _The regret bound in Theorem 6 is stated with respect to comparators in the restricted set \(_{c}\) defined in (4). It is possible to extend this guarantee to all comparators in \(\) under an additional assumption on the range of the losses. For example, if for \(w^{}_{w}(w)\), we have_

\[_{w,t[T]}_{t}( (1-) w+ w^{})-(w)  O(}),\] (7)

_then the regret guarantee in (6) can be extended to all comparators in \(\) up to an additive \(O()\) term (see Lemma 7 in the appendix). In this case, the \( c\) term in the computational complexity need be replaced by \( T\). We note that the condition in (7) does not require a uniform bound on the losses. Instead, it only restrict the rate of growth of the losses \((_{t}(w))\) as \(w\) approaches the boundary of \(\). As we show in the sequel (SS4.2), (7) is satisfied for some popular losses which are not Lipschitz._

We now instantiate the guarantee in Theorem 5 when the sub-gradients are bounded in Euclidean norm (instead of local norm); that is, we assume that for all \(t[T]\), \(\|g_{t}\| G\) for some \(G>0\). We note that this assumption implies (7), and we will be able to bound the regret against all comparators in \(\) as alluded to in Remark 1. The proof of the next theorem is in Appendix C.3).

**Theorem 7** (Euclidean norm bound).: _Let \(\) be an \((M_{},)\) self-concordant barrier for \(\) and let \(()()+}\|\|^{2}\). Further, let \(G,R>0\) and suppose that \((R)\) and for all \(t[T]\), \(\|g_{t}\| G\), where \(g_{t}_{t}(w_{t})\) and \((w_{t})\) are the iterates of BARONS with input parameters \((,,,m_{})\) such that_

\[}, }, 0.001, m_{} (}).\] (8)

_For \(T 1\) large enough such that \(\), \(}\), the regret of BARONS is bounded as_

\[_{T}^{}(w) RG, w.\] (9)

_Further, the computational complexity of BARONS in this case is bounded by_

\[O((_{}^{}()+d ^{2}) T}+_{}^{ }() M_{}).\]

## 4 Application to Polytopes Using the Lee-Sidford Barrier

In this section, we assume that the set \(\) is a polytope in \(^{d}\) specified by \(m\) linear constraints:

\[=\{w^{d}\  i[m],\ a_{i}^{}w b_{i}^{ }\},\] (10)

and we construct efficient gradient and Hessian Oracles for a self-concordant barrier for \(\). This will then allow us to instantiate the guarantees of BARONS in Section 3 and provide explicit and state-of-the-art bounds on the regret of BARONS.

We will assume without loss of generality that \(\|a_{i}\|=1\), for all \(i[m]\), and let \(A(a_{1},,a_{m})^{}^{m d}\) denote the _constraint_ matrix of the set \(\). For the rest of this section, it will be convenient to define the "slack" variables \(s_{w,i}=a_{i}^{}w-b_{i}^{}\), for \(i[m]\). Here, \(s_{w,i}\) essentially represents the distance of \(w\) to the \(i\)th facet of the polytope \(\). Further, we let \(S_{w}(s_{w})\) be the diagonal matrix whose \(i\)th diagonal entry is \(s_{w,i}\).

The \(\) barrier.To perform Online Convex Optimization over \(\), we pick the regularizer \(\) of BARONS to be the Lee-Sidford (LS) barrier \(^{}\) with parameter \(p>0\), which is defined as

\[^{}(v)=_{v^{m}_{v>0}}-(A^{ }S_{w}VS_{w}A)+}(V^{1+1/p}),\]

where \(V=(v)\). One way to think of the \(\) barrier is as a weighted log-barrier. As we will discuss in the sequel, this choice will confer computational and performance (in terms of regret) advantages over the standard log-barrier.

Self-concordance of the LS barrier.According to [8, Theorem 30], the LS barrier with the choice \(p=O((m))\) is a self-concordant function with parameter \(M_{^{}}\) satisfying

\[M_{^{}}=O((m)^{2/5})=(1),\]

The other favorable property of this barrier is that its Newton decrement at any point \(w\) is of order \(()\); that is,

\[\|^{}(w)\|_{^{-2}^{}(w)}= ().\] (11)

Therefore, \(^{}\) is a \(((1),(d))\)-self-concordant barrier. For the log-barrier, the right-hand side of (11) would be \(\).

Cost of gradient and Hessian Oracles.We consider the computational complexities of gradient and Hessian Oracles for \(^{}\). By , we have that for \(>0\),

\[^{}_{}(^{}) ^{}(1/), ^{}_{}(^{}) ^{}(1/ ),\]

where \(^{}\) is the computational cost of solving a linear system of the form \(A^{}(v)Ax=y\), for vectors \(v_{ 0}^{d}\) and \(y^{d}\); we recall that \(A=(a_{1},,a_{m})^{}\) is the constraint matrix for \(\). In the worst-case, such a linear system can be solved with cost bounded as

\[^{} O(md^{-1}),\] (12)

where \(\) is the exponent of matrix multiplication, and \(m\) is the number of constraints of \(\). However, as we show in the sequel, \(^{}\) can be much smaller in many practical applications.

With this, we immediately obtain the following corollary for the regret and run-time of BARONS under local norm and Euclidean norm bounds on the sub-gradients.

**Corollary 1** (OCO over a polytope with LS barrier).: _Let \(c(0,1),G,R,b>0\), and suppose \(\) is given by (10) and that \(^{}\) is the corresponding LS barrier. Further, let \((w_{t})\) be the iterates of BARONS, and let \(_{c}\) be the restricted version of \(\) defined in (4). Then, the following holds:_

* _Local norm bound:_ _If_ \(\|g_{t}\|_{^{-2}(w_{t})} b\)_, for all_ \(t 1\)_, and the parameters_ \((,,,m_{})\) _of_ BARONS _are set as in Theorem_ 6 _with_ \(=^{}\) _and_ \((M_{},)=((1),(d))\)_, then for_ \(T\) _large enough (as specified in Theorem_ 6_), the regret of_ BARONS _is bounded by_ \[_{T}^{}(w) b,  w_{c}.\] (13)
* _Euclidean norm bound:_ _If_ \((R)\) _and_ \(\|g_{t}\| G\)_, for all_ \(t 1\)_, and the parameters_ \((,,,m_{})\) _of_ BARONS _are set as in Theorem_ 7 _with_ \(()=^{}()+}\|\|^{2}\) _and_ \((M_{},)=((1),(d))\)_, then for_ \(T\) _large enough (as in Theorem_ 7_)_ BARONS _has regret bounded as_ \[_{T}^{}(w) RG,  w\,.\] (14)

_In either case, the computational complexity is bounded by_

\[^{}+d^{2}  T+^{} d,\] (15)

_where \(^{}\) is the computational cost of solving a linear system of the form \(A^{}(v)Ax=y\), for vectors \(v_{ 0}^{d}\) and \(y^{d}\) (recall that \(A\) is the constraint matrix for the polytope \(\))._

Using the log-barrier.We note that since \(\) is a polytope, we could have used the standard log-barrier

\[^{}(w)=_{i=1}^{m}(b^{}_{i}-a^{}_{i}w ).\] (16)

This barrier is \((1,m)\)-self-concordant, and so instantiating Theorem 5 with it would imply a \((b)\) regret bound in the case of local sub-gradient norms bounded by \(b>0\). Using the LS barrier replaces the \(\) term in this bound by \(\) regardless of the number of constraints--see(13). However, this comes at a \(^{ sys}\) computational cost, which can be as high as \(md^{-1}\) in the worst-case (see (12)). In the case of the log-barrier, this cost would be replaced by \(md\) (essentially because \(^{ grad}_{ c}(^{}) O(md)\)). Thus, when \(m\) is of the order of \(d\), using the log-barrier may be more computational-efficient compared to using the \( LS\) barrier. In the next corollary, we bound the regret of \( BARONS\) when \(=^{}\); this result is an immediate consequence of Theorem 7.

**Corollary 2** (OCO over a polytope with the \( log\) barrier).: _Let \(G,b>0\), and suppose \(\) is given by (10) and that \(^{}\) is the corresponding \(\)-barrier. Further, let \((w_{t})\) be the iterates of \( BARONS\). If \((R)\) and \(\|g_{t}\| G\), for all \(t 1\), and the parameters \((,,,m_{ Newton})\) of \( BARONS\) are set as in Theorem 7 with \(()=^{}()+}\|\|^{2}\) and \((M_{},)=(1,m)\), then for \(T\) large enough (as in Theorem 7) \( BARONS\) has regret bounded as_

\[_{T}^{ BARONS}(w) RG, w .\] (17)

_The computational complexity is bounded by_

\[(md+d^{2}) T+md^{-1}.\] (18)

### Implications for Lipschitz Losses

We now discuss implications of Corollary 1, and compare the bound of \( BARONS\) to those of existing algorithms for Lipschitz losses.

Dimension-free regret bound.We note when the Euclidean norms of the sub-gradients are bounded, \( BARONS\) achieves a _dimension-free_\(O()\) regret bound. In contrast, the best dimension-free regret bound4 achieved by existing projection-free algorithms is of order \(O(T^{3/4})\) (see e.g. ). We also note that existing separation/membership-based algorithms that achieve a \(\) regret; for examples those presented in , are not dimension-free. Their regret bounds are of order \(O()\), where \(=R/r\) with \(r,R>0\) such that \((r)(R)\). The asphericity parameter can depend on the dimension \(d\), and even after a pre-conditioning step (which would involve putting the set \(\) into near-isotropic position and can cost up to \((d^{4})\)), \(\) can be as large as \(d\) in the worst-case. Of course, to make a fair comparison with existing projection-free algorithms, we also need to take computational complexity into account. This is what we do next.

Computational cost.The computational cost in (15) should be compared with that of existing projection-free algorithms. For linear optimization-based projection-free algorithms, the computational cost after \(T\) rounds is typically of order \(^{ lin} T\), where \(^{ lin}\) is the cost of performing linear optimization over \(\) which, for a polytope \(\), reduces to solving a linear program. Using state-of-the-art interior point methods for solving such a linear program would cost \(^{ lin}(^{ sys})\); see e.g. . Thus, linear optimization-based projection-free algorithms5 can have a cost that is a factor \(\) worse than that of \( BARONS\) in the setting of Corollary 1. On the other hand, separation/membership-based algorithms, the computational cost scales with \(O(^{ sep} T)\) after \(T\) rounds, where \(^{ sep}\) is the cost of performing separation for the set \(\). For a general polytope in \(^{d}\) with \(m\) constraints, we have \(^{ sep} O(md)\), which may be smaller than \(^{ sys}\) (the latter can be as large as \(md^{-1}\) in the worse case;see (12)). Here, it may be more appropriate to compare against the computational guarantee of \( BARONS\) given in Corollary 2; by (18), we have that for \(T d^{-2}\), the computational cost of \( BARONS\) in the setting of the corollary is dominated by \((md+d^{2}) T\), which is comparable to that of existing separation-based algorithms.

### Implications for Non-Lipschitz Losses

Another advantage \( BARONS\) has over projection-free, and even projection-based, algorithms is that it has a regret bound that scales with a bound on the local norms of the gradients--see (13). We now showcase two online learning settings where this leads to non-trivial performance and computational improvements over existing OCO algorithms.

Online Portfolio Selection .The portfolio selection problem is a classical online learning problem where the gradients of the losses can be unbounded. In this paragraph, we demonstrate how the guarantee of BARONS in Corollary 1 leads to a non-trivial guarantee for this setting both in terms of regret and computational complexity. In the online portfolio setting, at each round \(t\), a learner (algorithm) chooses a distribution \(w_{t}_{d}\) over a fixed set of \(d\) portfolios. Then, the environment reveals a return vector \(r_{t}_{ 0}^{d}\), and the learner suffers a loss

\[_{t}(w_{t})- w_{t}^{}r_{t}.\]

The goal of the learner is to minimize the regret \(_{T}(w)_{t=1}^{T}(_{t}(w_{t})-_{t}(w))\) after \(T 1\) rounds. For this problem, it is known that a logarithmic regret is achievable, but the specialized algorithms that achieve this have a computational complexity that scales with \((d^{3}T,d^{2}T^{2})\). On the other hand, applying the generic Online Gradient Descent or the Online Newton Step to this problem leads to regret bounds that scale with the maximum norm of the gradient (which can be unbounded). Instantiating the guarantees of BARONS in Corollary 1 with \(\) set to the standard log-barrier for the simplex6, in particular the bound in (13), to the online portfolio selection problem leads to an \(()\) regret bound, which does not depend on the norm of the observed gradients. Furthermore, we have \(^{} O(d)\), and so by (15) the computational complexity is essentially \(O(d^{2}T)\) after \(T\) rounds. Technically, the bound in (13) is only against comparators in the restricted set \(_{c}\). However, by setting \(c=1/T\), it possible to extend this guarantee to all comparators in \(\) as explained in Remark 1, since the losses in this case satisfy (6) [27, Lemma 10].

Linear prediction with the log-loss.Another classical online learning problem with unbounded gradients is that of linear prediction with the log-loss . For this problem, at each round \(t\), the learner receives a feature vector \(x_{t}^{d}\), outputs \(w_{t}^{d}\), then observes label \(y_{t}\{-1,1\}\) and suffers loss

\[_{t}(w_{t})-\{y_{t}=1\}(1-w_{t}^{}x_{t})- \{y_{t}=0\}(1-w_{t}^{}x_{t}).\]

In the settings, where \((,)=(_{d},_{}(1))\) and \((,)=(_{}(1),_{d})\), we have that \(\|_{t}(w)\|_{^{2}(w)} O(1)\) for all \(w\), where \(\) is set to the corresponding log-barrier for \(\). Thus, instantiating Corollary 1 (in particular (13)) in this setting implies that BARONS achieves a regret bound of the form:

\[(),\] (19)

and has computational complexity bounded by \((d^{2}T)\), as long as \(T d\). Again, we emphasize that the bound in (19) does not depend on the norm of the gradients, which may be unbounded.

Finally, we note that there exist a few specialized algorithms that provide sublinear regret bounds for non-lipschitz losses. This includes, for example, the Soft-Bayes algorithm . However, this algorithm is specialized to the log-loss with a particular dependence on the predictions, and it is not clear, for example, what regret bound it would have in the linear prediction setting and other similar settings with non-Lipschitz losses.