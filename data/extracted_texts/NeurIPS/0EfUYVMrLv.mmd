# Test-time Adaptation in Non-stationary Environments

via Adaptive Representation Alignment

 Zhen-Yu Zhang

Center for Advanced Intelligence Project, RIKEN

zhen-yu.zhang@riken.jp

&Zhiyu Xie

Stanford University

zhiyuxie@stanford.edu

&Huaxiu Yao

UNC-Chapel Hill

huaxiu@cs.unc.edu

&Masashi Sugiyama

Center for Advanced Intelligence Project, RIKEN

Graduate School of Frontier Sciences, The University of Tokyo

sugi@k.u-tokyo.ac.jp

###### Abstract

Adapting to distribution shifts is a critical challenge in modern machine learning, especially as data in many real-world applications accumulate continuously in the form of streams. We investigate the problem of sequentially adapting a model to non-stationary environments, where the _data distribution is continuously shifting_ and _only a small amount of unlabeled data are available each time_. Continual test-time adaptation methods have shown promising results by using reliable pseudo-labels, but they still fall short in exploring representation alignment with the source domain in non-stationary environments. In this paper, we propose to leverage non-stationary representation learning to adaptively align the unlabeled data stream, with its changing distributions, to the source data representation using a sketch of the source data. To alleviate the data scarcity in non-stationary representation learning, we propose a novel _adaptive representation alignment_ algorithm called Ada-ReAlign. This approach employs a group of base learners to explore different lengths of the unlabeled data stream, which are adaptively combined by a meta learner to handle unknown and continuously evolving data distributions. The proposed method comes with nice theoretical guarantees under convexity assumptions. Experiments on both benchmark datasets and a real-world application validate the effectiveness and adaptability of our proposed algorithm.

## 1 Introduction

Machine learning algorithms, particularly deep learning models, have achieved remarkable success when the test data share the same distribution of the training data. However, in many real-world applications, the learning environment is changing over time, resulting in the test data inevitably encountering natural variations. For example, once an autonomous driving model is deployed, external factors such as weather changes (e.g., snow, frost, or fog) and internal factors like sensor degradation (e.g., causing Gaussian noise, defocus, or blur) can negatively impact its performance. Unfortunately, many well-trained models are highly sensitive to such distribution shifts and may suffer significant performance degradation, even when the shifts are minor . Moreover, once deployed, models often lack access to the original training data, making it essential to equip the learning system with the ability to adapt to non-stationary environments in test time .

A promising line of research is known as _test-time adaptation_ (TTA), which focuses on adapting models to new environments using only unlabeled data. Pioneering approaches consider adaptation to a fixed distribution, including introducing auxiliary self-supervised learning tasks  or employingentropy minimization to update the model [26; 32]. In addition, aligning the representation of unlabeled data back to the source representation has also been proposed to improve performance [28; 10]. More recently, several seminal works have explored _continual test-time adaptation_ with unlabeled data streams, where data arrive continuously, and the distribution may change over time. These algorithms often rely on generating and selecting high-confidence pseudo-labels to update the model, with techniques such as reliable entropy minimization [34; 25]. Non-parametric approaches have also be proposed, leveraging both source labels and pseudo-labeled data for adaptation . Despite these advances, the exploration of effective representation alignment with the source data representation in non-stationary environments remains underexplored.

In this paper, we propose a non-stationary representation learning approach to adaptively align the unlabeled data stream with changing distributions to the source data representation, leveraging the marginal information from the source distribution. Our framework follows a common configuration used in prior work, which assumes the model comprises a representation learning module and a linear classifier [30; 32]. The core idea is to continually update the representation learning module so that it projects non-stationary unlabeled data at each time step to a distribution aligned with the source data representation, relying solely on the source marginal distribution. Different from prior representation alignment methods for fixed distributions [23; 28], the key challenge in non-stationary representation learning lies in the limited amount of data available at each time. Updating the model with only a single batch of data can introduce high variance due to the small sample size, while relying on the entire data stream risks high bias as the distribution evolves over time.

To handle the challenges posed by the unknown and ever changing distributions and limited data in each round, we propose a novel algorithm named _adaptive representation alignment_ (Ada-ReAlign). Drawing inspiration from recent advances in non-stationary online learning [38; 43; 41], the representation learning module employs a group of base models learning with varying window sizes to explore different part of the data stream, along with a meta learner that adaptively combines their output to learn a well-aligned representation. We then further refine the linear classifier by applying entropy minimization, with regularization to the initial one, based on the aligned the data representation. Our algorithm enjoys nice theoretical guarantees with convex models and loss functions, providing a solid foundation for its empirical success. Through benchmark experiments and a real-world application, we demonstrate the effectiveness and efficiency of our method in improving performance under non-stationary environments. We summarize our contributions as follow:

1. We propose _non-stationary representation learning_ for continual test-time adaptation, which adaptively aligns non-stationary data with the source representation using a sketch of source data.
2. We propose a novel online learning algorithm that adaptively aligns representations to the source by exploring variations across different periods of the data. Theoretical analysis demonstrates that the proposed method approximates the optimal model sequence for convex losses and models.
3. We demonstrate the effectiveness and efficiency of our method for test-time adaptation in non-stationary environments through benchmark experiments and a real-world application.

**Organization.** We first introduce related work in Section 2. In Section 3, we present our main results, including the proposed algorithm with corresponding theoretical analysis. Section 4 reports the experiment results, followed by the conclusion in Section 5. All proofs and omitted details are provided in the Appendix.

## 2 Related Work

In this section, we present the most relevant literature related to our learning setting and the techniques used in our approach. A more detailed description is provided in **Appendix B**.

**Continual Test-time Adaptation in Non-stationary Environments.** Recently, continual test-time adaptation in non-stationary environments has gained significant attention. Due to the evolving nature of streaming data, the data distribution naturally changes over time. A simple idea involved recovering the model weights from the initial model after each adaptation step of a mini-batch, such as MEMO , episodic Tent , or DDA . However, these sequential one-step adaptation methods could be insufficient because they only explore the limited number of data at each round, and thus cannot explore the knowledge of the accumulated historical data.

To tackle this challenge, CoTTA  was introduced, generating robust pseudo-labels through a weighted average of historical models while preserving the initial model's parameters. It also stochastically replaces the model's parameters with the initial model's parameters at each round to resist distribution change. Building on this, EcoTTA  and BocTTA  improved parameter and memory efficiency during continual adaptation. Similarly, SAR  updated the model based on reliable entropy and reset it to its initial state whenever the entropy exceeds a predefined threshold. AdaNPC  resisted non-stationarity by constructing a memory buffer to store historical distributions. Although these methods have demonstrated empirical success in various real-world applications, they rely on prior knowledge to estimate pseudo-labels or require access to source-labeled data during adaptation.

**Adapting to Non-stationary Environments with Offline Labeled Data.** This line of research focuses on specific types of distribution shifts, employing adaptive learning with weighted source-labeled data to handle continuous distribution changes. Previous studies have tackled the challenge of non-stationarity in the context of online label shift, where only the class priors change. In such scenarios, an unbiased loss estimator is used to estimate the loss at each round, enabling dynamic regret minimization in non-stationary environments . Another work investigated the problem of continuous covariate shift, where only the input distribution changes . They reframed this problem as an online density ratio estimation task and proposed a generic reduction of the density ratio estimation problem to dynamic regret optimization. However, these approaches assume access to the offline training data for adaptation, which may not always be feasible in practice.

## 3 Algorithm and Theory

We start by introducing the notations and problem formulation, followed by a detailed explanation of the proposed Ada-ReAlign algorithm and its theoretical analysis.

### Problem Formulation

In this part, we first formulate the learning problem. We assume access to a well-trained model on source data, along with a sketch of them. During adaptation, unlabeled data arrive sequentially from non-stationary environments, where the underlying data distribution could change over time. Following previous work [30; 32], we assume the model consists of a representation learning module and a linear function as classification module. Let \(_{t}():^{d}\) be the representation learning module, and let the linear function be represented by a matrix \(_{t}^{k d}\) where \(k=||\). Thus, the prediction model is defined as \(f_{t}()=_{t},_{t}()\). We denote the representation module of the well-trained initial model on the source data by \(_{0}()\) and its corresponding linear function by \(_{0}\).

As streaming data are collected in non-stationary environments, the underlying data distribution remains both _unknown and ever-changing_. The learning task is framed as a sequential prediction problem over \(T\) rounds, with \(T>0\). At each round \(t[T]:=\{1,,T\}\), the learner receives a batch of unlabeled data \(S_{t}=\{_{t,i}\}_{i=1}^{N}\), sampled independently and identically from the distribution \(_{t}\), where \(N_{t} 1\) and \(_{t}\) could change over time. Our objective is to learn a sequence of models \(\{f_{t}\}_{t=1}^{T}\) that perform well across the evolving distributions \(\{_{t}\}_{t=1}^{T}\).

We define \(_{0}^{d}\) and \(_{0}^{d d}\) as the mean and covariance of the representation distribution of the source data with the initial model, where \(_{0}=_{_{0}}[_{0}()]\), \(_{0}=_{_{0}}[(_{0}()- _{0})^{T}(_{0}()-_{0})]\), and \(d\) denotes the dimensionality of the feature embedding. This approach of sketching the source data does not rely on label information from the source data, which is particularly advantageous in tasks involving privacy concerns. Moreover, marginal information can be generated using coreset techniques [31; 16], eliminating the need for direct access to the original source data.

Following the online learning literature , we use dynamic regret as the performance measure. The performance of the model sequence \(\{f_{t}\}_{t=1}^{T}\) is evaluated through the average excess risk, defined as:

\[(\{f_{t}\}_{t=1}^{T}):=_{t=1}^{T}R_{t}(f_{t})-_{t=1}^ {T}R_{t}(f_{t}^{*}),\] (1)

where \(R_{t}(f)=_{(,y)_{t}}[(f(),y)]\) is the expected loss at time \(t\) with loss function \(\), \(f_{t}^{*}_{f}R_{t}(f)\) represents the corresponding optimal model in the hypothesis space at each round.

When the distribution of unlabeled data stream is fixed, e.g., \(_{t}=_{1}\), \( t[T]\), this formulation recover back to the previous setting of TTA to a stationary environment [30; 32]

**Remark 1** (Dynamic Regret and Catastrophic Forgetting).: The dynamic regret defined in Eqn. (1) quantifies the difference between the performance of the learned model and the optimal model at each time step. In our formulation, the data distribution at any given time step can correspond to any previously encountered distribution, and the model has no prior knowledge of this distribution during prediction. Therefore, if the performance of the model remains comparable to that of the optimal model that minimizes the expected loss at that time step, this indicates that the learned model successfully retains previously acquired knowledge and mitigates the catastrophic forgetting issue.

### Representation Alignment with Source Sketch

To adapt the model to a new target domain, a natural intuition is that if the data in the target domain can be accurately projected back to their representation in the source domain, the well-trained source model can be reused for predictions. Based on this idea, we keep the classification module fixed by setting \(_{t}=_{0}\) and adapt the representation learning module \(\{_{t}\}_{t=1}^{T}\) to ensure that the representation of the non-stationary unlabeled data stream aligns closely with that of the source data.

We employ dynamic regret as the performance measure for representation learning in non-stationary environments and define the objective as:

\[_{_{t}}_{t=1}^{T}L_{t}(_{t},_{0})-_{t=1}^{T}L_{t}( _{t}^{*},_{0}),\] (2)

where \(L_{t}(,)\) represents the representation discrepancy between \(_{t}\) and \(_{0}\) in each round, where \(_{t}\) is the model learned at round \(t\). Here \(_{t}^{*}\) denotes the optimal representation learning function, defined as \(_{t}^{*}=_{}L_{t}(,_{0})\).

We now define the loss function \(L_{t}(,)\). Given the challenges in accurately estimating representation discrepancy, we propose to use a surrogate loss function to approximate it. Inspired by prior work on representation learning with deep neural networks [37; 28], we model the representation distribution using a Gaussian approximation. Specifically, we measure the discrepancy as the gap in mean and covariance between the projected unlabeled data and the source data representation, defined as follows:

\[L_{t}(,_{0})=\|_{t}-_{0}\|_{2}^{2}+\|_{t}-_{ 0}\|_{F}^{2}\]

where \(\) is the hyperparameter, \(_{t}=_{_{t}}[_{t}(_{t})]\), \(_{t}=_{_{t}}[(_{t}()- _{t})^{T}(_{t}()-_{t})]\), \(\|\|_{2}\) denotes the Euclidean norm, and \(\|\|_{F}\) denotes the Frobenius norm. To improve numerical stability, we also add the identity matrix multiplied with a small constant to each covariance matrices \(_{t}\) to reduce their condition number.

Since we only have empirical data at each round, we use the empirical loss to approximate the discrepancy. We define \(_{t}=_{i=1}^{n_{t}}_{t}(_{i})/n_{t}\) and \(_{t}=_{i=1}^{n_{t}}[(_{t}()-_{t})^{T}( _{t}()-_{t})]/n_{t}\), thus we have the empirical estimation of the divergence,

\[_{t}(,_{0})=\|_{t}-_{0}\|_{2}^{ 2}+\|_{t}-_{0}\|_{F}^{2}\] (3)

At first glance, it may seem straightforward to minimize the loss defined in Eqn. (3) to update the representation learning module. However, the limited amount of data available in each round poses a challenge to obtain a well-generalized model. Therefore, we leverage online learning techniques to reuse a suitable number of historical data, ensuring effective learning of the representation model.

**Remark 2** (Comparison with Distribution Alignment Approaches).: Aligning the representations of unlabeled data with those of source data has been explored in works such as [23; 28]. These studies primarily focus on adapting the model to a fixed domain with a large amount of unlabeled data. Our problem involves adaptation to non-stationary environments, where the data distribution can change continuously with a limited number of data available in each round. This non-stationary setting requires the development of novel methods to adaptively leverage historical data for adaptation.

The proposed discrepancy measure aligns the global representation distribution between the source data and the new unlabeled data. Additionally, exploring class-specific prototypes can further enhance performance [17; 28], which we leave for future investigation.

### Adaptive Representation Alignment

In this part, we present the proposed algorithm. Inspired from the _online ensemble_ framework  developed in recent research on non-stationary online learning, we propose a two-layer adaptive learning algorithm. This approach is designed to handle the unknown change in data distribution and the limited data available in each round.

**Base Learner.** We construct a set of base learners \(\{^{i}\}_{i=1}^{K}\), each with a different learning window size. These base learners initialize their parameters as \(_{0}\). As shown in Figure 1, at each round, they perform online gradient descent using the loss defined in Eqn. (3), i.e,

\[^{i}_{t+1}=^{i}_{t}-_{}_{t}(^{i}_{t},_{0}).\] (4)

In addition to performing gradient descent, each base learner is assigned a learning window of varying size, determined by its index. As an example, the \(i\)-th base learner trains on data segments of length \(2^{i}\). At each round \(t=2^{i}\), its representation function \(^{i}_{t}\) is re-initialized to the initial state \(_{0}\) and a new learning process is initiated using online gradient descent - a procedure we refer to as a "restart".

Intuitively, when the data distribution shifts gradually or stabilizes in a new environment, the base learner that leverages the entire historical dataset tends to perform well. In contrast, when the distribution undergoes abrupt changes, a base learner that frequently restarts and relies only on recent data can achieve competitive performance . The flexibility of exploring a set of base learners allows us to design a meta learner that strategically combines these base learners, optimizing the overall performance of the ensemble algorithm.

**Meta Learner.** As shown in Figure 1, we employ a meta learner to combine the base learners that learn on different time length. To implement the meta learner, we employ the AdaNormalHedge algorithm with the geometric covering scheme . At each round, the meta learner receives a set of loss (in Eqn. (3)) from the base learners and combine them to generate the output for round \(t\). Let \(p^{i}_{t}\) be the weight assigned to the \(i\)-th base learner at round \(t\). The meta leaner outputs

\[_{t}(_{t})=_{i}p^{i}_{t}^{i}_ {t}(_{t}).\] (5)

The weight \(p^{i}_{t}\) for each base-learner \(f^{i}_{t}\) at round \(t\) is updated by first calculating

\[p^{i}_{t}(R^{i}_{t-1}+1,C^{i}_{t-1}+1)-(R^{i}_{t-1}-1,C^{i}_{t- 1}+1),\] (6)

where \((R,C)=([R]^{2}_{+}/3C)\), \(L_{t}=_{i}p^{i}_{t} L^{i}_{t}\), and

\[R^{i}_{t}=R^{i}_{t-1}+(L_{t}-L^{i}_{t}), C^{i}_{t}=C^{i}_{t-1}+|L_{t}-L^{ i}_{t}|.\]

We set \(R^{i}_{t}\) and \(C^{i}_{t}\) to \(0\) when \(t=2^{i}\) for each restarted base learner.

Figure 1: An illustration of our problem and the Ada-ReAlign algorithm. The test data accumulate over time with changing distributions, and only a limited number of unlabeled data are available at each step. Initially, an offline model and the statistics of the offline data are provided, followed by continuous adaptation to the new distributions. Ada-ReAlign is composed of a group of base learners and a meta learner. Each base learner operates with a different window size by restarting, learning representations for its respective period by minimizing the discrepancy from the source representation. The outputs from the base learners are then combined by the meta learner to produce the final representation.

After updating the representation learning model, we follow previous studies on TTA [32; 39; 25] by employing entropy minimization with a regularization term. This regularization ensures that the updated linear classification model remains close to the initial one, enhancing performance, which is defined as

\[^{t}_{}(,)=-_{y}[ ,_{t}()]_{y}([,_{t}( )]_{y}),\]

where \([]_{y}\) is taking the \(y\)-th entry of the vector \([]\). This regularization term encourages the model to generate confident predictions on unlabeled data by assigning higher probabilities to the most likely classes and lower probabilities to less likely ones. As a result, it helps prevent the model from becoming overly uncertain and making unreliable predictions. We then minimize the entropy of the predictions using the updated representation learning model with regularization, that is,

\[_{t}=*{arg\,min}_{}_{i=1}^{N_{t}}^{t }_{}(,_{i})+\|-_{0}\|_{2}.\] (7)

We summarize the main procedures of the proposed algorithm in Algorithm 1.

```
1:Initialization:\( i[K],^{i}_{t}=_{0}\)
2:for\(t=1\)to\(T\)do
3:for\(i=0\)to\(K\)do
4:if\(2^{i}\) mod \(t==0\)then
5: set \(^{i}_{t}=_{0}\), \(R^{i}_{t}=0\), \(C^{i}_{t}=0\)
6:endif
7:endfor
8: update base learners by Eqn. (4) and update weight \(_{t}_{K}\) according to Eqn. (6)
9: combine base learners according to Eqn. (5)
10: update classifier module according to Eqn. (7)
11:endfor ```

**Algorithm 1** Adaptive Representation Alignment

**Remark 3** (Computational Efficiency).: Since the \(i\)-th base learner is restarted every \(2^{i}\)-th round, within a time interval of size \(T\), we only need to maintain at most \((T)\) base learners. For example, with \(T=100,000\), only \(11\) base learners are required. In the next section, we will demonstrate that this is sufficient to achieve the optimal dynamic regret for convex losses and models.

Note that the ensemble structure requires maintaining multiple base learners, to further enhance the computational efficiency, we follow the spirit of  to reduce the base learners' update complexity, which involves updating only the _affine parameters_ of the normalization layers similar to those used in previous studies [21; 32; 28; 25]. The affine parameters typically comprise less than 1% of the total model parameters , making them particularly efficient to update.

### Theoretical Analysis

In this part, we provide the theoretical analysis of our proposed Ada-ReAlign algorithm for convex losses and models. For convex representation learning models, such as input convex neural networks , and convex loss functions, we show that the proposed algorithm achieves a dynamic regret guarantee, using the optimal representation sequence \(\{^{*}_{t}\}_{t=1}^{T}\) as the comparator.

**Theorem 1**.: _Assuming \(_{t}\) is convex, \(L_{t}()\) is a convex with respect to \(\), and the input \(_{t}\), the value of the loss function, and its gradient are all bounded. The Ada-ReAlign algorithm satisfies_

\[[_{t=1}^{T}L_{t}(_{t})-_{t=1}^{T}L_{t}(^{*}_{t} )](T^{2/3}V_{T}^{1/3}),\]

_where function variation \(V_{T}=_{t=2}^{T}_{}|L_{t}()-L_{t-1}()|\). Detailed proofs are in Appendix C.1._

Theorem 1 demonstrates that the average regret decreases at a rate of \((T^{-1/3})\). In this theorem, the function variation \(V_{T}\) captures the cumulative change in the optimal representation function sequence,serving as a measure of the underlying distribution shift in non-stationary environments and reflecting the inherent difficulty of the learning task. When the unlabeled test data stream is generated from a relatively stable environment, indicated by a small \(V_{T}\), the accumulative loss decreases nearly at a rate of \((T^{2/3})\). We notice that directly optimizing Eqn. (3) in each round would result in \((T)\) regret, as a generalization error would accumulate in every round. Thus, Theorem 1 provides the theoretical foundation for the empirical success of the Ada-ReAlign algorithm in effectively adapting to unknown and continuous distribution shifts.

## 4 Experiments

We evaluate the proposed Ada-ReAlign algorithm on two large-scale benchmark datasets: CIFAR10C and ImageNetC. Our empirical studies aim to answer the following three questions: **Q1**: Does the Ada-ReAlign algorithm outperform competing methods? **Q2**: Are the mechanisms in the proposed algorithm effective in handling non-stationary data? **Q3**: Can the proposed method handle real-world data streams with unknown distribution shifts?

### Experimental Setups

**Data Stream Generation.** The CIFAR10C and ImageNetC datasets provide both original clean data and corrupted data with varying types and levels of severity. We train the offline model on the clean data and use the corrupted data to generate unlabeled data streams, allowing us to simulate diverse distribution shifts within the data stream.

We assume a small batch of data is obtained at each round \(t\), where \(t[T]:=\{1,...,T\}\). In each round, this batch is generated from a fixed data distribution with a specific corruption type and severity level. By continuously varying the corruption types or severity levels, we simulate unlabeled data streams across different non-stationary environments. Let \(N_{t}\) denote the number of data points in round \(t\) and \(M\) represent the duration for which the data distribution remains unchanged, spanning \(M\) rounds between distribution shifts.

In our empirical studies, we simulate two common types of distribution shifts:

1. _Gradual Shift_: To simulate an unlabeled data stream with a gradual shift, we keep the type of data corruption constant throughout the stream while varying the severity level every \(M\) rounds. For example, in an unlabeled stream representing the "Snow" condition, the severity levels change sequentially as follows: \(*M*M*M...\). Here, \(*M\) denotes \(M\) consecutive rounds of data under the "Snow" condition with a severity level of \(1\).
2. _Sequential Shift_: To simulate an unlabeled data stream with a sequential shift, we keep the corruption severity level constant throughout the stream while changing the type of data corruption every \(M\) rounds. For instance, with a fixed severity level of 5, the corruption types evolve sequentially as follows: \([]*M[]*M[]*M ...\). Here, \([]*M\) represents \(M\) consecutive rounds of data with "shot" at severity level \(5\). In this paper, we set the severity level of the sequentially shifting data stream to \(5\).

**Contenders.** We compare the proposed algorithm with six competing methods. First, we use the performance of the initial _Non-adapt_ model as a baseline. Next, we include methods that restart the model at each round and adapt based on the current round's data: _TENT-RE_, which minimizes entropy at each round, and _MEMO_, which enhances robustness through data augmentation. We also evaluate methods that leverage all the data, such as _TENT-CT_, which updates the model using the results from the previous round via the TENT  and _TTAC_, which focuses on aligning the representation with the initial model using the entire data stream. Additionally, we include two state-of-the-art TTA methods designed for non-stationary environments: _CoTTA_ and _SAR_, both of which incorporate a reset mechanism to mitigate long-term forgetting during adaptation.

**Implementation Details.** We conduct experiments using a deep neural network with a ResNet50 architecture from the torchvision library. The initial model is trained on the original CIFAR-10 and ImageNet datasets. For our proposed algorithm, we use SGD as the update rule, with a momentum of \(0.9\) and a learning rate of \(0.0005\). Following prior studies [21; 32; 28; 25], we adapt the _affine parameters_ of the normalization layers in ResNet50 during the adaptation process. Further details are provided in **Appendix A.1**.

[MISSING_PAGE_FAIL:8]

### Ablation Study

Next, we evaluate the adaptability of the Ada-ReAlign algorithm to changing distributions, along with its computational efficiency and the effectiveness of each component. Additional ablation studies on the impact of the number of data each round \(N_{t}\) and duration \(M\) are provided in **Appendix A.3**.

**Detailed Analysis of the Meta-Base Structure in Ada-ReAlign.** We now take a closer look at our adaptive representation alignment algorithm, which integrates a meta-base structure. Specifically, we conduct experiments to evaluate the algorithm's ability to handle sequential shifts, where the distribution of online data alternates between two distributions every \(M\) rounds. To explore this, we vary the duration \(M\) and report the weight assignment (expressed as percentages) for base learners with different interval lengths in Figure 3. For instance, when \(M=8\), the data distribution shifts every \(8\) rounds. The weights assigned to each base learner are averaged over its active period.

Our results show that the meta learner effectively assigns the highest weight to the base learner whose interval length aligns with the switch period \(M\). This result shows that the right amount of historical data is reused, leading to strong performance in non-stationary environments.

In addition, in Figure 3 (a) compares the average error of the Ada-ReAlign algorithm with that of the TTAC algorithm over \(200\) iterations. During the experiment, the data distribution shifts three times, transitioning from Noise "Gaussian" to Blur "defocus", then to Weather "Snow", and finally to Digital "contrast". Each distribution is maintained for \(50\) iterations. TTAC is chosen for comparison since it also aims to align the model's representation with the initial one.

The results show that the Ada-ReAlign algorithm adapts quickly to new distributions as soon as a shift occurs. In contrast, the TTAC algorithm struggles, as it relies on all historical data, including samples from different distributions, which limits its adaptability.

**Efficiency and Performance Evaluation.** We conduct additional experiments to evaluate the algorithm's efficiency and performance gain. Specifically, we measure the processing time per round and the average accuracy, comparing the proposed algorithm with SAR (single model with forward and backward procedures) and AdaNPC (single forward procedure only) . Since AdaNPC requires access to the labeled source data during adaptation, we exclude it from the main comparison.

As shown in Figure 3 (b), the Ada-ReAlign algorithm demonstrates superior performance in both gradual and sequential shifts on the CIFAR10-to-CIFAR10C dataset. In terms of computational time, Ada-ReAlign (with 11 base learners) is approximately five times slower than SAR. However, SAR involves solving a bi-level optimization problem during adaptation, which incurs additional computational overhead. AdaNPC is more efficient than both gradient-based algorithms, as it employs a KNN-based non-parametric classifier. These findings answer the question **Q2**.

**Component Analysis of the Proposed Algorithm.** We evaluate the impact of each component within the proposed algorithm in the sequential shift environment. The proposed algorithm consists of two elements: alignment of the representation divergence with the initial model and minimization of prediction entropy at each round. To investigate their individual contributions, we run the algorithm across the entire data stream using different loss configurations. Specifically, "Ada-ReAlign w/o DA" refers to the version where only prediction entropy is minimized at each step (without Distribution Alignment), while "Ada-ReAlign w/o EM" denotes the version where only the representation is aligned at each round (without Entropy Minimization).

We report the average accuracy for each type of data corruption. As shown in Figure 5, both representation alignment and entropy minimization play crucial roles in the performance of the Ada-ReAlign algorithm. Moreover, the results highlight that, in most cases of distribution shifts, representation alignment offers greater performance gains, underscoring the importance of adaptive representation alignment in non-stationary environments.

**Comparison with Restart Mechanisms.** We compare the proposed algorithm in a sequential shift environment with three different restart mechanisms: _Ada-RE_, _Ada-CT_, and _Ada-TS_. In _Ada-RE_, the model is reset to the initial offline model at the beginning of each round and undergoes "one-step" TTA using the surrogate loss defined in Eqn (3). This approach is similar to the MEMO and TENT-RE algorithms, which restart the model at each round.

The second method, _Ada-CT_, updates a single model continuously, where the adapted model from the previous round serves as the initial model for the next. The third approach, _Ada-TS_, also employs a single model but incorporates a restart mechanism based on a threshold for model entropy. Following the previous study , we restart the model whenever the entropy falls below a threshold of \(0.4\).

The average accuracy of our proposed method and the three competing approaches is presented in Figure 5. The Ada-ReAlign algorithm consistently outperforms the competitors across nearly all datasets. These results highlight the critical role of the meta learner in the online ensemble structure, which enables the adaptive combination of base learners to resist the non-stationarity.

### Real-World Evaluation on Wildlife Species Classification

We further evaluate the proposed algorithm on a real-world wildlife species classification task using the iWildCam dataset , where the distribution of images naturally varies with the time and location of capture. The earliest 10% of the data is used as labeled offline data to train the initial model, while the remaining data serves as the unlabeled data stream. We compare the performance of our method against competing approaches, and the results demonstrate that our algorithm achieves the best performance. These results answer question **Q3**.

## 5 Conclusion

In this paper, we explored non-stationary representation learning for continual test-time adaptation. Beyond entropy minimization with regularization, we proposed adaptively aligning the unlabeled data stream, with its evolving distributions, to the source data representation by leveraging a sketch of the source data. To exploit this marginal information, we introduced a novel two-layer algorithm, Ada-ReAlign, designed to track and to approximate the optimal representation learning model at each round. Our theoretical analysis showed that the learned model is comparable to the optimal model sequence under convexity assumptions. Experiments on various benchmark datasets and a real-world application demonstrated the superiority of our approach over competing methods, confirming the effectiveness of the adaptive representation alignment mechanism.