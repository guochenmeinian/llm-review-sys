# Constrained Multi-Objective Bayesian Optimization

Diantong Li

School of Data Science

Chinese University of Hong Kong, Shenzhen

Shenzhen, China

diantongli@link.cuhk.edu.cn &Fengxue Zhang

Department of Computer Science

University of Chicago

Chicago, IL, USA

zhangfx@uchicago.edu &Chong Liu

Department of Computer Science

University at Albany, State University of New York

Albany, NY, USA

cliu24@albany.edu &Yuxin Chen

Department of Computer Science

University of Chicago

Chicago, IL, USA

chenyuxin@uchicago.edu

###### Abstract

Multi-objective Bayesian optimization has been widely adopted in scientific experiment design, including drug discovery and hyperparameter optimization. In practice, regulatory or safety concerns often impose additional thresholds on certain attributes of the experimental outcomes. Previous work has primarily focused on constrained single-objective optimization tasks or active search under constraints. We propose CMOBO, a sample-efficient constrained multi-objective Bayesian optimization algorithm that balances learning of the feasible region (defined on multiple unknowns) with multi-objective optimization within the feasible region in a principled manner. We provide both theoretical justification and empirical evidence, demonstrating the efficacy of our approach on various synthetic benchmarks and real-world applications.

## 1 Introduction

Multi-objective Bayesian optimization (MBO) is essential in scientific experiment design, such as drug discovery (Fromer and Coley, 2023) and hyper-parameter optimization (Gardner et al., 2019), where efficient exploration of experimental space is crucial. However, real-world applications often require meeting additional safety or regulatory thresholds. For instance, drug discovery must balance therapeutic effectiveness with safety standards (Mellinghoff and Cloughesy, 2022), and hyper-parameter optimization must avoid overfitting or violating constraints (Karl et al., 2023).

Previous studies have focused on single-objective constrained Bayesian optimization, unconstrained multi-objective Bayesian optimization, or constrained active search, leaving a gap in constrained multi-objective Bayesian optimization (CMOBO). Research in Constrained Bayesian Optimization (CBO) has primarily extended unconstrained problems with early work by Schonlau et al. (1998) and subsequent studies incorporating posterior sampling methods (Eriksson and Poloczek, 2021) and information-based approaches (Hernandez-Lobato et al., 2014; Wang and Jegelka, 2017) to scale CBO and improve feasibility analysis (Hernandez-Lobato et al., 2015; Perrone et al., 2019; Takeno et al., 2022). The augmented Lagrangian framework further transformed constrained tasks into unconstrained ones (Gramacy et al., 2016; Picheny et al., 2016; Ariafar et al., 2019), though it often lacked guarantees on feasibility and regret. Recent advancements (Zhou and Ji, 2022; Lu and Paulson, 2022; Xu et al., 2023; Guo et al., 2023) focus on relaxed CBO objectives to ensure theoretical convergence. In Constrained Active Search, active learning for the level sets offers sampleefficiency guarantees (Gotovos et al., 2013) but struggles with multiple unknown functions. Recent approaches (Malkomes et al., 2021; Komiyama et al., 2022) emphasize diversity but fall short of balancing learning constraints with objective optimization. Multi-objective Bayesian Optimization Golovin and Zhang (2020); Daulton et al. (2022); Suzuki et al. (2020) typically relies on the scalarization of objectives combined and resort to generalized expected improvements. A principled integrated treatment of the constraints and multiple objectives in Bayesian optimization remains challenging.

We propose a sample-efficient constrained multi-objective Bayesian optimization (CMOBO) algorithm that balances learning of level sets on multiple unknowns with multi-objective optimization within feasible regions. The insight is that we constrain the search space to areas with the potential of being feasible, while the random scalarization (Deng and Zhang, 2019; Golovin and Zhang, 2020) allows an efficient and theoretically justified acquisition within the region. We offer theoretical justification, together with empirical evidence on both synthetic benchmarks and real-world applications, demonstrating the effectiveness and efficiency of the proposed method.

## 2 Preliminaries and Problem Statement

### Problem Statement

Let \([n]\) denote the set \(\{1,2,...,n\}\) and let \([x]^{+}\) denote function \((0,x)\). For a vector \(\), its \(_{2}\) norm is denoted by \(\|x\|\). For any two vectors \(_{1},_{2}\), we use \(_{1}_{2}\) to denote their element-wise comparisons. To improve the readability of this paper, we utilize the big O notation to omit constant terms in theoretical results.

Consider a constrained multi-objective optimization problem:

\[_{} F()=[f_{1}(),...,f_{m}()],\] \[ G()=[g_{1}(),...,g_{c}()] 0.\]

where \(f_{i}\) and \(g_{j}:, i[m], j[c]\) are black-box functions, \(^{d}\) is the search space of \(F:^{d}^{m}\), \(m\) is the number of objectives and \(c\) is the number of constraints. The goal is to find the Pareto frontier \(P\) of \(F\). For the main paper, we assume the search space \(\) to be finite, and extend our discussion of the continuous and compact search space in Appendix D.

**Definition 2.1** (Pareto Front).: Define the feasible region of this problem as \(=\{|g_{i}() 0,  i[c]\}\). For points \(_{1},_{2}\), in the context of this problem, \(_{1},_{2}\). \(_{1}\) is said to _dominate_\(_{2}\) if **1**) \(f_{i}(_{1}) f_{i}(_{2}), i[m]\) and **2**) \( j[m]\) s.t. \(f_{j}(_{1})>f_{j}(_{2})\). Denote \(^{*}=\{|dominated\}\), then the Pareto front is defined as \(P=\{F()|^{*}\}\).

**Assumption 1** (Gaussian Process).: _Following Srinivas et al. (2009) (shown in Definition B.5), we assume that objectives and constraint functions are drawn from their GP priors._

### Evaluation Metrics

**Definition 2.2** (Simple Hypervolume Regret).: Let simple hypervolume (HV) regret at step \(t\), \(r_{t}\) be the difference between the real _hypervolume indicator_ of the Pareto front and the current approximation of the Pareto front. Define \(Y_{t}\) to be a set of observed objectives, s.t. \(|Y_{t}|=t\)

\[r_{t}=_{z}(P)-_{z}(Y_{t} F())\]

where \(F()\) is the range of the objective in feasible area, and \(_{z}(Y)\) is defined as \((\{y|y z,y Y\})\). Maximizing \(_{z}(Y_{t} F())\) reflects the exploration of the Pareto Front since it cannot be greater than \(_{z}(P)\). We accordingly define the cumulative hypervolume regret as \(_{t}=_{t=1}^{T}r_{t}\).

To address the problem of constrained optimization, we introduce the metric simple constraint violation that evaluates the constraint violation of the algorithm.

**Definition 2.3** (Simple Constraint Violation).: We define the simple constraint violation of constraint \(g_{j}\) at the \(t^{th}\) observation \(_{t}\) as \(v_{j,t}=[-g_{j}(_{t})]^{+}\) where \([:]^{+}=(0,)\). We also define the cumulative constraint violation of the \(j-th\) constraint as \(_{j,T}=_{t}^{T}v_{j,t}\).

To assess the ability of the algorithm of simultaneously exploring the Pareto front and keeping a low constraint violation, based on the above definitions, we define a metric that considers both constraint violation and Hypervolume Regret as constraint regret at step \(t\) as \(_{t}\), the minimum of the sum of simple HV regret and simple constraint violation of all objectives among steps before \(t\), which was originally proposed in Xu et al. (2023)

**Definition 2.4** (Constraint Regret).: \[_{t}=_{[t]}\{r_{}+_{j=1}^{c}v_{j,}\}\]

In the experiments, we normalize \(r_{}\) and \(_{j=1}^{c}v_{j,}\) so that they are comparable.

## 3 Constrained Multi-Objective Bayesian Optimization

```
1:for\(t\{1,...,T\}\)do
2:if\(_{}\{_{j[c]}w_{j,t}()\}<0\)then
3: Declare infeasibility.
4:endif
5: For scalarization, sample \(_{t}\) uniformly from \(_{m-1}^{+}\)
6: Optimize acquisition function: \(_{t}*{arg\,max}_{}s_{ _{t}}(U_{t}())\)  s.t. \(w_{j,t}() 0, j[c]\).
7: Evaluate \(F\) at \(_{t}\).
8: Update GP posterior with the incoming observations.
9:endfor ```

**Algorithm 1** Constrained **Multi-**O**bjective **B**ayesian **O**ptimization (CMOBO)

In each step of the algorithm, we apply a random scalarization, \(s_{_{t}}\), to the upper confidence bound surrogates of \(m\) objectives. We substitute the \(c\) constraint functions \(g_{j}\) with their upper confidence bound surrogates, following the approach of Xu et al. (2023), and maximize the scalarized function subject to the new constraints. In line 2, we solve an auxiliary optimization problem, the solution of which helps determine whether to declare infeasibility. It can also be used in the subsequent optimization of the acquisition. See A for further discussion.

Scalarization.In our multi-objective setting, we address the challenge of trading off multiple acquisition functions by applying a scalarization mapping \(s_{_{t}}\) as defined in (1), parameterized by a randomly drawn variable \(_{t}\) at each iteration. This _hypervolume scalarization_, introduced by Deng and Zhang (2019), Golovin and Zhang (2020), allows for the Monte Carlo estimator of the hypervolume and its estimation error. This approach enables a principled combination of optimizing objectives and considering unknown constraints. We extend this scalarization to the constrained optimization scenario with both theoretical guarantees and comprehensive empirical evidence of its efficiency. Here, we define the acquisition function in Algorithm 1 with scalarization of UCBs.

**Definition 3.1** (Scalarization function, Deng and Zhang (2019), Golovin and Zhang (2020)).: The _hypervolume scalarization_ is defined as

\[s_{}(y)=_{i[m]}([y_{i}/_{i}]^{+})^{m}y, ^{m}.\] (1)

Furthermore, it holds that

\[_{z}(Y_{t})=c_{m}_{_{k-1 }^{+}}[_{y Y_{t} F()}s_{}(y-z)]\] (2)

where \(_{k-1}^{+}\) denote drawing \(\) uniformly from \(_{k-1}^{+}=\{y^{m}|\|y\|=1,y 0\}\) and \(c_{m}=}}{2^{m}(+1)}\).

This scalarization function is derived from the integration in the calculation of hypervolume, offering an unbiased estimation of the HV. When applying a sample of the random scalarization to the UCBs of the objectives at a certain time \(t\), we have the following acquisition function.

**Definition 3.2** (Acquisition function).: Let the \(m\)-dimensional vector \(U_{t}()\) denote the UCB of \(m\) objectives \(f_{i}\). We define the acquisition function \(_{t}()\) as the value of \(U_{t}()\) scalarized by _hypervolume scalarization_ (1).

\[U_{t}()=(u_{f_{1},t}()-z_{1},...,u_{f_{m},t}( )-z_{m})\] (3) \[_{t}()=s_{_{t}}(U_{t}())\] (4)

where \(z=(z_{1},...,z_{m})\) is a chosen sub-optimal value.

Now, we need to construct an optimistic estimation of the constraint functions to incorporate the consideration of feasibility.

Constrained optimization.With the optimistic estimation of feasibility discussed above and the sample from the random scalarization adaptive tradeoff among multiple objectives, we can define the CMOBO optimization loop. In each iteration, we maximize the scalarized function subject to the newly defined constraints. In line 2 of Algorithm 1, we solve an auxiliary optimization problem to determine whether infeasibility should be declared. The solution to this auxiliary problem, \(_{}_{j[c]}w_{j}()\), can also be leveraged in the optimization of the acquisition function, as it helps discard inactive constraints. Combined with the optimistic feasibility estimation in line 6 of Algorithm 1, we know that CMOBO iteratively picks the maximizer of the _UCB of the Monte Carlo estimator of the constrained hypervolume_. This allows the following theoretical guarantee of CMOBO.

## 4 Experiments

We applied Algorithm 1 to the following five tasks, including **Toy Function** (\(d=2,m=2,c=2\)), **Branin-Currin Function** (\(d=2,m=2,c=2\)), **Penicillin Function** (\(d=7,m=3,c=3\)) Liang and Lai (2021), **Caco2++** (\(d=2175,m=3,c=3\)) adapted from Park et al. (2024) and **ESOL+** (\(d=2133,m=4,c=4\)) adapted from Delaney (2004). Here, the Penicillin Function simulates penicillin production; the last two contain organic molecules and drug-related properties. Detailed experimental settings are in Appendix A. We trimmed the initial observations, leading to unequal starting values. Benchmarks include Parallel Noisy Expected Hypervolume Improvement Daulton et al. (2021)(**qNEHVI**), parallel ParEGO Daulton et al. (2020)(**qParEGO**), Max-value Entropy Search for Multi-Objective Bayesian Optimization with Constraints Belakaria et al. (2020)(**MESMOC**), and Random Search. All experiments except for **MESMOC** were carried out using the BoTorch Python library Balandat et al. (2020). The complete results are in Appendix E.

Figure 1: CMOBO performance on Penicillin function. From left to right: Hypervolume, Cumulative Hypervolume Regret, Cumulative Constraint Violation, Constraint Regret.

**Trade-off Between Simple HV Regret and Cumulative Violation.** As shown in Figure 2 in Appendix E, while qNEHVI converges on simple HV regret at a rate comparable to CMOBO and achieves a higher final value, it incurs significantly more constraint violations. In more complex objectives, qNEHVI's simple HV performance is near-random, though its constraint violations remain sub-random. Scalarization-based **qParEGO** surpasses random search in Simple HV regret at around 30 steps, with near-random overall constraint violation performance. In this case, the Constraint Violation performance is dominated by Simple HV regret. This trade-off, measured by constraint regret (Definition 2.4), reflects the ability to explore the Pareto Front within feasible regions. High constraint regret indicates a failure to explore or maintain constraints. CMOBO outperforms all benchmarks, achieving the best balance with faster constraint regret reduction.

## 5 Theoretical Results

In this section, we provide the theoretical analysis of our algorithm CMOBO. We leverage the maximum mutual information gain \(_{i,T}\) of the \(i^{th}objective\) on GP after \(T\) iterations, and \(_{T}\) is an upper bound for \(_{i,T}, i[m]\) and \(_{j,T}, j[c]\). Detailed definitions are shown in B.6. The corresponding upper bounds for common kernels are previously studied by Srinivas et al. (2009).

**Case 1: \(\).** With assumptions stated in Section 2.1, given \(\) and the existence of the Pareto Front, we could bound the cumulative regret and corresponding violation in the following, with detailed proof deferred to Appendix C.

**Theorem 1** (Cumulative HV regret bound).: _After \(T\) iterations, under the conditions in Lemma 1, for \((0,1)\) our Algorithm CMOBO satisfies that_

\[_{T} O(m^{2}[_{T}T T]^{1/2})\] (5)

_with probability at least \(1-\)._

**Theorem 2** (Cumulative constraint violation bound).: _Let \(c\) denote the number of constraints, then \( j~{}[c]\) and under the conditions in Lemma 1, with probability at least \(1-\), our Algorithm CMOBO satisfies that_

\[_{T} O(}).\] (6)

Combining Theorem 2 and Theorem 1, we can bound Constraint Regret defined in Definition 2.4 by \(O(cm^{2}[_{T} T/T]^{1/2})\) by taking the sum of two cumulative terms and taking minimum with respect to step indexes.

**Case 2: \(=\).** Now we assume \(=\). We conclude that we can declare infeasibility in (1) in Algorithm 1 within a certain number of steps with high probability.

**Theorem 3** (Declaration of infeasibility when the problem is infeasible).: _With conditions in Lemma 1, and that \(_{T}}}{}=0\). If the problem is infeasible, i.e. \( j[c],_{}g_{j}()=<0\) Then, given \((0,1)\), Algorithm 1 will declare infeasibility within number of steps equivalent to \(=_{T^{+}}\{T|}}{}  C\}\) with probability at least \(1-\)._

## 6 Conclusions

We proposed **CMOBO**, a stochastic scalarization-based Bayesian optimization algorithm based on stochastic scalarization for multiobjective constrained problems. **CMOBO** outperforms the **qParEGO** in various tests and excels in metrics that account for hypervolume regret and constraint violations, even if it does not always match **qNEHVI** in hypervolume regret convergence speed. We also provide a theoretical analysis of the metrics used. Future improvements include active learning of the feasible domain and adaptive scalarization parameters. While we have developed a heuristic to enhance candidate selection efficiency, challenges such as model misspecification remain.