# Combining Observational Data and Language

for Species Range Estimation

Max Hamilton\({}^{1}\) Christian Lange\({}^{2}\) Elijah Cole\({}^{3}\) Alexander Shepard\({}^{4}\) Samuel Heinrich\({}^{5}\) Oisin Mac Aodha\({}^{2}\) Grant Van Horn\({}^{1}\) Subhransu Maji\({}^{1}\)

\({}^{1}\)UMass Amherst \({}^{2}\)University of Edinburgh \({}^{3}\)Alto's Labs

\({}^{4}\)iNaturalist \({}^{5}\)Cornell University

###### Abstract

Species range maps (SRMs) are essential tools for research and policy-making in ecology, conservation, and environmental management. However, traditional SRMs rely on the availability of environmental covariates and high-quality species location observation data, both of which can be challenging to obtain due to geographic inaccessibility and resource constraints. We propose a novel approach combining millions of citizen science species observations with textual descriptions from Wikipedia, covering habitat preferences and range descriptions for tens of thousands of species. Our framework maps locations, species, and text descriptions into a common space, facilitating the learning of rich spatial covariates at a global scale and enabling zero-shot range estimation from textual descriptions. Evaluated on held-out species, our zero-shot SRMs significantly outperform baselines and match the performance of SRMs obtained using tens of observations. Our approach also acts as a strong prior when combined with observational data, resulting in more accurate range estimation with less data. We present extensive quantitative and qualitative analyses of the learned representations in the context of range estimation and other spatial tasks, demonstrating the effectiveness of our approach.

## 1 Introduction

Collecting sufficient point-based observations of species in the wild allows us to infer species range maps (SRMs), which describe the spatial extent of where a species is likely to occur. These maps are invaluable, enhancing our understanding of natural history and informing land use and conservation decisions. Large-scale citizen science projects like iNaturalist  and eBird  have recently accelerated SRM generation by systematically consolidating millions of observations across tens of thousands of species. By combining these extensive databases with environmental covariates, we can produce accurate SRMs. However, there remains a 'long tail' of species with few observations, and current methods fall short of producing reliable range maps in such low-data settings.

We propose learning SRMs by combining citizen science observations with text descriptions of species from Wikipedia (see Figure 1). These text descriptions describe a wide array of properties including habitat preferences, range estimates, and visual attributes. Our framework learns to map location embeddings over the Earth's surface and text embeddings from Wikipedia  articles into a common space based on the species observations (see Figure 2). This provides a way to ground the information in text describing tens of thousands of species to spatial locations based on millions of observations. As shown in Figure 1, our resulting model allows us to estimate SRMs based on text descriptions that might be known to an ecologist, such as habitat preferences, even when no location observations are available.

We evaluate our text-driven approach for zero-shot estimation of SRMs for species from the IUCN  and eBird Status and Trends (S&T)  benchmarks from , which were excluded from the training data. Our model easily outperforms baselines (Table 1) and is competitive with SRMs estimated with ten observations for S&T species (Figure 3). Additionally, our model can be combined with observational data to achieve strong few-shot performance. Logistic regression models are regularized to be close to the species vector obtained from text descriptions, allowing us to match the performance of SRMs estimated using an order of magnitude more observations (Figure 3).

While training is based on Wikipedia articles, it is unrealistic to expect a biologist to provide such extensive information for a novel species. Therefore, we evaluate our model based on short summaries, often just a few sentences long, that describe various aspects of the species. We further organize the summaries based on descriptions of the range (e.g., where they appear) and habitat preferences. While a biologist might not know the full range of an unknown species, they may be familiar with some of the latter (e.g., a tree might be in a tropical forest, or a bird might prefer wetlands). However, training on both forms of data allows the location embeddings to capture a wide range of geographic concepts embedded in language, such as countries, continents, climate regions, topology, and biomes, as revealed in our visualizations (Figures 4 and 5). Even short text summaries provide a significant boost in estimation accuracy over baselines when there are zero or few observations available. Our code and data is publicly available at: https://github.com/cvl-umass/le-sinr

## 2 Related work

Species distribution models (SDMs).SDMs are a broad family of models, primarily from the ecological statistics literature, that are concerned with modeling and predicting different geospatial properties of a species of interest [14; 13]. These spatially varying properties encompass quantities such as occurrence (i.e., the presence or absence of a species) through to abundance (i.e., a count of the number of individuals from a given species present). By integrating occurrence predictions over the earth, we can generate the _range_ of a species, which is defined as the geographic area in which a species can be found during its lifetime. Existing works can be broadly categorized based on the completeness of the data they are trained on (e.g., presence-only vs. presence-absence data), the number of species they simultaneously model (e.g., single vs. joint methods), or how interpretable they are (e.g., machine learning vs. mechanistic models). For an introduction to SDMs, we point interested readers to the following survey .

Most relevant to our work is the growing number of deep SDM approaches. These methods explore the core task from a representation learning perspective by training on raw observation data, typically from multiple species simultaneously, to learn an encoding of geographic space that is more predictive of species presence.  demonstrated the advantages of this approach by showing that model performance improves when trained on larger amounts of data, even if that data comes from disjoint species that do not appear in the evaluation set. Recent work has explored various challenges and design decisions related to training these models, addressing topics such as data imbalance , spatial biases , location encodings , the use of remote sensing data [11; 31], active learning , binarizing range maps , and modeling species co-occurrence . However, the current literature has not extensively investigated the few-shot setting, where very limited or potentially no observation data is available. There are an estimated nine million species on Earth , and given that only a limited proportion of these have reliable range estimates, there is a need for methods that can reliably estimate geospatial properties of interest from few observations.

Figure 1: Our LE-SINR model takes as input free-form text describing aspects of a speciesâ€™ preferred habitat or range and geospatially grounds it to generate a plausible range map for that species.

Geospatial data and large language models (LLMs).High-capacity transformer-based architectures , coupled with large web-sourced text training data, have largely contributed to recent advances in LLMs. LLMs have been demonstrated to be effective across a range of language-based reasoning tasks [35; 21; 7]. Inspired by this, recently there have been multiple attempts to explore what, if any, geospatial information is encoded inside of these models. For example,  evaluated a pre-trained closed-source LLM (i.e., GPT-4 ) on a range of geospatial tasks such as point based ones (e.g., location, distance, and elevation estimation) in addition to more complex path-based ones (e.g., geographic and outlines route planning) via carefully designed text prompts. They later extended this work to multimodal LLMs that can also take images as input . In both cases, they observed impressive capabilities, but also some notable limitations.

In  the authors used pre-trained LLMs to map geographic coordinates to continuous geospatial properties (e.g., population, house value, etc.). They improved upon simple text prompts by engineering a prompt which provides spatial context in terms of relative distance to nearby named locations to the query coordinate of interest. By fine-tuning the LLM they demonstrated that their approach works better than the more naive encoding. However, their approach is expensive to evaluate at inference time as it requires a full forward pass of the LLM for every geographic coordinate of interest.

Most related to our work is LD-SDM  which also uses an LLM in conjunction with an SDM. Their goal is to predict the spatial range of a set of species of interest using location observation data at training time. However, instead of simply learning a per-species latent embedding vector as in , they employ a frozen LLM to map a text string that describes the explicit taxonomic hierarchy (i.e., species, genus, family, etc.) of a species of interest to a latent embedding. Unlike us, their species text description is not very expressive (i.e., it has a very specific hierarchical structure) and thus cannot generalize as effectively to distinct held-out species at evaluation time. Instead, in this work, we show that it is possible to predict the range of a previously unseen species from free-form, highly unstructured, internet sourced text that describes its habitat and/or range preferences. Furthermore, once trained, we show that our approach is also able to efficiently and densely geoguentially ground non-species related text. Unlike , our approach is computationally efficient at inference time, requiring only one LLM forward pass for the text query of a species of interest, as opposed to one forward pass for each location of interest, which can number in the millions depending on the spatial resolution at which the evaluation is performed.

## 3 Methods

### Problem Setup

We focus on the problem of estimating SRMs across multiple species, indicating their presence or absence at each location on Earth. For a given location \(\), our goal is to predict the probability of each species being present there. Our observation dataset is composed of pairs \(\{(_{i},y_{i})\}_{i=1}^{N}\), where

Figure 2: LE-SINR learns to align location and text representations at training time using presence-only observation data and habitat or range descriptions for a set of species. Optionally, we can also include a learnable species token \(E_{y}\) allowing range estimation for seen species \(y\) from the training set. The model is trained on millions of observations from iNaturalist and language data from Wikipedia articles across thousands of species. LE-SINR supports zero-shot range estimation based on text descriptions for novel species and can also be used as a prior for few-shot range estimation.

\(_{i}=(lat,lon)\) is a geographic location and \(y_{i}\{1,,S\}\) is the observed species label. We use the dataset proposed in SINR , consisting of 35.5 million observations covering 47,375 species observed prior to 2022 on the iNaturalist platform. Included species have at least 50 observations. Removing those that are included in the S&T and IUCN evaluation benchmarks results in 44,181 species, which forms our training set.

We also consider estimating SRMs from text-based descriptions in addition to observational data. To this end we curate a text dataset \(\{(_{i},y_{i})\}\), where \(_{i}\) is a text description sourced from Wikipedia pertaining to species \(y_{i}\). For a particular species \(y_{i}\) and corresponding text description \(_{i}\), we aim to predict whether \(y_{i}\) is present at some location \(_{i}\) given \(_{i}\). It is important to emphasize that this prediction only depends on the text description \(_{i}\) and query location \(_{i}\). Thus, we are not constrained to only making range predictions for species that have been observed during training. This allows for zero-shot species range estimation, where we can generate a range map of a species not in our observation dataset by utilizing a text description for it.

### Text Data

We source our text descriptions from Wikipedia . For a particular species, we search for its Wikipedia article using its scientific name. We then extract the text and divide it into chunks by section. Every article starts with a lead section, which typically provides an overview, followed by a varying number of body sections. These body sections can describe a diverse range of attributes such as taxonomy, description, habitat, behavior, diet, etc. To improve data quality, we remove sections with "References," "Links," and "Bibliography" in their names. Since each species has multiple sections, at training time we randomly sample one section per iteration. Overall, our text dataset contains 127,484 sections from 37,889 species' articles. Note, not all species in our observation dataset have an associated text description.

### Language Enhanced SINR (LE-SINR) Architecture

We utilize the Spatial Implicit Neural Representation (SINR)  framework for our approach, which models the probability of presence for a species \(y\) at given location \(\) as \((f_{}() E_{y})\), where \(f_{}()\) is a location encoding, \(E_{y}\) is an embedding of species \(y\) and \(\) is the sigmoid function. Our architecture, shown in Figure 2, is similarly composed of two branches: one for representing locations and one for representing species. Each branch outputs a 256-dimensional feature vector. The probability of occurrence is then estimated by the sigmoid of their dot product.

The location branch is a location encoder model, \(f_{}()\), with parameters \(\), which takes a position embedding \(\) (e.g., a location denoted by latitude and longitude) as input. The species branch is composed of two models, allowing us to generate species embeddings in two different ways. The first is a text-based species encoder, \(g_{}()\), with parameters \(\), which takes text \(\) from our Wikipedia text data as input. The second species representation is a batch of species tokens optimized directly, \(E^{S 256}\). Given a known species \(y\{1,,S\}\) in the observation dataset, we can generate its representation with a simple lookup, \(E_{y}\). Since we learn a unique species token for each species in the training set, these species tokens cannot be used in the zero-shot setting. However, we are able to maintain the ability to have true supervised evaluation on species seen at training time. Additionally, the species tokens are used when a species has no text description.

Our text-based species encoder has two parts: a frozen LLM used to extract text embeddings and a learned fully connected network. As mentioned previously, to perform zero-shot SDM, we cannot directly utilize the species tokens. Instead, we input segments of text sourced from Wikipedia articles. Since these text segments can be as long as multiple paragraphs, we utilize a pretrained Large Language Model, GritLM , to create a fixed-length text embedding. GritLM is a recent language model with strong performance on text embedding tasks like document classification and retrieval. Due to the length of text in our data, it is much easier to work with a fixed-length embedding than with per-token embeddings from generative models like Llama3 . Given this text embedding, we then learn a three-layer fully connected language encoder network that outputs the final species embedding. As our approach incorporates language within the SINR framework for range estimation, we call it: **Language Enhanced SINR (LE-SINR)**.

### Training LE-SINR

During training we only have access to presence observations, i.e., locations where species have been observed, and do not have any absence observations, i.e., locations where species have been confirmed to be absent. As a result, we train our model with a modified version of \(_{}\) from SINR , which was one of the best-performing losses in their experiments. It minimizes binary cross-entropy with positives sampled from the observation dataset and negatives (i.e., 'pseudo absences') selected to be all other species at the same observation location, as well as all species at a uniformly sampled random location.

This loss is computationally expensive with our model, as it requires computing a species embedding for every species and sample in the batch. To reduce this computation, we perform an approximation by selecting \(M-1\) random negative species at the observation location and \(M\) random negatives from the random location, where \(M S\). We also weight the negatives by the inverse of the proportion selected. This ensures that the expectation over the randomly selected negative species equals the original loss. Our modified loss is given by:

\[^{}_{}=-_{j=1}^{M}[ _{[z_{j}=1]}(_{j})+_{[z_{j} 1]} (1-_{j})+(1-_{j}^{})].\] (1)

Here, \(}^{M}\) are predictions at one location for the ground truth species and \(M-1\) random other species, \(^{M}\) is the corresponding one-hot label, and \(}^{}^{M}\) are predictions for a random species at a random location uniformly sampled over earth. For all models, we set \(M=192\) based on memory and compute considerations. We also tried values as large as 2,048 but saw significantly slower training times with no effect on zero-shot performance.

During training, we first use the location encoder to generate location features. We then use these to make two predictions: one using the species tokens and the other from the text-based species embeddings. Finally, we apply \(^{}_{}\) to both of these predictions independently. We do not explicitly encourage the species tokens and text-based species embeddings to be close. In our preliminary experiments, this seemed to be too restrictive and hurt performance.

### Evaluation

Similar to SINR, we evaluate our model using expert-derived range maps from the eBird Status & Trends (S&T) dataset , which covers 535 bird species with a focus on North America, as well as range maps for 2,418 species from the International Union for Conservation of Nature (IUCN) Red List . During training, we exclude observations for these species to assess zero-shot and few-shot performance, measured using mean average precision (MAP), i.e., average precision (AP) averaged across all species in the set. SINR models trained with target species' observations provide an "upper bound" on performance.

Zero-shot evaluation.Our model naturally supports zero-shot evaluation by providing a text prompt from species not in the training data to the species model. The output species embedding can then be multiplied with position features to generate the probability of occurrence. We can then compute a precision-recall curve by varying the threshold over the score to generate the range map given an expert derived range map. We again report the mean average precision (MAP) across species in the S&T and IUCN datasets.

An important choice here is which text we provide for the evaluation. The Wikipedia section names are not consistent across articles and often the same information can appear under different headings. At the same time, it is unlikely that one can provide such detailed text for novel species. To standardize the information for a realistic evaluation, we use the open-source Llama-3 model  to generate two short summaries: a habitat description and a range description from the article text. The range description is most informative as it typically lists specific countries or regions where the species can be found. In practice, such a rich description might not be available, so we also generate a habitat description. During evaluation, we use these summaries instead of the Wikipedia text. Figure 4 shows some example summary texts along with zero-shot range predictions from LE-SINR. Further examples can be found in the Appendix.

Few-shot evaluation.While the original SINR model was trained with observations from the target species, we also consider a setting where position features are used to derive SRMs from sparse observational data. We achieve this by performing logistic regression with \(L_{2}\) normalization on the position features to predict presence or absence. For each species, we sample \(n_{p}\) positives from the observation dataset and \(n_{n}=20,000\) negatives. To mimic the \(_{}\) loss, we sample 10,000 negatives uniformly across the Earth and 10,000 negatives randomly from the training dataset species locations. Our logistic regression loss is given by,

\[L_{}=-}_{i=1}^{n_{p}}-(^ {}f(_{i}))-}_{i=1}^{n_{n}}1- (^{}f(_{i}))+d}|| ||_{2}^{2},\] (2)

where \(^{256}\) is the species parameter being optimized, \(\) is the regularization strength, \(d=256\), \(\) is the sigmoid function, \(f(_{i})\) is the output of the position branch for the \(i\)-th positive observation, and \(f(_{i})\) is the output of the position branch for the \(i\)-th negative observation. We use this loss to estimate a SRM when text is not provided at test time. The learned weights can then be applied to all positions to derive a range map.

To incorporate text at test time along with observational data, we modify the regularization to be the distance from the predicted text-based species embedding, resulting in the following loss,

\[L_{}=-}_{i=1}^{n_{p}}-( ^{}f(_{i}))-}_{i=1}^{n_{n}} 1-(^{}f(_{i}))+d}||-_{}||_{2}^{2},\] (3)

where \(_{}\) is the output of the text-based species encoder when provided a text summary. This encourages the learned species weight vector to be similar to the text derived one. This approach is simple to implement, and our experiments indicate that it is also effective.

### Implementation Details

We closely follow the hyperparameters from SINR for a fair comparison. We train with the Adam optimizer for 10 epochs with a learning rate of 0.0005. The species network has three linear layers with ReLU activation. The input text embedding dimension is 4,096, the hidden dimension is 512, and the output species embedding dimension is 256. During training, at each iteration, we choose a random Wikipedia section to generate each species embedding. For logistic regression in the later few-shot evaluation experiments, we use a regularization strength \(=20\). Training a single LE-SINR model from scratch using all the text and observational data takes about 10 hours on a single NVIDIA RTX 2080ti GPU occupying about 10GB of VRAM. Wikipedia text embeddings and their summaries were generated once using a distributed GPU cluster.

## 4 Results

### Zero-shot Range Estimation

In Table 1, we compare against several baseline methods to establish performance lower and upper bounds as zero-shot range prediction is a novel task. The constant prediction baseline assumes a species is present everywhere, while model mean predicts the mean species distribution map for all species. We also show the 'oracle' performance obtained by training a SINR which sees observations from evaluation species at training time. All models were trained with observations capped at \(1,000\) with uniform negatives, using the AN_full loss and '+Env' indicates models that are trained using extra environmental features as input, as in . We compare these to zero-shot range estimates obtained using various LE-SINR models and input text.

The results show that the zero-shot range estimates comfortably outperform the baselines, achieving non-trivial performance with no observations. Range text works the best, but even habitat text achieves strong performance on both IUCN and S&T species. Similar to SINR, we observe a boost when including environmental covariates. LE-SINR with explicit species tokens matches the Oracle SINR performance, i.e., when evaluation species are used during training, suggesting that LE-SINR does not lose performance on observed species. Therefore, LE-SINR can be used both to explicitly model observed species and for zero-shot prediction from text for novel species.

[MISSING_PAGE_FAIL:7]

Figure 3 shows few-shot results obtained using the text-driven prior from LE-SINR, as described in Section 3.5, on IUCN (left) and S&T (middle) species. Logistic regression models regularized toward species weights obtained from range and habitat text provide a significant boost over vanilla logistic models regularized toward zero. The gap is significant when the training data is limited, i.e., fewer than 100 observations. Range text priors reduce the need for observations on IUCN and S&T by a factor of \(3\) and \(10\), respectively. Figure A2 in the Appendix shows some qualitative examples of how range estimates change with different numbers of observations.

### Evaluation of Learned Positional Embeddings

Prior work on generating SRMs often rely on carefully-selected spatial covariates such as temperature, elevation, precipitation, land cover, etc., to predict the distribution of species based on a few observations. Our approach provides a way to learn a rich set of spatial covariates based on language data. Figure 3 (right) compares the position embeddings of SINR and LE-SINR as spatial covariates on the task of few-shot range estimation. In both cases, we use a model whose location branch is trained with position only (i.e., only latitude and longitude) as input to avoid conflation of the learned covariates with input ones. We find that the intermediate position embeddings learned when trained using language lead to better generalization, especially when training data is limited. Note that here we do not use any language input at test time, as both models are trained simply using observation data, same as the logistic regression baselines.

Figure A1 in the Appendix shows that the position embeddings of LE-SINR have a richer spatial structure than SINR. This figure was obtained by projecting the learned position embeddings to three dimensions using Independent Component Analysis and visualizing them as color in RGB space. Figure 5 visualizes a variety of maps generated from natural language. LE-SINR has learned about geographical regions, climate zones, and even abstract non-species concepts by aligning text representations with geographic locations through species observations. For example, the presence of a species such as the 'Fennec Fox' allows the model to learn that the species is associated with concepts such as the deserts of North Africa, particularly the Sahara Desert, sandy environments, and extreme temperatures based on information in Wikipedia text.

### Limitations and Broader Impacts

While we show that language and location observations can be combined to estimate range maps from a few examples, we do not compare to other few-shot methods such as those based on meta-learning [29; 20; 16]. However, recent results for non-species range estimation tasks indicate that a good underlying representation is a key component to superior few-shot performance, even outperforming more advanced methods .

Another limitation is that our models are most applicable when range and habitat descriptions are available with very few observations, which is not common. While we evaluate our approach based on Wikipedia, a more realistic scenario involves obtaining descriptions of rarely observed species from domain experts. However, we note that many species have substantial Wikipedia articles despite having fewer than 50 observations on iNaturalist.

Figure 3: **Range Estimation from Text and Observations. (Left) IUCN and (Middle) S&T results for zero-shot range estimation based on text, and few-shot estimation based on the text-driven prior. Both range and habitat texts improve few-shot performance over baseline SINR. (Right) Comparison of the position branch of SINR and LE-SINR for range estimation using a few examples. Language-driven covariates learned by LE-SINR lead to better generalization when observations are limited. We report the MAP for range estimation for species in the S&T and IUCN test sets.**

Our models rely on text embeddings and summaries generated from LLMs, and thus may inherit the biases contained within them. For example, our model could further amplify biases in the data by incorrectly spatially localizing specific text terms inappropriately. Both Wikipedia text and observational data from iNaturalist are biased toward the United States and Western Europe. As a result, our models may not generalize as well to other geographical regions. There could also be potential negative consequences associated with using the species range predictions from our model to inform conservation or policy decisions. While our results are promising, they may still fall short of the quality needed for such high-stakes use cases. Therefore, caution is encouraged when making decisions based on the model's predictions. Another risk is that the model could be used to locate threatened or endangered species. To mitigate this, we only train on publicly available observation data that has been deemed safe to redistribute by the iNaturalist platform.

## 5 Conclusion

The generation of detailed species range maps is often constrained by the need for extensive location observations, which can be expensive and time-consuming to collect. Our LE-SINR approach mitigates this issue by mapping species observations and text descriptions into the same space, enabling zero-shot range map generation from text alone. Unlike other methods that make use of text, we can generate a global range map for a species with a single forward pass of our language model, significantly increasing usability for potential downstream users.

Our extensive evaluation shows that zero-shot range maps produced by LE-SINR, derived solely from text descriptions, can outperform those produced by state-of-the-art models trained on tens of observations. Additionally, using LE-SINR as a prior also significantly enhances few-shot performance. By learning to relate text descriptions of species with locations where that species has been observed, we show that LE-SINR develops an understanding of a wide range of geographical and environmental features, as well as unrelated concepts not seen in the training data such as historical events and aspects of culture.

Figure 4: **Zero-Shot Range Estimation. Here we show the â€˜Habitatâ€™ and â€˜Rangeâ€™ text descriptions and corresponding zero-shot range maps for the Hyacinth Macaw (top) and the Yellow Baboon (bottom), with expert derived range maps inset.**

Figure 5: **Geospatial Grounding of Non-Species Concepts.** LE-SINR is able to geographically ground text prompts to locations on the earth. Here we display the inner product between the location encoderâ€™s features and the language modelâ€™s encoding of the text displayed in the bottom left of each panel. This includes coarse concepts such as continents and countries (top row), geographic features such as specific lakes and mountain ranges (second row), in addition to concepts that do not appear in our species text training data but are likely already represented in the language model (third and fourth row). We do, however, observe some limitations resulting from the biases in our training data which favors North America, Europe, and Australasia (final row). Please zoom in to see more detail.