# From Transparent to Opaque: Rethinking Neural Implicit Surfaces with \(\alpha\)-NeuS

# From Transparent to Opaque: Rethinking Neural Implicit Surfaces with \(\)-NeuS

Haoran Zhang1,2, Junkai Deng3, Xuhui Chen1,2, Fei Hou1,2, Wencheng Wang1,2, Hong Qin4, Chen Qian5, Ying He3

Equal contributions.Corresponding author.

Hong Qin4, Chen Qian5, Ying He3

###### Abstract

Traditional 3D shape reconstruction techniques from multi-view images, such as structure from motion and multi-view stereo, face challenges in reconstructing transparent objects. Recent advances in neural radiance fields and its variants primarily address opaque or transparent objects, encountering difficulties to reconstruct both transparent and opaque objects simultaneously. This paper introduces \(\)-NeuS--an extension of NeuS--that proves NeuS is unbiased for materials from fully transparent to fully opaque. We find that transparent and opaque surfaces align with the non-negative local minima and the zero iso-surface, respectively, in the learned distance field of NeuS. Traditional iso-surfacing extraction algorithms, such as marching cubes, which rely on fixed iso-values, are ill-suited for such data. We develop a method to extract the transparent and opaque surface simultaneously based on DCUDF. To validate our approach, we construct a benchmark that includes both real-world and synthetic scenes, demonstrating its practical utility and effectiveness. Our data and code are publicly available at https://github.com/728388808/alpha-NeuS.

## 1 Introduction

Surface reconstruction from multi-view images has been an important area of research for decades. Traditional methods such as structure from motion (SfM)  and multi-view stereo (MVS)  calibrate images and reconstruct 3D geometry based on color consistency. Recently, the emergence of Neural Radiance Fields (NeRF)  has revolutionized the field, producing impressive results in novel view synthesis results via volume rendering. Its implicit surface-based variants, such as NeuS , VolSDF , HF-NeuS , and NeuS2 , further advance this field by reconstructing high-quality geometry and appearance through the learning of signed distance fields (SDFs). However, these NeRF family methods are limited to reconstructing opaque surfaces. Reconstructing transparent surfaces presents a greater challenge, with relatively few investigations to date.

Recently, some works dealt with the refraction and reflection effects in the transparent scenes. For example, ReNeuS  effectively reconstructs opaque objects within transparent materials, such as glass, by assuming known parameters for these materials. Similarly, NeuS-HSR  separatesreflections from the glass to reconstruct objects within thin transparent objects. While these methods successfully reconstruct the opaque objects behind or within transparent materials, they do not extend to reconstructing the transparent objects themselves.

To address the challenges described above, we propose a new method, called \(\)-NeuS, for the simultaneous reconstruction of thin transparent objects and opaque objects. Given that transparent objects are thin, we can disregard refraction effects. A key observation in our work is that transparent surfaces induce local extreme values in the learned distance field of NeuS  during neural volumetric rendering. NeuS is unbiased, i.e., the maximum volume rendering weight coincides with the object surface, for opaque surface . We advance the theory of NeuS and prove that NeuS is unbiased for all transparent and opaque surfaces. Under various opacities, the unbiased surfaces are either the non-negative local minimum or the zero level set of the distance field learned by NeuS. Thus, we are able to extract the unbiased surface for transparent and opaque surface reconstruction simultaneously. However, precise values of these non-negative local minima are unknown beforehand and can vary spatially, they are unsuitable for extraction by conventional iso-surfacing algorithms, such as marching cubes , which require a specified fixed iso-value. To effectively extract the target geometry for transparent objects, we take the absolute value of the distance fields, making the unbiased surfaces become the local minima of the absolute distance field. Based on DCUDF , we introduce an optimization method to simultaneously extract the unbiased surfaces of the transparent and opaque surfaces.

To validate our approach, we construct a benchmark containing 5 real-world scenes and 5 synthesized scenes. Experimental results show that \(\)-NeuS effectively reconstructs both transparent and opaque objects in all tested scenarios. To summarize, our main contributions are as follows:

1. We prove that the density functions proposed in NeuS  are unbiased across a continuum of material opacities, from fully transparent to fully opaque, thereby completing the theoretical framework of NeuS.
2. We show that transparent and opaque surfaces correspond to the non-negative local minima and the zeros of the learned distance field of NeuS, respectively.
3. We present a method for simultaneously extracting the unbiased surfaces corresponding to the target geometry of transparent objects and opaque objects based on DCUDF , from mixed SDF and unsigned distance field (UDF).
4. We construct a benchmark comprised of 5 real-world scenes and 5 synthetic scenes for validating our method.

## 2 Related Works

### 3D reconstruction from multi-view images

Reconstructing 3D objects from multi-view 2D images has been a research interest for decades, with a wide range of approaches having been proposed. Traditional model structure recovery methods try to understand the images and infer the structure of the model. Notable examples in this category are voxel based approaches [12; 13; 14; 15; 16] and point cloud based approaches including SfM  and MVS .

Recently, with the advancement of machine learning, volume rendering based approaches have achieved high-fidelity reconstruction quality. Based on 3D Gaussian splatting , many model reconstruction methods are proposed, e.g., SuGaR  and 2D Gaussian splatting . Another category of method for surface reconstruction is NeuS  and VolSDF , based on NeRF . In particular, NeuS has gathered special attention and has spawned multiple descendants like Geo-Neus  and HF-NeuS . There are also several studies that focus on non-watertight model reconstruction also by extending NeuS, including NeUDF , NeuralUDF , NeAT  and 2S-UDF . However, these works all assume that the object is opaque.

### 3D reconstruction of transparent objects

Reconstruction of transparent objects presents a significant challenge due to the complex light paths  caused by refraction and reflection, which hinder multiview stereo from effectively solving this problem . Traditional methods [32; 33; 34] use additional devices or assumptions to reconstruct transparent objects. Li et al.  used deep learning to further improve the quality of reconstruction without additional inputs, but tend to produce over-smoothing results. With the development of NeRF , some works have explored how to use neural rendering to reconstruct transparent objects [25; 27; 35; 36; 37] for capturing more details. However, they all just focus on transparent objects neglecting opaque objects.

There are also some works attempting to capture the correct geometry of opaque objects under the influence of reflection and refraction, which are primarily caused by transparent objects. NeRFeN  and Ref-NeuS  reconstruct models by considering reflections in NeRF pipeline. NeuS-HSR  uses a similar idea to model opaque objects inside transparent objects by separating the reflection effect. ReNeuS  considers both reflection and refraction to model the opaque object inside glass, but needs strong assumption. These methods focus on the reconstruction of opaque models while overcoming the interference of reflection and refraction.

But none of them can reconstruct both transparent and opaque objects. They all have their own assumptions or conditions for reducing the effect of reflection or refraction. It is non-trivial to combine the two tasks. Please refer to Table 1 for a comprehensive comparison on the use cases. A concurrent work  proposed a NeRF-based efficient rendering method for non-opaque scenes with baked quadrature fields. Another concurrent work, \(\)Surf , extends Plenoxels  for modeling both transparent objects and opaque objects, while ignoring the effect of reflection and refraction. Concurrently, the work NU-NeRF  tries to model both transparent and opaque objects while recovering refractions. In this paper, we propose a new algorithm to reconstruct thin transparent objects and opaque objects uniformly based on NeuS .

## 3 Method

### Unbiased density mapping in NeuS across opacities

NeuS  utilizes signed distance fields for surface representation and introduces a density distribution induced by these SDFs, thereby enabling neural volume rendering coupled with SDF learning. NeuS  proved that for opaque objects, the mapping from SDF to density in NeuS is unbiased, ensuring that the reconstructed surface is a first-order approximation of the learned SDF. In this section, we further establish that the density mapping proposed in NeuS is indeed unbiased across a continuum of material opacities, from fully transparent to fully opaque. This verification completes the theoretical framework of NeuS.

A surface is considered unbiased if the rendering weights attain the local maxima on the surface. This is essential to minimize the discrepancy between the surface and the desired result. NeuS  assumes the surface is opaque and proved the zero iso-surface is unbiased. For transparent surface,

   Method & Opaque & Transparent & Refraction & Reflection & Note \\  NeuS  & Yes & No & No & No & \\ ReNeS  & Yes & No & Yes & Yes & 1,3 \\ NeuS-HSR  & Yes & No & No & Yes & 1 \\ TransPIR  & N/A & Yes & Yes & Yes & 2,5 \\ Li. 2020  & N/A & Yes & Yes & Yes & 2,4,5 \\ NeTO  & N/A & Yes & Yes & No & 2 \\ RefNeuS  & Yes & No & No & Yes & \\ \(\)Surf  & Yes & Yes & No & No & \\ \(\)-NeuS (Ours) & Yes & Yes & No & No & \\   

* **Notes:**
* \({}^{1}\)Opaque object inside transparent container.
* \({}^{2}\)Focuses on pure glass objects.
* \({}^{3}\)Assumes known container geometry and homogeneous background lighting.
* \({}^{4}\)Assumes maximum two light bounces.
* \({}^{5}\)Not involving volume rendering.

Table 1: Comparison with related works for respective use cases.

we observed that NeuS can also produce a local minimum distance on the transparent surface, which inspired us to explore the properties of these local minima. We have the following theorem.

**Theorem 1**.: _Assuming a single ray-plane intersection3, if the rendered opacity \( 0.5\), the learned distance field reaches a local minimum which is non-negative, and the corresponding color weight maximum aligns with the distance local minimum. Otherwise, the distance local minimum is smaller than zero, and the corresponding color weight maximum aligns with the zero iso-surface._

Please refer to Appendix A for the details of the proof. We simply sketch the proof here. Assume \(\) is the opacity and the ray starting from point \(\) in direction \(\) is \((t)=+t\) with parameter \(t\). The density function of NeuS  and HF-NeuS  is

\[((t))=(-s(1-_{s}(f((t)))) (),0),\] (1)

where \(s\) is a learnable parameter, \(_{s}()\) is the sigmoid function and \(\) is the angle between the ray direction and the gradient of the distance field \(f\). The \(\) operation avoids negative \(\) after crossing the local minimum \(m\) of the distance field. Assume the distance between origin of the ray and the plane is \(d_{0}\). Then, the opacity is

\[=}}{1+e^{sm}},&m 0\\ 1-}}{1+e^{-sm}},&m<0\] (2)

If \(m=0\), the opacity \(=}}{2} 0.5\), since \(s\) and \(d_{0}\) are relatively large. For the sake of brevity, we simply state \(0.5\) as the watershed value in the theorem.

The derivative of the rendering weight \(w(t)\) is \(w^{}(t)=T(t)[^{}((t))-^{2}(( t))]\). If the local maximum of weight occurs at \(t=t^{*}\), \(^{}((t^{*}))=^{2}((t^{*}))\). Taking the density function of NeuS into the above equation, we have \(f((t^{*}))=0\), if \(m<0\). Thus, if \(m<0\), the zero iso-surface attains the largest rendering weight. We can also deduce that \(w^{}(t)>0\) if \(m>0\), and thus the rendering weight continuously increases until touching the minimum of the distance field. Therefore, the local minimum of the distance field attains the largest rendering weight. In case of \(m=0\), the point where the distance reaches minimum also achieves zero distance value, so the rendering weight is maximum at the distance local minimum.

The theorem can be explained as follows. As illustrated in Figure 1, if \( 0.5\), the distance field local minimum is non-negative and the unbiased surface coincides with the local minimum. If \(0.5<<1\), the local minimum is negative and the unbiased surface coincides with the front zero iso-surface. If \( 1\), the local minimum approaching negative infinity and the back zero iso-surface approaching infinity. Along with the opacity \(\) increasing, the front and back faces separate gradually from overlap to infinity, so that the integral of densities increases to infinity gradually.

Figure 1: Conceptual illustration of the signed distances along a ray (black horizontal line) through a scene containing a single object (represented by a vertical line segment). (a) When the rendered opacity \(\) is less than or equal to \(0.5\), both the front and back faces of the object coincide with each other, aligning the maximal weight with the local minimum of the distance field. (b) When \(\) exceeds \(0.5\) but less than 1, the back face, which is not rendered, is separated from the front face. The further away the back face is, the more opaque the rendered front face is. The maximum weight in this case is aligned with the position of zero distance values. (c) For a fully opaque surface, the back face is infinitely away. The scene can therefore be considered the single ray-plane intersection discussed by NeuS .

_Remark_.: In NeuS, \(s\) is a learnable parameter that gradually converges to a large value over the course of training. A larger \(s\) value sharpens the edges and faces in the reconstructed model, enhancing overall quality. However, in practice, \(s\) cannot increase indefinitely due to numerical computation constraints, such as the number of sample points. This caps \(s\) at relatively high but finite values, which allows non-zero distance values to influence color calculation along the ray. Colors are derived from the the weighted sum of sampled radiance at points along the rays, and different distance minimum values contributes to achieving different levels of opacity.

We believe that the tendency of a larger \(s\), combined with the color loss and the actual situations with MLP and numerical calculation will achieve a balance that leads to the best results.

### Unbiased surface extraction

As mentioned in Section 3.1, we aim to extract the unbiased surface from the learned distance field. The unbiased surface is either the local minimum or the zero iso-surface depending on whether the local minimum is non-negative. Thus, the distance field learned by NeuS is not a UDF or an SDF. As illustrated in Figure 1, when \( 0.5\), the distance field is similar to a UDF whose values are positive on both side and the unbiased surface is the local minimum. Since the local minimum is greater than or equal to zero, the distance field is not a strict UDF. However, for simplicity, we still call such

Figure 3: Comparisons of projection on the mixed SDF and UDF \(f\) and the absolute field \(f^{a}\). The cutting plane draws the distance field. The white line indicates the 0 iso-surface and the orange line indicates the 0.005 iso-surface. (a) The extracted 0 iso-surface which attains the opaque surface exactly, but the transparent surface disappears. (b) The extracted 0.005 iso-surfaces. (c) Direct mapping on the original \(f\) would result in the opaque surfaces shrinking. (d) In contrast, after taking the absolute, all unbiased surfaces are properly extracted.

Figure 2: Illustration of our mesh extraction procedure. (a) The orange line denotes the input model, where the dashed line is transparent and the solid line is opaque. The color map illustrates the distance field \(f\). (b) The \(r\) iso-curve (red) is extracted. (c) The iso-curve is mapped to the local minima of the absolute distance field \(f^{a}\).

distance field a UDF. When \(>0.5\), the distance field is an SDF whose values are positive in front of the surface and negative behind the surface. The unbiased surface is the zero iso-surface and the zero is not an extreme value. Hence, the unbiased surface is a mixed SDF and UDF, which cannot be extracted using the conventional iso-surface extraction methods, e.g., marching cubes . In Figure 3(a), the zero iso-surface cannot extract the transparent hemisphere.

To extract the unbiased surface from the mixed SDF and UDF, we follow the idea of DCUDF  to extract the unbiased surface. As illustrated in Figure 2(a), given the mixed distance field \(f\) learned by NeuS, we extract the mesh \(\) of a non zero level set with a user-specific iso-value \(r\) (\(r>m\)) by marching cubes  (Figure 2(b) and 3(b)). \(\) encloses the intended unbiased surface as an envelop. As DCUDF , we compute a covering map to project \(\) back to the local minima. However, if \(>0.5\), the unbiased surfaces are not the local minima, but the zero iso-surface. In Figure 2(b), the values of \(f\) inside the opaque box are smaller than the values outside. If we project \(\) to the local minima of \(f\), the curve would shrink into the box. Figure 3(c) shows an example that the opaque surface shrinks if we project \(\) to the local minima of \(f\). Nevertheless, as shown in Figure 2(c) and 3(d), if we convert \(f\) into its absolute values denoted by \(f^{a}\), the non-negative local minima and the zero iso-surface of \(f\) are both the local minima of \(f^{a}\). Thus, \(f^{a}\) is a UDF whose local minima are the unbiased surfaces. We are able to map \(\) to the local minima to extract the unbiased surfaces. Following DCUDF , which employs a two-stage optimization process, we first solve a mapping \(_{1}\) to project \(\) to the local minima of \(f^{a}\):

\[_{_{1}} _{p_{i}}f^{a}_{1}(p_{ i})+_{1}_{p_{i}}w(p_{i})_{1}(p_{ i})^{2},\] \[_{1}(p_{i})=_{1}(p_{i})-(p_{i})| }_{p_{j}(p_{i})}_{1}(p_{j})\]

is the Laplacian of the projected point \(_{1}(p_{i})\) and \(\) is the set of triangle centroids of \(\). \(f(_{1}(p_{i}))\) drives the point \(p_{i}\) projecting to the local minima of \(f^{a}\). \((p_{i})\) denotes the 1-ring neighboring vertices of \(p_{i}\) and \(w(p_{i})\) is a weight adaptive to the area of the adjacent triangle faces of \(p_{i}\). The second term is a Laplacian constraint that prevents the mesh from folding and self-intersecting during optimization.

DCUDF  further calculates a mapping \(_{2}\) to refine \(_{1}()\) in the stage two, which further reduces the fitting error. \(_{i}\) denotes the normal of the \(i\)-th triangle face of \(_{1}()\), whose centroid is encouraged to move along the normal direction \(_{i}\) by penalizing the tangential displacements so as to prevent mesh folding and self-intersecting. The loss function of the refinement stage is :

\[_{_{2}}_{p_{i}}f^{a}_{2} _{1}(p_{i})+_{2}_{p_{i}} _{2}_{1}(p_{i})-_{1}(p_{i})_{i} \,,\]

where \(\) is the vector cross product. After projection, the initial \(\) shrinks to the unbiased surfaces as illustrated in Figure 3(d). Since the surface may contain non-manifold structures, e.g., the intersection of the transparent and opaque surfaces in Figure 2, we do not apply the min-cut postprocessing as . Hence, the unbiased surface is a two-layer mesh that coincides together in regions of \(m 0\) (i.e., \( 0.5\)), and a single-layer mesh in regions of \(m<0\) (i.e., \(>0.5\)).

## 4 Experiments

### Experimental settings

Datasets.Due to the absence of relevant datasets, we have prepared a dataset comprised of 5 synthetic scenes and 5 real-world scenes. The synthetic data are rendered using Blender. The real data are captured by ourselves and the camera are calibrated with the help of ArUco calibration boards.

Baselines.We compare our method with the original NeuS , and NeUDF  which learns UDF from multi-view images.

Implementation details.Our training structure is the same as NeuS. We also followed the recommended configuration for the synthetic dataset by the authors of NeuS, without changing the loss functions or their respective weights. That is, we chose \(_{1}=1.0\) for color loss and \(_{2}=0.1\) for Eikonal loss. All our trainings are without mask.

To extract the unbiased surface through DCUDF , we choose to use 0.005 as the threshold for synthetic scenes, and 0.002 or 0.005 for real-world scenes. We conducted our experiments using almost the same setting as DCUDF. DCUDF employs a two-stage optimization process. We performed 300 epochs for step 1 and 100 epochs for step 2 respectively, which is the default setting of DCUDF. We used the VectorAdam optimizer as suggested by DCUDF. We set the weights \(_{1}=500\) and \(_{2}=0.5\), which are different from DCUDF default setting.

The training process of NeuS typically takes about 9.75 hours and DCUDF convergence only requires a few minutes on a single NVIDIA A100 GPU.

### Synthetic data

In this section we focus on the Synthetic Blender dataset, where each synthetic dataset comprises 100 training images from different viewpoints. We compared the reconstruction results with NeuS and compared the Chamfer Distance (CD) with NeuS on the threshold 0 and 0.005. We report the Chamfer distance results in Table 2. The results indicate that our approach can effectively reconstruct unbiased surfaces, both transparent and opaque. Please refer to Figure 4 for a qualitative comparison.

In comparison to the vanilla NeuS  from which we extract zero iso-surface, large portions of transparent surfaces are absent from the reconstructed mesh due to the positive minimum distances. Consequently, the one-way Chamfer distance from the ground truth to the reconstructed mesh is considerably high. Figure 5 illustrates the percentage of sample points on the ground truth models, whose distances are smaller than the threshold. The final rates reflect the completeness of the reconstructed models. It is evident that our method all achieves \(100\%\) completeness, indicating the absence of unnecessary holes in our models. In contrast, if extracting the zero iso-surface, there are approximately \(20\%\) to \(40\%\) holes remaining. In comparison to the vanilla NeuS from which we extract 0.005 iso-surface, the extracted surface does not correspond to the maximum color weight, leading to sub-optimal reconstructed-to-ground-truth one-way Chamfer distance. Our method preserves transparent surfaces while being unbiased, leading to the best Chamfer distances across all data.

### Real-world data

We also capture 5 real-world scenes for validation. Due to the absence of ground-truth mesh data, qualitative comparisons are conducted with NeuS on real-world scenes. The results are presented in Figure 6. The visual results demonstrate that our method exhibits good reconstruction quality for both transparent and opaque surfaces, even in complex lighting conditions in real-world scenes. In contrast, NeuS with zero iso-surfaces is unable to extract a completed surface, resulting in artifacts.

### Discussion

Choice of NeuS.We use NeuS  as backbone for reconstruction, which learns a mixed SDF and UDF. However, during the projection stage of surface extraction, we use the absolute value

    & =0\))} & =0.005\))} &  \\   & g2d & d2g & CD & g2d & d2g & CD & g2d & d2g & CD \\  Snowglobe & 65.22 & 5.16 & 35.19 & 7.07 & 6.46 & 6.77 & **4.73** & **4.37** & **4.55** \\ Case & 39.60 & 8.18 & 23.89 & 6.23 & 8.80 & 7.51 & **5.52** & **7.66** & **6.59** \\ Bottle & 7.91 & 4.77 & 6.34 & 6.19 & 8.14 & 7.16 & **3.14** & **4.22** & **3.68** \\ Jug & 11.59 & 10.41 & 11.00 & 5.33 & 9.36 & 7.34 & **2.89** & **6.44** & **4.67** \\ Jar & 76.79 & **4.45** & 40.62 & **11.61** & 7.92 & 9.77 & 11.89 & 5.87 & **8.88** \\  mean & 40.22 & 6.60 & 23.41 & 7.29 & 8.14 & 7.71 & **5.63** & **5.71** & **5.67** \\   

Table 2: Quantitative evaluation (\( 10^{-3}\)) on the synthetic dataset. “g2d” is the Chamfer distance from the ground truth mesh to the reconstructed mesh, and “d2g” measures the reverse. “CD” denotes the average of “g2d” and “d2g”. The best results are marked in bold.

of the distance field. The absolute distance field \(f^{a}\) resembles UDF. While directly using UDF learning methods could avoid the distance field conversion process, we select NeuS rather than UDF learning methods because the the SDF learning method NeuS is simple, stable and robust, and is also capable of reconstructing details. We further compare with a UDF learning method NeUDF . We notice that other UDF learning methods including NeuralUDF  and 2S-UDF  both take advantage of the opaque surface assumption, introducing an indicator function or ray truncation

Figure 4: Qualitative comparison on synthetic data. Our method uses NeuS for distance field learning, and as shown in the normal maps, vanilla NeuS is in fact capable of reconstructing surfaces with transparency. The difference between our method and NeuS is drastic because NeuS cannot extract transparent surfaces where the distance field local minima are larger than zero with marching cubes, but our theory confirms and extends NeuS’s learning ability, extracting both the non-negative local minima and the zero iso-surface.

Figure 5: Percentage of sample points on the ground truth mesh that the distance to the reconstructed mesh is lower than given values. Blue: Ours, Orange: Zero iso-surface.

strategy respectively. This leaves NeUDF  the only method that is theoretically capable of rendering multiple layers of surfaces in a single ray.

Figure 7 shows the comparisons with NeUDF . Since the zero distance value of NeUDF would result in opaque surface, the minimum distances of transparent objects learned by NeUDF are also

Figure 6: Qualitative comparisons on real-world data.

Figure 7: Comparisons with UDF-based reconstruction method NeUDF  on synthetic and real-world data. While NeUDF can successfully reconstruct transparent surfaces and interior structures, it fails to preserve details and has difficulties reconstructing intricate structure. The Chamfer distances (\( 10^{-3}\)) are shown below the synthetic Snowglobe. The Snowglobe is shown in section view.

positive. We use DCUDF to extract surface instead of the default MeshUDF  used by NeUDF, because MeshUDF could only extract the zero iso-surface. The models reconstructed by NeUDF are over-smoothed and lack many intricate structures. Qualitative measurement of the synthetic model also shows that NeUDF results in a larger Chamfer distance. This is due to the volatile nature of UDF learning, requiring additional regularizers for successful convergence, often sacrificing the reconstruction fidelity.

Limitations.Although our method has been effectively validated on both synthetic and real-world data, it cannot handle all use cases. Our method, together with \(\)Surf , allows for simultaneous reconstruction of opaque and transparent objects. Other works either focus on the reconstruction of opaque objects, or pure-glass objects with refraction and reflection under certain assumptions. However, our method is not designed to handle the cases with complex lighting conditions like heavy refraction or reflection. As shown in Figure 8, when using NeuS  as the backbone, scenes with reflection and refraction may yield ambiguous distance fields, preventing the acquisition of the ideal surface. For these situations, on the one hand, improving the lighting conditions to minimize the occurrence of refraction and reflection can be considered. In our experiments, we used polarizer to reduce reflection and model only thin transparent objects that have as little refraction as possible. Meanwhile, it is also possible to use existing reflection removal algorithms . On the other hand, replacing the backbone with models like Ref-NeuS  or ReNeuS  (which focus on opaque object reconstruction but not the transparent object itself) could be considered. This will be one of our future research directions.

## 5 Conclusion

Overall, \(\)-NeuS presents a new perspective on NeuS. We proved the unbiasedness of NeuS for transparent objects and extended the capability of NeuS to transparent surface and opaque surface reconstruction by proposing a unified theoretical and practical framework. Based on DCUDF, we extract the unbiased transparent surface and opaque surface simultaneously for model reconstruction. We established a benchmark consisting of 5 synthetic and 5 real world scenes for validation. Our experiments have demonstrated the effectiveness of our proposed method, and its practical potentials.