# NeCGS: Neural Compression for 3D Geometry Sets

NeCGS: Neural Compression for 3D Geometry Sets

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

This paper explores the problem of effectively compressing 3D geometry sets containing diverse categories. We make _the first_ attempt to tackle this fundamental and challenging problem and propose NeCGS, a neural compression paradigm, which can compress hundreds of detailed and diverse 3D mesh models (\(\)684 MB) by about 900 times (0.76 MB) with high accuracy and preservation of detailed geometric details. Specifically, we first represent each _irregular_ mesh model/shape in a _regular_ representation that implicitly describes the geometry structure of the model using a 4D regular volume, called _TSDF-Def volume_. Such a regular representation can not only capture local surfaces more effectively but also facilitate the subsequent process. Then we construct a quantization-aware auto-decoder network architecture to regress these 4D volumes, which can summarize the similarity of local geometric structures within a model and across different models for redundancy elimination, resulting in more compact representations, including an embedded feature of a smaller size associated with each model and a network parameter set shared by all models. We finally encode the resulting features and network parameters into bitstreams through entropy coding. After decompressing the features and network parameters, we can reconstruct the TSDF-Def volumes, where the 3D surfaces can be extracted through the deformable marching cubes. Extensive experiments and ablation studies demonstrate the significant advantages of our NeCGS over state-of-the-art methods both quantitatively and qualitatively. We have included the source code in the _Supplemental Material_.

## 1 Introduction

3D mesh models/shapes are widely used in various fields, such as computer graphics, virtual reality, robotics, and autonomous driving. As geometric data becomes increasingly complex and voluminous, effective compression techniques have become critical for efficient storage and transmission. Moreover, current geometry compression methods primarily focus on individual 3D models or sequences of 3D models that are temporally correlated, but struggle to handle more general data sets, such as compressing large numbers of unrelated 3D shapes.

Unlike images and videos represented as _regular_ 2D or 3D volumes, mesh models are commonly represented as triangle meshes, which are irregular and challenging to compress. Thus, a natural idea is to structure the mesh models and then leverage image or video compression techniques to compress them.Converting mesh models into voxelized point clouds is a common practice, and the mesh models can be recovered from the point clouds via surface reconstruction methods [22; 24]. Based on this, in recent years, MPEG has developed two types of 3D point cloud compression (PCC) standards [46; 28]: geometry-based PCC (GPCC) for static models and video-based PCC (VPCC) for sequential models. And with advancements in deep learning, numerous learning-based PCC methods [41; 14; 55; 19; 54] have emerged, enhancing compression efficiency. However, the voxelized point clouds require a high resolution (typically \(2^{10}\) or more) to accurately represent geometry data, which is redundancy, limiting the compression efficiency.

Another regular representation involves utilizing implicit fields of mesh models, such as signed distance fields (SDF) and truncated signed distance fields (TSDF). This is achieved by calculating the value of the implicit field at each uniformly distributed grid point, resulting in a regular volume. And the mesh models can be recovered from the implicit fields through Matching Cubes  or its variants . Compared with point clouds, the implicit volume could represent the mesh models in a relatively small resolution. Recently proposed methods, such as DeepSDF , utilize multilayer perceptrons (MLPs) to regress the SDFs of any given query points. While this representation achieves high accuracy for single or similar models (e.g., chairs, tables), the limited receptive field of MLPs makes it challenging to represent large numbers of models in different categories, which is a more common scenario in practice.

We propose NeCGS, a novel framework for compressing large sets of geometric models. Our NeCGS framework consists of two stages: regular geometry representation and compact neural compression. In the first stage, each model is converted into a regular 4D volumetric format, called the _TSDF-Def volume_, which can be considered a 3D 'image'. In the second stage, we use an auto-decoder to regress these 4D volumes. The embedded features and decoder parameters represent these models, and compressing these components allows us to compress the entire geometry set. We conducted extensive experiments on various datasets, demonstrating that our NeCGS framework achieves higher compression efficiency compared to existing geometry compression methods when handling large numbers of models. Our NeCGS can achieve a compression ratio of nearly 900 on some datasets, compressing hundreds or even thousands of different models into 1\(\)2 MB while preserving detailed structures.

Figure 1: Our NeCGS can compress geometry data with hundreds or even thousands of shapes into 1\(\)2 MB while preserving details. **Left:** Original Geometry Data. **Right**: Decompressed Geometry Data. **Q** Zoom in for details.

Related Work

### Geometry Representation

In general, the representation of geometry data is divided into two main categories, explicit representation and implicit representation, and they could be transformed into another.

**Explicit Representation.** Among the explicit representations, voxelization  is the most intuitive. In this method, geometry models are represented by regularly distributed grids, effectively converting them into 3D 'images'. While this approach simplifies the processing of geometry models using image processing techniques, it requires a high resolution to accurately represent the models, which demands substantial memory and limits its application. Another widely used geometry representation method is the point cloud, which consists of discrete points sampled from the surfaces of models. This method has become a predominant approach for surface representation . However, the discrete nature of the points imposes constraints on its use in downstream tasks such as rendering and editing. Triangle meshes offer a more precise and efficient geometry representation. By approximating surfaces with numerous triangles, they achieve higher accuracy and efficiency for certain downstream tasks.

**Implicit Representation.** Implicit representations use the isosurface of a function or field to represent surfaces. The most widely used implicit representations include Binary Occupancy Field (BOF) , Signed Distance Field (SDF) , and Truncated Signed Distance Field (TSDF) , from which the model's surface can be easily extracted. However, these methods are limited to representing watertight models. The Unsigned Distance Field (UDF) , which is the absolute value of the SDF, can represent more general models, not just watertight ones. Despite this advantage, extracting surfaces from UDF is challenging, which limits its application.

**Conversion between Geometry Representations.** Geometry representations can be converted between explicit and implicit forms. Various methods  are available for calculating the implicit field from given models. Conversely, when converting from implicit to explicit forms, Marching Cubes  and its derivatives  can reconstruct continuous surfaces from various implicit fields.

### 3D Geometry Data Compression

**Single 3D Geometric Model Compression.** In recent decades, compression techniques for images and videos have rapidly advanced . However, the irregular nature of geometry data makes it more challenging to compress compared to images and video, which are represented as volumetric data. A natural approach is to convert geometry data into voxelized point clouds, treating them as 3D 'images', and then applying image and video compression techniques to them. Following this intuition, MPEG developed the GPCC standards , where triangle meshes or triangle soup approximates the surfaces of 3D models, enabling the compression of models with more complex structures. Subsequently, several improved methods  and learning-based methods  have been proposed to further enhance compression performance. However, these methods rely on voxelized point clouds to represent geometry models, which is inefficient and memory-intensive, limiting their compression efficiency. In contrast to the previously mentioned methods, Draco  uses a kd-tree-based coding method to compress vertices and employs the EdgeBreaker algorithm to encode the topological relationships of the geometry data. Draco utilizes uniform quantization to control the compression ratio, but its performance decreases at higher compression ratios.

**Multiple Model Compression.** Compared to compressing single 3D geometric models, compressing multiple objects is significantly more challenging. SLRMA  addresses this by using a low-rank matrix to approximate vertex matrices, thus compressing sequential models. Mekuria et al.  proposed the first codec for compressing sequential point clouds, where each frame is coded using Octree subdivision through an 8-bit occupancy code. Building on this concept, MPEG developed the VPCC standards , which utilize 3D-to-2D projection and encode time-varying projected planes, depth maps, and other data using video codecs. Several improved methods  have been proposed to enhance the compression of sequential models. Recently, shape priors like SMPL  and SMAL  have been introduced, allowing the pose and shape of a template frame to be altered using only a few parameters. Pose-driven geometry compression methods leverage this approach to achieve high compression efficiency. However, these methods are limited to sequences of corresponding geometry data and cannot handle sets of unrelated geometry data, which is more common in practice.

## 3 Proposed Method

**Overview.** Given a set of \(N\) 3D _mesh_ models containing diverse categories, denoted as \(=\{_{i}\}_{i=1}^{N}\), we aim to compress them into a bitstream while maintaining the quality of the decompressed models as much as possible. To this end, we propose a neural compression paradigm called NeCGS. As shown in Fig. 2, NeCGS consists of two main modules, i.e., Regular Geometry Representation (RGR) and Compact Neural Representation (CNR). Specifically, RGR first represents each _irregular_ mesh model within \(\) into a _regular_ 4D volume, namely TSDF-Def volume that _implicitly_ describes the geometry structure of the model, via a rendering-based optimization, thus leading to a set of 4D volumes \(:=\{_{i}\}_{i=1}^{N}\) with \(_{i}\) corresponding to \(_{i}\). Then CNR further obtains a more compact neural representation of \(\), where a _quantization-aware_ auto-decoder-based network is constructed to regress these volumes, producing an embedded feature for each volume. Finally, the embedded features along with the network parameters are encoded into a bitstream through a typical entropy coding method to achieve compression. We also want to **note** that NeCGS can also be applied to compress 3D geometry sets represented in _3D point clouds_, where one can either reconstruct from the given point clouds 3D surfaces through a typical surface reconstruction method or adopt a pre-trained network for SDF estimation from point clouds, e.g., SPSR  or IMLS , to bridge the gap between 3D mesh and point cloud models. In what follows, we will detail NeCGS.

### Regular Geometry Representation

Unlike 2D images and videos, where pixels are uniformly distributed on 2D _regular_ girds, the _irregular_ characteristic of 3D mesh models makes it challenging to compress them efficiently and effectively. We propose to convert each 3D mesh model to a 4D regular volume called TSDF-Def volume, which implicitly represents the geometry structure of the model. Such a regular representation can describe the model precisely, and its regular nature proves beneficial for compression in the subsequent stage.

**TSDF-Def Volume.** Although 3D regular SDF or TSDF volumes are widely used for representing 3D geometry models, they may introduce distortions when the volume

Figure 3: 2D visual illustration of DMC. The blue points refer to the deformable grid points, the green points refer to the vertices of the extracted surfaces, and the orange lines refer to the faces of the extracted surfaces. **Left:** The original grid points. **Right:** The surface extraction.

Figure 2: The pipeline of NeCGS. It first represents original meshes regularly into TSDF-Def volumes, and an auto-decoder network is utilized to regress these volume. Then the embedded features and decoder parameters are compressed into bitstreams through entropy coding. When decompressing the models, the decompressed embedded features are fed into the decoder with the decompressed parameters from the bitstreams, reconstructing the TSDF-Def volumes, and the models can be extracted from them.

resolution is relatively limited. Inspired by recent shape extracting methods [48; 49], we propose TSDF-Def, which extends the regular TSDF volume by introducing an additional deformation for each grid point to adjust the detailed structure during the extraction of models, as shown in Fig. 3. Accordingly, we develop the differentiable _Deformable Marching Cubes_ (DMC), the variant of the Marching Cubes method , for surface extraction from a TSDF-Def volume. Consequently, each shape \(\) is represented as a 4D TSDF-Def volume, denoted as \(^{ K 4}\), where \(K\) is the volume resolution. More specifically, the value of the grid point located at \((u,v,w)\) is \((u,v,w):=[(u,v,w), u, v, w]\), where \(( u, v, w)\) are the deformation for the grid point and \(1 u,v,w K\). TSDF-Def enhances representation accuracy, particularly when the grid resolution is relatively low.

**Optimization of TSDF-Def Volumes.** To obtain the optimal TSDF-Def volume \(\) for a given model \(\), after initializing the deformations of each grid to zero and computing the TSDF value for each grid we optimize the following problem:

\[_{}_{}((),),\] (1)

where \(()\) refers to the differentiable DMC process for extracting surfaces from TSDF-Def volumes, and the \(_{}(,\ )\) measures the differences between the rendered depth and silhouette images of two mesh models through the differentiable rasterization . Algorithm 1 summarizes the whole optimization process. More details can be found in Sec. A.2 of the subsequent _Appendix_.

``` Input: 3D mesh model \(\); the maximum number of iterations maxIter. Output: The optimal TSDF-Def volume \(^{K K K 4}\).
1 Place uniformly distributed grids in the cube of \(\), denoted as \(^{K K K 3}\);
2 Initialize \([,0]\) as the ground truth TSDF of \(\) at the location of \(\), the deformation \([,1:]\)=0, and the current iteration \(=0\);
3whileIter \(<\)do
4 Recover shape from \(\) according to DMC, \(()\);
5 Calculate the reconstruction error, \(_{}((),)\);
6 Optimize \(\) using ADAM optimizer based on the reconstruction error;
7 Iter:=Iter+1;
8 end while return\(\); ```

**Algorithm 1**Optimization of TSDF-Def Volumes

### Compact Neural Representation

Observing the similarity of local geometric structures within a typical 3D model and across different models, i.e., redundancy, we further propose a _quantization-aware_ neural representation process to summarize the similarity within \(\), leading to more compact representations with redundancy removed.

**Network Architecture.** We construct an auto-decoder network architecture to regress these 4D TSDF-Def volumes. Specifically, it is composed of a head layer, which increases the channel of its input, and \(L\) cascaded upsampling modules, which progressively upscale the feature volume. We also utilize the PixelShuffle technique  between the convolution and activation layers to achieve upscaling. We refer reviewers to Sec. B of _Appendix_ for more details. For TSDF-Def volume \(_{i}\), the corresponding input to the auto-decoder is the embedded feature, denoted as \(_{i}^{K^{} K^{} K^{}  C}\), where \(K^{}\) is the resolution satisfying \(K^{} K\) and \(C\) is the number of channels. Moreover, we integrate differentiable quantization to the embedded features and network parameters in the process, which can efficiently reduce the quantization error. In all, the compact neural representation process can be written as

\[}_{i}=_{()}((_{i})).\] (2)

where \(()\) stands for the differentiable quantization operator, and \(}_{i}\) is the regressed TSDF-Def.

**Loss Function.** We employ a joint loss function comprising Mean Absolute Error (MAE) and Structural Similarity Index (SSIM) to simultaneously optimize the embedded features \(\{_{i}\}\) and the network parameters \(\). In computing the MAE between the predicted and ground truth TSDF-Def volumes, we concentrate more on the grids close to the surface. These surface grids crucially determine the surfaces through their TSDFs and deformations; hence we assign them higher weights during optimization than the grids farther away from the surface. The overall loss function for the \(i\)-th model is written as

\[(}_{i},_{i})=\|}_{i }-_{i}\|_{1}+_{1}\|_{i}(}_{ i}-_{i})\|_{1}+_{2}(1-(}_{i}, _{i})),\] (3)

where \(_{i}=(|_{i}[...,0]|<)\) is the mask, indicating whether a grid is near the surface, i.e., its TSDF is less than the threshold \(\), while \(_{1}\) and \(_{2}\) are the weights to balance each term of the loss function.

**Entropy Coding.** After obtaining the quantized features \(\{}_{i}=(_{i})\}\) and quantized network parameters \(}=()\), we adopt the Huffman Codec  to further compress them into a bitstream. More advanced entropy coding methods can be employed to further improve compression performance.

### Decompression

To obtain the 3D mesh models from the bitstream, we first decompress the bitstream to derive the embedded features, \(\{}_{i}\}\) and the decoder parameter, \(}\). Then, for each \(}_{i}\), we feed it to the decoder \(_{}}()\) to generate its corresponding TSDF-Def volume

\[}_{i}=_{}}( {}_{i}).\] (4)

Finally, we utilize DMC to recover each shape from \(}_{i}\), \(}_{i}=(}_{i})\), forming the set of decompressed geometry data, \(}=\{}_{i}\}_{i=1}^{N}\).

## 4 Experiment

### Experimental Setting

**Implementation details.** In the process of optimizing TSDF-Def volumes, we employed the ADAM optimizer  for 500 iterations per shape, using a learning rate of 0.01. The resolution of TSDF-Def volumes was \(K=128\). The resolution and the number of channels of the embedded features were \(K^{}=4\) and \(C=16\), respectively. And the decoder is composed of \(L=5\) upsampling modules with an up-scaling factor of 2. During the optimization, we set \(_{1}=5\) and \(_{2}=10\), and the embedded features and decoder parameters were optimized by the ADAM optimizer for 400 epochs, with a learning rate of 1e-3. We achieved different compression efficiencies by adjusting decoder sizes. We conducted all experiments on an NVIDIA RTX 3090 GPU with Intel(R) Xeon(R) CPU.

**Datasets.** We tested our NeCGS on various types of datasets, including humans, animals, and CAD models. For human models, we randomly selected 500 shapes from the AMA dataset . For animal models, we randomly selected 500 shapes from the DT4D dataset . For the CAD models, we randomly selected 1000 shapes from the Thingi10K dataset . Besides, we randomly selected 200 models from each dataset, forming a more challenging dataset, denoted as Mixed. The details about the selected datasets are shown in Table 1. In all experiments, we scaled all models in a cube with a range of \([-1,1]\)3 to ensure they are in the same scale.

**Methods under Comparison.** In terms of traditional geometry codecs, we chose the three most impactful geometry coding standards with released codes, G-PCC\({}^{2}\) and V-PCC\({}^{3}\) from MPEG (see

   Dataset & Original Size (MB) & \# Models \\  AMA & 378.41 & 500 \\ DT4D & 683.80 & 500 \\ Thingi10K & 335.92 & 1000 \\ Mixed & 496.16 & 600 \\   

Table 1: Details of the selected datasets1.

more details about them in [13; 28; 47]), and Draco 4 from Google as the baseline methods. Additionally, we compared our approach with state-of-the-art deep learning-based compression methods, specifically PCGCv2 . Furthermore, we adapted DeepSDF  with quantization to serve as another baseline method, denoted as QuantDeepSDF. It is worth noting that while some of the chosen baseline methods were originally designed for point cloud compression, we utilized voxel sampling and SPSR  to convert them between the forms of point cloud and surface. More details can be found in Sec. C.2_appendix_.

**Evaluation Metrics.** Following previous reconstruction methods [35; 38], we utilize Chamfer Distance (CD), Normal Consistency (NC), F-Score with the thresholds of 0.005 and 0.01 (F1-0.005 and F1-0.01) as the evaluation metrics. Furthermore, to comprehensively compare the compression efficiency of different methods, we use Rate-Distortion (RD) curves. These curves illustrate the distortions at various compression ratios, with CD and F1-0.005 specifically describing the distortion of the decompressed models. Our goal is to minimize distortion, indicated by a low CD and a high F1-Score, while maximizing the compression ratio. Therefore, for the RD curve representing CD, optimal compression performance is achieved when the curve is closest to the lower right corner. Similarly, for the RD curve representing the F1-Score, the ideal compression performance is when the curve is nearest to the upper right corner. Their detailed definition can be found in Sec. C.1 of _appendix_.

### Results

The RD curves of different compression methods under different datasets are shown in Fig. 4. As the compression ratio increases, the distortion also becomes larger. It is obvious that our NeCGS can achieve much better compression performance than the baseline methods when the compression ratio is high, even in the challenging Mixed dataset. In particular, our NeCGS achieves a minimum compression ratio of 300, and on the DT4D dataset, the compression ratio even reaches nearly 900, with minimal distortion. Due to the larger model differences within the Thingi10K and Mixed datasets compared to the other two datasets, the compression performance on these two datasets is inferior.

The visual results of different compression methods are shown in Fig. 5. Compared to other methods, models compressed using our approach occupy a larger compression ratio and retain more details after decompression. Fig. 6

Figure 4: Quantitative comparisons of different methods on four 3D geometry sets.

Figure 6: Decompressed models under different compression ratios.

illustrates the decompressed models under different compression ratio. Even when the compression ratio reaches nearly 900, our method can still retain the details of the models.

### Ablation Study

In order to illustrate the efficiency of each design of our NeCGS, we conducted extensive ablation study about them on the Mixed dataset.

**Necessity of the Deformation of Grids.** We utilize TSDF-Def volumes to as the regular geometry representation, instead of TSDF volumes like previous methods. Compared with models recovered from TSDF volumes through MC, the models recovered from TSDF-Def volumes through DMC preserve more details of the thin structures, especially when the volume resolutions are relatively small, as shown in Fig. 7. We also conducted a numerical comparison of the decompressed models on the AMA dataset under these two settings, and the results are shown in Table. 2, demonstrating its advantages.

**Neural Representation Structure.** To illustrate the superiority of auto-decoder framework, we utilize an auto-encoder to regress the TSDF-Def volume. Technically, we used a ConvNeXt block  as the encoder by replacing 2D convolutions with 3D convolutions. Under the auto-encoder framework, we optimize the parameters of the encoder to change the embedded features. The RD

   RGR & Size (MB) & Com. Ratio & CD (\( 10^{-3}\)) \(\) & NC \(\) & F1-0.005 \(\) & F1-0.01 \(\) \\  TSDF & 1.631 & 304.20 & 5.015 & 0.944 & 0.662 & 0.936 \\ TSDF-Def & 1.612 & 307.79 & 4.913 & 0.947 & 0.674 & 0.943 \\   

Table 2: Quantitative comparisons of different RGRs.

Figure 5: Visual comparisons of different compression methods. All numbers in corners represent the compression ratio. \(\) Zoom in for details.

Figure 7: Models recovered from different regular geometry representations under various volume resolutions. From **Left** to **Right**: Original, TSDF with \(K=64\), TSDF with \(K=128\), TSDF-Def with \(K=64\), and TSDF-Def with \(K=128\).

curves about these two structures are shown in Fig. 8(a), demonstrating rationality of our decoder structure.

**SSIM Loss.** Compared to MAE, which focuses on one-to-one errors between predicted and ground truth volumes, the SSIM item in Eq. 3 emphasizes more on the local similarity between volumes, increasing the regression accuracy. To verify this, we removed the SSIM item and kept others unchanged. Their RD curves are shown in Fig. 8(b), and it is obvious that the SSIM item in the regression loss increases the compression performance. The visual comparison is shown in Fig. 9, and without SSIM, there are floating parts around the decompressed models.

**Resolution of TSDF-Def Volumes.** We tested the compression performance at different resolutions of TSDF-Def volumes by adjusting the decoder layers accordingly. Specifically, we removed the last layer for a resolution of 64 and added an extra layer for a resolution of 256. The quantitative and numerical comparisons are shown in Table 3 and Fig. 10, respectively. Obviously, increasing the volume resolution can enhance the compression effectiveness, resulting in more detailed structures preserved after decompression. However, the optimization and inference time also increase accordingly due to more layers involved.

## 5 Conclusion and Discussion

We have presented NeCGS, a highly effective neural compression scheme for 3D geometry sets. NeCGS has achieved remarkable compression performance on various datasets with diverse and detailed shapes, outperforming state-of-the-art compression methods to a large extent. These advantages are attributed to our regular geometry representation and the compression accomplished by a convolution-based auto-decoder. We believe our NeCGS framework will inspire further advancements in the field of geometry compression.

However, our method still suffers from the following two limitations. One is that it requires more than 15 hours to regress the TSDF-Def volumes, and the other one is that the usage of 3D convolution layers limits the inference speed. Our future work will focus on addressing these challenges by accelerating the optimization process and incorporating more efficient network modules.

Figure 8: (a) RD curves of different neural representation structures. (b) RD curves of different regression losses.

Figure 10: Visual comparison under different resolutions of TSDF-Def volume.

   Res. & Size (MB) & Com. Ratio & CD (\( 10^{-3}\)) \(\) & NC \(\) & F1-0.005 \(\) & F1-0.01 \(\) & Opt Time (h) & Infer. Time (ms) \\ 
64 & 1.408 & 268.75 & 4.271 & 0.927 & 0.721 & 0.966 & 2.16 & 38.97 \\
128 & 1.493 & 253.45 & 3.436 & 0.952 & 0.842 & 0.991 & 16.32 & 98.95 \\
256 & 1.627 & 232.58 & 3.234 & 0.962 & 0.870 & 0.995 & 94.50 & 421.94 \\   

Table 3: Quantitative comparisons of different resolutions of TSDF-Def volumes.

Figure 9: Visual comparison of regression loss w/ and w/o SSIM item.