# Bridging OOD Detection and Generalization:

A Graph-Theoretic View

 Han Wang

Department of Electrical and Computer Engineering

University of Illinois Urbana-Champaign

hanw14@illinois.edu

Work done while visiting UW-Madison.

Yixuan Li

Department of Computer Sciences

University of Wisconsin-Madison

sharonli@cs.wisc.edu

###### Abstract

In the context of modern machine learning, models deployed in real-world scenarios often encounter diverse data shifts like covariate and semantic shifts, leading to challenges in both out-of-distribution (OOD) generalization and detection. Despite considerable attention to these issues separately, a unified framework for theoretical understanding and practical usage is lacking. To bridge the gap, we introduce a graph-theoretic framework to jointly tackle both OOD generalization and detection problems. By leveraging the graph formulation, data representations are obtained through the factorization of the graph's adjacency matrix, enabling us to derive provable error quantifying OOD generalization and detection performance. Empirical results showcase competitive performance in comparison to existing methods, thereby validating our theoretical underpinnings. Code is publicly available at https://github.com/deeplearning-wisc/graph-spectral-ood.

## 1 Introduction

Machine learning models deployed in real-world applications often confront data that deviates from the training distribution in unforeseen ways. As depicted in Figure 1, a model trained on in-distribution (ID) data (e.g., seabirds) may encounter data exhibiting _covariate shifts_, such as birds in forest environments. In this scenario, the model must retain its ability to accurately classify these covariate-shifted out-of-distribution (OOD) samples as birds--an essential capability known as OOD generalization [1; 2]. Alternatively, the model may encounter data with novel semantics, like dogs, which it has not seen during training. In this case, the model must recognize these _semantic-shifted_ OOD samples and abstain from making incorrect predictions, underscoring the significance of OOD detection [3; 4]. Thus, for a model to be considered robust and reliable, it must excel in both OOD generalization and detection, tasks that are often addressed separately in current research.

Recently, Bai et al.  introduced a framework that addresses both OOD generalization and detection simultaneously. The problem setting leverages unlabeled wild data naturally arising in the model's operational environment, representing it as a composite distribution of ID, covariate-shifted OOD, and semantic-shifted OOD data. While such data is ubiquitously available in many real-world applications, harnessing the power of wild data is challenging due to the heterogeneity of the wild data distribution--the learner lacks clear membership (ID, Covariate-OOD, Semantic-OOD) for samples drawn from the wild data distribution. Despite empirical progress made, _a formalized understanding of how wild data impacts OOD generalization and detection is still lacking_.

In this paper, we formalize a graph-theoretic framework for understanding OOD generalization and detection problems jointly. We begin by formulating a graph, where the vertices are all the data points and edges connect similar data points. These edges are defined based on a combination of supervisedand self-supervised signals, incorporating both labeled ID data and unlabeled wild data. By modeling the connectivity among data points, we can uncover meaningful sub-structures in the graph (e.g., covariate-shifted OOD data is embedded closely to the ID data, whereas semantic-shifted OOD data is distinguishable from ID data). Importantly, this graph serves as a foundation for understanding the impact of wild unlabeled data on both OOD generalization and detection, enabling a theoretical characterization of performance through graph factorization. Within this framework, we derive a formal linear probing error, quantifying the misclassification rate on covariate-shifted OOD data. Furthermore, our framework yields a closed-form solution that quantifies the distance between ID and semantic OOD data, directly elucidating OOD detection performance (Section 4).

Beyond theoretical analysis, our graph-theoretic framework can be used practically. In particular, the spectral decomposition can be equivalently achieved by minimizing a surrogate objective, which can be efficiently optimized end-to-end using modern neural networks. Thus, our approach enjoys theoretical guarantees while being applicable to real-world data. Experimental results demonstrate the effectiveness of our graph-based approach, showcasing substantial improvements in both OOD generalization and detection performance. In comparison to the state-of-the-art method Scone , our approach achieves a significant reduction in FPR95 by an average of 8.34% across five semantic-shift OOD datasets (Section 5). We summarize our main contributions below:

1. We introduce a graph-theoretic framework for understanding both OOD generalization and detection, formalizing it by spectral decomposition of the graph containing ID, covariate-shift OOD data, and semantic-shift OOD data.
2. We provide theoretical insights by quantifying OOD generalization and detection performance through provable error, based on the closed-form representations derived from the spectral decomposition on the graph.
3. We evaluate our model's performance through a comprehensive set of experiments, providing empirical evidence of its robustness and its alignment with our theoretical analysis. Our model consistently demonstrates strong OOD generalization and OOD detection capabilities, achieving competitive results when benchmarked against the existing state-of-the-art.

## 2 Problem Setup

We consider the empirical training set \(_{l}_{u}\) as a union of labeled and unlabeled data. The labeled set \(_{l}=\{_{i},y_{i}\}_{i=1}^{m}\), where \(y_{i}\) belongs to _known_ class space \(_{l}\). Let \(_{}\) denote the marginal distribution over input space, which is referred to as the in-distribution (ID). Following Bai et al. , the unlabeled set \(_{u}=\{_{i}\}_{i=1}^{m}\) consists of ID, covariate OOD, and semantic OOD data, where each sample \(_{i}\) is drawn from a mixture distribution defined below.

**Definition 2.1**.: _The marginal distribution of the wild data is defined as:_

\[_{}:=(1-_{c}-_{s})_{}+_{c} _{}^{}+_{s}_{}^{ },\]

_where \(_{c},_{s},_{c}+_{s}\). \(_{}\), \(_{}^{}\), and \(_{}^{}\) represent the marginal distributions of ID, covariate-shifted OOD, and semantic-shifted OOD data respectively._

Figure 1: Illustration of our graph-theoretic framework for joint out-of-distribution generalization and detection. **Left**: Graph formulation containing three types of data in the wild: ID (e.g., seabird), covariate OOD (e.g., bird in the forest), and semantic OOD (e.g., dog). **Right**: Graph factorization for obtaining the closed-form solution of the data representations, which are used to derive OOD generalization and OOD detection errors.

**Learning goal.** We aim to learn jointly an OOD detector \(g_{}\{,\}\) and a multi-class classifier \(f_{}\), by leveraging labeled ID data \(_{l}\) and unlabeled wild data \(_{u}\). Let \((f_{}()):=*{argmax}_{f}_{}^{(y)}( )\), where \(f_{}^{(y)}()\) denotes the \(y\)-th element of \(f_{}()\), corresponding to label \(y\). We notate \(g_{}\) and \(f_{}\) with parameters \(\) to indicate that these functions share neural network parameters. In our model evaluation, we are interested in three metrics:

**Definition 2.2**.: _We define ID generalization accuracy (ID-Acc), OOD generalization accuracy (OOD-Acc), and OOD detection error as follows:_

\[(f_{}):=_{(,y) _{}}(\{(f_{}())=y\}),\] \[(f_{}):=_{(,y) _{}^{}}(\{(f_{}())=y \}),\] \[(g_{}):=_{ _{}^{}}(\{(g_{}()= \}),\]

_where \(\{\}\) represents the indicator function, and the arrows indicate the directionality of improvement (higher/lower is better). For OOD detection, ID samples are considered positive and FPR signifies the false positive rate._

## 3 Graph-Based Framework for OOD Generalization and Detection

### Graph Formulation

We start by formally defining the graph and adjacency matrix. We use \(\) to denote the set of all natural data (raw inputs without augmentation). Given an \(\), we use \((x|)\) to denote the probability of \(x\) being augmented from \(\), and \((|)\) to denote the distribution of its augmentation. For instance, when \(\) represents an image, \((|)\) can be the distribution of common augmentations  such as Gaussian blur, color distortion, and random cropping. We define \(\) as a general population space, which contains the set of all augmented data. In our case, \(\) is composed of augmented samples from both labeled ID data \(_{l}\) and unlabeled wild data \(_{u}\), with cardinality \(||=N\).

We define the graph \(G(,w)\) with vertex set \(\) and edge weights \(w\). Given our data setup, edge weights \(w\) can be decomposed into two components: (1) _self-supervised connectivity_\(w^{(u)}\) by treating all points in \(\) as entirely unlabeled, and (2) _supervised connectivity_\(w^{(l)}\) by incorporating labeled information from \(_{l}\) to the graph. We define the connectivity formally below.

**Definition 3.1** (Self-supervised connectivity).: _For any two augmented data \(x,x^{}\), \(w^{(u)}_{xx^{}}\) denotes the marginal probability of generating the positive pair :_

\[w^{(u)}_{xx^{}}_{}( x|)(x^{}|),\] (1)

_where \(x\) and \(x^{}\) are augmented from the same image \(\), and \(\) is the marginal distribution of both labeled and unlabeled data. A larger \(w^{(u)}_{xx^{}}\) indicates stronger similarity between \(x\) and \(x^{}\)._

Moreover, when having access to the labeling information for ID data, we can define the edge weight by adding additional supervised connectivity to the graph. We consider \((x,x^{})\) a positive pair when \(x\) and \(x^{}\) are augmented from two labeled samples \(_{l}\) and \(^{}_{l}\) with the same known class \(i_{l}\). The total edge connectivity can be formulated as below:

**Definition 3.2** (Total edge connectivity).: _Considering both self-supervised and supervised connectivities, the overall similarity for any pair of data \((x,x^{})\) is formulated as:_

\[w_{xx^{}}=_{u}w^{(u)}_{xx^{}}+_{l}w^{(l)}_{xx^{}}, w^{(l)}_{xx^{}}_{i_{l}}_{_ {l}_{l}}_{^{}_{l}_{l_{i}}} (x|_{l})(x^{}|^{}_{l} ),\] (2)

_where \(_{l_{i}}\) is the distribution of labeled samples with class label \(i_{l}\), and the coefficients \(_{u},_{l}\) modulate the relative importance between the two terms._

**Adjacency matrix.** Having established the notion of connectivity, we can define the adjacency matrix \(A^{N N}\) with entries \(A_{xx^{}}=w_{xx^{}}\). The adjacency matrix can be decomposed into the summation of self-supervised adjacency matrix \(A^{(u)}\) and supervised adjacency matrix \(A^{(l)}\):

\[A=_{u}A^{(u)}+_{l}A^{(l)}.\] (3)As a standard technique in graph theory , we use the _normalized adjacency matrix:_

\[ D^{-}AD^{-},\] (4)

where \(D^{N N}\) is a diagonal matrix with \(D_{xx}=w_{x}=_{x^{}}w_{xx^{}}\), indicating the total edge weights connected to a vertex \(x\). The normalized adjacency matrix defines the probability of \(x\) and \(x^{}\) being considered as the positive pair. The normalized adjacency matrix allows us to perform spectral decomposition as we show next.

### Learning Representations Based on Graph Spectral

In this section, we perform spectral decomposition or spectral clustering --a classical approach to graph partitioning--to the adjacency matrices defined above. This process forms a matrix where the top-\(k\) eigenvectors are the columns and _each row of the matrix can be viewed as a \(k\)-dimensional representation of an example_. The resulting feature representations enable us to rigorously analyze the separability of ID data from semantic OOD data in a closed form, as well as the generalizability to covariate-shifted OOD data (more in Section 4).

Towards this end, we consider the following optimization, which performs low-rank matrix approximation on the adjacency matrix:

\[_{F^{N k}}_{}(F,A)\| -FF^{}\|_{F}^{2},\] (5)

where \(\|\|_{F}\) denotes the matrix Frobenious norm. According to the Eckart-Young-Mirsky theorem , the minimizer of this loss function is \(F_{k}^{N k}\) such that \(F_{k}F_{k}^{}\) contains the top-\(k\) components of \(\)'s eigen decomposition.

A surrogate objective.In practice, directly solving objective (5) can be computationally expensive for an extremely large matrix. To circumvent this, the feature representations can be equivalently recovered by minimizing the following contrastive learning objective , which can be efficiently trained end-to-end using a neural network:

\[(f)-2_{u}_{1}(f)-2_{l}_{2}( f)+_{u}^{2}_{3}(f)+2_{u}_{l}_{4}(f)+_{l}^{2} _{5}(f),\] (6)

where

Importantly, this contrastive loss allows drawing a theoretical equivalence between learned representations and the top-\(k\) singular vectors of \(\), and facilitates theoretical understanding of the OOD generalization and detection on the data represented by \(\). The equivalence is formalized below.

**Theorem 3.3** (Theoretical equivalence between two objectives).: _We define each row \(f_{x}^{}\) of \(F\) as a scaled version of learned feature embedding \(f:^{k}\), with \(f_{x}=}f(x)\). Then minimizing the loss function \(_{}(F,A)\) in Equation 5 is equivalent to minimizing the surrogate loss in Equation 6. Full proof is in Appendix A._

**Interpretation for OOD generalization and detection.** The loss learns feature representation jointly from both labeled ID data and unlabeled wild data, so that meaningful structures emerge for both OOD generalization and detection (e.g., covariate-shifted OOD data is embedded closely to the ID data, whereas semantic-shifted OOD data is distinguishable from ID data). At a high level, the loss components \(_{1}\) and \(_{2}\) contribute to pulling the embeddings of positive pairs closer, while \(_{3}\), \(_{4}\) and \(_{5}\) push apart the embeddings of negative pairs. In particular, loss components on the positive pairs can pull together samples sharing the same classes, thereby helping OOD generalization. Atthe same time, loss components on the negative pairs can help separate semantic OOD data in the embedding space, thus benefiting OOD detection.

**Difference from prior works**. Spectral contrastive learning has been employed to analyze problems such as self-supervised learning , unsupervised domain adaptation , novel category discovery , open-world semi-supervised learning  etc. These works share the underlying loss form by pulling together positive pairs and pushing away negative pairs. Despite the shared loss formulation, our work has fundamentally distinct data setup and learning goals, which focus on the joint OOD generalization and detection problems (_cf._ Section 2). We are interested in leveraging labeled ID data to classify both unlabeled ID and covariate OOD data correctly into the known categories while rejecting the remainder of unlabeled data from new categories, which was not studied in the prior works. Accordingly, we derive a novel theoretical analysis for our setup and present empirical verification uniquely tailored to our problem focus, which we present next.

## 4 Theoretical Analysis

In this section, we present a novel theoretical analysis of how the learned representations via graph spectral can facilitate both OOD generalization and detection.

### Analytic Form of Learned Representations

To obtain the representations, one can train the neural network \(f:^{k}\) using the spectral loss defined in Equation 6. Minimizing the loss yields representation \(Z^{N k}\), where each row vector \(z_{i}=f(x_{i})^{}\). According to Theorem 3.3, the closed-form solution for the representations is equivalent to performing spectral decomposition of the adjacency matrix. Thus, we have \(F_{k}=Z\), where \(F_{k}F_{k}^{}\) contains the top-\(k\) components of \(\)'s SVD decomposition and \(D\) is the diagonal matrix. We further define the top-\(k\) singular vectors of \(\) as \(V_{k}^{N k}\), so we have \(F_{k}=V_{k}}\), where \(_{k}\) is a diagonal matrix of the top-\(k\) singular values of \(\). By equalizing the two forms of \(F_{k}\), the closed-formed solution of the learned feature space is given by \(Z=[D]^{-}V_{k}}\).

### Analysis Target

**Linear probing evaluation.** We assess OOD generalization performance based on the linear probing error, which is commonly used in self-supervised learning . Specifically, the weight of a linear classifier is denoted as \(^{k|_{l}|}\), which is learned with ID data to minimize the error. The class prediction for an input \(\) is given by \(h(;f,)=*{argmax}_{i_{l}}(f()^{})_{i}\). The linear probing error measures the misclassification of linear head on covariate-shifted OOD data:

\[(f)_{*{p}^{}_{}}[y() h(;f,)],\] (7)

where \(y()\) indicates the ground-truth class of \(\). \((f)=0\) indicates perfect OOD generalization.

**Separability evaluation.** Based on the closed-form embeddings, we can also quantify the distance between the ID and semantic OOD data:

\[(f)_{_{i}_{},_{j}*{p}^{}_{}}\|f(_{i})-f(_{j})\|_{2}^{2}.\] (8)

The magnitude of \((f)\) reflects the extent of separation between ID and semantic OOD data. Larger \((f)\) suggests better OOD detection capability.

### An Illustrative Example

**Setup.** We use an illustrative example to explain our theoretical insights. In Figure 2, the training examples come from 5 types of data: angel in sketch (ID), tiger in sketch (ID), angel in painting (covariate OOD), tiger in painting (covariate OOD), and panda (semantic OOD). The label space \(_{l}\) consists of two known classes: angel and tiger. Class Panda is considered a novel class. The goal is to classify between images of angels and tigers while rejecting images of pandas.

**Augmentation transformation probability.** Based on the data setup, we formally define the augmentation transformation, which encodes the probability of augmenting an original image to the augmented view \(x\):

\[(x)=\{&&y( )=y(x),d()=d(x);\\ &&y()=y(x),d() d(x);\\ &&y() y(x),d()=d(x);\\ &&y() y(x),d() d(x)..\] (9)

Here \(d()\) is the domain of sample \(\), and \(y()\) is the class label of sample \(\). \(\) indicates the augmentation probability when two samples share the same label but different domains, and \(\) indicates the probability when two samples share different class labels but with the same domain. It is natural to assume the magnitude order that follows \((,)(,) 0\).

**Adjacency matrix.** With Eq. 9 and the definition in Section 3.1, we can derive the analytic form of adjacency matrix \(A\).

\[_{u}A^{(u)}=^{2}+^{2}+^{2}+2^{2}&2 +^{2}+2&2+^{2}+2&2 +^{2}+2&(+++2)\\ 2+^{2}+2&^{2}+^{2}+2^{2}&2 +^{2}+2&2+^{2}+2&2 +^{2}+2&(+++2)\\ 2+^{2}+2&2+^{2}+2&2 +^{2}+2&^{2}+2^{2}&2+^{2}+2 &(+++2)\\ (+++2)&(+++2)&( +++2)&(+++2)&^{2}+4^ {2}\] (10)

\[A=(_{l}A^{(l)}+_{u}A^{(u)})=( ^{2}+^{2}&2&+&+& (+)\\ 2&^{2}+^{2}&+&+& (+)\\ +&+&^{2}+^{2}&2 &(+)\\ +&+&2&^{2}+ ^{2}&(+)\\ (+)&(+)&(+)&(+ )&2^{2}+_{u}A^{(u)}),\] (11)

where \(C\) is the normalization constant to ensure the summation of weights amounts to 1. Each row or column encodes connectivity associated with a specific sample, ordered by: angel sketch, tiger sketch, angel painting, tiger painting, and panda. We refer readers to Appendix D.1 for the detailed derivation.

Main analysis.We are primarily interested in analyzing the representation space derived from \(A\). We mainly put analysis on the top-3 eigenvectors \(^{5 3}\) and measure both the linear probing error and separability. The full derivation of Theorem 4.1 and Theorem 4.2 can be found in Appendix D.1.

**Theorem 4.1**.: _Assume \(_{u}=5,_{l}=1\), we have:_

\[=\{}&} &}&}&0\\ 0&0&0&0&1\\ -}&}&-}&} &0\}^{}>;\\ [}&}&}&}&0\\ 0&0&0&1\\ -}&-}&}&} ]^{}<..,\] (12)

Interpretation.The discussion can be divided into two cases: (1) \(>\). (2) \(<\). In the first case when the connection between the class (multiplied by \(\)) is stronger than the domain, the model could learn a perfect ID classifier based on features in the first two rows in \(V\) and effectively generalize to the covariate-shifted domain (the third and fourth row in \(\)), achieving perfect OOD generalization with linear probing error \((f)=0\). In the second case when the connection between the domain is stronger than the connection between the class (scaled by \(\)), the embeddings of covariate-shifted OOD data are identical, resulting in high OOD generalization error.

**Theorem 4.2**.: _Denote \(^{}=\) and \(^{}=\) and assume \(_{u}=5,_{l}=1\), we have:_

\[(f)=\{(7+12^{}+12^{ })(}{8}(1-^{}-^{ })^{2}+1)&>;\\ (7+12^{}+12^{})(}{8}(1-^{ }-^{})^{2}+1)&< ..\] (13)

Figure 2: Illustration of graph and augmentation probability.

**Interpretation.** We analyze the function \(S(f)\) under different \(^{}\) and \(^{}\) values in Figure 3. Overall the distance between semantic OOD data and ID data displays a large value, which facilitates OOD detection. Note that a clear boundary in Figure 3 indicates \(=\).

**More analysis.** Building upon the understanding of both OOD generalization and detection, we further discuss the influence of different semantic OOD data in Appendix B, and the impact of ID labels in Appendix C.

## 5 Experiments

Beyond theoretical insights, we show empirically that our approach is competitive. We present the experimental setup in Section 5.1, results in Section 5.2, and further analysis in Section 5.3.

### Experimental Setup

**Datasets and benchmarks.** Following the setup of , we employ CIFAR-10  as \(_{}\) and CIFAR-10-C  with Gaussian additive noise as the \(_{}^{}\). For \(_{}^{}\), we leverage SVHN , LSUN , Places365 , Textures . To simulate the wild distribution \(_{}\), we adopt the same mixture ratio as in Scene , where \(_{c}=0.5\) and \(_{s}=0.1\). Detailed descriptions of the datasets and data mixture can be found in the Appendix E.1. To demonstrate the adaptability and robustness of our proposed method, we extend the framework to more diverse and challenging datasets. Large-scale results on the ImageNet dataset can be found in Appendix E.2. Additional results on the Office-Home  can be found in Appendix E.3. More ablation studies can be found in Appendix E.4.

**Implementation details.** We adopt Wide ResNet with 40 layers and a widen factor of 2 . We use stochastic gradient descent with Nesterov momentum , with weight decay 0.0005 and momentum 0.09. We divide CIFAR-10 training set into 50% labeled as ID and 50% unlabeled. And we mix unlabeled CIFAR-10, CIFAR-10-C, and semantic OOD data to generate the wild dataset. Starting from random initialization, we train the network with the loss function in Eq. 6 for 1000 epochs. The learning rate is 0.03 and the batch size is 512. \(_{u}\) is selected within {1.00, 2.00} and \(_{l}\) is within {0.02, 0.10, 0.50, 1.00}. Subsequently, we follow the standard approach  and use labeled ID data to fine-tune the model with cross-entropy loss for better generalization ability. We fine-tune for 20 epochs with a learning rate of 0.005 and batch size of 512. The fine-tuned model is used to evaluate the OOD generalization and OOD detection performance. We utilize a distance-based method for OOD detection, which resonates with our theoretical analysis. Specifically, our default approach employs a simple non-parametric KNN distance , which does not impose any distributional assumption on the feature space. The threshold is determined based on the clean ID set at 95% percentile. For further implementation details, hyper-parameters, and validation strategy, please see Appendix F.

### Results and Discussion

**Competitive empirical performance.** The main results in Table 1 demonstrate that our method not only enjoys theoretical guarantees but also exhibits competitive empirical performance compared to existing baselines. For a comprehensive evaluation, we consider three groups of methods for OOD generalization and OOD detection. Closest to our setting, we compare with strong baselines trained with wild data, namely OE , Energy-regularized learning , Woods , and Scone .

The empirical results provide interesting insights into the performance of various methods for OOD detection and generalization. **(1)** Methods tailored for OOD detection tend to capture the domain-variant information and struggle with the covariate distribution shift, resulting in suboptimal OOD accuracy. **(2)** While approaches for OOD generalization demonstrate improved OOD accuracy, they cannot effectively distinguish between ID data and semantic OOD data, leading to poor OOD detection performance. **(3)** Methods trained with wild data emerge as robust OOD detectors, yet display a notable decline in OOD generalization, highlighting the confusion introduced by covariate

Figure 3: Value of function \(S(f)\)

[MISSING_PAGE_EMPTY:8]

## 6 Related Works

Out-of-distribution detection.OOD detection has gained soaring research attention in recent years. The current research track can be divided into post hoc and regularization-based methods. Post hoc methods derive OOD scores at test-time based on a pre-trained model, which can be categorized as confidence-based methods [39; 24; 40], energy-based methods [26; 41; 42; 43; 44; 29], distance-based methods [45; 46; 47; 23; 48; 49; 50], and gradient-based method . On the other hand, regularization-based methods aim to train the OOD detector by training-time regularization. Most approaches require auxiliary OOD data [52; 53; 54; 36; 55; 56; 57]. However, a limitation of existing methods is the reliance on clean semantic OOD datasets for training. To address this challenge, WOODS  first explored the use of wild data, which includes unlabeled ID and semantic OOD data. Building upon this idea, SCONE  extended the characterization of wild data to encompass ID, covariate OOD, and semantic OOD data, providing a more generalized data mixture in practice. In our paper, we provide a novel graph-theoretic approach for understanding both OOD generalization and detection based on the setup proposed by Scone .

Out-of-distribution generalization.OOD generalization aims to learn domain-invariant representations that can effectively generalize to unseen domains, which is more challenging than classic domain adaptation problem [58; 59; 60; 61], where the model has access to unlabeled data from the target domain. OOD generalization and domain generalization  focus on capturing semantic features that remain consistent across diverse domains, which can be categorized as reducing feature discrepancies across the source domains [63; 64; 31; 65; 66; 67], ensemble and meta learning [68; 69; 70; 71; 72], robust optimization [73; 74; 75; 76; 77], augmentation [78; 79; 80; 81], and disentanglement . Distinct from prior literature about generalization, Scone  introduces a framework that leverages the wild data ubiquitous in the real world, aiming to build a robust classifier and a reliable OOD detector simultaneously. Following the same problem setting in , we contribute novel theoretical insights into the understanding of both OOD generalization and detection.

Spectral graph theory.Spectral graph theory is a classical research field [8; 83; 84; 85; 86], concerning the study of graph partitioning through analyzing the eigenspace of the adjacency matrix. The spectral graph theory is also widely applied in machine learning [87; 88; 89; 90; 91; 92]. Recently, Haochen et al.  presented unsupervised spectral contrastive loss derived from the factorization of the graph's adjacency matrix. Shen et al.  provided a graph-theoretic analysis for unsupervised domain adaptation based on the assumption of unlabeled data entirely from \(_{}^{}\). Sun et al.  first introduced the label information and explored novel category discovery, considering unlabeled data covers \(_{}^{}\). All of the previous literature assumed unlabeled data has a homogeneous distribution. In contrast, our work focuses on the joint problem of OOD generalization and detection, tackling the challenge of unlabeled data characterized by a heterogeneous mixture distribution, which is a more general and complex scenario than previous works.

Contrastive learning.Recent works on contrastive learning advance the development of deep neural networks with a huge empirical success [6; 93; 94; 95; 96; 97; 98; 99; 100; 101]. Simultaneously, many theoretical works establish the foundation for understanding representations learned by contrastive learning through linear probing evaluation [102; 103; 104; 105; 106; 107]. Haochen et

Figure 4: (a) Distribution of KNN distance. (b) t-SNE visualization of learned embeddings. We employ CIFAR-10 as \(_{}\), CIFAR-10-C as \(_{}^{}\), and SVHN as \(_{}^{}\).

al. [7; 108], Sun et al.  extended the understanding and providing error analyses for different downstream tasks. Orthogonal to prior works, we provide a graph-theoretic framework tailored for the wild environment to understand both OOD generalization and detection.

## 7 Conclusion

In this paper, we present a graph-theoretic framework to jointly tackle both OOD generalization and detection problems. Based on the graph formulation, the data representations can be derived by factorizing the graph's adjacency matrix, allowing us to draw theoretical insight into both OOD generalization and detection performance. In particular, we analyze the closed-form solutions of linear probing error for OOD generalization, as well as separability quantifying OOD detection capability via the distance between the ID and semantic OOD data. Empirically, our framework demonstrates competitive performance against existing baselines, closely aligning with our theoretical insights. We anticipate that our theoretical framework and findings will inspire further research in unifying and understanding both OOD generalization and detection.

## 8 Broader Impact

In the rapidly evolving landscape of machine learning, addressing the dual challenges of OOD generalization and detection has become paramount for deploying _robust and reliable_ models in real-world scenarios. Our work provides a novel spectral learning solution, which not only improves model performance but also ensures its reliability and safety in diverse, dynamic environments. The implications of our research extend beyond theoretical advancements, with potential applications in healthcare, autonomous systems, and finance. The ability to deploy models with superior OOD generalization and detection capabilities addresses a critical bottleneck in the adoption of machine learning technologies, fostering trust among end-users and stakeholders.

## 9 Limitations

In our experimental setup, we focus on covariate shift as the primary form of shift in the out-of-distribution (OOD) generalization problem, a topic extensively explored in the literature. However, it's important to acknowledge the existence of other types of distributional shifts (e.g., concept shift), which we defer for future investigation.