# Crystal Structure Prediction

by Joint Equivariant Diffusion

Rui Jiao\({}^{1,2}\) Wenbing Huang\({}^{3,4}\)1 Peijia Lin\({}^{5}\) Jiaqi Han\({}^{6}\) Pin Chen\({}^{5}\) Yutong Lu\({}^{5}\) Yang Liu\({}^{1,2}\)1

\({}^{1}\)Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University

\({}^{2}\)Institute for AIR, Tsinghua University

\({}^{3}\)Gaoling School of Artificial Intelligence, Renmin University of China

\({}^{4}\) Beijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China

\({}^{5}\) National Supercomputer Center in Guangzhou,

School of Computer Science and Engineering, Sun Yat-sen University

\({}^{6}\) Stanford University

###### Abstract

Crystal Structure Prediction (CSP) is crucial in various scientific disciplines. While CSP can be addressed by employing currently-prevailing generative models (_e.g._ diffusion models), this task encounters unique challenges owing to the symmetric geometry of crystal structures--the invariance of translation, rotation, and periodicity. To incorporate the above symmetries, this paper proposes DiffCSP, a novel diffusion model to learn the structure distribution from stable crystals. To be specific, DiffCSP jointly generates the lattice and atom coordinates for each crystal by employing a periodic-E(3)-equivariant denoising model, to better model the crystal geometry. Notably, different from related equivariant generative approaches, DiffCSP leverages fractional coordinates other than Cartesian coordinates to represent crystals, remarkably promoting the diffusion and the generation process of atom positions. Extensive experiments verify that our DiffCSP significantly outperforms existing CSP methods, with a much lower computation cost in contrast to DFT-based methods. Moreover, the superiority of DiffCSP is also observed when it is extended for ab initio crystal generation. Code is available at [https://github.com/jiaor17/DiffCSP](https://github.com/jiaor17/DiffCSP).

## 1 Introduction

Crystal Structure Prediction (CSP), which returns the stable 3D structure of a compound based solely on its composition, has been a goal in physical sciences since the 1950s . As crystals are the foundation of various materials, estimating their structures in 3D space determines the physical and chemical properties that greatly influence the application to various academic and industrial sciences, such as the design of drugs, batteries, and catalysts . Conventional methods towards CSP mostly apply the Density Functional Theory (DFT)  to compute the energy at each iteration, guided by optimization algorithms (such as random search , Bayesian optimization , etc.) to iteratively search for the stable state corresponding to the local minima of the energy surface .

The DFT-based approaches are computationally-intensive. Recent attention has been paid to deep generative models, which directly learn the distribution from the training data consisting of stable structures . More recently, diffusion models, a special kind of deep generative models are employed for crystal generation , encouraged by their better physical interpretability and enhanced performance than other generative models. Intuitively, by conducting diffusion on stable structures,the denoising process in diffusion models acts like a force field that drives the atom coordinates towards the energy local minimum and thus is able to increase stability. Indeed, the success of diffusion models is observed in broad scientific domains, including molecular conformation generation , protein structure prediction  and protein docking .

However, designing diffusion models for CSP is challenging. From the perspective of physics, any E(3) transformation, including translation, rotation, and reflection, of the crystal coordinates does not change the physical law and thus keeps the crystal distribution invariant. In other words, the generation process we design should yield E(3) invariant samples. Moreover, in contrast to other types of structures such as small molecules  and proteins , CSP exhibits unique challenges, mainly incurred by the periodicity of the atom arrangement in crystals. Figure 1 displays a crystal where the atoms in a unit cell are repeated infinitely in space. We identify such unique symmetry, jointly consisting of E(3) invariance and periodicity, as _periodic E(3) invariance_ in this paper. Generating such type of structures requires not only modeling the distribution of the atom coordinates within every cell, but also inferring how their bases (_a.k.a._ lattice vectors) are placed in 3D space. Interestingly, as we will show in SS 4.1, such view offers a natural disentanglement for fulfilling the periodic E(3) invariance by separately enforcing constraints on fractional coordinates and lattice vectors, which permits a feasible implementation to encode the crystal symmetry.

In this work, we introduce DiffCSP, an equivariant diffusion method to address CSP. Considering the specificity of the crystal geometry, our DiffCSP jointly generates the lattice vectors and the fractional coordinates of all atoms, by employing a proposed denoising model that is theoretically proved to generate periodic-E(3)-invariant samples. A preferable characteristic of DiffCSP is that it leverages the fractional coordinate system (defined in SS 3) other than the Cartesian system used in previous methods to represent crystals [9; 15], which encodes periodicity intrinsically. In particular, the fractional representation not only allows us to consider Wrapped Normal (WN) distribution  to better model the periodicity, but also facilitates the design of the denoising model via the Fourier transformation, compared to the traditional multi-graph encoder in crystal modeling .

CDVAE  is closely related with our paper. It adopts an equivariant Variational Auto-Encoder (VAE) based framework to learn the data distribution and then generates crystals in a score-matching-based diffusion process. However, CDVAE focuses mainly on ab initio crystal generation where the composition is also randomly sampled, which is distinct from the CSP task in this paper. Moreover, while CDVAE first predicts the lattice and then updates the coordinates with the fixed lattice, we jointly update the lattice and coordinates to better model the crystal geometry. Besides, CDVAE represents crystals by Cartesian coordinates upon multi-graph modeling, whereas our DiffCSP applies fractional coordinates without multi-graph modeling as mentioned above.

To sum up, our contributions are as follows:

* To the best of our knowledge, we are the first to apply equivariant diffusion-based methods to address CSP. The proposed DiffCSP is more insightful than current learning-based approaches as the periodic E(3) invariance has been delicately considered.
* DiffCSP conducts joint diffusion on lattices and fractional coordinates, which is capable of capturing the crystal geometry as a whole. Besides, the usage of fractional coordinates in place of Cartesian coordinates used in previous methods (_e.g._ CDVAE ) remarkably promotes the diffusion and the generation process of atom positions.
* We verify the efficacy of DiffCSP on the CSP task against learning-based and DFT-based methods, and sufficiently ablate each proposed component in DiffCSP. We further extend DiffCSP into ab initio generation and show its effectiveness against related methods.

## 2 Related Works

**Crystal Structure Prediction** Traditional computation methods [4; 5; 17; 18] combine DFT  with optimization algorithms to search for local minima in the potential energy surface. However, DFT is computationally intensive, making it dilemmatic to balance efficiency and accuracy. With the improvement of crystal databases, machine-learning methods are applied as alternative energy predictors to DFT followed by optimization steps [19; 20; 21]. Apart from the predict-optimize paradigm, another line of approaches directly learns stable structures from data by deep generative models, which represents crystals by 3D voxels [7; 22; 23], distance matrices [8; 24; 25] or 3Dcoordinates [26; 27; 28]. Unfortunately, these methods are unaware of the full symmetries of the crystal structure. CDVAE  has taken the required symmetries into account. However, as mentioned above, the initial version of CDVAE is for different task and utilizes different generation process.

**Equivariant Graph Neural Networks** Geometrically equivariant Graph Neural Networks (GNNs) that ensure E(3) symmetry are powerful tools to represent physical objects [29; 30; 31; 32; 33], and have showcased the superiority in modeling 3D structures [34; 35]. To further model the periodic materials, Xie and Grossman  propose the multi-graph edge construction to capture the periodicity by connecting the edges between adjacent lattices. Yan et al.  further introduce periodic pattern encoding into a Transformer-based backbone. In this work, we achieve the periodic invariance by introducing the Fourier transform on fractional coordinates.

**Diffusion Generative Models** Motivated by the non-equilibrium thermodynamics , diffusion models connect the data distribution with the prior distribution via forward and backward Markov chains , and have made remarkable progress in the field of image generation [39; 40]. Equipped with equivariant GNNs, diffusion models are capable of generating samples from the invariant distribution, which is desirable in conformation generation [10; 13], ab initio molecule design , protein generation , and so on. Recent works extend the diffusion models onto Riemann manifolds [43; 44], and enable the generation of periodic features like torsion angles [12; 16].

## 3 Preliminaries

**Representation of crystal structures** A 3D crystal can be represented as the infinite periodic arrangement of atoms in 3D space, and the smallest repeating unit is called a _unit cell_, as shown in Figure 1. A unit cell can be defined by a triplet \(=(,,)\), where \(=[_{1},_{2},...,_{N}]^{h N}\) denotes the list of the one-hot representations of atom types, \(=[_{1},_{2},...,_{N}]^{3 N}\) consists of Cartesian coordinates of the atoms, and \(=[_{1},_{2},_{3}]^{3 3}\) represents the lattice matrix containing three basic vectors to describe the periodicity of the crystal. The infinite periodic crystal structure is represented by

\[\{(^{}_{i},^{}_{i})|^{}_{i}=_{i}, {x}^{}_{i}=_{i}+,\;^{3 1 }\}, \]

where the \(j\)-th element of the integral vector \(\) denotes the integral 3D translation in units of \(_{j}\).

**Fractional coordinate system** The Cartesian coordinate system \(\) leverages three standard orthogonal bases as the coordinate axes. In crystallography, the fractional coordinate system is usually applied to reflect the periodicity of the crystal structure [26; 27; 28; 45], which utilizes the lattices \((_{1},_{2},_{3})\) as the bases. In this way, a point represented by the fractional coordinate vector \(=[f_{1},f_{2},f_{3}]^{}[0,1)^{3}\) corresponds to the Cartesian vector \(=_{i=1}^{3}f_{i}_{i}\). This paper employs the fractional coordinate system, and denotes the crystal by \(=(,,)\), where the fractional coordinates of all atoms in a cell compose the matrix \([0,1)^{3 N}\).

**Task definition** CSP predicts for each unit cell the lattice matrix \(\) and the fractional matrix \(\) given its chemical composition \(\), namely, learning the conditional distribution \(p(,)\).

## 4 The Proposed Method: DiffCSP

This section first presents the symmetries of the crystal geometry, and then introduces the joint equivaraint diffusion process on \(\) and \(\), followed by the architecture of the denoising function.

### Symmetries of Crystal Structure Distribution

While various generative models can be utilized to address CSP, this task encounters particular challenges, including constraints arising from symmetries of crystal structure distribution. Here, we consider the three types of symmetries in the distribution of \(p(,)\): permutation invariance, \(O(3)\) invariance, and periodic translation invariance. Their detailed definitions are provided as follows.

**Definition 1** (Permutation Invariance).: _For any permutation \(_{N}\), \(p(,)=p(,)\), i.e., changing the order of atoms will not change the distribution._

**Definition 2** (O(3) Invariance).: _For any orthogonal transformation \(^{3 3}\) satisfying \(^{}=\), \(p(,)=p(,)\), namely, any rotation/reflection of \(\) keeps the distribution unchanged._

**Definition 3** (Periodic Translation Invariance).: _For any translation \(^{3 1}\), \(p(,w(+^{}))=p(,)\), where the function \(w()=-[0,1)^{3 N}\) returns the fractional part of each element in \(\), and \(^{3 1}\) is a vector with all elements set to one. It explains that any periodic translation of \(\) will not change the distribution2._

The permutation invariance is tractably encapsulated by using GNNs as the backbone for generation . We mainly focus on the other two kinds of invariance (see Figure 1), since GNNs are our default choices. For simplicity, we compactly term the \(O(3)\) invariance and periodic translation invariance as _periodic E(3) invariance_ henceforth. Previous approaches (_e.g._) adopt Cartesian coordinates \(\) other than fractional coordinates \(\), hence their derived forms of the symmetry are different. Particularly, in Definition 2, the orthogonal transformation additionally acts on \(\); in Definition 3, the periodic translation \(w(+^{})\) becomes the translation along the lattice bases \(+^{}\); besides, \(\) should also maintain E(3) translation invariance, that is \(p(,+^{}|)=p(,|)\). With the help of the fractional system, the periodic E(3) invariance is made tractable by fulfilling O(3) invariance _w.r.t._ the orthogonal transformations on \(\) and periodic translation invariance _w.r.t._ the periodic translations on \(\), respectively. In this way, such approach, as detailed in the next section, facilitates the application of diffusion methods to the CSP task.

### Joint Equivariant Diffusion

Our method DiffCSP addresses CSP by simultaneously diffusing the lattice \(\) and the fractional coordinate matrix \(\). Given the atom composition \(\), \(_{t}\) denotes the intermediate state of \(\) and \(\) at time step \(t\)\((0 t T)\). DiffCSP defines two Markov processes: the forward diffusion process gradually adds noise to \(_{0}\), and the backward generation process iteratively samples from the prior distribution \(_{T}\) to recover the origin data \(_{0}\).

Figure 1: (a)\(\)(b): The orthogonal transformation of the lattice vectors. (c)\(\)(d): The periodic translation of the fractional coordinates. Both cases do not change the structure.

Figure 2: Overview of DiffCSP. Given the composition \(\), we denote the crystal, its lattice and fractional coordinate matrix at time \(t\) as \(_{t}\), \(_{t}\) and \(_{t}\), respectively. The terms \(}\) and \(}\) are Gaussian noises, \(_{L}}\) and \(_{F}}\) are predicted by the denoising model \(\).

Joining the statements in SS 4.1, the recovered distribution from \(_{T}\) should meet periodic E(3) invariance. Such requirement is satisfied if the prior distribution \(p(_{T})\) is invariant and the Markov transition \(p(_{t-1}_{t})\) is equivariant, according to the diffusion-based generation literature . Here, an equivariant transition is specified as \(p(g_{t-1} g_{t})=p(_{t-1} _{t})\) where \(g\) refers to any orthogonal/translational transformation \(g\) acts on \(\) in the way presented in Definitions 2-3. We separately explain the derivation details of \(\) and \(\) below. The detailed flowcharts are summarized in Algorithms 1 and 2 in Appendix B.3.

**Diffusion on \(\)** Given that \(\) is a continuous variable, we exploit Denoising Diffusion Probabilistic Model (DDPM)  to accomplish the generation. We define the forward process that progressively diffuses \(_{0}\) towards the Normal prior \(p(_{T})=(0,)\) by \(q(_{t}|_{t-1})\) which can be devised as the probability conditional on the initial distribution:

\[q(_{t}|_{0})=_{t}|_{t}} _{0},(1-_{t}), \]

where \(_{t}(0,1)\) controls the variance, and \(_{t}=_{s=1}^{t}_{t}=_{s=1}^{t}(1-_{t})\) is valued in accordance to the cosine scheduler .

The backward generation process is given by:

\[p(_{t-1}|_{t})=(_{t-1}|(_{t}), ^{2}(_{t})), \]

where \((_{t})=}}_{t}-}{_{t}}}}_{}(_{t},t) \),\(^{2}(_{t})\)= \(_{t}_{t-1}}{1-_{t}}\). The denoising term \(}_{}(_{t},t)^{3 3}\) is predicted by the model \((_{t},_{t},,t)\).

As the prior distribution \(p(_{T})=(0,)\) is already O(3)-invariant, we require the generation process in Eq. (3) to be O(3)-equivariant, which is formally stated below.

**Proposition 1**.: _The marginal distribution \(p(_{0})\) by Eq. (3) is O(3)-invariant if \(}_{}(_{t},t)\) is O(3)-equivariant, namely \(}_{}(_{t},_{t},,t)= {}_{}(_{t},_{t},,t),^{ }=\)._

To train the denoising model \(\), we first sample \(_{}(0,)\) and reparameterize \(_{t}=_{t}}_{0}+_{t}}_{}\) based on Eq. (2). The training objective is defined as the \(_{2}\) loss between \(_{}\) and \(}_{}\):

\[_{}=_{_{}(0,),t(1,T)}[\|_{}-}_{}( _{t},t)\|_{2}^{2}]. \]

**Diffusion on \(\)** The domain of fractional coordinates \([0,1)^{3 N}\) forms a quotient space \(^{3 N}/^{3 N}\) induced by the crystal periodicity. It is not suitable to apply the above DDPM fashion to generate \(\), as the normal distribution used in DDPM is unable to model the cyclical and bounded domain of \(\). Instead, we leverage Score-Matching (SM) based framework [49; 50] along with Wrapped Normal (WN) distribution  to fit the specificity here. Note that WN distribution has been explored in generative models, such as molecular conformation generation .

During the forward process, we first sample each column of \(_{}^{3 N}\) from \((0,)\), and then acquire \(_{t}=w(_{0}+_{t}_{})\) where the truncation function \(w()\) is already defined in Definition 3. This truncated sampling implies the WN transition:

\[q(_{t}|_{0})_{^{3 N}} -_{t}-_{0}+\|_{F}^{2}}{2_{t}^{2}}. \]

Basically, this process ensures the probability distribution over \([z,z+1)^{3 N}\) for any integer \(z\) to be the same to keep the crystal periodicity. Here, the noise scale \(_{t}\) obeys the exponential scheduler: \(_{0}=0\) and \(_{t}=_{1}(}{_{1}})\), if \(t>0\). Desirably, \(q(_{t}|_{0})\) is periodic translation equivariant, and approaches a uniform distribution \((0,1)\) if \(_{T}\) is sufficiently large.

For the backward process, we first initialize \(_{T}\) from the uniform distribution \((0,1)\), which is periodic translation invariant. With the denoising term \(}_{}\) predicted by \((_{t},_{t},,t)\), we combine the ancestral predictor [38; 50] with the Langevin corrector  to sample \(_{0}\). We immediately have:

**Proposition 2**.: _The marginal distribution \(p(_{0})\) is periodic translation invariant if \(}_{}(_{t},t)\) is periodic translation invariant, namely \(}_{}(_{t},_{t},,t)=} _{}(_{t},w(_{t}+^{}),,t), ^{3}\)._The training objective for score matching is:

\[_{}=_{_{t} q(_{t}|_{0}),t (1,T)}_{t}\|_{_{t}} q(_{t}| _{0})-}_{}(_{t},t)\|_{2}^{2},\]

where \(_{t}=_{_{t}}^{-1}\|_{_{t}} q(_{t}|_{0})\|_{2}^{2}\) is approximated via Monte-Carlo sampling. More details are deferred to Appendix B.1.

**Extension to ab initio crystal generation** Although our method is proposed to address CSP where the composition \(\) is fixed, our method is able to be extended for the ab initio generation task by further generating \(\). We achieve this by additionally optimizing the one-hot representation \(\) with a DDPM-based approach. We provide more details in Appendix G.

### The Architecture of the Denoising Model

This subsection designs the denoising model \((,,,t)\) that outputs \(}_{}\) and \(}_{}\) satisfying the properties stated in Proposition 1 and 2.

Let \(^{(s)}=[_{1}^{(s)},,_{N}^{(s)}]\) denote the node representations of the \(s\)-th layer. The input feature is given by \(_{i}^{(0)}=(f_{}(_{i}),f_{}(t))\), where \(f_{}\) and \(f_{}\) are the atomic embedding and sinusoidal positional encoding [38; 51], respectively; \(\) is a multi-layer perception (MLP).

Built upon EGNN , the \(s\)-th layer message-passing is unfolded as follows:

\[_{ij}^{(s)} =_{m}(_{i}^{(s-1)},_{j}^{(s-1)},^{} ,_{}(_{j}-_{i})), \] \[_{i}^{(s)} =_{j=1}^{N}_{ij}^{(s)},\] (7) \[_{i}^{(s)} =_{i}^{(s-1)}+_{h}(_{i}^{(s-1)},_{i}^{(s)}). \]

\(_{}()[c,k]=(2 mf_{c})\), if \(k=2m\) (even); and \(_{}()[c,k]=(2 mf_{c})\), if \(k=2m+1\) (odd). \(_{}\) extracts various frequencies of all relative fractional distances that are helpful for crystal structure modeling, and more importantly, \(_{}\) is periodic translation invariant, namely, \(_{}(w(_{j}+)-w(_{i}+))=_{}( _{j}-_{i})\) for any translation \(\), which is proved in Appendix A.3.

After \(S\) layers of message passing conducted on the fully connected graph, the lattice noise \(}_{}\) is acquired by a linear combination of \(\), with the weights given by the final layer:

\[}_{}=_{L}_{i=1}^{N} _{i}^{(S)}, \]

where \(_{L}\) is an MLP with output shape as \(3 3\). The fractional coordinate score \(}_{}\) is output by:

\[}_{}[:,i]=_{F}(_{i}^{(S)}), \]

where \(}_{}[:,i]\) defines the \(i\)-th column of \(}_{}\), and \(_{F}\) is an MLP on the final representation.

We apply the inner product term \(^{}\) in Eq. (6) to achieve O(3)-invariance, as \(()^{}()=^{}\) for any orthogonal matrix \(^{3 3}\). This leads to the O(3)-invariance of \(_{L}\) in Eq. (10), and we further left-multiply \(\) with \(_{L}\) to ensure the O(3)-equivariance of \(}_{}\). Therefore, the above formulation of the denoising model \((,,,t)\) ensures the following property.

**Proposition 3**.: _The score \(}_{}\) by Eq. (9) is O(3)-equivariant, and the score \(}_{}\) from Eq. (10) is periodic translation invariant. Hence, the generated distribution by DiffCSP is periodic E(3) invariant._

**Comparison with multi-graph representation** Previous methods [9; 15; 29; 52] utilize Cartesian coordinates, and usually describe crystals with multi-graph representation to encode the periodic structures. They create multiple edges to connect each pair of nodes where different edges refer to different integral cell translations. Here, we no longer require multi-graph representation, since we employ fractional coordinates that naturally encode periodicity and the Fourier transform \(_{}\) in our message passing is already periodic translation invariant. We will ablate the benefit in Table 3.

[MISSING_PAGE_FAIL:7]

considers the ground-truth lattice initialization for encoding periodicity, yielding a final model named **P-cG-SchNet**. Another baseline **CDVAE** is a VAE-based framework for pure crystal generation, by first predicting the lattice and the initial composition and then optimizing the atom types and coordinates via annealed Langevin dynamics . To adapt CDVAE into the CSP task, we replace the original normal prior for generation with a parametric prior conditional on the encoding of the given composition. More details are provided in Appendix B.2.

**Evaluation metrics** Following the common practice , we evaluate by matching the predicted candidates with the ground-truth structure. Specifically, for each structure in the test set, we first generate \(k\) samples of the same composition and then identify the matching if at least one of the samples matches the ground truth structure, under the metric by the StructureMatcher class in pymatgen  with thresholds stol=0.5, angle_tol=10, ltol=0.3. The **Match rate** is the proportion of the matched structures over the test set. **RMSE** is calculated between the ground truth and the best matching candidate, normalized by \(\) where \(V\) is the volume of the lattice, and averaged over the matched structures. For optimization methods, we select 20 structures of the lowest energy of all 5,000 structures from all iterations during testing as candidates. For generative baselines and our DiffCSP, we let \(k=1\) and \(k=20\) for evaluation. We provide more details in Appendix B, C.1 and I.

**Results** Table 1 conveys the following observations. **1.** The optimization methods encounter low Match rates, signifying the difficulty of locating the optimal structures within the vast search space. **2.** In comparison to other generative methods that construct structures atom by atom or predict the lattice and atom coordinates in two stages, our method demonstrates superior performance, highlighting the effectiveness of jointly refining the lattice and coordinates during generation. **3.** All methods struggle with performance degradation as the number of atoms per cell increases, on the datasets from Perov-5 to MPTS-52. For example, the Match rates of the optimization methods are less than 10% in MPTS-52. Even so, our method consistently outperforms all other methods.

**Visualization** Figure 3 provides qualitative comparisons.DiffCSP clearly makes the best predictions.

### Comparison with DFT-based Methods

We further select 10 binary and 5 ternary compounds in MP-20 testing set and compare our model with USPEX , a DFT-based software equipped with the evolutionary algorithm to search for stable structures. For our method, we sample 20 candidates for each compound following the setting in Table 1. We select the model trained on MP-20 for inference, with a training duration of 5.2 hours. For USPEX, we apply 20 generations, 20 populations for each compound, and select the best sample in each generation, leading to 20 candidates as well. We summarize the **Match rate** over the 15 compounds, the **Averaged RMSD** over the matched structures, and the **Averaged Inference Time** to generate 20 candidates for each compound in Table 10. The detailed results for each compound are listed in Appendix F. DiffCSP correctly predicts more structures with higher match rate, and more importantly, its time cost is much less than USPEX, allowing more potential for real applications.

### Ablation Studies

We ablate each component of DiffCSP in Table 3, and probe the following aspects. **1.** To verify the necessity of jointly updating the lattice \(\) and fractional coordinates \(\), we construct two variants that separate the joint optimization into two stages, denoted as \(\) and \(\). Particularly, \(\) applies two networks to learn the reverse process \(p_{_{1}}(_{0:T-1}|,_{T},_{T})\) and \(p_{_{2}}(_{0:T-1}|,_{T},_{0})\). During inference, we first sample \(_{T},_{T}\) from their prior distributions, acquiring \(_{0}\) via \(p_{_{1}}\), and then \(_{0}\) by \(p_{_{2}}\) based on \(_{0}\). \(\) is similarly executed but with the generation order of \(_{0}\) and \(_{0}\) exchanged. Results indicate that \(\) performs better than the \(\), but both are inferior to the joint update in DiffCSP, which endorses our design. We conjecture that the joint diffusion fashion enables \(\) and \(\) to update synergistically, which makes the generation process more tractable to learn and thus leads to better performance. **2.** We explore the necessity of preserving the O(3) invariance when generating \(\), which is ensured by the inner product \(^{}\) in Eq. (6).

    & Match rate (\%)\(\) & Avg. RMSD\(\) & Avg. Time\(\) \\  USPEX  & 53.33 & **0.0159** & 12.5h \\ DiffCSP & **73.33** & 0.0172 & **10s** \\   

Table 2: Overall results over the 15 selected compounds.

When we replace it with \(\) and change the final output as \(}_{}=_{L}_{i=1}^{N}_{i} ^{(S)}\) in Eq. (9) to break the equivariance, the model suffers from extreme performance detriment. Only 1.66% structures are successfully matched, which obviously implies the importance of incorporating O(3) equivariance. Furthermore, we introduce the chirality into the denoising model by adding \((||)\), the sign of the determinant of the lattice matrix, as an additional input in Eq. 6. The adapted model is \(SO(3)\)-invariant, but breaks the reflection symmetry and hence is NOT \(O(3)\)-invariant. There is no essential performance change, indicating the chirality is not quite crucial in distinguishing different crystal structures for the datasets used in this paper. **3.** We further assess the importance of periodic translation invariance from two perspectives. For the generation process, we generate \(\) via the score-based model with the Wrapped Normal (WN) distribution. We replace this module with DDPM under standard Gaussian as \(q(_{t}|_{0})=_{t}|} _{0},(1-_{t})\) similarly defined as Eq. (3). A lower match rate and higher RMSE are observed for this variant. For the model architecture, we adopt Fourier Transformation(FT) in Eq. (6) to capture periodicity. To investigate its effect, we replace \(_{}(_{j}-_{i})\) with \(_{j}-_{i}\), and the match rate drops from 51.49% to 29.15%. Both of the two observations verify the importance of retaining the periodic translation invariance. **4.** We further change the fully-connected graph into the multi-graph approach adopted in Xie and Grossman . The multi-graph approach decreases the match rate, since the multi-graphs constructed under different intermediate structures may differ vibrantly during generation, leading to substantially higher training difficulty and lower sampling stability. We will provide more discussions in Appendix E.

### Ab Initio Crystal Generation

DiffCSP is extendable to ab initio crystal generation by further conducting discrete diffusion on atom types \(\). We contrast DiffCSP against five generative methods following : **FTCP**, **Cond-DFC-VAE**, **G-SchNet** and its periodic variant **P-G-SchNet**, and the orginal version of **CDVAE**. Specifically for our DiffCSP, we gather the statistics of the atom numbers from the training set, then sample the number based on the pre-computed distribution similar to Hoogeboom et al. , which allows DiffCSP to generate structures of variable size. Following , we evaluate the generation performance in terms of there metrics: **Validity, Coverage**, and **Property statistics**, which respectively return the validity of the predicted crystals, the similarity between the test set and the generated samples, and the property calculation regarding density, formation energy, and the number of elements. The detailed definitions of the above metrics are provided in Appendix G.

**Results** Table 4 show that our method achieves comparable validity and coverage rate with previous methods, and significantly outperforms the baselines on the similarity of property statistics, which indicates the high reliability of the generated samples.

## 6 Discussions

**Limitation 1.** Composition generation. Our model yields slightly lower compositional validity in Table 4. We provide more discussion in Appendix G, and it is promising to propose more powerful generation methods on atom types. **2.** Experimental evaluation. Further wet-lab experiments can better verify the effectiveness of the model in real applications.

**Conclusion** In this work, we present DiffCSP, a diffusion-based learning framework for crystal structure prediction, which is particularly curated with the vital symmetries existing in crystals. The diffusion is highly flexible by jointly optimizing the lattice and fractional coordinates, where

    & Match rate (\%) \(\) & RMSE \(\) \\   &  &  \\   & _w/o Joint Diffusion_ & \\  \(\) & 50.03 & 0.0921 \\ \(\) & 36.73 & 0.0838 \\   \\   & 1.66 & 0.4002 \\  & 49.68 & 0.0637 \\   \\   & 34.09 & 0.2350 \\  & 29.15 & 0.0926 \\   \\  MG _w/_ FT & 25.85 & 0.1079 \\ MG _w/o_ FT & 28.05 & 0.1314 \\   

Table 3: Ablation studies on MP-20. MG: **M**ulti-**G**raph edge construction , FT: Fourier-Transformation.

the intermediate distributions are guaranteed to be invariant under necessary transformations. We demonstrate the efficacy of our approach on a wide range of crystal datasets, verifying the strong applicability of DiffCSP towards predicting high-quality crystal structures.

## 7 Acknowledgement

This work was jointly supported by the following projects: the National Natural Science Foundation of China (61925601 & 62006137); Beijing Nova Program (20230484278); the Fundamental Research Funds for the Central Universities, and the Research Funds of Renmin University of China (23XNKJ19); Alibaba Damo Research Fund; CCF-Ant Research Fund (CCF-AFSG RF20220204); National Key R&D Program of China (2022ZD0117805).