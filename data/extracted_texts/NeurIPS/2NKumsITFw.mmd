# Learning from Noisy Labels via Conditional Distributionally Robust Optimization

Hui Guo

Department of Computer Science

University of Western Ontario

hguo288@uwo.ca

&Grace Y. Yi

Department of Statistical and Actuarial Sciences

Department of Computer Science

University of Western Ontario

gyi5@uwo.ca

&Boyu Wang

Department of Computer Science

University of Western Ontario

bwang@csd.uwo.ca

Corresponding author.

###### Abstract

While crowdsourcing has emerged as a practical solution for labeling large datasets, it presents a significant challenge in learning accurate models due to noisy labels from annotators with varying levels of expertise. Existing methods typically estimate the true label posterior, conditioned on the instance and noisy annotations, to infer true labels or adjust loss functions. These estimates, however, often overlook potential misspecification in the true label posterior, which can degrade model performances, especially in high-noise scenarios. To address this issue, we investigate learning from noisy annotations with an estimated true label posterior through the framework of _conditional distributionally robust optimization_ (CDRO). We propose formulating the problem as minimizing the worst-case risk within a distance-based ambiguity set centered around a reference distribution. By examining the strong duality of the formulation, we derive upper bounds for the worst-case risk and develop an analytical solution for the dual robust risk for each data point. This leads to a novel robust pseudo-labeling algorithm that leverages the likelihood ratio test to construct a pseudo-empirical distribution, providing a robust reference probability distribution in CDRO. Moreover, to devise an efficient algorithm for CDRO, we derive a closed-form expression for the empirical robust risk and the optimal Lagrange multiplier of the dual problem, facilitating a principled balance between robustness and model fitting. Our experimental results on both synthetic and real-world datasets demonstrate the superiority of our method.

## 1 Introduction

Recent advancements in supervised learning have spurred a growing demand for large labeled datasets . However, acquiring accurately annotated datasets is typically costly and time-consuming, often requiring a pool of annotators with adequate domain expertise to manually label the data. Crowdsourcing has emerged as an efficient and cost-effective solution for annotating large datasets. On crowdsourcing platforms, multiple annotators with varying levels of labeling skills are employed to gather extensive labeled data. However, this approach introduces a significant challenge: the labels collected through crowdsourcing are often subject to unavoidable noise, especially in fieldsrequiring substantial domain knowledge, such as medical imaging. Consequently, models trained on noisy labels are prone to error, including overfitting, since deep models can memorize vast amounts of data . In addition to statistical research on label noise (often termed response measurement error, e.g., ), a growing body of recent machine learning literature has focused on developing effective algorithms capable of training accurate classifiers using noisy data, e.g., . Many of these methods seek to approximate the _posterior distribution of the underlying true labels_ using the observed data.

Let \(\) be an instance, \(\) denote the unobserved true label for \(\), and \(}\) represent a vector of crowdsourced noisy labels for \(\). The data-generating distribution, \(P^{*}_{_{},}}\), can be factorized in two ways: \(P^{*}_{}P^{*}_{|}P^{*}_{}| ,}}\) or \(P^{*}_{,}}P^{*}_{|, {}}\), with \(P^{*}\) denoting the (conditional) distribution for the variables indicated by the corresponding subscripts. These factorizations have inspired research that trains models by estimating the posterior distribution of the true labels, \(P^{*}_{|,}}\), in the latter factorization.

Previous work  introduced various algorithms for estimating the _annotor confusions_, also known as _noise transition probabilities_, which yield an approximated conditional distribution of \(}\), given \(\) and \(\), denoted \(P_{}|,}\). For ease of reference, we use \(P^{*}\) and \(P\) to denote the true distribution and an approximate distribution for the variables indicated by the corresponding subscripts. Given the observed data \(\) and \(}\), along with an approximated conditional distribution \(P_{}|,}\) and a prior for \(\) given \(\), denoted \(P_{|}\), the true label posterior is then computed as \(P_{}|,}} P_{ }|} P_{}|, }\) by Bayes's theorem . This estimated true label posterior is often used to infer the underlying true labels or to weight the loss functions .

However, accurately computing the posterior of the true label is challenging, and the estimated posterior \(P_{}|,}}\) may deviate from the underlying true distribution \(P^{*}_{|,}}\) due to potential misspecifications in the prior belief and the conditional noise transition probabilities . To address this issue, we introduce a robust scheme for handling crowdsourced noisy labels through conditional distributionally robust optimization (CDRO), as discussed in . Specifically, we frame the problem as minimizing the worst-case risk within a distance-based _ambiguity set_, which constrains the degree of conditional distributional uncertainty around a _reference distribution_. By leveraging the strong duality in linear programming, we derive the dual form of the robust risk and establish informative upper bounds for the worst-case risk. Additionally, for each data point, we develop an analytical solution to the robust risk minimization problem, which encompasses existing approaches as special cases . This solution is presented in a likelihood ratio format and inspires a robust approach that assigns pseudo-labels only to instances with high confidence, with uncertain data filtered out. These pseudo-labels also enable us to construct a pseudo-empirical distribution that serves as a robust reference probability distribution in CDRO under potential model misspecifications. Moreover, we derive a closed-form expression for the empirical robust risk by identifying the optimal Lagrange multiplier in the dual form. Building on this, we ultimately develop an algorithm for learning from noisy labels via conditional distributionally robust true label posterior with an adaptive Lagrange multiplier (AdaptCDRP).

Our contributions are summarized as follows: (1) We formulate learning with noisy labels as a CDRO problem and develop its dual form to tackle the challenge of potential misspecification in estimating the true label posterior from noisy data. (2) We derive an analytical solution to the dual problem for each data point, and propose a novel algorithm that constructs a robust reference distribution for this problem. (3) By deriving the optimal Lagrange multiplier for the empirical robust risk, we develop an efficient one-step update method for the Lagrange multiplier, allowing for a principled balance between robustness and model fitting. Code is available at https://github.com/hguo1728/AdaptCDRP.

**Notations.** We use \([k]\) to denote \(\{1,,k\}\) for any positive integer \(k\), and \(()\) to denote the indicator function. For a vector \(\), \(v_{j}\) stands for its \(j\)th element, and \(^{}\) denotes its transpose. For \(=(v_{1},...,v_{p})^{}\) and \(q[1,+]\), the \(L^{q}\) norm is defined as \(\|\|_{q}=(_{j=1}^{p}|v_{j}|^{q})^{1/q}\) if \(1 q<\), and \(\|\|_{}=_{j}|v_{j}|\) if \(q=+\). For a matrix \(\), we use \(V_{i,j}\) to represent its \((i,j)\) element. Furthermore, let \((,,)\) denote the measure space under consideration, where \(\) is a set, \(\) is the \(\)-field of subsets of \(\), and \(\) is the associated measure. For \(q>0\), let \(L^{q}()\) represent the collection of Borel-measurable functions \(f:\) such that \(|f|^{q}d<\). Let \((,)\) denote a metric on \(\). We call \(f\)\(L\)-Lipschitz with respect to \((,)\) if \(|f(u_{1})-f(u_{2})| L(u_{1},u_{2})\) for all \(u_{1},u_{2}\), where \(L\) is a positive constant.

Proposed Framework

### Problem Formulation

Consider a classification task with feature space \(^{d}\) and label space \(\), where \(d\) is the feature dimension. Here \(\) is taken as \(\{0,1\}\) for binary classification and \([K]\) for multi-class classification with \(K>2\). Let \(\) denote an instance and \(\) denote its true label. Let \(\) denote the considered hypothesis class consisting of functions \(\) defined over \(\), which, for example, can be neural networks that output predicted label probabilities for each \(\). Specifically, for binary classification, \(:\), with \(()\) representing \(P(=1|=)\), and the classified value is given by \((()>0.5)\). For multi-class classification, \(:^{K-1}\) with \(K>2\) and \(^{K-1}\) denoting the \(K\)-simplex, where the \(j\)th component of \(()\), denoted \(()_{j}\), represents the conditional probability \(P(=j|=)\) for \(j[K]\), with the classified value defined as \(_{j[K]}()_{j}\).

In applications, the true label \(\) is often unobserved, and instead, a set of crowdsourced noisy labels \(}\{}^{(r)}\}_{r=1}^{R}\) is collected, where \(}^{(r)}\), denoting the label provided by annotator \(r\) out of \(R\) annotators. Let \(\{_{i},}_{i}\}_{i=1}^{n}\) denote the observed data of size \(n\), where \(}_{i}\) contains noisy labels provided by \(R\) annotators for instance \(_{i}\), which may differ from the true label \(_{i}\) for each \(i[n]\). Our goal is to train a classifier using \(\) to accurately predict the true label for a future instance.

A common assumption in supervised learning is that the data points \(\{_{i},_{i},}_{i}\}\) for \(i[n]\) are independently drawn from a probability measure \(P^{*}_{,},}}\) for \(\{,,}\}\), defined over the space \(^{R}\). Under this assumption, many existing methods aim to approximate the posterior distribution of the underlying true label \(\), given the observed data \(\) and \(}\)[7; 9; 10; 11]. The estimated true label posterior, denoted \(P_{|,}}\), is then applied to either infer the true labels or to weight the loss functions. For example,  utilized \(P_{|,}}\) as a weight in the loss functions, without considering potential misspecification of the associated model. However, such strategies typically ignore the variability induced in estimating the true label posterior.

To mitigate the effects of potential misspecifications, we propose a conditional distributionally robust risk optimization problem:

\[_{}_{}(;P_{|, }}),_{}(;P_{|, }})_{,}}_{Q_{|,}}_{ }(P_{|,}})}_{Q_{ |,}}}\{((), )\},\] (1)

where \((,)\) is a loss function, the expectation \(_{,}}\) is taken with respect to the joint distribution of the observed data \(\) and \(}\), and the expectation \(_{Q_{|,}}}\) is evaluated under the conditional distribution model, denoted \(Q_{|,}}\), of the true label \(\), given \(\) and \(}\). Here, \(_{}(P_{|,}})\) is an _ambiguity set_ of probability measures centered around the _reference probability distribution_\(P_{|,}}\), indexed by \(>0\)[16; 17; 18]. For instance, \(_{}(P_{|,}})\) can be conceptualized as a "ball" with \(P_{|,}}\) at its center and \(\) as the radius, where elements in the ball represent possible distribution models for \(P^{*}_{|,}}\), and the distance between two points is measured using a standard metric for distributions. Specifically,

\[_{}(P_{|,}})=\{Q_{ |,}}(): (Q_{|,}},P_{ |,}})\},\] (2)

where \(()\) denotes all Borel probability measures on \(\), and \(\) is a discrepancy metric of probability measures. In this paper, we employ the Wasserstein distance in Definition 2.1 to define the ambiguity set. By taking the supremum in (1) over the ambiguity set (2), we aim to minimize the worst-case risk around the reference distribution, thereby mitigating the impact of potential model misspecifications.

One main obstacle in solving (1) is constructing a reliable reference distribution \(P_{|,}}\), which typically depends on an empirical distribution that requires true labels in conventional distributionally robust optimization (DRO). We address this issue by investigating the dual form of the robust risk presented in (1), which enables us to create a robust pseudo-empirical distribution using a likelihood ratio test, as detailed in Section 3.1. An additional advantage of our approach is that it provides informative upper bounds for the worst-case risk in Section 2.3 via the dual formulation.

**Remark 2.1**.: For simplicity in theoretical presentation, we assume access to all annotations from all \(R\) annotators. However, the theoretical framework presented in this paper is applicable to both single-annotator (\(R=1\)) and multiple-annotator (\(R>1\)) scenarios. In our experiments in Section 4, we also consider the scenario of sparse labeling, where we generate a total of \(R\) annotators and then randomly select one annotation per instance from these \(R\) annotators. We also conduct experiments with varying numbers of annotators for a comprehensive analysis.

### Duality Result and Relaxed Problem

To derive the pseudo-label generation algorithm and establish a reliable reference distribution, we analyze the dual form of (1). We first define the Wasserstein distance of order \(p\) for \(p[1,+)\).

**Definition 2.1** (\(p\)-Wasserstein distance, ).: For a Polish space \(\) (i.e., a complete separable metric space) endowed with a metric \(c:_{ 0}\), also called a cost function, let \(()\) represent the set of all Borel probability measures on \(\), where \(_{ 0}\) represents the set of all nonnegative real values. For \(p 1\), let \(_{p}()\) stand for the subset of \(}()\) with finite \(p\)th moments. Then, for \(P_{1},P_{2}_{p}()\), the Wasserstein distance of order \(p\) is defined as

\[W_{p}(P_{1},P_{2})_{(P_{1},P_{2})} _{(S_{1},S_{2})}\{c^{p}(S_{1},S_{2})\}^{1/p},\]

where \((P_{1},P_{2})\) comprises all probability measures on the product space \(\) such that their marginal measures are \(P_{1}()\) and \(P_{2}()\). Here, \(c^{p}(,)\) represents \(\{c(,)\}^{p}\).

In (2), we set \((,)\) as the \(p\)-Wasserstein distance and incorporate the constraint \((Q_{|,}},P_{| ,}})\) using the Lagrange formulation, and then establish the strong duality result for (1) as follows.

**Proposition 2.1** (dual problem).: _Assume that for every given \(\), \(}^{R}\) and \(\), \(((),) L^{1}(P_{|,}})\), where \(L^{1}()\) is defined in Section 1. Consider \((,)\) in (2) as the Wasserstein distance of order \(p\). Then, for any \(>0\), \(_{}(;P_{|,}})\) in (1) becomes:_

\[_{}(;P_{|,}}) =_{,}}\{_{ 0} (^{p}+_{P_{|,}}}[_{y^{}}\{(( ),y^{})- c^{p}(y^{},)\}])\}.\] (3)

To avoid solving nested optimization problems, we consider an alternative formulation by swapping the infimum and the first expectation operations:

\[_{}(;P_{|,} })_{ 0}_{,}} (^{p}+_{P_{|,}}}_{y^{}}\{(( ),y^{})- c^{p}(y^{},)\}),\] (4)

which is an upper bound of \(_{}(;P_{|,}})\) according to Proposition 2.1, and hence, (4) can be regarded as an relaxation of (3). The empirical counterpart of \(_{}(;P_{|,}})\) is given by

\[}_{}(;P_{|,}})_{ 0}_{P_{,}}^{(n)}}(^{p}+_{P_{| ,}}}_{y^{}} \{((),y^{})- c^{p}(y^{},) \}),\] (5)

where \(P_{,}}^{(n)}_{i=1}^{ n}_{_{i},}_{i}}\) is the empirical distribution of \((,})\) based on the dataset \(\) defined in Section 2.1. Here, for any \(^{R}\), \(_{}\) represents the Dirac measure on \(^{R}\), defined as \(_{}(A)\{ A\}\) for any \(A^{R}\).

**Remark 2.2**.: The Lagrange multiplier \(\) in (4) and (5) captures the trade-off between robustness and model fitting in the presence of label noise and potential model misspecifications. When the solution in \(\) is large, the inner supremum tends to favor \(^{}=\), thus encouraging the minimization of the natural risk using the reference distribution directly. In contrast, a small solution in \(\) introduces perturbations to the data, pushing the classifier away from the sample instances weighted by the reference distribution.

**Remark 2.3**.: When \(p=1\), (5) represents the dual form of the following problem:

\[_{Q_{|,}}_{ }(P_{|,}})}_{P_{ ,}}^{(n)}}[_{Q_{| ,}}}\{((),) \}],\] (6)

where \(_{}(P_{|,}} )=\{Q_{|,}}( ):_{P_{,}}^{(n)}}\, (Q_{|,}},P_{| ,}})\}\). The proof of this statement is deferred to Appendix A.3. This result indicates that the empirical robust risk in the relaxed problem (5) corresponds to the worst-case risk within an ambiguity set that constrains the size of the average conditional distributional uncertainty.

### Generalization Bounds

With the duality result in Proposition 2.1 and the derivations of the alternative formulations (4) and (5), we now characterize the difference between \(}_{}(;P_{|,}})\) and its population counterpart \(_{}(;P_{|,}})\).

**Theorem 2.2**.: _Consider the loss function \((,)\) in Proposition 2.1, and let the cost function \(c(y,y^{})=(y y^{})\) for \(y,y^{}\), where \(\) is a positive constant. Assume that there exists a positive constant \(M\) such that \(((),y)[0,M]\) for all \(\), \(\), and \(\), and that \(((),y)\) is \(L\)-Lipschitz in the second argument with respect to the cost function \(c(,)\). Then, there exists a positive constant \(C_{1}\) such that for any given \(>0\), \(\), and \(0<<1\), with probability at least \(1-\):_

\[_{}(;P_{|,}})-}_{}(;P_{|,}})L^{p}}{^{p-1} }+M}.\]

Theorem 2.2 suggests that the empirical counterpart, \(}_{}(;P_{|,}})\), is a useful approximation for the risk function \(_{}(;P_{|,}})\), as their disparity is bounded and cannot grow indefinitely large. For a finite sample size \(n\), this disparity is upper bounded by a finite value depending on the characteristics of the cost and loss functions, as reflected by \(\), \(L\), and \(M\). As the sample size \(n\), the difference tends to zero with high probability, and specifically, the difference is of order \(O(n^{-1/2})\).

Next, we establish an informative bound for the empirical robust risk minimizer. For \(_{1},_{2}\) and for any given norm \(\|\|\), let \(\|_{1}-_{2}\|_{}_{}\|_ {1}()-_{2}()\|\). Here, \(\|\|\) can be taken as any specific norms, including the \(L^{q}\) norm with \(q 1\) that is defined in Section 1.

**Corollary 2.3** (Empirical Robust Minimizer).: _Let \(_{,n}_{}}_{ }(;P_{|,}})\). Under the assumptions in Theorem 2.2, if we further assume that the loss function \((,)\) is \(L^{}\)-Lipschitz in terms of the first argument with respect to the supremum metric \(\|\|_{}\), then there exists a positive constant \(C_{2}\) such that for any \(>0\) and \(0<<1\), with probability at least \(1-\), the empirical robust risk minimizer \(_{,n}\) satisfies:_

\[_{}(_{,n};P_{| ,}})_{}(_{,n};P_{|,}})\] \[_{}_{}(;P_{ |,}})+C_{2}\{}{ ^{p-1}}+L^{}_{0}^{})}ds \}}+2M},\]

_where \(N(s;,\|\|_{})\) denotes the \(s\)-covering number of \(\) with respect to the supremum metric._

## 3 Implementation Algorithm

In Section 3.1, we derive the analytical solution to the dual robust risk minimization problem in (5), which leads to the development of a novel approach for assigning pseudo-labels using the likelihood ratio test. These pseudo-labels facilitate the construction of a _pseudo-empirical distribution_, serving as a robust reference distribution in using (5). In Section 3.2, we derive the optimal value in \(\) for the empirical robust risk (5) and establish its closed-form expression. This analysis provides a principled framework for balancing the trade-off between robustness and model fitting and also motivates an efficient one-step update technique in solving the robust empirical risk minimization problem.

### Optimal Solution for Single Data Point

In this subsection, we determine the optimal value of \(()\) in (5) for a single data point \((,})\). To simplify the analysis, we first focus on the binary classification problem with \(=\{0,1\}\) and consider a broad family of loss functions of the form:

\[((),y)=(1-)(1-())+ (()),\] (7)

where \(()\) represents the conditional distribution \(P(=1|=)\) as described in Section 2.1, \(:\) is a bounded, decreasing, and twice differentiable function, and \(\) is a compact subset of \(\).

For any given \(\) and \(}^{R}\), let \(P_{j}(,}) P(=j|= ,}=})\) for \(j=0,1\). With the loss function in (7) and the metric \(c(,)\) considered in Theorem 2.2, minimizing (5) with respect to \(\) becomes:

\[_{}_{ 0}^{p}+P_{0}( ,})\{(1-()), (())-^{p}\}\] \[+P_{1}(,})\{(1- ())-^{p},(())\},\] (8)and let \(^{}\) denote the solution of (8). For \(\) and \(\) described in Theorem 2.2, let \(()^{p}/^{p}\). The following theorem shows that (8) has a closed-form solution, with its form varying based on whether \(\) is concave or convex.

**Theorem 3.1** (Optimal Action for Single Data Point: Binary Case).: _Let \(\) and \(}^{R}\) be given. Then, for a concave function \(\), the optimal solution for (8) is given by:_

\[^{}()= \{j,P_{j}(,})()+_{1}j=0,1;\\ 1/2,,.\]

_with \(_{1}=\{(0)-(1/2)\}/\{(0)-( 1)\}(0,1/2]\); and for a convex function \(\), the optimal solution of (8) is given by:_

\[^{}()= \{j,P_{j}(, })()+_{2}j=0,1,\\ t_{j}^{},()+1/2<P_{j}(,})<()+_{2}j=0,1,\\ 1/2,,.\]

_where \(_{2}=\{^{}(0)\}/\{^{}(0)+^ {}(1)\}[1/2,1)\), \(t_{0}^{}\) is the unique solution of \(\{P_{0}(,})-()\}^{ }(1-t)=\{P_{1}(,})+()\} ^{}(t)\) for \(t(0,)\), and \(t_{1}^{}\) is the unique solution of \(\{P_{0}(,})+()\}^{ }(1-t)=\{P_{1}(,})-()\} ^{}(t)\) for \(t(,1)\)._

**Remark 3.1**.: The optimal solution \(^{}()\) in Theorem 3.1 can also be expressed in a likelihood ratio format, which naturally leads to a novel algorithm for assigning _robust pseudo-labels_. Specifically, when \(\) is concave, the optimal solution can be expressed as: \(^{}()=0\) if \(P_{0}(,})/P_{1}(,}) C_{1}\); \(^{}()=1\) if \(P_{1}(,})/P_{0}(,}) C_{1}\); and \(^{}()=1/2\) otherwise, where \(C_{1}(()+_{1})/\{1-(()+_{ 1})\}>1\) serves as a threshold for the likelihood ratio test. Consequently, for a data point \((,})\), if \(P_{1}(,})/P_{0}(,}) C_{1}\), we assign a robust pseudo-label \(^{}=1\); if \(P_{0}(,})/P_{1}(,}) C_{1}\), we assign \(^{}=0\). Leveraging the likelihood ratio format also facilitates extending the robust pseudo-label selection method to the multi-class case by considering pairwise comparisons. Specifically, if \(P_{k^{}}(,})/_{j k^{}}P_{j}( ,}) C_{1}\), we assign the pseudo-label \(^{}=k^{}\) to the instance.

**Remark 3.2**.: Existing pseudo-labeling methods  typically identify the underlying true label as the one with the highest probability in the approximated true label posterior. In contrast, the proposed approach in Remark 3.1 considers both the highest and second-highest predicted probabilities. A pseudo-label is assigned only if the ratio of these probabilities exceeds a specified threshold. This strategy ensures that pseudo-labels are assigned to instances with high confidence, effectively filtering out uncertain data.

**Remark 3.3**.: In the special case where \(P_{j}(,})_{j}(} ;)P_{j}()\), with \(_{j}(};)=P^{}(} =}|=j,=)\) denoting the noisy label transition probability and \(P_{j}()\) representing a proper prior for \(=j\) conditional on \(\) for \(j=0,1\), previous studies have indicated the existence of a Chernoff information-type bound on the probability of error for robust pseudo-label selection, as described in Remark 3.1 . Specifically, for a fixed instance \(\), let a pseudo-label \(^{}\) be generated as described in Remark 3.1, which depends on \(\) and the corresponding noisy label vector \(}\). Consider the Bayes error, defined as \(_{}_{j=0,1}P_{j}()P^{}(^{ } j|=j,)\). According to Section 11.9 of , \(_{}\{-C(_{0}(;),_{1}(; ))\}\), where \(C(,)\) represents the Chernoff information between two distributions.

**Remark 3.4**.: In practice, one can use either uninformative priors, such as a uniform prior for each class, or informative priors derived from pre-trained or concurrently trained models for \(P_{j}()\) as discussed in Remark 3.3 . Moreover, the estimation of \(P_{j}(,})\) is not limited to Bayes's rule. For example,  proposed aggregating data and noisy label information by maximizing the \(f\)-mutual information gain.

**Remark 3.5**.: Theorem 3.1 is developed based on the assumption that the function \(\) is convex or concave. In our experiments, we use the cross-entropy loss for \(\), meaning \((t)=- t\) for \(t>0\). To meet the required conditions, we clip its input to \([0.01,1-0.01]\) to ensure \(()\) remains bounded.

Next, we extend the preceding development for binary classification to multi-class scenarios with \(K>2\). Letting \(()\) in (7) be specified as \((t)=1-t\), we extend loss function form (7) to facilitate the worst-case misclassification probability in multi-class scenarios: \(((),y)=_{j=1}^{K}(=j)\{1-()_{j}\}\). For ease of presentation, we sometimes omit the dependence on \(\) and \(}\) in the notation. Specifically, for \(j[K]\), we let \(P_{j} P_{j}(,}) P(=j| ,})\) and \(_{j}()_{j}\). In a manner similar to deriving (8), given \(\), minimizing (5) with respect to \(()\) can be expressed as:

\[_{}_{ 0}^{p}+ _{j=1}^{K}P_{j}\{1-_{1}-^{p},,1-_{j-1}- ^{p},\] \[1-_{j},1-_{j+1}-^{p},,1-_{K}- ^{p}\}.\] (9)

**Theorem 3.2** (Optimal Action for Single Data Point: Multi-class Case).: _Let \(\{P_{1},,P_{K}\}\) be arranged in decreasing order, denoted \(P^{(1)} P^{(K)}\), with the associated indexes denoted \((1),,(K)\). Let \(^{}\) denote the solution of the outer optimization problem in (9). For \(j[K]\), let \(^{(j)}\) denote the \((j)\)-th component of \(()\) corresponding to \(P^{(j)}\). Then, the elements of \(^{}\) are given as follows:_

1. _If_ \(_{j=1}^{k}P^{(j)}-()\) _for all_ \(k[K-1]\)_, then_ \(^{(j)}=\) _for all_ \(j[K]\)_._
2. _If there exists some_ \(k_{0}[K-1]\) _such that_ \(}_{j=1}^{k_{0}}P^{(j)}-}()> \)_, and_ \(}_{j=1}^{k_{0}}P^{(j)}-}() _{j=1}^{k}P^{(j)}-()\) _for all_ \(k[K-1]\)_, then_ \(^{(j)}=}\) _for_ \(j[k_{0}]\) _and_ \(^{(j)}=0\) _for_ \(j=k_{0}+1,,K\)_._

**Remark 3.6**.: The robust pseudo-labeling method described in Remark 3.1 can also be extended from Theorem 3.2. Specifically, by Theorem 3.2, if \(P^{(1)}\{+(),P^{(2)}+()\}\), then the optimal solution is: \(^{(1)}=1\) and \(^{(j)}=0\) for \(j=2,,K\), which can also be expressed in a likelihood ratio format and applied to assign robust pseudo-labels.

### Closed-Form Robust Risk

We investigate the empirical robust risk (5) by examining its closed form expression. For \(i[K]\) and \(j[K]\), we let \(P_{i,j} P_{j}(_{i},}_{i}) P (=j|=_{i},}=}_{i})\) and \(_{i,j}(_{i})_{j}\). For simplicity, we denote the Wasserstein robust loss in (5) and the nominal loss respectively as:

\[}_{}=_{ 0} ^{p}+_{i=1}^{n}_{j=1}^{K}P_{i,j} (_{i,1})-^{p},,(_{i,j- 1})-^{p}\] \[(_{i,j}),(_{i,j+1})-^{p },,(_{i,K})-^{p}}>0;\] (10) \[}=_{i=1}^{n}_{j=1}^{K}P_ {i,j}(_{i,j}).\] (11)

For given \(_{i}\), we sort \(\{_{i,1},,_{i,K}\}\) in decreasing order, denoted as \(_{i}^{(1)}_{i}^{(K)}\). Let \(_{i,j}(_{i}^{(K)})-(_{i,j})\) for \(i[n]\) and \(j[K]\), and sort \(\{_{i,j}:i[n],j[K]\}\) in decreasing order, denoted as \(^{(1)}^{(nK)}\). Correspondingly, the \(P_{i,j}\) values with the associated indexes are denoted as \(P^{(1)},,P^{(nK)}\). For any \(()\), define an associated positive integer \(s^{*}[nK+1]\) as follows: if \(P^{(1)}<()<_{i=1}^{nK}P^{(t)}\), then there exists \(s^{*}\{2,,nK\}\) such that \(_{t=1}^{s}P^{(t)}<()\) for \(s<s^{*}\), and \(_{t=1}^{s}P^{(t)}()\) for \(s s^{*}\); if \(()P^{(1)}\), then \(s^{*}\) is set as 1; if \(()_{t=1}^{nK}P^{(t)}\), then \(s^{*}\) is set as \(nK+1\).

Let \(_{}^{}\) denote the optimal value of \(\) in (10), where its dependence on \(\) is implicit, but its dependence on \(\) is explicit. The following theorem presents this value, based on which we demonstrate that the Wasserstein robust loss \(}_{}\) can be expressed as the nominal loss plus an additional term \(_{t=1}^{s^{*}-1}P^{(t)}^{(t)}(s^{*}>1)\) that prevents the classifier from becoming overly certain on the data.

**Theorem 3.3** (Closed-Form Robust Risk).: _The optimal value of \(\) in (10) is given by \(_{}^{}^{(s^{*})}/^{p}\), and the resulting robust risk is expressed as_

\[}_{}=}+_{t=1}^{s^{* }-1}P^{(t)}^{(t)}(s^{*}>1)+O()^{(s^{*})}.\]

**Remark 3.7**.: Theorem 3.3 shows that minimizing the Wasserstein robust loss \(}_{}\) in (10) effectively minimizes the nominal loss \(}\) in (11) while simultaneously penalizing terms associated with \(|_{i}|\) values exceeding a certain threshold \(|^{s^{*}}|\), weighted by the corresponding reference probability values. This minimization prevents the classifier from becoming overly confident in certain data points, particularly when there are potential misspecifications in the approximated true label posterior.

**Remark 3.8**.: As suggested by Remark 2.2, Theorem 3.3 provides a guideline for balancing robustness and model fitting by deriving the optimal value for \(\) in (10). In Section 3.3, we develop a one-step update method for determining \(_{}^{}\).

### Training using Conditional Distributionally Robust True Label Posterior

In this subsection, we outline the steps for approximating the true label posterior, constructing the pseudo-empirical distribution as the reference distribution for solving the robust risk minimization problem (5), and subsequently training classifiers robustly. The pseudo code for the training process is provided in Algorithm 1 in Appendix B.1. Here we elaborate on the details.

**Approximating noise transitions probabilities.** We begin by warming up the classifiers on the noisy training data, denoted \(}=\{_{i},_{i}\}_{i=1}^{n}\), where \(_{i}\) represents the majority vote label for instance \(_{i}\), determined by the label that receives the highest number of votes from the annotators. After warming up the classifiers for 20-30 epochs, we sort the dataset by the cross-entropy loss values and collect a subset of size \(m\) with the smallest \(m\) losses, denoted as \(_{0}^{}=\{_{i},_{i}\}_{i=1}^{m}\), where \(m n\), and the ratio of \(m\) to \(n\) is set to 1 minus the estimated noise rate. Next, we estimate the noise transition probabilities by \(_{j}(})=_{i=1}^{m}( }=}_{i},_{i}=j)/_{i=1}^{ m}(_{i}=j)\) for \(}[K]^{R}\) and \(j[K]\) (Line 1 of Algorithm 1). With \(_{j}(})\), we then iteratively update the approximated true label posterior, construct the pseudo-empirical distribution, and robustly train the classifiers (Lines 2-13 of Algorithm 1). Here, we employ the straightforward frequency-counting method for noise transition estimation for simplicity. However, our approach is versatile and can be integrated with various methods for estimating the noise transition matrices or the true label posterior. Additional experimental results using more advanced transition matrix estimation methods are provided in Appendix B.

**Constructing a pseudo-empirical distribution.** We train two classifiers, \(^{(1)}\) and \(^{(2)}\), in parallel each serving as an informative prior for the other. In the \(t\)th epoch, the approximated true label posterior with prior \(^{()}\) is updated as \(_{j}^{()}(,}) ^{()}(=j|}=},=)_{j}^{()}() _{j}(})\) (Line 4 of Algorithm 1), where \(_{j}^{()}()\) denotes the \(j\)th element of the vector-valued function \(^{()}()\) for \(j[K]\) and \(=1,2\). As described in Remark 3.1, for \(i[n]\), if \(_{k^{}}^{()}(_{i},}_{i}) /_{j k^{}}_{j}^{()}(,}) C\) for a pre-specified threshold \(C>1\), we assign the robust pseudo-label \(_{i}^{}=k^{}\) to the instance and collect it into \(_{t,}^{}\) (Lines 5-7 of Algorithm 1). The pseudo-empirical distribution \(P_{t,}^{}\) is updated based on \(_{t,}^{}\) (Line 8 of Algorithm 1).

**Robustly training the classifiers.** For \(=1,2\), let \(_{} 1\) if \(=2\); and \(_{} 2\) if \(=1\). With the updated pseudo-empirical distribution, the classifier \(^{()}\) is then trained by minimizing the empirical robust risk (5) with the reference distribution \(P_{t,_{}}^{}\) (Line 9 of Algorithm 1). After updating the classifier \(^{()}\) with \(_{t-1}^{()}\) from the previous iteration, we take one step to update the \(\) value \(_{t}^{()}\). In particular, as suggested by Theorem 3.3, we use \(_{0,t}=|^{(s^{*})}|/^{p}\) as a reference value for \(\) (Lines 11-12 f Algorithm 1). We then update \(_{t}^{()}\) by minimizing \([\{^{p}-_{P_{t,_{}}^{}c}p(y^{ },Y)\}+(-_{0})^{2}]\) (Line 13 of Algorithm 1) with respect to \(\), where \(y^{}\) is determined by (5) after updating \(^{()}\), and \(>0\) is a positive constant that determines the learning rate of \(\).

## 4 Experimental Results

**Datasets and model architectures.** We evaluate the performance of the proposed AdaptCDRP on two datasets, CIFAR-10 and CIFAR-100 , by generating synthetic noisy labels (details provided below), as well as four datasets, CIFAR-10N , CIFAR-100N , LabelMe [23; 24], and Animal-10N , which contain human annotations. For all datasets except LabelMe, we set aside 10% of the original data, together with the corresponding synthetic or human annotated noisy labels, to validate the model selection procedure. We use the ResNet-18 architecture  for CIFAR-10 andCIFAR-10N, and the ResNet-34 architecture  for CIFAR-100 and CIFAR-100N. Following , we employ a pretrained VGG-16 model with a 50% dropout rate for the LabelMe dataset. In line with , the VGG19-BN architecture  is used for the Animal-10N dataset. Further details on the datasets and experimental setup are provided in Appendix B.1.

**Noise generation.** We generate synthetic annotations on the CIFAR-10 and CIFAR-100 datasets using Algorithm 2 from . Three groups of annotators, labeled as IDN-LOW, IDN-MID, and IDN-HIGH, are considered, with average labeling error rates of approximately 20%, 35%, and 50%, respectively, representing low, intermediate, and high error rates. Each group consists of \(R=5\) annotators. To assess the algorithms in an incomplete labeling setting, we randomly select only one annotation per instance from the \(R\) annotators for the training dataset rather than using all available annotations . Further details on noise generation are provided in Appendix B.1.

**Comparison with SOTA methods.** We compare our method with a comprehensive set of state-of-the-art approaches, including: (1) CE (Clean) with clean labels; (2) CE (MV) with majority vote labels; (3) CE (EM) ; (4) Co-teaching ; (5) Co-teaching+ ; (6) CoDis ; (7) LogitClip ; (8) DoctorNet ; (9) MBEM ; (10) CrowdLayer ; (11) TraceReg ; (12) Max-MIG ; (13) CoNAL ; and (14) CCC . We report the average test accuracy over five repeated experiments, each with a different random seed, on synthetic datasets, CIFAR-10 and CIFAR-100, with instance-dependent label noise introduced at low, intermediate, and high error rates. Standard errors are shown following the plus/minus sign (\(\)), and the two highest accuraries are highlighted in bold. Table 2 presents evaluation results on four real-world datasets. As shown, our AdaptCDRP consistently outperforms competing methods across all scenarios. To further explore the impact of annotation sparsity, we conduct additional experiments with the number of annotators ranging from 5 to 100, with each instance labeled only once. Figure 1 illustrates the average accuracy across different numbers of annotators on CIFAR-10, highlighting the advantages of the proposed method under diverse settings. The results for the CIFAR-100 dataset are shown in Figure 3 in Appendix B.2.

**Hyper-parameter analysis.** We investigate the impact of the hyperparameter \(\) in the empirical robust risk (5). Under our experiment setup, \(\) should be chosen within \((0,1/K)\) for a \(K\)-class classification problem with \(K 2\) as demonstrated in the proof of Theorem 3.3 in Appendix A.8. Hence, we take \((0,0.1)\) for CIFAR-10 and \((0,0.01)\) for CIFAR-100, with the results presented in Figure 2. The results suggest that setting \(\) near zero leads to relatively low test accuracies, highlighting the importance of CDRO under model specification when handling noisy labels. Furthermore, continually increasing \(\) eventually results in a drop in accuracy due to excessive noise injection into the data.

**Additional experimental results.** To further evaluate the performance of the proposed method across various scenarios, we conducted additional experiments, detailed in Appendix B.2. Specifically, we compare different annotation aggregation methods, present average test accuracies and robust pseudo-label accuracies during training, assess sensitivity to the number of warm-up epochs, explore different noise transition estimation methods, and examine the impact of sparse annotation.

    &  &  \\   & IDN-LOW & IDN-MID & IDN-HIGH & IDN-LOW & IDN-MID & IDN-HIGH \\  CE (Clean) & \)} & \)} \\  CE (MV) & \(80.9_{ 0.88}\) & \(76.05_{ 0.70}\) & \(69.65_{ 1.73}\) & \(50.96_{ 0.49}\) & \(44.80_{ 0.99}\) & \(38.51_{ 0.66}\) \\ CE (EM)  & \(81.15_{ 0.74}\) & \(75.84_{ 0.97}\) & \(69.85_{ 1.43}\) & \(51.29_{ 1.00}\) & \(45.24_{ 0.41}\) & \(38.01_{ 0.90}\) \\ Co-teaching  & \(83.08_{ 0.52}\) & \(80.58_{ 0.36}\) & \(_{ 0.82}\) & \(53.10_{ 0.98}\) & \(47.25_{ 0.82}\) & \(44.11_{ 0.31}\) \\ Co-teaching+  & \(81.17_{ 0.55}\) & \(78.23_{ 0.43}\) & \(71.84_{ 1.13}\) & \(53.10_{ 0.64}\) & \(47.92_{ 0.76}\) & \(41.33_{ 0.81}\) \\ CoDis  & \(85.33_{ 0.39}\) & \(_{ 0.41}\) & \(78.67_{ 0.46}\) & \(_{ 0.44}\) & \(52.27_{ 0.64}\) & \(46.12_{ 0.66}\) \\ LogitClip  & \(_{ 0.35}\) & \(80.87_{ 0.42}\) & \(75.36_{ 0.79}\) & \(57.79_{ 0.77}\) & \(_{ 0.37}\) & \(_{ 0.35}\) \\ DoctorNet  & \(81.85_{ 0.41}\) & \(78.69_{ 0.75}\) & \(76.26_{ 1.28}\) & \(52.61_{ 0.70}\) & \(47.80_{ 0.86}\) & \(43.50_{ 0.53}\) \\ MBEM  & \(82.37_{ 0.77}\) & \(78.05_{ 0.83}\) & \(71.43_{ 2.43}\) & \(52.20_{ 0.27}\) & \(45.26_{ 0.50}\) & \(38.92_{ 0.69}\) \\ CrowdLayer  & \(83.98_{ 0.35}\) & \(77.76_{ 1.06}\) & \(67.77_{ 1.69}\) & \(51.28_{ 0.64}\) & \(45.28_{ 0.64}\) & \(38.93_{ 0.76}\) \\ TraceReg  & \(80.72_{ 0.79}\) & \(77.71_{ 1.36}\) & \(76.86_{ 1.77}\) & \(51.43_{ 0.61}\) & \(45.08_{ 0.57}\) & \(38.69_{ 1.01}\) \\ Max-MIG  & \(81.00_{ 0.72}\) & \(75.90_{ 0.52}\) & \(70.96_{ 0.96}\) & \(51.76_{ 1.11}\) & \(44.93_{ 0.71}\) & \(38.07_{ 0.49}\) \\ CoNAL  & \(81.60_{ 0.82}\) & \(76.02_{ 0.79}\) & \(69.50_{ 1.89}\) & \(51.61_{ 1.14}\) & \(44.19_{ 0.62}\) & \(38.24_{ 0.29}\) \\ CCC  & \(84.81_{ 0.89}\) & \(81.29_{ 0.66}\) & \(77.28_{ 1.05}\) & \(56.65_{ 0.55}\) & \(50.68_{ 0.40}\) & \(43.94_{ 0.95}\) \\  Ours (AdaptCDRP) & \(_{ 0.37}\) & \(_{ 0.29}\) & \(_{ 0.45}\) & \(_{ 0.15}\) & \(_{ 1.03}\) & \(_{ 0.99}\) \\   

Table 1: Average accuracies (with associated standard errors expressed after the \(\) signs) for learning the CIFAR-10 and CIFAR-100 datasets (\(R=5\)).

## 5 Conclusion

In this paper, we address the challenge of learning from noisy annotations by estimating true label posteriors using the CDRO framework. We formulate the problem as minimizing the worst-case risk within a distance-based ambiguity set, which constrains the conditional distributional uncertainty around a reference distribution. By deriving the dual form of the worst-case risk and finding the analytical solution to the robust risk minimization problem for each data point, we propose a novel approach for determining robust pseudo-labels using the likelihood ratio test. This approach further leads to the construction of a pseudo-empirical distribution that serves as a robust reference probability distribution in CDRO. We also derive a closed-form expression of the empirical robust risk and identify the optimal Lagrange multiplier for the dual problem. This leads to a guideline for balancing robustness and model fitting in a principled way and inspires an efficient one-step update method for the Lagrange multiplier.

Limitations and Extensions.Our development here does not focus on precisely estimating the noise transition matrix or the true label posterior. Further research may be conducted to address the sparse annotation problem and improve estimates of the true label posterior. This can be accomplished through several approaches: (1) employing regularization techniques to mitigate the impact of small sample sizes by smoothing estimates and reducing sensitivity to outliers; (2) leveraging subgroup structures among annotators to capture additional nuances; and (3) directly modeling the true label posterior by integrating both data and noisy label information, moving beyond the limitation of purely applying Bayes's rule.

   Method & CIFAR-10N CIFAR-100N & LabelMe & Animal-10N \\  CE (MV) & \(82.82_{ 0.05}\) & \(46.26_{ 0.81}\) & \(79.49_{ 0.48}\) & \(79.88_{ 0.38}\) \\ CE (EM)  & \(83.14_{ 0.80}\) & \(46.14_{ 0.69}\) & \(80.64_{ 0.55}\) & \(80.18_{ 0.34}\) \\ Co-teaching  & \(85.66_{ 0.54}\) & \(52.34_{ 0.31}\) & \(79.71_{ 0.55}\) & \(}\) \\ Co-teaching- & \(82.25_{ 0.21}\) & \(50.52_{ 0.40}\) & \(81.55_{ 0.92}\) & \(81.24_{ 0.22}\) \\ CoDis  & \(}\) & \(}\) & \(81.85_{ 0.49}\) & \(73.08_{ 0.35}\) \\ LogitClip  & \(86.37_{ 0.43}\) & \(51.50_{ 0.58}\) & \(81.75_{ 0.90}\) & \(70.89_{ 0.65}\) \\ DoctorNet  & \(84.52_{ 0.69}\) & \(46.21_{ 0.81}\) & \(79.09_{ 0.40}\) & \(79.96_{ 0.55}\) \\ MBEM  & \(85.49_{ 0.43}\) & \(46.74_{ 0.69}\) & \(80.10_{ 0.19}\) & \(79.69_{ 0.37}\) \\ CrowdLayer  & \(82.84_{ 0.24}\) & \(47.43_{ 0.59}\) & \(82.95_{ 0.21}\) & \(79.70_{ 0.35}\) \\ TraceReg  & \(82.94_{ 0.27}\) & \(47.71_{ 0.70}\) & \(83.10_{ 0.15}\) & \(80.34_{ 0.66}\) \\ Max-MIG  & \(85.12_{ 0.36}\) & \(46.56_{ 0.64}\) & \(}\) & \(79.78_{ 0.80}\) \\ CoNAL  & \(83.01_{ 0.21}\) & \(49.37_{ 0.48}\) & \(82.96_{ 0.30}\) & \(80.45_{ 0.49}\) \\ CCC  & \(86.45_{ 0.53}\) & \(48.57_{ 0.58}\) & \(83.18_{ 0.38}\) & \(78.36_{ 0.35}\) \\  Ours (AdaptCDRP) & \(_{ 0.34}\) & \(_{ 0.64}\) & \(_{ 0.68}\) & \(_{ 0.39}\) \\   

Table 2: Average accuracies (with associated standard errors expressed after the \(\) signs) for learning the CIFAR-10N, CIFAR-100N, LabelMe, and Animal-10N datasets.