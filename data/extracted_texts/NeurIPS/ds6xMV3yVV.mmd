# Nature-Inspired Local Propagation

Alessandro Betti

IMT School for Advanced Studies

Lucca, Italy

alessandro.betti@imtlucca.it

&Marco Gori

DIISM

University of Siena

Siena, Italy

marco.gori@unisi.it

###### Abstract

The spectacular results achieved in machine learning, including the recent advances in generative AI, rely on large data collections. On the opposite, intelligent processes in nature arises without the need for such collections, but simply by on-line processing of the environmental information. In particular, natural learning processes rely on mechanisms where data representation and learning are intertwined in such a way to respect spatiotemporal locality. This paper shows that such a feature arises from a pre-algorithmic view of learning that is inspired by related studies in Theoretical Physics. We show that the algorithmic interpretation of the derived "laws of learning", which takes the structure of Hamiltonian equations, reduces to Backpropagation when the speed of propagation goes to infinity. This opens the doors to machine learning studies based on full on-line information processing that are based on the replacement of Backpropagation with the proposed spatiotemporal local algorithm.

## 1 Introduction

By and large, the spectacular results of Machine Learning in nearly any application domain strongly rely on large data collections along with associated professional skills. Interestingly, the successful artificial schemes that we have been experimenting under this framework are far away from the solutions that Biology seems to have discovered. We have recently seen a remarkable effort in the scientific community to explore biologically inspired models (e.g. see ) where the crucial role of temporal information processing it is clearly identified.

While this paper is related to those investigations, it is based on more strict assumptions on environmental interactions that might stimulate efforts towards a more radical transformation of machine learning with emphasis on the temporal domain. In particular, we assume that learning and inference develop jointly under a nature based protocol of environmental interactions and then we suggest developing computational learning schemes regardless of biological solutions. Basically, the agent is not given the privilege of recording the temporal stream, but only to represent it properly by appropriate abstraction mechanisms. While the agent can obviously use its internal memory for storing those representations, we assume that it cannot access data collection. Instead, the agent can only rely on buffers of limited size to retain the information it acquires. From a cognitive perspective, these small buffers allow the agent to review recent inputs backward in time, implementing a form of selective attention.

We propose a pre-algorithmic framework which derives from the formulation of learning as an Optimal Control problem  and propose an approach to its solution that is also inspired by principles of Theoretical Physics. We formulate the continuous learning problem to emphasize how optimization theory brings out solutions based on differential equations that recall similar laws in nature. The discrete counterpart [2, p. 2], which is more similar to recurrent neural network algorithms that are found in the literature, can be derived as a numerical method and applied inpractical scenarios like lifelong learning with long video streams , where an Euler method for the differential equations can serve as an "optimizer" for RNN weights. Interestingly, we demonstrate that the online computation described in this paper achieves spatiotemporal locality, thereby contributing to the longstanding debate on the biological plausibility of Backpropagation [8; 33; 21]. Specifically, we address the _update locking problem_ and the issue of infinitely fast signal propagation in neural networks. Finally, the paper shows that the request of locality opens up a fundamental problem, namely that of approximating the solution of Hamilton's equations with boundary conditions using only initial conditions. A few insights on the solution of this problem are given for the task of tracking in optimal control, which opens the doors of a massive investigation of the proposed approach.

## 2 Recurrent Neural Networks and spatiotemporal locality

We put ourselves in the general case where the computational model that we are considering is based on a digraph \(D=(V,A)\) where \(V=\{1,2,,n\}\) is the set of vertices and and \(A\) is the set of directed arches that defines the structure of the graph. Let \((i)\) denote the set of vertices that are children of vertex \(i\) and with \((i)\) the set of vertices that are parents of vertex \(i\) for any given \(i V\). More precisely we are interested in the computation of neuron outputs over a temporal horizon \([0,T]\). Formally, this involves assigning each vertex \(i V\) a trajectory \(t x_{i}(t)\) of outputs that is computed based on the outputs of other neurons and environmental information. The environmental information is mathematically represented by a trajectory1\(u[0,+)^{d}\). We will assume that the output of the first \(d\) neurons (i.e the value of \(x_{i}\) for \(i=1,,d\)) matches the value of the components of the input: \(x_{i}(t)=u_{i}(t)\) for \(i=1, d\) and \( t[0,T]\). In order to consistently interpret the first \(d\) neurons as input we require two additional property of the graph structure:

\[(i)= i=1,,d; \] \[(\{d+1,,n\})\{1,,d\}. \]

Here (1) says that an input neuron do not have parents, and it also implies that no self loops are allowed for the input neurons. On the other hand (2) means that all input neurons are connected to at least one other neuron amongst \(\{d+1,,n\}\).

We will denote with \(x(t)\) (without a subscript) the ordered list of all the output of the neurons at time \(t\) except for the input neurons, \(x(t):=(x_{d+1}(t),,x_{n}(t))\), and with this definition we can represent \(x(t)\) for any \(t[0,T]\) as a vector in the euclidean space \(^{n-d}\). This vector is usually called the _state_ of the network since its knowledge gives you the precise value of each neuron in the net. The parameters of the model are instead associated to the arcs of the graph via the map \((j,i) A w_{ij}\) where \(w_{ij}\) assumes values on \(\). We will denote with \(w_{i*}(t)^{|(i)|}\) the vector composed of all the weights corresponding to arches of the form \((j,i)\). If we let \(N:=_{i=1}^{n}|(i)|\) the total number of weights of the model we also define \(^{N}(t):=(w_{1*}(t),,w_{n*}(t))\) the concatenation of all the weights of the network. Finally we will assume that the output of the model is computed in terms of a subset of the neurons. More precisely we will assume that, given a vector of \(m\) indices \((i_{1},,i_{m})\) with \(i_{k}\{d+1,,n\}\), at each temporal instant the output of the net is a function \(^{m}^{h}\) of \((x_{i_{1}},,x_{i_{m}})\). For future convenience we will denote \(O=\{i_{1},,i_{m}\}\).

Temporal locality and causalityIn general we are interested in computational schemes which are both local in time and causal. Let us assume that we are working at some fixed temporal resolution \(\), meaning that we can define a partition of the half line \((0,+)\), \(:=\{0=t_{}^{0}<t_{}^{1}<<t_{}^{n}<\}\) with \(t_{}^{n}=t_{}^{n-1}+\), then the input signal becomes a sequence of vectors \((U_{}^{+})_{n=0}^{+}\) with \(U_{}^{n}:=u(t_{}^{n})\) and the neural outputs and parameters can be regarded as an approximation of the trajectories \(x\) and \(\): \(X_{}^{n} x(t_{}^{n})\) and \(W_{}^{n}(t_{}^{n})\), \(n=1,[T/]\). A local computational rule for the neural outputs means that \(X_{}^{n}\) is a function of \(X_{}^{n-l},,X_{}^{n},,X_{}^{n+l}\), \(W_{}^{n-l},,W_{}^{n},,W_{}^{n+l}\) and \(t_{}^{n-l},,t_{}^{n},,t_{}^{n+l}\), where \(l T/\) can be thought as the order of locality. If we assume that \(l 1\) (first order method) then

\[X_{}^{n}=F(X_{}^{n-1},X_{}^{n},X_{}^{n+1},W_{}^{n-1},W_{ }^{n},W_{}^{n+1},t_{}^{n-1},t_{}^{n},t_{}^{n+1}). \]

Causality instead expresses the fact that only past information can influence the current state of the variables meaning that actually (3) should be replaced by \(X_{}^{n}=F(X_{}^{n-1},W_{}^{n-1},t_{}^{n-1})\). Returning to the continuous description, this equation can be interpreted as a discretization of a Cauchy problem for

\[=f(x,,t), \]

with assigned initial conditions on \(x(0)\). Note that the ability to determine the solution by evolving the state from a specified initial value is fundamentally due to our causality requirement.

Spatial localityFurthermore we assume that such computational scheme is local in time and make use only on spatially local (with respect to the structure of the graph) quantities as follows:

\[x_{i}(t)=u_{i}(t)&i=1, d  t[0,T];\\ c_{i}^{-1}_{i}(t)=^{i}(x_{i}(t),^{i}(x(t)),^{i}( (t)))&i=d+1,,n t[0,T].  \]

Here \(c_{i}>0\) for all \(i=d+1,,n\) sets the velocity constant that controls the updates of the \(i\)-th neuron, \(^{i}^{|(i)|}^{|(i)|}\) for all \(i=d+1,,n\) performs the mapping \((r,,)^{i}(r,,)\) for all \(r\), \(,^{|(i)|}\), \(^{i}^{n-d}^{|(i)|}\) project the vector \(^{n-d}^{i}()\) on the subspace generated by neurons which are in \((i)\) and \(^{i}^{N}^{|(i)|}\) maps the any vector \(^{N}^{i}()\) onto the space spanned by only the weights associated to arcs that points to neuron \(i\). The assumptions summarized above describe the basic properties of a RNN or, as sometimes is referred to when dealing with a continuous time computation, a Continuous Time RNN . The typical form of function \(_{i}\), is the following

\[^{i}(r,,)=-r+(), r,^{|(i)|}. \]

where in this case \(\,\,\) is the standard scalar product on \(^{|(i)|}\) and \(\) is a nonlinear bounded smooth function (usually a sigmoid-like activation function). Under this assumption the state equation in (5) becomes

\[c_{i}^{-1}_{i}(t)=-x_{i}(t)+(^{i}((t)) ^{i}(x(t)))-x_{i}(t)+_{j {pa}(i)}w_{ij}x_{j}(t), \]

which is indeed the classical neural computation. Here we sketch a result on the Bounded Input Bounded Output (BIBO) stability of this class of recurrent neural network which is also important for the learning process that will be described later.

**Proposition 1**.: _The recurrent neural network defined by ODE (7) is (BIBO) stable._

Proof.: See Appendix D 

## 3 Learning as a Variational Problem

In the computational model described in Section 2, once the graph \(D\) and an input \(u\) are assigned, the dynamics of the model is determined solely by the functions that describes the changes of the weights over time. Inspired by the Cognitive Action Principle  that formulate learning for FNN in terms of a variational problem, we claim that in an online setting the laws of learning for recurrent architectures can also be characterized by minimality of a class of functional. In what follows we will then consider variational problems for a functional of the form

\[F()=_{0}^{T}|}|^{2}+ c((t),x(t;),t)(t)\,dt, \]

where \(x(,)\) is the solution of (4) with fixed initial conditions2, \([0,T]\) is a strictly positive smooth function that weights the integrand, \(m>0\), \(^{n}^{N}[0,T]}_ {+}\) is a positive function and finally \(c:=_{i=d+1}^{n}c_{i}/(n-d)\). We discuss the requirements for making the stationarity conditions of this class of functional both temporally and spatially local and how they can be interpreted as learning rules.

### Optimal Control Approach

The problem of minimizing the functional in (8) can be solved by making use of the formalism of Optimal Control. The first step is to put this problem in the canonical form by introducing an additional control variable as follow

\[G()=_{0}^{T}\!\![||^{2}+c((t;), x(t;),t)]\!(t)\,dt, \]

where \((t;)\) and \(x(t;)\) solve

\[(t)=f(x(t),(t),t),}(t)=(t). \]

Then, the minimality conditions can be expressed in terms of the Hamiltonian function (see Appendix A), that is defined for every \(^{N}\), \(^{n}\), \(p^{N}\), \(q^{n}\) and \(t[0,T]\) as:

\[H(,,p,q,t)=-}{2mc}+c(,,t)(t)+p f(,,t), \]

via the following general result.

**Theorem 1** (Hamilton equations).: _Let \(H\) be as in (11) and assume that \(x(0)=x^{0}\) and \((0)=^{0}\) are given. Then a minimum of the functional in (9) satisfies the Hamilton equations:_

\[(t)=f(x(t),(t),t)\\ }(t)=-p_{}(t)/(mc(t))\\ _{x}(t)=-p_{x}(t) f_{}(x(t),(t),t)-c_{}((t), x(t),t)(t)\\ _{}(t)=-p_{x}(t) f_{}(x(t),(t),t)-c_{}((t),x(t),t)(t) \]

_together with the boundary conditions_

\[p_{x}(T)=p_{}(T)=0. \]

Proof.: See Appendix A. 

### Recovering spatio-temporal locality

Starting from the general expressions for the stationarity conditions expressed by (12) and (13), we will now discuss how the temporal and spatial locality assumptions that we made on our computational model in Section 2 leads to spatial and temporal locality of the update rules of the parameters \(\).

Temporal LocalityThe local structure of (10), that comes from the locality of the computational model that we discussed in Section 2 guarantees the locality of Hamilton's equations 12. However the functional in (9) has a global nature (it is an integral over the whole temporal interval) and the differential term \(m||^{2}/2\) links the value of the parameters across near temporal instant giving rise to boundary conditions in (13). This also means that, strictly speaking (12) and (13) overall define a problem that is non-local in time. We will devote the entire Section 4 to discuss this central issue.

Spatial LocalityThe spatial locality of (12) directly comes from the specific form of the dynamical system in (5) and from a set of assumptions on the form of the term \(\). In particular we have the following result:

**Theorem 2**.: _Let \((,,s)=kV(,s)+L(,s)\) for every \((,,s)^{N}^{n-d}[0,T]\), where \(V^{N}[0,T]_{+}\) is a regularization term on the weights3 and \(L^{n-d}[0,T]_{+}\) depends only on the subset of neurons from which we assume the output of the model is computed, that is \(L_{_{i}}(,s)=L_{_{i}}(,s)1_{O}(i)\), where \(1_{O}\) is the indicator function of the set of the output neurons. Let \(^{i}\) be as in (6) for all \(i=d+1,,n\), then the generic Hamilton's equations described in (12) become_

\[c_{i}^{-1}_{i}=-x_{i}+\!_{j(i)}w_{ij}x_{j}\\ _{ij}=-p_{}^{ij}/(mc)\\ _{x}^{i}=c_{i}p_{x}^{i}-_{k(i)}c_{k}^{} \!_{j(k)}w_{kj}x_{j}p_{x}^{k}w_{ki}-cL_{_{i }}(x,t)\\ _{}^{ij}(t)=-c_{i}p_{x}^{i}^{}\!_{m (i)}w_{im}x_{m}x_{j}-ckV_{_{ij}}(,t)  \]Proof.: See Appendix B. 

_Remark 1_.: Notice (14) directly inherit the spatially local structure from the assumption in (5).

Theorem 2 other than giving us spatio-temporal rules show that the computation of the \(p_{x}\) has a very distinctive and familiar property: for each neuron the values of \(p_{x}^{i}\) are computed using quantities defined on children's nodes as it happens for the computations of the gradients in the Backpropagation algorithm for a FNN. In order to better understand Eq. (14) let us define an appropriately normalized costate

\[_{x}^{i}(t):=(a_{i}(t))}{(t)}p_{x}^{i}(t),  a_{i}(t)=_{m(i)}w_{im}x_{m}  i=d+1,,n, \]

where we have introduced the notation \(a_{i}(t)\) to stand for the activation of neuron \(i\).4 With these definitions we are ready to state the following result

**Proposition 2**.: _The differential system in (14) is equivalent to the following system of ODE of mixed orders:_

\[c_{i}^{-1}_{i}=-x_{i}+(a_{i});\\ _{ij}=-}{}_{ij}+}{mc}_{x} ^{i}x_{j}+V_{_{ij}}(,t);\\ _{x}^{i}=[-}{}+(^{ }(a_{i}))+c_{i}]_{x}^{i}-^{}(a_{i})_{k (i)}c_{k}_{x}^{k}w_{ki}-cL_{_{i}}(x,t)^{ }(a_{i}), \]

_where \(_{x}^{i}\) is defined as in (15)._

Proof.: See Appendix C. 

This in an interesting result especially since via the following corollary gives a direct link between the rescaled costates \(_{x}\) and the delta error of Backprop:

**Corollary 1** (Reduction to Backprop).: _Let \(c_{i}\) be the same for all \(i=1,,n\) so that now \(c_{i}=c\), then the formal limit of the \(_{x}\) equation in the system 16 as \(c\) is_

\[_{x}^{i}=^{}(a_{i})_{k(i)}_{ x}^{k}w_{ki}+L_{_{i}}(x,t)^{}(a_{i}). \]

Proof.: Dividing both sides of the equation for \(_{x}^{i}\) in Eq. (16) by \(c\) we get:

\[_{x}}{c}=-}{}+ {d}{dt}(^{}(a_{i}))_{x}^{i}+_{x}^{i}- ^{}(a_{i})_{k(i)}_{x}^{k}w_{ki}-L_ {_{i}}(x,t)^{}(a_{i}).\]

As \(c\), the terms proportional to \(1/c\) vanish, leaving us exactly with Eq. (17). 

Notice that Eq. (17) is exactly the update equation for delta errors in backpropagation: when \(i\) is an output neuron the value of \(\) is directly given by the gradient of the error, otherwise it is express as a sum on its children (see ).

## 4 From boundary to Cauchy's conditions

While discussing temporal locality in Section 3, we came across the problem of the left boundary conditions on the costate variables. We already noticed that these constraints spoil the locality of the differential equations that describe the minimality conditions of the variational problem at hand. In general, this prevents us from computing such solutions with a forward/causal scheme.

The following examples should suffice to explain that, in general, this is a crucial issue and should serve as motivation for the further investigation we propose in the present section.

**Example 1**.: Consider a case in which \((,,s) V(,s)\), i.e. we want to study the minimization problem for \(_{0}^{T}(m|(t)|^{2}/2+V((t;),t))(t)dt\) under the constraint \(}=\). Then the dynamical equation \((t)=f(x(t),(t))\) does not represent a constraint on variational problems for functional in (9). If we look at the Hamilton equation for \(_{x}\) in (12) this reduces to \(_{x}=-p_{x} f_{}\). We would however expect \(p_{x}(t) 0\) for all \(t[0,T]\). Indeed this is the solution that we would find if we pair \(_{x}=-p_{x} f_{}\) with its boundary condition \(p_{x}(T)=0\) in (13). Notice that in general without this condition a random Cauchy initialization of this equation would not give null solution for the \(p_{x}\). Now assume that \(=( t)\) with \(>0\), and \(m=1\). Assume, furthermore5 that \(V(,s)=||^{2}/2\). The functional \(_{0}^{T}(||/2+|w|^{2}/2)e^{ t}dt\) defined over the functional space6\(H^{1}([0,T];^{N})\) is coercive and lower-semicontinuous, and hence admits a minimum (see ). Furthermore one can prove (see ) that such minimum is actually \(C^{}([0,T];^{N})\). This allows us to describe such minimum with the Hamilton equations described in (12). In particular as we already commented the relevant equations are only that for \(}\) and \(_{}\) that is \(}(t)=-p_{}(t)e^{- t}\) and \(_{}(t)=-e^{ t}\) with \(p_{}(T)=0\). This first order system of equations is equivalent to the second order differential equation \(}(t)+}(t)-(t)=0\). Each component of this second order system will, in general have an unstable behaviour since one of the eigenvalues is always real and positive. This is a strong indication that when solving Hamilton's equations with an initial condition on \(p_{}\) we will end up with a solution that is far from the minimum.

In the next subsection, we will analyze this issue in more detail and present some alternative ideas that can be used to leverage Hamilton's equations for finding causal online solutions.

### Time Reversal of the Costate

In Example 1 we discussed how the forward solution of Hamilton's (12) with initial conditions both on the state and on the costate in general cannot be related to any form of minimality of the cost function in (9) and this has to do with the fact that the proper minima are characterized also by left boundary conditions 13. The final conditions on \(_{x}\) and \(_{}\) suggest that the costate equations should be solved backward in time. Starting from the final temporal horizon and going backward in time is also the idea behind dynamic programming, which is of the main ideas at the very core of optimal control theory.

Autonomous systems of ODE with terminal boundary conditions can be solved "backwards" by time reversal [9, p. 597] operation \(t-t\) and transforming terminal into initial conditions. More precisely the following classical result holds:

**Proposition 3**.: _Let \((s)=(y(t))\) be a system of ODEs on \([0,T]\) with terminal conditions \(y(T)=y^{T}\) and let \(\) be the time reversal transformation maps \(t s=T-t\), then \((s):=y(^{-1}(s))=y(t)\) satisfies \(}(s)=-((s))\) with initial condition \((0)=y^{T}\)._

Clearly (12) or (16) are not an autonomous system and hence we cannot apply directly Proposition 3 nonetheless, we can still consider the following modification of (14)

\[c_{i}^{-1}_{i}=-x_{i}+_{j( i)}w_{ij}x_{j}\\ _{ij}=-p_{}^{ij}/(mc)\\ _{x}^{i}=-c_{i}p_{x}^{i}+_{k(i)}c_{k}^{} _{j(k)}w_{kj}x_{j}p_{x}^{k}w_{ki}+cL_{_{i} }(x,t)\\ _{}^{ij}(t)=c_{i}p_{x}^{i}^{}_{m(i)}w_{im}x_{m}x_{j}+ckV_{_{ij}}(,t) \]

which are obtained from (14) by changing the sign to \(_{x}\) and \(_{}\). Recalling the definition of the rescaled costates in (15) we can cast, in the same spirit of Proposition 2 a system of equations without \(p_{}\). In particular we have as a corollary of Proposition 2 that

**Corollary 2**.: _The ODE system in (18) is equivalent to_

\[c_{i}^{-1}_{i}=-x_{i}+(a_{i});\\ _{ij}=-}{}_{ij}-}{mc}_{x}^ {i}x_{j}-V_{_{ij}}(,t);\\ _{x}^{i}=[-}{}+(^{ }(a_{i}))-c_{i}]_{x}^{i}+^{}(a_{i})_{k (i)}c_{k}_{x}^{k}w_{ki}+cL_{_{i}}(x,t)^{ }(a_{i}), \]

Proof.: Let us consider (16). The change of sign of \(_{}\) only affect the signs of \(_{x}^{i}x_{j}\) and \(V_{_{ij}}(,t)\) in the \(_{ij}\) equation, while the change of sign of \(_{x}\) result in a sign change of the term \(c_{i}_{x}^{i}\), \(^{}(a_{i})_{k(i)}c_{k}_{x}^{k}w_{ki}\) and \(L_{_{i}}(x,t)^{}(a_{i})\) in the equation for \(_{i}^{x}\). 

Equation 19 is indeed particularly interesting because it offers an interpretation of the dynamics of the weights \(w\) that is in the spirit of a gradient-base optimization method. In particular this allow us the extend the result that we gave in Corollary 1 to a full statement on the resulting optimization method:

**Proposition 4** (GD with momentum).: _Let \(c_{i}\) be the same for all \(i=1,,n\) so that now \(c_{i}=c\), and let \((t)=( t)\) with \(>0\) then the formal limit of the system in (19) as \(c\) is_

\[x_{i}=(a_{i});\\ _{ij}=-_{ij}-_{x}^{i}x_{j}-(k/m)V_{_{ij}}(,t);\\ _{x}^{i}=^{}(a_{i})_{k(i)}_ {x}^{k}w_{ki}+L_{_{i}}(x,t)^{}(a_{i}). \]

_Remark 2_.: This result shows that at least in the case of infinite speed of propagation of the signal across the network (\(c\)) the dynamics of the weights prescribed by Hamilton's equation with the costate dynamics that is reversed (the sign of \(_{x}\) and \(_{}\) is changed) results in a gradient flow dynamic (heavy-ball dynamics) that it is interpretable as a gradient descent with momentum in the discrete. This is true since the term \(_{x}^{i}x_{j}\) in this limit is exactly the Backprop factorization of the gradient of the term \(L\) with respect to the weights.

In view of this remark we can therefore conjecture that also for \(c\) fixed:

**Conjecture 1**.: _Equation 19 is a local optimization scheme for the loss term \(\)._

Such result would enable us to use (19) with initial Cauchy conditions as desired.

### Continuous Time Reversal of State and Costate

Now we show that another possible approach to the problem of solving Hamilton's equation with Cauchy's conditions is to perform _simultaneous time-reversal_ of both state and costate equation. Since in this case the sign flip involves both the Hamiltonian equations the approach is referred to as _Hamiltonian Sign Flip_ (HSF). In order to introduce the idea let us begin with the following example.

**Example 2** (Lq control).: Let us consider a linear quadratic scalar problem where the functional in (9) is \(G(v)=_{0}^{T}qx^{2}/2+rv^{2}/2\,dt\) and \(=ax+bv\) with \(q\), \(r\) positive and \(a\) and \(b\) real parameters. The associated Hamilton's equations in this case are

\[=ax-sp,=-qx-ap, \]

where \(s-b^{2}/r\). These equation can be solved with the ansatz \(p(t)=(t)x(t)\), where \(\) is some unknown parameter. Differentiating this expression with respect to time we obtain

\[=(-)/x, \]

and using the (21) into this expression we find \(-s^{2}-2a-q=0\) which is known as _Riccati equation_, and since \(p(T)=0\), because of boundary (13) this implies \((T)=0\). Again if instead we try to solve this equation with initial condition we end up with an unstable solution. However \(\) solves an autonomous ODE with final condition, hence by Proposition 3 we can solve it with \(0\) initial conditions as long as we change the sign of \(\). Indeed the equation \(+s^{2}+2a+q=0\) is asymptotically stable and returns the correct solution of the Riccati algebraic equation. Now the crucial observation is that, as we can see from (22), the sign flip of \(\) is equivalent to the _simultaneous_ sign flip of \(\) and \(\).

In Example 2, as we observe from (22), the sign flip of \(\) is equivalent to the _simultaneous_ sign flip of \(\) and \(\). Inspired by the fact, let us associate the general Hamilton's equation ((12)), to this system the Cauchy problem

\[(t)\\ }(t)\\ _{}(t)\\ _{}(t)=s(t)f(x(t),(t),t)\\ -p_{}(t)/(mc(t))\\ -p_{x}(t) f_{}(x(t),(t),t)-c_{}((t),x(t),t)(t)\\ -p_{x}(t) f_{}(x(t),(t),t)-c_{}((t),x (t),t)(t) \]

where for all \(t[0,T]\), \(s(t)\{0,1\}\). Here we propose two different strategies that extends the sign flip discussed for the LQ problem.

Hamiltonian TrackThe basic idea is enforce system stabilization by choosing \(s(t)\) to bound both the Hamiltonian variables. This leads to define a _Hamiltonian track_:

**Definition 1**.: Let \(S(,,p,q)(^{n-d}^{N})^{2}\) for every \((,,p,q)(^{n-d}^{N})^{2}\) be a bounded connected set and let \(t X(t)\) any continuous trajectory in the space \((^{n-d}^{N})^{2}\), then we refer to

\[\{(t,S(X(t)):t[0,T]\}[0,T](^{n-d}^{N})^{2}\]

as _Hamiltonian track (HT)_.

Then we define \(s(t)\) as follow

\[s(t)=1&(x(t),(t),p_{x}(t),p_{}(t)) S((x( t),(t),p_{x}(t),p_{}(t)))\\ -1&. \]

For instance if we choose \(S(,,p,q)=\{(,,p,q):||^{2}+||^{2}+|p| ^{2}+|q|^{2} R\}\) we are constraining the dynamics of (23) to be bounded since each time the trajectory \(t(x(t),(t),p_{x}(t),p_{}(t))\) moves outside of a ball of radius \(R\) we are reversing the dynamics by enforcing stability.

Hamiltonian Sign Flip Strategy and time reversalWe can easily see that the sign flip driven by the policy of enforcing the system dynamics into the HT corresponds with time reversal of the trajectory, which can nicely be interpreted as focus of attention mechanism. A simple approximation of the movement into the HT is that of selecting \(s(t)=((t))\), where \(=2\) is an appropriate _flipping frequency_ which governs the movement into the HT. In the discrete setting of computation the strategy consists of flipping the right-side of Hamiltonian equations sign with a given period. In the extreme case the sign flip takes place at any Euler discretization step. Here we report the application of the _Hamiltonian Sign Flip_ strategy to the classic Linear Quadratic Tracking (LQT) problem by using a recurrent neural network based on a fully-connected digraph. The purpose of the reported experiments is to validate the HSF policy, which is in fact of crucial importance in order to exploit the power of the local propagation presented in the paper, since the proposed policy enables on-line processing.

The pre-algorithmic framework proposed in the paper, which is based on ODE can promptly give rise to algorithmic interpretations by numerical solutions. In the reported experiments we used Euler's discretization (see Appendix E for both architectural and algorithmic details).

_Sinusoidal signals: The effect of the accuracy parameter._ In this experiment we used a sinusoidal target and a recurrent neural network with five neurons, while the objective function was \(G(v)=_{0}^{T}q(x_{0}-z)^{2}/2+r|v|^{2}/2+r_{w}|w|^{2}\,dt\), where we also introduced a regularization term on the weights. Here, \(x_{0}\) denotes the neuron designated as the output (see Appendix E) and \(q\), \(r\) and \(r_{w}\) are positive parameters. The HSF policy gives rise to the expected approximation results. In Fig. 1-2 we can appreciate the effect of the increment of the accuracy term.

_Tracking under hard predictability conditions._ This experiment was conceived to assess the capabilities of the same small recurrent neural network with five neurons to track a signal which was purposely generated to be quite hard to predict. It is composed of patching intervals with cosine functions with constants.

The experimental analysis on this and related examples confirms effectiveness of the HSF policy shown in Fig. 3. Figure 4 shows the behavior of the Lagrangian and of the Hamiltonian term, with the latter providing insights into the energy exchange with the environment.

## 5 Related Work

Optimal control.Optimal control theory primarily studies minimality problems for dynamical systems [1; 6]. The two main complementary approaches to the problem are the Pontryagin Maximum Principle  and dynamic programming. Additionally, as a general minimization problem, both approaches significantly intersect with the calculus of variations . Optimal control for discrete problems is also a classic topic [2, p. 2].

Neural ODE.Recent works, such as  and subsequent studies [17; 24] have applied results from optimal control to develop learning algorithms based on differential equations. However, these approaches differ significantly from the continual online learning considered in this work, as the time variable in the class of ODEs they examine is not tied to the input signal that represents the flow of the learning environment.

Online.On the other hand several works propose to formulate the learning problems online and from a single stream of data [22; 34]. The classical approach to learn RNNs online is RTRL ; several approaches has been since proposed to reduce the high space/time complexities due to the progressive update of a Jacobian matrix . In our method no storing of Jacobian matrices happens, hence the proposed method is not a generalization/reformulation of RTRL not related approaches like .

Nature-inspired computations.The primary distinction of our approach in discussing the biological plausibility of backpropagation lies in our development of a theory grounded entirely in temporal analysis within the environment and the concept of learning over time. While several classical  and recent approaches [29; 25; 26; 14] share certain locality properties outlined here, they are primarily inspired by brain physiology. Similarly, most works that examine the biological plausibility of backpropagation [8; 33; 21] overlook the role of time in the sense that we present in this work. Here, we propose laws of neural propagation where connections are updated progressively over time, mirroring processes observed in nature.

## 6 Conclusions

This paper is motivated by the idea of a proposing learning scheme that, like in nature, arises without needing data collections, but simply by on-line processing of the environmental interactions. The paper gives two main contributions. First, it introduces a local spatiotemporal pre-algorithmic framework that is inspired to classic Hamiltonian equations. It is shown that the corresponding algorithmic formalization leads to the interpretation of Backpropagation as a limit case of the

Figure 1: Recurrent net with \(5\) neurons, \(q=100\) (accuracy term), \(r_{w}=1\) (weight regularization term), \(r=0.1\) (derivative of the weight term).

Figure 2: Recurrent net with \(5\) neurons, \(q=1000\) (accuracy term), \(r_{w}=1\) (weight regularization term), \(r=0.1\) (derivative of the weight term).

proposed diffusion process in case of infinite velocity. This sheds light on the longstanding discussion on the biological plausibility of Backpropagation, since the proposed computational scheme is local in both space and time. This strong result is indissolubly intertwined with a strong limitation. The theory enables such a locality under the assumption that the associated ordinary differential equations are solved as a boundary problem. The second result of the paper is that of proposing a method for approximating the solution of the Hamiltonian problem with boundary conditions by using Cauchy's initial conditions. In particular we show that we can stabilize the learning process by appropriate schemes of time reversal that are related to focus of attention mechanisms. We provide experimental evidence of the effect of the proposed Hamiltonian Sign Flip policy for problems of tracking in automatic control. While the proposed local propagation scheme is optimal in the temporal setting and overcomes the limitations of classic related learning algorithms like BPTT and RTRL, the given results show that there is no free lunch: The distinguishing feature of spatiotemporal locality needs to be sustained by appropriate movement policies into the Hamiltonian Track. We expect that other solutions better than the HSF policy herein proposed can be developed when dealing with real-word problems and may offer potential approaches to classic challenges in lifelong learning, such as forgetting, that remain open and are not fully addressed by the current framework. This paper must only be regarded as a theoretical contribution which offers a new pre-algorithmic view of neural propagation. While the provided experiments support the theory, the application to real-world problems need to activate substantial joint research efforts on different application domains.

#### Acknowledgments

We thank Stefano Melacci and Giovanni Bellettini for insightful discussions.