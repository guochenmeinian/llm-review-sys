# Differentiable Quantum Computing for

Large-scale Linear Control

Connor Clayton\({}^{*,1,2}\)

Jiaqi Leng\({}^{*,1,3,5}\)

Gengzhi Yang\({}^{*,1,3}\)

Yi-Ling Qiao\({}^{2,4}\)

Ming C. Lin\({}^{2,4}\)

Xiaodi Wu\({}^{,1,2}\)

\({}^{1}\)Joint Center for Quantum Information and Computer Science, University of Maryland

\({}^{2}\)Department of Computer Science, University of Maryland

\({}^{3}\)Department of Mathematics, University of Maryland

\({}^{4}\)Center for Machine Learning, University of Maryland

\({}^{5}\)Department of Mathematics and Simons Institute for the Theory of Computing, UC Berkeley

\({}^{*}\)Equal Contribution

\({}^{}\)xiaodiwu@umd.edu

###### Abstract

As industrial models and designs grow increasingly complex, the demand for optimal control of large-scale dynamical systems has significantly increased. However, traditional methods for optimal control incur significant overhead as problem dimensions grow. In this paper, we introduce an end-to-end quantum algorithm for linear-quadratic control with provable speedups. Our algorithm, based on a policy gradient method, incorporates a novel quantum subroutine for solving the matrix Lyapunov equation. Specifically, we build a _quantum-assisted differentiable simulator_ for efficient gradient estimation that is more accurate and robust than classical methods relying on stochastic approximation. Compared to the classical approaches, our method achieves a _super-quadratic_ speedup. To the best of our knowledge, this is the first end-to-end quantum application to linear control problems with provable quantum advantage.

## 1 Introduction

Over the past few decades, the growing complexity of modern engineering designs has made the control of large-scale dynamical systems a crucial task across various application fields, such as power grid management , swarm robotics , sensor networks , and airline scheduling . These challenges often involve high-dimensional solution spaces with tens of thousands of degrees of freedom, presenting a significant obstacle for traditional optimal control methods.

The emergence of quantum computing has expanded the potential for designing efficient algorithms in numerical optimization and machine learning . By leveraging the principles of quantum mechanics, such as superposition and entanglement, quantum computers excel at efficient data processing, making them promising for accelerating solutions to large-scale computational challenges .

Although there has been some progress in quantum algorithms for some specific optimal control problems arising in quantum sciences , a viable pathway for accelerating general large-scale optimal control problems remains unclear. A conventional approach to optimal control involves solving the Algebraic Riccati Equation (ARE, see Section 1.1 for details), which is a nonlinear matrix equation. This problem has been less explored in thefield of quantum computing for two reasons. First, most proposed quantum algorithms for algebraic and differential equations focus on linear and vector-valued problems, and extending them to nonlinear matrix equations is highly challenging. Second, while efficient quantum algorithms exist for certain weakly nonlinear problems , they are not powerful enough to handle the nonlinearity present in the Algebraic Riccati Equation. A breakthrough in this direction calls for novel ideas in algorithm design.

Inspired by the recent advances in differentiable physics  and reinforcement learning , we develop an end-to-end quantum algorithm that solves a fundamental optimal control problem called the linear-quadratic regulator (LQR). Given its widely applicable mathematical formulation, LQR has been extensively researched and serves as a standard case study for various computing and learning algorithms ; moreover, LQR is of significant practical relevance as many real-world optimal control problems can be formulated to address through linearization techniques. Our quantum algorithm is proven to output an \(\)-approximate optimal solution in time \(}(n^{-1.5})\)1, where \(n\) is the dimension of the state vector and \(\) is an error tolerance parameter. The algorithm involves two major components: a quantum differentiable simulator and a quantum-accessible classical data structure. This hybrid quantum-classical framework enables us to employ a _policy gradient_ method that exhibits a fast convergence rate for the LQR problem. Since almost all known classical methods for the LQR problem heavily rely on subroutines such as matrix factorization and matrix inversion , which require at least \((n^{3})\) overhead in the problem dimension \(n\), our new linear-time quantum algorithm, with _super-quadratic_ speedup, offers significant promise for large-scale applications.

Notation.We use \(\) and \(\) to denote the set of real and complex numbers, respectively. \(\) denotes an identity operator with an appropriate dimension. For two real vectors \(u,v^{n}\), the Euclidean inner product \( u,v=u^{T}v\), and the norm of a vector \(u\) is \(\|u\|=u}\). Given a symmetric/Hermitian matrix \(M\), we denote \(_{}(M)\) (or \(_{}(M)\)) as the maximal/minimal eigenvalue of \(M\). The spectral norm of a matrix \(M^{m n}\) is denoted by \(\|M\|=_{\|v\|=1}\|Mv\|\). The Frobenius norm of a matrix \(M^{m n}\) is denoted by \(\|M\|_{F}=_{i,j}|M_{i,j}|^{2}=M^{T}M\). We say \(\) if the random variable \(^{n}\) is distributed according to \(\).

### Problem Formulation

We focus on the infinite-horizon continuous-time linear-quadratic regulator (LQR) problem:

\[_{x,u}J =[_{0}^{}(x^{}(t)Qx(t)+u^{ }(t)Ru(t))t]\] (1a) \[=Ax+Bu,\ \ x(0),\] (1b)

where \(x(t)[0,]^{n}\) is the state vector, \(u(t)[0,]^{m}\) is the control input. \(A\) and \(B\) are constant matrices of appropriate dimensions; \(Q\) and \(R\) are positive definite matrices.

**Definition 1**.: For a square matrix \(M^{n n}\), we say \(M\) is _Hurwitz_ if every eigenvalue of \(M\) has a strictly negative real part.

**Definition 2**.: For a controllable pair \((A,B)\), the set of stabilizing feedback gains is given by

\[S_{K}\{K^{m n} A-BK\}.\] (2)

Given a controllable pair \((A,B)\), the optimal controller \(u(t)\) of problem (1) can be expressed as a linear function of the state vector \(x(t)\), namely

\[u(t)=-K^{*}x(t),\] (3)

where the matrix \(K^{*}\) is the optimal linear feedback gain. An analytical form of the optimal feedback gain is given by \(K^{*}=R^{-1}B^{}P^{*}\), where \(P^{*}\) is the unique positive solution to the Algebraic Riccati Equation (ARE),

\[A^{}P+PA+Q-PBR^{-1}B^{}P=0.\] (4)For large-scale control problems where the control input is much smaller than the state vector (i.e., \(m n\)), it is often desired to compute the optimal feedback gain matrix \(K^{*}\) without explicitly solving for \(P^{*}\). To this end, we can rewrite the LQR objective function \(J(x,u)\) as a function solely depending on \(K\) by leveraging the linearity of the optimal controller \(u(t)=-Kx(t)\). With standard algebraic manipulation, it turns out that

\[J(x,u)=f(K)=[P(K)_{0}]&K_{ K},\\ &,\] (5)

where

\[P(K)=_{0}^{}e^{(A-BK)^{}t}(Q+K^{}RK)e^{(A-BK)t} \ t,\] (6)

and \(_{0}_{}[^{}]\). Given this reformulation, the search for the optimal feedback gain \(K^{*}\) reduces to minimizing the unconstrained objective function \(f(K)\).

In practice, the matrices \(A,B,Q,R\) often possess sparsity structures that can be leveraged by quantum computers. We make the assumptions on the efficient quantum access model.

**Assumption 1** (Sparse-access matrices).: We assume \(A\), \(B\), \(Q\), and \(R\) are \(s\)-sparse, i.e., there are at most \(s\) non-zero entries in each row/column. For \(M\{A,B,Q,R\}\), we assume access to an efficient procedure2 that loads the matrix into quantum data:

\[|i|k|i|r_{i,k},||j |c_{,j}|j,|i|j|0 |i|j|M_{ij},\] (7)

where \(r_{i,k}\) is the index of the \(k\)-th non-zero entry of the \(i\)-th row of \(M\), \(c_{,j}\) is the index of the \(\)-th non-zero entry of the \(j\)-th column of \(M\), and \(M_{ij}\) is a fixed-length binary description of the \((i,j)\)-th entry of \(M\).

With quantum access to the problem data, we aim to determine the optimal linear feedback gain \(K^{*}\) so that the objective function \(f(K)\) is minimized, as summarized in the following problem statement:

**Problem 1**.: Assume \((A,B)\) is a controllable pair and \(Q\), \(R\) are positive-definite. Given quantum access to \(A,B,Q,R\) in the sense of Assumption 1, we want to compute an \(\)-approximate solution \(K\) such that \(\|K-K^{*}\|_{F}\), where \(>0\) is prefixed.

### Main Contributions

In this paper, we propose an end-to-end quantum algorithm for solving LQR problems that exhibits the desired quantum advantage in the large-scale setting (i.e., in the parameter regime \(m n\)). A detailed comparison between ours and various other methods is given in Table 1. Compared with state-of-the-art classical methods, our algorithm achieves a super-quadratic speedup in terms of the state vector dimension \(n\). To the best of our knowledge, this is the first end-to-end quantum application to linear control problems with provable speedup.

Our algorithm is based on a novel policy gradient strategy to find globally optimal solutions for linear-quadratic control problems. A brief overview of the policy gradient method for LQR is available in Section 3.2. In each iteration cycle, our algorithm executes a fast,

  
**Methods** & **Time/Gate Complexity** \\  Schur method  & \(}(n^{3})\) \\  Newton-Kleinman method  & \(}(n^{3})\) \\  (Model-based) policy gradient  & \(}(n^{3}(^{-1}))\) \\ 
**Ours** & \(}(n^{-1.5})\) (Theorem 7) \\   

Table 1: Asymptotic cost of different methods for LQR.

quantum-assisted differentiable simulator to obtain robust gradient estimates, as detailed in Theorem 31. The gradient estimates are then utilized by a classical computer to update the control policy \(K\).

As illustrated in Figure 1, with the back-and-forth iterations between the quantum simulator and a classical computer, the control policy \(K\) converges to the optimal policy \(K^{*}\) at a linear rate, leading to an end-to-end resolution of the LQR problem.

Our quantum algorithm design can be regarded as a novel realization of the hybrid quantum-classical computing paradigm, where collaboration between classical and quantum computers significantly reduces the burden on the quantum side. Moreover, we provide explicit constructions of the quantum simulator and analyze the convergence rate of the policy gradient based on our end-to-end model. These desirable attributes make our proposed design more practical and relevant in the early fault-tolerant era .

Notably, we propose a new quantum algorithm for solving the Lyapunov equation, a fundamental task in optimal control theory . Based on an integral representation of the solution and a rich toolbox of methods for quantum numerical linear algebra, our algorithm can produce a quantum representation of the solution matrix in a cost that is polylogarithmic in the matrix dimension \(n\) (see Theorem 4), leading to an _exponential speedup_ over existing classical methods . Moreover, since the matrix Lyapunov equation is fundamental to many control problems, we foresee that our quantum algorithm may play an important role in finding speedups for other tasks.

The fast quantum algorithm for the Lyapunov equation enables us to develop a quantum gradient estimation subroutine in near-optimal cost, as detailed in Theorem 31. Compared with the conventional gradient estimation techniques based on stochastic approximation (e.g., one- and two-point gradient estimators ), our quantum gradient estimation benefits from the explicit exploitation of the analytical form of the gradient. Numerical experiments suggest that our gradient estimation is robust and often leads to faster convergence in practice, as demonstrated in Section 5.3.

## 2 Related Work

We survey related work on model-based and model-free linear-quadratic control, differentiable physics, and quantum reinforcement learning in this section.

Model-based linear-quadratic control._Model-based_ optimal control  refers to the scenario where historical measurement data explicitly gives (or estimates) the problem description. In this case, the optimal linear feedback gain \(K^{*}\) can be computed by solving the algebraic Riccati equation (ARE), as detailed in Section 1.1. Commonly used numerical methods for ARE include factorization methods (e.g., Schur method ) and iterative methods (e.g., Newton-Kleinman method ). These methods require computing matrix factorization or matrix inverse, which in general leads to a \(O(n^{3})\) run time (assuming \(m n\)). Some methods for ARE can achieve \((n)\) runtime under strong assumptions such as the solution \(P^{*}\) is of low rank . It is also possible to solve LQR by reformulating it as a semidefinite programming (SDP) problem . We do not dive into the SPD approach as it does not demonstrate superior asymptotic scaling compared to other direct methods.

Model-free linear-quadratic control.LQR can be regarded as a continuous-time analog of the discrete Markov Decision Process (MDP) model and many techniques from reinforcement learning (RL) can be introduced to learn the optimal feedback gain (i.e., _control policy_), such as policy gradient , natural gradient , and policy iteration .

Figure 1: Differentiable quantum computing for linear control.

These RL-based methods are particularly useful when we have access to the observed costs but the system model can not be directly constructed.

Differentiable physics and quantum computing.The differentiable programming paradigm has been applied to many dynamical systems for learning  and control . Those gradient-based methods can be used in reinforcement learning , inverse problems , optimization , design , etc. People have developed differentiable pipelines for various dynamics including fluids , rigid body , soft body , and other hybrid systems . Recently,  have derived a differentiable analog quantum computing pipeline for quantum optimization and control. In this work, we will focus on using differentiable quantum computing to accelerate a widely studied classical problem - linear control synthesis.

Quantum reinforcement learning.Recently, quantum-accelerated reinforcement learning has attracted significant attention as it demonstrates the potential for computational speedup . It has been shown that quantum computers can be used to compute policy gradients given coherent access to a Markov Decision tree model . Some works also discuss the quantum policy iteration method for RL, see . It is worth noting that the existing works are usually based on a strong quantum access model and it remains unclear what the cost of constructing such models is in an _end-to-end_ sense.

## 3 Preliminaries

### Introduction to Quantum Computing

All quantum states of a quantum system form a Hilbert space, which is isomorphic to \(^{N}\). We may assume \(N=2^{n}\) and \(n\) is a non-negative integer. An element \(|\) in this Hilbert space is then noted as a \(N\)-dimensional quantum state, where

\[|=v_{0}\\ v_{1}\\ \\ v_{N-1},\] (8)

where \(v_{i},i\{0,1,,N-1\}\). Also, we often use \(|\) to denote the conjugate transpose of \(|\). For any \(c 0\), \(c|\) and \(|\) refer to the same state, thus without loss of generality, \(\||\|=1\) always holds. Specifically, a one qubit system corresponds to the aforementioned Hilbert space with \(n=1\).

Given \(m\) quantum states \(|_{1},|_{2},,|_{m}\) from \(m\) quantum systems, then

\[|=|_{1}|_{2}| _{m}\] (9)

is a quantum state in the space that consists \(m\) subspaces.

The evolution of a quantum state can be described by a unitary operator \(U\), meaning

\[U^{}U=UU^{}=I.\] (10)

We often note these operations as gates on the quantum circuit. One important type of unitary operators are the Pauli operators, namely

\[X=0&1\\ 1&0, Y=0&-i\\ i&0, Z=1&0\\ 0&-1.\] (11)

They form a basis of all the linear operators acting on \(^{2}\).

For the quantum measurement, given a quantum observable \(H\), we can do the measurement of a quantum state \(|\). Specifically, after the measurement on \(|\), the state collapses to \(|}{}}\), and we get an outcome \(_{m}\) with probability \(p_{m}=|P_{m}|\), where

\[H=_{m}_{m}P_{m}\] (12)

is the spectral decomposition of \(H\).

### Policy Gradient for LQR

For all stabilizing feedback gains \(K S_{K}\), the gradient of the objective function \(f(K)\) as defined in (5) has the following closed-form expression :

\[ f(K)=2(RK-B^{}P(K))X(K),\] (13)

where \(P(K)\) is given in (6), and \(X(K)\) is determined by

\[X(K)=_{0}^{}e^{(A-BK)t}_{0}e^{(A-BK)^{}t}\;t.\] (14)

The (direct) policy gradient method for LQR minimizes the objective \(f(K)\) via the vanilla gradient update rule \(K K-s f(K)\), where \(s>0\) is a fixed step size. Given sufficiently small \(s\), it has been shown that the policy gradient method converges at a linear rate [45, Theorem 2]. In practice, however, the policy gradient is often estimated through stochastic approximation, such as one- and two-point estimation . While these zeroth-order gradient estimation methods are less demanding in terms of computational cost, they tend to be sensitive to random perturbations and slow to converge.

In this paper, we propose a fast quantum algorithm that outputs a robust estimate of the gradient in \(}(n)\) time (assuming \(m n\), see Theorem 31). Leveraging the quantum gradient estimation subroutine, we recover the linear convergence rate using robust gradient descent, as detailed in Proposition 34.

### Quantum Data Structure

To perform policy gradient in the training process, the linear feedback gain \(K\) is stored in a _quantum-accessible data structure_ as proposed in . This data structure allows intermediate updates on \(K\) and efficient quantum queries to \(K\) as a block-encoded matrix. This data structure is a purely classical representation of \(K\), and quantum access to this data structure (e.g., through qRAM ) is required to build the block-encoding of \(K\). In the literature, this data structure is also known as _classical-write, quantum-read_ qRAM .

**Definition 3** (Block-encoding).: Suppose that \(M\) is an \(p\)-qubit operator, \(,^{+}\) and \(r\), then we say that the \((p+r)\)-qubit unitary \(U_{M}\) is an \((,r,)\)-block-encoding of \(M\), if

\[\|M-( 0|^{r})U_{M}(|0 ^{r})\|.\] (15)

In this paper, the growth of ancilla qubits (space complexity) is dominated by the number of elementary gates (gate complexity). Therefore, when referring to a specific block-encoding, we often omit the number of ancilla qubits (i.e., the parameter \(r\)) for simplicity.

**Lemma 1**.: _Let \(K^{m n}\). There exists a data structure to store \(K\) with the following properties: (1) the size of the data structure is \((mn^{2}(mn))\), (2) the time to store a new entry \((i,j,_{i,j})\) is \((^{2}(mn))\), and (3) for any \(>0\), a quantum algorithm can implement a \((\|K\|_{F},_{2}n+2,)\)-block-encoding of \(K\) in time \(((n,1/))\). There also exists an analogous data structure for \(^{}\)._

Proof.: We use the data structure as described in [30, Theorem 5.1]. To construct the block-encoding, we utilize [22, Lemma 50]. 

### Quantum Simulation of Linear Dynamics

Quantum computers can simulate certain linear ordinary differential equations (ODEs) exponentially faster than classical computers . In this paper, we present a quantum simulation subroutine based on quantum linear system solvers (QLSS) , as described below. While this approach may not be optimal in terms of state preparation cost compared to quantum singular value transformation  or linear combination of Hamiltonian simulation , it allows us to incorporate the Hurwitz stability of the system.

**Theorem 2** (Informal version of Theorem 17).: _Suppose that \(^{n n}\) is a Hurwitz matrix, and \(O_{}\) is an \((,0)\)-block-encoding of \(\). For an arbitrary \(t>0\), we can implement a \(( t,)\)-block-encoding of \(e^{t}\) using \(}( t(1/))\) queries to \(O_{A}\), and \(}( t(1/))\) queries to additional gates. Here, the normalization factor \(=()\), and the constant \(\) is solely determined by \(\)._

More details and the proof of Theorem 2 can be found in Appendix C. Note that the dependence on \(t\) in the above result can be further improved using a standard padding technique, but for simplicity, we do not discuss this minor improvement, as it does not affect our main end-to-end result. We also notice a technique called quantum eigenvalue transformation (QEVT), recently proposed by Low and Su . While this method cannot be directly applied to Hurwitz-stable systems, it may be enhanced to provide a simulation algorithm with a similar cost, as discussed in Appendix D.

## 4 Quantum Algorithm for the Lyapunov Equation

The (continuous-time) Lyapunov equation is a linear matrix equation of the following form,

\[X+X^{}+=0.\] (16)

Since this equation is linear in terms of the matrix \(X\), it is possible to derive a vectorization form of (16) and solve it using a quantum linear system algorithm . In this paper, we propose a new quantum algorithm for solving the Lyapunov equation based on an integral representation formula. Our algorithm directly prepares a block-encoded solution matrix \(X^{*}\). Compared to the previous approach, our method leads to an exponentially faster quantum objective function evaluation algorithm (see Theorem 5) and a new quantum gradient estimation subroutine (see Theorem 6).

### Representation

Given a positive-definite \(Q\), there exists a unique positive-definite \(X^{*}\) satisfying (16) if and only if \(\) is Hurwitz. The unique positive solution is given by

\[X^{*}=_{0}^{}e^{t} e^{^{}t}\ t.\] (17)

The integral formula (17) suggests that the solution to the Lyapunov equation can be computed using a numerical integration technique. For a finite \(>0\), we define

\[X_{}_{0}^{}e^{t} e^{^{}t }\ t.\] (18)

For any arbitrary \(>0\), we find that a \(=}((1/))\) is sufficient to ensure an \(\)-approximate solution. We denote \(\|X^{*}\|/_{}()\).

**Lemma 3** (Numerical integration).: _For any \(>0\), we have \(\|X^{*}-X_{}\|\), provided that_

\[=\| }{_{}(X^{*})}.\] (19)

Proof.: Note that \(\|X^{*}-X_{}\|=\|_{}^{}e^{t}  e^{^{}t}\ t\|_{}^{}\| \|\|e^{t}\|\|e^{^{}t}\|\ t\), where \(\|e^{t}\|\) (or \(\|e^{^{}t}\|\)) is upper bounded by \(\|}{_{}(X^{*})}e^{-t/}\) (see [44, Lemma 12]). It follows that \(\|X^{*}-X_{}\|\| }{_{}(X^{*})}e^{-/}\). Therefore, an integration time as given in (19) guarantees that \(\|X^{*}-X_{}\|\)

### Algorithm Complexity Analysis

The matrix \(X_{}\) can be approximated by a trapezoidal rule with \((K+1)\) quadrature node points, namely,

\[X_{}_{k=0}^{K}w_{k}e^{t_{k}} e^{^{ }t_{k}}=_{k=0}^{K}w_{k}(t_{k}),\] (20)

where \(w_{k}=)}{2K}\), \(t_{k}=}{K}\), and \((t) e^{t} e^{^{}t}\). The summation in (20) can be computed on a quantum computer by performing linear combinations of block-encoded matrices, which we will explain shortly.

**Definition 4** (Select oracle).: Let \(^{n n}\) be a Hurwitz matrix. Given an integer \(K>0\) and two positive scalars \(,>0\), we define the following unitary (named as the _select oracle_):

\[(,)_{k=0}^{K}|k\!  k| U_{k},\] (21)

where for each \(k=0,,K\), \(U_{k}\) is a \(( t_{k},)\)-block-encoding of \(e^{t_{k}}\) with \(t_{k}=k/K\). Here, \(\) denotes some parameter that only depends on \(\).

Now, we consider two select oracles:

\[(A,)_{k=0}^{K}|k\!  k| U_{k},(A^{},) _{k=0}^{K}|k\! k| V_{k},\] (22)

where for each \(k=0,,K\), \(U_{k}\) (or \(V_{k}\)) denotes a block-encoding of \(e^{t_{k}}\) (or \(e^{^{}t_{k}}\)) with normalization factor \( t_{k}\). Let \(O_{}\) be a \((,0)\)-block-encoding of \(\), and we find that

\[(A,)(I O_{})(A^{}, )=_{k=0}^{K}|k\! k| W_{k},\] (23)

where \(W_{k} U_{k}O_{}V_{k}\) is a \((^{2}t_{k}^{2},2)\)-block-encoding of the matrix \((t_{k})\). Denoting \(_{k} w_{k}k^{2}\), then it is clear that \(_{k=0}^{K}_{k}W_{k}\) is a block-encoding of \(X_{}\). Thus we can implement a block-encoded \(X_{}\) on a quantum computer using a technique known as linear combination of unitaries (LCU) [22, Lemma 52]. The rigorous complexity of this quantum algorithm is given in the following theorem, for which a complete proof is provided in Appendix E.

**Theorem 4**.: _Suppose that \(^{n n}\) is Hurwitz and \(^{n n}\) is positive-definite. Let \(O_{}\) be an \((,0)\)-block-encoding of \(\) and \(O_{}\) be an \((,0)\)-block-encoding of \(\). Then, we can implement a \((,)\)-block-encoding of \(X^{*}\), the unique solution to the Lyapunov equation (16), using a single query to \(O_{}\), \(}(^{2}})\) queries to controlled \(O_{}\) and its inverse, and \(}(^{2}})\) queries to other additional elementary gates. Here \(=}(^{2})\)._

### Objective Function Evaluation

As a direct consequence of Theorem 4, we can evaluate the objective function value \(f(K)\) for a given \(K_{K}\) in a cost that is logarithmic in the dimension parameter \(n\). This result demonstrates an exponential quantum advantage for the objective function evaluation task, as any known classical algorithm for this task requires at least matrix multiplication time.

**Theorem 5**.: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(}((n))\) time. Let \(K_{K}\) be a stabilizing policy stored in a quantum-accessible data structure. We can estimate the objective function \(f(K)\) up to multiplicative error \(\) in cost \(}(})\)._

Proof.: Given a \(K_{K}\), we can evaluate the objective function \(f(K)\) via the formula \(f(K)=[P(K)_{0}]\). Here, without loss of generality, we assume \(_{0}=\). \(P(K)\) has a closed-form representation as in (6), which corresponds to the unique positive solution to the Lyapunov equation

\[(A-BK)^{}P+P(A-BK)+(Q+K^{}RK)=0.\] (24)We denote \(=A-BK\), and \(=Q+K^{}RK\). By Lemma 11 and Remark 1, we can block-encode \(\) with normalization factor \(s(\|K\|_{F}+1)\) and \(\) with normalization factor \(s(\|K\|_{F}^{2}+1)\), both in cost \(((n,s))\). Suppose that \(f(K)=a\), it follows from Lemma 8 that \(\|K\|_{F}(a)\). Therefore, by Theorem 4, we can implement a \((,)\)-block-encoding of \(P(K)\) in cost \(}(a^{3}}{}})\), where \(}(a^{4}^{2}^{3})\). Note that \(P(K)\) is a Hermitian matrix, and \(_{}(P(K))_{}(Q)\), by invoking Theorem 25, we can estimate \(f(K)=[P(K)]\) up to a multiplicative error \(\) in cost \(}(}{} ^{5}}{}})}(^{6}^{10}}{^{2}})\). Here, the error parameter must be chosen so that \(}(^{2}/^{2})\). 

## 5 Quantum Policy Gradient for Large-Scale Control

### Quantum Gradient Estimation

**Definition 5**.: Given any \(K_{K}\), we call \(G^{m n}\) a \(\)-_robust estimate_ of \( f(K)\) if it approximates the gradient \( f(K)\) up to a multiplicative error \(\), i.e.,

\[\|G- f(K)\|_{F}\| f(K)\|_{F}.\] (25)

Here, we utilize the close-form expression of the policy gradient \( f(K)\), as shown in (13), to construct a quantum algorithm for gradient estimation. The complete theorem statement and the proof are in Appendix G.

**Theorem 6** (Informal version of Theorem 31).: _Assume we have efficient procedures (as described in Assumption 1) to access \(A,B,Q,R\) in \(((n))\) time. Let \(K_{K}\) be a stabilizing policy stored in a quantum-accessible data structure. Provided that \(\|K-K^{*}\|>\) and \(m n\), we can compute a \(\)-robust estimate of \( f(K)\) in cost \(}(^{1.5}})\)._

### Quantum Policy Gradient

Our main quantum algorithm for LQR is summarized in Algorithm 1.

``` Inputs:\(A,B,Q,R\) (problem data), \(K_{0}_{K}\) (initial guess), \(>0\) (step size/learning rate), \(\) (robustness parameter), \(N\) (number of iterations) Output: an approximate solution \(K_{N}\) for\(k\{0,1,,N-1\}\)do  Compute a \(\)-robust estimate of \( f(K_{k})\), denoted as \(G_{k}\), using Theorem 6.  Update the quantum-accessible data structure using the rule: \(K_{k+1}=K_{k}- G_{k}\). endfor ```

**Algorithm 1** Quantum policy gradient

We can prove that the iterates in Algorithm 1 converges to the optimal control policy \(K^{*}\) at a linear rate (Proposition 34). It follows that our algorithm can find an \(\)-approximate optimal policy with an end-to-end cost \(}(})\).

**Theorem 7** (Informal version of Theorem 35).: _Assume that we have efficient procedures (as described in Assumption 1) to access the problem data \(A,B,Q,R\) in \(((n))\) time. Let \(K_{0}_{K}\) be a stabilizing policy and assume that \(m n\). Then, Algorithm 1 outputs an \(\)-approximate solution to Problem 1 in cost \(}(})\)._

### Numerical Experiments

Correctness.We conduct a numerical experiment to showcase the correctness of our quantum policy gradient algorithm. Following a similar setup as in , a mass-spring-damper system with \(g=4\) masses is used for constructing our LQR problem. The state \(x=[p^{},v^{}]^{}^{2g}\) contains positions and velocities, with dynamic and input matrices,

\[A=0&I\\ -T&-T,B=0\\ I,Q=I+100e_{1}e_{1}^{},R=I+4e_{2}e_{2}^{},\] (26)

where \(0,I\) are \(g g\) zero and identity matrices, \(e_{i}\) is the \(i\)th unit vector, and matrix \(T\) has 2 on the main diagonal and -1 on the first super- and sub-diagonal. In Figure 2, we run our method against the classical model-free gradient-based method . It shows that our model-based policy gradient converges much faster to the ground truth ARE solution \(K^{*}\). In the benchmark example , ours converges within 750 iterations, while the classical method takes \(2 10^{4}\) iterations (_orders of magnitude_ longer). In Figure 2 (c), we increase the system size by scaling \(g\) from 4 to 64. Both methods run on a classical simulator with Intel i9-10980XE CPU. Our method runs much faster than  by **nearly 3 orders of magnitude**. The code for both methods can be seen at https://github.com/YilingQiao/diff_lqr. Additional numerical results can be found in Appendix I.

## 6 Conclusion and Future Work

In this paper, we propose the first quantum algorithm for solving linear-quadratic control problems that achieves end-to-end quantum speedups. Our quantum algorithm utilizes an exponentially faster quantum linear dynamics simulator combined with a policy gradient method. Compared to classical approaches relying on matrix factorization and iterations, our method achieves super-quadratic speedup in the large-scale regime (i.e., \(m n\)). Moreover, the hybrid quantum-classical algorithm design makes our algorithm a promising candidate for practical quantum advantage in the near horizon. We also provide numerical evidence to demonstrate the robustness and favorable convergence behavior of our method.

Limitations and Future Work.Accelerating optimal control and reinforcement learning using quantum computers remains an emerging research topic. Our work has focused on the theoretical aspects of quantum advantage for LQR, a classic optimal control problem of fundamental importance in both theory and practice. However, for special cases , we have no guarantee that our quantum algorithm still applies, since Lemma 33 may not hold. In the future, we aim to explore both the practical utility of quantum computing for such tasks and its potential for handling more complex optimal control scenarios, such as non-quadratic and nonlinear problems.