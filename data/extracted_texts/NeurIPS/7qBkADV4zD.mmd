# DeltaDEQ: Exploiting Heterogeneous Convergence for Accelerating Deep Equilibrium Iterations

Zuowen Wang  Longbiao Cheng  Pehuen Moure  Niklas Hahn  Shih-Chii Liu

Institute of Neuroinformatics, University of Zurich and ETH Zurich

{zuowen, shih}@ini.uzh.ch

###### Abstract

Implicit neural networks including deep equilibrium models have achieved superior task performance with better parameter efficiency in various applications. However, it is often at the expense of higher computation costs during inference. In this work, we identify a phenomenon named **heterogeneous convergence** that exists in deep equilibrium models and other iterative methods. We observe much faster convergence of state activations in certain dimensions therefore indicating the dimensionality of the underlying dynamics of the forward pass is much lower than the defined dimension of the states. We thereby propose to exploit heterogeneous convergence by storing past linear operation results (e.g., fully connected and convolutional layers) and only propagating the state activation when its change exceeds a threshold. Thus, for the already converged dimensions, the computations can be skipped. We verified our findings and reached 84% FLOPs reduction on the implicit neural representation task, 73% on the Sintel and 76% on the KITTI datasets for the optical flow estimation task while keeping comparable task accuracy with the models that perform the full update.

## 1 Introduction

Implicit neural networks  have gained much attention in recent years. They are capable of matching or surpassing state-of-the-art performance in domains such as computer vision , language modeling  and audio processing . Implicit networks typically model these tasks with certain dynamics represented by the evolution of the intermediate hidden states and are often described as fixed-point equations or differential equations. The implicit models, represented by the deep equilibrium (DEQ) model family, often achieve better parameter efficiency for reaching a similar level of task accuracy as their regular neural network counterparts. Furthermore, the implicit function theorem assists implicit models in avoiding the need for direct differentiation through numerous forward steps, like those required in back-propagation through time, which demands substantial memory for training.

Despite their compact architectural design with fewer parameters, implicit models frequently require extensive computations during inference to better approximate the fixed point. The fixed point is typically computed with fixed-point iteration methods  or other root-solving techniques such as Broyden  or Anderson  methods, all of which require multiple forward passes of the model. The substantial computational cost at inference time significantly hinders the deployment of implicit models. Various strategies have been developed to reduce this computational burden, including fixed-point reuse  to accelerate the convergence of the forward pass for temporally correlated inputs like consecutive video frames, and global early stopping criteria  that halt the forward pass once the absolute or relative change of the hidden states norm is below a threshold. However, these approaches uniformly control the termination of updates across all dimensions of the hidden states and they fail to consider the internal structure of the dynamics.

This work makes a finer-grained inspection of the dynamics of the hidden states update. By analyzing the element-wise trajectory and dimensionality of hidden states update, we observed the **heterogeneous convergence** phenomenon among implicit models. That is, there exists a significant variance in convergence speeds across different dimensions of the hidden states; and that certain dimensions converge substantially faster than others in the forward pass of an implicit model. Based on this finding, we modified the forward pass update of the DEQ models with the delta updating rule that stores the intermediate results of computationally intensive linear operators and only calculates at dimensions where their changes between two sequential updates exceed a threshold. Our method is orthogonal to other acceleration techniques including fixed-point reuse [4; 32] and early stopping [4; 41] of iterations. Unlike fixed-point reuse acceleration, our method does not assume temporal correlation of inputs i.e. effective even for static. While primarily applied to DEQ-based methods, our technique can be adapted to any iterative method that uses a fixed-point search in the forward pass. We empirically tested our method for two tasks: implicit neural representation (INR) for images and optical flow (OF) estimation. Compared to previous DEQ-based methods, Our approach achieved an 84% reduction in FLOPs for the INR task and a 73% and 76% reduction for the OF task using the Sintel and KITTI datasets, respectively, without significant loss in task accuracy. The code is available at [https://github.com/ZuowenWang0000/Delta-Deep-Equilibrium-Models](https://github.com/ZuowenWang0000/Delta-Deep-Equilibrium-Models).

## 2 Background

The majority of the findings in this study are derived from deep equilibrium models (DEQ)1, which represent a specific category of implicit models. We offer essential annotations and background information on DEQ in this section. A DEQ layer is modeled as a fixed-point equation:

\[z^{*}=f_{}(z^{*},x), \]

where \(x\) is the input and the layer is parameterized by \(\). Notice that \(f_{}\) does not need to be single-layered but could also be a block of layers. Thus, \(z^{*}\) could be activations of a block of layers. This fixed-point equation is solved with Broyden method  or Anderson acceleration  by finding the root of \(f_{}(z^{*},x)-z^{*}=0\) in the initial DEQ works [2; 4].

Alternatively, the fixed-point equation can be solved by iterative methods. Picard's method is an iterative method for approximating the fixed point \(z^{*}\). By simply substituting the state \(z^{i}\) at \(i\)-th iteration as the input and \(z^{0}\) as initialization, the state at iteration step \(i+1\) is computed as

\[z^{i+1}=f_{}(z^{i},x), \]

and \(z^{i} z^{*}\) as \(i\) when \(f_{}\) is a contraction mapping. Empirically the \(z^{*}\) can be approximated in limited numbers of iterations, in other words, the fixed-point iteration (FPI) converges empirically in limited steps.

For a temporal input sequence \(x_{t}\) where \(t=1,...,T\), processing each input \(x_{t}\) at time \(t\) requires solving a corresponding fixed-point \(z^{*}_{t}=f_{}(z^{*}_{t},x_{t})\). This means that for every input timestep \(t\), the forward pass of DEQ involves solving a fixed-point equation which could be computationally intensive. From previous studies [4; 56; 41], reusing the fixed point \(z^{*}_{t-1}\) as the initialization (\(z^{0}_{t}=z^{*}_{t-1}\)) for processing the next timestep input \(x_{t}\), could accelerate the convergence speed to \(z^{*}_{t}\).

## 3 Observations and motivation

Our methods are based on several key observations on the forward pass of DEQ models. We first demonstrate the observations with a simple DEQ model which is formulated as a deep equilibrium layer \(z^{*}=(W_{z} z^{*}+W_{x} x+b)\) and a linear readout layer \(y=Wz^{*}\), where \(W_{z}^{20 20},W_{x}^{20 1},W ^{1 20},b^{20 1}\) are the weights and bias respectively. We generated a dataset that consists of data points \((x,(x))\) with \(x\) being evenly sampled 200 points in \([-2,2]\). We train the network to fit the \((x)\) function learning from these data samples. The forward pass is implemented with Picard's method in Eq. 2 with 15 iterations and the backward pass is implemented with back-propagation through time (BPTT). The loss function used for training is \(=_{}+_{||||_{2}}\) where \(_{}\) is the mean squared error. The second term \(_{||||_{2}}=(||W_{z}||_{2}-1)\) is the spectral norm regularization on the matrix \(W_{z}\) and is applied when \(||W_{z}||_{2}>1\) in each iteration. This regularization is to ensure the model realizes a contrastive mapping and guarantees stable fixed points as stated in the Banach Fixed Point Theorem . As shown in Fig. 1(a) the model gradually converges to the ground truth \((x)\) values when the iterations at inference increased from 1 to 15.

In Fig. 1(c), we concatenated hidden states from different iterations for all the input \(x\) in the dataset and conducted the principal component analysis (PCA) on them. We can see that although the hidden states are defined with 20 dimensions, with only 3 principal components we could explain over 99% of the variance in all hidden states trajectory. This observation shows that for DEQ models trained on specific tasks, the underlying dynamics could be depicted with much lower dimensionalities than the defined state \(z^{*}\), which was observed similarly in  for continuous RNNs. Details of the PCA method are in Appendix. A.1.

**Heterogeneous convergence** The underlying dynamics of DEQ models, as well as other forms of recurring architectures , often have lower intrinsic dimensions than their explicitly defined dimensionality. Fig. 1(d) shows how this low intrinsic dimension characteristic is reflected in the original hidden state space. We can see that some dimensions of \(z\) experience much larger fluctuation with the hidden state trajectory while certain dimensions converge within a few iterations. Fig. 1(e) presents the evolution of the mean delta activation \(|z^{i+1}-z^{i}|_{k}\) at dimension \(k\) for 1000 uniformly sampled input points. We can observe very different convergence speed for different dimensions and large variances in all dimensions. The averaged histogram statistics for the number of dimensions that converged at \(i-th\) iteration is shown in Fig. 1(f). We observe that although globally the model reaches an MSE plateau at around 8 iterations, many dimensions have already converged long before that. We name this phenomenon **heterogeneous convergence**, indicating that different dimensions of the state \(z\) converge at uneven speeds for a fixed-point iteration implemented forward pass of a DEQ. A natural question arises from observations of this phenomenon:

_Can we exploit the heterogeneous convergence phenomenon in the dynamics of hidden state updates for accelerating deep equilibrium models and other iterative methods?_

Indeed, identifying and leveraging the rates at which dimensions stabilize could lead to more efficient computational strategies. In Sec. 4 we describe our DeltaDEQ method that exploits the heterogeneous convergence for reducing computation of the DEQ forward pass together with details for other associated methods used in this work.

Figure 1: (a) Reconstruction evolution when increasing inference iterations. (b) Hidden states trajectory for 5 consecutive input points with the first two principal components. Details in A.1. (c) Cumulative explained variance for all hidden states. (d) Evolution of different dimensions of hidden states (represented by colors) over iterations. (e) Mean delta activation for different dimensions (represented by colors). The colored solid areas indicate the standard deviation from different inputs. (f) Histogram of converged dimensions (blue) at i-th iteration and evolution of the model prediction MSE (red).

Methods

We propose DeltaDEQ to leverage the heterogeneous convergence phenomenon by inducing the **delta activation sparsity** in fixed-point iterations. DeltaDEQ can be instantiated with mainstream network architectures including recurrent neural networks (RNNs), convolutional neural networks (CNNs) and transformers just like DEQ. Computation savings for DeltaDEQ do **not** require the strong assumption [44; 45] that input data has to be minimally changing temporal sequences. Even when processing a static input, DeltaDEQ can still save computation in comparison to DEQ due to the convergence nature of equilibrium evolution.

### Delta deep equilibrium layer (DeltaDEQ)

We start the introduction of the DeltaDEQ with a simple instantiation of a single RNN layer:

\[z_{t}^{i+1}=(W_{z} z_{t}^{i}+W_{x} x_{t}), \]

where \(x_{t}^{d_{x}}\) is the input at timestep \(t\), \(z_{t}^{i}^{d}\) is the hidden states vector at fixed-point iteration \(i\), \(W_{z}^{d d}\) and \(W_{x}^{d d_{x}}\) are the weight matrices and \(\) represents the activation function. Due to the linearity of \(W_{z}\) projection, Eq. 3 can be reformulated as follows:

\[z_{t}^{i+1}=(W_{z}(z_{t}^{i}-z_{t}^{i-1})+W_{z} z_{t}^{i-1}+W_ {x} x_{t}). \]

Assuming that \(z_{t}^{i}-z_{t}^{i-1}\) is sparse, namely many dimensions are zeros, then the computation of the matrix-vector multiplication can be greatly reduced (see Fig. 5). This sparsity assumption holds due to the fact that DEQ models are trained to converge in the forward pass. In order to achieve higher sparsity, we further apply an **element-wise delta threshold**\(\) to zero out small changes. We define the thresholded delta hidden states vector and apply the delta rule on Eq. 4 as follows:

\[ z_{t}^{i}:=z_{t}^{i}-z_{t}^{i-1}&|z_{t}^{i}-z_{t}^{i-1}|\\ 0&)} \]

\[z_{t}^{i+1}}}{{}}(  z_{t}^{i}}_{}+  z_{t}^{i-1}}_{C_{z}}+ x_{t}}_{C_{x}}). \]

\[C_{z} W_{z} z_{t}^{i}+C_{z} \]

Figure 2: (a) Convolution type of DeltaDEQ. The input \(I_{t}^{i-1}\) from the previous iteration is stored and subtracted to create the sparse \( I_{t}^{i}\). White represents zero. (b) For sparse convolution, in theory, all zero entries in the feature map can be skipped; in practice, this is more feasible on hardware [1; 15] when the entire activation patch is fully sparse. The complete formulation and pseudo-code are given in A.2 and RNN type DeltaDEQ is illustrated in A.5.1.

Notice that Eq. 5 operates element-wise. The assignment Eq. 7 states that after finishing the sparse matrix-vector multiplication, we update the stored value \(C_{z}\) for the next iteration. There is no need to update the cached value \(C_{x}\) within the same input timestep \(t\) since the input \(x_{t}\) does not change. But when the computation moves to \(x_{t+1}\), a similar update rule as in Eq. 5 can be applied on input and thus also saving computation. An illustration for the RNN type DeltaDEQ is in Sec. A.5.1 Fig. 5.

**Convolutional DeltaDEQ** The convolution layers, which are most commonly used for vision tasks, are in principle also composed of linear transformation followed by non-linearities. Thus, we can also reformulate a convolutional DEQ block as a convolutional DeltaDEQ (ConvDeltaDEQ) block. Assuming the input features to a layer in a DeltaDEQ block at iteration \(i\) is \(I^{i}_{t}\) and the output is \(O^{i}_{t}\):

\[O^{i}_{t}=(*I^{i}_{t})=(*(I^{i}_{t}-I^{i-1}_ {t}+I^{i-1}_{t}))}{}(* I^{i}_{t}}_{}+*I^{i-1}_{t}}_{ }), \]

where \(*\) denotes the convolution operation and \(\) is the convolution kernel. The convolution \(* I^{i}_{t}\) is conducted on the sparse delta feature map \( I^{i}_{t}\). The multiply-accumulate (MAC) operations could be skipped on the zero entries in \( I^{i}_{t}\) as illustrated in Fig. 2.

**Theoretical complexity analysis and hardware practicality** Assuming the sparsity level (% zero entries) in \(z^{i}_{t}\) is \(o_{}}\). For every fixed-point iteration for the RNN type of network layer as in Eq. 5 the floating point operations (FLOPs) spent on computing \(W_{z} z^{i}_{t}\) is \(2d^{2}\), while the delta thresholded version costs approx. \(2(1-o_{}})d^{2}+d\). For convolution kernel with kernel size \(k\) and stride \(s\), and assuming \( z^{i}_{t},\ z^{i}_{t}^{d d}\) and padding so that the output feature map still has size \(d d\), the original convolution costs approx. \(2d^{2}k^{2}\) FLOPs while the delta version costs approx. \(2(1-o_{}})d^{2}k^{2}+d^{2}\) FLOPs. A large level of \(o_{}}\) could reduce FLOPs greatly for both the RNN type of layer as well as a convolution in theory. However, while the computation cost reduction for the RNN type of layer is easy to realize in practice [20; 43], the sparse convolution is in general more difficult due to its fine granularity and its realization often requires special hardware or library support [1; 15].

### Fixed-point iteration instead of root solving

The original DEQ work adopted root-solving, including Broyden  and Anderson  methods, in the forward pass. These methods contain overhead computation other than the model inference \(f_{}(z^{i}_{t},x_{t})\) itself. We found that fixed-point iterations, which include Picard's iteration (Eq. 2) and Krasnoselskii-Mann (KM) iteration, suffice for approximating the fixed-point in the forward pass and has good (global) convergence speed (fewer iterations needed to converge) in comparison to root-solving techniques. KM iteration maintains a history of one past iteration and conducts weighted sum: \(z^{i+1}_{t}=_{t}f_{}(z^{i}_{t},x_{t})+(1-_{t})z^{i}_{t}\), where \(_{t}\) is the coefficient for the weighted sum and in our work we choose a fixed \(\) namely \(_{t}=\). The KM method helps to accelerate the overall convergence of the fixed-point iteration with better asymptotic and stabilize the trajectory of the forward pass and improve task performance. It does not induce an additional memory footprint with DeltaDEQ since the storage of two steps of states is already required. We provide a detailed comparison of fixed-point iterations and root-solving techniques in A.7.

### Other acceleration techniques for DeltaDEQ

We adopt another two major acceleration techniques from previous works [2; 4; 32; 41; 56] for DeltaDEQ: (1) fixed-point reuse and (2) global early stopping. The fixed-point reuse method is often used for processing temporal sequences such as video frames. It initializes the hidden states \(z^{0}_{i+1}\) with the fixed-point from last input timestep \(t\), namely \(z^{0}_{t+1}=z^{*}_{t}\). This technique is based on the assumption that small distances between consecutive inputs \(d(x_{t},x_{t+1})\) will induce small distances of fixed-point \(d(z^{*}_{t},z^{*}_{t+1}) d(z^{0}_{t+1},z^{*}_{t+1})\) under their corresponding metric spaces. In the work  the authors recycle the fixed point from the last training epoch as initialization for accelerating the training. Distinct from heterogeneous convergence, global early stopping is used to terminate the fixed-point iteration when it has converged **globally**. After computing the new hidden state \(z^{i}_{t}\), we calculate its absolute \(\|z^{i}_{t}-z^{i-1}_{t}\|_{2}\) or relative \(\|z^{i}_{t}-z^{i-1}_{t}\|_{2}/\|z^{i-1}_{t}\|_{2}\) distance to the previous hidden state \(z^{i-1}_{t}\). If the distance is smaller than the tolerance, the forward pass is terminated. We emphasize that global early stopping requires storing the previous hidden state for calculating the difference \(z^{i}_{t}-z^{i-1}_{t}\), which is also required for the delta rule. This additional computation and memory usage can be shared for both techniques.

### Training and fine-tuning DeltaDEQ

One of the biggest advantages of deep equilibrium models  is the constant memory and computation costs for training in comparison to explicit iterative methods with (truncated-)BPTT. The loss value \(\) evaluated at fixed-point \(z^{*}\) in Eq. 1 with respect to the function parameters \(\) is given by the implicit function theorem (IFT) [2; 36]:

\[},r_{}(z^{*}))}{}=},r_{}(z^{*}))}{ z^{*}}}{}=},r_{}(z^{*}))}{  z^{*}}(I-(z^{*},x)}{ z^{*}} )^{-1}(z^{*},x)}{}, \]

where \(r_{}\) is the final read-off layer with parameters \(\) and \(y_{}\) is the ground truth label. The inversion in Eq. 9 could be expensive when the dimensionality of \(z^{*}\) is large. However, various methods have been proposed to avoid computing the inversion [19; 26; 28] without hurting task performance much. The Eq. 9 shows that the backward pass is independent of the forward pass regardless. Thus, applying the delta rule (Eq. 5) in the forward pass **will not** impose any additional cost in the backward pass.

## 5 Experiments

In this section, we present the experimental results of the INR task and the OF task with the DeltaDEQ method. We showcase the two instantiations: RNN and CNN-based DeltaDEQs and present the computation reduction we could achieve without hurting the task accuracy.

### Implicit neural representation

In this section, we present empirical results of DeltaDEQ for implicit neural representation (INR) [32; 48; 51]. INR is a type of method that represents the data with a coordination-based neural network. For example, for encoding a 2D image, the network is trained with input coordinate \((x,y)\) and to predict the corresponding (R,G,B) or greyscale value of the pixel \((x,y)\). The pixels in an image are the training set for fitting the network to represent such high-frequency data. Despite the simplicity of the task setting, training INR models to reconstruct the original data with good quality is not easy.

Two of the representative works are Siren  and multiplicative filter networks with Fourier filters . A later work  modified these two methods with a deep equilibrium paradigm and achieved better task performance with the same amount of parameters. The experimental setup of DeltaDEQ for INR is largely based on . Methods and hardware details and additional results are in A.5.

**DeltaDEQ architectures for INR** We apply the delta rule on the Implicit Sine-activate Networks and Implicit Multiplicative Filter Networks with Fourier filters, which we name DEQ-Siren and DEQ-Fourier respectively and their delta version DeltaDEQ-Siren and DeltaDEQ-Fourier. The DEQ-Siren (Eq. 10) and DEQ-Fourier (Eq. 11) are formulated as follows:

\[z^{} =(Wz^{}+W(Vx)+Ux+b) \] \[z^{} =(Wz^{*}+Wg(x;V)+b) g(x;U) \]

where \(g(x;U):=(Ux)\) represents the Fourier filters . The dimensionalities of the hidden state \(z\) used in the experiments is 512. The most computationally heavy part is the dense matrix-vector multiplication \(Wz^{*}\). We apply the delta rule described in Eq. 5 to convert the forward pass to reduce FLOPs (detailed formulations specific for each architecture are given in A.5.3).

**Inference acceleration with DeltaDEQ** We first train vanilla DEQ-Siren and DEQ-Fourier models without incorporating the delta rule in the training stage. The hidden state size is 512 and spectral normalization  is used for better stability and to ensure the non-diverging behavior of the network. The input image size is \(512 512\). As in , we use phantom gradient  to accelerate DEQ training. We use Adam  optimizer and cosine annealing learning rate schedule  with an initial

Figure 3: Original image and reconstructions with INR network.

learning rate of 0.001. The fixed point from the end of one training epoch is used for the initialization of the next epoch, and only one forward iteration is used if the fixed point is reused. This training technique  greatly accelerates the training speed and saves a lot of FLOPs. For global early stopping, we use absolute distance with a tolerance of 0.001 and a maximum of 40 forward iterations.

Figure 4 demonstrate the relationship of computation saving (FLOPs Reduction (%) \(\)), reconstruction quality (peak signal-to-noise ratio, PSNR \(\)) w.r.t. the choice of inference delta threshold as in Eq. 5. Mean values of three runs are given and the standard deviations are shown as colored areas around the mean. We evenly sample 1000 inference delta threshold values between 0 and 0.1, and 100 threshold values between 0.1 to 0.5. Both DeltaDEQ instantiations show great computation savings (55% to 80% approx.) with a robust range of delta threshold levels (\(10^{-3}\) to \(0.5\)) with little change in the task performance accuracy. Figure 3 shows a qualitative comparison of the reconstructed image with DEQ-Fourier and our DeltaDEQ-Fourier with threshold 0.5. We can see DeltaDEQ-Fourier achieved \( 84\%\) FLOPs reduction with a minor drop in PSNR.

**Learning with delta for the forward pass of DEQ** The forward pass of training DeltaDEQ is decoupled from the gradient calculation as described in Sec. 4.4. Thus, the saving of the forward pass could directly contribute to the training time reduction of DEQ-based INR methods. We study in this section the model behaviors when incorporating the delta rule during training. Tab. 1 shows the benefits of training with DeltaDEQ. For both Fourier and Siren variants of DEQ instantiations, applying the delta rule with training delta threshold \(=1e-4\) reduces the training FLOPs in the forward pass for both phantom gradient and implicit function theorem used for the backward pass. Notice that the training FLOPs reduction level is obtained at the circumstances of **fixed-point reuse** (Sec. 4.3) for each training epoch and **only one fixed-point iteration** is executed except for the first epoch. This approach  has already significantly reduced the FLOPs required during the training forward pass to an asymptotically constant level . Our method is orthogonal to this technique and can be implemented in conjunction with it. Furthermore, a single fixed-point iteration often does not suffice to accurately approximate \(z^{*}\) for other complicated tasks, even when the fixed-point is reused. By applying our method, a greater reduction in training computations can be achieved.

### Optical flow estimation

In this section, we study the application of DeltaDEQ on the classical computer vision task of optical flow (OF) estimation [16; 18; 31; 39; 53; 58]. OF estimation is a task for predicting the pixel displacement between two frames. Modern OF estimation is dominated by learning-based approaches and one of the representatives is the RAFT  network, which iteratively refines the OF estimation with a recurrent structure. In the work  the authors formulated the recurrent iterative structure of

   Training Method &  &  \\  & Tr. FLOPs* & PSNR\(\) & Tr. FLOPs* & PSNR\(\) \\  DEQ-Fourier  & 140 & 31.31 & 278 & 33.22 \\
**DeltaDEQ-Fourier** & 110 (-21\%) & 31.06 & 212 (-24\%) & 32.98 \\
**DEQ-Siren** & 140 & 29.94 & 278 & 34.96 \\
**DeltaDEQ-Siren** & 118 (-16\%) & 29.64 & 190 (-32\%) & 34.99 \\   

Table 1: Comparison of PSNR and training FLOPs w/o vs. **w** the delta rule during training. For reference, with same hyperparameters, the original Fourier and Siren (non-DEQ) networks recorded PSNRs of 30.06 and 33.31, respectively. All FLOPs values are presented in Tera-FLOPs (1e12). *This table only includes FLOPs for the forward pass of training; the computation cost of backward pass is independent of the forward pass.

Figure 4: FLOPs reduction and task accuracy (PSNR) at different inference delta threshold.

RAFT as a DEQ block which consumes 4 to 6 times less training memory than the original RAFT with BPTT and achieved SOTA on the MPI Sintel  and KITTI 2015  optical flow datasets.

**DEQ-RAFT architecture** We use the RAFT  network as the architectural backbone and the DEQ flow estimator version  (DEQ-RAFT) as our starting point for the conversion to DeltaDEQ. RAFT consists of mainly two parts: (1) the correlation and context encoders (feature extraction stage) and (2) the update block (iterative flow refinement stage). Although the feature extraction stage is also compatible with the delta rule and can be used to exploit the temporal correlation between the input frames, it is not the focus of this study since our main contribution is to accelerate the iterative computation in DEQ and other models. Thus, we omit the FLOPs of the first stage in results.

Assuming the feature extraction stage gives context embedding \(q\) and correlation tensor \(C\), the flow refinement stage conducts the fixed-point iteration simultaneously in two parts :

\[h^{i+1}=(h^{i},o^{i},q,C), o^{i+1}=(h^{i+1},o^{i}, q,C), \]

where \(h\) is the hidden representation and \(o\) is the optical flow estimation. Putting these notations into the fixed-point iteration framework in Eq.1, the extracted features \(q,C\) are the input \(x=(q,C)\), the iterative functions \(,\) are the function \(f_{}\) and the hidden states and the optical flow make the fixed-point iteration \(z^{i}=(h^{i},o^{i})\). Notice \(i\) marks the fixed-point iteration step and all the terms are **input time**\(t\) dependent when we move to process the next frame pair. Like in RAFT the optical flow refinement module is implemented with ConvGRU  for hidden states \(h\) updates and other convolutional layers for the optical flow \(o\) updates:

\[c^{i}=([q,o^{i},(o^{i}+C)]),\;\;h^{i+1}=(h ^{i},[c^{i},q]),\;\;o^{i+1}=o^{i}+(h^{i+1}) \]

where Corr is the correlation lookup. Design details of DEQ-RAFT are in Fig. 10 and A.6.2.

**DeltaDEQ conversion of DEQ-RAFT** We convert the layers in the update block (optical flow refinement stage, Fig. 10) of the DEQ-RAFT (DEQ in Tab. 2 for simplicity). We use pretrained models provided in  and show even **without any fine-tuning**, we can achieve good computation reduction without hurting the task accuracy. We also observed the heterogeneous convergence phenomenon in the DEQ-RAFT network (Fig. 9) and during the convergence of fixed-point iteration, the delta activation sparsity also increases (Fig. 8), indicating the DEQ-RAFT network is suitable for applying the delta rule. DeltaDEQ conversion, pertaining and fine-tuning settings are given in A.6.2.

In Tab. 2 we show the results of DeltaDEQ for the OF task in comparison with the original DEQ method  and other methods. The models were all pretrained on the FlyingChair  and FlyingThings3D  datasets and tested on the training splits of Sintel  and KITTI  datasets,

    & inf. &  & \(\) & FLOPs & KITTI (train)\(\) & \(\) & FLOPs \\  & \(\) & Clean & Final & Sp. & per pair & AEPE & F1-all & Sp. & per pair \\  PWC-Net  & - & 2.55 & 3.93 & - & - & 10.39 & 28.5 & - & - \\ VCN  & - & 2.21 & 3.68 & - & - & 8.36 & 25.1 & - & - \\ GMA  & - & 1.30 & 2.74 & - & - & 4.69 & 17.10 & - & - \\ RAFT  & - & 1.43 & 2.71 & - & - & 5.04 & 17.40 & - & - \\ DEQ(picard)  & - & 1.26 & 2.51 & - & 782G & 3.73 & 13.42 & - & 814G \\   & DeltaDEQ & 0.0 & 1.22 & 2.55 & \(0.52^{*}\) & 394G & 3.77 & 13.47 & \(0.54^{*}\) & 396G \\  & DeltaDEQ & 0.001 & 1.24 & 2.52 & 0.69 & 264G & 3.79 & 13.49 & 0.69 & 274G \\  & DeltaDEQ & 0.005 & 1.48 & 2.76 & 0.80 & 177G & 4.00 & 14.04 & 0.80 & 183G \\  & DeltaDEQ & 0.01 & 2.08 & 3.32 & 0.83 & 147G & 4.33 & 15.85 & 0.84 & 150G \\   & DEQ(picard) & - & 1.27 & 2.51 & - & 520G & 3.73 & 13.45 & - & 621G \\  & DeltaDEQ & 0.0 & 1.22 & 2.55 & 0.53* & 225G & 3.78 & 13.54 & 0.54* & 260G \\   & DeltaDEQ & 0.001 & 1.23 & 2.51 & 0.61 & 186G & 3.80 & 13.55 & 0.63 & 213G \\   & DeltaDEQ & 0.005 & 1.31 & 2.63 & 0.74 & **141G** & 3.90 & 13.75 & 0.74 & **152G** \\   & DeltaDEQ & 0.01 & 2.04 & 3.31 & 0.83 & 147G & 4.19 & 14.73 & 0.82 & 140G \\   & DeltaDEQ-ft & 0.005 & 1.25 & 2.59 & 0.73 & **127G** & 3.86 & 13.64 & 0.74 & **144G** \\   

Table 2: * Even for \(=0.0\) the sparsity level is already 0.53. This high level of sparsity is in favor of our method since it is not exploited in the vanilla DEQ. For DEQ and DeltaDEQ models, the default forward method is KM with \(=0.9\). Notice with early stopping the total FLOPs could be lower even when the \(\)Sp. is lower since a different number of global fixed-point iterations could be executed.

which is a common evaluation approach for the zero-shot generalization in OF. We report average end point error (AEPE) and F1-all (%) scores. We also report the delta activation sparsity \(\)Sp. which calculates \(}{}\) across all the iterations executed in the update block. We can see that applying the delta rule substantially reduced the averaged FLOPs needed in general. When using a fixed schedule of 60 iterations to process every input pair, the DeltaDEQ with \(=0.001\) could save 77% and 66% of FLOPs on Sintel (train) and KITTI (train) in theory without substantially hurting the task accuracy. It is worth mentioning that even when the threshold is set to 0, we still got over 50% of \(\)Sp.. This is due to the fact of usage of ReLU activations. In combination with early stopping with relative distance criteria and tolerance of 0.001, we further reduce the average FLOPs to below 20% of originally needed. We also found that fine-tune the model (DeltaDEQ-ft) with \(=0.005\) could improve the task accuracy while reducing the FLOPs and accelerating the convergence.

## 6 Related work

**Delta activation sparsity** For accelerating network inference, one can exploit the temporal correlation, which naturally arises in time-dependent data such as audio and video. Most related to our work is that of  where the authors proposed to use a delta update rule, which zeros out small hidden states change between two input timesteps to skip computation. Later works realized this structured delta activation sparsity on custom hardware [12; 14; 20; 21; 22] and turned the theoretical FLOPs reduction into runtime acceleration. Another line of work studies similar temporal-dependent delta activation sparsity but with CNNs. In [11; 29; 44; 45] the authors propose to exploit the linearity of the convolution operator and apply the delta rule to skip zero delta activities for processing consecutive video frames.

Several challenges arise with these approaches. To implement the delta rule in CNN architectures, it is necessary to store the intermediate feature maps of all convolution layers for computing the delta activations. If the network incorporates many layers and has low parameter efficiency, this will lead to substantial memory consumption. Although DeltaDEQ also requires storing feature maps, its property of high parameter efficiency could alleviate this issue by requiring fewer feature maps to be stored. Secondly, there is no guarantee that input data from consecutive time steps will produce temporally correlated features. Consequently, employing the delta rule might result in more overhead, offering no computational advantages. However, due to the fixed-point nature of DeltaDEQ, it is guaranteed to have a certain degree of sparsity from the delta activations between two FP iterations.

**Deep equilibrium models** Deep equilibrium (DEQ) models [2; 25] formulate stacking multiple layers of conventional network layers as a fixed-point solving problem of a single layer or a block of layers transformation. This could result in a smaller memory footprint and better parameter efficiency. DEQ models have also shown state-of-art task performance in various practical applications including object recognition or detection [3; 17], optical flow estimation , face landmark detection , implicit neural representation  and many others [10; 46]. One of the major drawbacks of DEQ models is its computation cost: for finding the fixed point, many fixed-point iterations or iterations in root-solving are usually required and every iteration requires one inference of the DEQ layer.

**Differences to other network acceleration algorithms** In comparison to layer skipping methods [9; 27; 29] which skip certain layers or halts the recurrence early in inference, our method exploits a finer-grained delta activation sparsity while the other methods can only skip an entire layer or recurrent step. Another line of works dynamically prunes activation, including channel selection  for CNNs and patch selection for transformer architectures [52; 55]. These works usually set certain channels or tokens of the activations to zeros or discard them so the network enjoys activation sparsity. Our method allows the activations to maintain non-zero values, while still generating delta activation sparsity, which could be exploited for computation saving. The non-zero activations could potentially make the network more expressive.

## 7 Conclusion

In this work, we introduce DeltaDEQ, a method designed to enhance computational efficiency for implicit models represented by deep equilibrium models. This method is inspired by our observation of the heterogeneous convergence phenomenon prevalent in implicit neural networks, where different dimensions of DEQ hidden states converge at varying speeds. DeltaDEQ leverages this disparity by calculating the delta activation between consecutive fixed-point iterations and utilizing the activation's sparsity to omit unnecessary computations for the already converged dimensions. We have tested DeltaDEQ across tasks involving implicit neural representation and optical flow, employing both RNN and CNN architectures. Our findings confirm that DeltaDEQ maintains accuracy while reducing computational demands across these network types. We provide detailed theoretical FLOPs reductions from our empirical research. This technique has the potential societal impact to decrease energy usage significantly in DEQ models  and other iterative methods, including those used in iterative refinement  and emerging diffusion models . However, translating these theoretical savings into actual wall-clock inference latency reductions often demands carefully designed implementation  and special hardware .