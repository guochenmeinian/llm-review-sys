# Foundation Inference Models for

Markov Jump Processes

 David Berghaus1,2, Kostadin Cvejoski1,2, Patrick Seifner1,3

Cesar Ojeda4 & Ramses J. Sanchez1,2,3

Lamarr Institute1, Fraunhofer IAIS2, University of Bonn3 & University of Potsdam4

{david.berghaus, kostadin.cvejoski}@iais.fraunhofer.de

seifner@cs.uni-bonn.de, ojedamarin@uni-potsdam.de, sanchez@cs.uni-bonn.de

###### Abstract

Markov jump processes are continuous-time stochastic processes which describe dynamical systems evolving in discrete state spaces. These processes find wide application in the natural sciences and machine learning, but their inference is known to be far from trivial. In this work we introduce a methodology for _zero-shot inference_ of Markov jump processes (MJPs), on bounded state spaces, from noisy and sparse observations, which consists of two components. First, a broad probability distribution over families of MJPs, as well as over possible observation times and noise mechanisms, with which we simulate a synthetic dataset of hidden MJPs and their noisy observations. Second, a neural recognition model that processes subsets of the simulated observations, and that is trained to output the initial condition and rate matrix of the target MJP in a supervised way. We empirically demonstrate that _one and the same_ (pretrained) recognition model can infer, _in a zero-shot fashion_, hidden MJPs evolving in state spaces of different dimensionalities. Specifically, we infer MJPs which describe (i) discrete flashing ratchet systems, which are a type of Brownian motors, and the conformational dynamics in (ii) molecular simulations, (iii) experimental ion channel data and (iv) simple protein folding models. What is more, we show that our model performs on par with state-of-the-art models which are trained on the target datasets.

Our pretrained model, repository and tutorials are available online1.

## 1 Introduction

Very often one encounters dynamic phenomena of wildly different nature, that display features which can be reasonably described in terms of a macroscopic variable that jumps among a finite set of _long-lived_, metastable discrete states. Think, for example, of the changes in economic activity of a country, which exhibit jumps between recession and expansion states (Hamilton, 1989), or the internal motion in proteins or enzymes, which feature jumps between different conformational states (Elber and Karplus, 1987). The states in these phenomena are said to be long-lived, inasmuch as every jump event among them is rare, at least as compared to every other event (or subprocess, or fluctuation) that composes the phenomenon and that occurs, by construction, _within_ the metastable states. Such a description in terms of macroscopic variables effectively decouples the fast, intra-state events from the slow, inter-state ones, and allows for a simple probabilistic treatment of the jumping sequences as Markov stochastic processes: the _Markov Jump Processes_ (MJPs). In this work we are interested in the general problem of inferring the MJPs that best describe empirical (time series) data, recorded from dynamic phenomena of very different kinds.

To set the stage, let us assume that we want to study some \(D\)-dimensional empirical process \((t):^{+}^{D}\), which features long-lived dynamic modes, trapped in some discrete set of metastable states. Let us call this set \(\). Let us also assume that we can obtain a macroscopic, coarse-grained representation from \((t)\) -- say, with a clustering algorithm -- in which the fast, intra-state events have been integrated out (_i.e._ marginalized). Let us call this macroscopic variable \(X(t):^{+}\). If we now make the Markov assumption and define the quantity \(f(x|x^{}) t\) as the infinitesimal probability of observing one jump from state \(x^{}\) (at some time \(t\)), into a different state \(x\) (at time \(t+ t\)), we can immediately write down, following standard arguments (Gardiner, 2009), a differential equation that describes the probability distribution \(p_{}(x,t)\), over the discrete set of metastable states \(\), which encapsulates the state of the process \(X(t)\) as time evolves, that is

\[}(x,t)}{dt}=_{x^{} x}f(x|x^{})p _{}(x^{},t)-f(x^{}|x)p_{}(x,t).\] (1)

Equation 1 is the so-called _master equation_ of the MJP whose solutions are completely characterized by an initial condition \(p_{}(x,t=0)\) and the transition rates \(f:^{+}\).

With these preliminaries in mind, we shall say that to infer an MJP from a set of (noisy) observations \((_{1}),,(_{l})\) on the process \((t)\), recorded at some observation times \(_{1},,_{l}\), means to infer both the transition rates and the initial condition determining the _hidden_ MJP \(X(t)\) that best explains the observations. In practice, statisticians typically assume that they directly observe the coarse-grained process \(X(t)\). That is, they assume they have access to the (possibly noisy) values \(x_{1},,x_{l}\), taken by \(X(t)\) at the observation times \(_{1},,_{l}\) (see Section 2). We shall start from the same assumptions. Statisticians then tackle the inference problem by (i) defining some (typically complex) model that encodes, in one way or the other, equation 1 above; (ii) parameterizing the model with some trainable parameter set \(\); and (iii) updating \(\) to fit the empirical dataset.

One issue with this approach is that it turns the inference of hidden MJPs into an instance of an _unsupervised learning problem_, which, as history shows, is far from trivial (see Section 2). Another major issue is that, if one happens to succeed in training said model, the trained parameter set \(^{*}\) will usually be overly specific to the training set \(\{(x_{1},_{1}),,(x_{l},_{l})\}\), which means it will likely struggle to handle a second empirical process, even if the latter can be described by a similar MJP. Figure 1 contains snapshots from two empirical processes of very different nature. The figure on the left shows a set of observations (blue circles) recorded from the discrete flashing ratchet process (black line). The figure on the right shows the ion flow across a cell membrane, which jumps between different activity levels (blue line). Despite the vast differences between the physical mechanisms underlying each of these processes, the coarse-grained representations of the second one (black line) is abstract enough to be strikingly similar to the first one. Now, we expect that -- at this level of representation -- one could train _a single inference model to fit each process_ (separately). Unfortunately, we also expect that an inference model trained to fit _only one_ of these (coarse-grained) processes, will have a hard time describing the second one.

In this paper we will argue that the _notion of an MJP description_ (in coarse-grained space) is simple enough, that it can be encoded into the weights of a single neural network model. Indeed, instead of training, in an unsupervised manner, a complex model (which somehow encodes the

Figure 1: Processes of very different nature (seem to) feature similar jump processes. _Left_: State values (blue circles) recorded from the discrete flashing ratchet process (black line). _Right_: Current signal (blue line) recorded from the viral potassium channel \(_{}\), together with one possible coarse-grained representation (black line).

master equation) on a single empirical process; we will train, in a supervised manner, a simple neural network model on a _synthetic dataset that is composed of many different MJPs, and hence implicitly encodes the master equation_. This procedure can be understood as an _amortization_ of the probabilistic inference process through a single _recognition model_, and is therefore akin to the works of Stuhlmuller et al. (2013), Heess et al. (2013) and Paige and Wood (2016). Rather than treating, as these previous works do, our (pretrained) recognition model as auxiliary to Monte Carlo or expectation propagation methods, we employ it to directly infer hidden MJPs from various synthetic, simulation and experimental datasets, _without any parameter fine-tuning_. We thus adopt the "zero-shot" terminology introduced by Larochelle et al. (2008), by which we mean that our procedure aims to recognize objects (i.e. MJPs) whose instances (i.e. noisy and sparse series of observations on them) may have not been seen during training. We have recently shown that such an amortization can be used to train a recognition model to perform _zero-shot imputation_ of time series data (Seifner et al., 2024). Below we demonstrate that it can also be used to train a model of minimal inductive biases, to perform _zero-shot inference_ of hidden MJPs from empirical processes of very different kinds, which take values in state spaces of different sizes. We shall call this recognition model _Foundation Inference Model_2 (FIM) for Markov jump processes.

In what follows, we first review both classical and recent solutions to the MJP inference problem in Section 2. We then introduce the FIM methodology in Section 3, which consists of a synthetic data generation model and a neural recognition model. In Section 4 we empirically demonstrate that our methodology is able to infer MJPs from a discrete flashing ratchet process, as well as from molecular dynamics simulations and experimental ion channel data, all in a zero-shot fashion, while performing on par with state-of-the-art models which are trained on the target datasets. Finally, Section 5 closes the paper with some concluding remarks about future work, while Section 6 comments on the main limitations of our methodology.

## 2 Related Work

The inference of MJP from noisy and sparse observations (in coarse-grained space) is by now a classical problem in machine learning. There are three main lines of research. The first (and earliest) one attempts to directly optimize the MJP transition rates, to maximize the likelihood of the discretely observed MJP via expectation maximization (Asmussen et al., 1996; Bladt and Sorensen, 2005; Metzner et al., 2007). Thus, these works encode the MJP inductive bias directly into their architecture. The second line of research leverages a Bayesian framework to infer the posterior distribution over the transition rates, through various Markov chain Monte Carlo (MCMC) algorithms (Boys et al., 2008; Fearnhead and Sherlock, 2006; Rao and Teg, 2013; Hajiaghayi et al., 2014). Accordingly, these

Figure 2: Foundation Inference Model (FIM) for MJP. _Left_: Graphical model of the FIM (synthetic) data generation mechanism. Filled (empty) circles represent observed (unobserved) random variables. The light-blue rectangle represents the continuous-time MJP trajectory, which is observed discretely in time. See main text for details regarding notation. _Right_: Inference model. The network \(_{1}\) is called \(K\) times to process \(K\) different time series. Their outputs is first processed by the attention network \(_{1}\) and then by the FNNs \(_{1}\), \(_{2}\) and \(_{3}\) to obtain the estimates \(}\), \(\,}\) and \(}_{0}\), respectively.

simulation-based approaches encode the MJP inductive bias directly into their trainable sampling distributions. The third one, also Bayesian in character, involves variational inference. Within it, one finds again MCMC (Zhang et al., 2017), as well as expectation maximization (Opper and Sanguinetti, 2007) and moment-based (Wildner and Koeppl, 2019) approaches. More recently, Seifiner and Sanchez (2023) used neural variational inference (Kingma and Welling, 2013) and neural ODEs (Chen et al., 2018) to infer an implicit distribution over the MJP transition rates. All these variational methods encode the MJP inductive bias into their training objective and, in some cases, into their architecture too.

Besides the model of Seifiner and Sanchez (2023), which automatically infers the coarse-grained representation \(X(t)\) from \(D\)-dimensional, continuous signals, all the solutions above tackle the MJP inference problem directly in coarse-grained space. Yet below, we also investigate the conformational dynamics of physical systems for which the recorded data lies in a continuous space. To approach such type of problems, we will first need to define a coarse-grained representation of the state space of interest. Fortunately for us, there is a large body of works, within the molecular simulation community, precisely dealing with different methods to obtain such representations, and we refer the reader to _e.g._Noe et al. (2020) for a review. McGibbon and Pande (2015), for example, leveraged one such method to infer the MJP transition rates describing a molecular dynamics simulation via maximum likelihood. Alternatively, researchers have also treated the conformational states in these systems as core sets, and inferred phenomenological MJP rates from them (Schutte et al., 2011), or modelled the fast intra-state events as diffusion processes, indexed by a hidden MJP, and inferred the latter either via MCMC (Kilic et al., 2021; Kohs et al., 2022) or variational (Horenko et al., 2006; Kohs et al., 2021) methods.

In this work we tackle the classical MJP inference problem _on coarse-grained space_ and present, to the best of our knowledge, its first zero-shot solution.

## 3 Foundation Inference Models

In this section we introduce a novel methodology for zero-shot inference of Markov jump processes which frames the inference task as a supervised learning problem. Our main assumption is that the space of _realizable MJPs_3, which take values on bounded state spaces that are not too large, is simple enough to be covered by a heuristically constructed synthetic distribution over noisy and discretely observed MJPs. If this assumption were to hold, a model trained to infer the hidden MJPs within a synthetic dataset sampled from this distribution _would automatically perform zero-shot inference on any unseen sequence of empirical observations_. We do not intend to formally prove this assumption. Rather, we will empirically demonstrate that a model trained in such a way can indeed perform zero-shot inference of MJPs in a variety of cases.

Our methodology has two components. First, a data generation model that encodes our believes about the class of realizable MJPs we aim to model. Second, a neural recognition model that maps subsets of the simulated MJP observations onto the initial condition and rate matrix of their target MJPs. We will explore the details of these two components in the following sections.

### Synthetic Data Generation Model

In this subsection we define a broad distribution over possible MJPs, observation times and noise mechanisms, with which we simulate an ensemble of noisy, discretely observed MJPs. Before we start, let us remark that we will slightly abuse notation and denote both probability distributions and their densities with the same symbols. Similarly, we will also denote both random variables and their values with the same symbols.

Let us denote the size of the largest state space we include in our ensemble with \(C\), and arrange all transition rates, for every MJPs within the ensemble, into \(C C\) rate matrices. Let us label these matrices with \(\). We define the probability of recording the noisy sequence \(x^{}_{1},,x^{}_{l}\), at the observation times \(0<_{1}<<_{l}<T\), with \(T\) the observation time horizon, as follows

\[_{i=1}^{l}p_{}(x_{i}^{}|x_{i},_{x})p_{}(x_{i} |_{i},,_{0})p_{}(_{1},,_{l}|_{ })p_{}(|,_{f})p(,_{f})p( _{0}|_{0}).\] (2)

Next, we specify the different components of Eq. 2, starting from the right.

**Distribution over initial conditions**. The distribution \(p(_{0}|_{0})\), with hyperparameter \(_{0}\), is defined over the \(C\)-simplex, and encodes our beliefs about the initial state (_i.e._ the preparation) of the system. It enters the master equation as the class probabilities of the _categorical distribution_ over the states of the system, at the start of the process. That is \(p_{}(x,t=0)=(_{0})\). We either choose \(_{0}\) to be the class probabilities of the stationary distribution of the process, or sample it from a Dirichlet distribution. Appendix B provides the specifics.

**Distribution over rate matrices**. The distribution \(p_{}(|,_{f})\) over the rate matrices encodes our beliefs about the class of MJPs we expect to find in practice. We define it to cover MJPs with state spaces whose sizes range from 2 until \(C\), because we want our FIM to be able to handle processes taking values in all those spaces. The distribution is conditioned on the adjacency matrix \(\), which encodes only connected state spaces (_i.e._ irreducible embedded Markov chains only), and a hyperparameter \(_{f}\) which encodes the range of rate values within the ensemble. Specifically, we define the transition rates as \(F_{ij}=a_{ij}f_{ij}\), where \(a_{ij}\) is the corresponding entry of \(\) and \(f_{ij}\) is sampled from a set of Beta distributions, with different hyperparameters \(_{f}\). Note that these choices restrict the values of the transition rates within the ensemble to the interval \((0,1)\) and hence, they restrict the number of _resolvable transitions_ within the time horizon \(T\) of the simulation. We refer the reader to Appendix B, where we specify the prior \(p(,_{f})=p()p(_{f})\) and its consequences, as well as give details about the sampling procedure. We also discuss the main limitations of choosing a Beta prior over the transition rates in Section 6.

**Distribution over observation grids**. The distribution \(p_{}(_{1},,_{l}|_{})\), with hyperparameter \(_{}\), gives the probability of observing the MJP at the times \(_{1},,_{l}\), and thus encodes our uncertainty about the recording process. Given that we do not know a priori whether the data will be recorded regularly or irregularly in time, nor we know its recording frequency, we define this distribution to cover both regular and irregular cases, as well as various recording frequencies. Note that the number of observation points on the grid is variable. Please see Appendix B for details.

**Distribution over noise process**. Just as the (instantaneous) solution of the master equation \(p_{}(x|t,,_{0})\), the noise distribution \(p_{}(x^{}|x,_{x})\), with hyperparameter \(_{x}\), is defined over the set of metastable states \(\). Recall that FIM solves the MJP inference problem directly in coarse-grained space. The noise distributions then encodes both, possible measurement errors that propagate through the coarse-grained representation, or noise in the coarse-grained representation itself. We provide details of its implementation in Appendix B.

We use the generative model, Eq. 2 above, to generate \(N\) MJPs, taking values on state spaces with sizes ranging from 2 to \(C\). We then sample \(K\) paths per MJP, with probability \(p(K)\), on the interval \([0,T]\). The \(j\)th instance of the dataset thus consists of \(K\) paths and is given by

\[_{j} p_{}(|_{j}, _{fj}),_{0j} p(_{0}|_{0}),(_{j},_{fj}) p(,_{f}),\] \[\{X_{jk}(t)\}_{k=1}^{K}(_{j},_{0j}),\] (3) \[\{x_{jki}^{} p_{}(x^{}|X_{ jk}(_{jk}))\}_{(k,i)=(1,1)}^{(K,l)},\{_{jk1},,_{jkl}\}_{k=1}^{K} p_{}(_{1}, ,_{l}|_{}),\]

where Gillespie denotes the Gillespie algorithm we use to sample the MJP paths (see Algorithm 1). Note that we make the number of paths (\(K\) above) per MJP random, because we do not know a priori how many realizations (_i.e._ experiments), from the empirical process of interest, will be available at the inference time. We refer the reader to Appendix B for additional details.

Figure 2 illustrates the complete data generation process.

### Supervised Recognition Model

In this subsection we introduce a neural recognition model that processes a set of \(K\) time series of the form \(\{(x_{k1}^{},_{k1}),,(x_{kl}^{},_{kl})\}_{k=1}^{K}\), as generated by the procedure in Eq. 3 above, and estimatesthe intensity rate matrix \(\) and initial distribution \(_{0}\) of the hidden MJP. Practically speaking, we would like the model to be able to infer MJPs from time series with observation times _on any scale_. To ensure this, we first normalize all observation times to lie on the unit interval, by dividing them by the maximum observation time \(_{}=\{_{k1},,_{kl}\}_{k=1}^{K}\), and then rescale the output of the model accordingly (see Appendix C for details).

Let us use \(\), \(\) and \(\) to denote feed-forward, sequence processing networks, and attention networks, respectively. Thus \(\) can denote _e.g._ LSTM or Transformer networks, while \(\) can denote _e.g._ a self-attention mechanism. Let us also denote the networks' parameters with \(\).

We first process each time series with a network \(_{1}\) to get a set of \(K\) embeddings, which we then summarize into a global representation \(_{}\) through the attention network \(_{1}\). In equations, we write

\[_{}=_{1}(_{1},,_{K },)\;\;\;\;_{k}=_{1}(x^{}_{k 1},_{k1},,x^{}_{kl},_{kl},)\;\;\;k=1,,K.\] (4)

Next we use the global representation to get an estimate of the intensity rate matrix, which we artificially model as a Gaussian variable with positive mean, and the initial distribution of the hidden MJP as follows

\[}=(_{1}(_{},)), \,}=(_{2}(_{},))\;\; }_{0}=_{3}(_{},),\] (5)

where the exponential function ensures the positivity of our estimates, and the variance is used to represent the model's _uncertainty_ in the estimation of the rates (Seifner et al., 2024). The right panel of Figure 2 summarizes the recognition model, and Appendix C provides additional information about the inputs to, outputs of and rescalings done by the model.

**Training objective**. We train the model to maximize the likelihood of its predictions, taking care of the exact zeros (_i.e._ the missing links) in the data. To wit

\[ =\] (6) \[-}_{_{0} p} _{i=1}^{C}_{i0}_{i0}},\]

where the second term is nothing but the mean-squared error of the predicted rates \(_{ij}\) (and its standard deviation) when the corresponding link is missing, and can be understood as a regularizer with weight \(\). The latter is a hyperparameter.

**FIM context number**. During training, FIM processes a variable number \(K\) of time series, which lies on the interval \([K_{},K_{}]\). Similarly, each one of these time series has a variable number \(l\) of observation points, which lies on the interval \([l_{},l_{}]\). We shall say that FIM needs a bare minimum of \(K_{}l_{}\) input data points to function. Perhaps unsurprisingly, we have empirically seen that FIM perform bests when processing \(K_{}l_{}\) data points. Going significantly beyond this number seems nevertheless to decrease the performance of FIM. We invite the reader to check Appendix D for details.

Let us define then, for the sake of convenience, the FIM context number \(c(K,l)=Kl\) as the number of input points4 FIM makes use of to estimate \(\) and \(_{0}\).

## 4 Experiments

In this section we test our methodology on five datasets of varying complexity, and corrupted by noise signals of very different nature, whose hidden MJPs are known to take values in state spaces of different sizes. In what follows we use _one and the same_ (pretrained) FIM to infer hidden MJPs from all these datasets, _without any parameter fine-tuning_. Our FIM was (pre)trained on a dataset of 45K MJPs, defined over state spaces whose sizes range from 2 to 6. A maximum of (\(K=\))300 realizations (paths) _per MJP_ were observed during training, everyone of which spanned a time-horizon \(T=10\), recorded at a maximum of 100 time points, 1% of which were mislabeled. Given these specifications, FIM is expected to perform best for the context number \(c(300,100)\) during evaluation. Additionalinformation regarding model architecture, hyperparameter selection and other training details can be found in Appendix D.

**Baselines**: Depending on the dataset, we compare our findings against the NeuralMJP model of Seifner and Sanchez (2023), the switching diffusion model (SDiff) of Kohs et al. (2021), and the discrete-time Markov model (VampNets) of Mardt et al. (2017).

All these baselines are trained on the target datasets.

### The Discrete Flashing Ratchet (DFR): A Proof of Concept

In statistical physics, the ratchet effect refers to the rectification of thermal fluctuations into directed motion to produce work, and goes all the way back to Feynman (Feynman et al., 1965). Here we consider a simple example thereof, in which a Brownian particle, immersed in a thermal bath at unit temperature, moves on a one-dimensional lattice. The particle is subject to a linear, periodic and asymmetric potential of maximum height \(2V\) that is switched on and off at a constant rate \(r\). The potential has three possible values when is switched on, which correspond to three of the states of the system. The particle jumps among them with rate \(f_{ij}^{}\). When the potential is switched off, the particle jumps freely with rate \(f_{ij}^{}\). We can therefore think of the system as a six-state system, as illustrated in Figure 3. Similar to Roldan and Parrondo (2010), we now define the transition rates as

\[f_{ij}^{}=(-(j-i)),\ \ \ i,j(0,1,2);\ \ \ \ f_{ij}^{}=b,\ \ \ i,j(3,4,5).\] (7)

Given these specifics, we consider the parameter set \((V,r,B)=(1,1,1)\) together with the dataset simulated by Seifner and Sanchez (2023), which consists of 5000 paths (in coarse-grained space) recorded on an irregular grid of 50 time points. The task is to infer \((V,r,B)\) from these time series. NeuralMJP infers a _global_ distribution over the rate matrices and hence relies on their entire train set, which amounts to about 4500 time series. We therefore report FIM evaluations with context number \(c(300,50)\) on that same train set, averaged over 15 (non-overlapping) batches in Table 1.

The results show that FIM performs on par with (or even better than) NeuralMJP, _despite not having been trained on the data_. Note in particular that our results are sharply peaked around their mean, indicating that a context of \(c(300,50)\) points only contains enough information to describe the data well. What is more, Table 16 in the Appendix demonstrates that FIM can infer vanishing transition rates as well (see Eq. 6). Now, being able to infer the rate matrix in zero-shot mode allows us to immediately estimate a number of observables of interest _without any training_. Stationary distributions, relaxation times and mean first-passage times (see Appendix A for their definition), as well as time-dependent moments, can all be computed zero-shot via FIM. For example, we report on the left block of Figure 4 the time-dependent class probabilities (_i.e._ the master eq. solutions) computed with the FIM-inferred rate matrix (black), against the ground-truth solution (blue). The agreement is very good.

**Zero-shot estimation of entropy production**. The DFR model is interesting because the random switching combined with the asymmetry in the potential make it more likely for the particle to jump towards the right (see Figure 4). Indeed, that is the ratchet effect. As a consequence, the system features a stationary distribution with a net current -- the so-called _non-equilibrium steady state

    & \(V\) & \(r\) & \(b\) \\  Ground Truth & \(1.00\) & \(1.00\) & \(1.00\) \\  NeuralMJP & \(\) & \(1.17\) & \(1.14\) \\ FIM & \(1.11(7)\) & \(\) & \(\) \\   

Table 1: Inference of the discrete flashing ratchet process. The FIM results correspond to FIM evaluations with context number \(c(300,50)\), averaged over 15 batches.

Figure 3: Illustration of the six-state discrete flashing ratchet model. The potential \(V\) is switched on and off at rate \(r\). The transition rates \(f_{ij}^{},f_{ij}^{}\) allow the particle to propagate through the ring.

(Ajdari and Prost, 1992), which is characterized by a non-vanishing (stochastic) entropy production. The development of (neural) estimators of entropy production is a very active topic of current research (see _e.g._ Kim et al. (2020) and Otsubo et al. (2022)). Given that the entropy production can be written down in closed form as a function of both the rate matrix and the master eq. solution (see _e.g._ Seifert (2012)), we can readily use FIM to estimate it.

Figure 4 displays the total entropy production computed with FIM for a set of different potentials. The results are averaged over 15 FIM evaluations with \(c(300,50)\) and are again in very good agreement with the ground truth. It is noteworthy that FIM, trained on our heuristically constructed dataset, captures well _a continuous set of MJPs_. That is, we evaluate _one and the same_ FIM over different datasets, each sampled from a DFR model with a different potential value. In sharp contrast, state-of-the-art models need to be _retrained_ for every new potential value (Kim et al., 2020).

**Zero-shot simulation of the DFR process**. Inferring the rate matrix and initial condition of a MJP process entails that one can also _sample from it_. Our FIM can thus be used as a _zero-shot generative model_ for MJPs. However, to test the quality of said MJP realizations wrt. some target MJP, we need a distance between the two. Here we propose to use the Hellinger distance (Le Cam and Yang, 2000) to first estimate the divergence between a sequence of (local) histogram pairs, recorded at a given set of observation times, and then average the local estimates along time. Appendix F.1 empirically demonstrates that this pragmatically defined MJP distance is sensible.

Table 2 reports the time-averaged Hellinger distance between 1000 (ground-truth) DFR paths and 1000 paths sampled from (the MJPs inferred by) NeuralMJP and FIM. We repeat this calculation 100 times, for 1000 newly sampled paths from NeuralMJP and FIM, but the same 1000 target paths, to compute the mean values and error bars in the Table. The results show that the zero-shot DFR simulation obtained through FIM is on par with the NeuralMJP-based simulation, wrt. the ground truth.

### Switching Ion Channel (IonCh): Zero-Shot Inference of Three-State MJP

In this section we study the conformational dynamics of the viral ion channel KcvMT325, which exhibits three metastable states (Gazzarrini et al., 2006). Specifically, we analyse the ion flow across the membrane as the system jumps between its metastable configurations. This ion flow was recorded at a frequency of 5kHz over one second. Figure 1 shows one snapshot of these recordings, which were made available to us via private communication (see the Acknowledgements). Our goal is to infer physical observables -- like the stationary distribution and mean first-passage times -- of the conformational dynamics, and to compare our findings against the SDiff model of Kohs et al. (2021) and NeuralMJP.

The recordings live in real space, which means that we first need to obtain a coarse-grained representation (CGR) from them, before we can apply FIM. Here we consider two CGRs: the CGR inferred

Figure 4: Zero-shot inference of DFR process. _Left_: master eq. solution \(p_{}(x,t)\) as time evolves, wrt. the (averaged) FIM-inferred rate matrix is shown in black. The ground-truth solution is shown in blue. _Right_: Total entropy production computed from FIM (over a time-horizon \(T=2.5[a.u.]\)). The model works remarkably well for a _continuous range_ of potential values.

by NeuralMJP and a naive CGR obtained with a Gaussian Mixture Model (GMM). Given that we only have 5000 observations available, we make use of a single FIM evaluation with context number \(c(50,100)\). We infer two FIM rate matrices, one per each CGR, which we label as FIM-NMJP and FIM-GMM.

Table 3 contains the inferred stationary distributions from all models and evidences that a single FIM evaluation is enough to unveil the long-time asymptotics of the process. Similarly, Table 15 in the Appendix, which contains the inferred mean-first passage times, demonstrates that FIM makes the same inference about the short-term dynamics of the process as do SDiff and NeuralMJP. See Appendix F for additional results.

**Zero-shot simulation of switching ion channel process**. Just as we did with the DFR process, we can use FIM to simulate the switching ion channel process in coarse-grained space. Since only paths on the same CG space can be compared, we evaluate NeuralMJP against FIM-NMJP. To construct the target distribution, we leverage another 30 seconds of measurements, which amount to 150K observations that have not been seen by any of the models. The results in Table 2 indicate that our zero-shot simulations is statistically closer to the ground-truth process than the NeuralMJP simulation.

### Alanine Dipeptide (ADP): Zero-Shot Inference of Six-State MJP

Alanine dipeptide is 22-atom molecule widely used as benchmark in molecular dynamics simulation studies. Its popularity stems from the fact that the heavy-atom dynamics, which jumps between six metastable states, can be fully described in terms of the dihedral (torsional) angles \(\) and \(\) (see _e.g._Mironov et al. (2019) for details).

We examine an all-atom ADP simulation of 1 microsecond, which was made available to us via private communication (see the Acknowledgements below), and compare against both, the VampNets model of Mardt et al. (2017) and NeuralMJP. The data consists of the values taken by the dihedral angles as time evolves and thus needs to be mapped onto some coarse-grained space. We again make use of NeuralMJP to obtain a CGR. We then use FIM with context number \(c(300,100)\) to process 32 100-point time windows of the simulation and compute an average rate matrix. Note that this is the optimal context number of our pretrained model. Table 4 (and Appendix F.2) confirms that, once again, FIM can infer the same physical properties from the ADP simulation as the baselines.

**Zero-shot simulation of the alanine dipeptide**. Simulations in coarse-grained space for molecular dynamics is a high-interest research direction (Husic et al., 2020). Here we demonstrate that FIM can be used to simulate the ADP process in zero-shot mode. Indeed, Table 2 reports the distance from both NeuralMJP and FIM to a target ADP process, computed from 200 paths with 100 observations each. Once more, FIM performs comparable to NeuralMJP.

### Zero-Shot Inference of Two-State MJPs

Finally, we consider two additional systems that feature jumps between two metastable states: a simple protein folding model and a two-mode switching system. We invite the reader to check out Appendix F.5 and F.6 for the details. That being said, Table 8 reports the distance of both NeuralMJP and FIM wrt. the empirical protein folding process (PFold). The high variance indicates that the distance cannot resolve any difference between the processes given the available number of samples.

   Dataset & NeuralMJP & FIM \\  DFR & \(0.30(0.06)\) & \(0.27(0.06)\) \\ IonCh & \(0.48(0.02)\) & \(()\) \\ ADP & \(1.38(0.52)\) & \(1.39(0.47)\) \\ PGold & \(0.015(0.015)\) & \(0.014(0.014)\) \\   

Table 2: Time-averaged Hellinger distances between empirical processes and samples from either NeuralMJP or FIM [in a 1e-2 scale] (lower is better). Mean and std. are computed from a set of 100 histograms

    & Bottom & Middle & Top \\  SDiff & 0.17961 & 0.14987 & 0.67052 \\ NeuralMJP & 0.17672 & 0.09472 & 0.72856 \\ FIM-NMJP & 0.18224 & 0.10156 & 0.71621 \\ FIM-GMM & 0.19330 & 0.08124 & 0.72546 \\   

Table 3: Stationary distribution inferred from the switching ion channel experiment. FIM-NMJP and FIM-GMM correspond to our inference from different coarse-grained representations. The results agree well.

## 5 Conclusions

In this work we introduced a novel methodology for zero-shot inference of Markov jump processes and its Foundation Inference Model (FIM). We empirically demonstrated that _one and the same_ FIM can be used to estimate stationary distributions, relaxation times, mean first-passage times, time-dependent moments and thermodynamic quantities (_i.e._ the entropy production) from noisy and discretely observed MJPs, taking values in state spaces of different dimensionalities, _all in zero-shot mode_. To the best of our knowledge, FIM is also the first zero-shot generative model for MJPs.

_Future work_ shall involve extending our methodology to Birth and Death processes, as well as considering more complex (prior) transition rate distributions. See our discussion on Limitations in the next section, for details.

## 6 Limitations

The main limitations of our methodology clearly involve our synthetic distribution. Evaluating FIM on empirical datasets whose distribution significantly deviates from our synthetic distribution will, inevitably, yield poor estimates. Consider Figure 4 (right), for example. The performance of FIM quickly deteriorates for \(V 3\), for which the ratio between the largest and smallest rates gets larger than about three orders of magnitude. These cases are unlikely under our prior Beta distributions, and hence effectively lie outside of our synthetic distribution.

More generally, the MJP dynamics underlying phenomena that feature long-lived, metastable states, ultimately depends on the shape of the energy landscape characterizing the set \(\), inasmuch as the transition rates between metastable states \(i\) and \(j\) (\(f_{ij}\) in our notation) are characterized by _the depth of the energy traps_ (that is, the height of the barrier between them).

In equations, we write

\[f_{ij}=(}{T}),\] (8)

where \(E_{j}\) is the \(j\)th trap depth, and \(T\) is the temperature of the system. Therefore, the distribution over energy traps determines the distribution over transition rates.

Just to give an example, if we studied systems with exponentially distributed energy traps -- as _e.g._ in the classical Trap model of glassy systems of Bouchaud (1992) -- we would immediately find \(p(f) Tf^{T-1}\). Transition rates sampled from such power-law distributions clearly lie outside our ensemble of Beta distributions, even if we use our rescaling trick. Future work shall explore training FIM on synthetic MJPs featuring power-law-distributed transition rates.