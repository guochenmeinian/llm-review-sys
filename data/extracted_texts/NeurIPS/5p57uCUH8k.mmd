# CLODE: Continuous Exposure Learning for Low-light Image Enhancement using Neural ODEs

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Low-light image enhancement poses a significant challenge due to the limited information captured by image sensors in low-light environments. Despite recent improvements in deep learning models, the lack of paired training datasets remains a significant obstacle. Therefore, unsupervised methods have emerged as a promising solution. In this work, we focus on the strength of curve-adjustment-based approaches to tackle unsupervised methods. The majority of existing unsupervised curve-adjustment approaches iteratively estimate higher order curve parameters to enhance the exposure of images while efficiently preserving the details of the images. However, the convergence of the enhancement procedure cannot be guaranteed, leading to sensitivity to the number of iterations and limited performance. To address this problem, we consider the iterative curve-adjustment update process as a dynamic system and formulate it as a Neural Ordinary Differential Equations (NODE) for the first time, and this allows us to learn a continuous dynamics of the latent image. The strategy of utilizing NODE to leverage continuous dynamics in iterative methods enhances unsupervised learning and aids in achieving better convergence compared to discrete-space approaches. Consequently, we achieve state-of-the-art performance in unsupervised low-light image enhancement across various benchmark datasets.

## 1 Introduction

Images taken in various low-light environments suffer from insufficient light, leading to the capture of limited information by the camera's image sensor. Therefore, many studies have been conducted to improve the quality of the low-light images and achieve images with optimal exposure levels. In particular, recent supervision-based deep learning approaches [1; 2; 3] have shown remarkable performance in enhancing low-light images. However, the process of collecting pairs of low-light scenes and their corresponding ground-truth images for supervised learning is time consuming and resource intensive. As a result, unsupervised approaches that rely solely on low-light images have been proposed to address this problem.

Among many unsupervised low-light image enhancement approaches, curve-adjustment-based methods, conventionally used in photo editing software (_e.g._, Photoshop), have received much attention. After the introduction of first learning-based curve-adjustment work by Yuan and Sun , iterative curve-adjustment-based methods have been explored in various subsequent studies. These unsupervised methods achieve enhancement without using the ground-truth images by fitting the brightness values of pixels in the input image to specific curves. In addition, it is advantageous to preserve local structural information adaptively by allowing efficient pixel-by-pixel computations. For example, ZeroDCE [6; 8] introduced a fast and lightweight neural network to predict pixel-wise curve parameter maps within a fixed iteration step. In addition, ReLLIE  produced more accurateimage enhancement results by using reinforcement learning to predict the curve parameter map at each iteration step, with users able to adjust the number of iterations.

In general, these curve-adjustment-based methods, which have fewer parameters, offer the advantage of fast and efficient training and also demonstrate the effectiveness of using higher-order curves for low-light image adjustment. However, conventional iterative approaches in discrete-space with fixed update steps do not arrive at the optimal solution and cannot guarantee convergence of the optimization. Therefore, we alleviate this problem in the discrete-space updating process of existing methods. In doing so, we bring out the strengths of curve fitting methods by reformulating the iterative update formula into ordinary differential equations, which allows the iterative approach to be transformed from discrete-space to continuous-space and find input-specific higher-order curves until convergence within a specified tolerance. To be specific, we present the Neural Ordinary Differential Equations (NODE) model for the low-light enhancement task for the first time. By solving the NODE problem using conventional ODE solvers, we obtain better approximate solutions to the curve-adjustment problem, producing more accurate results than conventional results from iterative updates in discrete-space by exploring the continuous exposure dynamics. In this work, we introduce Continuous exposure learning for Low-light image enhancement using neural Ordinary Differential Equations (**CLODE**), which is the first dynamic system for low-light image enhancement. Our main contributions can be summarized as follows:

* CLODE is the first approach to formulate the higher-order curve estimation problem as a NODE problem, enabling effective and accurate solutions with standard ODE solvers.
* By transforming the discrete update formula into NODE, which is solvable in continuous-space, we significantly enhance the unsupervised low-light image enhancement results across various benchmark datasets as shown in Fig. 1. This effectively bridges the performance gap between supervised and unsupervised approaches.
* CLODE also offers user controllability without altering the network architecture, enabling users to manually adjust the desired level of exposure as needed.

## 2 Related works

### Unsupervised Low-light Image Enhancement

Obtaining well-exposed ground-truth images paired with corresponding low-light images is inherently challenging, which limits the use of supervised learning in low-light image enhancement. To address this limitation, many unsupervised methods have been developed to tackle the problem. First, there are some approaches [10; 11; 12; 13] that utilize the principles of retinex-theory. Among them, PairLIE  utilizes retinex-theory to identify the reflectance and illumination, and employs gamma correction with user-defined gamma values to enhance the illumination. In addition, UDCN  and HEP  use histogram equalization results as a reference for exposure enhancement. Moreover, recent approaches using GANs have shown remarkable improvements by additionally utilizing unpaired images of normal exposed [16; 17]. Lastly, there are curve-adjustment-based methods [6; 8; 18; 9] that transform images through tone mapping. These methods have advanced the curve-fitting techniques from traditional editing tools into deep learning-based approaches, enhancing images by predicting the fitting curves pixel-by-pixel. By repeating the pixel-wise curve fitting and exposure enhancement for a fixed number of iterations in discrete-space, these approaches aim to handle locally varying exposure levels (_i.e._, single image with both underexposed and overexposed areas) in an unsupervised manner. Our CLODE also follows this unsupervised curve-adjustment-based method

Figure 1: **(a)** Quantitative Evaluation: The average PSNR values on the LSRW  and LOL , together with the respective parameter numbers for each model. **(b)** Visual Comparisons with ZeroDCE  (_unsupervised_), RetinexFormer  (_supervised_) and proposed CLODE (_unsupervised_).

and reformulates the curve-fitting problem into a neural ordinary differential equation (NODE). By solving the NODE problem using conventional ODE solvers, we increase the accuracy of curve fitting and thus significantly improve the performance of low-light image enhancement.

### Neural Ordinary Differential Equations

An ordinary differential equation (ODE) is a fundamental concept in mathematics that describes how a function changes with respect to a single variable. It captures the relationship between a function and its derivatives, providing a powerful tool for modeling dynamic systems, such as Newton's Second Law of Motion. To effectively apply the strength of ordinary differential equations to the deep learning model, the concept of neural ordinary differential equations (NODE) is introduced in . The use of NODE facilitates model definition and evaluation, highlighting its effectiveness in parameter efficiency, adaptive computation, and modeling continuous data. In order to effectively capture more complicated functions, the Augmented Neural ODE (ANODE)  has been introduced. Furthermore, for seamless continuous time-series modeling, Latent ODE  is proposed and recently, ClimODE  proposed a continuous-time NODE models for numerical weather prediction. To be specific, in the field of computer vision, the Vid-ODE approach  has been introduced to generate continuous-time videos. NODEO  has presented a versatile architecture tailored for deformable image registration, and a temporal deformation model using the capabilities of NODE has been developed in  to address the challenges associated with future prediction tasks in the context of 4D reconstruction. With advantages like continuous-space modeling, adaptive computation, and memory efficiency, NODE  is utilized in various deep learning tasks. However, it has not been extensively explored in the field of image restoration. While NODE-SR  has been introduced to address the arbitrary scale super-resolution problem, our methodology marks the first application in image exposure enhancement. In contrast to NODE-SR , which learns the continuous variation of the scaling factor for the arbitrary scale super-resolution problem, our CLODE learns the continuous variation of image exposure through curve-adjustment.

## 3 Proposed Method

### Preliminary

In photo editing applications, the curve-adjustment method is often used to adjust the tone of input images and provides effective exposure control. While this method is useful for pixel-wise manipulation, it is not well suited for images that contain areas of extreme over- or under-exposure. Additionally, a notable drawback of this approach is its reliance on manual adjustments (_e.g._, the number of updates) by the user for each input image. This can be time-consuming and potentially less accurate in certain scenarios. To address this problem, Yuan and Sun  have proposed a solution that aims to mitigate the limitations of manual adjustments. They introduced an automated approach that involves estimating an image-specific _S_-shaped nonlinear tone curve (referred to as an _S_-curve) tailored to each input image. Specifically, for a given low-light image \(I_{0}\), where each pixel value is in the range , the _S_-curve formula for the enhanced image \(I_{0}^{{}^{}}\) can be represented as follows:

\[I_{0}^{{}^{}}=I_{0}+_{s} P_{}(I_{0})-_{h} P_{ }(1-I_{0}),\] (1)

where \(_{s}\) and \(_{h}\) represent parameters for the amount of shadow and highlight, respectively. The function \(P_{}\) serves as an increasing function for the adjustment that manipulates the intensity of individual pixels within the input of the function.

While Eq.1 allows for adjusting the brightness of an entire image using a single global curve parameter, existing iterative curve-adjustments approaches  operate on a pixel-wise basis of the input images. Furthermore, they introduce the necessity of higher-order curves, which enhances images by fitting higher-order curves for fixed iteration steps while using a deep learning model to predict curve parameters on a pixel-by-pixel basis. Specifically the update formula enhances an image \(I_{n}\) at the \(n\)-th step to an image \(I_{n+1}\) at the next step as follows:

\[I_{n+1}=I_{n}+_{n} I_{n}(1-I_{n}),\] (2)

where \(_{n}^{C H W}\) represents a pixel-wise varying curve parameter map and \(C\), \(H\), and \(W\) represent the number of channels, height, and width of the image \(I_{n}\), and \(\) operation denotes element-wise multiplication. Note that, the elements of \(_{n}\) corresponding to the curve parameters at each pixel location are in the range \([-1,1]\) and determine the quadratic curve for the pixel-wise exposure adjustment during the enhancement process. Conventional curve-adjustment methods [6; 8; 9; 18] iteratively follow this process for \(N\) times, fitting an appropriate higher-order curve to produce the final well-exposed output image. On the contrary, our CLODE performs curve adjustment for image enhancement by reformulating Eq. 2 as an ordinary differential equation. This approach facilitates memory-efficient training and yields more accurate results through adaptive computation using modern ODE solvers.

### Continuous Exposure Learning for Low-light Image Enhancement using Neural ODEs

Although conventional curve-adjustment-based iterative methods offer advantages in terms of lightweight network architecture and local robustness, these approaches cannot guarantee convergence of the update process. ZeroDCE  empirically determines the iteration number \(N\) and enhances low-light images by iterating the curve-adjustment formula 8 (=\(N\)) times. While ReLLIE  provides users with optional flexibility, it requires manual selection of the value of \(N\) for each input image to further improve image quality. To tackle this challenge in optimization, we reformulate the curve-adjustment-based formula outlined in Eq. 2 as a Neural Ordinary Differential Equations (NODE). Then, we can solve the NODE with conventional ODE solvers (_e.g._, Euler, RK4, dopri5) which guarantees the convergence of loss within tolerances. Specifically, we reformulate the original curve-adjustment-based formula by introducing a continuous state \(t\) instead of using the discrete state \(n\) as follows:

\[I_{t+1}=I_{t}+f_{}(I_{t},t),\] (3)

where \(f_{}\) is a neural network with trainable parameters \(\) that satisfies \(f_{}(I_{t},t)=_{t} I_{t}(1-I_{t})\). Then, we can parameterize the derivative of the enhanced image during the update using the network \(f_{}\) if the continuous update step is very small, and it is given by,

\[}{dt}=f_{}(I_{t},t).\] (4)

By transforming the original curve fitting problem into a NODE problem with an initial condition \(I_{0}\), we can estimate not only the derivative value of each state but also recover the enhanced image by solving the problem, and the initial value problem is given by,

\[I_{T}=I_{0}+_{0}^{T}f_{}(I_{t},t)dt,\] (5)

where \(I_{T}\) denotes the well-exposed image at the final state \(T\). Finally, the low-light image enhancement process to output \(I_{T}\) is accomplished by using the ODE solver as:

\[I_{T}=(I_{0},[0,T],f_{}),\] (6)

where **ODE_Solver** denotes a conventional algorithm for solving the ordinary differential equations. In our experiments, CLODE adopts the well-known dopri5 (Dormand-Prince 5th order Runge-Kutta) as an adaptive ODE solver, that determines an input-specific number of iterations for each input and dynamically adjusts the step size. Using the adaptive solver, we can adaptively compute the optimal state for different exposure levels, thereby enabling a more accurate approximation of the solution. This is in contrast to conventional methods, which use the same fixed number of iterations for all input images and cannot guarantee optimality and convergence. To the best of our knowledge, our approach is the first to define the low-light image enhancement problem as a novel NODE problem with an initial condition.

Figure 2: **(a) Illustration of continuous update procedure of CLODE. Optimal iterative update can be achieved through the ODE equation. (b) Illustration of our ODEfunc \(f_{}\). ODEfunc contains the Noise Removal (\(g\)), Curve Parameter Estimation (\(h\)) module, and Eq. 9 to obtain the derivative value. Please refer to Appendix A.1.2 for more details.**

#### 3.2.1 ODE function (ODEfunc)

We can solve the NODE problem in Eq. 5 by integrating \(f_{}\) over the time interval \([0,T]\) with the given initial value \(I_{0}\) (e.g., a low-light image). In practice, conventional ODE solvers are used to address this problem, iteratively enhancing the low-light images using Eq. 3. In Fig. 2(a), we illustrate the continuous update procedure of our CLODE approach. Notably, the ODE function (ODEfunc) \(f_{}\) computes continuous dynamics of the latent image and is a key element in the update procedure. The detailed configuration of our ODEfunc \(f_{}\) is shown in Fig. 2(b). To be specific, our ODEfunc includes Noise Removal (\(g\)) and the Curve Parameter Estimation (\(h\)) modules with trainable parameters, and outputs \(}{dt}\), the continuous dynamics of \(I_{t}\). Please refer to Appendix A.1.2 for more details.

Noise RemovalIn the ODEfunc, we first employ a pre-processing step to eliminate the artifacts from \(I_{t}\) and generate the denoised image \(_{t}\) in order to produce more accurate curve adjustment parameters \(_{t}\). To minimize computational costs within the \(f_{}\), we employ a simple and lightweight three-layer convolutional neural network \(g\) as our Noise Removal module, expressed as follows:

\[_{t}=g(I_{t}).\] (7)

The refined image \(_{t}\) is then used as the input to the subsequent Curve Parameter Estimation stage.

Curve Parameter EstimationInspired by [7; 28], to enhance both under- and over- exposed areas, we not only use the denoised image \(_{t}\) and its inverted version \((1-_{t})\) as inputs to the Curve Parameter Estimation module. The formulation is given by:

\[_{t}=h(_{t},1-_{t}),\] (8)

where \(_{t}\) represents the curve parameter map at \(t\), and \(h\) represents the Curve Parameter Estimation module. For efficacy, this module is also a lightweight convolutional neural network. In particular, we apply layer normalization  to all intermediate features. Notably, the use of layer normalization enables CLODE to handle the diverse exposure ranges of input images. Furthermore, all convolutional layers within the Curve Parameter Estimation module \(h\) take the continuous state \(t\) as a conditional input, allowing for time-varying outputs during the integration interval \([0,T]\) as in .

Continuous DynamicsLastly, the derivative value of the one-step state at \(t\) is computed in our ODEfunc, and it is expressed as follows:

\[}{dt}=_{t} I_{t}(1-I_{t}).\] (9)

Notably, unlike conventional curve-adjustment-based update formulas that discretize update steps, our continuous dynamics allows the desired level of accuracy and produces more accurate solutions.

### Inference Process of CLODE

Inference ProcessGiven a low-light input image \(I_{0}\), CLODE undergoes successive image enhancement through \(f_{}\) until convergence within the specified tolerance of the ODE solvers, resulting in a well-exposed image \(I_{T}\). Note that, the output image \(I_{T}\) may contain some noise that is amplified during the image enhancement process. Therefore, we use the noise-free image \(_{T}\) as our final outcome by applying the Noise Removal module \(g\).

User Controllable DesignCLODE learns the low-light exposure adjustment mechanism in the continuous-space, and is trained to output \(I_{T}\) by integrating the states from \(0\) to \(T\) in Eq. 5 using a fixed \(T\). However, as shown in Fig. 3, users can manually adjust the integration interval by changing the final state \(T\) at the test stage, allowing them to output images with the preferred exposure level and even produce images darker than the input. In practice, by controlling the final state from \(-(T+ t)\) to \((T+ t)\), the exposure level of the output image can be easily controlled to provide a more user-friendly exposure level.

Figure 3: **Illustration of User Controllable Design**. By manually changing the integration interval from \(-(T+ t)\) to \(+(T+ t)\), ours can produce results with different exposure levels.

### Zero-Reference Loss Functions

To address the challenge posed by the lack of ground truth, we use five zero-reference loss functions for unsupervised training.

Spatial Consistency LossWhile the given low-light input image \(I_{0}\) is enhanced during the update procedure, maintaining spatial consistency in the pixel brightness order is crucial for preserving image details. Specifically, we measure the difference in spatial consistency between the input image \(I_{0}\) and our prediction \(I_{T}\) by comparing the differences in neighboring pixel values. Similar to , we compute the spatial consistency after applying 4-by-4 average pooling to both \(I_{0}\) and \(I_{T}\), and the spatial consistency loss \(_{spa}\) is expressed as:

\[_{spa}=_{i=1}^{K}_{j(i)}(|m_{4}(I_{T})_ {i}-m_{4}(I_{T})_{j}|-|m_{4}(I_{0})_{i}-m_{4}(I_{0})_{j}|)^{2}.\] (10)

The 4-by-4 average pooling operation is denoted as \(m_{4}()\) and \((i)\) includes neighboring pixels in four directions (left, right, top, bottom) centered at position \(i\). The normalization factor \(K\) denotes the number of pixels in the reduced image after the pooling operation, and \(K\) is given by \( C\).

Exposure LossTo enforce a consistent exposure level across pixels, conventional unsupervised methods incorporate exposure guidance into the loss function . Similarly, we introduce a desired exposure level parameter \(\) and define the exposure loss \(_{exp}\) as:

\[_{exp}=||m_{16}(I_{T})-||_{2}^{2}.\] (11)

In our experiments, we set the exposure level \(\) to 0.6, which corresponds to the gray level in the RGB color space. To maintain the overall exposure level in the results, we minimize the difference between the pixel values of the predicted image \(I_{T}\) and the desired exposure level \(\) after performing a 16-by-16 average pooling operation \(m_{16}()\) on the output image \(I_{T}\).

Color Constancy LossIn conventional zero-reference methods, two main approaches are used to enforce spatial color constancy: one based on the retinex-theory, and the other based on the Gray-World hypothesis in . In this work, the color constancy loss \(_{col}\) is based on the Gray-World hypothesis as in [6; 15], and the formulation is given by,

\[_{col}=(R-B)^{2}+(R-G)^{2}+(G-B)^{2},\] (12)

where \(R\), \(G\), and \(B\) are the mean pixel values of the red, green, and blue channels in the predicted image \(I_{T}\), respectively. We minimize the color constancy loss \(_{col}\) to correct the potential color deviations in the enhanced image.

Parameter Regularization LossTo prevent rapid changes of pixel values in nearby regions, we employ the spatial regularization to enforce smoothness among neighboring curve parameter values in \(_{t}\), and the formulation is given by,

\[_{param}=(|_{x}_{0}|+|_{y}_{0}|) ^{2}++(|_{x}_{T-1}|+|_{y}_{T-1}|)^{2},\] (13)

where the linear operations \(_{x}\) and \(_{y}\) compute the horizontal and vertical gradients from the parameter map \(_{t}\), respectively. For better understanding, we represent \(T-1\) as the stage before the final enhancement. We employ the parameter regularization loss at each update step (_e.g._, red points in Fig. 2 (a)) and accumulate the loss while solving the NODE problem.

Noise Removal LossTo estimate a spatially smooth \(_{t}\) regardless of the noise in the image \(I_{t}\), we use the Noise Removal module (\(g\)) to remove the noise. To train the Noise Removal module, we utilize a self-supervision-based loss \(_{noise}\) that follows the Noise2Noise approaches [31; 32; 33]. Specifically, we employ the loss introduced in Zeroshot-N2N . Our \(_{noise}\) has two components at state \(t\): the residual loss \(_{res}^{t}\) and the consistency loss \(_{cons}^{t}\). We minimize these losses using two different down-samplers; \(D_{1}\) and \(D_{2}\). Notably, \(D_{1}\) and \(D_{2}\) represent fixed 2D convolutional kernels: \(0.5&0\\ 0&0.5\) and \(0&0.5\\ 0.5&0\), respectively. Notably, these kernels are used for downsampling through convolutions with a stride of two. First, our \(_{res}^{t}\) fits the noise within \(I_{t}\) through a symmetric loss function similar to the approach in  and it yields:

\[_{res}^{t}=(||D_{1}(I_{t})-g(D_{1}(I_{t}))-D_{2}(I_{t})|| _{2}^{2}+||D_{2}(I_{t})-g(D_{2}(I_{t}))-D_{1}(I_{t})||_{2}^{2}).\] (14)Next, as in , \(_{cons}^{t}\) ensures spatial consistency by maintaining similarity in noise distributions, even if the order of denoising and downsampling is altered. Specifically, \(_{cons}^{t}\) also adopts a symmetric loss and is defined as at each update step (_e.g._, red points in Fig. 2 (a)):

\[_{cons}^{t}=(||D_{1}(I_{t})-g(D_{1}(I_{t}))-D_{1}(I_{t}-g (I_{t}))||_{2}^{2}+||D_{2}(I_{t})-g(D_{2}(I_{t}))-D_{2}(I_{t}-g(I_{t}))||_{2}^{ 2}).\] (15)

Therefore, our final noise removal loss \(_{noise}\) can be represented accumulating during the update procedure as:

\[_{noise}=(_{res}^{0}+_{cons}^{0})++( _{res}^{T-1}+_{cons}^{T-1}).\] (16)

As with Eq. 13, we represent \(T-1\) as the stage before the final enhancement. A more detailed description of the noise removal loss is provided in Appendix A.4.

Final Objective FunctionThe final objective function to optimize is given as follows:

\[_{total}=w_{spa}_{spa}+w_{exp}_{ exp}+w_{col}_{col}+w_{param}_{param}+w_{ noise}_{noise},\] (17)

where \(w_{spa}\), \(w_{exp}\), \(w_{col}\), \(w_{param}\), and \(w_{noise}\) are hyper-parameters used to control the relative significance of each associated loss during the training process.

## 4 Experiments

### Implementation Details

Please refer to Appendix A.1 for more implementation details and training scheme. The code will be available upon acceptance.

### Experimental Setup

In this work, we use the LOL  and SICE  Part1 datasets for training. The results of low-light image enhancement are evaluated on the LOL and LSRW  benchmark datasets. In addition, the SICE  Part2 dataset is used as a benchmark dataset for evaluation under various exposure conditions. SICE Part2 contains 229 image sequences with different exposure levels, and we use the entire sequences as the evaluation dataset. By default, each comparison model uses its official network weights. In cases where the official code is available but weights are not provided, the models are retrained using the official code and settings, except for ReLLIE . We present the performance of ReLLIE on the LOL dataset as reported in their original manuscript.

### Quantitative Comparisons

First, we quantitatively compare the performance of low-light image enhancement on different datasets. Notably, in the experimental results, CLODE represents our proposed method without requiring additional user input (by default), while CLODE\(\) represents the result of adjusting the final state \(T\) to the user's preferred level, as introduced in Sec. 3.3.

In Table 1, we compare the low-light image enhancement performance on the LSRW  and LOL  benchmark datasets in terms of peak signal-to-noise ratio (PSNR) and structural similarity (SSIM). The term "_GT Mean_" refers to the evaluation method used by Kimb  and LLFlow , which matches the average value of the output pixels to that of the ground truth pixels. CLODE and CLODE\(\) outperform other unsupervised learning methods. Notably, CLODE\(\) even surpasses the PSNR of state-of-the-art supervised learning methods by 0.73 dB, when averaging the results from the LSRW and LOL datasets in the rightmost columns, without using _GT Mean_. Moreover, two notable points can be highlighted in Table 1. First, the effectiveness of using NODE to compute accurate higher order curves is evident, as demonstrated by its superiority over curve-adjustment-based methods; ZeroDCE  and ReLLIE . Second, unlike other models trained on the same training dataset (LOL), our model shows robust performance on both the LSRW and LOL test datasets, indicating that our model generalizes better than conventional approaches.

In Table 2, we demonstrate the robustness under various exposure conditions including both under- and over- exposures, and evaluate the performance on SICE Part2 . The results show that CLODE exhibits robust performance compared to other models, even under various exposure conditions. It outperforms other unsupervised learning methods, and even when compared to supervised learning 

[MISSING_PAGE_FAIL:8]

### Ablation Study

Effectiveness of NODETo validate the impact of NODE, we adjust the curves using the architecture of CLODE in both discrete (w/o NODE) and continuous (w/ NODE) spaces, and we compare the results in Table 3. In the discrete setting, similar to , curve parameters for fixed update steps  are estimated in parallel ((a1) - (e1)). In the continuous setting, however, curve parameters are estimated sequentially for non-fixed adaptive steps, up to a maximum of 30 steps ((f1)). Results in Table 3 demonstrate that the curve parameters produced during the sequential continuous update procedure are more accurate and verify superior performance of the proposed method over the update procedure in the conventional discrete setting. In addition, in Fig. 5, we visualize the trajectories of improvement by plotting PCA dimension reduction results of latent images during updates. We observe that when curve adjustments are made in continuous space by (f1), the trajectories converge more accurately at the final states compared to (e1). This demonstrates that using NODE to find the optimal state certainly contributes to image enhancement.

Effect of the ModulesIn Table 4, we conduct ablation experiments on the modules used in ODEfunc \(f_{}\). We verify the effects of the Noise Removal module \(g\) and the layer normalization (LN) in the Curve Parameter Estimation module \(h\). Each module shows performance improvements compared to the baseline (a2). In particular, our final model (d2) achieves the largest performance gain in terms of PSNR/SSIM. Furthermore, case (c2), which includes layer normalization, has about a 4dB gain in PSNR compared to (a2), which does not include layer normalization. This shows that during the image enhancement process in NODE, it is essential to use layer normalization to normalize each state. The visual results can be seen in Fig. 8 of the Appendix.

## 5 Limitations

Table 5 shows the performance of PSNR/SSIM, number of parameters, and execution time measured in LSRW  using an NVIDIA RTX 4090. CLODE shows the advantage in model size compared to supervised methods. The iterative ODE solving process of CLODE takes longer than lightweight unsupervised models, but it exhibits faster speed and performance comparable to supervised methods. Additionally, a smaller version, CLODE-S in Appendix A.1.2 shows promising enhancement performance with competitive inference time comparable to those of unsupervised models.

## 6 Conclusions

In this work, we address the unsupervised low-light image enhancement problem by formulating it as a NODE problem. We introduce a novel iterative curve-adjustment approach with NODE, transforming discrete iterative problems into continuous ones. CLODE exhibits superior convergence compared to other unsupervised iterative methods, especially in diverse low-light and multi-exposure scenarios. In conclusion, our method effectively narrows the performance gap between unsupervised and supervised methods across various datasets.

  Case & Noise Removal \(g\) & LN in \(h\) & PSNR\(\) & SSIM\(\) \\  (a2) & & 14.72 & 0.538 \\ (b2) & ✓ & & 15.19 & 0.489 \\ (c2) & ✓ & & 18.67 & 0.577 \\ (d2) & ✓ & ✓ & 19.61 & 0.718 \\  

Table 4: Impact of the modules in \(f_{}\). Noise Removal and the layer normalization (LN) significantly improve performance.

  Method & Case & Step (\(N\)) & PSNR\(\) & SSIM\(\) & BRISQUE \\   & (a1) & 1 & 11.19/126 & 0.29/070.362 & 41.13/141.169 \\  & (b1) & 5 & 16.12/174.747 & 0.419/076.16 & 31.42/13.042 \\  & (c1) & 10 & 13.94/16.18 & 0.395/050.20 & 32.26/23.243 \\  & (d1) & 20 & 12.95/154.94 & 0.373/050.50 & 33.53/04.941 \\  & (e1) & 30 & 12.87/14.97 & 0.375/050.59 & 33.53/035.342 \\  Continuous & (f1) & \( 30\) (adaptive) & **17.28/19.61** & **0.533/0.718** & **18.42/68.220** \\  

Table 3: Comparative experiments according to using NODE on LSRW /LOL .The “Discrete” refers to performing curve adjustment in discrete steps, similar to the conventional methods , and “Continuous” refers to the reformulation of NODE.

Figure 5: Trajectories of improvement for (e1) and (f1) in Table 3. PCA dimension reduction is used to visualize the trajectories.

  Training & Method & PSNR/SSIM & \#Params (M) & Time (S) \\   & RetinexNet  & 15.49/0.355 & 0.44/46 & 0.33/ \\  & LIFlow  & 17.52/0.509 & 38.85/9 & 0.14/ \\  & ReineFormizer  & 17.70/517 & 1.60/57 & 0.072 \\   & SCL-medium  & 15.24/0.424 & 0.0003 & 0.001 \\  & RLWAS  & 14.27/0.470 & 0.0034 & 0.006 \\  & ZerQEDE  & 15.81/0.449 & 0.079/4 & 0.004 \\   & PairLE  & 16.97/0.498 & 0.34/17 & 0.008 \\   & **CLODE** & 17.28/0.533 & 0.216/ & 0.056 \\   & **CLODE-S** & 16.97/0.457 & 0.0004 & 0.005 \\  

Table 5: Execution time and performance.