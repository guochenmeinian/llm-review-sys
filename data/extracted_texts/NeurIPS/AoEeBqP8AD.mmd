# Unsupervised Anomaly Detection in The Presence of Missing Values

Feng Xiao\({}^{1}\) &Jicong Fan \({}^{1,2}\)

\({}^{1}\)The Chinese University of Hong Kong, Shenzhen, China

\({}^{2}\)Shenzhen Research Institute of Big Data, Shenzhen, China

xiaofeng.cs.ds@gmail.com &fanjicong@cuhk.edu.cn

Corresponding author

###### Abstract

Anomaly detection methods typically require fully observed data for model training and inference and cannot handle incomplete data, while the missing data problem is pervasive in science and engineering, leading to challenges in many important applications such as abnormal user detection in recommendation systems and novel or anomalous cell detection in bioinformatics, where the missing rates can be higher than 30% or even 80%. In this work, first, we construct and evaluate a straightforward strategy, "impute-then-detect", via combining state-of-the-art imputation methods with unsupervised anomaly detection methods, where the training data are composed of normal samples only. We observe that such two-stage methods frequently yield imputation bias from normal data, namely, the imputation methods are inclined to make incomplete samples "normal", where the fundamental reason is that the imputation models learned only on normal data and cannot generalize well to abnormal data in the inference stage. To address this challenge, we propose an end-to-end method that integrates data imputation with anomaly detection into a unified optimization problem. The proposed model learns to generate well-designed pseudo-abnormal samples to mitigate the imputation bias and ensure the discrimination ability of both the imputation and detection processes. Furthermore, we provide theoretical guarantees for the effectiveness of the proposed method, proving that the proposed method can correctly detect anomalies with high probability. Experimental results on datasets with manually constructed missing values and inherent missing values demonstrate that our proposed method effectively mitigates the imputation bias and surpasses the baseline methods significantly. The source code of our method is available at https://github.com/jicongfan/ImAD-Anomaly-Detection-With-Missing-Data.

## 1 Introduction

Anomaly detection (AD) [Breunig et al., 2000, Scholkopf et al., 2001, Liu et al., 2008, Pevny, 2016, Zong et al., 2018, Ruff et al., 2018, Cai and Fan, 2022, Fu et al., 2024, Zhang et al., 2024, Xiao et al., 2025], aiming at identifying anomalous or novel samples in data, is a crucial machine learning problem. It finds extensive applications in many high-stakes fields such as biology, healthcare, finance, and cybersecurity. Data missing or incompleteness, a persistent and unavoidable issue in many real-world situations, often arises during the processes of data collection, transmission, and storage. Moreover, in fields like bioinformatics (e.g. single-cell RNA sequencing) [Zhang and Zhang, 2018], psychology (e.g. questionnaire data) [Schlomer et al., 2010], and recommendation systems (e.g. user-item interaction data) [Shani and Gunawardana, 2011, Fan et al., 2024], the data missing rates are often higher than \(30\%\) or even \(80\%\). Indeed, the missing data problems lead tomany challenges for anomaly detection, such as detecting anomalous cells or rare cell types based on incomplete single-cell RNA sequencing data  and identifying abnormal users in recommendation systems . Regrettably, most existing AD methods necessitate complete data in both the training and test sets, rendering them ill-equipped to handle datasets with missing values. Consequently, addressing the AD challenge in the context of incomplete data becomes both necessary and inevitable.

A naive strategy is filling the missing values by statistical characteristics such as mean or median and then performing anomaly detection. Taking two real-world datasets "Adult" and "KDD" as examples, we consider the mechanism missing completely at random and fill the missing entries with the variable means and then perform a classical AD methods Isolation Forest ) and two deep learning based AD methods (Deep SVDD  and NeutraL AD ). The results are shown in Figure 1. The detection accuracies of the four methods degrade significantly with the missing rate increases. This verified the failure of the naive strategy and the difficulty of unsupervised anomaly detection with missing values. Besides the naive imputation, one may consider using more powerful imputation algorithms  to recover the missing values and subsequently implementing AD algorithms on imputed data. We refer to this strategy as "impute-then-detect".

It is worth noting that, for unsupervised anomaly detection, where the training set is composed of only normal samples, such "impute-then-detect" methods would yield imputation bias for normal data, i.e., the imputation methods are inclined to recover an abnormal sample with missing values as "normal" as possible during the inference, which leads to lower recall or higher false negative rate. Figure 2 clearly shows the negative impacts of the imputation bias, which is worth studying and addressing. The main challenge is that the training set and test set do not satisfy the condition of identical distribution and the imputation model trained only on incomplete normal data does not generalize well to incomplete abnormal data. In Section 4.2, we quantitatively and comprehensively evaluate the "impute-then-detect" methods using state-of-the-art imputation algorithms and AD algorithms.

To tackle the aforementioned problem, in this paper, we propose an end-to-end method, called ImAD, for unsupervised anomaly detection on incomplete data. The main idea of ImAD is to integrate data **im**putation and **a**anomaly **d**etection into a unified optimization objective and alleviate imputation bias by automatically learning to generate pseudo-abnormal samples. Note that the pseudo-abnormal samples are by-products of the training process and we do not use any extra data in all experiments. Our contributions are summarized as follows.

* We study the imputation bias problem of the "impute-then-detect" pipeline and quantitatively evaluate their detection performance.
* We propose a novel method ImAD for AD on incomplete data. To the best of our knowledge, it is the first end-to-end unsupervised AD method in the presence of missing value.
* We provide theoretical guarantees for ImAD, proving that it can correctly detect anomalies with high probability.
* We compare ImAD with more than 9 baselines on 11 real datasets of various domains, covering datasets with manually constructed missing values and datasets with inherent missing values.

Figure 1: Performance (AUROC) degradation of anomaly detection methods with increasing missing rate on Adult and KDD datasets.

Figure 2: The degradation of recall rate of abnormal data on “impute-then-detect” methods.

Related Work

Missing Data ImputationData imputation fills missing data with plausible values and provides imputed data for downstream tasks such as classification, clustering, and visualization. As the missing data problem is prevalent in many fields, the study on missing data imputation is extensive, and many algorithms have been proposed in the past decades. Mayer et al. (2019) pointed out that there are approximately 150 implementations available to handle missing data. These methods can be roughly organized into three categories. The first category is based on the iterative regression model, such as well-known methods Multiple Imputation by Chained Equations (MICE) (Royston and White, 2011) and MissForest (Stekhoven and Buhlmann, 2012) that trains random forests on observed data through an iterative imputation scheme. The second category is the matrix completion methods (Candes and Recht, 2012; Mazumder et al., 2010; Fan and Chow, 2018; Fan et al., 2019, 2020). The third category is based on deep learning especially deep generative models (Fan and Chow, 2017; Yoon et al., 2018; Li et al., 2019; Muzellec et al., 2020). For instance, Yoon et al. (2018) proposed generative adversarial imputation network (GAIN) based on generative adversarial network (GAN) (Goodfellow et al., 2014) and (Tashiro et al., 2021) proposed conditional score-based diffusion models for probabilistic time-series imputation (CSDI) based diffusion model (Sohl-Dickstein et al., 2015). Indeed, these deep imputation methods often achieve state-of-the-art performance in the tasks of missing data imputation, when the distributions of the training data and testing data are identical. However, their performance in recovering the missing values for unsupervised AD is rarely studied.

Anomaly detection on incomplete dataThe research on anomaly detection in the presence of missing values is very limited. To the best of the authors' knowledge, (Zemicheal and Dietterich, 2019) is the first work evaluating the detection performance of anomaly detection methods combined with different data imputation techniques. Their experiments of anomaly detection on a few UCI datasets with missing values showed that implementations of unsupervised anomaly detection methods such as Isolation Forest (Liu et al., 2008) on incomplete data should always include algorithms for handling missing values and the imputation contributes to improving the detection performance of anomaly methods. Fan et al. (2022) studied the problem of statistical process monitoring with missing values and proposed a fast incremental nonlinear matrix completion method for online and sequential imputation. Sarda et al. (2023) provided a study of existing unsupervised anomaly detection methods on GAN-imputed data.

It's worth noting that the strategies used in (Zemicheal and Dietterich, 2019; Fan et al., 2022; Sarda et al., 2023) are two-stage methods, where the imputation models are trained on the training dataset that does not contain any abnormal data or only contains very few unlabeled outliers. As a result, the imputation model will not generalize well on abnormal data during the inference and will use the learned pattern of normal data to fill the missing values of abnormal data, which makes the abnormal data similar to normal data and hence lowers detection accuracy. In contrast, our method integrates data imputation and anomaly detection into a unified process, and alleviates the imputation bias via introducing pseudo-abnormal samples, and hence achieves superior detection accuracy.

## 3 Proposed Method

### Problem Formulation and Our Motivation

Given \(n\) samples \(_{1},_{2},,_{n}\) drawn from an unknown distribution \(_{}^{m}\), the goal of unsupervised AD is to learn a decision function \(f:^{m}\{0,1\}\) by utilizing only these \(n\) samples, such that \(f()=0\) if \(_{}\) and \(f()=1\) if \(_{}\). We consider the scenario that \(:=[_{1}^{},_{2}^{},,_{ n}^{}]^{}^{n m}\) contains missing values. Let \(\{0,1\}^{n m}\) be a mask matrix determined by some missing mechanism \(\) such as MCAR, MAR, or MNAR, where \(M_{i,j}=1\) means \(X_{i,j}\) is observed and \(M_{i,j}=0\) means \(X_{i,j}\) is missing. Then the observed incomplete matrix is

\[}=[}_{1}^{},}_{2}^{ },,}_{n}^{}]^{}=()= \] (1)

where \(\) is the Hadamard product. Equation (1) implies that the missing values of \(\) are temporarily filled with zeros. In many scenarios such as gene expression data analysis, recommendation systems, and questionnaire surveys, the data missing rate in \(}\) is often high. Training an anomaly detection model \(f\) on \(}\) and using it to detect anomalies in new incomplete data has practical significance such as detecting anomalous cells or rare cell types in bioinformatics, identifying abnormal users in recommendation systems, and recognizing unusual subjects using questionnaires of psychology.

As mentioned before, conventional AD methods are vulnerable to missing values and a good imputation algorithm can raise the detection accuracy of an anomaly detection method to some extent. However, the strategy "impute-then-detect" is inclined to make incomplete abnormal samples normal and hence cannot provide satisfactory detection performance. Therefore, in this work, we aim to provide an end-to-end unsupervised anomaly detection method in the presence of missing values to mitigate the imputation bias and improve the detection accuracy. The most challenging problem is that the imputation model (denoted as \(\)) trained only on incomplete normal data cannot generalize well to incomplete abnormal data. To solve the challenge, we take the following strategy and consideration.

We propose to learn a model that can generate some pseudo-abnormal samples, and then learn an imputation model from both the original normal data and the generated pseudo-abnormal samples. Thus, the learned imputation model can generalize well to incomplete abnormal data during inference and recover the missing values with high accuracy, which further improves the accuracy of anomaly detection. However, we encounter the following issues.

* It is non-trivial to generate meaningful pseudo-abnormal samples that are similar enough to real ones. The reason is that the distribution (i.e., \(_{}\)) of training data is unknown and the data dimension \(m\) is often high.
* The incompleteness of \(\) further increases the difficulty of generating pseudo-abnormal samples.
* On the other hand, the generated pseudo-abnormal samples should not be too far from the normal data, where a large gap will make the learned imputation model fail to impute the abnormal samples close to normal data and cause the abnormal samples to be hard to detect.
* The generating model, imputation model, and detection model should be coordinated with each other and as a whole to ensure the reliability of the inference.

### Learning Framework of ImAD

To address the aforementioned challenges, we propose to find a \(d\)-dimensional latent space \(\) where the normal data are lying and then generate pseudo-abnormal samples around the normal samples in \(\). The samples in \(\) will be mapped back by a neural network to the original data space, yielding reliable pseudo-abnormal data.

We define \(_{}\) as the latent distribution of the normal data in \(\) and define \(_{}}\) as the latent distribution of pseudo-abnormal data in \(\). Since the patterns of normality are limited and the patterns of abnormality are unlimited, we let \(_{}\) be a truncated Gaussian distribution (a hyperball denoted by \(\), with radius \(r_{1}\)) in \(\) and assume that the remaining region of \(\) is the abnormal region, denoted as \(\). It should be pointed out that there is no need to define \(_{}}\) in the entire space \(\), which will be explained in the discussion for Theorem 3.2(b) and further supported by Theorem 3.4 in Section 3.4. Instead, we only need to define \(_{}}\) in a small region of \(\) that encloses \(\), which will reduce the uncertainty of random sampling (or samples size equivalently) and make it easier for mapping the samples back to the original data space. Thus, we define \(_{}}\) as a hypershell surrounding \(\) and let \(_{}}\) be a truncated Gaussian. The radii of the two hyperspheres forming the hypershell are \(r_{1}\) and \(r_{2}\) respectively, where \(r_{2}>r_{1}\). An illustration of \(_{}\) and \(_{}}\) in 2-D space is shown in Figure 3, where \(_{}\) and \(_{}}\) are truncated Gaussian from \((,0.5^{2}_{2})\) and \((,_{2})\) respectively. The theoretical analysis for sampling from \(_{}\) and \(_{}}\) is in Appendix A. We learn a reconstructor \(:^{d}^{m}\) to transform the samples drawn from \(_{}\) to the original data distribution \(_{}\), i.e.,

\[_{}(_{}).\] (2)

\(\) is actually a reconstruction model that recovers the original data from the latent space \(\). With \(_{}}\) and \(\), we can obtain a distribution \(_{}}\) of pseudo-abnormal data in the original data space as

\[_{}}:=(_{}}).\] (3)

The samples (denoted by \(}\)) drawn from \(_{}}\) are reasonable pseudo-abnormal samples, which will be explained by the discussion for Theorem 3.2(a) in Section 3.4.

Now we use a projector \(:^{m}^{d}\) to transform \(_{}\) and \(_{}}\) into \(_{}\) and \(_{}}\) respectively, i.e.,

\[_{}(_{}), _{}}(_{}}).\] (4)

However, the training set \(}=()\) is incomplete, and we need to learn an imputation model \(\) to recover the missing values, i.e., \(}=(})\). More generally, we denote

\[_{}}=(_{}}).\] (5)

We hope that the imputation model is also able to recover the missing values of the generated pseudo-abnormal samples if they have, though they are complete. We thus remove some values of the generated pseudo-abnormal samples \(}_{}}\) using missing mechanism \(}\) and let \(_{}}=}(_{}})\).

The missing values are then recovered by

\[_{}}=(_{}}).\] (6)

This step mitigates the problem of imputation bias encountered by the "impute-then-detect" methods. Let \(_{I}\), \(_{P}\), and \(_{R}\) denote some distance or discrepancy measure between distributions. We here show how to achieve the goals of (2), (3), (4), (5), and (6) in a unified optimization problem. First, for normal data, we solve

\[,,}{}\ _{I}( (_{}}),_{}} )+_{P}((_{}} ),_{})+_{R}(((_{}})),_{}})\] (7)

For the generated pseudo-abnormal data, we solve

\[,,}{}\ _{I} (}((_{}}))),}((_{ }}))}+_{P}( (}((_{}})) )),_{}})\] (8)

Let \(}\). be a finite-sample estimation of \(\).. Combining (7) and (8), we obtain the objective of ImAD:

\[,,}{}\ \ }_{I}( ([};}]),[}; {}][,}])}{^{()}} \ +}_{P}(([};}]),[;}])}_{^{()}} \ +}_{R}(((})),})}_{^{()}}\] (9)

where \(}=(})}\), \(}=(})\), and \([;]\) denotes the row-wise concatenation of two matrices. In (9), the samples in \(\) are drawn from \(_{}\) and the samples in \(}\) are drawn from \(_{}}\). The roles of the three parts of the objective function in (9) are analyzed as follows.

* \(^{()}\) denotes the data imputation loss. With this loss, the imputation model will be able to recover the missing values of normal data and abnormal data.

* \(^{()}\) denotes the anomaly detection loss. With this loss, the anomaly detection model will be discriminative and be able to project normal data and abnormal data into different regions in \(\).
* \(^{()}\) denotes the reconstruction loss. This loss is to ensure that \(_{}\) and \(_{}}\) are meaningful.

We see that our method ImAD couples data imputation with anomaly detection to a unified optimization objective. Figure 4 depicts the overall framework of ImAD, where the green and red arrows show the flow paths of normal data (starting from \(}\)) and pseudo-abnormal data (starting from \(}\)) respectively. The reconstructors in Figure 4 share parameters.

### Specific Implementation of ImAD

We use three neural networks \(h_{}\), \(f_{}\) and \(g_{}\) with parameters \(,,\) to model \(,\) and \(\) respectively. For \(\), we consider two different cases. If the samples are pair-wise, we directly use the square loss, which is simple and efficient. Thus, in \(^{}\) and \(^{}\), we use the square loss, and the square loss for \(^{}\) is masked by \(\). When the samples are not pair-wise, we take advantage of the Sinkhorn distance [Cuturi, 2013] derived from the optimal transport theory. The Sinkhorn distance between two distributions \(_{}\) and \(_{}\) supported by their finite samples \(=\{_{1},_{2},,_{n_{u}}\} _{u}\) and \(=\{_{1},_{2},,_{n_{v}}\} _{v}\) is defined as

\[(,):=_{}~{},_{F}+_{i,j}_{ij}(_{ij}), ~{}=,^{T}= , 0\] (10)

where \(^{n_{u} n_{v}}\) is the transport plan and \(^{n_{u} n_{v}}\) is the metric cost matrix. The two probability vectors \(\) and \(\) satisfy \(^{T}=1,^{T}=1\), and \( 0\) is a trade-off between the Wasserstein distance and entropy regularization.

By applying \(h_{},f_{},g_{}\), square loss, and Sinkhorn distance to (9), we obtain the following problem:

\[}& (f_{}(h_{}(})), )+\|}-f_{}(h_{}(g_{}(})}))\|_{F}^{2}}_{^{()}}\\ &+};}}]-h_{}([};}}])[;}]\|_{F}^{2}}_{^{()}}+}-g_{}(f_{}(h_{}(})) ))\|_{F}^{2}}_{^{()}}\] (11)

Solving the problem (11), we get well trained imputer \(h_{^{*}}\) and projector \(f_{^{*}}\). For a new sample \(}_{}\) containing missing values, we define an anomaly score \(s()\) by

\[s(}_{})=\|f_{^{*}}(h_{^{*}}(}_{}))\|,\] (12)

which is the distance to the origin in the latent space. If \(s(}_{})>r_{1}\), \(}_{}\) is detected as abnormal. Otherwise, \(}_{}\) is treated as a normal sample.

### Theoretical Guarantees for ImAD

WLOG, we assume \(f_{}\), \(g_{}\), and \(h_{}\) all have \(L\) layers, where \(=\{_{1}^{f},_{2}^{f},,_{L}^{f}\}\), \(=\{_{1}^{g},_{2}^{g},,_{L}^{g}\}\), and \(=\{_{1}^{h},_{2}^{h},,_{L}^{h}\}\). Denote the spectral norm and \(_{2,1}\)-norm of a matrix as \(\|\|_{}\) and \(\|\|_{2,1}\) respectively. We also make the following assumptions.

**Assumption 3.1**.: For \(f_{}\), \(g_{}\), and \(h_{}\), the following conditions hold: 1) \(\|_{l}^{f}\|_{}_{f}\), \(\|_{l}^{g}\|_{}_{g}\), \(\|_{l}^{h}\|_{}_{h}\), \( l[L]\); 2) \(\|_{l}^{f}\|_{2,1} b_{f}\), \(\|_{l}^{g}\|_{2,1} b_{g}\), \(\|_{l}^{h}\|_{2,1} b_{h}\), \( l[L]\); 3) all activation functions in \(f_{}\), \(g_{}\), and \(h_{}\) are \(\)-Lipschitz continuous; 4) the maximum width of the layers in \(f_{}\), \(g_{}\), and \(h_{}\) is \(\).

The following theorem can be used to obtain some deterministic guarantee for ImAD.

**Theorem 3.2**.: _Under Assumption 3.1, we have: (a) \(\|g_{}()-g_{}(})\|^{L}_{f}^{L} \|-}\|\) holds for any \(\), \(}\); (b) \(\|f_{}(h_{}(}))-f_{}(h_{}(}}))\|^{2L}_{f}^{L}_{h}^{L}\|}-}}\|\) holds for any \(}\) and \(}}\)._

Theorem 3.2(a) indicates that in the latent space \(\), if an abnormal sample \(}_{}}\) is close to a normal sample \(_{}\), in the original data space, the corresponding abnormal sample \(}\) is still close to the normal sample \(\) provided that \(_{g}\) is not too large. This means the generated pseudo-abnormalsamples are practical and useful. For Theorem 3.2(b), let's consider an incomplete abnormal sample \(}}\) and assume that its closest incomplete pseudo-abnormal sample generated by the \(}\) on the outer hypersphere (shown in Figure 3) is \(}}^{*}\), where \(\|}}-}}^{*}\|=\). Then in the latent space, we have \(\|}-}^{*}\|^{2L}_{f}^{L} _{h}^{L}\). Let the radii of the inner and outer hyperspheres be \(r_{1}\) and \(r_{2}\) respectively. Now we can conclude that if \(r_{2}-r_{1}>^{2L}_{f}^{L}_{h}^{L}\), \(}\) is outside the decision region given by the inner hypersphere and hence \(}}\) is successfully detected as an abnormal sample.

Now we study the theoretical guarantees for our ImAD in the sense of expectation. Let \(r_{1}\) be the thresholds for the anomaly score defined by (12) to determine whether a sample is normal or not. Let \(r_{2}\) be the radius of the outer hypersphere enclosing \(_{}}\). Let \(_{}}\) be the average anomaly score of the (incomplete) normal training data, i.e., \(_{}}^{2}=_{i=1}^{n}s(}_{i})^{2}\). Let \(_{}}}^{2}:=_{i=1}^{n}| r_{2}^{2}-s(}}_{i})^{2}|\), where \(}}_{i}\) are the (incomplete) pseudo-abnormal samples generated during the training stage. With these definitions and Assumption 3.1, the following (proved in Appendix C) presents the theoretical generalization ability of our ImAD.

**Theorem 3.3**.: _Suppose the squared anomaly score \(s(})^{2}\) of normal data is always upper-bounded by \(\), \(|r_{2}^{2}-s(}})^{2}|\) of the pseudo-abnormal data is always upper-bounded by \(\), and the absolute output of \(f_{}\) is always upper-bounded by \(\). Suppose the samples in \(}\) and \(}}\) are independently drawn \(_{}}\) and \(_{}}\) respectively. Define \(=_{f}^{L}_{h}^{L}\), \(=(1+L}{_{f}}^{2/3}+L}{_{h}}^{2/3})^{3/2}\), \(=r_{1}^{2}-_{}}^{2}\), and \(=r_{2}^{2}-r_{1}^{2}-_{}}^ {2}\)._

_(a) For normal data from_ \(_{}}\)_, over the randomness of_ \(}\)_,_

\[[_{_{}}}[s(})]>r_{1}],\] (13)

_where \(=2-2n-^{2}/(9 ^{2})\) and \(R=^{2L-1}\|}\|_{F})}\)._

_(b) For abnormal data from_ \(_{}}\)_, over the randomness of_ \(}\)_,_

\[[_{_{}}}[s(}})] r_{1}] 1-,\] (14)

_where \(=2(-2n(- )^{2}/(9^{2}))\) and \(=^{2L-1}\|}\|_{F})}\)._

Theorem 3.3(a) means that a normal sample, in expectation, is detected as anomalous with probability at almost \(\), where \(\) is close to zero under some mild conditions such as \(L\) is not too large and \(n\) is not too small. In other words, a false alarm happens with low probability. Theorem 3.3 (b) means that an abnormal sample drawn from \(_{}}\), in expectation, can be successfully detected with probability at least \(1-\), where \(\) is close to zero under some mild conditions. Theorem 3.3(b) also indicates that a larger \(r_{2}\) is better. It is worth noting that here we only focus on \(_{}}\), which is defined by \(_{}}\), \(}\), and \(g_{}\). \(_{}}\) can be regarded as a distribution of difficult anomalous data that are close to normal data. The anomalous samples drawn from space out of \(_{}}\) are much easier to detect, which is further supported by the following theorem (proved in Appendix D).

**Theorem 3.4**.: _Let \(c\) be a constant satisfying \(\|f_{} h_{} g_{}()-f_{} h_{}  g_{}(^{})\| c\|-^{}\|\) for any \(,^{}\) and assume that \(\|f_{} h_{} g_{}()-\|\). Any samples drawn from the space out of \(_{}}\) can be correctly detected if \(cr_{2}->r_{1}\)._

## 4 Experiments

### Datasets, Baselines, and Implementation Details

We compare ImAD with "impute-then-detect" methods on 11 publicly available tabular datasets from various fields, including seven datasets with manually constructed missing values and four datasets with inherent missing values. In all experiments, only incomplete normal data are used in the training stage, but there are both incomplete normal and abnormal data during the inference. The statistics of all datasets are in Table 1 and a detailed description of all datasets is in Appendix J. Considering the "impute-then-detect" strategy, for data imputation, we use MissForest (Stekhoven and Buhlmann, 2012) and GAIN (Yoon et al., 2018). For anomaly detection, we use Isolation Forest (Liu et al.,2008), Deep SVDD (Ruff et al., 2018), Neutral AD (Qiu et al., 2021) and DPAD (Fu et al., 2024). The pairwise combination between the imputation and anomaly detection methods yields eight "impute-then-detect" baselines.

We use MLPs to construct the three modules of ImAD, Adam (Kingma and Ba, 2015) as the optimizer and set coefficient \(\) of entropy regularization term in Sinkhorn distance to 0.1 in all experiments. Other experimental hyper-parameters are provided in Appendix J. Sensitivity analysis of hyper-parameters is provided in Appendix I. A detailed description of distinct missing mechanisms, including MCAR, MAR, and MNAR, is provided in Appendix J. In this study, we let the missing rate mr be 0.2 or 0.5, which is consistent with the previous data imputation works (Yoon et al., 2018; Muzzle et al., 2020). We use the AUROC (Area Under the Receiver Operating Characteristic curve) and AUPRC (Area Under the Precision-Recall curve) to evaluate the detection performance. ALL experiments were conducted on 20 Cores Intel(R) Xeon(R) Gold 6248 CPU with one NVIDIA Tesla V100 GPU, CUDA 12.0. We report the average results of five runs.

### Experimental Results on Datasets with Manually Constructed Missing Values

Before presenting the numerical results, we show the effectiveness of the generated pseudo-abnormal samples learned for the Botnet dataset in Figure 5, where we directly let the latent space \(\) be 2-D for convenient visualization. We see that the pseudo-abnormal samples cover the region of real abnormal samples, which matches our motivation and expectation.

The results of anomaly detection with missing data under the setting of MCAR are shown in Table 2 and more results under MCAR are provided in Appendix K. In Table 2, "Mean-Filling" denotes that the missing values are filled with feature means.

We have the following observations from the Table 2:

* The detection performance of "impute-then-detect" methods does not decrease with the increasing of missing rate from \(0.2\) to \(0.5\) in some cases (emphasized by underline), which indicates the adverse impact of imputation bias for the detection algorithm. The main reason is that a

   & dataset & field & features & instances & normal & abnormal \\   & Adult & income census & 14 & 30,162 & 22,658 & 7,508 \\ without & Botnet & cybersecurity & 115 & 40,607 & 13,113 & 27,494 \\ inherent & KDD & cybersecurity & 121 & 494,021 & 396,743 & 97,278 \\ missing & Arrhythmia & medical diagnosis & 274 & 452 & 320 & 132 \\ values & Speech & speech recognition & 400 & 3,686 & 3,625 & 61 \\  & Segertolge & cell analysis & 1,000 & 702 & 329 & 372 \\  & Uosskin & cell analysis & 25,334 & 610 & 323 & 378 \\    & dataset & field & features & instances & missing samples rate & missing entries rate \\  with & Titanic & pattern recognition & 9 & 891 & 79.46\% & 10.79\% \\ inherent & MovieLens1M & recommendation system & 498 & 6,040 & 100\% & 82.41\% \\ missing & Bladder & cell analysis & 23,341 & 2,500 & 100\% & 86.93\% \\ values & Seq2-Heart & cell analysis & 23,341 & 4,365 & 100\% & 88.51\% \\  

Table 1: Statistics of datasets. The “normal” and “abnormal” denote the number of normal and abnormal samples, respectively. “missing samples rate” means the proportion of samples with missing values and “missing entries rate” means the proportion of all missing values.

Figure 5: Two-dimensional visualization on Botnet.

lower missing rate implies a simpler imputation task, leading to a more pronounced imputation bias from normal data, which makes the abnormal data more "normal", thereby increasing the difficulty of detection for such two-stage methods.
* The "impute-then-detect" methods with "MissForest" (simple and shallow imputation algorithms) achieve better detection performance than those with "GAIN" (generative and deep imputation model) in most cases, suggesting that a sophisticated imputation module may not contribute positively to subsequent anomaly detection because the identical distribution assumption does not hold here. The outstanding recovery ability leads to a pronounced imputation bias and further affects the detection task.
* Compared with all baselines, ImAD achieves better detection performance in almost all cases. Besides, different from the "impute-then-detect" methods, the performance of ImAD increases with the changes of missing rate from \(0.5\) to \(0.2\) in all cases. This indicates that the imputation module of ImAD generalizes well on incomplete abnormal data and the generated pseudo-abnormal samples can alleviate the bias.

### Experimental Results on Datasets with Inherent Missing Values

We report experimental results on the four datasets with inherent missing values in Table 3, where the naive imputation methods "Zero-Filling" and 'Mean-Filling" are also considered. Observing Table 3, we notice that the naive imputation methods are insufficient for subsequent detection tasks when facing high missing rates and the imputation bias impacts the detection accuracy of "impute-then-detect" methods. Our ImAD outperforms all baselines in all cases. It indicates that our proposed method is practical and effective for real-world anomaly detection with missing data.

### Impact of Different Missing Mechanisms

Given a real dataset, the missing mechanism is usually unknown and difficult to estimate. It is expected that when the missing mechanism \(}\) in generating (incomplete) pseudo-normal samples is closer to the missing mechanism \(\) in the real data, the performance of ImAD should be better. In this section, we analyze the impact of different \(}\) on the detection performance of ImAD. Note that

   &  &  &  &  &  \\   & & \(=0.2\) & \(=0.5\) & \(=0.2\) & \(=0.5\) & \(=0.2\) & \(=0.5\) & \(=0.2\) & \(=0.2\) & \(=0.5\) \\   & 1-Forest & 74.1(1.92) & 57.44(4.791) & 81.19(1.31) & 64.35(5.95) & 96.63(0.56) & 56.01(0.84) & 57.99(0.59) & 52.95(0.72) \\  & Deep SVDD & 95.44(1.17) & 85.44(3.26) & 59.09(1.36) & 84.91(4.31) & 62.53(5.35) & 57.72(5.25) & 62.86(8.61) & 59.03(0.19) \\  & Neural.M & 96.63(1.65) & 87.39(1.27) & 88.69(1.36) & 88.10(2.87) & 60.37(2.50) & 54.64(1.08) & 63.20(2.86) & 57.43(1.16) \\  & DAD & 52.55(2.41) & 53.73(2.45) & 55.21(1.03) & 53.51(2.46) & 61.39(0.17) & 59.17(0.35) & 66.72(0.10) & 62.40(2.13) \\   & 1-Forest & 94.90(1.95) & **93.73(1.15)** & 93.24(2.13) & 93.21(1.29) & 60.06(1.69) & 69.00(0.69) & 57.12(1.26) & 56.80(1.27) \\  & Deep SVDD & 93.58(2.46) & 91.85(4.59) & 85.72(7.95) & 88.79(1.29) & 62.33(4.86) & 61.21(2.24) & 58.31(2.91) & 55.85(1.72) \\  & NetraL.M & 94.01(2.72) & 92.68(2.49) & 83.71(7.95) & **94.88(2.86)** & 58.71(1.58) & 51.23(2.41) & 50.67(2.50) & 52.72(2.61) \\  & DAD & 70.65(4.61) & 60.80(1.08) & 76.37(2.58) & 62.07(0.08) & 64.39(1.5) & 63.02(2.02) & 68.68(0.31) & 64.80(1.03) \\   & 1-Forest & 82.78(3.80) & 99.40(3.90) & 90.33(1.58) & 89.52(1.07) & 59.53(0.91) & 61.18(1.61) & 57.05(1.02) & 56.87(1.09) \\  & Deep SVDD & 88.68(4.87) & 84.45(4.98) & 88.36(3.42) & 85.55(6.74) & 88.65(4.34) & 65.44(2.40) & 57.61(4.24) & 59.55(2.34) \\  & Neural.M & 90.94(3.28) & 84.10(9.91) & 84.61(1.30) & 84.08(1.03) & 85.01(8.61) & 85.04(2.13) & 53.06(8.06) & 59.06(3.97) \\  & DAD & 70.34(8.20) & 90.80(0.09) & 72.29(1.99) & 94.49(0.44) & 62.10(8.05) & 62.60(0.18) & 68.39(0.42) & 68.48(0.21) \\   & **97.01**(0.33) & 90.78(1.35) & **95.96**(0.18) & 91.58(0.32) & **76.51**(1.22) & **71.19**(1.63) & **73.42**(2.08) & **71.50**(2.02) \\   &  &  &  &  &  \\   & & \(=0.2\) & \(=0.5\) & \(=0.2\) & \(=0.5\) & \(=0.2\) & \(=0.5\) & \(=0.2\) & \(=0.5\) \\   & 1-Forest & 78.38(1.48) & 76.29(1.62) & 75.83(0.83) & 76.65(1.26) & 26.28(1.45) & 34.54(2.03) & 36.10(4.07) & 38.98(0.79) \\  & Deep SVDD & 66.22(1.89) & 62.06(4.67) & 77.16(1.86) & 66.36(0.39) & 53.90(5.43) & 52.80(1.57) & 57.25(2.42) & 53.75(2.67) \\  & Neutral.M & 79.02(1.91) & 74.87(2.51) & 81.02(1.97) & 76.79(2.34) & 94.54(3.91) & 50.65(4.58) & 59.70(2.26) & 51.81(2.87) \\  & DAD & 78.33(1.47) & 73.37(2.35) & 87.97(1.76) & 74.63for the synthetic incomplete data, we accurately know the missing mechanism. The experimental results are reported in Table 4. On real incomplete data, our method is robust to the setting of missing mechanism \(}\) and has better overall performance when \(}\) is MCAR. Therefore, based on Occam's Razor principle and the empirical results, we recommend using MCAR as the missing mechanism for the generated pseudo-abnormal samples when the real missing mechanism is unknown. On the other hand, as shown in Table 4, on synthetic incomplete data, detection performance degrades when \(}\) is different from \(\).

### More Experimental Results

The appendices contain the following additional results: I. Performance gain from pseudo-abnormal samples (Appendix G); II. Influence of the constrained radii \(r_{1},r_{2}\) (Appendix H); III. Sensitivity analysis of hyperparameters (Appendix I); IV. Impact of different missing rates for training and test set(Appendix K); V. Results of MAR and MNAR (Appendix K).

## 5 Conclusion

This paper proposed ImAD, the first end-to-end unsupervised anomaly detection method on incomplete data. ImAD integrates data imputation with anomaly detection into a unified optimization objective and automatically generates pseudo-abnormal samples to alleviate the imputation bias. We theoretically proved the effectiveness of ImAD and empirically evaluated ImAD on multiple real-world datasets. The results showed that ImAD mitigates imputation bias from normal data and provides an effective solution for unsupervised anomaly detection in the presence of missing values. One limitation of this work is that we haven't considered the applications on incomplete image data and incomplete time series.

   &  & }\)} \\   & & MCAR &  &  \\   & & AUROC(\%) & AUPRC(\%) & AUROC(\%) & AUROC(\%) & AUROC(\%) & AUPRC(\%) \\  Titanic & Unknown & 82.09 & 81.39 & 79.06 & 77.08 & 80.50 & 79.17 \\ Movie\_ens1M & Unknown & 66.32 & 65.34 & 63.14 & 63.39 & 61.44 & 60.91 \\ Bladder & Unknown & 100.00 & 100.00 & 99.95 & 99.95 & 100.00 & 100.00 \\ Seq2\_Heart & Unknown & 96.62 & 96.40 & 96.79 & 96.60 & 95.56 & 94.41 \\ Adult & MCAR & 71.19 & 71.50 & 64.11 & 66.44 & 67.28 & 66.72 \\ Adult & MAR & 65.66 & 67.23 & 74.61 & 70.74 & 71.14 & 69.69 \\ Adult & MNAR & 70.69 & 69.17 & 68.35 & 68.78 & 71.60 & 68.97 \\  

Table 4: Performance comparison of different missing mechanisms \(}\).

   &  &  &  &  &  &  &  &  \\   & & & & & & & & & \\   &  & 77.44(0.29) & 77.74(0.27) & 73.55(0.43) & 4.087(0.32) & 3.22(0.72) & 39.23(0.41) & 4.788(0.63) & 46.250(5.4) \\  & Deep SVDD & 54.03(0.18) & 53.49(3.21) & 34.30(8.98) & 43.44(0.58) & 68.30(2.73) & 36.22(4.24) & 71.12(9.09) & 65.18(0.95) \\  & Neutral. AD & 94.90(5.81) & 47.10(1.31) & 39.29(2.79) & 44.50(7.26) & 63.20(3.93) & 54.86(0.84) & 82.84(3.37) & 78.762(1.71) \\  & DPA & 79.50(9.91) & 79.07(1.40) & 44.10(4.36) & 46.12(2.29) & 99.90(0.0) & 99.90(0.0) & 99.51(0.32) & 93.80(0.69) \\   &  & 79.60(0.65) & 78.64(0.94) & 36.30(0.75) & 41.47(0.46) & 44.06(3.12) & 46.63(3.88) & 54.69(2.32) & 51.98(2.07) \\  & Deep SVDD & 53.87(0.098) & 52.41(0.36) & 48.18(0.26) & 46.64(0.93) & 81.97(3.44) & 78.93(7.38) & 75.16(1.51) & 71.12(0.65) \\  & Neutral. AD & 65.16(0.20) & 63.63(0.23) & 63.74(0.86) & 42.15(0.46) & 99.10(3.94) & 99.82(2.64) & 89.78(3.66) & 66.75(75.80) \\  & DPAD & 67.02(0.66) & 69.85(0.85) & 47.74(0.48) & 48.52(2.89) & 97.52(1.43) & 97.88(1.15) & 77.93(10.20) & 76.37(9.95) \\   &  & 72.70(2.82) & 78.50(0.30) & 33.64(1.04) & 41.45(0.25) & 44.53(2.84) & 26.84(1.94) & 46.54(3.88) & 58.63(1.0) \\  & Deep SVDD & 60.46(8.95) & 69.78(3.73) & 56.40(4.85) & 53.70(4.92) & 94.53(5.91) & 97.94(9.20) & 94.20(4.29) & 32.30(0.45) \\   &  &  & 54.63(4.42) & 52.13(13.16) & 57.14(1.18) & 55.07(1.72) & 66.41(4.66) & 68.01(5.25) & 91.80(1.18) & 90.87(1.16) \\   & & DPAD & 88.18(1.45) & 70.01(1.03) & 47.50(4.40) & 48.49(3.03) & 96.96(1.30) & 79.21(0.71) & 78.03(5.20) & 4.675(3.33) \\   &  & 79.46(0.79) & 78.69(0.96) & 64.84(1.01) & 62.61(0.99) & 45.77(2.39) & 46.72(1.91) & 46.62(3.31) & 58.82(3.23) \\   & & Deep SVDD & 70.59(5.44) & 66.43(1.74) & 58.99(1.81) & 56.68(2.11) & 95.43(1.18) & 96.78(0.47) & 93.93(0.37) & 91.54(0.67) \\   & & Neural. AD & 53.71(2.74) & 51.55(2.25) & 57.72(2.81) & 51.42(2.38) & 65.30(3.39) & 65.68(4.69) & 94.18(0.76) & 90.79(1.36) \\   & & DPAD & 78.12(0.97) & 77.11(1.04) & 59.98(1.86) & 58.98(1.08) & 59.72(1.56) & 74.99(2.76) & 73.78(1.61) \\   & **82.09**(0.99) & **81.39**(0.84) & **66.32**(1.36) & **65.34**(1.35) & **100.00** & **1000.00** & **96.62**(0.11) & **96.40**(0.19) \\  

Table 3: Detection accuracy (AUROC and AUPRC (%, mean and std)