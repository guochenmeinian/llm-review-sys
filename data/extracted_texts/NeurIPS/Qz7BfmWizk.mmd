# The motion planning neural circuit in goal-directed navigation as Lie group operator search

Junfeng Zuo\({}^{1,3}\)

zuojunfeng@pku.edu.cn

&Ying Nian Wu\({}^{2}\)

ywu@stat.ucla.edu

Si Wu\({}^{1}\)

siwu@pku.edu.cn

&Wen-Hao Zhang\({}^{3,4}\)

wenhao.zhang@utsouthwestern.edu

\({}^{1}\)Peking-Tsinghua Center for Life Sciences, Academy for Advanced Interdisciplinary Studies,

School of Psychology and Cognitive Sciences, IDG/McGovern Institute for Brain Research,

Center of Quantitative Biology, Peking University.

\({}^{2}\)Department of Statistics, University of California, Los Angeles.

\({}^{3}\)Lyda Hill Department of Bioinformatics, UT Southwestern Medical Center.

\({}^{4}\)O'Donnell Brain Institute, UT Southwestern Medical Center.

Corresponding author.

###### Abstract

The information processing in the brain and embodied agents form a sensory-action loop to interact with the world. An important step in the loop is motion planning which selects motor actions based on the current world state and task need. In goal-directed navigation, the brain chooses and generates motor actions to bring the current state into the goal state. It is unclear about the neural circuit mechanism of motor action selection, nor its underlying theory. The present study formulates the motion planning as a Lie group operator search problem, and uses the 1D rotation group as an example to provide insight into general operator search in neural circuits. We found the abstract group operator search can be implemented by a two-layer feedforward circuit utilizing circuit motifs of connection phase shift, nonlinear activation function, and pooling, similar to Drosophila's goal-directed navigation neural circuits. And the computational complexity of the feedforward circuit can be even lower than common signal processing algorithms in certain conditions. We also provide geometric interpretations of circuit computation in the group representation space. The feedforward motion planning circuit is further combined with sensory and motor circuit modules into a full circuit of the sensory-action loop implementing goal-directed navigation. Our work for the first time links the abstract operator search with biological neural circuits.

## 1 Introduction

The information processing in the brain forms a sensory-action loop to interact with the external world (Fig. 1A) . The sensory-action loop consists of three modules: the sensory neural circuit module forms a neural representation of the world state, the motor circuit module produces motor actions to change the world states, and in between there is an essential sensorimotor transformation module that plans motor actions based on the sensory input and tasks goals . For example, in goal-directed navigation tasks, the sensorimotor transformation module plans a sequence of motor actions to bring the current sensory state towards a goal state. Extensive neuroscience studies have investigated theneural circuit mechanism of motion planning [4; 5; 6; 7; 8; 9], however, it remains far from clear as well as the underlying computational theory. Motion planning is also an essential computation for embodied agents in engineering research, including, e.g., robotic control, reinforcement learning, and machine learning [10; 11; 12; 13], etc. Studying the motion planning neural circuits and their computational theory will help us understand the brain and can provide brain-inspired circuit models for embodied agents.

To provide theoretical insight into motion planning, the present study defines the sensory-action loop using the (Lie) group theory. Denote by \(s\) as a continuous world state, and \(u(s) u(x|s)\) the evoked responses of a population of sensory neurons with \(x\) as the neuron index. Suppose the motor system generates the same kind of actions from a Lie _Group_\(\) (e.g., translation or rotation) to transform the world state \(s\). The effect of a motor action \(g\) to the world state \(s\) and updated sensory representation \(u(s)\) can be denoted by (Fig. 1A; \(\) denotes the group action in below),

\[u(s^{})=uR_{g} s=_{g} u(s),\ \ \ g.\] (1)

\(R_{g}\) is the group operator (motor action) changing the world state \(s\) (Fig. 1A, green), whose effect on updated sensory responses \(u(s^{})\) can be summarized as a neural operator \(_{g}\) directly acting on the original response \(u(s)\) (Fig. 1A, blue) that can be regarded as the motor-to-sensory neural feedback in the brain . To represent all world states \(s\) under all group transformations, \(u(s)\) must satisfy Eq. (1) for all \(g\), and is called _equivariance_ with the group \(\) (group homomorphism) (Fig. 1B). In the Lie group framework (Eq. 1), motion planning in goal-directed navigation can be formulated as finding an operator \(_{g}\) to bring the sensory response of the current state \(u(s)\) into a goal state \(u(h)\),

\[\ \ \ _{g};\ \ \ \ _{g} u(s)=u(h),\ \ \ g.\] (2)

An intuitive way to find \(_{g}\) is exhaustive search in the group space: apply every operator to \(u(s)\) and select the one transforming \(u(s)\) closest to the goal response \(u(h)\) (Table S1, Supplementary Info. (SI)), corresponding to find the peak location in the _group convolution_ (Fig. 1D, bottom) [16; 17],

\[g^{*}=_{g}\ L(g);\ \ \ L(g)=[u(h) u(s)](g)=u (h),_{g} u(s),\] (3)

then the optimal group operator is \(_{g^{*}}\). The \(\) denotes the group \(g\) convolution, and \(u(h),_{g} u(s)= u(x|h)u(x|R_{g} s )dx\) is the inner product. In particular, when \(s\) is a 1D variable and \(_{g}\) is a 1D translation operator, the group convolution \(L(g)\) (Eq. 3) simplifies into the cross-correlation function that is extensively used in signal processing [18; 19].

The present study investigates how brain's neural circuits search group operators \(_{g}\) (action) in goal-directed navigation (Eq. 2). We use the 1D rotation group as a working example to provide insight into the neural circuit mechanism of general operator search. Although finding 1D rotation operators is mathematically simple and can be realized by available signal processing algorithms, its neural circuit implementation has never been explored. We theoretically derive a two-layer nonlinear feedforward circuit for 1D rotation operator search, which is composed of circuit motifs of connection phase shift, nonlinear activation function, and pooling, and the derived circuit is similar to Drosophila's goal-directed navigation neural circuits [20; 21; 22; 23]. We link every neural circuit computation with

Figure 1: (A) The sensory-action loop. Sensorimotor transformation plans motion actions based on the world state and task goals. (B) The equivariant map of the sensory neurons’ responses. (C) A concrete example of 1D rotation group acting on periodic state \(s\) that can be regarded as the heading direction of a fly. The sensory neurons form a neuronal population code \(u(x|s)\) uniformly covering the space of \(s\) (Eq. 1). (D) Finding a desired operator can be realized by group convolution, i.e., finding the peak location of cross-correlation function over the group manifold.

operations in operator search, and provide geometric interpretations of circuit computation in the group representation space. Moreover, the computational complexity of the derived feedforward circuit for operator search can be even lower than the standard algorithm based on the fast Fourier transform in signal processing in certain conditions. We further assemble the derived feedforward circuit with sensory and motor circuits to form a full neural circuit of the whole sensory-action loop.

**Significance**. The present study is one of the first studies formulating motion planning as the group operator search problem, and deriving a biologically plausible neural circuit implementation with rigorous mathematical analysis. The group operator search formulation of motion planning can provide a normative approach to generalize existing motion planning algorithms into different transformations. Moreover, in terms of group equivariant machine learning, the theory and the sensorimotor transformation circuit model developed in the present study are complementary to many existing equivariant networks that correspond to the sensory system (e.g., [17; 24; 25; 26; 27]).

## 2 1D rotation neural group operator search

We use the 1D rotation group \((1)\) as an example to provide insight into the general principle of group operator search in neural circuits. The \((1)\) manifold is a unit circle on the complex plane (Fig. 2A), and can be parameterized by the angle \(\) (corresponding to \(g\) in a general Lie group, Eq. 1),

\[(1)=\{(i),\;[-,)\},\;\;\;i=.\] (4)

A group element \(R()(1)\) rotates a 1D stimulus direction \(s[-,)\), or its complex representation \(e^{is}\), by \(\), i.e., \(s\) into \(s+\) (mod \(2\)), and is denoted as \(R() s e^{i}e^{is}=e^{i(s+)}\). Based on Eq. (1), a rotation-equivariant sensory response \(u(s)\) should satisfy (suppress "mod \(2\)" for brevity),

\[u[R() s]=u(s+)=() u(s).\] (5)

\(()\) is the _neural operator_ rotating the sensory representation \(u(s)\). Since the rotation operator changes \(s\) in an additive way, i.e, \(u(x|s) u(x|s+)\), it can be checked the equivariant sensory response satisfies \(u(x|s)=u(x-s) u(s)\), where the neuron index \(x\) (also called preferred direction) additively interacts with \(s\), implying the neuronal response only depends on the difference \(x-s\) (Fig. 1D). The rotation-equivariant neural responses \(u(x-s)\) have been widely used in neural coding studies [29; 30; 31], and are usually called homogeneous neural codes. To make our theory general, we leave the concrete profile of \(u(s)\) open and will see how the group structure constrains it.

In the case of 1D rotation, the motion planning in goal-directed navigation task is finding a rotation operator \(()\) to rotate the sensory response \(u(s)\) into the goal direction, \(u(h)\). Due to the simplicity of \((1)\) (Eq. 5), the desired rotation operator is \((^{*}=h-s)\), in that

\[(h-s) u(x-s)=u[x-(s+h-s)]=u(x-h),\] (6)

whose parameter is the angular difference \(^{*}=h-s\). Although computing the angular difference is simple, it is non-trivial to search neural operators \(()\) in neural circuits. This is because \((^{*})\) is an abstract math object rather than the numerical value \(^{*}\), even if it is indexed by \(^{*}\). This distinction is reflected by the fact that although the operator's parameter \(^{*}=h-s\) is arithmetic subtraction, the neural operator \(()\) by no means of arithmetic subtraction between neural responses \(u(h)\) and \(u(s)\).

### The structure and representation of 1D neural rotation operators

Searching abstract neural operators \(()\) first requires neural circuits to represent them. Intuitively, the representation means a one-to-one mapping between abstract operators with numerical values (e.g., neuronal activity), and then searching abstract operators can be converted into common numerical optimizations and further mapped to neural dynamics. Hence, we study the structure of the neural operator \(()\) to reveal its neural representation. Consider an infinitesimal rotation \(()\) (\( 0\)), whose effect on the sensory response \(u(x-s)\) is (using first-order Taylor expansion),

\[() u(x-s)=u(x--s) u(x-s)+ (-_{x})u(x-s)=(1+)u(x-s).\] (7)

\(-_{x}=-/ x\) is the 1D rotation _generator_ characterizing the tangent space of infinitesimal rotations, and can be used as the basis of Lie _algebra_. By using the infinitesimal rotation, the differential and exponential form of a rotation operator is (see SI. Sec. 1.1),

\[()=() ()=(),\] (8)

The neural rotation operator \(()\) is _commutative_, meaning the composition of two rotations is the same regardless of their order, i.e., \((_{1})(_{2})=(_{2})(_{1})\). Commutative group operators share a common set of eigenfunctions that can be used to represent group operators. It can be checked \(\{f_{}(x)=e^{i x}/,\}\) is the normalized eigenfunction set of \(\),

\[ f_{}=-_{x}e^{i x}/=(-i) e ^{i x}/=_{}() f_{},\] (9)

with each \(f_{}\) having eigenvalue \(_{}()-i\). The eigenvalue \(_{}()\) can be regarded as the _representation_ of \(\) based on \(f_{}\). Hereafter, we call the space spanned by the eigenfunctions \(\{f_{}\}\) as the _representation space_. It is worth noting that \(\{f_{}\}\) are Fourier bases, which are widely used in frequency analysis in signal processing to extract each frequency component . In contrast, the current study uses Fourier bases to represent the generator \(\) and operator \(()\).

Since rotation operators can be composed by the generator \(\) via the exponential map (Eq. 8), the neural operator's representation based on the eigenfunction \(f_{}\) is derived as (details at SI. Sec. 1.2),

\[() f_{}=e^{-i} f_{} _{}() f_{},\] (10)

whose eigenvalue \(e^{-i}_{}()\) is regarded as the representation of rotation operator \(()\). Comparing Eqs. (9 and 10), we see the exponential map from the generator to the operator, i.e., \(()=()\), also exists in the representation space, i.e., \(_{}()=(-i)=[_{}( {J})]\). The closed-form formula of \(()\) is the _inner product_ between the rotated and the original eigenfunctions (multiplying both sides of Eq. (10) by \(f_{}^{}\) (\(\): conjugate), and integrating over \(x\)),

\[_{}()=() f_{},f_{} =_{-}^{}[() f_{}]f_{ }^{}dx=e^{-i}.\] (11)

There is an one-to-one mapping between each operator \(()\) and its representation \(_{}()\). The advantage of using eigenfunctions to represent _abstract_ operators \(()\) is searching abstract operators (Eq. 3) can be converted into usual _numerical_ optimization in the representation space.

### Rotation operator search in the representation space

Despite the ansatz of the desired operator (Eq. 6), we still need an algorithm explicitly outputting the operator based on neuronal responses. To derive the numerical computation in the representation space, we decompose neural responses \(u(s)\) and \(u(h)\) by using operators' eigenfunctions \(f_{}\),

\[u(s)=_{} u(s),f_{} f_{}=_{ }U(|s)f_{}^{-1}[U(|s)],\] (12)

corresponding to the inverse Fourier transform. Meanwhile the representation \(U(|s) U(s)\) (\(\) is suppressed unless confusion), called _Fourier coefficient_, is calculated via Fourier transform,

\[U(s)= u(s),f_{}=_{-}^{}u(s)f_{}^{} dx[u(s)],\] (13)

Figure 2: (A) The 1D rotation group manifold. (B) The eigenvalue spectrum of the 1D rotation group operators. (C-D) The representation of neural responses (C) and desired rotation operator (D) in the group representation space spanned by operators’ eigenfunctions. (E) Two mathematically equivalent processes of rotating sensory responses into the goal direction. (F) Sequential motion planning.

## 3 Towards a neural circuit of motion planning

### Sequential motion planning strategy

In reality, the motor system (muscles) has power constraints and cannot generate actions with too large amplitude, implying it might not rotate the stimulus direction abruptly within an infinitesimal time period. Rather, the brain decomposes a strategic, complex motion action into a continuous sequence of small actions [1; 4], forming a time-continuous process (Fig. 2F),

\[(^{*}) u(s_{0})=(_{t+1})(_{t})(_{0}) u(s_{0})= (_{t+1}) u(s_{t}),\] (16)

where \(s_{0}=s\) is the initial stimulus direction, and \(s_{t}=s_{0}+_{=0}^{t}_{}\) is the direction after applying rotation sequence with angles \(_{0}\) to \(_{t}\). The sequential motion planning imposes a _sensory-action loop_: after the motor system generates a small rotation \((_{t})\) at time \(t\), the sensory response updates from \(u(s_{t})\) to \(u(s_{t+1})\), followed by another rotation \((_{t+1})\), which repeats over time until the stimulus direction \(s\) is rotated to the goal \(h\). Differentiating Eq. (16) over \(t\), utilizing the differential form of operators (Eq. 8), the dynamics of the sensory responses \(u(s_{t})\) in the sensory-action loop is,

\[u(s_{t})=(_{t}) u(s_{0})=(_{t})}{d_{t}}}{dt} u(s_{0})=v_{t} (_{t}) u(s_{0})=v_{t} u(s_{t}),\] (17)

We see the rotation dynamics is determined by the rotation speed \(v_{t}=d_{t}/dt\). There are multiple strategies for generating \(v_{t}\) sequence and we consider a strategy performing _gradient ascent_ along the objective function (Eq. 3), i.e., the \(v_{t}\) at time \(t\) is proportional to the gradient of rotation angle \(_{t}\),

\[v_{t}=)}{d_{t}}= (_{t}) u(s_{0}),u(h)}{d_{t}}= _{}||U(|s)||^{2}[(h-s_{t})],\] (18)

with \(\) determining the step size. The rotation speed is a sine function of the direction difference \(h-s_{t}\) and representing rotation group parameter (comparing Eqs. 18 and 15, Fig. 3D).

 
**Group convolution** & **Representation space** & **Feedforward circuit** \\ (Eq. 3, Table S1) & via FFT (Eq. 15, Table S2) & (sequential motions, Fig. 2F, Table S3) \\  \((N^{2})\) & \((N N)\) & \((N(|h-s|))\) \\   Since \(u(s)=(s) u(0)\), we have \(U(s)=_{}(s)U(0)=e^{-i s}U(0)\), with \(U(0)\) the representation of \(u(s=0)\). Similarly, the representation of the goal neurons’ response \(u(h)\) is \(U(h)=_{}(h)U(0)\). Referring both \(U(s)\) and \(U(h)\) by \(U(0)\), their representations are \(_{}(s)\) and \(_{}(h)\) respectively, and are geometrically visualized as two vectors of unit length with angle \(s\) and \(h\) respectively (Fig. 2C).

With sensory and goal neuronal responses’ representations (Eq. 12), the objective function of _abstract_ rotation operators, \(L()=() u(s),u(h)\) (Eq. 3), simplifies into a numerical function as the _inner product_ of representations of neuronal responses and operators (see details in SI. Sec. 1.2),

\[L()=_{}U(|s)_{}()U(| h)^{}_{}\|U(|s)_{}()\|\|U( |h)\|,\] (14)

where the Cauchy-Schwartz inequality is used and \(\|a\|=}\). The Eq. (14) is maximized only if \(U(|s)_{}()=U(|h)\), implying the representation of the required rotation operator is (Fig. 2D),

\[_{}(^{*})=U(h)/U(s)=_{}(h)/_{}(s)=e^{-i (h-s)}\ \ ^{*}=_{}L()=h-s.\] (15)

In the representation space, the neural operator is a numerical _ratio_ with a closed-form solution, which provides an algorithm to find the operator rather than checking the ansatz (Eq. 6). Moreover, the computational complexity of finding operators in the representation space is much lower than the group convolution (Table 1; SI. Sec. 2): the complexity via the representation space is \((N N)\) with \(N\) the neuron number, mainly coming from Fourier transform when using fast Fourier transform (FFT) (Eq. 13) . In contrast, the complexity of the group convolution (Eq. 3) is \((N^{2})\). Once \(_{}(^{*})\) is found (Eq. 15), it can be multiplied with \(U(s)\) followed by inverse Fourier transform to rotate the sensory response into the goal direction \(u(h)\), i.e., \(^{-1}[U(s)_{}(^{*})]=^{-1}[U(h)]=u(h)\) (Fig. 2E, dashed lines). Nevertheless, this procedure (Fig. 2E, dashed lines) is _physically_ different from actual motor actions, which corresponds to firstly mapping \(_{}(^{*})\) back to the physical operator \((^{*})\) and acting on \(u(s)\) directly (Fig. 2E, solid line). Hence we explore how the neural circuit finds the operator \((^{*})\) and use it to physically rotate sensory response \(u(s)\) (Fig. 2, solid line).

## 3 Towards a neural circuit of motion planning

### Sequential motion planning strategy

In reality, the motor system (muscles) has power constraints and cannot generate actions with too large amplitude, implying it might not rotate the stimulus direction abruptly within an infinitesimal time period. Rather, the brain decomposes a strategic, complex motion action into a continuous sequence of small actions [1; 4], forming a time-continuous process (Fig. 2F),

\[(^{*}) u(s_{0})=(_{t+1}) (_{t})(_{0}) u(s_{0})= (_{t+1}) u(s_{t}),\] (16)

where \(s_{0}=s\) is the initial stimulus direction, and \(s_{t}=s_{0}+_{=0}^{t}_{}\) is the direction after applying rotation sequence with angles \(_{0}\) to \(_{t}\). The sequential motion planning imposes a _sensory-action loop_: after the motor system generates a small rotation \((_{t})\) at time \(t\), the sensory response updates from \(u(s_{t})\) to \(u(s_{t+1})\), followed by another rotation \((_{t+1})\), which repeats over time until the stimulus direction \(s\) is rotated to the goal \(h\). Differentiating Eq. (16) over \(t\), utilizing the differential form of operators (Eq. 8), the dynamics of the sensory responses \(u(s_{t})\) in the sensory-action loop is,

\[u(s_{t})=(_{t}) u(s_{0})=(_{t})}{d_{t}}}{dt} u(s_{0})=v_{t} (_{t}) u(s_{0})=v_{t} u(s_{t}),\] (17)

We see the rotation dynamics is determined by the rotation speed \(v_{t}=d_{t}/dt\). There are multiple strategies for generating \(v_{t}\) sequence and we consider a strategy performing _gradient ascent_ along the objective function (Eq. 3), i.e., the \(v_{t}\) at time \(t\) is proportional to the gradient of rotation angle \(_{t}\),

\[v_{t}=)}{d_{t}}=(_{t}) u(s_{0}),u(h)}{d_{t}}=_{} ||U(|s)||^{2}[(h-s_{t})],\] (18)

with \(\) determining the step size. The rotation speed is a sine function of the direction difference \(h-s_{t}\) and representing rotation group parameter (comparing Eqs. 18 and 15, Fig. 3D).

 
**Group convolution** & **Representation space** & **Feedforward circuit** \\ (Eq. 3, Table S1) & via FFT (Eq. 15, Table S2) & (sequential motions, Fig. 2F, Table S3) \\  \((N^{2})\) & \((N N)\) & \((N(|h-s|))\) \\   Since \(u(s)=(s) u(0)\), we have \(U(s)=_

### A feedforward circuit for motion planning

The closed-form solution of \(v_{t}\) in sequential motion planning (Eq. 18) and the optimal operator (Eq. 15) imply \(v_{t}\) can be computed by a _feedforward_ circuit in a single propagation of neural inputs, which would be faster and simpler than a recurrent circuit. We explore how a generic feedforward circuit computes \(v_{t}\) (Eq. 18) via receiving sensory response \(u(s)\) and goal response \(u(h)\),

\[r_{v}(x)=F w_{s}(x,x^{})u(x^{}-s)dx^{}+ w_{h}( x,x^{})u(x^{}-h)dx^{},\] (19)

where \(F()\) is a nonlinear increasing activation function. \(w_{s}(x,x^{})\) and \(w_{h}(x,x^{})\) are feedforward weights from sensory neuron \(u(x-s)\) and goal neuron \(u(x-h)\). Two issues are to be resolved for \(v_{t}\) computation in feedforward circuits. One is how the feedforward circuit as a nonlinear function of summed neural inputs (Eq. 19) computes \(L(_{t})\) as an inner product of neural inputs \(u(s)\) and \(u(h)\) (Eq. 18). Another is computing the derivative \(dL/d_{t}\) in the feedforward circuit.

We propose the feedforward circuit approximates the derivative \(dL(_{t})/d_{t}\) as a _difference_ form,

\[v_{t}+)-L(_{t}- )}{2}= u(s_{+}),u(h) - u(s_{-}),u(h),\] (20)

where \(s_{}=(s_{0}+_{t})=s_{t}\). To implement the inner product (Eq. 18) in the feedforward circuit (Eq. 19), we convert the inner product of two neural inputs into,

\[ u(s_{}),u(h)=\|u(s_{})+u(h)\|^{2}-\|u(s_{})\|^ {2}-\|u(h)\|^{2}/2.\] (21)

\(\|u(s_{})\|^{2}= u(x-s_{})^{2}dx\) where the square function is similar to feedforward circuit's nonlinear output (Eq. 19). By using the form in Eq. (21), the two inner products' difference in Eq. (20) is,

\[ u(s_{+}),u(h)- u(s_{-}),u(h)=\|u(s_{+})+u (h)\|^{2}-\|u(s_{-})+u(h)\|^{2}/2,\] (22)

where we used \(\|u(s_{})\|^{2}=\|u(h)\|^{2}\), i.e., the norm of neural responses is irrelevant with represented directions. Eq. (22) suggests computing \(L(_{t}+)-L(_{t}-)\) for \(v_{t}\) (Eq. 28) can be achieved by a two-layer feedforward circuit with each layer containing two neuronal populations (Fig. 3A).

\[:&\;r_{} (x)=[u(x-s_{})+u(x-h)]^{2},\\ :&\;r_{v_{}}= r_{ }(x)dx=\|u(s_{})+u(h)\|^{2}.\] (23)

In the 1st layer, each neuronal population \(r_{}(x)\) computes the square of the sum of sensory and goal inputs, followed by two neurons \(r_{v_{}}\) at the 2nd layer pooling responses \(r_{_{}}(x)\) at the 1st layer.

Figure 3: (A) The derived feedforward motion planning circuit, composed of circuit motifs of connection phase shift (\(r_{_{}}\) neurons receive different connection phases from \(u(s)\) and \(u(h)\)), nonlinear activation function (left-bottom inset), and pooling (\(\)). The difference between two output neurons \(r_{v_{}}\) conveys the rotation speed \(v_{t}\). (B) Drosophila’s goal-directed navigation circuit (adapted and modified from ). Neurons are arranged by their preferred direction \(x\). For illustration, only four PFL3 neurons (\(r_{_{}}\) neurons in A) are shown. The PFL3 right (green) and left (red) neurons receive heading input \(u(s)\) with shifted phases and goal input \(u(h)\). Two DN neurons (\(r_{v_{}}\) neurons in A) pool PFL3 left and right neurons respectively and rotate heading direction. (C-D) The geometry of feedforward circuit computation in the representation space. (C): Two populations of \(r_{_{}}\) neurons rotate the \(_{}(_{t})\) by \(\). The firing rate difference of two output neurons \(r_{v_{}}\) is regarded as the length difference between horizontal green and pink arrows, which is a sine function with \(_{t}=h-s_{t}\), the distance to the goal direction \(h\) (D).

Receiving rotated sensory input \(u(s_{})\) by \(\) can be realized by feedforward weights with _shifted connection phase_ (Fig. 3A, \(r_{_{}}\) receives connections from \(u(s)\) and \(u(h)\) with different phases),

\[w_{,s}(x,x^{})=(x-x^{}),\] (24)

where \(w_{,s}(x,x^{})\) is the weight from sensory neuron \(u(x^{}-s)\) to \(r_{_{}}(x)\). Eventually, the _difference_ of two neurons at the 2nd layer is proportional to the rotation speed \(v_{t}\) (combine Eqs. 20 and 22)

\[(r_{v_{+}}-r_{v_{-}})=2[ u(s_{+}),u(h)- u(s_{-}),u( h)] v_{t}.\] (25)

Then each \(r_{v_{}}\) can drive a corresponding effector (e.g., muscle) that generates actual motor actions to rotate the heading direction clockwise or counter-clockwise.

**General nonlinear activation functions**. The square function for the first layer neurons \(r_{}(x)\) (Eq. 23) doesn't necessarily mean their activation function must be a square function, otherwise our theory and circuit is limited. Instead, the derived feedforward circuit works well with a general nonlinear activation function \(F(u)\) monotonically increasing with \(u\) (Eq. 19). To see the mechanism of general nonlinear activation functions, we expand it at \(0\) to the second order,

\[F(u) F(0)+F^{}(0)u+F^{}(0)u^{2}/2 F_{0}+F_ {1} u+F_{2} u^{2}.\] (26)

Then the neuronal responses \(r_{_{}}(x_{v})\) can be approximated as,

\[ r_{_{}}(x)& F_{0}+F_ {1}[u(x-s_{})+u(x-h)]+F_{2}[u(x-s_{})^{2}+u(x-h)^{2}],\\ &+2F_{2} u(x-s_{})u(x-h),\] (27)

Finally, the _difference_ of neurons at the 2nd layer is still proportional to the rotation speed \(v_{t}\),

\[r_{v_{+}}-r_{v_{-}}= r_{_{+}}(x)dx- r_{_{-}}(x)dx=2F_{2} [ u(s_{+}),u(h)- u(s_{-}),u(h)] v_{t}.\] (28)

Again, we used the fact that the summed neuronal activities do not depend on the represented direction, i.e., \( u(x-s)dx= u(x)dx\), and \( u(x-s)^{2}dx= u(x)^{2}dx\). Notably, the 1st layer neuron \(r_{_{}}\) must have a nonlinear activation function to enable the feedforward circuit to output the rotation speed \(v_{t}\), otherwise (setting \(F_{2}=0\) in Eq. 28), the neurons at the 2nd layer, \(r_{v_{}}\) will fully cancel. Overall, the architecture of the derived feedforward circuit utilizes the connection phase shift, nonlinear activation function, and pooling of neuronal activities to compute the rotation speed \(v_{t}\).

**Comparison with Drosophila's circuit**. The derived feedforward circuit is similar to the recently identified Drosophila's goal-directed navigation circuit (Fig. 3A-B) , which also has a two-layer feedforward architecture receiving the sensory input \(u(s)\) (E-PG neurons) and the goal input \(u(h)\) (FC neurons) to compute the rotation speed \(v_{t}\). At the 1st layer in Drosophila's circuit, PFL3 left (right) neuronal population (Fig. 3B, red (green) neurons) combines the shifted sensory input \(u(s)\) with angle \(\) respectively with the goal input \(u(h)\), and output via a nonlinear activation function, which are similar to \(r_{}\) neurons in our feedforward circuit (Fig. 3A). Then the DN left and right neurons at the 2nd layer (equivalent to \(r_{v}\) neurons) pool all activities of PFL3 right and left neurons respectively, and their response difference determines the rotation speed \(v_{t}\).

**Neural circuit computational complexity**. Considering each \(r_{_{}(x)}\) neuron only receives one feedforward connection from sensory neurons \(u(s)\), i.e., \(w_{_{},s}\) is a delta function (Eq. 24), which is the case in Drosophila's circuit. Then in each time step during sequential rotations, the feedforward circuit computes \((N)\) addition and \((N)\) multiplication (suppose a square activation function). Given a fixed goal direction \(h\), the sequential rotation will take \((|h-s|)\) time steps to rotate from the original direction \(s\) into \(h\). Hence the total complexity of feedforward circuit during the whole sequential rotations is \((N|h-s|)\). When the stimulus direction \(s\) is close to the goal direction \(h\) enough, i.e., \(|h-s|<N\), the computational complexity of the feedforward circuit is even lower than the widely used fast Fourier transform (Eq. 13) with complexity \((N N)\) (Table 1).

### The geometry of feedforward circuit computation

Although the feedforward circuit doesn't explicitly use the operator's representation (Eq. 15, Fig. 2E), the representation space (Eq. 9) provides clear geometrical interpretation of the feedforward circuit computation. Substituting the representation of sensory response \(u(s_{t})\) at time \(t\) and goal response \(u(h)\) (Eq. 12) into rotation speed neurons \(r_{v_{}}\) (Eq. 27),

\[r_{v_{}}=2F_{2}_{}\|U(|0)\|^{2}_{}( _{t})+_{}(_{t}) ^{}+,\ \ (_{t}=h-s_{t}),\] (29)const is a constant irrelevant with angles (from the first two terms at Eq. (27), RHS). Geometrically, \(r_{v_{}}\) corresponds to rotate the optimal operator's representation \(_{}(_{t})\) by \(\), and sum the rotated operator with its complex conjugate (mirrored by the real axis, Fig. 3B), and hence it resides on the real axis. The difference between \(r_{v_{+}}\) and \(r_{v_{-}}\), exhibited by the length difference of pink and green arrows in Fig. 3C, is a sine function depending on the optimal operator's angle \(_{t}\) (Fig. 3D).

## 4 A full circuit model of the sensory-action loop

We further assemble the derived feedforward motion planning circuit (Fig. 3A) with concrete sensory and motor circuit modules to construct a full circuit of the sensory-action loop (Fig. 4A) implementing sequential rotations (Eq. 17). For simplicity, the full circuit model only includes the internal motor-to-sensory neural feedback (Fig. 1A, blue line) rather than the external loop (Fig. 1A, green lines), with a mildly implicit assumption that the actual sensory feedback from the physical world is the same as the internal motor-to-sensory feedback. To be realistic, all neurons in the full circuit have temporal dynamics, even if our theoretical derivations consider memory-less neurons (Eq. 19). All connection weights have Gaussian profiles spreading over the neuronal space \(x\) (SI.Eq. S12), with different peak weights, connection widths and phases. Due to the page limit, we briefly introduce key features of the full circuit here, and its detailed dynamics can be found at SI.Sec. 3.

**Sensory and motor circuit modules**. The sensory and motor circuit modules are based on a recent theoretical study that analytically linked Drosophila's sensory and motor circuit model in its internal compass circuit with the 1D translation/rotation group . The sensory circuit module \(u(s)\) is modeled by a ring attractor network that has been experimentally verified in Drosophila's brain (Fig. 4A, blue ring) [32; 33; 34]. The ring attractor network uses its rotation-invariant recurrent connections to generate rotation-equivariant sensory representation \(u(s)\). The motor circuit module has two neuronal populations \(r_{s_{}}(x)\) (Fig. 4A, P-EN), whose feedback connections to sensory neurons \(u(s)\) are shifted by \( x\) towards opposite directions (comparing connections from red and green PB neurons to the ring attractor, Fig. 4A). It was found that these shifted connections give rise to the rotation generator \(\) and the firing rate difference \(_{x}[r_{s_{+}}(x)-r_{s_{-}}(x)]\) determines the rotation speed \(v_{t}\) of sensory representation \(u(s)\). Hence we call \(r_{s_{}}\) as rotation generator neurons hereafter.

**Assemble the full sensory-action circuit**. The rotation group interpretation of sensory and motor circuits  provides a clear interface to connect three circuit modules. Functionally, we use feedforward circuit output neuron \(r_{v_{}}\) to modulate the gain of rotation generator neuron \(r_{s_{}}\), i.e., multiplying each generator neuron \(r_{s_{+}}(x)\) or \(r_{s_{-}}(x)\) by feedforward circuit output neuron response (scalar) \(r_{v_{+}}\) or \(r_{v_{-}}\) respectively. The gain modulation of rotation generator neurons \(r_{s_{}}\) by rotation speed \(v_{t}\) was indeed observed in experiments . In addition, the feedforward circuit receives the instantaneous sensory responses \(u(x-s)\) (Eq. 19) generated by the ring attractor network.

**Theoretical analysis of the full circuit**. We perform theoretical analysis of the full circuit dynamics to verify whether it implements sequential rotations toward the goal direction (Eq. 17). We perform

Figure 4: (A) The full circuit of the sensory-action loop. The diagram is simplified from Drosophila’s goal-directed navigation circuit to illustrate connections, without influencing the circuit function. Only neurons on the right side are labeled and names in the parenthesis denoting Drosophila’s neurons. (B) Top: population response of sensory neurons \(u(s)\) in the full circuit. Bottom: The decoded stimulus direction from \(u(s)\) moves towards the goal direction. (C) Right and left DN neural activities drive the rotation in (B). (D) Difference between right and left DN linearly matches the moving velocity of sensory representation. (E) Sensory response tracks a moving goal direction.

perturbative analysis of the whole circuit dynamics around its attractor states, analytically derive the eigenvector corresponding to the stimulus direction \(s\) in the neural dynamics and find the eigenvector of \(s\) has the largest eigenvalue suggesting the circuit dynamics is dominated by the movements along the stimulus direction. Then throwing away the circuit dynamics along the subspace perpendicular to the eigenvector of \(s\), we find the sensory responses in the ring attractor embedded into the full circuit are approximately reduced to a form similar to the sequential rotation dynamics (Eq. 17),

\[u(x-s_{t}) w_{s_{},s}(r_{v_{+}}-r_{v_{-}})(w_ {s,s_{}} x) u(x-s_{t}),\] (30)

where the difference of motion planning circuit's output neurons \(r_{v_{+}}-r_{v_{-}}\) determines the rotation speed \(v_{t}\) (compared to Eq. 17). In Eq. (30), \(w_{s,s_{}}\) and \( x\) denote respectively the peak weight and the weight shift (absolute value) of the connection from rotation generator neuron \(r_{s_{}}\) to the sensory neuron \(u(s)\) in ring attractor (Fig. 4A), and similarly for \(w_{s_{},s}\). Further analysis reveals,

\[(r_{v_{+}}-r_{v_{-}}) w_{v,}w_{,s}^{2}_{}\| R(|0)\|^{2}[((h-s))],\] (31)

where \(w_{,s}\) and \(w_{v,}\) are the peak weights from sensory neuron \(u(s)\) to neurons \(r_{_{}}\), and the one from \(r_{_{}}\) to the output neuron \(r_{v_{}}\) respectively. \(\) is the weight phase shift for the weight from \(u(s)\) to \(r_{_{}}\) (Eq. (24)). \(R(|0)\) is the Fourier transformation of \(r(x)\) at \(s=0\). The derivation details can be found in SI. Sec. 4.3.

We perform numerical simulations of the full sensory-action loop circuit. We fix all circuit parameters and only change the goal direction \(h\) that determines goal neurons' responses \(u(h)\). Fig. 4B shows the represented stimulus direction \(s\) in the ring attractor's population responses \(u(s)\) indeed moves towards the goal direction \(h\), which is driven by the activity difference between \(r_{v_{}}\) neurons (Fig. 4C. The full circuit model can also track a moving direction (Fig. 4D), although some delay exists due to the temporal dynamics of neurons (see Discussion). Numerical simulation also confirms the rotation speed of sensory responses is proportional to the response difference between \(r_{v_{}}\) (DN neurons).

## 5 Conclusion and Discussion

Motion planning is important in sensorimotor transformation in the brain and embodied agents. The present study formulates motion planning as a group operator search problem and investigates the neural circuit mechanism of operator search goal-directed navigation. Using the 1D rotation group as an example, we analytically derive searching 1D rotation operators can be realized by a two-layer feedforward circuit with three circuit motifs of connection phase shift, nonlinear activation function, and pooling, which is similar to the recently identified goal-directed navigation circuit in Drosophila's brain [20; 21; 22]. We further assemble the feedforward sensorimotor transformation circuit with sensory and motor circuit modules into a full circuit of the sensory-action loop which successfully produces sequential rotation dynamics in tracking goal direction (Fig. 4). Our study provides overarching connections between Lie group operator search with a biologically plausible neural circuit model comparable to Drosophila's circuit. It gains our understanding of neural circuit computations from a structured computation perspective, and also provides a biologically plausible neural network solution for artificial intelligence research.

### Comparison to other work

Although the derived feedforward circuit is similar to circuit models in recent neuroscience studies of Drosophila [20; 21; 22], there are several notable differences. First, recent circuit models required both neural responses \(u(s)\) and \(u(h)\) to have a _cosine_-profile (pure frequency component at \(=1\), Eq. 13) [20; 21]. Although the cosine profile is experimentally supported, our theory _releases_ the requirement of neural response profile, e.g., our sensory-action circuit has Gaussian profile neural responses (Fig. 4A). The generalization may reduce the limitation when deploying the neural circuit model in real applications. Second, goal-directed navigation circuit models in Drosophila's research [20; 21; 22] haven't composed a full circuit of the sensory-action loop as in the present study. In addition, from the group equivariant machine learning perspective, the group operator search theory and the motion planning feedforward circuit in the current study correspond to the sensorimotor transformation stage, which is complementary to many equivariant neural networks corresponding to the sensory system (e.g., [24; 25; 26; 17; 27]) when building embodied agents.

### Extensions and limitations of the model

**Extension to complicated scenarios**. For the sake of concision and biological solidity, we only demonstrated the 1D rotation case in the main text, but our modeling framework has the potential to extend to more complicated scenarios. The 2D translation group is a sufficient example to explain its generality. An important step in motion planning neural circuit is approximating the derivative of the objective function over the transformation amount (Eq. 18) by the spatial difference in the neural circuit (Eq. 20), i.e., the sensory representation is rotated to the positive and negative direction (\(_{t}+\) and \(_{t}-\) in Eq. 20). This spatial difference strategy can also be used in the 2D case and there are two equivalent circuit solutions. One is considering an allocentric representation with an x-y coordinates, where the sensory representation will be shifted along \( x\) and \( y\), forming 4 neuron populations analog to PFL3 left and right neurons in our model, which was also considered in spatial representation circuits . Another strategy operates in an egocentric representation with a polar coordinate, and the sensory representation will be shifted along the clockwise and counter-clockwise directions, requiring 2 neuron populations This strategy is supported by a recent experiment (). A simulation result is shown in Fig. S1.

**Non-uniform distribution of neurons**. Our model considered neurons are uniformly distributed in the attractor manifolds, a simplification widely used in continuous attractor networks [38; 39; 40; 41]. Although the assumption holds in Drosophila's brain, the representation is usually non-uniform in other cases. For non-uniform distributions of neurons in the current circuit model (the \(x\) in Eq. S12 is irregular), the same neural circuit dynamics (Eqs. S13-S15 in the SI.) can still approximately facilitate motion planning and rotate heading representations. To realize exact computation in the non-uniform case, the recurrent weights (below Eq.S12 in SI.) need to be fine-tuned numerically, by using a technique similar to . Overall, we think the non-uniform distribution does not alter the neural circuit implementation substantially while it requires new theoretical insights to understand why the system still functions effectively. Besides, the uniform distribution of neurons is only required by the translation symmetry , while it can be non-uniform/imperfect in other group structures, e.g., the scaling group would require a log coding .

**False nulling problem**. Our feedforward motion planning circuit outputs zero speed when the heading and goal directions are anti-aligned, which is under debate in experiments (e.g.,  observed maximum speed around the anti-aligned direction while  observed the opposite). A reasonable model should not have the 'false nulling' problem (setting at the opposite direction ), and one potential circuit solution is introducing PFL2 neurons observed in Drosophila which fire actively at the anti-aligned direction. That is, PFL2 neurons will speed up turning velocity near the opposite direction and provide gain modulation to P-EN to E-PG feedback. Moreover, including PFL2 will only change the \(\) in our theoretically defined objective function (Eq. 18).

**Future work**. From the neurobiology perspective, the direct gain modulation from \(r_{v_{}}\) (DN neurons) to \(r_{s_{}}\) (P-EN neurons) in the full circuit model (Fig. 4A, Eq.S14) needs to be verified by future experiments. It is likely to be the case in Drosophila's brain because \(r_{s_{}}\) neurons are gain modulated by rotation speed [32; 33; 34]. From the machine learning point of view, as a proof of concept, we only study the theory and corresponding circuit model for 1D rotation operator search, where the group representation theory (Sec. 2.1 - 2.2) appears unnecessary because an ansatz of the optimal operator can be obtained intuitively (Eq. 6). Nevertheless, the group representation theory and the research protocol in the present study are necessary for searching complicated group operators especially non-commutative groups, e.g., \(SO(3)\) and \(SE(2)\), where obtaining the solution of the required operator is non-trivial and no longer intuitive (e.g., ). The group representation theory is a normative method that guarantees to find such an operator and derive corresponding circuit models. Extending the motion planning circuit to search more complicated group operators forms our future research.