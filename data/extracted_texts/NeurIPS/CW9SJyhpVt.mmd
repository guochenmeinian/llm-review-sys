# GV-Rep: A Large-Scale Dataset for Genetic Variant Representation Learning

Zehui Li\({}^{*}\)

Imperial College London

Vector Institute

zl6222@ic.ac.uk

&Vallijah Subasri\({}^{*}\)

University Health Network

Hospital for Sick Children

Vector Institute

vallisubasri@gmail.com

&Guy-Bart Stan

Imperial College London

g.stan@imperial.ac.uk

&Yiren Zhao

Imperial College London

a.zhao@imperial.ac.uk

&Bo Wang\({}^{}\)

University Health Network

University of Toronto

Vector Institute

bowang@vectorinstitute.ai

###### Abstract

Genetic variants (GVs) are defined as differences in the DNA sequences among individuals and play a crucial role in diagnosing and treating genetic diseases. The rapid decrease in next generation sequencing cost, analogous to Moore's Law, has led to an exponential increase in the availability of patient-level GV data. This growth poses a challenge for clinicians who must efficiently prioritize patient-specific GVs and integrate them with existing genomic databases to inform patient management. To addressing the interpretation of GVs, genomic foundation models (GFMs) have emerged. However, these models lack standardized performance assessments, leading to considerable variability in model evaluations. This poses the question: _How effectively do deep learning methods classify unknown GVs and align them with clinically-verified GVs?_ We argue that representation learning, which transforms raw data into meaningful feature spaces, is an effective approach for addressing both indexing and classification challenges. We introduce a large-scale genetic variant dataset, named GV-Rep, featuring variable-length contexts and detailed annotations, designed for deep learning models to learn GV representations across various traits, diseases, tissue types, and experimental contexts. Our contributions are three-fold: (i) **Construction** of a comprehensive dataset with 7 million records, each labeled with characteristics of the corresponding variants, alongside additional data from 17,548 gene knockout tests across 1,107 cell types, 1,808 variant combinations, and 156 unique clinically-verified GVs from real-world patients. (ii) **Analysis** of the structure and properties of the dataset. (iii) **Experimentation** of the dataset with pre-trained genomic foundation models (GFMs). The results highlight a significant disparity between the current capabilities of GFMs and the accurate representation of GVs. We hope this dataset will advance genomic deep learning to bridge this gap.

## 1 Introduction

Genetic variants (GVs) play a pivotal role in disease diagnostics, phenotyping, risk stratification, and as therapeutic targets in drug design and discovery. The advent of next-generation sequencing (NGS) technologies has markedly increased the availability of GV data. This abundance necessitates advanced computational approaches for variant interpretation, which are crucial for advancing personalized medicine and mitigating clinician burnout .

Over the past decade, the ACMG-AMP  guidelines have become the standard for interpreting and reporting genetic variants (GVs) in the clinical genetic testing of Mendelian disorders, which are characterized by high penetrance and rarity. However, these guidelines do not account for the complex biological processes governing GVs, ranging from alternative splicing  and phenotypic variations , to changes in gene expression  and impacts on cellular fitness .

Recent advancements have seen deep learning models applied to GVs with promising results for variant effect prediction (VEP) [8; 10; 43]. However, evaluation frameworks employed by these models oversimplify the interpretation of GVs, treating them as binary entities: pathogenic variants leading to genetic diseases or benign variants found in healthy populations. This binary classification fails to account for the complexities of genetic expression, disregarding mechanisms like penetrance and expressivity. Penetrance is the proportion of individuals with a specific genotype who exhibit the associated phenotype , whereas expressivity refers to the intensity of a given phenotype. GVs can exhibit varying levels of penetrance and expressivity across different biological contexts (e.g. tissue type, cell type, organism) due to epigenetic and epistatic effects . As a result, individuals with the same genetic condition can experience a diverse spectrum of symptoms, underscoring gaps in current VEP datasets and benchmarks. Moreover, in clinical settings, a more nuanced variant classification system is essential for accurate risk assessment and effective genetic counseling .

The development of deep learning approaches for modeling these multifactorial effects of GVs is still in its nascent stages, primarily due to the lack of comprehensive datasets that capture the intricate relationships between GVs and their downstream effects on complex traits. While there are existing datasets for modeling GVs, they often suffer from limitations such as insufficient size, lack of diversity, and non-standardized formats that are not conducive to deep learning applications. It's not clear what pre-training datasets and regimes contribute to improved variant effect prediction (VEP). Our work introduces GV-Rep, a large-scale dataset designed to bridge this gap and foster the next generation of genetic variant analysis tools.

Our paper introduces _GV-Rep_, a large-scale dataset of functionally annotated genomic variants (GVs), which could be used for deep learning models to learn meaningful genomic representations. As illustrated in Figure 1, _GV-Rep_ aggregates data from seven leading public GV databases and a

Figure 1: **Overview of the proposed dataset pipeline** The input includes clinician-verified genetic variants from multiple sources like ClinVar and GTEx. These are processed through data cleaning, sequence extraction, and unified formatting. The resulting data is used in genomic foundation models for various tasks such as prediction and indexing.

clinician-validated set compiled by our team. The dataset organizes GV records into a standardized format, consisting of a (reference, alternative, annotation) triplet, and each record is tagged with a label that denotes attributes like pathogenicity, gene expression influence, or cell fitness impact. These annotated records are utilized to fine-tune genomic foundation models (GFMs) [10; 30; 43]. These finetuned GFMs generates meaningful vectorized representations, enabling the training of smaller models for classifying unknown GVs or for search and indexing within a vectorized space.

Our contribution is three-fold:

**Dataset for GV representation learning** We assemble a large-scale GV dataset with more than 7.5 million GV records with diverse labels. This includes 155 well-labeled clinician verified GV records, serving as the anchor GVs for clinical usage (Section 5.3.1).

**Analysis of dataset** We conduct detailed analyses of the _GV-Rep_ dataset, examining the distribution and statistics of the variants and labels, highlighting the diversity and unique properties of the dataset.

**Experimentation** We finetune several GFMs with our dataset for classification and indexing. While GFMs achieved more than 65% AUROC in conventional pathogenicity classification, their performance was only marginally better than random chance in more challenging scenarios, such as predicting cell-specific regulation of gene expression with splicing variants. We hope that this work will inspire further research into the representational learning of genetic variations.

The code and dataset are available at [https://github.com/bowang-lab/genomic-FM](https://github.com/bowang-lab/genomic-FM).

## 2 Preliminaries and Related Work

**Deep Learning for Genetic Variants** Genetic variants (GVs) are defined as differences observed between an individual's genome and the reference genome. Typically, a genetic variant is represented by a triplet consisting of: chromosome, position, reference nucleotides, and alternative nucleotides. GVs can include single nucleotide variants (SNVs), insertions or deletions (indels), and structural variants, depending on the specific changes in nucleotides . One of the earliest use cases of pathogenicity classification is utilized in a study where CNN models were leveraged to distinguish disease-causing mutations from benign genetic variants . Another study employed a CNN-based architecture to predict the influence of GVs on gene expression . Recently, the focus of deep learning applications to genomics has shifted to large foundation models such as DNABERT2 , Nucleotide Transformer  and HyenaDNA .

**Genomic Datasets for Deep Learning** There is a growing number of datasets emerging across a broad spectrum of genomic tasks from variant effect prediction (VEP) to genomic feature prediction. HyenaDNA leverages the Genomic Benchmarks dataset , which focuses on genomic feature prediction of enhancers (in humans and drosophila), non-TATA promoters, regulatory regions, and open chromatin regions . DNABERT2 draws on the Genome Understanding Evaluation (GUE) dataset , which encompasses genomic feature prediction tasks including promoter prediction, splice site prediction, COVID-19 variant classification, epigenetic marks prediction, and transcription factor binding sites prediction across human and mouse genomes. Genome Understanding and ANnotation in silico Evaluation (GUANinE)  is a benchmark dataset that focuses on prediction of functional elements, conservation, and gene expression. BEND  utilizes existing datasets to benchmark both transformer-based and state-space models, demonstrating the versatility and

   Database & \#Variants & Organism & Cell/Issse & Multi-Variants & Gene & Genotype-phenotype \\  & & Specificity & Specificity & Interactions & Knock-out & association \\  ClinVar  & 1.7M & \(\) & \(\) & \(\) & \(\) & ✓ \\ Cell Passport  & 0.7M & \(\) & ✓ & \(\) & \(\) & \(\) \\ Project Score  & 17.5K & \(\) & ✓ & \(\) & ✓ & \(\) \\ GTEx eQTLs  & 0.6M & \(\) & ✓ & \(\) & \(\) & ✓ \\ GTEx sqTLs  & 1.2M & \(\) & ✓ & \(\) & \(\) & ✓ \\ GWAS  & 0.3M & \(\) & \(\) & \(\) & \(\) & ✓ \\ MAVEDB  & 3.0M & ✓ & \(\) & \(\) & \(\) & \(\) \\ OIDA  & 1.8K & \(\) & \(\) & ✓ & \(\) & ✓ \\  GV-Rep & 7.5 M & ✓ & ✓ & ✓ & ✓ & ✓ \\   

Table 1: **Statistics of databases from which GV-Rep is constructed**performance of these architectures for VEP and genomic feature prediction of regulatory regions. Nucleotide Transformer  performs evaluation across a broad range of tasks including genomic feature prediction of regulatory elements, splice site, and histone mark, and prioritization of GVs.

**Limitations and Opportunities of Existing GV Datasets** Despite their extensive scope, existing genomic variant (GV) datasets often lack sufficient biological and clinical relevance and complexity, and are constrained by limited dataset sizes and fixed, short context lengths. These benchmarks predominantly focus on tasks such as binary classification of pathogenicity and expression quantitative trait loci (eQTLs) [4; 10; 43]. Moreover, the datasets used are generally derived from major GV databases, with varying criteria for selection across different studies. For example, the BEND benchmark distinguishes between pathogenic and benign variants from ClinVar as classified by Ensembl. GPN-MSA  evaluates variant effect by contrasting ClinVar pathogenic variants with those from the gnomAD database . Meanwhile, Nucleotide Transformer assesses ClinVar variants deemed likely pathogenic against variants from the 1000 Genomes project with a minor allele frequency (MAF) greater than 5 percent . In this work, our goal is to develop a GV dataset that surpasses the existing benchmarks in scale, diversity and complexity, minimizes selection bias, and provides a unified format that is optimized for consumption by machine learning algorithms.

**Deep Learning Model for Genomic Assay Prediction** Prior to the emergence of GFMs trained on pure DNA sequences with a reconstruction objective, deep learning had already demonstrated success in predicting genome-scale sequencing assays such as CAGE, DNase-seq, and ChIP-seq. In these tasks, DNA sequences are first mapped to high-dimensional vectors, which are subsequently transformed into real-valued arrays representing the assay results. Over the years, a variety of deep learning models have been developed for these predictions. Early models, such as DeepBind , Basenji , and Basenji2 , utilized CNN-based architectures. More recent approaches have combined CNNs with transformers, as seen in models like Enformer  and Borzoi . These models are not only effective in assay prediction but can also be applied to Genetic Variant Prediction. By using the predicted values or intermediate vector representations to form a latent space, scores for genetic variants can be directly extracted through dimensionality reduction techniques or a learned linear head. One challenge of training these models are that annotated dna sequence data with track information are needed for training, this potentially pose challenges to scale up the training.

## 3 Dataset

### Dataset Overview

As shown in Table 4, we collected the GV-Rep dataset from seven databases of genetic variant (GV) effects studies. These studies cover a wide range of existing GVs and extend beyond conventional binary classification settings that primarily sub-sample from ClinVar . Specifically, we included GV studies from Cell Passport  and Score Projects , which provide GV effects with cell- and tissue-specific contexts. Additionally, we incorporated data from OLIDA , which presents the effects of multiple GVs on diseases. The resulting dataset, GV-Rep, thereby offers a comprehensive and context-rich resource for the analysis of GV effects.

### Dataset Construction

**Construction** Figure 2 illustrates the dataset construction process. Firstly, Genetic Variant (GV) records, their annotations, and associated labels are extracted from databases. To enable downstream machine learning models to process these records, a **sequence extractor** is used to convert GV records by locating the position of the GV in the human reference genome. During this process, GVs located on rare contigs--specifically, contigs not included in the GRCh38/hg38 reference genome--are filtered out.

**Usage** The extracted sequence, which has the GV centered in the middle, is of a context length defined by the user, resulting in a (reference sequence, alternate sequences) pair. These paired sequences, along with the annotations, serve as inputs for fine-tuning or inference with GFMs based on user requirements. Additionally, once the GFMs are finetuned, they can be used to vectorize unknown GVs. This allows the use of vector database tools, such as FAISS , to search and match unknown GVs with labeled GVs in the database.

**GV Record**: Following this construction process, the minimum unit of GV-Rep dataset is a record, which is an \((x,y)\) pair. Here, \(x=(,,)\), and \(y\) is the corresponding label indicating the class of GV or a real value quantifying the effects of the GV.

#### 3.2.1 Dataset Description

**ClinVar** ClinVar hosts genetic variants (GVs) supported by evidence and classified into four pathogenicity categories across 13,209 disease types: likely benign (\(n=714,866\)), benign (\(n=195,030\)), pathogenic (\(n=143,348\)), and likely pathogenic (\(n=100,859\)). The genetic variants in ClinVar can be further classified by variant type as a missense variant, intronic variant, splice donor variant, or synonymous variant.

**Cell Passport** The Cell Model Passports dataset includes curated data on patient samples, model relationships, and over 1,200 established cancer cell lines and organoid models. It provides comprehensive model characteristics, genetic feature summaries, and the capacity to integrate multiple genomic datasets.

**Project Score** This dataset features genome-scale CRISPR-Cas9 drop-out screens across 1,107 cell lines, including extensively annotated cancer models, to identify genes critical for cellular fitness in specific molecular contexts.

**GTEx QTLs** The dataset comprises 1,207,976 expression quantitative trait loci (eQTLs) and 618,932 splicing quantitative trait loci (sQTLs) across 14 tissue types.

**GWAS Catalog** Maintained by NHGRI-EBI, this catalog includes data from over 45,000 genome-wide association studies (GWAS), covering more than 5,000 human traits and hosting over 40,000 datasets with full p-value summary statistics. It features 306,890 SNPs associated with 53,933 traits/diseases that were mapped to their Experimental Factor Ontology (EFO) term .

**MAVEDB** This database includes multiplex assays of variant effect (MAVEs), such as deep mutational scans and massively parallel reporter assays. Each experiment tests thousands of variants, providing functional effect scores relative to a reference for genetic elements (e.g. coding sequences, promoters, enhancers). MAVEDB was further curated to include only experiments with complete DNA sequence information, totaling 3,166,541 variants across 1,304 studies.

**OLIDA** The OLIDA database has been curated to include 1,808 high-quality bilocus variant combinations linked to 219 oligogenic diseases as a positive set , and 150,500 bilocus combinations from healthy individuals of The Thousand Genomes Project (1KGP) as a negative set . Future models can leverage OLIDA to predict interactions between multiple variants and their combined effects on phenotypes.

Figure 2: **Dataset Construction and Usage** This diagram give an example on the construction workflow of GV-Rep dataset from a source database. Genetic variant records, containing chromosome position and reference/alternate alleles, along with biospecimen-specific annotations and a binary label indicating the significance of the GV, are extracted from source GV database. The sequence extractor processes these GV records, which can then be used by GFMs for predicting the significance of unknown genetic variants. The finetuned GFMs could encode and index unknown GVs by matching them with GVs in the databases.

## 4 Dataset Statistics and Analysis

**Basic Statistics** Overall, we have GV-Rep \(=(,)=\{(x^{(n)},y^{(n)})\}_{n=1}^{N}\), with \(N=28,363,315\) (See Table 4 in Appendix A for breakdown statistics of each type of records). The number of Cell Type Specific Gene-KO records is significantly larger than the other types because for each type of cells, we will have numerous gene-ko experiment, and overall, there are 17,548 gene-ko \(\) 1107 cell lines records.

**Variants Distribution and Label Diversity** Figure 3 shows the _distribution of the GV across all the chromosomes_, we can see that GV-Rep covers most of the positions of human chromosomes uniformly. The exception is ChrY, which has much fewer GVs compared to the other chromosomes.

In addition, the labels associated with each GV exhibit significant diversity. **(1) Diseases Coverage**: Our dataset includes 65,153 diseases and disease-related traits sourced from ClinVar and GWAS. Figure 3(a) illustrates the text embeddings of these diseases and traits, generated using the T5 text encoder . Notably, GWAS traits  extend beyond simple disease names, including additional terms such as the expression levels of proteins, ligands, and hormones. In contrast, the disease names

Figure 4: (a) Distributions of Diseases and Trait Labels (b) Gene- KO Fitness Score Distributions

Figure 3: **Distributions of Genetic Variants by Chromosome**. The distribution of GVs are relatively uniform across various chromosomes.

from ClinVar  are primarily symptom-focused. **(2) Gene-KO Fitness Score Distribution**: The fitness score describes the influence of knockout of a gene on the host cell. A negative score indicates a statistically significant effect on cell fitness. Figure 4 shows the distribution of fitness scores across 1,107 cell lines and 17,548 genes. The overall distribution skews towards negative values, indicating that most gene knockouts influence the biological activity of genes. **(3) Multiplex Assays of Variant Effect (MAVE) Distribution**: The MAVE score is a normalized quantitative measure that indicates how a specific genetic variant affects a biological trait or function. A negative value indicates the pathogenicity of the variant . Figure 7 shows the distribution of MAVE scores. Overall, the scores are symmetrically distributed around zero.

Statistics of Clinically Verified GVsThis dataset contains 155 unique variants from 84 anonymized patients with hereditary cancer predisposition that have been interpreted and classified by board-certified clinical molecular geneticists, in accordance with the ACMG-AMP guidelines . The variants have been prioritized from highest known cancer predisposition potential to lowest using the Cancer Variant Classification Schema by leveraging tiered cancer gene lists, pedigree-based analyses and expert curation. The Cancer Variant Classification Schema consists of five classes that account for (i) the relationship between a given gene and the cancer developed, (ii) the functional consequence of a variant in a particular gene and iii) knowledge of co-segregation and familial inheritance patterns, whereby:

* _Class 1:_ P/LP variant in a known autosomal dominant cancer predisposition gene (CPG).
* _Class 2:_ P/LP variant in a known autosomal recessive CPG.
* _Class 3:_ P/LP variant in a known cancer gene frequently mutated in the somatic context.
* _Class 4:_ P/LP variant in a novel, candidate cancer gene supported by sufficient evidence.
* _Class 5:_ Cancer-segregating variants of uncertain significance (VUS) in a known cancer gene.

## 5 Experiment with Genomic Foundation Models

### Experiment Setup

To demonstrate the use case of our dataset, we run several experiments with four state-of-the-art pre-trained Genomic Foundation Models (GFMs): HyenaDNA(Hyena) , DNABERT2 , Nucleotide Transformer (NT), and Nucleotide Transformer v2 (NTv2) 3. During the model finetuning process, we attach a three-layer-CNN header to the frozen pretrained GFMs to aggregate information. PyTorch Lightning is used to implement the finetuning and evaluation process. NVIDIA V100 32GB are used for inference and finetuning. A total of 400 GPU hours are approximately used in total. We use Adam Optimizer  and set the learning rate to \(1e^{-3}\).

### Variant Property Prediction

Scaling Law in GV PredictionWe investigated the influence of context lengths on classification accuracy using the ClinVar disease classification task. Intuitively, the effect of a GV should be context-dependent. Longer contexts should facilitate better prediction of GV effects by modelling long-range interactions. For example, if a GV occurs in a gene-encoding region, it is more likely to be a pathogenic mutation based on it's context. To test this hypothesis, we constructed a simple task to predict whether a given GV would lead to lung-related diseases4. Figure 5 shows the AUC-ROC

Figure 5: **Scaling Law of Genomic Foundation Models in ClinVar Lung Disease Classification.** The plot shows the accuracy of various models (HyenaDNA, DNABERT2, NT, and NT_v2) vs. sequence length. The context length extends on both sides of the mutated nucleotides of genetic variants.

of fine-tuned GFMs versus sequence length. It is clear that as we decrease the context length, the prediction accuracy drops correspondingly. Moreover, there is a performance difference between the four models: while Nucleotide Transformer version 2 achieves the best performance with a context length of 1024, it is very sensitive to context length, and its accuracy drops steeply with reduced context length. In contrast, DNABERT2 and Hyena tend to be more robust to changes in context length.

Fine-Grained and Coarse-Grained TasksWhile existing tasks mainly focus on pathogenicity prediction, our dataset includes GVs from multiple perspectives, enabling the construction of more fine-grained tasks to predict how a GV influences splicing (sQTL) and how a GV is related to a gene fitness score in a given cell type (Gene-KO). Here, we present the evaluation results of four GFMs on three tasks: pathogenicity classification on ClinVar (four-class classification), splicing effect (sQTLs) (two-class classification), and a regression task, gene knock-out fitness score prediction (Gene-KO). The context length for all tasks is set to 1024 base pairs. Note that, compared to prior work, the ClinVar pathogenicity classification task we have here contains pathogenicity classes, longer context and 1.3 million GVs.

As shown in Table 2, the results are mixed. Overall, existing GFMs struggle with cell- and tissue-level tasks that are heavily influenced by complex regulatory mechanisms: Gene-KO and sQTLs. In sQTLs, most models perform only slightly better than random guessing. In the Gene-KO task, three models converged to the same solution, suggesting that the GFMs are unlikely to provide meaningful representations, and instead, the added header learns to encode the gene-KO values. Additionally, we found that multi-species models (DNABERT2 and NT-V2) tend to perform better on the proposed tasks than models (Hyena and HT-Human) trained with only the human reference genome.

### Genetic Variants Indexing

Genomic Foundation Models (GFMs) map GVs into a vector space, enabling the use of vector database tools such as faiss  to quickly index GVs - match unknown GVs with annotated GVs and quantify the distances between GVs. The **clinician verified GVs (CVGV)** in our dataset could serve as a testbench to show the effectiveness of GFMs when being applied for GV encoding and indexing.

**Approaches** Given a set of unknown GVs \(=\{x^{(n)}\}_{n=1}^{N}\), and the well annotated GVs set \(=(_{A},_{A})=\{(x_{A}^{(n)},y_{A}^{(n)})\}_{n= 1}^{N_{A}}\). we could use GFMs as an encoder \(_{}\) and a distance function \(d\) to form a Query \(Q\). The query can be formed in two ways 1) An unknown variant \(x_{i}\) is used as the keyword and search against in the annotated GVs set \(\). Then the query will be formed as \(Q(_{}(x_{i}),_{}(),d)\), returning a list of known GVs which are similar to \(x_{i}\). Such a clinical use case would be to better understand an unknown genetic variant that has been consistently identified in patient samples. In this scenario, clinicians may want to search to see if there are existing GVs that are similar to the unknown GV, such that it can be better categorized. 2) Set the keyword to be an annotated \(x_{A}^{i}\), and search against an unknown set of GVs \(\). This can then be used by genetic counsellors to prioritize unknown GVs from a patient. Here the query will be \(Q(_{}(x_{A}^{i}),_{}(),d)\).

#### 5.3.1 Comparison of Indexing Accuracy between Original and Finetuned GFMs

   Model & _ClinVar (AUROC\% \(\))_ & _sQTL (AUROC\% \(\))_ & _Gene-KO (MSE \(\))_ \\  Random & \(50.59 0.10\) & \(50.50 1.07\) & \(1.11 0.09\) \\  Hyena & \(65.05 0.27\) & \(52.20 2.62\) & \(1.06 0.11\) \\ DNABERT2 & **73.87 \(\) 0.21** & \(52.62 2.98\) & \(1.06 0.11\) \\ NT-Human & \(65.75 0.25\) & \(51.33 5.87\) & \(1.06 0.11\) \\ NT-V2 & \(68.73 0.27\) & **54.10 \(\) 1.13** & \(1.06 0.11\) \\   

Table 2: AUROC \(\) and mean square error (MSE \(\)) values for various Genomic Foundation Models running on GV-Rep dataset. The tasks are ClinVar pathogenicity (ClinVar), sQTL Significance Classification (sQTL), and Gene Knock-Out Fitness Score Prediction (Gene-KO).

**Task** In CVGV, each variant is annotated with a unique label, indicating to what extent a GV is associated with cancer predisposition. Here we compare how the original pretrained GFMs and finetuned GFMs with 1.3 million ClinVar GVs perform on GV indexing.

**Metric** We first check when querying with a GV with class label k, the optimal indexing algorithm should return GVs which are similar to the query and hereby most of the labels would be k. Here, we sample query vectors and search with the CVGV set, and for each query, we will take the top 10 results and count the number of returned GVs with the same label as the query. The percentage of the GVs with the same label as the query GV is used as the metric, indicating the _Variants Indexing Accuracy_.

**Result** As shown in Table 3, the fine-tuned GFMs consistently perform better than their pretrained counterparts across four GFMs. In terms of the difference in model performance, NT achieved the highest accuracy among models without finetuning, while Hyena achieves the best performance after finetuning with 1.3 million pathogenicity records in ClinVar.

#### 5.3.2 Querying Time

In many resource-limited scenarios such as clinical settings, the speed of search operations is critical. Consider a query \(Q(_{}(x_{i}),_{}(),d)\), where \(_{}\) encodes a genetic variant (GV) into an \(m\)-dimensional vector, and \(\) contains \(n\) data points. The dimensions of the embedding, \(m\), and the number of data points, \(n\), significantly influence the speed of the query. This theoretical understanding aligns with the empirical data presented in the subsequent figures.

Figure 5(a) shows that the querying time increases linearly with the database size, demonstrating that larger databases require more time for data retrieval. Similarly, Figure 5(b) reveals a linear increase in querying time as the vector dimension grows, suggesting that more complex data representations extend the retrieval process. These observations emphasize the need to carefully consider database size and vector dimensionality to maintain efficient querying performance in practical implementations.

## 6 Limitations and Future Work

While GV-Rep is unlikely to have a negative societal impact, caution must be exercised whenever this dataset is used to inform clinical decision-making. Applications developed using this dataset should be implemented with care to uphold the principle of human-in-the-loop for real-world applications. It is crucial that all genetic variants predicted by machine learning models are thoroughly reviewed and validated by geneticists and clinicians to ensure accurate and responsible use in informing patient care in clinical settings. The use of genetic data also presents risks to the privacy of an individual,

   Model & _W/O_ Finetuning & Finetuned \\  Random & 0.334 \(\) 0.04 & - \\  Hyena & 0.428 \(\) 0.09 & **0.662 \(\) 0.16** \\ DNABERT2 & 0.446 \(\) 0.06 & 0.616 \(\) 0.06 \\ NT & **0.558 \(\) 0.10** & 0.620 \(\) 0.10 \\ NTV2 & 0.478 \(\) 0.06 & 0.542 \(\) 0.05 \\   

Table 3: **Variants Indexing Accuracy of GFMs** on clinician verified GVs with and without (W/O) Finetuning

Figure 6: (a) Querying time as a function of database size, with vector dimension fixed at 512. (b) Querying time as a function of vector dimension, with database size fixed at 40,000.

which can be used for genetic discrimination. GV-Rep will be monitored and validated as more data is integrated, ensuring that the dataset continues to reflect the diversity of populations it aims to serve and minimizing the risk of bias over time. This vigilance will help ensure that GV-Rep remains a valuable tool for advancing personalized medicine, while safeguarding against unintended consequences.

Despite the advances offered by the GV-Rep dataset in GV benchmarking, there are several areas ripe for enhancement. Future considerations include leveraging fine-mapping tools that integrate GWAS/QTL association signal strength and linkage disequilibrium (LD) information to prioritize potential causal variants. To improve the fairness and applicability of these models, the dataset's scope should be broadened to include sensitive attributes such as ethnicity and sex. This would facilitate an evaluation of model fairness across demographics, especially for groups typically underrepresented in existing genomic databases. Integrating epigenetic data, like DNA methylation patterns, could deepen our understanding of how these factors influence gene expression and the resulting phenotypic manifestations of genetic variants. Expanding to include longer genetic contexts and cross-species pre-training could provide valuable evolutionary insights and accelerate translational research from model organisms to patient care.

Conducting a thorough assessment of tokenization, pre-training data, and training regimes across a wide range of tasks will inform more effective model training strategies. Additionally, detailed evaluations of variant indexing and scaling laws across various diseases contexts will inform model generalization. Future research should explore diverse fine-tuning approaches to enhance model accuracy and adaptability. Further development of polygenic risk scores and control vectors could lead to more personalized therapeutic strategies, dramatically increasing the dataset's utility and impact on genomics and personalized medicine. Addressing these limitations and focusing on these future directions will be crucial for enhancing the dataset's utility and impact on deep learning applications for GVs.