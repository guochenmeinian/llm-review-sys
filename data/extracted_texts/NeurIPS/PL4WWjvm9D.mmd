# Decoupling Quantile Representations from Loss Function

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

The simultaneous quantile regression (SQR) technique has been used to estimate uncertainties for deep learning models, but its application is limited by the requirement that the solution at the median quantile (\(=0.5\)) must minimize the mean absolute error (MAE). In this article, we address this limitation by demonstrating a duality between quantiles and estimated probabilities in the case of simultaneous binary quantile regression (SBQR). This allows us to decouple the construction of quantile representations from the loss function, enabling us to assign an arbitrary classifier \(()\) at the median quantile and generate the full spectrum of SBQR quantile representations at different values of \(\). We validate our approach through two applications: (i) detecting out-of-distribution samples, where we show that quantile representations outperform standard probability outputs, and (ii) calibrating models, where we demonstrate the robustness of quantile representations to distortions. We conclude with a discussion of several hypotheses arising from these findings.

## 1 Introduction

Deep learning models have become ubiquitous across diverse domains, and are increasingly being used for several critical applications. Common questions which arise in practice are - (a) Can this model be used on the given data input? and (b) If so, how much can one trust the probability prediction obtained? The former refers to the problem of Out-of-Distribution (OOD) detection [13; 9] and the latter refers to the problem of Calibration [10; 19; 22]. Understanding the applicability of a given deep learning model is a topic of current research [30; 6; 25; 14]. In this article we consider the quantile regression approach to answer these questions.

Quantile regression techniques [16; 17] provide much richer information about the model, allowing for more comprehensive analysis and understanding relationship between different variables. In  the authors show how simultaneous quantile regression (SQR) techniques can be used to estimate the uncertainties of the deep learning model in the case of regression problems. However, these techniques aren't widely used in modern deep learning based systems since  - (a) The loss function is restricted to be mean absolute error (MAE) or the pinball loss. This might not compatible with domain specific losses. (b) Moreover, it is difficult to optimize the loss function in presence of non-linearity. (c) Adapting the quantile regression approach for classification is also challenging due to piece-wise constant behavior of the loss function, due to discrete labels.

Decoupling loss function and computing quantile representations:Consider the problem setting where a pre-trained classifier \(f_{}()\) (including the dataset on which it is trained) is given and we wish compute the quantile representations for detailed analysis of the pre-trained classifier. Classical approach is to retrain the classifier using the quantile loss (equation 2). However, one runs the riskof losing important properties while retraining since pinball loss would have different properties compared to loss used for pre-training. Moreover, it is not clear how penalties (used for pre-training) given to attributes such as gender-bias etc. should change with the quantile1. Further, aspects like calibration error of the pre-trained network cannot be established by retraining with a different loss. Thus, one requires a more elegant solution than retraining using the pinball loss.

**Main Outcomes:** In this article we propose an approach to _decouple the construction of quantile representations from the loss function_. We achieve this by identifying the _Duality_ property between quantiles and probabilities. We leverage the duality to construct the quantile-representations for any pre-trained classifier \(f_{}()\) in section 3.1. Such quantile representations are shown to capture the training distributions in section 4.2. We show that these representations outperform the baseline for OOD detection in section 4.4. And further verify that quantile representations can potentially identify OOD samples perfectly. We also show that probabilities arising from quantile-representations are _invariant_ to distortions in section 4.3. Moreover, we see that standard post-hoc calibration techniques such as Platt-scaling fail to preserve invariance to distortions. Proof-of-concept experiments to improve OOD detection and identifying distribution shifts within the data are discussed in the appendix (supplementary material).

**Illustrating the Construction of Quantile Representations:** Before diving into the details, we illustrate the construction using a simple toy example and considering the problem of OOD detection. Figure 0(a) shows a simple toy example with 3 classes - \(0,1,2\). Class \(0\) is taken to be out-of-distribution (OOD), while classes \(1,2\) are taken to in-distribution (ID). To get the quantile representation - (step 1) we first construct a simple classifier to differentiate classes \(1,2\), (step 2) To get a classifier at quantile \(\), construct \(y_{i}^{+}=I[p_{i}>]\)2, where \(p_{i}\) denotes the predicted probability in (step 1). Construct a classifier using the new labels \(y_{i}^{+}\). Figure 0(b) illustrates the classifiers obtained at different \(\). In (step 3) concatenate the outputs (predictions) of all the classifiers at different \(\) to get the quantile-representations. Figures 0(c) and 0(d) demonstrate the advantage of having several classifiers as opposed to one. By aggregating (detailed later) the outputs from different classifiers, we are able to identify OOD vs ID samples (using One-Class-SVM ).

**Remark:** Note that the construction in (step 2) does not depend on the procedure followed in (step 1), but only the output probabilities \(p_{i}\). Thus, one can use _any_ procedure in (step 1) without affecting (step 2). This property of quantiles is based on the duality between quantiles and probabilities ( section 2). Intuitively, quantile representations capture the distribution of the training data. Thus, given a pre-trained classifier, quantile representations can be used to analyze the classifier. In particular, as we shall shortly illustrate, one can perform calibration and OOD-detection.

## 2 Simultaneous Binary Quantile Regression (SBQR)

In this section, we review some of the theoretical foundations required for constructing quantile representations. For more details please refer to [16; 17; 32].

Figure 1: Illustrating the construction of Quantile Representations. (a) Simple toy example. (b) Illustrates different classifiers obtained for different \(\). (c) OOD detection using Quantile Representations. (d) OOD detection using the predictions from a single classifier. The region of In-distribution is highlighted in red. Observe that, in this case, quantile-representations are able to differentiate the in-distribution (ID) vs out-of-distribution (OOD).

Let \(p_{}(X,Y)\), denote the distribution from which the data is generated. \(X\) denotes the features and \(Y\) denotes the targets (class labels). A classification algorithm predicts the latent variable (a.k.a _logits_) \(Z\) which are used to make predictions on \(Y\).

Let \(^{d}\) denote the \(d\) dimensional features and \(y\{0,1,,k\}\) denote the class labels (targets). We assume that the training set consists of \(N\) i.i.d samples \(=\{(_{i},y_{i})\}\). Let \(_{i}=f_{,}(;)\) denote the classification model which predicts the logits \(_{i}\). In binary case (\(k=1\)), applying the \(\) (Sigmoid) function we obtain the probabilities, \(p_{i}=f_{}(_{i})=(f_{,}(_{i}))\). For multi-class classification we use the \((f_{,}(_{i}))\) to obtain the probabilities. The final class predictions are obtained using the \(_{k}p_{i,k}\), where \(k\) denotes the class-index.

### Review - Quantile Regression and Binary Quantile Regression

Observe that, for binary classification, \(Z\) denotes a one dimensional distribution. \(F_{Z}()=P(Z)\) denotes the cumulative distribution of a random variable \(Z\). The function \(F_{Z}^{-1}()=\{:F_{Z}()\}\) denotes the quantile distribution of the variable \(Z\), where \(0<<1\). The aim of quantile regression is to predict the \(^{th}\) quantile of the latent variable \(Z\) from the data. That is, we aim to estimate \(F_{Z}^{-1}( X=)\). Minimizing pinball-loss or check-loss ,

\[=_{i=1}^{n}(f_{}(_{i}),y_{i}) {where,}(,y;)=(y-)&(y-)>0\\ (1-)(-y)&\] (1)

allows us to learn \(f_{}\) which estimates the \(^{th}\) quantile of \(Y\). When \(=0.5\), we obtain the loss to be equivalent to mean absolute error (MAE). For the multi-class case we follow the one-vs-rest procedure to learn quantiles for each class.

Simultaneous Quantile Regression (SQR):Observe that the loss in equation 1 is for a single \(\).  argues that - minimizing the expected loss over all \((0,1)\),

\[_{}_{ U}[((,),y;)]\] (2)

is better than optimizing for each \(\) separately. Using the loss in equation 2 instead of equation 1 enforces the solution to have _monotonicity property_. If \((,)\) denotes the solution to equation 2, monotonicity requires

\[(,_{i})(,_{j}) _{i}_{j}\] (3)

Observe that for a given \(_{i}\), the function \((_{i},)\) can be interpreted as a (continuous) representation of \(_{i}\) as \(\) varies over \((0,1)\). The function \((,)\) is referred to as _quantile representation_. \((,)\) is sometimes written as \((,;)\), where \(\) indicates the parameters (such as weights in a neural neural network). For brevity, we do not include the parameters \(\) in this article unless explicitly required.

**Remark on Notation:** To differentiate between the latent scores (logits) and probabilities - we use \((,)\), \(f_{}()\) to denote the probabilities and \(_{}(,)\), \(f_{,}()\) to denote the latent scores. Since we have the relation \((,)=(_{}(,))\) and \(f_{}()=(f_{,}())\) and \(()\) is monotonic, these quantities are related by a monotonic transformation.

Why Quantile Regression? Quantile regression techniques are relatively unknown in the machine learning community, but offers a wide range of advantages over the traditional single point regression. Quantiles give information about the shape of the distribution, in particular if the distribution is skewed. They are robust to outliers, can model extreme events, capture uncertainty in predictions. Quantile regression techniques have been used for pediatric medicine, survival and duration time studies, discrimination and income inequality. (See suppplememtary material for a more thorough discussion.)

## 3 Quantile Representations

As discussed earlier, minimizing equation 2 is not recommended due to unaccountable side-effects. Thus, we require a procedure to construct quantile representations without resorting to minimizing equation 2. In this section we present _duality_ property of the quantile representations, which allows us to do this.

* Let \(=\{(_{i},y_{i})\}\) denote the training dataset. Assume that a pre-trained binary classifier \(f_{}()\) is given. The aim is to generate the quantile representations with respect to \(f()\). We refer to this \(f_{}()\) as base-classifier.
* Assign \((,0.5)=f_{}()\), that is take the median classifier to be the given classifier.
* Define \(y_{i,}^{+}=I[f_{}(_{i})>(1-)]\). We refer to this as modified labels at quantile \(\).
* To obtain \((,)\), train the classifier using the dataset \(_{}^{+}=\{(_{i},y_{i,}^{+})\}\). Repeating this for all \(\) allows us to construct the quantile representation \((,)\).

### Generating Quantile Representations Using Duality between Quantiles and Probabilities

Observe that, for binary classification, equation 1 can be written as

\[(,y;)=(1-)&y=1\\ (1-)()&y=0\] (4)

Thus the following property holds :

\[(,y;)=(1-,y;1-)\] (5)

We refer to the above property as _duality between quantiles and probabilities_. Let \((,)\) denotes a solution to equation 2. It follows from above that, for a given \(_{i}\) and \(_{0}\), if we have \((_{i},_{0})=p_{i}\), then we should also have \((_{i},1-p_{i})=1-_{0}\). In words, a solution which predicts the \(^{th}\) quantile can be interpreted as the quantile at which the probability is \(1-\). This observation leads to the algorithm 1 for generating the quantile representations.

```
1: Let \(=\{(_{i},y_{i})\}\) denote the training dataset. Assume that a pre-trained binary classifier \(f_{}()\) is given. The aim is to generate the quantile representations with respect to \(f()\). We refer to this \(f_{}()\) as base-classifier.
2: Assign \((,0.5)=f_{}()\), that is take the median classifier to be the given classifier.
3: Define \(y_{i,}^{+}=I[f_{}(_{i})>(1-)]\). We refer to this as modified labels at quantile \(\).
4: To obtain \((,)\), train the classifier using the dataset \(_{}^{+}=\{(_{i},y_{i,}^{+})\}\). Repeating this for all \(\) allows us to construct the quantile representation \((,)\). ```

**Algorithm 1** Generating Quantile Representations.

Why does algorithm 1 return quantile representations?Assume for an arbitrary \(_{i}\), we have \((_{i},0.5)=p_{i}\). Standard interpretation states - at quantile \(=0.5\), the probability of \(_{i}\) in class \(1\) is \(p_{i}\). However, thanks to duality in equation 5, this can also be interpreted as - At quantile \(=(1-p_{i})\), the probability of \(_{i}\) in class \(1\) is 0.5.

Thanks to monotonocity property in equation 3, we have for all \(<(1-p_{i})\), probability of \(_{i}\) in class \(1\) is \(<0.5\), and hence belongs to class \(0\). And for all \(>(1-p_{i})\), probability of \(_{i}\) in class \(1\) is \(>0.5\), and hence belongs to class \(1\).

This implies that at a given quantile \(^{*}\), \(_{i}\) will belong to class \(1\) if \(^{*}>(1-p_{i})\) or if \(p_{i}>(1-^{*})\) or if \(f_{}(_{i})>(1-^{*})\). Defining, \(y_{i,^{*}}^{+}=I[f_{}(_{i})>(1-^{*})]\), we have that the classifier at quantile \(^{*}\) fits the data \(_{}^{+}=\{(_{i},y_{i,^{*}}^{+})\}\) and thus can be used to identify \((,^{*})\). This gives us the algorithm 1 to get the quantile representations for an arbitrary classifier \(f_{}()\).

**Remark (Sigmoid vs Indicator function):** In theory, we approximate \(}=I[_{i}}>0]\) (i.e Indicator function) with the sigmoid as \(}=(_{i}})\). The algorithm 1 gives a solution up to this approximation. In particular we have the following theorem

**Theorem 3.1**: _Let the base classifier \(f_{}()=(f_{,}())\) be obtained using the MAE loss, i.e by minimizing_

\[_{}_{i}|y_{i}-f_{}(_{i})|\] (6)

_Then the solution \((,)\) obtained by algorithm 1 minimizes the cost in equation 2 over the dataset \(\), i.e_

\[(,)=*{arg\,min}_{}_{ U}[_{i=1}^{N}(I[(_{i},) 0.5],y_{i}; )]\] (7)

The proof for the above theorem is discussed in the supplementary material. In simple words, the proof follows from the duality and the fact that we are only interested in the labels (for this theorem) obtained by applying the indicator function.

Importance of duality:Algorithm 1 and theorem 3.1 hinges on the duality property. Recall that pinball loss equation 4 penalizes the positive errors and negative errors differently. In the case of binary classification, since \(f_{}()(0,1)\), positive errors occur for class \(1\) and negative errors occur for class \(0\). Hence, the quantile value implicitly controls the probability of class \(1\), giving the duality property.

Thus, using quantile value as an input allows us to control the probabilities and hence confidence of our predictions. This is what we have exploited to construct quantile representations without resorting to optimizing equation 2. This ensures that the properties of the pre-trained model are preserved while still being able to compute quantile representations.

**Remark:** The other alternate to computing quantile representations are the Bayesian approaches . It is known that computing the _full predictive distribution_ - \(p(y|,x)= p(y|w,x)p(w|)dw\) is computationally difficult. Quantile representations approximate the inverse of the c.d.f of the predictive distribution for the binary classification.

To summarize, thanks to the duality in equation 5, one can compute the quantile representations for any arbitrary classifier. This allows for detailed analysis of the classifier and the features learned. In the following section we first discuss the implementation of algorithm 1 in practice and provide both qualitative and quantitative analysis for specific models.

## 4 Experiments and Analysis

### Generating Quantile Representations in practice

Let \(f_{}()\) denote a pre-trained classifier. Given a dataset \(=\{(_{i},y_{i})\}_{i}\), we construct a _quantile dataset_ - \(\{(_{i},y_{i,}^{+})\}_{i,}\) as described in algorithm 1 with the following modifications:

* \(\{f_{,}(_{i})\}_{i}\). Moreover, as multi-class classification problem gives class imbalance under one-vs-rest paradigm, we compute _weighted-quantiles_, where weights are inversely proportional to the size of the class. Observe that since \(f_{,}()\) is a monotonic function of \(f_{}()\), this does not make a difference in practice. However, this allows us to circumvent precision issues caused due to the sigmoid function.
* We only consider a fixed finite number of quantiles. The \(n_{}\) quantiles are given by \(\{}{{n_{}}+1},}{{n_{}}+1},, }}{{n_{}}+1}\}\).

For the sake of valid experimentation, we model \((,)\) using the same network as \(f_{}()\), except for the first layer. We concatenate the value of \(\) to the input, resulting in slightly more number of parameters in the first layer. For efficient optimization we start the training with the weights of the pre-trained classifier \(f_{}()\), except for the first layer.

Loss function to train \(_{}(,)\):Recall that \(_{}(,)\) indicates the latent logits. We use BinaryCrossEntropy loss to train \(_{}(,)\) where the targets are given by the modified labels \(\{y_{i,}^{+}\}\).

Inference using \(_{}(,)\) :After training, we compute the probabilities as follows

\[p_{i}=_{=0}^{1}I[_{}(_{i},) 0]d }_{i}I[_{}(_{i},) 0]\] (8)

**Remark:** For multi-class classification, we follow a one-vs-rest approach. Hence the loss in this case would be sum of losses over all individual classes. The probability, in multi-class case, is taken to be \(_{k}p_{i,k}\). Note that the probabilities \(p_{i,k}\) do not add up to \(1\) over all classes.

**Remark:** Since the aim is to analyze the pre-trained model, we only consider one specific architecture - Resnet34, and two datasets - CIFAR10 and SVHN to illustrate our results. Other related experiments are included in the appendix (supplementary material).

Training Details and Compute:Training quantile representations was done on a DGX server using 4 GPUs. It takes around 10 hours (40 GPU hours in total) to learn the quantile representations for each model. We use stochastic gradient descent with cyclic learning rate for optimization. The base_lr is taken to be \(0.02\) and max_lr is taken to be \(1.0\), with exponentially decreasing learning rate using \(=0.99994\). The batch_size is taken to be \(1024\) for resnet34. The number of steps for the cyclic learning is taken to be \(2(size\_dataset/2(batch\_size)+1)\). The \(size\_dataset\) describes the size of the training data. Complete code has been provided with the supplementary material.

### Quantile Representations captures the distribution of the input data

Firstly, we analyze the learned quantile representations - \(_{}(.,.)\). Broadly, the learned function \(_{}(.,.)\) captures the 1 dimensional caricature of the input distribution, in the direction where the label changes. We illustrate this using a simple toy example (figure 2). Consider a 1-dimensional dataset in a 2d-space. The labels are assigned by splitting the dataset at the mean of the values on x-axis. We then learn a simple 1 hidden layer neural network with \(100\) hidden neurons. Using this as a base classifier, we then learn the quantile representation function \(_{}(.,.)\) as described above. Then, we reconstruct data in the original space as follows - Assign arbitrary labels at each \(\) satisfying the monotonicity property equation 3. For each set of labels, keeping the learned function \(_{}(.,.)\) fixed, learn the input which gives these labels. This is illustrated in figure 2. Observe that the shape of the learned inputs (1-d thread like structure) resembles the shape of the input dataset. This shows that the function \(_{}(.,.)\) captures how the sample distribution changes in the input space.

### Calibration of ML models

For several applications the confidence of the predictions is important. This is measured by considering how well the output probabilities from the model reflect it's predictive uncertainty. This is referred to as _Calibration_.

Several methods [28; 37; 19; 1; 22] are used to improve the calibration of the deep learning models. Most of these methods consider a part of the data (apart from train data) to adjust the probability predictions. However, in [26; 23] it has been shown that most of the calibration approaches fail under distortions. In this section we show that calibration using quantile-representations are invariant to distortions.

Let \(p_{i,k}\) denote the predicted probability that the sample \(_{i}\) belongs to class \(k\). A perfectly calibrated model (binary class) will satisfy \(P(_{i}=1|p_{i,1}=p^{*})=p^{*}\). For multi-class case this is adapted to \(P(_{i}=*{arg\,max}_{k}(p_{i,k})|_{k}(p_{i,k})=p^{*})=p^ {*}\). The degree of miscalibration is usually measured using _Expected Calibration Error (ECE)_

\[E[|p^{*}-E[P(=*{arg\,max}_{k}(p_{i,k})|_{k}(p_{i,k})=p^ {*})]|]\] (9)

This is computed by binning the predictions into \(m\) bins - \(B_{1},B_{2},,B_{m}\) and computing \(=_{i=1}^{m}(|}}{{n}})|(B_{i})- (B_{i})|\). where \((B_{i})=(1/|B_{i}|)_{j B_{i}}I[_{j}=*{ arg\,max}_{k}(p_{j,k})]\) denotes the accuracy of the predictions lying in \(B_{i}\), and \((B_{i})=_{j B_{i}}_{k}(p_{j,k})\) indicates the average confidence of the predictions lying in \(B_{i}\).

In the ideal scenario, we have that quantile representations predict perfectly calibrated probabilities as illustrated in the following theorem.

**Theorem 4.1**: _Let \(f_{}(.)\) denote the pre-trained model. Assume that the data is generated using the model \(=I[f_{}()+>0]\), where \(\) denotes the error distribution. Let \((,)\) denote the quantile representations obtained on this data. The probabilities obtained using equation 8 are perfectly calibrated, that is,_

\[_{=0}^{1}I[(,) 0]d=P(f_{}()+ >0)\] (10)

Figure 2: Quantile Representations captures the distribution of the input data distribution.

[MISSING_PAGE_FAIL:7]

score without compromising invariance to distortions? It turns out that usual methods fail when trying to correct the calibration error of quantile representations. (**Remark:** A similar result is also obtained in Proposition 1 of ).

To verify this we perform the same experiment as earlier. Further we use Platt Scaling on validation data and accordingly transform the probability estimates for the corrupted datasets. These results are shown in figure 4. Observe that at severity \(0\), the calibration error is \(0\) for the corrected probabilities as expected. However, as distortion increases, the calibration error increases as well.

Discussion:Consider the following - Given a specific calibration error \(C\) (say), let the set of all probability assignments which give the calibration error \(C\) be \(_{C}\). If the network \(f_{}()\) has to remain invariant to distortions, it should return one of these possible probability distributions \(_{C}\). Our explanation for the above result is that - The vanilla neural networks do not have this property. The quantile networks, as illustrated, are evidenced to have this property. However, this also implies that calibration error _cannot_ be corrected post-hoc in a sample independent manner.

### OOD Detection using Quantile Representations

An assumption made across all machine learning models is that - Train and test datasets share the same distributions. However, test data can contain samples which are out-of-distribution (OOD) whose labels have not been seen during the training process . Such samples should be ignored during inference. Hence OOD detection is a key component of reliable ML systems. Several methods  have been proposed for OOD detection. Here we check how quantile representations compare to the baseline method in  for OOD detection.

Quantile representations construct different classifiers at different distances from the base-classifier (illustrated in figure 0(b)). This allows us to differentiate between OOD samples and ID samples. Intuitively, OOD samples are far from the boundary and result in low softmax probabilities. Thus, one way to assign OOD scores to samples is by considering the maximum softmax probabilities MSP as described in . We compare the OOD detection of quantile representations with this approach.

Experimental SetupFor this study, we use the CIFAR10 and SVHN datasets as in-distribution (ID) datasets and the iSUN, LSUN, and TinyImagenet datasets as out-of-distribution (OOD) datasets. Two versions of LSUN and TinyImagenet are considered - resized to \(32 32\) and cropped. We evaluate the quantile representations obtained using ResNet34 architecture. For evaluation we use (i) AUROC: The area under the receiver operating characteristic curve of a threshold-based detector. A perfect detector corresponds to an AUROC score of 100%. (ii) TNR at 95% TPR: The probability that an OOD sample is correctly identified (classified as negative) when the true positive rate equals 95%. (iii) Detection accuracy: Measures the maximum possible classification accuracy over all possible thresholds.

Methodology and ResultsTo identify OOD samples with quantile representations, we consider the entire representation - \(_{}(_{i},)\) as input features. In our experiments this would be of the dimension \(n_{r} n_{\_}classes\). To assign an OOD-score we use the One-Class SVM approach. The first rows of Table 1 shows the results. Observe that quantile-representations perform marginally better than than the baseline.

The more interesting result, however, is the fact that _quantile representations have all the information required to identify OOD samples_. To establish this we perform the following experiment - We use a simple linear classifier (logistic regression) to identify if the ID and OOD datasets are linearly separable or not. We measure the training accuracy to quantify linear separability - If the accuracy is close to \(100\%\), then the datasets are considered to be linearly separable. For comparison we perform the same experiment with the pre-trained logits \(f_{,}()\). These results are shown in the bottom rows of Table 1. Note that while the baseline scores vary with the dataset, the quantile scores are consistently close to 100%. This provides additional evidence to the hypothesis that quantile representations capture all the "relevant" information about the train distribution.

## 5 Related Work

 provides a comprehensive overview of approaches related to quantile regression and identifying the parameters.  extends the quantiles to multi-variate case.  use quantile regression based approaches for estimating confidence of neural networks based predictions.  uses conformal methods to calibrate probabilities, and is closely related to computing quantiles.  proposes a similar algorithm to overcome the restriction to pinball loss for regression problems.  generates predictive regions using quantile regression techniques.

## 6 Conclusion, Limitations and Future work

To summarize, in this article we show the duality between quantiles and probabilities in the case of SBQR. Exploiting the duality, we propose an algorithm to compute quantile representations for any given base classifier. We verify that the quantile representations model the training distribution well both qualitatively (by reconstructing the data in the input space) and quantitatively (using OOD detection baseline). We further show that the probabilities from quantile representations are robust to distortions. Interestingly, we found that traditional approaches cannot be used to correct the calibration error. Further experiments to validate the observations made in this article are discussed in the supplementary material.

The main limitation of the approach is the computation required for algorithm 1 for large scale datasets. Note that algorithm 1 creates \(n_{}\) copies of the same dataset by assigning different labels. For large scale datasets and large scale networks this requires a lot more computation than using a pre-trained classifier. However, we hypothesize that - we only need to retrain the quantile network only on a small sample size instead of the entire dataset We consider this for future work.

Based on strong convexity and Lipschitzness of loss functions, automatic learning rates can be computed for large networks via the inverse of the Lipschitz constant of the loss function being an ideal learning rate . We conjecture that exploiting the loss functions which inherit some convexity and Lipschitz properties from the known, closed form loss representations would achieve higher learning rates for faster convergence to compute quantile representations. We defer this as future work.

    & & AUROC & TNR-TPR95 & Det.Acc \\ Approach & Model/ID & OOD & & & \\  OneClassSVM & Resnet34/SVHN & iSUN & 92.28/**96.13** & 77.43/**80.15** & 89.77/**90.65** \\  & & LSUN(R) & 91.50/**95.44** & 74.95/**77.05** & 89.09/**89.67** \\  & & LSUN(C) & 92.99/**95.76** & 77.96/**80.93** & **90.10**/90.03 \\  & & Imagenet(R) & 93.52/**96.21** & **79.86**/79.60 & 90.58/**90.84** \\  & & Imagenet(C) & 94.18/**95.98** & **81.13**/79.77 & **91.23**/90.57 \\   & ResNet34/CIFAR10 & iSUN & 90.29/**95.53** & 41.90/**61.24** & 84.28/**87.06** \\  & & LSUN(R) & 90.07/**93.41** & 41.24/**61.01** & 84.25/**86.77** \\  & & LSUN(C) & 91.74/**91.79** & 45.87/**51.96** & **86.37**/**85.77** \\  & & Imagenet(R) & 90.33/**92.33** & 42.18/**58.95** & 84.21/**85.47** \\  & & Imagenet(C) & 90.96/**91.44** & 43.95/**52.08** & **84.80**/84.58 \\  LinearSeparability & Resnet34/SVHN & iSUN & 83.00/**99.98** & 60.87/**99.90** & 78.98/**99.38** \\  & & LSUN(R) & 81.90/**99.98** & 56.34/**99.97** & 77.76/**99.47** \\  & & LSUN(C) & 80.44/**99.75** & 52.80/**99.25** & 75.35/**97.76** \\  & & Imagenet(R) & 80.31/**99.96** & 57.61/**99.85** & 77.19/**99.19** \\  & & Imagenet(C) & 81.88/**99.93** & 61.28/**99.78** & 78.75/**98.91** \\   & ResNet34/CIFAR10 & iSUN & 98.73/**99.94** & 96.06/**99.88** & 95.75/**98.92** \\  & & LSUN(R) & 98.80/**99.96** & 96.18/**99.84** & 95.94/**99.17** \\  & & LSUN(C) & 92.78/**99.55** & 70.72/**98.31** & 87.47/**96.87** \\  & & Imagenet(R) & 92.57/**99.74** & 86.76/**98.93** & 91.02/**97.72** \\  & & Imagenet(C) & 94.38/**99.67** & 82.37/**98.72** & 89.15/**97.25** \\   

Table 1: Comparison of Quantile-Representations with baseline for OOD Detection. Observe that Quantile-Representations outperform the baseline in all the cases. The entries are represented as Baseline/Quantile-Representations.