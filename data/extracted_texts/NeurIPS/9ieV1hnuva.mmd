# Hypervolume Maximization: A Geometric View of Pareto Set Learning

Xiaoyuan Zhang\({}^{a}\), Xi Lin\({}^{a}\), Bo Xue\({}^{a}\), Yifan Chen\({}^{b}\), Qingfu Zhang\({}^{a}\)

\({}^{a}\) Department of Computer Science, City University of Hong Kong;

City University of Hong Kong Shenzhen Research Institute.

\({}^{b}\) Departments of Mathematics and Computer Science, Hong Kong Baptist University.

Correspondence to: Yifan Chen \(<\)yifanc@hkbu.edu.hk\(>\), Qingfu Zhang \(<\)qingfu.zhang@cityu.edu.hk\(>\).

###### Abstract

This paper presents a novel approach to multiobjective algorithms aimed at modeling the Pareto set using neural networks. Whereas previous methods mainly focused on identifying a finite number of solutions, our approach allows for the direct modeling of the entire Pareto set. Furthermore, we establish an equivalence between learning the complete Pareto set and maximizing the associated hypervolume, which enables the convergence analysis of hypervolume (as a new metric) for Pareto set learning. Specifically, our new analysis framework reveals the connection between the learned Pareto solution and its representation in a polar coordinate system. We evaluate our proposed approach on various benchmark problems and real-world problems, and the encouraging results make it a potentially viable alternative to existing multiobjective algorithms. Code is available at https://github.com/xzhang2523/hvpsl/tree/master.

## 1 Introduction

Pareto solutions  effectively balance multiple objectives, making optimal tradeoffs among all objectives. For a Pareto solution, improving one objective without adversely affecting others is not possible. The Pareto set (PS) refers to the set of all Pareto solutions, while the Pareto front (PF) denotes the image of the PS in the objective space. Over the years, numerous methods have been developed to generate a single Pareto optimal solution , or a finite set of Pareto solutions .

Under mild conditions on continuous optimization problems with \(m\) objectives, the Pareto set becomes a (\(m\)-1)-D continuous manifold ; given that, the finite set learned from classical methods might not accurately approximate the continuous manifold. To overcome this issue, Pareto set learning (PSL) has been recently proposed in , with the hope of training a neural network model capable of approximating the _entire_ Pareto set. The significant advantage of learning the complete Pareto set is that a trained model can generate the optimal solution for any preference (conceptually the weight of different objectives, see the definition in Lemma 1) in real time, allowing for comprehensive decisions.

The training approach utilized in prior PSL techniques can be viewed as an extension of decomposition-based multiobjective optimization strategies  to an infinite preference scenario. However, several unresolved issues existed in prior PSL methods. Firstly, the interpretation of the sum of aggregation functions under different preferences lacks clarity, simply taking all preferences as equally important and thus leading to a partial Pareto front. Secondly, aside from the EPO-basedPSL proposed in , there has been limited investigation into the connection between a preference and its corresponding Pareto solution. Despite the effectiveness of the EPO-based PSL approach, its computational latency has been identified as a significant obstacle in its ability to handle large-scale problems. Thirdly, theoretical guarantees of PSL are lacking, and therefore the underlying mechanism of PSL remains unknown.

After identifying the challenges regarding existing PSL techniques for solving multiobjective optimization problems, we propose a new approach that addresses all these issues. Our method utilizes a geometric perspective on Pareto set learning, which takes the form of a hypervolume maximization problem. This approach brings several benefits. Firstly, it provides a clear interpretation of Pareto set learning as a hypervolume maximization problem, allowing us to build a theoretical bound between the PSL results and the hypervolume, one of the most important indicators in multiobjective optimization. Secondly, our approach establishes a clear correspondence between a specific preference and the resulting Pareto solution in a polar coordinate system. Lastly, the new perspective implies several important techniques in hypervolume-based PSL to learn an entire Pareto set.

The contributions of this work can be summarized as follows:

1. We provide a novel geometric perspective for Pareto set learning, which recognizes its equivalence to hypervolume maximization. As a result, the Pareto solutions derived from this method are aligned precisely with the polar angle under mild conditions, which is the input of the neural network in use.
2. We provide the first theoretical analysis for Pareto set learning, specifically examining the gap between the estimated hypervolume and the true hypervolume of the Pareto set. Our analysis enhances a better understanding of Pareto set learning.
3. We have developed techniques to learn a more complete Pareto front, surpassing previous methods that obtain a partial solution set. Our approach achieves promising results on various benchmark problems and real-world problems.

## 2 Related works

Multiobjective Optimization via Hypervolume Maximization.The hypervolume (hv) indicator measures the quality of multiobjective optimization solution sets and is consistent with Pareto dominance. Maximizing hypervolume is a basic principle in multiobjective optimization algorithm design, and several popular algorithms like SMS-EMOA , SIBEA [15; 16], and MO-CMA-ES  use it to generate a finite number of optimal solutions. A new method named _multiobjective learning using hv maximization_ was proposed in , which leverages hypervolume maximization while training neural networks to obtain a _finite_ set of Pareto solutions. This method differs from our approach as it does not rely on a model to approximate the Pareto set. Instead, it adopts the gradient search method from  for hypervolume maximization. A major drawback of this approach is its high computational complexity in obtaining the hypervolume gradient.

Pareto Set Learning and Conditional Models.Pareto set learning involves using a neural network conditioned on user preference to learn the entire Pareto set. This concept was first introduced in [12; 13] and has gained popularity in various areas like drug design , multitask image classification [21; 22], and multiobjective neural combinatorial optimization . In addition, some studies have used a similar conditional model to generate a set of diverse solutions, including the works addressing multiobjective reinforcement learning [24; 25; 26], and the works generating policies under different conditional levels [27; 28].

## 3 Background

A multiobjective optimization (MOO) problem with \(m\) objectives can be stated as follows:

\[_{x^{n}}f(x)=(f_{1}(x),f_{2}(x),...,f_{m} (x)),\] (1)

where \(x\) is the decision variable, \(\) is a compact decision space, and \(f(x):^{m}\) is the objective function. The objective domain \(=f\)1. Given two candidate solutions \(x^{(a)},x^{(b)}\), we say \(x^{(a)}\)**dominates**\(x^{(b)}\) if and only if \(\ i[m]\)2, \(f_{i}(x^{(a)}) f_{i}(x^{(b)})\), and \( j[m] i\) such that \(f_{j}(x^{(a)})<f_{j}(x^{(b)})\). \(x^{*}\) is a **Pareto solution** if no other solution \(x\) dominates \(x^{*}\);its image \(f(x^{*})\) is called a **Pareto objective**. The set of all Pareto solutions is called the **Pareto set** (PS). And the image of PS is called the **Pareto front**\(:=f\). In a separate note, a solution \(x^{}\) is called weakly Pareto optimal if there exists no solution \(x\) such that \(f_{i}(x) f_{i}(x^{})\)3. A Pareto solution is a weakly Pareto solution, but a weakly Pareto solution is not necessarily a Pareto solution.

The nadir/ideal point of a multiobjective problem is constructed by the worst/best objective values of the Pareto set. \(y^{}_{i}=_{y}\{y_{i}\}\), and similarly, \(y^{}_{i}=_{y}\{y_{i}\}\), \( i[m]\). The hypervolume indicator is defined as a metric of the optimality of a set of objective vectors \(A\), detailed as follows.

**Definition 1** (The hypervolume (HV) indicator ).: _The hypervolume indicator of a set \(A\) is defined as:_

\[_{r}(A):=(\{q p A:p qq r\}),\] (2)

_where \(()\) denotes the Lebesgue measure, and \(r\) is a reference vector. We require that \(r y^{}\)._

Figure 1 depicts the hypervolume indicator of the Pareto front, represented by the yellow region.

## 4 Pareto Set Learning via Hypervolume Maximization

As shown in Figure 2, Pareto set learning (PSL) aims to learn the whole Pareto set by a model, which differs from population-based MOEAs [5; 6]. One straightforward way is to learn a _Pareto neural model_\(x_{}():^{n}\) that translates a polar coordinate \(\) into a Pareto solution \(x^{n}\), where \(=[0,]^{m-1}\). After the training, for any \(\), the Pareto neural model \(x_{}()\) can directly generate an approximate Pareto solution in real-time (\(<\)1s).

In this paper, we present a novel geometry view to formulate PSL based on hypervolume maximization. Firstly, we notice the following equivalence holds:

**Proposition 1** (Equivalence between PSL and HV maximization).: _When \(r\) is a reference point dominating the whole Pareto front \(\), and \(A\) is a non-dominated solution set, we have \(=_{A}_{r}(A)\)._

Proposition 1 shows that \(_{r}(A)\) achieves the maximal value if the model \(x_{}()\) learns all Pareto solutions. So, it is natural to convert the Pareto set learning problem with a parameter \(\) as a hypervolume maximization problem:

\[_{}_{r}(f x_{}()).\] (3)

In Equation (3), the subscript \(r\) refers to a fixed reference point satisfying \(y r, y\). The objective function measures the quality of the Pareto neural model \(x_{}()\) and this objective achieves optimality only when the model learns all Pareto solutions.

### Pareto Front Hypervolume as an Expectation

Figure 1: Pareto solutions, weakly Pareto solutions, dominated solutions, and the HV.

Figure 2: PSL learns the whole Pareto set. For a coordinate \(\), model \(x_{}()\) learns a corresponding Pareto solution \(x_{}()\).

In this section, we are devoted to casting the optimal solution of Equation (3) (i.e., the hypervolume of the Pareto front) into a polar coordinate form. To accomplish this, we leverage an existing technique to transform the hypervolume calculation of a finite set of solutions into an expectation problem, which is formulated as the following lemma,

**Lemma 1** (Hypervolume scalarization of a finite set [30; 31; 32]).: _Let \(A=\{y^{(1)},y^{(2)},,y^{(N)}\}\) be set of finite objective vectors and \(r\) is a reference point, \(r y^{(i)}\). The hypervolume of set \(A\) with \(r\) can be expressed in terms of an expectation,_

\[_{r}(A)=c_{m}_{}[(_{y A}_{i [m]}\{-y_{i}}{_{i}()}\})^{m} ],\] (4)

_where we specify \(\) follows \(()\), the uniform distribution on \(\). \(()_{+}^{m-1}\) is the preference vector: it is the Cartesian coordinate of \(\) on the positive unit sphere \(_{+}^{m-1}\), with \(_{1}()=_{1}_{2}..._{m-1}\), \(_{2}()=_{1}_{2}..._{m-1}\), \(\), \(_{m}()=_{1}\). \(c_{m}=}{2^{m}(m/2+1)}\) is a constant that is only dependent on \(m\) and \(()\) is the Gamma function._

We notice that, it is not "economic" to estimate the hypervolume \(_{r}(A)\) in Lemma 1: numerous samples from \(()\) are needed, while the expensive Monte Carlo estimation only provides the hypervolume for a finite set \(A\). Even when \(A\) consists of only one point, the calculation of \(_{r}(A)\) still relies on the expectation over \(()\). However, extending the scope of the input set \(A\) in Lemma 1, we discover that the hypervolume of a (weakly) Pareto front containing an infinite number of objective vectors can as well be expressed as an expectation,

\[_{r}()=c_{m}_{}[_{} ()^{m}],\] (5)

with proof provided in Appendix B.2. The distance function denoted as \(_{}()\), as illustrated in Figure 3(a), represents the Euclidean distance between a reference point denoted as \(r\) and the Pareto front at the coordinate of \(\). The distance function \(_{}()\) can be precisely evaluated using the equation provided, with the proof available in Appendix B.4.

\[_{}()=_{x}(x,)=_{x }_{i[m]}\{-f_{i}(x)}{_{i}()} \}.\] (6)

where \((x,)=_{i[m]}\{-f_{i}(x)}{_{i}()}\}\) represents the projected distance of an objective vector \(f(x)\) at coordinate \(\), as illustrated in Figure 3(a). Let \(\) be the shorthand of \(()\), we have the following proposition of the optimal solution of Equation (6).

**Proposition 2**.: _Given an objective vector \(y\) that satisfies \(-y_{1}}{_{1}}==-y_{m}}{_{m}}\). 1: If \(y\) is weakly Pareto optimal, then \(y\) is one of the optimal solutions of \((y,)=_{y y}_{i[m]}\{-y_{i}}{ _{i}}\}\). 2: If \(y\) is Pareto optimal, then \(y\) is the only optimal solution of \((y,)\)._

Proof.: 1: If there exists a \(y^{}\) such that \((y^{},)<(y,)\), then \(y^{} y\), contradicting the weakly Pareto optimality of \(y\). 2: If there exists a \(y^{} y\) such that \((y^{},)=(y,)\), then \(y^{} y\), and there exists at least one index \(j\) where \(y^{}_{j}<y_{j}\). This contradicts the Pareto optimality of \(y\). 

**Remark 1** (On the "exact" Pareto solution).: _Proposition 2 establishes a connection between the polar coordinate \(\) and the resulting Pareto solution. Once the Pareto neural model is well-trained, and assuming the absence of weakly Pareto solutions and the existence of an exact solution , the

Figure 3: Pareto front hypervolume calculation in the polar coordinate. \(_{}()\) is the distance from the reference point to the Pareto front along angle \(\). \((x,)\) (used in Equation (6)) is the projected distance at angle \(\).

Pareto neural model can predict the "exact" Pareto solution aligned with the polar angle \(\). Since we only utilize an efficient aggregation function (Equation (6)), this property reveals that there is no need to solve the optimization problem (Eq. (24) in ) in order to achieve the "exact" Pareto solution._

We close the subsection with a note on the case of disjointed Pareto fronts. With a disjointed Pareto front \(\), the function \(_{}()\) can serve to measure the distance between the reference point \(r\) and the _attainment surface_. In this disjointed scenario, the expectation form of the Pareto front hypervolume by \(_{}()\), as specified by Equation (5), still holds (c.f. Appendix B.4).

### Alternative Forms of Hypervolume

In this section, we train the Pareto neural model \(x_{}()\) by maximizing the alternative forms of hypervolumes. The optimization of the value of \(_{r}(f x_{}())\) as defined in Equation (1) is challenging. However, by utilizing Equation (6), we can choose to instead optimize an easy-to-compute form of hypervolume, denoted by \(}_{r}()\). This surrogate hypervolume function \(}_{r}()\), called PSL-HV1, is defined as follows:

\[}_{r}()=c_{m}_{}[_{}( )],_{}()=(x_{}(), )^{m}&(x_{}(),) 0\\ (x_{}(),)&.\] (7)

Here, \((x_{}(),)_{}()\) is the projected distance at angle \(\) as defined by Equation (6). When the Pareto neural model is supposed to learn the whole Pareto set, \((x_{}(),)_{}(),\ \) and thus \(}_{r}()_{r}()\).

We also provide a second surrogate hypervolume function, denoted as PSL-HV2 (derivation in Appendix B.5). The Pareto hypervolume can be estimated as the volume difference between the regions dominating \(r\) and those that dominate the Pareto front. PSL-HV2 maximizes the following objective,

\[}_{r}()=_{i=1}^{m}(r_{i}-y_{i}^{}) -c_{m}_{}[_{}()].\] (8)

where \(_{}()=_{}(x_{}( ),)^{m}\) and \(_{}()\) is an alternative projected distance function \(_{}(x_{}(),)=_{i[m]}(x_{}())-y_{i}^{}}{_{i}()}\). Although the Pareto neural model \(x_{}()\) theoretically has the ability to represent the complete Pareto set  with both surrogate hypervolume functions, our empirical results show that the quality of the learned solutions is sensitive to the specific choice: Equation (7) and Equation (8) give different performances on various tasks.

Algorithm.The goal of HV-based PSL is to maximize the objective function, \(_{}}_{r}()\). Both Equation (7) and Equation (8) can be effectively optimized using gradient descent approaches. The empirical gradient \(_{}}_{r}()\) can be obtained efficiently through backpropagation, as illustrated in Figure 4. Their analytical forms are provided in Appendix B.5. For practical algorithms, the _empirical_ gradient is estimated from a batch of \(N\) angles \(^{(1)},,^{(N)}\) through sampling from \(()\). Then the neural network is updated by \(+_{}}_{r}()\), where \(\) is a learning rate.

Figure 4: The gradient graph above is used for computing the estimated gradient of the hypervolume.

### Discussion on Different PSL Approaches

PSL-HV1 and PSL-HV2 have different designs for their projected distance function \((x,)\), with PSL-HV2 exhibiting significant growth as \(\) approaches boundary preferences such as  or  (taking the \(m=2\) case as an example). This property brings both pros and cons compared to PSL-HV1. The steep gradient may present numerical difficulties, but it also permits PSL to adopt larger weights and learn boundary solutions more effectively. We have observed that this feature of PSL-HV2 is particularly useful for learning the complete Pareto set, as opposed to previous PSL methods that only learned a partial Pareto front.

To avoid only learning a partial Pareto set, we propose a simple strategy for PSL-HV1 that involves using a larger reference point than the nadir point. This approach, which is common in hypervolume-based optimization methods [35; 36], gives larger weights to boundary preferences and allows for a more complete Pareto set.

Before our study, two primary approaches for PSL optimization were followed [12; 37]: optimizing the expectation using EPO/LS and optimizing using Tchebycheff functions. However, EPO-based PSL is slow for complex multiobjective problems and solely learns a partial Pareto set, and LS-based PSL only finds the convex portion of a Pareto front. Our work extends the approach in  by introducing a hypervolume interpretation for PSL. We establish a clear relationship between preferences and solutions and develop a theoretical analysis framework for PSL. Additionally, we propose methods to recover a more complete Pareto set, thus improving upon the existing approaches.

## 5 Statistical Guarantees on Hypervolume Convergence

This section first establishes the bounds for the generalization error of the Pareto front when using the exact distance function \(_{}()\) in Section 5.1. Subsequently, we discuss the generalization bound of proposed HV-based Pareto set learning in Section 5.2.

### Convergence of the Pareto Front Hypervolume

**Proposition 3**.: _(1): \((x,)\) is concave when \(f_{i}\)'s are convex. 2\((x,)\) is quasi-concave when \(f_{i}\)'s are quasi-convex. 3\(_{}()\) defined in Equation (7) is quasi-concave w.r.t \(x_{}()\) when the objective function \(f(x)\) is quasi-convex._

Proof.: The statements 1 and 2 are consequences of the preservation of convexity/quasi-convexity by taking the point-wise maximum of convex/quasi-convex functions. The statement 3 is justified by the fact that a non-decreasing composition of a quasi-concave function preserves quasi-concavity. Additionally, it can be observed that the function \(f(x)=x^{m}\) for \(x 0\) (and \(f(x)=x\) otherwise) is a non-decreasing function. 

**Remark 2**.: _To better understand Proposition 3, we analyze a modified bi-objective VLMOP2 problem from . In this example, let \(f_{1}(x)=1.2(1-(-{(x+1)}^{2}))\) and \(f_{2}(x)=1-(-{(x-1)}^{2})\). Figure 5 illustrates the limitation of the linear scalarization (LS) approach . It shows that the LS-based PSL may yield multiple local optimas when using a non-negative linear combination of quasi-convex functions \(f_{1}\) and \(f_{2}\), resulting local optimal Pareto models. However, it is worth noting that the function \(-(x,)\) considered remains quasi-convex ._

Assuming that \(b r_{i}-y_{i} B\), \( i[m],y\). Let \(()=c_{m}_{}()^{m}\), then \(_{}() c_{m}B^{m}m^{m/2}\). Let \(}_{r}():=_{i=1}^{N}( ^{(i)})\) denote the empirical estimation of \(_{r}()\) with \(N\)

Figure 5: The point-wise maximum of quasi-convex functions preserves quasi-convexity. A positive-weighted linear combination of quasi-convex functions can result in a non-quasi-convex function.

samples. Via Hoeffding inequality, similar to , we have the following inequality,

\[(|}_{r}()-_{r}()| ) 2(}{c_{m}^{2}B^{2m}m^{m}}).\]

### PSL Generalization Bound

In this section we show that the proposed hypervolume metric can fit into the regular neural network studies and similarly enjoy the statistical guarantees on error \(|}_{r}()-_{r}()|\) for PSL-HV1. Specifically, the term can be interrupted as the difference between the metric of \(x_{}\) computed and the metric of ground truth \(x^{*}\), indicating the quality of the MLP map \(x_{}\). We will shortly show the error above will converge with regular SGD optimizers and large enough sample size \(N\), as expected.

We can first decompose the aforementioned error as follows,

\[}_{r}()- _{r}()& }_{r}()-}}_{r}( )}_{_{1}}+}}_{r}()-}}_{r}(^{*} )}_{_{2}}+\\ &}}_{r}(^{* })-}_{r}(^{*})}_{_{3}}+}_{r}(^{*})-_{r}() }_{_{4}},\] (9)

in which we define \(}}_{r}()=}{N}_{i=1}^{N}[ (x_{}(^{(i)}),^{(i)})^{m}]\) as the empirical hypervolume estimation associated with parameter \(\). \(^{*}\) is a set of reference parameters for the MLP map \(x_{}\). Those errors respectively correspond to generalization error (\(_{1}\)), optimization error (\(_{2}\)), generalization error (\(_{3}\)), and approximation error (\(_{4}\)). We can conceptually set the reference parameter \(^{*}\) as a good local maxima (in the local region of \(\)) for hypervolume maximization so that the approximation error \(_{4}\) is small due to the universal approximation character of the MLP model family . In our analysis, we assume that regular SGD technique brings \(\) close enough to the local maxima \(^{*}\), resulting in a small optimization error \(_{2}\).

The rest steps to show convergence is to control the generalization error \(_{1}\) and \(_{3}\). We present the following theorem to give the uniform convergence rate of the generalization error, which applies to both \(_{1}\) and \(_{3}\).

**Theorem 1** (Generalization error).: _Let the object functions \(f_{i}\)'s all be \(L_{f}\)-Lipschitz, and let \(x_{}\) be an \(L\)-layer MLP \(_{L}(W_{L}_{L-1}(_{1}(W_{1} )))\), with \(1\)-Lipschitz positive homogeneous activation \(_{i}\)'s and \(\|W_{i}\|_{} B_{w}, i[L]\) (under this setting \(\) is the set of \(W_{i}\)'s). The design matrix \(X_{}\) denotes the \(N\) collected samples \(_{i}\)'s. We further set the reference point \(r\) so that \(r_{i}-f_{i}(x)[b,B], i,\) for \(x f x_{^{*}}() f x_{}( )^{n}\). With probability at least \(1-\) (\(<\)), for \(=^{*}\) or \(\), we have_

\[}_{r}()-}}_{r} () c_{m}B^{m}m^{}(mn}{Nb}L_{f}B _{w}^{L}\|X_{}\|_{}(1+)+3}).\]

**Remark 3**.: _The results above imply the generalization errors \(_{1}\) and \(_{3}\) can converge at the rate of \(1/\), considering for each row in \(X_{}\) its \(L^{2}\)-norm is bounded from above by \(/4}\)._

_Obtaining the results require adaptations of classical Rademacher complexity techniques. The difficulty comes from the minimum form of \((x,)=_{i[m]}\{-f_{i}(x)}{_{i}( )}\}\), which differs from usual loss functions. We provide the detailed derivation in Appendix B.6. We further remark the scale assumption on \(r_{i}-f_{i}(x)\) is mild. \(f x_{^{*}}()\) and \(f x_{}()\) are supposed to approach \(\), the Pareto Front, under proper optimization procedures; we are thus able to select a reference point \(r\) far away enough from the set \( f x_{^{*}}() f x_{}()\) to make the assumption hold._

## 6 Experiments

Testing problems.This section demonstrates that our method can generate high-quality continuous Pareto solutions by the Pareto neural model for multiobjective synthetic, design, and control 

[MISSING_PAGE_FAIL:8]

coverage; (2) the Range indicator, which measures the extent of the Pareto front learned by the model, where a larger Range is preferred; and (3) the Sparsity metric, which evaluates the degree of sparsity in the learned Pareto front, where a lower sparsity value indicates a denser Pareto front. See Appendix A.1 for formal metric definitions.

Key findings from experiments are summarized as follows.

1 (**Comparison with SMS-EMOA.**) PSL and HV-based evolutionary algorithms serve as different purposes. PSL is designed to find an _infinite_ set of solutions using a neural network model, while EMOAs aim to find a _finite_ solution set. This difference becomes evident in three-objective problems, as shown in Figure 8, where 100 evenly distributed solutions by traditional MOEAs fall short of approximating the full Pareto set/front. PSL requires only several seconds of training time and can quickly predict highly approximated Pareto solutions for other unknown preferences. In contrast, SMS-EMOA typically takes a much longer time, especially for objectives larger than three. The advantage of evolution-based SMS-EMOA is its ability to find global optimal solutions, while current PSL models still struggle with handling local optimas.

Table 2 reports the mean results for various PSL approaches under five random seeds. The standard deviation values can be found in Appendix A.4. All experiments were conducted with 1000 iterations for PSL-HV1, PSL-HV2, LS-based PSL, and Tchebycheff-based PSL, while EPO-based PSL is limited to 100 iterations due to time limitation.

2 (**Comparison with LS-based PSL.**) It is well-recognized that LS-based PSL  recovers only the convex part of a Pareto front , resulting in finding a small portion of Pareto solutions for concave problems. For example, in the case of ZDT2, LS-based PSL could only find two extreme points. We would like to mention another less-discussed limitation of linear scalarization: the non-uniform distribution of Pareto objectives under uniformly distributed preferences. This issue is evident in problems like ZDT1 and VLMOP2 where Pareto objectives are densely distributed at the front's margins, but fewer objectives are distributed around the center of the front.

3 (**Comparison with EPO-based PSL.**) As mentioned in Remark 1, both EPO and our proposed method (under mild conditions) can find the exact Pareto objective aligned with the preference vector. However, our proposed approach is approximately 40+ times faster than EPO-based PSL. Unlike the EPO-based PSL method, our approach only requires calculating the gradient of one objective function, avoiding the need to compute gradients for all objectives and solve complex optimization problems as described in their work . This efficiency advantage is particularly evident in

   & &  &  &  \\  Method & HV\(\) & Range\(\) & Sparsity\(\) & Time(s)\(\) & HV & Range & Sparsity & Time(s) & HV & Range & Sparsity & Time(s) \\  PSL-EPO & 10.82 & 0.94 & 0.14 & 90.7 & 11.21 & 1.43 & 0.86 & 91.1 & 11.55 & 1.18 & 0.11 & 90.79 \\ PSL-LS & **11.89** & **1.56** & 1.07 & 9.17 & 8.75 & 0.0 & 0.0 & 9.03 & 12.05 & 1.56 & 0.5 & 9.15 \\ PSL-Tche & 11.49 & 1.37 & 0.33 & 21.11 & 11.19 & 1.42 & 0.66 & 21.65 & 11.83 & 1.42 & 0.22 & 21.61 \\ PSL-HV1 & 11.79 & 1.52 & 0.72 & 31.79 & 11.3 & 1.46 & 0.73 & 36.68 & **12.07** & **1.57** & 0.84 & 32.24 \\ PSL-HV2 & 11.77 & 1.52 & 0.7 & 25.71 & **11.51** & **1.55** & 1.0 & 25.8 & 12.02 & 1.54 & 0.46 & 25.45 \\   &  &  &  \\  PSL-EPO & 11.37 & 1.49 & 0.63 & 90.95 & 11.2 & 1.18 & 0.21 & 255.44 & 11.96 & 1.16 & 0.07 & 649.12 \\ PSL-LS & 11.51 & **1.57** & 0.72 & 9.57 & 11.89 & **1.56** & 0.94 & 44.75 & 12.14 & 1.5 & 0.27 & 113.52 \\ PSL-Tche & 11.47 & 1.52 & 0.63 & 22.14 & 11.5 & 1.37 & 0.31 & 55.37 & 12.06 & 1.37 & 0.08 & 125.43 \\ PSL-HV1 & **11.57** & **1.57** & 0.98 & 32.52 & **11.9** & **1.56** & 0.81 & 66.6 & **12.18** & **1.53** & 0.7 & 131.36 \\ PSL-HV2 & 11.56 & 1.56 & 0.66 & 25.78 & 11.82 & 1.53 & 0.65 & 60.03 & 12.15 & 1.51 & 0.37 & 130.4 \\   &  &  &  \\  PSL-EPO & 3.42 & 0.3 & 0.23 & 546.81 & 37.23 & 0.68 & 0.81 & 133.03 & 2.41 & 0.31 & 2.33 & 1149.4 \\ PSL-LS & 3.59 & 0.5 & 0.84 & 296.95 & 35.55 & 0.19 & 0.88 & 21.35 & 2.58 & 0.37 & 1.9 & 408.59 \\ PSL-Tche & 3.52 & 0.39 & 0.44 & 314.75 & 37.73 & 0.19 & 1.34 & 34.01 & 2.54 & 0.38 & 2.19 & 424.15 \\ PSL-HV1 & **3.61** & **0.73** & 3.62 & 310.01 & 40.84 & **0.7** & 3.31 & 39.09 & **2.62** & **0.89** & 14.7 & 430.72 \\ PSL-HV2 & **3.61** & 0.59 & 2.19 & 312.95 & **40.94** & **0.7** & 5.54 & 36.63 & 2.6 & 0.55 & 8.93 & 424.51 \\  

Table 2: PSL results on all problems. For PSL-HV1, \(r=0.6+y^{}\). For Tche-based PSL, the reference point \(z=1.1 y^{}\), as claimed in their original paper.

MO-LQR problems, where EPO-based PSL takes significantly more time to execute. Furthermore, we have observed that EPO-based PSL does not perform well on tasks ZDT1 and Rocket Injector Design.

4 (**Balancing range and sparsity of a PF.**) When simply running PSL, we observed a tendency for the Pareto objectives to concentrate on the central portion of the Pareto front, neglecting solutions that correspond to boundary preferences, such as \(f=/\) for bi-objective problems. To address this observation, a simple technique is to assign higher weights to the boundary objectives. For PSL-HV1, a larger reference point \(r\) is suggested to be used in comparison to the nadir point, and therefore more coordinates will correspond to boundary Pareto objectives (refer to Remark 4 in Appendix B.4). However, setting the reference point to be excessively large can result in a sparse learned Pareto front; we empirically set this offset to be 0.6 (the empirical study is in Figure 10 and 11). In PSL-HV2, the preference \(\) is placed in the denominator, resulting in greater weighting for the boundary Pareto objectives when the preference value approaches zero.

PSL-HV2 is related to the modified Tchebycheff (mTche) scalarization function , but the latter has different sampling techniques and lacks a hypervolume interpretation. When \(\) approaches  or , both mTche and PSL-HV2 faces numerical challenges resulting in a large gradient, which can be effectively addressed the gradient clipping technique  with a clipping norm of a certain value (e.g., 4.0 is used). Figure 9 shows that the learning process is unstable without gradient clipping but is stabilized when gradient clipping is applied. In contrast, PSL-HV1 involves minimization rather than maximization in its inner optimization problem and does not suffer from gradient explosion.

## 7 Conclusion, Limitation, and Future Work

This paper presented a method to learn the set of all Pareto solutions through hypervolume maximization. The method was motivated by a previous lemma, which allows for hypervolume estimation of infinite solutions. We further gave a precise geometric perspective on Pareto set learning; we studied the generalization gap between estimated and true hypervolumes, and discussed the key techniques to train a Pareto neural model that outperformed previous methods. The proposed method will also be incorporated into the Moon library .

Limitation and future works.The acknowledged constraint of our work is the reliance on gradient-based methods, which can result in locally optimal solutions when the objectives \(f_{i}\)'s are non-convex. To overcome this issue and provide more solid statistical guarantee, one feasible direction is to explore classical nonparametric techniques that can improve the robustness of the method. Another way is to use some evolutionary methods such as  to skip local optimal solutions. Additionally, we plan to apply the more robust Pareto neural models to large-scale multi-objective problems, such as molecular design and deep reinforcement learning.