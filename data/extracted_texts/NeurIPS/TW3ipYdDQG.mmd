# Fair Streaming Principal Component Analysis:

Statistical and Algorithmic Viewpoint

 Junghyun Lee1  Hanseul Cho1  Se-Young Yun  Chulhee Yun

Kim Jachul Graduate School of AI, KAIST

{jh_lee00, jhs4015, yunseyoung, chulhee.yun}@kaist.ac.kr

Equal contributions

###### Abstract

Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called _probably approximately fair and optimal_ (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called _fair streaming PCA_ along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its _statistical_ guarantee in terms of PAFO-learnability, which is the first of its kind in fair PCA literature. Lastly, we verify the efficacy and memory efficiency of our algorithm on real-world datasets.

## 1 Introduction

Algorithmic fairness ensures that machine learning algorithms do not propagate nor exacerbate bias, which may lead to discriminatory decision-making (Barocas and Selbst, 2016) and thus has been a very active area of research. This has direct implications in our everyday life, including but not limited to criminal justice (Kirchner et al., 2016), education (Kizilec and Lee, 2021), and more. See Mehrabi et al. (2021) for a comprehensive survey of bias and fairness in machine learning.

Often, one needs to consider fairness for a large number of high-dimensional data points. One of the standard tools for dealing with such high-dimensional data is PCA (Hotelling, 1933; Pearson, 1901), a classical yet still one of the most popular algorithms for performing interpretable dimensionality reduction. It has been adapted as a baseline and/or standard tool in exploratory data analysis, whose application ranges from natural sciences, engineering (Abdi and Williams, 2010; Jolliffe and Cadima, 2016), and even explainable AI (Li et al., 2023; Tjoa and Guan, 2021). Due to its ubiquity and wide applicability, several works study defining fairness in PCA and developing a fair variant of it. A recent line of research (Kleindessner et al., 2023; Lee et al., 2022; Olfat and Aswani, 2019) defines PCA fairness in the context of fair representation (Zemel et al., 2013) in that the projected group conditional distributions should match.

However, existing fair PCA approaches suffer from two problems. Theoretically, they provide no statistical foundation of fair PCA or guarantees for their algorithms. By statistical foundation, we mean the usual PAC-learnability (Shalev-Schwartz and Ben-David, 2014) guarantees, e.g., sample complexity for ensuring optimality in explained variance and fairness constraint with high probability.

On top of that, the second problem arises from a practical viewpoint: memory limitation. All the aforementioned fair PCA algorithms assume that the learner can store the entire data points and incurs memory complexity of order at least \((d(N,d))\), where \(d\) is the dimensionality of the data and \(N\) is the number of data points. As memory limitation is often a critical bottleneck in deploying machine learning algorithms (Mitliagkas et al., 2013), as much as fairness is important, it is also paramount that imposing fairness to PCA does not incur too much memory overhead. A popular approach to mitigate such memory limitation for PCA is to consider the one-pass, streaming setting. In this setting, each data point is revealed to the learner sequentially, each point is irretrievably gone unless she explicitly stores it, and she can use only \((dk)\) memory, with \(k\) being the target dimension of projection. Indeed, without the fairness constraint, streaming PCA has been studied extensively; see Balzano et al. (2018) and references therein.

In this work, we address both problems in a principled manner. Our contributions are as follows:

* We provide an alternative formulation of fair PCA based on the "Null It Out" approach (Section 3). Based on the new formulation, we introduce the concept of _probably approximately fair and optimal_ (PAFO)-learnability to formalize the problem of fair PCA (Section 4).
* To address the memory limitation, we propose a new problem setting called _fair streaming PCA_, as well as _fair noisy power method_ (FNPM), a simple yet memory-efficient algorithm based on the noisy power method. (Section 5). We note that our algorithm incurs a much lower memory complexity even compared to the most efficient variant of fair PCA proposed by Kleindessner et al. (2023).
* We then prove that our algorithm achieves the PAFO-learnability for fair streaming PCA (Section 6). Such statistical guarantee is the first of its kind in fair PCA literature.
* Lastly, we empirically validate our algorithm on CelebA and UCI datasets. Notably, we run FNPM on the original _full-resolution_ CelebA dataset on which existing fair PCA algorithms fail due to high memory requirements. It shows turning such a non-streaming setting into a streaming setting and applying our algorithm allows one to bypass the memory limitation (Section 7).

## 2 Preliminaries

Notation.For \( 1\), let \(_{}\) be the identity matrix of size \(\). For \(k<d\), we bring the _Stiefel manifold_\((d,k)=\{^{d k}:^{}= _{k}\}\), which is the collection of all rank-\(k\) semi-orthogonal matrices. We denote an orthonormal column basis of a (full column rank) matrix \(^{d k}\) obtained by QR decomposition as \(()(d,k)\) and denote its column space by \(()\). Also, for \((d,k)\), we denote the orthogonal projection matrix to \(()^{}=(^{})\) as \(_{}^{}=_{d}-^{}=_{d}-_{}\). Moreover, we denote the collection of all possible \(d\)-dimensional probability distributions as \(_{d}\). For a zero-mean random matrix \(\), its (scalar-valued) variance is defined as \(()=(\|[^{ }]\|_{2},\|[^{}] \|_{2}).\) In general, \(()=(-[])\). Lastly, we use the usual \(\), \(\), and \(\) notations for asymptotic analyses, where tildes (\(}\), \(\), and \(\), resp.) are used for hiding logarithmic factors.

Setup.Assume that the sensitive attribute variable, which we will be imposing fairness, is binary, denoted by \(a\{0,1\}\). For each group \(a\), let \(_{a}\) be a \(d\)-dimensional distribution of mean \(_{a}\) and covariance \(_{a}\), both of which are assumed to be well-defined. We often call them group-conditional mean and covariance, respectively. With a fixed, _unknown_ mixture parameter \(p(0,1)\), let us denote the total data distribution as \(:=p_{0}+(1-p)_{1}\). Equivalently, the sensitive attribute follows \(a(p)\), and the conditional random variable \(|a\) is sampled from \(_{a}\). In that case, \(_{a}=[|a]\) and \(_{a}=[^{}|a]-_{a}_{a }^{}\). We often write \(p_{0}=1-p\) and \(p_{1}=p\) for brevity. We also define the mean difference \(:=_{1}-_{0}\) and the second moment difference \(:=[^{}|a]=1]-[^{ }|a=0]=_{1}-_{0}+_{1}_{1}^{ }-_{0}_{0}^{}\). Accordingly, denote the true mean and covariance of \(\) as \(\) and \(\), respectively. For simplicity, let us assume that \(\) is centered, i.e., \(=\); note that this does _not_ mean that the group conditional distributions \(_{a}\)'s are centered.

Pca.In the _offline_ setting, the full covariance matrix \(\) is given which is often a sample covariance matrix \(_{i=1}^{n}_{i}_{i}^{}\) for \(n\) data points \(_{1},,_{n}\). The goal of vanilla (offline) PCA (Hotelling, 1933; Pearson, 1901) is to compute the loading matrix \(^{d k}\) that preserves as much variance as possible after projecting \(\) via \(\), _i.e._, maximize \((_{})=(^{})\). Here, \(k<d\) is the target dimension to which the data's dimensionality \(d\) is to be reduced and is chosen by the learner. We additionally consider the constraint \((d,k)\) to ensure that the resulting coordinate after the transformation is orthogonal and thus amenable to various statistical interpretations (Johnson and Wichern, 2008). Without any fairness constraint, Eckart-Young theorem (Eckart and Young, 1936) implies that the solution is characterized as a matrix whose columns are the top-\(k\) eigenvectors of \(\).

Fair PCA.Recently, it has been suggested that performing vanilla PCA on real-world datasets may exhibit bias, making the final outputted projection "unfair". As is often the case, there can be multiple definitions of fairness in PCA, but the following two are the most popular: equalizing reconstruction losses (Kamani et al., 2022; Samadi et al., 2018; Tantipongpipat et al., 2019; Vu et al., 2022), or equalizing the projected distributions (Kleindessner et al., 2023; Lee et al., 2022; Olfat and Aswani, 2019) from the perspective of fair representation (Zemel et al., 2013); we focus on the latter one.

## 3 An Alternative Approach to Fair PCA

### "Null It Out" Formulation of Fair PCA

In this work, we consider fair PCA as learning fair representation (Zemel et al., 2013). The goal is to preserve as much variance as possible while obfuscating any information regarding the sensitive attribute. To this end, we take the "Null It Out" approach as proposed in Ravfogel et al. (2020). Intuitively, we want to nullify the directions in which the sensitive attribute \(a\) can be inferred, and in this work, we consider two such **unfair directions**: mean difference \(\) and _eigenvectors_ of second moment difference \(\). To give the learner flexibility in choosing the trade-off between fairness and performance (measured in explained variance), let \(m 1\) be the number of top eigenvectors of \(\) to nullify. Thus, the learner is nullifying at most \((m+1)\)-dimensional subspace that is unfair with respect to \(a\), which we refer to as the **unfair subspace**. Precisely, we formulate our fair PCA as follows:

\[_{(d,k)}(^{}),()([_{m}|])^{},\] (1)

where \(d\) is the data dimensionality, \(k\) is the target dimension, and the columns of \(_{m}(d,m)\) is top-\(m\) orthonormal eigenvectors of \(\).

### An Explicit Characterization for Solution of Fair PCA

To first construct the unfair subspace that is spanned by \(\) as well as \(_{m}\), let us define \((d,m^{})\) to be the orthogonal matrix whose columns form a basis of \(([_{m}|])\). Then, \(\) has a closed form as follows: \(m^{}=m\) if \((_{m})\) and \(m^{}=m+1\) otherwise, and

\[=_{m},&(_{m}) \\ ([_{m}|])=[_{m}|\\ \|\|_{2}.],&\] (2)

where \(=_{_{m}}^{}(_{m})^{}\). Note that \(\) is a vector in a direction that \(\) is projected onto \((_{m})^{}=(_{m}^{})\). For this \(\), our constraint in (1) can be interpreted as an equivalent nullity constraint \(_{}=\):

\[_{(d,k)}(^{}),_{}=.\] (3)

The above is equivalent to the following problem without any constraint other than semi-orthgonality:

\[_{(d,k)}(^{}_ {}^{}_{}^{}),\] (4)

which is basically the vanilla \(k\)-PCA problem of a matrix \(_{}^{}_{}^{}\). Therefore, a top-\(k\) orthonormal column basis of this matrix is indeed a solution of our problem (4).

### Comparison to the Existing Covariance Matching Constraint

Previous works on fair PCA (Kleindessner et al., 2023; Olfat and Aswani, 2019) consider an exact covariance-matching constraint (namely, \(^{}(_{1}-_{0})=\)). In fact, this is equivalent to the condition \(^{}=\) under the mean-matching constraint \(^{}=\), which can be derived as \[^{}(_{1}-_{0}) =^{}([^{}|a=1]- [^{}|a=0])-^{}( _{1}_{1}^{}-_{0}_{0}^{} )\] \[=^{}-^{}( _{1}^{}+_{0}^{})=^ {}=.\]

One immediate problem with this is that the constraint may be infeasible depending on the choice of \(_{0}\), \(_{1}\), or \(\); e.g., when \(_{1}-_{0}\) is positive definite. For this reason, Kleindessner et al. (2023); Olfat and Aswani (2019) propose relaxations of the fairness constraints but provide no further discussions on its impact on statistical guarantees. On the contrary, our formulation is always feasible without any need for relaxation, allowing us to consider a rigorous definition of fair PCA (Definition 2) for the first time in fair PCA literature.

## 4 Statistical Viewpoint: PAFO-Learnability of PCA

As all the distribution statistics (\(,p,\)) are unknown, the learner, given some finite number of samples, must learn all of them _and_ solve fair PCA. In supervised learning, such a problem is often formalized in a PAC-learnability framework (Shalev-Schwartz and Ben-David, 2014). In the context of PAC-learnability for unsupervised learning settings, TV-learning, which is the task of learning distribution, has been mainly considered so far (Ananthakrishnan et al., 2021; Hopkins et al., 2023). However, unlike TV-learning, it is unnecessary to learn the whole distribution in fair PCA; moreover, fair PCA has the fairness constraint \(_{}=\) to be satisfied. Inspired by the unsupervised PAC-learnability as well as constrained PAC-learnability (Chamon and Ribeiro, 2020), we propose a new notion of learnability for fair PCA, called _PAFO (Probably Approximately Fair and Optimal) learnability_, as follows:

**Definition 1** (Projection Learner).: \(A\) **projection learner** _is a function that takes \(k 1\) and \(d\)-dimensional samples as input and outputs a loading matrix \((d,k)\)._

**Definition 2** (PAFO-Learnability of PCA).: _Let \(d,k,m\) be integers such that \(1 k<d\) and \(m<d\). We say that \(_{d}_{d}_{d}(0,1)\) is_ **PAFO-learnable for PCA** _if there exists a function \(N_{_{d}}:(0,1)^{3}\) and a projection learner \(\) satisfying the following:_

_For every \(_{},_{}\), \((0,1)\) and \((_{0},_{1},p)_{d}\), when running \(\) on \(N N_{_{d}}(_{},_{},)\) i.i.d. samples from \(:=p_{1}+(1-p)_{0}\) of the form \((a,)\), \(\) returns \(\) s.t., with probability at least \(1-\) (over the draws of the \(N\) samples),_

\[(^{}) (_{}^{}_{} )-_{},\|_{}\|_{2} _{},\] (5)

_where \(\) is as defined in Eqn. (2) and \(_{}\) is any solution to Eqn. (4) (with prescribed \(k\) and \(m\))._

Like in the usual PAC-learnability, \(N_{_{d}}\) is referred to as the _sample complexity_ of fair PCA. Observe how the optimality is measured w.r.t. the optimal solution of _fair_ PCA, not the vanilla PCA. Also, the two conditions are not overlapping: vanilla PCA (overly) satisfies \(_{}\)-optimality in explained variance but does not satisfy \(_{}\)-optimality in fairness, and vice versa for a poorly chosen \( St(d,k)\) with \(()([_{m}|])^{}\).

## 5 Algorithmic Viewpoint: Fair Streaming PCA

We now introduce a new problem setting, _fair streaming PCA_. In this setting, the learner receives a stream of pairs \((a_{t},_{t})\{0,1\}^{d}\) sequentially. Note that the sensitive attribute information \(a_{t}\) is also available at each time-step; this is commonly assumed when considering fairness in streaming setting (Bera et al., 2022; El Halabi et al., 2020). Precisely, we assume the following model of the data generation process: at each time-step \(t\), a sensitive attribute is chosen as \(a_{t}(p)\), then the data is sampled from the corresponding sensitive group's conditional distribution \(_{t} a_{t}_{s_{t}}\). Importantly, as done in previous streaming PCA literature (Mitliagkas et al., 2013), we assume that the learner has only \((dk)\) memory, where \(d\) is the data dimension and \(k\) is the target dimension. We can formally define the PAFO-learnability in this streaming setting:

**Definition 3**.: _We say that \(_{d}_{d}_{d}(0,1)\) is_ **PAFO-learnable for streaming PCA** _if the projection learner \(\) for which Definition 2 holds uses only \((dk)\) memory for streaming data._

### Our Algorithm: Fair Noisy Power Method (FNPM)

One only needs to estimate \(\) to use the off-the-shelf streaming PCA algorithm. As \(\) is of size \(d m\), storing its estimate is no problem for the memory constraint as long as \(m=(k)\). Naturally, we proceed via a two-stage approach; first, estimate \(\) sufficiently well, then with the fixed estimate of \(\), apply the noisy power method (Hardt and Price, 2014; Mitliagkas et al., 2013) for \(\).

For estimating \(\), one needs to estimate \(\) and \(_{m}\). Estimating \(\) can be done using the usual cumulative averaging. As for \(_{m}\), we can consider the two main approaches for streaming PCA: Oja's method (Huang et al., 2021; Oja, 1982; Oja and Karhunen, 1985) and noisy power method (NPM) (Hardt and Price, 2014; Mitliagkas et al., 2013). We first show that Oja's method is _inapplicable_ for our purpose, as it may ignore some eigenvectors corresponding to negative (but large in magnitude) eigenvalues of \(\). For instance, if \(=-2_{1}_{1}^{}+_{2}_{2}^{}+4 _{3}_{3}^{}\) with \(_{i}\) being the standard basis vectors, then Oja's method with \(m=2\) would yield \(|_{2}|_{3}|\) when we actually want \([_{1}|_{3}]\). For the same reason, simply shifting the eigenvalue spectrum by considering \(+\|\|_{2}\) does not work. Thus we apply NPM for estimating \(_{m}\) in our case, which is known to converge as long as the singular value gap of \(_{m}\) is large enough and norms of the noise matrices at each iterate are properly bounded (Balcan et al., 2016; Hardt and Price, 2014).

```
1Input:\(m\), Block size \(b\), Number of iterations \(T\);
2Output: A matrix \(}\) with orthonormal columns;
3\(_{0}=((0,1)^{d m})\);
4\((}^{(0)},}^{(1)},B^{(0)},B^{(1)})=(_{d}, _{d},0,0)\);
5for\(t[T]\)do
6 Receive \(\{(a_{i},_{i})\}_{i=(t-1)b+1}^{tb}\);
7foreach\(a\{0,1\}\)do
8 Compute \(b_{t}^{(a)},_{t}^{(a)},_{t}^{(a)}\) as Eqn. (6);
9\(}^{(a)}}{B^{(a)}+b_{t}^{(a)}}}^{(a)}+^{(a)}}{B^{(a)}+b_{t}^{(a)}}_{t}^{(a)}\);
10\(B^{(a)} B^{(a)}+b_{t}^{(a)}\);
11\(_{t}=(_{t}^{(1)}-_{t}^{(0)})\);
12\(}}^{(1)}-}^{(0)}\);
13\(}}-_{T}_{T}^{} }\);
14if\(\|}\|_{2}=0\)then
15\(}=_{T}\)
16else
17\(}=[_{T}}}{\|\|_{2}}]\) return\(}\) ```

**Algorithm 1**UnfairSubspace

Description of the algorithms.The pseudocode of our algorithm is shown in Algorithms 1 and 2. The goal of Algorithm 1 is to estimate \(=[_{m}}{\|\|_{2}}]\) in Eqn. (2) as accurately as possible. Lines 5-13 do the estimation of \(_{m}\) and \(=_{_{m}}^{}\); line 11 is the NPM to find \(_{m}\), lines 12 and 13 are the estimation of \(\) and \(\) respectively, and line 17 is the concatenation of the estimates of \(_{m}\) and \(/\|\|_{2}\). Especially at line 17, the algorithm determines whether to incorporate mean difference by checking \(}\), which can be proved to be correct, _i.e._, \(=\) if and only if \(}=\) with high probability. With the estimated \(\) from Algorithm 1, Algorithm 2 performs the usual NPM on \(_{}^{}_{}^{}\), as in Eqn. (4). The memory complexity of Algorithm 2 is \((d(m,k))\), since we do not have to store all \(b\) or \(\) data points at each time, and all the operations used can be implemented in a manner that conforms to the memory limitation; the full pseudocodes are provided in Appendix B.

At time step \(t\) of Algorithm 1, for each \(a\{0,1\}\), \(b_{t}^{(a)}\) is the number of data points \(_{i}\)'s such that \(a_{i}=a\); \(_{t}^{(a)}\) is the term used for estimation of the group-wise sample mean of \(_{i}\)'s; \(_{t}^{(a)}\) is used for the group-wise sample second moment. Their forms are as follows and can be computed

[MISSING_PAGE_EMPTY:6]

**Assumption 1**.: _Consider our data generation process \(a(p)\) and \( a_{a}\). There exists \(,V,,,_{}>0\), \(f_{}(g_{},)\), and \(p_{}(0,0.5]\) such that the followings hold for any \((_{0},_{1},p)_{d}\): for \(a\{0,1\}\), \(_{a}()\),2_

\[[\|^{}-(_{a}+_{a} _{a}^{})\|_{2} a]=1,\ \ \|_{a}+_{a}_{a}^{ }\|_{2} V,\ \ (^{} a ),\]

_and_

\[\|\|_{2}=\|_{_{m}}^{}\|_{ 2}\{0\}[g_{},f_{}],\ \ \|\|_{2} f_{},\ \ \ \ p[p_{},1-p_{}].\]

**Assumption 2**.: _Fix \(m,k\). There exist \(_{m,},_{k,},K_{m,},K_{k,}(0,)\) such that for any \((_{0},_{1},)_{d}\), the followings hold:_

\[_{m}-_{m+1}_{m,},\ _{k}-_{k+1}_{k, },\ _{m} K_{m,},\ \ _{k} K_{k,},\]

_where \(_{1}_{d} 0\) and \(_{1}_{d} 0\) are the singular values of \(\) and \(_{}^{}_{}^{}\), respectively._

We start by establishing the sample complexity bounds of Algorithms 1 and 2 based on the convergence bound for NPM by Hardt and Price (2014). Recall that NPM is an algorithm for finding top-\(r\) eigenspace (in magnitude) of a symmetric (but _not necessarily PSD_) matrix \(\) under a random noise \(^{d k}\), by update \(_{t}(_{t-1}+_{t})\). We start by recalling their meta-sample complexity result for NPM, which we have slightly reformulated for our convenience:

**Lemma 1** (Corollary 1.1 of Hardt and Price (2014)).: _Let \(1 r<d\), \((0,1/2)\) and \((0,2e^{-cd})\), where \(c\) is an absolute constant.3 Let \(_{r}\) be the \(d r\) matrix, whose columns correspond to the top-\(r\) eigenvectors (in magnitude) of the symmetric (not necessarily PSD) matrix \(^{d d}\), and let \(_{1}_{d} 0\) be the singular values of \(\). Assume that the noise matrices \(_{t}^{d r}\) satisfy_

\[5\|_{t}\|_{2}(_{r}-_{r+1})  5\|_{r}^{}_{t}\|_{2}- _{r+1})}{2}, t 1.\] (8)

_Then, after \(T=(}{_{r}-_{r+1}}())\) steps of NPM, \(\|_{_{T}}^{}_{r}\|_{2}\) with probability at least \(1-\)._

First, we prove that the \(_{T}\) resulting from Algorithm 1 (NPM for the second moment gap) converges to the true value. We can view Algorithm 1's updates as \(_{t}(_{t-1}+_{t,1})\), where the noise matrix in this case is \(_{t,1}:=(_{t}^{(1)}-_{t}^{(0)})-_{t-1}\) and \(_{t}^{(a)}\) is as defined in Eqn. (6). The following lemma asserts that with large enough block size \(b\), the error matrices are sufficiently bounded such that the NPM iterates converge:

**Lemma 2**.: _Let \(,(0,1)\). It is sufficient to choose the block size \(b\) in Algorithm 1 as_

\[b=(}{_{m,}^{2}p_{}}( }+})+^{2}}{p_{}})\] (9)

_to make the following hold with probability at least \(1-\):_

\[5\|_{t,1}\|_{2}_{m,}  5\|_{m}^{}_{t,1}\|_{2}}{2}, t 1,\] (10)

_where we recall that the columns of \(_{m}\) are the top-\(m\) (in magnitude) orthonormal eigenvectors of \(\)._

Let \(}\) be the final estimate of the true \(\) outputted by Algorithm 1. For Algorithm 2, the noise matrix is \(_{,2}:=(_{}}^{}}_{ }_{}}^{}-_{}^{} _{}^{})_{-1}\), where \(}_{}:=_{j}_{j}_{j}^{}\) is the sample covariance at time step \(\) of Algorithm 2. Similarly, with large enough block size \(\), we have the following lemma:

**Lemma 3**.: _Let \(,(0,1)\). Suppose that \(\|_{}-_{}\|_{2} }{20V}(,})\). Then, it is sufficient to choose the block size \(\) in Algorithm 2 as_

\[=(+V^{2}}{_{k,}^{2}}( }+})+^{2}}{+V^{2}} ),\] (11)

_to make the following hold with probability at least \(1-\):_

\[5\|_{,2}\|_{2}_{k,}  5\|_{k}^{}_{,2} \|_{2}}{2},  1,\] (12)

_where the columns of \(_{k}\) is the top-\(k\) (in magnitude) orthonormal eigenvectors of \(_{}^{}_{ }^{}\). (We note that \(_{k}\) is a solution for Eqn. (4).)_

**Remark 1**.: _We emphasize that, regardless of the block size requirement in the above lemmas, all the operations can be implemented within \(o(d^{2})\) space requirement._

Combining the convergence results, we can prove the following PAFO-learnability guarantee in the memory-limited, streaming setting:

**Theorem 1**.: _Let \(d,m,k\) be fixed. Consider a collection \(_{d}_{d}_{d}(0,1)\) satisfying Assumptions 1 and 2. Then, \(_{d}\) is PAFO-learnable for streaming PCA with FNPM, where the sufficient number of samples is given as \(N_{_{d}}(_{},_{},)= N_{1}+N_{2}\), with_

\[N_{1} =(}{p_{}}\{}{_{m,}^{3}}(}+^{2}})+^{2}}{_{m,}} \}+[]^{2}}{p_{ }g_{}^{2}_{k}^{2}}),\] (Algorithm 1) \[N_{2} =((+V^{2})}{ _{k,}^{3}}(}+V^{2}}{ _{}^{2}})+^{2}}{_{k, }(+V^{2})}),\] (Algorithm 2)

_where \(_{k}=(\{_{},}{kV^{2}}_{},}{}\})\) and \(=1+]f_{}^{2}}\)._

Let us take a moment to digest the sample complexity in Theorem 1. The second term \(N_{2}\) is determined by the \(_{}\)-optimality requirement in our PAFO-learnability. Note that \(N_{2}\) has no dependencies on fairness-related quantities such as \(_{}\), \(p_{}\), and \(_{m,}\). On the other hand, the first term \(N_{1}\) is not only determined by the \(_{}\)-fairness requirement, but also the \(_{}\)-optimality as well. This is the "price" of pursuing fairness; \(\), which encodes the unfair subspace needed to be nullified, is required to be accurately estimated as it impacts not only the level of fairness but also the resulting solution's optimality. This is clear in our formulation of fair PCA; in Eqn. (4), note how the optimal solution depends heavily on \(_{}\).

We further elaborate on the dependencies of \(N_{1}\) on fairness-related quantities, namely \(p_{}\) and \(\). First, if \(p_{} 0\), i.e., if one of the two groups is never sampled, then the sample complexity tends to infinity, and the learnability does not hold; this aligns with our intuition, as we need samples from _both_ of the sensitive groups. Its dependency is also quite natural, as the minimum expected number of samples from either group depends linearly on \(}\). Also, when \(\), \(N_{1}\) has an additional additive term scaling linearly with \(^{2}}\). This is because when \(\), we must explicitly account for the approximation error of \(}{\|\|_{2}}\) due to the QR decomposition at the end of Algorithm 1.

## 7 Experiments on Real-World Datasets

The code for all experiments is available at github.com/HaneulJo/fair-streaming-pca.

### CelebA Dataset

We evaluate the efficacy of our proposed FNPM on the CelebA dataset (Liu et al., 2015). It has been considered by Kleindessner et al. (2023) to show the superior efficiency of their fair PCA algorithm compared to previous approaches (Lee et al., 2022; Olfat and Aswani, 2019; Ravfogel et al., 2022). However, even in Kleindessner et al. (2023), the images were resized and grey-scaled,reducing the dimension from the original 218\(\)178\(=\)38,804 to 80\(\)80\(=\)6,400. Indeed, for a modest-sized computer, it is impossible to load all 162,770 original images in training set to the memory at once, while they require a full dataset to run each step of their algorithm. Here, we use the _original_ resolution, full-color CelebA dataset. We implement our FNPM using Python JAX NumPy Module (Bradbury et al., 2023; Harris et al., 2020) and Pytorch (Paszke et al., 2017). All experiments were performed on Apple 2020 Mac mini M1 with 16GB RAM.

Although CelebA is not streaming in nature, we intend to show that transforming it to one and using our memory-efficient approach allow us to _scale up_ fair PCA. Since there are three channels of color, we run FNPM channel-wise but in _parallel_ as usual in vision tasks (Priorov et al., 2013). For each channel of colors, we project the data onto a \(k=1000\)-dimensional subspace while nullifying \(m=2\) leading eigenvectors of covariance difference.

The resulting images are displayed in Figure 1. Here, we consider 'Eyeglasses' as a sensitive attribute to divide groups. We adopt the predefined train-validation split and run our algorithm only on the training set for 5 iterations with block sizes of \(b==32,000\). Then, using the output \(\) of FNPM, we project images selected from the validation set. We observe that we have images of faces wearing colorful glasses by nullifying some of the leading eigenvectors of covariance difference. For the images originally with sunglasses, their glasses get blurred, and "virtual" eyes are added to them. We provide more results on the other attributes and ablation studies on varying \(m\) and \(b\) in Appendix F.2.

### UCI Datasets

For the sake of completeness, we conduct a quantitative evaluation of our algorithm on UCI datasets (Adult Income, COMPAS, German Credit) and compare it with six previous works (Kleindessner et al., 2023; Lee et al., 2022; Olfat and Aswani, 2019; Ravfogel et al., 2020, 2022a; Samadi et al., 2018). The results for the Adult Income dataset are shown in Table 1. We assess several variants of our methods: in Table 1, "mean" is when we match the means and not second moments, "FNPM" is when we run our Algorithm 2 with a block size of full-batch, and "offline" is when we directly solve our "Null It Out" formulation of fair PCA (Eqn. (4)) via offline eigen-decomposition. In the table, we report the explained variance (%Var), representation fairness measured by maximum mean discrepancy (MMD\({}^{2}\)), downstream task accuracy (%Acc), and downstream task fairness in demographic parity (%\(_{}\)). The result showcases that our method yields competitive quantitative performance even for the common tabular datasets while being much more memory efficient. We defer the full results for other UCI datasets to Appendix F.3.

## 8 Other Related Works

Fairness in ML.There are largely two directions in the literature of algorithmic fairness. One direction is to propose a suitable and meaningful fairness definition (Dwork et al., 2012; Feldman et al., 2015; Hardt et al., 2016). The other direction is to develop _efficient_ fair algorithms, although often the fairness constraint forces the algorithm to be much more inefficient than its unfair counterpart, or it calls for a need for a completely new algorithmic approach. There are also different ways of

Figure 1: Experimental results on full-resolution **CelebA** dataset. Original image v.s. FNPM output. (Sensitive attribute: “Eyeglasses”)

imposing fairness in an ML pipeline, such as learning fair pre-processing (Biswas and Rajan, 2021), fair in-processing (Roh et al., 2021; Wan et al., 2023; Zafar et al., 2019), and more. The reader is encouraged to check Barocas et al. (2019) for a more comprehensive treatment of this subject.

Fair online/streaming Learning.Bechavod et al. (2020); Gillen et al. (2018) study individual fairness in online learning in a learning theoretic framework, even when the underlying metric is unavailable. Stemming from the concept of fair clustering as proposed in Chierichetti et al. (2017), Bera et al. (2022); Schmidt et al. (2020) study imposing demographic parity on clustering in the streaming setting. Such fairness has been considered in various other streaming problems such as online selection (Correa et al., 2021), streaming submodular optimization (El Halabi et al., 2020), and diversity maximization (Wang et al., 2022). Quite surprisingly, demographic parity (or any other concept of fairness) has never been considered in the setting of streaming PCA.

Streaming PCA.Without the fairness constraint, streaming PCA has been studied much from statistics and the machine learning community. Two prominent algorithms have been studied; the noisy power method (Mitiiagkas et al., 2013) and Oja's method (Oja, 1982). Much work has been done in improving the theoretical guarantees of streaming PCA (Balcan et al., 2016; Hardt and Price, 2014; Jain et al., 2016; Liang, 2023), improving the algorithm itself (Xu, 2023; Yun, 2018), or extending the guarantees to various different settings (Balzano et al., 2018; Bienstock et al., 2022; Kumar and Sarkar, 2023). Memory-limited, streaming versions of somewhat related problems, such as community detection (Yun et al., 2014) and low-rank matrix completion (Yun et al., 2015), have been tackled as well using similar spectral techniques as PCA (e.g., power method). However, to the best of our knowledge, fairness (regardless of the definition) has never been considered in this context of streaming PCA, which we tackle in this work and which we believe is of great importance.

## 9 Conclusion

In this work, we tackled the two outstanding problems of the existing fair PCA literature. From the theoretical side, we illustrated a new formulation of fair PCA based on the "Null It Out" approach and then provided a novel statistical framework called PAFO-learnability of fair PCA. From the practical side, we addressed the memory-limited scenarios by proposing a new problem setting called fair streaming PCA and a memory-efficient two-stage algorithm called FNPM. Based on these, we established a statistical guarantee that our algorithm achieves the PAFO-learnability for fair streaming PCA. Lastly, we ran experiments on the CelebA and UCI datasets to certify the scalability of our method.