# Two Sides of The Same Coin:

Bridging Deep Equilibrium Models and Neural ODEs

via Homotopy Continuation

 Shutong Ding

ShanghaiTech University

dingsht@shanghaitech.edu.cn

&Tianyu Cui

ShanghaiTech University

cuity2022@shanghaitech.edu.cn

&Jingya Wang

ShanghaiTech University

wangjingya@shanghaitech.edu.cn

&Ye Shi

ShanghaiTech University

shiye@shanghaitech.edu.cn

Equal contribution. \(\)Corresponding author.

###### Abstract

Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations (Neural ODEs) are two branches of implicit models that have achieved remarkable success owing to their superior performance and low memory consumption. While both are implicit models, DEQs and Neural ODEs are derived from different mathematical formulations. Inspired by homotopy continuation, we establish a connection between these two models and illustrate that they are actually two sides of the same coin. Homotopy continuation is a classical method of solving nonlinear equations based on a corresponding ODE. Given this connection, we proposed a new implicit model called HomoODE that inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs, which _explicitly_ solve an equilibrium-point-finding problem via Newton's methods in the forward pass, HomoODE solves the equilibrium-point-finding problem _implicitly_ using a modified Neural ODE via homotopy continuation. Further, we developed an acceleration method for HomoODE with a shared learnable initial point. It is worth noting that our model also provides a better understanding of why Augmented Neural ODEs work as long as the augmented part is regarded as the equilibrium point to find. Comprehensive experiments with several image classification tasks demonstrate that HomoODE surpasses existing implicit models in terms of both accuracy and memory consumption.

## 1 Introduction

Recent studies of implicit models have certified that such models can meet or even surpass the performance of traditional deep neural networks. Instead of specifying the explicit computation process of the output, implicit models define the joint conditions that the layer's input and output satisfy. Instances of such models include the Neural Ordinary Differential Equations (Neural ODEs) , which treat ODEs as a learnable component and can be viewed as continuous Residual Networks  (ResNets), the Deep Equilibrium Models (DEQs) , which compute the equilibrium point of a nonlinear transformation corresponding to an infinite-depth weight-tied network; and optimization layers , which leverage the optimization techniques as layers of neural networks.

Although DEQs and Neural ODEs, as popular implicit models in recent years, have garnered much attention in terms of theoretical analysis and application, an insightful connection between these twobranches of the implicit model has not been established. DEQs involve an equilibrium-point-finding problem, which is a nonlinear equation system. Generally, this can be solved via the homotopy continuation method , a classical method that solves nonlinear equations along the zero path of the homotopy mapping and can be further formulated as an ODE. This motivated us to consider whether we could bridge DEQs and Neural ODEs via the theory of homotopy continuation.

In this paper, we show that Neural ODEs can also be viewed as a procedure for solving an equilibrium-point-finding problem. However, while both of the two models can be considered as solving equilibrium-point-finding problems, they differ in how the input information is used. On the one hand, DEQs regard the input information as the _condition_ that determines the equilibrium-point-finding problem to solve via injecting it into the equilibrium function in the forward pass. On the other hand, Neural ODEs generate the initial points with different input information and expect them to converge to different equilibrium points. Therefore, we claim that DEQs and Neural ODEs are actually two sides of the same coin.

Inspired by the theoretical connection between the two models, we developed a new implicit model called HomoODE, which inherits the advantages of both. Specifically, HomoODE injects the input information into the underlying dynamic of an equilibrium-point-finding problem in the same way as a DEQ does, but then obtains the output from an ODE solver just as a Neural ODE does. The connection between DEQ and Neural ODE means that HomoODE avoids DEQ's problem of unstable convergence in DEQs and the weak representation capability of Neural ODEs. Further, a common issue for implicit models is the trade-off between computational speed and precision. Therefore, a natural intuition to accelerate such models is to find a good initial point that is close to the solution. We observed that, as the distance between the initial point and the solution drops to some range, the numbers of function evaluations (NFE) almost stop decreasing when applying homotopy continuation. Hence, we introduced an extra loss instead of zero vector initialization in DEQ to train a shared initial point. In this way, the distance from the initial point to each solution is within appropriate ranges. A series of experiments with several image classification tasks verify that HomoODE is able to converge stably and that it outperforms existing implicit models with better memory efficiency on several image classification tasks, and our acceleration method significantly reduces the NFE of HomoODE. In summary, our contributions are as follows:

(1) **A connection between DEQs and Neural ODEs.** We establish a connection between DEQs and Neural ODEs via homotopy continuation, which illustrates that DEQs and Neural ODEs are actually the two sides of the same coin. We believe this new perspective provides novel insights into the mechanisms behind implicit models.

(2) **A New Implicit Model: HomoODE.** We propose a new implicit model called HomoODE, that inherits the advantages of both DEQs and Neural ODEs. HomoODE _implicitly_ solves equilibrium-point-finding problems using homotopy continuation, unlike DEQs which _explicitly_ solve these problems via Newton's methods. Additionally, we have accelerated HomoODE with a learnable initial point that is shared among all samples.

(3) **Understanding Augmented Neural ODE.** We demonstrate that Augmented Neural ODE can be treated as a special case of HomoODE based on homotopy continuation. Hence Augmented Neural ODE enjoys better representation ability and outperforms Neural ODE.

(4) **Better Performance.** We conduct experiments on image classification datasets and confirm our HomoODE outperforms DEQ, Neural ODE, and variants of them both in accuracy and memory usage. Furthermore, we also perform the sensitivity analysis on the hyper-parameters to research the characters of our model.

## 2 Related Works

**Deep Equilibrium Models**. DEQs  have shown competitive performance on a range of tasks, such as language modeling, graph-related tasks , image classification or segmentation , image generation , inverse problems in imaging, image denoising  and optical flow estimation . DEQs find an equilibrium point of a nonlinear dynamical system corresponding to an effectively infinite-depth weight-tied network. However, training such models requires careful consideration of both initializations and the model structure [6; 9; 3], and often consumes long training times. Many studies have been devoted to solving these problems. For example, the Monotone OperatorEquilibrium Network (monDEQ)  ensures stable convergence to a unique equilibrium point by involving monotone operator theory. Bai et al.  propose an explicit regularization scheme for DEQs that stabilizes the learning of DEQs by regularizing the Jacobian matrix of the fixed-point update equations. Kawaguchi et al. prove that DEQs converge to global optimum at a linear rate for a general class of loss functions by analyzing its gradient dynamics. Agarwala et al. show that DEQs are sensitive to the higher-order statistics of their initial matrix family and consequently propose a practical prescription for initialization. To reduce the computational expense of DEQ, Pal et al.  developed continuous DEQs utilizing an "infinity time" neural ODE but did not continue to explore the inherent connection between general DEQs and Neural ODEs. From the perspective of optimization, Optimization Induced Equilibrium Networks (OptEq) theoretically connect their equilibrium point to the solution of a convex optimization problem with explicit objectives. Instead of regularizing the structures or involving parameterizations of the implicit layer design, Bai et al.  propose a model-specific equilibrium solver, which both guesses an initial value of the optimization and performs iterative updates. However, unlike DEQs, which _explicitly_ solve equilibrium-point-finding problems via Newton's methods, our HomoODE solves these problems based on homotopy continuation _implicitly_. Accordingly, HomoODE does not suffer from the issue of unique equilibrium like DEQ and thus can avoid the stability issue. Moreover, we accelerate HomoODE using a good initial point learned with a corresponding loss function. Unlike Bai et al.'s approach , HomoODE learns an initial point shared among all samples without involving a network-based initializer.

**Neural Ordinary Differential Equations**. Neural ODEs have been applied to time series modeling [44; 32], continuous normalizing flows [10; 18], and modeling or controlling physical environments [50; 43; 48; 19; 14]. Neural ODEs treat ODEs as a learnable component and produce their outputs by solving the Initial Value Problem [10; 12; 29]. However, Neural ODEs are often characterized by long training times and sub-optimal results when the length of the training data increases [13; 15]. Prior works have tried to tackle these problems by placing constraints on the Jacobian or high derivatives of the differential equation . Conversely, Augmented Neural ODEs  learn the flow from the input to the features in an augmented space with better stability and generalization. Ghosh et al.  treat the integration time points as stochastic variables without placing any constraints. With diffeomorphism, the complexity of modeling the Neural ODEs can be offloaded onto the invertible neural networks , and training Neural ODEs with the adaptive checkpoint adjoint method  can be accurate, fast, and robust to initialization. The symplectic adjoint method  finds the exact gradient via a symplectic integrator with appropriate checkpoints and memory consumption that is competitive to the adjoint method. The advantage of HomoODE is that it inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. In addition, HomoODE provides an explanation of why Augmented Neural ODEs achieve better performance than Neural ODEs. Notably, Augmented Neural ODEs can be viewed as a special case of HomoODE.

**Homotopy Continuation.** Homotopy continuation  is a numerical technique that traces the solution path of a given problem as the parameter changes from an initial value to a final value. Homotopy methods have been successfully applied to solving pattern formation problems arising from computational mathematics and biology including computing multiple solutions of differential equations [21; 22], state problems of hyperbolic conservation laws , computing bifurcation points of nonlinear systems  and solving reaction-diffusion equations . Recent advances in deep learning have also seen the homotopy continuation method fused into learning processes. For instance, Ko et al. adapt homotopy optimization in Neural ODEs to gain better performance with less more training epochs. HomPINNs  traces observations in an approximate manner to identify multiple solutions, then solves the inverse problem via the homotopy continuation method. To reach a good solution to the original geometrical problem, Hruby et al.  learn a single starting point for a real homotopy continuation path. In this work, we establish a connection between DEQs and Neural ODEs from the perspective of homotopy continuation and develop a new implicit model called HomoODE based on this theoretical relationship.

## 3 Background on Homotopy Continuation

Homotopy continuation has been broadly applied to solve nonlinear equations. The first step to solving a specific problem \(r(z)=0\) is to construct a homotopy mapping.

**Definition 1**: _(Homotopy mapping ) The function \(H(z,)= r(z)+(1-)g(z)\) is said to be a homotopy mapping from \(g(z)\) to \(r(z)\), if \(\) is a scalar parameter from \(0\) to \(1\), and \(g(z)\) is a smooth function. The equation \(H(z,)=0\) is the zero path of this homotopy mapping._

Homotopy mapping provides a continuous transformation by gradually deforming \(g(z)\) into \(r(z)\) while \(\) increases from \(0\) to \(1\) in small increments. Hence, the solution to \(r(z)\) can be found by following the zero path of the homotopy mapping \(H(z,)=0\). Usually, one can choose \(g(z)\) as an artificial function with an easy solution. Here, we specifically consider Fixed Point Homotopy which chooses \(g(z)=z-z_{0}\):

\[H(z,)= r(z)+(1-)(z-z_{0}),\] (1)

where \(z_{0}^{n}\) is a fixed vector, and is the initial point of the homotopy continuation method. In one practical trick, we can follow the zero path by allowing both \(z\) and \(\) to be functions of an independent variable \(s\), which represents arc length along the path. In other words, \((z(s),(s))\) is the point arrived at by traveling a distance \(s\) along the zero path from the initial point \((z(0),(0))=(z_{0},0)\). In the zero path, we have \(H(z(s),(s))=0,\) for all \(s 0\).

Take the derivative for this equation with respect to \(s\) lead to:

\[+=0.\] (2)

The vector \((,)^{n+1}\) is the tangent vector to the zero path, and it lies in the null space of matrix \([,]^{n(n+1)}\). To complete the definition of \((,)\), a normalization condition is imposed to fix the length of the tangent vector, i.e.

\[\|\|^{2}+||^{2}=1.\] (3)

Given the tangent vector and the initial point, we can trace the zero path and obtain the solution of \(F(z)=0\) by solving the ODE (2).

## 4 Bridging DEQs & Neural ODEs via Homotopy Continuation

Here we briefly review DEQs and Neural ODEs, then bridge these two models via homotopy continuation. DEQs aim to solve the equilibrium point of the function \(f(z;x,)\), which is parameterized by \(\) and the input injection \(x\). The underlying equilibrium-point-finding problem of DEQs is defined as follows:

\[z^{}=f(z^{};x,).\] (4)

Usually, we choose \(f(z;x,)\) as a shallow stacked neural layer or block. Hence, the process of solving the equilibrium point can be viewed as modeling the "infinite-depth" representation of a shallow stacked block. One can use any black-box root-finding solver or fixed point iteration to obtain the equilibrium point \(z^{}\).

Unlike the underlying equilibrium-point-finding problem of DEQs, Neural ODEs view its underlying problem as an ODE, whose derivative is parameterized by the network. Specifically, Neural ODEs map a data point \(x\) into a set of features by solving the Initial Value Problem  to some time \(T\). The underlying ODE of Neural ODEs is defined as follows:

\[=F(z(t),t;), z(t_{0})=x,\] (5)

where \(z(t)\) represents the hidden state at time \(t\), \(F(z(t),t;)\) is neural networks parameterized by \(\).

**The same coin.** DEQs apply Newton's methods to solve the underlying equilibrium-point-finding problem \(z=f(z;x,)\). By defining \(r(z)=z-f(z;x,)\), one can alternatively solve this equilibrium-point-finding problem based on homotopy continuation. Now we will show that the underlying dynamics in Neural ODEs can also be treated as an equilibrium-point-finding problem.

Firstly, we apply the Fixed Point Homotopy to solve the equilibrium-point-finding problem \(z=f(z;)\) and obtain the homotopy mapping \(H(z,)=(z-f(z;))+(1-)z\). Taking the partial derivative of \(H(z,)\) with respect to \(z\) and \(\), respectively, we obtain

\[=I-_{z}f(z;),\ =-f(z;).\] (6)By substituting the partial derivative in (6) into (2), we can obtain:

\[=(I-_{z}f(z;))^{-1}f(z;).\] (7)

Based on the normalization condition (3), we can reformulate (7) as the following differential equation:

\[=(I-(z)_{z}f(z;))^{-1}f(z;)\|^{2}}.\] (8)

As Neural ODEs do, we can use neural networks to approximate the underlying dynamics of such an ODE (8). However, the norm of neural network output is likely to exceed the unit length, i.e. violating the normalization condition (3). To address this issue, we introduce \(v:=\) as the velocity of the point \((z,)\) traveling along the zero path, and modify the normalization condition by introducing \(v\) into (3):

\[\|\|^{2}+||^{2}=v^{2}.\] (9)

Note that the convergence of the homotopy continuation is not affected by the value of \(v\). The underlying dynamics of (7) becomes

\[=(I-(z)_{z}f(z;))^{-1}f(z;)- \|\|^{2}}.\] (10)

Following Neural ODEs, the differential equation (10) can be approximated by neural networks, i.e. \(=F(z(t),t;)\). However, we still need to ensure the existence of a corresponding equilibrium-point-finding problem for Neural ODE. Ingeniously, the modified normalization can also ensure the existence of the equilibrium-point-finding problem. When we obtain the Neural ODEs (5) by training the neural networks \(F(z(t),t;)\), we can compute the changing process of \((t)\) and the velocity \(v\) by solving the following equations:

\[=-\|F(z(t),t;)\|^{2}}, (0)=0,(1)=1.\] (11)

Note that the modified normalization condition (9) provides the dynamic with another degree of freedom, which guarantees the existence of \((t)\). Otherwise, there might be no solution for \((t)\) as there are two initial conditions (i.e., \((0)=0,(1)=1\)) for the system. Hence, the equilibrium-point-finding problem \(z=f(z;)\) is implicitly determined by the following partial differential equation:

\[F(z(t),t;)=(I-(t)_{z}f(z;))^{-1}f(z;)-\|F(z(t),t;)\|^{2}}.\] (12)

Therefore, Neural ODEs can be regarded as the procedure of solving an equilibrium-point-finding problem with homotopy continuation, and the hidden state at \(t=0\), \(z(t_{0})\) is the initial point of homotopy continuation.

**Two sides.** We have shown that both DEQs and Neural ODEs can be considered as solving equilibrium-point-finding problems through homotopy continuation. Now we discuss the difference in underlying equilibrium-point-finding problem between DEQs and Neural ODEs.

On the one hand, DEQs solve the problem from the same initial point \(z_{0}\). The equilibrium-point-finding problem of DEQs is parameterized by the input injection \(x\). The underlying equilibrium-point-finding problem of DEQs is defined as follows:

\[z^{}=f(z^{};x,),z^{(0)}=z_{0}\] (13)

The input injection \(x\) can be viewed as the _condition_ to fuse the information of input to the underlying equilibrium-point-finding problem. The underlying problem of DEQs varies depending on different _conditions_\(x\). Therefore, DEQs are able to map inputs to diverse representations, which is crucial for achieving superior performance.

On the other hand, unlike DEQs, Neural ODEs solve an equilibrium-point-finding problem with different initial points \(z(t_{0})\). The underlying equilibrium-point-finding problem of Neural ODEs is defined as follows:

\[z^{}=f(z^{};),\] (14)and Neural ODEs solve the problem through homotopy continuation:

\[=F(z(t),t;),z(t_{0})=x\] (15)

where \(f\) is determined by \(F\) in equation (12). Concretely, Neural ODEs map raw data into a set of features \(z(t_{0})=x\) and regard them as the initial points of the ODE. The fixed underlying problem ensures the stability of Neural ODEs but loses diversified representation capabilities. Therefore, we claim that DEQs and Neural ODEs are actually two sides of the same coin from the perspective of homotopy continuation.

## 5 HomoODE: an efficient and effective implicit model

As we show above, both DEQs and Neural ODEs can be considered as solving equilibrium-point-finding problems through homotopy continuation. Two well-known approaches for solving nonlinear equations are Newton's Method  and homotopy continuation . DEQs solve an equilibrium-point-finding problem \(r(z)=0\) via Newton's Methods which are local in the sense that a good estimate of the solution is required for the convergence. Unlike Newton's Method, homotopy continuation is global in the sense that solutions of \(g(z)=0\) may not need to be anywhere close to the solution of \(r(z)=0\). Inspired by the connection between DEQs and Neural ODEs, a very natural thought is that we can apply homotopy continuation to solve the underlying nonlinear equation of DEQs. By replacing the equilibrium-point-finding problem \(z=f(z;)\) to \(z=f(z;x,)\), we can obtain the following differential equation:

\[=(I-(z)_{z}f(z;x,))^{-1}f(z;x,)-\|\|^{2}}\] (16)

Hence, we proposed a new implicit model called HomoODE, which models an equilibrium problem \(z=f(z;x,)\) implicitly. Specifically, we employ neural networks to approximate the differential equation (16). In the design of the network structure, we introduce the _condition_\(x\) into the underlying dynamic of HomoODE as DEQ does and obtain the output from the same initial point through the ODE solver as Neural ODE does. In this way, HomoODE not only has the ability of diversified

Figure 1: Comparison between different running mechanisms of implicit models.

representation of DEQs but also has the property of stable convergence of Neural ODEs. In addition, the time information \(t\) is not explicitly formulated by the dynamic of HomoODE (16). So unlike Neural ODEs, HomoODE does not require the input of time information \(t\). Figure 1 illustrates the structure of HomoODE as well as Neural ODE and DEQ. Besides, it is worth noting that \(v\) mentioned in (16) is just an auxiliary variable for the theoretical analysis. Therefore, we do not need to include it as a hyperparameter or compute its value in the forward pass because it has been implicitly contained in the neural network.

**Forward Pass.** In HomoODE, the raw data \(x\) is first input to a feature extractor \(g(x;)\) and then injected into an ODE solver. Suppose \(z(t)\) represents the intermediate state of HomoODE, calculating \(z(t)\) involves an integration starting from the initial point \(z(t_{0})=0\) to the solution \(z(t_{1})\). Notably, the output \(z(t_{1})\) is equivalent to the solution \(z^{}\) of the implicit equilibrium-point-finding problem \(z=f(z;x,)\). Then we can use the ODE solvers to obtain the solution \(z^{}\) of the origin equilibrium problem and this representation can be used for downstream tasks, such as classification, regression, etc.

\[z(t_{1})=(z(t_{0}),F(z(t),t;x,),t_{0},t_{1})\] (17)

**Backward Pass.** In the backward pass of HomoODE, we can apply the adjoint sensitivity method, or straightly differentiate through the operations of the forward pass. The _condition_ traces back to another gradient flow. More details related to the construction of HomoODE dynamics and the computation of the gradients based on the adjoint method can be referred to in the supplementary materials.

## 6 Acceleration for HomoODE

In practice, we observe that HomoODE needs more function evaluations in the ODE-solving process, which results from bad initialization (e.g., zero vector initialization). To address this issue, we referred to , which makes an input-based initial point guess with an extra neural network to accelerate the equation-solving procedure in DEQ. However, this method poses an extra cost in both memory and computation.

To avoid these drawbacks, we further investigate the relationship between the number of iterations and the distance from the initialization \(z_{0}\) to the solution \(z^{}\) in homotopy continuation. Specifically, we perform the homotopy continuation method on a nontrivial nonlinear equation using ode45 in Matlab . As is shown in Figure 2, it does not bring any reduction in the number of iterations when the initial point is close enough to the equilibrium solution. This means it is unnecessary to approximate the specific initial point very accurately for a specific sample \(x\) in HomoODE, and that is different from that in .

Hence, we share the initial point for all the samples \(x\) and just maintain a scalar value for the averaged value of the whole feature map in one channel. Briefly, we just need to store a tensor with the shape of \((1,1,c)\) as the shared initial information \(_{0}\), and broadcast it into the initial point \(z_{0}\) with the shape of \((h,w,c)\) when taking it into the ODE solver. Here \(h,w,c\) means the height, width, and channel number of the feature map. The loss function of \(_{0}\) is defined as follows:

\[(_{0}):=_{x}[(z^{}(x)- _{0})^{2}],\] (18)

where \(z^{}(x)\) denotes the equilibrium solution of the sample \(x\) and \(\) denotes the distribution of \(x\). In fact, this update on \(_{0}\) is equivalent to maintaining the dynamic geometrical center of the equilibrium points of all the samples.

## 7 Understanding Augmented Neural ODE by HomoODE

Augmented Neural ODEs, as a simple extension of Neural ODEs, are more expressive models and outperform Neural ODEs. Augmented Neural ODEs allow the ODE flow to lift points into the extra

Figure 2: Relationship between the distance from \(z_{0}\) to \(z^{}\) and the iteration number of ODE solver. The x-axis is the inversion of the distance \(1/d\), and the y-axis is the iteration number \(N\).

dimensions to avoid trajectories crossing each other . However, more theoretical analysis of how and why augmentation improves Neural ODEs is lacking. Our work provides another perspective on understanding the effectiveness of Augmented Neural ODEs. Augmented Neural ODEs formulate the augmented ODE problem as:

\[h(t)\\ a(t)=F(h(t)\\ a(t),t;),\ \ \ \ \ h(0)\\ a(0)=x\\ 0,\] (19)

where \(a(t)^{p}\) denotes a point in the augmented part, and \(h(t)^{d}\) is the hidden state at time \(t\).

Specifically, Augmented Neural ODEs can track back the ODE flow to recover the original input \(x\) by using the hidden state \(h(t)\) and the time information \(t\). The input \(x\) is the injection of the dynamics in HomoODE. The augmented part \(a(t)\) can be viewed as the intermediate \(z(t)\) in HomoODE. In Augmented Neural ODEs, we can treat the recovered input \(x\) as the _condition_ in HomoODE, improving its representation ability. Hence, Augmented Neural ODEs outperform Neural ODEs. However, the origin input \(x\) computed by Augmented Neural ODEs may not be accurate enough. This probably is the reason why the performance of Augmented Neural ODEs is not competitive to HomoODE.

## 8 Experiments

To confirm the efficiency of HomoODE, we conduct experiments on several classical image classification datasets to compare our model with the previous implicit model, including DEQ , monDEQ , Neural ODE  and Augmented Neural ODE . For ODE datasets, DEQs inherently are not designed to handle simulation tasks of continuous physical processes as DEQs do not involve the continuous time series in the models. Sequential datasets are not suitable as well due to the inconsistent backbones. For sequential datasets, DEQ models are based on transformer, while Neural ODEs are based on fully-connected layers. Therefore, we consider the image classification task is suitable for the fair comparison of HomoODE and baselines. Concretely, we evaluate the stability of the training process via the learning curve of accuracy in the test dataset and exhibit the performance of different implicit models in terms of accuracy, memory consumption, and inference time. It is worth noting that we also perform HomoODE with & without the data augmentation and the adjoint backpropagation technique to check their impacts on our model. Besides, we also contrast HomoODE with zero vector initialization and learnable initialization to assess the capability of our acceleration method. Our code is available at: https://github.com/wadx2019/homoode.

**Experimental setup.** HomoODE is performed on several standard datasets, including CIFAR-10 , SVHN , and MNIST . As shown in Figure 3, HomoODE contains several simple convolutional layers. Its network structure is not specially designed for image classification tasks like MDEQ . Notably, the memory consumption of HomoODE is less than that of other implicit models as reported in [46; 48; 7]. As we discussed in Section 5, the time information \(t\) is not fused into the input of HomoODE, unlike Neural ODE. Besides, we optimize the shared initial information

Figure 3: The deployed neural network architecture in HomoODE. Here, \(s\) denotes the stride and the channel number of all convolutional layers is \(64\).

\(_{0}\) using SGD optimizer with the learning rate \(0.02\) and perform the update once every \(20\) updates for HomoODE.

**Comparison with former implicit models.** Table 1 presents the performance of HomoODE with different settings and other implicit models in the CIFAR-10 dataset. It can be observed that HomoODE outperforms the previous implicit models in terms of both accuracy and memory consumption. Moreover, the inference time of HomoODE is much faster than DEQ and its variants. Notably, we also find that DEQ runs slower with larger test batch sizes. This may be due to the inefficiency of DEQ for parallel computation with large test batch sizes. In contrast, HomoODE does not exhibit this problem. Additionally, there is a large increase in accuracy in our model when the data augmentation technique is applied. It suggests that HomoODE learns better and more complex representations through augmented datasets. Furthermore, given that we adopt the dopri5 node solver with an adaptive step, this complex representation may result in increased NFE and inference time. Overall, these phenomenons validate that HomoODE has a more powerful representation ability compared to other implicit models with similar model capacity. Extensive experiments in SVHN and MNIST also confirm these properties of our model as shown in Table 2.

Besides, we also plot the learning curves of different algorithms in Figure 4. The results demonstrate the stability of training HomoODE compared with other methods and exhibit that HomoODE is not prone to over-fitting, whereas other ODE-based models may suffer from that.

**Efficiency of the learnable initialization.** Figure 5 illustrates that the learnable initialization trick can improve HomoODE with about \(2.5\) speedup in the inference time than before. This impact is obvious in both cases with & without the adjoint backpropagation technique. In addition, the corresponding test accuracy during the training process also reflects this acceleration technique does not bring a loss in the performance of our model. Surprisingly, it even brings a slight improvement in the case of the adjoint backpropagation technique. This is probably because a good initial point can decrease the total length of zero path \(s\), which reduces the gradient error induced by using the adjoint method.

## 9 Conclusion

In this paper, we show that both DEQs and Neural ODEs can be viewed as a procedure for solving an equilibrium-point-finding problem via the theory of homotopy continuation. Motivated by this observation, we illustrate that these two implicit models are actually the two sides of the same coin. Specifically, DEQs inject the input information as the _condition_ into the equilibrium-point-finding problem \(z^{*}=f(z^{*};x,)\) while Neural ODEs fuse the input information into the initial point. Further, we propose a novel implicit model called HomoODE, which inherits the advantages of both DEQs and Neural ODEs. Our experiments indeed verify that HomoODE outperforms both DEQs and Neural ODEs while avoiding the instability of the training process, that is often observed with DEQs. Moreover, we developed a method to speed up HomoODE and the ODE-solving operation by almost three times by using a shared learnable initial point. Overall, the experimental results on several classical image classification datasets demonstrate the efficiency of HomoODE in terms of both accuracy and memory consumption.

Although this paper offers a brand new perspective on implicit models, we also want to highlight a limitation of this idea, Actually, we do not present an explicit form of the equilibrium transformation function, which is implicitly determined by a modified neural ODE. Besides, while HomoODE has a powerful representation ability, the equilibrium-point-solving procedure of it is implicit, which

Figure 4: Learning curve of different implicit models on CIFAR-10 datasets across 5 runs without data augmentation. The x-axis denotes the epoch during training and the y-axis denotes the accuracy of models on the test datasets.

weakens its interpretability. Hence, exploring a more interpretable approach for the forward pass and backpropagation of HomoODE is under consideration in our future work.