# Fine-Grained Dynamic Framework for Bias-Variance Joint Optimization on Data Missing Not at Random

Mingming Ha

MYbank, Ant Group

Beijing, China

hamingmingming.hmm@mybank.cn

&Xuewen Tao

MYbank, Ant Group

Shanghai, China

xuewen.txw@mybank.cn

&Wenfang Lin

MYbank, Ant Group

Hangzhou, China

moxi.lwf@mybank.cn

&Qiongxu Ma

MYbank, Ant Group

Shanghai, China

qiongxu.mqx@mybank.cn

&Wujiang Xu

MYbank, Ant Group

Shanghai, China

xuwujiang.xwj@mybank.cn

&Lixun Chen

MYbank, Ant Group

Beijing, China

linxun.clx@mybank.cn

###### Abstract

In most practical applications such as recommendation systems, display advertising, and so forth, the collected data often contains missing values and those missing values are generally missing-not-at-random, which deteriorates the prediction performance of models. Some existing estimators and regularizers attempt to achieve unbiased estimation to improve the predictive performance. However, variances and generalization bound of these methods are generally unbounded when the propensity scores tend to zero, compromising their stability and robustness. In this paper, we first theoretically reveal that limitations of regularization techniques. Besides, we further illustrate that, for more general estimators, unbiasedness will inevitably lead to unbounded variance. These general laws inspire us that the estimator designs is not merely about eliminating bias, reducing variance, or simply achieve a bias-variance trade-off. Instead, it involves a quantitative joint optimization of bias and variance. Then, we develop a systematic fine-grained dynamic learning framework to jointly optimize bias and variance, which adaptively selects an appropriate estimator for each user-item pair according to the predefined objective function. With this operation, the generalization bounds and variances of models are reduced and bounded with theoretical guarantees. Extensive experiments are conducted to verify the theoretical results and the effectiveness of the proposed dynamic learning framework.

## 1 Introduction

In virtually all real-world applications, the pieces of data we collected are partially missing with certain probabilities. A special case with the identical missing probability is known as missing at random (MAR) . However, in online recommendation, search, and display advertising, there are lots of missing-not-at-random (MNAR) click, conversion, and rating records [2; 3; 4], which are missing with different probabilities, i.e., propensities. For example, in recommendation systems, a user usually clicks the items that she/he is likely to purchase and ignores other items with a low willingness to buy. Therefore, the observed click and conversion data is MNAR, which are not representative samples of all the events . When the MNAR data is used to train a model, the prediction performance of this model on the MAR data is generally unacceptable. This is because MNAR data introduces sample selection bias [3; 6] into the prediction model. To eliminate sample selection bias, lots of debiasing estimators [3; 6; 7; 8; 9] have been developed, e.g., Error-ImputationBased (EIB) approach , Inverse Propensity-Scoring (IPS) technique , Doubly Robust (DR) method , and so forth.

However, in almost all debiased methods, the existence of propensities results in the high variance and generalization bound. [11; 12]. Therefore, various methods [5; 8; 12] have been developed to reduce estimation variances and improve the model stability. Even so, they still suffer from unbounded variances and generalization bounds when the propensity tends to zero. For the high variance and generalization bound caused by small propensities, some approaches compromise to self-normalized technique [12; 13] at the expense of unbiasedness. In addition, the overwhelming majority of previous works focus on the specific designs of the estimators or regularizers to reduce variance or eliminate bias while neglecting both the bias-variance relationship of estimators and the essence of the estimator designs.

In this paper, we reveal limitations of general regularization techniques. We find that it is impossible to reduce variance without sacrificing unbiasedness by introducing regularizers, and that regularization cannot guarantee estimators to have bounded variance and generalization bound. Besides, for general estimators, unbiasedness will inevitably result in unbounded variance and generalization bound. To some extent, the generalization bound can reflect the predictive performance of an estimator. Therefore, reducing and bounding the generalization bound can assist in improving the predictive performance of models. Since the generalization bounds of estimators contain the bias and variance terms, the essence of estimator design is not merely about eliminating bias, reducing variance, or simply achieving a bias-variance trade-off but about the quantitative joint optimization of bias and variance. Then, we develop a systematic dynamic learning framework to achieve this objective. To the best of our knowledge, this is the first work to systematically reveal limitations of general regularizers and the design perspective of the quantitative bias-variance joint optimization. Our main contributions can be summarized as follows:

1. We theoretically elaborate limitations of regularization techniques, and the relationship of unbiasedness, variance and generalization bound of general estimators.
2. Based on the general laws, we elaborate a novel design perspective for the estimator, namely the quantitative bias-variance joint optimization;
3. We develop a comprehensive dynamic learning framework with the bounded variances and generalization error to optimize a weighted objective with respect to bias and variance for each user-item pair \((u,i)\), which dynamically selects different estimators for different user-item pair from a family of estimators according to the given objective function;
4. We conduct extensive experiments to verify the theoretical results and the performance of the dynamic regularizer and estimators.

## 2 Preliminaries

Data missing not at random.Denote the sets of users and items as \(=\{u_{1},u_{2},,u_{M}\}\) and \(=\{i_{1},i_{2},,i_{N}\}\), respectively. The set of all user-item pairs is denoted as \(=\). Define the true and prediction matrices as \(Y^{M N}\) and \(^{M N}\), where prediction tasks include rating, CTR and CVR predictions, and so forth. Each element \(y_{u,i}\) in \(Y\) and each entry \(_{u,i}\) in \(\) are the true label and predicted output of a user \(u\) to an item \(i\). In general, it is impossible to observe all entries in the matrix \(Y\). The indicator entry of revealed elements is defined as \(o_{u,i}\{0,1\}\). If the true label \(y_{u,i}\) is revealed, the indicator entry of \((u,i)\) satisfies \(o_{u,i}=1\). If an entry in \(Y\) is missing, then \(o_{u,i}=0\). The corresponding indicator set is denoted as \(=\{o_{u,i}=1\}\). Considering the case that no entries are missing, the prediction inaccuracy  of \(\) is defined as

\[L_{}(,Y)=_{u=1}^{M}_{i=1}^{N}e_{u,i}= |}_{(u,i)}e_{u,i},\]

where \(e_{u,i}\) is the prediction error. \(e_{u,i}\) can be selected as mean absolute error (MAE), mean square error (MSE) or other measures. The objective of prediction problems is to minimize the prediction inaccuracy \(L_{}(,Y)\)[5; 7; 8; 11; 12; 14]. Actually, only the observed label set \(Y^{o}\) can be used to establish the prediction model. The naive approach uses \(Y^{o}\) to minimize the following prediction inaccuracy:

\[L_{}(,Y^{o})=|}_{(u,i) }e_{u,i}=|}_{(u,i)}o_{u,i}e_ {u,i}.\]As mentioned in , if the probability of every entry \(y_{u,i}\) in \(Y\) being missing is identical, then the naive estimator is unbiased, that is \(_{O}[L_{}]=L_{}\), where \(O\) is taken to represent the random variable of observation. The unbiased estimation property of the naive approach is no longer valid when the data is MNAR, which even results in a large difference between \(L_{}\) and \(_{O}[L_{}]\).

Quantitative Bias-Variance Joint Optimization.Considering the large difference between \(L_{}\) and \(_{O}[L_{}]\), various unbiased estimation methods have been developed to overcome this problem, such as EIB , IPS estimator , DR method , and various variations of them [5; 7; 8; 12; 13; 15]. The corresponding estimators are given as follows:

\[L_{}(,Y^{o})= |}_{(u,i)}[o_{u,i}e_{u,i}+ (1-o_{u,i})_{u,i}],\] \[L_{}(,Y^{o})= |}_{(u,i)}}{ _{u,i}}e_{u,i},\] \[L_{}(,Y^{o})= |}_{(u,i)}_{ u,i}+}{_{u,i}}(e_{u,i}-_{u,i}),\]

where \(_{u,i}=w|_{u,i}-|\) for MAE or \(_{u,i}=w(_{u,i}-)^{2}\) for MSE of missing entries \(y_{u,i}\) is the imputed errors, and \(_{u,i}(0,1)\) is the estimation of the observation propensity, i.e., \(p_{u,i}=(o_{u,i}=1)(0,1)\). Note that \(w\) and \(\) are hyper-parameters . For the naive, EIB, IPS, and DR estimators, their biases, variances and generalization bounds are summarized in Table 4 (see Appendix A for more details), where \(_{u,i}=1-}{_{u,i}}\) and \(_{u,i}=e_{u,i}-_{u,i}\). In general, the learning of the imputation model also involves the MNAR problem. Some joint learning algorithms [11; 12] employ the propensity model to overcome this problem. Therefore, propensity estimation has a crucial role in unbiasedness and robustness. Besides, it is difficult to accurately estimate imputed errors for all user-item pair \((u,i)\) in the sense that it is difficult to achieve the unbiasedness of the EIB estimator. If the propensity estimation \(_{u,i}\) is accurate, that is \(_{u,i}=p_{u,i}\), then IPS and DR estimators are unbiased. For a new dataset, we cannot know in advance the range of the propensities in this dataset. Therefore, a new dataset may introduce extremely small propensities to lead to unbounded variances of IPS and DR, which will disrupt the stability of estimators, especially for larger datasets. It is unacceptable for real industrial scenarios. Specifically, the smaller the propensity, the larger the variance. When the propensity tends to zero, the variance tends to infinity (see Appendix B for more details). Similarly, variances of other IPS-based and DR-based unbiased estimation methods  are also unbounded. On the other hand, although the variances of naive and EIB methods are bounded when the prediction error \(e_{u,i}\) is bounded, it is difficult and even impossible to achieve an unbiased estimation. Other variance reduction estimation methods [5; 7; 8; 12] are generally biased. According to the expressions of estimators and Table 4, the bias and variance of an estimation are determined by the random variable \(O\). We found that slightly relaxing the requirements for unbiasedness will lead to a bounded variance for all propensities. Therefore, the core problem of estimation on MNAR data is the bias-variance joint optimization.

## 3 Fine-Grained Dynamic Framework for Quantitative Bias-Variance Joint Optimization

In this section, we first discuss limitations of regularization techniques and the relationship between unbiasedness of the generalized estimator and its generalization bound, which illustrate the core of the fine-grained estimator design. Then, the dynamic estimation framework for quantitative bias-variance optimization is present. Its generalization bounds and variances are reduced and bounded with theoretical guarantees.

### Limitations of Regularization Techniques

Define the general form of the estimator with regularization as

\[L_{}=|}_{(u,i)}f(o_{u,i},_{u,i})e_{u,i}+g(o_{u,i},_{u,i})_{u,i} }_{L_{}}+|}_{(u,i)}h(o_{u,i},_{u,i})}_{L_{}},\] (1)where \(f(,) 0\) with \(f(0,_{u,i})=0\), \(g(,)\), and \(h(,)\) are functions with respect to \(o\) and \(\). \(L_{}\) and \(L_{}\) are prediction inaccuracies of the estimator and regularizer, respectively. For all \((u,i)\) pairs, they satisfy \(f(o_{u,i},_{u,i})e_{u,i}+g(o_{u,i},_{u,i})_{u,i} 0\) and \(h(o_{u,i},_{u,i}) 0\). \(>0\) is a scalar weight. The generalized estimator form \(L_{}\) given in Eq. (1) covers the vast majority of existing estimators involving EIB , IPS , DR , More Robust DR (MRDR) , Targeted DR (TDR) , MIS , IPS/DR-SV , and other IPS-based and DR-based methods. On the other hand, almost all existing regularization designs, including the Sample Variance (SV) , mean inverse square (MIS) , Balancing-Mean-Square Error (BMSE) , and so forth, can be transformed into the form \(L_{}\) given in (1). In previous works, the regularization technique plays a critical role in variance reduction of estimators and improvement of the generalization performance to a certain extent. However, it still have some inevitable limitations described in the following box.

_Core Results_

1. _For the general estimator with regularization_ \(L_{}\)_, it is impossible to reduce variance without sacrificing unbiasedness._
2. _Regularization_ \(L_{}\) _cannot guarantee a bounded variance and generalization bound._

In what follows, we provide a detailed theoretical analysis to reveal the aforementioned limitations of the regularization technique. Considering the variance of \(L_{}\), we have

\[_{O}[L_{}]=_{O}[L_{}]+2 (L_{},L_{})+^{2}_{O}[L_{}].\]

As mentioned in , when the parameter \(\) is set as the optimal parameter \(_{}=-(L_{},L_{})}{ _{O}[L_{}]}\), the variance \(_{O}[L_{}]\) achieves its minimum and satisfies \(_{O}[L_{}]_{O}[L_{}]\) in the sense that the regularization term \( L_{}\) enables the estimator \(L_{}\) to reduce its variance. However, the covariance \((L_{},L_{})\) needs to fulfill \((L_{},L_{})<0\) as \(>0\). Otherwise, an inappropriate parameter will result in an increased variance. The formal theoretical results are provided by Theorems 3.1 and Corollary 3.2, which reveal the limitation 1) (see Appendix D for proofs). Corollary 3.2 is the contrapositive of Theorems 3.1.

**Theorem 3.1**.: _Let \(L_{}\) be defined in (1) and the estimator \(L_{}\) be unbiased. If \(L_{}\) is unbiased, then the variance of \(L_{}\) is greater than the variance of the original estimator \(L_{}\)._

**Corollary 3.2**.: _If the variance of \(L_{}\) is less than the variance of the original estimator \(L_{}\), then \(L_{}\) is not unbiased._

We further find that, if the variance of the original estimator is unbounded, the variances of estimators cannot be bounded by introducing a regularizer even if \(_{u,i}=p_{u,i}\). The theoretical results are shown in Theorem 3.3(see Appendix D for proofs).

**Theorem 3.3**.: _Let the bias of \(L_{}\) be bounded and the variance of \(L_{}\) satisfy \(_{p_{u,i} 0}_{O}[L_{}]_{u,i}=p_{u,i}]=\). Then, there exists no regularizer \(L_{}\) that enables the variance and generalization bound of the estimator bounded even the learned imputed errors or propensities are accurate._

According to the previous works and the present Theorem 3.3, regularizers enable variance reduction to a certain extent while cannot enable estimators to possess bounded variances and generalization bounds. In other words, regularization techniques have limited impact on improving the predictive performance of the model. In the next subsection, a novel perspective of dynamic estimator designs is proposed, which not only achieves quantitative bias-variance joint optimization but also guarantees bounded variances and generalization bounds.

### Dynamic Estimator Designs With Quantitative Optimization

Most of the existing estimators are based on IPS and DR methods, which are elaborately designed to reduce bias or variance. However, all these estimators are static estimators in the sense that they cannot achieve bias-variance joint optimization for each user-item pair \((u,i)\). Even though some methods [5; 8] can effectively reduce the variance of estimators, the estimators are biased and the corresponding variances are unbounded. In this subsection, the core results are provided in the following box. Also, based on theses results, we develop a fine-grained dynamic framework with quantitative optimization to guarantee the reduction and boundedness of variances and generalization bounds

_Core Results_

* For the generalized estimator \(L_{}\), unbiasedness of the estimator will inevitably lead to the unbounded variance and generalization bound.
* The core of the estimator design involves not merely a simple bias-variance trade-off, but rather a quantitative joint optimization of both bias and variance.

We find that the unbiased estimators with general form generally possess unbounded variances, which is formally derived in Theorem 3.4. Its proofs are provided in Appendix D.

**Theorem 3.4** (Limitation of Static Estimator).: _Given prediction errors \(e_{u,i}\), imputed errors \(_{u,i}\), and learned propensities \(_{u,i}\) for all user-item pairs \((u,i)\), if for any \(e_{u,i}-g(0,_{u,i})_{u,i} 0\), \(L_{}\) given in (1) is unbiased, then the corresponding variance and generalization bound are unbounded._

According to Theorem 3.4, the core objective of estimators is not merely about eliminating bias, reducing variance, or simply achieving a bias-variance trade-off but about a quantitative joint optimization between bias and variance. Therefore, as mentioned in _Core Results_, it is necessary to develop a dynamic estimation framework to achieve the quantitative joint optimization.

Design Principle of Dynamic Estimators.The IPS-based and DR-based dynamic learning frameworks are designed as

\[L_{}=|}_{(u,i)}}{f^{_{u,i}}(_{u,i})}e_{u,i},\ L_{}=|}_{(u,i) }_{u,i}+}{f^{_{u,i}}(_{u,i })}_{u,i},\] (2)

where \(f()\) is a designed function and \(_{u,i}\) is optimizable parameters. When \(f(_{u,i})=_{u,i}\) and \(_{u,i}=1\), D-IPS and D-DR are equivalent to the original IPS and DR estimators, respectively, which possess unbiasedness. When \(f(_{u,i})=_{u,i}\) and \(_{u,i}=0\), D-IPS and D-DR are equivalent to \(|}{||}L_{}\) and EIB estimators, which have bounded variances and generalization bounds. The function \(f(_{u,i})\) in (2) is actually a mapping, which balances the bias and variance of estimators. The design principles of \(f(_{u,i})\) are provided as follows:

* **(Isotonic Propensity)**\(f(_{u,i})\) with \(f(0)=0\), \(f(1)=1\), and \(f(_{u,i})>_{u,i}\) is a monotonically increasing function.
* **(Same Order)**\(_{_{u,i} 0}_{u,i}}{f(_{u,i})}=C\), where \(C\) is a positive constant.

Some specific expressions of \(f(_{u,i})\) fulfilling the above design principles are summarized in Table 1. The corresponding biases, variances and tail bounds of D-IPS and D-DR estimators are formally formulated in Lemmas D.1-D.4 given in Appendix D. From the biases and variances of the D-IPS and D-DR methods given as

\[(L_{})=|} _{(u,i)}h_{V}^{}(_{u,i},p_{u,i},_{u,i} )e_{u,i},\ (L_{})=|}_{(u,i) }h_{B}^{}(_{u,i},p_{u,i},_{u,i})_{u,i} ,\] \[_{O}[L_{}]=|^{2}}_ {(u,i)}h_{V}^{}(_{u,i},p_{u,i},_{u,i})e_ {u,i}^{2},\ _{O}[L_{}]=|^{2}}_ {(u,i)}h_{V}^{}(_{u,i},p_{u,i},_{u,i}) _{u,i}^{2},\]

Figure 1: The surfaces of determining factors and the objective function of dynamic estimators, and the optimal objective values: (a) \(h_{B}^{}\); (b) \(h_{V}^{}\); (c) \(w_{1}(h_{B}^{})^{2}+w_{2}h_{V}^{}\); (d) Objective\({}_{}\).

where \(h_{B}^{}(_{u,i},p_{u,i},_{u,i})=1-}{f^{w_{u,i} }(_{u,i})}\) and \(h_{V}^{}(_{u,i},p_{u,i},_{u,i})=(1-p_{u,i})} {f^{2w_{u,i}}(_{u,i})}\), functions \(h_{B}^{}\) and \(h_{V}^{}\) determine the biases and variance, respectively. \(h_{B}^{}\) and \(h_{V}^{}\) corresponding the specific expressions of \(f(_{u,i})\) are given in Table 1. The monotonicity of bias and variance are provided in Appendix D Proposition D.3. The surfaces of \(h_{B}^{}\) and \(h_{V}^{}\) are plotted in Figs. 1(a) and (b). It is observed that \(h_{B}^{}\) is monotonically decreasing and \(h_{V}^{}\) is monotonically increasing as the number of \(_{u,i}\) increases.

Bias-Variance Quantitative Joint Optimization.According to Proposition D.3 given in Appendix D, the bias-variance trade-off problem can be quantitatively formalized as the following joint optimization problem:

\[=_{_{u,i}}w_{1}(L( _{u,i}))+w_{2}_{O}[L(_{u,i})]},0_{u,i} 1,\] (3)

where \(w_{1}\) and \(w_{2}\) are weights of the bias and variance.

According to determine factors \(h_{B}^{}\) and \(h_{V}^{}\) of bias and variance, respectively, the bias-variance joint optimization problem can be defined as

\[^{}=_{_{u,i}}w_{1}E_{ B}(h_{B}^{}(_{u,i}))+w_{2}E_{V}(h_{V}^{}(_{u,i})) },0_{u,i} 1.\] (4)

For each user-item pair \((u,i)\), minimizing \(E_{B}(h_{B}^{})\) and \(E_{V}(h_{V}^{})\) given accurate propensity estimations \(_{u,i}\) leads to the bias and variance reduction, respectively. Therefore, the optimal parameter \(_{u,i}\) for each user-item pair \((u,i)\) can achieve fine-grained bias-variance joint optimization. The function \(h_{B}^{}\) under \(_{u,i}\), \(f(_{u,i})_{u,i}\) and \(_{u,i}=p_{u,i}\) satisfies \(h_{B}^{}(_{u,i},p_{u,i},_{u,i})[0,1)\). On the other hand, \(h_{V}^{}\) under \(_{u,i}\) and \(_{u,i}=p_{u,i}\) satisfies \(h_{V}^{}(_{u,i},p_{u,i},_{u,i})[0,)\). Therefore, the objective function in (4) can be simplified as \(w_{1}h_{B}^{}(_{u,i})+w_{2}h_{V}^{}(_{u,i})\). The curves of objective functions under different designed functions \(f()\) are given in Fig. 1(c). It can be observed that for a fixed propensity, there exists an \(\) such that the objective function attains the minimum value. Besides, different measure metrics are also applicable for dynamic estimators, such as \(E(h^{})=(h^{}(_{u,i}))^{2}\), \(E(h^{}(_{u,i}))=((h^{}(_{u,i})))\), and so on. In what follows, under the objective function \(w_{1}h_{B}^{}+w_{2}h_{V}^{}\), the analytical solution of the optimal parameter \(_{u,i}^{}\) is given in Theorem 3.5 (see Appendix D for proofs).

**Theorem 3.5** (The optimal parameter \(_{u,i}^{}\)).: _Let the learned propensities be accurate, i.e., \(_{u,i}=p_{u,i}\). For weights \(w_{1}\) and \(w_{2}\), the objective function \(w_{1}h_{B}^{}+w_{2}h_{V}^{}\) under \(_{u,i}\) achieves its minimum at_

\[_{u,i}^{}= }{w_{1}}(1-p_{u,i})}{(f(p_{u,i}))},0},1}.\] (5)

From the expression of the optimal parameter (5), the optimal solution of (4) under different weights depends on the weight ratio \(w_{2}/w_{1}\). Under different designed function \(f()\), the schematic diagram of optimal objective values corresponding to the optimal parameter \(_{u,i}^{}\) is shown in Fig. 1(d). Next, the generalization bounds of the developed dynamic estimator framework are further discussed. The formalized results are derived in Theorem 3.6 (see Appendix D for more details).

**Theorem 3.6** (Generalization Bounds of D-IPS and D-DR).: _For any finite hypothesis space \(\) of \(\) and the optimal prediction matrix \(^{-}\), given \(_{u,i}\) and \(_{u,i}\) for all \((u,i)\), with probability \(1-\), the prediction inaccuracies \(L_{}(^{-},Y)\) and \(L_{}(^{-},Y)\) under D-IPS and D-DR have the following upper bounds_

\[L_{}(^{-},Y^{O})+}^{Eq}(_{u,i},p_{u,i},_{u,i})e_{u,i}^{-} |}{||}}_{Term}}+^{Est}(e_{u,i}^{+})}_{ Term}}\] \[L_{}(^{-},Y^{O})+}^{Eq}(_{u,i},p_{u,i},_{u,i})_{u,i}^{-}|}{||}}_{Term}}+^{Est}(_{ u,i}^{+})}_{Term}}\]

_where \(e_{u,i}^{+}\) and \(_{u,i}^{+}\) are the error and error deviation corresponding to \(^{+}=_{}_{(u,i)}(}{f^{_{u,i}}(_{u,i})})^{2}}\) and \(^{+}=_{}_{(u,i)}(}{f^{_{u,i}}(_{u,i})})^{2}}\), respectively, and the function \(h_{G}^{Est}\) is formulated as \(h_{G}^{Est}(z_{u,i}^{+})=|}{})}{2| |^{2}}_{(u,i)}(^{+}}{f^{ _{u,i}}(_{u,i})})^{2}}\) From Theorem 3.6, the bias-variance joint optimization is actually to minimize generalization bounds, which include both the bias term and the variance term. Besides, the dynamic estimators with the optimal parameter \(_{u,i}^{}\) make variances and generalization bounds bounded. The formal result is given in Theorem 3.7 (The corresponding proofs and bounds of variances are given in Appendix D).

**Theorem 3.7** (Boundedness of Variance and Generalization Bound).: _Let \(_{u,i}^{opt}\) be the optimal parameter of (4). If the dynamic estimators adopt \(_{u,i}^{opt}\) as the parameter, then the corresponding variance and generalization bounds are bounded._

## 4 Experiments

In this section, we conduct extensive experiments to compare the performance of the present dynamic learning framework with existing SOTA approaches and to answer the following questions: **Q1**: Does the developed dynamic learning framework improve the prediction performance compared with the SOTA approaches? **Q2**: Do the present dynamic estimator designs reduce the variance and make performance more stable compared with the SOTA approaches? **Q3**: How do the performance and variance of the proposed method change under different optimization weights and estimator functions?

### Experimental Setup

Dataset and Preprocessing.Three real-world datasets with MNAR and MAR samples are used to conduct the experiments, namely Coat with 4,640 MAR and 6,960 MNAR ratings of 290 users to 300 coats, Yahoo! R3 with 54,000 MAR and 311,704 MNAR ratings of 15,400 users to 1,000 songs, and KualRec with 4,676,570 video watching ratio records of 1,411 users to 3,327 video. Similar to literature [8; 7; 5], the rating scores in Coat and Yahoo! R3 are binarized as 1 when it is greater than three, otherwise as 0. For the KualRec dataset, the video watching ratios are binarized as 0 when it is less than two, otherwise as 1.

Baselines and Experimental Details.To avoid the uncertainty caused by the prediction and observe the performance of the prediction model, we take the matrix factorization (MF)  as the base model and compare the present dynamic learning framework with the following representative IPS-based and DR-based approaches: naive **MF**, **IPS**, **SNIPS**, **IPS-AT**, **CVIB**, **IPS-V2**, **DR**, **DR-JL**, **MRDR-JL**, **Stable DR**, **Stable MRDR**, **TDR-CL**, **TMRDR-CL**, **TMRDR-CL**, **DR-V2**. Here, we adopt the two common metrics used in recommender system, i.e., area under the ROC curve (AUC), and normalized discounted cumulative gain (NDCG), to evaluate the performance of prediction models. To guarantee the fair comparison, we set the same parameters for all approaches. The learning rates are tuned in \(\{0.001,0.005,0.01,0.05\}\) and weight decay is tuned in \(\{1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6\}\). Note that, for _XX_ and _D-XX_ approaches, their model structures and parameters are identical. Every approach is preformed 10 times to record its mean and standard deviation.

[MISSING_PAGE_FAIL:8]

bounds and then further improve the generalization performance. Meanwhile, we find that the variances of dynamic estimators is not decreasing when the weight ratio increases. This because, for different ratios, the global minimum of the objective function (4) cannot be reached within the interval \(\). For SNIPS, the property of variance reduction might lead to the non-obvious performance and variance trends.

Under the identical weight ratio \(}{w_{1}}=0.1\), we further discuss the effects of different functions \(f^{}(_{u,i})\) on the prediction performance and variance. The experimental results are shown in Fig. 3. Nearly all dynamic estimators with different function expressions outperform the corresponding debiased approaches given in Table 3. It further demonstrates that the proposed dynamic learning mechanism can greatly improve the performance of the original estimator. Besides, the prediction performance of the dynamic estimator with \(f^{}(_{u,i})=(_{u,i}+1)}{(2)})^{}\) outperforms other dynamic estimators.

## 5 Related Work

Aiming at the prediction model bias caused by the MNAR data, EIB  and IPS  approaches are two classical unbiased estimators. To leverage the advantages of EIB and IPS, the DR method  was designed to make the unbiasedness of estimator doubly robust. Focusing on the unbiasedness of estimators, various estimation methods have been proposed to overcome mixed or even unknown biases in the data , to solve the sample selection bias problem in the multi-task learning [20; 21; 22; 23], to improve the performance of the propensity model by different approaches [18; 14], and so forth. A multiple robust estimator is developed in  by taking the advantage of multiple candidate imputation and propensity models, which is unbiased when any of the imputation or propensity models, or a linear combination of these models is accurate. From a novel function balancing perspective, Li et al. propose to approximate the balancing functions in reproducing kernel Hilbert space . Moreover, aimed at limitations of miscalibrated imputation and propensity models, Kweon and Yu  propose a doubly calibrated estimator and a tri-level joint learning framework to simultaneously optimize calibration experts alongside prediction and imputation models. For the variance of estimators, an increasing body of works have emerged to reduce the variance. The most common estimator reducing variance is Self-Normalized IPS (SNIPS) . Based on DR, literature  designed a MRDR estimator to reduce the variance of the DR estimator by the present variance expression of DR. In , TDR estimator is elaborated to reduce the bias and variance of DR simultaneously by the present semi-parametric collaborative learning. Moreover, stable DR estimator  achieves the bounded bias, variance, and generalization error bound simultaneously for arbitrarily small propensities by combining SNIPS and DR methods. Various regularization designs, such as SV , MIS , BMSE , and so forth, are also introduced into the estimator to achieve variance reduction.

   \(f^{}(_{u,i})\) & _{u,i}^{}\)} & _{u,i}))^{}}{(1)}\)} \\  Methods & AUC & Gain\({}_{}\) & NDCG@5 & Gain & AUC & NDCG@5 & Gain \\  D-IPS & 0.7702\(\)**0.0011** & 2.16\% & 0.6362\(\)**0.0043** & -2.06\% & 0.7753\(\)0.0017 & 2.84\% & 0.6475\(\)0.0043 & -0.32\% \\ D-SNIPS & 0.7413\(\)0.0045 & -0.13\% & **0.6146\(\)**0.0079 & 0.59\% & 0.7392\(\)0.0038 & -0.42\% & 0.6109\(\)0.0089 & -0.02\% \\ D-IPS-AT & 0.7711\(\)0.0016 & 0.25\% & 0.6360\(\)0.0051 & 11.17\% & 0.7710\(\)0.0022 & 0.23\% & 0.6346\(\)0.0036 & 0.89\% \\ D-DR & 0.7710\(\)**0.0014** & 2.28\% & 0.6384\(\)**0.0047** & -0.6476\(\)0.0021 & 2.98\% & 0.6516\(\)0.0052 & 1.42\% \\ D-DR-JL & 0.7695\(\)0.0013 & 1.60\% & 0.8346\(\)0.0058 & -2.31\% & 0.7748\(\)0.0012 & 2.30\% & 0.6444\(\)0.0053 & -0.80\% \\ D-MRDR-JL & 0.7711\(\)0.0016 & 1.59\% & 0.6365\(\)0.0040 & -2.11\% & 0.7751\(\)**0.0012** & 2.12\% & 0.6470\(\)**0.038** & -0.49\% \\   \(f^{}(_{u,i})\) & _{u,i}))^{}}{(2)}\)} \\  Methods & AUC & Gain\({}_{}\) & NDCG@5 & Gain & AUC & Gain\({}_{}\) & NDCG@5 & Gain\({}_{}\) \\  D-IPS & **0.7777\(\)**0.0015 & 3.16\% & **0.6584\(\)**0.0049 & 1.35\% & 0.7771\(\)0.0016 & 3.08\% & 0.6578\(\)0.0048 & 1.26\% \\ D-SNIPS & **0.7429\(\)**0.0036** & 0.08\% & 0.6096\(\)**0.0062** & **-0.23\%** & 0.7418\(\)0.0070 & -0.07\% & 0.6115\(\)0.0082 & 0.08\% \\ D-IPS-AT & 0.7705\(\)0.0012 & 0.17\% & **0.6367\(\)**0.0052 & 1.22\% & **0.7718\(\)0.0011** & 0.34\% & 0.6357\(\)**0.0029** & 1.07\% \\ D-DR & **0.7804\(\)**0.0023 & 3.53\% & **0.6671\(\)**0.0051 & 3.83\% & 0.7792\(\)0.0019 & 3.37\% & 0.6680\(\)0.0053 & 2.85\% \\ D-DR-JL & 0.7757\(\)0.0016 & 2.65\% & **0.6577\(\)**0.0036** & 1.25\% & **0.7782\(\)**0.0011** & 2.75\% & 0.6537\(\)0.0039 & 0.63\% \\ D-MRDR-JL & **0.7786\(\)**0.0025 & 2.58\% & **0.6616\(\)**0.00044 & 1.75\% & 0.7779\(\)0.0017 & 2.49\% & 0.6576\(\)0.0071 & 1.14\% \\   

Table 3: Effects of different functions on performances of dynamic estimators.

Conclusions

To the best of our knowledge, this is the first work to reveal that the essence of estimator designs is not merely to eliminate bias, to reduce variance, or to achieve a simple bias-variance trade-off but to quantitatively and simultaneously optimize bias and variance. Besides, the limitations of general regularization techniques and general static estimators are presented. Based on the general laws with respect to the relationship between bias and variance, we propose a systematic dynamic learning framework, which guarantees the bounded variances and generalization bounds by the present fine-grained bias-variance joint optimization scheme. Extensive experiment results have verified the theoretical results and the performance of the present dynamic estimators. The search for optimal weights in the objective function and the functions in the dynamic estimation framework remains an open question.