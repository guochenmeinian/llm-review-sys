# From Lazy to Rich: Exact Learning Dynamics in Deep Linear Networks

Clementine C. J. Domine\({}^{,,1}\)

 Clementine.domine.20@ucl.ac.uk

&Nicolas Anguita\({}^{,2}\)

nicolas.anguita20@imperial.ac.uk

Alexandra M. Proca\({}^{2}\) &Lukas Braun\({}^{3}\) &Daniel Kunin\({}^{4}\) &Pedro A.M. Mediano\({}^{,2,5}\)

Andrew M. Saxe\({}^{ 1,6,7}\)

###### Abstract

Biological and artificial neural networks create internal representations for complex tasks. In artificial networks, the ability to form task-specific representations is shaped by datasets, architectures, initialization strategies, and optimization algorithms. Previous studies show that different initializations lead to either a lazy regime, where representations stay static, or a rich regime, where they evolve dynamically. This work examines how initialization affects learning dynamics in deep linear networks, deriving exact solutions for \(\)-balanced initializations, which reflect the weight scaling across layers. These solutions explain how representations and the Neural Tangent Kernel evolve from rich to lazy regimes, with implications for continual, reversal, and transfer learning in neuroscience and practical applications.

+
Footnote â€ : dagger\) First authors

\(1\). Gatsby Computational Neuroscience Unit, University College London, London, United Kingdom

\(2\). Department of Computing, Imperial College London, London, United Kingdom

\(3\). Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom

\(4\). Institute for Computational and Mathematical Engineering, Stanford University, Stanford, USA

\(5\). Division of Psychology and Language Sciences, University College London, London, United Kingdom

\(6\). Sainsbury Wellcome Centre, University College London, London, United Kingdom

\(7\). CIFAR Azrieli Global Scholar, CIFAR, Toronto, Canada

\(\) Co-senior Author

## 1 Introduction

Biological and artificial neural networks learn internal representations that enable complex tasks such as categorization, reasoning, and decision-making. Both systems often develop similar representations from comparable stimuli, suggesting shared information processing mechanisms Yamins et al. (2014). Although not yet fully understood, this similarity has garnered significant interest from neuroscience, AI, and cognitive science Haxby et al. (2001); Laakso and Cottrell (2000); Morcos et al. (2018); Kornblith et al. (2019); Moschella et al. (2022). The success of neural models relies on their ability to form these representations and extract relevant features from data to build internal representations, a complex process that in machine learning is defined by two regimes: _lazy_ and _rich_ Saxe et al. (2014); Pennington et al. (2017); Chizat et al. (2019); Bahri et al. (2020). Despite significant advances, these learning regimes and their characterization are not yet fully understood and would benefit from clearer theoretical predictions, particularly regarding the influence of prior knowledge (initialization) on the learning regime. We discuss related works in the appendix A.

**Our contributions.** (1) We derive exact solutions for the gradient flow in unequal-input-output two-layer deep linear networks, under a broad range of lambda-balanced initialization conditions (Section 2). (2) We model the full range of learning dynamics from _lazy_ to _rich_, showing that this transition is influenced by a complex interaction of architecture, _relative scale_, and _absolute scale_, (Section 3). (3) We present applications relevant to both the neuroscience and machine learning field, providing exact solutions for continual learning dynamics, reversal learning dynamics, and transfer learning (Section 4).

## 2 Exact Learning Dynamics

**Setting** Consider a supervised learning task where input vectors \(_{n}^{N_{i}}\), from a set of \(P\) training pairs \(\{(_{n},_{n})\}_{n=1}^{P}\), need to be mapped to their corresponding target output vectors \(_{n}^{N_{o}}\). We learn this task with a two-layer linear network model that produces the output prediction\(}_{n}=_{2}_{1}_{n}\), with weight matrices \(_{1}^{N_{h} N_{i}}\) and \(_{2}^{N_{o} N_{h}}\), where \(N_{h}\) is the number of hidden units. The network's weights are optimized using full batch gradient descent with learning rate \(\) (or respectively time constant \(=\)) on the mean squared error loss \((},)=||}-||^{2}\), where \(\) denotes the average over the dataset. The dynamics are completely determined by the input covariance and input-output correlation matrices of the dataset, defined as \(}^{xx}=_{n=1}^{P}_{n}_{n}^{T}^{N_{i} N_{i}}}^{yx}=_{n=1}^{P}_{n}_{n}^{T} ^{N_{o} N_{i}}\), and the initialization \(_{2}(0),_{1}(0)\). Our objective is to describe the entire dynamics of the network's output and internal representations based on this initialization and the task statistics. We consider an approach first introduced in the foundational work of Fukumizu Fukumizu (1998) and extended in recent work by Braun et al. (2022), which rather than consider the dynamics of the parameters directly, we consider the dynamics of a matrix of the important statistics. In particular, defining \(=_{1}&_{2}^{T}^{T} ^{(N_{i}+N_{o}) N_{h}}\), we consider the \((N_{i}+N_{o})(N_{i}+N_{o})\) matrix \(^{T}(t)=_{1}^{T}_{1}(t )&_{1}^{T}_{2}^{T}(t)\\ _{2}_{1}(t)&_{2}_{2}^{T}(t)\), which is divided into four quadrants with interpretable meanings. The approach tracks several key statistics collected in the matrix. The off-diagonal blocks contain the network function \(}(t)=_{2}_{1}(t)\), which can be used to evaluate the dynamics of the loss as shown in Fig. 1. The on-diagonal blocks capture the correlation structure of the weight matrices, allowing for the calculation of the temporal evolution of the network's internal representations. This includes the representational similarity matrices (RSM) of the neural representations within the hidden layer, as first defined by Braun et al. (2022),\(_{I}=^{T}_{1}^{T}_{1}(t) \), \(_{O}=^{T}(_{2}_{2}^{T}(t))^{+ }\), where \(+\) denotes the pseudoinverse; and the network's finite-width NTK Jacot et al. (2018); Lee et al. (2019); Arora et al. (2019)\(=_{N_{o}}^{T}_{1}^{T} _{1}(t)+_{2}_{2}^{T}(t) ^{T}\), where \(\) is the identity matrix and \(\) is the Kronecker product. Hence, the dynamics of \(^{T}\) describes the important aspects of network behaviour.

We extend previous solutions Fukumizu (1998); Braun et al. (2022); Kunin et al. (2024) and derive exact solutions for the dynamics of \(^{T}\) in unequal-input-output under a broad range of lambda-balanced initialization conditions. See Appendix B.2 for a further discussion of the assumptions and their relation to previous works. The proof of the Theorem and lemma leading to the theorem is in Appendix C. With this solution we can calculate the exact temporal dynamics of the loss, network function, RSMs and NTK (Fig. 1A, C) over a range of lambda-balanced initializations. **Implementation and simulation.** Simulation details are in Appendix F.7.

## 3 Rich and Lazy Learning

In this section we aim to gain a deeper understanding of the transition between the _rich_ and _lazy_ regimes by examining the dynamics as a function of lambda - the _relative scale_ - as it varies between positive and negative infinity.

**Dynamics of the singular values.** Here we examine a _lambda-balanced_ linear network initialized with _task-aligned_ weights. Previous research Saxe et al. (2019) has demonstrated that initial weights that are aligned with the task remain aligned throughout training, restricting the learning dynamics to the singular values of the network. As shown in Fig.4 B, as \(\) approaches zero, the dynamics resemble sigmoidal learning curves that traverse between saddle points, characteristic ofthe _rich_ regime Braun et al. (2022). In this regime the network learns the most salient features first, which can be beneficial for generalization Lampinen and Ganguli (2018). Conversely, as shown in Fig.4 A and C, as the magnitude of \(\) increases, the dynamics become exponential, characteristic of the _lazy_ regime. In this regime, all features are treated equally and the network's dynamics resemble that of a shallow network. Overall, our results highlight the critical influence of both the _absolute scale_ and the _relative scale_\(\) has in shaping the learning dynamics, from sigmoidal to exponential, steering the network between the _rich_ and _lazy_ regimes. The proof can be found in Appendix D.1.

**The dynamics of the representations.** We examine how the representations of the parameters \(_{1}\) and \(_{2}\) evolve during training. With lambda-balanced initializations, the structure persists throughout training, allowing us to recover the dynamics up to a time-dependent orthogonal transformation. The singular values \(_{}\) of the weights are adjusted based on \(\), splitting the representation into two parts (Theorem D.2). Using \(^{T}(t)\), we capture the temporal dynamics of hidden layer activations and analyze whether the network adopts a _rich_ or _lazy_ representation, depending on \(\). Upon convergence, the internal representation satisfies \(_{1}^{T}_{1}=}}_{1}^{2 }}^{T}\) and \(_{2}_{2}^{T}=}}_{2}^{2 }}^{T}\), with detailed proof in Theorem D.3. For a hierarchical semantic task Saxe et al. (2014); Braun et al. (2022), the representational similarity of inputs (\(}}}^{T}\)) and targets (\(}}}^{T}\)) aligns with the task structure. When training a two-layer network with relative scale \(=0\), the representational similarity matrices match the task upon convergence (Theorem D.3). As \(\) approaches positive or negative infinity, the network transitions to the _lazy_ regime, adopting task-agnostic representations (Theorem D.4, Fig. 2). The NTK becomes static and identity-like, while downscaled representations remain structured. This property can enhance generalization during fine-tuning, as shown in Section 4. In contrast, large Gaussian initializations result in _lazy_ learning, lacking structural representation. We propose a new _semi-structured lazy_ regime, where initialization determines whether task-specific features reside in input or output layers.

Figure 1: **A** The temporal dynamics of the numerical simulation of the loss, network function, correlation of input and output weights, and the NTK (row 1-5 respectively) are exactly matched by the analytical solution for \(=-2\). **B**\(=0.001\) Large initial weight values. **C**\(=2\) initial weight values.

**Representation robustness and sensitivity to noise.** In appendix D.3 we examine the relationship between the learning regime and the robustness of the learned representations to added noise in the inputs and parameters. In practice, parameter noise could be interpreted as the noise occurring within the neurons of a biological network. We find that a rich solution may enable a more robust representation in such systems.

**The impact of the architecture.** Thus far, we have found that the magnitude of the _relative scale_ parameter \(\) determines the extent or rich and lazy learning. Here, we explore how a network's learning regime is influenced by the interaction of its architecture and the sign of the _relative scale_. We consider three types of network architectures, depicted in Fig. 3A: _funnel networks_, which narrow from input to output (\(N_{i}>N_{h}=N_{o}\)); _inverted-funnel networks_, which expand from input to output (\(N_{i}=N_{h}<N_{o}\)); and _square networks_, where input and output dimensions are equal (\(N_{i}=N_{h}=N_{o}\)). Our solution, \(^{T}\), captures the NTK dynamics across these different network architectures. To examine the NTK's evolution under varying \(\) initializations, we compute the kernel distance from initialization, as defined in Fort et al. (2020). As shown in Fig. 3B, we observe that funnel networks consistently enter the _lazy_ regime as \(\), while inverted-funnel networks do so as \(-\). The NTK remains static during the initial phase, rigorously confirming the rank argument first introduced by Kunin et al. (2024) for the multi-output setting. In the opposite limits of \(\), these networks transition from a _lazy_ regime to a _rich_ regime. During this second alignment phase, the NTK matrix undergoes changes, indicating an initial _lazy_ phase followed by a _delayed rich_ phase. We further investigate and quantify this _delayed rich_ regime, showing the NTK movement over training in Fig. 3C. This behavior is also quantified in Theorem D.6, which describes the rate of learning in this network. For square networks with equal input and output dimensions, this behavior is discussed in Section 3. Across all architectures, as \( 0\), the networks consistently transition into the _rich_ regime. Altogether, we further characterize the _delayed rich_ regime in wide networks.

Figure 3: **A. Schematic representations of the network architectures considered, from left to right: funnel network, square network, and inverted-funnel network. B. The plot shows the NTK kernel distance from initialization, as defined in Fort et al. (2020) across the three architecture depicted schematically. C. The NTK kernel distance away from initialization over training time.**

Figure 2: **A A semantic learning task with the SVD of the input-output correlation matrix of the task. (top) \(U\) and \(V\) represent the singular vectors, and \(S\) contains the singular values. (bottom) The respective RSMs for the input and for the output task. B Simulation results and C Theoretical input and output representation matrices after training, showing convergence when initialized with varying lambda values, according to the initialization scheme described in F.7. D Final RSMs matrices after training converged when initialised from random large weights. E After convergence, the networkâ€™s sensitivity to input noise (top panel) is invariant to \(\), but the sensitivity to parameter noise increases as \(\) becomes smaller (or larger) than zero.**Application

**Continual learning.** In line with the framework presented by Braun et al. (2022), our approach describes the exact solutions of the networks dynamics trained across a sequence of tasks. As detailed in Appendix E.1, we demonstrate that, regardless of the chosen value of lambda, training on subsequent tasks can result in the overwriting of previously acquired knowledge, leading to catastrophic forgetting McCloskey Cohen (1989); Ratcliff (1990); French (1999).

**Reversal learning.** As demonstrated in Braun et al. (2022), reversal learning theoretically does not succeed in deep linear networks as the initalization aligns with the separatrix of a saddle point. While simulations show that the learning dynamics can escape the saddle point due to numerical imprecision, the process is catastrophically slowed in its vicinity. However, when \(\) is non-zero, reversal learning dynamics consistently succeed, as they avoid passing through the saddle point due to the initialization scheme. This is both theoretically proven and numerically illustrated in Appendix E.2. We also present a spectrum of reversal learning behaviors controlled by the _relative scale_\(\), ranging from _rich_ to _lazy_ learning regimes. This spectrum has the potential to explain the diverse dynamics observed in animal behavior, offering insights into the learning regimes relevant to various neuroscience experiments.

**Transfer learning.** We consider how different \(\) initializations influence generalization to a new feature after being trained on an initial task. We observe in Appendix figure 7 that the task specific structure of the data is effectively transferred to the new feature when the representation is task-specific and \(\) is zero. Conversely, when the output feature representation is _lazy_, meaning the hidden representation lacks adaptation, no task specific generalization is observed. Strikingly, when \(\) is positive, the task specific structure in the input weights remains small but structured, while the output weights exhibit a _lazy_ representation and the network generalizes to the task specific features. This suggests that the _lazy_ regime structure can be beneficial for transfer learning.

## 5 Discussion

We derive exact solutions to the learning dynamics within a tractable model class: deep linear networks. We examine the transition between the _rich_ and _lazy_ regimes by analyzing the dynamics as a function of \(\)--the _relative scale_--across its full range from positive to negative infinity. Our analysis demonstrates that the _relative scale_, \(\), plays a crucial role in managing the transition between _rich_ and _lazy_ regimes.

#### Acknowledgments

This research was funded in whole, or in part, by the Wellcome Trust [216386/Z/19/Z]. For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission. C.D. and A.S. were supported by the Gatsby Charitable Foundation (GAT3755). Further, A.S. was supported by the Sainsbury Wellcome Centre Core Grant (219627/Z/19/Z) and A.S. is a CIFAR Azrieli Global Scholar in the Learning in Machines & Brains program. A.M.P. was supported by the Imperial College London President's PhD Scholarship. L.B. was supported by the Woodward Scholarship awarded by Wadham College, Oxford. and the Medical Research Council [MR/N013468/1]. D.K. thanks the Open Philanthropy AI Fellowship for support. This research was funded in whole, or in part, by the Wellcome Trust [216386/Z/19/Z].

#### Author Contributions

Clementine and Nicolas led the work on the equal input-output solution to the exact dynamics, with support from Daniel. Clementine lead the extention to this work to the unequal input-output case from priminilary work from Nicolas. Then she examining the impact of the architecture. Clementine and Nicolas also spearheaded the development of the minimal model for _rich_ and _lazy_ learning, emphasizing exact solutions and representation convergence. Daniel, Nicolas, and Clementine collaborated on analyzing the dynamics of singular values, while Lukas led the investigation into representation robustness and sensitivity to noise. Clementine and Nicolas primarily conducted the analysis of the continual learning framework, while Alexandra and Clementine focused on transfer learning in the _rich_ and _lazy_ settings. Clementine took the lead on the reversal learning analysis. She was primarily responsible for leading the manuscript writing, with assistance from Daniel. Initial work on this project was carried during Nicolas masters supervised by Clementine and Pedro. All authors contributed to writing the appendix and refining the final manuscript.