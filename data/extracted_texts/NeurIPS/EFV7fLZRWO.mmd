# Muscles in Time: Learning to Understand Human Motion by Simulating Muscle Activations

David Schneider

Corresponding author: david.schneider@kit.edu

Simon Reiss

Karlsruhe Institute of Technology

Marco Kugler

Alexander Jaus

Mercedes-Benz Tech Innovation

Kunyu Peng

Karlsruhe Institute of Technology

Susanne Sutschet

Mercedes-Benz Tech Innovation

M. Saquib Sarfraz

Mercedes-Benz Tech Innovation

Sven Matthiesen

Mercedes-Benz Tech Innovation

Rainer Stiefelhagen

Corresponding author: david.schneider@kit.edu

###### Abstract

Exploring the intricate dynamics between muscular and skeletal structures is pivotal for understanding human motion. This domain presents substantial challenges, primarily attributed to the intensive resources required for acquiring ground truth muscle activation data, resulting in a scarcity of datasets. In this work, we address this issue by establishing _Muscles in Time (MinT)_, a large-scale synthetic muscle activation dataset. For the creation of _MinT_, we enriched existing motion capture datasets by incorporating muscle activation simulations derived from biomechanical human body models using the OpenSim platform, a common approach in biomechanics and human motion research. Starting from simple pose sequences, our pipeline enables us to extract detailed information about the timing of muscle activations within the human musculoskeletal system. _Muscles in Time_ contains over nine hours of simulation data covering 227 subjects and 402 simulated muscle strands. We demonstrate the utility of this dataset by presenting results on neural network-based muscle activation estimation from human pose sequences with two different sequence-to-sequence architectures.

Data and code are provided under https://simplexsigil.github.io/mint.

## 1 Introduction

Like prisoners in Plato's cave, neural networks for human motion understanding often rely on indirect representations rather than direct, biologically grounded data. In Plato's allegory, prisoners in a cave see only shadows cast on the wall, not the true objects. Similarly, neural networks trained on accessible data, such as RGB and depth-based video recordings or motion capture, only perceive surface-level appearance of motion in contrast to the inner mechanics of the human body.

This reliance on external visual observations provides an incomplete understanding of the true complexities of human motion. Just as the prisoners lack a direct view of the objects casting the shadows, current models lack exposure to the internal workings of the human body, such as the muscle activations driving motion. This gap limits their ability to develop an in-depth understanding of physical exertion, motion difficulty, and mass impact on the body.

Our community has progressed from capturing human motion with camera sensors and predicting activities to pose-based recognition systems that account for the body and its motion over time. These advances, while significant, still overlook the interplay of muscle activations, which are the root of pose sequences and patterns.

Collecting electromyographic (EMG) data or more commonly used surface electromyographic (sEMG) data, as a measure of muscle activation, presents challenges. It is resource intensive, requiring specialized equipment, controlled environments, and is an invasive procedure. Existing EMG and sEMG datasets are small, limited in scope, and not representative of the variety of human motions. These limitations hinder the development of neural networks that can generalize across different types of motion and subjects.

While acknowledging the contributions of EMG and sEMG datasets, we identify an opportunity to supplement this domain with a synthetic dataset that overcomes some limitations of real-world data collection. The strength of our dataset lies in its scale and detail of muscle activation data, a feat not achievable through conventional methods alone.

Every dataset, simulated or real, has domain-specific fidelity and relevance. Real-world recordings offer authenticity that underpins our understanding of human biomechanics with nuances, such as EMG measurements being subject-specific and varying over the course of one day. Simulated datasets, like ours, offer a complementary perspective by providing comprehensive data for the understanding of muscle activation patterns through a scalable data acquisition pipeline.

In this work, we present a comprehensive large-scale dataset incorporating muscle activation information. We enrich existing motion capture datasets with muscle activation simulations from biomechanical models of the human body. Our pipeline uses simple pose and shape sequences with estimated weight and mass of the human body to simulate muscle activations for individual movements. Using this, we generate the muscles' activation that fit the provided human motions. Figure 1 provides an overview of our pipeline.

We showcase the utility of muscle activations as an additional data type for human motion understanding and gather insights by visualizing the intricate details of our data. Our dataset, the first of its magnitude and detail, describes muscle activation across a wide array of movements. By enhancing the current set of tools available to researchers, we expand the potential for scientific investigation and innovation in the study of human motion.

## 2 Related Work

**Human Motion Analysis and Datasets** EMG-based muscle activation analysis is a well-established field in biomechanical research. Still, publicly available databases including experimentally measured muscle excitation using sEMG are often small in size or cover a small range of muscles or motion variations [21; 30; 79; 25; 51; 46; 61; 42; 34; 50; 65]. The dataset proposed by Zhang _et al_. 

Figure 1: Simulation pipeline of the Muscles in Time dataset. The SMPL representation is extracted from videos, then, the SMPL represented motions are mapped to bio-mechanically validated human body models to simulate fine-grained muscle activation, connecting computer vision with biomechanical research. Bottom right: two activation sequences for exemplary muscles. Images from [47; 15]

contains 5 persons and leveraged 8 EMG sensors. The KIMHu dataset , for example, includes sEMG data of four upper limb muscles measured during different arm exercises performed by 20 subjects. The MIA Dataset  includes sEMG signals for eight muscles in total (upper and lower limb) across 10 subjects who performed 15 different exercises, e.g., running, jumping jacks, squats, and elbow punches. MuscleMap is a video-based muscle activation estimation dataset, which assigns binary muscle activation labels to action categories, involving \(20\) muscle groups and \(135\) actions . In Table 1, we provide a comparison of multiple recent EMG datasets to MinT. Most notably MinT features a significantly larger number of subjects, a larger number of activation measurements and a diverse range of motions.

OpenSim is an open-source software platform for musculoskeletal modeling, simulation, and analysis. It is widely used in various research areas such as biomechanics research, orthopedics and rehabilitation science, and medical device design [16; 66]. The state-of-the-art process in OpenSim for simulating muscle activations of a certain task requires subject-specific motion and force data. In most cases, these data are obtained through experimental studies, which can be time-consuming and resource-intensive.

In a related field, musculoskeletal humanoid control and simulation focuses on developing computational models and control strategies for simulating human motion with musculoskeletal detail. Recent work by Jiang et al. , Caggiano et al. , Feng et al. , and He et al. [83; 29] has advanced methods for efficient and realistic simulation of muscle-actuated characters. While these approaches differ from OpenSim's focus, they highlight the broader interest in understanding and simulating human musculoskeletal dynamics.

**Skeleton-based Vision Models** Skeleton-based action recognition [22; 1] is pivotal in decoding human actions from video footage, providing a streamlined and insightful depiction of human poses and movements that remains invariant to changes in appearance, illumination, and backdrop. This approach enhances the identification of dynamic skeletal characteristics essential for precise action recognition, finding utility across surveillance, human-computer interaction, and medical fields. The goal of skeleton-based action recognition is to classify actions based on skeletal geometry information [36; 44; 49; 19; 56; 74; 54; 72; 7]. Predominantly, the techniques employed are based on graph convolutional neural networks (GCN)[38; 76; 68; 9; 77; 8], with newer methods adopting transformer architectures [69; 58; 41; 81; 17; 73]. Chen _et al._ proposed channel-wise topology refinement graph convolution for skeleton-based action recognition. Yan _et al._ proposed skeleton masked auto encoder to achieve skeleton sequence pretraining which delivers promising benefits for the skeleton based action recognition. Apart from the GCN and transformer based models, PoseC3D is proposed by Duan _et al._ to use 3D convolutional neural networks on the heat map figures painted by the skeleton joints.

**Sequence-to-sequence Models** Sequence to sequence models [52; 37; 11; 80; 43; 67; 24] are a class of deep neural network architectures designed to transform sequences from one domain into sequences in another domain, typically used in applications such as machine translation, speech recognition, and text summarization. These models generally consist of an encoder that processes the input sequence and a decoder that generates the output sequence, facilitating the learning of complex

  & & & & & & & & & & & & \\
**Camargo _et al._ & 2021 & 22 & 11 & 10 mm & 4 & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\
**Feldotto _et al._ & 2022 & 5 & 7 & 10 min & 4 & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\
**KIMHu** & 2023 & 20 & 4 & 10 h & 3 & ✓ & ✓ & ✓ & ✓ & ✓ & \(\) \\
**MuscleMap** & 2023 & N/A & 20a & \(\)25 hb & 135 & ✓ & ✓ & ✓ & ✗ & ✓ & ✗ \\
**MiA** & 2023 & 10 & 8 & 12.5 h & 15 & ✓ & ✓ & ✗ & ✗ & ✓ & ✗ \\
**MinT (ours)** & 2024 & 227 & 402a & 10 h & 187 & ✓d & ✓d & ✓d & ✓d & ✓d & ✓ \\  

* Clip-wise binary labels. \({}^{}\) Coarse estimation based on 15,004 clips of 3-9s. \({}^{}\) Muscle strands, some muscles represented by multiple strands. \({}^{}\) Simulated data. \({}^{}\) From 

Table 1: Comparison between recent muscle activation datasets and _Muscles in Time_.

sequence mappings through recurrent neural networks (RNNs) [45; 53; 57; 33] or transformer-based architectures [18; 32]. Chan _et al_.  proposed Imputer method by using imputation and dynamic programming to achieve sequence modelling. Colombo _et al_.  used guiding attention for sequence-to-sequence modelling for dialogue activities prediction. Rae _et al_.  proposed compressed transformer architecture for long-range sequence modelling. Foo _et al_.  proposed a unified pose sequence modelling method for human behavior understanding.

## 3 The Muscles In Time dataset

To develop the _Muscles in Time (MinT)_ framework, we harnessed the comprehensive AMASS dataset, which consolidates various marker-based motion capture (mocap) sequences into a uniform representation using the MoSh++ method, resulting in Skinned Multi-Person Linear Model (SMPL) parametric representations for body pose and shape. AMASS amalgamates mocap data from multiple sources, including the KIT Whole-Body Human Motion Database , BMLrub, and BMLmovi , encompassing over 11,000 motion captures from more than 300 subjects. This extensive collection enables the analysis of a broad array of human movements, providing a rich basis for studying diverse motion patterns.

The SMPL model serves as a pivotal link, translating mocap data from AMASS into mesh representations which we use to transfer the data into a format compatible with the OpenSim  platform. OpenSim is instrumental in constructing intricate biomechanical models that simulate the musculoskeletal system's physical and mechanical properties, allowing for an in-depth analysis of human motion. These models are intricate, requiring precise definitions of joints, masses, inertia, and muscle parameters, such as maximum isometric force, which act as the force-generating actuators.

In this work, we abstain from developing new biomechanical models due to the complexity and expertise required. Instead, we utilize established, pre-validated models, specifically the lower body model by Lai _et al_.  and the thoracolumbar region body model by Bruno _et al_. , see Figure 2. These models simulate muscle activations for an extensive network of individual muscle strands across various muscle groups, providing a comprehensive simulation of human musculature. A detailed list of these muscle groups and their function in the human body is provided in the Appendix.

Tailoring body model parameters to an individual's anatomical properties results in similar difficulties as with the creation of new body models, therefore parameters are commonly used as specified in the validated original models [40; 3], in the OpenSim community. We follow this approach, providing simulation results for standard models rather than subject-specific human bodies.

To integrate human motion data from AMASS with OpenSim, we map virtual mocap markers to the SMPL-H body mesh's surface vertices, following the method proposed by Bittner _et al_. . This results in a selection of 67 strategically placed vertices that represent marker positions on the body mesh, visualized on the left of Figure 2. We deliberately exclude soft tissue dynamics from the SMPL-H mesh generation to maintain consistent marker positions during motion.

Figure 2: The AMASS body model with specific indices mapped onto the OpenSim lower body model by Lai _et al_.  (middle) and model of the thoracolumbar region by Bruno _et al_.  (right). Best viewed by zooming in.

Despite OpenSim's automatic scaling capabilities, manual adjustments of marker positions are sometimes necessary to reconcile differences between simulated and real-world data. These adjustments are made on a subject-specific basis, rendering our pipeline semi-automatic. The manually adjusted marker positions are documented and shared to ensure the reproducibility of our simulations.

AMASS lacks data on external ground reaction forces or contact forces, which are crucial for realistic motion simulation. To address this, we integrate the OpenSimAD  implementation used in the OpenCap  project, which calculates ground reaction forces based on kinematic data and the musculoskeletal model. We employ a tailored parameter setup to optimize the trajectory problem, balancing computational load and accuracy.

Kinematic data is analyzed using OpenSim's _Inverse Kinematics_ method. Muscle activations for the lower body are derived from a trajectory optimization problem described in . The estimated ground reaction forces from this problem serve as inputs for the _Static Optimization_ method, which calculates muscle activations for the thoracolumbar region.

Due to the computational demands of the trajectory optimization problem, we process the data in segments, ensuring manageable computation times without compromising the continuity of the motion capture sequences. We implement overlapping buffers to mitigate inaccuracies during segment processing, discarding data that fails to meet our stringent error tolerance criteria to maintain a high standard of data quality. Further details on implementation and design decisions of our simulation process are presented in the Appendix.

The Muscles in Time (MinT) dataset represents a significant contribution to the field of biomechanical and computer vision simulation. By integrating and refining existing methodologies, we present a robust pipeline that facilitates the accurate simulation of human muscles in motion by combining established biomechanical models with high quality mocap data. To ensure reproducibility, we will release all relevant data and details of our simulation process to the scientific community.

### Dataset Composition

Due to missing information on external forces based on object interactions, inaccurate motion capture recordings or non-converging simulations, the _MinT_ dataset covers a subset of its originating datasets in AMASS and does not follow their respective dataset statistics.

**Anthropometrics** While the motion capture recordings in AMASS provide gender labels, information about subjects height and weight is approximated from the SMPL body model. Body weight is calculated by volume resulting from average shape parameters, which follows the approach of Bittner _et al_. . The weight is relevant for the calculation of ground reaction forces and the distribution of weight in the model, affecting the muscle activation in different parts of the body.

The Figure 3 shows the distribution of weight, indicating significant diversity. Underweight subjects are slightly underrepresented in the dataset, subjects in the obese range are well represented.

**Composition of Subdatasets** Within AMASS, _MinT_ is limited to the subdatasets EyesJapan, BMLrub, KIT, BMLmovi, and TotalCapture. Figure 9 in the appendix shows the ratio of the originating subdatasets in our final simulation results as well as the average sequence length within these subdatasets. The short sequences in BMLmovi typically depict single activities, while the longer

Figure 3: Approximated weight and height distribution of the analysed subjects in the MinT dataset.

ones for example in JapanEyes capture a more diverse range of motions within a single sequence. Since we compute activation information for shorter segments and rejoin them afterwards, longer sequences are more prone to gaps in the analysis due to individually failing segment computations.

**Motion Diversity** Figure 4 displays the frequencies of grouped activities on a logarithmic scale. The action labels are based on the BABEL dataset, a large annotation dataset which is coupled with AMASS. Most interesting are dynamic actions, since expected muscle activations for simple dynamic actions are well documented and we present a short qualitative analysis based on such actions in Section 3.2.

### Data Analysis, Validation, and Visualization

In Figure 5 (left) we explore the interrelation between different activities by investigating our simulated muscle activation time-series. To this end, we extract features from the temporal muscle activation sequences using tsfresh , a commonly used framework in time series analysis that extracts a feature vector based on time series characteristics such as mean, skewness, standard deviation _etc_. We chose distinct and descriptive groups of activities from the BMLmovi subset such as jumping, kicking, stepping and walking, the resulting features were normalized and clustered using FINCH  and visualized with h-NNE . It can be observed, that activities do not only cluster together based on variations within the same category (e.g., different types of jumps, including jumping jacks), but also align closely across different categories, when they share similar motion patterns (e.g. sideways movements). This underlines the descriptive information contained in our simulated muscle activation sequences for characterizing activities.

## 4 Motion to Muscle Activation Estimation Benchmark

While OpenSim provides a means for simulating muscle activations, it is both highly compute intensive as well as sensitive regarding hyper parameters as described in Section 6. These properties limit it to be used by experts in an offline manner and prevent usage in everyday applications. In this section we explore the usage of MinT as a training dataset for the estimation of muscle activation based on pose motion. Such networks provide muscle activation estimation in an instant and can easily be deployed for various downstream tasks.

Given pose motion sequences, we use the preprocessing step defined by  which adjusts skeletal structure to a uniform format and normalizes positions and enriches the resulting data points with additional features. This procedure maps each input to a \(263\)-dim descriptor, resulting in samples of the form \(x=[x_{1},...,x_{T}]\), \(x_{t}^{263}\). For training our models we segment the resulting data into clips of 1.4 second sampled at 20 frames per second, resulting in \(T=28\) input frames. Given a network \(f_{}:^{T d}^{T m}\) we predict \(f(x)=y\) with \(y=[y_{1},...,y_{T}]\), \(m=402\) being the

Figure 4: Prevalence of different motions in the MinT dataset.

number of individual muscle strain activations simulated in our dataset, consisting of 80 lower body muscle strains from  and 322 muscle strains for the upper thoracolumbar region body model . Evaluation is performed by calculating Root Mean Squared Error (RMSE), Pearson Correlation Coefficient (PCC), and Symmetric Mean Absolute Percentage Error (SMAPE). RMSE is commonly used but highly susceptible to data scaling, resulting in significantly lower error values for downscaled data. In practice, EMG signals vary strongly between subjects, scaling of signals is therefore a common preprocessing step. PCC is a good indicator for muscle activation series similarity, since it is scale and offset invariant. SMAPE allows for considering fixed offsets as error while being less sensitive to scaling in comparison to RMSE. PCC and SMAPE are calculated for each muscle strain individually and averaged. For our benchmark we use the train, val and test splits defined by the BABEL dataset . Evaluation results are reported separately for muscles of the upper and lower body model.

## 5 Experiments

We evaluate five different architectures on MinT. Since we make use of human motion as input for our predictor, we adapted a common architecture for motion-to-motion prediction from  to the task of motion-to-muscle activation prediction by simply exchanging its prediction head. We further evaluate a Long Short-Term Memory (LSTM) , a fully convolutional network (FConv) , a Mamba2 Mixer model  and a simple transformer architecture  with 16 transformer layers, results for the lower and upper body model are listed in Table 2. All models are trained from scratch for 300k iterations with a batch size of 256 unless noted otherwise. More details on the model implementations can be found in the supplementary.

The evaluated transformer architecture showed the best results as compared to the adapted VQ-VAE model, LSTM, FConv and Mamba in all metrics on all evaluated motion types. The results of the experiment also show the importance of reporting PCC and SMAPE, since the differences on RMSE are marginal while PCC shows significant improvements as does SMAPE. We suspect this to be the case, since many muscles in the human body are mostly relatively inactive unless required for specific motions. For a simple analysis of this effect, we calculated the integral for each individual ground truth muscle activation sequence in all our validation set chunks and created 402 color coded histograms that are sorted by median and vertically displayed side by side on the right hand side of Figure 5 (one column in the image is a single muscle activation integral area frequency histogram). A wide range of muscles are rarely activated, resulting in the majority of activation sequences displaying integral areas significantly below 0.1 or 0.05. This property is challenging for RMSE and SMAPE, average RMSE reports a small error, since most activations are close to zero and SMAPE reports a high percentage error, since a deviation from a close to zero value is more likely to result in a high percentage deviation. For similar reasons, the upper body model displays lower RMSE and higher SMAPE, the upper body model contains a larger number of small and rarely activated muscles in contrast to the lower body model.

Figure 5: **Left: Clustering of multiple activities within the BMLmovi dataset by muscle activation features. Right: Column-wise color coded histograms of areas under muscle activation curves for 402 muscle strains, sorted by histogram medians. Log-normalized color map, best displayed in color.**

To provide a more detailed analysis we list the results on the collection of all available muscle strains in the main paper, but list further evaluations on carefully chosen subsets of major motion inducing body muscles in the appendix. We recommend future users of our dataset to consider actively evaluating on either the full range of provided muscle activations or choosing one of these muscle strand subsets depending on their specific application. Please also see the appendix for additional experiments as well as a comparison to the work of .

### Qualitative Results

In Figure 6 we list two examples from our dataset, one displaying the action _kick_, the other displaying the action _jumping jacks_, predictions are calculated with the 8-layer transformer architecture. The figure displays four key muscles essential for lower body locomotion; _biceps femoris long head_ (knee flexion and hip extension), _gluteus maximus_ (hip extension and external rotation), _gluteus medius_ (abduction and medial rotation of the hip), and _rectus femoris_ (hip flexion and knee extension), each for the left and right body half. The kick is clearly executed with the left leg with _rectus femoris_ providing the force for the swing in the second half of the motion and the other muscles of the

   Act &  &  &  &  &  \\   & R\(\) & S\(\) & P\(\) & R\(\) & S\(\) & P\(\) & R\(\) & S\(\) & P\(\) & R\(\) & S\(\) & P\(\) & R\(\) & S\(\) & P\(\) \\  \\ all & 0.058 & 59.7 & 0.40 & 0.052 & 66.0 & 0.49 & 0.052 & 57.8 & 0.48 & 0.051 & 55.4 & 0.49 & **0.048** & **45.1** & **0.54** \\ jump & 0.062 & 66.7 & 0.52 & 0.053 & 68.1 & 0.66 & 0.052 & 62.2 & 0.67 & **0.051** & 60.8 & 0.68 & **0.051** & **52.3** & **0.71** \\ kick & 0.069 & 69.1 & 0.38 & 0.057 & 74.9 & 0.55 & 0.058 & 66.5 & 0.55 & 0.059 & 67.6 & 0.55 & **0.053** & **54.8** & **0.62** \\ stand & 0.056 & 60.0 & 0.42 & 0.049 & 64.4 & 0.51 & 0.050 & 58.2 & 0.51 & 0.049 & 55.1 & 0.52 & **0.046** & **45.0** & **0.58** \\ walk & 0.053 & 57.7 & 0.66 & 0.046 & 61.7 & 0.73 & 0.045 & 53.7 & 0.73 & 0.045 & 50.4 & 0.74 & **0.044** & **42.4** & **0.77** \\ jog & 0.059 & 64.8 & 0.58 & 0.052 & 69.1 & 0.66 & 0.050 & 61.5 & 0.68 & 0.047 & 58.2 & 0.69 & **0.046** & **51.1** & **0.71** \\ dance & 0.070 & 71.4 & 0.40 & 0.064 & 76.0 & 0.59 & 0.063 & 71.5 & 0.57 & 0.063 & 70.2 & 0.57 & **0.057** & **58.5** & **0.65** \\  \\ all & 0.041 & 115.3 & 0.32 & 0.034 & 114.8 & 0.47 & 0.035 & 111.1 & 0.48 & 0.034 & 112.2 & 0.50 & **0.033** & **107.7** & **0.55** \\ jump & 0.064 & 118.1 & 0.38 & **0.052** & 119.6 & 0.54 & 0.054 & 115.4 & 0.56 & 0.053 & 117.2 & 0.58 & **0.052** & **112.7** & **0.63** \\ kick & 0.058 & 122.2 & 0.35 & 0.048 & 121.5 & 0.55 & 0.048 & 118.1 & 0.57 & 0.048 & 119.4 & 0.58 & **0.044** & **114.8** & **0.65** \\ stand & 0.039 & 117.6 & 0.34 & 0.031 & 118.2 & 0.48 & 0.031 & 114.2 & 0.49 & 0.030 & 114.9 & 0.51 & **0.028** & **110.5** & **0.55** \\ walk & 0.028 & 110.2 & 0.43 & 0.021 & 109.8 & 0.55 & 0.022 & 105.6 & 0.57 & 0.020 & 106.8 & 0.59 & **0.019** & **102.6** & **0.63** \\ jog & 0.040 & 117.1 & 0.52 & 0.034 & 118.5 & 0.64 & 0.032 & 113.9 & 0.66 & 0.031 & 115.4 & 0.66 & **0.029** & **110.8** & **0.71** \\ dance & 0.046 & 127.3 & 0.29 & 0.041 & 129.5 & 0.48 & 0.044 & 126.7 & 0.48 & 0.039 & 128.2 & 0.49 & **0.036** & **121.8** & **0.59** \\   

* R: RSME S: SMAPE P: PCC

Table 2: Human motion-to-muscle activation prediction results for the lower- and upper body model.

Figure 6: Example lower body muscle activations (split in left and right muscle strands) for the actions _kick_ and _jumping jacks_. It is clearly visible that the kick is performed with the left leg. During _jumping jacks_, _gluteus medius_ and _rectus femoris_ are activated alternatingly for both legs.

left leg preparing it in the first half. During _jumping jacks, gluteus medius_ and _rectus femoris_ are activated alternatingly for both legs. Predicted muscle activations closely follow the ground truth from our dataset, with slight underestimation at the activation peaks. Similar estimation quality can be observed across the test set and we refer the reader to the appendix where we provide a larger number of randomly selected results for qualitative analysis.

## 6 Discussion

We believe that enhancing models through detailed muscle activation data aligned with human motion is a worthwhile direction to explore in the future, which is now made possible by the presented _MinT_ dataset. The dataset offers a large amount of intricately simulated data, based on real human motions, and utilizing bio-mechanically validated musculoskeletal models. By showing that neural models can learn to connect motion input to muscle activation sequences, we broaden the pathway towards models which understand the nuanced interplay between motion and muscles.

**Societal Impact** While the dataset has a good balance in terms of gender distribution, ethnicity is not distributed equally, and some body-weight types are less represented, impacting the dataset diversity.

**Limitations**_MinT_ is a simulation dataset, and despite careful design of our pipeline and rigorous data analysis, a synthetic-to-real domain gap remains inevitable. Researchers should be mindful of these limitations and consider their potential impact on real-world applications. Any models or analysis based on _MinT_ require appropriate validation, ideally with real-world experiments.

Our simulations are a computationally intensive process. Given the potential for non-convergence in complex movement data, we imposed an iteration limit, discarding samples which do not meet a predefined error tolerance within this range. This potentially creates a category distribution shift in comparison to AMASS, since some motion categories might generally be harder to simulate.

Furthermore, the dataset is mostly restricted to motion types limited to foot-ground contact alone; motions with environment contact by other body parts or interactions with external objects were mostly excluded due to missing information about such reaction forces. We included certain object-related motions, such as lifting and throwing, as these motions are especially valuable for examining back muscle activation. Since we miss information about object mass, we assume interaction with very small, lightweight objects of negligible weight in these cases.

More extensive descriptions of these design decisions and preprocessing steps are provided in the appendix, including details on runtime distribution and error handling, to offer transparency for researchers seeking to adapt or expand upon our approach.

## 7 Conclusion

The quest to analyze human motion necessitates a critical component that has been notably absent: a comprehensive biomechanical dataset. Our contribution, the Muscles in Time (MinT) dataset, addresses this gap by providing an unprecedented collection of synthetic muscle activation data. This dataset encompasses \(402\) distinct simulated muscle strains, all derived from authentic human movements, thus offering a vital resource for human motion research. Our methodology entails a scalable pipeline that utilizes cutting-edge musculoskeletal models to derive muscle activations from recorded human motion sequences. The culmination of this process is the MinT dataset, which also contains 9.8 hours of time series data representing muscle activations. We demonstrate that neural networks can effectively utilize this muscle activation data to discern patterns linking motion to muscle activation. This represents a significant stride towards a deeper comprehension of human motion from a biomechanical standpoint. The MinT dataset enables the research community in exploration of human motion and muscular dynamics through a data-centric approach. Our work not only enriches the field of biomechanical studies but also paves the way for future advancements in understanding the complex interplay of muscles in human movement.