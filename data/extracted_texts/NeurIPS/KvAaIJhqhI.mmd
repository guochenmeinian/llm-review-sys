# Style Adaptation and Uncertainty Estimation for Multi-Source Blended-Target Domain Adaptation

Yuwu Lu, Haoyu Huang, and Xue Hu

School of Artificial Intelligence, South China Normal University

{luyuwu2008, hyhuang99, hx1430940232}@163.com

corresponding author

###### Abstract

Blended-target domain adaptation (BTDA), which implicitly mixes multiple sub-target domains into a fine domain, has attracted more attention in recent years. Most previously developed BTDA approaches focus on utilizing a single source domain, which makes it difficult to obtain sufficient feature information for learning domain-invariant representations. Furthermore, different feature distributions derived from different domains may increase the uncertainty of models. To overcome these issues, we propose a style adaptation and uncertainty estimation (SAUE) approach for multi-source blended-target domain adaptation (MBDA). Specifically, we exploit the extra knowledge acquired from the blended-target domain, where a similarity factor is adopted to select more useful target style information for augmenting the source features. Then, to mitigate the negative impact of the domain-specific attributes, we devise a function to estimate and mitigate uncertainty in category prediction. Finally, we construct a simple and lightweight adversarial learning strategy for MBDA, effectively aligning multi-source and blended-target domains without the requirements of domain labels of the target domains. Extensive experiments conducted on several challenging DA benchmarks, including the ImageCLEF-DA, Office-Home, VisDA 2017, and DomainNet datasets, demonstrate the superiority of our method over the state-of-the-art (SOTA) approaches.

## 1 Introduction

Domain adaptation (DA), whose objective is to transfer knowledge from one or more well-labeled source domains to a non-labeled target domain, has been studied in recent years [1; 2; 3; 4; 5; 6], including object classification [1; 2], semantic segmentation [3; 4], and object detection . However, most DA approaches are based on a setting that has single source domain and single target domain [1; 2]. In the real world, unlabeled target domains are usually drawn from different distributions. Therefore, most of the existing single target-based DA approaches may not be the best answer to address domain shifts in reality.

Fortunately, an increasing number of researchers have focused on the above-mentioned issues, and multi-target domain adaptation (MTDA) [7; 8; 9] has been studied. MTDA aims to learn a model that can simultaneously utilize information from single source domain and multiple target domains and then perform well in multiple target domains. For instance, HGAN  adopts a heterogeneous graph attention network to explore the relations among multiple target domain features. In , multiple expert models employed the corresponding source-target domain pair-groups and were then aligned by a student model. Although the existing MTDA approaches have made certain progress, the standard MTDA is still facing challenges because massive amounts of unlabeled data drawn from different distributions are commonly used in real-world settings. It is time-consuming and expensive to divide massive data into multiple corresponding distributions (target domains). For example, forencrypted data stored in a cloud server, due to privacy protection, models cannot directly know the origins of these data (domain labels), which are drawn from different distributions and are blended into a large target domain. Based on the above-mentioned case, blended-target DA (BTDA), which is a more beneficial scenario in real-world settings, has been proposed .

Current BTDA approaches [12; 13] are mainly based on three points: 1) the adaptation process contains single source domain and multiple target domains. 2) During the adaptation process, the model cannot access both the domain labels and category labels of the target domains. 3) In blended-target domain, the category labels of each sub-target domain may not follow the same distribution. Therefore, simply utilizing MTDA or SSDA (single source domain adaptation) methods to handle the BTDA task may lead to negative transfer because the domain labels of target domains are unseen, and the category feature space is a hybrid space. As the first deep learning work focused on the BTDA scenario, AMEAN  employs two adversarial learning steps and utilizes meta-learning to minimize the domain gap between the source domain and the blended-target domain. However, insufficient information obtained from single source domain makes models difficult to align the distributions of multiple target domains. Moreover, the presence of different distributions in the blended-target domain may aggravate negative transfer. Recently, multi-source domain adaptation (MSDA) [14; 15; 16] has produced impressive results. MSDA approaches can utilize more feature information from extra source domains to learn domain-invariant representations, effectively solving negative transfer. However, as far as we know, no related works have been proposed to utilize more feature information from multiple source domains for BTDA.

In this paper, to further exploit feature information from multiple domains, we pay attention to the BTDA in the case of multiple source domains, _i.e.,_ Multi-Source Blended-Target Domain Adaptation (MBDA). The comparisons of different DA settings are illustrated in Table 1. At the same time, a style adaptation and uncertainty estimation (SAUE) method is proposed for MBDA. Different from previous works, we utilize the style information of the blended-target domain to enhance source domain features, thus building a better representation space. Specifically, we first simultaneously extract the source and target style information and then calculate the similarity factors between the source and target style information. The similarity factors are served as the weighted matrix during the feature augmentation process. Based on style adaptation, we further analyze the uncertainty in the classification model and adopt a loss function to eliminate the uncertainty introduced by the multi-source domains. In addition, as the domain labels of the blended-target domain are unavailable in MBDA, we construct an adversarial learning scheme for MBDA without the requirement of domain labels of the target domains.

The main contributions of this work are summarized as follows:

* An approach SAUE is proposed to explore information from multiple source domains for BTDA. As far as we know, SAUE is the first work that was proposed for MBDA, which can utilize more feature information from extra source domains to learn domain-invariant representations.
* To further exploit the style information in the blended-target domain, we propose a similarity-based style adaptation strategy for MBDA, which selects target styles to enhance the source representation space.
* We propose an uncertainty estimation technique to enhance the robustness of our method, which exploits valuable knowledge from multiple source domains. In addition, we construct a specific adversarial learning strategy for MBDA, which aligns domains without the requirement of domain labels.

   Settings & Source domain number & Target domain number & Domain labels \\  UDA/SSDA & single & single & ✓ \\ MSDA & multiple & single & ✓ \\ MTDA & single & multiple & ✓ \\ BTDA & single & multiple & \(\) \\ MMDA & multiple & multiple & ✓ \\ MBDA & multiple & multiple & \(\) \\   

Table 1: Comparison about different settings of DA.

Related Works

**Single-source and Single-target DA (SSDA).** The objective of SSDA is to learn domain-invariant representations through the relations between the source and target domains. Based on this objective, researchers have carried out widespread researches and achieved certain progress [17; 18; 19; 20; 21; 22; 23]. The current SSDA methods are mainly divided into two types: distance metric-based approaches [17; 18; 19] and adversarial learning-based approaches [20; 21; 22; 23]. Distance metric-based methods learn domain-invariant representations through feature discrepancy matching by using a distance metric function. DAN  utilizes multi-kernel maximum mean discrepancy (MMD) to measure the discrepancy between the source and target domains and then minimizes the discrepancy to learn domain-invariant representations. CAF  utilizes sliced Wasserstein distance (SWD)  to measure domain discrepancy. Motivated by the GANs [25; 26], adversarial learning-based SSDA methods have also been widely researched [20; 21; 22; 23]. Adversarial learning methods perform min-max two-player games between the category classifier and domain discriminator to learn domain-invariant representations. DANN , which was the earliest work in adversarial learning-based SSDA, successfully achieves domain-level adaptation via a gradient reverse layer. Different from DANN, SCDA  and DALN  remove the discriminator from their networks and model the adversarial relation between the feature extractor and category classifier. Although the above-mentioned approaches have achieved great success, due to the limitations of single source domain features and single target domain features, current SSDA methods still face some challenges in real applications.

**Multiple Domains DA.** The motivation of multiple domains DA is to explore more useful knowledge from multiple domains for the tasks. Many researchers have focused on multiple-domain DA and proposed many excellent methods [13; 14; 15; 8], including MSDA [14; 15; 27; 28], MTDA , BTDA [13; 12], and MMDA (multi-source and multi-target DA) . M3SDA  utilizes moment matching to align domain distribution. DCA  further extracts the multiview features from multiple source domains and then utilizes multiple classifiers and pseudo-label learning strategy to align distributions. Meanwhile, in MTDA, CGCT  utilizes feature aggregation and curriculum learning to learn the pseudo-labels of multiple target domains. AMDA  constructs multiple domain discriminators and utilizes attention mechanism to address the MMDA issue.

Recently, a more realistic DA scenario, BTDA, has been studied [12; 13]. For example, MCDA  utilizes the mutual condition to learn domain-invariant representations, which has achieved great progress in BTDA. However, single source domain in BTDA cannot provide sufficient feature information for aligning the source and blended-target domains. Furthermore, the unseen domain labels of the target domains also aggravate the challenges. Therefore, we consider multiple source domains in BTDA and utilize the style information of the target domains to optimize the representations of source features and minimize the model uncertainty, thereby obtaining a better transfer.

## 3 Method

### Preliminary

In MBDA, we have \(M\) labeled source domains \(=\{_{m}\}_{m=1}^{M}\) that are drawn from distributions \(\{P_{_{m}}\}_{m=1}^{M}\). \(_{m}=\{x_{i}^{_{m}},y_{i}^{_{m}}\}_{i=1}^{| _{m}|}\), where \(x_{i}^{_{m}}^{d}\) denotes the \(i\)-th source sample from the \(m\)-th source domain and \(y_{i}^{_{m}}\) is the corresponding category label, and \(d\) denotes the number of dimensions. Meanwhile, we have an unlabeled blended-target domain \(\) that consists of \(N\) sub-target domains \(\{_{n}\}_{n=1}^{N}\), and \(=\{x_{j}^{T}\}_{j=1}^{||}\). The distributions of sub-target domains are \(\{P_{_{n}}\}_{n=1}^{N}\). Therefore, the distribution of blended-target domain \(P_{}\) is the mixture of sub-target domains, _i.e._, \(P_{}=_{n=1}^{N}_{n}P_{_{n}}\), where \(\) and \(_{n=1}^{N}_{n}=1\). Each of the source and target domains shares the same category space. The objective of MBDA is to train a model that utilizes multiple source domain features and performs well on the blended-target domain. Different from MTDA, the target domain labels are unseen in MBDA. In addition, the analysis in  demonstrated that directly utilizing DA methods to address BTDA transfer tasks may cause increased uncertainty and negative transfer. Therefore, we utilize the style information of the blended-target domain to augment source features and minimize the uncertainty of the model. Furthermore, the adversarial learning strategy in our method without the requirement of domain labels of the sub-target domains is suitable for MBDA setting. Figure 1 illustrates the overall architecture of SAUE.

### Style Adaptation from Blended-Target Domain

Since the principal parts of features from different domains remain domain-invariant, the domain-specific parts, which mainly contain style information, are the main discrepancies between different domains. In addition, the target feature distributions in MBDA are confused, which may cause model degradation. Therefore, we try to utilize the style information of blended-target domain to augment source features, which brings source features closer to target features. Previous work  has demonstrated that low-level features of deep neural networks (DNNs) mainly represent style information. Some works [13; 30] have utilized the channel-wise mean and variance of the low-level features to represent the style information of input samples. Thus, for sample \(x_{i}^{_{m}}\) which from the \(m\)-th source domain, let its low-level feature be \(z_{i}^{_{m}}^{d H_{_{m}} W_{ _{m}}}\), where \(d\) denotes the channel and \(H_{_{m}}\), \(W_{_{m}}\) denote the height and width of sample \(x_{i}^{_{m}}\). The channel-wise mean and variance of the low-level feature \(z_{i}^{_{m}}\) can be defined as follows:

\[_{i}^{_{m}}=_{m}}W_{_{m}}} _{h=1}^{H_{_{m}}}_{w=1}^{W_{_{m}}}z_{i}^{ _{m}},\ _{i}^{_{m}}=_{m}}W_{ _{m}}}_{h=1}^{H_{_{m}}}_{w=1}^{W_{_{m }}}(z_{i}^{_{m}}-_{i}^{_{m}})^{2}}.\] (1)

Low-level features mainly represent style information, but different samples contain specific pieces of style information. Therefore, we adopt feature normalization technique to standardize the feature \(z_{i}^{_{m}}\), and the normalized feature \(_{i}^{_{m}}\) is defined as:

\[_{i}^{_{m}}=^{_{m}}-_{i}^{ _{m}}}{_{i}^{_{m}}+},\] (2)

where \(\) is a small value used to avoid division by zero.

Then, the target features will be utilized to augment the normalized source features. Previous work  randomly augmented source features through target style information, which yielded limited performance. In our work, we select the target style information according to a weight factor. Specifically, we leverage the Wasserstein Distance  to measure the style distribution discrepancy \(w_{i}^{_{m}}\) between the source low-level feature \(z_{i}^{_{m}}\) and the target low-level feature \(z_{j}^{}\) as follows:

\[w_{i}^{_{m}}=\|_{i}^{_{m}}-_{j}^{}\|+( _{i}^{_{m}})^{2}+(_{j}^{})^{2}-2_{i} ^{_{m}}_{j}^{}.\] (3)

Then, we utilize \(w_{i}^{_{m}}\) to calculate the weight factor as follows:

\[_{i}^{_{m}}=^{_{m}}))}{ _{m=1}^{M}_{i=1}^{|_{m}|}(1/(1+w_{i}^{_{m}}))}.\] (4)

Figure 1: Overview of the proposed SAUE approach. First, the style information of the blended-target domain is utilized to augment the source features through the similarity factors. Second, we calculate the uncertainty of the model and optimize prediction uncertainty via the Dirichlet distribution. Finally, the adversarial learning strategy without discriminator effectively guides the SAUE process to adapt the blended-target domain without the requirement of domain labels of sub-target domains.

To ensure that the sum in Eq. (4) equals to 1, we utilize softmax operation to normalize each \(_{i}^{S_{m}}\). Then, we can obtain the weighted target style as follows:

\[_{i}=_{m=1}^{M}_{i=1}^{|_{m}|}_{i}^{_{m}} _{j}^{},\;_{i}=_{m=1}^{M}_{i=1}^{|_{m}|} _{i}^{_{m}}_{j}^{}.\] (5)

Finally, the low-level source feature augmented by the blended-target style information can be calculated as follows:

\[z_{i}^{_{m}}=_{i}_{i}^{_{m}}+ _{i}.\] (6)

Different from previously developed image augmentation method , our method directly utilizes target information with weight factor to augment source features instead of generating specific images. The low-level feature \(z_{i}^{_{m}}\) augmented by diverse target styles further mitigates the impact of the domain-specific attributes.

### Uncertainty Estimation and Elimination

Although multiple source domains provide additional supervised information for adaptation compared to a single source domain, they also introduce more domain-specific attributes. This can cause model degradation, especially when some source domains are significantly dissimilar to the blended-target domain due to the abundance of domain-specific attributes. Evidential model learning (EDL)  is an interpretable approach that fuses knowledge from multiple domains using the Dempster-Shafer Rule [33; 34], which is more beneficial to MBDA scenario. Thus, we utilize the Dirichlet-based evidential model  to estimate the uncertainty of our model during the training process. Specifically, for a sample \(x_{i}\), we have the predictions \(p_{i}=C(G(x_{i}))=[p_{i1},p_{i2},,p_{iK}]\), where \(C\) and \(G\) denote the classifier and feature generator, respectively. The probability density function of \(p_{i}\) is defined as follows:

\[D(p_{i}|_{i})=\{)}_{k= 1}^{K}p_{k}^{_{k}-1}& p U_{K}\\ 0&.,\] (7)

where \(U_{k}=\{p_{i}|_{k=1}^{K}p_{ik}=10 p_{i1},...,p_{iK} 1\}\) is the \(K\)-dimensional unit simplex and \(_{i}\) is the parameter of the Dirichlet distribution. \(B(_{i})=^{K}_{ik})}{_{k=1}^{K}( _{ik})}\) is the \(K\)-dimensional multinomial beta function, and \(()\) denotes the gamma function.

Previous work  has demonstrated that DNNs can generate opinions for classification tasks as Dirichlet distributions. Therefore, given sample \(x_{i}\), for prediction of class \(c\) that generated by DNNs, the Dirichlet distributions connected with DNNs can be defined as follows:

\[P(y=c|x_{i})=}{_{k=1}^{K}_{ik}}=(G(x_{i} ))}{_{k=1}^{K}C_{k}(G(x_{i}))}=[D(p_{ic}|_{i})].\] (8)

The derivation of Eq. (8) is provided in Appendix B.

In this work, for source sample \(x_{i}^{_{m}}\), we utilize the prediction of the category classifier as the evidence vector, and the parameters of the corresponding Dirichlet distribution can be defined as \(_{i}^{_{m}}=C(G(x_{i}^{_{m}}))+1\). To eliminate the uncertainty, we force the total evidence to zero when the model generates an incorrect prediction for the source sample, and the corresponding uniform Dirichlet distribution is \(D(p_{i}^{_{m}}| 1,,1)\). For implementation, we utilize the Kullback-Leibler (KL) divergence to reduce the impact of incorrectly classified source samples in our loss function, which is defined as follows:

\[_{unc}(x^{_{m}})=_{i=1}^{|_{m}|}KL[D(p_{i }^{_{m}}|_{i}^{_{m}})\|D(p_{i}^{_ {m}}| 1,,1)],\] (9)

where \(_{i}^{_{m}}=y_{i}^{_{m}}+(1-y_{i}^{_{m}})_{i}^{_{m}}\) denotes the Dirichlet parameter used to remove the true evidence from prediction \(_{i}^{_{m}}\). Specifically, the KL divergence is:

\[KL[D(p_{i}^{_{m}}|_{i}^{_{m}}) \|D(p_{i}^{_{m}}| 1,,1)]\] (10) \[=[^{K}_{i}^{ _{m}})}{(K)_{k=1}^{K}(_{ik})} ]+_{k=1}^{K}(_{ik}-1)[(_{ik})- (_{j=1}^{K}_{ij})],\]

where \(()\) and \(()\) denotes the gamma function and digamma function, respectively.

```
0: Source domains \(\{_{m}\}_{m=1}^{M}\) and the corresponding data \(\{x_{i}^{_{m}},y_{i}^{_{m}}\}_{i}^{|_{m}|}\), blended-target domain data \(\{x_{j}^{}\}\), hyper-parameters \(_{e}\) and \(_{d}\), maximum iteration \(I\), and mini-batch size \(B\).
0: Optimal feature generator \(G\) and category classifier \(C\).
1:for\(i\) in 1:1do
2: Randomly sample a mini-batch of \(B\) source samples and target samples.
3: Augment the source features by utilizing style adaptation, _i.e._, Eq. (6).
4: Minimize the parameters of the feature generator and category classifier by \(_{cls}\).
5: Optimize the uncertainty of model through \(_{unc}\).
6: Perform the min-max game between feature generator and classifier with \(_{d}\): \[_{G}_{C}_{d}(x^{_{m}},x^{}).\]

**Algorithm 1** SAUE for MBDA

### Domain Adversarial Alignment without Domain Labels

Existing works [20; 21; 22; 8] have demonstrated that adversarial learning strategy is beneficial in DA. However, most of the adversarial learning strategies in DA [20; 21] usually request the domain labels of the source and target domains to train their discriminators, which cannot satisfy MBDA. Inspired by the intra- and inter-class correlation , we design an adversarial learning strategy for MBDA without discriminator and domain label requirements. Specifically, the category classifier is reused to discriminate which domain a feature originates from, with the guidance of the Nuclear norm \(\|\|_{*}\). We first measure the distribution difference between the source and blended-target domains through the nuclear-norm 1-Wasserstein discrepancy (NWD)  and then utilize a gradient reverse layer (GRL)  to maximize the discriminative loss of the classifier. Simultaneously, we minimize the feature generator to play the min-max game with the classifier through the NWD. First, the NWD loss can be defined as:

\[_{d}(x^{_{m}},x^{})=_{m}| }_{i=1}^{|_{m}|}\|C(G(x_{i}^{_{m}}))\|_{ *}-|}_{j=1}^{||}\|C(G(x_{j}^{ }))\|_{*}.\] (11)

Then, the adversarial learning strategy between feature generator and classifier is defined as follows:

\[_{G}_{C}_{d}(x^{_{m}},x^{}).\] (12)

### Model Optimization and Theoretical Analysis

**Overall Objective.** The overall loss function that optimizes SAUE for MBDA is defined as:

\[_{G,C}\{_{cls}(x^{_{m}},x^{})+ _{e}_{unc}(x^{_{m}})+_{d}_{C} _{d}(x^{_{m}},x^{})\},\] (13)

where \(_{e}=(1,e/_{e}^{})\) is the annealing coefficient, which prevents \(_{unc}\) from over-penalizing the neural network to a uniform distribution in the early training epochs, and \(e\) is the current number of epochs and \(_{e}^{}=40\). \(_{d}\) is a hyper-parameter which is initially set to \(_{d}=1\) as in . \(_{cls}\) is the classification loss, which ensures that the category classifier can correctly classify samples. With the the cross-entropy loss \(_{ce}\), the classification loss \(_{cls}\) is defined as follows:

\[_{cls}(x^{_{m}},y^{_{m}})=_{m=1}^{M}_{m}|}_{i=1}^{|_{m}|}_{ce}(C(G(x_{i }^{_{m}})),y_{i}^{_{m}}).\] (14)

After adversarial training, our model can effectively adapt the blended-target domain without the requirement of domain labels of sub-target domains. The concrete steps of SAUE are shown in Algorithm 1.

**Theoretical Analysis.** Here, we utilize PAC-Bayesian theory  to optimize our classification model with uncertainty estimation and elimination. The full-bound theorem motivated by previous work  is illustrated in Theorem 1 and Lemma 1, and the proofs are provided in Appendix C.

**Theorem 1**. _Suppose we have given the m-th source data distribution \(P_{_{m}}\), a hypothesis set \(\), and a prior distribution \(\) over the hypothesis space \(\). For any \((0,1]\) and \(>0\), with a probability at least \(1-\) over the source samples \(_{m} P_{_{m}}\), for all posteriors \(\), we have:_

\[_{()}[()] _{()}[}_{_{m}}( )]+[KL(\|)++_{ _{m},}(,n)],\] (15)

_where \(_{_{m},}(,n)=_{()}_{_{m} P_{_{m}}}[e^{(( )-(}))}]\)._

**Lemma 1**. _The PAC-Bayes bound, involving constants \(\) and \(n\), as introduced in Theorem 1, is minimized by the Bayesian posterior \(p()\), which represents the distribution over \(\)._

During uncertainty estimation and elimination, just as in Eq. (9), we utilize \(D(p_{i}^{_{m}}|_{i}^{_{m}})\) as the posterior distribution and \(D(p_{i}^{_{m}}|~{}<1,,1>)\) as the prior distribution. Therefore, the upper bound of the classification model can be expressed as:

\[_{m=1}^{M}_{m}|}_{i=1}^{|_{m}|}[ _{cls}+KL(D(p_{i}^{_{m}}|_{i}^{_{m}})\|D(p_{i}^{_{m}}|<1,...,1>)) ].\] (16)

**Generalization Bound.** In this part, we prove why SAUE performs well on the blended-target domain via Lemma 2 and Theorem 2. The proofs and derivations are provided in Appendix D.

**Lemma 2**. _Suppose we have given the probability measures \(_{_{m}},_{}()\) of the \(m\)-th source feature \(f_{_{m}}\) and the blended-target domain feature \(f_{}\), a hypothesis space \(\), and a subspace \(}\). Let \(\) denote a fixed representation space and \(c(f_{_{m}},f_{})\) denote the adaptation cost. For the ideal classifier \(h^{}}\) and any classifier \(h}\) with \(f_{_{m}}_{_{m}}\) and \(f_{}_{}\), we have:_

\[|_{_{m}}(h,h^{})-_{}(h,h^{} )|d_{}(_{_{m}},_{ }),\] (17)

_where \(_{_{m}}\) and \(_{}\) denote the error on the \(m\)-th source domain and the error on the blended-target domain respectively, and \(_{}=_{j=1}^{N}_{_{j}}\). \(d_{}\) denotes the \(\)-distance._

**Theorem 2**.: _Based on Lemma 2, with the error of the ideal joint hypothesis \(^{}=_{_{m}}(h^{})+_{}(h ^{})\) which is a sufficiently small constant, for any \((0,1)\), with probility at least \(1-\), for every \(h\), \(_{}(h)\) is bounded by the following terms:_

\[_{}(h)_{_{m}}(h)+_ {}(_{_{m}},_{})+4 {)+()}{b^{}}}+ ^{},\] (18)

_where \(^{}=_{_{m}}(h^{})+_{}(h ^{})\) is the ideal error for the classifier, which is a sufficiently small constant. \(b^{}\) is the size of unlabeled samples._

Therefore, the final objective of the MBDA classification task is to reduce the joint domain discrepancy term \(_{m=1}^{M}|_{_{m}}(h,h^{})-_{} (h,h^{})|\).

## 4 Experiments

### Datasets and Implementation Details

**Datasets.** Four standard benchmark datasets are used to validate the effectiveness of our proposed method. The **ImageCLEF-DA** contains 2,400 images and is divided into 4 domains: Bing (b), Caltech (c), ImageNet (i), and Pascal (p). Each domain has 12 categories, and every category has 50 images. The **Office-Home** also consists of 4 domains and 15,588 images belonging to 65 categories from four subdomains: Art (Ar), Clipart (Cl), Products (Pr), and Real world (Rw). The **DomainNet** is a large-scale dataset in DA that contains 0.6 million images of 345 categories from 6 domains: Clipart (C), Infograph (I), Painting (P), Quickdraw (Q), Real world (R), and Sketch (S). Following the protocol used in , we select 126 categories and 4 domains (C, P, R, and S) in our experiments. The **VisDA 2017** dataset is a challenging dataset consists of 2 domains (Syn. and Rel.) and 7 categories.

**Implementation Details.** We utilize PyTorch framework  to perform our experiments; the PyTorch version is 1.13.1 and CUDA version is 11.7. We use an ImageNet pre-trained ResNet , replacing the last FC layer with task-specific FC layers. All experiments are run on a single GeForce RTX-4090 GPU, and the batch size of both the source and blended-target domains are set to 32. The optimizer is Stochastic Gradient Descent (SGD) with a momentum parameter of 0.9 and a weight decay of 1e-3. The learning rate is 1e-3 and updated by the LambdaLR  during the training process.

### Comparisons to State-of-the-Art

To evaluate the effectiveness of our proposed method, we conduct extensive experiments and compare our approach with the state-of-the-art (SOTA) methods in terms of DA classification. The comparison methods include SSDA approaches, _i.e.,_ MCD , DAN , TSA , DALN , BIWAA , and SCDA ; MSDA methods, _i.e.,_ MDAN , DCTTN , and DIDA . MTDA/BTDA methods: MTDA-ITA  and MCDA ; and Multi-source Multi-target DA (MMDA), _i.e.,_ AMDA  and HTA . The comparison results are presented in Tables 2-4, in which we select two domains as source domains and combine other two domains to form the blended-target domain. Note that these approaches do not totally match the MBDA setting. Therefore, we utilize the following rule for our comparison. For SSDA setting, one column denotes one SSDA task, such as R\(\)C in Table 2. For MSDA methods that contain more than two source domains, we implement those methods according to their released codes, reset the source domain into two domains, such as R+S\(\)C, and mark them with "*". Similarly, under the MTDA and BTDA settings, we reset the target into two domains and select the highest one in MTDA/BTDA task group that contains the same target domains, such as R\(\) C+P and S\(\) C+P in Table 2. For MMDA setting, two domains are sources, and the other domains are targets, such as R+S\(\)C+P in Table 2. For better comparison, all results in Tables 2-4 are the averages of two target domains.

**Results on the DomainNet** are displayed in Table 2. Our SAUE method achieves SOTA performance in most of the experimental groups and attains the best performance in terms of average accuracy. Compared to the BTDA method MCDA in multi-source setting, our method achieves better performance because the style information of the target domain selected by the weight factor can enhance the source feature representations. Compared to MMDA method AMDA, although AMDA can access the domain labels of the target domains, our method still overpasses AMDA in terms of average classification accuracy (overpasses **7.5**%) and without the requirement of the domain labels of the target domains. Furthermore, both AMDA and our method are adversarial learning methods, and the comparison results further demonstrate the effectiveness of our adversarial learning strategy. These obtained improvements are mainly due to the uncertainty optimization process and the style information derived from target features.

**Results on the Office-Home** are shown in Table 2(a). The experimental results are compared with those of the SOTA methods, illustrating that our proposed method achieves dramatic improvements in most comparison groups and achieves the highest average classification accuracy (**73.7**%). Note that the Rw domain contains a total of 34,856 images, which is far more numerous than the other

Table 2: Accuracy (%) on the DomainNet for MBDA (ResNet-50).

Table 3: Accuracy (%) on the (a) Office-Home and the (b) ImageCLEF-DA for MBDA (ResNet-50).

three domains. Therefore, the adaptation task faces larger domain shifts and extremely unbalanced classes. The proposed method still achieves 2.8% improvements over AMDA and achieves dramatic improvements in the Rw+Pr\(\)Ar+Cl and Rw+Ar\(\)Pr+Cl tasks. These results occur because the proposed method decreases the impact of unbalanced classes by enhancing the feature representations and optimizing the prediction uncertainty.

**Results on the ImageCLEF-DA** are provided in Table 2(b). Compared with the SOTA methods, our proposed method achieves an average accuracy of **84.3%**, outperforming the existing approaches. Note that all four domains in ImageCLEF-DA contain 600 images. Therefore, the experimental results further demonstrate that our proposed method is effective when all the domains contain the same samples and classes.

**Results on the Default Version of DomainNet and VisDA 2017**. To evaluate the effectiveness of SAUE in different numbers of the source and target domains. We perform comparisons on the default version of the DomainNet dataset and the VisDA 2017 dataset, respectively. The default version of the DomainNet dataset consists of 5 domains, leading to the division of transfer tasks for MBDA into two categories: C+P+Q\(\)R+S and R+S\(\)C+P+Q. As shown in Table 4, SAUE outperforms the comparison methods across all transfer tasks, achieving the highest average classification accuracy. These results from large-scale datasets further demonstrate the superiority and flexibility of SAUE.

### Experiment Analysis

**Sensitivity Analysis.** We evaluate the model's performance under different hyperparameter choices. Note that the hyperparameters in our method are the adversarial learning balance parameter \(_{d}\) and annealing parameter \(_{e}\). As shown in Figure 2, we test different parameter groups to analyze the parameter sensitivity of our method, where \(_{d}=\{0.1,0.5,1.0,1.5,2.0\}\) and \(_{e}=\{10,20,40,60,80\}\). The corresponding numerical results of Figure 2 are illustrated in Table 5. In Figure 2, our method is not sensitive to \(_{d}\) and the best parameter choice is \(_{d}=1.0\), but very sensitive to \(_{e}\) (with \(_{e}=40\)

Table 4: Accuracy (%) on the (a) default version of DomainNet dataset and (b) VisDA-2017 dataset (ResNet-101).

Table 5: The detailed numerical results corresponding to the relevant tasks.

Figure 2: The analysis of the SAUE parameters.

working best); if \(_{e}\) too small, the model will suffer from tremendous degradation due to the model is over-penalized by uncertainty loss.

**Ablation Study.** As listed in Table 6, we conduct ablation experiments to demonstrate the effectiveness of the style adaptation module and the loss function of the uncertainty optimization process. We test three experimental groups in the DomainNet dataset, including that: 1) remove the style adaptation (SA) module, 2) remove the uncertainty loss \(_{unc}\), and 3) remove both of the above-mentioned items.

The results illustrate that both style adaptation and prediction uncertainty optimization are useful for MBDA. Furthermore, we explore different style adaptation techniques. We directly change the Wasserstein Distance (WD) to randomly selected style information and report the obtained results in the fourth row of middle part of Table 6. Compared with the random augmentation methods, our proposed method can better select the style information through weight factors, which enhances the feature representations of the source domains and reduces the impact of domain shifts. More experiment analysis is provided in Appendix E.

**Effectiveness of the SA Module with Different Backbones.** We have analyzed the performance of our method using the ResNet-50 and ResNet-101 backbones in the default version of the DomainNet dataset in Table 7. The experimental results show that our method achieves significant performance gains when utilizing powerful backbones (ResNet-101). We compared the performance gains of the style adaptation module with standard backbone (ResNet-50) and powerful backbone (ResNet-101). The results indicate that the performance gains (+2.8% and +2.3%) of the style adaptation module when integrated into the ResNet-50 backbone surpass those (+1.6% and +1.3%) when integrated into the ResNet-101 backbone.

**Effectiveness of the SAUE with ResNet and ViT backbones.** We further evaluate the model's performance using different backbones, as shown in Table 8. When using ViT as the backbone, SAUE outperforms its performance with the ResNet-50 backbone. This performance gain is primarily due to the larger number of tunable parameters in ViT-B/16, demonstrating that our method effectively leverages these additional parameters to exploit transferable knowledge from multiple domains.

## 5 Conclusion

In this paper, we propose a SAUE approach for MBDA, which utilizes information from multiple source domains to adapt a blended-target domain. In particular, the style adaptation process utilizes similarity factors to select target style information to enhance the representations of the source features. The uncertainty estimation procedure utilizes the Dirichlet distribution to estimate the uncertainty of the model and then adopts the KL divergence measure to optimize the prediction uncertainty. The discriminator-free adversarial learning strategy is beneficial for MBDA. Extensive experimental results demonstrate the superior performance of SAUE to that of the competing methods.

  
**Source** & R+S & S+P & P+R & C+S & R+C & C+P & **Avg** \\ 
**Target** & C+P & C+R & C+S & P+R & P+S & R+S & **Avg** \\  w/o SA & 68.4 & 72.1 & 64.2 & 70.0 & 60.8 & 70.1 & 67.6 \\ w/o \(_{unc}\) & 69.7 & 75.0 & 65.8 & 71.2 & 64.8 & 72.6 & 69.9 \\ w/o both & 65.1 & 71.9 & 63.8 & 68.8 & 60.2 & 69.3 & 66.5 \\ w/o WD & 70.2 & 77.0 & 66.3 & 71.6 & 64.1 & 71.5 & 70.1 \\ 
**SAUE** & **70.8** & **76.9** & **67.6** & **71.9** & **65.2** & **73.1** & **70.9** \\   

Table 6: Ablation study of SAUE on the DomainNet.

    &  & C+P+R & C+P+S & C+Q+R & C+Q+S & C+P+S & P+Q+R & P+Q+S & P+R+S & **Avg** \\   & R+S & Q+S & Q+R & P+S & P+R & P+Q & C+S & C+R & C+Q & C+P & **Avg** \\  without SA (ResNet-50) & 51.2 & 28.6 & 36.7 & 49.6 & 52.9 & 30.2 & 51.0 & 57.8 & 30.3 & 51.1 & 43.9 \\ with SA (ResNet-50) & 53.9 & 30.7 & 39.8 & 51.3 & 55.7 & 33.7 & 52.8 & 60.4 & 33.7 & 55.3 & 46.7 (**+2.8**) \\  without SA (ResNet-101) & 56.1 & 33.7 & 41.3 & 53.1 & 57.3 & 35.1 & 54.8 & 61.2 & 36.4 & 56.7 & 48.6 \\ with SA (ResNet-101) & 57.7 & 34.6 & 42.9 & 54.7 & 59.2 & 36.9 & 56.0 & 63.6 & 37.1 & 58.7 & 50.2 (**+1.6**) \\    &  &  &  & P+S & P+R & P+Q & C+S & C+C & C+P & **Avg** \\   & C+P+R & C+P+R & C+P+S & C+P+R & C+P+S & P+R+S & P+R & P+R & P+S & **Avg** \\  without SA (ResNet-50) & 39.5 & 53.2 & 47.3 & 33.2 & 40.1 & 52.4 & 45.8 & 38.2 & 45.3 & 40.5 & 43.5 \\ with SA (ResNet-50) & 41.1 & 55.3 & 49.8 & 35.6 & 42.5 & 54.7 & 48.3 & 39.5 & 47.7 & 43.2 & 45.8 (**+2.3**) \\  without SA (ResNet-101) & 42.1 & 56.5 & 51.6 & 35.2 & 43.8 & 57.0 & 49.4 & 39.9 & 50.7 & 43.1 & 46.9 \\ with SA (ResNet-101) & 43.3 & 57.7 & 53.1 & 37.7 & 44.6 & 57.5 & 50.5 & 41.2 & 51.3 & 45.3 & 48.2 (**+1.3**) \\   

Table 7: Comparison about the SA module on the DomainNet dataset with different backbones.

    &  & C+R+R & P+S & P+R+A & Arx-P & C+A & Arx \\   & Ar+C & Arx+ & Arx+ & Arx+ & C+P & C+R & P+R & **Avg** \\  ResNet-50 & 65.6 & 79.9 & 75.2 & 70.1 & 71.8 & 79.3 & 73.7 \\ ViT-B/16 & 69.2 & 83.1 & 79.1 & 73.6 & 74.5 & 83.7 & 77.2 \\   

Table 8: Comparison about different backbones on the Office-Home dataset.