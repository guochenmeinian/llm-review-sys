# Dream the Impossible:

Outlier Imagination with Diffusion Models

 Xuefeng Du, Yiyou Sun, Xiaojin Zhu, Yixuan Li

Department of Computer Sciences

University of Wisconsin, Madison

{xfdu,suniyyou,jerryzhu,sharonli}@cs.wisc.edu

###### Abstract

Utilizing auxiliary outlier datasets to regularize the machine learning model has demonstrated promise for out-of-distribution (OOD) detection and safe prediction. Due to the labor intensity in data collection and cleaning, automating outlier data generation has been a long-desired alternative. Despite the appeal, generating photo-realistic outliers in the high dimensional pixel space has been an open challenge for the field. To tackle the problem, this paper proposes a new framework Dream-ood, which enables imagining photo-realistic outliers by way of diffusion models, provided with only the in-distribution (ID) data and classes. Specifically, Dream-ood learns a text-conditioned latent space based on ID data, and then samples outliers in the low-likelihood region via the latent, which can be decoded into images by the diffusion model. Different from prior works [1; 2], Dream-ood enables visualizing and understanding the imagined outliers, directly in the pixel space. We conduct comprehensive quantitative and qualitative studies to understand the efficacy of Dream-ood, and show that training with the samples generated by Dream-ood can benefit OOD detection performance. Code is publicly available at https://github.com/deeplearning-wisc/dream-ood.

## 1 Introduction

Out-of-distribution (OOD) detection is critical for deploying machine learning models in the wild, where samples from novel classes can naturally emerge and should be flagged for caution. Concerningly, modern neural networks are shown to produce overconfident and therefore untrustworthy predictions for unknown OOD inputs . To mitigate the issue, recent works have explored training with an auxiliary outlier dataset, where the model is regularized to learn a more conservative decision boundary around in-distribution (ID) data [4; 5; 6; 7]. These methods have demonstrated encouraging OOD detection performance over the counterparts without auxiliary data.

Despite the promise, preparing auxiliary data can be labor-intensive and inflexible, and necessitates careful human intervention, such as data cleaning, to ensure the auxiliary outlier data does not overlap with the ID data. Automating outlier data generation has thus been a long-desired alternative. Despite the appeal, generating photo-realistic outliers has been extremely challenging due to the high dimensional space. Recent works including VOS and NPOS [1; 2] proposed sampling outliers in the low-dimensional feature space and directly employed the latent-space outliers to regularize the model. However, these latent-space methods do not allow us to understand the outliers in a human-compatible way. Today, the field still lacks an automatic mechanism to generate high-resolution outliers in the _pixel space_.

In this paper, we propose a new framework Dream-ood that enables imagining photo-realistic outliers by way of diffusion models, provided with only ID data and classes (see Figure 1). Harnessing the power of diffusion models for outlier imagination is non-trivial, since one cannot easily describethe exponentially many possibilities of outliers using text prompts. It can be particularly challenging to characterize informative outliers that lie on the boundary of ID data, which have been shown to be the most effective in regularizing the ID classifier and its decision boundary . After all, it is almost impossible to describe something in words without knowing what it looks like.

Our framework circumvents the above challenges by: **(1)** learning compact visual representations for the ID data, conditioned on the textual latent space of the diffusion model (Section 3.1), and **(2)** sampling new visual embeddings in the text-conditioned latent space, which are then decoded to pixel-space images by the diffusion model (Section 3.2). Concretely, to learn the text-conditioned latent space, we train an image classifier to produce image embeddings that have a higher probability to be aligned with the corresponding class token embedding. The resulting feature embeddings thus form a compact and informative distribution that encodes the ID data. Equipped with the text-conditioned latent space, we sample new embeddings from the low-likelihood region, which can be decoded into the images via the diffusion model. The rationale is if the sampled embedding is distributionally far away from the in-distribution embeddings, the generated image will have a large semantic discrepancy from the ID images and vice versa.

We demonstrate that our proposed framework creatively imagines OOD samples conditioned on a given dataset, and as a result, helps improve the OOD detection performance. On Imagenet dataset, training with samples generated by Dream-ood improves the OOD detection on a comprehensive suite of OOD datasets. Different from [1; 2], our method allows visualizing and understanding the imagined outliers, covering a wide spectrum of near-OOD and far-OOD. Note that Dream-ood enables leveraging off-the-shelf diffusion models for OOD detection, rather than modifying the diffusion model (which is an actively studied area on its own ). In other words, this work's core contribution is to leverage generative modeling to improve discriminative learning, establishing innovative connections between the diffusion model and outlier data generation.

Our key contributions are summarized as follows:

1. To the best of our knowledge, Dream-ood is the first to enable the generation of photo-realistic high-resolution outliers for OOD detection. Dream-ood establishes promising performance on common benchmarks and can benefit OOD detection.
2. We conduct comprehensive analyses to understand the efficacy of Dream-ood, both quantitatively and qualitatively. The results provide insights into outlier imagination with diffusion models.
3. As an _extension_, we show that our synthesis method can be used to automatically generate ID samples, and as a result, improves the generalization performance of the ID task itself.

## 2 Preliminaries

We consider a training set \(=\{(_{i},y_{i})\}_{i=1}^{n}\), drawn _i.i.d._ from the joint data distribution \(P_{}\). \(\) denotes the input space and \(\{1,2,...,C\}\) denotes the label space. Let \(_{}\) denote the marginal distribution on \(\), which is also referred to as the _in-distribution_. Let \(f_{}:^{C}\) denote a multi-class classifier, which predicts the label of an input sample with parameter \(\). To obtain an

Figure 1: **Top**: Original ID training data in ImageNet. **Bottom**: Samples generated by our method Dream-ood, which deviate from the ID data.

optimal classifier \(f^{*}\), a standard approach is to perform empirical risk minimization (ERM) : \(f^{*}=_{f}_{i=1}^{n}(f(_ {i}),y_{i})\) where \(\) is the loss function and \(\) is the hypothesis space.

**Out-of-distribution detection.** When deploying a machine model in the real world, a reliable classifier should not only accurately classify known in-distribution samples, but also identify OOD input from _unknown_ class \(y\). This can be achieved by having an OOD detector, in tandem with the classification model \(f_{}\). At its core, OOD detection can be formulated as a binary classification problem. At test time, the goal is to decide whether a test-time input is from ID or not (OOD). We denote \(g_{}:\{,\}\) as the function mapping for OOD detection.

**Denoising diffusion models** have emerged as a promising generative modeling framework, pushing the state-of-the-art in image generation [11; 12]. Inspired by non-equilibrium thermodynamics, diffusion probabilistic models [13; 14; 15] define a forward Gaussian Markov transition kernel of diffusion steps to gradually corrupt training data until the data distribution is transformed into a simple noisy distribution. The model then learns to reverse this process by learning a denoising transition kernel parameterized by a neural network.

Diffusion models can be conditional, for example, on class labels or text descriptions [11; 16; 17]. In particular, Stable Diffusion  is a text-to-image model that enables synthesizing new images guided by the text prompt. The model was trained on 5 billion pairs of images and captions taken from LAION-5B , a publicly available dataset derived from Common Crawl data scraped from the web. Given a class name \(y\), the generation process can be mathematically denoted by:

\[ P(|_{y}),\] (1)

where \(_{y}=(y)\) is the textual representation of label \(y\) with prompting (e.g., "A high-quality photo of a [\(y\)]"). In Stable Diffusion, \(()\) is the text encoder of the CLIP model .

## 3 Dream-ood: Outlier Imagination with Diffusion Models

In this paper, we propose a novel framework that enables synthesizing photo-realistic outliers with respect to a given ID dataset (see Figure 1). The synthesized outliers can be useful for regularizing the ID classifier to be less confident in the OOD region. Recall that the vanilla diffusion generation takes as input the textual representation. While it is easy to encode the ID classes \(y\) into textual latent space via \((y)\), one cannot trivially generate text prompts for outliers. It can be particularly challenging to characterize informative outliers that lie on the boundary of ID data, which have been shown to be most effective in regularizing the ID classifier and its decision boundary . After all, it is almost impossible to concretely describe something in words without knowing what it looks like.

Overview.As illustrated in Figure 2, our framework circumvents the challenge by: **(1)** learning compact visual representations for the ID data, conditioned on the textual latent space of the diffusion model (Section 3.1), and **(2)** sampling new visual embeddings in the text-conditioned latent space, which are then decoded into the images by diffusion model (Section 3.2). We demonstrate in Section 4 that, our proposed outlier synthesis framework produces meaningful out-of-distribution samples conditioned on a given dataset, and as a result, significantly improves the OOD detection performance.

Figure 2: **Illustration of our proposed outlier imagination framework Dream-ood. Dream-ood first learns a text-conditioned space to produce compact image embeddings aligned with the token embedding \((y)\) of the diffusion model. It then samples new embeddings in the latent space, which can be decoded into pixel-space outlier images \(_{}\) by diffusion model. The newly generated samples can help improve OOD detection. Best viewed in color.**

### Learning the Text-Conditioned Latent Space

Our key idea is to first train a classifier on ID data \(\) that produces image embeddings, conditioned on the token embeddings \((y)\), with \(y\). To learn the text-conditioned visual latent space, we train the image classifier to produce image embeddings that have a higher probability of being aligned with the corresponding class token embedding, and vice versa.

Specifically, denote \(h_{}:^{m}\) as a feature encoder that maps an input \(\) to the image embedding \(h_{}()\), and \(:^{m}\) as the text encoder that takes a class name \(y\) and outputs its token embedding \((y)\). Here \(()\) is a fixed text encoder of the diffusion model. Only the image feature encoder needs to be trained, with learnable parameters \(\). Mathematically, the loss function for learning the visual representations is formulated as follows:

\[=_{(,y)}[-(y)^{}/t)}{_{j=1}^{C}( (y_{j})^{}/t)}],\] (2)

where \(=h_{}()/\|h_{}()\|_{2}\) is the \(L_{2}\)-normalized image embedding, and \(t\) is temperature.

**Theoretical interpretation of loss.** Formally, our loss function directly promotes the class-conditional von Mises Fisher (vMF) distribution [21; 22; 23]. vMF is analogous to spherical Gaussian distributions for features with unit norms (\(\|\|^{2}=1\)). The probability density function of \(^{m}\) in class \(c\) is:

\[p_{m}(;_{c},)=Z_{m}()( _{c}^{}),\] (3)

where \(_{c}\) is the class centroid with unit norm, \( 0\) controls the extent of class concentration, and \(Z_{m}()\) is the normalization factor detailed in the Appendix B. The probability of the feature vector \(\) belonging to class \(c\) is:

\[P(y=c|;\{,_{j}\}_{j=1}^{C}) =()( _{c}^{})}{_{j=1}^{C}Z_{m}( )(_{j}^{})}\] \[=_{c}^{}/t) }{_{j=1}^{C}(_{j}^{}/t)},\] (4)

where \(=\). Therefore, by encouraging features to be aligned with its class token embedding, our loss function \(\) (Equation (2)) maximizes the log-likelihood of the class-conditional vMF distributions and promotes compact clusters on the hypersphere (see Figure 3). The highly compact representations can benefit the sampling of new embeddings, as we introduce next in Section 3.2.

### Outlier Imagination via Text-Conditioned Latent

Given the well-trained compact representation space that encodes the information of \(_{}\), we propose to generate outliers by sampling new embeddings in the text-conditioned latent space, and then decoding via diffusion model. The rationale is that if the sampled embeddings are distributionally far away from the ID embeddings, the decoded images will have a large semantic discrepancy with the ID images and vice versa.

Recent works [1; 2] proposed sampling outlier embeddings and directly employed the latent-space outliers to regularize the model. In contrast, our method focuses on generating _pixel-space_ photo-realistic images, which allows us to directly inspect the generated outliers in a human-compatible way. Despite the appeal, generating high-resolution outliers has been extremely challenging due to the high dimensional space. To tackle the issue, our generation procedure constitutes two steps:

1. _Sample OOD in the latent space_: draw new embeddings \(\) that are in the low-likelihood region of the text-conditioned latent space.
2. _Image generation:_ decode \(\) into a pixel-space OOD image via diffusion model.

Figure 3: **TSNE visualization of learned feature embeddings using \(\). Black dots indicate token embeddings, one for each class.**

**Input:** In-distribution training data \(=\{(_{i},y_{i})\}_{i=1}^{n}\), initial model parameters \(\) for learning the text-conditioned latent space, diffusion model.

**Output:** Synthetic images \(_{}\).

**Phases:** Phase 1: Learning the Text-conditioned Latent Space. Phase 2: Outlier Imagination via Text-Conditioned Latent.

**while**_Phase 1_**do**

1. Extract token embeddings \((y)\) of the ID label \(y\).

2. Learn the text-conditioned latent representation space by Equation (2).

**end**

**while**_Phase 2_**do**

1. Sample a set of outlier embeddings \(V_{i}\) in the low-likelihood region of the text-conditioned latent space as in Section 3.2.

2. Decode the outlier embeddings into the pixel-space OOD images via diffusion model by Equation (6).

**end**

**Sampling OOD embedding.** Our goal here is to sample low-likelihood embeddings based on the learned feature representations (see Figure 4). The sampling procedure can be instantiated by different approaches. For example, a recent work by Tao _et.al._ proposed a latent non-parametric sampling method, which does not make any distributional assumption on the ID embeddings and offers stronger flexibility compared to the parametric sampling approach . Concretely, we can select the boundary ID anchors by leveraging the non-parametric nearest neighbor distance, and then draw new embeddings around that boundary point.

Denote the \(L_{2}\)-normalized embedding set of training data as \(=(_{1},_{2},...,_{n})\), where \(_{i}=h_{}(_{i})/\|h_{}(_{i})\|_{2}\). For any embedding \(^{}\), we calculate the \(k\)-NN distance _w.r.t._\(\):

\[d_{k}(^{},)=\|^{}-_{(k)}\| _{2},\] (5)

where \(_{(k)}\) is the \(k\)-th nearest neighbor in \(\). If an embedding has a large \(k\)-NN distance, it is likely to be on the boundary of the ID data and vice versa.

Given a boundary ID point, we then draw new embedding sample \(^{m}\) from a Gaussian kernel1 centered at \(_{i}\) with covariance \(^{2}\): \((_{i},^{2})\). In addition, to ensure that the outliers are sufficiently far away from the ID data, we repeatedly sample multiple outlier embeddings from the Gaussian kernel \((_{i},^{2})\), which produces a set \(V_{i}\), and further perform a filtering process by selecting the outlier embedding in \(V_{i}\) with the largest \(k\)-NN distance _w.r.t._\(\). Detailed ablations on the sampling parameters are provided in Section 4.2.

Outlier image generation.Lastly, to obtain the outlier images in the pixel space, we decode the sampled outlier embeddings \(\) via the diffusion model. In practice, this can be done by replacing the original token embedding \((y)\) with the sampled new embedding \(\)2. Different from the vanilla prompt-based generation (_c.f._ Equation (1)), our outlier imagination is mathematically reflected by:

\[_{} P(|),\] (6)

where \(_{}\) denotes the generated outliers in the pixel space. Importantly, \( S h_{}(_{})\) is dependent on the in-distribution data, which enables generating images that deviate from \(_{}\). \(S()\) denotes the sampling procedure. Our framework Dream-ood is summarized in Algorithm 1.

Figure 4: TSNE visualization of ID embeddings (purple) and the sampled outlier embeddings (orange), for the class “hen” in Imagenet.

**Learning with imagined outlier images.** The generated synthetic OOD images \(_{}\) can be used for regularizing the training of the classification model :

\[_{}=_{_{}}[-(_{})))}}]+_{ _{}}[-( )))}}{1+^{(E(f_{}()))}}],\] (7)

where \(()\) is a three-layer nonlinear MLP function with the same architecture as VOS , \(E()\) denotes the energy function, and \(f_{}()\) denotes the logit output of the classification model. In other words, the loss function takes both the ID and generated OOD images, and learns to separate them explicitly. The overall training objective combines the standard cross-entropy loss, along with an additional loss in terms of OOD regularization \(_{}+_{}\), where \(\) is the weight of the OOD regularization. \(_{}\) denotes the cross-entropy loss on the ID training data. In testing, we use the output of the binary logistic classifier for OOD detection.

## 4 Experiments and Analysis

In this section, we present empirical evidence to validate the effectiveness of our proposed outlier imagination framework. In what follows, we show that Dream-ood produces meaningful OOD images, and as a result, significantly improves OOD detection (Section 4.1) performance. We provide comprehensive ablations and qualitative studies in Section 4.2. In addition, we showcase an _extension_ of our framework for improving generalization by leveraging the synthesized inliers (Section 4.3).

### Evaluation on OOD Detection Performance

**Datasets.** Following , we use the Cifar-100 and the large-scale Imagenet dataset  as the ID training data. For Cifar-100, we use a suite of natural image datasets as OOD including Textures, Svhn, Places365, iSun & Lsun. For Imagenet-100, we adopt the OOD test data as in , including subsets of iNaturalist, Sun, Places, and Textures. For each OOD dataset, the categories are disjoint from the ID dataset. We provide the details of the datasets and categories in Appendix A.

**Training details.** We use ResNet-34  as the network architecture for both Cifar-100 and Imagenet-100 datasets. We train the model using stochastic gradient descent for 100 epochs with the cosine learning rate decay schedule, a momentum of 0.9, and a weight decay of \(5e^{-4}\). The initial learning rate is set to 0.1 and the batch size is set to 160. We generate \(1,000\) OOD samples per class using Stable Diffusion v1.4, which results in \(100,000\) synthetic images in total. \(\) is set to 1.0 for Imagenet-100 and 2.5 for Cifar-100. To learn the feature encoder \(h_{}\), we set the temperature \(t\) in Equation (2) to 0.1. Extensive ablations on hyperparameters \(\), \(k\) and \(\) are provided in Section 4.2.

**Evaluation metrics.** We report the following metrics: (1) the false positive rate (FPR95) of OOD samples when the true positive rate of ID samples is 95%, (2) the area under the receiver operating characteristic curve (AUROC), and (3) ID accuracy (ID ACC).

**Dream-ood significantly improves the OOD detection performance.** As shown in Table 1 and Table 3, we compare our method with the competitive baselines, including Maximum Softmax Probability , ODIN score , Mahalanobis score , Energy score , Generalized ODIN ,

    &  \\   &  &  &  &  &  & ID ACC \\   & FPPR95\(\) & AUROC & FPR95\(\) & AUROC & FPR95\(\) & AUROC & FPR95\(\) & AUROC & FPR95\(\) & AUROC \\  KSPF  & 31.80 & 94.98 & 47.10 & 90.84 & 47.60 & 90.86 & 65.50 & 83.54 & 48.08 & 90.01 & 87.64 \\ ODIN  & 24.40 & 95.92 & 50.30 & 90.20 & 44.90 & 91.55 & 61.00 & 81.37 & 45.15 & 89.76 & 87.64 \\ Mallalanobis  & 91.60 & 75.16 & 90.76 & 90.67 & 90.74 & 62.23 & 35.00 & 91.43 & 80.55 & 72.42 & 87.64 \\ Energy  & 25.20 & 94.82 & 50.80 & 90.76 & 47.60 & 91.71 & 63.80 & 80.54 & 48.68 & 89.46 & 87.64 \\ GODN  & 39.90 & 93.94 & 59.70 & 89.20 & 58.70 & 90.65 & 39.90 & 92.71 & 49.55 & 91.62 & 87.38 \\ KNN  & 26.67 & 95.57 & 65.83 & 83.72 & 58.08 & 90.17 & 12.92 & 90.37 & 41.38 & 91.20 & 87.64 \\ VAN  & 75.50 & 87.18 & 83.80 & 81.25 & 88.70 & 83.17 & 15.60 & 96.63 & 67.03 & 86.61 & 87.64 \\ ReAct  & 22.40 & 96.05 & 41.50 & 92.28 & 37.90 & 93.04 & 59.30 & 85.19 & 41.17 & 91.64 & 87.64 \\ DICE  & 37.30 & 92.51 & 53.80 & 87.75 & 45.60 & 89.21 & 50.00 & 83.27 & 46.67 & 88.19 & 87.64 \\   \\ GAN  & 83.10 & 71.35 & 83.20 & 69.85 & 84.40 & 67.56 & 91.00 & 59.16 & 85.42 & 66.98 & 79.52 \\ VOS  & 43.00 & 93.77 & 47.60 & 91.77 & 39.40 & 93.17 & 66.10 & 81.42 & 49.02 & 90.03 & 87.50 \\ NPCS  & 53.84 & 86.52 & 59.66 & 83.50 & 53.54 & 87.99 & **8.98** & **98.13** & 44.00 & 89.04 & 85.37 \\
**DREAM-OOIN ** & **24.10** & 96.02 & **96.01** & **93.97** & **93.74** & **93.15** & **36.08** & **93.14** & **93.55** & **93.66** & **92.02** & **92.04** & **87.85** & **94.41** \\   

Table 1: OOD detection results for Imagenet-100 as the in-distribution data. We report standard deviations estimated across 3 runs. Bold numbers are superior results.

[MISSING_PAGE_FAIL:7]

**Ablation on the regularization weight \(\).** In Figure 7 (a), we ablate the effect of weight \(\) of the regularization loss \(_{}\) for OOD detection (Section 3.2) on the OOD detection performance. Using a mild weighting, such as \(\) = 1.0, achieves the best OOD detection performance. Too excessive regularization using synthesized OOD images ultimately degrades the performance.

**Ablation on the variance value \(^{2}\).** We show in Figure 7 (b) the effect of \(^{2}\) -- the number of the variance value for the Gaussian kernel (Section 3.2). We vary \(^{2}\{0.02,0.03,0.04,0.05,0.06,0.2\}\). Using a mild variance value \(^{2}\) generates meaningful synthetic OOD images for model regularization. Too large of variance (e.g., \(^{2}=0.2\)) produces far-OOD, which does not help learn a compact decision boundary between ID and OOD.

**Ablation on \(k\) in calculating \(k\)-NN distance.** In Figure 7 (c), we analyze the effect of \(k\), _i.e._, the number of nearest neighbors for non-parametric sampling in the latent space. We vary \(k=\{100,200,300,400,500\}\) and observe that our method is not sensitive to this hyperparameter.

**Visualization of the generated outliers.** Figure 5 illustrates the generated outlier images under different variance \(^{2}\). Mathematically, a larger variance translates into outliers that are more deviated from ID data. We confirm this in our visualization too. The synthetic OOD images gradually become semantically different from ID classes "jellyfish" and "ladybug", as the variance increases. More visualization results are in Appendix C.

### Extension: From Dream-ood to Dream-id

Our framework can be easily extended to generate ID data. Specifically, we can select the ID point with small \(k\)-NN distances _w.r.t._ the training data (Equation (5)) and sample inliers from the Gaussian kernel with small variance \(^{2}\) in the text-conditioned embedding space (Figure 6). Then we decode the iniler embeddings via the diffusion model for ID generation (Visualization provided in Appendix G). For the synthesized ID images, we let the semantic label be the same as the anchor ID point. Here we term our extension as Dream-id instead.

**Datasets.** We use the same Imagenet-100 as the training data. We measure the generalization performance on both the original Imagenet test data (for ID generalization) and variants with distribution shifts (for OOD generalization). For OOD generalization, we evaluate on (1) Imagenet-a  consisting of real-world, unmodified, and naturally occurring examples that are misclassified by ResNet models; (2) Imagenet-v2 , which is created from the Flickr dataset with natural distribution shifts. We provide the experimental details in Appendix H.

Figure 5: **Visualization of the imagined outliers _w.r.t. jellyfish, ladybug_ class under different variance \(^{2}\).**

Figure 6: TSNE visualization of ID embeddings (purple) and the synthesized iniler embeddings (orange), for class “hen” in Imagenet.

**Dream-id improves the generalization performance.** As shown in Table 4, we compare Dream-id with competitive data augmentation and test-time adaptation methods. For a fair comparison, all the methods are trained using the same network architecture, under the same configuration. Specifically, our baselines include: the original model without any data augmentation, RandAugment , AutoAugment , CutMix , AugMix , DeepAugment  and MEMO . These methods are shown in the literature to help improve generalization. The results demonstrate that our approach outperforms all the baselines that use data augmentation for training in both ID generalization and generalization under natural distribution shifts (\(\)0.74% vs. the best on Imagenet-a, \(\)0.70% vs. the best on Imagenet-v2). Implementation details of the baselines are in Appendix I.

In addition, we compare our method with using generic prompts (_i.e._, "A high-quality photo of a [\(y\)]") for data generation. For a fair comparison, we synthesize the same amount of images (_i.e._, \(1000\) per class) for both methods. The result shows that Dream-id outperforms the baseline by \(0.72\%\) on Imagenet test set and \(0.95\%,1.20\%\) on Imagenet-a and Imagenet-v2, respectively.

## 5 Related Work

**Diffusion models** have recently seen wide success in image generation , which can outperform GANs in fidelity and diversity, without training instability and mode collapse issues . Recent research efforts have mostly focused on efficient sampling schedulers , architecture design , score-based modeling , large-scale text-to-image generation , diffusion personalization , and extensions to other domains .

Recent research efforts mainly utilized diffusion models for data augmentation, such as for image classification , object detection , spurious correlation  and medical image analysis  while we focus on synthesizing outliers for OOD detection. Graham _et.al._ and Liu _et.al._ utilized diffusion models for OOD detection, which applied the reconstruction error as the OOD score, and therefore is different from the discriminative approach in our paper. Liu _et.al._ jointly trained a small-scale diffusion model and a classifier while regarding the interpolation between the ID data and its noisy version as outliers, which is different from the synthesis approach in Dream-od. Meanwhile, our method does not require training the diffusion model at all. Kirchheim _et.al._ modulated the variance in BigGAN  to generate outliers rather than using diffusion models. Franco _et.al._ proposed denoising diffusion smoothing for certifying the robustness of OOD detection. Sehwag _et.al._ modified the sampling process to guide the diffusion models towards low-density regions but simultaneously maintained the fidelity of synthetic data belonging to the ID classes. Several works employed diffusion models for anomaly segmentation on medical data , which is different from the task considered in our paper.

**OOD detection** has attracted a surge of interest in recent years . One line of work performed OOD detection by devising scoring functions, including confidence-based methods ,

  Methods & Imagenet & Imagenet-a & Imagenet-v2 \\  Original (no aug) & 87.28 & 8.69 & 77.80 \\ RandAugment & 88.10 & 11.39 & 78.90 \\ AutoAugment & 88.00 & 10.85 & 79.70 \\ CutMix & 87.98 & 9.67 & 79.70 \\ AugMix & 87.74 & 10.96 & 79.20 \\ DeepAugment & 86.86 & 10.79 & 78.30 \\ MEMO & 88.00 & 10.85 & 78.60 \\  Generic Promps & 87.74 & 11.18 & 79.20 \\ 
**Dream-id (Ours)** & **88.46\(\)0.1** & **12.13\(\)0.1** & **80.40\(\)0.1** \\  

Table 4: Model generalization performance (accuracy, in %), using Imagenet-100 as the training data. We report standard deviations estimated across 3 runs.

Figure 7: (a) Ablation study on the regularization weight \(\) on \(_{}\). (b) Ablation on the variance \(^{2}\) for synthesizing outliers in Section 3.2. (c) Ablation on the \(k\) for the \(k\)-NN distance. The numbers are AUROC. The ID training dataset is Imagenet-100.

energy-based score [6; 103; 104], distance-based approaches [105; 106; 107; 23; 27; 108; 109; 110; 105; 106; 107; 108], gradient-based score , and Bayesian approaches [110; 111; 112; 113; 114; 115]. Another promising line of work addressed OOD detection by training-time regularization [116; 117; 118; 119; 120; 121; 122; 123; 124; 125]. For example, the model is regularized to produce lower confidence [4; 33] or higher energy [6; 126; 5] on the outlier data. Most regularization methods require the availability of auxiliary OOD data. [127; 128] enhanced OOD detection from the perspective of ID distribution. Several recent works [1; 2] synthesized virtual outliers in the feature space, and regularizes the model's decision boundary between ID and OOD data during training. In contrast, Dream-ood synthesizes photo-realistic outliers in pixel space, which enables visually inspecting and understanding synthetic outliers in a human-compatible way.

Recently, there has been growing interest in multi-modal OOD detection that utilizes textual information for visual OOD detection. Fort _et.al._ proposed a scheme where pretrained CLIP models are provided with candidate OOD labels for each target dataset, and show that the output probabilities summed over the OOD labels effectively capture OOD uncertainty. Esmaeilpour _et.al._ proposed to train a label generator based on the visual encoder of CLIP and use the generated labels for OOD detection. Ming _et.al._[98; 99] alleviates the need for prior information on OOD by investigating pre-trained CLIP models and parameter-efficient fine-tuning methods for OOD detection.  utilized textual outlier exposure with vision-language models to enhance the neural network's capability to distinguish between ID and OOD data. In contrast, Dream-ood generates the outlier visual embeddings by training a classifier conditioned on the ID texts and then uses the diffusion model for outlier image synthesis.

## 6 Conclusion

In this paper, we propose a novel learning framework Dream-ood, which imagines photo-realistic outliers in the pixel space by way of diffusion models. Dream-ood mitigates the key shortcomings of training with auxiliary outlier datasets, which typically require label-intensive human intervention for data preparation. Dream-ood learns a text-conditioned latent space based on ID data, and then samples outliers in the low-likelihood region via the latent. We then generate outlier images by decoding the outlier embeddings with the diffusion model. The empirical result shows that training with the outlier images helps establish competitive performance on common OOD detection benchmarks. Our in-depth quantitative and qualitative ablations provide further insights on the efficacy of Dream-ood. We hope our work will inspire future research on automatic outlier synthesis in the pixel space.

## 7 Broader Impact

Our project aims to improve the reliability and safety of modern machine learning models. Our study on using diffusion models to synthesize outliers can lead to direct benefits and societal impacts, particularly when auxiliary outlier datasets are costly to obtain, such as in safety-critical applications. Nowadays, research on diffusion models is prevalent, which provides various promising opportunities for exploring the off-the-shelf large models for our research. Our study does not involve any violation of legal compliance. Through our study and release of code, we hope to raise stronger research and societal awareness towards the problem of data synthesis for out-of-distribution detection in real-world settings.

## 8 Acknowledgement

We thank Yifei Ming for his valuable suggestions on the draft. The authors would also like to thank NeurIPS anonymous reviewers for their helpful feedback. Research is supported by the Jane Street Graduate Research Fellowship, AFOSR Young Investigator Program under award number FA9550-23-1-0184, National Science Foundation (NSF) Award No. IIS-2237037 & IIS-2331669, Office of Naval Research under grant number N00014-23-1-2643, Philanthropic Fund from SFF, and faculty research awards/gifts from Google and Meta. Zhu is supported in part by NSF grants 2023239, 2041428, 2202457, ARO MURI W911NF2110317 and AF CoE FA9550-18-1-0166.