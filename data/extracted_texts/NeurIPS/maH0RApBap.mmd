# MoFDiff: Coarse-grained Diffusion for

Metal-Organic Framework Design

 Xiang Fu\({}^{1}\)\({}^{}\) Tian Xie\({}^{2}\) Andrew S. Rosen\({}^{3,4}\) Tommi Jaakkola\({}^{1}\) Jake Smith\({}^{2}\)

\({}^{1}\)MIT CSAIL Microsoft Research AI4Science

\({}^{3}\)Department of Materials Science and Engineering, UC Berkeley

\({}^{4}\)Materials Science Division, Lawrence Berkeley National Laboratory

Correspondence to Xiang Fu (xiangfu@mit.edu) and Jake Smith (jakesmith@microsoft.com).Work partially done during an internship at Microsoft Research AI4Science.

###### Abstract

Metal-organic frameworks (MOFs) are of immense interest in applications such as gas storage and carbon capture due to their exceptional porosity and tunable chemistry. Their modular nature has enabled the use of template-based methods to generate hypothetical MOFs by combining molecular building blocks in accordance with known network topologies. However, the ability of these methods to identify top-performing MOFs is often hindered by the limited diversity of the resulting chemical space. In this work, we propose MoFDiff: a coarse-grained (CG) diffusion model that generates CG MOF structures through a denoising diffusion process over the coordinates and identities of the building blocks. The all-atom MOF structure is then determined through a novel assembly algorithm. As the diffusion model generates 3D MOF structures by predicting scores in E(3), we employ equivariant graph neural networks that respect the permutational and roto-translational symmetries. We comprehensively evaluate our model's capability to generate valid and novel MOF structures and its effectiveness in designing outstanding MOF materials for carbon capture applications with molecular simulations.

## 1 Introduction

Metal-organic frameworks (MOFs), characterized by their permanent porosity and highly tunable structures, are emerging as a versatile class of materials with applications spanning gas storage , gas separations , catalysis , and drug delivery . These frameworks are constructed from metal ions or clusters ("nodes") coordinated to organic ligands ("linkers"), forming a vast and diverse family of crystal structures . Unlike traditional solid-state materials, MOFs offer unparalleled tunability, as their structure and function can be engineered by varying the choice of metal nodes and organic linkers. The surge in interest surrounding MOFs is evident in the increasing number of research studies dedicated to their synthesis, characterization, and computational design .

The modular nature of MOFs naturally lends itself to template-based representations and algorithmic assembly. These algorithms create hypothetical MOFs by connecting metal nodes and organic linkers (collectively, building blocks) along connectivity templates known as topologies . Given a combination of topology, metal nodes, and organic linkers, the MOF structure is obtained through heuristic algorithms that arrange the building blocks, aligning them with the vertices and edges designated by the chosen topology, followed by a structural relaxation process based on classical force fields.

The template-based approach to MOF design has led to the use of high-throughput computational screening approaches , variational autoencoders , genetic algorithms , Bayesian optimization , and reinforcement learning [81; 56] to discover new combinations of building blocks and topologies to identify top-performing materials. However, template-based methods enforce a set of pre-curated topology templates and building block identities. This inherently narrows the range of designs these hypothetical MOF construction methods can produce , possibly excluding materials suited for some applications. Therefore, we aim to derive a generative model based on 3D representations of MOFs without the need for pre-defined templates that often rely on chemical intuition.

Diffusion models [66; 28; 67] have made significant progress in generating molecular and inorganic crystal structures [65; 73; 74; 75; 76; 29; 33; 15; 30; 46; 79; 70; 40; 57; 32]. Recent work  also explored using a diffusion model to design linker molecules in specific MOFs. In terms of data characteristics, both inorganic crystals and MOFs are represented as atoms in a unit cell. However, a typical MOF unit cell contains hundreds of atoms (Figure 1), while the most challenging dataset studied in previous works [73; 47] only focused on inorganic crystals with less than 20 atoms in the unit cell. Training a diffusion model for complex MOF systems with atomic-scale resolution is not only technically challenging and computationally expensive but also suffers from extremely poor data efficiency. To name one challenge, without accounting for the internal structures of the metal clusters and the molecular linkers, directly applying diffusion models over the atomic representation of MOFs can very easily lead to unphysical structures for the inorganic nodes and/or organic linkers.

To address the challenges above, we propose MOFDiff, a coarse-grained diffusion model for generating 3D MOF structures that leverages the modular and hierarchical structure of MOFs (Figure 1 (a)). We derive a coarse-grained 3D representation of MOFs, a diffusion process over this CG MOF representation, and an assembly algorithm for recovering the all-atom MOF structure. In our experiments, we adapt the MOF dataset from Boyd et al. 6 (BW-DB) that contains hypothetical MOF structures and computed property labels related to separation of carbon dioxide (CO\({}_{2}\)) from flue gas. We train MOFDiff on BW-DB and use MOFDiff to generate and optimize MOF structures for carbon capture.

In summary, the contributions of this work are:

Figure 1: (a) MOFDiff encodes a coarse-grained (CG) representation of MOF structures and decodes CG MOF structures with a denoising diffusion process. To generate a coarse-grained MOF structure, the lattice parameters \(\) and the number of building blocks \(K\) are predicted from the latent vector \(\) to initialize a random structure. A denoising diffusion process conditional on \(\) generates the building block identities and coordinates. Inverse design is enabled through gradient-based optimization over \(\) in the latent space. (b) The all-atom MOF structure is recovered from the coarse-grained representation through three steps: (1) the building block identities are decoded from the learned representation; (2) building block orientations are randomly initialized, then the assembly algorithm (Figure 7) is run to re-orient the building blocks; (3) the assembled structure goes through an energetic minimization process using the UFF force field. The relaxed structure is then used to compute structural and gas adsorption properties. Atom color code: Zn (purple), O (red), C (gray), N (blue), H (white).

* We derive a coarse-grained representation for MOFs where we specify the identities and coordinates of structural building blocks. We propose to learn a contrastive embedding to represent the vast building block design space.
* We formulate a diffusion process for generating coarse-grained MOF 3D structures. We then design an assembling algorithm that, given the identities and coordinates of building blocks, re-orients the building blocks to recover the atomic MOF structures. The generated atomic structures are further refined with force field relaxation (Figure 1 (b)).
* We demonstrate that MOFDiff can generate valid and novel MOF structures. MOFDiff surpasses the scope of previous template-based methods, producing MOFs that extend beyond simple combinations of pre-specified building blocks.
* We use MOFDiff to optimize MOF structures for carbon capture and evaluate the performance of the generated MOFs using molecular simulations. We show that MOFDiff can discover MOF structures with exceptional CO\({}_{2}\) adsorption properties with excellent efficiency.

## 2 Experiment Hightlight

Climate change is one of the most significant and urgent challenges that humanity needs to address. Carbon capture is one of the few technologies that can mitigate current CO\({}_{2}\) emissions, for which MOFs are promising candidate materials [69; 17]. In this experiment, we evaluate MOFDiff's capability to optimize MOF structures for use as CO\({}_{2}\)-selective sorbents in point-capture applications. We train and evaluate our method on the BW-DB dataset. On average, each MOF contains 185 atoms (6.9 building blocks) in the unit cell. We highlight the results for optimizing carbon capture MOFs while deferring the results on unconditional sampling to Appendix D.

The key property for practical carbon capture purposes is high CO\({}_{2}\) working capacity, the net quantity of CO\({}_{2}\) capturable by a given quantity of MOF in an adsorption/desorption cycle. Several factors contribute to a high working capacity, such as the CO\({}_{2}\) selectivity over N\({}_{2}\), CO\({}_{2}\)/N\({}_{2}\) uptake for each condition, and CO\({}_{2}\) heat of adsorption, which reflects the average binding energy of the adsorbing gas molecules. We compute these properties using molecular simulations, which is detailed in Appendix E.

**MOFDiff discovers promising candidates for carbon capture.**

We randomly sample 10,000 MOFs from the training dataset and encode these MOFs to get 10,000 latent vectors. We use the Adam optimizer  to maximize the model-predicted CO\({}_{2}\) working capacity for 5,000 steps with a learning rate of \(0.0003\). The resulting optimized latent vectors are then decoded, assembled, and relaxed. After conducting the validity checks described in Appendix D, we find 2054 MOFs that are valid, novel, and unique (Figure 3 (a)). These 2054 MOFs are then simulated with our GCMC workflow to compute gas adsorption properties. Given the systematic differences between the original labels of BW-DB and those calculated with our reimplemented GCMC workflow, we randomly sampled 5,000 MOFs from the BW-DB dataset and recalculated the gas adsorption properties using our GCMC workflow to provide a fair baseline for comparison. Figure 3 shows the CO\({}_{2}\) working capacity distribution of the BW-DB MOFs and the MOFDiff optimized MOFs: the MOFs generated by MOFDiff have significantly higher CO\({}_{2}\) working capacity. The four smaller panels break down the contributions to CO\({}_{2}\) working capacity from CO\({}_{2}\)/N\({}_{2}\) selectivity, CO\({}_{2}\) heat of adsorption, as well as CO\({}_{2}\) uptake at the adsorption (0.15 bar, 298 K) and the desorption stages (0.1 bar, 363 K). We observe that MOFDiff generates a distribution of MOFs that are more selective towards CO\({}_{2}\), have higher CO\({}_{2}\) uptakes under adsorption conditions, and bind more strongly to CO\({}_{2}\).

From an efficiency perspective, GCMC simulations take orders of magnitude more computational time (tens of minutes to hours) than other components of the MOF design pipeline (seconds to tens of seconds). These simulations can also be made more accurate at significantly higher computational

Figure 2: The validity of MOFDiff samples optimized for CO\({}_{2}\) working capacity. “Match” stands for matched connection points. “VNU” stands for valid, novel, and unique. Definitions of the various validity criteria are included in Appendix D. Almost all valid samples are also novel and unique.

costs (days) by converging sampling to tighter confidence intervals or using more advanced techniques, such as including blocking spheres, which prohibit Monte Carlo insertion of gas molecules into kinetically prohibited pores of the MOF, and calculating atomic charges with density functional theory (DFT). Therefore, the efficiency of a MOF design pipeline can be evaluated by the average number of GCMC simulations required to find one qualifying MOF for carbon capture applications. Naively sampling from the BW-DB dataset requires, on average, 58.1 GCMC simulations to find one MOF with a working capacity of more than 2 mol/kg. For MOFDiff, only 14.6 GCMC simulations are needed to find one MOF with a working capacity of more than 2 mol/kg, a 75% decrease in compute cost per candidate structure.

**Compare to carbon capture MOFs from literature.** Beyond efficiency, MOFDiff's generation flexibility also allows it to discover top MOF candidates that are outstanding for carbon capture. We compute gas adsorption properties of 18 MOFs that have been investigated for CO\({}_{2}\) adsorption from previous literature  using our GCMC simulation workflow. We compare the gas adsorption properties of the top ten MOFs discovered from our 10,000 samples (visualized in Figure 4) to these 18 MOFs in Table 1 of Appendix E and annotate selected MOFs in Figure 3. MOFDiff can discover highly promising candidates, making up 9 out of the top 10 MOFs. In particular, Al-PMOF is

Figure 4: The top ten samples from MOFDiff in terms of the highest CO\({}_{2}\) working capacity. Atom color code: Cu (brown), Zn (purple), S (yellow), O (red), N (blue), C (gray), H (white).

Figure 3: CO\({}_{2}\) adsorption properties for MOFDiff optimized samples (top-5 annotated with green boxes) compared to the reference distribution and selected MOF structures (grey boxes). The four small panels breakdown working capacity to more fundamental gas adsorption properties.

[MISSING_PAGE_FAIL:5]

* Corso et al.  Gabriele Corso, Hannes Stark, Bowen Jing, Regina Barzilay, and Tommi Jaakkola. Diffdock: Diffusion steps, twists, and turns for molecular docking. _arXiv preprint arXiv:2210.01776_, 2022.
* Day and Wilmer  Brian A Day and Christopher E Wilmer. Genetic algorithm design of mof-based gas sensor arrays for co2-in-air sensing. _Sensors_, 20(3):924, 2020.
* Ding et al.  Meili Ding, Robinson W Flaig, Hai-Long Jiang, and Omar M Yaghi. Carbon capture and conversion using metal-organic frameworks and mof-based materials. _Chemical Society Reviews_, 48(10):2783-2828, 2019.
* Dubbeldam et al.  David Dubbeldam, Sofia Calero, Donald E Ellis, and Randall Q Snurr. Raspa: molecular simulation software for adsorption and diffusion in flexible nanoporous materials. _Molecular Simulation_, 42(2):81-101, 2016.
* Falcon and LyTorch Lightning team  William Falcon and The PyTorch Lightning team. PyTorch Lightning, March 2019. URL https://github.com/Lightning-AI/lightning.
* Fey and Lenssen  Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In _ICLR Workshop on Representation Learning on Graphs and Manifolds_, 2019.
* Garcia-Sanchez et al.  Almudena Garcia-Sanchez, Conchi O Ania, Jose B Parra, David Dubbeldam, Thijs JH Vlugt, Rajamani Krishna, and Sofia Calero. Transferable force field for carbon dioxide adsorption in zeolites. _The Journal of Physical Chemistry C_, 113(20):8814-8820, 2009.
* Gasteiger et al.  Johannes Gasteiger, Florian Becker, and Stephan Gunnemann. Gemnet: Universal directional graph neural networks for molecules. _Advances in Neural Information Processing Systems_, 34:6790-6802, 2021.
* Gasteiger et al.  Johannes Gasteiger, Muhammed Shuaibi, Anuroop Sriram, Stephan Gunnemann, Zachary Ward Ulissi, C. Lawrence Zitnick, and Abhishek Das. Gemnet-OC: Developing graph neural networks for large and diverse molecular simulation datasets. _Transactions on Machine Learning Research_, 2022. URL https://openreview.net/forum?id=u8tvXm4Bs.
* Gomez-Gualdron et al.  Diego A Gomez-Gualdron, Oleksii V Gutov, Vaiva Krungleviciute, Bhaskarjyoti Borah, Joseph E Mondloch, Joseph T Hupp, Taner Yildirim, Omar K Farha, and Randall Q Snurr. Computational design of metal-organic frameworks based on stable zirconium building units for storage and delivery of methane. _Chemistry of Materials_, 26(19):5632-5639, 2014.
* Gonzalez-Zamora and Ibarra  Eduardo Gonzalez-Zamora and Ilich A Ibarra. Co 2 capture under humid conditions in metal-organic frameworks. _Materials Chemistry Frontiers_, 1(8):1471-1484, 2017.
* Hadsell et al.  Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality reduction by learning an invariant mapping. In _2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06)_, volume 2, pp. 1735-1742. IEEE, 2006.
* Higgins et al.  Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In _International conference on learning representations_, 2016.
* Ho et al.  Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. _Advances in neural information processing systems_, 33:6840-6851, 2020.
* Hoogeboom et al.  Emiel Hoogeboom, Victor Garcia Satorras, Clement Vignac, and Max Welling. Equivariant diffusion for molecule generation in 3d. In _International conference on machine learning_, pp. 8867-8887. PMLR, 2022.
* Ingraham et al.  John Ingraham, Max Baranov, Zak Costello, Vincent Frappier, Ahmed Ismail, Shan Tie, Wujie Wang, Vincent Xue, Fritz Obermeyer, Andrew Beam, et al. Illuminating protein space with a programmable generative model. _BioRxiv_, pp. 2022-12, 2022.
* Jablonka  Kevin Maik Jablonka. mofchecker, June 2023. URL https://github.com/kjappelbaum/mofchecker.

*  Rui Jiao, Wenbing Huang, Peijia Lin, Jiaqi Han, Pin Chen, Yutong Lu, and Yang Liu. Crystal structure prediction by joint equivariant diffusion. _arXiv preprint arXiv:2309.04475_, 2023.
*  Bowen Jing, Gabriele Corso, Jeffrey Chang, Regina Barzilay, and Tommi Jaakkola. Torsional diffusion for molecular conformer generation. _Advances in Neural Information Processing Systems_, 35:24240-24253, 2022.
*  Ian T Jolliffe. _Principal component analysis for special types of data_. Springer, 2002.
*  Eugene S Kadantsev, Peter G Boyd, Thomas D Daff, and Tom K Woo. Fast and accurate electrostatics in metal organic frameworks with a robust charge equilibration parameterization for high-throughput virtual screening of gas adsorption. _The Journal of Physical Chemistry Letters_, 4(18):3056-3061, 2013.
*  Markus J Kalmutzki, Nikita Hanikel, and Omar M Yaghi. Secondary building units as the turning point in the development of the reticular chemistry of mofs. _Science advances_, 4(10):eaat9180, 2018.
*  Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In _International Conference on Learning Representations (ICLR)_, San Diego, CA, USA, 2015.
*  Aditi S Krishnapriyan, Maciej Haranczyk, and Dmitriy Morozov. Topological descriptors help predict guest adsorption in nanoporous materials. _The Journal of Physical Chemistry C_, 124 (17):9360-9368, 2020.
*  Harrison D Lawson, S Patrick Walton, and Christina Chan. Metal-organic frameworks for drug delivery: a design perspective. _ACS applied materials & interfaces_, 13(6):7004-7020, 2021.
*  Jin Sub Lee, Jisun Kim, and Philip M Kim. Score-based generative modeling for de novo protein design. _Nature Computational Science_, pp. 1-11, 2023.
*  Sangwon Lee, Baekjun Kim, Hyun Cho, Hooseung Lee, Sarah Yunmi Lee, Eun Seon Cho, and Jihan Kim. Computational screening of trillions of metal-organic frameworks for high-performance methane storage. _ACS Applied Materials & Interfaces_, 13(20):23647-23654, 2021.
*  Hao Li, Kecheng Wang, Yujia Sun, Christina T Lollar, Jialuo Li, and Hong-Cai Zhou. Recent advances in gas storage and separation using metal-organic frameworks. _Materials Today_, 21 (2):108-121, 2018.
*  Mian Li, Dan Li, Michael O'Keeffe, and Omar M Yaghi. Topological analysis of metal-organic frameworks with polytopic linkers and/or multiple building units and the minimal transitivity principle. _Chemical reviews_, 114(2):1343-1370, 2014.
*  Rui-Biao Lin, Shengchang Xiang, Wei Zhou, and Banglin Chen. Microporous metal-organic framework materials for gas separation. _Chem_, 6(2):337-363, 2020.
*  Shitong Luo, Chence Shi, Minkai Xu, and Jian Tang. Predicting molecular conformation via dynamic graph score matching. _Advances in Neural Information Processing Systems_, 34:19784-19795, 2021.
*  Shitong Luo, Yufeng Su, Xingang Peng, Sheng Wang, Jian Peng, and Jianzhu Ma. Antigen-specific antibody design and optimization with diffusion-based generative models for protein structures. _Advances in Neural Information Processing Systems_, 35:9754-9767, 2022.
*  Peder Lyngby and Kristian Sommer Thygesen. Data-driven discovery of 2d materials by deep generative models. _npj Computational Materials_, 8(1):232, 2022.
*  David G Madden, Hayley S Scott, Amrit Kumar, Kai-Jie Chen, Rana Sanii, Alankriti Bajpai, Matteo Lusi, Teresa Curtin, John J Perry, and Michael J Zaworotko. Flue-gas and direct-air capture of co2 by porous metal-organic materials. _Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences_, 375(2084):20160025, 2017.
*  Richard Luis Martin and Maciej Haranczyk. Construction and characterization of structure models of crystalline porous polymers. _Crystal growth & design_, 14(5):2431-2440, 2014.

*  Peyman Z Moghadam, Aurelia Li, Seth B Wiggin, Andi Tao, Andrew GP Maloney, Peter A Wood, Suzanna C Ward, and David Fairen-Jimenez. Development of a cambridge structural database subset: a collection of metal-organic frameworks for past, present, and future. _Chemistry of Materials_, 29(7):2618-2625, 2017.
*  Seyed Mohamad Moosavi, Aditya Nandy, Kevin Maik Jablonka, Daniele Ongari, Jon Paul Janet, Peter G Boyd, Yongjin Lee, Berend Smit, and Heather J Kulik. Understanding the diversity of the metal-organic framework ecosystem. _Nature communications_, 11(1):1-10, 2020.
*  Aditya Nandy, Gianmarco Terrones, Naveen Arunachalam, Chenru Duan, David W Kastner, and Heather J Kulik. Mofsimplify, machine learning models with extracted stability data of three thousand metal-organic frameworks. _Scientific Data_, 9(1):74, 2022.
*  Aditya Nandy, Shuwen Yue, Changhwan Oh, Chenru Duan, Gianmarco G Terrones, Yongchul G Chung, and Heather J Kulik. A database of ultrastable mofs reassembled from stable fragments with machine learning models. _Matter_, 6(5):1585-1603, 2023.
*  Michael O'Keeffe and Omar M Yaghi. Deconstructing the crystal structures of metal-organic frameworks and related materials into their underlying nets. _Chemical reviews_, 112(2):675-702, 2012.
*  Hyun Park, Xiaoli Yan, Ruijie Zhu, EA Huerta, Santanu Chaudhuri, Donny Cooper, Ian Foster, and Emad Tajkhorshid. Ghp-mofassemble: Diffusion modeling, high throughput screening, and molecular dynamics for rational discovery of novel metal-organic frameworks for carbon capture at scale. _arXiv preprint arXiv:2306.08695_, 2023.
*  Hyunsoo Park, Sauradeep Majumdar, Xiaoqi Zhang, Jihan Kim, and Berend Smit. Inverse design of metal-organic frameworks for direct air capture of co2 via deep reinforcement learning. _ChemRxiv_, 2023.
*  Junkil Park, Aseem Partap Singh Gill, Seyed Mohamad Moosavi, and JIHAN KIM. Inverse design of porous materials: A diffusion model approach. _ChemRxiv_, 2023.
*  Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. _Advances in neural information processing systems_, 32, 2019.
*  Jeffrey J Potoff and J Ilja Siepmann. Vapor-liquid equilibria of mixtures containing alkanes, carbon dioxide, and nitrogen. _AIChE journal_, 47(7):1676-1682, 2001.
*  Qihui Qian, Patrick A Asinger, Moon Joo Lee, Gang Han, Katherine Mizrahi Rodriguez, Sharon Lin, Francesco M Benedetti, Albert X Wu, Won Seok Chi, and Zachary P Smith. Mof-based membranes for gas separations. _Chemical reviews_, 120(16):8161-8266, 2020.
*  Anthony K Rappe and William A Goddard III. Charge equilibration for molecular dynamics simulations. _The Journal of Physical Chemistry_, 95(8):3358-3363, 1991.
*  Anthony K Rappe, Carla J Casewit, KS Colwell, William A Goddard III, and W Mason Skiff. Uff, a full periodic table force field for molecular mechanics and molecular dynamics simulations. _Journal of the American chemical society_, 114(25):10024-10035, 1992.
*  David Rogers and Mathew Hahn. Extended-connectivity fingerprints. _Journal of chemical information and modeling_, 50(5):742-754, 2010.
*  Andrew S Rosen, Justin M Notestein, and Randall Q Snur. Realizing the data-driven, computational discovery of metal-organic framework catalysts. _Current Opinion in Chemical Engineering_, 35:100760, 2022.
*  Chence Shi, Shitong Luo, Minkai Xu, and Jian Tang. Learning gradient fields for molecular conformation generation. In _International conference on machine learning_, pp. 9558-9568. PMLR, 2021.

* Song and Ermon  Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution. _Advances in Neural Information Processing Systems_, 32, 2019.
* Song et al.  Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In _International Conference on Learning Representations_, 2021. URL https://openreview.net/forum?id=PxTIG12RRHS.
* a flexible simulation tool for particle-based materials modeling at the atomic, meso, and continuum scales. _Comp. Phys. Comm._, 271:108171, 2022.
* Trickett et al.  Christopher A Trickett, Aasif Helal, Bassem A Al-Maythalony, Zain H Yamani, Kyle E Cordova, and Omar M Yaghi. The chemistry of metal-organic frameworks for co2 capture, regeneration and conversion. _Nature Reviews Materials_, 2(8):1-16, 2017.
* Watson et al.  Joseph L Watson, David Juergens, Nathaniel R Bennett, Brian L Trippe, Jason Yim, Helen E Eisenach, Woody Ahern, Andrew J Borst, Robert J Ragotte, Lukas F Milles, et al. De novo design of protein structure and function with rdfiffusion. _Nature_, pp. 1-3, 2023.
* Willems et al.  Thomas F Willems, Chris H Rycroft, Michael Kazi, Juan C Meza, and Maciej Haranczyk. Algorithms and tools for high-throughput geometry-based analysis of crystalline porous materials. _Microporous and Mesoporous Materials_, 149(1):134-141, 2012.
* Xie and Grossman  Tian Xie and Jeffrey C Grossman. Crystal graph convolutional neural networks for an accurate and interpretable prediction of material properties. _Physical review letters_, 120(14):145301, 2018.
* Xie et al.  Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi S. Jaakkola. Crystal diffusion variational autoencoder for periodic material generation. In _International Conference on Learning Representations_, 2022. URL https://openreview.net/forum?id=03RLpj-tc_.
* Xu et al.  Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, and Jian Tang. Geodiff: A geometric diffusion model for molecular conformation generation. _arXiv preprint arXiv:2203.02923_, 2022.
* Xu et al.  Minkai Xu, Alexander S Powers, Ron O Dror, Stefano Ermon, and Jure Leskovec. Geometric latent diffusion models for 3d molecule generation. In _International Conference on Machine Learning_, pp. 38592-38610. PMLR, 2023.
* Yaghi  Omar M Yaghi. The reticular chemist, 2020.
* Yang and Gates  Dong Yang and Bruce C Gates. Catalysis by metal organic frameworks: perspective and suggestions for future research. _Acs Catalysis_, 9(3):1779-1798, 2019.
* Yao et al.  Zhenpeng Yao, Benjamin Sanchez-Lengeling, N Scott Bobbitt, Benjamin J Bucior, Sai Govind Hari Kumar, Sean P Collins, Thomas Burns, Tom K Woo, Omar K Farha, Randall Q Snurr, et al. Inverse design of nanoporous crystalline reticular materials with deep generative models. _Nature Machine Intelligence_, 3(1):76-86, 2021.
* Yim et al.  Jason Yim, Brian L Trippe, Valentin De Bortoli, Emile Mathieu, Arnaud Doucet, Regina Barzilay, and Tommi Jaakkola. Se (3) diffusion model with application to protein backbone generation. _arXiv preprint arXiv:2302.02277_, 2023.
* Yusuf et al.  Vadia Foziya Yusuf, Naved I Malek, and Suresh Kumar Kailasa. Review on metal-organic framework classification, synthetic approaches, and influencing factors: Applications in energy, drug delivery, and wastewater treatment. _ACS omega_, 7(49):44507-44531, 2022.
* Zhang et al.  Xiangyu Zhang, Kexin Zhang, and Yongjin Lee. Machine learning enabled tailor-made design of application-specific metal-organic frameworks. _ACS applied materials & interfaces_, 12(1):734-743, 2019.

## Appendix A Representation of 3D MOF structures

Like any solid-state material, a MOF structure can be represented as the periodic arrangement of atoms in 3D space, defined by the infinite extension of a 3-dimensional unit cell. A unit cell that includes \(N\) atoms is described by three components: (1) atom types \(=(a_{1},...,a_{N})^{N}\), where \(\) denotes the set of all chemical elements; (2) atom coordinates \(=(_{1},...,_{N})^{N 3}\); and (3) periodic lattice \(=(_{1},_{2},_{3})^{3 3}\). The periodic lattice defines the periodic translation symmetry of the material. Given \(=(,,)\), the infinite periodic structure is represented as,

\[\{(a^{}_{i},^{}_{i})|a^{}_{i}=a_{i},^{}_{ i}=_{i}+k_{1}_{1}+k_{2}_{2}+k_{3}_{3},k_{1},k_{2},k_{3} \},\] (1)

where \(k_{1},k_{2},k_{3}\) are any integers that translate the unit cell using \(\) to tile the entire 3D space. A MOF generative model aims to generate 3-tuples \(\) that correspond to valid3, novel, and functional MOFs. As noted in the introduction, prior research  employed a diffusion model on atomic types and coordinates to produce valid and novel inorganic crystal structures, specifically with fewer than 20 atoms in the unit cell. However, MOFs present a distinct challenge: their unit cells typically comprise tens to hundreds of atoms, composed of a diverse range of metal nodes and organic linkers. Directly applying the atomic diffusion model to MOFs poses formidable learning and computational challenges due to their increased size and complexity. This necessitates a new approach that can leverage the hierarchical nature of MOFs.

**Hierarchical representation of MOFs.** A coarse-grained 3D structural representation of a MOF can be derived from the coordinates and identities of the building blocks constituting the MOF. Such a representation is attractive, as the number of building blocks (denoted \(K\)) in a MOF is generally orders of magnitude smaller than the number of atoms (denoted \(N\), \(K N\)). We denote a coarse-grained MOF structure with \(K\) building blocks as \(^{C}=(^{C},^{C},)\). The three components: (1) \(^{C}=(a^{C}_{1},...,a^{C}_{K})^{K}\) are the identities of the building blocks, where \(\) denotes the set of all building blocks; (2) \(^{C}=(^{C}_{1},...,^{C}_{K})^{K 3}\) are the coordinates of the building blocks; (3) \(\) are the lattice parameters. To obtain this coarse-grained representation, we need a systematic procedure to determine which atoms constitute which building blocks. In other words, we need an algorithm to assign the \(N\) atoms to \(K\) connected components, which correspond to \(K\) building blocks.

Luckily, multiple methods have been developed for decomposing MOFs into building blocks based on network topology and MOF chemistry . We employ the metal-oxo algorithm from the popular MOF identification method MOFid. Figure 1 (a) demonstrates the coarse-graining process: the atoms of each building block are identified with MOFid and assigned the same color in the visualization. From these segmented atom groups, we can compute the building block coordinates \(^{C}\) and identities \(^{C}\) for all \(K\) building blocks to construct the coarse-grained representation. Each building block is extracted by removing single bonds that connect it to other building blocks. Every atom that forms such bonds to another building block is then assigned a special pseudo atom, called a connection point, at the midpoint of the original bonds that were removed. Figure 5 illustrates this process. We can now compute building block coordinates \(^{C}\) by computing the centroid of the connection points for each building block4.

Figure 5: MOF decomposition with connections visualized. Connection points are light blue. (a) A MOF unit cell. (b) For visibility, we visualize the metal node and one other organic linker, one at a time. (c) All four building blocks in this example MOF.

The building block identities \(^{C}\) are, on the other hand, tricky to represent because there is a huge space of possible building blocks for any non-trivial dataset. Furthermore, many building blocks share an identical chemical composition, varying only by small geometric variations in 3D orientation. Example building blocks are visualized in Figure 6 (a). To illustrate the vast space of building blocks, we extracted 2 million building blocks from the training split of the BW-DB dataset (289k MOFs). To quantify the extent of geometric variation among building blocks with the same molecule/metal cluster, we computed the ECFP4 fingerprints  for each building block using their molecular graphs and found 242k unique building block identities. This building block space is too large to be represented as a categorical variable in a generative model.

**Contrastive representation of building blocks.** In order to construct a compact representation of building blocks for diffusion-based modeling, we use a contrastive learning approach  to embed building blocks into a low dimensional latent space. A building block \(i\) is encoded as a vector \(_{i}\) using a GemNet-OC encoder , an E(3)-invariant graph neural network model. We then train the GNN building block encoder using a contrastive loss to map small geometric variations of the same building block to similar latent vectors in the embedding space. In other words, two building blocks are a positive pair for contrastive learning if they have the same ECFP4 fingerprint. Figure 6 (a) illustrates the contrastive learning process, while Figure 6 (b) shows the distribution of the number of atoms and the distribution of the number of connection points for building blocks extracted from BW-DB. The contrastive loss is defined as:

\[_{}=-_{i}_{i}^{+} }(s_{i,j}/)}{_{j}(s_{i,j}/)}\] (2)

where \(\) is a training batch, \(_{i}^{+}\) are the other data points in \(\) that have the same ECFP4 fingerprint as \(i\), \(s_{i,j}\) is the similarity between building block \(i\) and building block \(j\), and \(\) is the temperature factor. We define \(s_{i,j}=_{i}^{T}_{j}/(||_{i}||||_{j}||)\), which is the cosine similarity between projected embeddings \(_{i}\) and \(_{j}\). The projected embedding is obtained by projecting the building block embedding \(_{i}\) using a multi-layer perceptron (MLP) projection head: \(_{i}=(_{i})\). The projection layer is a standard practice in contrastive learning frameworks for improved performance.

With a trained building block encoder, we encode all building blocks extracted from a MOF to construct the building block identities in the coarse-grained representation: \(^{C}=(_{1},...,_{K})^{K d}\), where \(d\) is the embedding dimension of the contrastive building block encoder (\(d=32\) for BW-DB). The contrastive embedding allows accurate retrieval through finding the nearest neighbor in the embedding space.

Figure 6: (a) Learning a compact representation of building blocks for CG diffusion. Building blocks are extracted from MOF structures and embedded through a GemNet-OC encoder. The representation is trained through a contrastive learning loss such that similar building blocks have similar embeddings. (b) The distribution of the number of atoms and the distribution of the number of connection points for the building blocks extracted from BW-DB. Atom color code: Cu (brown), Zn (purple), O (red), N (blue), C (gray), H (white).

**Building block representation.** The building block encoder is a GemNet-OC model that inputs the 3D configuration of the building block, including the connection points, and outputs building block embedding \(\). A radius-cutoff graph is built as the building block for message passing. In addition to the contrastive loss \(_{C}\), we also train the building block latent representation to encode the number of atoms \(N_{b}\), the number of connection points \(C_{b}\), and the largest distance between any pair of atoms \(l\) in the building block by predicting these quantities. Cross-entropy loss is used for \(N_{b}\) and \(C_{b}\), while mean squared error loss is used for \(l\):

\[_{}=(N_{b},_{b})+(C_{b},_{b})+||l-||^{2}\] (3)

where \(_{b},_{b},\) are model predictions. These quantities are important indicators of the size and connection pattern of the building block. The overall loss for the building block encoder is:

\[_{}=_{}+_{}+_{ }||||^{2}\] (4)

where the last term is an \(L_{2}\) regularization over the building block embedding with a loss weighting of \(_{}=0.0001\) to constrain the norm of building block embedding. The regularization makes the embedding numerically stable to use in diffusion modeling later. We do not apply weighting over \(_{}\) and \(_{}\). Hyperparameters of the building block encoder are reported in Table 2. GemNet-OC hyperparameters are the default values for the Base version from Gasteiger et al.  unless otherwise noted. After being trained to convergence, the building block encoder is frozen and used for encoding all building blocks to construct the CG representation of MOFs.

## Appendix B MOF design with coarse-grained diffusion

**MOFDiff.** Equipped with the CG MOF representation, we encode MOFs as latent vectors and decode MOF structures with conditional diffusion. The MOFDiff model is composed of four components (Figure 1 (a)): (1) A periodic GemNet-OC encoder5 that outputs a latent vector \(=_{}(^{C})\); (2) an MLP predictor that predicts the lattice parameters and the number of building blocks from the latent code \(\): \(},=_{,K}()\); (3) a periodic GemNet-OC denoiser that denoises random structures to CG MOF structures conditional on the latent code: \(_{^{C}},_{^{C}}=_{}(}^{C}_{},)\), where \(_{^{C}},_{^{C}}\) are the predicted scores for building block identities \(^{C}\) and coordinates \(^{C}\), and \(}^{C}_{t}\) is a noisy CG structure at time \(t\) in the diffusion process; (4) an MLP predictor that predicts properties \(\) (such as CO\({}_{2}\) working capacity) from \(\): \(}=_{}()\).

The first three components are used to generate MOF structures, while the property predictor \(_{}\) can be used for property-driven inverse design. To sample a CG MOF structure from MoFDiff, we follow three steps: (1) randomly sample a latent code \((,)\); (2) decode the lattice parameters \(\) and the number of building blocks \(K\) from \(\), use \(\) and \(\) to initialize a random coarse-grained MOF structure \(}^{C}=(}^{C},}^{C},)\); (3) generate the coarse-grained MOF structure \(^{C}=(^{C},^{C},)\) through the denoising diffusion process conditional on \(\). Given the final building block embedding \(^{C}^{K d}\), we decode the building block identities by finding the nearest neighbors in the building block embedding space of the training set.

**Recover all-atom MOF structures.** The orientations of building blocks are not specified by the CG MOF representation, but they can be determined by forming connections between the building blocks. We design an assembly algorithm that optimizes the building block orientations to match the

Figure 7: The MOF assembly process. Connection points (light blue) are highlighted for visibility.

connection points of adjacent building blocks such that the MOF becomes connected (visualized in Figure 7). This optimization algorithm places Gaussian densities at the position of each connection point and maximizes the overlap of these densities between compatible connection points. Two connection points are compatible if they come from two different building blocks: one is from a metal atom, and the other is from a non-metal atom (Figure 5). The radius of the Gaussian densities is gradually reduced in the optimization process: at the beginning, the radius is high, so the optimization problem is smoother, and it is simpler to find an approximate solution. At the end of optimization, the radius of the densities is small, so the algorithm can find accurate orientations for matching the connection points closely. This overlap-based loss function is differentiable with regard to the building block orientation, and we optimize for the building block orientations using the L-BFGS optimizer .

The assembly algorithm outputs an all-atom MOF structure that is fed to a structural relaxation procedure using the UFF force field . We modify a relaxation workflow from previous work  implemented with LAMMPS  and LAMMPS Interface to refine both atomic positions and the lattice parameters using the conjugate gradient algorithm.

**Full generation process.** Six steps are needed to generate a MOF structure: (1) sample a latent vector \(\); (2) decode the lattice parameters \(\) and the number of building blocks \(K\) from \(\), use \(\) and \(K\) to initialize a random coarse-grained MOF structure; (3) generate the coarse-grained MOF structure through the denoising diffusion process conditional on \(\); (4) decode the building block identities by finding their nearest neighbors from the building block vocabulary; (5) use the assembly algorithm to re-orient building blocks such that compatible connection points' overlap is maximized; (6) relax the all-atom structure using the UFF force field to refine the lattice parameter and atomic coordinates. All steps are demonstrated in Figure 1.

## Appendix C Model Details

**MOFDiff encoding.** Before feeding the MOF structures to the periodic GNN encoder, we normalize all MOFs by dividing all lattice lengths by the mean lattice length and dividing all building block embedding by the mean of all building block embedding's \(L_{2}\)-norms. This normalization makes it easier to select the noisy distributions for diffusion modeling. The coarse-grained diffusion model only operates on the coarse-grained representation. To encode a CG MOF structure, we build the coarse-grained graph with the CG connections inferred from the all-atom inter-building-block connections: two building blocks \(i\) and \(j\) have an edge with the periodic image \(I\) if an atom in building block \(i\) has a bond connection to an atom in building block \(j\) (considering periodic image \(I\)). We refer interested readers to Xie et al.  for more details on the multi-graph representation of crystals. The periodic GNN encoder is an E(3)-invariant GemNet-OC model. After invariant message passing, we apply pooling to the node embedding to obtain the CG MOF latent code \(\).

**Diffusion process.** The forward diffusion process injects noise into the coarse-grained MOF \(^{C}=^{C},^{C},)\) to obtain the noisy structure \(}^{C}_{t}=(}^{C}_{t},}^{C}_{t},)\) for \(t=0\) to \(T\), where at \(t=T\) the data is diffused to the prior distribution. At time step \(t\), the denoiser \(_{}\) inputs the noisy structure \(^{C}_{t}\), latent code \(\), and the time step \(t\) then predicts scores \(_{^{C}_{t},},_{^{C}_{t},}\) for building block embedding and coordinates. The lattice parameter remains fixed throughout the diffusion process. With contrastive building block embedding in \(^{K d}\) (\(d=32\) for BW-DB), we employ a DDPM  (variance-preserving) forward process for type embedding:

\[q(}^{C}_{t}|}^{C}_{t-1}) =(}}^{C}_{t-1}, _{t})\] (5) \[q(}^{C}_{t}|}^{C}_{0}) =(_{t}}}^{C}_{0},(1 -_{t}))\] (6)

where \(_{1},,_{T}\) is the variance schedule, \(_{t}:=1-_{t}\) and \(_{t}=_{s=1}^{t}_{s}\). The corresponding reverse diffusion sampling process is:

\[q(}^{C}_{t-1}|}^{C}_{t},)=( }}(^{C}_{t}-}{_{t}}}_{^{C}_{t},}),_ {t-1}}{1-_{t}}_{t})\] (7)We refer interested readers to Ho et al. 28 for a more detailed derivation of the DDPM diffusion process. We use the same noise schedule as Hoogeboom et al. 29, a, for the building block type diffusion.

With building block coordinates in \(^{K 3}\), we employ a variance-exploding forward diffusion process for the coordinates:

\[q(}_{t}^{C}|}_{0}^{C})=(}_{0} ^{C},_{t}^{2})\] (8)

where \(_{1},,_{T}\) are noise levels. The corresponding reverse diffusion sampling process is:

\[q(}_{t-1}^{C}|}_{t}^{C},)=( }_{t}^{C}-^{2}-_{t-1}^{2}}_{_{t}^{C},},^{2}(_{t}^{2}-_{t-1}^{2})}{ _{t}^{2}})\] (9)

We refer interested readers to Song et al. 67 for a more detailed derivation of the variance-exploding diffusion process. We use the same noise schedule as Song et al. 67: \(_{t}=_{}(}{_{}})^{ }\). We handle the denoising target under periodicity similarly as Xie et al. 73 and direct readers interested in further details to this reference.

To train the denoising score network \(_{}\), we use the following loss functions:

\[_{}=_{t,^{C},_{}}[|| _{}-_{_{t}^{C},}||^{2}]_{}=_{t,^{C},_{}} [_{t}^{2}||_{}-_{_{t}^{C},}||^ {2}]\] (10)

where \(_{},_{}(,)\) are sampled Gaussian noises, injected through the forward diffusion processes defined in Equation (6) and Equation (8). The reverse diffusion process defined in Equation (7) and Equation (9) are used for sampling MOF structures at inference time.

In addition to the diffusion losses \(_{}\) and \(_{}\), MOFDiff is also trained to predict the lattice parameters \(}\), the number of building blocks \(\) and property labels \(}\) from the latent code \(\). We use a mean squared error loss for the lattice parameters and the property labels, and a cross-entropy loss for the number of building blocks:

\[_{,K,}=||-}||^{2}+(K,)+||-}||^{2}\] (11)

The entire MOFDiff is then trained end-to-end with the loss function:

\[_{}=_{}+_{}+ _{,K,}+_{}_{}\] (12)

Where the \(_{}\) is the KL regularization for variational autoencoders. We did not use weighting over the different loss terms except for the KL regularization, which is weighted with \(_{}=0.01\). All hyperparameters are reported in Table 3.

The coarse-grained MOF structures generated by the diffusion model specify the lattice parameters, building block identities, and building block coordinates (the centroid of connection points). However, they do not specify the orientations of building blocks. The assembly algorithm finds the orientations of the building blocks to connect them to each other. Throughout the assembly process, we fix the centroids of the building blocks, the internal structures (atom relative coordinates) of the building blocks, and the lattice parameters. The building block orientations are the only variables that are allowed to change (Figure 7). As we change the orientation of a building block, all atoms and connection points within rotate around its centroid.

For any ground truth structure, the connection points (as defined in Appendix A) of adjacent building blocks will perfectly overlap since they are midpoints of the bonds connecting inter-building-block atoms. Therefore, a viable objective for the assembly algorithm is to maximize the overlap of compatible inter-building-block connection points. Two connection points are compatible if (1) one connection point is from a metal atom, and the other is from a non-metal atom; (2) they are not from the same building block. We denote the set of all connection points as \(\), the number of connection points as \(C\), the coordinate of connection point \(i\) as \(_{i}\), the Euclidean distance between connection points \(i\) and \(j\) as \(d_{ij}:=||_{i}-_{j}||\), and the connection points compatible with \(i\) as \(_{i}\). We define the objective function:

\[_{,k,}=-_{i}_{j _{i}}(}{^{2}})[||\{q:q_{i },d_{iq} d_{ij}\}|| k)\] (13)Where \(\) is the indicator function. This loss can be thought of as measuring the inverse of the overlap under a Gaussian kernel of width \(\), and the overlap is only evaluated for the \(k\) nearest neighbors among the compatible connection points. Minimizing this loss maximizes the overlap. This loss is related to the building block orientations because the coordinate of a connection point \(_{i}\) is related to the orientation \(_{a}\) (under the axis-angle representation) and CG coordinate \(_{a}^{C}\) of the corresponding building block \(a\) through:

\[_{i}=_{a}^{C}+_{a,i}_{a}\] (14)

where \(_{a,i}\) is the vector from the building block centroid to the connection point under a canonical orientation (which is invariant throughout the assembly process), and \(_{a}\) is the rotation matrix corresponding to \(_{a}\). The distance between a pair of connection points \(d_{ij}\) can then be related to the orientations of the two corresponding building blocks through Equation (14). \(_{0,k,}\) is twice-differentiable with respect to building block rotations \(\) for all building blocks as \(_{0,k,}\) is twice-differentiable with respect to \(d_{ij}\) for all connection points \(i,j\), and \(d_{ij}\) is twice-differentiable with respect to \(_{a}\) and \(_{b}\). This allows us to use L-BFGS, a second-order optimization algorithm.

We can now define an annealed optimization process by gradually reducing \(\) and \(k\): at the beginning, the width \(\) and the number of other connection points we evaluate overlap with \(k\) are high, so it is easier to find overlap between connection points, and the optimization problem becomes smoother. This makes it simpler to find an approximate solution. At the end of optimization, the kernel width \(\) is small, and we are only computing the overlap for the closest compatible connection points. At this stage, the algorithm should have already found an approximate solution, and a stricter evaluation over overlapping can let the algorithm find more accurate orientations for matching the connection points closely.

The assembly algorithm starts by randomly initializing the orientations of the building blocks. Using the L-BFGS method, the algorithm iteratively minimizes \(_{0,k,}\) by adjusting the building block orientations \(\): \(_{a_{i}^{C}}\) (using the axis-angle representation) for all building blocks \(a_{i}^{C}\). We use the axis-angle representations because rotation matrices need to follow specific constraints. As explained above, we start with a relatively high \(\) and \(k\) and gradually reduce them in the optimization process to gradually refine the optimized orientations. The full algorithm is shown in Algorithm 1. In our experiments, we use 3 rounds: \(U=3\), with \(=[3,1.65,0.3]\) and \(k=\). An example assembly process is visualized in Figure 7.

```
1:Input: MOF structure \(=(^{C},^{C},)\), the number of optimization rounds \(U\), Gaussian kernel width \(_{1}>>_{U}\), number of nearest neighbors for overlap evaluation \(k_{1}>>k_{U}\)
2:Output: Building block orientations: \(=\{_{a_{i}^{C}}a_{i}^{C}^{C}\}\)
3:Randomly initialize building block orientations \(\)
4:for round \(u=1,,U\)do
5: Let \(_{u}\), \(k k_{u}\)
6: minimize \(_{0,k,}()\) with respect to \(\) using L-BFGS
7:endfor ```

**Algorithm 1** Optimize building block orientations for MOF assembly

**Force field relaxation.** The relaxation process is modified from a workflow proposed in Nandy et al. (52) and has four rounds of energy minimization using the UFF force field and the conjugate gradient algorithm in LAMMPS. At each round, we use LAMMPS's minimize function with \( 10^{-8}\), \( 10^{-8}\), \( 10^{6}\), and \( 10^{6}\). In the first and third rounds, we only relax the atom coordinates while keeping the lattice parameters frozen. In the second and fourth rounds, we relax both atom coordinates and the lattice parameters. The relaxation process can refine the all-atom structures based on the complete MOF configuration and correct minor errors in the previous steps (such as slightly smaller/bigger unit cells). Structural optimization using classical force field is commonly done in materials and MOF design .

## Appendix D Generate valid and novel MOF structures

**Determine the validity and novelty of MOF structures.** Assessing MOF validity is generally challenging. We employ a series of validity checks:1. The number of metal connection points and the number of non-metal connection points should be equal. We call this criterion Matched Connection.
2. The MOF atomic structure should successfully converge in the force field relaxation process.
3. For the relaxed structure, we adopt MOFChecker to check validity. MOFChecker includes a variety of criteria: the presence of metal and organic elements, porosity, no overlapping atoms, no non-physical atomic valences or coordination environments, no atoms or molecules disconnected from the primary MOF structure, and no excessively large atomic charges. We refer interested readers to Jablonka 31 for details.

We say a MOF structure is **valid** if all three criteria above are satisfied. For novelty, we adopt the MOF identifier extracted by MOFid and say a MOF is **novel** if its MOFid differs from any other MOFs in the training dataset. We also count the number of **unique** generations by filtering out replicate samples using their MOFid. We are ultimately interested in the valid, novel, and unique (VNU) MOFs discovered.

**MOFDiff generates valid and novel MOFs.** A prerequisite for functional MOF design is the capability to generate novel and valid MOF structures. We randomly sample 10,000 latent vectors from \((,)\), decode through MOFDiff, assemble, and apply force field relaxation to obtain the atomic structures. Figure 9 shows the number of MOFs satisfying the validity and novelty criteria: out of the 10,000 generations, 5,865 samples satisfy the matching connection criterion; 3012 samples satisfy the validity criteria, and 2998 MOFs are valid, novel, and unique. To evaluate the structural diversity of the MOFDiff samples, we investigate the distribution of four important structural properties calculated with Zeo++: the diameter of the smallest passage in the pore structure, or pore limiting diameter (PLD); the surface area per unit mass, or gravimetric surface area; the mass per unit volume, or density; and the ratio of total pore volume to total cell volume, or void fraction . These structural properties, which characterize the geometry of the pore network within the MOF, have been shown to correlate directly with important properties of the bulk material . The distributions of MOFDiff samples and the reference distribution of BW-DB are shown in Figure 8. We observe that the property distribution of generated samples matches well with the reference distribution of BW-DB, covering a wide range of property values.

## Appendix E Experiment Details

The BW-DB dataset contains 304k MOFs with less than 20 building blocks (as defined by the metal-oxo decomposition algorithm) from the 324k MOFs in Boyd et al. 6. We limit the size of MOFs within the dataset under the hypothesis that MOFs with extremely large primitive cells may be difficult to synthesize. The median lattice constant in the primitive cell of an experimentally realized MOF in the Computation-Ready, Experiment (CoRE) MOF 2019 dataset is, for example, only 13.8

Figure 8: MOFDiff samples match the reference distribution for various structural properties.

Figure 9: The validity of MOFDiff samples for increasingly strict criteria. “Match” stands for matched connection. “VNU” stands for valid, novel, and unique. Almost all valid samples are also novel and unique. The last column shows the validity percentage of BW-DB under our criteria.

A . We use 289k MOFs (95%) for training and the rest for validation. We do not keep a test split, as we evaluate our generative model on random sampling and inverse design capabilities.

**Molecular simulations for gas adsorption property calculations.** For faithful evaluation, we carry out grand canonical Monte Carlo (GCMC) simulations to calculate the gas adsorption properties of MOF structures. We implement the protocol for simulation of CO\({}_{2}\) separation from simulated flue gas with vacuum swing regeneration proposed in Boyd et al. 6 from scratch, using equlp to calculate per-atom charges on the MOF  and RASPA2 to carry out GCMC simulations  since the original simulation code is not publicly available. Parameters for CO\({}_{2}\) and N\({}_{2}\) were taken from Garcia-Sanchez et al. 21 and TraPPE , respectively. Under this protocol, the adsorption stage considers the flue exhaust a mixture of CO\({}_{2}\) and N\({}_{2}\) at a ratio of 0.15:0.85 at 298 K and a total pressure of 1 bar. The regeneration stage uses a temperature of 363 K and a vacuum pressure of 0.1 bar for desorption. Figure 10 shows the benchmark results of our implementation compared to the original labels of BW-DB, which demonstrate a strong positive correlation with our implementation underestimating the original labels by an average of around 30%. MOFDiff is trained over the original BW-DB labels and uses latent-space optimization to maximize the BW-DB property values. In the final evaluation, we use our re-implemented simulation code.

**Further details on molecular simulations.** Per-atom charges on the MOF were calculated with equlp using the MEPO parameter set and the default configuration. GCMC simulations were per

Figure 11: Principle component analysis of the MOFDiff latent space of the validation set, color-coded with various structural and gas adsorption properties.

Figure 10: Benchmark GCMC results. PCC stands for “Pearson correlation coefficient”.

formed with RASPA2 using the default configuration unless otherwise noted. Charge-charge interactions were modeled with Ewald sums at a precision of \(1 10^{-6}\) J. Other interactions were modeled with the Lennard-Jones 12-6 potential using UFF parameters for the MOF atoms with the epsilon parameters scaled by 0.635, parameters from Garcia-Sanchez et al. 21 for CO\({}_{2}\), and TraPPE parameters for N\({}_{2}\). A 12.0 Acutoff was applied to all interactions, with potentials shifted to zero at the cutoff radius. The minimum sized supercell was constructed for each MOF such that all lattice vectors were greater than 24.0 Ain length. The allowed Monte Carlo moves for gas atoms were identity change, swap, translation, rotation, and reinsertion at a likelihood ratio of 2:2:1:1:1, and the MOF atoms were held constant throughout the simulation.

Simulations were run for 2000 equilibrium cycles followed by 2000 production cycles, with the uptake of each gas calculated as the average loading over the 2000 production cycles as implemented in RASPA2. Similarly, each enthalpy of adsorption was calculated as the average internal energy of guest molecules within the MOF averaged over the 2000 production cycles as implemented in RASPA2 and converted to heat of adsorption by changing the sign. Adsorption conditions were modeled using a mixture of CO\({}_{2}\) and N\({}_{2}\) at a partial pressure ratio of 0.15:0.85, an external temperature of 298 K, and an external pressure of 1 bar. Regeneration conditions were modeled using only CO\({}_{2}\), an external temperature of 363 K, and an external pressure of 0.1 bar. Working capacity was calculated as the difference in CO\({}_{2}\) uptake under adsorption and regeneration conditions. CO\({}_{2}\)/N\({}_{2}\) selectivity was calculated as the ratio of each gas's respective uptake under adsorption conditions.

Figure 10 shows a benchmark that compares the gas adsorption labels obtained from BW-DB (original labels) and the labels obtained from our workflow (our implementation) for 5,000 randomly sampled MOFs from BW-DB. The Pearson correlation coefficient (PCC) is also reported for each property. We observe a strong positive correlation, while the working capacity is generally underestimated. Our model is trained with the original labels, and for property optimizing inverse design, we use a property predictor trained over the original labels. Our model still demonstrates significant property improvement (Figure 3), which demonstrates the robustness of our method under a shifted property evaluator.

**MOF latent space.** In Figure 11, we conduct a principle component analysis  to produce two-dimensional visualization of the MOFDiff latent space. The latent space exhibits smooth transitions for property values, indicating a smooth property landscape.

    & CO\({}_{2}\) working & CO\({}_{3}\)/N\({}_{2}\) & CO\({}_{2}\) uptake [mol/kg] & CO\({}_{3}\) uptake [mol/kg] & CO\({}_{2}\) heat & CO\({}_{2}\) absorption [kcal/mol] & adsorption [kcal/mol] \\  & capacity [mol/kg] & selectivity & (0.15 bar, 298 K) & (0.1 bar, 363 K) & (0.1 bar, 298 K) & (0.1 bar, 363 K) \\  MOPDiff-1 & 4.89 & 197.66 & 7.05 & 2.16 & 10.13 & 10.05 \\ MOPDiff-2 & 4.86 & 65.17 & 6.57 & 1.71 & 9.39 & 9.00 \\ MOPDiff-3 & 4.03 & 39.55 & 5.08 & 1.05 & 7.85 & 8.44 \\ MOPDiff-4 & 4.03 & 26.21 & 4.85 & 0.82 & 9.05 & 8.41 \\ MOPDiff-5 & 3.87 & 1026.38 & 13.27 & 9.40 & 12.61 & 11.27 \\ AI-PMPC & 3.82 & 8.74 & 4.95 & 1.13 & 6.97 & 8.26 \\ MOPDiff-6 & 3.80 & 73.34 & 4.73 & 0.93 & 9.13 & 9.02 \\ MOPDiff-7 & 3.70 & 19.80 & 4.28 & 0.57 & 7.36 & 7.90 \\ MOPDiff-8 & 3.65 & 50.62 & 4.68 & 1.02 & 8.94 & 8.98 \\ MOPDiff-9 & 3.61 & 19.13 & 4.18 & 0.57 & 8.07 & 7.77 \\ MOPDiff-10 & 3.61 & 45.60 & 4.57 & 0.96 & 9.41 & 9.51 \\ InOF-1 & 3.11 & 9.26 & 3.43 & 0.32 & 7.61 & 6.69 \\ Ni-APC & 2.53 & 11.18 & 3.46 & 0.92 & 8.29 & 7.71 \\ MIL-5/3A[] & 2.26 & 5.16 & 2.57 & 0.31 & 6.50 & 6.09 \\ MOOFU-1Ni & 2.15 & 21.13 & 2.64 & 0.49 & 8.41 & 8.01 \\ UO-66 & 2.11 & 19.15 & 2.70 & 0.59 & 7.82 & 8.72 \\ AIFu & 2.08 & 5.30 & 2.46 & 0.38 & 6.95 & 6.45 \\ SIFSN3-Ca & 1.22 & inf & 2.69 & 1.47 & 11.80 & 11.79 \\ NORT-400 & 0.95 & 3.57 & 1.09 & 0.13 & 6.03 & 5.54 \\ MOF-14Cu & 0.88 & 3.11 & 1.02 & 0.14 & 5.93 & 5.66 \\ DORO3-Ni4 & 0.61 & 10.36 & 0.69 & 0.07 & 7.54 & 7.47 \\ MIL-100Fe & 0.53 & 3.61 & 0.63 & 0.10 & 5.82 & 6.88 \\ MIL-101 & 0.38 & 2.87 & 0.46 & 0.08 & 5.29 & 5.06 \\ CuBTC & 0.36 & 2.21 & 0.45 & 0.09 & 5.52 & 5.82 \\ DMOF-1 & 0.35 & 2.10 & 0.41 & 0.07 & 5.07 & 4.82 \\ ZIF-8 & 0.33 & 2.42 & 0.38 & 0.05 & 5.37 & 5.16 \\ MIL-125C(Ti)-NH2 & 0.27 & 1.71 & 0.32 & 0.05 & 4.86 & 4.70 \\ MOF-5 & 0.09 & 1.02 & 0.12 & 0.03 & 3.34 & 3.11 \\   

Table 1: Carbon capture properties of top ten MOFDiff optimized samples and MOFs from previous literature, sorted by CO\({}_{2}\) working capacity.

**Compare to literature MOFs.** In Table 1, we compare the top-ten MOFs generated by MOFDiff and 18 MOFs from previous literature . Notably, Al-PMOF was proposed in Boyd et al. 6, synthesized, and validated through real-world experiments.

**Software versions.** MOFid-v1.1.0, MOFChecker-v0.9.5, egulp-v1.0.0, RASPA2-v2.0.47, LAMMPS-2021-9-29, and Zeo++-v0.3 are used in our experiments. Neural network modules are implemented with PyTorch-v1.11.0 , Pyg-v2.0.4 , and Lightning-v1.3.8  with CUDA 11.3.

**Code availability.** Source code will be released upon publication.

## Appendix F Conclusion

We proposed MOFDiff, a coarse-grained diffusion model for metal-organic framework design. Our work presents a complete pipeline of representation, generative model, structural relaxation, and molecular simulation to address a specific carbon capture materials design problem. To design 3D MOF structures without using pre-defined templates, we derive a coarse-grained representation and the corresponding diffusion process. We then design an assembly algorithm to realize the all-atom MOF structures and characterize their properties with molecular simulations. MOFDiff can generate valid and novel MOF structures covering a wide range of structural properties as well as optimize MOFs for carbon capture applications that surpass state-of-the-art MOFs in molecular simulations.

One limitation of MOFDiff is its generated samples have a lower validity rate when the size of the MOF becomes bigger. Figure 12 shows a declining validity percentage for samples of more building blocks. This result is unsurprising since a bigger MOF with more building blocks is inherently more complex. For a generated structure to be valid, the coordinates of every atom need to be correct, especially at every connection. The lattice parameters also need to be very accurate. Reformulating the diffusion process to enable the iterative refinement of the lattice parameters through the generation process and regularizing the diffusion process with known templates are two future directions to overcome this challenge.

   Hyperparameter & Value \\  building block embedding dimension & \(32\) \\ GNN hidden layer dimension & \(256\) \\ projection dimension & \(128\) \\ \# encoder GNN layers & \(3\) \\ radius cutoff & \(20\) \\ maximum number of neighbors & \(50\) \\ temperature (\(\)) & \(0.1\) \\ \(_{}\) & \(0.0001\) \\ batch size & \(512\) \\ optimizer & Adam \\ initial learning rate & \(0.0003\) \\ learning rate scheduler & ReduceLROnPlateau \\ learning rate patience & \(10\) epochs \\ learning rate factor & \(0.6\) \\   

Table 2: Hyperparameters for building block representation learning.

Figure 12: The percent of valid samples declines with more building blocks.

   Hyperparameter & Value \\  latent dimension & \(256\) \\ GNN hidden layer dimension & \(256\) \\ \# encoder GNN layers & \(3\) \\ \# decoder GNN layers & \(3\) \\ radius cutoff & \(4\) \\ maximum number of neighbors & \(24\) \\ total number of diffusion steps (\(T\)) & \(2000\) \\ \(_{}\) for coordinate diffusion & \(0.001\) \\ \(_{}\) for coordinate diffusion & \(10\) \\ noise schedule for coordinate diffusion & \(_{t}=_{}(}{_{}})^{ }\) \\ noise schedule for embedding diffusion & Hoogeboom et al. 29 \\ time step embedding & Fourier \\ time step embedding dimension & \(64\) \\ \(_{}\) & \(0.01\) \\ batch size & \(128\) \\ optimizer & Adam \\ initial learning rate & \(0.0003\) \\ learning rate scheduler & ReduceLROnPlateau \\ learning rate patience & \(50\) epochs \\ learning rate factor & \(0.6\) \\   

Table 3: Hyperparameters for MoFDiff.