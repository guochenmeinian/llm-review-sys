# Bootstrapping Top-down Information for

Self-modulating Slot Attention

 Dongwon Kim\({}^{1}\)   Seoyeon Kim\({}^{1}\)   Suha Kwak\({}^{1,2}\)

Dept. of CSE, POSTECH\({}^{1}\)   Graduate School of AI, POSTECH\({}^{2}\)

{kdwon, syeonkim07, suha.kwak}@postech.ac.kr

###### Abstract

Object-centric learning (OCL) aims to learn representations of individual objects within visual scenes without manual supervision, facilitating efficient and effective visual reasoning. Traditional OCL methods primarily employ bottom-up approaches that aggregate homogeneous visual features to represent objects. However, in complex visual environments, these methods often fall short due to the heterogeneous nature of visual features within an object. To address this, we propose a novel OCL framework incorporating a _top-down pathway_. This pathway first bootstraps the semantics of individual objects and then modulates the model to prioritize features relevant to these semantics. By dynamically modulating the model based on its own output, our _top-down pathway_ enhances the representational quality of objects. Our framework achieves state-of-the-art performance across multiple synthetic and real-world object-discovery benchmarks.

## 1 Introduction

Object-centric learning (OCL) is the task of learning representations of individual objects from visual scenes without manual labels. The task draws inspiration from the human perception which naturally decomposes a scene into individual entities for comprehending and interacting with the real world visual environment. Object-centric representations provides improved generalization and robustness , and have been proven to be useful for diverse downstream tasks such as visual reasoning , simulation , and multi-modal learning . In this context, OCL which learns such representations without labeled data has gained increasing attention.

A successful line of OCL builds upon slot attention . This method decomposes an image into a set of representations, called slots, that iteratively compete with each other to aggregate image features. Reconstructing the original image from the slots, they are encouraged to capture entities constituting the scene. This simple yet effective method has been further advanced by novel encoder or decoder architectures , optimization technique , and new query initialization strategies .

It is worth noting that all these methods are fundamentally considered bottom-up models, as they rely on aggregating visual features without incorporating high-level semantic information from the beginning. This bottom-up approach assumes that visual features within an object are homogeneous and can be clustered in the feature space, which only holds for simplistic objects that can be identified using low-level cues such as color . In complex real-world scenarios where visual entities of the same semantics exhibit diverse appearances, this homogeneity often breaks down, leading to suboptimal object representations . Thus, we take an approach different from the previous line of research: _introducing top-down information into slot attention_, such as object categories and semantic attributes.

Incorporating top-down information enables slot attention to specialize in discerning objects within specific semantic categories. For instance, identifying vehicles in a complex urban environment can be challenging due to the diverse and cluttered nature of the scene. Top-down information can guide the model to prioritize vehicle-specific features, such as wheels and windows. This inhibits the contributions of irrelevant features when computing slots, and enhances the aggregation of visual features of individual vehicles into slots. Nevertheless, devising such a top-down approach is not straightforward since OCL assumes an unsupervised setting without any labeled data, making it hard to identify and exploit the high-level semantics typically obtained from annotated datasets.

We propose a novel framework that incorporates a _top-down pathway_ into slot attention to provide and exploit top-down semantic information; Fig. 1 illustrates of our framework. The pathway consists of two parts: bootstrapping semantics and exploiting them for better representations. Firstly, top-down semantic information is bootstrapped from the output of slot attention itself, by mapping continuous slots to discrete codes selected from a finite learned codebook. Such an approach allows the codebook to learn prevalent semantics in the dataset, with each code representing a specific semantic concept. Thus, semantic information can be bootstrapped without any object-level annotations and used to provide top-down semantic information. Secondly, slot attention is modulated using bootstrapped top-down cues obtained from the first phase, which we call self-modulation. In this phase, the _top-down pathway_ dynamically guides the slot attention by re-scaling its inner activations based on the top-down information. This self-modulation process enables the model to focus on feature sub-spaces where object homogeneity is more consistent, thereby improving its performance in diverse and realistic settings.

Our contributions are threefold:

* We introduce a method to bootstrap top-down semantic information from the output of slot attention, without requiring any object-level annotations. This allows the extraction of high-level semantic cues from an unsupervised learning process.
* We propose a self-modulation scheme that dynamically guides the slot attention's inner activations to enhance object representation, successfully incorporating the top-down semantic cues extracted.
* By integrating the proposed _top-down pathway_ into slot attention, we demonstrate that the performance of object discovery is largely improved on various OCL benchmarks.

## 2 Related Work

**Object-centric learning** OCL aims to learn representations of individual objects within an image. The 'object-centric' dimension is orthogonal to the conventional representation learning which learns representations independent of the composition of the image. The structured nature of

Figure 1: The overall pipeline of our framework. A _top-down pathway_ is introduced into slot attention to utilize top-down information. The pathway consists of two parts: bootstrapping top-down knowledge and exploiting them. Firstly, semantic information is bootstrapped from slot attention outputs by mapping slots to discrete codes from a learned codebook through vector quantization. Secondly, slot attention is modulated using these codes and its attention maps, transforming it into a self-modulating module. Inner activations are modulated across channels with codes and across space with centered attention maps. Slot attention is then repeated with these modulated activations, yielding more representative slots.

object-centric representations offers improved generalization , making it valuable for various applications, including visual reasoning , dynamics simulation , and multi-modal learning [23; 24]. A foundational method in this field is slot attention , which introduced a simple yet effective framework that employs a competitive attention mechanism between slots. Following slot attention, many recent works have proposed improvements by introducing novel encoder or decoder formulations [33; 19; 46; 35], optimization techniques [18; 6], additional slot refinement modules [37; 25; 3], and expansions to video modality [27; 11; 36]. These methods are primarily bottom-up models, while our approach proposes to bootstrap and incorporate top-down information.

**Incorporating top-down information** The human visual system perceives scenes by leveraging both top-down and bottom-up visual information [4; 8]. Top-down information represents task-driven contextual cues, such as high-level semantics and prior knowledge about the scene. In contrast, bottom-up information is derived directly from the sensory input. Inspired by this dual-processing mechanism of the human visual system, several studies [34; 1; 48] have attempted to model this approach within deep learning, achieving significant improvements across various tasks. Our work follows in a similar direction, specifically focusing on introducing top-down information into the representative OCL method, slot attention. By incorporating top-down semantic and spatial information, we aim to enhance the performance of slot attention in diverse visual environments, addressing the limitations of previous bottom-up methods

**Discrete representation learning** Discrete representations within neural networks are considered effective for modeling discrete modalities [50; 38] and tackling generation tasks [13; 28]. Particularly, the pioneering work, VQ-VAE , introduced a method for learning discrete latent representations through vector quantization. This model uses a discrete codebook, where the encoder maps input data to discrete codes using nearest-neighbor lookup and the decoder reconstructs the input from the codes. Another notable approach is the Gumbel-softmax trick [17; 32], which provides a differentiable approximation of sampling from a categorical distribution. Recent advancements have aimed to incorporate a more sophisticated formulation of codebooks  or improve codebook utilization  to better handle discrete representations. Recent work by Wallingford et al.  is related to our research in terms of using vector quantization for segmentation task. However, our method differs in that the quantized codes are used to modulate bottom-up slot attention, while in Wallingford et al. , the codes are used solely for segmentation labeling.

## 3 Method

We propose an OCL framework that incorporates top-down semantic information, such as object categories and semantic attributes, into slot attention through a _top-down pathway_. Fig. 1 illustrates the overall pipeline of our framework. Firstly, slot attention is applied to visual features extracted from an image encoder to output slots (Sec. 3.1). Then, a _top-down pathway_ leverages the slots to identify semantics in the input image and modulate slot attention. The pathway consists of two parts: bootstrapping top-down semantic information from a learned codebook and attention maps (Sec. 3.2) and modulating the inner activations of slot attention with this semantic information (Sec. 3.3). During the self-modulation stage, slot attention is repeated with the modulated activations, resulting in more representative slots.

### Slot Attention

Slot attention is a recurrent bottom-up module that aggregates image features into slots through an iterative attention process, where each of the resulting slots represent an entity in the input image. Within our framework, these slots are used to bootstrap top-down information in the later stage (Sec. 3.2).

The module takes in the initial slots, \(^{0}^{K D}\), and visual features extracted from an image encoder, \(^{N D_{}}\). The initial slots are obtained by sampling \(K\) vectors from a learnable Gaussian distribution using a reparameterization trick. The slots \(=[_{1},_{2},,_{K}]^{K D}\), where each represents an individual object in the image, are computed by iteratively updating the initial slots \(T\) times as

\[:=^{T},\ \ ^{t+1}= ,^{t}. \]

In each iteration, the slots attend to the visual features, refining their representations through a series of attention-based updates. Let \(q()\), \(k()\), and \(v()\) represent linear projections from dimension \(d\) to 

[MISSING_PAGE_EMPTY:4]

where \(}\) represents the slots from the self-modulating slot attention, different from the slots of the original slot attention denoted by \(\). Note that the original slot attention (Sec. 3.1) and self-modulating slot attention share parameter weights and initial slots, such that \(^{0}=}^{0}\).

Specifically, we modulate slot attention with a modulation map \(_{k}^{N D}\) computed from \(_{k}^{*}\) and \(_{k}\). Each element of the modulation map represents the relevance score between the corresponding visual feature element and the top-down information of the expected object. This modulation map can be used to guide the update of each slot \(}_{k}\) (Eq. 3), by prioritizing specific value elements with the high relevance scores. In the self-modulating slot attention, computation of the slot update \(\) is replaced with:

\[=[_{1},_{2},,_{K}]^{K  D},\ \ _{k}=_{k}(_{k} v)), \]

where \(\) represents Hadamard product. Such re-scaling of the value features with the modulation map ensures that the specific channel dimension or regions contribute more to the update of each slot, based on the semantics or locations encoded in bootstrapped top-down information.

The modulation map \(_{k}\) is computed by taking the outer product between channel-wise and spatial-wise modulation vectors, which are predicted using \(_{k}^{*}\) and \(_{k}\), respectively:

\[_{k}=_{k}^{s}_{k}^{c}^{N D}. \]

For predicting channel-wise modulation vector \(_{k}^{c}\), quantized slot \(_{k}^{*}\) is used, which tells us "_what_" the object appearing in the image is. The channel-wise scaling is designed to enforce the model to focus on certain feature subspaces closely correlated to the semantic concept identified. Specifically, channel-wise modulation vector \(_{k}^{c}\) can be obtained by feeding quantized slot \(_{k}^{*}\) to the MLP, which is represented as:

\[_{k}^{c}=(_{k}^{*})^{D}. \]

The spatial-wise modulation vector \(_{k}^{s}\) can be obtained by further processing the attention map of each slot, which contains the top-down information on the location of the semantic concept:

\[_{k}^{s}=1+(_{k}-_{k}})^{N}, \]

where \(_{k}}\) is for the average of the attention score of \(_{k}\). Using an attention map as is for modulation will make all values down-scaled, while some regions likely to contain the object should be highlighted for effective incorporation of the spatial top-down information. Thus, we use the attention map shifted to have a mean value of 1 for the spatial-wise modulation map.

### Training

Slot attention is trained within an autoencoding framework, using a decoder that reconstructs visual features output by the image encoder [35; 33] or the original image  from the slots. In this paper, we choose the visual feature reconstruction as our training objective since it is known to provide more robust training signals for real-world datasets . We also employ a vector quantization objective for the codebook \(\) only, which thereby learns to minimize the mean-squared error between the slot and the sampled codes. The reconstruction objective \(_{}\) and vector quantization objective \(_{}\) are given by

\[_{}=\|(};)-\| _{2}^{2},_{}=\|()-^{*}\|_{2}^ {2}, \]

where \(()\) represents stop gradient operation and \(^{*}=[_{1}^{*},_{2}^{*},,_{K}^{*}]^ {K D}\). For the decoder, we utilized the autoregressive slot decoder [35; 33]. The reconstruction objective ensures that the learned slot representations capture essential information about the objects in the scene, while the vector quantization objective encourages the codebook to capture recurring semantic concepts in the dataset.

## 4 Experiments

### Experimental Settings

#### 4.1.1 Datasets

To verify the proposed method in diverse settings, including synthetic and authentic datasets, we considered four object-centric learning benchmarks: MOVI-C , MOVI-E , PASCAL VOC 2012 , and MS COCO 2017 . MOVI-C and MOVI-E are synthetic datasets, adopted for validating our method in relatively simple visual environments. MOVI-C contains 87,633 images for training and 6,000 images for evaluation, while MOVI-E contains 87,741 and 6,000, respectively. To evaluate the proposed model in real-world settings, we leverage the VOC and COCO datasets. Following DINOSAUR , we use the trainaug variants, containing 10,582 training images, for VOC dataset. For the evaluation, we use the validation split containing 1,449 images. The COCO dataset consists of 118,287 training images and 5,000 images for evaluation. While the VOC dataset includes some images with a single object, images of the COCO dataset always contain 2 or more objects, making it the most challenging. MOVI datasets are licensed under apache license 2.0 and COCO is licensed under CC-BY-4.0.

#### 4.1.2 Metrics

We evaluate our method with three metrics: foreground adjusted random index (FG-ARI), mean best overlap (mBO), and mean intersection over union (mIoU). The FG-ARI is the ARI metric computed for foreground regions only (objects), which measures the similarity between different clustering results. The mBO and mIoU are both IoU-based metrics, computed for all regions including the background. The mBO computes the average IoU between ground truth and prediction pairs, obtained by assigning each prediction to the ground truth mask with the largest overlap. The mIoU is computed as the average IoU between ground truth and prediction pairs obtained from Hungarian matching. For COCO and VOC, mBO\({}^{i}\) and mBO\({}^{c}\) indicate the mBO metric computed using semantic segmentation and instance segmentation ground truth. We use the instance segmentation ground truth for other metrics. Following previous work , the internal attention maps of the autoregressive decoder are used as the mask prediction results of the slots.

#### 4.1.3 Implementation details

To assess the effectiveness of the proposed top-down pathway, our model is implemented based on DINOSAUR , a representative slot-based OCL method. For the encoder and decoder, we use a DINO  pretrained ViT-B/16  and an autoregressive transformer decoder [35; 33], respectively. The model is trained using an Adam optimizer  with an initial learning rate of 0.0004, while the encoder parameters are not trained. The number of slots \(K\) is set to 11, 24, 7, and 6 for MOVI-C, MOVI-E, COCO, and VOC, respectively. The codebook size \(E\) is set to 128 for synthetic datasets (MOVI-C and MOVI-E) and 512 for authentic datasets (COCO and VOC). The model is trained for 250K iterations on VOC and for 500K iterations on the others. For the ablation study and analysis, models are trained for 200K iterations on COCO, as this was enough to reveal overall trends given limited computational resources. Full training of the model takes 26 hours using a single NVIDIA RTX 3090 GPU.

#### 4.1.4 Codebook size \(E\) selection

The performance of the proposed _top-down pathway_ depends on codebook size \(E\) (Sec. 4.4), necessitating a principled selection method. We determine \(E\) automatically by monitoring the perplexity of code usage distribution during training, requiring only the training set without validation data. Perplexity--the exponent of entropy--indicates how uniformly the codes are being used. While perplexity typically increases with codebook size, it plateaus when \(E\) exceeds the number of distinct semantic patterns in the data, as some codes become unused [16; 49; 28]. To find the optimal size, we start with \(E=64\) and double it until the perplexity plateaus after 250K iterations. For example, on COCO, the perplexity when the codebook size is 256, 512, and 1024 are 

[MISSING_PAGE_FAIL:7]

refines the attention maps, depending on how well they have captured the scene. For example, when the attention map is well-structured but coarse, the modulation process refines the boundaries of the attention map without changing the overall layout (first row). However, if the attention maps fail to delineate objects, the modulation process recomposes the attention maps to differentiate objects (second to fourth row). By providing top-down semantic and spatial information via self-modulation, the attention maps are enhanced to capture the object within complex real-world environments.

### In-depth Analysis

#### Effect of codebook size

In our framework, vector quantization maps slots to distinct top-down semantic information stored in the codebook, as shown in Fig. 2. In Tab. 4, we report the performances across different codebook sizes, \(E\). The results show that a codebook size too large (\(E=1024\)) or small (\(E 256\)) leads to performance degradation. When the codebook size is too small, the codes cannot sufficiently learn distinct semantic information, which degrades the quality of the bootstrapped top-down semantic information. On the other hand, a codebook size too large may cause the codes to capture irrelevant details such as appearance variance or positional information rather than meaningful semantic concepts. However, we determine the optimal codebook size automatically using the perplexity of codebook usage during training (Sec. 4.1), eliminating the need for extensive hyperparameter tuning using validation split and benchmark metrics.

    &  &  &  &  \\   & FG-ARI & mBO\({}^{i}\) & FG-ARI & mBO\({}^{i}\) & FG-ARI & mBO\({}^{i}\) & FG-ARI & mBO\({}^{i}\) \\  Slot Attention  & 21.4 & 17.2 & 12.3 & 24.6 & 43.8\(\)0.3 & 26.2\(\)1.0 & 45.0\(\)1.7 & 24.0\(\)1.2 \\ SLATE  & 32.5 & 29.1 & 15.6 & 35.9 & 49.54\(\)1.4 & 39.4\(\)0.8 & 46.06\(\)3.3 & 30.2\(\)1.7 \\ DINOSAUR  & 34.1\(\)1.0 & 31.6\(\)0.7 & 24.8\(\)2.2 & 44.0\(\)1.9 & 55.7 & 42.4 & - & - \\ Rotating Features  & - & - & - & - & 40.7\(\)0.1 & - & - & - & - \\ SlotDiffusion  & 37.2 & 31.0 & 17.8 & **50.4** & - & - & **60.0** & 30.2 \\ LSD  & 35.0 & 30.4 & - & - & 52.0 & 45.6 & 52.2 & 39.0 \\  Ours & **37.4\(\)**0.0 & **33.3\(\)**0.3 & **26.7\(\)**4.7 & 43.9\(\)2.6 & **58.9\(\)**5.1 & **46.8\(\)**2.4 & 59.7\(\)3.1 & **39.3\(\)**1.8 \\   

Table 3: Comparison with state of the arts  on COCO , VOC , MOVI-C , and MOVI-E . Performances of Slot Attention on MOVI-C and -E are reproduced by  and that of SLATE by . Those on COCO and VOC are from .

Figure 2: Visualization of the codebook \(\) on COCO . The results show that the codebook learns to capture recurring semantic concepts in the dataset, such as ‘pizza’ (code 124), ‘sign’ (code 496), ‘clock’ (code 235), ‘zebra’ (code 207), ‘motorcycle’ (code 341), ‘surfer’ (code 352), ‘dog’ (code 359), and ‘skier’ (code 343).

Impact of increased iterationsSince our method requires repeating slot attention with self-modulation, we investigate whether our performance improvement simply comes from the increased iterations of slot attention. In Tab. 5, we compare the results of our model with the DINOSAUR baseline model using six iterations of slot attention, which is twice as many iterations as the default setting. Notably, both our model and the DINOSAUR 6-iteration model leverage the same number of iterations. The results show that the DINOSAUR model with six iterations actually performs worse compared to the default 3 iterations. This indicates that merely increasing the number of iterations does not guarantee improvement. Our method's superior performance is thus attributed to the self-modulation mechanism rather than the increased number of iterations.

Computation overhead of _top-down pathway_While our model requires one more forward pass for slot attention, the additional computation cost is negligible. In DINOSAUR, slot attention accounts for only 0.64% of the total FLOPs, compared to 71.26% for the encoder and 28.10% for the decoder. Consequently, our model requires 47.62 GFLOPs versus 47.32 GFLOPs of DINOSAUR--a mere increase below 1%. In practice, processing the entire COCO 2017 val split on a single NVIDIA RTX 3090 GPU takes 71.4 seconds for our model compared to 70.5 seconds for DINOSAUR, demonstrating minimal impact on inference time.

Codes representing broader semanticsWhile most codes in our codebook consistently represent single object categories, we observed interesting cases where codes capture broader concepts, as shown in Fig. 4. Some codes are trained to represent supercategories - for instance, grouping different animal species (code 468) or various human parts into shared codes (code 328). This suggests the codebook can flexibly adapt to different levels of semantic abstraction when beneficial. We also discovered an edge case where certain codes (e.g., code 223) specialize in capturing top-left patches of images. This behavior appears to be influenced by the autoregressive decoding process, which

   & 128 & 256 & 512 & 1024 \\  FG-ARI & 33.1 & 32.6 & **37.3** & 31.4 \\ mBO & 30.2 & 30.5 & **32.7** & 29.8 \\   
   & FG-ARI & mBO \\  DINOSAUR 6-iter & 28.5 & 28.2 \\ Ours & **37.3** & **32.7** \\  

Table 4: Comparison between different codebook sizes on COCO .

Figure 3: Visualization of the input image, predicted object mask, and attention maps of slot attention before and after self-modulation on COCO . Lighter the color, higher the attention score.

must reconstruct the top-left patch first without surrounding context. However, these specialized positional codes are rare (1-2 out of 512 codes) and have minimal impact on overall performance. Additionally, we found that certain codes specialize in capturing background elements common in natural scenes. For example, code 236 represents sky regions, code 133 captures sports fields, and code 508 represents crowd scenes.

**Ablation study** In Tab. 6, we present an ablation study of our method on COCO for channel-wise modulation, vector quantization, spatial-wise modulation, and attention map shifting. In the first row, the result with no modules is presented, which is equivalent to the baseline DINOSAUR model. The last row is the performance of using all four modules, equivalent to our proposed method. The second and third rows are for the ablation of vector quantization and channel-wise modulation, demonstrating that incorporating top-down semantic information significantly improves performance. In the fourth and fifth rows, the ablation of attention map shifting and spatial-wise modulation is presented. The results show that both operations are critical for the effective exploitation of top-down spatial information.

## 5 Conclusion

In this paper, we introduced an OCL framework that incorporates top-down information into the slot attention mechanism through a _top-down pathway_. In this pathway, the output of the slot attention is used to bootstrap high-level semantic knowledge and rough localization cues for existing objects. Using the bootstrapped top-down knowledge, slot attention is modulated to focus on features most relevant to the objects in the scene. Consequently, by incorporating the proposed _top-down pathway_ into slot attention, we achieved state-of-the-art performance on various OCL benchmarks, including challenging synthetic and authentic datasets.

**Limitation** The proposed _top-down pathway_ has a limitation in that its overall performance relies on the quality of the codebook learned during training. As shown in Tab. 4, an incorrect choice of codebook size can result in the codes failing to learn distinct semantic concepts or capturing irrelevant details. While we mitigate this limitation through perplexity-based automatic codebook size tuning, the more principled codebook design that can eliminate the need for a pre-defined hyperparameter, such as dynamically expanding codebook during learning , will be promising future research direction.

   \(^{c}\) & \(\)Q & \(^{s}\) & shift & FG-ARI & mBO \\    & DINOSAUR & & & 34.8 & 30.5 \\  ✓ & & ✓ & ✓ & 36.3 & 32.3 \\  & & ✓ & ✓ & 35.1 & 32.5 \\  ✓ & ✓ & ✓ & & 35.2 & 31.7 \\ ✓ & ✓ & & & 36.0 & 31.9 \\  ✓ & ✓ & ✓ & ✓ & **37.3** & **32.7** \\   

Table 6: Ablation studies on COCO dataset for each module consisting of the proposed top-down pathway: channel-wise modulation (\(^{c}\)), vector quantization (VQ), spatial-wise modulation (\(^{s}\)), and shifting attention map (shift).

Figure 4: Visualization of the codebook \(\) on COCO . The results show that the codebook learns to capture broader semantics other than single object categories, such as supercategory (code 468, 328), top-left patch (code 223), and background (code 236, 133, 508).