# Sample Efficient Bayesian Learning of

Causal Graphs from Interventions

 Zihan Zhou

Electrical and Computer Engineering

Purdue University

zhou1248@purdue.edu

&Muhammad Qasim Elahi

Electrical and Computer Engineering

Purdue University

elahi0@purdue.edu

&Murat Kocaoglu

Electrical and Computer Engineering

Purdue University

mkocaoglu@purdue.edu

Equal Contribution.38th Conference on Neural Information Processing Systems (NeurIPS 2024).

###### Abstract

Causal discovery is a fundamental problem with applications spanning various areas in science and engineering. It is well understood that solely using observational data, one can only orient the causal graph up to its Markov equivalence class, necessitating interventional data to learn the complete causal graph. Most works in the literature design causal discovery policies with perfect interventions, i.e., they have access to infinite interventional samples. This study considers a Bayesian approach for learning causal graphs with limited interventional samples, mirroring real-world scenarios where such samples are usually costly to obtain. By leveraging the recent result of Wienobst et al. (2023) on uniform DAG sampling in polynomial time, we can efficiently enumerate all the cut configurations and their corresponding interventional distributions of a target set, and further track their posteriors. Given any number of interventional samples, our proposed algorithm randomly intervenes on a set of target vertices that cut all the edges in the graph and returns a causal graph according to the posterior of each target set. When the number of interventional samples is large enough, we show theoretically that our proposed algorithm will return the true causal graph with high probability. We compare our algorithm against various baseline methods on simulated datasets, demonstrating its superior accuracy measured by the structural Hamming distance between the learned DAG and the ground truth. Additionally, we present a case study showing how this algorithm could be modified to answer more general causal questions without learning the whole graph. As an example, we illustrate that our method can be used to estimate the causal effect of a variable that cannot be intervened.

## 1 Introduction

Causal discovery refers to learning the underlying causal graph of a data generating process using a combination of observational and interventional data. This is a fundamental problem with applications across various areas including economics, genomics, meteorology, could computing, and etc. (Pearl, 2009; Hoover, 1990; King et al., 2004; Ikram et al., 2022; Runge et al., 2019). In recent decades, the technological progress has facilitated the accumulation of vast quantities of observational data, i.e., data collected without perturbing the underling causal mechanisms. However, with only observational data, one can only recover the causal graph up to its Markov equivalence class (MEC) (Verma, 1991; Andersson et al., 1997). In general, interventional data, i.e., data collected after a perturbation inthe system, is needed to learn the whole graph. Therefore, many recent works aim to use both observational and interventional data (Choo et al., 2022; Squires et al., 2020; Shanmugam et al., 2015; He and Geng, 2008; Hauser and Buhlmann, 2014).

These works use perfect \(do(X)\) intervention (Pearl, 2009) on a set of intervention targets \(X\) and can be categorized along various dimensions. One such dimension is whether they are adaptive or non-adaptive. Non-adaptive approaches (Shanmugam et al., 2015), determine the intervention targets before any interventions (experiments), whereas adaptive algorithms (Squires et al., 2020; Choo et al., 2022) can suggest the next intervention targets based on previous experiments. Non-adaptive methods can parallelize experiments, while adaptive ones are sequential but demand fewer interventions to learn the entire graph (Choo and Shiragur, 2023). These works provide theoretic guarantees that the experiments are sufficient to learn the graph. Jiang and Aragam (2024) established conditions under which latent causal graphs are nonparametrically identifiable and can be learned from unknown interventions.

Nevertheless, these studies operate under the assumption that an infinite amount of interventional data can be gathered after each intervention. However, in most real-world scenarios, collecting interventional data is considerably more challenging. For instance, while modern single-cell RNA sequencing technologies have facilitated the collection of vast amounts of gene expression data for downstream tasks (Stuart and Satija, 2019; Zhou et al., 2022), accurately perturbing each gene remains difficult (Chandrasekaran et al., 2024; Uhler and Shivashankar, 2017; Sharma et al., 2022). Consequently, practical applications tend to favor interventional methods that require fewer data, although this aspect receives less attention. To bridge this disparity, our work assumes access to an infinite oracle of observational data, while only a finite number of interventional samples can be acquired for each intervention.

Among those that consider a limited number of interventional samples, the majority employ a Bayesian approach. This method offers several advantages, including the ability to make finer distinctions among different graphs and resilience to erroneous categorical decisions in the face of limited interventional samples. These studies can be categorized based on whether they assume a parametric structural causal model (SCM). Many works, such as those by Heckerman et al. (1997); Annadani et al. (2024); Toth et al. (2022), make certain assumptions about the SCM, such as additive Gaussian noise or linear causal models. However, their results will be inaccurate if the underlying SCM does not adhere to these assumptions. In contrast, the only non-parametric work (Greenewald et al., 2019) assumes that the ground truth causal graph is a forest of trees. Each undirected component of a tree with \(n\) nodes contains \(n\) Directed Acyclic Graphs (DAGs) in its MEC, which facilitates the tracking of the posterior of each possible DAG. For general undirected graphs, the MEC size could be exponential to \(n\)(He et al., 2015; Meek, 1995) which makes the Bayesian posterior updating intractable. In this study, we adopt a non-parametric approach to mitigate the risk of erroneous outcomes resulting from assumptions about the SCM while mediating the problem of exponentially many DAGs in the MEC. We additionally assume causal sufficiency and faithfulness. Causal sufficiency asserts the absence of latent confounders, while faithfulness implies that every conditional independence relation that holds in the probabilistic model is entailed by the d-separation property of the causal graph. Given these assumptions, the PC algorithm (Spirtes et al., 2001) can be employed to identify all v-structures in the causal graph, followed by the application of Meek Rules (Meek, 1995) to derive the essential graph. The subgraph induced by the unoriented edges in the essential graph comprises multiple chordal chain components and can be oriented independently from other unoriented chain components and the oriented subgraph (Andersson et al., 1997). Given our assumption of infinite observational data and that PC algorithm and Meek Rules are complete, i.e., they orient all the edges that can be identified from the data, our focus lies on fully orienting the undirected chordal chain graphs (UCCG) of the essential graph of the ground truth causal graph. The main contributions of our work are listed below:

* We study the causal discovery problem with limited interventional samples and propose an algorithm to solve this problem in an Bayesian approach. We analyze this algorithm and show in theory that it can learn the true causal graph with a high probability given a large enough number of interventional samples and calculate the convergence rate.
* We conduct experiments on simulated datasets with random chordal DAGs to compare our algorithm with other baseline methods. The results show that our algorithm outperforms other baselines in that it takes fewer interventional samples to receive the same accuracy.

Additionally, the performance of our algorithm is stable across different settings (order and density of the random DAGs).
* We discuss how we can modify our algorithm to answer more general causal questions without learning the whole graph using DAG sampling from the MEC. We show how we can estimate the posterior of a set to be the backdoor adjustment set of a causal query given the essential graph and some interventional data as an example. We further show through simulated experiments that we can modify our algorithm to estimate causal effects of variables that cannot be intervened.

**Outline of the paper:** In Section 2, we summarize the related works. In Section 3, we state the preliminary notations and background knowledge. In Section 4, we describe how we setup the initialization steps of the main algorithm. In Section 5, we describe the algorithm with details and analysis on the convergence to the ground truth. In Section 6, we discuss how our algorithm can be modified to answer more general causal questions with an example. In Section 7, we present the experiment results on simulated datasets and compare with baselines. In Section 8, we conclude with discussion of limitations and future extensions.

## 2 Related Works

We can roughly divide the causal discovery methods into 3 categories: non-adaptive, adaptive, and Bayesian. Non-adaptive methods design intervention targets for each experiment before retrieving interventional samples. Since no information is shared between experiments, they can be conducted in parallel. Eberhardt (2007) discussed non-adaptive methods as fixed searching strategies and they show that in the worst-case scenarios \(( n)\) size \(\) interventions are necessary to orient the whole causal graph, regardless of the adaptivity of the algorithm. Hyttinen et al. (2013) show the connection between orienting causal graph via intervention and the concept of separating system from combinatorics. Ghassami et al. (2018) studied the problem of orienting the maximum expected number of edges with a budgeted number of size 1 interventions. Kocaoglu et al. (2017), Lindgren et al. (2018) studied the problem of non-adaptive causal graph learning while minimizing intervention costs when each vertex is assigned with a different intervention cost. Many of the early works in causal discovery are non-adaptive, and therefore they construct the theoretical basis of causal discovery algorithm. Separating system is also used in our proposed method.

Adaptive methods make the decision of next intervention based on the results of previous experiments. Less interventions are usually required than non-adaptive counterparts. Eberhardt (2007) compares adaptive strategies with non-adaptive ones and propose a heuristic algorithm. He and Geng (2008) proposed _MinMaxMEC_ and _MaxEntropy_ algorithms that select the next intervention target that minimizes the maximum \(I\)-MEC size or maximizes the intervention entropy respectively. Hauser and Buhlmann (2014) proposed _OptSingle_ which calculates the target that minimizes the maximum number of unoriented edges in the interventional graph. Squires et al. (2020) show that any algorithm would take at least \(\) size 1 interventions to recover the whole graph and proposed a two-stage active learning algorithm. In the first stage, it finds the directed clique tree representation of the unoriented graph and orient the residuals separately in the second stage. Choo et al. (2022) show that a size 1 intervention set can orient the whole graph if and only if it cuts all the covered edges in the ground truth DAG, and propose a learning algorithm that intervenes on a \(1/2-\)separator in each experiment to iteratively decrease the size of the currently unoriented components.

The aforementioned works all assume the existence of an infinite intervention oracle. The Bayesian approach is usually used when this assumption is untenable. Heckerman et al. (1997) investigated learning Structural Causal Models (SCMs) under the assumption that each local likelihood is a combination of multinomial distributions and all variables are discrete. Similarly, Buntine (1994) discussed simple linear local likelihoods involving both discrete and continuous variables. Tong and Koller (2001) proposed an active learning algorithm for Bayesian network learning. Previous studies typically employed Markov Chain Monte Carlo (MCMC) for sampling Directed Acyclic Graphs (DAGs) to estimate posterior distributions over DAGs and function parameters, which grow exponentially with the size of the model. Acharya et al. (2018) studied the problem of distinguishing two causal models on the same graph with limited interventional samples. Nishikawa-Toomey et al. (2022) uses variational inference and GFlowNets (Bengio et al., 2023) to learn and parameterize the joint posterior distribution over DAGs and mechanisms while assuming linear model and equal noise variances. Recent researches (Lorch et al., 2021; Charpentier et al., 2022; Cundy et al., 2021; Toth et al., 2022; Hagele et al., 2023) started leveraging gradient information for more efficient inference, while they suffer from poor inference quality. These studies all make specific parametric assumptions regarding functions or noises in the SCM, which lead to incorrect outcomes when these assumptions are violated. Kuipers et al. (2022) combines constraint-based methods and MCMC methods to efficiently search DAGs, but no guarantee of convergence is provided. To circumvent such issues, Greenewald et al. (2019) directly update the posterior of a specific subgraph containing the root when the graph is a tree without any constraint on the SCM. However in practice, causal graphs are usually more complicated than trees, which motivates our work.

## 3 Preliminaries

A causal graph \(=(,)\) is a directed acyclic graph (DAG) where the vertex set \(\) represents a group of random variables. In the context of \(\), a directed edge \((X,Y)\) from variable \(X\) to variable \(Y\) (denoted as \(X Y\)) signifies that \(X\) serves as an immediate parent of \(Y\). We denote the parent set of variable \(Y\) by \((Y)\). The cut at vertex set \(\), denoted as \(E[,]\), constitutes the set of edges between \(\) and some vertex in the set \(\). According to the Markov assumption, the joint distribution can be decomposed as \(P()=_{i=1}^{n}P(v_{i}|(X_{i}))\). A causal graph entails specific conditional independence (CI) relationships among variables via \(d\)-separation statements. The \(d\)-separation serves as a criterion to determine whether a set of variables \(\) is independent of another set \(\), given a third set \(\). This approach links dependence to connectedness, meaning the existence of a connecting path, while it associates independence with the absence of connection or separation. A set of DAGs is deemed Markov equivalent when they entail identical conditional independence (CI) statements. All Markov equivalent DAGs must have the same adjacencies and unshielded colliders (or v-structures). An unshielded collider is a graph structure of the form \(A B C\) where \(A\) and \(C\) are non-adjacent vertices. The set of all Markov equivalent DAGs is called a Markov Equivalence Class (MEC). We denote the set of all DAGs that is Markov equivalent to \(\) as \([]\).

**Definition 1** (Faithfulness (Zhang and Spirtes, 2012)).: _If the population distribution exhibits a conditional independence relation only when there exists a corresponding \(d\)-separation statement in the causal graph, then we say that the population distribution is faithful to the causal graph._

The positivity assumption is fundamental for making causal inferences. It asserts that, in theory, every individual possesses a non-zero chance of being both exposed and unexposed (Hernan and Robins, 2020). In many cases, we have access to abundant observational data, which allows for precise estimation of the true observational distribution. The no positivity violation assumption is merely needed for theoretical guarantees to hold while not required by the algorithm. We assume access to the observational distribution, and the observational distribution is faithful to the true causal graph, with no positivity violations.

A partially directed acyclic graph (PDAG) is a partially directed graph free from directed cycles. All Markov equivalent DAGs can be represented by a completed partially directed acyclic graph (CPDAG), denoted by \(\). A DAG \(\) can be represented by a CPDAG when they share the same set of adjacencies and unshielded colliders, and every oriented edge in the CPDAG is also present in \(\)(Meek, 2013). CPDAGs are chain graphs with chordal chain components (Andersson et al., 1997). In graph theory, a chordal graph is one in which cycles of four or more vertices always contain an additional edge, called a chord. We denote the set of all chain components of a PDAG \(\) as \(CC()\).

An intervention on a subset of variables \(\), denoted by the do-operator \(do(=)\), involves setting each \(W_{j}\) to \(w_{j}\). For every intervention, we have an induced post-interventional graph denoted by \(_{}\) with incoming edges to vertices in \(\) removed. We denote the interventional and observational distributions as \(P^{}_{}()\) and \(P^{}()\) respectively for a given DAG \(\). Using the truncated factorization formula over the post-interventional graph (\(_{}\)), we have the following:

\[P_{}():=P( do(=))= _{}P(v|(v))\] (1)

Where \(\) must be consistent with the intervention \(do(=)\). Consider a set of intervention targets \(=\{_{1},_{2},...,_{n}\}\) where each \(_{i}\) for all \(i[n]\). For every target \(_{i}\), we define the collection of all possible cut configurations, i.e., all possible orientations of edges in \(E[_{i},_{i}]\), as \(_{k}(_{i})\) for all \(k[n_{_{i}}]\). Also note that \(n_{_{i}} 2^{|_{i}|d_{m}}\) where \(d_{m}\) is the maximum degree of the graph.

Additionally, for bounded size intervention targets i.e., \(|_{i}| k\), we have \(n_{_{i}} 2^{kd_{m}}\). We use the notation \(P_{_{1}}^{_{k}(_{i})}()\) to represent the interventional distribution in \(()\) with the cut configuration \(C_{k}(_{i})\). Also we use the notation \(^{*}(_{i})\) for the cut configuration in the true DAG \(^{*}\). Given an intervention set \(_{}\), if we assume perfect intervention, one can recognize all the edges adjacent to vertices in \(_{}\) and further apply Meek Rules. The resulting PDAG is called an interventional essential (I-essential) graph of \(\) denoted as \(_{_{}}()\). When \(_{}\) is empty, it is the observational essential graph. I-essential graphs are also known to be maximally oriented partially directed acyclic graphs (MPDAGs). We denote an MPDAG as \(\) and the I-essential graph with \(C_{k}(_{i})\) as \(_{C_{k}(_{i})}\). MPDAGs are also chain graphs with chordal components (Hauser and Buhlmann, 2012). We denote the KL divergence between two distributions \(p,q\) as \(D_{KL}(p||q)\).

## 4 Algorithm Initializations

Assume the true DAG is \(^{*}\), our algorithm aims to return a most 'probable' causal graph \(\) given \(N\) interventional samples. With the access to infinite observational data, we can retrieve the essential graph \(G=(^{*})\) by PC algorithm (Spirtes et al., 2001) and joint distribution \(P()\). Here we describe how we compute the separating system of \(G\) and the causal effect of a given intervention set.

### Separating System

As mentioned in Section 2, separating system plays the key role for non-adaptive intervention design of causal discovery. Roughly speaking, a separating system on a set of elements is a collection of subsets such that for every pair of elements from the set, there exists at least one subset which contains exactly one element from the pair. Consider an undirected complete graph \(G\) of \(n\) vertices indexed as \(1,...,n\), a separating system \(\) on \([n]\) would cut every edge of \(G\). In the worst case, a separating system is needed to learn the causal graph with \(G\) as its essential graph (Shanmugam et al., 2015). If we further bound the size of each \(\) such that \(|| k,k<\), the resulting set is called an \((n,k)\)-separating system. We provide the formal definition below:

**Definition 2** (\((n,k)\)-Separating System (Katona, 1966; Wegener, 1979)).: _An \((n,k)\)-separating system on \([n]\) is a set of subsets \(=\{_{1},_{2},...,_{m}\}\) such that \(|_{i}| k\) and for every pair \(i,j\) there is a subset \(\) such that either \(i,j\) or \(i,j\)._

We discuss the detailed steps of how we construct the \((n,k)\)-separating system in Appendix D.

### Enumerating Causal Effects

To use a Bayesian approach, we need to construct a set of disjoint events and track their posteriors. Here we consider the events as interventional causal effects when we intervene on a set of vertices. By the assumption of faithfulness, Lemma 1 shows that the post-interventional distribution is determined by the edge configurations that are adjacent to vertices in the intervention set. Perkovic (2020) proposed a formula is to identify any causal effect in an MPDAG. One can enumerate all valid edge cuts and use the identification formula to calculate the post-interventional distributions. Here we propose a simple Algorithm 3 to enumerate through all possible configurations of a given set \(\) and calculate the post-interventional distribution \(P_{}^{C()}()\) via DAG sampling. For each candidate configuration \(C_{k}()\), we check if it contains invalid structures, i.e. unshielded colliders or cycles. If it is valid, we apply Meek Rules to get the MPDAG \(_{C_{k}()}\) which is an I-essential graph \(_{}(^{*})\) for some DAG \(_{C_{k}()}[^{*}]\) that is consistent with \(C_{k}()\). The chain components of \(\) are chordal graphs and can be oriented independently (Hauser and Buhlmann, 2012). To efficiently calculate the interventional distribution, we use a DAG sampler (Wienobst et al., 2023) to sample a DAG for each chain component and replace the edges in \(_{C_{k}()}\) with the arcs in the sampled DAG to get a fully oriented graph \(\). The sampling process takes linear time. Given the DAG \(\), the interventional distribution could be calculated by using the Equation 1 over the DAG.

## 5 Algorithm Design and Analysis

In the previous section, we discuss two key steps for the algorithm initialization, which include the construction of \((n,k)\)-separating systems and enumerating causal effects for all possible cutting edge configurations for all the intervention targets in the separating system. For a given intervention target \(_{i}\), we utilize the following result that under the faithfulness assumption, shows that we have a unique interventional distribution for every cutting edge orientation \(_{j}(_{i})\).

**Lemma 1**.: _[_(_Elahi et al._,_ 2024_)_]_ _Assume that the faithfulness assumption holds and \(^{*}\) is the true DAG. For any DAG \(_{1}^{*}\), if \(P_{}^{_{1}}=P_{}^{^{*}}\) for some \(\), they must share the same cutting edge orientation \(()\)._

Lemma 1 allows us to uniquely orient cutting edges for every intervention target in the separating system, which in turn orients every edge and gives us the true DAG. We use the notation \(D_{ab}^{_{i}}:=D_{KL}(\;P_{_{i}}^{_{a}(_{i})}()||P_{_{i}}^{_{b}(_{i})}( )\;)>0\; a b\;,\; a,b[n_{_{i}}]\) and \(D^{_{i}}:=_{ a b\;,\; a,b[n_{_{i} }]}D_{ab}^{_{i}}\). The idea is to use the interventional data \(do(_{i}=_{i})\) to determine the true cutting edge configuration \(^{*}(_{i})\) and repeat this for all intervention targets in the separating system. Suppose we have access to \(m_{_{i}}\) i.i.d. samples from the intervention \(do(_{i}=_{i})\), which we denote as \(_{do(_{i})}=\{_{1},_{2},..., _{m_{_{i}}}\}\). We define the posterior probabilities of \(_{j}(_{i})\) for all possible cutting configurations at \(_{i}\), i.e., for all \(j[n_{_{i}}]\) where \(n_{_{i}} 2^{kd_{m}}\) as follows:

**Definition 3**.: _(Posterior Probabilities of Cutting Edge Configurations) Consider an intervention target \(_{i}\) and a collection of all possible cutting edge configurations \(_{j}(_{i})\) for all possible cutting configurations at \(_{i}\), i.e., for all \(j[n_{_{i}}]\) and the interventional dataset of i.i.d. samples \(_{do(_{i})}=\{_{1},_{2},..., _{m_{_{i}}}\}\). We define probabilities of Cutting Edge Configurations as:_

\[P(_{j}(_{i})\;|\;_{do(_{i})})= _{i}}^{_{j}(_{i})}(_{1}, _{2},...,_{m_{_{i}}})\;p_{j}}{_{a=1}^{n_{ _{i}}}P_{_{i}}^{_{a}(_{i})}(_{1},_{2},...,_{m_{_{i}}})\;p_{a}} j [n_{_{i}}]\;,\;_{i}\] (2)

_where \(p_{a}\) for all \(a[n_{_{i}}]\) are the set of priors such that \(_{a=1}^{n_{_{i}}}p_{a}=1\)._

Given the fact that the interventional samples are i.i.d we can rewrite the posterior probabilities as

\[P(_{j}(_{i})\;|\;_{do(_{i})})= ^{m_{_{i}}}P_{_{i}}^{_{j}( _{i})}(_{k})\;p_{j}}{_{a=1}^{n_{_{i}}} _{k=1}^{m_{_{i}}}P_{_{i}}^{_{a}(_{i})} (_{k})\;p_{a}} j[n_{_{i}}]\;,\; _{i}\] (3)

**Assumption 1**.: _We assume access to the observational distribution that is faithful to the true causal graph. Furthermore, we have \(|_{i}}^{_{a}(_{i})}()}{P_{_{i}^{_{b}(_{i})}()}^{_{a}(_{i})}()}|\) for every intervention set \(_{i}\) and for all \(a,b[n_{_{i}}]\)._

The second half of the assumption can be seen as a version of the positivity assumption commonly used in causal discovery and many other applications. We show that for the problem of learning the true cutting edge configuration, the posterior is consistent, i.e., as the number of samples \(m_{_{i}}\), the posterior of the true cutting edge configuration given the data converges to \(1\) with high probability.

**Lemma 2**.: _(Posterior Consistency) Consider an intervention target \(_{i}\) and the corresponding true cutting-edge configuration \(^{*}(_{i})\). As the number of samples \(m_{_{i}}\) in \(_{do(_{i})}=\{_{1},_{2},, _{m_{_{i}}}\}\), the posterior of the true cutting-edge configuration \(P(^{*}(_{i})\;|\;_{do(_{i})})\) converges to \(1\) with high probability. More precisely, we have the following high probability lower bound on the posterior probability of the true cutting-edge configuration._

\[P(^{*}(_{i})\;|\;_{do(_{i})}) 1 -(m_{_{i}})-_{2} _{i}}}}\;w.p. \;\;at\;least\;1-\] (4)

_Where \(_{1}\) and \(_{2}\) are constants depending on the prior and the problem instance. Thus, for any small choice of the probability \(\), with a sufficiently large number of samples \(m_{_{i}}\), the posterior of the true cutting-edge configuration \(P(^{*}(_{i})\;|\;_{do(_{i})})\), converges to \(1\) with a probability at least \(1-\)._Note that the randomness in the high-probability result in Equation 4 arises from the finite sample size. Lemma 2 guarantees that with a sufficiently large number of samples from interventions on \(_{i}\), the posterior of the true cutting edge configuration \(P(^{*}(_{i})_{do(_{i})})\) converges to \(1\) with high probability. However, in scenarios where we want to know ahead of time how many interventional samples we need from every target \(_{i}\) to ensure that the posterior of the corresponding true cutting orientations \(P(^{*}(_{i})_{do(_{i})}) 1-\) with high probability, we need to determine the required number of samples. The parameter \( 0\) represents the error tolerance. We extend Lemma 2 to provide the minimum number of samples \(m_{_{i}}\) required for an intervention on the target set \(_{i}\) to ensure that the posterior of the corresponding true cutting orientations is greater than some threshold.

**Theorem 3**.: _Given that the Assumption1 hold, consider an intervention target \(_{i}\) such that \(|_{i}| k\) and the corresponding true cutting edge configuration \(^{*}(_{i})\). If the number of samples \(m_{i}\) in \(_{do(_{i})}=\{_{1},_{2},..., _{m_{_{i}}}\}\) satisfies the following:_

\[m_{_{i}}=}{(D^{_{i}})^{2}}}}{}+_{i}}}}(1-)(1-p ^{*})}{p^{*}}\] (5)

_where \(p^{*}\) is the prior assigned to the true cutting-edge configuration \(^{*}(_{i})\), then we have \(P(^{*}(_{i})_{do(_{i})}) 1-\) with a probability at least \(1-\)._

Since we have multiple intervention targets in the \((n,k)\)-separating system of the form \(=\{_{1},_{2},.._{p}\}\) such that \(|_{i}| k\) for all \(i[p]\). We can have a total of \(p\) bad events one for every target set \(_{i}\) where posterior of corresponding true cutting edge configuration \(^{*}(_{i})\) is not greater than the desired threshold \(1-\). Thus we extend the Theorem 3 as follows:

**Corollary 4**.: _Given that Assumption1 hold, consider a separating system of the form \(=\{_{1},_{2},.._{p}\}\) such that \(|_{i}| k\) for all \(i[p]\). If the number of samples \(m_{_{i}}\) in \(_{do(_{i})}=\{_{1},_{2},..., _{m_{_{i}}}\}\) for every target set \(_{i}\) satisfies the following:_

\[m_{_{i}}=}{(D^{_{i}})^{2}} {2^{(k+1)d_{m}}}{^{}}+_{i}}} }(1-)(1-p^{*})}{p^{*}}\] (6)

_where \(p^{*}\) is the prior assigned to the true cutting edge configuration \(^{*}(_{i})\) and \(^{}=\), then we have \(P(^{*}(_{i})_{do(_{i})}) 1-\) with probability at least \(1-\) for every \(_{i}\)._

To ensure that for every target set \(_{i}\), we have the posterior probability of the corresponding true cutting-edge configuration \(P(^{*}(_{i})_{do(_{i})}) 1-\), we need \(m_{_{i}}\) samples (as in Equation 6) from every target. Therefore, for the causal discovery problem with \(p\) targets in a separating system, we require a total of \(p m_{_{i}}\) samples.

Based on the analysis, we propose Algorithm 1 as the main algorithm. We start by calculating a \((n,k)\)-separating system \(\) using the labeling procedure described in Appendix D for the essential graph \(G=(^{*})\), and them identify all valid configurations \(C(),\) using Algorithm 3. For each valid configuration, one can simply assume that their priors are uniform. In our algorithm, we assume that each possible DAG in \([^{*}]\) are equally likely to be the true DAG. Therefore we can calculate the prior more accurately using the MEC counting algorithm [Wienobst et al., 2023]. Specifically, for each valid configuration \(C_{k}()\), we find the MPDAG \(_{C_{k}(S)}\) that matches with it by applying Meek Rules. \(_{C_{k}()}\) is a chain graph with chordal components that can be oriented independently. Thus, the interventional MEC size of \(_{C_{k}(S)}\) could be calculated by:

\[|[_{C_{k}()}]|=_{H CC(_{C_{k}()})}|[H]|\] (7)

The prior of each configuration could then be estimated by:

\[P(C_{k}())=_{C_{k}()}]|}{_{C_{j} C ()}|[_{C_{j}()}]|}\] (8)

If we are allowed to collect \(N\) total interventional samples, we can randomly choose a target set from the \((n,k)\)-separating system for each sample. Algorithm 3 iterates all valid configurations to calculate the likelihood \(P(_{do(S)}|C_{k}(S))\) by sampling DAG from the interventional MEC. After calculating all the likelihoods, we can update the posteriors and priors. For the last step, we need to combine all the configurations of each \((n,k)\)-separating set to return a DAG. We consider a greedy approach. At each step, we choose the configuration with the highest posterior across all unvisited target sets that is compatible with chosen configurations. Given the anytime nature of our algorithm, we can propose a candidate DAG after each interventional sample. With a large enough sample number, according to Theorem 3, our algorithm will return the true DAG with a high probability.

## 6 Case Study: Estimating Causal Effects of Non-Intervenable Vertices

Here we show how to use DAG sampler to estimate the causal effect when some vertex cannot be intervened in the causal graph. The detailed problem setup is as follow. \(=(,)\) is an undirected underlying causal graph, \(X,Y\) are non-adjacent vertices. We want to estimate \(p(y|do(x))\) using interventional data while \(X\) is not intervenable in the graph. Thus we cannot directly use the method in Perkovic (2020) to estimate the causal effect. With the DAG sampler, we can first intervene on \(X\)'s neighborhood \(Ne(X)\) and then sample DAG to estimate the likelihood of each configuration being the true one in the causal graph. When we have large sample size, the posterior of the true configuration will go to 1 with a high probability according to Lemma 2. Then, we iterate through each configuration and their posterior to calculate the average divergence \(\) between the estimated and true causal effect. The divergence \(D\) here can be KL divergence or Total Variation Distance (TVD). If the ground truth causal effect is \(p^{*}\), the interventional data is \(_{do(Ne(X))}\), then \(\) is formally defined as:

\[=_{C_{i} C(Ne(X))}D(p^{*}||P^{C_{i}}_{Ne(X)}(y|do(x))) P (C_{i}|_{do(Ne(X))})\] (9)

In this experiment, we randomly create 50 causal graphs with \(n=5,6,7,=0.3,0.6\) using a similar approach described in Section 7. Then we randomly choose a pair of non-adjacent vertices \(X,Y\). We then intervene on \(X\) and collect 100,000 samples. We plot \(_{KL}\) and \(_{TVD}\) between estimated causal effect and the ground truth given different number of interventional samples. The mean and standard deviation are plotted in Figure 1. We can see that as the number of interventional samples increases, the estimated causal effect gets close to the ground truth and the variance is also decreasing. The difference decreases sharply w.r.t. the number of samples, showing the efficiency of our proposed approach.

## 7 Experiments

We compare the proposed Bayesian Causal Discovery algorithm with 3 existing baselines. The first baseline, Random Intervention, intervenes randomly on the graph separating system. In each step, one interventional sample is collected, and then we perform independence tests to learn the cuts at the targets based on the collected samples from each intervention target. The second baseline is Active Structure Learning of Causal DAGs via Directed Clique Trees (DCTs) (Squires et al., 2020). The third baseline is the adaptivity-sensitive search algorithm proposed in Choo and Shiragur (2023). It chooses the intervention target based on the clique tree representation of a chordal graph.

We generate random connected moral DAGs with order \(n\) and density \(\) using a modified Erdos-Renyi sample approach, similar to the process in Squires et al. (2020). We start by generating a random ordering \(\) over vertices. Then, for the \(i^{th}\) vertex, we sample its in-degree as \(_{i}=max(1,Bin(n-1,))\). The vertices precede it in the ordering are uniformly assgined as its parents. In the last step, we apply the elimination algorithm in Koller and Friedman (2009) to chordalize the graph. The elimination algorithm uses an ordering that is the reverse of \(\). Based on the generated graph, we randomly sample the conditional probability table (CPT) that is consistent with the graph and strictly positive. The essential graph of the generated DAG is then fed into the causal discovery algorithms together with the Bayes network that is consistent with the DAG.

To measure the performance of the algorithms, we plot the Structural Hamming Distance (SHD) between the ground truth and learned DAGs with respect to the number of collected interventional samples. SHD counts the number of edge insertions, deletions, or flips to transform from one DAG into another. For each setting of \(n\) and \(\), we sample 50 random DAGs and calculate the mean and standard deviation of SHD by each causal discovery algorithm. The mean is plotted as a curve and the shaded area around the curve represents the standard deviation. We use Chi-Square independence test from the Causal Discovery Toolbox (Kalainathan et al., 2020) to perform statistical tests with limited samples.

The results in Figure 2 and 3 show that our algorithm outperforms other causal discovery algorithms. Figure 2 shows the performance of causal discovery algorithms on complete graphs with order 5, 6, and 7 respectively. Our algorithm uses significantly less samples to reach a low SHD and the number of samples required does not increase much with the order of the graph compared to the other algorithms. Figure 3 shows the results of graphs with the same order but varying densities. Similarly, our algorithm uses comparable number of samples across different densities. In contrast, the baseline algorithms require much more samples in denser graphs to reach the same SHD. To wrap up, in both cases, our algorithm reaches a low SHD using much fewer samples than the baselines

Figure 1: Average KL divergence and TVD between estimated causal effect and ground truth vs number of interventional samples for random causal graphs.

and is more stable across different settings. The results on larger graphs (\(n=20\)) are provided in Appendix H.1. The algorithm code is provided at https://github.com/CausalML-Lab/Bayesian_SampleEfficient_Discovery.

## 8 Conclusion

In this work, we discuss the problem of learning causal graphs with minimum number of interventional samples. We propose an algorithm that solves this problem in a Bayesian approach. Specifically, we keep track of the posteriors of interventional distributions of each target set in the \((n,k)\)-separating system and then combine the configurations that have high posteriors to propose a DAG. We show in theory that given enough samples, our algorithm can return the true causal graph with a high probability. Also, according to the Bayesian nature of our algorithm, we can stop the algorithm anytime and check the output graph. Experiments on simulated datasets show that compared with the baselines, our algorithm use significantly fewer interventional samples to achieve the same SHD. Additionally in the case study, we demonstrate that we can modify our algorithm to answer special causal queries with DAG sampling. For future extensions, it is of great interest to decrease the space of posteriors being tracked, since on large dense graphs, it will be intractable to track all interventional distributions of a target set. Besides, we can try to remove/weaken the assumptions like causal sufficiency and faithfulness while maintaining theoretical guarantees. Our work can potentially have some societal consequences including ethical considerations related to performing interventions and the risk of biased or partial understandings which may cause misled decision-making in real-world cases.