# IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark

Fredrik D. Johansson

Chalmers University of Technology

and University of Gothenburg

fredrik.johansson@chalmers.se

###### Abstract

Evaluating observational estimators of causal effects demands information that is rarely available: unconfounded interventions and outcomes from the population of interest, created either by randomization or adjustment. As a result, it is customary to fall back on simulators when creating benchmark tasks. Simulators offer great control but are often too simplistic to make challenging tasks, either because they are hand-designed and lack the nuances of real-world data, or because they are fit to observational data without structural constraints. In this work, we propose a general, repeatable strategy for turning observational data into sequential structural causal models and challenging estimation tasks by following two simple principles: 1) fitting real-world data where possible, and 2) creating complexity by composing simple, hand-designed mechanisms. We implement these ideas in a highly configurable software package and apply it to the well-known Adult income data set to construct the IncomeSCM simulator. From this, we devise multiple estimation tasks and sample data sets to compare established estimators of causal effects. The tasks present a suitable challenge, with effect estimates varying greatly in quality between methods, despite similar performance in the modeling of factual outcomes, highlighting the need for dedicated causal estimators and model selection criteria.

## 1 Introduction

Estimating causal effects of interventions is fundamental to improving decision-making by data-driven means. As a result, an ever-growing body of research develops machine learning algorithms for this task (Hernan and Robins, 2006; Shalit et al., 2017; Wager and Athey, 2018; Yoon et al., 2018; Kunzel et al., 2019; Kennedy, 2023). However, identification of causal effects--and, therefore, evaluation of these algorithms--rely either on interventions (e.g., randomized experiments) or unverifiable assumptions (e.g., exchangeability) (Pearl, 2009). As experimentation is costly or prohibited in many domains, simulated environments are uniquely suited as benchmarks for causal effects estimation from observational data. They can be constructed to satisfy conditions for identifiability and to answer interventional queries, providing ground truth labels for estimates. But this strategy begs the question: How can we build simulators that reveal which causal estimators work best in the real world?

Primarily, two kinds of data sets are used for offline evaluation of causal effect estimates: experimental data and (semi-) synthetic data. Experimental data (e.g., the LaLonde (Jobs) data set (LaLonde, 1986)) supports unbiased estimation by removing confounding by construction (Imbens and Rubin, 2015). But learning from unconfounded data is rarely the goal of the methods we seek to evaluate. To overcome this, researchers can introduce selection bias synthetically by subsampling observations depending on the intervention, as in Twins (Louizos et al., 2017). A drawback of this approach is that experimental data tends to be small, both in sample size and dimensionality, and subsampling decreases its size even further. In other semi-synthetic data, e.g., IHDP (Hill, 2011), the analyst simulates one or more of the variables in the system of interest, typically the outcome variable.

Hand-designed simulators are great for designing benchmarks to test estimators in a particular challenge, such as learning from non-linear outcomes (Hill, 2011) or heteroskedastic noise (Hahn et al., 2019). Their main drawbacks are that they (i) scale poorly with the size of the system, requiring significant domain expertise by the designer, or (ii) model overly simple or extreme systems, not reflecting the intricacies of real-world data (Hernan, 2019). In contrast, purely data-driven simulators of potential outcomes can fit and generate complex relations between context, treatment, and outcome variables which are difficult to design by hand (Chan et al., 2021). However, they often lack structural constraints on the causality between variables, making them insufficient for reasoning about rivaling identification strategies, e.g., with instrumental variables or alternative adjustment sets, and for changing the nature of confounding or interventions (Hernan et al., 2019). In short, mimicking only the observational distribution of a chosen system is not sufficient to stress test causal effect estimators.

Contributions.In this work, we construct a simulator using a sequential structural causal model based on the well-known Adult data set (Becker and Kohavi, 1996) and use this to create a new benchmark data set for causal effect estimation. We apply a generalizable strategy for developing realistic and challenging estimation tasks by imposing structural constraints on the simulator using a causal graph and fitting parts of its mechanisms to non-sequential tabular data. Our strategy assumes that the initial state of a system of variables follows a complex distribution (e.g., the age, education, and income of a subject), but that its transitions are simpler (e.g., the income next year is close to the income from the previous year). Thus, we can build a realistic simulator by fitting the causal mechanisms of initial states to data and hand-designing transition mechanisms. The effects of interventions in early time steps on outcomes later in time are determined by compositions of several transitions which renders causal effects non-trivial functions of the initial state, even if each transition is simple. We use our simulator IncomeSCM to generate data for an observational study of the effects of studies on future income and compare popular estimators from the literature. Our results indicate that different estimators yield estimates that differ substantially in quality despite fitting observed variables similarly well, pointing to the challenging nature of the tasks.

## 2 Related work

Simulated data has long been used to evaluate estimators of causal effects as a way to get around the unavailability of counterfactual outcomes. The extent and nature of simulation vary from replacing a single variable (typically the outcome) with a simulated counterpart, to simulating an entire system of random variables. A notable example, the "IIHD" data set was derived from a randomized study of the Infant Health and Development Program by removing a biased subset of treated participants and introducing a synthetic response surface (Hill, 2011). It was built to support multiple settings, see e.g., (Dorie, 2016), but the variant used by Shalit et al. (2017) has stuck as the primary benchmark. Generally, randomized data can be turned observational by subsampling cohorts with treatment selection bias, as in Twins (Louizos et al., 2017) or by adding observational data to an experimental cohort as in Jobs (Shalit et al., 2017). Both strategies benefit from context variables remaining untouched, representative of real-world data. A downside is that the sample size is fixed to the number in the original study. This limitation can be overcome by designing every variable in the system, such as in the 2016 data challenges of the Atlantic Causal Inference Conference (ACIC) (Dorie et al., 2019). However, this often leads to very simplistic simulators.

Recognizing the limitations of relying on purely synthetic simulators for benchmarking, several works have proposed fully or partially data-driven simulators, where components are learned from real-world data. A recent example is Medkit-Learn Chan et al. (2021), developed for off-policy evaluation of reinforcement learning, and the Alzheimer's Disease Causal estimation Benchmark (ADCB) (Kinyaniui and Johansson, 2022). The 2022 iteration of the ACIC challenge included a partially data-driven design, which used a strategy similar to ours, but to the best of our knowledge, the details of the simulator remain unpublished (Mathematica, 2022). Complementing purpose-built data sets and simulators, causality toolboxes, such as DoWhy (Sharma and Kiciman, 2020) and CausalML (Chen et al., 2020) include multiple ways of generating simple forms of synthetic data. Gentzel et al. (2019) provide an excellent overview of different approaches to evaluating causal modeling methods and suggest another approach: Use complex systems, such as a PostGres database, where interventions on its configuration can be performed but the outcome are hard to predict. This can provide both observational data for learning and interventional data for evaluation. Appendix D contains a tabular summary of common causal effect estimation benchmarks.

Finally, several previous works have analyzed the Adult data set in the context of causality (Von Kugelgen et al., 2022; Mahajan et al., 2019), for example, in causal discovery (Binkyte et al., 2023). As a result, there are several DAGs proposed in the literature, including those by Zhang et al. (2016) (inferred from data), by Li et al. (2016) and by Nabi and Shpitser (2018) in the context of counterfactual (algorithmic) fairness (constructed by the analysts). We use the latter strategy here.

## 3 Constructing the simulator

We create IncomeSCM-1.0--a simulator of a sequential decision-making process associated with personal income. This will serve as an example of a general strategy for creating realistic and challenging benchmark tasks for causal effect estimation from cross-sectional observational data.

IncomeSCM is based on a discrete-time Markov structural causal model (SCM). The primary goal of the model is to simulate the effects of an intervention of interest \(A\) on a given outcome \(Y\) in a system of random variables \(\{A,Y\}\), where \(\) is a set of context variables. Each variable \(V\) is simulated at \(T\) time points in a sequence \(V_{1},...,V_{T}\). The _initial state_ of \(V_{1}\) is determined by a deterministic structural equation \(V_{1} f_{V}((V_{1}),U_{V_{1}})\) where \((V_{1})\) are the _parents_ (direct causes) of \(V_{1}\) and \(U_{V_{1}}\) is a source of noise. Values of \(V_{t}\) for \(t>1\) are determined by a time-homogenous _transition_ mechanism \(V_{t} g_{V}((V_{t}),U_{V_{t}})\). In general, mechanisms and parent sets are _not shared_ by initial states and transitions, i.e., \(f_{V} g_{V}\) and \((V_{1})(V_{t})=(V_{s})\) for \(s,t>1\). One of the main reasons for this is that transitions \(g_{V}\) typically depend on the previous value of the variable \(V\), but the initial state cannot. As a result, the initial state of a variable typically has a much stronger dependence on other variables in the systems than the transitions do. The model is Markov in that \((V_{t})\) includes only variables from time \(t\) and \(t-1\).

To ensure that the model captures realistic correlations between variables, its structural equations are _learned_ whenever data on a variable and its parents are available. When such data are unavailable, the structural equations are _hand-designed_. Our simulator and data set construction, generalizable to any cross-sectional data set, proceeds as follows (see Figure 1 for an overview):

1. **Data set.** Compile a base cross-sectional data set \(\) with observations of random variables \(\) from which to learn the structural equations of the simulator.
2. **Initial-state graph.** Learn or design, based on domain knowledge, a causal directed acyclic graph (cDAG) \(G_{1}\) of the initial states \(V_{1}\) of all variables \(V\).
3. **Transition graph.** Posit a time-independent cDAG \(G_{t}\) for the causes of transitions of variable values as functions of variables in the current and previous time steps.

Figure 1: Overview of the IncomeSCM simulator. All variables (left) are observed at a single time point in the well-known Adult data set, except the Studies variable (node and edges in red). A causal graph is constructed for the initial state (middle-left) and for the transitions, illustrated here by the parents of a single node in the full graph (middle-right). Each variable is associated with an initial sampler and a transition sampler (example to the right) which simulate the trajectory of the variable.

4. **Samplers.** Learn samplers (structural equations) \(f_{V}\) of the initial states of each variable \(V\) by fitting estimators to the base data set and design samplers \(g_{V}\) for transitions.
5. **Simulation.** Create observational and counterfactual data sets of causal effects from the SCM through ancestral sampling, while performing interventions on one or more variables.

A benefit of this strategy is that it blends the strengths of data-driven and knowledge-guided design: 1) Imposing a causal structure defines interventional distributions of all variables, allowing benchmarks to ask flexible causal queries of the simulator (e.g., about mediation or path-specific effects), 2) Fitting the initial states of variables adds realistic complexity to structural equations. 3) A sequential model creates causal effects of future outcomes that are interesting functions of early interventions and context variables even when transition mechanisms are hand-designed.

On hand-crafted transitions.The design strategy for our simulator is developed for systems with simpler transitions than initial states. A strong argument for this idea is that most variables are easier to model once you know a recent value of them. The classical example is that the weather tomorrow is usually similar to the weather today (transition is simple), but modeling the weather based on other variables, such as location and time of year, is more difficult (the initial-state model is complex). Another example is the distribution of patients in a hospital. When a new patient gets admitted (initial state), we can view their demographics, symptoms, and medications as drawn from a complex distribution of possible patients. When we observe them the next day, the changes in their variable tend to be more predictable given their values at admission and obey simpler rules, such as dose response to medication or day-night cycles of vitals. A counter-example to this pattern would be a system where all variables are independent in the initial state but become dependent in transitions. For example, let the variables measure the opinions of a random set of people (e.g., students) who begin to meet regularly (say, in a class). In the initial state, there will be no correlation among the opinions but he next state may be a complicated function of the opinions of different people.

As an example of a generic task derived from such a simulator, we consider atomic interventions \(A_{t_{0}} a\) performed at a baseline time point, \(t=t_{0}\), on an outcome \(Y_{T}\), measured at the final time step, \(t=T\). In the potential outcomes framework (Imbens and Rubin, 2010), we define the conditional average treatment effect with respect to a subset of baseline variables \(Z X_{t_{0}}\),

\[(z)=[Y_{T}(A_{t_{0}} 1)-Y_{T}(A_{t_{0}}  0) Z=z]\;.\]

and aim to estimate \(\) from observational data generated by the simulator, as well as the average treatment effect, \(_{Z}[(Z)]\).

### The base data set: Adult

IncomeSCM-1.0 is based on the widely-used Adult data set (Becker and Kohavi, 1996) and its release on the UC Irvine Machine Learning Repository.1 The set contains 48 842 observations of 14 variables and a sample weight, extracted from the 1994 US Census Bureau database. The original task associated with the Adult set is to predict whether an individual will earn more than $50 000 in a year and the full variable set comprises age, workclass, education (categorical and numeric), marital-status, occupation, relationship, race, sex, capital-gains/losses (summarized as capital-net in the simulator), hours-per-week (of work), native-country and income. We ignore the sample-weight in the simulator and drop any rows containing missing values in any column, leaving 30 162 samples. Statistics for these features are presented in Table 1.

Outcome of interestAs the primary outcome of interest \(Y\), we use the yearly income of subjects in US dollars. In the Adult data set, income is coded as a binary variable, representing whether the yearly income of a subject exceeds $50 000, denoted here by \(R\{0,1\}\). For IncomeSCM, we construct a continuous income variable \(Y\) by first fitting a small random forest _regressor_\(h_{R}\) to predict the original binary outcome \(R\) as a function of all covariates \(X\) (excluding the added variable studies). The continuous predictions \(_{i}=h_{R}(X_{i})\) of the regressor are computed for each subject \(i\). This intermediate value represents the likelihood that the income exceeds $50 000, which is then re-scaled and shifted by two constants so that the average of the resulting numbers, across the full cohort, matches the average US population annual salary (in USD). Leaving the outcome a binary variable would make it more difficult to design, for example, income transitions. With a continuous value, we can reason about the average increase in salary due to a pay raise. A binary-income model would be much more coarse-grained.

Intervention of interestFor a causal estimation task to be realistic, the primary intervention of interest must be possible to implement in practice, for example, in an experiment (Hernan, 2019; Hernan et al., 2022). The Adult data set contains a small number of variables that could be _directly_ intervened upon and serve as the primary intervention. Base variables age, sex, native-country, and race can be removed from consideration, as can capital-gain, capital-loss as these are outside of the control of any feasible experiment. occupation is feasible to change on a yearly basis, but most jobs are unavailable to most people. relationship and marital-status are possible to change, through e.g., divorce, but most people would not be willing to change these in order to optimize their income, let alone participate in an experiment to do so. workclass, occupation and hours-per-week are candidates that could be intervened upon a yearly basis. education is coded in Adult by the highest attained degree (e.g., Bachelor's degree) or the number of years of study. However, in the time scale of the simulator (one observation per year, \(t=1,...,T\)), an intervention of, say \(A_{t}\) Doctorate is not feasible. Instead, to showcase the blend of data-driven and knowledge-guided design, we create an intervention on studies, a constructed variable, with values "Full-time studies", "Day course", "Evening course" and "No studies", representing the study activity of a person during a year. The initial state of studies is determined by a logistic regression with manually selected coefficients for age, relationship, and education, and intercepts for each of the study types. studies directly affect the education level, current income and the propensity to study in the next year, and indirectly the future income of a subject.

### The causal graph

We construct a cDAG for the Adult data set (_the_ initial-state cDAG for IncomeSCM-1.0) by assigning direct causes to each variable. age, sex, race, and native-country were taken to be base variables without causal parents in the data set. education was deemed to be causal of workclass, which in turn causes occupation and marital-status. marital-status and relationship are closely linked, and the causal direction was chosen to be from the former to the latter. Finally, hours-per-week and capital-net were determined by the previous variables, and income is the furthest downstream, directly caused also by studies, the hand-designed variable. The full graph is illustrated in Figure 1 (middle-left). A very similar graph was used by Nabi and Shpitser (2018) except, in their case, marital-status was a direct cause of education, not the other way around.

For transitions, the full causal graph is too large to be easily legible. Instead, we give an example in Figure 1 (middle-right) and report all direct causes as an edge list in Table 6 in Appendix E. Each variable has transition causes that come either from the previous time step, e.g., age\({}_{t-1}\) age\({}_{t}\), or from the current time, e.g., studies\({}_{t}\)income\({}_{t}\). Base variables age, sex, race and native-country depend only on their previous values.

### The samplers

IncomeSCM implements structural equations through _samplers_, functions of the values of parent variables, and independent sources of noise. The variables are either numeric or categorical. For the initial states of numeric variables \(V\), we use (with few exceptions) an additive noise model,

\[V=f_{V}(V)+_{V}\,\]

where \(f_{V}\) predicts the value of \(V\) given its parents--\(f_{V}\) is a model of the conditional mean, \([V(V)]\)--and \(_{V}\) is a source of homoskedastic noise (e.g., Gaussian). All structural equations for initial-state variables, except for studies, have observations \((V,(V))\) available (income is a special case as described above). For these, \(f_{V}\) is implemented by fitting a regression (e.g., a Random forest regressor) to the observed data, and the scale of \(_{V}\) is chosen proportional to the mean squared regression error. capital-net is an exception to this form, since the majority of capital gains/losses is 0. For this, we blend a classifier that predicts whether the value will be non-zero and a conditional regressor for the case where the value is non-zero.

For categorical variables \(V\{1,...,k\}\), we sample from a categorical distribution given by the softmax function \(\) applied to map \(f_{V}\) from parent variables to logits for the categories of \(V\). By the Gumbel-Max trick (Gumbel, 1954), we can write this as a structural equation

\[V=*{arg\,max}_{j}f_{V}((V))_{j}+_{j}\;,\]

where \(_{j}(0,1)\). For observed pairs \((V,(V))\), the map \(f_{V}\) is fitted using stochastic classifiers, such as logistic regression, classification trees or neural networks with softmax outputs.

Hand-crafted samplers.For equations with no available data, such as for studies and all variable transitions, the samplers are designed by hand. All transition samplers are described in Appendix Table 7. For the intervention variable studies, the initial-state distribution and transitions are described above. The demographic variables native-country\({}_{t}\), sex\({}_{t}\) and race\({}_{t}\) are constant, and age\({}_{t}\) increments deterministically by 1 each time step. For the initial state of the outcome variable income\({}_{1}\) and the transitions \(g_{V}\) of most variables \(V\), we use a blend of hand-designed rules and fitted regressions. This allows us to generate complex dependencies between variables without observing a time series. For example, income\({}_{1}\) is based on a regression of the original binary variable in the Adult data set, with hand-crafted modifications depending on studies and workclass. The transition sampler of relationship\({}_{t}\) has a fixed probability \(p_{}\), that the person will stay in their relationship, relationship\({}_{t}=_{t-1}\). With probability \(1-p_{}\), relationship\({}_{t}\) is resampled from the same fitted model as the initial state, see Figure 1 (right). In this way, only the event that the relationship is changed is hand-designed, but what it is changed to depends on data. A similar strategy is used for all context variables except demographics and education.

## 4 Implementation & data set

IncomeSCM-1.0 is implemented in Python as a "fit-predict" estimator in the style of scikit-learn (Pedregosa et al., 2011). The code for the simulator and for reproducing all experimental results is available at [https://github.com/Healthy-AI/IncomeSCM](https://github.com/Healthy-AI/IncomeSCM). The simulator is configured by a YAML specification of all variables in the system, how they should be learned from data, and how they evolve in a time series. The specification is passed to the simulator at initialization and is used to fit structural equations to observed data from the base data set. We use the variable education as an example of such a variable specification below.

```
education: parents:[age,race,sex,native-country] sampler: type:LogisticSampler multi_class:multinomial seq_parents_curr:[] seq_parents_prev:[education,studies] seq_sampler: type:EducationTransition
```

Here, parents specify the direct causes of the initial state of the variable. sampler specifies the type and parameters of the sampler. In this case, the initial state of education is distributed according to a logistic regression of age, race, sex and native-country. seq_parents_curr specifies the direct causes of the transition probability from the current time step, and seq_parents_prev causes from the previous time step. seq_sampler specifies which function determines this probability. LogisticSampler is a general sampler, that outputs the probability of the given variable as a logistic-linear function of the direct causes specified in parents. General samplers can be reused for other data sets and are defined in samplers.py.

Since the base data set is cross-sectional (from a single time point), EducationTransition is a hand-crafted sampler that returns the distribution of the education variable in the next time step. In this example, Education is determined completely by studies, depending on the type of studies and with a small probability of not advancing due to failing the year.

### Benchmark data set

We construct a single-time causal effect estimation benchmark around the question:What is the effect on the income \(Y_{7}\) of a subject at \(t=7\), six years after a year of \(A_{2}=\)"Full-time studies" compared to \(A_{2}=\)"No studies" at \(t=2\), and then proceeding as they wish?

For this task, we create a cross-sectional observational data set by first sampling from the simulator at time \(t=1,...,7\) where studies are selected by a "default" observational stochastic policy as defined by the samplers in IncomeSCM. Then, time \(t=1\) is used to record the previous income level income_prev and studies_prev, prior to intervention. All other covariates are read off at time \(t_{0}=2\). The binary intervention of interest is then performed at \(t_{0}=2\), with \(A_{2}=1\) representing Full-time studies and \(A_{2}=0\)No studies. The outcome variable \(Y_{T}=\)income\({}_{T}\) is recorded at \(T=7\). We use this to sample \(n=50000\) independent and identically distributed observation sequences, each representing an individual. The sequences are drawn with an incrementing random seed, starting at \(s=0\). First-order covariate statistics of covariates, interventions, and outcomes for this seed can be seen in Table 1. There are no unobserved confounders or temporal confounding in this benchmark task--all direct causes of the intervention are observed in the cross-sectional data set.

To create ground truth for causal effect estimates, we generate two analogous sets of trajectories where the same set of subjects \(i=1,...,m\) are either _all_ assigned \(A_{2}^{i}=1\) (Full-time studies) or _all_ assigned \(A_{2}^{i}=0\) (No studies), thereby recording samples of _both_ counterfactual outcomes \(Y^{i}(0),Y^{i}(1)\) of these subjects. We control that the sets of subjects are identical before both interventions at \(t_{0}=2\) by setting a shared seed, \(s=1\). We use a different seed from the observational data set to measure out-of-sample generalization. The resulting data set(s) of observational and two interventional samples is referred to as IncomeSCM-1.0.CATE.

Identification strategies for the causal effect of any variable in the simulator on any downstream variable can be derived from the edge list in Table 6 using graphical criteria like the backdoor criterion (BDC) (Pearl, 2009). In the benchmark data set, the observed intervention is performed at time \(t=2\) with \(t=1\) being the initial state. By the BDC, a minimal adjustment set for estimating the causal effect of intervening on studies\({}_{2}\) is the set of direct causes of this variable. In IncomeSCM-1.0, studies\({}_{t}\) at times \(t>0\) are directly caused by studies\({}_{t-1}\), income\({}_{t-1}\), age\({}_{t}\), sex\({}_{t}\),education\({}_{t}\), and relationship\({}_{t}\).2 Regression adjustment of potential outcomes or propensity-based adjustment using these variables leads to the identification of causal effects. Expanding this set with any pre-intervention variables (e.g., other variables at times \(t=1,2\)) also results in valid adjustment sets.

We consider three tasks on the same dataset based on the following causal estimands:

1. ATE and CATE conditioned on the full set of pre-intervention covariates, including previous income and previous studies.
2. ATE and CATE conditioned only on the direct causes of the intervention \(A_{2}\).
3. CATE, conditioned only on education\({}_{2}\) (not itself a valid adjustment set), represented as 16 numeric bins, using the full adjustment set from Task 1.

Task 3 is an example of when the conditioning set of the CATE differs from any valid adjustment set. That is, to estimate the CATE conditioned only on education\({}_{2}\), it is not sufficient to adjust only for this variable; it requires a slightly unusual application of common causal effect estimators.

## 5 Experiments

The observational base statistics for IncomeSCM-1.0.CATE, as well as fitting results for samplers fit to data (\(R^{2}\) for continuous variables, AUC for discrete variables) are presented in summarized form in Table 1. The full set of statistics for categorical variables is presented in the Appendix, Table 4.

We see a generally good match in the base statistics of variables, with the biggest discrepancy for income>50k. This is due to renormalizing the simulator samples to achieve an average income of $70 000 before applying noise and correcting for the effects of studies and workclass = Without-pay. The discriminative performance for the fitted samplers (AUC/\(R^{2}\)) varies greatly between variables, some (such as marital-status) being more predictable from their parents in the posited causal graph than others (such as capital-net). This is expected since the original data set was not constructed with predicting _all_ variables in mind, nor are all available variables used for prediction, only the causal parents. However, it does mean that the values of variables with low discriminative performance are largely determined by exogenous noise.

Causal effect estimators.We include regression estimators in the form of T-learners, which fit one model per potential outcome, and S-learners, which treat the intervention as an input to a single model, mixed in with adjustment variables (Kunzel et al., 2019). For both, we compare multiple base estimators in ridge regression (Ridge), random forests (RF), and XGBoost (XGB). Second, we use two classical inverse-propensity weighting estimators, the Horvitz-Thompson (IPW) and Hayek or "Weighted" (IPW-W). Third, we include three double-machine learning (DML) estimators created by fitting regressions to the target \(-M_{Y}(x_{i})}{a_{i}-M_{A}(x_{i})}\), where \(M_{Y},M_{A}\) model \([Y X]\) and \(p(A=1 X)\) respectively, using sample weights \(w_{i}=(a_{i}-M_{A}(x_{i}))^{2}\). This stems from the residualization of Robinson (1988), as used by Chernozhukov et al. (2018). The three variants use different base estimators of the nuisance functions. DML (Mix) uses an XGBoost regressor for \(M_{Y}\), logistic regression for \(M_{A}\), and linear regression for the cate estimator. Finally, we include a nearest-neighbor

   Variable & IncomeSCM-1.0 & Adult & \(R^{2}\)/AUC \\  \(n\) & 50000 & 30162 & \\ native-country (+ 30 more categories) & & & \(\) \\ United-States & 45519 (91.0) & 27504 (91.2) & \\ sex = Female & 16206 (32.4) & 9782 (32.4 & \(\) \\ race (+ 3 more categories) & & & \(\) \\ White & 42947 (85.9) & 25933 (86.0) & \\ Black & 4677 (9.4) & 2817 (9.3) & \\ age & 41.1 (32.0, 49.0) & 38.4 (28.0, 47.0) & \(\) \\ education (+ 14 more categories) & & & 0.68 \\ HS-grad & 15086 (30.2) & 9840 (32.6) & \\ Some-college & 9558 (19.1) & 6678 (22.1) & \\ workclass (+ 5 more categories) & & & 0.70 \\ Some-college & 9558 (19.1) & 6678 (22.1) & \\ Self-emp-not-inc & 3804 (7.6) & 2499 (8.3) & \\ occupation (+ 12 more categories) & & & 0.81 \\ Prof-specialty & 6968 (13.9) & 4038 (13.4) & \\ Craft-repair & 6626 (13.3) & 4030 (13.4) & \\ marital-status (+ 4 more categories) & & & 0.77 \\ Married & 26695 (53.4) & 14456 (47.9) & \\ relationship (+ 4 more categories) & & & 0.92 \\ Husband & 17263 (34.5) & 12463 (41.3) & \\ Wife & 6767 (13.5) & 1406 (4.7) & \\ capital-net & 1081.1 (0.0, 0.0) & 1003.6 (0.0, 0.0) & 0.11* \\ hours-per-week & 42.0 (26.0, 57.0) & 40.9 (40.0, 45.0) & 0.28 \\ studies & & & \\ Full-time studies & 6586 (13.2) & & & \\ No studies & 25241 (50.5) & & & \\ income50K (baseline) & 21167 (42.3)\(\) & 7508 (24.9) & & \\ incomeprev (\$1000) & 60.1 (16.1, 82.9) & & 0.93\({}^{}\) \\ income (\$1000) & 78.2 (34.6, 103.1) & & & \\   

Table 1: Baseline characteristics in the IncomeSCM-1.0 cohort at \(t=0\) and the base data set Adult (after removing missing values), as well as in-sample fit quality. Categorical variables are reported as number (rate) and continuous variables as mean (interquartile range). \(\)The proportion of subjects with income higher than S50 000 is higher in IncomeSCM-1.0 than in Adult since the average income was calibrated to match the US population of 2023. \({}^{}\)Base variables do not involve modeling, only computing proportions/means. \({}^{*}\)The capital-net regressor is fit only to sample with non-zero result. Fit quality is reported as \(R^{2}\) for continuous variables and AUC for categorical variables. \({}^{}\)The income variable is evaluated using AUC since the raw data has binary income indicators.

matching estimator with a Euclidean metric. The IPW, matching, and Ridge-regression S-learner estimators return estimates only of the ATE, not the CATE. For a more detailed description of all estimators, see Appendix F.

Hyperparameters for all estimators (see Appendix Table 8) were selected based on 5-fold cross-validation of 20 uniformly sampled hyperparameter settings. The estimators were then refitted to the entirety of the observational training data. Producing all results, including fitting the simulator, sampling, estimating, and evaluating causal effects, took less than 1 hour on a 2023 M2 MacBook Pro. The results were replicated on a 2 x 16 core Intel(R) Xeon(R) Gold 6226R CPU @ 2.90GHz with minimal differences except for XGBoost which is known to yield different fits for different machines.

Results.We present the results for causal effect estimation Tasks 1 & 2 in Table 2 and for Task 3 in Table 3 and Figure 2. IPW methods and S-learner (Ridge) are excluded from the latter two since these methods do not return heterogeneous effect estimates, only estimates of the ATE. The fit to observables was good for both propensity models (AUC \( 0.98\) in predicting observed treatments) and regression estimators (\(R^{2}\) 0.80 in predicting observed outcomes). Despite this, all causal estimation tasks were challenging for the methods to solve. The best methods achieved CATE \(R^{2}\) of

  Estimator & \(R^{2}\) CATE (\(\)) & AE ATE (\$\(\)) & AUC/\(R^{2}\) CV (\(\)) \\  “Full” adjustment set: All covariates & & & & \\  IPW (LR) & & 18645 & (18121, 19166) & 0.98 \\ IPW (RF) & & & 57025 & (56501, 57546) & 0.98 \\ IPW-W (LR) & & & 4878 & (4354, 5398) & 0.98 \\ IPW-W (RF) & & & 17406 & (16882, 17927) & 0.98 \\ Match (EU-NN) & & & 7147 & (6623, 7668) & -1.56 \\ S-learner (Ridge) & -0.00 & (-0.00, -0.00) & 400 & (22, 901) & 0.79 \\ S-learner (XGB) & 0.15 & (0.14, 0.15) & 533 & (90, 1023) & **0.84** \\ S-learner (RF) & 0.03 & (0.03, 0.03) & 487 & (50, 985) & **0.84** \\ DML (Linear) & -0.02 & (-0.02, -0.02) & 8299 & (7784, 8817) & 0.79 \\ DML (XGB) & -0.25 & (-0.26, -0.23) & 4580 & (4012, 5199) & 0.83 \\ DML (Mix) & 0.06 & (0.06, 0.07) & 6069 & (5575, 6581) & 0.83 \\ T-learner (Ridge) & 0.24 & (0.23, 0.25) & 1696 & (1213, 2164) & 0.80 \\ T-learner (XGB) & 0.24 & (0.23, 0.25) & **207** & (10, 574) & 0.83 \\ T-learner (RF) & **0.30** & (0.29, 0.31) & 2719 & (2256, 3165) & **0.84** \\   \\  IPW (LR) & & & 12106 & (11582, 12627) & 0.97 \\ IPW (RF) & & & 58118 & (57594, 58638) & 0.98 \\ IPW-W (LR) & & & 3369 & (2845, 3890) & 0.97 \\ IPW-W (RF) & & & 16133 & (15609, 16653) & 0.98 \\ Match (EU-NN) & & & 8937 & (8413, 9458) & -1.56 \\ S-learner (Ridge) & -0.00 & (-0.00, -0.00) & 1701 & (1177, 2222) & 0.78 \\ S-learner (XGB) & 0.14 & (0.14, 0.14) & 1528 & (1020, 2012) & **0.80** \\ S-learner (RF) & 0.02 & (0.02, 0.03) & **1143** & (630, 1643) & **0.80** \\ DML (Linear) & **0.21** & (0.20, 0.22) & 2722 & (2239, 3177) & 0.78 \\ DML (XGB) & -1.13 & (-1.17, -1.10) & 16305 & (15558, 17033) & 0.79 \\ DML (Mix) & 0.18 & (0.17, 0.20) & 11887 & (11405, 12329) & **0.80** \\ T-learner (Ridge) & 0.20 & (0.18, 0.21) & 6104 & (5630, 6595) & 0.79 \\ T-learner (XGB) & -0.13 & (-0.15, -0.11) & 16549 & (16012, 17095) & 0.79 \\ T-learner (RF) & 0.16 & (0.14, 0.17) & 10931 & (10453, 11406) & **0.80** \\  

Table 2: Results estimating CATE and ATE using the full IncomeSCM-1.0.CATE data set. \(R^{2}\) is the coefficient of determination, AE is the absolute error. AUC/\(R^{2}\) CV are the (non-random) 5-fold cross-validation AUC of the propensity estimate, and \(R^{2}\) of the observed outcome, for propensity and regression estimators, respectively. For \(R^{2}\) CATE and AE ATE, the confidence intervals (\(=0.05\)) are computed by 1000 bootstrap iterations over test samples. An unbiased estimate of the ATE is $40 919. Empty cells are intentionally left out as they don’t apply to the corresponding estimators.

only 0.30, 0.20, and 0.33 on Tasks 1, 2, and 3, respectively, falling short of explaining the majority of variation in these effects with the respective conditioning set. This is likely in large part to the separation between intervention and outcome by a horizon of six time steps (years), which introduces substantial uncertainty and functional complexity into the process.

No method is consistently at the top: The best CATE estimator is not the best ATE estimator and the best CATE estimators are different for Tasks 1, 2, and 3. More importantly, the best factual fit (e.g., S-learner (RF) in Task 1) does not yield the best effect estimates. Despite great discrimination of the fitted propensity scores, IPW estimators generally returned ATE estimates with large errors. These results show the importance of constructing several evaluation tasks to understand which methods are preferable in which circumstances. For example, in Figure 2, we see that S-learner (XGB) captures very little of the variation in CATE with education, despite passable performance in Task 1.

## 6 Discussion

We have presented the simulator and sequential structural causal model IncomeSCM-1.0, modeled on the Adult data set. The simulator exemplifies a general strategy for creating simulators with causal structure from cross-sectional data sets and use these to create benchmarks for causal effect estimation with challenging complexity. However, the current version and benchmark data set have several limitations. First, all trajectories are equally long, with a fixed horizon of \(T\) years. This matches observational studies with a fixed follow-up window but is not representative of a common data analysis challenge: censoring. Specifically, no subjects leave the "study", either by choice or due to death. Since the age distribution of the initial state follows the census data behind the Adult data set, if the horizon \(T\) is set to 100, the simulator would generate samples of humans well over 150 years of age. Similarly, missing values are a challenge in many observational studies but are not generated by the simulator in its current form. Studying the effects of missingness on the ability of estimators to adjust for confounding bias is an interesting direction for future work. Finally, the estimators used to fit initial-state mechanisms were fit with a single set of hyperparameters. It is likely that the fit to Adult could be improved slightly by optimizing these.

Our benchmarking results show that models with comparable fit to observed variables can vary greatly in the quality of their causal effects estimates, highlighting the challenge of the tasks and the importance of developing purpose-built data sets, causal estimators, and model selection criteria.