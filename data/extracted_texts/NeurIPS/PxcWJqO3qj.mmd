# Learning Exponential Families from Truncated Samples

Jane H. Lee

Department of Computer Science

Yale University

jane.h.lee@yale.edu

&Andre Wibisono

Department of Computer Science

Yale University

andre.wibisono@yale.edu

&Manolis Zampetakis

Department of Computer Science

Yale University

emmanouil.zampetakis@yale.edu

###### Abstract

Missing data problems have many manifestations across many scientific fields. A fundamental type of missing data problem arises when samples are _truncated_, i.e., samples that lie in a subset of the support are not observed. Statistical estimation from truncated samples is a classical problem in statistics which dates back to Galton, Pearson, and Fisher. A recent line of work provides the first efficient estimation algorithms for the parameters of a Gaussian distribution  and for linear regression with Gaussian noise .

In this paper we generalize these results to log-concave exponential families. We provide an estimation algorithm that shows that _extrapolation_ is possible for a much larger class of distributions while it maintains a polynomial sample and time complexity on average. Our algorithm is based on Projected Stochastic Gradient Descent and is not only applicable in a more general setting but is also simpler than the recent algorithms of . Our work also has interesting implications for learning general log-concave distributions and sampling given only access to truncated data.

## 1 Introduction

In many statistical estimation and inference problems, we have access to only a limited part of the data that would be necessary for the classical statistical methods to work, which motivates the development of statistical methods that are resilient to _missing data_. _Truncation_ is a fundamental and frequent type of missing data and arises when samples that lie outside a subset of the support are not observed and their count is also not observed. Statistical estimation from truncated samples is the focus of the field of truncated statistics, which was developed since the beginning of the twentieth century starting with the work of Galton , Pearson and Lee , and Fisher . Truncated statistics is widely applicable in Econometrics and many other theoretical and applied fields .

A recent line of work establishes the first sample optimal and computationally efficient methods for fundamental statistical estimation problems from truncated samples . All the aforementioned works though heavily rely on the Gaussianity of the distribution of data or the Gaussianity of the noise in regression problems. Gaussianity is an idealized assumption and the question of generalizing truncated statistics beyond Gaussianity has been explored in many existing works, e.g., . The only results in this regime though are for single dimensional problems and truncations that can be described as intervals.

In this work we provide _statistically and computationally efficient methods for estimating the parameters of exponential families from truncated samples_. Our results generalize the recent work of  and are the first to provide an estimation algorithm for this problem for a general class of exponential families and for a general class of truncation biases.

_Exponential families_ are one of the most influential type of distribution classes since they include many fundamental distributions such as normal, exponential, beta, gamma, chi-squared, and Weibull distributions. They were first introduced by Fisher  and later generalized by . The estimation of the parameters of exponential families over continuous domains is the subject of many classical and recent results; starting from the work of Fisher  until the recent results of . This line of work has also found applications in many areas of statistics including causal inference . Our work contributes in this line of research as well since we show how to estimate exponential families even when we only have access to truncated samples.

### Our Results

For every distribution \(p\), we define the truncated version \(p^{S}\) as the distribution with density that satisfies \(p^{S}()\{ S\} p()\). We consider distributions \(p_{}\) with support \(^{m}\) parameterized by a vector of parameters \(^{k}\) that can be written in the following form:

\[p_{}() h()( ^{}T())\]

where \(h\) and \(T\) are known functions and \(T\) is called the _sufficient statistics_ of the exponential family. Our goal is to estimate the vector of parameters \(\) up to \(\) error in \(_{2}\) distance using only samples from \(p^{S}_{}\) when we have oracle access to \(S\), i.e., there is an oracle that for every \(\) can answer whether \( S\) or not.

Without any further assumptions estimation from truncated samples is impossible as shown in . In this paper we use the following assumptions to get our estimation guarantees:

**Assumption I**: _We assume a lower bound and an upper bound on the variance of the sufficient statistics in any direction. This assumption is used in estimation of the parameters of exponential families even without truncated samples, e.g., Assumption 4.1 in ._
**Assumption II**: _We assume that the exponential families contain log-concave distributions. We use this assumption in two places: (1) to show our extrapolation result, our distributions must satisfy an anti-concentration property; this is a property that is heavily utilized even in estimating a Gaussian distribution , (2) we require access to a sampling oracle for the underlying distributions; this sampling oracle can be implemented efficiently using Langevin dynamics if we have log-concavity._
**Assumption III**: _We assume that the sufficient statistics \(T\) are bounded degree polynomials. This assumption combined with log-concavity provides the anti-concentration property that we

Figure 1: Visualizing the density and truncation set for 2-dimensional exponential distribution. The plot on the left is the density of \(p(x_{1},x_{2})(-}{5}-}{2})\). On the right is a contour plot of the truncation set \(\) under \(p(x_{1},x_{2})\). Note that \([X_{1}]=5\) and \([X_{2}]=2\), so the truncation set excludes the mean in one direction and includes it only as a boundary point in the other.

need. Alternatively, we can assume that the sufficient statistics belongs to a function class that satisfies anti-concentration but for simplicity of exposition we focus on the case where \(T()\) is a polynomial.

Our main result is the following.

**Informal Theorem 1.1** (See Theorem 3.1 for the formal statement).: Under Assumptions I, II, III, and given samples \(n\) (at least \(}(k/^{2})\) for some \(\)) from \(p^{S}_{^{*}}\), where \(S\) is a measurable set to which we have oracle access, there exists an estimation algorithm with (expected) running time \((m,k,n)\) that outputs \(}\) such that with probability at least 99%, it holds that \(\|}-^{*}\|<\).

Our main result has the following important implications:

* We show that our assumptions are satisfied from exponential distributions, Weibull distributions, continuous Bernoulli, continuous Poisson, Gaussian distributions, and generalized linear models. Hence, our result implies an efficient method for estimation from truncated samples for all these distribution classes.
* Another interesting corollary of our result is that we can combine it with the ideas of  and get a general method for learning log-concave distributions from truncated samples. In particular, assume that we want to learn from truncated samples a distribution that can be written in the form \(p()(-f())\) where \(f\) is a convex function. Now under mild assumptions, we can replace \(f()\) with a finite Taylor approximation, i.e., we have that \(f()_{i}a_{i}t_{i}()\) for some polynomials \(t_{i}()\). Then, using our method we can estimate the parameters \(a_{i}\) and output an estimation of \(p\).
* In the context of sampling, the gradient of the log-likelihood is the score function that is needed to run Langevin dynamics (e.g., see [30; 7]). Our result also says that we are able to sample from the original distribution, given that we only observe truncated samples.

Technical Contributions.Our algorithm is _projected stochastic gradient descent (PSGD)_ on the _negative log-likelihood_ function and is the same algorithm that is used in many of the recent works in truncated statistics. As in the previous work though, the main challenge is to show that PSGD will converge in our general setting. The previous analysis of the convergence of PSGD was based on exact properties of the Gaussian distribution. When we move away from Gaussianity every step of the convergence analysis becomes much more technical and we need to make sure to only use properties that generalize to exponential families beyond Gaussian distributions. In particular, certain results such as that of Lemma 3.6 and its related quantities in C.1 can be generalized even beyond exponential families, holding for any density.

### Related Work

Our most related literature is the recent series of works on truncated statistics which includes the following results: estimation of multivariate normal distributions , linear regression with Gaussian noise [10; 26; 11; 13; 14; 37], estimation of product distributions over the hypercube , non-parametric density estimation . All of these works heavily rely on properties of the Gaussian distributions, or product distributions over the hypercube, or their dependence in the number of dimensions is not efficient, e.g., . In our work we identify the properties of exponential families that are only required to get the efficient estimation results and we show that linear dependence on the dimension is achievable in settings that are more general than the Gaussian case.

Another related work is that of  that solves parameter estimation of a truncated density given samples through the score matching technique. To derive a tractable objective, we need appropriate boundary conditions which are not satisfied by truncated densities, but  instead uses a modified weighted Fisher distance given that the truncation set \(S\) is a Lipschitz domain (a type of open and connected set). On the other hand, our work assumes no particular structure about \(S\) and hence our results are more general and applicable in much more complicated settings for exponential families.

## 2 Preliminaries

Notation.Lowercase bold letters will denote real-valued vectors, e.g., \(^{m}\), and uppercase bold letters will denote matrices with real values, e.g., \(^{n m}\). For a random vector \(\)\([]=[,]=[(- [])(-[])^{}]\) is its covariance matrix, and \(()\) is the trace of the covariance matrix (a scalar value). Depending on whether it is clear from context, \(\) and \(\) may include subscripts to indicate the distribution \(\). The notation \(B(c,R)\) is the Euclidean ball centered at \(c\) with radius \(R>0\).

Exponential Families.Let \(^{m}\). We are interested in a class of densities which have the form,

\[p_{}()=h()(^{}T()-A()),\]

where \(h:^{m}_{+}\) is the _base_ or _carrier measure_, \(\) with \(=\{^{k}:A()<\}\) is the _natural parameter space_, \(T:^{m}^{k}\) is the _sufficient statistic_ for \(\), and \(A()= Z()\) is the log-partition function, where \(Z()= p_{}()d\).

A _regular_ exponential family is one where \(\) is an open set. It is _minimal_ if the \(\) and \(T()\) are each linearly independent. Any non-minimal family can be made minimal by appropriate reparametrization. In any regular exponential family, \(A()\) is convex. It is strictly convex if the representation is minimal. Exponential families have several nice properties (e.g., see Theorem 1 of ), among which are that \( A()=_{p_{}}[T()]\) and \(^{2}A()=_{p_{}}[T( )]\).

Truncated Distributions.Let \(\) be a probability distribution on \(^{m}\). We represent \(\) as a probability density function with respect to the Lebesgue measure \(d\) on \(^{m}\). Let \(S^{m}\) be such that \((S)=\) for some \((0,1]\). Let \(^{S}:=( S)\) be the conditional distribution of \(\) given that \( S\). Concretely, the density of \(^{S}\) is

\[^{S}()=)\{ S \}}{(S)}.\]

For exponential families, we have the truncated density \(p_{}^{S}()\) is:

\[p_{}^{S}()=}( )}{_{S}p_{}()d} \{ S\}=)(^{ }T())}{_{S}h()(^{}T( ))d}\{ S\}.\]

See Figure 1 for an illustration.

Sub-Exponential Distributions.Although the term sub-exponential has been overloaded (e.g.,  v.s.), the definition we will use describes a class of distributions whose tails decay at least as fast as an exponential, but with potentially heavier tails than Gaussians .

There are several equivalent characterizations of sub-exponential random variables (e.g., see Prop. 2.7.1 of ), one of which uses the moment generating function.

**Definition** (Sub-exponential random variable).: A centered, real-valued random variable \(X SE(^{2},)\) is sub-exponential with parameters \(^{2},>0\) if

\[[e^{ X}] e^{^{2}}{2}},\ \ :||<1/.\]

Membership Oracle of a Set.Let \(S^{m}\). A _membership oracle_ is an efficient procedure which computes \(\{ S\}\).

## 3 Projected Stochastic Gradient Descent Algorithm

Problem Setup.We are given truncated samples \(\{_{i}\}_{i=1}^{n}\), with each \(_{i} p_{^{*}}^{S}\), where \(p_{^{*}}(S)=>0\). Without knowledge of the truncation set \(S\) beyond access to a membership oracle, can one recover \(^{*}\) and thus \(p_{^{*}}\) efficiently?

We answer this question positively, under the following assumptions:

**Assumption A1** (Strong Convexity, Smoothness of Non-truncated Negative Log-Likelihood over \(\)).: \[ I_{ p_{}}[T( ),T()] LI,\]

for some \(,L>0\). Here, we've abused notation for \(\) which can be a subset of the entire natural parameter space. As mentioned earlier, this is always at least convex for exponential families and strictly convex in minimal representation. Thus the negative log-likelihood (of the non-truncated density) can be made strongly convex and smooth by restricting the natural parameter space appropriately.

**Assumption A2** (Log-Concave Density).: The density \(p_{}()\) is log-concave in \(\).

**Assumption A3** (Sufficient Statistics \(T()\) is polynomial in \(\)).: \(T()^{k}\) has components which are polynomial in \(\), with degree at most \(d\).

Assumptions A2 and A3 allow us to use the anti-concentration result needed for Lemma 3.2 which is heavily utilized even in the Gaussian case. While A2 also allows for efficient sampling via Langevin dynamics, the latter is only used in Lemma 3.2. Refer back to 1.1 for discussion of these assumptions.

**Main Result.**

**Theorem 3.1** (Main).: Given membership oracle access to a measurable set \(S\) whose measure is some constant \((0,1]\) under an unknown exponential family distribution \(p_{^{*}}\) which satisfies A1, A2, A3, and given samples \(_{1},,_{n}\) from \(p_{^{*}}\) that are truncated to this set, there exists an expected polynomial-time algorithm that recovers an estimate \(}\). That is, for any \(>0\) the algorithm

* Uses an expected \(}(k/^{2})\) truncated samples and queries to the membership oracle,
* Runs in expected \((m,k,1/)\) time.
* Produces an estimate \(}\) such that with probability at least 99%, \[\|}-^{*}\|<.\]

In order the solve this problem, we need to define an objective whose optimum is \(^{*}\) and we need to be able to recover it uniquely. To use maximum likelihood estimation (or minimize the negative log-likelihood), we have to be able to compute gradients which depend on the truncation set \(S\), which we cannot do directly without more knowledge about \(S\). However, we can sample unbiased estimates of the gradient, as long we have non-trivial mass on \(S\) at a current parameter estimate (otherwise the truncated likelihood function at that parameter is not well-defined and rejection sampling would take infinite time). To address all of these issues, the organization of this section is as follows:

* Section 3.1 establishes that after truncation, the negative log-likelihood remains strongly convex and smooth (in \(\)) over a subset of parameters which have non-trivial mass on the truncation set.
* In Section 3.3, we show that while we do not know the truncation set, we can solve the non-truncated MLE problem with truncated samples to find an initial parameter \(_{0}\) which assigns non-trivial mass to the truncation set.
* Then given this \(_{0}\), in Section 3.2 we show that we can construct a set of parameters \(K\) which all assign non-trivial mass to the truncation set (and contains the true parameter \(^{*}\)).
* In Section 3.4, we use results from the previous sections to prove that we can efficiently recover the true parameter \(^{*}\) using a stochastic gradient descent procedure minimizing the truncated negative log-likelihood, which projects to the parameter space \(K\).

### Strong Convexity and Smoothness of Truncated Negative Log-Likelihood

Without truncation, recovering the true parameter \(^{*}\) for any parameterized distribution given samples is a classical problem solved by maximizing the likelihood (or minimizing its negation). Here, we state the main objective we will minimize through a stochastic gradient descent procedure as well as the properties of this objective that will allow us to recover \(^{*}\). Define:

\[() :=-_{ p_{^{*}}^{S}}[ p_{}^{S}()]\] \[_{}() =_{ p_{}^{S}}[T()]- _{ p_{^{*}}^{S}}[T()]\] \[_{}^{2}() =_{ p_{}^{S}}[T(), T()]\]

Note that since the Hessian is a covariance matrix which is at least PSD, this objective is always convex in \(\). Thus \(^{*}\) is a minimizer since it satisfies the first-order optimality condition. (These calculations can be found in Appendix A.1.) However, if the objective is too flat, we may not be able to recover \(^{*}\) even after sufficiently reducing the objective value. For this, we prove that if the original non-truncated covariance has bounded eigenvalues, the truncated one does as well under A1, A2, and A3 at parameters which assign non-trivial mass to \(S\).

**Lemma 3.2** (Preservation of Strong Convexity under Truncation).: Assume the lower bound in A1, A2, A3. If \(p_{}(S)>0\), then

\[_{ p_{}^{S}}[T(),T()] (}(S)}{4Cd})^{2d} I,\]

where \(C\) is a universal constant guaranteed by Theorem 8 of  and \(d\) is the maximum degree of \(T()\). See proof in Appendix A.2 which follows that of .

**Lemma 3.3** (Preservation of Smoothness under Truncation).: Assume the upper bound in A1. Suppose \(p_{}(S)>0\), then

\[_{ p_{}^{S}}[T(),T()] }(S)}LI.\]

See proof in Appendix A.3. The proof is simple and can be done similarly to the previous lemma.

Thus, we have shown that as long as we optimize over a parameter space where every \(\) assigns non-trivial mass to the truncation set, our objective is both strongly convex and smooth. The following sections will help us determine and then construct this set given samples.

_Remark_.: Note that the upper bound increased and the lower bound decreased for the eigenvalues of the truncated covariance matrix. Even in a one-dimensional simple case like \((0,1)\), it is easy to construct examples of both increasing the shrinking the variance given freedom to place mass anywhere under \((0,1)\). Thus, it may be natural that the eigenvalue range expands after truncation.

_Remark_.: Lemma 3.2 and the log-likelihood calculations are direct generalizations of prior work in the Gaussian case, where we can recover the results of  by noting that the re-parameterization of Gaussian parameters \((,)\) as \(=^{-1}\) and \(=^{-1}\) is the natural parameterization of multivariate Gaussian distributions in exponential family form (up to constants). The sufficient statistics here \(T()[,^{}]\) has components which are polynomial in \(\) with degree at most 2, and plugging in \(d=2\) to Lemma 3.2 recovers Lemma 4 in . Appendix B includes other examples beyond Gaussians which satisfy A1, A2, and A3.

### Parameter Space with Non-Trivial Mass on Truncation Set

The prior section established that the strong convexity and smoothness parameter of the truncated objective is controlled by the mass that \(p_{}\) assigns to the truncation set \(S\) for any given \(\). In this section, we will prove lower bounds on the mass that \(p_{}\) assigns to the truncation set, given that the parameter distance to the optimum \(\|-^{*}\|\) is bounded.

**Lemma 3.4** (Lower bound for mass on truncation set under smoothness given parameter distance).: Assume A1. Let \(,^{}\). Then for two distributions from the same exponential family

\[p_{}(S) p_{^{}}(S)^{2}(-\|-^{}\|^{2}).\]

Proof is provided in Appendix C.3, and only needs smoothness. Thus, we can lower bound the mass that a parameter \(\) assigns to \(S\) given its distance \(\|-^{*}\|\) from \(^{*}\) which is assumed to have \(p_{^{*}}(S)=\).

Thus, to make use of this property we want to establish a procedure to initialize a parameter \(_{0}\) such that its distance to the optimum \(^{*}\) is bounded. Then during the optimization procedure we will make sure to make progress toward \(^{*}\). The following is the result we will be able to prove after proving some results between truncated and non-truncated quantities in the following Section 3.3.

**Corollary 3.5** (Parameter space with non-trivial mass on truncation set).: Given \(_{0}\) such that \(E_{p_{_{0}}}[T()]=\) where \(=_{i=1}^{n}T(_{i})\) is the empirical mean sufficient statistics given our samples \(\{_{i}\}_{i=1}^{n}\) for each \(_{i} p_{^{*}}\), if we define

\[K=B(_{0},+( 1/)}{ })\]

then \(p_{}(S)^{2}(-}(_{S} +( 1/))^{2})>0\) holds \( K\) (with probability at least \(1-\) for \(n((1/))\)). Furthermore, \(^{*} K\) (as long as \(^{*}\) satisfies conditions of Claim 1).

This result will follow from Lemma 3.4, Claim 1, Lemma 3.7, and Lemma 3.9 in the next section.

### Initialization with Empirical Samples and Non-truncated MLE

Given samples from the truncated density \(p_{^{*}}^{S}\), one may first try to solve the non-truncated empirical MLE problem to find a parameter \(_{0}\) without truncation and hope that it is good enough. (We will show that it is.) In order to understand how good this initial guess is, we need to establish some relationships between the truncated and non-truncated density.

**Lemma 3.6** (Truncated vs. Non-truncated Mean Sufficient Statistics for General Densities).: Let \(\) be a probability distribution on \(^{d}\) (not necessarily from an exponential family). Let \(S^{d}\) with \((S)>0\). Then

\[\|_{^{S}}[]-_{}[]\|}_{}()}.\]

Proof of this lemma and several related quantities for general truncated densities is in Appendix C.1. In low dimensions, this variance term may effectively be a constant; however, in high-dimensional settings this term can grow with dimension (which is undesirable if we want an efficient algorithm). Given more assumptions about the density, we can get better dimension-free bounds which generalize the results from the Gaussian case.

**Claim 1**.: Let \(\) such that \(+\) for some \(>0\) for all unit vectors \(\) and such that Assumption A1 holds for \(p_{}\) from an exponential family. Then \(X^{}(T()-_{ p_{}}[T()])\) is \(SE(L,)\). (Proof provided in Appendix C.2.)

_Remark_.: This claim allows us to have concentration of the empirical mean sufficient statistics to its population mean for the non-truncated distribution. The prior work  analyzed the mean and covariance of a Gaussian separately, but for instance to establish bounds on distances between the truncated and non-truncated mean parameter, it made use of Gaussian concentration inequalities (which are tighter than sub-exponential ones). The relationship between the truncated density and the non-truncated one will allow us to say that the empirical truncated mean sufficient statistics is also somewhat close to the non-truncated population mean.

**Lemma 3.7** (Concentration of Empirical vs. Non-truncated Mean Sufficient Statistics).: Suppose \(^{*}\) satisfies the conditions of Claim 1 and \(p_{^{*}}(S)=>0\). Let \(=_{i=1}^{n}T(_{i})\) be the empirical mean sufficient statistics given our samples \(\{_{i}\}_{i=1}^{n}\) each \(_{i} p_{^{*}}^{S}\). Let \(_{S}>0\). For \(n(}())\), with probability at least \(1-\),

\[\|-_{p_{^{*}}}[T()]\|_ {S}+( 1/).\]

It should be noted that it suffices to consider \(_{S}\) as some independent constant (and not related to the \(\) accuracy parameter in the main theorem). However, by taking \(n\) at least \(}(k/^{2})\) as stated in the main theorem, this will be small. See proof in Appendix C.4.

_Remark_.: At a high level, the truncated samples can be thought of as \((n/)\) samples from the non-truncated distribution (keeping only those in \(S\)), and each are "not too far" (depending on how much mass the set \(S\) has under the non-truncated distribution) from the non-truncated mean due to concentration. Note that the \(( 1/)\) term will never disappear even as we increase \(n\), which quantifies the inherent bias that the truncated mean sufficient statistics will have with respect to the non-truncated one (and is large if the mass \(\) is small). From this, we can also say something about the population mean sufficient statistics, one on the truncated distribution and one on the non-truncated.

**Corollary 3.8** (Truncated vs. Non-truncated Mean Sufficient Statistics).: Let \(\) satisfy the conditions of Claim 1 and \(p_{}(S)>0\). Then

\[\|_{p_{}^{S}}[T()]-_{ p _{}}[T()]\|( 1/p_{}(S)).\]

The proof follows from the preceding lemma, replacing \(\) with \(p_{}(S)\) and taking \(n\). Compare this to the Gaussian case , where the mean and truncated means were bounded as \(\|-_{S}\|(}(S)})\) and separately the covariances were bounded as \(\|^{-1/2}_{S}^{-1/2}-\|_{F} ( 1/p_{}(S))\). Note the smaller \((}(S)})\) quantity due to tighter Gaussian concentration vs. the sub-exponential rate.

Once we have bounds on the norm of the difference between the truncated and non-truncated mean sufficient statistics, we can bound distance in parameter space. The following completes this.

**Lemma 3.9** (Non-truncated MLE Solution Distance to \(^{*}\)).: Suppose \(^{*}\) satisfies the conditions of Claim 1 and \(p_{^{*}}(S)=>0\). Let \(_{0}\) be such that \(_{p_{_{0}}}[T()]=\) where \(=_{i=1}^{n}T(_{i})\) given each \(_{i} p_{^{*}}^{S}\). Let \(_{S}>0\) and \(n>(}(1/))\). Then w.p. at least \(1-\),

\[\|_{0}-^{*}\|(( 1/ )+_{S}).\]

Proof.: Define \(^{}()_{  p_{_{0}}}[- p_{}()]\). Its gradient and Hessian calculations can be done similarly to \(()\), the truncated version, but with \(S=\) the full support of the distribution.

Since \(E_{ p_{^{*}}}[T()]-_{  p_{_{0}}}[T()]=(^{* })^{}\) is the gradient of the untruncated negative log-likelihood whose optimum is at \(_{0}\), by A1 this gives

\[\|^{}(^{*})-^{}(_{0})}_{0}\|\|_ {0}-^{*}\|\|_{0}-^{*}\|\|^{}(^{*})\|\]

where the result follows from the fact that \(_{ p_{_{0}}}[T()]=\) and \(\|_{ p_{^{*}}}[T()]- \|( 1/+_{S})\) w.p. \(1-\) from Lemma 3.7. 

Note that this result combined with Lemma 3.4 gives Corollary 3.9.

### Analysis of Projected Stochastic Gradient Descent Algorithm

Now we have all the tools we need to analyze the main algorithm. For ease of notation, define \(d()_{S}+( 1/)\) which is a constant that depends on \(\). The following describes the projected stochastic gradient descent algorithm referenced by Theorem 3.1.

```  Given \(\{_{i}\}_{i=1}^{n}\), each \(_{i} p_{^{*}}^{S}\).  Initial \(_{0}^{k}\) s.t. \(_{ p_{_{0}}}[T()]=\), where \(=_{i}T(_{i})\). for\(i=0,,N\)do \(_{i}\) = SampleGradient\((_{i},_{i})\) \(_{i+1}_{i}-_{i}\)  Project \(_{i+1}\) onto \(K=B(_{0},)\). endfor  Return \(_{T}\) ```

**Algorithm 1** Projected SGD Algorithm Given Truncated Samples

Given the results from the previous sections, we can now prove the main result. The analysis is based on that of Chapter 5 (Theorem 5.7) of  which we modify and state below:

**Theorem 3.10** (SGD Convergence).: Let \(f\) be a \(\)-strongly convex function. Let \(^{*}_{ K}f()\). Consider the sequence \(\{_{t}\}_{t=1}^{N}\) generated by SGD (Algorithm 3) and \(\{_{t}\}_{t=1}^{N}\) the sequence random vectors satisfying \([_{t}_{t}]= f(_{t})\) and \([\|_{t}\|^{2}_{t}]<^{2}\) for all \(t\), with a constant step size \(\) satisfying \(0<<\). It follows that for \(t 0\),

\[\|_{t}-^{*}\|^{2}(1-2)^{t}\|_{0}-^{*}\|^{2}+^{2}.\]

[MISSING_PAGE_FAIL:9]

Algorithmic problems.For the algorithmic problems, by Cor. 3.8 and Lemmas 3.9, 3.7, we can address (a) by solving the empirical MLE problem with no truncation. Given that we can efficiently sample exactly (or approximately see Appendix D.2) from the non-truncated \(p_{}\) for any \(\), we can sample unbiased gradients via Algorithm 2 with expected \((1/p_{_{i}}(S))=()}{^{2}})\) samples at each step \(t\) to address (b). Point (c) can be done efficiently, since our parameter space is a simple intersection of Euclidean balls if we choose \(\) to be a Euclidean ball that sits inside the whole parameter space which contains \(^{*}\).

Let \(D(k,L,,)=+L)+(1+2)^{2}(6(d())^{2}- 2)^{2}}{_{S}^{2}^{2}}\). Putting everything together, to get \(\|_{N}-^{*}\|^{2}^ {2}\), the number of iterations and samples should be

\[N\{D(k,L,,),\}(}),\]

provided that \(=\{^{2}}{2^{2}},}\}\), applying Lemma D.1 to the bound from Theorem 3.10 with \(A=}{_{S}}\), \(C=_{S}\), \(=2_{S}\), and \(^{2}=kL_{S}+kL+(1+2)^{2}(( 1/p_{}(S)))^{2}\) by Lemma 3.11. Further, Lemma 3.4 guarantees \(( 1/p_{}(S))()}{^{2}})\) for all \( K\).

In probability, we get \((\|_{N}-^{*}\|^{2} 3 ^{2}) 1/3\) by Markov's inequality. Then we can amplify the probability of success to \(1-\) by repeating the procedure from scratch \( 1/\) times, as in . Given a polynomial time (poly\((m,k,1/)\)) algorithm \(A_{S}\) to sample from \(p_{}\) for all \(\), each iteration takes expected \((1/p_{_{i}}(S))=(:(d())^{2})}{^{2}})\) times the running time of \(A_{S}\) plus the projection step (which is also efficient). This completes the result of Theorem 3.1.

_Remark_.: In the Gaussian case, the sample complexity was given in terms of \(m\), the dimension of the \(\) and was stated in  as \(}(m^{2}/^{2})\). For multivariate Gaussian, the dimension \(k\) of \(\) is the dimension of \([,^{}]\) (vectorized) which is \(m+m^{2}\), thus we can recover the previous result.

Numerical example.While a lot of the analyses shown can seem complicated, they give some guarantees for a rather simple algorithm: simply initialize your parameters using MLE as if there is no truncation at all, then run projected stochastic gradient descent using rejection sampling. We do not even need to describe the truncation set \(S\) as long as we can query whether a point is inside \(S\) or not efficiently. As a proof of concept for the use of this algorithm, we've implemented our simple projected SGD algorithm to learn the parameters of multivariate exponential distributions, given truncated samples. To save space in the main body for exposition of the theoretical results, we've included the results and details in Appendix E.

## 4 Discussion

To our knowledge, this work is the first which develops a computationally and statistically efficient algorithm for learning from samples truncated to very general sets \(S\) of the form in  in high dimensions whose distribution does not rely on Gaussianity. This work also has interesting implications for learning general log-concave distributions through applying the Taylor theorem to the log density as in  and for sampling (e.g., as in ). Through generalizing the previous Gaussian results to general exponential families, we also extract the broader abstract properties (e.g., concentration and anti-concentration) of distributions for which the previously proposed projected stochastic gradient descent procedure still applies. It would be interesting to understand how much these results can be generalized to densities beyond exponential families, or even to extend the current work presented from expected polynomial running time to deterministic polynomial running time. We hope that our work provides the foundation for future work in this direction.

## 5 Acknowledgements

We thank Tim Kunisky for insightful discussions during the preparation of this work. Jane Lee was supported by a GFSD fellowship sponsored by the U.S. National Security Agency (NSA).