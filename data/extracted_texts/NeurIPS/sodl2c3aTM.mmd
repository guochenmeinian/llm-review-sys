# [MISSING_PAGE_EMPTY:1]

[MISSING_PAGE_EMPTY:1]

collapse . These methods show that the discriminator is very crucial to the training of GANs. Nevertheless, stably training GANs remains a challenging problem [33; 31; 93].

In this paper, we rethink the difficulty of training GANs from the discriminator side. The discriminator guides the training of the generator via learning the distributions of real/generated samples. However, since it has been observed that the characteristics of generated samples vary during the whole training process , a question arises: _how challenging is it for the discriminator to learn from such time-varying generated samples?_ Our study shows that the distribution of generated samples dynamically changes during training, posing significant challenges to the discriminator. In particular, the discriminator in existing work (_e.g._, [6; 36; 57; 50]) does not explicitly consider an online task that addresses time-varying distributions of generated samples but is presented for a typical classification task. We refer to such a discriminator as _fixed_. We find that the fixed discriminator often improperly relies on local features that are important to historically generated samples to distinguish incoming ones, although the distributions of these generated samples are different. As a result, the discriminator insufficiently learns the distribution of incoming generated samples, leading to subpar guidance to the generator (see Fig. 1).

We propose a novel method for training GANs, from the perspective of online continual learning. Online continual learning has attracted increasing attention [52; 14; 40]. Different from offline continual learning focusing on the catastrophic forgetting problem [51; 38; 60], recent online continual learning methods [17; 7; 22] pointed out that data with time-vary distribution requires learning methods to have the ability of fast learning and quick adaption. Motivated by these methods, we propose to detect whether the discriminator slows down the learning of new knowledge in generated data by treating generated samples throughout training as a stream of data. We then explicitly force the discriminator to learn new knowledge fast. To this end, we propose a simple yet effective scheme to detect the retardation of the discriminator and force it to learn fast. Instead of designing a sophisticated network architecture, we dynamically mask discriminator features when the discriminator is predicted to be retarded, such that the discriminator adaptively learns the temporally-vary distribution of generated data.

Our contributions are summarized as follows.

* From the perspective of online continual learning, we propose a novel approach that effectively improves the training of GANs by explicitly considering the time-varying distribution of generated samples.
* The proposed discriminator fast learns and adapts to the time-varying distribution of the generated samples via dynamically masking discriminator features, improving the training of GANs.

Figure 1: **Illustration of the advantage of our method**, where the first and second rows show generated images and feature maps taken from a discriminator layer, respectively. (a) StyleGAN-V2 introduces similar artifacts into generated images, despite the increased training steps. Our method is simple yet effectively improves the training of GANs, boosting the quality of generated samples for StyleGAN-V2 in (b). By fast learning incoming generated samples, the proposed discriminator captures artifacts in the local regions, better guiding the training of the generator. The averaging cosine similarity between the current and previous feature maps is 0.8353 for StyleGAN-V2 and 0.4232 for ours, which indicates that our method enforces the attentive regions of the discriminator to be more different than the baseline, better adapting to time-varying distribution of generated data.

* Extensive experimental results show that our method generates high-quality images, outperforming state-of-the-art GAN approaches. Besides, the performance of our method surpasses advanced diffusion models.

## 2 Related Works

**Generative adversarial networks.** GANs have attracted increasing attention from researchers [19; 84; 20; 5; 72]. By learning a min-max objective, GANs generate samples from a given data distribution, which can serve for various applications, _e.g_., image editing [18; 28; 75; 3; 27; 97; 83; 43] and text-conditional image synthesis [69; 31; 78; 45; 64; 98]. As a fundamental technology, GANs coupled with the diffusion model (DM) [65; 26; 58; 62; 66] and auto-regressive model (AR) [63; 91; 10; 9] indirectly turn on the light of AIGC . Compared with the other emergent generative models, GANs have the advantages of rapid inference , generating fixed objects [31; 65] and controllable latent distribution [35; 36; 34; 4; 23; 75]. Recently, as an _answer ball_ against DM and AR, GigaGAN , StyleGAN-T and GALIP  adapted GANs to large image-text datasets, demonstrating that GANs can be another viable solution for zero-shot text-to-image generation. However, as _"No Pain, No Gain"_, the payments of GANs are also high, _i.e_., GANs suffer from unstable training and mode collapse. As a directed result, GANs are difficult to be equipped with some standard modules, such as dropout  and masking operator [10; 24], which strengthen the model generalization via introducing randomness into the training process, but further decrease the training stability. Existing studies [92; 74; 13; 96] illustrated that GANs learn from the stream, where the training distribution varies in the different time steps. Without any regularization, GANs may harmfully learn a bias on historical data and neglect the current data. Our goal in this paper is to downgrade the potential payments of GANs and integrate the masking operator into GANs to overcome overfitting on historical data.

**Regularization on discriminators.** As a model helping the generator to align with real distribution, the discriminator plays a pivotal role to train GANs. Various methods have been proposed to improve GANs by redesigning discriminators [2; 21; 50; 93; 87; 30; 48; 96; 32; 57]. WGAN  employs the discriminator to measure the synthetic and natural samples with Wasserstein distance. Since WGAN requires Lipschitz continuity to ensure model convergence, weight clipping  and gradient penalty  were proposed to enhance the discriminators. Such technologies are then inherited by the family of StyleGAN [35; 36; 34]. Thanks to the advanced architecture [6; 36; 32], several regularization technologies, including ADA , APA , LC-Reg , DiffAugment , Con-Reg , AdaptiveMix , DAG , and MEE  were proposed to train GANs with low-data regime [50; 30; 33; 82; 80; 95] or combat mode collapse . In addition to exploring training data, some studies redesigned the discriminator via proposing extra tasks [11; 79; 29; 88] and implementing large-scale pre-trained models [68; 41]. In this paper, the proposed method does not require additional training data, which can work as a plug-and-play module for existing discriminators. Compared with the previous regularization focusing on data augmentation, the proposed method investigates the capacity of the discriminator from a new perspective, _i.e_., 'augmenting' the architecture to quickly adapt the current (new) knowledge. Note that the most related study to this paper is DynamicD , which dynamically adapts the capacity of the discriminator to the training data. However, DynamicD suffers from divergent solutions on different data regimes. In contrast, our method can help to re-adjust the attentions of discriminators and obtain consistent improvement against varying regimes.

## 3 Pilot Study

We first conduct a study to investigate the distribution shifts of generated samples over time during training. We then demonstrate the challenges posed by such a time-varying distribution to the fixed discriminator. We adopt a representative GAN, _i.e_., StyleGAN-V2 , for the study, due to its advanced network architectures, training strategies, and impressive results.

**Analysis on generated distribution over time.** We train a StyleGAN-V2 on a widely-used dataset FFHQ , to study the distribution changes of its generated samples. In particular, we collect 5k generated samples at each time interval during training and then analyze the distribution of generated samples per time interval. The distribution is estimated with Frechet Inception Distance (FID) . More specifically, FID measures the distribution similarity between real and fake samples by calculating the mean and covariance of real/fake samples. Similarly, we first extract the feature of a generated sample by an Inception model , and then represent the distribution of generated samples per time interval by the mean and variance of these samples' features.

We observe that the generated distributions undergo dynamical and complex changes over time (see Fig. 2), as the generator evolves during training. For example, the generated samples are not even independently and identically distributed (i.i.d) across the training progress in Fig. 2. Such time-varying distribution inevitably poses significant challenges to the discriminator, since this has not been explicitly considered in the discriminator typically.

**Adaption ability of fixed discriminator.** Learning the distributions of generated samples is vital to training the generator. We investigate whether the fixed discriminator, which does not explicitly consider distribution changes, can effectively learn the time-varying distributions of generated samples. We argue that the discriminator needs to adaptively adjust its model weights and rely on different local features for discriminating generated samples at different steps. Suppose the generator synthesizes unrealistic hair for human faces at a time interval \([t_{1},t_{2}]\), and synthesizes plausible hair but introduces artifacts in cheek regions at \([t_{3},t_{4}]\) (see  and  kimgs in Fig. 2). It is expected that the discriminator pays less attention to hair regions and more attention to cheek regions in \([t_{3},t_{4}]\), compared to \([t_{1},t_{2}]\), so as to fast distinguish fake samples. Accordingly, the parameters of the discriminator model are expected to be updated, such that the discriminator adapts to the distribution changes of generated samples for \([t_{1},t_{2}]\) to \([t_{3},t_{4}]\).

Here we investigate the discriminator of StyleGAN-V2 since it is a representative fixed discriminator. We find the parameter differences of the discriminator are usually small between two adjacent steps, (see Fig. 3 (a)), indicating the discriminator slows down learning. Moreover, we find the discriminator model trained at different times pays attention to almost fixed local regions given an image, as indicated by the feature map extracted by the layers of the discriminator (see Fig. 3 (b)). As a result, the discriminator relies on old knowledge learned from historical data, which is insufficient to learn incoming generated samples under a dynamic distribution shift.

Figure 3: We trace the training of StyleGAN-V2’s discriminator. The curve in (a) shows the model parameter difference of the discriminator between \(t_{i}\) and \(t_{i-1}\) in the training progress. In (b), the attentive regions of the discriminator are almost fixed at training steps when the discriminator slows down its model parameter updating, where each feature map is represented by the feature space of the discriminator trained at a time step.

Figure 2: **Illustration of time-varying distributions of generated samples**, where we trace the training process of StyleGAN-V2  on FFHQ . The mean and variance of generated 5k samples’ features are computed per time interval, showing the generated distributions are dynamic and time-varying during training, as the generator evolves. kimg refers to the number of images (measured in thousand) trained so far.

## 4 Methodology

### Problem Formulation

The discriminator learns the distribution of real and generated samples, which is vital to training the generator. Nevertheless, as studied in Sec. 3, the distribution of generated samples varies and drifts over time during training, posing challenges to existing discriminators (_e_.\(g\)., [36; 50]). By treating the generated samples of the generator across training as a stream, we innovatively formulate learning the distribution of generated samples as an online continual learning problem. Motivated by recent advances in online learning [17; 7; 47], our target is to enable a discriminator to quickly adapt to incoming generated data.

Since the generator is trained via a min-max game with the discriminator, the distribution of generated samples is significantly complex and unpredictable. Hence, it is non-trivial to accurately predict distribution changes. In other words, it is difficult for the discriminator to predict when it needs to be rapidly adjusted for the new distribution.

**Overview.** We address the problem by considering two questions: (1) when does the discriminator slow down the learning from incoming generated samples? (2) how to force the discriminator to fast learn new knowledge? By exploring the two aspects, we propose a method named Dynamically Masked Discriminator (DMD) for GANs, as shown in Fig. 4.

### Dynamically Masked Discriminator

Different from existing GANs methods [36; 50; 33; 48], we propose to automatically adjust the discriminator during training towards the time-varying distribution of generated samples. Instead of designing complex network architectures, we propose two key modules which can be easily integrated into existing discriminators. The two modules are (1) discriminator retardation detection and (2) dynamic discriminator adjustment. The first module automatically determines when the discriminator slows down learning. Here, _slow down_ is referred to as the discriminator largely relies on old knowledge learned from historical data, given incoming generated samples with different distributions. The second module adjusts the discriminator for fast learning via dynamically assigning or removing masks at a certain interval.

With the two proposed modules, we improve an existing discriminator into a dynamic one at the time axis. That is, the discriminator in our method has two states, \(i\)._e_., mask and non-mask training. \(\) denotes the original discriminator without masks, and \(\) denotes the adjusted discriminator with masks. During training, we dynamically switch \(\) and \(\) for guiding the training of the generator

Figure 4: **The pipeline of the proposed method. Our method, named Dynamically Masked Discriminator (DMD), automatically adjusts the discriminator via dynamically marking the discriminator. When DMD detects that the discriminator slows down learning, DMD dynamically assigns masks or removes masks to features of the discriminator per time interval, forcing the discriminator to learn new knowledge and preventing it from relying on old knowledge from historical samples.**according to discriminator retardation detection. Let \((|t)\) describe the probability to use \(\) at time \(t\). The probability of \(\) is thus formed as \(1-(|t)\). Let \(\{^{t}\}\) denote a stream consisting of samples generated by the generator \(\), where \(^{t}=(z,^{t})\) is a generated sample from a vector \(z\) at time \(t\) during training, and \(^{t}\) denotes parameters of the generator at \(t\). We formulate our training of GANs as follows:

\[_{^{t}}:=-_{z p_{z},t}[(|t) log(((z,^{t}),^{t}))+(1-(|t)) log(_{M}((z,^{t}),^{t})]\] (1)

\[_{^{t}}:=-_{I p_{z},t}[(1-( |t))\,log(_{M}(I,^{t}))+(|t)log( (I,^{t}))]\] (2) \[-_{z p_{z},t}[(1-(|t)log(1- _{M}((z,^{t}),^{t}))+(|t)log(1- ((z,^{t}),^{t}))]\]

where \(I\) is a real sample and \(^{t}\) is the parameter of the discriminator at time \(t\).

**Dynamic discriminator adjustment.** When the discriminator is detected to be retarded (_i.e._, slow down learning), we adjust the discriminator to force it to learn fast. In this paper, we mainly focus on the issue that the discriminator largely relies on old knowledge learned from historical data and cannot rapidly adapt to incoming generated samples. To address this issue, one possible solution is to design complex network architectures. Instead, we propose to dynamically switch the discriminator from mask/non-mask states to non-mask/mask at a time interval. We argue that such dynamic masking at time intervals can break the original dependency of the discriminator on some local features that are important to distinguish historical samples, inspired by . For example, by masking a feature map that is fed to a layer of the discriminator, we can control the layer of the discriminator and enforce it to pay attention to other regions of a generated image.

In this paper, we force the non-mask discriminator (_i.e._, original one) \(\) with parameter \(^{t_{i}}\) to be converted into the mask state \(_{M}\) by masking its feature map or input. In particular, given the \(d\)-th layer of a discriminator, we propose to mask its input \(^{(d-1),t}\) in a time interval \((t_{j},t_{j+}]\). Let \(_{d-1}^{t}\) denote a mask in the \(t\)-th training step with the same size as \(^{(d-1),t}\). We can dynamically mask the discriminator by masking the input features of its \(d\)-th layer:

\[}^{(d),t}=L(^{(d-1),t},_{d-1}^{t})=L( ^{(d-1),t}_{d-1}^{t}), t(t_{j},t_{j+}]\] (3)

where \(}^{(d),t}\) is the output of \(d\)-th layer of a discriminator by masking, \(\) denotes Hadamard product, \(L\) is the convolutional operator. Different from the traditional dropout, the mask does not continuously change. Instead, this mask is fixed for a period of training steps, _i.e._, \((t_{i},t_{i+}]\). Switching the discriminator from mask to non-mask is simply removing all masks in the discriminator. Such dynamical switching encourages the discriminator to pay attention to various local regions/features over time, making our discriminator better adapt to the time-varying generated distribution and leading to better guidance of training the generator, compared with StyleGAN-V2 (see Fig. 1).

**Discriminator retardation detection.** This module is to detect whether the discriminator slows down the learning, _i.e._,, the discriminator largely relies on old knowledge from historical data to distinguish future generated samples with new distributions. Given the current time step \(t_{i}\), an ideal solution is to use future-generated samples with different distributions at time \((t_{j},t_{j+}]\) to evaluate the discriminator. However, these future-generated samples are unavailable at the current time step. Moreover, it is non-trivial to predict the distribution of future-generated samples.

Instead, we propose to construct a pseudo sample that possibly belongs to new distribution to detect the Retardation of the discriminator. Without loss of generality, we assume the distribution changes of generated samples correspond to the changes in local regions/features of these samples. For example, some hair regions are unrealistic in a generated sample at time \(t_{i}\), and become realistic at \(t_{j}\), as the generator evolves in Fig. 2. By randomly masking a generated sample or its intermediate features in the discriminator, it is possible to remove discriminative local regions/features that are important for the sample's distribution, shifting the sample to a new distribution. For example, if the right face region of the man is removed/masked in Fig. 5, the remaining regions become more realistic (_i.e._, belongs to a new distribution).

Therefore, given a generated sample \(^{t_{i}}\) for a distribution, we construct a pseudo sample that possibly belongs to another distribution by randomly masking local image regions or intermediate features of the discriminator. For generated samples at time \(t\), if the discriminator determines they are similar to their pseudo samples, it is probable that the discriminator does not discriminate the distribution difference and is detected as retardation. Formally, given \(m\) samples at time \(t\), we can define our heuristic Retardation metric, \(_{t}\), as

\[_{t}=_{i U_{t}}}_{i}^{(d),t} _{i}^{(d),t}}{|}_{i}^{(d),t}||_{i}^{(d ),t}|}\] (4)

where \(U_{t}\) is the index of samples, \(_{i}^{(d),t}\) is the output of the \(d\)-th layer of the discriminator taking original sample as input, \(_{i}^{(d),t}\) is that of a pseudo sample where its image region or feature maps in the discriminator is masked. If \(_{t}\) is larger than a predefined threshold, the discriminator doesn't detect differences between original and pseudo samples and is detected as retardation. The pseudo-code is given in the _Appendix_.

## 5 Experiments

### Experimental Setup

**Dataset.** We evaluate the performance of our method on six widely used datasets, including AFHQ-Cat , AFHQ-Dog , AFHQ-Wild , FFHQ , and LSUN-Church  with 256 \(\) 256 resolutions and CIFAR-10  with 32 \(\) 32 resolutions. We elaborate on these datasets and implementation details in the _Appendix_.

**Evaluation Metrics.** Following prior works [50; 33; 30], we use two evaluation metrics, including Frechet Inception Distance (FID)  and Inception Score (IS) , to evaluate the quality of generated results. The number of testing samples is set to 50k in our experiments.

**Baselines.** Following the previous studies [33; 30; 50], we integrate our method with StyleGAN-V2 , StyleGAN-V3 , and BigGAN . We compare our method with state-of-the-art methods that improve discriminators via data augmentation, including ADA  and APA . We also compare with GANs using regularization: LC-Reg , zCR , InsGen , Adaptive Dropout , AdaptiveMix , MEE  and DynamicD . Besides StyleGAN, we compare with other generative models: DDPM , ImageBART , PGGAN  and LDM .

### Comparison with State-of-the-art Methods

**Main results.** To show the superiority of the proposed method, we compare the performance of our approach with state-of-the-art methods on FFHQ. As shown in Table 1, our method achieves the best performance in terms of FID score on FFHQ. Recent methods [87; 50; 88] improve GANs by data augmentation,, ADA  and APA . By further combining with APA , FID score of our method reduces from 3.299 to 3.075, significantly surpassing the other approaches. In addition to the quantitative analysis, Fig. 6 and Fig. 7 show qualitative results of our method. StyleGAN-V2 introduces noticeable artifacts, while our method generates images with much better quality. This is because our discriminator effectively learns the time-varying distributions of generated samples,

Figure 5: **Illustration of the generated images, feature maps, and the corresponding masks. The feature maps are extracted from the discriminator of StyleGAN-V2  trained on FFHQ , and the red region denotes the artifacts. By masking feature maps of the discrimination, it is possible to remove discriminative local regions/features (, unrealistic regions) that are important for the sample’s distribution, shirting the sample to a new distribution.**

[MISSING_PAGE_FAIL:8]

Performance on the large-scale training dataset.We evaluate the performance of our method trained on a large-scale dataset LSUN-Church  shown in Table 3. LSUN-Church contains 120k images and can be augmented to 240k with flipping. Diffusion models and auto-regressive models achieve impressive performance by training on large-scale datasets. We compare our method with representative diffusion models: LDM , DDPM , and ImageBART . LDM outperforms StyleGAN-V2 slightly (4.02 vs. 4.29 FID). However, our method significantly reduces the FID of StyleGAN-V2 from 4.29 to 3.06 FID, achieving the best performance, compared with the other generative models.

### Ablation Study and Analysis

Ablation studies.Since our method is plug-and-play, which is easy to be integrated into existing methods. We adopt StyleGAN-V2 as the baseline and evaluate the improvement of integration with our method. As shown in Table 6, our method improves StyleGAN-V2 on AFHQ-V2 and LSUN datasets. For example, our method enables better performance of StyleGAN-V2, where FID is improved by 25.8% on AFHQ-Cat. One of our contributions is to automatically switch the discriminator between mask and non-mask training, according to discriminator retardation detection. We evaluate the effectiveness of this automatic scheme. We test the performance of the baseline with different fixed intervals for the transition between the mask and non-mask training. As shown in Table 7, fixed interval improves the performance of StyleGAN-V2, indicating that dynamically adding/removing masks in the discriminator helps the training of GANs. Nevertheless, the proposed method can achieve the best performance, since discriminator retardation detection automatically detects when the discriminator slows down.

    &  &  &  &  \\   & FID \(\) & IS \(\) & FID \(\) & IS \(\) & FID \(\) & IS \(\) & FID \(\) & IS \(\) \\  Baseline & 7.924 & 1.890 & 26.310 & 9.000 & 3.957 & 5.567 & 4.292 & 2.589 \\ Ours & **5.879(-25.8\%)** & **1.988(+5.2\%)** & **21.240(-19.3\%)** & **9.698(+7.8\%)** & **3.471(-12.3\%)** & **5.647(+1.4\%)** & **3.061(-28.7\%)** & **2.792 (+7.8\%)** \\   

Table 6: The ablation study of our method on AFHQ-V2  and LSUN-Church , where the baseline is the StyleGAN-V2  and Ours is StyleGAN-V2+DMD.

Figure 8: **Probe of hyper-parameters of the proposed method on FFHQ-70k. We discuss the depth, ratio, and probabilities for masking. Probabilities of Dyna. Mask control the times in the masking stage. In each iteration of mask training, masking the discriminator in the 5-th layer with 0.3 ratios can achieve the best result.**

Figure 7: The generated samples of the proposed method on (a) AFHQ-Cat, (b) AFHQ-Dog, (c) AFHQ-Wild, (d) FFHQ, and (e) LSUN-Church. All training data are in a resolution of 256 \(\) 256.

**Hyper-parameters and masking strategies.** We then search the hyper-parameters for the proposed method. As shown in Fig. 8, we separately investigate the efficacy of the depth for masking, the mask ratio, and the probabilities to trigger the mask. Accordingly, the best performance appears with the 5-th layer, 0.3 masking ratios, and masking discriminator every time (_i.e._, probability=1) in the mask training stage. Meanwhile, we investigate different masking strategies, including Vanilla Dropout, Input Masking, Dynamic Head, and Vanilla Dropout. We detail the corresponding implementations in the _Appendix_. As shown in Table 8, the proposed method can achieve the best performance among all the cases. Note that the empirical study shows that directly applying dropout will incur unstable training and hurt the capacity of the discriminator, leading to worse FID. This shows the advantage of our method, which automatically switches the discriminator at a time interval.

## 6 Conclusion

In this paper, we propose a novel method named DMD for training GANs from a new perspective, _i.e._, online continuous learning. Our study shows that the distribution of generated samples is time-varying, while this problem has been underexplored. This makes the discriminator often largely rely on historically generated data, instead of learning new knowledge from the incoming generated samples, degrading generation performance. We propose to force the discriminator to fast learn and adapt to incoming generated samples. We propose a simple yet effective method that automatically detects whether the discriminator slows down learning, and adjusts the discriminator by dynamically imposing or removing masks of the discriminator per time interval. Experimental results show our method improves the learning of the discriminator on temporally-vary distribution, boosting the guidance of training the generator, achieving the best performance than state-of-the-art methods.

**Limitations:** Theoretical studies can make this work more comprehensive; however, we have not explored it in the paper, since it is beyond the scope of this study. Moreover, while the proposed method can effectively improve the training of the CNN-based GANs models, combining our method with Transformer-based ones is left to be investigated in the future.

**Broader Impact:** Our method can be used for various applications such as producing training data and creating photorealistic images. On the other hand, like other generative models, our method can be misused for the application of Deepfake , where fake content is synthesized to deceive and mislead people, leading to a negative social impact. Nevertheless, many researchers have considered this problem while exploring fake content detection and media forensics techniques. In addition, we believe there would be regulations on fake content generation, such as forcing synthesized content to be injected with identifications that indicate it to be fake.