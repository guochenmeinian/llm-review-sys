# Gradient-based Discrete Sampling with

Automatic Cyclical Scheduling

 Patrick Pynadath

Department of Computer Science

Purdue University

West Lafayette, IN, 47907

ppynadat@purdue.edu.edu

&Riddhiman Bhattacharya

Department of Management

Purdue University

West Lafayette, IN, 47907

bhatta76@purdue.edu

&Arun Hariharan

Department of Computer Science

Purdue University

West Lafayette, IN, 47907

harihar4@purdue.edu

&Ruqi Zhang

Department of Computer Science

Purdue University

West Lafayette, IN, 47907

ruqiz@purdue.edu

###### Abstract

Discrete distributions, particularly in high-dimensional deep models, are often highly multimodal due to inherent discontinuities. While gradient-based discrete sampling has proven effective, it is susceptible to becoming trapped in local modes due to the gradient information. To tackle this challenge, we propose an automatic cyclical scheduling, designed for efficient and accurate sampling in multimodal discrete distributions. Our method contains three key components: (1) a cyclical step size schedule where large steps discover new modes and small steps exploit each mode; (2) a cyclical balancing schedule, ensuring "balanced" proposals for given step sizes and high efficiency of the Markov chain; and (3) an automatic tuning scheme for adjusting the hyperparameters in the cyclical schedules, allowing adaptability across diverse datasets with minimal tuning. We prove the non-asymptotic convergence and inference guarantee for our method in general discrete distributions. Extensive experiments demonstrate the superiority of our method in sampling complex multimodal discrete distributions.

## 1 Introduction

Discrete variables are common in many machine learning problems, highlighting the crucial need for efficient discrete samplers. Recent advances (Grathwohl et al., 2021; Zhang et al., 2022; Sun et al., 2021, 2023; 2023; Xiang et al., 2023) have leveraged gradient information in discrete distributions to improve proposal distributions, significantly boosting their efficiency. These advancements have set new benchmarks in discrete sampling tasks across graphical models, energy-based models, and combinatorial optimization (Goshvadi et al., 2023).

However, one major limitation of gradient-based methods is their susceptibility to becoming trapped in local modes (Ruder, 2016; Ziyin et al., 2021), which significantly reduces the accuracy and efficiency of sampling results. In continuous spaces, several strategies such as cyclical step sizes (Zhang et al., 2020), parallel tempering (Swendsen and Wang, 1986; Deng et al., 2020), and flat histograms (Berg and Neuhaus, 1991; Deng et al., 2020), have been proposed to address this issue. When it comes to discrete distributions, which are inherently more multimodal due to their discontinuous nature, the problem becomes even more severe. Despite the pressing need, there is a lack of methodology for gradient-based discrete samplers to effectively explore multimodal distributions. Current methodsoften fall far short in traversing the complex landscapes of multimodal distributions, as illustrated in Figure 1.

In this paper, we propose _automatic cyclical scheduling_ for gradient-based discrete sampling to efficiently and accurately sample from multimodal distributions. To balance between uncovering new modes and characterizing the current mode, we parameterize a family of gradient-based proposals that span a spectrum from local to global proposals. The parameterized proposal dynamically adjusts according to cyclical schedules of both step size and the balancing parameter, smoothly transitioning from global exploratory moves to more localized moves within each cycle. These cyclical schedules are automatically tuned by a specially designed algorithm, which identifies optimal step sizes and balancing parameters for discrete distributions. Our contributions are summarized as follows:

* We present the first gradient-based discrete sampling method that targets multimodal distributions. Our method incorporates cyclical schedules for both step size and balancing parameter to facilitate the exploration and exploitation in discrete distributions.
* We propose an automatic tuning algorithm to configure the cyclical schedule, enabling effortless and customized adjustments across various datasets without much manual intervention.
* We offer non-asymptotic convergence and inference guarantees for our method in general discrete distributions. To our knowledge, this is the first non-asymptotic convergence bound of gradient-based discrete sampling to the target distribution with inference guarantees, which could be of independent interest.
* We demonstrate the superiority of our method for both sampling and learning tasks including restricted Boltzmann machines, deep energy-based models, and large language models.

## 2 Related Work

Gradient-based Discrete Sampling Zanella (2017) introduced a family of locally informed proposals, laying the foundation for recent developments in efficient discrete sampling. Building upon this, Grathwohl et al. (2021) further incorporates gradient approximation, significantly reducing computational costs. Following these pioneering efforts, numerous studies have proposed various gradient-based discrete sampling techniques (Rhodes and Gutmann, 2022; Sun et al., 2021, 2022, 2023b; Xiang et al., 2023). Zhang et al. (2022b) develops a discrete Langevin proposal, translating the powerful Langevin algorithm to discrete spaces. Sansone (2022) introduces a self-balancing method to optimize the balancing functions in locally balanced proposals. While our work also utilizes an adaptive phase, it differs in that our parameterization extends beyond the local regime, and our proposal parameterization is considerably simpler.

Perhaps the most closely related study is the any-scale balanced sampler (Sun et al., 2023a). This method uses a non-local balancing proposal and adaptively tunes it. Our work, however, differs in several key aspects: (1) We focus on combining both local and non-local proposals to effectively characterize multimodal discrete distributions, as opposed to focusing on a single optimal proposal. (2) Our automatic tuning algorithm adjusts the step size and balancing parameter by considering

Figure 1: Sampling on a 2d distribution with multiple modes. (a): ground truth. (b): results from a random walk sampler. (c): results from DMALA (Zhang et al., 2022b) with a manually tuned step size. (d): results from AB (Sun et al., 2023a). (e): results from our method ACS. While the random walk sampler can find all modes, its characterization is noisy and lacks details for each mode. Gradient-based samplers (b) and (c) effectively characterize a specific mode but are easily trapped in some local modes. Our method (d) can find all modes efficiently and characterize each mode accurately.

the special discrete structures and targets a specific Metropolis-Hastings acceptance rate, rather than maximizing the average coordinates changed per step. (3) Our method can be applied to learning energy-based models (EBM) and sampling large language models, whereas their approach cannot.

Sampling on Multimodal DistributionsThere exist several sampling methods targeting discrete multimodal distributions, such as simulated tempering (Marinari and Parisi, 1992), the Swendsen-Wang algorithm (Swendsen and Wang, 1987), and the Wolff algorithm (Wolff, 1989). However, these methods usually use random walk or Gibbs sampling as their proposals. It is unclear how these methods can be adapted for gradient-based discrete sampling.

In continuous spaces, various gradient-based methods have been developed specifically for multimodal distributions (Zhang et al., 2020; Deng et al., 2020, 2020, 2020). Our method distinguishes from the cyclical step size in Zhang et al. (2020) by incorporating an additional cyclical balancing parameter schedule and an automatic tuning scheme, which are crucial for efficient exploration in discrete distributions. Furthermore, our theoretical analysis of convergence is different from that in Zhang et al. (2020) which relies on continuous stochastic processes.

## 3 Preliminaries

### Problem Definition

We consider the task of sampling from some target distribution defined over a discrete space

\[()=(U()),\ \ .\]

Here, \(\) is a \(d\) dimensional discrete variable in domain \(\), \(U\) is the energy function, and \(Z\) is the normalizing constant. We make the following assumptions of the domain and the energy function, following the literature of gradient-based discrete sampling (Grathwohl et al., 2021; Sun et al., 2021; Zhang et al., 2022): (1) The domain is coordinatewisely factorized, \(=_{i=1}^{d}_{i}\). (2) The energy function \(U\) can be extended to a differentiable function in \(^{d}\).

### Locally Balanced Proposals

Zanella (2017) introduces a family of informed proposals, which is defined below:

\[Q_{g,}(^{}|)=)}{ ()})K_{}(^{}-)}{Z_{g,}()}\] (1)

Here, \(K_{}\) is a kernel that determines the scale of the proposal where \(\) plays a similar role as the step size. \(g(t)\) is a balancing function that determines how to incorporate the information about \(\). If \(g(t)=tg()\), the proposal becomes a locally balanced proposal, which is asymptotically optimal in the local regime, that is, when the step size \( 0\).

## 4 Automatic Cyclical Sampler

We aim to develop a sampler capable of escaping local modes in general multimodal discrete distributions, including those that appear in deep energy-based models and large language models. First, we motivate using the cyclical schedule by demonstrating the issue of gradient-based samplers getting stuck in local modes on a toy dataset. We then present our sampler's parameterization of the step size and balancing function. Next, we introduce a cyclical schedule for the proposal distribution that enables effective exploration and characterization of discrete multimodal distributions. Finally, we develop an automatic tuning method that simplifies the process of identifying hyperparameters in cyclical schedules.

### Motivating Example: A Synthetic Multimodal Discrete Distribution

To demonstrate the crucial issue of local modes trapping gradient-based samplers, we construct a 2-dimensional dataset consisting of integers. We define \(=\{0,1, N\}^{2}\), where \(N\) is the maximum value for each coordinate. Given a set of modes \(\{_{1},_{2},_{l}\}\), we define the energy as follows:

\[U()=(_{i=1}^{l}(||^{2}}{2 })).\] (2)

This distribution enables easy comparison between different methods in terms of their ability to both explore and exploit the target distribution. We demonstrate the results of various samplers in Figure 1. More experimental details can be found in Appendix D.1.

A visual comparison reveals that while gradient-based samplers (DMALA (Zhang et al., 2022) and AB (Sun et al., 2023)) are very effective at characterizing a given mode, they tend to get trapped in some small neighborhood, preventing a proper characterization of the distribution as a whole.

We can understand this behavior of gradient-based samplers by comparing them to a random walk sampler (RW), which is able to explore all the modes but unable to fully characterize the detail of each one. While the RW sampler proposes movements uniformly over the sample space, gradient-based samplers propose movement based on the geometry of the distribution as captured by the gradient. Because the proposed movements are in the direction of increasing density, these proposals are able to characterize a given mode in detail. At the same time, these proposals hinder escape to more distant modes as the gradient points away from their direction. For this reason, we observe that local modes are able to "trap" gradient-based samplers.

### Parameterized Proposal Distribution

To derive an automatic schedule for the proposal, we need to parameterize the proposal first. We define \(K_{}\) and \(g(t)\) in the informed proposal (Zanella, 2017) as follows:

\[K_{}(^{}-)=- ||^{2}}{2}}{Z},\ \ (0,); g(t)=t^{},\ \ [0.5,1)\] (3)

where \(\) is called a balancing parameter. \( 0,=0.5\) correspond to a locally-balanced proposal and \(,=1\) correspond to a globally-balanced proposal. Values in between result in interpolations between locally-balanced and globally-balanced proposals. Note that \((0,1)\) in Sun et al. (2023) while our range is narrower.

We substitute these definitions into Equation (1) and apply the first-order Taylor expansion:

\[Q_{,}(^{}|)((U(^{ })-U())--||^{2}}{2}) ((_{}U()(^{}-))- -||^{2}}{2}).\] (4)

As in Zhang et al. (2022), we use the assumption of coordinate-wise factorization to obtain the following coordinate-wise proposal function:

\[Q^{i}_{,}(^{}_{i}|)=(( U()_{i}(^{}_{i}-_{i})-_{i}-_{i})^{2}}{2})).\] (5)

In order to make the resulting Markov chain reversible, we apply the Metropolis-Hastings correction, where we accept the proposed step with the following probability:

\[A(^{}|,,)=(1,(U(^{})-U ()))(|^{})}{Q_{,}( ^{}|)}).\] (6)

In summary, we parameterize our proposal as in Equation (5) which includes a spectrum of local and global proposals. Our proposal is determined by two hyperparameters, the step size \(\) and the balancing parameter \(\).

### Cyclical Hyperparameter Schedules

Cyclical Step Size ScheduleIn order to effectively explore the whole target distribution while retaining the ability to exploit local modes, we adopt the cyclical step size schedule from Zhang et al. (2020). The definition of step size \(\) for iteration \(k\) is as follows:

\[_{k}=(_{}((k, s)}{s})+1,_{}),\] (7)where \(_{}\) is the initial step size, \(_{}\) is the minimum step size, and \(s\) is the number of sampling steps per cycle. Differing from the cyclical schedule in Zhang et al. (2020), we additionally add \(_{}\) to make sure that even the smallest step size remains effective in discrete spaces.

Cyclical Balancing ScheduleUsing large step sizes in (7) can easily result in very low acceptance rates, removing any benefit of exploration. To address this issue, we introduce a balancing parameter schedule, which enables reasonable acceptance rates for large step sizes. As discussed in Zanella (2017); Sun et al. (2023), the balancing parameter should vary with different step sizes to achieve a "balanced" proposal. A balanced proposal ensures that the Markov chain is reversible with respect to a certain distribution, which will converge weakly to the target distribution. For example, when the step size \( 0\), the optimal balancing parameter is \(=0.5\), whereas for \(\), the ideal balancing parameter becomes \(=1\).

Thus for a schedule of step sizes, each \(_{i}\) requires a different \(_{i}[.5,1)\), with larger step sizes having \(_{i}\) closer to 1 and smaller step sizes having \(_{i}\) closer to 0.5. Using the Metropolis-Hastings acceptance rate to characterize the quality of a given \(,\) pair, we define the value of \(_{i}\) as follows:

\[_{i}=_{[.5,_{i-1}]}(_{ ,^{} Q_{,}}[\{A(^{}|, _{i},)\}])\] (8)

Intuitively, this definition means that the best \(_{i}\) for a given step size \(_{i}\) maximizes the average acceptance rate for the proposal function \(Q_{,}\). It also conveys that larger step sizes will have larger balancing parameters.

We include a visualization of the resulting schedules in Figure 1(a) and outline our algorithm using the \(\), \(\) schedules in Algorithm 1. Note that it incurs no extra overhead compared to previous gradient-based discrete sampling methods as it only adjusts hyperparameters \(\) and \(\). By using a combination of large and small \(\) and \(\), we enable the sampler to explore the distribution fully without sacrificing the ability to characterize each mode. This is demonstrated in Figure 0(e).

Figure 2: (a) \(\)-schedule along with the corresponding \(\) schedule. The initial large steps enable the sampler to explore different regions of the distribution, while the smaller steps enable good characterization of each region. The balancing parameter \(\) varies with the step size to enable high acceptance rates for all step sizes. (b) Acceptance rate v.s. step size on EBM sampling on MNIST shows a non-monotonic relationship.

### Automatic Schedule Tuning

For schedules in Equations (7) and (8), we have parameters \(_{}\), \(_{}\), and \(\{_{1},_{2}_{s}\}\) to be decided. In this section, we will introduce an automatic tuning algorithm to easily find suitable values.

Main IdeaOur automatic tuning algorithm depends on the initial balancing parameter \(_{}\), the final balancing parameter \(_{}\), a target acceptance rate \(^{*}\), and the number of steps per cycle \(s\). These values are relatively easy to select, as detailed in Appendix A. Below, we assume they are already determined. The tuning algorithm first estimates the optimal choices for \(_{}\) and \(_{}\) based on \(^{*}\), which can then be used to construct the full step-size schedule using (7). We then construct the balancing parameter schedule using (8). The method is summarized in Algorithm 2 with details regarding subroutines in Appendix A. Our automatic tuning introduces minimal overhead relative to the more expensive sampling process. For example, in Section 6, we use 500 steps as the budget for Algorithm 2 where the total number of sampling steps is at least 5000. We further demonstrate that our algorithm is relatively robust to hyperparameters in Appendix A.1.

In short, our tuning algorithm adopts an alternative optimization strategy, leveraging existing knowledge about hyperparameter values (e.g. \(_{}\) and \(_{}\) should be around \(0.5\) and \(1\) respectively). While estimating the best pair \(,\) is challenging due to their interdependence, it is much easier to fix one and optimize the other (Sun et al., 2023).

Estimating \(_{},_{}\)For a given \(_{},_{}\), our goal is to find step sizes \(_{},_{}\) that enable an acceptance rate close to \(^{*}\). We can formally state this goal as follows:

\[J(,)=_{}[_{^{}  Q_{,}(|)}\,|^{*}-A(^{}|, ,)|].\] (9)

Given \(_{},_{}\), we construct the following objectives to pick the corresponding \(_{},_{}\):

\[_{} =\{J(,_{}) 0\}\] \[_{} =\{J(,_{}) 0\}.\] (10)

By defining the initial and final step sizes in this manner, we ensure that our cyclical schedule includes a wide range of hyperparameter pairs with different trade-offs in exploration and exploitation.

To solve (10), we estimate \(_{}\) by starting with a large step size and gradually decreasing it to find the step size that yields \(^{*}\). Unlike existing works that start with small step sizes, we observed that multiple \(\) values can yield the same acceptance rate for a given \(\), as shown in Figure 2b. Therefore, we start with an upper limit \(_{}\) and reduce the step size to avoid missing any larger \(\) values that meet our criteria. Detailed implementation is provided in Algorithm 4 in the Appendix. \(_{}\) can be obtained similarly.

Estimating Balancing ScheduleAfter setting the start and end pairs for the \(\) and \(\) schedules, we now define intermediate \(\) values. As the entire step size schedule is fixed by (7), the problem is to determine the best balancing parameter for each step size. A simple strategy is to test different \(\) spaced out evenly throughout the interval \([.5,_{i-1}]\) and select the best value in terms of acceptance rate. This approach leverages the observation that smaller step sizes tend to have smaller optimal balancing parameters. Detailed implementation is given in Algorithm 5 in Appendix.

Theoretical Analysis

In this section, we present a convergence rate analysis for Algorithm 1. For general step size and balancing parameter schedules, i.e., at each cycle, the algorithm will go through \(s\) steps in which it will use step sizes \(_{1},_{2},,_{s}\) and balancing parameters \(_{1},_{2},,_{s}\). Note that for each pair \((_{i},_{i})\), we have a Markov transition operator which we label \(P_{i}\) for \(i=1,2,,s\). The Markov operator for a single cycle is given by \(=P_{1}P_{2} P_{s}\). We have the following two assumptions:

**Assumption 5.1**.: The function \(U() C^{2}(^{d})\) has \(M\)-Lipschitz gradient. That is

\[\| U()- U(^{})\| M \|-^{}\|.\]

Note that it implicitly assumes that the set in domain \(\) is finite. We define \(conv()\) as the convex hull of the set \(\).

**Assumption 5.2**.: For each \(^{d}\), there exists an open ball containing \(\) of some radius \(r_{}\), denoted by \(B(,r_{})\), such that the function \(U()\) is \(m_{}\)-strongly concave in \(B(,r_{})\) for some \(m_{}>0\).

Assumptions 5.1 and 5.2 are standard in optimization and sampling literature (Bottou et al., 2018; Dalalyan, 2017). Under Assumption 5.2, \(U()\) is \(m\)-strongly concave on \(conv()\), following Lemma C.3 in Appendix.

We define \(diam()=_{,^{}}\|-^{}\|\) and \(_{_{i},_{i}}\) to be

\[\{-(}+_{i}M-m}{2})\,diam()^{2}-\| U(a)\|diam() \}.\]

The Markov kernel corresponding to each \(P_{i}\) in each step of the cycle in Algorithm 1 is

\[p_{i}(^{}|)=A(^{}|,_{i },_{i})Q_{_{i},_{i}}(^{}|)+(1-L())\, _{}(^{})\] (11)

where

\[L()=_{^{}}()Q_{_{i},_{i}}(|^{})}{()Q_{ _{i},_{i}}(^{}|)} 1)Q_{_{i},_{i}}( ^{}|)\]

is the total rejection probability from \(\). Finally, recall that the total variation distance between two probability measures \(\) and \(\), defined on some space \(^{d}\) is

\[\|-\|_{TV}=_{A()}|(A)-(A)|\]

where \(()\) is the set of all measurable sets in \(\).

Constant Step Size and Balancing ParameterTo analyze Algorithm 1 with step size and balancing parameter schedules, we first solve a simpler problem where the step size and balancing parameter are fixed and then extend the analysis to the setting of Algorithm 1.

Our main method of proof is to establish uniform ergodicity of the Markov chain \(P\), for a single \(,\), by establishing a uniform minorization for \(P\). We denote the transition kernel for this Markov chain \(P\) as \(p()\), which is given in (11) with \(_{i},_{i}\) replaced by a fixed \(,\).

**Lemma 5.3**.: _Let Assumptions 5.1-5.2 with \(<\) hold. Then for the Markov chain \(P\) we have, for any \(,^{}\),_

\[p(^{})_{,}\,)\}}{_{^{}} \{ U(^{})\}},\]

_where_

\[_{,}= \{-(+ M- )diam()^{2}.\] \[.-\| U(a)\|diam()\}\]

_with \(a_{}\| U()\|.\)_

Proof.: The proof is provided in Appendix C.1.

**Theorem 5.4**.: _Let Assumptions 5.1-5.2 hold with \(<1/ M\). Then for the Markov chain \(P\), the following hold: i. \(P\) is uniformly ergodic with_

\[\|P^{n}-\|_{TV}(1-_{,})^{n}\,.\]

_ii. For any real-valued function \(f\) and samples \(X_{1},X_{2},X_{3},,X_{n}\) from \(P\), one has_

\[(_{i=1}^{n}f(X_{i})-_{}f( )())}{{}}N(0, _{*}^{2})\]

_for some \(_{*}>0\) as \(n\)._

Proof.: The proof directly follows from our Lemma 5.3 and Jones [Corollary 5]. 

Note that as \( 0\), we have \(_{,} 1\) which implies that small step sizes result in low convergence rates. This is intuitive as the algorithm could not explore much in this case. Furthermore, our results suggest that large \(\) restricts \(\) to small values. Given that large \(\) generally requires large \(\), our findings imply an upper bound for the step size.

Adaptive Step Size and Balancing ParameterNow we tackle the case of varying step sizes and balancing parameters. Each cycle has \(s\) steps with step sizes \(_{1},_{2},,_{s}\) and balancing parameters \(_{1},_{2},,_{s}\). Note that this case is more challenging as at each step the transition operator changes and the Markov chain is no longer homogeneous. However, the marginal chain for each cycle is indeed homogeneous and can be analyzed. We present our results in this setting as follows:

**Theorem 5.5**.: _Let Assumptions 5.1 and 5.2 hold with \(_{i}<1/_{i}M\), \(i=1,2, s\). Then for the Markov chain \(\), the following hold i. \(\) is uniformly ergodic with_

\[\|^{n}-\|_{TV}(1-_{_{*},_{s}})^{n}.\]

_ii. For any real-valued function \(f\) and samples \(X_{1},X_{2},X_{3},,X_{n}\) from \(\), one has_

\[(_{i=1}^{n}f(X_{i})-_{}f( )())}{{}}N(0, _{*}^{2})\]

_for some \(_{*}>0\) as \(n\), where,_

\[_{_{*},_{s}}= \{-(}+_{s}M-\,m}{2})diam()^{2}\}\] \[\{-\| U(a)\|diam()\}\]

_with \(a_{}\| U()\|\)._

Proof.: The proof follows from our Lemma 5.3, Proposition C.1 and Jones [Corollary 5]. 

Both Theorems 5.4 and 5.5 hold uniformly over all functions in the class of functions with at least a local minima in \(\). The Central Limit Theorem results in Theorems 5.4 and 5.5 imply that we may perform inference on the target distribution \(()\) even though the asymptotic variances are unknown, as we may perform batch-means to estimate these variances Vats et al. .

In summary, we have established a geometric convergence rate to the target distribution for our sampler. Previous research has only established asymptotic convergence [Zhang et al., 2022b] or relative convergence rate bounds [Grathwohl et al., 2021] for gradient-based discrete samplers. To the best of our knowledge, our results present the first non-asymptotic convergence bounds that explicitly quantify the distance between the estimated and target distributions. Further, our convergence bound also shows that discrete spaces play a fundamental part in the ergodic nature of these algorithms.

## 6 Experiments

We call our method that combines Algorithm 1 and 2 _Automatic Cyclical Sampler_ (ACS). For RBM and EBM sampling tasks, we compare our method to Gibbs-with-Gradient (GWG) (Grathwohl et al., 2021), Any-scale sampler (AB) (Sun et al., 2023a), and Discrete Metropolis Adjusted Langevin Algorithm (DMALA) (Zhang et al., 2022b), which are popular and recent gradient-based discrete samplers. For learning tasks, we omit AB sampler as it is not originally applied to the model learning tasks. More experimental details are in Appendix D. We released our code at the following link: https://github.com/patrickpynadath1/automatic_cyclical_sampling.

### Sampling Tasks

We evaluate our sampling method on both Restricted Boltzmann Machines (RBMs) and deep convolutional Energy-Based Models (EBMs). For RBMs, we measure accuracy by comparing the Maximum Mean Divergence (MMD) between samples generated by our method and Block Gibbs, which can be considered the ground truth. We sample on EBMs to demonstrate our method's scalability to more complex distributions. Experimental details are provided in Appendices D.2 and D.3 for RBM and EBM sampling, respectively.

ResultsIn Figure 3, our proposed ACS method performs competitively for both RBMs and EBMs across all datasets. For RBM sampling, ACS is able to converge to the ground truth quicker than other methods due to the ability to capture the multi-modal nature of the target distribution. We see that this performance generalizes to more complex distributions as represented by deep EBMs.

### Learning RBMs and EBMs

One common application of MCMC techniques is learning energy-based models (EBMs), where a neural network parameterized by \(\) represents an energy function \(E_{}\). These models are typically trained using Persistent Contrastive Divergence (PCD) and evaluated with Annealed Importance Sampling (AIS). Details on ACS for EBM learning are in Appendix B. We test our algorithm on

    & GWG\({}^{*}\) & DMALA & ACS \\  Static MNIST & \(-80.01\) & \(-80.031 0.038\) & \(\) \\ Dynamic MNIST & \(-80.51\) & \(-80.120 0.036\) & \(-79.634 0.024\) \\ Omniglot & \(-94.72\) & \(-99.243 2.101\) & \(\) \\ Caltech & \(-96.20\) & \(-98.001 0.371\) & \(\) \\   

Table 1: Deep Convolution EBM Log likelihood scores on test data as estimated by AIS. GWG results are taken from (Grathwohl et al., 2021). ACS is able to achieve better results than the baselines.

Figure 3: Sampling performance of various methods. Top row demonstrates convergence to ground truth on RBMs, bottom row demonstrates convergence speed on deep EBMs. We report the average performance across 11 random seeds within 1 standard error for the top row, and we show the average performance for the bottom row, as the error area is not visibly clear. For both distribution types, ACS demonstrates competitive performance with all baselines.

learning deep convolutional EBMs, with experimental details in Appendix D.5. We include additional experimentation with learning RBMs in Appendix D.4.

**Results** Table 1 demonstrates that ACS is capable of learning better quality EBMs given the same computational budget as DMALA. Furthermore, ACS learns better quality models with _less_ computational budget than GWG.

### Text Infilling

One challenging application of discrete MCMC methods is text-infilling, where the goal is to complete a sentence with some missing words. Given a dataset of sentences, we randomly mask our 50% of the words and fill them in using the distribution given by a pretrained RoBERTa model. We include experiment details in Appendix D.6.

**Results** Table 2 demonstrates that ACS is capable of generating more diverse sentences, as ACS has a lower self-BLEU and higher percentage of unique n-grams. While the perplexity results seem to imply that ACS generates lower quality than DMALA, we note that the ACS generations are more likely to be predicted as linguistically acceptable as shown by the CoLA scores. We discuss the results more extensively in Appendix D.6.

## 7 Conclusion and Limitations

In this work, we propose Automatic Cyclical Sampler (ACS) to more effectively characterize multimodal distributions in discrete spaces. First, we demonstrate that gradient-based samplers are prone to getting trapped in local modes, preventing a full characterization of target distributions. To address this issue, we combine a cyclical step size schedule with a cyclical balancing parameter schedule along with an automatic tuning algorithm to configure these schedules. We also theoretically establish the non-asymptotic convergence bound of our method to the target distribution in addition to providing extensive experimental results.

While our proposed ACS method generates impressive results on a wide range of experiments, there are some limitations to our work that should be mentioned. Specifically, though we have proven a geometric convergence rate and the relationship between \(\) and \(\) in our theoretical analysis, we require \(U()\) to be twice differentiable as well as locally strongly concave and the proof is not based on the specific tuning algorithm implemented. This is why we provide extensive experimentation to demonstrate that our algorithm is capable of picking good \(,\) schedules.

    &  &  &  &  &  \\   & & & & & n=2 & n=3 \\   & DMALA & \(\) & \(50.46 1.25\) & \(41.83 6.85\) & \(48.55\) & \(70.56\) \\  & ACS & \(369.44 30.85\) & \(\) & \(\) & \(\) & \(\) \\   & DMALA & \(\) & \(42.62 1.14\) & \(37.47.79\) & \(57.68\) & \(75.21\) \\  & ACS & \(307.05 14.84\) & \(\) & \(\) & \(\) & \(\) \\   

Table 2: Empirical evaluation of the generated sentences. ACS outperforms DMALA for all metrics related to diversity.