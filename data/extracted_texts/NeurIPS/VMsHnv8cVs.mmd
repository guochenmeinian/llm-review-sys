# Learning Better Representations From Less Data For Propositional Satisfiability

Mohamed Ghanem\({}^{*}\)  Frederik Schmitt\({}^{*}\)  Julian Siber\({}^{*}\)  Bernd Finkbeiner\({}^{*}\)

\({}^{*}\)CISPA Helmholtz Center for Information Security

{mohamed.ghanem,frederik.schmitt,julian.siber,finkbeiner}@cispa.de

###### Abstract

Training neural networks on NP-complete problems typically demands very large amounts of training data and often needs to be coupled with computationally expensive symbolic verifiers to ensure output correctness. In this paper, we present NeuRes, a neuro-symbolic approach to address both challenges for propositional satisfiability, being the quintessential NP-complete problem. By combining certificate-driven training and expert iteration, our model learns better representations than models trained for classification only, with a much higher data efficiency - requiring orders of magnitude less training data. NeuRes employs propositional resolution as a proof system to generate proofs of unsatisfiability and to accelerate the process of finding satisfying truth assignments, exploring both possibilities in parallel. To realize this, we propose an attention-based architecture that autoregressively selects pairs of clauses from a dynamic formula embedding to derive new clauses. Furthermore, we employ expert iteration whereby model-generated proofs progressively replace longer teacher proofs as the new ground truth. This enables our model to reduce a dataset of proofs generated by an advanced solver by \(\)\(32\%\) after training on it with no extra guidance. This shows that NeuRes is not limited by the optimality of the teacher algorithm owing to its self-improving workflow. We show that our model achieves far better performance than NeuroSAT in terms of both correctly classified and proven instances.

## 1 Introduction

Boolean satisfiability (SAT) is a fundamental problem in computer science. For theory, this stems from SAT being the first problem proven NP-complete . For practice, this is due to many highly-optimized SAT solvers being used as flexible reasoning engines in a variety of tasks such as model checking , software verification , planning , and mathematical proof search . Recently, SAT has also served as a litmus test for assessing the symbolic reasoning capabilities of neural models and a promising domain for neuro-symbolic systems . So far, neural models only provide limited, if any, justification for unsatisfiability predictions. NeuroCore , for example, predicts an unsatisfiable core, the verification of which can be as hard as solving the original problem. No certificates at all or certificates that are hard to check limit neural methods in a domain where correctness is critical and prevents close integrations with symbolic methods. Therefore, we propose a neuro-symbolic model that utilizes _resolution_ to solve SAT problems by generating easy-to-check certificates.

A resolution proof is a sequence of case distinctions, each involving two clauses, that ends in the empty clause (falsum). This technique can also be used to prove satisfiability by exhaustively applying it until no further new resolution steps are possible and the empty clause has not been derived. Generating such a proof is an interesting problem from a neuro-symbolic perspective because unlike other discrete combinatorial problems that have been considered before , itrequires selecting compatible _pairs_ of clauses from the dynamically growing pool, as newly derived clauses are naturally considered for derivation in subsequent steps. In this work, we devise three attention-based mechanisms to perform this pair-selection needed for generating resolution proofs. In addition, we augment the architecture to efficiently handle _sat_ (satisfiable) formulas with an assignment decoding mechanism that assigns a truth value to each literal. We hypothesize that, despite their final goals being in complete opposition, resolution and _sat_ assignment finding can form a mutually beneficial collaboration. On the one hand, clauses derived by resolution incrementally inject additional information into the network, e.g., deriving a single-literal clause by resolution directly implies that literal should be true in any possible _sat_ assignment. On the other hand, finding a _sat_ assignment absolves the resolution network from having to prove satisfiability by exhaustion. On that basis, given an input formula, NeuRes proceeds in two parallel tracks: (1) finding a _sat_ assignment, and (2) deriving a resolution proof of unsatisfiability. Both tracks operate on a shared representation of the problem state. Depending on which track succeeds, NeuRes produces the corresponding SAT verdict which is guaranteed to be sound by virtue of its certificate-based design. Since both of our certificate types are efficient to check, we can afford to perform these symbolic checks at each step. When comparing NeuRes with NeuroSAT , which has been trained to predict satisfiability with millions of samples, we demonstrate that NeuRes achieves a higher accuracy while providing a proof and requires only thousands of training samples.

As for most problems in theorem proving we are not only interest in finding any proof but a short proof. Resolution proofs can vary largely in their size depending on the resolution steps taken. Being able to efficiently check the proof, also allows us to adapt the proof target while training the model. In particular, we explore an expert iteration mechanism [2; 39] that pre-rolls the resolution proof of the model and replaces the target proof whenever the pre-rolled proof is shorter. We demonstrate that this bootstrapping mechanism iteratively shortens the proofs of our training dataset while further improving the overall performance of the model.

We make the following contributions:

1. We introduce novel architectures which combine graph neural networks with attention mechanisms for generating resolution proofs and assignments for CNF formulas (Section 4).
2. We show that for propositional logic, learning to prove rather than predict satisfiability results in better representations and requires far less training samples (Section 6 and 7).
3. We devise a bootstrapped training procedure where our model progressively produces shorter resolution proofs than its teacher (Section 6.2) boosting the model's overall performance.

The implementation of our framework can be found at https://github.com/Oschart/NeuRes.

## 2 Related Work

SAT Solving and Certificates.We refer to the annual SAT competitions  for a comprehensive overview on the ever-evolving landscape of SAT solvers, benchmarks, and proof checkers. SAT solvers are complex systems with a documented history of bugs [9; 26], hence proof certificates have been partially required in this competition since 2013 . Unlike satisfiable formulas, there are several ways to certify unsatisfiable formulas . Resolution proofs [52; 20] are easy to verify , but non-trivial to generate from modern solvers based on the paradigm of conflict-driven clause learning . Clausal proofs, e.g., in DRAT format , are easier to generate and space-efficient, but hard to validate. Verifying the proofs can take longer than their discovery  and requires highly optimized algorithms .

Deep Learning for SAT Solving.NeuroSAT  was the first study of the Boolean satisfiability problem as an end-to-end learning task. Building upon the NeuroSAT architecture, a simplified version has been trained to predict unsatisfiable cores and successfully integrated as a branching heuristic in a state-of-the-art SAT solver . Recent work has employed a related architecture as a phase selection heuristic . It has been shown that both the NeuroSAT architecture and a newly introduced deep exchangeable architecture can outperform SAT solvers on instances of 3-SAT problems . The NeuroSAT architecture has also been applied on special classes of crypto-analysis problems . In addition to supervised learning, unsupervised methods have been proposed for solving SAT problems. For Circuit-SAT a deep-gated DAG recursive neural architecture has been presented together with a differentiable training objective to optimize towards solving the Circuit-SAT problem and finding a satisfying assignment . For Boolean satisfiability, a differentiable training objective has been proposed together with a query mechanism that allows for recurrent solution trials .

Deep Learning for Formal Proof Generation.In formal mathematics, deep learning has been integrated with theorem proving for clause selection [33; 18], premise selection [25; 48; 6; 35], tactic prediction [51; 37] and whole proof searches [40; 19]. For SMT formulas specifically, deep reinforcement learning has been applied to tactic prediction . In the domain of quantified boolean formulas, heuristics have been learned to guide search algorithms in proving the satisfiability and unsatisfiability of formulas . For temporal logics, deep learning has been applied to prove the satisfiability of linear-time temporal logic formulas and the realizability of specifications [21; 41; 14].

## 3 Proofs of (Un-)Satisfiability

We start with a brief review of certifying the (un-)satisfiability of propositional formulas in conjunctive normal form. For a set of Boolean variables \(V\), we identify with each variable \(x V\) the _positive literal_\(x\) and the _negative literal_\( x\) denoted by \(\). A _clause_ corresponds to a disjunction of literals and is abbreviated by a set of literals, e.g., \(\{,3\}\) represents \(( x_{1} x_{3})\). A formula in _conjunctive normal form (CNF)_ is a conjunction of clauses and is abbreviated by a set of clauses, e.g., \(\{\{,3\},\{1,2,\}\}\) represents \(( x_{1} x_{3})(x_{1} x_{2} x_{4})\). Any Boolean formula can be converted to an equisatisfiable CNF formula in polynomial time, for example with Tseitin transformation .

A CNF formula is _satisfiable_ if there exists an _assignment_\(:V\{,\}\) such that all clauses are satisfied, i.e., each clause contains a positive literal \(x\) such that \((x)=\) or a negative literal \(\) such that \((x)=\). If no such assignment exists we call the formula _unsatisfiable_. To prove unsatisfiability we rely on resolution, a fundamental inference rule in satisfiability testing . The resolution rule (_Res_) picks clauses with two opposite literals and performs the following inference:

\[\{x\}}{C_{1} C_{2}}\]

Resolution effectively performs a case distinction on the value of variable \(x\): Either it is assigned to _false_, then \(C_{1}\) has to evaluate to \(\), or it is assigned to \(\), then \(C_{2}\) has to evaluate to \(\). Hence, we may infer the clause \(C_{1} C_{2}\). A _resolution proof_ for a CNF formula is a sequence of applications of the _Res_ rule ending in the empty clause.

## 4 Models

### General Architecture

NeuRes is a neural network that takes a CNF formula as a set of clauses and outputs either a satisfying truth assignment or a resolution proof of unsatisfiability. As such, our model comprises a formula

Figure 1: Overall NeuRes architecture

embedder connected to two downstream heads: (1) an attention network responsible for selecting clause pairs, and (2) a truth assignment decoder. See Figure 1 for an overview of the NeuRes architecture. After obtaining the initial clause and literal embeddings (representing the input formula), we continue with the iterative certificate generation phase. At each step, the model selects a clause pair which gets resolved into a new clause to append to the current formula graph while decoding a candidate truth assignment in parallel. The model keeps deriving new clauses until the empty clause is found (marking resolution proof completion), a satisfying assignment is found (marking a certified _sat_ verdict), or the limit on episode length is reached (marking timeout).

### Message-Passing Embedder

Similar to NeuroSAT, we use a message-passing GNN to obtain clause and literal embeddings by performing a predetermined number of rounds. Our formula graph is also constructed in a similar fashion to NeuroSAT graphs where clause nodes are connected to their constituent literal nodes and literals are connect to their complements (cf. Appendix A). For a formula in \(m\) variables and \(n\) clauses, the outputs of this GNN are two matrices: \(E^{L}^{m d}\) for literal embeddings and \(E^{C}^{n d}\) for clause embedding, where \(d^{+}\) is the embedding dimension. Here we have two key differences from NeuroSAT. Firstly, NeuroSAT uses these embeddings as voters to predict satisfiability through a classification MLP. In our case, we use these embeddings as clause tokens for clause pair selection and literal tokens for truth value assignment. Secondly, since our model derives new clauses with every resolution step, we need to embed these new clauses, as well as update existing embeddings to reflect their relation to the newly inferred clauses. Consequently, we need to introduce a new phase to the message-passing protocol, for which we explore two approaches: _static embeddings_ and _dynamic embeddings_.

In a _static_ approach, we do not change the embeddings of initial clauses upon inferring a new clause. Instead, we exchange local messages between the node corresponding to the new clause and its literal nodes, in both directions. The main advantage of this approach is its low cost. A major drawback is that initial clauses never learn information about their relation to newly inferred clauses.

In a _dynamic_ approach, we do not only generate a new clause and its embedding, we also update the embeddings of all other clauses. This accounts for the fact that the utility of an existing clause may change with the introduction of a new clause. We perform one message-passing round on the mature graph for every newly derived clause, which produces the new clause embedding and updates other clause embeddings. Since message-passing rounds are parallel across clauses, a single update to the whole embedding matrix is reasonably efficient.

### Selector Networks

After producing clause and literal embeddings, NeuRes enters the derivation stage. At each step, our model needs to select two clauses to resolve, produce the resultant clause, and add it to the current formula. To realize our clause-pair selection mechanism, we employ three attention-based designs.

#### 4.3.1 Cascaded Attention (Casc-Attn)

In this design, pairs are selected by making two consecutive attention queries on the clause pool. We condition the second attention query on the outcome (i.e., the clause) of the first query. Figure 2 shows this scheme where we perform the first query using the mean of the literal embeddings \(}\) concatenated with a zero vector while performing the second query using the mean of the literal

Figure 2: Cascaded attention

embeddings concatenated with the embedding vector \(E_{c_{i}}^{C}\) of the clause selected in the first query. Formally, Casc-Attn selects a clause index pair \((c_{1},c_{2})\) as follows:

\[c_{i}=}[u^{T}(W_{1}q_{i}+W_{2}E_{j}^{C}) ] q_{i}=} &i=1\\ } E_{c_{1}}^{C}&i=2\] (1)

where \(W_{1}^{2d d},W_{2}^{d d},u^ {d}\) are trainable network parameters.

The advantage of this design is that it is not limited to pair selection and can be used to select a tuple of arbitrary length. The main downside, however, is that this design chooses \(c_{1}\) independently from \(c_{2}\), which is undesirable because the utility of a resolution step is determined by both clauses simultaneously (not sequentially).

#### 4.3.2 Full Self-Attention (Full-Attn)

To address the downside of independent clause selection, this variant performs self-attention between all clauses to obtain a matrix \(S^{n n}\) where \(S_{i,j}\) represents the attention score of the clause pair \((c_{i},c_{j})\) as shown in Figure 3. The model selects clause pairs by choosing the cell with the maximal score. In this attention scheme, the clause embeddings are used as both queries and keys.

Formally, Full-Attn selects a clause index pair \((c_{1},c_{2})\) as follows:

\[(c_{1},c_{2})=}\;\;S_{i,j} Q =E^{C}W_{Q}; K=E^{C}W_{K}; S=}{}\] (2)

where \(W_{Q}^{d d},W_{K}^{d d}\) are trainable network parameters. Since \(S\) contains many cells that correspond to invalid resolution steps (i.e., clause pairs that cannot be resolved), we mask out the invalid cells from the attention grid in ensure the network selection is valid at every step.

#### 4.3.3 Anchored Self-Attention (Anch-Attn)

In Full-Attn, the attention grid grows quadratically with the number of clauses. In this variant, we relax this cost by exploiting a property of binary resolution where each step targets a single variable in the two resolvent clauses. This allows us to narrow down candidate clause pairs by first selecting a variable as an anchor on which our clauses should be resolved. As such, we do not need to consider the full clause set at once, only the clauses containing the chosen variable \(v\). We further compress the attention grid by lining clauses containing the literal \(v\) on rows while lining clauses containing the literal \( v\) on columns. This reduces the redundancy of the attention grid since clauses containing the variable \(v\) with the same parity cannot be resolved on \(v\), so there is no point in matching them. In this scheme, we have two attention modules: one attention network to choose an anchor variable followed by a self-attention network to produce the anchored score grid.

In light of Figure 4, this approach combines structural elements from Casc-Attn and Full-Attn; however, both elements are used differently in Anch-Attn. Firstly, the attention mechanism in Casc-Attn is used to select clauses whereas Anch-Attn uses it to select variables. Secondly, self-attention in Full-Attn matches any pair of clauses (\(c_{i}\), \(c_{j}\)) in both directions as the row and column dimensions in the attention score grid reflect the same clauses (all clauses). By contrast, Anch-Attn computes self-attention scores for clause pairs in only one order (positive instance to negative instance). Formally,

Figure 3: Full self-attention

(2)

Anch-Attn selects an anchor variable \(v\) as follows:

\[v=}[u^{T}(W_{1}}+W_{2}(E_{i} ^{L^{+}}+E_{i}^{L^{-}}))]\] (3)

where \(W_{1}^{d d},W_{2}^{d d},u^{d}\) are trainable network parameters. The clause index pair \((c_{1},c_{2})\) is then selected according to the same equations of Full-Attn (Eq. 2) using the \(v\)-anchored set of clause embeddings.

### Assignment Decoder

To extract satisfying assignments, we use a sigmoid-activated MLP \(\) on top of the literal embeddings \(E^{L}\) to assign a truth value \(}(l_{i})\) to a literal \(l_{i}\) as shown in Eq. 4.

\[}(l_{i})=((E_{i}^{L}))\] (4)

Note that since for each variable, we have a positive and a negative literal embeddings, we can construct two different truth assignments at a time using this method. However, supervising both assignments did not improve the performance compared to only supervising the positive assignment (on positive literal embeddings). Thus, to simplify our loss function, we only derive truth assignments from the positive literal embeddings at train time while extracting both at test time. Interestingly, at test time, we found using negative literals (in addition to the positive ones) sometimes produces satisfying assignments before the positive branch despite receiving no direct supervision during training. Our intuition regarding this observation attributes it to the fact that the formula graph has no explicit notion of positive and negative literals, it only represents connections to clauses (positive and negative literals are connected by an undirected edge that does not distinguish their parity). As such, both literal nodes have a different local view into the rest of formula, which could result in one of them leading to a satisfying assignment faster than the other.

## 5 Training and Hyperparameters

### Dataset

For our training and testing data, we adopt the same formula generation method as NeuroSAT , namely \((n)\) where \(n\) is the number of variables in the formula. This method was designed to generate a generalized formula distribution that is not limited to a particular domain of SAT problems. To control our data distributions, we vary the range on the number of Boolean variables involved in each formula. For our training data, we use formulas in \((U(10,40))\) where \(U(10,40)\) denotes the uniform distribution on integers between 10 and 40 (inclusive). To generate our teacher certificates comprising resolution proofs and truth assignments, we use the BooleForce solver  on the formulas generated on the **SR** distribution.

### Loss Function

We train our model in a supervised fashion using teacher-forcing on solver certificates. During _unsat_ episodes, teacher actions (clause pairs) are imposed over the whole run. The length of the teacher proof dictates the length of the respective episode, denoted as \(T\). Model parameters \(\) maximize the likelihood of teacher choices \(y_{t}\) thereby minimizing the resolution loss \(_{Res}\) shown in Eq 5.

\[_{Res}=-_{t}(p(y_{t};))^{(T-t)}\] (5)

Figure 4: Anchored self-attention

[MISSING_PAGE_FAIL:7]

### Shortening Teacher Proofs with Bootstrapping

During our initial experiments, we discovered proofs produced by NeuRes that were shorter than the corresponding teacher proofs in the training data. Although teacher proofs were generated by a traditional SAT solver, they are not guaranteed to be size-optimal. The size of resolution proofs is their only real drawback, hence any method that can reduce this size would be immensely useful. Upon closer inspection we find that, on average, our previous best performer trained with regular teacher-forcing manages to shorten \(\)\(18\%\) of teacher proofs by a notable factor (cf. Appendix C). This inspired us to devise a bootstrapped training procedure to capitalize on this feature: We pre-roll each input problem using model actions only, and whenever the model proof is shorter than the teacher's, it replaces the teacher's proof in the dataset. In other words, we maximize the likelihood of the shorter proof. In doing so iteratively, the model progressively becomes its own teacher by exploiting redundancies in the teacher algorithm.

The outcome of this bootstrapped training process is summarized in Table 6. We find that bootstrapping results in notable gains in terms of both success rate and optimality. The sharp decline in proof length (relatively quantified by p-Len) at test time shows that the models transfers the bootstrapped knowledge to unseen test formulas, as opposed to merely overfitting on training formulas. In addition to success rate and p-Len, we inspect the reduction statistics of our bootstrapped variant (first three rows of Table 6). Since the bootstrapped model performs multiple reduction scans over the training dataset, we add a metric for reduction depth computed as the number of progressive reductions made to a proof. To further quantify this effect, we report the maximum and average reduction ratios of reduced proofs relative to teacher proofs. Finally, we report the total reduction made to the dataset size in terms of total number of proof steps.

In Appendix C, we have compiled additional statistics (cf. Table 5) on proof shortening during the training process, as well as an example proof reduced by the bootstrapped NeuRes (Figure 7). We only include a small reduction example (from 20 steps to 10 steps) for space constraints, but we observed many more examples of much larger reductions (e.g., over \(400\) steps).

## 7 Resolution-Aided SAT Solving

In this section, we evaluate the performance of our fully integrated model trained on a hybrid dataset comprising 8K unsatisfiable formulas (and their resolution proofs) and 8K satisfiable formulas (and their satisfying assignments). For the unsatisfiable formulas, timeout (\(4|_{}|\)) and optimality (p-Len) are measured similarly to previous experiments. For satisfiable formulas, we set the timeout (maximum #trials) to \(2|V|\). Ultimately, this section aims to investigate the effect of incorporating a certificate-driven downstream head on the quality of the learnt representations through its impact on the performance of the complementary task, i.e., proving/predicting satisfiability. We use NeuroSAT as our baseline as it employs the same formula embedding architecture. Since NeuroSAT proves _sat_ but only _predicts unsat_, we train a classification MLP on top of our trained NeuRes model to further showcase the benefit of our representations on prediction accuracy.

Table 3 confirms this main hypothesis. In essence, this result points to the fact that learning signals obtained from training on _unsat_ certificates largely enhance the ability of the neural network to extract useful information from the input formula. This is doubly promising considering NeuroSAT was

  Reduction Depth & **max**: \(23\), **avg**: \(6.6\) \\  Proof Reduction (\%) & **max**: \(86.11\), **avg**: \(33.51\) \\  Proofs Reduced (\%) & 90.08 \\  Total Reduction (\%) & 31.85 \\  p-Len & 1.15 \\  Success Rate (\%) & 100.0 \\   

Table 2: Bootstrapped training data reduction statistics. Reduction statistics are computed on the \((U(10,40))\) training set while p-Len and success rate are computed on a test set of the same distribution.

trained on _millions_ of formulas while NeuRes was trained on only _16K_ formulas. Lastly, we find that augmenting _sat_ formulas by resolution derivations results in relative improvements (\( 2.3\%\)) in success rate even though these derivations are attempting to prove unsatisfiability.

## 8 Utilizing Model Fan-Out

In our Full-Attention module, we compute \(n^{2}\) scores and only perform the top-score resolution step. This greedy approach arguably underutilizes the attention grid computations as it ignores other high-scoring steps that might lead to a shorter proof thereby improving the success rate in addition to reducing the number of queries to the model. The latter leads to an overall runtime reduction since performing an extra symbolic resolution step is much faster than a forward model pass. As such, we experiment with performing the top \(k\) steps of the attention grid after each forward pass. It should be noted, however, that this yields diminishing returns as it leads to a faster growth of the clause base which in turn inflates the attention grid. For \(k>1\), after deriving the empty clause, only clauses that connect to it in the resolution graph are kept in the final proof. This post-processing step is linear in the proof length and eliminates redundant resolution steps resulting from the higher fan-out. Table 4 shows that taking the top \(3\) steps already yields a massive reduction in proof lengths along with a significant boost to the success rate.

One way to offset the attention grid inflation with higher fan-out would be to keep a saliency map for all clauses then discarding \(k\) clauses with the least saliency scores after each forward pass. One simple way to compute this saliency score for a clause would be the sum/mean/max of its respective row in the attention scores grid. Another proxy for saliency could be the recency score reflecting how many steps have elapsed since the last time a given clause was used.

## 9 Generalizing to Larger Problems

In order to test our model's out-of-distribution performance, we evaluate our NeuRes model on five datasets comprising formulas with up to 5 times more variables than encountered during training. We use the same distributions reported by NeuroSAT and we run our model for the same maximum number of iterations (1000).

Figure 5 shows the scalability of NeuRes to larger problems by letting it run for more iterations. Compared to NeuroSAT , NeuRes scores a much higher first-try success rate on all 5 problem distributions, and a higher final success rate on all of them except for \((40)\) on which both models nearly score \(100\%\). Particularly, NeuRes shows higher first-try success on the 3 largest problem sizes where NeuroSAT solves zero or near-zero problems on the first try.

  
**Full-attn Fan-out** & **p-Len** & **\#Model Calls** & **Total Proven (\%)** \\ 
**Top-1** & 1.15 & 1.15 & 98.2 \\ 
**Top-3** & 0.57 & 0.49 & 99.9 \\ 
**Top-5** & **0.52** & **0.43** & **100.0** \\   

Table 4: Performance of different model fan-outs on \((40)\) test data. Proof length (p-Len) and #Model Calls are both normalized by the length of the teacher proof.

   &  &  \\   & SAT & UNSAT & Total & SAT & UNSAT & Total \\  NeuRes & **96.8** & **99.6** & **98.2** & **84.28** & **99.2** & **91.65** \\  NeuroSAT  & 70 & - & - & 73 & 96 & 85 \\   

Table 3: Performance of full solver mode tested on \((40)\) problems and trained on \((U(10,40))\) problems where predicted refers to the satisfiability prediction without certificate.

## 10 Conclusion

In this paper, we introduced a deep learning approach for proving and predicting propositional satisfiability. We proposed an architecture that combines graph neural networks with attention mechanisms to generate resolution proofs of unsatisfiability. Unlike methods that merely predict unsatisfiability, our models provide easily verifiable certificates for their verdicts. We demonstrated that our certificate-based training and resolution-aided mode of operation surpass previous approaches in terms of performance and data efficiency, which we attribute to learning better representations.

Despite its promising benchmark performance, our model cannot solely outperform highly engineered industrial solvers, as is currently the case for all neural methods as standalone tools. The gap between neural networks and symbolic algorithms is still rather large, and our hope is to bring deep learning methods one concrete step closer to filling this gap. For NeuRes, this step is recognizing the immense value of carefully integrating certificates into the model design and training as opposed to using shallow supervision labels. Last but not least, it is worth noting that even at their present state, neural networks stand great potential to advance traditional solvers by combining them into hybrid solvers that utilize the deep long-range dependencies captured by neural networks along with the exploration speed of symbolic algorithms. Moreover, we demonstrated a unique potential to advance SAT solving through proof reduction, as proof size is a major challenge in certifying the results of traditional solvers. This proof reduction is facilitated by a bootstrapped training procedure that uses teacher proofs as a guide as opposed to a golden standard.