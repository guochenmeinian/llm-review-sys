# Supplementary Materials

[MISSING_PAGE_EMPTY:1]

Introduction

Three-dimensional human motion estimation is a long-standing and challenging research goal in computer vision, particularly in monocular scenarios due to inherent depth ambiguities. Previous approaches have incorporated kinematic priors, e.g. by enforcing smoothness, maintaining bone length constancy, or imposing symmetry constraints. However, due to inconsistencies of frame-wise predictions, these solutions do not necessarily lead to physically plausible motions. This has led to the emergence of a new research direction that combines traditional 3D motion estimation with physical models of the human skeleton. Instead of directly predicting a human pose, these approaches estimate the internal joint torques and exterior forces that drive the motion. Consequently, physics simulators are employed to obtain the resulting motion [37; 38; 8; 50; 21].

However, since simulators are never perfect representations of the real world, they introduce inevitable errors, where the complex human body was never fully modelled, only approximation by rigid body dynamics . Moreover, measurements, including "ground truth" recordings, are inherently noisy. To tackle these problems, we propose _OSDCap_, a state-aware architecture that combines a differentiable physical simulation with our novel neural Kalman filtering approach. Fig. 1 shows our reconstructed poses predicted from noisy kinematics estimates as well as the estimated dynamics from a video.

_OSDCap_ is an online filtering and dynamics estimation that can be trained in an end-to-end manner. In detail, our approach consists of two steps, starting from a noisy kinematics reconstruction obtained by an off-the-shelf video-based 3D human pose estimator: 1) a simulation branch that estimates joint torques using a PD controller and computes the resulting motion, 2) an adaptive filtering stage that combines the output of the simulation stage and the video-based kinematics input to produce a refined motion. We follow prior work that utilizes the meta-PD algorithm for torque calculation [38; 21] to simulate plausible motion. However, the effectiveness of the PD algorithm heavily relies on the choice of the P and D gains  and on an accurate model of the human kinematic chain, which is generally unknown. Moreover, the measurements from the monocular 3D kinematics pose estimator contain a large amount of noise, which ultimately leads to inaccurate predictions. Shimada et al.  mitigate these problem by introducing an additional offset term into the PD controller. While this approach still produces reasonable output motion it is neither physically explainable nor consistent with PD controllers in control theory. We aim to solve this problem at the root by taking inspiration from control theory and propose a solution for processing the imperfect PD calculation by a learnable Kalman filtering method . The proposed Kalman filter takes the simulated motions and the noisy 3D pose estimation as inputs, combines them, and produces an optimal state prediction as the output. The Kalman filter effectively refines the PD controller-based simulated motions into more plausible and realistic motions. While the Kalman filter fixes inaccurate kinematic measurements from the 3D pose estimator it does not take different weight distributions in the human body parts into account. We calculate an initial weight distribution - the inertia matrix - for an average human body shape. However, as for the skeletal structure, these are only approximations that lead to inaccurate simulations. We mitigate this issue by predicting an inertia bias matrix in each time step which is added to the initial inertia matrix.

We demonstrated the 3D reconstruction performance of our method on the popular Human3.6M  dataset, and the newer Fit3D  and SportsPose  datasets, comparing them with recent state-of-the-art physics-based methods.

In summary, _OSDCap_ introduces a new physics-based human motion and dynamics estimation method leveraging a learnable Kalman filter and a learnable inertia prediction, that produces plausible motion as well as valuable estimates of exterior forces and internal torques. By offering improved accuracy and interpretability in human motion estimation, _OSDCap_ presents a promising step towards bridging the gap between computer vision and the complex physics-based human motion modeling.

## 2 Related Work

### Kinematics 3D Human Motion Capture

Monocular 3D human motion capture is a well-studied line of research, with common approaches that can be roughly divided into two groups, 1) end-to-end approaches that directly predict human poses from images [39; 29], and 2) lifting from 2D [1; 26; 28; 12; 4; 30; 42; 2; 10; 44; 22; 47; 43; 31]. Recent work addresses the problem by fitting volumetric models to 2D/3D evidence, aiming to achieve realistic human motion [27; 17; 25; 19; 20; 48; 45; 18; 23; 53; 40]. Despite the significant progress, vision-based human 3D pose estimation is still an ill-posed problem, due to the loss of depth information from the monocular setup. Therefore, captured 3D motions often contain different types of implausibility, ranging from unnatural poses, jittering, or unrealistic body artifacts [46; 8].

### Physics-based 3D Human Motion Capture

Recent studies [37; 50; 46; 8; 21] enforce physics as constraints for motion reconstruction, eliminating implausible artifacts created by the monocular estimation, i.e. jittering, ground penetration, and unnatural human poses.

Motion imitation using reinforcement learning (RL) is a popular approach for simulating physically plausible results [32; 49; 50; 33; 51]. RL-based methods enforce physics constraints in the reward functions, either from manually-designed formulas, or from physics engines. The bottleneck of RL-based approaches is the low transferability of the learned policies to unseen motions.

Motion optimization is another common approach for physics-based human motion capture. However, optimization problems often require a differentiable framework, thus, instead of relying on non-differentiable physics engines, prior studies [34; 37; 46] adapt simplified motion equations  as a dynamics constraint for simulated motions. More recent approaches [13; 9] manage to optimize through non-differentiable simulation using evolutionary optimization methods . Gartner et al.  implement a differentiable version of PyBullet , resulting in an optimizable framework with complex physics engines. However, most optimized motion solutions, similar to RL-based solutions, have limited adaptability to different data distributions, requiring re-optimizing on new sets of action.

Utilizing the generalizability of neural network models in an end-to-end manner is still an open line of research, due to the difficulty of finding physical plausibility patterns from data. Rempe et al.  utilizes a variational autoencoder architecture for predicting plausible motions, approximating the dynamics simulation by a decoder network. This assumption might result in unrealistic force prediction with respect to biomechanics literature. Li et al.  utilize the meta-PD controller with learnable parameters for torque prediction, but with an additional compensation term based on root residual forces. Zhang et al.  realize a transformer-based autoencoder to refine kinematics input sequences, while integrating physics constrain inside the latent embedding. However, both Li et al.  and Zhang et al.  make predictions based on the encoding of the full motion sample, i.e. they require knowledge of past and future motions, therefore, limiting the applicability of the method to offline setups, where future information is available. Shimada et al.  also use a meta-PD controller for calculating the optimal joint torques, which in turn generates a simulated motion matching visual kinematics estimation. Despite the plausibility of the estimated pose, the global precision of the motion in world coordinate is limited and not fully addressed.

We aim to leverage physics-based approach (with meta-PD controller) on motion data captured by monocular camera systems, in a recursive online setup, and expand the prediction to more complex practical movements such as sports.

## 3 Method

This section presents our proposed approach _OSDCap_ in detail. We start by creating an average proxy character B based on the uniform human configuration from the Human3.6M dataset . The character approximates a human body by circles and cylinders. Additionally, we leverage the pretrained neural network TRACE  to obtain an initial 3D pose estimation. Without any additional priors, _OSDCap_ aims to predict the joint torques and external forces that drive the proxy character to match the kinematics evidence given by TRACE. Following prior work, we employ a neural network that predicts the parameters of a meta-PD controller which consecutively predicts the joint torques. While related approaches [38; 21] stop here, we note that the quality of the motion given by the PD controllers' prediction highly depends on the realism of the videos-based kinematic estimation and the proxy character. Since a model can always only be an approximation of the real world, this leads to inaccurate predictions which prior work compensates for by adding an additional offset term to the PD controller. Unfortunately, this not only introduces a non-physical assumption but through experimentation we found that this term attributes the major part to the prediction of the PD controller. We aim to maintain the physical plausibility of our approach by introducing a novel filtering approach inspired by a neural Kalman filter  to refine and update the motion states. Additionally, at each time step, the foot contact states and ground reaction forces are estimated directly from the motion leading to a full description of the system dynamics. Fig. 2 shows an overview of our method.

### Preliminaries - Rigid Body Dynamics

Similar to previous studies [34; 37; 38; 46], we enforce physics constraints based on _Rigid Body Dynamics_, inline with the Newtonian equation of motion. For a total of \(N\) keypoints, the full human pose is represented as a vector \(^{6+3N}\), encoding the global translation and rotation in the first 6 entries, and internal joint angle states in the remaining \(3N\) entries. \(}^{6+3N}\) is the corresponding velocity vector. The motion dynamics of the captured human poses should satisfy the Newtonian equation of motion, expressed as

\[()}=+-(,}),\] (1)

where \((q)^{(6+3N)(6+3N)}\) is the inertia matrix, computed from the proxy character, \(}^{6+3N}\) is the acceleration, \(^{6+3N}\) are the internal joint torques, \(^{6+3N}\) are the external forces, and \((,})^{6+3N}\) is the non-linear term including gravitational, Coriolis, and centrifugal forces, computed using inverse dynamics with zero acceleration on the proxy character . Our goal is to estimate the two vectors \(\) and \(\) that produce plausible motion dynamics.

### Optimal-state Dynamics Capture

The proposed _OSDCap_ consists of three main processing stages: an optimal pose estimation, a physics priors calculation, and a velocity update based on physics simulation. The optimal pose estimation phase is a filtering approach inspired by KalmanNet  that estimates an optimal output pose based on the current system state and video-based 3D kinematics inputs. The physics priors calculation computes the current inertia matrix and non-linear forces based on the proxy character from the current system state. The physics simulation phase computes the next velocity state using the PD algorithm and forward dynamics (Eq. 1) from the estimated optimal pose.

The required inputs for the optimal pose estimation and physics simulation are estimated by our neural network _OSDNet_. _OSDNet_ consists of two modules, one predicts Kalman gains for the Kalman filtering, and the other predicts PD gains, external forces and inertia-bias for the physics simulation.

**Optimal Pose Estimation.** As shown in Fig. 2, the Kalman filtering block takes the current system state and the videos-based kinematics pose as inputs. Following traditional Kalman filters the next predict state is computed from the previous state. We define the state transitioning phase as

\[_{t+1|t}=_{t|t}+}_{t|t} t.\] (2)

Figure 2: The main pipeline of _OSDCap_. Our approach consists of one neural network model, _OSDNet_ (orange), and three processing components. _OSDNet_ takes the current system state, estimates a Kalman gain matrix, PD gains, external force and an inertia-bias matrix. The optimal pose estimation performs contains a Kalman filter for the current system state and the input kinematics. Yellow refers to the algorithm’s state vectors and cyan denotes processing operations. The physics priors block (gray) computes the inertia matrix and non-linear forces using the Composite rigid-body algorithm and Inverse dynamics . Using the PD algorithm and forward dynamics (Eq. 1), the physics simulation block (green) updates the velocity based on the computed optimal pose and physics priors.

The predicted positional state \(_{t+1|t}\) is the physics-constrained body pose. The observation matrix \(\) (Fig. 2) maps the predicted states \(_{t+1|t}\) to an observed simulated positional state. \(\) is an adaptation matrix to reduce the gap between observed states from videos, and observed states from physics simulation. \(\) and \(\) are optimized along with _OSDNet_ while training, but stay constant during inference. From the current system states, a Kalman state update process is performed as

\[_{t+1|t+1}=_{t+1|t}+_{t}(}_{t}-_{t+1|t}),\] (3)

where \(_{t}\) contains the estimated Kalman gains at step \(t\) based on the current states and observations. Inspired by , the Kalman gains estimation module is implemented as _Gated Recurrent Units_, which have the ability to propagate the latent motion dynamics throughout the simulated motion via the hidden states of the GRU. The prediction of Kalman gains requires information about the the system's state dynamics , thus four additional dynamics features need to be feed into _OSDNet_'s GRU input, namely: _observation_, _innovation_, _forward evolution_ and _forward update_. They are calculated as

\[ =_{t|t}-_{t-1|t-1}\] (4) \[ =_{t|t}-_{t|t-1}\] \[ =}_{t+1}-_{t+1|t}\] \[ =}_{t+1}-_{t}.\]

We modify the original design from  due to the practical reasons of our system. In self-occluded scenarios, the noisy input \(}_{t}\) often contains artifacts such as body deformation and they often last for a period of time (approx. 10 frames). The intermediate difference between \(}_{t}\) and \(}_{t-1}\) in the original design  is not strong enough to model those artifacts, because they could both contain the same incorrect kinematic estimation. We change the calculation of \(\)observation as in Eq. 4 better deal with mis-detection cases that would cause large responses in \(\)observation. The pose \(_{t|t}\) is the optimal state at step \(t\) and inherits the global translation estimation from kinematics observations while retaining the physical plausibility of the human pose from the physics simulation.

**Physics Simulation.** The purpose of the physics simulation stage in Fig. 2 is to update the velocity \(}_{t|t}\) that best describes the dynamics of the filtering process. Therefore, the estimated pose \(_{t+1|t+1}\) can be used as the target signal for the PD algorithm, calculating the joint torque \(_{t}\) that maps the predict pose \(_{t+1|t}\) to the optimal pose \(_{t+1|t+1}\). The joint torque is predicted by the PD algorithm

\[_{t}=_{P}(_{t+1|t+1}-_ {t+1|t})+_{D}}_{t|t},\] (5)

where \(_{P}\), \(_{D}\) are proportional and derivative gains respectively. Inspired by , the meta-PD controller was applied at this stage, where \(_{P}\), \(_{D}\) are learnable and estimated from _OSDNet_. By using the filtered optimal pose as the target, no unrealistic temporal filtering or optimization is needed to refine the noisy kinematics inputs.

Additionally, the external forces are also estimated by _OSDNet_, assuming the source of external forces comes only from contact points and is computed as

\[_{t}=_{c}^{2}_{t}^{c}_{t}^ {c}_{t}^{c},\] (6)

where \(_{t}^{c}\) is Jacobian matrix that maps linear velocity at contact point \(c\) to rotational velocity of every other joints, \(_{t}^{c}\) and \(_{t}^{c}\) are the contact probability and the linear force vector at contact \(c\). The three vectors are separately estimated by _OSDNet_.

**Inertia Estimation.** Since we do not have access to the real bone length and mass distribution of the human, there exists a knowledge gap between simulated human character and the real human subject, the inertia tensor computed by the composite rigid-body algorithm is sub-optimal. _OSDNet_ is designed to also estimate an inertia bias term \(_{t}^{b}\) that reduces this knowledge gap. The required acceleration to drive the current simulated pose to the next states is calculated as in Eq. 7.

\[}_{t}=((_{t})^{-1}+_{t}^{b})( _{t}+_{t}-(_{t}, }_{t})),\] (7)

To update the system state, finite interpolation is applied, using the newly calculated acceleration \(_{t}\). The update process is given by

\[}_{t+1|t+1}=}_{t|t}+}_{t}  t,\] (8)

where \(}_{t+1|t+1}\) is the updated system state that represents the current system dynamics, under physics constraints from gravity and contact forces. The system now proceeds back to the transitioning phase in Eq. 2, creating a closed loop process that works recursively.

### Objective Losses

To reconstruct the optimal state, we define the overall objective loss \(L\) as a weighted sum of multiple loss functions as

\[L=_{t}^{T}_{1}L_{t}^{_{t+1|t+1}}+_{2 }L_{t}^{_{t+1|t+1}}+_{3}L_{t}^{_{t+1|t}}+_{4}L_ {t}^{_{t+1|t}}+_{5}L_{t}^{c}+L_{t}^{},\] (9)

where \(_{1}=0.5,_{2}=0.1,_{3}=0.7,_{4}=0.2,_{5}=0.4\) are weighting factors. The optimal reconstruction losses \(L_{t}^{_{t+1|t+1}}\) and \(L_{t}^{_{t+1|t+1}}\) measure the L1 distance between the estimated optimal pose \(_{t+1|t+1}\) and its corresponding 3D keypoints (obtained from forward kinematics) with the ground-truth poses \(_{t+1}^{GT}\) and ground-truth 3D keypoints \(_{t+1}^{GT}\). The supervision for predict pose \(_{t+1|t}\) is carried out similarly, ensuring the correct behaviour of the physics simulation. \(L_{t}^{c}\) is the contact loss, using Binary Cross Entropy measurement between the predicted contact probabilities \(_{t}^{c}\) of two feet with pseudo-ground-truth contact binary labels \(_{t}^{c}\). We generate the ground truth contact labels for training based on the foot-ground distances of ground-truth 3D keypoints. The individual losses are computed as

\[L_{t}^{_{t+1|t+1}}=^{N}_{t+ 1}^{GT}-_{t+1|t+1}, L_{t}^{_{t+1|t+1}}=^{6+3N}_{t+ 1}^{GT}-_{t+1|t+1},\] \[L_{t}^{_{t+1|t}}=^{N}_{t+1} ^{GT}-_{t+1|t}, L_{t}^{_{t+1|t}}=^{6+3N}_{t+ 1}^{GT}-_{t+1|t},\] (10) \[L_{t}^{c}=-^{2}_{c=1}_{t}^{c}(_{t }^{c})+(1-_{t}^{c})(1-_{t}^{c}).\]

By re-introducing a part of the noisy kinematics measurements into the prediction, an additional regularization loss \(L_{t}^{}\) is beneficial to ensure smoothness and plausibility of the output motions. The regularization consists of three objectives: 1) \(L_{t}^{acc}\) is the acceleration loss, computed as the absolute difference between \(}_{t}\) and \(}_{t-1}\), 2) \(L_{t}^{vel}\) is the velocity loss, measuring the distance between the first-order difference of ground-truth motion \(_{t+1}^{GT}\) and of estimated optimal \(_{t+1}\), and 3) The friction loss \(L_{t}^{fric}\) encourages the feet to stay in the same position during ground contact. With the regulator weighting of \(_{6}=0.14,_{7}=0.03,_{8}=0.28\), \(L_{t}^{}\) is expressed as

\[L_{t}^{}=_{6}L_{t}^{acc}+_{7}L_{t}^{vel}+ _{8}L_{t}^{fric}\] \[=_{6}^{6+3N}}_{t}-}_{t-1}+_{7}^{6+3N}_{t+1}^{ GT}-_{t}^{GT}-(_{t+1}-_{t})+ _{8}^{2}_{c=1}_{t}^{c}(_{t+1}^{c}-_{t}^{c}).\] (11)

## 4 Experiments

### Datasets

We evaluate our approach on two human motion benchmark datasets. The first and main dataset is the popular Human3.6M dataset . The dataset contains indoor 3D human motion capture data, including 2D and 3D keypoints, skeleton joint angles, and videos. Seven actors perform 15 different actions. Following previous work [38; 21], the first five subjects (S1, S5, S6, S7, S8) are used for training, and the last two (S9, S11) for evaluation. According to , only actions that have foot-ground contacts were considered. Details about the selected sequences are found in the supplemental document C.

The second database is Fit3D . Fit3D contains indoor motion capture data for a variety of exercises. We split the data by taking samples from the 6 actors (s03, s04, s05, s07, s08, s10) for training, and 2 actors (s09, s11) for evaluation, inspired by the setup from  on Human3.6M.

Since the scene setting from Human3.6M and Fit3D are very similar, we perform an additional evaluation on the new dataset SportsPose , which consists of video-based sport action sequences with corresponding ground truth 3D keypoints. We use this dataset to show out-of-domain performance, since the 3D kinematics estimator TRACE  has not been trained on it.

### Implementation Setups

The initial motion observation is generated by TRACE . As suggested by [38; 8], all extracted motions are down-sampled from 100Hz to 50Hz. The samples are aligned to the world origin in the first frame, then split into 100-frame sub-sequences to utilize batch training and evaluation. The proxy character is created with respect to the provided skeleton metadata in Human3.6M , including the mean bone lengths and joint angles configuration. The inertia matrix and bias force (including gravitational, Coriolis, and centrifugal forces) are calculated online using RBDL , based on the state of the proxy character.

We train _OSDNet_ in an end-to-end procedure. _OSDNet_ consists of three fully-connected layers, followed by six different heads for PD gains (\(_{P}\), \(_{D}\)), inertia bias (\(^{b}\)), contact probability (\(^{}\)), linear external force from the ground (\(\)), and Jacobian matrix (\(\)). These six entries are responsible for the motion simulation phase, following Eq. 1 and 6. The GRU units in the proposed optimal-state prediction module (cf. Fig. 2) take current system states, additional dynamics features (Eq. 4), and its hidden state \(_{}\) as inputs. The output is the Kalman gain-matrix for the Kalman update process. For a details descriptions of the _OSDNet_'s architecture, please refer to the supplementary document A.

_OSDNet_ is trained for 15 epochs with a base learning rate of \(5e^{-4}\) and a batch size of 64. The learning rates from all training processes are scheduled to reduce by a factor of 10 at epochs 10 and 13. LeakyReLU and Layernorm are used as the activation function and normalization for each linear layer of every module. We also apply a training warm-up strategy on the first 5 epochs by increasing the learning rate by factor of 2 to the base learning rate at epoch 5. This helps reducing the impact of unstable physics simulation at the beginning of training, mitigating gradient explosion.

### Metrics

There are two standard protocols for the evaluation on Human3.6M . Both of these protocols assess the _Mean Per Joint Position Error_ (MPJPE). This metric represents the average Euclidean distance between the reconstructed joint coordinates and the provided ground truth 3D keypoints. While the first protocol directly calculates the MPJPE for root-aligned poses, the second protocol initially employs a rigid alignment between the poses which is called MPJPE-PA (MPJPE Procrustes Aligned). Since our approach estimates poses in a global coordinate system, we additionally calculate the MPJPE-G in global coordinates which is the MPJPE without frame-wise root alignment. In addition to the different variations of the MPJPE, the _Percentage of Correct Keypoints_ (PCK) measures the percentage of predicted joints that are within a distance of \(150mm\) or less from their corresponding ground truth joint. Unlike the PCK, the CPS measurement  determines a pose as correct only if all its joints are estimated correctly according to a threshold value, similar to the PCK. To ensure independence from a specific threshold value, the CPS computes the area under the curve within the \(1\)mm to \(300\)mm threshold range. To evaluate the global translation error, not accounting for the differences between poses, we report the global root position (GRP) error, which calculates the Euclidean distance between only the root joints. We also use the acceleration (Accel) metric from  to measure the jitter of the output motions. Accel is computed as the second-order difference between 3D keypoints across all sequence frames.

### Comparison with State of the Art

We report the quantitative results of _OSDCap_ and other related work on different metrics in Tab. 1. Due to the novelty of dynamics-based motion capture the evaluation protocols differ significantly across different approaches. Here, we make an effort of consistently structuring approaches with similar evaluation protocols to achieve a fair comparison. To be as comparable as possible we follow the most used protocol introduced by Shimada et al. . We outperform all online approaches in MPJPE, PCK and CPS. For the global error MPJPE-G, we improve upon state of the art by a large margin. Notably, DnD  achieves a lower MPJPE-PA. However, DnD's estimation depends on encoding the full action sequence, extracted from temporal convolutions, assuming significantly more knowledge which is not suitable for an online setting. Moreover, AMASS  is used as an additional training data source, thereby, not following the standard protocols for Human3.6M. SimPoE  achieves best smoothness performance on the Accel metric, due to being constrained by a high-frequency physics engine. However, as the discussion in Sec. 1, only relying on modeling the physics can lead to sub-optimal human pose quality. IPMAN-R  also shows good performance in terms of MPJPE-PA. However, it is a single-image approach that contains physically inspired constraints such as ground penetration, but no dynamics. The MPJPE-PA, i.e. the MPJPE afterpose-wise rigid alignment, is reported for completeness. While being a reasonable metric for single-image pose estimation, we argue that for physics-based pose estimation, rigid alignments distort the interpretation of the results since they remove all information about global rotation.

We additionally evaluate _OSDCap_ on the more challenging motions in the Fit3D dataset . Tab. 2 shows the results. Since Fit3D is recorded in the same setting as Human3.6M, we additionally evaluate on the newer SportsPose  dataset to show the generalizability to other motion domains. We improve on the kinematics baseline TRACE by a large margin, especially for global metrics as shown by the MPJPE-G and GRP. Fig. 3 illustrates the benefits of _OSDCap_. _OSDCap_ significantly reduces the impact of noisy and inaccurate kinematics input when encountering high depth-uncertainty from monocular views, while retaining the correct estimation with respect to the ground truth. The bars on the left represent the predicted Kalman gains, where the y-direction is the direction of the optical axis which indicates a predicted low trust in the kinematics prediction and leads the Kalman filter to prefer the physics simulation. Fig. 2(b) shows an example (side view) of _OSDCap_ adjusting unnatural leaning into a physically plausible pose by our physics simulation.

### Ablation study

#### 4.5.1 Optimal-State Estimation

We conduct an ablation study to verify the impact of the optimal-state estimation process on simulated motions. We sample a subset of data consisting of only the first action class of all subjects in the camera view \(60457274\) from Human3.6M . S9 and S11 are for evaluation, and the rest for training. This setup creates a suitable challenge to test the proposed method, limiting the types of motion that are seen during training. Tab. 3 shows the original simulated result from straight-foward smoothing methods, PD controller and the improvement by _OSDCap_.

    &  & MPJPE \(\) & MPJPE-G \(\) & MPJPE-PA \(\) & PCK \(\) & CPS \(\) & GRP \(\) & Accel \(\) \\  & & [mm] & [mm] & [mm] & [\%] & [mm] & [mm] & [mm] & \(mm/s^{2}\) \\  Vnet  & ✘ & ✔ & 89.6 & - & 62.7 & 85.1 & - & 185.1 & - \\ HMMR  & ✔ & 79.4 & - & 55.0 & 88.4 & - & 231.1 & - \\ HMR  & ✔ & 78.9 & - & 54.3 & 88.2 & - & 204.2 & - \\ TRACE  & ✘ & 78.1 & 152.7 & 62.5 & 88.3 & 169.1 & 125.9 & 19.2 \\ VIBE  & ✔ & 68.6 & 207.7 & 43.6 & - & - & - & 23.4 \\  Garter et al.  & ✔ & ✘ & 84.0 & 143.0 & 56.0 & - & - & - & - \\ DuPlpy  & ✔ & ✘ & 81.7 & 139.1 & 55.6 & - & - & - & - \\ PhysPT  & ✔ & ✘ & 52.7 & - & 36.7 & - & - & - & - \\ “DnD  & ✔ & ✘ & **52.5** & - & **35.5** & - & - & - & - \\  PhysCap  & ✔ & ✔ & 97.4 & - & 65.1 & 82.3 & - & 182.6 & - \\ Neuffus  & ✔ & 76.5 & - & 58.2 & 89.5 & - & - & - \\ Xie et al.  & ✔ & ✔ & 68.1 & - & - & - & **85.1** & - \\ IPMAN-R  & ✔ & ✔ & 60.7 & - & 41.1 & - & - & - & - \\ SimPoe  & ✔ & 56.7 & - & 41.6 & - & - & - & **6.7** \\  OSDCap & ✔ & ✔ & 54.8\(\)0.1 & **132.8\(\)**1.6 & 39.8\(\)0.1 & **95.5\(\)**0.1 & **197.7\(\)**0.1 & 119.1\(\)1.8 & 8.4\(\)0.2 \\   

Table 1: Quantitative comparison on the Human3.6M dataset . Related methods are separated into two main categories: kinematics (top) and physics-based (bottom). In addition only  retains the online prediction ability of the video-based kinematics estimations. Bold numbers denote the best evaluation score on each metric. Our approach achieves state-of-the-art in MPJPE and PCK among online approaches, and competitive results on GRP and Accel. Note that *DnD  does not follow standard evaluation protocols by using additional training data.

    &  & MPJPE \(\) & MPJPE-G \(\) & MPJPE-PA \(\) & PCK \(\) & CPS \(\) & GRP \(\) & Accel \(\) \\  & & [mm] & [mm] & [mm] & [\%] & [mm] & [mm] & [\(mm/s^{2}\)] \\   & TRACE  & 85.4 & 131.2 & 65.2 & 85.5 & 166.6 & 178.1 & 20.2 \\  & OSDCap & **58.7** & **73.8** & **42.6** & **96.7** & **209.4** & **47.2** & **8.2** \\   & TRACE  & 97.3 & 361.9 & 71.1 & 60.1 & 168.1 & 333.0 & 15.8 \\  & OSDCap & **71.7** & **113.6** & **52.4** & **68.8** & **190.0** & **90.2** & **10.9** \\   

Table 2: Evaluation results on Fit3D  and SportsPose . _OSDCap_ improves the kinematics baseline TRACE by a large margin across all metrics. We fine-tune _OSDCap_ (pretrained on Human3.6M) on SportsPose’s ground truth keypoints for additional 15 epochs. Even with very noisy inputs from SportsPose, _OSDCap_ still manage to retain the robust estimation thanks to the Kalman filtering process, especially on global translation metrics (MPJPE-G and GRP).

Naive approaches for smoothing the noisy input estimation apply temporal filters such as median or Gaussian filter. However, simply filtering the signal does not help the motion to become physically plausible, unnatural poses still prevail. As shown in Tab. 3, naive filtering reduces the jitter of the input motions (reduction in Accel measurements), but does not help with any other metrics.

To ensure the plausible physics constraints of the forward dynamics process (unlike ), we employ external forces into the calculation, which leads to a much more challenging scenario for the PD controller. This can be observed in Tab. 3 where the PD controller struggles to reconstruct the motions, even with temporal filtering on the input signals and increase the number of parameters. By using our optimal-state estimation module, the PD controller has a significantly better performance, leading to the optimal results for online human motion reconstruction.

#### 4.5.2 Comparison to classical Kalman Filter

The biggest challenge of using classical Kalman filter for _OSDCap_ is the tuning of unknown noise covariances of both the kinematic input TRACE  and the simulated result from PD controller. Our choice of a learnable Kalman filter  relieves us from trial-and-error process of finding the correct noise covariance matrices and achieves the best results. We conducted an additional experiment where we replace our learnable filter by a traditional one, the results are shown in Tab. 4.

Assuming noise covariances that are constant over time and equal in all directions, the ratio between the noise covariance of the simulated PD controller (process noise) and the noise covariance of the kinematic input TRACE (measurement noise) governs the quality of the Kalman filter estimates. The evaluation results can be seen in Tab. 4, where we use constant noise covariances with ratios \(100/1,10/1,1/1,1/10,1/100\) between process noise and measurement noise. While a classical Kalman filter approach increases the result marginally, optimal results are difficult to find.

   & \#params. & MP/P\(\) & MP/P\(\) & MP/P\(\) & PCK \(\) & GRP \(\) & Accel \(\) \\  & \([mm]\) & \([mm]\) & \([mm]\) & \([\%]\) & \([mm]\) & \([mm/s^{2}]\) & \\  TRACE  & - & 78.4 & 153.9 & 62.7 & 88.1 & 128.2 & 19.7 \\ TRACE (median) & - & 78.2 & 153.1 & 62.6 & 88.2 & 127.4 & 13.6 \\ TRACE (Gaussian) & - & 77.8 & 162.4 & 62.4 & 88.5 & 126.7 & 6.5 \\ PD (only) & 8.4M & 87.7 & 145.0 & 67.7 & 82.7 & 105.9 & 6.4 \\ PD (Gaussian) & 8.4M & 77.7 & 136.0 & 61.0 & 86.5 & 103.2 & **5.2** \\  OSDCap (no bias) & 6.6M & 55.0 & 111.9 & 40.0 & 95.7 & 94.9 & 9.5 \\ OSDCap & 7.2M & **54.0** & **111.0** & **40.0** & **95.9** & **94.8** & 8.7 \\  

Table 3: Ablation study on the impact of _OSDNet_ on a subset of Human 3.6M . Naive methods such as median or Gaussian smoothing cannot help with the plausibility of the pose. Without our Kalman filtering process, the PD controller cannot train and estimate the correct dynamics. We also study the effects of the inertia-bias \(^{b}\) and some performance gains has been recorded.

Figure 3: Qualitative results of _OSDCap_ (cyan) compared to the kinematics input  (purple), with corresponding ground truth pose (red). Left: Filtering results of _OSDCap_ on a sample from SportsPose , where the kinematics estimation is very inaccurate along the camera’s depth dimension. The Kalman gain at the y-axis (optical axis) is greatly decreased due to the incorrect translation of the kinematics input. Therefore, the simulated state is preferred. Right: Example from Fit3D , with an unnaturally leaning pose caused by depth ambiguities. Unlike Fig. 2(a), the three poses are manually separated apart for better visualization. _OSDCap_ recovers the physically plausible upright pose.

#### 4.5.3 Additional physics-based metrics

We provide additional metrics for physic-based measurements introduced in Sec. 3.3. The results can be seen in Tab. 5. _OSDCap_ helps refining the input kinematics on most of the physics-based metrics. Note that TRACE outperforms our approach in the ground penetration metric. The reason is that in most cases the TRACE predictions float above the ground, which gives a low penetration error but can be seen as equally bad. Thus, we additionally provide a ground distance metric (GD) to reflect the correct foot-ground quality during contact. The value is computed as the mean absolute vertical differences between foot contact points and ground plane during contact duration, expressed as

\[_{c=1}^{6}_{c}|p_{c}^{OSD}-p_{c}^{GT}|,\] (12)

where \(_{c}\) is the predicted binary label of contact, \(p_{c}^{OSD}\) and \(p_{c}^{GT}\) are the 3D vertical positions of contact. There are a total of six contact points considered, three contacts in each foot accounting for heel, foot and toe. The joint configuration follow Human 3.6M skeleton , with bone length between joints optimized during training and fixed during inference.

## 5 Conclusion

This paper presents _OSDCap_, a new physics-based approach to reconstruct kinematics-based human motion captured from monocular videos. We found that previous approaches relying only on a physical simulation produce non-optimal motions due to unavoidable imperfections in the physical model and noisy measurements. This led us to introduce a learnable Kalman filtering for refining implausible motions simulated by a PD controller with noisy kinematic evidence as the target. In comparison with related research on physics-based motion capture, the proposed approach achieves state-of-the-art results on the Human3.6M, Fit3D, and SportPose datasets, especially on the global estimation of pose trajectories.

**Limitations and future work.** While taking a step into highly accurate predictions of the full body dynamics, our physical external forces are still not comparable to directly measuring with mechanical force plates. However, our approach only requires a single camera, e.g. from a smartphone, instead of a motion capture studio or other expensive hardware, such as force plates, to estimate meaningful forces. In the future, detailed modeling for the hands, feet, and body shape, will be investigated, targeting more realistic motion reconstruction.

 Method & MPJPE \(\) & MPJPE-G \(\) & MPJPE-PA \(\) & PCK \(\) & GRP \(\) & Accel \(\) \\  & [mm] & [mm] & [mm] & [\%] & [mm] & [\(mm/s^{2}\)] \\  TRACE & 78.4 & 153.9 & 62.7 & 88.1 & 128.2 & 19.7 \\ cKF\_kin\_only & 78.3 & 153.0 & 63.0 & 87.9 & 127.4 & 7.8 \\ cKF\_100/1 & 60.9 & 120.7 & 43.4 & 94.3 & 102.0 & 7.7 \\ cKF\_10/1 & 61.5 & 122.6 & 43.7 & 94.4 & 103.0 & 9.1 \\ cKF\_1/1 & 59.9 & 117.6 & 43.2 & 94.8 & 100.1 & **6.5** \\ cKF\_1/10 & 63.6 & 124.0 & 44.3 & 93.8 & 102.7 & 11.5 \\ cKF\_1/100 & 65.3 & 132.3 & 44.0 & 93.5 & 110.2 & 9.7 \\  OSDCap & **54.0** & **111.0** & **40.0** & **95.9** & **94.8** & 8.7 \\ 

Table 4: Ablation study on the performance of the classical Kalman filtering (cKF) on the ablation set from the Human 3.6m dataset. Due to unknown noise covariance matrices, we tested with constant noise covariances with ratios \(100/1,10/1,1/1,1/10,1/100\). The performance of applying Kalman filtering on only the kinematics input TRACE  (cKF_kin_only) is also conducted.

 Method &  GP \(\) \\ [mm] \\  &  GD \(\) \\ [mm] \\  &  Friction \(\) \\ [mm] \\  &  Velocity \(\) \\ [mm/s] \\  & 
 Foot-skating \(\) \\ [\%] \\  \\  TRACE & **2.6** & 12.5 & 31.5 & 22.4 & 37.0 \\ OSDCap & 5.3 & **8.2** & **14.6** & **12.8** & **15.2** \\ 

Table 5: Additional physics-based measurements for kinematics input TRACE and _OSDCap_. Because the ground penetration (GP) metric does not correctly reflect the foot-ground contact quality, i.e. floating above the ground is ignored and produces no error, we propose using an additional ground-distance (GD) metric. For foot-skating, we followed DiffPhy to compute the percentage of frames that contain skating artifacts over the whole sequence.