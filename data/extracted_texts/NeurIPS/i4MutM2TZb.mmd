# Pre-trained Large Language Models Use

Fourier Features to Compute Addition

 Tianyi Zhou  Deqing Fu  Vatsal Sharan  Robin Jia

Department of Computer Science

University of Southern California

Los Angeles, CA 90089

{tzhou029,deqingfu,vsharan,robinjia}@usc.edu

###### Abstract

Pre-trained large language models (LLMs) exhibit impressive mathematical reasoning capabilities, yet how they compute basic arithmetic, such as addition, remains unclear. This paper shows that pre-trained LLMs add numbers using Fourier features--dimensions in the hidden state that represent numbers via a set of features sparse in the frequency domain. Within the model, MLP and attention layers use Fourier features in complementary ways: MLP layers primarily approximate the magnitude of the answer using low-frequency features, while attention layers primarily perform modular addition (e.g., computing whether the answer is even or odd) using high-frequency features. Pre-training is crucial for this mechanism: models trained from scratch to add numbers only exploit low-frequency features, leading to lower accuracy. Introducing pre-trained token embeddings to a randomly initialized model rescues its performance. Overall, our analysis demonstrates that appropriate pre-trained representations (e.g., Fourier features) can unlock the ability of Transformers to learn precise mechanisms for algorithmic tasks.

## 1 Introduction

Mathematical problem solving has become a crucial task for evaluating the reasoning capabilities of large language models (LLMs) . While LLMs exhibit impressive mathematical abilities , it remains unclear how they perform even basic mathematical tasks. Do LLMs apply mathematical principles when solving math problems, or do they merely reproduce memorized patterns from the training data?

In this work, we unravel how pre-trained language models solve simple mathematical problems such as "Put together \(15\) and \(93\). Answer: _--_". Prior work has studied how Transformers, the underlying architecture of LLMs, perform certain mathematical tasks. Most studies  focus on Transformers with a limited number of layers or those trained from scratch;  analyzes how the pre-trained GPT-2-small performs the greater-than task. Our work focuses on a different task from prior interpretability work--integer addition--and shows that pre-trained LLMs learn distinct mechanisms from randomly initialized Transformers.

In SS3, we show that pre-trained language models compute addition with Fourier features--dimensions in the hidden state that represent numbers via a set of features sparse in the frequency domain. First, we analyze the behavior of pre-trained LLMs on the addition task after fine-tuning, which leads to almost perfect accuracy on the task. Rather than merely memorizing answers from the training data, the models progressively compute the final answer layer by layer. Next, we analyze the contributions of individual model components using Logit Lens . We observe that some components primarily _approximate_ the answer--they promote all numbers close to the correct answer in magnitude--while other components primarily _classify_ the answer modulo \(m\) for various numbers \(m\). Then,we use Fourier analysis to isolate features in the residual stream responsible for the low-frequency "approximation" and high-frequency "classification" subtasks. Identifying these features allows us to precisely ablate the ability of the model to perform either approximation or classification by applying a low-pass or high-pass filter, respectively, to the outputs of different model components. We find that MLP layers contribute primarily to approximation, whereas attention layers contribute primarily to classification.

In SS4, we show that _pre-training_ is crucial for learning this mechanism. The same network trained from scratch with random initialization not only shows no signs of Fourier features, but also has lower accuracy. We identify pre-trained token embeddings as a key source of inductive bias that help the pre-trained model learn a more precise mechanism for addition. Across the pre-trained token embeddings of many different pre-trained models, Fourier analysis uncovers large magnitudes of components with periods \(2\), \(5\), and \(10\). Introducing pre-trained token embeddings when training the model from scratch enables the model to achieve perfect test accuracy. Finally, we show that the same Fourier feature mechanism is present not only in models that were pre-trained and then fine-tuned, but also in frozen pre-trained LLMs when prompted with arithmetic problems.

Overall, our work provides a mechanistic perspective on how pre-trained LLMs compute addition through the lens of Fourier analysis. It not only broadens the scope from only investigating few-layer Transformers trained to fit a particular data distribution to understanding LLMs as a whole, but also hints at how pre-training can lead to more precise model capabilities.

## 2 Problem Setup

**Task and Dataset.** We constructed a synthetic addition dataset for fine-tuning and evaluation purposes. Each example involves adding two numbers \( 260\), chosen because the maximum number that can be represented by a single token in the GPT-2-XL tokenizer is \(520\). For each pair of numbers between \(0\) and \(260\), we randomly sample one of five natural language question templates and combine it with the two numbers. The dataset is shuffled and then split into training (\(80\%\)), validation (\(10\%\)), and test (\(10\%\)) sets. More details are provided in Appendix F. In Appendix C.3, we show our that results generalize to a different dataset formatted with reverse Polish notation.

**Model.** Unless otherwise stated, all experiments focus on the pre-trained GPT-2-XL model that has been fine-tuned on our addition dataset. This model, which consists of \(48\) layers and approximately \(1.5\) billion parameters, learns the task almost perfectly, with an accuracy of \(99.74\%\) on the held-out test set. We examine other models in SS4.2 and SS4.3.

**Transformers.** We focus on decoder-only Transformer models , which process text sequentially, token by token, from left to right. Each layer \(\) in the Transformer has an attention module with output \(^{()}\) and an MLP module with output \(^{()}\). Their outputs are added together to create a continuous residual stream \(h\), meaning that the token representation accumulates all additive updates within the residual stream, with the representation \(h^{()}\) in the \(\)-th layer given by:

\[h^{()}=h^{(-1)}+^{()}+^{()}.\] (1)

The output embedding \(W^{U}\) projects the residual stream to the space of the vocabulary; applying the softmax function then yields the model's prediction. We provide formal definitions in Appendix A.

## 3 Language Models Solve Addition with Fourier Features

In this section, we analyze the internal mechanisms of LLMs when solving addition tasks, employing a Fourier analysis framework. We first show that the model initially approximates the solution before iteratively converging to the correct answer (SS3.1). We then show that the model refines its initial approximation by computing the exact answer modulo \(2\), \(5\), and \(10\), employing Fourier components of those same periods (SS3.2). Finally, we demonstrate through targeted ablations that the identified Fourier components are causally important for the model's computational processes (SS3.3). Specifically, we show that MLP layers primarily approximate the magnitude of the answer, using low-frequency features, while attention layers primarily perform modular addition using high-frequency components.

### Behavioral Analysis

Our first goal is to understand whether the model merely memorizes and recombines pieces of information learned during training, or it performs calculations to add two numbers.

**Extracting intermediate predictions.** To elucidate how LLMs perform computations and progressively refine their outputs towards the correct answer, we extract model predictions at each layer from the residual stream. Let \(L\) denote the number of layers. Using the Logit Lens method , instead of generating predictions by computing logits \(W^{U}h^{(L)}\), predictions are derived through \(W^{U}h^{()}\) where \([L]\). We compute the accuracy of the prediction using each intermediate state \(h^{()}\). If the models merely retrieve and recombine pieces of information learned during training, certain layers will directly map this information to predictions. For instance,  demonstrates that there is a specific MLP module directly maps a country to its capital.

**LLMs progressively compute the final answers.** Figure 0(a) instead shows that the model progressively approaches the correct answer, layer by layer. The model is capable of making predictions that fall within the range of \( 2\) and \( 10\) relative to the correct answer in the earlier layers, compared to the exact-match accuracy. This observation implies that the Transformer's layer-wise processing structure is beneficial for gradually refining predictions through a series of transformations and updates applied to the token representations.

### Fourier Features in MLP & Attention Outputs

**Logits for MLP and attention have _periodic_ structures.** We now analyze how each MLP and attention module contributes to the final prediction. We transform the output of the attention and MLP output at layer \(\) into the token space using \(W^{U}^{()}\) and \(W^{U}^{()}\) at each layer, thereby obtaining the logits \(\) for each MLP and attention module. We use the running example "Put together \(15\) and \(93\). Answer: \(108\)" to demonstrate how the fine-tuned GPT-2-XL performs the computation. As illustrated in Figure 0(b) and Figure 0(c), both the MLP and attention modules exhibit a periodic pattern in their logits across the output number space, e.g., the MLP in layer \(33\), outlined in green, promotes all numbers that are congruent to \(108\) mod \(2\) (in Figure 1(d) in the appendix, we zoom into such layers to make this clearer). Overall, we observe two distinct types of computation within these components. Some components predominantly assign a high weight to numbers around the correct answer, which we term _approximation_. Meanwhile, other components predominantly assign a high weight to all numbers congruent to \(a+b\) mod \(c\) for some constant \(c\), which we term _classification_.

**Logits for MLP and attention are approximately sparse in the Fourier space.** It is natural to transform the logits into Fourier space to gain a better understanding of their properties such as the periodic pattern. We apply the discrete Fourier transform to represent the logits as the sum of

Figure 1: (a) Visualization of predictions extracted from fine-tuned GPT-2-XL at intermediate layers. Between layers 20 and 30, the model’s accuracy is low, but its prediction is often within 10 of the correct answer: the model first approximates the answer, then refines it. (b) Heatmap of the logits from different MLP layers for the running example, “Put together 15 and 93. Answer: 108”. The \(y\)-axis represents the subset of the number space around the correct prediction, while the \(x\)-axis represents the layer index. The \(33\)-rd layer performs mod \(2\) operations (favoring even numbers), while other layers perform other modular addition operations, such as mod \(10\) (\(45\)-th layer). Additionally, most layers allocate more weight to numbers closer to the correct answer, \(108\). (c) Analogous plot for attention layers. Nearly all attention modules perform modular addition.

sine and cosine waves of different periods: the \(k\)-th component in Fourier space has period \(520/k\) and frequency \(k/520\) (see Appendix A for more details). Let \(}\) denote the logits in Fourier space. Figure 2 shows the Fourier space logits for two layers from Figure 0(b) and Figure 0(c) that have a clear periodic pattern. We find that the high-frequency components in Fourier space, which we define as components with index greater or equal to \(50\), are approximately sparse as depicted in Figure 2. This observation aligns with , which found that a one-layer Transformer utilizes particular Fourier components within the Fourier space to solve the modular addition task.

In Figure 3, we show that similar sparsity patterns in Fourier space hold across the entire dataset. We compute the logits in Fourier space for the last \(15\) layers, i.e., \(}^{()}_{}\) and \(}^{()}_{}\) where \(\), for all test examples and average them. We annotate the top-\(10\) outlier high-frequency components based on their magnitude. The MLPs also exhibit some strong low-frequency components; the attention modules do not exhibit strong low-frequency components, only high-frequency components.

**Final logits are superpositions of these outlier Fourier components.** The final logits, \(^{(L)}\), are the sum of all \(^{(l)}_{}\) and \(^{(l)}_{}\) across all layers \(l[L]\). Figure 4 elucidates how these distinct Fourier components contribute to the final prediction, for the example "Put together \(15\) and \(93\). Answer: \(108\)".

Figure 3: Analysis of logits in Fourier space for all the test data across the last \(15\) layers. For both the MLP and attention modules, outlier Fourier components have periods around \(2\), \(2.5\), \(5\), and \(10\).

Figure 2: The intermediate logits in Fourier space. We annotate the top-\(10\) outlier high-frequency Fourier components based on their magnitudes. \(T\) stands for the period of that Fourier component. (a) The logits in Fourier space for the MLP output of the \(33\)-rd layer, i.e., \(}^{(33)}_{}\). The component with period \(2\) has the largest magnitude, aligning with the observations in Figures 0(b) and 1(a). (b) The logits in Fourier space for the attention output of the \(40\)-th layer, i.e., \(}^{(40)}_{}\). The components with periods \(5\) and \(10\) have the largest magnitude, aligning with the observations in Figures 0(c) and 1(b).

We select the top-\(5\) Fourier components of \(}^{(L)}\) based on their magnitudes and transfer them back to logits in number space via the inverse discrete Fourier transform (Figure 3(a)). The large-period (low-frequency) components approximate the magnitude while the small-period (high-frequency) components are crucial for modular addition. Figure 3(b) shows that aggregating these \(5\) waves is sufficient to predict the correct answer.

**Why is high-frequency classification helpful?** The Fourier basis comprises both \(\) and \(\) waves (see Definition A.3). By adjusting the coefficients of \(\) and \(\), the trained model can manipulate the phase of the logits in Fourier space (number shift in number space), aligning the peak of the wave more closely with the correct answer. As shown in Figure 3(a), consider a wave with a period of \(2\). Here, the peak occurs at every even number in the number space, corresponding to the \( 2\) task. In contrast, for components with a large period such as \(520\), the model struggles to accurately position the peak at \(108\) (also see Figure 14 in the appendix for the plot of this component with period \(520\) in the full number space). This scenario can be interpreted as solving a "\(\) 520" task--a classification task among \(520\) classes--which is challenging for the model to learn accurately. Nevertheless, even though the component with a period of \(520\) does not solve the "\(\) 520" task precisely, it does succeed in assigning more weight to numbers near \(108\). The classification results from the high-frequency components can then provide finer-grained resolution to distinguish between all the numbers around \(108\) assigned a large weight by the lower frequencies. Due to this, the low-frequency components need not be perfectly aligned with the answer to make accurate predictions.

### Fourier Features are Causally Important for Model Predictions

In the previous section, we demonstrated that there are outlier Fourier components in the logits generated by both the MLP and attention modules, as shown in Figure 3. We also illustrated that, in one example, the low-frequency components primarily approximate the magnitude, while the high-frequency components are crucial for modular addition tasks, as depicted in Figure 4. In this section, through an ablation study conducted across the entire test dataset, we show that both types of components are essential for correctly computing sums. Moreover, we reveal that the MLP layers primarily approximate the magnitude of the answer using low-frequency features, whereas the attention layers are responsible for modular addition using high-frequency features.

**Filtering out Fourier components.** To understand the role various frequency components play for the addition task, we introduce low-pass and high-pass filters \(\). For an intermediate state \(h\), and a set of frequencies \(=\{_{1},,_{k}\}\), the filter \((h;)\) returns the vector \(\) that is closest in \(L_{2}\) distance to \(h\) subject to the constraint that the Fourier decomposition of \(W^{U}\) at every frequency \(_{i}\) is \(0\). We show in Appendix A that this has a simple closed-form solution involving a linear projection. We then apply either a low-pass filter by taking \(\) to be all the components whose frequencies are greater than the frequency of the \(\)-th component for some threshold \(\) (i.e., removing high-frequency components), and a high-pass filter by taking \(\) to be all the components whose frequencies are less

Figure 4: Visualization of how a sparse subset Fourier components can identify the correct answer. (a) Shows the top-\(5\) Fourier components for the final logits. (b) Shows the sum of these top-\(5\) Fourier components, highlighting how the cumulative effect identifies the correct answer, \(108\).

than the frequency of the \(\)-th component (i.e., removing low-frequency components). As in the previous subsection, we take the high-frequency threshold \(=50\) for the following experiments (see Appendix B for more details).

Different roles of frequency components in approximation and classification tasks.We evaluated the fine-tuned GPT-2-XL model on the test dataset with different frequency filters applied to all of the output of MLP and attention modules. The results, presented in Table 1, indicate that removing low-frequency components from attention modules or high-frequency components from MLP modules does not impact performance. This observation suggests that attention modules are not crucial for approximation tasks, and MLP modules are less significant for classification tasks.

Eliminating high-frequency components from attention results in a noticeable decrease in accuracy. Furthermore, removing high-frequency components from both the attention and MLP modules simultaneously leads to an even greater reduction in accuracy. This finding corresponds with observations from Figure 0(b),c and Figure 3, which indicate that both MLP and attention modules are involved in classification tasks due to the presence of high-frequency components in the logits. As shown in Table 1, the approximation tasks are primarily performed by the MLP modules, with contributions from the attention modules as well.

The errors induced by these ablations align with our mechanistic understanding. Ablating low-frequency parts of MLPs leads to off-by \(10\), \(50\), and \(100\) errors: the model fails to perform the approximation subtask, though it still accurately predicts the unit digit. Conversely, ablating high-frequency parts of attention leads to small errors less than \(6\) in magnitude: the model struggles to accurately predict the units digit, but it can still estimate the overall magnitude of the answer. See Figure 21 in the Appendix for more details. These observations validate our hypothesis that low-frequency components are crucial for approximation, while high-frequency components are vital for classification. The primary function of MLP modules is to approximate the magnitude of outcomes using low-frequency components, while the primary role of attention modules is to ensure accurate classification by determining the correct unit digit.

## 4 Effects of Pre-training

The previous section shows that pre-trained LLMs leverage Fourier features to solve the addition problem. Now, we study where the models' reliance on Fourier features comes from. In this section, we demonstrate that LLMs learn Fourier features in the token embeddings for numbers during pre-training. These token embeddings are important for achieving high accuracy on the addition task: models trained from scratch achieve lower accuracy, but adding just the pre-trained token embeddings fixes this problem. We also show that pre-trained models leverage Fourier features not only when fine-tuned, but also when prompted.

### Fourier features in Token Embedding

Number embedding exhibits approximate sparsity in the Fourier space.Let \(W^{E}^{p D}\), where \(p=521\) and \(D\) is the size of the token embeddings, denote the token embedding for numbers. We apply the discrete Fourier transform to each column of \(W^{E}\) to obtain a matrix \(V^{p D}\), where

  
**Module** & **Fourier Component Removed** & **Validation Loss** & **Accuracy** \\  None & Without Filtering & 0.0073 & 0.9974 \\  ATTN \& MLP & Low-Frequency & 4.0842 & 0.0594 \\ ATTN & Low-Frequency & 0.0352 & 0.9912 \\ MLP & Low-Frequency & 2.1399 & 0.3589 \\  ATTN \& MLP & High-Frequency & 1.8598 & 0.2708 \\ ATTN & High-Frequency & 0.5943 & 0.7836 \\ MLP & High-Frequency & 0.1213 & 0.9810 \\   

Table 1: Impact of Filtering out Fourier Components on Model Performance. Removing low-frequency components from attention modules (blue) or high-frequency components from MLP modules (red) does not impact performance each row represents a different Fourier component. Then we take the \(L_{2}\) norm of each row to yield a \(p\)-dimensional vector. Each component \(j\) in this vector measures the overall magnitude of the \(j\)-th Fourier component across all the token embedding dimensions. Figure 4(a) shows the magnitude of different Fourier components in the token embedding of GPT-2-XL. We see that the token embedding has outlier components whose periods are \(2,2.5,5\), and \(10\). Therefore, similar to how the model uses different Fourier components to represent its prediction (as shown in Section 3.2), the token embeddings represent numbers with different Fourier components. Figure 15 in the Appendix shows that the token embeddings of other pre-trained models have similar patterns the Fourier space. This suggests that Fourier features are a common attribute in the token embedding of pre-trained LLMs. In Figure 4(b), we use t-SNE and \(k\)-means to visualize the token embedding clustering. We can see that numbers cluster not only by magnitude but also by their multiples of \(10\).

### Contrasting Pre-trained Models with Models Trained from Scratch

To understand the necessity of Fourier features for the addition problem, we trained the GPT-2-XL model from scratch on the addition task with random initialization. After convergence, it achieved only \(94.44\%\) test accuracy (recall that the fine-tuned GPT-2-XL model achieved \(99.74\%\) accuracy).

Figure 5: (a) Number embedding in Fourier space for fine-tuned GPT-2-XL. \(T\) stands for the period of that Fourier component.(b) Visualization of token embedding clustering of GPT-2 using T-SNE and \(k\)-means with \(10\) clusters. The numbers are clustered based on their magnitude and whether they are multiples of \(10\).

Figure 6: Visualization of the logits in Fourier space on the test dataset from the last \(15\) layers for the GPT-2-XL model _trained from scratch_. For both the MLP and attention modules, there are no outlier Fourier components, in contrast with the clear outlier components in the fine-tuned model (Figure 3).

**Fourier features are learned during pre-training.** Figure 6 shows that there are no Fourier features in the intermediate logits of the GPT-2-XL model trained from scratch on the addition task. Furthermore, Figure 6(a) shows that the token embeddings also have no Fourier features. Without leveraging Fourier features, the model merely approximates the correct answer without performing modular addition, resulting in frequent off-by-one errors between the prediction and the correct answer (see details in Figure 23).

**Pre-trained token embeddings improve model training.** We also trained GPT-2-small, with \(124\) million parameters and \(12\) layers, from scratch on the addition task. GPT-2-small often struggles with mathematical tasks . This model achieved a test accuracy of only \(53.95\%\) after convergence. However, when we freeze the token embedding layer and randomly initialize the weights for all other layers before training on the addition task, the test accuracy increases to \(100\%\), with a significantly faster convergence rate. This outcome was consistently observed across five different random seeds, as illustrated in Figure 6(b). Following Section 3.2, to validate that the model learn to leverage the Fourier feature to solve addition, we analyze the logits in Fourier space for all the test data across all \(12\) layers In Figure 8, we can clearly observe that, with solely the pre-trained number embedding, the Fourier features appear in the MLP and attention modules' output for most layers. This demonstrates that given the number embeddings with Fourier features, the model can effectively learn to leverage these features to solve the addition task.

### Fourier Features in Prompted Pre-Trained Models

Finally, we ask whether larger language models use similar Fourier features during prompting.

**Pre-trained LLMs use Fourier features to compute addition during in-context learning.** We first test on the open-source models GPT-J  with 6B parameters, and Phi-2  with 2.7B parameters on the test dataset. Without in-context learning, the model cannot perform addition tasks. Therefore, we use 4-shot in-context learning to test its performance. Their absolute errors are predominantly multiples of \(10\): 93% of the time for GPT-J, and 73% for Phi-2. Using the Fourier analysis framework proposed in Section 3.2, we demonstrate that for Phi-2 and GPT-J, the outputs of MLP and attention modules exhibit approximate sparsity in Fourier space across the last \(15\) layers (Figure 9 and Figure 19). This evidence strongly suggests that these models leverage Fourier features to compute additions.

**Closed-source models exhibit similar behavior.** We study the closed-source models GPT-3.5 , GPT-4 , and PaLM-2 . While we cannot analyze their internal representations, we can study whether their behavior on addition problems is consistent with reliance on Fourier features. Since closed-source LLMs are instruction tuned and perform well without in-context learning, we conduct error analysis with 0-shot. Most absolute errors by these models are also multiples of \(10\): 100% of the time for GPT-3.5 and GPT-4, and 87% for PaLM-2. The similarity in error distribution to

Figure 7: (a) The number embedding in Fourier space for GPT-2-XL trained from scratch. There are no high-frequency outlier components, in contrast with the pre-trained embeddings (Figure 4(a)). (b) Validation accuracy of GPT-2-small trained from scratch either with or without pre-trained token embeddings. We show the mean and the standard deviation of the validation accuracy across \(5\) random seeds. GPT-2-small with pre-trained token embedding consistently achieves \(100\%\) accuracy, while GPT-2-small without pre-trained token embedding only achieves less than \(60\%\) accuracy.

that of open-source models leads us to hypothesize that Fourier features play a critical role in their computational mechanism.

Figure 8: Analysis of logits in Fourier space for all the test data across the \(12\) layers. **(a,b)** GPT-2-small trained from scratch fail to learn to leverage the Fourier feature to solve addition. **(c,d)** However, with solely the pre-trained number embeddings, GPT-2-small is able to learn to leverage the Fourier features to solve the addition as the fine-tuned models.

Figure 9: For Phi-2 (4-shot), we analyzed the logits in Fourier space for all the test data across the last \(15\) layers. For both the MLP and attention modules, the outlier Fourier components have periods around \(2\), \(2.5\), \(5\), and \(10\), similar to the fine-tuned GPT-2-XL logits (Figure 3).

Related Work

**Learning mathematical tasks.** Previous studies primarily explore what pre-trained LMs can achieve on arithmetic tasks, with less emphasis on the underlying mechanisms [29; 37]. For instance,  demonstrates that small Transformer models can effectively learn arithmetic by altering the question format and utilizing a scratchpad method .  identifies activation patterns for the "greater-than" operation in GPT-2, and  focuses on the enumeration and selection processes in GCD computation. In this paper, we dive into the specific roles of MLP and attention layers in solving mathematical tasks. Our research analyzes these components' distinct contributions to integer addition tasks.

**Mechanisms of pre-trained LMs.** Recent studies have significantly advanced our understanding of the underlying mechanisms of pre-trained Transformer models. For instance, research on "skill neurons" by  and "knowledge neurons" by  underscores the development of specialized neural components that encode task-specific capabilities or hold explicit factual information in the pre-trained LMs, enhancing model performance on related tasks.  and  discuss how MLPs and FFNs transform and update token representations for general language tasks. In contrast, we show that the pre-trained LMs use multiple layers to compute addition by combining the results of approximation and classification. Additionally,  demonstrated the capacity of GPT-2 to consolidate similar information through pre-training in the model weights, which aligns with our observations on the importance of pre-training in developing effective number embedding and arithmetic computation strategies in LMs.

**Fourier features in Neural Networks.** Fourier features are commonly observed in image models, particularly in the early layers of vision models [32; 31; 10]. These features enable the model to detect edges, textures, and other spatial patterns effectively. Recently, Fourier features have been noted in networks trained for tasks that allow cyclic wraparound, such as modular addition [28; 27], general group compositions , or invariance to cyclic translations .  demonstrates that learning Fourier features can induce 'grokking' . Furthermore,  provides a mathematical framework explaining the emergence of Fourier features when the network exhibits invariance to a finite group. We extend these insights by observing Fourier features in tasks that do not involve cyclic wraparound.  found that by selecting problem-specific Fourier features, the performance of MLPs can be improved on a computer vision-related task.

## 6 Conclusion

In this paper, we provide a comprehensive analysis of how pre-trained LLMs compute numerical sums, revealing a nuanced interplay of Fourier features within their architecture. Our findings demonstrate that LLMs do not simply memorize answers from training data but actively compute solutions through a combination of approximation and classification processes encoded in the frequency domain of their hidden states. Specifically, MLP layers contribute to approximating the magnitude of sums, while attention layers contribute to modular operations.

Our work also shows that pre-training plays a critical role in equipping LLMs with the Fourier features necessary for executing arithmetic operations. Models trained from scratch lack these crucial features and achieve lower accuracy; introducing pre-trained token embeddings greatly improves their convergence rate and accuracy. This insight into the arithmetic problem-solving capabilities of LLMs through Fourier features sets the stage for potential modifications to training approaches. By imposing specific constraints on model training, we could further enhance the ability of LLMs to learn and leverage these Fourier features, thereby improving their performance in mathematical tasks.

## 7 Limitations

We note that our contributions are limited by the size of the dataset. As the maximum number that can be represented by one token for GPT-2-XL is \(520\), we analyze on the dataset whose operands are less than \(260\). However, as the Fourier features commonly exist in many different pre-trained models as shown in Section 4, we believe different models still use Fourier features, possibly with a more complicated strategy.