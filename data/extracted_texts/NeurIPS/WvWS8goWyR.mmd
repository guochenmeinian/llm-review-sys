# Fairness-Aware Estimation of Graphical Models

Zhuoping Zhou, Davoud Ataee Tarzanagh, Bojian Hou, Qi Long, Li Shen

University of Pennsylvania

{zhuopinz@sas., tarzanaq@upenn.edu

{bojian.hou, qlong, li.shen}@penmmedicine.upenn.edu

Equal contributionCorresponding authors

###### Abstract

This paper examines the issue of fairness in the estimation of graphical models (GMs), particularly Gaussian, Covariance, and Ising models. These models play a vital role in understanding complex relationships in high-dimensional data. However, standard GMs can result in biased outcomes, especially when the underlying data involves sensitive characteristics or protected groups. To address this, we introduce a comprehensive framework designed to reduce bias in the estimation of GMs related to protected attributes. Our approach involves the integration of the _pairwise graph disparity error_ and a tailored loss function into a _nonsmooth multi-objective optimization_ problem, striving to achieve fairness across different sensitive groups while maintaining the effectiveness of the GMs. Experimental evaluations on synthetic and real-world datasets demonstrate that our framework effectively mitigates bias without undermining GMs' performance.

## 1 Introduction

Graphical models (GMs) are probabilistic models that use graphs to represent dependencies between random variables . They are essential in domains such as gene expression , social networks , computer vision , and recommendation systems . The capacity of GMs to handle complex dependencies makes them crucial across various data-intensive disciplines. Therefore, as our society's reliance on machine learning grows, ensuring the fairness of these models becomes increasingly paramount; see Section 1.1 for further discussions. While significant research has addressed fairness in supervised learning , the domain of unsupervised learning, particularly in the estimation of GMs, remains less explored.

We address the fair estimation of sparse GMs where the number of variables \(P\) is much larger than the number of observations \(N\). We focus on three types of GMs:

1. **Gaussian Graphical Model:** Rows \(_{1:},,_{N:}\) in the data matrix \(^{N P}\) are i.i.d. from a multivariate Gaussian distribution \((,)\). The _conditional independence_ graph is determined by the sparsity of the inverse covariance matrix \(^{-1}\), where \((^{-1})_{jj^{}}=0\) indicates conditional independence between the \(j\)th and \(j^{}\)th variables.
2. **Gaussian Covariance Graph Model:** Rows \(_{1:},,_{N:}\) are i.i.d. from \((,)\). The _marginal independence_ graph is determined by the sparsity of the covariance matrix \(\), where \(_{jj^{}}=0\) indicates marginal independence between the \(j\)th and \(j^{}\)th variables.
3. **Binary Ising Graphical Model:** Rows \(_{1:},,_{N:}\) are binary vectors and i.i.d. with \[p(;)=(Z())^{-1}_{j=1}^ {P}_{jj}x_{j}+_{1 j<j^{} P}_{jj^{}}x_{j} x_{j^{}}.\] (1) Here, \(\) is a symmetric matrix, and \(Z()\) normalizes the density. \(_{jj^{}}=0\) indicates conditional independence between the \(j\)th and \(j^{}\)th variables. The sparsity pattern of \(\) reflects the conditional independence graph.

In a data matrix \(^{N P}\), each column corresponds to a node in a graph \(=(,)\), where \(=\{1,2,,P\}\) are vertices and \(\) are edges. Column \(_{:i}\) (\(i\{1,2,,P\}\)) is a vector of length \(N\), representing the observations for the \(i\)-th variable across all \(N\) samples. The graph \(\), represented by the symmetric matrix \(\), has nonzero entries indicating edges and reflects the graph's independence properties. To obtain a sparse and interpretable graph estimate, we consider

\[}{}(;)+\|\|_{1}\ \ \ \ .\] (2)

Here, \(\) is a loss function; \(\|\|_{1}\) is the \(_{1}\)-norm regularization with parameter \(>0\); and \(\) is a convex constraint subset of \(^{P P}\). For example, in a Gaussian GM, \((;)=-()+()\), where \(=n^{-1}_{i=1}^{n}_{:i}^{}_{:i}\), and \(\) is the set of \(P P\) positive definite matrices.

### Motivation

Our motivations for obtaining a fair GM estimation are summarized as follows. _i) Equitable Representation_: Standard group-specific GM models may improve accuracy for targeted groups but do not ensure fairness and can reinforce biases present in the data . A unified approach considering the entire dataset is essential for mitigating biases and promoting fairness across all groups. _ii) Legal and Ethical Compliance:_ Ethical and legal considerations  require explicit consent for processing sensitive attributes in model selection. Thus, constructing a fair estimation approach that adheres to fairness practices, uses data with consent, and excludes sensitive attribute information during deployment ensures privacy and legal compliance. _iii) Generalization across Groups_: A unified fair GM captures differences across groups without segregating the model, enhancing generalizability and preventing overfitting to a specific group , a risk in training separate models for each group.

For further discussion, we compare a GM with its proposed Fair variant, as illustrated in Figure 1. Panel (a) shows the entire dataset, divided into Group Blue and Group Orange in panels (b) and (c). Panels (d) and (e) detail the GM for each group, highlighting variable relationships. Panel (f) demonstrates a conventional GM applied to the full dataset, revealing a bias towards Group Blue. Panel (g) introduces a Fair GM, including modifications (red dashed lines) to reduce bias and ensure balanced representation. These adjustments correct relationships within the model, promoting fairness by preventing disproportionate favor towards any group. This illustration highlights the bias challenge in GMs and the steps Fair GMs take to ensure fair and equal modeling outcomes across groups.

### Contributions

Our contributions are summarized as follows:

* We propose a framework to mitigate bias in Gaussian, Covariance, and Ising models related to protected attributes. This is achieved by incorporating _pairwise graph disparity error_ and a tailored loss function into a _nonsmooth multi-objective optimization_ problem, striving to achieve fairness across different sensitive groups while preserving GMs performance.
* We develop a proximal gradient method with non-asymptotic convergence guarantees for nonsmooth multi-objective optimization, applicable to Gaussian, Covariance, and Ising models (Theorems 6-8). To our knowledge, this is the first work providing a multi-objective proximal gradient method for GM estimation, in contrast to existing single-objective GM methods .
* We provide extensive experiments to validate the effectiveness of our GM framework in mitigating bias while maintaining model performance on synthetic data, the Credit Dataset,

Figure 1: Illustration of a GM and its fair variant. (a) displays the entire dataset, split into Group Blue (b) and Group Orange (c). (d) and (e) show GMs for each group, detailing the relationships between variables. (f) uses a GM for the entire dataset. The fair model in (g) adjusts these relationships to ensure equitable representation and minimize biases in subgroup analysis.

the Cancer Genome Atlas Dataset, Alzheimer's Disease Neuroimaging Initiative (ADNI), and the binary LFM-1b Dataset for recommender systems3.

## 2 Related Work

**Estimation of Graphical Models.** The estimation of network structures from high-dimensional data [89; 51; 1; 84; 19; 84] is a well-explored domain with significant applications in biomedical and social sciences [44; 59; 25]. Given the challenge of parameter estimation with limited samples, sparsity is imposed via regularization, commonly through an \(_{1}\) penalty to encourage sparse network structures [22; 37; 25]. However, these approaches may overlook the complexity of real-world networks, which often have varying structures across scales, including densely connected subgraphs or communities [13; 26; 23]. Recent work extends beyond simple sparsity to estimate hidden communities within networks, reflecting homogeneity within and heterogeneity between communities . This includes inferring connectivity and performing graph estimation when community information is known, as well as considering these tasks in the context of heterogeneous observations [42; 80; 24].

**Fairness.** Fairness research in machine learning has predominantly focused on supervised methods [11; 4; 15; 39; 92; 79; 28]. Our work broadens this scope to unsupervised learning, incorporating insights from [65; 77; 56; 9; 10]. Notably,  has developed algorithms for fair clustering using the Laplacian matrix. Our approach diverges by not presupposing any graph and Laplacian structures. The most relevant works to this study are [78; 93; 52; 53]. Specifically,  initiated the learning of fair GMs using an \(_{1}\)-regularized pseudo-likelihood method for joint GMs estimation and fair community detection. [93; 94] proposed a fair spectral clustering model that integrates graph construction, fair spectral embedding, and discretization into a single objective function. Unlike these models, which assume community structures, our study formulates fair GMs without such assumption. Concurrently with this work,  proposed a regularization method for fair Gaussian GMs assuming the availability of node attributes. Their methodology significantly differs from ours, as we focus on developing three classes of fair GMs (Gaussian, Covariance, and Ising models) for imbalanced groups _without node attributes_, aiming to _automatically_ ensure fairness through non-smooth multi-objective optimization.

## 3 Fair Estimation of Graphical Models

**Notation.**\(^{d}\) denotes the \(d\)-dimensional real space, and \(_{+}^{d}\) and \(_{++}^{d}\) its positive and negative orthants. Vectors and matrices are in bold lowercase and uppercase letters (e.g., \(\), \(\)), with elements \(a_{i}\) and \(a_{ij}\). Rows and columns of \(\) are \(_{i:}\) and \(_{:j}\), respectively. For symmetric \(\), \( 0\) and \( 0\) denote positive definiteness and semi-definiteness. \(_{i}()\) is the \(i\)th smallest eigenvalue of \(\). The matrix norms are defined as \(\|\|_{1}=_{ij}|a_{ij}|\) and \(\|\|_{F}=(_{ij}|a_{ij}|^{2})^{1/2}\). For any positive integer \(n\), \([n]:=\{1,,n\}\). Any notation is defined upon its first use and summarized in Table 3.

### Graph Disparity Error

To evaluate the effects of joint GMs learning on different groups, we compare models trained on group-specific data with those trained on a combined dataset. Let a dataset \(\) be divided into \(K\) sensitive groups, with the data for group \(k[K]\) represented as \(_{k}^{N_{k} P}\), where \(N_{k}\) is the sample size for group \(k\), and \(N=_{k=1}^{n}N_{k}\). The performance of a GM, denoted by \(\), for group \(k\) is measured by the loss function \((;_{k})\). Our goal is to find a global model \(^{*}\) that minimizes performance discrepancies across groups. We define graph disparity error to quantify fairness:

**Definition 1** (**Graph Disparity Error**).: _Given a dataset \(^{N P}\) with \(K\) sensitive groups, where \(_{k}\) represents the data for group \(k[K]\), let_

\[_{k}^{*}_{k}}{ }\ (_{k};_{k})+\|_{k}\|_ {1}.\] (3)

_The graph disparity error for group \(k\) is then:_

\[_{k}():=(; _{k})-(_{k}^{*};_{k}), 1  k K.\] (4)

This measures the loss difference between a global graph matrix \(\) and the optimal local graph matrix \(_{k}^{*}\) for each group's data \(_{k}\). A fair GM, under Definition 1, seeks to balance \(_{k}\) across all groups.

**Definition 2** (**Fair GM**).: _A GM with graph matrix \(^{*}\) is called fair if the graph disparity errors among different groups are equal, i.e.,_

\[_{1}(^{*})=_{2}(^{*})==_{K}(^{*}).\] (5)

To address the imbalance in graph disparity error among all groups, we introduce the idea of pairwise graph disparity error, which quantifies the variation in graph disparity between different groups.

**Definition 3** (**Pairwise Graph Disparity Error**).: _Let \(:_{+}\) be a penalty function such as \((x)=(x)\) or \((x)=x^{2}\). The pairwise graph disparity error for the group \(k\) is defined as_

\[_{k}():=_{s[K],s k} (_{k}()-_{s}( )).\] (6)

The motivation for Definition 3 follows from the work of [35; 65; 95] in PCA and CCA. In our convergence analysis, we focus on smooth functions \(\), such as squared or exponential functions, while nonsmooth choices, such as \((x)=|x|\), can be explored in the experimental evaluations.

### Multi-Objective Optimization for Fair GMs

This section introduces a framework designed to mitigate bias in GMs (including Gaussian, Covariance, and Ising) related to protected attributes by incorporating pairwise graph disparity error into a nonsmooth multi-objective optimization problem. Smooth multi-objective optimization tackles fairness challenges in unsupervised learning [35; 95], proving particularly useful when decision-making involves multiple conflicting objectives.

We use _non-smooth multi-objective optimization_ to balance two key factors: the loss in GMs and the pairwise graph disparity errors. To achieve this, let

\[f_{1}()=(;), f_{k}()=_{k-1 }(), 2 k K+1,\] (7a) \[F_{k}()=f_{k}( )+g(), 1 k M:=K+1,\] (7b)

where \(g():=\|\|_{1}\) for some \(>0\).

Consequently, we propose the following multi-objective optimization problem for Fair GMs:

\[}{}\ \ ():=[F_{1}(),,F_{M}( )]\ \ .\] (8)

Here, \(\) is a convex constraint subset of \(^{P P}\) and \(:^{M}\) is a multi-objective function.

**Assumption A**.: _For some \(L>0\), all \(,\), \(k[M]\), \(\| f_{k}()- f_{k}( )\|_{F} L\|-\|_{F}\)._

Note that Assumption A holds for smooth \(\) functions such as squared or exponential, as specified in Definition 6, and when \(\) is a smooth loss function. We demonstrate in Appendix C that this assumption holds for the Gaussian, Covariance, and Ising models studied in this work. To proceed, we provide the following definitions; see [20; 75; 73] for more details.

**Definition 4** (Pareto Optimality).: _In Problem (8), a solution \(^{*}\) is Pareto optimal if there is no \(\) such that \(()(^{*})\) and \(()(^{*})\). It is weakly Pareto optimal if there is no \(\) such that \(()(^{*})\)._

**Definition 5** (Pareto Stationary).: _We define a point \(}^{P P}\) as Pareto stationary (or critical) if it satisfies the following condition:_

\[_{k[M]}F_{k}^{}(};):=_{  0}(}+)-F_{k}(})}{} 0 ^{P P}.\]To solve Problem (8), we use the proximal gradient method and establish its convergence to a Pareto stationary point for the nonsmooth Problem (8). The procedure for our fairness-aware GMs (Fair GMs) is detailed in Algorithm 1. Given local graph estimates \(\{_{k}^{*}\}_{k=1}^{K}\) obtained in S1., and \(>L\), where \(L\) is a Lipschitz constant defined in Assumption A, the update of the global fair graph estimate \(\) is produced in S2. by solving:

\[_{}():=*{arg\,min}_{ }_{}(; ),\] (9a) \[_{}(;):= _{k[M]} f_{k}(),- +g()-g()+ \|-\|_{F}^{2}.\] (9b)

Note that the convexity of \(g()=\|\|_{1}\) ensures a unique solution for Problem (9). We provide a simple yet efficient approach to solve Subproblem (9) through its dual in Appendix B. In addition, Proposition 11 in Appendix B characterizes the weak Pareto optimality for Problem (8).

### Theoretical Analysis

We apply Algorithm 1 to Gaussian, Covariance, and Ising models and provide theoretical guarantees.

Fair Graphical Lasso (Fair GLasso).Consider \(_{1:},,_{N:}\) as i.i.d. samples from \((,)\). In the GLasso method , the loss is defined as \(_{G}(;):=-()+()\), where \(\) is constrained to the set \(=\{:,=^{}\}\) and \(=n^{-1}_{i=1}^{n}_{i:}_{i:}^{}^{N N}\) is the empirical covariance matrix of \(\). Extending this to fair GLasso and following (8), the multi-objective optimization problem is formulated as:

\[}{} ()=[_{G}(; )+\|\|_{1},F_{2}(), ,F_{M}()]\] (Fair GLasso) subj. to \[=\{:,=^{}\}.\]

**Assumption B**.: _Let \(^{*}\) be the set of weakly Pareto optimal points for (8), and \(_{}():=\{ ()\}\) denote the the level set of \(\) for \(^{M}\). For all \(_{}((^{(0)}))\), there exists \(^{*}^{*}\) such that \((^{*})()\) and_

\[R:=_{^{*}(^{*}_{}( (^{0})))}_{^{-1 }(\{^{*}\})}\|-^{(0)} \|_{F}^{2}<.\]

This assumption is satisfied when \(_{F}((^{(0)}))\) is bounded [75; 73]. When \(M=1\), it holds if the problem has at least one optimal solution. If \(_{F}(^{(0)}))\) is bounded, Assumption B also holds, such as when \(F_{k}\) is strongly convex for some \(k[M]\).

**Theorem 6**.: _Suppose Assumptions A and B hold. Let \(\{^{(t)}\}_{t 1}\) be the sequence generated by Algorithm 1 for solving (Fair GLasso). Then,_

\[_{}_{k[M]}F_{k}(^{(t)})-F_{k}()}.\]

Fair Covariance Graph (Fair CovGraph).For the Fair CovGraph, we assume \(_{1:},,_{N:}\) are i.i.d. samples from \((,)\). We use a sparse estimator for the covariance matrix, ensuring it remains positive definite and specifies the marginal independence graph. Following , we define the estimator's loss function as \(_{C}(,):=\|- \|_{F}^{2}-()\) with \(>0\). Building on this and using (7) and (8), for some nonegative constants \(_{C}\) and \(\), we introduce the Fair CovGraph optimization problem, formulated as follows:

\[}{} ()=[F_{1}(),F_{2} (),,F_{M}()]\] subj. to \[=\{: ,=^{}\}\] (Fair CovGraph)

Here, following (8), we have \(f_{1}()=_{C}(;)\) and \(f_{k}()=_{k-1}()\) for \(2 k K+1\). Also, \(F_{1}()=f_{1}()+\| \|_{1}\) and \(F_{k}()=f_{k}()+\| \) with \(\) and \(_{G}(;)\) with \(_{C}(,)\), for the sequence \(\{^{(t)}\}_{t 1}\) generated by Algorithm 1 applied to (Fair CovGraph), and for \(_{C}\{0,-_{}(^{2}f_{k}())\}\) for all \(k[K]\), we have:_

\[_{}_{k[M]}\{F_{k}(^{(t)})-F_{k}()\}.\]

Fair Binary Ising Network (Fair BinNet).In this section, we focus on the binary Ising Markov random field as described by . The model considers binary-valued, i.i.d. samples with probability density function defined in (1). Following , we consider the following loss function:

\[_{I}(;)=-_{j=1}^{P}_{j ^{}=1}^{P}_{jj^{}}(^{})_{jj^{ }}+_{i=1}^{N}_{j=1}^{P}1+_{jj}+_{j^{ } j}_{jj^{}}x_{ij^{}}.\] (10)

Given some nonegative constants \(_{I}\) and \(\), the Fair BinNet objective is defined as:

\[}{} ()=[F_{1}(),F_{2}(),,F_{M}()]\] (Fair BinNet) \[ =\{: =^{}\}.\]

Here, following (8), we have \(f_{1}()=_{I}(;)\), and \(f_{k}()=_{k-1}()\) for \(2 k K+1\). Also, \(F_{1}()=f_{1}()+ \|\|_{1}\), and \(F_{k}()=f_{k}()+ \|\|_{1}+_{I}\|\|_{F}^{2}\) for \(2 k M=K+1\). The parameter \(_{I}\) convexifies Problem (Fair BinNet) and ensures Algorithm 1 converges. The following theorem establishes the convergence of Algorithm 1 for Problem (Fair BinNet).

**Theorem 8**.: _Suppose Assumptions A and B hold, and that \(_{I}\{0,-_{}(^{2}f_{k}())\}\) for all \(k[K]\). Then, the sequence \(\{^{(t)}\}_{t 1}\) generated by Algorithm 1 for (Fair BinNet) satisfies_

\[_{}_{k[M]}\{F_{k}(^{(t)})-F_{k}()\}.\]

**Remark 9** (Iteration Complexity of Algorithm 1).: _Theorems 6, 7, and 8 establish the global convergence rates of \(O(1/t)\) for Algorithm 1 for Gaussian, Covariance, and Ising models, respectively. In contrast to Theorem 6, Theorems 7 and 8 necessitate the inclusion of an additional convex regularization term with parameters \(_{C}\) and \(_{I}\), respectively, to achieve Pareto optimality._

**Remark 10** (Computational Complexity of Algorithm 1).: _Given the iteration complexity to achieve \(\)-accuracy is \(O(^{-1})\), the overall time complexity of our optimization procedure becomes \(O(^{-1}(NP^{2},P^{3}))\). Assuming a small number of groups (\(K<<N,P,1/\)), the complexity aligns with that of standard proximal gradient methods used for covariance and inverse covariance estimation, making it feasible for large \(N\) and \(P\). To further support the theoretical analysis, sensitivity analysis experiments are conducted to investigate the impact of varying \(P\), \(N\), \(K\), and group imbalance on the performance of the proposed methods. Note that the complexity of Algorithm 1 applied to (Fair BinNet) depends on the choice of subproblem solver (e.g., first or second order) due to the nonlinearity of (10). Further experiments and discussions are detailed in Appendices D.6-D.9._

## 4 Experiment

### Experimental Setup

Baseline.The Iterative Shrinkage-Thresholding Algorithm (ISTA) is widely used for sparse inverse covariance estimation  due to its simplicity and efficiency. We adapt ISTA for the Covariance and Ising models and use them as a baseline to compare with our proposed Fair GMs. Note that our Fair GMs reduce to ISTA for Gaussian, Covariance, and Ising models if \(M=1\) in (8). The detailed ISTA algorithm used in this study is provided in Appendix D for reference.

Parameters and Architecture.The initial iterate \(^{(0)}\) is chosen based on the highest graph disparity error among local graphs. This initialization can improve fairness by minimizing larger disparity errors. The \(_{1}\)-norm coefficient \(\) is fixed for each dataset, searched over a grid in \(\{1e-5,,0.01,,0.1,1\}\). Tolerance \(\) is set to \(1e-5\), with a maximum of \(1e+7\) iterations. The initial value of \(\) is \(1e-2\), undergoing a line search at each iteration \(t\) with a decay rate of \(0.1\).

[MISSING_PAGE_FAIL:7]

\((z_{}/(1+z_{}))\), where \(z_{}=(_{jj}+_{j^{} j}_{jj^{}}x_{j^{ }}^{(t)})\). The first 10,000 iterations are designated as the burn-in period to ensure statistical independence among observations. Finally, observations are collected at every 100th iteration.

**Results.** Figure 2k illustrates the global graph from Standard BinNet, which is predominantly biased towards \(_{2}\) by identifying only one hub node. In contrast, Figure 2l, derived from Fair BinNet, presents a more balanced structure. While this improvement might not be visually evident, the quantitative results in Table 1 and Table 2 confirm it. Table 1 reveals that PCEE for Group 1 improved significantly, increasing from 0.4444 to 0.7485. Conversely, PCEE for Group 2 exhibited a decrease from 0.9481 to 0.7662. This convergence in performance metrics between the two groups indicates a more balanced distribution of predictive errors, thus enhancing the overall fairness of the model.

### Application of Fair GLasso to Gene Regulatory Network

We apply GLasso to analyze RNA-Seq data from TCGA, focusing on lung adenocarcinoma. The data includes expression levels of 60,660 genes from 539 patients. From these, 147 KEGG pathway genes  are selected to construct a gene regulatory network. GLasso reveals conditional dependencies, aiding in understanding cancer genetics and identifying therapeutic targets. However, initially, this method, without accounting for sex-based differences, risks overlooking critical biological disparities, potentially skewing drug discovery and health outcomes across genders. Therefore, we divide the patient cohort into two groups based on sex: 248 males and 291 females. This stratification enables the use of Fair GLasso, which creates a more equitable gene regulatory network by accounting for these differences. The parameter \(\) is set to 0.03 for this experiment. Additionally, each variable is normalized to achieve a zero mean and a unit variance.

**Results.** The gene networks identified by GLasso and Fair GLasso are presented in Figures 3a-3b. GLasso identified several hub nodes, including NCOA1, BRCA1, FGF8, AKT1, NOTCH4, and CSNK1A1L. In contrast, Fair GLasso uniquely detected PIK3CD, suggesting its potential relevance in capturing sex-specific differences in lung adenocarcinoma. Although direct evidence linking PIK3CD exclusively to sex-specific traits in cancer is limited, this finding aligns with recent insights into sex-specific regulatory mechanisms in cancer [63; 45]. PIK3CD is a key component of the PI3K/Akt signaling pathway, which is involved in cell regulation and frequently implicated in various malignancies. The identification of PIK3CD by Fair GLasso demonstrates its potential to uncover biologically relevant genes that may be overlooked in conventional analyses, enhancing our understanding of lung adenocarcinoma and facilitating the development of personalized therapies.

### Application of Fair GLasso to Amyloid / Tau Accumulation Network

The performance of GLasso and Fair GLasso is evaluated using AV45 and AV1451 PET imaging data from the Alzheimer's Disease Neuroimaging Initiative (ADNI) [85; 86], focusing on amyloid-\(\) and tau deposition in the brain. The dataset includes standardized uptake value ratios of AV45 and AV1451 tracers in 68 brain regions, as defined by the Desikan-Killiany atlas , collected from 1,143 participants. An amyloid (or tau) accumulation network  is constructed to investigate the pattern of amyloid (or tau) accumulation. GLasso and Fair GLasso are used to uncover conditional dependencies between brain regions, providing insights into Alzheimer's disease progression and identifying potential biomarkers for early diagnosis and treatment response monitoring. To examine the influence of sensitive attributes on the network structure, marital status, and race are incorporated as exemplary sensitive attributes due to their reported association with dementia risk [71; 49]. Comprehensive details regarding the experiments, results, and analysis are provided in Appendix 4.5.

### Application of Fair CovGraph to Credit Datasets

The performance of Fair CovGraph is evaluated using the Credit Datasets  from the UCI Machine Learning Repository . These datasets have been previously used in research on Fair PCA [55; 83], which shows potential for improvement through sparse covariance estimation. The dataset composition is detailed in Table 5 in Appendix D.5, with categorizations based on gender, marital status, and education level. For this experiment, the parameters \(\) and \(\) are set to 0.01 and 0.1, respectively. Each variable in the dataset is standardized to have a mean of zero and a variance of one. As shown in Table 2, our Fair CovGraph achieves a 53.75% increase in fairness with only a 0.42% decrease in the graph objective, demonstrating the strong ability of our method to attain fairness.

### Application of Fair BinNet to Music Recommendation Systems

LFM-1b Dataset4 contains over one billion listening events intended for use in recommendation systems . In this experiment, we use the user-artist play counts dataset to construct a recommendation network of artists. Our analysis focuses on 80 artists intersecting the 2016 Billboard Artist 100 and 1,807 randomly selected users who listened to at least 400 songs. We transform the play counts into binary datasets for BinNet models, setting play counts above 0 to 1 and all others to 0.

This experiment examines male and female categories, stratifying the dataset into two groups with 1,341 and 466 samples, respectively. We set the BinNet models' parameter, \(\), to \(1e-5\).

**Results.** Figures 2(c)-2(d) show the recommendation networks of the 2016 Billboard Top 10 popular music artists based on BinNet's and Fair BinNet's outputs. The comparative analysis reveals that Fair BinNet provides a more diversified recommendation network, particularly for the artist The Weeknd. Enhancing fairness fosters cross-group musical preference exchange, breaks the echo chamber effect, and broadens users' exposure to potentially intriguing music, enhancing the user-friendliness of the music recommendation system.

### Trade-off Analysis

In fairness studies, the trade-off between fairness and model accuracy presents a fundamental challenge. An effective fair method should achieve equitable outcomes while maintaining strong accuracy performance. We evaluate this balance by analyzing the percentage changes in both accuracy and fairness metrics. Specifically, we define these changes as: \(\%F_{1}=--F_{1}}{F_{1}} 100\%\), and \(\%=--}{} 100\%\).

Our empirical results (Tables 2, 4, and Figure 4) demonstrate that Fair GMs substantially reduce disparity error, thereby improving fairness, while incurring only minimal degradation in the objective function's value. This favorable trade-off validates the effectiveness of our approach. However, Fair GMs do face computational challenges, primarily stemming from two sources: local graph computation and multi-objective optimization.

    & \)} & \)} &  &  &  \\    & **GM** & & & & **GM** & **Fair GM** & & **GM** & **Fair GM** \\  Simulation (GLasso) & **97.172** & 97.443 & -0.28\% & 7.8149 & **0.6237** & +92.02\% & **0.395 (\(\) 0.24)** & 32.32 (\(\) 1.5) \\ Simulation (CovGraph) & **14.319** & 14.484 & -1.15\% & 5.2627 & **0.3889** & +92.61\% & **0.254 (\(\) 0.05)** & 12.58 (\(\) 0.3) \\ Simulation (BinNet) & **34.363** & 34.362 & -0.00\% & 1\(\)10\({}^{-6}\) & **0.0000** & +100.00\% & **0.536 (\(\) 0.15)** & 3.29 (\(\) 0.48) \\ TCGA Dataset & **127.96** & 128.11 & -0.11\% & 2.5875 & **0.0742** & +97.13\% & **8.468 (\(\) 1.17)** & 63.72 (\(\) 5.9) \\ Credit Dataset & **9.2719** & 9.3110 & -0.42\% & 0.5436 & **0.2513** & +53.76\% & **0.256 (\(\) 0.08)** & 64.20 (\(\) 1.8) \\ LFM-1b Dataset & 87.531 & **87.138** & +0.45\% & 0.0040 & **0.0001** & +96.60\% & **0.669 (\(\) 0.19)** & 41.19 (\(\) 3.5) \\   

Table 2: Outcomes in terms of the value of the objective function \((F_{1})\), the summation of the pairwise graph disparity error \(()\), and the average computation time in seconds (\(\) standard deviation) from 10 repeated experiments. “\(\)” means the smaller, the better, and the best value is in bold. Note that both \(F_{1}\) and \(\) are deterministic.

Figure 3: (a)-(b) Comparison of graphs generated by standard GLasso and Fair GLasso on TCGA Dataset. Week edges are removed for visibility, and hub nodes that own at least 4 edges are highlighted. (c)-(d) Comparison of sub-graphs generated by standard BinNet and Fair BinNet on LFM-1b Dataset. Fair BinNet provides a more diversified recommendation network.

To address these limitations, we propose several solutions. The local graph learning phase can be accelerated using advanced graphical model algorithms such as QUIC , SQUIC , PISTA , GISTA , OBN , or ALM . Moreover, to mitigate the increased complexity from multiple objectives, we introduce a stochastic objective selection strategy, randomly sampling a subset of objectives in each iteration. This approach effectively reduces computational overhead while maintaining model fairness and performance. To validate these computational considerations, we conducted additional experiments using GLasso, with detailed results presented in the Appendix D.10.

## 5 Conclusion

In this paper, we tackle fairness in graphical models (GMs) such as Gaussian, Covariance, and Ising models, which interpret complex relationships in high-dimensional data. Standard GMs exhibit bias with sensitive group data. We propose a framework incorporating a pairwise graph disparity error term and a custom loss function into a nonsmooth multi-objective optimization. This approach enhances fairness without compromising performance, validated by experiments on synthetic and real-world datasets. However, it increases computational complexity and may be sensitive to the choice of loss function and balancing multiple objectives. Future research can include:

**F1.** Integrating our Fair GMs approach with supervised methods for downstream tasks, including spectral clustering , graph regularized dimension reduction .

**F2.** Developing novel group fairness notions based on sensitive attributes within our nonsmooth multi-objective optimization framework.

**F3.** Extending fairness to ordinal data models, which are crucial for socioeconomic and health-related applications , neighborhood selection , and partial correlation estimation .

Despite some limitations of Fair GMs for larger group sizes, this work demonstrates the potential of _nonsmooth multi-objective optimization_ as a powerful tool for mitigating biases and promoting fairness in _high-dimensional_ graph-based machine learning, contributing to the development of more equitable and responsible AI systems across a wide range of domains.

## 6 Acknowledgements

This work was supported in part by the NIH grants U01 AG066833, U01 AG068057, U19 AG074879, RF1 AG068191, RF1 AG063481, R01 LM013463, P30 AG073105, U01 CA274576, RF1-AG063481, R01-AG071174, and U01-CA274576. The ADNI data were obtained from the Alzheimer's Disease Neuroimaging Initiative database (https://adni.loni.usc.edu), funded by NIH U01 AG024904. The authors thank Laura Balzano and Alfred O. Hero for their helpful suggestions and discussions.