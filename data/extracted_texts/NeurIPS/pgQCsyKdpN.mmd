# AdaptiveISP: Learning an Adaptive Image Signal Processor for Object Detection

Yujin Wang \({}^{1}\) Tianyi Xu \({}^{1,2}\) Fan Zhang \({}^{1}\) Tianfan Xue \({}^{3,1}\) Jinwei Gu \({}^{3}\)

\({}^{1}\) Shanghai AI Laboratory \({}^{2}\) Peking University

{wangyujin, zhangfan}@pjlab.org.cn, photon@stu.pku.edu.cn

\({}^{3}\) The Chinese University of Hong Kong

{tfxue@ie, jwgu@cse}.cuhk.edu.hk

###### Abstract

Image Signal Processors (ISPs) convert raw sensor signals into digital images, which significantly influence the image quality and the performance of downstream computer vision tasks. Designing ISP pipeline and tuning ISP parameters are two key steps for building an imaging and vision system. To find optimal ISP configurations, recent works use deep neural networks as a proxy to search for ISP parameters or ISP pipelines. However, these methods are primarily designed to maximize the image quality, which are sub-optimal in the performance of high-level computer vision tasks such as detection, recognition, and tracking. Moreover, after training, the learned ISP pipelines are mostly fixed at the inference time, whose performance degrades in dynamic scenes. To jointly optimize ISP structures and parameters, we propose AdaptiveISP, a task-driven and scene-adaptive ISP. One key observation is that for the majority of input images, only a few processing modules are needed to improve the performance of downstream recognition tasks, and only a few inputs require more processing. Based on this, AdaptiveISP utilizes deep reinforcement learning to automatically generate an optimal ISP pipeline and the associated ISP parameters to maximize the detection performance. Experimental results show that AdaptiveISP not only surpasses the prior state-of-the-art methods for object detection but also dynamically manages the trade-off between detection performance and computational cost, especially suitable for scenes with large dynamic range variations. Project website: https://openimaginglab.github.io/AdaptiveISP/.

## 1 Introduction

Image Signal Processors (ISPs) play a fundamental role in camera systems. Originally, ISPs aimed at enhancing the perceptual quality, focusing on photography-related applications. Recently, machine vision cameras also optimized the ISP pipeline for downstream recognition tasks . For recognition tasks, studies have shown a specially designed ISP can significantly enhance their performance. However, most machine vision cameras  still prefer a static hand-designed ISP and manually-tuned parameters, making it sub-optimal for downstream recognition tasks and also inflexible for dynamic scenes. Another solution is to directly train detection networks that take raw files as input, skipping the entire ISP processing. However, this may require re-training the detection network for each camera sensor, as the raw format varies between cameras, and studies  also show that the raw detection network still performs worse than the detection network runs on ISP-processed images. Therefore, a well-tuned ISP is important for downstream recognition tasks.

In this work, we aim to design an ISP that can dynamically adapt its pipeline and parameters for different inputs, tailored for a given high-level computer vision task. This problem faces two challenges: complexity and efficiency. First, it is a complicated optimization problem to jointlyre-organize the ISP modules, update their parameters, and also improve the performance of the downstream recognition module. Because of this complexity, previous works only update the parameters [35; 25; 30; 31; 38; 16; 26]. Some recent works jointly optimize the ISP pipeline and parameters [10; 28], but they are not designed for downstream recognition tasks. Second, ISP optimization must be efficient enough to adapt to dynamically changing scenes, which is particularly important in real-time applications such as autonomous driving and robotics. The majority of ISP pipeline optimization methods use searching strategies, such as the neural architecture search (NAS) method  and the multi-object optimization search method , which often takes several hours, making them infeasible for real-time applications across dynamically changing scenes.

To solve this challenge, we observe that the majority of input images only require a few ISP operations to increase the downstream recognition accuracy. As shown in Figure 1 on the right, only the first two stages of ISP already boost the detection accuracy (mAP) from 67.8 to 70.9, and the rest of the three stages only further boost it to 71.4. Only challenging examples require more complicated pipelines. Therefore, we can model the ISP configuration process as a Markov Decision Process , and our AdaptiveISP only selects one ISP module at each stage, as shown in Figure 1 on the left. This greatly reduces the search space at inference time and enables adaptively changing the ISP length, spending less time on easy inputs.

Based on this idea, we introduce AdaptiveISP, a real-time reconfigurable ISP based on reinforcement learning (RL). As shown in Figure 1, AdaptiveISP takes a linear image as input and generates an optimal ISP pipeline with associated parameters that best fit this image for object detection. Unlike previous neural architecture search (NAS)  that generates the entire pipeline at once, AdaptiveISP takes a greedy approach to only generate one module at each iteration, greatly reducing the searching time. At each iteration, a lightweight RL agent takes the processing output from the previous stage as input and finds the optimal module for the next iteration. Because of its efficiency, AdaptiveISP only takes 1 ms to predict one stage and can generate different pipelines for different scenes on the fly in real-time, as illustrated in Figure 1.

Furthermore, we design a reinforcement learning scheme tailored for ISP configuration. First, we integrate a pre-trained fixed object detection network, YOLO-v3 , into the optimization system as a loss function, guiding our model to prioritize specific high-level computer vision tasks. Second, with the observation that many later-stage ISP modules may only bring little improvement to detection, we introduce a new cost penalty mechanism so that AdaptiveISP supports dynamically trading off object detection accuracy and ISP latency.

The proposed AdaptiveISP have several distinctive properties compared to a typical ISP for visual quality. First, ISP for detection can be much simpler. As shown on the right side of Figure 1, with only 4 stages, it achieves the best detection accuracy, while traditional ISP may need more than 10 stages to enhance image quality. Second, while color processing is important in both types of ISPs for both detection and viewing, their behaviors are different. For instance, ISPs for detection often completely desaturate color in low-light scenarios to boost the detection rate, as shown in the second-row of Figure 1, which rarely happens for traditional ISPs. Third, a simple sharpening or

Figure 1: AdaptiveISP takes a raw image as input and automatically generates an optimal ISP pipeline \(\{M_{i}\}\) and the associated ISP parameters \(\{_{i}\}\) to maximize the detection performance for any given pre-trained object detection network with deep reinforcement learning. AdapativeISP achieved mAP@0.5 of 71.4 on the dataset LOD dataset, while a baseline method  with a fixed ISP pipeline and optimized parameters can only achieve mAP@0.5 of 70.1. Note that AdaptiveISP predicts the ISP for the image captured under normal light requires a CCM module, while the ISP for the image captured under low light requires a Desaturation module.

blurring module may greatly enhance detection accuracy, while a more widely used denoising module in traditional ISPs is not super helpful for detection.

We have evaluated the proposed AdaptiveISP on the LOD , OnePlus , and synthetic raw COCO  datasets and showed that it outperforms prior state-of-the-art methods under different challenging conditions and different downstream tasks. Experimental results also demonstrate the ability to dynamically switch from a high-accuracy ISP pipeline to a low-latency one.

## 2 Related Work

**ISP Parameter Tuning.** Recent studies have explored various methods for optimizing Image Signal Processing (ISP) hyper-parameters, particularly those based on handcrafted designs and tailored to meet the demands of downstream evaluation metrics. One category of methods focuses on derivative-free optimization techniques. Nishimura _et al_.  introduced an automatic image quality tuning method that employs nonlinear optimization and automatic reference generation algorithms. Another category utilizes gradient-based optimization techniques. Tseng _et al_.  introduced a gradient optimization method that relies on differentiable approximations, allowing for efficient hyper-parameter tuning but the ISP parameters are fixed during the inference stage. Immediately afterward, some researchers realized that one set of parameters was not necessarily suitable for different scenarios. Qin _et al_.  proposed an attention-based CNN method, but it does not consider sequence-specific prior knowledge. Then, Qin _et al_.  proposed a sequential ISP hyper-parameter prediction framework, which optimizes the ISP parameters by leveraging sequential relationships and parameter similarities. Additionally, Liu _et al_.  proposed the IA-YOLO approach, which can adaptively process images under both normal and adverse weather conditions. Yoshimura _et al_.  proposed _DynamicISP_, which can causally and smoothly control the parameters of the current frame according to the recognition result of the previous frame. Departing from approximation methods, Mosleh _et al_.  introduced a hardware-in-the-loop approach. This approach directly optimizes hardware-based image processing pipelines to meet specific end-to-end objectives by using a novel \(0\)th-order stochastic solver. Furthermore, an image enhancement method based on reinforcement learning, proposed by Kosugi _et al_. , leverages reinforcement learning techniques to optimize hyper-parameters in an unpaired manner.

**ISP Pipeline Design.** The conventional ISP pipelines are crafted to adhere to human visual perception, and this alignment might not always be conducive to fulfilling the demands of downstream high-level tasks. The prior research works [34; 39] have proved that handcrafted ISP configuration does not necessarily benefit the downstream high-level vision tasks. ReconfigISP  proposed a novel Reconfigurable ISP whose architecture and parameters can be automatically tailored to specific data and tasks by using neural architecture search (Darts) . RefactoringISP  jointly optimized ISP structure and parameters with task-specific loss and ISP computation budgets through multi-objective optimization algorithm (NSGA-II) . However, these approaches maintain the ISP pipeline and parameters fixed during inference, regardless of the distinct characteristics of the input. An innovative study addresses the challenge of photo retouching by leveraging deep learning on unpaired data, allowing users to emulate their preferred retouching style . Additionally, recent studies have explored replacing traditional ISP pipelines or modules with deep learning models to enhance image quality. PyNET  proposed a unified model that directly learns the RAW-to-RGB mapping to improve mobile photography, while CycleISP  introduced a noise-aware denoising approach. ParamISP  developed forward and inverse ISP models conditioned on camera parameters, enabling a more accurate emulation of real-world ISP behavior to enhance image processing performance. DualDn  further employs a differentiable ISP to improve denoising capabilities. Although these methods improve image quality, they do not consistently translate into better performance for downstream high-level vision tasks.

## 3 Our Method

Image Signal Processors (ISPs) often consist of a pipeline of image processing modules that primarily transform raw sensor pixel data into RGB images suitable for human viewing . A typical camera ISP pipeline includes two parts: raw-domain and RGB-domain. Compared to raw-domain processing, the RGB-domain processing is normally image-dependent and requires more dedicated design and tuning efforts. Details of ISP pipeline and modules can be found in the _appendix_.

In this work, we focus on the RGB-domain processing. We assume that the captured raw sensor data is already converted to linear RGB images using a simple static raw-domain processing, and our tuning mainly focuses on sRGB-domain processing, similar to [9; 38].

### Problem Formulation of AdaptiveISP

Given an input linear RGB image \(I\), the goal of AdaptiveISP is to find an optimal ISP pipeline and parameters, with which the processed output image will result in high performance for object detection. Let \(_{(M,)}\) denote one ISP module, where \(M\) is the ISP module type and \(\) is the set of parameters for that module. An ISP pipeline consists of a sequence of ISP modules \(\{_{(M_{t},_{t})}\}_{t=0}^{T}\), which transforms an input image \(I\) to an output image \(I_{t}\) with \(t\) stages of ISP processing as

\[I_{t}=(_{(M_{t},_{t})}_{(M_{0 },_{0})})(I)\,.\] (1)

The goal of AdaptiveISP is to predict an optimal ISP pipeline (with \(T\) stages) and its parameters, i.e., \(\{M_{t},_{t}\}_{t=0}^{T}\) for an input image, in order to maximize its performance for a given computer vision task (e.g. object detection), which can be formulated as

\[\{M_{t},_{t}\}_{t=0}^{T*}=*{argmin}_{\{M_ {t},_{t}\}_{t=0}^{T}}\{(I_{T})\},\] (2)

where \(\) is the detection error with a given object detector. This optimization problem can thus be modeled as a Markov Decision Process , which can be solved efficiently via deep reinforcement learning.

### Optimization Objectives

Our formulation is similar to [5; 6; 10; 28]. Let us denote the problem as \(P=(S,A)\), where \(S\) is a state space and \(A\) is an action space. Specifically, in our task, \(S\) is the space of images, which includes the input images and all the intermediate results in the ISP process, while \(A\) is the set of all ISP modules. Since each action includes the selection of ISP modules and the prediction of ISP module parameters, we can decompose the action space \(A\) into two parts: a discrete selection of ISP modules \(a^{M}\) and a continuous prediction of ISP module parameters \(a^{}\). At stage \(i\), with a selected ISP module and its parameters \((a_{i}^{}},a_{i}^{})\), the input image at state \(s_{i}\) is mapped to state \(s_{i+1}\). Applying a sequence of \(T\) selected ISP modules to an input image corresponds to a trajectory \(\) of states and actions:

\[=(s_{0},a_{0}^{M},a_{0}^{},,s_{T-1},a_{T-1}^{M},a_{T-1}^{ },s_{T}),\] (3)

where \(s_{T}\) is the stopping state. Our goal is to find a policy \(\) that maximizes the accumulated reward during the decision-making process. The policy \(\) consists of two sub-policies \((^{M}\) and \(^{})\), where \(^{M}\) takes a state and returns a probability distribution over ISP modules, and \(^{}\) predicts the parameters \(a^{}\) of the selected ISP module. In this paper, the reward function with the \(i\)-th action (i.e., corresponding to the \(i\)-th stage of ISP processing) is thus written as:

\[r(s_{i},a_{i}^{M},a_{i}^{})=(s_{i})- (s_{i+1}),\] (4)

Figure 2: Overview of our method. The ISP configuration process is conceptualized as a Markov Decision Process, where a CNN-based policy network predicts the selection of ISP modules and their parameters. Concurrently, a CNN-based value network estimates the state value. The YOLO-v3  is employed to calculate the reward for the current policy. The entire system is optimized using the actor-critic algorithm [15; 24].

where \(s_{i+1}=p(s_{i},a_{i}^{M},a_{i}^{})\), and \(\) is the error of object detection. Given a trajectory \(\), we define the return \(g_{t}\) as the summation of the discounted rewards after \(s_{t}\):

\[g_{t}=_{k=0}^{T-t}^{k} r(s_{t+k},a_{t+k}^{M},a_{t+k}^{}),\] (5)

where \(\) is a discount factor that places greater importance on rewards in the near future. We can thus define the value of state function \(V^{}(s)\) as:

\[V^{}(s)=}_{}[g_{0}|s_{0}=s],\] (6)

and the value of action function \(Q^{}(s,a^{},a^{})\) as:

\[Q^{}(s,a^{},a^{})=}_{}[g_{0}| s_{0}=s,a^{},a^{}].\] (7)

Our goal is to select a policy \(=(^{M},^{})\) that maximizes the expected accumulated reward during the decision-making process:

\[J()=}_{s S_{0}}[V^{}(s)],\] (8)

where \(S_{0}\) denotes the entire image dataset.

Similar to [10; 28; 16; 5], we employ deep neural networks to approximate the value function \(V^{}(s)\) and the policy \(\). As shown in Figure 2, convolutional neural networks (CNNs) and a fully-connected layer are used as the policy network, which maps the image \(s\) into action probabilities \(^{M}(s,_{M})\) (after softmax) and ISP module parameters \(^{}(s,_{})\) (after \(\)), where \((_{M},_{})\) are the network parameters. The value network \(V^{}(s,_{V})\) uses a similar architecture with parameters \(_{V}\). By maximizing the objective \(J()_{}\) with training these two networks \(=(_{M},_{},_{V})\), we can learn to predict the optimal policy \((s)\) for an input image \(s\). Specifically, to train the policy network and the value network, as shown in Figure 2, we apply the actor-critic algorithm [15; 24], where the actor is represented by the policy network and the critic is the value network. Details of network architectures and training are provided in the _appendix_.

### Implementation Details

To ensure stable and effective reinforcement learning for the ISP pipeline and parameter prediction, we augment the network input and implement several penalty functions to better constrain the training process. Specifically, we modify the reward function Equation 4 to:

\[r(s_{i},a_{i}^{M},a_{i}^{})=(s_{i})- (s_{i+1})-P_{i},\] (9)

where \(P_{i}\) stands for the penalties as explained below.

**Exploitation and Exploration.** To avoid the same ISP module being selected consecutively multiple times by the policy network, we augment the network input with the module usage record (which is represented as \(N\) channels where \(N\) is the size of the ISP module pool) and one additional "stage" channel. At each stage, if an ISP module is being used, the corresponding "use" channel and penalty of reusing will be set to 1 and 0 otherwise. The "stage" channel is set with the index of the stage. During training, these additional inputs and the penalty of reusing constrain the policy network picking the same ISP module no more than once, which can effectively narrow down the solution space and improve the performance. Details of network input are provided in the _appendix_.

In addition, we want to encourage the policy network \(^{M}(s)\) to explore different ISP modules to prevent the parameter prediction network from insufficient learning. Specifically, we introduce a penalty term \(P_{e}\) on the output entropy of the policy network \(^{M}(s)\) to ensure that the action distribution is not overly concentrated.

\[P_{e}=_{e}_{m M}p(m) p(m),\] (10)

where \(p(m)\) is the probability of an ISP module \(m\) in the softmax output, and \(_{e}\) is a penalty coefficient and gradually decreases from 1 to 0 with the progress of the training process.

**Penalty of Computational Time.** ISP pipelines typically consist of multiple modules responsible for specific image processing tasks, such as denoising, sharpening, white balance, and more. These modules exhibit varying computational costs, some being faster and others slower, as shown in Table 4. Consequently, when designing ISP pipelines, it is crucial to consider the distinct computational costs associated with these modules. Particularly, in scenarios requiring swift responses like autonomous driving, optimizing the computational efficiency of ISP pipelines becomes paramount. In order to make our method automatically select the appropriate modules and their sequence, we should account for the computational time of each module during the design of the ISP pipeline. Specifically, we collect the run time of all modules, marked as \(_{c}\), which can be found in Table 4, and the penalty of cost \(P_{c}\) is defined as:

\[P_{c}=_{c}_{m M}_{m}_{c},\] (11)

where \(_{m}\) represents the one-hot encoding whether the module \(m\) is used, and \(_{c}\) is the penalty coefficient.

## 4 Experiments

**Datasets.** In line with prior research [9; 27; 38; 39; 30; 31], we train and evaluate our models on widely used real low-light detection datasets and synthetic normal-light datasets, including:

* **LOD.** LOD Dataset  is a real-world low-light object detection dataset, which contains 2,230 14-bit low-light raw images with eight categories of objects. This dataset aims to systematically assess the low-light detection performance. There are 1,830 data pairs for training and 400 data pairs for validation. Additionally, it provides accompanying metadata, including ISO, shutter speed, aperture settings, and more, which greatly facilitates our experimental analysis.
* **OnePlus.** OnePlus Dataset  is a real-world low-light object detection dataset collected by the OnePlus 6T A6010 smartphone at driving scenes, which contains 141 raw images with three classes of objects in the street scenes. There are 50 pairs for training and 91 pairs for validation. Given the limited size of the dataset, all raw images were utilized as the validation set in our experiments.
* **Raw COCO.** COCO  is a large-scale object detection, segmentation, and captioning dataset. To evaluate the generalization ability of our method, we convert the COCO validate dataset (5,000 images) to a synthetic raw-like dataset as our evaluate dataset by using UPI , similar with [9; 38; 30; 31].

**Experiment Details.** Similar to , YOLOv3  is utilized as the detection model in all methods unless explicitly stated otherwise. YOLOv3 is a robust and fast object detection algorithm. Its real-time applicability, speed, and high-performance capabilities make it a powerful choice for various applications in numerous classic object detection algorithms [4; 33; 8; 21; 18; 5]. In terms of back-propagation, YOLOv3 passes gradients back to our method for optimizing both structure and parameters. It is important to note that the pre-trained YOLOv3 model remains unaltered throughout the training process. During training and inference, we follow  to use a fixed input resolution of \(512 512\). In addition, unless otherwise stated, our methods and comparison methods are all experiments conducted on handcrafted ISP.

**Evaluation Metrics.** We utilize the mean Average Precision (mAP) across all Intersection over Union (IoU) thresholds to assess the performance of our method, following a similar approach as used in object detection algorithms [4; 33; 8; 21; 18; 5].

### Results

**Results on LOD Dataset.** The LOD dataset provides JPEG images with accompanying metadata, which serves as a convenience for the analysis of our experimental results. On this dataset, we choose several baseline methods for evaluation. First, we select two network-based ISP methods, namely Crafting  and NeuralAE . Also, we evaluate our method against the static handcrafted pipeline and parameter methods, specifically, Hyperparameter Optimization . Furthermore, we compare our approach with static handcrafted pipelines combined with dynamic parameters techniques, suchas Attention-aware Learning  and DynamicISP . Finally, we compare our method with the optimization method for ISP pipelines and parameters, as exemplified by ReconfigISP  and Refactoring ISP . ReconfigISP utilizes a neural architecture search algorithm (Darts) , while Refactoring ISP is based on Non-dominated Sorting Genetic Algorithm II (NSGA-II) .

As shown in the first column of Table 1, our method achieves the best performance across all object detection metrics on the LOD dataset. Note that static pipelines with dynamic parameter methods outperform static pipeline and parameter approaches, dynamic pipelines and parameters yield superior results across all methods. We further show the detection results of our method in Figure 3, showcasing its superior performance in terms of both missed detection and false detection compared to all other methods.

**Cross Datasets Test.** To evaluate the generalization ability of our method on different datasets, we utilize a model trained on the LOD dataset and conduct testing on both the OnePlus and raw COCO datasets. As displayed in the central and rightmost column of Table 1, our method achieves the best performance, which verifies that our method also has the best generalization ability. In terms of the mAP@0.75 evaluation metric, our method exhibits an improvement of approximately 1 point compared to alternative approaches on both Oneplus and raw COCO datasets. Furthermore, our method outperforms Refactoring ISP  and ReconfigISP  by 2 points on the raw COCO dataset and by 4 points on the OnePlus dataset in terms of mAP@0.5:0.95 evaluation metrics.

**Cross Detectors Test.** To evaluate the generalization ability of our method on different detectors, we use the detection results from the RGB (existing ISP) as a baseline and conduct comparative experiments on DDQ , representing the Transformer-based approach, and YOLOX , representing the CNN-based approach. As shown in Table 3, all detectors using our AdaptiveISP demonstrate improved detection performance, demonstrating that our method does not overfit one detector, but is suitable for other detectors. Note that DDQ  and YOLOX  are not used in the training process, but our ISP can still generalize to these detectors at testing time.

**Results for Image Segmentation.** To show our approach can generalize to other tasks, in Table 2, we also conduct an experiment using image segmentation as the downstream task. Note that all models are trained on the LOD dataset using the pre-trained YOLOv3  detector and evaluated

   &  &  &  \\   & mAP & mAP & mAP & mAP & mAP & mAP & mAP & mAP \\  & @0.5 & @0.75 & @0.5 & @0.5 & @0.75 & @0.5 & @0.5 & @0.75 & @0.5 \\  Carfing  & 67.9 & 49.0 & 44.7 & - & - & - & - & - & - \\ NeuralAE  & - & - & 45.5 & - & - & - & - & - & - \\ DynamicISP  & - & - & 46.2 & - & - & - & - & - & - \\ Hyperparameter Optimization  & 70.1 & 49.7 & 46.1 & 69.8 & 48.7 & 43.8 & 53.8 & 38.7 & 36.6 \\ Attention-aware Learning  & 70.9 & 51.0 & 46.6 & **70.9** & 48.9 & 44.7 & 53.6 & 38.7 & 36.6 \\ ReconfigISP  & 69.4 & 49.6 & 45.6 & 65.1 & 42.1 & 40.4 & 52.6 & 38.0 & 35.8 \\ Refactoring ISP  & 68.3 & 47.6 & 44.1 & 66.7 & 44.3 & 40.9 & 52.4 & 38.0 & 35.7 \\ 
**Ours** & **71.4** & **51.7** & **47.1** & 70.1 & **49.7** & **45.0** & **54.9** & **40.1** & **37.7** \\  

Table 1: Experimental results of LOD , OnePlus , and raw COCO Dataset .

Figure 3: Object detection visualization results on LOD dataset. Our method outperforms the state-of-the-art methods  in terms of missed detection and false detection. The methods with fixed pipelines or fixed parameters struggle to effectively handle varying noise levels and brightness scenarios.

on the synthetic raw COCO datasets with the pre-trained YOLO-v5  segmentor. Our method performs better than all baselines, further showing its generalizability for different downstream tasks and algorithms. We further present the segmentation results of our method in Figure 4, highlighting its superior performance in terms of missed detection compared to all other methods.

**Accuracy-Efficiency Trade-off.** Our approach can control \(_{c}\) to regulate whether the optimization process also takes the computational time of each ISP module into consideration, where \(_{c}\) is the weight computational cost. By tuning up \(_{c}\), we can generate a more efficient ISP with a minor drop of the recognition accuracy.

We conducted analysis experiments on the LOD dataset, where \(_{c}=0.0\) represents the accuracy-oriented results and \(_{c}=0.01\) stands for efficiency-oriented results. We calculated the proportions of the occurrence of each module in the test results. As shown in Table 4, the efficiency-oriented method has a significant reduction in the average running time for each sample, which is accompanied by a slight decrease in performance. In addition, the frequency of appearance of modules with higher computational time, such as Sharpen/Blur and Tone Mapping, decreased by more than 50%. Conversely, modules with lower computational time, like Exposure and White Balance, saw a substantial increase in selection frequency.

**Runtime.** To verify the practicality of our approach, we conducted speed tests using the NVIDIA GTX1660Ti GPU, which offers a computational capability of 11 TOPS--markedly lower than that of the NVIDIA DRIVE Orin(tm) SoC at 254 TOPS. Our method only takes 1.2 ms per stage during inference, this efficiency is attributed to just need to utilize the light-weight policy network to predict the modules and parameters during inference.

### Ablation Study and Analysis

**Adaptive ISP.** We perform a study to show that different data require different ISP pipelines to achieve the best performance. To accomplish this, we begin by gathering the various ISP pipelines predicted by our method on the LOD dataset. Next, we select the three most representative ISP pipelines along with their corresponding input raw images, resulting in three subsets of the LOD dataset. The specifics of these three distinct ISP pipelines can be found in Figure 5. Finally, we conduct cross-testing on the three sets of ISP pipelines generated by our method using the three subsets, as depicted in Figure 5. By analyzing the experimental results, we can see that only the

   Methods & mAP@0.5 & mAP@0.5:0.95 \\  Hyperparameter Optimization  & 46.4 & 28.4 \\ Attention-aware Learning  & 45.5 & 27.9 \\ ReconfigISP  & 42.1 & 25.2 \\ Refactoring ISP  & 40.6 & 24.7 \\  Ours & **47.0** & **28.8** \\   

Table 2: Image Segmentation results on raw COCO datasets .

Figure 4: Image segmentation visualization results on raw COCO dataset. Our method detects all the object, while the state-of-the-art methods  may miss some.

most matching pipeline can achieve the best results, otherwise, it will lead to varying degrees of performance degradation, which also proves that there are different pipeline requirements in different scenarios.

**Module preferences of different images.** Furthermore, we analyze the reasons why different ISP pipelines are necessary for various scenarios. The LOD dataset provides JPEG images with accompanying metadata, which serves as a convenience for the analysis of our experimental results.

It is noticed that there are two different choices at the first stage of the three ISP pipelines: CCM and Desaturation. The High ISO (ISO6400, ISO3200) and high noise level cases tend to favor the Desaturation module, whereas low ISO (ISO800, ISO1600) and low noise level cases tend to prefer the CCM module, as shown in Figure 5. Because Desaturation can reduce the color noise and saturation, high ISO images with high-level noise prefer it. CCM can remove color casts and enhance color saturation. Therefore, it is the best choice is CCM for low-ISO images.

Subsequently, we observe a divergence between the second and third ISP pipelines during the third stage. While the second ISP pipeline opts for the Tone Mapping module, the third ISP pipeline favors the White Balance module. Upon the analysis of the images subsequent to the second stage, we observe a pronounced color cast problem, particularly prevalent when the overall brightness was relatively high. In such scenarios, the most suitable course of action is to opt for the White Balance module. Conversely, when dealing with images characterized by a high dynamic range, such as those containing electric lights or direct sunlight, it becomes evident that the superior choice is to employ the Tone Mapping module.

Finally, when summarizing the commonalities among the three ISP pipelines, several key conclusions emerge: i) The color correction module notably enhances detection performance (distinct from color correction for image quality tasks). However, optimal choices vary for images with different brightness and noise levels. ii) The Sharpen/Blur module holds a significant position, either enhancing or blurring the image to align with the detection network. iii) Tone Mapping also plays a crucial role,

   Detectors & Methods & mAP@0.5 & mAP@0.75 & mAP@0.5:0.95 \\  YOLO-v3  & RGB & 55.6 & 40.9 & 37.4 \\
**Ours** & **71.4** & **51.7** & **47.1** \\  YOLOX  & RGB & 57.0 & 43.5 & 39.2 \\
**Ours** & **69.7** & **51.4** & **47.2** \\  DDQ  & RGB & 50.3 & 42.0 & 35.9 \\
**Ours** & **74.0** & **58.1** & **52.0** \\  LOD & Subset 1 & & Subset 2 & Subset 3 \\  Representative Images & & & & \\  Metrics & mAP@0.5 & mAP@0.75 & mAP@0.5 & mAP@0.75 & mAP@0.5 & mAP@0.75 \\  Pipeline 1 & & **63.0** & **39.8** & 82.1 & 66.8 & 78.2 & 64.5 \\  Pipeline 2 & & **62.1** & 39.6 & **82.7** & **68.9** & **79.2** & 65.2 \\  Pipeline 3 & & **62.4** & 39.5 & 82.4 & 67.8 & 79.1 & **65.4** \\   

Table 3: Experimental results of different detectors on LOD dataset. Note that the DDQ  and YOLOX  do not participate in our training process. All detectors using our method demonstrate improved detection performance.

Figure 5: The cross-validated result of different ISP pipelines and its sub-dataset on LOD datasets. Only the most matching pipeline can achieve the best results, which proves that a different pipeline is necessary.

enhancing detection accuracy by adjusting the overall color and brightness. iv) Denoising, contrary to previous research conclusions, is not deemed crucial. This finding contributes to substantial computational cost savings for the ISP. These analyses and conclusions provide valuable insights for the future designs of ISPs tailored to specific downstream tasks.

**Adaptive Trade-off.** To demonstrate that our model can achieve an adaptive trade-off between efficiency and accuracy during the inference phase, we use stages to represent the number of ISP modules. Recall that none of the previous algorithms support dynamic efficiency-accuracy trade-off. Hyper-parameter Optimization  and Attention-aware Learning  are optimized based on handcrafted ISP, so the time consumption cannot be changed during the inference phase. Although ReconfigISP  and Refactoring ISP  have optimized ISP pipelines and parameters for specific tasks, the ISP pipelines and parameters remain fixed during inference. As shown in Table 5, our method only requires 3 stages to achieve the best performance on the LOD dataset and reaches a good trade-off between efficiency and accuracy. Moreover, this trade-off happens at inference time, without any retraining, and supports the dynamic update of the trade-off strategy.

## 5 Conclusion

In this paper, we introduce AdaptiveISP, a novel approach that leverages deep reinforcement learning to automatically generate an optimized ISP pipeline and associated parameters, maximizing detection performance with a pre-trained object detection network. Our method incorporates several key innovations. Firstly, we formulate the ISP configuration process as a Markov Decision Process, allowing reinforcement learning to autonomously discover an optimal pipeline and parameters for specific high-level computer vision tasks. Secondly, to account for computational costs associated with different ISP modules, we introduce a penalty of computational time. Comprehensive experiments demonstrate that AdaptiveISP surpasses existing state-of-the-art methods, and dynamically manages the trade-off between performance and computational cost. Furthermore, we conduct a detailed analysis of individual modules within ISP configurations, offering valuable insights for future ISP designs tailored to specific downstream tasks. The present approach relies on the utilization of differentiable ISP modules in research, with future endeavors aimed at exploring non-differentiable ISP methodologies.

    &  &  &  &  &  &  &  & mAP & mAP & mAP &  \\  & & & & & Blitz & Mongege & Contrast & & Satisfactory & Densification & Balance &  & 0.75 & 0.50.95 &  \\  Time (ms) & 17 & 20 & 19 & 63 & 10 & 27 & 2.1 & 2.0 & 19 & 1.7 & - & - & - \\  \(=0\) & 0.97 & 0.97 & 99.95\% & 100\% & 0.94 & 100\% & 0.24\% & 79.56 & 100\% & 22.59 & **74.24** & **51.7** & **41.73** \\ \(=-3\) & 4.79\% & 18 & 35.5\% & 100\% & 0.98 & 59.75\% & 31.5\% & 32.1\% & 14.9\% & 96.5\% & 71.1 & 51.5 & 47.0 & 14.5 \\ \(=-2\) & 57.5\% & 56.2\% & 100\% & 0.98 & 42.7\% & 37.75\% & 31.9\% & 14.9\% & 71.0 & 31.6 & 47.0 & 11.54 \\ \(=-2\) & 100\% & 75 & 100\% & 0.98 & 0.98 & 40.5\% & 49.75\% & 92.5\% & 100\% & 80.0 & 49.9 & 46.0 & 9.26 \\ \(=-1\) & 100\% & 0.75\% & 99.5\% & 0.98 & 0.98 & 0.98 & 0.97\% & 99.17\% & 100\% & 69.9 & 50.1 & 45.9 & **9.20** \\   

Table 4: Experimental results considering computational cost on LOD dataset . \(_{c}=0.0\) represents the accuracy-oriented, \(_{c}=0.1\) stands for efficiency-oriented. The total time represents the average running time of each sample. The efficiency-oriented method has a significant reduction in the average running time for each sample, which is accompanied by a slight decrease in performance. As \(_{c}\) increases, our method tends to favor faster-executing modules.

   Methods & Stages & mAP@0.5 & mAP@0.75 & mAP@0.5:0.95 \\  Hyperparameter Optimization  & 10 & 70.1 & 49.7 & 46.1 \\ Attention-aware Learning  & 10 & 70.9 & 51.0 & 46.6 \\ ReconfigISP  & 5 & 69.4 & 49.6 & 45.6 \\ Refactoring ISP  & 6 & 68.3 & 47.6 & 44.1 \\   & 1 & 69.6 & 49.8 & 45.7 \\  & 2 & 70.9 & 51.1 & 46.6 \\   & 3 & 71.3 & 50.7 & 46.9 \\   & 4 & 71.4 & 51.6 & 47.1 \\   & 5 & **71.4** & **51.7** & **47.1** \\   

Table 5: Comparison of object detection performance at different stages on the LOD dataset . Our approach attains optimal performance with just two stages and dynamically achieves a trade-off between object performance and computational cost.