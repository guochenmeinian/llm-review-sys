# Shape Non-rigid Kinematics (Snk):

A Zero-Shot Method for Non-Rigid Shape Matching

via Unsupervised Functional Map Regularized

Reconstruction

 Souhaib Attaiki

LIX, Ecole Polytechnique, IP Paris

attaiki@lix.polytechnique.fr

&Maks Ovsjanikov

LIX, Ecole Polytechnique, IP Paris

maks@lix.polytechnique.fr

###### Abstract

We present Shape Non-rigid Kinematics (**Snk**), a novel zero-shot method for non-rigid shape matching that eliminates the need for extensive training or ground truth data. **Snk** operates on a single pair of shapes, and employs a reconstruction-based strategy using an encoder-decoder architecture, which deforms the source shape to closely match the target shape. During the process, an unsupervised functional map is predicted and converted into a point-to-point map, serving as a supervisory mechanism for the reconstruction. To aid in training, we have designed a new decoder architecture that generates smooth, realistic deformations. **Snk** demonstrates competitive results on traditional benchmarks, simplifying the shape-matching process without compromising accuracy. Our code can be found online: https://github.com/pvnieo/SNK.

## 1 Introduction

Shape matching, specifically non-rigid shape matching, is a fundamental problem in Computer Vision, Computational Geometry, and related fields. It plays a vital role in a wide range of applications, including statistical shape analysis , deformation , registration , and texture transfer , among others. This problem involves finding a correspondence between two shapes that may differ due to non-rigid deformations, such as bending, stretching, or compression.

Traditional methods for addressing this problem have predominantly been axiomatic, offering several benefits, such as theoretical guarantees  and their application in different scenarios . Some of these methods include intrinsic isometries-based methods , parametrization domain-based methods , and functional map methods . However, these methods often heavily rely on the availability of good initialization  or the use of handcrafted descriptors . This dependence can be a limiting factor, constraining the performance of these methods and making them less effective in situations where these requirements cannot be adequately met.

Learning-based approaches have emerged as an alternative to these traditional methods, with notable examples including Deep Functional Maps methods , dense semantic segmentation methods , or template-based methods  which have shown significant promise in solving the shape-matching problem. The strength of these methods lies in their capacity to learn features and correlations directly from data, outperforming handcrafted descriptors. However, these techniques introduce a significant challenge. Even when the task is to match just a single pair of shapes, these methods necessitate the collection and training on a large data set, often in the tens of thousands . The demand for these extensive data collections, coupled with the long training times that can extend into days , can be particularly onerous.

Our proposed method, Shape Non-rigid Kinematics (**S**N**k), positions itself uniquely in this landscape, combining the benefits of both axiomatic and learning-based approaches while addressing their limitations.

In particular, **S**N**k works directly on a given pair of shapes, without requiring any prior training. This removes the need for large data sets or pre-existing examples. Unlike axiomatic methods, however, that rely on fixed input features such as HKS or SHOT, we employ a deep neural network for feature computation. As we demonstrate below, this use of a neural network introduces a significant prior for our method, setting it apart from purely geometric approaches. We thus refer to our method as "zero-shot" to highlight its ability to be trained on a single pair of shapes, while using a neural network for feature learning.

**S**N**k is applied to each pair individually using a reconstruction-based strategy that employs an encoder-decoder architecture. By doing so, **S**N**k effectively deforms the source shape to closely match the target shape. A point-to-point map is then extracted by a simple nearest neighbor between the target and the deformed source.

At the heart of our method lies the functional map paradigm. In our approach, a functional map is generated in an unsupervised manner and then converted into a point-to-point map. This map is subsequently used as supervision for the decoder, ensuring the accuracy of the shape reconstruction process. To confine the deformation to plausible transformations, we introduce a new decoder architecture that is grounded on the PriMo energy . Lastly, our method is trained using losses in both the spatial (reconstruction) and spectral (functional map) domains, ensuring comprehensive performance improvement.

Overall, our contributions can be summarized as follows:

* We have devised a new decoder architecture rooted in the PriMo energy concept. This architecture facilitates the production of deformations that appear smooth and natural.
* We have shown that a loss function, which imposes penalties on both spatial and spectral quantities, is adequate for deriving matches on a single pair of shapes without any prerequisite training.
* We have developed a method for zero-shot shape matching that attains state-of-the-art results among methods that are not trained on shape collections. Furthermore, it competes with, and frequently outperforms, several supervised training-based approaches.

Figure 1: **Method overview**. Given two shapes as input, we deform a source shape to resemble the target. Our network can be trained using just a single pair of shapes and uses a combination of spatial and spectral losses, as well as a regularization on the decoder.

Related Works

Non-rigid shape matching is a widely researched subject, and providing a comprehensive overview is beyond the scope of this paper. However, we will briefly discuss methods closely related to ours. For a more detailed exploration, we encourage interested readers to refer to recent surveys .

Functional MapOur method is built upon the functional map paradigm, which since its introduction , has been widely used for nonrigid shape matching . It offers a distinct advantage by transforming the complexity of pointwise maps optimization, originally quadratic relative to the vertex count, into a more manageable process of optimizing a functional map (which consists of small quadratic matrices), making the optimization process feasible, see  for an overview.

In the pursuit of identifying the functional map, initial studies depended on handcrafted feature functions defined on both source and target shapes, such as HKS , WKS , and SHOT  features. Subsequent research enhanced this pipeline by incorporating extra regularization , adjusting it to accommodate partial shapes , and suggesting efficient refinement techniques . Contrarily, while these techniques often rely on an initial map for refinement or handcrafted features that lack robustness , our approach distinctively learns features by precisely fitting the source and target shapes using a neural network.

Learning-based Methods for Shape MatchingThe field of shape matching has recently seen a surge in success with learning-based methods. These approaches take on various forms, including framing the issue as a segmentation problem, which involves training a network to segment each vertex on the source shape into a class corresponding to a vertex ID on a template shape . Other methods include template fitting, which deforms a template to align with source and target shapes , and the use of functional maps .

The latter method involves a neural network that extracts features from source and target shapes to predict the functional map, which is then transformed into a point-to-point map. This innovative line of research was pioneered by FMNet  and subsequently expanded in numerous studies . These studies used ground-truth functional maps for supervision.

Simultaneously, a parallel line of research focuses on unsupervised learning, which proves to be beneficial when ground truth correspondences are unavailable. These methods ensure structural properties like bijectivity and orthonormality on functional maps in the reduced basis , penalize the geodesic distortion of the predicted maps , or harmonize intrinsic and extrinsic shape alignment .

However, unlike axiomatic approaches, these methods are typically not competitive when applied on a single pair without prior training. In contrast, our method, though it is based on a neural network, can be directly applied to a single pair without any prerequisite training.

Shape ReconstructionOur method employs an encoder-decoder framework to deform the source shape to fit the target shape. One significant challenge in this domain is crafting a shape decoder architecture capable of generating a 3D shape from a latent code. Early efforts in this field, such as those by Litany _et al._, Ranjan _et al._, and Bouritsas _et al._, built on graph architecture, defining convolution, pooling, and unpooling operations within this structure. However, they presumed uniform triangulation across all shapes, rendering them ineffective for shape matching.

Other methods, such as Zhang _et al._, predict occupancy probabilities on a 3D voxel grid, but the resource-intensive nature of dense, volumetric representations restricted resolution. Different approaches decod shapes as either raw point clouds  or implicit representations . Nevertheless, these methods overlooked the point ordering, making them unsuitable for matching.

In our work, we propose a novel decoding architecture, which leverages the architecture of DiffusionNet  as a foundational element. Our approach computes a rotation and a translation matrix for every face on the source shape to align with the target shape. While previous methods relied on energies such as As-Rigid-As-Possible (ARAP) , Laplacian , or edge contraction  to restrict the decoder, our approach is adept at using the PriMo energy . This energy encourages smooth, natural deformations that effectively preserve local features, particularly in areas of bending , providing a more constrained and intuitive approach to shape deformation.

Notation & Background

Our work adopts the functional map paradigm  in conjunction with the PriMo energy . In the following section, we briefly introduce these concepts, where we will use consistent notation throughout the paper.

### Notation

Given a 3D shape \(S_{i}\) composed of \(n_{i}\) vertices and represented as a triangular mesh, we perform a cotangent Laplace-Beltrami decomposition  on it. The first \(k\) eigenvalues of \(S_{i}\) are captured in the matrix \(_{i}^{n_{i} k}\). We also create a diagonal matrix \(_{i}^{k k}\), where the diagonal elements hold the first \(k\) eigenvalues of \(S_{i}\).

Next, the diagonal matrix of area weights, \(M_{i} R^{n n}\), is defined. It's worth mentioning that \(_{i}\) is orthogonal in relation to \(M_{i}\), and that \(_{i}^{}M_{i}_{i}\) is equivalent to the \(^{k k}\) identity matrix, denoted as \(I_{k}\). Lastly, we represent \(_{i}^{}=_{i}^{}M_{i}\) using the (left) Moore-Penrose pseudo-inverse symbol, \({}^{}\).

### Functional Map Pipeline

Denoting source and target shapes as \(S_{1}\) and \(S_{2}\), we define a pointwise map, \(T_{12}:S_{1} S_{2}\), encapsulated in binary matrix \(_{12}^{n_{1} n_{2}}\). To manage its quadratic growth with vertex count, we employ the functional map paradigm , yielding a \((k k)\) size functional map \(C_{21}=_{1}^{}_{12}_{2}\), with \(k\) usually around 30, making the optimization process feasible.

Feature functions \(F_{1}\) and \(F_{2}\) are then derived from \(S_{1}\) and \(S_{2}\) respectively, with their spectral coefficients calculated as \(_{i}=_{i}^{}F_{i}\). This enables the formulation of an optimization problem:

\[*{arg\,min}_{}\|_{1}-_{2 }\|_{F}^{2}+\|_{1}-_{2}\|,\] (1)

where \(\) is the desired functional map and the second term is a regularization to promote structural correctness . Finally, the point map \(_{21}\{0,1\}\) is derived from the optimal \(_{12}\), based on the relationship \(_{2}_{12}_{21}_{1}\), using methods such as nearest neighbor search or other post-processing techniques [18; 50].

### PriMo Energy: Prism Based Modeling

The PriMo approach, introduced in , is a prominent method in shape deformation , employing a model that mimics the physically plausible behavior of thin shells and plates [70; 71]. In this model, a volumetric layer is formed by extruding the input mesh along vertex normals, thus generating rigid prisms for each mesh face (refer to Fig. 2). These prisms are interconnected by elastic joints, which stretch under deformation--the extent of this stretch effectively determines the deformation energy. Interestingly, this formulation permits a unique global minimum of the energy in the undeformed state, with any form of bending, shearing, twisting, or stretching causing an increase in this energy.

We elaborate on the elastic joint energy using the notation in Fig. 2. Two adjacent prisms, denoted \(P_{i}\) and \(P_{j}\), are considered. In their undeformed state, they share a common face that might no longer match after deformation. The face of \(P_{i}\) adjacent to \(P_{j}\) is defined as a rectangular bi-linear patch \(^{i j}(u,v)\), which interpolates its four corner vertices. The corresponding opposite face is denoted as \(^{j i}(u,v) P_{j}\). The energy between \(P_{i}\) and \(P_{j}\) is thus defined as:

\[E_{ij}:=_{^{2}}\|^{i j}(u,v)-^{j  i}(u,v)\|^{2}dudv\] (2) \[E:=_{\{i,j\}}w_{ij} E_{ij}, w_{ij}:=_{ij}\|_{2}^{2}}{|F_{i}|+|F_{j}|}\] (3)

Here, \(E\) is the deformation energy of the whole mesh, and the energy contribution from each pair \(P_{i}\), \(P_{j}\) is influenced by the areas of their corresponding mesh faces \(F_{i}\), \(F_{j}\), and the squared length of their shared edge \(_{ij}\). In the original PriMo paper, users are allowed to dictate the positions and orientations of some prisms, while an optimization technique is deployed to minimize the total deformation energy. In contrast, in our approach, the deformation is the result of the decoder's output and the PriMo energy is utilized to regularize it.

## 4 Method

In this section, we delve into our proposed method for zero-shot matching, which consists of two primary modules. The initial (functional map) module, is responsible for predicting functional maps between the source and target shapes and converting these into point-to-point (p2p) maps. The second module, an encoder-decoder, encodes the target shape into a latent code. Subsequently, the decoder utilizes this latent code to morph the source shape to align with the target shape.

Diverging from previous studies, we incorporate losses in _both_ the spatial and spectral domains. Spatially, we utilize the p2p map, as predicted by the functional map module, to ensure the reconstruction closely resembles the target. Spectrally, we enforce structural properties such as bijectivity and orthogonality on the functional map. Furthermore, to facilitate the learning process, we minimize the PriMo energy on the decoder, which ensures it generates a natural-looking and smooth deformation.

In the subsequent sections, we elaborate on each stage of our proposed model, and we will use the same notation as Sec. 3.

### Functional Map Module

The functional map module is designed with a two-fold objective - to predict both fmap and p2p maps reciprocally between the source and target shapes. This module is composed of two key elements: the feature extractor and the fmap solver, as illustrated in Fig. 1.

The feature extractor's purpose is to extract features from the raw geometry that are robust to shape deformation and sampling, which are later employed for predicting the fmap. To achieve this, we use the DiffusionNet architecture , following the recent approaches in the domain . The feature extractor processes both the target and the source shapes, \(S_{1}\) and \(S_{2}\) respectively, and extracts pointwise features in a Siamese manner, denoted as \(F_{1}\) and \(F_{2}\).

Following the feature extraction, the fmap solver accepts the features \(F_{1}\) and \(F_{2}\), and predicts an initial approximation of the fmaps \(_{12}^{0}\) and \(_{21}^{0}\) utilizing Eq. (1). These fmaps are matrix solutions to the least square optimization, and thus do not necessarily originate from p2p maps. To rectify this, we draw inspiration from recent methodologies  and predict a new set of fmaps that stem from p2p maps. Initially, we transform the preliminary fmaps into an early estimation of p2p maps by applying:

Figure 2: **PriMo construction**. The mesh vertices are represented as white circles. The elastic joints are colored yellow.

\[^{0}_{21}(i,j)=_{2},G^{j}_{1} /)}{_{k=1}^{n_{1}}( G^{i}_{2},G^{k}_{1} /)}.\] (4)

Here, \(G_{1}=_{1}\), \(G_{2}=_{2}^{0}_{12}\), \(^{0}_{21}\) is a soft p2p map predicted in a differentiable manner, \(,\) represents the scalar product, and \(\) denotes a temperature parameter. We predict \(^{0}_{12}\) in a comparable way, followed by predicting the final fmaps \(_{12}\) and \(_{21}\) that arise from p2p maps using the definition \(_{ij}=^{}_{j}^{0}_{ij}_{i}\). Ultimately, we estimate the final p2p map \(_{ij}\) from \(_{ji}\) by applying Eq. (4) for a second time. This procedure aligns with two iterations of the ZoomOut algorithm .

### Shape Reconstruction Module

The goal of the shape reconstruction module is to deform the source shape to match the target shape. It is composed of a encoder that extract a latent code that summarize the target shape, and a decoder that takes the latent code as well as the source shape and deform it to match the target.

The encoder is a DiffusionNet network , that takes the 3D coordinates of the target shape, and produce a \(d_{1}\)-dimentional vertex-wise features. A max pooling is applied in the vertex dimension to obtain a latent code \(l^{d_{1}}\).

The prism decoderWe introduce a novel architecture for the decoder, utilizing DiffusionNet at its core. An overview of this architecture is presented in Fig. 3. The decoder receives two inputs: the 3D coordinates of the source shape and the latent code \(l\). The latent code is duplicated and combined with the XYZ coordinates, which are subsequently inputted into the DiffusionNet architecture. This process generates vertex-wise features \(D^{n_{2} d_{2}}\) of dimension \(d_{2}\).

These vertex-wise features \(D\) are then transformed into face-wise features \(G^{f_{2} d_{2}}\), where \(f_{2}\) denotes the number of faces of the source shape. This transformation is achieved via mean pooling, where the three features corresponding to the vertices constituting each face are averaged: \(G_{i}=_{j_{i}}D_{j}\), with \(_{i}\) representing the \(i^{}\) face of the target shape.

These features are further refined by a compact network composed of pointwise linear layers and ReLU nonlinearities, producing outputs \(H^{f_{2} 12}\). The first three features are interpreted as a translation vector \(t_{i}\), and the final nine features are reshaped into a \(3 3\) matrix \(R^{0}_{i}\). This matrix is subsequently transformed into a rotation matrix \(R_{i}\) by solving the Orthogonal Procrustes problem :

\[R=*{arg\,min}_{}\|-R^{0}\|_{F} ^{}=I_{3}.\] (5)

Figure 3: **Prism Decoder**. Our novel architecture, built upon DiffusionNet, initiates the process by extracting per-vertex features, which are subsequently consolidated into per-face features. These features are then processed by a Multilayer Perceptron (MLP) to generate per-face rotation and translation, which are used to rigidly transform the input faces. The transformed faces are then consolidated to produce the final reconstruction.

With \(t_{i}\) and \(R_{i}\) defined for each face, we transform the original source shape's faces \(\), resulting in a new set of faces \(^{}\). The vertices of the decoded shape are then constructed by averaging the new face coordinates' positions for all the faces they belong to.

### Training Procedure

Our method operates in a zero-shot manner, meaning that it is trained on each new pair of shapes independently. This approach merges the benefits of axiomatic methods, which do not rely on large training sets and extended training periods, and the advantages of learning methods, which facilitate matching through _learned_ features, transcending the limitations of handcrafted features used in axiomatic methods.

The process of our method unfolds as follows: the target and source shapes, designated \(S_{1}\) and \(S_{2}\), are processed through the functional map module. The output of this stage comprises the fmap and p2p maps, represented as \(_{ij}\) and \(_{ij}\). Concurrently, a latent code, \(l\), is extracted via the encoder and employed to deform the source shape to align with the target shape. The resulting deformed shape, \(S_{3}\), maintains the same triangulation as the source shape. Utilizing all these outputs, a loss, denoted as \(\), is computed, which subsequently guides the optimization of the parameters of the various networks through gradient descent. This process is iteratively executed until either the loss ceases to decrease or the maximum number of iterations is achieved. The output that yields the lowest loss is ultimately chosen for matching.

In this context, a p2p map between the source and target shape, known as \(T_{21}^{0}\), is derived by performing a nearest neighbor search between the reconstructed shape \(S_{3}\) and the target shape \(S_{1}\). As suggested in previous works [27; 52; 25; 29; 64; 26], we refine this map by applying the ZoomOut algorithm . This method enhances the map by iterating between the spectral and spatial domains, gradually augmenting the number of spectral basis functions. The refined map, \(T_{21}\), is then employed for evaluation.

Loss functionIn training our network, we employ multiple loss functions. Contrary to prior works [29; 28; 36; 35] that solely utilize either spatial or spectral losses, our method synergistically integrates both types for enhanced performance. The overall loss function is as follows:

\[=_{}_{}+_{}_{}+_{}_{ }+_{}_{}\] (6)

We denote \(_{i}\) as the XYZ coordinates of shape \(S_{i}\). The Mean Square Error (MSE) loss, \(_{}\), is employed to ensure that the reconstructed shape closely resembles the target shape using the predicted p2p map, it's calculated as \(_{}=\|_{21}_{1}-_{3}\|_{ F}^{2}\).

The fmap loss, \(_{}\), is used to regularize the structural properties of the predicted fmaps, such as bijectivity and orthogonality : \(_{}=\|_{ij}_{ji}-I_{k}\|_{F}^{2}+ \|_{ij}^{}_{ij}-I_{k}\|_{F}^{2}\). The bijectivity constraint ensures that the map from \(S_{i}\) through \(S_{j}\) and back to \(S_{i}\) is the identity map, while the orthogonality constraint enforces local area preservation of the map.

The cycle loss, \(_{}\), enforces cyclic consistency between predicted p2p maps: \(_{}=\|_{12}_{21}_{1}- _{1}\|_{F}^{2}\). Lastly, the primo energy, \(_{}\), is employed to encourage the decoder to yield a coherent shape and to ensure the deformation appears smooth and natural, facilitating the training process. It is calculated as the energy \(E\) from Eq. (3).

## 5 Results

In this section, we evaluate our method on different challenging shape matching scenarios.

### Datasets

Our experimental setup spans two tasks and involves four distinct datasets referenced in previous literature, incorporating both human and animal representations.

For near-isometric shape matching, we employed several standard benchmark datasets, namely, **Faust**, **Scape**, and **Shrec'19**. To enhance the complexity, we selected the remeshed versions of these datasets, as suggested in [29; 25; 48], instead of their original forms. The **Faust**dataset contains 100 shapes, depicting 10 individuals in 10 different poses each, with our evaluation focused on the last 20 shapes. The **Scape** dataset comprises 71 distinct poses of a single person, and we based our assessment on the final 20 shapes. The **Shrec** dataset, with its notable variations in mesh connectivity and poses, presents a more significant challenge. It consists of 44 shapes and a total of 430 evaluation pairs. For unsupervised methods, we used the oriented versions of the datasets as detailed in . Moreover, for training methods, we showcase their optimal performance on **Shrec** using a model trained either on **Faust** or **Scape**.

In the context of non-isometric shape matching, we conducted our experiments using the SMAL animal-based dataset [78; 79], hereinafter referred to as **Smal**. This dataset includes 50 distinct, non-rigid 3D mesh models of organic forms. We divided these into two equal sets of 25 for training and testing, ensuring that the specific animals and their poses used for testing were not seen during the training phase.

### Near-Isometric Shape Matching

In this section, we evaluate our method's performance in near-isometric, non-rigid shape matching. We draw comparisons with several contemporary approaches in the field of non-rigid shape matching. These can be broadly divided into three categories. The first category is axiomatic approaches and it includes BCICP , ZoomOut , Smooth Shells , and DiscreteOp . The second category is supervised learning approaches and it comprises methods such as 3D-CODED , FMNet , GeomFmaps , DiffGeoFMNet , and TransMatch . Finally the third category is unsupervised learning approaches and it includes Unsupervised FMNet , SURFMNet , Cyclic FMaps , Weakly Supervised FMNet , DeepShells , and NeuroMorph .

To evaluate all correspondences, we adopt the Princeton protocol, a method widely used in recent works [24; 25; 27; 29; 35]. Specifically, we calculate the pointwise geodesic error between the predicted maps and the ground truth map, normalizing it by the square root of the target shape's total surface area.

Results are presented in Table 1. As can be seen, our method outperforms axiomatic approaches and is comparable or superior to some training-based methods, particularly on the **Faust** and **Scape** datasets. When it comes to the **Shrec** dataset, our method achieves state-of-the-art results across _all methods_. Most learning-based methods stumble over this challenging dataset, even though they have been trained on many training examples. This is because of the wide mix of poses and identities in the

   } &  &  &  \\   & +\@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ +\@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ .\)}} & 6.4 & 11 & - \\  & +\@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ .\)}} & 6.1 & 7.5 & - \\  & \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ .\)}} & 2.5 & 4.7 & 12.2 \\  & ]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\ \@@cite[cite]{[\@@bibref{}{DBL}{}{}]} \\   

Table 1: **Quantitative Results on Near-Isometric Benchmarks**. The **best** and **second**-best results are highlighted. Our method comes out on top among axiomatic methods and matches or even surpasses some trained methods.

dataset. This highlights how our approach, which focuses on overfitting a single pair, is particularly effective in such challenging cases.

In Fig. 4, we showcase point-to-point maps generated by our method on the **Shrec** dataset. We compare these maps to those produced by the best-performing baseline method across each category - axiomatic, unsupervised, and supervised. Upon inspection, it is apparent that our method attains highly accurate correspondences. In contrast, the baseline methods either fail to achieve a precise matching or suffer from symmetry flip issues.

### Non-Isometric Shape Matching

In the non-isometric, non-rigid context, we adhered to the same evaluation protocol and present our findings in Table 2. It can be seen from these results that our method outperforms both the axiomatic and unsupervised approaches, and competes strongly with, or even surpasses, some supervised techniques. This further demonstrates the efficacy and versatility of our method across diverse shape-matching scenarios.

  
**Method** & **SMAL** \\   & 47.1 \\  & 8.8 \\  & **6.6** \\  & 20 \\  & 13.3 \\  & 15.2 \\  & 23.1 \\ } & Smooth Shells  & 16.3 \\  & **9.1** \\  

Table 2: **Quantitative results on the non-isometric benchmark**. We highlight the **best** and the second best results. Our method achieves competitive results with trained methods.

Figure 4: **Qualitative Results** from the **Shrec** dataset. The correspondences are visualized by transferring a texture through the map. Our method results in visually superior outcomes.

In Fig. 5, we present qualitative examples of non-isometric and non-homeomorphic matching from the **Smal** and **Shrec** datasets, respectively. The results further highlight the resilience of our approach to various deformations and topological changes.

### Ablation Studies & Additional Details

In the supplementary material, we present an ablation study that underscores the efficacy of each component introduced in our methodology. Additionally, we provide comprehensive details regarding the implementation process, the computational specifications involved, as well as some qualitative results.

Importance of the neural priorIn the supplementary we also evaluate the importance of using neural networks for training our method. In particular, we show that when unconstrained optimization replaces neural networks, the results degrade significantly. This illustrates the importance of the "neural prior" [83; 84] employed by our method and further highlights the difference between our approach and purely axiomatic methods.

## 6 Conclusion & Limitations

In this work, we introduced **Snk**, a novel approach to zero-shot shape matching that operates independently of prior training. Our method hinges on the precise alignment of a pair of shapes, enabling the source shape to be deformed to match the target shape without any user intervention. By integrating both spatial and spectral losses, and architecting a new decoder that encourages smooth and visually pleasing deformations, our method has proven its effectiveness. Extensive experiments reveal that our approach competes with, and often surpasses, many supervised techniques, even achieving state-of-the-art results on the **Shrec** dataset.

Despite its success, **Snk** has certain limitations we aim to address in future research. Firstly, our method is currently tailored towards complete shape correspondence, necessitating adaptation for partial shape-matching scenarios. Secondly, while our method's convergence time of approximately 70 seconds per shape outpaces many competitors, exploring ways to further expedite this process would be beneficial. Finally, our method utilizes DiffusionNet as a backbone, which theoretically could accommodate both point clouds and triangular 3D meshes. Consequently, extending our approach to encompass other types of representations could prove useful.

AcknowledgementsThe authors would like to thank the anonymous reviewers for their valuable suggestions. Parts of this work were supported by the ERC Starting Grant No. 758800 (EXPROTEA) and the ANR AI Chair AIGRETTE.

Figure 5: Examples of non-isometric and non-homeomorphic matching on the **Smal** and **Shrec** datasets, respectively.