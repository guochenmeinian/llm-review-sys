# Interpreting the Weight Space

of Customized Diffusion Models

 Amil Dravid\({}^{*1,2}\)

Yossi Gandelsman\({}^{*1}\)

Kuan-Chieh Wang\({}^{2}\)

Rameen Abdal\({}^{3}\)

Gordon Wetzstein\({}^{3}\)

Alexei A. Efros\({}^{1}\)

Kfir Aberman\({}^{2}\)

\({}^{1}\)UC Berkeley \({}^{2}\)Snap Inc. \({}^{3}\)Stanford University

###### Abstract

We investigate the space of weights spanned by a large collection of customized diffusion models. We populate this space by creating a dataset of over 60,000 models, each of which is a base model fine-tuned to insert a different person's visual identity. We model the underlying manifold of these weights as a subspace, which we term _weights2weights_. We demonstrate three immediate applications of this space that result in new diffusion models - sampling, editing, and inversion. First, sampling a set of weights from this space results in a new model encoding a novel identity. Next, we find linear directions in this space corresponding to semantic edits of the identity (e.g., adding a beard), resulting in a new model with the original identity edited. Finally, we show that inverting a single image into this space encodes a realistic identity into a model, even if the input image is out of distribution (e.g., a painting). We further find that these linear properties of the diffusion model weight space extend to other visual concepts. Our results indicate that the weight space of fine-tuned diffusion models can behave as an interpretable _meta_-latent space producing new models.1

Code: https://github.com/snap-research/weights2weights

Figure 1: _weights2weights (w2w)_ space enables controllable creation of new customized diffusion models. We model a manifold of customized diffusion models as a subspace of weights that encodes different instances of a broad visual concept (e.g., human identities, dog breeds, etc.). This forms a space that supports inverting the subject (e.g., identity) from a single image into a model, editing the subject encoded in the model, and sampling new models that encode new instances of the visual concept. Each of these operations results in a new model that can consistently generate the subject.

## 1 Introduction

Generative models have emerged as a powerful tool to model our rich visual world. In particular, the latent space of single-step generative models, such as generative adversarial networks (GANs) [18; 28], has been shown to linearly encode meaningful concepts in the output images. For instance, datasets of latent vectors were used to discover linear directions in the GAN latent space encoding different attributes (e.g., gender or age of faces) [20; 60]. Even earlier, datasets of images and keypoints were leveraged to discover subspaces of facial shape and appearance [6; 53].

We aim to extend this even further, using datasets of model weights instead datasets of images or latents. Can we discover such interpretable subspaces in the model weights themselves? Recently introduced personalization approaches, such as Dreambooth  or Custom Diffusion , may hint that this is the case. These methods aim to learn an instance of a subject, such as a person's visual identity. Rather than searching for a latent code that represents an identity in the input noise space, these approaches customize diffusion models by fine-tuning on subject-specific images, which results in identity-specific model weights. We therefore hypothesize that a latent space can exist _in the weights themselves._

To test our hypothesis, we fine-tune over 60,000 personalized models on individual identities to obtain points that lie on a manifold of customized diffusion model weights. To reduce the dimensionality of each data point, we use low-rank approximation (LoRA)  during fine-tuning and further apply Principal Components Analysis (PCA) to the set of data points. This forms our final space: _weights2weights_ (\(w2w\)). Unlike traditional generative models like GANs, which model the pixel space of images, we model the _weight space_ of these personalized models. Thus, each sample in our space corresponds to an identity-specific model which can consistently generate that subject. We provide a schematic in Fig. 2 that contrasts a typical latent space with our proposed \(w2w\) space, demonstrating the differences and analogies between these two representations. \(w2w\) space can be thought of as a _meta_-latent space, enabling controllable creation of new models instead of just images like a traditional latent space.

Creating this space unlocks a variety of applications that involve traversal in \(w2w\) (Fig. 1). First, we demonstrate that sampling model weights from \(w2w\) space corresponds to a new model encoding a novel subject. Second, we find linear directions in this space corresponding to semantic edits of the identity. Finally, we show that enforcing weights to live in this space enables a diffusion model to learn a subject given a single image, even if it is out of distribution.

We find that \(w2w\) space is highly expressive through quantitative evaluation on editing customized models and encoding new identities given a single image. Qualitatively, we observe this space supports sampling models that encode diverse and realistic identities, while also capturing the key characteristics of out-of-distribution identities. We finally demonstrate that similar weight subspaces exist for other visual concepts such as dog breeds and car types.

Figure 2: **The _weights2weights_ space operates as a _meta_-latent space**. Unlike a traditional generative latent space, \(w2w\) space controls the model itself rather than single image instances. New identity-encoding models can be sampled from the space and edited by linearly traversing along semantic directions in weight space. Additionally, a single image can be inverted into the space to produce a model that consistently generates that identity.

## 2 Related Work

**Image-based generative models.** Various models have been proposed for image generation, including variational autoencoders (VAEs) , flow-based models [12; 32; 49], generative adversarial networks (GANs) , and diffusion models [62; 43; 22]. Within the realm of high-quality photo-realistic image generation, GANs [25; 28; 29] and diffusion models [63; 22; 43; 52] have garnered significant attention due to their controllability and ability to produce high-quality images. Leveraging the compositionality of these models, methods for personalization and customization have been developed which aim to insert user-defined concepts via fine-tuning [16; 34; 40; 54]. Various works try to reduce the dimensionality of the optimized parameters for personalization either by operating in specific model layers  or in text-embedding space , by training hypernetworks , and by constructing a linear basis in text embedding space .

**Latent space of generative models.** Linear latent space models of facial shape and appearance were studied extensively in the 1990s, using PCA-based representations (e.g. Active Appearance Models , 3D Morphable Models ) as well as operating directly in pixel and keypoint space . However, these techniques were restricted to aligned and cropped frontal faces. More recently, generative adversarial networks (GANs), particularly the StyleGAN series [26; 27; 28; 29], have showcased editing capabilities facilitated by their interpretable latent space. Furthermore, linear directions can be found in their latent space to conduct semantic edits by training linear classifiers or applying PCA [20; 60], among other methods for discovering semantic directions [66; 8]. Several methods aim to project real images into the GAN latent space in order to conduct this editing [1; 3; 51; 64; 77]. Beyond the latent space, works such as  found that directions could be discovered in the neuron activation space, suggesting the interpretability of weights.

Although diffusion models architecturally lack a GAN-like latent space, some works aim to discover similar spaces in these models. This has been explored in the UNet bottleneck layer [35; 41], noise space [10; 78], and text-embedding space . Concept Sliders  explores the weight space for semantic image editing by conducting low-rank training with contrasting image or text pairs.

**Weights as data.** Past works have exploited the structure within weight space of deep networks for various applications. In particular, some have found linear properties of weights, enabling simple model ensembling and editing via arithmetic operations [56; 59; 24; 69]. Other works create datasets of neural network parameters for training hypernetworks [14; 19; 42; 55; 68], predicting properties of networks , and creating design spaces for models [46; 47].

## 3 Method

We start by demonstrating how we create a manifold of model weights as illustrated in Fig. 3. We explain how we obtain low-dimensional data points for this space, each of which represents an individual subject from a broad class (i.e., identity). We then use these points to model a weights manifold. Next, we find linear directions in this manifold that correspond to semantic attributes and use them for editing the identities. Finally, we demonstrate how this manifold can be utilized for constraining an ill-posed inversion task with a single image to reconstruct its identity.

Figure 3: **Building _weights2weights (w2w)_ space. We create a dataset of model weights where each model is personalized to a specific identity using low-rank updates (LoRA). These model weights lie on a weights manifold that we further project into a lower-dimensional subspace spanned by its principal components. We train linear classifiers to find disentangled edit directions in this space.**

### Preliminaries

In this section, we first introduce latent diffusion models (LDM) , which we will use to create a dataset of weights. Then, we explain the approach for obtaining identity-specific models from LDM via Dreambooth  fine-tuning. We finally present a version of fine-tuning that uses low-dimensional weight updates (LoRA ). We will use the fine-tuned low-dimensional per-identity weights as data points to construct the weights manifold in Sec. 3.2.

**Latent diffusion models .** We will extract weights from latent diffusion models to create \(w2w\) space. These models follow the standard diffusion objective  while operating on latents extracted from a pre-trained Variational Autoencoder [15; 31; 50]. With text, the conditioning signal is encoded by a text encoder (such as CLIP ), and the resulting embeddings are provided to the denoising UNet model. The loss of latent diffusion models is:

\[_{,,,t}[w_{t}||-_{ }(_{t},,t)||_{2}^{2}],\] (1)

where \(_{}\) is the denoising UNet, \(_{t}\) is the noised version of the latent for an image, \(\) is the conditioning signal, \(t\) is the diffusion timestep, and \(w_{t}\) is a time-dependent weight on the loss.

To sample from the model, a random Gaussian latent \(x_{T}\) is deterministically denoised conditioned on a prompt for a fixed set of timesteps with a DDIM sampler . The denoised latent is then fed through the VAE decoder to generate the final image.

**Dreambooth .** To obtain an identity-specific model, we use the Dreambooth personalization method. Dreambooth fine-tuning introduces a novel subject into a pre-trained diffusion model given only a few images of it. During training, Dreambooth follows a two-part objective:

\[_{,,,t}[w_{t}||-_{ }(_{t},,t)||_{2}^{2}+ w_{t^{}}|| ^{}-_{}(_{t}^{},^{ },t^{})||_{2}^{2}],\] (2)

where the first term corresponds to the standard diffusion denoising objective using the subject-specific data \(\) conditioned on the text prompt "[identifier] [class noun]" (e.g., "_[v]_ person"), denoted \(\). The second term, weighted by \(\), corresponds to a prior preservation loss, which involves the standard denoising objective using the model's own generated samples \(^{}\) for the broader class \(^{}\) (e.g., "person"). This prevents the model from associating the class name with the specific instance, while also leveraging the semantic prior on the class.

**Low Rank Adaptation (LoRA) .** Dreambooth requires fine-tuning all the weights of a model, which is a high-dimensional space. We turn to a more efficient fine-tuning scheme, LoRA, that modifies only a low-rank version of the weights. LoRA uses weight updates \( W\) with a low intrinsic rank. For a base model layer \(W^{m n}\), the LoRA update for that layer \( W\) can be decomposed into \( W=BA\), where \(B^{m r}\) and \(A^{r n}\) are low-rank matrices with \(r min(m,n)\). During training, for each model layer, only the \(A\) and \(B\) are updated. This significantly reduces the number of trainable parameters. During inference, the low-rank weights are added residually to the weights of each layer in the base model and scaled by a coefficient \(\): \(W+ W\).

### Constructing the weights manifold

**Creating a dataset of model weights.** To construct the _weights2weights_ (_w2w_) space, we begin by creating a dataset of model weights \(_{i}\). We conduct Dreambooth fine-tuning on latent diffusion models in order to insert new subjects with the ability to control image instances using text prompts. This training is done with LoRA in order to reduce the space of model parameters. Each model is fine-tuned on a set of images corresponding to one human subject. After training, we flatten and concatenate all of the LoRA matrices, resulting in a data point \(_{i}^{d}\) which represents one identity. After training over \(N\) different instances, we have our final dataset of model weights \(=\{_{1},_{2},...,_{N}\}\), representing a diverse array of subjects.

**Modeling the weights manifold.** We posit that our data \(D^{d}\) lies on a lower-dimensional manifold of weights that encode identities. A randomly sampled set of weights in \(^{d}\), would not be guaranteed to produce a valid model encoding identity as the \(d\) degrees of freedom can be fine-tuned for any purpose. Therefore, we hypothesize that this manifold is a subset of the weight space. Inspired by findings that high-level concepts can be encoded as linear subspaces of representations [13; 37; 45; 48], we model this subset as a linear subspace \(^{m}\) where \(m<d\), and call it _weights2weights_ (_w2w_) space. We represent points in this subspace as a linear combinationof basis vectors **w** = \(\{w_{1},...,w_{m}\}\), \(w_{i}^{d}\). In practice, we apply Principal Component Analysis (PCA) on the \(N\) models and keep the first \(m\) principal components for dimensional reduction and forming our basis of \(m\) vectors.

**Sampling from the weights manifold.** After modeling this weights manifold, we can sample a new model that lies on it, resulting in a new model that generates a novel identity. We sample a model represented with basis coefficients \(\{_{1},...,_{m}\}\), where each coefficient \(_{k}\) is sampled from a normal distribution with mean \(_{k}\) and standard deviation \(_{k}\). The mean and standard deviation are calculated for each principal component \(k\) from the coefficients among all the training models.

### Finding Interpretable Weight Space Directions

We seek a direction \(^{d}\) defining a hyperplane that separates between binary identity properties embedded in the model weights (e.g., male/female), similarly to hyperplanes observed in the latent space of GANs . We assume binary labels are given for attributes present in the identities encoded by the models. We then train linear classifiers using weights of the models as data based on these labels, imposing separating hyperplanes in weight space. Given an identity parameterized by weights \(\), we can manipulate a single attribute by traversing in a direction \(\), orthogonal to the separating hyperplane: \(_{}=+\). An edit operation in \(w2w\) space produces a new model with the original subject edited, allowing the model to generate infinitely many new images of the edited subject.

### Inversion into _w2w_ Space

Traditionally, inversion of a generative model involves finding an input such as a latent code that best reconstructs a given image [38; 70]. This corresponds to finding a projection of the input onto the learned data manifold . With _w2w_ space, we model a manifold of model weights rather than images. Inspired by latent optimization methods [1; 77], we propose a gradient-based method of inverting a single identity from an image into our discovered space.

Given a single image \(\), we follow a constrained denoising objective:

\[_{}\ _{,,,t}[w_{t}||- _{}(_{t},,t)||_{2}^{2}] w2w\] (3)

Specifically, we constrain the model weights to lie in _w2w_ space by optimizing a set of basis coefficients \(\{_{1},...,_{m}\}\) rather than the original parameters. Unlike Dreambooth, we do not employ a prior preservation loss, since the optimized model lies in the subspace defined by our dataset of weights, and inherits their priors.

## 4 Experiments

We demonstrate _w2w_ space on the visual concept of human identities for a variety of applications. We begin by detailing implementation details. Next, we use _w2w_ space for 1) sampling new models encoding novel identities, 2) editing identity attributes in a consistent manner via linear traversal in _w2w_ space, 3) embedding a new identity given a single image, and 4) projecting out-of-distribution identities into _w2w_ space. Finally, we analyze how scaling the number of models in our dataset of model weights affects the disentanglement of attribute directions and preservation of identity.

### Implementation Details

**Creating an identity dataset.** We generate a synthetic dataset of \(\)65,000 identities using , where each identity is associated with multiple images of that person. Each identity is based on an image with labeled binary attributes (e.g., male/female) from CelebA . Each set of images corresponding to an identity is then used as data to fine-tune a latent diffusion model with Dreambooth. Further details on this dataset and train/test splits are provided in Appendix E.

**Encoding identities into model weights.** We conduct Dreambooth fine-tuning using LoRA with rank 1 on the identities. Following , we only fine-tune the query and value projection matrices in the cross-attention layers. We utilize the RealisticVision-v51 checkpoint2 based on Stable Diffusion1.5. Conducting Dreambooth fine-tuning on each identity training set results in a dataset of \(\)65,000 weights \(\) where \(^{100,000}\).

**Finding semantic attribute directions.** We utilize binary attribute labels from CelebA to train linear classifiers on the dataset of model weights we curated. We run Principal Component Analysis (PCA) on the \(\)65,000 training models and project to the first 1000 principal components in order to reduce the dimensionality. The orthogonal edit directions are calculated via the analytic least squares solution on the matrix of projected training models \(^{65,000 1000}\), and then unprojected to the original dimensionality of the model weights: \(^{100,000}\).

### Sampling from _w2w_ Space

We present images generated from models that were sampled from the weights manifold (i.e., _w2w_ Space) in Fig. 4. We follow the sampling procedure from Sec. 3.2, and generate images from the sampled model. As shown, each new model encodes a novel, realistic, and consistent identity. Additionally, we present the nearest neighbor model among the training dataset of model weights. We use cosine similarity on the models' principal component representations. Comparing with the nearest neighbors shows that these samples are not just copies from the dataset, but rather encode diverse identities with different attributes. Yet, the samples still demonstrate some similar features to the nearest neighbors. These include jawline and eye shape (top row), facial hair (middle row), and nose and eye shape (bottom row). Appendix A includes more such examples.

### Editing Subjects

We demonstrate how directions found by the linear classifiers can be used to edit subjects encoded in the models. It is desired that these edits are 1) disentangled (i.e., do not interfere with other attributes of the embedded subject and preserve all other concepts such as context) 2) identity preserving (i.e., the person is still recognizable) 3) and semantically aligned with the intended edit.

**Baselines.** We compare against a naive baseline of prompting with the desired attribute (e.g., "_[v]_ person with small eyes"), and then Concept Sliders , an instance-specific editing method which we adapt to subject editing. In particular, we train their most accessible method, the text-based slider, which trains LoRAs to modulate attributes in a pretrained diffusion model based on contrasting text prompts. We then apply these sliders to the personalized identity models.

Figure 4: **Identity samples from _w2w_ space. We show the samples from _w2w_ space do not overfit to nearest-neighbor identities, although they incorporate facial attributes from them. The identities are diverse and consistent across generations.**

Figure 5: **Qualitative comparison.**_w2w_ edits preserve identity while being disentangled and semantically aligned. Concept Sliders  tends to exaggerate effects which induces artifacts and degrades identity, while prompting the subject with the desired edit has unexpected effects.

**Evaluation protocol.** We evaluate these three methods for identity preservation, disentanglement, and edit coherence. To measure identity preservation, we first detect faces in the original generated images and the result of the edits using MTCNN . We then calculate the similarity of the FaceNet  embeddings. We also use LPIPS  computed between the images before and after the edit to measure the degree of disentanglement with other visual elements, and CLIP score , to measure if the desired edit matches the text caption for the edit.

To generate samples, we fix a set of prompts and random seeds which are used as input to the held-out identity models. Then, we choose a set of identity-specific manipulations. For prompt-based editing, we augment the attribute description to the set of fixed prompts (e.g., "chubby _[v]_ person"). For Concept Sliders and _w2w_, we apply the weight space edit directions to the personalized model with a fixed norm which determines the edit strength. The norm is calculated using the maximum projection component onto the edit direction among the training set of model weights.

_w2w_ **edits are identity preserving and disentangled.** We evaluate over a range of identity-specific attributes and present three (gender, chubby, narrow eyes) in Tab. 1. Edits in _w2w_ preserve the identity of the original subject as measured by the ID score. These edits are semantically aligned with the desired effect as indicated by the CLIP score while minimally interfering with other visual concepts, as measured by LPIPS. We note that the CLIP score can be noisy in this setting as text captions can be too coarse to describe attributes as nuanced as those related to the human face. We supplement this with a user study presented in Appendix B.

Qualitatively, _w2w_ edits make the minimal amount of changes to achieve semantic and identity-preserving edits (Fig. 5). For instance, changing the gender of the man does not significantly change the facial structure or hair, unlike Concept Sliders or prompting with text descriptions. Prompting has inconsistent results, either creating no effect or making drastic changes. Concept Sliders tends to make caricaturized effects, such as making the man cartoonishly chubby and baby-like.

**Composing edits.** Edit directions in _w2w_ space can be composed linearly as shown in Fig. 6. The first column represents samples from the original model, and each subsequent column represents samples from the edited models. Each row shares the same fixed random generation seed. The composed edits persist in appearance across different generations, binding to the identity. Furthermore, the edited weights result in a new model, where the subject has different attributes while still maintaining as much of the prior identity. This is in contrast to editing in a traditional latent space, where an edit only corresponds to a single image. Additionally, as we operate on an personalized identity-specific weight manifold, minimal changes are made to other concepts, such as scene layout or other people. For instance, in Fig. 6, adding edits to the woman does not interfere with the person standing by her.

    &  &  &  \\  & Prompting & Sliders & _w2w_ & Prompting & Sliders & _w2w_ & Prompting & Sliders & _w2w_ \\  Gender & 0.39\(\)0.08 & 0.33\(\)0.09 & **0.45\(\)0.09** & **0.30\(\)0.00** & 0.39\(\)0.00 & 0.31\(\)0.03 & 1.98\(\)0.07 & 3.50\(\)0.08 & **4.13\(\)0.59** \\ Chubby & 0.29\(\)0.14 & 0.33\(\)0.09 & **0.45\(\)0.09** & 0.41\(\)0.05 & 0.38\(\)0.04 & **0.36\(\)**0.04 & 1.12\(\)0.01 & **2.21\(\)**0.01 & 2.16\(\)0.51 \\ Eyes & 0.52\(\)0.06 & 0.53\(\)0.04 & **0.72\(\)**0.03 & 0.32\(\)0.03 & 0.30\(\)0.02 & **0.19\(\)**0.02 & 0.17\(\)0.17 & 0.01\(\)0.22 & **0.59\(\)**0.19 \\   

Table 1: **Edits in _w2w_ space preserve identity, are disentangled, and semantically aligned.**

Figure 6: **Composing edits in _w2w_ space. Each column represents fixed seed samples from an edited model. Multiple edits in _w2w_ space minimally degrade the original identity or interfere with other concepts, while maintaining edit appearance across different samples.**

### Inverting Subjects

**Evaluation protocol.** We measure _w2w_ space's ability to represent novel identities by inverting a set of 100 random FFHQ  face images. We follow our inversion objective from eq. 3. We then provide a set of diverse prompts to generate multiple images and follow the identity preservation metric from Sec. 4.3 to measure subject fidelity. Implementation details are provided in Appendix C.

We compare our results to two approaches that use Dreambooth with rank-1 LoRA. The first is trained on a single image. The second is trained on _multiple images of each identity_. We generate such images by following our identity dataset construction from Sec. 4.1. This approach can be viewed as a pseudo-upper bound on modeling identity as it uses multiple images.

_w2w_ space provides a strong identity prior. Inverting a single image into _w2w_ space improves on the single image Dreambooth baseline and closes the gap with the Dreambooth baseline that uses multiple identity images (Tab. 2). Conducting Dreambooth fine-tuning with a single image in the original weight space leads to image overfitting and poor subject reconstruction as indicated by a lower ID score. In contrast, by constraining the optimized weights to lie on a manifold of identity weights, _w2w_ inversion inherits the rich priors of the models used to discover the space. As such, it can extract a high-fidelity identity that is consistent and compositional across generations. We present qualitative comparisons against Dreambooth and single-image Dreambooth in Appendix C. We additionally compare against other personalization methods in that section.

**Inverted models are editable.** Fig. 7 demonstrates that a diverse set of identities can be faithfully represented in _w2w_ space. After inversion, the encoded identity can be composed in novel contexts and poses. For instance, the inverted man (rightmost example) can be seen posing with a celebrity or rendered as a statue. Moreover, semantic edits can be applied to the inverted models while maintaining appearance across generations.

### Out-of-Distribution Projection

_w2w_ space captures out-of-distribution identities.** We follow the _w2w_ inversion method from Sec. 4.4 to project images of unrealistic identities (e.g., paintings, cartoons, etc.) onto the weights manifold, and present these qualitative results in Fig. 8. By constraining the optimized model to live in _w2w_ space, the inverted identities are converted into realistic renditions of the stylized identities, capturing prominent facial features. In Fig. 8, notice how the inverted identities generate a similar

   Method & Single-Image & ID Score \(\) \\  DB-LoRA & \(\) & \( 0.01\) \\ DB-LoRA & \(\) & \(0.43 0.03\) \\ _w2w_ & \(\) & \(0.64 0.01\) \\   

Table 2: _w2w Inversion closes the gap with Dreambooth._

Figure 8: **Projecting out-of-distribution identities.** We show that our inversion method can convert unrealistic identities into realistic renderings with in-domain facial features. Each image represents a generated sample from the inverted model. The resulting identities can be composed in novel scenes, such as playing tennis or rendered into other artistic domains.

Figure 7: **Single image inversion reconstructs identity and enables editing in _w2w_ space.** We present generated samples from the inverted models. These inverted identities can be composed in novel contexts and edited using our discovered semantic directions in weight space. These edits persist in appearance across generation seeds and prompts.

blonde hairstyle and nose structure in the first example, defined jawline and lip shape in the second example, and head shape and big nose in the last example. As also shown in the figure, the inverted identities can also be translated to other artistic domains using text prompts. We present a variety of domains projected into \(w2w\) space in Appendix D.

### Effect of Number of Models Spanning \(w2w\) Space

We ablate the number of models used to create \(w2w\) space and investigate the expressiveness of the resulting space. In particular, we measure the degree of entanglement among the edit direction and how well this space can capture identity.

**Disentanglement vs. the number of models.** We find that scaling the number of models in our dataset of weights leads to less entangled edit directions in \(w2w\) space (Fig. 10). We vary the number of models in our dataset of weights and reapply PCA to establish a basis. We then measure the absolute value of cosine similarity (lower is better) between all pairs of linear classifier directions found for CelebA labels. We repeat this as we scale the number of model weights used to train the classifiers. We report the mean and standard deviation for these scores, along with three notable semantic direction pairs. We observe a trend in decreasing cosine similarity. Notably, pairs such as "Black Hair - Pale Skin," "Young - Bald," and "Male - Beard" which may correlate in the distribution of identities, become less correlated as we scale our dataset of model weights.

**Identity preservation vs. the number of models.** We observe that as we scale the number of models in our dataset of weights, identities are more faithfully represented in \(w2w\) space (Fig. 10). We follow the same procedure as the disentanglement ablation, reapplying PCA to establish a basis based on the dataset of model weights. Next, following Sec. 4.4, we optimize coefficients for this basis and measure the average ID score over the 100 inverted FFHQ evaluation identities. As each model in our dataset encodes a different instance of an identity, growing this dataset increases the span of \(w2w\) space and its ability to capture more diverse identities. We plot the average multi-image Dreambooth LoRA (DB-LoRA) ID score from Sec. 4.4, which is agnostic to our dataset of models. This establishes a pseudo-upper bound on identity preservation. Scaling enables \(w2w\) to represent identities given a single image with performance approaching that of traditional Dreambooth with LoRA, which uses multiple images and trains in a higher dimensional space.

## 5 Extending to Other Domains

We extend our hypothesis of interpretable linear weight subspaces in diffusion models to other visual concepts beyond human identities. We apply the _weights_2weights framework to form a subspace for models encoding different dog breeds. To create a dataset for fine-tuning, we generate images with Stable Diffusion based on each of the \(120\) dog classes from ImageNet . We then conduct Dreambooth fine-tuning on each set of dog breed images to create a dataset of \(120\) dog-encoding models, subsequently applying PCA. To find edit directions, we use GPT-4  to create labels for each dog breed (e.g., wavy hair or not) and then train linear classifiers on the model weight principal component projections like Sec. 3.3. We apply the same framework to different car categories using models fine-tuned on images from a dataset of 197 different car types . We present results for traversing edit directions in these two subspaces in Fig. 11. Each column represents samples from an edited model. Each row shares the same fixed random generation seed.

Our results provide further evidence that diffusion models can encode visual concepts linearly. This enables the creation of new models in a controlled manner via simple interpolation. For instance, in Fig. 11, we rewrite the model's learned concept of a small golden retriever to make it bigger, or the model's encoding of a red van to make it a sports car. Additionally, unlike older PCA-based methods  which rely on aligned pixels or keypoints of human faces, _weights2weights_ can extend to other domains beyond human identities. We refer the reader to Appendix G for more results of applying _w2w_ space to other visual concepts.

## 6 Limitations

As with any data-driven method, _w2w_ space inherits the biases of the data used to discover it. For instance, co-occurring attributes in the identity-encoding models would cause linear classifier directions to entangle them (e.g. gender and facial hair). However, as we scale the number of models, spurious correlations will drop as evidenced by Fig. 9. These semantic directions are also limited by the labels present in CelebA. Additionally, the span of the _w2w_ space is dictated by the models used to create it. Thus, _w2w_ space can struggle to represent more complex identities as seen in Fig. 12. Inversion in these cases amounts to projecting onto the closest identity on the weights manifold. Despite this, our analysis on the size of the model dataset reveals that forming a space using a larger and more diverse set of identity-encoding models can mitigate this limitation.

## 7 Discussion and Broader Impact

We presented a paradigm for representing diffusion model weights as a point in a subspace defined by other customized models - _weights2weights_ (_w2w_) space. This enabled applications analogous to those of a generative latent space - inversion, editing, and sampling - but producing model weights rather than images, resulting in what we term a _meta_-latent space. We demonstrated these applications on model weights encoding human identities and extended this space to other visual concepts. Although these applications could enable malicious manipulation of real human identities and model weights, we hope the community uses the framework to explore visual creativity as well as utilize this interpretable space for controlling models for safety.

Figure 11: _weights2weights_ linear subspaces can be created for other visual concepts. We follow the same procedure of applying PCA and finding edit directions with linear classifiers on datasets of models encoding dog breeds and models encoding car types.

Figure 12: _weights2weights_ **fails to capture identities with undersampled attributes.**