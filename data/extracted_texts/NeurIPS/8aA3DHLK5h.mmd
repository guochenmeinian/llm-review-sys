# Extensive-Form Game Solving via Blackwell

Approachability on Treeplexes

 Darshan Chakrabarti

IEOR Department

Columbia University

dc3595@columbia.edu

&Julien Grand-Clement

ISOM Department

HEC Paris

grand-clement@hec.fr

&Christian Kroer

IEOR Department

Columbia University

christian.kroer@columbia.edu

###### Abstract

We introduce the first algorithmic framework for Blackwell approachability on the sequence-form polytope, the class of convex polytopes capturing the strategies of players in extensive-form games (EFGs). This leads to a new class of regret-minimization algorithms that are stepsize-invariant, in the same sense as the Regret Matching and Regret Matching\({}^{+}\) algorithms for the simplex. Our modular framework can be combined with any existing regret minimizer over cones to compute a Nash equilibrium in two-player zero-sum EFGs with perfect recall, through the self-play framework. Leveraging predictive online mirror descent, we introduce _Predictive Treeplex Blackwell\({}^{+}\)_ (\(^{*}\)), and show a \(O(1/)\) convergence rate to Nash equilibrium in self-play. We then show how to stabilize \(^{*}\) with a stepsize, resulting in an algorithm with a state-of-the-art \(O(1/T)\) convergence rate. We provide an extensive set of experiments to compare our framework with several algorithmic benchmarks, including \(^{*}\) and its predictive variant, and we highlight interesting connections between practical performance and the stepsize-dependence or stepsize-invariance properties of classical algorithms.

## 1 Introduction

In this paper, we focus on solving _Extensive-Form Games_ (EFGs). Finding a Nash equilibrium of a two-player zero-sum EFG can be cast as solving

\[_{}_{}, \]

where the sets \(,\) are two _sequence-form polytopes_ (also referred to as _treeplexes_) representing the strategies \(,\) of each player, and \(\) is a payoff matrix. EFGs have been successfully used to obtain superhuman performances in several recent poker AI breakthroughs . Many algorithms have been developed based on (1). Since \(\) and \(\) are polytopes, (1) can be formulated as a linear program . However, because \(\) and \(\) themselves have very large dimensions in realistic applications, _first-order methods_ (FOMs) and _regret minimization_ approaches are preferred for large-scale game solving. FOMs such as the Excessive Gap Technique (\(\), ) and Mirror Prox  instantiated for EFGs  converge to a Nash equilibrium at a rate of \(O(1/T)\), where \(T\) is the number of iterations. Regret minimization techniques rely on a folk theorem relating the regrets of the players and the duality gap of the average iterates . For instance, predictive online mirror descent with the treeplexes \(\) and \(\) as decision sets achieves a \(O(1/T)\) convergence rate .

_Counterfactual regret minimization_ (CFR)  is a regret minimizer for the treeplex that runs regret minimizers _locally_, i.e. directly at the level of the information sets of each player. \(^{*}\), used in virtually all poker AI milestones , instantiates the CFR framework with a regret minimizercalled _Regret Matching\({}^{+}\)_ (RM\({}^{*}\))  and guarantees a \(O(1/)\) convergence rate. The strong empirical performance of CFR\({}^{*}\) remains mostly unexplained, since this algorithm does not achieve the fastest theoretical \(O(1/T)\) convergence rate. Interestingly, there is a stark contrast between the role of stepsizes in CFR\({}^{*}\) versus in other algorithms. CFR\({}^{*}\) may use different stepsizes across different infosets, and the iterates of CFR\({}^{*}\) do not depend on the values of these stepsizes. We identify this property as _infoset stepsize invariance_. In contrast, the convergence properties of FOMs depend on the choice of a single stepsize used across the entire treeplex, which may be hard to tune in practice.

\(^{+}\) is an instantiation of _Blackwell approachability_ for the simplex, a versatile framework with connections to online learning . Empirically, using a regret minimizer (over simplexes) based on Blackwell approachability (\(^{+}\)) is central to the success of CFR\({}^{*}\): combining CFR with other local regret minimizers than \(^{+}\), e.g., Online Mirror Descent (\(\)), leads to much weaker practical performance . This raises the question of whether the performance of CFR\({}^{*}\) is mostly explained by the use of Blackwell approachability _on simplexes_ (\(^{+}\)), and if a Blackwell approachability-based algorithm operating _directly on treeplexes_, bypassing the CFR decomposition, could outperform CFR\({}^{*}\). Our **goal** in this paper is to address these questions. To do so, we develop the _first_ Blackwell approachability-based algorithms for treeplexes, and we provide a new hypothesis for explaining the performance of CFR\({}^{*}\). In particular, our **main contributions** are as follows.

**Treeplex Blackwell approachability.** We introduce the first Blackwell approachability-based regret minimizer for treeplexes. Using the self-play framework, we correspondingly get the first framework for solving two-player zero-sum EFGs via Blackwell approachability on treeplexes. Blackwell approachability enables an equivalence between regret minimization over the treeplex \(\) and over its conic hull \(()\), and any existing regret minimizer for \(()\) yields a new algorithm for solving EFGs. A crucial advantage of using Blackwell approachability on the treeplex, rather than regret minimization directly on the treeplex, is that it leads to a variety of interesting stepsize properties (e.g. stepsize invariance), which are not achieved by regret minimizers such as \(\) on the treeplex.

We then provide several instantiations of our framework. \(^{+}\) (_Predictive Treeplex Blackwell\({}^{+}\)_, Algorithm 2) combines our framework with predictive \(\) over \(()\) and achieves a \(O(1/)\) convergence rate. \(^{+}\) is _treeplex stepsize invariant_: its iterates do not change if we rescale all stepsizes by a positive constant. This is a desirable property for practical use, although it is a weaker property than the _infoset_ stepsize invariance of CFR\({}^{*}\). Smooth \(^{*}\) (Algorithm 3) is a variant of \(^{+}\) ensuring that successive iterates vary smoothly. We show that Smooth \(^{+}\) is the first EFG-solving algorithm based on Blackwell approachability achieving a \(O(1/T)\) convergence rate, answering an important open question. Crucially, it is necessary to introduce a stepsize to achieve this faster convergence, and thus \(\)\(^{+}\) is not treeplex stepsize invariant; this is analogous to existing FOM-based \(O(1/T)\)-methods for solving EFGs. We also consider \(^{+}\) and \(^{+}\), which learn different stepsizes for every dimension of the treeplexes, based on \(\) and \(\). We present the convergence properties of our algorithms in Table 1.

**Numerical experiments.** We provide two comprehensive sets of numerical experiments over benchmark EFGs. We find that \(^{+}\) performs the best among all the algorithms introduced in our paper (Figure 4), highlighting the advantage of _treeplex_ stepsize invariant algorithms (\(^{+}\)) over stepsize-dependent algorithms achieving faster theoretical convergence rate (\(\)\(^{+}\)), and over adaptive algorithms learning decreasing stepsizes (\(^{+}\), \(^{+}\)). We then compare our best method (\(^{+}\)) with CFR\({}^{*}\), predictive CFR\({}^{*}\) (\(^{+}\)), and predictive \(\) (\(\)) (Figure 2). We expected \(^{+}\) to perform on par with \(^{+}\), since \(^{+}\) is stepsize invariant, predictive, and based on Blackwell approachability. However, we find that \(^{+}\) outperforms all other algorithms. This suggests that _infoset_ stepsize invariance is an important property, even more than the _treeplex_ stepsize invariance of \(^{+}\). Due to the CFR decomposition, \(^{+}\) can use different stepsizes at different infosets, where the values of the variables may be of very different magnitudes (typically, smaller for infosets appearing deeper in the treeplex), and \(^{+}\) does not require tuning these different stepsizes, which may be impossible for large instances. No algorithms appear to consistently outperform the others for the last-iterate performances, and we leave studying this as an open question.

**A new hypothesis on EFG-solving algorithms: the role of stepsize invariance.** Overall, as part of our main contributions, we identify and distinguish the infoset and treeplex stepsize invariance properties, and based on our empirical experiments, we posit that infoset stepsize invariance explains part of the puzzle behind the strong empirical performance of CFR\({}^{*}\) and \(^{+}\). Our results highlight that for practical performance, the stepsize invariance properties may be more important than faster theoretical convergence rates, which require introducing a stepsize, as for Smooth PTB\({}^{}\) or POMD. The very strong empirical performance of (predictive) CFR\({}^{}\) has been unexplained for a long time and is one of the major open questions in EFG-solving; we view providing a new hypothesis for this phenomenon (infoset stepsize invariance) as important contributions to the EFG-solving community.

## 2 Preliminaries on EFGs

We first provide some background on EFGs and treeplexes.

**Extensive-form games.** Two-player zero-sum extensive-form games (later referred to as _EFGs_) are represented by a game tree and a payoff matrix. Each node of the tree belongs either to one of the players, or to a _chance player_, modeling the random events in the game, e.g., tossing a coin. The players are assigned payoffs at the terminal nodes only. Imperfect information is modeled using _information sets_ (_infosets_), which are subsets of nodes of the game tree. A player cannot distinguish between the nodes in a given infoset, and they must take the same action at all these nodes.

**Treeplexes.** The strategy of a player can be described by a polytope called the _treeplex_, also known as the _sequence-form polytope_. The treeplex is constructed as follows. We index the infosets of a player by \(=\{1,...,||\}\). The set of actions available at infoset \(j\) is written \(_{j}\) with cardinality \(|_{j}|=n_{j}\). We represent choosing action \(a_{j}\) at infoset \(j\) by a _sequence_\((j,a)\), and we denote by \(_{ja}\) the set of next infosets reachable from \((j,a)\) (possibly empty if the game terminates). The parent \(p_{j}\) of an infoset \(j\) is the sequence leading to \(j\); note that \(p_{j}\) is unique assuming perfect recall. We assume that there is a single root denoted as \(\) and called the _empty sequence_. If the player does not take any action before reaching \(j\), then by convention \(p_{j}=\). Under the perfect recall assumption, the set of infosets has a tree structure: \(_{ja}_{j^{}a^{}}=\), for all pairs of sequences \((j,a)\) and \((j^{},a^{})\) such that \(j j^{},a a^{}\). This tree is the treeplex and it represents the set of all admissible strategies for a given player. We denote by \(n\) the total number of sequences \((j,a)\) with \(j\) and \(a_{j}\). With these notations, the treeplex \(\) of a given player is

\[=\{_{+}^{n+1} x_{}=1,_{a _{j}}x_{ja}=x_{p_{j}},\;j\} \]

where the first component \(x_{}\) is related to the empty sequence \(\). A player _makes an observation_ to arrive at \(j\), if \(|_{p_{j}}|>1\). We define the depth \(d\) of a treeplex to be the maximum number of actions and observations that can be made starting at the root until reaching a leaf infoset. Computing a Nash equilibrium of EFGs can be formulated as solving (1) (under the perfect recall assumption), with \(^{n_{1}+1}\) and \(^{n_{2}+1}\) the treeplex of each player, \(n_{1}\) and \(n_{2}\) are the number of sequences of each player, and \(^{(n_{1}+1)(n_{2}+1)}\) the payoff matrix such that for a pair of strategy \((,)\), \(,\) is the expected value that the second player receives from the first player.

**Regret minimization and self-play framework.** A _regret minimizer_ Regmin over a decision set \(^{d}\) is an algorithm such that, at every iteration, Regmin chooses a decision \(^{t}\), a _loss vector_\(^{d}\) is observed, and the scalar loss \(^{t},^{t}\) is incurred. A regret minimizer ensures that the _regret_\(^{T}=_{}}_{t=1}^{T}^{t},^{t}-}\) grows at most as \(O()\). As an example, _predictive online mirror descent_ (POMD, ) generates a sequence of decisions \(_{1},...,_{T}\) as follows:

\[_{t}=_{}(}_{t}-_{t}), }_{t+1}=_{}(}_{t}-_{t}) \]

  
**Algorithms** & **Convergence rate** & **Stepsize invariance** \\  CFR\({}^{}\) & \(1/\) & \(\) \\ PCFR\({}^{}\) & \(1/\) & \(\) \\ EGT  & \(1/T\) & \(\) \\ POMD  & \(1/T\) & \(\) \\ PTB\({}^{}\) (Algorithm 2) & \(1/\) & \(\) \\ Smooth PTB\({}^{}\) (Algorithm 3) & \(1/T\) & \(\) \\ AdaGradTB\({}^{}\) (Algorithm 6) & \(1/\) & \(\) \\ AdamTB\({}^{}\) (Algorithm 7) &? & \(\) \\   

Table 1: Convergence rates to a Nash equilibrium of a two-player zero-sum EFG for several algorithms. \(\) refers to _infoset_ stepsize invariance and \(\) refers to _treeplex_ stepsize invariance.

with \(_{1},...,_{T}^{d}\) some predictions of the losses \(_{1},...,_{T}^{d}\), and where we write the orthogonal projection of \(^{d}\) onto \(\) as \(_{}():=_{}\|- \|_{2}\).

The _self-play framework_ solves EFGs via regret minimization. The players compute two sequences of strategies \(_{1},...,_{T}\) and \(_{1},...,_{T}\) such that, at iteration \(t 1\), the first player observes its loss vector \(_{t-1}\) and the second player observes its loss vector \(-^{}_{t-1}\). Each player computes their current strategies \(_{t}\) and \(_{t}\) via regret minimization. A well-known theorem states that the duality gap of the average of the iterates is bounded by the sum of the average regrets of the players.

**Proposition 2.1** ().: _Let \(_{1},...,_{T}\) and \(_{1},...,_{T}\) be computed in the self-play framework. Let \((}_{T},}_{T})=_{t=1}^{T}( _{t},_{t})\). Then, for \(_{1}^{T}\) and \(_{2}^{T}\) the regret of each player,_

\[_{}\,}_{T},} -_{}\,}, {}_{T}=(_{1}^{T}+_{2}^{T} )/T.\]

We present more details on the self-play framework in Appendix A.

**CFR and Regret Matching\({}^{+}\).**_Counterfactual Regret minimization_ (CFR, ) runs independent regret minimizers with counterfactual losses at each infoset of the trespelexes. This considerably simplifies the optimization problem, since the decision set at each infoset \(j\) is the simplex over the set of next available actions \(^{n_{j}}:=\{_{+}^{n_{j}}_{i=1}^{n_{j}}x_{i}=1\}\). In the CFR framework, the regret of each player (over the trespelex) is bounded by the maximum of the local regrets incurred at each infoset. Therefore, CFR combined with any regret minimizer over the simplex converges to a Nash equilibrium at a rate of \(O(1/)\). We refer to Appendix B for more details. Combining CFR with a local regret minimizer called _Regret Matching\({}^{+}\)_ (RM\({}^{+}\), ) along with alternation and linear averaging yields an algorithm called \(^{*}\), which has been observed to attain strong practical performance compared to theoretically-faster methods . Crucially, RM\({}^{+}\) can only be implemented on the simplex and not for other decision sets, and proceeds as follows: given a sequence of loss \(_{1},...,_{T}^{d}\), RM\({}^{+}\) maintains a sequence \(_{1},...,_{T}^{d}\) such that \(_{1}=\) and

\[_{t}=_{t}/\|_{t}\|_{1},_{t+1}=_{_{+}^{d} }(_{t}-(_{t},_{t})) \]

with \(>0\) and \(/0:=(1/d)\) for \(:=(1,...,1)^{d}\), and, for \(,^{d}\),

\[(,):=-, . \]

\(^{+}\) is _stepsize invariant_: \(_{1},...,_{T}\) are independent of \(\), since \(_{t}=_{t}/\|_{t}\|_{1}\) and \(\) only rescales the entire sequence \(_{1},...,_{T}\). Since \(^{*}\) runs \(^{*}\) at each infoset independently, \(^{*}\) is _infoset stepsize invariant_: there may be different stepsizes across different infosets and the iterates of \(^{*}\) do not depend on them, which is desirable for large-scale EFGs where stepsize tuning may be difficult.

\(^{+}\) can be interpreted as an instantiation of _Blackwell approachability_, where the goal of the decision maker is to compute the sequence of strategies \(_{1},...,_{T}^{d}\) to ensure that the auxiliary sequence \(_{T}/T_{+}^{d}\) approaches the _target set_\(_{-}^{d}\) as \(T+\). Since \(_{t}_{+}^{d}\), this is equivalent to ensuring that \(_{T+}_{T}/T=\). The vector \((,)\) is interpreted as an instantaneous loss for the approachability instance. As an instantiation of Blackwell approachability, at each iteration \(^{*}\) computes an orthogonal projection onto the _conic hull_ of the decision set:

\[_{+}^{d}=(^{d}) \]

with \(():=\{, 0\}\) for a set \(\). The function \(/\|\|_{1}\) is based on

\[^{d}\{^{d}, =1\}. \]

Since for \(_{+}^{d},,=\|\|_{1}\), then \(_{t}=_{t}/\|_{t}\|_{1}\) can be written \(_{t}=_{t}/_{t},\), with \(\) a vector such that the decision set \(^{d}\) satisfies (7). This ensures that

\[_{t},(_{t},)=0,\ ^{d}. \]

We provide an illustration of the dynamics of \(^{+}\) in Figure 1. Equation (8) is known as a _hyperplane forcing condition_ and is a key ingredient in any Blackwell approachability-based algorithm; it ensures that the vector \(_{T}\) grows at most at a rate of \(O()\) so that \(_{T+}_{T}/T=\). We refer to  and to Appendix C for more details on Blackwell approachability.

Blackwell Approachability on Treeplexes

In this section we introduce a modular regret minimization framework for the treeplex based on Blackwell approachability. This framework can be used as a regret minimizer over \(\) in the self-play framework (described in the previous section and in Appendix A) to obtain an algorithm for solving EFGs. Our algorithms are based on the fact that for \(^{n+1}\) a treeplex as defined in (2), we have

\[\{^{n+1},=1\} \]

for \(=(1,)^{n+1}\) with \(=(0,...,0)^{n}\). This property is analogous to (7) for the simplex. With this analogy in mind, we define \(^{n+1}\) and \((,)^{n+1}\) as, for \(,^{n+1}\),

\[ :=() \] \[(,) :=-,. \]

Equation (10) and Equation (11) are analogous to (6) and (5). The cone \(\) and the vector \((,)\) play a similar role for \(\) as \(_{+}^{d}\) and \((,)\) play for \(^{d}\) in \(^{*}\). Our framework is described in Algorithm 1 and relies on running a regret minimizer Regmin over \(=()\) against the losses \((_{t},_{t})\) to obtain a regret minimizer over \(\) against the losses \(_{t}\), for \(t 1\).

```
1:Input: A regret minimizer Regmin with decision set \(\)
2:Initialization:\(_{1}=^{n+1}\)
3:for\(t=1,,T\)do
4:\(_{t}=_{t}/_{t},\)
5: Observe the loss vector \(_{t}^{n+1}\)
6:\(\) observes \((_{t},_{t})^{n+1}\)
7:\(_{t+1}=()\)
```

**Algorithm 1** Blackwell approachability on the treeplex

By convention that \(/0\) is the uniform strategy for the treeplex. Algorithm 1 is the first Blackwell approachability-based algorithm operating on the entire treeplex (in contrast to \(^{*}\) which relies on Blackwell approachability locally at the infosets level). We first describe some important properties of Algorithm 1:

Feasibility of the iterates.Algorithm 1 produces feasible strategies, i.e., \(_{t},\ t 1\). Indeed, since \(\) is a regret minimizer with \(\) as the decision set, \(_{t}()\), i.e., \(_{t}=\) with \(_{+}\) and \(\). From (9), we have \(,=1\). Therefore, \(_{t}=_{t}}{_{t},}=}{,}=\). This is analogous to \(^{*}\), where \(_{t}\) is proportional to \(_{t}\), see (4) and Figure 1.

Hyperplane forcing.For any \(t\) we have

\[_{t},f(_{t},)=0,\, ^{n+1}. \]

The hyperplane forcing equation (12) is a crucial component of algorithms based on Blackwell approachability. It ensures that \(\|_{t}\|_{2}=O()\). Equation (12) is analogous to (8) for \(^{*}\) and follows from \(_{t}=_{t}}{_{t},}\), so that

\[_{t},(_{t},)=_{t},-_{t},_{t}, =_{t},-_{t}}{_{t },},_{t},=_{t},-_{t},=0.\]

Regret minimization over \(\).Algorithm 1 always yields a regret minimizer over the treeplex \(\), i.e., it ensures that the regret of \(_{1},...,_{T}\) against any \(_{1},...,_{T}^{n+1}\) is bounded by \(O()\). The proof is instructive and shows a central component to Blackwell approachability-based algorithms: minimizing regret over \(\) can be achieved by minimizing regret over \(()\).

**Proposition 3.1**.: _Let \(\) be a regret minimizer with \(\) as the decision set. Let \(_{1},...,_{T}\) be computed by Algorithm 1. Then \(_{}_{t=1}^{T}_{t}-},_{t}=O()\)._Proof.: Let \(}\) and let us write \(}=}\). We have

\[_{t=1}^{T}_{t}-},_{t}=_{t=1}^{T }-},(_{t},_{t})=_{ t=1}^{T}-},(_{t},_{t})= _{t=1}^{T}_{t}-},(_{t},_{ t})\]

where the first equality follows from the definition of \((_{t},_{t})\) and \(,=1\) for any \(\), the second equality is because \(}=}\), and the last equality follows from the hyperplane forcing condition (12). Now note that \(_{t=1}^{T}_{t}-},(_{t},_ {t})\) is the regret of a regret minimizer Regmin choosing \(_{1},...,_{T}\) in the decision set \(:=()\) against a sequence of loss \((_{1},_{1}),...,(_{T},_{T})\) and a comparator \(}()\). Therefore, \(_{t=1}^{T}_{t}-},(_{t},_ {t})=O()\). 

**Remark 3.2**.: _In their seminal paper, Abernethy et al.  show a general reduction from regret minimization to Blackwell approachability for compact convex decision sets. Our reduction from Algorithm 1 builds upon the ideas in , but our reduction is different and exploits the structure of treeplexes. Additionally,  focuses on the case of adversarial losss, whereas we focus on solving EFGs, where stepsize invariance properties is crucial and where we can prove fast \(O(1/T)\) convergence rates. We provide a more detailed comparison with  in Appendix C._

## 4 Instantiations of Algorithm 1

We can instantiate Algorithm 1 with any regret minimizer over \(\) to obtain various properties such as stepsize invariance or achieving \(O(1/T)\) convergence rate. We show next how to do so.

**Predictive Treeplex Blackwell\({}^{+}\)** (\(^{*}\)).** We first introduce _Predictive Treeplex Blackwell\({}^{+}\)_ (Algorithm 2), combining Algorithm 1 with \(\) with \(\) as a decision set.

```
1:Input: \(>0\), \(_{1},...,_{T}^{n+1}\)
2:Initialization: \(}_{1}=^{n+1}\)
3:for\(t=1,,T\)do
4:\(_{t}_{}(}_{t}-_{t})\)
5:\(_{t}=_{t}/_{t},\)
6: Observe the loss vector \(_{t}^{n+1}\)
7:\(}_{t+1}_{}(}_{t}-( _{t},_{t}))\)
```

**Algorithm 3**Smooth \(^{*}\)

We start by highlighting a crucial property of \(^{*}\), _treeplex stepsize invariance._ The sequence of iterates \(_{1},...,_{T}\) generated by Algorithm 2 is independent of the choice of the stepsize \(>0\), that only rescales the sequences \(}_{1},...,}_{T}\) and \(_{1},...,_{T}\), the orthogonal projection onto a cone is positively homogeneous of degree 1: \(_{}()=_{}()\) for \(>0\) and \(^{n+1}\), and the function \(/,\) is scale-invariant: \(}{(,)}=}{,}\) for \(>0\) and \(^{n+1}\). We provide a rigorous statement in the following proposition and we present the proof in Appendix D.

**Proposition 4.1**.: _The sequence \(_{1},...,_{T}\) computed by \(^{*}\) is independent on the stepsize \(>0\)._

Treeplex stepsize invariance is a crucial property, since in large EFGs, stepsize tuning is difficult and resource-consuming. This is the main advantage of using Blackwell approachability: running \(\) directly on the treeplex \(\) does not result in a stepsize invariant algorithm, whereas \(^{*}\) runs \(\) on \(()\) and is stepsize invariant. To our knowledge, \(^{*}\) and \(^{*}\) are the only other treeplex stepsize invariant algorithms for solving EFGs. In fact, they satisfy a stronger _infoset stepsize invariance_ property: different stepsizes can be used at different infosets, and the iterates do not depend on their values. We discuss the relation between \(^{*}\) and known instantiations of Blackwell approachability over the simplex (\(^{*}\) and \(^{*}\)) in Appendix E.

From Proposition 3.1 and the regret bounds on \(\) (see for instance section 3.1.1 in  or section 6 in ), we obtain the following proposition. We define \(_{+}\) as \(:=_{}\|\|_{2}\).

**Proposition 4.2**.: _Let \(_{1},...,_{T}\) be computed by \(^{*}\). Then \(_{}_{t=1}^{T}_{t}-},_{t}^{T}\|(_{t},_{t} )-_{t}\|_{2}^{2}}\)._

From Proposition 4.2, \(^{*}\) is a regret minimizer over treeplexes, and we can combine it with the self-play framework to solve EFGs, as shown in the next corollary. We use the notations \(d:=\{n,m\}+1,:=\{\|\|_{2} \},\|\|_{2}:=_{} \|_{2}}{\|\|_{2}}\).

**Corollary 4.3**.: _Let \((_{t})_{t 1}\) and \((_{t})_{t 1}\) be the sequence of strategies computed by both players employing \(^{*}\) in the self-play framework, with previous losses as predictions: \(_{t}^{}=(_{t-1},_{t-1}),_{t}^{ }=(_{t-1},-^{}_{t-1})\). Let \((}_{T},}_{T})=_{t=1}^{T}(_{t}, _{t})\). Then_

\[_{}\,}_{T},-_{ }\,,}_{T}^{3}\|_{2}}}{}.\]

Finally, we can efficiently compute the orthogonal projection onto \(\), since \(\) admits the following simple formulation of as a polytope: \(=\{_{+}^{n+1}\,_{a_{j}}x_{ ja}=x_{p_{j}},\;j\}\).

**Proposition 4.4**.: _Let \(\) be a treeplex with depth \(d\), number of sequences \(n\), number of leaf sequences \(l\), and number of infostes \(m\). The orthogonal projection \(_{}()\) of a point \(^{n+1}\) onto \(=()\) can be computed in \(O(dn(l+m))\) arithmetic operations._

**A stable algorithm:**Smooth \(^{*}\). We now modify \(^{*}\) to obtain faster convergence rates. The \(O(1/)\) average convergence rate of \(^{*}\) may seem surprising since in the _matrix game_ setting, \(\) over the simplexes obtains a \(O(1/T)\) average convergence . This discrepancy comes from \(^{*}\) running \(\)_on the set \(=()\)_ instead of the original decision set \(\), so that the Lipschitz continuity of the loss function and the classical _RVU bounds_ (Regret Bounded by Variation in Utilities, see Equation (1) in ), central to proving the fast convergence of predictive algorithms, may not hold. For \(^{*}\), the Lipschitz continuity of the loss \((,)\) with \(=/,\) depends on the Lipschitz continuity of the decision function \(/,\) over \(\), which we analyze next.

**Proposition 4.5**.: _Let \(_{1},_{2}()\). Then \(\|_{1}}{_{1},}-_{2}}{ _{2},}\|_{2}_{1}- _{2}\|_{2}}{\{_{1},,_{2},\}}\)._

We present the proof of Proposition 4.5 in Appendix F. Proposition 4.5 shows that when the vector \(\) is such that \(,\) is small, the decision function \(/,\) may vary rapidly, an issue known as _instability_ and also observed for a predictive variant of \(^{*}\). To ensure the Lipschitzness of the decision function, we can ensure that \(_{t}\) and \(}_{t}\) always belong to the _stable region_\(_{}\):

\[_{}:=()\{^{n+1 }, R_{0}\}\]

for \(R_{0}>0\), and we recover Lipschitz continuity over \(_{}\):

\[\|_{1}}{_{1},}-_{2}}{ _{2},}\|_{2}}\|_{ 1}-_{2}\|_{2},\;_{1},_{2}_{}.\]

This leads us to introduce Smooth \(^{*}\)(Algorithm 3), a variant of \(^{*}\),where \(_{t}\) and \(}_{t}\) always belong to \(_{}\). For \(\)\(^{*}\),\(_{t}\) since \(_{t}_{}()\), and we also have the hyperplane forcing property (12), which only depends on \(_{t}=_{t}/_{t},\). However, \(\)\(^{*}\) is not treeplex stepsize invariant, because the orthogonal projections are onto \(_{}\), which is not a cone. Note that \(_{}\) admits a simple polytope formulation:

\[_{}=\{_{+}^{n+1} x_{} R_{0 },_{a_{j}}x_{ja}=x_{p_{j}},\;j\}\]

so the complexity of computing the orthogonal projection onto \(_{}\) is the same as computing the orthogonal projection onto \(\). We provide a proof in Appendix H. We now show that \(\)\(^{*}\) is a regret minimizer. Indeed, the proof of Proposition 3.1 can be adapted to relate the regret in \(_{1},...,_{T}\) in \(\) to regret in \(_{1},...,_{T}\) in \(_{}\).

**Proposition 4.6**.: _Let \(_{1},...,_{T}\) be computed by \(\)\(^{*}\). Let \(=}{^{T}\|f(_{t},_{t})-_{t} \|_{2}^{2}}}\). Then \(_{}}_{t=1}^{T}_{t}-}, _{t}^{T}\|f(_{t},_{t} )-_{t}\|_{2}^{2}}\)._In Smooth \( PTB^{*}\)\(_{t}\) and \(}_{t}\) always belong to \(_{}\), and we are able to recover a RVU bound and show faster convergence. We let \(\|\|\) be the maximum \(_{2}\)-norm of any column and any row of \(\).

**Theorem 4.7**.: _Let \((_{t})_{t 1}\) and \((_{t})_{t 1}\) be the sequence of strategies computed by both players employing \( Smooth\)\( PTB^{*}\) in the self-play framework, with previous losses as predictions: \(_{t}^{x}=(_{t-1},_{t-1}),_{t}^{y}=( _{t-1},-^{}_{t-1})\). Let \(=}{\|}}\) and \((}_{T},}_{T})=_{t=1}^{T}{(_{t},_{t})}\). Then \(_{}}_{T},- _{},}_{T} }{}\)._

We present the proof of Theorem 4.7 in Appendix I. To the best of our knowledge, \( Smooth\)\( PTB^{*}\) is the first algorithm based on Blackwell approachability achieving a \(O(1/T)\) convergence rate for solving EFGs as in (1), answering an important open question. However, achieving the faster rate in \( Smooth\)\( PTB^{*}\) requires introducing a stepsize, a situation similar to all other \(O(1/T)\)-methods for EFGs, like Mirror Prox and Excessive Gap Technique for EFGs  and predictive OMD directly on the treeplex . We can compare the \(O(1/T)\) convergence rate of \( Smooth\)\( PTB^{*}\) with the \(O(1/)\) convergence rate of Predictive \( CFR^{*}\), which combines CFR with Predictive \( RM^{*}\) (see Appendix B). Despite its predictive nature, Predictive \( CFR^{*}\) only achieves a \(O(1/)\) convergence rate because of the CFR decomposition, which enables running regret minimizers _independently and locally_ at each infoset, and it is not clear how to combine, at the treeplex level, the regret bounds obtained at each infoset. Since \( Smooth\)\( PTB^{*}\) operates over the entire treeplex, we can combine the RVU bound for each player to obtain a \(O(1/T)\) convergence rate.

**Remark 4.8**.: _The Clairvoyant CFR algorithm from  is based on Blackwell approachability over simplexes, combined with the CFR decomposition and a Mirror Prox-style update . For solving EFGs, Clairvoyant CFR achieves a \(O((T)/T))\) convergence rate, slower than the \(O(1/T)\) convergence rate of \( Smooth\)\( PTB^{*}\), where the additional \((T)\) factor occurs because each outer iteration of Clairvoyant CFR itself solves an approximate fixed-point problem._

For completeness, we also instantiate Algorithm 1 with regret minimizers that learn heterogeneous stepsizes across information sets in an adaptive fashion. This results in \( AdaGradTB^{*}\)(Algorithm 6) and \( AdamTB^{*}\)(Algorithm 7), which adapt the scale of the stepsizes for each dimension to the magnitude of the observed gradients for this dimension based on \( AdaGrad\) and \( Adam\). This may be useful if the losses across different dimensions differ in magnitudes, but the stepsizes decrease over time, which could be conservative. These algorithms are presented in Appendix J

**Remark 4.9** (Comparison with Lagrangian Hedging).: _Algorithm 1 is related to Lagrangian Hedging . Lagrangian Hedging builds upon Blackwell approachability with various potential functions to construct regret minimizers for general decision sets. As explained in the introduction, the main focus of our paper is on two-player zero-sum EFGs, i.e., on the case where the decision sets are treeplexes, and where we can obtain several additional interesting properties not studied in , such as stepsize invariance, fast convergence rates, and efficient projection, as we detail in the next section. If one were to instantiate Algorithm 1 with the Follow-The-Regularized Leader algorithm, it would yield the regret minimizer for treeplexes studied in Gordon , and our Proposition 4.4 in the next section yields an efficient projection oracle for the setup in Gordon , which appealed to general convex optimization as an oracle._

## 5 Numerical Experiments

Figure 2: Convergence to a Nash equilibrium for \( PTB^{*}\), \( CFR^{*}\), \( PCFR^{*}\) and \( SC\)-POMD. All algorithms use alternation and quadratic averaging except \( CFR^{*}\) instantiated with linear averaging.

We conduct two sets of numerical experiments to investigate the performance of our algorithms for solving several two-player zero-sum EFG benchmark games: Kuhn poker, Leduc poker, Liar's Dice, Goofspiel and Battleship. Additional experimental detail is given in Appendix K.

We first determine the best instantiatons our framework. We compare PTB*, Smooth PTB* and AdaGradTB* in the self-play framework with alternation (see Appendix A) and uniform, linear or quadratic weights for the iterates. PTB* and Smooth PTB* use the previous losses as predictions. We also study _Treeplex Blackwell_+ (TB*), corresponding to PTB* without predictions (\(_{t}=\)), and AdamTB*. For conciseness, we present our plots in Appendix K.3 (Figure 4) and state our conclusion here. We find that, for every game, PTB* performs the best or is among the best algorithms. This underlines the advantage of _treeplex stepsize invariance_ over algorithms that require tuning a stepsize (Smooth PTB*) and adaptive algorithms (AdaGradTB*), which may perform poorly due to the stepsize decreasing at a rate of \(O(1/)\). AdamTB* does not even converge in some games.

We then compare the best of our algorithms (PTB*) with some of the best existing methods for solving EFGs: CFR*, predictive CFR* (PCFR*, , see Appendix B), and a version of optimistic online mirror descent with a single call to the orthogonal projection at every iteration (SC-POMD, ) achieving a \(O(1/T)\) convergence rate; there are a variety of FOMs with a \(O(1/T)\) rate, SC-POMD was observed to perform well in . We determine the best empirical setup for each algorithm in Appendix K.4. In Figure 2, we compare the performance of the (weighted) average iterates. We find that PCFR* outperforms both CFR* and the theoretically-faster SC-POMD, as expected from past work. We had hoped to see at least comparable performance between PTB* and PCFR*, since they are both based on Blackwell-approachability regret minimizers derived from applying POMD on the conic hull of their respective decision sets (simplexes at each infoset for PCFR*, treeplexes of each player for PTB*). However, in some games PCFR* performs much better than PTB*. Given the similarity between PTB* and PCFR*, our results suggest that the use of the CFR decomposition is part of the key to the performance of PCFR*. The CFR decomposition allows PCFR* to have stepsize invariance _at an infoset level_, as opposed to stepsize invariance at the treeplex level in PTB*. Because of the structure of treeplexes, the numerical values of variables associated with infosets appearing late in the game, i.e., deeper in the treeplexes, may be much smaller than the numerical values of the variables appearing closer to the root. For this reason, allowing for different stepsizes at each infosets (like CFR* and PCFR* do) appears to be more efficient than using a single stepsize across all the infosets, even when the iterates do not depend on the value of this single stepsize (like in PTB*) and when this stepsize is fine-tuned (like in SC-POMD). Of course one could try to run SC-POMD with different stepsizes at each infoset and attempt to tune each of these stepsizes, but this is impossible in practical instances where the number of actions is large, e.g., \(4.9 10^{4}\) actions in _Liar's Dice_ and \(5.3 10^{6}\) actions in _Goofspiel_. CFR* and PCFR* bypass this issue with their infoset stepsize invariance, which enables both each infoset to have its own stepsize (via the CFR decomposition) _and_ not needing to choose these stepsizes (via using RM* and PRM* as local regret minimizers, which are stepsize invariant).

We also investigate the performance of the _last iterates_ in Figure 3. No algorithm appears to be the best across all game instances. CFR* may not converge to a Nash equilibrium (e.g., on Kuhn), as has been observed before . PCFR* exhibits linear convergence in some games (Kuhn, Liar's Dice, Goofspiel) but not others (Leduc). The same is true for PTB*. Further investigations about last-iterate convergence are left as an important open question.

Figure 3: Convergence to a Nash equilibrium for the last iterates of PTB*, CFR*, PCFR*, and SC-POMD. Every algorithm is using alternation.

Conclusion

We propose the first Blackwell approachability-based regret minimizer over the treeplex (Algorithm 1) and we give several instantiations of our framework with different properties, including treeplex stepsize invariance (\(^{*}\)), adaptive stepsizes (\(^{*}\)) and achieving \(O(1/T)\) convergence rates on EFGs with a Blackwell approachability-based algorithm for the first time (\(^{*}\)). Since \(^{*}\) and \(^{*}\) are stepsize invariant and have strong empirical performance, we were expecting \(^{*}\) to have comparable performance. However, our experiments show that \(^{*}\) often converges slower than \(^{*}\) and \(^{*}\), so this treeplex stepsize invariance is not the only driver behind the practical performance of \(^{*}\) and \(^{*}\). We view this negative result as an important contribution of our paper, since it rules out a previously plausible explanation for the practical performance of \(^{*}\). Instead, we propose that one piece of the puzzle behind the \(^{*}\) and \(^{*}\) performances is their _infoset_ stepsize invariance, a consequence of combining the CFR framework with Blackwell approachability-based regret minimizers (\(^{*}\) and \(^{*}\), themselves stepsize invariant over simplexes). Future directions include better understanding the last-iterate performance of algorithms based on Blackwell approachability as well as the role of alternation. It would also be interesting to explore EFG applications of new reductions between Blackwell approachability and regret minimization  (which differs from the reduction in ) and Blackwell approachability generalizations based on various norms and pseudo-norms , potentially to obtain better stepsize invariance properties.