# Supplementary Material for

Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning

 Guozheng Ma\({}^{1}\) Linrui Zhang\({}^{1}\) Haoyu Wang\({}^{1}\) Lu Li\({}^{1}\) Zilin Wang\({}^{1}\)

Zhen Wang\({}^{2}\) Li Shen\({}^{3}\)1 Xueqian Wang\({}^{1}\)1 Dacheng Tao\({}^{2}\)

\({}^{1}\)Tsinghua University \({}^{2}\)The University of Sydney \({}^{3}\)JD Explore Academy

{mgz21,haoyuwa22,liu21,wangzl21}@mails.tsinghua.edu.cn

zwan4121@uni.sydney.edu.au; wang.xq@sz.tsinghua.edu.cn

{zhanglr.auto,mathshenli,dacheng.tao}@gmail.com

Corresponding authors: Li Shen and Xueqian Wang

###### Abstract

Data augmentation (DA) is a crucial technique for enhancing the sample efficiency of visual reinforcement learning (RL) algorithms. Notably, employing simple observation transformations alone can yield outstanding performance without extra auxiliary representation tasks or pre-trained encoders. However, it remains unclear _which attributes of DA account for its effectiveness in achieving sample-efficient visual RL_. To investigate this issue and further explore the potential of DA, this work conducts comprehensive experiments to assess the impact of DA's attributes on its efficacy and provides the following insights and improvements: (1) For _individual DA operations_, we reveal that both ample spatial diversity and slight hardness are indispensable. Building on this finding, we introduce Random PadResize (Rand PR), a new DA operation that offers abundant spatial diversity with minimal hardness. (2) For _multi-type DA fusion schemes_, the increased DA hardness and unstable data distribution result in the current fusion schemes being unable to achieve higher sample efficiency than their corresponding individual operations. Taking the non-stationary nature of RL into account, we propose a RL-tailored multi-type DA fusion scheme called Cycling Augmentation (CycAug), which performs periodic cycles of different DA operations to increase type diversity while maintaining data distribution consistency. Extensive evaluations on the DeepMind Control suite and CARLA driving simulator demonstrate that our methods achieve superior sample efficiency compared with the prior state-of-the-art methods.

## 1 Introduction

Visual reinforcement learning (RL) has shown great potential in various domains, enabling decision-making directly from high-dimensional visual inputs . However, the dual requirements of simultaneously learning compact state representations and optimizing task-specific policies lead to prohibitive sample complexity and massive environment interactions, hindering its practical deployment . Enhancing sample efficiency is a critical and inevitable challenge faced by the entire visual RL community, and data augmentation (DA) has emerged as a remarkably effective approach to tackle this issue . As illustrated in Figure 1, even simple random shift transformations applied to input observations can lead to significant performance improvements in previously unsuccessful algorithm . Moreover, it has been proven that DA alone can lead to more

Figure 1: Benefit of DA in visual RL.

efficient performance compared with meticulously crafting self-supervised learning tasks  or pre-training representation encoders with extra data . The substantial effectiveness of DA in improving sample efficiency has established it as an essential and indispensable component in the vast majority of visual RL methods [4; 5; 7; 10; 11; 12].

However, recent research has predominantly concentrated on integrating DA with other complementary techniques to enhance performance [7; 13; 14; 15; 16; 17], while ignoring the opportunity to fully explore and harness the intrinsic potential of DA operations themselves. There is a notable absence of actionable guidelines for designing more effective DA operations specifically tailored to visual RL scenarios. Motivated by this imperative requirement, it is crucial to undertake a thorough investigation and in-depth analysis to explore a fundamental question:

_Which attributes enable effective DA for achieving sample-efficient visual RL?_

Hence, this study begins with comprehensive experiments in order to assess the essential attributes of DA for enhancing sample efficiency in visual RL. Specifically, we unpack the attributes of DA operations in terms of _hardness_ and _diversity_, which are two main dimensions that previous studies leveraged to deconstruct DA in other domains [18; 19; 20; 21]. The extensive experiments provide strong support for the following key findings, which highlight the distinctive requirements of visual RL: \(\) The training performance of visual RL is highly sensitive to the increase of DA's hardness. \(\) Sufficient spatial diversity is an indispensable attribute for achieving effective DA. \(\) Unlimited increases in strength diversity can harm visual RL performance. \(\) Despite the increased type diversity, naively applying multi-type DA to visual RL training can lead to decreased performance.

Drawing upon these findings, we propose two actionable guidelines and corresponding strategies for enhancing the effectiveness of DA in visual RL. (**1**) For _individual DA operations_, we reveal that effective operations should exhibit sufficient spatial diversity with minimal hardness. Building on this insight, we introduce Random PadResize (Rand PR), a new DA transformation that satisfies the essential attributes required for visual RL. Rand PR alleviates the hardness of DA by preventing the loss of information in observations, which is inevitable in the conventional PadCrop transformation that widely used in previous methods such as DrQ-v2 . Additionally, it provides significant spatial diversity by randomly scaling and positioning the original content within the final input space. (**2**) For _multi-type DA fusion schemes_, it is imperative to take the data-sensitive nature of RL training into account when designing appropriate fusion schemes in visual RL. Inspired by this guideline, we propose a RL-tailored multi-type DA fusion scheme called Cycling Augmentation (CycAug), which leverages the diversity benefits of multiple DAs by cyclically applying different transformations while mitigating the negative impact on training stability caused by the excessively frequent changes in data distribution. With Rand PR as a key component, CyCAug achieves superior sample efficiency on various tasks of the DeepMind Control suite . Moreover, in the challenging low data regime of CARLA , CyCAug outperforms the previous SOTA algorithm by a substantial margin of \(43.7\%\).

In the end, our main contributions can be summarized as following three-fold:

1. We conduct extensive experiments to investigate the essential DA attributes for achieving sample-efficient visual RL and highlight the unique requirements of visual RL for DA.
2. We present two actionable guidelines to further exploit the potential of DA, specifically focusing on individual DA operations and multi-type DA fusion schemes. Building upon these guidelines, we propose Rand PR and CyCAug as corresponding improvement strategies.
3. CyCAug, incorporating Rand PR as a key component, achieves state-of-the-art sample efficiency in extensive benchmark tasks on DM Control and CARLA.

## 2 Related Work

In this section, we provide a succinct overview of prior research conducted in sample-efficient visual RL, as well as DA methods utilized in the broader domain of deep learning.

### Sample-Efficient Visual RL

Visual RL entails learning compact state representations from high-dimensional observations and optimizing task-specific policies at the same time, resulting in a prohibitive sample complexity . To enhance sample efficiency, the first widely adopted approach is leveraging self-supervised learning to promote agent's representation learning. Specifically, various _auxiliary tasks_ have been designed in previous studies, including pixel or latent reconstruction [2; 14], future prediction [24; 7; 13] and contrastive learning for instance discrimination [16; 17; 15] or temporal discrimination [25; 26; 27; 28]. Another approach aimed at facilitating representation learning is to _pre-train a visual encoder_ that enables efficient adaptation to downstream tasks [29; 30; 31; 32; 33; 34]. Additionally, a number of model-based methods explicitly construct a _world model_ of the RL environment in either pixel or latent spaces to enable planning [35; 36; 37; 38; 39; 40; 41]. Orthogonal to these methods, DA has demonstrated astonishing effectiveness in improving the sample efficiency of visual RL algorithms [10; 4; 5]. Moreover, recent research has focused on effectively integrating DA with other representation learning methods to further enhance sample efficiency [7; 13; 16; 25; 14]. However, the intrinsic potential of DA operations has been inadequately explored. To address this research gap, this study conducts thorough experiments to investigate the fundamental attributes that contribute to the effectiveness of DA and subsequently provide actionable guidelines for DA design. Furthermore, we illustrate that developing more effective DA methods alone can result in a substantial improvement in sample efficiency.

### Data Augmentation (DA)

Over the past decades, DA has achieved widespread recognition and adoption within the deep learning community [42; 43; 44; 45; 46; 47; 48]. For clarity, we classify previous studies on DA into two distinct aspects: individual DA operations, which utilize single-type data transformations, and multi-type DA fusion methods, which combine diverse DA operations through specific fusion schemes.

**Individual DA Operations.** Numerous studies have shown that the adoption of more effective DA techniques can result in substantial improvements across various tasks [49; 50; 51], such as Mixup  for image classification, DiffAugment  for GAN training, and Copy-Paste  for instance segmentation, among others. However, there has been a lack of investigation into the design of DA operations that specifically align with the requirements of sample-efficient visual RL. Only the early studies, RAD  and DrQ , conducted initial ablations and suggested that geometric transformations, exemplified by PadCrop, can achieve the best sample efficiency performance. More details regarding the previous DA design are in Appendix A.2. To achieve more precise design of DA operations, our study delves into an in-depth analysis of the essential DA attributes required for sample-efficient visual RL. Based on this analysis, we propose two actionable guidelines along with corresponding specific improvement strategies to enhance the effectiveness of DA methods.

**Multi-Type DA Fusion Methods.** The commonly employed multi-type DA fusion schemes can be categorized into three types: composing-based fusion [54; 55], mixing-based fusion [46; 48] and sampling-based fusion [56; 45]. Due to space constraints, we provide an expanded exposition of previous fusion schemes and their illustrations in Appendix A.3. While these fusion methods have proven effective in improving training accuracy and robustness in supervised and self-supervised learning [44; 18; 20; 57], our experiments in Section 3.2 indicate that they cannot result in improved sample efficiency in visual RL. Our proposed RL-tailored fusion scheme, CycAug, adopts individual operations during each update to prevent excessive increases in the hardness level, in contrast to composition-based and mixing-based fusion schemes [54; 55; 46; 19]. Additionally, CycAug performs periodic cycles of different DA operations at predetermined intervals, avoiding the instability caused by frequent switching of DA types between each update, unlike the sampling-based fusion approach [56; 45]. This way, CycAug can benefit from the type diversity brought by different operations while avoiding the aforementioned drawbacks.

## 3 Rethinking the Essential Attributes of DA for Sample-Efficient Visual RL

In this section, we analyze the attributes of DA, focusing on hardness and diversity, and thoroughly investigate their impact on DA's effectiveness in achieving sample-efficient visual RL.

### Unpacking the Attributes of DA

**Hardness.** Hardness is a model-dependent measure of distribution shift, which was initially defined as the ratio of performance drop on augmented test data for a model trained in clean data [18; 20]. Considering the RL paradigm, the definition of hardness can be adapted to:

\[=(,)\! (,^{}),\] (1)

where \(\) denotes the policy trained in the original Markov Decision Process (MDP) \(\) without DA. \((,)\) and \((,^{})\) represent the average episode return of policy \(\) achieved in \(\) and \(^{}\), respectively. The only difference between the original MDP \(=(,,P,R,,d_{0})\) and the augmented MDP \(^{}=(^{},,P,R,, d_{0})\) lies in the observation space where \(^{}\) is obtained by applying DA to \(\). Consistent with previous studies [18; 20], we observe a strong linear positive correlation between the hardness level and strength of individual DA operations in visual RL (refer to Appendix B.1 for further details). This implies that precise control of the hardness level of DA can be achieved by adjusting the strength of individual transformations.

**Diversity.** Another critical attribute of DA is diversity, which quantifies the randomness (degrees of freedom) of the augmented data [20; 18]. Typically, DA's diversity can be achieved through the following three approaches that we will investigate separately in Section 3.2. \(\)_Strength Diversity_ refers to the variability of strength values, and a wider range indicates greater diversity . In our experiments, we manipulate the strength diversity by expanding the range of hardness values while maintaining a constant average hardness. \(\)_Spatial Diversity_ denotes the inherent randomness in the geometric transformations . For example, the spatial diversity of the Translate operation can be characterized by the number of possible directions allowed for translations. \(\)_Type Diversity_ is widely employed in numerous state-of-the-art DA methods by combining multiple types of operations. Enhancing type diversity is widely recognized as an effective strategy to explore the potential of DA. We provide a visual illustration in Appendix B.2 to facilitate a better understanding of the three different categories of diversity.

### Investigating the Impact of DA's Attributes on Sample Efficiency

This section aims to comprehensively evaluate how hardness, strength diversity, spatial diversity, and type diversity impact the effectiveness of DA in sample-efficient visual RL. To conduct this investigation, we introduce three individual DA operations, namely PadResize-HD, CropShift-HD and Translate-HD. These operations provide precise control over the hardness level through mean strength, the strength diversity level through the range of strength, and the spatial diversity level through the degree of freedom. Meanwhile, each individual operation possesses a fixed level of type diversity. Implementation details and example demonstrations can be found in the Appendix C.1. Following experiments are conducted in the DeepMind Control (DMC) suite , where we apply diverse DA operations across various tasks to robustly assess the essential attributes. For each given scenario, we perform \(10\) random runs with \(10\) testing evaluations per seed and report the interquartile mean (IQM) of these \(10\) evaluation episode returns . Detailed setup is in Appendix C.2.

How Hardness Affects the Effectiveness of DA?We investigate the impact of hardness on individual DA by varying the level of hardness while maintaining a constant level of diversity. As illustrated in Figure 2, the agent's performance exhibits a steep decline with the increase of hardness. In additional, DA can even lead to a deleterious impact once the hardness level goes beyond a certain threshold. Compared with other domains such as supervised learning [19; 21], our experiments reveal that the training process of visual RL is significantly sensitive to the hardness level of DA.

**Finding 1**: Maintaining a low level of DA hardness is a crucial priority in visual RL, as even minor increases in hardness can have a significant negative impact on training performance.

Figure 2: The impact of hardness on individual DA effectiveness. We present the IQM scores of \(6\) distinct individual DA operations, with fixed diversity levels while varying their hardness level. The maximum environment interactions is limited to \(5 10^{5}\) steps (consistently throughout this section). “Strength D” and “Spatial D” are abbreviations for Strength Diversity and Spatial Diversity. The gray line denotes the performance without DA. Further comparative results are in Appendix C.3.

How Strength Diversity Affects the Effectiveness of DA?

Strength diversity is a readily modifiable attribute that can improve the overall diversity of DA, for instance, by enlarging the range of rotation permitted in Rotate. We manipulate the range of strength while maintaining spatial diversity and a constant average hardness/strength level. The trends depicted in Figure 3 suggest that a moderate level of strength diversity can yield the most favorable enhancement effect. Insufficient strength diversity fails to meet the randomness demand of RL training, particularly when the individual DA's spatial diversity is constrained. Meanwhile, excessive strength diversity can also lead to a drastic decrease in the DA effect. This is attributed to the high sensitivity of RL to hardness, as increasing strength diversity unavoidably amplifies the highest hardness of the DA.

How Spatial Diversity Affects the Effectiveness of DA?The PadCrop operation (also named Random Shift in the original paper ) has shown outstanding effectiveness in improving the sample efficiency of visual RL algorithms. The subsequent studies further revealed that this individual PadCrop operation can provide significant smoothness and randomness, thus preventing unfavorable self-overfitting . Compared to other DA operations such as Translate and Rotate, PadCrop exhibits greater diversity in spatial randomness. As such, spatial diversity is highly regarded as a crucial determinant of whether DA can effectively enhance the sample efficiency of visual RL. We evaluate the influence of spatial diversity on the DA effect by incrementally loosening the restriction on it while maintaining a consistent level of hardness. The experimental trends consistently indicate that spatial diversity plays a crucial role in achieving effective DA.

Figure 4: The impact of spatial diversity on individual DA effectiveness. We provide a thorough analysis of the correlation between sample efficiency and spatial diversity of 3 individual DA operations at varying levels of hardness. Training curves are provided in the Appendix C.5.

Figure 3: The impact of strength diversity on individual DA effectiveness. Strength diversity is generated by defining five gradual ranges of strength with a fixed mean hardness level. During training, the specific strength applied to different batches is randomly sampled from the given range. For detailed settings regarding the strength ranges, please consult Appendix C.4.

How Type Diversity Affects the Effectiveness of DA?

Multi-type DA fusion methods have been widely adopted as a paradigm for overcoming the limitations of individual DA operations. This implies that enhancing type diversity is an effective approach to improve the effectiveness of DA [46; 45]. In this part, we conduct a comprehensive evaluation of the impact of type diversity by testing three main fusion schemes with six different DA operations. Surprisingly, none of the fusion schemes outperformed their corresponding individual operations. This abnormal failure can be attributed to the increased data hardness caused by the complex transformations (in the case of composition-based and mixing-based fusion ) or to the dynamic fluctuations in the data distribution that result from frequent switching between different types of DA operations (in the case of sampling-based fusion [45; 55]). These adverse effects are further compounded when transferring the fusion schemes from supervised learning to RL, mainly due to the non-stationary nature of the RL training process and its high sensitivity to the hardness of the DA [61; 62].

**Overall,** the aforementioned findings provide two key insights for further harnessing the potential of DA in sample-efficient visual RL: \(\)**For _individual DA operations_**, maintaining a minor level of hardness and maximizing its spatial diversity are two crucial measures to enhance the effectiveness of DA. On the contrary, indiscriminately increasing strength diversity may not always be a prudent approach, as it inevitably amplifies the highest level of hardness. \(\)**For _multi-type DA fusion schemes_**, exploring RL-tailored fusion schemes that leverage the advantages of diverse DA types is a promising approach to maximize the effectiveness of DA. However, adaptive fusion schemes must avoid introducing extra hardness of DA and ensure data stability during training.

## 4 Methodologies for Enhancing the Effectiveness of DA

Drawing on the insights gained in the previous rethinking, this section presents our corresponding improvement measures. Firstly, we propose a novel individual DA operation, Random PadResize (Rand PR), that ensures slight hardness by preserving content information while providing ample spatial diversity through random scaling and location. Secondly, we introduce Cycling Augmentation (CycAug), a multi-type DA fusion scheme tailored to the unstable nature of RL training.

### Random PadResize (Rand PR): A Diverse yet Hardness-Minimal DA Operation

As recommended in the previous section, an individual DA operation for enhancing the sample efficiency of visual RL should provide as ample spatial diversity as possible while ensuring a low level of hardness. This insight reveals the key factors behind the previous impressive success of PadCrop (Shift) augmentation [10; 4; 5]. It offers greater spatial diversity than common Translate and Rotate operations due to its increased degree of freedom in shift, while also introducing lower augmentation hardness than Cutout and Color Jitter. However, the crop operation in PadCrop

Figure 5: The impact of combining two distinct DA operations using three widely employed fusion schemes. The reported performances are the average scores evaluated after \(1.5 10^{6}\) interactions on _Quadruped Run_. The entries along the main axis correspond to using only one individual operation. Additional experimental results and analysis can be found in Appendix C.6 for further reference.

inevitably leads to a loss of observation information. Although such loss may not have severe consequences in the DM Control suite  due to the agent always being in the center of the image with fixed camera position , it can lead to high hardness in real-world scenarios where task-relevant information near the observation boundaries will be reduced.

Motivated by aforementioned weakness of the original PadCrop operation, we introduce a modified version, Random PadResize (Rand PR), which offers increased diversity while minimizing augmentation hardness. As illustrated in Figure 6 (Left), Rand PR randomly adds a specified number of pixels in each direction of the image and then resizes it back to the original size. The sum of pixels padded in each direction (i.e., top, bottom, left, and right) is defined as the strength of this operation. Rand PR offers sufficient spatial diversity through its large degrees of freedom in scaling ratio and content location while avoiding the high hardness introduced by information reduction. The comparative experiment conducted in the _Cartpole Balance_ task demonstrated that our Rand PR can achieve lower hardness than the original PadCrop operation, as shown in Figure 6 (Right).

### Cycling Augmentation (CycAug): A Multi-Type DA Scheme Tailored to RL

As demonstrated in Section 3.2, generic multi-type DA fusion paradigms utilized in other fields cannot improve the sample efficiency of visual RL algorithms. Consequently, our second improvement measure focuses on devising a multi-type DA fusion scheme tailored for visual RL tasks.

We argue that the failure of generic multi-type DA fusion methods is mainly due to the struggle nature of RL training, which makes it highly sensitive to both the hardness and distribution evolving of the training data. Considering the inherent instability of the RL training process, we provide two recommendations: (1) to apply only one type of individual operation in each update to avoid introducing additional hardness, and (2) to appropriately reduce the frequency of switching between different operations to maintain the data distribution consistency during training. Based on these recommendations, we propose a multi-type DA fusion scheme specifically tailored for RL training, called Cycling Augmentation (CycAug). CyCAug enables visual RL to benefit from type diversity while ensuring the adequate stability during the learning process. Specifically, CyCAug applies individual operations during each update and cyclically switches between different types of operations after a certain number of steps. In addition, the experiments in Section 3.2 indicate that the efficacy of individual operations strongly influences the performance of their fusion. Consequently, in this paper, we adopt PadCrop and Random PR as two individual DA components for CyCAug.

Figure 6: **(Left) Illustration of the Random PadResize operation. The four augmented observations exhibit substantial spatial diversity through differentiated scaling ratios and locations, while fully retaining the observation information. (Right) The hardness comparison between PadResize and PadCrop. We train 10 agents without DA in the _Cartpole Balance_ task and evaluate their performance on augmented observations generated by PadCrop and PadResize. The results indicate that PadResize achieves lower hardness. For fairness, we set pad=4 in PadCrop and strength=\(16\) in PadResize.**

Figure 7: Illustration of the CyCAug scheme: (a) The CyCAug pipeline consists of a simple workflow optimized for the RL objective, without the need for complex auxiliary representation tasks. (b) CyCAug achieves multi-type DA fusion by cyclically switching between different types of operations.

## 5 Empirical Evaluation

In this section, we evaluate the effectiveness of Rand PR and CyCAug in enhancing the sample efficiency of visual RL algorithms. We conduct extensive experiments on both the DeepMind control suite  and the challenging autonomous driving simulator, CARLA  The code is accessible at https://github.com/Guozheng-Ma/CycAug. Furthermore, we provide empirical evidence to demonstrate the effectiveness of CyCAug in ensuring training stability, as well as its scalability across an expanded range of augmentation quantities and types destined for fusion.

### Evaluation on DeepMind Control Suite

**Setup.** We first evaluate our methods on continuous control tasks in the DM Control suite. Concretely, we integrate Rand PR and CyCAug into the training procedure and network architecture of DrQ-V2 , while modifying its DA operation. We also compare our results with A-LIX , which achieved superior efficiency on this benchmark by using adaptive regularization on the encoder's gradients. Additionally, we include the performance of the original DrQ , CURL , and SAC  to demonstrate the significant improvement in sample efficiency achieved by our methods. For evaluation, we have chosen a collection of 12 challenging tasks from the DMC that showcase various difficulties such as complex dynamics, sparse rewards, and demanding exploration requirements. To assess sample efficiency, we limit the maximum number of training frames to \(1.5 10^{6}\), which is half of the value employed in DrQ-V2. The cycling interval of CyCAug is set to \(10^{5}\) steps, i.e, \(2 10^{5}\) frames with \(2\) action repeat. More setup details are placed in Appendix D.1 due to page limit.

**Results.** The evaluation results are exhibited in Table 1, along with the training curves of four representative tasks, presented in Figure 8. Overall, Rand PR achieves competitive sample efficiency compared to the original PadCrop operation, while CyCAug outperforms all previous methods in both efficiency and final performance by a significant margin. In particular, CyCAug demonstrates more

   Tasks & SAC & CURL & DrQ & DrQ-V2 & A-LIX & Rand PR & CyCAug \\  Acrobot Swingup & \(8 9\) & \(6 5\) & \(24 27\) & \(256 47\) & \(270 99\) & \(240 37\) & \(\) \\ Cartpole Swingup Sparse & \(118 233\) & \(479 329\) & \(318 389\) & \(485 396\) & \(\) & \(549 125\) & \(682 297\) \\ Cheetah Run & \(9 8\) & \(507 114\) & \(788 59\) & \(792 29\) & \(\) & \(745 28\) & \(799 62\) \\ Finger Turn Easy & \(190 137\) & \(297 150\) & \(199 132\) & \(854 73\) & \(546 101\) & \(846 112\) & \(\) \\ Finger Turn Hard & \(79 73\) & \(174 106\) & \(100 63\) & \(491 182\) & \(587 109\) & \(619 289\) & \(\) \\ Hopper Hop & \(0 0\) & \(184 127\) & \(268 91\) & \(198 102\) & \(287 48\) & \(285 122\) & \(\) \\ Quadruped Run & \(68 72\) & \(164 91\) & \(129 97\) & \(419 204\) & \(528 107\) & \(543 1131\) & \(\) \\ Quadruped Walk & \(75 65\) & \(134 53\) & \(144 149\) & \(591 256\) & \(776 37\) & \(689 99\) & \(\) \\ Reach Duplo & \(1 1\) & \(8 10\) & \(8 12\) & \(220 7\) & \(212 3\) & \(217 13\) & \(\) \\ Reacher Easy & \(52 64\) & \(707 142\) & \(600 201\) & \(\) & \(887 19\) & \(965 8\) & \(\) \\ Reacher Hard & \(3 2\) & \(463 196\) & \(320 233\) & \(\) & \(720 83\) & \(725 91\) & \(697 179\) \\ Walker Run & \(26 4\) & \(379 234\) & \(474 148\) & \(571 276\) & \(691 10\) & \(642 141\) & \(\) \\  Average score & 52.28 & 291.73 & 281.03 & 547.96 & 585.67 & 588.75 & **654.83** \\   

Table 1: Evaluation of Sample Efficiency on the DeepMind Control Suite. We report the average episode return over 10 random seeds and 10 evaluation runs after training for 1.5M frames. The results of previous methods are sourced from the A-LIX  report.

Figure 8: Training Curves of 4 Representative Challenging Tasks in DMC: _Finger Turn Hard_, _Hopper Hop_, _Quadruped Run_ and _Walker Run_. The curves of DrQ-V2 are adopted from its original paper.

substantial performance improvements in several challenging tasks, including _Finger Turn Hard_ with sparse rewards and _Quadruped Run_ with a large action space. This confirms that cycling-based fusion of multi-type DA operations effectively mitigates catastrophic self-overfitting, which prior works identified as a critical limitation to visual RL performance [59; 64; 65; 60].

### Evaluation on Autonomous Driving in CARLA

**Setup.** We conduct a second round of evaluation on more challenging tasks using the autonomous driving simulator CARLA . We adopt the reward function and task setting from prior work , where the objective of the agent is to drive along a winding road for as long as possible within limited time-steps while avoiding collisions with other vehicles. We set the maximum number of allowed environment interactions to \(2 10^{5}\) steps, and configure the CyCAug cycling interval to be \(2 10^{4}\) steps. To demonstrate the efficacy of our proposed augmentation methods, we compare Rand PR and CyCAug against the original DrQ-V2 with random shift (PadCrop) and the baseline without DA. We include a detailed account of the experimental setup and hyperparameters in Appendix D.2.

**Results.** The evaluation results presented in Table 2 and Figure 9 further validate the efficacy of our proposed improvements in enhancing DA for more sample-efficient visual RL. Different weather conditions not only provide a rich set of realistic observations but also introduce diverse dynamics within the environments. In general, Rand PR outperforms the original DrQ-V2 with PadCrop as DA, indicating that preserving boundary information can effectively reduce the hardness of DA and thus improves sample efficiency in realistic environments. Furthermore, CyCAug outperforms the previous SOTA algorithm by substantial margins \(23.8\%\) in final performance and \(43.7\%\) in low data regime.

### Ablation Study and Detailed Analysis.

**Training Stability.** RL training is highly sensitive to data stability ; hence, when fusing various DA operations to enhance diversity, it is imperative to minimize frequent distribution shifts to ensure stability. To quantitatively assess training stability, we measure the _Q Variance_ and _Q-Target Variance_ during the training process, adhering to the experimental methodology outlined by . The results presented in Figure 10 demonstrate that CyCAug can optimally preserve training stability in comparison to other fusion approaches.

**Expanded DA Quantities and Types.** We primarily demonstrate the performance of CyCAug when fusing PadCrop and Rand PR as components. However, as a multi-type DA fusion scheme, CyCAug

    &  &  \\  Weather & w/o DA & DrQ-V2 & Rand PR & CyCAug & w/o DA & DrQ-V2 & Rand PR & CyCAug \\  Default & \(62.6 15\) & \(94.7 34\) & \(99.5 13\) & \(\) & \(90.3 29\) & \(213.7 27\) & \(232.9 8\) & \(\) \\ WetNon & \(65.4 11\) & \(106.8 12\) & \(118.8 20\) & \(\) & \(106.5 26\) & \(208.5 13\) & \(215.4 18\) & \(\) \\ SoftRainNon & \(46.7 30\) & \(93.9 12\) & \(121.2 7\) & \(\) & \(90.6 62\) & \(219.6 24\) & \(221.9 40\) & \(\) \\ HardRainSunset & \(52.2 35\) & \(103.5 7\) & \(103.9 18\) & \(\) & \(82.7 60\) & \(229.4 16\) & \(240.5 15\) & \(\) \\  Average Score & \(56.7\) & \(99.7\) & \(110.8\) & \(\) (+43.7\%) & \(92.5\) & \(217.8\) & \(227.7\) & \(\) \\   

Table 2: Evaluation of sample efficiency on CARLA with 4 different weathers. The average episode returns are averaged over 5 seeds and 20 evaluation runs after 100k and 200k training steps.

Figure 9: Training Curves of CyCAug, Rand PR, original DrQ-V2  and the baseline without DA across 4 CARLA environments. The model architecture follows that of DrQ-V2, while we focus on manipulating the DA operations. The line plots denote the average episode returns across 5 seeds.

can integrate a wider variety of DA operations in greater quantities, provided these DA operations are individually effective. We illustrate the scalability of CyCAug in Figure 11. Three-component CyCAug utilizing PC, PR, and CS attains superior sample efficiency versus the dual-component CyCAug with PC and PR, exhibiting the capacity for additional expansion of CyCAug.

## 6 Conclusion

In conclusion, this work investigates the critical DA attributes for improving sample efficiency in visual RL and proposes two methods to enhance its effectiveness. We find that both spatial diversity and slight hardness are crucial for individual DA operations, and introduce Random PadResize (Rand PR) as a new transformation that satisfies these attributes. We also propose a multi-type DA fusion scheme, referred to as Cycling Augmentation (CycAug), which employs a cyclic application of different DA operations to enhance type diversity while ensuring data distribution consistency for stability. The evaluations on the DeepMind Control suite and CARLA demonstrate the superior sample efficiency of CyCAug with Rand PR as a key component, surpassing previous SOTA methods. Furthermore, this work demonstrates the potential of enhancing sample-efficient visual RL through more effective DA operations, without modifying the underlying RL algorithm or network architecture. Therefore, we advocate for a greater emphasis on data-centric methods in the visual RL community.

**Limitations.** We investigate the essential attributes of DA for sample-efficient visual RL. However, further research is needed to understand how these attributes impact visual RL training fundamentally.

**Acknowledgements.** This work is supported by STI 2030--Major Projects (No. 2021ZD0201405). We thank Yunjie Su, Zixuan Liu, and Zexin Li for their valuable suggestions and collaboration. We sincerely appreciate the time and effort invested by the anonymous reviewers in evaluating our work, and are grateful for their valuable and insightful feedback.

Figure 11: Expanded DA components integrated by CyCAug. **(Left) More Types.** Employing CyCAug to fuse the commonly employed DA approach of PadCrop (PC) with other DA operations reveals varied performance outcomes. **(Right) More Quantities.** The effect of further integrating the original CyCAug (PC+PR) with the third DA operation depends on the effectiveness of using that DA alone. PC+PR+CS surpasses PC+PR, highlighting CyCAug’s potential for further enhancement.

Figure 10: Comparison of Q Variance and Q-Target Variance during the training process with CyCAug and other multi-type DA fusion schemes. Variance is consistently assessed through 4 forward passes, employing random data augmentation on identical observations. CyCAug demonstrates notably superior data stability, which is crucial during the training process of visual RL.