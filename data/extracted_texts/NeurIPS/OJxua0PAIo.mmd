# Stochastic Extragradient with Flip-Flop Shuffling & Anchoring: Provable Improvements

Jiseok Chae

Department of Mathematical Sciences

KAIST

Daejeon, Republic of Korea

jsch@kaist.ac.kr

&Chulhee Yun

Kim Jaechul Graduate School of AI

KAIST

Seoul, Republic of Korea

chulhee.yun@kaist.ac.kr

&Donghwan Kim

Department of Mathematical Sciences

KAIST

Daejeon, Republic of Korea

donghwankim@kaist.ac.kr

###### Abstract

In minimax optimization, the extragradient (EG) method has been extensively studied because it outperforms the gradient descent-ascent method in convex-concave (C-C) problems. Yet, stochastic EG (SEG) has seen limited success in C-C problems, especially for unconstrained cases. Motivated by the recent progress of shuffling-based stochastic methods, we investigate the convergence of _shuffling-based SEG_ in unconstrained _finite-sum_ minimax problems, in search of convergent shuffling-based SEG. Our analysis reveals that both random reshuffling and the recently proposed flip-flop shuffling alone can suffer divergence in C-C problems. However, with an additional simple trick called anchoring, we develop the _SEG with flip-flop anchoring_ (SEG-FFA) method which successfully converges in C-C problems. We also show upper and lower bounds in the strongly-convex-strongly-concave setting, demonstrating that SEG-FFA has a provably faster convergence rate compared to other shuffling-based methods.

## 1 Introduction

Minimax problems with a finite-sum structure, which are optimization problems of the form

\[_{}_{}\ f(,)_{i=1}^{n} f_{i}(,),\] (1)

can be found in many interesting applications, such as generative adversarial networks , refining diffusion models , adversarial training , optimal transport based generative models , multi-agent reinforcement learning , and so on. Deterministic methods for minimax problems, such as _gradient descent-ascent_ (GDA)  and _extragradient_ (EG) , have been extensively studied in the literature. It is though known that, unlike _gradient descent_ (GD) for minimization problems, GDA may diverge even when \(f\) is convex on \(\) and concave on \(\). On the other hand, EG employs a two-step update procedure, named _extrapolation_ and _update_ steps (see Section 2 for details), which allows it to find an optimum under this _convex-concave_ setting , and moreover, attains a convergence rate faster than GDA  when \(f\) is strongly convex on \(\) and strongly concave on \(\).

In contrast, attempts to construct stochastic variants of these algorithms have not been so fruitful. When \(f\) is convex-concave, _stochastic gradient descent-ascent_ (SGDA) clearly may diverge, just asin the deterministic GDA. To make matters worse, _stochastic extragradient_ (SEG) methods have also had limited success on unconstrained convex-concave problems. As we elaborate in Section 2 in more detail, existing versions of SEG and their analyses have limitations that hinder its application to general unconstrained finite-sum convex-concave problems, requiring additional assumptions such as bounded domain, increasing batch size, convex-concavity of each component \(f_{i}\), uniformly bounded gradient variance, and/or absence of convergence rates.

In the context of finite-sum optimization, most of the theoretical studies on stochastic methods have long been based on the _with-replacement_ sampling scheme, where an index \(i(t)\) is independently and uniformly sampled among \(\{1,,n\}\) at each iteration \(t\). Such a sampling scheme is relatively easy to theoretically analyze, because the sampled \(f_{i(t)}\) is an unbiased estimator of the full objective function \(f\). In practice, however, inspired by the empirical observations of faster convergence in finite-sum minimization [8; 47], the _without-replacement_ sampling schemes have been the de facto standard. Among them, the most popular is the _random reshuffling_ (RR) scheme, where in every _epoch_ consisting of \(n\) iterations, the indices are chosen exactly once in a randomly shuffled order.

This gap between theory and practice in minimization problems is being closed by the recent breakthroughs in stochastic gradient descent (SGD), namely that SGD with RR leads to a provably faster convergence compared to with-replacement SGD when the number of epochs is large enough [1; 35; 39; 41; 55; 56]. This has motivated further studies on finding other shuffling-based sampling schemes that can improve upon RR, resulting in the discoveries such as the _flip-flop_ scheme  and _gradient balancing_ (GraB) [11; 32]. The flip-flop scheme is a particularly simple yet interesting modification of RR with improved rates in _quadratic_ problems: a random permutation is used twice in a single epoch (i.e., two passes over \(n\) components in an epoch), but the order is reversed in the second pass.

The aforesaid progress in minimization also triggered the study of stochastic minimax methods with shuffling. Similar to minimization problems, SGDA with RR indeed converges faster than the with-replacement SGDA, under assumptions such as strongly-convex-strongly-concave objectives  or \(f\) satisfying the Polyak-Lojasiewicz condition . Despite the superiority of EG over GDA, the _SEG with shuffling_ has not been shown to have a solid theoretical advantage over the SGDA with shuffling yet. This motivated us to study the following question:

_Can shuffling schemes provide convergence guarantees for SEG, improved upon SGDA with shuffling, in unconstrained finite-sum (strongly-)convex-(strongly-)concave settings?_

There are two types of SEG: _same-sample_ SEG, where a sample chosen is used both for the extrapolation step and the update step, and _independent-sample_ SEG, where two independently chosen samples are used in each step. We will particularly focus on the same-sample SEG because it combines more naturally with shuffling-based schemes than independent-sample SEG. Therefore, to be more specific, we are interested in developing shuffling-based variants of _same-sample_ SEG in unconstrained finite-sum minimax problems with minimal modifications to the algorithm. We show that **(a)** in convex-concave settings, our new method reaches an optimum with a guarantee on the rate of convergence, overcoming the limitations of existing results; **(b)** in strongly-convex-strongly-concave settings, the method converges faster than other SGDA/SEG variants.

### Our Contributions

In this paper, we study various same-sample SEG algorithms under different shuffling schemes, and propose the _stochastic extragradient with flip-flop anchoring_ (\(\)) method, which is SEG amended with the techniques of _flip-flop_ shuffling scheme and _anchoring_. Here, by _anchoring_ we refer to a step of taking a convex combination between the initial and final iterates of an epoch, resembling the celebrated _Krasnosel'skii-Mann iteration_[30; 33] as we discuss in Section 5. With such minimal modifications to SEG, we show that \(\) achieves provably improved convergence guarantees. More precisely, our contributions can be listed as follows (see Table 1 for a summary). For clarity, we use \(\) to refer to with-replacement SEG, where US stands for uniform sampling.

* We first study the same-sample versions of \(\), SEG with RR (\(\)), and SEG with flip-flop (\(\)). We show that they all can diverge when \(f\) is convex-concave,1by constructing an explicit counterexample (Theorem 4.1). This shows that shuffling alone _cannot_ fix the divergence issue of SEG-US.
* We next investigate the underlying cause for the nonconvergence of SEG-US, SEG-RR, and SEG-FF. In particular, we identify that either they fail to match the update equation of the reference method EG beyond _first-order_ Taylor expansion terms, or attempting to match both the _first-_ and _second-order_ Taylor expansion terms results in divergence (Proposition 5.2).
* By adopting a simple technique of _anchoring_ on top of flip-flop shuffling, we devise our algorithm SEG-FFA, whose epoch-wise update deterministically matches EG up to second-order Taylor expansion terms (Proposition 5.3). We prove that SEG-FFA enjoys improved convergence guarantees, as anticipated by our design principle. Most importantly, we show that SEG-FFA achieves a convergence rate of \(}(}{{K^{1/3}}})\) when \(f\) is convex-concave, where \(K\) denotes the number of epochs. This is in stark contrast to other baseline algorithms that diverge under this setting (see the last column of Table 1).
* Moreover, we show that when \(f\) is strongly-convex-strongly-concave, SEG-FFA achieves a convergence rate of \(}(}{{nK^{4}}})\) (Theorem 5.5). In addition, by proving \((}{{nK^{3}}})\) lower bounds for the convergence rates of SGDA-RR and SEG-RR under the same setting (Theorem 5.6), we show that SEG-FFA has a _provable advantage_ over these baseline algorithms.

## 2 Related Works

Extragradient and EG+Extragradient (EG) method  is a widely used minimax optimization method, well-known for resolving the nonconvergence issue of GDA on convex-concave problems. In this paper, we also consider EG+ , which is a generalization of EG. The update rule of EG+ is defined, for stepsizes \(\{_{1,k}\}_{k 0}\) and \(\{_{2,k}\}_{k 0}\), as

\[^{k}^{k}-_{1,k}_{}\,f( {x}^{k},^{k})\\ ^{k}^{k}+_{1,k}_{}\,f(^{k},^ {k}),^{k+1}^{k}-_ {2,k}_{}\,f(^{k},^{k})\\ ^{k+1}^{k}+_{2,k}_{}\,f(^{k},^{k}).\] (2)

The first step is called the _extrapolation step_, and the second step is called the _update step_. If \(f\) is convex-concave, Diakonikolas et al.  show that EG+ reaches an optimum when \(_{1,k}_{2,k}\). In particular, when \(_{1,k}=_{2,k}\), we recover the standard EG by Korpelevich .

    &  &  \\  Method & Upper Bound & Lower Bound & Upper Bound & Lower Bound \\  SGDA-US & \(()\) & \(()\) & N/A & \((1)\) (as SGA) \\ SEG-US & \(()\) & \(()\) & N/A\({}^{}\) & \((1)\) (Timb. 4.1) \\  SGDA-RR & \(}(})\) & \((})\) (Timb. 5.6) & N/A & \((1)\) (as SGA) \\ SEG-RR & \(}(})\) & \((})\) (Timb. 5.6) & \((})\) (18) & \((1)\) (Timb. 4.1) \\ SEG-FF & \(}(})\) (Timb. F.5) & \(-\) & N/A & \((1)\) (Timb. 4.1) \\  SEG-FFA & \(}(})\) (Timb. 5.5) & \(-\) & \(}(})\) (Timb. 5.4) & \(-\) \\   

*  show upper bounds for SEG-US, but they require increasing batch sizes as well as other assumptions (see Appendix B.1).
*  shows that _independent-sample_ SEG-US converges for stepsizes \(_{k}\), \(_{t}\) decaying at different rates, but gives no conv. rate.
* Unfortunately, the proof of this convergence bound in this recent AISTATS 2024 paper seems to be incorrect: see Appendix B.4.

Table 1: Summary of upper/lower convergence rate bounds of _same-sample_ SEG for unconstrained finite-sum minimax problems, without requiring increasing batch size, convex-concavity of each component, and uniformly bounded gradient variance. Pseudocode of algorithms can be found in Appendix A. We only display terms that become dominant for sufficiently large \(T\) and \(K\). To compare the with-replacement versions (-US) against shuffling-based versions, one can substitute \(T=nK\). The optimality measure used for SC-SC problems is \([\|}-^{*}\|^{2}]\) for the last iterate \(}\). For C-C problems, we consider \(_{t=0,,T}[\|_{t}\|^{2}]\) for with-replacement methods and \(_{k=0,,K}[\|_{0}^{k}\|^{2}]\) for shuffling-based methods.

Stochastic Variants of ExtragradientIn (2), if the _stochastic estimators_ of \(_{}\,f\) and \(_{}\,f\) are used instead of the gradients themselves, we get the standard SEG. If an estimator chosen is used for both the extrapolation and the update steps, we get the _same-sample_ SEG, which we focus on in this paper; see Appendix A for the pseudocode.

While EG improves upon GDA, unfortunately, SEG has not been able to show a clear advantage over SGDA. On one hand, analyses of SEG on strongly-convex-strongly-concave problems have shown some success; see, _e.g._, [18; 20]. Yet, on the other hand, for general unconstrained convex-concave problems, to the best of our knowledge, the existing stochastic variants of EG and their analyses face several limitations.23 Assumptions commonly imposed in the existing literature include: **(i)** the domain is bounded, either explicitly or implicitly [27; 36], **(ii)** one must increase the batch size to achieve convergence [9; 17; 20],4 and **(iii)** each component \(f_{i}\) is convex-concave [20; 36], and **(iv)** the components have uniformly bounded gradient variance [9; 17; 42]. For further details, see Appendix B.1 and Table 2 therein. Notably, Hsieh et al.  prove convergence of the _independent-sample_ SEG without these four restrictions, but the result lacks an explicit convergence rate.

Our proposed SEG-FFA overcomes all the aforementioned limitations, and reaches an optimum with an explicit rate in unconstrained convex-concave problems, under relatively mild conditions. The readers may also refer to  for a comprehensive overview on this topic.

Meanwhile, under the finite-sum setting, variance reduction schemes have also been considered, achieving some promising results [2; 10]. Yet, although theoretically appealing, variance reduction is less widely used in practice due to their curiously inferior performance in training neural networks . On top of this practical issue, variance reduction techniques share the aforementioned limitation (ii), as accessing full gradients can be viewed as increasing the batch size. In contrast, our main goal in this paper is to study how a carefully chosen sampling scheme, with minimal modifications to the algorithm, can improve the convergence of SEG without the need for increased batch size; therefore, we believe that our work is not directly comparable to variance reduction-based EG.

Taylor Expansion Matching and Convergence GuaranteesIt has been repeatedly reported that the convergence of an optimization method is deeply related to the degree to which the Taylor expansion (with respect to the step size) of its update equation matches with that of an already known convergent method. For example, Mokhtari et al.  observed that the advantage of EG over GDA comes from the Taylor expansion of update equations of EG matching that of the _proximal point_ (PP) method  up to second-order terms, whereas GDA matches PP only up to first-order terms.

The advantages of the shuffling scheme over the with-replacement sampling can be explained in a similar way. One key property of shuffling-based methods is that, while the individual estimators are biased as they are dependent to other estimators within the same epoch, the overall stochastic error across the epoch decreases dramatically compared to using \(n\) independent unbiased estimators. For instance, in SGD with RR  and in SGDA with RR , the overall progress made within each epoch exactly matches their deterministic counterparts up to the first-order, leaving an error as small as \((^{2})\), where \(\) is the stepsize. Rajput et al.  observed that, when each component functions are convex quadratics, then using flip-flop on SGD can reduce the error further to \((^{3})\), resulting in an even faster convergence. As we further elaborate in Section 5, the motivation behind our design principle of SEG-FFA is also based on this line of observations.

## 3 Notations and Problem Settings

Let \([n]\) denote the set \(\{1,,n\}\). The set of all permutations on \([n]\) will be denoted by \(_{n}\). For the finite-sum minimax problem (1), we denote the _saddle gradient_ operators by

\[(\,\,)_{}\,f(\,\,)\\ -_{}\,f(\,\,),\;\;_{i}(\,\,) _{}\,f_{i}(\,\,)\\ -_{}\,f_{i}(\,\,), i[n].\]The derivative of an operator will be denoted with a prefix \(D\). For example, the derivative of \(\) is denoted by \(D\). Often a single vector will be used to denote the minimization and the maximization variable at once. For instance, for \(^{d_{1}+d_{2}}\) which is a concatenation of \(^{d_{1}}\) and \(^{d_{2}}\), we simply write \(\) to denote \((,)\).

It is well known that, if \(f\) is \(\)-strongly convex on \(\) and \(\)-strongly concave on \(\) for some \(>0\) (respectively, \(=0\)), then its saddle gradient \(\) is \(\)-strongly monotone (respectively, monotone), in the following sense. For a proof of this standard fact, see, _e.g._, .

**Assumption 3.1** (Monotonicity & Strong Monotonicity).: For \(>0\), we say that an operator \(\) is \(\)-strongly monotone if, for any \(,^{d_{1}+d_{2}}\), it holds that

\[-,-\| -\|^{2}.\] (3)

If (3) holds for \(=0\), then we say that \(\) is monotone.

Thus, from now on, we will use the term _strongly monotone_ (respectively, _monotone_) problems rather than strongly-convex-strongly-concave (respectively, convex-concave) problems. Notice that we only assume that the full saddle gradient \(\) is (strongly) monotone, not the individual \(_{i}\)'s.

In addition, we remark that our convergence analysis under the monotonicity of \(\), Theorem 5.4, in fact requires only a relaxed version of monotonicity, known as _star_-monotonicity. This condition imposes the inequality (3) with \(=0\), but only when \(=^{*}\), where \(^{*}\) is a point such that \(^{*}=\). This relaxation allows for a certain degree of nonconvex-nonconcavity in \(f\). For a more detailed discussion on the star-monotonicity condition, see Appendix G.1.

Other three underlying assumptions we make on the problem (1) can be listed as follows.

**Assumption 3.2** (Existence of an Optimal Solution).: An optimal solution of the problem (1), which is a point we denote by \(^{*}=(^{*},^{*})\) that satisfies

\[f(^{*},) f(^{*},^{*}) f(,^{*})\]

for any \(^{d_{1}}\) and \(^{d_{2}}\), exists in \(^{d_{1}+d_{2}}\).

Because the problem is unconstrained and \(f\) is convex-concave, a point \(^{*}\) is an optimum if and only if \(^{*}=\). For strongly monotone problems, Assumption 3.2 is not explicitly required, as it is guaranteed _a priori_[5, Proposition 22.11]. For monotone problems, we explicitly impose Assumption 3.2 in order to exclude pathological problems such as \(f(x,y)=x-y\).

**Assumption 3.3** (Smoothness).: Each \(f_{i}\) is \(L\)-smooth, and each \(_{i}\) is \(M\)-smooth. That is, for any \(,^{d_{1}+d_{2}}\),

* \(\|_{i}-_{i}\| L\|-\|\),
* \(\|D_{i}-D_{i}\| M\|-\|\).

It is worth mentioning that the gradient operator \(_{i}\) arising from a quadratic function \(f_{i}\) is \(M\)-smooth with \(M=0\). Notice also that, by the finite-sum structure \(=_{i=1}^{n}_{i}\), it is clear that Assumption 3.3 implies \(f\) being \(L\)-smooth and \(\) being \(M\)-smooth.

The \(L\)-smoothness assumption on the objective functions is standard in the optimization literature, while the \(M\)-smoothness assumption on the saddle gradients may look less standard. This smoothness assumption on the saddle gradient, in other words the Lipschitz Hessian condition, for analyzing SEG-FFA stems from the analysis of the flip-flop sampling scheme . In particular, this is needed for bounding the high-order error terms between the (deterministic) EG and SEG-FFA in Section 5.1. The existing analysis of flip-flop sampling  is limited to quadratic functions that trivially have \(0\)-Lipschitz Hessians (\(M=0\)), so our analysis is a step forward.

**Assumption 3.4** (Component Variance).: There exist constants \( 0\) and \( 0\) such that

\[_{i=1}^{n}\,\|_{i}-\|^{2} (\|\|+)^{2}.\] (4)

For strongly monotone problems, Assumption 3.4 is not explicitly required, because it can be obtained as a consequence of the preceding assumptions: see Lemma C.9. Nevertheless, for convenience, we will keep the notations \(\) and \(\) as in (4) for the strongly monotone setting as well.

In many existing works on stochastic optimization methods for minimax problems, Assumption 3.4 with \(=0\) is imposed. This _uniform_ bound on the variance simplifies the convergence analyses, but it is also fairly restrictive especially in the unconstrained settings. Already for bilinear finite-sum minimax problems \(f(,)=_{i=1}^{n}^{}_{i}\), one can easily check that setting \(=0\) forces the matrices \(_{i}\) to be exactly equal to each other. For machine learning applications, it has been also reported that the assumption with \(=0\) often fails to hold . Therefore, allowing the variance to grow with the gradient \(\) makes the assumption much more realistic.

The Lipschitz Hessian condition and the component variance assumption for monotone problems may still look rather strong. We leave the study on how one can relax such assumptions to prove _upper_ bounds for convergence rates as an interesting future direction. On the other hand, while our lower bound results in Theorems 4.1 and 5.6 are derived under those strong assumptions, they still serve as lower bound results also for larger function classes that do not have those assumptions. In other words, the value of those results are not limited because of those assumptions being imposed.

## 4 Shuffling Alone Is Not Enough

Under the settings we have discussed, we study the SEG with shuffling-based sampling schemes. First we describe the precise methods of our consideration, namely the \(\)-\(\) and \(\)-\(\).

For \(k 0\), in the beginning of an epoch, a random permutation \(_{k}\) is sampled from a uniform distribution over \(_{n}\). Then, for \(n\) iterations, we use each of the component functions once, in the order determined by \(_{k}\). That is, for \(i=0,1,,n-1\) we do

\[_{i}^{k} _{i}^{k}-_{k}_{_{k}(i+1)}_ {i}^{k},\] (5) \[_{i+1}^{k} _{i}^{k}-_{k}_{_{k}(i+1)}_{i} ^{k},\]

for some stepsizes \(_{k}\) and \(_{k}\). In case of \(\)-\(\), the epoch is completed here, and we set \(_{0}^{k+1}_{n}^{k}\) as the initial point for the next epoch.

In case of \(\)-\(\), we additionally perform \(n\) more iterations in the epoch, as proposed in Rajput et al. . In these additional iterations, the component functions are each used once more, but in the reverse order. That is, for \(i=n,n+1,,2n-1\), we do

\[_{i}^{k} _{i}^{k}-_{k}_{_{k}(2n-i)}_ {i}^{k},\] (6) \[_{i+1}^{k} _{i}^{k}-_{k}_{_{k}(2n-i)}_ {i}^{k}.\]

Then we set \(_{0}^{k+1}_{2n}^{k}\) as the initial point for the next epoch. The full pseudocode of these methods can be found in Appendix A.

When \(\) is strongly monotone, it is possible to show that both \(\)-\(\) and \(\)-\(\) indeed provide speed-up over \(\)-\(\). The well-known rate of \(\)-\(\) under strong monotonicity of \(\) is \((}{{1}}/{{T}})\), where \(T\) is the total number of iterations . Translating this rate to our shuffling-based setting, where there are \((n)\) iterations per epoch, this rate amounts to \((}{{nK}})\). Recently, Emmanouilidis et al.  have shown that \(\)-\(\), under the same setting as ours, attains a convergence rate of \(}(}{{nK^{2}}})\), on par with the rate of \(\)-\(\). In Appendix F, we also show that \(\)-\(\) attains a similar rate of convergence.

However, it turns out that the benefit of shuffling does not extend further beyond the strongly monotone setting. In fact, when \(\) is merely monotone, then in the worst case, \(\)-\(\) and \(\)-\(\) suffers from nonconvergence, just as in the case of \(\)-\(\).

**Theorem 4.1**.: _For \(n=2\), there exists a minimax problem with \(f(x,y)=_{j=1}^{2}f_{i}(x,y)\) having a monotone \(\), consisting of \(L\)-smooth quadratic \(f_{i}\)'s satisfying Assumption 3.4 with \((,)=(1,0)\), such that \(\)-\(\), \(\)-\(\) and \(\)-\(\) diverge in expectation for any positive stepsizes._

We provide the explicit counterexample and the proof of divergence in Appendix H.1. Note that Theorem 4.1 and its proof in Appendix H.1 imply that \(_{t=0,,T}[_{t}^{2}]= (1)\) for \(\)-\(\) and \(_{k=0,,K}[_{0}^{k}^{2}]= (1)\) for \(\)-\(\) and \(\)-\(\), as summarized in Table 1.

SEG-FFA: SEG with Flip-Flop Anchoring

In this section, we investigate the underlying cause for nonconvergence of SEG-RR and SEG-FF from the perspective of how accurately they match the convergent EG or PP methods in terms of the Taylor expansions of updates. We then propose adding a simple _anchoring_ step at the end of each epoch of SEG-FF. It turns out that adding the _anchoring_ step, which is a step of taking a convex combination of an iterate with a previously computed iterate, reduces the stochastic noise and leads to a method with improved convergence properties.

### Design Principle: Second-Order Matching

As observed by , the key feature of EG behind its superior convergence properties compared to GDA is its update rule closely resembling PP, while the "error" of GDA as an approximation of PP is so large that it hinders convergence. The difference between the updates of EG and PP, in the Taylor expansion, is as small as \((^{3})\) per iteration, where \(\) is the stepsize. On the other hand, GDA and PP show a difference of \((^{2})\), and this greater "error" explains why GDA diverges while EG and PP converge. Of course, EG and PP are not the only two algorithms that converge in the monotone setting; let us recall the update rule of EG+ method , and Taylor-expand it as the following:

\[^{+}&-_{2} (-_{1})\\ &=-_{2}+_{1}_{2}D() {F}+O(_{1}^{2}_{2}).\] (7)

EG+ is known to converge for unconstrained monotone problems if \(_{1}_{2}\). When \(_{1}=_{2}\), it recovers EG and matches PP up to second-order terms.

Based on these observations, we now state our key principle for designing a convergent version of SEG: _second-order matching_. We would like to choose proper stepsizes, sampling scheme, and anchoring scheme so that our without-replacement SEG can _deterministically_ match the update equation of a convergent algorithm (EG/PP or EG+) up to the \(O(^{2})\) terms (i.e., _second-order_ terms in the Taylor expansion), thereby satisfying a small \((^{3})\) approximation error. We show that **(a)** this _second-order matching_ can be achieved with _flip-flop anchoring_, but not solely by permutation-based sampling such as RR and flip-flop (without anchoring), and **(b)** second-order matching indeed grants convergence for monotone problems. In particular, we demonstrate that

1. SEG-RR suffers a poor approximation error of \((^{2})\) as an approximation of EG/EG+.
2. SEG-FF can match EG+ up to second-order terms, but it results in a choice of stepsizes (\(_{2}=2_{1}\)) that make EG+ diverge (Proposition 5.2).
3. SEG-FFA, the method we propose, matches EG up to second-order terms to get an error of \((^{3})\) (Proposition 5.3), achieving convergence in monotone problems (Theorem 5.4).

To this end, let us consider a general form of SEG that incorporates any arbitrary sampling scheme. More precisely, in the \(k\)-th "epoch" consisted of \(N\) iterations, the components are chosen in the order of \(_{0}^{k},_{1}^{k},,_{N-1}^{k}\), where \(_{i}^{k}\{_{1},,_{n}\}\) for each \(i\). For our purpose, we assume that \(N\) is some multiple of \(n\) (e.g., \(N=n\) for SEG-RR, \(N=2n\) for SEG-FF). Then, given \(\) and \(\) we perform SEG updates, for \(i=0,1,,N-1\),

\[_{i}^{k}&_{i}^{k} -_{i}^{k}_{i}^{k},\\ _{i+1}^{k}&_{i}^{k}- _{i}^{k}_{i}^{k}.\] (8)

#### 5.1.1 Necessity of Flip-Flop Sampling

The general method in (8) that sets the initial point for the next epoch as \(_{0}^{k+1}_{N}^{k}\) satisfies the following property.

**Proposition 5.1**.: _Suppose that Assumption 3.3 holds. For some \(_{N}^{k}=o((+)^{2})\), it holds that_

\[_{0}^{k+1}=_{0}^{k}-_{j=0}^{N-1}_{j}^{k}_{0}^{ k}+_{j=0}^{N-1}D_{j}^{k}(_{0}^{k})_{j}^{k}_{0}^{ k}+^{2}_{i<j}D_{j}^{k}(_{0}^{k})_{i}^{k}_{0}^{k}+ _{N}^{k}.\] (9)See Appendix D.1 for the proof. To make (7) and (9) match up to the second-order, both the equations

\[}{n}_{j=1}^{n}_{i}_{0}^{k}=_{ j=0}^{N-1}_{j}^{k}_{0}^{k}\] (10) \[_{2}}{n^{2}}_{j=1}^{n}D_{j}( {z}_{0}^{k})_{j}_{0}^{k}+_{i j}D_{j}(_{0}^{k}) _{i}_{0}^{k}=_{j=0}^{N-1}D_{j}^{k}(_{0}^{k})_{j}^{k}_{0}^{k}+^{2}_{i<j}D_{j}^{k}(_{0}^ {k})_{i}^{k}_{0}^{k}\] (11)

must hold. Clearly, without-replacement sampling will make (10) hold. However, it is easy to check that random reshuffling falls short of making (11) hold. This is because, if RR is used, then \(_{0}^{k},_{1}^{k},,_{n-1}^{k}\) is nothing but a reordering of \(_{1},,_{n}\) into \(_{(1)},,_{(n)}\), so the RHS of (11) can only contain terms \(D_{(j)}(_{0}^{k})_{(i)}_{0}^{k}\) with \(i j\). This observation motivates the use of flip-flop sampling, because choosing \(_{i}^{k}=_{2n-1-i}^{k}\) lets all the required terms \(D_{j}(_{0}^{k})_{i}_{0}^{k}\) to appear in the RHS of (11).

#### 5.1.2 Designing SEG-Ffa

Flip-flop does resolve the aforesaid issue, but still another complication remains for plain SEG-FF.

**Proposition 5.2**.: _Suppose we use flip-flop sampling (without anchoring). In order to make (10) and (11) hold, we must choose \(=}}{{n}}\) and \(=}{{2}}\). However, this leads to \(_{2}=2_{1}\), which is the set of parameters that fails to make EG+ converge._

For the proof, see Appendix D.2. This shows that a modification is necessary to develop a stochastic method that achieves second-order matching to _convergent_ EG/EG+ methods.

We thus propose to add an _anchoring_ step:

\[_{0}^{k+1}(_{N}^{k}+_{0}^{k} ),\] (12)

after finishing the \(N\) updates (8), instead of \(_{0}^{k+1}_{N}^{k}\). This is our _Stochastic ExtraGradient with Flip-Flop Anchoring_ (SEG-FFA) method, named after the design of combining the flip-flop sampling scheme and the anchoring step. We note that this idea of taking a convex combination has originally appeared in the Krasnosel'skii-Mann iteration , and also under the name of _Lookahead_ methods . This slightly differs from the more widely used _Halpern iteration_ based anchoring (_cf._), which would have used the initial point \(_{0}^{0}\) instead of \(_{0}^{k}\) in (12).

This anchoring step changes (9) accordingly, and essentially amounts to dividing the right-hand sides of (10) and (11) each by \(2\) (see Appendix D for the detailed derivations). We show that choosing \(=}{{2}}\) in fact leads to the second-order matching to EG, i.e., EG+ with \(_{1}=_{2}\).

**Proposition 5.3**.: _Suppose that Assumptions 3.3 and 3.4 hold. Then, for \(_{k}=\) and \(_{k}=}}{{2}}\), SEG-FFA becomes an approximation of EG with error at most \((^{3})\). In other words, we achieve_

\[\|_{0}^{k}- n(_{0}^{k}- n_{0}^{k})- _{0}^{k+1}\|=(^{3}).\]

In other words, adding the anchoring step allows us to get a method that well approximates the convergent EG with an error as small as \((^{3})\). For a more in-depth discussion, see Appendix E.

### Convergence Analysis of SEG-Ffa

As a result of the second-order matching, we obtain SEG-FFA, a stochastic method that has an error of \((^{3})\) as an approximation of EG. Achieving this order of magnitude for the approximation error turns out to be the key to the exact convergence to an optimum under the monotone setting.

**Theorem 5.4**.: _Suppose that \(\) is (star-)monotone, Assumptions 3.2, 3.3, and 3.4 hold, and we are running SEG-FFA. Then, for any \(K 1\), by choosing the stepsizes sufficiently small and decaying as \(_{k}=(}{{k^{1/3}}} k)\) and \(_{k}=}}{{2}}\), the iterates generated by SEG-FFA achieves the bound_

\[_{k=0,1,,K}\|_{0}^{k}\|^{2}= (}{K^{1/3}}).\]For the full statement of the theorem and its proof, see Appendix G. We note that, although Theorem 5.4, and also Theorem 5.5 below, are stated specifically for \(\)-\(\), our analyses show that both theorems can be applied to any method that achieves the second-order matching in terms of Proposition 5.3.

The reduced error also shows a gain in the rate of convergence under the strongly monotone setting. This aligns with the intuition that error hinders convergence, hence having a smaller error is beneficial.

**Theorem 5.5**.: _Suppose that \(\) is \(\)-strongly monotone with \(>0\) and Assumption 3.3 holds. Then, there exists a choice of \(>0\) such that, when \(\)-\(\) is run for \(K\) epochs with constant stepsizes \(_{k}=\) and \(_{k}=}{{2}}\), for some constant \(\) independent of \(\), the iterates generated by \(\)-\(\) achieves the bound_

\[\|_{0}^{K}-^{*}\|^{2}(- {2} nK)\|_{0}^{0}-^{*}\|^{2}+(K))^{4}}{nK^{4}}).\]

Theorem 5.5 actually stems from a unified analysis that encompasses all the shuffling-based SEG methods introduced in this paper, including \(\)-\(\) and \(\)-\(\). See Appendix F for the details.

Notice the exponent \(4\) of the number of epochs \(K\) in the convergence rate, which is twice as large as the exponent \(2\) of \(\)-\(\) and \(\)-\(\). In fact, this gain in the rate of convergence turns out to be fundamental. As we show in the following theorem, the theoretical lower bounds of convergence for \(\)-\(\) and \(\)-\(\) with constant stepsize are both \((}{{n}}K^{3})\). This exhibits that there is a _provable gap_ between those methods and \(\)-\(\), which attains \(}(}{{n}}K^{4})\).

**Theorem 5.6**.: _Suppose \(n 2\). For both \(\)-\(\) with constant stepsize \(_{k}=>0\) and \(\)-\(\) with constant stepsize \(_{k}=>0\), \(_{k}=>0\), there exists a \(\)-strongly monotone minimax problem \(f()=_{i=1}^{n}f_{i}()\) with \(>0\) such that regardless of stepsizes, we have_

\[[\|_{0}^{K}-^{*}\|^{2}]= (}{L nK})&K L/,\\ (}{^{3}nK^{3}})&K>L/.\]

Proof.: The full statement and the proof are presented in Appendix H.3. 

## 6 Experiments

We consider randomly generated quadratic problems of the form

\[_{^{d_{x}}}_{^{d_{y}}}\ _{i=1}^{n}\ \\ ^{\!\!}\!\!_{i}&_{i}\\ _{i}^{}&-_{i}\!\!\\ -_{i}^{}\!\!\\ .\] (13)

In particular, we sample the random components so that the full objective is either monotone or strongly monotone, respectively, while each of the components may be nonmonotone. For the exact descriptions on how we constructed the problems, see Appendix I.1.

Monotone CaseWe ran the experiment on \(5\) random instances of (13) with the stepsizes scheduled as \(_{k}=}}{{(1+k/10)^{0.34}}}\) where \(_{0}=\{0.01,\}\) for \(\)-\(\), and \(_{k}=_{k}=_{k}\) for \(\)-\(\), \(\)-\(\), and \(\)-\(\). The exponent \(0.34\) is to ensure a sufficient decay rate required by Theorem 5.4, and the convergence of \(\)-\(\) under such a stepsize scheduling is validated in Remark G.5. The value of \(_{0}\) is, however, a heuristically determined small number. The results of the geometric mean over the \(5\) runs are plotted in Figure 1. As expected by our theory, \(\)-\(\) successfully shows convergence, while all of \(\)-\(\), \(\)-\(\), and \(\)-\(\) diverge in the long run.

Strongly monotone caseAlong with the variants of SEG, we also compare the performances of \(\)-\(\) and \(\)-\(\). We ran the experiment on \(5\) random instances of (13) with stepsizes \(_{k}=0.001\), and the results are plotted in Figure 1. Additional results obtained from using other stepsizes can be found in Appendix I.4. We again observe an agreement between the empirical results and our theory; \(\)-\(\) eventually finds the point with the smallest gradient norm among the methods that are considered.

Further additional experiments and ablation studies we have conducted can be found in Appendix I.

## 7 Conclusion

We proposed SEG-FFA, a new stochastic variant of EG that uses flip-flop sampling and anchoring. While being a minimal modification from the vanilla SEG, SEG-FFA attains the crucial "second-order matching" property to the deterministic EG, leading to a two-fold improved convergence. On one hand, SEG-FFA reaches an optimum in the monotone setting, unlike many baseline methods such as SEG-US, SEG-RR, and SEG-FF that diverge. Moreover, in the strongly monotone setting, SEG-FFA shows a faster convergence with a provable gap from the other methods.

An interesting future direction would be to extend our work to more general nonconvex-nonconcave problems, further exploring the potentials of the second-order matching technique. It would also be appealing to further study whether it is possible to devise a new method that achieves second-order (or higher) matching without the anchoring step, potentially enhancing our understanding of the effectiveness of the matching technique.