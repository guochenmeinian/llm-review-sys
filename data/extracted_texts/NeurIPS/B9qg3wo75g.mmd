# Generative Fractional Diffusion Models

Gabriel Nobis

Fraunhofer HHI

&Maximilian Springenberg

Fraunhofer HHI

&Marco Aversa

Dotphoton

&Michael Detzel

Fraunhofer HHI

&Rembert Daems

Ghent University

FlandersMake-MIRO

&Roderick Murray-Smith

University of Glasgow

&Shinichi Nakajima

BIFOLD, TU Berlin

RIKEN AIP

Sebastian Lapuschkin

Fraunhofer HHI

&Stefano Ermon

Stanford University

&Tolga Birdal

Imperial College London

&Manfred Opper

TU Berlin

University of Potsdam

University of Birmingham

&Christoph Knochenhauer

Technical University of Munich

&Luis Oala

Dotphoton

&Wojciech Samek

Fraunhofer HHI

TU Berlin

BIFOLD

###### Abstract

We introduce the first continuous-time score-based generative model that leverages fractional diffusion processes for its underlying dynamics. Although diffusion models have excelled at capturing data distributions, they still suffer from various limitations such as slow convergence, mode-collapse on imbalanced data, and lack of diversity. These issues are partially linked to the use of light-tailed Brownian motion (BM) with independent increments. In this paper, we replace BM with an approximation of its non-Markovian counterpart, fractional Brownian motion (fBM), characterized by correlated increments and Hurst index \(H(0,1)\), where \(H=0.5\) recovers the classical BM. To ensure tractable inference and learning, we employ a recently popularized Markov approximation of fBM (MA-fBM) and derive its reverse-time model, resulting in _generative fractional diffusion models_ (GFDM). We characterize the forward dynamics using a continuous reparameterization trick and propose _augmented score matching_ to efficiently learn the score function, which is partly known in closed form, at minimal added cost. The ability to drive our diffusion model via MA-fBM offers flexibility and control. \(H 0.5\) enters the regime of _rough paths_ whereas \(H>0.5\) regularizes diffusion paths and invokes long-term memory. The Markov approximation allows added control by varying the number of Markov processes linearly combined to approximate fBM. Our evaluations on real image datasets demonstrate that GFDM achieves greater pixel-wise diversity and enhanced image quality, as indicated by a lower FID, offering a promising alternative to traditional diffusion models1.

## 1 Introduction

Recent years have witnessed a remarkable leap in generative diffusion models , celebrated for their ability to accurately learn data distributions and generate high-fidelity samples. These models have made significant impact across a wide spectrum of application domains, including the generation of complex molecular structures  for material  or drug discovery , realisticaudio samples , 3D objects  or textures , medical images , aerospace applications , and DNA sequence design . Despite these successes, modern score-based generative models formulated in continuous-time  face limitations due to their reliance on a simplistic driving noise, the Brownian motion (BM) . As a light-tailed process, using BM can results in slow convergence rates and susceptibility to mode-collapse, especially with imbalanced data . Additionally, its purely Markovian nature may also make it hard to capture the full complexity and richness of real-world data. All these attracted a number of attempts for involving different noise types . In this paper, we propose leveraging fractional noises, particularly the renowned non-Markovian fractional BM (fBM)  to drive diffusion models. fBM extends BM to stationary increments with a more complex dependence structure, _i.e._, long-range dependence vs. roughness/regularity controlled by a Hurst index, a measure of "mild" or "wild" randomness . This all comes at the expense of computational challenges and intractability of inference, mostly stemming from its non-Markovian nature. Moreover, deriving a reverse-time model poses theoretical challenges, as fBM is not only non-Markovian but also not a semimartingale . To overcome these limitations, we leverage recent works in Markov approximations of fBM (MA-fBM)  and establish a framework for training continuous-time score-based generative models using an approximate fractional diffusion process, as well as generating samples from the corresponding tractable reverse process. Notably, our method maintains the same number of score model evaluations during both training and data generation, with only a minimal increase in computational load. Our contributions are:

* We derive the time-reversal of forward dynamics driven by a Markovian approximation of fractional Brownian motion in a way that the dimensionality of the unknown part of the score function matches that of the data.
* We derive an explicit formulae for the marginals of the conditional forward process via a continuous reparameterization trick.
* We introduce a novel augmented score matching loss for learning the score function in our generative fractional diffusion model, which can be minimized by a score model of data-dimension.

Our experimental evaluation validates our contributions, demonstrating the gains of correlated-noise with long-term memory, approximated by a combination of a number of Markov processes, where the amount of processes further control the diverstiy.

**Differentiation from existing work.** Yoon et al.  generalizes score-based generative models from an underlying BM to a driving Levy process, a stochastic process with independent and stationary increments. A driving noise with correlated increments is not included in the framework of Yoon et al. . Conceptually, every Levy process is a semimartingale . Since fBM is not a Levy process, it is not included in the framework of Yoon et al. . The closest work to ours is Tong et al.  constructing a neural-SDE based on correlated noise and using the neural SDE as a forward process of a score-based generative model. Our framework with exact reverse-time model is based on the integral representation of fBM derived in Harms and Stefanovits  and the optimal approximation coefficients of Daems et al. , while the fractional noise in  is sparsely approximated by a linear combination of independent standard normal random variables without exact reverse-time

Figure 1: **Each data dimension transitions to a known prior distribution through a forward process that approximates a fractional diffusion process.** The Hurst index \(H\) on the LHS interpolates between the roughness of a Brownian driven SDE and the underlying integration in PF ODEs. The driving noise process is a linear combination of the correlated processes on the RHS, all driven by the same Brownian motion. The score function of these augmenting processes is available in closed form and serves as guidance for the unknown score function.

model. Moreover, the framework of Tong et al.  is limited to \(H>\) and only compatible with the Euler-Maruyama sample schema  while our framework is up to numerical stability applicable for any \(H(0,1)\) and compatible with any suitable SDE or ODE solver. To the best of our knowledge, we are the first to build a framework for continuous-time score-based generative models that includes driving noise processes converging to non-Markovian processes with infinite quadratic variation.

## 2 Background

Modeling the distribution transforming process of a score-based generative model through stochastic differential equations (SDEs)  offers a unifying framework to generate data from an unknown probability distribution. Instead of injecting a finite number of fixed noise scales via a Markov chain, infinitely many noise scales tailored to the continuous dynamics of the Markov process \(=(_{t})_{t[0,T]}\) are utilized during the distribution transformation, offering considerable practical advantages over discrete time diffusion models . The forward dynamics, transitioning from a data sample \(_{0} p_{0}\) to a tractable noise sample \(_{T} p_{T}\) are specified by a continuous drift function \(\) and a continuous diffusion coefficient \(g\). These dynamics define a diffusion process that solves the SDE

\[_{t}=(_{t},t)t+g(t) _{t},_{0} p_{0} \]

driven by a multivariate BM \(\). To sample data from noise, a reverse-time model is needed that defines the backward transformation from the tractable noise distribution to the data distribution. Whenever \(=(_{t})_{t[0,T]}\) is a stochastic process and \(g\) is a function on \([0,T]\), we write \(}_{t}=_{T-t}\) for the reverse-time model and \((t)=g(T-t)\) for the reverse-time function. The marginal density of the stochastic process \(\) at time \(t\) is denoted by \(p_{t}\) throughout this work2. Remarkably, an exact reverse-time model to the forward model in eq. (1) is given by the backward dynamics [31; 32; 33]

\[}_{t}=[}(}_{t},t)-^{2}(t)_{}_{t}(}_{t})]t+(t)}_{ t},}_{0}=_{T} p_{T}, \]

where the only unknown is the score function \(_{} p_{t}\), inheriting the intractability from the unknown initial distribution \(p_{0}\). In addition to the stochastic dynamics, the reverse-time model provides deterministic backward dynamics via an ordinary differential equation (ODE) by the so called probability flow ODE (PF ODE) 

\[}_{t}=[}(}_{t},t)-^{2}(t)_{}_{t }(}_{t},t)]t,_{T} p_{T}. \]

Stochasticity is only injected into the system through the random initialization \(_{T} p_{T}\), implying a deterministic and bijective map from noise to data . Conditioning the forward process on a data sample \(_{0} p_{0}\) results for linear \((,t)\) in a tractable Gaussian forward process with conditional score function \(_{} p_{0t}(|_{0})\) in closed form. To approximate the exact reverse-time model, this tractable score function is used to train a time-dependent score model \(S_{}\) via score matching [34; 35]. Upon training, any solver for SDEs or ODEs can be utilized to generate data from noise by simulating the stochastic or deterministic backward dynamics of the reverse-time model with \(S_{}_{} p\).

**Simulation error of the reverse-time model**. The two main sources of error when simulating the reverse-time model are the approximation error due to \(S_{}\) only approximating \(_{} p\), and the discretization error, which arises from transitioning from continuous-time to discrete steps. Simulating the PF ODE with the Euler method over \(N\) equidistant time steps results in a global error of order \(N^{-1}\). In contrast, the expected global error for simulating the SDE using the Euler-Maruyama method is of a lower order \(N^{-}\), indicating a larger error for the same number of steps [30; 36]. From this perspective it is reasonable that sampling from the PF ODE requires fewer steps. Yet, the source of qualitative differences between sampling from the ODE and the SDE  remains unclear.

**A pathwise perspective on sampling**. The roughness of a path can be measured by its Holder exponent \(0< 1\). For example, BM as the integrator in the backward dynamics eq. (2) has \(\)-Holder continuous paths for any \(0<<\), whereas the integrator \(t t\) of the PF ODE eq. (3) can be regarded as a Holder continuous path with exponent \(=1\). Therefore, from a pathwise perspective, we move away from a rough path when we sample using the PF ODE. An unexplored topic in score-based generative models is the interpolation between the SDE and the PF ODE in termsof the Holder exponent. It remains to be examined whether there is, to some extent, an optimal degree of Holder continuity in between, or if an even rougher path with \(\) could yield an advantageous data generator.

The process that naturally arises from this line of thought is fBM  with Hurst index \(H(0,1)\), where almost all paths are Holder continuous for any exponent \(<H\), controlled by \(H\). In terms of roughness, the Hurst index interpolates between the paths of Brownian driven SDEs and those of the underlying integration in PF ODEs, while also offering the potential for even rougher paths. Motivated by these observations, we define a novel score-based generative model with underlying dynamics that approximate a fractional diffusion process.

## 3 Fractional driving noise

Before describing the challenges in defining a score-based generative model with control over the roughness of the distribution transforming path, we introduce fBM. The literature distinguishes between "Type I" fBM and "Type II" fBM  having stationary and non-stationary increments, respectively. The type II fBM, also called Riemann-Liouville fBM, possesses smaller deviations from its mean, potentially an advantageous property for a driving noise of a score-based generative model, since large deviations of the sampling process to the data mean can lead to sample artifacts . Here and in the experiments we focus on type II fBM. However, our theoretical framework generalizes to both types as detailed in Appendix A. The empirical study of a score-based generative model approximating a fractional diffusion process driven by type I fBM is dedicated to future work. We begin with the definition of Riemann-Liouville fBM , a generalization of BM permitting correlated increments.

**Definition 3.1** (Type II Fractional Brownian Motion ).: _Let \(B=(B_{t})_{t 0}\) be a standard Brownian Motion (BM) and \(\) the Gamma function. The centered Gaussian process_

\[B_{t}^{H}=)}_{0}^{t}(t-s)^{H-} B_{s}, t 0, \]

_uniquely characterized in law by its covariances_

\[[B_{t}^{H}B_{s}^{H}]=(H+)} _{0}^{\{t,s\}}((t-u)(s-u))^{H-}u, t,s[0,) \]

_is called type II fractional Brownian motion (fBM) with Hurst index \(H(0,1)\)._

BM being the unique continuous and centered Gaussian process with covariance \(\{t,s\}\) is recovered for \(H=0.5\), since \((1)=1\). In comparison to the purely Brownian setting with independent increments (diffusion), the path of \(B^{H}\) becomes more smooth for \(H>0.5\) due to positively correlated increments (super-diffusion) and more rough for \(H<0.5\) due to negatively correlated increments (sub-diffusion). These three regimes are reflected in the Holder exponent of \(<H\) for almost all paths.

**Generalization challenges**. The most challenging part in defining a score-based generative model driven by fBM is the derivation of a reverse-time model. Due to its covariance structure, fBM is not a Markov process  and the shift in the roughness of the sample path leads to changes in its quadratic variation: from \(t\) in the purely Brownian (diffusion) regime to zero in the smooth regime, and to infinite in the rough regime . For that reason fBM is neither a Markov process nor a semimartingale  for all \(H 0.5\). Hence, we cannot make use of the Markov property or the Kolmogorov equations (Fokker-Planck) that are used to derive the reverse-time model of Brownian driven SDEs . See Appendix H for a more illustrative view of the problem. The existence of a reverse-time model can be proven in the smooth regime of fBM . However, due to the absence of an explicit score function in Darses and Saussereau  it does not provide a sufficient structure to train a score-based generative model.

To overcome this difficulty we follow  and define the driving noise of our generative model by a linear combination of Markovian semimartingales. The approximation is based on the exact infinite-dimensional Markovian representation of fBM given in Theorem A.2.

**Definition 3.2** (Markov approximation of fBM ).: _Choose \(K\) Ornstein-Uhlenbeck (OU) processes_

\[Y_{t}^{k}=_{0}^{t}e^{-_{k}(t-s)}B_{s}, k, t 0, \]_with speeds of mean reversion \(_{1},...,_{K}\) and dynamics \(Y_{t}^{k}=-_{k}Y_{t}^{k}t+B_{t}\). Given a Hurst index \(H(0,1)\) and a geometrically spaced grid \(_{k}=r^{k-n}\) with \(r>1\) and \(n=\) we call the process_

\[_{t}^{H}:=_{k=1}^{K}_{k}Y_{t}^{k}, H(0,1), t 0, \]

_Markov-approximate fractional Brownian motion (MA-fBM) with approximation coefficients \(_{1},...,_{K}\) and denote by \(}^{H}=(_{1}^{H},...,_{D}^{H})\) the corresponding \(D\)-dimensional process where \(_{i}^{H}\) and \(_{j}^{H}\) are independent for \(i j\) inheriting independence from the underlying standard BMs \(B_{i}\) and \(B_{j}\)._

Our framework is conceptually independent of the specific choice of spatial grid and approximation coefficients. To achieve strong convergence rates with a high polynomial order in \(K\) for \(H<0.5\) in the driving noise to fBM, one may follow the approach outlined in Harms . Consequently, our framework includes driving noise processes that converge to non-Markovian processes with infinite quadratic variation. For computational efficiency, we instead follow the approach of Daems et al.  to choose the \(L^{2}()\) optimal approximation coefficients for a given \(K\), achieving empirically good results in approximating fBM, even with a small number of OU processes.

**Proposition 3.3** (Optimal Approximation Coefficients ).: _The optimal approximation coefficients \(=(_{1},...,_{K})^{K}\) for a given Hurst index \(H(0,1)\), a terminal time \(T>0\) and a fixed geometrically spaced grid to minimize the \(L^{2}()\)-error_

\[():=_{0}^{T}[(B_{t}^{H}- _{t}^{H})^{2}]t \]

_are given by the closed-form expression \(=\) with_

\[_{i,j}:=^{-(_{i}+_{j})T}-1} {_{i}+_{j}}}{_{i}+_{j}},_{k}:= {T}{_{k}^{H+}}P(H+,_{k}T)-}{_{k}^{H+}}P(H+,_{k}T) \]

_and where \(P(z,x)=_{0}^{x}t^{z-1}e^{-t}t\) is the regularized lower incomplete gamma function._

MA-fBM serves as the driving noise of our generative model, replacing BM in the distribution transforming process solving eq.1, approximating a fractional diffusion process. See Figure1 for an illustration of the underlying processes.

## 4 A score-based generative model based on fractional noise

In this section, we define a continuous-time score-based generative model driven by MA-fBM. A detailed treatment of the theory can be found in AppendixA. We begin with the forward dynamics, transitioning data to noise.

**Definition 4.1** (Forward process).: _Let \(}^{H}\) be a \(D\)-dimensional MA-fBM with Hurst index \(H(0,1)\). For continuous functions \(:[0,T]\) and \(g:[0,T]\) we define the forward process \(=(_{t})_{t[0,T]}\) of a generative fractional diffusion model (GFDM) by_

\[_{t}=(t)_{t}t+g(t)}_{t}^{H},_{0}=_{0} p_{0}, t[0,T], \]

_where \(p_{0}\) is the unknown data distribution from which we aim to sample from._

Considering both the forward process as well as the OU processes defining the driving noise \(}^{H}\), we have for every data dimension an augmented vector of correlated processes (\(X,Y^{1},,Y^{K}\)), driven by the same BM, approximating the time-correlated behavior of a one-dimensional fractional diffusion process . We denote the stacked process of the \(D\) augmented vectors as \(=(_{t})_{t[0,T]}\) and refer to the resulting \(D(K+1)\)-dimensional process as the _augmented forward process_. Rewriting the dynamics of the forward process we observe that the augmented forward process \(\) solves a linear SDE. Hence, \(|_{0}\), the augmented forward process conditioned on a data sample \(_{0} p_{0}\), is a linear transformation of BM. Thus \(|_{0}\) is a Gaussian process and so is \(|_{0}\). For each dimension \(1 d D\), we have a system of \(K+1\) trajectories that transform \(_{0,d}\) according to the augmented forward process with \(D=1\), following the dynamics

\[_{t}=(t)_{t}t+(t) B_{t}, \]where all \(K+1\) processes are driven by the same one-dimensional BM \(B\) with matrix valued functions \(\) and \(\) defined in Appendix A.2. To efficiently sample for every \(t(0,T]\) from the conditional augmented forward distribution during training, we characterize its marginal statistics.

**Derivation of marginal statistics**. The marginal mean \([_{t}|_{0}]=_{0}(_{0}^{t}(s) s)\) of the conditional forward process is unaffected by changing the driving noise to MA-fBM, and the mean of the augmenting OU processes is zero. See Appendix A.2 for a detailed derivation of the marginal statistics of the augmenting processes. The missing components in the marginal covariance matrix \(_{t}\) of the conditional augmented forward process \(|_{0}\) are the marginal variance of the forward process and the marginal correlation between the conditional forward process and the augmenting processes. We derive by reparameteriziation an explicit formula for the marginal variance of the conditional forward process. This generalizes the formula for the perturbation kernel \(p_{0t}(|_{0})=(;c(t)_{0},c^ {2}(t)^{2}(t)_{D})\) given in Karras et al.  to a driving MA-fBM and is reminiscent of the reparameterization trick used in discrete time.

**Proposition 4.2** (Continuous Reparameterization Trick).: _The forward process \(\) of GFDM conditioned on \(_{0}^{D}\) admits the continuous reparameterization_

\[_{t}=c(t)(_{0}+_{0}^{t}(t,s) _{s})(c(t)_{0},c^{2}(t)^{2}(t) _{D}) \]

_with \(c(t)=(_{0}^{t}(s)s)\) and \(^{2}(t)=_{0}^{t}^{2}(t,s)s\) where \(\) is given by_

\[(t,s)=_{k=1}^{K}_{k}[-_{k}_{s} ^{t}f_{k}(u,s)u], f_{k}(u,s)=e^{-_ {k}(u-s)}. \]

Sketch of Proof.: Reparameterization of the forward dynamics in eq.10 and the Stochastic Fubini Theorem yields the Gaussian process \(_{t}=c(t)(_{0}+_{0}^{t}(t,s) _{s})\) with variance \([_{t}]=c^{2}(t)_{0}^{t}^{2}(t,s) s\) by Ito isometry. See Theorem A.3 for the full proof. 

By the above definition of \(\), we retrieve the perturbation kernel of the purely Brownian setting given in Karras et al. [44, Equation 12] for \(K=1\), \(_{1}=0\) and \(_{1}=1\). When, depending on the choice of forward dynamics, \(_{0}^{t}(t,s)s\) is not accessible in closed form, \(_{t}\) can be described by an ODE and solved numerically as described in Appendix B. Thus our method admits any choice of forward dynamics in terms of \(\) and \(g\).

**Explicit fractional forward dynamics**. Although our framework is not bound to any specific dynamics, this work's empirical evaluation focuses on _Fractional Variance Exploding_ (FVE) dynamics given by

\[_{t}=_{min}(}{_{min}} )^{t}}{_{min}}}}_{t}^{H}, t[0,T] \]

with \((_{min},_{max})=(0.01,50)\) and _Fractional Variance Preserving_ (FVP) dynamics given by

\[_{t}=-(t)_{t}t+ {(t)}}_{t}^{H}, t[0,T] \]

with \((t)=(t)=_{}+t(_{max}-_{ min})\) and \((_{min},_{max})=(0.1,20)\). Leveraging the continuous reparameterization trick we derive in Appendix B the conditional marginal covariance matrix of FVE in closed form. To the best of our knowledge, the integral in eq.13, needed to compute \(\) in the setting of FVP dynamics, is not accessible in closed form. Therefore, we use a numerical ODE solver to estimate this quantity for FVP dynamics. See Appendix B for details on the computation of the marginal variances and an illustration of the resulting variance schedules.

**The reverse-time model**. We observe that the augmented forward dynamics of GFDM are already encompassed in the general framework presented in Song et al. [16, Appendix A], although they differ from the Variance Exploding (VE), Variance Preserving (VP), and sub-VP dynamics discussed therein. To simplify notation, we use \(p_{t}\) here to denote the marginal density of both \(_{t}\) and \(_{t}\). The specific density referred to will be clear from the context. By the significant results of , the reverse-time model of GFDM is given by the backward dynamics

\[}_{t}=[}(t)}_{t}-}(t)}(t)^{T}_{ }_{t}(}_{t})]t+ }(t)}_{t}, t[0,T]. \]However, a direct application of  would require to train a score model with input and output dimension of \(D(K+1)\). By proposing _augmented score matching_ below, we show that learning a score model with input and output dimension \(D\) is sufficient, enabling the use of the same highly curated model architecture as in traditional diffusion models to approximate the score function.

**Augmented score matching**. We condition the score function \(_{} p_{t}\) on a data sample \(_{0} p_{0}\)_and additionally_ on the states of the stacked vector \(_{t}^{[K]}:=(_{t}^{1},...,_{t}^{K})\) of augmenting processes. To train our time-dependent score model \(s_{}\) we propose the _augmented score matching loss_

\[():=_{t}\{_{(_{0}, _{t}^{[K]})}_{(_{t}|_{t}^{[K]}, _{0})}[\|s_{}(_{t}-_{k}_{t}^{k} _{t}^{k},t)-_{} p_{0t}(_{t}|_{t}^{[K]},_{0})\|_{2}^{2}]\}. \]

The weights \(_{t}^{1},...,_{t}^{K}\) arise from conditioning \(_{t}|_{0}\) on \(_{t}^{[K]}\) and the time points \(t\) are uniformly sampled from \([0,T]\). We show in the following that the optimal \(s_{}\) w.r.t. the _augmented score matching loss_ is the \(L^{2}\)-optimal approximation of the score function of our reverse-time model.

**Proposition 4.3** (Optimal Score Model).: _Assume that \(s_{}\) is optimal w.r.t. the augmented score matching loss \(\). The score model_

\[S_{}(_{t},t):=(s_{}(_{t}-_{k} _{t}^{k}_{t}^{k},t),-_{t}^{1}s_{}(_{t}- _{k}_{t}^{k}_{t}^{k},t),...,-_{t}^{K}s_{}( _{t}-_{k}_{t}^{k},t)) \]

_yields the optimal \(L^{2}()\) approximation of \(_{} p_{t}(_{t})\) via_

\[S_{}(_{t},t)+_{} q_{t}(_{t} ^{[K]})_{} p_{t}(_{t}). \]

Sketch of Proof.: Using the relation \(_{} p_{0t}=-_{t}^{k}_{^{k}} p_{0t}\) and the independence of \(_{0}\) and \(_{t}^{[K]}\) yields the claim. See Appendix A.3 for the full proof. 

In addition to the result that a score model of data dimension \(D\) minimizes the proposed _augmented score matching loss_, Proposition 4.3 also implies that GFDM requires the same number of score model evaluations during sampling from the reverse-time model as traditional diffusion models. This is because, for a given time point \(t\), we only need to evaluate \(s_{}(,t)\) once at \(_{t}-_{k}_{t}^{k}_{t}^{k}\) to compute \(S_{}(_{t},t)\) according to eq.18, and \(S_{}\) is all that is required to approximate the reverse-time dynamics described below. We provide a thorough quantitative evaluation of compute time in seconds for GFDM in Appendix F, validating the theoretical reasoning in this section that GFDM incur only minimal additional computational cost.

**Sampling from reverse-time model**. Once we trained our score model \(S_{}\) via augmented score matching, we simulate the reverse-time model backward in time and sample from the reverse-time model via the SDE

\[}_{t}=\{}(t)}_{t}-}(t)}(t)^{T}[ _{}(}_{t},t)+_{} _{t}(}_{t}^{[K]})]\} t+}(t)}_{t}, t[0,T] \]

or the corresponding augmented PF ODE 

\[}_{t}=\{}(t) {}_{t}-}(t)}(t)^{ T}[_{}(}_{t},t)+_{ }_{t}(}_{t}^{[K]})] \}t, t[0,T], \]

where we initialize in both cases the reverse dynamics with the centered (non-isotropic) Gaussian \(}_{0}\) with covariance matrix \(_{T}\). To traverse backward from noise to data, we may deploy any suitable SDE or ODE solver. In both cases, for each data dimension, we have \(K+1\) trajectories that transform the Gaussian initialization into an approximate sample of the data distribution. The PF ODE enables in addition negative log-likelihoods (NLLs) estimation of test data under the learned density . See Appendix G for the computation details of NLLs.

**Remark 4.4**.: _We showed in this section that it suffices to approximate a \(D\)-dimensional score to reverse the \(D(K+1)\)-dimensional MA-fBM driven SDE with unknown starting distribution. Since this holds for any fixed \(K\) an interesting task is to examine the behaviour of the reverse-time model as \(K\) and potentially link it to the dynamics of a reverse-time model of true fBM. To the best of our knowledge, existence of such a reverse-time model is not known for \(H<0.5\) and the drift of the reverse-time model for \(H>0.5\) lacks sufficient structure to train a score-based generative model ._

## 5 Experiments

We conduct experiments on MNIST and CIFAR10 to evaluate the ability of GFDM to generate real images. First, we measure the quality and the pixel-wise diversity of the generated images across different numbers of augmenting processes and various Hurst indices, showing that the super-diffusive regime with \(H>0.5\) yields better performance compared to the purely Brownian driven dynamics. Second, we further evaluate the best performing models in terms of class-wise image quality and class-wise distribution coverage. We measure image quality by the Frechet Inception Distance (FID)  and the Inception score (IS) , pixel-wise diversity by the pixel Vendi Score (VS\({}_{p}\))  and class-wise distribution coverage by improved recall (Recall) . See Appendix D for the implementation details and additional experimental results. We begin with the empirical evaluation of how the augmenting processes affect performance on MNIST.

**Effect of augmentation on MNIST.** To isolate the effect of the augmenting processes on MNIST while minimally adapting the driving noise distribution, we fix \(H=0.5\) so that the weighted sum of the augmenting processes approximates BM, rather than fBM. We observe an increase of the pixel-wise diversity VS\({}_{p}\) for both FVE and FVP dynamics, with increasing \(K\). In Table 1 we can observe that VS\({}_{p}\) increases from \(24.20\) to \(24.54\) for FVE dynamics and from \(23.64\) to \(24.56\) for FVP dynamics. The enhanced pixel-wise diversity on MNIST comes at the cost of a reduced likelihood of test data under the learned density, indicated by a higher NLLs for more augmenting processes.

**Quality results across different Hurst indices**. On both, MNIST and CIFAR10, we obtain the best performance in terms of FID and VS\({}_{p}\) in the super-diffusive regime with \(H=0.9\) and FVP dynamics. On MNIST we achieve state of the art FID of \(0.72\), compared to an FID of \(1.44\) with the purely Brownian VP dynamics (Table 1(a)). Comparing FVP to the best-performing purely BM driven VP dynamics, we observe not only an improvement in quality but also an increase in pixel-wise diversity from \(23.64\) to \(24.18\), as measured by VS\({}_{p}\). In Table 1(b) we observe the same behaviour on CIFAR10. The best performing configuration in terms of FID and pixel-wise diversity is achieved for FVP(\(H=0.9,K=2\)) with an FID of \(3.77\) instead of \(4.85\) and an VS\({}_{p}\) of \(3.60\) instead of \(3.28\). Additionally, in Figure 7, we show the FID evolution of the super-diffusive regime for various numbers of augmenting processes, showing a similar pattern that either that \(K=2\) or

    &  & \)} & _{p}\) \(\)} &  &  & \)} & _{p}\) \(\)} \\  
**V** (_breathing_) & 10.82 & 2.73 & 24.20 & VP(trained) & **1.44** & **2.38** & 23.64 & \(K=1\) & 2.81 & 3.90 & 23.69 & \\ \(K=2\) & 9.59 & 3.03 & 24.15 & \(K=2\) & 2.52 & 4.57 & 23.63 & \(K=3\) & 3.51 & 7.02 & 23.78 & \\ \(K=3\) & **9.74** & 2.93 & 24.42 & \(K=3\) & 3.51 & 7.02 & 23.78 & \(K=4\) & 1.25 & 3.10 & 7.02 & 23.70 & \\ \(K=4\) & 11.25 & 3.10 & **24.54** & \(K=4\) & 1.86 & 5.71 & 24.50 & \(K=5\) & 25.51 & 3.94 & \(K=5\) & 4.89 & 7.09 & **24.56** \\  
**MNIST** & \(H=0.9\) & \(H=0.7\) & \(H=0.5\) & \(H=0.1\) & **CIFAR10** & \(H=0.9\) & \(H=0.7\) & \(H=0.5\) & \(H=0.1\) & \\ 
**fBM driven** & & & & & & & & & & & & \\ 
**V** (_breathing_) & - & - & - & - & 10.82 & 24.20 & - & - & - & - & - & - & - \\
**V** (_breathing_) & - & - & - & - & 1.44 & 25.64 & - & - & - & - & - & - & - \\ 
**M-fBM driven** & & & & & & & & & & & & & \\ 
**FVV**(_IR_ + 1) & 2.86 & 23.56 & 20.1 & 23.78 & 2.81 & 23.69 & 2.92 & 23.50 & \((H,K=1)\) & **4.79** & **3.53** & 4.96 & \(\) \\
**FV**(_IR_ + 2) & 1.53 & 24.00 & 23.08 & 22.92 & 25.63 & 26.58 & \((H,K=2)\) & **5.77** & \(\) & **4.17** & 3.85 & \(\) & \(\) & \(\) & \(\) \\
**FV**(_IR_ + 3_) & **0.72** & 24.18 & 20.67 & 23.96 & 3.51 & 23.78 & \(\) & 23.87 & \(\) & \(\) & \(\) & \(\) & \(\) \\
**FV**(_IR_ + 4_) & **1.22** & **24.76** & **0.06** & **24.29** & 1.56 & \(\) & \(\) & 23.89 & \(\) & \(\) & \(\) & \(\) \\
**FV**(_IR_ + 5_) & 2.17 & **28.15** & **1.36** & **24.63** & 4.89 & \(\) & \(\) & 23.70 & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 2: FID and pixel-wise diversity VS\({}_{p}\) of GFDM compared to the original setting of purely Brownian driven VE and VP. In bold the scores that are better than both purely Brownian driven dynamics. The overall best scores within the experiment are boxed in, indicating that the highest scores on both datasets are achieved in the super-diffusive regime for \(H=0.9\).

Figure 2: Comparison of the super-diffusive regime and purely Brownian dynamics in terms of average FID over three rounds of sampling plotted across different NFEs.

\(K=3\) yields the best performance across different datasets and dynamics. Evaluating the performance with different number of sampling steps in Figure 2 shows that the super-diffusive regime with \(K=2\) saturates already at \(500\) number of function evaluations (NFEs) on a lower level than both purely Brownian driven dynamics VP and VE. See Figure 2 in Appendix D for the exact FID values.

**Class-wise distribution coverage**. We evaluate the capability to generate samples from different classes in terms of FID and class-wise distribution coverage, measured by Recall, comparing the best-performing purely Brownian driven dynamics to the super-diffusive regime with \(K=2\). In Table 3 we observe that the super-diffusive regime with \(K=2\) outperforms in both FID and Recall, where \(H=0.7\) and \(H=0.9\) achieve better class-wise FID for all but two and one class, respectively (deer and dog for \(H=0.7\), bird for \(H=0.9\)). Additionally, the super-diffusive regime shows improved class-wise distribution coverage, as indicated by a higher Recall across all classes. Overall, both \(H=0.7\) and \(H=0.9\) perform significantly better in terms of distribution coverage than VP dynamics, \(H=0.9\) being the best performing model.

**Sampling with the augmented probability flow ODE**. We compare the performance of sampling via the PF ODE for the best performing models from above. For MA-fBM driven dynamics, we have \(K+1\) deterministic trajectories for each pixel, traversing from noise to data. As shown in Figure 3, the PF ODE associated with purely Brownian dynamics outperforms the super-diffusive regime in terms of FID, while the super-diffusive regime achieves the overall highest pixel-wise diversity of \(_{p}=4.89\) confirmed mildly perceptually in Figure 4. See Appendix E for additional visualization of the generated data.

Our experiments show that, compared to purely Brownian dynamics, the super-diffusive regime of MA-fBM yields higher image quality with fewer NFEs, improved pixel-wise diversity and better distribution coverage.

## 6 Related work

**Diffusion models in continuous-time**. The seminal work of Song et al.  offers a unifying framework modeling the distribution transforming process by a stochastic processes in continuous-time with exact reverse-time model. Extensive research has been carried out to examine [44; 49; 50] and extend [39; 51; 52; 53; 54; 55] the continuous-time view on generative models through the lens of

Figure 4: Visual comparison of PF ODE samples. (LHS) Purely Brownian VP dynamics. (RHS) Super-diffusive regime \((H=0.9,K=2)\).

Figure 3: Quantitative performance comparison of SDE and PF ODE sampling.

    & FID \(\) & IS \(\) & \(_{p}\) \\ 
**Sampled with SDE** & & & \\  VE (retrained) & \(5.20\) & \(9.60\) & \(3.42\) \\ VP (retrained) & \(4.85\) & \(9.64\) & \(3.28\) \\ FP (\(H=0.7,K=2\)) & \(4.17\) & \(9.51\) & \(3.35\) \\ FP(\(H=0.9,K=2\)) & \(\) & \(9.41\) & \(3.60\) \\ 
**Sampled with PF ODE** & & & \\  VE (retrained) & \(6.40\) & \(9.22\) & \(3.14\) \\ FP(\(H=0.7,K=2\)) & \(5.63\) & \(9.23\) & \(3.91\) \\ FP(\(H=0.7,K=2\)) & \(12.23\) & \(\) & \(4.38\) \\ FP(\(H=0.9,K=2\)) & \(12.26\) & \(9.55\) & \(\) \\   

Table 3: The class-wise image quality and class-wise distribution coverage of the super-diffusive regime \((H=0.9,K=2)\) compared to the purely Brownian VP dynamics.

SDEs, including deterministic corruptions  and blurring diffusion . While critic on this view question the usefulness of the theoretical superstructure , others extend in line with our work the theoretical framework to new types of underlying diffusion processes . Conceptually similar to our work,Yoon et al.  generalizes the score-based generative model from an underlying Brownian motion to a driving Levy process, thereby dropping the Gaussian assumptions on the increments. In contrast to our work, the framework of Yoon et al.  does not include correlated increments. Importantly, every Levy process is a semimartingale, which means that fBM is not a Levy process.

**Fractional noises in machine learning.** Recently, Hayashi and Nakagawa  considered neural-SDEs driven by fractional noise. Yet they do not study diffusion models. The closest work to our work, Tong et al.  approximated the type-II fBM with sparse Gaussian processes constructing a neural SDE as a forward process of a score-based generative model, without exact reverse-time dynamics. Unfortunately, they are also limited to Euler-Maruyama solvers and to the case of \(H>1/3\), while our framework is up to numerical stability applicable for any \(H(0,1)\) and compatible with any suitable SDE or ODE solver. Daems _et al._, who inspired our Markov-approximate noise, includes a more elaborate discussion as well as a variational inference framework for MA-fBM.

**Rough path theory**. The pathwise analysis of SDEs driven by processes with a Holder exponent less than \(0.5\), including fBM for \(H<0.5\) and BM, is encompassed by rough path theory . Rough path theory is applied in machine learning in several ways including (i) deriving stability bounds for the trained weights of a residual neural network , (ii) enabling rough control of neural ODEs , and (iii) modeling long time series behavior via neural rough differential equations [63; 64]. In finance the famous Black-Scholes model  is driven by BM, while more recent continuous-time models employ fractional noise to model price processes [66; 67] or rough volatility [68; 69] to more closely mimic real-world behavior.

## 7 Conclusion

In this work, we propose a generalized framework of continuous-time score-based generative models, introducing a novel generative model driven by MA-fBM with control over the roughness of distribution transformation paths via augmenting processes. Despite the increased dimensionality of the forward process, learning a score model with the dimensionality of the data distribution, guided by the marginal known score of the augmenting processes, is sufficient. Consequently, both training and sampling is efficient. Our experimental results show that the super-diffusive regime of our MA-fBM driven dynamics achieves superior performance in terms of FID and pixel-wise diversity. Additionally, the FID saturates at a lower level with fewer function evaluations compared to purely Brownian driven dynamics. The super-diffusive regime also improves class-wise distribution coverage, as measured by Recall. Based on these results, GFDM offers a promising alternative to traditional diffusion models for generating data from an unknown distribution.

**Limitations and future work**. Several practical and theoretical questions remain open. While we draw our conclusions from experiments conducted on MNIST and CIFAR10, generalizing the observed behavior to other datasets and data modalities may not be valid. In future work, we aim to empirically and theoretically determine the optimal degree of correlated noise, and thus the optimal Hurst index, for training and sampling across different data modalities. Beyond image data, a particularly interesting modality could be the generation of rough time series data using dynamics of the sub-diffusive regime. A theoretical open question is the limiting behavior of GFDM's reverse dynamics with infinitely many augmenting processes and whether this limit is connected to the reverse time model for true fBM. An intriguing extension would be to adapt the dynamics of our framework to switch between two unknown distributions. This adaptation would enable the use of MA-fBM driven dynamics in the sciences to model real-world evolution between two states of unknown distributions. This is a promising direction, as the assumption of independent increments in real-world noise processes is often too strong.

**Broader impact**. Our contribution advances generative modeling by introducing a specific driving noise process to improve the learning of an unknown distribution. This conceptual work aims to support impactful applications of generative modeling, such as molecular structure generation, medical imaging, drug discovery, and DNA sequence design. However, we acknowledge that generative models can reflect biases in the datasets they are trained on and may pose risks, including misuse for human impersonation and the spread of fake content.