# Supplemental Materials

Label Correction of Crowdsourced Noisy Annotations with an Instance-Dependent Noise Transition Model

 Hui Guo

Department of Computer Science

University of Western Ontario

hguo288@uwo.ca

&Boyu Wang

Department of Computer Science

University of Western Ontario

bwang@csd.uwo.ca

Corresponding authors.

Grace Y. Yi

Department of Statistical and Actuarial Sciences

Department of Computer Science

University of Western Ontario

gyi5@uwo.ca

###### Abstract

The predictive ability of supervised learning algorithms hinges on the quality of annotated examples, whose labels often come from multiple crowdsourced annotators with diverse expertise. To aggregate noisy crowdsourced annotations, many existing methods employ an annotator-specific instance-independent _noise transition matrix_ to characterize the labeling skills of each annotator. Learning an _instance-dependent_ noise transition model, however, is challenging and remains relatively less explored. To address this problem, in this paper, we formulate the noise transition model in a Bayesian framework and subsequently design a new label correction algorithm. Specifically, we approximate the instance-dependent noise transition matrices using a Bayesian network with a hierarchical spike and slab prior. To theoretically characterize the distance between the noise transition model and the true instance-dependent noise transition matrix, we provide a posterior-concentration theorem that ensures the posterior consistency in terms of the Hellinger distance. We further formulate the label correction process as a hypothesis testing problem and propose a novel algorithm to infer the true label from the noisy annotations based on the pairwise likelihood ratio test. Moreover, we establish an information-theoretic bound on the Bayes error for the proposed method. We validate the effectiveness of our approach through experiments on benchmark and real-world datasets.

## 1 Introduction

Deep neural networks (DNNs) have achieved remarkable performance in various tasks [1; 2], and they have proven to be useful in handling sizable labeled data. Acquiring large accurately annotated datasets, however, is usually expensive and time consuming. To enhance the efficiency of annotation, in many applications, _crowdsourcing_ is employed as an alternative way for data labeling, where the labels are provided by multiple annotators with varying and imperfect labeling skills, and thus, the collected labels suffer from unavoidable noise. As deep models have a strong memorization power, using these noisy labels as the ground truth deteriorates the performance of DNNs [4; 5], and most importantly, yields erroneous learning results. Further, potentially substantial disagreement among the annotators for each instance presents extra challenges in the application of traditional supervised learning algorithms. Hence, in the crowdsourcing scenario, to effectively train DNNs on noisy labeled datasets, a fundamental question is how to aggregate the noisy crowdsourced annotations and infer the latent true labels .

One naive approach to aggregate the crowdsourced labels is simply by computing the majority vote, which can be ineffective when the number of annotators is not large enough or the labeling task is difficult [7; 8]. Recent research has developed more powerful techniques for inferring the ground truth labels [7; 9; 10; 11], among which the _annotator-specific noise transition matrix_, aka _annotator confusion_, plays an important role by modeling the labeling process for each individual annotator. To estimate the transition matrix, available research [8; 11; 12; 13] usually makes the _instance-independent_ assumption that for annotator \(r\), given the true label \(\), the corruption process is independent of the input \(\), i.e., \((}^{(r)}=l|=k,)=( }^{(r)}=l|=k)\), where \(\) denotes the random variable for instance/feature, \(}^{(r)}\) represents the noisy label given by annotator \(r\), and \(\) is the underlying ground truth label. This assumption, however, is often violated in applications. _Instance-dependent_ annotation noise is more realistic and appropriate for real-world datasets, as suggested by the example that factors such as the quality of ultrasound images and the domain expertise of human annotators can greatly influence the actual diagnostic process in medical analysis [14; 15]. For annotator \(r\), the transition matrix \(^{(r)}()\) is a matrix-valued function, with the \((k,l)\) element defined as \(^{(r)}_{kl}()=(}^{(r)}=l| =k,)\). Unfortunately, the case of instance-dependent annotation noise remains challenging and less explored. Most existing works considering instance-dependent noise are designed for the single annotator case [16; 17; 18]. For the case with multiple annotators, existing methods investigate the human annotation process and use different models to estimate instance-dependent noise matrices. Approaches in [3; 19; 20; 21; 22] use traditional classification models such as logistic regression, while others [23; 24; 25] cater to large datasets and deep models. Methods in [3; 19; 20; 21; 22] and [24; 25] are heuristic in nature and lack theoretical guarantees in estimating instance-dependent noise matrices.  makes some theoretical progress in justifying the use of the trace regularisation, and extends the work of  which establishes the theory only for settings with an instance-independent noise matrix. The theory in  is constrained to individual samples rather than the population setting. Importantly, the theoretical characterization of the distance of the noise model and the true annotator confusion remains absent from the literature.

In this paper, we address this notable problem by framing it within the Bayesian paradigm. We **formulate the instance-dependent annotator-specific label transition matrix**, and further propose **a novel algorithm to infer the underlying ground truth by aggregating the noisy annotations**. To model the noise transition matrix, we invoke the Bayesian generalized linear mixed effects model (GLMM), which can be learned by deploying anchor points within the deep learning framework [12; 26; 27]. To facilitate the fact that the number of anchor points learned from the noisy training data is relatively small compared to the sample size, we employ a hierarchical spike and slab prior on the network parameters. This approach offers an interpretable mechanism for variable selection and allows us to establish the theoretical result within the deep learning setup. Our study reveals that the proposed noise transition model is close to the underlying true transition matrix with respect to the Hellinger distance in the Bayesian framework. Such a result is established for independently, nonidentically distributed (i.n.i.d.) observations, substantially extending the existing sparse Bayesian theories within the deep learning paradigm. Further, we develop a label correction method using the pairwise likelihood ratio test to aggregate and infer the ground truth from the noisy crowdsourced annotations. This development is carried out by formulating the label correction process as a hypothesis testing problem and utilizing the proposed Bayesian model in place of the unknown transition matrix in the pairwise likelihood ratio test (LRT). More importantly, with the posterior consistency result, we also derive information-theoretic bounds on the Bayes error for the proposed algorithm even without access to the underlying true noise transition matrix.

This research brings forth several noteworthy advancements: (1) We formulate the annotator-specific noise transition matrix in the Bayesian framework (Section 3.1). This method offers a practical and flexible framework to address real-world problems with noisy annotators. (2) We theoretically characterize the closeness of the proposed model and the underlying annotator confusions with respect to the Hellinger distance. (Section 3.2). (3) We develop a novel label correction algorithm by aggregating the noisy annotations using the pairwise likelihood ratio test, and identify information-theoretic bounds on the Bayes error (Section 3.3). The effectiveness of the proposed algorithm is confirmed by the application to both synthetic and real-world noisy datasets (Section 5). Code is available at https://github.com/hguo1728/BayesianIDNT.

## 2 Problem Setup

Objective and Data.Consider a classification task with a feature space \(^{p}\) and a label space \(=[K]\), where \(p\) is the dimension of the features, \(K\) is the number of classes, and \([k]\) represents \(\{1,...,k\}\) for any positive integer \(k\). Our goal is to develop a classifier \(h:\), which can accurately predict the true label for a test instance. However, in applications, the true label \(\) is often not observed for each input vector \(\). Instead, we receive a set of noisy crowdsourced labels \(}=\{}^{(1)},..,}^{(R)}\}\) from \(R\) distinct annotators, where \(}^{(r)}\) represents the label given by the \(r\)th annotator for \(r[R]\). Thus, a noisy dataset \(\) of size \(N\) is defined as \(=\{_{i},}_{i}^{(1)},..,}_{i}^{(R)}\}_{i=1}^{N}\), where for each instance \(_{i}\), the true label \(_{i}\) is unobserved. Under this setting, we aim to learn a reliable classifier \(h\) by utilizing the noisy crowdsourced dataset \(\).

In practice, on commercial crowdsourcing platforms, large-scale labels can often be collected from independent human annotators. We thereby make a common assumption that the \(R\) annotators independently label the instances [7; 8]. The conditional probability of the \(R\) noisy labels, given an instance, can then be formulated as

\[(}^{(1)},..,}^{(R)}|)= _{r=1}^{R}(}^{(r)}|)=_{r=1}^{R} _{k}\{(}^{(r)}|=k,)P(=k|)\},\] (1)

where for \(k\), \((y=k|)\), called the _base model_, denotes the conditional probability of the latent true label \(\) given \(\), which can be modeled by the output of a DNN parameterized by a parameter vector, say \(\); and \((}^{(r)}|=k,)\) is the _noise transition model_ for the \(r\)th annotator , satisfying \(_{l=1}^{K}(}^{(r)}=l|=k,)=1\) for any \(\) and \(k[K]\). For ease of theoretical presentation, we assume the accessibility to all the annotations from the \(R\) workers for now, and consider more general situations in the experimental part in Section 5; extensions to accommodating the case where each instance is only annotated by a subset of annotators are straightforward.

Notation.In this paper, sets are denoted by calligraphic upper case letters, and vectors and matrices are denoted by bold lower and upper case letters, respectively. For a vector \(\), \(v_{j}\) denote its \(j\)th element, and \(^{}\) denotes its transpose. For \(=(v_{1},...,v_{d})^{}\), we denote \(\|\|_{q}=(_{j=1}^{d}|v_{j}|^{q})^{1/q}\) for \(q>0\), \(\|\|_{}=_{j}|v_{j}|\), and \(\|\|_{0}=_{j=1}^{d}(v_{j} 0)\), with \(()\) denoting the indicator function. The \(L_{2}\) norm of \(\) is also denoted by \(\|\|\) for simplicity. For a matrix \(\), we use \(V_{i,j}\) to represent its \((i,j)\) element. Let \((,,)\) denote the measure space under consideration, where \(\) is a set, \(\) is the \(\)-field of subsets of \(\), and \(\) is the associated measure. For a measurable function \(f:^{d}\), we write \(\|f\|_{q}\|f\|_{L^{q}()}\) when there is no ambiguity of the domain, where \(\|f\|_{L^{q}()}=(_{}_{j=1}^{d}|f_{j}(x)|^{q}d )^{1/q}\) for \(q>0\). For two sequences, \(\{a_{n}\}\) and \(\{b_{n}\}\), we write \(a_{n} b_{n}\) if there exists a positive constant \(C\) such that \(a_{n} Cb_{n}\) for large enough \(n\), and we write \(a_{n} b_{n}\) if \(a_{n} b_{n}\) and \(b_{n} a_{n}\).

## 3 Main Results

### Instance-dependent transition matrix with multiple annotators

Annotator-specific instance-dependent noise transition model.Given an instance \(\), the conditional probability mass function of noisy annotations can be characterized by \(R\) instance-dependent matrices of dimension \(K K\), termed _transition matrices_ or _annotator confusions_[8; 13], with the \(k\)th row of the \(r\)th matrix denoted \(((}^{(r)}=1|=k,),, (}^{(r)}=K|=k,))\). Thus, the distribution of noisy annotation depends on the instance in different ways due to the differences in the annotator \(r\) and the underlying true label \(\), which can be characterized by a Bayesian generalized linear mixed effects model (GLMM) [29; 30] in the deep learning framework.

Specifically, conditioned on the true label \(=k\) and the feature vector \(\), we treat the noisy label \(}^{(r)}\) from annotator \(r\) as a random variable generated from the distribution:

\[}^{(r)}|\{=k,\}(^{(k,r )}),\] (2)

where \(^{(k,r)}=(s_{1}^{(k,r)},...,s_{K}^{(k,r)})^{}^{K-1}\) with \(^{K-1}=\{(s_{1},...,s_{K})^{}^{K}:s_{j} 0\) for \(j[K]\) and \(_{j=1}^{K}s_{j}=1\}\) representing the \((K-1)\)-dimensional simplex, and \((^{(k,r)})\) represents a categorical distribution specified by the parameter vector \(^{(k,r)}\). We extend existing works on mixed effects neural networks (MNN) [31; 32] by employing two nonlinear transformations \(_{1}\) and \(_{2}\) to incorporate different effects in the instance-dependent noise transition model, and set

\[^{(k,r)}=G(_{0}^{(k,r)})_{0}^{(k,r)}= _{0}^{(r)}_{1}()+_{0}^{(k)}_{2}( ),\] (3)

where \(_{0}^{(r)}=(_{10}^{(r)},...,_{K0}^{(r)})^{}\) and \(_{0}^{(k)}=(_{10}^{(k)},...,_{K0}^{(k)})^{}\) are the regression weights; \(_{1}()\) and \(_{2}()\) can be modeled by some suitable networks; and \(G\) is a function mapping \(^{K}\) to \(^{K-1}\), which, in practice, is chosen to be the softmax function in the final layer. Utilizing two different network components \(_{1}\) and \(_{2}\) enables us to flexibly reflect possibly different effects of the annotator expertise (\(r\)) and the ground truth (\(k\)) in the annotation process, which can be interpreted as the input in mixed effects models.

Approximating the transition matrices.The proposed instance-dependent noise transition model can be learned by leveraging anchor points [12; 26; 27], or instances that are similar to anchor points learned from noisy training data . An instance \(\) is defined to be an anchor point of class \(k\) if it belongs to the \(k\)th class almost surely, that is, \((=k|)=1\), and hence, \((}^{(r)}|)=(} ^{(r)}|=k,)\). For \(k[K]\), let \(}_{0,k}\) be the set of anchor points of the \(k\)th class and the associated noisy annotations, i.e., \(}_{0,k}=\{\{_{i},}_{i}\}: (_{i}=k|_{i})=1\}\). Define \(}_{0}=}_{0,1}}_{0,2}}_{0,K}\), and let \(n\) denote the subsample size of the learned anchor points, i.e., the cardinality of \(}_{0}\). Paired variables \(\{_{i},}_{i}\}\) in \(}_{0}\) are independent, but **not necessarily identically** distributed (i.n.i.d). We write the input dimension \(p\) as \(p_{n}\) from now on to emphasize that its dependence on \(n\) is allowed.

In applications, overfitting can occur when the subsample size \(n\) of the learned anchor points is relatively small compared to the main sample size \(N\). To address this issue, we propose to learn \(_{j}()\) with a sparse Bayesian DNN, denoted \(_{j}(;^{(j)})\), where \(^{(j)}\) represents the vector of all involved parameters in the network with \(j=1,2\). Furthermore, invoking the sparse Bayesian setting allows us to rigorously characterize the distance between the proposed model and the underlying true transition matrices, as presented in Theorem 1 of Section 3.2.

### Bayesian analysis and posterior consistency result

Prior specification.To implement sparse Bayesian analysis, we utilize the spike and slab prior  on the network parameters, offering an interpretable mechanism for variable selection. The spike and slab model is formulated by constructing a prior hierarchy of the involved parameters and selects nonzero coefficients according to the posterior inclusion probability. Marginally, these priors are mutually independent and have a mixture distribution consisting of a flat distribution (slab) and a distribution concentrated at zero (spike). Parameters with a small posterior mean will be set to zero to achieve sparsity.

Specifically, for network \(_{j}(;^{(j)})\), we write \(^{(j)}\) as \(^{(j)}=(_{1}^{(j)},...,_{J_{j}}^{(j)})^{}\) with \(J_{j}\) denoting the length of \(^{(j)}\) for \(j=1,2\). For \(k[J_{j}]\), we treat \(_{k}^{(j)}\) as a random variable generated from the following prior hierarchy:

\[_{k}^{(j)} (_{nj}),\] (4a) \[_{k}^{(j)}|_{k}^{(j)} _{k}^{(j)}_{1}(_{k}^{(j)};_{nj}^{2})+(1 -_{k}^{(j)})_{0}(_{k}^{(j)};c_{nj}_{nj}^{2}),\] (4b)

where \(_{k}^{(j)}\{0,1\}\) indicates whether or not \(_{k}^{(j)}\) is nonzero, \(c_{nj}\) is specified as a very small positive number, \(_{nj}^{2}\) and \(c_{nj}_{nj}^{2}\) are the parameters related to the variances of distributions \(_{1}()\) and \(_{0}()\), respectively, and \(_{nj}(0,1)\) determines the ratio of the mixture distribution. As \(c_{nj} 0\)\(_{0}(^{(j)}_{k};c_{nj}^{2}_{nj})\) becomes the degenerate distribution at zero. The marginal distribution of \(^{(j)}_{k}\) is then determined by

\[^{(j)}_{k}_{nj}_{1}(^{(j)}_{k};^{2}_{nj})+(1- _{nj})_{0}(^{(j)}_{k};c_{nj}^{2}_{nj}),\] (5)

which is presented as \(^{(j)}()\) for short; and this is taken as the prior distribution of \(^{(j)}_{k}\).

To further incorporate the effects of the true label information and the randomness from different annotators in (3), we place the following probabilistic structure on the generic weights for \(^{(r)}_{0}\) and \(^{(k)}_{0}\) in (3), \(^{(r)}=(^{(r)}_{1},...,^{(r)}_{K})\) and \(^{(k)}=(^{(k)}_{1},...,^{(k)}_{K})\):

\[^{(r)}_{j}(,^{(r)}_{}) ^{(k)}_{j}(,^{(k)}_{}).\] (6)

for \(j,k[K]\) and \(r[R]\), where \(^{(r)}_{}\) and \(^{(k)}_{}\) are nonnegative definite matrices. We use \(^{(r)}_{A}()\) and \(^{(k)}_{B}()\) to denote the prior distribution of \(^{(r)}\) and \(^{(k)}\) in (6). Here the regression weights \(^{(r)}\) and \(^{(k)}\) can be seen as fully connected layers on top of \(_{1}(;^{(1)})\) and \(_{2}(;^{(2)})\), respectively. The conditions on the aforementioned priors are given in Appendix A.3.

Prior and posterior probability measure.Let \(=(^{(1)},^{(2)},( ^{(1)})^{},,(^{(K)})^{},.\)

\(.(^{(1)})^{},,(^{ (R)})^{})^{}\) stand for the vector of all involved parameters in the noise transition model, with \(\) denoting the parameter space. We use \(_{0}\) to represent the true value of \(\), which is an interior point of \(\). The foregoing specification of the prior distribution places a prior probability measure, denoted \(()\), on \(\). With the data \(}_{0}\), the posterior probability measure \((|}_{0})\) is given by

\[(G|}_{0})=p^{n}_{}( {}_{0})d()}{_{}p^{n}_{}( }_{0})d()}G,\] (7)

where \(\) is the \(\)-field on \(\), and \(p^{n}_{}\) is the joint probability density or mass function for the observations in \(}_{0}\) under \(\). Let \(^{n}_{}()\) denote the probability measure associated with \(p^{n}_{}()\), and write \(^{n}_{0}()^{n}_{_{0}}()\). Hence, the data \(}_{0}\) is generated from \(^{n}_{0}()\) in our setup.

Let \(f\) denote the unknown density of \(\). For \(\{,}\}}_{0,k}\), let \(f^{(k,r)}_{0}\) and \(f^{(k)}_{0}\) respectively represent the underlying true distributions for \(^{(r)}\) and \(}\), given \(\{=k,\}\), determined by (2) and (3); and let \(f^{(k,r)}_{}\) and \(f^{(k)}_{}\) denote the corresponding distributions characterized by the model indexed by \(\). We let \(p_{,i}}(k_{i})}{f}\) denote the probability density or mass function of the \(i\)th component in \(}_{0}\) under \(\), with \(k_{i}[K]\) denoting the class that the instance belongs to almost surely. Then, the joint probability density or mass function \(p^{n}_{}\) is calculated as \(p^{n}_{}_{i=1}^{n}p_{,i}\). The following theorem describes the closeness of the proposed noise transition model and the true annotator confusions with respect to the Hellinger distance within the Bayesian framework.

**Theorem 1**.: _Suppose Conditions A.1-A.4 in Appendix A.2 and B.1-B.3 in Appendix A.3 are satisfied. Let \(d(,)\) and \(d_{n}(,)\)denote the Hellinger distance given in Definition 1 and the semimetric defined in (16) in Appendix B.1, respectively. Then there exists a sequence of constants \(\{^{2}_{n}\}_{n=1}^{}\) with \(^{2}_{n}=O(_{n1}+_{n2}+_{n})\) and \((1/^{2}_{n})<n^{2}_{n}\), satisfying \(0<^{2}_{n}<1\), \(_{n} 0\) and \(n^{2}_{n}\) as \(n\), such that 2,_

\[\{:d_{n}(,_{0})>M_{n} _{n}|}_{0}\} 0\] (8)

_in \(^{n}_{0}\) probability for every \(M_{n}\), where \(\{_{jn}\}\) is a sequence of nonnegative numbers converging to 0 as \(n\) for \(j=1,2\) as given in (14), and \(\{_{n}\}_{n=1}^{}\) is a sequence given in Appendix A.3depending on the structures of \(_{1}(|^{(1)})\) and \(_{2}(|^{(1)})\) with \(_{n} 0\) as \(n\). If we further assume that \(|}_{0,k}|/|}_{0}|>_{1}\) for some positive constant \(_{1}\), with \(||\) representing the cardinality of a set, then for any \(k[K]\) and \(r[R]\)_

\[\{:d(f_{}^{(k,r)},f_{0}^{(k,r)})>M_{n} _{n}|}_{0}\} 0,\] (9)

_in \(_{0}^{n}\) probability for any \(M_{n}\)._

Intuitively, Theorem 1 reveals that the sparse noise transition model is close to the underlying true transition matrix with respect to the Hellinger distance under mild conditions. Notably, our posterior consistency result extends the existing theories in sparse Bayesian learning  to the setup of i.n.i.d observations. Moreover, this result on the convergence rate of the posterior measure allows us to infer the underlying true label from the noisy annotations with a theoretical guarantee on the bounds of the Bayes error, which will be discussed in detail in the following section.

### Pairwise likelihood ratio test for label correction

The asymptotic result (9) in Theorem 1 indicates that for each annotator, the underlying true instance-dependent transition matrix can be accurately modeled under the Bayesian framework. This enables us to aggregate and infer the ground truth label from noisy crowdsourced annotations.

A novel label correction algorithm.To highlight the idea, we first assume that the noise transition matrix \((}^{(r)}|y=k,)\), or \(f_{0}^{k,r}()\), is known. To simplify the notation, for each \(_{i}\) in the noisy dataset \(\), denote \(_{i,k}^{(r)}_{kl}^{(r)}(_{i})(}^{(r)}=l|=k,_{i})\) for \(i[N]\) and \(k,l[K]\). We assign class prior \(_{i}=(h_{i,1},...,h_{i,K})^{}\) for the ground truth label for the \(i\)th task, where the \(h_{i,k}\) for \(k[K]\) are nonnegative weights satisfying \(_{k=1}^{K}_{i,k}=1\). For each instance, with the class prior and the noise transition matrices, the label correction process can be formulated as a hypothesis testing problem, where different hypotheses are generated from different choices of the true label values. Specifically, selecting the label for the instance \(_{i}\) from \(\{g,g^{}\}\), with \(1 g<g^{} K\), is equivalent to choosing from the two competitors \((}|y=g,_{i})\) and \((}|y=g^{},_{i})\). We thereby consider the following hypothesis testing problem: \(H_{g}:}_{i}|\{_{i},_{i}\} (}|y=g,_{i})\) versus \(H_{g^{}}:}_{i}|\{_{i},_{i}\} (}|y=g^{},_{i})\). By the Neyman-Pearson Lemma , the Bayes testing error is minimized by the likelihood ratio test, and the decision region for hypothesis \(H_{g}\) is given by

\[\{}:(}|y=g, _{i})}{h_{i,g^{}}(}|y=g^{}, _{i})}=_{r=1}^{R}_{l=1}^{K}\{_{i, gl}^{(r)}\}^{1(^{(r)}=l)}}{_{i,g^{}}_{r=1}^{R} _{l=1}^{K}\{_{i,g^{}}^{(r)}\}^{1(^{(r)}=l)} >1}\}.\]

Building from the abovementioned reformulation of the label correction process, we now propose an algorithm to infer the underlying ground truth by aggregating noisy crowdsourced annotations with the help of the annotator confusions. Formally, we propose the following label correction method by setting the estimated label of \(_{i}\) to be \(}_{i} g\) if

\[_{r=1}^{R}_{l=1}^{K}\{_{i,gl}^{(r)}\}^{ (_{i}^{(r)}=l)}}{_{i,g^{}}_{r=1}^{R}_{l= 1}^{K}\{_{i,g^{}l}^{(r)}\}^{(_{i}^{(r)} =l)}}>g^{} g,\] (10)

where \( 1\) is a pre-specified threshold.

Information-theoretic bounds on the Bayes error.To theoretically justify the effectiveness of the proposed label correction method (10), we derive information-theoretic bounds on the Bayes error, given the instances. Let \(}=\{_{i},}_{i}\}_{i=1}^{ }\) denote the collection of instances with estimated labels, where \(\) represents the size of \(}\). We write \(}=\{}_{i}\}_{i=1}^{}\) and the corresponding true label is denoted \(=\{_{i}\}_{i=1}^{}\). A loss measured by the accuracy of the estimated labels is given by \((},)=}_{i=1}^{ {n}}(}_{i}_{i})\). Let \((|;)\) denote the joint probability distribution of \(\{}_{i}\}\), given \(\) and \(\), and let \((|;)\) denote the associated expectation operator, where \(\{_{i}\}_{i=1}^{}\{_{i}^{ (r)}:\)\(r[R]_{i=1}^{}\) represents the collection of the corresponding transition matrices \(_{i}^{(r)}\) having \(_{i,kl}^{(r)}\) as its \((k,l)\) element. Then, the Bayes risk is defined as 

\[_{}(,)=_{}}[ _{[K]^{n}}()\{( {},)|;\}],\] (11)

or \(_{}\) for short, where \(()\) is the joint prior probability of \(\) calculated from \(\{_{i}\}_{i=1}^{}\). The following theorem identifies bounds for the Bayes risk.

**Theorem 2**.: _Let \(D_{{}_{KL}}(_{i,g*}^{(r)}\|_{i,g^{}*}^{(r)})\) denote the Kullback-Leibler (KL) divergence for discrete distributions \(_{i,g*}^{(r)}\) and \(_{i,g^{}*}^{(r)}\), where, for \(i[]\), \(r[R]\), and \(g,g^{}[K]\), \(_{i,g*}^{(r)}\) and \(_{i,g^{}*}^{(r)}\) stand for the \(g\)th and \(g^{}\)th rows of \(_{i}^{(r)}\), respectively. For \(=\{_{i}\}_{i=1}^{}\) and \(=\{_{i}\}_{i=1}^{}\), define_

\[_{{}_{KL}}(,)=}_{i=1}^{ }_{r=1}^{R}_{g=1}^{K}_{g^{}=1}^{K}_{i,g}h_{i,g^{ }}D_{{}_{KL}}(_{i,g*}^{(r)}\|_{i,g^{}*}^{( r)})\]

\[C_{gg^{}}^{(i)}=-_{0 1}[- (}{_{i,g^{}}})+_{r=1}^{R }\{_{l=1}^{K}(_{i,gl}^{(r)})^{1-}( _{i,g^{}l}^{(r)})^{}\}].\]

_For \(i\) and \(g[K]\), let \(I_{}^{(g)}(_{i},_{i})=_{g^{} g}C_{gg^{ }}^{(i)}\). Then the Bayes error defined in (11) is bounded as follows:_

\[}[1-_{{}_{KL}}(, )+}(2-_{i=1}^{}_{k[K]}_{i,k})}{\{_{i=1}^{}(_{k[K]}_{i,k})\}/}]\] \[ _{}(,)} _{i=1}^{}_{g=1}^{K}_{i,g}\{-RI_{}^{(g)}( {}_{i},_{i})\}.\]

_Remark 1_.: Theorem 2 establishes information-theoretic bounds on the Bayes error \(_{}\) for arbitrary priors \(_{i}\) with \(i[]\), which theoretically quantifies the combined impact of the prior knowledge and annotators' expertise on label accuracy using algorithm (10). The lower bound is proved in light of the concept of \(f\)-informativity , and is stronger than the commonly-used Bayes lower bound based on Fano's inequality . The proof of the upper bound considers the inference procedure of \(}\) and applies Markov's inequality. The details are given in Appendix B.

_Remark 2_.: The quantity \(C_{gg^{}}^{(i)}\) in Theorem 2 reflects how the identified upper bound of the Bayes error may be influenced by the prior \(_{i}\) and the ability of the \(R\) annotators to distinguish between labels \(g\) and \(g^{}\) for instance \(i\). If we set \(_{i}\) to be the uniform prior and let \(=1\), \(C_{gg^{}}^{(i)}\) will degenerates to the average of the Chernoff information between \(\{_{i,g*}^{(r)}\}_{r=1}^{R}\) and \(\{_{i,g^{}*}^{(r)}\}_{r=1}^{R}\), which is a statistical divergence measuring the deviation between two probability distributions.

Result under the sparse Bayesian model.The label correction method (10) is not immediately applicable if we have no access to the underlying true annotator confusions, which is usually the case in real-world applications. To get around the issue induced from the unknownness of the true noise transition probability \(f_{0}^{(k,r)}\), we consider the model \(f_{}^{(k,r)}\) given in Theorem 1 and write the corresponding transition matrices as \(_{i,kl}^{(r)}_{kl}^{(r)}(_{ i}) f_{}^{(k,r)}(|_{i})_{=l}\) for \(k,l[K]\) and \(r[R]\). We then replace the \(_{i,gl}^{(r)}\) in (10) with \(_{i,gl}^{(r)}\) to determine corrected labels. With a slight abuse of notation, we still use \(}=\{_{i},_{i}\}_{i=1}^{}\) to denote the set of instances with estimated labels but let \(_{}\) denote the resulting Bayes error. We let \(}_{}=\{_{i}\}_{i=1}^{}\) represent the set of the considered instances. Combining Theorems 1 and 2 yields the following corollary.

**Corollary 3**.: _Suppose that the conditions in Theorem 1 are satisfied, and further assume that \(f(_{i})>_{2}\) for \(_{i}}_{}\) and \(_{r[R],i[],k,l[K]}_{i,kl}^{(r)} _{3}\), where \(f()\) is the probability density function of \(\), and \(_{2}\) and \(_{3}\) are some positive constants. Then, for any \(>0\),_

\[[:_{}}_{i= 1}^{}_{g=1}^{K}_{i,g}\{-RI_{}^{(g)}(_ {i},_{i})+\}|}_{0}|  1\]

_in \(_{0}^{n}\) probability as \(n\), where \(I_{}^{(g)}(_{i},_{i})\) is given in Theorem 2 for \(i[]\) and \(g[K]\)._

## 4 Algorithm

Learning the noise transition model.In the warm-up stage, we train the base models on noisy training data and obtain the set of anchor points \(}_{0}\). With \(}_{0}\), we first obtain the maximum a posteriori (MAP) estimate of network parameters of the transition model \(\) by maximizing the log posterior distribution of \(\), with the constant term omitted,

\[}=_{}\{_{i=1}^{n} p_{ {},i}+()\},\] (12)

where \(p_{,i}\) is the probability mass function of the \(i\)th component in \(}_{0}\) given before Theorem 1, and \(()\) is the probability density function of \(\) relative to the prior probability measure \(()\). Given the MAP estimate \(}\), according to the prior hierarchy (4), the posterior inclusion probability of the \(k\)th parameter in the network \(_{j}(;^{(j)})\) is calculated as

\[(_{k}^{(j)}=1|})=_{1 }(_{k}^{(j)};_{nj}^{2})}{_{nj}_{1}(_{k}^{(j)};_{nj}^{2})+(1-_{nj})_{0}(_{ k}^{(j)};c_{nj}_{nj}^{2})}\] (13)

for \(k[J_{j}]\) with \(j=1,2\). If the posterior inclusion probability is smaller than a pre-specified threshold, chosen to be 0.5 in our experiments, the associated parameter is zet to be zero. We then fine tune the sparse network and obtain the noise transition model.

Training the classifiers with corrected labels.With the noise transition model trained, we then train the base models with the label correction algorithm proposed in Section 3.3. Specifically, we train two base classifiers to reciprocally provide class priors for each instance in the label correction process. In the \(t\)th epoch, for instance \(_{i}\), if \(_{i}\) satisfies the condition (10) for the pre-specified threshold \(_{t}\), we put \(\{_{i},_{i}\}\) in \(_{t}\). The base models are then updated on the collected dataset \(_{t}\). The complete pseudocode of our algorithm is included in Appendix C.

## 5 Experiments

Datasets.We assess the effectiveness of our method on three image datasets with synthetic annotations, MNIST , CIFAR-10 , and CIFAR-100 , and two datasets with human annotations, CIFAR-10N  and LabelMe . Detailed information can be found in Appendix C. For all the datasets except LabelMe, we leave out 10% of the training data as a noisy validation set.

Noise generation.For the three datasets, MNIST, CIFAR10, and CIFAR100, we consider three groups of annotators with varying expertise, with an average labeling error rate of about 20%, 35% and 50%, respectively. We abbreviate these three groups as IDN-LOW, IDN-MID, and IDN-HIGH, which represent instance-dependent annotators with low, middle ("mid" for short), and high labeling error rates, respectively. To generate noisy annotations, we independently simulate \(R=5\) annotators for each group according to Algorihtm 2 in , with IDN-\(\) denoting that the noise rate is upper bounded by \(\) for each annotator. For each instance, we then randomly choose one of the annotations given by the \(R\) annotators, which is designed to evaluate the methods under incomplete annotator labeling. We manually corrupt the three datasets according to the following three groups of annotators:

**(I) IDN-LOW.**_IDN-10%, IDN-10%, IDN-20%, IDN-20%, IDN-30%;_

**(II) IDN-MID.**_IDN-30%, IDN-30%, IDN-40%, IDN-40%, IDN-50%;_

**(III) IDN-HIGH.**_IDN-50%, IDN-50%, IDN-60%, IDN-70%._Experiment setup.The network structure for the MNIST dataset is chosen to be Lenet-5 . We choose ResNet-18  for CIFAR-10 and CIFAR-10N, and ResNet-34 architecture  for CIFAR-100 dataset. As in , we employ the pretrained VGG-16 network followed by a fully connected layer and a softmax output layer for the LabelMe dataset, using 50% dropout. More implementation details can be found in Appendix C.

Competing methods.We compare the proposed method with the following state-of-art methods: (1) CE (Clean), which trains the network with the standard cross entropy loss on the clean datasets; (2) CE (MV), which trains the network using the labels from majority voting; (3) CE (EM) ; (4) DoctorNet ; (5) GCE ; (6) Co-teaching ; (6) Co-teaching+ ; (7) BLTM ; (8) MBEM ; (9) CrowdLayer ; (10) TraceReg ; (11) Max-MIG ; (12) CoNAL ; (13) GeoCrowdNet (F) ; and (14) GeoCrowdNet (W) . Among these methods, GCE, Co-teaching, Co-teaching+, and BLTM are strong baselines dealing with single noisy label issues, and we adapt them to the multiple annotations setting by utilizing the majority vote labels for loss computation.

Ablation study.In Figure 1, We plot the average estimation error for the noise transition matrices to demonstrate the effectiveness of the proposed method in modeling the instance-dependent annotator confusions. For instance \(_{i}\) with clean class label \(_{i}\) in the validation set, we analyse the \(_{i}\)th row rather than the whole noise transition matrix as in previous studies [16; 12]. Specifically, let \(^{(r)}(_{i})\) and \(^{(r)}(_{i})\) represent the estimated and the true noise transition matrix for annotator \(r\), respectively. The estimation error on instance \(_{i}\) is defined as \(err_{i}^{(r)}=_{l K}|^{(r)}(_{i})_{ _{i},l}-^{(r)}(_{i})_{_{i},l}|\), where \(^{(r)}(_{i})_{_{i},l}\) and \(^{(r)}(_{i})_{_{i},l}\) stand for the \((_{i},l)\) element in the corresponding matrices. The average estimation error for annotator \(r\) is then calculated as \(}_{i=1}^{n_{v}}err_{i}^{(r)}\) with \(n_{v}\) denoting the size of the validation set. For each annotator, we compare the average estimation error of the proposed method with six baselines, CrowdLayer , TraceReg , GeoCrowdNet (F) , GeoCrowdNet (W) , MBEM , and BLTM , on the CIFAR10 dataset. In most of the cases, the proposed method leads to smaller estimation error especially when the noise rate is high, which shows the efficacy of the proposed sparse Bayesian model.

Figure 1: Average estimation error of annotator-specific instance-dependent noise transition matrices on CIFAR10. The error bar for standard deviation has been shaded.

Figure 2: Average accuracy of learning CIFAR-10 dataset with varying number of annotators. The error bar for standard deviation has been shaded.

Classification accuracy.Table 1 presents the average test accuracy of 5 random trials on the datasets of CIFAR-10, CIFAR-100, CIFAR-10N and LabelMe, together with the standard errors of the test accuracies of the random trials, expressed after the plus/minus sign \(\), where the two highest accuraries are bold faced; standard errors of the accuracies are calculated based on repeating those experiments 5 times, each with a different random seed. All the results demonstrate the superior performance of the proposed method on both synthetic and real-world noisy datasets. Moreover, to investigate the influence of the sparsity of annotations, we conduct more experiments with the number of annotators varying from 5 to 100, and each instance only has one label. Figure 2 shows the average accuracy with various numbers of annotators, which further exhibit the advantages of the proposed method under different settings. Additional experimental results, including the test accuracy on MNIST, the average estimation error on MNIST and CIFAR100, and the accuracy of the corrected labels using algorithm (10), are deferred to Appendix C to save space.

## 6 Conclusion

In this paper, we address the challenge of training classifiers using noisy crowdsourced labels, a common issue in various applications. We formulate the annotator-specific instance-dependent noise transition matrix within the Bayesian framework, and theoretically characterize the closeness of the proposed model and the true annotator confusions with respect to the Hellinger distance. Our result is established for the setup of i.n.i.d. observations, which substantially broadens the application scope of our method. Building on the convergence rate of the posterior measure, we propose a novel algorithm to aggregate noisy annotations and infer the ground truth label based using pairwise LRT. Additionally, we provide information-theoretic bounds on the Bayes error of the proposed algorithm. Empirical evidence demonstrates the effectiveness of our algorithm on both synthetic and real-world noisy datasets.

## Limitations and Extensions

Our work can be further extended in different directions. It is interesting to generalize the setup here to the hierarchical classification setup. Instance-dependent transition matrices can be further refined with varying structures imposed and are learned with manifold regularization.