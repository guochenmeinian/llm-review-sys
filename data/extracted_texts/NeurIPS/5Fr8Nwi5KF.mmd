# We utilize a neural network model (\(nn_{\theta}\)) to learn about \(p_{\theta}\left(\bm{x}_{t-1}^{i}\mid\bm{x}_{t}^{i}\right)\) and estimate \(q\left(\bm{x}_{0}^{i}\mid\bm{x}_{t}^{i}\right)\). The detailed design of \(nn_{\theta}\) will be elaborated later in Section 3.4.

Diffusion Model for Graph Inverse Problems: Towards Effective Source Localization on Complex Networks

Xin Yan\({}^{1,*}\) Hui Fang\({}^{2,*}\) Qiang He\({}^{1,}\)

\({}^{1}\)College of Medicine and Biological Information Engineering, Northeastern University, China

\({}^{2}\)RIIS & SIME, Shanghai University of Finance and Economics, China

yanx_in@outlook.com,fang.hui@mail.shufe.edu.cn,heqiangcai@gmail.com

Equal contribution. Corresponding author.

###### Abstract

Information diffusion problems, such as the spread of epidemics or rumors, are widespread in society. The inverse problems of graph diffusion, which involve locating the sources and identifying the paths of diffusion based on currently observed diffusion graphs, are crucial to controlling the spread of information. The problem of localizing the source of diffusion is highly ill-posed, presenting a major obstacle in accurately assessing the uncertainty involved. Besides, while comprehending how information diffuses through a graph is crucial, there is a scarcity of research on reconstructing the paths of information propagation. To tackle these challenges, we propose a probabilistic model called DDMSL (Discrete Diffusion Model for Source Localization). Our approach is based on the natural diffusion process of information propagation over complex networks, which can be formulated using a message-passing function. First, we model the forward diffusion of information using Markov chains. Then, we design a reversible residual network to construct a denoising-diffusion model in discrete space for both source localization and reconstruction of information diffusion paths. We provide rigorous theoretical guarantees for DDMSL and demonstrate its effectiveness through extensive experiments on five real-world datasets.

## 1 Introduction

Information diffusion is a pervasive phenomenon in our daily lives. Data scientists have conducted extensive research on information diffusion along the direction of entropy increase, such as maximizing the influence of nodes in social networks [15; 3], and developing control policies to curb the scale of epidemics in disease transmission networks . However, merely comprehending the mechanism of forward diffusion is insufficient. When destructive information spreads across a network, it can cause huge damage on the entire system. For example, the rapid spread of rumors in social networks can cause harm to society , and the spread of computer viruses on the Internet can paralyze a system consisting of millions of users . Additionally, pandemics such as SARS and COVID-19 in human interaction networks pose serious challenges to human health and social functioning . Therefore, accurately identifying the sources of transmission and cutting off their possible transmission paths in time is crucial. This can help limit the spread of negative information and maintain the stability of the network.

Common information dissemination models like SIR (Susceptible-Infected-Recovered) and SI (Susceptible-Infected)  are subject to uncertainties during the process of information diffusion. As illustrated in Figure 1, the diffusion graph of information should follow a non-explicit distribution, implying that a single diffusion source may correspond to multiple different diffusion graphs, and a diffusion graph may have multiple different diffusion sources. Therefore, the inverse problem of information diffusion is underdetermined.

Previous source localization research has primarily relied on manually formulating rules to filter source nodes, such as using Jordan centrality  to locate multiple source nodes in SI model, or unbiased intermediary centrality to identify source nodes in SIR model . Besides, IVGD  exploited fixed point theorem for source localization of IC model . However, these algorithms impose **relatively strict requirements on information diffusion patterns**, which could hardly be satisfied in real-world applications. To address this issue, some algorithms  have been proposed using graph neural networks (GNN)  to learn source nodes under different diffusion models. Unfortunately, most deep learning-based algorithms ignore the underdeterminacy of information propagation and attempt to establish a direct mapping between observed data and source nodes. As a result, inference results are often deterministic and **fail to quantify the uncertainty of source localization**. In addition to source localization, **it is equally important to recover the possible propagation paths of information**. For example, when an infectious disease breaks out, it is necessary to promptly trace the virus transmission trajectory and corresponding close contacts. However, in reality, this can only be achieved by analyzing the genetic evolution tree of the virus strain , which is both time-consuming and labor-intensive. In summary, **there is a current dearth of methods that can simultaneously locate information sources and restore information propagation paths**.

Inspired by diffusion phenomena, the diffusion denoising model  has garnered significant achievements in the realm of image generation. It effectively restores the original image within a noise distribution through gradual refinement. This process bears resemblance to the challenges encountered in information reconstruction and diffusion, demanding our attention. Throughout the propagation process, the source information continually undergoes blurring, presenting an exceedingly arduous task of restoring the original source node. In this scenario, employing a diffusion model for the reverse recovery of the entire information dissemination process proves highly appropriate. However, using diffusion models to solve inverse problems in graphs presents several challenges: (1) Information diffusion occurs on non-Euclidean space graphs, making learning discrete non-Euclidean data difficult; (2) Diffusion over graphs is governed by information propagation rules that operate in non-Euclidean spaces, making it challenging to establish both the forward process and reverse inference process of information diffusion within the network; and (3) Most existing algorithms only work for specific propagation patterns, suffering from the problem of model generalization.

To address the aforementioned challenges, we propose a new framework, DDMSL2(Discrete Diffusion Model for Source Localization). DDMSL excels at source localization and reconstructing the evolution of diffusion, showing promising results across different propagation patterns. Our contributions can be summarized as follows:

Figure 1: The SIR diffusion process of information over complex networks. Distinct sources may produce identical infection graphs (\(x_{T}\)), and initiating forward diffusion from \(x_{T}\) may lead to different diffusion outcomes. The distribution of sources and forward diffusion can be represented by probability models \(P^{-1}\) and \(P\), respectively.

* We model the information diffusion process using Markov chains and demonstrate that at each moment, the state transition matrix converges, enabling us to reconstruct the information diffusion paths from any time point.
* We design a residual network block based on graph convolutional networks to approximate the information diffusion process and provide a theoretical proof for the model's reversibility.
* We propose an end-to-end framework being capable of both reconstructing the evolution of information diffusion and source localization. To the best of our knowledge, this is the first study to employ denoising diffusion models for solving graph inverse problems. Extensive experiments on five real-world datasets demonstrate its effectiveness.

## 2 Related work

**Diffusion models for inverse problems**. The diffusion denoising model [16; 29] is currently one of the best available deep generative models, which has been extensively applied in image-related inverse problems [33; 23; 34]. Previous studies have extended DP3Ms  to discrete spaces and used this work as a foundation for developing multiple generative diffusion models for graph data [14; 42]. Additionally, Stevens et al.  and Chung et al.  demonstrated that the diffusion model can solve nonlinear inverse problems. These works collectively demonstrate the effectiveness of diffusion models across different domains in addressing inverse problems.

**Localization of information sources on the graph.** To facilitate the localization of infection sources, various algorithms have been proposed [25; 52; 44; 9]. Early algorithms focused on screening source nodes by employing feature engineering. For instance, Luo et al.  identified the diffusion source by the centrality of the diffusion subgraphs, while Prakash et al.  and Zhu et al.  respectively developed NETSLEUTH and OJC algorithms based on the minimum description length of nodes and the shortest path. Wang et al.  designed a series of label propagation algorithms based on the aggregation process of information diffusion, on which Dong et al.  further improved using GCN . Recently, the proposed reversible perception algorithm IVGD based on graph diffusion  has been applied to the IC model. However, **these algorithms generally have strict limitations on diffusion patterns or network structures.** DDMIX  was the first algorithm to use a generative model for reconstructing the dissemination paths of information. It leverages a VAE (variational autoencoder) to learn the state of nodes across all time steps; however, as the number of time steps increases, the solution space of the dissemination path becomes significantly more complex, leading to low accuracy in source localization. Ling et al. later introduced SLVAE , which is also based on VAE and can efficiently localize the source node but cannot directly reconstruct the propagation paths. Current generative model-based approaches for source localization **cannot simultaneously handle the problems of source localization and reconstructing diffusion paths**.

## 3 Methodology

### Problem definition

We consider an undirected graph \(=(,)\) where \(=\{x^{1},x^{2},,x^{N}\}\) is the node set and \(\) is the edge set. Let \(=\{x_{0}^{s_{1}},x_{0}^{s_{2}}, x_{0}^{s_{m}}\}\) denote the set of initial diffusion source nodes at \(t=0\). The source nodes undergo diffusion on the graph \(\) for \(T\) time steps, governed by the diffusion pattern \(g()\), and the set of node states at time step \(t\) is denoted by \(}=\{x_{t}^{1},,x_{t}^{N}\}\) with \(x_{t}^{i}\{0,1\}^{M}\) (e.g., if \(g()\) is the SIR model, then \(M\{S,I,R\}\), where \(S,I,R\) denote susceptible, infected and recovered state, respectively). If the node \(i\), then \(x_{0}^{i}=1\), otherwise \(x_{0}^{i}=0\). We define the research problem as finding the intermediate state \(=\{},},,}\}\) that maximizes the likelihood function \(^{*}=argmax_{}^{P\{}|, \}}\), given the observed \(}\).

### Information diffusion in discrete spaces

Susceptible-Infected-Recovered (SIR) and Susceptible-Infected (SI) models  are commonly used to model diffusion phenomena in nature, such as the spread of epidemics  and rumors . In this paper, we will demonstrate our approach using the SIR model. The SIR model categorizes node states into susceptible (S), infected (I), and recovered (R) states. The S state represents individuals who are susceptible to infection, while the I state represents those who have been infected, and the R state indicates recovery from the infected state. The transition between these three states is irreversible. We assume that all nodes on the graph are homogeneous and follow the same transition process for the different states of the SIR model3:

\[\{P(x_{t+1}^{i}=I x_{t}^{i}=S)=1-_{ j}(1-_{I}^{j}(t)A_{ij}I_{j}(t))\\ P(x_{t+1}^{i}=R x_{t}^{i}=I)=_{R}^{i}(t).\] (1)

And, the SIR diffusion process can be represented using a state transfer matrix:

\[Q_{t}^{i}=1-_{I}^{j}(t)&_{I}^{i}(t)&0\\ 0&1-_{R}^{i}(t)&_{R}^{i}(t)\\ 0&0&1\] (2)

where \(Q_{t}^{i}\) denotes the state transfer matrix of node \(i\) at moment \(t\), and \([Q_{t}^{i}]_{uv}\) denotes the probability of transferring from state \(u\) to state \(v\)4. \(_{I}^{i}(t)\) and \(_{R}^{i}(t)\) denote the infection rate and recovery rate at moment \(t\), respectively. Let \([P_{S}^{i}(t),P_{I}^{i}(t),P_{R}^{i}(t)]\) to be the probabilities of node \(i\) being in three states \(S\), \(I\), and \(R\) at time \(t\), then \(_{I}^{i}(t)\) and \(_{R}^{i}(t)\) can be calculated by the following equation:

\[\{ _{I}^{i}(t)&= ^{i}(t+1)-P_{I}^{i}(t)(1-_{R}^{i}(t))}{P_{S}^{i}(t)}=1- {P_{S}^{i}(t+1)}{P_{S}^{i}(t)}\\ _{R}^{i}(t)&=^{i}(t+1)-P_{R}^{i}(t)}{P _{I}^{i}(t)}.\] (3)

**Theorem 3.1**: _Given graph \(\) and the infected seed set \(\), it can be determined that the state transfer matrix \(Q_{t}^{i}\) for the \(SIR\) diffusion process on \(\) converges at all times._

**Sketch of Proof**. Given \(\) and \(\), the initial state of information diffusion can be determined. Based on the SIR propagation rule, an iterative equation can be constructed for the state distribution of the nodes at any given time. Finally, \(Q_{t}^{i}\) can be calculated according to Equations 2 and 3.

Referring to Equations 2 and 3, we can readily demonstrate the convergence of the state transition matrix \(Q_{t}^{i}\) at every moment, rendering the discrete diffusion model a practicable solution . The proof is shown in Theorem3.1.

### Discrete diffusion model for source localization

#### 3.3.1 Forward process

We represent the state of node \(i\) by an one-hot vector \(_{t}^{i}^{1 M}\), and the state distribution of node \(i\) at time \(t\) is written as:

\[q(_{t}^{i}_{t-1}^{i})= {x}_{t-1}^{i}Q_{t}^{i}^{i}}^{T}( _{t}^{i};=_{t-1}^{i}Q_{t}^{i})\] (4)

Information diffusion is a Markov process that allows for inference of the node state at any given moment based on the initial state:

\[q(_{t}^{i}_{0}^{i})=_{ _{1:t-1}^{i}}_{k=1}^{t}q(_{k}^{i} _{k-1}^{i})=_{0}^{i}_{t}^{i} ^{i}}^{T}(_{t}^{i}; =_{0}^{i}_{t}^{i})\] (5)

#### 3.3.2 Reverse process

Reconstructing the information diffusion process requires backward inference of the forward process, which can be achieved through Bayesian formulation5:

\[q(_{t-1}^{i}_{t}^{i},_{0}^ {i})(_{t-1}^{i};= _{t}^{i}Q_{t}^{i^{T}})(_{0}^{i}_{t-1}^{i})}{_{0}^{i}_{t}^{i} ^{i}}^{T}})\] (6)In the absence of knowledge about \(x_{0}^{i}\), the posterior distribution \(q(_{t-1}^{i}_{t}^{i},_{0}^{i})\) becomes intractable to compute directly. As a result, we must approximate this distribution using other methods. Continuing with Bayes' theorem, we can express the posterior distribution as follows:

\[q(_{t-1}^{i}_{t}^{i},_{0}^{i})=q(_{ t-1}^{i}_{t}^{i})=_{0}^{i}}q(_{t-1}^{i},_{t}^{i},_{0}^{i})}{q(_{t}^{i})}=_{q(_{0}^{i}_{t}^{i})}q(_{t-1}^{i} _{t}^{i},_{0}^{i})\] (7)

**We utilize a neural network model (\(nn_{}\)) to learn about \(p_{}(_{t-1}^{i}_{t}^{i})\) and estimate \(q(_{0}^{i}_{t}^{i})\). The detailed design of \(nn_{}\) will be elaborated later in Section 3.4.**

\[ q(_{t-1}^{i}_{t}^{i})  p_{}(_{t-1}^{i}_{t}^{i})& =_{_{0}^{i} p_{}(_{0}^{i} _{t}^{i})}q(_{t-1}^{i}_{t}^{i},_{0 }^{i})\\ &=_{t}^{i}_{t-1}^{i})[ _{j}q(_{t-1}^{i}_{0}^{i})p_{}(_{0}^{i}_{t}^{i})]}{q(_{t}^{i}_{0 }^{i})}\] (8)

Similar to , we predict \(x_{0}^{i}\) and then use this prediction to learn the distribution of \(q(_{0}^{i}_{t}^{i})\). This approach offers several benefits. First, it leverages prior knowledge by exploiting the fact that at \(t=0\) there are only two states: susceptible and infected. This makes \(nn_{}\) easier to train. Second, locating \(x_{0}^{i}\) is a key target of our task. Finally, predicting \(x_{0}^{i}\) can help constrain errors in the information reconstruction process (Refer to Appendix C).

\[ L_{}^{i}=&_{q (_{0}^{i})}[}[q(_{T}^{i}_{0}^{i})\|p(_{T}^{i})\| .}_{L_{T}}+.\\ &._{t=2}^{T}_{q(_{t}^{ i}_{0}^{i})}[D_{}[q(_{t-1}^{i} _{t}^{i},_{0}^{i})\|p_{}(_{t-1}^{i }_{t}^{i})]]}_{L_{t-1}}-_{q (_{1}^{i}_{0}^{i})}[ p_{}(_{0}^{i}_{1}^{i})]}_{L_{0}}]\] (9)

Equation 9 presents the variational lower bound loss function of the denoising diffusion model , where \(D_{KL}\) represents relative entropy. Furthermore, as highlighted in our earlier discussion, it is crucial for us to supervise \(x_{0}^{i}\) directly. As a result, we arrive at the simplified variational lower bound loss (\(L_{simple}\)), which is denoted as:

\[L_{simple}=^{N}}(L_{vb}^{i}+_{q( {x}_{0}^{i})}_{q(_{t}^{i}_{0}^{i})} [-_{}(_{0}^{i}_{t}^{i}) ])\] (10)

#### 3.3.3 Supervision of information propagation rules

Our reconstructed information diffusion must adhere to the propagation rules of model \(g()\). During early training, the predictions of \(nn_{}\) for \(x_{t-1}^{i}\) may not be accurate enough, which could lead to violations of the propagation rules. For example, using the SIR model, if the state of node \(i\) at time \(t\) is classified as \(I\), then the state of \(i\) at time \(t-1\) can only be either \(S\) or \(I\). However, the prediction result of \(nn_{}\) may erroneously output state \(R\), resulting in the failure to calculate \(q(_{t-1}^{i}_{t}^{i},_{0}^{i})\).

To prevent violations of the propagation rules, we can take two measures: (1) In cases where the inference result of \(nn_{}\) violates the propagation rule, \(q(x_{t-1}^{i}|x_{t}^{i},x_{0}^{i})\) should be set to \(\). and (2) To supervise the training of \(nn_{}\), the propagation rule loss function \(L_{constrain}=L_{constrain1}+L_{constrain2}\) is introduced. The detailed derivations of (1) and (2) are shown in Appendix C.

\[\{L_{constrain1}=Relu(}-( )})\\ L_{constrain2}=\|(,^{(j)}-X_{t-1}^{(i)} })\|_{2}^{2},^{(i)}}^{(j)}} .\] (11)

In order to evaluate Equation 11, we must first sample \(}\) from the discrete probability distribution computed in Equation 8. To ensure gradient preservation during the sampling process, we employ the \(Gumbel\)-\(Softmax\) technique : \(} Gumbel\)-\(Softmax(q(x_{t-1}^{i}|x_{t}^{i},x_{0}^{i}))\). Equation 11 demonstrates that each node's contribution to the information diffusion process is non-negative. In summary, the constrained loss function is \(L_{constrain=}=L_{constrain1}+L_{constrain2}\), and the loss function of DDMSL is:

\[Loss=L_{simple}+L_{constrain}\] (12)

### Design of the inference model

**In this section, we discuss the design of the \(nn_{}\) in detail**. Let \(}=\{x_{0}^{1},x_{0}^{2} x_{0}^{N}\}\) and \(}=\{x_{T}^{1},x_{T}^{2},x_{T}^{N}\}\). The diffusion of information on complex networks can be modeled using the following processes [46; 43]:

\[}[]{f_{w}}[]{}}\] (13)

Within this framework, \(f_{w}\) and \(\) serve as the feature vector construction and feature propagation functions, respectively. The relationship between \(}\) and \(}\) be expressed as:\(}=(})=(f_{w}(}))\). Our research objective focuses on the inverse problem of the SIR or SI diffusion model, which entails a large number of stochastic processes. Thus, when \(=\), solving \(^{-1}\) can be extremely challenging. In the following subsections, we will explore how to construct suitable functions \(f_{w}\) and \(\) to facilitate the calculation of \(}\).

#### 3.4.1 Relationship between GCN and SIR diffusion models

According to , diffusion models such as SIR are analogous to message passing neural networks (MPNNs ), where each node's state is only updated based on the states of its neighboring nodes. However, the operational architecture must be designed to enable each node to aggregate both its own features and those of its neighbors, and update its state via nonlinear activation as shown in Equation 26. Therefore, we propose using MPNNs to remodel the SIR diffusion process. Denoting \(P_{}^{i}(t) P(x_{t}^{i}=)\) as the probability that node \(i\) is in state \(\{S,I,R\}\) at time \(t\) in the SIR diffusion process. It can be observed that this process is structurally equivalent to:

\[\{m_{}^{i}(t+1)&=&_{j N(i)}M_{t}(h( P_{}^{i}(t)),h(P_{}^{j}(t)),e_{ij})\\ P_{}^{i}(t+1)&=&U_{t}(h(P_{}^{i}(t)),m_{}^{i}(t+1) )\\ h(P_{}^{i}(t))&=&(}P_{}^{i}(t)+ }).\] (14)

where \(M_{t}\) is the aggregate function and \(U_{t}\) represents the node status update function. \(()\) is a nonlinear activation function. \(e_{ij}\) represents the edge between nodes i and j. Additionally, since \(h(P_{}^{i}(t))\) already contains nonlinear transformations, more complex forms of transformation are not necessary and \(U_{t}\) can be defined as: \(U_{t}(a,b)=a+b\). To sum up, Equation 14 can be simplified as:

\[P_{}^{i}(t+1)=h(P_{}^{i}(t))+(_{j N(i)}h(P_{ }^{j}(t)))\] (15)

We can achieve this using a residual block composed of graph convolutional networks, which allows us to easily fit the SIR model:

\[\{_{i,t}^{(0)}=(x_{i}^ {t})^{C M}\\ g()=_{g}(^{-1/2}^{-1/2} +)\\ _{,}^{()}=_{, }^{()}+(((g (_{,}^{()}))) ).\] (16)

Among them, \(\) is a linear transformation, \(_{i,t}^{(l)}\) denotes the representation of the \(l\)-\(th\) layer of the network, \(\) is the degree matrix, \(()\) and \(()\) represent spectral normalization and batch normalization, respectively. \(()\) and \(_{g}()\) are nonlinear activation functions6. In fact, \(f_{w}\) and \(^{7}\) in Equation 13 are the \((())\) and residual blocks in Equation 16.

Figure 2: Multi-layer reversible residual network.

#### 3.4.2 Reversibility of residual blocks

We now discuss the invertibility of Equation 13 as reconstructed from Equation 16. Equation 13 can be written as:

\[\{((}))=f_{w }(})=;\\ +(((g())))= +f_{}()=()=}..\] (17)

**Lemma 3.1**: _Denoting the Lipschitz constants of \(f_{w}\) and \(f_{}\) to be \(L_{w}\) and \(L_{}\), then \(L_{w}<1\) and \(L_{}<1\)._

**Sketch of Proof**. Since \(f_{w}\) and \((g())\) are spectrally normalized, their Lipschitz coefficients are less than 1 . Additionally, since the \(()\) is set to \(Mish()\), it can be determined that the Lipschitz constant of their composite function (i.e., \(f_{}\)) is less than 1.

**Theorem 3.2**: _If \(L_{w}<1\) and \(L_{}<1\), then \(}=(f_{w}(}))\) is reversible._

**Sketch of Proof**. \(}=(f_{w}(}))\) can be written as \(\{}=+}-f_{w}(})\\ =}-f_{}()..\) Since \(f_{w}<1\) and \(f_{}<1\), constructing the iteration according to the Banach fixed point theorem , \(}=(f_{w}(}))\) is invertible.

In practical applications, we typically use multiple residual blocks to form a residual network. This approach is employed to improve the receptive field of the GCN and alleviate the problem of node smoothing caused by multi-layer graph convolution. The multi-layer reversible residual network that we designed is depicted in Figure 2, where \(\) represents dropout. If the dropout rate is \(r\) and the \(i\)-th layer residual block is \(}\), then we have \(}()=(+f_{w}())\).

**Theorem 3.3**: _If \(dropout\)-\(rate=0.5\), \(L_{w}<1\), and \(L_{}<1\), the residual network \(}=(}} })(f_{w}(}))\) is reversible._

**Sketch of Proof**. Denoting this multilayer residual network as \(F\), the upper bound of \(L_{F}\) is the product of the Lipschitz constants of each function . Additionally, with a dropout rate of \(r\), the Lipschitz constants of the functions will be limited to \((1-r)\) times their original values. Using these two conclusions, we can calculate the upper bound of the Lipschitz constant of a multilayer reversible network with \(L_{F} 1\) when \(r=0.5\).

## 4 Experiments

### Datasets and evaluation metrics

**Datasets**. The diffusion of information occurs in a broad range of network types, and DDMSL was evaluated on five distinct realistic datasets: **Karate**, **Jazz**, **Cora-ML**, **Power Grid**, and **PGP**. The detailed parameters of these networks are provided in the Appendix F.2. Following previous research [43; 9; 22], we conducted SIR and SI diffusion simulations on each dataset by randomly selecting 10% of the nodes as source nodes at the initial moment, and stopping the simulation when approximately 50% of the nodes were infected8 (For PGP dataset, simulation stopped at 30% infection rate). We randomly divided each generated dataset into a training set, a validation set and a test set in the ratio of \(8:1:1\).

**Evaluation Metrics**. Our objective consists of two components: source localization and information diffusion paths recovery. The source localization task is a binary classification task, and thus evaluated using four metrics: Precision (**PR**), which denotes the proportion of nodes predicted as sources that are true sources; Recall (**RE**), which represents the proportion of actual source nodes that are correctly predicted; **F1** score, the harmonic mean of PR and RE; and ROC-AUC (**AUC**), quantifying the model's ability to classify accurately. To evaluate the performance of the recovering information diffusion paths, we adopted the Mean Squared Error (MSE) error in : \(MSE=_{t=0}^{T-1}\|}-}} \|^{2}\), where \(}\) is the ground truth. This metric is solely computed for infected nodes, with nodes in the recovered and susceptible states being marked as 0.

[MISSING_PAGE_FAIL:8]

**Reconstructing information diffusion paths**. Both DDMSL and DDMIX can reconstruct the evolution of information diffusion, but DDMIX can only recover the states of susceptible nodes (\(S\)) and infected nodes (\(I\)), whereas DDMSL can reconstruct nodes of all states. To facilitate fair comparison, we calculate MSE loss for node reconstruction in states \(S\) and \(I\), as shown in Figure 3. DDMSL consistently outperforms DDMIX on all datasets, especially in SI diffusion mode where DDMSL's average reconstruction loss is 69% lower than DDMIX's. Unlike DDMIX, which recovers the entire graph state, DDMSL allows for fine-grained node-level reconstruction.

**Additional experiments**. DDMSL represents a source detection algorithm relying on diffusion models, necessitating an assessment of its aptitude for generalization. Concurrently, we assessed its computational complexity while also incorporating experiments utilizing two real diffusion datasets. We have documented the results of these experiments in Appendix G.

**Visualization**. To further showcase the efficacy of DDMSL in solving the inverse problem of information diffusion on complex networks, we designed a visualization that demonstrates source localization and the propagation evolution process. Due to space constraints, we have presented the visualization in Appendix H.

### Ablation study

To evaluate the effectiveness of each component, we conducted ablation experiments on DDMSL in SIR diffusion mode. One essential component of DDMSL is the reversible residual network. We removed this component and replaced each reversible residual block with a GCN network, denoted as DDMSL(a). Additionally, DDMSL is also supervised by \(L_{constarin}\) on the propagation rules. The model without the propagation rule supervision module is denoted as DDMSL(b). Finally, to assess the impact of GCN (Graph Convolutional Network) in reversible residual blocks, DDMSL(c) represents the model after removing the GCN modules from residual blocks. We ran the three variants on five datasets and compared the results,

Figure 4: MSE error in ablations.

Figure 3: Comparisons of DDMSL and DDMIX on reconstructed information diffusion processes.

   &  &  &  &  &  \\ 
**Methods** & **PR** & **RE** & **FI** & **AUC** & **PR** & **RE** & **FI** & **AUC** & **PR** & **RE** & **FI** & **AUC** & **PR** & **RE** & **FI** & **AUC** & **PR** & **RE** & **FI** & **AUC** \\ 
**DDMSL** & 0.708 & 0.706 & 0.722 & 0.853 & 0.817 & 0.88 & 0.848 & 0.930 & 0.884 & 0.867 & 0.880 & 0.928 & 0.833 & 0.879 & 0.855 & 0.930 & 0.856 & 0.903 & 0.879 & 0.943 \\ DDMSL(a) & 0.264 & 0.910 & 0.379 & 0.827 & 0.254 & 0.683 & 0.367 & 0.741 & 0.277 & 0.626 & 0.384 & 0.722 & 0.459 & 0.605 & 0.522 & 0.706 & 0.366 & 0.857 & 0.513 & 0.846 \\ DDMSL(b) & 0.655 & 0.850 & 0.718 & 0.860 & 0.648 & 0.822 & 0.723 & 0.889 & 0.834 & 0.856 & 0.845 & 0.915 & 0.818 & 0.875 & 0.845 & 0.919 & 0.811 & 0.888 & 0.848 & 0.922 \\ DDMSL(c) & 0.339 & 0.185 & 0.236 & 0.592 & 0.931 & 0.111 & 0.1943 & 0.556 & 0.817 & 0.043 & 0.08 & 0.521 & 0.998 & 0.2756 & 0.432 & 0.618 & 0.997 & 0.656 & 0.792 & 0.823 \\  

Table 3: The results of the ablation study.

which are shown in Table 3 and Figure 4. As can be seen in table 3, we have these observations: (1) removing the residual module (DDMSL(a)) leads to a significant degradation in model performance, with the F1 score and AUC decreasing by 49% and 17%, respectively. Although the GCN network is also a form of MPNNs, we noticed that the output of the inference network composed of GCNs were very similar, indicating node feature oversmoothing, and further highlighting the effectiveness of the reversible residual network module; (2) \(L_{constraint}\) is also effective, which contributes to 5% and 2% performance improvement in terms of F1 score and AUC, respectively. Similar results can be obtained in Figure 4 regarding the task of reconstructing the information diffusion processes; and (3) upon the drop of the GCNs from the reversible residual network (DDMSL(c)), a noteworthy deterioration model performance was observed, manifesting as a substantial decrease in F1 scores and AUC by 59% and 32% respectively. This compellingly signifies the indispensable role of GCN in acquiring the diffusion mode of the SIR model through the process of learning. Similar results can be obtained in Figure 4 regarding the task of reconstructing the information diffusion processes.

## 5 Conclusions

In this paper, we introduced a reversible residual network block based on the relationship between diffusion phenomena and message passing neural networks, while ensuring the reversibility of the network by limiting its Lipshitz coefficient. Using this, we constructed a discrete denoising diffusion model (DDMSL) which can locate the source of graph diffusion and restore the diffusion paths. Extensive experiments on five real datasets have demonstrated the effectiveness of DDMSL and its constituent modules. Our work offers insights into how to calculate the distribution of solutions to graph diffusion inverse problems based on the information propagation laws on complex networks.

Solving the inverse problem of graph diffusion plays a crucial role in many social operations, including controlling the spread of infectious diseases, rumors, and computer viruses. It provides valuable insights on enhancing source detection performance and fills the gap in methods for recovering diffusion evolution. However, our work has some limitations. For instance, DDMSL requires the prior knowledge about propagation models, such as infection rate and recovery rate. Although we can infer these parameters from existing observation data [32; 21], it limits the application of DDMSL in situations with insufficient observations of propagation conditions. Our future research will focus on reducing the dependence of DDMSL on prior conditions.

## 6 Acknowledgement

This work was supported in part by the National Key R&D Program of China under Grant No. 2021YFC3300302, the National Natural Science Foundation of China (Grant No. 62202089, 72192832 and U22A2004), the General project of Liaoning Provincial Department of Education (Grant No. LJKZ0005), the Shanghai Rising-Star Program (Grant No. 23QA1403100), the Natural Science Foundation of Shanghai (Grant No. 21ZR1421900), and the Fundamental Research Funds for the Central Universities (Grant No. N2319004).