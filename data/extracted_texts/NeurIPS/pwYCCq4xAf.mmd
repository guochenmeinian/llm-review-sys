# DynamicsDiffusion: Generating and Rare Event Sampling of Molecular Dynamic Trajectories Using Diffusion Models

**Magnus Petersen**

FIAS

Goethe University Frankfurt

mapetersen@ias.uni-frankfurt.de

**Gemma Roig**

Goethe University Frankfurt

roig@cs.uni-frankfurt.de

**Roberto Covino**

FIAS

covino@fias.uni-frankfurt.de

###### Abstract

Molecular dynamics simulations are fundamental tools for quantitative molecular sciences. However, these simulations are computationally demanding and often struggle to sample rare events crucial for understanding spontaneous organization and reconfiguration in complex systems. To improve general speed and the ability to sample rare events in a directed fashion, we propose a method called _DynamicsDiffusion_ based on denoising diffusion probabilistic models (DDPM) to generate molecular dynamics trajectories from noise. The generative model can then serve as a surrogate to sample rare events. We leverage the properties of DDPMs, such as conditional generation, the ability to generate variations of trajectories, and those with certain conditions, such as crossing from one state to another, using the 'inpainting' property of DDPMs, which became only applicable when generating whole trajectories and not just individual conformations. To our knowledge, this is the first deep generative modeling for generating molecular dynamics trajectories. We hope this work will motivate a new generation of generative modeling for the study of molecular dynamics.

## 1 Introduction

Diffusion models Sohl-Dickstein et al.Ho et al. Song et al.  have recently emerged as a powerful approach to generative modeling, allowing for significant advances in the field of image synthesis Ramesh et al.Rombach et al.. These models can produce high-quality samples that capture the complex distributions of natural images. Early attempts to apply these models to dynamics are being undertaken for video Ho et al.  and action modeling Janner et al.Chi et al., with promising results. In the context of the molecular sciences, diffusion models have so far been used to generate ensembles of molecular conformations conditioned to thermodynamic parameters Wang et al.Arts et al.. However, their potential in the study of the dynamics of molecular systems is still unexplored. Deep learning has made outstanding contributions in the structural modeling of molecular systems Jumper et al., However, an accurate description of the dynamics is essential to understand the biological function of proteins and other molecules. Here, we make a first attempt to extend diffusion models from the generation of conformations to the whole trajectories encoding the molecule's dynamics. We show how we can take advantage of a variety of guided generation methods that allow for the targeted sampling of the dynamics of otherwise rare but important events.

Molecular dynamics (MD) simulations are physics-based simulations where the system propagates in time according to Newton's second law of dynamics on a specified energy function Dror et al.. These simulations are one of the standard methods to obtain quantitative insight into the dynamic organization of complex molecular systems. To guarantee physical accuracy and numerical stability, the integration of the dynamics must proceed in very small iterations. For instance, standard classical atomistic MD must use an integration time step of 2 fs. The disparity between the integration time step and the time scales on which interesting biomolecular events occur severely limits the potential of classical MD simulations. This limitation is particularly severe for "rare events"--many conformational reorganizations, like large conformational motions, folding, and assembly, but also binding and more general collective rearrangements-- which occur on time scales that are many orders of magnitude larger than the typical integration time steps.

Machine learning, particularly deep learning, has emerged as a promising approach to speed up and guide the sampling in simulations. Two common strategies are to either approximate the physical forces and enable larger integration timesteps by using Graph Neural Networks (GNN) Park et al.Li et al. , or to learn a coarse-grained representation of the system and its dynamics to speed up the simulation, with GNN's Husic et al.Li et al.Li et al. , or by using diffusion models Arts et al..

The guided sampling of rare events is particularly useful for systems with hindered ergodicity, i.e., where large energy barriers separate alternative metastable states. For some systems, these events occur so rarely that speeding up simulations is not sufficient. Therefore, new methodological approaches are essential to focus computational resources on sampling trajectories where the system overcomes the energy barriers. Umbrella sampling Torrie and Valleau and metadynamics Laio and Parrinello are popular techniques to compute the thermodynamic properties of a system by introducing external biases to force the system to sample low-probability regions of its configuration space. A popular method, transition path sampling (TPS) Bolhuis et al. is used to study the kinetics of rare events by generating a set of unbiased reactive trajectories using a trajectory sampling scheme. TPS and related methods Jung et al. focus the sampling on transition paths--the short segments of trajectories that overcome barriers and connect different states.

The sampling of molecular conformations using deep generative models has been explored using normalizing flow methods like Boltzmann generators Noe et al. and recently diffusion models Wang et al.Arts et al.. The latter has come to the forefront of research due to their less strict requirements for the architecture and the ease of training even on high dimensional data Song and Ermon. Recently these models have been employed to sample conformations conditional on properties like temperature Wang et al. or reaction coordinates Falkner et al. in order to sample conformations of interest, including in low-probability regions of the molecular configuration space.

Figure 1: DynamicsDiffusion is trained on molecular dynamics trajectories generated via the numerical integration of Newton’s laws of motion for a molecular system. The trained diffusion model is then a surrogate of the simulator but with added properties of speed and steerability. This steerability allows for the sampling of rare events, like state transitions, that are crucial to the understanding of molecular systems but are often not or rarely observed in conventional simulations.

Here, we present an approach that builds on diffusion models to generate whole dynamic trajectories of molecular systems. Diffusion models have been successfully applied to learn time series data, in the form of action planning Janner et al.Chi et al., and molecular conformations Arts et al.Wang et al.. In essence, we train a surrogate of the physical integrator using a diffusion-based generative model that can perform enhanced sampling and generate trajectories of interest. This combines two promising research directions, both learning the integrator and sampling rare events using deep learning. Our approach presents two very attractive features. First, it enables us to speed up the sampling of the system's dynamics. Second, diffusion models offer ways of controlling the sampling absent from classical physical simulators.

We can take advantage of these properties to generate trajectories conditionally. Once our surrogate diffusion model is trained, we can: 1. Generate trajectories that are conditioned to a global parameter, like temperature; 2. Generate trajectories crossing the barrier between states by leveraging the 'inpainting' ability of diffusion modelsSong et al. Song et al. Chung et al.Lugmayr et al.. By fixing the start and end points of the trajectory in distinct states and allowing the model to fill in the transition, rare-event enhanced sampling becomes possible. 3. Generate an ensemble of (reactive) trajectories by partially noising and denoising them.

### Contributions

* We demonstrate the ability of diffusion models to learn to generate molecular dynamics trajectories and propose an architecture suitable to the properties of this specific task.
* We show how this approach enables rare event enhanced sampling, the generation of variations in trajectories, the ability to generate transition paths between states, and conditional generation.
* We test the model by training it on a molecular system and show that it is able to reconstruct free energy and dynamics accurately.

## 2 Diffusion Generative Modelling for Trajectories

### Molecular Dynamic Trajectories as a Datatype

In this section, we introduce the notation for the training data. Let \(=\{x_{i}\}_{i=1}^{K}\) represent the dataset of trajectory snippets sampling an unknown (non-normalized) probability density \(p(x)\), where \(x_{i}\) denotes the \(i\)-th training sample. Each sample is a trajectory of \(\) time steps, where \(\) is sampled uniformly from the range \([_{min},_{max}]\) to aid multi-length generation at inference. This is equivalent to the ordered set, \(x_{i}=\{R_{}^{(i)}\}_{i=1}^{}\), where \(R_{}\) is a configuration of the system at time step \(\). For a molecular system consisting of \(N\) atoms, we can define a configuration as the set of Cartesian coordinates for each atom in the molecule, \(R_{}^{N 3}\), with each entry corresponding to a coordinate of an atom.

To represent the training data as a batch array, with batch size \(b\), with shape (\(b\), \(\), \(N 3\)), we first organize the trajectory snippets into batches. Let \(=\{_{k}\}_{k=1}^{b}\) denote a batch, where \(_{k}=\{_{i}^{(k)}\}_{i=1}^{K}\) represents the \(k\)-th set of trajectory snippets.

Each trajectory snippet \(_{i}^{(k)}\) consists of \(\) time steps with \(N\) atoms and their respective three-dimensional coordinates, however, the model can also be trained for multiple snippet lengths, to allow for the generation of trajectories of multiple lengths. The complete data array for a batch \(\) can then be represented as \(A^{b N 3}\). Each array entry corresponds to a specific trajectory snippet, time step, and Cartesian atomic coordinate. The final data can be treated equivalently to an image in image diffusion models where the time dimension corresponds to the image width, albeit of a very wide shape due to the long time dimension.

### Diffusion Model Theory Design Choices

Diffusion-based generative models have been independently formulated multiple times under different theoretical frameworks Sohl-Dickstein et al., Song et al.  and Ho et al. . To illustrate the relationship of the trained diffusion model with the forces of a physical system, we will introduce the score-matching interpretation since it makes this relationship apparent and highlights how it can be used to introduce an inductive bias into the diffusion model's architecture. In this formulation, the model learns to approximate the score \(_{x}(p(x))\) instead of learning the distribution of the data \(p(x)\) directly, avoiding the calculation of the normalization constant of \(p(x)\), which is usually intractable. The score can be seen as a vector pointing toward the dense regions of the data distributions. Given the score, we can sample data points using an iterative sampling scheme based on Langevin dynamics Song et al. :

\[x_{i+1} x_{i}+_{x}(p(x))+z_{i},i=0, 1,...,K\] (1)

Here \(z_{i}\) is noise sampled from \((0,I)\) and if \(K\) and \( 0\) we sample one \(x_{k}\) from \(p(x)\). However, the estimation of this score is inaccurate in regions of low density in the data and even if approximation was possible the sampling would be inhibited by local minima, making sampling impossible. To counteract this limitation the model is trained to estimate the score of the data distribution at different levels of added noise, and conditioning the model on the noise level Song and Ermon. Adding noise to the data makes the data density more uniform, allowing for a more accurate score estimation. When sampling with this conditioned model the Langevin dynamics become annealed, decreasing in noise level at each step, all a sample from the non-noised data distribution is obtained. After the introduction of the noise levels, this framework becomes functionally equivalent to the DDPM approach described in the appendix section 'The noising and de-noising process'.

Design ChoicesWhen understanding the diffusion model under this framework Arts et al. show that a model trained on conformations of physical systems, \(R_{}^{(i)}\) and their equivalents along the noising process \(R_{,t}^{(i)}\), approximates the force-field of that system at that noise level. At noise level \(t=0\) this corresponds to the forces of the non-noised conformations, i.e. the original physical system generating the training data.

\[Model(R_{,t=0}^{(i)},t=0)_{R_{,t=0}^{(i)}}(p_{0}(R_{,t= 0}^{(i)}))=^{(i)})}{k_{}T}=^{(i)}}}{k_{}T}\] (2)

This follows since the distribution of a physical system's states is given by the Boltzmann distribution:

\[p(R_{}^{(i)}) e^{-^{(i)})}{k_{}T}}\] (3)

Based on this interpretation the diffusion model corresponds to the forcefield of the system. Conservative forces in physical systems are such that the work done by a particle moving between two points is the same irrespective of the path taken. This property is not satisfied by a basic UNet architecture Ronneberger et al. which is commonly used for images. However, it can be built in as an inductive bias by computing the forces as the gradient of an energy function, \(- V(R_{}^{(i)})=F_{R_{}^{(i)}}\) Arts et al.

Figure 2: The model’s architecture extends the conventional UNet to one with a physics-informed inductive bias.

per construction. Including this bias led to more accurate reconstructions of trajectories in our work (see ablations).

In this work, we extend the inductive bias from individual conformations \(R_{}^{(i)}\) Arts et al. to trajectories \(_{i}\). We implemented this by outputting one channel per time step meaning the UNet part of the model transforms one batch \(\) of shape \(^{b N 3}^{b}\) which can be interpreted as outputting a singular energy value per conformation \(V_{R_{}^{(i)}}\). These energies then get summed to a singular trajectory-level energy \(V_{x_{i,i}}\). From this energy, we can then recover the forces of the same shape as the input by computing the Jacobian with respect to the model's input \(- V_{x_{i,1}}\) 2. Based on the success of UNet models with 1D-convolutions for time-series generation in the context of action planning Janner et al., we chose a similar architecture for our study, which additionally included self-attention layers Vaswani et al.. For the embedding of additional conditioning, such as temperature, we used a small multilayer perceptron, MLP, adding the embedding in each of the ResNet blocks.

### Enhanced Sampling Methodology

There are two different approaches to enhanced sampling via Dynamics diffusion, one based on inpainting and the other one based on variation generation. The inpainting variant works by imposing a few selected frames that the diffusion model must include during the generation of a trajectory. The variation approach works by taking an existing trajectory (or pseudo-trajectory, like a linear interpolation), partially noising it, and then denoising it with the diffusion model, in this way creating variations of the original trajectory. How close to the original trajectory the variation should be can be determined by the amount of noise that is added before denoising it.

Where \(_{t}\) is the parameter that defines the noise schedule, i.e. the weighted mean between the data and noise at the noise level \(t\), \((x_{t},t)\) is the noise level conditioned noise prediction network or alternatively the learned gradient of the data when considered from the score matching perspective, and \(_{t}\) is the standard deviation of the noise at noise level \(t\).

```
1:\(x_{T}(0,I)\)\(\) Sample a noise vector
2:select \(x_{},_{}\)\(\) Select the frames that are imposed and their index/location
3:for\(t=T,...,1\)do\(\) Iterate through all noise levels t
4:\(z(0,I)\) if \(t>1\), else \(z=0\)\(\) Sample a noise vector for the denoising operation and the noising of the inpainting condition
5:\(x_{t}[_{}]=}x_{}+ }z\)\(\) Noise the imposed frames and insert them
6:\(x_{t-1}=}}(x_{t}-}{ }})(x_{t},t)+_{t}z\)\(\) Perform one denoising step
7:endfor
8:Return\(x_{0}\) ```

**Algorithm 1** Inpainting Generation

```
1:\(x_{T}(0,I)\)\(\) Sample a noise vector
2:select \(x_{}\)\(\) Select a sample to generate variations of
3:select \(t_{}\)\(\) Select a noise level to noise the variation sample to
4:\(x_{t_{}}=}}}x_{}+ }}}x_{T}\)\(\) Noise \(x_{}\) to noise level \(t_{}\)
5:for\(t=t_{},...,1\)do\(\) Iterate through all noise levels after \(t_{}\)
6:\(z(0,I)\) if \(t>1\), else \(z=0\)\(\) Sample a noise vector for the denoising operation
7:\(x_{t-1}=}{}}(x_{t}-}{ }})(x_{t},t)+_{t}z\)\(\) Perform one denoising step
8:endfor
9:Return\(x_{0}\) ```

**Algorithm 2** Variation Generation

Experiments

We first illustrate our method on a benchmark system, defined by Brownian dynamics of a particle in a 2-dimensional energy function. We prepared a training set by generating trajectory snippets with a physical simulator and trained a surrogate Diffusion Model to reproduce the original physical dynamics.

We then demonstrated the enhanced sampling capabilities of the model, as compared to the physical simulator, in the form of conditional generation, generation using constraints on the trajectory, and the generation of variations of trajectories. We then showcased our approach on a benchmark molecular system, namely Alanine Dipeptide.

Lastly, we performed an ablation study to highlight the importance of the energy formulation, and the self-attention layers, and to study the quality and quantity of the training set produced by the physical simulators necessary to produce accurate results. The appendix section 'Experimental Settings' contains the experimental settings, including data generation and processing, model size, training hyperparameters, and an experiment pertaining to the physical validity of the enhanced sampling trajectories.

### Brownian Motion in a Benchmark Potential

To assess the reconstruction accuracy of DynamicsDiffusion and its ability to perform rare event sampling via inpainting, variation generation, and conditional generation, we generated trajectories by simulating the dynamics of a particle in a double well under Brownian motion. This simple system recapitulates a molecular rare transition between two metastable states. We sampled trajectories integrating Brownian motion with the Euler-Maruyama integrator on the energy \(V(x,y)=-9x^{2}+x^{3}+4.5x^{4}+3y^{2}\), setting the system's temperature at \(k_{}T=1\) for the unconditioned experiments, and in a range from \(0.5\) to \(1.5\) for the temperature-conditioned experiments.

After training the diffusion model, we systematically benchmarked it by comparing the thermodynamics and dynamics of the reconstructed trajectories with the ones obtained by the physical integrator. Trajectories sampled by the diffusion model qualitatively behave like physical trajectories. They mostly populate the bottoms of the energy wells, and only rarely cross the barrier in between 4. Additionally, trajectories sampled by conditioning at higher temperatures explore higher energy values, as one would expect given the physics of this system. We also quantitatively assessed the accuracy of the reconstruction by comparing the stationary probability distribution explored by the trajectories sampled from the diffusion model. In our case this distribution is proportional to the Boltzmann factor, \( e^{-}^{(1)})}{k_{}T}}\), which determines the thermodynamics of the system. Both original and reconstructed distributions match quantitatively across different temperatures.

The reconstructed dynamics were also accurate, as can be assessed by comparing the auto-correlation of training data trajectories and those generated by the model (figure 3).

We also illustrated the possibility of performing enhanced sampling of rare events by sampling a transition path crossing over the barrier performing inpainting, and variations of an existing transition path 4.

Figure 3: Free energy and dynamics comparison.

### Molecular System

We tested our approach on the alanine dipeptide system, a well-known benchmark in molecular simulations. Even though the system's dynamics operate over its full configuration space, significant conformational transitions are centered around the dihedral angle \(\) and \(phi\). By showing these angles in a Ramachandran plot for both the sampled and simulated trajectories, we can validate the results for this 30-dimensional system.

We simulated the molecular trajectories for the training data saving every 0.02 picoseconds. The resulting Cartesian atomic coordinates were filtered for hydrogen atoms and aligned to a reference frame to remove rotation and translation symmetries from the data.

We computed the free energy of the training data and the DDPM samples for the dihedral angles 5. We evaluated the accuracy of the reconstructed dynamics by comparing the autocorrelation of the trajectories mapped onto these two angles. The results, seen in 5, show that the model can capture the dynamics and the free energy of the system.

Figure 4: (Properties of the trajectory diffusion model) **(a) Sampling the Boltzmann Distribution**: The diffusion model is able to generate samples according to the Boltzmann distribution of the training data, including transitions. At inference, the sampling steps to generate a trajectory can be lowered from 1000 to 30 using numerical integration. **(b) Conditional generation**: The model can be trained in a conditional manner to generate samples that fulfill a condition, like a temperature or other physical properties. **(b1)** Comparison of the free energy of the model samples and the data at 0.5 \(k_{b}T\). **(b2)** Comparison of the free energy of the model samples and the data at 1.5 \(k_{b}T\).**(c) Inpainting/Spatial conditioned generation**: Another way to condition the generation of the model to perform enhanced sampling is to fix certain parts of the generated trajectories and let the model fill in the rest. This can, for instance, be used to sample state transitions by fixing the start and the end of the generated trajectory to the two states respectively, and letting the model generate the states between them. **(d) Trajectory variation generation**: The diffusion model can be used to generate similar trajectories or ’variations’ of existing trajectories or even hand-crafted faux-trajectories by partially noising the trajectory and then letting the diffusion model denoise them again. The degree of noise added to the original trajectory determines the degree of similarity to the generated variations.

### Ablation Studies

We performed ablations to see the effect of the design choices we made and to identify crucial components. To evaluate the performance of the models, we trained on the double-well potential and evaluated the free energy mismatch between samples and the ground truth along the x-axis, which was chosen as it is the reaction coordinate of the system. This mismatch was computed for 100 bins of the x-coordinate and averaged. Ablations were also performed on the size and trajectory length needed to train a good _DynamicsDiffusion_ model, which can be found in the appendix.

We train N=10 UNets with and without the energy inductive bias. The results in Table 9 show that the energy formulation outperforms the force formulation of the UNet. The same experimental setup was used to study the effect of self-attention layers in the model.

## 4 Conclusions

We proposed the first deep generative model to generate accurate trajectories of a molecular system which can serve as a useful surrogate model of the physics-based simulator, due to its enhanced sampling capabilities. One limitation of the current model it can only accurately generate trajectories for time horizons in the ranges it has seen during training. Another avenue of improvement is to generalize the method to work for any molecular system, by changing the underlying diffusion model to a GNN, thereby due to the parameter-sharing nature of the system making it system agnostic. Furthermore using new GNN architectures that are equivariant to translations, rotations, and permutations like those proposed by Satorras et al. would account for the system's inherent symmetries making learning easier. Further research can go into scaling this method to larger systems.

   Formulation & Free Energy Error k\({}_{b}T\) & Free Energy Error Transition-Region k\({}_{b}T\) \\  Energy & 0.36\( 0.19\) & 0.63\( 0.36\) \\ Force & 0.55\( 0.32\) & 0.86\( 0.67\) \\  Self-Attention \& Energy & 0.17\( 0.19\) & 0.33\( 0.19\) \\ No-Attention \& Energy & 0.34\( 0.34\) & 0.30\( 0.33\) \\   

Table 1: Energy vs force and self-attention vs attention-free model comparison

Figure 5: (Properties of the trajectory diffusion model) **(a) Dynamics Comparison**: The dynamics of the DDPM samples and the simulated samples were compared via an autocorrelation, \(\) its standard deviation, along a time lag. **(b) Free Energy Profile**: The free energy of both the model, top, and the simulated samples, bottom. **(c) Spatial conditioned generation**: Example trajectory between two states of Alanine Dipeptide generated via inpainting.