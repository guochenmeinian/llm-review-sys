# Discrete Modeling via Boundary Conditional Diffusion Processes

Yuxuan Gu\({}^{}\) Xiaocheng Feng\({}^{}\) Lei Huang\({}^{}\) Yingsheng Wu\({}^{}\) Zekun Zhou\({}^{}\)

Weihong Zhong\({}^{}\) Kun Zhu\({}^{}\) Bing Qin\({}^{}\)

\({}^{}\)Harbin Institute of Technology Peng Cheng Laboratory

{yxgu,xcfeng,lhuang,yswu,zkzhou,whzhong,kzhu,qinb}@ir.hit.edu.cn

###### Abstract

We present an novel framework for efficiently and effectively extending the powerful continuous diffusion processes to discrete modeling. Previous approaches have suffered from the discrepancy between discrete data and continuous modeling. Our study reveals that the absence of guidance from discrete boundaries in learning probability contours is one of the main reasons. To address this issue, we propose a two-step forward process that first estimates the boundary as a prior distribution and then rescales the forward trajectory to construct a boundary conditional diffusion model. The reverse process is proportionally adjusted to guarantee that the learned contours yield more precise discrete data. Experimental results indicate that our approach achieves strong performance in both language modeling and discrete image generation tasks. In language modeling, our approach surpasses previous state-of-the-art continuous diffusion language models in three translation tasks and a summarization task, while also demonstrating competitive performance compared to auto-regressive transformers. Moreover, our method achieves comparable results to continuous diffusion models when using discrete ordinal pixels and establishes a new state-of-the-art for categorical image generation on the Cifar-10 dataset.

## 1 Introduction

Discrete modeling is essential due to the natural prevalence of discreteness in numerous domains, including proteins (Madani et al., 2020, 2023), images (Parmar et al., 2018; Dosovitskiy et al., 2021), and natural language (Sutskever et al., 2014; Brown et al., 2020). Recent dominant framework for discrete modeling is the Transformer (Vaswani et al., 2017) with an autoregressive manner. While achieving impressive performance, it does suffer from a slow step-by-step generation process, especially for long sequences. Continuous Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020), on the contrary, exhibit the ability to recover high-dimensional data from noise in parallel with limited iteration steps. Although proved to be effective in continuous data generation (Rombach et al., 2022; Kong et al., 2021), they continue to encounter challenges in discrete modeling (Austin et al., 2021; Chen et al., 2023; Li et al., 2022; Gong et al., 2023).

In this paper, we reveal a significant discrepancy pertaining to the modeling of discrete data using continuous diffusion models. Current approaches represent a discrete sample with a vector point in the continuous space. The diffusion process learns a neural network to model the probability distributions that recovers this continuous point from Gaussian noise. However, the discrete data actually corresponds to an area in the continuous space rather than a single point, where the oversimplified assumption leads to a mismatch between learned probability contours and the boundary of the discrete area. Take language generation as an example, a word is represented with an embedding vector in the embedding space. To generate this word, it is impractical to strictly enforce the predicted vector to be an exact match to the embedding. On the contrary, vectors around this embedding can also generatethe same word, thereby defining the collective area they encompass as a discrete area of this word. As illustrated in Figure 1A, suppose the learned probability density function is \(p_{}()\) and two points \(^{i}\) and \(^{o}\) are sampled in the same density contour where \(p_{}(^{i})=p_{}(^{o})\). It is obvious that \(^{i}\) lies in the discrete area and is able to recover the discrete data while \(^{o}\) can not. This means that the diffusion model only learns a simplified scenario that does not match the real probability distribution.

To address the issues above, we proposed to take the boundaries of discrete areas as priors, as shown in Figure 1B, where boundary curves are regarded as oracle contours. As it gradually approaches the discrete boundary, the learned density contours of diffusion models are expected to transform from Gaussian distributions to the boundary distribution. Therefore, we propose to divide the forward process into two steps. First is the boundary estimation where we precisely calculate the stopping time \(t_{0}\) and position \(_{t_{0}}\) at which the forward trajectory cross the boundary. Then we rescale the trajectory for both training and inference stages to make the sampling probability of noisy point \(_{t}\) conditioned on the boundary. To make the boundary estimation tractable (appendix A) and eliminate randomness in conditional state transitions \(_{t_{0}}_{t}\), we utilize the Ordinary Differential Equations (ODEs) to describe the forward trajectory.

Our approach is experimented in both language modeling and discrete image generation. On three machine translation datasets (Iwslt14 de-en, Wmt14 en-de, Wmt16 en-ro) and a text summarization dataset (Gigaword) for language modeling, our proposed approach not only significantly improves existing diffusion models to at most \(7.8\%\) but also achieves competitive performance to autoregressive transformers. For image generation on Cifar-10 , our model realizes a comparable result to continuous diffusion models with discrete ordinal pixels and establishes a new state-of-the-art for categorical pixels.

## 2 Preliminaries

Diffusion ModelsTo model a real distribution \(q(_{0})\), diffusion models utilize a forward process \(p_{t}(|_{0})\) with \(T\) steps to gradually add Gaussian noise \(()=(,)\) into the data distribution, where \(p_{T}(|_{0})=()\). There are different architectures for the forward process. A common approach  considers the forward process as the Markovian process, where \(p_{t}(|_{0})=_{s=1}^{t}p_{s}(_{s}|_{s-1})\) combines a series of Gaussian distributions. Thus the forward process follows a Gaussian distribution that \(p_{t}(|_{0})=(_{t}}_{0},(1-_{t}))\) (Variance Preserving) or \(p_{t}(|_{0})=(_{0},_{t}^{2} )\) (Variance Exploding) , where noise scheduler \(_{t}\) monotonically decreases from 1 to 0 and \(_{t}\) increases from sufficiently small to the maximum pairwise distance between all training data points. To recover data from noise, diffusion processes train neural networks \(_{}(_{t},t)\) to predict \(_{0}\) (other equivalent targets include \(\) and \( p(_{t})\)) from \(_{t} p_{t}(|_{0})\):

\[_{}=_{t_{(1,T)},_{0} q (_{0}),_{t} p_{t}(|_{0})}[ \|_{0}-_{}(_{t},t)\|^{2} ].\] (1)

Samples are generated with a series of reverse state transition \(p(_{t-1}|_{t},_{}(_{t},t))\).

Flow MatchingAnother architecture  utilizes the ODEs and defines a time-dependent flow function \(_{t}()=_{t}(_{0})+_{t}(_{ 0})\) that maps \(p_{t}(|_{0})=[_{t}]_{*}()=(_{t}^{ -1}())|_{*}^{-1}()}{}|=(_{t}(_{0}),_{t}^{2}(_{0}))\), where \(_{t}\) and \(_{t}\) can be the same as in diffusion

Figure 1: (A) Blue and green curves are the learned probability density contours of the diffusion model for two data points. The red area is the discrete area of the blue data \(_{0}\) and the boundary of this area is naturally a density contour. The discrete boundary is a complex hypersurface in the high-dimensional continuous space and we simplify it into a red line for convenience of description. As observed in the magnified part, the learned contours deviate from the boundary contour, resulting in inconsistent probability densities and gradient directions. (B) We consider the discrete boundary as priors for the diffusion process to estimate a more appropriate probability distribution, where the learned contours are expected to follow the shape of the discrete boundary.

models or a more straightforward form that \(_{t}=(1-)_{0}\) and \(_{t}=\). Recovering data from noises relies on the vector field \(u_{t}(|_{0})\) that generates the probability path with the ODE \(_{T-t}()=u_{T-t}(_{T-t}()|_{0} )t,t:0 T\). Neural networks \(u_{}(,t)\) are trained to estimate the vector field \(u_{t}(|_{0})\) via the following objective:

\[_{}=_{t_{(1,T)},_{0} q (_{0}),_{T}()}[\|u_{ }(_{t}(_{T}),t)-_{t}(_{T})}{ t}\|^{2}].\] (2)

Besides, the vector field is proved to have the form:

\[u_{t}(|_{0})=^{}(_{0})}{ _{t}(_{0})}(-_{t}(_{0}))+ _{t}^{}(_{0}),t.\] (3)

## 3 Methodology

As illustrated in Figure 2, our objective is to refine the probability density contours of \(p_{t}(|_{0})\) so that they better fit the boundaries of discrete samples while still allowing for the ease of sampling. Let \(_{0}\) denote the samples from a real distribution \(q(_{0})\). Obtaining a boundary-aware corresponding noisy data \(\) at time \(t[1,T]\) is \(p_{t}(|_{0})= p_{t}(,_{t_{0}},t_{ 0}|_{0})_{t_{0}}t_{0}\), where \(t_{0}\) is a random variable distributed according to when the diffusion trajectory and the discrete boundary intersect, and \(_{t_{0}}\) is the corresponding sample point at \(t_{0}\). Then the forward process is rescaled in two steps:

\[_{t}(|_{0})=_{t}(| _{t_{0}},t_{0},_{0})}{} _{t_{0}},t_{0}|_{0})}{} _{t_{0}}t_{0},\] (4)

where the latter term is to calculate the discrete boundaries and the former term is to rescale the forward trajectory. In order to make the equation tractable and ensure that \(\) and \(_{t_{0}}\) are on the same trajectory, we model the forward process with flow functions \(_{t}()\) and extend the notation as:

\[_{t}()=(_{0},t)\;_{0}+ (_{0},t)\;, p_{t}(|_{0})=[_{ t}]_{*}()\] (5)

where \(()\) and \(()\) are coefficient functions and sampling \(_{t}\) from \(p_{t}(|_{0})\) equals to

\[_{t}=_{t}(),() =(,).\] (6)

### Estimate Discrete Boundaries

Before figuring out the joint distribution \(p(_{t_{0}},t_{0}|_{0})\), let's start by discussing how to verify whether an arbitrary point \(\) in the continuous space belongs to the discrete area of \(_{0}\). Suppose \(_{0}\), which exists in the continuous space \(S\), is the representation vector of a discrete random variable \(\) in a discrete space with \(K\) states. Besides, \(\) is another discrete random variable _i.i.d._ with \(\). We define the discrete area of \(_{0}\) in the continuous space \(S\) as:

\[C_{}=\{ S|f(,)>f(,),\},\] (7)

Figure 2: (A) Rescaled Probability Contours. The bold curve \(1\) is the density contour of one standard deviation. As the time \(t\) decreases from \(T\) to \(0\), the rescaled contours will gradually fit the discrete boundary and probability densities will also concentrate to this boundary. (B) Rescaled Forward Trajectory. Original forward trajectory \(_{0}_{t_{0}}_{}\) is rescaled to be a boundary conditional trajectory \(}_{1}}_{t}\) that starts from \(}_{1}=_{t_{0}}\). The rescaled forward distribution \(_{t}(}_{t}|_{0})\) is transformed from the discrete boundary to Gaussian distributions.

where \(f(,)\) is a function assessing the likelihood of an arbitrary continuous point \(\) inside the discrete area of \(_{0}\). For instance, in language modeling, \(K\) is the vocabulary size. \(, K^{n}\) are two different sequences of \(n\) tokens and \(_{0}^{[n,m]}\) is a sequence of \(m\)-dimensional vector embeddings for \(\). \(f(,)\) is the dot similarity function. \(C_{}\) collects all vectors in the embedding space that will be decoded to generate \(\) and excludes vectors associated with any other token sequences \(\).

Given a noisy point \(_{t_{0}}\) locating at the boundary between \(C_{}\) and \(C_{}\), we can get \(|f(_{t_{0}},)-f(_{t_{0}},)|=0\) based on previous definition. Replacing \(_{t_{0}}\) with eqs. (5) and (6), there is:

\[f(_{t_{0}}_{0}+_{t_{0}}, )=f(_{t_{0}}_{0}+_{t_{0}},).\] (8)

In language modeling and categorical images, \(f()\) is a linear projection function that:

\[_{t_{0}}(f(_{0},)-f(_{0}, ))=_{t_{0}}(f(,)-f(,)).\] (9)

Further simplification of this equation can not be universally applied to all arbitrary forms of \(_{t_{0}}\) and \(_{t_{0}}\). Therefore, we calculate separately for several commonly occurring special cases.

Diffusion ProcessFor variance preserving, there is \(_{t}^{2}+_{t}^{2}=1\) and we have:

\[_{t_{0}}=1_{0},) -f(_{0},)}{f(,)-f( ,)})^{2}}_{t_{0}}=1 ,)-f( ,)}{f(_{0},)-f(_{0},)})^{2}}.\] (10)

For variance exploding, there are \(_{t}=1\) and \(_{t}=_{t}\). We can obtain:

\[_{t_{0}}=1_{t_{0}}=(f(,)-f(,))/(f( _{0},)-f(_{0},)).\] (11)

Flow MatchingFor optimal transport, there is \(_{t}+_{t}=1\) and similarly we get:

\[_{t_{0}}=1(1+_{0},)-f( _{0},)}{f(,)-f( ,)})_{t_{0}}=1 (1+,)-f(,)}{f(_{0},)-f(_{0}, )}).\] (12)

As a result, \(t_{0}\) can be directly derived by inverting the coefficient function \(_{t}\) or \(_{t}\), which depends on the choice of noise scheduling strategies. Since their differences do not affect our results, we omit the detailed calculation (appendix E) and denote this process with a function \(G()\):

\[t_{0}=G(_{0},),( _{0},G(_{0},))=_{t_{0}} (_{0},G(_{0},))= _{t_{0}}.\] (13)

It's worth noting that \(t_{0}\) is not a scalar but a vector, where the dimension is the number of elements in \(_{0}\). If \(_{0}\) is a sequence of \(n\) tokens, \(t_{0}[1,T]^{n}\). If \(_{0}\) is a RGB image with \(3\)-channel \(\)\(h\)-height \(\)\(w\)-width of pixels, \(t_{0}[1,T]^{3 h w}\). Furthermore, the corresponding noisy sample \(_{t_{0}}\) is derived as:

\[_{t_{0}}=(_{0},G(_{0},))_{0}+(_{0},G(_{0}, ))=_{G(_{0}, {})}(),\] (14)

which is a time-independent function of the Gaussian noise \(\). It's worth mentioning that both \(p(t_{0}|_{0})\) and \(p(_{t_{0}}|_{0})\) are intractable, since \(G(_{0},)\) and \(_{G(_{0},)}()\) are not invertible to \(\). Different \(\)s can be mapped to a same \(t_{0}\) or \(_{t_{0}}\). Fortunately, there is an one-to-one mapping between \(\) and the \([_{t_{0}};t_{0}]\) pair. We denote the boundary flow function and the corresponding inversion as

\[()=[_{G(_{0},)}( );G(_{0},)],^{ 1}([_{t_{0}};t_{0}])=(_{t_{0}}-(_{0},t_{0})_{0})/(_{0},t_{0}),\] (15)

and the joint boundary distribution is calculated as

\[p(_{t_{0}},t_{0}|_{0})=[]_{*}([_{t_{0}};t_{ 0}]).\] (16)

The support set of \(_{t_{0}}\) is restricted to the boundary contour, while other regions in the space are assigned a probability of \(0\). To obtain the complete boundary, it is necessary to iterate over all possible choices of \(\) and perform pairwise comparisons with \(\). The complexity is \(O(n K)\), where \(n\) elements in \(_{0}\) is independently iterated. In practical implementation, obtaining the tightest boundary only requires one step of parallel calculation and an extra \(()\) function over all \(t_{0}\) candidates.

Confidence FactorThe discrete area defined by eq. (7) represents an ideal scenario in which the confidence of the boundary is insufficiently reliable for practical application. Due to the intractability of obtaining the probability density function across the entire discrete area and calculating its confidence interval, we employ an empirical strategy. This approach involves utilizing a confidence factor, denoted as \(r\), ranging from \(0\) to \(1\), which is multiplied by \(t_{0}\) to strike a balance between confidence and discreteness. Therefore, \(r=0\) implies the exclusion of discrete priors, causing the discrete area to collapse into a single point, which is the original diffusion process. As the value of \(r\) increases, the modeling of discrete boundaries improves at the expense of reliability. Empirically, when the model is conditioned with good guidance, setting a larger value for \(r\) allows us to obtain better discrete priors. However, in the case of unconditional modeling, maintaining reliability becomes more crucial to prevent oscillations and even collapses during training.

### Rescale the Forward Trajectory

In this section, we introduce how to formulate the forward trajectory conditioned on discrete boundaries and derive the rescaled noisy sampling distribution. We start with the boundary-independent forward process \(p_{t}(|_{0})\). Let \(_{t}\) denote a noisy point at time \(t\) sampled from \(p_{t}(|_{0})\), there is \(_{t}=(_{t}-(_{0},t) _{0})/(_{0},t)\) given eq. (5). Equations (13) and (14) provide the corresponding \([_{t_{0}};t_{0}]\) pair on the same trajectory, which is deterministically calculated with no randomness:

\[[_{t_{0}};t_{0}]=(_{t}),_{t}=(_{t}-(_{0},t) _{0})/(_{0},t).\] (17)

To model the transition probability \(p_{t}(_{t_{0}},t_{0}|_{t},_{0})\), we utilize the Dirac delta function \(()_{ 0}(, ^{2})\), which can be loosely thought of as aggregating all probability densities toward the origin, assigning an infinite density at the origin and zero densities elsewhere. Therefore, we have \(p_{t}(_{t_{0}},t_{0}|_{t},_{0})=( [_{t_{0}};t_{0}]-(_{t})).\) Then the forward process, conditioned on the discrete boundary, is simply derived via Bayes' rule:

\[p_{t}(_{t}|_{t_{0}},t_{0},_{0})=p_{t}(_{t_{0}},t_{0}|_{t},_{0})(_{t}| _{0})}{p(_{t_{0}},t_{0}|_{0})}=0, [_{t_{0}};t_{0}](_{t}) \\ +(_{t}|_{0})}{p(_{t_{0}},t _{0}|_{0})},.\] (18)

Since \(p_{t}(_{t}|_{0})>0\) and \(p(_{t_{0}},t_{0}|_{0})>0\), \(p_{t}(_{t}|_{t_{0}},t_{0},_{0})\) is also a delta function that

\[p_{t}(_{t}|_{t_{0}},t_{0},_{0})=( _{t}-(_{0},t)_{0}-(_{0},t)^{ 1}([_{t_{0}};t_{0}])).\] (19)

Based on the translation property of the Dirac delta function, i.e. \( f(x)(x-a)x=f(a)\), the original forward process \(p_{t}(_{t}|_{0})=[_{t}^{ 1}]_{ }(_{t})=[_{t}]_{}(_{t})\) naturally ignores the influence of discrete boundaries, even if the boundary information is explicitly added as a condition.

To enable the discrete priors, we propose a simple and intuitive approach: rescale the forward trajectory. As shown in Figure 2B, the original forward process flows from \(_{0}\) to a random noise \(\), and we reset the starting point to \(_{t_{0}}\). Accordingly, the intermediate noisy points \(_{t},t[1,T]\) will be proportionally mapped on this new path, which is

\[}_{t}&=_{ },=(t,t_{0})=r t_{0}+t(T-r t_{0})/T \\ &=(_{0},(t,t_{0}))_{0}+ (_{0},(t,t_{0}))^{ 1}([ _{t_{0}};t_{0}]).\] (20)

Similar to eq. (19), the rescaled conditional forward process is a Dirac delta function:

\[_{t}(}_{t}|_{t_{0}},t_{0},_{0}) =(}_{t}-(_{0},(t, t_{0}))_{0}-(_{0},(t,t_{0}))^{  1}([_{t_{0}};t_{0}])).\] (21)

However, \(_{t}(}_{t}|_{0})\) faces the same problem of irreversibility as in eq. (14) and we derive it as:

\[_{t}(}_{t}|_{0})& =_{t}(}_{t},|_{0}) =_{t}(}_{t},|_{t_ {0}},t_{0},_{0})p(_{t_{0}},t_{0}|_{t_{0}}) [_{t_{0}};t_{0}]\\ &=[_{}^{ 1}]_{}([ }_{t};])=[_{}]_{}([ }_{t};]).\] (22)

Obtaining the probability density function requires gathering together the probability densities of the same location \(}_{t}\) with different \(\), which is intractable. Fortunately, we only need to sample noisy points from this probability distribution \(}_{t}_{t}(}_{t}|_{0})\), which is easy to implement:

\[}_{t}=(_{0},(t,G(_{0},)))_{0}+(_{0}, (t,G(_{0},))), ().\] (23)
Training ObjectiveTheoretically, the diffusion neural networks can be trained as in eq.2, where the rescaled vector field is derived as \(_{t}=_{0}}{t}= }_{t}}{}}{ }}\). However, since a low error estimation on \(_{0}\) is of significant importance to our trajectory rescaling method, according to eqs.10 to 13, we convert the objective to an upper bound of the eq.2 (See appendix F for more details) and train a neural network \(_{}(}_{t},t)\) to predict \(_{0}\) directly:

\[_{}=_{_{0} q(_{0}),t _{(1,T)},}_{t}_{t}(|_{0})}[\|_{0}-_{}(}_{t},t)\|^{2} ].\] (24)

The training procedure is demonstrated in algorithm1 and key steps are summarized in the line4.

```
1:repeat
2:\(_{0} q(_{0})\), \(()=(,)\)
3:\(t(\{1,,T\})\)
4:\((t,G(_{0},))\)// eqs.13 and 20
5:\(}_{t}(_{0},)_{0}+ (_{0},)\)// eq.23
6: Take gradient descent step on \(_{}\|_{0}-_{}(}_{t},t) \|^{2}\)// eq.24
7:until converged ```

**Algorithm 1** Training

Reverse ProcessA direct approach that follows the flow matching is to solve the ODE of \(_{T-t}()=_{T-t}(_{T-t}( )_{0})t,_{T}()( )\). This form of transformation is inefficient with \(_{0}\)-prediction during inference because we have to solve the equation of \(=(t,G(_{},}_{t }-(_{},)_{}}{(_{},)}))\) to get the \(\) with respect to the change of \(}_{t}\) and \(_{}\) in real time. Therefore, we provide a deterministic reverse process as an alternative, which is a special case of DDIM  or the ODE with discrete timesteps. Given the time intervals \( t[ t_{1}, t_{s}], t=T\), we generalize the boundary conditions \([_{t_{0}};t_{0}]\) in \(_{t}(}_{t}|_{t_{0}},t_{0},_{0})\) of eq.21 and \(^{-1}([_{t_{0}};t_{0}])\) of eq.15 to any arbitrary condition pairs \([}_{t};]\) and obtain the reverse process:

\[([}_{t- t};_{}][}_{t};],}_{0})=\] (25) \[([}_{t- t} \\ _{}]-[( }_{0},_{})}_{0}+(}_{0}, _{})}\\ (t- t,G(}_{0},}) )]),\]

where \(}_{0}=_{}(}_{t},t)\) and \(_{}\) is the previous timestep of \(\) on the same rescaled trajectory.

Sampling from the reverse process is illustrated in algorithm2. Similar to the sampling process of DDIM , it starts from the Gaussian noise, iteratively predicts the pseudo target \(}_{0}\), and updates the reverse trajectory. However, since the \(\) and \(}\) are mutually conditioned, we have to keep track of the \(t\), \(\), \(}_{t}\), and \(}\) during each iteration and split the update of \(}\) into an asynchronous step (line8). Because reverse trajectory keeps changing due to different pseudo targets \(}_{0}\) predicted by learned neural networks, which brings severe instability, sometimes simply fixing the initial path (removing the line8) exhibits better performance in experiments.

```
1:repeat
2:\(_{0} q(_{0})\), \(()=(,)\)
3:\(t(\{1,,T\})\)
4:\((t,G(_{0},))\)// eqs.13 and 20
5:\(}_{t}(_{0},)_{0}+ (_{0},)\)// eq.23
6: Take gradient descent step on \(_{}\|_{0}-_{}(}_{t},t) \|^{2}\)// eq.24
7:until converged ```

**Algorithm 2** Sampling

## 4 Language Modeling

Recent diffusion language models  inherit the embedding-rounding framework that a sentence with \(n\) discrete tokens \(W=[w_{1},,w_{n}]\) is embedded to a continuous space via a trainable embedding layer \((W)=[(w_{1}),,(w_{n})]\). The vocabulary set is \(K\) that \( w_{n} K\). Besides, the token embeddings are used as the target points \(_{0}=[_{0}^{1},,_{0}^{n}]\), \(_{0}^{n}=(w_{n})\), for continuous diffusion trajectories. Hence, generating tokens from embeddings is:

\[p(W|_{0})=_{i=1}^{n}p(w_{i}|_{0}^{i})= _{i=1}^{n}_{0}^{i},w_{i}))}{_{j K}(f( _{0}^{i},j))},\] (26)

where \(f(,j)=(j)\) is the dot production distance. It's also the function assessing the likelihood of point \(\) inside the discrete area of \(j\). The coefficient functions follow the DDPM , which are \((_{0},t)=_{t}}\) and \((_{0},t)=_{t}}\). Besides, the objectives are

\[_{}=_{W,t,}_{t}}[_{ i=1}^{n}(w_{i})-_{}(}_{t}^{i},t)\|^{2}/n]\] (27)

[MISSING_PAGE_FAIL:7]

length beam \(\)\(3\) sentence beams) of our model. The reranked performance can even outperform transformers on Iwslt14 de-en and Wnt16 en-ro.

AblationOur approach is a general framework applicable to almost all continuous diffusion models, providing them with discrete boundaries as priors. We choose Difformer [Gao et al., 2022] as the base model and follow the configurations. As proved in eq. (19), the original forward process will ignore the discrete priors although explicitly demonstrated. We conduct ablation experiments on the rescaling module. As illustrated in Table 2, our approach rescales the trajectory of both forward and reverse processes on Difformer. Only rescaling the forward trajectory is also effective but sub-optimal due to the inconsistent distribution during inference. Due to computational cost and fair comparison, our method leaves room for improvement. For example, replacing the forward trajectory with optimal transport in Flow Matching, \((_{0},t)=1-t/T\) and \((_{0},t)=t/T\), achieves better performance on Wnt16.

AnalysisOur training objective, eq. (24), is an upper bound of the eq. (2). We demonstrate the influence of this approximation in Table 3 on Iwslt14 de-en to reveal the thought of our formula. On the one hand, \(_{_{0}}\) brings theoretical errors at a constant scale. On the other hand, \(_{_{0}}\) mitigates some experimental errors from the neural networks. The first row \(_{_{0}}\) is the objective we used in eq. (24) and the second row \(_{_{t}}=_{\{t,_{0},}_{t}\}}[\|_{t}(}_{t}|_{}( }_{t},t))-}_{t}}{t}\|^{2}]\) is directly derived from the eq. (2). The first two columns represent the error expectations of \(_{0}\) and \(_{t}\) on the test set. It is easy to observe that, with the dynamic coefficient \(}{}=_{0}, _{0})}{T}\) (appendix F), the value of \(_{0}\)'s error (\(8.44\)) is much larger than the \(_{t}\)'s error (\(1.56\)). Therefore, \(_{_{0}}\) is beneficial for reducing the impact of the prediction error from the neural network. The third column in Table 3 illustrates the one-step accuracy of predicting \(_{0}\) and the fourth column is the Bleu score on the test set. Experimental results show that optimizing the upper bound has a negligible impact on the final performance (only a \(0.2\%\) drop of the Bleu score), while can improve the efficiency of the loss calculation during the training phase.

## 5 Discrete Image Generation

Image pixels are usually treated as real numbers in continuous space since adjacent pixel values exhibit linear continuity.They are essentially discrete and quantized data with a finite state space, such as \(256\) states in RGB format. We utilize two discrete image representations. One is binary coding provided by Bit Diffusion [Chen et al., 2023b] that converts a sub-pixel with 256 integers to a \(8\)-bit binary code. It is more efficient as it stores ordinal relationships, but the representation space it constructs will be sparse. Another is pixel embedding, which is a more discrete form of representation because the relationships between pixels are thoroughly broken down and reconstructed by learning the embedding representation. Each pixel is regarded as a one-hot vector and transformed with an embedding layer Emb as used in language. Furthermore, we design an intermediate state to demonstrate the correlation between discreteness and modeling difficulty, which is initializing a fixed embedding with binary coding. The optimization target for binary coding is the MSE loss, and pixel embeddings take the same objective as in language.

Experimental SetupWe use Cifar-10 [Krizhevsky et al., 2009] for discrete image generation. The evaluation metric is Fid [Heusel et al., 2017], which compares 50K generated samples with the training set. Our image generation model is constructed on Bit Diffusion [Chen et al., 2023b], where the architecture is U-Net [Ronneberger et al., 2015] with \(3\) stages, \(256\) channels and \(3\) residual blocks

 
**Models** & **Iwslt14** & **Wmt16** \\   Base (Difformer) & 31.58 & 30.08 \\ + forward only & 33.02 & 32.86 \\ + forward \& reverse & **33.42** & 33.15 \\   Optimal Transport & 32.77 & **33.65** \\  

Table 2: Ablation studies.

 
**Objectives** & \(_{}_{t}}\|_{0}-}_{0}\|^{2}\) & \(_{}_{t}}\|_{t}(}_{t}| _{0})-_{t}(}_{t}|}_{0})\|^{2 }\) & \(_{}_{t}}[p(}_{0} C_{_{0}})]\) & Bleu \\   \(_{_{0}}\) (eq. 24) & 8.44 & 1.56 & 51.81\% & 33.42 \\   \(_{_{t}}\) & 8.41 & 1.55 & 52.34\% & 33.49 \\  

Table 3: Analysis on the training objectives.

[MISSING_PAGE_FAIL:9]

cost increases drastically as the size of sentence length or the image resolution increases. Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Dhariwal and Nichol, 2021; Saharia et al., 2022) can generate data in parallel, but are tailored for continuous problems. To generalize diffusion models for discrete data, the most straightforward methods define discrete processes in discrete spaces (Sohl-Dickstein et al., 2015; Hoogeboom et al., 2021; Austin et al., 2021; Campbell et al., 2022; Zhang et al., 2023; Sun et al., 2023; Lou et al., 2023), which will be bothered by large number of discrete status. Besides, a simplified version of discrete diffusion processes is recently used in language modeling (He et al., 2023; Chen et al., 2023). Approaches in another line argue to located discrete data in continuous spaces, which is more flexible and efficient, with the mapping functions including binary bits (Chen et al., 2023) and embeddings (Li et al., 2022; Gong et al., 2023, 2023; Yuan et al., 2022; Gulrajani and Hashimoto, 2023; Han et al., 2023). Other generative models adapted for discrete modeling includes Variational Autoencoders (Kingma and Welling, 2014), Generative Adversarial Networks (Hjelm et al., 2018; Fedus et al., 2018), and Normalizing Flows (Lindt and Hoogeboom, 2021; Hoogeboom et al., 2021; Tan et al., 2022).

Diffusion Models with Deterministic TrajectoryDeterministic diffusion process is usually used in the inference stage to speed up sampling, where DDIM (Song et al., 2021) derives a serial of non-Markovian diffusion processes and the deterministic one is a special case from this implicit perspective. Additionally, deterministic diffusion processes can be converted to ordinary differential equations (Song et al., 2021), which is utilized by recent sampling acceleration approaches such as DEIS (Zhang and Chen, 2023) and DPM-Solvers (Lu et al., 2022, 2022; Zheng et al., 2023). Our approach requires a deterministic forward trajectory to eliminate the randomness between the boundary point and sampled point. Flow matching (Liu, 2022; Lipman et al., 2023; Albergo and Vanden-Eijnden, 2023; Liu et al., 2023) is a collection of generative models that employ ordinary differential equations to facilitate both forward and reverse processes. They can be regarded as generally equivalent to Diffusion models. Therefore, we extend the framework of flow matching for our method.

## 7 Conclusion

We studied the gap between discrete modeling and continuous spaces, focusing on the inconsistency between probability density contours learned by continuous diffusion models and discrete boundaries. We have proposed a novel and general approach to address this issue by enabling continuous diffusion models to be conditioned on discrete priors, which is achieved via discrete boundary estimation and trajectory rescaling. An important limitation is that our method is designed for continuous diffusion models, where discrete diffusion models constructed specially on the discrete state space would not encounter the problem. However, discrete diffusion models also possess their own shortcomings, and the practical applications of continuous diffusion models are more extensive. We believe that our method has the potential to advance the development of unified and general diffusion models. By bridging the gap between discrete and continuous modeling, we hope to inspire new possibilities for modeling complex systems and phenomena.