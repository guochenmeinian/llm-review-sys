# Gradient Rewiring for Editable Graph Neural Network Training

Zhimeng Jiang\({}^{1}\), Zirui Liu\({}^{2}\), Xiaotian Han\({}^{3}\), Qizhang Feng\({}^{1}\), Hongye Jin\({}^{1}\),

**Qiaoyu Tan\({}^{4}\), Kaixiong Zhou\({}^{5}\), Na Zou\({}^{6}\), Xia Hu\({}^{7}\)**

\({}^{1}\)Texas A&M University, \({}^{2}\)University of Minnesota, \({}^{3}\)Case Western Reserve University,

\({}^{4}\)NYU Shanghai, \({}^{5}\)North Carolina State University, \({}^{6}\)University of Houston, \({}^{7}\)Rice University

###### Abstract

Deep neural networks are ubiquitously adopted in many applications, such as computer vision, natural language processing, and graph analytics. However, well-trained neural networks can make prediction errors after deployment as the world changes. _Model editing_ involves updating the base model to correct prediction errors with less accessible training data and computational resources. Despite recent advances in model editors in computer vision and natural language processing, editable training in graph neural networks (GNNs) is rarely explored. The challenge with editable GNN training lies in the inherent information aggregation across neighbors, which can lead model editors to affect the predictions of other nodes unintentionally. In this paper, we first observe the gradient of cross-entropy loss for the target node and training nodes with significant inconsistency, which indicates that directly fine-tuning the base model using the loss on the target node deteriorates the performance on training nodes. Motivated by the gradient inconsistency observation, we propose a simple yet effective Gradient Rewiring method for Editable graph neural network training, named **GRE**. Specifically, we first store the anchor gradient of the loss on training nodes to preserve the locality. Subsequently, we rewire the gradient of the loss on the target node to preserve performance on the training node using anchor gradient. Experiments demonstrate the effectiveness of GRE on various model architectures and graph datasets in terms of multiple editing situations. The source code is available at https://github.com/zhimengj0326/Gradient_rewiring_editing.

## 1 Introduction

Graph Neural Networks (GNNs) have demonstrated exemplary performance for graph learning tasks, such as recommendation, link prediction, molecule property analysis [1; 2; 3; 4; 5; 6; 7]. With message passing, GNNs learn node representations by recursively aggregating the neighboring nodes' representations. Once trained, GNN models are deployed to handle various high-stake tasks, such as credit risk assessment in financial networks  and fake news detection in social networks . However, the impact of erroneous decisions in such influential applications can be substantial. For instance, misplaced credit trust in undetected fake news can lead to severe financial loss.

An ideal approach to tackle such errors should possess the following properties: 1) the ability to _rectify_ severe errors in the model's predictions, 2) the capacity to _generalize_ these corrections to other similar instances of misclassified samples, and 3) the ability to _preserve_ the model's prediction accuracy for all other unrelated inputs. To achieve these goals, various model editing frameworks have been developed to rectify errors by dynamically adjusting the model's behavior when errors are detected [10; 11]. The core principle is to implement minimal changes to the model to correct the error while keeping the rest of the model's behavior intact. However, model editing is not a simpleplug-and-play solution. These frameworks often require an additional training phase to prepare for editing before they can be used effectively for editing [10; 11; 12; 13]. Although model editing techniques have shown significant utility in computer vision and language models, there is rare work focused on rectifying critical errors in graph data. The unique challenge arises from the inherent message-passing mechanism in GNNs when edits involve densely interconnected nodes [14; 15]. Specifically, editing the behavior of a single node can unintentionally induce a ripple effect, causing changes that propagate throughout the entire graph.  theoretically and empirically demonstrate the complexity of editing GNNs through the lens of the loss landscape of the Kullback-Lieber divergence between the pre-trained node features and edited final node embeddings. Moreover, a simple yet effective model structure, named EGNN, is proposed with stitched peer multi-layer perception (MLP), where only the stitched MLP is trained during model editing.

In this work, we investigate the model editing problem for GNNs from a _brand-new gradient perspective_, which is compatible with existing work . Specifically, we first found a considerable inconsistency between the gradients of the cross-entropy loss for the target node and the training nodes for GNNs. Such inconsistency implies that direct fine-tuning of the base model using the loss of the target node can lead to a deterioration in the performance on the training nodes. Motivated by the above observation, we propose a simple yet effective Gradient Rewiring method for Editable graph neural network training, named **GRE**. Specifically, we first calculate and store the anchor gradient of the loss on the training nodes. This anchor gradient represents the original learning direction that we wish to preserve. Then, during the editing process, we adjust the gradient of the loss on the target node based on the stored anchor gradient. This adjustment, or "rewiring", ensures that the changes made to the target node do not adversely affect the performance on the training nodes. Experiments demonstrate the effectiveness of our proposed method for various model structures and graph datasets. Moreover, the proposed method is compatible with the existing EGNN baseline and further improves the performance.

## 2 Preliminary and Related Work

We first introduce the notations used throughout this paper. A graph is given by \(=(,),\) where \(=(v_{1},,v_{N})\) is the set of nodes indexed from \(1\) to \(n\), and \(=(e_{1},,e_{m})\) is the set of edges. \(n=||\) and \(m=||\) are the numbers of nodes and edges, respectively. Let \(^{n d}\) be the node feature matrix, where \(d\) is the dimension of node features. \(^{n n}\) is the graph adjacency matrix, where \(_{i,j}=1\) if \((v_{i},v_{j})\) else \(_{i,j}=0\). \(}=}^{-}(+)}^{- }\) is the normalized

Figure 1: (a) Top: RMSE distance between the gradients of cross-entropy loss over training datasets and over the targeted sample for different architectures. (b) Middle: Cross-entropy loss over training datasets when the model is updated using target loss. (c) Bottom: Cross-entropy loss over the targeted sample when the model is updated using target loss.

adjacency matrix, where \(}\) is the degree matrix of \(+\). The node label is defined as \(y_{i}\) for node \(v_{i}\). We consider node classification tasks with \(C\) classes in this paper.

### Graph Neural Networks

Graph Neural Networks have been successfully applied across various domains/tasks, including knowledge graphs [16; 17], graph condensation [18; 19; 20], event extraction , and entity relation tasks . Most graph neural networks follow a neighborhood aggregation procedure to learn node representation via propagating representations of neighbors and then follow up with feature transformation . The \(l\)-th layer of graph neural networks is given by:

\[_{i}^{(l)} = ^{(l)}\{_{i}^{(l-1)}, _{j}^{(l-1)}|j_{i}\},\] \[_{i}^{(l)} = ^{(l)}_{i}^{(l)},\]

where \(_{i}^{(l)}\) is the representation of node \(v_{i}\) at \(l\)-th layer and \(x_{i}^{(0)}\) is initialized as node feature \(_{i}\), i.e, the \(i\)-th row at node feature matrix \(\). Many GNNs, such as GCN , GraphSAGE , and GAT , can be defined under this computation paradigm via adopting the different propagation and transformation operations. For example, the \(l\)-th layer in GCN can be defined as:

\[^{(l)}=(}^{(l-1)}^{(l)}),\] (1)

where \(^{(l)}^{n d}\) and \(^{(l-1)}^{n d}\) are the node representation matrix containing the \(_{v}\) for each node \(v\) at the layer \(l\) and layer \(l-1\), respectively. \(^{(l)}^{d d}\) is a layer-specific trainable weight matrix, and \(()\) is a non-linear activation function (e.g., ReLU).

### Model Editing

Model editing aims to modify a base model's responses for a misclassified sample \(x_{tg}\) and its analogs. This is typically achieved by fine-tuning the model using only a single pair of input \(x_{tg}\) and the desired output \(y_{tg}\), while preserving the model's responses to unrelated inputs [10; 11; 12; 14]. Our contribution lies in the novel application of model editing to graph data, a domain where misclassifications on a few pivotal nodes can trigger substantial financial losses, fairness issues, or even the propagation of adversarial attacks. Consider the scenario of node classification where a well-trained GNN incorrectly predicts a particular node. Model editing can be employed to rectify this erroneous prediction. By leveraging the node's characteristics and the desired label, the model can be updated to correct such behavior. The ideal outcome of model editing is twofold: first, the updated model should correctly predict the specific node and its similar instances; second, the model should maintain its original behavior on unrelated inputs. It is important to note that some model editors require a preparatory training phase before they can be applied effectively [10; 13; 12; 11]. This crucial step ensures that the model editing process is both precise and effective in its application.

## 3 Methodology

In this section, we first provide the preliminary experimental results as the motivation to rewire gradients for model editing. Subsequently, we propose our gradient rewiring method for editable graph neural networks training (GRE) and an advanced version (GRE+) to improve the effectiveness of model editing, respectively.

### Motivation

In the preliminary experiments, we first pre-train GCN, GraphSAGE, and MLP on the training dataset \(_{train}\) (e.g., Cora, Flickr, ogbn-arxiv, and Amazon Photo datasets) using cross-entropy loss. Subsequently, we find the misclassified samples in the validation dataset and randomly select one sample as the target sample \((_{tg},y_{tg})\). During the model editing, we update the pre-trained model using cross-entropy loss over the target sample using gradient descent, i.e., _the models are trained inductively_. Following previous work [10; 12; 14], we perform \(50\) independent edits and report the averaged metrics.

It is well-known that model editing incurs training performance degradation [11; 10; 12]1 for many model architectures. To deeply delve into the underlying reason, we investigate performance degradation from a model gradient perspective. We further define the training loss as \(_{train}=_{train}|}_{i_{train} }CE(f_{}(_{i}),y_{i})\), where \(f_{}()^{C}\) is a prediction model parameterized with \(^{L}\), \(C\) and \(L\) are the number of classes and model parameters, \(CE(,)\) is the cross-entropy loss, the target loss is given by \(_{tg}=CE(f_{}(_{tg}),y_{tg})\). For example, model \(f_{}()\) can be instantiated by GNNs with the number of layers defined in Eq. (1) or a simple MLP. For model editing, the gradient for training and target loss is given by \(g_{train}=_{train}}{}^{L}\) and \(g_{tg}=_{tg}}{}^{L}\), respectively. To investigate why the model editing leads to training performance degradation, we use gradient RMSE (Root-Mean-Squared-Error), i.e., \(_{RMSE}=-g_{tg}\|_{2}^{2}}\), to measure the model editing discrepancy for training datasets and target sample.

The model editing curves for gradient RMSE 2, training loss, and target loss across various model architectures (GCN, GraphSAGE, and MLP) are shown in Figure 1. Although the gradient RMSE for training datasets and target sample is close to 0, the model parameters demonstrate significant inconsistent behavior in terms of training loss due to large gradient discrepancy in the initial editing stage. We observe that: 1) Even though the target loss decreases during model editing, the training loss increases significantly. 2) The increasing rates of training loss for GCN and GraphSAGE are significantly higher than that of MLP. The above observations imply that editing training for graph neural networks is more challenging due to higher gradient discrepancy between the training dataset and the target sample.

### Gradient Rewiring Approach

Preliminary results show a high discrepancy in training loss and target loss for GNNs, which implies that the vanilla model editing hampers the performance on the overall training dataset and thus results in a high accuracy drop for node classification tasks. Therefore, we aim to tackle the training dataset performance degradation from the gradient rewiring approach.

GreWe propose a simple yet effective gradient rewiring approach for editable graph neural network training, named GRE. We first formulate a constrained optimization problem to _regulate_ model editing and then solve the constrained optimization problem via gradient rewiring.

Model editing aims to correct the prediction for the target sample while maintaining the prediction accuracy on the training nodes. The objective function focuses on minimizing the loss at the target node. To preserve the predictions on the training nodes, we introduce two constraints: (1) the training loss should not exceed its value prior to model editing (see Eq. (3)); and (2) the differences in model predictions after editing should remain within a predefined range (see Eq. (4)). Define \(_{0}\) and \(^{}\) as the model parameters before and after model editing. Then we have the following constrained optimization problem:

\[_{} _{tg}f_{}(_{tg}),y_{tg}\] (2) s.t. \[_{train}f_{^{}},_{train} _{train}f_{_{0}},_{train}\] (4) \[\|_{train}|}_{i_{train}}f_{ ^{}}(_{i})-f_{_{0}}(_{i})\|^{2} ^{},\]

where \(\) and \(^{}\) represent the model parameters before and after model editing, respectively, the hyperparameter \(^{}\) represents the maximum average prediction difference on training nodes. Notice that the model parameters update adopts gradient descent using target loss without any constraints, i.e., \(^{}=_{0}- g_{tg}\), where \(\) is step size in model editing. The key idea of our proposed solution is to rewire gradient \(g_{tg}\) as \(g\), which is obtained by satisfying the involved constraints. Note that the model editing usually corrects the model prediction on the target sample within a few steps, i.e. there are no significant model parameter differences, thus we adopt Taylor expansion to tackle such constrained optimization problem. For target loss \(_{tg}\), we can approximate it as:

\[_{tg}f_{^{}}(_{tg}),y_{tg}   _{tg}f_{_{0}}(_{tg}),y_{tg} +g_{tg}^{}(^{}-_{0})\] (5) \[= _{tg}f_{_{0}}(_{tg}),y_{tg} - g_{tg}^{}g.\]

To optimize the objective function Eq. (2), it is easy to conclude that the gradient cosine similarity \(g_{tg}^{}g\) should be maximized. Given the gradient before/after model editing is fixed, the maximization of gradient cosine similarity \(g_{tg}^{}g\) is equivalent to the minimization of \(\|g_{tg}-g\|^{2}\). To satisfy Eq. (3), we also adopt Taylor expansion on \(_{train}\) and it is easy to obtain that the gradient cosine similarity should be positive, i.e., \(g_{tg}^{}g 0\). As for the constraint in Eq. (4), similarly, a Taylor expansion is used to express the relationship between the model predictions before and after the model editing, as follows:

\[f_{^{}}(_{i}) f_{_{0}}(_{i})+ }(_{i})}{}^{}(^ {}-)=f_{_{0}}(_{i})-}( _{i})}{}^{} g,\] (6)

Therefore, we can obtain the following approximation on Eq. (4):

\[\|_{train}|}_{i_{train}}f_{^{ }}(_{i})-f_{_{0}}(_{i})\|^{2}\|_{train}^{}(- g)\|^{2}^{},\] (7)

where gradient for a model prediction is defined as \(_{train}=_{train}|}_{i _{train}}f_{_{0}}(_{i})}{}\|_{ =_{0}}^{L C}\). Therefore, the model prediction difference constraint can be transformed into \(\|_{train}^{T}g\|^{2}\|_{train}\|_{spect}^{2}\|g\|^{2}\), where \(\|\|_{spect}\) represents matrix spectrum norm and \(\|_{train}\|_{spect}\) is fixed in model editing, and \(=}{^{2}}\). In a nutshell, our goal is to correct the target sample (i.e., minimize \(\|g_{tg}-g\|^{2}\)) and minimize gradient discrepancy for model prediction among training dataset and target sample (i.e., \(\|g\|^{2}\)), while guaranteeing non-increased training loss (i.e., \(g_{train}^{}g 0\)). The original constraint optimization problem is simplified as gradient rewiring, i.e.,

\[_{g}\|g-g_{tg}\|^{2}+\|g\|^{2}=_{g}g^{}g-g_{tg}^{}g+g_{tg}^{}g_{tg}  g_{train}^{}g 0,\] (8)

where \( 0\) is the hyperparameter to control the balance between target sample correction and gradient discrepancy for model prediction. It is easy to obtain that Eq.(8) is a quadratic program (QP) in \(L\)-variables (the number of model parameters is usually high in neural networks). Fortunately, we can effectively solve this problem in the dual space via transforming as a smaller QP problem with only one variable \(v\), where the relation between primal and dual variable is \(g_{train}v-(1+)g=-g_{tg}\). Then we have the following problem:

\[_{v}}{2}(g_{train}v+g_{tg})^{}(g_{train}v+g_{tg })\ v 0.\] (9)

It is easy to obtain the optimal dual variable \(v^{*}=-\{^{T}g_{tg}}{g_{train}},0\}\) and the optimal rewired gradient \(g^{*}=(1+)^{-1}g_{tg}-v^{*}g_{train}\). In other words, the gradient rewiring procedure is quite simple: for the gradient of the target loss \(g_{tg}\), reduce its projection component on \(g_{train}\) and then scale it by \((1+)^{-1}\).

Additionally, we highlight that the gradient for training loss \(g_{train}\) must be stored before model editing. In this way, gradient rewiring can be conducted to remove the harmful gradient component on target loss that increases training loss. Since shallow GNNs model performs well in practice , the model size of GNNs is small and the memory cost \(O(L)\) for storing anchor gradient is negligible.

GRE+In GRE, the training loss after model editing is required not to be larger than that before model editing. However, it is still possible that the training loss on specific sub-training sets performs worse after model editing. At the same time, the training loss for the whole training dataset, after model editing, is on par with or even lower than that of before editing. To tackle this issue, we proposed an advanced gradient rewiring approach, named GRE+, via applying loss constraint on multiple disjoint sub-training sets. Specifically, we split training dataset \(_{train}\) into \(K\) sub-training sets \(\{_{train}^{1},_{train}^{2},,_{train}^{ K}\}\). Similarly, we define \(g_{train}^{k}=_{train}^{k}}{} ^{L}\), where \(_{train}^{k}=_{train}^{k}|}_{i _{train}^{k}}CE(f_{}(_{i}),y_{i})\).

[MISSING_PAGE_FAIL:6]

Datasets and Models.In our experiments, we utilize a selection of eight graph datasets from diverse domains, split evenly between small-scale and large-scale datasets. The small-scale datasets include Cora, A-computers , A-photo , and Coauthor-CS . On the other hand, the large-scale datasets encompass Reddit , Flickr , _ogbn-arxiv_, and _ogbn-products_. Note that our approach is based on gradient rewiring, which is orthogonal to model architectures. We adopt two prevalent models GCN  and GraphSAGE , where both of them are trained with the entire graph at each step. We evaluate our method under the **inductive setting**, which means the model is trained on a subgraph containing only the training node, and evaluated on the whole graph.

Baselines.Our methods are evaluated against three notable baselines: the traditional gradient descent editor (GD), the Editable Neural Network editor (ENN) , and editable training for GNNs. 3 The GD editor is a straightforward application using gradient descent on the target loss with respect to the GNNs model parameters until the desired prediction outcome is achieved. ENN adopts a different approach by initially training the GNN parameters for a few steps to prime the model for subsequent edits. After this preparatory phase, ENN, like GD, applies the gradient descent on the parameters of GNN until the correct prediction is attained. EGNN  stitches a peer MLP and only trains MLP during model editing. Note that our method is compatible with EGNN, and different GNN architectures integrated with EGNN (e.g., EGNN-GCN, EGNN-GraphSAGE) are treated as distinct architectures.

Independent, sequential, and batch editing.All independent, sequential, and batch editing processes involve well-trained GNN models using training datasets, with target samples randomly selected multiple times from misclassified instances in the validation dataset. The key differences lie in the base model that needs to be edited. For independent editing, the same well-trained model using the training datasets is edited multiple times. In contrast, for sequential editing, the model is edited iteratively, with each editing step using the previously edited model from the last target sample, incorporating both the training datasets and partial samples from the validation dataset. For batch editing, all batched samples are edited simultaneously in one editing process. 4

Evaluation Metrics.Consistent with preceding studies [10; 12; 11], we assess the effectiveness of the various methods using two primary metrics: (1) **Accuracy (Acc)**: We use accuracy for the test dataset to evaluate the effectiveness after model editing. (2) **DrawDown (DD)**: This metric measures the mean absolute difference in test accuracy before and after model editing. A lower drawdown value signifies a superior editor locality. (3) **Success Rate (SR)**: This metric evaluates the proportion of edits in which the editor successfully amends the model's prediction. Both metrics offer a different perspective on the effectiveness of the editing process.

### Experimental Results in the Independent and Sequential Editing Setting

In many real-world scenarios, well-trained models often produce inaccurate predictions on unseen data. To evaluate the practical effectiveness of editors for independent editing (**RQ1**), we randomly choose nodes from the validation set that were misclassified during the training. The editor is then

   &  &  &  &  \\  & & &  &  &  &  &  &  &  &  \\  & & & & & & & & & & & & & & & \\   & GD & 13.95111.100 & 37.254103.10 & 1.00 & 75.20612.30 & 20.82611.30 & 1.00 & 2.73142.90 & 46.50814.90 & 1.00 & 53.296494 & 20.176394 & 1.00 \\  & ENN & **25.8412.30** & **25.8816.90** & 1.00 & 1.1685.10 & 54.8648.10 & 1.00 & 1.65947.90 & 35.6280.10 & 1.00 & 0.00 & OOM & OOM \\  & GRE & 17.361.50 & **33.641.50** & 1.00 & 1.2484.794 & 3.2481.90 & 1.00 & 1.73241.86 & 1.1561.16 & 1.00 & 53.929406 & 20.1480.60 & 1.00 \\  & GRE & 22.980.67 & 28.1687 & 0.97 & 31.351.35 & 33.581.33 & 1.80 & 80.611.60 & 1.35941.10 & 1.00 & 57.8431.30 & 1.68941.30 & 1.00 \\   & GD & 17.1642.50 & 33.1842.10 & 1.00 & 58.5852.30 & 37.2617.30 & 1.00 & 40.21410.56 & 36.5810.10 & 1.00 & 57.82162.10 & 1.00 \\   & GD & 17.1642.50 & 33.1846.23 & 1.00 & 58.8852.30 & 37.040 & 1.00 & 1.00 & 40.21410.56 & 36.5810.10 & 1.00 & 57.82162.10 & 1.00 \\   & ENN & 22.735.46 & 33.1546 & 1.00 & 8.88849.39 & 0.96864.80 & 1.00 & 1.00 & 40.8746.810 & 1.00 & 40.00 & OOM & OOM \\   & SAGE & 20.96412.6 & 25.3141.60 & 9.92 & 19.4914.94 & 4.07749.04 & 1.00 & 1.73142.24 & 4.84 & 10.6194.10 & 4.5841.02 & 1.00 \\   & GRE+ & **38.414.17** & **10.594.17** & 0.82 & 22.9562.10 & **39.7442.10** & 1.00 & 68.29823.35 & 37.7142.35 & 1.00 & 63.2652.25 & **3.2942.25** & 1.00 \\  

Table 2: The results on four large-scale datasets after applying one single edit. “OOM” is the out-of-memory error. The best/second-best results are highlighted in **boldface**/underlined, respectively. The results for more backbones (e.g., MLP, EGNN-GCN, EGNN-SAGE) are in Appendix D.1.

applied to rectify the model's predictions for these misclassified nodes, and we evaluate the drawdown and edit success rate on the test set.

We edit one random single node \(50\) times and report the mean and standard deviation results in Tables 1 and 2 for small-scale and large-scale graph datasets, respectively. Our observations are made below:

_Contrasting model editing on textual data [11; 12; 30], all editors can effectively rectify model predictions in the graph domain._ As shown in Table 1, all editors achieve a high success rate (typically from \(96\% 100\%\)) after editing GNNs, which is highly different from transformers with below \(50\%\) SR. This finding indicates that GNNs, unlike transformers, can be more easily adjusted to produce correct predictions. However, this improvement comes at the expense of **substantial drawdown** on other unrelated nodes, underscoring the key challenge of maintaining prediction locality for unrelated nodes before and after editing.

_Our proposed GRE and GRE+ notably surpass both GD and ENN in terms of test drawdown._ This advantage stems mainly from the rewired gradient based on the pre-stored training loss gradient, which facilitates target sample correction while preserving the training loss. GD and ENN attempt to rectify model predictions by updating the parameters of GNNs without incorporating training loss information. In contrast, GRE and GRE+ maintain much better test accuracy after model editing. For example, for Amazon-photos, the accuracy drop dynihles from roughly \(65.08\%\) to around \(43.87\%\), a \(43.9\%\) improvement over the baseline. This is due to the gradient rewiring approach that facilitates target sample correction while preserving the training loss. Interestingly, when applied to GNNs, ENN performs markedly worse than the basic editor GD. Moreover, GD performs well in MLP, which is consistent with the low gradient discrepancy of MLP.

_Our proposed GRE and GRE+ are compatible with EGNN and further improve the performance._ We observe that while GRE occasionally underperforms, GRE+ consistently shows better performance than GD in reducing accuracy. For instance, when the A-computers dataset is evaluated with EGNN-GCN, GRE, and GRE+ exhibit an average accuracy drop of \(4.62\%\) and \(0.51\%\), respectively, whereas GD shows a decrease of \(0.73\%\). Notably, we find that for 7 out of 8 datasets, GRE+ with EGNN-SAGE shows a negative drop in accuracy, meaning that the test accuracy actually increases after model editing. This points towards the superior performance of the EGNN-SAGE model architecture.

In the **sequential editing setting**, we select a sequence of nodes from the validation set that were misclassified during the training phase. The editor is then used to iteratively correct the model's predictions for these sequentially misclassified nodes, and we measure the resulting drawdown and success rate of edits on the test set.

In Figure 2, we report the test accuracy drawdown in the sequential setting, a more challenging scenario that warrants further investigation. In particular, we plot the test accuracy drawdown compared to GD across various GNN architectures and graph datasets. Our observations are as follows:

_The proposed GRE and GRE+ consistently outperform GD in the sequential setting._ However, the drawdown is significantly higher than in the single edit setting. For instance, GRE+ exhibits a \(43.87\%\) drawdown for GCN on the A-photo dataset in the single edit setting, which

Figure 2: The test accuracy drawdown in sequential editing setting for GCN and GraphSAGE on various datasets. The units for y-axis are percentages (\(\%\)).

escalates up to a \(65\%\) drawdown in the sequential edit setting. These results also highlight the challenge of maintaining the locality of GNN prediction in sequential editing. _The improvement of GRE+ over GRE is quite limited in the sequential setting._ For example, GRE+ exhibits a \(24.52\%\) drawdown over GRE for GCN on the A-photo dataset in the single edit setting while is on par with GRE in the sequential edit setting. These results further verify the difficulty of sequential editing and indicate more comprehensive training subset selection may be promising.

### Trade-off Performance Comparison

We further compare the trade-off between the accuracy drawdown and the success rate of our method on various GNN architectures and graph datasets. As shown in Figure 3, we plot Pareto front curves by assigning different hyperparameters for the proposed methods. The upper-left corner point represents the ideal performance, i.e., the highest SR and lowest accuracy drawdown. The results show that GRE+ achieves better trade-off results compared to GRE, and all methods consistently maintain a high success rate on various GNN architectures and graph datasets.

### Hyperparameter Study

In this experiment, we investigate the sensitivity of our proposed method w.r.t. \(\) across a variety of GNN architectures and graph datasets. Specifically, we search for \(\) from the set of \(\{0.0,0.1,1.0,10.0,50.0\}\). As shown in Figure 4, the test accuracy drop remains relatively stable despite variations in \(\), suggesting that meticulous tuning of this parameter may not be crucial. For the ogbn-arxiv dataset, an uptick in accuracy drop corresponds with an increase in \(\), reflecting the inherent difficulty of this dataset. Intriguingly, in the case of GRE+5 with 5 training subsets, the test accuracy drop exceeds that of GRE+2 and GRE+3, a pattern that diverges from the trend observed in other datasets.

Figure 4: The hyperparameter study on test accuracy drawdown in independent editing setting w.r.t. \(\).

Figure 3: The success rate and test accuracy drawdown tradeoff in independent editing setting for GCN and GraphSAGE on various datasets. The trade-off curve close to the top left corner means better trade-off performance. The units for x- and y-axis are percentages (\(\%\)).

Conclusion

In this paper, we explore the editing of graph neural networks from a new gradient perspective. Through empirical observations, we discover that conventional model editing techniques often underperform due to the gradient discrepancy between the training loss and target loss in GNNs. To address this issue, we propose a gradient rewiring approach. Specifically, we formulate a constrained optimization problem to regulate the model performance during model editing and identify a simple yet effective gradient rewiring approach to explicitly satisfy the constraints. In this way, the proposed approach can correct the target sample while preventing an increase in training loss. Experiments demonstrate the effectiveness of our approach, and our proposed method is also compatible with the existing baseline EGNN and can further improve performance. Future work includes more comprehensive training subset selection in GRE+ and a tailed approach for editable graph neural networks training in the sequential editing setting.

## 6 Acknowledgements

The authors thank the anonymous reviewers for their helpful comments. This work is in part supported by NSF grants NSF IIS-2310260, IIS-2224843, IIS-2450662, IIS-2431515 and IIS-2239257. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies.