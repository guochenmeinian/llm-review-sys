# Diffusion Models are Certifiably Robust Classifiers

Huanran Chen\({}^{1,2}\), Yinpeng Dong\({}^{1,2}\), Shitong Shao\({}^{1}\), Zhongkai Hao\({}^{1}\),

Xiao Yang\({}^{1}\), Hang Su\({}^{1,3}\), Jun Zhu\({}^{1,2}\)

\({}^{1}\)Dept. of Comp. Sci. and Tech., Institute for AI, Tsinghua-Bosch Joint ML Center, THBI Lab

BNRist Center, Tsinghua University, Beijing, 100084, China \({}^{2}\)RealAI

\({}^{3}\) Zhongguancun Laboratory, Beijing, China

huanran.chen@outlook.com {dongyinpeng, dcszj}@mail.tsinghua.edu.cn

The corresponding Author.

###### Abstract

Generative learning, recognized for its effective modeling of data distributions, offers inherent advantages in handling out-of-distribution instances, especially for enhancing robustness to adversarial attacks. Among these, diffusion classifiers, utilizing powerful diffusion models, have demonstrated superior empirical robustness. However, a comprehensive theoretical understanding of their robustness is still lacking, raising concerns about their vulnerability to stronger future attacks. In this study, we prove that diffusion classifiers possess \(O(1)\) Lipschitzness, and establish their certified robustness, demonstrating their inherent resilience. To achieve non-constant Lipschitzness, thereby obtaining much tighter certified robustness, we generalize diffusion classifiers to classify Gaussian-corrupted data. This involves deriving the evidence lower bounds (ELBOs) for these distributions, approximating the likelihood using the ELBO, and calculating classification probabilities via Bayes' theorem. Experimental results show the superior certified robustness of these Noised Diffusion Classifiers (NDCs). Notably, we achieve over 80% and 70% certified robustness on CIFAR-10 under adversarial perturbations with \(_{2}\) norms less than 0.25 and 0.5, respectively, using a single off-the-shelf diffusion model without any additional data.

## 1 Introduction

Despite the unprecedented success of discriminative learning [32; 22], they are vulnerable to adversarial examples, which are generated by imposing human-imperceptible perturbations on natural examples but can mislead target models into making erroneous predictions [44; 8]. To improve the robustness of discriminative learning, numerous defense techniques have been developed [29; 51; 35; 27; 34]. However, since discriminative models are directly trained for specific tasks, they often find shortcuts in the objective function, exhibiting non-robust nature [7; 36]. For example, adversarial training exhibits poor generalization against unseen threat models [45; 34], and purification-based methods typically cannot completely remove adversarial perturbations, leaving subsequent discriminative classifiers still affected by these perturbations [1; 25; 3; 15].

On the contrary, generative learning is tasked with modeling the entire data distribution, which offers a degree of inherent robustness without any adversarial training [53; 9]. As the current state-of-the-art generative approach, diffusion models provide a more accurate estimation of the score function across the entire data space. Thus, they have been effectively utilized as generative classifiers for robust classification, known as diffusion classifiers [26; 3; 5]. Specifically, they calculate the classification probability \(p(y|) p(|y)p(y)\) through Bayes' theorem and approximate the log likelihood \( p(|y)\) via the evidence lower bound (ELBO). This method establishes a connection between robust classification and the fast-growing field of pre-trained generative models. Althoughpromising, there is still a lack of rigorous theoretical analysis, raising questions about whether their robustness is overestimated and whether they will be vulnerable to (potentially) stronger future adaptive attacks. In this work, we use theoretical tools to derive the certified robustness of diffusion classifiers, fundamentally address these concerns, and gain a deeper understanding of their robustness.

We begin by analyzing the smoothness of diffusion classifiers through the derivation of their Lipschitzness. We prove that diffusion classifiers possess an \(O(1)\) Lipschitz constant, demonstrating their inherent robustness. This allows us to certify the robust radius of diffusion classifiers by dividing the gap between predictions on the correct class and the incorrect class by their Lipschitz constant. Although we obtain a non-trivial certified radius, it could be much tighter if we could derive non-constant Lipschitzness (i.e., the Lipschitzness at each point). Randomized smoothing [6; 38], a well-researched technique, allows us to obtain tighter Lipschitzness based on the output at each point. However, randomized smoothing requires the base classifier (e.g., diffusion classifiers) to process Gaussian-corrupted data \(_{}\), where \(\) is the noise level. To address this, we generalize diffusion classifiers to calculate \(p(y|_{})\) by estimating \( p(_{}|y)\) using its ELBO and then calculating \(p(y|_{})\) using Bayes' theorem. We named these generalized diffusion classifiers as **Noised Diffusion Classifiers**. Hence, the core problem becomes deriving the ELBO for noisy data.

Naturally, we conceive to generalize the ELBO in Sohl-Dickstein et al.  and Kingma et al.  to \( 0\), naming the corresponding diffusion classifier the Exact Posterior Noised Diffusion Classifier (EPNDC). EPNDC achieves state-of-the-art certified robustness among methods that do not use extra data. Surprisingly, we discover that one can calculate the expectation or ensemble of this ELBO without any additional computational overhead. This finding allows us to design a new diffusion classifier that functions as an ensemble of EPNDC but does not require extra computational cost. We refer to this enhanced diffusion classifier as the Approximated Posterior Noised Diffusion Classifier (APNDC). Towards the end of this paper, we reduce the time complexity of diffusion classifiers by significantly decreasing variance through the use of the same noisy samples for all classes and by proposing a search algorithm to narrow down the candidate classes for the diffusion classifier.

Experimental results substantiate the superior performance of our methods. Notably, we achieve 82.2%, 70.7%, and 54.5% at \(_{2}\) radii of 0.25, 0.5, and 0.75, respectively, on the CIFAR-10 dataset. These results surpass the previous state-of-the-art  by absolute margins of 5.6%, 6.1%, and 4.1% in the corresponding categories. Additionally, our approach registers a clean accuracy of 91.2%, outperforming Xiao et al.  by 3.6%. Moreover, our time complexity reduction techniques decrease the computational burden by a factor of 10 on CIFAR-10 and by a factor of 1000 on ImageNet, without compromising certified robustness. Furthermore, our comparative analysis with heuristic methods not only highlights the tangible benefits of our theoretical advancements but also provides valuable insights into several evidence lower bounds and the inherent robustness of diffusion classifiers.

The contributions of this paper are summarized as follows:

* We derive the Lipschitz constant and certified lower bound for diffusion classifiers, demonstrating their inherent provable robustness.
* We generalize diffusion classifiers to classify noisy data, enabling us to derive non-constant Lipschitzness and state-of-the-art certified robustness.
* We propose a variance reduction technique that greatly reduces time complexity without compromising certified robustness.

## 2 Background

### Diffusion Models

For simplicity in derivation, we introduce a general formulation that covers various diffusion models. In Appendix A.8, we show that common models, such as Ho et al. , Song et al. , Kingma et al.  and Karras et al. , can be transformed to align with our definition.

Given \(:=_{0}^{D}\) with a data distribution \(q(_{0})\), the forward diffusion process incrementally introduces Gaussian noise to the data distribution, resulting in a continuous sequence of distributions \(\{q(_{t}):=q_{t}(_{t})\}_{t=1}^{T}\) by:

\[q(_{t})= q(_{0})q(_{t}|_{0})d _{0},\] (1)where \(q(_{t}|_{0})=(_{t};_{0}, _{t}^{2})\), i.e., \(_{t}=_{0}+_{t},(,)\). Typically, \(_{t}\) monotonically increases with \(t\), establishing one-to-one mappings \(t()\) from \(\) to \(t\) and \((t)\) from \(t\) to \(\). Additionally, \(_{T}\) is large enough that \(q(_{T})\) is approximately an isotropic Gaussian distribution. Given \(p:=p_{}\) as the parameterized reverse distribution with prior \(p(_{T})=(_{T};,_{T}^{2} )\), the diffusion process used to synthesize real data is defined as a Markov chain with learned Gaussian distributions [11; 42]:

\[p(_{0:T})=p(_{T})_{t=1}^{T}p(_{t-1}| _{t}).\] (2)

In this work, we parameterize the reverse Gaussian distribution \(p(_{t-1}|_{t})\) using a neural network \(_{}(_{t},t)\) as

\[ p(_{t-1}|_{t})=( _{t-1};_{}(_{t},t), ^{2}(_{t+1}^{2}-_{t}^{2})}{_{t+1}^{2}}),\\ _{}(_{t},t)=^{ 2}-_{t-1}^{2})_{}(_{t},_{t})+_{t- 1}^{2}_{t}}{_{t}^{2}}.\] (3)

The parameter \(\) is usually trained by optimizing the evidence lower bound (ELBO) on the log likelihood [41; 11; 17]:

\[ p(_{0})-_{t=1}^{T}_{} [w_{t}\|_{}(_{t},_{t})-_{0}\| _{2}^{2}]+C_{1},\] (4)

where \(w_{t}=}}{_{t+1}^{2}}\) is the weight of the loss at time step \(t\) and \(C_{1}\) is a constant. Similarly, the conditional diffusion model \(p(_{t-1}|_{t},y)\) is parameterized by \(_{}(_{t},_{t},y)\). A similar lower bound on conditional log likelihood is

\[ p(_{0}|y)-_{t=1}^{T}_{} [w_{t}\|_{}(_{t},_{t},y)-_{0} \|_{2}^{2}]+C,\] (5)

where \(C\) is another constant.

### Diffusion Classifiers

Diffusion classifier [3; 5; 26]\(():^{D}^{K}\) is a generative classifier that uses a single off-the-shelf diffusion model for robust classification. It first approximates the conditional likelihood \( p(y|_{0})\) via conditional ELBO (i.e., using ELBO as logit), and then calculates the class probability \(p(y|_{0}) p(_{0}|y)\) through Bayes' theorem, with the assumption that \(p(y)\) is a uniform prior:

\[(_{0})_{y}&:=_{t=1}^{T}_{}[w_{t} \|_{}(_{t},_{t},y)-_{0}\|_{2}^{2} ])}{_{}(-_{t=1}^{T}_{ }[w_{t}\|_{}(_{t},_{ t},)-_{0}\|_{2}^{2}])}\\ &_{0}|y))}{_{} ( p(_{0}|))}=_{0}|y)p(y)}{ _{}p(_{0}|)p()} p(y|_ {0}).\] (6)

Figure 1: Illustration of our theoretical contributions. We derive the Lipschitz constant and the corresponding certified radius for diffusion classifiers . Additionally, we introduce two novel evidence lower bounds, which are used to approximate the log likelihood. These lower bounds are then employed to construct classifiers based on Bayes’ theorem. By applying randomized smoothing to these classifiers, we derive their certified robust radii.

In other words, it utilizes the ELBO of each conditional likelihood \( p(y|_{0})\) as the logit of each class. This classifier achieves state-of-the-art empirical robustness across several types of threat models and can generalize to unseen attacks as it does not require training on adversarial examples . However, there is still lacking a rigorous theoretical analysis, leaving questions about whether they will be vulnerable to (potentially) future stronger adaptive attacks.

### Randomized Smoothing

Randomized smoothing [23; 6; 48; 20] is a model-agnostic technique designed to establish a lower bound of robustness against adversarial examples. It is scalable to large networks and datasets and achieves state-of-the-art performance in certified robustness . This approach constructs a smoothed classifier by averaging the output of a base classifier over Gaussian noise. Owing to the Lipschitz continuity of this classifier, it remains stable within a certain perturbation range, thereby ensuring certified robustness.

Formally, given a classifier \(f:^{D}^{K}\) that takes a \(D\)-dimensional input \(_{0}\) and predicts class probabilities over \(K\) classes, the \(y\)-th output of the smoothed classifier \(g\) is:

\[g(_{0})_{y}=P(*{arg\,max}_{\{1,,K\}}f( _{0}+_{})_{}=y),\] (7)

where \((,)\) is a Gaussian noise and \(_{}\) is the noise level. Let \(^{-1}\) denote the inverse function of the standard Gaussian CDF. Salman et al.  prove that \(^{-1}(g(_{0})_{y})\) is \(}\)-Lipschitz. However, the exact computation of \(g(_{0})\) is infeasible due to the challenge of calculating the expectation in a high-dimensional space. Practically, one usually estimates a lower bound \(}\) of \(g(_{0})_{y}\) and an upper bound \(}\) of \(_{ y}g(_{0})_{}\) using the Clopper-Pearson lemma, and then calculates the lower bound of the certified robust radius \(R\) for class \(y\) as

\[R=}{2}(^{-1}(})-^{-1}( })).\] (8)

Typically, the existing classifiers are trained to classify images in clean distribution \(q(_{0})\). However, the input distribution in Eq. (7) is \(q(_{})= q(_{0})q(_{}|_{0}) d_{0}\). Due to the distribution discrepancy, \(g(_{0})\) constructed by classifiers trained on clean distribution \(q(_{0})\) exhibits low accuracy on \(q(_{})\). Due to this issue, we cannot directly incorporate the diffusion classifier  with randomized smoothing. In this paper, we propose a new category of diffusion classifiers, that can directly calculate \(p(y|_{})\) via an off-the-shelf diffusion model.

To handle Gaussian-corrupted data, early work [6; 38] trains new classifiers on \(q(_{})\) but is not applicable to pre-trained models. Orthogonal to our work, there is also some recent work on using denoiser for certified robustness [39; 46], and some of them choose diffusion model as denoiser [2; 47; 52]. They first denoise \(_{} q(_{})\), followed by an off-the-shelf discriminative classifier for classifying the denoised image. However, the efficacy of such an algorithm is largely constrained by the performance of the discriminative classifier.

## 3 Methodology

In this section, we first derive an upper bound of the Lipschitz constant in Sec. 3.1. Due to the difficulty in deriving a tighter Lipschitzness for such a mathematical form, we propose two variants of Noised Diffusion Classifiers (NDCs), and integrate them with randomized smoothing to obtain a tighter robust radius, as detailed in Sec. 3.2 and Sec. 3.3. Finally, we propose several techniques in Sec. 3.4 to reduce time complexity and enhance scalability for large datasets.

### The Lipschitzness of Diffusion Classifiers

We observe that the logits \(-_{t=1}^{T}w_{t}_{}[\| _{}(_{t},_{t})-_{0}\|_{2}^{2}]\) of diffusion classifier in Eq. (6) can be decomposed as

\[-_{t=1}^{T}w_{t}(_{}[ \|_{}(_{t},_{t})\|_{2}^{2}]+\|_{0}\|_{2}^{2}-2_{}[_{}( _{t},_{t})^{}]_{0}).\] (9)Given that \(_{}[\|_{}(_{t},_{t})\|_{2}^ {2}]\) and \(_{}[_{}(_{t},_{t})]\) are smoothed by Gaussian noise and lie within the range \(^{D}\), they satisfy the Lipschitz condition . Consequently, the logits of diffusion classifiers should satisfy a Lipschitz condition. Thus, it can be inferred that the entire diffusion classifier is robust and possesses a certain robust radius.

We derive an upper bound for the Lipchitz constant of diffusion classifiers in the following theorem:

**Theorem 3.1**.: _The upper bound of Lipschitz constant of diffusion classifier is given by:_

\[|(_{0}+)_{y}-(_{0})_{y}| }_{t=1}^{T}}{_{t}T}(}+})\|\|_{2}.\] (10)

_If one can get a lower bound \(p_{A}\) for \((_{0})_{y}\) and a upper bound \(}\) for \(_{ y}(_{0})_{}\) (e.g., probabilistic bound by Bernstein inequality ), the lower bound of certified radius for diffusion classifier can be obtained:_

\[R_{DC}=T(p_{A}-})}{(2/+) _{t=1}^{T}w_{t}/_{t}}.\] (11)

Proof.: (Sketch; details in Appendix A.2). Employing a similar methodology to that used by Salman et al. , we derive the gradient of the diffusion classifier. Since the gradient norm of a neural network is unbounded, we transfer the target of the gradient operator from the neural network to the Gaussian density function, so that we can bound the gradient norm and the Lipschitz constant. 

As demonstrated in Theorem 3.1, the Lipschitz constant of diffusion classifiers is nearly identical to that in the "_weak law_" of randomized smoothing (See Appendix A.3, or Lemma 1 in Salman et al. ). This constant is small and independent of the dimension \(D\), indicating the inherent robustness of diffusion classifiers. However, similar to the weak law of randomized smoothing, such certified robustness has limitations because it assumes the maximum Lipschitz condition is satisfied throughout the entire perturbation path, i.e., it assumes the equality always holds in \(|f(_{adv})_{y}-f()_{y}| L\|-_{adv }\|_{2}\) when \(f\) has Lipschitz constant \(L\). As a result, the equality also holds in \(f(_{adv})_{y} f()_{y}-L\|-_{adv }\|_{2}\) and \(f(_{adv})_{} f()_{}+L\|- _{adv}\|_{2}\) for \(_{ y}f()_{}\). To guarantee the prediction is unchanged (i.e., \(f(_{adv})_{y} f(_{adv})_{}\)), its requires the perturbation \(\|-_{adv}\|_{2}\) must be less than \(\).

To be specific, under the weak law of randomized smoothing, it is impossible to achieve a certified radius greater than 1.253. According to Eq. (11), a certified radius greater than 0.39 is unattainable, and empirically, the average certified radius achieved is only 0.156 (refer to Appendix C.3). This is significantly lower than the empirical robustness upper bound obtained through adaptive attacks as reported in Chen et al. .

On the other hand, the "_strong law_" of randomized smoothing (See Eq. (8) or Lemma 2 in Salman et al. ) can yield a non-constant Lipschitzness, leading to a more precise robust radius, with the upper bound of the certified radius potentially being infinite. Therefore, in the subsequent sections, we aim to combine diffusion classifier with randomized smoothing to achieve a tighter certified radius, thus thoroughly explore its robustness.

### Exact Posterior Noised Diffusion Classifier

As explained in Sec. 2.3, randomized smoothing constructs a smoothed classifier \(g\) from a given base classifier \(f\) by aggregating votes over Gaussian-corrupted data. This process necessitates that the base classifier can classify data from the noisy distribution \(q(_{})\). However, the diffusion classifier in Chen et al.  is limited to classifying data solely from \(q(_{0})\). Therefore, in this section, we generalize the diffusion classifier to enable the classification of images from \(q(_{})\) for any given \(\).

Similar to Chen et al. , our fundamental idea involves deriving the ELBO for \( p(_{}|y)\) and subsequently calculating \(p(y|_{})\) using the estimated \( p(_{}|y)\) via Bayes' theorem. Drawing inspiration from Ho et al. , we derive a similar ELBO for \( p(_{})\), as elaborated in the following theorem (the conditional ELBO is similar to unconditional one, see Appendix A.4 for details):

**Theorem 3.2**.: _(Proof in Appendices A.4 and A.5). The ELBO of \( p(_{})\) is given by:_

\[ p(_{})-_{t=}^{T}w_{t}^{()}_{q( _{t+1}|_{})}[\|_{q(_{t}|_{t+1},_{})}[_{t}]-_{p(_{t}| _{t+1})}[_{t}]\|^{2}]+C_{2},\] (12)

_where_

\[_{t+1}& q(_{t +1}|_{}),\;_{q(_{t}|_{t+1},_{})}[_{t}]=^{2}-_{t}^{2})_{ }+(_{t}^{2}-_{}^{2})_{t+1}}{_{t+1}^{2}- _{}^{2}},\\ w_{t}^{()}&=^{2}-_{ }^{2}}{2(_{t}^{2}-_{t}^{2})(_{t+1}^{2}-_{t}^{2})},\; _{p(_{t}|_{t+1})}[_{t}]=^{2}-_{t}^{2})h(_{t+1},_{t+1})+_{t}^{2} _{t+1}}{_{t+1}^{2}}.\] (13)

_Remark 3.3_.: Notice that the summation of KL divergence in the ELBO of \( p(_{})\) starts from \(+1\) and ends at \(T\), while that of \( p(_{0})\) starts from \(1\). Besides, the posterior is \(q(_{t}|_{t+1},_{})\) instead of \(q(_{t}|_{t+1},_{0})\).

_Remark 3.4_.: When \(=0\), this result degrades to the diffusion training loss \(-_{t}}{_{t+1}}\|_{0}-( _{t+1},_{t+1})\|^{2}\), consistent with Kingma et al.  and Karras et al. .

Due to the page width limit, we only present the unconditional ELBO in the main text. We can get the conditional ELBO by adding \(y\) to the condition. Using the conditional ELBOs as approximation for log likelihood (i.e., using ELBOs as logits), one can calculate \(p(y|_{})=(_{}|y)}}{_{g }e^{ p_{}(_{}|g)}}\) for classification. We name this algorithm as Exact Posterior Noised Diffusion Classifier (EPNDC), as demonstrated in Algorithm 1.

```
1:Require: A pre-trained diffusion model \(_{}\), a noisy input image \(_{}\), noisy level \(\).
2:for\(y=0\)to\(K-1\)do
3: Calculate the lower bound \( p(_{}|y)\) of \( p(_{}|y)\) by: \(_{t=+1}^{T}w_{t}\|_{}(_{},_{ })-_{}(_{t},_{t+1},y)\|^{2}\), where \(w_{t}=-_{t}}{_{t+1}^{3}}\);
4:endfor
5:Approximate \(p_{}(y|_{})\) by \((_{}|y))}{_{g} ( p_{}(_{}|0))}\);
6:Return:\(=_{y}p_{}(y|_{})\). ```

**Algorithm 2** APNDC

Although this classifier achieves non-trivial certified robustness, it still has limitations. For instance, we cannot theoretically determine the optimal weight \(w_{t}^{()}\) (see Appendix C.2 for details). Additionally, the time complexity is high. In the next section, we propose a new diffusion classifier called the Approximated Posterior Noised Diffusion Classifier (APNDC), which addresses these problems and acts like an ensemble of EPNDC so that greatly enhanced certified robustness without any computational overhead.

### Approximated Posterior Noised Diffusion Classifier

Greatly inspired by Song et al.  and Meng et al. , we propose to approximate the posterior in a similar manner:

\[q(_{t}|_{t+1},_{})=q(_{t}|_{t+1},_{},_{0}=_{}(_{}, _{})) q(_{t}|_{t+1},_{0}= _{}(_{},_{})).\] (14)As a result, the KL divergence can be simplified using this approximation:

\[D_{}(q(_{t}|_{t+1},_{}) \|p_{}(_{t}|_{t+1})) D_{}(q( _{t}|_{t+1},_{0}=_{}(_ {},_{}))\|p_{}(_{t}|_{t+1}))\] \[= -_{t}}{_{t+1}^{3}}\|( _{},_{})-(_{t+1},_{t+1})\|^ {2}+C_{3}.\] (15)

Intriguingly, Eq. (15) is the ELBO of \(_{q(}_{}|_{0}=_{}( _{},_{}))}[ p_{}(}_{})]\), i.e.,

\[_{q(}_{}|_{0}=_{}( _{},_{}))}[ p_{}(}_{})]  C_{4}-_{t=+1}^{T-1}w_{t}_{q(_{t}|_{ 0}=_{}(_{},_{}))}[\|_{ }(_{t},_{t})-_{0}\|_{2}^{2}].\] (16)

Therefore, one can use the ELBO in Eq. (16) as a approximation for \( p(_{})\) (i.e., employing the ELBOs of this expected log likelihood as the logits), and calculate the class probabilities through Bayes' theorem. We name this method as Approximated Posterior Noised Diffusion Classifier (APNDC), as shown in Algorithm 2.

APNDC is functionally equivalent to an ensemble of EPNDC, as it calculates the ELBO of \(_{q(}_{}|_{0}=_{}( _{},_{}))}[ p_{}(}_{})]\), which corresponds to the expected \( p(_{}|y)\). This nearly-free ensemble can be executed with only one more forward pass of UNet to compute \(_{}(_{},)\). For detailed explanations, please refer to Appendix A.7.

_Remark 3.5_.: From a heuristic standpoint, one might consider first employing a diffusion model for denoising (named DiffPure by Nie et al. ), followed by using a diffusion classifier for classification. This approach differs from our method, where we calculate the diffusion loss only from \(+1\) to \(T\), and the noisy samples \(_{t}\) are obtained by adding noise to \(_{}\) instead of \(_{0}\). In Table 1, we demonstrate that our APNDC method significantly outperforms this heuristic approach (DiffPure+DC).

### Time Complexity Reduction

**Variance reduction.** The main computational effort in our approach is dedicated to calculating the evidence lower bound for each class. This involves computing the sum of reconstruction losses. For instance, in DC, the reconstruction loss is \(\|_{0}-_{}(_{t},_{t+1})\|_{2}^{2}\). In EPNDC, it is \(\|_{q(_{t}|_{t+1},_{})}[_{t}]-_{p(_{t}|_{t+1})}[_{t}]\|_{2}^ {2}\), and in APNDC, the loss is \(\|_{}(_{},_{})-_{}( _{t+1},_{t+1})\|_{2}^{2}\), with the summation carried out over \(t\). Chen et al.  attempt to reduce the time complexity by only calculating the reconstruction loss at certain timesteps. However, this approach proves ineffective. We identify that the primary reason for this failure is the large variance in the reconstruction

    &  &  &  \\  & & & 0.25 & 0.5 & 0.75 & 1.0 \\  PixelDP  & ✗ & ✗ & \((71.0)22.0\) & \((44.0)2.0\) & - & - \\ RS  & ✗ & ✗ & \((75.0)61.0\) & \((75.0)43.0\) & \((65.0)32.0\) & \((65.0)23.0\) \\ SmoothAdv  & ✗ & ✗ & \((82.0)68.0\) & \((76.0)54.0\) & \((68.0)41.0\) & \((64.0)32.0\) \\ Consistency  & ✗ & ✗ & \((77.8)68.8\) & \((75.8)58.1\) & \((72.9)48.5\) & \((52.3)37.8\) \\ MACER  & ✗ & ✗ & \((81.0)71.0\) & \((81.0)59.0\) & \((66.0)46.0\) & \((66.0)38.0\) \\ Boosting  & ✗ & ✗ & \((83.4)70.6\) & \((76.8)60.4\) & \((71.6)52.4\) & \((73.0)38.8\) \\ SmoothMix  & ✓� & ✗ & \((77.1)67.9\) & \((77.1)57.9\) & \((74.2)47.7\) & \((61.8)37.2\) \\ Denoised  & ✓� & ✗ & \((72.0)56.0\) & \((62.0)41.0\) & \((62.0)28.0\) & \((44.0)19.0\) \\ Lee  & ✓� & ✗ & \((-60.0)\) & \((-4)2.0\) & \((-2)28.0\) & \((-1)9.0\) \\ Carlini  & ✓� & ✓ & \((88.0)73.8\) & \((88.0)56.2\) & \((88.0)41.6\) & \((74.2)31.0\) \\ DensePure  & ✓� & ✓ & \((87.6)76.6\) & \((87.6)64.6\) & \((87.6)50.4\) & \((73.6)37.4\) \\  DiffPure+DC (baseline, ours) & ✓� & ✗ & \((87.5)68.8\) & \((87.5)53.1\) & \((87.5)41.2\) & \((73.4)25.6\) \\ EPNDC (\(T^{}=100\), ours) & ✓� & ✗ & \((89.1)77.4\) & \((89.1)60.0\) & \((89.1)35.7\) & \((74.8)24.4\) \\ APNDC (\(T^{}=100\), ours) & ✓� & ✗ & \((89.5)80.7\) & \((89.5)68.8\) & \((89.5)50.8\) & \((76.2)35.2\) \\ APNDC (\(T^{}=1000\), ours) & ✓� & ✗ & \((91.2)82.2\) & \((91.2)70.

loss, necessitating sufficient calculations for convergence. To address this, we propose an effective variance reduction technique that uses identical input samples across all categories at each timestep. In other words, we use the same \(_{t}\) for different classes. This approach significantly reduces the difference in prediction difficulty among various classes, allowing for a more equitable calculation of the reconstruction loss for each class. As shown in Figure 2(a), we can utilize a much smaller number of timesteps, such as \(8\), without sacrificing accuracy, thereby substantially reducing time complexity.

**Sift-and-refine algorithm.** The time complexity of these diffusion classifiers is proportional to the number of classes, presenting a significant obstacle for their application in datasets with numerous classes. Chen et al.  suggest the use of multi-head diffusion to address this issue. However, this approach requires training an additional diffusion model, leading to extra computational overhead. In our work, we focus solely on employing a single off-the-shelf diffusion model to construct a certifiably robust classifier. To tackle the aforementioned challenge, we propose a Sift-and-refine algorithm. The core idea is to swiftly reduce the number of classes, thereby limiting our focus to a manageable subset of classes. We provide more detailed analysis in Algorithm 5.

## 4 Experiment

Following previous studies [2; 47; 52], we evaluate the certified robustness of our method on two standard datasets, CIFAR-10  and ImageNet , selecting a subset of 512 images from each. We adhere to the certified robustness pipeline established by Cohen et al. , although our method potentially offers a tighter certified bound, as demonstrated in Appendix A.3. To make a fair comparison with previous studies, we also select \(_{}\{0.25,0.5,1.0\}\) for certification (thus \(\) is determined) and use EDM  as our diffusion models. For a re-clarification on the hyper-parameters and additional experiments (including ablation studies on diffusion checkpoints and time complexity comparison), please refer to Appendix B.

### Results on CIFAR-10

**Experimental settings.** Due to computational constraints, we employ a sample size of \(N=10,000\) to estimate \(p_{A}\). The number of function evaluations (NFEs) for each image in our method is \(O(N T^{} K)\), amounting to \(10^{8}\) for \(T^{}=100\) and \(10^{9}\) for \(T^{}=1000\) since \(K=10\) in this dataset. In contrast, the NFEs for the previous state-of-the-art method  are \(4 10^{8}\), which is four times higher than our method when \(T^{}\) is 100. It is important to highlight that our sample size \(N\) is 10 times smaller than those baselines in (Table 1), potentially placing our method at a significant disadvantage, especially for large \(_{}\).

**Experimental results.** As shown in Table 1, our method, utilizing an off-the-shelf model without the need for extra data, significantly outperforms all previous methods at smaller values of \(=\{0.25,0.5\}\). Notably, it surpasses all previous methods on clean accuracy, and exceeds the previous state-of-the-art method  by \(5.6\%\) at \(=0.25\) and \(6.1\%\) at \(=0.5\). Even with larger values of \(\), our method attains performance levels comparable to existing approaches. This is particularly noteworthy considering our constrained setting of \(N=10,000\), substantially smaller than the \(N=100,000\) used in prior works. Considering that the community of randomized smoothing employs hypothesis tests to establish a probabilistic upper bound of the smoothed function, with consistent type-one error rates, our method encounters significant disadvantages. This is particularly the case since, with equivalent accuracy on noisy data, certified robustness is a monotonically

   Method & Off-the-shelf & Extra data &  \\  & & 0.25 & 0.5 & 0.75 & 1.0 \\  RS  & ✗ & ✗ & \({}^{(45.5)}\)37.3 & \({}^{(45.5)}\)26.6 & \({}^{(37.0)}\)20.9 & \({}^{(37.0)}\)15.1 \\ SmoothAdv  & ✗ & ✗ & \({}^{(44.4)}\)37.4 & \({}^{(44.4)}\)27.9 & \({}^{(34.7)}\)21.1 & \({}^{(34.7)}\)17.0 \\ Consistency  & ✗ & ✗ & \({}^{(43.6)}\)36.9 & \({}^{(43.6)}\)31.5 & \({}^{(43.6)}\)26.0 & \({}^{(31.4)}\)16.6 \\ MACER  & ✗ & ✗ & \({}^{(46.3)}\)35.7 & \({}^{(46.3)}\)27.1 & \({}^{(46.3)}\)15.6 & \({}^{(38.7)}\)11.3 \\ Carlini  & ✓ & ✗ & \({}^{(41.1)}\)37.5 & \({}^{(39.4)}\)30.7 & \({}^{(39.4)}\)24.6 & \({}^{(39.4)}\)21.7 \\ DensePure  & ✓ & ✗ & \({}^{(37.7)}\)35.4 & \({}^{(37.7)}\)29.3 & \({}^{(37.7)}\)26.0 & \({}^{(37.7)}\)18.6 \\ APNDC (Sift-and-Refine, ours) & ✓ & ✗ & \({}^{()}\)**46.3** & \({}^{()}\)**38.3** & \({}^{()}\)**35.2** & \({}^{()}\)**32.8** \\   

Table 2: Certified accuracy at ImageNet-64x64. The clean accuracy is in the parentheses.

increasing function with respect to sample size \(N\). However, we still achieve competitive performance despite its inherent sample size disadvantage.

### Results on ImageNet

Experimental settings.We conduct experiments on ImageNet64x64 due to the absence of conditional diffusion models for 256x256 resolution. Due to computational constraints, we employ a sample size of \(N=1000\), 10 times smaller than all other works in Table 2. We use the Sift-and-Refine algorithm to improve the efficiency.

Experimental results.As demonstrated in Table 2 and Figure 2(c), our method, only employing a single off-the-shelf diffusion model without requiring extra data, significantly outperforms previous training-based and training-free approaches. In contrast, diffusion-based purification methods, when applied with small CNNs and no extra data, do not maintain their superiority over training-based approaches. It is noteworthy that our experiments are conducted with only one-tenth of the sample size typically used in previous works. This success on a large dataset like ImageNet64x64 underscores the scalability of diffusion classifiers in handling extensive datasets with a larger number of classes.

### Discussions

Comparison with heuristic methods.From a heuristic standpoint, one might consider initially using a diffusion model for denoising, followed by a diffusion classifier for classification. As shown in Table 1, this heuristic approach outperforms nearly all prior off-the-shelf and no-extra-data baselines. However, the methods derived through our theoretical analysis significantly surpass this heuristic strategy. This outcome underscores the practical impact of our theoretical contributions.

Trivial performance of EPNDC.Although EPNDC exhibits non-trivial improvements compared to previous methods, it still lags significantly behind APNDC. There are two main reasons for this gap. First, as extensively discussed in Appendix C.2, the weight in EPNDC is not optimal, and we cannot theoretically determine the optimal weight. Additionally, APNDC is equivalent to an ensemble of EPNDC, which may contribute to its superior performance compared to EPNDC.

Explanation of Eq. (11).Eq. (11) is extremely similar to _the weak law of randomized smoothing_. When \(_{t}\) is larger, it could potentially have a larger certified radius, but the input images will be more noisy and hard to classify. This trade-off is quite similar to the role of \(_{}\) in randomized smoothing. However, there are two key differences. First, the inputs to the network contain different levels of noisy images, which means the network could see clean images, less noisy images, and very noisy images, hence could make more accurate predictions. Besides, the trade-off parameter is \(}{_{t}}\), allowing users some freedom to select different noise levels and balance them by \(w_{t}\). We observe that this is the common feature of such denoising and reconstructing classifiers. We anticipate this observation will aid the community in developing more robust and certifiable defenses.

Figure 2: (a) The accuracy (%) on CIFAR-10 dataset with time complexity reduction technique in Chen et al.  and ours. (b, c) The upper envelop of certified radii of different methods.

Conclusion

In this work, we conduct a comprehensive analysis of the robustness of diffusion classifiers. We establish their non-trivial Lipschitzness, a key factor underlying their remarkable empirical robustness. Furthermore, we extend the capabilities of diffusion classifiers to classify noisy data at any noise level by deriving the evidence lower bounds for noisy data distributions. This advancement enable us to combine the diffusion classifiers with randomized smoothing, leading to a tighter certified radius. Experimental results demonstrate substantial improvements in certified robustness and time complexity. We hope that our findings contribute to a deeper understanding of diffusion classifiers in the context of adversarial robustness and help alleviate concerns regarding their robustness.