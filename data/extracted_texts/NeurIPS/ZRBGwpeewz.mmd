# Revisiting Area Convexity: Faster Box-Simplex Games and Spectrahedral Generalizations

Arun Jambulapati

Simons Institute

jmblpati@berkeley.edu

&Kevin Tian

University of Texas at Austin

kjtian@cs.utexas.edu

Work completed at the University of Washington.Work completed at Microsoft Research.

###### Abstract

We investigate different aspects of area convexity , a mysterious tool introduced to tackle optimization problems under the challenging \(_{}\) geometry. We develop a deeper understanding of its relationship with more conventional analyses of extragradient methods . We also give improved solvers for the subproblems required by variants of the  algorithm, designed through the lens of relative smoothness .

Leveraging these new tools, we give a state-of-the-art first-order algorithm for solving box-simplex games (a primal-dual formulation of \(_{}\) regression) in a \(d n\) matrix with bounded rows, using \(O( d^{-1})\) matrix-vector queries. Our solver yields improved runtimes for approximate maximum flow, optimal transport, min-mean-cycle, and other basic combinatorial optimization problems. We also develop a near-linear time algorithm for a matrix generalization of box-simplex games, capturing a family of problems closely related to semidefinite programs recently used as subroutines in robust statistics and numerical linear algebra.

## 1 Introduction

Box-simplex, or \(_{}\)-\(_{1}\), games are a family of optimization problems of the form

\[_{x[-1,1]^{n}}_{y^{d}}x^{}y-b^{}y+c^{ }x.\] (1)

These problems are highly expressive, as high-accuracy solutions capture linear programs (LPs) as a special case .3 More recently, approximation algorithms for the family (1) have been applied to improve runtimes for applications captured by LPs naturally bounded in the \(_{}\) geometry. The current state-of-the-art first-order method for (1) is by Sherman , who used the resulting solver to obtain a faster algorithm for the maximum flow problem. As further consequences, solvers for (1) have sped up runtimes for optimal transport , a common task in modern computer vision , and min-mean-cycle , a basic subroutine in solving Markov decision processes , among other combinatorial optimization problems .

The runtimes of first-order methods for approximating (1) are parameterized by an additive accuracy \(>0\) and a Lipschitz constant4\(L:=\|\|_{1 1}\); in several prominent applications of (1) where the relevant \(\) has favorable structure, e.g. the column-sparse edge-vertex incidence matrix of a graph, \(L\) is naturally small. Standard non-Euclidean variants of gradient descent solve a smoothed variant of (1) using \((L^{2}^{-2})\) matrix-vector products with \(\) and \(^{}\). Untilrecently however, the lack of accelerated algorithms for (1) (using a quadratically smaller \((L^{-1})\) matrix-vector products) was a notorious barrier in optimization theory. This barrier arises due to the provable lack of a strongly convex regularizer in the \(_{}\) geometry with dimension-independent additive range ,5 a necessary component of standard non-Euclidean acceleration schemes.

Sherman's breakthrough work  overcame this obstacle and gave an algorithm for solving (1) using roughly \(O(L(d)(L^{-1})^{-1})\) matrix-vector products.6 Roughly speaking, Sherman exploited the primal-dual nature of the problem (1) to design a smaller regularizer over the \(_{}\) ball \([-1,1]^{n}\), which satisfied a weaker condition known as _area convexity_ (rather than strong convexity). The algorithm in  combined an extragradient method "outer loop" requiring \(O(L d^{-1})\) iterations, and an alternating minimization subroutine "inner loop" solving the subproblems required by the outer loop in \(O((L^{-1}))\) steps. However, Sherman's analysis in  was quite ad hoc, and its relationship to more standard optimization techniques has remained mysterious. These mysteries have made further progress on (1) and related problems challenging in several regards.

1. Sherman's algorithm pays a logarithmic overhead in the complexity of its inner loop to solve subproblems to high accuracy. Does it tolerate more approximate subproblem solutions?
2. The analysis of Sherman's alternating minimization scheme relies on multiplicative stability properties of the dual variable \(y\). In generalizations of (1) where the dual variable is unstable, how do we design solvers handling instability to maintain fast subproblem solutions?
3. The relationship between the area convexity definition  and more standard Bregman divergence domination conditions used in classical analyses of extragradient methods  is unclear. Can we unify these extragradient convergence analyses?

A central goal of this work is to answer Question 3 by revisiting the area convexity technique of , and developing a deeper understanding of its relationship to more standard tools in optimization theory such as relative smoothness  and the classical extragradient methods of . We summarize these insights in Section 2 and give self-contained expositions in Appendices A and B of the supplement. As byproducts, our improved understanding of area convexity results in new state-of-the-art runtimes for (1) by affirmatively answering Question 1, and the first accelerated solver for a matrix generalization by affirmatively answering Question 2.

### Our results

**Box-simplex games.** We give an algorithm for solving (1) improving the runtime of  by a logarithmic factor, by removing the need for high-accuracy inner loop solutions.7

**Theorem 1**.: _There is an algorithm (stated in full as Algorithm 4 in the supplement) deterministically computing an \(\)-approximate saddle point to (1) in time_

\[O(()\|_{1 1} d}{ }).\]

We define nnz and \(\|\|_{1 1}\) in Section 1.3. The most direct comparison to Theorem 1 is the work , which we improve. All other first-order methods for solving (1) we are aware of are slower than  by at least an \((^{-1},)\) factor. Higher-order methods for (1) (e.g. interior point methods) obtain improved dependences on \(\) at the cost of polynomial overhead in the dimension.

As a byproduct of Theorem 1, we improve all the recent applications of (1), including approximate maximum flow , optimal transport , min-mean-cycle , and semi-streaming variants of bipartite matching and transshipment . These are summarized in Section 5 of the supplement. The design of efficient approximate solvers for optimal transport in particular is a problem which has received a substantial amount of attention from the learning theory community (see Table 1 and the survey ). The runtime of Theorem 1 represents a natural conclusion to this line of work.8 We believe our improvement in Theorem 1 (avoiding a high-accuracy subproblem solve) takes an important step towards bridging the state-of-the-art in the theory and practice of optimal transport, a well-motivated undertaking due to its widespread use in applications.

**Box-spectraplex games.** We initiate the algorithmic study of box-spectraplex games of the form

\[_{x[-1,1]^{n}}_{^{d d}},_{i[n]}x_{i}_{i}-, +c^{}x,\] (2)

where \(\{_{i}\}_{i[n]},\,\) are \(d d\) symmetric matrices and \(\) satisfies \(()=1\) (i.e. \(^{d d}\), cf. Section 1.3). This family of problems is a natural formulation of semidefinite programming (SDP), and generalizes (1), the special case of (2) where all of the matrices \(\{_{i}\}_{i[n]},\,,\,\) are diagonal.

Our main result on solving (2), stated below as Theorem 2, has already found use in  to obtain faster solvers for spectral sparsification and related discrepancy-theoretic primitives, where existing approximate SDP solvers do not apply. Beyond the fundamental nature of the problem solved by Theorem 2, we are optimistic that it will find use in other applications of structured SDPs.

To motivate our investigation of (2), we first describe some history of the study of the simpler problem (1). Many applications captured by (1) are structured settings where optimization is at a _relative scale_, i.e. we wish to obtain an \((1+)\)-multiplicative approximation to the value of a LP, \(:=_{ b}c^{}x\). We use bipartite matching as an example: \(x\) is a fractional matching and \(\) is a nonnegative edge-vertex incidence matrix. For LPs with a nonnegative constraint matrix \(\), custom positive LP solvers achieve \((1+)\)-multiplicative approximations at accelerated rates scaling as \((^{-1})\). This result then implies a \((^{-1})\)-rate algorithm for approximating bipartite matching and its generalization, optimal transport (where the first such algorithm used positive LP solvers ). However, existing accelerated positive LP solvers  are both sequential and randomized, and whether this is necessary has persisted as a challenging open question.

In several applications with nonnegative constraint matrices , this obstacle was circumvented by recasting the problem as a box-simplex game (1), for which faster, deterministic, and efficiently-parallelizable solvers exist (see e.g. Section 4.1 of  for the bipartite matching reduction).9 In these cases, careful use of box-simplex game solvers (and binary searching for the problem scale) match the guarantees of positive LP solvers, with improved parallelism or determinism. Notably, simpler primitives such as simplex-simplex game solvers do not apply in these settings.

The current state-of-affairs in applications of fast SDP solvers is very similar. For various problems in robust statistics (where the goal is to approximate a covariance matrix or detect a corruption

   Method & Runtime & Comments \\ 
 & \(O(d^{2} d^{-3})\) & \\
 & \(O(d^{2} d^{-2})\) & \\
 & \(O(d^{2.5}^{-1})\) & \\
 & \(O(d^{2}(d)(^{-1})^{-1})\) & sequential, randomized \\
 & \(O(d^{2}^{-1}+d^{-2})\) & sequential \\
 & \(O(d^{2}(d)(^{-1})^{-1})\) & \\
 & \(O(d^{7/3}^{-4/3})\) & \\  Theorem 1 & \(O(d^{2} d^{-1})\) & \\   

Table 1: **Runtime complexities of first-order algorithms for optimal transport.** Stated for a \(d d\) cost matrix with unit-bounded costs, additive error tolerance \(\). Results labeled “sequential” require a parallel depth which scales polynomially in the problem dimension \(d\).

spectrally)  and numerical linear algebra (where the goal is to reweight or sparsify a matrix sum) , positive SDP solvers have found utility. However, these uses appear quite brittle: current positive SDP solvers  only handle the special case of packing SDPs (a special class of positive SDP with one-sided constraints), preventing their application in more challenging settings (including pure covering SDPs).

In an effort to bypass this potential obstacle when relying on positive SDP solvers more broadly, we therefore develop a nearly-linear time solver for box-spectraplex games in Theorem 2 (we define \(_{}\), the time required to perform a matrix-vector product, in Section 1.3).

**Theorem 2**.: _There is an algorithm which computes an \(\)-approximate saddle point to (2) in time_

\[O((_{}()+_{i[n]}( _{}(_{i})+_{}(|_{ i}|)))^{3}( )}{^{3.5}}),\]

_with probability \( 1-\), for \(L:=\|_{i[n]}|_{i}|\|_{}+\| \|_{}\). A deterministic variant uses time_

\[O(((_{}()+_{i[n]}( _{}(_{i})+_{}(|_{ i}|))) d+d^{}))}{}).\]

Theorem 2 follows as a special case of Theorem 3 in the supplement, which has refined guarantees stated in terms of the cost to perform certain queries of matrix exponentials required by our algorithm, typical of first-order methods over \(^{d d}\). The first runtime in Theorem 2 implements these queries using randomized sketching tools, and the second uses an exact implementation. Beyond its generic utility, we find Theorem 2 conceptually interesting, as its development used our relative smoothness viewpoint on area convexity in Section 2 (for overcoming instability of dual matrix variables), and new techniques for proving area convexity of a matrix variant of the  regularizer.

To put Theorem 2 in context, we compare it to existing solvers for simplex-spectraplex games, a relative of (2) where both players are \(_{1}\) constrained. Simplex-spectraplex games are more well-studied , and the state-of-the-art algorithms  query \((L^{2.5}^{-2.5})\) vector products in \(\{_{i}\}_{i[n]}\) and \(\). A slight variant of these algorithms (using a separable regularizer in place of area convex techniques) gives a complexity of \((n L^{2.5}^{-2.5})\) such queries for the more challenging box-spectraplex games (2), which is the baseline in the literature. In comparison, Theorem 2 requires \((L^{3.5}^{-3.5})\) products, but assumes access to \(\{|_{i}|\}_{i[n]}\). This is not without loss of generality, as \(||\) can be dense even when \(\) is sparse, though in important robust statistics or spectral sparsification applications (where \(\{_{i}\}_{i[n]}\) are rank-one), it is not restrictive. We find it interesting to understand whether access to \(\{|_{i}|\}_{i[n]}\) and the \((L^{-1})\) overhead in Theorem 2 (due to higher-rank randomized sketches) can be avoided.

### Related work

The family of box-simplex games (1) is captured by linear programming , where state-of-the-art solvers  run in time \(((n+d)^{})\) or \((nd+(n,d)^{2.5})\), where \( 2.37\) is the current matrix multiplication constant . These LP solvers run in superlinear time, and practical implementations do not currently exist; on the other hand, the convergence rates depend polylogarithmically on the accuracy parameter \(L^{-1}\). The state-of-the-art approximate solver for (1) (with runtime depending linearly on the input size \(()\) and polynomially on \(L^{-1}\)) is the accelerated algorithm of , which is improved by our Theorem 1 by a logarithmic factor. Finally, we mention  as another recent work which relies on area convexity techniques to design an algorithm in a different problem setting; their inner loop also requires high-precision solves (as in ), and this similarly results in a logarithmic overhead in the runtime.

For the specific application of optimal transport, a problem captured by (1) receiving significant recent attention from the learning theory community, several alternative solvers have been developed beyond Table 1. By exploiting relationships between Sinkhorn regularization and faster solvers for matrix scaling ,  gave an alternative solver obtaining a \((n^{2}^{-1})\) rate. These algorithms call specialized graph Laplacian system solvers as a subroutine, which are currently less practical than our methods based on matrix-vector queries. Finally, the recent breakthrough maximum flow algorithm of  extends to solve optimal transport in \(O(n^{2+o(1)})\) time (though its practicality is unclear). For moderate \( n^{-o(1)}\), this is slower than Theorem 1.

To our knowledge, there have been no solvers developed tailoring specifically to the family (2). These problems are solved by general-purpose SDP solvers, where the state-of-the-art runtimes of \((n^{}+nd^{2.5})\) or \((n^{}+d^{4.5}+n^{2})\) are highly superlinear (though again depend polylogarithmically on the inverse accuracy). We believe our techniques in proving Theorem 2 extend to show that a variant of gradient descent in the \(_{}\) geometry  solves (2) in an unaccelerated \((L^{2}^{-2})\) iterations, with the same per-iteration complexity as Theorem 2.

### Notation

**General notation.** We use \(\) to suppress polylogarithmic factors in problem parameters for brevity. Throughout \([n]:=\{i 1 i n\}\) and \(_{p}\) is the \(_{p}\) norm. We refer to the dual space (bounded linear operators) of a set \(\) by \(^{*}\). The all-zeroes and all-ones vectors in dimension \(d\) are denoted \(_{d}\) and \(_{d}\). When \(u,v\) are vectors of equal dimension, \(u v\) denotes their coordinatewise multiplication. For \(^{n d}\) we denote its \(i^{}\) row (for \(i[n]\)) by \(_{i:}\) and \(j^{}\) column (for \(j[d]\)) by \(_{:j}\). For \(p,q 1\) we define \(_{p q}:=_{ v_{p }=1}v_{q}\). The number of nonzero entries in \(\) is denoted \(()\), and \(_{}()\) is the time it takes to multiply a vector by \(\). We use \((x,-1,1)\) to project \(x\) onto \([-1,1]\), where med means median. We define the \(d\)-dimensional simplex and the \(d d\) supertaplex \(^{d}:=\{y_{ 0}^{d} y_{1}=1\}\) and \(^{d d}:=\{_{ 0}^{d d} =1\}\). Throughout we reserve \(h(y):=_{j[d]}y_{j} y_{j}\) (for \(y^{d}\)) for negated (vector) entropy.

**Optimization.** For convex function \(f\), \( f(x)\) refers to the subgradient set at \(x\); we sometimes use \( f\) to denote any (consistently chosen) subgradient. Following , we say \(f\) is \(L\)-relatively smooth with respect to convex function \(r\) if \(Lr-f\) is convex, and we say \(f\) is \(m\)-strongly convex with respect to \(r\) if \(f-mr\) is convex. For a differentiable convex function \(f\) we define the associated Bregman divergence \(V_{x}^{f}(x^{}):=f(x^{})-f(x)- f(x),x^{}-x\), which satisfies the identity

\[ V_{x}^{f}(x^{}),u-x^{}= f(x^{ })- f(x),u-x^{}=V_{x}^{f}(u)-V_{x^{}}^{f}(u)-V_ {x}^{f}(x^{}).\] (3)

For convex function \(f\) on two variables \((x,y)\), we use \(_{y}f(x,y)\) to denote the subgradient set at \(y\) of the restricted function \(f(x,)\). We call a function \(f\) of two variables \((x,y)\) convex-concave if its restrictions to the first and second block are respectively convex and concave. We call \((x,y)\) an \(\)-approximate saddle point if its _duality gap_, \(_{y^{}}f(x,y^{})-_{x^{}} f(x^{},y)\), is at most \(\). For differentiable convex-concave function \(f\) clear from context, its subgradient operator is \(g(x,y):=(_{x}f(x,y),-_{y}f(x,y))\); when \(f\) is differentiable, we will call this a gradient operator. We say operator \(g\) is monotone if for all \(w,z\) in its domain, \( g(w)-g(z),w-z 0\): examples are the subgradient of a convex function or subgradient operator of a convex-concave function.

### Organization

We summarize our improved area convexity insights in Section 2 (with extended expositions in the supplement), and showcase how they prove Theorem 1 in Section 3. Due to space constraints, we defer proving Theorem 2 and our applications to the supplement (Sections 4 and 5, respectively).

## 2 Revisiting area convexity

In this section and Section 3, we consider _box-simplex_ games of the form (1), for \(^{n d}\), \(b^{d}\), and \(c^{n}\). For simplicity we assume \(_{1 1} 1\), lifting this assumption (by scale invariance) in the proof of Theorem 1. We approximate saddle points to (1) by using the family of regularizers:

\[r_{}^{()}(x,y):=||y,x^{2}+  h(y),h(y):=_{j[d]}y_{j} y_{j},\] (4)

where the absolute value is applied to \(\) entrywise, and squaring is applied to \(x\) entrywise. This family was introduced by , a minor modification to a similar family given by , and has favorable properties for the geometry present in the problem (1). In the remainder of the paper,we specialize the notation \(:=[-1,1]^{n}\), and for any \(v^{n}\) we let \(_{}(v):=(v,-1,1)\) be truncation applied entrywise. We also use \(:=^{d}\) and for any \(v^{d}_{ 0}\) we let \(_{}(v):=v/\|v\|_{1}\) normalize onto \(\). We let \(:=\), and define the gradient operator of (1):

\[g(x,y):=(y+c,b-^{}x).\] (5)

We refer to the \(x\) and \(y\) components of \(g(x,y)\) by \(g^{}(x,y):=y+c\) and \(g^{}(x,y):=b-^{}x\). Finally, to minimize clutter we denote the Bregman divergence in \(r_{}^{()}\) by \(V^{()}:=V^{r_{}^{()}}\).

1. Section 2.1 presents our unification of the convergence analysis in  with more standard analyses, by way of interpreting area convexity as Bregman domination (6).
2. Section 2.2 presents several helper results from convex analysis which demonstrates how area convexity implies relative smoothness of the subproblems encountered by , leading to simpler subproblem solvers. This also gives way to developments which generalize to the matrix setting (and are crucial for our proof of Theorem 2).

Ultimately, our proof of Theorem 1 in Section 3 will build upon both of these sets of insights.

### Area convexity as Bregman domination

In Appendix B of the supplement, we analyze extragradient algorithms for approximately solving variational inequalities in an operator \(g\), i.e. which find \(z\) with small \( g(z),z-u\) for all \(u\) in the domain (in the minimax optimization setting where \(g\) is taken to be the gradient operator, e.g. the operator in (5), this corresponds to duality gap). Specifically, we analyze convergence under the following condition, weaker than previous notions in .

**Definition 1** (Relaxed relative Lipschitzness).: _We say an operator \(g:^{*}\) is \(\)-relaxed relatively Lipschitz with respect to \(r:\) if for all \((z,z^{},z^{+})\),_

\[ g(z^{})-g(z),z^{}-z^{+} V_{z}^{ r}(z^{})+V_{z^{}}^{r}(z^{+})+V_{z}^{r}(z^{+}).\]

This notion is related to and subsumes the notions of relative Lipschitzness  and area convexity  which have recently been proposed to analyze extragradient methods, which we define below. In particular, Definitions 2 and 3 were motivated by designing solvers for (1).

**Definition 2** (Relative Lipschitzness ).: _We say an operator \(g:^{*}\) is \(\)-relatively Lipschitz with respect to \(r:\) if for all \((z,z^{},z^{+})\),_

\[ g(z^{})-g(z),z^{}-z^{+} V_{z}^{ r}(z^{})+V_{z^{}}^{r}(z^{+}).\]

**Definition 3** (Area convexity ).: _We say convex \(r:\) is \(\)-area convex with respect to an operator \(g:^{*}\) if for all \((z,z^{},z^{+})\), defining \(c:=(z+z^{}+z^{+})\),_

\[ g(z^{})-g(z),z^{}-z^{+} r(z)+r( z^{})+r(z^{+})-3r(c).\]

_Area convexity is monotone in \(\) as the right-hand side is nonnegative for any \(z,z^{},z^{+}\)._

Relaxed relative Lipschitzness simultaneously generalizes relative Lipschitzness and area convexity. The relationship is obvious for Definition 2, but the generalization of Definition 3 relies on the following simple observation, which has not previously appeared explicitly to our knowledge:

\[r(z)+r(z^{})+r(z^{+})-3r(c)=V_{z}^{r}(z^{+})+V_{z}^{r}(z^{})-3V_{z} ^{r}(c) V_{z}^{r}(z^{+})+V_{z}^{r}(z^{}).\] (6)

In Appendix B of the supplement we give a framework unifying previous analyses of , possibly of further utility. The realization (6) that area convexity implies a Bregman divergence bound lets us reinterpret the  outer loop to tolerate larger amounts of inexactness in the subproblems, where inexactness is measured in Bregman divergence. We combine our improved outer loop analysis with tools leveraging relative smoothness (to be discussed) to remove alternating minimization from . We will use the following known fact.

**Fact 1** (Lemma 2, ).: _For convex functions \(f,r\), if \(f\) is \(L\)-relatively smooth with respect to \(r\), then \( f\) is \(L\)-relatively Lipschitz with respect to \(r\)._

We also summarize some useful properties of \(r_{}^{()}\) adapted from .

**Lemma 1**.: _For \(\), \(r_{}^{()}\) is jointly convex; for \( 2\), \(r_{}^{()}\) is \(\)-area convex with respect to \(g\) (5)._

### Area convexity as relative smoothness

In , the second property in Lemma 1 was used with an ad hoc outer loop analysis (unified with existing analyses in Appendix B of the supplement) to prove convergence. However, it remains to discuss how to implement steps of the outer loop method, each of which solves a regularized subproblem of the form, for \((g^{},g^{})^{*}^{*}\) (and recalling our regularizer (4))

\[_{x[-1,1]^{n},y^{d}}F(x,y):= g^{},x+  g^{},y+||y,x^{2}+  h(y).\]

These subproblem forms are standard for mirror descent-based methods (including extragradient methods). In contrast to schemes using separable regularizers (admitting closed-form solutions), the subproblems induced by (4) themselves require an iterative method to solve. In , a linearly-convergent minimization subroutine for \(F\) was given based on multiplicative stability of simplex variables, using a fairly nonstandard analysis (see Lemma 6, ). Our next observation is that a linearly-convergent subproblem solver follows off-the-shelf from  and viewing area convexity under the lens of _relative smoothness_, a more standard condition in optimization theory. We use the following convex analysis facts, deferring proofs to Section 3.2 of the supplement.

**Lemma 2**.: _Let \(^{m}\) and \(^{n}\) be convex compact subsets. Suppose \(F:\) is jointly convex over its argument \((x,y)\). For \(y\), define \(x_{}(y):=*{argmin}_{x}F(x,y)\) and \(f(y):=F(x_{}(y),y)\). Then for all \(y\), \(_{y}F(x_{}(y),y) f(y)\)._

**Lemma 3**.: _In the setting of Lemma 2, suppose for any \(x\), \(F(x,)\) (as a function over \(\)) always is \(r:\) plus a linear function (where the linear function may depend on \(x\)). Then \(r-f\) is convex, and \(f-q\) is convex for any \(q:\) such that \(F-q:\) is jointly convex._

Recall from Lemma 1 that \(F\) is jointly convex over \((x,y)\) for any \(\). Hence, for \(=2\), we may apply Lemma 3 with \(r(y):=2h(y)\) to conclude that \(f(y):=_{x[-1,1]^{n}}F(x,y)\) is \(2\)-relatively smooth with respect to \(h\), as a function over \(=^{d}\). Moreover, applying Lemma 3 with \(q(y):=h(y)\), and again using the joint convexity fact in Lemma 1, shows that \(f\) is further \(1\)-relatively strongly convex with respect to \(h\). At this point, a direct application of Theorem 3.1 in  (which gives an algorithm for optimization under relative smoothness and strong convexity) yields a linearly-convergent algorithm for minimizing \(F\). We remark that in light of Lemma 2, we can implement gradient queries to \(f\) by computing the best response argument for a given \(y\).

Interestingly, this argument used nothing more than Lemma 3, joint convexity of \(r_{}^{()}\), and the ability to tune \(\) to induce relative strong convexity (in contrast to , which requires multiplicative stability properties). An important consequence is that the same technique generalizes to the matrix setting via new joint convexity facts we prove in Section 4 of the supplement, where multiplicative stability breaks due to non-monotonicity of matrix exponentials; the corresponding subproblem analysis in  hence does not apply. This gives a simple proof-of-concept matching Theorem 2 up to logarithmic factors, which we improve via our approximation-tolerant extragradient methods.

## 3 Box-simplex games without alternating minimization

In this section, we show how to combine the insights regarding area convexity from Section 2, along with a careful implementation of our inner loop subproblem solvers, to prove Theorem 1.

### Approximation-tolerant extragradient method

We begin by stating two oracles whose guarantees, when combined with Definition 3, give our conceptual algorithm for (1). These oracles can be viewed as approximately implementing steps of the extragradient method framework in Appendix B of the supplement. We develop subroutines which satisfy these relaxed definitions in the following Section 3.2. In the following definitions (and throughout), we let \(V^{()}:=V^{r_{}^{()}}\) be the divergence associated with \(r_{}^{()}\) for notational convenience.

**Definition 4** (Gradient step oracle).: _For a problem (1), we say \(_{}:^{*}\) is an \((,)\)-gradient step oracle if on input \((z,v)\), it returns \(z^{}\) such that_

\[ v,z^{}-u V_{z}^{(+)}(u)-V_{z^{}}^{( )}(u)-V_{z}^{()}(z^{})u.\]

**Definition 5** (Extragradient step oracle).: _For a problem (1), we say \(_{}}:^{*} \) is an \((,)\)-extragradient step oracle if on input \((z,v,)\), it returns \((z^{+},^{+})\) such that_

\[v,z^{+}-u V_{z}^{()}(u)-V_{z^{+}}^{( )}(u)-V_{z}^{()}(z^{+})+V_{}^{ h}(u^{y})-V_{^{+}}^{  h}(u^{y})u=(u^{}},u^{}}) .\]

When \(=0\), Definitions 4 and 5 reduce to the conventional proximal oracle steps used by the extragradient method of . In our solver for (1), we use \(>0\) to compensate for our inexact subproblem solves. The asymmetry in Definitions 4 and 5 reflect an asymmetry in the analyses of extragradient methods. In typical analyses, the regret is bounded for the "gradient oracle" points, but the regret upper bound is stated in terms of the divergences of the "extragradient oracle" points (which our inexact oracles need to compensate for).

The utility of our Definitions 3, 4, and 5 reveals itself through the following lemma.

**Lemma 4**.: _Let \(z\), \(\), \( 2\), \(, 0\) and \(0\). Let \(z^{}_{}}(z, g(z))\) and \((z^{+},^{+})_{}}(z,g (z^{}),)\), where \(_{}}\) is an \((,)\)-gradient step oracle and \(_{}}\) is an \((+,)\)-extragradient step oracle. Then for all \(u\),_

\[ g(z^{}),z^{}-u 2V_{z}^{(+)}(u)-2V_ {z^{+}}^{(+)}(u)+2V_{}^{ h}(u^{y})-2V_{^{+}}^{  h}(u^{y}).\]

Proof.: By definition of \(_{}}\) (with \(u z^{+}\)) and \(_{}}\), we have

\[ g(z),z^{}-z^{+}  V_{z}^{(+)}(z^{+})-V_{z^{}}^{()}(z^{+ })-V_{z}^{()}(z^{}),\] (7) \[ g(z^{}),z^{+}-u  2V_{z}^{(+)}(u)-2V_{z^{+}}^{(+)}(u)-2V_ {z}^{(+)}(z^{+})+2V_{}^{ h}(u^{y})-2V_{^{+}}^{  h}(u^{y}).\]

Combining yields

\[ g(z^{}),z^{}-u  2V_{z}^{(+)}(u)-2V_{z^{+}}^{(+)}(u)+2V _{}^{ h}(u^{y})-2V_{^{+}}^{ h}(u^{y})\] \[+\,g(z^{})-g(z),z^{}-z^{+} -V_{z}^{()}(z^{})-V_{z}^{(+)}(z^{+})-V_{z^{}}^{( }(z^{+})\] \[ 2V_{z}^{(+)}(u)-2V_{z^{+}}^{(+)}(u)+2V _{}^{ h}(u^{y})-2V_{^{+}}^{ h}(u^{y})\] \[+\,g(z^{})-g(z),z^{}-z^{+} -V_{z}^{()}(z^{})-V_{z}^{()}(z^{+}),\]

where in the second inequality we used that \(V^{(+)}\) dominates \(V^{()}\), and \(V_{z^{}}^{()}(z^{+}) 0\) by Lemma 1. The conclusion follows by applying Definition 3 (see (6)) and the second fact in Lemma 1. 

When \(==0\), Lemma 4 is the same as Appendix B of the supplement, and hence yields similar implications as standard extragradient methods: a scaling of the left-hand side upper bounds duality gap of \(z^{}\), and the right-hand side telescopes (and is bounded using the following standard fact).

**Lemma 5**.: _Let \(, 0\), and let \(z_{0}=(x_{0},y_{0})\) where \(x_{0}=_{n}\) and \(y_{0}=_{d}\). Then \(z_{0}\) is the minimizer of \(r_{}^{()}\) over \(\), and \(V_{z_{0}}^{()}(u) 1+ d,\ V_{y_{0}}^{ h}(u^{y})  d\) for all \(u=(u^{}},u^{}})\)._

Finally, for convenience to the reader, we put together Lemma 4 and 5 to obtain an analysis of the following conceptual "outer loop" extragradient algorithm (subject to the implementation of gradient and extragradient step oracles), Algorithm 1. Our end-to-end algorithm will be an explicit implementation of the framework in Algorithm 1; we provide a runtime analysis and error guarantee for our complete algorithm in Theorem 1, as well as pseudocode in Algorithm 4 of the supplement.

**Algorithm 1**: ConceptualBoxSimplex(\(,b,c,_{},_{}\))

```
1Input:\(^{n d}\) with \(L:=\|\|_{1 1}\), desired accuracy \((0,L)\), \(_{}\) a \((2,2)\)-gradient step oracle, \(_{}\) a \((4,4)\)-extragradient step oracle Initialize \(x_{0}_{n}\), \(y_{0}_{d}\), \(_{0}_{d}\), \(_{n}\), \(_{d}\), \(T\), \(\) Rescale \(\), \(bb\), \(cc\)
2for\(t=0\)to\(T-1\)do
3\(g_{t}(y_{t}+c,b-^{}x_{t})\)
4\(z^{t}_{t}:=(x^{}_{t},y^{}_{t})_{} (z_{t}, g_{t})\)
5\(g^{t}_{t}(y^{}_{t}+c,b-^{}x^{}_ {t})\)
6\((z_{t+1},_{t+1}):=(x_{t+1},y_{t+1},_{t+1})_{ }(z_{t},g^{}_{t},_{t})\)
7 end for Return:\((,)_{t=0}^{T-1}(x^{}_{t},y^{ }_{t})\) ```

**Algorithm 1**ConceptualBoxSimplex(\(,b,c,_{},_{}\))

**Corollary 1**.: _Algorithm 1 deterministically computes an \(\)-approximate saddle point to (1)._

Proof.: First, clearly the rescaling in Line 3 multiplies the entire problem (1) by \(\), so an \(\)-approximate saddle point to the new problem becomes an \(\)-approximate saddle point for the original. Throughout the rest of the proof it suffices to treat \(L=1\). Next, by telescoping and averaging Lemma 4 with \(==2\), \(=4\), and \(=\), we have for \(z_{0}=(x_{0},y_{0})\) and any \(u=(u^{},u^{})\)

\[_{t=0}^{T-1} g(z^{}_{t}),z^{}_{t}-u }^{(4)}(u)+V_{_{0}}^{4Lh}(u^{ }))}{T}.\]

The last inequality used the bounds in Lemma 5 and the definition of \(T\). Moreover since \(g\) is bilinear, and \(:=(,)\) is the average of the \(z^{}_{t}\) iterates, we have \( g(),-u\). Taking the supremum over \(u\) bounds the duality gap of \(\) and gives the conclusion. 

### Implementing oracles

In this section, we give generic constructions of gradient and extragradient step oracles.10

**Input:**\(z=(x,y)\), \(v=(v^{},v^{})^{*}\), \(, 0\)

\(y^{}_{} v^{ }+_{y}r_{}^{()}(x_{}(y),y)-_{y}r_{ }^{()}(z),+V_{y}^{ h}()\), where for all \(\),

\[x_{}():=_{} v^{ }-_{x}r_{}^{()}(z),+r_{ }^{()}():=(,)\] (8)

\(x^{} x_{}(y^{})\)

**Return:**\((x^{},y^{})\)

**Lemma 6**.: _For \(\), Algorithm 2 is an \((,)\)-gradient step oracle._

Proof.: By (3) and the first-order optimality condition for \(y^{}\), we have for any \(u=(u^{},u^{y})\),

\[ v^{y}+_{y}r_{}^{()}(x_{}(y),y)- _{y}r_{}^{()}(z),y^{}-u^{y} V_{y}^{  h}(u^{y})-V_{y^{}}^{ h}(u^{y})-V_{y}^{ h}(y^{}).\] (9)

Further, define for any \(\),

\[f():= v,+V_{z}^{()}():=(x_{}(),).\] (10)

Note that \(f\) is a partial minimization of a function on two variables which is a linear term plus \(r_{}^{()}\), which is convex by Lemma 1. For any fixed \(x\), \(r_{}^{()}(x,y)\) is itself \( h(y)\) plus a linear function.

Lemma 3 then shows \(f\) is \(\)-relatively smooth with respect to \(h\). We then have for all \(,u^{}\),

\[_{y}r^{()}_{}(x_{ }(),)-_{y}r^{()}_{}(x_{} (y),y),-w^{}&= f()- f(y),-u^{}\\ & V^{ h}_{y}()+V^{ h}_{}(u^{}). \] (11)

Here the equality used Lemma 2 where the linear shift between \(r^{()}_{}\) and the minimization problem inducing \(f\) cancels in the expression \( f()- f(y)\), and the inequality used Fact 1. Combining (9) and (11) (with \( y^{}\)) and using \(V^{ h}\) dominates \(V^{ h}\) yields

\[ v^{}+_{y}r^{()}_{}(z^{})-_{ y}r^{()}_{}(z),y^{}-u^{} V^{ h }_{y}(u^{}).\] (12)

Finally, first-order optimality of \(x^{}\) with respect to the objective induced by \(y^{}\) implies for all \(u^{}\),

\[ v^{}+_{x}r^{()}_{}(z^{})- _{x}r^{()}_{}(z),x^{}-u^{} 0,\] (13)

so combining with (12) we have for \(u=(u^{},u^{})\), \( v+ r^{()}_{}(z^{})- r^{() }_{}(z),z^{}-u V^{ h}_{y}(u^{})\). The conclusion follows by using the identity (3) to rewrite \( r^{()}_{}(z^{})- r^{()}_{ }(z),u-z^{}\). 

```
1Input:\(z=(x,y)\), \(v=(v^{},v)^{*}\), \(\), \(, 0\)
2\(y^{+}_{} v^{}+ _{y}r^{()}_{}(x_{}(),)-_{ y}r^{()}_{}(z),+V^{ h}_{}()\) (following (8))
3\(x^{+} x_{}(y^{+})\)
4\(^{+}_{} v^{ }+_{y}r^{()}_{}(x^{+},y^{+})-_{y}r^{()}_{ }(z),+V^{ h}_{}()\)
5Return:\((x^{+},y^{+},^{+})\) ```

**Algorithm 3**XGradStepOracle(\(z,v,,,\))

We defer a proof of the following to Section 3.2 of the supplement, as it is similar to Lemma 6. We remark that the auxiliary sequence \(,^{+}\) used in the extragradient step oracle definition is itself inspired by running a few steps of a descent method on the subproblem, inducing a telescoping divergence sequence used by the outer loop to pay for inaccuracy in the subproblem solution.

**Lemma 7**.: _For \(\), Algorithm 3 is an \((,)\)-extragradient step oracle._

### Proof of Theorem 1

**Theorem 1**.: _There is an algorithm (stated in full as Algorithm 4 in the supplement) deterministically computing an \(\)-approximate saddle point to (1) in time_

\[O(()\|_{1 1}  d}{}).\]

Proof.: We briefly describe the algorithm from the supplement for completeness here, as correctness follows straightforwardly from combining Corollary 1 with Lemmas 6 and 7. The algorithm is an instance of the conceptual Algorithm 1. Each step of Algorithm 1 then first implements Algorithm 2 (used in Lemma 6), with the parameters required by Lemma 4, to obtain a gradient step oracle. Similarly, it next implements Algorithm 3 (used in Lemma 7), with the parameters required by Lemma 4, to obtain an extragradient step oracle. Correctness follows from Corollary 1. For the runtime, without loss of generality \(()(n,d)\) (else we may drop columns or rows appropriately), and each of \(T\) iterations is dominated by a constant number of matrix-vector multiplications.