# BioTrove: A Large Curated Image Dataset Enabling AI for Biodiversity

Chih-Hsuan Yang\({}^{1,*}\)

Ben Feuer\({}^{2,*}\)

Zaki Jubery\({}^{1}\)

Zi K. Deng\({}^{3}\)

Andre Nakkab\({}^{2}\)

Md Zahid Hasan\({}^{1}\)

Shivani Chiranjeevi\({}^{1}\)

Kelly Marshall\({}^{2}\)

Nirmal Baishnab\({}^{1}\)

Asheesh K Singh\({}^{1}\)

Arti Singh\({}^{1}\)

Soumik Sarkar\({}^{1}\)

Nirav Merchant\({}^{3}\)

Chinmay Hegde\({}^{2}\)

Baskar Ganapathysubramanian\({}^{1}\)

###### Abstract

We introduce BioTrove, the largest publicly accessible dataset designed to advance AI applications in biodiversity. Curated from the iNaturalist platform and vetted to include only research-grade data, BioTrove contains 161.9 million images, offering unprecedented scale and diversity from three primary kingdoms: _Antimalia_ ("animals"), _Fungi_ ("fungi"), and _Plantae_ ("plants"), spanning approximately 366.6K species. Each image is annotated with scientific names, taxonomic hierarchies, and common names, providing rich metadata to support accurate AI model development across diverse species and ecosystems.

We demonstrate the value of BioTrove by releasing a suite of CLIP models trained using a subset of 40 million captioned images, known as BioTrove-Train. This subset focuses on seven categories within the dataset that are underrepresented in standard image recognition models, selected for their critical role in biodiversity and agriculture: _Aves_ ("birds"), _Arachinda_ ("spiders/ticks/mites"), _Insecta_ ("insects"), _Plantae_ ("plants"), _Fungi_ ("fungi"), _Mollusca_ ("snails"), and _Reptilia_ ("snakes/lizards"). To support rigorous assessment, we introduce several new benchmarks and report model accuracy for zero-shot learning across life stages, rare species, confounding species, and multiple taxonomic levels.

We anticipate that BioTrove will spur the development of AI models capable of supporting digital tools for pest control, crop monitoring, biodiversity assessment, and environmental conservation. These advancements are crucial for ensuring food security, preserving ecosystems, and mitigating the impacts of climate change. BioTrove is publicly available, easily accessible, and ready for immediate use.

## 1 Introduction

AI advances are poised to play a crucial role in biodiversity conservation, ecology management, and agriculture. Already, AI tools have been shown to enable automated species identification, monitoring of ecological changes, and optimization of crop management . However, standard AI approaches for biodiversity applications persistently face major challenges. Training datasets are labor-intensive and costly to create; they cover only a narrow set ofvisual concepts; standard vision models excel at single tasks but require extensive retraining for new tasks; models often struggle with generalizing to unseen labels and new environments, limiting their effectiveness in real-world applications . Models that perform well on benchmarks often fail in the wild . Standard computer vision datasets (ImageNet and its successors) have significant limitations, including incorrectly labeled images, geographical and cultural biases, and overlapping or ill-defined labels, all of which impair the development of high-performant AI models . Consequently, there is a critical need for large, diverse, accurately annotated datasets that are specific to biodiversity, ecology, and agricultural research .

In response to this need, several datasets have been introduced. Perhaps the most well-known (raw) pool of biodiversity images on the Web is iNaturalist , from which several curated datasets have been sourced, among them being iNat2021  with 2.7M images of over 10,000 species of plants, animals, and fungi. However, insects (which comprise a very large fraction of extant species) are under-represented in this dataset. IP102 , Insecta , and the more recent BioScan-1M , are alternative datasets that focus on the Insecta Class. Perhaps the latest advance in such research is TreeOfLife-10M , which is currently the state-of-the-art dataset of text-annotated biological images, comprising 10M images with approximately 450K unique taxonomic classes.

In this paper, we contribute to advancing biodiversity AI research by curating and releasing **BioTrove**, a dataset comprising **161.9 million captioned images** across approximately **366.6K species**. This dataset surpasses all previous collections in both scale and diversity, representing the largest publicly available, "AI-ready" dataset of curated biodiversity images. Each image in BioTrove is paired with language data and spans a diverse range of

Figure 1: **Top Seven Phyla in the BioTrove Dataset. This figure displays the seven most frequently occurring phyla within BioTrove, which is curated to include data exclusively from the three primary kingdoms: Animalia, Plantae, and Fungi. For each phylum, the five most common species are shown, including their scientific names, common names, and the number of images per species. The phyla are ordered by species diversity, with the most diverse phylum on the right and the least diverse on the left.**

taxonomic groups, including _Reptilia_ (reptiles), _Plantae_ (plants), _Mollusca_ (mollusks), _Mammalia_ (mammals), _Insecta_ (insects), _Fungi_ (fungi), _Aves_ (birds), _Arachnida_ (archinds), _Animalia_ (animals), _Amphibia_ (amphibians), and _Actinoptergii_ (ray-finned fish). The dataset spans global regions, supporting robust training across diverse environmental contexts. Representative examples are shown in Figure 1, and additional details are provided on the project website.

Each image in BioProve originates from the iNaturalist community science platform  and is annotated with detailed metadata, including the common name, scientific name, and complete taxonomic hierarchy. This curated metadata provides research-grade high-quality text annotations that enhance AI model training. Additionally, we open-source a data management pipeline, BioProve-Process, to facilitate interaction with BioProve metadata. With BioProve-Process, researchers can efficiently filter and balance data by selecting specific taxonomic categories, adjusting for taxonomy level, and managing species distribution to reduce skewness. This enables users to create custom subsets that align with their research goals while maintaining consistency in species representation.

To showcase the capabilities of BioProve, we introduce two technical contributions. First, we train and release BioProve-CLIP, a suite of vision-language foundation models, using a subset, BioProve-Train, consisting of approximately 40M images from BioProve and representing around 33K species. This subset, constructed with BioProve-Process, includes diverse taxa, specifically focusing on birds (_Aves_), spiders/ticks/mites (_Arachnida_), insects (_Insecta_), plants (_Plantae_), fungi (_Fungi_), snails (_Mollusca_), and snakes/lizards (_Reptilia_). These taxonomic classes were selected to capture a broad range of species--outside of charismatic megafauna--that critically impact biodiversity. The models exhibit robust generalization capabilities, demonstrating high zero-shot and few-shot performance on unseen taxa when using either common or scientific names. We anticipate that BioProve-CLIP will serve as a valuable foundation for biodiversity-related applications and can be further fine-tuned for specific research needs.

Second, we rigorously quantify the performance of our foundation models on five existing fine-grained image classification benchmarks, as well as on three newly curated test datasets. We find that BioProve-CLIP models comfortably achieve the state-of-the-art in certain settings, while both the original (OpenAI) CLIP model as well as BioCLIP  excel in certain other settings. We analyze these findings in further detail below, but overall we hope that our dataset can be used by the AI community as a testbed for further algorithmic and scaling research in fine-grained image recognition.

The remainder of this paper is organized as follows. Section 2 introduces the BioProve dataset, the dataset's salient characteristics, and a comparison with previous work. Section 3 details our curation methodology. Section 4 introduces our newly proposed test datasets and their characteristics. Section 5 details our new BioProve-CLIP models and their benchmark performance relative to previous work. Section 6 concludes with a discussion of limitations and potential future directions.

## 2 The BioProve Dataset

Characteristics.BioProve comprises over 161.9 million images spanning 372,966 species. This dataset is an order of magnitude larger than existing biodiversity datasets, such as the state-of-the-art TreeOfLife-10M dataset, which it surpasses in _scale_ by a factor of nearly 13.5\(\) while maintaining comparable _species diversity_. Figure 1 shows representative image samples, while Figure 2 displays the distribution of samples across the seven major categories with the most frequently observed species. Additionally, Figure 3 illustrates the range of phyla, taxonomic classes, orders, and families represented in the dataset.

BioProve includes only research-grade data and publicly accessible licensed content for research purposes from iNaturalist, which designates observations as research-grade once they meet strict validation criteria. To qualify, two or more experienced iNaturalist community members--naturalists, biologists, or citizen scientists--must agree on the species identification. Additionally, the observation must meet other requirements, such as a clear photograph and precise geolocation data. Recent experiments have shown that iNaturalist's Research Grade observations achieve approximately 97% accuracy, underscoring the reliability of this community-based validation process . Furthermore, iNaturalist continuously enhances data quality by refining validator criteria and implementing new data quality assessment measures, ensuring BioTrove remains a robust dataset for scientific use.

Each image sample in BioTrove is enriched with detailed, curated metadata that facilitates efficient filtering by species count and taxonomic information. The metadata includes common names, scientific names, and hierarchical taxonomic data, which enhances the usability of the dataset for AI model training. For the complete list of metadata fields, see Table 1.

Along with the dataset, we also release our data curation tooling pipeline: BioTroveProcess, which enables users to easily access and manipulate the dataset. This pipeline allows researchers to select specific categories across different taxonomic levels, visualize data distributions, and effectively manage class imbalance according to their needs. It facilitates the downloading of specific images by their URLs and provides image-text pairs as well as user-defined chunks to support various AI applications. BioTroveProcess thus enables users to define custom subsets of BioTrove with ease, making the dataset fully AI-ready and reducing barriers to follow-up research in biodiversity-focused AI.

Dual-language text descriptions.We adopt both common and scientific names since Latin is a low-resource language, and current AI models do not perform well on scientific names alone in a zero-shot manner. We found that a well-structured text description that integrates common names, scientific names, and detailed taxonomic hierarchies facilitates the learning of relationships between Latin and English terms, thereby improving the models' applicability in scientific contexts . Moreover, incorporating the taxonomic hierarchy enables models to more effectively associate visual data with taxonomic terminology . This matches the guidelines suggested by BioCLIP  to enhance model performance and generalization. **Privacy Measures:** The images of BioTrove were sourced from the

Figure 2: **Distribution of the BioTrove dataset.** (a) Size of the top seven Phyla in the BioTrove dataset. (b) Species counts for the top seven Phyla. (c) The 40 highest occurring species in entire BioTrove dataset.

iNaturalist Open Dataset, whose metadata included Personally Identifiable Information (PII). This included information about observers, such as their usernames and sometimes their real names if they have chosen to share that information publicly. We removed all such fields to ensure that no PII is present in the metadata associated with BioProve samples, ensuring the privacy of all contributors. **License:** During curation, we took care to include only images from iNaturalist Open Data, which are all licensed under either the CC0, or CC-BY, or CC-BY-NC licenses. This ensures that all our images are available for public research purposes. **Offensive Content:** Some of our URLs may point to images that users could find disturbing or harmful, such as photos of dead or dismembered animals. We retained these types of

   Text Type & Description \\  Common Name & Vernacular name (e.g., Western honey bee) \\ Scientific Name & Genus and species (e.g., _Apis mellifera_) \\ Taxonomic Name & Flattened taxonomy concatenated into a single string \\ Taxonomic Rank & Specific level in the hierarchy (e.g., subspecies, species) \\   

Table 1: **Annotations provided in the BioProve Dataset.**

Figure 3: **Treemap diagram of the BioProve dataset, starting from Kingdom. The nested boxes represent phyla, (taxonomic) classes, orders, and families. Box size represents the relative number of samples.**

images since they sometimes can provide valuable scientific data about wildlife, including information on predation events, roadkill, and other occurrences relevant to conservation and biodiversity studies. Although iNaturalist relies on user contributions and community moderation to maintain the quality and appropriateness of the data, we acknowledge that the vast and diverse nature of the data means that some offensive or inappropriate content might be present.

Our closest comparisons are with BioScan-1M (which appeared in NeurIPS 2023 Datasets and Benchmarks) and TreeOfLife-10M (which will appear in CVPR 2024). BioScan-1M focuses solely on the Insecta Class and provides scientific names, taxonomic ranks, as well as DNA barcodes. The TreeOfLife-10M dataset comprises 10.4 million images, integrating data from iNat2021 , BioScan-1M, and a fresh set of image samples sourced from the Encyclopedia of Life (EOL). It also supports dual-language labels and detailed taxonomic hierarchies and was used to train the BioCLIP vision-language model. See Table 2 for essential differences.

## 3 Data Collection and Curation Methodology

Challenges with iNaturalist Open Data.All of BioProve is sourced from the iNaturalist Open Data community science platform, which (in all) comprises over 280M biodiversity-relevant observations shared by users. However, there are still significant gaps in usability for AI research. The photos and metadata, although easily downloadable, are provided in four separate metadata sheets that are not ready to use. Taxa information is encoded as numerical IDs, requiring additional API calls and non-trivial lookups to convert these into common or scientific names. The multiple metadata sheets structure is fragmented across four separate files--photos, taxa, observations, and observers--adding complexity to data integration. Managing data balance and filtering out species with too few images can lead to biases toward common (charismatic) species and an imbalanced training process.

Curation of BioProve.The iNaturalist Open Dataset comprises a collection of 284.2 million images stored on an AWS S3 bucket as of 2024-09-27, with associated metadata provided across four separate CSV files (photos, observations, taxa, and observers). Details on each of these files are presented in Section A.5 in the Appendix. Although these files contain a wealth of valuable information, they are structured for rapid retrieval rather than AI-readiness. To address this, we curate the metadata into a streamlined, AI-optimized format.

We populate an SQL database with each CSV file as an individual SQL table, then create an aggregated table by joining photos, observations, and taxa on their relational columns, discarding irrelevant columns. In this aggregate table, we add a new column populated with

 
**Feature** & **BioProve** & **TreeOfLife** & **BioScan** \\ 
**Size** & 161.9 million images & 10.4 million images & 1.1 million images \\ 
**Diversity** & 366.6K species & 454.1K species & 8.3K \\ 
**Labels** & Dual language & Dual language & Single language \\
**Provided** & (common and scientific names), detailed & (common and scientific names), detailed & (scientific names), taxonomic ranks \\  & taxonomic hierarchies & taxonomic hierarchies & (family to species), \\  & & & DNA barcodes \\ 
**Data Source** & iNaturalist Open & iNaturalist, Encyclopedia of Life & Specimens from \\  & Dataset & (EOL), BioScan-1M & Malaise traps, DNA barcodes matched to \\  & & & \\ 
**Key Features** & Ready-to-use pipeline, reduce class imbalance, high-quality annotations, supports BioProve-CLIP & Rich hierarchical representations, comprehensive metadata, supports BioCLIP & Focus on insects, high-resolution images, detailed taxonomic annotation, DNA codes \\  

Table 2: **Comparison** of BioProve with existing biodiversity datasets.

the Amazon S3 URL and generate individual columns for taxonomic kingdom, phylum, class, order, family, genus, and species.

BioTrove includes only research-grade images from the _Animalia_, _Plantae_, and _Fungi_ kingdoms, filtering out other domains to maintain a clear biodiversity focus. To achieve this filtering, we apply strict taxonomic criteria, ensuring only these three kingdoms are represented. The iNaturalist metadata files lack common names, so we reconstruct this information by cross-referencing species names from the iNaturalist Taxonomy DarwinCore Archive, updated monthly. This enriched metadata, including common names, is then appended to the SQL table. The final curated dataset is exported as parquet files, available for public access on HuggingFace.

Data Filtering and Preprocessing.As outlined, BioTrove includes structured metadata that is both comprehensive and easy to work with, featuring full taxonomic information and direct URLs to image files. To further support accessibility, we release an accompanying software pipeline that allows users to filter specific categories, visualize data distributions, and manage dataset imbalances effectively. These tools make it simple for researchers to interact with BioTrove, creating tailored subsets based on their specific needs. The iNaturalist data, sourced from citizen science contributions, has inherent variability in species representation, with some species documented extensively and others less so. To address this, our tools enable user-defined filters to exclude species with fewer than a set number of images and to cap image counts per species, thus supporting more balanced model training.

To further mitigate dataset imbalances (detailed in our experiments section), we use a semi-global shuffling strategy in which the data is organized into chunked tar files. These files are shuffled, divided into smaller groups, and then merged into larger batches to ensure a balanced species distribution within each batch. This method enhances dataset integrity, helping to prevent the overrepresentation of any single species across the batches.

## 4 Models and Benchmarks

We now showcase and demonstrate the utility of the BioTrove dataset by creating and benchmarking BioTroveCLIP, a new suite of vision-language foundation models for biodiversity.

### BioTrove-Train

BioTrove-Train is a curated subset comprising approximately 40M samples and 33K species, focused specifically on seven taxonomic categories: _Aves_, _Anchnida_, _Insecta_, _Plantae_, _Fungi_, _Mollusca_, and _Reptilia_. As discussed previously, the BioTrove dataset is accompanied by a flexible pipeline that enables users to apply customized filtering to select specific categories or subsets based on research needs, thereby allowing researchers to generate their own training datasets. For BioTrove-Train, these seven categories were pre-selected due to their significant impact on biodiversity and agricultural ecosystems, as well as their relative underrepresentation in standard image recognition models. Unlike megafauna, which are typically well-represented in existing models, these categories address unique challenges in biodiversity-focused AI.

This subset comprises data posted on iNaturalist prior to 2024-01-27. We applied strict filtering criteria to ensure high-quality data, excluding species with fewer than 30 images and capping the maximum number of images per species at 50,000. To maintain balance, we employed a semi-global shuffling method, organizing the data into mini-batches of approximately 50,000 samples. From these, 95% were randomly selected for training and validation, while the remaining 5% were reserved for testing. Detailed statistics can be found in Table 3.

### New Benchmarks

We created three new benchmark datasets, all of which are non-overlapping curated subsets of the BioTrove dataset. These benchmarks focus on fine-grained image classification within the seven taxonomic categories: _Aves_, _Arachnida_, _Insecta_, _Plantae_, _Fungi_, _Mollusca_, and _Reptilia_. All benchmarks presented here are independent and strictly within these seven categories, without overlapping with each other or with the BioTrove-Train subset.

Additionally, we report results on several established benchmarks from the literature (see Table 4).

**BioTrove-Balanced.** To ensure balanced species representation across the seven key taxonomic categories, we curate the BioTrove-Balanced benchmark. Each category includes up to 500 species, with 50 images per species, resulting in a total of 112,209 images. This balanced dataset provides a consistent foundation for model performance evaluations. The exact species counts for each category are detailed in Table 7 (see Appendix).

**BioTrove-Unseen.** To assess the ability of models to generalize to previously unseen species within the seven categories, we curated the BioTrove-Unseen benchmark. This dataset includes species from BioTrove-Train with fewer than 30 instances, ensuring they were unseen during training. Each species is represented by at least 10 images, with a total of 11,983 images. This benchmark tests the models' robustness on rare species not encountered during training.

**BioTrove-LifeStages.** The BioTrove-LifeStages benchmark evaluates the model's ability to recognize species across different developmental stages, focusing on insect species that exhibit significant visual variations throughout their life cycle. This dataset contains 20 labels representing four life stages (egg, larva, pupa, and adult) for five distinct insect species. The data was collected via the observation export feature on the iNaturalist platform between February 1, 2024, and May 20, 2024, ensuring no overlap with the training dataset. This benchmark allows for comprehensive evaluations of model performance across various life stages (see Figure 4).

Figure 4: (a) Example images from BioTrove-Unseen. (b) BioTrove-Life-Stages with 20 class labels: four life stages (egg, larva, pupa, and adult) for five distinct insect species.

  
**Dataset** & **Description** & **Images** & **Unique Classes** \\  TreeOfLife-10M &  Dataset combines a subset \\ of iNaturalist, \\ Encyclopedia of Life (EOL), BioScan-1M. \\ One subset of BioTrove \\ Train \\  & 10.4M & 454,103 \\ BioTrove-Train &  BioTrove- \\ One subset of BioTrove \\ with size 40M. \\  & 39.9M & 33,364 \\    
  
**Level** & **Uniques** \\  kingdom & 3 \\ phylum & 14 \\ class & 50 \\ order & 311 \\ family & 1692 \\ genus & 11506 \\ species & 33364 \\   

Table 3: **Training data sources used in BioTrove-Train and Diversity in Different Taxonomy Levels. We integrate taxonomic labels into the images.**

[MISSING_PAGE_FAIL:9]

BioProve-Train. For BioCLIP-Rare, the dataset is a subset from EOL which BioCLIP did not see before, but TreeOfLife contains the majority of the EOL dataset.

**Limitations**. We also evaluated all models on the challenging Confounding-species benchmark introduced in , but find that all models perform at or below random chance and do not report results here; this could be an interesting avenue for follow-up work.

In Table 8 in the Appendix, we report model performance at different levels of the taxonomic hierarchy. Generally, we find that models trained on web-scraped data perform better with common names, whereas models trained on specialist datasets perform better when using scientific names. Additionally, models trained on web-scraped data excel at classifying at the highest taxonomic level (kingdom), while models begin to benefit from specialist datasets like BioProve-Train and Tree-of-Life-10M at the lower taxonomic levels (order and species). From a practical standpoint, this is not problematic: BioProve-CLIP is highly accurate at the species level, and higher-level taxa can be deterministically derived from lower ones.

Addressing these limitations will further enhance the applicability of models like BioProve-CLIP in real-world biodiversity monitoring tasks.

## 6 Concluding Discussion

We introduce BioProve, the largest publicly accessible dataset designed to advance AI for biodiversity applications. This dataset, curated from the iNaturalist community science platform, includes 161.9 million images, surpassing existing datasets in scale by an order of magnitude. We anticipate that BioProve will enable the development of AI models that can enable various digital tools ranging from pest control strategies, crop monitoring, and worldwide biodiversity assessment and environmental conservation.

We also believe that BioProve can be used as a unique testbed for measuring progress on fine-grained image recognition. The success of BioProve-CLIP on BioProve-Unseen underscores the importance of scaling up per-category sample size, or vertical scaling , in achieving high accuracy on long-tailed extreme-imbalance classification. However, BioCLIP continues to exhibit superior performance on several datasets, and we believe that this is because TreeofLife-10M contains an order-of-magnitude more _classes_ (species) than BioProve-Train. We invite the AI community to create new subsets of BioProve with varying degrees of balance and species diversity and use our tooling to measure model performance against current benchmarks.