# Bayesian Disease Progression Models that Capture Health Disparities

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Disease progression models, in which a patient's latent severity is modeled as progressing over time and producing observed symptoms, have developed great potential to help with disease detection, prediction, and drug development. However, a significant limitation of existing models is that they do not typically account for healthcare disparities that can bias the observed data. We draw attention to three key disparities: certain patient populations may (1) start receiving care only when their disease is more severe, (2) experience faster disease progression even while receiving care, or (3) receive care less frequently conditional on disease severity. To address this, we develop an interpretable Bayesian disease progression model that captures these three disparities. We show theoretically and empirically that our model correctly estimates disparities and severity from observed data, and that failing to account for these disparities produces biased estimates of severity.

## 1 Introduction

Using observed data to model the progression of a latent variable over time is useful for making predictions in many settings. Models of infrastructure deterioration use physical observations and inspection results to model a system's overall health changing over time ; models of human aging use a person's observed physical and biological characteristics to learn the progression of their underlying "biological age" ; and disease progression models, the setting we focus on in this paper, use observed symptoms to learn a patient's evolving latent disease severity . Disease progression models provide insight on both individual-level disease trajectories and general representations of disease dynamics. Accurately modeling disease progression offers great promise in enabling healthcare providers to better personalize care and predict a patient's disease trajectory, detect diseases at earlier stages, and study interventions such as drug development [4; 5].

In order for the benefits of these models to apply to all patients equitably, it is crucial that they make accurate predictions for all populations of patients. However, disease progression models have typically failed to account for systemic disparities in the healthcare process. Disparities have been shown to exist along many demographic features including socioeconomic status [6; 7], proximity to care [8; 9], and race  -- intuitively, we expect that models not accounting for these disparities will make predictions that are consistently inaccurate for some patient groups. In this paper, we define three main axes along which we observe and analyze disparities:

1. Certain patient groups may start receiving care only when their disease is more severe (leaving more of their disease trajectory unobserved).
2. Certain patient groups may experience faster disease progression even while receiving care (indicating consistent differences in the efficacy or quality of treatment).

3. Certain patient groups may receive care less frequently conditional on disease severity (decreasing the frequency with which they are observed in the data).

As such, our key contributions are: (1) we propose an interpretable Bayesian model that learns disease progression while accounting for disparities along all three of these axes, (2) we show theoretically and empirically that failing to account for any of these disparities will lead to biased severity estimates, and (3) we outline the beginning of a heart failure case study. We anticipate that the results from this case study, which we are working on in close collaboration with the New York-Presbytarian hospital system, will have two main applications: descriptions of healthcare disparities across demographic groups can help to target future interventions, and validating the model in a real healthcare setting will demonstrate that it is possible to make predictions without bias from these disparities.

## 2 Related Work

Disease progression modeling.Disease progression models have been developed for many chronic diseases, including Parkinson's disease , Alzheimer's disease , diabetes , and cancer . A key feature of the progression models we consider is that a latent severity \(Z_{t}\) progresses over time and gives rise to the observed symptoms \(X_{t}\). Models in this family include variants of hidden markov models (HMM) [14; 15; 16; 17; 18] and recurrent neural networks (RNN) [19; 20; 21; 22; 23; 24; 25].

Healthcare disparities.Disparities have been documented in many parts of the healthcare process. Factors such as distance from hospitals [8; 9], distrust of the healthcare system , or lack of insurance  can result in underutilization of health services. Biases in the judgements of healthcare providers can lead to minority groups receiving later screening , fewer referrals , or generally worse care . And issues such as limited health literacy or trust in healthcare can create disparities in follow-through for appointments or effectiveness of at-home care [31; 32].

These disparities have been shown to emerge along the three axes that we identify: (1) how severe a patient's disease gets before they start to receive care [33; 34; 35]; (2) how quickly their latent severity \(Z_{t}\) progresses even while receiving care [36; 37]; and (3) how likely they are to visit a clinician at a given disease severity level . Despite thorough literature showing the existence of these disparities and their impact on healthcare, disease progression models have not (to the best of our knowledge) accounted for disparities when making predictions.

## 3 Model

We build on a standard setup for disease progression modeling, in which each patient \(i\) has an underlying latent disease severity \({Z_{t}}^{(i)}\) that progresses over time and gives rise to a set of observed features \({X_{t}}^{(i)}\)[39; 40]. For notational convenience, we will omit the \((i)\) superscript from here on.

We characterize a patient's severity \(Z_{t}\) at timestep \(t\) by their _initial severity_\(Z_{0}\) at their first observation (which we denote as \(t=0\)) and their _rate of progression_\(R\) after that point:

\[Z_{t}=Z_{0}+R t\]

While we expect our approach to extend naturally to non-linear models of progression, estimating the slope of a potentially non-linear progression still provides valuable insight on a patient's general disease trajectory relative to others. The assumption of linear progression over time to capture long-term disease trajectory is a common approach in existing models [11; 2].

Whether a patient actually visits a healthcare provider at time \(t\) is captured by an observed binary indicator \(D_{t}\{0,1\}\). If a patient does visit at time \(t\), we will observe some recorded set of disease-relevant features \(X_{t}^{d}\) (e.g., lab results, imaging, and symptoms). At any given timestep, a clinician will not necessarily observe or record all features -- we model the features that _are_ observed as a noisy function of latent severity \(Z_{t}\):

\[X_{t}=f(Z_{t})+_{t}\]

where diagonal covariance matrix \(_{}^{d d}\) parameterizes feature-specific noise \(_{t} N(0,_{})\) (accounting for both measurement error and variation in how the patient's physical state can fluctuate day-to-day). We specifically instantiate \(f\) as a linear function \(f(Z_{t})=F Z_{t}+F_{int}\), where \(F_{int}^{d}\) is a feature-specific intercept and \(F^{d}\) has its first element constrained to be positive for identifiability; we leave extending this to non-linear functions for future work.

Capturing disparities.We next specify a demographic feature vector \(A\) for each patient. \(A\) can capture multiple social determinants of health (each element of \(A\) can encode any continuous or categorical feature), but for simplicity in exposition, we assume \(A\) encodes a single categorical label (e.g., a patient's race group). By modeling dependence between \(A\) and other aspects of the model, depicted in Figure 1, we can capture health disparities along three interpretable axes; as we discuss in SS2, the existence of these disparities has been well-documented in past studies:

1. **Underserved patients may start receiving care only when their disease is more severe.** We capture this by learning group-specific distributions of \(Z_{0}\), a patient's disease severity at first visit. We pin \(Z_{0}\) for one group (\(A=a_{0}\)) to be drawn from a unit normal distribution (as is standard because it fixes the scale of \(Z_{t}\)). For other groups \(A=a\), \(Z_{0} N(^{(a)}_{Z_{0}},^{(a)}_{Z_{0}})\), where \(^{(a)}_{Z_{0}}\) and \(^{(a)}_{Z_{0}}\) are learned group-specific parameters for group \(a\).
2. **Underserved patients may experience faster disease progression even while receiving care**. This we capture by learning group-specific distributions of progression rate \(R N(^{(a)}_{R},^{(a)}_{R})\), where \(^{(a)}_{R}\) and \(^{(a)}_{R}\) are learned group-specific parameters for group \(a\).
3. **Underserved patients may receive care frequently conditional on disease severity.** This we capture by modeling patient visits as generated by an inhomogeneous Poisson process parameterized by a non-negative, time-varying rate parameter \(_{t}\) that depends on both \(Z_{t}\) and \(A\) for all groups \(a\): \((_{t})=_{0}+(_{Z} Z_{t})+^{(a)}_{A}\), where \(_{Z}\) and \(_{0}\) are learned parameters for the entire population and \(^{(a)}_{A}\) is a learned group-specific parameter for group \(a\). We pin \(^{(a_{0})}_{A}\) at 0 as a reference for all other groups.

Overall, our model parameters (on which we place weakly informative priors) are \(F\), \(F_{int}\), \(_{}\), \(\{^{(a)}_{Z_{0}}\}\), \(\{^{(a)}_{Z_{0}}\}\), \(\{^{(a)}_{R}\}\), \(\{^{(a)}_{R}\}\), \(_{0}\), \(_{Z}\), and \(\{^{(a)}_{A}\}\) for all demographic groups \(a\). We learn these values from our observed data \(X_{t},D_{t}\), and \(A\). Figure 1 summarizes the data generating process.

## 4 Theoretical analysis

### Identifiability

As we show in SSA.1, our model is identifiable, meaning different sets of parameters yield different observed data distributions [41; 42]:

**Theorem 4.1**.: _All parameters of the model are identified by \(P(X_{t},D_{t} A)\)._

We confirm our theoretical identifiability results experimentally in SS5, showing that the model does indeed recover the true parameters in synthetic data.

Figure 1: Plate diagram of generative model, capturing \(N\) patients over \(T\) timesteps. Shaded nodes indicate observed features, and red arrows indicate dependencies capturing health disparities.

### Bias in models that do not account for disparities

Next we show that disease progression models will produce biased estimates of severity if they fail to account for any of the three disparity types we capture. We use the strict Monotone Likelihood Ratio Property (MLRP) to characterize the existence of disparities between two populations . Our results apply to any setting in which data is generated according to the relationships depicted in Figure 1 and disparities exist, not relying on the parametric assumptions of our implemented model.

First, we prove that any model failing to account for disparity 1 will produce biased severity estimates:

**Theorem 4.2**.: _A model that does not take into account demographic disparities in initial disease severity \(Z_{0}\) will underestimate the disease severity of groups with higher values of initial severity and overestimate that of groups with lower values of initial severity._

That is (for the underestimation case), if \(P(Z_{0}=z_{0} A=a)\) strictly MLRPs \(P(Z_{0}=z_{0})\) for some group \(a\), then \([Z_{t} X_{t}=x_{t}]<[Z_{t} X_{t}=x_{t},A=a]\). A full proof is provided in SSB.1. We then prove that failing to account for disparity 2 or disparity 3 will also lead to biased estimates of severity (full proofs in SSB.2 and SSB.3, respectively):

**Theorem 4.3**.: _A model that does not take into account demographic disparities in rate of progression \(R\) will underestimate the disease severity of groups with higher progression rates and overestimate that of groups with lower progression rates._

**Theorem 4.4**.: _A model that does not take into account demographic disparities in visit frequency \(_{t}\) will underestimate the disease severity of groups with lower visit frequency and overestimate that of groups with higher visit frequency._

## 5 Synthetic experiments

We implement our model in Stan, a Bayesian inference package , to validate our theoretical results in simulations with synthetic data.

### Identifiability

We first verify Theorem 4.1 in simulations, showing our model can accurately recover the true data-generating parameters for synthetic data. Across 50 runs, we find high correlation between the true parameters and the posterior mean estimates (mean Pearson's \(r\) 0.98 across all parameters; median 0.98), and good calibration (mean linear regression slope 0.97; median 0.98). We provide scatterplots of all parameter recovery in Appendix C.

### Bias in models that do not account for disparities

We now verify in simulation that failing to account for disparities can lead to biased severity estimates. We generate simulated data for two groups, \(A=0\) and \(A=1\), where group \(1\) is underserved with respect to each of the three disparities we capture (i.e., \(_{Z_{0}}^{(1)}>_{Z_{0}}^{(0)}\), \(_{R}^{(1)}>_{R}^{(0)}\), and \(_{A}^{(0)}>_{A}^{(1)}\)). We then fit our main model, which accounts for all disparities, alongside three models that each fail to account for one of the disparities, on the same set of data to compare their recovery of individual patient severity values. As seen in Figure 2, the models that do not account for disparities all underestimate severity for the underserved group \(1\) and overestimates severity for the other group -- these simulations empirically support Theorems 4.2, 4.3, and 4.4. While our main model achieves average error (mean inferred estimate minus mean true value for a single run) \(-0.004\) and \(-0.02\) for groups \(0\) and \(1\) respectively, the other models have error \(1.03\), \(0.01\), and \(0.42\) for group \(0\) (all overestimated) and error \(-0.78\), \(-0.24\), and \(-0.88\) for group \(1\) (all underestimated).