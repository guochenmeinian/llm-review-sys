# Confusion-Resistant Federated Learning via Diffusion-Based Data Harmonization on Non-IID Data

Xiaohong Chen\({}^{1,2,3}\)   Canran Xiao\({}^{1}\)1   Yongmei Liu\({}^{1,4}\)

\({}^{1}\) School of Business, Central South University, Changsha, Hunan 410083, China

\({}^{2}\) Xiangjiang Laboratory, Changsha, Hunan 410205, China

\({}^{3}\) School of Advanced Interdisciplinary Studies, School of Management Science and Engineering, Hunan University of Technology and Business, Changsha, Hunan 410205, China

\({}^{4}\) Urban Smart Governance Laboratory, Changsha, Hunan 410083, China

c88877803@163.com, xiaocanran@csu.edu.cn, liuyongmeicn@163.com

Corresponding author

###### Abstract

Federated learning has become a pivotal distributed learning paradigm, involving collaborative model updates across multiple nodes with private data. However, handling non-i.i.d. (not identically and independently distributed) data and ensuring model consistency across heterogeneous environments present significant challenges. These challenges often lead to model performance degradation and increased difficulty in achieving effective communication among participant models. In this work, we propose Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed), a novel framework designed to address these issues. Our approach introduces a new diffusion-based data harmonization mechanism that includes data augmentation, noise injection, and iterative denoising to ensure consistent model updates across non-i.i.d. data distributions. This mechanism aims to reduce data distribution disparities among participating nodes, enhancing the coordination and consistency of model updates. Moreover, we design a confusion-resistant strategy leveraging an indicator function and adaptive learning rate adjustment to mitigate the adverse effects of data heterogeneity and model inconsistency. Specifically, we calculate importance sampling weights based on the optimal sampling probability, which guides the selection of clients and the sampling of their data, ensuring that model updates are robust and aligned across different nodes. Extensive experiments on benchmark datasets, including MNIST, FashionMNIST, CIFAR-10, CIFAR-100, and NIPD, demonstrate the effectiveness of CRFed in improving accuracy, convergence speed, and overall robustness in federated learning scenarios with severe data heterogeneity.

## 1 Introduction

Federated Learning (FL)  has emerged as a powerful paradigm for distributed machine learning, enabling multiple clients to collaboratively train a shared model without exchanging raw data. This approach addresses critical concerns around data privacy and security, which are increasingly significant in various sectors such as healthcare , finance , and IoT . However, one of the fundamental challenges in FL is dealing with non-independent and identically distributed (non-IID) data, which can significantly impair the performance and convergence of the global model .

As illustrated in Figure 1, FL on non-IID data often suffers from issues like divergent model updates and inconsistent global models. Client models trained on heterogeneous data distributions tend to diverge (Ye et al., 2023), making it difficult for the server to aggregate them into a coherent global model. This divergence is due to inconsistencies in data sources (Xiao and Liu, 2024) and distributions across clients (Duan et al., 2021). This problem leads to reduced accuracy and slower convergence rates, highlighting the need for effective solutions to handle data heterogeneity. Existing research has made significant strides in improving the robustness and efficiency of FL in non-IID settings. Notable methods include FedProx (Li et al., 2020), which adds a proximal term to handle heterogeneity. Techniques such as MOON (Li et al., 2021)and FedGen (Nguyen et al., 2021) introduce sophisticated strategies like contrastive learning and data generation to mitigate the effects of data heterogeneity. Despite these advancements, issues related to data distribution disparities and model inconsistency persist, limiting the scalability and effectiveness of FL in real-world scenarios.

Given the critical gaps in existing FL approaches, particularly their limited robustness to severe non-IID data distributions, there is a pressing need for more resilient and adaptive solutions. This research is motivated by the necessity to enhance FL's capability to handle heterogeneous data efficiently. The primary objective of this study is to develop a novel FL framework, Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed), which integrates advanced mechanisms to address data distribution disparities and enhance model consistency across clients.

Our contributions can be summarized as follows:

1. We propose a novel indicator function that dynamically adjusts sample weighting based on loss values and uncertainties, facilitating a self-paced learning approach that prioritizes more difficult samples over time.
2. Our framework employs a diffusion-based mechanism to harmonize data distributions, involving iterative noise injection and denoising processes that align local data with the desired distribution.
3. We implement a strategic client selection method based on the indicator function, ensuring the inclusion of the most reliable clients, which enhances the robustness and consistency of model updates.
4. Our extensive experimental evaluations demonstrate that CRFed achieves state-of-the-art performance on benchmark datasets. CRFed outperforms existing methods significantly in terms of accuracy and convergence speed under various non-IID settings.

## 2 Related Work

### Non-IID Challenge in Federated Learning

The issue of non-IID data in FL was initially highlighted by FedAVG (McMahan et al., 2017), and it has since been demonstrated that this challenge can significantly hinder the convergence and overall performance of the global model (Zhao et al., 2018; Li et al., 2019). Numerous studies, categorized as client-centric methods, have been proposed to tackle this problem by adjusting the local training

Figure 1: Problem illustration of federated learning on Non-i.i.d data.

objectives using insights from the global model and the local models of other clients (Wang et al., 2021). For instance, FedProx (Li et al., 2020) introduced a proximal term to constrain local updates by leveraging the global model. SCAFFOLD (Karimireddy et al., 2020) utilized control variates to correct for local training drift, while FedDyn (Acar et al., 2021) introduced a dynamic regularizer for parallelizing gradients among clients. MOON (Li et al., 2021) applied contrastive learning to minimize the discrepancy between model representations, thereby correcting local training.

Despite their contributions, these methods fall short of fully resolving the core of the non-IID issue and may experience performance limitations in scenarios with highly skewed data distributions (Li et al., 2022). Beyond client-side adjustments, the server also plays a role in mitigating the adverse effects of non-IID data by calibrating the biased global model post-aggregation. For example, CCVR (Luo et al., 2021) uses virtual representations from an approximated Gaussian mixture model to correct the classifier. FedFTG (Zhang et al., 2022) employs data-free knowledge distillation to refine the global model with the knowledge derived from local models. Additionally, strategies such as client clustering (Ghosh et al., 2020; Long et al., 2023) and client selection (Zhang et al., 2021; Wang et al., 2020), can be implemented by the server to alleviate the non-IID problem. IFCA (Ghosh et al., 2020) iteratively estimates client cluster identities based on local empirical loss and updates model parameters for each cluster via gradient descent.

### Importance Sampling in Federated Learning

In federated learning (FL), data sampling strategies are vital for enhancing distributed training efficiency. (Tuor et al., 2020) proposed selecting local training data based on user-end data correlation analysis. This led to dynamic sampling strategies like (Li et al., 2021), where training sample importance is determined by model gradient magnitudes. Similarly, (Rizk et al., 2022) used gradient norms to derive sampling weights, minimizing theoretical convergence bounds. However, these methods require immediate gradient computations, increasing local overhead, and assume convex loss functions, which may not apply to deep learning models (Rizk et al., 2021). Therefore, developing importance sampling methods suitable for deep learning-based FL remains an open challenge.

FL convergence can be theoretically analyzed due to the model aggregation mechanism (Wang et al., 2021; Li et al., 2021; Li et al., 2021), with experimental validation for deep learning tasks (Wan et al., 2021). Most studies rely on theoretical derivations, limiting practical application. This study aims to use a diffusion model to automate the modeling of optimal sampling strategies in FL.

## 3 Method

### Overview

The CRFed framework, shown in Figure 2, addresses challenges posed by non-i.i.d. data in FL. Our approach integrates a diffusion mechanism and a confusion-resistant strategy to ensure consistent and robust model updates across heterogeneous data distributions. The core idea of CRFed is that the performance of client \(i\)'s data on the global model reflects its contribution to the training process. By using an optimal indicator function, we determine the optimal data sampling probability for each client, enhancing training efficiency and model performance.

The framework comprises several key components: the current global model downloaded by clients at time \(t\); the Model Encoder and Meta-model, which process the global model and client-specific data for the diffusion process; an indicator function, computed using client \(i\)'s data on the global model; the Diffusion-based Data Harmonization Mechanism, which uses data augmentation, noise injection, and probabilistic modeling to mitigate data distribution disparities; and the Distribution Decoder, which aligns the denoised data distribution with the desired distribution.

### Indicator Function and Meta-model

The Indicator Function \(I_{}(l_{i},_{i})\) is designed to measure the reliability of the \(i\)-th sample's loss value \(l_{i}\) and its associated uncertainty \(_{i}\). The design is inspired by self-paced learning (Fan et al., 2017; Castells et al., 2020), which adjusts the weights of samples based on their loss values, allowing for a gradual learning process from easy to difficult samples. In the context of federated learning, this means that each client should adopt a self-paced learning paradigm, sampling its data in a way that allows the global model to learn from simple to complex tasks. The Indicator Function captures this performance and is defined as follows:\[I_{}(l_{i},_{i})=(l_{i}-)_{i}+(_{i})^{2}\] (1)

where \(\) is a pre-set regularization coefficient. \(\) is a confidence threshold that determines the difficulty of the sample based on its loss value. It can either be a fixed constant or a dynamically adjusted weighted average during the training process.

The Indicator Function can be further explained using the following steps: for each client \(i\), the loss value \(l_{i}\) of each sample is calculated on the current global model, and the uncertainty \(_{i}\) of each sample is estimated based on its difficulty. The Indicator Function \(I_{}(l_{i},_{i})\) is then used to assign weights to the samples, with easier samples having lower weights and more difficult samples having higher weights. This adaptive weighting mechanism ensures that the model focuses more on difficult samples over time, leading to improved learning efficiency and robustness.

**Theorem 3.1**.: _In the CRFed framework, using the indicator function \(I_{}(l_{i},_{i})\) ensures stable and convergent updates for heterogeneous federated learning. For an appropriately chosen learning rate \(\), the model update rule for client \(i\) at iteration \(t\),_

\[_{t+1}=_{t}-(_{i}^{*}+(l_{i}-)k+2 {_{i}^{*}}{_{i}^{*}}k)_{}l_{i},\] (2)

_guarantees a decreasing step size, promoting convergence. Moreover, CRFed achieves a tighter bound on update steps than FedAvg, indicating faster convergence under the same conditions._

The proof of Theorem 3.1 can be found in Appendix A.2.

Given the global model \(\), the optimal uncertainty \(_{i}^{*}\) can be derived through the following theorem:

**Theorem 3.2**.: _The optimal uncertainty \(_{i}^{*}\) for a given loss value \(l_{i}\) is obtained by minimizing the Indicator Function \(I_{}(l_{i},_{i})\). The solution is given by:_

\[_{i}^{*}(l_{i})=(-W((- {e},l_{i}-)))\] (3)

_where \(W()\) is the Lambert W function._

Figure 2: **CRFed Framework. The process begins with the current global model, which is downloaded by clients. The model encoder processes the global model, and the meta-model is obtained. This meta-model is then projected into a higher-dimensional space and concatenated with the indicator function, forming the combined representation \(z_{i}\). The diffusion-based data harmonization mechanism adds noise to this representation and iteratively denoises it to achieve the desired distribution. The distribution decoder then aligns the denoised data distribution. Client \(i\)â€™s data is sampled based on importance sampling weights \(w_{i}\), calculated as the ratio of the optimal sampling probability \(P_{i}^{*}\) to the original data distribution \(P_{0}\). This ensures that the sampled data aligns with the desired distribution, following a curriculum learning approach that progresses from easy to difficult samples, thus enhancing overall model performance.**

We rewrite the indicator function by setting \(_{i}=e^{x_{i}}\), reduce the derivative condition to a Lambert \(W\) form under domain constraints, and thus obtain a closed-form solution for \(_{i}^{*}\); the complete derivation is presented in Appendix A.3.

For each sample indexed by \(i\), we determine the optimal uncertainty \(_{i}^{*}\) as a function of its loss \(l_{i}\). Specifically, let \(I_{}(l_{i},_{i})\) be the indicator function defined before. Then, selecting \(_{i}^{*}\) that minimizes \(I_{}(l_{i},_{i})\) induces an adaptive weighting scheme:

\[_{i}(l_{i})\ \ ^{*}(l_{i})},\] (4)

ensuring that when \(l_{i}\) is relatively large, the corresponding optimal \(_{i}^{*}\) decreases, thus increasing \(_{i}(l_{i})\) and emphasizing more difficult samples. Conversely, smaller \(l_{i}\) values lead to larger \(_{i}^{*}\) and lower \(_{i}(l_{i})\), indicating that easier samples receive diminished focus. As a result, the distribution defined by \(_{i}^{*}\) is optimally aligned with the current global model \(_{t}\), conforming to the self-paced learning principle.

Since \(I_{}(l_{i},_{i})\) can be regarded as quantifying each client's contribution relative to \(_{t}\), we embed \(_{t}\) within the diffusion model as follows: using an autoregressive encoder \(E\), we compress \(_{t}\) to a meta-model \(_{t}=E(_{t})\). Subsequently, \(_{t}\) is projected into a high-dimensional representation \(P(_{t})\), and concatenated with \(I_{}(l_{i},_{i})\) to form

\[z_{i}\ =\ P(_{t}),\,I_{}(l_{i},_{i}) .\] (5)

We then feed \(z_{i}\) into the diffusion model, denoted by \((z_{i})\), to refine the data distribution with respect to the global context. Further implementation details about the encoder \(E\) are provided in Appendix A.4.

### Diffusion-based Data Harmonization

The diffusion-based data harmonization mechanism is a critical component of the CRFed framework, responsible for mitigating data distribution disparities and ensuring consistent model updates across heterogeneous environments. The harmonization process is shown in Figure 3, which involves adding noise to the data distribution and then iteratively denoising it to achieve the desired distribution. The workflow of this mechanism can be divided into two main processes: the forward diffusion process and the reverse denoising process.

Forward Diffusion ProcessSuppose that a training sample \(_{0}\) is of a certain distribution, denoted as \(q(_{0})\). In the forward diffusion process, Gaussian noise with variance \(_{t}(0,1)\) is added gradually to the sample \(_{0}\) for \(T\) steps, resulting in a latent sample \(_{T}(0,)\). The process is defined as follows:

\[q(_{1:T}|z_{i})=_{t=1}^{T}q(_{t}|_{t-1}),\] (6)

\[q(_{t}|_{t-1})=(_{t};}_{t-1},_{t}).\] (7)

Using notations \(_{t}=1-_{t}\) and \(_{t}=_{s=1}^{t}_{s}\), the sample \(_{t}\) can be defined directly as:

\[_{t}=_{t}}z_{i}+_{t}},\ \ \ \ (0,).\] (8)

Reverse Denoising ProcessThe reverse denoising process aims to sample reversely from \(_{T}\) through transition probabilities \(q(_{t-1}|_{t})\) for timesteps \(T-1\) through \(1\), yielding a sample drawn from \(q(z_{i})\). The transition \(q(_{t-1}|_{t})\) is a Gaussian distribution, tractable when conditioned on \(z_{i}\):

\[q(_{t-1}|_{t},z_{i})=(_{t-1};}_{t}(_{t},z_{i}),_{t}),\] (9)

where the mean \(}_{t}\) and variance \(_{t}\) are calculated as:\[}_{t}(_{t},z_{i})=}}( _{t}-}{_{t}}}_{t} ),\] (10)

\[_{t}=_{t-1}}{1-_{t}}_{t}.\] (11)

The reverse transition probability \(p_{}(_{t-1}|_{t})\) relies on the entire data distribution and is approximated through a neural network:

\[p_{}(_{t-1}|_{t})=(_{t-1};_{}(_{t},t),_{}(_{t},t)),\] (12)

The detailed derivations and computations for these processes can refer to A.1. In the context of federated learning, the reverse denoising process starts from the optimal indicator function \(I^{*}\) obtained in the forward diffusion process. By progressively denoising, we obtain the optimal sampling probability for client \(i\), ensuring that the final data distribution aligns with the desired distribution. This minimizes the impact of data heterogeneity and ensures robust model updates across all clients.

### Confusion-Resistant Strategy

The confusion-resistant strategy is designed to address the challenges posed by data heterogeneity and model inconsistency in federated learning. It consists of three key components: client selection based on the indicator function, data sampling using the diffusion-based harmonization mechanism, and adaptive learning rate adjustment.

Client Selection StrategyTo mitigate the adverse effects of data heterogeneity, we select clients based on their indicator function \(I_{}(l_{i},_{i})\), which quantifies the reliability of their data. Clients with the lowest indicator values, reflecting higher data reliability, are chosen for training. This approach follows the curriculum learning paradigm, where lower values indicate better data:

\[=\{i|I_{}(l_{i},_{i})\},\] (13)

where \(\) is a dynamically adjusted threshold ensuring the selection of the most suitable clients.

Data Sampling StrategyFor each selected client, the optimal sampling probability \(P_{i}^{*}\) is determined through the reverse denoising process, starting from the optimal indicator function \(I^{*}\). This ensures that the sampled data aligns with the desired distribution, enhancing the robustness of model updates. The importance sampling weight \(w_{i}\) is calculated as follows:

\[w_{i}=^{*}}{P_{0}}.\] (14)

where \(P_{0}\) is the original data distribution. Using \(w_{i}\), we sample the local training data (\(_{i}^{}=(_{i},w_{i})\)). This sampling ensures the effective sampling probability aligns with \(P_{i}^{*}\).

The distribution decoder, which is implemented as an autoencoder, is then used to decode the denoised data distribution. The autoencoder is trained to map the denoised samples back to the desired distribution, further ensuring that the data used for training is aligned with the ideal distribution. Refer to the A.4 for more details of distribution decoder.

Adaptive Learning Rate AdjustmentThe learning rate \(_{i}\) for each client is adjusted based on the indicator function value, enhancing the influence of more reliable data:

\[_{i}=_{0}(l_{i},_{i})}{_{j}I_{ }(l_{j},_{j})},\] (15)

where \(_{0}\) is the base learning rate.

The complete computational process(pseudocode) of CRFed is provided in the A.5.

Experiments

### Experiment Setup

DatasetsOur experiments are conducted on four widely used benchmark datasets: MNIST [LeCun et al., 1998], FashionMNIST [Xiao et al., 2017], CIFAR-10 [Krizhevsky et al., 2009], and CIFAR-100 [Krizhevsky et al., 2009]. To simulate Non-IID data scenarios, we utilize the Dirichlet distribution [Yurochkin et al., 2019] to generate non-IID partitions with varied concentration parameters, \(\). Smaller values of \(\) lead to more imbalanced data distributions among clients, thereby increasing levels of data heterogeneity. In our experiments, we set \(\) to 0.5 to reflect this imbalance. In all experiments, we simulate a federated learning environment with 10 edge nodes, i.e., \(K=10\). For the MNIST and FashionMNIST datasets, each node has 600 data samples. For the CIFAR-10 dataset, each node has 500 data samples. For CIFAR-100, the partitioning strategy remains the same, ensuring that each client's local data distribution varies significantly, simulating real-world federated learning scenarios. MNIST and FashionMNIST datasets consist of grayscale images of size \(28 28\) pixels, with 10 classes. CIFAR-10 and CIFAR-100 contain color images of size \(32 32\) pixels.

Additionally, we use the NIPD dataset [Yin et al., 2023], a benchmark specifically designed for federated learning in person detection tasks with Non-IID data. This dataset provides a real-world non-IID scenario to test the generalization of CRFed.

Competing MethodsApart from FedAvg [McMahan et al., 2017a], we compare the proposed algorithm with several benchmarking FL algorithms specialized for solving the non-IID problem, including FedProx [Li et al., 2020b], MOON [Li et al., 2021b], and FedGen [Nguyen et al., 2021]. We also compare our method against HFMDS-FL [Li et al., 2024], FRAug [Chen et al., 2023], G-FML [Yang et al., 2023], FedCD [Long et al., 2023], FedNP [Wu et al., 2023], and FedDPMS [Chen and Vikalo, 2023], which are recent state-of-the-art approaches addressing non-IID data issues in federated learning.

HyperparameterFor local training, the settings are as follows: MNIST with \(E=5\), \(B=10\), \(=5 10^{-3}\); FashionMNIST with \(E=5\), \(B=100\), \(=2 10^{-4}\); CIFAR-10 and CIFAR-100 with \(E=5\), \(B=100\), \(=1 10^{-4}\). Momentum optimization with a coefficient of 0.5 is applied. In the CRFed framework, key hyperparameters include maximum global rounds (\(T_{G}\)) set to 100, local training cycles (\(E_{l}\)) per global round set to 1, regularization coefficient (\(\)) set to 0.1, dynamically adjusted confidence threshold (\(\)), and client selection threshold (\(\)) initially set to 0.5. These parameters are fine-tuned based on preliminary experiments to ensure training efficiency and model performance. The experiments were conducted using an NVIDIA GeForce RTX 4060 GPU, which has 8GB of VRAM. Detailed configurations of model structure are provided in A.6.

Evaluation metricsThe primary evaluation metrics for our experiments focus on accuracy and the number of training rounds needed to reach convergence, addressing the challenges posed by non-IID data in federated learning. Accuracy is measured at the same training round across different models to ensure fair comparison. Convergence is assessed by the number of rounds required to achieve a target accuracy, which reflects the model's stability and efficiency. For the NIPD dataset,

Figure 3: The diffusion-based data harmonization mechanism in CRFed framework. The process involves a forward diffusion process where Gaussian noise is added to the initial data distribution, transforming it into a latent representation. This is followed by a reverse denoising process that iteratively removes the noise, aligning the data distribution with the desired target distribution.

we use mean Average Precision (mAP) as the evaluation metric. Following , all reported results are averaged over five runs with different random seeds to account for variability.

### Performance Comparison

Accuracy comparisonTable 1 presents the test accuracy of CRFed compared to several federated learning algorithms under a highly heterogeneous setting (\(=0.5\)). Our proposed method shows notable improvements over FedAvg , with relative gains of 0.9% on MNIST, 3.7% on FashionMNIST, 5.1% on CIFAR-10, 7.5% on CIFAR-100, and a significant 7.4% improvement in mAP on the NIPD dataset. This highlights CRFed's robustness in handling non-IID data distributions. CRFed consistently outperforms all other methods across the datasets, underscoring its effectiveness in federated learning scenarios with severe data heterogeneity.

Effect of Data HeterogeneityWe analyze the impact of data heterogeneity on the performance of the top 5 models by varying the Dirichlet concentration parameter \(\). Table 2 shows the performance of these models on CIFAR-100 and NIPD datasets for \(\) values ranging from 0.1 to 0.5. As expected, the performance generally decreases with smaller \(\) values due to increased data heterogeneity. Table 2 indicates that as \(\) decreases, representing higher data heterogeneity, the performance of all models declines. CRFed consistently outperforms other methods across different \(\) settings, demonstrating its robustness in handling data heterogeneity. Notably, the relative performance gap between CRFed and other methods widens as \(\) decreases, highlighting its efficacy in more challenging federated learning scenarios.

Effect of Increasing Edge NodesFigure 4 presents the performance of the top 5 models on CIFAR-100 and NIPD datasets as the number of edge nodes \(K\) increases from 10 to 100. Across all models, performance generally improves with higher \(K\) values, reflecting better data utilization. Notably, CRFed shows the most significant gains, with accuracy increasing from 0.389 to 0.425 on CIFAR-100 and mAP from 0.882 to 0.920 on NIPD. This demonstrates CRFed's superior scalability and effectiveness in handling more edge nodes, making it robust in federated learning environments with increasing data sources.

  
**Scheme** & **MNIST** & **FashionMNIST** & **CIFAR-10** & **CIFAR-100** & **NIPD (mAP)** \\  FedAvg  & 0.976 & 0.847 & 0.650 & 0.362 & 0.821 \\ FedProx  & 0.978 & 0.844 & 0.655 & 0.365 & 0.826 \\ MOON  & 0.980 & 0.846 & 0.674 & 0.372 & 0.836 \\ FedGen  & 0.982 & 0.862 & 0.672 & 0.369 & 0.841 \\ HFMDS-FL  & 0.982 & 0.868 & 0.678 & 0.377 & 0.846 \\ FRAug  & 0.981 & 0.865 & 0.675 & 0.374 & 0.851 \\ G-FML  & 0.983 & 0.870 & 0.681 & 0.378 & 0.854 \\ FedCD  & 0.982 & 0.867 & 0.677 & 0.376 & 0.861 \\ FedNP  & 0.982 & 0.869 & 0.680 & 0.377 & 0.863 \\ FedDPMS  & 0.983 & 0.876 & 0.680 & 0.386 & 0.871 \\ CRFed & **0.985** & **0.878** & **0.683** & **0.389** & **0.882** \\   

Table 1: Test accuracy of CRFed and the competing methods on five datasets. We run five trials with different random seeds and report the mean accuracy.

    &  &  \\ 
**Scheme** & 0.1 & 0.3 & 0.5 & 0.1 & 0.3 & 0.5 \\  FedDPMS & 0.270 & 0.330 & 0.386 & 0.751 & 0.810 & 0.871 \\ FRAug & 0.268 & 0.328 & 0.374 & 0.746 & 0.800 & 0.851 \\ G-FML & 0.265 & 0.329 & 0.378 & 0.748 & 0.802 & 0.854 \\ FedCD & 0.275 & 0.333 & 0.376 & 0.750 & 0.808 & 0.861 \\ CRFed & **0.280** & **0.345** & **0.389** & **0.760** & **0.820** & **0.882** \\   

Table 2: Performance of top 5 models on CIFAR-100 and NIPD datasets under different \(\) values.

Figure 4: Effect of Increasing Edge Nodes

Convergence RateThe convergence performance of the top five models on FMNIST, CIFAR-10, and CIFAR-100 datasets is depicted in Figure 5. As observed, CRFed demonstrates significantly faster and more stable convergence compared to the competing methods across all three datasets. This superior performance is attributed to the diffusion-based data harmonization mechanism, which effectively aligns data distributions, and the confusion-resistant strategy that selects reliable clients and adaptively adjusts learning rates, ensuring efficient and robust training even in highly heterogeneous environments.

### Ablation Study

To evaluate the contribution of each component in the CRFed framework, we conduct an ablation study by removing or altering specific components and observing the impact on model performance. Removing the Indicator Function and using uniform sampling led to significant performance drops, with CIFAR-10 accuracy falling from 0.683 to 0.661, CIFAR-100 from 0.389 to 0.365, and NIPD mAP from 0.882 to 0.861. Excluding the Diffusion-based Data Harmonization (DDH) mechanism resulted in reduced accuracy on CIFAR-10 (0.670), CIFAR-100 (0.373), and NIPD mAP (0.870), highlighting its role in aligning data distributions. Replacing strategic client selection with random selection markedly decreased performance, emphasizing the importance of reliable client selection. Fixing the learning rate instead of adapting it slowed convergence and destabilized training. These findings validate the theoretical and practical significance of our proposed components in improving federated learning performance.

### Comparison with Importance Sampling Methods

Previous importance sampling methods typically require prior analysis of the data relevance at each client-side (Hsu et al., 2020; Tian et al., 2022) or necessitate deriving optimal sampling weights based on assumptions such as the convexity of the loss function (Rizk et al., 2022; Zhu et al., 2024). While these methods offer strong theoretical guarantees, they are somewhat limited in their adaptability to real-world federated learning (FL) scenarios. For instance, both FedIR (Hsu et al., 2020) and Harmony (Tian et al., 2022) assume that the server has knowledge of the local distributions of all clients. Although this assumption does not violate the privacy-preserving principles of FL, it can be challenging to obtain in real-world applications.

In contrast, our CRFed does not depend on these assumptions. Instead, it iteratively adjusts the data distributions during the FL process itself, enabling the model to dynamically harmonize the diverse, non-IID data across clients without requiring explicit distributional assumptions or centralized access to all client data distributions. Guided by the indicator function, our CRFed can derive the optimal sampling strategy for each local node.

Figure 5: Test accuracy across federated training rounds for top 5 models on FMNIST, CIFAR-10, and CIFAR-100 datasets.

Figure 6: Ablation study results on CIFAR-10, CIFAR-100, and NIPD datasets. The bar charts show the accuracy on CIFAR-10 and CIFAR-100 datasets, while the line plot represents the mAP on the NIPD dataset.

Moreover, as shown in Table 3, empirical experiments demonstrate that the diffusion model achieves superior performance, outperforming other benchmark methods.

It is worth noting that this comparison is not entirely fair, as each importance sampling method operates under different assumptions. For example, ISFL requires a validation set to update the empirical gradient Lipschitz constants for each local model, while FedIR requires all clients to upload the conditional distribution of images given class labels to match the target distribution. Nevertheless, our CRFed outperforms the others even under less restrictive conditionsunlike ISFedAvg and ISFL, it does not require assumptions about the loss function or gradient variance, and unlike FedIR and Harmony, it does not require centralized access to all client data distributions before calculating the importance sampling weights.

## 5 Conclusion

In conclusion, this study tackles the pressing challenge of handling non-i.i.d. data in federated learning environments. We propose the Confusion-Resistant Federated Learning via Consistent Diffusion (CRFed) framework. This framework introduces a novel Indicator Function that dynamically adjusts sample weighting, facilitating a self-paced learning paradigm that prioritizes more difficult samples over time. Additionally, our diffusion-based data harmonization mechanism ensures consistent and aligned data distributions through iterative noise injection and denoising processes, mitigating the adverse effects of data heterogeneity. Our strategic client selection method, guided by the Indicator Function, ensures that the most reliable clients are chosen for training, thus improving the robustness and consistency of global model updates.

Despite the promising results, our approach has certain limitations. The reliance on complex diffusion mechanisms and adaptive strategies may introduce computational overhead, which could be a concern for resource-constrained environments. Future work should focus on optimizing the computational efficiency of the CRFed framework and exploring its applicability to a broader range of real-world federated learning scenarios (Zhang et al., 2023).

## 6 Acknowledgement

This research was funded by the Basic Science Center Project for National Natural Science Foundation of China (Grant No: 72088101), the Xiangjiang Laboratory Major Project(Grant No: 23XJ01007), and the Fundamental Research Funds for the Central Universities of Central South University(Grant No: 1053320214050).