# FSscore: A Machine Learning-based Synthetic Feasibility Score Leveraging Human Expertise

Rebecca M. Neeser\({}^{12}\) Bruno Correia\({}^{2}\) Philippe Schwaller\({}^{13}\)

\({}^{1}\) Laboratory of Artificial Chemical Intelligence (LIAC), EPFL, Switzerland

\({}^{2}\) Laboratory of Protein Design and Immunoeningering (LPDI), EPFL, Switzerland

\({}^{3}\) National Centre of Competence in Research (NCCR) Catalysis, EPFL, Switzerland

{rebecca.neeser,bruno.correia,philippe.schwaller}@epfl.ch

###### Abstract

Determining whether a molecule can be synthesized is crucial for many aspects of chemistry and drug discovery, allowing prioritization of experimental work and ranking molecules in _de novo_ design tasks. Existing scoring approaches to assess synthetic feasibility struggle to extrapolate to out-of-distribution chemical spaces or fail to discriminate based on minor differences such as chirality that might be obvious to trained chemists. This work aims to address these limitations by introducing the Focused Synthesizability score (FSscore), which learns to rank structures based on binary preferences using a graph attention network. First, a baseline trained on an extensive set of reactant-product pairs is established that subsequently is fine-tuned with expert human feedback on a chemical space of interest. Fine-tuning on focused datasets improves performance on these chemical scopes over the pre-trained model exhibiting moderate performance and generalizability. This enables distinguishing hard- from easy-to-synthesize molecules and improving the synthetic accessibility of generative model outputs. On very complex scopes with limited labels achieving satisfactory gains remains challenging. The FSscore showcases how human expert feedback can be utilized to optimize the assessment of synthetic feasibility for a variety of applications.

## 1 Introduction

The ability to assess the synthetic feasibility of a small molecule is of great importance in many different areas of chemistry, notably in early drug discovery stages. Trained chemists traditionally perform this task through intuition or retrosynthetic analysis, allowing them to decide, which molecules are likely possible to synthesize and prioritize based on synthetic complexity. However, the chemical space that might be accessible is massive, and only a small fraction has been explored. [1; 2] Furthermore, computational approaches such as virtual screening (VS)  in drug discovery or the recent surge of generative methods for _de novo_ molecular design [4; 5; 6; 7; 8; 9; 10; 11; 12; 13; 14] emphasize the requirement for suitable tools to score synthetic feasibility quickly in an automated fashion. [15; 16].

Currently, available scores work well at discriminating feasible from unfeasible molecules in the data distribution that they were designed for but often fail to generalize. This is especially true for machine learning (ML) based scores that are unable to capture such an abstract concept as synthesizability and fail to perform well on out-of-distribution data, especially when applied in the context of generative models. [15; 17; 18; 19] However, exploring new chemical space is of great interest specifically in the context of _de novo_ design or new drug modalities such as synthetic macrocycles or proteolysis targeting chimeras (PROTACs). On the other hand, synthetic feasibility cannot be merely captured by the structure as it also depends on a chemist's available resources and expertise.  Thus, incorporating human preference would greatly improve the practical utility of such a score. This work presents a novel approach to assess synthetic feasibility and investigates the incorporation of expert knowledge to tune the model towards a desired chemical space. We build on ideas first put forth by Coley et al.  when introducing the SCScore. As such, we use reaction data to pre-train our model, which implicitly informs on the difficulty of synthesizing a molecule through the relational nature of the data, while containing more information than just the number of reaction steps. Furthermore, by framing this task as a ranking problem based on pairwise preferences, we avoid the need for a ground truth score, but base the model on reported chemical reactions. [22; 21] To ultimately tune to a specific chemical space with as little data as possible we fine-tune the unbiased baseline model with expert chemist-labeled data in an active-learning type framework as inspired by MolSkill . Besides the various applications as an offline scoring tool, this fully differentiable approach could also be directly used as guidance in generative models or as reward function in reinforcement learning (RL) frameworks. Compared to previous work [22; 23; 24], our representations consider stereochemistry and repeated substructures, which are crucial for determining the synthesizability of molecules. To summarize, the FSscore is trained in two stages:

1. Pre-trained on a large dataset of reactions to establish an unbiased baseline using an expressive graph neural network (GNN).
2. Fine-tuning using human feedback to focus the model towards a chemical space of interest.

Our main contributions are:

* We propose a novel approach for assessing synthetic feasibility that uses pairwise preferences and fine-tuning with human feedback to focus the model on a desired chemical space. This allows for incorporating expert knowledge and intuition.
* The method is fully differentiable, allowing it to be easily incorporated into generative models.
* Our experiments show the model can be effectively fine-tuned with relatively small amounts of human-labeled data, as little as 20-50 pairs, which is important for practicality.
* Fine-tuning improved performance on several chemical scopes, including natural products and PROTACs, demonstrating the approach's ability to adapt to new domains.

## 2 Related Work

Various methods to capture synthetic accessibility or complexity exist and can be structure-based (SA score , SYBA , GASA ) or reaction-based (SCScore , RAscore , CMPNN , RetroGNN , DFRscore ). The commonly used Synthetic Accessibility score (SA score) is rule-based and penalizes the occurrence of fragments rarely found in a reference dataset and the presence of specific structural features.  Thus, it captures more synthetic complexity than accessibility and fails to identify big complex molecules with mostly reasonable fragments. [15; 20] The SYBA score was trained to distinguish existing synthesizable molecules from artificial complex ones but the performance was found to be sub-optimal. [17; 23] Many of these structure-/fragment-based approaches suffer from the inability to capture small structural differences due to lacking sensitivity. Yu et al.  attempt to address this by using a graph representation to classify molecules into hard (HS) and easy (ES) to synthesize similarly to SYBA. The Synthetic Complexity score (SCScore) predicts complexity in terms of required reaction steps and is based on 1024-bit Morgan fingerprints. The SCScore was trained on the assumption that reactants are easier to make than products.  This score performs well on benchmarks approximating the length of the predicted reaction path but poorly when predicting feasibility in benchmarks using synthesis predictors.  The Retrosynthetic Accessibility score (RAscore) predicts synthetic feasibility with respect to a synthesis prediction tool and thus is directly dependent on the performance of the upstream model.  Similarly, RetroGNN classifies molecules based on retrosynthetic accessibility with the specific aim of being applied in VS.  Li and Chen  suggested a score based on a Communicative Message Passing Neural Network (CMPNN), which aims at discriminating ES from HS based on number of reaction steps using a reaction knowledge graph. Recently, the Drug-Focused Retrosynthetic score (DFRscore) was introduced by Kim et al.  predicting the number of reaction steps required based on a limited set of reaction templates relevant to drug discovery.

The incorporation of human feedback in ML has gained increasing attention since the introduction of RL with Human Feedback (RLHF)  by OpenAI, which lead to the development of popular tools such as InstructGPT  and ChatGPT . Learning with human feedback has also found its way into applications in chemistry: Sheridan et al.  trained a random forest model to predict the complexity based on human rankings. Ranking individual molecules instead of preference labeling is likely to suffer from more bias, which might be reflected in the moderate correlations of the labels to the predicted score.  This is avoided in the design of MolSkill, where the model learns to rank based on binary preferences made by medicinal chemists.  However, the scored objective, general preference, is loosely defined, and substantial pre-filtering of the training data makes the model not applicable to synthesizability and likely fails to generalize well.

## 3 Methods

### Focused Synthesizability score

The following sections outline the method behind the novel Focused Synthesizability score (FSscore). We first train a baseline score assessing synthesizability using a graph representation and suitable message passing scheme improving expressivity over similar frameworks such as the SCScore. Secondly, we introduce our fine-tuning approach using human expert knowledge, allowing us to focus the score towards a specific chemical space of interest.

#### 3.1.1 Ranking molecules using graph embeddings

Our approach to learning a continuous score to assess the synthesizability is inspired by Choung et al. , who frame a similar task as a ranking problem using binary preferences. Specifically, every data point consists of two molecules for which we each predict a scalar in separate forward passes. The minimization of the binary cross entropy between the true preference and the learned score difference \(_{ij}:=(m_{i})-(m_{j})\) (scaled using a sigmoid function) constitutes our training objective.

The function \(f:\) learns to parametrize molecules as an expressive latent representation given a set of molecules \(m_{1},...,m_{n}\). We represent molecules as graphs \(G=(,)\) with atoms as nodes \(x_{1},...,x_{n}\) and bonds as edges \(e_{1},...,e_{m}\) from which we can compute the line graph \(L(G)\) offline iteratively to the desired depth. The transformation process to the line graph is defined such that the edges \(\{e_{1},...,e_{m}\}\) of graph \(G\) are the nodes of the line graph and these nodes are connected if the corresponding edges of \(G\) share a node. The graph neural network (GNN) embedding the molecular graph consists of the graph attention network (GATv2)  operating on the graph \(G\) and the Line Evolution (LineEvo)  layer operating on the line graph \(L(G)\) as message passing schemes. Both GATv2 and LineEvo use an attention mechanism to update the node representations \(\{h_{1},...,h_{n}\}\) as followed:

\[e(h_{i},h_{j})=a^{T}(W_{i}h_{i}||W_{j}h_{j})\] (1)

where \(a^{2d^{}}\) and \(W^{d^{} d}\) are learned, \(\) denotes an activation function (LeakyReLU for GATv2 and ELU for LineEvo) and \(||\) denotes concatenation. In GATv2, these local attention scores \(e_{ij}\) are then averaged across all neighbors \(\) (see Eq. 2 to obtain a normalized attention coefficient \(_{ij}\) to compute the updated node representation \(h^{}_{i}\) as a weighted average (see Eq. 3):

\[_{ij}=_{j}(e(h_{i},h_{j}))=(e(h_{i},h_{j}) )}{_{j_{i}}(e(h_{i},h_{j}))}\] (2)

\[h^{}_{i}=(_{j_{i}}_{ij}Wh_{j})\] (3)

with PReLU as nonlinearity \(\). In LineEvo layers, \(e(h_{i},h_{j})\) is simply transformed using ELU to obtain the new node representation \(h^{}_{i}\).

These transformation layers are stacked so that two GATv2 (G) layers are followed by one LineEvo (L) layer (GGLGGL). Each of these layers is followed by a readout function to obtain a molecular representation, which consists of a global max pooling layer and global weighted-add pooling as suggested by Ren et al. . The intermediate molecular representations of all layers are summed and the final score \(s_{i}=(m_{i})\) is inferred with a multilayer perceptron (MLP). The model described above was compared to five other implementations: GATv2 layers only (GGG) and four fingerprint implementations, namely Morgan (boolean), Morgan counts, Morgan chiral (boolean), Morgan chiral counts all with radius 4 and 2048 bits.  The fingerprints are embedded by one linear layer with ReLU as activation function followed by the aforementioned MLP. More detailed information can be found in Appendix S1.2.

#### 3.1.2 Fine-tuning on human feedback

To focus our scoring model on a desired chemical space using human feedback, we apply a fine-tuning approach inspired by Cheung et al. . This approach was optimized to require as little data as possible in order to limit the time required from expert chemists labeling the training examples. Datasets to be used for fine-tuning can be of various origins such as a chemical scope suggested by experimentalists or specific chemical spaces encompassing e.g. natural products (see. Section 3.3. Data points from this set of molecules are determined using \(k\)-means clustering and subsequent pairing of molecules from different clusters. If labels are already available (no human feedback needed) they are used to inform the pairing such that pairs get opposite labels. Subsequently, the uncertainty of the prediction of the pre-trained model on those pairs is determined based on the variance of \(_{ij}\) obtained using the Monte Carlo dropout method  with a dropout rate of 0.2 on 100 predictions. The top \(n\) pairs (\(n\) depends on the dataset size) based on the uncertainty are submitted to be evaluated by our expert chemist based on their preference with regard to synthesizability.

These pairs of molecules capturing the desired human intuition or some predefined label (e.g. HS _vs._ ES) are subsequently used for fine-tuning the FSscore model. The fine-tuning process can be achieved with as little as up to 20 epochs. Furthermore, an early stopping approach was designed that incorporates both the improvement on the fine-tuning data while ensuring that the model does not experience degradation of the previously learned. Details can be found in Appendix S1.3.

### Data

To pre-train our model on a large collection of reactions we combine the USPTO_full  patent dataset with the complementary CJHIF . Reaction data implicitly contains information on the synthetic feasibility through the relation of reactant to product, with the product being synthetically more difficult. The USPTO_full  contains reactions extracted from the US patents grants and applications while CJHIF was mined from chemical journals with high impact factor . One data point consists of one reactant and its corresponding product. Reactions with multiple reactants per product were split into separate data points accordingly. The cleaned and filtered dataset was split into training (3,349,455 pairs) and hold-out test set (711,550 pairs) and a random validation set of 1% of the training data was sampled (33,495 pairs). We detail data processing in Appendix S2.1.

### Case studies and evaluation

We compare our approach with established scores, namely SA score, SCScore, SYBA and RAscore and report numerous metrics as described in Appendix S3. We investigate the qualitative performance of the pre-trained model on the MOSES  and COCONUT  datasets. MOSES contains commercially available drug-like molecules and is often used to benchmark generative models for drug discovery and COCONUT is a collection of natural products extracted from various sources. [42; 43]

We showcase the model's ability to efficiently focus our score by fine-tuning on several datasets:

* A subset from the pre-training set with chiral tetrahedral centers. The molecule with assigned chirality is labeled as more complex as opposed to the same molecule stripped of the respective assignment.
* The MC (manually curated) and CP (computationally picked) test sets published with the SYBA score.  Labels are provided and correspond to ES and HS.
* The meanComplexity dataset containing averaged complexity scores from chemists.  Binary labels are extracted from the continuous score [1; 5] based on a set-off of at least two.
* The PROTAC-DB , which is an open-source collection of PROTACs. Labels were obtained from human experts.

Additionally, the applicability to a generative modeling task is assessed. REINVENT  is used as a molecular generator due to its well-established RL framework and good performance on several benchmarks.  We further make use of the recently proposed augmented memory algorithm for sample efficiency.  First, an agent is optimized for docking to the D2 dopamine receptor (DRD2, PDB ID: 6CM4), which is a target for antipsychotic drugs. The collected SMILES are subsequently used to fine-tune the FSscore, which in turn serves as reward for a second round of RL. For comparison, another agent is optimized for the SA score for the same amount of oracle calls. The results are compared by number of reaction steps predicted by AiZynthFinder.  All case studies are further detailed in Appendix S2.2.

## 4 Results and discussion

### Pre-trained model

The pre-trained model with varying algorithmic and representation implementations was evaluated on the hold-out test set (see Tab. 1). The graph versions outperform fingerprint representations by a small difference and the best-performing model each is used for further investigations. These correspond to the GNN with GATv2 and LineEvo layers (GGLGGL) and the Morgan counts fingerprint. Furthermore, preliminary investigations with models trained on a random subset of 100k data points showed weaknesses of the boolean Morgan fingerprint, resulting in an unfair comparison. Not including the counts of fragments in the fingerprint leads to the inability to capture complexity based on recurrence even if the single fragment is common in the training set. The original publication of the SCScore briefly touches on the impact of varying the Morgan fingerprint, but contrary to us, they found this aspect to not influence the performance, leading them to choose the boolean 1024-bit vector. 

The analysis of the pre-trained model's predictions on MOSES (known drugs)  and COCONUT (natural products)  shows that the pre-trained FSscore is unable to distinguish these molecule classes assuming that COCONUT  contains more complex structures (see Fig. 1). While both the fingerprint- and graph-based FSscore outperform the SCScore in the area under the receiver operating characteristic curve (_AUC_), the SA score, SYBA and RAscore yield better results. The structures found in COCONUT  are likely out-of-distribution for the FSscore highlighting the opportunity for fine-tuning but it also emphasizes the power of rule-based methods such as the SA score.

### Fine-tuning

Figure 2 showcases the inability of all baseline scores, including our pre-trained models, to differentiate structures with assigned chirality from those without assignment. Synthesizing a predefined stereoisomer is a much more challenging task than being able to choose or even leave it up to chance. Figure 2 shows that fine-tuning on the chirality test set allows the differentiation of molecules in terms of their chirality assignment resulting in predicting molecules with a given isomer as more difficult to synthesize. The performance could likely be improved by increasing the dataset size as opposed to the 50 pairs used here. While the fingerprint-based models (Morgan _chiral_ counts) clearly are able to predict different scores, the meaning of the different representations are not captured by either the pre-trained or fine-tuned model.

Both SYBA test sets show clear room for improvement from the pre-trained baseline, especially on the MC set (see Fig. S4.4). The RAscore, SA score and SYBA clearly outperform the other scores. The RAscore, being an actual classifier, has a structural advantage on this task. The same is true for

  
**Model** & **Representation** & _Aec_\(\) & _AUC_\(\) \\  GNN (GGLGGL) & graph & **0.905** & **0.971** \\ GNN (GGG) & graph & 0.903 & 0.970 \\ MLP & Morgan & 0.87 & 0.954 \\ MLP & Morgan counts & 0.880 & 0.959 \\ MLP & Morgan chiral & 0.867 & 0.952 \\ MLP & Morgan chiral counts & 0.875 & 0.957 \\   

Table 1: Performance on the hold-out test set of graph-based models compared to various fingerprint implementations. Accuracy (_Acc_) and _AUC_ based on the score differences are reported. The best performing model is highlighted in bold. G = GATv2 layer; L = LineEvo layer SYBA, which was purposely trained to perform well on such datasets. The high _AUC_ with the SA score is to be expected on the CP set, where all HS molecules contain a ring-bridging atom. The good performance on the MC set is more surprising and showcases how well-formulated rules are valuable on in-distribution datasets. Fine-tuning on molecules from CP resulted in substantial increase in performance yielding an _AUC_ of 0.992 when fine-tuning on only 50 pairs. Good performance gain was even achieved with fewer data points as seen in Table S4.2. The MC test set is more challenging and the limited dataset size (40 pairs) makes evaluation challenging. However, Table S4.2 clearly shows that the FSscore can also improve such a heterogeneous dataset. When using overlapping pairs (molecules can appear in multiple pairs) the performance is improved substantially improved over the unique setting, however with the trade-off of reduced generalizability measured as performance on the pre-training test set (see Table S4.3). Furthermore, our goal is to keep the fine-tuning size to a minimum in order to facilitate human labeling.

The ability to score molecules, whose complexity was assigned by chemists was assessed on the meanComplexity dataset by Sheridan et al. . The correlations between all scores and the meanComplexity are shown in Figure S4.6. The correlation to meanComplexity was improved through fine-tuning (see Table S4.4) but still lacks behind scores such as SA score or RAscore. This could likely be rescued by increasing the fine-tuning dataset size from 50 pairs, which we aimed at keeping small. Only by using 500 overlapping pairs (molecules can appear in multiple pairs) can the fine-tuned FSscore outperform the SA score in terms of PCC (0.84 _vs._ 0.8 - see Figure S4.7).

Figure 1: Results showcasing the ability to differentiate molecules originating from MOSES  from those in COCONUT . The latter are expected to be more complex being natural products. The ROC curves in Figure 0(b) detail the power to discriminate MOSES  from COCONUT . The arrows in the distribution plot (Fig. 0(a)) indicate the direction of higher synthetic feasibility.

Figure 2: Distributions showcasing the ability to differentiate molecules with assigned tetrahedral chirality from their unassigned counterpart. The desired prediction would score the assigned molecules as more complex resulting in negative delta values (assigned - unassigned) in Figure 1(b).

PROTACs are large molecules (700-1100 Da) compared to traditional drugs but their fragmented composition allows synthesis of each ligand and the linker separately before connecting the three parts. Thus, their size often "fools" known scores, which rank them as synthetically hard making their relative scores unreliable. We obtain feedback from a chemist with expertise on PROTACs, who also remarked that most molecules they were prompted with are relatively easy to make. Figure 5 shows a distinct shift towards higher predicted synthetic feasibility after fine-tuning the FSscore and Figure 4 highlights the narrowing gap between each PROTAC and the respective most complex fragment (ligands or linker) after fine-tuning. The latter observation is desirable under the assumption that, given that connecting the three fragments is not challenging, the complexity of the full PROTAC is not much higher than its most complex components. However, the increase in performance is small (50 pairs: _Acc_ increases from 0.53 to 0.57 and _AUC_ from 0.43 to 0.52) on all tested fine-tuning dataset sizes and evaluation is challenging with only 100 labels (see Tab. S4.2). The performance gain on all PROTACs and the learning curves (see Fig. S6.29) clearly show the ability to learn relevant features emphasizing the need for more labeled data.

Our last case study couples human feedback to a generative model attempting targeted improvement of synthetic feasibility of the generated molecules. The optimization of the first agent for docking to DRD2 leads to the generation of lipophilic structures and polyaromatic ring systems. To improve the synthesizability a second agent is optimized for the fine-tuned FSscore. Figure 6 shows the superiority of the FSscore over the SA score in capturing the synthetic feasibility and generating molecules that are predicted to require less reaction steps. However, this comes at the expense in terms of docking score compared to the SA-optimized agent, which in turn generated many outliers with high docking scores. Figure S5.21 shows examples of generated structures of all three agents.

## 5 Limitations and future work

The pre-trained model often achieves worse results than the SA score indicating that the incorporation of carefully selected rules could be beneficial for a baseline. While focusing the score towards the chemical space of interest is attractive for many applications, it also poses its challenges to keep baseline generalizability. Furthermore, the necessity for individual fine-tuning comes at the expense of convenience as the FSscore is not meant to be used out of the box. The dataset size required for fine-tuning seems to be related to the complexity and homogeneity of the data. However, recruiting human labelers with sufficient expertise can be a challenge on its own and limited labels makes evaluation challenging. Further investigations should aim at performing a more extensive hyperparameter search as well as optimizing the architecture itself. Furthermore, a study of larger scale with more expert chemists would be of benefit to showcase generalizability and robustness. Lastly, extending the use for generative models in a variety of downstream tasks would be beneficial. Such experiments should include different architectures, a variety of specific objectives as well as ways of incorporating the score potentially through iterative fine-tuning in a active learning framework. It can be argued that directly incorporating synthesizability by design leads to more robust results in terms of synthetic feasibility but it also restricts the accessible chemical space more. 

## 6 Conclusion

This work introduces the novel FSscore, for evaluating synthetic feasibility, leveraging pairwise preferences and fine-tuning with human feedback to focus on specific chemical spaces. The score could be applied as filter in VS studies or as reward in RL frameworks and being fully differentiable allows the seamless integration into generative models. The use of pre-training on an extensive reaction dataset establishes a robust baseline, implicitly capturing synthetic complexity. Importantly, our experiments demonstrate the practicality of FSscore, showcasing its efficacy even with very small amounts of labeled data in certain cases. Fine-tuning improved performance on several chemical scopes over the pre-trained baseline, demonstrating the approach's ability to adapt to new domains.

## 7 Code availability and app

All code used for training, fine-tuning and scoring the FSscore is available at https://github.com/schwallergroup/fsscore. This repository also included an application that can be run locally and allows a more intuitive and accessible way to label data, fine-tune and deploy a model.