# Incentivized Communication for Federated Bandits

Zhepei Wei\({}^{1}\)1  Chuanhao Li\({}^{1}\)1  Haifeng Xu\({}^{2}\)  Hongning Wang\({}^{1}\)

University of Virginia\({}^{1}\) University of Chicago\({}^{2}\)

{tqf5qb, cl5ev, hw5x}@virginia.edu

haifengxu@chicago.edu

Equal Contribution

###### Abstract

Most existing works on federated bandits take it for granted that all clients are altruistic about sharing their data with the server for the collective good whenever needed. Despite their compelling theoretical guarantee on performance and communication efficiency, this assumption is overly idealistic and oftentimes violated in practice, especially when the algorithm is operated over self-interested clients, who are reluctant to share data without explicit benefits. Negligence of such self-interested behaviors can significantly affect the learning efficiency and even the practical operability of federated bandit learning. In light of this, we aim to spark new insights into this under-explored research area by formally introducing an incentivized communication problem for federated bandits, where the server shall motivate clients to share data by providing incentives. Without loss of generality, we instantiate this bandit problem with the contextual linear setting and propose the first incentivized communication protocol, namely, Inc-FedUCB, that achieves near-optimal regret with provable communication and incentive cost guarantees. Extensive empirical experiments on both synthetic and real-world datasets further validate the effectiveness of the proposed method across various environments.

## 1 Introduction

Federated bandit learning has recently emerged as a promising new direction to promote the application of bandit models while preserving privacy by enabling collaboration among multiple distributed clients . The main focus in this line of research is on devising communication-efficient protocols to achieve near-optimal regret in various settings. Most notably, the direction on federated contextual bandits has been actively gaining momentum, since the debut of several benchmark communication protocols for contextual linear bandits in the P2P  and star-shaped  networks. Many subsequent studies have explored diverse configurations of the clients' and environmental modeling factors and addressed new challenges arising in these contexts. Notable recent advancements include extensions to asynchronous linear bandits , generalized liner bandits , and kernelized contextual bandits .

Despite the extensive exploration of various settings, almost all existing federated bandit algorithms rely on the assumption that every client in the system is willing to share their local data/model with the server, regardless of the communication protocol design. For instance, synchronous protocols  require all clients to simultaneously engage in data exchange with the server in every communication round. Similarly, asynchronous protocols  also assume clients must participate in communication as long as the individualized upload or download event is triggered, albeit allowing interruptions by external factors (e.g., network failure).

In contrast, our work is motivated by the practical observation that many clients in a federated system are inherently self-interested and thus reluctant to share data without receiving explicit benefits from the server . For instance, consider the following scenario: a recommendation platform(server) wants its mobile app users (clients) to opt in its new recommendation service, which switches previous on-device local bandit algorithm to a federated bandit algorithm. Although the new service is expected to improve the overall recommendation quality for all clients, particular clients may not be willing to participate in this collaborative learning, as the expected gain for them might not compensate their locally increased cost (e.g., communication bandwidth, added computation, lost control of their data, and etc). In this case, additional actions have to be taken by the server to encourage participation, as it has no power to force clients. This exemplifies the most critical concern in the real-world application of federated learning . And a typical solution is known as _incentive mechanism_, which motivates individuals to contribute to the social welfare goal by offering incentives such as monetary compensation.

While recent studies have explored incentivized data sharing in federated learning [30; 38], most of which only focused on the supervised offline learning setting . To our best knowledge, ours is the first work that studies incentive design for federated bandit learning, which inherently imposes new challenges. First, there is a lack of well-defined metric to measure the utility of data sharing, which rationalizes a client's participation. Under the context of bandit learning, we measure data utility by the expected regret reduction from the exchanged data for each client. As a result, each client values data (e.g., sufficient statistics) from the server differently, depending on how such data aligns with their local data (e.g., the more similar the less valuable). Second, the server is set to minimize regret across all clients through data exchange. But as the server does not generate data, it can be easily trapped by the situation where its collected data cannot pass the critical mass to ensure every participating client's regret is close to optimal (e.g., the data under server's possession cannot motivate the clients who have more valuable data to participate). To break the deadlock, we equip the server to provide monetary incentives. Subsequently, the server needs to minimize its cumulative monetary payments, in addition to the regret and communication minimization objectives as required by federated bandit learning. We propose a provably effective incentivized communication protocol, based on a heuristic search strategy to balance these distinct learning objectives. Our solution obtains near-optimal regret \(O(d T)\) with provable communication and incentive cost guarantees. Extensive empirical simulations on both synthetic and real-world datasets further demonstrate the effectiveness of the proposed protocol in various federated bandit learning environments.

## 2 Related Work

Federated Bandit LearningOne important branch in this area is federated multi-armed bandits (MABs), which has been well-studied in the literature [27; 36; 19; 4; 20; 28; 32; 39; 34; 33; 43]. The other line of work focuses on the federated contextual bandit setting [18; 40], which has recently attracted increasing attention. Wang et al.  and Korda et al.  are among the first to investigate this problem, where multiple communication protocols for linear bandits [1; 26] in star-shaped and P2P networks are proposed. Many follow-up works on federated linear bandits [10; 15; 22; 13] have emerged with different client and environment settings, such as investigating fixed arm set , incorporating differential privacy , and introducing asynchronous communication [13; 22]. Li et al.  extend the federated linear bandits to generalized linear bandits . And they further investigated federated learning for kernelized contextual bandits in both synchronous and asynchronous settings [24; 25].

In this work, we situate the incentivized federated bandit learning problem under linear bandits with time-varying arm sets, which is a popular setting in many recent works [40; 10; 22; 13]. But we do not assume the clients will always participate in data sharing: they will choose not to share their data with the server if the resulting benefit of data sharing is not deemed to outweigh the cost. Here we need to differentiate our setting from those with asynchronous communication, e.g., Asyn-LinUCB . Such algorithms still assume all clients are willing to share, though sometimes the communication can be interrupted by some external factors (e.g., network failure). We do not assume communication failures and leave it as our future work. Instead, we assume the clients need to be motivated to participate in federated learning, and our focus is to devise the minimum incentives to obtain the desired regret and communication cost for all participating clients.

Incentivized Federated LearningData sharing is essential to the success of federated learning , where client participation plays a crucial role. However, participation involves costs, such as the need for additional computing and communication resources, and the risk of potential privacy breaches, which can lead to opt-outs [5; 14]. In light of this, recent research has focused on investigating incentive mechanisms that motivate clients to contribute, rather than assuming their willingness to participate. Most of the existing research involves multiple decentralized clients solving the same task, typically with different copies of IID datasets, where the focus is on designing data valuation methods that ensure fairness or achieve a specific accuracy objective [35; 41; 8]. On the other hand, Donahue et al.  study voluntary participation in model-sharing games, where clients may opt out due to biased global models caused by the aggregated non-IID datasets. More recently, Karimireddy et al.  investigated incentive mechanism design for data maximization while avoiding free riders. For a detailed discussion of this topic, we refer readers to recent surveys on incentive mechanism design in federated learning [42; 38].

However, most works on incentivized federated learning only focus on better model estimation among fixed offline datasets, which does not apply to the bandit learning problem, where the exploration of growing data is also part of the objective. More importantly, in our incentivized federated bandit problem, the server is obligated to improve the overall performance of the learning system, i.e., minimizing regret among all clients, which is essentially different from previous studies where the server only selectively incentivizes clients to achieve a certain accuracy  or to investigate how much accuracy the system can achieve without payment .

## 3 Preliminaries

In this section, we formally introduce the incentivized communication problem for federated bandits under the contextual linear bandit setting.

### Federated Bandit Learning

We consider a learning system consisting of (1) \(N\) clients that directly interact with the environment by taking actions and receiving the corresponding rewards, and (2) a central server that coordinates the communication among the clients to facilitate their learning collectively. The clients can only communicate with the central server, but not with each other, resulting in a star-shaped communication network. At each time step \(t[T]\), an arbitrary client \(i_{t}[N]\) becomes active and chooses an arm \(_{t}\) from a candidate set \(_{t}^{d}\), and then receives the corresponding reward feedback \(y_{t}=f(_{t})+_{t}\). Note that \(_{t}\) is time-varying, \(f\) denotes the unknown reward function shared by all clients, and \(_{t}\) denotes zero mean sub-Gaussian noise with known variance \(^{2}\).

The performance of the learning system is measured by the cumulative (pseudo) regret over all \(N\) clients in the finite time horizon \(T\), i.e., \(R_{T}=_{t=1}^{T}r_{t}\), where \(r_{t}=_{_{t}}[y|]-[ y_{t}|_{t}]\) is the regret incurred by client \(i_{t}\) at time step \(t\). Moreover, under the federated learning setting, the system also needs to keep the communication cost \(C_{T}\) low, which is measured by the _total number of scalars_ being transferred across the system up to time \(T\). With the linear reward assumption, i.e., \(f()=^{}_{}\), where \(_{}\) denotes the unknown parameter, a ridge regression estimator \(_{t}=V_{t}^{-1}b_{t}\) can be constructed based on sufficient statistics from all \(N\) clients at each time step \(t\), where \(V_{t}=_{s=1}^{t}_{s}_{s}^{}\) and \(b_{t}=_{s=1}^{t}_{s}y_{s}\). Using \(_{t}\) under the Optimism in the Face of Uncertainty (OFUL) principle , one can obtain the optimal regret \(R_{T}=O(d)\). To achieve this regret bound in the federated setting, a naive method is to immediately share statistics of each newly collected data sample to all other clients in the system, which essentially recovers its centralized counterpart. However, this solution incurs a disastrous communication cost \(C_{T}=O(d^{2}NT)\). On the other extreme, if no communication occurs throughout the entire time horizon (i.e., \(C_{T}=0\)), the regret upper bound can be up to \(R_{T}=O(d)\) when each client interacts with the environment at the same frequency, indicating the importance of timely data/model aggregation in reducing \(R_{T}\).

To balance this trade-off between regret and communication cost, prior research efforts centered around designing communication-efficient protocols for federated bandits that feature the "delayed update" of sufficient statistics [40; 22; 13]. Specifically, each client \(i\) only has a delayed copy of \(V_{t}\) and \(b_{t}\), denoted as \(V_{i,t}=V_{t_{}}+ V_{i,t},b_{i,t}=b_{t_{}}+ b _{i,t}\), where \(V_{t_{}},b_{t_{}}\) is the aggregated sufficient statistics shared by the server in the last communication, and \( V_{i,t}, b_{i,t}\) is the accumulated local updates that client \(i\) obtain from its interactions with the environment since \(t_{}\). In essence, the success of these algorithms lies in the fact that \(V_{t},b_{t}\) typically changes slowly and thus has little instant impact on the regret for most time steps. Therefore, existing protocols that only require occasional communications can still achieve nearly optimal regret, despite the limitation on assuming clients' willingness on participation as we discussed before.

### Incentivized Federated Bandits

Different from the prior works in this line of research, where all clients attractitically share their data with the server whenever a communication round is triggered, we are intrigued in a more realistic setting where clients are _self-interested_ and thus reluctant to share data with the server if not well motivated. Formally, each client in the federated system inherently experiences a cost2 of data sharing, denoted by \(_{i}^{p}\), due to their individual consumption of computing resources in local updates or concerns about potential privacy breaches caused by communication with the server. Moreover, as the client has nothing to lose when there is no local update to share in a communication round at time step \(t\), in this case we assume the cost is 0, i.e., \(D_{i}^{p}=_{i}^{p}( V_{i,t})\). As a result, the server needs to motivate clients to participate in data sharing via the incentive mechanism \(:^{N}^{d d}^{N}\), which takes as inputs a collection of client local updates \( V_{i,t}^{d d}\) and a vector of cost values \(D^{p}=\{D_{1}^{p},,D_{N}^{p}\}^{N}\), and outputs the incentive \(=\{_{1,t},,_{N,t}\}^{N}\) to be distributed among the clients. Specifically, to make it possible to measure gains and losses of utility in terms of real-valued incentives (e.g., monetary payment), we adopt the standard _quasi-linear_ utility function assumption, as is standard in economic analysis [2; 31].

At each communication round, a client decides whether to share its local update with the server based on the potential utility gained from participation, i.e., the difference between the incentive and the cost of data sharing. This requires the incentive mechanism to be _individually rational_:

**Definition 1** (Individual Rationality ): _An incentive mechanism \(:^{N}^{d d}^{N}\) is individually rational if for any \(i\) in the participant set \(S_{t}\) at time step \(t\), we have_

\[_{i,t} D_{i}^{p}\] (1)

_In other words, each participant must be guaranteed non-negative utility by participating in data sharing under \(\)._

The server coordinates with all clients and incentivizes them to participate in the communication to realize its own objective (e.g., collective regret minimization). This requires \(\) to be _sufficient_:

**Definition 2** (Sufficiency): _An incentive mechanism \(:^{N}^{d d}^{N}\) is sufficient if the resulting outcome satisfies the server's objective._

Typically, under different application scenarios, the server may have different objectives, such as regret minimization or best arm identification. In this work, we set the objective of the server to minimize the regret across all clients; and ideally the server aims to attain the optimal \((d)\) regret in the centralized setting via the incentivized communication. Therefore, we consider an incentive mechanism is sufficient if it ensures that the resulting accumulated regret is bounded by \((d)\).

## 4 Methodology

The communication backbone of our solution derives from DisLinUCB , which is a widely adopted paradigm for federated linear bandits. We adopt their strategy for arm selection and communication trigger, so as to focus on the incentive mechanism design. We name the resulting algorithm Inc-FedUCB, and present it in Algorithm 1. Note that the two incentive mechanisms to be presented in Section 4.2 and 4.3 are not specific to any federated bandit learning algorithms, and each of them can be easily extended to alternative workarounds as a plug-in to accommodate the incentivized federated learning setting. For clarity, a summary of technical notations can be found in Table 7.

### A General Framework: Inc-FedUCB Algorithm

Our framework comprises three main steps: 1) client's local update; 2) communication trigger; and 3) incentivized data exchange among the server and clients. Specifically, after initialization, an active client performs a local update in each time step and checks the communication trigger. If a communication round is triggered, the system performs incentivized data exchange between clients and the server. Otherwise, no communication is needed.

Formally, at each time step \(t=1,,T\), an arbitrary client \(i_{t}\) becomes active and interacts with its environment using observed arm set \(_{t}\) (Line 5). Specifically, it selects an arm \(_{t}_{t}\) that maximizes the UCB score as follows (Line 6):

\[_{t}=*{arg\,max}_{_{t}}^{}_{i_{t},t-1}()+_{i_{t},t-1}||||_{V_ {i_{t},t-1}^{-1}()}\] (2)

where \(_{i_{t},t-1}()=V_{i_{t},t-1}^{-1}()b_{i_{t},t-1}\) is the ridge regression estimator of \(_{*}\) with regularization parameter \(>0\), \(V_{i_{t},t-1}()=V_{i_{t},t-1}+ I\), and \(_{i_{t},t-1}=,t-1}())}{ ( I)}+2 1/}+\). \(V_{i_{t},t}()\) denotes the covariance matrix constructed using data available to client \(i_{t}\) up to time \(t\). After obtaining a new data point \((_{t},y_{t})\) from the environment, client \(i_{t}\) checks the communication event trigger \( t_{i_{t},t},t}())}{(V_{i_{t},t _{}}())}>D_{c}\) (Line 9), where \( t_{i_{t},t}\) denotes the time elapsed since the last time \(t_{}\) it communicated with the server and \(D_{c} 0\) denotes the specified threshold.

Incentivized Data ExchangeWith the above event trigger, communication rounds only occur if (1) a substantial amount of new data has been accumulated locally at client \(i_{t}\), and/or (2) significant time has elapsed since the last communication. However, in our incentivized setting, triggering a communication round does not necessarily lead to data exchange at time step \(t\), as the participant set \(S_{t}\) may be empty (Line 11). This characterizes the fundamental difference between Inc-FedUCB and DisLinUCB : we no longer assume all \(N\) clients will share their data with the server in an altruistic manner; instead, a rational client only shares its local update with the server if the condition in Eq. (1) is met. In light of this, to evaluate the potential benefit of data sharing, all clients must first reveal the value of their data to the server before the server determines the incentive. Hence, after a communication round is triggered, all clients upload their latest sufficient statistics update \( V_{i,t}\) to the server (Line 10) to facilitate data valuation and participant selection in the incentive mechanism (Line 11). Note that this disclosure does not compromise clients' privacy, as the clients' secret lies in \( b_{i,t}\) that is constructed by the rewards. Only participating clients will upload their \( b_{i,t}\) to the server (Line 13). After collecting data from all participants, the server downloads the aggregated updates \( V_{-i,t}\) and \( b_{-i,t}\) to every client \(i\) (Line 17-20). Following the convention in federated bandit learning , the communication cost is defined as the total number of scalars transferred during this data exchange process.

### Payment-free Incentive Mechanism

As mentioned in Section 1, in federated bandit learning, clients can reduce their regret by using models constructed via shared data. Denote \(_{t}\) as the covariance matrix constructed by all available data in the system at time step \(t\). Based on Lemma 5 and 7, the instantaneous regret of client \(i_{t}\) is upper bounded by:

\[r_{t} 2_{i_{t},t-1}_{t}^{}_{t-1}^{-1} _{t}}_{t-1})}{(V_{i_{t},t-1}) }}=O(})\|_{t}\|_{ _{t-1}^{-1}}_{t-1})}{(V_{ i_{t},t-1})}}\] (3)

where the determinant ratio reflects the additional regret due to the delayed synchronization between client \(i_{t}\)'s local sufficient statistics and the global optimal oracle. Therefore, **minimizing this ratio directly corresponds to reducing client \(i_{t}\)'s regret**. For example, full communication keeps the ratio at 1, which recovers the regret of the centralized setting discussed in Section 3.1.

Therefore, given the client's desire for regret minimization, the data itself can be used as a form of incentive by the server. And the star-shaped communication network also gives the server an information advantage over any single client in the system: a client can only communicate with the server, while the server can communicate with every client. Therefore, the server should utilize this advantage to create incentives (i.e., the LHS of Eq. (1)), and a natural design to evaluate this data incentive is:

\[_{i,t}:=_{i,t}^{d}=(S_{t})+V_{i,t })}{(V_{i,t})}-1.\] (4)

where \(D_{i,t}(S_{t})=_{j:\{ V_{j,t} S_{t}\}\{j i\}} V _{j,t}+ V_{-i,t}\) denotes the data that the server can offer to client \(i\) during the communication at time \(t\) (i.e., current local updates from other participants that have not been shared with the server) and \( V_{-i,t}\) is the historically aggregated updates stored in the server that has not been shared with client \(i\). Eq. (4) suggests a substantial increase in the determinant of the client's local data is desired by the client, which ultimately results in regret reduction.

With the above data valuation in Eq. (4), we propose the _payment-free_ incentive mechanism that motivates clients to share data by redistributing data collected from participating clients. We present this mechanism in Algorithm 2, and briefly sketch it below. First, we initiate the participant set \(S_{t}=_{t}\), assuming all clients agree to participate. Then, we iteratively update \(S_{t}\) by checking the willingness of each client \(i\) in \(S_{t}\) according to Eq. (1). If \(S_{t}\) is empty or all clients in it are participating, then terminate; otherwise, remove client \(i\) from \(S_{t}\) and repeat the process.

```
1:\(D^{p}=\{D_{i}^{p}|i[N]\}\), \(_{t}=\{ V_{i,t}|i[N]\}\)
2:Initialize participant set \(S_{t}=_{t}\)
3:while\(S_{t}\)do\(\) iteratively update \(S_{t}\) until it becomes stable
4: StableFlag \(=\) True
5:for\(i: V_{i,t} S_{t}\)do
6:if\(_{i,t}<D_{i}^{p}\)then\(\) Eq. 4
7: Update participant set \(S_{t}=S_{t}\{ V_{i,t}\}\)\(\) remove client \(j\) from \(S_{t}\)
8: StableFlag \(=\) False
9:break
10:break
11:if StableFlag \(=\) True then
12:break
13:return\(S_{t}_{t}\) ```

**Algorithm 2** Payment-free Incentive Mechanism

While this payment-free incentive mechanism is neat and intuitive, it has no guarantee on the amount of data that can be collected. To see this, we provide a theoretical negative result with rigorous regret analysis in Theorem 3 (see proof in Appendix C).

**Theorem 3** (Sub-optimal Regret): _When there are at most \(\) number of clients (for some constant \(C,c>0\)), whose cost value \(D_{i}^{p}\{(1+}{})^{T},(1+}{ d})^{ d}\}\), there exists a linear bandit instance with \(=L=S=1\) such that for \(T Nd\), the expected regret for Inc-FedUCB algorithm with payment-free incentive mechanism is at least \((d)\)._Recall the discussion in Section 3.1, when there is no communication \(R_{T}\) is upper bounded by \(O(d)\). Hence, in the worst-case scenario, the payment-free incentive mechanism might not motivate any client to participate. It is thus not a sufficient mechanism.

### Payment-efficient Incentive Mechanism

To address the insufficiency issue, we further devise a _payment-efficient_ incentive mechanism that introduces additional monetary incentives to motivate clients' participation:

\[_{i,t}:=_{i,t}^{d}+_{i,t}^{m}\] (5)

where \(_{i,t}^{d}\) is the data incentive defined in Eq. (4), and \(_{i,t}^{m}\) is the real-valued monetary incentive, i.e., the payment assigned to the client for its participation. Specifically, we are intrigued by the question: rather than trivially paying unlimited amounts to ensure everyone's participation, can we devise an incentive mechanism that guarantees a certain level of client participation such that the overall regret is still nearly optimal but under acceptable monetary incentive cost?

Inspired by the determinant ratio principle discussed in Eq. (3), we propose to control the overall regret by ensuring that every client closely approximates the oracle after each communication round, which can be formalized as \((V_{g,t})/(_{t})\), where \(V_{g,t}=V_{g,t-1}+(S_{t})\) is to be shared with all clients and \((S_{t})=_{j:\{ V_{j,t} S_{t}\}} V_{j,t}\). The parameter \(\) characterizes the chosen gap between the practical and optimal regrets that the server commits to. Denote the set of clients motivated by \(_{i,t}^{d}\) at time \(t\) as \(S_{t}^{d}\) and those motivated by \(_{i,t}^{m}\) as \(S_{t}^{m}\), and thus \(S_{t}=S_{t}^{m} S_{t}^{d}\). At each communication round, the server needs to find the minimum \(_{i,t}^{m}\) such that pooling local updates from \(S_{t}\) satisfies the required regret reduction for the entire system.

Note that Algorithm 2 maximizes \(_{i,t}^{d}\), and thus the servers should compute \(_{i,t}^{m}\) on top of optimal \(_{i,t}^{d}\) and resulting \(S_{t}^{d}\), which however is still combinatorially hard. First, a brute-force search can yield a time complexity up to \(O(2^{N})\). Second, different from typical optimal subset selection problems , the dynamic interplay among clients in our specific context brings a unique challenge: once a client is incentivized to share data, the other uninvolved clients may change their willingness due to the increased data incentive, making the problem even more intricate.

To solve the above problem, we propose a heuristic ranking-based method, as outlined in Algorithm 3. The heuristic is to rank clients by the marginal gain they bring to the server's determinant, as formally defined in Eq. (6), which helps minimize the number of clients requiring monetary incentives, while empowering the participation of other clients motivated by the aggregated data. This forms an iterative search process: First, we rank all \(m\) non-participating clients (Line 2-3) by their potential contribution to the server (with participant set \(S_{t}\) committed); Then, we segment the list by \(\), anyone whose participation satisfies the overall \(\) gap constraint is an immediately valid choice (Line 4). The first client \(i_{}\) in the valid list and its payment \(_{}^{m}\) (\(\) if not available) will be our _last resort_ (Line 5); Lastly, we check if there exist potentially more favorable solutions from the invalid list (Line 6). Specifically, we try to elicit up to \(k=-1\) (\(k=m\) if \(i_{}\) is not available) clients from the invalid list in \(n k\) rounds, where only one client will be chosen using the same heuristic in each round. If having \(n\) clients from the invalid list also satisfies the \(\) constraint and results in a reduced monetary incentive cost compared to \(_{}^{m}\), then we opt for this alternative solution. Otherwise, we will adhere to the _last resort_.

This _Heuristic Search_ is detailed in Appendix A, and it demonstrates a time complexity of only \(O(N)\) in the worst-case scenarios, i.e., \(n=m=N\). Theorem 4 guarantees the sufficiency of this mechanism _w.r.t_ communication and payment bounds.

**Theorem 4**: _Under threshold \(\) and clients' committed data sharing cost \(D^{p}=\{D_{1}^{p},,D_{N}^{p}\}\), with high probability the monetary incentive cost of Inc-FedUCB satisfies_

\[M_{T}=O( D^{p} P N-_{i=1}^{N}P_{i}()})^{}}).\]

_where \(P_{i}\) is the number of epochs client \(i\) gets paid throughout time horizon \(T\), \(P\) is the total number of epochs, which is bounded \(P=O(Nd T)\) by setting communication threshold \(D_{c}=d T}-}{N^{2}dR T}}\), where \(R= d(1+)\)._

_Henceforth, the communication cost satisfies_

\[C_{T}=O(Nd^{2}) P=O(N^{2}d^{3} T)\]

_Furthermore, by setting \( e^{-}\), the cumulative regret is_

\[R_{T}=O(d T)\]

The proof of theorem 4 can be found in Appendix D.

## 5 Experiments

We simulate the incentivized federated bandit problem under various environment settings. Specifically, we create an environment of \(N=50\) clients with cost of data sharing \(D^{p}=\{D_{1}^{p},,D_{N}^{p}\}\), total number of iterations \(T=5,000\), feature dimension \(d=25\), and time-varing arm pool size \(K=25\). By default, we set \(D_{i}^{p}=D_{}^{p}, i[N]\). Due to the space limit, more detailed results and discussions on real-world dataset can be found in Appendix E.

### Payment-free vs. Payment-efficient

We first empirically compared the performance of the payment-free mechanism (named as Inc-FedUCB-PF) and the payment-efficient mechanism Inc-FedUCB in Figure 1. It is clear that the added monetary incentives lead to lower regret and communication costs, particularly with increased \(D_{*}^{p}\). Lower regret is expected as more data can be collected and shared; while the reduced communication cost is contributed by reduced communication frequency. When less clients can be motivated in one communication round, more communication rounds will be triggered as the clients tend to have outdated local statistics.

Figure 1: Comparison between payment-free vs. payment-efficient incentive designs. The results are averaged over 10 runs with standard deviation as the error bars.

### Ablation Study on Heuristic Search

To investigate the impact of different components in our heuristic search, we compare the full-fledged model Inc-FedUCB with following variants on various environments: (1) Inc-FedUCB (w/o PF): without payment-free incentive mechanism, where the server only use money to incentivize clients; (2) Inc-FedUCB (w/o IS): without iterative search, where the server only rank the clients once. (3) Inc-FedUCB (w/o PF + IS): without both above strategies.

In Figure 2, we present the averaged learning trajectories of regret and communication cost, along with the final payment costs (normalized) under different \(D_{}^{p}\). The results indicate that the full-fledged Inc-FedUCB consistently outperforms all other variants in various environments. Additionally, there is a substantial gap between the variants with and without the PF strategy, emphasizing the significance of leveraging the server's information advantage to motivate participation.

### Environment & Hyper-Parameter Study

We further explored diverse \(\) hyper-parameter settings for Inc-FedUCB in various environments with varying \(D_{}^{p}\), along with the comparison with DisLinUCB  (only comparable when \(D_{}^{p}=0\)). Specifically, we explored different hyper-parameter settings for Inc-FedUCB with determinant ratio threshold \([0.3,0.7,1]\), and various environmental configurations with data sharing cost \(D_{}^{p}\).

As shown in Table 1, when all clients are incentivized to share data, our Inc-FedUCB essentially recover the performance of DisLinUCB, while overcoming its limitation in incentivized settings when clients are not willing to share by default. Moreover, by reducing the threshold \(\), we can substantially save payment costs while still maintaining highly competitive regret, albeit at the expense of increased communication costs. And the reason for this increased communication cost has been explained before: more communication rounds will be triggered, as clients become more outdated.

    & DisLinUCB & Inc-FedUCB (\(=1\)) & Inc-FedUCB (\(=0.7\)) & Inc-FedUCB (\(=0.3\)) \\   ^{p}=0\)} & Regret (Acc.) & 48.46 & 48.46 (\(=0\%\)) & 48.46 (\(=0\%\)) \\   & Comm. Cost & 7,605,000 & 7,605,000 & 7,605,000 (\(=0\%\)) & 7,605,000 (\(=0\%\)) \\   & Pay. Cost & \(\) & 0 & 0 (\(=0\%\)) & 0 (\(=0\%\)) \\   ^{p}=10\)} & Regret (Acc.) & \(\) & 48.46 & 47.70 (\(=1.6\%\)) & 48.38 (\(=0.2\%\)) \\   & Comm. Cost & \(\) & 7,605,000 & 7,668,825 (\(+0.8\%\)) & 7,733,575 (\(+1.7\%\)) \\   & Pay. Cost & \(\) & 75.12 & 60.94 (\(-18.9\%\)) & 22.34 (\(-70.3\%\)) \\   ^{p}=10\)} & Regret (Acc.) & \(\) & 48.46 & 48.21 (\(-0.5\%\)) & 47.55 (\(-1.9\%\)) \\   & Comm. Cost & \(\) & 7,605,000 & 7,779,425 (\(+2.3\%\)) & **8,599,950 (\(+13\%\))** \\   & Pay. Cost & \(\) & 12,819,61 & 9,050.61 (\(-29.4\%\)) & **4,859.17 (\(-62.1\%\))** \\   ^{p}=100\)} & Regret (Acc.) & \(\) & 48.46 & 48.22 (\(-0.5\%\)) & 48.44 (\(-0.1\%\)) \\   & Comm. Cost & \(\) & 7,605,000 & 7,842,775 (\(+3.1\%\)) & **8,718,425** (\(+14.6\%\)) \\    & Pay. Cost & \(\) & 190,882.45 & 133,426.01 (\(-30.1\%\)) & **88,893.78 (\(-53.4\%\))** \\   

Table 1: Study on hyper-parameter of Inc-FedUCB and environment.

Figure 2: Ablation study on heuristic search (w.r.t \(D_{}^{p}\)). The results are averaged over 10 runs with standard deviation as the error bars.

Conclusion

In this work, we introduce a novel incentivized communication problem for federated bandits, where the server must incentivize clients for data sharing. We propose a general solution framework Inc-FedUCB, and initiate two specific implementations introducing data and monetary incentives, under the linear contextual bandit setting. We prove that Inc-FedUCB flexibly achieves customized levels of near-optimal regret with theoretical guarantees on communication and payment costs. Extensive empirical studies further confirmed our versatile designs in incentive search across diverse environments. Currently, we assume all clients truthfully reveal their costs of data sharing to the server. We are intrigued in extending our solution to settings where clients can exhibit strategic behaviors, such as misreporting their intrinsic costs of data sharing to increase their own utility. It is then necessary to study a truthful incentive mechanism design.

Acknowledgement.We thank the anonymous reviewers for their insightful and constructive comments. This project is partially supported by NSF Award IIS-2213700 and IIS-2128019. Haifeng Xu is supported by an NSF Award CCF-2303372, an Army Research Office Award W911NF-23-1-0030, and an Office of Naval Research Award N00014-23-1-2802.