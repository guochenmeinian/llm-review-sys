# Stochastic oracle:

From Linear to Linearizable Optimization: A Novel Framework with Applications to Stationary and Non-stationary DR-submodular Optimization

 Mohammad Pedramfar

McGill University and Mila 1

mohammad.pedramfar@mila.quebec

&Vaneet Aggarwal

Purdue University

vaneet@purdue.edu

###### Abstract

This paper introduces the notion of upper-linearizable/quadratzable functions, a class that extends concavity and DR-submodularity in various settings, including monotone and non-monotone cases over different types of convex sets. A general meta-algorithm is devised to convert algorithms for linear/quadratic maximization into ones that optimize upper-linearizable/quadratzable functions, offering a unified approach to tackling concave and DR-submodular optimization problems. The paper extends these results to multiple feedback settings, facilitating conversions between semi-bandit/first-order feedback and bandit/zeroth-order feedback, as well as between first/zeroth-order feedback and semi-bandit/bandit feedback. Leveraging this framework, new algorithms are derived using existing results as base algorithms for convex optimization, improving upon state-of-the-art results in various cases. Dynamic and adaptive regret guarantees are obtained for DR-submodular maximization, marking the first algorithms to achieve such guarantees in these settings. Notably, the paper achieves these advancements with fewer assumptions compared to existing state-of-the-art results, underscoring its broad applicability and theoretical contributions to non-convex optimization.

## 1 Introduction

**Overview:** The prominence of optimizing continuous adversarial \(\)-weakly up-concave functions (with DR-submodular and concave functions as special cases) has surged in recent years, marking a crucial subset within the realm of non-convex optimization challenges, particularly in the forefront of machine learning and statistics. This problem has numerous real-world applications, such as revenue maximization, mean-field inference, recommendation systems [4; 20; 30; 12; 24; 18; 26]. This problem is modeled as a repeated game between an optimizer and an adversary. In each round, the optimizer selects an action, and the adversary chooses a \(\)-weakly up-concave reward function. Depending on the scenario, the optimizer can then query this reward function either at any arbitrary point within the domain (called full information feedback) or specifically at the chosen action (called semi-bandit/bandit feedback), where the feedback can be noisy/deterministic. The performance metric of the algorithm is measured with multiple regret notions - static adversarial regret, dynamic regret, and adaptive regret. The algorithms for the problem are separated into the ones that use a projection operator to project the point to the closest point in the domain, and the projection-free methods that replace the projection with an alternative such as Linear Optimization Oracles (LOO) or Separation Oracles (SO). This interactive framework introduces a range of significant challenges, influenced by the characteristics of the up-concave function (monotone/non-monotone), the constraints imposed, the nature of the queries, projection-free/projection-based algorithms, and the different regret definitions.

[MISSING_PAGE_FAIL:2]

therefore also static regret) guarantees for the three setups of DR-submodular (or more generally, up-concave) optimization with semi-bandit feedback/first order feedback in the respective cases. Then, the meta-algorithms for conversion of first-order/semi-bandit to zeroth-order/bandit are used to get result with zeroth-order/bandit feedback. In the cases where the algorithms are full-information and not (semi-)bandit, we use another meta-algorithm to obtain algorithms in (semi-)bandit feedback setting. In the next application, we use the "Improved Ader" algorithm of  which is a projection based algorithm providing dynamic regret guarantees for the convex optimization. Afterwards, the same approach as above are used to obtain the results in the three scenarios of up-concave optimization with first-order feedback.

**Technical Novelty:** The main technical novelties in this work are as follows.

1. We proposes a novel notion of linearizable/quadratzable functions and extend the meta-algorithm framework of  from convex functions to linearizable/quadratzable functions. This allows us to relates a large class of algorithms and regret guarantees for optimization of linear/quadratic functions to that for linearizable/quadratzable functions.
2. We show that the class of quadratizable function optimization is general, and includes not only concave, but up-concave optimization in several cases. For some of the cases, this proof uses a generalization of the idea of boosting () which was proposed for DR-submodular maximization, as mentioned in Corollaries 2 and 3.
3. We design a new meta-algorithm, namely SFTT, that captures the idea of random permutations (sometimes referred to as blocking) as used in several papers such as . While previous works used this idea in specific settings, our meta-algorithm is applicable in general settings.
4. We note the generality of the above results in this paper. Our results are general in the following three aspects: 1. In this work, we improve results for projection-free static regret guarantees for DR-submodular optimization in all considered cases and obtain the first results for dynamic and adaptive regret. Moreover, these guarantees follow from existing algorithms for the linear optimization, using only the statement of the regret bounds and simple properties of the algorithms. 2. We consider 3 classes of DR-submodular functions in this work. However, to extend these results to another function class, all one needs to do is to (i) prove that the function class is quadratizable; and (ii) provide an unbiased estimator of \(\) (as described in Equation 1). 3. We consider 2 different feedback types in offline setting (first/zero order) and 4 types of feedback in the online setting (first/zero order and full-information/trivial query). Converting results between different cases is obtained through meta-algorithms and guarantees for the meta-algorithms which only relies on high level properties of the base algorithms (See Theorems 5, 7, 6 and 8)

**Key contributions:** The key contributions in this work are summarized as follows.

1. We formulate the notion of _upper-quadratzable/upper-linearizeble_ functions, which is a class that generalizes the notion of strong-concavity/concavity and also DR-submodularity in several settings. In particular, we demonstrate the the following function classes are upper-quadratzable: (i) monotone \(\)-weakly \(\)-strongly DR-submodular functions with curvature \(c\) over general convex sets, (ii) monotone \(\)-weakly DR-submodular functions over convex sets containing the origin, and (iii) non-monotone DR-submodular optimization over general convex sets.
2. We provide a general meta-algorithm that converts algorithms for linear/quadratic maximization to algorithms that maximize upper-quadratzable functions. This results is a unified approach to maximize both concave functions and DR-submodular functions in several settings.
3. While the above provides results for semi-bandit feedback (for monotone DR-submodular optimization over general convex sets) and first-order feedback (for monotone DR-submodular optimization over convex sets containing the origin, and non-monotone DR-submodular optimization over general convex sets), the results could be extended to more general feedback settings. Four meta algorithms are provided that relate semi-bandit/first-order feedback to bandit/zeroth order feedback; that relate; first order to deterministic zeroth order; and that relate first/zeroth order feedback to semi-bandit/bandit feedback. Together they allow us to obtain results in 5 feedback settings (first/zeroth order full-information and semi-bandit/bandit; and deterministic zeroth order). We also discuss a meta-algorithm to convert online results to offline guarantees.
4. The above framework is applied using different algorithms as the base algorithms for linear optimization. SO-OGD is a projection-free algorithm using separation oracles that provides adaptive regret guarantees for online convex optimization. We use our framework to cover the 18 cases in Table 1. We improve the regret guarantees for the previous SOTA projection-free algorithms in all the cases. If we also allow comparisons with the algorithms that are not projection-free, we still improve the SOTA results in 12 cases and match the SOTA in 5 cases.
5. Using our framework, we convert online results using SO-OGD to offline results to obtain 6 projection free algorithms described in Table 2. We improve the regret guarantees for the previous SOTA projection-free algorithms in all the cases, except for deterministic first order feedback where existing results are already SOTA. If we also allow comparisons with the algorithms that are not projection-free, we still improve the SOTA results in 6 cases and match the SOTA in the remaining 3 cases.
6. We use our framework to convert the adaptive regret guarantees of SO-OGD to obtain projection-free algorithms with adaptive regret bounds that cover all cases in Table 3. Our results are first algorithms with adaptive regret guarantee for online DR-submodular maximization.
7. "Improved Ader"  is an algorithm providing dynamic regret guarantees for online convex optimization. We use our framework to obtain 6 algorithms which provide the dynamic regret guarantees as shown in Table 3. Our results are first algorithms with dynamic regret guarantee for online DR-submodular maximization.
8. For monotone \(\)-weakly functions with bounded curvature over general convex sets, we improve the approximation ratio (See Lemma 1).
9. As mentioned in the descriptions of the tables, in all cases considered, whenever there is another existing result, we obtain our results using fewer assumptions than the existing SOTA.

## 2 Problem Setup and Definitions

For a set \(^{d}\), we define its _affine hull_\(()\) to be the set of \(+(1-)\) for all \(,\) in \(\) and \(\). The _relative interior_ of \(\) is defined as \(():=\{ r>0, _{r}^{d}()() \}\). For any \(^{T}\), we define the path length \(P_{T}():=_{i=1}^{T-1}\|_{i}-_{i+1}\|\). Given \( 0\) and \(0< 1\), we say a differentiable function \(f:\) is \(\)_-strongly \(\)-weakly up-concave_ if it is \(\)-strongly \(\)-weakly concave along positive directions. Specifically if, for all \(\) in \(\), we have

\[( f(),-+\|-\|^{2}) f()-f() ( f(),- -\|-\|^{2}).\]

We say \(f:^{d}\) is a \(\)_-strongly \(\)-weakly up-super-gradient_ of \(f\) if for all \(\) in \(\), the above holds with \(\) instead of \(\). We say \(f\) is \(\)-strongly \(\)-weakly up-concave if it is continuous and it has a \(\)-strongly \(\)-weakly up-super-gradient. When it is clear from the context, we simply refer to \(f\) as an up-super-gradient for \(f\). When \(=1\) and the above inequality holds for all \(,\), we say \(f\) is \(\)-strongly concave. A differentiable function \(f:\) is called \(\)_-weakly continuous DR-submodular_ if for all \(\), we have \( f() f()\). It follows that any \(\)-weakly continuous DR-submodular functions is \(\)-weakly up-concave. We refer to Appendix B for more details.

Given a continuous monotone function \(f:\), its curvature is defined as the smallest number \(c\) such that \(f(+)-f()(1-c)(f(+)-f( ))\), for all \(,\) and \( 0\) such that \(+,+\). We define the curvature of a function class \(\) as the supremum of the curvature of functions in \(\).

Online optimization problems can be formalized as a repeated game between an agent and an adversary. The game lasts for \(T\) rounds on a convex domain \(\) where \(T\) and \(\) are known to both players. In \(t\)-th round, the agent chooses an action \(_{t}\) from an action set \(^{d}\), then the adversary chooses a loss function \(f_{t}\) and a query oracle for the function \(f_{t}\). Then, for \(1 i k_{t}\)the agent chooses a points \(_{t,i}\) and receives the output of the query oracle. The precise definition of agent \((^{},^{},^{})\) is given in Appendix B, with the query oracle being any of stochastic/deterministic first/zeroth order or semi-bandit/bandit.

An adversary \(\) is a set of realized adversaries \(=(_{1},,_{T})\), where each \(_{t}\) maps \((_{1},,_{t})^{T}\) to \((f_{t},_{t})\) where \(f_{t}\) and \(_{t}\) is a query oracle for \(f_{t}\). Adversaries can be oblivious (\(_{t}\) are constant and independent of \((_{1},,_{t})\)), weakly adaptive (\(_{t}\) are independent of \(_{t}\)), or fully adaptive (no restrictions). We use \(^{}_{i}()\) to denote the set of all possible realized adversaries with deterministic \(i\)-th order oracles. If the oracle is instead stochastic and bounded by \(B\), we use \(^{}_{i}(,B)\) to denote such an adversary. Finally, we use \(^{}_{i}()\) and \(^{}_{i}(,B)\) to denote all oblivious realized adversaries with \(i\)-th order deterministic and stochastic oracles, respectively. In order to handle different notions of regret with the same approach, for an agent \(\), adversary \(\), compact set \(^{T}\), approximation coefficient \(0< 1\) and \(1 a b T\), we define _regret_ as \(^{}_{,}()[a,b]:=_{ }[_{=( _{1},,_{T})}_{t=a}^{b}f_{t}(_{t})- _{t=a}^{b}f_{t}(_{t})],\) where the expectation in the definition of the regret is over the randomness of the algorithm and the query oracle. We use the notation \(^{}_{,}()[a,b]:=^{ }_{,}()[a,b]\) when \(=\{\}\) is a singleton. We may drop \(\) when it is equal to \(1\). When \(<1\), we often assume that the functions are non-negative. _Static adversarial regret_ or simply _adversarial regret_ corresponds to \(a=1\), \(b=T\) and \(=^{T}_{}:=\{(,,) \}\). When \(a=1\), \(b=T\) and \(\) contains only a single element then it is referred to as the _dynamic regret_. _Adaptive regret_ is defined as \(_{1 a b T}^{}_{,}( ^{T}_{})[a,b]\). We drop \(a\), \(b\) and \(\) when the statement is independent of their value or their value is clear from the context.

## 3 Formulation of Upper-Quadratzable Functions and Regret Relation to that of Quadratic Functions

Let \(^{d}\) be a convex set, \(\) be a function class over \(\). We say the function class \(\) is _upper-quadratzable_ if there are maps \(:^{d}\) and \(h:\) and constants \( 0\), \(0< 1\)

  \(F\) & Set & Feedback & Reference & Appx. & Complexity \\    } &  &  &  & \(1-e^{-}\) & \(O(1/e^{2})\) \\  & & &  & \(1-e^{-}\) & \(O(1/e^{2})\) \\  & & &  & \(1-e^{-}\) & \(O(1/e^{2})\) \\  & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\  & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\   & &  &  &  & \(1-e^{-}\) & \(O(1/e^{2})\) \\  & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\   & & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\   & & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\    } &  &  &  & \(^{2}/(1+^{2})\) & \(O(1/e^{2})\) \\  & & &  & \(^{2}/(1+^{2})\) & \(O(1/e^{2})\) \\  & & & Corollary \(\)-\(\) & \(^{2}/(1+^{2})\) & \(O(1/e^{2})\) \\   & & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\   & & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\   & & & & Corollary \(\)-\(\) & \(1-e^{-}\) & \(O(1/e^{2})\) \\    } &  &  &  & \(-^{2})}\) & \(O(1/e^{3})\) \\  & & & & Corollary \(\)-\(\) & \(1-(1-)/4\) & \(O(1/e^{2})\) \\   & & & &  & \((-^{2})\) & \(O(1/e^{3})\) \\   & & & & Corollary \(\)-\(\) & \(1-h/4\) & \(O(1/e^{2})\) \\   & & & &  & \((-^{2})\) & \(O(1/e^{3})\) \\   & & & & Corollary \(\)-\(\) & \(1-h/4\) & \(O(1/e^{2})\) \\   & & & &  & \((-^{2})\) & \(O(1/e^{3})\) \\   & & & & Corollary \(\)-\(\) & \(1-h/4\) & \(O(1/e^{2})\) \\  

Table 2: Offline up-concave maximization and \(>0\) such that 2

\[ f()-f(h())((f, ),--\|- \|^{2}),\] (1)

As a special case, when \(=0\), we say \(\) is _upper-linearizable_. We use the notation \(_{,}\) to denote the class of functions \(q():=(f,),- -\|-\|^{2}:,\) for all \(f\) and \(\). Similarly, for any \(B_{1}>0\), we use the notation \(_{}[B_{1}]\) to denote the class of functions \(q():=,-- \|-\|^{2}:,\) for all \(\) and \(_{B_{1}}^{d}()\). A similar notion of _lower-quadratizablelinearizable_ may be similarly defined for minimization problems such as convex minimization.

We say an algorithm \(\) is a first order query algorithm for \(\) if, given a point \(\) and a first order query oracle for \(f\), it returns (a possibly unbiased estimate of \((f,)\). We say \(\) is bounded by \(B_{1}\) if the output of \(\) is always within the ball \(_{B_{1}}^{d}()\) and we call it trivial if it simply returns the output of the query oracle at \(\).

Recall that an online agent \(\) is composed of action function \(^{}\) and query function \(^{}\). Informally, given an online algorithm \(\) with semi-bandit feedback, we may think of \(^{}:=(,,h)\) as the online algorithm with \((^{})^{} h(^{})\) and \((^{})^{}\). As a special case, when \(h=\) and \(\) is trivial, we have \(^{}=\).

``` Input : horizon \(T\), semi-bandit algorithm \(\), query algorithm \(\) for \(\), the map \(h:\) for \(t=1,2,,T\)do Play \(h(_{t})\) where \(_{t}\) is the action chosen by \(\) The adversary selects \(f_{t}\) and a first order query oracle for \(f_{t}\) Run \(\) with access to \(_{t}\) and the query oracle for \(f_{t}\) to calculate \(_{t}\) Return \(_{t}\) as the output of the query oracle to \(\) ```

**Algorithm 1**Online Maximization

By Quadratization - \((,,h)\)

  \(F\) & Set &  & Reference & Appx. & regret type & \(\)-regret \\   &  &  &  & Corollary 8-c & \(1-e^{-}\) & dynamic & \(T^{1/2}(1+P_{T})^{1/2}\) \\  & & & & Corollary 7-c & \(1-e^{-}\) & adaptive & \(T^{1/2}\) \\   & & & Semi-bandit & stoch. & Corollary 7-c & \(1-e^{-}\) & adaptive & \(T^{2/3}\) \\   & & & & Corollary 7-c & \(1-e^{-}\) & adaptive & \(T^{2/3}\) \\   & & & & & Corollary 8-c & \(1-e^{-}\) & adaptive & \(T^{1/2}\) \\   & & & & & Corollary 7-c & \(1-e^{-}\) & adaptive & \(T^{1/2}\) \\   & & & & & Corollary 8-c & \(1-e^{-}\) & adaptive & \(T^{3/4}\) \\   & & & & Bandit & stoch. & Corollary 7-c & \(1-e^{-}\) & adaptive & \(T^{4/5}\) \\   & & & & & & Corollary 7-c & \(1-e^{-}\) & adaptive & \(T^{4/5}\) \\   &  &  &  & Corollary 8-b & \(^{2}/(1+c^{2})\) & dynamic & \(T^{1/2}(1+P_{T})^{1/2}\) \\  & & & & Corollary 7-b & \(^{2}/(1+c^{2})\) & adaptive & \(T^{1/2}\) \\   & & & & & Corollary 8-c & \(^{2}/(1+c^{2})\) & dynamic & \(T^{1/2}(1+P_{T})^{1/2}\) \\   & & & & & Corollary 7-c & \(^{2}/(1+c^{2})\) & adaptive & \(T^{1/2}\) \\   & & & & Bandit & stoch. & Corollary 8-b & \(^{2}/(1+c^{2})\) & dynamic & \(T^{3/4}(1+P_{T})^{1/2}\) \\   & & & & & Corollary 7-b & \(^{2}/(1+c^{2})\) & adaptive & \(T^{3/4}\) \\   &  &  &  & Corollary 8-d & \((1-h)/4\) & dynamic & \(T^{1/2}(1+P_{T})^{1/2}\) \\  & & & & Corollary 7-d & \((1-h)/4\) & adaptive & \(T^{1/2}\) \\   & & & Semi-bandit & stoch. & Corollary 7-d & \((1-h)/4\) & adaptive & \(T^{2/3}\) \\   & & & & & Corollary 8-d & \((1-h)/4\) & dynamic & \(T^{1/2}(1+P_{T})^{1/2}\) \\   & & & & & Corollary 7-d & \((1-h)/4\) & adaptive & \(T^{1/2}\) \\   & & & & & & Corollary 7-d & \((1-h)/4\) & adaptive & \(T^{1/2}\) \\   & & & & & & Corollary 7-d & \((1-h)/4\) & adaptive & \(T^{1/2}\) \\   This table includes different results for non-stationary up-concave maximization, while no prior results exist in this setup to the best of our knowledge. The results for adaptive regret are projection-free and use a separation oracle while results for dynamic regret use convex projection. Note that full-information algorithms with deterministic feedback require 2 queries per function while the ones with stochastic feedback only require one, at the cost of higher regret.

Table 3: Non-stationary up-concave maximization 

**Theorem 1**.: _Let \(\) be algorithm for online optimization with semi-bandit feedback. Also let \(\) be a function class over \(\) that is quadraraizable with \( 0\) and maps \(:^{d}\) and \(h:\), let \(\) be a query algorithm for \(\) and let \(^{}=(,,h)\). Then the following are true._

_1.If \(\) returns the exact value of \(\), then we have \(^{^{}}_{,^{}_{1}( )}^{}_{1,^{}_{1}( _{,})}\)._

_2.On the other hand, if \(\) returns an unbiased estimate of \(\) and the output of \(\) is bounded by \(B_{1}\), then we have \(^{^{}}_{,^{}_{1}( ,B_{1})}^{}_{1,^{} _{1}(_{}[B_{1}])}\)._

As a special case, when \(f\) is concave, we may choose \(==1\), \(h=\), and \((f,)\) to be a super-gradient of \(f\) at \(\). In this case, Theorem 1 reduces to the concave version of Theorems 2 and 5 in .

## 4 Up-concave function optimization is upper-quadratizable function

In this section, we study three classes of up-concave functions and show that they are upper-quadratizable. We further use this property to obtain meta-algorithms that convert algorithms for quadratic optimization into algorithms for up-concave maximization.

### Monotone up-concave optimization over general convex sets

For differentiable DR-submodular functions, the following lemma is proven for the case \(=1\) in Lemma 2 in  and for the case \(=0\) in  (See Inequality 7.5 in the arXiv version). We show the result for general \(\)-strongly \(\)-weakly up-concave function with curvature bounded by \(c\), See Appendix D for proof.

**Lemma 1**.: _Let \(f:^{d}\) be a non-negative monotone \(\)-strongly \(\)-weakly up-concave function with curvature bounded by \(c\). Then, for all \(,^{d}\), we have_

\[}{1+c^{2}}f()-f()}(f(),- -\|-\|^{2}),\]

_where \(f\) is an up-super-gradient for \(f\)._

Further, we show that any semi-bandit feedback online linear optimization algorithm for fully adaptive adversary is also an online up-concave optimization algorithm.

**Theorem 2**.: _Let \(^{d}\) be a convex set, let \( 0\), \((0,1]\), \(c\) and let \(\) be algorithm for online optimization with semi-bandit feedback. Also let \(\) be an \(M_{1}\)-Lipschitz function class over \(\) where every \(f\) may be extended to a monotone \(\)-strongly \(\)-weakly up-concave function curvature bounded by \(c\) defined over \(^{d}\). Then, for any \(B_{1} M_{1}\), we have_

\[^{_{}{1+c^{2}},^{ }_{1}()}}_{}}}^{}_{1,^{}_{1}(_{}[ M_{1}])},^{_{}{1+c^{2}}, ^{}_{1}(,B_{1})}}_{}} }^{}_{1,^{ }_{1}(_{}[B_{1}])}\]

These results follows immediately from Theorem 1 and Lemma 1. Note that it is important to assume that every function in \(\) may be extended to a non-negative up-concave function over \(^{d}\) for Lemma 1 to be applied.

**Corollary 1**.: _The results of ,  and  on monotone continuous DR-submodular maximization over general convex sets may be thought of as special cases of Theorem 2 when \(\) is the online gradient ascent algorithm._

### Monotone up-concave optimization over convex sets containing the origin

The following lemma is proven for differentiable DR-submodular functions in Theorem 2 and Proposition 1 of . The proof works for general up-concave functions as well. We include a proof in Appendix E for completeness.

**Lemma 2**.: _Let \(f:^{d}\) be a non-negative monotone \(\)-weakly up-concave differentiable function and let \(F:^{d}\) be the function defined by_

\[F():=_{0}^{1}}{(1-e^{-})z}(f(z *)-f())dz.\]

_Then \(F\) is differentiable and, if the random variable \(\) is defined by the law_

\[ z,( z)=_{0}^{z}}{1-e^{-}}du,\] (2)

_then we have \([ f(*)]= F()\). Moreover, we have \((1-e^{-})f()-f()}{}  F(),-\)._

**Theorem 3**.: _Let \(^{d}\) be a convex set containing the origin, let \((0,1]\) and let \(\) be algorithm for online optimization with semi-bandit feedback. Also let \(\) be a function class over \(\) where every \(f\) is the restriction of a monotone \(\)-weakly up-concave function defined over \(^{d}\) to the set \(\). Assume \(\) is differentiable and \(M_{1}\)-Lipschitz for some \(M_{1}>0\). Then, for any \(B_{1} M_{1}\), we have_

\[^{A^{}}_{1-e^{-},_{1}^{}(,B _{1})}}{}^{}_{1,_{1}^{}(_{0}[B_{1}])}\]

_where \(^{}=(,,)\)._

This result now follows immediately from Theorem 1 and Lemma 2.

**Corollary 2**.: _The result of  in the online setting (when there is no delay) may be seen as an application of Theorem 3 when \(\) is chosen to be online gradient ascent._

### Non-monotone up-concave optimization over general convex sets

The following lemma is proven for differentiable DR-submodular functions in Corollary 2, Theorem 4 and Proposition 2 of . The arguments works for general up-concave functions as well. We include a proof in Appendix F for completeness.

**Lemma 3**.: _Let \(f:^{d}\) be a non-negative continuous up-concave differentiable function and let \(}\). Define \(F:^{d}\) as the function \(F():=_{0}^{1})^{3}}(f(*(-})+})-f( }))dz\). Then \(F\) is differentiable and, if the random variable \(\) is defined by the law_

\[ z,( z)=_{0}^{z})^{3}}du,\] (3)

_then we have \([ f(}{2}*(-})+})]= F()\). Moreover, we have_

\[}\|_{}}{4}f()-f(+}}{2}) F( ),-.\]

**Theorem 4**.: _Let \(^{d}\) be a convex set, \(}\), \(h:=\|}\|_{}\) and \(\) be algorithm for online optimization with semi-bandit feedback. Also let \(\) be a function class over \(\) where every \(f\) is the restriction of an up-concave function defined over \(^{d}\) to the set \(\). Assume \(\) is differentiable and \(M_{1}\)-Lipschitz for some \(M_{1}>0\). Then, for any \(B_{1} M_{1}\) and \(^{}=(,, _{i}+}}{2})\), we have \(^{^{}}_{_{}},_{_{1}^ {}(,B_{1})}^{}_{1,_{1}^{}(_{0}[B_{1}])}\)._

These results now follows immediately from Theorem 1 and Lemma 3.

**Corollary 3**.: _The result of  in the online setting without delay may be seen as an application of Theorem 4 when \(\) is chosen to be online gradient ascent._Meta algorithms for other feedback cases

In this section, we study several meta-algorithms that allow us to convert between different feedback types and also convert results from the online setting to the offline setting.

First order/semi-bandit to zeroth order/bandit feedback:In this section we discuss meta-algorithms that convert algorithms designed for first order feedback into algorithms that can handle zeroth order feedback. These algorithms and results are generalization of similar results in  to the case where \(<1\).

We choose a point \(()\) and a real number \(r>0\) such that \(()_{r}^{d}()\). Then, for any shrinking parameter \(0<r\), we define \(}_{}:=(1-)+ \). For a function \(f:\) defined on a convex set \(^{d}\), its \(\)-smoothed version \(_{}:}_{}\) is given as

\[_{}():=_{()_{}^{d}()}[f()]=_{ _{0}_{1}^{d}()}[f(+ )],\]

where \(_{0}=()-\), for any \(\), is the linear space that is a translation of the affine hull of \(\) and \(\) is sampled uniformly at random from the \(k=(_{0})\)-dimensional ball \(_{0}_{1}^{d}()\). Thus, the function value \(_{}()\) is obtained by "averaging" \(f\) over a sliced ball of radius \(\) around \(\). For a function class \(\) over \(\), we use \(}_{}\) to denote \(\{_{} f\}\). We will drop the subscript \(\) when there is no ambiguity (See Appendix G for the description of the algorithms and the proof.).

**Theorem 5**.: _Let \(\) be an \(M_{1}\)-Lipschitz function class over a convex set \(\) and choose \(\) and \(r\) as described above and let \(<r\). Let \(^{T}\) be a compact set and let \(}=(1-)+\). Assume \(\) is an algorithm for online optimization with first order feedback. Then, if \(^{}=()\) where \(\) is described by Algorithm 5 and \(0< 1\), we have_

\[^{^{}}_{,_{0}^{}(,B_{0})}()^{}_{,_{1}^{ }(,B_{0})}(})+(3+ {r}) M_{1}T.\]

_On the other hand, if we assume that \(\) is semi-bandit, then the same regret bounds hold with \(^{}=()\), where \(\) is described by Algorithm 6._

**Theorem 6**.: _Under the assumptions of Theorem 5, if \(^{}=\)-\(()\) where \(\)-\(\) is described by Algorithm 7 and \(0< 1\), we have_

\[^{^{}}_{,_{0}^{}()}()^{}_{,_{1}^{ }(,kM_{1})}(})+(3+)  M_{1}T.\]

Full information to trivial query:In this section, we discuss a meta-algorithm that converts algorithms that require full-information feedback into algorithms that have a trivial query oracle. In particular, it converts algorithms that require first-order full-information feedback into semi-bandit algorithms and algorithms that require zeroth-order full-information feedback into bandit algorithms.

Here we assume that \(^{}\) does not depend on the observations in the current round. If the number of queries \(k_{t}\) is not constant for each time-step, we simply assume that \(\) queries extra points and then discards them, so that we obtain an algorithm that queries exactly \(K\) points at each time-step, where \(K\) does not depend on \(t\). We say a function class \(\) is closed under convex combination if for any \(f_{1},,f_{k}\) and any \(_{1},,_{k} 0\) with \(_{i}_{i}=1\), we have \(_{i}_{i}f_{i}\).

**Theorem 7**.: _Let \(\) be an online optimization algorithm with full-information feedback and with \(K\) queries at each time-step where \(^{}\) does not depend on the observations in the current round and \(^{}=()\). Then, for any \(M_{1}\)-Lipschitz function class \(\) that is closed under convex combination and any \(B_{1} M_{1}\), \(0< 1\) and \(1 a b T\), let \(a^{}=(a-1)/L+1\), \(b^{}= b/L\), \(D=()\) and let \(\{T\}\) and \(\{T/L\}\) denote the horizon of the adversary. Then, we have_

\[^{^{}}_{,_{1}^{}(,B_{1})\{T\}}(^{T}_{})[a,b] M_{1}DK(b^{}-a^{}+1)+L ^{}_{,_{1}^{}(,B_{1}) \{T/L\}}(^{T/L}_{})[a^{},b^{}],\]

This result (proof in Appendix H) is based on the idea of random permutations used in .

Online to Offline:An offline optimization problem can be though of as an instance of online optimization where the adversary picks the same function and query oracle at each round. Moreover, instead of regret, the performance of the algorithm is measured by sample complexity, i.e., the minimum number of queries required so that the expected error from the \(\)-approximation of the optimal value is less than \(\).

Conversions of online algorithms to offline are referred to online-to-batch techniques and are well-known in the literature (See ). A simple approach is to simply run the online algorithm and if the actions chosen by the algorithm are \(_{1},,_{T}\), return \(_{t}\) for \(1 t T\) with probability \(1/T\). We use \(\) to denote the meta-algorithm that uses this approach to convert online algorithms to offline algorithms. The following theorem is a corollary which we include for completion. (See Appendix I for the proof.)

**Theorem 8**.: _Let \(\) be an online algorithm that queries no more than \(K=T^{}\) times per time-step that obtains an \(\)-regret bound of \(O(T^{})\) over an oblivious adversary \(\). Then the sample complexity of \(()\) over \(\{(f,_{f})((f,_{f}),,(f,_{f})) \}\) is \(O(^{-})\)._

## 6 Applications

Figure 6 captures the applications that are mentioned in Tables 1, 2 and 3. The exact statements are stated in Corollaries 7 and 8 in the Appendix. To obtain a result from the graph, let \(\) be one of \(\) or \(\) and select a directed path that has the following properties: (i) The path starts at one of the three nodes on the left. (ii) The path must be at least of length 1 and the edges must be the same color. (iii) If \(\) is \(\), the path should not contain \(\) or \(\).

For example, if \(=\) and the path starts at the middle node on the left, then passes through \(\), \(\), \(\), we get \((((,, )))\), which is a projection-free algorithm (using separation oracles) with bandit feedback for monotone up-concave functions over convex sets that contain the origin. As mentioned in Table 3 and Corollary 7-(c), the adaptive regret of this algorithm is of order \(O(T^{4/5})\). Note that the text written in the three nodes on the left correspond to the inputs of the meta-algorithm \(\). Also note that the color red corresponds to the setting where \(\) is a trivial query algorithm which means that the output of \(\) is semi-bandit.

## 7 Conclusions

In this work, we have presented a comprehensive framework for addressing optimization problems involving upper-quadrizable functions, encompassing both concave and DR-submodular functions across various settings and feedback types. Our contributions include the formulation of upper-quadrizable functions as a generalized class, the development of meta-algorithms for algorithmic conversions, and the derivation of new algorithms with improved static/ dynamic/ adaptive regret guarantees. Exploring more subset of classes of upper-quadrizable functions where such a framework could be applied is an important future direction.

## 8 Acknowledgement

This research was supported in part by the National Science Foundation under grant CCF-2149588.

Figure 1: Summary of applications