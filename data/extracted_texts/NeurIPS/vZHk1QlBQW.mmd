# ForkMerge: Mitigating Negative Transfer in Auxiliary-Task Learning

Junguang Jiang, Baixu Chen, Junwei Pan, Ximei Wang, Dapeng Liu, Jie Jiang,

Mingsheng Long

Equal contribution.School of Software, BNRist, Tsinghua University, China

\({}^{\$}\)Tencent Inc, China

{jjg20,cbx22}@mails.tsinghua.edu.cn, {jonaspan,messixmwang,rocliu,zeus}@tencent.com,

mingsheng@tsinghua.edu.cn

###### Abstract

Auxiliary-Task Learning (ATL) aims to improve the performance of the target task by leveraging the knowledge obtained from related tasks. Occasionally, learning multiple tasks simultaneously results in lower accuracy than learning only the target task, which is known as negative transfer. This problem is often attributed to the gradient conflicts among tasks, and is frequently tackled by coordinating the task gradients in previous works. However, these optimization-based methods largely overlook the auxiliary-target generalization capability. To better understand the root cause of negative transfer, we experimentally investigate it from both optimization and generalization perspectives. Based on our findings, we introduce _ForkMerge_, a novel approach that periodically forks the model into multiple branches, automatically searches the varying task weights by minimizing target validation errors, and dynamically merges all branches to filter out detrimental task-parameter updates. On a series of auxiliary-task learning benchmarks, _ForkMerge_ outperforms existing methods and effectively mitigates negative transfer.

## 1 Introduction

Deep neural networks have achieved remarkable success in various machine learning applications, such as computer vision [23; 22], natural language processing [62; 11; 57], and recommendation systems . However, one major challenge in training deep neural networks is the scarcity of labeled data. In recent years, Auxiliary-Task Learning (ATL) has emerged as a promising technique to address this challenge [67; 39; 43]. ATL improves the generalization of target tasks by leveraging the useful signals provided by some related auxiliary tasks. For instance, larger-scale tasks, such as user click prediction, can be utilized as auxiliary tasks to improve the performance of smaller-scale target tasks, such as user conversion prediction in recommendation [47; 36]. Self-supervised tasks on unlabeled data can serve as auxiliary tasks to improve the performance of the target task in computer vision and natural language processing, without requiring additional labeled data [34; 69; 11; 3].

However, in practice, learning multiple tasks simultaneously sometimes leads to performance degradation compared to learning only the target task, a phenomenon known as _negative transfer_[84; 75]. Even in large language models, negative transfer problems may still exist. For example, RLHF , a key component of ChatGPT , achieves negative effects on nearly half of the multiple-choice question tasks when post-training GPT-4 . There has been a significant amount of methods proposed to mitigate negative transfer in ATL [71; 79; 15; 39]. Notable previous studies attribute negative transfer to the optimization difficulty, especially the gradient conflicts between different tasks, and propose to mitigate negative transfer by reducing interference between task gradients[79; 15]. Other works focus on selecting the most relevant auxiliary tasks and reducing negative transfer by avoiding task groups with severe task conflicts [71; 17]. However, despite the significant efforts to address negative transfer, its underlying causes are still not fully understood.

In this regard, we experimentally analyze potential causes of negative transfer in ATL from the perspectives of optimization and generalization. From an optimization view, our experiments suggest that _gradient conflicts do not necessarily lead to negative transfer_. For example, weight decay, a special auxiliary task, can conflict with the target task in gradients but still be beneficial to the target performance. From a generalization view, we observe that negative transfer is more likely to occur when _the distribution shift between the multi-task training data and target test data is enlarged._

Based on our above findings, we present a new approach named _ForkMerge_. Since we cannot know which task distribution combination leads to better generalization in advance, and training models for each possible distribution is prohibitively expensive, we transform the problem of combining task distributions into that of combining model hypotheses. Specifically, we fork the model into multiple branches and optimize the parameters of different branches on diverse data distributions by varying the task weights. Then at regular intervals, we merge and synchronize the parameters of each branch to approach the optimal model hypothesis. In this way, we will filter out harmful parameter updates to mitigate negative transfer and keep desirable parameter updates to promote positive transfer.

The contributions of this work are summarized as follows: (1) We systematically identify the problem and analyze the causes of negative transfer in ATL. (2) We propose _ForkMerge_, a novel approach to mitigate negative transfer and boost the performance of ATL. (3) We conduct extensive experiments and validate that _ForkMerge_ outperforms previous methods on a series of ATL benchmarks.

## 2 Related Work

### Auxiliary-Task Learning

Auxiliary-Task Learning (ATL) enhances a model's performance on a target task by utilizing knowledge from related auxiliary tasks. The two main challenges in ATL are selecting appropriate auxiliary tasks and optimizing them jointly with the target task. To find the proper auxiliary tasks for ATL, recent studies have explored task relationships by grouping positively related tasks together and assigning unrelated tasks to different groups to avoid task interference [81; 71; 17; 70]. Once auxiliary tasks are determined, most ATL methods create a unified loss by linearly combining the target and auxiliary losses. However, choosing task weights is challenging due to the exponential increase in search space with the number of tasks, and fixing the weight of each task loss can lead to negative transfer . Recent studies propose various methods to automatically choose task weights, such as using one-step or multi-step gradient similarity [15; 39; 9], minimizing representation-based task distance  or gradient gap , employing a parametric cascade auxiliary network , or from the perspective of bargaining game . However, these methods mainly address the optimization difficulty after introducing auxiliary tasks and may overlook the generalization problem.

Recently, AANG  formulates a novel searching space of auxiliary tasks and adopts the meta-learning technique, which prioritizes target task generalization, to learn single-step task weightings. This parallel finding highlights the importance of the target task generalization and we further introduce the multi-step task weightings to reduce the estimation uncertainty. Another parallel method, ColD Fusion , explores collaborative multitask learning and proposes to fuse each contributor's parameter to construct a shared model. In this paper, we further take into account the diversity of tasks and the intricacies of task relationships and derive a method for combining model parameters from the weights of task combinations.

### Multi-Task Learning

Different from ATL, Multi-Task Learning (MTL) aims to improve the performance of all tasks by learning multiple objectives from a shared representation. To facilitate information sharing and minimize task conflict, many multi-task architectures have been designed, including hard-parameter sharing [30; 22; 24] and soft-parameter sharing [51; 64; 16; 46; 44; 48; 72]. Another line of work aims to optimize strategies to reduce task conflict. Methods such as loss balancing and gradient balancing propose to find suitable task weighting through various criteria, such as task uncertainty , task loss magnitudes , gradient norm , and gradient directions [79; 6; 40; 41; 25; 55].

Although MTL methods can be directly used to jointly train auxiliary and target tasks, the asymmetric task relationships in ATL are usually not taken into account in MTL.

### Negative Transfer

Negative Transfer (NT) is a widely existing phenomenon in machine learning, where transferring knowledge from the source data or model can have negative impact on the target learner [63; 60; 27]. To mitigate negative transfer, domain adaptation methods design importance sampling or instance weighting strategies to prioritize related source data [75; 83]. Fine-tuning methods filter out detrimental pre-trained knowledge by suppressing untransferable spectral components in the representation . MTL methods use gradient surgery or task weighting to reduce the gradient conflicts across tasks [79; 76; 25; 42]. Different from previous work, we propose to dynamically filter out harmful parameter updates in the training process to mitigate negative transfer. Besides, we provide an in-depth experimental analysis of the causes of negative transfer in ATL, which is rare in this field yet will be helpful for future research.

## 3 Negative Transfer Analysis

Problem and Notation.In this section, we assume that both the target task \(_{}\) and the auxiliary task \(_{}\) are given. Then the objective is to find model parameters \(\) that achieve higher performance on the target task by joint training with the auxiliary task,

\[_{}_{_{}}_{}( )+_{_{}}_{}(),\] (1)

where \(\) is the training loss, and \(\) is the relative weighting hyper-parameter between the auxiliary task and the target task. Our final objective is \(_{}[()]\), where \(\) is the relative performance measure for the target task \(_{}\), such as the accuracy in classification. Next we define the Transfer Gain to measure the impact of \(_{}\) on \(_{}\).

**Definition 3.1** (Transfer Gain, TG).: Denote the model obtained by some ATL algorithm \(\) as \(_{}(_{},_{},)\) and the model obtained by single-task learning on target task as \((_{})\). Let \(\) be the performance measure on the target task \(_{}\). Then the algorithm \(\) can be evaluated by

\[TG(,)=(_{}(_{},_{},))-((_{})).\] (2)

Going beyond previous work on Negative Transfer (NT) [75; 84], we further divide negative transfer in ATL into two types.

**Definition 3.2** (Weak Negative Transfer, WNT).: For some ATL algorithm \(\) with weighting hyper-parameter \(\), weak negative transfer occurs if \(TG(,)<0\).

**Definition 3.3** (Strong Negative Transfer, SNT).: For some ATL algorithm \(\), strong negative transfer occurs if \(_{>0}TG(,)<0\).

Figure 1 illustrates the difference between weak negative transfer and strong negative transfer. The most essential difference is that we might be able to avoid weak negative transfer by selecting a proper weighting hyper-parameter \(\), yet we cannot avoid strong negative transfer in this way.

Next, we will analyze negative transfer in ATL from two different perspectives: **optimization** and **generalization**. We conduct our analysis on a multi-domain image recognition dataset DomainNet  with ResNet-18  pre-trained on ImageNet. Specifically, we use task Painting and Quickdraw in DomainNet as target tasks respectively to showcase weak negative transfer and strong negative transfer, and mix all other tasks in DomainNet as auxiliary tasks. We will elaborate on the DomainNet dataset in Appendix C.3 and provide the detailed experiment design in Appendix B.

### Effect of Gradient Conflicts

It is widely believed that gradient conflicts between different tasks will lead to optimization difficulties [79; 40], which in turn lead to negative transfer. The degree of gradient conflict is usually measured by the Gradient Cosine Similarity [79; 76; 15].

Figure 1: Weak Negative Transfer (WNT) vs. Strong Negative Transfer (SNT).

**Definition 3.4** (Gradient Cosine Similarity, GCS).: Denote \(_{ij}\) as the angle between two task gradients \(_{i}\) and \(_{j}\), then we define the gradient cosine similarity as \(_{ij}\) and the gradients as conflicting when \(_{ij}<0\).

In Figure 2, we plot the correlation curve between gradient cosine similarity and transfer gain. Somewhat counterintuitively, we observe that negative transfer and gradient conflicts are not strongly correlated, and negative transfer might be severer when the task gradients are highly consistent.

_Finding 1. Negative transfer is not necessarily caused by gradient conflicts and gradient conflicts do not necessarily lead to negative transfer._

It seems contradictory to the previous work [79; 15] and the reason is that previous work mainly considers the _optimization_ convergence during training, while in our experiments we further consider the _generalization_ during evaluation (transfer gain is estimated on the validation set). Although the conflicting gradient of the auxiliary task will increase the training loss of the target task and slow down its convergence speed , it may also play a role similar to regularization , reducing the over-fitting of the target task, thereby reducing its generalization error. To confirm our hypothesis, we repeat the above experiments with the auxiliary task replaced by \(L_{2}\) regularization and observe a similar phenomenon as shown in Figure 2(c)-(d), which indicates that the gradient conflict in ATL is not necessarily harmful, as it may serve as a proper regularization.

Figure 2 also indicates that the weighting hyper-parameter \(\) in ATL has a large impact on negative transfer. A proper \(\) not only reduces negative transfer but also promotes positive transfer.

### Effect of Distribution Shift

Next, we will analyze negative transfer from the perspective of generalization. We notice that adjusting \(\) will change the data distribution that the model is fitting. For instance, when \(=0\), the model only fits the data distribution of the target task, and when \(=1\), the model will fit the interpolated distribution of the target and auxiliary tasks. Formally, given the target distribution \(_{}\) and the auxiliary distribution \(_{}\), the interpolated distribution of the target and auxiliary task is \(_{}\),

\[_{}(1-Z)_{}+Z_{ },Z(),\] (3)

where \(\) is the task-weighting hyper-parameter. Figure 3(a) quantitatively visualizes the distribution shift under different \(\) using t-SNE .

To quantitatively measure the distribution shift in ATL, we introduce the following definitions. Following the notations of , we consider multiclass classification with hypothesis space \(\) of scoring functions \(f:\) where \(f(x,y)\) indicates the confidence of predicting \(x\) as \(y\).

**Definition 3.5** (Confidence Score Discrepancy, CSD).: Given scoring function hypothesis \(\), denote the optimal hypothesis on distribution \(\) as \(f^{*}_{}\), then confidence score discrepancy between

Figure 2: The effect of _gradient conflicts_. The correlation curve between Transfer Gain (TG) and Gradient Cosine Similarity (GCS) under different \(\). For a fair comparison, each data point starts from the same model parameters in the middle of the training process and updates with one-step multi-task gradient descent. **P** and **Q** are short for **P**ainting and **Q**uickdraw tasks, respectively.

distribution \(\) and \(^{}\) induced by \(\) is defined by

\[d_{}(,^{}) 1-_{x ^{}}_{y}f_{}^{*}(x,y).\] (4)

Confidence score discrepancy between training and test data indicates how unconfident the model is on the test data, which is expected to increase when the data shift enlarges [59; 50].

Figure 3(b) indicates the correlation between confidence score discrepancy and transfer gain. For weak negative transfer tasks, when \(\) increases at first, the introduced auxiliary tasks will shift the training distribution towards the test distribution, thus decreasing the confidence score discrepancy between training and test data and improving the generalization of the target task. However, when \(\) continues to increase, the distribution shift gradually increases, finally resulting in negative transfer. For strong negative transfer tasks, there is a large gap between the distribution of the introduced auxiliary tasks and that of the target task. Thus, increasing \(\) always enlarges confidence score discrepancy and always leads to negative transfer. In summary,

_Finding 2. Negative transfer is likely to occur if the introduced auxiliary task enlarges the distribution shift between training and test data for the target task._

## 4 Methods

In Section 4.1, based on our above analysis, we will introduce how to mitigate negative transfer when the auxiliary task is determined. Then in Section 4.2, we will further discuss how to use the proposed method to select appropriate auxiliary tasks and optimize them jointly with the target task simultaneously.

### ForkMerge

In this section, we assume that the auxiliary task \(_{}\) is given. When updating the parameters \(_{t}\) with Equation (1) at training step \(t\), we have

\[_{t+1}()=_{t}-(_{}(_{t})+ _{}(_{t})),\] (5)

where \(\) is the learning rate, \(_{}\) and \(_{}\) are the gradients calculated from \(_{}\) and \(_{}\) respectively. Section 3.1 reveals that the gradient conflict between \(_{}\) and \(_{}\) does not necessarily lead to negative transfer as long as \(\) is carefully tuned and Section 3.2 shows that negative transfer is related to generalization. Thus we propose to dynamically adjust \(\) according to the target validation performance \(}\) to mitigate negative transfer:

\[_{}}(_{t+1})=}( _{t}-(_{}(_{t})+_{}(_{t}))).\] (6)

Figure 3: The effect of _distribution shift_. **(a)** Visualization of training distribution and test distribution under different \(\). **(b)** For weak negative transfer tasks, as \(\) increases, Confidence Score Discrepancy (CSD) first drops and then rises and Transfer Gain (TG) is first positive and then negative. For strong negative transfer tasks, CSD increases monotonically and TG remains negative.

Equation (6) is a bi-level optimization problem. One common approach is to first approximate \(}\) with the loss of a batch of data on the validation set, and then use first-order approximation to solve \(\)[18; 43]. However, these approximations within a single step of gradient descent introduce large noise to the estimation of \(\) and also increase the risk of over-fitting the validation set. To tackle these issues, we first rewrite Equation (6) equally as

\[_{}}(1-)_{t+1}(0)+ _{t+1}(1),\] (7)

where \(_{t+1}(0)=_{t}-_{}(_{t})\) and \(_{t+1}(1)=_{t}-(_{}(_{t})+ _{}(_{t}))\). The proof is in Appendix A.1. Note that we assume the optimal \(^{*}\) satisfies \(0^{*} 1\), which can be guaranteed by increasing the scale of \(_{}\) when necessary. Yet an accurate estimation of performance \(}\) in Equation (7) is still computationally expensive and prone to over-fitting, thus we extend the one gradient step to \( t\) steps,

\[^{*}=_{}}(1-)_{ t+ t}(0)+_{t+ t}(1).\] (8)

Algorithm.As shown in Figure 4 and Algorithm 1, the initial model parameters \(_{t}\) at training step \(t\) will first be forked into two branches. The first one will be optimized only with the target task loss \(_{}\) for \( t\) iterations to obtain \(_{t+ t}(0)\), while the other one will be jointly trained for \( t\) iterations to obtain \(_{t+ t}(1)\). Then we will search the optimal \(^{*}\) that linearly combines the above two sets of parameters to maximize the validation performance \(}\). When weak negative transfer occurs in the joint training branch, we can select a proper \(^{*}\) between \(0\) and \(1\). And when strong negative transfer occurs, we can simply set \(^{*}\) to \(0\). Finally, the newly merged parameter \(_{t+ t}^{*}=(1-^{*})_{t+ t}(0)+^{*} _{t+ t}(1)\) will join in a new round, being forked into two branches again and repeating the optimization process for \(\) times.

Discussion.Compared to grid searching \(\), which is widely used in practice, ForkMerge can dynamically transfer knowledge from auxiliary tasks to the target task during training with varying \(^{*}\). In terms of computation cost, ForkMerge has a lower complexity as it only requires training \(2\) branches while grid searching has a cost proportional to the number of hyper-parameters to be searched.

```
0: initial model parameter \(_{0}\), total iterations \(T\), interval \( t\)
0: final model parameter \(_{T}^{*}\), task relevance \(^{*}\)
0: for\(b=0\)to 1 do \(\) initialization
0: endfor \(t<T\)do \(\) independent update for\(t^{}=t\)to \(t+ t-1\)do \(_{t^{}+1}^{*}=_{t^{}}^{*}-(_{}( _{t^{}}^{*})+b_{}(_{t^{}}^{b}))\) endfor \(^{*}_{}}((1-) _{t+ t}^{*}+_{t+ t}^{*})\) \(\) search \(\) on the validation set \(_{t+ t}^{*}=(1-^{*})_{t+ t}^{0}+^{*} _{t+ t}^{*}\) for\(b=0\)to 1 do \(_{t+ t}^{b}_{t+ t}^{*}\) \(\) synchronize parameters endfor \(t t+ t\) endwhile ```

**Algorithm 1** ForkMerge Training Pipeline.

### ForkMerge for Task Selection Simultaneously

When multiple auxiliary tasks are available, we can simply mix all the auxiliary tasks together to form a single auxiliary task. This simple strategy actually works well in most scenarios (see Section 5.2) and is computationally cheap. However, when further increasing the performance is desired, we can also dynamically select the optimal weighting for each auxiliary task. Formally, the objective

Figure 4: ForkMerge training pipeline. The model parameters will be forked into two branches, one optimized with the target task loss and the other jointly trained, and be merged at regular intervals of \( t\) steps.

when optimizing the model for the target task \(_{0}\) with multiple auxiliary tasks \(\{_{k}\}_{k=1}^{K}\) is

\[_{}_{_{0}}_{0}()+_{k=1}^{K} _{k}_{_{k}}_{k}(),\] (9)

where \(_{k=1}^{K}_{k} 1\) and \( k,_{k} 0\). Using gradient descent to update \(_{t}\) at training step \(t\), we have

\[_{t+1}()=_{t}-_{k=0}^{K}_{k} _{k}(_{t}),\] (10)

where \(_{0}=1\). Given \(K\) task-weighting vectors \(\{^{k}\}_{k=0}^{K}\) that satisfies \(_{i}^{k}=[i=ki=0]\), i.e., the \(k\)-th and \(0\)-th dimensions of \(^{k}\) are \(1\) and the rest are \(0\), and a vector \(\) that satisfies

\[_{k}=1-_{i 0}_{i},&k=0,\\ &_{k},&k 0,\] (11)

then optimizing \(^{*}\) in Equation (10) is equivalent to

\[^{*}=_{}}_{k=0 }^{K}_{k}_{t+1}(^{k}).\] (12)

In Equation (12), the initial model parameters are forked into \(K+1\) branches, where one branch is optimized with the target task, and the other branches are jointly optimized with one auxiliary task and the target task. Then we find the optimal \(^{*}\) that linearly combines the \(K+1\) sets of parameters to maximize the validation performance (see proof of Equation (12) and the detailed algorithm in Appendix A.2). The training computational complexity of Equation 12 is \((K)\), which is much lower than the exponential complexity of grid searching, but still quite large. Inspired by the early-stop approximation used in task grouping methods , we can prune the forking branches with \(_{k}=0\) (strong negative transfer) and only keep the branches with the largest \(K^{}<K\) values in \(\) after the early merge step. In this way, those useless branches with irrelevant auxiliary tasks can be stopped early. Additionally, we introduce a greedy search strategy in Algorithm 3 to further reduce the computation complexity when grid searching all possible values of \(\).

Lastly, we introduce a general form of ForkMerge. Assuming \(B\) candidate branches with task-weighting vectors \(^{b}\) (\(b=1,,B\)), the goal is to optimize \(}^{*}\):

\[}^{*}=_{}}}_{b=1}^{B}_{b}_{t+ t}( ^{b}).\] (13)

From a generalization view, the mixture distributions constructed by different \(\) lead to diverse data shifts from the target distribution, yet we cannot predict which \(\) leads to better generalization. Thus, we transform the problem of mixture distribution into that of mixture hypothesis  and the models trained on different distributions are combined dynamically via \(}^{*}\) to approach the optimal parameters. Here, Equation 12 is a particular case by substituting \(B=K+1\) and \(^{b}_{i}=[i=b-1i=0]\). By comparison, Equation 13 allows us to introduce human prior into ForkMerge by constructing more efficient branches, and also provides possibilities for combining ForkMerge with previous task grouping methods [81; 71; 17]. The detailed algorithm of Equation 13 can be found in Algorithm 2.

## 5 Experiments

We evaluate the effectiveness of ForkMerge under various settings, including multi-task learning, multi-domain learning, and semi-supervised learning. First, in Section 5.1, we illustrate the prevalence of negative transfer and explain how ForkMerge can mitigate this problem. In Section 5.2, We examine whether ForkMerge can mitigate negative transfer when joint training the auxiliary and target tasks, and compare it with other methods. In Section 5.3, we further use ForkMerge for task selection simultaneously. Experiment details can be found in Appendix C. We will provide additional analysis and comparison experiments in Appendix D. The codebase for both our method and the compared methods will be available at https://github.com/thuml/ForkMerge.

### Motivation Experiment

Negative Transfer is widespread across different tasks.In Figure 5 (a), we visualize the transfer gains between \(30\) task pairs on DomainNet, where the auxiliary and target tasks are equally weighted, and we observe that negative transfer is common in such case (\(23\) of \(30\) combinations lead to negative transfer). Besides, as mentioned in Definition 3.2 and 3.3, whether negative transfer occurs is related to a specific ATL algorithm, in Figure 5 (b), we observe that negative transfer in all \(30\) combinations can be successfully avoided when we use ForkMerge algorithm. This observation further indicates the limitation of task grouping methods [71; 17], since they use Equal Weight between tasks and may discard some useful auxiliary tasks.

Mixture of hypotheses is an approximation of mixture of distribution.Figure 6 uses the ternary heatmaps to visualize the linear combination of a set of three models optimized with different task weightings for \(25K\) iterations, including a single-task model and two multi-task models. Similar to mixing distributions for weak negative transfer task Painting (see Figure 3), the transfer gain when mixing models **P**ainting and **P**ainting+**R**eal first increases and then decreases. Also similar to mixing distributions for strong negative transfer task **Q**uickdraw, the transfer gain when mixing models **Q**uickdraw and **Q**uickdraw+**R**eal decreases monotonically. Besides, Figure 6 also indicates a good property of deep models: the loss surfaces of over-parameterized deep neural networks are quite well-behaved and smooth after convergence, which has also been mentioned by previous works [20; 35] and provides an intuitive explanation of the merge step in ForkMerge.

### Use ForkMerge for Joint Optimization

First, we use ForkMerge only for joint training of the target and auxiliary tasks. When datasets contain multiple tasks, we will mix all tasks together to form a single auxiliary task for ForkMerge. Yet for the compared methods, a distinction is still made between different tasks for better performance.

Specifically, we compare ForkMerge with: (1) Single Task Learning (STL); (2) EW, which assigns equal weight to all tasks; (3) GCS , an ATL approach using gradient similarity between target and auxiliary tasks; (4) OL_AUX , an ATL approach adjusting the loss weight based on gradient inner product; (5) ARML , an ATL approach adjusting the loss weight based on gradient difference; (6) Auto-\(\), an ATL method that estimates loss weight through finite-difference approximation ; (7) Post-train, an ATL method that pre-trains the model on all tasks and then fine-tunes it for each task separately. (8) UW , which adjusts weights based on task uncertainty; (9) DWA , which adjusts weights based on loss change; (10) MGDA , which computes a convex combination of gradients with a minimum norm to balance tasks; (11) GradNorm , which rescales the gradient norms of different tasks to the same range; (12) PCGrad , which eliminates conflicting gradient components; (13) IMTL , which uses an update direction with equal projections on task gradients; (14) CAGrad , which optimizes for the average loss and minimum decrease rate across tasks; (15) NashMTL , which combines the gradients using the Nash bargaining solution. Since different tasks have varying evaluation metrics, we will report the average per-task performance improvement for each method using \(_{m}\), as defined in Appendix C.1.

Figure 5: Negative Transfer on DomainNet. The rows of each matrix represent auxiliary tasks, and the columns represent target tasks. The blue and red cells correspond to negative and positive transfer gain. Deeper colors indicate stronger impacts.

Figure 6: Ternary heatmap for mixture of model hypotheses. Each triangle vertex represents an optimized model, e.g., **P+R** is the model jointly optimized with **P**ainting and **R**eal tasks. Each point inside the triangle corresponds to a mixture of model hypotheses and its heat value measures the Transfer Gain (TG).

**Auxiliary-Task Scene Understanding.** We evaluate on the widely-used multi-task scene understanding dataset, NYUv2 , which contains \(3\) tasks: \(13\)-class semantic segmentation, depth estimation, and surface normal prediction. Following , we use \(636\), \(159\) and \(654\) images for training, validation, and test. Our implementation is based on LibMTL  and MTAN . The results are presented in Table 1. Negative transfer is not severe on this dataset, where both _segmentation_ and _depth_ benefit from ATL and only _normal_ task gets worse. In such cases, our method still achieves significant improvement on all tasks. We also find that Post-train serves as a strong baseline in most of our ATL experiments. Its drawback is that it fails to consider the task relationship in the pre-training phase, and suffers from catastrophic forgetting during the fine-tuning process.

**Auxiliary-Domain Image Recognition.** Further, we evaluate on the widely-used multi-domain image recognition dataset, DomainNet , which contains \(6\) diverse visual domains and approximately \(0.6\) million images distributed among \(345\) categories, where the task difference is reflected in the marginal distribution. Our implementation is based on TLlib . As the original DomainNet does not provide a separate validation set, we randomly split \(50\%\) data from the test set as the validation set. The results are presented in Table 2. DomainNet contains both positive transfer tasks (**C**lipart), weak negative transfer tasks (**I**nfograph, **P**ainting, **R**eal, **S**ketch), and strong negative transfer tasks (**Q**uickdraw). When negative transfer occurs, previous ATL methods lead to severe performance degradation, while our method can automatically avoid strong negative transfer and improve the performance over STL in other cases.

### Use ForkMerge for Task Selection Simultaneously

As mentioned in Section 4.2, when there are multiple auxiliary task candidates, we can use ForkMerge to simultaneously select auxiliary tasks and jointly train them with the target task, which is denoted as ForkMerge\({}^{}\).

**Auxiliary-Task Scene Understanding.** In NYUv2, we have \(2\) auxiliary tasks for any target task, thus we can construct \(3\) branches with different task weights in Equation 12. In this way, we are able to select auxiliary tasks adaptively by learning different \(\) for different branches in the merge step. As shown in Table 3, this strategy yields better overall performance.

**Auxiliary-Domain Image Recognition.** For any target task in DomainNet, we can construct up to \(6\) branches with different task weights in Equation 12, which is computationally expensive. As mentioned in Section 4.2, we will prune the branches after the first merge step to reduce the computation cost. Table 4 reveals the impact of the pruning strategy. As the number of branches increases, the gain brought by auxiliary tasks will enlarge, while the gain brought by each branch will reduce. Therefore, pruning is an effective strategy to achieve a better balance between performance and efficiency. In practical terms, when confronted with multiple auxiliary tasks, users have the flexibility to tailor the number of branches to align with their available computational resources.

**CTR and CTCVR Prediction.** We evaluate on AliExpress dataset , a recommendation dataset from the industry, which consists of \(2\) tasks: CTR and CTCVR, and \(4\) scenarios and more than \(100\)M records. Our implementation is based on MTReclib . For any target task in AliExpress, we can construct up to \(8\) branches with different task weights, and we prune to \(3\) branches after the first merge

    &  &  &  & }\)} \\    & **mIoU\(\)** & **Pix Acc\(\)** & **Abs Err\(\)** & **Rel Err\(\)** & **Mean\(\)** \\  STL & 51.42 & 74.14 & 41.74 & 17.37 & 22.82 & - \\  EW & 52.13 & 74.51 & 39.03 & 16.43 & 24.14 & 0.305 \\ UW & 52.51 & 74.72 & 39.15 & 16.56 & 25.39 & 0.65\% \\ DWA & 52.10 & 74.45 & 39.26 & 16.57 & 24.12 & 0.07\% \\ MODA & 50.79 & 73.81 & 39.19 & 16.25 & 23.14 & 1.44\% \\ GradNorm & 52.25 & 74.54 & 39.51 & 16.37 & 28.36 & 0.56\% \\ PCGrad & 51.77 & 74.72 & **38.91** & 16.36 & 24.31 & 0.22\% \\ DTL & 52.24 & 74.73 & 39.46 & **15.92** & 23.25 & 2.10\% \\ CAfGrad & 52.04 & 74.25 & 39.06 & 16.30 & 23.39 & 1.41\% \\ NashMTL & 51.73 & 74.10 & 39.55 & 16.50 & 23.21 & 1.11\% \\  GCS & 52.67 & 74.59 & 39.72 & 16.64 & 24.10 & 0.09\% \\ OL\_AUX & 52.07 & 74.28 & 39.32 & 16.30 & 25.98 & 0.17\% \\ ARML & 52.73 & 74.85 & 39.61 & 16.65 & 25.89 & 0.37\% \\ Auto-A & 52.04 & 74.62 & 39.25 & 16.25 & 23.38 & 1.17\% \\ Post-train & 52.08 & 74.86 & 39.58 & 16.77 & 22.98 & 1.49\% \\ ForkMerge & **53.67** & **75.64** & **38.91** & 16.47 & **22.18** & **4.03\%** \\   

Table 1: Performance on NYUv2 dataset.

  
**Methods** & **C** & **I** & **P** & **Q** & **R** & **S** & **Avg** & \(}\) \\  STL & 77.6 & 41.4 & 71.8 & **73.0** & 84.6 & 70.2 & 69.8 & - \\  EW & 78.0 & 38.1 & 67.2 & 50.8 & 77.1 & 67.0 & 63.0 & -9.62\% \\ UW & 79.1 & 35.8 & 68.2 & 50.5 & 77.9 & 67step. The results are presented in Table 5. Note that improving on such a large-scale dataset with auxiliary tasks is quite difficult. Still, ForkMerge achieves the best performance with \(_{m}=\).

**Semi-Supervised Learning (SSL)**. We also evaluate on two SSL datasets, CIFAR-10  and SVHN . Following , we use Self-supervised Semi-supervised Learning (S4L)  as our baseline algorithm and use \(2\) self-supervised tasks, Rotation  and Exempler-MT , as our auxiliary tasks. Table 6 presents the test error of S4L using different ATL approaches, along with other SSL methods, and shows that ForkMerge consistently outperforms the compared ATL methods. Note that we do not aim to propose a novel or state-of-the-art SSL method in this paper. Instead, we find that some SSL methods use ATL and the auxiliary task weights have a great impact (see Grid Search in Table 6). Thus, we use ForkMerge to improve the auxiliary task training within the context of SSL.

## 6 Conclusion

Methods have been proposed to mitigate negative transfer in auxiliary-task learning, yet there still lacks an in-depth experimental analysis on the causes of negative transfer. In this paper, we systematically delved into the negative transfer issues and presented ForkMerge, an approach to enable auxiliary-task learning with positive transfer gains. Experimentally, ForkMerge achieves state-of-the-art accuracy on four different auxiliary-task learning benchmarks, while being computationally efficient. We view the integration of previous task grouping methods with our auxiliary task learning approach as a promising avenue for further research.