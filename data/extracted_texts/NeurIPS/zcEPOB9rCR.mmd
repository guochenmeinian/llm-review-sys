# Bridging Geometric States

via Geometric Diffusion Bridge

 Shengjie Luo\({}^{1}\), Yixian Xu\({}^{1,4}\), Di He\({}^{1}\), Shuxin Zheng\({}^{2}\), Tie-Yan Liu\({}^{2}\), Liwei Wang\({}^{1,3}\)

\({}^{1}\)State Key Laboratory of General Artificial Intelligence,

School of Intelligence Science and Technology, Peking University

\({}^{2}\)Microsoft Research AI4Science \({}^{3}\)Center for Data Science, Peking University

\({}^{4}\)Pazhou Laboratory (Huangpu), Guangzhou, Guangdong 510555, China

luosj@stu.pku.edu.cn, xyx050@stu.pku.edu.cn,

{shuz, tyliu}@microsoft.com, {dihe, wanglu}@pku.edu.cn

Equal contribution.Correspondence to: Di He<dihe@pku.edu.cn>, Liwei Wang <wanglu@pku.edu.cn>.

###### Abstract

The accurate prediction of geometric state evolution in complex systems is critical for advancing scientific domains such as quantum chemistry and material modeling. Traditional experimental and computational methods face challenges in terms of environmental constraints and computational demands, while current deep learning approaches still fall short in terms of precision and generality. In this work, we introduce the Geometric Diffusion Bridge (GDB), a novel generative modeling framework that accurately bridges initial and target geometric states. GDB leverages a probabilistic approach to evolve geometric state distributions, employing an equivariant diffusion bridge derived by a modified version of Doob's \(h\)-transform for connecting geometric states. This tailored diffusion process is anchored by initial and target geometric states as fixed endpoints and governed by equivariant transition kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB framework by using a chain of equivariant diffusion bridges, providing a more detailed and accurate characterization of evolution dynamics. Theoretically, we conduct a thorough examination to confirm our framework's ability to preserve joint distributions of geometric states and capability to completely model the underlying dynamics inducing trajectory distributions with negligible error. Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches, opening up a new pathway for accurately bridging geometric states and tackling crucial scientific challenges with improved accuracy and applicability.

## 1 Introduction

Predicting the evolution of the geometric state of a system is essential across various scientific domains , offering valuable insights into difficult tasks such as drug discovery , reaction modeling , and catalyst analysis . Despite its critical importance, accurately predicting future geometric states of interest is challenging. Experimental approaches often face obstacles due to strict environmental requirements and physical limits of instruments . Computational approaches seek to solve the problem by simulating the dynamics based on underlying equations . Though providing greater flexibility, such calculations are typically driven by first-principle methods or empirical laws, either requiring extensive computational costs  or sacrificing accuracy .

In recent years, deep learning has emerged as a pivotal tool in scientific discovery for many fields [43; 23; 69; 107], offering new avenues for tackling this problem. One line of approach aims to train models to predict target geometric states (e.g., equilibrium states) from initial states directly and develop neural network architectures that respect inherent symmetries of geometric states, such as the equivariance of rotation and translation [104; 31; 8; 87; 89; 103]. However, this paradigm requires encoding the iterative evolution into a single-step prediction model, which lacks the ability to fully capture the system's underlying dynamics and potentially leading to reduced accuracy. Another line of research trains machine learning force fields (MLFFs) to simulate the trajectory of geometric states over time [32; 34; 6; 70; 5; 58], showing a better efficiency-accuracy balance [15; 13; 105; 84]. Nevertheless, MLFFs are typically trained to predict intermediate labels, such as the force of the (local) current state. During inference, states are iteratively updated step by step. Since small local errors can accumulate, reliable predictions over long trajectories highly depend on the quality of intermediate labels, which cannot be guaranteed [7; 106; 30]. Therefore, an ideal solution that can precisely bridge initial and target geometric states and effectively leverage trajectory data (if available) as guidance is in great demand.

In this work, we introduce _Geometric **D**iffusion **B**ridge (GDB)_, a general framework for bridging geometric states through generative modeling. From a probabilistic perspective, predicting target geometric states from initial states requires modeling the joint state distribution across different time steps. The diffusion models [37; 99] are standard choices to achieve this goal. However, these methods ideally generate data by denoising samples drawn from a Gaussian prior distribution, which makes it challenging to bridge pre-given geometric states or leverage trajectories in a unified manner. To address the issue, we establish a novel _equivariant diffusion bridge_ by developing a modified version of _Doob's h-transform_[82; 81; 16]. The proposed stochastic differential equation (SDE) is anchored by initial and target geometric states to simultaneously model the joint state distribution and is governed by equivariant transition kernels to satisfy symmetry constraints. Intriguingly, we further demonstrate that this framework can seamlessly leverage trajectory data to improve prediction. With available trajectory data, we can construct _chains of equivariant diffusion bridges_, each modeling one segment in the trajectory. The segments are interconnected by properly setting the boundary conditions, allowing complete modeling of trajectory data. For model training, we derive a scalable and simulation-free matching objective similar to [59; 61; 77], which requires no computational overhead when trajectory data is leveraged.

Overall, our GDB framework offers a unified solution that precisely bridges geometric states by modeling the joint state distribution and comprehensively leverages available trajectories as fine-grained depiction of dynamics for enhanced performance. Mathematically, we prove that the joint distribution of geometric states across different time steps can be completely preserved by our (chains of) equivariant diffusion bridge technique, confirming its expressiveness in bridging geometric states and underscoring the necessity of design choices in our framework. Furthermore, under mild and practical assumptions, we prove that our framework can approximate the underlying dynamics governing the evolution of geometric state trajectories with negligible error in convergence, remarking on the completeness and usefulness of our framework in different scenarios. These advantages show the superiority of our framework over existing approaches.

Practically, we provide a comprehensive guidance for implementing our GDB framework in real-world applications. To verify its effectiveness and generality, we conduct extensive experiments covering diverse data modalities (simple molecules & adsorbate-catalyst complex), scales (small, medium and large scales) and scenarios (with & without trajectory guidance). Numerical results show that our GDB framework consistently outperforms existing state-of-the-art machine learning approaches by a large margin. In particular, our method even surpasses strong MLFF baselines that are trained on \(10\) more data in the challenging structure relaxation task of OC22 , and trajectory guidance can further enhance our performance. The significantly superior performance demonstrates the high capacity of our framework to capture the complex evolution dynamics of geometric states and determine valuable and crucial geometric states of interest in critical real-world challenges.

## 2 Background

### Problem Definition

Our task of interest is to capture the evolution of geometric states, i.e., predicting future states from initial states. Formally, let \(S\) denote a system consisting of a set of objects located in the three-dimensional Euclidean space. We use \(^{n d}\) to denote the objects with features, where \(n\) is the number of objects, and \(d\) is the feature dimension. For object \(i\), let \(_{i}^{3}\) denote its Cartesian coordinate. We define the system as \(S=(,R)\), where \(R=\{_{1},...,_{n}\}\). This data structure ubiquitously corresponds to various real-world systems such as molecules and proteins [17; 20; 101]. In practice, the geometric state is governed by physical laws and evolves over time, and we denote the geometric state at a given time \(t\) as \(R^{t}=\{_{1}^{t},...,_{n}^{t}\}\). Given a system \(S^{t_{0}}=(,R^{t_{0}})\) at time \(t_{0}\), our goal is to predict \(S^{t_{1}}=(,R^{t_{1}})\) at a future time \(t_{1}\). As an example, in a molecular system, \(R^{t_{1}}\) can be the equilibrium state of interest evolved from the initial state \(R^{t_{0}}\).

In this problem, inherent symmetries in geometric states should be considered. For example, a rotation that is applied to the coordinate system at time \(t_{0}\) should also be applied to subsequent time steps. These symmetries are related to the concept of equivariance in group theory [19; 18; 91]. Formally, let \(:\) denote a function mapping between two spaces. Given a group \(G\), let \(^{}\) and \(^{}\) denote its group representations, which describe how the group elements act on these spaces. A function \(:\) is said to be equivariant if it satisfies the following condition: \(^{}(g)[(x)]=(^{}(g)[x]),  g G,x\). When \(^{}=^{}\) (identity transformation), it is also known as invariance. \((3)\) group, which pertains to translations (\((3)\)) and rotations (\((3)\)) in 3D Euclidean space, is one of the most widely used groups and is employed in our framework.

### Diffusion Models

Diffusion models [95; 37; 99] have emerged as the state-of-the-art generative modeling approaches across various domains [83; 85; 47; 115; 113; 117]. The main idea of this method is to construct a diffusion process that maps data to noise, and train models to reverse such process by using a tractable objective.

Formally, to model the data distribution \(q_{data}()\), where \(^{d}\), we construct a diffusion process \((_{t})_{t[0,T]}\), which is represented as a sequence of random variables indexed by time steps. We set \(_{0} q_{}()\) and \(_{T} p_{}()\), where \(p_{}()\) has a tractable form to generate samples efficiently, e.g. standard Gaussian distribution. Mathematically, we model \((_{t})_{t[0,T]}\) as the solution to the following stochastic differential equation (SDE):

\[_{t}=(_{t},t)t+(t) _{t},\] (1)

where \((,):^{d}[0,T]^{d}\) is a vector-valued function called the _drift_ coefficient, \(():[0,T]\) is a scalar function known as the _diffusion_ coefficient, and \((_{t})_{t[0,T]}\) is the standard Wiener process (a.k.a., Brownian motion) . We hereafter denote by \(p_{t}()\) the marginal distribution of \(_{t}\). Let \(p(x^{},t^{}|x,t)\) denote the transition density function such that \(P(_{t^{}} A|_{t}=x)=_{A}p(x^{},t^{ }|x,t)x^{}\) for any Borel set \(A\). By simulating this diffusion process forward in time, the distribution of \(_{t}\) will become \(p_{}()\) at the final time \(T\). In the literature, there exist various design choices of the SDE formulation in Eqn. (1) such that it transports the data distribution into the fixed prior distribution [98; 37; 99; 72; 97; 47].

In order to sample \(_{0} p_{0}():=q_{}()\), an intriguing fact can be leveraged: the reverse of a diffusion process is also a diffusion process . This reverse process runs backward in time and can be formulated by the following time-reversal SDE:

\[_{t}=[(_{t},t)-^{2}(t) _{_{t}} p_{t}(_{t})]t+(t) _{t},\] (2)

where \(_{} p_{t}()\) denote the score of the marginal distribution at time \(t\). If the score is known for all time, then we can derive the reverse diffusion process from Eqn. (2), sample from \(p_{}()\), and simulate this process to generate samples from the data distribution \(q_{}()\). In particular, the score \(_{} p_{t}()\) can be estimated by training a parameterized model \(_{}(,t)\) with a denoising score matching objective [98; 97]. In theory, the minimizer of this objective approximates the ground-truth score  and this objective is tractable.

## 3 Geometric Diffusion Bridge

As discussed in the introduction, effectively capturing the evolution of geometric states is crucial, for which three desiderata should be carefully considered:* _Coupling Preservation_: From a probabilistic perspective, the evolution of geometric states transports their distribution from \(q_{}(S^{t_{0}})\) to \(q_{}(S^{t_{1}})\), and we are interested in modeling the distribution of target geometric states given the initial states, i.e., \(q_{}(S^{t_{1}}|S^{t_{0}}):=q_{}(R^{t_{1}}|,R^{t _{0}})\), which can be achieved by preserving the _coupling_ of geometric states, i.e., \(q_{}(R^{t_{0}},R^{t_{1}}|)\). For brevity, we hereafter omit the condition of \(\) because it keeps the same along the evolution and can be easily incorporated into the models.
* _Symmetry Constraints_: Since the law governing the evolution is unchanged regardless of how the system is rotated or translated, the distribution of the geometric states should satisfy symmetry constraints, i.e., \(q_{}(^{}(g)[R^{t_{1}}]|^{}(g)[R^{t_{ 0}}])=q_{}(R^{t_{1}}|R^{t_{0}})\) and \(q_{}(^{}(g)[R^{t_{0}}],^{}(g)[R^{t_ {1}}])=q_{}(R^{t_{0}},R^{t_{1}})\) for all \(g(3),R^{t}\).
* _Trajectory Guidance_: Trajectories of geometric states are sometimes accessible and provide fine-grained descriptions of the evolution dynamics. For completeness, it is crucial to develop a unified framework that can characterize and leverage trajectory data as guidance for better bridging geometric states and capturing the evolution.

However, existing approaches typically have their limitations for this task, which we thoroughly discuss in Sec. 5 and summarize into Table 1. In this section, we introduce Geometric Diffusion Bridge (GDB), a general framework for bridging geometric states through generative modeling. We will elaborate on key techniques for completely preserving couping under symmetry constraints (Sec. 3.1), and demonstrate how our framework can be seamlessly extended to leverage trajectory data (Sec. 3.2). Theoretically, we conduct a thorough analysis on the capability of our unified framework, showing its completeness and superiority. All proofs of theorems are presented in Appendix B. A detailed guidance of practical implementing our framework is further provided (Sec. 3.3).

### Equivariant Diffusion Bridge

Our key design lies in the construction of _equivariant diffusion bridge_, a tailored diffusion process \((^{t})_{t[0,T]}\) for bridging initial states \(^{0}{}q_{}(R^{t_{0}})\) and target states \(^{T}{}q_{}(R^{t_{1}}|R^{t_{0}})\), completely preserving coupling of geometric states and satisfying symmetry constraints. Firstly, we investigate necessary conditions for a diffusion process on geometric states to meet the symmetric constraints:

**Proposition 3.1**.: _Let \(\) denote the space of geometric states and \(_{}(,):[0,T]\) denote the drift coefficient on \(\). Let \((^{t})_{t[0,T]}\) denote the Wiener process on \(\). Given an SDE on geometric states \(^{t}=_{}(^{t},t)t+(t)^{t}\), \(^{0} q(^{0})\), its transition density \(p_{}(z^{},t^{}|z,t),z,z^{}\) is \((3)\)-equivariant, i.e., \(p_{}(^{t^{}},t^{}|^{t},t)=p_{ }(^{}(g)[^{t^{}}],t^{}|^ {}(g)[^{t}],t), g(3),0 t,t^{ } T,\) if these conditions are satisfied: (1) \(q(^{0})\) is \((3)\)-invariant; (2) \(_{}(,t)\) is \((3)\)-equivariant and \((3)\)-invariant; (3) the transition density of \((^{t})_{t[0,T]}\) is \((3)\)-equivariant._

Using Proposition 3.1, we can obtain a diffusion process that respect symmetry constraints by properly considering conditions for key components. Next, we modify a useful tool in probability theory called _Doob's h-transform_, which plays an essential role in the construction of our equivariant diffusion bridge for preserving coupling of geometric states:

**Proposition 3.2**.: _Let \(p_{}(z^{},t^{}|z,t)\) be the transition density of the SDE in Proposition 3.1. Let \(h_{}(,):[0,T]_{>0}\) be a smooth function satisfying: (1) \(h_{}(,t)\) is \((3)\)-invariant; (2) \(h_{}(z,t)= p_{}(z^{},t^{}|z,t)h_{}(z^{},t^{})z^{}\). Then we can derive the following \(h_{}\)-transformed SDE on geometric states:_

\[^{t}=[_{}(^{t},t)+ ^{2}(t)_{^{t}} h_{}(^{t},t) ]t+(t)^{t},\] (3)

_with \((3)\)-equivariant transition density \(p_{}^{h}(z^{},t^{}|z,t)\) equals to \(p_{}(z^{},t^{}|z,t)}(z^{},t^ {})}{h_{}(z,t)}\)._

  
**Methods** & **Symmetry Constraints** & **Coupling Preservation** & **Trajectory guidance** \\  Direct Prediction  & ✓ & ✓ & ✗ \\  MLFFs  & ✓ & ✗ & ✓ \\  Geometric Diffusion Model  & ✓ & ✗ & ✗ \\ 
**Geometric Diffusion Bridge (ours)** & ✓ & ✓ & ✓ \\  

Table 1: Comparisons of different candidates for bridging geometric statesProposition 3.2 provides an equivariant version of Doob's \(h\)-transform, which can be used to guide a free SDE on geometric states to hit an event almost surely. For example, if we set \(h_{}(,t)=p_{}(z,T|,t),z\), i.e., the transition density of the original SDE evaluated at \(^{T}=z\), then the \(h_{}\)-transformed SDE in Eqn. (3) arrives at the specific geometric state \(z\) almost surely at the final time (see Proposition B.7 in the appendix for more details). Therefore, if we derive a proper \(h_{}(,)\) function under the symmetry constraints, our target process \((^{t})_{t[0,T]}\) can be constructed:

**Theorem 3.3** (Equivariant Diffusion Bridge).: _Let \(^{t}=_{}(^{t},t)t+(t)^{t}\) be an SDE on geometric states with transition density \(p_{}(z^{},t^{}|z,t),z,z^{}\) satisfying the conditions in Proposition 3.1. Let \(h_{}(z,t;z_{0})= p_{}(z^{},T|z,t)}(z^{}|z_{0})}{p_{}(z^{},T|z_{0},0)}z^{}\). By using Proposition 3.2, we can derive the following \(h_{}\)-transformed SDE:_

\[^{t}=[_{}(^{t},t)+ ^{2}(t)_{q_{}(^{T},T|^{t},t; ^{0},0)}[_{^{t}} p_{}(^{T}, T|^{t},t)|^{0},^{t}]]t+(t) ^{t},\] (4)

_which corresponds to a process \((^{t})_{t[0,T]},^{0} q_{}(R^{t_{0}})\) satisfying the following properties:_

* _let_ \(q(,):_{ 0}\) _denote the joint distribution induced by_ \((^{t})_{t[0,T]}\)_, then_ \(q(^{0},^{T})\) _equals to_ \(q_{}(R^{t_{0}},R^{t_{1}})\)_;_
* _its transition density_ \(q_{}(^{t^{}},t^{}|^{t},t;^{0},0)\)_=_\(q_{}(^{}(g)[^{t^{}}],t^{}| ^{}(g)[^{t}],t;^{}(g)[^{0}], 0)\)_,_ \( 0\)_\(\)_\(t\),_\(t^{}\)\(\)_\(T\),_\(g\)_\(\)_SE(3),_\(^{0}\)\(\)_\(q_{}(R^{t_{0}})\)_._

_We call the tailored diffusion process \((^{t})_{t[0,T]}\) an equivariant diffusion bridge._

According to Theorem 3.3, given an initial geometric state \(R^{t_{0}}\), we can predict target geometric states \(R^{t_{1}}\) by simulating the equivariant diffusion bridge \((^{t})_{t[0,T]}\) from \(^{0}=R^{t_{0}}\), which arrives at \(^{T} q_{}(R^{t_{1}}|R^{t_{0}})\). However, the score \(_{q_{}(^{T},T|^{t},t;^{0}, 0)}[_{^{t}} p_{}(^{T},T|^{ t},t)|^{0},^{t}]\) in Eqn. (4) is not tractable in general. Inspired by the score matching objective in diffusion models , we use a parameterized model \(_{}(^{t},t;^{0})\) to estimate the score by using the following training objective:

\[()=_{(z_{0},z_{1}) q_{}(R^{t_{0}},R^ {t_{1}}),^{t} q_{}(^{t},t|z_{1},T;z_{0},0) }(t)\|_{}(^{t},t;z_{0})-_{^{t }} p_{}(z_{1},T|^{t},t)\|^{2},\] (5)

where \(t(0,T)\) (the uniform distribution on \([0,T]\)), and \(():[0,T]_{ 0}\) is a positive weighting function. Theoretically, we prove that the minimizer of Eqn. (5) approximates the ground-truth score (see Appendix B.5 for more details). Moreover, this objective is tractable because the transition density \(p_{}\) and \(q_{}\) can be designed to have simple and explicit forms such as Gaussian, which we will elaborate on in Sec. 3.3.

### Chain of Equivariant Diffusion Bridges for Leveraging Trajectory Guidance

In this subsection, we elaborate on how to leverage trajectories of geometric states as a fine-grained guidance in our framework. Let \((^{i})_{i[N]}\) denote a trajectory of \(N+1\) geometric states and \(q_{}(^{0},...,^{N})\) denote the joint probability density function of geometric states in a trajectory. In practice, the markov property of trajectories typically holds [109; 78]. Under this assumption, \(q_{}(^{0},...,^{N})\) can be equivalently reformulated into \(q^{0}_{}(^{0})_{i=1}^{N}q^{i}_{}( ^{i}|^{i-1})\) by the chain rule of probability. If \(q^{i}_{}(^{i}|^{i-1})\) can be well modeled, we can capture the distribution of trajectories of geometric states completely.

According to Theorem 3.3, given \(^{0} q^{0}_{}(^{0})\), an equivariant diffusion bridge \((^{t})_{t[0,T]}\) can be constructed to model the joint distribution \(q_{}(^{0},^{1})\) and hence \(q^{1}_{}(^{1}|^{0})\) is preserved. Therefore, if we construct a series of interconnected equivariant diffusion bridges, the distribution of trajectories can be modeled:

**Theorem 3.4** (Chain of Equivariant Diffusion Bridges).: _Let \(\{(^{t}_{i})_{t[0,T]}\}_{i[N-1]}\) denote a series of \(N\) equivaraint diffusion bridges defined in Theorem 3.3. For the \(i\)-th bridge \((^{t}_{i})_{t[0,T]}\), if we set (1) \(h^{i}_{}(z,t;z_{0})= p_{}(z^{},T|z,t)_{}(z^{}|z_{0})}{p_{}(z^{},T|z_{0},0 )}z^{}\); (2) \(^{0}_{0} q^{0}_{}(^{0}),^{0}_{i}= ^{T}_{i-1}, 0<i<N\), then the joint distribution \(q_{}(^{0}_{0},^{T}_{1},,^{T}_{N-1})\) induced by \(\{(^{t}_{i})_{t[0,T]}\}_{i[N-1]}\) equals to \(q_{}(^{0},...,^{N})\). We call this process a chain of equivariant diffusion bridges._In this way, a chain of equivariant diffusion bridge can be used to model prior trajectory data, and simulating this chain not only bridges initial and target geometric states but also yields intermediate evolving states. Similarly, we can also use a parameterized model to estimate the scores of bridges in this chain. Instead of having only one objective in all time steps, we now have \(N\) bridges in total, which categorize the time span into \(N\) groups with different time-dependent objectives. Therefore, by properly specifying time steps and initial conditions, the objective in Eqn. (5) can be seamlessly extended (see Appendix B.7 for more details on its provable guarantee):

\[^{}()=_{(z_{0},,z_{N}) q_{}(^{0},,^{N}),t,^{}_{i}}(t) \|_{}(^{t^{}}_{i},t;z_{i})-_{^ {}_{i}} p^{i}_{}(z_{i+1},T|^{t^{}}_{i},t ^{})\|^{2},\] (6)

where \(t(0,N T),i=,t^{}=t-i T,^{t^{}}_{i} q^{i}_{}(^{t^{}}_{i },t^{}|z_{i+1},T;z_{i},0)\).

Lastly, we provide the following theoretical result, which further characterizes our framework's expressiveness to completely model the underlying dynamics that induce the trajectory distributions:

**Theorem 3.5**.: _Assume \((^{i})_{i[N]}\) is sampled by simulating a prior SDE on geometric states \(}^{t}=- H^{*}_{}(}^{t})t+}^{t}\). Let \(^{*}_{}\) denote the path measure of this prior SDE when \(t[iT,(i+1)T]\). Building upon \((^{i})_{i[N]}\), let \(\{^{i}_{}\}_{i[N-1]}\) denote the path measure of our chain of equivariant diffusion bridges. Under mild assumptions, we have \(_{N}_{i}(^{*}_{i}\|^{i}_{ })=0\)._

It is noteworthy that the assumption of the prior SDE existence holds in various real-world applications. For example, in geometry optimization, we can formulate the iterative updating process of a molecular system as \(^{t}=-_{^{t}}V(^{t}) t+^{t}\), where \(V(^{t})\) denotes the potential energy at \(^{t}\) and \(,\) are step sizes . From Theorem 3.5, such prior SDE serves as the underlying law governing the evolution dynamic, and our chain of equivariant diffusion bridges constructed from empirical trajectory data can well approximate it, showing the completeness of our framework.

### Practical Implementation

In this subsection, we elaborate on how to practically implement our framework. According to Eqn. (5), it is necessary to carefully design (1) tractable distribution \(q_{}(^{t},t|z_{1},T;z_{0},0)\) for sampling \(^{t}\); (2) closed-form matching objective \(_{^{t}} p_{}(z_{1},T|^{t},t)\).

Matching objective.Inspired by diffusion models that use Gaussian transition kernels for tractable computation, we design the SDE on geometric states in Proposition 3.1 to be:

\[^{t}=^{t}, p_{}(z^{},t^{}|z,t)=(z_{0},^{2}(t^{}-t) )\] (7)

The explicit form of the objective can be directly calculated, i.e., \(_{^{t}} p_{}(z_{1},T|^{t},t)=-^{t}}{^{2}(T-t)}\).

Sampling distribution.According to Theorem 3.3, the transition density \(q_{}(^{t},t|z_{1},T;z_{0},0)\) can be calculated by using the Doob's \(h\)-transform in Proposition 3.2, i.e., \(q_{}(^{t},t|z_{1},T;z_{0},0)=p_{}(^ {t},t|z_{1},T)}(^{t},t;z_{0})}{h_{}(z _{1},T;z_{0})}\). Moreover, \(h_{}\) is determined by \(q_{}\) and \(p_{}\), which is already specified in Eqn. (7). Therefore, we can also calculate \(q_{}(^{t},t|z_{1},T;z_{0},0)=(z_{1} +z_{0},^{2}})\).

Symmetry constraints.In proposition 3.1, we have several conditions that should be satisfied to meet the symmetry constraints. Firstly, since a parameterized model \(_{}(^{t},t;^{0})\) is used to estimate the score of our equivariant diffusion bridge, it should be \((3)\)-equivariant and \((3)\)-invariant. Besides, we follow [50; 115] to consider CoM-free systems: given \(R=\{_{1},...,_{n}\}\), we define \(}=_{i=1}^{n}_{i}\) and the CoM-free version of \(R=\{_{1}-},...,_{n}-}\}\). To sample from \((z_{0},^{2})\) with \(z_{0}\) consisting of \(n\) objects, we (1) sample \(=\{_{i}\}_{i=1}^{n}\) by i.i.d. drawing \(_{i}(,_{3})\); (2) calculate the CoM-free \(^{}\) of \(\); (3) obtain \(z_{0}+^{}\).

Trajectory guidance.According to Eqn. (6), both \(p^{i}_{}\) and \(q^{i}_{}\) for all \(i[N-1]\) should be determined. Similarly, we set \(p^{i}_{}(z_{i+1},T|^{t^{}},t^{}) (^{t^{}},^{2}_{i}(T-t^{}))\), which further induces \(q^{i}_{}(^{t^{}},t^{}|z_{i+1},T;z_{i},0)= (}{T}z_{i+1}+}{T}z_{i},^{2} _{i}(T-t^{})}{T^{2}})\).

Combining all the above design choices, we have the following algorithms for training our Geometric Diffusion Bridge (Alg. 3) and leveraging trajectory guidance if available (Alg. 4). After the model is well trained, we leverage ODE numerical solvers  to simulate the bridge process by using its equivalent probability flow ODE . In this way, we can effectively and deterministically predict future geometric states of interest from initial states in an efficient iterative process. Lastly, it is also noteworthy that our framework is general to be implemented by using other advanced design strategies [99; 47; 48], which we leave as future work.

```
1:repeat
2:\((z_{0},z_{1}) q_{}(R^{t_{0}},R^{t_{1}})\)
3:\(t[0,T]\)
4:\((,)\)
5:\(^{t}=z_{1}+z_{0}+}{T} \)
6: Take gradient descent step on \(_{}(t)\|-^{t}}{^{2}_{t}(T- t)}-_{}(^{t},t;z_{0})\|^{2}\)
7:until converged ```

**Algorithm 1** Training

## 4 Experiments

In this section, we empirically study the effectiveness of our Geometric Diffusion Bridge on crucial real-world challenges requiring bridging geometric states. In particular, we carefully design several experiments covering different types of data, scales and scenarios, as shown in Table 2. Due to space limits, we present more details in Appendix D.

### Equilibrium State Prediction

Task.Equilibrium states typically represent local minima on the Born-Oppenheimer potential energy surface of a molecular system , which correspond to its most stable geometric state and play an essential role in determining its properties in various aspects [4; 21]. In this task, our goal is to accurately predict the equilibrium state from the initial geometric state of a molecular system.

Dataset.Two popular datasets are used: (1) QM9  is a medium-scale dataset that has been widely used for molecular modeling, consisting of 130,000 organic molecules. In convention, 110k, 10k, and 11k molecules are used for train/valid/test sets respectively; (2) Molecule3D  is a large-scale dataset curated from the PubChemQC project [67; 71], consisting of 3,899,647 molecules in total and its train/valid/test splitting ratio is \(6:2:2\). In particular, both random and scaffold splitting methods are adopted to thoroughly evaluate the in-distribution and out-of-distribution performance. For each molecule, an initial geometric state is generated by using fast and coarse force field [73; 52] and geometry optimization is conducted to obtain DFT-calculated equilibrium geometric structure.

Setting.In this task, we parameterize \(_{}(^{t},t;^{0})\) by extending a Graph-Transformer based equivariant network [92; 63] to encode both time steps and initial geometric states as conditions. For inference, we use 10 time steps with the Euler solver . Following , we choose several strong baselines for a comprehensive comparison, and use three metrics for measuring the error between predicted target states and ground-truth states: C-RMSD, D-MAE and D-RMSE. The detailed descriptions of the baselines, evaluation metrics and training settings are presented in Appendix D.1.

Results.Results on QM9 and Molecule3D are shown in Table 3 and 4 respectively. It can be easily seen that our GDB framework consistently surpasses all baselines by a significantly large margin on

  
**Dataset** & **Task Description** & **Data Type** & **Trajectory data** & **Training set size** \\  QM9  & Equilibrium State Prediction & Simple molecule & ✗ & 110,000 \\  Molecule3D  & Equilibrium State Prediction & Simple molecule & ✗ & 2,339,788 \\  OC22, IS2RS  & Structure Relaxation & Adsorbate-Catalyst complex & ✓ & 45,890 \\   

Table 2: Summary of experimental setup.

QM9, e.g., 60.5%/59.7% relative C-RMSD reduction on valid/test sets respectively, establishing a new state-of-the-art performance. Similar trends also can be observed in Molecule3D, i.e., 12.6%/13.2% relative C-RMSD reduction for valid/test sets of the random split and 12.7%/13.0% reduction for the scaffold split, largely outperforming the best baseline. These significant error reduction results show the superiority of our GDB framework for bridging geometric states, and its generality on both medium and large-scale challenges. Moreover, our framework performs consistently across valid and tests of both random and scaffold splits, further verifying its robustness in challenging scenarios.

### Structure Relaxation

Task.Catalyst discovery is crucial for various applications. Adsorbate candidates are placed on catalyst surfaces and evolve through structure relaxation to adsorption states, in which the adsorption structures can be determined for measuring catalyst activity and selectivity. Our goal is thus to accurately predict adsorption states from initial states of adsorbate-catalyst complexes.

Dataset.We adopt Open Catalyst 2022 (OC22) dataset , which has great significance for the development of Oxygen Evolution Reaction (OER) catalysts. Each data is in the form of the adsorbate-catalyst complex. Both initial and adsorption states with trajectories connecting them are provided. The training set consists of 45,890 catalyst-adsorbate complexes. To better evaluate the model's performance, the validation and test sets consider the in-distribution (ID) and out-of-distribution (OOD) settings which use unseen catalysts, containing approximately 2,624 and 2,780 complexes respectively.

Setting.Following , we use the Average Distance within Threshold (ADwT) as the evaluation metric, which reflects the percentage of structures with an atom position MAE below thresholds. We parameterize \(_{}(^{t},t;^{0})\) by using GemNet-OC , which also serves as a verification that

    &  &  \\   & D-MAE\(\) & D-RMSE\(\) & C-RMSD\(\) & D-MAE\(\) & D-RMSE\(\) & C-RMSD\(\) \\  (a) Random Split & & & & & & \\  RDKit DG & 0.581 & 0.930 & 1.054 & 0.582 & 0.932 & 1.055 \\ RDKit ETKDG & 0.575 & 0.941 & 0.998 & 0.576 & 0.942 & 0.999 \\ DeepGCN-DAGNN  & 0.509 & 0.849 & * & 0.571 & 0.961 & * \\ GINE  & 0.590 & 1.014 & 1.116 & 0.592 & 1.018 & 1.116 \\ GATv2  & 0.563 & 0.983 & 1.082 & 0.564 & 0.986 & 1.083 \\ GPS  & 0.528 & 0.909 & 1.036 & 0.529 & 0.911 & 1.038 \\ GTMGC  & 0.432 & 0.719 & 0.712 & 0.433 & 0.721 & 0.713 \\ 
**GDB (ours)** & **0.374** & **0.631** & **0.622** & **0.376** & **0.626** & **0.619** \\  (b) Scaffold Split & & & & & & \\  RDKit DG & 0.542 & 0.872 & 1.001 & 0.524 & 0.857 & 0.973 \\ RDKit ETKDG & 0.531 & 0.874 & 0.928 & 0.511 & 0.859 & 0.898 \\ DeepGCN-DAGNN  & 0.617 & 0.930 & * & 0.763 & 1.176 & * \\ GINE  & 0.883 & 1.517 & 1.407 & 1.400 & 2.224 & 1.960 \\ GATv2  & 0.778 & 1.385 & 1.254 & 1.238 & 2.069 & 1.752 \\ GPS  & 0.538 & 0.885 & 1.031 & 0.657 & 1.091 & 1.136 \\ GTMGC  & 0.406 & 0.675 & 0.678 & 0.400 & 0.679 & 0.693 \\ 
**GDB (ours)** & **0.335** & **0.587** & **0.592** & **0.341** & **0.608** & **0.603** \\   

Table 4: Results on the Molecule3D dataset (Å). We report the official results of baselines from 

    &  &  \\   & D-MAE\(\) & D-RMSE\(\) & C-RMSD\(\) & D-MAE\(\) & D-RMSE\(\) & C-RMSD\(\) \\  RDKit DG & 0.358 & 0.616 & 0.722 & 0.358 & 0.615 & 0.722 \\ RDKit ETKDG & 0.355 & 0.621 & 0.691 & 0.355 & 0.621 & 0.689 \\ GINE  & 0.357 & 0.673 & 0.685 & 0.357 & 0.669 & 0.693 \\ GATv2  & 0.339 & 0.663 & 0.661 & 0.339 & 0.659 & 0.666 \\ GPS  & 0.326 & 0.644 & 0.662 & 0.326 & 0.640 & 0.666 \\ GTMGC  & 0.262 & 0.468 & 0.362 & 0.264 & 0.470 & 0.367 \\ 
**GDB (ours)** & **0.092** & **0.218** & **0.143** & **0.096** & **0.223** & **0.148** \\   

Table 3: Results on the QM9 dataset (Å). We report the official results of baselines from our framework is compatible with different backbone models. For inference, we also use 10 time steps with the Euler solver. Following , we choose strong MLFF baselines trained on force field data for a challenging comparison. The detailed descriptions of baselines and settings are presented in Appendix D.2.

Results.In Table 5, our GDB significantly outperforms the best baseline, e.g., 3.3%/3.6%/3.4% relative improvement on the ADwT metric of ID, OOD and Avg respectively. It is noteworthy that the best baseline is the GemNet-OC force field trained on both OC20 and OC22 data, which is 10 times more than OC22 data only. Nevertheless, our framework still achieves better performance on predicting the adsorption geometric states. Moreover, our framework without using any trajectory data still can achieve better performance compared to the best baseline, e.g., 58.54 v.s. 57.42 Avg[%]. All the results on this challenging task further demonstrate the superiority and completeness of our framework.

Ablation study.Furthermore, we conduct ablation studies to examine key designs of our framework in Table 5. Firstly, we can see that using trajectory guidance indeed improves the performance of our framework, e.g., 1.4% relative improvement on Avg ADwT. Moreover, we also investigate the impact of \(^{0}\) condition in \(_{}(^{t},t;^{0})\), which plays an essential role in preserving the joint distribution of geometric states. Without this condition, we can see a significant drop, e.g., 6.5%/10.3% relative ADwT drop on Avg/OOD respectively. Overall, these ablation studies serve as strong supports on the necessity of developing a unified framework that can precisely bridge geometric states by preserving their joint distributions and effectively leverage trajectory data as guidance for enhanced performance.

## 5 Related Works

Direct Prediction.One line of approach for bridging geometric states is direct prediction, i.e., training a model to directly predict target geometric states given initial states as input. Models that carefully respect symmetry constraints such as the equivariance to 3D rotations and translations are typically used, which are called Geometric Equivariant Networks [11; 36; 120; 27]. Different techniques have been explored to encode such priors, which mainly include vector operations such as scalar and vector product [35; 87; 89; 41; 103; 14], e.g., the scalar-vector product used in EGNN , and tensor product based operations [104; 31; 8; 57; 64]. Despite its simplicity and efficiency, direct prediction requires encoding the iterative evolution of geometric states into a single-step prediction model, which lacks the ability to capture the underlying dynamics and cannot leverage trajectories of geometric states.

Machine Learning Force Field.Another line of approach is called machine learning force field (MLFF) [106; 5; 6; 70; 75; 58], which are trained to predict intermediate labels, such as the potential

   Model & ADwT [\%] \(\) (ID) & ADwT [\%] \(\) (OOD) & Avg [\%] \(\) \\  OC20+OC22 & & & \\  SpinConv  & 55.79 & 47.31 & 51.55 \\ GemNet-OC  & 60.99 & 53.85 & 57.42 \\  OC20\(\)OC22 & & & \\  SpinConv  & 56.69 & 45.78 & 51.23 \\ GemNet-OC  & 58.03 & 48.33 & 53.18 \\ GemNet-OC-Large  & 59.69 & 51.66 & 55.67 \\  OC22-only & & & \\  IS baseline & 44.77 & 42.59 & 43.68 \\ SpinConv  & 54.53 & 40.45 & 47.49 \\ GemNet-dT  & 59.68 & 51.25 & 55.46 \\ GemNet-OC  & 60.69 & 52.90 & 56.79 \\ 
**GDB (ours)** & **63.01** & **55.78** & **59.39** \\ \(-\) trajectory guidance & 62.14 & 54.94 & 58.54 \\ \(-\)\(^{0}\) condition & 60.17 & 49.26 & 54.71 \\   

Table 5: Results on the OC22 IS2RS Validation set. “OC20+OC22” denotes using both OC20  and OC22 data; “OC20\(\)OC22” means pre-training on OC20 data then fine-tuning on OC22 data; “OC22-only” means only using OC22 data. We report the official results of baselines from energy or force of the (local) current geometric state instead. After training, MLFFs can be used to simulate the trajectory of geometric states over time based on underlying equations. Using Geometric Equivariant Networks as the backbone, MLFFs typically satisfy the symmetry constraints. Besides, trajectory data with additional energy or force labels can directly be used for training MLFFs. However, this paradigm highly depends on the existence and quality of intermediate labels since small local errors in energy or force prediction can accumulate along the simulation process [7; 106; 30]. Moreover, there exists no guarantee that MLFFs can completely model joint state distributions, which is another limitation for bridging geometric states.

Geometric Diffusion Models.In recent years, diffusion models [37; 99] have emerged with state-of-the-art generative modeling performance across various domains [85; 108; 51; 56]. In geometric domain, diffusion models are typically used for molecule conformation generation [115; 38; 114] and protein design [108; 117]. By properly design the noising process and model architectures, symmetry constraints on the transition kernel and prior distribution can be satisfied, which guarantees the generated data is sampled from roto-translational invariant distributions [115; 38]. In addition to the score-based formulation, recent advances further extend new techniques such as flow matching [59; 61; 1] to satisfy symmetry constraints for these generation tasks [49; 100]. Nevertheless, there exists no guarantee that these approaches can model the joint distribution of geometric states [61; 96]. And how to leverage trajectory data as guidance for bridging geometric states is also challenging.

Other techniques.MoreRed  trains a diffusion model on equilibrium molecule conformations with a time step predictor, and directly use it for bridging any conformations to their equilibrium states. GTMGC  instead develop a Graph Transformer to directly predict equilibrium conformations from their 2D graph forms. Both of them are limited to the equilibrium conformation prediction task, cannot preserve the joint state distribution and leverage trajectory data. EGNO  is a concurrent work that develops a neural operator based approach to model dynamics of trajectories. By carefully designing temporal convolution in fourier spaces, EGNO can learn from trajectory data. However, this tailored approach cannot be directly used without trajectory guidance. To preserve joint data distributions, [22; 121] coincide with us to leverage Doob's \(h\)-transform to repurposing standard diffusion processes, but they do not respect symmetry constraints and cannot leverage trajectories. There also exist recent works that study the diffusion bridge framework [76; 93] and apply it to various domains such as images and graphs [110; 62; 42]. Compared to all above approaches, our GDB framework stands out as a unique and ideal solution that can precisely bridge geometric states and effectively leverage trajectory data (if available) in a unified manner.

## 6 Conclusion

In this work, we introduce Geometric Diffusion Bridge (GDB), a general framework for bridging geometric states through generative modeling. We leverage a modified version of Doob's \(h\)-transform to construct an equivariant diffusion bridge for bridging initial and target geometric states. Trajectory data can further be seamlessly leveraged as guidance by using a chain of equivariant diffusion bridges, allowing complete modeling of trajectory data. Mathematically, we conduct a comprehensive theoretical analysis showing our framework's ability to preserve joint distributions of geometric states and capability to completely model the evolution dynamics. Empirical comparisons on different settings show that our GDB significantly surpasses existing state-of-the-art approaches and ablation studies further underscore the necessity of several key designs in our framework. In the future, it is worth exploring better implementation strategies of our framework for enhanced performance, and applying our GDB to other critical challenges involving bringing geometric states.

## Broader Impacts and Limitations

This work newly proposes a general framework to bridge geometric states, which has great significance in various scientific domains. Our experimental results have also demonstrated considerable positive potential for various applications, such as catalyst discovery and molecule optimization, which can significantly contribute to the advancement of renewable energy processes and chemistry discovery. However, it is essential to acknowledge the potential negative impacts including the development of toxic drugs and materials. Thus, stringent measures should be implemented to mitigate these risks.

There also exist some limitations to our work. For the sake of generality, we do not experiment with advanced implementation strategies of training objectives and sampling algorithms, which leave room for further improvement. Besides, the employment of Transformer-based architectures may also limit the efficiency of our framework. This has also become a common issue in transformer-based diffusion models, which we have earmarked for future research.