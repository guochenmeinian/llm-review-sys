# Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection

Yu Bai

Salesforce Research

yu.bai@salesforce.com

&Fan Chen

Massachusetts Institute of Technology

fanchen@mit.edu

&Huan Wang

Salesforce Research

huan.wang@salesforce.com

&Caiming Xiong

Salesforce Research

cxiong@salesforce.com

&Song Mei

UC Berkeley

songmei@berkeley.edu

Equal technical and directional contributions.

Code is available at https://github.com/allenbai01/transformers-as-statisticians.

###### Abstract

Neural sequence models based on the transformer architecture have demonstrated remarkable _in-context learning_ (ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences.

Building on these "base" ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving _in-context algorithm selection_, akin to what a statistician can do in real life--A _single_ transformer can adaptively select different base ICL algorithms--or even perform qualitatively different tasks--on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a transformer that can perform nearly Bayes-optimal ICL on a challenging task--noisy linear models with mixed noise levels. Experimentally, we demonstrate the strong in-context algorithm selection capabilities of standard transformer architectures.

## 1 Introduction

Large neural sequence models have demonstrated remarkable _in-context learning_ (ICL) capabilities , where models can make accurate predictions on new tasks when prompted with training examples from the same task, in a zero-shot fashion without any parameter update to the model. A prevalent example is large language models based on the transformer architecture , which can perform a diverse range of tasks in context when trained on enormous text . Recent modelsin this paradigm such as GPT-4 achieve surprisingly impressive ICL performance that makes them akin to a general-purpose agent in many aspects [65; 14]. Such strong capabilities call for better understandings, which a recent line of work tackles from various aspects [49; 94; 28; 72; 15; 57; 64].

Recent pioneering work of Garg et al.  proposes an interpretable and theoretically amenable setting for understanding ICL in transformers. They perform ICL experiments where input tokens are real-valued (input, label) pairs generated from standard statistical models such as linear models (and the sparse version), neural networks, and decision trees. Garg et al.  find that transformers can learn to perform ICL with prediction power (and fitted functions) matching standard machine learning algorithms for these settings, such as least squares for linear models, and Lasso for sparse linear models. Subsequent work further studies the internal mechanisms [2; 86; 18], expressive power [2; 32], and generalization  of transformers in this setting. However, these works only showcase simple mechanisms such as regularized regression [31; 2; 47] or gradient descent [2; 86; 18], which are arguably only a small subset of what transformers are capable of in practice; or expressing universal function classes not specific to ICL [89; 32]. This motivates the following question:

_How do transformers learn in context beyond implementing simple algorithms?_

This paper makes steps on this question by making two main contributions: (1) We **unveil a general mechanism--_in-context algorithm selection_**--by which a _single_ transformer can adaptively _select different "base" ICL algorithms_ to use on _different ICL instances_, without any explicit prompting of the right algorithm to use in the input sequence. For example, a transformer may choose to perform ridge regression with regularization \(_{1}\) on ICL instance 1, and \(_{2}\) on ICL instance 2 (Figure 2); or perform regression on ICL instance 1 and classification on ICL instance 2 (Figure 5). This adaptivity allows transformers to achieve much stronger ICL performance than the base ICL algorithms. We both prove this in theory, and demonstrate this phenomenon empirically on standard transformer architectures. (2) Along the way, equally importantly, we present a comprehensive theory for ICL in transformers by establishing end-to-end quantitative guarantees for the **expressive power, in-context prediction performance, and sample complexity of pretraining**. These results add upon the recent line of work on the statistical learning theory of transformers [97; 89; 27; 39], and lay out a foundation for the intriguing special case where the _learning targets are themselves ICL algorithms_.

A detailed summary of our contributions is as follows.

* We prove that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, convex risk minimization for learning generalized linear models (such as logistic regression), and gradient descent for two-layer neural networks (Section 3). Our constructions admit mild bounds on the number of layers, heads, and weight norms, and achieve near-optimal prediction power on many in-context data distributions.
* Technically, the above transformer constructions build on a new efficient implementation of in-context gradient descent (Appendix D), which could be broaderly applicable. For a broad class of smooth convex empirical risks over the in-context training data, we construct an \((L+1)\)-layer transformer that approximates \(L\) steps of gradient descent. Notably, the approximation error accumulates only _linearly_ in \(L\), utilizing a stability-like property of smooth convex optimization.
* We prove that transformers can perform in-context algorithm selection (Section 4). We construct two algorithm selection mechanisms: Post-ICL validation (Section 4.1), and Pre-ICL testing

Figure 1: **Illustration of in-context algorithm selection, and two mechanisms constructed in our theory.**_Left, middle-left_: A single transformer can perform ridge regression with different \(\)â€™s on input sequences with different observation noise; we prove this by the **post-ICL validation** mechanism (Section 4.1). _Middle-right, right_: A single transformer can perform linear regression on regression data and logistic regression on classification data; we prove this via the **pre-ICL testing** mechanism (Section 4.2).

(Section 4.2). For both mechanisms, we provide general constructions as well as concrete examples. Figure 1 provides a pictorial illustration of the two mechanisms.
* As a concrete application, using the post-ICL validation mechanism, we construct a transformer that can perform nearly Bayes-optimal ICL on noisy linear models with _mixed_ noise levels (Section 4.1.1), a more complex task than those considered in existing work.
* We provide the first line of results for _pretraining_ transformers to perform the various ICL tasks above, from polynomially many training sequences (Section 5 & Appendix K).
* Experimentally, we find that learned transformers indeed exhibit strong in-context algorithm selection capabilities in the settings considered in our theory (Section 6). For example, Figure 2 shows that a _single_ transformer can approach the individual Bayes risks (the optimal risk among all possible algorithms) simultaneously on two noisy linear models with different noise levels.

Transformers as statisticiansWe humbly remark that the typical toolkit of a statistician contains much more beyond those covered in this work, including and not limited to inference, uncertainty quantification, and theoretical analysis. This work merely aims to show the algorithm selection capability of transformers, akin to what a statistician _can_ do.

Related workOur work is intimately related to the lines of work on in-context learning, theoretical understandings of transformers, as well as other formulations for learning-to-learn such as meta-learning. Due to limited space, we discuss these related work in Appendix A.

## 2 Preliminaries

We consider a sequence of \(N\) input vectors \(\{_{i}\}_{i=1}^{N}^{D}\), written compactly as an input matrix \(=[_{1},,_{N}]^{D N}\), where each \(_{i}\) is a column of \(\) (also a _token_). Throughout this paper, we let \((t):=(t)=\{t,0\}\) denote the standard relu activation.

### Transformers

We consider transformer architectures that process any input sequence \(^{D N}\) by applying (encoder-mode2) attention layers and MLP layers formally defined as follows.

**Definition 1** (Attention layer).: _A (self-)attention layer with \(M\) heads is denoted as \(_{}()\) with parameters \(=\{(_{m},_{m},_{m}) \}_{m[M]}^{D D}\). On any input sequence \(^{D N}\),_

\[}=_{}():= +_{m=1}^{M}(_{m}) (_{m})^{}(_{m}) ^{D N},\] (1)

_where \(:\) is the ReLU function. In vector form,_

\[}_{i}=[_{}()]_{i}=_{i}+_{m=1}^{M}_{j=1}^{N}( (_{m}_{i},_{m}_{j}))_ {m}_{j}.\]

Figure 2: In-context algorithm selection on two separate noisy linear regression tasks with noise \((_{1},_{2})=(0.1,0.5)\). _(a,b)_**A single transformer**TF_alg_select **simultaneously approaches the performance of the two individual Bayes predictors** ridge_lam_1 on task 1 and ridge_lam_2 on task 2. _(c)_ At token 20 (using example \(\{0,,19\}\) for training), TF_alg_select approaches the Bayes error on two tasks simultaneously, and **outperforms ridge regression with any fixed \(\)**. _(a,b,c)_ Note that transformers pretrained on a single task (TF_noise_1, TF_noise_2) perform near-optimally on that task but suboptimally on the other task. More details about the setup and training method can be found in Appendix M.2.

Above, (1) uses a normalized ReLU3 activation \(t(t)/N\) in place of the standard softmax activation; we remark this activation is also found to work well empirically in recent studies [78; 93].

**Definition 2** (MLP layer).: _A (token-wise) MLP layer with hidden dimension \(D^{}\) is denoted as \(_{}()\) with parameters \(=(_{1},_{2})^{D^{}  D}^{D D^{}}\). On any input sequence \(^{D N}\),_

\[}=_{}():= +_{2}(_{1}),\]

_where \(:\) is the ReLU function. In vector form, we have \(}_{i}=_{i}+_{2}(_{1} _{i})\)._

We consider a transformer architecture with \(L 1\) transformer layers, each consisting of a self-attention layer followed by an MLP layer.

**Definition 3** (Transformer).: _An L-layer transformer, denoted as \(_{}()\), is a composition of L self-attention layers each followed by an MLP layer: \(^{(L)}=_{}(^{(0)})\), where \(^{(0)}^{D N}\) is the input sequence, and_

\[^{()}=_{^{()}_{}}_{^{()}_{}}( ^{(-1)}),\ \ \{1,,L\}.\]

_Above, the parameter \(=(^{(1:L)}_{},^{(1:L)}_{})\) consists of the attention layers \(^{()}_{}=\{(^{()}_{m}, ^{()}_{m},^{()}_{m})\}_{m[M^{()}]} ^{D D}\) and the MLP layers \(^{()}_{}=(^{()}_{1}, ^{()}_{2})^{D^{()} D}^{ D D^{()}}\). We will frequently consider "attention-only" transformers with \(^{()}_{1},^{()}_{2}=\), which we denote as \(^{}_{}()\) for shorthand, with \(=^{(1:L)}:=^{(1:L)}_ {}\)._

We additionally define the following norm of a transformer \(_{}\):

\[\|\|:=_{[L]}_{m[M]}\| ^{()}_{m}\|_{},\|^{()}_{m}\|_{}}+_{m=1}^{M}\|^{()}_{m}\|_{}+\| ^{()}_{1}\|_{}+\|^{()}_{2}\|_{}}.\] (2)

In (2), the choices of the operator norm and max/sums are for convenience only and not essential, as our results (e.g. for pretraining) depend only logarithmically on \(\|\|\).

### In-context learning

In an in-context learning (ICL) instance, the model is given a dataset \(=\{(_{i},y_{i})\}_{i[N]}}}{{}}\) and a new test input \(_{N+1}_{}\) for some data distribution \(\), where \(\{_{i}\}_{i[N]}^{d}\) are the input vectors, \(\{y_{i}\}_{i[N]}\) are the corresponding labels (e.g. real-valued for regression, or \(\{0,1\}\)-valued for binary classification), and \(_{N+1}\) is the test input on which the model is required to make a prediction. Different from standard supervised learning, in ICL, each instance \((,_{N+1})\) is in general drawn from a different distribution \(_{j}\), such as a linear model with a new ground truth coefficient \(_{,j}^{d}\). Our goal is to construct _fixed_ transformer to perform ICL on a large set of \(_{j}\)'s.

We consider using transformers to perform ICL, in which we encode \((,_{N+1})\) into an input sequence \(^{D(N+1)}\). In our theory, we use the following format, where the first two rows contain \((,_{N+1})\) (zero at the location for \(y_{N+1}\)), and the third row contains fixed vectors \(\{_{i}\}_{i[N+1]}\) with ones, zeros, and indicator for being the train token (similar to a positional encoding vector):

\[=_{1}&_{2}&&_{N}& _{N+1}\\ y_{1}&y_{2}&&y_{N}&0\\ _{1}&_{2}&&_{N}&_{N+1} ^{D(N+1)},_{i}:=_{D -(d+3)}\\ 1\\ 1\{i<N+1\}^{D-(d+1)}.\] (3)

We will choose \(D=(d)\), so that the hidden dimension of \(\) is at most a constant multiple of \(d\). We then feed \(\) into a transformer to obtain the output \(}=_{}() ^{D(N+1)}\) with the same shape, and _read out_ the prediction \(_{N+1}\) from the \((d+1,N+1)\)-th entry of \(}=[}_{i}]_{i[N+1]}\) (the entry corresponding to the missing test label): \(_{N+1}=_{}(}):= (}_{N+1})_{d+1}\). The goal is to predict \(_{N+1}\) that is close to \(y_{N+1}_{y|_{N+1}}\) measured by proper losses. We emphasize that we consider predicting only at the last token \(_{N+1}\), which is without much loss of generality.4

Miscellaneous setupsWe assume bounded features and labels throughout the paper (unless otherwise specified, e.g. when \(_{i}\) is Gaussian): \(\|_{i}\|_{2} B_{x}\) and \(|y_{i}| B_{y}\) with probability one. We use the standard notation \(=[_{1}^{};;_{N}^{}]^ {N d}\) and \(=[y_{1};;y_{N}]^{N}\) to denote the matrix of inputs and vector of labels, respectively. To prevent the transformer from blowing up on tail events, in all our results concerning (statistical) in-context prediction powers, we consider a clipped prediction \(_{N+1}=_{}(}):=_{R}(}_{N+1})_{d+1}\), where \(_{R}(t):=_{[-R,R]}(t)\) is the standard clipping operator with (a suitably large) radius \(R 0\) that varies in different problems.

## 3 Basic in-context learning algorithms

We begin by constructing transformers that approximately implement a variety of standard machine learning algorithms in context, with mild size bounds and near-optimal prediction power on many standard in-context data distributions.

### In-context ridge regression and least squares

Consider the standard ridge regression estimator over the in-context training examples \(\) with regularization \( 0\) (reducing to least squares at \(=0\) and \(N d\)):

\[_{}^{}:=_{^{d}} _{i=1}^{N}(,_{i}-y_{i} )^{2}+\|\|_{2}^{2}.\] (ICRidge)

We show that transformers can approximately implement (ICRidge) (proof in Appendix F.1).

**Theorem 4** (Implementing in-context ridge regression).: _For any \( 0\), \(0\) with \(:=\), \(B_{w}>0\), and \(<B_{x}B_{w}/2\), there exists an \(L\)-layer attention-only transformer \(_{}^{0}\) with_

\[L= 2(B_{x}B_{w}/(2))+1,_{[L]}M ^{()} 3,\|\| 4R+8(+ )^{-1}.\] (4)

_(with \(R:=\{B_{x}B_{w},B_{y},1\}\)) such that the following holds. On any input data \((,_{N+1})\) such that the problem (ICRidge) is well-conditioned and has a bounded solution:_

\[_{}(^{}/N)_{}( ^{}/N),\|_{}^{}\|_{2} B_{w}/2,\] (5)

\(_{}^{0}\) _approximately implements (ICRidge): The prediction \(_{N+1}=_{}(_{ }^{0}())\) satisfies_

\[|_{N+1}-_{}^{}, _{N+1}|.\] (6)

Theorem 4 presents the first quantitative construction for end-to-end in-context ridge regression up to arbitrary precision, and improves upon Akyurek et al.  whose construction does not give (or directly imply) an explicit error bound like (6). Further, the bounds on the number of layers and heads in (4) are mild (constant heads and logarithmically many layers).

Near-optimal in-context prediction power for linear problemsCombining Theorem 4 with standard analyses of linear regression yields the following corollaries (proofs in Appendix F.3 & F.4).

**Corollary 5** (Near-optimal linear regression with transformers by approximating least squares).: _For any \(N}(d)\), there exists an \((( N/))\)-layer transformer \(\), such that on any \(\) satisfying standard statistical assumptions for least squares (Assumption A), its ICL prediction \(_{N+1}\) achieves_

\[_{(,_{N+1},y_{N+1})}[(_{N+1}-y_{N+1})^{2}]_{}_{(,y) }(y-,)^{2}+ }(d^{2}/N).\]

Assumption A requires only generic tail properties such as sub-Gaussianity, and _not_ realizability (i.e., \(\) follows a true linear model); \(,\) above denote the covariance condition number and the noise level therein. The \(}(d^{2}/N)\) excess risk is known to be rate-optimal for linear regression , and Corollary 5 achieves this in context with a transformer with only logarithmically many layers.

Next, consider Bayesian linear models where each in-context data distribution \(=_{_{}}^{}\) is drawn from a Gaussian prior \(:_{}(0,_{d}/d)\), and \((,y)_{_{}}^{}\) is sampled as \((,_{d})\), \(y=_{},+(0,^{2})\). It is a standard result that the Bayes estimator of \(y_{N+1}\) given \((,_{N+1})\) is given by ridge regression (ICRidge): \(_{N+1}^{}:=_{}^{ },_{N+1}\) with \(=d^{2}/N\). We show that transformers achieve nearly-Bayes risk for this problem, and we use

\[_{}:=_{_{},(, _{N+1},y_{N+1})_{_{}}^{}} [_{N+1}^{}-y_{N+1}^{2}]\]

to denote the Bayes risk of this problem under prior \(\).

**Corollary 6** (Nearly-Bayes linear regression with transformers by approximating ridge regression).: _Under the Bayesian linear model above with \(N\{d/10,((1/))\}\), there exists a \(L=((1/))\)-layer transformer such that \(_{_{},(,_{N+1},y_{N+1})}/{[ _{N+1}-y_{N+1}^{2}]}_{}+\)._

Generalized linear modelsIn Appendix G, we extend the above results to generalized linear models  and show that transformers can approximate the corresponding convex risk minimization algorithm in context (which includes logistic regression for linear classification as an important special case), and achieve near-optimal excess risk under standard statistical assumptions.

### In-context Lasso

Consider the standard Lasso estimator  which minimizes an \(_{1}\)-regularized linear regression loss \(_{}\) over the in-context training examples \(\):

\[_{}:=_{^{d}}_{}()=_{i=1}^{N}( ,_{i}-y_{i})^{2}+_{N} _{1}.\] (IClasso)

We show that transformers can also approximate in-context Lasso with a mild number of layers, and can perform sparse linear regression in standard sparse linear models (proofs in Appendix H).

**Theorem 7** (Implementing in-context Lasso).: _For any \(_{N} 0\), \(>0\), \(B_{w}>0\), and \(>0\), there exists a \(L\)-layer transformer \(_{}\) with_

\[L= B_{w}^{2}/+1,_{[L]} M^{()} 2,_{[L]}D^{()} 2d, R+(1+_{N})^{ -1}\]

_(where \(R:=\{B_{x}B_{w},B_{y},1\}\)) such that the following holds. On any input data \((,_{N+1})\) such that \(_{}(^{}/N)\) and \(_{}_{2} B_{w}/2,\,_{}(^{(0)})\) approximately implements (IC Lasso), in that it outputs \(_{N+1}=_{N+1},}\) with \(_{}(})-_{}(_{})\)._

**Theorem 8** (Near-optimal sparse linear regression with transformers by approximating Lasso).: _For any \(d,N 1,>0,B_{w}^{*},>0\), there exists a \(}((B_{w}^{*})^{2}/^{2}(1+(d/N)))\)-layer transformer \(\) such that the following holds: For any \(s\) and \(N}(s(d/))\), suppose that \(\) is an \(s\)-sparse linear model: \(_{i}(0,_{d})\), \(y_{i}=_{},_{i}+(0,^{2})\) for any \(_{}_{2} B_{w}^{*}\) and \(_{}_{0} s\), then with probability at least \(1-\) (over the randomness of \(\)), the transformer output \(_{N+1}\) achieves_

\[_{(_{N+1},y_{N+1})}(_{N+1}- y_{N+1})^{2}^{2}[1+(s(d/)/N)].\]

The \(}(s d/N)\) excess risk obtained in Theorem 8 is optimal up to log factors [62; 87]. We remark that Theorem 8 is not a direct corollary of Theorem 7; Rather, the bound on the number of layers in Theorem 8 requires a sharper convergence analysis of the (IClasso) problem under sparse linear models (Appendix H.2), similar to .

### Proof technique: In-context gradient descent

The constructions in Section 3.1 and 3.2 is built on the following result for approximating in-context (proximal) gradient descent on (regularized) convex losses.

**Theorem 9** (ICGD; Informal version of Theorem D.1 & D.2).: _For a broad class of convex losses of form \(_{i=1}^{N}(^{}_{i},y _{i})+R()\), there exists an \(L\)-layer transformer that takes in any \((,^{0})\) and outputs \(}^{L}\) such that \(\|}^{L}-^{L}_{\{,\}}\|_{2} (L)\), by composing \(L\) identical layers each \(()\)-approximating a single step of GD (so that \((L)\) is a linear error accumulation)._Theorem 9 is established in two main steps:

* Approximating one-step of ICGD using one attention layer (Proposition E.1), which substantially generalizes that of von Oswald et al.  (which only does GD on square losses with a _linear_ self-attention), and is simpler than the ones in Akyurek et al.  and Giannonu et al. .
* Stacking \(L\) of the above layer to approximate \(L\) steps of ICGD. Done naively, the error accumulation of this stacking operation is exponential in \(L\) in the worst case. We utilize the stability of _convex_ gradient descent (Lemma D.1) to obtain the _linear_ in \(L\) error accumulation in Theorem 9.

In Appendix D.3, we also give results for _non-convex_ GD on two-layer neural nets, though with a worse (exponential in \(L\)) error accumulation as expected.

## 4 In-context algorithm selection

We now show that transformers can perform various kinds of _in-context algorithm selection_, which allows them to implement more complex ICL procedures by adaptively selecting different "base" algorithms on different input sequences. We construct two general mechanisms: _Post-ICL validation_, and _Pre-ICL testing_; See Figure 1 for a pictorial illustration.

### Post-ICL validation mechanism

In our first mechanism, post-ICL validation, the transformer begins by implementing a _train-validation split_\(=(_{},_{})\), and running \(K\)_base_ ICL algorithms on \(_{}\). Let \(\{f_{k}\}_{k[K]}(^{d})\) denote the \(K\) learned predictors, and

\[_{}(f):=_{}|}_{( _{i},y_{i})_{}}(f(_{i}),y_{i})\] (7)

denote the validation loss of any predictor \(f\).

We show that (proof in Appendix I.1) a 3-layer transformer can output a predictor \(\) that achieves nearly the smallest validation loss, and thus nearly optimal expected loss if \(_{}\) concentrates around the expected loss \(L\). Below, the input sequence \(\) uses a generalized positional encoding \(_{i}:=[_{D-(d+3)};1;t_{i}]\) in (3), where \(t_{i}:=1\) for \(i_{}\), \(t_{i}:=-1\) for \(i_{}\), and \(t_{N+1}:=0\).

**Proposition 10** (In-context algorithm selection via train-validation split).: _Suppose that \((,)\) in (7) is approximable by sum of relus (Definition D.1, which includes all \(C^{3}\)-smooth bivariate functions). Then there exists a 3-layer transformer \(_{}\) that maps (defining \(y_{i}^{}=y_{i}1\{i<N+1\}\))_

\[_{i}=[_{i};y_{i}^{};*;f_{1}(_{i}); \ ;f_{K}(_{i});_{K+1};1;t_{i}]_{i}^{ }=[_{i};y_{i}^{};*;(_{i});1;t_{i} ],\ i[N+1],\]

_where the predictor \(:^{d}\) is a convex combination of \(\{f_{k}:_{}(f_{k})_{k_{*}[K]} _{}(f_{k_{*}})+\}\). As a corollary, for any convex risk \(L:(^{d})\), \(\) satisfies_

\[L()_{k_{*}[K]}L(f_{k_{*}})+_{k[K]}| {L}_{}(f_{k})-L(f_{k})|+.\]

Ridge regression with in-context regularization selectionAs an example, we use Proposition 10 to construct a transformer to perform in-context ridge regression with regularization selection according to the _unregularized_ validation loss \(_{}():=_{}| }_{(x_{i},y_{i})_{}}(, _{i}-y_{i})^{2}\) (proof in Appendix I.2). Let \(_{1},,_{K} 0\) be \(K\) fixed regularization strengths.

**Theorem 11** (Ridge regression with in-context regularization selection).: _There exists a transformer with \(((1/))\) layers and \((K)\) heads such that the following holds: On any \((,_{N+1})\) well-conditioned (cf. (5)) for all \(\{_{k}\}_{k[K]}\), it outputs \(_{N+1}=},_{N+1}\), where_

\[\!(},\{ }_{,}^{_{k}}: _{}(}_{,}^{_{k}})_{k_{*}[K]}_{}( }_{,}^{_{k_{*}}})+ \}).\]

_Above, \(}_{,}^{}\) denotes the solution to (ICRidge) on the training split \(_{}\)._

#### 4.1.1 Nearly Bayes-optimal ICL on noisy linear models with mixed noise levels

We build on Theorem 11 to show that transformers can perform nearly Bayes-optimal ICL when data come from noisy linear models with a _mixture of \(K\) different noise levels_\(_{1},,_{K}>0\).

Concretely, consider the following data generating model, where we first sample \(=_{_{*},_{k}}\) from \(k([K])\), \(_{*}(,_{d}/d)\), and then sample data \(\{(_{i},y_{i})\}_{i[N+1]}}}{{}}_{_{*},_{k}}\) as

\[_{_{*},_{k}}:_{i}(,_{d}), y_{i}=_{i},_{*}+ (0,_{k}^{2}).\]

For any fixed \((N,d)\), consider the Bayes risk for predicting \(y_{N+1}\) under this model:

\[_{}:=_{}_{}()(_{N+1})-y_{N+1})^{2}.\]

By standard Bayesian calculations, the above Bayes risk is attained when \(\) is a certain _mixture of \(K\) ridge regressions_ with regularization \(_{k}=d_{k}^{2}/N\); however, the mixing weights depend on \(\) in a highly non-trivial fashion (see Appendix J.2 for a derivation). By using the post-ICL validation mechanism in Theorem 11, we construct a transformer that achieves nearly the Bayes risk.

**Theorem 12** (Nearly Bayes-optimal ICL; Informal version of Theorem J.1).: _For sufficiently large \(N,d\), there exists a transformer with \(( N)\) layers and \((K)\) heads such that on the above model, it outputs a prediction \(_{N+1}\) that is nearly Bayes-optimal:_

\[_{}(y_{N+1}-_{N+1})^{2} _{}+(( K/N)^{1/3}).\] (8)

In particular, Theorem 12 applies in the _proportional setting_ where \(N,d\) are large and \(N/d=(1)\), in which case \(_{}=(1)\), and thus the transformer achieves vanishing excess risk relative to the Bayes risk at large \(N\).

This substantially strengthens the results of Akyurek et al. , who empirically find that transformers can achieve nearly Bayes risk under any _fixed_ noise level. By contrast, Theorem 12 shows that a _single_ transformer can achieve nearly Bayes risk even under a mixture of \(K\) noise levels, with quantitative guarantees. Also, our proof in fact gives a stronger guarantee: The transformer approaches the _individual Bayes risks on all \(K\) noise levels simultaneously_ (in addition to the overall Bayes risk for \(k\) as in Theorem 12). We demonstrate this empirically in Section 6 (cf. Figure 2(b) & 2).

Exact Bayes predictor vs. Post-ICL validation mechanismAs \(_{}\) is the theoretical lower bound for the risk of any possible ICL algorithm, Theorem 12 implies that our transformer performs similarly as the exact Bayes estimator5. Notice that our construction builds on the (generic) post-ICL validation mechanism, rather than a direct attempt of approximating the exact Bayes predictor, whose structure may vary significantly case-by-case. This highlights post-ICL validation as a promising mechanism for approximating the Bayes predictor on broader classes of problems beyond noisy linear models, which we leave as future work.

Generalized linear models with adaptive link function selectionAs another example of the post-ICL validation mechanism, we construct a transformer that can learn a generalized linear model with adaptively chosen link function for the particular ICL instance; see Theorem J.2.

### Pre-ICL testing mechanism

In our second mechanism, pre-ICL testing, the transformer runs a _distribution testing_ procedure on the input sequence to determine the right ICL algorithm to use. While the test (and thus the mechanism itself) could in principle be general, we focus on cases where the test amounts to computing some simple summary statistics of the input sequence.

To showcase pre-ICL testing, we consider the toy problem of selecting between in-context regression and in-context classification, by running the following _binary type check_ on the input labels \(\{y_{i}\}_{i[N]}\):

\[^{}()=_{i=1}^{N}(y_{i}), (y):=1,&y\{0,1\},\\ 0,&y[-,][1-,1+],\\ ,&.\]

**Lemma 13**.: _There exists a single attention layer with 6 heads that implements \(^{}\) exactly._

Using this test, we construct a transformer that performs logistic regression when labels are binary, and linear regression with high probability if the label admits a continuous distribution.

**Proposition 14** (Adaptive regression or classification; Informal version of Proposition I.4).: _There exists a transformer with \(((1/))\) layers such that the following holds: On any \(\) such that \(y_{i}\{0,1\}\), it outputs \(_{N+1}\) that \(\)-approximates the prediction of in-context logistic regression._

_By contrast, for any distribution \(\) whose marginal distribution of \(y\) is not concentrated around \(\{0,1\}\), with high probability (over \(\)), \(_{N+1}\)\(\)-approximates the prediction of in-context least squares._

The proofs can be found in Appendix I.3. We additionally show that transformers can implement more complex tests such as a _linear correlation test_, which can be useful in certain scenarios such as "confident linear regression" (predict only when the signal-to-noise ratio is high); see Appendix I.4.

## 5 Analysis of pretraining

Building on the expressivity results in Section 3 & 4, we provide the first line of polynomial sample complexity results for _pretraining_ transformers to perform ICL (including with in-context algorithm selection). We begin by providing a generic generalization guarantee for pretraining transformers.

Consider the pretraining ERM problem (TF-ERM), which minimizes the pretraining risk \(_{}()\) over \(n\) pretraining sequences. Let \(L_{}()\) denote the corresponding population risk.

**Theorem 15** (Generalization of transformers; Informal version of Theorem K.1).: _The solution \(}\) to (TF-ERM) over transformers with \(L\) layers, \(M\) heads per layer, and hidden dimension \(D^{}\) satisfies_

\[L_{}(})_{}L_{}( )+}(MD^{2}+DD^{ })}{n}}.\]

Theorem 15 builds on standard uniform concentration analysis via chaining (Proposition B.4). Combining Theorem 15 with the in-context linear regression construction in Theorem 4 gives the following end-to-end result on the excess in-context prediction risk of trained transformers.

**Theorem 16** (Pretraining transformers for in-context linear regression; Informal version of Theorem K.2).: _Under Assumption \(A\) and \(N}(d)\), the solution \(}\) to (TF-ERM) with \(L=(( N/))\) layers, \(M=3\) heads, \(D^{}=0\) (attention-only as in Theorem 4) achieves small excess ICL risk over the best linear predictor \(_{}^{}:=_{}[^{}]^{ -1}_{}[y]\) for each \(\):_

\[L_{}(})-_{}_{(,y)}(y-_{ }^{},)^{2}} d^{2}}{n}}+}{N},\]

See Appendix K.2 for similar results in several additional settings.

## 6 Experiments

We test our theory by studying the ICL and in-context algorithm selection capabilities of transformers, using the encoder-based architecture in our theoretical constructions (Definition 3). Due to limited space, additional experimental details can be found in Appendix M.1. Results with a decoder architecture as in [31; 47] (including the setup of Figure 2) can be found in Appendix M.2.

Training data distributions and evaluationWe train a 12-layer transformer, with two modes for the training sequence (instance) distribution \(\). In the "base" mode, similar to [31; 2; 86; 47], we sample the training instances from _one_ of the following base distributions (tasks), where we first sample \(=_{_{}}\) by sampling \(_{}(,_{d}/d)\), and then sample \(\{_{i},y_{i}\}_{i[N+1]}}}{{}}_{_{}}\) as \(_{i}}}{{}}(,_{d})\), and \(y_{i}\) from one of the following models studied in Section 3:

1. Linear model: \(y_{i}=_{},_{i}\);
2. Noisy linear model: \(y_{i}=_{},_{i}+ z_{i}\), where \(>0\) is a fixed noise level, and \(z_{i}(0,1)\)3. Sparse linear model: \(y_{i}=_{},_{i}\) with \(\|_{}\|_{0} s\), where \(s<d\) is a fixed sparsity level, and in this case we sample \(_{}\) from a special prior supported on \(s\)-sparse vectors;
4. Linear classification model: \(y_{i}=(_{},_{i} )\).

These base tasks have been empirically investigated by Garg et al. , though we remark that our architecture (used in our theory) differs from theirs in several aspects, such as encoder-based architecture instead of decoder-based, and ReLU activation instead of softmax. All experiments use \(d=20\). We choose \(\{_{1},_{2}\}=\{0.1,0.5\}\) and \(N=20\) for noisy linear regression, \(s=3\) and \(N=10\) for sparse linear regression, and \(N=40\) for linear regression and linear classification.

In the "mixture" mode, \(\) is the uniform _mixture of two or more base distributions_. We consider two representative mixture modes studied in Section 4:

* Linear model + linear classification model;
* Noisy linear model with four noise levels \(\{0.1,0.25,0.5,1\}\).

Transformers trained with the mixture mode will be evaluated on _multiple_ base distributions simultaneously. When the base distributions are sufficiently diverse, a transformer performing well on all of them will _likely_ be performing some level of in-context algorithm selection. We evaluate transformers against standard machine learning algorithms in context (for each task respectively) as baselines.

ResultsFigure 2(a) shows the ICL performance of transformers on five base tasks, within each the transformer is trained on the same task. Transformers match the best baseline algorithm in four out of the five cases, except for the sparse regression task where the Transformer still outperforms least squares and matches Lasso with some choices of \(\) (thus utilizing sparsity to some extent). This demonstrates the strong ICL capability of the transformer architecture considered in our theory.

Figure 2(b) & 2(c) examine the in-context algorithm selection capability of transformers, on noisy linear regression with two different noise levels (Figure 2(b)), and regression + classification (Figure 2(c)). In both figures, the transformer trained in the mixture mode (TF_alg_select) approaches the best baseline algorithm on both tasks simultaneously. By contrast, transformers trained in the base mode for one of the tasks perform well on that task but behave suboptimally on the other task as expected. The existence of TF_alg_select showcases a single transformer that performs well on multiple tasks simultaneously (and thus has to perform in-context algorithm selection to some extent), supporting our theoretical results in Section 4.

## 7 Conclusion

This work shows that transformers can perform complex in-context learning procedures with strong in-context algorithm selection capabilties, by both explicit theoretical constructions and experiments. We believe our work opens up many exciting directions, such as (1) more mechanisms for in-context algorithm selection; (2) Bayes-optimal ICL on other problems by either the post-ICL validation mechanism or new approaches; (3) understanding the internal workings of transformers performing in-context algorithm selection; (4) other mechanisms for implementing complex ICL procedures beyond in-context algorithm selection; (5) further statistical analyses, e.g. of pretraining. Besides, this work focuses on the transformer architecture; alternative sequence-to-sequence architectures (such as RNNs) are beyond our scope but would be interesting directions for future work.

Figure 3: ICL capabilities of the transformer architecture used in our theoretical constructions. _(a)_ On five representative base tasks, transformers approximately match the best baseline algorithm for each task, when pretrained on the corresponding task. _(b,c)_ A **single transformer**TF_alg_select **simultaneously approaches the performance of the strongest baseline algorithm** on two separate tasks: _(b)_ noisy linear regression with two different noise levels \(\{0.1,0.5\}\), and _(c)_ adaptively selecting between regression and classification.