# Differential Privacy of Cross-Attention with Provable Guarantee

Yingyu Liang

The University of Hong Kong

University of Wisconsin-Madison

yingyul@hku.hk, yliang@cs.wisc.edu

&Zhenmei Shi

University of Wisconsin-Madison

zhmeishi@cs.wisc.edu

&Zhao Song

The Simons Institute for the Theory of Computing

at the University of California, Berkeley

magic.linuxkde@gmail.com &Yufa Zhou

University of Pennsylvania

yufazhou@seas.upenn.edu

###### Abstract

Cross-attention has become a fundamental module nowadays in many important artificial intelligence applications, e.g., retrieval-augmented generation (RAG), system prompt, guided stable diffusion, and many more. Ensuring cross-attention privacy is crucial and urgently needed because its key and value matrices may contain sensitive information about model providers and their users. In this work, we design a novel differential privacy (DP) data structure to address the privacy security of cross-attention with a theoretical guarantee. In detail, let \(n\) be the input token length of system prompt/RAG data, \(d\) be the feature dimension, \(0< 1\) be the relative error parameter, \(R\) be the maximum value of the query and key matrices, \(R_{w}\) be the maximum value of the value matrix, and \(r,s,_{s}\) be parameters of polynomial kernel methods. Then, our data structure requires \((ndr^{2})\) memory consumption with \((nr^{2})\) initialization time complexity and \((^{-1}r^{2})\) query time complexity for a single token query. In addition, our data structure can guarantee that the process of answering user query satisfies \((,)\)-DP with \((n^{-1}^{-1}^{-1/2}R^{2s}R_{w}r^{2})\) additive error and \(n^{-1}(+_{s})\) relative error between our output and the true answer. Furthermore, our result is robust to adaptive queries in which users can intentionally attack the cross-attention system. To our knowledge, this is the first work to provide DP for cross-attention and is promising to inspire more privacy algorithm design in large generative models (LGMs).

## 1 Introduction

The development of Artificial Intelligence (AI) has four stages: (1) prediction AI, e.g., ResNet  in image classification; (2) generation AI, e.g., ChatGPT  in language generation; (3) autonomous agent AI, Voyager  autonomously plays Minecraft game ; (4) Artificial Generalization Intelligence (AGI). Humans have made rapid progress in generative AI, and we are excitingly heading to the third stage, the era of AI agent . One prevalent application of AI agents is customized large generative models (LGMs) agents , e.g., AgentGPT , SuperAGI , MetaGPT , GPT Researcher  and many so on. In particular, recently, Apple Inc. introduced Apple Intelligence , signaling the integration of LGMs into physical devices. This innovation allows devices to use personal information for real-life assistance, such as entering passport numbers when booking flights or informing users of their latestmeetings. With increased AI capabilities, privacy concerns become significant, as the more personal information devices handle, the greater the potential privacy risks.

One fundamental technique used in LGMs is cross-attention (Vaswani et al., 2017), which is an essential module in retrieval-augmented generation (RAG) (Lewis et al., 2020), system prompt, guided stable diffusion, and many so on. In RAG, to be more professional, the LGMs answer user input queries by using a domain-specific database under cross-attention, which may contain specific privacy data and knowledge so that the LGMs gain additional power. For system prompts, based on cross-attention, some customized long prompts, e.g., user information or concrete rules, are concatenated before user input to follow human instructions better, which are commonly used in ChatGPT (GitHub, 2024b), Claude3 (Anthropic, 2024) and other commercial LGMs.

Consequently, protecting the privacy of domain-specific data in RAG or system prompts is crucial as they contain sensitive information about users and companies. These data and prompts are the core assets of many start-ups. However, these data and prompts can be easily recovered (Li et al., 2023b), jailbroken (Jin et al., 2024), and released (Li et al., 2023a) by user adversarial attack (Yu et al., 2024), e.g., there are 1700 tokens in ChatGPT system prompts (Patel, 2024). These findings highlight the critical importance of robust privacy protections in LGMs, making privacy not just essential but an urgent issue that demands immediate attention.

To fundamentally preserve cross-attention privacy, we borrow the powerful tools from differential privacy (DP) (Dwork et al., 2006), which provides measurable privacy and combines with statistical machine learning seamlessly (Ponomareva et al., 2023). Thus, in this work, we would like to ask and answer the following question,

_How can we use differential privacy to protect the security of cross-attention in LGMs?_

Our work demonstrates that the Softmax cross-attention computation is equivalent to computing the weighted distance problem.

**Definition 1.1** (Softmax cross-attention).: _Let \(n\) and \(m\) be the token length of the data and input query, respectively. Let \(d\) be the feature dimension. Given fixed key matrix \(K[0,R]^{n d}\) and fixed value matrix \(V[-R_{w},R_{w}]^{n d}\), for any input query matrix \(Q[0,R]^{m d}\), the goal of the Softmax Cross-Attention Computation is to get the matrix \((Q,K,V)^{m d}\), which is_

\[(Q,K,V):=D^{-1}AV,\]

_where \(A^{m n}\) satisfies \(A_{i,j}:=( Q_{i},K_{j}/d)\) for any \(i[m],j[n]\) (\(Q_{i}\) and \(K_{j}\) denote the \(i\)-th and \(j\)-th rows of \(Q\) and \(K\), respectively) and \(D:=(A_{n})^{m m}\) is a diagonal matrix._

Note that \((QK^{})=D^{-1}A^{m n}\) in Definition 1.1, which is the standard function used in transformers, and usually, we call it as attention matrix. Our main theorem, presented below, provides a robust solution of cross-attention, ensuring privacy and accuracy guarantees.

**Theorem 1.2** (Main result; Informal version of Theorem 3.1).: _Let \(Q,K,V,\) be defined in Definition 1.1. Let \((0,1)\) be the relative error parameter and \(p_{f}\) be the probability of failure parameter. Let \(r,s,_{s}\) be the parameters of the polynomial kernel methods (Lemma D.7). Let \(l=(r)\). Then, our Algorithm 1 requires \(O(lndr)\) memory with \(O(lnr)\) initialization time and \((^{-1}lr)\) query time, such that with probability \(1-p_{f}\), the output process of cross-attention satisfies \((,)\)-DP and is robust to adaptive query with relative error \(n^{-1}(+_{s})\) and additive error \((n^{-1}^{-1}^{-1/2}lR^{2s}R_{w}r)\)._

Our main technique in Theorem 1.2 ensures that cross-attention is differentially private by using the polynomial kernel approximation method and transforming it into a weighted distance problem. We then solve the problem by summing over weighted distances (depending on the value embedding) between the query embedding and the key embedding. We build a data structure for weighted Softmax queries in Section 4.3, and we extend this data structure to handle adaptive queries using the \(_{0}\)-net/metric entropy argument in Section 4.4. Furthermore, our error decreases as the input token length grows, diminishing both the relative and additive errors to zero.

Our contributions are as follows:

* We demonstrate that cross-attention computations are equivalent to the weighted distance problem (Section 3).

* We design a novel algorithm (Algorithm 2) that privately answers weighted Softmax queries with high probability and a concrete accuracy bound.
* Our algorithm (Algorithm 1) handles multiple cross-attention queries and is robust against adaptive query attacks (Theorem 3.1), meaning that potential attackers cannot intentionally extract information of system prompts/RAG data.

To our knowledge, this is the first work to utilize DP to protect prompts in LGMs with theoretically provable guarantees. While some have explored protecting user/system prompts with DP (Edemacu and Wu, 2024; Mai et al., 2023), they are primarily empirical and lack theoretical guarantees. Additionally, many others are working on protecting private datasets by applying DP to the fine-tuning stage of LGMs (Behnia et al., 2022; Singh et al., 2024; Liu et al., 2024; Yu et al., 2021; Li et al., 2021; Shi et al., 2022), which diverges from our work. The strength of DP lies in its strong, unambiguous, and concrete definition of privacy, enabling algorithm designs with provable privacy and accuracy analysis. Therefore, we believe that the theoretical aspects of DP applications in LGMs remain a highly impactful direction, and we aim to pave the way for further exploration in this area.

### Related Work

**Differential Privacy in Data Structure and Attention.** Differential privacy (DP) is a flourishing and powerful technique that has enormous applications in the topic of private machine learning. In the era of Large Generative Models (LGMs), there are three primary approaches to ensuring privacy: (1) during the pre-training stage: to protect training data (Abadi et al., 2016; Ponomareva et al., 2023), (2) during the adaptation stage: to protect target data (Behnia et al., 2022; Singh et al., 2024; Liu et al., 2024; Yu et al., 2021; Li et al., 2021; Shi et al., 2022), (3) during the inference stage: to protect user/system prompts (Edemacu and Wu, 2024) and RAG data (Lewis et al., 2020). To protect training data, DP-SGD (Abadi et al., 2016) uses DP optimizer to ensure data privacy, severing as the traditional baseline method. Recently, numerous works have aimed to improve this method by integrating DP in both the pre-training and fine-tuning stages of LGMs (Yu et al., 2021; Li et al., 2021; Golatkar et al., 2022; Behnia et al., 2022; Shi et al., 2022; Mattern et al., 2022; Singh et al., 2024; Zheng et al., 2024; Liu et al., 2024). To protect user/system prompts, Edemacu and Wu (2024) provides a survey on both DP and non-DP methods. In the use of LGMs, prompting methods almost become a standard way for inference (Schulhoff et al., 2024). Given the billions of prompt interactions daily, ensuring privacy is essential (Mai et al., 2023). We refer readers to Appendix B for more related works.

**Roadmap.** In Section 2, we present the preliminary of differential privacy (DP) and cross-attention. In Section 3, we present the main result of our cross-attention theorem (Theorem 3.1). In Section 4, we outline the main results of our algorithms. In Section 5, we conclude our paper.

## 2 Preliminary

In this section, we give the preliminary of differential privacy (DP) and cross-attention. In Section 2.1, we describe the notations. In Section 2.2, we give definitions related to DP.

### Notations

We use \([]\) to denote the probability. We use \([]\) to denote the expectation. We use \([]\) to denote the variance. For two vectors \(x^{d}\) and \(y^{d}\), we use \( x,y\) to denote the inner product between \(x,y\), i.e., \( x,y=_{i=1}^{d}x_{i}y_{i}\). We use \(X^{d}\) and \(|X|=n\) to mean the same thing as \(X^{n d}\). Also, we denote \(x_{i}^{}\) as the \(i\)-th row of \(X\). We use \(x_{i,j}\) to denote the \(j\)-th coordinate of \(x_{i}^{n}\). We use \(_{n}\) to denote a length-\(n\) vector where all the entries are ones. We use \(\|x\|_{p}\) to denote the \(_{p}\) norm of a vector \(x^{n}\), i.e., \(\|x\|_{1}:=_{i=1}^{n}|x_{i}|\), \(\|x\|_{2}:=(_{i=1}^{n}x_{i}^{2})^{1/2}\), and \(\|x\|_{}:=_{i[n]}|x_{i}|\).

### Differential Privacy Definitions

In this section, we give several definitions related to differential privacy (DP). We refer the reader to Dwork and Roth (2014) for more background and details on DP.

**Definition 2.1** (Neighboring dataset).: _We define the two neighboring datasets as \(X,X^{}^{n}\) such that \(\|X-X^{}\|_{1} 1\), i.e., they differ on a single data point._

**Definition 2.2** (Sensitivity).: _The sensitivity of a function \(f:^{n}^{d}\) is defined by: \(:=_{X,X^{}^{n},\|X-X^{}\|_{1}=1}\|f(X)-f(X^ {})\|_{1}\)._

**Definition 2.3** (\((,)\)-Dp).: _For \(>0, 0\), a randomized algorithm \(\) is \((,)\)-DP, if for all \(()\) and for all \(X,X^{}\) such that \(\|X-X^{}\|_{1} 1\): \([(X)]()[(X^{} )]+\). When \(=0\), the algorithm is said to have pure differential privacy._

We mainly use the truncated Laplace mechanism, which has the following definitions.

**Definition 2.4** (Truncated Laplace distribution).: _We use \((,,)\) to denote the Truncated Laplace distribution with pdf proportional to \((-|z|/)\) on the region \([-B,B]\), where \(B=(1+)\)._

**Fact 2.5** (Theorem 3 in Geng et al. (2020)).: _Let \(z\) denote a \((,,)\) random variable. Then we have \([z]=0\), and \([z]=}{^{2}}(1-( 1+-1}{2})+2(1+-1}{2})}{ ^{2}-1})\). Furthermore, if \(=0\), we have \([z]=2^{2}/^{2}\), meaning truncated Laplacian mechanism will be reduced to the standard Laplacian mechanism._

**Lemma 2.6** (Laplace mechanism, (Dwork and Roth, 2014; Geng et al., 2020), see Lemma 2.2 in Andoni et al. (2023)).: _Given a numeric function \(f\) that takes a dataset \(X\) as the input, and has sensitivity \(\), the mechanism that outputs \(f(X)+z\) where \(z(/)\) is \((,0)\)-DP. In addition, if \(,(0,0.5)\), \(f(X)+z\), where \(z(,,)\) is \((,)\)-DP. Moreover, the truncated Laplace mechanism is always accuracy up to error \(B\)._

```
1:datastructureDPTreeSoftmaxAdaptive\(\) Theorem 4.4
2:members
3:\(_{1},,_{O(r(dR/(_{s}p_{f})))}:\)DPTreeSoftmax\(\) Algorithm 2
4:endmembers
5:procedureInit(\(X[0,R]^{d},n_{+},w[-R_{w},R_{w}]^{n},(0,1), (0,1),^{}(0,1),c(0,0.1)),_{s}(0,0.1),p_ {f}(0,0.01)\))
6:\(l O(r(dR/(_{s}p_{f})))\)
7:for\(i=1 l\)do
8:\(_{i}\).Init(\(X,n,w,/l,/l,^{}/l,c,_{s}\))
9:endfor
10:endprocedure
11:procedureDistanceQuery(\(y[0,R]^{d},(0,1)\))
12:\(l O(r(dR/(_{s}p_{f})))\)
13:\(r 0^{l}\)
14:for\(i=1 l\)do
15:\(r_{i}_{i}\).DistanceQuery(\(y,\))
16:endfor
17:return Median of \(r\)
18:endprocedure
19:end datastructure ```

**Algorithm 1** Adaptive query data structure

## 3 Main Results: Cross-Attention

In this section, we show our main result for cross-attention. Theorem 3.1 states that we can ensure the entire cross-attention module satisfies DP and is robust to adaptive queries. Our high-level idea is based on the similarity between weighted distance problem and cross-attention. For a typical weighted distance problem, we define the following: Let \(w^{n}\) be the weights, \(X^{n d}\) be the data matrix, where \(x_{i}^{}\) is the \(i\)-th row of \(X\) for \(i[n]\), and let \(y^{d}\) be the query. Suppose we need to answer \(_{1}\)-distance query. We have

\[_{i[n]}}_{}_{ }-}_{}_{1}.\]Now we introduce cross-attention. Let \(Q,K,V,\) be defined in Definition 1.1. In a standard cross-attention process, we have access to \(K\) and \(V\) before inference, but not to the user input \(Q\). For the cross-attention mechanism \(\) (Definition 1.1), we aim to ensure that the matrix \(AV\) satisfies DP guarantee. Let \(A_{i,j}=((Q_{i},K_{j})/d)\) for \(i[m],j[n]\). Let \(V_{j,k}\) be the \((j,k)\)-th entry of \(V\), for \(j[n],k[d]\). By post-processing property (Fact C.5), to ensure that the forward output \((Q,K,V)=D^{-1}AV\) (Definition 1.1) satisfies DP, we only need to ensure the DP of its component \(AV\)1. The \((i,k)\)-th entry of \(AV\) for each \(i[m],k[d]\) is computed by

\[(AV)_{i,k}=_{j=1}^{n}}_{}( }_{},}_{}/d),\] (1)

which can be viewed as a weighted Softmax problem, where \(V\) provides the weights, \(Q\) is the query, and \(K\) is the dataset. Thus, we choose to add noise to \(K\) and \(V\) based on the similarity between the weighted distance problem and cross-attention. Furthermore, we find that we can only handle one column of \(V\), i.e., \(V_{*,k}^{n}\), in a single data structure. Therefore, we need to initialize a total of \(d\) different data structures, each with weights \(V_{*,k}\) for \(k[d]\).

Here, we present our main result below.

**Theorem 3.1** (Softmax cross-attention, informal version of Theorem J.12).: _Let \(Q,K,V,\) be defined in Definition 1.1. Let \((0,1)\) be the relative error parameter and \(p_{f}\) be the probability of failure parameter. Let \(r,s,_{s}\) be the parameters of the polynomial kernel methods (Lemma D.7). Let \(_{R,s}:=_{j[s]}}{}\) (Definition I.3). Let \(l=O(r(dR/(_{s}p_{f})))\). There is a data structure (Algorithm 1) that uses \(O(lnrd)\) spaces to ensure cross-attention satisfies DP and supports the following operations:_

* _We initialize_ \(d\) _data structures using_ \((K,n,V_{*,k},(0,1),(0,1),^{}( 0,1),c(0,0.1),_{s}(0,0.1),p_{f}(0,0.01))\) _(Algorithm_ 1_), for_ \(k[d]\)_. It takes_ \(O(lnr)\) _time to initialize one data structure._
* _At query time, for user input_ \(Q\)_, we process one token at a time by passing the_ \(i\)_-th row of_ \(Q\)_, denoted_ \(Q_{i}^{d}\)_, to_ DistanceQuery_\((Q_{i},(0,1))\) _(Algorithm_ 1_) for each_ \(i[m]\)_. It takes_ \(O(^{-1}lr^{2}n)\) _time to output an entry_ \(z\) _in_ \((Q,K,V)\) _such that_
* _the process of output_ \(z\) _satisfies_ \((,+^{})\)_-DP,_
* _the process of output_ \(z\) _has relative error_ \(n^{-1}(+_{s})\)_,_
* _the process of output_ \(z\) _has additive error_ \(O(n^{-1}^{-1}^{-1/2}l_{R,s}^{2}R_{w}r)}^{3/2}n)\)_,_
* _it holds with probability_ \(1-p_{f}\) _(where_ \(p_{f}\) _is used in_ \(l\)_),_
* _it is robust to adaptive query._

In Theorem 3.1, we use our DPTreeSoftmaxAdaptive (Algorithm 1) and guarantee that, for each query token of cross-attention, the output process satisfies \((,)\)-DP with \(n^{-1}(+_{s})\) relative error and \(O(n^{-1}^{-1}^{-1/2}l_{R,s}^{2}R_{w}r)}^{3/2}n)\) additive error, and \(O(^{-1}lr^{2}n)\) running time under adaptive query. More specifically, the algorithm creates \(d\)DPTreeSoftmaxAdaptive data structures, each requiring \(O(lnr)\) memory consumption and \(O(lnr)\) initialization time. Notably, our error is inversely proportional to \(n\), meaning that as the input token length increases, both the relative and approximate errors approach zero. This is achieved by the normalizing matrix \(D\) (Definition 1.1). We refer the reader to Section J for proof details.

Thus, our algorithm theoretically protects system prompts/RAG data in cross-attention as discussed in Section 1. In Section 4, we provide a detailed technical overview, and in Section A, we will present self-attention and DP-related discussion.

## 4 Key Data Structure: DPTree

This section provides our key data structures: DPTree (Algorithm 3), DPTreeDistance (Algorithm 5 and 6), DPTreeHighDim (Algorithm 7), DPTreeSoftmax (Algorithm 2), and DPreeSoftmaxAdaptive (Algorithm 1).

In Section 4.1, we provide our high-level proof insights. In Section 4.2, we give our basic building block algorithms DPTree, DPTreeDistance and DPTreeHighDim. In Section 4.3, we present our DPTreeSoftmax algorithm that solves the weighted Softmax problem. In Section 4.4, we present our DPTreeSoftmaxAdaptive algorithm that enables DPTreeSoftmax to handle adaptive query problem.

### Technique Overview

Notice that Eq. (1) is not a typical distance measure like \(_{1}\) or \(_{2}\), but by using polynomial kernel method techniques, we transform it into a distance measure. Alman and Song (2023) states that the exponential inner product can be approximated by polynomial kernel function \(P():^{d}^{r}\), i.e., \(P(x)^{}P(y)(x^{}y/d)\) for two vector \(x,y^{d}\), with a relative error. Then, by the Law of Cosines, we transform the inner product of polynomial kernel functions into a distance measure, i.e.,

\[2P(x)^{}P(y)=\,-\,\|P(x)-P(y)\|_{2}^{2}+\|P(x)\|_{2}^{2}+\|P(y)\|_{2}^{2}.\] (2)

After transforming Eq. (1) into a distance measure, we design the DPTree series data structures to provide cross-attention DP guarantee.

In summary, we first design the data structure DPTree (Algorithm 3) that builds a binary segment tree with truncated Laplace noise added in the leaf nodes to ensure DP guarantee. Then, based on this data structure, we design DPTreeDistance (Algorithm 5 and 6) to answer one dimensional weighted distance queries \(_{i=1}^{n}w_{i}|y-x_{i}|\), which utilizes DPTree to store and return noised weights \(w_{i}\) multiplied with the approximated distances between the query \(y\) and data \(x_{i}\). We further decompose high dimensional \(_{p}^{p}\)-distance problem into one dimensional \(_{1}\)-distance problems using

\[_{i=1}^{n}w_{i}\|y-x_{i}\|_{p}^{p}=\,_{k=1}^{d}_{i=1}^{n}w_{i }|y_{k}-x_{i,k}|^{p}.\] (3)

Based on this decomposition, we design DPTreeHighDim (Algorithm 7) which is capable of answering high dimension queries. Then, using Eq. (2) and DPTreeHighDim, we design DPTreeSoftmax (Algorithm 2) to answer Softmax queries. By building multiple copies of this data structure, we boost the success probability such that it can answer any query (including adaptive query) with an additive error, establishing the final data structure DPTreeSoftmaxAdaptive (Algorithm 1). See Section D for a more detailed outline of algorithms and proof techniques.

### DPTree, DPTreeDistance, and DPTreeHighDim

We design a basic data structure DPTree (Algorithm 3) that answers summation queries by a summation segment tree with truncated Laplace noise (Definition 2.4). The algorithm first builds a binary summation tree in an array and then adds truncated Laplace noises to each node. In query time, we first trace from bottom nodes to find their lowest common ancestor, then report the summation by using at most \(2 n\) nodes on the path (Algorithm 3). Based on the parallel composition rule of DP (Fact C.7), we find that if we have multiple disjoint interval queries, the error of the weighted sum of the intervals can be bounded independently of the number of queries (Lemma E.8). See more details in Section E.

We then design DPTreeDistance, a one-dimensional weighted \(_{1}\) distance data structure detailed in Algorithm 5 and 6. Initialization involves rounding each data point to the nearest multiple of a small interval and aggregating their weights into an array (illustrated in Figure 1), which is then input into our DPTree. At query time, we retrieve aggregated weights within small intervals and multiply them by their distances to the query point. We introduce a relative error parameter \(\) to reduce the number of iterations to \(O((n)/)\), improving efficiency. Guided by Eq.(3), we design DPTreeHighDim (Algorithm 7), which extends DPTreeDistance to higher dimension by constructing independent data structures for each coordinate. See details in Section G and H.

### Softmax Activation

In this section, we present DPTreeSoftmax (Algorithm 2) that answers the weighted Softmax query (Definition 4.1) and is further used to design DP cross-attention. First, we introduce the definition of weighted Softmax query, an abstraction for the problem described in Eq. (1).

**Definition 4.1** (Weighted Softmax query (without normalization)).: _For the dataset \(X[0,R]^{n d}\) where \(x_{i}^{}\) is the \(i\)-th row of \(X\) and query \(y[0,R]^{d}\), we define the weighted exponential inner product/Softmax query to be:_

\[_{i[n]}w_{i}( x_{i},y/d)=w^{}(Xy/d).\]

Building on Definition 4.1, we develop a novel algorithm to answer differentially private weighted Softmax queries using the polynomial kernel method from Alman and Song (2023). Specifically, in Eq.(2), there is a term that computes the weighted \(_{2}^{2}\) distance, which we calculate using DPTreeHighDim. We then compute the exact term for the weighted \(_{2}^{2}\) norms of the approximation kernel. By summing these terms with a controlled error, we extend DPTreeHighDim to answer the Softmax query efficiently. More details can be found in Section J.

**Theorem 4.2** (Softmax query, informal version of Theorem J.8).: _Let \(R 1\). Let \(r\) and \(s=O(\{)}{((1/_{s})/R)},R^{2}\})\). Let \(_{R,s}:=_{j[s]}}{}\) (Definition J.3). Let the accuracy parameter be \(_{s}(0,0.1)\). Our data structure DPTreeSoftmax (Algorithm 2) uses \(O(nr)\) spaces to solve Softmax query problem for dataset \(X[0,R]^{d}\) and support following operations:_

* \((X[0,R]^{d},n_{+},w[-R_{w},R_{w}]^{n}, (0,1),(0,1),^{}(0,1),c(0,0.1), _{s}(0,0.1))\)_. (Algorithm 2) It takes_ \(O(nr)\) _time to initialize the data structure._
* \((y[0,R]^{d},(0,1))\)_. (Algorithm 2) It takes_ \(O(^{-1}r^{2}n)\) _time to output a number_ \(z\) _such that__;_ * _the process of output_ \(z\) _satisfies_ \((,+^{})\)_-DP private, which computes_ \(w^{}(Xy/d)\)_,_ * _the error bound satisfies_ \(|z-w^{}(Xy/d)|(+_{s}) w^{}(Xy/d)\)__ \(+\ O(^{-1}^{-1/2}_{R,s}^{2}R_{w}r)}^{3/2}n)\)_,_ * _it holds with probability at least_ \(0.99\)_._

**Remark 4.3**.: _In Theorem 4.2, the parameter \(_{s}\) is the accuracy parameter for polynomial kernel approximation described in Section D.5. Besides, note that the error bound in Theorem 4.2 does not depend on \(\) but depends on \(^{}\). The role of \(\) is to control a hidden constant term in the big \(O\) notation, i.e., increasing \(\) reduces the error by a small constant (Fact 2.5). In practice, we set \(\) as a small positive constant close to \(0\). Please refer to the Lemma E.6 for more details._

### Adaptive Query Data Structure

We adapt our DPTreeSoftmax to DPTreeSoftmaxAdaptive (Algorithm 1) to solve the adaptive query problem. By proving it can handle any query within the query space with a certain error, we ensure it effectively processes adaptive queries. We first boost the constant probability to high probability using the Chernoff bound (Lemma C.2). Employing an \(_{0}\)-net argument and the union bound, we bound all query points within the net. Finally, we use the Lipschitz property of the weighted Softmax distance function with an additive error to bound all points in the query space. The corresponding proofs can be found in Section I and Section J.

**Theorem 4.4** (Adaptive query Softmax data structure, informal version of Theorem J.11).: _Let \(R 1\). Let \(r\) and \(s=O(\{)}{((1/_{s})/R)},R^{2}\})\). Let \(_{R,s}:=_{j[s]}}{}\) (Definition J.3). Let the accuracy parameter be \(_{s}(0,0.1)\). Let \(X[0,R]^{n d}\) be the dataset, \(w[-R_{w},R_{w}]^{n}\) be weights, \(y[0,R]^{d}\) be the query, \((0,1)\) be the relative error parameter and \(p_{f}\) be the failure probability parameter. Let \(l=O(r(dR/(_{s}p_{f})))\). There is a data structure DPTreeSoftmaxAdaptive (Algorithm 1) that uses \(O(lnr)\) spaces to solve the weighted Softmax query problem for the dataset \(X[0,R]^{d}\) and supports the following operations:

* \((X[0,R]^{d},n_{+},w[-R_{w},R_{w}]^{n}, (0,1),(0,1),^{}(0,1),c(0,0.1),_ {s}(0,0.1),p_{f}(0,0.01))\). It takes \(O(lnr)\) time to initialize the data structure.
* DistanceQuery\((y[0,R]^{d},(0,1))\). It takes \(O(^{-1}lr^{2}n)\) time to output a number \(z\) such that
* the process of output \(z\) satisfies \((,+^{})\)-DP private, which computes \(w^{}(Xy/d)\),
* the error bound satisfies \(|z-w^{}(Xy/d)|(+_{s}) w^{}(Xy/d)\) \(+\ O(^{-1}^{-1/2}l_{R,s}^{2}R_{w}r)}^{3/2}n)\),
* it holds with probability at least \(1-p_{f}\) (where \(p_{f}\) is used in \(l\)),
* it is robust to adaptive query._

**Remark 4.5**.: _We describe the parallelization of our algorithms. In the second for loop of Init and the for loop of DistanceQuery in Algorithm 2, the \(r\) DPTreeDistance data structures instantiated for each coordinate are independent of each other. In addition, the for loops in Algorithm 1 are also parallelizable since the \(l=O(r(dR/(_{s}p_{f})))\) copies are independent. After parallelization, we have the final time complexity of Init to be \(O(nr)\) and DistanceQuery to be \(O(^{-1}^{2}n)\) in Algorithm 1 with \(O(lr)\) GPU process._

## 5 Conclusion and Discussion

To our knowledge, we are the first work to provide differential privacy for cross-attention. This paper presents the DPTree data structures, which provide a differential privacy guarantee for the cross-attention module in large generative models. This is achieved by transforming the cross-attention mechanism into a weighted distance problem. Furthermore, our algorithm is robust to adaptive queries, allowing users to interact with the model arbitrarily without extracting sensitive information from the system prompts or RAG data. Our results may inspire more privacy algorithm design in large generative models. Further discussion, including extension to self-attention and DP related design issue, is deferred to Section A.