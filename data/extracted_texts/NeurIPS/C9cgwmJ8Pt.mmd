# Fast Projected Newton-like Method for Precision

Matrix Estimation under Total Positivity

 Jian-Feng Cai\({}^{1,2}\), Jose Vinicius de M. Cardoso\({}^{1}\), Daniel P. Palomar\({}^{1}\), Jiaxi Ying\({}^{1,2}\)

Hong Kong University of Science and Technology\({}^{1}\)

HKUST Shenzhen-Hong Kong Collaborative Innovation Research Institute\({}^{2}\)

Corresponding author.

###### Abstract

We study the problem of estimating precision matrices in Gaussian distributions that are multivariate totally positive of order two (\(_{2}\)). The precision matrix in such a distribution is an \(M\)-matrix. This problem can be formulated as a sign-constrained log-determinant program. Current algorithms are designed using the block coordinate descent method or the proximal point algorithm, which becomes computationally challenging in high-dimensional cases due to the requirement to solve numerous nonnegative quadratic programs or large-scale linear systems. To address this issue, we propose a novel algorithm based on the two-metric projection method, incorporating a carefully designed search direction and variable partitioning scheme. Our algorithm substantially reduces computational complexity, and its theoretical convergence is established. Experimental results on synthetic and real-world datasets demonstrate that our proposed algorithm provides a significant improvement in computational efficiency compared to the state-of-the-art methods.

## 1 Introduction

We consider the problem of estimating the precision matrix (_i.e.,_ inverse covariance matrix) in a multivariate Gaussian distribution, where all the off-diagonal elements of the precision matrix are nonpositive. The resulting precision matrix is a symmetric _M-matrix_. Such property is also known as multivariate totally positive of order two (\(_{2}\)) . For ease of presentation, we call the nonpositivity constraints on the off-diagonal elements of the precision matrix as \(_{2}\) constraints. This model arises in a variety of applications such as taxonomic reasoning , graph signal processing , factor analysis in psychometrics , and financial markets .

Estimating precision matrices under \(_{2}\) constraints is an active research topic. Recent results in  show that \(_{2}\) constraints lead to a drastic reduction on the number of observations required for the maximum likelihood estimator (MLE) to exist in Gaussian distributions and Ising models. This advantage is crucial in high-dimensional regimes with limited observations. Growing interest in estimating precision matrices under \(_{2}\) constraints is seen in graph signal processing . A precision matrix fulfilling \(_{2}\) constraints can be regarded as a generalized graph Laplacian, where eigenvalues and eigenvectors are interpreted as spectral frequencies and Fourier bases, facilitating the computation of graph Fourier transform . The \(_{2}\) property has also been studied in portfolio allocation  and structure recovery .

Estimating precision matrices under \(_{2}\) constraints can be formulated as a sign-constrained log-determinant program. Existing algorithms for solving this problem, such as the block coordinate descent (BCD)  and proximal point algorithm (PPA) , are efficient for low-dimensionalproblems. However, they become time-consuming in high-dimensional scenarios due to the necessity of solving numerous nonnegative quadratic programs or large-scale linear systems. An alternative is the gradient projection method , which offers computational efficiency per iteration. Nevertheless, it often grapples with slow convergence rates in high-dimensional cases. Thus, there is a demand for efficient and scalable algorithms for precision matrix estimation under \(_{2}\) constraints.

### Contributions

In this paper, we propose a fast projected Newton-like algorithm for estimating precision matrices under \(_{2}\) constraints. While second-order algorithms generally require fewer iterations than first-order methods, they often encounter computational challenges due to the necessity of computing a large (approximate) Hessian matrix inverse or equivalently solving the linear system. Our main contributions in this paper are threefold:

1. Our proposed algorithm, rooted in the two-metric projection method, stands apart from current BCD and PPA approaches [2; 3; 8; 9] for solving the target problem. Utilizing a well-designed search direction and variable partitioning scheme, our algorithm avoids the need to solve nonnegative quadratic programs or linear systems, yielding a significant computational reduction compared to BCD and PPA algorithms. As a second-order method, our algorithm maintains the same per-iteration computational complexity as the gradient projection method.
2. We establish that our algorithm converges to the minimizer of the target problem. Furthermore, under a mild assumption, we prove the convergence of the set of _free_ variables to the support of the minimizer within finite iterations and provide the convergence rate of our algorithm.
3. Numerical experiments on both synthetic and real-world datasets provide compelling evidence that our algorithm converges to the minimizer considerably faster than the compared methods. We apply the proposed method to financial time-series data and observe significant performance in terms of _modularity_ value on the learned financial networks.

Notation:Lower case bold letters denote vectors and upper case bold letters denote matrices. Both \(X_{ij}\) and \([]_{ij}\) denote the \((i,j)\)-th entry of \(\). \([p]\) denotes the set \(\{1,,p\}\), and \([p]^{2}\) denotes the set \(\{1,,p\}\{1,,p\}\). Let \(\) be the Kronecker product and \(\) be the entry-wise product. \(()=\{(i,j)[p]^{2}\,|\,X_{ij} 0\}\). \(\|\|_{}=_{i,j}|X_{ij}|\) and \(\|\|_{}=_{i,j}|X_{ij}|\). \(_{+}^{p}\) and \(_{++}^{p}\) denote the sets of symmetric positive semi-definite and positive definite matrices with dimension \(p p\). \(()\) and \(^{}\) denote the vectorized version and transpose of \(\).

## 2 Problem Formulation and Related Work

In this section, we first introduce the problem formulation, then present related works.

### Problem formulation

Let \(=(y_{1},,y_{p})\) be a \(p\)-dimensional random vector following \((,)\), where \(\) is the covariance matrix. We focus on the problem of estimating the precision matrix \(:=^{-1}\) given \(n\)\(i.i.d.\) observations \(^{(1)},,^{(n)}\). Let \(=_{i=1}^{n}^{(i)}^{(i)}^{}\) be the sample covariance matrix. Throughout the paper, the sample covariance matrix is assumed to have strictly positive diagonal elements, which holds with probability one. This is because some diagonal element \(S_{jj}\) is zero if and only if the \(j\)-th element of \(^{(i)}\) must be zero for every \(i[p]\), which holds with probability zero.

We consider solving the following sign-constrained log-determinant program:

\[^{*}:=&\\ ^{p}&-()+( )+_{i j}_{ij}|X_{ij}|,\\ & X_{ij}=0,\;\,(i,j),\] (1)

where \(_{ij}\) is the regularization parameter, \(\) is the disconnectivity set with each node pair forced to disconnect, and \(^{p}\) is the set of all \(p\)-dimensional, symmetric, non-singular _M-matrices_ defined by

\[^{p}:=\{_{++}^{p}|\,X_{ij} 0,\; i  j\}.\] (2)

The disconnectivity set in (1) can be obtained in several ways: (i) it is often the case that some edges between nodes must not exist due to prior knowledge; (ii) it can be estimated from initial estimators; (iii) it can be obtained in some tasks of learning structured graphs such as bipartite graph [14; 15; 16].

### Related work

Estimating precision matrices under Gaussian graphical models has been extensively studied in the literature. One well-known method is graphical lasso [17; 18; 19; 20], which minimizes the \(_{1}\)-regularized Gaussian negative log-likelihood. Various algorithms were proposed to solve this problem including first-order methods [17; 18; 21; 22; 23; 24; 25; 26; 27; 28; 29] and second-order methods [30; 31; 32; 33]. The graphical lasso optimization problem is unconstrained and nonsmooth, while Problem (1) is smooth and constrained. The difficulties in solving the two problems are inherently different, and the algorithms mentioned above cannot be directly extended to solve Problem (1).

Recent studies [2; 3; 8; 9] employed BCD and PPA-type algorithms to estimate precision matrices under \(_{2}\) constraints. In , the primal variable is updated one column/row at a time by solving a nonnegative quadratic program, cycling until convergence. The work  follows a similar approach but addresses the dual problem, improving memory efficiency. Both works target Problem (1) without the disconnectivity constraint. A BCD-type algorithm was proposed in  to accommodate disconnectivity constraints. However, the computational complexity of these algorithms, at \(O(p^{4})\) operations per cycle, becomes prohibitive for high-dimensional problems. Alternatively, recent work  introduced an inexact PPA algorithm to solve a transformed problem, derived using the soft-thresholding technique. However, this algorithm demands the computation of an inexact Newton direction from a \(p^{2} p^{2}\) linear system at every iteration within the inner loop, presenting computational difficulties in high-dimensional scenarios.

The proposed algorithm adopts the two-metric projection framework , incorporating distinct metrics for search direction and projection. A representative method in this framework is the projected Newton algorithm , originally designed for nonnegativity constrained problems. However, it is unsuitable for Problem (1) due to its \(O(p^{6})\) operations needed to compute the inverse of the Hessian at each iteration. To mitigate computation and memory costs, the projected quasi-Newton algorithm with limited-memory Boyden-Fletcher-Goldfarb-Shanno (L-BFGS) was introduced in , requiring \(O((m+p)p^{2})\) operations per iteration, with \(m\) the number of iterations stored for Hessian approximation. By leveraging the structure of Problem (1), this paper carefully designs the search direction and variable partitioning scheme to substantially reduce computation and memory costs, achieving the same orders per iteration as the gradient projection method .

## 3 Proposed Algorithm

In this section, we propose a fast projected Newton-like algorithm to solve Problem (1). The constraints in Problem (1) can be rewritten as \(\,\,_{++}^{p}\), where \(\) is defined as

\[:=\{^{p p}\,|\,X_{ij}=0,\;\,(i,j) ;\;X_{ij} 0,\;\,i j\}.\]

The set \(\) is convex and closed, thus this constraint can be handled by a projection \(_{}\) defined by

\[[_{}()]_{ij}=0&(i,j) ,\\ A_{ij}&i=j,\\ (A_{ij},0)&(i,j)\;\;i j.\] (3)

The positive definite set \(_{++}^{p}\) is not closed and cannot be managed by a projection, which will be handled using the line search method in Section 3.3. Let \(f\) denote the objective function of Problem (1). To address Problem (1), we start with the gradient projection method, expressed as:

\[_{k+1}=_{}_{k}-_{k} f( _{k}),\] (4)

where \(_{k}\) is the step size. To accelerate convergence, one may consider

\[_{k+1}=_{}_{k}-_{k}_{k},\] (5)

in which \(_{k}^{p p}\) is a search direction defined by

\[(_{k})=_{k}^{-1}( f (_{k})),\] (6)

where \(_{k}^{p^{2} p^{2}}\) is a positive definite symmetric matrix, incorporating second-order derivative information. If we adopt \(_{k}\) as the Hessian matrix, then \(_{k}\) becomes the Newton direction as shown in Proposition 3.1, with the proof provided in Appendix B.1, and iterate (5) can be viewed as a natural adaptation of the unconstrained Newton's method. Regrettably, the convergence of such an iterate to the minimizer cannot be guaranteed, as \(_{k}\) may not be a descent direction here, which is supported by numerical results in Section 5.1.1. Similar observations have also been reported in [35; 37].

**Proposition 3.1**.: _If \(_{k}\) is constructed as the Hessian matrix \(_{k}\) of Problem (1), then the search direction \(_{k}\) defined in (6) can be written as \(_{k}=_{k} f(_{k})_{k}\)._

_Remark 3.2_.: We refer to iterate (5) as the two-metric projection method , as it adopts two distinct metrics: the search direction \(_{k}\) induced by the quadratic norm \(\|\|_{_{k}}\) defined by \(\|\|_{_{k}}=( ),\;_{k}()^{}\), and the projection \(_{}\) with respect to the Frobenius norm \(\|\|_{}\).

### Identifying the sets of _restricted_ and _free_ variables

In order to guarantee iterate (5) to converge to the minimizer, we partition the variables into two groups, _i.e._, _restricted_ and _free_ variables, and update the two groups separately. We first define a set \((,)\) with respect to \(_{++}^{p}\) and \(_{+}\),

\[(,):=(i,j)[p]^{2}\,|\,- X_{ij}  0,\;[ f()]_{ij}<0}.\] (7)

Then at the \(k\)-th iteration, we identify the set of _restricted_ variables based on \(_{k}\) as follows,

\[_{k}:=(_{k},_{k}),\] (8)

where \(\) is the disconnectivity set from Problem (1), and \(_{k}\) is a small positive scalar. For any \((i,j)(_{k},_{k})\), \(X_{ij}\) in the next iterate is likely to be outside the feasible set (_i.e._, \(X_{ij}>0\)) if we remove the projection \(_{}\), as it is near zero and moves towards the positive direction if using the negative of the gradient as the search direction. Therefore, we set all _restricted_ variables to zero.

To establish the theoretical convergence of the algorithm, the positive scalar \(_{k}\) in (8) is specified as

\[_{k}:=2(1-)m^{2}[ f(_{k})]_{ _{k}}_{},\;,\] (9)

where \(m\) is a positive scalar (See Lemma B.1 in Appendix), \((0,1)\) is a parameter in the line search condition, and \(_{}\) represents the set \((_{k},)\). In the rare event that \(_{}\) is empty, particularly in sparse settings, we define \(_{k}=\), implying an empty \((_{k},_{k})\) in (8). The parameter \(\) satisfies \(0<<_{(i,j)(^{})}|[^{}]_{ij}|\), where \(^{}\) is the minimizer of Problem (1). Such a condition can be ensured by setting a sufficiently small positive \(\). Then \(_{k}\) in (9) is nearly equal to \(\). From an implementation view, we can directly set a small positive \(_{k}\), resulting in the algorithm performing well in practice. The set of free variables, denoted by \(_{k}^{c}\), is the complement of \(_{k}\).

### Computing approximate Newton direction

While the (approximate) Newton direction usually demands a considerably higher computational cost than the gradient, our designed direction maintains the same computational order as the gradient.

At the \(k\)-th iteration, we first partition \(_{k}\) into two groups, \([_{k}]_{_{k}}\) and \([_{k}]_{_{k}^{c}}\), where \([_{k}]_{_{k}}^{|_{k}|}\) and \([_{k}]_{_{k}^{c}}^{|_{k}^{c}|}\) denote two vectors containing all elements of \(_{k}\) in the sets \(_{k}\) and \(_{k}^{c}\), respectively. Then we can rewrite the search direction \(_{k}\) in (6) as follows,

\[_{k}(_{k})=_{k}\,_{k}( f(_{k})),\] (10)

where \(_{k}(_{k})\) stacks \(_{k}\) into a vector, similar to \((_{k})\), but places elements from \(_{k}^{c}\) first, followed by those from \(_{k}\). \(_{k}\) is obtained by permuting the rows and columns of \(_{k}^{-1}\) in (6). To enhance computational efficiency, we propose constructing \(_{k}\) and \(_{k}^{-1}\) as follows:

\[_{k}=[_{k}^{-1}]_{_{k}^{c}_{ k}^{c}}&_{k}^{-1}]_{_{k}^{c}_{k}}\\ &_{k}^{-1}_{_{k}_{k}^{c}}& _{k}^{-1}_{_{k}_{k}}\\ =[_{k}^{-1}]_{_{k}^{c}_{ k}^{c}}&\\ &_{k}\\ ,\] (11)

where \(_{k}^{|_{k}||_{k}|}\) is a positive definite diagonal matrix, and \(_{k}^{-1}_{_{k}^{c}_{k}^{c}} ^{|_{k}^{c}||_{k}^{c}|}\) is a principal submatrix of \(_{k}^{-1}\), preserving rows and columns indexed by \(_{k}^{c}\). Here, \(_{k}\) is the Hessian matrix at \(_{k}\). The construction of \(_{k}^{-1}\) in (11) is crucial for defining the search direction, enabling computation and memory costs comparable to the gradient projection method while effectively incorporating second-order derivative information.

Next, we compute the approximate Newton direction \(_{k}\) over the set \(_{k}^{c}\) and present the iterate \([_{k+1}]_{_{k}^{c}}\). We define a projection \(_{_{k}^{c}}()\) as follows,

\[_{_{k}^{c}}()_{ij}=A_{ ij}&\,(i,j)_{k}^{c},\\ 0&.\] (12)Leveraging the well-designed gradient scaling matrix \(_{k}\) in (11), we can efficiently compute the approximate Newton direction, as demonstrated in Proposition 3.3, with proof in Appendix B.2.

**Proposition 3.3**.: _If \(_{k}\) is constructed by (11), then the search direction \(_{k}\) defined in (6) over \(_{k}^{c}\) can be written as \([_{k}]_{_{k}^{c}}=[_{k}_{ _{k}^{c}}( f(_{k}))_{k}]_{_{k}^ {c}}\)._

Using the search direction from Proposition 3.3, we update \(_{k+1}\) over \(_{k}^{c}\) as follows,

\[[_{k+1}]_{_{k}^{c}}=_{} _{k}_{_{k}^{c}}-_{k}[_{k}_{_{k}^{c}}( f(_{k}))_{k}]_{_{k}^{c}} .\] (13)

For the _restricted_ variables in the set \(_{k}\), we directly set them to zero, _i.e._, \([_{k+1}]_{_{k}}=\).

### Computing step size

We adopt an Armijo-like rule for step size selection, ensuring the global convergence of our algorithm. Based on the iterate proposed in Section 3.2, we define \(_{k}(_{k})\) with \([_{k}(_{k})]_{_{k}}=\) and

\[[_{k}(_{k})]_{_{k}^{c}}=_{ }[_{k}]_{_{k}^{c}}-_{k}_{k} _{_{k}^{c}}( f(_{k}))_{k}_{ _{k}^{c}}.\] (14)

We test step sizes \(_{k}^{0},^{1},^{2},}\) with \((0,1)\), until we find the smallest \(t\) such that \(_{k}(_{k})\), with \(_{k}=^{t}\), satisfies \(_{k}(_{k})_{++}^{p}\) and the line search condition:

\[f(_{k}(_{k})) f(_{k})-_{k}  f(_{k})_{_{k}^{c}},\,[_{k}]_{ _{k}^{c}}- f(_{k})_{ _{k}},\,[_{k}]_{_{k}},\] (15)

where \((0,1)\) is a scalar. We then set \(_{k+1}=_{k}(_{k})\). Positive definiteness of \(_{k+1}\) can be verified during Cholesky factorization for objective function evaluation. It is worth mentioning that working with the positive semi-definiteness constraint on \(\) instead of positive definiteness would not change anything in the algorithm if we keep the line search, as the positive definiteness is automatically enforced due to the form of the objective function.

The line search condition (15) is a variant of the Armijo rule. Condition (15) can be always satisfied for a small enough step size as shown in Proposition 3.4. Define the feasible set of Problem (1) as

\[^{p}:=^{p p}\,|\, ^{p},\,X_{ij}=0,\,\,(i,j)}\,.\] (16)

For any given \(^{o}^{p}\), define the lower level set of the objective function \(f\) for Problem (1) as:

\[L_{f}:=\{^{p}\,|\,f() f(^{o})\}.\] (17)

**Proposition 3.4**.: _For any \(_{k} L_{f}\), there exists a \(_{k}>0\) such that \(_{k}(_{k})_{++}^{p}\) and the line search condition (15) holds for any \(_{k}(0,\,_{k})\)._

The proof of Proposition 3.4 is available in Appendix B.3. We demonstrate that \(_{k}(_{k})\) ensures a decrease of the objective function value in Proposition 3.5, proved in Appendix B.4.

**Proposition 3.5**.: _For any \(_{k} L_{f}\), if \(_{k}(_{k})\) satisfies the line search condition (15), then we have_

\[f(_{k}(_{k})) f(_{k})- _{k}m^{2} f(_{k})_{_{k}^{c}} ^{2},\]

_where \(m\) is a positive scalar (See Lemma B.1 in Appendix)._

### Computation and memory costs

In each iteration, our algorithm calculates the gradient, performs two matrix multiplications, and conducts two projections, with respective computational costs of \(O(p^{3})\), \(O(p^{3})\), and \(O(p^{2})\). In our current implementation of the line search method, we first conduct the Cholesky factorization \(=^{}\) using MATLAB's "chol" function. This function can simultaneously verify the positive definiteness of \(\). Next, we calculate the log-determinant function as \(()=2_{i}(L_{ii})\). The Cholesky factorization is the most computationally demanding step, generally requiring \(O(p^{3})\) costs for a \(p p\) matrix.

To mitigate the computational burden associated with Cholesky factorization, we suggest a more efficient method for evaluating the log-determinant function and verifying positive definiteness, as presented in . This method, which leverages Schur complements and sparse linear system solving, can tackle problems of up to \(10^{6}\) dimensions. Furthermore, it is worthwhile to investigate more efficient strategies for computing an approximate log-determinant function. In this context, the approach proposed in  offers a nearly linear scaling of execution time with the number of non-zero entries, while maintaining a high level of accuracy.

In summary, our algorithm has an overall complexity of \(O(p^{3})\) per iteration. BCD-type algorithms  need \(O(p^{4})\) operations per cycle, while projected quasi-Newton with L-BFGS  requires \(O((m+p)p^{2})\) operations per iteration, with \(m\) as the stored iteration count for Hessian approximation. The PPA algorithm  requires computing an inexact Newton direction from a \(p^{2} p^{2}\) linear system during each inner loop iteration, with the exact complexity not established. In addition, our algorithm, gradient projection and BCD-type methods  need \(O(p^{2})\) memory costs, while projected quasi-Newton with L-BFGS  requires \(O(mp^{2})\) and PPA  demands \(O(p^{4})\).

## 4 Convergence Analysis

Prior to delving into the convergence analysis, we first establish the uniqueness of the minimizer for Problem (1) and determine the sufficient and necessary conditions for a point to be the minimizer.

**Theorem 4.1**.: _The minimizer of Problem (1) is unique, and a point \(^{}^{p}\) is the minimizer if and only if it satisfies_

\[[^{}]_{ij}=0\;\;\,(i,j),[ f(^ {})]_{},[  f(^{})]_{^{c}}=,\] (18)

_where \(=\{(i,j)[p]^{2}\,|\,[^{}]_{ij}=0\}\)._

The proof of Theorem 4.1 is available in Appendix B.5. The following theorem shows that our algorithm converges to the minimizer of Problem (1).

**Theorem 4.2**.: _The sequence \(\{_{k}\}\) generated by Algorithm 1 with \(_{0} L_{f}\) converges to the minimizer \(^{}\) of Problem (1), with \(\{f(_{k})\}\) monotonically decreasing._

The proof of Theorem 4.2 is available in Appendix B.6. It is worth noting that constructing an initial point \(_{0} L_{f}\), as defined in (17), is straightforward. Please refer to the proof of Theorem 4.2 for more details on this. The theoretical analysis on support set convergence and sequence convergence rate relies on the following assumption.

**Assumption 4.3**.: For the minimizer \(^{}\) of Problem (1), we assume that the gradient of the objective function \(f\) at \(^{}\) satisfies

\[ f(^{})_{ij}<0,\,(i,j),\]

where \(=(i,j)[p]^{2}\,\,^{}_{ij}= 0}\), and \(\) is the disconnectivity set.

**Theorem 4.4**.: _Under Assumption 4.3, the set of free variables \(_{k}^{c}\) generated by Algorithm 1 converges to the support of the minimizer \(^{}\) of Problem (1) in finite iterations. In other words, there exists some \(k_{o}_{+}\) such that \(_{k}^{c}=(^{})\) for any \(k k_{o}\)._

The proof of Theorem 4.4 is provided in Appendix B.7. Theorem 4.4 demonstrates that the set of _free_ variables constructed by our variable partitioning scheme can exactly identify the support of \(^{}\) in finite iterations. Now we establish the convergence rate of our algorithm. Define

\[_{k}=[_{k}]_{_{k}^{c}_{k}^{c}}- [_{k}]_{_{k}^{c}_{k}}[_{k} ]_{_{k}_{k}}^{-1}[_{k}]_{ _{k}^{c}_{k}}^{}.\] (19)

**Theorem 4.5**.: _Under Assumption 4.3, the sequence \(\{_{k}\}\) generated by Algorithm 1 satisfies_

\[_{k}_{k+1}-^{}\|_{_{ k}}^{2}}{\|_{k}-^{}\|_{_{k}}^{2}}_{k }(1-(m_{k},\ }{M_{k}}))^{2},\]

_where \(m_{k}\) and \(M_{k}\) as the smallest and largest eigenvalues of \(_{k}^{-}[_{k}]_{_{k}^{c}_{k}^{c}}_{k}^{-}\), respectively._

The proof of Theorem 4.5 is provided in Appendix B.8. Theorem 4.5 reveals that the convergence rate of our algorithm depends on the condition number \(m_{k}/M_{k}\) of \(_{k}^{-}[_{k}]_{_{k}^{c}_{k}^{c} _{k}}_{k}^{-}\). Replacing \(_{k}\) with an identify matrix, (_i.e._, using the projected gradient method) results in a rate dependent on the condition number of \([_{k}]_{_{k}^{c}_{k}^{c}}\). The condition number of \(_{k}^{-}[_{k}]_{_{k}^{c}_{k}^{c} _{k}}_{k}^{-}\) could be larger, as \(_{k}\) could approximate \([_{k}]_{_{k}^{c}_{k}^{c}}\) well. Thus, the gradient scaling matrix \(_{k}^{-1}\), _i.e._, \([_{k}^{-1}]_{_{k}^{c}_{k}^{c}}\) in (11), leads our algorithm to converge faster than the projected gradient method.

It is important to note that our algorithm generally does not achieve superlinear convergence, despite the incorporation of second-order information. Superlinear convergence necessitates that the inverse gradient scaling matrix progressively approximate the Hessian at the minimizer . However, this is a condition that our constructed scaling matrix does not meet. Despite this, we should note that constructing a search direction to achieve superlinear convergence proves significantly more computationally demanding than our approach, as it cannot leverage the special structure of the Hessian to decrease the computational load.

## 5 Experimental Results

We conduct experiments on synthetic and real-world data to verify the performance of our algorithm. All experiments were conducted on 2.10GHZ Xeon Gold 6152 machines and Linux OS, and all methods were implemented in MATLAB. State-of-the-art methods for comparisons include:

* BCD : Updates each column/row of primal variable using a nonnegative quadratic program.
* optGL : Similar to BCD but solves nonnegative quadratic programs on the dual variable.
* GGL : Similar to BCD but handles disconnectivity constraints, while BCD and optGL cannot.
* PGD : Projected gradient descent method with backtracking line search.
* APGD : Accelerated projected gradient algorithm with extrapolation step.
* PPA : Inexact proximal point algorithm with Newton-CG method.
* PQN-LBFGS: Projected quasi-Newton method using limited-memory BFGS.

Note that all state-of-the-art methods listed above can converge to the minimizer of Problem (1), and we focus on the comparison of computational time for those methods. To that end, we report the relative error of the objective function value as a function of the run time, which is calculated by

\[|f(_{k})-f(^{})|/|f(^{})|,\] (20)

where \(f\) is the objective function of Problem (1), and \(^{}\) is its minimizer. The \(^{}\) is computed by running the state-of-the-art method GGL  until it converges to a point \(_{k}^{p}\) satisfying

\[[_{k}]_{ij}=0(i,j), [ f(_{k})]_{} ,\| f(^{})]_{^{c}}\|_{ } 10^{-8},\] (21)

where \(:=\{(i,j)[p]^{2}||[_{k}]_{ij}|  10^{-8}\}\). Through the comparison with the sufficient and necessary conditions of the unique minimizer of Problem (1) presented in Theorem 4.1, we can see that any point \(_{k}\) satisfying the conditions in (21) is sufficiently close to the minimizer.

### Synthetic data

We generate independent samples \(^{(1)},,^{(n)}^{p}\) from a multivariate Gaussian distribution with zero mean and precision matrix \(\), where \(^{p}\) is the underlying precision matrix associated with a graph consisting of \(p\) nodes. We use the Barabasi-Albert (BA) model  to generate the support of the underlying precision matrix. To help readers to know well the BA graphs, we present two examples in Figure 1. More details about experimental setting are provided in Appendix A.

#### 5.1.1 Comparisons of search directions

We evaluate the convergence of algorithms with different search directions. Figure 1 (c) demonstrates that our algorithm, using the direction from Proposition 3.3, converges to the minimizer, aligning with our theoretical convergence results in Theorem 4.2. In contrast, the algorithm using iterate (5) and the Newton direction from Proposition 3.1 stops decreasing the objective function value after a few iterations, indicating that this direction cannot be consistently regarded as a descent direction. The algorithm selects the step size through the Armijo rule, _i.e._, it is continually reduced until a decrease in the objective function is achieved.

#### 5.1.2 Comparisons of computational time

We evaluate the computational time of our algorithm and state-of-the-art methods on synthetic datasets, averaging results over 10 realizations. We plot markers every 10 iterations for PGD, APGD, PQN-LBFGS, and FPN, while marking each cycle of updating all columns/rows for BCD-type algorithms (BCD, GGL, and optGL) and each outer iteration for PPA.

Figure 2 compares the computational time of various methods for solving Problem (1) on BA graphs of degree one. Our proposed FPN significantly outperforms all state-of-the-art methods in convergence time for node counts ranging from \(1000\) to \(5000\). BCD and GGL are efficient at \(1000\) nodes, being faster than PGD and APGD, and competitive with PQN-LBFGS and PPA. However, at \(5000\) nodes, BCD and GGL become slower due to the \(O(p^{4})\) operations per cycle required to solve \(p\) nonnegative quadratic programs, leading to rapidly increasing computational costs.

Figure 1: Illustration of BA graphs of degree one (a) and degree two (b) with \(500\) nodes. (c) Convergence comparison between our algorithm and the Newton direction from Proposition 3.1.

Figure 2: Relative errors of the objective function values versus time on BA graphs of degree one.

Figure 3 presents the computational time of different methods on BA graphs of degree two. As with degree one graphs, FPN outperforms state-of-the-art methods in computational time for varying node counts. PQN-LBFGS and FPN require fewer iterations to converge to the minimizer than PGD and APGD, particularly in high dimensions (_e.g._, \(p=5000\)), indicating faster convergence. This is because both PQN-LBFGS and FPN utilize second-order information and approximate Newton direction, overcoming low convergence rates of first-order methods in high-dimensional cases.

Figure 4 (a) and (b) compare the computational time of various algorithms solving Problem (1) with disconnectivity constraints, where FPN consistently converges fastest. (c) evaluates the impact of the estimated precision matrix's sparsity level on run time. BCD, GGL, PPA, and FPN exhibit stable run time across varying sparsity levels, highlighting their robustness regarding regularization parameter settings, while other methods display increased run time as sparsity decreases.

### Real-world data

We perform experiments on two real-world datasets: the _concepts_ dataset and a financial time-series dataset. For the _concepts_ dataset, we compare the computational time of different algorithms solving Problem (1). The experimental results on the financial time-series dataset are provided in Appendix A, where we examine the performance of our method in graph edge recovery.

The _concepts_ dataset , from Intel Labs, comprises 1000 nodes and 218 semantic features, with \(p=1000\) and \(n=218\). Nodes represent concepts like "house," "coat," and "whale," while semantic features are questions like "Can it fly?", "Is it alive?", and "Can you use it?". Responses, collected via Amazon Mechanical Turk, range from "definitely no" to "definitely yes" on a five-point scale.

Figure 5 (a) compares the run time of various algorithms solving Problem (1) on the _concepts_ dataset. Our proposed algorithm converges to the minimizer considerably faster than state-of-the-art algorithms, which is consistent with the observations in synthetic experiments. Note that all compared algorithms can reach the minimizer of Problem (1), and thus learn the same graph.

Figure 4: Relative errors of objective function values versus time on data sets: (a) BA graph of degree one and (b) BA graph of degree two, imposing disconnectivity constraints. (c) Run time versus numbers of nonzero elements in precision matrices across varying regularization parameter values, with the underlying precision matrix having 2998 nonzero elements (indicated by vertical red line).

Figure 3: Relative errors of the objective function value versus time on BA graphs of degree two.

Figure 5 (b) displays a connected subgraph illustrated by the minimizer of Problem (1). Interestingly, it is observed that the learned graph forms a semantic network, where related concepts are closely connected. For instance, insect concepts such as "bee", "butterfly", "flea", "mosquito", and "spider" are grouped together, while human-related concepts like "baby", "husband", "child", "girls", and "man" form another group. Moreover, the network connects "penguin" closely to birds like "owl" and "crow" and sea animals like "goldfish" and "seal", highlighting its aquatic bird nature. Overall, the learned network effectively captures concept relationships.

## 6 Conclusions and Discussions

In this paper, we have introduced a fast projected Newton-like method for estimating precision matrices under \(_{2}\) constraints. Our algorithm, leveraging the two-metric projection method, stands out from existing BCD and PPA-type approaches for addressing the target problem. The proposed algorithm is not only straightforward to implement but also efficient in terms of computation and memory usage. We have provided theoretical convergence analysis and conducted extensive experiments, which clearly demonstrate the superior efficiency of our algorithm in computational time, outperforming state-of-the-art methods. Moreover, we have observed significant performance of our method in terms of _modularity_ value on the learned financial time-series graphs.

Finally, we discuss the limitations of our paper. Our algorithm is proven to converge to the minimizer without any assumptions; however, we require Assumption 4.3 to establish support set convergence in finite iterations and to determine the convergence rate. This assumption is relatively mild, as Theorem 4.1 shows that the minimizer \(}\) must satisfy \([ f(})]_{ij} 0\) for each \((i,j)\). The only additional requirement in Assumption 4.3 is the strictness of this inequality. However, the conditions for ensuring this strictness remain unclear. As this assumption is equivalent to the strict complementary slackness condition in optimization theory, exploring verifiable conditions to guarantee Assumption 4.3 could enrich our algorithm's insights.

## 7 Acknowledgements

This work was supported by the Hong Kong Research Grants Council GRF 16207820, 16310620, and 16306821, the Hong Kong Innovation and Technology Fund (ITF) MHP/009/20, and the Project of Hetao Shenzhen-Hong Kong Science and Technology Innovation Cooperation Zone under Grant HZQB-KCZYB-2020083. We would also like to thank the anonymous reviewers for their valuable feedback on the manuscript.

Figure 5: (a) Relative errors of the objective function values versus time for different algorithms in solving Problem (1) on the _concepts_ data set, consisting of 1000 nodes. (b) The connected subgraph illustrated by the minimizer on the _concepts_ data set, which consists of 132 nodes.