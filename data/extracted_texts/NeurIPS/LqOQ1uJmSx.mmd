# Compositional Generalization from First Principles

Thaddaus Wiedemer\({}^{1,2,3}\)

Equal contribution \({}^{}\)Equal supervision

Prasanna Mayilvahanan\({}^{1,2,3}\)

Equal contribution \({}^{}\)Equal supervision

Matthias Bethge\({}^{1,2}\)

Equal contribution \({}^{}\)Equal supervision

 Wieland Brendel\({}^{2,3}\)

\({}^{1}\)University of Tubingen \({}^{2}\)Tubingen AI Center

\({}^{3}\)Max-Planck-Institute for Intelligent Systems, Tubingen

{thaddaus.wiedemer, prasanna.mayilvahanan}@uni-tuebingen.de

###### Abstract

Leveraging the compositional nature of our world to expedite learning and facilitate generalization is a hallmark of human perception. In machine learning, on the other hand, achieving compositional generalization has proven to be an elusive goal, even for models with explicit compositional priors. To get a better handle on compositional generalization, we here approach it from the bottom up: Inspired by identifiable representation learning, we investigate compositionality as a property of the data-generating process rather than the data itself. This reformulation enables us to derive mild conditions on only the support of the training distribution and the model architecture, which are sufficient for compositional generalization. We further demonstrate how our theoretical framework applies to real-world scenarios and validate our findings empirically. Our results set the stage for a principled theoretical study of compositional generalization.

## 1 Introduction

_Systematic compositionality_ is the remarkable ability to utilize a finite set of known components to understand and generate a vast array of novel combinations. This ability, referred to by Chomsky  as the "_infinite use of finite means_", is a distinguishing feature of human cognition, enabling us to adapt to diverse situations and learn from varied experiences.

It's been a long-standing idea to leverage the compositional nature of the world for learning. In object-centric learning, models learn to isolate representations of individual objects as building blocks for complex scenes. In disentanglement, models aim to infer factors of variation that capture compositional and interpretable aspects of their inputs, for example hair color, skin color, and gender for facial data. So far, however, there is little evidence that these methods deliver substantially increased learning efficacy or generalization capabilities (Schott et al. , Montero et al. ). Across domains and modalities, machine learning models still largely fail to capture and utilize the compositional nature of the training data (Lake and Baroni , Loula et al. , Keysers et al. ).

To exemplify this failure, consider a model trained on a data set with images of two sprites with varying position, size, shape, and color overlaid on a black canvas. Given the latent factors, a simple multi-layer neural network can easily learn to reconstruct images containing _compositions_ of these sprites that were covered by the training set. However, reconstruction fails for novel compositions--even if the individual _components_ have been observed before (see Figure 1). Failure to generalize tounseen data in even this simplistic regression setting demonstrates that _compositional generalization_ does not automatically emerge simply because the data is of a compositional nature.

We therefore take a step back to formally study compositionality and understand what conditions need to be fulfilled for compositional generalization to occur. To this end, we take inspiration from identifiable representation learning and define a broad class of data generating processes that are compositional and for which we can prove that inference models can generalize to novel compositions that have not been part of the training set. More precisely, our contributions are as follows:

* We specify _compositional data-generating processes_ both in terms of their function class and latent distributions (Sections 3.1 and 3.2) such that they cover a wide range of assumptions made by existing compositional methods.
* We prove a set of sufficient conditions under which models trained on the data are able to generalize compositionally (Section 3.3).
* We validate our theory in a range of synthetic experiments and perform several ablation studies that relate our findings to empirical methods (Section 4).

## 2 Related Work

Representation learning_Disentanglement_ and _identifiable representation learning_ aim to learn succinct representations that both factorize the data space efficiently and are robust towards distributional changes [8; 9; 10]. However, the expectation that more compositional representations lead to better out-of-distribution (OOD) generalization has not been met, as demonstrated by Schott et al.  and Montero et al. . Although our work does not directly address generalization issues in identifiable representation learning, our setup is directly inspired by it, and we examine data-generating processes similar to [12; 13; 14].

Empirical ApproachesMany empirical methods use compositional priors and claim improved compositional generalization. The problem has been studied especially closely in language [15; 16; 17], but it remains far from being solved [5; 6; 7]. Object-centric learning is another domain in which compositionality plays a major role, and many approaches explicitly model the composition of scenes from object-"slots" [18; 19; 20; 21; 22]. The slot approach is also common in vector-symbolic architectures like  and . For most of these works, however, compositional generalization

Figure 1: **Compositional generalization fails even in regression settings. Left: We train a model \(f\) to reconstruct images containing two sprites given their latent representation (x, y, shape, size, color). Center: In the training set (top row and left column), one sprite is fixed in its base configuration (orange triangle or red circle), while the other is varied randomly (in this example, sprite 1 varies in position, sprite 2 in shape and color). As a result, each sample in the test set (lower right block) can be expressed as a novel _composition_ of known _components_. Right: While the model is able to fit the training data, it fails to _generalize compositionally_ to the test data.**

is not a focal point, and their actual generalization capability remains to be studied. There are also some architectures like transformers , graph neural networks , bilinear models , or complex-valued autoencoders  that have been claimed to exhibit some degree of compositional generalization, but again, principled analysis of their generalization ability is lacking. Our framework can guide the systematic evaluation of these methods. While we use the visual domain as an example throughout this work, our contributions are not tied to any specific data domain or modality.

Theoretical approaches to OOD generalizationThe OOD generalization problem for non-linear models where train and test distributions differ in their densities, but not their supports, has been studied extensively, most prominently by Ben-David and Urner  and Sugiyama et al. . We refer the reader to Shen et al.  for a comprehensive overview. In contrast, compositional generalization requires generalizing to a distribution with different, possibly non-overlapping support. This problem is more challenging and remains unsolved. Ben-David et al.  were able to show that models can generalize between distributions with a very specific relation, but it is unclear what realistic distributions fit their constraints. Netanyahu et al.  also study _out-of-support_ problems theoretically but touch on compositional generalization only as a workaround for general extrapolation. Recently, Dong and Ma  took a first step towards a more applicable theory of compositional generalization to unseen domains, but their results still rely on specific distributions, and they do not consider functions with arbitrary (nonlinear) compositions or multi-variate outputs. In contrast, our framework is independent of the exact distributions used for training and testing, and our assumptions on the compositional nature of the data allow us to prove generalization in a much broader setting.

## 3 A framework for compositional generalization

Notation\([N]\) denotes the set of natural numbers \(\{1,2,...,N\}\). Vector-valued variables (e.g., \(\)) and functions (e.g., \(\)) are written in bold. **I**d denotes the (vector-valued) identity function. We write the support of a distribution \(P\) as \(P\). To express that two functions \(,\) are equal for all points in the support of distribution \(P\), i.e., \(()=()\ P\), we write \(_{P}\ \). Finally, \(}{}\) denotes the total derivative of a vector-valued function \(\) by all its inputs \(\), corresponding to the Jacobian matrix with entries \(}{ x_{j}}\).

### Compositionality

Colloquially, the term "_compositional data_" implies that the data can be broken down into discrete, identifiable components that collectively form the whole. For instance, in natural images, these components might be objects, while in music, they might be individual instruments. As a running illustrative example, we will refer to a simple dataset similar to multi-dSprites , as shown in Figure 1. Each sample in this dataset is a composition of two basic sprites, each with a random position, shape, size, and color, size.

Drawing inspiration from identifiable representation learning, we define compositionality mathematically as a property of the data-generating process. In our example, the samples are generated by a simple rendering engine that initially renders each sprite individually on separate canvases. These canvases are then overlaid to produce a single image featuring two sprites. More specifically, the rendering engine uses the (latent) properties of sprite one, \(_{1}=(z_{1,},z_{1,},z_{1,},z_{1, },z_{1,})\), to produce an image \(}_{1}\) of the first sprite. The same process is repeated with the properties of sprite two, \(_{2}=(z_{2,},z_{2,},z_{2,},z_{2, },z_{2,})\), to create an image \(}_{2}\) of the second sprite. Lastly, the engine combines \(}_{1}\) and \(}_{2}\) to create the final overlaid rendering \(\) of both sprites. Figure 2 demonstrates this process.

In this scenario, the individual sprite renderers carry out the bulk of the work. In contrast, the composition of the two intermediate sprite images \(}_{1},}_{2}\) can be formulated as a simple pixel-wise operation (see Appendix B.1 for more details). The rendering processes for each sprite are independent: adjusting the properties of one sprite will not influence the intermediate image of the other, and vice versa.

We posit that this two-step generative procedure--the (intricate) generation of individual components and their (simple) composition into a single output--is a key characteristic of a broad class of compositional problems. If we know the composition function, then understanding the basic elements (for example, the individual sprites) is enough to grasp all possible combinations of sprites in the dataset. We can thus represent any latent variable model \(:\), which maps a latent vector \(\) to a sample \(\) in the observation space \(\), as a two-step generative process.

**Definition 1** (Compositional representation).: \(\{,_{1},,_{K},_{1},, _{K},}_{1},,}_{K}\}\) is a _compositional representation_ of function \(\) if

\[()=_{1}(_{1}),...,_{K}(_{K}) =_{1}_{K},\] (1)

where \(_{i}\) denotes the canonical projection of \(\) onto \(_{i}\). We refer to \(_{k}:_{k}}_{k}\) as the _component functions_, to \(}_{1},,}_{K}\) as the (hidden) component spaces, and to \(:}_{1}}_{K} \) as the _composition function_.

Note that in its most general form, we do not require the component functions to be identical or to map to the same component space. The compositional representation of a function \(\) is also not unique. For instance, any \(\) possesses a trivial compositional representation given by \(\{,,,\}\) (for the sake of clarity, we will omit the explicit mention of the latent factorization and component spaces henceforth). We will later establish conditions that must be met by at least one compositional representation of \(\).

Our definition of compositionality naturally aligns with various methods in the fields of identifiability, disentanglement, or object-centric learning. In the decoder of SlotAttention , for example, each component function is a spatial broadcast decoder followed by a CNN, and the composition function is implemented as alpha compositing. Frady et al.  model the component functions as element-wise multiplication of high-dimensional latent codes, which are then composed through a straightforward sum. A similar approach is chosen by Vankov and Bowers , except that interactions between components are modeled using matrix multiplication.

### Compositional Generalization

The model in Figure 1 was trained supervisedly, i.e., it was trained to reconstruct samples \(\) given the ground-truth latent factors \((_{1},_{2})\) for each sprite (see Section 4 for more details). We denote this model as \(}\), indicating that it is meant to replicate the ground-truth generating process \(\) of the data. The model \(}\) indeed learned to fit \(\) almost perfectly on the training distribution \(P\), but failed to do so on the test distribution \(Q\).

Figure 3: **Compositional support** (Definition 2). **A-D**: Distribution \(P\) (blue) has _compositional support_ w.r.t. to the entire latent space if it has full support over the marginals. **E**: Gaps in the support require the model to interpolate/extrapolate rather than generalize compositionally. **F**: The support of the joint needs to be in an open set.

Figure 2: **Compositional representation of a function** (Definition 1). The _component functions_\(_{k}\) map each _component latent_\(_{k}\) to an intermediate component representation \(}_{k}\). The _composition function_\(\) composes all component representations into a final data point \(\).

This failure is surprising because the test samples only contain sprites already encountered during training. The novelty lies solely in the combination of these sprites. We would expect any model that comprehends the compositional nature of the dataset to readily generalize to these test samples.

This compositional aspect of the generalization problem manifests itself in the structure of the training and test distribution. In our running example, the model was trained on samples from a distribution \(P\) that contained all possible sprites in each slot but only in combination with one base sprite in the other slot (illustrated in Figure 3A). More formally, the support of \(P\) can be written as

\[P=\{(_{1}_{1},_{2} _{2})|_{1}=_{1}^{0}_{2}=_{2}^{0}\},\] (2)

where \(_{k}^{0}\) denotes the base configuration of a sprite (e.g., the orange triangle and red square in the samples shown in Figure 1).

The test distribution \(Q\) is a uniform distribution over the full product space \(_{1}_{2}\), i.e., it contains all possible sprite combinations. More generally, we say that a generalization problem is compositional if the test distribution contains only components that have been present in the training distribution, see Figure 3. This notion can be formalized as follows based on the support of the marginal distributions:

**Definition 2** (Compositional support).: Given two arbitrary distribution \(P,Q\) over latents \(=(_{1},...,_{K})=_{1} _{K}\), \(P\) has _compositional support_ w.r.t. \(Q\) if the support over all marginals \(P_{_{k}},_{_{k}}\) is the same:

\[P_{_{k}}=Q_{_{k}} _{k} k[K].\] (3)

Clearly, _compositional generalization_ requires compositional support. If regions of the test latent space exist for which a component is not observed, as in Figure 3E, we can examine a model's generalization capability, but the problem is not compositional. Depending on whether the gap in the support is in the middle of a latent's domain or towards either end, the generalization problem becomes an _interpolation_ or _extrapolation_ problem instead, which are not the focus of this work.

### Sufficient conditions for compositional generalization

With the above setup, we can now begin to examine under what conditions compositional generalization can be guaranteed to occur.

To make this question precise, let us assume for the moment that sprites don't occlude each other but that they are just summed up in pixel space. Then the compositional representation of the generative process is simply \(\{(),_{1},_{2}\}\), i.e.

\[()=_{1}(_{1})+_{2}(_{2}).\] (4)

The question becomes: Given training samples \((,)\) from \(P\), can we train a model \(}\) that fitting this generative process \(\) on \(P\) also guarantees fitting it on \(Q\)? That is, we are looking for conditions such that the model _generalizes_ from \(P\) to \(Q\):

\[}{}}}{}}.\] (5)

We assume that \(\) is known, so in order to generalize, we must be able to reconstruct the individual component functions \(_{k}\). For the simple case from equation 4, we can fully reconstruct the component functions as follows. First, we note that if \(P\) is in an open set, we can locally reconstruct the hidden Jacobian of \(_{k}\) from the observable Jacobian of \(\) as

\[}{_{k}}()=_ {k}}{_{k}}(_{k}).\] (6)

Since the training distribution contains all possible component configurations \(_{k}\), we can reconstruct the Jacobian of \(_{k}\) in every point \(_{k}\). Then we know everything about \(_{k}\) up to a global offset (which can be removed if there exists a known initial point for integration).

Our goal is to extend this approach to a maximally large set of composition functions \(\). Our reasoning is straightforward if \(\) is the identity, but what if we have occlusions or other nonlinear interactions between slots? What are general conditions on \(\) and the support of the training distribution \(P\) such that we can still reconstruct the individual component functions and thus generalize compositionally?Let us now consider the sprites example with occlusions, where \(_{1}\) renders the background sprite that is occasionally occluded by the foreground sprite rendered by \(_{2}\). Let us also assume that the support of \(P\) is basically a thin region around the diagonal; see Figure 4 (left). In this case, the two sprites are always relatively similar, leading to large overlaps for practically all samples of the training set. It is impossible to reconstruct the full Jacobian of the occluded sprite from a single sample. Instead, we need a set of samples for which the background sprite is the same while the foreground sprite is in different positions; see Figure 4 (right). With sufficient samples of this kind, we can observe all pixels of the background sprite at least once. Then reconstruction of the Jacobian of \(_{1}\) is possible again.

This line of thought brings us to a more general condition on the data-generating process: The composition function \(\) and the support of the training set must be chosen such that the full Jacobian can be reconstructed for each component function and for all component latents. In other words, for each configuration of a given component, \(P\) must be sufficiently large so that it is possible to track how each dimension of the output depends on each dimension of the component representation. We formally define the concept of _sufficient support_ below. Note that whether the support of \(P\) is sufficient or not depends on the choice of composition function \(\); see Appendix C for examples.

**Definition 3** (Sufficient support).: A distribution \(P\) over latents \(=(_{1},...,_{K})\), has _sufficient support_ w.r.t. a compositional representation of a function \(\), if \(P\) is in an open set and for any latent value \(_{k}^{*}\), there exists a finite set of points \(P^{}(,k)\{P| _{k}=_{k}\}\) for which the sum of total derivatives of \(\) has full rank. That is,

\[_{ P^{}(,k)} {}{_{k}} {}()=M,\] (7)

where \(M\) is the dimension of the component space \(}_{k}^{M}\).

We are now ready to state our main theorem, namely that if \(,}\) share the same composition function and if \(P\) has compositional and sufficient support, then the model \(}\) generalizes to \(Q\) if it matches the ground-truth data-generating process \(\) on \(P\).

**Theorem 1**.: _Let \(P\), \(Q\) be arbitrary distributions over latents \(=(_{1},...,_{K})\). Let \(,}\) be functions with compositional representations in the sense of definition 1 that share \(\{,_{1},...,_{K}\}\), but use arbitrary \(\{_{1},...,_{K},}_{1 },...,}_{K}\},\{}_{1},..., {}_{K},}_{1},...,}_{K}\}\)._

_Assume the following assumptions hold:_

1. \(,_{k},}_{k}\) _are differentiable,_ \(\) _is Lipschitz in_ \(\)_, and_ \(\) _is continuous in_ \(\)_._
2. \(P\) _has_ compositional support _w.r.t._ \(Q\) _in the sense of definition_ 2_._
3. \(P\) _has_ sufficient support _w.r.t._ \(\) _in the sense of definition_ 3_._
4. _There exists an initial point_ \(^{0}P\) _such that_ \((^{0})=}( ^{0})\)_._

_Then \(}\) generalizes to \(Q\), i.e. \(} }\)._

Figure 4: **Sufficient support condition** (Definition 3). For a (compositional) diagonal support, all samples will contain sprites with similar positions, leading to heavy occlusions and making reconstruction of the background sprite impossible (left). Reconstruction of the background sprite is only possible if the support is chosen broad enough, such that the subset of points sharing the same background sprite \(P^{}\) contains samples with sufficient variance in the foreground sample. Specifically, each pixel of the background sprite must be observable at least once (right).

The proof follows roughly the intuition we developed above in that we show that the Jacobians of the component functions can be reconstructed everywhere. Bear in mind that this is simply a construction for the proof: The theorem holds whenever \(}\) fits the output of \(\) on the training distribution \(P\), which we can achieve with standard supervised training and without access to the ground-truth Jacobians. It should also be emphasized that since the compositional representation is not unique, the theorem holds if there exists at least one for which the assumptions are fulfilled. Note also that the initial point condition (A4) is needed in the proof, but in all practical experiments (see below), we can generalize compositionally without explicit knowledge of that point. We relegate further details to Appendix A.

## 4 Experiments

We validate our theoretical framework on the multi-sprite data. All models were trained for 2000 epochs on training sets of 100k samples using an NVIDIA RTX 2080 Ti; all test sets contain 10k samples. Table 1 summarizes the reconstruction quality achieved on the in-domain (ID) test set (\(P\)) and the entire latent space (\(Q\)) for all experiments.

Motivating experimentWe implement the setup from Figure 1 to demonstrate that a compositional model does indeed generalize if the conditions from Theorem 1 are met. We model the component functions as four fully-connected layers followed by four upsampling-convolution stages, mapping the 5d component latent to \(64 64\) RGB images. For training stability, the composition function is implemented as a soft pixel-wise addition using the sigmoid function \(()\) as

\[=(}_{1})}_{1}+(-}_{1})}_{2},\] (8)

which allows component 1 to occlude component 2. We contrast this to a non-compositional _monolithic_ model, which has the same architecture as a single component function (with adjusted layer sizes to match the overall parameter count of the compositional model). Both models are trained on samples \((,)\) from the training set using an MSE reconstruction loss. We show that both models have the capacity to fit the data by training on random samples covering the entire latent space (Table 1, **#1,2**). We then train on a distribution with orthogonal support as in equation 2, albeit with two planes for the foreground component to satisfy the sufficient support condition (Definition 3) as explained in Figure 4. Both models can reconstruct ID samples, but only the compositional model generalizes to the entire latent space (Table 1, **#3,4**).

Flexible compositional supportNext, we demonstrate the variety of settings that fulfill the compositional support assumption as illustrated in Figure 3B and C. To this end, we repeat the experiment on training sets \(P\) sampled from (i) a normal distribution with orthogonal support (Table 1, **#5**) and (ii) a uniform distribution over a diagonal support chosen broad enough to satisfy the sufficient support condition (Table 1, **#6**; see also Appendix C for details on how the support was chosen). The model generalizes to the entire latent space in both settings. Since the generalization performance is already close to the performance ceiling, broadening the support of both distributions (Table 1, **#7,8**) does not further increase performance.

Violating ConditionsFinally, we look at the effect of violating some conditions.

* **Gaps in support** (Table 1, **#9**) Gaps in the support of the training set such that some component configurations are never observed (Figure 3E) violate the compositional support condition (Definition 2). While the overall reconstruction performance only drops slightly, visualizing the reconstruction error over a 2d-slice of the latent space in Figure 5 illustrates clearly that generalization fails exactly where the condition is violated.
* **Insufficient training variability** (Table 1, **#10**) Reducing the width of the diagonal support violates the sufficient support condition (Definition 3) as soon as some parts of the background component are always occluded and can not be observed in the output anymore (Compare Appendix C for details). We can clearly see that reconstruction performance on the entire latent space drops significantly as a result.
* **Collapsed Composition Function** (Table 1, **#11**) Changing the output of each component function from RGB to RGBa and implementing the composition as alpha compositing yields a model that is still compositional, but for which no support can satisfy the sufficient support condition since the derivative of transparent pixels will always be zero and the Jacobian matrix can therefore never have full rank (see Appendix B.1 for more details). However, we observe that the model still generalizes to the entire latent space and achieves even lower reconstruction error than the original model. This emphasizes that what we present are merely _sufficient_ conditions. We include this experiment to motivate future work to find weaker conditions.

## 5 Discussion

We presented a first step and a framework to study compositional generalization in a more principled way. Clearly, there remain many open questions and limitations that we leave for future work.

Supervised settingWe only studied a supervised regression setting in which the model has access to the ground-truth latents of each training sample. Or own findings underlined the results of previous works, e.g., Schott et al.  that compositional generalization is not trivial even in this setting. Ultimately, we are of course interested in the unsupervised setting akin to what is typically studied in identifiable representation learning. The unsupervised setting comes with inherent ambiguities as the

  
**\#** & **Train Set** & **Model** & \(R^{2}\)**ID**\(\) & \(R^{2}\)**all**\(\) & \( R^{2}\)\(\) \\ 
1 & Random & Monolithic & \(0.931_{+5.8e-4}\) & \(0.931_{+5.8e-4}\) & \(0.000_{+8.2e-4}\) \\
2 & Random & Compositional & \(0.957_{+1.0e-3}\) & \(0.957_{+1.0e-3}\) & \(0.000_{+1.4e-3}\) \\
3 & Orthogonal & Monolithic & \(0.948_{+1.7e-3}\) & \(-0.500_{+6.7e-2}\) & \(1.448_{+6.7e-2}\) \\
4 & Orthogonal & Compositional & \(0.957_{+6.4e-4}\) & \(0.951_{+1.4e-3}\) & \(0.006_{+1.5e-3}\) \\ 
5 & Ortho. \(\) & Compositional & \(0.957_{+5.5e-4}\) & \(0.951_{+1.0e-3}\) & \(0.006_{+1.1e-3}\) \\
6 & Diagonal & Compositional & \(0.954_{+5.4e-3}\) & \(0.945_{+1.6e-2}\) & \(0.009_{+1.7e-2}\) \\
7 & Ortho. (broad) & Compositional & \(0.959_{+9.7e-4}\) & \(0.954_{+1.3e-3}\) & \(0.005_{+1.6e-3}\) \\
8 & Diag. (broad) & Compositional & \(0.957_{+1.2e-3}\) & \(0.955_{+1.2e-3}\) & \(0.002_{+1.7e-3}\) \\ 
9 & Ortho. (gap) & Compositional & \(0.954_{+1.7e-3}\) & \(0.895_{+7.4e-3}\) & \(0.059_{+7.6e-3}\) \\
10 & Diag. (narrow) & Compositional & \(0.867_{+7.5e-2}\) & \(0.859_{+2.8e-1}\) & \(0.278_{+2.9e-1}\) \\
11 & Orthogonal & Comp. (RGBa) & \(0.984_{+1.8e-4}\) & \(0.979_{+1.4e-4}\) & \(0.005_{+2.3e-4}\) \\   

Table 1: We report the reconstruction quality measured as variance-weighted \(R^{2}\) score (closer to 1 is better) on the in-domain (ID) test set and the entire latent space. As the ID region occupies a tiny fraction of the entire latent space, the difference in performance (\( R^{2}\)) indicates how well a model generalizes OOD. All results are averaged over 5 random seeds.**#1-4** The results demonstrate that a _monolithic_ model fails to generalize in the setup from Figure 1, but a _compositional_ model performs well on the entire latent space. **#5-8** Generalization can occur in a variety of settings that fulfill the sufficient conditions from Theorem 1. **#9,10** Violating the compositional and sufficient support condition prohibits generalization while choosing a more complex function class still works (**#11**). Table 2 in the appendix additionally reports the MSE for all experiments.

Figure 5: Heatmap of the reconstruction error over a \(z_{1,}\)-\(z_{2,}\)-projection of the latent space with overlaid training support (red). Generalization can occur when the support is compositional (left) but fails exactly where the support is incomplete at \(z_{1,}[0.14,0.46]\) (right).

relationship between ground-truth latent space and inferred representations is unknown. No prior works exist that address this _identifiability_ problem when training on a subset \(P\) of the latent space, which makes generalizations guarantees as presented in this work harder to derive. Still, the results in this paper build an important foundation for future studies as sufficient conditions in the supervised setting can be considered necessary conditions in the unsupervised setting.

Jacobian and initial pointThe proof of Theorem 1 utilizes the Jacobian of the ground-truth model. We emphasize again that this construction is necessary only for the proof and does not mean that we require access to the data-generating processes' full Jacobian for training. Similarly, the existence of an initial point \(}\) is a technicality of the proof that is not reflected in the experiments. While it is not yet clear whether it is possible to complete the proof without the initial point condition, we believe there is a self-consistency condition that might alleviate the need for this condition. The experiments thus hint at the existence of alternative proof strategies with relaxed assumptions.

Known composition functionWe also assume the composition function to be known which is approximately true in many interesting scenarios, such as object composition in scenes or the composition of instruments in music. In fact, many structured representation learning approaches like e.g. SlotAttention  incorporate structural components that are meant to mimic the compositional nature of the ground-truth-generating process. In other interesting cases like language, however, the composition function is unknown a priori and needs to be learned. This might be possible by observing how the gradients of \(\) change with respect to a fixed slot, at least if certain regularity conditions are fulfilled.

Inductive biasesSome of the conditions we derived can be relaxed in the presence of certain inductive biases. For example, models with an inductive bias towards shift invariance might be able to cope with certain gaps in the training support (e.g., if sprites are not visible in every position). Similarly, assuming all component functions \(\) to be identical would substantially simplify the problem and allow for much smaller sufficient supports \(P\). The conditions we derived do not assume any inductive bias but are meant to formally guarantee compositional generalization. We expect that our conditions generalize to more realistic conditions as long as the core aspects are fulfilled.

Error boundsOur generalization results hold only if the learned model perfectly matches the ground-truth model on the training distribution. This is similar to identifiable representation learning, where a model must find the global minimum of a certain loss or reconstruction error for the theory to hold. Nonetheless, extending our results towards generalization errors that are bounded by the error on the training distribution is an important avenue for future work.

Broader impactCompositional generalization, once achieved, has the potential to be benefit many downstream applications. By increasing sample and training efficiency, it could help to democratize the development and research of large-scale models. Better generalization capabilities could also increase the reliability and robustness of models but may amplify existing biases and inequalities in the data by generalizing them and hinder our ability to interpret and certify a model's decisions.

## 6 Conclusion

Machine learning, despite all recent breakthroughs, still struggles with generalization. Taking advantage of the basic building blocks that compose our visual world and our languages remains unique to human cognition. We believe that progress towards more generalizable machine learning is hampered by a lack of a formal understanding of how generalization can occur. This paper focuses on compositional generalization and provides a precise mathematical framework to study it. We derive a set of sufficient conditions under which compositional generalization can occur and which cover a wide range of existing approaches. We see this work as a stepping stone towards identifiable representation learning techniques that can provably infer and leverage the compositional structure of the data. It is certainly still a long road toward scalable empirical learning techniques that can fully leverage the compositional nature of our world. However, once achieved, there is an opportunity for drastically more sample-efficient, robust, and human-aligned machine learning models.

## Author contributions

The project was led and coordinated by TW. TW and PM jointly developed the theory with insights from WB. TW implemented and conducted the experiments with input from PM and WB. TW led the writing of the manuscript with help from WB, PM, and MB. TW created all figures with comments from PM and WB.