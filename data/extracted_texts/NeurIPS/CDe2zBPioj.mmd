# DropEdge not Foolproof: Effective Augmentation Method for Signed Graph Neural Networks

Zeyu Zhang\({}^{1,2}\), Lu Li\({}^{2}\), Shuyan Wan\({}^{4}\), Sijie Wang\({}^{3}\),

Zhiyi Wang\({}^{2}\), Zhiyuan Lu\({}^{2}\), Dong Hao\({}^{4}\), Wanli Li\({}^{1,2}\)

\({}^{1}\)Engineering Research Center of Intelligent Technology for Agriculture, Ministry of Education

\({}^{2}\)College of Informatics, Huazhong Agricultural University, Wuhan, China

\({}^{3}\)The University of Auckland, \({}^{4}\)University of Electronic Science and Technology of China

zhangzeyu@mail.hzau.edu.cn, lu123@webmail.hzau.edu.cn,

wanshuyanzzz@163.com, swan387@aucklanduni.ac.nz,1492487431@qq.com,

1953764760@qq.com,haodong@uestc.edu.cn,liwanli@mail.hzau.edu.cn

Corresponding Author

###### Abstract

Signed graphs can model friendly or antagonistic relations where edges are annotated with a positive or negative sign. Signed Graph Neural Networks (SGNNs) have been widely used for signed graph representation learning. While significant progress has been made in SGNNs research, two issues (i.e., graph sparsity and unbalanced triangles) persist in the current SGNN models. We aim to alleviate these issues through data augmentation (_DA_) techniques which have demonstrated effectiveness in improving the performance of graph neural networks. However, most graph augmentation methods are primarily aimed at graph-level and node-level tasks (e.g., graph classification and node classification) and cannot be directly applied to signed graphs due to the lack of side information (e.g., node features and label information) in available real-world signed graph datasets. Random _DropEdge_ is one of the few _DA_ methods that can be directly used for signed graph data augmentation, but its effectiveness is still unknown. In this paper, we are the first to provide the generalization error bound for the SGNN model and demonstrate from both experimental and theoretical perspectives that the random _DropEdge_ cannot improve the performance of link sign prediction. Therefore, we propose a novel Signed Graph Augmentation framework (**SGA**) tailored for SGNNs. Specifically, SGA first integrates a structure augmentation module to detect candidate edges solely based on network information. Furthermore, SGA incorporates a novel strategy to select beneficial candidates. Finally, SGA introduces a novel data augmentation perspective to enhance the training process of SGNNs. Experiment results on six real-world datasets demonstrate that SGA effectively boosts the performance of diverse SGNN models, achieving improvements of up to 26.2% in F1-micro for SGCN on the Slashdot dataset in the link sign prediction task. Code and data are available at [https://github.com/Alex-Zeyu/SGA](https://github.com/Alex-Zeyu/SGA).

## 1 Introduction

As social networks continue to gain widespread popularity, they foster a multitude of interactions among individuals, which are later documented within social graphs . While many of these social interactions denote positive connections, such as liking, trust, and friendship, there are alsoinstances of negative interactions, encompassing feelings of hatred, distrust, and more. For example, Slashdot , a tech-related news website, allows users to tag other users as either 'friends' or 'foes'. Graphs that incorporate positive and negative interactions or links are commonly termed _signed graphs_. In recent years, there has been a growing interest among researchers in exploring network representation within the context of signed graphs . Most of these methods are combined with Graph Neural Networks (GNNs) , and are therefore collectively referred to as _Signed Graph Neural Networks_ (SGNNs) . This endeavor focuses on acquiring low-dimensional representations of nodes, with the ultimate goal of facilitating subsequent network analysis tasks, especially _link sign prediction_.

Despite increasing interest in SGNNs in recent years, two issues remain unresolved. First, real-world signed graph datasets are exceptionally sparse (see Table 5 from Appendix H). The sparsity of signed graphs makes downstream tasks challenging. As shown in **Issue 1** (from Figure 1), without additional structure information or side information, predicting the edge sign between nodes \(v_{j}\) and \(v_{k}\) in the test set is difficult. However, this changes with the introduction of extra edges (\(e_{il}\)) through data augmentation. Second, according to the analysis in , SGNNs cannot learn proper representations for nodes from unbalanced triangles. The intuitive understanding is as follows: as shown in **Issue 2**(c) (from Figure 1), there is a negative relationship between node \(v_{i}\) and node \(v_{j}\) in a one-hop path, while through a two-hop path via node \(v_{k}\), it becomes a positive relationship. In other words, the relationship between node \(v_{i}\) and node \(v_{j}\) is uncertain, which complicates the task of SGNNs in learning representations for these three nodes. Furthermore, we notice that the proportion of unbalanced triangles is considerable (see Table 3).

One promising approach to alleviate the aforementioned issues in SGNNs is data augmentation (_DA_) which has been well studied in computer vision  and natural language processing . Recently, significant advances have been made in graph augmentation , including node perturbation , edge perturbation , and subgraph sampling . However, current graph augmentation methods cannot be directly applied to signed graphs for the following reasons: 1) Some methods  require side information (e.g., node features and labels), which are often absent in real-world signed graph datasets that contain only structural information. 2) Random structural perturbation-based enhancement methods  cannot improve SGNN performance. As shown in Figure 2, random _EdgeDrop_ cannot stably improve SGCN performance. For more experimental results on data augmentation methods based on random structural perturbations, please refer to the Appendix A. In addition, we take a first step in developing a deeper theoretical understanding of SGNN models and deriving the generalization error bound of the SGCN. Based on this analysis, we further demonstrate that randomly deleting edges increases the generalization error bound of SGNN, and therefore it is not an effective enhancement method for SGNN (see Section 4). In summary, it is necessary to design a new _DA_ method specifically for SGNNs.

Overall, the designed signed graph augmentation method should address the two common obstacles encountered by popular SGNN models:

1. Exploring new structural information using only network information.
2. Alleviate the negative impact of unbalanced triangles on SGNNs.

Figure 1: Green and red lines represent positive and negative edges, resp. Solid lines represent edges in the training set, while dashed lines represent edges in the test set.

Figure 2: Effectiveness of random EdgeDrop (SGCN  as backbone model) on link sign prediction performance with six real-world signed graph datasets.

To address the aforementioned obstacles, we propose a novel Signed Graph Augmentation framework, **SGA**. For the **first** obstacle, we use a classic SGNN model, such as SGCN  to discover candidate samples. The nodes of a signed graph are first projected into the embedding space. In the embedding space, following the principles of the extended structural balance theory , we interpret the relationships between closely proximate nodes as potential positive edges, whereas the relationships between more distant nodes are considered as potential negative edges. The newly added edges are treated as candidate samples (i.e., edges). To overcome the **second** obstacle, we approach it from two perspectives. _Foremost_, we attempt to reduce the number of existing unbalanced triangles. The candidate samples yield two outcomes: creating new edges or modifying the sign of existing edges. These operations do not reduce the number of training samples, which is consistent with the results of the theoretical analysis (see Sect. 4). Instead of directly incorporating the candidate samples into the training set, we analyze them beforehand. Only candidate samples that do not introduce new unbalanced triangles are retained. _Next,_, we aim to reduce the training weight of edges that belong to unbalanced triangles. To achieve this, we introduce a new perspective on data augmentation, namely edge difficulty scores (see Def. 3.3). Based on this, we design a curriculum learning training strategy tailored for SGNNs, aiming to decrease the training weight of edges with high difficulty scores and increase the training weight of edges with low difficulty scores.

To evaluate the effectiveness of SGA, we perform extensive experiments on six real-world datasets, i.e. Bitcoin-alpha, Bitcoin-otc, Epinions, Slashdot, Wiki-elec, and Wiki-RfA. We verify that our proposed SGA framework can improve the performance of the baseline models. The results of the experiment show that SGA improves the accuracy of the prediction of link signs of five base models, including two unsigned GNN models (GCN  and GAT ) and three signed GNN models (SGCN , SiGAT  and GS-GNN ) (see Table 1 and Table 6). SGA boosts up to 14.8% in terms of AUC for SGCN on Wiki-RfA, 26.2% in terms of F1-binary, 32.3% in terms of F1-micro, and 24.7% in terms of F1-macro for SGCN on Slashdot in link sign prediction, at best. These experiment results demonstrate the effectiveness of SGA.

**Limitations**. Our data augmentation method utilizes the conclusions from SGNN representation limitation based on balance theory . However, it is well known that balance theory cannot model all signed graph formation patterns, as discussed in the paper . Therefore, for real-world datasets that do not strongly conform to balance theory, our data augmentation may be less effective. Additionally, we have only validated our method on the primary downstream task of link sign prediction in signed graphs. Some works [33; 34] consider the clustering task for signed graphs, but these primarily use synthetic datasets and there are no real-world datasets available yet, which is why we have not conducted tests on them.

Overall, our contributions are summarized as follows:

* We are the first to provide the generalization error bound for the SGNN model. Based on this, we theoretically demonstrate the random _DropEdge_ method, which is suitable for node classification and graph classification, is not applicable to edge-level task (i.e., link sign prediction).
* We propose a novel signed graph augmentation framework that alleviates the two issues (i.e., sparsity and unbalanced triangles) widely existing in SGNNs.
* Extensive experiments on six real-world datasets with five backbone models demonstrate the effectiveness of our framework.

## 2 Problem Statement

A _signed graph_ is defined as \(=(,^{+},^{-})\), where \(=\{v_{1},,v_{||}\}\) represents the set of nodes, and \(^{+}\) and \(^{-}\) denote the positive and negative edges, respectively. Each edge \(e_{ij}^{+}^{-}\) connecting two nodes \(v_{i}\) and \(v_{j}\) can be either positive or negative, but not both, meaning that \(^{+}^{-}=\). We use \((e_{ij})\{+,-\}\) to denote the _sign_ of \(e_{ij}\). The structure of \(\) is represented by the adjacency matrix \(A^{||||}\), where each entry \(A_{ij}\{1,-1,0\}\) signifies the sign of the edge \(e_{ij}\). It's important to note that, unlike unsigned graph datasets, signed graphs typically do not provide node features, meaning there is no feature vector \(x_{i}\) associated with each node \(v_{i}\).

_Positive_ and _negative neighbors_ of \(v_{i}\) are denoted as \(^{+}_{i}=\{v_{j} A_{ij}>0\}\) and \(^{-}_{i}=\{v_{j} A_{ij}<0\}\), respectively. Let \(_{i}=^{+}_{i}^{-}_{i}\) be the set of neighbors of node \(v_{i}\). \(_{3}\) represents the set of _triangles_ in the signed graph, i.e., \(_{3}=\{\{v_{i},v_{j},v_{k}\} A_{ij}A_{jk}A_{ik} 0\}\). A triangle \(\{v_{i},v_{j},v_{k}\}\) is called _balanced_ if \(A_{ij}A_{jk}A_{ik}>0\), and is called _unbalanced_ otherwise.

**Problem Definition**: \(D_{}\) refers to the set of train samples (edges) and \(D_{}\) refers to the set of test samples. When only given \(D_{}\), our purpose is to design a graph augmentation strategy \(:(D_{})(D^{}_{},)\), where \(D^{}_{}\) refers to augmented train edge set and \(\) refers to the newly generated edge features (i.e., edge difficulty score).

## 3 Proposed Method

The overall framework of SGA is shown in Figure 3, which aims to augment training samples (i.e., edges) from a structure perspective (edge manipulation) to side information (edge feature). SGA mainly encompasses three key elements: 1) generating new training candidate samples, 2) selecting beneficial candidate samples, and 3) introducing a new feature (i.e., edge difficulty score) for training samples. For the specific procedural details of each part, please refer to Appendix C.

### Generating Candidate Training Samples

Real-world signed graph datasets are extremely sparse (see Table 2) with many uncovered edges. In this part, we attempt to uncover the potential relationships between nodes. We first use a SGNN model, e.g., SGCN , as the encoder to project nodes from topological space to embedding space. Here, the node representations are updated by aggregating information from different types of neighbors as follows:

For the first aggregation layer \(=1\):

\[& H^{pos(1)}=(^{pos(1)}[A^ {+}H^{(0)},H^{(0)}])\\ & H^{neg(1)}=(^{neg(1)}[A^{-}H^{(0)},H^ {(0)}]) \]

For the aggregation layer \(>1\):

\[& H^{pos()}=(^{pos()} [A^{+}H^{pos(-1)},A^{-}H^{neg(-1)},H^{pos(-1)}])\\ & H^{neg()}=(^{neg()}[A^{+}H^{ neg(-1)},A^{-}H^{pos(-1)},H^{neg(-1)}]), \]

where \(H^{pos()}(H^{neg()})\) represents the positive (negative) segment of representation matrix at the \(\)th layer. \(A^{+}(A^{-})\) represents the row normalized matrix of the positive (negative) part of the adjacency matrix \(A\). \(^{pos()}(^{neg()})\) denotes learnable parameters of the positive (negative) part, and \(()\) is the activation function ReLU. \([.]\) is the concatenation operation. After conducting message-passing for \(L\) layers, the final node representation matrix is \(Z=H^{(L)}=[H^{pos(L)},H^{neg(L)}]\). For node \(v_{i}\), the node embedding is \(Z_{i}\). As we wish to classify whether a pair of nodes has a positive, negative, or no edge between them. We train a multinomial logistic regression classifier (MLG) (as in ). The training loss is as follows:

Figure 3: The overall process of SGA. Green lines represent positive edges and red lines represent negative edges.

\(^{}\) refers to the parameter of the MLG classifier. Using this classifier, for any two nodes \(v_{i}\), \(v_{j}\), we can calculate the probability of forming a positive or negative edge between any two nodes, denoted as \(Pr_{e_{ij}}^{pos}\) and \(Pr_{e_{ij}}^{neg}\). We set up four probability threshold hyper-parameters, namely the probability threshold for adding positive edges (\(_{add}^{+}\)), the probability threshold for adding negative edges (\(_{add}^{-}\)), the probability threshold for deleting positive edges (\(_{del}^{+}\)) and the probability threshold for deleting negative edges (\(_{del}^{-}\)). Subsequently, we employ the following strategy to generate candidate training samples:

* \( v_{i},v_{j}\), if \(Pr_{e_{ij}}^{pos}>_{add}^{+} Pr_{e_{ij}}^{neg}>_{add}^{-}\), then \(D_{}^{}\{(v_{i},v_{j},(e_{ij}))\}\);
* \( v_{i},v_{j}\), if \((v_{i},v_{j},(e_{ij})) D_{}\), \(A_{ij}>0\), \(Pr_{e_{ij}}^{pos}<_{del}^{+}\), then \(D_{}^{}\{(v_{i},v_{j},(e_{ij}))\}\);
* \( v_{i},v_{j}\), if \((v_{i},v_{j},(e_{ij})) D_{}\), \(A_{ij}<0\), \(Pr_{e_{ij}}^{neg}<_{del}^{-}\), then \(D_{}^{}\{(v_{i},v_{j},(e_{ij}))\}\).

\(D_{}^{}\) and \(D_{}^{}\) refer to the candidate training set for adding edges and the candidate training set for deleting edges.

### Selecting Beneficial Candidate Training Samples

After obtaining candidates, we do not merge them into the training set directly. Instead, we select the beneficial portions based on some rules. According to , it proves SGNNs cannot learn proper representations from unbalanced triangles (see Figure 1). The intuitive insight from this conclusion for signed graph augmentation is that beneficial candidates should not lead to new unbalanced triangles. Therefore, after generating candidate training set \(D_{}^{}\) and \(D_{}^{}\), we need to discern which operations are beneficial or not. Considering that removing edges will not introduce new unbalanced triangles, it can be directly applied to the training set. However, adding edges may potentially introduce unbalanced triangles, so it needs to be analyzed whether it should be applied to the training set. The specific criteria are as follows:

* \((v_{i},v_{j},(e_{ij})) D_{}^{ }\), \(D_{}\{(v_{i},v_{j},(e_{ij}))\}\);
* \((v_{i},v_{j},(e_{ij})) D_{}^{ }\), if \((v_{i},v_{j},(e_{ij})) D_{}\), and \( v_{k}_{i}_{j}\), \(((e_{ij})*(e_{ik})*(e_{jk}))>0\), then \(D_{}\{(v_{i},v_{j},(e_{ij}))\}\).

According to the above steps, we have merged the \(D_{}^{}\) and \(D_{}^{}\)into the training set \(D_{}\).

### Introducing New Feature for Training Samples

In this part, we attempt to alleviate the negative impact of unbalanced triangles on SGNNs from another perspective by augmenting a new feature for training samples (i.e., edges), namely edge difficulty score. Intuitively, edges belonging to unbalanced triangles have higher difficulty scores, while those belonging to balanced triangles have lower difficulty scores. Based on the difficulty scores, we design a curriculum learning-based training plan, aiming to reduce the training weights of edges with high difficulty scores, thereby mitigating the negative impact of unbalanced triangles on SGNNs.

We provide a definition of global and local balance degree:

**Definition 3.1**.: The _Global Balance Degree_ of a signed graph is defined by:

\[D_{3}()=_{3}^{+}|}{|_{3}|} \]

where \(_{3}\) represents the set of triangles, \(_{3}^{+}\) represents the set of balanced triangles. \(||\) represents the set cardinal number.

**Definition 3.2** (Local Balance Degree).: For edge \(e_{ij}\), the local balance degree is defined by:

\[D_{3}(e_{ij})=_{3}^{+}(e_{ij})|-|_{3}^{-}(e_{ij})| }{|_{3}^{+}(e_{ij})|+|_{3}^{-}(e_{ij})|} \]where \(_{3}^{+}(e_{ij})\) (\(_{3}^{-}(e_{ij})\)) represents the set of balanced (unbalanced) triangles containing edge \(e_{ij}\). \(||\) represents the set cardinal number.

From Def. 3.2, we can observe that the edge's local balance degree is related to the count of balanced and unbalanced triangles that include this edge. Based on this, we can define the edge difficulty score:

**Definition 3.3** (Edge Difficulty Score).: For edge \(e_{ij}\), the difficulty score is defined by:

\[(e_{ij})=(e_{ij})}{2} \]

where \(D_{3}(e_{ij})\) denotes the local balance degree of edge \(v_{ij}\).

Upon quantifying the difficulty scores for each edge within the training set, a curriculum-based training approach is applied to enhance the performance of the SGNN model. This curriculum is fashioned following the principles outlined in , which enables the creation of a structured progression from easy to difficult. The process entails initially sorting the training set \(\) in ascending order based on their respective difficulty scores. Subsequently, a pacing function \(g(t)\) is used to allocate these edges to distinct training epochs, transitioning from easier to more challenging samples, where \(t\) signifies the \(t\)-th epoch. we use a linear pacing function as shown below:

\[g(t)=(1,_{0}+(1-_{0})*) \]

\(_{0}\) denotes the initial proportion of the easiest examples available, and \(T\) indicates the training epoch at which \(g(t)\) reaches value 1. The process of SGA is detailed in Appendix D.

## 4 Generalization Bound of SGNN

In this section, we are going to prove the generalization error bound for SGNN. Our results show that the generalization performance of the model is affected by the number of edges. A larger number of edges in the training set usually generalizes better, which means that dropout cannot always contribute to improving the model's generalization ability in many situations. For the basic setup and assumptions, please see the Appendix E.

**Main Result.** Under link prediction task, we denote \(A_{D}\) as a learning algorithm trained on dataset \(D\). According to Algorithm 2, we can set \(A_{D}=(f(z_{i},z_{j},w))\), the generalization gap is defined as the difference between training error and test error:

\[_{gen}=E_{A}[R(A_{D_{train}})-R(A_{D_{test}})] \]

\[_{gen}(,,},L) \]

**Theorem 1** (Generalization Gap of SGNN).: \[_{gen} 2_{L}^{x}+_{L}^{y}M(+t _{L}^{x}_{f})}{n_{t}}\] (10)

Here \(\) refers to the infinite norm of the matrix \(Z\), \(\) refers to paradigm of initial weight matrix \(\|w_{init}\|\). \(R()\) is the error function and \(L\) is the loss function. The generalization ability is mainly influenced by scale of the graph(the number of nodes and edges) and the norm of weights matrix. In the main result, \(t\) is the number of iterations in training, \(eta\) is the learning rate, \(_{L}\), \(_{f}\), \(M\) are constants determined by the non-linear activation function, function \(g\) and function \(f\) respectively.

## 5 Experiments

In this section, we commence by assessing the enhancements brought about by SGA in comparison to diverse backbone models for the link sign prediction task. We will answer the following questions:

* **Q1**: Can SGA improve the performance of backbone models? Does SGA effectively alleviate issues related to graph sparsity and the presence of unbalanced triangles?

[MISSING_PAGE_FAIL:7]

Regarding unbalanced triangles, we conduct a statistical analysis, as shown in Table 3. The calculation of balance degree is based on Definition 3.1. From the statistical results, it can be seen that in most cases, SGA indeed reduces the number of unbalanced triangles, improving the balance degree of real-world datasets.

In addition to the statistical results, we also validated the effectiveness of SGA through the case study illustrated in Figure 4. Both of these two cases are from Bitcoin-alpha dataset. Case 1 verifies that SGA, by exploring latent structures, assists SGCN in correctly predicting the sign of edge (\(e_{144,130},e_{130,147}\)) that are originally mispredicted. Case 2 indicates that SGA, by changing the signs of edges (\(e_{67,12}\)) in existing structures, reduces the impact of unbalanced triangles, allowing the model to achieve correct prediction results (\(e_{67,1536}\)).

### Ablation Study (Q2)

In this section, we explore how different parts of SGA, contribute to its overall effectiveness. We do this by testing the SGCN  under various settings:

* **SGCN:** Here, we use the SGCN in its basic form. It works directly on the original graph data without any additional techniques or modifications.
* **+SA (Structure Augmentation, refer to Sec. 3.1 and Sec. 3.2):** SGCN operates on augmented datasets. This augmentation involves the addition or removal of edges from the initial graph.
* **+TP (Training Plan, refer to Sec. 3.3):** SGCN runs on the original graph but with a modified training paradigm. Adopting a curriculum learning approach, we rank edges by their difficulty. The model is then progressively exposed to these edges, transitioning from simpler to more challenging ones as training epochs progress.
* **+SGA(Combining both the structural augmentation and the tailored training plan)** The SGCN runs on augmented graph using a curriculum learning training plan.

Our thorough ablation study, detailed in Table 4 and conducted across six benchmark datasets, reveals several insights:

* **Importance of Structural Augmentation:** This strategy proves crucial for improving model performance. In almost all cases, using only structural augmentation leads to better results than the baseline model, which is trained on the unmodified graph without any specific training strategy.

   Dataset &  &  \\   & \# BT & \# UT & BD (\%) & \# BT & \# UT & BD (\%) \\  Bitcoin-alpha & 52,126 & 6,971 & 88.20 & 63,535 & 5,060 & 92.58 \\ Bitcoin-oc & 75,460 & 9,292 & 89.04 & 72,105 & 9,289 & 88.60 \\ Epinions & 6,286,597 & 516,723 & 92.40 & 6,162,877 & 391,307 & 94.02 \\ Slashdot & 709,417 & 64,190 & 91.70 & 66,378 & 45,268 & 93.72 \\ Wiki-elec & 311,251 & 92,934 & 77.01 & 242,691 & 29,579 & 89.13 \\ Wiki-RfA & 603,753 & 195,532 & 75.54 & 491,458 & 84,840 & 85.38 \\   

Table 3: The balance degree of original datasets and after augmentation. BT refers to balanced triangle, UT refers to unbalanced triangle, BD refers to balance degree (see Def. 3.1).

Figure 4: Case Study of SGA. Note that green lines denote positive edges and red lines denote negative edges.

* **Effect of the Training Plan Alone:** Implementing just the training plan, without other modifications, yields a smaller performance improvement compared to using structural augmentation alone.
* **Combined Advantages of Training Plan and Data Augmentation:** Combining the training plan with structural augmentation often enhances the benefits of each approach, yielding the largest performance gain on most of the datasets.

### Parameter Sensitivity Analysis (Q3)

In this subsection, we perform a sensitivity analysis focusing on six hyper-parameters: \(^{+}_{del}\), \(^{-}_{del}\), \(^{+}_{add}\), \(^{-}_{add}\) (these denote the probability thresholds for adding or removing positive/negative edges); \(T\) represents the number of intervals during the training process where more challenging edges are incrementally added to the training set; and \(_{0}\) designates the initial fraction of the easiest examples. Performance metrics for the SGCN model within the SGA framework, as measured by AUC across various hyper-parameter configurations, is illustrated in Figures 5. F1-binary, F1-macro and F1-micro scores are illustrated in Appendix K.

The figures reveal divergent patterns in AUC and F1 scores based on hyperparameter adjustments, with SGCN showing more significant variations on the Slashdot dataset compared to others. On a broader scale, the AUC is fairly consistent with changes to \(^{+}_{del}\) and \(^{-}_{add}\). Notably, as \(^{-}_{del}\) or \(^{+}_{add}\) rise, there's a tendency for the AUC to augment. Interestingly, AUC initially increases and then experiences a slight dip as \(_{0}\) rises. Regarding the F1 score, it is less sensitive to changes in \(^{-}_{add}\), \(T\), and \(_{0}\), except for the case of the Slashdot dataset. In general, an increase in \(^{-}_{del}\) and \(^{+}_{add}\) boosts the F1 score. However, for \(^{+}_{del}\), the optimal value can differ across datasets, typically lying between 0.1 and 0.4.

## 6 Conclusion

In this paper, we introduce the Signed Graph Augmentation framework (SGA), a novel approach designed to address two prominent issues in existing signed graph neural networks, namely, data

   Dataset & Metric & SGCN & +sGA & +TP & +SGA \\   & AUC & 73.3\(\)0.2 & 79.3\(\)1.1 & 73.5\(\)2.8 & **80.9\(\)2.0** \\  & F1-binary & 90.5\(\)0.8 & **93.8\(\)0.4** & 91.3\(\)1.2 & **92.0\(\)0.7** \\  & F1-micro & 63.4\(\)1.3 & **88.8\(\)0.7** & 84.6\(\)1.9 & 87.2\(\)1.0 \\  & F1-macro & 62.1\(\)1.3 & **60.9\(\)1.0** & 63.1\(\)1.7 & 67.2\(\)0.3 \\   & AUC & 79.4\(\)1.8 & 70.2\(\)0.7 & 79.1\(\)0.0 & **82.1\(\)0.3** \\  & F1-binary & 92.3\(\)1.2 & 84.5\(\)0.7 & 91.3\(\)1.7 & **94.6\(\)0.3** \\  & F1-macro & 86.7\(\)1.9 & 90.2\(\)1.1 & 86.7\(\)2.7 & **90.5\(\)0.4** \\  & F1-macro & 72.0\(\)1.5 & 76.5\(\)1.5 & 72.2\(\)2.0 & **77.3\(\)0.6** \\   & AUC & 65.4\(\)2.4 & 75.9\(\)1.0 & 73.2\(\)1.1 & **77.4\(\)0.4** \\  & F1-binary & 90.5\(\)1.4 & 90.4\(\)1.6 & 87.5\(\)3.5 & **92.2\(\)0.9** \\  & F1-micro & 83.9\(\)2.0 & 84.1\(\)2.4 & 80.1\(\)4.7 &sparsity and unbalanced triangles. This framework has three main components: generating candidate training samples, selecting beneficial candidate training samples, and introducing a new feature (edge difficulty score) for training samples. Based on this new feature, we have designed a curriculum learning framework tailored for SGNNs. Through extensive experiments on benchmark datasets, our SGA framework proves its effectiveness in boosting various models.