# Universal Gradient Descent Ascent Method for Nonconvex-Nonconcave Minimax Optimization

Taoli Zheng

CUHK

tlzheng@se.cuhk.edu.hk

&Linglingzhi Zhu

CUHK

llzzhu@se.cuhk.edu.hk

&Anthony Man-Cho So

CUHK

manchoso@se.cuhk.edu.hk

&Jose Blanchet

Stanford University

jose.blanchet@stanford.edu

&Jiajin Li

Stanford University

jiajinli@stanford.edu

Corresponding author

###### Abstract

Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Most existing algorithms rely on one-sided information, such as the convexity (resp. concavity) of the primal (resp. dual) functions, or other specific structures, such as the Polyak-Lojasiewicz (PL) and Kurdyka-Lojasiewicz (KL) conditions. However, verifying these regularity conditions is challenging in practice. To meet this challenge, we propose a novel universally applicable single-loop algorithm, the doubly smoothed gradient descent ascent method (DS-GDA), which naturally balances the primal and dual updates. That is, DS-GDA with the same hyper-parameters is able to uniformly solve nonconvex-concave, convex-nonconcave, and nonconvex-nonconcave problems with one-sided KL properties, achieving convergence with \((^{-4})\) complexity. Sharper (even optimal) iteration complexity can be obtained when the KL exponent is known. Specifically, under the one-sided KL condition with exponent \((0,1)\), DS-GDA converges with an iteration complexity of \((^{-2\{2,1\}})\). They all match the corresponding best results in the literature. Moreover, we show that DS-GDA is practically applicable to general nonconvex-nonconcave problems even without any regularity conditions, such as the PL condition, KL condition, or weak Minty variational inequalities condition. For various challenging nonconvex-nonconcave examples in the literature, including "Forsaken", "Bilinearly-coupled minimax", "Sixth-order polynomial", and "PolarGame", the proposed DS-GDA can all get rid of limit cycles. To the best of our knowledge, this is the first first-order algorithm to achieve convergence on all of these formidable problems.

## 1 Introduction

In this paper, we are interested in studying nonconvex-nonconcave minimax problems of the form

\[_{x}_{y}f(x,y),\] (P)

where \(f:^{n}^{d}\) is nonconvex in \(x\) and nonconcave in \(y\), and \(^{n}\), \(^{d}\) are convex compact sets. Such problems have found significant applications in machine learning and operation research, including generative adversarial networks [27; 2], adversarial training [44; 53], multi-agentreinforcement learning [16; 48], and (distributionally) robust optimization [6; 19; 38; 25; 7], to name a few.

For smooth functions, one natural idea is to use gradient descent ascent (GDA) , which applies gradient descent on the primal function and gradient ascent on the dual function. However, GDA is originally designed for the strongly-convex-strongly-concave problem, where either primal or dual players can dominate the game. When applying it to the nonconvex-concave case, a so-called two-timescale method can make it converge. In this scenario, the primal player is the dominant player in the game. We can regard this one-step GDA scheme as an inexact subgradient descent on the inner max function \(_{y}f(x,y)\), thus it is necessary for the dual update to be relatively faster than the primal update at each iteration. However, this two-timescale GDA yields a high iteration complexity of \((^{-6})\). To achieve a lower iteration complexity, smoothed GDA (S-GDA) [62; 59] employs the Moreau-Yosida smoothing technique to stabilize the primal sequence. The resulting stabilized sequence can help S-GDA achieve a lower iteration complexity of \((^{-4})\). Alternating Gradient Projection (AGP)  can also achieve this lower iteration complexity by adding regularizers to both primal and dual functions. It is worth noting that the convergence of all these algorithms is heavily contingent on the convexity/concavity of primal/dual functions, leading to asymmetric updates. In the convex-nonconcave scenario, the roles are reversed, and the dual player takes dominance in the game. To apply the aforementioned algorithms, their updates should be modified accordingly. Specifically, for SGDA and AGP, the smoothing and regularized sides also need to be changed to guarantee the optimal convergence rate. However, when dealing with nonconvex-nonconcave problems, no player inherently dominates the other and all existing first-order algorithms cannot be guaranteed to converge to stationary points (see Definition 1), and they can even suffer from _limit cycles_. That is, the generated trajectories of all these algorithms will converge to cycling orbits that do not contain any stationary point of \(f\). Such _spurious_ convergence phenomena arise from the inherent minimax structure of (P) and have no counterpart in pure minimization problems. Conceptually, nonconvex-nonconcave minimax optimization problems can be understood as a seesaw game, which means no player inherently dominates the other. More explicitly, the key difficulty lies in adjusting the primal and dual updates to achieve a good balance. Most existing works address this challenge by adding additional regularity conditions to ensure the automatic domination of one player over the other. Specifically, research works either impose the global Polyak-Lojasiewicz (PL) condition on the dual function \(f(x,)\)[58; 47; 22; 59] or assume the satisfaction of \(\)-dominance condition [29; 30]. Both approaches fall into this line of research, enabling the adoption of algorithms and analysis for nonconvex-concave minimax problems. Although the recent work  extends the PL condition to the one-sided Kurdyka-Lojasiewicz (KL) property, it is still hard to provide the explicit KL exponent, and prior knowledge regarding which side satisfies the KL condition is required to determine the appropriate side to employ extrapolation. If we choose the wrong side, it will result in a slow convergence or even divergence (see Figure 5). On another front, variational inequality (VI) provides a unified framework for the study of equilibrium/minimax problems [46; 36; 26; 60; 45]. However, VI-related conditions are usually hard to check in practice. Hence, the convergence of the existing algorithms all highly rely on prior knowledge of the primal/dual function, which makes it paramount to design a universal algorithm for convex-nonconcave, nonconvex-concave, and nonconvex-nonconcave minimax problems.

We propose a new algorithm called the Doubly Smoothed Gradient Descent Ascent (DS-GDA) algorithm. DS-GDA builds upon S-GDA by applying the Moreau-Yosida smoothing technique to both the primal and dual variables, which allows a better trade-off between primal and dual updates. All hyperparameters, including the stepsize for gradient descent and ascent steps, and extrapolation parameters are carefully and explicitly controlled to ensure the sufficient descent property of a novel Lyapunov function that we introduce in our paper. The carefully selected variables automatically decide the dominant player, thereby achieving the balance of primal and dual updates by the interaction of parameters. Furthermore, the doubly smoothing technique enables the use of a set of symmetric parameters to achieve universality. This stands in sharp contrast to S-GDA, where only primal/dual function is smoothed. Specifically, the regularized function and the primal-dual updates in DS-GDA are inherently symmetric, which provides the possibility of applying the DS-GDA without prior information on the primal and dual functions.

To validate our idea and demonstrate the universality of DS-GDA, we provide a visual representation of the feasible symmetric parameter selections by relating the regularizer to Lipschitz constants and step sizes. This graphical illustration, depicted in Figure 0(a), reveals that numerous parameter settingscan be chosen to guarantee convergence, which showcases the flexibility of DS-GDA. An experiment for a nonconvex-nonconcave problem has also been done to test the efficiency of using symmetric parameters.

We also evaluate the performance of DS-GDA on a range of representative and challenging nonconvex-nonconcave problems from the literature, which violate all known regularity conditions. These include the "Forsaken" example [32, Example 5.2], the "Bilinearly-coupled minimax" example , the "Sixth-order polynomial" example , and the "PolarGame" example . In all cases, DS-GDA successfully escapes limit cycles and converges to the desired stationary point, while other methods either suffer from the recurrence behavior or diverge. Moreover, our algorithm exhibits robustness to parameter selection (see Section 4.2), offering practical flexibility.

To corroborate its superior performance and have a better understanding of its convergence behaviors, we demonstrate that DS-GDA converges to a stationary point for nonconvex-concave, convex-nonconcave, and nonconvex-nonconcave problems that satisfy a one-sided KL property. By employing a single set of parameters, DS-GDA converges with an iteration complexity of \((^{-4})\) across all these scenarios. Remarkably, DS-GDA achieves this without prior verification of these conditions. However, if we have access to a one-sided KL condition or knowledge of the convexity (concavity) of the primal (dual) function, the range of allowable parameters can be expanded. What is more, DS-GDA attains a lower or even optimal iteration complexity of \((^{-2\{2,1\}})\) when the one-sided KL property with exponent \((0,1)\) is satisfied. Notably, these convergence results match the best results for single-loop algorithms when the dual function is concave  or satisfies KL condition . To the best of our knowledge, our work demonstrates, for the first time, the possibility of having a simple and unified single-loop algorithm for solving nonconvex-nonconcave, nonconvex-concave, and convex-nonconcave minimax problems. However, it remains an open question whether convergence results can be derived without any regularity conditions. This question is intriguing and warrants further theoretical investigation of nonconvex-nonconcave minimax problems in the future.

Our main contributions are summarized as follows:

(i) We present DS-GDA, the first universal algorithm for convex-nonconcave, nonconvex-concave, and nonconvex-nonconcave problems with one-sided KL property. A single set of parameters can be applied across all these scenarios, guaranteeing an iteration complexity of \((^{-4})\). With the KL exponent \((0,1)\) of the primal or dual function, we improve the complexity to \((^{-2\{2,1\}})\). Our current convergence analysis achieves the best-known results in the literature.

(ii) We demonstrate that DS-GDA converges on various challenging nonconvex-nonconcave problems, even when no regularity conditions are satisfied. This makes DS-GDA the first algorithm capable of escaping limit cycles in all these hard examples.

## 2 Doubly Smoothed GDA

In this section, we propose our algorithm (i.e., DS-GDA) for solving (P). To start with, we introduce the blanket assumption, which is needed throughout the paper.

**Assumption 1** (Lipschitz gradient): _The function \(f\) is continuously differentiable and there exist positive constant \(L_{x},L_{y}>0\) such that for all \(x,x^{}\) and \(y,y^{}\)_

\[\|_{x}f(x,y)-_{x}f(x^{},y^{})\| L_{x} (\|x-x^{}\|+\|y-y^{}\|),\] \[\|_{y}f(x,y)-_{y}f(x^{},y^{})\| L_{y }(\|x-x^{}\|+\|y-y^{}\|).\]

_For simplicity, we assume \(L_{y}= L_{x}= L\) with \(>0\)._

For general smooth nonconvex-concave problems, a simple and natural algorithm is GDA, which suffers from oscillation even for the bilinear problem \(_{x[-1,1]}_{y[-1,1]}xy\). To address this issue, a smoothed GDA algorithm that uses Moreau-Yosida smoothing techniques is proposed in . Specifically, they introduced an auxiliary variable \(z\) and defined a regularized function as follows:

\[F(x,y,z) f(x,y)+\|x-z\|^{2}.\]

The additional quadratic term smooths the primal update. Consequently, the algorithm can achieve a better trade-off between primal and dual updates. We adapt the smoothing technique to the nonconvex-nonconcave setting, where the balance of primal and dual updates is not a trivial task. To tackle this problem, we also smooth the dual update by subtracting a quadratic term of dual variable and propose a new regularized function \(F:^{n}^{d}^{n}^{d} \) as

\[F(x,y,z,v) f(x,y)+}{2}\|x-z\|^{2}-}{2}\|y-v\|^{2}\]

with different smoothed parameters \(r_{1}>L_{x}\), \(r_{2}>L_{y}\) for \(x\) and \(y\), respectively. Then, our DS-GDA is formally presented in Algorithm 1.

``` Data: Initial \(x^{0},y^{0},z^{0},v^{0}\), stepsizes \(,c>0\), and extrapolation parameters \(0<,<1\)
1for\(t=0,,T\)do
2\(x^{t+1}=_{}(x^{t}-c_{x}F(x^{t},y^{t},z^{t},v^{t}))\);
3\(y^{t+1}=_{}(y^{t}+_{y}F(x^{t+1},y^{t},z^{ t},v^{t}))\);
4\(z^{t+1}=z^{t}+(x^{t+1}-z^{t})\);
5\(v^{t+1}=v^{t}+(y^{t+1}-v^{t})\).
6 end for ```

**Algorithm 1**Doubly Smoothed GDA (DS-GDA)

The choice of \(r_{1}\) and \(r_{2}\) is crucial for the convergence of the algorithm in both theoretical and practical senses. In particular, when \(r_{1}=r_{2}\), it reduces to the _proximal-point mapping_ proposed in  and inexact proximal point method (PPM) is only known to be convergent under certain VI conditions. Even with the exact computation of proximal mapping, PPM will diverge in the absence of regularity conditions . By contrast, with an unbalanced \(r_{1}\) and \(r_{2}\), our algorithm can always converge. The key insight here is to carefully adjust \(r_{1}\) and \(r_{2}\) to balance the primal-dual updates, ensuring the sufficient descent property of a novel Lyapunov function introduced in our paper. In fact, as we will show later in Section 3, \(r_{1}\) and \(r_{2}\) are typically not equal theoretically and practically. The two auxiliary variables \(z\) and \(v\), which are updated by averaging steps, are also indispensable in our convergence proof. Intuitively, the exponential averaging applied to proximal variables \(z\) and \(v\) ensures they do not deviate too much from \(x\) and \(y\), contributing to sequence stability.

We would like to highlight that the way we use the Moreau-Yosida smoothing technique is a notable departure from the usual approach. Smoothing techniques are commonly invoked when solving nonconvex-concave problems to achieve better iteration complexity [62; 40; 59]. However, we target at smoothing both the primal and dual variables with different magnitudes to ensure global convergence.

## 3 Convergence Analysis

The convergence result of the proposed DS-GDA (i.e., Algorithm 1) will be discussed in this section. To illustrate the main result, we first provide the stationarity measure in Definition 1.

**Definition 1** (Stationarity measure): _The point \((,)\) is said to be an (i) \(\)-game stationary point (GS) if_

\[(,_{x}f(,)+_{ }())(,-_{y}f(,)+_{}());\]

(ii) \(\)_-optimization stationary point (OS) if_

\[\|_{_{y}f(,)+_{ }}()-\|.\]

**Remark 1**: _The definition of game stationary point is a natural extension of the first-order stationary point in minimization problems. It is a necessary condition for local minimax point  and has been widely used in nonconvex-nonconcave optimization [21; 37]. We have investigated their relationships in Appendix K._

### Complexity under Nonconvex-(Non)concave Setting

Inspired by [62; 40], we consider a novel Lyapunov function \(:^{n}^{d}^{n}^{d} \) defined as follows:

\[(x,y,z,v) _{}+ _{}+_{ }+_{}+ _{}\] \[=F(x,y,z,v)-2d(y,z,v)+2q(z),\]

where \(d(y,z,v)_{x}F(x,y,z,v)\), \(p(z,v)_{y}d(y,z,v)\), \(q(z)_{v^{d}}p(z,v)\), and \(_{z^{n}}q(z)\). Obviously, this Lyapunov function is lower bounded, that is, \(\). To gain a better understanding of the rationale behind the construction of \(\), it is observed that the Lyapunov function has a strong connection to the updates of the iterations. The primal update corresponds to "primal descent" and gradient ascent in dual variable corresponds to the "dual ascent". The averaging updates of proximal variables could be understood as an approximate gradient descent of \(p(z,v)\) and an approximate gradient ascent of \(g(v)\), resulting in the "proximal descent" and "proximal ascent" terms in the Lyapunov function. Compared with that in [62; 40], we have an additional "proximal ascent" term. It is introduced by the regularized term for dual variable in \(F\) and the update of proximal variable \(v\). Essentially, the "nonconcavity" of \(f(x,)\) brings the additional term. With this Lyapunov function, we can establish the following basic descent property as our first important result.

**Proposition 1** (Basic descent estimate): _Suppose that Assumption 1 holds and \(r_{1} 2L\), \(r_{2} 2 L\) with the parameters_

\[0<c \{)},\},0<\{},}, {1}{5L}\},\] \[0< \{}{360r_{1}+5r_{1}^{2}+(2  L+5r_{1})^{2}},L^{2}}{384r_{1}(+5)( +1)^{2}}\},\] \[0< \{L^{2} },L^{2}}{64r_{2}(+5)}\}.\]

_Then for any \(t 0\),_

\[^{t}-^{t+1} }{32}\|x^{t+1}-x^{t}\|^{2}+}{15}\|y^{t} -y^{t}_{+}(z^{t},v^{t})\|^{2}+}{5}\|z^{t}-z^{t+1}\|^{2}+}{4}\|v^{t}_{+}(z^{t+1})-v^{t}\|^{2}\] \[-4r_{1}\|x(z^{t+1},v(z^{t+1}))-x(z^{t+1},v^{t}_{+}(z^{t+ 1}))\|^{2}.\] (1)

_where \(+1}{c(r_{1}-L)}\) and \(L_{d}(-L}+2) L+r_{2}\). Moreover, we have \(y_{+}(z,v)_{}(y+_{y}F(x(y,z, v),y,z,v))\) and \(v_{+}(z) v+(y(x(z,v),z,v)-v)\) with the following definitions:_ (i)_\(x(y,z,v)_{x}F(x,y,z,v)\),_ (ii)_\(y(x,z,v)_{y}F(x,y,z,v)\),_ (iii)_\(x(z,v)_{x}_{y}F (x,y,z,v)\),_ (iv)_\(v_{v^{d}}P(z,v)\)_._

The lower bound of \(\) by \(\) is established by its construction, so the crux of proving subsequence convergence is to establish the decreasing property of the Lyapunov function. Although Proposition 1 quantifies the variation of the Lyapunov function values between two consecutive iterates, there is a negative error term \(\|x(z^{t+1},v(z^{t+1}))-x(z^{t+1},v^{t}_{+}(z^{t+1}))\|\) that makes the decreasing property of \(\) unclear.

Next, we characterize the negative error term in terms of other positive terms and then exhibit the sufficient descent property by bounding the coefficients. Conceptually, the error term is related to \(\|v^{t}_{+}(z^{t+1})-v(z^{t+1})\|\) by the Lipschitz property of the solution mapping \(x(z,)\). However, \(\|v^{t}_{+}(z^{t+1})-v(z^{t+1})\|\) may not be a suitable surrogate since it includes the information about the optimal solution \(v(z^{t+1})\). Fortunately, with the help of the global KL property or concavity for the dual function (see Assumption 2 and 3), we can bound the negative error term by \(\|v^{t}_{+}(z^{t+1})-v(z^{t+1})\|\) (called the proximal error bound). The explicit form of this bound is provided in the following Propositions 2.

**Assumption 2** (KL property with exponent \(\) of the dual function): _For any fixed point \(x\), the problem \(_{y}f(x,y)\) has a nonempty solution set and a finite optimal value. Moreover, thereexist \(>0\), \((0,1)\) such that for any \(x,y\)_

\[(_{y^{}}f(x,y^{})-f(x,y))^{} (,-_{y}f(x,y)+_{}(y)).\]

**Assumption 3** (Concavity of the dual function): _For any fixed point \(x\), \(f(x,)\) is concave._

**Proposition 2** (Proximal error bound): _Under the setting of Proposition 1 with Assumption 2 or 3, for any \(z^{n},v^{d}\) one has_

(i) KL exponent \((0,1)\):__

\[\|x(z^{t+1},v_{+}^{t}(z^{t+1}))-x(z^{t+1},v(z^{t+1}))\|^{2}_{0}\|v_{+ }^{t}(z^{t+1})-v^{t}\|^{};\]

(ii) Concave:__

\[\|x(z^{t+1},v_{+}^{t}(z^{t+1}))-x(z^{t+1},v(z^{t+1}))\|^{2}_{1}\|v_{ +}^{t}(z^{t+1})-v^{t}\|,\]

_where \(_{0}:=-L)}((1-)}{}+ ^{2}}{r_{2}- L})^{}\) and \(_{1}:=()}{r_{1}-L}( {1-}{}+}{r_{2}- L})\). Here, \(()\) denotes the diameter of the set \(\)._

Armed with Proposition 1 and Proposition 2, we establish the main theorem concerning the iteration complexity of DS-GDA with respect to the above-mentioned standard stationarity measure for (P).

**Theorem 1** (Iteration complexity for nonconvex-(non)concave problems): _Under the setting of Theorem 1 and Proposition 2, for any \(T>0\), there exists a \(t\{1,2,,T\}\) such that_

(i) KL exponent \((,1)\):__\((x^{t+1},y^{t+1})\) _is an_ \((T^{-})\)_-GS and_ \(z^{t+1}\) _is an_ \((T^{-})\)_-OS if_ \((T^{-})\)_;_

(ii) KL exponent \((0,]\):__\((x^{t+1},y^{t+1})\) _is an_ \((T^{-})\)_-GS and_ \(z^{t+1}\) _is an_ \((T^{-})\)_-OS if_ \(}{32r_{1}_{0}(2() )^{-2}}\)_;_

(iii) Concave:__\((x^{t+1},y^{t+1})\) _is an_ \((T^{-})\)_-GS and_ \(z^{t+1}\) _is an_ \((T^{-})\)_-OS if_ \((T^{-})\)_._

Moreover, when the problem (P) equipped with the widely fulfilled semi-algebraic structure  and the dual function satisfies the KL property with \((0,]\), we additionally have the following sequential convergence result of the DS-GDA.

**Theorem 2** (Last-iterate convergence of DS-GDA): _Consider the setting of Theorem 1 and suppose that Assumption 2 holds with \((0,]\). Suppose that \(f(,y)\) is semi-algebraic and \(\), \(\) are semi-algebraic sets. Then, the sequence \(\{(x^{t},y^{t},z^{t},v^{t})\}\) converges to \((x^{*},y^{*},z^{*},v^{*})\), where \((x^{*},y^{*})\) is a GS and \(z^{*}\) is an OS._

### Universal Results

For convex-nonconcave or nonconvex-nonconcave minimax problems in which the primal function satisfies the KL property, analogous results to Theorem 1 can be established. This can be accomplished by introducing an alternative Lyapunov function \(:^{n}^{d}^{n}^{d }\) as follows:

\[(x,y,z,v):=_{}+ _{}+_{ }+-g(v)}_{},\]

where \(h(x,z,v)_{y}F(x,y,z,v)\), \(g(v)_{z^{n}}p(z,v)\), and \(_{v^{d}}g(v)\).

It is worth noting that our Lyapunov function exhibits symmetry with respect to nonconvex-(non)concave problems, since the adjustment only entails interchanging the position between \((d(y,z,v),q(z))\) and \((h(x,z,v),g(v))\). Therefore, similar convergence results as Theorem 1 could be derived without any effort. A more detailed proof can be found in Appendix H.

Based on these results, we are ready to show that our DS-GDA is a universal algorithm. By incorporating the choices of parameters, we can identify a consistent set of parameters that ensures the convergence of DS-GDA in nonconvex-nonconcave, nonconvex-concave, and convex-nonconcave problems. The universal convergence rate is stated as follows:

**Theorem 3** (Universal convergence of DS-GDA): _Without loss of generality, we consider the case where \(=1\), implying \(L_{x}=L_{y}=L\). For convex-nonconcave, nonconvex-concave, and nonconvex-nonconcave minimax problems that satisfy the one-sided KL property, if we further set \(r_{1}=r_{2}=r 20L\), DS-GDA converges provided certain parameter conditions are met:_

\[-14Lr+r^{2}}+L^{2}-8Lr+r^{2}}{12Lr^{2}} c =},\] \[0<=\{+(2L+5r)^{2}}, }{9216r},}\}(T^{-}).\]

_When KL exponent \((0,]\), we further require_

\[=(2( ))^{-2},_{2}(2())^{-2}\}}},\]

_where \(_{0}\) and \(_{2}\) are the coefficients in Propositions 2 and 6. Then, \((x^{t+1},y^{t+1})\) is an \((T^{-})\)-GS._

**Remark 2**: _It is worth noting that our results are more general compared to AGP in , where a unified analysis for convex-nonconcave and nonconvex-concave problems is provided. Here, our algorithm can also be applied to the nonconvex-nonconcave problem with one-sided KL property. Moreover, our algorithm is universal, meaning that one single set of parameters can ensure convergence across all these scenarios. By contrast, different choices of parameters are required to guarantee optimal convergence in AGP._

## 4 Empirical Validation of DS-GDA

### Universality of DS-GDA

To validate the universality of DS-GDA, we commence by providing a graphical description of feasible regions for the choice of parameters. Subsequently, employing a set of symmetric parameters, we will show that the KL-nonconvex problems can converge to the desired stationary point, which supports our universality results.

Without loss of generality, we consider the case where \(=1\). In the pursuit of symmetric parameter selection, we initially fix \(==1/5000\), thus reducing the problem to determining only two remaining parameters: \(c\) and \(r\). We then explore their relationships by setting \(r_{1}=r_{2}=t_{2}L\) and \(c==1/(t_{1}r)\). Restricting \(0 t_{1},t_{2} 100\), the feasible choices of \(t_{1}\) and \(t_{2}\) are selected to guarantee the first four coefficients in basic descent estimate (1) are positive. As visually depicted in Figure 0(a), it becomes apparent that a large number of choices for \(r\) and \(c\) are available to ensure convergence.

Next, we test our algorithm on a nonconvex-nonconcave problem that satisfies the one-sided KL property. With a set of symmetric parameters, we find that DS-GDA can easily converge to the desired stationary point. We first introduce the KL-nonconcave problems as follows:

KL-Nonconcave ExampleThe following example satisfies two-sided KL property with exponent \(\), which is studied in :

\[_{x}_{y}x^{2}+3(x)^{2}(y)^{2}-4y ^{2}-10(y)^{2},\] (2)

where \(==\{z:-1 z 1\}\). The only saddle point is \(u^{*}=[x^{*};y^{*}]=[0;0]\).

From Figure 0(b), we can observe that symmetric parameter selection is effective for addressing KL-nonconcave problems. To be specific, by setting \(r_{1}=r_{2}=0.125\), \(c==0.04\), \(==0.8\), DS-GDA directly converges to the saddle point, which validates the universal results in Theorem 3.

### Robustness of DS-GDA

In this section, we compare the convergence performance of DS-GDA with the closely related algorithm S-GDA on some illustrative examples. Additionally, we report the range of parameters for these two algorithms to demonstrate the robustness of DS-GDA. To begin, we present some simple polynomial examples.

Convex-Nonconcave ExampleThe following example is convex-nonconcave, which is studied in :

\[_{x}_{y}2x^{2}-y^{2}+4xy+4y^{3}/3-y^{4}/4,\]

where \(==\{z:-1 z 1\}\) and \(u^{*}=[x^{*};y^{*}]=[0;0]\) is the only stationary point.

KL-Nonconcave ExampleThe KL-nonconcave example considered here is mentioned in Section 4.1 (see equation (2)). The \(u^{*}=[x^{*};y^{*}]=[0;0]\) is a saddle point and the only stationary point.

Nonconvex-Nonconcave ExampleThe nonconvex-nonconcave example considered here is the "Bilinearly-coupled Minimax" example (3) discussed in :

\[_{x}_{y}f(x)+Axy-f(y),\] (3)

where \(f(z)=(z+1)(z-1)(z+3)(z-3)\), \(A=11\), and \(==\{z:-4 z 4\}\). It does not satisfy any existing regularity condition, and the point \(u^{*}=[x^{*};y^{*}]=[0;0]\) is the only stationary point.

The extrapolation parameters \(z\) and \(v\) are initialized as \(x\) and \(y\), respectively. According to Lemma 8, our algorithm terminates when \(\|z-v\|\) and \(\|y-v\|\) are less than \(10^{-6}\) or when the number of iterations exceeds \(10^{7}\). To ensure a fair comparison, we use the same initializations for DS-GDA and S-GDA in each test. The algorithm parameters are tuned so that both DS-GDA and S-GDA are optimal. In other words, they can converge to a stationary point in a minimum number of iterations. We compare the convergence of two algorithms by plotting the iteration gap \(\|u^{k}-u^{*}\|\) against the number of iterations for each example, where \(u^{*}\) denotes the stationary point. Our results show that DS-GDA and S-GDA have similar convergence performance when the primal function is convex or satisfies the KL property, as depicted in Figure 1(a) and 1(b). However, for the nonconvex-nonconcave example where no regularity condition is satisfied, DS-GDA achieves much faster convergence than S-GDA, as shown in Figure 1(c).

To demonstrate the robustness of the proposed DS-GDA, we present feasible regions of all common hyperparameters in Figure 3. We tune the lower and upper bounds of each parameter while keeping other parameters fixed at their optimal values. As illustrated in Figures 2(a) and 2(b), for examples that satisfy the one-sided KL property or with a convex primal function, the implementable ranges of DS-GDA and S-GDA for common parameters are roughly similar. In addition, the two auxiliary parameters for DS-GDA, i.e., \(r_{2}\) and \(\), have relatively wide ranges of values, indicating that they allow for flexibility in their selection. However, for nonconvex-nonconcave problems, DS-GDA exhibits a wider range of viable parameter values compared to S-GDA. This observation highlights the robustness of DS-GDA when it comes to parameter selection (refer to Figure 2(c)).

Figure 1: In Figure (a), the blue region indicates where convergence cannot be guaranteed. The green region indicates a series of parameters that can be chosen to guarantee convergence. Figure (b) demonstrates the effectiveness of symmetric parameter selection for (non)convex-(non)concave problems.

### Effectiveness of Getting Rid of Limit Cycle

In this section, we demonstrate the effectiveness of the proposed DS-GDA on some illustrative examples that are widely used in literature. Notably, they do not satisfy any of the regularity conditions in previous literature (i.e., KL condition, weak MVI, and \(\)-dominant condition). We refer the readers to Appendix L for details on how to check the failure of these conditions for these examples. In addition to the violation of regularity conditions, it has been verified that none of the existing first-order algorithms can achieve convergence for all four examples. The detailed description of the four examples can be found in Appendix B.

To showcase the convergence behavior and effectiveness of the proposed DS-GDA, we compare it with three other state-of-the-art methods, that is, damped extragradient method (Damped EGM) , S-GDA , and generalized curvature extragradient method (CurvatureEG+) . Damped EGM is guaranteed to converge under \(\)-dominant condition, and S-GDA converges when the dual function is concave. CurvatureEG+ could converge under weak MVI condition, which is the weakest variational inequality-based condition as far as we know in the literature.

For the experiments, we use the same initializations of primal and dual variables for all four methods to ensure a fair comparison. For DS-GDA, the exponentially weighted variables are initialized as the same values of the primal and dual variables, respectively. We stop DS-GDA when the differences between primal-dual variables and the corresponding exponentially weighted variables are all less than \(10^{-6}\) or when the number of iterations exceeds \(10^{5}\). For other baseline methods, we terminate them when either the number of iterates reaches \(10^{5}\) or the difference between two consecutive iterates is less than \(10^{-6}\).

Figure 4 shows the trajectories of different methods with various initializations for the aforementioned four examples. We observe from the first column that our DS-GDA successfully gets rid of limit cycles in all examples. While S-GDA exhibits similar performance as DS-GDA, it is still not as potent in terms of its overall effectiveness. Specifically, in the case of the "Bilinearly-coupled minimax" example, S-GDA gets trapped in a limit cycle, while our DS-GDA successfully avoids it and achieves convergence. The figure in the second column provides more details on this comparison. With the violation of the of \(\)-interaction dominance condition, damped EGM either suffers from the spurious cycling convergence phenomenon or diverges to a point on the boundary (see the third row in the fourth column). It converges only when the initialization is very close to the stationary point (see the fourth row in the last column). Similar results are observed for CurvatureEG+ (see Figures in the third column for details). Thus, the proposed DS-GDA outperforms other methods. It is the only

Figure 3: Range of parameters for different problems.

Figure 2: Convergence performance of different problems.

algorithm that can get rid of the limit cycle and enjoy global convergence for all these challenging examples.

## 5 Conclusion

In this paper, we propose a single-loop algorithm called the doubly smoothed gradient descent ascent (DS-GDA) algorithm, which offers a natural balance between primal-dual updates for constrained nonconvex-nonconcave minimax problems. This is the first simple and universal algorithm for nonconvex-concave, convex-nonconcave, and nonconvex-nonconcave problems with one-sided KL property. By employing a single set of parameters, DS-GDA achieves convergence with an iteration complexity of \((^{-4})\) across all these scenarios. Sharper iteration complexity can be obtained when the one-sided KL property is satisfied with an exponent \((0,1)\), matching the state-of-the-art results. We further conduct experiments to validate the universality and efficiency of DS-GDA for avoiding the limit cycle phenomenon, which commonly occurs in challenging nonconvex-nonconcave examples. There is still a gap between theory and practice, and it would be intriguing to explore the possibility of achieving global convergence for DS-GDA without any regularity conditions. This opens up new avenues for research on nonconvex-nonconcave minimax problems.

Figure 4: Trajectories of different methods with various initialization for the aforementioned four examples. The initialization of every trajectory is marked as a black star, the blue (resp. red) line represents the path (resp. limit cycle) of the methods, and the red rhombus is the stationary point.