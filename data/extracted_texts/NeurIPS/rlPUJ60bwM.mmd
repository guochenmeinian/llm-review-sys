# False Discovery Proportion control for aggregated Knockoffs

Alexandre Blain

INRIA

Universite Paris-Saclay

alexandre.blain@inria.fr

Bertrand Thirion

INRIA

CEA

bertrand.thirion@inria.fr

Olivier Grisel

INRIA

olivier.grisel@inria.fr

Pierre Neuvial

Institut de Mathematiques de Toulouse

Universite de Toulouse

pierre.neuvial@math.univ-toulouse.fr

###### Abstract

Controlled variable selection is an important analytical step in various scientific fields, such as brain imaging or genomics. In these high-dimensional data settings, considering too many variables leads to poor models and high costs, hence the need for statistical guarantees on false positives. Knockoffs are a popular statistical tool for conditional variable selection in high dimension. However, they control for the expected proportion of false discoveries (FDR) and not their actual proportion (FDP). We present a new method, KOPI, that controls the proportion of false discoveries for Knockoff-based inference. The proposed method also relies on a new type of aggregation to address the undesirable randomness associated with classical Knockoff inference. We demonstrate FDP control and substantial power gains over existing Knockoff-based methods in various simulation settings and achieve good sensitivity/specificity tradeoffs on brain imaging and genomic data.

## 1 Introduction

Statistically controlled variable selection arises in many different application fields, when the aim is to identify variables that are important for predicting an outcome of interest. For instance, in the context of brain imaging, practitioners are interested in finding which brain areas are relevant for predicting behavior or brain diseases. Such problems also appear in genomics, where practitioners wish to select genes associated with disease outcomes.

More precisely, we consider here _conditional_ variable selection, meaning that we wish to select variables that are relevant to predict an outcome _given_ the other variables. This type of inference is substantially more challenging than marginal inference, especially in high-dimensional settings, where the number of variables exceeds the number of samples. This is typically the case for brain mapping studies that comprise at most a few hundred subjects (hence, samples), while modern functional Magnetic Resonance Imaging (MRI) scans consist of more than 100k _voxels_. In the context of conditional inference, those are typically reduced to a few hundreds of brain regions, still possibly more than the number of samples.

Importantly, statistical guarantees are needed to ensure that the inference is reliable - i.e. that the proportion of false discoveries made by the variable selection procedure is controlled.

In the Knockoffs framework , this problem is tackled by building noisy copies of the original variables. These copies are then compared to their original counterpart to perform variable selection.

The intuition underlying Knockoffs is that irrelevant variables do not get a larger weight than their Knockoff, while relevant variables do. Crucially, the Model-X Knockoffs procedure  controls the False Discovery Rate  which is the expected proportion of false discoveries.

A major caveat with this procedure is the random nature of the Knockoffs generation process: for two runs of the Knockoffs procedure on the same data, different Knockoffs will be built and subsequently different variables may be selected. This undesirable behavior hinders reproducibility. A second caveat is that False Discovery Rate (FDR) control does not imply False Discovery Proportion (FDP) control . This leads to potentially unreliable inference: single runs of the method can produce a much higher proportion of False Discoveries than the chosen FDR level.

In this work, we propose a novel Knockoff-based inference procedure that addresses both concerns while offering power gains over existing methods, for no significant computation cost. The paper is organized as follows. After a refresher on Knockoff inference and aggregation, we consider the \(\) statistic introduced in  to rank variables by relevance. Using the symmetry of knockoffs under the null hypothesis, we construct explicit upper bounds on the Joint Error Rate (JER; 4) of these statistics, leading to FDP control. We then use the calibration principle of  to obtain sharper bounds. Finally, we obtain a robust version of this method using harmonic mean aggregation of the \(\) statistics across multiple Knockoffs draws. We demonstrate empirical power gains in various simulation settings and show the practical benefits of the proposed method for conditionally important region identification on fMRI and genomic datasets.

## 2 Related work

There has been much effort in the statistical community to achieve derandomized Knockoff-based inference.  introduced the idea of running Model-X Knockoffs  multiple times and computing for each the proportion of runs for which it was selected.  explore the idea of sampling multiple Knockoffs simultaneously. This induces a massive computational cost, which is prohibitive compared to methods that can support parallel computing.  introduced an aggregation method that relies on viewing Model-X Knockoffs as a Benjamini-Hochberg (BH) procedure  on so-called _intermediate \(p\)-values_. Such \(p\)-values can be computed on different Knockoff runs and aggregated using quantile aggregation  - then, BH is performed on the aggregated \(p\)-values to select variables. This approach relies on the heavy assumption that Knockoff statistics are i.i.d. under the null. Additionally, it is penalized by the conservativeness of the quantile aggregation scheme. Alternative aggregation schemes such as the harmonic mean  can be used but do not yield valid \(p\)-values.

 introduced an alternative aggregation procedure where Model-X Knockoffs are viewed as an e-BH procedure  on well-defined e-values . Since the mean of two e-values remains an e-value, aggregation is done by averaging e-values across different Knockoffs draws. Then, e-BH is performed on the aggregated e-values to select variables. FDR control on aggregated Knockoffs is achieved without any additional assumption compared to Model-X Knockoffs. However, this method requires the difficult setting of a hyperparameter related to the chosen risk level, which highly impacts power in practice. Other recent developments in Knockoffs include the conditional calibration framework of Luo et al.  which aims at improving the power of Knockoffs-based methods.

There have been a few attempts at controlling other type 1 errors than the FDR using Knockoffs.  achieves k-FWER control and proposes that FDP control can be obtained by using a procedure that leverages joint k-FWER control. Recently,  introduced such a procedure to reach FDP control based on the k-FWER control introduced in . In summary, the KOPI approach is the first one that aims at controlling the FDP of knockoffs-based inference for any aggregation scheme, leading to both accurate FDP control and increased sensitivity.

## 3 Refresher on Knockoffs

**Notation.** We denote vectors by bold lowercase letters. A vector \(=\{x_{1},,x_{p}\}\) from which we removed the \(j^{th}\) coordinate is denoted by \(_{-j}\), i.e. \(\{x_{j}\}\). Independence between two random vectors \(\) and \(\) is denoted by \(\). For two vectors \(\) and \(}\) and a subset \(S\) of indices, \((,})_{swap(S)}\) denotes the vector obtained from \((,})\) by swapping the entries \(x_{j}\) and \(_{j}\) for each \(j S\). Matrices are denoted by bold uppercase letters, the only exception being the vector of Knockoff statistics that we denote by \(\) as in . For any set \(S\), \(|S|\) denotes the cardinality of \(S\). For a vector \(=(z_{j})_{1 j p}\) and \(S p\), we denote by \(z_{(j:S)}\) (or \(z_{(j)}\) when there is no ambiguity) the \(j^{th}\) smallest value in the sub-vector \((_{s})_{s S}\). For an integer \(k\), \( k\) denotes the set \(\{1,,k\}\). Equality in distribution is denoted by \(}{{=}}\).

**Problem setup.** The input data are denoted by \(^{n p}\), where \(n\) is the number of samples and \(p\) the number of variables. The outcome of interest is denoted by \(^{n}\). The goal is to select variables that are relevant with regards to the outcome _conditionally on all others_. Formally, we test simultaneously for all \(j p\):

\[H_{0,j}:y x_{j}|_{-j} H_{1,j}:y  x_{j}|_{-j}.\]

The output of a variable selection method is a rejection set \( p\) that estimates the true unknown support \(_{1}=\{j:y x_{j}|_{-j}\}\). Its complement is the set of true null hypotheses \(_{0}=\{j:y x_{j}|_{-j}\}\). Its cardinality \(|_{0}|\) is denoted by \(p_{0}\). To ensure reliable inference, our aim is to provide a statistical guarantee on the proportion of False Discoveries in \(\). The False Discovery Proportion (FDP) and the False Discovery Rate (FDR)  are defined as:

\[()=_{0}|}{|| 1},()=[()]= [_{0}|}{|| 1}].\]

An \(\)-level post-hoc \(\) upper bound  is a function \(V\) that verifies:

\[( S p,(S) V( S)/|S|) 1-\,.\]

**Knockoffs.** The Knockoff filter is a variable selection technique introduced by  and refined by  which controls the FDR. This procedure relies on building noisy copies of the original variables called Knockoff variables, that are designed to serve as controls for variable selection.

**Definition 1** (Model-X Knockoffs, 6).: For the family of random variables \(=(x_{1},,x_{p})\), Knockoffs are a new family of random variables \(}=(_{1},,_{p})\) satisfying:

1. for any \(S p\), \((,})_{swap(S)}}{{=}}( ,})\)
2. \(}|\).

Once we have such variables at our disposal, we quantify their importance relative to the original ones. This is done by computing Knockoff statistics \(=(W_{1},,W_{p})\) that are defined as follows.

**Definition 2** (Knockoff Statistic, 6).: A knockoff statistic \(=(W_{1},,W_{p})\) is a measure of feature importance that satisfies:

1. \(\) depends only on \(,}\) and \(\): \(=g(,},)\).
2. Swapping column \(_{j}\) and its knockoff column \(}_{j}\) switches the sign of \(W_{j}\): \[W_{j}([,}]_{swap(S)},)=\{ []{l}W_{j}([,}],)j S^{c}\\ -W_{j}([,}],)j S..\]

The most commonly used Knockoff statistic is the Lasso-coefficient difference (LCD) . This statistic is obtained by fitting a Lasso estimator  on \([,}]^{n 2p}\), which yields \(}^{2p}\). Then, the Knockoff statistic can be computed using \(}\):

\[ j p, W_{j}=|_{j}|-| _{j+p}|.\]

This coefficient summarizes the importance of the original \(j^{th}\) variable relative to its own Knockoff: \(W_{j}>0\) indicates that the original variable is more more important for fitting \(y\) than the Knockoff variable, meaning that the \(j^{th}\) variable is likely relevant. Conversely, \(W_{j}<0\) indicates that the \(j^{th}\) variable is probably irrelevant. We thus wish to select variables corresponding to large and positive \(W_{j}\). Formally, the rejection set \(\) can be written \(=\{j:W_{j}>T_{q}\},\) where \(T_{q}\) is chosen to provably control the \(\) at level \(q\).

**Aggregation schemes.** Due to the randomness in the knockoff generation process, different variables may be selected for two different runs of the method, which is undesirable. To mitigate this, aggregation of multiple Knockoffs runs is needed. Ren and Barber  introduced an aggregation scheme which relies defining Knockoffs \(e\)-values.

\[e_{j}=-T_{q}\}|}1_{\{W_{j} T_{q} \}}.\]

Such e-values can be averaged across \(D\) draws and e-BH  is performed for variable selection. Alternatively,  defines the following \(\)-statistic, that quantifies the evidence against a variable:

\[_{j}=\{-W_{j}\}|}{ 1} W_{j}>0\\ 1}{p}{W_{j} 0}..\] (1)

In \(\) statistics are treated as \(p\)-values and aggregated using quantile aggregation . However, they can only be considered \(p\)-values under restrictive assumptions that are hard to check. In the next section, these statistics are used as a building block to reach FDP control. The KOPI framework does not require \(\) statistics to be valid \(p\)-values.

## 4 Main contribution: FDP control for aggregated Knockoffs

### Post hoc FDP control for \(\) statistics

To obtain FDP control, we rely on Joint Error Rate control as introduced in . For \(k_{max} p\), we define a _threshold family_ of size \(k_{max}\) as a vector \(=(t_{j})_{j k_{max}}\) such that \(0 t_{1} t_{k_{max}} 1\).

**Definition 3** (Joint Error Rate, 4).: Denote by \(_{(j:_{0})}\) the \(j^{th}\) smallest value \(_{j}\) amongst all null hypotheses. The JER associated with \(=(t_{j})_{j k_{max}}\) is:

\[()=( j k_{max} p _{0}:_{(j:_{0})}<t_{j}).\] (2)

The threshold family \(\) is said to control the JER at level \(\) iff \(()\).

An \(\)-level \(\) upper bound can be derived from \(\) control via the following result:

**Proposition 1** (FDP control via JER control 4).: _If \(\) is a threshold family of length \(k_{max}\) that controls the JER at level \(\), then, \(V^{}(S)/|S|\) is an \(\)-level FDP upper bound, with:_

\[V^{}(S)=_{1 k k_{max}}(k-1)+_{i S}1_{\{ _{i}>t_{k}\}}.\] (3)

The proof of this result - originally included in  - can be found in appendix A.1 for self-containedness. In the remainder of this section, we show how to obtain JER control for \(\) statistics.

### Joint distribution of \(\) statistics under the null

By Definition 3, \(()\) of a given threshold family only depends on the joint null distribution of the \(\) statistics. As for earlier FDR control  or k-FWER control  results, the key idea to obtain JER control for \(\) statistics is to prove that the relevant part of this distribution is in fact known, thanks to the properties of knockoff statistics. We use the same notation as in . Letting \(Z_{j}=|\{k p:W_{k}-W_{j}\}|\) and \(_{j}=sign(W_{j})\), the \(\) statistics \((_{j})_{j= p}\) are given by:

\[_{j}=}{p}1_{\{_{j}=1\}}+1_{\{_{j}=-1 \}}.\]

For a given \(\), let \(()\) be a permutation of \( p\) that sorts \(\) by decreasing modulus: \(()=(_{1},,_{p})\) such that \(|W_{_{1}}||W_{_{2}}||W_{_{p}}|\). We start by proving that the \(Z\) statistics can be expressed as a function of the vector of \(\) statistics:

**Lemma 1**.: _For \(j p\) such that \(_{_{j}}=1\), \(Z_{_{j}}=_{k=1}^{j-1}1_{\{_{_{k}}=-1\}}\)._Proof of Lemma 1.: Since \(_{_{j}}=1\), we have:

\[Z_{_{j}} =|\{k p:W_{_{k}}-W_{_{ j}}\,\}|\] \[=|\{k p:W_{_{k}}<0W_{ _{k}}-W_{_{j}}\,\}|\] \[=|\{k p:W_{_{k}}<0|W_{_{k}}||W_{_{j}}|\}|\] \[=|\{k p:W_{_{k}}<0k j \}|\] \[=_{k=1}^{j-1}1_{\{_{_{k}}=-1\}}.\]

Lemma 1 implies that the distribution of order statistics of \(|()\) is entirely determined by that of \(|()\). To formalize this, we introduce \(^{0}\) statistics.

**Definition 4** (\(^{0}\) statistics).: Let \(^{0}=(^{0}_{j})_{1 j p}\) be a collection of \(p\) i.i.d. Rademacher random variables, that is, for all \(j\), \((^{0}_{j}=1)=(^{0}_{j}=-1)=1/2\). The associated \(^{0}\) statistics are defined for \(j p\) by

\[^{0}_{j}=_{j}}{p}1_{\{^{0}_{j}=1\}}+1_{\{^{0}_{j}=-1 \}},Z^{0}_{j}=_{k=1}^{j-1}1_{\{^{0}_{k}=-1\}}.\] (4)

**Theorem 1**.: _Let \(\) be a threshold family of length \(k_{max}\). Then, for \(^{0}=(^{0}_{j})_{j p}\) as in (4),_

\[()^{0}( ):=( k k_{max} :^{0}_{(k)}<t_{k}).\] (5)

Proof of Theorem 1.: Let \(k k_{max}\). Since \(t_{k} 1\), we have \(_{(k:_{0})}<t_{k}\) if and only if \(N_{k} k\), where

\[N_{k}=|\{j_{0},_{j}=1}{p}<t_{k} \}|.\]

With the notation of Definition 4, we define the random variable

\[N^{0}_{k}=|\{j_{0},^{0}_{j}=1_{j}}{p}<t_{k}\}|.\]

If \(_{0}= p\), then Lemma 1 implies that conditional on \(()\), \(N_{k}\) and \(N^{0}_{k}\) have the same distribution. Indeed, the vectors \((W_{j})_{j/_{j}=1}\) and \((Z_{j})_{j/_{j}=1}\) have the same ordering, and conditional on \(()\), \((_{j})_{j_{0}}\) are jointly independent and uniformly distributed on \(\{-1,1\}\) (Lemma 2.1 in 11; 1). Using the same argument as in the proof of Lemma 3.1 in Janson and Su , in the case where \(_{0} p\), false null \(_{j}\) will insert \(-1\)'s into the process on the nulls, implying that \(N_{k}\) is stochastically dominated by \(N^{0}_{k}\). Noting that \(N^{0}_{k} k\) if and only if \(^{0}_{(k)}<t_{k}\), we obtain that

\[( k k_{max} p_{0} ,_{(k:_{0})}<t_{k}|()) ( k k_{max} p_{0} ,^{0}_{(k)}<t_{k})\] \[( k k_{max},^ {0}_{(k)}<t_{k}).\]

Taking the expectation with respect to \(()\) yields the desired result. 

Theorem 1 is related to Lemma 3.1 of Janson and Su  and Lemma 3.1 of Li et al. , that rely on the sign-flip property of Knockoff statistics under the null . The interest of Theorem 1 is that the upper bound \(^{0}()\) only depends on the \(^{0}\) statistics and the threshold family \(\), and not on the original data. Therefore, it can be estimated with arbitrary precision for any given \(\) using Monte-Carlo simulation, as explained in the next section and described in Algorithm 1 in Supp. Mat.

### Joint Error Rate control for \(\) statistics via calibration

To approximate the \(\) upper bound derived in Theorem 1, we draw \(B\) Monte-Carlo samples using Algorithm 1. This yields a set of \(B\) vectors of \(^{0}\) statistics denoted by \(^{0}_{b}^{p}\) for each \(b B\). This allows us to evaluate the empirical \(\), which estimates the upper bound of interest.

**Definition 5** (Empirical JER).: For \(B\) vectors of \(^{0}\) statistics and a threshold family \(\), the empirical \(\) is defined as:

\[}^{0}_{B}()=_{b=1}^{B}1\{  k k_{max}:^{0}_{b(k)}<t_{k}\},\] (6)

where for each \(b B\), \(^{0}_{b(1)}^{0}_{b(p)}\).

Since \(}^{0}_{B}()\) can be made arbitrarily close (by choosing \(B\) large enough) to \(}^{0}()\) for any given threshold family \(\), it remains to choose \(\) such that \(}^{0}()\) in order to ensure \(\) control. To this end, we consider a sorted set of candidate threshold families called a _template_:

**Definition 6** (Template ).: A template is a component-wise non-decreasing function \(:^{p}\) that maps a parameter \(\) to a threshold family \(()^{p}\).

This definition is naturally extended to the case of templates containing a finite number of threshold families. The template corresponding to \(B^{}\) threshold families is then denoted by \(((b^{}/B^{}))_{b^{} B^{ }}\).

Once a template is specified, the _calibration_ procedure  can be performed; this consists in finding the least conservative threshold family \(\) amongst the template that controls the empirical \(\) at level \(\). Formally, we consider the threshold family defined \(^{B}_{}=(_{B}())\), where

\[_{B}()=}\{b^{} B ^{} s.t.}^{0}_{B}( (}{B^{}}))\}.\]

As observed by Blain et al. , optimal power is reached when the candidate families match the shape of the distribution of the null statistics. We define a template based on the distribution of the \(^{0}\) statistics appearing in Theorem 1. In practice, we draw \(B^{}\) samples from this distribution independently from the \(B\) Monte Carlo samples to avoid circularity biases. Since a template has to be component-wise non-decreasing, i.e. the set of candidate threshold families has to be sorted, we extract empirical quantiles from these \(B^{}\) sorted vectors. This yields a template \(^{0}\) composed of \(B^{}\) candidate curves that match quantiles of the distribution of \(^{0}\) statistics. The \(}{B^{}}\)-quantile curve defines the threshold family \(^{0}(b^{}/B^{})\). We obtain the following result:

**Theorem 2** (JER control for \(\)-statistics).: _Consider the threshold family defined by \(^{B}_{}=^{0}(_{B}())\). Then, as \(B+\),_

\[(^{B}_{})+O_{P}(1/).\]

The number \(B\) of Monte-Carlo samples in Theorem 2 can be chosen arbitrarily large to obtain \(\) control, leading to valid \(\) bounds via Equation 3. This result is proved in Appendix A.2.

### False Discovery Proportion control for aggregated Knockoffs

In the previous section we have seen how to reach FDP control via Knockoffs. As explained above, aggregation is needed to mitigate the randomness of the Knockoff generation process. Therefore, we aim to extend the previous result to the case of aggregated Knockoffs. Let us first define aggregation:

**Definition 7**.: For \(D\) draws of Knockoffs, an aggregation procedure is a function \(f:^{D}\) that maps a vector of \((^{d})_{d D}\) statistics to an aggregated statistic \(\).

In practice, since we have \(p\) variables, aggregation is performed for each variable, i.e.:

\[ j p, f(^{1}_{j},,^{D}_{j})= }.\]

Then, inference is performed on the vector of aggregated statistics \((_{1},,_{p})\).

For a fixed aggregation scheme \(f\), we can naturally extend the calibration procedure of the preceding section. Instead of drawing a single \(B p\) matrix of \(^{0}\) statistics containing \(^{0}_{b}^{p}\) for each \(b B\), we draw \(D\) such matrices. Given \(d D\), each matrix contains \(^{0,d}_{b}^{p}\) for each \( B\).

Then, for each \(b B\), we perform aggregation: \(^{0}_{b}=f((^{0,d}_{b})_{d D} ).\) The \(\) in the aggregated case is defined as:

\[}()=( j  k_{max} p_{0}:_{(j:_{0})}<t_ {j}).\]

We obtain the aggregated template following the same procedure, i.e. drawing \(D\) templates and aggregating them. For each \(b^{} B^{}\), the aggregated threshold family is written:

\[}(}{B^{}})=f(( ^{d}(}{B^{}}))_{d  D}).\]

We can then write the empirical \(\) in the aggregated case as:

\[}(}(}{B^{}}))=_{b=1}^{B}1\{ j  k_{max}:^{0}_{b(j)}<}_{ j}(}{B^{}})\}.\]

Calibration can be performed in the same way as in the non-aggregated case. Note that we perform calibration _after_ aggregating; therefore, \(\) control is ensured directly on aggregated statistics and is not a result of aggregating \(\) controlling families. Importantly, this approach holds without additional assumptions on the aggregation scheme \(f\). We consider the threshold family \(}^{B}_{}=}(_{B}())\), where

\[_{B}()=}\{b^{} B ^{} s.t.}^{0}_{B}( }(}{B^{}})) \}.\]

With \(}^{0}\) a template composed of \(B^{}\) candidate curves that match quantiles of the distribution of \(^{0}\) statistics, we obtain the following result:

**Theorem 3** (\(\) control for aggregated \(\)-statistics).: _Consider the threshold family defined by \(}^{B}_{}=}^{0}(_{B}( ))\). Then, as \(B+\),_

\[}(}^{B}_{})+O _{P}(1/).\]

Proof.: The proof is identical to that of Theorem 2 using the empirical aggregated \(\). 

The calibrated aggregated threshold family yields valid \(\) upper bounds via Proposition 1. The proposed **KOPI** (Knockoffs - \(\)) method therefore achieves FDP control on aggregated Knockoffs.

## 5 Experiments

**Methods considered.** In our implementation of KOPI, we rely on the harmonic mean  as the aggregation scheme \(f\). Additionally, we set \(k_{max}= p/50\) following the approach of . We also consider both state-of-the-art Knockoffs aggregation schemes: AKO (Aggregation of Multiple Knockoffs, 17) and e-values based aggregation . Additionally, we consider Vanilla Knockoffs, i.e.  and \(\) control via Closed Testing . In simulated data experiments, we generate Knockoffs assuming a Gaussian distribution for \(\), with all variables centered. For methods that support aggregation, we use \(D=50\) Knockoff draws.

### Simulated data

**Setup.** At each simulation run, we generate Gaussian data \(^{n p}\) with a Toeplitz correlation matrix corresponding to a first-order auto-regressive model with parameter \(\), i.e. \(_{i,j}=^{|i-j|}\).

Then, we draw the true support \(^{*}\{0,1\}^{p}\). The number of non-null coefficients of \(^{*}\) is controlled by the sparsity parameter \(s_{p}\), i.e. \(s_{p}=\|^{*}\|_{0}/p\). The target variable \(\) is built using a linear model:

\[=^{*}+,\]with \(\) controlling the amplitude of the noise: \(=\|^{*}\|_{2}/(\| \|_{2})\), \(\) being the signal-to-noise ratio. We choose the central setting \(n=500,p=500,=0.5,s_{p}=0.1,=2\). For each parameter, we explore a range of possible values to benchmark the methods across varied settings.

To select variables using \(\) upper bounds, we retain the largest possible set of variables \(S\) such that \(V(S) q|S|\) (Algorithm 4). For each of the \(N\) simulations and each method, we compute the empirical FDP and True Positive Proportion (TPP):

\[(S)=_{0}|}{|S|} (S)=_{1}|}{|_{1}|}.\]

If the \(\) is controlled at level \(\), \(|\{k[\![N]\!]:(S_{k})>q\}|(N,)\). Then, we can compute error bands on the \(\)-level using \(((N,)/N)=\). The second row of Fig. 1 represents the empirical power achieved by each method, which corresponds to the average of TPPs defined above for \(N\) runs i.e. Power \(=_{k=1}^{N}(S_{k})/N\). Fig. 1 shows that across all different settings, KOPI retains FDP control. We can also see that FDR control does not imply FDP control, as Vanilla Knockoffs are consistently outside of FDP bound coverage intervals. However, the two existing aggregation schemes (AKO and e-values) that formally guarantee FDR control are generally conservative and achieve FDP control empirically. This is consistent with the findings of . The Closed Testing procedure of  achieves FDP control as announced but suffers from a lack of power.

Interestingly, KOPI achieves FDP control while offering power gains compared to FDR-controlling Knockoffs aggregation methods. Yet FDP control is a much stronger guarantee than FDR control, as discussed previously. These gains are especially noticeable in challenging inference settings where most methods exhibit a clear decrease in power or even catastrophic behavior (i.e. zero power).

Moreover, Fig. 3 (in appendix) shows that when using \(q=0.05\) rather than \(q=0.1\) as in Fig. 1, the robustness of KOPI with regards to difficult inference settings is even more salient. More precisely, for \(q=0.05\), AKO and Closed Testing are always powerless. E-values aggregation yields good power in easier settings such as \( 0.6\), \( 2.5\) or \(n>750\) but exhibits catastrophic behavior in harder settings. Overall, apart from KOPI, only Vanilla Knockoffs exhibit non-zero power, but this method fails to control the FDP as it is intended to control FDR. KOPI preserves FDP control in all settings while yielding superior power compared to all other methods.

Figure 1: **FDP bound coverage at level \(\) and empirical Power for 50 simulation runs and five different methods:** Vanilla Knockoffs, aggregated Knockoffs using e-values, aggregated Knockoffs using quantile-aggregation, KOPI and Knockoff inference via Closed Testing. We use \(D=50\) Knockoffs draws and the following simulation settings: \(=0.1,q=0.1,p=500\). Each column represents a varying parameter with the first row displaying FDP coverage and the second row displaying power. The red line and associated error bands represent the acceptable limits for FDP bound coverage. KOPI consistently outperforms all other methods while retaining FDP control.

### Brain data application

The goal of human brain mapping is to associate cognitive tasks with relevant brain regions. This problem is tackled using functional Magnetic Resonance Imaging (fMRI), which consists in recording the blood oxygenation level dependent signal via an MRI scanner. The importance of conditional inference for this problem has been outlined in . We use the Human Connectome Project (HCP900) dataset that contains brain images of healthy young adults performing different tasks while inside an MRI scanner. Details about this dataset and empirical results can be found in Appendix E.

While these results demonstrate the face validity of the approach, FDP control and power cannot be evaluated. Therefore, following , we consider an additional experiment that consists in using semi-simulated data. We consider a first fMRI dataset \((_{1},_{1})\) on which we perform inference using a Lasso estimator; this yields \(_{1}^{*}^{p}\) that we will use as our ground truth. Then, we consider a separate fMRI dataset \((_{2},_{2})\) for data generation. The point of using a separate dataset is to avoid circularity between the ground truth definition and the inference procedure. Concretely, we discard the original response vector \(_{2}\) for this dataset and build a simulated response \(_{2}^{sim}\) using a linear model, with the same notation as previously (we set \(\) so that \(SNR=4\)): \(_{2}^{sim}=_{2}_{1}^{*}+\).

Then, inference is performed using Knockoffs-based methods on \((_{2},_{2}^{sim})\). Since we consider \(_{1}^{*}\) as the ground truth, the FDP and TPP can be computed for each method. As can be seen in Fig. 2, KOPI is the most powerful method among those that control the FDP.

### Genomic data application

In addition to the brain data application, we compared KOPI to other Knockoffs-based methods on gene-expression data  containing \(79\) samples and \(90\) genes. KOPI yields a non trivial selection for all runs, with 3 genes selected in \(100\%\) of all \(50\) runs of the experiment. Across all runs, only \(8\) different genes are selected by KOPI. Vanilla Knockoffs select \(24\) different genes across all runs and no gene exceeds a selection frequency of \(70\%\). All other methods are powerless in all runs. Details and results of this experiment can be found in Appendix D.

## 6 Discussion

In this paper, we have proposed a novel method that reaches FDP control on aggregated Knockoffs. It combines the benefits of aggregation, i.e. improving the stability of the inference, in addition to providing a probabilistic control of the FDP, rather than controlling only its expectation, the FDR.

Figure 2: **Empirical FDP and power on semi-simulated data for 42 contrast pairs. We use 7 HCP contrasts C0: “Motor Hand”, C1: “Motor Foot”, C2: “Gambling”, C3: “Relational”, C4: “Emotion”, C5: “Social”, C6: “Working Memory”. We consider all 42 possible train/test pairs: the train contrast is used to obtain a ground truth, while the test contrast is used to generate the response. Inference is performed using the 5 methods considered in the paper and the empirical FDP is reported in the left box plot, while power is reported in the right box plot. Notice (right figure) that KOPI yields superior power compared to all other Knockoffs-based methods while controlling the FDP (left Fig.).**Simulation results support that KOPI indeed controls the FDP. Furthermore, while FDP control is a stricter guarantee than FDR control, KOPI actually offers power gains compared to state-of-the-art aggregation-based Knockoffs methods. This sensitivity gain is a direct benefit from the JER approach and its adaptivity to arbitrary aggregation schemes. While the latter has been formulated and used so far in mass univariate settings , the present work presents a first use of this approach in the context of multiple regression. Moreover, KOPI does not require any assumption on the data at hand or on the law of Knockoff statistics under the null.

The computation time of the proposed approach is comparable to existing aggregation schemes for Knockoffs: sampling \(\) statistics under the null using Algorithm 1 can be done once and for all for a given value of \(p\). JER estimation via Algorithm 2 and calibration can be performed via binary search of complexity \((log(B^{}))\). Finding the rejection set \(\) after performing calibration is done in linear time via . In practice, the computation time is the same as for classical knockoff aggregation  and is in minutes for the brain imaging datasets considered. Avenues for future work include a theoretical analysis of the False Negative Proportion (FNP)  of KOPI and developing a step-down version of the method to further improve power.

We provide a Python package containing the code for KOPI available at https://github.com/alexblnn/KOPI.

Acknowledgments and disclosure of funding

This project was funded by a UDOPIA PhD grant from Universite Paris-Saclay and also supported by the FastBig ANR project (ANR-17-CE23-0011), the KARAIB AI chair (ANR-20-CHIA-0025-01), the H2020 Research Infrastructures Grant EBRAIN-Health 101058516 and the SansSouci ANR project (ANR-16-CE40-0019). The authors thank Binh Nguyen for his precious help on the code base and Samuel Davenport for useful discussions about this work.