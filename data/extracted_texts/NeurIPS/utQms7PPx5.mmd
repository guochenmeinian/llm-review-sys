# All Points Matter: Entropy-Regularized Distribution Alignment for Weakly-supervised 3D Segmentation

Liyao Tang\({}^{1}\), Zhe Chen\({}^{2}\), Shanshan Zhao\({}^{1}\), Chaoyue Wang\({}^{1}\), Dacheng Tao\({}^{1}\)

\({}^{1}\) The University of Sydney, Australia \({}^{2}\) La Trobe University, Australia

ltan9687@uni.sydney.edu.au, zhe.chen@latrobe.edu.au

chaoyue.wang@outlook.com, {sshan.zhao00, dacheng.tao}@gmail.com

###### Abstract

Pseudo-labels are widely employed in weakly supervised 3D segmentation tasks where only sparse ground-truth labels are available for learning. Existing methods often rely on empirical label selection strategies, such as confidence thresholding, to generate beneficial pseudo-labels for model training. This approach may, however, hinder the comprehensive exploitation of unlabeled data points. We hypothesize that this selective usage arises from the noise in pseudo-labels generated on unlabeled data. The noise in pseudo-labels may result in significant discrepancies between pseudo-labels and model predictions, thus confusing and affecting the model training greatly. To address this issue, we propose a novel learning strategy to regularize the generated pseudo-labels and effectively narrow the gaps between pseudo-labels and model predictions. More specifically, our method introduces an Entropy Regularization loss and a Distribution Alignment loss for weakly supervised learning in 3D segmentation tasks, resulting in an ERDA learning strategy. Interestingly, by using KL distance to formulate the distribution alignment loss, it reduces to a deceptively simple cross-entropy-based loss which optimizes both the pseudo-label generation network and the 3D segmentation network simultaneously. Despite the simplicity, our method promisingly improves the performance. We validate the effectiveness through extensive experiments on various baselines and large-scale datasets. Results show that ERDA effectively enables the effective usage of all unlabeled data points for learning and achieves state-of-the-art performance under different settings. Remarkably, our method can outperform fully-supervised baselines using only 1% of true annotations. Code and model will be made publicly available at https://github.com/LiyaoTang/ERDA.

## 1 Introduction

Point cloud semantic segmentation is a crucial task for 3D scene understanding and has various applications , such as autonomous driving, unmanned aerial vehicles, and augmented reality. Current state-of-the-art approaches heavily rely on large-scale and densely annotated 3D datasets, which are costly to obtain . To avoid demanding exhaustive annotation, weakly-supervised point cloud segmentation has emerged as a promising alternative. It aims to leverage a small set of annotated points while leaving the majority of points unlabeled in a large point cloud dataset for learning. Although current weakly supervised methods can offer a practical and cost-effective way to perform point cloud segmentation, their performance is still sub-optimal compared to fully-supervised approaches.

During the exploration of weak supervision , a significant challenge is the insufficient training signals provided by the highly sparse labels. To tackle this issue, pseudo-labeling methods  have been proposed, which leverage predictions on unlabeled points as labels to facilitate the learning of the segmentation network. Despite some promising results, these pseudo-label methods have been outperformed by some recent methods based on consistency regularization . We tend to attribute this to the use of label selection on pseudo-labels, such as confidence thresholding, whichcould lead to unlabeled points being wasted and under-explored. We hypothesize that the need for label selection arises from the low-confidence pseudo-labels assigned to unlabeled points, which are known for their noises  and potential unintended bias [60; 100]. These less reliable and noisy pseudo-labels could contribute to discrepancies between the pseudo-labels and the model predictions, which might confuse and impede the learning process to a great extent.

By addressing the above problem for label selection in weakly supervised 3D segmentation, we propose a novel learning-based approach in this study. Our method aims to leverage the information from all unlabeled points by mitigating the negative effects of the noisy pseudo-labels and the distributional discrepancy.

Specifically, we introduce two learning objectives for the pseudo-label generation process. Firstly, we introduce an _entropy regularization_ (ER) objective to reduce the noise and uncertainty in the pseudo-labels. This regularization promotes more informative, reliable, and confident pseudo-labels, which helps alleviate the limitations of noisy and uncertain pseudo-labels. Secondly, we propose a _distribution alignment_ (DA) loss that minimizes statistical distances between pseudo-labels and model predictions. This ensures that the distribution of generated pseudo-labels remains close to the distribution of model predictions when regularizing their entropy.

In particular, we discover that formulating the distribution alignment loss using KL distance enables a simplification of our method into a cross-entropy-style learning objective that optimizes both the pseudo-label generator and the 3D segmentation network simultaneously. This makes our method straightforward to implement and apply. By integrating the entropy regularization and distribution alignment, we achieve the ERDA learning strategy, as shown in Fig. 1.

Empirically, we comprehensively experiment with three baselines and different weak supervision settings, including 0.02% (1-point, or 1pt), 1%, and 10%. Despite its concise design, our ERDA outperforms existing weakly-supervised methods on large-scale point cloud datasets such as S3DIS , ScanNet , and SensatUrban . Notably, our ERDA can surpass the fully-supervised baselines using only 1% labels, demonstrating its significant effectiveness in leveraging pseudo-labels. Furthermore, we validate the scalability of our method by successfully generalizing it to more other settings, which illustrates the benefits of utilizing dense pseudo-label supervision with ERDA.

## 2 Related Work

**Point cloud segmentation.** Point cloud semantic segmentation aims to assign semantic labels to 3D points. The cutting-edge methods are deep-learning-based and can be classified into projection-based and point-based approaches. Projection-based methods project 3D points to grid-like structures, such as 2D image [84; 55; 39; 12; 4; 45] or 3D voxels [15; 71; 67; 28; 22; 23; 76]. Alternatively, point-based

Figure 1: While existing pseudo-labels (a) are limited in the exploitation of unlabeled points, ERDA (b) simultaneously optimizes the pseudo-labels \(\) and predictions \(\) taking the same and simple form of cross-entropy. By reducing the noise via entropy regularization and bridging their distributional discrepancies, ERDA produces informative pseudo-labels that neglect the need for label selection. As in (c), it thus enables the model to consistently benefit from more pseudo-labels, surpasses other methods and its fully-supervised baseline, and can be extended to advance the fully-supervised performance.

methods directly operate on 3D points [56; 57]. Recent efforts have focused on novel modules and backbones to enhance point features, such as 3D convolution [3; 48; 78; 68; 51; 58], attentions [34; 26; 97; 79; 42; 59], graph-based methods [74; 44], and other modules such as sampling [18; 86; 88; 7] and post-processing [54; 35; 66]. Although these methods have made significant progress, they rely on large-scale datasets with point-wise annotation and struggle with few labels . To address the demanding requirement of point-wise annotation, our work explores weakly-supervised learning for 3D point cloud segmentation.

**Weakly-supervised point cloud segmentation.** Compared to weakly-supervised 2D image segmentation [99; 49; 75; 1; 64], weakly-supervised 3D point cloud segmentation is less explored. In general, weakly-supervised 3D segmentation task focus on highly sparse labels: only a few scattered points are annotated in large point cloud scenes. Xu and Lee  first propose to use 10x fewer labels to achieve performance on par with a fully-supervised point cloud segmentation model. Later studies have explored more advanced ways to exploit different forms of weak supervision [77; 14; 40] and human annotations [53; 69]. Recent methods tend to introduce perturbed self-distillation , consistency regularization [85; 62; 80; 81; 43], and leverage self-supervised learning [62; 37; 47; 87] based on contrastive learning [29; 10]. Pseudo-labels are another approach to leverage unlabeled data, with methods such as pre-training networks on colorization tasks , using iterative training , employing separate networks to iterate between learning pseudo-labels and training 3D segmentation networks , or using super-point graph  with graph attentional module to propagate the limited labels over super-points . However, these existing methods often require expensive training due to hand-crafted 3D data augmentations [95; 87; 80; 81], iterative training [53; 32], or additional modules [87; 32], complicating the adaptation of backbone models from fully-supervised to weakly-supervised learning. In contrast, our work aims to achieve effective weakly supervised learning for the 3D segmentation task with straightforward motivations and simple implementation.

**Pseudo-label refinement.** Pseudo-labeling , a versatile method for entropy minimization , has been extensively studied in various tasks, including semi-supervised 2D classification [82; 60], segmentation [64; 89], and domain adaptation [98; 73]. To generate high-quality supervision, various label selection strategies have been proposed based on learning status [72; 91; 20], label uncertainty [60; 98; 73; 50], class balancing , and data augmentations [64; 89; 100]. Our method is most closely related to the works addressing bias in supervision, where mutual learning [20; 70; 92] and distribution alignment [100; 31; 41] have been discussed. However, these works typically focus on class imbalance [100; 31] and rely on iterative training [70; 20; 92; 41], label selection [20; 31], and strong data augmentations [100; 31], which might not be directly applicable to 3D point clouds. For instance, common image augmentations  like cropping and resizing may translate to point cloud upsampling , which remains an open question in the related research area. Rather than introducing complicated mechanisms, we argue that proper regularization on pseudo-labels and its alignment with model prediction can provide significant benefits using a very concise learning approach designed for the weakly supervised 3D point cloud segmentation task.

Besides, it is shown that the data augmentations and repeated training in mutual learning [70; 38] are important to avoid the feature collapse, _i.e.,_ the resulting pseudo-labels being uniform or the same as model predictions. We suspect the cause may originate from the entropy term in their use of raw statistical distance by empirical results, which potentially matches the pseudo-labels to noisy and confusing model prediction, as would be discussed in Sec. 3.2. Moreover, in self-supervised learning based on clustering  and distillation , it has also been shown that it would lead to feature collapse if matching to a cluster assignment or teacher output of a close-uniform distribution with high entropy, which agrees with the intuition in our ER term.

## 3 Methodology

### Formulation of ERDA

As previously mentioned, we propose the ERDA approach to alleviate noise in the generated pseudo-labels and reduce the distribution gaps between them and the segmentation network predictions. In general, our ERDA introduces two loss functions, including the entropy regularization loss and the distribution alignment loss for the learning on pseudo-labels. We denote the two loss functions as \(L_{ER}\) and \(L_{DA}\), respectively. Then, we have the overall loss of ERDA as follows:

\[L_{p}= L_{ER}+L_{DA},\] (1)where the \(>0\) modulates the entropy regularization which is similar to the studies [46; 24].

Before detailing the formulation of \(L_{ER}\) and \(L_{DA}\), we first introduce the notation. While the losses are calculated over all unlabeled points, we focus on one single unlabeled point for ease of discussion. We denote the pseudo-label assigned to this unlabeled point as \(\) and the corresponding segmentation network prediction as \(\). Each \(\) and \(\) is a 1D vector representing the probability over classes.

**Entropy Regularization loss.** We hypothesize that the quality of pseudo-labels can be hindered by noise, which in turn affects model learning. Specifically, we consider that the pseudo-label could be more susceptible to containing noise when it fails to provide a confident pseudo-labeling result, which leads to the presence of a high-entropy distribution in \(\).

To mitigate this, for the \(\), we propose to reduce its noise level by minimizing its Shannon entropy, which also encourages a more informative labeling result . Therefore, we have:

\[L_{ER}=H(),\] (2)

where \(H()=_{i}-p_{i} p_{i}\) and \(i\) iterates over the vector. By minimizing the entropy of the pseudo-label as defined above, we promote more confident labeling results to help resist noise in the labeling process1.

**Distribution Alignment loss.** In addition to the noise in pseudo-labels, we propose that significant discrepancies between the pseudo-labels and the segmentation network predictions could also confuse the learning process and lead to unreliable segmentation results. In general, the discrepancies can stem from multiple sources, including the noise-induced unreliability of pseudo-labels, differences between labeled and unlabeled data , and variations in pseudo-labeling methods and segmentation methods [92; 20]. Although entropy regularization could mitigate the impact of noise in pseudo-labels, significant discrepancies may still persist between the pseudo-labels and the predictions of the segmentation network. To mitigate this issue, we propose that the pseudo-labels and network can be jointly optimized to narrow such discrepancies, making generated pseudo-labels not diverge too far from the segmentation predictions. Therefore, we introduce the distribution alignment loss.

To properly define the distribution alignment loss (\(L_{DA}\)), we measure the KL divergence between the pseudo-labels (\(\)) and the segmentation network predictions (\(\)) and aim to minimize this divergence. Specifically, we define the distribution alignment loss as follows:

\[L_{DA}=KL(||),\] (3)

where \(KL(||)\) refers to the KL divergence. Using the above formulation has several benefits. For example, the KL divergence can simplify the overall loss \(L_{p}\) into a deceptively simple form that demonstrates desirable properties and also performs better than other distance measurements. More details will be presented in the following sections.

**Simplified ERDA.** With the \(L_{ER}\) and \(L_{DA}\) formulated as above, given that \(KL(||)=H(,)-H()\) where \(H(,)\) is the cross entropy between \(\) and \(\), we can have a simplified ERDA formulation as:

\[L_{p}=H(,)+(-1)H().\] (4)

In particular, when \(=1\), we obtain the final ERDA loss2:

\[L_{p}=H(,)=_{i}-p_{i} q_{i}\] (5)

The above simplified ERDA loss describes that the entropy regularization loss and distribution alignment loss can be represented by a single cross-entropy-based loss that optimizes both \(\) and \(\).

We would like to emphasize that Eq. (5) is distinct from the conventional cross-entropy loss. The conventional cross-entropy loss utilizes a fixed label and only optimizes the term within the logarithm function, whereas the proposed loss in Eq. (5) optimizes both \(\) and \(\) simultaneously.

### Delving into the Benefits of ERDA

To formulate the distribution alignment loss, different functions can be employed to measure the differences between \(\) and \(\). In addition to the KL divergence, there are other distance measurements like mean squared error (MSE) or Jensen-Shannon (JS) divergence for replacement. Although many mutual learning methods [20; 92; 41; 38] have proven the effectiveness of KL divergence, a detailed comparison of KL divergence against other measurements is currently lacking in the literature. In this section, under the proposed ERDA learning framework, we show by comparison that \(KL(||)\) is a better choice and ER is necessary for weakly-supervised 3D segmentation.

To examine the characteristics of different distance measurements, including \(KL(||)\), \(KL(||)\), \(JS(||)\), and \(MSE(||)\), we investigate the form of our ERDA loss \(L_{p}\) and its impact on the learning for pseudo-label generation network given two situations during training.

More formally, we shall assume a total of \(K\) classes and define that a pseudo-label \(=[p_{1},...,p_{K}]\) is based on the confidence scores \(=[s_{1},...,s_{K}]\), and that \(=()\). Similarly, we have a segmentation network prediction \(=[q_{1},...,q_{K}]\) for the same point. We re-write the ERDA loss \(L_{p}\) in various forms and investigate the learning from the perspective of gradient update, as in Tab. 1.

**Situation 1: Gradient update given confident pseudo-label \(\).** We first specifically study the case when \(\) is very certain and confident, _i.e.,_\(\) approaching a one-hot vector. As in Tab. 1, most distances yield the desired zero gradients, which thus retain the information of a confident and reliable \(\). In this situation, however, the \(KL(||)\), rather than \(KL(||)\) in our method, produces non-zero gradients that would actually increase the noise among pseudo-labels during its learning, which is not favorable according to our motivation.

**Situation 2: Gradient update given confusing prediction \(\).** In addition, we are also interested in how different choices of distance and \(\) would impact the learning on pseudo-label if the segmentation model produces confusing outputs, _i.e.,_\(\) tends to be uniform. In line with the motivation of ERDA learning, we aim to regularize the pseudo-labels to mitigate potential noise and bias, while discouraging uncertain labels with little information. However, as in Tab. 1, most implementations yield non-zero gradient updates to the pseudo-label generation network. This update would make \(\) closer to the confused \(\), thus increasing the noise and degrading the training performance. Conversely, only \(KL(||)\) can produce a zero gradient when integrated with the entropy regularization with \(=1\). That is, only ERDA in Eq. (5) would not update the pseudo-label generation network when \(\) is not reliable, which avoids confusing the \(\). Furthermore, when \(\) is less noisy but still close to a uniform vector, it is indicated that there is a large close-zero plateau on the gradient surface of ERDA, which benefits the learning on \(\) by resisting the influence of noise in \(\).

In addition to the above cases, the gradients of ERDA in Eq. (5) could be generally regarded as being aware of the noise level and the confidence of both pseudo-label \(\) and the corresponding prediction \(\). Especially, ERDA produces larger gradient updates on noisy pseudo-labels, while smaller updates on confident and reliable pseudo-labels or given noisy segmentation prediction. Therefore, our formulation demonstrates its superiority in fulfilling our motivation of simultaneous noise reduction and distribution alignment, where both \(L_{ER}\) and KL-based \(L_{DA}\) are necessary. We provide more empirical studies in ablation (Sec. 4.3) and detailed analysis in the supplementary.

### Implementation Details on Pseudo-Labels

In our study, we use a prototypical pseudo-label generation process due to its popularity as well as simplicity . Specifically, prototypes  denote the class centroids in the feature space, whichare calculated based on labeled data, and pseudo-labels are estimated based on the feature distances between unlabeled points and class centroids.

As shown in Fig. 2, we use a momentum-based prototypical pseudo-label generation process due to its popularity as well as simplicity [94; 85; 93]. Specifically, prototypes  denote the class centroids in the feature space, which are calculated based on labeled data, and pseudo-labels are estimated based on the feature distances between unlabeled points and class centroids. To avoid expensive computational costs and compromised representations for each semantic class [94; 87; 47], momentum update is utilized as an approximation for global class centroids.

Based on the momentum-updated prototypes, we attach an MLP-based projection network to help generate pseudo-labels and learn with our method. Aligned with our motivation, we do not introduce thresholding-based label selection or one-hot conversion [46; 94] to process generated pseudo-labels. More details are in the supplementary.

More formally, we take as input a point cloud \(\), where the labeled points are \(^{l}\) and the unlabeled points are \(^{u}\). For a labeled point \(^{l}\), we denote its label by \(y\). The pseudo-label generation process can be described as follows:

\[_{k}=^{l}}_{^{l } y=k}g f()\;,\;C_{k} mC_{k}+(1-m)_{k},\] \[^{u}\;,\;s_{k}=d(g f( ),C_{k})\;,\;=(),\]

where \(C_{k}\) denotes the global class centroid for the \(k\)-th class, \(N_{k}^{l}\) is the number of labeled points of the \(k\)-th class, \(g f=g(f())\) is the transformation through the backbone network \(f\) and the projection network \(g\), \(m\) is the momentum coefficient, and we use cosine similarity for \(d(,)\) to generate the score \(\). By default, we use 2-layer MLPs for the projection network \(g\) and set \(m=0.999\).

Besides, due to the simplicity of ERDA, we are able to follow the setup of the baselines for training, which enables straightforward implementation and easy adaptation on various backbone models with little overhead.

**Overall objective.** Finally, with ERDA learning in Eq. (5), we maximize the same loss for both labeled and unlabeled points, segmentation task, and pseudo-label generation, where we allow the gradient to back-propagate through the (pseudo-)labels. The final loss is given as

\[L=}_{^{l}}L_{ce}(,y)+ }_{^{u}}L_{p}(, ),\] (6)

where \(L_{p}(,)=L_{ce}(,)=H(, )\) is the typical cross-entropy loss used for point cloud segmentation, \(N^{l}\) and \(N^{u}\) are the numbers of labeled and unlabeled points, and \(\) is the loss weight.

## 4 Experiments

We present the benefits of our proposed ERDA by experimenting with multiple large-scale datasets, including S3DIS , ScanNet , SensatUrban  and Pascal . We also provide ablation studies for better investigation.

Figure 2: Detailed illustration of our ERDA with the prototypical pseudo-label generation process, which is shared for both (a) and (b) in Fig. 1.

### Experimental Setup

We choose RandLA-Net  and CloserLook3D  as our primary baselines following previous works. Additionally, while transformer models [17; 52] have revolutionized the field of computer vision as well as 3D point cloud segmentation [97; 42], none of the existing works have addressed the training of transformer for point cloud segmentation with weak supervision, even though these models are known to be data-hungry . We thus further incorporate the PointTransformer (PT)  as our baseline to study the amount of supervision demanded for effective training of transformer.

For training, we follow the setup of the baselines and set the loss weight \(=0.1\). For a fair comparison, we follow previous works [94; 95; 32] and experiment with different settings, including the 0.02% (1pt), 1% and 10% settings, where the available labels are randomly sampled according to the ratio3. More details are given in the supplementary.

### Performance Comparison

**Results on S3DIS.** S3DIS  is a large-scale point cloud segmentation dataset that covers 6 large indoor areas with 272 rooms and 13 semantic categories. As shown in Tab. 2, ERDA significantly improves over different baselines on all settings and almost all classes. In particular, for confusing classes such as column, window, door, and board, our method provides noticeable and consistent improvements in all weak supervision settings. We also note that PT suffers from severe over-fitting and feature collapsing under the supervision of extremely sparse labels of "1pt" setting; whereas it is alleviated with ERDA, though not achieving a satisfactory performance. Such observation agrees with the understanding that transformer is data-hungry .

Impressively, ERDA yields competitive performance against most supervised methods. For instance, with only \(1\%\) of labels, it achieves performance better than its stand-alone baselines with full supervision. Such result indicates that the ERDA is more successful than expected in alleviating the lack of training signals, as also demonstrated qualitatively in Fig. 3.

Therefore, we further extend the proposed method to fully-supervised training, _i.e.,_ in setting "Fully" in Tab. 2. More specifically, we generate pseudo-labels for all points and regard the ERDA as an auxiliary loss for fully-supervised learning. Surprisingly, we observe non-trivial improvements (+3.7 for RandLA-Net and +3.4 for CloserLook3D) and achieve the state-of-the-art performance of 72.6 (+2.2) in mIoU with PT. We suggest that the improvements are due to the noise-aware learning from ERDA, which gradually reduces the noise during the model learning and demonstrates to be generally effective. Moreover, considering that the ground-truth labels could suffer from the problem of label noise , we also hypothesize that pseudo-labels from ERDA learning could stabilize fully-supervised learning and provide unexpected benefits.

We also conduct the 6-fold cross-validation, as reported in Tab. 3. We find our method achieves a leading performance among both weakly and fully-supervised methods, which further validates the effectiveness of our method.

**Results on ScanNet.** ScanNet  is an indoor point cloud dataset that covers 1513 training scenes and 100 test scenes with 20 classes. In addition to the common settings, _e.g.,_ 1% labels, it also provides official data efficient settings, such as 20 points, where for each scene there are a pre-defined

  settings & methods & mIoU \\   & PointNet  & 23.7 \\  & RandLA-Net  & 64.5 \\  & RCPonv  & 76.6 \\  & HybridCR  & 70.7 \\  & \(\)  & 73.5 \\  & PointNet\(\)  & 74.4 \\  & RandLA-Net + **ERDA** & 57.0 \\   &  & All-Trans  & 54.4 \\  & CloserLook3D + **ERDA** & 57.0 \\   & CloserLook3D + **ERDA** & 57.0 \\   & & \(\)  & 54.0 \\   & & RandLA-Net + **ERDA** & 56.4 \\    & & \(\)  & 51.1 \\   & PSD  & 68.0 \\   & HybridCR  & 69.2 \\   & RandLA-Net + **ERDA** & 69.4 \\   & CloserLook3D + **ERDA** & 72.3 \\    & & \(\) **+ ERDA** & 73.5 \\  

Table 4: Results on ScanNet test.

Figure 3: We show obvious improvement of our ERDA over baseline (RandLA-Net) on different scenes from S3DIS Area 5. In the office and hallway (top 2), ERDA produces more detailed and complete segmentation for windows and doors, and avoids over-expansion of the board and bookcase on the wall, thanks to the informative pseudo-labels. In more cluttered scenes (bottom 2), ERDA tends to make cleaner predictions by avoiding improper situations such as desk inside clutter and preserving important semantic classes such as columns.

  settings & methods & mIoU \\   & PointNet  & 23.7 \\  & RandLA-Net  & 64.5 \\  & RCPonv  & 76.6 \\  & HybridCR  & 70.7 \\  & \(\)  & 73.5 \\  & PointNet\(\)  & 74.4 \\  & RandLA-Net + **ERDA** & 71.0 \\  & CloserLook3D + **ERDA** & 73.7 \\   &  & All-Trans  & 54.4 \\  & CloserLook3D + **ERDA** & 57.0 \\   & & \(\)  & 54.0 \\   & & RandLA-Net + **ERDA** & 56.4 \\    & & \(\)  & 53.9 \\   & PSD  & 68.0 \\   & HybridCR  & 69.2 \\   & RandLA-Net + **ERDA** & 69.4 \\   & CloserLook3D + **ERDA** & 72.3 \\    & & \(\) **+ ERDA** & 73.5 \\  

Table 5: Results on SensatUrban test.

set of 20 points with the ground truth label. We evaluate on both settings and report the results in Tab. 4. We largely improve the performance under \(0.1\%\) and \(1\%\) labels. In 20pts setting, we also employ a convolutional baseline (CloserLook3D) for a fair comparison. With no modification on the model, we surpass MIL-transformer  that additionally augments the backbone with transformer modules and multi-scale inference. Besides, we apply ERDA to baseline under fully-supervised setting and achieve competitive performance. These results also validate the ability of ERDA in providing effective supervision signals.

**Results on SensatUrban.** SensatUrban  is an urban-scale outdoor point cloud dataset that covers the landscape from three UK cities. In Tab. 5, ERDA surpasses SQN  under the same 0.1% setting as well as its fully-supervised baseline, and also largely improves under full supervision. It suggests that our method can be robust to different types of datasets and effectively exploits the limited annotations as well as the unlabeled points.

**Generalizing to 2D Pascal.** As our ERDA does not make specific assumptions on the 3D data, we explore its potential in generalizing to similar 2D settings. Specifically, we study an important task of semi-supervised segmentation on image [72; 89; 8] and implement our method to the popular baseline, FixMatch , which combines the pseudo-labels with weak-to-strong consistency and is shown to benefit from stronger augmentation . We use DeepLabv3+  with ResNet-101 .

As in Tab. 6, we show that ERDA brings consistent improvement from low to high data regime, despite the existence of strong data augmentation and the very different data as well as setting4. It thus indicates the strong generalization of our method. We also see that the improvement is less significant than the 3D cases. It might be because 2D data are more structured (_e.g.,_ pixels on a 2D grid) and are thus less noisy than the 3D point cloud.

### Ablations and Analysis

We mainly consider the 1% setting and ablates in Tab. 7 to better investigate ERDA and make a more thorough comparison with the current pseudo-label generation paradigm. For more studies on hyper-parameters, please refer to the supplementary.

**Individual effectiveness of ER and DA.** To validate our initial hypothesis, we study the individual effectiveness of \(L_{ER}\) and \(L_{DA}\) in Tab. 6(a). While the pseudo-labels essentially improve the baseline performance, we remove its label selection and one-hot conversion when adding the ER or DA term. We find that using ER alone can already be superior to the common pseudo-labels and largely reduce the entropy of pseudo-labels (ent.) as expected, which verifies that the pseudo-labels are noisy, and reducing these noises could be beneficial. The improvement with the DA term alone is even more significant, indicating that a large discrepancy is indeed existing between the pseudo-labels and model prediction and is hindering the model training. Lastly, by combining the two terms, we obtain the ERDA that reaches the best performance but with the entropy of its pseudo-labels larger than ER only and smaller than DA only. It thus also verifies that the DA term could be biased to uniform distribution and that the ER term is necessary.

**Different choices of ER and DA.** Aside from the analysis in Sec. 3.2, we empirically compare the results under different choices of distance for \(L_{DA}\) and \(\) for \(L_{ER}\). As in Tab. 6(b), the outstanding result justifies the choice of \(KL(||)\) with \(=1\). Additionally, all different choices and combina

Table 7: Ablations on ERDA. If not specified, the model is RandLA-Net trained with ERDA as well as dense pseudo-labels on S3DIS under the 1% setting and reports in mIoU. Default settings are marked in gray.

tions of ER and DA terms improve over the common pseudo-labels (63.3), which also validates the general motivation for ERDA.

**Ablating label selection.** We explore in more detail how the model performance is influenced by the amount of exploitation on unlabeled points, as ERDA learning aims to enable full utilization of the unlabeled points. In particular, we consider three pseudo-labels types: common one-hot pseudo-labels, soft pseudo-labels (\(\)), and soft pseudo-labels with ERDA learning. To reduce the number of pseudo-labels, we select sparse but high-confidence pseudo-labels following a common top-\(k\) strategy  with various values of \(k\) to study its influence. As in Tab. 6(c), ERDA learning significantly improves the model performance under all cases, enables the model to consistently benefit from more pseudo-labels, and thus neglects the need for label selection such as top-\(k\) strategy, as also revealed in Fig. 1. Besides, using soft pseudo-labels alone can not improve but generally hinders the model performance, as one-hot conversion may also reduce the noise in pseudo-labels, which is also not required with ERDA.

## 5 Limitation and Future Work

While we mostly focus on weak supervision in this paper, our method also brings improvements under fully-supervised setting. We would then like to further explore the effectiveness and relationship of \(L_{ER}\) and \(L_{DA}\) under full supervision as a future work. Besides, despite promising results, our method, like other weak supervision approaches, assumes complete coverage of semantic classes in the available labels, which may not always hold in real-world cases. Point cloud segmentation with missing or novel classes should be explored as an important future direction.

## 6 Conclusion

In this paper, we study the weakly-supervised 3D point cloud semantic segmentation, which imposes the challenge of highly sparse labels. Though pseudo-labels are widely used, label selection is commonly employed to overcome the noise, but it also prevents the full utilization of unlabeled data. By addressing this, we propose a new learning scheme on pseudo-labels, ERDA, that reduces the noise, aligns to the model prediction, and thus enables comprehensive exploitation of unlabeled data for effective training. Experimental results show that ERDA outperforms previous methods in various settings and datasets. Notably, it surpasses its fully-supervised baselines and can be further generalized to full supervision as well as 2D images.

**Acknowledgement.** This project is supported in part by ARC FL-170100117, and IC-190100031.