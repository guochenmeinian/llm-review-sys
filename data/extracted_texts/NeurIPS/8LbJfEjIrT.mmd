# Pricing and Competition for Generative AI

Rafid Mahmood

NVIDIA & University of Ottawa

rmahmood@nvidia.com

###### Abstract

Compared to classical machine learning (ML) models, generative models offer a new usage paradigm where (i) a single model can be used for many different tasks out-of-the-box; (ii) users interact with this model over a series of natural language prompts; and (iii) the model is ideally evaluated on binary user satisfaction with respect to model outputs. Given these characteristics, we explore the problem of how developers of new generative AI software can release and price their technology. We first develop a comparison of two different models for a specific task with respect to user cost-effectiveness. We then model the pricing problem of generative AI software as a game between two different companies who sequentially release their models before users choose their preferred model for each task. Here, the price optimization problem becomes piecewise continuous where the companies must choose a subset of the tasks on which to be cost-effective and forgo revenue for the remaining tasks. In particular, we reveal the value of market information by showing that a company who deploys later after knowing their competitor's price can always secure cost-effectiveness on at least one task, whereas the company who is the first-to-market must price their model in a way that incentivizes higher prices from the latecomer in order to gain revenue. Most importantly, we find that if the different tasks are sufficiently similar, the first-to-market model may become cost-ineffective on all tasks regardless of how this technology is priced.

## 1 Introduction

The recent explosion of generative artificial intelligence (AI) has introduced new machine learning (ML) frameworks for applications from chatbots to robotics (Wu et al., 2023; Nasiriany et al., 2024). Whereas in classical ML, a user interacted with a single model designed for a specific predictive task (e.g., classification) via input data and output predictions, a single generative AI model can solve a variety of tasks for a user out-of-the-box (Brown et al., 2020). Moreover, users interact with the generative model over a universal interface of natural language prompting (Arora et al., 2022).

The prompt-based paradigm has fostered two recent human-AI interaction trends. First, prompting facilitates such a wide distribution of tasks (i.e., user inputs and model outputs) that conventional metrics for evaluating models have become insufficient, leaving the most effective evaluation metric to be a binary score of whether the user is satisfied with the model output (Li et al., 2024; Chiang et al., 2024). For example, Ziegler et al. (2024) empirically analyzed the GitHub Copilot software to reveal that the frequency of generated code approved by a user _'is a better predictor of perceived [user] productivity than alternative measures.'_ Second, if a user does not receive a satisfactory output, they can try again in another prompting round by inputting to the model additional information (Castro et al., 2023). For instance, the Anthropic HH and the Chatbot Arena datasets report on average 2.3 and 1.3 prompting rounds per conversation, respectively (Bai et al., 2022; Chiang et al., 2024).

In this work, we study the impact of these interaction characteristics on the pricing of generative AI technology. While classical ML products can be priced by analyzing the user demand for a model that can achieve a given performance metric on a specific task (Gurkan and de Vericourt, 2022, Mahmoodet al., 2022), a generative AI model is priced per user prompt 1. This set price determines the user cost for multiple different tasks and variable number of prompting rounds, e.g., the cost of using GPT-4 for math reasoning or code generation depends only on the per-token price, and the length and number of prompts. Thus, developers of a generative AI product must factor the demand for all potential use-case tasks of the technology when setting a price. This pricing problem becomes further challenging when considering the rapidly growing marketplace of competing generative AI models, since companies must also ensure that their products do not become unattractive to users as soon as a competitor develops a newer and better model.

We first characterize when, for a given task, a user will prefer one generative AI model versus another. We argue that users minimize their total cost, measured by the cost-per-prompt times the number of prompting rounds needed for the model to produce a satisfactory output; this leads to a comparison of price-performance competitiveness between AI models. We then study a game with two firms developing competing models used for a set of tasks. Both firms know each other's model's performance on the tasks. The first firm deploys their product and sets a price, followed by the second firm with their product and price. Finally, a user decides which models to use for each task. Both firms seek to maximize revenue, but the first firm acts without knowledge of their competitor's price. Figure 1 summarizes the problem setting and insights. Our key observations include:

1. **The pricing problem reduces to a piecewise optimization problem, where firms price their model to be competitive on a subset of the tasks while forgoing revenue from the others.** This subset can be determined by ranking the tasks on the competitive ratio between the two models for each task and selecting the most competitive tasks.
2. **A firm who deploys late always obtains revenue from at least one task by leveraging the available market information.** In contrast, the first-to-market must strategically set their prices to encourage the latecomer to set higher prices and focus on fewer tasks.
3. **Under certain conditions on model performance and user demand, the first-to-market may acquire zero revenue regardless of their price.** In these settings, the latecomer naturally maximizes their revenue by being competitive for all tasks. Thus, developers that are first should have a minimum model performance before deploying their product.

## 2 Related literature

**Evaluating ML models.** ML models are typically evaluated on generalization error for a task via out-of-sample test dataset benchmarks and competitions (Deng et al., 2009). Generative AI and large language models (LLMs) are evaluated on a suite of benchmark tasks such as for coding (Chen et al., 2021), math (Cobbe et al., 2021), and problem solving (Hendrycks et al., 2021). However, standardized benchmarks become uninformative over time as new models are trained to overfit to these metrics (Roelofs et al., 2019; Koch et al., 2021). Recently, Chiang et al. (2024) introduced the Chatbot Arena for comparing LLMs head-to-head on human preference. Here, a user poses a real-world prompt which is input to two models. The user reviews both model outputs and can even continue multiple conversation rounds, before ranking which model generated a satisfactory answer first. Although difficult to measure, user satisfaction rate is increasingly viewed as the most informative metric as seen from generated code approvals on GitHub Copilot (Ziegler et al., 2024), or perceived aesthetic quality of text-to-image generation such as MidJourney and Playground (Li et al., 2024). Our work combines user satisfaction with a user cost to construct a price-performance ratio for comparing different models.

Figure 1: Overview of the competitive pricing problem for generative AI models.

Human-generative AI interaction.Prompt-based interaction has increased the diversity of tasks where these models can be applied (Eloundou et al., 2023). Castro et al. (2023) analyze how and when human users will use a generative AI model for a task versus performing it manually, as well as the characteristics of interacting over multiple prompt rounds. The quality of prompts is crucial to generating higher-quality answers (Liu et al., 2023; Binz and Schulz, 2023). This has motivated studies on prompt techniques, such as chain-of-thought (Wei et al., 2022) and self-consistency (Wang et al., 2022). In our work, we treat prompt quality as a random variable and to simplify the structural analysis, assume that users will interact with a generative AI model for as many prompting rounds as needed to get a satisfactory answer.

Pricing and competition.Duopolies of competitive products use game theoretic models such as the Bertrand (i.e., simultaneous pricing) and Stackelberg (i.e., sequential pricing) models of interaction (Gibbons, 1992). Both deterministic and probabilistic demand can be used to study oligopolistic pricing of a single or multiple products Chintagunta and Rao (1996); Gallego and Hu (2014). Specific structured demand frameworks allow for identifying market equilibria and failure settings where revenue is unobtainable (Federgruen and Hu, 2015, 2019). Our work is most closely related to the Stackelberg literature by modeling a sequential game and exploring the conditions under exponential demand that make certain generative AI models unattractive (Hamilton and Slutsky, 1990).

Pricing AI products.AI technology can be priced at various levels, ranging from training data to model queries (Liu et al., 2021; Chen et al., 2019; Cong et al., 2022). A core aspect of the pricing problem involves valuating the ML model based on performance (Xu et al., 2024). ML products are further susceptible to an AI flywheel effect where the release and price of an AI product will affect the subsequent collection of new training data from users, leading to a dynamic pricing problem (Gurkan and de Vericourt, 2022; Chen and Xue, 2023). More generally, novel technology products such as a new generative AI model with emergent use-cases may feature social-learning and dynamically growing market sizes (Feldman et al., 2019; Zhang et al., 2022). The closest to our work is Gurkan and de Vericourt (2022) who explore pricing and contracting the development of a classical ML model under the AI flywheel. In contrast, our work explores competition between ML model developers when faced with a diverse set of potential downstream tasks for which the model can be used.

## 3 Main model

We first define the characteristics of the pricing problem. We then propose a model of user choice between two competing models from a price-performance perspective.

### Problem setup

Tasks.We define a task as a set of independent problem instances where for each instance, a user queries a machine learning model with an input prompt and receives an output generated the model. For example, a programming task may have instances where a user inputs a commented function definition and the model must complete the code to perform the function Chen et al. (2021); Ziegler et al. (2024). Task instances are evaluated by a user via a binary correctness score. For tasks where correctness is unambiguous (e.g., whether the program runs), the score is equivalent to accuracy, whereas for open-ended tasks (e.g., whether the output meets the stylistic preferences of the user), we treat correctness simply as whether the user is satisfied with the output 2

Generative AI model.Given a set of \(T\) different tasks, a generative model is an ML model that can be used to solve instances of any of the different tasks via prompts. We define this model as a tuple \((p,V_{1},V_{2},,V_{T})\) where \(p\) denotes the price for using the model, as measured in dollars-per-prompt (see Appendix B for the extension to pricing per-token), and for each \(t[T]\), \(V_{t}(0,1)\) denotes the average score of the model over instances of each task. We assume that \(V_{t} 1\) implies that the model can always generate a correct output for any task instance and \(V_{t} 0\) implies that the model will always generate an incorrect output. Therefore, for any random instance of task \(t\), \(V_{t}\) can also be interpreted as a Bernoulli probability of the generative model producing a satisfactory output in a single attempt.

Users will not use the generative model if it's price is too high with respect to the user's valuation of the specific task. For any given task \(t\), let \(D_{t}(p)_{+}\) be the demand function, i.e., the number of users who will use a generative AI model for task \(t\) as a function of the price \(p\). Following standard assumptions, we assume that \(D_{t}(p)\) is differentiable and non-increasing in the model price, as well as being known to the developer of the AI model (Gallego and Van Ryzin, 1994).

Multi-round use.Most ML benchmarks typically evaluate models on whether the models can generate the correct output under a single prompt round (Chen et al., 2021; Cobbe et al., 2021; Hendrycks et al., 2021). However, in-the-wild users of generative models typically have interactive multi-round conversations where if the model generates an unsatisfactory solution after the first prompt, the user can provide feedback via their preferences or corrections in a second prompt round (Castro et al., 2023; Liao et al., 2024). For example in code completion, if the model fails to account for an edge-case input to the function, the user can identify the edge-case and ask the model to account for it. To characterize this multi-round use, we extend the single prompt to a sequence of Bernoulli trials that continue until the user is satisfied with the model output. For simplicity of modeling, we make the following assumptions on user behavior.

**Assumption 1**.: _The total number of prompting rounds \(n_{t}(V_{t})\) that a user will engage with the model: (i) has a finite mean; and (ii) is independent of the model price \(p\) conditioned on the user knowing \(V_{t}\)._

Assumption 1 implies that the price of a model only determines demand via whether the model is used at all, rather than how many times (i.e., prompting rounds) the model is used. Under this assumption, there are many choices for modeling the distribution of \(n_{t}(V_{t})\). We give three examples:

* _Geometric:_ Because non-expert users tend to design uninformative prompts (Zamfirescu-Pereira et al., 2023), we may suppose the probability of success on any round does not depend on user input, and each round is an i.i.d. Bernoulli trial with probability \(V_{t}\). Then, the total number of rounds is \(n_{t}(V_{t})\), following a Geometric distribution.
* _Truncated Geometric:_ Users may quit the model after a maximum \(T_{t}\) rounds if it fails to generate a satisfactory response (Castro et al., 2023). For instance, conversations in the Chatbot Arena dataset terminate after an average 1.3 rounds (Chiang et al., 2024). Here, \(\{n_{t}=n\}:=(1-V_{t})^{n-1}V_{t}\) for \(1 n<T_{t}\) and \(\{n_{t}=T_{t}\}:=(1-V_{t})^{T_{t}-1}\).
* _Prompt-dependent:_ Suppose the success probability is prompt-dependent \(V_{t}(x_{i})\) where \(x_{i}\{x\}\) is the prompt on the \(i\)-th round. If users prompt until the model generates a satisfactory answer, we have \(\{n_{t}=n\}:=_{x_{1},,x_{n}}[V_{t}(x_{n})_{i=1}^{n-1}( 1-V_{t}(x_{i}))]\).

Ultimately, the choice of characterizing \(n_{t}\) depends on the information available to the generative AI model provider. With limited information, the Geometric assumption may be most practical, but given knowledge of user prompts, we may consider more sophisticated models. Our results all hold independent of the distribution as long as Assumption 1 is satisfied. For ease of notation and interpretability, we assume \(n_{t}(V_{t})\) in the remainder of this work.

### Modeling user preference between AI models

Given the above task and user behavior framework, we analyze the problem of a user who must choose between two competing generative models to solve instances of their tasks. Since a user may prefer different models for different tasks, we consider a single task and omit subscript \(t\).

Consider two generative models: model A \((q,W)\) and model B \((p,V)\). Under Assumption 1, given a sufficient number of prompt rounds, both models can eventually solve every task instance. Thus, a rational user will seek to minimize the expected cost of completing a task instance, measured by the average price-per-prompt times the expected number of rounds required to complete the task instance. In this comparison, model B will incur a lower cost for the user if

\[p[n(V)] q[n(W)]\ \ .\] (1)

Otherwise, model A incurs lower user costs. We assume that model B is preferred in ties. Note that the implication follows from our Geometric assumption of \(n(V)\).

Condition (1) states that for any task, a specific generative AI model is preferred if the price-performance ratio for this task (i.e., the cost of using this model over the model's performance) is lower than any other competing generative model. For example, if model B is twice as likely to generate a user-satisfactory output as model A for a given input prompt, i.e., \(V=2W\), then the user will prefer model B as long the cost of prompting this model is not twice as high, i.e., \(p 2q\). Otherwise, the user will incur lower costs and still obtain their desired outputs by simply prompting the weaker model for twice as many rounds.

We note that (1) can also compare the use of a generative AI model versus manually performing the task (Castro et al., 2023). For instance, if we treat model B as a human and a prompt round as a timed attempt at completing a task (e.g., coding the function within one hour), then \(V\) is the probability of a human being able to perform the task in the single attempt and \(p\) is the time-value of this labor.

Finally, this framework can also compare free-to-use generative AI models such as LLaMA (Touvron et al., 2023). Although there may not be a given price-per-token for using these models, there is a fixed cost to set up the infrastructure and environment. Given an expected total number of task instances, this fixed cost can be approximated to an equivalent \(p\).

## 4 Pricing generative AI models

We now develop a general framework under which a provider of a generative AI model can price their product. We first define the pricing problem as a game between two firms developing competing generative AI models. We then create tractable reformulations for these problems for both firms, representing pricing with and without considering competition.

Pricing problem.Consider a set of \(T\) tasks. Let \((q,W_{1},W_{2},,W_{T})\) and \((p,V_{1},V_{2},,V_{T})\) be the generative models released by two competing firms, A and B, respectively. Firm A deploys their generative AI model (i.e., model A) first and sets the price \(q\) for this product. Then, firm B deploys their competing model (i.e., model B) and sets their price \(p\). After both firms deploy their models, a user with demand functions \(D_{t}()\) for each \(t\) will decide which models to use as determined by (1). We evaluate the total revenue obtained by each firm, given by \(R_{A}(q|p)\) and \(R_{B}(p|q)\) respectively:

\[R_{A}(q|p):=q_{t=1}^{T}D_{t}(q)\{}<}\} 28.452756ptR_{B}(p|q):=p_{t=1}^{T}D_{t}(p) \{}}\}.\] (2)

Note that in practice, the user demand may depend on \(p\) and \(q\) simultaneously; for simplicity, we assume the demand for a specific model to be determined only after the user preference condition (1) is resolved. The results in this section easily generalize to more complex demand functions. The revenue functions are composed of the demand for each task times the price set by the firm (Van Ryzin and Talluri, 2005), summed over all tasks for which the firm's model is competitive according to the price-performance ratios. Each firm's objective is to maximize their revenue. However, because firm A is the first-to-market and they do not know the action that firm B will take; instead, firm A must optimize for the worst-case scenario as determined by firm B. On the other hand, firm B first observes the price set by firm A. Thus, the two firms set prices as follows:

\[q^{*}:=*{arg\,max}_{q 0}\;\{R_{A}(q|) *{arg\,max}R_{B}(p|q)\} 28.452756ptp^{*}:= *{arg\,max}_{p 0}\;\{R_{B}(p|q^{*})\}.\] (3)

We assume both firms know \(V_{t}\) and \(W_{t}\) for all \(t[T]\). This is motivated by the availability of research papers and reported benchmark scores, and the predictability of model performance via power laws (Kaplan et al., 2020). In practice, a firm may not know their competitor's performance, but they can forecast the state-of-the-art score in the short term.

### Pricing in isolation

We first consider firm B's problem, who set their price after firm A has already released a competing model with price \(q^{*}\). Firm B's problem depends on the competitive ratio \(_{t}:=[n(W_{t})]/[n(V_{t})]\) for task \(t[T]\), i.e., the relative ratio of number of prompting rounds between the two firms, which under a Geometric distribution assumption, simplifies to \(_{t}:=V_{t}/W_{t}\). To maximize their revenue, firm B can rank the tasks in order of \(_{t}\), select a subset of tasks in this order, and solve the optimization problem for each subset. This results in an overall piecewise optimization problem.

**Theorem 1**.: _Consider the following ordering \(:[T+1][T+1]\) for which_

\[_{(1)}>_{(2)}>>_{(T)}>_{(T +1)}:=0.\] (4)

_Then, firm B's pricing problem is equivalent to the piecewise optimization problem:_

\[_{t[T]}\;_{p}\;\{p_{s=1}^{t}D_{(s)}(p)\;|\; _{(t)}>_{(t+1)}\}.\] (5)

Theorem 1 shows that a generative AI model should be priced by prioritizing a subset of the tasks and making the model price-performance competitive for those tasks only. Consequently, the firm ignores the remaining tasks for which the model has low competitive ratios \(_{t}\), since they would need extremely low prices in order to satisfy (1) for these tasks. This strategy is due to the observation that for any task \((t)\), if a model satisfies (1), then the model will also satisfy the condition for all \((t^{})\) for \(t^{} t\). Furthermore, Theorem holds without loss of generality with respect to the strict inequalities on (4), since tasks with the same competitive ratios can be grouped together by summing the constituent demand functions. Finally, Theorem 1 holds for arbitrary demand functions. In practice, the demand functions are known and typically have a parametric structure. Figure 2 gives an example using three tasks with demand that decays exponentially with price.

Theorem 1 reveals two key implications on how a firm can price a generative mode when given competitor information. First, pricing reduces to solving \(T\) optimization problems, where each of these problems are of a single variable with a differentiable objective and boundary constraints. Thus, the inner problems can be solved via gradient descent. Second, as long as firm B sets a price \(p_{(1)}\), they will obtain some non-zero revenue, i.e., problem (5) always has a feasible solution. This advantage is due to the fact that firm B sets their price given a fixed \(q\).

### Pricing when accounting for competition

We next consider firm A's problem of setting a problem while assuming that firm B will act optimally next. This pricing problem is a bi-level optimization problem, but it can be solved by ranking the tasks according to the competitive ratios for firm A and prioritizing a subset of these tasks.

Figure 2: _(Left)_ Three tasks with three different exponential demand functions \(D_{1}(p)=100e^{-0.5p}\), \(D_{2}(p)=200e^{-0.5p}\), \(D_{3}(p)=400e^{-0.5p}\). _(Right)_ The corresponding revenue from each task along with the total revenue function for a firm \(R_{B}(p)\). The vertical lines correspond to \(_{1}q\), \(_{2}q\), and \(_{3}q\), where \(_{1}>_{2}>_{3}\). For \(p<_{3}q\), revenue is obtained from all three tasks, for \(p(_{3}q,_{2}q]\), revenue is obtained from only the first two tasks, and for \(p(_{2}q,_{1}q]\), revenue is only obtained from the first task. No revenue can be obtained if \(p>_{1}q\).

**Theorem 2**.: _Firm A's pricing problem is equivalent to the piecewise bi-level optimization problem:_

\[_{t[T-1]} _{q 0} q_{s=t+1}^{T}D_{(s)}(q)\] (6) \[ _{p}\{p_{s=1}^{t}D_{(s)}(p)\ \ _{(t)}>_{(t+1)}\}\] \[>_{p^{}}\{p_{s=1}^{t^{}}D_{(s)}(p ^{})\ \ _{(t^{})}}{q}>_{(t^{ }+1)}\} t^{} t\]

Theorem 2 relies on the observation that the reverse order of \(()\) in (4) cn rank the most to least competitive tasks for firm A. For any \(t\), if \(q<p_{(t)}^{-1}\), then model A is price-performance competitive for all tasks \((t),,(T)\) and firm A will acquire revenue from all these tasks.

Firm A may not always be able to obtain revenue. Problem (6) is infeasible if for every \(t[T-1]\), there is no \(q 0\) that satisfies the bi-level constraint. This infeasibility implies for any \(q 0\), firm B always maximizes their revenue by setting a low price \(p_{(T)}q\). Thus, the key motivation of firm A is that the firm benefits only when their competitor is incentivized to set high prices.

## 5 Structural analysis under exponential demand

Demand is typically modeled via structured parametric functions (Van Ryzin and Talluri, 2005). In this section, we specialize the pricing problem to the standard choice of exponentially decaying parametric demand to extend the previous general results. See Figure 2 (Left) for an example.

**Assumption 2**.: _For each task \(t\), the demand function decays exponentially in price \(D_{t}(p):=a_{t}(-bp)\), where \(a_{t}>0\) is the zero-price base demand and \(b>0\) is the price-sensitivity of users. Furthermore, all tasks have the same price-sensitivity._

Under the exponential demand model, the demand for each task \(t\) is equal to \(a_{t}\) when \(p=0\), and decays at a rate \(-b\). We assume that the decay rate is the same for each task; this is motivated by the practical consideration that the different tasks should have relatively similar 'user value' to have the same price. If one task is uniquely price-sensitive to users, the firm may instead develop a finetuned model for that task or propose incentives such as task-specific discounts to better optimize revenue.

Below, we revisit both firm B's and firm A's problems under this demand model to derive globally optimal solutions and structural insights on the market dynamics.

### Pricing in isolation under exponential demand

Under Assumption 2, firm B's problem (5) now simplifies to the maximum of up to \(T\) possible values that are the globally optimal solution to each of the individual inner optimization problems.

**Theorem 3**.: _Suppose Assumption 2 holds. For any \(t\), let \(_{(t)}:=_{s=1}^{t}a_{(t)}\). Without loss of generality, let \(t^{*}[T]\) be the task index that satisfies \(_{(t^{*})}q 1/b>_{(t^{*}+1)}q\). Then, firm B's pricing problem is equivalent to the following maximum value:_

\[(_{t>t^{*}}\{_{(t)}q_{(t)}e^{-b _{(t)}q}\}\,\ _{(t^{*})}e^{-1})\] (7)

Theorem 3 states that problem (5) can be solved by by solving each of the inner problems starting from the lowest price range up until we arrive at the zero-gradient solution of the revenue function, i.e., \(1/b\). Furthermore, for each of the price ranges before this point, the optimal solution is the upper price boundary. Note that if \(1/b>_{(1)}q\), i.e., there does not exist any \(t^{*}\) satisfying the condition, then we take the maximum of all \(T\) problems. Figure 2 (Right) visualizes the revenue function \(R_{B}(p|q)\) for \(T=3\) tasks with exponential demand. Finally, this structure also reveals that the optimal price is bounded from both above and below via these optima.

**Corollary 1**.: _The optimal price for firm B is bounded \(1/b p^{*}_{(1)}q\)._

### Pricing when accounting for competition under exponential demand

We now revisit firm A's pricing problem, which is a bi-level problem with multiple inner optimization constraints. To obtain structural insights on the challenges of pricing under competition, we explore a special case with \(T=2\) tasks. Without loss of generality, we assume \(_{1}>_{2}\), i.e., \((t)=t\).

When there are only two tasks, firm B will either set their price to be competitive for the first task only (i.e., the task with the higher competitive ratio) or for both tasks. In the latter case, model A would be unattractive for both tasks and firm A would obtain zero revenue. Therefore, firm A should set their price in such a way that they maximize revenue on the second task, while ensuring that firm B is motivated to be competitive only for the first task. Thus, problem (6) simplifies to

\[&_{q}\;\;qD_{2}(q)\\ &\;\;_{p}\{pD_{1}(p)\;|\;_{1} q p>_{2}q\}>_{p}\{p(D_{1}(p)+D_{2}(p))\; |\;_{2}q p>0\}\] (8)

If firm A sets a price \(q\) that is infeasible for this problem, they will get zero revenue. Furthermore, this problem reduces to two single-level optimization problems with only bounding constraints.

**Theorem 4**.: _Suppose that \(T=2\), that Assumption 2 holds, and without loss of generality, assume \((t)=t\). For \(z\), let \((z)\) be the Lambert \(\) function defined only over \(z>-e^{-1}\). If_

\[}{_{1}}-(-e^{-1}}{a_{1}+ a_{2}})\] (9)

_then, the firm A's pricing problem is equivalent to_

\[\{qa_{2}e^{-bq}\;|\;-}(- e^{-1}}{a_{1}+a_{2}}) q>0\}.\] (10)

_Otherwise, firm A's problem is equivalent to_

\[\{qa_{2}e^{-bq}\;|\;-_{2})}( }{_{2}}+}{a_{1}+a_{2}}) q> 0\}.\] (11)

Recall from Theorem 3, the second-level problems in (8) can be solved analytically by checking the boundary points and zero-gradient solution. Theorem 4 uses this property to map problem (8) to two sub-problems based on whether condition (9) holds.

Determining which problem to solve to obtain the optimal price depends on a relationship between two constants \(_{2}/_{1}\) and \(a_{1}/(a_{1}+a_{2})\). Here, \(_{2}/_{1}\) is the relative competitive ratio with respect to

Figure 3: The relationship between \(_{2}/_{1}\) and \(a_{1}/(a_{1}+a_{2})\) for firm A. In the blue region, firm B will always set a price that is competitive on both tasks and firm A will acquire zero revenue. In the orange region, the maximum price that firm A can set is upper bounded (see problem (11)). In the green region, the maximum price that firm A can set has a higher upper bound (see problem (10)).

the two tasks for firm B, where \(_{1}>_{2}>0\). Thus, \(_{2}/_{1} 1\) suggests that the relative performance differences between model A and model B are similar for both tasks, whereas \(_{2}/_{1} 0\) suggests that relative to model A, model B's performance is much worse on the second task than for the first task. The second parameter \(a_{1}/(a_{1}+a_{2})\) is the fraction of the total demand that is occupied by the first task. If this is close to \(1\), then the first task has significantly higher demand than the second, but if it is close to \(0\), then the first task has significantly lower demand than the second.

We now discuss the structural insights obtained from Theorem 4 (see Figure 3 for a visualization). First, note that when condition (9) is satisfied, firm A is able to set higher prices than it could if the condition were not satisfied. In the latter case, the optimal price that firm A can set must be upper bounded by the constraint in problem (11), which in this scenario, is less than the upper bound in problem (10). Intuitively, this condition partitions firm A's pricing problem into two regimes: a high-price and low-price regime. Furthermore, the high-price regime is only attainable if the relative performance difference between the two tasks is greater than the Lambert \(\) function of the fraction of total demand occupied by the first task.

Second, if firm B's relative performance difference between the two tasks is larger than the fraction of demand occupied by the first task, then firm A's pricing problem is infeasible. That is, no matter what price that firm A sets, firm B is always incentivized to set a price that ensures users will prefer model B and consequently, leave no revenue for firm A.

**Proposition 1**.: _If \(_{2}/_{1}>a_{1}/(a_{1}+a_{2})\), then for any price that firm A sets, firm B will always set a price that allows them to be price-performance competitive for both tasks._

Intuitively, if the relative performance difference is high, then model B's performance relative to model A is approximately the same for both tasks. Consequently, the range \((_{2}q,_{1}q]\) is small, meaning that a small perturbation from this price would not significantly decrease firm B's revenue from the first task, while permitting the firm to obtain revenue from the second task as well. Note that model B does not necessarily have to be 'better' than model A, only that the performance on the tasks must be similar. Finally, this ratio \(_{2}/_{1}\) only needs to be larger than the fraction of total demand that is occupied by the first task. Consequently, even if the ratio is small, firm B can still be incentivized to set a competitive price for both tasks if the potential revenue that can be obtained from the second task is high.

Theorem 4 and Proposition 1 sets a guideline for when a firm should deploy their generative AI model. Consider a company that has developed a model for a new application area with no competitors. This company knows that upon releasing their model to the public, competitors will release their own models. If the first-to-market company believes that the use-cases for this model are sufficiently similar to each other with respect to model performance, but are differentiated with respect to user demand, then they must ensure that the model performs exceedingly well on at least one specific use-case that their competitors cannot match. That is, the company must differentiate their product , or competitors can outprice the initial company with similar products.

Although firm A must price accounting for firm B's actions, if model A is sufficiently differentiated from model B, then firm A can acquire their maximum possible revenue. Recall that the zero-gradient optimal price for problem (8) is \(q^{*}=1/b\). Furthermore recall that if condition (9) is met, then firm A can set higher prices for their model. We show below that if condition (9) is satisfied and if \(_{2}\) is sufficiently low with respect to the demand ratio, then the optimal price is feasible.

**Proposition 2**.: _If \(_{2}-(a_{1}e^{-1}/(a_{1}+a_{2}))(_{1},1)\), then firm A maximizes their revenue by setting \(q^{*}=1/b\)._

## 6 Conclusion

We study how a company developing a generative AI model can set the price for this technology. Generative AI models are a fundamentally different technology product compared to classical AI models due to two factors. First, a single generative AI model is performant on multiple distinct use-cases that each invite individual respective user demands. Second, generative AI models offer interactivity via prompting, thereby encouraging 'geometric' user interaction where users can repeatedly prompt the model until it generates a satisfactory answer, compared to classical non-interactive AI models that invite one-shot 'Bernoulli' interaction. These features combined with a singular unit price per-prompt for model use warrant new revenue maximization frameworks for this technology.

We find that for generative AI models, the pricing problem reduces to ranking the different tasks in order of the relative performance of the model versus a competing alternative. In isolation, a company can then always obtain non-zero revenue by setting a price to be competitive for at least one downstream task. However, when considering the competition from alternative models that may be released after the price is set, the company faces strict upper bounds on the prices they can set based on the performance of the company's model relative to the latecomers. In particular, if the relative difference in performances on the tasks is sufficiently small, then a competitor will always be able to outprice the company on all tasks. This result reveals that an outsized performance improvement on at least one of the downstream applications of a generative AI model is essential to maximizing revenue.

Limitations.We explore a theoretical market problem where firms know user demand and the performance of competing AI models. In practice, these would be estimated with some noise. Furthermore, we study a static marketplace where each firm sets their price once. In contrast, AI technologies feature a flywheel where a low price and an early release of a product can allow for a firm to collect more training data and improve their model downstream (Gurkan and de Vericourt, 2022). In particular, the opportunity to acquire high-quality data can significantly improve model performance, thereby motivating the first mover position. Finally, we do not include the cost of developing the generative AI models themselves, but assumes that the firms have already decided to build these models. The market dynamics can change when considering how large of a model to build, how much resources (e.g., compute hours) to spend, or even whether to build a generative AI model. We see these scenarios as important future extensions.

Societal impact.Pricing of generative AI can significantly affect the democratization of generative AI technology. This paper explores the conditions that incentivize firms to develop or deploy this technology, e.g., when firms can obtain revenue. Setting appropriate prices for these models can allow for this technology to be more easily accessible to a wider set of users.