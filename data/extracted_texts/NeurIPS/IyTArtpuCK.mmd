# Assumption violations in causal discovery and the robustness of score matching

Francesco Montagna

MaLGa, Universita di Genova

&Atalanti A. Mastakouri

AWS

&Elias Eulig

German Cancer Research Center (DKFZ)

&Nicoletta Noceti

MaLGa, Universita di Genova

&Lorenzo Rosasco

MaLGa, Universita di Genova

MIT, CBMM

Istituto Italiano di Tecnologia

&Dominik Janzing

AWS

&Bryon Aragam

University of Chicago

&Francesco Locatello

Institute of Science and Technology Austria (ISTA)

###### Abstract

When domain knowledge is limited and experimentation is restricted by ethical, financial, or time constraints, practitioners turn to observational causal discovery methods to recover the causal structure, exploiting the statistical properties of their data. Because causal discovery without further assumptions is an ill-posed problem, each algorithm comes with its own set of usually untestable assumptions, some of which are hard to meet in real datasets. Motivated by these considerations, this paper extensively benchmarks the empirical performance of recent causal discovery methods on observational _iid_ data generated under different background conditions, allowing for violations of the critical assumptions required by each selected approach. Our experimental findings show that score matching-based methods demonstrate surprising performance in the false positive and false negative rate of the inferred graph in these challenging scenarios, and we provide theoretical insights into their performance. This work is also the first effort to benchmark the stability of causal discovery algorithms with respect to the values of their hyperparameters. Finally, we hope this paper will set a new standard for the evaluation of causal discovery methods and can serve as an accessible entry point for practitioners interested in the field, highlighting the empirical implications of different algorithm choices.

## 1 Introduction

The ability to infer causal relationships from observational data, instead of simple statistical associations, is crucial to answer interventional and counterfactual queries without direct manipulation of a system . The challenge of drawing causal conclusions from pure observations lies in the modeling assumptions on the data, which are often impossible to verify. Methods based on conditional independence testing (e.g. PC, FCI and their variations ) require _faithfulness_ of the distribution  to the causal graph, which formalizes the intuition that causal relations manifest themselves in the form of statistical dependencies among the variables. The assumption of _causal sufficiency_ (i.e. the absence of unobserved confounders ) is a common requirement forcausal discovery [4; 6; 9; 10; 11; 12], which allows interpreting associations in the data as causal relationships. These strong conditions are arguably necessary but nevertheless hard or impossible to verify, and posit an entry barrier to the unobscured application of causal analysis in general settings. In addition to that, structure identifiability results define limitations on the parts of the causal graph that can be inferred from pure observations [1; 10; 13]. Traditional causal discovery methods (e.g. PC, FCI, GES [4; 9]) are limited to the inference of the Markov Equivalence Class of the ground truth graph , while additional assumptions on the structural equations generating effects from the cause ensure identifiability of a unique Directed Acyclic Graph (DAG) from observational data. In particular, restrictions on the class of functions generating the data (linear or not) and on the distribution of the noise terms (i.e. additive noise models assumed in LINGAM and more) characterizing their non-deterministic relationships are necessary in order to infer causal directions [10; 11; 12; 13]. Requirements on the data collection process are also needed: although an error-free measurement model is commonly assumed, it has been a recent subject of interest that measurement error in the observed values of the variables can greatly change the output of various causal discovery methods [15; 16].

Real data hardly satisfy all of these assumptions at once, and it is often the case that these are impossible to verify, which calls for algorithms that demonstrate a certain degree of robustness with respect to violations of the model hypothesis. Previous work from Heinze-Deml et al.  investigates the boundaries of robust graph inference under model misspecifications, on Structural Causal Models (SCM) with linear functional mechanisms. Mooij et al.  benchmark considers the case of additive noise models with nonlinear mechanisms, but only for datasets with two variables. Singh et al.  presents an empirical evaluation limited to methods whose output is a Markov Equivalence Class. Glymour et al.  review some of the existing approaches with particular attention to their required assumptions, but without experimental support to their analysis. Our paper presents an extensive empirical study that evaluates the performance of classical and recent causal discovery methods on observational datasets generated from _iid_ distributions under diverse background conditions. Notably, the effects of these conditions on most of the methods included in our benchmark have not been previously investigated. We compare causal discovery algorithms from the constraint and score-based literature, as well as methods based on restricted functional causal models of the family of additive nonlinear models [11; 13; 20]. These include a recent class of methods deriving connections between the score matching [21; 22] with the structure of the causal graph [23; 24; 25]. Algorithms that focus on _sequential_ data [26; 27; 28; 29; 30; 31; 32; 33; 34; 35; 36; 37] are beyond the scope of this paper's benchmarking. Finally, we propose an experimental analysis of the stability of the benchmarked approaches with respect to the choices of their hyperparameters, which is the first effort of this type in the literature.

We summarise the contributions of our paper as follows:

* We investigate the performance of current causal discovery methods in a large-scale experimental study on datasets generated under different background conditions with violations of the required background assumptions. Our experimental protocol consists of more than 2M experiments with \(11\) different causal discovery methods on more than \(60000\) datasets synthetically generated.
* We release the code for the generation of the synthetic data and a Python implementation of six causal discovery algorithms with a shared API. With this contribution, we aim at facilitating the benchmarking of future work in causal discovery on challenging scenarios, and the comparison with the most prominent existing baselines.
* We analyze our experimental results, and present theoretical insights on why score matching-based approaches show better robustness in the setting where assumptions on the data may be violated, compared to the other methods. Based on our empirical evidence, we suggest a new research direction focused on understanding the role of the statistical estimation algorithms applied for causal inference, and the connection of their inductive biases with good empirical performance.

## 2 The causal model

In this section, we define the problem of causal discovery, with a brief introduction to the formalism of Structural Causal Models (SCMs). Then we provide an overview of SCMs for which sufficient conditions for the _identifiability_ of the causal graph from observational data are known.

### Problem definition

A Structural Causal Model \(\) is defined by the set of _endogenous_ variables \(^{d}\), vertices of the causal graph \(\) that we want to identify, the _exogenous_ noise terms \(^{d}\) distributed according to \(p_{}\), as well as the functional mechanisms \(=(f_{1},,f_{d})\), assigning the value of the variables \(X_{1},,X_{d}\) as a deterministic function of their causes and of some random disturbance.

Each variable \(X_{i}\) is defined by a structural equation:

\[X_{i} f_{i}(_{i},U_{i}),\  i=1,,d,\] (1)

where \(_{i}\) is the set of parents of \(X_{i}\) in the causal graph \(\), and denotes the set of direct causes of \(X_{i}\). Under this model, the recursive application of Equation (1) entails a joint distribution \(p_{}\), such that the Markov factorization holds:

\[p_{}()=_{i=1}^{d}p_{i}(X_{i}|_{i}),\] (2)

The goal of causal discovery is to infer the causal graph underlying \(\) from a set of \(n\) observations sampled from \(p_{}\).

### Identifiable models

In order to identify the causal graph of \(^{d}\) from purely observational data, further assumptions on the functional mechanisms in \(\) and on the joint distribution \(p_{}\) of model (1) are needed. Intuitively, having one condition between nonlinearity of the causal mechanisms and non-Gaussianity of the noise terms is necessary to ensure the identifiability of the causal structure. Additionally, we consider causal _sufficiency_ (Appendix A.3) of the model to be satisfied, unless differently specified.

**Linear Non-Gaussian Model (LINGAM).** A linear SCM is defined by the system of structural equations

\[=+.\] (3)

\(^{d d}\) is the matrix of the coefficients that define \(X_{i}\) as a linear combination of its parents and the disturbance \(U_{i}\). Under the assumption of non-Gaussian distribution of the noise terms, the model is identifiable. This SCM is known as the LiNGAM (Linear Non-Gaussian Acyclic Model) .

**Additive Noise Model.** An Additive Noise Model (ANM) [11; 13] is defined by Equation (1) when it represents the causal effects with nonlinear functional mechanisms and additive noise terms:

\[X_{i} f_{i}(_{i})+U_{i},\  i=1,,d,\] (4)

with \(f_{i}\) nonlinear. Additional conditions on the class \(\) of functional mechanisms and on the joint distribution of the noise terms are needed to ensure identifiability . In the remainder of the paper, we assume these to hold when referring to ANMs.

**Post NonLinear Model.** The most general model for which sufficient conditions for the identifiability of the graph are known is the Post NonLinear model (PNL) . In this setting the structural equation (1) can be written as:

\[X_{i} g_{i}(f_{i}(_{i})+U_{i}),\  i=1,,d,\] (5)

where both \(g_{i}\) and \(f_{i}\) are nonlinear functions and \(g_{i}\) is invertible. As for ANMs, we consider identifiability conditions defined in Zhang and Hyvarinen  to be satisfied in the rest of the paper.

## 3 Experimental design

In this section, we describe the experimental design choices regarding the generation of the synthetic datasets, the evaluated methods, and the selected metrics.

### Datasets

The challenge of causal structure learning lies in the modeling assumptions of the data, which are often untestable. Our aim is to investigate the performance of existing causal discovery methods in the setting where these assumptions are violated. To this end, we generate synthetic datasets underdiverse background conditions, defined by modeling assumptions that do not match the working hypothesis of the evaluated methods.

**Vanilla model.** First, we specify an additive noise model with variables generated according to the structural equation (4). The exogenous terms follow a Gaussian distribution \(U_{i}(0,_{i})\) with variance \(_{i} U(0.5,1.0)\) uniformly sampled. We generate the nonlinear mechanisms \(f_{i}\) by sampling Gaussian processes with a unit bandwidth RBF kernel (Appendix B.1). We refer to this model as the _vanilla_ scenario, as it is at one time both identifiable and compliant with the assumptions of the majority of the benchmarked methods (see Table 1).

#### 3.1.1 Misspecified scenarios

We define additional scenarios such that each specified model targets a specific assumption violation with respect to the vanilla conditions.

**Confounded model.** Let \(^{d}\) be a set of latent common causes. For each pair of distinct nodes \(X_{i}\) and \(X_{j}\), we sample a Bernoulli random variable \(C_{ij} Bernoulli()\) such that \(C_{ij}=1\) implies a confounding effect between \(X_{i}\) and \(X_{j}\). The index \(k\) of the confounder \(Z_{k}\) is assigned at random. The parameter \(\{0.1,0.2\}\) determines the amount of confounded pairs in the graph.

**Measurement error model.** Measurement errors in the process that generates the data are regarded as a source of mistakes for the inference of the causal graph . In order to account for potential errors induced by the measurements, we specify a model in which the observed variables are:

\[_{i} X_{i}+_{i}, i=1,,d,\] (6)

a noisy version of the \(X_{i}\)'s generated by the ANM of Equation (4). The \(_{i}\) disturbances are independent Gaussian random variables centered at zero, whose variance is parametrized by the inverse signal-to-noise ratio \(_{i}(_{i})}{(X_{i})}\). Given that the total variance of \(_{i}\) is \((_{i})=(X_{i})+(_{i})\), \(_{i}\) controls the amount of variance in the observations that is explained by the error in the measurement. Each dataset with measurement error is parametrized with \(\{0.2,0.4,0.6,0.8\}\), shared by all the \(_{i}\).

**Unfaithful model.** To model violations of the _faithfulness_ assumption (Appendix A.2), we tune the causal mechanisms of Equation (4) such that we induce direct cancellation of causal effects between some variables. In particular, for each triplet \(X_{i} X_{k} X_{j} X_{i}\) in the graph, causal mechanisms are adjusted such that cancellation of the causal effect \(X_{i} X_{k}\) occurs (for implementation details, see Appendix B.4). This is a partial model of unfaithfulness, as it only covers a limited subset of the scenarios under which unfaithful path canceling might occur, and must be viewed in the light that there is no established procedure to enforce unfaithful conditional independencies in the case of ANM with nonlinear relationships.

**Autoregressive model.** In order to simulate violations of the _iid_ distribution of the data, we model observations as a stochastic process where each sample is indexed by time. In particular, we define the structural equations generating the data as:

\[X_{i}(t) X_{i}(t-1)+f_{i}(_{i}(t))+U_{i},\ \ t=1,2,3,\ \ .\] (7)

  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\  Gaussian noise & ✓ & ✓ & ✓ & ✗ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\ Non-Gaussian noise\({}^{*}\) & ✓ & ✓ & ✗ & ✓ & ✓ & ✓ & ✗ & ✗ & ✗ & ✗ & ✗ \\ Linear mechanisms & ✓ & ✓ & ✓ & ✓ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\ Nonlinear mechanisms & ✓ & ✓ & ✓ & ✗ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\ Unfaithful distribution & ✗ & ✗ & ✗ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\ Confounding effects & ✗ & ✓ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\ Measure errors & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ & ✗ \\  Output & CPDAG & pAG & CPDAG & DAG & DAG & DAG & DAG & DAG & DAG & DAG & DAG & DAG \\  

* GraN-DAG and GES optimize the Gaussian likelihood.

Table 1: Summary of the methods assumptions and their output graph. The content of the cells denotes whether the method supports (✓) or not (✗) the condition specified in the corresponding row.

Autoregressive effects are modeled with a time lag \(l=1\), whereas at \(t=0\) we define \(X_{i}(0)\) with Equation (4). The ground truth is the graph whose edges represent the connections between parents \(_{i}(0)\) and their direct effect \(X_{i}(0)\).

**Post NonLinear model**. We replace nonlinear causal mechanisms of the additive noise models (4) with the structural equations defined in the PNL model (5). We select the post nonlinear function \(g_{i}\) such that \(g_{i}(x)=x^{3},x, i=1,,d\).

**LiNGAM model**. We define a model with the linear system of structural equations (3). The non-Gaussian distribution of the noise terms is defined as a nonlinear transformation of a standard normal random variable (see Appendix B.2), and the linear mechanisms are simulated by sampling the weighting coefficients of the parents of a node in the interval \([-1,-0.05][0.05,1]\).

#### 3.1.2 Data generation

For each specified model, we generate datasets that differ under the following characteristics: number of nodes \(d\{5,10,20,50\}\), number of samples \(n\{100,1000\}\) and density of edges \(p\{,\}\). We sample the ground truth causal structures according to different algorithms for random graph generation. In line with previous causal discovery literature [23; 24; 25; 38; 39] we generate Erdos-Renyi (ER)  and Scale-free (SF) graphs . Furthermore, we consider Gaussian Random Partitions (GRP)  and Fully Connected graphs (FC) (see Appendix B.3). By considering all the combinations of the number of nodes, number of samples, admitted edge densities, and algorithms for structure generation, we define a cartesian product with all the graph configurations of interest. For each of such configurations and for each modeling scenario, we generate a dataset \(\) and its ground truth \(\) with \(20\) different random seeds. Details on the generated data can be found in Appendix B.5.

### Methods

We consider \(11\) different algorithms and a random baseline spanning across the main families of causal discovery approaches: constraint and score-based methods, and methods defined under restrictions on the structural causal equations. In the main text, we provide a detailed overview of the methods most relevant for the discussion of our key experimental findings. The remaining approaches are described in further detail in the Appendix C. Table 1 summarizes the algorithms' assumptions and the output object of their inference procedure.

**Method outputs.** Causal discovery algorithms output different graphical objects based on their underlying assumptions. If identifiability is not implied by the model requirements but _faithfulness_ of the distribution is satisfied, one can instead recover the Markov equivalence class of the ground truth graph, that is, the set of DAGs sharing the same conditional independencies. This is represented by a complete partially directed acyclic graph (CPDAG), where undirected edges \(X_{i}\,\,\,\,X_{j}\) are meant to encode conditional dependence between the variables, but uncertainty in the edge orientation. If a method can identify a directed acyclic graph \(=(,)\), one can define a partial ordering of the nodes \(=\{X_{_{1}},,X_{_{d}}\},_{i}\{1,,d\}\), such that whenever we have \(X_{_{i}} X_{_{j}}\), then \(X_{_{i}} X_{_{j}}\) (\(X_{_{j}}\) is a _successor_ of \(X_{_{i}}\) in the ordering) . The permutation \(\) is known as the _topological order_ of \(\), and allows to disambiguate the direction of the edges in the graph. A topological order can be encoded in a fully connected DAG with edges \(_{}=\{X_{_{i}} X_{_{j}}:X_{_{i}} X_{_{j}}\,,  i,j=1,,d\}\), obtained connecting all nodes in the ordering \(\) with their successors.

**Methods summary.** A summary of all the methods included in the benchmark and their required assumptions is presented in Table 1. PC  and GES  are limited to identifying the Markov equivalence class of the DAG. DirectLiNGAM  is designed for inference on data generated by a linear non-Gaussian model whereas SCORE , NoGAM , DiffAN , DAS , RESIT , GraN-DAG  and CAM , are meant for inference on additive noise models: these methods perform inference in a two steps procedure, first identifying a topological ordering of the graph, and then selecting edges between those admitted by the inferred causal order. To enable fair comparison in our experiments, all methods (with the exception of DirectLiNGAM) are implemented with the same algorithm for edge detection, consisting of variable selection with sparse regression. This pruning strategy is known as _CAM-pruning_, being originally proposed in CAM paper . A detailed discussion of all the methods in the benchmark is presented in Appendix C. In the Appendix L we consider experiments on FCI , which are not reported in the main text since we did not find metrics for a straightforward comparison of its output partial ancestral graph (PAG ) with CPDAGs and DAGs.

**Selected metrics** To evaluate the output graphs we use the false positive and false negative rates, and the F1 score (details in the Appendix D). In the case of directed edges inferred with reversed direction, we count this error as a false negative. For methods that output a CPDAG with undirected edges, we evaluate them favorably by assuming correct orientation whenever possible, similar to Zheng et al. . For the methods whose output also includes an estimate \(\) of the topological order, we define the false negative rate of the fully connected DAG with edges \(_{}=\{X_{_{i}} X_{_{j}}:X_{_ {i}} X_{_{j}}\, i,j=1,,d\}\), denoted as FNR-\(\). If \(\) is correct with respect to the ground truth graph, then FNR-\(=0\).

This choice of metrics reflects the implementation of most of the algorithms involved in the benchmark, which separates the topological ordering step from the actual edge selection. In particular, given that the majority of the methods share the same pruning procedure after the inference of the order, we expect that differences in the performance will be mostly observed in the FNR-\(\) score.

#### 3.2.1 Deeptive on SCORE, NoGAM and DiffAN

In this section, we review a recent class of causal discovery algorithms, that derive constraints on the score function \( p()\) that uniquely identifies the directed causal graph of an additive noise model. Identifiability assumptions provide sufficient conditions to map a joint distribution \(p_{}\) to the unique causal DAG \(\) induced by the underlying SCM. Applying the logarithm to the Markov factorization of the distribution of Equation (2), we observe that \( p_{}()=_{i}^{d} p(X_{i}_{i})\). By inspection of the gradient vector \( p_{}()\), it is possible to derive constraints mapping the score function to the causal graph of an ANM. Given a node \(X_{i}\) in the graph, its corresponding score entry is defined as:

\[s_{i}()_{X_{i}} p_{}()= _{X_{i}} p_{i}(X_{i}_{i})+_{k_{i} }_{X_{i}} p_{k}(X_{k}_{k}).\] (8)

Instead, the rate of change of the log-likelihood over a leaf node \(X_{l}\) with the set of children \(_{l}=\) is:

\[s_{l}()_{X_{l}} p_{}()= _{X_{l}} p_{l}(X_{l}|_{l}).\] (9)

We see that, for a leaf node, the summation over the set of children of Equation (8) vanishes. Intuitively, being able to capture this asymmetry in the score entries enables the identification of the topological order of the causal graph.

**SCORE.** The SCORE algorithm  identifies the topological order of ANMs with Gaussian noise terms by iteratively finding leaf nodes as the \(_{i}[_{X_{i}}s_{i}()]\), given that the following holds:

\[[_{X_{i}}s_{i}()]=0 X _{i} i=1,,d.\] (10)

**NoGAM.** The NoGAM  algorithm generalizes the ideas of SCORE on additive noise models with an arbitrary distribution of the noise terms. After some manipulations, it can be shown that for a leaf node \(X_{l}\) the score entry of Equation (9) satisfies

\[s_{l}()=_{U_{l}} p_{l}(U_{l}),\] (11)

such that one could learn a consistent estimator of \(s_{l}\) taking as input the exogenous variable \(U_{l}\). For an ANM, the authors of NoGAM show that the noise term of a leaf is equivalent to the residual defined as:

\[R_{i} X_{i}-[X_{i}\{X_{i}\} ],\, i=1,,d.\] (12)

Then, by replacing \(U_{l}\) with \(R_{l}\) in Equation (11), it is possible to find a consistent approximator of the score of a leaf using \(R_{l}\) as the predictor. Formally:

\[[([s_{i}() R_{i}]-s_{i }())^{2}]=0 X_{i}\] (13)

which identifies a leaf node as the \(\) of the vector of the mean squared errors of the regression of the score entries \(s_{i}()\) on the corresponding residuals \(R_{i}\), for all \(i=1,,d\).

**Connection of NoGAM with the post nonlinear model.** It is interesting to notice that, similarly to Equation (11) for additive noise models, the score of a leaf \(X_{l}\) generated by a PNL model can be defined as a function of the disturbance \(U_{l}\).

**Proposition 1**.: _Let \(^{d}\) be generated according to the post nonlinear model (5). Then, the score function of a leaf node \(X_{l}\) satisfies \(s_{l}()=_{l} p_{l}(U_{l})\)._

This result suggests a connection with the NoGAM sorting criterion: indeed, one could hope to identify leaf nodes in the graph by consistent estimation of the score of a leaf from residuals equivalent to the noise terms. A more detailed discussion with the proof of Proposition 1 is presented in Appendix E.

Das.The DAS algorithm (acronym for Discovery At Scale, ) identifies the topological ordering with the same procedure defined in SCORE, while the two methods differ in the way they find edges in the graph. DAS edge selection procedure exploits the information in the non-diagonal entries of the Jacobian of the score. In particular, for ANM with Gaussian noise terms, it can be shown that:

\[[|_{X_{j}}s_{l}()|] 0  X_{j}_{l}(),\ \  j\{1,,d\}\{l\}\] (14)

Exploiting Equation 14 to define the inference rule for the edge selection in DAS provides a significant computational advantage with respect to SCORE, reducing the time complexity in the number of nodes from cubic to quadratic.

**DiffAN**. DiffAN  method finds the topological ordering of a DAG exploiting the same criterion of Equation (10) of SCORE: the difference is in that it estimates the score function with probabilistic diffusion models, whereas SCORE, NoGAM, and DAS  rely on score matching estimation [21; 22].

## 4 Key experimental results and analysis

In this section we present our experimental findings on datasets generated according to the misspecified models of Section 3.1.1, with theoretical insights into the performance of score matching-based approaches. We draw our conclusions by comparing the methods' performance against their accuracy in the vanilla scenario and against a random baseline 1 (defined in Appendix C.10). The results are discussed on datasets of size \(1000\) for Erdos-Renyi dense graphs with 20 nodes (_ER-20 dense_), and can be generalized to different size and sparsity configurations. Due to space constraints, we include the plots only for the F1 score and FNR-\(\), whereas the false negative and false positive rates are discussed in Appendix I. In order to provide statistical significance to our conclusions, we repeat the experiments on each scenario over \(20\) datasets generated with different random seeds. To enable a fair comparison between the methods, we fix their hyperparameters to their optimal value with respect to each specific dataset, in the case where these can not be tuned without having access to the ground truth (see Appendix G for a discussion on the tuning of GraNDAG and DiffAN learning hyperparameters). In the Appendix H we analyze the stability of the benchmarked methods with respect to different values of their hyperparameters.

### Can current methods infer causality when assumptions on the data are violated?

Our experimental findings suggest that score matching-based algorithms can robustly infer part of the causal information even in the case of misspecified ground truth data generation.

**Post nonlinear model.** Figure 0(a) (right) illustrates the accuracy of topological order estimates on post nonlinear model data. Among the selected methods, NoGAM shows better ability to generalize its performance to this scenario, with FNR-\(\) error rate significantly lower than the random baseline. Interestingly, we can interpret this observation in the light of Proposition 1, which defines the score of a leaf in the PNL model: our result indeed suggests that, similarly to the case of an additive noise model, it is possible to learn a consistent approximator of the score of a leaf \(X_{l}\) from the exogenous variable \(U_{l}\) of a post nonlinear model. Notably, we also observe that RESIT order accuracy is better in the PNL scenario than in the vanilla case: Zhang and Hyvarinen  show that testing for independent residuals identifies the direction of causal relationships also under the PNL model.

**LiNGAM model.** Figure 0(b) (right) shows that NoGAM can infer the causal order with remarkable accuracy in the case of ground truth data generated by a linear non-gaussian additive model. Together with our observations on the post nonlinear model, our empirical evidence corroborates the idea that the NoGAM algorithm is surprisingly robust with respect to the misspecification of the causal mechanisms. Notably, none of the other methods can infer the ordering with accuracy significantly better than the random baseline. This could lead to decreased performance in the realistic setting of mixed linear and nonlinear mechanisms. However, the F1 score in Figure 0(b) (left) shows that CAM-pruning is still able to correctly infer edges in the graph when these are admitted by the identified causal order. We note that, given that we observed high _varsortability2_ for this model, we display results on data standardized dividing by their empirical variance.

**Confounded model.** Spurious correlations, that occur when the causal sufficiency is violated, can not be handled by statistical tests for edge selection, as shown by the F1 score of Figure 1c (left) (the amount of confounders is parametrized by \(=0.2\)). In this case, we are also interested to see whether the presence of latent confounders can disrupt the inference of the topological ordering when the observed variables have a non-spurious connection in the causal graph. Figure 1c (right) indicates that the score matching-based approaches SCORE, DAS, and NoGAM can still be exploited to find a reliable ordering, while other methods fail to do so.

**Measurement error.** Given data generated under the model of Equation (6), we observe convergence in distribution \(p(_{i}_{i})p(X_{i}_{i})\) for \( 0\). We are then interested in the boundaries of robust performance of each method with respect to increasing values of \(\). Figure (1d) (right) illustrates FNR-\(\) on datasets with \(=0.8\) such that \( 35\%\) of the observed variance of each variable is due to noise in the measurements. Under these conditions, we see that score matching-based approaches display robustness in the inference of the order where all the other methods' capability is comparable to that of the random baseline with statistical significance. This is also reflected in Figure (1d) (left), where SCORE, DAS, and NoGAM are the only algorithms whose F1 score (slightly) improves compared to the random baseline.

**Unfaithful model.** Figure 1e (right) shows that the ordering procedure of several methods, in particular SCORE, DAS, NoGAM, and GraN-DAG, seems unaffected by direct cancellation of causal effects, in fact displaying a surprising decrease in the FNR-\(\) performance with respect to the vanilla scenario. To understand these results, we note that under the occurrence of causal effect cancellations in the ground truth graph \(\), the unfaithful model defined in Section 3.1.1 generates observations of \(\) according to a graph \(}\) whose causal order agrees with that of the ground truth: it

Figure 1: Experimental results on the misspecified scenarios. For each method, we also display the violin plot of its performance on the _vanilla_ scenario with transparent color. F1 score (the higher the better) and FNR-\(\) (the lower the better) are evaluated over \(20\) seeds on Erdos-Renyi dense graphs with \(20\) nodes (ER-20 dense). FNR-\(\) is not computed for GES and PC, methods whose output is a CPDAG. Note that DirectLiNGAM performance is reported in Appendix I.2, on data under non-Gaussian distribution of the noise terms.

is indeed immediate to see that the causal order of \(X_{i} X_{k} X_{j} X_{i}\) also holds for the triplet \(X_{i} X_{j} X_{k}\). Moreover, the set of edges of the graph \(}\) is sparser than that of the ground truth, due to the cancellation of causal effects. Thus, given that inference on sparser graphs is generally easier, it can positively affect the empirical performance, in line with our observations.

**Implications.** Our experimental findings show that most of the benchmarked methods significantly decrease their performance on the misspecified models. This is particularly problematic since the violations considered in this work are realistic and met on many real-world data. On the other hand, we observe surprising robustness in the inference of score matching-based methods.

#### 4.1.1 Discussion on PC and GES performance

The experimental results of Figure 1 show that the F1 score of GES and PC is consistently worse than random in the setting of Erdos-Renyi dense graphs with \(20\) nodes. We note that this pertains specifically to large graphs with dense connections, where the accuracy of both methods significantly degrades. In the case of PC, this is in line with previous theoretical findings in the literature: Uhler et al.  demonstrate that large and dense graphs are characterized by many _quasi-violations_ of the faithfulness assumptions, which can negatively impact the algorithm's inference ability. In Appendix M we discuss experiments on lower dimensional networks with sparse edge structures, showing that PC and GES report performance significantly better than random across different scenarios. Overall, we find that increasing the size and density of the graph negatively impacts the inference ability of PC and GES.

#### 4.1.2 Discussion on score matching robustness

Our empirical findings indicate that score matching-based methods are surprisingly capable of partial recovery of the graph structure in several of the misspecified scenarios. We connect this robust performance to the decomposition properties of the score function defined in Equations (8) and (9). In particular, we argue that the common factor that enables leaf node identification in NoGAM and SCORE is that the score entry of a leaf is characterized by a smaller magnitude, compared to the score associated with a node that has children in the graph. To explain what we mean by this, we define a simple condition under which it is possible to identify leaf nodes and the causal order of the graph from the variance of the entries of the score function.

**Definition 1**.: Let \(^{d}\) be a random vector defined by a structural causal model \(\) (1). Let \(X_{l}\) be a leaf node of the causal graph \(\). We say that \(X_{l}\) is _score-identifiable_ if \(l=*{argmin}_{i}*{Var}[s_{i}()]\).

Moreover, we say that the model is _score-sortable_ if the recursive identification of _score-identifiable_ leaf nodes in the causal graph and in the subgraphs defined by removing a leaf from the set of vertices up to a source node, yields a correct causal order. SCORE, NoGAM, and DAS present results for consistent inference of the structure of an identifiable graph from properties of the score function and its second order partial derivatives. However, when these conditions are not satisfied, exploitation of _score-sortability_ can heuristically estimate a causal ordering that partially agrees with the causal structure. Intuitively, the variance of the score of a non-leaf node \(s_{i}()\) of Equation (8) is proportional to the number of children in the summation. In particular, the total variance of \(s_{i}()\) is the sum of the marginal variances of the two terms on the RHS of Equation (8), plus their covariance. Errors in the ordering defined with _score-sortability_ are induced only if the variance associated with the score of a non-leaf node can be smaller than the one relative to every leaf of the graph.

**Proposition 2**.: _Let \(^{d}\) be a random vector whose elements \(X_{i}\) are defined by a structural equation model \(\) (1) that satisfies score-sortabilty. Then, for each subgraph of \(\) defined by recursively removing a leaf from the set of vertices up to a source node, there exists a leaf \(X_{l}\) such that \(\,i\) index of a node:_

\[*{Var}[_{X_{l}} p_{l}(X_{l}*{PA}_{l} )]*{Var}[_{X_{i}} p_{i}(X_{i}*{ PA}_{i})]+_{k*{CH}_{i}}*{Var}[_{X_{i}}  p_{k}(X_{k}*{PA}_{k})]+C,\]

_with \(C\) accounting for the covariance term._

(See Appendix F for the proof.) Lemma 1 of SCORE defines a similar criterion of sortability of the causal variables on the variance of the second order partial derivatives of the log-likelihood, which is always satisfied when \(^{d}\) is generated by an ANM with Gaussian distribution of the noise terms. We can extend these considerations to the NoGAM algorithm, which identifies leaf nodes by minimizing the mean squared error of the predictions of the score entries from the residual estimators of the noise terms, as defined in Equation (13). If we consider an uninformative predictor of the score function that maps every input residual to a constant value zero, the NoGAM algorithm is equivalent to a simple _score-sortability_ heuristic criterion, identifying leaf nodes as the \(*{argmin}_{i}[s_{i}^{2}()]\). In Appendix I.3 we corroborate our considerations by comparing the empirical performance of a _score-sortability_ baseline with SCORE and NoGAM.

**Implications.** Score matching-based approaches SCORE, DAS, and NoGAM show empirical robustness in several scenarios included in our benchmark. We impute these results to the structure of the score function discussed in Section (3.2.1), and to the algorithmic design choices of these methods that exploit different magnitude in the score of a leaf compared to other nodes with children in the graph.

### Is the choice of statistical estimators neutral?

In the previous section, we motivated the empirical observations on the robustness of methods based on the score function. Given that the DiffAN algorithm differs from SCORE only in the score estimation procedure (where the former applies probabilistic diffusion models in place of the score matching), we can explain the gap in performance of DiffAN with the other approaches based on the score as an effect of the different statistical estimation technique. From this observation, we suggest that score matching plays a crucial role in connecting the gradient of the log-likelihood with effective causal inference.

**Implications.** The choice of modular statistical estimator for causal inference procedures is not neutral. We argue that inductive bias in statistical estimators may be connected with good empirical performance, and we think that this potential connection should be further investigated in future works.

## 5 Conclusion

In this work we perform a large-scale empirical study on eleven causal discovery methods that provide empirical evidence on the limits of reliable causal inference when the available data violate critical algorithmic assumptions. Our experimental findings highlight that score matching-based approaches can robustly infer the causal order from data generated by misspecified models. It would be important to have procedures for edge detection that display the same properties of robustness in diverse scenarios and to have a better theoretical understanding of failure modes of CAM-pruning variable selection, given its broad use for causal discovery. Finally, we remark that this benchmarking is limited to the case of observational _iid_ samples, and it would be of great practical interest to have equivalent empirical insights on the robustness of methods for causal discovery on sequential data in the setting of time series or passively observed interventions.

## 6 Acknowledgements

We thank Kun Zhang and Carl-Johann Simon-Gabriel for the insightful discussions. This work has been supported by AFOSR, grant n. FA8655-20-1-7035. FM is supported by _Programma Operativo Nazionale ricerca e innovazione 2014-2020_. FM partially contributed to this work during an internship at Amazon Web Services with FL. FL partially contributed while at AWS.