# Linear Causal Bandits: Unknown Graph and Soft Interventions

Zirui Yan

Rensselaer Polytechnic Institute

yanz11@rpi.edu &Ali Tajer

Rensselaer Polytechnic Institute

tajer@ecse.rpi.edu

###### Abstract

Designing causal bandit algorithms depends on two central categories of assumptions: (i) the extent of information about the underlying causal graphs and (ii) the extent of information about interventional statistical models. There have been extensive recent advances in dispensing with assumptions on either category. These include assuming known graphs but unknown interventional distributions, and the converse setting of assuming unknown graphs but access to restrictive hard/\(\) interventions, which removes the stochasticity and ancestral dependencies. Nevertheless, the problem in its general form, i.e., _unknown_ graph and _unknown_ stochastic intervention models, remains open. This paper addresses this problem and establishes that in a graph with \(N\) nodes, maximum in-degree \(d\) and maximum causal path length \(L\), after \(T\) interaction rounds the regret upper bound scales as \(}((cd)^{L-}+d+RN)\) where \(c>1\) is a constant and \(R\) is a measure of intervention power. A universal minimax lower bound is also established, which scales as \((d^{L-})\). Importantly, the graph size \(N\) has a diminishing effect on the regret as \(T\) grows. These bounds have matching behavior in \(T\), exponential dependence on \(L\), and polynomial dependence on \(d\) (with the gap \(d\) ). On the algorithmic aspect, the paper presents a novel way of designing a computationally efficient CB algorithm, addressing a challenge that the existing CB algorithms using soft interventions face.

## 1 Motivation & Overview

Causal bandits (CBs) provide a formal framework for the sequential design of experiments over a network of agents with _causal_ interactions. The objective of CBs is to identify an experiment that maximizes a notion of utility over the causal network. CB settings are specified by three elements: (i) a causal graphical model that defines the topological ordering of the causal variables and their probabilistic relationships; (ii) a set of structural equation models (SEMs) that specify their cause-effect dependencies among the variables; and (iii) _intervention_ models that specify the extent of exogenous variations imposed on the causal interactions by an external force. By interpreting the set of interventions as the set of _arms_ and the decision quality (utility) as the rewards, CBs' objective is to maximize the cumulative reward by strategically selecting the sequence of interventions that optimize a notion of cumulative utility [1; 2]. CBs have a broad range of applications [3; 4; 5].

The recent advances in CBs can be grouped based on three assumption dimensions: (i) the assumptions on the extent of information available about the causal graph structure, (ii) the assumptions about pre- and post-intervention statistical models, and (iii) the nature of the SEMs. There have been significant advances in understanding CBs when the _causal graphs are known_. The most relevant studies include those that started with analyzing \(do\) interventions as the simplest form of interventions [1; 2; 6; 7] and have progressed toward the more complex stochastic interventions (hard and soft). These studies have investigated various linear and non-linear SEMs. Specifically, the studies in [8; 9; 10; 11; 12; 13] assume that the pre- and post-interventional statistical distributions are known. The study in  further advances the results by assuming that these distributions are known only partially, and finally, the studies in [15; 16; 17; 18] entirely dispense with all the assumptions about the interventions' statistical models.

In sharp contrast, when the causal graph is _unknown_, the problem is far less investigated and open in its general form. The lack of topology knowledge makes the problem substantially more complex, since the graph's topology captures all the conditional independence information about the random variables in the system. Hence, when the graph is known, it is unnecessary to learn the conditional independencies; however, when it is unknown, all the conditional independencies should be learned.

The notable results under unknown graphs include , which assumes that all interventional distributions are _fully known_. Dispensing with the assumption of interventional distributions with a focus on \(do\) is investigated in . \(do\) interventions are generally more amenable to tractable analysis because of the analytical simplifications they enable. A \(do\) intervention at a node sets the random value of that node to a pre-specified fixed value. This results in (i) removing all the causal dependence of that node on its ancestors and (ii) removing the randomness of the data generated by that node. In sharp contrast, _stochastic soft interventions_ are the more general and realistic forms of interventions that retain all the ancestral dependencies and the probabilistic nature of the model. A soft intervention, specifically, changes the pre-intervention statistical models to other distinct models.

Contributions.We establish upper and lower regret bounds for the CB problem under _unknown_ graphs, _unknown_ pre- and post-intervention statistical models, and _soft_ stochastic interventions. Furthermore, we also provide a novel approach to algorithm design and regret analysis. The main assumptions and contributions of the paper are as follows.

* **Topology:** We assume to know only the number of the nodes on the graph and the in-degree of the causal graph.1 * **Statistical model:** We assume that all pre- and post-intervention statistical models are unknown.
* **Regret bounds:** We characterize almost matching upper and lower bounds on the regret as a function of the time horizon and graph topology parameters. Specifically, we show the achievable regret of \(}( d)^{L-}+d+N\) where \(>1\) is a constant, \(N\) is the number of graph nodes, \(d\) is the maximum in-degree of the graph, \(L\) is the maximum causal depth, and \(T\) is the time horizon. We also establish the minimax regret lower bound of \((d^{L-})\).
* **Tightness of the bounds:** The dependence of the achievable regret on \(N\) is diminishing as \(T\) grows. Therefore, the mismatch of the achievable and the minimax regrets is on the order of \(d\) and a constant \(^{L-}\).
* **Special cases:** Our general regret bounds provide improvements for the known special cases. In particular, we show that when the graph becomes known, our achievable regret becomes \(}(d^{L-})\), which is tighter than the best known results \(}(d^{2L-1})\).
* **Scalabe algorithm:** We introduce a novel CB algorithm under soft interventions. We note that the existing algorithms for soft algorithms are based on the upper confidence bound (UCB) principle, and they are generally not scalable due to the intractable optimization problem pertinent to maximizing the UCBs. In our algorithm, we circumvent his issue, resulting in a scalable algorithm as the graph size grows.

  Algorithm & Regret bound & Intervention & Scalable & Lower bound \\    \\  CN-UCB & \(}+Kd\) & \(\) & ✓ & \(()\)1  \\  GA-LCB (This paper) & \(}( d)^{L-}+d+RN\) & soft & ✓ & - \\    \\  C-UCB & \(}(T})\) & \(\) & ✓ & - \\  LinSEM-UCB & \(}(d^{2L-})\) & soft & ✗ & })\)} \\  GCB-UCB & \(}(d^{2L-1})\) & soft & ✗ & \\ GA-LCB (this paper) & \(}(d^{L-})\) & soft & ✓ & \\  

Table 1: Cumulative instance-independent regrets for linear CBs.

Notations.For a positive integer \(N\), we define \([N]\{1,,N\}\). Random variables and their realizations are represented by upper- and lower-case letters, respectively. Matrices and vectors are represented by bold upper- and lower-case letters. The \(i\)-th element of vector \(\) is denoted by \(x_{i}\). The \(i\)-th column vector of matrix \(\) is denoted by \([]_{i}\) and \([]_{i,j}\) denotes the \((i,j)\) element of \(\). \(^{n}\) denotes the \(n\)-th power of matrix \(\) for \(n\). \(\) denotes the indicator function. Sets and events are denoted by calligraphic letters. The cardinality of set \(\) is denoted by \(||\). For any set \([N]\), \(\{\}\{0,1\}^{N}\) is specified such that its elements at the coordinates included in \(\) are set to \(1\), and the rest are \(0\). For a vector \(\) and positive semidefinite matrix \(\), we define \(\|\|_{}=^{} }\) as the weighted \(_{2}\) norm. The \(_{1}\)-norm and \(_{2}\)-norm of vector \(^{d}\) are denoted by \(\|\|_{1}\) and \(\|\|_{2}\), respectively. The notation \(}\) is an order notation that ignores constant and poly-logarithmic factors.

## 2 Causal Bandit Problem Setup

Causal graph.Consider an _unknown_ directed acyclic graph (DAG) \(=\{,\}\) in which \(=[N]\) is the set of nodes and \(\) is the set of directed edges. A directed edge from node \(i\) to node \(j\) is denoted by the ordered tuple \((i,j)\). The set of parents of node \(i\) is denoted by \((i)\). Similarly, the sets of ancestors and descendants of node \(i\) are denoted by \((i)\) and \((i)\), respectively. We define the _causal depth_ of node \(i\), denoted by \(L_{i}\), as the length of the longest directed causal path that ends at node \(i[N]\). According, we denote the maximum causal depth of the graph by \(L_{i[N]}L_{i}\) and denote the _maximum in-degree_ of the graph by \(d\{_{i[N]}|(i)|\}\).

Data model.DAG \(\) represents a Bayesian network, in which we denote the causal random variable associated with node \(i\) by \(X_{i}\). Accordingly, we define the random vector \(X(X_{1},,X_{N})^{}\). For any \(A\), \(X_{A}\) denotes the vector formed by \(\{X_{i}:i A\}\). The extents of the cause-effect relationships among the causal variables \(X\) are specified by the following linear SEMs:

\[X\ =\ ^{}X+\;,\] (1)

where \(^{N N}\) is the edge weights matrix and \((_{1},,_{N})^{}\) denotes the model noises. It is noteworthy that the element \([]_{j,i}\) is non-zero if and only if \(j(i)\). We denote the conditional distribution of \(X_{i}\) given its parents by \((X_{i} X_{(i)})\).

Soft stochastic interventions.We use _soft_ interventions as the most general form of intervention. A _soft_ intervention on node \(i\) retains the ancestral dependence of \(X_{i}\) on \(X_{(i)}\) and its probabilistic nature. Specifically, a soft intervention on node \(i\) changes the conditional probability \((X_{i} X_{(i)})\) to a distinct one denoted by \((X_{i} X_{(i)})\). In a linear SEM, the impact of a soft intervention on node \(i\) can be abstracted by a change in the vector \([]_{i}\). We denote the post-intervention vector by \([^{*}]_{i}\). We refer to \(\) and \(^{*}\) as the observational and interventional weights matrices, respectively. We allow multiple nodes to be intervened simultaneously and denote the space of possible interventions by \( 2^{[N]}\). For a specific intervention \(\), we define \(_{}\) as the post-intervention weight matrix specified by

\[[_{}]_{i}\ \ \{i\}[ ^{*}]_{i}+\{i\}[]_{i}\;.\] (2)

Causal bandit - problem statement.In causal bandit, a learner performs a sequence of interventions to optimize a reward measure. Each unique set of interventions \(\) is represented by an arm. Following the CB's convention, we designate node \(N\) as the reward node and its associated value \(X_{N}\) as the reward variable. We denote the post-intervention probability measure of \(X\) induced by intervention \(\) by \(_{}\), and the associated expectation by \(_{}\). Subsequently, we denote the expected value of variable \(X_{i}\) under intervention \(\) by

\[_{i,}\ \ _{}[X_{i}]\;,\] (3)

Accordingly, we denote the optimal intervention by \(^{*}\), which is specified by

\[^{*}\ \ *{arg\,max}_{} _{N,}\;.\] (4)

The sequence of interventions over time is denoted by \(\{(t):t\}\). Upon intervention \((t)\) in round \(t\), the learner observes \(X(t)(X_{1}(t),,X_{N}(t))^{}\) and collects the reward \(X_{N}(t)\). The learner's objective is to minimize the regret that it incurs with respect to an omniscient oracle that hasaccess to the best intervention \(^{*}\). Hence, the average regret incurred at time \(t\) is \(r(t)=_{^{*}}-_{}\). Accordingly, the average cumulative regret over horizon \(T\) is given by

\[[(T)]\ \ T_{^{*}}-_{t=1}^{T}_{ (t)}\.\] (5)

We list the set of assumptions that we make about the SEMs.

**Assumption 1** (Unknown graph).: _We assume that the skeleton and orientation of the edges in graph \(\) are unknown. We assume the number of nodes \(N\) and degree \(d\) are known._

This assumption is in contrast to all the existing studies on soft intervention [15; 16; 17; 18].

**Assumption 2** (Unknown conditional distributions).: _We assume that all observational and interventional conditional distributions \(\{(X_{i} X_{(i)}):i[N]\}\) and \(\{(X_{i} X_{(i)}):i[N]\}\) are unknown._

**Assumption 3** (Weight matrices).: _The interventional and observational matrices \(\) and \(^{*}\) are unknown. We assume that the range of weight matrix elements is known, i.e., there exists a known \(m_{}_{+}\) such that \(|[]_{j,i}|\ \ m_{}\) and \(|[^{*}]_{j,i}|\ \ m_{}\) for all \(i,j[N]\)._

**Assumption 4** (Noise model).: _We assume that the noise statistical model is unknown. The expected noise value \([]\) is known. We assume the noise terms are independent and bounded, i.e., there exists \(m_{}_{+}\) such that \(|_{i}(t)| m_{}\) for all \(i[N]\) and \(t[T]\)._

We note the assumption that knowing \(d\) can be replaced by knowing an upper bound, and the requirement of expected noise value \(\) can be removed by the re-arrange method in . To ensure the bounded stability of the system, the bounded noise and weights assumptions are widely used in the linear causal bandits literature [15; 26; 27]. These assumptions imply boundedness of the variables, i.e., there exists constant \(m\) such that \(\|X\| m\). The recent study in  shows that in linear bandits, the regret will scale linearly with this constant. Without loss of generality, we assume \(m_{}=m_{}=1\). Finally, we provide the following standard regularity condition on interventions to ensure sufficient distinction between the observational and interventional statistical models [20; 23].

**Assumption 5** (Intervention regularity).: _A soft intervention on node \(i\) with causal depth \(L_{i} 1\) shifts the expected values of the descendants of \(i\) at least \(\), i.e., \(_{j,}-_{j,(i)}\ >\ \) for all \(i[N]\) and \(j(i)\)._

## 3 Graph-Agnostic Linear Causal Bandit (GA-LCB) Algorithm

In this section, we introduce our proposed algorithm **G**raph-**A**gnostic **L**inear **C**ausal **B**andit (GA-LCB). We also provide detailed comparisons to the existing algorithms designed for soft interventions. We will provide the regret analysis in Section 4, and defer all the proofs to the appendices.

Algorithm overview.Identifying the best intervention \(^{*}\) defined in (4) hinges on learning all the possible probability distributions \(_{}\), the number of which grows exponentially with graph size \(N\). Learning such an excessive number of distributions can be circumvented by properly leveraging the SEM parameters. Specifically, all the distributions \(\{_{}:\}\) are functions of the observational and interventional weight matrices \(\) and \(^{*}\). Furthermore, we note that each of these matrices consists of at most \(Nd\) non-zero entries. Hence, learning the entire set of distributions is equivalent to estimating at most \(2Nd\) non-zero parameters of \(\) and \(^{*}\). This problem, however, faces the hard constraint that the estimated matrices \(\) and \(^{*}\) must conform to a valid DAG structure. Not enforcing this constraint gives rise to issues such as the possibility of support structures that include cycles or inconsistent supports for the estimates of \(\) and \(^{*}\).

For this DAG-constrained problem of estimating matrices \(\) and \(^{*}\), we take a two-step approach. The first step aims to resolve the skeleton uncertainty to the extent needed to identify the best intervention, and the second step leverages the skeleton estimates to identify the best intervention design. More specifically, the first step (GA-LCB-SL in Algorithm 1) focuses on estimating the skeleton, which is equivalent to estimating the parent sets \(\{(i):i[N]\}\). Forming such estimates based on _soft_ interventions is fundamentally different from doing so based on \(do\) intervention setting [20; 23] since under \(do\) interventions, identifying \((N)\) suffices to determine the best intervention when there are no confounders. This is because \(do\) interventions remove all ancestral dependence of \(X_{N}\), and its statistical model can be specified only by the value assigned to its parents under a \(do\) intervention. Under soft interventions, however, all the causal paths from the youngest nodes to the reward node remain intact. This means that all nodes along the causal paths that end at the reward node contribute to the reward. Therefore, inevitably, we need to estimate the parent sets \(\{(i):i[N]\}\). Motivated by these, Algorithm 1 provides estimates \(\{}(i):i[N]\}\) such that with a high probability: (1) \((i)}(i)\); and (2) \(|}(i)| c|(i)|\) for a small constant \(c>1\). We note that our approach is distinct from the conventional approaches to learning causal skeletons, which typically identify only the Markov equivalence class and assume the existence of an oracle rather than focusing on sample complexity and computational efficiency. For linear non-Gaussian data, a DAG can be learned using observational data with a sample complexity of \(O(d^{4} n)\). In comparison, our CB-based structure learning saves on sample complexity and computation.

```
1:Inputs: identifiability parameter \(\), sufficient exploration conditions \(T_{1}\) and \(T_{2}\)
2:\(t=0\)
3:while\(}\) is not a DAG or \(t(N+1)T_{1}\)do
4: Pull the arm \((Nt+1)=\) and observe \(X(t)\) and set \(t=t+1\)
5:for\(i[N-1]\)do
6: Pull the arm \((Nt+i+1)=\{i\}\) and observe \(X(t)\)
7: Identify the ancestors set \(}(i)\) according to (9) and construct \(}\)
8:\(t=t+1\)
9:if\(N_{}<T_{2}\)then Pull the arm \((t)=\) and observe \(X(t)\) until \(N_{}=T_{2}\)
10: Calculate the Lasso estimator \([}]_{i}^{}\) as in (10)
11: Identify the parents: \(}(i)=([}]_{i}^ {})\)
12: Return: \(\{}(i) i[N]\}\) and topological ordering \(\) based on ancestors sets ```

**Algorithm 1** Graph-Agnostic Linear Causal Bandit: Structure Learning (GA-LCB-SL)

The second step is focused on narrowing the search space for the set of candidate interventions among which the optimal one is identified. This will provide significant computational savings as we will discuss. In this step, specifically, based on the estimates \(\{}(i):i[N]\}\), the GA-LCB-ID algorithm performs a successive refinement of the set \(\) to identify the intervention set of interest. This process consists of \(S=\) refinement stages, where the refined set in stage \(s[S]\) is denoted by \(}_{s}_{s-1}\) with \(}_{1}\). To identify the interventions to be eliminated at stage \(s\), the GA-LCB-ID algorithm identifies the interventions whose UCB values fall below the maximum in \(}_{s}\) minus a bandwidth \(m2^{1-s}\). Such successive refinement allows us to calculate UCBs only for promising interventions, leading to a higher computational efficiency. Furthermore, the refinement rules do not need to calculate the exact UCB values. Instead, they calculate an upper bound for the UCBs, referred to as the UCB _widths_. This circumvents the computational challenge of calculating the exact UCBs.

### Step 1: CB-based Structure Learning

Our approach to using a sequence of interventions to learn the unknown graph \(\) consists of two procedures. It starts by identifying the correct ancestors \((i)\) for \(i[N]\). After \(T_{1}\) rounds of exploration, for all \(i,j[N]\) we compute the mean estimates as

\[_{i,}(t)\ =\ (t)}_{[t], ()=}X_{i}()\,_{i,\{j\}}(t)\ =\ }(t)}_{[t],()=\{j\}}X_{i}()\,\] (6)

where \(N_{}(t)\) denote the number of times the \(\) is selected up to time \(t\)

\[N_{}(t)\ \ _{[t]}\{( )=\}\,.\] (7)

Subsequently, the algorithm identifies descendants sets \(}(i)\) for \(i[N]\) according to:

\[}(i)\ =\ \{j[N]\ :\ |_{j,}-_{j, \{i\}}|>\}\,\] (8)according to which clearly \(i}(i)\). Note that \(|(i)|=0\) indicates that node \(i\) is a root node (intervention on a root node does not change the conditional distributions). Furthermore, we also estimate the ancestors sets \(\{}(i):i[N]\}\) according to:

\[}(i)=j[N]\;:\;i j\{|}(j)|=0i}(j)\}}\;.\] (9)

The algorithm will check whether the ancestor sets will form a DAG. This is confirmed by verifying that there does not exist \(i,j[N]\) such that \(j}(i)\) and \(i}(j)\). To further refine the estimate of the parent set, the algorithm initiates \(T_{2}\) rounds of additional explorations. This ensures the algorithm has gathered sufficient observational data to accurately identify the parent set \((i)\). Subsequently, it uses the Lasso estimator on the ancestors set with \(=m}(i)|/)}{N_{}(t)}}\) for \(i[N]\) as

\[[}^{}]_{i}\;=\;^{| (i)|}}{}}(t)}_{ [t],()=}X_{i}()-^{}X_{ {}(i)}()^{2}+\|\|_{1}.\] (10)

Based on these steps, Algorithm 1 identifies the parent set of node \(i[N]\) as

\[}(i)\;=\;([}^{ }]_{i})\;.\] (11)

Specifically, Algorithm 1 returns the estimates \(\{}(i):i[N]\}\) and a valid topological order \(\) based on ancestor information. Given a causal graph \(\), an ordered permutation of \([N]\), denoted by \(\) is said to be a valid topological order if for each edge \((i j)\), we have \(_{i}<_{j}\). This can be achieved by iteratively adding nodes to \(\) such that the parents of that node are already included in \(\). Finally, we note that we set the exploration constants \(T_{1}\) and \(T_{2}\) as follows.

\[T_{1}=}{^{2}}(}{})\;,  T_{2}=cd(N)\;,\] (12)

where \(c>1\) is a constant.

```
1:Inputs: Time Horizon \(T\), \(S=\), exploration parameter \(^{+}\), {identifiability parameter \(\), sufficient exploration conditions \(T_{1}\) and \(T_{2}\)} or {edge set \(\)},
2:if\(\) not given then
3:\(\{}(i)\;|\;i[N]\},=\)GraphLearning(\(,T_{1},T_{2}\))
4:set \(s=1\) and \(}_{1}=\)
5:while\(t T\)do
6:for\(i[N]\)do
7: Calculate the ridge regression estimators \([(t-1)]_{i}\) and \([^{*}(t-1)]_{i}\) as in (13) and (14)
8:for\(}_{s}\)do
9:for\(i\)do
10: Calculate estimated mean \(_{i,}(t)\) as in (17)
11: Calculate the width \(w_{i,}(t-1)\) according to (19)
12: Calculate \(_{}(t-1)=_{N,}(t-1)+w_{N, }(t-1)\)
13:if\(w_{N,}(t-1) m}\) for all \(}_{s}\)then
14: Choose \((t)\) according to (23) until \(t=T\)
15: Break
16:while\(w_{N,}(t-1) m2^{-s}\) for all \(}_{s}\)do
17: Update \(}_{s+1}\) as in (22) and set \(s=s+1\)
18: Choose \((t)}_{s}\) such that \(w_{(t)}^{*}>m2^{-s}\) ```

**Algorithm 2** Graph-Agnostic Linear Causal Bandit: Intervention Design (GA-LCB-ID)

### Step 2: Sequential Design of Interventions

Assume at the stage \(s S\), the algorithm maintains a refined set \(}_{s}\). It starts with the set of candidates \(}_{1}=\) and successively refines this set by performing elimination on the previous refined set using the \(\)_width_. Based on the outputs of Algorithm 1, we first estimate 

[MISSING_PAGE_EMPTY:7]

### Computational Efficiency

We compare the computational efficiency of our algorithm with those of the existing algorithms for linear SEMs with soft interventions in [15; 18]. The algorithms in these studies adopt similar procedures: they find estimators for observational and interventional weights, form the confidence ellipsoids for the weights, and solve a joint optimization problem to calculate UCBs as

\[_{}\ =_{}_{}_{ }} f_{N}}_{},\,,\] (24)

where \(_{}=_{i[N]}_{i,}\) and \(_{i,}=\{i\}_{i}^{*}+ \{i\}_{i}\) are confidence regions, \(f_{N}\) is compounding function (see [15, Lemma 1] or Appendix C). Subsequently, the interventions are chosen as those that maximize \(_{}\)

\[(t+1)=*{arg\,max}_{}_{}.\] (25)

All the algorithms estimate the observational and interventional weights by solving \(2N\) ridge regressions, which is not the computation bottleneck. The two bottlenecks in this standard UCB-type approach lie in solving (24) and (25).

First, different from the case in linear bandits , the optimization problem in (24) for CBs is neither convex nor concave. This is due to the highly non-linear reward function. The nonlinearity arises from the compounding effects of the causal influences along different paths leading to the reward node. The contribution of any given node \(X_{i}\) to the reward value will be multiplied by all the coefficients along the path connecting \(X_{i}\) to the reward node (see Appendix C for more details). When there are multiple such paths, the aggregate weight products of all paths carry the contribution of \(X_{i}\) to the reward node. Therefore, the reward becomes a function of the product of causal weights (i.e., elements of \(\) and \(^{*}\)). This non-linearity in weights makes the optimization problem in (24) becomes computationally impossible for larger graphs. In contrast, GA-LCB addresses this issue by computing the upper confidence bounds iteratively through causal depth, which can be done in polynomial time.

Secondly, solving (25) involves an optimization problem over a discrete set of size \(2^{N}\), the computational complexity of which grows exponentially with \(N\). To circumvent this, GA-LCB randomly chooses the under-explored intervention (line 18). UCB optimization specified in (23) is performed only when the refinement process is completed, indicating that (23) will be solved over a small subset of sufficiently good interventions.

## 4 Regret Analysis

We show that the GA-LCB is almost minimax optimal by characterizing the achievable regret of the GA-LCB algorithm in the graph-independent setting and establishing that it matches a minimax regret lower bound. We provide additional discussions to interpret the dependence of the regret terms on various graph parameters and the relationship of these results vis-a-vis the existing results in the literature. We also present an improved graph-dependent bound, when additional information about the graph is available.

### Graph-independent bounds

We first show the graph-independent bounds that hold for a class of bandits with a maximum in-degree \(d\) and maximum causal length \(L\). The key steps in these analyses involve determining the exploration time that ensures the identification of the parent sets with high probability and bounding the time instances that the refinement process is conducted. To delineate a regret upper bound, we start by establishing the performance guarantee for the GA-LCB-SL algorithm. In the following theorem, we demonstrate that with high probability, this algorithm correctly identifies the topological ordering and the parent sets. For this purpose, we define \(_{}\) and \(_{}\) as the maximum and minimum eigenvalue of the following second moment with null intervention:

\[_{}\ \ _{}(_{}[XX^{ }])\,,_{}\ \ _{}(_{}[XX^{}]).\] (26)

**Theorem 1** (Achievable Graph Skeleton Learning).: _Under Assumptions 1-4, the GA-LCB-SL algorithm ensures that_1. _with probability_ \(1-\) _we have a valid topological ordering_ \(\)_; and_
2. _with probability at least_ \(1-2\)_, for all_ \(i[N]\) _we have_ \((i)}(i)\) _and_ \(|}(i)||(i)|\)_,_

_where \(\) is defined as_

\[=,_{}+m^{2}} ()}\}}{_{}}\;.\] (27)

Leveraging the result of Theorem 1, we characterize the achievable regret of GA-LCB.

**Theorem 2** (Achievable Regret).: _Under Assumptions 1-5, the GA-LCB-ID algorithm ensures that with probability \(1-3\)_

\[[(T)]\;\;}( d)^{L- }+d+RN\;,\] (28)

_where we have defined \(R}{^{2}}\)._

We note that \(R\) represents the guaranteed maximum signal-to-intervention-power ratio. This ratio measures the difficulty in distinguishing between observational and interventional distributions (the higher \(R\), the harder to distinguish).

To emphasize the cost of learning the skeleton, in the next corollary, we provide the achievable regret of the GA-LCB algorithm when the graph skeleton is known.

**Corollary 1** (Achievable Regret - Known Skeleton).: _When the graph skeleton is known, under the same setting as in Theorem 2, with probability \(1-\), GA-LCB-ID ensures that_

\[[(T)]\;\;}d^{L-} \;.\] (29)

Comparing Corollary 1 with Theorem 1, we observe that the term \(}(d+RN)\) represents the cost to do structure learning, while \(^{L-}\) reflects the cost resulting from imperfect graph learning.

Next, we establish a lower bound on the regret. Any lower bound on the regret of the setting in which the graph's skeleton is _known_ will immediately serve as a lower bound for our setting with an _unknown_ graph. We will present one such lower bound and show that even though it is expectedly looser than a lower bound for our setting, it still almost matches the achievable regret characterized in Theorem 2. We also emphasize that our result improves the known minimax lower bound when the graph skeleton is known (c.f. ).

**Theorem 3** (Regret Lower Bound).: _For any given skeleton with parameters \(d\) and \(L\), there exists a causal bandit instance such that the expected regret of any algorithm is at least_

\[[(T)]\;\;d^{L-} \;.\] (30)

When comparing the upper bound in Theorem 2 and the lower bound in Theorem 3, we observe that the regret upper bound and lower bound show similar behavior with respect to graph parameter \(d\), \(L\), and the time horizon \(T\). Given these results, we provide some observations.

* **Dependence on \(N\).** We first note that the achievable regret has a diminishing dependence on the graph size \(N\) as \(T\) grows. This is especially important since the number of interventions grows exponentially with \(N\). This result indicates that the achievable regret has a diminishing effect not only on the graph size but also on the cardinality of the intervention space.
* **Unknown Skeleton.** Comparing Theorem 2 and Corollary 1 indicates that the impact of an unknown graph has two parts. First, sufficient exploration is required to determine the correct topological ordering and parent sets, which adds a \(}(d+RN)\) term to the regret bound. Secondly, the imperfect identification of the parent set by the Lasso estimator leads to an estimated graph with a maximum in-degree of \(cd\) instead of \(d\), which is propagated through the network layers.
* **Graph topology.** The regret bounds depend on the graph through its connectivity parameters \(d\) and \(L\). Unlike the observations in , we have almost-matching upper and lower bounds up to a \(d\) factor. This significantly improves from the previously-known gap of \(d^{L}\).

* **Dependence on \(T\).** Regret upper and lower bound both scale with \(T\) at the rate \(}()\).
* **Linear bandits.** Finally, we note that despite some similarities, our problem is significantly different from linear bandits since, as shown in Appendix C, in linear causal bandits, the reward is non-linear with respect to the parameters or the interventions. This is the case for even \(L=1\). We note that our regret's dependence on \(d\) differs from that in the linear bandit setting. In linear bandits, the regret scales linearly with \(d\) as shown in [31; 32]. When \(L=1\), the regret upper bound in our case scales as \(}()\), and the regret lower bound scales as \(()\). We conjecture that the regret upper bound is tighter because it more accurately captures the uncertainty of parameter estimation.
* **Regret bounds comparisons.** GA-LCB provides significantly improved regret bounds compared to LinSEM-UCB  and GCB-UCB . Specifically, under the known graph skeleton setting, GA-LCB achieves a \(d^{L}\) factor improvement in the regret bounds compared to LinSEM-UCB. While GCB-UCB removes the \(\) factor, it underperforms compared to LinSEM-UCB. Furthermore, our regret upper bound has only a \(d\) factor more than the lower bound.

### Graph-dependent Regret Bound

The graph-independent bounds can be further refined to recover graph-dependent regret bounds that use the instance-level information. To account for the actual influence of the graph parameters on the reward node, we define the _effective maximum in-degree_ as \(d_{e}=_{i(N)}d_{i}\) and the _effective maximum causal depth_ as \(L_{e}=_{i(N)}L_{i}\). We have the natural inequalities \(d_{e} d\) and \(L_{e} L\). To characterize the graph-dependent bound, we need to slightly modify the GA-LCB-ID algorithm. Specifically, we only need to identify the optimal intervention within \(^{}=2^{[}(N)]}\) and estimate the column vectors \(\{[]_{i},[^{*}]_{i}:i}(N)\}\). By incorporating instance-specific information about the graph structure, the regret upper bound can be further refined as follows.

**Corollary 2** (Achievable Regret - Graph-Dependent).: _When \(L_{e}\) and \(d_{e}\) are known, the modified GA-LCB-ID algorithm ensures that with probability \(1-3\)_

\[[(T)]\ \ }( d_{e})^{L_{e }-}+d+RN\.\] (31)

By comparing the upper bound in Theorem 2 and Corollary 2, we observe that the cost of learning the graph remains intact. The reason is that we must explore interventions on every node \(i[N]\) to identify the ancestor relationships, even when graph-dependent information is known. Hence, all the regret improvements are due to the part of learning the best intervention, particularly in relation to the graph topology. The term \(( d)^{L-}\) in Theorem 2 is replaced with \(( d_{e})^{L_{e}-}\). The change is due to the fact we do not need to learn optimal intervention in the whole graph \(\) as the interventions on non-ancestor nodes will not affect the reward. Instead, it suffices to learn only the optimal intervention on the subgraph \(}\) formed by \(}(N)\) and the parameters of \(}\).

## 5 Conclusions

In this paper, we have solved the causal bandit problem with unknown graph skeletons under general stochastic interventions. We have proposed an implementable algorithm and provided regret analysis for both unknown and known graph skeletons. The unknown skeleton affects the achievable regret bounds in two ways: a term that is linear in \(d+N\) but is independent of \(T\) and a \(cd\) factor due to the imperfect identification of the parents. When the graph skeleton is unknown, the achievable regret bounds and the minimax regret lower bound are shown to match up to a \(d\) factor. Compared to the existing algorithms, the proposed algorithm is more amenable to scalable implementation.