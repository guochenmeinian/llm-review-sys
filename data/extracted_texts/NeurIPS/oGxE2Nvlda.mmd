# UniT: A Unified Look at Certified Robust Training against Text Adversarial Perturbation

Muchao Ye1  Ziyi Yin1  Tianrong Zhang1  Tianyu Du2

Jinghui Chen1  Ting Wang3  Fenglong Ma1

The Pennsylvania State University, 2Zhejiang University, 3Stony Brook University

{muchao, zmy5171, tbz5156, jzc5917, fenglong}@psu.edu,

zjradty@zju.edu.cn, twang@cs.stonybrook.edu

Corresponding author.

###### Abstract

Recent years have witnessed a surge of certified robust training pipelines against text adversarial perturbation constructed by synonym substitutions. Given a base model, existing pipelines provide prediction certificates either in the discrete word space or the continuous latent space. However, they are isolated from each other with a structural gap. We observe that existing training frameworks need unification to provide stronger certified robustness. Additionally, they mainly focus on building the certification process but neglect to improve the robustness of the base model. To mitigate the aforementioned limitations, we propose a unified framework named UniT that enables us to train flexibly in either fashion by working in the word embedding space. It can provide a stronger robustness guarantee obtained directly from the word embedding space without extra modules. In addition, we introduce the decoupled regularization (DR) loss to improve the robustness of the base model, which includes two separate robustness regularization terms for the feature extraction and classifier modules. Experimental results on widely used text classification datasets further demonstrate the effectiveness of the designed unified framework and the proposed DR loss for improving the certified robust accuracy.2

## 1 Introduction

Despite the tremendous performance of deep neural networks (DNNs) in natural language processing (NLP) tasks, their robustness has been doubted due to their vulnerability against adversarial attacks . Particularly, a type of word-level adversarial perturbation named _synonym substitution_ can generate adversarial examples with high semantic similarity even in the hard-label setting with limited information [14; 26]. Accordingly, recent years have seen an urge for robust NLP models that can provide certified robust predictions [23; 25; 31] for this type of attack. A prediction for a text sample is **certified** if the hard-label prediction is correct and remains unchanged when the input is changed to any text sample constructed from the synonym substitution. The key to producing certified predictions is _certified robust training_, which introduces perturbation during training to ask the model to adapt to it and enables it to still perform well in the inference stage under perturbation.

Due to the large scale of NLP models nowadays, certification methods adopted for text data are usually probabilistic ones. In this context, given a base model that outputs a single prediction, a smoothed model is built on it in the inference stage with randomized mechanisms, whose outputs are used to decide whether predictions are certified. Thus, two aspects are essential for generating certified predictions: the robustness of the base model and the certification of the smoothed model.

Existing studies have established the foundation for designing smoothing techniques and their corresponding certification conditions. As Figure 1(a) manifests, a base model usually consists of three modules: (1) an embedding module that converts discrete words into continuous embeddings, (2) a feature extraction module that obtains its deep representation, and (3) a classifier constructed by the fully connected (FC) layer that converts the deep representation to logits. Given that, randomized mechanisms can either build in the discrete word space (**Type I**) or the continuous latent space (**Type II**). Figure 1(b) shows that Type I pipelines, including SAFER  and WordDP , use _perturbed text samples_ generated by replacing original words with their corresponding synonyms to train the base model and construct a smoothed model for certification. Another type of training, the Type II one, is shown in Figure 1(c), which are recently proposed by CISS . They _add Gaussian noise to latent features of original text samples_ to train the base model and certify the prediction in the latent space in a randomized smoothing  fashion with the help of the interval bound propagation (IBP)  module.

Given these profound pioneering works, the observation motivating our work is that existing pipelines _ignore the unification of training frameworks and robustness of the base model_. For one thing, structure-wise speaking, Type II frameworks like CISS need to include an extra IBP module compared to Type I frameworks, which affects the certification because of the loose bound problem  of IBP. This is validated by our finding that IBP can cause the failure to strike a balance between natural accuracy and certification ratio. For another, both types of frameworks mainly use the cross-entropy (CE) loss calculated from the perturbed inputs for training to improve the discriminative ability of the base model, which is the same as normal training. However, this strategy lacks fine-grained robustness regularization for individual modules and consideration of the final certification target.

To develop a new method that mitigates the aforementioned limitations, we will face two research questions: (**RQ1**) how to build a unified framework for these two types of pipelines to provide stronger certified robustness and (**RQ2**) how to design robustness regularization terms for individual modules to further improve the base model robustness. Our solution to them is as follows:

For **RQ1**, we propose a new framework named UniT to unify Type I and Type II training. UniT resorts to the embedding space as an intermediate for unification. In the Type I scenario, it uses embeddings of perturbed words to train the base model directly. For the Type II scenario, it does not need the IBP module and adds Gaussian noise directly to the concatenated word embeddings of the text sample. We accordingly provide a novel certification condition in the embedding space.

For **RQ2**, we design a novel loss for certified robust training named decoupled regularization (DR) loss that compensates the CE loss with the modular regularization (MR) term. It consists of two parts. Part I is the \(l_{2}\) norm between the representations of the original sample and the perturbed input, which concentrates on the feature extraction module. Part II includes a novel term calculating the prediction margin from the logits when the original sample representation is slightly perturbed (modeled by Gaussian noise), which takes the certification target into consideration and aims to regularize the classifier module. They are linearly combined to provide supportive regularization for different modules based on their responsibilities and refine the robustness. To sum up, our contributions are:

* To the best of our knowledge, we are the first to provide a comprehensive viewpoint on certified robust training in text. We design a unified structure named UniT built in the embedding space that enables Type II frameworks to be conducted without using IBP during training and certification.
* We propose the DR loss to improve the robustness of the base model. It provides modular regularization directly to aid the CE loss. That is, the feature extraction module is regularized by

Figure 1: Given the (a) base model, (b) Type I frameworks construct the smoothed model in the discrete word space while (c) Type II frameworks construct it in the latent space with IBP. There is a need for unifying these training frameworks and improving the robustness of the base model.

the representational \(l_{2}\) norm, while the classifier module is regularized based on the prediction margin calculated from the perturbed representations obtained by adding noise to the original ones.
* Experimental results show that the design of the UniT with DR loss is effective in improving the certified robust accuracy of both types of certification scenarios.

## 2 Preliminaries and Related Work

### Certified Robust Training in Image

The development of certified robust training dates back to certifying multi-layer perceptions (MLPs) for image data. Early work tries to formulate certification as an optimization problem with the techniques of mixed integer linear programming  and semidefinite relaxation . A practical solution to this problem is using the IBP  method and its variants , whose key idea is to regard the upper and lower bounds of activated output in each layer as parameters and they are trained by backpropagation. Later development on deterministic certification methods also includes developing Lipschitz networks . However, they can only certify the robustness of shallow neural networks. Another line of certified robust training is conducted by randomized smoothing . It helps provide a certificate in a probabilistic manner, which is more scalable and can certify larger DNNs.

### Certified Robust Training in Text

**Problem Formulation.** Suppose that we are given a text classification dataset \(\). Let \(=\{y_{1},,y_{c}\}\) denote the set of \(c\) classes of \(\). We have \((X,y)\) as a sample drawn from \(\). For the text sample \(X=[w_{1},,w_{n}]\) with \(n\) words, \(w_{i}\) is the \(i\)-th word, and its ground truth is \(y\). We denote \(f\) as the **base model** for the text classification task, which outputs the prediction logits \([f_{y_{1}}(X),,f_{y_{c}}(X)]\) for each class in \(\). Suppose that \(f\) can make the correct prediction, i.e., \(_{y_{i}}f_{y_{i}}(X)=y\). In the context of **certified robustness**, we are interested in getting a certified prediction result such that \(_{y_{i}}f_{y_{i}}(X^{})=y\) holds for any allowed perturbed sample \(X^{}\) of \(X\). In this paper, we center on certifying perturbed samples that are constructed by a powerful adversarial attack named synonym substitutions  (an example is shown in Table 10 in the Appendix). Note that this setting is different from the one in  which certifies the prediction under unconstrained word perturbation for a limited amount of words, and adversarial examples generated from synonym substitution have lower perturbation rates compared to the ones from rephrasing  and prompting. In this setting, for each word \(w_{i} X\), suppose it has \(m_{i}\) synonyms, its allowable adversarial substitution set is denoted by \(S(w_{i})=\{w_{i}^{(1)},,w_{i}^{(m_{i})}\}\) (Note that \(S(w_{i})\) includes \(w_{i}\)). All perturbed samples \(X^{}\) obtained by replacing original words with their synonyms construct the allowed perturbed sample set \(A(X)=\{X^{}|X^{}=[w_{1}^{},,w_{n}^{}],w_{i}^{ } S(w_{i}),i=1,,n\}\).

**Training and Certification.** Since \(A(X)\) is a large set of perturbed samples (\(|A(X)|=_{i=1}^{n}m_{i}\)), it is impractical to certify the prediction by asking \(f\) to make a prediction on every \(X^{} A(X)\). Therefore, existing techniques usually certify prediction results by the upper bound condition. If such a certification condition satisfies, the prediction is certified robust. Certified robust training is needed to attain a certified prediction result for \(X\) such that the certification condition can be satisfied in testing. For example,  and  introduce the IBP-based methods and use the upper bound of text representation in the final layer to certify the result. However, due to the costly bound propagation, IBP-based methods can only be used in shallow MLPs and cannot be applied to large language models like BERT . Besides, IBP has a loose bound problem , i.e., upper bounds get loose in the last several layers during propagation, which obstructs the certification of some samples.

Thus, recent studies mainly use probabilistic certified defense methods to obtain certified predictions for more powerful but intricate networks. As demonstrated in Figure 1, existing certified robust training methods for probabilistic certification are categorized into two types. Their common treatment is to introduce perturbation during training. They ask the whole network to get used to the perturbed samples, which are either perturbed input texts \(X^{}\) (**Type I**) [23; 25] or perturbed latent features injected into Gaussian noise (**Type II**) . They usually use the CE loss to improve the discriminative ability of the base model. In certification, they construct a **smoothed model**\(F\) for \(f\). _A prediction is certified when the logit score of the ground truth class output by \(F\) is larger than that of the runner-up class by a large enough margin_, which we refer to as the certification condition. Denote \(F_{y_{i}}\) as the soft-label prediction score of \(F\) on class \(y_{i}\). The runner-up class is defined as \(y_{B}=_{y_{i},y_{i} y}F_{y_{i}}(X)\) with the largest logit except for \(F_{y}\). We now briefly mention their certification and kindly ask readers to review their works for a more complete picture if needed.

(1) For the Type I scenario, \(F\) is constructed by averaging the results attained from inputting several perturbed text samples to \(f\). The certification _depends explicitly on the prediction margin_\(F_{y}(X)-F_{y_{B}}(X)\). For example, the certification condition of SAFER (Proposition 1 in ) is \(F_{y}(X)-F_{y_{B}}(X)>2q_{X}\), where \(q_{X}\) is a constant calculated from the synonym set of the input \(X\).

(2) In the Type II scenario, \(F\) is constructed by repeatedly adding Gaussian noise \((0,^{2}I)\) to the text representation in the latent space, where \(\) is the standard deviation and \(I\) is the identity matrix. To illustrate, under the randomized smoothing framework, CISS  repeatedly draws Gaussian noise perturbations and adds them to the latent feature of the original sample. It counts the top-1 prediction distribution of \(\) given all perturbed inputs. After that, the prediction is certified if \(_{y}>0.5\) and \(R=^{-1}(_{y})>\) (Algorithm 2 in ), where \(_{y}\) is the lower bound of the expected value of the event that the hard-label prediction output by \(f\) of the given perturbed input is class \(y\), \(R\) is the certified radius, \(^{-1}\) is the inverse of the standard Gaussian cumulative distribution function (CDF), and \(\) is the maximum \(l_{2}\) norm between \(X\) and any \(X^{} A(X)\) in the latent space obtained from IBP. The certification _implicitly depends on the prediction margin_. If the prediction margin is large, the calculated \(_{y}\) and \(R\) will get greater, which helps the certification.

There are also some interesting discussions extended from certified robustness such as whether certified robustness helps fairness . We mainly focus on the certification performance herein and kindly ask readers to review related works for further information about those discussions.

## 3 UniT: Unified Certified Robust Training

To provide stronger certified robustness for those important but independent frameworks, we design a unified one named UniT that can unify these two types of training without introducing extra modules such as the IBP module used in CISS. In this paper, we utilize BERT as the base model because it yields the best performance for state-of-the-art training frameworks such as SAFER and CISS in two settings. The basic processing procedure of the base model is shown in Figure 2, indicated by the black solid lines. It first transforms the input sample with \(n\) words to a concatenated BERT word embedding \(x^{n d}\) where \(d=768\) is the dimension of word embedding. Then the word embeddings will be processed by the BERT feature extraction module (Transformer [22; 24] blocks) which outputs the [_CLS_] token embedding \(z^{d}\) as the representation of the whole text. Finally, the classifier module (FC layer) outputs logits from \(z\), and the loss is calculated for training. We shall notice that the structural decomposition analysis above is general among different models, e.g., RoBERTa  and ALBERT , so we can also adopt DR loss for other structures when needed. We now detail our motivation and design of UniT.

### Motivation: Why Do We Need Unification and Better Supervision?

The supervision for improving the discriminative ability of the model during certified robust training generally builds on the CE loss. Since the calculation of the loss function is only related to the last FC layer in the classifier, we denote the last FC layer as \(g\) for illustration. We denote \(z^{}^{d}\) as the representation obtained from the feature extraction module given a perturbed input.

The CE loss is calculated from \(z^{}\), i.e., \(_{ce}=-((g_{y_{i}}(z^{}))}{_{i}(g_ {y_{i}}(z^{}))})\), where \([g_{y_{1}},,g_{y_{c}}]\) is the logit distribution given the perturbed input for each class in \(y_{i}\). As depicted in Figure 1, Type I training builds a smoothed model in the discrete word space, and its training is almost the same as normal training except for perturbed inputs. Meanwhile, the loss for Type II training is \(_{tr}=_{ce}+_{}\), where \(\) is the weight hyperparameter. It contains not only the CE loss but also a certified radius regularizer \(_{}=(-R+,0)\), where \(\) is the relaxation hyperparameter, \(R\) is the certified

Figure 2: Given the base model, UniT unifies two frameworks by working in the embedding space. Type I training replaces original embeddings with embeddings of perturbed samples. Type II training adds Gaussian noise to original word embeddings.

radius, and \(\) is the maximum deviation caused by synonym substitution in the latent space that we introduce in Sec. 2.2. We notice that there is a trade-off between the certification ratio and the natural accuracy for \(_{tr}\) in Type II training: _a relaxed regularization on the certified radius can make the base model have higher natural accuracy but a lower certification ratio, and vice versa._

We verify this observation by taking CISS for instance. We can obtain a relaxed regularization on certified radius by replacing \(\) with its **lower bound**\(_{lb}\) and a strict one by its **upper bound**\(_{ub}\). Suppose the minimum and the maximum deviation in any dimension is \(\) and \(\), respectively, and the number of dimensions in the latent space is \(d_{I}\). We then have \(_{lb}=}\) and \(_{ub}=}\). We denote the corresponding regularizers as \(_{_{lb}}=(_{lb}-R+,0)\) and \(_{_{ub}}=(_{ub}-R+,0)\).

We show the results of how this trade-off affects certified robust accuracy in Table 1. Compared to the original \(_{}\), if we impose a relaxed regularization \(_{_{lb}}\), the natural accuracy will increase but the certification condition is hard to satisfy, and consequently, the certified robust accuracy is near \(0\%\). On the contrary, a stricter regularization \(_{_{ub}}\) makes the smoothed model satisfy the certification condition easily (almost 100%), but it hurts the natural accuracy. An interesting finding in Table 1 is that strict regularization \(_{_{ub}}\) helps obtain a higher certified robust accuracy (CRA) than the original regularization \(_{}\) used in CISS. This is because \(\) in CISS is obtained from IBP, and it has a loose bound problem. The certified radius regularization \(_{}\) from IBP is a somewhat strict one, so CISS cannot strike a balance for this trade-off with IBP. Therefore, **we shall remove IBP and avoid this calculation**. In addition, since the CE loss is deployed to improve discriminative ability, another direction for mitigation is to adopt better supervision other than the CE loss for ameliorating the model robustness, which motivates us to **provide individual supervision for each module**.

### Training Input

Recall that in the **Type I** scenario, the original input \(X=[w_{1},,w_{n}]\) is replaced by the perturbed sample \(X^{}=[w^{}_{1},,w^{}_{n}] A(X)\). Correspondingly, in this scenario, UniT uses the embedding \(x^{}=[u(w^{}_{1}),,u(w^{}_{n})]\) as the input to train the base model, where \(u\) is the _BERT embedding_ function. For the **Type II** scenario, to facilitate randomized smoothing, UniT needs to inject Gaussian noise into the _BERT embeddings_ for training. Thus, given a sample of zero-mean Gaussian noise \((0,^{2}I)^{n d}\), UniT uses the embedding \(x+\) as the input. In this sense, we unify two types of certified robust training in one framework by utilizing the embedding space as the intermediate. Thus, all modules can remain the same for either type of certified robust training.

### Certification

For the **Type I** scenario, we can obtain the certified robustness guarantee from Proposition 1 of SAFER  by constructing the smoothed model based on synonym substitutions. We thereby intend to detail our proposed certification for the **Type II** scenario without IBP. Note that the key calculation for certification in this scenario is \(\), which is the maximum \(l_{2}\) norm caused by allowed perturbed synonyms in the embedding space. This calculation by UniT is different from CISS because UniT does not need IBP module, and it is directly obtained in the BERT embedding space \(^{n d}\) as follows.

Given the text sample \(X=[w_{1},,w_{n}]\), its BERT embedding is \(x=[u(w_{1}),,u(w_{n})]\). Similarly, for any perturbed sample \(X^{}=[w^{}_{1},,w^{}_{n}] A(X)\), its embedding \(x^{}=[u(w^{}_{1}),,u(w^{}_{n})]\). Since each word is independent of the others in the embedding space, the \(l_{2}\) norm between \(x\) and any \(x^{}\) is \(||x^{}-x||=^{n}||u(w_{i})-u(w^{}_{i})||^{2}}\). For each word \(w_{i} X\), because its synonym embedding set is \(U_{i}=\{u(w^{(1)}_{i}),,u(w^{(m_{i})}_{i})\}\), the maximum deviation between \(w_{i}\) and any word in \(S(w_{i})\) measured by \(u\) is \(||v_{i}||=_{e U_{i}}||u(w_{i})-e||\). Due to the independence of embedding of each word, the maximum deviation caused by all synonyms is

\[=||^{2}++||v_{n}||^{2}}.\] (1)

  Regularization & \(_{}\) & \(_{_{ub}}\) & \(_{_{ub}}\) \\  Natural Acc. (\%) & 93.88 & 89.57 & **96.34** \\  Cert. Ratio (\%) & 94.38 & **99.56** & 0.81 \\  CRA (\%) & 88.60 & **89.18** & 0.78 \\  

Table 1: Trade-off between natural accuracy and certification ratio. Experiments are conducted in Yelp  with CISS.

By adopting Eq. (1) to calculate \(\), we can train and certify in the Type II scenario without IBP and avoid bound propagation. We can conduct the certification in the embedding space with Theorem 1.

**Theorem 1**: _Given\((X,y)\) from \(\), suppose that the text embedding of \(X\) is \(x\). Let \(h:s\) be the hard-label prediction function of UniT in the Type II scenario that takes as the input a vector \(s^{n d}\) in the text embedding space and outputs the class with the largest logit. Let \((0,^{2}I)\), where \(\) is the standard deviation of the added Gaussian noise. If_

\[_{}[h(x+)=y]_{y_{i},y_{i} y} \ _{}[h(x+)=y_{i}],\] (2)

_then \( x^{},h(x^{})=y\) is robust where \(x^{}\) is the text embedding of any \(X^{} A(X)\) if \( R\), and_

\[R = [^{-1}(_{}[h(x\ +\ )=  y])\ -\ ^{-1}(_{y_{i},y_{i} y}_{}[h(x\ +\ )= y_{i}])],\] (3)

_where \(^{-1}\) is the inverse of the standard Gaussian CDF, and \(\) is calculated from Eq. (1). Due to the space limit, the proof and certification algorithm are shown in Sec. A.7 in the Appendix._

### Training Loss

To provide better supervision for training the base model, we propose a decoupled regularization (DR) learning paradigm that directly conducts modular regularization to aid the CE loss. We decouple the regularization on the whole model into one on the feature extraction module and the other on the classifier module. Thus, this pathway includes two branches. Such a regularization decomposition requires each module to be robust under the perturbation, which contributes to enhancing the robustness of the base model with more flexibility, leading to better training and certification results.

**Feature Extraction Regularization.** For the feature extraction module, its responsibility is to output a deep representation of a given text. The stability of representation, i.e., the degree of change in the representation space given a small change of input, depicts the robustness of the feature extraction module. To regularize it, we calculate the \(l_{2}\) norm between perturbed representation \(z^{}\) and original representation \(z\),

\[_{fr}=||z^{}-z||,\] (4)

where \(||||\) is the \(l_{2}\) norm.

We choose \(l_{2}\) norm over cosine similarity because it is directly related to the prediction margin defined in Sec. 2.2 in calculation. Thus, it can limit the influence of perturbation on downgrading the certification performance. Intuitively, it functions as a regularization term that asks the representations obtained from the feature extraction module given the original sample and perturbed sample to be similar to each other, which is helpful for obtaining a similar logit for \(z^{}\) given the same classifier module. Hence, it further enhances the representational stability and the model robustness.

**Classifier Robustness Regularization.** Since the representational stability regularization in Eq. (4) only concerns the feature extraction module, another direction for strengthening the base model robustness is to design a feedback signal in the classifier level that is complementary to Eq. (4). We know that the classifier module is the one that outputs the logits. Recall that in Sec. 2.2 we discuss that the certification is highly dependent on the prediction margin output by the smoothed model, which is the difference between the logits of the ground truth class and the runner-up class. By connecting these two observations together, in the context of certified robust training, we can interpret the robustness of the classifier module as being able to generate a positive prediction margin despite the perturbation added to the original input \(z\).

Consequently, we introduce a novel regularization term for the classifier module based on its ability to output a positive prediction margin against a small perturbation. Since this regularizer is confined to the classifier, we introduce a small amount of Gaussian noise \(\) here to model the perturbation and sample a point \(z+\) from the neighbor of \(z\). _Note that \(\) only serves for modeling small

Figure 3: DR loss contains a pathway (MR term) for providing modular regularization for CE loss.

perturbation in training. It will not be added in certification and is not related to the Gaussian noise \(\) used for certification in Type II scenario._ That is, it starts with adding Gaussian noise \(^{d}\) to \(z\), where \((0,^{2}I)\) is drawn from the zero-mean isotropic Gaussian distribution with \(\) as the standard deviation hyperparameter. Denote the prediction margin given a vector \(k^{d}\) as \((k)=g_{y}(k)-_{y_{i},y_{i} y}g_{y_{i}}(k)\), where \(g_{y}()\) and \(_{y_{i},y_{i} y}g_{y_{i}}()\) refers to the logits of the ground truth class and the runner-up class, respectively. We then calculate the margin given perturbed input \(z+\) as \((z+)\). We take its negative as an optimization term for minimization:

\[_{cr}=-((z+),0).\] (5)

\(_{cr}\) has a \(\) operation that outputs 0 when \((z+)<0\). This operation acts as feedback for asking the optimization to concentrate on improving the representation space and the discriminative ability through the other terms when \((z+)<0\), which will not regularize \(g\) if \(z\) is not well learned.

**Modular Regularization Term.** After that, these two regularizers are combined as

\[_{mr}=(_{fr}+_{cr},),\] (6)

which we refer to as the modular regularization (MR) term. In Eq. (6), the MR term is calculated from the linear combination of \(_{fr}\) and \(_{cr}\), where \(\) is a weight hyperparameter greater than 0. Additionally, we introduce relaxation during optimization with \(\) operation, and \(>0\) is the relaxation hyperparameter. Putting them together provides a regularization on how small \(||z^{}-z||\) should be given the margin information. This geometric interpretation is detailed in Sec. A.8.

**DR loss.** Given the MR term, we can combine it with the CE loss as the DR loss, which is

\[_{dr}=_{ce}+_{mr},\] (7)

where \(\) is a weight hyperparameter for \(_{mr}\) term. Given that, in the Type I training, we can directly use \(_{dr}\) for training. For Type II training, since the certification is related to \(\), we also have a regularizer for \(\) with \(_{}=(-R+,0)\) as CISS does, where \(R\) is calculated from Eq. (3) and \(\) is the relaxation hyperparameter. Thus, the training loss in the Type II scenario is \(_{tr}=_{dr}+_{}\), where \(\) and \(\) are hyperparameters.

**Remark.** From Eq. (7), we observe that the DR loss is composed of the CE loss and the MR term, which are indispensable to each other. If we only use the CE loss, the individual regularization will be ignored. With the help of the MR term, the introduced regularizers in Eq. (6) directly request the representation to be stable and the classifier to be robust under the perturbation, which helps the CE loss to improve the base model robustness. Meanwhile, since the MR term does not penalize the wrongly classified cases, the CE loss is necessary for improving the discriminative ability.

As for computation cost, we acknowledge that compared to CE loss calculating the proposed DR loss needs to increase the computation complexity due to the calculation of getting the features of perturbed input and original input during training. Such a tradeoff is natural: to obtain better robustness it is generally unavoidable to increase computation cost, and the increase of computation cost also occurs for existing training techniques for improving robustness such as using PGD  loss and TRADES  loss. We want to point out that the computation cost of calculating DR loss is relatively lower which is approximately twice of the cost of caluating CE loss, which is similar to that of single-step PGD and is acceptable in implementation.

## 4 Experiments

Given the proposed method above, the questions of interest include: **(Q1)** Does the unified framework UniT outperform existing state-of-the-art approaches in both scenarios? **(Q2)** How does UniT improve the robustness of the base model in certified robust training? **(Q3)** Is the design of the UniT reasonable? We now answer them with the following experimental results.

### Experimental Setup

We describe the experimental setup first. Due to the space limit, we kindly ask the readers to refer to the Appendix for the details of hyperparameters, dataset description, and metric calculation.

**Datasets.** We conduct experiments on four widely used text classification datasets: (1) IMDB , (2) SST2 , (3) Yelp  and (4) AG .

**Baselines.** Because of different certification conditions used in different works, to gain a fair comparison, we compare the proposed method with baselines individually in Type I and Type II scenarios. To illustrate: (1) Since the code of WordDP  is unavailable, the Type I baseline we use is SAFER , which is the ground-breaking method that trains a model by inputting perturbed text samples constructed by randomly sampled synonyms and certifies the prediction results directly by the prediction margin. (2) The Type II baseline is CISS , a recently proposed method that trains the model and certifies the prediction with IBP in a randomized smoothing manner. Their implemented base models are BERT because it yields the best performance. Since  has shown that IBP methods [4; 5] cannot certify large networks like BERT, we hereby do not discuss them. We also include adversarial training losses like PGD loss  and TRADES loss  as baselines.

**Metric.** Naturally, certified robust accuracy (CRA) is the used comparison metric, and _certified robust accuracy \(=\) natural accuracy \(\) certification ratio_. It denotes the fraction of predictions that are not only correctly classified but also certified robust. As for its calculation, we follow the same process used in the baseline methods to have a fair comparison. Further details are in Appendix.

### Comparison Results

**Comparison of Certified Robustness in Type I Scenario.** To answer Q1, we first conduct the comparison experiments in Type I scenario. For SAFER and UniT, both of them use BERT as the base model, and the difference is that SAFER is trained with the CE loss and UniT is with the DR loss. The comparison results are in Table 2, which show that the DR loss increases the certified robust accuracy up to 3.68%, 1.37%, 0.68%, and 0.53% in IMDB, SST2, Yelp, and AG datasets, respectively. These results indicate that the MR term enlarges the prediction margin from the CE loss under perturbation to yield a higher certified robust accuracy. Hence, the DR loss can improve the robustness of the base model and help UniT achieve better performance in Type I scenario.

We also include adversarial training losses as baselines for Type I Scenario. From Table 2, DR loss can consistently perform better than PGD loss and TRADES loss in four datasets. Especially, DR loss is able to obtain a relatively high increment in terms of CRA on the datasets with long text samples such as IMDB and SST2. Thus, DR loss is a more suitable choice for certified robust training for its decomposed regularization, which requires each module to be robust under perturbation.

**Comparison of Certified Robustness in Type II Scenario.** We further conduct the comparison experiments in the Type II scenario to answer Q1, and the results are shown in Table 3. During implementation, we find that the training for randomized smoothing in CISS can only work in relatively large datasets (100k+ training samples). Therefore, we can only report comparison results on two large datasets satisfying this condition, i.e., Yelp and AG, with CISS as the baseline. As we have seen before, directly replacing the CE loss (first row) with the DR loss (second row) can help improve CRA.

In this setting, we are more interested in the analysis of whether using the structure of UniT can make Type II training achieve stronger certification without using extra modules. By comparing the last two rows in Table 3, we find that UniT achieves an increase of 2.02% and 1.39% in Yelp and AG in terms of certified robust accuracy than the CISS structure trained with the DR loss, respectively. This improvement shows that by directly conducting randomized smoothing in the BERT embedding space, UniT not only adapts to both Type I and Type II training but also improves the certified robust accuracy by avoiding the loose bound problem of the IBP module.

  Base Model & Loss & IMDB & SST2 & Yelp & AG \\   & CE Loss (SAFER) & 85.36 & 91.65 & 97.19 & 93.78 \\   & PGD Loss & 87.52 & 90.28 & 97.86 & 93.98 \\   & TRADES Loss & 86.80 & 90.44 & 97.56 & 93.96 \\    & DR Loss (UniT) & **89.04** & **93.02** & **97.87** & **94.31** \\  

Table 2: Comparison of certified robust accuracy (%) in the Type I scenario.

  Method & Loss & Yelp & AG \\  CISS & CE & 88.60 & 82.47 \\  CISS & DR & 89.22 & 82.93 \\  UniT & DR & **91.24** & **84.32** \\  

Table 3: Comparison of certified robust accuracy (%) in the Type II scenario.

[MISSING_PAGE_FAIL:9]

**Analysis on Trade-Off Balance.** To answer Q3, we conduct the trade-off experiment in Yelp again but on UniT. Comparing Table 7 and Table 1, we can see that UniT does not suffer as much drop in certification ratio as CISS does when it adopts \(_{}\) compared to \(_{_{_{_{}}}}\), and \(_{}\) leads to the best performance. It is because UniT avoids the restriction caused by IBP. Therefore, the design of UniT for conducting certification in the embedding space can achieve a balance for the mentioned trade-off.

**Analysis on the Design of DR Loss.** For Q3, w.l.o.g., we further justify the design of the DR loss with ablation studies in IMDB in the Type I scenario. First, we illustrate the necessity of designing separate regularization terms for different modules. A straightforward choice that regularizes these two modules simultaneously is \(||g(z^{})-g(z)||\), which is referred to as the adversarial logit pairing (ALP) , and \(g()^{c}\) is the corresponding logit vector. From Table 8, if we adopt ALP that penalizes two modules together, the CRA only improves from 85.36% to 86.64%. Thus, the decoupled regularization brings optimization flexibility.

Meanwhile, from Table 8, we can see that only using \(_{fr}\) or \(_{cr}\) causes a drop of 0.96% and 3.12%, respectively, compared to the DR loss. Thus, these two terms are indispensable for modular regularization. Additionally, we also validate our design of modeling perturbation for classifier by Gaussian noise. We incorporate the negative margin calculated from \(z^{}\) with \(_{fr}\), but this regularization does not collaborate with the representational \(l_{2}\) norm and worsens the regularization effectiveness. Thus, we should use \(z+\) to model the perturbation for the classifier module to enhance its robustness.

We further justify the design of each term in the MR term. For clarity, we here denote \(t=(z+)\). For the choice of the classifier regularization, it could be the ALP term, the margin loss \((-t,0)\), or the function without \(\) operation \(-t\). Table 9 indicates that these choices all undermine the improvement brought by the representational \(l_{2}\) norm. This is because the calculation of \(||g(z^{})-g(z)||\) depends on \(||z^{}-z||\) too, and it attaches too much weight to \(||z^{}-z||\). Additionally, compared to \((-t,0)\) or \(-t\), the used \(-(t,0)\) has a selected gradient activation area for \(t>0\), so it adjusts the optimization direction when \(z\) has not been trained well yet and sends a clearer optimization guidance than the others. We also note that the improvement decreases if we change the \(l_{2}\) norm to the squared \(l_{2}\) norm. Thus, the design in Figure 3 is reasonable.

## 5 Conclusion

The development of certified robust training in text is restricted by the lack of a unified framework and modular regularization. To alleviate these problems, we propose a unified framework named UniT to strengthen the certification of prediction results for text data. Under this framework, we introduce the DR loss combining the CE loss with the modular regularization term for different modules specifically to improve the base model robustness. Experiments show that UniT allows more correctly classified samples to satisfy the certification condition by avoiding IBP. Additionally, the DR loss can generate more similar representations for perturbed samples to the original ones and reduce the drop of prediction margin. Higher certified robust accuracy is achieved consequently.