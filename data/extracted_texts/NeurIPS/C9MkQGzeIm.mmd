# ###### Abstract

###### Abstract

Machine unlearning is the process of efficiently removing the influence of a training data instance from a trained machine learning model without retraining it from scratch. A popular subclass of unlearning approaches is _exact machine unlearning_, which focuses on techniques that explicitly guarantee the removal of the influence of a data instance from a model. Exact unlearning approaches use a machine learning model in which individual components are trained on disjoint subsets of the data. During deletion, exact unlearning approaches only retrain the affected components rather than the entire model. While existing approaches reduce retraining costs, it can still be expensive for an organization to retrain a model component as it requires halting a system in production, which leads to service failure and adversely impacts customers. To address these challenges, we introduce an exact unlearning framework - Sequence-aware **S**hared **S**liced Training (S\({}^{3}\)T), which is designed to enhance the deletion capabilities of an exact unlearning system while minimizing the impact on model's performance. At the core of S\({}^{3}\)T, we utilize a lightweight parameter-efficient fine-tuning approach that enables parameter isolation by sequentially training layers with disjoint data _slices_. This enables efficient unlearning by simply deactivating the layers affected by data deletion. Furthermore, to reduce the retraining cost and improve model performance, we train the model on multiple data sequences, which allows S\({}^{3}\)T to handle an increased number of deletion requests. Both theoretically and empirically, we demonstrate that S\({}^{3}\)T attains superior deletion capabilities across a wide range of settings.

## 1 Introduction

In recent years, the growing success of machine learning (ML) has led to its widespread deployment across a range of applications (Achaim et al., 2023; Team et al., 2023; Qayyum et al., 2020; Surden, 2021). Once a machine learning model has been trained, it is often necessary to _unlearn_ specific training data instances for various reasons, like complying with user data deletion requests (Mantelero, 2013; European Parliament & Council of the European Union; Shastri et al., 2019; Achille et al., 2024), removing stale or corrupt data (Biggio et al., 2012; Steinhardt et al., 2017), etc. Retraining an ML model entirely from scratch with each deletion request is expensive, especially for modern large-scale models (Brown et al., 2020; Achiam et al., 2023; Team et al., 2023). Machine unlearning (Nguyen et al., 2022; Xu et al., 2023) techniques focus on efficiently unlearning the influence of a data instance from a trained machine learning model.

Machine unlearning techniques are classified into two broad categories: approximate and exact unlearning (Xu et al., 2024). Approximate unlearning techniques (Guo et al., 2020; Liu et al., 2024) modify the parameters of a trained model to reduce the influence of the deleted data instance. While cost-effective, approximate unlearning cannot guarantee the complete removal of an instance's influence and it may still retain non-zero influence on the model. Moreover, auditing approximate unlearning is challenging due to the stochastic nature of ML optimization (Thudi et al., 2022). An alternative approach is exact unlearning (Cao & Yang, 2015; Bourtoule et al., 2021; Golatkar et al., 2023), which can guarantee the removal of a data instance's influence from a trained model. Exact unlearning techniques use a modular system, where different components within the system are trained on disjoint data subsets. When a deletion request occurs, only the affected component needs to be retrained. However, in real-world settings, halting a production system to even retrain a single component can result in service failure. The alternative is to function without the affected component, which may result in reduced performance, ultimately impacting consumers. To address these challenges, we introduce a novel exact unlearning framework, Sequence-aware Shared Sliced Training (S\({}^{3}\)T), which enhances the deletion capability while minimizing performance impact.

The key idea behind our S\({}^{3}\)T framework is to perform additional offline training before deploying the initial model to reduce retraining costs. At the core of S\({}^{3}\)T, we leverage a novel lightweight fine-tuning approach that allows parameter isolation by sequentially training model layers using disjoint data slices. Due to this parameter isolation, we efficiently perform exact unlearning by deactivating the layers associated with the deleted instance, rather than discarding the entire checkpoint. We efficiently train multiple models using different sequences of the same data slices depending on a training budget. We show that increasing the training budget before deployment can significantly reduce retraining costs and improve the model's performance. We also observe that it is important to train the model using diverse sequences and provide several approaches for selecting diverse sequences using graph matching (Cormen et al., 2022). Furthermore, we theoretically show that S\({}^{3}\)T achieves provably better deletion guarantees than existing approaches. We conduct extensive empirical evaluations to evaluate the effectiveness of S\({}^{3}\)T using Transformers with parameter counts ranging from 86M to 13B on a range of tasks. Additionally, we empirically validate the sequence selection algorithm and show that S\({}^{3}\)T has superior deletion performance compared to existing methods.

The rest of the paper is organized as follows: **(a)** We introduce the prior literature related to approximate and exact machine unlearning (Section 2), **(b)** We describe the problem setup for exact unlearning (Section 3.1), **(c)** We introduce the fine-tuning approach, S\({}^{3}\)T, and sequence selection algorithm under budget constraints (Section 3.2 & 3.3), **(d)** We theoretically analyze several properties of S\({}^{3}\)T (Section 3.4), and **(e)** We present experiments to evaluate the effectiveness of S\({}^{3}\)T's fine-tuning approach, deletion performance and sequence selection algorithm (Section 4).

## 2 Background

Machine unlearning techniques for deep learning is broadly classified into two categories: _approximate_ and _exact_ unlearning (Xu et al., 2024). Approximate unlearning techniques focus on reducing the influence of a deleted instance from a model after it has been trained. Exact unlearning techniques provide unlearning guarantees by ensuring model components trained on a deleted instance are not used during inference. In this section, we discuss each of these categories in detail.

**Approximate Machine Unlearning**. These techniques focus on approximating the model parameters as if the deleted data instance was not there in the training set from the beginning (Guo et al., 2020). These techniques typically quantify the influence of an instance (Koh and Liang, 2017) and perform gradient ascent for unlearning (Goldatkar et al., 2020; Neel et al., 2021; Sekhari et al., 2021; Gupta et al., 2021; Suriyakumar and Wilson, 2022; Liu et al., 2024a). In contrast to these approaches, (Graves et al., 2021) stores the exact gradients encountered during training and uses them directly for gradient ascent. Another line of work (Taru et al., 2023; Tu et al., 2023; Chen and Yang, 2023; Eldan and Russionovich, 2023; Patil et al., 2023; Kurmanji et al., 2024; Liu et al., 2024b) focuses on unlearning in a batch setting, where they assume access to both a retention set and a forget set of data instances for approximate unlearning. While efficient in practice, auditing approximate unlearning techniques is challenging due to the stochastic nature of the optimization process (Thudi et al., 2022; Wang et al., 2024) and may have weak privacy guarantees in practice (Hayes et al., 2024).

**Exact Machine Unlearning**. These techniques focus on developing a modular machine learning system, where individual components are trained using disjoint subsets of the data. Such a system offers the advantage that when a deletion request is received for an input instance, we only need to retrain the affected component rather than the entire model. However, these systems require modifying the original training process of the model. The seminal work for such a modular unlearning system is Sharded, Isolated, Sliced, and Aggregated training (SISA) (Bourtoule et al., 2021). SISA uses an ensemble of models each trained on a disjoint shard of the dataset as shown in Figure 1 (left). To further reduce retraining costs, each shard is divided into slices, and the models are incrementally trained on these slices, with their checkpoints stored sequentially (shown in Figure 1 (right)). If a deletion request is received for a data instance within 4th slice of a shard, we must retrieve the checkpoint from the 3rd slice and retrain using the remaining data within that shard. Several approaches focus on improving the components within SISA in application-specific settings like enhancing the dataset partitioning mechanism (Aldaghri et al., 2021; Yan et al., 2022), the retraining efficiency using light-weight adapters (Kumar et al., 2023; Dukler et al., 2023), or extending the SISA is a well-known framework that can guarantee exact unlearning and has found widespread applications. However, using SISA within production systems is challenging because retraining even a single component would result in system downtime. Furthermore, in the worst-case scenario, if deletion requests impact the first slice in all the shards, the entire service goes down, necessitating retraining the model from scratch. In this work, we leverage parameter-efficient fine-tuning to introduce a framework that improves upon the service availability and deletion capabilities of SISA.

## 3 Sequence-aware **S**harded **S**liced Training (S\({}^{3}\)T)

In this section, we describe the functioning of our proposed exact unlearning framework, **S**equence-aware **S**harded **S**liced Training (S\({}^{3}\)T).

### Problem Setting

We consider the general setting where the user fine-tunes a pre-trained model like BERT (Devlin et al., 2019) or Llama (Touvron et al., 2023) on private data using PEFT techniques. We assume that the deletion requests affect only the private fine-tuning data, not the pre-training data. In S\({}^{3}\)T, we partition a dataset \(=\{_{1},,_{m}\}\) into \(m\) disjoint shards. Each shard is further divided into \(L\) slices: \(_{i}=\{S_{1},,S_{L}\}\). S\({}^{3}\)T trains a separate model per shard and uses their aggregate decision.

Existing unlearning frameworks SISA (Bourtoule et al., 2021) use a similar setup described above. In SISA, within each shard, the model is trained in multiple stages sequentially on the slices (training stages are Slice 1, Slice 1+2, and so on), and their checkpoints are stored. However, a key weakness of SISA is that if deletion requests affect Slice 1 of all shards, then the entire service goes down necessitating retraining from scratch. Another drawback of SISA is that individual models within the ensemble need to be retrained whenever a deletion request is executed. Retraining even on a single slice is expensive for large-scale models in production serving a huge customer base. A naive alternative would be to use the last known usable checkpoint and perform retraining after regular intervals. For example, in Figure 1 (right), if a deletion request arrives for a data instance in Slice 4, the model in production can be replaced with the checkpoint obtained after Slice 3. It is easy to see that the performance of the overall model will degrade with the number of deletion requests.

We present an exact unlearning framework, S\({}^{3}\)T, to address these challenges. The core idea involves training several copies of each model (within the ensemble) that are trained using different slice sequences. When deletion requests occur, we utilize the model that minimizes performance degradation. To further reduce the training cost, we leverage PEFT techniques and present a novel sequential slice-wise fine-tuning strategy in Section 3.2. Our training strategy allows us to use the same model by deactivating certain layers without the need to swap checkpoints in case of a deletion. In the following sections, we introduce the fine-tuning strategy and sequence selection process.

Figure 1: Schematic diagram of the Sharded, Isolated, Sliced, and Aggregated training (SISA) (Bourtoule et al., 2021) framework. An ensemble of models is individually trained on disjoint shards. (_Left_) Each shard is further divided into slices. (_Right_) Each model is sequentially trained on the slices and checkpoints are stored. After deletion, retraining resumes from the best available checkpoint.

### Sequential Slice-wise Training

In this section, we introduce **S**equence-aware **S**hared **S**liced Training (S\({}^{3}\)T) a lightweight fine-tuning approach for efficient exact unlearning. This fine-tuning approach enables parameter isolation by sequentially training PEFT layers using different data slices. Due to this parameter isolation, it is possible to efficiently handle deletion requests by deactivating layers associated with the instance.

We describe S\({}^{3}\)T using the PEFT technique, LoRA (Hu et al., 2021), but our method is general can be easily extended to other PEFT techniques. LoRA introduces a small number of trainable low-rank (\(r d\)) parameters, \((,)\), while the pre-trained weights \(}\) remains fixed as shown below:

\[=}+^{},,^{r d},} ^{d d}.\] (1)

Our key idea involves training different LoRA layers using different data slices. This approach allows us to selectively deactivate (zero out) the LoRA parameters (\(\) or \(\)) associated with a particular layer in the event of data deletion from that slice. In Figure 2 (left), we illustrate the training process in detail, where we follow a sequential top-to-bottom training approach. At stage 1, we train the final model layer (Layer 1 in the figure) using slice 1 while LoRA parameters from all other layers are switched off. In the next stage, we train second last layer (Layer 2) using slices 1 & 2, while keeping the LoRA parameters from the Layer 1 frozen. This process continues for the rest of the layers. Note that the training does not need to proceed in a single layer-wise fashion, we can even train multiple LoRA layers per slice. We discuss more details about the design choice in Appendix C.2.

The sequential slice-wise training process ensures that the LoRA parameter updates at the \(i\)-th layer are a function of the data instances within slices \(\{1,,i\}\). Therefore, if a deletion request affects the \(i\)-th slice, the same model can still be used by deactivating the LoRA parameters corresponding to slices \(\{i,,L\}\) (see details in Algorithm 4). For example, if a deletion request affects slice \(S_{3}\) only the subsequent LoRA layers need to be deactivated to ensure exact unlearning, as shown in the first example of Figure 2 (right). This is because during training the parameters of layers 1 & 2 were not affected by instances in \(S_{3}\). During this deletion process, we use the same model checkpoint and switch off LoRA layers, resulting in an \(L\)-time reduction in storage cost compared to SISA.

Now we consider the scenario where deletion requests affect multiple slices. This is shown in the \(2^{}\) sequence of Figure 2 (right), where slices \(S_{1}\) and \(S_{3}\) are affected. In this case, we observe that a model trained on the default ordering of the sequence \(\{S_{1},,S_{L}\}\) is rendered useless when \(S_{1}\) and \(S_{3}\) are affected. This motivates us to train multiple models using different permutations of the slices. This would enhance the service time and system performance by selecting a model trained with the most effective ordering (e.g., the \(3^{}\) sequence in Figure 2 (right) yields the best-performing model). However, training on all \(L!\) slice permutations is prohibitively expensive. In the following section 3.3, we present strategies to select a diverse set of permutations under budget constraints.

Figure 2: (_Left_) We show the schematic diagram of the slice-wise training strategy in S\({}^{3}\)T. We incrementally train the model \(-i^{}\) layer (from the top) using slices \(S_{1:i}\) while keeping the other layers fixed. (_Right_) We show the impact of deletion on models trained on different permutations of slices.

Using these selection approaches, in Section 3.4 we theoretically show that we do not need more than \(L\) sequences to achieve the optimal deletion performance.

### Training under Budget Constraints

In this section, we discuss strategies to select sequences under a budget, \(B\) (maximum number of sequences that can trained). First, we show that there exists an optimal subset of sequences and randomly selecting \(B\) sequences may not be effective. To illustrate this idea, we use a permutation tree (Bhattacharya, 1994), where all possible permutations are embedded into a tree structure.

In Figure 3 (left), we show an example of a permutation tree with \(L=3\) slices, paths from the root to the leaves correspond to unique permutation sequences \((S_{1},S_{2},S_{3})\), \((S_{1},S_{3},S_{2})\), and so on. We know that the topmost slice is most sensitive because if a deletion request affects the topmost slice the entire model needs to be retrained (shown in Figure 2 (right)). To address this and reduce the retraining cost, we should ensure we train models on sequences with different top slices. Building on this intuition, in the general setting we should train the model on diverse permutation sequences. Two sequences are considered _diverse if no element appears at the same position_, e.g., \((S_{1},S_{2},S_{3})\) and \((S_{2},S_{3},S_{1})\). An example is illustrated in Figure 3 (left), where a diverse set of 3 sequences is marked in green (where no identical slices occupy the same position). Selecting diverse permutations is challenging as relying solely on random sampling may not always yield the best results. Moreover, in certain scenarios, it is possible to have prior knowledge about the deletion probabilities of data slices; for example, younger users might be more likely to request data deletion than older users. Therefore, we present two strategies for selecting diverse permutation sequences for a budget \(B\), depending on whether or not prior deletion probabilities are available.

**Uniform Deletion Prior**. In the setting, where each slice has a uniform (or unknown) deletion prior, we can generate diverse sequences by using cyclic permutations of the original sequence. Given a sequence \((S_{1},S_{2},S_{3})\), the cyclic permutations are (shown in Figure 3 (middle)):

\[(S_{1},S_{2},S_{3})(S_{3},S_{1},S_{2})(S_{2},S_{3},S_{ 1}).\] (2)

Figure 4: Illustration of the BMS algorithm. BMS selects one element for each permutation at a time. This is done by constructing a bipartite graph with all feasible edges to the next node, where edge weights are the current sequence scores. We compute the maximum weight matching on this graph. The dark gray arrows (\(\)) indicate the selected edges and dotted arrows (\(\) ) the feasible ones.

Figure 3: Illustration of the slice sequence selection problem with uniform deletion prior under a budget constraint, \(B\). (_Left_) A permutation tree with \(L=3\) and a diverse set of sequences for budget \(B=3\) is shown in green. (_Center_) We show the functioning of the cyclic rotation algorithm, where we generate cyclic permutations of the original sequence. (_Right_) We iteratively extend the algorithm when budget \(B>L\) by generating cyclic rotations of the subsequences.

The above approach guarantees that no element is repeated in the same position. However, it can only generate up to \(L\) different sequences. For budget \(B>L\), we extend the cyclic rotation algorithm to generate more sequences. In Figure 3 (right), we generate new sequences by iterating over the existing sequences and performing cyclic rotations of the subsequences. For example, for \((S_{1},S_{2},S_{3})\) we perform cyclic rotation of the \(2^{}\) and \(3^{}\) element to obtain the sequence: \((S_{1},S_{3},S_{2})\) (more examples in Figure 8). We provide the general _iterative cyclic rotation_ algorithm in Appendix B.1.

**Non-uniform Deletion Prior.** In scenarios, where we have prior knowledge of the deletion probabilities, sequences generated by cyclic rotation may not be ideal. For example, consider the deletion probabilities are: (\(S_{1}\): 0.5, \(S_{2}\): 0.4, \(S_{3}\): 0.1). Then, the first sequence in Eq. 2 is a bad choice because two of the slices most likely to be deleted are placed at the top. It is possible to select better sequences while satisfying the diversity criteria (no repeated slices at the same position). We score a sequence with deletion probabilities: \(=(p_{1},,p_{L})\) by computing the expected number of functioning slices after \(t\) deletions: \([,t]=_{i=1}^{L}i.(1-_{j=1}^{i}p_{ j})^{t}\).

We present a bipartite-matching based sequence (BMS) selection algorithm. We will provide an intuitive explanation of the algorithm here and refer to Appendix B.2 for complete details. An illustration of BMS is shown in Figure 4. BMS iteratively selects elements of sequences by constructing a bipartite graph between one level to the next one (where edges are incident on feasible elements for the current sequence). The edges are weighted by the score of the current sequence, \([,t]\). Selecting the next element then is equivalent to finding a maximum weight perfect matching (Gaili, 1986) using the Hungarian algorithm (Kuhn, 1955) shown by the bold lines in Figure 4. This continues till all sequences have \(L\) elements. For a budget \(B>L\), we use conditional sampling to randomly generate sequences according to their deletion probabilities (see Appendix B.2).

### Theoretical Analysis

In this section, we theoretically analyze the performance of exact unlearning systems. For this, introduce the definition of _deletion rate_ for exact unlearning systems.

**Definition 1** (Deletion Rate).: _The deletion rate, \((S)\), of an exact unlearning system \(S\), is the expected number of deletion requests until the system needs to be retrained from scratch._

The deletion rate captures the effectiveness of an exact unlearning system by quantifying the expected number of deletion requests it can handle. Next, we quantify the deletion rate for \(^{}\)T and SISA.

**Lemma 1**.: _For dataset size \(N r\), where \(r\) is the number of deletion requests, the deletion rate of \(S^{}\) is \((S^{}T) O(mL(m(B,L)))\) and for SISA it is \(() O(mL m)\), where \(m\) is the number of shards and \(L\) is the number of slices per shard._

This result shows that the deletion rate doesn't improve by increasing the budget \(B\) beyond \(L\) (proof in Appendix A.1). This shows that the optimal deletion rate can be achieved using _only \(L\) sequences_ (instead of \(L\)!). Next, we analyze the impact of deletion requests on the system's performance. We perform a fine-grained analysis focusing on the performance of an individual shard. In this setting, we consider the real-world scenario where we do not retrain every time a slice is impacted instead work with the best available model. For \(^{}\)T, this means switching off the necessary PEFT layers, while for SISA, it means reverting to the best available checkpoint. The unlearning system experiences performance degradation with an increasing number of deletion requests, as we are compelled to utilize a model trained on fewer data slices (we show this empirically in Section 4). To quantify the performance retention we use a monotonically increasing function \(F(k)\), which indicates a model's performance when trained on \(k\) slices. The exact formulation of \(F()\) depends on several factors like the dataset, model size, etc. We analyze the performance retention while processing deletion requests.

**Lemma 2** (Performance Retention).: _Given a set of randomly selected \(B 1\) sequences and uniform deletion prior of slices, the difference between the probability that a shard retains a performance, \(F_{r}()\), of at least \(F(k)\) after \(r\) deletion requests between \(^{}\)T and SISA is shown below_

\[ k[1 L],\ |[F_{r}(S^{}T) F(k) ]-[F_{r}() F(k)]=(1- ^{B^{}-1}),\] (3)

_where \(=1-(1-k/L)^{r}\) is a positive fraction and \(B^{}=\{B,\}\)._

This above result shows that compared to SISA, \(^{}\)T enhances performance by increasing the probability that the system maintains at least \(F(k)\) by a factor of \(B^{}\) (proof in Appendix A.2).

## 4 Experiments

In this section, we outline the experimental setup and evaluate the unlearning performance of S\({}^{3}\)T across various setups. Specifically, we design experiments to answer the following research questions:

1. [label=**(RQ1)**]
2. Does S\({}^{3}\)T training (Section 3.2) impact the model's performance compared to full training?
3. Does S\({}^{3}\)T enhance the deletion capabilities of unlearning, and what is its cost tradeoff?
4. Is the sequence permutation selection algorithm (Section 3.3) effective in practice?

**Sequential Slice-wise Training Performance**. The objective of the experimental setup is to demonstrate that S\({}^{3}\)T can achieve performance comparable to full training. The goal of S\({}^{3}\)T is to achieve parameter isolation for data slices without impacting the overall performance. We perform a range of experiments with different Transformer model sizes ranging from 86M up to 13B. The details of the experimental setup are in Appendix C.1.

In Figure 5, we report the performance on vision, GLUE, and SuperGLUE benchmarks. We use ViT\({}_{}\)(Dosovitskiy et al., 2020) (for CIFAR10 & CIFAR100 (Krizhevsky et al., 2009)), ViT\({}_{}\)(for Tiny ImageNet (Le and Yang, 2015)), and RoBERT\({}_{}\)(Liu et al., 2019) (for GLUE (Wang et al., 2018) & SuperGLUE (Wang et al., 2019)). We observe that S\({}^{3}\)T achieves comparable performance to full training (FT) across all settings. In some of the settings, we also observe that S\({}^{3}\)T is able to outperform FT (e.g., S\({}^{3}\)T obtains 2.5% accuracy gain on TinyImagenet using ViT-large). Next, we conduct experiments to evaluate the effectiveness of S\({}^{3}\)T while using large language models (LLMs). Specifically, we perform instruction tuning of Llama2-7B (Touvron et al., 2023), Llama2-13B, and Llama3-8B using Alpaca dataset (Taori et al., 2023). Then, we evaluate each instruction-tuned model on a range of tasks to evaluate the model's general/world knowledge (MMLU (Hendrycks et al., 2020), OpenBookQA (Mihaylov et al., 2018)), truthfulness in QA (TruthfulQA (Lin et al., 2022)), and commonsense reasoning (PIQA (Bisk et al., 2020), HellaSwag (Zellers et al., 2019), Winogrande (Sakaguchi et al., 2021), ARC (Clark et al., 2018)). We use LLM-evaluation suite (Gao et al., 2023) to report the performance and report the zero-shot performance for all datasets. Similar to the previous setup, in Table 3, we observe that S\({}^{3}\)T achieves comparable performance to full finetuning across all datasets and even outperforms FT on many datasets across different model sizes. These experiments provide the answer to (**RQ1**) demonstrating that S\({}^{3}\)T is an effective way to achieve parameter isolation for data slices without impacting the model's performance.

**Deletion Performance**. In this section, we evaluate the performance of S\({}^{3}\)T as deletion requests are received. In Figure 6 (left), we report the performance of S\({}^{3}\)T and baselines SISA (Bourtoule et al., 2021) and ProtoSISA (Yan et al., 2022) (\(m=5\) shards, \(L=4\) slices) on CIFAR-10 and CIFAR-100 datasets. In this experiment, we use a uniform deletion prior over slices. We also report the performance of full re-training, which retrains the model after each deletion request and serves as an upper performance bound. We report S\({}^{3}\)T's performance under various budgets. We observe that S\({}^{3}\)T can achieve very close performance to the full budget (\(B=24\)) with a significantly smaller budget, \(B=4\). For SISA and ProtoSISA, we observe that the plot ends after approximately 40 deletion requests as these systems do not have functioning models beyond this point. We observe that S\({}^{3}\)T can handle more deletion requests while consistently outperforming the baseline approaches. Note that increasing the budget \(B>L\) does not help improve the deletion rate but increases the probability of a better-performing model (as observed in Lemma 1). Next, we extensively evaluate the impact of increasing the training budget \(B\) on the deletion rate (with \(m=5\) shards & \(L=64\) slices). In Figure 6 (right), we observe that there is a steady growth in the deletion rate with an increasing

Figure 5: Comparison of the performance between S\({}^{3}\)T training and full training (FT) on vision, GLUE & SuperGLUE benchmarks. We report the Matthewâ€™s correlation for CoLA, Pearson correlation for STS-B, and accuracy for other tasks. We observe that S\({}^{3}\)T achieves similar performance to FT.

budget. The growth is slightly higher in the initial stages when the budget is low and slows down gradually. This experiment provides empirical evidence to our theoretical result in Lemma 2, which claims that the performance improves with an increased budget.

**Sequence Selection**. We evaluate the quality of the sequences generated by the iterative cyclic rotation and BMS algorithm (Section 3.3). Ideally, we want the selected sequences to be diverse and have a high edit distance between sequences. Therefore, we report the average edit distance within a selected subset, \(O\): \(_{o O}[d_{}(o,o^{})]\). First, when the deletion prior is uniform and compare cyclic rotation with random sampling. In Figure 7 (left), we report the average edit distance with varying budget (\(B\)) while the slice count (\(L\)) is fixed. We observe that cyclic rotation produce significantly better sequences than random sampling. Second, we consider slices associated with a deletion prior. We present the results by averaging over 10 deletion priors sampled from a Dirichlet distribution. In Figure 7 (center & right), we observe that BMS consistently outperforms random sampling both in terms of diversity (avg. edit distance) and chosen sequence scores (\([,t]\)).

## 5 Conclusion

In this paper, we introduced S\({}^{3}\)T, an effective framework for performing exact unlearning. S\({}^{3}\)T uses a modular machine learning model that is trained using disjoint shards of the data. Each shard is used to train a different model using a lightweight fine-tuning approach that enables parameter isolation, which allows us to execute unlearning requests efficiently. The key idea behind S\({}^{3}\)T is to train multiple models using different sequences of slices before deploying the system. This helps reduce retraining costs and improve the model's performance while the model is in production. Both theoretically and empirically, we show that S\({}^{3}\)T has significantly improved deletion capabilities compared to existing approaches. Future work can focus on developing techniques for finer-grained parameter isolation to further improve S\({}^{3}\)T's performance.

Figure 6: (_Left_) We report the impact on performance of S\({}^{3}\)T and baselines with an increasing number of deletion requests. S\({}^{3}\)T handles a higher number of deletion requests while maintaining high performance with a relatively low budget (\(\) indicates the failure point for the system). (_Right_) We report the deletion rate of S\({}^{3}\)T with an increasing budget and observe steady growth.

Figure 7: We evaluate the performance of iterative cyclic rotation and bipartite matching-based selection (BMS). (_Left_) We observe that cyclic rotation selection consistently outperforms random sampling for all budgets, \(1 B 120\) (with fixed \(L=5\)). (_Center_) We evaluate the average edit distance of the sequences generated by BMS and observe that it achieves the optimal edit distance (\(L\)). (_Right_) We also observe that sequences from BMS achieves higher scores than random sampling.