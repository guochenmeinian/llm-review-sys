# Learning to Solve Quadratic Unconstrained Binary Optimization in a Classification Way

Ming Chen\({}^{1}\)

These authors contributed equally.

Jie Chun \({}^{1}\)

These authors contributed equally.

Shang Xiang \({}^{2}\)

Luona Wei\({}^{3}\)

Yonghao Du\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

Correspondence

College of Systems Engineering, National University of Defense Technology

Yingwu Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

School of Public Administration, Xiangtan University

College of Electronics and Information Engineering, South-Central Minzu University

Qian Wan\({}^{4}\)

National Engineering Research Center of Educational Big Data,

Central China Normal University

{cmself, chunjie0720, xiangshang165, wlhelysion, duyonghao15, wanq8228}@163.com, cynnudt@hotmail.com, cywnudt@163.com

Jie Chun\({}^{1}\)

Correspondence

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

School of Public Administration, Xiangtan University

College of Electronics and Information Engineering, South-Central Minzu University

Qian Wan\({}^{4}\)

National Engineering Research Center of Educational Big Data,

Central China Normal University

{cmself, chunjie0720, xiangshang165, wlhelysion, duyonghao15, wanq8228}@163.com, cynnudt@hotmail.com, cywnudt@163.com

Jie Chun\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

School of Public Administration, Xiangtan University

College of Electronics and Information Engineering, South-Central Minzu University

Qian Wan\({}^{4}\)

National Engineering Research Center of Educational Big Data,

Central China Normal University

{cmself, chunjie0720, xiangshang165, wlhelysion, duyonghao15, wanq8228}@163.com, cynnudt@hotmail.com, cywnudt@163.com

Jie Chun\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{4}\)

Yuning Chen\({}^{1}\)

College of Systems Engineering, National University of Defense Technology

Qian Wan\({}^{2}\)

School of Public Administration, Xiangtan University

College of Electronics and Information Engineering, South-Central Minzu University

Qian Wan\({}^{4}\)

National Engineering Research Center of Educational Big Data,

Central China Normal University

{cmself, chunjie0720, xiangshang165, wlhelysion, duyonghao15, wanq8228}@163.com, cynnudt@hotmail.com, cywnudt@163.com

###### Abstract

The quadratic unconstrained binary optimization (QUBO) is a well-known NP-hard problem that takes an \(n n\) matrix \(Q\) as input and decides an \(n\)-dimensional 0-1 vector \(x\), to optimize a quadratic function. Existing learning-based models that always formulate the solution process as sequential decisions suffer from high computational overload. To overcome this issue, we propose a neural solver called the Value Classification Model (VCM) that formulates the solution process from a classification perspective. It applies a Depth Value Network (DVN) based on graph convolution that exploits the symmetry property in \(Q\) to auto-grasp value features. These features are then fed into a Value Classification Network (VCN) which directly generates classification solutions. Trained by a highly efficient model-tailored Greedy-guided Self Trainer (GST) which does not require any priori optimal labels, VCM significantly outperforms competitors in both computational efficiency and solution quality with a remarkable generalization ability. It can achieve near-optimal solutions in milliseconds with an average optimality gap of just 0.362% on benchmarks with up to 2500 variables. Notably, a VCM trained at a specific DVN depth can steadily find better solutions by simply extending the testing depth, which narrows the gap to 0.034% on benchmarks. To our knowledge, this is the first learning-based model to reach such a performance.

## 1 Introduction

Nonlinear integer programming is a highly challenging subject in mathematical programming and operations research, where the Quadratic Unconstrained Binary Optimization (QUBO) problem is one of the most well-known cases. Due to its extensive applicability and computational intricacies, the QUBO continues to receive widespread attention. The purpose of the QUBO problem is to optimize an unconstrained quadratic function:

\[/ OFV=f(x)=x^{}Qx=_{i=1}^{n}_{j=1}^{n}q_{ij}x_{i}x_{j}\] (1)

where \(Q\) is a symmetric matrix with \(n n\) coefficients, while \(x\) is a binary (0-1) \(n\)-dimensional column vector, i.e., \(x_{i}\{0,1\},i=1,...,n\). \(OFV\) is short for objective function value.

This simple formulation is able to represent a remarkable spectrum of applications in Combinatorial Optimization (CO), including those from quantum computing , asset exchange problem , financial analysis , transaction settlement , set packing problem , linear ordering problem , etc. A large number of classic graph problems and constrained quadratic problems can be re-casted into QUBO through simple transformations [7; 8; 9; 10], for which QUBO solving methods can be easily applied. From a computational perspective, the QUBO problem belongs to the NP-hard family. Typical solving methods for the QUBO include exact methods and heuristic methods. Due to its NP-hardness, the QUBO is not expected to be solved by any exact method in polynomial time. For this reason, intensive research has been devoted to developing heuristic methods.

In recent years, the research on learning-based Neural CO (NCO) methods for solving CO problems has become a hot topic in this field [11; 12]. This type of data-driven method has strong scalability and high efficiency for problems of different types and scales, as opposed to traditional search-based metaheuristics which often require substantial computational effort when problem size is large. These works typically model the solution of CO problems as a Markov Decision Process (MDP) , and then use deep reinforcement learning (DRL) to train an advanced policy network, Pointer Network (PN)  and Graph Neural Network (GNN)-based  models for instance, to support dynamic decision-making at each MDP step. Despite the remarkable performance of these models in addressing certain classical CO problems such as the Vehicle Routing Problem (VRP) , their applications to QUBO encounter significant limitations:

**1) PN-based DRL models.** PN-based models require problem data represented by a \(n C\) matrix to satisfy its fixed \(C\) embedding channels, where \(n\) is the number of tasks and \(C\) is a fixed number of features per task. For instance, the Travelling Salesman Problem (TSP) can be represented by \(n\) nodes and their coordinates (each node described by an (\(x,y\)) pair), forming an \(n 2\) matrix. Due to such a requirement, PN-based models encounter difficulties in processing \(n n\)-dimensional input matrix of the QUBO directly since it is not able to handle problem data where both dimensions are variable, resulting in weak scalability of the model for problems of different scales.

**2) GNN-based DRL models.** Conversely, GNN-based models  excel at encoding \(n n\) graph data by graph embeddings. Despite this advantage, GNNs incur significant computational and storage costs due to the repeated updating of node and edge hidden states at each MDP step, particularly for large problem sizes. For instance, the GNN in  requires an \(n n h\)-dimensional hidden matrices to store edge encodings, which is \(n\) times the storage of the PN needed at the same hidden size \(h\). Our preliminary tests revealed that the machine we used for this work could not handle the storage demands of GNNs for large-scale instances (see the results of P7000 in Table 1). Additionally,  reported that GNNs are not able to compete with greedy heuristics in certain graph combinatorial optimization problems, aligning with our QUBO experimental results.

The limitations encountered by these networks in solving QUBO are closely related to the MDP-solving paradigm attached to them. When addressing QUBO via an MDP, each step involves flipping the assigned value of a selected binary variable (see the top of Figure 1). According to , it is critical to evaluate the impact of each flip on the \(OFV\) to ensure the high quality of the resulting solution. However, the repeated \(OFV\) evaluation throughout the MDP leads to significant computational overhead, which may be unacceptable for large-scale instances.

**Contributions.** Given the above limitations, a radical improvement would require revolutionizing the solution paradigm to compensate for the limitations of DRL models by not using MDP and avoiding repeated \(OFV\) computations. Considering the binary nature of QUBO variables, a novel solution paradigm based on classification is proposed, which can provide the binary values of all variables directly at once, rather than following sequential decision-making to determine values one by one.

To operationalize the concept of this innovative QUBO classification solution paradigm, we propose a Value Classification Model (VCM)3, which is a neural solver comprised of three key components: an Extractor, the Depth Value Network (DVN), for feature extraction; a Classifier, the Value Classification Network (VCN), for solution determination; and a Trainer, the Greedy-guided Self Trainer (GST), for solver training. Based on graph convolutional, DVN exploits the symmetry property of input data of QUBO to efficiently extract the value features, with performance steadily improving as depth increases. These resulting value features of each variable enable VCN to directly generate the solutions in a classification way. For effective model training, we propose the GST, which does not need any prior optimal labels. Extensive experiments demonstrate the effectiveness of the proposed VCM and GST. A well-trained VCM can directly generate near-optimal solutions for QUBO within milliseconds and exhibit remarkable generalization capabilities across both instance sizes and data distributions. For example, a VCM trained on instances of size 10 can produce near-optimal results for instances of size 7,000 in milliseconds. Furthermore, simply by increasing the testing DVN depth, a VCM trained at a specific depth can attain even better solutions. To our knowledge, this represents the first learning-based classification model for solving QUBO with such a performance.

## 2 Related Works

The literature on QUBO dates back to , which introduced pseudo-boolean functions and binary quadratic optimization. Due to the combinatorial complexity, QUBO has been proven NP-hard in 1979 . Over the decades, a large number of methods for solving QUBO have emerged in the literature. The research on exact methods primarily employed branch-and-bound [21; 22; 23; 24; 25] or branch-and-cut . Since the exact methods are prohibitively expensive when applied to large-size instances, various heuristic methods have extensively emerged, which are designed for high-quality solution discovery within acceptable timeframes. Noteworthy ones include Tabu Search (TS) [26; 27; 28], Simulated Annealing (SA) , Local Search (LS) , Ant Colony Optimization (ACO) , Memetic Algorithm (MA)  and hybrid algorithms .

Recently, learning-based neural CO methods have exhibited significant promise in addressing CO challenges. Successful applications include 3-D Bin Packing Problem , Maximum Cut [15; 35], Routing Problems [14; 36; 37; 38; 39; 16; 40; 41], etc. Unlike traditional search-based methods, these approaches aim to autonomously acquire solution policies from a significant amount of problem data. Nevertheless, the integration of these learning-based heuristics into QUBO-specific applications is still in its infancy, with only a handful of studies exploring this direction and they all adopted the solving paradigm based on MDP. Based on PN,  designed hand-crafted features, such as row sum, diagonal elements, and \(OFV\) values. These feature values can only reflect a small number of characteristics of the problem data, making it difficult to characterize the overall picture of the problem, leading to unsatisfactory results. In addition, since this method models the problem solution process as an MDP, it requires repeated calculation of \(OFV\) values, resulting in low solving efficiency.

## 3 The Neural Solver VCM

**General scheme.** The general scheme of our proposed Value Classification Model (VCM) is outlined in Figure 1 at the bottom, with the detailed neural architecture provided in Appendix A. The neural solver VCM comprises three key components: an Extractor, the Depth Value Network (DVN), for feature extraction; a Classifier, the Value Classification Network (VCN), for solution determination; and a Trainer, the Greedy-guided Self Trainer (GST), for solver training.

**The Extractor DVN.** The Extractor is responsible for automatically grasping variables and their correlation features from \(Q\) matrix to support the Classifier. The efficacy of the Extractor essentially determines the performance of the VCM. We notice that the \(Q\) matrix is graph-like data. It is known that the Graph Convolutional Network (GCN)  is a robust technique for graph representation, which learns hidden layer representations that encode both local graph structure and features of nodes. The extraction of the \(l\)-th layer is summarized as \(H^{(l+1)}=(^{-1/2}(A+I_{N})^{-1/2}H^{(l)}W^{(l)})\). Here, \(A\), \(I_{N}\), and \(\) are the adjacency matrix, identity matrix, and the degree matrix of the undirected graph \(\). \(W^{(l)}\) is a layer-specific trainable weight matrix, and \(H^{(l)}\) is the matrix of activations in the \(l\)-th layer. The core operation in graph convolution is \(AH\). In QUBO, the \(A\) is instantiated as \(Q\), while \(H\) is the set of extracted features of the variable vector \(x\).

However, directly using GCN as the Extractor for QUBO poses several insurmountable challenges. First, transforming QUBO into a graph typically results in a fully connected \(Q\) matrix, leading to \(n^{2}\) real-valued edges, with each edge \(q_{ij}\) directly affecting the \(OFV\) of the problem. It is essential to manage the extraction of large-scale edges and discern their distinctions. As stated in , the graph convolution in GCNs is a special form of Laplacian smoothing, a key factor for their effectiveness. This smoothing could diminish the influence of high-weight edges, which is not required in QUBO since their original weight differences are essential for the model to accurately identify their impact on the objective function. Also, GCN performance significantly degrades when its depth exceedstwo layers , even when employing residual connections. This is because when a GCN contains numerous convolutional layers, the resulting output features may become excessively smoothed, making it difficult to differentiate vertices from various clusters. To address these issues and based on the principles of graph convolution, we propose a QUBO-tailored Depth Value Network (DVN).

In QUBO, each variable \(x_{j}\) directly affects the elements of the corresponding \(j\)-th row and column in \(Q\). Given that \(Q\) is symmetric, i.e., \(Q=Q^{T}\), the features associated with each row should be unified with those of the corresponding column. We first define the features of each variable \(x_{j}\) to be extracted as a value feature, accompanied by a value feature vector \(_{j}^{h}\), where \(h\) denotes the hidden size. Let \(_{j}\) be the value features of the \(j\)-th column of \(Q\) (denoted as \(_{j}^{col}\)). Each element in row \(j\) can then be expressed as \(q_{ij}_{j}^{col}\). Consequently, the value features for the \(i\)-th row can be computed as \(_{i}^{row}=_{j=1}^{n}(q_{ij}_{j}^{col})\). To ensure unified row and column features, the value of each column, \(_{i}^{col}\), should match the value of its corresponding row, \(_{i}^{row}\). This requirement translates to unifying \(\) and \(Q\), where the computation of \(Q\) mirrors the core operation of GCN. This alignment may be an additional reason why GCN exhibits effective performance.

In DVN, we take the \(Q\) and current \(\) as inputs and employ a learning function \(_{E}\) to iterate the value feature. The iteration at depth \(d\) is updated as follows:

\[^{(d+1)}=_{E}(^{(d)},Q^{(d)})\] (2)

Here, \(=\{_{i}\}_{i=1}^{N}\) is the value feature matrix for all variables \(x\) (i.e., the nodes in the graph). Each \(_{i}^{h 1}\) is the value feature vector for \(x_{i}\) with all initial values set to 1. \(_{E}\) consists of specific neural networks and activation functions tailored for pattern recognition and features processing. Specifically, it obtains the new value features \(^{(d),D}\) based on the current and \(Q\) convolution value features as follows:

\[^{(d),D}=_{3}[^{(d)};(_{2}((_{1 }Q^{(d)})))]\] (3)

Where \(_{1},_{2}^{h h}\) are learnable memory units that capture specific feature interactions. ReLU and tanh are the activation functions used to filter the extracted features and compress the value features within a limited threshold, respectively. [;] is the horizontal concatenation operator and \(_{3}^{h 2h}\) is a learnable memory unit that connects the current and convolution value features. Finally, \(^{(d+1)}\) is then obtained as follows.

\[^{(d+1)}=(^{(d),D})\] (4)

The output value of tanh, within a symmetric range of \([-1,1]\), can effectively represent the features of distinct variables. An ablation study on activation functions and memory units demonstrates the

Figure 1: The processes of DRL-based policy models and our QUBO solver. Both PN and GNN-based DRL policy models construct solutions sequentially by capturing environmental embeddings at each step to support decision-making. In contrast, our neural solver VCM outputs solutions directly in a classification way, without any additional decision steps.

effectiveness of our neural architecture design (see Appendix E). These filtering and compression processes allow DVN to iteratively extract features from Q at any depth, which effectively avoids the problem of decreased performance caused by the convolutional layer increase of GCN. Additionally, during data initialization, we scale the data by \( Q\) to enhance the efficiency of value compression (see Appendix A), where \(\) represents the scaling factor with a specific value. Experimental results verify that the performance of our solver steadily improves when the iteration depth of the DVN increases. Notably, without incurring additional training costs, our solver can find better solutions simply by extending the iteration depth (see Section 4.3).

**The Classifier VCN.** Based on the obtained value features \(^{(d),D}\), we propose a Value Classification Network (VCN) which serves as the classifier to generate the solution \(x\) for the QUBO.

\[x=_{C}(^{(d),D})\] (5)

Where \(_{C}\) is a learning function that maps the value feature of each variable into a binary value. To this end, we calculate the state of each \(x_{i}\) and use the activation function \(\) to obtain the state of each \(x_{i}\). The classification result is then determined based on the state of \(x_{i}\).

\[\{state_{i}\}_{i=1}^{n}=((_{4}^{(d),D}))\] (6)

\[x_{i}=\{1,&state_{i}>0\\ 0,&state_{i} 0.\] (7)

Where \(_{4}^{h h}\) is a learnable memory unit and \(^{1 h}\) is the learnable uniform vector to integrate the value features of each variable. VCN can produce a complete solution directly by simultaneously considering all variables through a single classification action. Compared to other DRL policy models that rely on sequential decisions, our solver can significantly reduce the computational complexity from \(O(kn^{2})\) (where the sequence length \(k\) can potentially expand to \(2^{n}\) when the flip of all variables is enumerated) to \(O(n^{2})\).

**The Trainer GST.** It is known that the classification model usually requires labeled solutions for training. Unfortunately, in the case of QUBO, acquiring optimal solutions is rather expensive and may be infeasible for large-size problems. For this reason, we propose a Greedy-guided Self Trainer (GST), which effectively avoids the need for pre-labeled optimal solutions. The GST is outlined in Algorithm 1 and its working logic is shown in Figure 2, which consists of three components: a VCM, a Batch Greedy Flip (BGF) algorithm, and a historical best solution set (HB) \(X^{L}\), where the BGF and HB are two featured ingredients of the GST.

The Greedy Flip algorithm employs a flip operation to change the assignment for each variable \(x_{i}\) between 0 and 1 (detailed in Appendix B.1). At each step, the algorithm first calculates the Objective Function Value Increment (OFI) for each variable, which quantifies the change of \(OFV\) resulting from flipping \(x_{i}\) (detailed in Appendix B.2). The flip operation with the highest positive OFI is selected. The above process continues until all variables are processed. However, computing the OFI at each step is computationally expensive, making it impractical for batch training.

To overcome this computational bottleneck, we propose a batch OFI calculation technique (detailed in Appendix B) that leverages matrix computation acceleration to significantly enhance efficiency. Based on this, we develop a Batch Greedy Flip (BGF) method (detailed in Appendix C), a GPU-accelerated heuristic that improves on the VCM (termed VCM-BGF) by identifying and correcting obvious sub-optimal classification in the current VCM solution.

Figure 2: Working logic of the GST.

Finally, we introduce a historical best solution set \(X^{L}\). During the multi-epoch training process, the training dataset is fixed, ensuring that each instance is used once in each training epoch. This allows us to use the VCM-BGF solution \(X^{G}\) at each epoch to maintain and update the historical best solution set \(X^{L}\). The updated historical best solutions serve as the training labels for our neural solver. This VCM-based, data-driven label-generating process yields adaptive, high-quality labels at low cost. The Binary Cross Entropy (BCE) is applied to calculate the training loss, with the optimization handled by the well-known Adam optimizer .

## 4 Experiments

### Experimental Details

**Datasets.** The datasets used in our experiments include generated instances (G), benchmarks (B), and well-known instances (P), described in the format: dataset+instance size+(number of instances). For the G set, the \(Q\) matrix is uniformly generated at random within [-100,100], following the benchmark data format. The B set is B2500(10) consisting of ten ORLIB instances of size 2500 . The P set includes 21 very-large instances  including P3000(5), P4000(5), P5000(5), P6000(3), and P7000(3). The average \(OFV\) gap to the current optimal baseline (GAP in %) and the average running time (ART in milliseconds for default, ms) are used as the evaluation indicators.

**Parameter setting.** Following the Parameters Study (see Appendix F), the default values for VCM parameters are set as \(h=128\), \(=4\), and \(d=40\). VCM is trained for 100 epochs under four sets of small-size instances (with 10, 20, 50, and 100 variables) with a batch size of 512, resulting in 400 VCMs. Each set includes 512,000 G instances (limited by memory). For fair validation, the test batch size is fixed at 1. Each model is initialized with Xavier initialization , and the Adam optimizer is applied with a \(10^{-4}\) learning rate and 0.975 decay factor. Experiments were run on an NVIDIA GeForce RTX 3090 and an Intel i9-9900K CPU with 64GB RAM and Ubuntu 18.04 using Pytorch 1.90 in a Python 3.7 environment.

**Competitors.** Our evaluation includes several types of competitors: 1) The exact optimizer Gurobi . We set the max allowed time to 1s and 1h. 2) Heuristic classification methods, Diag and SR, proposed in . 3) Heuristic construction algorithm BGF, part of GST. 4) The physics-inspired neural solver, PI-GNN , with varying numbers of layers. 5) Three learning-based sequential-decision construction models: one PN-based model called DRLH  (which is the state-of-the-art), two GNN-based models called S2V-DQN  and ECO-DQN  (which are the most relevant state-of-the-art models for solving optimization problems over graphs). These models use the same parameter setting as VCM and are accelerated by our batch OFI calculation technique, resulting in competitors DRLH-B, S2V-DQN-B, and ECO-DQN-B. To assess the stability of VCM, we also include its enhanced version VCM-BGF as a competitor. In addition, for each instance of the datasets, we obtain a high-quality reference solution using an integrated model (called VCM-BGF-HB)composed of 400 trained VCM-BGFs under depth \(d=100\). VCM-BGF-HB is deemed a high-quality baseline since it is able to achieve an average 0.012% deviation from benchmark optimality (see Table 1).

### Experimental Results

We use the B set and P set to validate the performance of the trained VCMs. The results in Table 1 show that PN-based DRLH-B requires seconds to obtain suboptimal solutions. In terms of solution quality, DRLH-B is outperformed by the ECO-DQN-B, yet it incurs substantial time increases and computational costs due to graph embedding, resulting in an insurmountable GPU memory limitation to preclude their execution on P7000. Among the learning-based competitors, the 2-layer PI-GNN demonstrates the best performance in terms of solution quality. Interestingly, our proposed BGF easily outperforms these learning-based models in both solution quality and speed. Yet it is still dominated by the VCM which is the best solver. Indeed, it surpasses all competitors across the whole instance set in both quality and computational efficiency with the highest Wilcoxon P-value of 3.09E-03 (see Appendix D). Taking VCM50 as an example, it can achieve near-optimal solutions with an average gap of only 0.362% within 8ms for benchmarks. Such a solution speed is rather impressive. The results of the very large instances from the P set show that our proposed VCM maintains near-optimal performance. Particularly, the VCM trained on instances with 10 variables achieves an average gap of 0.569% on P7000, displaying significant generalization ability. The results of the VCM-BGF-HB and Gurobi are also presented as a reference to the VCM. They produce optimal or near-optimal solutions. However, Gurobi can only solve problems in a sequential way and incurs substantial time cost (over 1h for each G100 instance in Appendix G).

To further investigate the generalization ability of the VCM, we conduct experiments on an additional 1,000 generated G instances with 20, 50, 100, 200, 500, and 1,000 variables. We use VCM-BGF-HB as the optimal baseline. The results, illustrated in Figure 3 and detailed in Appendix G, demonstrate that a VCM trained at a specific size performs well on instances of other sizes. For example, the gap between VCM10 and VCM100 on G100 instances is merely 0.056%, demonstrating the remarkable generalization ability of VCM. The results also show that BGF can further enhance the performance of the VCM, with a solution quality improvement of 0.27% on average. Meanwhile, this improvement afforded by BGF is limited, reflecting the inherent stability of VCM.

In comparison to MDP-based methods, VCM replaces this complex sequential decision-making process with a simple classification process, providing an inherent advantage in solving efficiency that becomes more pronounced as the instance size increases. Notably, the VCM achieves this performance without using OFI (which is essential in sequential decision-based methods), thereby

    & B2500(10) & P300(5) & P4000(5) & P5000(5) & P6000(3) & P7000(3) \\   &  \\  Algorithm & 1479921.4 & 5134727.2 & 7869134.2 & 10973791.4 & 13950582.0 & 17725010.33 \\   & GAP (\%) & ART (ms) & GAP (\%) & ART (ms) & GAP (\%) & ART (ms) & GAP (\%) & ART (ms) & GAP (\%) & ART (ms) \\  Diag & 81.842 & 0.7 & 99.262 & 1.7 & 97.374 & 2.9 & 98.256 & 4.4 & 99.273 & 11.1 & 98.843 & 14.3 \\ SR & 26.867 & 0.1 & 32.861 & 0.0 & 33.510 & 0.1 & 33.428 & 0.2 & 33.679 & 0.0 & 32.758 & 0.4 \\ VCM10 & 3.068 & 7.8 & **0.566** & 7.9 & **0.40** & 8.1 & **0.698** & 8.5 & **0.645** & 8.8 & **0.569** & 9.1 \\ VCM20 & 0.488 & 7.7 & 0.598 & 7.9 & 0.673 & 8.1 & 0.657 & 8.3 & 0.712 & 8.6 & 0.646 & 9.1 \\ VCM50 & **0.962** & 7.7 & 0.861 & 7.9 & 0.669 & 8.1 & 0.738 & 8.1 & 0.806 & 8.7 & 0.702 & 9.1 \\ VCM100 & 0.401 & 7.8 & 0.763 & 7.9 & 0.668 & 8.0 & 0.803 & 8.0 & 0.914 & 8.7 & 0.772 & 9.1 \\  BGF & 0.807 & 800.8 & 0.979 & 99.844 & 0.834 & 999.4 & 0.914 & 994.7 & 0.966 & 99.9 & 0.730 & 983.6 \\ DRLH-B & 1.640 & 1.56-e03 & 2.044 & 2.463 & 1.884 & 5.069-e03 & 1.853 & 8.986 & 2.030 & 1.554-e04 & 1.825 & 2.284+04 \\ S2V-DQ-B & 21.657 & 1.66\(-\)e04 & 13.172 & 2.726-e04 & 13.255 & 8.66 -e04 & 1.450 & 1.26-e05 & 1.440 & 2.16-e05 & - & - \\ ECO-DQN-B & 0.937 & 2.85e+04 & 1.371 & 5.464 & 1.333 & 2.26-e05 & 1.270 & 2.345-e05 & 1.467 & 4.08-e05 & - & - \\ VCM10-BGF & 0.230 & 40.8 & 0.382 & 0.26 & 0.297 & 107.4 & 0.322 & 196.3 & 0.374 & 44.44 & 0.335 & 613.6 \\ VCM20-BGF-BGF & 0.227 & 52.3 & 0.260 & 87.8 & 0.342 & 135.83 & 0.310 & 282.6 & 0.316 & 506.8 & 0.312 & 634.7 \\ VCM50-BGF & **0.136** & 44.1 & 0.277 & 100.2 & 0.214 & 170.0 & 0.262 & 376.20 & **0.267** & 523.3 & 0.224 & 770.2 \\ VCM100-BGF & 0.139 & 49.2 & **0.203** & 106.0 & **0.178** & 186.7 & **0.245** & 298.2 & 0.271 & 549.7 & **0.212** & 770.4 \\  PI-GNN(2-Layer) & 1.689 & 4.42+04 & 2.13 & 6.2E+04 & 1.636 & 7.1E+04 & 1.418 & 8.6E+04 & 1.986 & 1.1E+05 & 1.437 & 1.6E+05 \\ PI-GNN(2-Layer) & 1.909 & 5.75e+04 & 2.523 & 7.2E+04 & 2.092 & 8.6E+04 & 1.945 & 1.0E+05 & 2.18 & 1.32E+05 & 2.076 & 1.9E+05 \\ PI-GNN(2-Layer) & 2.58 & 1.2E+05 & 3.947 & 1.6E+05 & 2.761 & 1.1E+05 & 2.463 & 1.3E+05 & 2.548 & 1.8E+05 & 2.289 & 2.72E+05 \\ GRUROBI-15 & 0.044 & 1.0E+03 & 0.070 & 0.683 & 0.108 & 1.0E+05 & 0.091 & 1.0E+05 & 0.122 & 1.0E+05 & 0.143 & 1.0E+03 \\ GRUROBI-11 & **0.0023** & 3.6E+06 & **0.0023** & 3.6E+06 & **0.0199** & 1.6E+06 & **0.0096** & 3.6E+06 & **0.0144** & 3.6E+06 & **0.0190** & 3.6E+06 \\ VCM-BGF-HB & 0.012 & 1.9E+04 & 0.020 & 3.6E+04 & 0.027 & 6.0E+04 & 0.040 & 1.1E+05 & 0.030 & 2.0E+05 & 0.057 & 2.8E+05 \\   

* The **Bold** indicates the best average result in different classes of methods.
* 1
* The **Bold** indicates the best average result in different classes of methods.
* 2
* 3
* The **Bold** indicates the best average result in different classes of methods.
* 4considerably reducing computational overhead. The computing time is thousands of times less on average. Also, the computing time increases moderately as the problem size enlarges (see Figure 4). Across the whole datasets (with variables ranging from 20 to 7000), the computing time is always under 10ms. In contrast, other sequential-decision competitors, especially GNN-based models, exhibit excessive time growth as the problem size grows, since the number of decision-making steps increases significantly.

### Model Study

**Efficiency of GST.** We introduce three training competitors, UnS , LHB, and LGF, to validate our Trainer GST. The UnS is an unsupervised training method that directly uses the optimization objective function as the loss function and relaxes the 0-1 variables for optimization. The labels for LHB are obtained by VCM-BGF-HB. The LHB can be considered supervised learning with optimal labels. The labels for LGF are obtained using the current VCM-BGF, which is GST without the historical best solution set. We adopt VCM-BGF-HB as the optimal baseline and illustrate the training curves in Figure 5. The results indicate that GST outperforms competitors in terms of both efficiency and stability. Specifically, GST demonstrates a more efficient and stable training process compared to the unsupervised trainer UnS, which suffers from considerable fluctuations. GST achieves the same performance as the supervised LHB in the early stages of the training process while requiring at least 50% fewer epochs. Although LGF can reach local optimum from time to time, its training process experiences fluctuations due to the unstable quality of the labels outputted by VCM-BGF alone. Therefore, the integration of BGF and historical solutions within GST enables a rapid, stable, and adaptive formation of VCM, and circumvents the substantial costs associated with supervised learning.

**Distribution Generalization of VCM.** The G set, whose default distribution is denoted as R-1, with all elements of the matrix non-zero. To assess the generalization ability of VCM across diverse data distributions, we generate new datasets by following a standard normal random distribution (RN-1) and deactivating the matrix elements to 0 with probabilities of 10% (R-0.9), 40% (R-0.6), 70% (R-0.3), and 90% (R-0.1). We conduct tests on these instances of diverse distributions with 20, 50, and 100 variables using our trained corresponding-sized VCMs. For each distribution, we generate 1,000 G instances and apply VCM-BGF-HB as the optimal baseline to measure the gap. The results (summarized in Figure 6 and detailed in Appendix H) demonstrate that VCM maintains

Figure 4: Average running time of different datasets in seconds and milliseconds.

Figure 3: The size generalization ability of VCM and VCM-BGF under different datasets.

near-optimal across various data distributions. The VCM performance on the R-0.1 instance set with 100 variables, where 90% Q matrix elements are zero, manages to sustain a performance gap no larger than 0.15%. Besides, since the MaxCut problem can be re-casted into UQBO, with the difference in the data distribution, we extend our evaluation to MaxCut benchmarks to validate our findings. Results detailed in Appendix I further confirm the practical applicability of VCM. These observations imply that the Extractor in VCM can be considered a generic module with distribution-independent and problem-specific in QUBO, thereby bringing VCM a remarkable generalization ability and wide-spread applicability.

**The Study of DVN Depth.** The depth is crucial for ensuring interaction and coherence between row and column features in DVN graph convolution. As shown in the Parameter Study in Appendix F.2, increasing the training depth of DVN improves feature extraction precision, leading to consistent enhancement in VCM performance. It is logical to hypothesize that a VCM trained at a particular depth \(d\) would perform better at deeper testing depths. To investigate this hypothesis, we evaluate six VCMs on benchmark B2500 across eight testing depths. The results (illustrated in Figure 7(a) and detailed in Appendix J) show that all VCMs exhibit significant performance gains as testing depth increases. Even at the training depth of 10, VCM already learns an iterative feature extraction pattern. However, when the testing depth retracts below the training depth, VCM presents a perceptible but tolerable performance degradation, reinforcing the premise that reaching the training depth threshold is essential for DVN stabilization.

To further investigate the rationale behind this performance, we apply the t-SNE  on the output \(^{(d),D}\) of Extractor DVN from the trained VCM50-\(d10\) with varying testing depths. Figure 8 shows that as \(d\) increases, clustering transitions into binary clusters gradually. When \(d=1\), it converges to a number of lines, and when \(d>100\), the binary clustering occurs. This demonstrates that our DVN overcomes the limitation of GCN (i.e., its performance degrades as the depth increases, as shown in our evaluation in Appendix K), thus effectively supporting the Classifier VCN. For instance, the default VCM50-\(d40\) achieves an average gap of merely 0.034% when the testing \(d\) hits 300, as opposed to its original gap of 0.362%. This performance enhancement can be generalizable to very large instances, as demonstrated by our evaluations on well-known instances (see Appendix J) and G instance with 10,000 and 20,000 variables (see Appendix L), and is achieved without additional training costs. As shown in Figure 7(b), the computational time increases linearly (on average 0.17ms per depth) as the testing depth enlarges, which verifies the remarkable performance of the VCM and extends its applications.

Figure 5: VCM training process under different methods at instance size 50. Figure 6: VCM results under different distributions in instances.

## 5 Conclusions and Future Work

Our neural solver VCM is a new state-of-the-art learning-based model designed for efficiently solving QUBO from a classification perspective. It applies the Extractor DVN based on graph convolution and exploits the symmetry property in \(Q\) to auto-grasp value features. Utilizing these resultant value features of each variable, VCM generates solutions directly through the Classifier VCN in a classification way. Trained by a highly efficient model-tailored Trainer GST which does not require any priori optimal labels, VCM shows near-optimality, high efficiency, and generalization ability in problem-solving. In particular, it can achieve an average gap to benchmark optimality of 0.362% in milliseconds and steadily narrow it down to 0.034% by simply extending the testing depth, which brings only a linearly increased computational time (average 0.17ms per depth).

Although VCM reaches such a performance by single classification decision-making, its optimality may be potentially limited by the VCN utilization of value features from DVN. This limitation poses challenges in achieving the optimal solution. Future research could explore enhancing VCM capabilities, including the development of more accurate classification networks and more efficient trainers, as well as adapting it to address other combinatorial optimization problems and real-world applications.