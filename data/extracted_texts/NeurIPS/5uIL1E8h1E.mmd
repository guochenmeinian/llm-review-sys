# Residual Scheduling: A New Reinforcement Learning Approach to Solving Job Shop Scheduling Problem

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Job-shop scheduling problem (JSP) is a mathematical optimization problem widely used in industries like manufacturing, and flexible JSP (FJSP) is also a common variant. Since they are NP-hard, it is intractable to find the optimal solution for all cases within reasonable times. Thus, it becomes important to develop efficient heuristics to solve JSP/FJSP. A kind of method of solving scheduling problems is construction heuristics, which constructs scheduling solutions via heuristics. Recently, many methods for construction heuristics leverage deep reinforcement learning (DRL) with graph neural networks (GNN). In this paper, we propose a new approach, named residual scheduling, to solving JSP/FJSP. In this new approach, we remove irrelevant machines and jobs such as those finished, such that the states include the remaining (or relevant) machines and jobs only. Our experiments show that our approach reaches state-of-the-art (SOTA) among all known construction heuristics on most well-known open JSP and FJSP benchmarks. In addition, we also observe that even though our model is trained for scheduling problems of smaller sizes, our method still performs well for scheduling problems of large sizes. Interestingly in our experiments, our approach even reaches zero gap for 49 among 50 JSP instances whose job numbers are more than 150 on 20 machines.

## 1 Introduction

The _job-shop scheduling problem_ (_JSP_) is a mathematical optimization (MO) problem widely used in many industries, like manufacturing (Zhang et al., 2020; Waschneck et al., 2016). For example, a semiconductor manufacturing process can be viewed as a complex JSP problem (Waschneck et al., 2016), where a set of given jobs are assigned to a set of machines under some constraints to achieve some expected goals such as minimizing makespan which is focused on in this paper. While there are many variants of JSP (Abdolrazzagh-Nezhad and Abdullah, 2017), we also consider an extension called _flexible JSP_ (_FJSP_) where job operations can be done on designated machines.

A generic approach to solving MO problems is to use mathematical programming, such as mixed integer linear programming (MILP) and constraint satisfaction problem (CSP). Two popular generic MO solvers for solving MO are _OR-Tools_(Perron and Furnon, 2019) and _IBM ILOG CPLEX Optimizer_ (abbr. _CPLEX_) (Cplex, 2009). However, both JSP and FJSP, as well as many other MO problems, have been shown to be NP-hard (Garey and Johnson, 1979; Lageweg et al., 1977). That said, it is unrealistic and intractable to find the optimal solution for all cases within reasonable times. These tools can obtain the optimal solutions if sufficient time (or unlimited time) is given; otherwise, return best-effort solutions during the limited time, which usually have gaps to the optimum. When problems are scaled up, the gaps usually grow significantly.

In practice, some heuristics (Gupta and Sivakumar, 2006; Haupt, 1989) or approximate methods (Jansen et al., 2000) were used to cope with the issue of intractability. A simple greedy approach is touse the heuristics following the so-called _priority dispatching rule (PDR)_(Haupt, 1989) to construct solutions. These can also be viewed as a kind of _solution construction heuristics_ or _construction heuristics_. Some of PDR examples are _First In First Out (FIFO)_, _Shortest Processing Time (SPT)_, _Most Work Remaining (MWKR)_, and _Most Operation Remaining (MOR)_. Although these heuristics are usually computationally fast, it is hard to design generally effective rules to minimize the gap to the optimum, and the derived results are usually far from the optimum.

Furthermore, a generic approach to automating the design of heuristics is called _metaheuristics_, such as tabu search (Dell'Amico and Trubian, 1993; Saidi-Mehrabad and Fattahi, 2007), genetic algorithm (GA) (Pezzella et al., 2008; Ren and Wang, 2012), and PSO algorithms (Lian et al., 2006; Liu et al., 2011). However, metaheuristics still take a high computation time, and it is not ensured to obtain the optimal solution

Recently, deep reinforcement learning (DRL) has made several significant successes for some applications, such as AlphaGo (Silver et al., 2016), AlphaStar (Vinyals et al., 2019), AlphaTensor (Fawzi et al., 2022), and thus it also attracted much attention in the MO problems, including chip design (Mirhoseini et al., 2021) and scheduling problems (Zhang et al., 2023). In the past, several researchers used DRL methods as construction heuristics, and their methods did improve scheduling performance, illustrated as follows. Park et al. (2020) proposed a method based on DQN (Mnih et al., 2015) for JSP in semiconductor manufacturing and showed that their DQN model outperformed GA in terms of both scheduling performance (namely gap to the optimum on makespan) and computation time. Lin et al. (2019) and Luo (2020) proposed different DQN models to decide the scheduling action among the heuristic rules and improved the makespan and the tardiness over PDRs, respectively.

A recent DRL-based approach to solving JSP/FJSP problems is to leverage graph neural networks (GNN) to design a size-agnostic representation (Zhang et al., 2020; Park et al., 2021, 2021, 2023). In this approach, graph representation has better generalization ability in larger instances and provides a holistic view of scheduling states. Zhang et al. (2020) proposed a DRL method with disjunctive graph representation for JSP, called _L2D (Learning to Dispatch)_, and used GNN to encode the graph for scheduling decision. Besides, Song et al. (2023) extended their methods to FJSP. Park et al. (2021) used a similar strategy of (Zhang et al., 2020) but with different state features and model structure. Park et al. (2021) proposed a new approach to solving JSP, called _ScheduleNet_, by using a different graph representation and a DRL model with the graph attention for scheduling decision. Most of the experiments above showed that their models trained from small instances still worked reasonably well for large test instances, and generally better than PDRs. Among these methods, ScheduleNet achieved state-of-the-art (SOTA) performance. There are still other DRL-based approaches to solving JSP/FJSP problems, but not construction heuristics. Zhang et al. (2022) proposes another approach, called Learning to Search (L2S), a kind of search-based heuristics.

In this paper, we propose a new approach to solving JSP/FJSP, a kind of construction heuristics, also based on GNN. In this new approach, we remove irrelevant machines and jobs, such as those finished, such that the states include the remaining machines and jobs only. This approach is named _residual scheduling_ in this paper to indicate to work on the remaining graph.

Without irrelevant information, our experiments show that our approach reaches SOTA by outperforming the above mentioned construction methods on some well-known open benchmarks, seven for JSP and two for FJSP, as described in Section 4. We also observe that even though our model is trained for scheduling problems of smaller sizes, our method still performs well for scheduling problems of large sizes. Interestingly in our experiments, our approach even reaches zero gap for 49 among 50 JSP instances whose job numbers are more than 150 on 20 machines.

## 2 Problem Formulation

### JSP and FJSP

A \(n m\) JSP instance contains \(n\) jobs and \(m\) machines. Each job \(J_{j}\) consists of a sequence of \(k_{j}\) operations \(\{O_{j,1},,O_{j,k_{j}}\}\), where operation \(O_{j,i}\) must be started after \(O_{j,i-1}\) is finished. One machine can process at most one operation at a time, and preemption is not allowed upon processing operations. In JSP, one operation \(O_{j,i}\) is allowed to be processed on one designated machine, denoted by \(M_{j,i}\), with a processing time, denoted by \(T_{j,i}^{(op)}\). Table 1 (a) illustrates a \(3 3\) JSP instance, where the three jobs have 3, 3, 2 operations respectively, each of which is designated to be processed on one of the three machines \(\{M_{1},M_{2},M_{3}\}\) in the table. A solution of a JSP instance is to dispatch all operations \(O_{j,i}\) to the corresponding machine \(M_{j,i}\) at time \(_{j,i}^{(s)}\), such that the above constraints are satisfied. Two solutions of the above 3x3 JSP instance are given in Figure 1 (a) and (b).

While there are different expected goals, such as makespan, tardiness, etc., this paper focuses on makespan. Let the first operation start at time \(=0\) in a JSP solution initially. The makespan of the solution is defined to be \(T^{(mksp)}=(_{j,i}^{(c)})\) for all operations \(O_{j,i}\), where \(_{j,i}^{(c)}=_{j,i}^{(s)}+T_{j,i}^{(op)}\) denotes the completion time of \(O_{j,i}\). The makespans for the two solutions illustrated in Figure 1 (a) and (b) are 12 and 15 respectively. The objective is to derive a solution that minimizes the makespan \(T^{(mksp)}\), and the solution of Figure 1 (a) reaches the optimal.

A \(n m\) FJSP instance is also a \(n m\) JSP instance with the following difference. In FJSP, all operations \(O_{j,i}\) are allowed to be dispatched to multiple designated machines with designated processing times. Table 1 (b) illustrates a \(3 3\) FJSP instance, where multiple machines can be designated to be processed for one operation. Figure 1 (c) illustrates a solution of an FJSP instance, which takes a shorter time than that in Figure 1 (d).

### Construction Heuristics

An approach to solving these scheduling problems is to construct solutions step by step in a greedy manner, and the heuristics based on this approach is called _construction heuristics_ in this paper. In the approach of construction heuristics, a scheduling solution is constructed through a sequence of partial solutions in a chronicle order of dispatching operations step by step, defined as follows. The \(t\)-th partial solution \(S_{t}\) associates with a _dispatching time_\(_{t}\) and includes a partial set of operations that have been dispatched by \(_{t}\) (inclusive) while satisfying the above JSP constraints, and all the remaining operations must be dispatched after \(_{t}\) (inclusive). The whole construction starts with \(S_{0}\) where none of operations have been dispatched and the dispatching time is \(_{0}=0\). For each \(S_{t}\), a set of operations to be chosen for dispatching form a set of pairs of (\(M\), \(O\)), called _candidates_\(C_{t}\), where operations \(O\) are allowed to be dispatched on machines \(M\) at \(_{t}\). An agent (or a heuristic algorithm) chooses one from candidates \(C_{t}\) for dispatching, and transits the partial solution to the next \(S_{t+1}\). If there exists no operations for dispatching, the whole solution construction process is done and the partial solution is a solution, since no further operations are to be dispatched.

Table 1: JSP and FJSP instances

Figure 1: Both (a) and (b) are solutions of the 3x3 JSP instance in Table 1 (a), and the former has the minimal makespan, 12. Both (c) and (d) are solutions of the 3x3 FJSP instance in Table 1 (b), and the former has the minimal makespan, 9.

Figure 2 illustrates a solution construction process for the 3x3 JSP instance in Table 1(a), constructed through nine partial solutions step by step. The initial partial solution \(S_{0}\) starts without any operations dispatched as in Figure 2 (a). The initial candidates \(C_{0}\) are \(\{(M_{1},O_{1,1}),(M_{3},O_{2,1}),(M_{1},O_{3,1})\}\). Following some heuristic, construct a solution from partial solution \(S_{0}\) to \(S_{9}\) step by step as in the Figure, where the dashed line in red indicate the time \(_{t}\). The last one \(S_{9}\), the same as the one in Figure 1 (a), is a solution, since all operations have been dispatched, and the last operation ends at time 12, the makespan of the solution.

For FJSP, the process of solution construction is almost the same except for that one operation have multiple choices from candidates. Besides, an approach based on solution construction can be also viewed as the so-called _Markov decision process_ (_MDP_), and the MDP formulation for solution construction is described in more detail in the appendix.

## 3 Our Approach

In this section, we present a new approach, called _residual scheduling_, to solving scheduling problems. We introduce the residual scheduling in Subsection 3.1, describe the design of the graph representation in Subsection 3.2, propose a model architecture based on graph neural network in Subsection 3.3 and present a method to train this model in Subsection 3.4;

### Residual Scheduling

In our approach, the key is to remove irrelevant information, particularly for operations, from states (including partial solutions). An important benefit from this is that we do not need to include all irrelevant information while training to minimize the makespan. Let us illustrate by the state for the partial solution \(S_{3}\) at time \(_{3}=3\) in Figure 2 (d). All processing by \(_{3}\) are irrelevant to the remaining scheduling. Since operations \(O_{1,1}\) and \(O_{2,1}\) are both finished and irrelevant the rest of scheduling, they can be removed from the state of \(S_{3}\). In addition, operation \(O_{2,2}\) is dispatched at time 2 (before \(_{3}=3\)) and its processing time is \(T_{2,1}^{(op)}=4\), so the operation is marked as _ongoing_. Thus, the operation can be modified to start at \(_{3}=3\) with a processing time \(4-(3-2)\). Thus, the modified state for \(S_{3}\) do not contain both \(O_{1,1}\) and \(O_{2,1}\), and modify \(O_{2,2}\) as above. Let us consider two more examples. For \(S_{4}\), one more operation \(O_{2,2}\) is dispatched and thus marked as ongoing, however, the time \(_{4}\) remains unchanged and no more operations are removed. In this case, the state is almost the same except for including one more ongoing operation \(O_{2,2}\). Then, for \(S_{5}\), two more operations

Figure 2: Solution construction, a sequence of partial solutions from \(S_{0}\) to \(S_{8}\).

and \(O_{2,2}\) are removed and the ongoing operation \(O_{1,2}\) changes its processing time to the remaining time (5-3).

For residual scheduling, we also reset the dispatching time \(=0\) for all states with partial solutions modified as above, so we derive makespans which is also irrelevant to the earlier operations. Given a scheduling policy \(\), \(T_{}^{(mksp)}(S)\) is defined to be the makespan derived from an episode starting from states \(S\) by following \(\), and \(T_{}^{(mksp)}(S,a)\) the makespan by taking action \(a\) on \(S\).

### Residual Graph Representation

In this paper, our model design is based on graph neural network (GNN), and leverage GNN to extract the scheduling decision from the relationship in graph. In this subsection, we present the graph representation. Like many other researchers such as Park et al. (2021), we formulate a partial solution into a graph \(=(,)\), where \(\) is a set of nodes and \(\) is a set of edges. A node is either a machine node \(M\) or an operation node \(O\). An edge connects two nodes to represent the relationship between two nodes, basically including three kinds of edges, namely operation-to-operation (\(O O\)), machine-to-operation (\(M O\)) and operation-to-machine (\(O M\)). All operations in the same job are fully connected as \(O O\) edges. If an operation \(O\) is able to be performed on a machine \(M\), there exists both \(O M\) and \(M O\) directed edges. In (Park et al., 2021), they also let all machines be fully connected as \(M M\) edges. However, our experiments in section 4 show that mutual \(M M\) edges do not help much based on our Residual Scheduling. An illustration for graph representation of \(S_{3}\) is depicted in Figure 3 (a).

In the graph representation, all nodes need to include some attributes so that a partial solution \(S\) at the dispatching time \(\) can be supported in the MDP formulation (in the appendix). Note that many of the attributes below are normalized to reduce variance. For nodes corresponding to operations \(O_{j,i}\), we have the following attributes:

_Status_\(_{j,i}\): The operation status \(_{j,i}\) is _completed_ if the operation has been finished by \(\), _ongoing_ if the operation is ongoing (i.e., has been dispatched to some machine by \(\) and is still being processed at \(\)), _ready_ if the operation designated to the machine which is idle has not been dispatched yet and its precedent operation has been finished, and _unready_ otherwise. For example, in Figure 3 (a), the gray nodes are _completed_, the red _ongoing_, the yellow _ready_ and the white _unready_. In our residual scheduling, there exists no completed operations in all partial solutions, since they are removes for irrelevance of the rest of scheduling. The attribute is a one-hot vector to represent the current status of the operation, which is one of _ongoing_, _ready_ and _unready_. Illustration for all states \(S_{0}\) to \(S_{8}\) are shown in the appendix.

_Normalized processing time_\(_{j,i}^{(op)}\): Let the maximal processing time be \(T_{max}^{(op)}=_{ j,i}(T_{j,i}^{(op)})\). Then, \(_{j,i}^{(op)}=T_{j,i}^{(op)}/T_{max}^{(op)}\). In our residual scheduling, the operations that have been finished are removed in partial solutions and therefore their processing time can be ignored; the operations that has not been dispatched yet still keep their processing times the same; the operations that are _ongoing_ change their processing times to the remaining times after the dispatching time \(_{t}\). As for FJSP, the operations that has not been dispatched yet may have several processing times on different machines, and thus we can simply choose the average of these processing times.

Figure 3: Graph representation and networks.

_Normalized job remaining time \(^{(job)}_{j,i}\)_: Let the rest of processing time for job \(J_{j}\) be \(T^{(job)}_{j,i}=_{ i^{} i}T^{(op)}_{j,i^{}}\), and let the processing time for the whole job \(j\) be \(T^{(job)}_{j}=_{ i^{}}T^{(op)}_{j,i}\). In practice, \(T^{(job)}_{j}\) is replaced by the processing time for the original job \(j\). Thus, \(^{(job)}_{j,i}=T^{(job)}_{j,i}/T^{(job)}_{j}\). For FJSP, since operations \(O_{j,i}\) can be dispatched to different designated machines \(M_{l}\), say with the processing time \(T^{(op)}_{j,i,l}\), we simply let \(T^{(op)}_{j,i}\) be the average of \(T^{(op)}_{j,i,l}\) for all \(M_{l}\).

For machine nodes corresponding to machines \(M_{l}\), we have the following attributes:

_Machine status \(_{l}\)_: The machine status \(_{l}\) is _processing_ if some operation has been dispatched to and is being processed by \(M_{l}\) at \(\), and _idle_ otherwise (no operation is being processed at \(\)). The attribute is a one-hot vector to represent the current status, which is one of _processing_ and _idle_.

_Normalized operation processing time \(^{(mac)}_{l}\)_: On the machine \(M_{l}\), the processing time \(T^{(mac)}_{l}\) is \(T^{(op)}_{j,i}\) (the same as the normalized processing time for node \(O_{j,i}\)) if the machine status is _processing_, i.e., some ongoing operation \(O_{j,i}\) is being processed but not finished yet, is zero if the machine status is _idle_. Then, this attribute is normalized to \(T^{(op)}_{max}\) and thus \(^{(mac)}_{l}=T^{(mac)}_{l}/T^{(op)}_{max}\).

Now, consider edges in a residual scheduling graph. As described above, there exists three relationship sets for edges, \(O O\), \(O M\) and \(M O\). First, for the same job, say \(J_{j}\), all of its operation nodes for \(O_{j,i}\) are fully connected. Note that for residual scheduling the operations finished by the dispatching time \(\) are removed and thus have no edges to them. Second, a machine node for \(M_{l}\) is connected to an operation node for \(O_{j,i}\), if the operation \(O_{j,i}\) is designated to be processed on the machine \(M_{l}\), which forms two edges \(O M\) and \(M O\). Both contains the following attribute.

_Normalized operation processing time \(^{(edge)}_{j,i,l}\)_: The attribute is \(^{(edge)}_{j,i,l}=T^{(op)}_{j,i}/T^{(op)}_{max}\). Here, \(T^{(op)}_{j,i}=T^{(op)}_{j,i,l}\) in the case of FJSP. If operation \(O_{j,i}\) is ongoing (or being processed), \(T^{(op)}_{j,i}\) is the remaining time as described above.

### Graph Neural Network

In this subsection, we present our model based on graph neural network (GNN). GNN are a family of deep neural networks (Battaglia et al., 2018) that can learn representation of graph-structured data, widely used in many applications (Lv et al., 2021; Zhou et al., 2020). A GNN aggregates information from node itself and its neighboring nodes and then update the data itself, which allows the GNN to capture the complex relationships within the data graph. For GNN, we choose _Graph Isomorphism Network (GIN)_, which was shown to have strong discriminative power (Xu et al., 2019) and summarily reviewed as follows. Given a graph \(=(,)\) and \(K\) GNN layers (\(K\) iterations), GIN performs the \(k\)-th iterations of updating feature embedding \(h^{(k)}\) for each node \(v\):

\[h^{(k)}_{v}=MLP^{(k)}((1+^{(k)})h^{(k-1)}_{v}+_{u N_{b}(v)}h^{( k-1)}_{u}),\] (1)

where \(h^{(k)}_{v}\) is the embedding of node \(v\) at the \(k\)-th layer, \(^{(k)}\) is an arbitrary number that can be learned, and \(N_{b}(v)\) is the neighbors of \(v\) via edges in \(\). Note that \(h^{(0)}_{v}\) refers to its raw features for input. \(MLP^{(k)}\) is a _Multi-Layer Perceptron_ (_MLP_) for the \(k\)-th layer with a batch normalization (Ioffe and Szegedy, 2015).

Furthermore, we actually use _heterogeneous GIN_, also called _HGIN_, since there are two types of nodes, machine and operation nodes, and three relations, \(O O\), \(O M\) and \(M O\) in the graph representation. Although we do not have cross machine relations \(M M\) as described above, updating machine nodes requires to include the update from itself as in (1), that is, there is also one more relation \(M M\). Thus, HGIN encodes graph information between all relations by using the four MLPs as follows,

\[h^{(k+1)}_{v}=_{}MLP^{(k+1)}_{}((1+e^{(k+1)}_{ })h^{(k)}_{v}+_{u N_{}(v)}h^{(k)}_{u})\] (2)

where \(\) is one of the above four relations and \(MLP^{(k)}_{}\) is the MLP for \(\). For example, for \(S_{0}\) in Figure 2 (a), the embedding of \(M_{1}\) in the \((k+1)\)-st iteration can be derived as follows.

\[h^{(k+1)}_{M_{1}}=MLP^{(k+1)}_{MM}((1+^{(k+1)}_{MM})h^{(k)}_{M_{1}})+ MLP^{(k+1)}_{OM}(h^{(k)}_{O_{1,1}}+h^{(k)}_{O_{1,2}}+h^{(k)}_{O_{1,3}})\] (3)Similarly, the embedding of \(O_{1,1}\) in the \((k+1)\)-st iteration is:

\[h_{O_{1,1}}^{(k+1)}=MLP_{OO}^{(k+1)}((1+_{OO}^{(k+1)})h_{O_{1,1}}^{(k)}+h _{O_{1,2}}^{(k)}+h_{O_{1,3}}^{(k)})+MLP_{MO}^{(k+1)}(h_{M_{1}}^{(k)})\] (4)

In our approach, an action includes the two phases, graph embedding phase and action selection phase. Let \(h_{Q}^{(k)}\) denote the whole embedding of the graphs \(\), a summation of the embeddings of all nodes, \(h_{v}^{(k+1)}\). In the graph embedding phase, we use an HGIN to encode node and graph embeddings as described above. An example with three HGIN layers is illustrated in Figure 3 (b).

In the action selection phase, we select an action based on a policy, after node and graph embedding are encoded in the graph embedding phase. The policy is described as follows. First, collect all _ready_ operations \(O\) to be dispatched to machines \(M\). Then, for all pairs (\(M\), \(O\)), feed their node embeddings (\(h_{M}^{(k)}\), \(h_{Q}^{(k)}\)) into a MLP \(Score(M,O)\) to calculate their scores as shown in Figure 3 (c). The probability of selecting (\(M\), \(O\)) is calculated based on a softmax function of all scores, which also serves as the model policy \(\) for the current state.

### Policy-Based RL Training

In this paper, we propose to use a policy-based RL training mechanism that follows REINFORCE (Sutton and Barto, 2018) to update our model by policy gradient with a normalized advantage makespan with respect to a baseline policy \(_{b}\) as follows.

\[A_{}(S,a)=}^{(mksp)}(S,a)-T_{}^{(mksp)}(S,a)}{T_{_{b} }^{(mksp)}(S,a)}\] (5)

In this paper, we choose a lightweight PDR, MWKR, as baseline \(_{b}\), which performed best for makespan among all PDRs reported from the previous work (Zhang et al., 2020). In fact, our experiment also shows that using MWKR is better than the other PDRs shown in the appendix. The model for policy \(\) is parametrized by \(\), which is updated by \(_{}log_{}A_{_{}}(S_{t},a_{t})\). Our algorithm based on REINFORCE is listed in the appendix.

## 4 Experiments

### Experimental Settings and Evaluation Benchmarks

In our experiments, the settings of our model are described as follows. All embedding and hidden vectors in our model have a dimension of 256. The model contains three HGIN layers for graph embedding, and an MLP for the score function, as shown in Figure 3 (b) and (c). All MLP networks including those in HGIN and for score contain two hidden layers. The parameters of our model, such as MLP, generally follow the default settings in PyTorch (Paszke et al., 2019) and PyTorch Geometric (Fey and Lenssen, 2019). More settings are in the appendix.

Each of our models is trained with one million episodes, each with one scheduling instance. Each instance is generated by following the procedure which is used to generate the TA dataset (Taillard, 1993). Given (\(N\), \(M\)), we use the procedure to generate an \(n m\) JSP instance by conforming to the following distribution, \(n(3,N)\), \(m(3,n)\), and operation count \(k_{j}=m\), where \((x,y)\) represents a distribution that uniformly samples an integer in a close interval \([x,y]\) at random. The details of designation for machines and processing times refer to (Taillard, 1993) and thus are omitted here. We choose (10,10) for all experiments, since (10,10) generally performs better than the other two as described in the appendix. Following the method described in Subsection 3.4, the model is updated from the above randomly generated instances. For testing our models for JSP and FJSP, seven JSP open benchmarks and two FJSP open benchmarks are used, as listed in the appendix.

The performance for a given policy method \(\) on an instance is measured by the makespan gap \(G\) defined as

\[G=^{(mksp)}-T_{*}^{(mksp)}}{T_{*}^{(mksp)}}\] (6)

where \(T_{*}^{(mksp)}\) is the optimal makespan or the best-effort makespan, from a mathematical optimization tool, OR-Tools, serving as \(*\). By the best-effort makespan, we mean the makespan derived with a sufficiently large time limitation, namely half a day with OR-Tools. For comparison in experiments, we use a server with Intel Xeon E5-2683 CPU and a single NVIDIA GeForce GTX 1080 Ti GPU. Our method uses a CPU thread and a GPU to train and evaluate, while OR-Tools uses eight threads to find the solution.

### Experiments for JSP

For JSP, we first train a model based on residual scheduling, named RS. For ablation testing, we also train a model, named RS+op, by following the same training method but without removing irrelevant operations. When using these models to solve testing instances, action selection is based on the greedy policy that simply chooses the action \((M,O)\) with the highest score deterministically, obtained from the score network as in Figure 3 (c).

For comparison, we consider the three DRL construction heuristics, respectively developed in (Zhang et al., 2020) called L2D, (Park et al., 2021b) by Park et al., and (Park et al., 2021a), called ScheduleNet. We directly use the performance results of these methods for open benchmarks from their articles. For simplicity, they are named L2D, Park and SchN respectively in this paper. We also include some construction heuristics based PDR, such as MWKR, MOR, SPT and FIFO. Besides, to derive the gaps to the optimum in all cases, OR-Tools serve as \(*\) as described in (6).

Now, let us analyze the performances of RS as follows. Table 2 shows the average makespan gaps for each collection of JSP TA benchmarks with sizes, 15x15, 20x15, 20x20, 30x15, 30x20, 50x15, 50x20 and 100x20, where the best performances (the smallest gaps) are marked in bold. In general, RS performs the best, and generally outperforms the other methods for all collections by large margins, except for that it has slightly higher gaps than RS+op for the two collections, 15 \(\) 15 and 20 \(\) 20. In fact, RS+op also generally outperforms the rest of methods, except for that it is very close to SchN for two collections. For the other six open benchmarks, ABZ, FT, ORB, YN, SWV and LA, the performances are similar and thus presented in the appendix. It is concluded that RS generally performs better than other construction heuristics by large margins.

### Experiments for FJSP

For FJSP, we also train a model based on residual scheduling, named RS, and a ablation version, named RS+op, without removing irrelevant operations. We compares ours with one DRL construction heuristics developed by (Song et al., 2023), called DRL-G, and four PDR-based heuristics, MOR,

  Size & 15\(\)15 & 20\(\)15 & 20\(\)20 & 30\(\)15 & 30\(\)20 & 50\(\)15 & 50\(\)20 & 100\(\)20 & \(Avg.\) \\   RS & 0.148 & **0.165** & 0.169 & **0.144** & **0.177** & **0.067** & **0.100** & **0.026** & **0.125** \\ RS+op & **0.143** & 0.193 & **0.159** & 0.192 & 0.213 & 0.123 & 0.126 & 0.050 & 0.150 \\  MWKR & 0.191 & 0.233 & 0.218 & 0.239 & 0.251 & 0.168 & 0.179 & 0.083 & 0.195 \\ MOR & 0.205 & 0.235 & 0.217 & 0.228 & 0.249 & 0.173 & 0.176 & 0.091 & 0.197 \\ SPT & 0.258 & 0.328 & 0.277 & 0.352 & 0.344 & 0.241 & 0.255 & 0.144 & 0.275 \\ FIFO & 0.239 & 0.314 & 0.273 & 0.311 & 0.311 & 0.206 & 0.239 & 0.135 & 0.254 \\   L2D & 0.259 & 0.300 & 0.316 & 0.329 & 0.336 & 0.223 & 0.265 & 0.136 & 0.270 \\ Park & 0.201 & 0.249 & 0.292 & 0.246 & 0.319 & 0.159 & 0.212 & 0.092 & 0.221 \\ SchN & 0.152 & 0.194 & 0.172 & 0.190 & 0.237 & 0.138 & 0.135 & 0.066 & 0.161 \\  

Table 2: Average makespan gaps for TA benchmarks.

  Method & MK & LA(rdata) & LA(data) & LA(vdata) \\   RS & **0.232** & **0.099** & **0.146** & 0.031 \\ RS+op & 0.254 & 0.113 & 0.168 & **0.029** \\  DRL-G & 0.254 & 0.111 & 0.150 & 0.040 \\  MWKR & 0.282 & 0.125 & 0.149 & 0.051 \\ MOR & 0.296 & 0.147 & 0.179 & 0.061 \\ SPT & 0.457 & 0.277 & 0.262 & 0.182 \\ FIFO & 0.307 & 0.166 & 0.220 & 0.075 \\  

Table 3: Average makespan gaps for FJSP open benchmarksMWKR, SPT and FIFO. We directly use the performance results of these methods for open datasets according to the reports from (Song et al., 2023).

Table 3 shows the average makespan gaps in the four open benchmarks, MK, LA(rdata), LA(edata) and LA(vdata). From the table, RS generally outperforms all the other methods for all benchmarks by large margins, except for that RS+op is slightly better for the benchmark LA(vdata).

## 5 Discussions

In this paper, we propose a new approach, called residual scheduling, to solving JSP an FJSP problems, and the experiments show that our approach reaches SOTA among DRL-based construction heuristics on the above open JSP and FJSP benchmarks. We further discusses three issues: large instances, computation times and further improvement.

First, from the above experiments particularly for TA benchmark for JSP, we observe that the average gaps gets smaller as the number of jobs increases, even if we use the same model trained with \((N,M)=(10,10)\). In order to investigate size-agnostics, we further generate 13 collections of JSP instances of sizes for testing, from 15 \(\) 15 to 200 \(\) 20, and generate 10 instances for each collection by using the procedure above. Figure 4 shows the average gaps for these collections for RS and L2D, and these collections are listed in the order of sizes in the x-axis. Note that we only show the results of L2D in addition to our RS, since L2D is the only open-source among the above DRL heuristics. Interestingly, using RS, the average gaps are nearly zero for the collections with sizes larger than 100 \(\) 15, namely, 100 \(\) 15, 100 \(\) 20, 150 \(\) 15, 200 \(\) 15 and 200 \(\) 20. Among the 50 JSP instances in the five collections, 49 reaches zero gaps. A strong implication is that our RS approach can be scaled up for job sizes and even reach the optimal for sufficient large job count.

Second, the computation times for RS are relatively small and has low variance like most of other construction heuristics. Here, we just use the collection of TA 100x20 for illustration. It takes about 30 seconds on average for both RS and RS+op, about 28 for L2D and about 444 for SchN. In contrast, it takes about 4000 seconds with high variance for OR-tools. The times for other collections are listed in more detail in the appendix.

Third, as proposed by Song et al. (2023), construction heuristics can further improve the gap by constructing multiple solutions based on the softmax policy, in addition to the greedy policy. They had a version constructing 100 solutions for FJSP, called DRL+100 in this paper. In this paper, we also implement a RS version for FJSP based on the softmax policy, as described in Subsection 3.3, and then use the version, called RS+100, to constructing 100 solutions. In Table 4, the experimental results show that RS+100 performs the best, much better than RS, DRL-G and DRL+100. An important property for such an improvement is that constructing multiple solutions can be done in parallel. That is, for construction heuristics, the solution quality can be improved by adding more computation powers.

  Method & MK & LA(rdata) & LA(edata) & LA(vdata) \\   RS & 0.232 & 0.099 & 0.146 & 0.031 \\ RS+100 & **0.154** & **0.047** & **0.079** & **0.007** \\  DRL-G & 0.254 & 0.111 & 0.150 & 0.040 \\ DRL+100 & 0.190 & 0.058 & 0.082 & 0.014 \\  

Table 4: Average makespan gaps for FJSP open benchmark.

Figure 4: Average makespan gaps of JSP instances with different problem sizes.