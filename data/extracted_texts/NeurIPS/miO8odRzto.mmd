# Online Relational Inference for Evolving Multi-agent Interacting Systems

Beomseok Kang, Priyabrata Saha, Sudarshan Sharma, Biswadeep Chakraborty,

Saibal Mukhopadhyay

Georgia Institute of Technology

{beomseok,smukhopadhyay6}@gatech.edu

###### Abstract

We introduce a novel framework, Online Relational Inference (ORI), designed to efficiently identify hidden interaction graphs in evolving multi-agent interacting systems using streaming data. Unlike traditional offline methods that rely on a fixed training set, ORI employs online backpropagation, updating the model with each new data point, thereby allowing it to adapt to changing environments in real-time. A key innovation is the use of an adjacency matrix as a trainable parameter, optimized through a new adaptive learning rate technique called AdaRelation, which adjusts based on the historical sensitivity of the decoder to changes in the interaction graph. Additionally, a data augmentation method named Trajectory Mirror (TM) is introduced to improve generalization by exposing the model to varied trajectory patterns. Experimental results on both synthetic datasets and real-world data (CMU MoCap for human motion) demonstrate that ORI significantly improves the accuracy and adaptability of relational inference in dynamic settings compared to existing methods. This approach is model-agnostic, enabling seamless integration with various neural relational inference (NRI) architectures, and offers a robust solution for real-time applications in complex, evolving systems. Code is available at https://github.com/beomseokg/ORI.

## 1 Introduction

Multi-agent interacting systems have been studied in various fields, including particle-based physical simulations , traffic systems , and social networks . Interaction among agents is crucial information to accurately model such systems and also provides interpretability in agent behaviors . However, external observers can only access the trajectory of agents without knowing interaction graphs. Consequently, identifying unknown interaction graphs from observable trajectories of agents has been emerged as a specific problem referred to as relational inference .

In recent years, neural relational inference (NRI) and its variants have shown promising performance in synthetic and real-world environments . Prior studies mostly aimed to present better network for NRI based on variational autoencoder (VAE) built with graph neural networks (GNN) . These methods involve an encoder to infer an interaction graph as an adjacency matrix from observed trajectories and a decoder to predict the future trajectories employing the inferred interaction graph. They generally perform training offline assuming the well-aligned distribution in training and testing data. Unfortunately, such assumption is frequently violated in practice due to the shifts in test condition, including sudden changes in the interaction, evolving system parameters and even dynamics itself. Building a relational inference model generalizable to all the different scenarios is challenging . In this case, online learning is an attractive approach to continuously adapt the model to newly observed environments . However, online learning for relational inference has been rarely explored.

Online backpropagation using gradient descent is a widely used online learning method as it is compatible with various neural network designs . However, online backpropagation on existing NRI models significantly degrades the accuracy on relational inference, since their decoder quickly learns the trajectory prediction even before the encoder generates reasonable interaction graphs. It is important to note that while the models are trained in self-supervised manner (_i.e._, trajectory prediction), true labels of interaction graphs are never provided to the models, indicating that identifying interaction graphs is essentially unsupervised. That is, optimizing the unsupervised encoder is more challenging than the self-supervised decoder in nature. The key problem is how to match the learning speed between the interaction identification and the trajectory prediction so that both the tasks can be collaboratively optimized.

In this paper, we propose a novel framework named **On**line **R**elational **I**nference (**ORI**) to efficiently identify hidden interaction graphs in evolving multi-agent interacting systems. Our method strategically allocates an adjacency matrix representing the interaction as a trainable parameter in the model and directly optimizes it through online backpropagation on the predicted trajectories. It effectively accelerates the update of the adjacency matrix than the encoder-based approach and ensures the following decoder to be learned with reasonable adjacency matrices from the early stage of training. ORI can seamlessly integrate with prior NRI models, offering architectural flexibility (_i.e._, model-agnostic). Moreover, we developed an adaptive learning rate technique named AdaRelation particularly designed for relational inference in the evolving systems. It employs the historical adjacency matrix to indirectly estimate the decoder's sensitivity over the adjacency matrix and determine whether the learning needs to be accelerated. In addition, we introduce a data augmentation technique named Trajectory Mirror (TM) to expose various trajectories by flipping the axis in the systems. We experimentally demonstrate the effectiveness of ORI on various NRI models in both the synthetic and real-world (CMU MoCap for human motion ) datasets. Our key contributions are as follows:

* To the best of our knowledge, ORI is the first model-agnostic online relational inference framework for evolving multi-agent interacting systems. ORI employs online backpropagation to optimize an adjacency matrix from the trajectory information without any assumptions on the model architecture.
* We experimentally demonstrate that ORI identifies unknown interaction graphs in various evolving multi-agent interacting systems, such as sudden changes in interaction (Figure 2), parameters in the dynamics (Figure 3), and even dynamics itself (Figure 3), outperforming existing NRI models (Table 2).
* We propose AdaRelation, a novel adaptive learning rate technique particularly designed for relational inference in evolving multi-agent systems. It automatically tunes the learning rate for the adjacency matrix when interaction or/and dynamics in the system suddenly change (Figure 3).
* We propose Trajectory Mirror, a data augmentation technique to ensure the reasonable relational inference regardless of the trajectory axis. It significantly improves the convergence speed and overall interaction prediction accuracy in the several evolving scenarios (Supplementary).

## 2 Related Works

Neural relational inference.NRI  is the first work that formulated the problem of an unsupervised relational inference from observed agent trajectories. They implemented a VAE-based graph

   &  &  Model \\ Agnostic \\  } &  Consider Evolution in \\ Interaction \\  } &  Criteria \\  } \\   & & & & & & Acc. & MSE \\   Prior offline works &  offline backpropagation \\ [11; 17; 12; 23; 16] \\  &  - \\ novel encoder and decoder \\  & - & \(\) & \(\) & \(\) & \(\) & \(\) \\  Prior online work &  online convex optimization \\ constant learning rate \\  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   &  online backpropagation \\  & 
 \(\) \\ AdaRelation; Traj. Mirror \\  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\  

Table 1: Comparison of key features between prior works and this work.

neural network that encodes trajectories into an adjacency matrix, representing relation types, and then decodes the trajectory using the predicted adjacency matrix. This approach has been established as a standard in several follow-up works. For example, dNRI  and EvolveGraph  introduced graph recurrent network-based architectures to encode and generate dynamic priors for predicting evolving interactions. Additionally, a memory-augmented architecture has been proposed for enhanced long-term prediction using external associative memory pools . More recently, finer granularities in relation modeling have been considered, such as edge to edge interaction , relation potentials using an energy-based function , and disentangled edge features . However, all of these methods commonly rely on an encoder-decoder pair in an offline setting, supported by a large amount of batched training samples, without considering various evolving scenarios.

Evolving multi-agent systems.Apart from relational inference, trajectory learning of evolving multi-agent interacting systems have actively explored using graph neural networks [18; 26; 6]. In particular, graph neural ordinary different equations (ODE) have been applied to various evolving scenarios, including evolving environments (_e.g._, temperature and pressure) [18; 20] and stochastic motion . However, these approaches assume a known graph structure, focusing on accelerating the simulation of physical dynamical systems [1; 7]. Additionally, each model addresses a specific type of evolution, raising questions about its generalizability to other scenarios. Moreover, adapting neural ODEs, potentially through online backpropagation, is a challenging problem since they are optimized from initial values .

Online learning for multi-agent systems.Online learning for relational inference in multi-agent systems is a rarely explored research problem despite its significance. One primary related work  also treats the adjacency matrix as a trainable parameter without using an encoder, optimizing it with an online expert mixture algorithm, a type of online convex optimization algorithm. Consequently, the loss function needs to be convex over the adjacency matrix to guarantee optimization. Their model architecture is specifically designed to place message passing in the last layer of the model to ensure the model output is a linear combination of hidden states and the adjacency matrix, maintaining the convex property. However, this simple architecture significantly differs from recent architectures (_e.g._, NRI and its variants), making it challenging to model nonlinear and complex interactions. Additionally, this work only reports trajectory prediction errors without providing any accuracy metrics on relational inference. Please note that a comparison with ORI is provided in the supplementary material.

## 3 Proposed Approach

### Background

Neural relational inference.Relational inference aims to identify an unknown interaction graph represented by an adjacency matrix \(I^{*} R^{N N m}\), where \(N\) is the number of agents and \(m\) is the number of interaction types, from their trajectory in a given time period \(x_{t:t+ t}\), which generally include positions and velocities of agents. Existing approaches are mostly designed with a pair of neural network-based encoder and decoder, where encoder (\(g_{}\)) predicts the adjacency matrix \(I_{t}\) from an observed trajectory (_i.e._, \(g_{}(x_{t- t:t})\) and then decoder predicts the future trajectory (\(_{t:t+ t}\)) by \(f_{}(x_{t- t:t},I_{t})\). That is, the encoder is optimized to return the adjacency matrix for a lower error on the predicted trajectory (decoder output), assuming \(I^{*}=_{I_{t}}L(x_{t: t},f_{}(x_{t- t:t},I_{t})\).

Online learning.Online learning problems have traditionally been formulated within the online convex optimization (OCO) framework, as introduced in . Conventional gradient descent-based online optimization projects the updated variables onto a convex set at each step . Such learning settings provide theoretical convergence guarantees when the loss function is convex with respect to the optimization variables. However, applying online gradient descent to deep neural networks (DNNs) is challenging due to the nonconvex nature of the loss function, and standard backpropagation performs poorly in an online setting . Two primary directions of study have emerged to tackle the challenges of online backpropagation. One approach involves employing a flexible network structure, where the DNN architecture evolves over time [21; 30]. The other approach focuses on using an adaptive learning rate, where the learning rate is adjusted over time [31; 32]. Since our primary focus is on learning multi-agent interactions online without relying on any specific network structure, we concentrate on adapting the learning rate based on the evolution of the adjacency matrix.

### Motivation of ORI

Our objective is to discover hidden relations between agents in evolving multi-agent interacting systems using their streaming trajectories. The motivation of this work comes from the primary challenges to apply existing methods to implement a fast-adapting, accurate, and stable online relational inference framework. Accordingly, we summarize our key motivations into three categories.

Why we consider adjacency matrix as trainable parameter?It may not be effective to simply apply the encoder and decoder-based existing methods to evolving multi-agent systems in the online setting. The primary challenge is that the intricate encoder is slowly trained with streaming and evolving data. It eventually degrades the decoder as well since the encoder and decoder are jointly trained, influencing each other. Whereas, ORI allocates the adjacency matrix as a trainable parameter, significantly enhancing the training speed in both the matrix and decoder. While such allocation is motivated from , this work still faces following crucial challenges.

Why we need model-agnostic learning?The relation inference is performed through the trajectory prediction without explicit supervision on graph structures (_i.e._, true relation is not observable). This means the only supervision is defined by the predicted trajectories from the decoder, and hence largely depending on how effectively the decoder responds to changes in the embedding adjacency matrix. If a learning method is constrained to a specific decoder design, like , the performance achievable by the method can be constrained by the decoder design. Ideally, the learning method should offer the flexibility to seamlessly integrate to various decoder designs.

Why we need adaptive learning rate?The choice of a learning rate is particularly important in the evolving systems since the loss landscape can significantly vary with the evolution in the systems. For example, a low learning rate may be suitable for a slowly evolving dynamics A, but may a high one is needed for stable operation in a fast evolving dynamics B. A constant (or decaying) learning rate leads to a slow convergence or/and potentially a sub-optimal performance as the dynamics evolves over time. Ideally, the learning rate needs to be automatically tuned over time, avoiding a trade-off between faster convergence and unstable learning.

### Training Procedures of ORI

First, the key difference in our training setup compared to the offline learning setup is that both batch and epoch are 1 (_i.e._, streaming data). There is no separate validation or test dataset in online learning. Training of ORI is performed by online backpropagation on each individual training sample every iteration. Figure 1 describes the proposed approach. Note that the input and output to the decoder in the figure (denoted as GNN) and its optimization are essentially the same as existing methods. Our

Figure 1: A brief illustration of the proposed Online Relational Inference (ORI) framework.

contribution is primarily in the optimization method for the adjacency matrix given by:

\[I(t+1)=I(t)-h_{}(D_{I(t)},(t))}(_{t- t +1:t+ t})}{dI(t)}\] (1)

where \(h_{}(D_{I(t)},(t)) R^{1}\) is the relation-aware adaptive learning rate, elaborated in the following paragraph. Initially, the adjacency matrix (\(I(t) R^{N N m};I_{i,j}(t)\)) is filled with 0.5. Each training sample given to the model involves a single trajectory for a time period of \(t- t:t+ t\) (_i.e._, \(x_{t- t:t+ t}\)). The decoder (\(f_{}\)) observes \(x_{t- t:t}\) and then predicts the future trajectory by \(_{t:t+ t}=f_{}(x_{t- t:t},I(t))\) in an autoregressive manner. It also reconstructs the trajectory \(_{t- t+1:t}\) during the observation. ORI estimates a MSE loss on the predicted and reconstructed trajectory at \(t+ t\) (_i.e._, \(L_{}(_{t- t+1:t+ t})\)) and then updates the decoder and adjacency matrix using gradient descent. Note that, the adjacency matrix is updated only once at each iteration. The model infers the relation in the given trajectory at the last time step. While the training objective is to minimize the overall MSE loss throughout the streaming data, our primary evaluation criterion is the relation accuracy representing the proportion of true positive and true negative in the adjacency matrix.

Adaptive relation-aware learning rate.We propose AdaRelation, a learning rate adaptation technique specifically designed for relational inference. AdaRelation adjusts the learning rate for the adjacency matrix (not the decoder) based on changes in the norm of the adjacency matrix. For example, if the norm exceeds a certain threshold, it gradually decreases the learning rate within a defined range.

The mechanism is intuitive: a good trajectory predictor should show a large output variance depending on the adjacency matrix, meaning the quality of a predicted trajectory should vary clearly with changes in the adjacency matrix. We observe that the norm of gradient (\(||}}{dI(t)}||_{1}\)) indeed increases as the model adapts to the evolved system, often making the adjacency matrix unstable (see (1)). Conversely, it decreases when the system suddenly evolves, slowing down the update of the adjacency matrix. Therefore, the gradient norm indicates when the update of the adjacency matrix needs to be stabilized or accelerated. Given the adjacency matrix is the sum of this gradient over time, comparing the current matrix with a past one essentially reflects changes in the gradient norm. Accordingly, we define \(D_{I(t)}\) to estimate the evolution in the L1 norm of the adjacency matrix over \(w\) time steps as follows:

\[D_{I(t)}=m}||I(t)-I(t-w)||_{1}\] (2)

This measures how much the predicted interaction strength (\(I_{i,j,k}\)) changes on average over \(w\) time steps. We define a threshold parameter \(\) to restrict changes in \(I_{i,j,k}\) to be remain near this threshold. The update of \((t)\) involves adding or subtracting \(\), an adaptation step size, determined by the range of \(D_{I(t)}\) and the threshold:

\[(t)=-&D_{I(t)}>\\ &\] (3)

Consequently, the next learning rate (\((t+1)\)) is represented by \(h_{}(D_{I(t)},(t))\):

\[h_{}(D_{I(t)},(t))=_{_{};_{}}((t)+(t)))\] (4)

where \(_{_{;}}\) limits the learning rate within the lower bound (\(_{}\)) and upper bound (\(_{}\)). This effectively controls the learning rate to automatically stabilize and accelerate the update of the adjacency matrix. More intuition behind AdaRelation is discussed in the supplementary material.

Trajectory Mirror.The models trained by the online backpropagation are often prone to be biased to certain training samples. It also happens in multi-agent interacting systems. For example, the coordinates and velocities of agents in the currently observed data samples can be biased. Such scenario has not been discussed much in literature because existing works expose the model to a huge amount of simulations with short-term trajectories, ensuring several different initial positions and velocities. However, our problem addresses streaming trajectories in a much longer-term, where we do not have an access to initialize their positions and velocities. Ideally, the relation between agents should be correctly inferred, regardless where the model observes them. Accordingly, we consider a data augmentation technique named Trajectory Mirror, which flips the axis and generates,for example in a two-dimensional space, three additional trajectories (see Figure 1). It is simple yet effective to avoid the model bias and significantly enhance the convergence speed of the model without storing the past trajectories. Ablation studies are available in the supplementary material.

Technical novelty.ORI is a novel model-agnostic online relational inference framework, incorporating a strategic combination of two different learning methods for the adjacency matrix and decoder. ORI introduces AdaRelation, an adaptive learning rate technique designed for relational inference, and Trajectory Mirror, a simply yet effective data augmentation technique proved in several evolving scenarios (results are in supplementary). Our approach clearly differs from existing methods which perform end-to-end gradient descent on the encoder [11; 12; 23] or online convex optimization constrained to a specific decoder design .

## 4 Experimental Results

Dataset.We experimented with three common benchmarks, synthetic springs and charged systems, and CMU MoCap (human motion) . The synthetic datasets were generated using the open-source code from NRI . For the springs and charged systems, 10 simulations with 90k time steps each were created, involving 10 agents with different random interactions (\(p=0.5\)). These simulations are sequentially presented to models. The evolving relation dataset features different interaction graphs in each simulation with fixed spring \(k=0.1\) and \(k_{e}=1.0\). Another dataset varies these constants, generated from uniform distributions \([0.1,0.2]\) for springs and \(\) for charged constants. The evolving relation and dynamics dataset randomly selects each simulation from either the springs or charged systems. The CMU MoCap dataset, processed using dNRI's open-source code , includes human motion data with 31 joints and various actions, captured at 120Hz.

Baseline and implementation detail.ORI is a model-agnostic online learning framework involving the trainable adjacency matrix. The adjacency matrix is initialized only at the initialization stage. The same adjacency matrix is used throughout the entire samples and simulations without assuming that we know when the interaction evolves. ORI can integrate with various models as long as they use the adjacency matrix as input. Most prior works use decoders based on graph multi-layer perceptron (MLP) and graph recurrent neural networks (RNN), as seen in NRI , incorporating node-to-edge and edge-to-node message passing. Additionally, MPM  introduces a graph RNN and an attention-based graph RNN for more efficient edge-to-edge message passing. To demonstrate ORI's effectiveness, we use four different trajectory predictors: NRI (MLP-based), NRIr (RNN-based), MPMr (RNN-based), and MPMa (attention-based). Since ORI employs the decoders in NRI and MPM, we primarily compare our approach with the original NRI and MPM. We also include dNRI , which is specifically designed for dynamically evolving interaction graphs. As these works analyzed the performance in the offline setup, we evaluated their models in the online setup. We follow their default implementation but replace the encoder with the trainable adjacency matrix. More details on the training setup are available in the supplementary material.

### Inferring Relation in Evolving Interaction Graph

We explore relation inference accuracy in the synthetic systems incorporating evolving interaction graphs. These systems involve constant parameters and no switching in the dynamics. Figure 2 demonstrates the relation accuracy over time and predicted trajectories in the springs system. The relation accuracy is evaluated based on the number of true positives and true negatives excluding self-interaction (_i.e._, total 10\(\)9 relations). Our approach is able to quickly recover the relation accuracy when the model encounters a new interaction graph. For example, at the bottom of Figure 2(a), the target interaction matrix suddenly changes at the 15k-th iteration. While it fails to adapt in a single iteration, the target and predicted matrices are aligned well after 100 iterations. In contrast, the baseline (MPM) accuracy slowly increases throughout the entire training iterations, showing a significant gap in the average relation accuracy. Figure 2(b) compares the target and predicted trajectories at the 15k-th iteration (_i.e._, right after the new interaction) and 18k-1-th iteration (_i.e._, right before another interaction), indicating the trajectory quality also improves along with the accuracy.

Table 2 showcases the average accuracy and average MSE loss during entire iterations in the springs and charged systems. As the interaction graph changes over time, simply reporting the final accuracy only represents how well the model adapts to the last graph. Accordingly, we report the average

accuracy over entire iterations to understand the model's accuracy on the multiple graphs and how fast it adapts to the change in the graphs. ORI with four different decoders consistently outperform the existing encoder and decoder-based methods with respect to the accuracy. Note that TM is applied to both existing methods and ours for the fair comparison. It is crucial to emphasize that, in the charged system, our results with almost 40% higher accuracy does not exhibit lower trajectory errors. For example, NRI reaching an accuracy of 52.0% still shows the lower MSE of \(3.80 10^{-3} 4.63 10^{-2}\) over all the prediction steps than our results. This implies the comparison solely using the MSE loss may not indicate the quality of inferred relations at all. The lower MSE in existing methods is probably achieved by the larger capacity than our methods due to the encoder, overfitting to the trajectory modeling, not the relation inference. However, in spring systems, the methods with higher accuracy exhibits lower trajectory errors.

### Inferring Relation in Evolving Interaction Graph and Dynamics

ORI is evaluated on the two additional evolving scenarios in the springs (spr) and charged (cha) systems, where 1) interaction graph and parameter evolve and 2) interaction graph and the dynamics itself evolve. In addition, we analyze the relation learning rate to understand how the relation accuracy responds depending on the learning rate. The yellow, red, and blue curves correspond to ORI with AdaRelation and ORI with constant learning rates (lower and upper bound). Figure 3 presents the relation accuracy and relation learning rate over 30k training iterations in both the evolution scenarios. Although the models tend to slowly converge compared to the springs systems, they can still adapt to the systems with evolving parameters or switching dynamics, reaching the 1.0 accuracy given enough training iterations.

An interesting observation lies in changes of the relation learning rate. For example, in Figure 3 (left bottom), the learning rate in AdaRelation (yellow) automatically increases at the 12k-th

   &  &  \\  & Acc (\%) & mse 1 & mse 10 & mse 20 & mse 30 & Acc (\%) & mse 1 & mse 10 & mse 20 & mse 30 \\  dNRI  & 51.1 & 4.34e-5 & 8.07e-4 & 2.40e-3 & 5.34e-3 & 50.3 & 2.02e-3 & 5.00e-3 & 9.44e-3 & 5.40e-2 \\ NRI  & 57.4 & 1.70e-4 & 1.36e-3 & 4.49e-3 & 1.11e-2 & 52.0 & 3.80e-3 & 1.13e-2 & 2.40e-2 & 4.63e-2 \\ MPM  & 61.6 & 2.76e-4 & 1.10e-3 & 4.10e-3 & 9.15e-3 & 51.7 & 6.16e-3 & 1.12e-2 & 2.60e-2 & 4.86e-2 \\  Ours w/ NRI & 74.5 & 1.45e-4 & 8.19e-4 & 2.71e-3 & 7.32e-3 & 88.6 & 6.60e-3 & 1.61e-2 & 3.79e-2 & 7.33e-2 \\ Ours w/ NRI & 94.2 & 1.24e-4 & 6.02e-4 & 1.71e-3 & 3.44e-3 & 90.9 & 4.87e-3 & 1.47e-2 & 3.54e-2 & 6.85e-2 \\ Ours w/ MPM & 95.2 & 2.80e-4 & 4.54e-4 & 1.43e-3 & 3.16e-3 & **95.3** & 6.98e-3 & 1.35e-2 & 3.00e-2 & 5.91e-2 \\ Ours w/ MPM & **96.4** & 2.59e-4 & 3.74e-4 & 1.17e-3 & 2.62e-3 & 87.1 & 6.85e-3 & 1.42e-2 & 3.25e-2 & 6.26e-2 \\  

Table 2: Comparison with offline learning models in springs and charged systems with evolving interactions. Acc and mse stand for the relation accuracy and mse on the predicted trajectory averaged over the entire training iterations. The number following mse (_e.g._, mse 10) denotes the mse at the 10-th prediction time step.

Figure 2: Prediction results of ORI with MPMr decoder and the baseline MPM in the springs system. (a) the relation accuracy in the two models throughout the training (top) and visualization of the target and predicted adjacency matrix in our model (bottom). (b) target and predicted trajectories in our model.

iteration, decreases over time, and then increases again at the 15k-th iteration. This means that AdaRelation notices a change in the interaction graph of the systems in an unsupervised manner and hence increases the learning rate for a while. This ensures not only the fast adaptation to a new environment but also the stability (_i.e._, less fluctuation in the accuracy) after the relation accuracy converges. Moreover, Figure 3 (right bottom) demonstrates that AdaRelation controls the learning rate depending on the dynamics as well. The models with a high learning rate are stable enough in the springs systems. However, the fluctuation in the accuracy emerges in the charged systems, particularly when the accuracy almost reaches 1. AdaRelation effectively suppresses such fluctuation without sacrificing the convergence speed. For example, between the 18k-th and 21k-th iterations, the accuracy of AdaRelation converges as fast as the high learning rate's one while having much less fluctuation in the later iterations. Thus, AdaRelation effectively enhances the convergence speed, stability, and overall accuracy in evolving multi-agent interacting systems. The related accuracy and ablation studies are available in the supplementary material.

### Discussion on Performance Gain in ORI

We discuss how existing methods fail to clarify the benefit of ORI over them. Since they share the same trajectory predictors, the primary reason should be studied with respect to the encoder side.

Lightweight encoders in existing works.One of the key features in ORI is the encoder-less design, having much fewer trainable parameters, excluding the trajectory predictor, than existing works. To clarify whether the performance gain is from the less trainable parameters, we demonstrate how existing methods perform when their encoder is significantly lightened while having the same decoder. Figure 4(a) showcases the relation accuracy depending on the encoder complexity in the spring system with evolving interaction. However, the performance gain from their lightweight encoders is not significant, indeed still much lower than ORI. Accordingly, we explore the following two additional experiments.

Figure 4: Comparison between ORI and existing methods with respect to the relation accuracy (a), variance in the adjacency matrix (b), and variance in the predicted trajectory (c) depending on encoder complexity. The number in the MPM (-) represents the dimension of hidden states in the encoder.

Figure 3: Prediction results of ORI with NRIr decoder in the charged system with evolving interaction and parameters (a) and ORI with MPMr decoder in the springs and charged systems with evolving interaction and dynamics (b). 1-st row compares the relation accuracy between constant learning rates and AdaRelation. 2-nd row shows changes in the relation learning rate throughout the training.

Changes in inferred relations. Figure 4(b) describes changes in the adjacency matrix (\(D_{I(t)}\)) throughout training in the models with different encoder complexity. Note that \(D_{I(t)}\) estimates how much the current adjacency matrix differs from the past one (_i.e._, \(||I(t)-I(t-w)||_{1}\)). First, the range of \(D_{I(t)}\) in ours is consistent throughout the entire iterations, effectively updating the adjacency matrix from the early stage of training. In contrast, MPMs even with the smaller encoder, such as MPM (64) and MPM (32), exhibit sudden increases in \(D_{I(t)}\) after few thousands iterations. This means that the predicted adjacency matrix is not responding much to the observed trajectory, implying their encoders completely fail to discover the relationship between the observed trajectory and the adjacency matrix. The larger models, MPM (256) and MPM (128), show worse results such as slow increases in \(D_{I(t)}\) and almost no changes in the first 10k training iterations. That is, the lightweight encoder still shows the totally different behavior to ORI and does not effectively update the adjacency matrix in the early stage.

Output variance given true and wrong relations.Following the above paragraph, we study how the slow optimization of the encoder influences the trajectory predictor. Figure 4(c) displays the gap in MSE losses between the output with true interaction graph and one with completely wrong interaction graph over the training iterations. This essentially represents how sensitive the trajectory predictor is to the input interaction graph. ORI demonstrates a clearly larger gap in the MSE losses than all the other MPM models. Apart from ORI, the smaller encoders increase the MSE gap in the trajectory predictor. That is, the failure in the encoder degrades the trajectory predictor, which potentially influences the encoder again. In summary, allocating the trainable adjacency matrix in ORI ensures the stable update in the embedding adjacency matrix to the trajectory predictor and enhances its output variance depending on the interaction graph.

### Real-world Application

ORI is assessed in the real-world human motion dataset (CMU MoCap)  against existing offline methods. Figure 5 showcases the target and predicted trajectories on walking motion from ORI (1-st row) and the top-30 strongest relations between joints in a skeleton model for the corresponding frame (2-nd row). Additionally, the figure incorporates the inferred relations from MPM (3-rd row). The visual comparison illustrates that ORI's predicted joint trajectories closely align with the target, yet ORI exhibits higher MSE loss compared to MPM (see the supplementary material). However, similar with the observation in the charged systems (Table 2), ORI appears to offer more interpretable relation inference on the joints. For example, in 3-rd row of the figure, MPM simplifies the relational inference by cyclically focusing on right foot, left foot, and right foot again. In contrast, ORI introduces an additional layer of shifts in the relation, emphasizing primary connections between left foot, right knee, and right foot. This additional detail improves the interpretability of the walking motion.

Figure 5: Prediction results of ORI with MPMr decoder and MPM in CMU MoCap dataset. 1-st row represents the last frame in the predicted and target trajectory from ORI. 2-nd and 3-rd rows visualize the top-30 strongest interaction edges in the corresponding frame from ORI and MPM. Note that MPM allocate higher relation strengths in the front foot while ORI focuses on the foot behind.

Conclusion

Summary.We introduced Online Relational Inference (ORI), a novel framework for online relational inference in evolving multi-agent interacting systems. ORI employs an adaptive learning rate technique, AdaRelation, allowing it to adapt dynamically to changing environments through online backpropagation. Our approach also includes the Trajectory Mirror (TM) data augmentation method to enhance generalization. This model-agnostic framework seamlessly integrates with various neural relational inference architectures, providing a robust solution for real-time applications in complex, evolving systems. Future work will focus on enhancing the adaptability in more fast-evolving interaction and exploring its applicability to a wider range of multi-agent systems.

Limitation and future work.Our current experiments do not evaluate ORI in non-ideal environments, incorporating directed interaction graphs or/and variable number of nodes. This limits the potential of ORI in relatively ideal environments. We expect that ORI can be extended to scenarios when agents are added or deleted, provided we are aware of which agent is added and deleted by adding and deleting corresponding row and column in the adjacency matrix. While the experiments in the paper do not explicitly include directed interactions, ORI does not assume any symmetry (undirected graph) in the adjacency matrix. In other words, there is no technical limitation to apply ORI in directed interaction.