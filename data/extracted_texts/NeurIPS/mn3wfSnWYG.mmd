# Fast and Scalable Inference of Dynamical Systems via Integral Matching

Baptiste T. Rossi

MIT

Cambridge, MA

brossi@mit.edu &Dimitris J. Bertsimas

MIT

Cambridge, MA

dbertsim@mit.edu

###### Abstract

We present a novel approach to identifying parameters of nonlinear Ordinary Differential Equations (ODEs). This method, which is based on collocation methods, enables the direct identification of parameters from time series data by matching the integral of the dynamic with an interpolation of the trajectory. This method is distinct from existing literature in that it does not require ODE solvers or an estimate of the time derivative. Furthermore, batching strategies, by time subintervals and component of the state, are proposed to improve scalability, thus providing a fast and highly parallel method to evaluate gradients, and a faster convergence than adjoint methods. The effectiveness of the method is demonstrated on chaotic systems, with speed-ups of three orders of magnitude compared to adjoint methods, and its robustness to observational noise and data availability is assessed.

## 1 Introduction

This paper introduces a new approach for learning coefficients of ordinary differential equations from time series data. We focus on scalability and universality to learn possibly high-dimensional systems from large datasets while making minimal assumptions on the equations. The resulting algorithm can be used to infer parameters of equations derived from scientific laws or, when no prior structure is known, to train universal approximators such as the Neural ODEs from Chen et al. (2018).

### The problem

Let \((t)^{n}\) be the state of a system of dimension \(n\) at time \(t\). We have \(M\) observations \((t_{m})\) over a single trajectory, where \(t_{m}[0,T]\) for all \(m=1 M\), and are interested in the inverse problem of inferring parameters \(^{*}\) and an initial condition \(_{0}^{*}\) that minimize the prediction error on \(}(t)\):

\[_{_{0},} _{m[M]}\|}(t_{m})-(t_{ m})\|^{2}\] (1a) \[ }(t)=f(}(t),),  t,\] \[}(0)=_{0}.\] (1b)

\(}\) is Newton's notation for the time derivative \(}{dt}\). \(f\) and \(\) parameterize the dynamic, which can include dynamics where each component of \(f\) is a polynomial of the state, as well as Neural ODEs as

Figure 1: On the damped oscillator from Chen et al. (2018), our algorithm (blue) fits a neural ODE with fewer network evaluations and to greater accuracy than Backpropagation through time (BPTT) (red) and Adjoint sensitivity (orange). The best accuracy reached by the adjoint sensitivity within 15 minutes on CPU is reached after only 2.5s by the proposed method. The number of evaluation is reduced respectively by a factor 95 and 328 compared to BPTT and Adjoint and computation times are divided by a factor 50 to 450.

in Chen et al. (2018). Moreover, it is not necessary for observations to be simultaneously available for each dimension; the loss is only computed for the dimensions where observations are present.

## 2 Background and related work

The inverse problem (1), has been widely studied in optimal control where it is referred to as system identification and in scientific machine learning, with renewed interest since the Neural ODEs in Chen et al. (2018); Rubanova et al. (2019). The existing literature splits into direct approaches that solve Problem (1) using numerical integration method (ODE Solvers), and surrogate methods.

Direct approaches:In this family of methods, the continuous Problem (1) is solved by alternating between numerical integrations of the dynamic given a choice of parameters \(\) and gradient-based parameter updates. Balancing accuracy, memory, and computational complexity leads to a variety of techniques. The continous version of the Backpropagation Through Time (BPTT) method used to train Recurrent Neural Networks (RNNs) is obtained by differentiating through the operations of an ODE Solver using an automatic differentiation framework such as Pytorch Paszke et al. (2019) or JAX Bradbury et al. (2018), or through a custom ODE Solver as for Liquid Time-Constant (LTC) networks in Hasani et al. (2020) or in Forgione and Piga (2021). Memory usage can be decreased compared to these methods by utilizing one additional backward numerical integration to estimate the gradient using the Pontryagin principle in the adjoint sensitivity method, as described in Chen et al. (2018). To solve numerical discrepancies between the forward and backward integrations, adaptive checkpointing (ACA) methods have been developed in Zhuang et al. (2020) to partially mitigate the problem, while in Kim et al. (2021) the forward pass is completely stored in memory and only the adjoint is integrated backwards. Inherently, direct methods require an estimate of the initial condition, which can reduce the accuracy of the gradients on chaotic systems so that shooting methods can be used to consider smaller subtrajectories, albeit reducing the ability of these methods to interpolate between observations. We compare the memory and computational complexity of the method in this paper to direct methods in Table 1. The initialization of parameters may impact convergence as the optimization landscape is non convex, see Varah (1982). Additionally, bifurcations may lead to instability, where random weight initialization or updates can cause trajectories to diverge or require numerous adaptive steps. See Section 4 for a comparison of wall-clock times among methods.

Surrogate methods:Gradient matching was proposed in Varah (1982) and involves smoothing the trajectory to estimate the trajectory and its time derivative (the gradient) before adjusting parameters \(\) to match the estimated gradients along the trajectory. Different optimization algorithms are discussed in Varah (1982); Ramsay et al. (2007); Tjoa and Biegler (1991), which involve block descent and various update techniques. Niu et al. (2016) provides a framework for these algorithms by using a reproducing kernel approach. The Sparse Identification of Nonlinear Dynamics (SINDy) framework, introduced in Brunton et al. (2016) combines gradient matching with sparse regression when \(f\) is a linear combination of nonlinear functions. Weak formulations and integral form using trapezoidal integration for regularly sampled data are presented in Messenger and Bortz (2021); Schaeffer and McCalla (2017). Calderhead et al. (2008); Dondelinger et al. (2013) have explored Bayesian approaches that combine gradient matching with sampling strategies and Bayesian updates.

   Method & Adapt. & Stiff & \#NFE & Memory & Accuracy & Ref \\  Adjoint-RK & ✓ & ✗ & \(4KN\) & \((n)\) & \(\,|\,\) & Chen et al. (2018) \\ BPTT-RK & ✓ & ✓ & \(2KN\) & \((nN)\) & \(\,|\,\) & Gruslys et al. (2016) \\ ACA-CVODE & ✓ & ✓ & \(4KN\) & \((nN)\) & \(\,|\,\) & Zhuang et al. (2020) \\ LTC & ✗ & ✓ & \(2KN(4,T)\) & \((nN(4,T))\) & \(\,|\,\) & Hasani et al. (2020) \\  This paper & ✗ & ✓ & \(2KN\) & \((nK)\) & \(\,|\,\) & \\   

Table 1: Efficiency comparison: Function Evaluations (Forward/Backpropagation) and memory. Our method is more effective computationally at the cost of a controlled memory overhead. An explicit Runge-Kutta method of order \(K\) uses \(N(K,T)=(^{-1/K}T)\) steps, our method uses \(=(^{-1/2K-1}T)\).

### Collocation methods

In recent decades, the use of collocation methods for computing numerical solutions to optimal control problems has become increasingly popular (see Betts (2010); Ljung (1999)). These are implicit integration techniques in which the values of the state and control (in our case, the parameters \(\)) at the discretization nodes are treated as decision variables. Constraints ensure that the dynamics are satisfied at the nodes, resulting in a nonlinear optimization problem. Although, as noted in Varah (1982), these methods justify gradient matching methods, to the best of our knowledge, their use as numerical integration method to the learning problem is original. In this paper, we use the selection of nodes from the Legendre-Gauss-Radau (LGR) method for its suitability to initial value problems. This choice results in an implicit technique that is A-stable, i.e., with numerical stability guarantees for classes of initial value problems, and symplectic, i.e., preserving the Hamiltonian of the system. Additionally, it has an approximation error of \(o(h^{2K-1})\), where \(K\) is the degree of the approximating polynomial and \(h\), the size of the time step. see Fahroo and Ross (2008); Garg et al. (2011) for more discussions and proofs. Other choices of collocation method are compatible with our approach, although, as shown in Wei et al. (2016), using a Gaussian quadrature collocation method ensures that the KKT optimality conditions on the discretized problem are a discretization of the Pontryagin Principle, which connects our method to the adjoint sensitivity methods mentioned earlier.

### Contributions

This paper presents a new surrogate approach addressing the direct problem on the trajectory by using collocation methods to eliminate the need for estimating derivatives from (noisy) data, and to provide accurate integral solutions without relying on ODE solvers. The method scales well with dataset size and horizon length \(T\), by using low-dimensional regressions on fixed length subintervals, and to large dimensions of the state as components can be learned independently in parallel.

We evaluate our approach on synthetic experiments and also examine experimentally the limitations of our method's reliance on data and design principles. In particular, interpolation before learning coefficients can lead to failure if the available data cannot recover a relevant trajectory.

## 3 Algorithm

The algorithm, _Batched Integral Matching_, whose pseudo code is Algorithm 1, alternates between linear regressions estimating vectors \(_{l}\) of values of the state at LGR points and gradient descents minimizing the loss \(\):

\[()=_{i=1}^{N-1}_{l=1}^{n}\|}^{-1} _{i}(}^{},)-^{k} }_{i}\|^{2}\]

Which is a collocation based approximation of:

\[_{i=1}^{N-1}_{l=1}^{n}_{k=1}^{K}\|_{t_{i-1}}^{t_{i-1}+h_{i} _{k}}}(t)-((),)dt\|^{2}\]

Where \(h_{i}=t_{i+1}-t_{i}\). The separable structure of the loss \(\) allows for batching strategies. Section 3.1 details the steps from the continuous problem to the problem of minimizing the introduced loss \(\). Section 4 presents experimental results.

### Theoretical foundations of the algorithm

This section presents the derivation of the loss \(\) and its theoretical motivation.

We discretize the continuous problem (1) using a multistep LGR collocation: the state is approximated by continuous piecewise polynomials of degree \(K\) on a subdivision: \(0=t_{1}<<t_{N}=T\). Then, subintervals are rescaled to \(\), and the polynomials are represented in the Lagrange polynomials basis \((l_{j})_{j=0,,K}\) associated with the LGR points \((_{j})_{j=0,,K}\): on the \(i\)th subinterval, of length \(h_{i}=t_{i+1}-t_{i}\), we use the change of variable: \(t=t_{i}+ h_{i}\). Using the vector \(}^{n(K+1)}\) obtainedby stacking the \(_{ij}=(t_{i}+h_{i}_{j})\) by component, then index \(j\), the state and its derivative are:

\[ t[t_{i},t_{i+1}],=}{h_{i}},\;(t)=_{j=0 }^{K}l_{j}()_{ij}=()_{i},\;}(t)=}_{j=0}^{K}t_{j}^{}()_{ij}=}()_{i}\]

Using this approximation, we obtain the classical collocation based formulation, Problem (2):

\[_{,_{0}\\ (_{i})_{i}} _{i=1}^{N-1}_{m[M]\\ t_{m}[t_{i},t_{i+1}]}\|(-t_{i}}{h_ {i}})_{i}-(t_{m})\|^{2}\] \[ (0)_{1}=_{0},\] (2a) \[(0)_{i}=(1)_{i-1}, i 2,...,N-1,\] (2b) \[(_{j})_{i}=h_{i}f(_{ij},). \] (2c)

Noting that the continuity constraints (2b) do not directly link the variables \(_{i}\) and \(_{j}\) when \(i j\), their relaxation transforms the problem into a multiple subtrajectories problem with shared parameters \(\), with a natural link to shooting methods.

As detailed in appendix D, the single subinterval problem has a special structure that is later used to reformulate the multi-trajectories problem: on a single subinterval \([a,a+h]\), Problem (2) has a block diagonal matrix of constraints \(}=diag(}_{K},,}_{K})\), where \(}_{K}\) is invertible and \(\), which consists of evaluations of \(f\) at the collocation nodes:

\[_{,\\ } _{m[M]}\|(-a}{h})-(t_{m})\|^{2}\] (3) \[ }=(,).\]

The \(k\)th component of \(\) is: \((,)_{k}=_{k(K+1)},hf( (_{1}),)_{k},,hf((_{K})), )_{k}^{T}\).

Using the invertibility, we consider from now on the problem in integral form

\[_{,\\ } _{m[M]}\|(-a}{h})-(t_{m})\|^{2}\] (4) \[ =}^{-1}(,).\]

Lastly, \(}_{K}^{-1}\) has a special structure: \( k,}_{K}^{-1}(,)_{ k}=_{k(K+1)}+h_{K}^{-1}}(, )_{k}\) where \(}(,)_{k}=(f((_{1}), )_{k},,f((_{K})),)_{k})^{T}\) and \(_{K}^{-1}\) is another matrix that can be precomputed. Details and proofs can be found in appendices D and E and rely on permutations of constraints by component and the invertibility is due to the polynomial interpretation of the differentiation matrix \(\). The special structure allows for a reduction in complexity of the matrix multiplication from a \(K+1\) by \(K+1\) square matrix to a \(K\) by \(K\) square matrix.

Finally, we obtain Problem (5) from Problem (2) by relaxing continuity constraints and, using augmented lagrangian ideas, by introducing a quadratic penalty on the integral form, weighted by \(>0\) discussed after:

\[_{,\\ (_{i})_{i}} _{i=1}^{N-1}_{m[M]\\ t_{m}[t_{i},t_{i+1}]}\|(-t_{i}}{h_ {i}})_{i}-(t_{m})\|^{2}+_{i=1}^{N-1}\| }^{-1}_{i}(_{i},)- _{i}\|^{2}.\] (5)

Using the block diagonal structure of \(}\) and expanding the norms, the problem becomes:

\[_{} _{i=1}^{N-1}_{l=1}^{n}m[M]\\ t_{m}[t_{i},t_{i+1}]}\|(-t_{i}}{h_ {i}})_{il}-_{l}(t_{m})\|^{2}}_{r_{l}(_{ })}+}_{ }^{-1}_{i}(_{},)_{l}- _{}\|^{2}}_{s_{i}(_{})}.\] (6)We solve this last formulation with Algorithm (1), inspired by the Alternating Direction Method of Multipliers (ADMM) from Boyd et al. (2011). The algorithm alternates between linear regressions that estimate the trajectory at LGR nodes and system inversion steps that use gradient descent to fit parameters \(\) to match integrals. We set \(=1\) as it only affects gradient estimation, not parameter optimization. In practice, good results can be obtained by using a pool of overlapping subintervals and going over the pool during training epochs, thus caching computations from linear regressions. Note: using a pure ADMM approach would have brought the algorithm close to the alternating updates of parameters of an interpolating Reproducing Kernel and the parameters of ODEs to be infered, as studied in Niu et al. (2016). In that latter case, and more broadly, the use collocation methods in an integral form leads to a problem on the trajectory directly, which is generally easier to estimate than the derivative. Such a difference may explain the enhancement in robustness to noise on observations over gradient matching methods as observed in section 4.

The design of the loss is such that, if the estimates at Gauss-Radau nodes are accurate and the loss at convergence is zero, then the simulation of the trained model will be an exact match to the observed trajectory of the system, apart from the integration error due to the collocation method of order \(K\).

Reexamining the relaxation of continuityRelaxing continuity between adjacent subintervals controls the propagation of integration errors over the horizon, and also makes the method less vulnerable to inaccurate initial conditions. Those two properties are to learn chaotic systems. Ultimately, overlapping intervals allow the continuity of state components contained in the data to be transferred back to the estimated trajectory by data and ultimately to the solution through the loss function.

Speed-upsEvaluating \(}\) and its gradient requires the evaluation of \(f\) at each LGR node of each subinterval. Since the values at these nodes are already known when estimating the gradient, the evaluation of the value and the gradient is performed in the software and hardware optimized setting of a parallel batch evaluation. Furthermore, when parameters \(\) can be partitioned by state component, such as in polynomial dynamics, problem (6) separates by component that can be learned independently and in parallel, facilitating the learning of high-dimensional states.

Estimating the trajectory: the added value of denoisingThe performance of the proposed method is dependent on the accuracy of the values estimated at the collocation nodes. The distribution of discretization nodes over the interval \(\) is not uniform, with more density near the boundaries and can lead to artifacts in noisy settings at the boundaries. To address this, we use a simple sliding window technique inspired by Savitzky and Golay (1964). See Appendix A for more details.

## 4 Experiments

For each dynamical system in the benchmark, each experiment consists in running a simulation of the dynamic from a random initial condition and running the algorithms on observations corrupted by with Gaussian noise. As our method is capable of handling arbitrary dynamics, we use baselines that are suited to structure of \(f\). We also report runtimes and compare the number of function evaluations.

We study the raw performance of the training procedure on Section 4.1, higher-dimensional problems in Section 4.2, failure modes of the algorithm in Section 4.3 and its complexity in Section 4.4.

### Raw performance on the learning of accurate models from noisy observations

We first consider the following canonical examples of chaotic systems: the Lorenz 63 attractor Lorenz (1963), the Rossler attractor Rossler (1976), the Duffing model Duffing and Emde (1918). Those systems are of dimensions up to 4 and are polynomials of degree up to 3. We implemented the algorithm in Python (PyTorch and JAX) and Julia.

Learning Polynomial dynamics:We start by fitting the coefficients of polynomial dynamics of degree 3 that contain the original equations along with other terms and compare our method (IMATCH) to the SINDy approach from Brunton et al. (2016), for different levels of noise. These experiments, reported in Table 2, show that our algorithm learns meaningful models, even when the observations are noisy. It should be noted that no regularization was used in our method for these experiments. SINDy, on the other hand, applies thresholding to coefficients which aids its accuracy, as the underlying model is sparse and could explain why SINDy has a slight advantage in noiseless cases. In noisy conditions, our method, which operates on a smoothed trajectory rather than SINDy's finite differences, has a considerable edge.

Learning Neural ODESWe first considered the same damped oscillator as in Chen et al. (2018) and a simple network with one hidden layer of size \(50\) (202 parameters) and ReLU activation, as indicated in Table 3. On this task, our method outperformed ODE Solver-based approaches by almost two orders of magnitude. To analyze the reasons for this improvement, we compared various metrics: global wall clock time, time to evaluate a gradient for a batch of 20 observations, and the number of function evaluations. In Figure 1, we present a comparison on a training trajectory with the same data and initialization strategy. The \(x\) axis is the number of function evaluations. While the figure represents one training trajectory, the observations and orders of magnitude are consistent across multiple experiments. In total, our method achieves similar RMSEs on the test set with 95 to 320 times fewer function evaluations up to 99.7% reduction compared to ODE Solver methods, and, function evaluations are faster by order of magnitudes due to batching and parallelism, up to a 25,000 speed up on gradient estimation for our instance, on CPU. We then trained a simple ResNet architecture with 300 hidden units (90,000 parameters) and two shared residual blocks with ReLU activations, on the Lorenz63 model and present results in Table 4. On a Tesla T4 GPU, an RMSE of around 1% was obtained within 20 minutes with our method. See appendix B for more details.

Learning coefficients in nonlinear structuresThe FitzHugh-Nagumo model FitzHugh (1961) is a common benchmark in the gradient matching literature as though this model is polynomial in the state, the parameters to be inferred have nonlinearities contrary to the previous systems. We find that our method yields similar errors on the coefficients as the Bayesian approach in Calderhead et al. (2008) in only \(5\)s, which is at least two times faster than the results from this reference.

    & RMSE \(}\) (\%) & RMSE \(}\) (\%) & RMSE \(}\) (\%) \\ Method & 3 min. & 5 min. & 10 min. \\  Integral Matching & \(4.31 0.5\) & \(3.8 0.4\) & \(3.4 0.4\) \\ BPTT & \(41.51 3.29\) & \(32.20 2.46\) & \(21.83 2.13\) \\ Adjoint & \(91.87 2.93\) & \(87.89 4.37\) & \(80.73 4.79\) \\   

Table 4: Learning the Lorenz63 model with Neural Networks: comparison of performance between our method and adjoint based methods for various execution times, \(5\%\) noise added.

    & &  \\ Metric & Model & Method & 0\% & 5\% & 10\% & 20\% \\   & Lorenz63 & SINDY & \(\) & \(7.45 5.9\) & \(10.77 0.4\) & \(22.95 3.4\) \\  & Lorenz63 & IMATCH & \(\) & \(\) & \(\) & \(\) \\ RMSE (\%) & Rossler & SINDY & \(0.02\) & \(4.3 0.5\) & \(12.15 1.0\) & \(26.95 2.3\) \\ \(}\)(\%) & Rossler & IMATCH & \(<}\) & \(\) & \(\) & \(\) \\  & Duffing & SINDY & \(\) & \(5.64 0.3\) & \(9.79 0.3\) & \(13.27 1.2\) \\  & Duffing & IMATCH & \(0.34\) & \(\) & \(\) & \(\) \\   

Table 2: On polynomial dynamics: for \(T=40\), our method with subintervals of length \(1\) and an integration order \(K=30\) outperforms the SINDy method in noisy settings

    & &  & \# NFEs & & Speed-up per \\ Method & RMSE \(}\) (\%) & time (s) & (\(10^{6}\)) & Total time (s) & gradient \\  Ours & \(1.61\)\([1.47,1.77]\) & \(1.8\)\(10^{-5}\) & \(3.1\) & \(2.08\)\([1.01,3.69]\) & \\ BPTT & \(1.78\)\([1.19,3.37]\) & \(510^{-2}\) & \(3.9\) & \(100.5\)\([88.9,116.3]\) & \(2777\) \\ Adjoint & \(1.83\)\([1.15,2.57]\) & \(4.510^{-1}\) & \(28.8\) & \(959.8\)\([909.,993.9]\) & \(25000\) \\   

Table 3: We conducted a benchmark of 40 runs of each algorithm on a CPU to compare the runtime performances of learning a spiral dynamic in Chen et al. (2018) using a neural network with one hidden layer containing 50 neurons. Our algorithm was found to compute gradients almost two orders of magnitude faster than the backpropagation through the solver (BPTT) and three orders of magnitude faster than the adjoint. Computation times were measured for 2000 iterations of the adjoint/BPTT with the default parameters from the official Neural ODE library and a stopping criterion on the loss of \(10^{-4}\) for our method. The results are given as the 1st and 9th decile intervals.

### Learning chaotic systems in high dimensions

The Lorenz (1996) family of models represent chaotic systems of arbitary dimensions. We focus on the \(40\) dimension model with forcing terms of \(16\), exhibiting 9 positive eigenvalues for the linearized equation around the equilibrium, leading to very chaotic evolutions, see Sapsis and Majda (2013).

This model represents a significant jump in complexity compared to the previous canonical examples. We consider trajectories obtained from an initial equilibrium with a disturbance that is typically below the numerical tolerance errors: these systems can fail many adjoint methods from the start. To promote sparsity, we used a simple sequential thresholding heuristic: small values of parameters were successively projected to \(0\) and the model retrained. The results presented in Figure 2 exhibit a phase transition that we conjecture to be associated with sparsity and the large dimension of the system.

### Limitations and impact of data quality and availability on the learned model

Taking an opposite view to observing longer trajectories, we observe a phase transition to failure when the available signal decreases: the RMSE of the learned model increases with the signal-to-noise ratio until a certain point where the algorithm's performance deteriorates. Denoising delays the performance collapse and slows down error growth but when the interpolation is not relevant for too many subintervals to be averaged, convergence fails.

This hints at a limitation of the presented version, which relies on fixed length subintervals and orders. If the integration order \(K\) needs not be fixed (aside from easing implementation and providing a rigid computation graph), we can in principle use variable-length subintervals. Another observed failure mode on neural ODEs happens when the integrated trajectory diverges from the trajectory that was fitted: contrary to adjoint based methods that have been trained around the training trajectory, potentially outside of its manifold, our method is sharp around the observations, so that the structure of equations or the variety of the observed trajectory is paramount. To solve these limitations, given its speed, our method can be used to warm start an ODE Solver method, with a relevant prior.

### Comparison of the number of backpropagations with ODE solvers methods

We complement the theoretical estimates from Table 1 by a experimental comparison on the Lorenz63 model. While adaptive methods involve varying step numbers during descent, our analysis provides a static estimation that hints at the significant computational gap between methods. To avoid interference with measurement times, we only compute the state at \(t=T\) (\(M=1\)). We present averaged results for ODE solvers recommended for Neural ODEs in Table 5. Experiments reveal that our method requires between 10 to 40 times fewer backpropagations on the neural network \(f\) than standard stiff methods for Neural ODEs. On the Lorenz96 with 40 dimensions, this gap widens further to a factor of 20 when comparing \(K=30\) to its closest contender BDF. Looking at Table 5 and Figure 3, a natural question is the choice of \(K\). Increasing \(K\) improves accuracy but also increases data requirements and computational costs due to the super-quadratic complexity of matrix multiplication (Strassen or Fawzi et al. (2022)). A higher \(K\) might also capture more noise, putting an emphasis on denoising. In our experiments, using \(K=30\) and \(h=1\) yielded satisfactory results in terms of accuracy and runtime.

Figure 2: For the Lorenz96 model, for various levels of noise and observed length, we plot (top) The RMSE of the error on the derivative, (middle) the true positive rate of the non zero terms identified in equations, (bottom) the relative error on parameters

## 5 Conclusion

In conclusion, we have studied the utilization of collocation methods for system identification of nonlinear dynamical systems. While collocation methods are typically computationally intensive due to their implicit nature, we have leveraged data to simplify computations, opening up new possibilities, particularly in applications where abundant data is available and trajectories can be reliably estimated. Our method are more efficient as they require less backpropagation that existing methods to evaluate gradients at each step of the descent, and offer effective batching strategies to parallelize computations. We hope these advancements can have significant implications for the field of dynamical system modeling and help improve our understanding of underlying dynamics.