# Rethinking Evaluation Strategy for Temporal Link Prediction through Counterfactual Analysis

Aniq Ur Rahman\({}^{1}\) Alexander Modell\({}^{2}\) Justin P. Coon\({}^{1}\)

\({}^{1}\)University of Oxford, U.K. \({}^{2}\)Imperial College London, U.K.

aniq.rahman@eng.ox.ac.uk, a.modell@imperial.ac.uk, justin.coon@eng.ox.ac.uk

###### Abstract

In response to critiques of existing evaluation methods for Temporal Link Prediction (TLP) models, we propose a novel approach to verify if these models truly capture temporal patterns in the data. Our method involves a sanity check formulated as a counterfactual question: "What if a TLP model is tested on a temporally distorted version of the data instead of the real data?" Ideally, a TLP model that effectively learns temporal patterns should perform worse on temporally distorted data compared to real data. We provide an in-depth analysis of this hypothesis and introduce two data distortion techniques to assess well-known TLP models. Our contributions are threefold: (1) We introduce simple techniques to distort temporal patterns within a graph, generating temporally distorted test splits of well-known datasets for sanity checks. These distortion methods are applicable to any temporal graph dataset. (2) We perform counterfactual analysis on TLP models such as JODIE, TGAT, TGN, and CAWN to evaluate their capability in capturing temporal patterns across different datasets. (3) We propose an alternative evaluation strategy for TLP, addressing the limitations of binary classification and ranking methods, and introduce two metrics - average time difference (ATD) and average count difference (ACD) - to provide a comprehensive measure of a model's predictive performance. The code and datasets are available at: https://github.com/Aniq55/TLPCF.git.

## 1 Introduction

In static graphs, link prediction refers to the task of predicting whether an edge exists between two nodes after having observed other edges in the graph. Temporal link prediction (TLP) is a dynamic extension of link prediction wherein the task is to predict whether a link (edge) exists between any two nodes in the future based on the historical observations (Qin and Yeung, 2023). The predictive capability of TLP models make them useful in applications pertaining to dynamic graphs, such as product recommendations (Qin et al., 2024; Fan et al., 2021), social network content or account recommendation (Fan et al., 2019; Daud et al., 2020), fraud detection in financial networks (Kim et al., 2024), and resource allocation, to name a few.

In the TLP literature (Kumar et al., 2019; Trivedi et al., 2019; Xu et al., 2020; Rossi et al., 2020; Wang et al., 2020; Cong et al., 2023), the TLP task is treated as a binary classification problem where the query

\[_{1}:\]

is processed by a model and then compared with the ground truth following which metrics such as area under the receiver operating characteristic curve (AU-ROC), and average precision (AP) are reported. The ground truth consists of positive samples, and a fixed number of random negative samples. There are a couple of issues in the binary classification approach. Firstly, the timestamps in the query are restricted to the timestamps present in the ground truth, which makes the evaluationbiased and does not test the model's performance in the continuous time range. Secondly, checking for the existence of an edge at a specific timestamp is an ill-posed question, and instead the existence of an edge should be queried within a finite time-interval. Lastly, the negative edge sampling strategy, and the number of negative samples per positive sample impact the performance metrics as seen in EXH(Poursafaei and Rabbany, 2023).

Alternatively, in a rank-based approach, the query is formulated as:

\[_{2}:\]

In this case, the model returns an ordered list of nodes arranged from most likely to least likely. Then, the rank of the ground truth edge is returned if a match is found, and if not, a high number is reported. For all the edges in the test data, metrics such as Mean Average Rank (MAR) or Mean Reciprocal Rank (MRR) can be reported to assess the performance of the model (Huang et al., 2024). While the rank-based metrics are more intuitive than AU-ROC and AP, the issues regarding binary classification mentioned above still remain unaddressed. To give a true picture of the predictive power of the TLP models, a penalty term should be introduced to account for the nodes that are incorrectly estimated to form an edge with node \(u\) at time \(t\).

In a recent work, Poursafaei et al. (2022) highlighted that the state-of-the-art (SoTA) performance of some TLP models on the standard benchmark datasets is near-perfect. This is counterintuitive because TLP is a challenging task, even more challenging than link prediction of static graphs, due to the additional degree of freedom in the data induced by the temporal dimension. The flaw in the evaluation method is attributed to the limited negative sampling strategy, and the authors propose a new negative edge sampling strategy which results in a different ranking of the baselines.

Inspired by the critique of the evaluation method, we propose a method to conduct sanity check of the TLP models to determine if they truly capture the temporal patterns in the data. The sanity check is formulated as the counterfactual question (Pearl, 2019):

"What if a TLP model which is trained on a temporal graph is tested on _temporally distorted_ version of the data instead of the real data?"

Ideally, a TLP model which is capable of learning the temporal patterns should perform worse on temporally distorted data compared to the real data. We conduct an in-depth analysis of this argument and introduce various data distortion techniques to assess well-known TLP models.

ContributionsThe contributions of our work can be summarised as follows:

* We introduce simple **techniques** to distort the temporal patterns within a graph. These techniques are then used to generate temporally distorted version of the test split of some famous datasets which can be used for **sanity check**. Moreover, the distortion methods can be applied to any temporal graph dataset.
* We perform **counterfactual analysis** on TLP models such as JODIE(Kumar et al., 2019), TGAT(Xu et al., 2020), TGN(Rossi et al., 2020), and CAWN(Wang et al., 2020) to check whether they are capable of capturing the temporal patters within various datasets.
* We propose an alternative **evaluation strategy** for TLP through which the existing pitfalls of binary classification and ranking methods can be avoided. We also propose two **metrics**: average time difference (ATD), and average count difference (ACD) to measure the performance of TLP models. These metrics can provide a holistic picture of a model's predictive performance.

OrganizationIn Sec. 2, we define temporal graphs and the associated notations. We also provide a brief overview of interpreting temporal graphs as point processes, which forms the theoretical foundation of TLP. In Sec. 3, we formalize the counterfactual analysis through logical arguments, and also propose data distortion techniques. The results of the counterfactual analysis are presented in Sec. 4 along with the details of the datasets and TLP models used for evaluation. In Sec. 5, we suggest a generative evaluation approach for TLP, and discuss the broader impact and limitations of our work.

Preliminaries

### Definitions

In TLP literature, continuous-time temporal graphs with _ephemeral edges_ are often considered, where edges represent interaction events between two nodes at a specific point in time. Alternatively, temporal graphs can be defined with edges that appear at a certain time and either persist for a duration (Celikkanat et al., 2024; Farzaneh and Coon, 2023) or accumulate indefinitely. In this work, we focus on the ephemeral edge temporal graph, also known as interaction graphs (Qin et al., 2024) or unevenly sampled edge sequence (Qin and Yeung, 2023).

**Definition 2.1**.: A **temporal graph** with \(m\) ephemeral edges formed between nodes in \(\) and \(\) is defined as \(=(,,)\), where \(\{(u_{i},v_{i},t_{i}):i[m],u_{i},v_{i} ,t_{i}\}\) denotes the set of edges. The tuple \((u,v,t)\) is referred to as an edge event.

While the definition caters to bipartite structure, with \(=\), it can also represent general graphs.

**Definition 2.2**.: The occurrences of a particular edge \((u,v)\) in \(\) is denoted as \(_{(u,v)}\) and defined as \(_{(u,v)}\{(u,v,t):(u,v,t)\}\).

**Definition 2.3**.: The slice of edges in \(\) with timestamps in the range \((t_{1},t_{2})\) is denoted as \((t_{1},t_{2})\), and defined as \((t_{1},t_{2})\{(u,v,t):(u,v,t),t(t_{1}, t_{2})\}\).

**Definition 2.4**.: The timestamps in \(\) consisting of \(m\) edges can be extracted through a function \(:()^{m}^{m}\) as \(()\{t:(u,v,t)\}\).

### Point Process

Perry and Wolfe (2013) modelled the interaction events of a directed edge \((u,v)\) as an inhomoegenous Poisson point process. In a recent work on continuous-time representation learning on temporal graphs, Modell et al. (2024) followed suit, and assumed \(_{(u,v)}\) to be sampled from an independent inhomogenous Poisson point process with intensity \(_{(u,v)}(t)\). The number of edge events \((u,v)\) between timestamps \(t_{1}\) and \(t_{2}\) follow a Poisson distribution with rate \(_{t_{1}}^{t_{2}}_{(u,v)}(t)\,dt\), i.e.,

\[|_{(u,v)}(t_{1},t_{2})|(_{t_{1}}^{t_{2 }}_{(u,v)}(t)\,dt).\] (1)

To connect the present to the past, Du et al. (2016) view the intensity function \(^{}_{(u,v)}(t)\) as a nonlinear function of the sample history, where \(\) indicates that the function is conditioned on the history. The conditional density function for edge \((u,v)\) is written as

\[p^{}_{(u,v)}(t)=^{}_{(u,v)}(t)(-_{t^{}}^{ t}^{}_{(u,v)}()\,d),\] (2)

where \(t^{}<t\) is the last time when edge \((u,v)\) was observed. The goal is to find the parameters \(^{}_{(u,v)}(t):0<t T\) which can describe the observation \(_{(u,v)}\). This is done by minimizing the negative log likelihood (NLL) at the timestamps of edge occurrence (Shchur et al., 2021):

\[_{^{}_{(u,v)}(t):\,0<t T}-_{t( _{(u,v)})}(^{}_{(u,v)}(t))+_{0 }^{T}^{}_{(u,v)}()\,d, T=( _{(u,v)}).\] (3)

In (Shchur et al., 2021), the operation of a neural temporal point process is summarized as:

* The edge events in \(\{(u,v,t_{i}):i[m]\}\) are represented as feature vectors \(_{i}=f_{}(u,v,t_{i})\),
* The historical feature vectors are encoded into a state vector \(_{i}=f_{}(_{1},_{i-1})\),
* The distribution of \(t_{i}\) conditioned on the past is simply conditioned on \(_{i}\).

The functions \(f_{}\) and \(f_{}\), as well as the conditioning on \(_{i}\), can be implemented using neural networks.

**Conjecture 2.1**.: _The samples from a neural temporal point process are **learnable**, i.e., a model exists which can perform temporal link predictions based on the past observations._

## 3 Counterfactual Analysis

Experiment SetupA model \(f\) is trained on a temporal graph \(_{}\) and tested on \(_{}\) through the binary classification approach resulting in metrics such as AU-ROC, and AP. In general, \(_{}=(0,_{0})\), and \(_{}=(_{0},T)\), i.e., the train and test data are chronologically split from the same temporal graph which is assumed to be generated through a common causal mechanism.

In light of the experimental setup, we ask the question: "Would the model \(f\) which is trained on \(_{}\) perform well if tested on a distorted version of \(_{}\) instead of \(_{}\)?" To formalise the question in the counterfactual framework proposed by Pearl (2019), we consider the following statements:

* The test data is \(_{}\).
* The test data is a temporally distorted version of \(_{}\).
* The performance metric is in the range \((-,\{1,+\})\).
* The performance metric is strictly less than \(-\).

Then, the counterfactual question can be framed as \(P(y_{x} x^{},y^{})\) which stands for:

* The probability that the prediction accuracy would be less than \(-\) had the test data been a temporally distorted version of \(_{}\), given the prediction accuracy was observed to be approximately \(\) when the model was tested on \(_{}\).

We link the counterfactual question to our hypothesis in the following proposition:

**Proposition 3.1**.: _If \(P(y_{x} x^{},y^{}) 0_{}$}\)._

Proof.: Consider the set of logical statements:

* The temporal graph \(\) contains patterns that allow future edge predictions to be made based on past information, i.e., \(\) is learnable.
* The model \(f\) is _capable_ of learning the patterns in a learnable temporal graph.
* \(_{}=(0,_{0}),_{}=(_{0},T)\).
* \(^{}=(_{})\), where \(()\) is the temporal distortion function.
* The model \(f\) is trained on \(_{}\).
* The prediction metric reported by \(f\) on the real test data \(_{}\) is higher than the prediction metric on the distorted data \(^{}\). \[_{1}_{2}_{3} _{4}&_{5}&&_{6}\\ _{6}&&_{1}_{2} _{3}_{4}_{5}&\] (4)

For the experimental setup \(_{3}=1\), and \(_{5}=1\). Assuming that the temporal graph \(\) is learnable \(_{1}=1\), and that the function \((_{})\) results in a temporally distorted version of \(_{}\), i.e., \(_{4}=1\), we get \(_{6}_{2}\). Alternatively, \(_{6}(P(y_{x} x^{},y^{} ) 0)\), and \(_{2}\) is interpreted as "model \(f\) is _incapable_ of learning the temporal patterns in \(^{}\). 

ExampleIn Fig. 1, we show that \(_{}_{}\) is sampled from a point process with intensity \(^{*}(t),t[0,T]\). We generate \(^{}\) from another point process with intensity \(^{}(t),t[_{0},T]\). We depict the intensity functions as two sinusoidal waves with different frequency and phase. If a model \(f\) learns this intensity function by observing \(_{}\), and then generates samples for prediction, they would be more similar to \(_{}\) than \(^{}\).

Figure 1: Example of Temporal distortion.

### Temporal Distortion Techniques

Let \(\) be a temporal graph sampled from a temporal point process with intensity \(^{}(t)\) for \(t[0,T]\). Let \(^{}\) be data sampled from another point process with intensity \(^{}(t)\) for \(t[0,T]\).

**Definition 3.1**.: The temporal graph \(^{}\) is \(\)**-temporally distorted** w.r.t. \(\) if for some \(>0\),

\[_{0}^{T}|^{}(t)-^{}(t)|\,dt>.\] (5)

In practice, we do not have access to the true intensity functions, and have to compare the realisations instead. Let \(\) and \(^{}\) be two temporal graphs, then we measure the difference in their characteristics through the following two metrics.

**Definition 3.2**.: The average time difference (ATD) between \(\) and \(^{}\) is defined as:

\[(,^{})|}_{(u,v,t)}_{^{} (^{}_{(u,v)})\{T\}}|t-t^{}|,\] (6)

where \(T=()-()\).

**Definition 3.3**.: The average count difference (ACD) between \(\) and \(^{}\) is defined as:

\[(,^{})|}_{(u,v,t)}||_{(u,v)}(t-,t+ {})|-|^{}_{(u,v)}(t-,t+)|||,\] (7)

where \(=()- ()}{||}\).

Now that we are equipped with metrics to measure the difference between two temporal graphs, we device distortion functions \(()\) which can enable us to investigate the counterfactual question posed earlier. We propose two distortion techniques \(_{}(,K)\) which creates \(K\) time-perturbed copies of each edge events, and \(_{}()\) wherein the timestamps of different edge events are shuffled.

IntenseLet the real temporal graph data be denoted by \(=_{(u,v)}_{(u,v)}\), and the distorted version be denoted by \(^{}=_{(u,v)}^{ }_{(u,v)}\). then, for each edge event \((u,v,t)\) in the real data \(\), we create \(K\) edge events \((u,v,t+)\) with \(\) sampled uniformly from \((-,)\) for some \(>0\). Alternatively, if it is known that \(_{(u,v)}\) is sampled from a point process with intensity \(^{}_{(u,v)}(t)\), then we can generate \(^{}_{(u,v)}\) by sampling from another point process with intensity \(^{}_{(u,v)}(t)\), such that

\[^{}_{(u,v)}(t)=K^{}_{(u,v)}(t),\,(u,v) .\]

The operation of \(_{}\) is described in Algorithm 1.

ShuffleFor any two edge events \((u,v,t),(u^{},v^{},t^{})\), we shuffle the timestamps in the distorted version, i.e. \((u,v,t^{}),(u^{},v^{},t)^{}\). The shuffling process is also called label permutation (Chatterjee, 2018). In terms of the point process, we can explain shuffling as follows. If \(_{(u,v)}\) is known to be sampled from a point process with intensity \(^{}_{(u,v)}(t)\), then \(^{}_{(u,v)}\) can be generated by sampling from an inhomogenous Poisson point process with intensity \(^{}_{(u,v)}(t)\), where

\[^{}_{(u,v)}(t)=^{T}^{}_{(u,v)}(t)\,dt} {_{0}^{T}^{}(t)\,dt}^{}(t),\,(u,v) .\]

We describe the operation of \(_{}\) in Algorithm 2.

```
0:\(,K\)
0:\(^{}=\)
1:\(^{}=\)
2:\(_{0}()\)
3:\(T()\)
4:\(}{||}\)
5:for\((u,v,t)\)do
6:for\(k[K]\)do
7:\((-,)\)
8:\(^{}^{}\{(u,v,t+)\}\)
9:endfor
10:endfor ```

**Algorithm 1**\(_{}\)

```
0:\(^{}\)
1:\(^{}=\)
2:\(_{0}()\)
3:\(T()\)
4:\(}{||}\)
5:for\((u,v,t)\)do
6:for\(k[K]\)do
7:\((-,)\)
8:\(^{}^{}\{(u,v,t+)\}\)
9:endfor
10:endfor ```

**Algorithm 2**\(_{}\)

```
0:\(^{}\)
1:\(^{}\)
2:\(^{}^{}\{(u,v,t)\}\)
3:for\((u,v,t)\)do
4:\(\)
5:\(^{}^{}\{(u,v,)\}\)
6:\(\{\}\)
7:endfor ```

**Algorithm 2**\(_{}\)

```
0:\(^{}^{}\{(u,v,)\}\)
1:\(^{}^{}\{(u,v,)\}\)
2:\(^{}^{}\{(u,v,)\}\)
3:\(^{}^{}\{(u,v,t+)\}\)
4:endfor ```

**Algorithm 3**\(_{}\)

```
0:\(^{}^{}\{(u,v,)\}\)
4:\(^{}^{}\{(u,v,)\}\)
5:\(^{}^{}\{(u,v,)\}\)
6:\(^{}^{}\{(u,v,)\}\)
7:\(^{}^{}\{(u,v,)\}\)
8:endfor ```

**Algorithm 4**\(_{}\)

### Temporal Distortion Techniques

Let \(\) be a temporal graph sampled from a temporal point process with intensity \(^{}(t)\) for \(t[0,T]\). Let \(^{}\) be data sampled from another point process with intensity \(^{}(t)\) for \(t[0,T]\).

**Definition 3.1**.: The temporal graph \(^{}\) is \(\)**-temporally distorted** w.r.t. \(\) if for some \(>0\),

\[_{0}^{T}|^{}(t)-^{}(t)|\,dt>.\] (5)

In practice, we do not have access to the true intensity functions, and have to compare the realisations instead. Let \(\) and \(^{}\) be two temporal graphs, then we measure the difference in their characteristics through the following two metrics.

**Definition 3.2**.: The average time difference (ATD) between \(\) and \(^{}\) is defined as:

\[(,^{})|} _{(u,v,t)}_{t^{}(^{} _{(Experiment

DatasetsWe use the following datasets1 to perform counterfactual analysis:

* wikipedia(Kumar et al., 2019) describes a dynamic graph of interaction between the editors and Wikipedia pages over a span of one month. The entries consist of the user ID, page ID, and timestamp. The edge features are LIWC-feature vectors (Pennebaker et al., 2001) of the edit text. The edge feature dimension is \(172\).
* reddit(Kumar et al., 2019) describes a bipartite interaction graph between the users and subreddits. The interaction event is recorded with the IDs of the user, subreddit and timestamp. Similar to wikipedia, the post content is converted into a LIWC-feature vector of dimension \(172\) which serves as the edge feature.
* uci(Panzarasa et al., 2009) is a dynamic graph describing message-exchange among the students at University of California at Irvine (UCI) from April to October 2004. The interaction event consists of the user IDs, and timestamp.

The scale of the datasets are presented in Table 1. The datasets are chronologically split in the ratio \(0.7:0.15:0.15\) into train, validation, and test sets, respectively.

Next, we use \(_{}(,5)\) and \(_{}()\) to create \(10\) temporally distorted samples of the test splits of each dataset. In Table 2, we present the \(\), and \(\) by comparing the distorted samples with the original test data of different datasets. Through \(_{}(,5)\), the \(\) is negligible, however, the \(\) is close to \(5\). Through \(_{}()\), the \(\) is approximately \(1\) for wikipedia and reddit, and close to \(2\) for uci. We also see an increase in \(\) which is close to \(0.1\) for all datasets. Therefore, the metrics \(\) and \(\) should be considered in conjunction to measure the dissimilarity of two temporal graphs.

ModelsWe evaluate2 the performance of the following TLP models3 in light of Proposition 3.1:

* JODIE(Kumar et al., 2019) uses a recurrent neural network (RNN) to generate node embeddings for each interaction event. The future embedding of a node is estimated through a novel projection operator which is turn in used to predict future edge events.
* TGAT(Xu et al., 2020) relies on self-attention mechanism to generate node embeddings to capture the temporal evolution of the graph structure.
* TGN(Rossi et al., 2020) combine memory modules with graph-based operators to create an encoder-decoder pair capable of creating temporal node embeddings.
* CAWN(Wang et al., 2020) propose a novel strategy based on the law of triadic closure, where temporal walks retrieve the dynamic graph motifs without explicitly counting and selecting the motifs. The node IDs are replaced with the hitting counts to facilitate inductive inference.

For all the models we have forked the main branch of their original Github repositories, and added additional arguments to account for the distortion technique, as well as more focused logging. We wanted to evaluate GraphMixer(Cong et al., 2023) as it claims superior performance, however the distorted datasets we generated were not compatible with the dataloader used in their codebase.

   Dataset & \(||\) & \(||\) \\  wikipedia & 9227 & 157474 \\ reddit & 10984 & 672447 \\ nici & 1899 & 59835 \\   

Table 1: Number of nodes and edges in temporal graph datasets.

    &  &  &  \\   & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\  Intense & 6.9e-6 \(\) 2e-8 & 4.479 \(\) 1.9e-3 & 1.6e-6 \(\) 2e-9 & 4.112 \(\) 3e-8 & 1.6e-5 \(\) 1.2e-7 & 7.214 \(\) 1.2e-2 \\ Shuffle & 0.078 \(\) 5.7e-4 & 1.093 \(\) 3.4e-4 & 0.099 \(\) 3e-4 & 1.033 \(\) 8e-5 & 0.132 \(\) 8.4e-4 & 1.877 \(\) 3.3e-3 \\   

Table 2: Distortion measures on different datasets.

ResultsThe models are evaluated under two settings: _transductive_, and _inductive_. In transductive TLP, the nodes \(u,v\) in the positive sample \((u,v,t)_{}\) were observed during training. In contrast, in inductive TLP, at least one node in \(u,v\) is novel, and was not observed during training.

From Table 3 it is evident that none of the models are capable of distinguishing between the real data, and data sampled from a five-times more intense version. However, we see that TGN is fairly robust when the timestamps of the test data are shuffled, as its performance worsens the most compared to other models. The performance gap between the real and distorted versions decrease as the dataset size increases (see Table. 1).

In Fig. 2, and Fig. 3 we present the metric gap \([y_{x}-y^{}]\) for \(x_{}(x^{},5)\), and \(x_{}(x^{})\), respectively, for different models in categorical bar plots grouped by the dataset. We

    &  &  &  \\   & AU-ROC & AP & AU-ROC & AP & AU-ROC & AP \\  _transductive_ & 0.9170 \(\) 3e-3 & 0.9137 \(\) 5e-3 & 0.9679 \(\) 4e-3 & 0.9654 \(\) 5e-3 & 0.8950 \(\) 3e-3 & 0.8726 \(\) 3e-3 \\  Intense & 0.9177 \(\) 7e-3 & 0.9078 \(\) 1e-2 & 0.9619 \(\) 9e-3 & 0.9567 \(\) 1e-2 & 0.9244 \(\) 2e-3 & 0.9129 \(\) 8e-3 \\ Shuffle & 0.9097 \(\) 2e-2 & 0.8962 \(\) 4e-2 & 0.9661 \(\) 1e-2 & 0.9613 \(\) 4e-2 & 0.8852 \(\) 3e-3 & 0.8509 \(\) 3e-3 \\  _inductive_ & 0.8941 \(\) 4e-3 & **0.8970** \(\) 5e-3 & **0.9343** \(\) 9e-3 & **0.9138** \(\) 2e-2 & **0.7546** \(\) 8e-3 & **0.7310** \(\) 2e-2 \\  Intense & 0.9036 \(\) 1e-2 & 0.8972 \(\) 1e-2 & 0.9457 \(\) 1e-2 & 0.9308 \(\) 4e-2 & 0.8384 \(\) 3e-3 & 0.8332 \(\) 8e-3 \\ Shuffle & 0.9157 \(\) 1e-2 & 0.9078 \(\) 2e-2 & 0.9419 \(\) 3e-2 & 0.9251 \(\) 6e-3 & 0.7368 \(\) 5e-3 & 0.6994 \(\) 8e-3 \\    &  &  &  \\   & AU-ROC & AP & AU-ROC & AP & AU-ROC & AP \\  _transductive_ & 0.9499 \(\) 2e-3 & 0.9528 \(\) 2e-3 & 0.9806 \(\) 6e-4 & **0.9818** \(\) 6e-4 & **0.7885** \(\) 1e-2 & **0.7694** \(\) 7e-3 \\  Intense & 0.9680 \(\) 2e-3 & 0.9691 \(\) 2e-3 & 0.9821 \(\) 6e-4 & 0.9825 \(\) 6e-4 & 0.8707 \(\) 1e-2 & 0.8637 \(\) 2e-2 \\ Shuffle & 0.9492 \(\) 5e-3 & 0.9532 \(\) 5e-3 & 0.9814 \(\) 7e-3 & 0.9826 \(\) 6e-3 & 0.7719 \(\) 1e-2 & 0.7336 \(\) 2e-2 \\  _inductive_ & **0.9353** \(\) 2e-3 & 0.9401 \(\) 2e-3 & 0.9641 \(\) 1e-3 & **0.9658** \(\) 1e-3 & 0.7020 \(\) 8e-3 & 0.7008 \(\) 1e-2 \\  Intense & 0.9604 \(\) 2e-3 & 0.9621 \(\) 2e-3 & 0.9676 \(\) 8e-4 & 0.9676 \(\) 1e-3 & 0.8019 \(\) 2e-2 & 0.8095 \(\) 2e-2 \\ Shuffle & 0.9257 \(\) 7e-3 & 0.9304 \(\) 7e-3 & 0.9644 \(\) 7e-3 & 0.9664 \(\) 3e-3 & 0.6558 \(\) 7e-3 & 0.6324 \(\) 1e-2 \\    &  &  &  \\   & AU-ROC & AP & AU-ROC & AP & AU-ROC & AP \\  Intense & 0.9898 \(\) 1e-3 & 0.9911 \(\) 6e-4 & 0.9723 \(\) 2e-3 & 0.9744 \(\) 2e-3 & 0.9653 \(\) 3e-3 & 0.9709 \(\) 3e-3 \\ Shuffle & 0.8310 \(\) 3e-2 & 0.8487 \(\) 3e-2 & 0.9533 \(\) 2e-3 & 0.9563 \(\) 2e-3 & 0.6722 \(\) 6e-2 & 0.6520 \(\) 4e-2 \\  _inductive_ & **0.9374** \(\) 1e-3 & **0.9463** \(\) 1e-3 & **0.9299** \(\) 1e-3 & **0.9346** \(\) 1e-3 & **0.7714** \(\) 6e-3 & **0.7948** \(\) 6e-3 \\  Intense & 0.9903 \(\) 1e-3 & 0.9908 \(\) 6e-4 & 0.9617 \(\) 3e-3 & 0.9645 \(\) 3e-3 & 0.9592 \(\) 3e-3 & 0.9650 \(\) 2e-3 \\ Shuffle & 0.8194 \(\) 2e-2 & 0.8376 \(\) 3e-2 & 0.9266 \(\) 4e-3 & 0.9299 \(\) 3e-3 & 0.6245 \(\) 2e-2 & 0.6193 \(\) 9e-3 \\    &  &  &  \\   & AU-ROC & AP & AU-ROC & AP & AU-ROC & AP \\  _transductive_ & 0.9886 \(\) 1e-4 & 0.9901 \(\) 1e-4 & **0.9864** \(\) 4e-3 & **0.9884** \(\) 3e-3 & **0.9162** \(\) 9e-4 & **0.9397** \(\) 8e-4 \\  Intense & 0.9977 \(\) 9e-5 & 0.9975 \(\) 8e-5 & 0.9931 \(\) 8e-5 & 0.9942 \(\) 7e-5 & 0.9848 \(\) 6e-4 & 0.9889 \(\) 7e-4 \\ Shuffle & 0.9868 \(\) 3e-4 & 0.9887 \(\) 3e-4 & 0.9859 \(\) 6e-4 & 0.9880 \(\) 2e-3 & 0.8495 \(\) 7e-3 & 0.8866 \(\) 2e-3 \\  _inductive_ & 0.9877 \(\) 5e-4 & **0.9896** \(\) 4e-4 & **0.9833** \(\) 5e-3 & **0.9859** \(\) 3e-check whether \(}<}\) in an empirical way by checking if \([y_{x}]+<[y^{}]-^{} [y_{x}]-[y^{}]<-(+^{ })\). Therefore, we plot \([y_{x}]-[y^{}]\) as coloured bars, and \(-(+^{})\) as black diamonds. Moreover, we indicate \(=0.05\) as the dashed black line passing through \(-0.05\).

The models evaluated in this work form the set of baselines to validate the performance of new models. However, as we demonstrate, a higher metric alone is not indicative of good performance without sanity checks. The counterfactual question helps make the evaluation more explainable, as models that perform worse on temporally distorted data with high ATD and ACD can claim superiority over modes that do not. An ideal TLP model should be able to capture the difference in the count of edge events, as well as temporal shifts in the edge events.

Discussion

Moving away from the binary classification approach to assess the performance of temporal link prediction, the research should explore a generative approach where after observing a temporal graph from time \(t(0,_{0})\), the model can generate a temporal graph in \(t(_{0},T)\). This generated temporal graph should be compared with the ground truth for similarity to assess the performance of the model. The metrics \(\) and \(\) can be used to measure the difference in the timestamps, as well as the edge counts along the time axis.

We showed that the performance gap in light of Proposition 3.1 decreases with increasing size of the temporal graph, focus should be establish TLP models on smaller datasets, first in the transductive setting, and then progress to inductive setting. In the generative method of evaluation, we can also make use of other metrics that characterise a network, or a point process to add additional constraints.

Broader ImpactWe presented a framework, wherein we asked a counterfactual question, and then designed intervention mechanisms by generating temporally distorted test sets. In the future, researchers can devise their own temporal distortion techniques to assess the performance of a TLP model, if they follow the binary classification approach to evaluation. Our aim is also to encourage researchers to explore the generative evaluation strategy, and design TLP models which can generate temporal graphs after observing the edge events in the past. While our work focused on temporal graphs with ephemeral edges (see Definition 2.1), distortion techniques can also be designed for interval graphs, where the edge events persist for a duration. In this work, rather than introducing novel datasets, we present techniques for generating temporally distorted versions of any temporal graph dataset. This makes the contribution relevant even for datasets which will be introduced in the future.

LimitationsDue to resource constraints, we could not evaluate the models on more datasets. However, we aim to get additional results by the rebuttal period on the datasets used in Poursafaei and Rabbany (2023). We also wanted to measure the performance of the models through ranking metrics like \(\) or \(\), but the distorted datasets were not compatible with the dataloader used by Temporal Graph Benchmark (TGB) (Huang et al., 2024).