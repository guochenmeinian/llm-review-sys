# Private estimation algorithms for stochastic block models and mixture models

Hongjie Chen

ETH Zurich

Vincent Cohen-Addad

Google Research

&Tommaso d'Orsi

Bocconi

&Alessandro Epasto

Google Research

Jacob Imola

UC San Diego

&David Steurer

ETH Zurich

&Stefan Tiegel

ETH Zurich

Much of this work was done while the author was at ETH Zurich.

###### Abstract

We introduce general tools for designing efficient private estimation algorithms, in the high-dimensional settings, whose statistical guarantees almost match those of the best known non-private algorithms. To illustrate our techniques, we consider two problems: recovery of stochastic block models and learning mixtures of spherical Gaussians.

For the former, we present the first efficient \((,)\)-differentially private algorithms for both weak recovery and exact recovery. Previously known algorithms achieving comparable guarantees required quasi-polynomial time. We complement these results with an information-theoretic lower bound that highlights how the guarantees of our algorithms are almost tight.

For the latter, we design an \((,)\)-differentially private algorithm that recovers the centers of the \(k\)-mixture when the minimum separation is at least \(O(k^{1/t})\).

For all choices of \(t\), this algorithm requires sample complexity \(n k^{O(1)}d^{O(t)}\) and time complexity \((nd)^{O(t)}\). Prior work required either an additional additive \(()\) term in the minimum separation or an explicit upper bound on the Euclidean norm of the centers.

## 1 Introduction

Computing a model that best matches a dataset is a fundamental question in machine learning and statistics. Given a set of \(n\) samples from a model, how to find the most likely parameters of the model that could have generated this data? This basic question has been widely studied for several decades, and recently revisited in the context where the input data has been partially corrupted (i.e., where few samples of the data have been adversarially generated--see for instance ). This has led to several recent works shedding new lights on classic model estimation problems, such as the Stochastic Block Model (SBM)  and the Gaussian Mixture Model (GMM)  (see Definitions 1.1 and 1.2).

Privacy in machine learning and statistical tasks has recently become of critical importance. New regulations, renewed consumer interest as well as privacy leaks, have led the major actors to adopt privacy-preserving solutions for the machine learning . This new push has resulted in a flurry of activity in algorithm design for private machine learning, including very recently for SBMs and GMMs . Despite this activity, it has remain an open challenge to fully understand how privacy requirements impact model estimation problems and in particular their recovery thresholds and the computational complexity. This is the problem we tackle in this paper.

While other notions of privacy exist (e.g. \(k\)-anonymity), the de facto privacy standard is the differential privacy (DP) framework of Dwork, McSherry, Nissim, and Smith . In this framework, the privacy quality is governed by two parameters, \(\) and \(\), which in essence tell us how the probability of seeing a given output changes (both multiplicatively and additively) between two datasets that differ by any individual data element. This notion, in essence, quantifies the amount of information _leaked_ by a given algorithm on individual data elements. The goal of the algorithm designer is to come up with differentially private algorithms for \(\) being a small constant and \(\) being of order \(1/n^{(1)}\).

Differentially private analysis of graphs usually considers two notions of neighboring graphs. The weaker notion of _edge-DP_ defines two graphs to be neighboring if they differ in one edge. Under the stronger notion of _node-DP_, two neighboring graphs can differ arbitrarily in the set of edges connected to a single vertex. Recently, there is a line of work on node-DP parameter estimation in random graph models, e.g. Erdos-Renyi models  and Graphons . However, for the more challenging task of graph clustering, node-DP is sometimes impossible to achieve.2 Thus it is a natural first step to study edge-DP graph clustering.

Very recently, Seif, Nguyen, Vullikanti, and Tandon  were the first to propose differentially private algorithms for the Stochastic Block Model, with edge-DP. Concretely, they propose algorithms achieving exact recovery (exact identification of the planted clustering) while preserving privacy of individual edges of the graph. The proposed approach either takes \(n^{( n)}\) time when \(\) is constant, or runs in polynomial time when \(\) is \(( n)\).

Gaussian Mixture Models have also been studied in the context of differential privacy by  using the subsample-and-aggregate framework first introduced in  (see also recent work for robust moment estimation in the differential privacy setting ). The works of  require an explicit bound on the euclidean norm of the centers as the sample complexity of these algorithms depends on this bound. For a mixture of \(k\) Gaussians, if there is a non-private algorithm that requires the minimum distance between the centers to be at least \(\), then  can transform this non-private algorithm into a private one that needs the minimum distance between the centers to be at least \(+\), where \(n\) is the number of samples.

In this paper, we tackle both clustering problems (graph clustering with the SBM and metric clustering with the GMM) through a new general privacy-preserving framework that brings us significantly closer to the state-of-the-art of non-private algorithms. As we will see, our new perspective on the problems appear to be easily extendable to many other estimation algorithms.

From robustness to privacyIn recent years a large body of work (see  and references therein) has advanced our understanding of parameter estimation in the presence of adversarial perturbations. In these settings, an adversary looks at the input instance and modifies it arbitrarily, under some constraints (these constraints are usually meant to ensure that it is still information theoretically possible to recover the underlying structure). As observed in the past , the two goals of designing privacy-preserving machine learning models and robust model estimation are tightly related. The common objective is to design algorithms that extract global information without over-relaying on individual data samples.

Concretely, robust parameter estimation tends to morally follow a two-steps process: _(i)_ argue that typical inputs are well-behaved, in the sense that they satisfy some property which can be used to accurately infer the desired global information, _(ii)_ show that adversarial perturbations cannot significantly alter the quality of well-behaved inputs, so that it is still possible to obtain an accurate estimate. Conceptually, the analysis of private estimation algorithms can also be divided in two parts: _utility_, which is concerned with the accuracy of the output, and _privacy_, which ensures there is no leak of sensitive information. In particular, the canonical differential privacy definition can be interpreted as the requirement that, for any distinct inputs \(Y,Y^{}\), the change in the output is _proportional_ to the distance3 between \(Y\) and \(Y^{}\).

It is easy to see this as a generalization of robustness: while robust algorithm needs the output to be stable for typical inputs, private algorithms requires this stability for _any possible input_. Then,stability of the output immediately implies adding a small amount of noise to the output yields privacy. If the added noise is small enough, then utility is also preserved.

Our work further tightens this connection between robustness and privacy through a simple yet crucial insight: if two strongly convex functions over constrainted sets -where both the function and the set may depend on the input- are point-wise close (say in a \(_{2}\)-sense), their minimizers are also close (in the same sense). The alternative perspective is that projections of points that are close to each other, onto convex sets that are point-wise close, must also be close. This observation subsumes previously known sensitivity bounds in the empirical risk minimization literature (in particular in the output-perturbation approach to ERM, see Section 2 for a comparison).

The result is a clean, user-friendly, _framework to turn robust estimation algorithms into private algorithms_, while keeping virtually the same guarantees. We apply this paradigm to stochastic block models and Gaussian mixture models, which we introduce next.

Stochastic block modelThe stochastic block model is an extensively studied statistical model for community detection in graphs (see  for a survey).

**Model 1.1** (Stochastic block model).: _In its most basic form, the stochastic block model describes the distribution4 of an \(n\)-vertex graph \(_{n}(d,,x)\), where \(x\) is a vector of \(n\) binary5 labels, \(d\), \(>0\), and for every pair of distinct vertices \(i,j[n]\) the edge \(\{i,j\}\) is independently added to the graph \(\) with probability \((1+ x_{i} x_{j})\)._

For balanced label vector \(x\), i.e., with roughly the same number of \(+1\)'s and \(-1\)'s, parameter \(d\) roughly corresponds to the average degree of the graph. Parameter \(\) corresponds to the _bias_ introduced by the community structure. Note that for distinct vertices \(i,j[n]\), the edge \(\{i,j\}\) is present in \(\) with probability \((1+)\) if the vertices have the same label \(x_{i}=x_{j}\) and with probability \((1-)\) if the vertices have different labels \(x_{i} x_{j}\).6

Given a graph \(\) sampled according to this model, the goal is to recover the (unknown) underlying vector of labels as well as possible. In particular, for a chosen algorithm returning a partition \(()\{ 1\}^{n}\), there are two main objective of interest: _weak recovery_ and _exact recovery_. The former amounts to finding a partition \(()\) correlated with the true partition. The latter instead corresponds to actually recovering the true partition with high probability. As shown in the following table, by now the statistical and computational landscape of these problems is well understood :

   & **Objective** & can be achieved (and efficiently so) _iff_ \\   _weak recovery_ & \(_{_{n}(d,,x)}(|  x,()|_{d,}(1))  1-o(1)\) & \(^{2} d 1\) \\  _exact recovery_ & \(_{_{n}(d,,x)}(( )\{x,-x\}) 1-o(1)\) & \((1-}) 1\) \\  

Learning mixtures of spherical GaussiansThe Gaussian Mixture Model we consider is the following.

**Model 1.2** (Mixtures of spherical Gaussians).: _Let \(D_{1},,D_{k}\) be Gaussian distributions on \(^{d}\) with covariance \(\) and means \(_{1},,_{k}\) satisfying \(\|_{i}-_{j}\|\) for any \(i j\). Given a set \(=\{_{1},,_{n}\}\) of \(n\) samples from the uniform mixture over \(D_{1},,D_{k}\), estimate \(_{1},,_{k}\)._

It is known that when the minimum separation is \(=o()\), superpolynomially many samples are required to estimate the means up to small constant error . Just above this threshold, at separation \(k^{O(1/)}\) for any constant \(\), there exist efficient algorithms based on the sum-of-squares hierarchy recovering the means up to accuracy \(1/(k)\). In the regime where \(=O()\) these algorithms yield the same guarantees but require quasipolynomial time. Recently,  showed how to efficiently recover the means as long as \(=O((k)^{1/2+c})\) for any constant \(c>0\).

### Results

Stochastic block modelWe present here the first \((,)\)-differentially private efficient algorithms for exact recovery. In all our results on stochastic block models, we consider the _edge privacy_ model, in which two input graphs are adjacent if they differ on a single edge (cf. Definition C.1).

**Theorem 1.3** (Private exact recovery of SBM).: _Let \(x\{ 1\}^{n}\) be balanced7. For any \(,d,,>0\) satisfying_

\[(1-})(1) {and}(}+),\]

_there exists an \((,)\)-differentially edge private algorithm that, on input \(_{n}(d,,x)\), returns \(()\{x,-x\}\) with probability \(1-o(1)\). Moreover, the algorithm runs in polynomial time._

For any constant \(>0\), Theorem 1.3 states that \((,)\)-differentially private exact recovery is possible, in polynomial time, already a constant factor close to the non-private threshold. Previous results  could only achieve comparable guarantees in time \(O(n^{O( n)})\). It is also important to observe that the theorem provides a trade-off between signal-to-noise ratio of the instance (captured by the expression on the left-hand side with \(\), \(d\)) and the privacy parameter \(\). In particular, we highlight two regimes: for \(d( n)\) one can achieve exact recovery with high probability and privacy parameters \(=n^{-(1)}\,,=O(1/+1/^{2})\). For \(d( n)\) one can achieve exact recovery with high probability and privacy parameters \(=o(1),=n^{-(1)}\). Theorem 1.3 follows by a result for private weak recovery and a boosting argument (cf. Theorem C.3 and Appendix C.2).

Further, we present a second, exponential-time, algorithm based on the exponential mechanism  which improves over the above in two regards. First, it gives _pure_ differential privacy. Second, it provides utility guarantees for a larger range of graph parameters. In fact, we will also prove a lower bound which shows that its privacy guarantees are information theoretically optimal.8 All hidden constants are absolute and do not depend on any graph or privacy parameters unless stated otherwise. In what follows we denote by \((,x)\) the minimum of the hamming distance of \(\) and \(x\), and the one of \(-\) and \(x\), divided by \(n\).

**Theorem 1.4** (Slightly informal, see Theorem C.18 in the supplements for full version).: _Let \((1)\), \(x\{ 1\}^{n}\) be balanced, and \((-(^{2}d))\). For any \(()\), there exists an algorithm which on input \(_{n}(,d,x)\) outputs an estimate \(()\{ 1\}^{n}\) satisfying \(((),x)\) with probability at least \(1-\). In addition, the algorithm is \(\)-differentially edge private. Further, we can achieve error \((1/)\) with probability \(1-e^{-n}\)._

A couple of remarks are in order. First, our algorithm works across all degree-regimes in the literature and matches known non-private thresholds and rates up to constants.9 In particular, for \(^{2}d=(1)\), we achieve weak/partial recovery with either constant or exponentially high success probability. Recall that the optimal non-private threshold is \(^{2}d>1\). For the regime, where \(^{2}d=(1)\), it is known that the optimal error rate is \((-(1-o(1))^{2}d)\) even non-privately which we match up to constants - here \(o(1)\) denotes a function that tends to zero as \(^{2}d\) tends to infinity. Moreover, our algorithm achieves exact recovery as soon as \(^{2}d=( n)\) since then \(<\). This also matches known non-private thresholds up to constants . We remark that  gave an \(\)-DP exponential time algorithm which achieved exact recovery and has inverse polynomial success probability in the utility case as long as \(()\). We recover this result as a special case (with slightly worse constants). In fact, their algorithm is also based on the exponential mechanism, but their analysis only applies to the setting of exact recovery, while our result holds much more generally. Anothercrucial difference is that we show how to privatize a known boosting technique frequently used in the non-private setting, allowing us to achieve error guarantees which are optimal up to constant factors.

It is natural to ask whether, for a given set of parameters \(,d,\) one can obtain better privacy guarantees than Theorem 1.4. Our next result implies that our algorithmic guarantees are almost tight.

**Theorem 1.5** (Informal, see Theorem C.22 in the supplements for full version).: _Suppose there exists an \(\)-differentially edge private algorithm such that for any balanced \(x\{ 1\}^{n}\), on input \(_{n}(d,,x)\), outputs \(()\{ 1\}^{n}\) satisfying_

\[(((),x)<) 1 -\,.\]

_Then,_

\[(+)\,.\] (1.1)

This lower bound is tight for \(\)-DP exact recovery. By setting \(=1/n\) and \(=1/(n)\), Theorem 1.5 implies no \(\)-DP exact recovery algorithm exists for \( O()\). There exist \(\)-DP algorithms (Algorithm C.19 in the supplements and the algorithm in ) exactly recover the community for any \(()\).

Notice Theorem 1.5 is a lower bound for a large range of error rates (partial to exact recovery). For failure probability \(=\), the lower bound simplifies to \(()\) and hence matches Theorem 1.4 up to constants. For exponentially small failure probability, \(=e^{-n}\), it becomes \(()\). To compare, Theorem 1.4 requires \(( d})\) in this regime, using the substitution \(\).

Further, while formally incomparable, this \(\)-DP lower bound also suggests that the guarantees obtained by our efficient \((,)\)-DP algorithm in Theorem 1.3 might be close to optimal. Note that setting \(=\) in Theorem 1.5 requires the algorithm to exactly recover the partitioning. In this setting, Theorem 1.3 implies that there is an efficient \((,n^{-(1)})\)-DP exact recovery algorithm for \( O(})\). Theorem 1.5 states any \(\)-DP exact recovery algorithm requires \(()\). Further, for standard privacy parameters that are required for real-world applications, such as \( 1\) and \(=n^{-10}\), Theorem 1.3 requires that \( d( n)\). Theorem 1.5 shows that for pure-DP algorithms with the same setting of \(\) this is also necessary. We leave it as fascinating open questions to bridge the gap between upper and lower bounds in the context of \((,)\)-DP.

Learning mixtures of spherical GaussiansOur algorithm for privately learning mixtures of \(k\) spherical Gaussians provides statistical guarantees matching those of the best known non-private algorithms.

**Theorem 1.6** (Privately learning mixtures of spherical Gaussians).: _Consider an instance of Model 1.2. Let \(t>0\) be such that \( O(k^{1/t})\). For \(n(k^{O(1)} d^{O(t)})\,,k( n)^{1/5}\,,\) there exists an algorithm, running in time \((nd)^{O(t)}\), that outputs vectors \(}_{1},,}_{k}\) satisfying_

\[_{[k]}\|}_{}-_{()}\|_ {2} O(k^{-12})\,,\]

_with high probability, for some permutation \(:[k][k]\,.\) Moreover, for \( k^{-10}\,, n^{-10}\,,\) the algorithm is \((,)\)-differentially private10 for any input \(Y\)._

The conditions \( k^{-10}\,, n^{-10}\) in Theorem 1.6 are not restrictive and should be considered a formality. Moreover, setting \(=0.01\) and \(=n^{-10}\) already provides meaningful privacy guarantees in practice. The condition that \(k( n)^{1/5}\) is a technical requirement by our proofs.

Prior to this work, known differentially private algorithms could learn a mixture of \(k\)-spherical Gaussian either if: (1) they were given a ball of radius \(R\) containing all centers ;11 or (2) the minimum separation between centers needs an additional additive \(()\) term 12.

To the best of our knowledge, Theorem 1.6 is the first to get the best of both worlds. That is, our algorithm requires no explicit upper bounds on the means (this also means the sample complexity does not depend on \(R\)) and only minimal separation assumption \(O().\) Furthermore, we remark that while previous results only focused on mixtures of Gaussians, our algorithm also works for the significantly more general class of mixtures of Poincare distributions. Concretely, in the regime \(k,\) our algorithm recovers the state-of-the-art guarantees provided by non-private algorithms which are based on the sum-of-squares hierarchy [36; 30; 59]:13

* If \( k^{1/t^{*}}\) for some constant \(t^{*},\) then by choosing \(t(t^{*})\) the algorithm recovers the centers, up to a \(1/(k)\) error, in time \((k,d)\) and using only \((k,d)\) samples.
* If \(()\) then choosing \(t=O( k)\) the algorithm recovers the centers, up to a \(1/(k)\) error, in quasi-polynomial time \((k^{O(t)},d^{O(t^{2})})\) and using a quasi-polynomial number of samples \((k,d^{O(t)})\).

For simplicity of exposition we will limit the presentation to mixtures of spherical Gaussians. We reiterate that separation \(()\) is information-theoretically necessary for algorithms with polynomial sample complexity .

Subsequently and independently of our work, the work of  gives an algorithm that turns any non-private GMM learner into a private one based on the subsample and aggregate framework. They apply this reduction to the classical result of  to give the first finite-sample \((,)\)-DP algorithm that learns mixtures of unbounded Gaussians, in particular, the covariance matrices of their mixture components can be arbitrary.

## 2 Techniques

We present here our general tools for designing efficient private estimation algorithms in the high-dimensional setting whose statistical guarantees almost match those of the best know non-private algorithms. The algorithms we design have the following structure in common: First, we solve a convex optimization problem with constraints and objective function depending on our input \(Y\). Second, we round the optimal solution computed in the first step to a solution \(X\) for the statistical estimation problem at hand.

We organize our privacy analyses according to this structure. In order to analyze the first step, we prove a simple sensitivity bound for strongly convex optimization problems, which bounds the \(_{2}\)-sensitivity of the optimal solution in terms of a uniform sensitivity bound for the objective function and the feasible region of the optimization problem.

For bounded problems -such as recovery of stochastic block models- we use this sensitivity bound, in the second step, to show that introducing small additive noise to standard rounding algorithms is enough to achieve privacy.

For unbounded problems -such as learning GMMs- we use this sensitivity bound to show that on adjacent inputs, either most entries of \(X\) only change slightly, as in the bounded case, or few entries vary significantly. We then combine different privacy techniques to hide both type of changes.

Privacy from sensitivity of strongly convex optimization problemsBefore illustrating our techniques with some examples, it is instructive to explicit our framework. Here we have a set of inputs \(\) and a family of strongly convex functions \(()\) and convex sets \(()\) parametrized by these inputs. The generic _non-private_ algorithm based on convex optimization we consider works as follows:

1. Compute \(:=_{X(Y)}f_{Y}(X)\) ;
2. Round \(\) into an integral solution.

For an estimation problem, a distributional assumption on \(\) is made. Then one shows how, for typical inputs \(\) sampled according to that distribution, the above scheme recovers the desired structured information.

We can provide a privatized version of this scheme by arguing that, under reasonable assumptions on \(()\) and \(()\), the output of the function \(*{argmin}_{X(Y)}f_{Y}(X)\) has low \(_{2}\)-sensitivity. The consequence of this crucial observation is that one can combine the rounding step 2 with some standard privacy mechanism and achieve differential privacy. That is, the second step becomes:

## 2 Add random noise \(\) and round \(+\) into an integral solution.

Our sensitivity bound is simple, yet it generalizes previously known bounds for strongly convex optimization problems (we provide a detailed comparison later in the section). For adjacent \(Y,Y^{}\,,\) it requires the following properties:

1. For each \(X(Y)(Y^{})\) it holds \(|f_{Y}(X)-f_{Y^{}}(X)|\);
2. For each \(X(Y)\) its projection \(Z\) onto \((Y)(Y^{})\) satisfies \(|f_{Y}(X)-f_{Y^{}}(Z)|\,.\)

Here we think of \(\) as some small quantity (relatively to the problem parameters). Notice, we may think of _(i)_ as Lipschitz-continuity of the function \(g(Y,X)=f_{Y}(X)\) with respect to \(Y\) and of _(ii)_ as a bound on the change of the constrained set on adjacent inputs. In fact, these assumptions are enough to conclude low \(_{2}\) sensitivity. Let \(\) and \(^{}\) be the outputs of the first step on inputs \(Y,Y^{}\). Then using (i) and (ii) above and the fact that \(\) is an optimizer, we can show that there exists \(Z(Y)(Y^{})\) such that

\[|f_{Y}()-f_{Y}(Z)|+|f_{Y^{}}(^{})-f_{Y^{}}(Z)|  O()\,.\]

By \(\)-strong convexity of \(f_{Y}\,,f_{Y^{}}\) this implies

\[\|-Z\|_{2}^{2}+\|^{}-Z\|_{2}^{2}  O(/)\]

which ultimately means \(\|-^{}\|_{2}^{2} O(/)\) (see Lemma B.1). Thus, starting from our assumptions on the point-wise distance of \(f_{Y}\,,f_{Y^{}}\) we were able to conclude low \(_{2}\)-sensitivity of our output!

A simple application: weak recovery of stochastic block modelsThe ideas introduced above, combined with existing algorithms for weak recovery of stochastic block models, immediately imply a private algorithm for the problem. To illustrate this, consider Model 1.1 with parameters \(^{2}d C\), for some large enough constant \(C>1\). Let \(x\{ 1\}^{n}\) be balanced. Here \(Y\) is an \(n\)-by-\(n\) matrix corresponding to the rescaled centered adjacency matrix of the input graph:

\[Y_{ij}=(1-)&ij  E(G)\\ -&\]

The basic semidefinite program  can be recast14 as the strongly convex constrained optimization question of finding the orthogonal projection of the matrix \(Y\) onto the set \(:=\{X^{n n}\ |\ X\,,X_{ii}=\  i\}.\) That is

\[:=*{argmin}_{X}\|Y-X\|_{}^{2}\,.\]

Let \(f_{Y}(X):=\|X\|_{}^{2}-2 X,Y\) and notice that \(=*{argmin}_{X}f_{Y}(X)\). It is a standard fact that, if our input was \(_{n}(d,,x)\), then with high probability \(X()=*{argmin}_{X}f_{Y()}(X)\) would have leading eigenvalue-eigenvector pair satisfying

\[_{1}() 1-O(1/^{2}d)  v_{1}(),x/\|x\|)^{2} 1-O(1/^{2}d )\,.\]

This problem fits perfectly the description of the previous paragraph. Note that since the constraint set does not depend on \(Y\), Property (ii) reduces to Property (i). Thus, it stands to reason that the projections \(,^{}\) of \(Y,Y^{}\) are close whenever the input graphs generating \(Y\) and \(Y^{}\) are adjacent. By Holder's Inequality with the entry-wise infinity and \(_{1}\)-norm, we obtain \(|f_{Y}(X)-f_{Y^{}}(X)| 2\|X\|_{}\|Y-Y^{ }\|_{1}\). By standard facts about positive semidefinite matrices, we have \(\|X\|_{}\)for all \(X\). Also, \(Y\) and \(Y^{}\) can differ on at most 2 entries and hence \(\|Y-Y^{}\|_{1} O()\). Thus, \(\|-^{}\|_{}^{2} O()\).

The rounding step is now straightforward. Using the Gaussian mechanism we return the leading eigenvector of \(+\) where \( N(0,})^{n n}\). This matrix has Frobeinus norm significantly larger than \(\) but its spectral norm is only

\[\|\|}{} }}\,.\]

Thus by standard linear algebra, for typical instances \(_{n}(d,,x)\), the leading eigenvector of \(()+\) will be highly correlated with the true community vector \(x\) whenever the average degree \(d\) is large enough. In conclusion, a simple randomized rounding step is enough!

**Remark 2.1** (From weak recovery to exact recovery).: _In the non-private setting, given a weak recovery algorithm for the stochastic block model, one can use this as an initial estimate for a boosting procedure based on majority voting to achieve exact recovery. We show that this can be done privately. See Appendix C.2 in the supplements._

An advanced application: learning mixtures of GaussiansIn the context of SBMs our argument greatly benefited from two key properties: first, on adjacent inputs \(Y-Y^{}\) was bounded in an appropriate norm; and second, the convex set \(\) was fixed. In the context of learning mixtures of spherical Gaussians as in Model 1.2, _both_ this properties are _not_ satisfied (notice how one of this second properties would be satisfied assuming bounded centers!). So additional ideas are required.

The first observation, useful to overcome the first obstacle, is that before finding the centers, one can first find the \(n\)-by-\(n\) membership matrix \(W(Y)\) where \(W(Y)_{ij}=1\) if \(i,j\) where sampled from the same mixture component and \(0\) otherwise. The advantage here is that, on adjacent inputs, \(\|W(Y)-W(Y^{})\|_{}^{2} 2n/k\) and thus one recovers the first property.15 Here early sum-of-squares algorithms for the problem  turns out to be convenient as they rely on minimizing the function \(\|W\|_{}^{2}\) subject to the following system of polynomial inequalities in variables \(z_{11}\,,\,,z_{1k}\,,\,,z_{nk}\), with \(W_{ij}=_{}z_{i}z_{j}\) for all \(i,j[n]\) and a parameter \(t>0\).

\[z_{i}^{2}=z_{i}& i[n]\,,[k] \\ _{[k]}z_{i} 1& i[n]\\ z_{i} z_{i^{}}=0& i[n]\,,[k]\\ _{i}z_{i}=n/k&[k] @note{footnote}{While this is far from being true, it turns out that having access to a pseudo-distribution satisfying $(Y)$ is enough for our subsequent argument to work, albeit with some additional technical work required.}\\ _{}^{}=_{i}z_{i} y_{i}&[k] \\ _{i}z_{i} y_{i}-_{}^{},u ^{2t}(2t)^{t}\|u\|_{2}^{t}& u^{d}\,,[k]\] ( \[(Y)\] )

For the scope of this discussion,16 we may disregard computational issues and assume we have access to an algorithm returning a point from the convex hull \((Y)\) of all solutions to our system of inequalities.17 Each indicator variable \(z_{i}\{0,1\}\) is meant to indicate whether sample \(y_{i}\) is believedto be in cluster \(C_{}\). In the non-private setting, the idea behind the program is that -for typical \(\) sampled according to Model 1.2 with minimum separation \( k^{1/t}-\) any solution \(W()()\) is close to the ground truth matrix \(W^{*}()\) in Frobenius norm: \(\|W()-W^{*}()\|_{}^{2} 1/(k)\,.\) Each row \(W()_{i}\) may be seen as inducing a uniform distribution over a subset of \(\).19 Combining the above bound with the fact that subgaussian distributions at small total variation distance have means that are close, we conclude the algorithm recovers the centers of the mixture.

While this program suggests a path to recover the first property, it also possesses a fatal flaw: the projection \(W^{}\) of \(W(Y)\) onto \((Y)(Y^{})\) may be _far_ in the sense that \(\|\|W\|_{}^{2}-\|W^{}\|_{}^{2}\|(\|W\|_{}^{2}+\|W^{ }\|_{}^{2})(n^{2}/k)\,.\) The reason behind this phenomenon can be found in the constraint \(_{i}z_{i}=n/k\,.\) The set indicated by the vector \((z_{1}\,\,,z_{n})\) may be subgaussian in the sense of \((Y)\) for input \(Y\) but, upon changing a single sample, this may no longer be true. We work around this obstacle in two steps:

1. We replace the above constraint with \(_{i}z_{i} n/k\,.\)
2. We compute \(:=_{W(Y)}\|J-W\|_{ }^{2}\,\), where \(J\) is the all-one matrix.20

The catch now is that the program is satisfiable for _any_ input \(Y\) since we can set \(z_{il}=0\) whenever necessary. Moreover, we can guarantee property _(ii)_ (required by our sensitivity argument) for \( O(n/k)\), since we can obtain \(W^{}(Y)(Y^{})\) simply zeroing out the row/column in \(W\) corresponding to the sample differing in \(Y\) and \(Y^{}\). Then for typical inputs \(\), the correlation with the true solution is guaranteed by the new strongly convex objective function.

We offer some more intuition on the choice of our objective function: Recall that \(W_{ij}\) indicates our guess whether the \(i\)-th and \(j\)-th datapoints are sampled from the same Gaussian component. A necessary condition for \(W\) to be close to its ground-truth counterpart \(W^{*}\), is that they roughly have the same number of entries that are (close to) 1. One way to achieve this would be to add the lower bound constraing \(_{}z_{i}\). However, such a constraint could cause privacy issues: There would be two neighboring datasets, such that the constraint set induced by one dataset is satisfiable, but the constraint set induced by the other dataset is not satisfiable. We avoid this issue by noticing that the appropriate number of entries close to 1 can also be induced by minimizing the distance of \(W\) to the all-one matrix. This step is also a key difference from , explained in more detail below.

From low sensitivity of the indicators to low sensitivity of the estimatesFor adjacent inputs \(Y,Y^{}\) let \(,^{}\) be respectively the matrices computed by the above strongly convex programs. Our discussion implies that, applying our sensitivity bound, we can show \(\|-^{}\|_{}^{2} O(n/k)\,.\) The problem is that simply applying a randomized rounding approach here cannot work. The reason is that even tough the vector \(_{i}\) induces a subgaussian distribution, the vector \(_{i}+v\) for \(v^{n}\), _might not_. Without the subgaussian constraint we cannot provide any meaningful utility bound. In other words, the root of our problem is that there exists heavy-tailed distributions that are arbitrarily close in total variation distance to any given subgaussian distribution.

On the other hand, our sensitivity bound implies \(\|-^{}\|_{1}^{2} o(\|\|_{1})\) and thus, all but a vanishing fraction of rows \(i[n]\) must satisfy \(\|_{i}-^{}_{i}\|_{1} o(\|_{i}\|_{1})\). For each row \(i\,,\) let \(_{i}\,,_{i}^{}\) be the means of the distributions induced respectively by \(_{i}\,,^{}_{i}\,.\) We are thus in the following setting:

1. For a set of \((1-o(1)) n\) good rows \(\|_{i}-_{i}^{}\|_{2} o(1)\,,\)
2. For the set \(\) of remaining bad rows, the distance \(\|_{i}-_{i}^{}\|_{2}\) may be unbounded.

We hide differences of the first type as follows: pick a random subsample \(}\) of \([n]\) of size \(n^{c}\), for some small \(c>0\), and for each picked row use the Gaussian mechanism. The subsampling step is useful as it allows us to decrease the standard deviation of the entry-wise random noise by a factor \(n^{1-c}\,.\) We hide differences of the second type as follows: Note that most of the rows are clustered together in space. Hence, we aim to privately identify the regions which contain many of the rows.

Formally, we use a classic high dimensional \((,)\)-differentially private histogram learner on \(}\) and for the \(k\) largest bins of highest count privately return their average (cf. Lemma A.13). The crux of the argument here is that the cardinality of \(}\) is sufficiently small that the privacy guarantees of the histogram learner can be extended even for inputs that differ in \(|}|\) many samples. Finally, standard composition arguments will guarantee privacy of the whole algorithm.

Comparison with the framework of Kothari-Manurangsi-VelingkerBoth Kothari-Manurangsi-Velingker  and our work obtained private algorithms for high-dimensional statistical estimation problems by privatizing strongly convex programs, more specifically, sum-of-squares (SoS) programs. The main difference between KMV and our work lies in how we choose the SoS program. For the problem of robust moment estimation, KMV considered the canonical SoS program from  which contains a minimum cardinality constraint (e.g., \(_{l}z_{il}\) in the case of GMMs). Such a constraint is used to ensure good utility. However, as alluded to earlier, this is problematic for privacy: there will always exist two adjacent input datasets such that the constraints are satisfiable for one but not for the other. KMV and us resolve this privacy issue in different ways.

KMV uses an exponential mechanism to pick the lower bound of the minimum cardinality constraint. This step also ensures that solutions to the resulting SoS program will have low sensitivity. In contrast, we simply drop the minimum cardinality constraint. Then the resulting SoS program is always feasible for any input dataset! To still ensure good utility, we additionally pick an appropriate objective function. For example, in Gaussian mixture models, we chose the objective \(\|W-J\|_{F}^{2}\). Our approach has the following advantages: First, the exponential mechanism in KMV requires computing \(O(n)\) scores. Computing each score requires solving a large semidefinite program, which can significantly increase the running time. Second, proving that the exponential mechanism in KMV works requires several steps: 1) defining a (clever) score function, 2) bounding the sensitivity of this score function and, 3) showing existence of a large range of parameters with high score. Our approach bypasses both of these issues.

Further, as we show, our general recipe can be easily extended to other high dimensional problems of interest: construct a strongly convex optimization program and add noise to its solution. This can provide significant computational improvements. For example, in the context of SBMs, the framework of  would require one to sample from an exponential distribution over matrices. Constructing and sampling from such distributions is an expensive operation. However, it is well-understood that an optimal fractional solution to the basic SDP relaxation we consider can be found in _near quadratic time_ using the standard matrix multiplicative weight method , making the whole algorithm run in near-quadratic time. Whether our algorithm can be sped up to near-linear time, as in , remains a fascinating open question.

Comparison with previous works on empirical risk minimizationResults along the lines of the sensitivity bound described at the beginning of the section (see Lemma B.1 for a formal statement) have been extensively used in the context of empirical risk minimization . Most results focus on the special case of unconstrained optimization of strongly convex functions. In contrast, our sensitivity bound applies to the significantly more general settings where both the objective functions and the constrained set may depend on the input.21 Most notably for our settings of interest,  studied unconstrained optimization of (smooth) strongly convex functions depending on the input, with bounded gradient. We recover such a result for \(X^{}=X\) in _(ii)_. In , the authors considered constraint optimization of objective functions where the domain (but _not_ the function) may depend on the input data. They showed how one can achieve differential privacy while optimize the desired objective function by randomly perturbing the constraints. It is important to remark that, in , the notion of utility is based on the optimization problem (and their guarantees are tight only up to logarithmic factors). In the settings we consider, even in the special case where \(f\) does not depend on the input, this notion of utility may not correspond to the notion of utility required by the estimation problem, and thus, the corresponding guarantees can turn out to be too loose to ensure the desired error bounds.