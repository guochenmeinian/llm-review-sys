# Variational Inference for Interacting Particle Systems

with Discrete Latent States

 Giosue Migliorini

Department of Statistics

University of California, Irvine &Padhraic Smyth

Department of Statistics and Computer Science

University of California, Irvine

###### Abstract

We present a novel Bayesian learning framework for interacting particle systems with discrete latent states, addressing the challenge of inferring dynamics from partial, noisy observations. Our approach learns a variational posterior path measure by parameterizing the generator of the underlying continuous-time Markov chain. We formulate the problem as a multi-marginal Schrodinger bridge with aligned samples, employing a two-stage learning procedure. Our method incorporates an emission distribution for decoding latent states and uses a scalable variational approximation.

## 1 Introduction

Many real-world phenomena, from epidemics to wildfires, can be modeled as systems of interacting components evolving in continuous time, where the underlying dynamics are governed by discrete latent states. This paradigm extends the concept of hidden Markov models (Baum and Petrie, 1966; Kouemou and Dymarski, 2011) to spatially structured, continuous-time processes. Interacting particle systems (IPSs) (Liggett, 1985; Lanchier, 2024) offer a powerful mathematical framework for describing local propagation dynamics. However, inferring the rules governing these systems from partial, noisy observations remains a significant challenge. We propose a novel Bayesian approach that addresses this challenge by learning a variational posterior path measure on the space of IPS trajectories. Our approach parameterizes the rate matrix of the continuous-time Markov chain (CTMC) of the latent IPS using neural networks and incorporates an emission model that can decode internal discrete states to continuous data and noisy observations. Key contributions of our approach include:

* Framing the problem as a multi-marginal discrete Schrodinger bridge, solved by a two-stage procedure: learning an endpoint-conditioned process for trajectory reconstruction, followed by distillation to an unconditional process for prediction.
* A scalable variational approximation using site-wise factorization of time-marginals and assuming independent particle evolution in infinitesimal time intervals conditionally on the present global configuration, enabling efficient learning for high-dimensional spatio-temporal processes.
* Flexibility in incorporating domain knowledge through informative priors on rate matrix entries and neural architectures with desirable inductive biases.

We demonstrate preliminary results of our approach on two simulated datasets for the following tasks: reconstructing the trajectory of an epidemic on a network and predicting wildfire spread on a lattice. For a description of the notation, see Appendix A. An overview of the relevant literature is presented in Appendix B, while proofs and other derivations are provided in Appendix C.

## 2 Background

Interacting particle systemsConsider a graph \(=(V,E)\), and denote \(i j\) if there is an edge between the vertices \(i,j\), i.e., \(\{i,j\} E\). Following Liggett (1985), we refer to vertices \(i V\) as sites. For a countable local state space \(S\), consider the configuration space \(:=\{:V S\}\). For our analysis, we assume both \(V\) and \(S\) to be finite. An IPS adds a continuous-time dimension to this setting. Specifically, we obtain a CTMC \((t)\) on \(\) restricted to a time interval \([0,T]\), whose path space we denote \(_{[0,T]}\). We define \(z^{i}(t) S\) as the state of site \(i\) at time \(t\). We consider a scenario where the dynamics of each site are described by local transition rates that depend on the graph's connectivity (Lanchier, 2017), corresponding to

\[_{t}^{s}(i,(t))_{ t 0 }(z^{i}(t+ t)= z^{i}(t)=s, \,z^{j}(t):\,i j),\]

for \(s\) to \(s^{} s\) at site \(i\) and time \(t[0,T]\), and set \(_{t}^{s s}(i,(t))-_{s^{} s} _{t}^{s s^{}}(i,(t))\). The local transition rates for each site can be compactly represented as matrices \(_{t}(i,(t))\).

**Definition 1** (Local generator).: _A mapping \(_{t}:[0,T]^{|V||S||S|}\) assigning to each configuration \((t)\) a three-dimensional array containing the local transition rate matrices \(_{t}(i,(t))\) for all sites \(i V\)._

One can characterize the CTMC on the space of configurations by making the additional assumption that updates at each site happen independently from one another. Then, for an arbitrarily small \( t\) and \(}\),

\[p_{t+ t|t}(}|)_{ ,}}+ t_{i V}_{t}^{z^{i} ^{i}}(i,(t))_{j i}_{z^{j},^ {j}}+o( t).\] (1)

For brevity, we denote these transition rates as \(_{t}(})_{i V} _{t}^{z^{i}^{i}}(i,(t))_{j i} _{z^{j},^{j}}\). A detailed derivation can be found in Appendix C.3. We refer to endpoint-conditioned processes as Markov bridges, and we provide a quick overview in Appendix C.1 for noisy data.

## 3 Variational Discrete Interacting Particle Systems

We consider a dataset of sequences of observations in a space \(\) and observation times \(\{_{1:K_{j}}^{(j)},t_{1:K_{j}}^{(j)}\}_{j=1:N}\). We assume these are noisy observations of a latent IPS \((^{(j)}(t))_{t[t_{1}^{(j)},t_{K_{j}}^{(j)}]}_{[t_{1}^ {(j)},t_{K}^{(j)}]}\). Pairwise conditional independence is assumed for any couple of observations in a sequence, i.e. \(_{k}^{(j)}_{k}^{(j)}^{(j)}(t)\) for \(t[t_{k}^{(j)},t_{k}^{(j)}]\) and \(t_{k}^{(j)}<t_{k}^{(j)}\). The discrete set of measurement times \(t_{1}^{(j)}<<t_{K_{j}}^{(j)}\) is allowed to be arbitrarily defined for each sequence, e.g., at random or regularly spaced. For ease of illustration, we present our results for a fixed set of observation times \(t_{1},,t_{K}\), but the extension to irregularly sampled time series is straightforward and presented in Appendix C.2. We assume that the graph determining the particles' dependence structure is fixed for each realization and directly deducible from the observed sequences.

Consider an emission distribution \(p_{t}()()\) and a prior path measure \(P(_{[t_{1},t_{K}]})\) for the latent IPS. This can be specified directly on the entries of a prior local generator, encoding possible constraints in the latent dynamics, and by an initial prior distribution. Let \((^{K}_{[t_{1},t_{K}]})\)

Figure 1: An illustration of our methodology on a simulated noiseless dataset of wildfire propagation. The first model approximates a Markov bridge interpolating between the observations, enabling to reconstruct the unobserved trajectory. The second model, approximating the unconditional process, can predict beyond the last observation. Results shown for a held-out example.

denote the reference measure constructed by gluing the prior and emission probabilities at each observed timestep, i.e. \((d_{1:K},(d(t))_{t[t_{1},t_{K}]})=_{k=1}^{K}p_{t_{k}} (d_{k}(t_{k}))P((d(t))_{t[t_{1},t_{K}]})\). The marginal distribution of the data at an observation time \(t_{k}\) is denoted as \(_{k}()\), for \(k=1,,K\). For a given sequence of distributions \(\{_{k}\}_{k=1:K}\), we can express a multi-marginal discrete Schrodinger bridge problem with noisy observations as

\[^{*}*{arg\,min}_{( ^{K}_{[t_{1},t_{K}]})}\{D_{}(\,|| \,)\,|\,q_{t_{k}}=_{k},\,k=1,,K\},\] (2)

where \(q_{t_{k}}()\) correspond to marginalizations of \(\) at each observed timepoint in the space of observations \(\).

Our goal is twofold:

* **Trajectory reconstruction**, by learning the conditional local generator \(_{t}(_{1:K})\) of the Markov bridge \(Q^{*}_{_{1:K}}(_{[t_{1},t_{K}]})\);
* **Prediction**, by learning the local generator \(_{t}\) of the Markov process \(Q^{*}(_{[t_{1},t_{K}]})\), enabling extrapolation beyond an observed time window or with no past observations at all for a given graph.

We show that the second goal can be achieved by distilling knowledge from a model trained for the first goal into a model that does not glance at future observations.

### Trajectory reconstruction

Let \(_{1:K}\) denote the coupling solving the static version of (2), that is

\[_{1:K}=*{arg\,min}_{q_{1:K}(^{K})}\{ D_{}(q_{t_{1:K}} p_{t_{1:K}})\,|\,q_{k}=_{k},\,k=1,,K\},\] (3)

where \(p_{1:K}(^{K})\) is the marginal of the observed trajectories obtained from the reference measure \(\). Similarly to the setting considered in Sommath et al. (2023), we assume that our dataset is comprised of trajectories of _aligned_ samples, in the sense that each observed trajectory \(_{1:K}\) is sampled from the coupling \(_{1:K}\). By the additive property of the Kullback-Leibler divergence (Leonard, 2013), the dynamic problem in equation 2 can be rewritten as

\[*{arg\,min}_{Q(_{[t_{1},t_{K}]})} _{_{1:K}}[D_{}(Q_{_{1:K}} P_{ _{1:K}})].\] (4)

As samples from \(_{1:K}\) are available, we can treat this stage as a _smoothing_ problem, and perform approximate posterior inference.

#### 3.1.1 Noiseless data

In the special case where observations are noiseless snapshots of the IPS, i.e. \(_{k}=(t_{k})\), the latent variables in the model correspond to the unobserved portions of the stochastic process of the form \(((t))_{t(t_{k},t_{k+1})}\). The emission distribution corresponds to the transition probability \(p_{t_{k}}()=_{t t_{k+1}^{-}}((t_{k})= (t)=)\), obtained from the prior rates using equation 1. We learn a variational posterior \(Q^{}(_{[t_{1},t_{K}]})\) through amortization (Amos et al., 2023), by parameterizing the local generator of the approximate Markov bridge with a neural model \(^{}\), having parameters \(\).

**Proposition 2**.: _Let (3) admit a solution \(_{1:K}\). Moreover, let \(_{1:K}\) be noiseless observations of \(((t))_{[0,T]}\), and let \(P(_{[0,T]})\). Then, the amortized version of the problem in equation 2 reduces to_

\[*{arg\,min}_{}_{k=1}^{K-1}_{_{k,k+ 1}}[D_{}(Q^{}_{_{k},_{k+1}}||\,P)- _{Q^{}_{_{k},_{k+1}}}[ p_{t_{k+1}}( _{k+1}(t_{k+1}^{-}))]],\] (5)

_where \(_{k,k+1}(^{2})\) is obtained by marginalizing \(_{1:K}\), and \((t_{k+1}^{-})=_{t t_{k+1}^{-}}(t)\)._

Notice that this parameterization is highly scalable as it allows mini-batching across segments of time. The KL divergence of two CTMCs can be estimated using Monte Carlo integration, using the analytic form derived in Opper and Sanguinetti (2007), see Appendix C.4 for a derivation.

#### 3.1.2 Noisy data

In order to learn a conditional model with noisy data, we propose to parameterize our variational posterior in an autoregressive fashion, extending the method proposed in Seifner and Sanchez (2023). The authors propose to compute a single hidden representation of the entire sequence via an ODE-RNN model (Rubanova et al., 2019), and then condition the inference model at every time step using that variable. We extend their approach by letting the conditioning variable change through time, only capturing dependence on future observations. Note that the option to drop conditioning on past observations follows naturally from the conditional independence assumption. We do not need to train multiple models to accomplish this, as it is enough to checkpoint the ODE-RNN model at the observation times. We can express the variational posterior as

\[q^{}_{t_{1}}(d(t_{1})\,|\,h_{t_{1}}(_{1:K}))_{k=1}^{K-1 }dQ^{}((d(t))_{t(t_{k},t_{k+1})}\,|\,(t_{k}),h^{}_{t _{k}}(_{k+1:K})),\] (6)

where \(q^{}_{t_{1}}\) is a Categorical distribution parameterized by an encoder. The model can be learned by minimizing the negative evidence lower bound

\[^{}()_{_{1:K}}[D_{ {KL}}(Q^{}_{:|_{1:K}}\,||\,P)-_{Q^{}_{:|_{1 :K}}}[_{k=1}^{K} p_{t_{k}}(_{k}\,(t_{k}))] ].\] (7)

#### 3.1.3 Simulation

While at sampling time any exact stochastic simulation algorithm (e.g. Gillespie, 2001) can be employed, at training time we are limited to differentiable approximations. We propose two options, trading off assumptions on the variational family for scalability.

Forward simulationThis approach involves fixing a time-discretization grid \(t_{k}<t_{k}+ t<<t_{k+1}- t<t_{k+1}\) and sampling iteratively from a Gumbell-softmax approximation (Jang et al., 2017) to equation 1, updating the latent state \((t+ t)=(t)+N_{t}^{}( t,(t))\), where \(N_{t}^{}\) is the jump process describing the latent CTMC. While this method is exact in the limit \( t 0\) and requires no additional restrictions to the variational family, its cost scales linearly with respect to the number of jumps (Jia and Benson, 2019). However, we are not required to compute inflow rates (of the form \(^{s z^{i}}\)), but only outflow rates (like \(^{z^{i} s}\)), making the output of our local rates model scale linearly with respect to \(|S|\).

Neural master equationTechniques from the literature on neural ODEs (Chen et al., 2021) can be applied if we consider a factorized posterior \(q_{t}(\,_{1:K})=_{i V}q_{t}^{i}(z^{i}_{1:K})\). Note that spatial dependence is still propagated through time, as the local rates model depends on the global configuration (or a neighborhood restriction). For notational simplicity we omit conditioning on \(_{1:K}\), but note that this applies to conditional and unconditional settings alike. We can then simulate from the system of marginal master equations given initial conditions \(q_{1}^{i}(z_{1}^{i}),\,i V,\) as

\[_{t}q_{t}^{i}(z^{i}(t))=_{s z^{i}(t)}_{q_{i }^{-i}}_{t}^{s z^{i}(t)}(i,(t))q_{t}^{i}(s)- _{q_{t}^{-i}}_{t}^{z^{i}(t) s}(i,(t)) q_{t}^{i}(z^{i}(t))\,,\,\,i V.\] (8)

This variational approximation was introduced for continuous-time Bayesian networks in Linzner and Koeppl (2018) under the name of _star_-approximation. This is to be distinguished from the _mean-field_ approach, where the approximation entails either a fixed rate for each site or compartmental models directly describing the mean-field behaviour of the system (Seifner and Sanchez, 2023; Opper and Sanguinetti, 2007; Cohn et al., 2010). As the solution to equation 8 is a continuous function, one can use the memory-efficient adjoint method (Chen et al., 2021; Seifner and Sanchez, 2023) at training time, making this approach extremely scalable.

### Prediction

The trajectory reconstruction model learned in Section 3.1 approximates the Schrodinger bridge \(^{}\) through an endpoint-conditioned scheme for the latent trajectories, leveraging the factorization \(Q^{}_{:|_{1:K}}((dz(t))_{t[t_{1},t_{K})})_{1:K}(d_{1:K})\). However, for many applications, we require the ability togenerate predictions beyond observed time intervals. Given an initial observation \(_{1}\) at time \(t_{1}\), we aim to predict observations at arbitrary times \((t_{1},t_{K}]\). This prediction task leverages an alternative factorization of \(^{}\):

\[q_{}^{}(d_{}(\,))Q^{}_{ _{1}}((d(t))_{t[t_{1},t_{K}]})_{1}(d_{1}).\]

While it can be shown that \(q_{}^{}(_{}(\,))=p_{} (_{}(\,))\) using the additive property of the KL, the models developed thus far are constrained by their dependence on endpoint conditions. To overcome this limitation, we propose learning an unconditional amortized posterior \(Q^{}\) by minimizing the KL divergence

\[_{}() D_{}(Q^{}\,||\,Q^{}) _{_{1:K}}[D_{}(Q^{}_{_{1:K}},||,Q^{})].\] (9)

A direct computation of this loss is intractable due to the unavailability of \(Q^{}\) and \(Q^{}_{_{1:K}}\), hence we employ the surrogate loss function

\[}_{}^{}()_{_{1:K}} [D_{}(Q^{}_{_{1:K}},||,Q^{})].\] (10)

The absolute difference between these quantities can be upper bounded in terms of the total variation distance between the solution to equation 2 and our conditional approximation. We provide a detailed analysis of the bound in Appendix C.6.

## 4 Experiments

We demonstrate our methodology on two simulated scenarios: epidemic trajectory inference on networks and wildfire spread prediction on lattices. We parameterize the neural models for the local generators with a novel architecture, detailed in Appendix D. Results and details of the simulations are reported in Appendix E.

## 5 Conclusion

We introduce a variational inference method to fit partially observed trajectories whose dynamics can be modeled by a continuous-time latent process, parameterized as an interacting particle system. Our solution is an approximation to a multi-marginal Schrodinger bridge, that we obtain by first fitting an endpoint-conditioned model and then distilling it into an unconditional one. This methodology enables both trajectory reconstruction and prediction of future states. In future work we aim at testing our models on real data, comparing with state-of-the-art methods.