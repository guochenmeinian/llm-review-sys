# Stage 1: Answer Agent Election & Answering

Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Visual geo-localization demands in-depth knowledge and advanced reasoning skills to associate images with real-world geographic locations precisely. In general, traditional methods based on data-matching are hindered by the impracticality of storing adequate visual records of global landmarks. Recently, Large Vision-Language Models (LVLMs) have demonstrated the capability of geo-localization through Visual Question Answering (VQA), enabling a solution that does not require external geo-tagged image records. However, the performance of a single LVLM is still limited by its intrinsic knowledge and reasoning capabilities. Along this line, in this paper, we introduce a novel visual geo-localization framework called smileGe that integrates the inherent knowledge of multiple LVLM agents via inter-agent communication to achieve effective geo-localization of images. Furthermore, our framework employs a dynamic learning strategy to optimize the communication patterns among agents, reducing unnecessary discussions among agents and improving the efficiency of the framework. To validate the effectiveness of the proposed framework, we construct GeoGlobe, a novel dataset for visual geo-localization tasks. Extensive testing on the dataset demonstrates that our approach significantly outperforms state-of-the-art methods. The source code is available at https://anonymous.4open.science/r/ViusalGeLocalization-F8F5/ and the dataset will also be released after the paper is accepted.

## 1 Introduction

Visual geo-localization, referred to the task of estimating geographical identification for a given image, is vital in various fields such as human mobility analysis [1; 2; 3; 4; 5] and robotic navigation [6; 7; 8; 9; 10; 11]. In general, accurate visual geo-localization without the help of any localization equipment (_e.g.,_ GPS sensors) is a complex task that requires abundant geospatial knowledge and strong reasoning capabilities. Traditional methods [12; 13; 14; 15] typically formulate it as an image retrieval problem where to geo-localize the given image by retrieving similar images with known geographical locations. Thus, their effectiveness is limited by the scope and quality of the geo-tagged image records.

Recently, the success of Large Vision-Language Models (LVLMs) has enabled Visual Question Answering (VQA) to become a unified paradigm for multi-modal problems [16; 17], providing a novel solution for visual geo-localization without the need for external geo-tagged image records. However, the performance of a single LVLM on the geo-localization task is still limited by its inherent geospatial knowledge and reasoning capabilities. Along this line, in this paper, we introduce a novel multi-agent framework, named **swarm** intelligence **Geo**-localization (**smileGeo**), which aims to adaptively integrate the inherent knowledge and reasoning capabilities of multiple LVLMsto effectively and efficiently geo-localize images. Specifically, for a given image, the framework initially elects \(K\) suitable LVLM agents as answer agents for initial location analysis. Then, each answer agent chooses several review agents via an adaptive social network, which imitates the collaborative relationships between agents with a target on the visual geo-localization task, to discuss and share their knowledge for refining its location analysis. Finally, our framework conducts free discussion among all of the answer agents to reach a consensus. Besides, we also design a novel dynamic learning strategy to optimize the election mechanism along with the adaptive collaboration social network of agents. We hope that by the effectiveness of the election mechanism and the review mechanism, our framework can discover the mode of communication among agents, thereby enhancing geo-localization performance through multi-agent collaboration while minimizing unnecessary discussions. In summary, our contributions are demonstrated as follows:

* A novel swarm intelligence geo-localization framework, smileGeo, is proposed to adaptively integrate the inherent knowledge and reasoning capability of multiple LVLMs through discussion for visual geo-localization tasks.
* A dynamic learning strategy is introduced to discover the most appropriate discussion mode among LVLM agents for enhancing the effectiveness and efficiency of the framework.
* A new visual geo-localization dataset named GeoGlobe1 is collected, containing a wide variety of images globally. The diversity and richness of GeoGlobe allow us to evaluate the performance of different models more accurately. Moreover, extensive experiments demonstrate our competitive performance compared to state-of-the-art methods.

The remainder of this paper is organized as follows: Section 2 discusses the related literature. In Section 3, the proposed framework is introduced. Section 4 provides the performance evaluation, and Section 5 concludes the paper.

## 2 Related Work

**Visual Geo-localization**. Recent research in visual geo-localization, commonly referred to as geo-tagging, primarily focuses on developing image retrieval systems to address this challenge [3; 18; 19; 20; 21; 22]. These systems utilize learned embeddings generated by a feature extraction backbone, which includes an aggregation or pooling mechanism [23; 24; 25; 26]. However, the applicability of these retrieval systems to globally geo-localize landmarks or natural attractions is often limited by the constraints of the available database knowledge and the restrictions imposed by national or regional geo-data protection laws. Alternatively, some studies treat visual geo-localization as a classification problem [27; 28; 29; 30]. These approaches posit that two images from the same geographical region, despite depicting different scenes, typically share common semantic features. Practically, these methods organize the geographical area into discrete cells and categorize the image database accordingly. This cell-based categorization facilitates scaling the problem globally, provided the number of categories remains manageable. However, while the number of countries globally remains relatively constant, accurately enumerating cities in real-time at a global scale is challenging due to frequent administrative changes, such as city reorganizations or mergers, which reflect shifts in national policies. Additionally, in the context of globalization, this strategy has inherent limitations. The recent advent of LVLMs offers promising compensatory mechanisms for the deficiencies observed in traditional geo-localization methodologies, making the exploration of LVLM-based approaches significantly relevant in current research.

**Multi-agent Framework for LLM/LVLMs**. LLM/LVLM agents have demonstrated the potential to act like human [31; 32; 33], and a large number of studies have focused on developing robust architectures for collaborative LLM/LVLM agents [34; 35; 36; 37; 38]. These architectures enable each LLM/LVLM agent that endows with unique capabilities to engage in debates or discussions. For instance,  proposes an approach to aggregate multiple LLM/LVLM responses by generating candidate responses from various LLM/LVLM in a single round and employing pairwise ranking to synthesize the most effective response. While some studies  utilize a static architecture potentially limiting the performance and generalization of LLM/LVLM, others like  have implemented dynamic interaction architectures that adjust according to the query and incorporate user feedback.

Recent advancements also demonstrate the augmentation of LLM/LVLM as autonomous agents capable of utilizing external tools to address challenges in interactive settings. These techniques include retrieval augmentation [39; 40; 41], mathematical tools [40; 42; 43], and code interpreters [44; 45]. With these capabilities, LLM/LVLMs are well-suited for various tasks, especially for geo-localization. However, most LLM/LVLM agent frameworks mandate participation from all agents in at least one interaction round, leading to significant computational overhead. To address this issue, our framework introduces a dynamic learning strategy electing only a small number of agents to geo-localize different images, which significantly enhances the efficiency of LLM/LVLM agents by reducing unnecessary interactions.

## 3 Methodology

In this section, we first present the overall framework and then introduce each part of smileGeo in detail for geo-localization tasks.

### Model Overview

In this paper, we denote the social network of LVLM agents by \(\), where \(=\{,\}.\) stands for the agent set and \(\) presents the edge set. Each agent \(v_{i},i[N]\) is an LVLM, which is pre-trained by massive vision-language data and can infer the possible location \(\) of a given image \(\). Besides, each edge \(e_{ij},i,j[N]\) is the connection weighted by the improvement effect of agent \(v_{i}\) to agent \(v_{j}\) via discussion regarding the geo-localization performance.

As illustrated in Figure 1, smileGeo contains the process of the review mechanism in agent discussions along with a dynamic learning strategy of agent social networks:

The review mechanism in agent discussions is a 3-stage anonymous collaboration approach to allow LVLM agents to reach a consensus via discussion. In the first stage, for a given image \(\), our framework elects the most suitable \(K\) agents as answer agents by agent election probability \(\). In the second stage, these answer agents respectively select \(R\) review agents by the adaptive collaboration social network \(\) to refine their answer via discussion. Finally, our framework facilitates consensus among all agents through open discussion to reach a final answer. Both \(\) and \(\) are analyzed from the given image \(\), allowing our framework to minimize unnecessary discussions, thereby significantly enhancing its efficiency while maintaining its accuracy. Moreover, the multi-stage discussion facilitates communication among agents, maximizing the integration of their knowledge and reasoning abilities to generate an accurate response \(\).

To get \(\) and \(\), we specifically design a dynamic learning module, which initially deploys the encoder component of a pre-trained image variational autoencoder (VAE) to extract features from the given image \(\). The extracted features, combined with agent embeddings \(\), are employed to determine the suitability of agents _w.r.t._\(\) for agent discussions and predict agent collaboration connections \(\) in the geo-localization task.

### Review Mechanism in Agent Discussions

LLM/LVLM have demonstrated remarkable capabilities in complicated tasks and some pioneering works have further proven that the performances can be further enhanced by ensembling multiple LLM/LVLM agents. Thus, to improve the geo-localization capability of LVLMs, we propose a cooperation framework to effectively integrate the diverse knowledge and reasoning abilities of multiple LVLMs. Inspired by the fact that community review mechanisms can improve the quality of manuscripts, an iterative 3-stage anonymous reviewing mechanism is proposed for helping agents share knowledge and reasoning capability with each other through their collaboration social network: i) answer agent election & answering, ii) review agent selection & reviewing, and iii) final answer conclusion.Initially, we select \(K\) agents with the highest agent election probabilities \(\) as answer agents and let them geo-localize independently as the preliminary step for further discussion. By initiating the discussion with a limited number of agents, we aim to reduce potential chaos and maintain the efficiency of our framework as the number of participating agents increases.

After the answer agents are elected, we send the image \(\) to all answer agents and let them give the primary analysis. Each answer must contain three parts: one location (city, country, and so on), one confidence (a percentage number), and a detailed explanation.

**Stage 2: Review Agent Selection & Reviewing**

In this stage, for each answer agent, we choose \(R\) review agents by performing a transfer-probability-based random walk on the agent collaboration social network \(\) for answer reviewing. The transfer probability \(p(v_{i},v_{j})\) from node \(v_{i}\) to node \(v_{j}\) can be calculated as follows:

\[p(v_{i},v_{j})=_{ij}}{_{k(v_{i})} _{ik}},&e_{ij}\\ 0,&\] (1)

where \((v_{i})\) is the 1-hop neighbor node set of node \(v_{i}\).

For each selected review agent, it reviews the results as well as the explanations generated by the corresponding answer agent and gives its own comments. After that, each answer agent would summarize their preliminary analysis and the feedback from all of its review agents to get the final answer, which must include three parts as well: one location, one confidence, and an explain.

**Stage 3: Final Answer Conclusion**

In the previous stage, each answer agent produces a refined result based on feedback. When \(K>1\) in Stage 1, the proposed framework generates multiple independent results, which may not be consistent.

Figure 1: The framework overview of smileGeo. It contains the process of review mechanism in agent discussions along with a dynamic learning strategy of agent collaboration social networks. The first part deploys a review mechanism for LVLMs to discuss and share their knowledge anonymously, which could enhance the overall performance of geo-localization tasks. The second one mainly utilizes the GNN-based learning module to improve efficiency by reducing unnecessary discussions among agents while showing the process of updating the agent collaboration social network during the training process.

However, we aim to provide a definitive answer rather than multiple options for people to choose from. To address this, we allow up to \(Z\) rounds of free discussion among those answer agents to reach a unified answer:

First, we maintain a global dialog history list, \(diag\), recording all replies agents respond. In addition, discussions are executed asynchronously, which means that any answer agent can always reply based on the latest \(diag\), and replies would be added to the end of \(diag\) as soon as they are posted. Each answer agent is allowed to speak only once in each discussion round, and after \(Z\) rounds of free discussion, we determine the final result using a minority-majority approach, _i.e.,_ we choose the reply with the most agreement as the final conclusion. If all agents reach a consensus, we early stop this stage and adopt the consensus answer as the final answer. If none of any consensus is reached, we only select the reply of the first answer agent elected from Stage 1 as the final result.

### Dynamic Learning Strategy of Agent Collaboration Social Networks

In our framework, choosing the appropriate answer agents and review agents for knowledge sharing and discussion is vital to its effectiveness and efficiency. Therefore, we propose a dynamic learning strategy to optimize them. Specifically, for each training sample, _i.e.,_ a geo-tagged image, we would first estimate the optimal answer agent election probability \(}\) and the optimal collaboration social network of agent \(}\) by its actual location. Then we train an attention-based graph neural network, which aims to predict \(\) and \(\), by such estimated ground truth.

To estimate the optimal \(}\) and \(}\) for agents to geo-localize image \(\), we first initialize the agent social network \(^{(0)}\) by a fully connected graph with the agent set \(\). Besides, we initialize the agent election probability \(^{(0)}=[0.5,0.5,]\), with all agents having \(50\%\) probability of being chose as answer agents.

Then, we iteratively conduct our 3-stage discussion framework to get the prediction answer. \(^{(l)}\) and \(^{(l)}\) is updated at the end of each round \(l L\) by comparing the answers \(_{v_{i}}^{(l)}\) from each answer agent with the ground truth \(}\).

After \(L\) rounds of agent discussions, the updated agent election probability for an image \(\), \(}:=^{(L)}()=[P_{v_{1}}^{(L)},P_{v_{2}}^{ (L)},,P_{v_{N}}^{(L)}]\), determines whether an agent \(v_{i}\) gives the correct/wrong answers \(_{vi}^{(L)}\) by comparing it with the ground truth \(}\). Here, the definition of \(P_{v_{i}}^{(l)}\) of agent \(v_{i}\) at round \(l\) is as follows:

\[P_{v_{i}}^{(l)}:=0,&(},_{v_{i} }^{(l)})>th\\ 1,&(},_{v_{i}}^{(l)}) th\\ ,&v_{i}\] (2)

where \(th\) is a pre-defined threshold for determining whether the predicted location is close enough to the actual location. In the distance function \(()\), we first deploy geocoding to convert natural language into location intervals in a Web Mercator coordinate system (WGS84) by utilizing OSM APIs, and then compute the shortest distance between two two location intervals.

Please note that, rather than electing the top-\(K\) answer agents in each round, we choose each agent with probability \(P_{v_{i}}\) during the training period to ensure that every agent has the opportunity to participate in the discussion for more accurate estimation, as shown at the left part of the dynamic learning strategy module of agent collaboration social networks in Figure 1.

In addition, the agent collaboration social network would also be updated by comparing the actual location with the generated answer of each answer agent at the same time. For \(l\)-th round, we strengthen the link between the correctly answered agent and the corresponding review agents while weakening the link between the incorrectly answered agent and the corresponding review agents:

\[}_{ij}:=_{ij}^{(l)}()= {A}_{ij}^{(l-1)}(),&v_{i}\\ _{ij}^{(l-1)}(),&v_{i}\] (3)where \(_{ij}^{(l-1)}()\) is the weight of the connection between answer agent \(v_{i}\) and review agent \(v_{j}\) at round \(l-1\) when geo-locating image \(\), \(_{ij}^{(0)}()=1,i j,_{ii}^{(0)}()=0,i,j[N],\,tt\) is the number of consecutive times an agent has answered correctly, which is used to attenuate the connection weights when updating them, preventing the performance of an agent on a certain portion of the continuous dataset from interfering with the model's evaluation of the current agent's performance on the entire dataset.

Then, we try to learn an attention-based graph neural network to predict the corresponding optimal agent election probability \(=h(,|)\) and the optimal agent collaboration connections \(=f(,|)\):

\[&=_{}( ,,)\\ &=(^{}}{ }}),\\ &=^{}(( (() ))),\\ &=(+_{}()),\] (4)

where \(,\) are two learnable parameters, \(:=[_{v_{1}},_{v_{2}},]^{}\) is the agent embedding and \(\) is the weight matrix, \(()\) is the LeakyReLU function, \(^{}()\) is the Sigmoid function, \(_{}()\) is the encoder of the image VAE that compresses and maps the image data into the latent space. It is used to align the image features with the agent embedding, and \(d_{k}\) is the dimension of the \(\). Our learning target can be formalized as:

\[_{}_{i}^{N}(},_{v_{i}})(v_{i})+(},)+(},),\] (5)

where \(()\) denotes the distance between the places an LVLM agent answered and the ground truth, \(()\) is the indicator function, \(_{v_{i}}:=_{v_{i}}^{(L)}=g_{v_{i}}(,_{v_{j}}^{(L-1)})\), \(g_{v_{i}}()\) represent the LVLM agent \(v_{i}\) with fixed parameters and \(_{v_{i}}^{(0)}=g_{v_{i}}()\) is the answer that LVLM agent \(v_{i}\) generates at the initial stage of discussion.

## 4 Experiments

To evaluate the performance of our framework, we conducted experiments on the real-world dataset that was gathered from the Internet to answer the following research questions:

\(\)**RQ1**: Can smileGeo outperform state-of-the-art methods in open-ended geo-localization tasks?

\(\)**RQ2**: Are LVLM agents with diverse knowledge and reasoning abilities more suitable for building a collaboration social network of agents?

\(\)**RQ3**: How does the setting of hyperparameters affect the performance of smileGeo?

### Experiment Setup

**Datasets**. In this paper, we newly construct a geo-localization dataset named GeoGlobe. It contains a variety of man-made landmarks or natural attractions from nearly 150 countries with different cultural and regional styles. The diversity and richness of GeoGlobe allow us to evaluate the performance of different models more accurately. More details can be found in Appendix B.

**Implemention Details**. We select both open-source and close-source LVLMs with different scales trained by different datasets as agents in the proposed framework. As for the open-source LVLMs, we utilize several open-source fine-tuned LVLMs: Infi-MM2, Qwen-VL 3, vip-llava-7b&13b4, llava1.5-7b-base&mistral&vicuna5, Ilava-1.6-7b&13b&34b-mistral&vicuna6, CogVLM7. As for the closed-source LVLMs, we chose the models provided by three of the most famous companies in the world: Claude-3-opus8, GPT-4V9, and Gemini-1.5-pro 10. Besides, 99% of images (about 290,000 samples) from the original dataset are randomly chosen as training samples. For the open-world geolocation problem, we construct the test dataset using approximately 4,000 samples, of which nearly 66.67% samples reflected different locations not present in the training dataset. More details about the deployment of smileGeo and the related parameter settings can be found in Appendix C.

**Baselines**. In this work, we compare the proposed framework with three kinds of baselines: single LVLMs, LLM/LVLM-based multi-agent frameworks, and image retrieval approaches. Firstly, we use each LVLM alone as an agent directly for the geo-localization task and compute the performance of these single LVLMs under the same dataset. In addition, we experiment with multi-agent collaborative frameworks, including LLM-Blender , PHP , Reflexion , LLM Debate , and DyLAN . Finally, several state-of-the-art image retrieval approaches, including NetVLAD , GeM , and CosPlace , are also used to be part of the baselines. We set the training dataset as the geo-tagged image database of each image retrieval system and use images in the test dataset for the retrieval system to generate answers.

**Evaluation Metrics**. We use _Accuracy_ (Acc) to evaluate the performance: \(Accuracy=}}{N_{}}\), where \(N_{}\) is the number of samples that the proposed framework correctly geo-localizes, and \(N_{}\) refers to the total number of testing samples.

In this paper, we first geo-encode the answers with the ground truth, _i.e.,_ we transform the addresses described through natural language into latitude-longitude coordinates. Then, we calculate the distance between the two coordinates. When the distance between the two coordinates is less than \(th=50km\) (city-level), we consider the answer of the framework to be correct.

### Performance Comparison

We divide the baseline comparison experiment into three parts: i) comparison with single LVLMs, ii) comparison with LLM/LVLM-based agent frameworks, and iii) comparison with image retrieval systems.

   &  &  \\  & **Natural** & **ManMade** & **Overall** & **Natural** & **ManMade** & **Overall** \\  Infi-MM & 19.2547 & 21.4133 & 20.9883 & 0.9938 & 0.3351 & 0.4648 \\ Qwen-VL & 42.4845 & 37.4657 & 38.4540 & 4.9689 & 11.2093 & 9.9804 \\ vip-llava-13b & 20.6211 & 15.4127 & 16.4384 & 8.323 & 4.3558 & 5.137 \\ vip-llava-7b & 21.9876 & 18.4892 & 19.1781 & 31.9255 & 56.5032 & 51.6634 \\ Ilava-1.5-7b & 17.3913 & 16.3265 & 16.5362 & 27.205 & 47.2129 & 43.273 \\ Ilava-1.6-7b-mistral & 0.3727 & 0.0914 & 0.1468 & 0.8696 & 2.1627 & 1.908 \\ Ilava-1.6-7b-vicuna & 2.2360 & 2.0713 & 2.1037 & 6.9565 & 15.8696 & 14.1145 \\ Ilava-1.6-13b & 10.4348 & 8.8943 & 9.1977 & 12.1739 & 28.2668 & 25.0978 \\ lava-1.6-34b & 10.3106 & 9.1379 & 9.3689 & 52.795 & 77.1855 & 72.3826 \\ CogVLM & 7.7019 & 7.5845 & 7.6076 & 6.8323 & 10.3564 & 9.6624 \\  claude-3-opus & 22.06 & 37.38 & 16.5468 & 33.0435 & 40.7125 & 39.2027 \\ GPT-4V & 27.5776 & 35.3443 & 33.8145 & 61.9876 & 87.6028 & 82.5587 \\ Gemini-1.5-pro & 55.6522 & 60.3107 & 59.3933 & 62.2360 & 82.8206 & 78.7671 \\ 
**smileGeo** & **58.6111** & **64.3968** & **63.2730** & **78.0448** & **87.0069** & **85.2630** \\  

Table 1: Results of different single LVLM baselines.

Firstly, the performance of all single LVLM baselines is shown in Table 1, in terms of the metric Acc. The data in Table 1 indicate that open-source LVLMs with diverse knowledge and reasoning capabilities exhibit significant variations, particularly in geo-localization tasks. This may be due to the difference in the overlap between the pre-training datasets used by different LVLMs and the dataset we constructed. Therefore, in addition to querying the LVLM locations about images, we also incorporated real-time image search results from Google to provide the model with more comprehensive information. These results from Internet retrievals are incorporated into the chain-of-thoughts (CoT)  of LVLMs as external knowledge. At this time, models with larger parameters, such as lava-1.6-34b, demonstrate superior reasoning abilities compared to smaller models (7b or 13b). In addition, closed-source large models also show more consistent performance than their open-source counterparts and are more adept at analyzing and utilizing external knowledge for accurate inferences. Compared to all single LVLMs, our proposed LVLM agent framework surpasses all single LVLM baselines in accuracy. This improvement confirms the effectiveness of different LVLMs collaborating by engaging in discussions and analyzing various types of images, thus producing more precise results.

Secondly, the comparative results across various LLM/LVLM agent frameworks are presented in Table 2. It is evident that the majority of LLM/LVLM agent frameworks surpass individual LVLMs in terms of geo-localization accuracy. This improvement can primarily be attributed to the ability to integrate knowledge from multiple LVLM agents, thereby enhancing the overall precision of these frameworks. However, LLM-Blender and LLM Debate exhibit lower accuracy due to statements of some agents misleading others during discussions, which impedes the generation of correct outcomes. Our framework, smileGeo, guarantees the highest accuracy while being able to accomplish the geo-localization task with the lowest token costs. The average number of tokens our framework spent per query is 18,876, and it is less than the computational overhead of LLM-Blender (23,662), which has the simplest agent framework structure but the lowest accuracy among all baselines. This is mainly due to a'small' GNN-based dynamic learning model being deployed for agent selection stages and significantly reducing unnecessary discussions among agents.

Finally, Table 3 presents the comparison between the proposed framework and existing image retrieval systems. Our framework, smileGeo, consistently outperforms all other retrieval-based approaches. This superior performance can be attributed to the fact that other image retrieval methods rely on a rich geo-tagged image database. In our test dataset, however, two-thirds of the images are new and localized in completely different areas from those in the training dataset. This highlights the shortages of conventional database-based retrieval systems due to the limitations of the geo-tagged image databases and demonstrates the effectiveness of our proposed framework in solving open-world geo-localization tasks.

### Ablation Study

**Number of Agents**. We further demonstrate the relationships between the number of agents and the framework performance. We conduct experiments in two ways: i) by calling the same closed-source LVLM API (Here, we use Gemini-1.5-pro because it performs best without the help of the Internet) under different prompts (_e.g.,_ You are good at recognizing natural attractions; You're a traveler around

  Framework &  LLM- \\ Blender \\  & PHP & Reflexion & 
 LLM \\ Debate \\  & DyLAN & **smileGeo** \\   &  &  &  &  &  &  &  \\  & & & & & & \\  Acc \(\) & 55.7802\% & 60.9809\% & 62.3412\% & 57.0119\% & 62.8187\% & **63.2730\%** \\ Tks \(\) & 23,662 & 154,520 & 109,524 & 260,756 & 159,320 & **18,876** \\  

* 'Acc' stands for the accuracy of the framework;
* 'Tks' means the average tokens a framework costs per query (including image tokens).

Table 2: Results of different agent frameworks without web searching.

   & **Natural** & **ManMade** & **Overall** \\  NetVLAD & 26.5134 & 28.9955 & 28.6047 \\ GeM & 23.1022 & 25.4175 & 25.0749 \\ CosPlace & 28.1688 & 30.2782 & 29.8701 \\ 
**smileGeo** & **58.6111** & **64.3968** & **63.2730** \\  

* Bold indicates the statistically significant improvements (_i.e.,_ two-sided t-test with \(p<0.05\)) over the best baseline.

Table 3: Comparison with image retrieval systems.

Europe) to simulate different agents, and ii) by using different LVLM backbones to represent distinct agents. The results are shown in Figure 2.

As illustrated in Figure 2(a), the framework achieves optimal accuracy with 4 or 5 agents. Beyond this number, the framework's performance begins to deteriorate. This shows that using models with the same knowledge and reasoning capabilities as different agents has limited improvement in the accuracy of the framework. Despite this decline, the performance of frameworks other than LLM-Blender and LLM Debate remains superior to that of a single agent. LLM-Blender and LLM Debate, however, have a significant decrease in model accuracy when the number of agents exceeds 11. This is mainly because both of them involve all LVLMs in every discussion, which suffers from excessive repetitive and redundant discussions. Figure 2(b) reveals that the accuracy of the framework improves with the incorporation of more LVLM backbones, indicating that the diversity of LVLMs can enhance the quality of discussions.

**Hyperparameter \(K\) & \(R\).** There are two hyperparameters, \(K\) and \(R\), that need to be pre-defined in the proposed framework: \(K\) is the number of agents (answer agents) that respond in each round of discussion, and \(R\) is the number of agents (review agents) used to review answers from answer agents. Therefore, we conduct experiments under different combinations of \(K\) and \(R\), as shown in Figure 3. The results indicate that optimal performance can be achieved with relatively small values of \(K\) or \(R\). However, the computational cost, measured in tokens, increases exponentially with higher values of \(K\) and \(R\). To balance both the efficiency and the accuracy of smileGeo, for the experiments presented in this paper, we set both \(K\) and \(R\) equal to 2.

## 5 Conclusion

This work introduces a novel LVLM agent framework, smileGeo, specifically designed for geo-localization tasks. Inspired by the review mechanism, it integrates various LVLMs to discuss anonymously and geo-localize images worldwide. Additionally, we have developed a dynamic learning strategy for agent collaboration social networks, electing appropriate agents to geo-localize each image with different characteristics. This enhancement reduces the computational burden associated with collaborative discussions among LVLM agents. Moreover, we have constructed a geo-localization dataset called GeoGlobe and will open-source it. Overall, smileGeo demonstrates significant improvements in geo-localization tasks, achieving superior performance with lower computational demands compared to contemporary state-of-the-art LLM/LVLM agent frameworks.

Looking ahead, we aim to expand the capabilities of smileGeo to incorporate more powerful external tools beyond just web searching. Additionally, we plan to explore extending its application to complex scenarios, such as high-precision global positioning and navigation for robots, laying the cornerstone for exploring LVLM agent collaboration to handle different complex open-world tasks efficiently.

Figure 3: Results under different \(K\) and \(R\).

Figure 2: Results of model performance in relation to the number of agents.