# F00gd: Federated Collaboration for Both Out-of-distribution Generalization and Detection

Xinting Liao\({}^{1}\), Weiming Liu\({}^{1}\), Pengyang Zhou\({}^{1}\), Fengyuan Yu\({}^{1}\), Jiahe Xu\({}^{1}\),

Jun Wang\({}^{2}\), Wenjie Wang\({}^{3}\), Chaochao Chen\({}^{1}\), Xiaolin Zheng\({}^{1}\)

\({}^{1}\) Zhejiang University, \({}^{2}\) OPPO Research Institute, \({}^{3}\) National University of Singapore

{xintingliao, 21831010, zhoupy, zjuccc, xlzheng}@zju.edu.cn, junwang.lu@gmail.com, wenjiewang96@gmail.com

Corresponding author.

###### Abstract

Federated learning (FL) is a promising machine learning paradigm that collaborates with client models to capture global knowledge. However, deploying FL models in real-world scenarios remains unreliable due to the coexistence of in-distribution data and unexpected out-of-distribution (OOD) data, such as covariate-shift and semantic-shift data. Current FL researches typically address either covariate-shift data through OOD generalization or semantic-shift data via OOD detection, overlooking the simultaneous occurrence of various OOD shifts. In this work, we propose F00GD, a method that estimates the probability density of each client and obtains reliable global distribution as guidance for the subsequent FL process. Firstly, SM\({}^{3}\)D in F00GD estimates score model for arbitrary distributions without prior constraints, and detects semantic-shift data powerfully. Then SAG in F00GD provides invariant yet diverse knowledge for both local covariate-shift generalization and client performance generalization. In empirical validations, F00GD significantly enjoys three main advantages: (1) reliably estimating non-normalized decentralized distributions, (2) detecting semantic shift data via score values, and (3) generalizing to covariate-shift data by regularizing feature extractor. The prejoct is open in https://github.com/XeniaLL/F00GD-main.git.

## 1 Introduction

Federated learning (FL)  provides a distributed machine learning paradigm, which collaboratively models decentralized data resources. Specifically, each client models its data locally and server improves model performance by aggregating client models, which indirectly shares knowledge among clients and preserves privacy. FL further makes efforts to adapt real-world scenarios, i.e., adapting non-independent and identical distribution (_non-IID_) .

Beyond non-IID issues, deploying FL models in real-world also encounters different tasks of out-of-distribution (OOD) shift , e.g., tackling covariate shifts (_OOD generalization_) and handling semantic shifts (_OOD detection_). In FL, OOD generalization task is devised to capture the invariant data-label relationships of covariate-shift data intra- and inter-client, which offers the potential of adapting unseen clients . The OOD detection task in FL aims to find semantic-shift data samples that do not belong to any known categories of all client data during FL training . Both OOD generalization and detection simultaneously exist in FL, hindering the deployment of FL methods. Nevertheless, the existing work only tackles each OOD task in isolation. SCONE  proposes a unified margin-based framework to realize OOD generalization and OOD detection tasksin centralized machine learning. But it is infeasible to FL due to two reasons, i.e., being non-trivial in searching for consistent margin among non-IID distribution, and requiring outlier exposure of data. This motivates us to a crucial yet unexplored question:

_Can we devise a FL framework that adapts to wild data, which coexists with non-IID in-distribution (IN) data, covariate-shift (IN-C) data, and semantic-shift (OUT) data?_

In this work, we simultaneously promote OOD generalization and detection by collaborating with clients in FL. The objectives of OOD generalization and detection vary among different clients due to their non-normalized and heterogeneous probability densities. This motivates us to build systematic and global guidance to distinguish IN, IN-C, and OUT data. As depicted in Fig. 1, for non-IID client distributions, we first estimate the probability density in each local client and then compose these local estimations for global distribution in server. Once a reliable global distribution estimation is established, we can leverage it to guide FL OOD tasks in deployment. However, this approach presents two challenges, i.e., _CH1: How to estimate the reliable and global probability density among decentralized clients for detection?_ and _CH2: How to enhance intra- and inter-client OOD generalization based on global distribution estimation?_

To fill these gaps, we propose a federated collaboration framework named as F00GD, which estimates client distribution in feature space via score matching with maximum mean discrepancy (SM\({}^{3}\)D) and enhances the client model generalization by Stein augmented generalization (SAG). **To solve CH1**, inspired by the flexibility of score matching [58; 7], we originally devise SH\({}^{3}\)D to train score model that estimates limited and heterogeneous data distributions for each client, and aggregate score models in server as global estimation. Because the score values are vectors indicating position and changing degree of the log data density , SM\({}^{3}\)D brings the potential of discriminating OUT data in low-density areas with large change degree. However, it is unreliable to directly apply vanilla score matching for modeling decentralized data, which suffers from sparsity and multi-modal complexity [72; 55]. To obtain a reliable density estimation, SM\({}^{3}\)D explores wider space by generating random samples via Langevin dynamic sampling, and constrains the generated samples to be similar to data samples via maximum mean discrepancy (MMD). **To mitigate CH2**, SAG regularizes feature invariance between data samples and its augmented version, which is measured by score-based discrepancy. Though the existing generalization methods capture the invariance in feature space [1; 34], the vital feature information is inevitably lost due to strictly invariant constraints [87; 10]. This also deteriorates the performance of solving FL OOD generalization. With the benefits of distributional alignment based on Stein identity , SAG in client model captures IN-C data in a similar feature space with IN data, which not only avoids representation collapse but also maintains diversifying information. Thus SAG makes F00GD generalize to IN-C data from local covariate-shift distribution and unseen client distribution.

The main contributions are: (1) We are the first to study OOD generalization and detection in FL simultaneously, and formulate a evaluation on deploying FL methods in the wild data. (2) We propose F00GD which estimates reliable global distributions based on arbitrary client probability densities, to guide both OOD generalization and detection. (3) We devise SH\({}^{3}\)D which not only explores wider probability space for density estimation, but also provides the score function values to detect OUT samples. (4) We utilize SAG to maintain the invariance between IN-C and IN data in feature space, which obtains better generalization without collapsing for FL scenarios. (5) We provide theoretical analyses and conduct extensive experiments to validate the effectiveness of F00GD.

## 2 Related Works

### OOD Detection

OOD detection discriminates semantic shift (OUT) data during deployment time [3; 20; 53]. There are two main categories of OOD detection work, i.e., enhancing training-time regularization [48;

Figure 1: Motivation of F00GD. The distributions of two clients are non-IID, and we seek to estimate the global distribution among decentralized data.

21, 75, 13], and measuring post-hoc detection function of a well-trained model . The first category focuses on ensuring predictors produce low-confidence predictions for OOD data during training, which is effective but mainly requires access to real OUT data . By the way, selecting different auxiliary detection objectives  unexpectedly varies the overall performance. The second category utilizes the classification logits , energy score , and feature space estimation  from pre-trained models, to detect the OUT data. This reduces the costly computation burden but rigidly relies on the data distribution captured in the pre-trained model. As one kind of methods in post-hoc way, density-based estimation methods  can relieve the cost of collecting or synthesizing representative OOD datasets, avoiding biased and ineffective detection  and bringing the potential of densities composition.

### OOD Generalization

OOD generalization targets extracting invariant feature-label relationships and maintaining the deployment performance of model with covariate-shift data in the open-world . To reach this goal, IRM-based work  utilizes invariant risk regularization to find invariant representations from different covariate shift data. Besides, there are various work calibrating invariant representations by distribution robust optimization methods , feature alignment methods , augmented training , gradient manipulation methods , diffusion modeling  and so on. SCONE  takes advantage of unlabeled wild mixture data to enhance generalization and build detectors simultaneously. However, SCONE is not suitable for FL, since it requires a hyper-parameter of energy margin and the outlier exposure data . To tackle the meta-task detection and generalization, Chen propose an Energy-Based Meta-Learning (EBML) framework that learns meta-training distribution via two energy-based neural networks. However, it is tough to model two reliable energy models in decentralized models where data and computation resources are constrained.

### Federated Learning with Wild Data

In FL, wild data makes it challenging in tackling non-IID modeling, OOD generalization, and OOD detection. Firstly, FL with non-IID data presents significant challenges in balancing global and local model performance (Appendix C). Secondly, FL considers two aspects of generalization, i.e., (1) intra-client generality, and (2) inter-client generality. The intra-client generalization keeps the invariant relationship between data samples and class labels, which is similar to centralized OOD generalization. The inter-client generality work captures invariant representation for heterogeneous client distributions, making the global model adaptive to a newly unseen client . Lastly, regarding OOD detection in FL, it is expected to detect semantic shift data out of the whole class categories set among decentralized data, yet avoid wrongly distinguishing unseen data classes of other clients. FOSTER  treats unseen data classes in each client as OUT, and enhances their detection capability via synthesizing virtual data with external classes of other clients. Different from the above methods, we aim to enhance OOD detection and generalization simultaneously by collaborating with different clients. Recently, FedGMM  utilizes a federated expectation-maximization algorithm to fit data distribution among clients by estimating Gaussian mixture models(GMM), and detects OUT data via computing GMM probability. It can only roughly capture the data distribution with the prior assumption of GMM. Meanwhile, a orthogonal paradigm of studies focus on tackling concept shifts in federated process . However, it overlooks the coexistence of wild data, resulting in suboptimal performance in federated tasks of OOD generalization and detection.

## 3 Methodology

### Problem Setting

**Federated Learning Formulation with Wild Data.** We first formulate the wild data in FL deployment and provide the optimization goal of FL. Empirically, we assume a dataset decentralizes among \(K\) clients, i.e., \(=_{k[K]}_{k}\). The data distribution of \(k-\)th client is simulated following the real-world wild data, i.e., \(_{k}=_{k}^{}+_{k}^{}+ _{k}^{}\). The objective of the FL model, which simultaneously tackles OOD generalization and detection, is defined as follows:

\[*{argmin}_{_{f},_{g}}_{k=1}^{K}w_{k} _{ p_{_{k}}}[_{k}(_{f}, _{g};_{k})],\] (1)where \(_{k}(_{g},_{f};_{k})=_{k}^{}+_{k}^{}+_{k}^{}\), and \(w_{k}\) represents weight ratio for the \(k\)-th client. The OOD measurements \(_{k}^{},_{k}^{},_{k}^{}\) correspondingly justify the IN generalization, IN-C generalization, and OUT detection in each client \(k\), as follows:

\[_{k}^{}:=_{(,y) p_{_{k} ^{}}}(\{y_{}(f_{}()) y\})(a)\] (2) \[_{k}^{}:=_{(,y) p_{ _{k}^{}}}(\{y_{}(f_{}( ) y)\})(b)\] \[_{k}^{}:=_{(,y) p_{ _{k}^{}}}(\{g_{}()= \})(c),\]

where \(f_{}()\) is main task model, \(g_{}()\) is detector, \(\) is indicator function, and \(y_{}\) is predicted label.

**Framework Overview.** To optimize the FL objective in Eq. (1), we propose FOOGD whose framework overview is depicted in Fig. 2. For \(K\) clients with non-IID data, FOOGD composes their local distributions and aggregate their model parameters in server. In each client, the data samples \(\) as well as its fourier augmented  counterparts \(}\), are fed into the same feature extractor of main task \(f_{}()\) to obtain their latent features, \(=f_{}()\) and \(}=f_{}(})\), respectively. To avoid overwhelming communication costs brought by score models, score matching with maximum mean discrepancy (SM\({}^{3}\)D) trains a score model \(s_{}()\) in feature space. This model captures the data distribution by estimating the gradient of log densities (score functions) of latent features \(\), i.e., \(_{^{*}}()=_{} p_{}() _{} p_{}()\). Then score model serves as the detector for the objective in Eq. (2c), discriminating OUT based on the norm of score function values. Besides, Stein augmented generalization (SAG) enhances the generalization capabilities of the feature extractor \(f_{}()\), by the distribution regularization defined via score model. Because score model based distribution ensures that data features and their neighboring augmented samples, e.g., \(\) and \(}\), maintain a consistent probability space . The local modeling iterates until performance converges.

In each communication round, since both main task model and score model are parameterized neural networks, it is practical to follow conventional weighted average aggregation , i.e.,

\[\{_{s},_{f}\}=_{k=1}^{K}w_{k}\{_{s}^{k}, _{f}^{k}\},\] (3)

with \(w_{k}=_{k}|}{_{k=1}^{K}|_{k}|},_{k[ K]}.\) These collaborative processes among clients continue until the global model converges, bringing reliable and comprehensive global distribution in the form of global score model. We introduce the details later and illustrate the algorithm of FOOGD in Appendix A Algo. 1.

### Sm\({}^{3}\)d: Estimating Score Model for Detection

In this part, we introduce the estimation of FL data distribution and how to utilize it for detection. As shown in Fig. 1, a reliable probability density is eagerly necessary for distinguishing IN and OUT data . Different from existing centralized OUT aware and OUT synthesis methods , the FL framework suffers from the accessibility of OUT data . In this study, we aim to explicitly capture the local IN data distribution of clients, and subsequently compose them to reliable global

Figure 2: Framework of FOOGD. For each client, we have main task feature extractor, a SM\({}^{3}\)D module estimates score model (Eq. (8)) for detection, and a SAG module regularizes feature extractor for enhancing generalization. The server aggregates models and obtains global distribution.

distribution for discrimination. However, it remains challenging to estimate heterogeneous and non-normalized probability density without prior information during FL modeling.

**Dynamic Feature Density Estimation.** FOOGD estimates score model via score matching in the feature space , i.e., \(p_{}()\), circumventing the need for prior distribution knowledge or distribution normalization . Moreover, it alleviates the computational burden by modeling the score of latent representations in a smaller, yet more expressive and continuous space, compared to the scores of the original data . Specifically, given the latent features \(=f_{}()\), we perturb it via adding random noise \((,)\) to obtain \(}=+\), which follows noise-perturbed data distribution \(p_{}(}|):=(};, ^{2})\). And we model it with noise conditional score model \(s_{}(},)\) by minimizing the denoising score matching (DSM) loss, i.e.,

\[_{}=_{p_{}()p_{ }(}|)}\|s_{}(}, )-_{}} p_{}(}) \|^{2},\] (4)

where the score function of \(_{}} p_{}(})\) for \(d\)-dimensional features, is computed as follows:

\[_{}} p(})=_{ }}[})^{d}} \{-}-\|^{2}}{2^{2}}\} ]=-}-}{^{2}}=-}{}.\] (5)

When the noise get to zero, i.e., \( 0\), we have the exact score values \(s_{}(},)=s_{}()\). However, score model based density estimation will inevitably fail once the distribution contains sparse data samples  or multiple modalities , as shown in Fig. 3 (a). SM3D is motivated to broadly explore the generated random features \(_{}\) that samples from the whole distribution space. In detail, SM3D first sample from a random distribution, e.g., Normal distribution, as the start latent features, i.e., \(^{0}(,)\). Then SM3D utilizes \(T\)-step Langevin dynamic sampling  (LDS) from density vector fields modeled by the score model, to derive generated latent features \(_{}=^{T}\):

\[^{t}=^{t-1}+s_{}(^{t-1},) +^{t},\] (6)

with \(\) indicating the step size and \(^{t}(,)\) introducing stochasticity in each step. Lastly, the distribution of a batch of the generated features \(_{}=\{_{,i}\}_{i=1}^{B}\), i.e., \(p_{}(_{})\), is supposed to approximate the distribution of original features \(=\{_{i}\}_{i=1}^{B}\), i.e., \(p_{}()\), with the calibration of maximum mean discrepancy (\((,_{})\)) matching:

\[_{}=_{_{},_{}^{ } p_{}}[k(_{},_{}^{}) ]-2_{_{} p_{},_{}^{ } p_{}}[k(_{},_{}^{ })]+_{_{},_{}^{} p_{ }}[k(_{},_{}^{})].\] (7)

where \(k(,^{})=(\|-^{}\|^{2})\) with bandwidth \(h\) is Gaussian kernel function  within a unit ball in universal Reproducing Kernel Hilbert Space (RKHS). Because MMD is a non-parametric method that accurately measures the distance between two densities in RKHS, it provides reliable estimations and adapts well to complex data modalities . This approach mitigates the limitations of directly using DSM to estimate distributions by exploring a wider feature space. Unfortunately, as depicted in Fig. 3 (d), simply using MMD matching does not enhance density estimation, when the target distribution is unknown or inaccurate. But it is quite necessary that the latent distribution is inaccurate and heterogeneous in FL. To fill this gap, SM3D seeks to harness and integrate the strengths of both density estimation paradigms, via a trade-off coefficient \(_{m}\):

\[^{}=(1-_{m})_{}+_{m}_{}.\] (8)

In this way, SM3D brings an accurate and flexible implementation for non-normalized data distribution. The implementation procedure of SM3D is in Appendix A Algo.2. To illustrate the effectiveness of SM3D, we further visualize a density estimation of \(2\)-D toy example in Fig. 3. In detail, we model the red target points by tuning a series of coefficients, i.e., \(_{m}=\{0,0.1,0.5,1\}\) in Eq. (8). As we

Figure 3: Motivation of SM3D. Red points are sampled from target data distribution, and the blue points are generated by LDS in Eq. (6).

can see, with the mutual impacts between score matching and MMD estimation, \(^{3}\) has more compact density estimation when \(_{m}=0.1\), compared with blankly using score matching (\(_{m}=0\)) or simply using MMD (\(_{m}=1\)). As a brand new objective of density estimation, \(^{3}\) expands the searching range and depth of score modeling, making it possible to comprehensively model data density. Moreover, with the calibration of MMD estimation, original data features and the generated samples based on the score model are effectively matched. Hence \(^{3}\) could ensure a more aligned and reliable density estimation for sparse and multi-modal data.

**OOD detection in clients.** Remind that the score function indicates the gradient of the log density, which are actually vector fields pointing to the highest density area, as shown in the score function visualization of Fig. 2. The IN data should point to the high density and reflect the distance via its vector norm. While the OUT data cannot present this satisfying property and further exposure boldly, since the OUT data is always in low-density area [48; 55]. That is, the norm of the score \(\|s_{}}()\|=\|}p_{}}( )}{p_{}}()}\|\) decreases in regions of higher density, while increases in lower density. It indicates the larger the norm of score is, the more likely the data sample is OUT. For _negative threshold_\(<0\), we have detection score function:

\[()=,\|s_{ }}(f_{}}())\|>-;,()=.\] (9)

### Saq: Enhancing Feature Extractor for Gerneralization

In this section, we will illustrate how to enhance generalization capability of feature extractor in FOOGD. In FL scenarios, solving OOD generalization needs not only to keep the local IN-C data classification correctly, but also to maintain performance consistency among all participating clients. The non-IID issue creates a contradiction between achieving both targets. This is because enhancing IN-C accuracy intra-client requires diversification across different classes, whereas inter-client generalization benefits from all IN data being closely clustered, irrespective of class distinctions. Hence, it is expected to balance the feature diversification of different classes and the feature consistency of in-distribution, to realize the consistent data-label relationships intra- and inter-client.

**Diversifying Feature Invariance Augmentation.** FOOGD regularizes invariance among client feature extractors using distribution-aware divergence between the original data \(\) and its augmented version \(}=()\) by transformation \(\). To address this, we propose SAG, which utilizes global distribution and optimizes distributional invariance between latent features of the original and augmented data. This approach maintains the distinguishable diversification of features and consistent data-label mapping across clients.

In the feature space, SAG regularizes original data samples to be aligned with augmented ones, i.e., aligning \(=f_{}()\) and \(}=f_{}(})\). However, directly computing the norm regularization between \(\) and \(}\) will cause mode collapse  in FL, further degrading the estimation of score model \(s_{}()\) based on \(^{3}\). While contrastive methods [62; 73; 51; 50] like FedICON , and L-DAWA  ensure diversification and alignment for generalization, they rely on selecting negative samples instead of leveraging global distribution knowledge. Consequently, they fail to maintain consistent invariance among clients. Instead, SAG alternatively introduces kernelized Stein operator guided by score function, i.e.,

\[_{p}()=()_{} p()+_{ }(),\] (10)

where \(()\) is implemented with kernel function \(k(,)\) mentioned in Eq. (7) , while \(p()\) and \(q(})\) are the distributions for a batch of features \(=\{_{i}\}_{i=1}^{B}\), and \(}=\{}_{i}\}_{i=1}^{B}\), respectively. By utilizing the kernelized Stein operator, SAG encourages the samples of augmented features to align with high probability regions of the original features. Additionally, the second term of (10) improves feature diversification and prevents data from collapsing directly to the original distribution modes. According to a fundamental theory named as Stein identity, i.e., \(_{q(x)}[_{q}(x)]=0\) for arbitrary distribution \(q(x)\), Stein operator brings the potential of measuring two data distributions with the guidance of global distribution estimation. Because score models capture local probability densities and are aggregated into a global score model on the server, they inherit distribution information from all participating clients. Specifically, we first illustrate kernelized Stein discrepancy (KSD) [46; 41; 45] that measures the distribution discrepancy between original data \(p()\) and augmented data \(q(})\):

\[(p(),q(})) =_{},^{}} q}[s_{ }(})^{}s_{}(}^{} )k(},}^{})+s_{}(} )^{}_{}^{}}k(},}^ {})\] (11) \[+s_{}(}^{})^{}_{ {}}k(},}^{})+(_{ }}_{}^{}}k(},}^{}))].\]We provide the full induction of KSD between original data and augmented data in B.2. And \((p(),q(}))\) equals zero if and only if \(p()\) and \(q(})\) are the same. By taking the derivative of KSD, we can obtain the updating direction of moving \(}\) towards \(\), which not only keep the invariance of features, but also guarantee diversification avoiding collapse. Therefore, the augmented representation \(}\) has minimal KSD with the original latents \(\). This ensures that the final objective of the feature extractor is to minimize the subsequent classification error (between predictions \(_{}\) and ground truth \(_{}\)) and achieve invariant alignment:

\[^{}+^{}=(_{},_{})+_{a}\,(p(),q(})).\] (12)

Besides, the score model in Eq. (11) communicates among different clients to obtain the global distribution, making it possible to be reliable guidance of invariance among clients. This makes SAG a potential generalization approach for modeling feature invariance in the overall FL scenario, even acting warm-start for unseen clients. Therefore, FOOGD is capable of both local IN-C data generalization and consistent performance generalization of clients. The algorithm of SAG can be found in Appendix A Algo. 3.

## 4 Theoretical Discussion

In this section, we provide the error bound of modeling score model via \(^{3}\) in federated scenarios, and provide the error bound in Theorem 4.1. Besides, the federated training procedure of score model is the same with the main task model. This indicates that our federated learning convergence bound is unchanged, following . We provide more theoretical details in Appendix B.

**Theorem 4.1** (Error Bound of Decentralized Score Matching via \(^{3}\)).: _Assume the original \((,_{}) C\) for randomly initialized score model \(s_{}()\) in Eq. (7), the score model achieves optimum and MMD decreases. By Lemma B.1, we can obtain the final error bound of global \(s_{}()\) as:_

\[\|s_{}()-_{} p_{}()\|^{2} ^{}}{^{2}}-_{p_{}( )}[\|_{} p_{}()\|^{2}]+|}{ B}C,\] (13)

_where \(C\) is the upper bound of the MMD, \(B\) is batch size, and \(||\) is the data amount._

## 5 Experiments

### Experimental Setups

**Datasets.** Following SCONE , we choose clear Cifar10, Cifar100 , and TinyImageNet  as the IN data, and select the corresponding corrupted versions , i.e., Cifar10-C, Cifar100-C and TinyImageNet-C as IN-C data. We evaluate detection with five OUT image datasets: SVHN , Texture , iSUN , LSUN-C and LSUN-R . To simulate the non-IID scenarios, we sample data by label in a Dirichlet distribution parameterized by non-IID degree , i.e., \(\), for \(K\) clients. The smaller \(\) simulates the more heterogeneous client data distribution in federated settings. To evaluate FOOGD on unseen client generalization data, we also use PACS  dataset for leave-one-out domain generalization. Details of dataset simulation are in Appendix D.1.

**Comparison Methods and Evaluations.** We study the performance of FOOGD with the state-of-the-art (SOTA) federated learning model and FedAvg-like derivant of SOTA centralized OOD methods, i.e., LogitNorm  (FedLN), ATOL  (FedATOL), T3A  (FedT3A). We compare FOOGD with three types of baseline models, i.e., (1) _Vanilla FL model_: **FedAvg** and **FedRoD**, (2) _FL with OOD detection_: **FOSTER**, **FedLN**, and **FedATOL**, (3) _FL with OOD generalization_: **FedT3A**, **FedIIR**, **FedTHE**, **FedICON**. For evaluation, we report the accuracy of IN data (ACC-IN) and IN-C data (ACC-IN-C) to validate IN generalization and OOD generalization, respectively. We compute the maximum softmax probability  (MSP) and report the standard metrics used for OOD detection, i.e., the area under the receiver operating characteristic curve (AUROC), and the false positive rate at threshold corresponding to a true positive rate of 95% (FPR95) .

**Implementation Details.** We choose WideResNet  as our main task model for Cifar datasets, and ResNet18  for TinyImageNet and PACS, and optimize each model 5 local epochs per communication round until converging with SGD optimizer. We conduct all methods at their best and report the average results of three repetitions with different random seeds. We consider client number \(K=10\), participating ratio of \(1.0\) for performance comparison, and the hyperparameters \(_{m}=0.5\), \(_{a}=0.05\). We provide the full implementation details in Appendix D.2.

### Experimental Results

**Performance Comparison on non-IID data.** We categorized our baseline models into two groups based on whether they consider personalization. The results for Cifar10, Cifar100, and TinyImageNet are shown in Tab. 1, Tab. 2, and Tab. 7 in Appendix E.1, respectively. **For the first group without considering personalization**, the existing centralized OOD methods, i.e., LogitNorm (FedLN), ATOL (FedATOL) and T3A (FedT3A), are not directly competitive among different non-IID scenarios. Though FedATOL achieves satisfying results for both generalization and detection tasks on Cifar10 \(=5\), it fails neither in smaller \(\) and dataset containing more classes (i.e., Cifar100). Meanwhile, the vanilla FedAvg degrades its performance in OOD generalization for both Cifar10 and Cifar100 data, and shows no potential of detecting OUT data samples. FedIIR pays more effort to maintain the inter-client generalization via restricting model consistency, making it less effective in non-IID settings. **For the second group of personalized FL methods**, personalization is quite necessary for both IN data generalization and IN-C generalization, which is similarly illustrated in FedTHE  and FedICON . In general, personalized methods are worse in FL detection than non-personalized methods, indicating that there is a conflict between detecting OUT data and enhancing prediction in non-IID setting. More surprisingly, we also discover that personalized adaption methods also detect outliers better compared with vanilla FedRoD model. FOSTER has better detection in more heterogenous data distribution, i.e., \(=0.1\), compared with its results in \(=5\), but its overall performance is supposed to enhance in the future. F00GD is a flexible FL

    &  &  \\   & ACC-IN\(\) & ACC-IN\(\) & PRPS\(\) & ATOL & ACC-IN\(\) & ACC-IN\(\) & PRPS\(\) & ATOL & ACC-IN\(\) & ACC-IN\(\) & PRPS\(\) & ATROC\(\) \\  FedAvg & 68.03 & 65.44 & 83.41 & 58.05 & 86.59 & 83.72 & 43.70 & 84.18 & 86.50 & 58.08 & 38.24 & 85.37 \\ FedN & 75.24 & 71.77 & 54.14 & 84.16 & 86.10 & 84.20 & 39.86 & 89.64 & 87.20 & 85.08 & 33.13 & 90.87 \\ FedT3A & 55.93 & 54.44 & 40.90 & 86.22 & 87.55 & 85.64 & 27.87 & 93.48 & 89.27 & 85.28 & 19.66 & 95.25 \\ FedT3A & 68.03 & 61.52 & 78.13 & 63.64 & 86.59 & 82.85 & 47.50 & 84.18 & 86.50 & 85.11 & 38.24 & 85.37 \\ FedT4R & 68.26 & 66.12 & 79.48 & 63.31 & 86.75 & 84.75 & 49.19 & 84.94 & 87.77 & 66.10 & 34.69 & 57.66 \\ FedT4R & 75.09 & 75.31 & **75.35** & **79.11** & **88.36** & **78.26** & **78.26** & **78.65** & **88.90** & **88.25** & **78.02** & **97.72** \\  FedLoD & 91.15 & 89.90 & 47.97 & 89.96 & 89.62 & 87.70 & 37.03 & 86.50 & 87.69 & 86.26 & 36.13 & 86.65 \\ FOTER & 90.22 & 88.70 & 47.40 & 77.43 & 86.92 & 85.82 & 42.03 & 83.91 & 87.83 & 85.96 & 36.42 & 86.19 \\ FedT4R & 91.05 & 89.71 & 58.14 & 82.04 & 89.14 & 87.68 & 40.28 & 85.50 & 88.14 & 86.18 & 35.55 & 86.79 \\ FedCON & 89.06 & 89.13 & 86.22 & 81.28 & 75.83 & 75.35 & 56.19 & 79.88 & 87.20 & 85.39 & 35.63 & 86.45 \\ FedCoN & **97.51** & **92.74** & **32.99** & **91.72** & **90.46** & **70.16** & **75.81** & **74.19** & **70.44** & **78.62** & **78.91** & **76.25** \\   

Table 1: Main results of federated OOD detection and generalization on Cifar10. We report the ACC of brightness as IN-C ACC, the FPR95 and AUROC of LSUN-C as OUT performance.

    &  &  \\   & ACC-IN\(\) & ACC-IN\(\) & PRPS\(\) & ATOL & ACC-IN\(\) & ACC-IN\(\) & PRPS\(\) & ATOL & ACC-IN\(\) & ACC-IN\(\) & PRPS\(\) & ATROC\(\) \\  FedAvg & 51.67 & 47.54 & 78.53 & 67.16 & 58.28 & 54.62 & 72.84 & 70.36 & 61.40 & 56.72 & 72.68 & 70.59 \\ FedN & 52.48 & 48.15 & 66.94 & 78.24 & 59.39 & 53.56 & 68.31 & 73.41 & 61.00 & 56.33 & 60.18 & 75.87 \\ FedT4R & 43.65 & 41.08 & 46.25 & 81.64 & 60.62 & 56.63 & 70.10 & 2.77 & 64.16 & 63.61 & 80.27 & 60.51 \\ FedT4R & 51.67 & 51.00 & 78.36 & 67.22 & 59.97 & 55.42 & 72.86 & 70.38 & 61.64 & 55.51 & 72.77 & 70.44 \\ FedT4R & 51.63 & 47.88 & 81.91 & 63.99 & 56.66 & 55.72 & 77.62 & 63.87 & 61.70 & 57.65 & 72.57 & 69.07 \\ FedT5A & **53.84** & **51.00** & **50.00** & **50.00** & **50.00** & **50.00** & **50.00** & **50.00** & **50.00** & **50.00** & **50.00** & **50.00** \\  FedLoD & 73.13 & 69.26 & 86.34 & 73.02 & 66.88 & 61.28 & 70.13 & 69.98 & 61.34 & 55.80 & 74.86 & 67.76 \\ FedT5R & 72.54 & 67.30 & 61.25 & 75.44 & 62.45 & 57.62 & 73.26 & 68.71 & 53.00 & 49.28 & 76.94 & 65.47 \\ FedT6R & 73.53 & 69.09 & 64.73 & 75.16 & 66.22 & 61.19 & 72.96 & 69.38 & 61.00 & 57.03 & 71.43 & 69.01 \\ FedCON & 72.22 & 67.79 & 61.36 & 77.12 & 65.86 & 61.33 & 69.99 & 71.03 & 62.11 & 57.62 & 70.91 & 70.54 \\ FedCoN & **77.88** & **75.10** & **58.84** & **58.07** & **70.30** & **60.23** & **45.50** & **50.00** & **64.34** & **52.86** & **65.18** & **50.00** \\   

Table 2: Main results of federated OOD detection and generalization on Cifar100. We report the ACC of brightness as IN-C ACC, the FPR95 and AUROC of LSUN-C as OUT performance.

Figure 4: T-SNE visualizations of FedAvg and FedRoD with F00GD.

[MISSING_PAGE_FAIL:9]

**Client Generalization on PACS Dataset.** To validate the effectiveness of FOOGD in domain generalization tasks, i.e., each client contains one domain data and we train domain generalization model by leave-one-out, following FedIIR . To compare fairly, we pretrain all models from scratch and utilize adaption methods as stated in their main paper. In terms of Tab. 6, FOOGD obtains performance improvements for FedAvg and FedRoD. Compared with existing adaption methods, FOOGD achieves outstanding results even in the toughest task, i.e., leaving Sketch domain out. This also concludes that FOOGD is capable of inter-client generalization, via utilizing global distribution knowledge.

**Hyperparameter sensitivity studies and other empirical studies.** Due to the space limitation, we leave the other relevant experiments in Appendix E. Summarily, we study four additional evaluations: (1) In Tab. 10 We compute different detection metrics, i.e., MSP, energy score, and ASH, and validate that Eq. (9) is consistently powerful in detection. (2) We vary the coefficient of SM\({}^{3}\)D \(_{m}=\{0.1,0.2,0.5,0.8,1\}\) in Fig. 11(a)-Fig. 11(b), and vary the coefficient of SAG \(_{a}=\{0,0.01,0.05,0.1,0.2,0.5,0.8\}\) in Fig. 11(c), to obtain the best modeling in FOOGD. (3) We vary the number of participating clients in Fig. 10 and found FOOGD can have better results among different participating clients.

## 6 Conclusion and Future Work

In this work, we consider enhancing both detection and generalization capability of FL methods among non-IID settings. To realize it, we try to model global distribution by collaborating clients, and propose FOOGD, which consists of SM\({}^{3}\)D for estimating score model for detection, and SAG to enhance the invariant representation for generalization. We conduct extensive experiments to validate the effectiveness of FOOGD: (1) reliably and flexibly estimating non-normalized decentralized distribution, (2) detecting semantic shift data via the norm of score values, and (3) generalizing adaption of covariate shift data by regularizing feature extractor invariant distribution discrepancy.

In the future, we plan to integrate privacy enhancement techniques, such as differential privacy, into FOOGD. While the score model in FOOGD captures the score function of the data probability in the latent space, which is extremely difficult to be used for reconstructing the original data by attacking. The primary risk exposure for each client arises from the exchange of model parameters, i.e., the feature extractor and score model. Hence, FOOGD has a comparable level of privacy exposure as existing FL methods dealing with non-IID and OOD shifts, acquiring to be addressed comprehensively.