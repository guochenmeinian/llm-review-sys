# Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization

Liang Zhang

ETH Zurich & Max Planck Institute

liang.zhang@inf.ethz.ch

Equal Contribution.

&Junchi Yang

ETH Zurich

junchi.yang@inf.ethz.ch

&Amin Karbasi

Yale University & Google Research

amin.karbasi@yale.edu

&Niao He

ETH Zurich

niao.he@inf.ethz.ch

###### Abstract

Algorithmic reproducibility measures the deviation in outputs of machine learning algorithms upon minor changes in the training process. Previous work suggests that first-order methods would need to trade-off convergence rate (gradient complexity) for better reproducibility. In this work, we challenge this perception and demonstrate that both optimal reproducibility and near-optimal convergence guarantees can be achieved for smooth convex minimization and smooth convex-concave minimax problems under various error-prone oracle settings. Particularly, given the inexact initialization oracle, our regularization-based algorithms achieve the best of both worlds - optimal reproducibility and near-optimal gradient complexity - for minimization and minimax optimization. With the inexact gradient oracle, the near-optimal guarantees also hold for minimax optimization. Additionally, with the stochastic gradient oracle, we show that stochastic gradient descent ascent is optimal in terms of both reproducibility and gradient complexity. We believe our results contribute to an enhanced understanding of the reproducibility-convergence trade-off in the context of convex optimization.

## 1 Introduction

In the realm of machine learning, improving model performance remains a primary focus; however, this alone falls short when it comes to the practical deployment of algorithms. There has been a growing emphasis on the development of machine learning systems that prioritize trustworthiness and reliability. Central to this pursuit is the concept of reproducibility , which requires algorithms to yield consistent outputs, in the face of minor changes to the training environment. Unfortunately, a lack of reproducibility has been reported across various domains , posing significant challenges to the integrity and dependability of scientific research. Notably, empirical studies in Henderson et al.  have revealed that reproducing baseline algorithms in reinforcement learning is a formidable task due to both inherent sources (e.g., random seeds, environment properties) and external sources (e.g., hyperparameters, codebases) of non-determinism. These findings underscore the criticality of having access to the relevant code and data, as well as sufficient documentation of experimental details, to ensure reproducibility in machine learning algorithms.

Instead of considering the irreproducibility issue solely from an empirical perspective, Ahn et al.  initiated the theoretical study of reproducibility in machine learning as an inherent characteristic of the algorithms themselves. They focus on first-order algorithms for convex minimization problems anddefine reproducibility as the deviation in outputs of independent runs of the algorithms, accounting for sources of irreproducibility captured by inexact or noisy oracles. In particular, they consider three practical error-prone operations, including inexact initialization, inexact gradient computation due to numerical errors, and stochastic gradient computation due to sampling or shuffling. When restricting the outputs to be \(\)-optimal and assuming the level of inexactness that could cause irreproducibility is bounded by \(\), they establish both lower and upper reproducibility bounds of (stochastic) gradient descent for all three settings. The lower-bounds indicate the existence of intrinsic irreproducibility for any first-order algorithms, while the matching upper-bounds suggest that (stochastic) gradient descent already achieves optimal reproducibility.

An important question arises regarding whether there is a fundamental trade-off between reproducibility and convergence speed in algorithms. For example, in the case of inexact initialization, the optimally reproducible algorithm , gradient descent (GD), is known to be strictly sub-optimal in terms of gradient complexity for smooth convex minimization problems . On the other hand, the optimally convergent algorithm, Nesterov's accelerated gradient descent (AGD) , suffers from a worse reproducibility bound . The situation becomes more intricate in the case of inexact gradient computation. A natural question that we aim to address in this paper is: _Can we achieve the best of both worlds - optimal convergence and reproducibility?_

On another front, while minimization problems can effectively model and explain the behavior of many traditional machine learning systems, recent years have witnessed a surge of applications that are formulated as minimax optimization problems. Important examples include generative adversarial networks (GANs) , robust optimization , and reinforcement learning . Despite a wealth of convergence theory for various minimax optimization algorithms, extensive empirical evidence suggests that these algorithms can be hard to train in practice [67; 4; 53]: the training procedure can be very unstable  and highly sensitive to changes of hyper-parameters. Motivated by such issues, we initiate the theoretical study of algorithmic reproducibility in minimax optimization. The second question that we aim to address in this paper is: _What are the fundamental limits of reproducibility for minimax optimization algorithms and their convergence-reproducibility trade-offs?_ We will focus on smooth convex-concave minimax optimization as a first step, where the irreproducibility issue comes from either inexact initialization, inexact gradient computation, or stochastic gradient computation.

### Our Contributions

Our main contributions are two-fold:

First, we propose Algorithm 1, which solves a regularized version of the smooth convex minimization problem. This algorithm achieves both optimal algorithmic reproducibility of \((^{2})\) and near-optimal gradient complexity of \(}(1/)\)2 under the \(\)-inexact initialization oracle. Table 1 provides a comparison with GD and AGD. Our results rely on the key observation that solutions to strongly

    &  &  \\   & Convergence & Reproducibility & Convergence & Reproducibility \\  GD  & \((1/)\) & \((^{2})\) & \((1/)\) & \((^{2}/^{2})\) \\  AGD  & \((1/)\) & \((^{2}e^{}{{}}})\) & - & - \\  Algo. 1 (Thm. 3.3, 3.5) & \(}(1/)\) & \((^{2})\) & \(}(1/)\) & \((^{2}/^{2.5})\) \\  LB [61; 1] & \((1/)\) & \((^{2})\) & \((1/)\) & \((^{2}/^{2})\) \\   

Table 1: Algorithmic reproducibility (Def. 3) and gradient complexity for algorithms in the smooth convex minimization setting given inexact deterministic oracles (Def. 1). Here, “LB” stands for lower-bound and \(a b\) denotes \(\{a,b\}\). For the inexact gradient oracle, \(()\) is required for GD to be \(\)-optimal and \((^{5/4})\) is required for Algo. 1.

convex regularized problems are unique, allowing algorithms that converge close to the minimizers to be reproducible. This highlights the effectiveness of regularization in achieving near-optimal convergence without compromising reproducibility.

Second, we extend the notion of reproducibility to smooth convex-concave minimax optimization (1) under inexact initialization and inexact gradient oracles. We establish the first reproducibility analysis for commonly-used minimax optimization algorithms such as gradient descent ascent (GDA) and Extragradient (EG) . Our results indicate that they are either sub-optimal in terms of convergence or reproducibility. To address this, we propose two new algorithms (Algorithm 2 and 3) which utilize regularization techniques to achieve optimal algorithmic reproducibility and near-optimal gradient complexity. The summarized results are presented in Table 2. Additional numerical experiments showcasing the effectiveness of our algorithms can be found in Appendix D. Although smooth convex-concave minimax optimization is nonsmooth in its primal form, our results indicate an improved reproducibility compared to the result of general nonsmooth convex problems  by leveraging the additional minimax structure. Lastly, in the case of stochastic gradient oracle, we show stochastic GDA can simultaneously attain both optimal convergence and optimal reproducibility.

### Related Works

Related Notions._(Reproducibility)_ Previous works that study reproducibility in machine learning are mostly on the empirical side. They either conduct experiments to report irreproducibility issues in the community , or propose practical tricks to improve reproducibility . Ahn et al.  initiated the theoretical study of reproducibility in convex minimization problems as a property of the algorithm itself. _(Replicability)_ In an independent work, Impagliazzo et al.  proposed the notion of replicability in statistical learning, where an algorithm is replicable if its outputs on two i.i.d. datasets are exactly the same with high probability. Its connection to generalization and differential privacy  is established in Bun et al.  and Kalavasis et al. . Replicable algorithms are proposed in the context of stochastic bandits  and clustering . _(Stability)_ Depending on the context, the term stability may have different meanings. In empirical studies , instability often refers to issues such as oscillations or failure to converge during training. In learning theory, algorithmic stability  measures the deviation in an algorithm's outputs for finite-sum problems when a single item in the input dataset is replaced by an i.i.d. in-distribution sample. The concept receives increasing attention as it implies dimension-independent generalization bounds of gradient-based methods for both minimization  and minimax  problems. In the area of differential equations  and variational inequalities , stability is also examined as a property of the solution set in response to perturbations in the problem conditions.

In this work, we consider the notion of reproducibility that characterizes the behavior of algorithms upon slight perturbations in the training. We defer the task of establishing intrinsic connections

    &  &  \\   & Convergence & Reproducibility & Convergence & Reproducibility \\  GDA (Thm. 4.2) & \((1/^{2})\) & \((^{2})\) & \((1/^{2})\) & \((^{2}/^{2})\) \\  EG (Thm. 4.3) & \((1/)\) & \((^{2}e^{}{{}}}(^{2}+1/ ^{2}))\) & \((1/)\) & \((^{2}e^{}{{}}} 1/^{2})\) \\  Algo. 2 (Thm. 4.4, 4.6) & \(}(1/)\) & \((^{2})\) & \(}(1/)\) & \((^{2}/^{2})\) \\  Algo. 3 (Thm. 4.7, 4.8) & \(}(1/)\) & \((^{2})\) & \(}(1/)\) & \((^{2}/^{2})\) \\  LB (, Lem. B.3) & \((1/)\) & \((^{2})\) & \((1/)\) & \((^{2}/^{2})\) \\   

Table 2: Algorithmic reproducibility (Def. 6) and gradient complexity for algorithms in the smooth convex-concave minimax setting given inexact deterministic oracles (Def. 4). Here, “LB” stands for lower-bound and \(a b\) denotes \(\{a,b\}\). For the inexact gradient oracle, \(()\) is required for GDA, EG, and Algo. 3 to be \(\)-optimal, and \((^{2})\) is required for Algo. 2. The diameter \(D\) in Assumption 4.1 is a trivial upper-bound for reproducibility in all cases.

among related notions to future work. The most closely related concept is algorithmic stability, where the analysis is similar to reproducibility under the inexact deterministic gradient oracle. Attia and Koren  showed the stability of AGD  grows exponentially with the number of iterations. Later, this is improved to quadratic dependence  based on a similar idea as ours that leverages stability of solutions to strongly-convex minimization problems . However, since there is no inexactness of the gradients in their setting, it is possible to ensure outputs that are arbitrarily close to the optimal solution. Given the presence of inexact gradients in our case, the convergence is only limited to a neighborhood of the optimal solution, which makes the problem more challenging. The trade-off between stability and convergence was investigated in Chen et al. . Their results suggest that a faster algorithm has to be less stable, and vice versa. However, we show the feasibility of achieving both optimal reproducibility and near-optimal convergence simultaneously in the setting we considered.

Minimax Optimization.Existing literature on minimax optimization primarily focuses on convergence analysis across various settings. For instance, there are studies on the strongly-convex-strongly-concave case , convex-concave case , and nonconvex-(strongly)-concave case . The lower complexity bounds have also been established for these settings . Our work aims to design reproducible algorithms while maintaining the optimal oracle complexities achieved in these previous works.

Inexact Gradient Oracles.A series of works investigate the convergence properties of first-order methods under deterministic inexact oracles for minimization  and minimax  problems. However, their inexact oracles differ from ours, and our focus is more on reproducibility. In recent years, there has been increasing interest in studying biased stochastic gradient oracles as well, where the bias arises from various sources such as problem structure , compression  or Byzantine failure  in distributed learning, and gradient-free optimization . These biases can also contribute to irreproducibility, and this direction would be an interesting avenue of research.

Regularization Technique.The central algorithmic insight driving our improvements towards obtaining both optimal convergence and reproducibility is the regularization technique, which is commonly used in the optimization literature. One important use case is to boost convergence by leveraging known and good convergence properties of algorithms on smooth strongly-convex functions for solving convex and nonsmooth problems, see e.g., , just to name a few. In addition, the regularization technique has also been demonstrated to be useful in improving stability and generalization , enhancing sensitivity and privacy guarantees , etc. In this paper, we provide another important use case by showing an improved convergence-reproducibility trade-off.

## 2 Preliminaries in Algorithmic Reproducibility

Notation.We use \(\|\|\) to represent the Euclidean norm. \(_{}(x)\) denotes the projection of \(x\) onto the set \(\). A function \(h:S\) is \(\)-smooth if it is differentiable and its gradient \( h\) satisfies \(\| h(x_{1})- h(x_{2})\|\|x_{1}-x_{2}\|\) for any \(x_{1},x_{2}\) in the domain \(S^{d}\). A function \(g:S\) is convex if \(g( x_{1}+(1-)x_{2}) g(x_{1})+(1-)g(x_{2})\) for any \(\) and \(x_{1},x_{2} S\). If \(g\) satisfies \(g(x)-(/2)\|x\|^{2}\) being convex with \(>0\), then it is \(\)-strongly-convex. Similarly, a function \(g:S\) is concave if \(-g\) is convex, and \(\)-strongly-concave if \(-g\) is \(\)-strongly-convex.

Ahn et al.  studied the algorithmic reproducibility for convex minimization problems \(_{x}F(x)\), measured by the \((,)\)-deviation bound of an algorithm \(\). Here, \(\) denotes the size of errors in the oracles that can lead to different outputs in independent runs of the same algorithm. The notion of reproducibility also requires \(\) to produce \(\)-optimal solutions, avoiding trivial outputs.

Definition 1.: Three different inexact oracle models are considered: \((i)\) a _\(\)-inexact initialization oracle_ that returns a starting point \(x_{0}\) such that \(\|x_{0}-u_{0}\|^{2}^{2}/4\) for some reference point \(u_{0}\), \((ii)\) a _\(\)-inexact deterministic gradient oracle_ that returns an inexact gradient \(G(x)\) such that \(\| F(x)-G(x)\|^{2}^{2}\) for the true gradient \( F(x)\), \((iii)\) a _\(\)-inexact stochastic gradient oracle_ that returns an unbiased gradient estimate \( f(x;)\) such that \(\| f(x;)- F(x)\|^{2}^{2}\).

Definition 2.: A point \(\) is an \(\)-optimal solution if \(F()-_{x}F(x)\) in the deterministic setting, or \([F()]-_{x}F(x)\) in the stochastic setting, where the expectation is taken over all the randomness in the gradient oracle and in the algorithm that outputs \(\).

**Definition 3**.: The \((,)\)-deviation \(\|-^{}\|^{2}\) is used to measure the reproducibility of an algorithm \(\) with \(\)-optimal solutions \(\) and \(^{}\), where \(\) and \(^{}\) are outputs of two independent runs of the algorithm \(\) given a \(\)-inexact oracle in Definition 1.

We expand the definitions of reproducibility to encompass minimax optimization problems:

\[_{x}_{y}\,F(x,y). \]

Our goal is to find the _saddle point_\((x^{*},y^{*})\) of the function \(F(x,y)\), such that \(F(x^{*},y) F(x^{*},y^{*}) F(x,y^{*})\) holds for all \((x,y)\). The optimality of a point \((,)\) can be assessed by its _duality gap_, defined as \(_{y}F(,y)-_{x}F(x,)\). In the minimax setting, we analyze reproducibility under the following inexact oracle models.

**Definition 4**.: Three different inexact oracle models are considered: \((i)\) a \(\)_-inexact initialization oracle_ that returns a starting point \((x_{0},y_{0})\) such that \(\|x_{0}-u_{0}\|^{2}+\|y_{0}-v_{0}\|^{2}^{2}/4\) for some reference point \((u_{0},v_{0})\), \((ii)\) a \(\)_-inexact deterministic gradient oracle_ that returns an inexact gradient \(G(x,y)=(G_{x}(x,y),G_{y}(x,y))\) at any querying point \((x,y)\) such that \(\| F(x,y)-G(x,y)\|^{2}^{2}\) for the true gradient \( F(x,y)=(_{x}F(x,y),_{y}F(x,y))\), \((iii)\) a \(\)_-inexact stochastic gradient oracle_ that returns an unbiased gradient estimate \( f(x,y;)=(_{x}f(x,y;),_{y}f(x,y;))\) such that \(_{}\| f(x,y;)- F(x,y)\|^{2}^{2}\).

**Definition 5**.: A point \((,)\) is an \(\)-saddle point solution if its duality gap satisfies that \(_{y}F(,y)-_{x}F(x,)\) in the deterministic setting, or its _weak_ duality gap satisfies that \(_{y}[F(,y)]-_{x}[F(x,)]\) in the stochastic setting.

**Definition 6**.: The \((,)\)-deviation \(\|-^{}\|^{2}+\|-^{}\|^{2}\) is used to measure the reproducibility of an algorithm \(\) with \(\)-saddle points \((,)\) and \((^{},^{})\), where \((,)\) and \((^{},^{})\) are outputs of two independent runs of the algorithm \(\) given a \(\)-inexact oracle in Definition 4.

The optimal convergence rates are well-understood for the convex optimization problems, including convex minimization  and convex-concave minimax optimization . Ahn et al.  provided the theoretical lower-bounds of reproducibility for convex minimization problems, which can be extended to convex-concave minimax problems as well (Lemma B.3). We say an algorithm achieves optimal reproducibility if its reproducibility upper-bounds match the established theoretical lower-bounds.

## 3 Deterministic Gradient Oracle for Minimization Problems

In this section, we consider convex minimization problems of the form

\[_{x}F(x),\]

where \(\) is a convex and closed set. We focus on the standard smooth and convex setting as detailed in Assumption 3.1. Our goal is to find an \(\)-optimal point as in Definition 2. Ahn et al.  showed that the optimal convergence rate and reproducibility can be achieved at the same time using stochastic gradient descent (SGD) for the stochastic gradient oracle model. In the deterministic case, they showed GD achieves the optimal reproducibility, albeit with a sub-optimal convergence rate . Considering the instability of accelerated gradient descent (AGD) , Ahn et al.  conjectured that \((1/)\) gradient complexity is necessary to attain the optimal reproducibility.

**Assumption 3.1**.: _The function \(F\) is convex and \(\)-smooth. We have access to initial points \(x_{0}\) that are \(D\)-close to an optimal solution, i.e., \(\|x^{*}-x_{0}\|^{2} D^{2}\) for some \(x^{*}_{x}F(x)\)._

We introduce a generic algorithmic framework outlined in Algorithm 1, that solves a quadratically regularized auxiliary problem (\(\)) using a base algorithm \(\) with initialization \(x_{0}\) until an accuracy of \(_{r}\) is reached. Our key insight is that since the optimal solution for strongly convex problems is unique, the reproducibility of the outputs from the regularized problem can be easily guaranteed. Note that the regularization parameter \(r\) presents a trade-off: as \(r\) increases, the auxiliary problem can be solved more efficiently, but the obtained solution deviates further from the original solution. We will show that Algorithm 1 achieves a near-optimal complexity of \(}(1/)\), along with optimal reproducibility under an inexact initialization oracle and slightly sub-optimal reproducibility under an inexact deterministic gradient oracle. This finding disproves the conjecture  that \((1/)\) complexity is necessary to achieve optimal reproducibility.

**Input:** Regularization parameter \(r>0\), accuracy \(_{r}>0\), base algorithm \(\), initial point \(x_{0}\).

Apply \(\) to approximately solve the \(r\)-strongly-convex and \((+r)\)-smooth problem

\[x_{r}*{arg\,min}_{x}F_{r}(x):=F(x)+\|x-x_{0}\|^{2},\] ( \[\] )

such that the optimality gap

\[F_{r}(x_{r})-_{x}F_{r}(x)_{r}.\]

**Output:**\(x_{r}\).

**Algorithm 1** Reproducible Algorithmic Framework for Convex Minimization Problems

### Inexact Initialization Oracle

We first examine the behavior of Algorithm 1 with access to exact deterministic gradients but given different initializations. Starting from two distinct initial points \(x_{0}\) and \(x_{0}^{}\) such that \(\|x_{0}-x_{0}^{}\|^{2}^{2}\), we want to control the deviation between the final outputs \(x_{r}\) and \(x_{r}^{}\) of the algorithm. The following contraction property is essential to attain optimal reproducibility.

**Lemma 3.2**.: _Let \(x_{r}^{*}=*{arg\,min}_{x}\{F(x)+(r/2)\|x-x_{0}\|^ {2}\}\) and \((x_{r}^{*})^{}=*{arg\,min}_{x}\{F(x)+(r/2)\| x-x_{0}^{}\|^{2}\}\). When \(F\) is convex, it holds that \(\|x_{r}^{*}-(x_{r}^{*})^{}\|^{2}\|x_{0}-x_{0}^{}\|^{2}\) for any \(r>0\)._

This indicates the optimal solutions are reproducible up to \(^{2}\). Consequently, if we can solve the auxiliary problem (\(\)) to a high accuracy \(_{r}\), we can ensure the final output \(x_{r}\) is reproducible. The selection of \(_{r}\) exhibits a trade-off: a smaller value increases complexity, yet brings the output closer to the reproducible \(x_{r}^{*}\). We characterize the complexity and reproducibility of Algorithm 1 by carefully choosing the parameters \(r\) and \(_{r}\).

**Theorem 3.3**.: _Under Assumption 3.1 and given an inexact initialization oracle, Algorithm 1 with \(r=/D^{2}\), \(_{r}=(/2)\{1,^{2}/(4D^{2})\}\) and AGD  as base algorithm \(\) outputs an \(\)-optimal point \(x_{r}\) with \(}(/})\) gradient complexity, and the reproducibility is \(\|x_{r}-x_{r}^{}\|^{2} 4^{2}\)._

This theorem implies that we can simultaneously achieve the near-optimal complexity of \(}(/})\) and optimal reproducibility of \((^{2})\), which improves over the \(( D^{2}/)\) complexity of GD . In fact, when combined with any base algorithm that solves the auxiliary problem, Algorithm 1 attains optimal reproducibility. However, using AGD as the base algorithm results in the best complexity. To the best of our knowledge, this is the only algorithm capable of achieving the best of both worlds. Previously, Attia and Koren  proved that the algorithmic reproducibility (referred to as initialization stability in their study) of Nesterov's AGD is \((^{2}e^{}{{}}})\) when the initialization is \(^{2}\)-apart.

**Remark 1**.: Adding regularization is a common and useful technique in the optimization literature. Our algorithmic framework solves one auxiliary regularized strongly-convex problem, which is referred to as classical regularization reduction in Allen-Zhu and Hazan . Algorithm 1 is biased and requires the knowledge of \(\) and \(D\) to control the biased term introduced by the regularization term. The convergence guarantee also has an additional sub-optimal logarithmic term. Allen-Zhu and Hazan  proposed to use a double-loop algorithm, where a sequence of auxiliary regularized strongly-convex problems with decreasing regularization parameters are solved. The vanishing regularization ensures the algorithm is unbiased, and the resulting convergence guarantee requires no knowledge of \(\) and does not have an additional logarithmic term. Similar idea could apply to our case as well, and the task of bridging such gaps is deferred to future work.

### Inexact Deterministic Gradient Oracle

We further study the algorithmic reproducibility and gradient complexity of Algorithm 1 under the inexact gradient oracle model that returns an inexact gradient \(G(x)^{d}\) such that \(\|G(x)- F(x)\|^{2}^{2}\) at any query point \(x\). From the inexact gradient oracle of \(F\), we can construct an inexact gradient oracle for the auxiliary problem \(F_{r}\): \(G_{r}(x)=G(x)+r(x-x_{0})\) which satisfies the condition \(\|G_{r}(x)- F_{r}(x)\|^{2}=\|G(x)- F(x)\|^{2}^{2}\). To solve the auxiliary problem, we consider AGD with an inexact oracle (Inexact-AGD) as proposed by Devolder et al. . The proposition below establishes its convergence behavior.

**Proposition 3.4**.: _Consider \(_{x}F_{r}(x)\), where \(F_{r}\) is \(r\)-strongly-convex and \((+r)\)-smooth. Given an inexact gradient oracle that returns \(G_{r}(x)\) such that \(\|G_{r}(x)- F_{r}(x)\|^{2}^{2}\), starting from \(y_{0}=x_{0}\). AGD with the following update rule_

\[ x_{t+1}&=_{}y_{t }-G_{r}(y_{t}),\\ y_{t+1}&=x_{t+1}+}{2+ }(x_{t+1}-x_{t}),\] (Inexact-AGD)

_for \(t=0,1,,T-1\), satisfies that_

\[F_{r}(x_{T})-F_{r}(x_{r}^{*})-}F_{r}(x_{0})-F_{r}(x_{r}^{*})+\|x_{0}-x_{r}^{*} \|^{2}+}+ ^{2},\]

_where \(x_{r}^{*}\) is the unique minimizer of \(F_{r}(x)\)._

This proposition suggests that Inexact-AGD converges to a neighborhood with a radius of \((^{2}/r^{3/2})\) around the optimal value. We note that convergence to the exact solution is unattainable for algorithms employing inexact gradients [27; 28], and the size of this neighborhood is important in determining the reproducibility of \(x_{r}\).

**Theorem 3.5**.: _Under Assumption 3.1 with \(0< D^{2}\) and given an inexact deterministic gradient oracle in Definition 1, Algorithm 1 with \(r=/D^{2}\), \(_{r}=6^{2}D^{3})}\) and Inexact-AGD as base algorithm outputs a \((6^{2}D^{3})}+/2)\)-optimal point \(x_{r}\) with \(}(/})\) gradient complexity, and the reproducibility is \(\|x_{r}-x_{r}^{}\|^{2}(^{2}/^{5/2})\)._

Ahn et al.  showed that GD achieves optimal reproducibility of \((^{2}/^{2})\) and a complexity of \((1/)\) when \(()\). Our results indicate that a reproducibility of \((^{2}/^{5/2})\) and a near-optimal complexity of \(}(1/)\) can be attained when \((^{5/4})\). We conjecture that this suboptimal reproducibility bound is inevitable for the proposed framework given the lower bound result in Devolder et al.  for algorithms under a \((,,)\)-inexact oracle associated with \(\)-smooth \(\)-strongly-convex functions. Further discussions are provided in Appendix A.2. Moreover, we point out that for minimizing \(\)-smooth and \(\)-strongly-convex functions, Proposition 3.4 already implies that Inexact-AGD attains the optimal reproducibility of \((\{^{2},\})\) and the optimal complexity of \(}()\) when the problem is well-conditioned, improving over the \(}(/)\) complexity in the previous work .

**Remark 2**.: In Appendix D, we demonstrate the effectiveness of Algorithm 1 on a quadratic minimization problem equipped with an inexact gradient oracle. The results are plotted in Figure 1 in the appendix. We observe that the reproducibility can be greatly improved when adding regularization, with only a small degradation in the convergence performance.

## 4 Deterministic Gradient Oracle for Minimax Problems

In this section, we address the minimax optimization problem of the form

\[_{x}_{y}F(x,y),\]

where \(\) and \(\) are convex compact sets. We focus on the standard smooth and convex-concave setting as detailed in Assumption 4.1. We aim to find an \(\)-saddle point \((,)\) such that its duality gap satisfies \(_{y}F(,y)-_{x}F(x,)\). Here, the assumption that the domains are convex and bounded ensures the existence of the saddle point when the objective is convex-concave . We focus on minimax problems equipped with inexact initialization oracles and inexact deterministic gradient oracles as defined in Definition 4. We first show that two classical algorithms, gradient descent ascent (GDA) and Extragradient (EG) [48; 72], are either sub-optimal in convergence or sub-optimal in reproducibility, which mirrors the minimization setting. Based on the same regularization idea, we propose two new frameworks in Algorithm 2 and 3 that successfully attain near-optimal convergence and optimal reproducibility at the same time.

**Assumption 4.1**.: _For all \(y\), \(F(,y)\) is convex, and for all \(x\), \(F(x,)\) is concave. Furthermore, \(F\) is \(\)-smooth on the domain \(\). Additionally, both \(\) and \(\) have a diameter of \(D\). This means that \(\|x_{1}-x_{2}\|^{2} D^{2}\) and \(\|y_{1}-y_{2}\|^{2} D^{2}\) for all \(x_{1},x_{2}\) and \(y_{1},y_{2}\)._The optimal gradient complexity to find \(\)-saddle point under such assumptions is \((1/)\). Since the minimax problem reduces to a minimization problem on \(\) when the domain \(\) is restricted to be a singleton, the reproducibility lower-bounds  for smooth convex minimization hold as lower-bounds for smooth convex-concave minimax optimization as well. That is, \((^{2})\) under the inexact initialization oracle, and \((^{2}/^{2})\) under the inexact gradient oracle (see Lemma B.3). We now present the convergence rate and reproducibility bounds of GDA (see Algorithm 4) and EG (see Algorithm 5).

**Theorem 4.2**.: (GDA) _Under Assumption 4.1, the average iterate \((_{T},_{T})\) output by GDA with stepsize \(1/()\) after \(T=(1/^{2})\) iterations is an \(\)-saddle point. Furthermore, the reproducibility of the output is \((i)\)\((^{2})\) under \(\)-inexact initialization oracle; \((ii)\)\((^{2}/^{2})\) under \(\)-inexact deterministic gradient oracle if \(()\)._

**Theorem 4.3**.: (Extragradient) _Under Assumption 4.1, the average iterate \((_{T+1/2},_{T+1/2})\) output by EG with stepsize \(1/\) after \(T=(1/)\) iterations is an \(\)-saddle point. Furthermore, the reproducibility of this output is \((i)\)\((\{^{2}e^{1/},^{2}+1/^{2},D^{2}\})\) under \(\)-inexact initialization oracle; \((ii)\)\((\{^{2}e^{1/},1/^{2},D^{2}\})\) under \(\)-inexact deterministic gradient oracle if \(()\)._

While GDA can achieve optimal reproducibility, it converges with a sub-optimal complexity of \((1/^{2})\). On the other hand, EG achieves an optimal \((1/)\) complexity but is not optimally reproducible. Further details on this are provided in Appendix B. In Appendix B.3.4, we also demonstrate that EG, through an alternative parameter selection, can achieve optimal reproducibility at a sub-optimal rate \((1/^{3/2})\). The question that remains open is how to simultaneously attain both optimal reproducibility and gradient complexity. To address this, we have developed two algorithmic frameworks with near-optimal guarantees, one based on regularization and the other based on proximal point methods .

### Regularization Helps!

```
0: Regularization parameter \(r>0\), accuracy \(_{r}>0\), base algorithm \(\), initialization \((x_{0},y_{0})\).
0: Apply \(\) to inexactly solve the \(r\)-strongly-convex-strongly-concave and \((+r)\)-smooth problem \[(x_{r},y_{r})_{x}_{y}F_{r}(x,y) :=F(x,y)+\|x-x_{0}\|^{2}-\|y-y_{0}\|^{2},\] ( \[*\] )

 such that \((x,y)\), \[_{x}F_{r}(x_{r},y_{r})^{}(x_{r}-x)-_{y}F_{r}(x_{r},y_{r})^{ }(y_{r}-y)_{r}.\] (2)
0:\((x_{r},y_{r})\).
```

**Algorithm 2** Reproducible Algorithmic Framework for Convex-Concave Minimax Problems

We demonstrate that adding regularization is sufficient to achieve near-optimal guarantees for smooth convex-concave minimax problems. The general framework is summarized in Algorithm 2, where a base algorithm \(\) is applied to solve a regularized auxiliary problem which is strongly-convex in \(x\) and strongly-concave in \(y\). For the inexact initialization case, we show that an optimal reproducibility bound of \((^{2})\) and a near-optimal convergence rate of \(}(1/)\) can be attained simultaneously.

**Theorem 4.4**.: _Under Assumption 4.1 and given an inexact initialization oracle, Algorithm 2 with \(r=/D^{2}\), \(_{r}=\{1,^{2}/(8D^{2})\}\) and EG as base algorithm \(\) outputs a \((2)\)-saddle point \((x_{r},y_{r})\) with \(}( D^{2}/)\) gradient complexity, and the reproducibility is \(4^{2}\)._

Consider a \(\)-inexact deterministic gradient oracle that returns \(G(x,y)=(G_{x}(x,y),G_{y}(x,y))\). First note \(G_{r}(x,y)=(G_{x}(x,y)+r(x-x_{0}),G_{y}(x,y)-r(y-y_{0}))\) is a \(\)-inexact gradient for the auxiliary problem (\(*\)). We now characterize the convergence behavior of EG with this \(\)-inexact gradient oracle, referred to as Inexact-EG, to solve the auxiliary problem.

**Lemma 4.5**.: _Consider \(_{x}_{y}F_{r}(x,y)\), where \(F_{r}(x,y)\) is \(r\)-strongly-convex-strongly-concave and \((+r)\)-smooth. Given an inexact gradient oracle that returns \(G_{r}(x,y)\) such that \(\|G_{r}(x,y)- F_{r}(x,y)\|^{2}^{2}\), Inexact-EG with stepsize \(1/(2(+r))\) satisfies_

\[\|x_{T}-x_{r}^{*}\|^{2}+\|y_{T}-y_{r}^{*}\|^{2}\!(- )(\|x_{0}-x_{r}^{*}\|^{2}+\|y_{0}-y_{r}^{*}\|^{2} )+}{r}\!(+)\!.\]_where \((x_{r}^{*},y_{r}^{*})\) is the unique saddle point of \(F_{r}(x,y)\)._

This lemma implies that Inexact-EG converges linearly to a neighborhood of size \((^{2}/r^{2})\) around the saddle point, which can be translated to the inaccuracy measure in (2) with \(_{r}=(/r)\) utilizing Lemma C.5. It is worth emphasizing that the size of this neighborhood is critical for achieving optimal reproducibility, and the dependency on \(r\) in the above convergence rate is key for attaining near-optimal complexity. Stonyakin et al.  analyzed Mirror-Prox  with restarts for strongly-monotone variational inequalities under a different inexact oracle (see Devolder et al.  and [70, Example 6.1] for its relationship with the inexactness notion of ours). Compared to Inexact-EG, their two-loop structure of the restart scheme is more complicated to implement.

**Theorem 4.6**.: _Under Assumption 4.1 with \(0< D^{2}\) and given an inexact gradient oracle, Algorithm 2 with \(r=/D^{2}\), \(_{r}=(/r)\) and Inexact-EG as base algorithm \(\) outputs an \((+/)\)-saddle point with \(}( D^{2}/)\) gradient complexity, and the reproducibility is \((^{2}/^{2})\)._

**Remark 3**.: Some numerical experiments on a bilinear matrix game with inexact gradient information are provided in Appendix D (see Figure 2). With a small degradation in the convergence speed, the regularized framework in Algorithm 2 effectively improves the reproducibility of the base algorithm.

The theorem indicates that optimal reproducibility \((^{2}/^{2})\) and near-optimal gradient complexity \(}(1/)\) can be achieved when \((^{2})\). Note by Theorem 4.2 and 4.3, GDA and EG can find \(\)-saddle points when \(()\). Next, we introduce an alternative algorithmic framework that preserves the optimal reproducibility and attains the near-optimal complexity as long as \(()\).

### Inexact Proximal Point Method

We propose a two-loop inexact proximal point framework, presented in Algorithm 3, which can achieve both near-optimal gradient complexity and optimal algorithmic reproducibility. Compared to Algorithm 2, the regularization parameter \(1/=()\) does not depend on the target accuracy \(\) and the diameter \(D\), and the center of the regularization term is the last iterate \((x_{t},y_{t})\) instead of the initial point. Since the auxiliary problem is \(\)-strongly-convex-strongly-concave and \(2\)-smooth with condition number being \((1)\), a wider range of base algorithms can be used to achieve the optimal complexity than solving the problem in Algorithm 2 where the condition number is \((1/)\).

```
Input: Stepsize \(>0\), accuracy \(>0\), algorithm \(\), initialization \((x_{0},y_{0})\), iteration number \(T\). for\(t=0,1, T-1\)do  Apply \(\) to inexactly solve the smooth strongly-convex-strongly-concave problem \[(x_{t+1},y_{t+1})_{x}_{y}\ _{t}(x,y):=F(x,y)+\|x-x_{t}\|^{2}-\|y-y_{t}\|^{2}.\]  such that \((x,y)\), \[_{x}_{t}(x_{t+1},y_{t+1})^{}(x_{t+1}-x)-_{y}_{t}(x_{t+1},y_{t+1})^{}(y_{t+1}-y).\] Output:\((_{T+1},_{T+1})=(1/T)_{t=0}^{T-1}(x_{t+1},y_{t+1})\).
```

**Algorithm 3** Inexact Proximal Point Method for Convex-Concave Minimax Problems

**Theorem 4.7**.: _Under Assumption 4.1 and given a \(\)-inexact initialization oracle in Definition 4 with \((1/)\), Algorithm 3 with \(^{2}/(2 T^{2})\) and \(=1/\) outputs an \(()\)-saddle point after \(T=(1/)\) iterations, and the reproducibility is \(9^{2}\)._

**Remark 4**.: The required accuracy \(\) for the auxiliary problem is \((^{2}^{2})\). Given that the auxiliary problem is \(\)-strongly-convex-strongly-concave and \(2\)-smooth, various linearly convergent algorithms such as EG, GDA, and Optimistic GDA  can find a point that satisfies the stopping criterion within \(((1/()))\) iterations. As a result, the total gradient complexity is \(}(1/)\). In contrast, using GDA as the base algorithm in Algorithm 2 will lead to a sub-optimal gradient complexity.

**Theorem 4.8**.: _Under Assumption 4.1 and given a \(\)-inexact deterministic gradient oracle in Definition 4 with \(()\), Algorithm 3 with \(()\) and \(=1/\) outputs an \(()\)-saddle point after \(T=(1/)\) iterations, and the reproducibility is \((^{2}/^{2})\)._

**Remark 5**.: This theorem requires solving the auxiliary problem with a \(\)-inexact gradient oracle. In addition to Inexact-EG presented in Lemma 4.5, we show in Appendix C.1 that GDA with inexact gradients (Inexact-GDA) can also converge linearly to the optimal point up to a \((^{2})\) error. Thus the total complexity is \(((1/)(1/))\) using both Inexact-EG and Inexact-GDA.

## 5 Stochastic Gradient Oracle for Minimax Problems

To provide a complete picture, in this section, we consider the stochastic minimax problem:

\[_{x}_{y}\ F(x,y)=_{}[f(x,y; )], \]

where the expectation is taken over a random vector \(\). We have access to a \(\)-inexact stochastic gradient oracle that can return unbiased gradients \( f(x,y;)\) with a bounded variance \(^{2}\) at each point \((x,y)\). We consider the popular algorithm called stochastic gradient descent ascent (SGDA). The convergence behaviors of SGDA for the stochastic minimax problem (3) are well-known in various settings. However, due to the randomness in the gradient oracle, independent runs of SGDA may lead to different outputs even with the same parameters. Following Definition 6, we further establish the \((,)\)-deviation of SGDA in the theorem below.

**Theorem 5.1**.: _Under Assumptions 4.1 and given an inexact stochastic gradient oracle in Definition 4 with \(=(1)\), the average iterates \((_{T},_{T})=(1/T)_{t=0}^{T-1}(x_{t},y_{t})\) of SGDA with stepsize \(1/( T)\) after \(T=(1/^{2})\) iterations is an \(()\)-stationary point and the reproducibility is \(^{2}/(^{2}T)\)._

The \((1/^{2})\) sample complexity of SGDA is known to be optimal when the objective \(F(x,y)\) is convex-concave . Moreover, our results suggest that SGDA is also optimally reproducible, as the lower-bound of \(^{2}/(^{2}T)\) for convex minimization problems  is also valid for minimax optimization according to our discussions in Lemma B.3.

## 6 Conclusion

In this work, instead of solely focusing on convergence performance, we investigate another crucial property of machine learning algorithms, i.e., algorithms should be reproducible against slight perturbations. We provide the first algorithms to simultaneously achieve optimal algorithmic reproducibility and near-optimal gradient complexity for both smooth convex minimization and smooth convex-concave minimax problems under various inexact oracle models. We focus on the convex case as a first step since it is the most basic and fundamental setting in optimization. We believe a solid understanding of the reproducibility in convex optimization will shed insights for that of the more challenging nonconvex optimization. Note that some of the analysis and techniques used in this paper can be extended to the smooth nonconvex setting, aligning with the stability analysis for nonconvex objectives [42; 49]. The proposed regularized framework can be applied to nonconvex functions as well using the convergence analysis of regularization or proximal point-based methods [2; 74]. However, the non-expansiveness property in Lemma 3.2 that is essential for the reproducibility analysis will not hold any more without the convexity assumption. One potential way to alleviate it is to impose additional structural assumptions on the gradients such as negative comonotonicity . We leave a detailed study of the reproducibility in nonconvex optimization to future work.

Other possible improvements of our results include deriving optimal reproducibility with an accelerated convergence rate for smooth convex minimization problems under the inexact gradient oracle, removing the additional logarithmic terms in the complexity of our algorithms using techniques in Allen-Zhu and Hazan , studying the reproducibility under the presence of mixed inexact oracles, and extending the results to nonsmooth settings. Another interesting direction is to design simpler and more direct methods with both optimal reproducibility and convergence guarantees. A possible way is to directly unwrap the regularized algorithmic framework 1 or 2, leading to Tikhonov regularization  or anchoring methods .