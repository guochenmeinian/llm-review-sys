# TARSS-Net: Temporal-Aware Radar Semantic Segmentation Network

Youcheng Zhang\({}^{1}\) Liwen Zhang\({}^{1}\)\({}^{}\) Zijun Hu\({}^{1}\) Pengcheng Pi\({}^{1}\)

Teng Li\({}^{2}\) Yuanpei Chen\({}^{1}\) Shi Peng\({}^{1}\) Zhe Ma\({}^{1}\)

\({}^{1}\)Intelligent Science and Technology Academy of CASIC

\({}^{2}\)Shenzhen International Graduate School, Tsinghua University

youcheng17@163.com\({}^{}\) lwzhang9161@126.com\({}^{}\)mazhe_thu@163.com\({}^{}\)

Equal contributions.Corresponding author.

###### Abstract

Radar signal interpretation plays a crucial role in remote detection and ranging. With the gradual display of the advantages of neural network technology in signal processing, learning-based radar signal interpretation is becoming a research hot-spot and made great progress. And since radar semantic segmentation (RSS) can provide more fine-grained target information, it has become a more concerned direction in this field. However, the temporal information, which is an important clue for analyzing radar data, has not been exploited sufficiently in present RSS frameworks. In this work, we propose a novel temporal information learning paradigm, _i.e._, **data-driven temporal information aggregation with learned target-history relations**. Following this idea, a flexible learning module, called **Temporal Relation-Aware Module** (TRAM) is carefully designed. TRAM contains two main blocks: i) an encoder for capturing the target-history temporal relations (TH-TRE) and ii) a learnable temporal relation attention pooling (TRAP) for aggregating temporal information. Based on TRAM, an end-to-end Temporal-Aware **RSS Network** (TARSS-Net) is presented, which has outstanding performance on publicly available and our collected real-measured datasets. Code and supplementary materials are available at https://github.com/zlw9161/TARSS-Net.

## 1 Introduction

Radar is a reliable remote sensing device for its robustness in adverse weather and illumination conditions. It is widely used for applications like the autonomous driving , Unmanned Aerial Vehicle (UAV) surveillance , sea monitoring , etc. However, the received scattered radar signals are high-entropy information body coupled with environmental clutters from a large spatial range, device noise and moving target information (_i.e._, distance/range, direction/angle and velocity/Doppler shift). These components are additionally condensed into the received echoes, which is inherently a gap in understanding of radar signals to human perception, as opposed to visible light images, which are modalities aligned with human visual perception, and natural language texts that are naturally based on human semantic understanding. This human-unfriendly perception gap causes great difficulty in semantic perception of scenes and objects . More information on radar signals and processing is in Appendix A.

Encouraged by the success of deep learning techniques in computer vision, in especial, object detection  and semantic segmentation , some efforts have been made recently to better understand complex radar data. Compared with detection models  using bounding boxes, the segmentation models  can provide _pixel-wise_ (a unit of therange-angle (RA) or range-doppler (RD) frequency representation) detection results for objects and even the background, which is practical for radar scene understanding and is also followed by this work. Most of these methods are based on convolutional auto-encoding-decoding (CAED), which take the frequency representations of a series of fast Fourier transforms (FFTs) on the radar signals as input, and make predictions on the RA or RD view or both views.

By analysing current efforts in RSS, two primarily concerned problems can be concluded for effective design of RSS system. i) _How to capture target signature effectively in spatial domain_. Typically, atrous spatial pyramid pooling (ASPP)  is used to obtain multi-scale spatial information [14; 21], and deformable convolution is utilized to extract target features with irregular shape . Specifically, PeakConv (PKC)  is the learning-based operator tailored for radar signals which aims to capture target signature's salience. ii) _How to utilize inherent temporal information of radar input tensor_. Commonly, \(3\)D convolution (\(3\)DConv) is implemented [21; 33; 6]. It is worth noting that, compared with the direct use of existing methods, taking into account the intrinsic merits of radar signal can achieve more performance advantages. In terms of temporal information utilization, the common practice is still \(3\)DConv. Few work has explored a specific temporal modeling mechanism for RSS and even less conducted a discussion of other off-the-shelf methods from the perspective of RSS task.

Considering the above research gaps, this paper conducts a comprehensive discussion from the perspective of RSS for existing time series modeling paradigms, including i) _causal temporal relation modeling_, represented by hidden Markov models (HMM)  and recurrent neural network (RNN) family [8; 7; 4]; ii) _parallelized sequence representation modeling_, represented by \(3\)DConv  and Transformer  family. Based on this, we propose a novel modeling paradigm for radar temporal information utilization. Specifically, this paper makes the following efforts:

i. **A novel temporal modeling paradigm for RSS**. Based on the in-depth analysis and discussion of existing temporal modeling methods, several specific design principles for RSS temporal modeling paradigm are given (SS 2). Following these principles, a novel temporal information learning paradigm for radar spatio-temporal tensors is proposed, _i.e._, _data-driven temporal information aggregation with learned target-history relations_.

ii. **Temporal relation attentive module (TRAM)**. TRAM is proposed to realize the learning paradigm mentioned above, which is a flexible temporal relation encoding and aggregating module. For encoding, the target-**h**istory **t**emporal **r**elation encoder (TH-TRE) is designed, which aims to capture relations between target frame and its historical neighbors. For aggregating, temporal relation attentive **po**ooling (TRAP) with two forms, _i.e._, learning in temporal-depth and spatio-temporal, is presented. Both the encoder and aggregator can be independently inserted into arbitrary \(2\)/\(3\)DConv-based networks (SS 3).

iii. **Reasonable-scale RSS Network with variable input time lengths**. Processing high-dimensional radar sequence while ensuring the use of temporal information is computationally expensive. To ensure RSS model has the ability of online real-time processing, **t**emporal-**a**ware **RSS****net**work (TARSS-Net) with moderate parameters is designed based on TRAM, which keeps its parameter scale constant while accepting adjustable time length input. Compared with existing temporal modeling methods, TARSS-Net could effectively avoids the long-term dependence decreasing risk as well as gradient disappearance problem, which shows good segmentation performance and inference efficiency in both multi-view and single-view conditions (SS 3, Appendix C).

iv. **Model performance verification with real-measured data in different detection scenarios**. To verify the scope of application of TARSS-Net, we conduct quantitative experiments on different real-measured large scale radar datasets including CARRADA  which is collected from a low cost FMCW (\( 77\)GHz) on-board radar in driving scenario and self-collected dataset, KuRALS, recorded from a Kurz-under (Ku) band (\( 17\)GHz) radar for UAV surveillance and sea monitoring. Experimental results show TARSS-Net can achieve state-of-the-art (SoTA) performance (SS 4).

## 2 Discussion of Temporal Modeling Paradigms for RSS

In this section, a deep discussion and analysis of current temporal modeling paradigm is conducted. On this basis, the design principles of spatio-temporal encoding suitable for RSS domain are given, and then TRAM paradigm is developed. For better explanation, Fig. 1 intuitively presents the core modeling mechanism of the discussed paradigms.

**i. Causal temporal relation modeling**.

* **HMM** is the classic causal temporal modeling methods, which uses hidden states to model temporal dependencies as shown in Fig. 1-(a1). Based on the assumption of Markov first-order homogeneity and observation independence, it can conveniently use the transition probabilities between hidden states to describe the intrinsic causal relationship of sequential data. However, as a shallow probabilistic model, HMM cannot perform data representation and downstream task prediction end-to-end. Meanwhile, the Markov assumption and discretized encoding of the hidden states also limit its ability to describe long-term dependencies.
* **RNN** also introduces hidden state to describe temporal relation of input sequence similar with HMMs. However, its hidden state is extended to a continuous vector, _i.e._, real-valued representation projected by a parameterized connection shown in Fig. 1-(a2). In this way, RNN is no longer limited to a probabilistic model, but a learnable one that can be deepened. The gradient descent algorithm can be used to realize end-to-end training of RNN's representation and prediction, which greatly alleviates the problem of HMM's insufficient ability to depict long-term dependencies. With more complex computing units such as LSTM  and GRU , its representational power can be further enhanced. However, in addition to the resistance caused by gradient dispersion/disappearance under the back-propagation framework, RNNs are sequential causal computing model after all, and their popularity is gradually fading under current main theme of multi-core parallel computing framework.
2. **Parallelized sequence representation modeling**.
* \(3\)**DConv** uses the concept of local receptive field (LRF) and the design of shared kernel. It can efficiently fulfill encoding and representation of high-dimensional spatio-temporal tensors in a multi-core computing environment as shown in Fig. 1-(b1). Therefore, \(3\)DConv has become the preference for RSS models that require spatio-temporal encoding capabilities . However, due to the limitation of LRF, it cannot achieve temporal-dependence across long-term range while retaining efficient computation and appropriate parameter amount. Meanwhile, an inherent contradiction between \(3\)DConv and RSS is ignored by most of current works, that is, convolution naturally follow the rules of context encoding, which is more suitable for obtaining responses in the center position of LRF. For input sequence, \(\{_{1},,_{1+},,_{1+2}\} ^{H W(2+1)}\), performing predictions on \(_{1+}\) is more of a natural advantage of \(3\)DConv-based models, instead of predicting \(_{1+2}\) as most RSS required. In terms of pragmatism, performing the prediction at the current instant, _i.e._, \((1+2)\)-th time step, is more reasonable, more causal, and more real-time. For this reason, \(3\)DConv might not be optimal for RSS.
* **Transformer** is becoming the backbone of fundamental models in many computing fields . Compared with RNN, it overcomes the problem of parallel computing for handling sequential data; compared with convolution, it breaks the limitation of LRF by preserving the sequence-to-sequence encoding style. The key to Transformer's success lies in self-attention (SA) mechanism. However, its problem is also with SA. By using parameterized connections with different weights, the sequence \(\{_{t}\}_{t=1}^{T}\) is abstracted into the forms of \(\{_{t}\}_{t=1}^{T}\), \(\{_{t}\}_{t=1}^{T}\) and \(\{_{t}\}_{t=1}^{T}\), and then the temporal relation between any two primitives is obtained by densely calculating the pairwise

Figure 1: Brief illustration of temporal modeling paradigms.

inner product along time dimension, _i.e._, \(\{_{i}_{j}^{}\}_{i=1,j=1}^{T,T}\), resulting the computational complexity of \((T^{2})\) for temporal relation modeling. This greedy manner is acceptable for data where only time-dimension is a concern, but for spatio-temporal tensors with large spatial ranges, _e.g._, radar data, the computational cost versus performance gain ratio may not be cost-effective. Moreover, since predictions are required only on current time step, computing resources should not be blindly allocated to each historical time step of input, which would lead to redundancy.

The above analysis motivates this paper to redesign spatio-temporal encoding module for RSS task, and teases out the following \(5\) design principles:

* Utilizing **parameterized rather than probabilistic connections to characterize the temporal relations** of sequence like Transformers and RNNs do.
* On the premise of making predictions at current time step, the module should **emphasize the use of the current input frame**, _i.e._, the non-context calculation in time.
* The module should be able to handle **temporal relations in parallel**.
* Considering the high-dimensional spatio-temporal characteristics of radar data, the module should **ensure the efficient learning ability of long-term relationship and keep the parameters appropriately scaled**.
* Due to the coupling of device noise and environmental clutter, radar data would be non-smooth in time dimension. In this way, the module should **consider the contribution of each time step differently** during historical information aggregation.

To take into account the above principles, a novel temporal learning paradigm for RSS is proposed as shown in Fig. 1-(c), _i.e._, _data-driven temporal information aggregation with learned target-history relations_. The careful designs are as follows:

* The idea of modeling temporal relations with parameterized connections in RNNs and Transformers is preserved, _i.e._, _temporal relation is explicitly treated as an intermediate embedding obtained by a parameterized layer/block_ (relation embeddings mentioned in SSS 3.1).
* The _current/target-history relation encoding mechanism_ is introduced (see TH-TRE in SSS 3.1). In this way, the complexity of \((T^{2})\) for temporal relations in SA is avoided (\((T)\) for TRAM), the use of the current frame is emphasized, and the convolution is non-context calculation in time.
* In order to achieve temporal relation encoding in the parallel way, temporal-relation-inception convolution is designed in TH-TRE (TRIC mentioned in SSS 3.1), which is also helpful to _keep model scale constant with variable time length of input sequence_.
* A learnable temporal pooling layer (see TRAP in SSS 3.2) is designed to _measure and reallocate the contribution degree of different target-history relation embeddings_, thus the adverse effects caused by time non-smoothing of radar data quality can be alleviated in a data-driven way.

## 3 Temporal Relation Attentive Model (TRAM)

As illustrated in Fig. 2, the proposed TARSS-Net is based on CAED framework, which consists of basic encoder, TRAM, latent space encoder (LSE) and decoder. For each single-view radar input sequence, the basic encoder is used to generate high-level representations. The LSE is used to align and fuse the high-level semantic features of different views, which is further applied to the single-view decoder to improve its performance. Decoder receives inputs from TRAM and LSE, and finally produces segmentation results on RD and RA perspectives, respectively. As the key of temporal relation learning, TRAM will be detailed in this section, and remaining components can be found in Appendix C. TRAM contains of two components: the target/current-historical **t**emporal **r**elation **e**noder (TH-TRE) and **t**emporal **r**elation-**a**ware **p**ooling (TRAP).

### Target-History Temporal Relation Encoding (TH-TRE)

TH-TRE aims at capturing temporal relations of encoded target frame and its adjacent historical frame features. To achieve this goal, we design the temporal-relation-inception convolution (TRIC) block to handle each target-historical feature pair, as shown in Fig. 3. Given the feature map sequence \(\{_{t-},\ ,\ _{t-1},\ _{t}\}^{C (+1) H W}\) obtained from a basic encoder (_e.g._, RA Encoder), the whole process of TH-TRE can be formalized in Eq. (1). \(C,\ (+1),\ H,\ W\) are the numbers of channels/depth, time frames, range cells and angle cells, respectively.

\[ THTRE(\{_{j}\}_{j=t-} ^{t})&=\{TRIC(_{t},\ \{_{i}\}_{i=t-}^{t-1})^{} (_{1}(_{t}))\},\\ &\ TRIC(_{t},\ \{_{i}\}_{i=t-}^{t-1} )&=\{_{2}(_{1}(_ {t})^{}_{1}(_{t}))\}_{i=t- }^{t-1}.\] (1)

Where \(_{1}():^{C H W}^{C  H_{1} W_{1}}\) and \(_{2}():^{2C H_{1} W_{1}} ^{C H_{2} W_{2}}\) are \(2\)D convolution layers, the operator \(^{}\) and \(^{}\) denotes concatenation on depth and temporal dimension, respectively, \(\) is the \(2\)D max-pooling operation with the spatial downsampling rate of \(2\). In this work, \(H_{1}=H/2,\ W_{1}=W/2,\ H_{2}=H/4,\ W_{2}=W/4\).

It can be seen that \(_{1}()\) drags input feature maps of different time frames into a common feature space to ensure representation compatibility , and then \(_{2}()\) takes the enhanced feature maps of each compatible feature pair, _i.e._, \(_{1}(_{t})^{}_{1}( _{i})\), as input to learn the relations between target frame and its historical frames. In this way, the associations between target feature maps, \(_{t}\), and each of its historical feature maps, \(\{_{i}\}_{i=t-}^{t-1}\) is obtained. Finally the outputs from TRIC will be grouped together with \(_{1}(_{t})\) to form the output relation embeddings, _i.e._, \(\{}_{t-},\ ,\ }_{t}\}\) shown in Fig. 3, It is worth noting that convolution kernels in TH-TRE are shared, which helps it accept input with adjustable time length while keeping the number of parameters constant.

### Temporal Relation-Aware Pooling (TRAP)

The relation embeddings obtained by TH-TRE block are still in a temporal sequence form. While, for making final predictions on the target frame, the aggregation for generating summarized representation of entire input sequence is required. To this end, a learnable temporal pooling, _i.e._, TRAP, is proposed. In general, the TRAP block aims at perceiving the contribution degree of each historical frame for prediction task according to the target-history relations, and using these measurements of importance to aggregate the temporal information in each

Figure 3: The illustration of TH-TRE.

Figure 2: The illustration of multi-view TARSS-Net. The segmentation results for the radar data in RD and RA views, as well as referenced detection results in the camera image are presented for intuitive illustration.

Single-view radar sequence. However, due to the computational pressure and parameter expansion caused by high-dimensional spatial-time tensors, it is necessary to consider the trade-off of information utilization in each dimension before aggregation. In turn, two forms of TRAP are presented, _i.e._, Spatio-TRAP and Depth-TRAP. For each form of the TRAP, there are two main steps: compression (discard) and attentive pooling (aggregation).

**Spatio-TRAP.** Spatio-TRAP is performed on the entire spatial domain of input feature maps. Therefore, the importance of temporal relations will be estimated on the spatial space of relation embeddings. As shown in Fig. 4-(a), given the relation embeddings, \(\{}_{i}\}_{i=t-}^{t}^{C( +1) H_{2} W_{2}}\), the two main steps of Spatio-TRAP are as follows:

i. _Depth-Compression_. First, all the relation embeddings are compressed by both global depth average-pooling and max-pooling. Then a temporal-shared \(2\)D convolution block is used to generate the contribution map sequence, \(\{_{i}\}_{i=t-}^{t}^{1(+1)  H_{2} W_{2}}\), for following aggregation step. For each \(_{i}\), the process can be formalized as follows,

\[_{i}=_{2}^{}(_{1}^{} (^{}(}_{i})^{$}}^{}(}_{i}))).\] (2)

Where \(/^{}()\) denotes the global depth average/max-pooling operation, \(_{1}^{}():^{2 H_{2} W_{2}} ^{16 H_{2} W_{2}}\) and \(_{2}^{}():^{16 H_{2} W_{2}} ^{1 H_{2} W_{2}}\) are temporal-shared convolution layers with kernel size of \(3 3\) and \(1 1\), respectively.

ii. _Spatio-Temporal Attentive Pooling_. To modulate the input feature maps in spatio-temporal dimension, a \(2\)D softmax is performed on each map of \(\{_{i}\}_{i=t-}^{t}\). Moreover, as deriving from the relation embeddings \((\{}_{i}\}_{i=t-}^{t})\), the contribution maps have a smaller spatial size than \(\{_{i}\}_{i=t-}^{t}\), _i.e._, \([H_{2},W_{2}]=1/4[H,W]\). Hence a spatial interpolation operation for expanding the size of \(\{_{i}\}_{i=t-}^{t}\) is required, so as to ensure the dimension consistency of the following weighted summation and skip connection. Then the whole process of this step can be formalized as

\[}_{t}^{}&= \{_{i=t-}^{t}_{i}^{}_{i,d} \}_{d=1}^{C}+_{t},\\ _{i}^{ST}&=(\{ 2()\}_{i},\;[H/H_{2},W/W_{2}])}{HW/H_{2} W_{2}}.\] (3)

Where, \(}_{t}^{}\) and \(_{i}^{}\) are enhanced target representation and spatio-temporal contribution weights of the \(i\)-th frame. Since the nearest interpolation \((,\;[,])\) expands \(HW/H_{2}W_{2}\) times the spatial size of \(2()\), the values of \(_{i}^{}\) should be shrank to satisfy \(_{i=1,h=1,w=1}^{+1,H,W}_{i,h,w}^{}=1\).

**Depth-TRAP.** Depth-TRAP is performed on the depth of input feature maps. During learning process, features expanded by the depth dimension are of great significance for unit-level classification (semantic segmentation), and they adequately represent semantic information. In this way, Depth-TRAP measures the importance of temporal relations on semantic space of relation embeddings. Similar with the spatio form, Depth-TRAP also requires compression and aggregation steps (see Fig. 4-(b)), which are as follows:

i. _Spatio-Compression_: The input relation embeddings are first compressed in spatial domain by global average-pooling and max-pooling, then these two global pooled sequences are concatenated

Figure 4: The illustration of two forms of the proposed TRAP block: (a) Spatio-TRAP with Depth-Compression; (b) Depth-TRAP with Spatio-Compression.

and presented to a temporal-shared small MLP network, \(^{}():^{2C}^{C}\), to obtain the spatio-compressed sequence, \(\{_{i}^{}\}_{i=t-}^{t}\). This process can be formalized as follows,

\[_{i}^{}=^{}(^{ }(}_{i})^{}^{}(}_{i})).\] (4)

Where \(/^{}()\) denotes global average/max-pooling operation on spatial domain, with a kernel size of \(H_{2} W_{2}\).

ii. _Depth-Temporal Attentive Pooling_: This step calculates the contribution vector for each spatial-compressed temporal relation embedding, \(_{i}^{}\), through depth dimension, which achieves the importance measurement of temporal relations in semantic space. Then, with these contribution vectors, a weighted summation along with a skip connection is conducted to aggregate each single-view encoding feature sequence, \(\{_{i}\}_{i=t-}^{t}\), and therefore the enhanced target representation, \(}_{t}^{}^{C H W}\) is obtained. The contribution vectors can be obtained as follows,

\[^{} =(\{^{}( _{i})\}_{i=t-}^{t}),\] (5) \[_{i} =\{x_{i,d}^{}+p_{i,d}\}_{d=1}^{C},\ p_{i,d} =\{p_{i,d}=0.1(i/10^{8(d/2)/C}),d\ \ 2=0;\\ p_{i,d}=0.1(i/10^{8((d-1)/2)/C}),d\ \ 2=1. .\]

Where \(^{}():^{C}^{C}\) denotes the temporal-shared MLP, and \(p_{i,d}\) is the depth-temporal position encoding result following self-attention  for each element of \(\{_{i}^{}\}_{i=t-}^{t}\). Similar to Spatio-TRAP, the contribution vectors are scaled by softmax to jointly modulate the input feature maps in both depth and time dimensions. Then the scaled vectors, \(^{}^{C(+1)}\), are used to aggregate information from input feature maps as follows,

\[}_{t}^{}=\{_{i=t-}^{t}_{i}^{ }_{i,h,w}\}_{h=1,w=1}^{H,W}+_{t}.\] (6)

Where the operator \(\) denotes Hadamard product, and \(_{i,h,w}^{C}\) is the feature in each spatio-temporal position of input feature maps \(\{_{i}\}_{i=t-}^{t}\) obtained from a basic encoder. Finally, the output target representation, \(}_{t}\), enhanced by the TRAM will be presented to the corresponding decoder.

## 4 Experiments

### Datasets and training setup

Three datasets have been used to valid the performance of TARSS-Net including: **CARRADA**, which contains multi-view annotated radar recordings (RAD tensors) for \(4\) categories of objects in driving scenarios under different weathers conditions; **CARRADA-RAC**, which is an improved version of CARRADA with calibrations on RA view; **KuRALs**, which is a real-measured dataset with refined annotation collected by a Ku-band surveillance radar and includes various typical targets. The training setup for TARSS-Nets and other compared SoTA networks strictly follows the consistent configuration, including hardware platform, hyper-parameter settings and evaluation metrics, and the number of input frames for TARSS-Nets is \(5\) by default (\(=4\)). See Appendix D for more details.

### Comparisons with State-of-The-Art Methods

The most widely used RSS dataset, CARRADA, is used to comprehensively compare the performance of TARSS-Net with existing RSS methods. CARRADA-RAC and KuRALS dataset are utilized to explore the generalization and stability of TARSS-Net, on which only representative methods are compared, _i.e._, TMVA-Net (temporal-based model) and PKCIn-Net (current SoTA). TARSS-Net_S and TARSS-Net_D denote the TARSS-Net with Spatio-TRAP and Depth-TRAP, respectively.

i. **CARRADA**. The overall results on the test subset are listed in Table 1. Generally, the models that explicitly consider the temporal dynamics in radar signals, _e.g._, TMVA-Net , can obviously achieve better performance than other convolution-based models [20; 28; 2; 14; 6]. By introducing SA

[MISSING_PAGE_FAIL:8]

[MISSING_PAGE_FAIL:9]

TRAP. Therefore, we argue that maintaining more semantic information might be an effective way to further improve Spatio-TRAP, which is worth of investigating in the future work.

### Effect of input time length on TARSS-Net performance

The RD performance of TARSS-Net_D increases with time length of inputs grows and achieves the optimum at \(6\) frames, _i.e._, \(=5\), as presented in Fig. 5. With the careful design of temporal modeling paradigm, TARSS-Net can handle arbitrarily long sequence relations without increasing parameter scale, which is significant to find the optimal duration of temporal dependencies not only for RSS tasks but also for all temporal relation modeling methods.

### Real-time performance comparison

In addition to model scale, the computational complexity and inference speed of the RSS methods are also important for deploying applications, which is measured by multiply-accumulate operations (MACs) and frames per second (FPS), respectively. All the real-time performance shown in this section are obtained on a single RTX 3090 GPU.

Among existing RSS models, TMVA-Net is the SoTA one for multi-view temporal relation learning. As far as our knowledge, none of existing methods applied Transformer or SA on the time dimension in RSS task because of the exploding number of parameters. In order to deeply explore the real-time performance of different temporal relationship modeling methods, we introduce vision Transformer (ViT) into the basic architecture of TARSS-Net, which forms a ViT-based baseline method, called Vit-based-Net. The left part of Table 7 compares the real-time performance of TARSS-Net with TMVA-Net and Vit-based-Net with multi-view inputs. All methods take \(5\) consecutive time frames as input. It can be seen that directly introducing Transformer in temporal relationship modeling of radar data is inefficient, which would consume more computation source but obtaining lower RSS performance. TARSS-Net consumes more computation and inference time than TMVA-Net in temporal relation learning, but achieves better RSS accuracy. In addition, the inference speed of \(23\) FPS in TARSS-Net_D is also sufficient for real-time applications.

The right part of Table 7 compares real-time performance of several temporal relationship learning models in single view. That is, the results for RD and RA views are measured separately by the corresponding single-view network versions. In terms of real-time performance, TMVA-Net still has the fastest inference speed. But Vit-based-Net achieves the worst inference speed with the most number of parameters. However, it is not to be overlooked that TARSS-Net still leads the pack in terms of RSS performance with competitive real-time performance.

More supplementary experiments are presented in Appendix E, including abalatioin experiment of AD encoding branch, class-wise performance comparisons, features visualization of core process in TARSS-Net and some example visualization of segmentation results.

## 5 Conclusions

This work focuses on exploiting temporal information in radar signals to enhance the representation capacity of multi-view RSS network. Firstly, the advantages and disadvantages of existing temporal modeling methods in RSS domain were deeply discussed, and on this basis, the design principles of RSS spatio-temporal encoding methods were introduced. Based on the principles, a flexible temporal-aware learning module, TRAM, and TARSS-Net based on TRAM is proposed, which follows the nove temporal learning paradigm, _i.e._ data-driven temporal information aggregation with learned target-history relations. Experiments fully verifies the superiority of TARSS-Net through SoTA methods comparison on three datasets, ablation experiments, performance under variation input time length, as well as its real-time performance.

 
**Method** & **Inputs** &  **Params** \\ (M) \\  &  **MACs** \\ (G) \\  & **FPS** &  **mIoU** \\ (\%) \\  &  **mDice** \\ (\%) \\  & **Inputs** &  **Params** \\ **(M)** \\  &  **RD-View** \\ **MACs(G)** \\  & **FPS** & 
 **RA-View** \\ **MACs(G)** \\  \\  TMVA-Net & MV & 7.2 & **119.5** & **66** & 46.9 & 57.1 & SV & **1.2** & 11.3 & **250** & 36.6 & **250** \\ Vit-based-Net & MV & 27 & 449 & 12 & 38.1 & 44.5 & SV & 3.6 & **1.8** & 59 & **7.0** & 55 \\
**TARSS-Net_S** & MV & **6.2** & 197.6 & 35 & 51.9 & 62.5 & SV & **1.2** & 13.3 & 181 & 40.4 & 143 \\
**TARSS-Net_D** & MV & 6.3 & 175.4 & 23 & **52.4** & **63.3** & SV & **1.2** & 13.3 & 111 & 40.4 & 112 \\  

Table 7: Real-time performance (MV: multi-view; SV: single-view).