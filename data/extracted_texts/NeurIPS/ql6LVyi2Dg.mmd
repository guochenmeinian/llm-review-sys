# Stability and Generalization of the Decentralized Stochastic Gradient Descent Ascent Algorithm

Miaoxi Zhu\({}^{1}\) Li Shen\({}^{2}\) Bo Du\({}^{1}\) Dacheng Tao\({}^{3}\)

\({}^{1}\) School of Computer Science, National Engineering Research Center for Multimedia Software,

Institute of Artificial Intelligence and Hubei Key Laboratory of Multimedia

and Network Communication Engineering, Wuhan University, China

\({}^{2}\) JD Explore Academy, China \({}^{3}\) The University of Sydney, Australia

{zhumx,dubo}@whu.edu.cn, {mathshenli,dacheng.tao}@gmail.com

Corresponding authors.

###### Abstract

The growing size of available data has attracted increasing interest in solving minimax problems in a decentralized manner for various machine learning tasks. Previous theoretical research has primarily focused on the convergence rate and communication complexity of decentralized minimax algorithms, with little attention given to their generalization. In this paper, we investigate the primal-dual generalization bound of the decentralized stochastic gradient descent ascent (D-SGDA) algorithm using the approach of algorithmic stability under both convex-concave and nonconvex-nonconcave settings. Our theory refines the algorithmic stability in a decentralized manner and demonstrates that the decentralized structure does not destroy the stability and generalization of D-SGDA, implying that it can generalize as well as the vanilla SGDA in certain situations. Our results analyze the impact of different topologies on the generalization bound of the D-SGDA algorithm beyond trivial factors such as sample sizes, learning rates, and iterations. We also evaluate the optimization error and balance it with the generalization gap to obtain the optimal population risk of D-SGDA in the convex-concave setting. Additionally, we perform several numerical experiments which validate our theoretical findings.

## 1 Introduction

Minimax problems have shown extensive applications in machine learning, such as adversarial robustness [26; 16], GAN , the zero-sum game , multi-agent reinforcement learning , AUC maximization . Alongside this, as the use of large-scale models has become widespread, distributed learning algorithms have emerged as a noteworthy approach for handling massive amounts of data and model parameters [5; 1]. Without a parameter server  aggregating all data from each local agent, decentralized algorithms that do not rely on the central structure can be advantageous when network bandwidth is low or latency is high, and they can also protect data privacy. In this work, we consider the following decentralized minimax stochastic optimization problems:

\[_{}_{}F(,):=_{i=1}^{m}F_{i}(,):=_{i=1}^{m}_{ _{i}_{i}}[f_{i}(,;_{i})]\] (1)

where \(m\) denotes the number of agents, \(F_{i}\) is the local loss function, \(_{i}\) represents local data stored on agent \(i\), and \(^{d_{}}\), \(^{d_{}}\). Note that the data distributions \(_{i}\) may differ across the agents.

The most straightforward algorithm for solving the above stochastic minimax optimization problem is to apply Stochastic Gradient Descent Ascent (SGDA) [14; 22] in a decentralized manner, namedD-SGDA. Many algorithms  have been proposed to solve Problem (1). As for the theoretical part, they mainly focus on analyzing the convergence behavior and communication complexity of their proposed algorithms. Due to the inaccessibility of the data distribution \(_{i}\), they approximate the expectation value by averaged sum on the training dataset \(=\{_{1},...,_{m}\}\) with local samples \(_{i,l_{i}}\) stored in local dataset \(_{i}=\{_{i,l_{i}}\}_{1 l_{i} n}:\)

\[_{}_{}F_{}(, ),\ \ F_{}(,)=_{i=1}^{m}F_{ _{i}}(,)=_{i=1}^{m}_{l_{i }=1}^{n}f_{i}(,;_{i,l_{i}})\] (2)

However, it is insufficient to evaluate the stochastic algorithm not to consider the generalization performance, which is roughly the gap between Eq. (1) and Eq. (2). Generally speaking, saddle point of \(F_{}(,)\) may not be the optimal solution of \(_{}_{}F(,)\). As a result, the model learned by Eq. (2) may not perform well on the test dataset. In fact, the generalization gap is a crucial criterion for us to foresee the performance of the trained model on the unknown dataset. Furthermore, it is quite necessary for us to make a trade-off between the optimization error and the generalization gap to obtain models with optimal population risk (see Eq. (1)).

Concerning the stability and generalization of the minimax problem, several works  have studied the generalization gap and population risk of some algorithms, including SGDA, SGDmax, PPM, and AGDA. However, these results cannot be directly extended to the decentralized case due to the additional communication step during the training process. Intuitively, the number of nodes and communication topology in decentralized training may exert a potential influence on the model's generalizability. Note that even for the decentralized minimization problem, the generalization and stability of decentralized SGD are adversely affected by an extra non-vanishing term , and the stability usually suffers from a constant term \(^{2}\), compared to vanilla SGD. Building upon these findings, we argue that it is worthy to investigate the generalization and stability of D-SGDA for decentralized minimax problems, where there do exist more newly unveiled problems.

To mitigate this theoretical deficiency, we present the first comprehensive analysis of the stability and generalization of D-SGDA for the decentralized minimax problem in this paper. Specifically, we develop a refined stability analysis in a decentralized manner and derive the generalization gap and population risk for D-SGDA under different settings. The main theoretical results are summarized in Table 1. And our main contributions are summarized as follows:

* _First work on the stability and generalization of D-SGDA for decentralized minimax problem._ We extend the concepts of algorithmic stability, which includes argument stability and weak stability, to the decentralized setting. And we establish a universal connection between argument stability and different measures of generalization gap in the framework of decentralization. We propose a subtle technique to distribute the "different" samples in the neighboring datasets among agents by methods of permutation and combination.
* _New theoretical results._ Our theoretical results reveal that decentralized structure does not hurt the stability and generalizability of D-SGDA compared with SGDA and explain how topology of the communication network influences the performance in stongly-convex-strongly-concave,

   Cases & Measure & Bound \\   & strong/weak primal-dual generalization gap & \(}(}{T}{T+}}+ }{n})\) [Thm. 2] \\   & strong/weak primal-dual population risk & \((}{T^{\{, \}}}+)\) [Thm. 3] \\   & weak primal-dual generalization gap & \((+)\) [Thm. 4] \\   & weak primal-dual population risk & \((+}}{n})\) [Thm. 5] \\  NC-NC & weak primal-dual generalization gap & \(((C_{}T^{L})^{()^{1-}})\) [Thm. 6] \\   

Table 1: Main results on different cases: SC-SC, C-C, and NC-NC represent strongly-convex-strongly-concave, convex-concave, and nonconvex-nonconcave, respectively. \(}\) means it contains the logarithmic function. \(C_{}\) is a constant concerning about the spectral gap \(1-\) of different topology which is defined in Thm. 2. \(T\) represents iterations. \(L\) is Lipschitz constant. \(\) represents the strong convexity and strong concavity parameter. \(n\) denotes the sample size in each node. \(m\) denotes the number of nodes and \(0<c 1\) is configurable constant.

convex-concave, and nonconvex-nonconcave conditions (see Table 1,2). We also evaluate the optimization error and leverage it with generalization gap to obtain the optimal population risk.
* _Experiments._ We provide several numerical experiments on AUC maximization (C-C) and adversarial learning (NC-NC) in which we vary different factors to support our theoretical findings. The preliminary experimental results align with our theoretical insights.

## 2 Related Work

**Decentralized minimax problem.** Existing works mainly focus on improving the convergence rate and communication complexity. Liu et al.  propose DPOSG, which is firstly applied in case of nonconvex-nonconcave, i.e., GAN training, and they prove \((^{-12})\) computational complexity and \((log(1/))\) communication complexity on the busiest node. Xian et al.  propose DM-HSGD with convergence rate of \((^{3}^{-3})\) and Chen et al.  propose DREAM with communication rounds of \((^{2}^{-2}/})\) in nonconvex-strongly-concave condition. Chen et al.  propose SPIDER-GDA and achieve stochastic first-order oracle of \(((n+_{x}_{y}^{2})log(1/))\) under two-sided PL condition. Rogozin et al.  propose a Mirror-prox based algorithm with \((^{-1})\) communication complexity in C-C setting. Huang , Luo and Ye  accelerates by variance reduction. Beznosikov et al.  considers time-varying networks with heterogeneous data, Kovalev et al.  provides a rigorous complexity for decentralized variational inequalities.

**Stability and generalization.** There are mainly two approaches to investigating the generalization: algorithm-independent generalization, which is also called uniform convergence generalization, and algorithm-dependent generalization respectively. Where the former may degrade to a vacuous conclusion in  and we adopt the latter method in our paper which can better explain the generalization behavior of a detailed algorithm. Bousquet and Elisseeff  come up with algorithmic stability, Elisseeff et al.  extend the concept to randomized algorithms. Hardt et al.  further develop the framework by connecting algorithmic stability with the generalization gap. Sun et al.  and Zhu et al.  extend the generalization and stability analysis to D-SGD. In the minimax problem, Zhang et al.  focus on argument stability and prove \((1/n)\) weak and strong generalization bounds for the SC-SC condition; Farnia and Ozdaglar  analyze the uniform stability and generalization gap of GDA, GDmax, and PPM (proximal point method) in the case of NC-NC and Lei et al.  summarize the connection between different measures of stability and generalization gap and further develop the corresponding high-probability results. Xing et al.  specify the generalization gap for adversarial training and Yang et al.  investigate the stability-based generalization of SGDA with differential privacy constraints. Ozdaglar et al.  propose a new metric to better evaluate the generalization performance even in the case when the existing metric fails.

## 3 Problem Formulation

In this section, we provide the necessary assumptions, notations, terminologies of population risk, generalization gap, and algorithmic stability in decentralized minimax problems.

### Basic Assumptions

**Notations.** We use bold lower case to denote vectors and bold upper case to denote matrices. \(\|\|_{2}\) means \(_{2}\) norm for vectors and \(\|\|_{F}\) means Frobinius norm for matrices, and we will omit the subscript when the type of norm is clear from the context. \(_{n}^{n}\) denotes the all-one vector and \(_{i}()\) represents the \(i\)-th largest eigenvalue of a matrix. \([n]:=\{1,2,...,n\}\).

**Assumption 1** (Lipschitz continuous).: Each local function \(f_{i}\) is differentiable and there exists \(G>0\) that \(f_{i}\) is \(G\)-Lipschitz continuous with respect to both \(\) and \(\) on any given sample \(_{i}\), i.e.,

\[|f_{i}(,;_{i})-f_{i}(^{},^{};_{i})|  G\|(-^{}\\ -^{})\|_{2}.\]

**Assumption 2** (Lipschitz smooth).: Each local function \(f_{i}\) is differentiable and there exists \(L>0\) that \(f_{i}\) is \(L\)-Lipschitz smooth with respect to both \(\) and \(\) on any given sample \(_{i}\), i.e.,

\[\|(_{}f_{i}(,;_{i})- _{}f_{i}(^{},^{};_{i})\\ _{}f_{i}(,;_{i})-_{}f_{i}(^{ },^{};_{i}))\| L\|( -^{}\\ -^{})\|_{2}.\]

**Definition 1** (**Convexity-Concavity)**.: For each local loss function \(f_{i}(,;_{i})\), we say that \(f_{i}\) is \(_{}\)-strongly convex on \(\) if for any given \(\) and on any given sample \(_{i}\), there holds:

\[f_{i}(^{},;_{i}) f_{i}(,;_{i})+_{ }f_{i}(,;_{i})^{T}(^{}-)+} {2}\|^{}-\|^{2},_{} 0,,^{ }.\]

we say that \(f_{i}\) is \(_{}\)-strongly concave on \(\) if for any given \(\) and on any given sample \(_{i}\), there holds:

\[f_{i}(,^{};_{i}) f_{i}(,;_{i})+_ {}f_{i}(,;_{i})^{T}(^{}-)-}}{2}\|^{}-\|^{2},_{} 0,, ^{}.\]

We can call it is convex w.r.t. \(\) when \(_{}=0\) and concave w.r.t. \(\) when \(_{}=0\).

**Remark 1**.: Assumptions about the Lipschitz continuity and smoothness are commonly used in the context of decentralized minimax optimization problems [42; 9; 32].

### Decentralized Stochastic Gradient Descent Ascent (D-SGDA)

In decentralized setting, each node will exchange information alternatively and we represent the communication network between nodes as \(=(,)\), which is a connected graph with node set \(=\{1,2,...,m\}\) and edge set \(\). Specifically, \((i,l)\) indicates that agent \(l\) can receive information from agent \(i\) and therefore we symbolize the _in_ and \(\) neighbors as \(^{in}(i)\{l,(l,i)\}\) and \(^{out}(i)\{l,(i,l)\}\) respectively. In an undirected graph, there is no consideration about the order, thus \((i,l)\) implies \((l,i)\) and the _in_ and _out_ neighbors are identical which we will abbreviate as \(\) for brief. In our work, we focus on undirected graphs. The communication graph is associated with an adjacency matrix, which is also called a mixing matrix, \(=[_{ij}]^{m m}\). It implies the connection between \(m\) agents that \(_{ij}>0\) if and only if \((j,i)\), otherwise \(_{ij}=0\). And there are some basic assumptions about the mixing matrix which is commonly used in decentralized settings [17; 21; 23; 32].

**Assumption 3** (**Mixing matrix)**.: We assume the mixing matrix \(=[_{ik}]^{m m}\) defined on the graph \(=(,)\) is a symmetric doubly stochastic matrix, which holds the property that \(^{T}=\) and \(_{m}=_{m},_{m}^{T}=_{m}^ {T}\). Besides, we assume \(:=\{|_{2}|,|_{m}()|\}(0,1)\).

For a symmetric doubly stochastic matrix, \(\) holds the property that: \(_{1}=1\). For different topologies, \( 1\) implies the sparsity while \( 0\) implies the complete connection. Nedic et al.  and Ying et al.  list upper bounds for the spectral gap \(1-\) over the commonly communication network. More knowledge on decentralized optimization is placed in Appendix A.

In this paper, we study the decentralized minimax problem solved via D-SGDA (see Algorithm 1). We use the superscript to denote the \(t\)-th iteration and the subscript to denote the \(i\)-th local agent. During iteration, each client first computes its local gradient approximation by \(_{}f_{i}(_{i}^{t},_{i}^{t};_{i,j_{t}(i)})\) and \(_{}f_{i}(_{i}^{t},_{i}^{t};_{i,j_{t}(i)})\) respectively where \(j_{t}(i)\) is randomly chosen from \([n]\). Then each client communicates with its neighbor \((i)\) and updates by SGDA.

### Generalization Gap

In a sense, we obtain the result by minimax the empirical one \(F_{}\) in Eq. (2), which differs from the population one \(F\) in Eq. (1). So we can not guarantee the same performance on the unknown distribution as on the training dataset. And therefore the gap between the empirical one and the population one reflects the ability of generalization. Unlike the standard learning theory which only contains a single variable that can directly define the population risk and empirical risk by the objective function. Owing to the structure of minimax, there are different methods to define the population and empirical risk as concluded in , where primal-dual measure starts from the idea of duality gap in optimization. And we first introduce two types of population risks as follows.

**Definition 2** (**Population risk)**.: For a randomized model \((,)\), we define the population risk as:

1. _Weak primal-dual population risk_: \(^{w}(,)=_{^{}}[F( ,^{})]-_{^{}}[F(^{},)]\).

2. _Strong primal-dual population risk:_\(^{s}(,)=[_{^{}}F( ,^{})-_{^{}}F(^{}, )]\).

Here the expectation is taken over the randomness of the model. By replacing function \(F\) with function \(F_{}\) (see Eq. (2)) in Def. 2 when considering the empirical risk, we obtain the corresponding _weak primal-dual empirical risk_\(^{s}_{}(,)=_{^{}} [F_{}(,^{})]-_{^{ }}[F_{}(^{},)]\) and _strong primal-dual empirical risk_\(^{s}_{}(,)=[_{^{ }}F_{}(,^{})-_{^{ }}F_{}(^{},)]\) respectively. Subtracting the empirical risk from population risk, we can define the generalization gap as follows.

**Definition 3** (**Generalization gap**).: For a randomized model \((,)\), we define the corresponding generalization gap as:

1. _Weak primal-dual generalization gap:_\(^{w}_{gen}(,)=^{w}(,)-^{w}_{ }(,)\).
2. _Strong primal-dual generalization gap:_\(^{s}_{gen}(,)=^{s}(,)-^{s}_{ }(,)\).

**Remark 2**.: Notice that we revise the name as generalization gap to avoid misunderstanding since "generalization error" usually refers to the empirical risk in learning theory (see ). Our primal target (see Problem (1)) is to obtain small population risk (Def. 2) which can be considered as a summation like \(^{w}(,)=^{w}_{gen}(,)+^{w}_{ }(,)\), where generalization gap reflects how well the model generalizes and empirical risk reflects the optimization performance. The strong primal-dual risk is stronger than the weak one due to \(^{w}(,)^{s}(,)\) according to Jensen's inequality. But in some cases, it is sufficient to bound weak primal-dual population risk such as the MDP .

### Algorithmic Stability

Inspired by  that the generalization gap of an \(\)-stable algorithm can be bounded by \(\). And this connection between stability and generalization for minimax problem is furthermore established in . For a randomized algorithm \(\) solving the problem (2), we use \(()=(_{}(),_{ {y}}())\) to denote the output of applying algorithm \(\) on dataset \(=\{_{1},...,_{m}\}\). Let \(_{}\) and \(_{}\) denote taking expectation on the randomness of the algorithm \(\) and the dataset \(\) respectively. Sometimes we omit the subscript as \([]\) when it is clear from the context. Next, we first refine the definitions of algorithmic stability in a decentralized manner and then provide a connection between algorithmic stability and generalization gap in the framework of decentralization.

**Definition 4** (**Decentralized neighboring dataset**).: We call \(,^{}\) the decentralized neighboring datasets when there are at most one different sample in each local dataset, where \(=\{_{1},_{2},...,_{m}\}\), \(^{}=\{^{}_{1},^{}_{2},..., ^{}_{m}\}\) and each \(_{i}\) and \(_{i}^{}\) differs by at most one sample.

**Definition 5** (**Decentralized algorithmic stability**).: For a randomized algorithm \(\), we say:

1. \(\) is \(\)**-argument stable** if there holds for any neighboring datasets \(,^{}\): \[_{}\|(_{ }()-_{}(^{})\\ _{}()-_{}(^{}) )\|_{2}.\]
2. \(\) is \(\)**-weakly stable** if there holds for any neighboring datasets \(,^{}\): \[_{}\![_{^{}}\!_ {}[(_{}(),^{};\!)\!-\!(_{}(^{}),^{};\! )]\!+\!_{^{}}\!_{}[(^{},_{}(\!);\!)\!-\!( ^{},_{}(\!^{});\!)] ]\!\!.\] where \(\!\!\{_{1},...,_{m}\}\) denotes sample index with \(_{i}_{i}\) and \((,;)\!\!_{i=1}^{m}f_{i}( ,;_{i})\).

And we further specify the stability error as \(^{arg}_{sta}()\) and \(^{w}_{sta}()\) respectively.

**Remark 3**.: The definition of neighboring datasets in the decentralized setting can degenerate to the traditional neighboring datasets where there is at most a single different sample between \(\) and \(^{}\). And the refined concepts of algorithmic stability are also fit for classic stability without decentralization in . These facts validate that our definitions above are well-defined. Notice that the argument stability can imply weak stability because of the property of Lipschitz continuity (see Assumption 1). Specifically speaking, when algorithm \(\) is \(\)-argument stable, then it is \(G\)-weakly stable. So we will mainly focus on the argument stability in the rest part.

**Theorem 1** (**Connection**).: _For an \(\)-argument stable decentralized algorithm \(\), under Assumption 1, we have the following different measures of generalization gap:_

1. _Weak primal-dual generalization gap:_ \(^{w}_{gen}(_{}(),_{}( ))G\)_._
2. _Strong primal-dual generalization gap holds under extra Assumption_ 2 _when_ \(f_{i}\) _is_ \(_{}\)_SC-_\(_{}\)_SC:_ \[^{s}_{gen}(_{}(),_{}( )) G}{^{2}}},\] _where_ \(\{_{},_{}\}\)_._

[MISSING_PAGE_FAIL:6]

**Generalization gap.** According to Thm. 1, we can directly derive the weak and strong primal-dual generalization gap of D-SGDA as \(G_{sta}^{arg}\) and \(G}{^{T}}}_{sta}^{arg}\) respectively. Therefore, we hold the same analysis as stability in above Remark 5.

Next, we will first derive the optimization error and then provide the population risk by decomposition \(^{s}(,)=_{gen}^{s}(,)+_{S}^{s}( ,)\). Population risk is an important evaluation for the performance of a stochastic learning algorithm, which will evaluate how our model obtained by training dataset behave over the whole distribution. Notice that we will use the average output instead of the last iterate in analyzing the optimization errors. We denote that:

\[_{ave}^{T}^{T-1}_{,t}^{t}}{ _{t=0}^{T-1}_{,t}},_{ave}^{T}^{T-1}_{,t}^{t}}{_{t=0}^{T-1}_{,t}}.\] (3)

**Theorem 3** (**Strong primal-dual population risk**).: _Under Assumption 1,2,3, when each \(f_{i}\) is \(_{}\)SC-\(_{}\)SC, we have the strong primal-dual population risk as follows, where \(_{t}^{max}\{_{,t},_{,t}\}\), \(_{t}^{min}\{_{,t},_{,t}\}\), \(=\{_{},_{}\}\), and \((_{ave}^{T},_{ave}^{T})\) is defined in Eq. (3):_

1. _for fixed learning rates,_ \[^{s}(_{ave}^{T},_{ave}^{T}) G}{^{2}}}(2GL}()^{2}L}{1- }+}{n}))+}^{2}+C_{}^{2}}{2^{ min}T}\] \[+^{max}G^{2}+}+C_{})GL ^{}}{1-}+}+C_{})G}{}.\]
2. _for decaying learning rates that_ \(_{t}^{min}\!=\!\) _and_ \(_{t}^{max}\!=\!}\) _with_ \(c\!\!1\) _and_ \(2c\!\!\!+\!1\)_,_ \[^{s}(_{ave}^{T},_{ave}^{T})\] \[ G}{^{2}}}()}}{n}+}{^{2}T}(_{2c L/(L+)+1}}{2c--1}+ T\!\! _{2c=L/(L+)+1}))\] \[+}\!\!+\!C_{})}{}\!\!\!+\!\! {G^{2}}{2}\!\!(\!+\!_{c 1}}{(1\!-\!c)T^{c}} \!+\!_{c=1}}{T})\!\!+\!(C_{}\!\!+\!C_{})}{ T^{c}}(_{c 1}}{1-c}\!+\! T\!\!_{c=1}).\]

**Remark 6**.: By Jensen's inequality (see Remark 2), we can conclude that weak primal-dual population risk also satisfies the conclusions above. **(i) Bound analysis and comparison.** For fixed learning rates, it is interesting to see that we should choose \( 1/\) to get the optimal population risk of \((+})\), although when \( 1/T\) we can get optimal generalization performance but the optimization error will not converge. While for the decaying learning rates, the population risk bound is \(}(T^{1-c}/n+C_{}/T^{\{,\}})\), which matches the corresponding results for SGDA (see Thm.3.(c) in ) of \(( N/N)\) when \(n T^{\{,\}}\). **(ii) Topology influence.** We omit the trivial factor influence analysis here (or see Remark 5). And the effect of topology is captured quantitatively by \(C_{}\) and \(\) which have been discussed in Remark 5 and Table 2.

### Results on Convex-Concave Case

In this section, we provide the argument stability and weak primal-dual population risk of D-SGDA algorithm for the NC-NC condition in the following theorems with proof in Appendix F.

**Theorem 4** (**Argument Stability**).: _Under Assumption 1,2,3, when each \(f_{i}\) is convex-concave, we have the argument stability bound for D-SGDA (denoted as \(\)):_

\[_{sta}^{arg}()_{k=0}^{T-1}_{k}^{ max}+4GL_{k=1}^{T-1}(_{k}^{max}_{s=0}^{k-1}_{s}^{max}^{k-1-s }).\]

  Topology & \(\) & \(C_{}\) & \(\) \\  fully connected & 0 & 0 & 0 \\ exponential & \(1-\) & \(( m)\) & \(( m)\) \\ grid & \(1-\) & \((m m)\) & \((m m)\) \\ ring & \(1-}{3^{2}}\) () & \((m^{2})\) & \((m^{2})\) \\ star & \(1-}\) & \((m^{2})\) & \((m^{2})\) \\ disconnected & 1 & N/A & N/A \\  

Table 2: \(\) value of different topology. Here \(0\) means the extra term will disappear and N/A means the term will diverge.

**Remark 7**.: **(i) Bound analysis and comparison**. When there is no strong convexity or strong concavity, we can no longer choose the decaying learning rates, otherwise the argument stability error may not converge. For fixed learning rates, \(_{sta}^{arg}\) is upper bounded by \((+T}{1-})\), which is slightly lower than SC-SC condition. While we can still choose \( 1/T\) to obtain optimal result \((+)\). Besides, compared with the corresponding result for SGDA (see Thm.2.(b) in ) of \((}{N}+})\), we can approach it when \( 1/T^{3/4}\) and \(n T^{3/4}\). **(ii) Topology influence.** In C-C condition, the effect of topology on the stability is quantified by \(\) which has been discussed in Table 2. And we can conclude that denser topology is more stable and fewer nodes will increase stability under the same topology.

**Generalization gap.** Thm. 1 implies \(_{gen}^{w}(_{}(),_{}( ))G_{sta}^{arg}()\). So the generalization gap holds with the same quantitative analysis as stability above. Analogously we can present the weak primal-dual population risk in the following theorem.

**Theorem 5** (**Weak primal-dual population risk**).: _Under Assumption 1,2,3, when each \(f_{i}\) C-C, we have the weak primal-dual population risk as follows, where \(_{t}^{max}\{_{,t},_{,t}\}\), \(_{t}^{min}\{_{,t},_{,t}\}\), \(=\{_{},_{}\}\), and \((_{ave}^{T},_{ave}^{T})\) is defined in Eq. (3):_

\[^{w}(_{ave}^{T},_{ave}^{T})G(T}{n}+)^{2}T}{1-})+}^{2} +C_{}^{2}}{2^{min}T}\] \[+^{max}G^{2}+}+C_{ })GL^{}}{1-}+}+C_{})G}{}.\]

**Remark 8**.: The weak primal-dual population risk attains optimal of \((}{n}+})\) when we choose \(^{max}=^{} 1/T^{}\). Note that we select \( 1/T\) to obtain optimal generalization performance (see Remark 7), but the optimization error will diverge in that case. Compared with the result of SGDA: \((N^{-1/2})\) (see Thm.3.(b) in ), our result can approach it by \(n^{1/2} T^{1/3}\). Then the effect of topology and number of nodes on the population risk is reflected by \(\), which has been discussed in Remark 5 and Table 2.

### Results on Nonconvex-Nonconcave Case

In this section, we present the weak stability and weak primal-dual generalization gap of D-SGDA algorithm for the NC-NC problem in the following theorem with proof in Appendix G.

**Theorem 6** (**Weak stability**).: _Under Assumption 1,2,3, denoting D-SGDA algorithm as \(\), we have the following weak stability bound when \(_{t}^{max}\{_{,t},_{,t}\}\), and \(_{t}^{min}\{_{,t},_{,t}\}\):_

1. _for fixed learning rates that_ \(_{t}^{max}=^{max}\)_, and_ \(_{t}^{min}=^{min}\)_,_ \[_{sta}^{w}() 2G^{2}(T}{n}+ T}{1-}).\]
2. _for decaying learning rates that_ \(_{t}^{min}=\)_, and_ \(_{t}^{max}=},c 1\)_,_ \[_{sta}^{w}()(c+L)(c+L-1)^{}( G^{2}T^{L}}{(c+L-1)n}+G^{2}LC_{}T^{L}}{2c+ L-1})^{}()^{1-}.\]

**Weak primal-dual generalization gap.** According to Thm. 1, we can derive the weak primal-dual generalization gap as \(_{gen}^{w}(_{}(),_{}( ))G_{sta}^{w}()\) for D-SGDA in NC-NC condition.

**Remark 9**.: For case a. with fixed learning rates, the weak stability and weak primal-dual generalization gap is bounded by \((+T}{1-})\), which can reach \((+)\) when \(\). For case b. with decaying learning rates, the stability and generalization gap is bounded by \(((C_{})^{}T^{}()^{1- })\). It is evident to analyze the influence of factors that, larger sample size and fewer nodes will result in a smaller stability error and generalization gap, which coincides with results in (S)C-(S)C conditions (see Remark 5). Approaching to the weak primal-dual generalization bound of \((n^{-}T^{})\) provided \(\)-weakly-convex-weakly-concave (see Thm.5 in ). \(C_{}\) reflects the effect of topology on the stability and generalization gap and its value has been discussed in Reamrk 5 and Table 2.

## 5 Experiments

**Experiments Setup.** We evaluate our theoretical results of the C-C case by adopting the SOLAM method  to solve the AUC problem on two datasets svmguide and w5a, and the NC-NC case by solving the generative adversarial network on MNIST. We extend the methods for both cases to a decentralized implementation. Our experimental setting follows the way conducted in [13; 19] to study how the stability and generalizability of D-SGDA would behave along the learning process with different factors, including learning rates, typologies, nodes, and sample sizes. We employ the same randomized method to generate two model sequences, one for the original data and another for a one-observation perturbing data, and subsequently calculate the Euclidean distance \(\) between their respective parameter sets. Additional implementation details can be found in the **Appendix**.

**Results analysis:** From Fig. 1 and Fig. 2, we can observe that: (i) faster learning rates, fewer number of nodes and smaller sample size can result in a smaller Euclidean distance between weights and a smaller difference between training dataset and validation dataset; (ii) the performance of different topology on stability: fully connected(all) \(>\) exponential \(>\) grid \(\) ring \(\) star \(>\) disconnected(single).

Figure 1: \(\) against the number of iterations, with the first row showing different settings. From left to right, the settings include varying learning rates, communication typologies, sample sizes on the w5a dataset, and learning rates(svmguide3). The generalization error is displayed at the bottom accordingly.

Figure 2: The first row shows the performance of the generator. From left to right, the settings include varying learning rates, the number of nodes, sample sizes, and communication typologies on the MNIST dataset. The performance of the discriminator is displayed at the bottom accordingly. The dashes denote different layers.

These validate our theoretical results of the algorithmic stability for D-SGDA (see Remark 5 below Thm. 2). And the impact of different topologies also coincides with our discussion in Table 2.

## 6 Conclusion

In this paper, we provide the first comprehensive analysis for the stability and generalization of D-SGDA for decentralized minimax problems. Our theoretical results show that a decentralized structure does not destroy the stability and generalization of D-SGDA, instead we can leverage between the iterations and the number of nodes, as well as sample size to achieve better population performance. Numerical experiments also validate our theory. Our analysis technique has the potential used for studying the ability and generalization of other decentralized minimax algorithms.

**Limitation&Broader Impacts.** In our analysis, we require the Lipschitz smoothness, which may be further relaxed in future work. In addition, D-SGDA can converge with the heterogeneous data distribution, whose stability and generalization are still unexplored in this work. Since our work focuses on the theoretical understanding of D-SGDA, it does not suffer from negative impacts.