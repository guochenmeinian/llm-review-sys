# Attention Temperature Matters in ViT-Based Cross-Domain Few-Shot Learning

Yixiong Zou Ran Ma Yuhua Li Ruixuan Li

School of Computer Science and Technology, Huazhong University of Science and Technology

{yixiongz, ranma, idcliyuhua, rxli}@hust.edu.cn

Corresponding author.

###### Abstract

Cross-domain few-shot learning (CDFSL) is proposed to transfer knowledge from large-scale source-domain datasets to downstream target-domain datasets with only a few training samples. However, Vision Transformer (ViT), as a strong backbone network to achieve many top performances, is still under-explored in the CDFSL task in its transferability against large domain gaps. In this paper, we find an interesting phenomenon of ViT in the CDFSL task: by simply multiplying a temperature (even as small as 0) to the attention in ViT blocks, the target-domain performance consistently increases, even though the attention map is downgraded to a uniform map. In this paper, we delve into this phenomenon for an interpretation. Through experiments, we interpret this phenomenon as a remedy for the ineffective target-domain attention caused by the query-key attention mechanism under large domain gaps. Based on it, we further propose a simple but effective method for the CDFSL task to boost ViT's transferability by resisting the learning of query-key parameters and encouraging that of non-query-key ones. Experiments on four CDFSL datasets validate the rationale of our interpretation and method, showing we can consistently outperform state-of-the-art methods. Our codes are available at https://github.com/Zoilsen/Att_Temp_CDFSL.

## 1 Introduction

Deep networks have shown great power in learning from large-scale datasets [18; 11; 7]. However, collecting sufficient training data for every domain is always challenging, which gives rise to the Cross-Domain Few-Shot Learning (CDFSL) task. CDFSL requires a model to be firstly trained on a large-scale pretraining dataset (source domain, general dataset, e.g., ImageNet ), and then transferred to downstream datasets (target domain, expert-knowledge dataset, e.g., medical dataset [5; 44]) where only a few training samples are available. Typically, large domain gaps exist between the source and target dataset, making the transferring and downstream learning difficult [2; 12; 15].

Vision Transformer (ViT) , as a prevailing kind of deep network, has achieved top performances in many computer vision tasks [47; 9; 37]. However, only a few works [14; 10; 53] studied ViT's transferability against large domain gaps for the CDFSL task. In this paper, we find an intriguing phenomenon for the ViT-based CDFSL task: by multiplying a temperature parameter \(\) to the attention map of ViT blocks, the downstream target-domain few-shot performance consistently increases when \(<1.0\) or even close to 0, albeit the attention map is downgraded to a uniform map (Fig. 1).

In this paper, we delve into this phenomenon for an interpretation. We find the query-key attention mechanism in the ViT network demonstrates high discriminability but low transferability, which makes the target-domain attention ineffective, and the temperature adjustment is interpreted as a remedy for the ineffective target-domain attention. Moreover, we find the non-query-key structuresin ViT show complementary characteristics against the query-key parts, i.e., higher transferability but lower discriminability. Based on these interpretations and findings, we propose a method for the CDFSL task to encourage the learning of non-query-key parameters and resist that of query-key ones, so as to improve the transferability of ViT against large domain gaps.

In summary, our contribution can be listed as

\(\) To the best of our knowledge, we are the first to unveil the importance of the attention temperature in ViT-based CDFSL methods.

\(\) Through experiments, we find the query-key attention mechanism shows limited transferability against large domain gaps, which causes ineffective target-domain attention and needs to be remedied by the temperature adjustment.

\(\) Based on it, we propose a method for the CDFSL task to boost ViT's transferability by resisting the learning of query-key parameters and encouraging that of the non-query-key ones.

\(\) Extensive experiments validate the rationale of our interpretation and method, and show that we can consistently outperform state-of-the-art works.

## 2 Delve into Attention in ViT-based Cross-Domain Few-Shot Learning

### Preliminaries

Cross-Domain Few-Shot Learning (CDFSL) requires the model to first learn from a general dataset (i.e., source dataset) containing sufficient training samples, and then transfer to downstream target datasets where only scarce training data is available. We denote the source dataset as \(D^{S}=\{x_{i}^{S},y_{i}^{S}\}_{i=1}^{N}\) where \(x_{i}^{S}\) and \(y_{i}^{S}\) represent the id in training sample and its label, respectively. Similarly, the target dataset is termed as \(D^{T}=\{x_{i}^{T},y_{i}^{T}\}_{i=1}^{N^{}}\). During the learning and testing on \(D^{T}\), for the fair comparison, current works [2; 12] adopt a \(k\)-way \(n\)-shot paradigm to sample from \(D^{T}\) to construct small datasets (i.e., episodes) consisting of \(k\) classes and \(n\) training samples in each class. Based on episodes, the model learns from these \(k n\) samples (a.k.a. support set, \(\{x_{ij},y_{i}\}_{i=1,j=1}^{k,n}\)) and is evaluated on testing samples from these \(k\) classes (a.k.a. query set, \(\{x^{q}\}\)).

Vision Transformer (ViT) has recently been popular in vision tasks, which divides images into tokens and captures the image patterns through self-attentions. As shown in Fig. 1, ViT is composed of stacked blocks containing an attention network and an MLP network, which can be represented as

\[f(x_{i}^{S})=M(A(M( A(E(x_{i}^{S}))))),\] (1)

where \(M()\) denotes the MLP network, \(A()\) denotes the self-attention network, and \(E()\) denotes the embedding layer. In this paper, we focus on the ViT-based CDFSL method to study its downstream generalization. Specifically, we follow  to initialize ViT on ImageNet  by DINO  (see appendix for other settings), and train ViT on \(D^{S}\) by the cross-entropy loss with a fully-connected (FC) layer as

\[L=L_{cls}((f(x_{i}^{S})),y_{i}^{S}),\] (2)

Figure 1: (a) Vision Transformer (ViT) is composed of multiple blocks of the MLP and attention networks. (b) We train a ViT model on _mini_ImageNet (source dataset), and conduct prototype-based classification on target datasets. By multiplying a temperature \(\) (even as small as 0) to the attention in ViT blocks (e.g., the last block) during the target-dataset classification, we find the accuracy consistently increases on most target datasets (Crop. Euro. ISIC. and Ches., even with a uniform attention map) while that of the source dataset drops. In this paper, we delve into this phenomenon for an interpretation, and propose a simple but effective method for the CDFSL task based on it.

where \(()\) denotes the FC-based classifier and \(f()\) denotes ViT. Finally, we utilize the ProtoNet  with the distance function \(d(,)\) for the target domain few-shot learning as

\[}=_{i}d(_{j}f(x_{ij}),f(x_{q})).\] (3)

In this section, we follow  to take _mini_ImageNet  as the source dataset, and take CropDiseases , EuroSAT , ISIC2018  and ChestX  as target datasets.

### Interpretation: Attention Temperature Remedies Target-Domain Attentions

#### 2.2.1 Intuitive Observation of Ineffective Target-Domain Attentions

To study why the temperature-based attention adjustment improves on target datasets but harms the source dataset, we first visualize the attention map on each domain in Fig. 1(a). As the backbone network utilizes the CLS token feature from the last ViT block as the final feature, we take the attention map w.r.t. the CLS token in the last ViT block for visualization, where a large attention value indicates the color of red and a small value refers to blue. We plot the CLS token's attention value in the left-top of the map. We can see the source-domain-trained ViT shows a good capability of discovering meaningful objects in the source dataset (_mini_ImageNet), but it always shows wrong attention on target datasets, which is represented in two aspects:

(1) It tends to excessively focus on the CLS token and ignores all image tokens, as the left-top patches are red but the image heatmap is blue for the first two columns. (2) For its focus on images, it tends to focus on a large range of noisy regions instead of meaningful objects (the third column).

Ideally, if there is no domain gap between the source and target domains, the target-domain attention should perform like the source-domain attention to focus on meaningful regions in the image. Therefore, these phenomena indicate that the attention network performs poorly on target domains.

#### 2.2.2 Quantitative Verification of Target-Domain Attentions' Ineffectiveness

To verify this observation, we quantitatively measure (1) the attention value on the CLS token and (2) the sparsity of the attention on image tokens, on _all images from different datasets and blocks_. The attention value on the CLS token is measured as

\[V(A)=}}_{i,j,k}r(A_{i,j,k})_{},\] (4)

where \(A R^{b n_{h} n_{t} n_{t}}\) is the attention map, \(b\) is the batch size, \(n_{h}\) is the number of heads, \(n_{t}\) is the number of tokens and \(r()\) denotes the \(L_{2}\)-normalization, Similarly, The sparsity of the image

Figure 2: (a) Visualization of ViT attention. Although ViT behaves well on the source domain (_mini_ImageNet), on target domains ViT tends to (1) wrongly focus on the CLS token while omitting the input images, and (2) dispersively focus on a large range of noisy image regions. (b) We quantitatively plot (top) the attention value of the CLS token and (bottom) the density of attention maps on image tokens _for all images in each domain_. The black curve of _mini_ImageNet is always below other curves of target domains, verifying the ineffectiveness of target-domain attention. Therefore, we interpret the temperature adjustment as a remedy for the ineffective target-domain attention.

attention is measured by the averaged \(L_{2}\)-normalized \(L_{1}\) norm  of the attention map as

\[norm(A)=}}_{i,j,k}L_{1}(r(A_{i,j,k})_{ [1:]}).\] (5)

Results are plotted in Fig. 2b. As the smaller the \(L_{1}\) norm is, the sparser (i.e., less dense) the attention would be, in Fig. 2b (bottom), we use density as the Y-axis to align with the \(L_{1}\) norm value. We can see that curves of the source dataset (_mini_ImageNet) are always located under those of target datasets in Fig. 2b, indicating the model averagely pays more attention to the CLS token or noisy image regions on target datasets, quantitatively validating the ineffectiveness of target-domain attention.

Therefore, we interpret the temperature adjustment as a remedy for ineffective target-domain attention: If we apply a small temperature to the attention map, the attention map will be smoothed. For example, given the smallest temperature 0, the attention map will be downgraded to a uniform map. Such a smoothing operation would remedy the wrong attention on all tokens (i.e., CLS token and image tokens), because **uniform attention is at least better than wrong attention** (e.g., uniform attention allows the model to collect information from image tokens, but the wrong attention restricts the model to only collect information from the CLS token). These also interpret why the temperature remedy only improves on target datasets: the source dataset is effective in finding meaningful regions, indicating a good attention map that does not need to be remedied.

### Why do attention networks get ineffective on target domains?

Then, we take the attention network in the last ViT block for ablation, and study the performance (5-way 1-shot accuracy, Tab. 1) and domain similarity (Tab. 2) induced by these modules. The domain similarity is measured by the CKA similarity [17; 23], where we extract features from images of different domains, and measure the CKA similarity between the source and each target dataset by aligning the channel dimension. Large domain similarities indicate less domain information contained. Since a trade-off exists between discriminability and transferability [19; 27; 46], we utilize the source-domain (_mini_ImageNet) accuracy in Tab. 1 to measure the discriminability and use the average domain similarity in Tab. 2 to measure the transferability, and the average target-domain accuracy in Tab. 1 is the result caused by the trade-off.

In Tab. 1, 2, Input Tokens denote features input into the attention network (i.e., the output of the 11th ViT block), and SA (self-attention) denotes the output of the attention network (i.e., the input of the MLP network in the 12th ViT block), which is the default ViT self-attention module. By appending SA to Input Tokens, in Tab. 1, the source-domain accuracy increases. Accordingly, in Tab. 2, the CKA similarity significantly drops, indicating SA is more on the side of discriminability than transferability, which therefore makes target-domain accuracies decrease.

Then, we study the token relation modeled by the self-attention mechanism. We replace the default query-key relation with three simpler relations: the identity relation (tokens are not merged), the cosine relation (tokens are merged by the cosine similarity with softmax), and the average relation (tokens are merged uniformly, equivalent to the temperature set to 0). Firstly, we can see the identity SA shows low source and target accuracy but high domain similarity, indicating the merge of tokens

   Method & _mini_ImageNet & CropDiseases & EuroSAT & ISIC2018 & ChestX & Average \\  Input Tokens & 90.17 & 79.63 & 73.12 & 32.81 & 22.41 & 51.99 \\ Input Tokens + SA & 92.59 & 79.10 & 73.17 & 32.54 & 22.47 & 51.82 \\ Input Tokens + Identity SA & 87.45 & 77.97 & 69.89 & 32.15 & 22.52 & 50.63 \\ Input Tokens + Cosine SA & 88.80 & 79.98 & 74.35 & 32.65 & 22.57 & 52.39 \\ Input Tokens + Average SA & 89.53 & 80.73 & 74.59 & 32.04 & 22.64 & 52.50 \\   

Table 1: Ablation of the attention network from ViT’s last block.

   Method & _mini_ImageNet & CropDiseases & EuroSAT & ISIC2018 & ChestX & Average \\  Input Tokens & 1.0 & 0.4569 & 0.4381 & 0.3608 & 0.3900 & 0.4115 \\ Input Tokens + SA & 1.0 & 0.1853 & 0.1829 & 0.1344 & 0.1998 & 0.1756 \\ Input Tokens + Identity SA & 1.0 & 0.5857 & 0.5873 & 0.5376 & 0.4836 & 0.5486 \\ Input Tokens + Cosine SA & 1.0 & 0.2692 & 0.2252 & 0.1616 & 0.2295 & 0.2214 \\ Input Tokens + Average SA & 1.0 & 0.2235 & 0.2226 & 0.1580 & 0.2002 & 0.2011 \\   

Table 2: Domain similarity w.r.t. ablated attention modules.

is crucial for discriminability. Therefore, if target-domain attention majorly focuses on the CLS token (Fig. 2), the merge of image tokens would be abandoned, leading to downgraded performance.

By substituting the Identity SA with the Cosine and the Average SA, the performance improves on all datasets, which is lower on the source dataset but much higher on target datasets than the default SA. Also, the domain similarity is higher than the default SA but is lower than the Identity SA, indicating:

(1) The modeling of token relations contains domain information and discriminability itself, therefore it contributes to the source domain and reduces the domain similarity. The increase in target-domain accuracies indicates the gain of discriminability is larger than the loss of transferability.

(2) The default query-key relation contains the most domain information and discriminability, which increases the source-domain performance the most and decreases the domain similarity the most. Therefore, the query-key relation even harms the target-domain performance.

As a result, we can conclude that ineffective target-domain attention is majorly caused by the self-attention mechanism in the attention network. Given the trade-off between discriminability and transferability, the modeling of token relations is not entirely harmful for target-domain generalization. However, the query-key attention mechanism tends to be much less transferable, and some related works  have partly shown the tendency of overfitting in this mechanism, therefore it may harm the generalization to target domains and lead to ineffective target-domain attention.

### Handle the Ineffective Target-Domain Attention

Besides the query-key attention (SA) in Tab. 1 and 2, we can also find the rows of Input Tokens and Average SA demonstrate higher domain similarity and good target-domain performance, albeit the limited source-domain performance. This indicates these features, compared with the features of the query-key attention, tend to be on the transferability side in the trade-off between discriminability and transferability, since the query-key attention contains more learnable parameters.

To verify this hypothesis, we also visualize the activation map of the Input Tokens of Tab. 1 in Fig. 2(a). We observe (1) no exceeding activation on the CLS token, and (2) the activation maps can indeed reflect rough object contours in images from different domains, although not perfect.

Moreover, we measure the image token density and the CLS token value on these features. Similar to \(norm(A)\) and \(V(A)\), these two criteria are written as \(norm(M)=_{i}L_{1}(r(M_{i})_{[1:)})\) and \(V(M)=_{i}r(M_{i})_{}\), where \(M R^{b n_{t} c}\) is the MLP outputs and \(r(M)= M_{:,:,k}/\| M_{:,:,k}\| R^{b n_{ t}}\) is the \(L_{2}\)-normalized average activation of each token. The results are plotted in Fig. 2(b), and we can see the source and target datasets are **non-distinguishable** on these two criteria, indicating better transferability and adequate discriminability.

Figure 3: (a) We visualize the activation maps of Input Tokens in Tab. 1, and find that although the activation maps are not perfect, they show (1) no exceeding activations on the CLS token, and (2) rough object contours in input images. (b) We further find CLS token activation values as well as the map density on image tokens are non-distinguishable between source and target domains, indicating a better transferability of representations against large domain gaps. These indicate the Input Token in Tab. 1 tends to be more transferable than the query-key attention.

Therefore, we conclude that the query-key features tend to be discriminative but less transferable, while the non-query-key features tend to be transferable but less discriminative. This inspires us to encourage the learning of the non-query-key parameters in ViT (since their ability to be discriminative and overfitting is limited by parameters), and resist the learning of the query-key parts (as they are discriminative enough after the pretraining, so the source-domain training may not be needed).

### Conclusion and Discussion

The self-attention mechanism is the core design of ViT, where the query-key attention mechanism is capable of fitting large-scale training data. However, such characteristic also limits the transferability against large domain gaps, leaving the target-domain attention ineffective. Therefore, a remedy of the attention map by the temperature adjustment is needed, as a uniform attention map is at least better than a wrong attention map. Compared with the query-key attention, the non-query-key components in ViT tend to be more transferable but less discriminative than the query-key components, which inspires us to improve the generalization of ViT by encouraging the learning of non-query-key parts and resisting the learning of query-key ones during the source-domain training.

## 3 Method

Based on the above analysis, we further propose a simple but effective method to boost ViT's transferability, which can be divided into a source-domain stage and a target-domain stage.

### Source-Domain Attention Abandonment

Since the default query-key attention is verified to be vulnerable to domain gaps, we aim to enhance the non-query-key part of ViT in the source-domain training. We propose to stochastically abandon the query-key attention of all ViT blocks during the source-domain training, by multiplying a temperature of 0 (Fig. 4), so that the attention will be randomly downgraded to a uniform map. This is written as

\[A(x)=softmax(A^{}(x)^{S}(p)),\] (6)

where \(A^{}(x) R^{b n_{h} n_{t} n_{t}}\) denotes the un-normalized attention map in Eq. 1, \(^{S}(p)\{0,1\}\) is a scalar sampled from the binary distribution, and \(p\) (typically set to 0.8) is the probability of being 0.

This operation will resist the learning of the query-key attention parameters (i.e., Q and K in Fig. 4), as query-key attention will be applied in the forward pass with a probability of \(1-p\). This operation will also encourage the learning of the non-query-key attention parameters, as the average attention is applied with a probability of \(p\). Moreover, it will also resist the exceeding attention on the CLS token, as the CLS token's attention value in the uniform map would be \(1/n_{t}\) which is very small. Note that it is different from the Dropout  operation in (1) Dropout is carried out element-wisely in the attention map, but we directly shift the whole attention map to a uniform map; (2) Dropout is conducted after the softmax function, but ours is before it.

### Target-Domain Attention Adjustment

During the finetuning and evaluation of target datasets, the default query-key attention is still applied in the network, but we follow section 2 to set a pre-defined hyper-parameter \(^{T}\) for ViT blocks to

Figure 4: During the source-domain training, we propose to randomly abandon the attention network by multiplying a temperature of 0 to the attention in each block respectively, which resists the learning of the query-key attention parameters and enhances the non-query-key parts.

alleviate the influence of ineffective attention maps. This operation is written as

\[A(x)=softmax(A^{}(x)^{T}).\] (7)

Finally, we follow current works [12; 4] to conduct the prototype-based classification on the target-domain episodes as Eq. 3, or finetune our model on the support set of these episodes for the classifier-based classification.

## 4 Experiments

### Datasets

Following current works [2; 12], we utilize the _mini_ImageNet dataset  as the source dataset, and utilize 4 cross-domain datasets as the target datasets, including CropDiseases , EuroSAT , ISIC2018  and ChestX  for few-shot training and evaluation, using the \(k\)-way \(n\)-shot classification as stated in section 2.1. _mini_Imagenet  is a subset of the large-scale ImageNet  dataset with 100 categories and 60,000 images, where 64 categories are utilized for training. CropDiseases  is a dataset for agricultural disease recognition, consisting of 38 categories and 43,456 images. EuroSAT  is a satellite image dataset for land classification, comprising 10 classes and 27,000 images. ISIC2018  is for skin lesion recognition, comprising 7 categories with 10,015 images. ChestX  contains chest X-ray images, with 7 categories and 25,847 images.

### Implementation Details

We follow StyleAdv  to take ViT-S as the backbone network and take the DINO  pretraining on ImageNet as the initialization (other pretraining can be found in the appendix). During the source-domain training, we apply all ViT blocks to the Attention Abandonment. We use the Adam  optimizer with a learning rate of 0.001 for the classifier and 10\({}^{-6}\) for the backbone network. During the target-domain few-shot evaluation, we set the temperature for the first two blocks as 0.3, and set the attention of the CLS token to 0 for blocks whose ID is greater than 4.

### Comparison with State-of-the-Art Works

Tab. 3 and 4 report our results compared with state-of-the-art works for both 1-shot and 5-shot settings. We separately compare works with and without finetuning (FT) for fairness. The asterisk (*) denotes a transductive setting. PMF , StyleAdv , MEM-FS  and FLoR  are introduced for comparison. For all results, our work achieves the top average performance in all

   Method & backbone & FT & Mark & Crop. & Euro. & ISIC. & Ches. & Ave. \\  GNN+AFA  & ResNet10 & \(\) & ECCV-22 & 67.61 & 63.12 & 33.21 & 22.92 & 46.97 \\ LDP-net  & ResNet10 & \(\) & CVPR-23 & 69.64 & 65.11 & 33.97 & 23.01 & 47.18 \\ FLoR  & ResNet10 & \(\) & CVPR-24 & 73.64 & 62.90 & **38.11** & 23.11 & 49.69 \\ SDT  & ResNet10 & \(\) & NN-24 & 73.92 & 65.87 & 36.45 & **23.22** & 49.97 \\ MEM-FS  & ViT-S & \(\) & TIP-23 & 81.11 & 68.11 & 32.97 & 22.76 & 51.24 \\ StyleAdv  & ViT-S & \(\) & CVPR-23 & 81.22 & 72.15 & 33.05 & 22.92 & 52.34 \\ SDT  & ViT-S & \(\) & NN-24 & 81.03 & 72.71 & 33.40 & 22.79 & 52.48 \\ FLoR  & ViT-S & \(\) & CVPR-24 & 81.81 & 72.39 & 34.20 & 22.78 & 52.80 \\
**AttRemp** & ViT-S & \(\) & **Ours** & **84.02** & **74.35** & 34.92 & 23.19 & **54.12** \\  FLoR  & ResNet10 & ✓ & CVPR-24 & 84.04 & 69.13 & **38.81** & 23.12 & 53.78 \\ PMF  & ViT-S & ✓ & CVPR-22 & 80.79 & 70.74 & 30.36 & 21.73 & 50.91 \\ FLoR  & ViT-S & ✓ & CVPR-24 & 83.55 & 73.09 & 35.49 & 23.26 & 53.85 \\ StyleAdv  & ViT-S & ✓ & CVPR-23 & 84.11 & 74.93 & 33.99 & 22.92 & 53.99 \\
**AttRemp** & ViT-S & ✓ & **Ours** & **84.78** & **75.09** & 38.05 & **23.63** & **55.39** \\  LDP-net\({}^{*}\) & ResNet10 & ✓ & CVPR-23 & 81.24 & 73.25 & 33.44 & 22.21 & 52.54 \\ RDC\({}^{*}\) & ResNet10 & ✓ & CVPR-22 & 85.79 & 70.51 & 36.28 & 22.32 & 53.73 \\ FLoR\({}^{*}\) & ResNet10 & ✓ & CVPR-24 & 86.30 & 71.38 & **41.67** & 23.12 & 55.62 \\ MEM-FS+RDA\({}^{*}\) & ViT-S & ✓ & TIP-23 & 83.74 & 75.91 & 37.07 & 23.85 & 55.14 \\
**AttRemp\({}^{*}\)** & ViT-S & ✓ & **Ours** & **87.58** & **77.40** & 40.13 & **23.96** & **57.23** \\   

Table 3: Comparison with state-of-the-art works by the 5-way 1-shot classification.

settings and achieves the highest performance in almost all datasets. This demonstrates that our method effectively reduces the domain gap and enhances model transferability.

### Ablation Study

We first ablate the Attention Adjustment and Abandonment. In Tab. 5 we can see both modules contribute to the performance, especially for the Attention Abandonment module which yields a significant 2.47% average improvement. By adding the Adjustment module, the performance also increases but is smaller than that applied to the baseline model. This is because by applying Attention Abandonment, the attention is improved so that the remedy by temperature is not in great need.

Then, we ablate our designs and compare them with other attention-temperature-based works.

(1) **Learnable or stochastic temperature?** applied a small network to dynamically learn temperatures, which shows only trivial improvements, showing the importance of stochastic temperature.

(2) **Global or element-wise temperature?** Dropout  element-wisely abandons the attention after softmax and LSA  masks the diagonal attention map, which shows only marginal improvements on CDFSL, indicating the importance of a global temperature for each attention map.

(3) **Train attention or not?** Since abandoning the attention network can reduce its training and alleviate overfitting, we directly fix the attention network for verification and see only slight performance improvements, as the training of non-query-key parameters is limited by ineffective attention.

(4) **Maintain attention or not?** Due to the ineffectiveness of attention, we try to directly abandon all attention by setting a temperature of 0 for all blocks. We can see the performance is improved by

   Methods & backbone & FT & Mark & Crop. & Euro. & ISIC. & Ches. & Ave. \\  LDP-net  & ResNet10 & \(\) & CVPR-23 & 89.40 & 82.01 & 48.06 & 26.67 & 61.29 \\ GNN+AFA  & ResNet10 & \(\) & ECCV-22 & 88.06 & 85.58 & 46.01 & 25.02 & 61.67 \\ SDT  & ResNet10 & \(\) & NN-24 & 90.27 & 82.02 & 48.66 & 27.20 & 62.04 \\ FLoR  & ResNet10 & \(\) & CVPR-24 & 91.25 & 80.87 & 51.44 & 26.70 & 62.32 \\ MEM-FS  & ViT-S & \(\) & TIP-23 & 93.74 & 86.49 & 47.38 & 26.67 & 63.57 \\ StyleAdv  & ViT-S & \(\) & CVPR-23 & 94.85 & 88.57 & 47.73 & 26.97 & 64.53 \\ MICM  & ViT-S & \(\) & MM-24 & 94.61 & 90.08 & 46.85 & 27.11 & 64.66 \\ SDT  & ViT-S & \(\) & NN-24 & 95.00 & 89.60 & 47.64 & 26.72 & 64.75 \\ FLoR  & ViT-S & \(\) & CVPR-24 & 95.28 & **90.41** & 49.52 & 26.71 & 65.48 \\
**AttRemp** & ViT-S & \(\) & **Ours** & **95.53** & 90.13 & **53.09** & **27.72** & **66.62** \\  FLoR  & ResNet10 & ✓ & CVPR-24 & 92.33 & 83.06 & **56.74** & 26.77 & 64.73 \\ PMF  & ViT-S & ✓ & CVPR-22 & 92.96 & 85.98 & 50.12 & 27.27 & 64.08 \\ StyleAdv  & ViT-S & ✓ & CVPR-23 & 95.99 & 90.12 & 51.23 & 26.97 & 66.08 \\ FLoR  & ViT-S & ✓ & CVPR-24 & 96.47 & 90.75 & 53.06 & 27.02 & 66.83 \\
**AttRemp** & ViT-S & ✓ & **Ours** & **96.66** & **90.82** & 54.91 & **28.03** & **67.61** \\  LDP-net  & ResNet10 & ✓ & CVPR-23 & 91.89 & 84.05 & 48.44 & 26.88 & 62.82 \\ RDC  & ResNet10 & ✓ & CVPR-22 & 93.30 & 84.29 & 49.91 & 25.07 & 63.14 \\ FLoR  & ResNet10 & ✓ & CVPR-24 & 93.60 & 83.76 & **57.54** & 26.89 & 65.45 \\ MEM-FS+RDA\({}^{*}\) & ViT-S & ✓ & TIP-23 & 95.04 & 88.77 & 51.02 & 27.98 & 65.70 \\
**AttRemp\({}^{*}\)** & ViT-S & ✓ & **Ours** & **96.74** & **91.34** & 55.22 & **28.41** & **67.93** \\   

Table 4: Comparison with state-of-the-art works by the 5-way 5-shot classification.

   Adjustment & Abandonment & CropDisease & EuroSAT & ISIC2018 & ChestX & Ave. \\   & & 94.24\(\)0.27 & 88.62\(\)0.22 & 45.72\(\)0.33 & 25.66\(\)0.17 & 63.53\(\)0.13 \\ ✓ & & 94.48\(\)0.31 & 88.73\(\)0.25 & 49.12\(\)0.28 & 25.81\(\)0.21 & 64.53\(\)0.20 \\  & ✓ & 95.40\(\)0.33 & 89.08\(\)0.29 & 52.01\(\)0.31 & 27.49\(\)0.19 & 66.00\(\)0.19 \\ ✓ & ✓ & **95.53\(\)**0.22 & **90.13\(\)**0.33 & **53.09\(\)**0.18 & **27.72\(\)**0.19 & **66.62\(\)**0.19 \\   & Learnable Temp.  & 94.26\(\)0.08 & 88.91\(\)0.09 & 46.45\(\)0.11 & 26.44\(\)0.08 & 64.02\(\)0.07 \\  & Dropout  & 94.44\(\)0.17 & 89.62\(\)0.22 & 46.03\(\)0.16 & 26.34\(\)0.18 & 64.11\(\)0.17 \\ Masking Diagonal Atten.  & 94.83\(\)0.08 & 88.95\(\)0.09 & 46.98\(\)0.12 & 26.74\(\)0.09 & 64.38\(\)0.17 \\ Fix Attention & 94.67\(\)0.22 & 89.66\(\)0.20 & 46.22\(\)0.19 & 26.31\(\)0.20 & 64.08\(\)0.19 \\ Totally abandon attention & 95.07\(\)0.18 & 88.90\(\)0.23 & 49.23\(\)0.19 & 27.44\(\)0.14 & 65.16\(\)0.16 \\   

Table 5: Ablation study by the 5-way 5-shot accuracy.

more than 1%, indicating relying on the non-query-key outputs can indeed help the cross-domain transferring. However, the accuracy is still lower than Attention Abandonment, showing that the query-key attention network still contains useful information for classification.

### Verification of Improved Attention

#### 4.5.1 Qualitative Study

We visualize attention maps of our model on both the source and target domain in Fig. 4(a). In contrast to Fig. 1(a), where attention primarily focuses on the CLS token in the target domain, our model can correctly activate meaningful and discriminative tokens. Furthermore, compared to the dispersed attention observed in Fig. 1(a), our model focuses on more concentrated regions within the image, indicating that our model effectively transfers the attention network from the source to target domains.

#### 4.5.2 Quantitative Study

We compare the image token attention density and the CLS token attention value mentioned in Sec. 2.2. As depicted in Fig. 4(b), these criteria are mostly consistent between the source and target domain, in contrast to the disparities in Fig.1(b), suggesting improved transferability of attentions.

Moreover, in Tab. 6, we report the domain similarity and target-domain accuracy of the features output by the attention network from each ViT block. Following Tab. 2, we measure the domain similarity by the CKA similarity. From Tab. 6, we can see our model improves the domain similarity of each self-attention's output, indicating improved transferability of attention networks. Consistently, the target-domain accuracy is also improved by our method.

Finally, following Tab. 1, we compare the domain similarity and performance between the default query-key attention and other attention choices in Tab. 5(b). We can see the Input feature of the attention network's CKA is decreased, as we encourage the learning of non-query-key parameters in ViT. However, such a decrease in CKA is much smaller than the decrease brought by the query-key attention. In contrast, the CKA of the attention network's output consistently increases, indicating better transferability against domains. This can also be verified in Tab. 5(b) that the performance difference between different attention choices is narrowed.

   Metric. & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\  BL CKA & 0.9805 & 0.9500 & 0.9667 & 0.9654 & 0.9455 & 0.9146 & 0.8940 & 0.8406 & 0.7446 & 0.6337 & 0.2063 & 0.1756 \\ Ours CKA & 0.9857 & 0.9590 & 0.9659 & 0.9704 & 0.9547 & 0.9347 & 0.9148 & 0.8763 & 0.7903 & 0.6655 & 0.2955 & 0.1886 \\  BL Acc. & 34.67 & 39.88 & 42.19 & 44.73 & 47.20 & 48.93 & 50.05 & 50.98 & 52.60 & 53.02 & 52.03 & 51.82 \\ Ours Acc. & 34.91 & 40.47 & 43.01 & 45.19 & 47.28 & 48.93 & 50.40 & 51.47 & 53.26 & 54.34 & 53.98 & 53.70 \\   

Table 6: Verification of improved self-attention w.r.t. domain similarity and target-domain accuracy.

Figure 5: (a) Visualization of attention maps of our model. We can see images activated only on the CLS token in Fig. 1(a) are now correctly activated, and the model can focus on the meaningful and concentrated regions, verifying the improved attention networks. (b) By evaluating the image-token-attention density and the CLS-token-attention value of our model, we can see these criteria are non-distinguishable between the source and target domains (compared with Fig. 1(b)), indicating attention networks’ transferability against domain gaps is improved.

#### 4.5.3 Sensitivity Study of Hyper-parameters

We plot the average target-domain accuracy vs. abandonment probability \(p\) in Fig. 6c. When \(p=0\), it is downgraded to the baseline method. When \(p=1\), it means all attentions are abandoned. A high probability of abandoning can help the cross-domain transferring, but we cannot simply abandon all attention, indicating useful information in the attention network. Moreover, we ablate ViT blocks added to the Abandonment method in Fig. 6d. By gradually adding or removing abandoned blocks, the accuracy of the target domain increases or decreases accordingly. This indicates each block positively contributes to the model, highlighting the necessity of all blocks for Attention Abandonment.

## 5 Related Work

**Cross-Domain Few-Shot Learning** (CDFSL) aims to acquire knowledge from the target domain with limited training samples [2; 12]. The domain gaps between source and target domains make it challenging. Current works can be categorized into two groups: meta-learning based [2; 38; 43; 15], which simulates the data structure for the target-domain learning, and transferring-based [12; 32; 28; 25], involving training a model with strong generalization. However, they are mainly limited to the CNN structure, and while recent works [10; 42; 14; 45] have begun to utilize the transformer architecture for CDFSL tasks, they have not fully leveraged the potential of ViT architecture.

**Domain Generalization** (DG) aims to generalize models from seen to unseen domains [41; 24], aligning with the objective of CDFSL. Recently, transformer-based approaches have been studied [48; 21; 31; 35].  discovered that self-attention is not indispensable.  discovered that self-attention is not adept at distinguishing the transferability and discriminability of features across different domains. Different from them, we explore the influence of temperature on attention transferability against large domain gaps, without introducing any additional modules.

**Attention Temperature** can adjust the smoothness of the Softmax output distribution in the attention network.  proposes using a constant temperature to scale the dot product to alleviate a small extreme gradient. Recently, some methods have emerged to dynamically adjust the temperature while training deep learning models [26; 20; 3].  proposes to apply a learnable temperature to attention scores to address overly smooth distributions.  reduces attention noise by suppressing accumulated trivial attention weights. In contrast, our study is the first, to our knowledge, to delve into the impact of attention temperature on cross-domain transferability.

## 6 Conclusion

In this paper, we find a phenomenon for the temperature-based attention adjustment in the ViT-based CDFSL task and delve into it for an interpretation. We interpret it as a remedy for the ineffective target-domain attention caused by the default query-key attention mechanism. Based on it, we further propose a method for CDFSL. Experiments validate our rationale and effectiveness.