# Causal Effect Identification

in Uncertain Causal Networks

 Sina Akbari

EPFL, Switzerland

sina.akbari@epfl.ch

&Fateme Jamshidi

EPFL, Switzerland

fateme.jamshidi@epfl.ch

&Ehsan Mokhtarian

EPFL, Switzerland

ehsan.mokhtarian@epfl.ch

&Matthew J. Vowels

University of Lausanne, Switzerland

matthew.vowels@unil.ch

&Jalal Etesami

TUM, Germany

j.etesami@tum.de

&Negar Kiyavash

EPFL, Switzerland

negar.kiyavash@epfl.ch

###### Abstract

Causal identification is at the core of the causal inference literature, where complete algorithms have been proposed to identify causal queries of interest. The validity of these algorithms hinges on the restrictive assumption of having access to a correctly specified causal structure. In this work, we study the setting where a probabilistic model of the causal structure is available. Specifically, the edges in a causal graph exist with uncertainties which may, for example, represent degree of belief from domain experts. Alternatively, the uncertainty about an edge may reflect the confidence of a particular statistical test. The question that naturally arises in this setting is: Given such a probabilistic graph and a specific causal effect of interest, what is the subgraph which has the highest plausibility and for which the causal effect is identifiable? We show that answering this question reduces to solving an NP-complete combinatorial optimization problem which we call the edge ID problem. We propose efficient algorithms to approximate this problem and evaluate them against both real-world networks and randomly generated graphs.

## 1 Introduction

A large proportion of questions of interest in various fields, including but not limited to psychology, social sciences, behavioral sciences, medical research, epidemiology, economy, etc., are causal in nature . In order to estimate causal effects, the gold standard is performing controlled interventions and experiments. Unfortunately, such experiments can be prohibitively expensive, unethical, or impractical . In contrast, non-experimental data are comparatively abundant, and no expensive interventions are required to generate such data. This has motivated the development of numerous techniques for understanding whether a causal query can be answered using observational data. Specifically, if a particular causal query is _identifiable_, it means it can be expressed as a function of the observational distribution and thus estimated from observational data (at least in principle).

A significant body of the causal inference literature is dedicated to the identification problem . In particular,  presented a complete algorithmic approach to decide the identifiability of a specific query and proved that Pearl's do calculus is complete. Furthermore,  provided graphical criteria to decide the identifiability based on the _hedge_ criterion. The problem of identifiability was later generalized to deal with interventional data , selection bias , context-specific independence relations  and causal bandits . However, all of these results hinge on the full specification of the causal structure, i.e., access to a correctly specified Acyclic Directed Mixed Graph (ADMG) that models the causal dynamics of the system. This requirement is restrictive in a number of ways. (i) The causal identification problem is concerned with inference from theobservational data, but the ADMG cannot be inferred from the observational distribution alone. (ii) Structure learning methods rely heavily on statistical tests , which are prone to errors arising from lack of sufficient data and method-specific limitations . This can in turn result in misspecification of the causal structure.

A notable work to address the second challenge is , where the authors proposed a causal discovery method that assigns a probability to the existence of each edge, as opposed to making "hard" decisions based on a single or limited number of tests. This is achieved by updating the posterior probability of a direct link between two variables, denoted as \(X\) and \(Y\), using conditional dependence tests that incorporate independent evidence. The authors demonstrate that the posterior probability denoted as \(p_{i}\), of a link between \(X\) and \(Y\) after performing \(i\) dependence tests (\(d_{j}\), where \(j\) ranges from \(1\) to \(i\)) is given by the following equation:

\[p_{i}=d_{i}}{p_{i-1}d_{i}+(1-p_{i-1})(G+1-d_{i})},\]

where \(G\) represents a factor ranging from \(0\) to \(1\), and it can be interpreted as the measure of "importance" or relevance associated with the truthfulness of each test, denoted as \(d_{i}\). Other closely linked work include  and , where an optimal transport (OT)-based causal discovery approach is proposed that assigns a score to each edge of the graph denoting the strength of that edge.

While previous research, such as , has focused on probabilistic learning of causal graphs, the problem of causal effect identification on these graphs remains unexplored. This paper introduces a novel approach to address causal effect identification in a scenario where only a probabilistic model of the causal structure is available, as opposed to a complete specification of the structure itself. For instance, an ADMG \(\) is given along with probabilities assigned to each edge of \(\). An example is shown in Figure 0(a). These probabilities could represent uncertainties arising from statistical tests or the strength of belief of domain experts concerning the plausibility of the existence of an edge. Under this setting, each ADMG on the set of vertices of \(\) is assigned its own plausibility score. Since the causal structure is not deterministic anymore, answering questions such as "_is the causal effect \(P(Y|do(X))\) identifiable?_" also becomes probabilistic in nature. One can compare the overall plausibility of different subgraphs in which the causal effect is identifiable and then select the graph which maximizes the plausibility. In this work, for a specific causal query \(P(Y|do(X))\), we first answer the question, "Which graph has the highest plausibility among those compliant with the probabilistic ADMG model that renders \(P(Y|do(X))\) identifiable?" The answer to this question allows us to quantify how confident we are about the causal identification task given the combination of the data at hand and the corresponding probabilistic model.

As the causal identification task is carried out through an identification formula that is based on the causal structure, our second focus is on deriving an identification formula for a given causal query that holds with the highest probability. This problem poses a greater challenge compared to the former, as a single identification formula can be valid for various graphs. Consequently, the probability that a particular identification formula is valid for a causal query becomes an aggregate probability across all graphs where this formula holds. We shall illustrate this point in more detail through Example 1 in Section 2. The intricacy of characterizing all valid graphs for a given formula makes it an intractable and open problem. To surmount this obstacle, we establish that if an identification formula is valid for a causal graph, it remains valid for all edge-induced subgraphs of that graph. This allows us to form a surrogate problem (see Problem 2 in Section 2.1) that recovers a causal graph with the highest aggregated probability of its subgraphs. The probability of the resulting graph provides a lower bound on the highest probable identification formula.

Both problems discussed in this work are aimed at evaluating the plausibility of performing causal identification for a specific query given a dataset and a non-deterministic model describing the causal structure. To sum up, our main contributions are as follows.

1. We study the problem of causal identifiability in probabilistic causal models, where there are uncertainties about the existence of edges and whether a given causal effect is identifiable. More precisely, we consider two problems: 1) finding the most probable graph that renders a desired causal query identifiable, and 2) finding the graph with the highest aggregate probability over its edge-induced subgraphs that renders a desired causal query identifiable.

2. We show that both aforementioned problems reduce to a special combinatorial optimization problem which we call the _edge ID problem_. Moreover, we prove that the edge ID problem is NP-complete, and thus, so are both of the problems.
3. We propose several exact and heuristic algorithms for the aforementioned problems and evaluate their performances through different experiments.

## 2 Preliminaries

We utilize small letters for variables and capital letters for sets of variables. Calligraphic letters are used to denote graphs. An acyclic directed mixed graph (ADMG) \(=(V^{},E_{d}^{},E_{b}^{})\) is defined as an acyclic graph on the vertices \(V^{}\), where \(E_{d}^{} V^{} V^{}\) and \(E_{b}^{}}}{2}\) are the set of directed and bidirected edges among the vertices, respectively. With slight abuse of notation, if \(e E_{d}^{} E_{b}^{}\), we write \(e\). We use \(^{}\) when \(^{}\) is an edge-induced subgraph of \(\), i.e., \(^{}=(V^{^{}},E_{d}^{^{}},E _{b}^{^{}})\), where \(V^{^{}}=V^{}\) and \(E_{i}^{^{}} E_{i}^{}\) for \(i\{b,d\}\). We denote by \([X]\) the vertex-induced subgraph of \(\) over the subset of vertices \(X V^{}\). For a set of vertices \(X\), we denote by \(_{}(X)\) the set of vertices in \(\) that have a directed path to \(X\). Note that \(X_{}(X)\). Let \(P_{X}(Y)\) be a shorthand for \(P(Y|do(X))\), and \(P^{M}()\) denote the distribution of variables described by the causal model \(M\).

**Definition 2.1** (Identifiability ).: Given a causal ADMG \(=(V^{},E_{d}^{},E_{b}^{})\), and two disjoint subsets of variables \(X,Y V^{}\), the causal effect of \(X\) on \(Y\), denoted by \(P_{X}(Y)\), is identifiable in \(\) if \(P_{X}^{M_{1}}(Y)=P_{X}^{M_{2}}(Y)\) for any two models \(M_{1}\) and \(M_{2}\) that induce \(\) and \(P^{M_{1}}(V^{})=P^{M_{2}}(V^{})>0\).

**Definition 2.2** (Valid identification formula).: For a causal ADMG \(\) over variables \(V^{}\) and a causal query \(P_{X}(Y)\), we say a functional \(\) defined on the probability space over \(V^{}\) is a valid identification formula for \(P_{X}(Y)\) in \(\) if \(P_{X}^{M_{1}}(Y)=P_{X}^{M_{2}}(Y)=(P^{M_{1}}(V^{}))= (P^{M_{2}}(V^{}))\) for any two models \(M_{1}\) and \(M_{2}\) that induce \(\) and \(P^{M_{1}}(V^{})=P^{M_{2}}(V^{})>0\).

For any query \(P_{X}(Y)\), let \([]_{Id(P_{X}(Y))}\) denote the set of subgraphs of \(\) in which \(P_{X}(Y)\) is identifiable (note that if \(\) is complete graph, \([]_{Id(P_{X}(Y))}\) is the set of all graphs in which \(P_{X}(Y)\) is identifiable.) We denote by \(Q[Y]\) the causal effect of \(V Y\) on \(Y\), i.e., \(Q[Y]\!=\!P(Y|do(V Y))\).

**Definition 2.3** (District).: For ADMG \(=(V^{},E_{d}^{},E_{b}^{})\), let \(_{}\) denote the edge-induced subgraph of \(\) over its bidirected edges. \(X V^{}\) is a district (aka c-component) in \(\) if \(_{}[X]\) is connected.

**Definition 2.4** (Hedge ).: Let \(\) be an ADMG, and \(Y X\) be two subsets of its vertices, where \(Y\) is a district in \([Y]\). Vertices \(X\) form a hedge for \(Q[Y]\) if \(X\) is a district in \([X]\) and \(_{[X]}(Y)=X\)1.

**Definition 2.5** (Maximal hedge ).: For ADMG \(\) with set vertices \(Y\), let \(X\) be the union of all hedges formed for \(Q[Y]\). Graph \([X]\), denoted by \((,Y)\), is called the maximal hedge for \(Q[Y]\).

As an example, both sets \(\{t,x\}\) and \(\{z,x\}\) form a hedge for \(Q[x]\) in \(\) in Figure 0(a), and \([\{x,z,t\}]\) is the maximal hedge for \(Q[x]\).

### Problem setup

Let \(=(V^{},E_{d}^{},E_{b}^{})\) be an ADMG, where \(V^{}\) is the set of vertices each representing an observed variable of the system, \(E_{d}^{}\) is the set of directed edges, and \(E_{b}^{}\) is the set of bidirected edges among \(V^{}\). We know _a priori_ that the true ADMG describing the system is an edge-induced subgraph of \(^{2}\), and we are given a probability map that indicates for each subgraph of \(\) such as \(_{s}\), with what probability \(_{s}\) is the true causal ADMG of the system. We denote this probability as \(P(_{s})\). For instance, if edge probabilities \(p_{e}\) are assumed to be mutually independent, \(P(_{s})\) takes the form:

\[P(_{s})=_{e_{s}}p_{e}_{e_ {s}}(1-p_{e}).\] (1)

In what follows, we will refer to \(P(_{s})\) simply as the probability of the ADMG \(_{s}\). The first problem of our interest is formally defined as follows.

**Problem 1**.: _We consider the problem of finding the most probable edge-induced subgraph of \(\), in which the causal effect \(Q[Y]\)3 is identifiable. That is, the goal is to find the ADMG \(^{*}\) defined by_

\[^{*}:=*{arg\,max}_{_{s},_{s}[]_{td(Q[Y])}}P(_{s}).\] (2)

We will prove in Lemma 3 that if \(Q[Y]\) is identifiable in \(\), then it is also identifiable in every edge-induced subgraph of \(\). In other words, if \(\) is a feasible solution to the above optimization problem, so are all its edge-induced subgraphs. Furthermore, the same identification functional that is valid w.r.t. \(\), is also valid w.r.t. every subgraph of \(\). Let us illustrate this first on an example.

**Example 1**.: _Consider the ADMG in Figure 0(a). With the given edge probabilities and assuming independence among the edge probabilities, the subgraph of \(\) illustrated in Figure 0(b) has probability \(0.7 0.7 0.1=0.049,\) whereas the subgraph of Figure 0(c) has probability \(0.3 0.3 0.9=0.081\) (see Eq. (1)). If we were to solve Problem 1, we would choose \(_{2}\) over \(_{1}\), as it has a higher probability. Now consider identification formulas in \(_{1}\) and \(_{2}\), respectively:_

\[_{1}:Q[Y]=P(Y|X),_{2}:Q[Y]=_{Z,T}P(Y|X,Z,T)P(Z, T).\]

\(_{1}\) _is a valid identification formula for any edge-induced subgraph of \(_{1}\) (see Lemma 3). Analogously, \(_{2}\) is valid for all edge-induced subgraphs of \(_{2}\). If we consider the aggregate probability of the subgraphs of \(_{1}\) and \(_{2}\), i.e.,_

\[_{_{1}}P(})=1-0.9=0.1, _{_{2}}P(} )=(1-0.7)(1-0.7)=0.09,\]

_then we should prefer choosing \(_{1}\) over \(_{2}\), as its identification formula \(_{1}\) is more likely to be valid than \(_{2}\) considering the fact that for all its subgraphs, the identification functional \(_{1}\) is still valid._

_Plausibility_ of a certain identification functional \(\) is the sum of the probabilities of all graphs in which \(\) is valid given the query of interest. Finding the most plausible identification formula for a given query requires computing the plausibility of all formulae. Since the space of all formulae is intractable, alternatively, we can enumerate all valid formulae for a given graph which changes the problem's search space to the space of all graphs. However, this is yet another challenging and, to the best of our knowledge, an open problem. Instead, we proposed a surrogate problem that yields a lower bound for the most plausible identification formula and identifies a causal graph where this formula is valid. To do so, we use the result of Lemma 3 that shows when an identification functional is valid in a causal graph, it is also valid in all its edge-induced subgraphs.

**Problem 2**.: _Consider the problem of finding the edge-induced subgraph \(^{*}\) of \(\) with a maximum aggregate probability of its subgraphs, in which \(Q[Y]\) is identifiable. Formally,_

\[^{*}:=*{arg\,max}_{_{s},_{s}[]_{td(Q[Y])}}_{_{s}}P(}).\] (3)In other words, we are looking for a causal graph \(^{*}\) with the maximum aggregate probability of its subgraphs among the graphs in \([]_{Id(Q[Y])}\), i.e., the graphs in which \(Q[Y]\) is identifiable. Running an identification algorithm on \(^{*}\) yields an identification formula for \(Q[Y]\), which is valid at least with the aggregate probability of the subgraphs of \(^{*}\). Therefore, Problem 2 is a surrogate for recovering the identification formula with the highest plausibility. In the sequel, for simplicity, we study Problems 1 and 2 under the following assumption. However, as proved in Appendix C, our results are valid in a more general setting where we allow only for perfect negative or positive correlations among the edges. An example of a perfect negative correlation between two edges is that both cannot exist simultaneously. Appendix C.1 discusses the significance of this generalization.

**Assumption 2.1**.: The edges of \(\) are mutually independent, i.e., the probability of a subgraph \(_{s}\) of \(\) is of the form (1).

**Remark 2.1**.: It is noteworthy that our results are not limited to causal queries of the form \(Q[Y]=P(Y|do(V^{} Y))\). They can be applied to general causal queries of the form \(P_{X}(Y)\) if the set \(_{ X}(Y)\) is known. This is because the causal query \(P_{X}(Y)\) can be expressed as \(_{_{ X}(Y) Y}Q[_{  X}(Y)]\), where \(_{ X}(Y)\) is the set of ancestors of \(Y\) in \(\) after removing the vertices of \(X\). Furthermore, \(P_{X}(Y)\) is identifiable in \(\) if and only if \(Q[_{ X}(Y)]\) is identifiable in \(\)[30; 26; 14]. Note that the assumption that \(_{ X}(Y)\) is known is not equivalent to precluding uncertainty on the directed edges (as in the case of fixing the edge probabilities to 0 or 1), but it rather imposes a perfect correlation type of constraint. Consider for instance the three graphs of Figure 2, where all of them share the same set \(_{ X}(Y)=\{z,t\}\). In fact, knowing this set forces a constraint of the type that if the edge \(z y\) does not exist, the path \(z t y\) must.

## 3 Reduction to edge ID problem and establishing complexity

We begin this section with the following lemma, to which we referred before. Thereafter, we discuss the hardness of the two problems considered in this work. For any causal query \(P_{X}(Y)\) and ADMG \(\), if \(\) is a valid identification formula for \(P_{X}(Y)\) in \(\) (Def. 2.2), then \(\) is a valid identification formula for \(P_{X}(Y)\) in any \(^{}\). All proofs are presented in Appendix A. In what follows, we first formally define the edge ID problem and then show the equivalence of Problems 1 and 2 to the edge ID problem under Assumption 2.1.

**Definition 3.1** (Edge ID problem).: For ADMG \(=(V^{},E^{}_{d},E^{}_{b})\), a set of non-negative edge weights \(W_{}=\{w_{e} 0|e\}\), and a causal query \(Q[Y]\) for \(Y V^{}\), the objective of the edge ID problem is to find the set of edges \(E^{*} E^{}_{d} E^{}_{b}\) with minimum aggregated weight (cost), such that \(Q[Y]\) is identifiable in the graph resulting from removing \(E^{*}\) from \(\). Formally,

\[E^{*}:=}_{d} E^{}_{b}}{ }_{e E}w_{e},^{}=(V^{ },E^{}_{d} E,E^{}_{b} E) []_{Id(Q[Y])}.\] (4)

That is, the cost of removing a set of edges from \(\) is the sum of the weights of each individual edge.

The following result unifies the two problems considered in this work by establishing their equivalence to the edge ID problem. This is done by transforming Problems 1 and 2 with multiplicative objectives into the edge ID problem that has an additive objective.

**Lemma 3.2**.: _Under Assumption 2.1, Problem 1 is equivalent to the edge ID problem with the edge weights chosen to be the log propensity ratios, i.e., \(w_{e}=\{0,(}{1-p_{e}})\}\), \( e\). Moreover, Problem 2 is equivalent to the edge ID problem with the choice of weights \(w_{e}=-(1-p_{e})\), \( e\). That is, an instance of Problems 1 and 2 can be reduced to an instance of the edge ID problem in polynomial time, and vice versa._

As we mentioned earlier, the equivalence of these three problems can be established in more general settings than what is described under Assumption 2.1. We refer the interested reader to Appendix C for a discussion on one such setting. The following result shows no polynomial-time algorithm for solving these three problems exists unless \(=\).

**Theorem 3.3**.: _The edge ID problem is NP-complete._

Theorem 3.3 is established through a reduction from another NP-complete problem, namely the _minimum-cost intervention problem_ (MCIP) [2; 3], which we shall discuss in Section 4.3. Theorem3.3 is a key result which shows the hardness of recovering the most plausible graph in which a specified causal effect of interest is identifiable.

**Corollary 3.4**.: _Problems 1 and 2 are NP-complete under Assumption 2.1._

It is noteworthy that the size of the problem depends on the number of vertices of \(\), i.e., \(|V^{}|\), and the number of edges of \(\) with finite weight, i.e., \(|E^{}|=|E^{}_{d}|+|E^{}_{b}|\). Since the ID algorithm (function ID of ) runs in time \((|V^{}|^{2})\), the brute-force algorithm that tests the identifiability of \(Q[Y]\) in every edge-induced subgraph of \(\) and chooses the one with the minimum weight of deleted edges runs in time \((2^{|E^{}|}|V^{}|^{2})\). In the next Section, we present various algorithmic approaches for solving or approximating the solutions to these problems.

## 4 Algorithmic approaches

We first present a recursive approach for solving the edge ID problem in Section 4.1, described in Algorithm 1. Since the problem itself is NP-complete, Algorithm 1 runs in exponential time in the worst case. In Section 4.2, we present heuristic approximations of the edge ID problem, which runs in cubic time in the worst case. These heuristics can also be used as a pre-process to reduce the runtime of Alg. 1 by providing an upper bound that can be fed into Alg. 1 to prune the search space. Finally, in Section 4.3, we present a reduction of edge ID to yet another NP-complete problem, namely minimum-cost intervention problem , which allows us to use the algorithms designed for that problem to solve edge ID. Our simulations in Section 5 evaluate these approaches against each other.

### Recursive exact algorithm

This approach is described in Algorithm 1. The inputs to the algorithm are an ADMG \(\) along with edge weights \(W_{}\), a set of vertices \(Y\) corresponding to the causal query \(Q[Y]\), an upper bound \(^{ub}\) on the aggregate weight (cost) of the optimal solution, and a threshold \(^{th}\), an upper bound on the acceptable cost of a solution. The closer \(^{ub}\) is to the optimal cost, the quicker Algorithm 1 will find the solution. If no upper bound is known, the algorithm can be initiated with \(^{ub}=\). However, we shall discuss a few approaches to find a good upper bound \(^{ub}\) in the following Section. Note that when \(^{th}=0\), Algorithm 1 will output the optimal solution. Otherwise, as soon as a feasible solution with weight less than \(^{th}\) is found, the algorithm terminates (line 13).

The algorithm begins with calling subroutine **MH** in line 2, which constructs the maximal hedge for \(Q[Y]\), denoted by \(\). We discuss this subroutine in detail in Appendix B. Throughout the rest of the algorithm, we only consider the edges in \(\), as the other edges do not alter the identifiability. If there is no hedge formed for \(Q[Y]\), i.e., \(=[Y]\), there is no need to remove any edges from \(\) and the effect is already identified. Otherwise, we remove the edge with the lowest weight (\(e\)) from \(\) and recursively call the algorithm to find the solution after removing the edge \(e\), unless the weight of \(e\) is already higher than the upper bound \(^{ub}\), which means no feasible solutions exist for the provided upper bound. Whenever a feasible solution is found, the upper bound \(^{ub}\) is updated to the lowest weight among all the solutions weights discovered so far. This, in turn, helps the algorithm prune the exponential search space during the next iterations to reduce the runtime. As soon as a solution with a weight less than the acceptable threshold, i.e., \(^{th}\), is found, the algorithm returns the solution. Otherwise, \(w_{e}\) is updated to infinity so that it never gets removed (line 14). This is due to the fact that we have already explored all the solutions involving \(e\).

Figure 2: Three different graphs that share the same set \(Anc_{}(\{y\})=\{z,t\}\).

### Heuristic algorithms

In this section, we present two heuristic algorithms for approximating the solution to the edge ID problem. These algorithms can also be used to efficiently find the upper bound \(^{ub}\), which could be fed as an input to Algorithm 1.

```
1:functionHEID(\(,Y,W_{}\))
2:\(^{}(,Y)\),
3:\(Z\{z V^{^{}}|zy Y:\{z,y\} E_{b}^{ ^{}}\} Y\),
4:\(\) induced subgraph of \(^{}\) on its directed edges.
5:\(W_{}\{w_{e} W_{}|e\}\), \(V^{} V^{}\{y^{*},z^{*}\}\)
6:for\(z Z\)do\(E^{} E^{}(z^{*},z)\), \(W_{} W_{}\{w_{(z^{*},z)}=_{y}w_{\{z,y\}}\}\)
7:for\(y Y\)do\(E^{} E^{}(y,y^{*})\), \(W_{} W_{}\{w_{(y,y^{*})}=\}\)
8:\(E MinCut(,W_{},z^{*},y^{*})\)
9:return\((E,_{e E}w_{e})\) ```

**Algorithm 2** Heuristic algorithm for edge ID.

Let \(Z=\{z V^{}|\;\;y Y:\{z,y\} E_{b}^{}\}  Y\) denote the set of vertices that have at least one common bidirected edge with a vertex in \(Y\). Any hedge formed for \(Q[Y]\) contains at least one vertex of \(Z\). As a result, to eliminate all the hedges formed for \(Q[Y]\), it suffices to ensure that none of the vertices in \(Z\) appear in such a hedge. To this end, for any \(z Z\), it suffices to either remove all the bidirected edges between \(z\) and \(Y\) or eliminate all the directed paths from \(z\) to \(Y\). The problem of eliminating all directed paths from \(Z\) to \(Y\) can be cast as a minimum cut problem between \(Z\) and \(Y\) in the edge-induced subgraph of \(\) over its directed edges. To add the possibility of removing the bidirected edges between \(Z\) and \(Y\), we add an auxiliary vertex \(z^{*}\) to the graph and draw a directed edge from \(z^{*}\) to every \(z Z\) with weight \(w=_{y Y}w_{\{z,y\}}\), i.e., the sum of the weights of all bidirected edges between \(z\) and \(Y\). Note that \(z\) can have bidirected edges to multiple vertices in \(Y\). We then solve the minimum cut problem for \(z^{*}\) and \(Y\). If an edge between \(z^{*}\) and \(z Z\) is included in the solution to this minimum cut problem, it is mapped to remove all the bidirected edges between \(z\) and \(Y\) in the main problem. Note that we can run the algorithm on the maximal hedge formed for \(Q[Y]\) in \(\) rather than \(\) itself. This heuristic is presented as Algorithm 2.

```
1:functionHEID(\(,Y,W_{}\))
2:\(^{}(,Y)\),
3:\(Z\{z V^{^{}}|zy Y:\{z,y\} E_{b}^{ ^{}}\} Y\),
4:\(\) induced subgraph of \(^{}\) on its directed edges.
5:\(W_{}\{w_{e} W_{}|e\}\), \(V^{}\{y^{*},z^{*}\}\)
6:for\(z Z\)do\(E^{} E^{}(z^{*},z)\), \(W_{} W_{}\{w_{(z^{*},z)}=_{y}w_{\{z,y\}}\}\)
7:for\(y Y\)do\(E^{} E^{}(y,y^{*})\), \(W_{} W_{}\{w_{(y,y^{*})}=\}\)
8:\(E MinCut(,W_{},z^{*},y^{*})\)
9:return\((E,_{e E}w_{e})\) ```

**Algorithm 3** Heuristic algorithm for edge ID.

An analogous approach which goes through solving an undirected minimum cut on the edge-induced subgraph of \(\) over its bidirected edges is presented in Algorithm 4 in Appendix D. As mentioned earlier, these algorithms can be used either as standalone algorithms to approximate the solution to the edge ID problem, or as a pre-processing step to find an upper bound \(^{ub}\) for Algorithm 1.

Complexity and performance.The aforementioned heuristic algorithms can be broken down into two primary components: constructing an instance of the minimum-cut problem, and solving the latter. Both algorithms follow similar steps for constructing the minimum-cut problem. For reference,Alg. 2 starts with identifying the maximal hedge formed for \(Q[Y]\), which is cubic-time in the worst case , followed by forming a directed graph \(\) over the vertices of the maximal hedge. Forming this graph, which inherits its vertices and directed edges from \(\), is linear in time. Lastly, there exist several minimum-cut-maximum-flow algorithms that exhibit cubic-time performance. Therefore, our heuristic algorithms have a cubic runtime in the worst case. On the other hand, given the hardness result we provided in the previous section, and in light of the fact that there is a polynomial-time reduction from the minimum hitting set problem to MCIP , the edge ID problem is NP-hard to approximate within a factor better than logarithmic . Since our heuristic algorithms run in polynomial time, they are expected to be suboptimal by at least a logarithmic factor in the worst case. However, as we shall see in our simulations, both algorithms achieve near-optimal results on random graphs.

### Alternative approach: reduction to MCIP

As an alternative approach to the algorithms discussed so far, we present a reduction of the edge ID problem to another NP-complete problem, i.e., the minimum-cost intervention problem (_MCIP_) introduced in . This reduction allows us to exploit algorithms designed for MCIP to solve our problems. The formal definition of MCIP is as follows.

**Definition 4.1** (Mcip).: Suppose \(=(V^{},E_{d}^{},E_{b}^{})\) is an ADMG, \(C:V^{}^{ 0}\) is a cost function mapping each vertex of \(\) to a non-negative cost, and \(Y V^{}\). The objective of the minimum-cost intervention problem for identifying the causal effect \(Q[Y]\) is to find the subset \(A V^{}\) with the minimum aggregate cost such that \(Q[Y]\) is identifiable after intervening on the set \(A\).

The reduction from edge ID to MCIP is based on a transformation from ADMG \(\) to another ADMG \(\), where each edge in \(\) is represented by a vertex in \(\). This transformation is based on the causal query \(Q[Y]\), and it maps the identifiability of \(Q[Y]\) in \(\) to the identifiability of \(Q[Y^{mcip}]\) in \(\), where \(Y^{mcip}\) is a set of vertices in \(\). This transformation satisfies the following property; removing a set of edges \(E^{*}\) in \(\) makes \(Q[Y]\) identifiable if and only if intervening on the corresponding vertices of \(E^{*}\) in \(\) makes \(Q[Y^{mcip}]\) identifiable. More precisely, after this transformation, solving the edge ID problem for \(Q[Y]\) in \(\) is equivalent to solving MCIP for \(Q[Y^{mcip}]\) in \(\). The complete details of this transformation can be found in Appendix A.2. An example of this reduction is shown in Figure 3, where \(Q[\{y_{1},y_{2}\}]\) in \(\) (Figure 2(a)) is mapped to \(Q[\{y_{1},y_{2},y_{2}^{12}\}]\) in \(\) (Figure 2(b)), where \(\{y_{1},y_{2},y_{2}^{12}\}\) is a district, and the set of all vertices of \(\) forms a hedge for it. The vertices of \(\) corresponding to each edge in \(\) are indicated with the same color and have the same weight (cost). We assign infinity cost to them to avoid intervening on the remaining vertices in \(\). It is straightforward to see that the solution to the edge ID problem in \(\) with the query \(Q[Y=\{y_{1},y_{2}\}]\) would be to remove the edge with the lowest weight. This is because after removing any edge in \(\), no hedge remains for \(Q[Y]\). Similarly, in \(\), the solution to MCIP with the query \(Q[Y^{mcip}=\{y_{1},y_{2},y_{2}^{12}\}]\) is to intervene on the vertex with the lowest cost among \(Z=\{z_{11}^{d},x_{21}^{d},x_{12}^{b},y_{12}^{b},z_{22}^{b}\}\). This is because after intervening on any vertex in \(Z\), no hedge remains for \(Q[Y^{mcip}]\). The following result establishes the link between the edge ID problem in \(\) and MCIP in \(\).

Figure 3: Reduction from edge ID to MCIP.

**Proposition 4.2**.: _There exists a polynomial-time reduction from edge ID to MCIP and vice versa._

In particular, the time complexity of the transformation from edge ID to MCIP scales linearly in size of \(\), and is cubic in \(|Y|\). More precisely, the time complexity is \((|V^{}|+|E_{d}^{}|+|E_{b}^{}|+|Y|^{ 3})\). For further details, refer to the construction in Appendix A.2.

## 5 Experiments

We evaluate the proposed heuristic algorithms 2 (HEID-1) and 4 (HEID-2), as well as the exact algorithm 1 (EDGEID), where the upper-bound \(^{ub}\) for EDGEID is set to be the minimum cost found by HEID-1 or -2. Furthermore, given the reduction of the edge ID problem to the MCIP problem described in Section 4.3, we also evaluate the two approximation and one exact algorithms from  (MCIP-H1, MCIP-H2, and MCIP-exact, respectively). Experimental results are provided for Problem 1, and analogous results for Problem 1 are provided in Appendix E.3. All experiments were carried out on an Intel i9-9900K CPU running at 3.6GHz4.

**Simulations:** The algorithms are evaluated for graphs with between 5 and 250 vertices. For a given number of vertices, we uniformly sample 50 ADMG structures from a library of graphs which are non-isomorphic to each other. Edges for each of these 100 graphs are sampled with probability of \((n)/n\), where \(n\) is the number of (observable) vertices, to impose sparsity (thus pragmatically reducing the search space). For each graph, we sample directed and bidirected edge probabilities \(p_{e}\) uniformly between 0.51 and \(1.0@math@degree\). The problem is then converted into edge ID according to Lemma 3.2. The vertices in the graphs are topologically sorted and the outcome \(Y\) is selected to be the last vertex in the topological ordering. We then check whether a solution exists in principle by removing all finite cost edges and checking for identifiability. If not, a new graph is sampled to avoid evaluating the algorithms on graphs with no solution. For each of these 50 probabilistic ADMGs, we run the algorithms and record the resulting runtime and the associated cost of the solution. If the runtime exceeds 3 minutes, we abort and log that the algorithm has failed to find a solution.

Results are presented in Figure 4. Runtimes and costs are shown for the subset of graphs for which all algorithms found a solution (to facilitate comparison). Runtimes for each algorithm are shown in Fig. 3(a), where it can be seen that our proposed HEID-1 and HEID-2 heuristic algorithms have negligible runtime, followed by the MCIP variants. Interestingly, the exact algorithm EDGEID outperformed the MCIP algorithms on larger graphs, for which the transformation time from the edge ID problem to the MCIP increases with the size of the graph. In contrast, EDGEID had large runtime variance which depended heavily on the specifics of the graph under evaluation, particularly for graphs with fewer vertices. The costs for each graph are shown in Fig. 3(b), and here we see, as expected, the lowest cost is achieved by the two exact algorithms, EDGEID and MCIP-exact, followed closely by the heuristic algorithms. Figure 3(c) shows the fraction of evaluations for which the runtime exceeded 3 minutes (applicable to the exact algorithms). In general, and owing to the sparsity

Figure 4: Experimental results for runtime, solution costs, fraction of graphs for which no solution was found, and fraction of graphs for which runtime limit of 3 minutes was exceeded. Error bars for runtime and cost graphs indicate 5th and 95th percentiles. Best viewed in color.

penalty in our graph generation mechanism, the cost of identified solutions falls with the number of vertices. However, among the exact algorithms, EDGEID, exceeds the 3-minute runtime more often than the MCIP-Exact, regardless of the number of vertices and despite the fact that EDGEID is quicker at finding a solution when it does so. Overall, HEID-1 was the most consistent in finding a solution, having a short runtime, and achieving a close to optimal cost.

Real-world graphs: We also apply the algorithms to four real-world datasets. The first 'Psych' (22 nodes & 70 directed edges) concerns the putative structure from a causal discovery algorithm Structural Agnostic Model  using data collected as part of the Health and Relationships Project . The other three 'Barley' (48 nodes & 84 directed edges), 'Water' (32 nodes & 66 directed edges), and 'Alarm' (37 nodes & 46 directed edges) come from the bnlearn python package . For all four graphs, and as with the simulations described above, we introduce bidirected edges with a sparsity constraint of \((n)/n\), and simulate expert domain knowledge by randomly assigning directed and bidirected edge probabilities between 0.51 and 1. The outcome \(Y\) is selected to be the last vertex in the topological ordering. For these results, we provide the runtime (limited to 500 seconds) and cost, as well as the ratio of graph plausibility before and after selecting a subgraph in which the effect is identifiable \(P(}^{*})/P()\). This ratio is 1.0 if the effect is identifiable in the original graph and decreases according to the plausibility of an identified subgraph.

Results are shown in Table 1. In cases where MCIP-exact and/or EDGEID did not exceed the runtime limit, it can be seen that HEID-2 and MCIP-H2 achieved equivalent to optimal cost and ratio. Runtimes for MCIP variants exceeded the HEID variants owing to the required transformation. EDGEID timed out on all but the Alarm structure, whereas MCIP-exact only timed out on the Psych structure, indicating that the MCIP-exact is more consistent (this also corroborates Figure 4c).

## 6 Concluding remarks

Researchers in causal inference are often faced with graphs for which the effect of interest is not identifiable. It is common to identify a target effect by assuming ignorability. A less drastic and more reasonable approach would be to relax this assumption by identifying the most plausible subgraph, given uncertainty about the structure as we suggested in this work. We presented a number of algorithms for finding the most probable/plausible probabilistic ADMG in which the target causal effect is identifiable. We provided an analysis of the complexity of the problem, and an experimental comparison of runtimes, solution costs, and failure rates. We noted that our heuristic algorithms, Alg. 2 and Alg. 4 performed remarkably well across all metrics. In terms of limitations, we made the assumption that the edges in \(\) are mutually independent (Assumption 2.1). Future work should explore the case where this assumption does not hold. In this work, we studied the problem of point identification of the target effect. We envision that a similar methodology can be applied to partial identification. Finally, it is worth noting that the external validity of the derived subgraph (i.e., whether or not the subgraph is correctly specified with respect to the corresponding real-world process) is not guaranteed. As such, practitioners using such approaches are encouraged to do so with caution, particularly for research involving human participants.