# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

Taken together, these works paint an encouraging picture of our understanding of DDPMs which takes into account both the diversity of data in applications (including data distributions which are highly multimodal or supported on lower-dimensional manifolds), as well as the non-convex training process which is not guaranteed to accurately learn the score function uniformly in space.

Besides DDPMs, instead of implementing the time reversed diffusion as an SDE, it is also possible to implement it as an ordinary differential equation (ODE), called the _probability flow ODE_; see SS2. The ODE implementation is often claimed to be faster than the SDE implementation , with the rationale being that ODE discretization is typically more accurate than SDE discretization, so that one could use a larger step size. Indeed, the discretization error usually depends on the regularity of the trajectories, which is \(^{1}\) for ODEs but only \(^{-}\) for SDEs (_i.e._, Holder continuous with any exponent less than \(\)) due to the roughness of the Brownian motion driving the evolution.

Far from being able to capture this intuition, current analyses of SGMs cannot even provide a _polynomial-time_ analysis of the probability flow ODE. The key issue is that under our minimal assumptions (_i.e._, without log-concavity of the data distribution), the underlying dynamics of either the ODE or SDE implementation are not contractive, and hence small errors quickly accumulate and are magnified. The aforementioned analyses of DDPMs managed to overcome this challenge by leveraging techniques specific to the analysis of SDEs, through which we now understand that _stochasticity_ plays an important role in alleviating error accumulation. It is unknown, however, how to carry out the analysis for the purely deterministic dynamics inherent to the probability flow ODE.

Our first main contribution is to give the first convergence guarantees for SGMs with OU forward dynamics in which steps of the discretized probability flow ODE--referred to as _predictor steps_--are interleaved with _corrector steps_ which runs the overdamped Langevin diffusion with estimated score, as pioneered in . Our results are akin to prior works on DDPMs in that they hold under minimal assumptions on the data distribution and under \(L^{2}\) bounds on the score estimation error, and our guarantees scale polynomially in all relevant problem parameters. Here, the corrector steps inject stochasticity which is crucial for our proofs; however, we emphasize that the use of corrector steps does _not_ simply reduce the problem to applying existing DDPM analyses. Instead, we must develop an entirely new framework based on Wasserstein-to-TV regularization, which is of independent interest; see SS4 for a detailed overview of our techniques. Our results naturally raise the question of whether the corrector steps are necessary in practice, and we discuss this further in SS5.

When the data distribution is log-smooth, then the dimension dependence of prior results on DDPMs, as well as our first result for the probability flow ODE with overdamped corrector, both scale as \(O(d)\). Does this contradict the intuition that ODE discretization is more accurate than SDE discretization? The answer is _no_; upon inspecting our proof, we see that the discretization error of the probability flow ODE is indeed smaller than what is incurred by DDPMs, and in fact allows for a larger step size of order \(1/\). The bottleneck in our result stems from the use of the overdamped Langevin diffusion for the corrector steps. Taking inspiration from the literature on log-concave sampling (see, _e.g._,  for an exposition), our second main contribution is to propose corrector steps based on the _underdamped_ Langevin diffusion (see SS2) which is known to improve the dimension dependence of sampling. In particular, we show that the probability flow ODE with underdamped Langevin corrector attains \(O()\) dimension dependence. This dependence is better than what was obtained for DDPMs in  and therefore highlights the potential benefits of the ODE framework. We note that the benefit to which we refer is at _generation time_, and not at training time.

Previously,  have proposed a "noise-denoise" sampler using the underdamped Langevin diffusion, but to our knowledge, our work is the first to use it in conjunction with the probability flow ODE. Although we provide preliminary numerical experiments in the Appendix, we leave it as a question for future work to determine whether the theoretical benefits of the underdamped Langevin corrector are also borne out in practice.

### Our contributions

In summary, our contributions are the following.

* We provide the first convergence guarantees for the probability flow ODE with overdamped Langevin corrector (DPOM; Algorithm 1).

* We propose an algorithm based on the probability flow ODE with underdamped Langevin corrector (DPUM; Algorithm 2).
* We provide the first convergence guarantees for DPUM. These convergence guarantees show improvement over (i) the complexity of DPOM (\(O()\) vs \(O(d)\)) and (ii) the complexity of DDPMs, _i.e._, SDE implementations of score-based generative models (again, \(O()\) vs \(O(d)\)).
* We provide preliminary numerical experiments in a toy example showing that DPUM can sample from a highly non log-concave distribution (see Appendix). The numerical experiments are not among our main contributions and are provided for illustration only. The Python code can be found in the Supplementary material.

Our main theorem can be summarized informally as follows; see SS3 for more detailed statements.

**Theorem 1** (Informal).: _Assume that the score function along the forward process is \(L\)-Lipschitz, and that the data distribution has finite second moment. Assume that we have access to \((/)\)\(L^{2}\)-accurate score estimates. Then, the probability flow ODE implementation of the reversed Ornstein-Uhlenbeck process, when interspersed with either the overdamped Langevin corrector (DPOM; Algorithm 1) or with the underdamped Langevin corrector (DPUM; Algorithm 2), outputs a sample whose law is \(\)-close in total variation distance to the data distribution, using \((L^{3}d/^{2})\) or \((L^{2}/)\) iterations respectively._

Our result provides the _first_ polynomial-time guarantees for the probability flow ODE implementation of SGMs, so long as it is combined with the use of corrector steps. Moreover, when the corrector steps are based on the underdamped Langevin diffusion, then the dimension dependence of our result is significantly smaller (\(O()\) vs. \(O(d)\)) than prior works on the complexity of DDPMs, and thus provides justification for the use of ODE discretization in practice, compared to SDEs.

Our main assumption on the data is that the score functions along the forward process are Lipschitz continuous, which allows for highly non-log-concave distributions, yet does not cover non-smooth distributions such as distributions supported on lower-dimensional manifolds. However, as shown in [10; 11; 12], we can also obtain polynomial-time guarantees without this smoothness assumption via early stopping (see Remark 1).

### Related works

The idea of using a time-reversed diffusion for sampling has been fruitfully exploited in the log-concave sampling literature via the _proximal sampler_[14; 1; 15; 16; 17; 18; 19], as put forth in , as well as through algorithmic stochastic localization [11; 21]. Although we do not aim to be comprehensive in our discussion of the literature, we mention, e.g., [1; 1] for alternative approaches for diffusion models. We also note that the recent work of  obtained a discretization analysis for the probability flow ODE (without corrector) in KL divergence, though their bounds have a large dependence on \(d\) and are exponential in the Lipschitz constant of the score integrated over time.

Since the original arXiv submission of this paper, there have been further works studying the probability flow ODE. The work of  also studied the probability flow ODE, but without providing discretization guarantees (and with possibly exponential dependencies). The work  provides polynomial-time guarantees for the probability flow ODE (without corrector steps), at the cost of larger polynomial dependencies and more stringent score assumptions (namely, bounds on the Jacobian of the score). Also,  study another variant of the predictor-corrector framework.

## 2 Preliminaries

### Score-based generative modeling

Let \(q_{}\) denote the data distribution, _i.e._, the distribution from which we wish to sample. In score-based generative modeling, we define a forward process \((q_{t}^{})_{t 0}\) with \(q_{0}^{}=q_{}\), which transforms our data distribution into noise. In this paper, we focus on the canonical choice of the Ornstein-Uhlenbeck(OU) process,

\[x_{t}^{}=-x_{t}^{}\,t+\, B_{t}\,, x_{0}^{} q_{}\,, q_{t}^{ }(x_{t}^{})\,,\] (1)

where \((B_{t})_{t 0}\) is a standard Brownian motion in \(^{d}\). It is well-known that the OU process mixes rapidly (exponentially fast) to its stationary distribution, the standard Gaussian distribution \(^{d}\).

Once we fix a time horizon \(T>0\), the time reversal of the SDE defined in (1) over \([0,T]\) is given by

\[x_{t}^{}=(x_{t}^{}+2\, q_{t}^{ }(x_{t}^{}))\,t+\,B_{t}\,,\] (2)

where \(q_{t}^{} q_{T-t}^{}\), and the reverse SDE is a generative model: when initialized at \(x_{0}^{} q_{0}^{}\), then \(x_{T}^{} q\). Since \(q_{0}^{}=q_{T}^{}^{d}\), the reverse SDE transforms samples from \(^{d}\) (i.e., pure noise) into approximate samples from \(q_{}\). In order to implement the reverse SDE, however, one needs to estimate the score functions \( q_{t}^{}\) for \(t[0,T]\) using the technique of score matching . In practice, the score estimates are produced via a deep neural network, and our main assumption is that these score estimates are accurate in an \(L^{2}\) sense (see Assumption 4). This gives rise to the denoising diffusion probabilistic modeling (DDPM) algorithm.

Notation.Since the reverse process is the primary object of interest, we drop the arrow \(\) from the notation for simplicity; thus, \(q_{t} q_{t}^{}\). We will always denote the forward process with the arrow \(\).

For each \(t[0,T]\), let \(s_{t}\) denote the estimate for the score \( q_{t}= q_{t}^{}\).

### Probability flow ODE (predictor steps)

Instead of running the reverse SDE (2), there is in fact an alternative process \((x_{t})_{t[0,T]}\) which evolves according to an ODE (and hence evolves deterministically), and yet has the same marginals as (2). This alternative process, called the _probability flow ODE_, can also be used for generative modeling.

One particularly illuminating way of deriving the probability flow ODE is to invoke the celebrated theorem, due to , that the OU process is the Wasserstein gradient flow of the KL divergence functional (i.e. relative entropy) \((\,\|\,^{d})\). From the general theory of Wasserstein gradient flows (see ), the Wasserstein gradient flow \((_{t})_{t 0}\) of a functional \(\) can be implemented via the dynamics

\[_{t}=-[_{W_{2}}(_{t})](z_{t})\,, z_{0} _{0}\,,\]

in that \(z_{t}_{t}\) for all \(t 0\). Applying this to \((\,\|\,^{d})\), we arrive at the forward process

\[_{t}^{}=-^{}}{ ^{d}}(x_{t}^{})=-x_{t}^{}- q_{t}^{ }(x_{t}^{})\,.\] (3)

Setting \(x_{t} x_{T-t}^{}\), it is easily seen that the time reversal of (3) is

\[_{t}=x_{t}+ q_{t}(x_{t})\,,_{t }=x_{t}+ q_{T-t}^{}(x_{t})\,,\] (4)

which is called the probability flow ODE. In this paper, the interpretation of the probability flow ODE as a reverse Wasserstein gradient flow is only introduced for interpretability, and the reader who is unfamiliar with Wasserstein calculus can take (4) to be the definition of the probability flow ODE. Crucially, it has the property that if \(x_{0} q_{0}\), then \(x_{t} q_{t}\) for all \(t[0,T]\).

We can discretize the ODE (4). Fixing a step size \(h>0\), replacing the score function \( q_{t}\) with the estimated score given by \(s_{t}\), and applying the exponential integrator to the ODE (i.e., exactly integrating the linear part), we arrive at the discretized process

\[x_{t+h}=x_{t}+_{0}^{h}x_{t+u}\,u+h\,s_{t}(x_{t})=(h)\,x_{t}+ ((h)-1)s_{t}(x_{t})\,.\] (5)

### Corrector steps

Let \(q\) be a distribution over \(^{d}\), and write \(U\) as a shorthand for the potential \(- q\).

Overdamped Langevin.The _overdamped Langevin diffusion_ with potential \(U\) is a stochastic process \((x_{t})_{t 0}\) over \(^{d}\) given by

\[x_{t}=- U(x_{t})\,t+\,B_{t}\,.\]

The stationary distribution of this diffusion is \(q(-U)\).

We also consider the following discretized process where \(- U\) is replaced by a _score estimate_\(s\). Fix a step size \(h>0\) and let \((_{t})_{t 0}\) over \(^{d}\) be given by

\[_{t}=s(_{ t/h\,h})\,t +\,B_{t}\,.\]

Underdamped Langevin.Given a friction parameter \(>0\), the corresponding _underdamped Langevin diffusion_ is a stochastic process \((z_{t},v_{t})_{t 0}\) over \(^{d}^{d}\) given by

\[z_{t} =v_{t}\,t\,,\] \[v_{t} =-( U(z_{t})+ v_{t})\,t+\, B_{t}\,.\]

The stationary distribution of this diffusion is \(q^{d}\).

We also consider the following discretized process, where \(- U\) is replaced by a score estimate \(s\). Let \((_{t},_{t})_{t 0}\) over \(^{d}^{d}\) be given by

\[_{t} =_{t}\,t\,,\] (6) \[_{t} =(s(_{ t/h\,h})-_{t}) \,t+\,B_{t}\,.\]

Diffusions as corrector steps.At time \(t\), the law of the ideal reverse process (4) initialized at \(q_{0}\) is \(q_{t}\). However, errors are accumulated through the course of the algorithm: the error from initializing at \(^{d}\) rather than at \(q_{0}\); errors arising from discretization of (4); and errors in estimating the score function. That's why the law of the algorithm's iterate will not be exactly \(q_{t}\). We propose to use either the overdamped or the underdamped Langevin diffusion with stationary distribution \(q_{t}\) and estimated score as a corrector, in order to bring the law of the algorithm iterate closer to \(q_{t}\). In the case of the underdamped Langevin diffusion, this is done by drawing an independent Gaussian random variable \(_{0}^{d}\), running the system (6) starting from \((_{0},_{0})\) (where \(_{0}\) is the current algorithm iterate) for some time \(t\), and then keeping \(_{t}\). In our theoretical analysis, the use of corrector steps boosts the accuracy and efficiency of the SGM.

## 3 Results

### Assumptions

We make the following mild assumptions on the data distribution \(q_{*}\) and on the score estimate \(s\).

**Assumption 1** (second moment bound).: _We assume that \(_{2}^{2}:=_{q_{*}}[\|\|^{2}]<\)._

**Assumption 2** (Lipschitz score).: _For all \(t[0,T]\), the score \( q_{t}\) is \(L\)-Lipschitz, for some \(L 1\)._

**Assumption 3** (Lipschitz score estimate).: _For all \(t\) for which we need to estimate the score function in our algorithms, the score estimate \(s_{t}\) is \(L\)-Lipschitz._

**Assumption 4** (score estimation error).: _For all \(t\) for which we need to estimate the score function in our algorithms,_

\[_{q_{*}}[\|s_{t}- q_{t}\|^{2}]_{ }^{2}\,.\]

Assumptions 1, 2, and 4 are standard and were shown in  to suffice for obtaining polynomial-time convergence guarantees for DDPMs. The new condition that we require in our analysis is Assumption 3, which was used in  but ultimately shown to be unnecessary for DDPMs. We leave it as an open question whether this can be lifted in the ODE setting.

_Remark 1_.: As observed in , Assumption 2 can be removed via early stopping, at the cost of polynomially larger iteration complexity. The idea is that if \(q_{*}\) has compact support but does not necessarily satisfy Assumption 2 (_e.g._, if \(q_{*}\) is supported on a compact and lower-dimensional manifold), then \(q_{}^{*}\) will satisfy Assumption 2 if \(>0\). By applying our analysis up to time \(T-\) instead of time \(T\), one can show that a suitable projection of the output distribution is close in Wasserstein distance to \(q_{*}\) (see [13, Corollary 2.4] or [11, Corollary 5]). For brevity, we do not consider this extension of our results here.

### Algorithms

We provide the pseudocode for the two algorithms we consider, _Diffusion Predictor + Overdamped Modeling_ (DPOM) and _Diffusion Predictor + Underdamped Modeling_ (DPUM), in Algorithms 1 and 2 respectively. The only difference between the two algorithms is in the corrector step, which we highlight in Algorithm 2. For simplicity, we take the total amount of time \(T\) to be equal to \(N_{0}/L+h_{}\) for an integer \(N_{0} 1\), and we assume that \(1/L\) is a multiple of \(h_{}\) and that \(h_{}\) is a multiple of \(=}{L^{2}(d^{2}})}\).

We consider two stages: in the first stage, which lasts until time \(N_{0}/L=T-h_{}\), we intersperse predictor epochs (run for time \(1/L\), discretized with step size \(h_{}\)) and corrector epochs (run for time \((1/L)\) for the overdamped corrector or for time \((1/)\) for the underdamped corrector, and discretized with step size \(h_{}\)). The second stage lasts from time \(T-h_{}\) to time \(T-\), and we incorporate geometrically decreasing step sizes for the predictor. Note that this implies that our algorithm uses _early stopping_.

``` Input: Total time \(T\), predictor step size \(h_{}\), corrector step size \(h_{}\), score estimates \(s\) Output: Approximate sample from the data distribution \(q_{}\)
1 Draw \(_{0}^{d}\).
2for\(n=0,1,,N_{0}-1\)do
3Predictor: Starting from \(_{n/L}\), run the discretized probability flow ODE (5) from time \(\) to \(\) with step size \(h_{}\) and estimated scores to obtain \(^{}_{(n+1)/L}\).
4Corrector: Starting from \(^{}_{(n+1)/L}\), run overdamped Langevin Monte Carlo for total time \((1/L)\) with step size \(h_{}\) and score estimate \(s_{(n+1)/L}\) to obtain \(_{(n+1)/L}\).
5Predictor: Starting from \(_{T-h_{}}\), run the discretized probability flow ODE (5) with step sizes \(h_{}/2,h_{}/4,h_{}/8,,\) and estimated scores to obtain \(^{}_{T-}\).
6Corrector: Starting from \(^{}_{T-}\), run overdamped Langevin Monte Carlo for total time \((1/L)\) with step size \(h_{}\) and score estimate \(s_{T-}\) to obtain \(_{T-}\). return\(_{T-}\) ```

**Algorithm 1**DPOM(\(T,h_{},h_{},s\))

### Convergence guarantees

Our main results are the following convergence guarantees for the two predictor-corrector schemes described in SS3.2:

**Theorem 2** (Dpm).: _Suppose that Assumptions 1-4 hold. If \(\) denotes the output of DPOM (Algorithm 1) with \(}{L^{2}(d_{2}})}\), then_

\[(,q_{})(_{2})( -T)+L^{2}Td^{1/2}h_{}+L^{3/2}Td^{1/2}h_{}+L^{1/2}T _{}+\,.\] (7)

_In particular, if we set \(T=(_{2}^{2}}{^{2}}) \), \(h_{}=(d^{1/2}})\), \(h_{}=(}{L^{3/2}})\), and if the score estimation error satisfies \(_{}(})\), then we can obtain TV error \(\) with a total iteration complexity of \((d}{^{2}})\) steps._

The five terms in the bound (7) correspond, respectively, to: the convergence of the forward (OU) process; the discretization error from the predictor steps; the discretization error from the corrector steps; the score estimation error; and the early stopping error.

Theorem 2 recovers nearly the same guarantees as the one in , but for the probability flow ODE with overdamped Langevin corrector instead of the reverse SDE without corrector. Recall also from Remark 1 that our results can easily be extended to compactly supported data distributions without smooth score functions. This covers essentially all distributions encountered in practice. Therefore, our result provides compelling theoretical justification complementing the empirical efficacy of the probability flow ODE, which was hitherto absent from the literature.

However, in Theorem 2, the iteration complexity is dominated by the corrector steps. Next, we show that by replacing the overdamped LMC with underdamped LMC, we can achieve a quadratic improvement in the number of steps, considering the dependence on \(d\). As discussed in the Introduction, this highlights the potential benefits of the ODE framework over the SDE.

**Theorem 3** (Dpm).: _Suppose that Assumptions 1-4 hold. If \(\) denotes the output of DPUM (Algorithm 2) with \(}{L^{2}(d_{2}})}\), then_

\[(,q_{})(_{2}) (-T)+L^{2}Td^{1/2}h_{}+L^{3/2}Td^{1/2}h_{}+L^{1/2} T_{}+\,.\]

_In particular, if we set \(T=(_{2}^{2}}{^{2}}) \), \(h_{}=(d^{1/2}})\), \(h_{}=(d^{1/2}})\), and if the score estimation error satisfies \(_{}(})\), then we can obtain TV error \(\) with a total iteration complexity of \((d^{1/2}}{})\) steps._

## 4 Proof overview

Here we give a detailed technical overview for the proof of our main results, Theorems 2 and 3. As in , the three sources of error that we need to keep track of are (1) estimation of the score function; (2) discretization of time when implementing the probability flow ODE and corrector steps; and (3) initialization of the algorithm at \(^{d}\) instead of the true law of the end of the forward process, \(q_{0}=q_{T}^{-}\). It turns out that (1) is not so difficult to manage as soon as we can control (2) and (3). Furthermore, as in prior work, we can easily control (3) via the data-processing inequality: the total variation distance between the output of the algorithm initialized at \(q_{0}\) versus at \(^{d}\) is at most \((q_{T}^{-},^{d})\), which is exponentially small in \(T\) by rapid mixing of the OU process. So henceforth in this overview, let us assume that both the algorithm and the true process are initialized at \(q_{0}\). It remains to control (2).

Failure of existing approaches.In the SDE implementation of diffusion models, prior works handled (2) by directly bounding a strictly larger quantity, namely the KL divergence between the laws of the _trajectories_ of the algorithm and the true process; by Girsanov's theorem, this has a clean formulation as an integrated difference of drifts. Unfortunately, in the ODE implementation, this KL divergence is infinite: in the absence of stochasticity in the reverse process, these laws over trajectories are not even absolutely continuous with respect to each other.

In search of an alternative approach, one might try a Wasserstein analysis. As a first attempt, we could couple the initialization of both processes and look at how the distance between them changes over time. If \((_{t})_{0 t T}\) and \((x_{t})_{0 t T}\) denote the algorithm and true process, then smoothness of the score function allows us to naively bound \(_{t}}[\|_{t}-x_{t}\|^{2}]\) by \(O(L)}[\|_{t}-x_{t}\|^{2}]\). While this ensures that the processes are close if run for time \( 1/L\), it does not rule out the possibility that they drift apart exponentially quickly after time \(1/L\).

Restarting the coupling--first attempt.What we would like is some way of "restarting" this coupling before the processes drift too far apart, to avoid this exponential compounding. We now motivate how to achieve this by giving an argument that is incorrect but nevertheless captures the intuition for our approach. Namely, let \(p_{t}(_{t})\) denote the law of the algorithm, let \(P^{t_{0},h}_{}\) denote the result of running the ideal probability flow ODE for time \(h\) starting from time \(t_{0}\), and let \(^{t_{0},h}_{}\) denote the same but for the discretized probability flow ODE with estimated score. For \(h 1/L\), consider the law of the two processes at time \(2h\), i.e.,

\[p_{2h}=q_{0}^{0,2h}_{} q_{2h}=q_{0} P^{0,2h}_{}\,.\] (8)

The discussion above implies that \(q_{0}P^{0,h}_{}\) and \(q_{0}^{0,h}_{}\) are close in 2-Wasserstein distance, so by the data-processing inequality, this implies that \(q_{0}P^{0,h}_{}^{h,h}_{}\) and \(q_{0}^{0,h}_{}^{h,h}_{}\) are also close. To show that \(p_{2h}\) and \(q_{2h}\) in Eq. (8) are close, it thus suffices to show that \(q_{0}P^{0,2h}_{}\) and \(q_{0}P^{0,h}_{}^{h,h}_{}\) are close. But these two distributions are given by running the algorithm and the true process for time \(h\), both starting from \(q_{0}P^{0,h}_{}\). So if we "restart" the coupling by coupling the processes based on their locations at time \(h\), rather than time \(0\), of the reverse process, we can again apply the naive Wasserstein analysis.

At this juncture, it would seem that we have miraculously sidestepped the exponential blowup and shown that the expected distance between the processes only increases linearly over time! The issue of course is in the application of the "data-processing inequality," which simply does not hold for the Wasserstein distance.

Restarting the coupling with a corrector step.This is where the corrector comes in. The idea is to use _short-time regularization_: if we apply a small amount of noise to two distributions which are already close in Wasserstein, then they become close in KL divergence, for which a data-processing inequality holds. The upshot is that if the noise doesn't change the distributions too much, then we can legitimately restart the coupling as above and prove that the distance between the processes, now defined by interleaving the probability flow ODE and its discretization with periodic injections of noise, increases only linearly in time.

It turns out that naive injection of noise, e.g., convolution with a Gaussian of small variance, is somewhat wasteful as it fails to preserve the true process and leads to poor polynomial dependence in the dimension. On the other hand, if we instead run the overdamped Langevin diffusion with potential chosen so that the law of the true process is stationary, then we can recover the linear in \(d\) dependence of Theorem 2. Then by replacing overdamped Langevin diffusion with its underdamped counterpart, which has the advantage of much smoother trajectories, we can obtain the desired quadratic speedup in dimension dependence in Theorem 3.

Score perturbation lemma.In addition to the switch from SDE to ODE and the use of the underdamped corrector, a third ingredient is essential to our improved dimension dependence. The former two ensure that the trajectory of our algorithm is smoother than that of DDPMs, so that even over time windows that scale with \(1/\), the process does not change too much. By extension, as the score functions are Lipschitz, this means that any fixed score function evaluated over iterates in such a window does not change much. This amounts to controlling discretization error in _space_.

It is also necessary to control discretization error in _time_, i.e., proving what some prior works referred to as a _score perturbation lemma_. That is, for any fixed _iterate_\(x\), we want to show that the score function \( q_{t}(x)\) does not change too much as \(t\) varies over a small window. Unfortunately, prior works were only able to establish this over windows of length \(1/d\). In this work, we improve this to windows of length \(1/\) (see Lemma 3 and Corollary 1).

In our proof, we bound the squared \(L^{2}\) norm of the derivative of the score along the trajectory of the ODE. The score function evaluated at \(y\) can be expressed as \(_{P_{0|t}(|y)}[ U]\); here, the posterior distribution \(P_{0|t}( y)\) is essentially the prior \(q_{*}\) tilted by a Gaussian of variance \(O(t)\). Hence we need to bound the change in the expectation when we change the distribution from \(P_{0|t}\) to \(P_{0|t+ t}\); because \( U\) is \(L\)-Lipschitz, we can bound this by the Wasserstein distance between the distributions. For small enough \(t\), \(P_{0|t}\) is strongly log-concave, and a transport cost inequality bounds this in terms of KL divergence, which is more easily bounded. Indeed, we can bound it with the KL divergence between the joint distributions \(P_{0,t}\) and \(P_{0,t+ t}\), which reduces to bounding the KL divergence between Gaussians of unequal variance.

However, since our score perturbation lemma degrades near the beginning of the forward process, we require better control of the discretization error during this part of the algorithm, hence leading to our choice of geometrically decreasing step sizes. Alternatively, we could use a two-stage step size schedule, see Remark 4.

## 5 Conclusion

In this work, we have provided the first polynomial-time guarantees for the probability flow ODE implementation of SGMs with corrector steps and exhibited improved dimension dependence of the ODE framework over prior results for DDPMs (_i.e.,_ the SDE framework). Our analysis raises questions relevant for practice, of which we list a few.

* Although we need the corrector steps for our proof, are they in fact necessary for the algorithm to work efficiently in practice?
* Is it possible to obtain even better dimension dependence, perhaps using higher-order solvers and stronger smoothness assumptions?
* Can we obtain improved dimension dependence even in the non-smooth setting, compared to the result of ?

We also list several limitations of our work, namely:

* Our analysis only covers the probability flow ODE corresponding to the OU forward process. We leave the study of more general dynamics for future study.
* Our guarantees require the score function to be learned to \(L^{2}\) accuracy \((/)\), which is more stringent than the prior works  and may be an technical artefact of our proof.
* We have not validated our theoretical findings with large-scale experiments. In particular, it is still unclear whether flow-based methods can outperform the standard DDPM algorithm in practical, high dimensional settings.

## 6 Acknowledgments

We want to thank Yin Tat Lee for his valuable comments, shaping the direction of this research project in its early stages. SC was supported by NSF Award 2103300 for part of this work.