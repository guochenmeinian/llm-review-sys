# FEEL-SNN: Robust Spiking Neural Networks with Frequency Encoding and Evolutionary Leak Factor

Mengting Xu1,2 De Ma 1,2 HuaJin Tang 1,2 Qian Zheng1,2 Gang Pan 1,2

1 The State Key Lab of Brain-Machine Intelligence, Zhejiang University, Hangzhou, China

2 College of Computer Science and Technology, Zhejiang University, Hangzhou, China

{xumengting, made, htang, qianzheng, gpan}@zju.edu.cn

Corresponding author

###### Abstract

Currently, researchers think that the inherent robustness of spiking neural networks (SNNs) stems from their biologically plausible spiking neurons, and are dedicated to developing more bio-inspired models to defend attacks. However, most work relies solely on experimental analysis and lacks theoretical support, and the direct-encoding method and fixed membrane potential leak factor they used in spiking neurons are simplified simulations of those in the biological nervous system, which makes it difficult to ensure generalizability across all datasets and networks. Contrarily, the biological nervous system can stay reliable even in a highly complex noise environment, one of the reasons is selective visual attention and non-fixed membrane potential leaks in biological neurons. This biological finding has inspired us to design a highly robust SNN model that closely mimics the biological nervous system. In our study, we first present a unified theoretical framework for SNN robustness constraint, which suggests that improving the encoding method and evolution of the membrane potential leak factor in spiking neurons can improve SNN robustness. Subsequently, we propose a robust SNN (FEEL-SNN) with Frequency Encoding (FE) and Evolutionary Leak factor (EL) to defend against different noises, mimicking the selective visual attention mechanism and non-fixed leak observed in biological systems. Experimental results confirm the efficacy of both our FE, EL, and FEEL methods, either in isolation or in conjunction with established robust enhancement algorithms, for enhancing the robustness of SNNs.

Our code is available at https://github.com/zju-bmi-lab/FEEL_SNN.

## 1 Introduction

In recent years, brain-inspired spiking neural networks (SNNs)  have been increasingly prominent. Unlike traditional artificial neural networks (ANNs), which process a single image using floating-point values, spiking neural networks encode spatial-pixel image into temporal spike train. Information is transmitted by the occurrence of spikes (using \(0\) to signify no spike and \(1\) to denote a spike) whenever the membrane potential of a spiking neuron exceeds its threshold, thereby emulating biological neurons [30; 37; 14]. The distinctive spatio-temporal characteristics, discrete representation, and event-driven properties of SNNs enable them to operate efficiently on neuromorphic hardware [26; 4; 20; 46]. This makes them increasingly applicable to a variety of tasks [42; 19; 48], such as spatio-temporal pattern recognition  and high-speed detection . As SNNs attract increasing attention from academia and industry, the issue of security  becomes more important. When SNNs are applied to safety-critical systems, their reliability should be a major concern . While SNNs have demonstrated better robustness compared to ANNs [11; 32; 31], recent studies have shown that they are still vulnerable to noise [17; 8]. Among all types of perturbations, adversarial noise , whichrefers to visually imperceptible alterations that can mislead a well-trained network, is particularly concerning. Therefore, improving the robustness of SNNs is crucial for their real-life deployment.

At present, researchers believe that the inherent robustness of SNN is brought by its more biologically plausible spiking neurons, and they are dedicated to developing more bio-inspired models to cope with noise attacks. Among them, some work focuses on SNN robustness analysis.  investigates the SNNs robustness to adversarial attacks with different values of the neuron's firing voltage thresholds and time window boundaries.  suggests that the utility of spike timing in SNNs could improve the robustness against attacks. [39; 32; 3] analyze the adversarial accuracy of SNNs trained with leak factor in LIF spiking neurons. However, these analyses rely solely on experimental analysis and lack sufficient theoretical support to ensure generalizability across all datasets and networks. Other work aims to improve the robustness of SNN from biological aspects.  further introduces stochasticity in biological neurons as a stochastic gating mechanism for spiking neurons to enhance model robustness. However, this may result in the loss of the original information. The noise environment encountered by the biological nervous system is highly complex, with various types of noise spanning different frequency ranges . Adversarial noises also exhibit different frequencies across datasets, rather than being fixed [23; 1]. Despite this complexity, the biological nervous system maintains robustness. This inspired us to design a highly robust SNN model that more closely mimics the biological nervous system, allowing it to adapt to and overcome the challenges posed by diverse and dynamic noise environments.

For the biological brain, as shown in Fig. (1a), there exists the selective visual attention mechanism that selectively focuses on stimuli of different frequencies over time and can filter out unwanted information [7; 45]. This aids the biological nervous system in avoiding the instability caused by noise . Additionally, as shown in Fig. (1b), the changes in membrane potential in biological neurons are determined by ion concentration inside and outside the cell membrane. Different environments and types of nerve axon fibers can affect the degree of leak of the membrane potential [38; 13], which contributes to the biological nervous system's processing of complex noise . Motivated by these biological insights, we undertake a theoretical examination of the robustness of SNNs. We present a unified framework for SNN robustness constraint, which indicates that refining the encoding technique and evolution of the membrane potential leak factor can enhance SNN robustness. Subsequently, we propose a robust SNN with Frequency Encoding and Evolutionary Leak factor (FEEL-SNN) to defend against different noises. Our main contributions are summarized as follows:

* Through analysis of the model's adversarial loss, we theoretically present a unified framework for SNN robustness. Our findings suggest that enhancing the encoding method and evolution of the membrane potential leak factor can improve SNN robustness.
* We propose a frequency encoding (FE) method for SNNs. FE captures information of varying frequencies at different time steps, mimicking the selective visual attention mechanism observed in biological systems. FE can preserve the original information while suppressing different frequency range noises, effectively filtering out image noise.
* Based on FE, we propose an evolutionary membrane potential leak factor (EL). EL ensures that different neurons in the network learn the optimal robustness leak factor at different time steps, which is aimed at learning the correlation between frequencies at different time steps. It simulates the membrane potential leak in biological neurons and ensures an enhancement in model robustness.

Figure 1: Illustration of the (a) selective visual attention and (b) non-fixed membrane potential leak in biological nervous system.

* Experimental results validate that both our FE and EL methods can effectively improve the robustness of SNN to different noises, and can be used in conjunction with other methods to improve the robustness further.

## 2 Related Work

[24; 31] demonstrate that compared to ANNs, SNNs exhibit inherent robustness. Currently, researchers consider that this superior robustness of SNNs stems from their more biologically plausible spiking neurons, and they are dedicated to developing more bio-inspired models to cope with noise attacks.  investigate the security of SNNs from the impact of structural parameters on the robustness of SNNs to adversarial attacks, and demonstrate that the inherent robustness of SNNs is highly conditioned by the choice of (time window; firing voltage thresholds) combination.  systematically demonstrates that precise spike timing is conducive to improving the robustness of neural networks, providing opportunities for understanding the robustness of the brain.  confirms that the leak factor in LIF neurons offers an extra knob to control the adversarial perturbation.  also investigates the role played by leak factor and concludes from frequency domain analysis that leak factor can filter high-frequency components thus improving model robustness. However, the spiking neurons used in these works only offer a simplified representation of the intricate dynamics of the biological system , and the robustness verification of the above works is mainly carried out experimentally, lacking a theoretical explanation. It's doubtful that their conclusion can adapt to other datasets and varying noises. Then, StoG  is proposed to further introduce stochasticity which is observed in biological neurons into the spiking neurons. The more biologically plausible StoG method can improve the robustness efficiently, however, it sacrifices a little original accuracy. In contrast to the aforementioned work, we conducted a theoretical analysis of the robustness of SNNs, showing that it is constrained by the encoding method and the membrane potential leak factor. We then designed a frequency encoding and evolutionary leak factor model that closely mimics the biological nervous system to enhance the robustness of SNNs.

Another method improves the robustness of SNNs by incorporating additional training strategies.  continuously adds newly generated adversarial examples during the training process to improve the robustness of SNN.  proposes a regularized adversarial training scheme by performing the Lipschitz analysis on model weights. However, these methods are rooted in the concept of adversarial training  in ANNs, and their defense performance can be influenced by downstream tasks. Furthermore, they all rely on a simplified direct encoding approach (i.e., repeating the original image \(T\) times) as input, which deviates from the visual attention mechanism observed in biological brains. Developing more biologically plausible models is essential for improving robustness and advancing SNN applications. In this work, we leverage the selective visual attention mechanism found in biological brains and introduce a frequency encoding method. This method effectively filters noise in images, enhancing the robustness of SNNs.

## 3 Preliminaries

### Spiking Neurons

The most commonly used spiking neuron of SNNs today is the Leaky Integrate-and-Fire (LIF) spiking neuron [36; 6]. LIF neurons simplify and computationally simulate the three main processes involved in information transmission in biological neurons: synaptic integration, membrane potential accumulation and decay, and neuronal firing. The dynamics of LIF spiking neurons in layer \(l\) can be described as follows:

\[Synaptic integration:_{l}^{t}=_{l-1,l} _{l-1}^{t},&l>1\\ ^{t}.&l=1\] (1)

\[Membrane potential accumulation:_{l}^{t}=_{l}^{t} _{l}^{t-1}(1-_{l}^{t-1})+_{l}^{t}.\] (2)

\[Neuronal firing:_{l}^{t}=(_{l}^{t}-V_{th}).\] (3)

In the first layer, the injected electrical signal \(_{1}^{t}\) accumulates from the input signal \(^{t}\). For subsequent layers \(l>1\), the electrical signal \(_{l}^{t}\) is the sum of spike signals \(_{l-1}^{t}\) from the preceding layer scaled by weights \(_{l-1,l}\). The operator \(\) represents element-wise product. The membrane potential \(_{l}^{t}\) at time step \(t\) is the accumulation of the leaked membrane potential \(_{l}^{t-1}\) from the previous time step and the newly injected signal \(_{l}^{t}\). If the membrane potential \(_{l}^{t}\) exceeds the threshold \(V_{th}\), a spike \(_{l}^{t}\) is generated by a Heaviside function \(()\). After spikes are produced, the membrane potential of the corresponding neurons is reset to 0. Typically, \(_{l}^{t}\) is treated as a constant value \((0,1]\) in previous work.

### Adversarial Attacks

Given a classification model \(f\) with dataset \((,y_{true})\), where \(\) is the clean image and \(y_{true}\) is the corresponding label. The adversarial attack aims to generate an adversarial example \(}\) that satisfies:

\[f(}) f() s.t.||}-||_{p},\] (4)

where\(||||_{p}\) is the \(L_{p}\)-norm, we use \(L_{}\)-norm on our work, and \(\) limits the strength of the perturbation to a level that is indistinguishable to the human eye. Here we consider four classic adversarial attack algorithms: Fast Gradient Sign Method (FGSM) , Projected Gradient Descent (PGD) , Basic iterative Method (BIM)  and CW  attacks. The detailed formulations of these attacks can be found in the Appendix A.1. The introduction of surrogate functions [25; 47; 41] addresses the limitation of backpropagating gradients through LIF neurons. This advancement enables effective adversarial attacks on SNNs using the aforementioned methods.

## 4 FEEL-SNN: Robust SNNs with Frequency Encoding and Evolutionary Leak Factor

### The robustness analysis of SNNs

The robustness of the model is quantified as \((+)-()\), the difference in loss value before and after perturbation. Improving robustness entails reducing this perturbation-induced loss difference.  utilizes the local linearity technique to theoretically address this difference, expressed as:

\[(+)-()|_{ }(x)|_{1}+g(,),\] (5)

where \(g(,)\) is the residual term, \(||_{1}\) is \(l_{1}\) norm for vector. This theoretical framework motivates research into regularization that minimize \(|_{}(x)|_{1}\) in ANNs to enhance robustness [18; 29].

The situation for SNNs differs slightly from that for ANNs . In SNNs, the perturbed input \(}=+\) is encoded into temporal trains over \(T\) time steps. Consequently, the robustness constraint for SNNs should aim to minimize the term \(_{t}|(t)}{^{t}}|_{1}\) according to Eq. (5), where \(^{t}\) is the input encoding image at time step \(t\), and \((t)\) represents the perturbation of the encoding image \(^{t}\) at time step \(t\). By applying the BPTT rule , we can derive the constraint for the term \(_{t}|(t)}{^{t}}|_{1}\) in SNNs, as presented in Theorem 1 (The detailed proof is in the Appendix A.2).

**Theorem 1**: _Given an L-layered SNN intended to inference \(T\) time-steps with \(\) as the leak factor, suppose that there are \(N_{l}\) neurons in layer \(l\) for \(l=1,2, L\). \(_{l}^{N_{l} T}\), \(_{l-1,l}^{N_{l} N_{l-1}}\), it satisfies:_

\[_{t}|(t)}{^{t}}|_{ 1}=_{t}|_{l=1}^{L}[(^{T}( t)_{l}^{k}}_{})^{l}_{q-1,q}}_{ }^{l}_{v}^{t}}{ _{v}^{t}}}_{}}{ _{l}^{T}}]|_{1},\] (6)

_where \(\) is the perturbation, \(\) is the loss function._

According to Eq. (6), the robustness of SNNs is relative to the perturbation \(\) and the leak factor \(\) in the 1 term, the model weight \(\) in the 2 term, and the \(_{l}^{t}}{_{v}^{t}}\) in the 3 term. Eq. (6) presents a unified framework for SNNs robustness constraint, which helps explain why weight regularization  (the 2 term) and surrogate gradient  (the 3 term ) can promote robustness. And the previous work [39; 32; 3] also analyzes the inherent robustness of SNNs from the leak factor in the 1 term. However, there is still a lack of work on removing input perturbation and improving leak factors in the 1 term to enhance the robustness of SNNs.

### Frequency encoding to simulate the selective visual attention in biological brain

According to the 1 term in Eq. (6), reducing input perturbations \((t)\) at every time step helps the model achieve reliable output. However, the encoding method that much of the current work relies on is the simplified direct encoding approach [11; 9; 10] (_i.e._, repeating \(T\) images), which repeats the noise \(T\) times and inevitably overlooks noise removal. In contrast, the biological nervous system can maintain stability even in complex noise environments, benefiting from the selective visual attention mechanism [7; 45] of the brain (as illustrated in Fig. (1a). The brain processes only a fraction of the information available on the retina at any given time and has the ability to filter out unwanted information. To simulate the selective visual attention of the biological nervous system while effectively removing noise at different frequencies, we propose the Frequency Encoding method (FE) for SNNs. Specifically, given an input image, FE transforms it into the frequency domain via Discrete Fourier Transform (DFT) [34; 49]. Then, FE suppresses information of different frequencies at different time steps to decrease \((t)\) shown in the 1 term in Eq. (6). Specifically, as illustrated in Fig. 2, the information of the original image is concentrated in the low-frequency region (center area of the second column), while the noise information spans from low-frequency (center area) to high-frequency (edgearea) regions (third to fifth columns). Therefore, to remove as much frequency noise from the image as possible, the frequency suppression range gradually increases from high-frequency to low-frequency over time steps. This operator ensures that FE removes various noises present in the original image while retaining its essential information, as depicted in Fig. (3a).

Formally, denote \(^{M N}\) as the input image and \(^{F}^{M N}\) as its frequency representation, then the DFT (\(\)) between \(\) and \(^{F}\) is formulated as follows:

\[^{F}_{m,n}=(_{m,n})=_{a=0}^{M-1}_{b=0}^{N-1} {x}_{a,b}e^{-j2(a+b)},\] (7)

Figure 3: Illustration of the proposed FEEL-SNN. (a) Frequency encoding to simulate the selective visual attention in biological brain and (b) Evolutionary leak factor to simulate the non-fixed membrane potential leak in biological nervous system.

Figure 2: Visualization frequency spectrums for data observation. The first column shows three cases of original CIFAR10 images. The second column shows the corresponding frequency spectrums of the images in the first column. The third column to the seventh column shows the frequency spectrums of corresponding added noises to the images in the first column, where added noise maps the difference between the noise image and the original one. The center of each frequency spectrum represents the low-frequency information, and the edge area is the high-frequency information.

and according to the DFT, the low-frequency parts of the image is in the center of the \(^{F}\). To suppress different frequency components at different time steps, for a given time step \(t\), we update \(^{F_{i}}\) as follows:

\[^{F_{i}}^{F_{i}}\] (8)

where \(\) is element-wise multiplication. The matrix \(^{M N}\) controls the scaling of different frequencies. Intuitively, \(\) should be close to 0 for high-frequency components and close to 1 for low-frequency ones. In this study, we set \(\) to a box window with radius \(r\), defined as:

\[_{m,n}=1,&0|m|,|n| r\\ 0.&else\] (9)

The overall function of our Frequency Encoding (FE) module at time step \(t\) is then defined as:

\[}_{r_{i}}^{t}^{-1}(_{r_{i}} ^{t}^{t}()), i,t\{1,2,,T\},\] (10)

and set

\[r_{i}>r_{j}, if i<j.\] (11)

In summary, the proposed FE method, as described in Eq. (10), allows us to control the frequency mask radius \(r\) at each time step, enabling the suppression of different frequency ranges. This effectively removes noise at various frequencies, thereby enhancing the robustness of SNNs.

Evolutionary leak factor to simulate the non-fixed membrane potential leak in biological nervous system

Recalling the 1 term in Eq. (6), in addition to the proposed frequency encoding, the selection of the leak factor \(\) is also crucial for improving the robustness of SNNs. However, most existing work overlooks this aspect [8; 17]. They often assume that all neurons in the SNN adopt the same fixed leak factor at all time steps, which contradicts the membrane potential leak mechanism of the biological nervous system. In the biological nervous system, neuron membrane potential exhibits varying degrees of leak due to different environmental conditions and axon fibers [38; 13], aiming to enhance the processing of useful information , as illustrated in Fig. (1b). Therefore, in this study, we draw inspiration from the biological membrane potential leak and propose a method for training SNNs with an evolutionary membrane potential leak factor (EL).

According to 1 term in Eq. (6), a smaller leak \(\) can better constrain robustness. However, excessive leak can lead to a significant loss of effective information and a decrease in original accuracy. Thus, in our approach, we aim for EL to learn the correlation between frequencies at different time steps, building upon the foundation of FE to ensure effective information utilization. We propose a trainable leak factor training scheme instead of the leak factor regularization term in our work. Specifically, leveraging the frequency-encoded input, we assign trainable leak factors to different neurons within a layer across time steps to mitigate the propagation of noise information, as shown in Fig. (3b).

Formally, the neurons in the convolutional and fully-connected layers are defined by the LIF, as illustrated in Eq. (1)(2)(3), and finally the leak factor update is computed as:

\[_{l}^{t}=_{l}^{t}-_{l}^{t},\] (12)

\[_{l}^{t}=}{ _{l}^{t}}=}{_{l}^{t}}_{l}^{t}}{_{l}^{t}}_{l}^ {t}}{_{l}^{t}}=}{_ {l}^{t}}_{l}^{t}}{_{l}^{t}}_ {l}^{t-1},\] (13)

\[=_{CE}(x,y,,),\] (14)

where \(_{l}^{t}}{_{l}^{t}}\) is estimated by the surrogate gradient, \(_{l}^{t}}{_{l}^{t}}=} (0,-|_{l}^{t}-V_{th}|)\). \(\) denotes the constraint factor that determines the sample range to activate the gradient. \(_{CE}\) is the commonly used Cross-Entroy loss.

To sum up, our FEEL-SNN focuses on the 1 term of Eq. (6). Here, FE serves to attenuate the impact of input noise \((t)\) during each time step, while EL facilitates the continual learning of information correlations across varying time steps. This concerted effort enables a more effective utilization of useful information, thereby enhancing the robustness of the model.

## 5 Experiments

### Experimental settings

The datasets we used are CIFAR-10, CIFAR-100 , and Tiny-ImageNet . The network architectures include VGG11, WideResNet16, and ResNet19. We set \(=1.0\) in surrogate gradient and threshold \(V_{th}=1.0\) in Eq. (3) following the general settings . We adopted four training strategies to determine the effectiveness of the proposed FEEL method. The first is a vanilla training scheme (BPTT), directly using raw images for training . The second is an adversarial training strategy, which uses examples from white-box (WB) PGD attacks (\(=2/255\), iterative step \(k=2\)) for training  (abbreviated as AT). The third is to add a Lipschitz penalty proposed in  to the weights under the adversarial training setting (abbreviated as RAT). The fourth introduces the stochastic gating mechanisms to spike firing  (abbreviated as StoG). For all four strategies, we test their robustness with and without the proposed FE and FEEL methods. The attack methods include adversarial attacks (i.e., FGSM , PGD with random start , BIM , and CW , for both white-box and black-box attacks) and common noise attack (i.e., gaussian noise, GN). Since the DFT (\(\)), IDFT (\(^{-1}\)) (Eq. (7) and Eq. (10)) and frequency mask operation (\(^{F_{t}}\), Eq. (8)) are differentiable, the FE module can be directly utilized to generate adversarial perturbations.

Figure 4: Performance of the proposed FE and FEEL under different **white-box attacks**. The attack perturbation \(=4/255\) for all attacks, iterative step \(k=4\), and step size \(=0.01\) for PGD, BIM.

Figure 5: Performance of the proposed FE and FEEL under different **black-box attacks**. The attack perturbation \(=4/255\) for all attacks, and iterative step \(k=4\) for PGD, BIM.

Therefore, the adversarial perturbations are applied to the image domain before FE. In our study, for CIFAR10 and CIFAR100 dataset with \(T=4\), we set \(r=\). For CIFAR10 and CIFAR100 dataset with \(T=8\), we set \(r=\). For Tiny-ImageNet with \(T=4\), we set \(r=\). The impact of the frequency masking radius \(r\) on robustness is detailed in Section 5.3. More detailed experimental settings can be found in Appendix A.3.

### Overall performance for various attack types

**White-box attack.** First, we integrate the proposed FE and FEEL methods into the standard training (vanilla) of SNNs. We present experimental results for our method on various datasets (_i.e._, CIFAR-10, CIFAR-100, and Tiny-ImageNet) using different networks (_i.e._, VGG11, WideResNet16, and ResNet19) under white-box attacks, as summarized in Fig. 4. Our findings demonstrate that across all attacks, FE and FEEL can enhance model robustness and maintain the original accuracy. Specifically, on VGG11 with CIFAR-10, compared to the vanilla method (shown in blue bar), FEEL enhances model robustness by up to 15% and 6% against PGD and CW attacks, respectively, at time step 4. Similar trends are observed across other datasets and networks. Moreover, it is clear from the Fig. 4 that simple FE application can effectively improve the robustness of SNN, and EL can further effectively improve the robustness based on FE.

**Black-box attack.** We utilize a model trained with a different seed to generate perturbed images for black-box attacks. The efficacy of our FE and FEEL method under various attacks is illustrated in Fig. 5. Across all models and datasets, the same observation can be obtained as the white-box performance. FE and FEEL consistently outperform vanilla training. Notably, with \(T=8\), FEEL enhances robustness (attacked by CW) by up to 4.27% compared to the vanilla approach, when on WideResNet16 with CIFAR100.

**Comparison with state-of-the-art work on robustness of SNN.** To further evaluate the effectiveness of our FE and FEEL methods, we compare it with state-of-the-art (SOTA) robust SNN methods, namely AT , RAT , and StoG  in Tab. 1. From Tab. 1, we observe that FE and FEEL can enhance the original accuracy and robustness of these SOTA methods. For example, when under attack by PGD, SNN-RAT improves the robustness of the original model (Vanilla) from 0.16% to 8.87%, our FE (RAT+FE) enhances the robustness of RAT (RAT) to 9.70%. FEEL further enhances the robustness of RAT (RAT+FEEL) to 12.36%. These experimental results underscore the effectiveness of our FE and FEEL methods.

More experimental results of our FE, EL, and FEEL with different time steps, datasets, and networks can be found in Appendix. A.4.

   Methods & clean & FGSM & PGD & BIM & CW \\  Vanilla & 72.93 & 68.93 & 4.91 & 0.16 & 0.14 & 6.53 \\ Vanilla+FEEL (Ours) & 72.67 (-0.26) & **69.40 (+0.47)** & 5.18 (+0.27) & 0.31 (+0.15) & 0.24 (+0.10) & **7.63 (+1.10)** \\ Vanilla+FEEL (Ours) & **73.79 (+0.86)** & 68.05 (-0.88) & **9.60 (+4.69)** & **2.04 (+1.88)** & **1.81 (+1.57)** & 6.66 (+0.13) \\  AT  & 69.14 & 68.27 & 17.21 & 8.63 & 8.13 & 16.54 \\ AT+FEEL (Ours) & 69.34 (+0.20) & 68.67 (+0.40) & 17.65 (+0.44) & 8.92 (+0.29) & 8.33 (+0.20) & 21.49 (+4.95) \\ AT+FEEL (Ours) & **69.79 (+0.65)** & **69.02 (+0.75)** & **18.67 (+1.46)** & **11.07 (+2.44)** & **10.56 (+2.43)** & **21.78 (+5.24)** \\  RAT  & **70.03** & **69.26** & 18.88 & 8.87 & 7.93 & 20.79 \\ RAT+FEEL (Ours) & 69.74 (-0.29) & 68.35 (-0.91) & 18.74 (-0.14) & 9.70 (+0.83) & 8.91 (+0.98) & **27.16 (+6.37)** \\ RAT+FEEL (Ours) & 69.80 (-0.23) & 68.46 (-0.80) & **19.08 (+0.20)** & **12.36 (+3.49)** & **11.96 (+4.03)** & 25.52 (+4.73) \\  StoG  & 72.22 & 61.63 & 5.92 & 0.26 & 0.20 & 19.87 \\ StoG+FE (Ours) & **73.13 (+0.91)** & **67.65 (+6.02)** & 6.95 (+1.03) & 0.22 (-0.04) & 0.25 (+0.05) & 23.02 (+3.15) \\ StoG+FEEL (Ours) & 72.13 (-0.09) & 65.96 (+4.33) & **9.15 (+3.23)** & **0.55 (+0.29)** & **0.31 (+0.11)** & **24.79 (+4.92)** \\  AT+StG & 69.24 & 63.35 & 19.64 & 9.77 & 3.23 & 44.79 \\ AT+StG+FEEL (Ours) & 69.45 (+0.21) & **68.83 (+5.48)** & **20.06 (+0.42)** & 10.69 (+0.92) & 3.24 (+0.01) & 38.56 (-6.23) \\ AT+StG+FEEL (Ours) & **69.53 (+0.29)** & 68.47 (+5.12) & 18.27 (-1.37) & **11.52 (+1.75)** & **3.90 (+0.67)** & **45.18 (+0.39)** \\  RAT+StG & 69.12 & 68.37 & 20.25 & 15.43 & 6.91 & 32.08 \\ RAT+StG+FEEL (Ours) & 68.97 (+0.15) & **68.52 (+0.15)** & 31.65 (+2.40) & 17.49 (+2.06) & 8.57 (+1.66) & 47.16 (+15.08) \\ RAT+StG+FEEL (Ours) & **69.97 (+0.85)** & 68.15 (-0.22) & **31.68 (+2.43)** & **18.07 (+2.64)** & **8.89 (+1.98)** & **50.56 (+18.48)** \\   

Table 1: Performance of the proposed FE and FEEL with different training strategies. The perturbation \(=8/255\) for all attacks, and iterative step \(k=7\), step size \(=0.01\) for PGD, BIM. The dataset is CIFAR100 with \(T=8\), the network is VGG11. The improvement brought by our method is shown in parentheses.

### Ablation study

**Performance under different \(\) and iterative step \(k\).** We plot the accuracy of the white-box and black-box scenarios under PGD attack with varying \(\) and iterative step \(k\) in Fig. 6 and Fig. 7, respectively. The results indicate that the accuracy of our FEEL models decreases slowly compared to that of vanilla models.

**Rationality of FE method.** To further verify the effectiveness of FE which crops information from high-frequency to low-frequency over time steps, we compare it with an alternative strategy, Inverse-FE (IFE), which crops information from low-frequency to high-frequency over time steps. As shown in Tab. 2, IFE causes a significant drop in clean accuracy (64.81% vs. vanilla 92.64%). This demonstrates that a substantial amount of valid information is lost, verifying that valid information is concentrated in the low-frequency area. In contrast, FE not only effectively removes noise (21.56% vs. vanilla 15.59% when under PGD attack) but also minimizes the loss of valid information (92.26% vs. vanilla 92.64%).

**Effect of frequency masking radius \(r\) on robustness.** We investigate the frequency masking radius \(r\) on robustness to SNNs, defined in Eq. (9), which governs the degree of frequency suppression at each time step. We present three different strategies to illustrate the superiority of our method as shown in Tab. 3. The first strategy employs a direct encoding method, wherein the frequency information outside a fixed radius \(r\) is removed from each original image, followed by T-step image replication (using a different \(r\) for each image, akin to data augmentation), as depicted in the first row of Tab. 3. The second strategy utilizes FE but with a uniform radius \(r\) across all time steps, as shown in rows 2 to 5 of Tab. 3. The third strategy is the FE method proposed in this study, where a different \(r\) is applied to each time step to remove as many noise frequencies as possible, as depicted in the last row of Tab. 3. From Tab. 3, we observe that across various \(r\) selections, our method outperforms the first and second strategies in all attack scenarios.

**Rationality of EL method.** According to Eq. (2), the leak factor controls the residual membrane potential between time steps. A smaller leak factor may lead to a weakened temporal modeling capability of the SNN, leading to a decline in network performance . Considering the leak factor's

   Method & Clean & GN & FGSM & PGD & BIM & CW \\  Vanilla & **92.64** & 91.28 & 35.47 & 15.59 & 14.95 & 6.92 \\ IFE & 64.81 & 64.48 & 12.33 & 4.44 & 4.25 & 4.18 \\ FE & 92.26 & **92.02** & **39.67** & **21.56** & **21.05** & **10.12** \\   

Table 2: Performance (%) of the proposed Frequency Encoding (FE) and the alternative strategy Inverse-FE (IFE). The perturbation \(=4/255\) for all attacks, and iterative step \(k=4\), step size \(=0.01\) for PGD. The dataset is CIFAR10 with time step \(T=4\), the network is VGG11.

Figure 6: Performance of the white-box (WB) and black-box (BB) scenarios under PGD attack with different perturbation \(\), the iterative step \(k=4\), the network is VGG11.

Figure 7: Performance of the white-box (WB) and black-box (BB) scenarios under PGD attack with different iterative step \(k\), the perturbation \(=4/255\), the network is VGG11.

dual role in original information transmission (Eq. (2)) and robustness enhancement (Eq. (6)), we propose EL. The EL dynamically learns the optimal robustness leak factor across different time steps and neurons, which also increases the expression capability of SNN, helping maintain clean accuracy and improving robustness. We further compare EL with two alternative strategies. The first strategy sets all leak factors to 0. The second strategy, termed Reg-EL (REL), adds L2 regularization to the EL to further constrain the leak factor. As shown in Tab. 6 in Appendix. A.4, a small leak factor significantly reduces clean accuracy (vanilla 92.64% vs. REL 88.52% vs. EL with \(=0.0\) at 81.76%), consistent with analysis above. Besides, a small leak factor does increase the robustness of SNN (\(e.g.\), under PGD attack, EL with \(=0.0\) is 63.80%, REL is 29.98%, compared to vanilla 15.59%). This also aligns with the proposed robustness framework (Eq. (6)) by demonstrating that controlling the leak factor improves robustness. And our EL method ensures improvements in both robustness and original accuracy (\(e.g.\), the PGD defense accuracy of EL is 30.27%, compared to 15.59% for vanilla, and the clean accuracy of EL is 92.73%, compared to 92.64% for vanilla). In Appendix. A.4, we further verify the proposed EL does not destroy the impact of other terms in Eq. (6) on the robustness of SNN.

All the above experimental results illustrate the rationality and effectiveness of our method.

## 6 Conclusions and Discussions

**Conclusion:** In this study, drawing inspiration from the selective visual attention and dynamic membrane potential leak observed in biological nervous systems, we introduce a robust SNN with Frequency Encoding and Evolutionary membrane potential Leak factor (FEEL-SNN). Specifically, our approach theoretically presents a unified framework for SNN robustness, demonstrating that refining the encoding technique and evolving the membrane potential leak factor can enhance SNN robustness. Then we propose a novel image encoding method for SNNs, termed frequency encoding (FE). FE captures information of varying frequencies at different time steps, which preserves the original information while suppressing different frequency range noises, effectively filtering out image noise. Building upon FE, we propose an evolutionary leak factor (EL). EL ensures that different neurons in the network learn the optimal robustness leak factor at different time steps. It facilitates the continual learning of information correlations across varying time steps, enabling more effective utilization of pertinent information and thereby enhancing SNN robustness. Experimental results validate that both our FE and EL methods can effectively improve the robustness of SNN to different noises, and can be used in conjunction with other methods to improve the robustness further.

**Limitation:** Our focus has been primarily on static datasets. In future work, how to propose a reliable and effective encoding method for the DVS datasets is a topic worthy of study.

**Broader Impact:** In neuroscience, the selective visual attention and non-fixed membrane potential leak are considered to contribute to the robustness of biological nervous systems. By using SNN as a research tool, computational modeling of biological nervous systems can be further facilitated. We can contribute valuable insights to ongoing discussions in neuroscience regarding robustness.

## 7 Acknowledgement

This work was supported in part by the STI 2030 Major Projects under Grant 2021ZD0200400, in part by the National Natural Science Foundation of China (61925603, 62376247, U20A20220, and 62334014), and in part by the grants from Key R&D Program of Zhejiang (2022C01048).

   } &  &  &  &  &  &  &  \\  Direct & \([r_{0}]_{4},[r_{1}]_{4},[r_{2}]_{4},[r_{3}]_{4}\) & 70.88 & 69.73 & 14.43 & 4.33 & 4.19 & 6.21 \\ FE & \([r_{4}]_{4}\) & 62.01 & 60.73 & 9.47 & 2.28 & 2.17 & 4.79 \\ FE & \([r_{3}]_{4}\) & 68.78 & 67.55 & 13.62 & 4.74 & 4.35 & 6.37 \\ FE & \([r_{2}]_{4}\) & 69.96 & 69.26 & 14.60 & 5.38 & 5.20 & 6.87 \\ FE & \([r_{1}]_{4}\) & 70.95 & 70.39 & 15.72 & 5.41 & 5.22 & 7.45 \\ FE (Ours) & \([r_{0},r_{1},r_{2},r_{3}]\) & **71.40** & **70.59** & **16.80** & **6.89** & **6.62** & **8.09** \\   

Table 3: Effect of frequency masking radius \(r\) on robustness. The attack is PGD with perturbation \(=4/255\), iterative step \(=0.01\), and iterative step \(k=4\). The dataset is CIFAR10 with \(T=4\), the network is VGG11. \(r_{0}=16,r_{1}=14,r_{2}=12,r_{3}=10,r_{4}=6\)