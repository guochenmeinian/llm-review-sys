# Learning Interpretable Low-dimensional Representation via Physical Symmetry

Xuanjie Liu\({}^{1,2}\) Daniel Chin\({}^{1,2}\) Yichen Huang\({}^{1}\) Gus Xia\({}^{1,2}\)

\({}^{1}\)Mohamed bin Zayed University of Artificial Intelligence

\({}^{2}\)New York University Shanghai

{Xuanjie.Liu, Nanfeng.Qin, Yichen.Huang, Gus.Xia}@mbzuai.ac.ae

###### Abstract

We have recently seen great progress in learning interpretable music representations, ranging from basic factors, such as pitch and timbre, to high-level concepts, such as chord and texture. However, most methods rely heavily on music domain knowledge. It remains an open question what general computational principles _give rise to_ interpretable representations, especially low-dim factors that agree with human perception. In this study, we take inspiration from modern physics and use _physical symmetry_ as a self-consistency constraint for the latent space of time-series data. Specifically, it requires the prior model that characterises the dynamics of the latent states to be _equivariant_ with respect to certain group transformations. We show that physical symmetry leads the model to learn a _linear_ pitch factor from unlabelled monophonic music audio in a self-supervised fashion. In addition, the same methodology can be applied to computer vision, learning a 3D Cartesian space from videos of a simple moving object without labels. Furthermore, physical symmetry naturally leads to _counterfactual representation augmentation_, a new technique which improves sample efficiency.

## 1 Introduction

Interpretable representation-learning models have achieved great progress for various types of time-series data. Taking the _music_ domain as an example, tailored models  have been developed to learn pitch, timbre, melody contour, chord progression, texture, etc. from music audio. These human-interpretable representations have greatly improved the performance of generative algorithms in various music creation tasks, including inpainting , harmonization , (re-)arrangement, and performance rendering .

However, most representation learning models still rely heavily on domain-specific knowledge. For example, to use pitch scales or instrument labels for learning pitch and timbre representations  and to use chords and rhythm labels for learning higher-level representations . Such an approach is presumably very different from human learning; even without formal music training, we see that many people can learn _pitch_, a fundamental music concept, simply from the experience of listening to music. Hence, it remains an open question how to learn interpretable pitch factor using inductive biases that are more general. In other words, _what general computational principle gives rise to the concept of pitch_.

We see a similar issue in other domains. For instance, various computer-vision models  can learn3D representations of human faces or a particular scene by using domain knowledge (e.g., labelling of meshes and voxels, 3D convolution, etc.) But when these domain setups are absent, it remains a non-trivial task to learn the 3D location of a simple moving object in a self-supervised fashion.

Inspired by modern physics, we explore to use _physical symmetry_ (i.e., symmetry of physical laws) as a weak self-consistency constraint for the learned latent \(z\) space of time-series data \(x\). As indicated in Figure 1, this general inductive bias requires the learned prior model \(R\), which is the induced physical law describing the temporal flow of the latent states, to be equivariant to a certain transformation \(S\) (e.g., translation or rotation). Formally, \(z_{t+1}=R(z_{t})\) if and only if \(z_{t+1}^{S}=R(z_{t}^{S})\), where \(z^{S}=S(z)\). In other words, \(R\) and \(S\) are commutable for \(z\), i.e., \(R(S(z))=S(R(z))\). Note that our equivariant assumption applies only to the latent \(z\) space. This is fundamentally different from most existing symmetry-informed models , in which the equivariant property also imposes assumptions on the raw data space.

Specifically, we design self-supervised learning with **p**hysical **s**ymmetry (**SPS**)1, a method that adopts an encoder-decoder framework and applies physical symmetry to the prior model. We show that SPS learns a _linear_ pitch factor (that agree with human music perception) from monophonic music audio without any domain-specific knowledge about pitch scales, f0, or harmonic series. The same methodology can be applied to the computer vision domain, learning 3D Cartesian space from monocular videos of a bouncing ball shot from a fixed perspective. In particular, we see four desired properties of SPS as a self-supervised algorithm for interpretability:

* Section 4.)
* Section 5.2.)
* **Robustness**: Even with an incorrect symmetry assumption, SPS can still learn more interpretable representations than baselines. (See Section 5.3.)
* **Extendability**: SPS can be easily combined with other learning techniques. For example, if we _further_ assume an extra global invariant style code, the model becomes a disentangled sequential autoencoder, capable of learning content-style disentanglement from temporal signals. (See appendix.)

## 2 Intuition

The idea of using physical symmetry for representation learning comes from modern physics. In classical physics, scientists usually first induce physical laws from observations and then discover symmetry properties of the law. (E.g., Newton's law of gravitation, which was induced from planetary orbits, is symmetric with respect to Galilean transformations.) In contrast, in modern physics, scientists often start from a symmetry assumption, based on which they derive the corresponding law and predict the properties (representations) of fundamental particles. (E.g., general relativity was developed based on a firm assumption of symmetry with respect to Lorentz transformations).

Figure 1: An illustration of physical symmetry as our inductive bias.

Analogously, we use physical symmetry as an inductive bias of our representation learning model, which helps us learn a regularised prior and an interpretable low-dim latent space. If it is a belief of many physicists that symmetry in physical law is a major design principle of nature, we regard symmetry in physical law as a general inductive bias of perception. In other words, if physical symmetry leads an AI agent to learn human-aligned concepts in a self-supervised fashion, we believe that it could also provide insights into the ways that human minds perceive the world.

The introduction of physical symmetry naturally leads to **counterfactual representation augmentation**, a novel learning technique which helps improve sample efficiency. Representation augmentation means to "imagine" extra pairs of \(z_{t}^{S}\) and \(z_{t+1}^{S}\) as training samples for the prior model \(R\). Through the lens of causality, this augmentation can be seen as a _counterfactual_ inductive bias of the prediction on the representation level - _what if_ the prior model makes predictions based on _transformed_ latent codes? As indicated in Figure 1, it requires the prediction of the \(z\) sequence to be _equivariant_ to certain group transformations, \(S\). This regularisation also constrains the encoder and decoder _indirectly through the prior model_ since the network is trained in an end-to-end fashion.

## 3 Methodology

With physical symmetry, we aim to learn an interpretable low-dimensional representation \(z_{i}\) of each high-dimensional sample \(x_{i}\) from time-series \(_{1:T}\). We focus on two problems in this paper: 1) to learn a _1D linear_ pitch factor of music notes from music audio, where each \(x_{i}\) is a spectrogram of a note, and 2) to learn _3D Cartesian location_ factors of a simple moving object (a bouncing ball) from its trajectory shot by a fixed, single camera, where each \(x_{i}\) is an image.

### Model

Figure 2 shows the model design of SPS. During the training process, the temporal data input \(_{1:T}\) is first fed into the encoder \(E\) to obtain the corresponding representation \(_{1:T}\). Then it is fed into _three_ branches. In the first branch (the green line), \(_{1:T}\) is decoded directly by the decoder \(D\) to reconstruct \(_{1:T}^{}\). In the second branch (the orange line), \(_{1:T}\) is passed through the prior model \(R\) to predict its next timestep, \(}_{2:T+1}\), which is then decoded to reconstruct \(}_{2:T+1}\). In the third branch (the blue line), we transform \(_{1:T}\) with \(S\), pass it through \(R\), and transform it back using the inverse transformation \(S^{-1}\) to predict another version of the next timestep \(}_{2:T+1}\), and finally decode it to \(}_{2:T+1}\). We get three outputs from the model: \(_{1:T}^{}\), \(}_{2:T+1}\), and \(}_{2:T+1}\).

The underlying idea of physical symmetry is that the dynamics of latent factor and its transformed version _follow the same physical law_ characterised by \(R\). Therefore, \(}\) and \(}\) should be close to each other and so are \(}\) and \(}\), assuming \(S\) is a proper transformation. This self-consistency constraint helps the network learn a more regularised latent space.

Figure 2: An overview of our model. \(_{1:T}\) is fed into the encoder \(E\) to obtain the corresponding representation \(_{1:T}\), which is then fed into three different branches yielding three outputs respectively: \(_{1:T}^{}\), \(}_{2:T+1}\) and \(}_{2:T+1}\). Here, \(R\) is the prior model and \(S\) is the symmetric operation. The inductive bias of physical symmetry enforces \(R\) to be equivaraint with respect to \(S\), so \(}\) and \(}\) should be close to each other and so are \(}\) and \(}\).

### Training objective

The total loss contains four terms: reconstruction loss \(_{}\), prior prediction loss \(_{}\), symmetry-based loss \(_{}\), and KL divergence loss \(_{}\). Formally,

\[=_{}+_{1}_{}+ _{2}_{}+_{3}_{},\] (1)

where \(_{1}\), \(_{2}\) and \(_{3}\) are weighting parameters. By referring to the notations in section 3.1,

\[_{}=_{}(_{1:T}^{}, _{1:T})+_{}(}_{2:T},_{ 2:T})+_{}(}_{2:T},_{2:T})\] (2)

\[_{}=_{2}(}_{2:T},_{2:T}),\] (3)

\[_{}=_{2}(}_{2:T},}_{ 2:T})+_{2}(}_{2:T},_{2:T}).\] (4)

\(_{}\) is the Kulback-Leibler divergence loss between the prior distribution of \(z_{i}\) and a standard Gaussian. Lastly, we build two versions of SPS: SPSVAE and SPSAE, with the latter replacing the VAE with an AE (and trivially doesn't have \(_{}\)).

### Symmetry-based counterfactual representation augmentation

During training, \(S\) is the _counterfactual representation augmentation_ since it creates extra imaginary sequences of \(z\) (i.e., imaginary experience) to help train the prior. In practice, for each batch we apply \(K\) different transformations \(S_{1:K}\) to \(\) and yield \(K\) imaginary sequences. Thus, the two terms of symmetry-based loss can be specified as:

\[_{2}(}_{2:T},_{2:T})=_{k=1}^{K} _{2}(S_{k}^{-1}(R(S_{k}(_{1:T-1}))),_{2:T})\] (5)

\[_{2}(}_{2:T},}_{2:T})=_{k=1 }^{K}_{2}(S_{k}^{-1}(R(S_{k}(_{1:T-1}))),}_{2:T})\] (6)

where the lower case \(k\) denotes the index of a specific transformation and we refer to \(K\) as the _augmentation factor_. Likewise, the last term of reconstruction loss can be specified as:

\[_{}(}_{2:T},_{2:T})= {K}_{k=1}^{K}_{}(D(S_{k}^{-1}(R(S_{k}(_{1: T-1})))),_{2:T})\] (7)

Each \(S\) applied to each sequence \(_{1:T}\) belongs to a certain group, and different groups are used for different problems. For the music problem, we assume \(_{i}\) be to 1D and use random \(S G(,+)\). In other words, we add a random scalar to the latent codes. As for the video problem, we assume \(_{i}\) be to 3D and use random \(S G(^{2},+)(2)\). In other words, random rotation and translation are applied on two dimensions of \(_{i}\).

## 4 Results

We test SPS under two modalities of temporal signals: music (section 4.1) and video (section 4.2). Each model is executed with 10 random initialisations, and evaluated on the test set. The highlight of this section is that SPS effectively learns interpretable low-dimensional factors that align with human perceptions. Also, by utilizing _small_ training sets, we show the _high sampling efficiency_ of our model. In the appendix, we further show that SPS also maintains accuracy in both reconstruction and prediction tasks (section A.2). Additionally, we present supplementary results trained on more complicated datasets and a more advanced configuration of our model, called SPS+, which enables content-style disentanglement in addition to interpretable learning. The findings from these more complex scenarios align closely with those observed in the simpler cases presented in this section.

### Learning linear pitch factor from music audio

#### 4.1.1 Dataset and training setups

We synthesise a training dataset of 27 audio clips, each containing 15 notes in major scales with the first 8 notes ascending and the last 8 notes descending. We vary the starting pitch by integer numbers of MIDI pitch such that every MIDI pitch in the range A#4 to C7 is present in the training set. Only the accordion is used to generate the clips. For each clip in the training set, we uniformly randomly shift its pitch upwards by a decimal between 0 and 1, in this way generate the test set for evaluation.

We convert each audio clip into a sequence of image segments for processing. First, we run STFT (with sample rate \(=16000/s\), window length \(=1024\), hop length \(=512\), with no padding and no logarithmic frequency scale) over each audio clip to obtain a power spectrogram. After normalising the energy to the range \(\), we slice the power spectrogram into fifteen image segments, each containing one note. The CNN encoder, in each timestep, takes one segment as input. For the latent space, we assume \(_{i}\) and sample counterfactual representation augmentation \(S([-1,1])\) where \(S G(,+)\). Note this assumption does not indicate any domain-specific inductive bias of music, such as the logarithmic relationship between pitch and frequency or the relationship between F0 and harmonics.

#### 4.1.2 Results on interpretable pitch space

Figure 3 demonstrates that the 1D pitch factor learned by our model exhibits a linear relationship with the conventional numerical ordering used to represent pitch by humans (e.g. MIDI pitch numbers). The plot shows the mappings of two tasks and six models. In the embedding task (the first row), the \(x\)-axis is the true pitch and the \(y\)-axis is embedded \(\). In the synthesis task (the second row), the \(x\)-axis is \(\) and the \(y\)-axis is the detected pitch (by YIN algorithm, a standard pitch-estimation method by ) of decoded (synthesised) notes. The first two models are SPS based on VAE and AE, respectively, trained with counterfactual representation augmentation factor \(K=4\). The third and fourth models are trained without constraints of physical symmetry (\(K=0\)), serving as our ablations. The fifth one is a vanilla \(\)-VAE, trained only to reconstruct, not to predict. The last one is SPICE , a SOTA unsupervised pitch estimator _with strong domain knowledge on how pitch linearity is reflected in log-frequency spectrograms_. As the figure shows, 1) without explicit knowledge of pitch, our model learns a more interpretable pitch factor than \(\)-VAE, and the result is comparable to SPICE, and 2) without the Gaussian prior assumption of latent variable distribution, our model SPS\({}_{}\) also learns a continuous representation space.

Figure 3: A visualisation of the mapping between the 1D learned factor \(\) and the true pitch, in which a straight lines indicates a better result. In the upper row, models encode notes in the test set to \(\). The \(x\) axis shows the true pitch and the \(y\) axis shows the learned pitch factor. In the lower row, the \(x\) axis traverses the \(\) space. The models decode \(\) to audio clips. We apply YIN to the audio clips to detect the pitch, which is shown by the \(y\) axis. In both rows, a linear, noiseless mapping is ideal, and our method performs the best.

Table 1 shows a more quantitative analysis using \(R^{2}\) as the metric to evaluate the linearity of the pitch against \(z\) mapping from the encoder and the decoder. All models except SPICE are trained with 10 random initializations.

### Learning object 3D coordinates from videos of a moving object

#### 4.2.1 Dataset and training setups

We run physical simulations of a bouncing ball in a 3D space. The ball is randomly thrown and affected by gravity and the bouncing force (elastic force). A fixed camera records a 20-frame video of each 4-second simulation to obtain one trajectory (see Figure 4). The ball's size, gravity, and proportion of energy loss per bounce are constant across all trajectories. For each trajectory, the ball's initial location and initial velocity are randomly sampled. We utilize 512 trajectories for training, and an additional 512 trajectories for evaluation.

For the latent space, we set the dimension of the latent space to 3, but only constrain 2 of them by augmenting the representations with \(S G(^{2},+)(2)\). Those two dimensions are intended to span the horizontal plane. The third one, which is the unaugmented latent dimension, is intended to encode the vertical height.

#### 4.2.2 Results on interpretable 3D representation

Figure 5 visually evaluates the interpretability of the learned location factors by traversing the \(z\) space, one dimension at a time, and using the learned decoder to synthesise images. If the learned factors are linear w.r.t. the 3D Cartesian coordinates, the synthesised ball should display linear motions as we change \(z\) linearly. In brief, SPS learns an a more interpretable and linear \(z\) space. Here, subplot (a) depicts the results of SPSVAE with \(K\)=4. We see that the un-augmented dimension, \(z_{2}\), controls the height of the ball, while \(z_{1}\) and \(z_{3}\) move the ball along the horizontal (ground) plane. Each axis is much more linear than in (b) and (c). Subplot (b) evaluates SPSVAE with counterfactual representation augmentation \(K\)=0, essentially turning _off_ SPS. As \(z_{i}\) varies, the ball seems to travel along curves in the 3D space, showing the ablation learns some continuity w.r.t. the 3D space, but is obviously far from linear. In (c), the \(\)-VAE fails to give consistent meaning to any axis.

Table 2 further shows quantitative evaluations on the linearity of the learned location factor, in which we see that SPS outperforms other models by a large margin. To measure linearity, we fit a linear regression from \(z\) to the true 3D location over the test set and then compute the Mean Square Errors (MSE). Therefore, a smaller MSE indicates a better fit. To give an intuitive example, the MSEs of (a), (b) and (c) in Figure 5 are 0.09, 0.58 and 0.62 respectively. Here, we also include the results of SPSAE. Very similar to the music experiment in session 4.1, we again see that even without the Gaussian prior assumption, our model SPSAE learns an interpretable latent space comparable to SPSVAE.

   Methods & Learned factor \(R^{2}\) & Synthesis \(R^{2}\) \\  SPSVAE, \(K\)=4 (Ours) & 0.999\(\)0.001 & **0.986\(\)0.025** \\ SPSAE, \(K\)=4 (Ours) & 0.998\(\)0.001 & **0.986\(\)0.025** \\ SPSVAE, \(K\)=0 (Ablation) & 0.997\(\)0.002 & 0.910\(\)0.040 \\ SPSAE, \(K\)=0 (Ablation) & 0.993\(\)0.006 & 0.832\(\)0.129 \\ \(\)-VAE & 0.772\(\)0.333 & 0.534\(\)0.275 \\ SPICE & **1.000** & N/A \\   

Table 1: The linearity of learned pitch factor and synthesized sound pitch evaluated by \(R^{2}\).

Figure 4: Two example trajectories from the bouncing ball dataset.

## 5 Analysis

To better understand the effects of counterfactual representation augmentation (first introduced in section 3.3), we ran extra experiments with different \(S\) and \(K\). We choose the vision problem since a 3D latent space manifests a more obvious difference when physical symmetry is applied. In section 5.1, we show that a larger augmentation factor \(K\) leads to higher sample efficiency. In section 5.2, we visualise the change of learned latent space against training epoch according to different values of \(K\). In section 5.3, we show that some deliberately incorrect group assumptions \(S\) can also achieve good results.

### Counterfactual representation augmentation improves sample efficiency

Figure 6 shows that _a larger factor of counterfactual representation augmentation leads to a lower linear projection loss_ (the measurement defined in section 4.2.2) of the learned 3D representation. Here, \(K\) is the augmentation factor, and \(K=0\) means the model is trained without physical symmetry. The comparative study is conducted on 4 training set sizes (256, 512, 1024, and 2048), in which each box plot shows the results of 10 experiments trained with a fixed \(K\) and random initialisation. We see that a larger \(K\) leads to better results and compensates for the lack of training data. E.g., the loss trained on 256 samples with \(K=4\) is comparable to the loss trained on 1024 samples with \(K=0\), and the loss trained on 512 samples with \(K=4\) is even lower than the loss trained on 2048 samples with \(K=0\). Furthermore, when \(K=0\), increasing the number of training samples beyond a certain point does not further shrink the error, but increasing \(K\) still helps.

### Counterfactual representation augmentation improves interpretability

Figure 7 visualises the latent space during different stages of model training, and we see that a larger \(K\) leads to a better enforcement of interpretability. The horizontal axis shows the training epoch. Three experiments with different \(K\) values (\( 0\), \( 4\), \( 16\)) are stacked vertically. Each experiment is

   Method & \(x\) axis MSE \(\) & \(y\) axis MSE \(\) & \(z\) axis MSE \(\) & MSE \(\) \\  SPSVAE, \(K\)=4 (Ours) & **0.11 \(\) 0.09** & **0.31 \(\) 0.34** & 0.26 \(\) 0.34 & 0.26 \(\) 0.30 \\ SPSAE, \(K\)=4 (Ours) & 0.13 \(\) 0.07 & 0.39 \(\) 0.33 & **0.21 \(\) 0.17** & **0.24 \(\) 0.17** \\ SPSVAE, \(K\)=0 (Ablation) & 0.33 \(\) 0.10 & 0.80 \(\) 0.18 & 0.75 \(\) 0.17 & 0.62 \(\) 0.14 \\ SPSAE, \(K\)=0 (Ablation) & 0.26 \(\) 0.09 & 0.44 \(\) 0.27 & 0.55 \(\) 0.17 & 0.42 \(\) 0.15 \\ \(\)-VAE & 0.36 \(\) 0.03 & 0.70 \(\) 0.01 & 0.68 \(\) 0.03 & 0.58 \(\) 0.01 \\   

Table 2: Linear fits between the true location and the learned location factor. We run the encoder on the test set to obtain data pairs in the form of (location factor, true coordinates). We then run a linear fit on the data pairs to evaluate factor interpretability. Two outliers are removed from the 50 runs.

Figure 5: A visualisation of latent-space traversal performed on three models: (a) ours, (b) ablation, and (c) baseline, in which we see (a) achieves better linearity and interpretability. Here, row \(i\) shows the generated images when changing \(z_{i}\) and keeping \(z_{ i}=0\), where the \(x\) axis varies \(z_{i}\) from \(-2_{z}\) to \(+2_{z}\). We center and normalise \(z\), so that the latent space from different runs is aligned for fair comparison. Specifically, in (a), changing \(z_{2}\) controls the ball’s height, and changing \(z_{1},z_{3}\) moves the ball parallel to the ground plane. In contrast, the behavior in (b) and (c) are less interpretable.

trained twice with random initialisation. Each subplot shows the orthogonal projection of the \(z\) space onto the plane spanned by \(z_{1}\) and \(z_{3}\), therefore hiding most of the \(y\)-axis (i.e. ball height) wherever a linear disentanglement is fulfilled. During training, the role of physical symmetry is to "straighten" the encoded grid and a larger \(K\) yields a stronger effect.

### Counterfactual representation augmentation with deliberately incorrect group assumptions

Additionally, we test SPS with deliberately incorrect group assumptions. The motivation is as follows. In real applications, researchers may incorrectly specify the symmetry constraint when the data are complex or the symmetry is not known _a priori_. SPS is more useful if it works with various groups assumptions close to the truth. In our analysis, we are surprised to find that SPS still learns interpretable representations under alternate group assumptions via perturbing the correct one.

Figure 8 shows our results with the vision task (on the bouncing ball dataset). The \(x\) tick labels show the augmentation method. Its syntax follows section 3.3, e.g., "\((^{1},+)(2)\)" denotes augmenting representations by 1D translations and 2D rotations. The \(y\) axis of the plot is still linear projection loss (as discussed in section A.5.3) that evaluates the interpretability of the learned representation. As is shown by the boxplot, five out of five perturbed group assumptions yield better results than the "w/o Symmetry" baseline. Particularly, \((^{3},+)(2)\) and \((^{2},+)(3)\) learn significantly more linear representations, showing that some symmetry assumptions are "less incorrect" than others, and that SPS can achieve good results under a multitude of group assumptions.

Figure 6: A comparison of linear projection MSEs among different augmentation factors (\(K\)) and training set sizes, which shows that counterfactual representation augmentation improves sample efficiency.

Figure 7: A visualisation of the learned latent space against training epoch, in which we see that a larger \(K\) leads to a stronger enforcement on learning a linear latent space. Here, we plot how the encoder projects an equidistant 3D grid of true Cartesian coordinates onto the \(z\) space. Different colours denote respective axes in the true coordinates.

## 6 Related work

The idea of using a predictive model for better self-supervised learning has been well established . In terms of model architecture, our model is very similar to VRNN . In addition, our model can be seen as a variation of joint-embedding predictive architecture (JEPA) in  if we eliminate the reconstruction losses on the observation. In fact, we see the network topology of a model as the "hardware" and see the learning strategy (e.g., contrastive method, regularised method, or a mixed one) as the "software". The main contribution of this study lies in the learning strategy -- to use physical symmetry to limit the complexity of the prior model, and to use counterfactual representation augmentation to increase sample efficiency.

The existing notation of "symmetry" as in  is very different from physical symmetry as an inductive for representation learning. Most current symmetry-based methods care about the relation between observation \(x\) and latent \(z\). E.g., when a certain transformation is applied to \(x\), \(z\) should simply keep invariant or follow a same/similar transformation. Such an assumption inevitably requires some knowledge in the domain of \(x\). In contrast, physical symmetry focuses solely on the dynamics of \(z\), and therefore we only have to make assumptions about the underlying group transformation in the latent space. We see two most relevant works in the field of reinforcement learning , which apply an equivariant assumption similar to the physical symmetry used in this paper. The major differences are twofold. First, to disentangle the basic factors, our method requires no interactions with the environment. Second, our method is much more concise; it needs no other tailored components or other inductive biases such as symmetric embeddings network and contrastive loss used in  or MDP homomorphism applied in .

## 7 Limitation

We have identified several limitations in the generality and soundness of SPS. Firstly, when the underlying concept following physical symmetry only contains partial information of the time series and cannot fully reconstruct the inputs, SPS may not function properly. We hypothesize that this issue is connected to content-style disentanglement, and present some preliminary results in appendix A.4 and A.5. Secondly, the current model lacks the ability to distill concepts from multibody systems. For example, it is unable to learn the concept of pitch from polyphonic music or understand 3D space from videos featuring multiple moving objects. Lastly, it is essential to develop a formalized theory for quantifying the impact of counterfactual representation augmentation in future work. This would involve measuring the degree of freedom in the latent space with and without physical symmetry, and explaining why incorrect symmetry assumptions can still result in a correct and interpretable latent space.

Figure 8: Evaluation on various group assumptions, which shows that physical symmetry is a very robust inductive bias as even the incorrect symmetry assumptions lead to better results than baseline. Here, the \(y\) axis is linear projection loss between the learned location factor and the true coordinates, so a lower value means better interpretability of representations. The leftmost box shows the baseline without symmetry constraint. The next five boxes show five deliberately _incorrect_ group assumptions, trained with \(K\)=4. The rightmost box shows the correct group assumption.

Conclusion

In this paper, we use physical symmetry as a novel inductive bias to learn interpretable and low-dimensional representations from time-series data. Experiments show that physical symmetry effectively distills an interpretable linear pitch concept, which agrees with human music perception, from music audios without any labels. With the same method, we can learn the concept of 3D Cartesian space from monocular videos of bouncing ball shot from a fixed perspective. In addition, a robust training technique, counterfactual representation augmentation, is developed to enforce physical symmetry during training. Analysis shows that counterfactual representation augmentation leads to higher sample efficiency and better latent-space interpretability, and it stays effective even when the symmetry assumption is incorrect. Last but not least, we see that with physical symmetry, our sequential representation learning model can drop the the Gaussian prior regulation on the latent space. Such a result empirically indicates that physical symmetry, as a causal (counterfactual) inductive bias, might be more essential compared to the Gaussian prior as a purely statistical regularization.

#### Acknowledgments

We'd like to thank to Dr. Zhao Yang and Dr. Maigo Wang for inspiring discussion on physical symmetry. Also, we'd like to like to extend our sincere thanks to Junyan Jiang and Yixiao Zhang for their useful and practical suggestions.