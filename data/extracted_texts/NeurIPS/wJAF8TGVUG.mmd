# S-MolSearch: 3D Semi-supervised Contrastive Learning for Bioactive Molecule Search

Gengmo Zhou\({}^{1,2}\), Zhen Wang\({}^{2}\), Feng Yu\({}^{2}\), Guolin Ke\({}^{2}\), Zhewei Wei\({}^{1}\), Zhifeng Gao\({}^{2}\)

\({}^{1}\)Renmin University of China \({}^{2}\)DP Technology

{zgm2015, zhewei}@ruc.edu.cn, {wangz, yufeng, kegl, gaozf}@dp.tech

Equal contribution.Corresponding authors.

###### Abstract

Virtual Screening is an essential technique in the early phases of drug discovery, aimed at identifying promising drug candidates from vast molecular libraries. Recently, ligand-based virtual screening has garnered significant attention due to its efficacy in conducting extensive database screenings without relying on specific protein-binding site information. Obtaining binding affinity data for complexes is highly expensive, resulting in a limited amount of available data that covers a relatively small chemical space. Moreover, these datasets contain a significant amount of inconsistent noise. It is challenging to identify an inductive bias that consistently maintains the integrity of molecular activity during data augmentation. To tackle these challenges, we propose S-MolSearch, the first framework to our knowledge, that leverages molecular 3D information and affinity information in semi-supervised contrastive learning for ligand-based virtual screening. Drawing on the principles of inverse optimal transport, S-MolSearch efficiently processes both labeled and unlabeled data, training molecular structural encoders while generating soft labels for the unlabeled data. This design allows S-MolSearch to adaptively utilize unlabeled data within the learning process. Empirically, S-MolSearch demonstrates superior performance on widely-used benchmarks LIT-PCBA and DUD-E. It surpasses both structure-based and ligand-based virtual screening methods for AUROC, BEDROC and EF.

## 1 Introduction

Virtual Screening [1; 2; 3; 4] plays a crucial role in the early stages of drug discovery by identifying potential drug candidates from large molecular libraries. Structure-Based Virtual Screening (SBVS) [5; 6; 7; 8], a widely used virtual screening method, attempts to predict the best interaction between ligands against a protein target to form a protein-ligand complex. Recently, deep learning methods have also been explored. Methods trained on affinity labels [9; 10; 11] conduct virtual screening by modeling binding affinities and ranking based on prediction. Additionally, a method  uses similarities between embedding of pockets and molecules to search for active molecules. However, these SBVS methods cannot escape the dependency on the structure of protein targets, which is unavailable for challenging or novel targets, such as disordered proteins like c-Myc, limiting the applicability of SBVS. Besides, plenty of assays used in Virtual Screening  are cell-based rather than target-specific, introducing noise into the active molecules since their activity is not entirely dependent on interaction with the protein target.

To remedy this, Ligand-Based Virtual Screening (LBVS) [14; 15; 16; 17; 18] searches similar molecules via known bioactive molecules and does not depend on the structure of protein targets, which has attracted increasing attention. Computational LBVS methods [19; 20; 18] rigidly employstructural similarity to search for molecules, often using atom-centered, smooth Gaussian overlays to assess molecular similarity. Searching for bioactive molecules needs to consider both structure and electronic similarity. Some methods  also require charge comparison, which is expensive and time-consuming. These methods struggle with inefficiency when handling large databases. Moreover, since only structural or charge information is considered while affinity is ignored, even if molecules with similar structures or charges are identified, they may still exhibit poor affinity in practical applications due to activity cliffs .

A natural question arises: how can we enhance LBVS by collecting molecule similarity data from large-scale unlabeled molecules? To search both similar and bioactive molecules, we can choose those bioactive molecules that bind to the same protein. Meanwhile, labeled molecule-protein binding data is limited due to the expensive affinity acquisition. Also various standards [22; 13] across different datasets, introducing substantial noise. It is difficult to cover the searching chemical space with affinity data alone. A feasible solution is to leverage similarity from finite affinity data to broader chemical space.

Inspired by the success of contrastive learning [23; 24; 25; 26], which can extract informative representations from large-scale data, we explore its feasibility for molecule data. However, those data augmentation techniques in vision or language cannot be directly applied to molecules due to their inherent 3D structure. This limitation stems from a lack of inductive bias to guarantee augmentation maintains the integrity of molecular activity.

To address the challenges, we propose S-MolSearch, a novel semi-supervised contrastive learning framework based on inverse optimal transport (IOT) . S-MolSearch directly uses 3D molecular structures to capture structure similarity. It consists of two main components: one encoder \(f_{}\) for labeled dataset and another encoder \(g_{}\) for the full dataset, which includes both labeled and unlabeled data. Both encoders are trained simultaneously to effectively leverage the two types of data. We organize a dataset of labeled molecule-protein binding data from ChEMBL . Molecules are assigned to different targets based on binding affinity, with the active molecules corresponding to each target forming clusters. We sample from these clusters, treating molecules from the same cluster as positive samples and those from different clusters as negative samples to train encoder \(f_{}\). This approach incorporates affinity information into training and avoids the limitation caused by relying solely on structural similarity. For the update of encoder \(g_{}\), we assume that the similarity measurements obtained by encoder \(f_{}\) can be generalized to unlabeled data. We input the same data from the full dataset into these two encoders separately and use optimal transport to obtain soft labels from \(f_{}\). The encoder \(g_{}\) is then trained using these soft labels. This integration enables S-MolSearch to effectively utilize unlabeled data, ensuring that the model learns from both affinity-labeled samples and broader structural similarities across the molecular dataset.

Empirically, S-MolSearch demonstrates superior performance on widely-used benchmarks LIT-PCBA  and DUD-E . It consistently achieves state-of-the-art results, surpassing both SBVS methods and LBVS methods on AUROC, BEDROC and EF. Notably, S-MolSearch trained with a 0.9 similarity threshold significantly outperforms existing methods, achieving more than a 49% improvement on BEDROC and over a 30% improvement on EF compared to the best baseline on DUD-E. These results provide strong empirical support for the effectiveness of S-MolSearch, confirming its advanced capability for virtual screening.

Our main contributions are summarized as follows:

* We introduce S-MolSearch, which is the first time integrates both molecular 3D structures and affinity information into molecule search.
* Built upon inverse optimal transport, we develop a semi-supervised contrastive learning framework, which induces S-MolSearch. By combining limited labeled data with extensive unlabeled data, S-MolSearch can learn more informative representations and explore the chemical space more effectively.
* S-MolSearch is evaluated on widely-used benchmarks LIT-PCBA and DUD-E, surpassing both SBVS and LBVS methods to achieve state-of-the-art results.

Related work

### Virtual Screening

Virtual screening can be broadly divided into two main categories: Structure-Based Virtual Screening (SBVS) and Ligand-Based Virtual Screening (LBVS). SBVS [5; 6; 7; 8] heavily relies on the structure of protein targets and typically employs molecular docking. Recently, many deep learning methods [29; 10; 11; 12] have also emerged. In contrast, LBVS [14; 15; 16; 17; 18] uses known active ligands as seeds to identify potential ligands. Molecule search is a major LBVS approach, typically divided into two categories: 2D similarity search and 3D similarity search. 2D molecule search methods [30; 31] use molecular fingerprints to search for similar molecules, while 3D molecular search methods [15; 16; 18] depend on shape overlap.

### Optimal Transport and inverse optimal transport

Optimal Transport (OT) is a mathematical problem that aims to determine the most efficient way to redistribute one initial distribution (known as the source distribution) into another distribution (known as the target distribution) while minimizing a defined transportation cost. To handle computational complexities, OT often incorporates regularization , leading to a softened optimization problem. The regularized OT objective is a convex function, thereby ensuring a unique solution that can be efficiently solved using iterative methods [33; 34].

Inverse Optimal Transport (IOT) seeks to determine the cost matrix that explains an observed optimal transport.  introduces a method to infer unknown costs.  explores the mathematical theory behind IOT. In many IOT studies [36; 37], optimization is directly performed over the cost matrix, typically focusing on learnable distances between samples rather than on the sample features.

### Semi-supervised learning

Semi-supervised learning [38; 39; 40; 41] is typically used in scenarios where labeled data is limited but unlabeled data is abundant. Pseudo-labeling  is a classic technique of semi-supervised learning.  introduce a self-ensembling method that generates pseudo-labels by forming a consensus prediction using the outputs of the network under different regularization and augmentation conditions. UPS  proposes an uncertainty-aware pseudo-label selection framework that improves pseudo-labeling accuracy by reducing the amount of noise in the training process. UST  employs a teacher-student training paradigm. The teacher model is responsible for selecting and generating pseudo-labels, while the student model learns from the labeled set augmented with these pseudo-labels. Recent work  utilizes additional unpaired images to construct caption-level and keyword-level pseudo-labels, enhancing training.

## 3 Method

### Overview

Molecular similarity search is a type of ligand-based virtual screening whose purpose is to perform a rapid search and filtering of similar molecules in a molecular database based on a query molecule provided by the user. We model the task as a dense retrieval problem, using a well-trained encoder to extract embedding representations of molecules and rank them by their cosine similarity to a query molecule, thereby identifying the top \(k\) most similar candidates.

Building upon the principles of inverse optimal transport (IOT), we have developed the S-Molesearch method. As shown in Figure 1, S-Molesearch uses a molecular structure encoder \(f_{}\) for labeled dataset \(D_{sup}\) and another encoder \(g_{}\) for the full dataset \(D_{full}\), encompassing both labeled and unlabeled dataset. \(f_{}\) utilizes contrastive learning to learn from labeled dataset. \(g_{}\) optimizes its parameters using the soft labels produced by \(f_{}\), which have been processed through smooth optimal transport. The two encoders are initialized with a molecular pretraining backbone Uni-Mol . Both encoders are trained simultaneously under the guidance of a unified loss function \(_{total}\). The encoder \(g_{}\), trained on full dataset, is used for inference.

In the following sections, we will provide more details about the core components and training strategies that underpin S-Molsearch. In section 3.2, we explain the pretraining backbone of the molecular structural encoder, Uni-Mol. In sections 3.3 and 3.4, we will sequentially examine the training strategies for both \(f_{}\) and \(g_{}\). In section 3.5, we will discuss the regularization techniques employed to enhance model generalizability and stability. In section 3.6, we will provide an analysis of S-Molsearch from the perspective of IOT, offering insights into its methodological strengths.

### Pretraining Backbone of Molecular Encoder

To effectively encode the structural information of molecules, we choose Uni-Mol as the backbone of molecular encoder for S-Molsearch. Uni-Mol is a molecular pretraining model specifically designed to adeptly process molecular 3D conformation data. It has achieved state-of-the-art performance across a range of downstream tasks. The UniMol model utilizes a self-attention mechanism that incorporates distance bias to integrate information about atoms and their spatial relationships, thereby generating a structural representation of molecules. The molecular embedding is created by using the embedding of the CLS token, and the embedding vector is normalized using the Euclidean norm.

### Training Strategy of Encoder on Labeled Dataset

In this part, we employ molecular-protein binding data sourced from the ChEMBL. Molecules are assigned to different targets based on binding affinity. The active molecules corresponding to each target form clusters. We sample from these clusters to obtain data for contrastive learning. Molecules from the same cluster are considered positive pairs, while molecules from different clusters are considered negative pairs. We employ InfoNCE loss for encoder \(f_{}\) on labeled dataset, as shown in Equation 1:

\[_{sup}=-_{i=1}^{N}(x_{i},y_{i})/) }{_{j=1}^{N}((x_{i},y_{j})/)}\] (1)

where \(x_{i}\) and \(y_{i}\) are the embeddings of positive molecule pairs, while \(x_{i}\) and \(y_{j}\) form negative molecule embedding pairs within the batch when \(j i\). sim\((x,y)\) denotes the similarity score between embeddings, typically computed as the inner product of the normalized vectors \(xy^{T}\). \(\) is the temperature parameter that scales the similarity scores. By utilizing the InfoNCE loss, \(f_{}\) pulls the embeddings of positive samples close while enforcing them away from the negative samples in the embedding space.

### Training Strategy of Encoder on Full Dataset

To harness large-scale unsupervised data effectively, S-MolSearch utilizes the \(f_{}\) to guide the learning of another encoder on full data \(g_{}\). Specifically, we employ \(f_{}\) to preprocess the data for the \(g_{}\)

Figure 1: Overview of S-MolSearch Framework

ensuring that \(f_{}\) remains detached from the backpropagation process at this stage. The embeddings obtained from \(f_{}\) are subsequently utilized for computing a similarity matrix \(M_{sup} R^{N N}\), where \(M_{sup}(i,j)=x_{sup,i}x_{sup,j}^{T}\) The task of generating soft labels for \(g_{}\) based on this similarity matrix is presented as a smooth and sparse optimal transport (OT) problem:

\[_{ U(p,q)}&,C +||||^{2}\\ & U(p,q)=\{ R_{+}^{N N }|_{N}=p,^{}_{N}=q\}\] (2)

Where \(\) denotes the transportation plan matrix between the embeddings, \(C R_{+}^{N N}\) is the cost matrix derived from the cosine similarities between embeddings: \(C_{i,j}=c-x_{sup,i}x_{sup,j}^{T}\), \(,C\) denotes Frobenius inner product of \(\) and \(C\), and \(p\) and \(q\) are the source and sink distributions, respectively. In this context, \(c=1\), \(p=1_{N}\) and \(q=1_{N}\). \(1_{N}\) is an \(N\)-dimensional vector of all ones. By introducing the OT formulation, we guarantee that signals from the supervised model \(f_{}\) are more effectively transferred to the unsupervised model \(g_{}\), while handling high label uncertainty in the supervised model \(f_{}\) with appropriate regularization. The OT could be effectively addressed by the POT. We define \(_{i,j}\) as pseudo-labels for the similarity matrix \(M_{full}\) of \(g_{}\), where \(M_{full}\) is created by embedding of \(g_{}\)\(M_{full}(i,j)=x_{full,i}x_{full,j}^{T}\).

The cross-entropy loss \(H\) is employed to optimize \(g_{}\), using the pseudo-labels provided:

\[_{soft}=H(,M_{full})\] (3)

### Regularization techniques

In order to promote uniformity of embedding space, we apply KoLeo regularizer[49; 50] to the embeddings of the semi-supervised encoder. KoLeo regularizer is defined as:

\[_{reg}=-_{i=1}^{n}(_{n,i})\] (4)

Here, \(_{n,i}\) represents the minimum distance between the \(i\)-th sample and all other samples, which serves as a proxy for local density. This loss function has a geometric interpretation that effectively pushes closer points apart, ensuring diminishing returns as distances increase, thereby encouraging a uniformly dispersed embedding space.

### Framework for S-Molesearch Induced by Inverse Optimal Transport

By integrating the losses and regularization terms from sections 3.3, 3.4, and 3.5, we have derived the overall loss function \(_{total}\) for the S-MolSearch model:

\[_{total}=_{sup}+_{soft}+_{reg}\] (5)

where \(\) is 0.1 in our setting. Building on the relationship between contrastive learning and IOT established in , we extend this relationship to a semi-supervised contrastive learning in proposition 1.

**Proposition 1**: _Given encoder \(f_{}\) for labeled dataset \(X_{sup}\) and \(g_{}\) for full dataset \(X_{full}\), \(x_{sup}\) represents the embeddings of labeled data from \(f_{}\), while \(x_{full}\) represents the embeddings of the full dataset from \(g_{}\). Semi-supervised contrastive learning is then formulated using IOT as follows:_

\[_{,}(KL(^{g}||^{ })+KL(^{}||^{})+ Reg_{1}(^{})+  Reg_{2}(^{})))\\ &^{}=_{ U (a),\,a=}( C^{},- H() ),\\ ^{}&=_{ U(a),\,a=}( C^{},- H()),\\ ^{}&=(f_{}^{fixed },g_{}^{fixed},X_{label},X_{full})\] (6)_where \(KL(X||Y)=_{ij}x_{ij}log}{y_{ij}}-x_{ij}+y_{ij}\) represents the Kullback-Leibler divergence, and \(H()=-_{i,j}_{ij}((_{ij})-1)\) represents entropic regularization. \(^{},^{},^{g} R_{+}^{N N}\), \(^{g}_{ij}=}{N}\) represents the ground truth based on labeled data, \(_{ij}\) denotes the Kronecker delta function. \(C^{},C^{} R_{+}^{N N}\) are cost matrix of \(f_{}\), \(g_{}\) and \(C^{}(i,j)=c-x_{sup,i}x_{sup,j}^{T}\), \(C^{}(i,j)=c-x_{full,i}x_{full,j}^{T}\), \(\) generally refers to a technique for transferring supervised information to unsupervised data. \(Reg_{1},Reg_{2}\) denotes regularization term._

The proof is provided in the Appendix C.1. In proposition 1, we model the contrastive learning problem on the labeled dataset and full dataset as two optimal transport problems. Additionally, we use \(\) to transfer knowledge from the labeled dataset to the unlabeled data, with the method of transfer depending on prior assumptions about the dataset and certain bias structures. For instance, If we initially optimize \(f_{}\) on a large-scale labeled dataset to obtain \(f_{}^{*}\), then generate \(^{}\) as \(^{}(i,j)=e_{full,i}e_{full,j}^{T}\), where \(e_{full,i}=f_{}^{*}(x_{i}),x_{i} X_{full}\), we can develop a model that leverages knowledge distillation for contrastive learning. In the context of molecular search tasks, we employ smooth optimal transport for the modeling of \(^{}\), leading to the development of S-MolSearch as follows:

**Proposition 2**: _Assuming the conditions outlined in Proposition 1 are satisfied, the optimal parameters \(^{*}\) and \(^{*}\) of S-MolSearch can be regarded as the solution to the following IOT problem:_

\[_{,}(KL(^{g}\|^{})+KL(^{}\|^{})+ Reg_{1}(^{}))\] (7) _subject to_ \[^{}=_{ U(a),\,a=}(  C^{},- H()),\] \[^{}=_{ U(a),\,a=}(  C^{},- H()),\] \[^{}=_{ U(a,b),\,a=1_{N},\,b=1 _{N}}( C^{^{}},+ \|\|^{2})\]

_where \(C^{^{}} R_{+}^{N N}\) and \(C^{^{}}(i,j)=c-x_{full,i}^{}(x_{full,j}^{ {fixed}})^{T}\). The \(x_{full}^{}\) represents the embeddings of the same data in \(X_{full}\) obtained from the supervised encoder \(f_{}\), where \(f_{}\) is detached._

The proof is located in the Appendix C.2. We compute the KL divergence to guide the optimization of \(f_{}\) and \(g_{}\), where the regularization term simplification only affects the full data. Moreover, we set the marginal values of \(U(a,b)\) to an all-ones vector. In this way, we find that the knowledge in \(f_{}\) transfers effectively to \(g_{}\), thereby achieving excellent performance on molecule search task.

## 4 Experiments

### Training Data

The labeled data comes from ChEMBL , an open-access database containing extensive information on bioactive compounds with drug-like properties. We prepare nearly 600,000 protein-molecule pairs, encompassing about 4,200 protein targets and 300,000 molecules. The details of data curation can be found in appendix A. To prevent information leakage, the data is filtered based on protein sequence similarity. Specifically, the amino acid sequences of all protein targets in the benchmarks DUD-E and LIT-PCBA are extracted. Then, we use MMseqs  tool with similarity thresholds of 0.4 and 0.9 to filter out proteins in ChEMBL. Using a 0.9 threshold helps filter out identical and highly similar targets, while the stricter 0.4 threshold filters out nearly all similar targets. After filtering, 3,369 proteins and 327,917 protein-ligand pairs remain for the 0.4 threshold, while 4,102 proteins and 529,856 pairs remain for the 0.9 threshold. We sample 1 million pairs from the filtered data as labeled data respectively.

The unlabeled data, consistent with what is used by Uni-Mol, comes from a series of public databases, totaling about 19 million entries. Additionally, we incorporate the small molecule data from ChEMBL into this collection, thereby obtaining the full dataset.

### Benchmarks

We choose the widely used virtual screening benchmarks DUD-E  and LIT-PCBA  to evaluate the performance of S-MolSearch. DUD-E is designed to help benchmark virtual screening programs by providing challenging decoys. It includes 102 protein targets along with 22,886 active ligands, each accompanied by 50 decoys with similar physico-chemical properties. LIT-PCBA is designed for virtual screening and machine learning, aiming to address the chemical biases present in other benchmarks such as DUD-E. It consists of 15 targets, with 7,844 confirmed active compounds and 407,381 inactive compounds.

### Baselines

We choose a range of LBVS and SBVS methods as comparative baselines for a thorough evaluation. ROCS , Phase Shape , LIGSIFT , and SHAFTS [19; 20] are LBVS methods that evaluate similarity by calculating the overlap of molecular 3D shapes. Other methods are SBVS methods. Among them, DeepDTA , OnionNet , Pafnucy , BigBind , and Planet  are trained on binding affinity labels. Glide , Vina , and Surflex  are molecular docking software. Gnina  is a deep learning based molecular docking method. DrugClip  utilizes the similarity between targets and molecules to find active compounds.

### Results

#### 4.4.1 Main Results

   Method & AUROC (\%) & BEDROC (\%) & EF 0.5\% & EF 1\% & EF 5\% \\  ROCS & 75.20 & - & - & 23.79 & 6.89 \\ Phase Shape & 76.70 & - & - & 30.33 & 9.01 \\ LIGSIFT & 78.40 & - & - & 25.89 & 8.01 \\ SHAFTS & 78.20 & - & - & 32.49 & 9.67 \\  Glide-SP & 76.70 & 40.70 & 19.39 & 16.18 & 7.23 \\ Vina & 71.60 & - & 9.13 & 7.32 & 4.44 \\ Pafnucy & 63.11 & 16.50 & 4.24 & 3.86 & 3.76 \\ OnionNet & 59.71 & 8.62 & 2.84 & 8.83 & 5.40 \\ Planet & 71.60 & - & 10.23 & 8.83 & 5.40 \\ DrugCLIP & 80.93 & 50.52 & 38.07 & 31.89 & 10.66 \\  S-MolSearch\({}_{0.4}\) & 84.61 & 54.22 & 40.85 & 34.60 & 11.44 \\ S-MolSearch\({}_{0.9}\) & **92.56** & **75.37** & **51.50** & **47.94** & **15.82** \\   

Table 1: Performance on DUD-E in zero-shot setting. The best results are **bolded** and the second-best results are underlined.

   Method & AUROC (\%) & BEDROC (\%) & EF 0.5\% & EF 1\% & EF 5\% \\  ROCS & 52.41 & - & - & 2.48 & - \\ Phase Shape & 52.24 & - & - & 2.98 & - \\ LIGSIFT & 54.94 & - & - & 2.39 & - \\ SHAFTS & 54.53 & - & - & 2.79 & - \\  Surflex & 51.47 & - & - & 2.50 & - \\ Glide-SP & 53.15 & 4.00 & 3.17 & 3.41 & 2.01 \\ Planet & 57.31 & - & 4.64 & 3.87 & 2.43 \\ Gnina & 60.93 & 5.40 & - & 4.63 & - \\ DeepDTA & 56.27 & 2.53 & - & 1.47 & - \\ BigBind & 60.80 & - & - & 3.82 & - \\ DrugCLIP & 57.17 & 6.23 & 8.56 & 5.51 & 2.27 \\  S-MolSearch\({}_{0.4}\) & 57.34 & 7.58 & 10.93 & 6.28 & 2.47 \\ S-MolSearch\({}_{0.9}\) & **61.78** & **8.48** & **11.97** & **7.36** & **3.21** \\   

Table 2: Performance on LIT-PCBA in zero-shot setting.

Tables 1 and 2 respectively present the performance of S-MolSearch on DUD-E and LIT-PCBA compared with other competitive baselines, where the best results are highlighted in bold and the second-best results are underlined. The methods in the upper part of the two tables are ligand-based virtual screening methods, and their results come from . The methods in the middle part of the two tables are structure-based virtual screening methods, and their results come from DrugClip. We also present the results of S-MolSearch trained on data filtered with 0.4 and 0.9 similarity thresholds. Following previous work, we choose AUROC, BEDROC, Enrichment factor (EF) as performance metrics to evaluate both general accuracy and screening capacity, with higher values indicating better performance. Their definitions are in appendix B. The zero-shot setting means inferring directly without using any data from the benchmarks for training, which more close to real virtual screening scenarios.

Table 1 shows that S-MolSearch achieves the best on all metrics. S-MolSearch trained with a strict 0.4 similarity threshold avoid overfitting similar targets and surpasses all ligand-based and structure-based virtual screening baselines. S-MolSearch trained with a 0.9 similarity threshold shows substantial improvements over existing methods, with over a 49% increase in BEDROC and more than a 30% boost in EF compared to the best baseline. We find that S-MolSearch, as a ligand-based virtual screening method, demonstrates strong performance without requiring specific protein structures.

S-MolSearch also achieves SOTA on LIT-PCBA as shown in Table 2. While its AUROC performance is not the best at the 0.4 similarity threshold, S-MolSearch perform better in BEDROC and EF, indicating its strength in screening scenarios. We notice that the metrics for all methods decline on LIT-PCBA compared to DUD-E. Unlike DUD-E, which uses putative decoys, LIT-PCBA is based on experimental results. Since many of its assays are cell-based rather than target-specific, there is noise in the active molecules, which we consider may lead to the decline. Meanwhile, S-MolSearch demonstrates its advantage over structure-based virtual screening by not requiring specific target information, but instead performing searches based on active molecules.

#### 4.4.2 Ablation Study

We conduct extensive ablation studies to explore how S-MolSearch works. These results are derived from S-MolSearch trained with a 0.4 similarity threshold. First, we performed ablation studies on several key techniques of S-MolSearch. The results are summarized in Table 3, where the best results are bolded and the second-best results are underlined. 'Soft label' refers to training the encoder \(g_{}\) using soft labels obtained from inverse optimal transport. Without this, we directly use the similarity matrix as the hard label for training. 'Regularizer' indicates the use of KoLeo regularizer. 'Pretrain' refers to starting the training of S-MolSearch from a pretrained checkpoint of Uni-Mol. Otherwise, it starts from random initialization. The results show that each component contributes to the final results. Although S-MolSearch may not be the best in some individual metrics, the absence of these components leads to poor performance on at least one benchmark. For example, not using Soft label significantly degrades performance on DUD-E. S-MolSearch performs consistently on both DUD-E and LIT-PCBA, with nearly all metrics being the best.

To visually illustrate the difference between the embeddings learned by S-MolSearch and those from Uni-Mol, we visualize their embeddings, as shown in Figure 2. The molecules are from ChEMBL, with different colors indicating different protein targets. Comparing the two, the classification boundaries in Figure 2b from S-MolSearch are clearer, and the intra-class molecular distances are more appropriate. Some clusters split into several subclusters, possibly reflecting the hierarchical structure within the molecules.

    &  &  &  &  \\  & & & EF 0.5\% & EF 1\% & EF 5\% & EF 0.5\% & EF 1\% & EF 5\% \\  ✗ & ✓ & ✓ & 37.35 & 30.73 & 10.43 & 10.59 & 6.19 & **2.72** \\ ✓ & ✗ & ✓ & 39.64 & 33.32 & **11.47** & 9.01 & 5.24 & 2.38 \\ ✓ & ✓ & ✗ & 38.09 & 31.86 & 10.88 & 8.26 & 5.24 & 2.30 \\ ✓ & ✓ & ✓ & **40.85** & **34.60** & 11.44 & **10.93** & **6.28** & 2.47 \\   

Table 3: Ablation studies performance on DUD-E and LIT-PCBA.

In addition, we conduct ablation studies on the semi-supervised learning paradigm of S-MolSearch. The results are summarized in Table 4. For 'Self-supervised', we train the model using a self-supervised learning paradigm. Specifically, we cluster the unlabeled molecule data based on their scaffolds. Molecules from the same cluster are considered as positive pairs, while those from different clusters are considered as negative pairs, and contrastive learning is performed using the InfoNCE loss. For 'Supervised', we use only the ChEMBL data for supervised contrastive learning, where molecules binding to the same target are treated as positive pairs and those binding to different targets as negative pairs. For 'Finetuning', we first train the model under the self-supervised paradigm described above, then, starting from the self-supervised checkpoint, perform the supervised learning described above on the ChEMBL data. The results show that S-MolSearch consistently performs well on both benchmarks, achieving the best results in almost all metrics. Notably, compared to finetuning, S-MolSearch demonstrates a superior ability to integrate information from both unlabeled and labeled data in ligand-based virtual screening scenarios.

#### 4.4.3 Impact of Labeled Data Scale

In the molecular field, obtaining or creating labeled data can be expensive. We also analyze how the scale of labeled data affects the results. These results are derived from S-MolSearch trained with a 0.4 similarity threshold. As shown in Figure 3, experiments are conducted with varying amounts of labeled data, while keeping the unlabeled data fixed at 1 million. The performance of encoder \(g_{}\) improves as the amount of labeled data increases, especially when the absolute number of labeled data is limited. Additionally, the results of encoder \(g_{}\) are consistently higher than encoder \(f_{}\) trained using only labeled data. The best results are achieved with 50k and 100k labeled data, corresponding to labeled-to-unlabeled data ratios of 1:20 and 1:10, respectively. Beyond these amounts, increasing labeled data results in stable or slightly declining performance, suggesting that further improvements

    &  &  \\  & EF 0.5\% & EF 1\% & EF 5\% & EF 0.5\% & EF 1\% & EF 5\% \\  Self-supervised & 27.33 & 20.13 & 6.81 & 4.78 & 3.26 & 1.97 \\ Supervised & 34.61 & 28.51 & 9.83 & 7.55 & 4.73 & 1.98 \\ Finetuning & 35.11 & 29.20 & 9.96 & 7.01 & 5.71 & 2.44 \\  S-MolSearch & **40.85** & **34.60** & **11.44** & **10.93** & **6.28** & **2.47** \\   

Table 4: Performance under different learning paradigms on DUD-E and LIT-PCBA.

Figure 2: t-SNE visualization of molecular representations learned by S-MolSearch versus pretrained checkpoint. Different colors represent different protein targets’ active molecules.

may necessitate an increase in unlabeled data or a reevaluation of hyperparameters. This trend helps us to find an optimal balance between labeled and unlabeled data to maximize efficiency and performance in S-MolSearch.

## 5 Conclusion

This study introduces S-MolSearch, a novel semi-supervised contrastive learning framework that significantly enhances the generalizability of machine learning models in virtual screening. Built on inverse optimal transport, S-MolSearch skillfully integrates limited labeled data with a vast reservoir of unlabeled data and excels at identifying potential drug candidates from extensive molecular libraries, substantially improving the accuracy and efficiency of molecule searches. This advancement addresses current challenges in virtual screening by facilitating efficient filtering of large datasets, highlighting the framework's capability in scenarios where data annotation is costly.

Currently, S-MolSearch predominantly focuses on the molecular affinity data, omitting broader biochemical interactions, which suggests a potential area for improvement. Future work could integrate more extensive unsupervised datasets to further refine the framework's effectiveness and explore additional applications in various bioinformatics fields.