# Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes

Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes

 Gehua Ma

College of Computer Science and Technology

Zhejiang University

gehuama@icloud.com

&Runhao Jiang

College of Computer Science and Technology

Zhejiang University

Rhjiang@zju.edu.cn

&Rui Yan

College of Computer Science and Technology

Zhejiang University of Technology

ryan@zjut.edu.cn

&Huajin Tang

College of Computer Science and Technology

Zhejiang University

###### Abstract

Developing computational models of neural response is crucial for understanding sensory processing and neural computations. Current state-of-the-art neural network methods use temporal filters to handle temporal dependencies, resulting in an unrealistic and inflexible processing paradigm. Meanwhile, these methods target trial-averaged firing rates and fail to capture important features in spike trains. This work presents the temporal conditioning spiking latent variable models (TeCoS-LVM) to simulate the neural response to natural visual stimuli. We use spiking neurons to produce spike outputs that directly match the recorded trains. This approach helps to avoid losing information embedded in the original spike trains. We exclude the temporal dimension from the model parameter space and introduce a temporal conditioning operation to allow the model to adaptively explore and exploit temporal dependencies in stimuli sequences in a _natural paradigm_. We show that TeCoS-LVM models can produce more realistic spike activities and accurately fit spike statistics than powerful alternatives. Additionally, learned TeCoS-LVM models can generalize well to longer time scales. Overall, while remaining computationally tractable, our model effectively captures key features of neural coding systems. It thus provides a useful tool for building accurate predictive computational accounts for various sensory perception circuits.

## 1 Introduction

Building precise computational models of neural response to natural visual stimuli is a fundamental scientific problem in sensory neuroscience. These models can offer insights into neural circuit computations, reveal new mechanisms, and validate theoretical predictions [1; 2; 3; 4; 5; 6]. However, constructing such models is challenging due to the complex nonlinear processes involved in neural coding, such as synaptic transmission and spiking dynamics. For modeling retinal responses, early attempts using linear-nonlinear (LN) models and generalized linear models (GLMs) were successful with simple data such as white noise [2; 7] but fell short with more complex stimuli like natural visual scenes [8; 9]. Artificial neural networks (ANNs), which are powerful function approximators and loosely resemble biological neurons and architectures [10; 11], have shown promise in modeling the visual stimuli coding process through various ANN-based methods [9; 12; 13; 14; 15]. Recent research has demonstrated that complex neural activity can be well represented in a low-dimensional space [16; 17]. This has led to growing interest in a type of neural network known as latent variable models (LVMs). LVMs strike a balance between model accuracy and representation space simplicity, enabling accurate neural coding modeling and interpretation of neural activity in a low-dimensional space [18; 19; 20; 21; 22; 23; 24]. Although the current state-of-the-art neural network models for visual neural coding have produced decent results and provided some exciting insights, they have two major limitations:

* Most of these works focus on simulating the firing rates of real neurons. This is a decent choice (following the classic Poisson LN/GLM models) for artificial neuron networks, which are essentially real-valued processing-based. However, as a trial-averaged spike statistic, firing rates only characterize some aspects of the original spike train . As a result, directly using firing rates as the target may result in losing information embedded in the original spike trains [26; 27].
* Existing models mostly employ fixed-length temporal filters. For example, the CNN approach  concatenates stimuli within a fixed duration as input and processes these inputs using temporal filters. Therefore, they cannot process long stimuli sequences like a real neural circuit. Instead, they must slice the long sequences into fixed-length short segments and process them separately, thus losing biological realism (see also Fig. 2A). Secondly, in simulation, the learned models can only take inputs of the same length as during the training phase, thus limiting their flexibility.

Although these two points are important for a realistic computational model, an approach that addresses these limitations is still lacking. This work introduces the TeCoS-LVM (temporal conditioning spiking LVM) models of the neural responses to natural visual stimuli. We employ spiking neurons to allow the model to aim directly at producing realistic spike trains. This avoids spike train information loss that might occur when targeting spike statistics. To address the second limitation, we completely exclude the temporal dimension from the parameter space and introduce a temporal conditioning operation to handle the temporal dependencies. Inspired by the information compression in biological coding systems, we formalize TeCoS-LVM models within the information bottleneck framework of LVMs and introduce a general learning method for them. Evaluations on real neural recordings demonstrate that TeCoS-LVM models accurately fit spike statistics and produce realistic spike activities. Further simulations show that TeCoS-LVM models learned on short sequences can generalize well to longer time scales and exhibit memory mechanisms similar to those in biological cognitive circuits.

## 2 Preliminaries

Leaky integrate-and-fire spiking neuronWe adopt the Leaky Integrate-and-Fire (LIF) neuron model in this work, which briefly describes the sub-threshold membrane potential dynamics as \(_{m}=-(u-u_{})+RI(t)\), where \(u_{t}\) denotes membrane potential, \(R,_{m}\) are membrane resistance, time constant, and \(I\) is the input current. \(v_{},u_{}\) denote the firing threshold, resting potential, respectively. In practice, it leads to the following discrete-time computational form [28; 29; 30]. The sub-threshold dynamic, firing, and resetting are written as \(u_{t}= u_{t-1}+I_{t};\;o_{t}=(u_{t}-v_{});\;u_{t}=u _{}\) if \(o_{t}=1\), where \(o_{t}\) is the spike output, \(I_{t}\) is the input current, usually transformed by a parameterized mapping, and \(\) is the membrane time constant. In this discrete form, the membrane constant \(_{m}\) is combined with timestep \(t\) for simplification, as in all our experiments, the length of simulation timestep \(t\) is fixed. To introduce a simple model of neuronal spiking and refractoriness, we assume \(v_{}=1\), \(=0.5\) is a fixed constant, and \(u_{}=0\) for all spiking neurons throughout this research.

**Variational information bottleneck** The information bottleneck (IB) principle  offers an appealing framework to formulate LVMs. In short, a desired LVM should have latent representations that are maximally expressive regarding its target while being maximally compressive about its input. Let us consider a latent variable model \(\) with input \(\), target \(\), and latent representation \(\) defined by a parametric encoder \(q(|;)\). Let \(I(,;)\) be the mutual information between the \(\) and \(\), and \(I(,;)\) be the mutual information between \(\) and \(\), IB suggests an objective

\[_{}I(,;)I(,;)<I_{c},\] (1)

where \(I_{c}\) is the information constraint. With the introduction of a Lagrange multiplier \(\), the IB objective is equivalent to

\[_{}[I(,;)- I(, ;)].\] (2)Deep variational IB [32; 33] leverages variational inference to construct a lower bound on the IB objective in (2). By assuming the factorization \(p(,,)=p(|)p(|)p()\), we have an equivalent objective that comprises one predictive term and one compressive term (refer to Appendix D) as follows,

\[_{}_{q(;)}[- p( |;)]}_{^{}}+[q(|;) ]\|p()}_{^{}},\] (3)

where \([Q\|P]\) is the Kullback-Leibler divergence between two distributions, and \(p(|;)\) is a parameterized decoder.

## 3 Methodologies

### Temporal Conditioning Spiking Latent Variable Model

**Basic formulation** (see also Appendix D) We denote a sequence of visual stimuli as \(=(_{1},,_{t},,_{T}) ^{T[_{t}]}\), \([_{t}]\) stands for the dimension of \(_{t}\). At each timestep \(t\), one high-dimensional visual stimulus \(_{t}\) is received. We want to predict the corresponding neural population response \(_{t}(0,1]^{[_{t}]}\), where \([_{t}]\) denotes the number of retinal ganglion cells (RGCs). This is implemented by an LVM, which first compresses the visual stimuli into a low-dimensional latent representation \(_{t}^{[_{t}]}\), and then decodes the neural population response from it. Biological neural coding can effectively compress observed stimuli while retaining the informative contents [34; 35; 36; 37]. Therefore, we further encourage this LVM to construct a latent space in which \(\) have maximal predictive power regarding response \(\) while being maximally compressive about input stimuli \(\). As a result, our target to model the neural coding process of visual stimuli turns to an optimization problem of minimizing the loss function (3) presented in the variational IB framework.

However, assuming independence along the temporal dimension becomes inappropriate due to the complex temporal dependencies in stimuli-neural response modeling [39; 40; 41]. To address this, we introduce a hidden state into the prior, encoder, and decoder of the latent variable model. This hidden state maintains earlier stimuli information [42; 43], allowing the entire inference-generation

Figure 1: Overview of our approach. **A.** Graphical illustration of TeCoS-LVM models of retinal neural response to natural visual scenes. Our model can directly generate neural response sequences in real-time, thus faithfully simulating the real neural computation process (see also Fig. 2A). **B.** Full graphical illustration of the computational operations. **C.** Separate illustrations of the prior, encoder inference, decoder generation, and hidden state update operations. With the introduction of the hidden state (acts as the sensory memory), our prior, encoder and decoder are linked to the entire stimuli sequence \(_{1:t}\) rather than just the current stimulus \(_{t}\) (see also Appendix 3.1). Hence, although we completely exclude the time dimension from the model parameter space, TeCoS-LVM can still adaptively explore and exploit temporal information for predictive (generative) modeling.

process to be conditioned on the entire stimuli sequence \(_{1:r}\) rather than just \(_{t}\) (Fig. 5). To enable adaptive exploitation and accumulation of temporal dependencies within the stimuli sequence, we employ a recurrent network to update the hidden state [44; 45; 46; 47], formally,

\[_{t}=f_{}(_{t},_{t-1}).\] (4)

The hidden state here serves as the sensory memory , akin to the Tolman-Eichenbaum Machine , which employs an attractor network to store and retrieve memories.

Note that, as we focus on high-dimensional visual stimuli here, we use a spiking convolutional feature extractor to reduce the dimensionality of the stimuli. It is shared in the hidden state update and the temporal conditioning encoder inference process (as illustrated in Fig. 1). To make our notation simpler and easier to understand during reading, we do not explicitly denote the feature extractor in our formulations (stimuli features for de facto computation, but still marked as \(\)).

Temporal conditioning priorWith the introduction of the hidden state, the prior over latent variable is no longer a standard isotropic Gaussian. Instead, it becomes a parameterized conditional distribution that depends on the hidden state, which carries information about previous stimuli. Formally, the latent variable follows the distribution \(p(_{t}|_{1:t-1})\), given by

\[p(_{t}|_{1:t-1})=_{t}; }(_{t-1})}_{},}( _{t-1})}_{^{2}},\] (5)

where \(^{}\) denotes the parametric model to compute the means and variances, a spiking MLP. In particular, the real-valued means and variations are calculated through the linear readout synapses of spiking neurons.

Temporal conditioning encoderIn a similar manner, the encoder is not only a function of \(_{t}\), but also a function of \(_{t-1}\). By Eq. 4, the hidden state \(_{t-1}\) is a function of \(_{1:t-1}\). Hence, the temporal conditioning encoder defines the distribution \(q(_{t}|_{1:t})\). We can write

\[q(_{t}|_{1:t})=_{t};^{ }(_{t},_{t-1}),^{}(_{t},_{t-1}),\] (6)

where \(^{}\) is the parameterized model for computing the variational posterior distribution, which is also a spiking MLP.

Temporal conditioning decoderThe decoder generates the neural population responses \(_{t}\) only using the latent representation \(_{t}\) and hidden state \(_{t-1}\) as inputs. As the hidden state is a function of previous stimuli, the decoder defines the distribution \(p(_{t}|_{t},_{1:t-1};^{})\), where \(^{}\) stands for the decoder parameters. Since we use spiking neurons, the decoder will directly output spike trains that simulate the recorded neural population responses.

Model learningThe TeCoS-LVM models are optimized to minimize a loss function (Eq. 3, see also Appendix D) that has the form:

\[=^{}+^{},\] (7)

and all synaptic weights are optimized jointly during the learning. To elucidate the loss function, we first examine the compressive term. As we adopt Gaussian distributions in our temporal conditioning prior and encoder, the compressive term composed of KL divergences can be calculated analytically. In particular, we have,

\[^{}=_{t=1}^{T}[q(_{t} |_{1:t};^{})\|p(_{t}|_{1:t-1}; ^{})].\] (8)

On the other hand, since our model directly outputs spike trains, we adopt the Maximum Mean Discrepancy (MMD) as the predictive loss term [26; 50]. Also, we use the first-order postsynaptic potential (PSP) kernel that can effectively depict the temporal dependencies in spike train data [51; 52]. Denoting the predicted, recorded spike trains as \(}\), \(\), respectively, we can write the PSP kernel MMD predictive loss as

\[^{}=_{t=1}^{T}_{=1}^{t} (}_{1:})-(_{1:})^ {2},\] (9)

where \((_{1:})=(1-})(_{1: -1})+}_{}\), and we set the time constant \(_{s}=2\).

### TeCoS-LVM Models

We shall consider two types of TeCoS-LVM models, TeCoS-LVM and TeCoS-LVM Noisy in this work. Specifically:

* In TeCoS-LVM, all spiking neurons are LIF neurons.
* In TeCoS-LVM Noisy, all spiking neurons are Noisy LIF spiking neurons (, refer to Appendix C for details). Using Noisy LIF neuron allows TeCoS-LVM to have neuron-level stochasticity, which is considered a crucial component in biological neural computation [54; 55; 56].

## 4 Experiments

### Dataset and Baselines

We perform evaluations and analyses on real neural recordings from RGCs of dark-adapted axololol salamander retinas . The dataset contains spike responses of two retinas on two movies (see also Appendix E). We partitioned all records into stimuli-response sample pairs of 1 second (30 time bins) and down-sampled the frames to 90 pixel\(\)90 pixel. This results in four datasets, each split into non-overlapping train/test (50%/50%) parts. We shall refer to these four datasets as follows for brevity. **Movie 1 Retina 1**: records of 38 RGCs on movie 1 ("salamander movie"), 75 repetitions. **Movie 1 Retina 2**: records of 49 RGCs on movie 1, 30 repetitions. **Movie 2 Retina 1**: records of 38 RGCs on movie 2 ("wildlife movie"), 107 repetitions. **Movie 2 Retina 2**: records of 49 RGCs on movie 2, 42 repetitions.

CNN modelWe use the state-of-the-art CNN model [9; 15] for comparison. In the CNN model, the network's predicted outputs are the average maximum likelihood estimation of retina responses in firing rates based on spatiotemporal (frames are concatenated on the channel dimension) input (see also Appendix G).

IB-DisjointIB-Disjoint  is a high-performance model that performs similarly to the IB-GP model that uses a Gaussian Process prior . This model employs an isotropic Gaussian as the prior over latents. It is similar to the vanilla variational IB, where the latent variables are assumed to be independent along the temporal dimension.

### Metrics and Features for Evaluations and Visualizations

Pearson correlation coefficientThis metric evaluates the model performance by calculating the Pearson correlation coefficient between the recorded and predicted firing rates [9; 14; 15]. The higher the value, the better the performance. Refer to Appendix F for more details.

Spike train dissimilarityThis metric assesses the model performance by computing the dissimilarity between recorded and predicted spike trains. A lower value indicates better model performance. Here we use the MMD with a first-order PSP kernel [51; 52] to measure the spike train dissimilarity [27; 50; 58] (see also Appendix F).

Spike autocorrelogramThe spike autocorrelogram is computed by counting the number of spikes that occur around each spike within a predefined time window [14; 9]. The resulting trace is then normalized to its maximum value (which occurs at the origin of the time axis by construction), and the maximum value is set to zero for better visualization. Refer to Appendix F for more details.

### Experimental Details

TeCoS-LVM hyper-parameters were fixed to be the same on all four datasets. We set the latent variable dimension to 32 and the hidden state dimension to 64 by default (see also Appendix A). We used the Adam optimizer (\(_{1}=0.9,_{2}=0.999\)) with a cosine-decay learning rate scheduler , starting at a rate of 0.0003. The mini-batch size was set to 64, and the models were trained for 64 epochs. We used the same architectures to implement TeCoS-LVM models. The factor \(\) in the loss function (7) is set to 0.01 by default to balance information compression and predictive power [32; 60]. More experimental details are presented in Appendix G.

At test time, the test samples have the same length as the training samples (30 bins, 1 second) by default. However, the learned model can handle longer test samples as our model excludes the time dimension from its parameter space. This will be discussed further in the Results sub-section. We tested TeCoS-LVM models with a "warmup period" of 0.5 seconds (15 bins), during which themodel's predictions will be discarded (see also Fig. 4A). This was done because our hidden state was zero-initialized, making the early predictions less accurate.

### Results

#### 4.4.1 TeCoS-LVM Models Accurately Fit Real Spike Activities and Statistics

As shown in Fig. 2B, 2C, TeCoS-LVM models can effectively fit the recorded firing rates. Especially, TeCoS-LVM Noisy can reproduce real firing rates more accurately than baselines. Furthermore, we verified the potential information loss caused by using trial-averaged statistics as the optimization target. While the firing rate target may allow models to learn coarse-grained features, it does not necessarily yield optimal capturing of fine-grained features such as spike autocorrelations. As shown by the autocorrelograms in Fig. 2D, the baselines failed to capture the spike autocorrelation

Figure 2: TeCoS-LVM models well fit the spike statistics of real neural activities. The error bars (SD) were computed across multiple random seeds. **A.** Graphical illustrations of the processing flows of baselines and TeCoS-LVM models. **B.** Heatmaps of the real (Data) and predicted firing rates on Movie 2 Retina 2 test data. The TeCoS-LVM Noisy model precisely reproduces the firing rate patterns of real neural data. **C.** Histograms of firing rate Pearson correlation coefficients on test data of four datasets. **D.** Autocorrelograms acquired on test data of four datasets. While the baselines fail, the TeCoS-LVM models accurately capture the spike autocorrelations. **E.** Recorded and predicted activities of two representative neurons responding to repeated trials of a randomly selected test segment of Movie 1 Retina 1 data.

feature accurately. By contrast, TeCoS-LVM models reproduced the spike autocorrelations more precisely. The TeCoS-LVM models also outperformed other models in synthesizing more realistic spike activities (Fig. 3A&B). Our results suggest that TeCoS-LVM models can accurately fit real spike activities and statistics. In particular, the TeCoS-LVM Noisy model significantly outperforms baselines on all metrics.

We also noticed that including neuronal noise is important for modeling neural activities. Because of the absence of neuron-level randomness, the TeCoS-LVM model failed to reproduce trial-to-trial variability (Fig. 2E) in real neurons. Consequently, as shown in Fig. 2B, TeCoS-LVM's firing rate predictions (obtained by averaging over multiple runs) are less smooth than others, thus negatively impacting the firing rate correlations. That explains why the TeCoS-LVM achieved lower spike train dissimilarities on some data (Movie 1 Retina 2, Movie 2 Retina 2 in Fig. 3B) but still lacks behind other methods in terms of the firing rate metric (Fig. 2C).

Evaluation using more spike distancesThe TeCoS-LVM models are specifically optimized to minimize the discrepancy in the PSP kernel space, making them naturally advantageous in comparing PSP-MMD-based spike train dissimilarity. To ensure a more fair assessment of the spike train prediction quality, we have considered several different spike train distances. Specifically, we computed van Rossum, Victor-Purpura, and SPIKE distances (refer to Appendix F for more details) between the predicted spike trains with the recorded ones. We observed consistent and significant improvements in the TeCoS-LVM models over two state-of-the-art baselines, as shown by results in Table 1. We also noticed that when considering these spike train distances, the performance of TeCoS-LVM Noisy is slightly affected due to the noise-perturbed neuronal dynamics, which accords with results in Fig. 3B. However, the overall performance of TeCoS-LVM Noisy surpasses the baselines by a large margin and, moreover, effectively reproduces the variability in neural processing.

#### 4.4.2 Train Short, Test Long: Learned TeCoS-LVM Models Generalize to Longer Time Scales

TeCoS-LVM models completely exclude the time dimension from parameter space and, therefore, can handle input stimuli sequences of any duration without being limited to the length of training data (1 second here). We evaluated the temporal scalability of TeCoS-LVM models by running them on

Figure 3: TeCoS-LVM models synthesize realistic neural activities and generalize well to larger time scales. **A.** Examples of the predicted spike trains on a Movie 1 Retina 2 test data clip. The spike trains generated by the TeCoS-LVM models are closer to the recorded spike trains than those of the baselines. **B.** Histograms of spike train dissimilarities on test data. The dissimilarities acquired using TeCoS-LVM models are significantly lower than those of baselines. **C.** TeCoS-LVM models learn general temporal dependencies. We ran TeCoS-LVM models trained using 1-second sequences on longer test sequences and observed that extending the length of the test sequence only leads to minor performance drops.

longer test data sequences. The firing rate correlation coefficients and spike train dissimilarities were calculated to measure the performance changes. TeCoS-LVM models consistently produce accurate coding results at different time scales. Results in Fig. 3C show that increasing the length of the test sequence only brings slight performance drops, as evidenced by the minor decrease in the firing rate correlations and little increase in the spike train dissimilarities. This demonstrates that TeCoS-LVM models learn general (multi-time-scales) temporal dependencies from short-sequence training.

#### 4.4.3 Hidden State Analyses: Exploring Memory Mechanisms in TeCoS-LVMs

Interestingly, TeCoS-LVM models' predictions are less accurate for that short period after initialization, likely due to the model's sensory memory requiring time to accumulate. We observed that it takes at most 0.5 seconds for the L2 norm of the hidden state to reach the average value of consecutive runs on a long sequence (Fig. 4A). As a result, we set a warmup period of 0.5 seconds for all our tests. We further investigated the memory mechanism in TeCoS-LVM models, which is implemented by the hidden state update. To this end, we quantified the variation of stimuli by computing the Structural Similarity (SSIM) of adjacent stimuli (\(_{t}\) and \(_{t-1}\)). If the change in stimuli at a certain moment is drastic, then the SSIM at this moment is low. For the sensory system, the stimulus it receives at that time is quite novel or surprising . We also measured the memory update magnitude by calculating the cosine distance of adjacent hidden state vectors (\(_{t}\) and \(_{t-1}\)). As shown in Fig. 4B,

    & SPIKE & Victor-Purpura & van Rossum & SPIKE & V.-P. & van Rossum \\  Model & Data &  &  \\  TeCoS-LVM Noisy (This work) & 0.155 & 14.024 & 238.614 & 0.116 & 21.599 & 425.871 \\ TeCoS-LVM (This work) & 0.124 & 12.835 & 127.346 & 0.111 & 18.182 & 150.445 \\ McIntosh NeurIPS-16 & 0.207 & 19.601 & 376.822 & 0.220 & 39.168 & 2672.211 \\ Rahmani NeurIPS-22 & 0.224 & 21.916 & 394.020 & 0.219 & 39.075 & 2276.706 \\  Model & Data &  &  \\  TeCoS-LVM Noisy (This work) & 0.162 & 14.412 & 553.510 & 0.153 & 28.441 & 1135.805 \\ TeCoS-LVM (This work) & 0.128 & 12.693 & 308.784 & 0.123 & 22.666 & 574.298 \\ McIntosh NeurIPS-16 & 0.212 & 22.713 & 1650.823 & 0.221 & 39.261 & 2638.964 \\ Rahmani NeurIPS-22 & 0.204 & 22.271 & 1615.934 & 0.221 & 38.378 & 2244.981 \\   

Table 1: Evaluation results using SPIKE, Victor-Purpura, and van Rossum spike train distances, results reported here are averaged across multiple trials.

Figure 4: Visualizations of hidden state and latent space dynamics. **A.** The evolution of \(\|_{t}\|\) over time after initialization. **B.** SSIM curve of neighboring stimuli and cosine distance curves of adjacent hidden state vectors of TeCoS-LVM models. **C.** Scatterplots of the Pearson correlation coefficients between hidden state cosine distance and stimuli SSIM. **D.** Model performances under different weighting factor \(\)s, obtained on Movie 1 Retina 2 test data. **E.** Visualizations of \(_{t}\) dynamics in TeCoS-LVM Noisy models learned using different levels of \(\). **F.** Model performances with and without TeCo (shorthand of temporal conditioning operation). We increased the number of parameters for models without TeCo to be approximately on par with the standard models.

C, the two have a strong negative correlation. This suggests that the TeCoS-LVM models perform more significant memory updates (indicated by a large cosine distance) when facing highly dynamic stimuli (low SSIM); only minor updates are performed when stimuli are relatively stable. This is consistent with previous sensory neuroscience findings suggesting that the sensory circuits focus more on unpredictable or surprising events. When repeatedly exposed to an initially novel stimulus, the neural processing becomes less active [62; 63; 61; 64].

#### 4.4.4 Latent Space Dynamic Analyses

We next explored the latent variables under different weighting factor \(\) settings. Setting a proper \(\) value can lead to richer latent variable dynamics. It is more advantageous to show how they relate to factors like anatomy and behavior through correlation analysis, thereby interpreting the inferred latent variables. The compressive loss term forces the latent variable to act like a minimal sufficient statistic of stimuli for predicting neural responses. Therefore, tiny \(\) values correspond to weak regularization provided by the compressive term. In this case, the latent representation learns to be more deterministic (Fig. 4E-Left). This prevents the model from benefiting from the regularization brought by the compressive loss term, resulting in poorer performance compared to moderate \(\) values (Fig. 4D). When using a large \(\), we observed that the latent variables seem to have lost some temporal information in the stimuli (Fig. 4E-Right). And, if \(\) is further increased, the model cannot obtain enough stimuli information to predict the responses, resulting in a sharp decline in performance (Fig. 4D).

#### 4.4.5 Functional Implication Analyses by In-silico Ablating

Temporal conditioning operationWe then evaluated the performance of TeCoS-LVM models without temporal conditioning operations, which is a reduced variant with an isotropic Gaussian prior (see also Appendix Fig. 5). Results in Fig. 4F show that the TeCo operation significantly improves model performance by exploiting the temporal dependencies. This suggests that visual coding requires the integration and manipulation of temporally dispersed information from continuous streams of stimuli.

Spiking hidden neuronsWe conducted experiments to investigate the effect of employing spiking neurons in modeling neural activity to natural stimuli (see also Appendix H). Specifically, we replaced all spiking hidden neurons in the TeCoS-LVM models with LIF-Rate neurons while retaining only the output spiking neurons so that the training pipeline remains unchanged. The LIF-Rate neurons maintain the neuronal recurrency by using the same membrane potential update as LIF and Noisy LIF neurons. This allows us to directly assess the effect of using spiking neurons by ablating them. Our experimental results show that the use of spiking neurons can significantly enhance the performance of computational models. As can be seen from Table 2, all performance indicators have significantly decreased after replacing the spiking hidden units with rate ones. Previous studies have pointed out that natural stimuli have a sparse latent structure ; therefore, using spiking hidden units may better fit the latent structure of natural stimuli by utilizing sparse spike representation. Also, previous research  indicated that the coding method of SNNs can lead to highly competitive results, which is consistent with the conclusion of this part of our experiment.

## 5 Related works

This work builds on previous research on modeling neural responses to visual scenes. Early attempts included Linear-nonlinear (LN) [68; 69] and Generalized Linear Models (GLMs) [2; 7]. However,

these models have limited capabilities and fail when faced with more complex stimuli [8; 9]. A promising way is to leverage powerful neural networks. One attractive advantage of this approach is that it may eliminate the need to specify spike statistics explicitly. McIntosh et al.  proposed a convolutional neural network (CNN) approach that outperformed LN and GLM baselines by a large margin. Some researchers have also investigated CNN variants with a recurrent layer [9; 15]. Batty et al.  proposed a hybrid model that combines GLMs and recurrent neural networks (RNNs) to separate spatial and temporal processing components in neural coding. Our model also has specified structures that deal with the time dimension, but the temporal and spatial processing are tightly integrated. Generative adversarial networks (GANs) have also been used to synthesize realistic neural activities , but this method cannot be used to predict neural responses given the stimuli. Mahuas et al.  introduced a novel two-step strategy to improve the basic GLMs. Bellec et al.  introduced a model with spiking response model (SRM) neurons and proposed a sample and measure criteria in addition to the traditional Poisson likelihood objective. More recently, Rahmani et al.  introduced the Gaussian Process prior and variational information bottleneck to LVMs for modeling retinal responses. Compared to biological coding systems, these methods have two aspects of authenticity missing (Fig. 2A). Firstly, most of these methods target trial-averaged firing rates. Secondly, they cannot directly process long stimuli sequences in a _natural paradigm_ but must divide them into segments of pre-defined lengths to be processed separately.

Latent variable modelsLVMs are popular tools for investigating and modeling neural response [18; 19; 72]. Some studies suggest that low-dimensional latent factors can effectively represent high-dimensional neural activities [16; 17]. In recent works, LVMs demonstrated promising results in uncovering the low-dimensional structure underlying complex neural activities in the motor region [20; 23; 22]. Also, LVMs have shown promise in visual neural coding modeling [18; 19; 21].

ConditioningConditioning is an effective technique to integrate information from multiple sources and realize adaptive information gating. Typically, conditioning methods rely on external information sources like labels  or outputs from other models [74; 75]. Some studies have demonstrated that direct conditioning on previous states can also significantly improve performance, especially in a sequential processing regime [49; 76]; these approaches are often termed self-conditioning or temporal conditioning. Notably, the temporal conditioning design exposed here is loosely inspired by the Tolman-Eichenbaum Machine , where the conditional operations ensure that the model profits from a sequential learning paradigm.

## 6 Discussion

This work presents the TeCoS-LVM (temporal conditioning spiking LVM) models. Our approach is formalized within the information bottleneck framework of latent variable models, inspired by the efficient coding theory [34; 38]. TeCoS-LVM models can directly produce neural response sequences in real-time rather than repeatedly producing single-step predictions, thus faithfully simulating the biological coding process. Using the retinal response to natural scenes as an example, we showed that TeCoS-LVM models effectively fit spike statistics, spike features, and recorded spike trains. In particular, TeCoS-LVM models that incorporate Noisy LIF neurons significantly exceed high-performance baselines. Also, learned TeCoS-LVM models generalize well to longer time scales, indicating that they can learn general temporal features from short-sequence training. Overall, TeCoS-LVM models effectively capture key features of biological coding systems while remaining computationally tractable.

OutlookAlthough we use visual coding as an example to demonstrate the impressive performance of TeCoS-LVM models in this article, the models exposed here _can be easily applied to sensory data of other modalities_. As such, TeCoS-LVM demonstrates a promising framework for building computational accounts for various sensory neural circuits and will enable richer models of complex neural computations in the brain.

LimitationsAs an accurate model that relates stimulus-driven responses, from a _neuroconnectionsim_ perspective , the TeCoS-LVM model aims to provide neuroscientific insights and understandings at the computational level. Compared to previous endeavors, TeCoS-LVM takes spike-based neural computation and natural processing paradigms into account. Nonetheless, while the TeCoS-LVM model makes predictions at the level of retinal cells, its fundamental principles are at a computational level, so it is only partially biophysically realistic.