# Higher-Order Causal Message Passing for

Experimentation with Complex Interference

 Mohsen Bayati\({}^{1}\) Yuwei Luo\({}^{1}\) William Overman\({}^{1}\) Sadegh Shirani\({}^{1}\) Ruoxuan Xiong\({}^{2}\)

\({}^{1}\) Stanford Graduate School of Business \({}^{2}\) Emory University

{bayati, yuweiluo, wpo, sshirani}@stanford.edu, ruoxuan.xiong@emory.edu

###### Abstract

Accurate estimation of treatment effects is essential for decision-making across various scientific fields. This task, however, becomes challenging in areas like social sciences and online marketplaces, where treating one experimental unit can influence outcomes for others through direct or indirect interactions. Such interference can lead to biased treatment effect estimates, particularly when the structure of these interactions is unknown. We address this challenge by introducing a new class of estimators based on causal message-passing, specifically designed for settings with pervasive, unknown interference. Our estimator draws on information from the sample mean and variance of unit outcomes and treatments over time, enabling efficient use of observed data to estimate the evolution of the system state. Concretely, we construct non-linear features from the moments of unit outcomes and treatments and then learn a function that maps these features to future mean and variance of unit outcomes. This allows for the estimation of the treatment effect over time. Extensive simulations across multiple domains, using synthetic and real network data, demonstrate the efficacy of our approach in estimating total treatment effect dynamics, even in cases where interference exhibits non-monotonic behavior in the probability of treatment.

## 1 Introduction

Randomized experiments are widely recognized as a reliable method in data-driven decision-making for determining the causal effects of new interventions, such as medical treatments or upgrades of market products. The conventional approach involves administering the new treatment to a randomly selected subset of the observation units (e.g., patients, products, or geographical areas), referred to as the _treatment_ group, and comparing their outcomes with those units who received no treatment, the _control_ group. However, the validity of these methods substantially relies on the assumption that treating a group of units does not interfere with the outcomes of the control units, known as the Stable Unit Treatment Value Assumption (SUTVA) (Cox, 1958; Rubin, 1978; Manski, 1990; Imbens and Rubin, 2015; Sussman and Airoldi, 2017).

In many social science and online marketplace scenarios, treating one unit impacts not only its outcome but also the outcomes of units that directly or indirectly interact with the treated unit (Bond et al., 2012; Blake and Coey, 2014; Holtz et al., 2020; Johari et al., 2022; Bright et al., 2022). This _interference_ of treatments and outcomes makes estimating the causal effect of the treatment particularly challenging. Considering the network of interactions, when a unit is treated, its interactions with neighboring units lead to subsequent changes in their outcomes. These interactions continue over the experimental time horizon and may display complex behaviors. For example, as the treatment is expanded to a larger population, the interference effect may intensify or diminish. This necessitates efficient data usage and robust estimators to capture and adapt to such intricacies.

Given the complexity of analyzing interference phenomena, research on network interference often relies on a series of simplifying assumptions. One common assumption is to ignore variations over time and assume outcomes are observed at equilibrium, which discards valuable information before the system reaches equilibrium. To reduce the complexity of the analysis, further assumptions are imposed on the nature and level of interference (Choi, 2017; Cortez et al., 2022; Li and Wager, 2022), such as the neighborhood interference assumption or assumptions on the maximum degree of the network. Additionally, a frequently made assumption to help estimate treatment effects is that the interference network is observed (Chen et al., 2024; Agarwal et al., 2022; Jia et al., 2024), which is impractical in some settings, such as under pervasive interference. For example, in large-scale online platforms, units may interact through competing platforms, making it difficult to account for all sources of interference. Our aim in this paper is to relax these assumptions.

The impact of network interference can be intricate, particularly when considering interactions among units over time. For example, applying the treatment to one unit can have _spillover effects_ on some control units, or one unit's outcome can directly exert _peer effects_ on other units' outcomes. Simultaneously, treatments with long-lasting effects can have _carryover effects_ to future time periods, and units' outcomes can be serially correlated or have _autocorrelation_ over time. Consequently, whenever SUTVA fails to hold, the number of potential outcomes grows exponentially with the population size and the time horizon of the experiment. This renders the estimation of causal effects under general interference structures impossible due to non-identifiability challenges (Manski, 2013; Aronow and Samii, 2017; Basse and Airoldi, 2018; Karwa and Airoldi, 2018; Forastiere et al., 2022).

Recently, Shirani and Bayati (2024) introduced a new framework called _Causal Message-Passing_ (CMP) to address the challenge of causal effect estimation under unobserved pervasive interference. Their methodology relies on observing outcomes over time and is rooted in statistical physics (Mezard et al., 1986; Mezard and Montanari, 2009) and approximate message passing (AMP) (Donoho et al., 2009; Bayati and Montanari, 2011) from high dimensional statistics. Instead of investigating the complex relationships among units, which requires knowledge of the network, CMP focuses on the dynamics of one-dimensional quantities, such as the sample mean and sample variance of units' outcomes over time. These one-dimensional equations, also known as _state evolution_ equations, can help track how the administered intervention propagates through the network of units over time, which enables the estimation of counterfactual scenarios. However, it remains underexplored how to use state evolution to estimate causal effects.

In this work, we propose to utilize machine learning to learn a mapping that updates key parameters of the distribution of outcomes over time for causal effect estimation. This is achieved by introducing a set of non-linear feature functions that act on the observed outcomes, creating a "basis" for the learning task. By training a properly designed machine learning model on this extracted basis, we estimate the Total Treatment Effect (TTE), also known as the Global Treatment Effect (GTE) or Global Average Treatment Effect (GATE), which measures the causal effect of altering the treatment scenario from treating no one to treating everyone. The result is a family of estimators that allow one to extract more information from the experimental data, thereby ensuring efficient use of the data.

To be more specific, this work builds on the foundation established by Shirani and Bayati (2024), extending their method in two directions by introducing Higher-Order Causal Message Passing (HO-CMP) algorithms. First, HO-CMP incorporates higher-order moments of unit outcomes, unlike Shirani and Bayati (2024)'s approach, which only employs the first moments for estimation. Second, while Shirani and Bayati (2024) focus solely on two-stage experiments with two different probabilities of treatment, our work leverages the additional data provided by having more than two experimental stages with multiple probabilities of treatment. Thus, our work aligns with the common practice in the tech industry of rolling out treatments through a sequence of experiments (Kohavi et al., 2020).

We then validate the performance of HO-CMP by simulating multiple experimental settings, encompassing both linear and non-linear outcome specifications and various types of interference, such as synthetic random geometric networks and real-world networks. Specifically, we introduce a _Non-LinearInMeans_ outcome specification, where the spillover effect is non-monotone in the fraction of treated neighbors; as an example of a complex treatment effect structure, we demonstrate how HO-CMP successfully estimates the total treatment effect by effectively utilizing higher-order moments of unit outcomes.

Simulating the experiments also allows us to calculate the ground truth value of the TTE, which remains unknown in real experiments, enabling us to compare the performance of HO-CMP to the ground truth TTE. Additionally, we benchmark HO-CMP against standard approaches such as difference-in-means and Horvitz-Thompson estimators, a recent technique of Cortez et al. (2022), and a first-order CMP estimation, like the one by Shirani and Bayati (2024). We emphasize that a large body of recent estimators, e.g., Jia et al. (2024), requires knowledge of the interference network and is not applicable in our setting. The results showcase HO-CMP outperforming the benchmarks in estimating the TTE over time and its flexibility to cover different outcome specifications and interference structures.

Related causal inference literature.The primary objective of research on causal inference in the context of network interference is to estimate causal effects while relaxing SUTVA. For this purpose, various assumptions and methods have been proposed. We briefly discuss the predominant ones.

A common approach to relax SUTVA is partial interference. Under this assumption, units are divided into disjoint clusters and interference is assumed only within the same cluster (Sobel, 2006; Rosenbaum, 2007; Hudgens and Halloran, 2012; Tchetgen and VanderWeele, 2012; Liu and Hudgens, 2014; Kang and Imbens, 2016; Viviano, 2020; Bhattacharya et al., 2020; Qu et al., 2021; Auerbach and Tabord-Meehan, 2021; Candogan et al., 2023; Ugander and Yin, 2023). When interference extends across clusters, standard estimators become biased. To address this, Eckles et al. (2016) propose a cluster-randomized approach that randomizes treatment assignment across clusters, reducing bias. However, it requires knowledge of the clusters.

The other assumption to replace SUTVA is the Neighborhood Interference Assumption (NIA). NIA states that outcomes are only influenced by the treatments of neighboring units in the network. This assumption is commonly imposed in the literature that relaxes the SUTVA (Sussman and Airoldi, 2017). Some recent studies combine the NIA with the availability of either a fully or partially observed interference structure (Leung, 2020; Viviano, 2020; Agarwal et al., 2022; Belloni et al., 2022; Li and Wager, 2022). Without prior knowledge of the interference structure, Cortez et al. (2022) consider low-degree polynomial interactions among units in the network. Leung (2022) also introduces a weaker version of the NIA, where the interference between two units located far away from each other is allowed to be nonzero, but negligible.

Another approach is to facilitate the estimation of causal effects by setting restrictions on the network structure (Chin, 2018; Jagadeesan et al., 2020; Wang et al., 2020; Li and Wager, 2022; Agarwal et al., 2022; Jagadeesan et al., 2020; Leung, 2022). These restrictions include bounding the largest node degree of the interference graph, limiting the degree of the dependency graph, observing specific patterns in the network, locally constrained interference structures, and restricting the topology of the interference network.

Driven by applications in marketplace platforms and two-sided marketplaces, several recent works have examined specific interference patterns (Holtz et al., 2020; Wager and Xu, 2021; Munro et al., 2021; Johari et al., 2022; Harshaw et al., 2022; Farias et al., 2022; Bright et al., 2022; Farias et al., 2023). For example, Farias et al. (2022) study experiments in Markovian systems where interference effects propagate through constraints like limited inventory.

From another perspective, most of the existing literature on network interference focuses on the case of single-time point observation (Hudgens and Halloran, 2012; Aronow and Samii, 2017; Basse et al., 2019; Jackson et al., 2020; Sayje et al., 2021). These studies have provided insightful results on spatial interference effects, but they often overlook temporal variations of the treatment effect. Recently, there has been a shift to consider settings with multiple-time observations (Li and Wager, 2022; Boyarsky et al., 2023). However, the problem of considering the dynamics of units' outcomes remains understudied (Arkhangelsky and Imbens, 2023).

## 2 Setup and Foundation

Consider a system of \(N\) units indexed by \(i[N]:=\{1,,N\}\) subject to a randomized experiment. The units are observed over a time horizon of \(T+1\) periods and for each \(t\{0,1,,T\}\), we let \(W_{t}^{i}\) denote the treatment status of unit \(i\) during time period \(t\). For simplicity, we consider a Bernoulli randomized design such that \(W_{t}^{i}(_{t})\). That is, at time \(t\) unit \(i\) receives the _treatment_ with a probability of \(_{t}\), corresponding to \(W_{t}^{i}=1\). Otherwise, unit \(i\) belongs to the _control_ group and \(W_{t}^{i}=0\). In this context, we collectively define \(=(_{0},_{1},,_{T})\) as the _experimental design_. Then, following the potential outcome framework (Imbens and Rubin, 2015), let \(Y_{t}^{i}()\) represent the potential outcome of unit \(i\) at time \(t\), where \(\) denotes the entire treatment allocation matrix, with \(W_{t}^{i}\) as the entry in row \(t\) and column \(i\).

Administering the treatment of unit \(i\) at time \(t\) according to \(w_{t}^{i}\) (as one realization of the random variable \(W_{t}^{i}\)), we use \(\) (as one realization of \(\)) to show the matrix that captures the treatments of all units throughout the experiment; accordingly, we let \(y_{t}^{i}=Y_{t}^{i}(=)\) be the observed outcome of unit \(i\) at time \(t\) under the treatment assignment \(\):

\[=w_{0}^{1}&w_{0}^{2}&&w_{0}^{N}\\ w_{1}^{1}&w_{1}^{2}&&w_{1}^{N}\\ &&&\\ w_{T}^{1}&w_{T}^{2}&&w_{T}^{N},= y_{0}^{1}&y_{0}^{2}&&y_{0}^{N}\\ y_{1}^{1}&y_{1}^{2}&&y_{1}^{N}\\ &&&\\ y_{T}^{1}&y_{T}^{2}&&y_{T}^{N}.\]

Observing \((,)\), we are interested in estimating the TTE of the intervention, defined as below:

\[_{t}=_{N}_{i=1}^{N}[Y_{t}^{i}( )-Y_{t}^{i}()], t=0,1,,T,\] (1)

where \(\) and \(\) are matrices of all \(1\) and all \(0\) of appropriate dimensions (in this case, \(T+1\) by \(N\)). Intuitively, the TTE measures the average effect of changing the treatment for the entire population. This is a common estimand in the network interference literature and provides important insights into the efficacy of the treatment for decision-makers (Jia et al., 2024; Chen et al., 2024; Viviano et al., 2023; Yu et al., 2022; Cortez et al., 2022).

Deriving a practical and efficient estimator for the TTE is challenging due to the fact that we can observe the population only under one treatment scenario (Holland, 1986). Indeed, in Eq. (1), we can observe at most one of \(Y_{t}^{i}()\) or \(Y_{t}^{i}()\), and often, neither.1 In the following sections, we address this challenge by proposing a new class of estimators grounded in the CMP framework. These estimators rely on the efficient use of experimental data, \(\) and \(\), yielding accurate causal estimation under unknown network interference.

### Potential outcome specification and state evolution of the experiment

In this section we provide a summary of the outcome specification and results of Shirani and Bayati (2024) that we utilize in the remaining. For \(t=0,1,,T-1\), we let \(g_{t}:^{T+1}\) be an unknown measurable function. We also use \(^{i}=(W_{0}^{i},,W_{T}^{i})^{}\) to denote the treatment assignment of unit \(i\) during the experiment. Accordingly, the treatment allocation matrix \(\) is a \(T+1\) by \(N\) matrix with columns equal to \(^{i}\). Given potential outcomes \(Y_{t}^{j}()\) at time \(t\) and \(j[N]\), their outcomes in time period \(t+1\) are specified by

\[Y_{t+1}^{i}()=_{j=1}^{N}^{ij}g_{t}(Y_{t}^{j}(), ^{j})+_{t}^{i}, t=0,1,,T-1,\] (2)

where \(^{ij}\) quantifies the impact of unit \(j\) on unit \(i\) at time \(t\) and \(_{t}^{i}\) is a zero-mean Gaussian noise with a variance of \(_{e}^{2}\), accounting for measurement errors. In addition, we let \(=[^{ij}]_{i,j[N]}\) and refer to it as the _interference matrix_. Then, according to Eq. (2), the function \(g_{t}\) captures the impact of past outcomes and treatment assignments of other units on the current outcome of unit \(i\).

Now, fixing \(t\), we define

\[_{t}():=_{N}_{i=1}^{N}Y_{t}^{i}(), _{t}()^{2}:=_{N}_{i=1}^{N}Y_{t}^{i} ()^{2}-_{t}()^{2}.\] (3)

Then, as shown by Shirani and Bayati (2024), whenever the elements of the interference matrix \(^{ij}\) are i.i.d. Gaussian random variables with mean \(/N\) and variance \(^{2}/N\), under mild moment conditions on initial values \(Y_{0}^{i}\), we have

\[_{t+1}()&}}{{=}}[g_{t}_{t}()+_{t}( )Z_{t},],\\ _{t+1}()^{2}&}}{{=}}^{2}[g_{t}_{t}()+_{t}( )Z_{t},^{2}]+_{e}^{2},\] (4)where \(Z_{t}(0,1)\) is independent from \(()\) (that is, \(W_{t}(_{t})\) and \(=(W_{0},W_{1},,W_{T})^{}\)) and the equalities hold almost surely. We note that the theory behind this result is rooted in the AMP literature, going back to Bolthausen (2014), Bayati and Montanari (2011). However, as Shirani and Bayati (2024) note, there is a major distinction between the AMP literature and the above setting: in the AMP literature, the matrix \(\) is observed, and the aim is to construct proper functions \(g_{t}\) for a completely different objective, which is studying the high-dimensional asymptotics of first-order algorithms. However, in the current context, the matrix \(\) and functions \(g_{t}\) are _unknown_ and the goal is to estimate them.

Considering Eq. (3), the equations in (4) determine the dynamics of the sample mean and sample variance of unit outcomes over time in large sample asymptotics, and are denoted by the State Evolution (SE) equations of the experiment (Shirani and Bayati, 2024). In the next section, we present an efficient algorithm to learn the state evolution dynamics outlined in Eq. (4). This method enables us to accurately estimate the TTE defined in Eq. (1) and its corresponding confidence interval.

## 3 Algorithm

In this section, we introduce _Higher-order Causal Message-passing_ (HO-CMP) for estimating the TTE over the entire time horizon of the experiment. Briefly speaking, HO-CMP directly estimates the update function in the state evolution equations (4), thereby estimating counterfactual quantities while accounting for the impact of unknown network interference. To this end, by Eqs. (1) and (3), we rewrite the TTE as the difference of the sample means in the large limits:

\[_{t}=_{t}()-_{t}().\]

That means the problem of estimating the TTE is equivalent to estimating \(_{t}()\) and \(_{t}()\) using the observed data, denoted by \((,)\). On the other hand, considering the state evolution equations in (4), the _system state_ at time \(t+1\), denoted by \((_{t+1}(),_{t+1}()^{2})\), is a (nonlinear) function of the system state distribution at time \(t\), characterized by \((_{t}(),_{t}()^{2})\) and \(\), encompassing the sample mean and variance of observed outcomes as well as the design of the experiment. However, because the exact functional form and parameters of equations in (4) are unknown, one cannot directly apply the SE to track the evolution of states. Therefore, we propose to estimate the unknown update functions in SE equations, utilizing the observed data \((,)\). For this purpose, we fix the treatment assignment matrix \(\) and define

\[_{t}() :=_{i=1}^{N}y_{t}^{i},_{t}( )^{2}:=_{i=1}^{N}y_{t}^{i}-_{t}() ^{2},\] \[_{t} :=_{i=1}^{N}w_{t}^{i},}:=(_{0},,_{T})^{}.\]

In addition, let \(=(_{k})_{k[K]}\) be a prespecified vector of measurable feature functions of current estimates of the sample mean \(_{t}()\), sample variance \(_{t}()^{2}\), and the design \(\). We define \(_{t}\) to represent the _feature vector_ as follows:

\[_{t}=_{t}(),_{t}(), {w}_{1}_{t}(),_{t} (),\,,,\,_{K}_{t}(),_{t}(),^{}.\]

Then, we formally propose learning the mapping \(f_{}()\) defined by,

\[(_{t+1}(),_{t+1}()^{2})=f_{}(_ {t})\] (5)

We summarize the method in Algorithm 1. Note in our experiment design we begin with all units under control by setting \(_{0}=0\), meaning no units receive treatment in period \(0\). Additionally, to avoid non-identifiability issues, the experiment requires at least two stages, which corresponds to having at least two distinct values in the set \(\{_{1},,_{T}\}\).

The proposed HO-CMP method encompasses a rich family of estimators, offering flexibility through the selection of feature functions \(\{_{k}\}_{k[K]}\) and model \(f_{}()\). Specifically, incorporating proper feature (basis) functions, with examples shown in Table 1, facilitates the extraction of informative patterns for learning the unknown nonlinear dynamics of the system throughout the experiment. Inpractice, one could choose these basis functions based on heuristics, domain knowledge, and prior information about the dynamics.

Specifically, in this paper, we consider the following estimators, as summarized in Table 1.

FO-CMP (First-Order Causal Message-Passing): This corresponds to the simple setting where \(_{t+1}()\) is assumed to be a function of the previous sample mean \(_{t}()\), the sample mean of the current treatment \(_{t+1}\), and an additional term to model the interaction of the dynamics and previous treatments \(_{t}()_{t}\). Consequently, this model is irrelevant of the variance \(_{t+1}()^{2}\). This is true when \(g_{t}\) takes a simple nonlinear form \(g_{t}(y_{t},)= y_{t}+ w_{t+1}+ y_{t}w_{t}\). We remark that FO-CMP essentially uses the first state evolution equation in (4) and fails to extract informative signals from the second evolution equation.

HO-CMP (Higher-Order Causal Message-Passing): HO-CMP further introduces the second-order terms \((_{t+1})^{2}\) and \(_{t}()^{2}\) to model the nonlinear treatment effects. It improves data efficiency by utilizing both state evolution equations. It also allows estimation of higher order terms in Taylor series of \(g_{t}\).

While FO-CMP extends the estimation algorithm in Shirani and Bayati (2024) to accommodate experiments with more than two stages, HO-CMP introduces a new dimension to the estimation problem by incorporating second-order terms. This inclusion enhances data utilization, resulting in higher estimation efficiency in HO-CMP compared to FO-CMP.

**Data:** Observed data \((,)\), feature functions \(=(_{k})_{k[K]}\), machine learning model \(f_{}()\)

**Step 1: Data processing**

**for** \(t 0\) _to T_ **do**

\(_{t}()_{i=1}^{N}y_{t}^{i}\),

\(_{t}()^{2}_{i=1}^{N}(y_{t}^{i}-_{t}())^{2}\),

\(_{t}(_{t}(),_{t}()^{2},)\)

**end**

**Step 2: Model Estimation**

Estimate \(f_{}\) from data \(\{_{t},(_{t+1}(),_{t+1}( )^{2})\}_{t[T-1]}\), guided by (5).

**Step 3: Counterfactual Estimation**

\(_{0}()_{0}()\), \(_{0}()_{0}()\), \(_{0}()^{2}_{t}()^{2}\), \(_{0}()^{2}_{t}()^{2}\), \(}_{0} 0\)

**for** \(t 0\) _to T_ \(-1\) **do**

Compute the features and predict the counterfactuals

\(_{t}()(_{t}(),_{ t}()^{2},)\), \(_{t}()(_{t}(),_{ t}()^{2},)\)

\((_{t+1}(),_{t+1}()^{2}) f _{}(_{t}())\), \((_{t+1}(),_{t+1}()^{2}) f _{}(_{t}())\)

Estimate the TTE

\(}_{t+1}_{t+1}()-_{t+1}( )\)

**end**

**Result:**\(\{}_{t}\}_{t[T]}\)

   Algorithms & Feature functions \(\{_{k}(_{t}(),_{t}()^{2},)\}_{k[K]}\) & \(f_{}()\) \\  FO-CMP & \(\{_{t}(),_{t+1},_{t}()_{t}\}\) & linear regression \\ HO-CMP & linear regression \\   

Table 1: Two examples of feature functionsExperiments

In this section, we use synthetic experiments under simulated and real-world network interference patterns, to compare the performance of FO-CMP and HO-CMP estimators, outlined in Table 1 and Algorithm 1, with several benchmarks. First, we introduce the experimental design, benchmark estimators, interference patterns, and outcome specifications.

Experimental design.We primarily focus on the staggered rollout design with \(L\) distinct treated probabilities, denoted by \(^{(1)},,^{(L)}\), where \(^{()}\) increases monotonically with \(\{1,,L\}\). In the first \(T^{(1)}\) periods, \(^{(1)} 100\%\) of units are in the treatment group. From \(T^{(1)}\) to \(T^{(2)}\) periods, \(^{(2)} 100\%\) of units are in the treatment group, and so forth. In the staggered rollout design, once a unit is allocated to treatment, it remains in the treatment group until the experiment concludes (Xiong et al., 2024). In the appendix, we also consider the Bernoulli randomized design, where the treatment is re-randomized at every time period, allowing units to switch between the treatment and control groups throughout the experiment. We use two values of \(T=40,\ 200\) and set \(L=4\), with \((^{(1)},^{(2)},^{(3)},^{(4)})=(0.1,0.2,0.4,0.5)\). In the appendix, we show the impact of increasing \(L\) or the maximum treatment probability \(^{(L)}\).

Benchmark estimators.We first present two benchmark estimators commonly used for treatment effect estimation, both in settings with and without network interference. The final estimator is designed specifically for settings with unknown network interference (Cortez et al., 2022).

The first benchmark estimator is the standard difference-in-means (DM) estimator given by

\[}_{t}^{}=^{N}y_{t}^{j}w_{t}^ {j}}{_{j=1}^{N}w_{t}^{j}}-^{N}y_{t}^{j}(1-w_{t}^{j})}{ _{j=1}^{N}(1-w_{t}^{j})}\,,\]

which is the difference in average outcomes between treated and control units at each time period \(t\).

The second benchmark is the standard Horvitz and Thompson (1952) (HT) estimator given by

\[}_{t}^{}=_{j=1}^{N}[ {y_{t}^{j}w_{t}^{j}}{_{t}}-^{j}(1-w_{t}^{j})}{1-_{t}}]\,,\]

which weights observed outcomes by the inverse propensity score (i.e., \(1/_{t}\) or \(1/(1-_{t})\)).

The third benchmark estimator is the polynomial interpolation estimator (PolyFit) introduced by Cortez et al. (2022). PolyFit operates by obtaining estimates for the average of outcomes at equilibrium for \(L\) treated probabilities \(^{(1)},,^{(L)}\), denoted by \(_{}(^{(1)}),,_{}(^{(L)})\), then it utilizes Lagrange interpolation method and obtains a degree-\(L\) polynomial approximation for the function \(_{}:\) which can be used to estimate the equilibrium values under global control and treatment, \(_{}(0)\) and \(_{}(1)\). Finally, TTE is estimated by

\[}_{t}^{}=_{}(1)- _{}(0)\,.\]

On the one hand, PolyFit does not need any knowledge of the interference network; however, it comes at the expense of having to grapple with two challenges. First, it may incur a high variance as \(L\) increases due to fitting a high-degree polynomial. The second challenge is that it needs accurate estimates for each \(_{}(^{()})\), which requires treating \(^{()}\) fraction of units for a long enough number of periods so that the outcomes reach an equilibrium. This can be achieved if the staggered roll-out design is performed over a long enough horizon \(T\) with each \(T^{()}\) sufficiently large, and then estimating each \(_{}(^{()})\) by sample average of outcomes at time \(T^{()}\). However, when such a lengthy experiment is not feasible, the estimates for \(_{}(^{()})\) will be less accurate.

Interference networks.We consider two networks (graphs). The first graph is a simulated random geometric graph model, studied by Leung (2022). The second graph is a social network of Twitch users (Rozemberczki and Sarkar, 2021). In either scenario, we denote the adjacency matrix of the graph by \(E\{0,1\}^{N N}\). For any \(i\) and \(j\), \(E_{ij}\) equals \(1\) if \(j\) is a neighbor of \(i\) and \(0\) otherwise.

Outcome generating processes.We consider two outcome specifications to model monotone and non-monotone interference patterns. Specifically, for both settings, we generate outcomes using the following specification:

\[Y_{t+1}^{i}=+^{N}E_{ij}Y_{t}^{j}}{_{j=1}^{N}E_{ij }}+ g(^{N}E_{ij}W_{t+1}^{j}}{_{j=1}^{N}E_{ ij}})+ W_{t+1}^{i}+_{t+1}^{i}\,,\]

where in the first setting, \(g()\) is taken to be the identity function, i.e., \(g(x)=x\) for any \(x\). Therefore, \(Y_{t+1}^{i}\) depends linearly on the fraction of treated neighbors, and we refer to this setting as the _LinearInMeans_ outcome setting. This setting is widely studied in the causal inference literature (Cai et al., 2015; Eckles et al., 2016; Leung, 2022).

In the second setting, \(g()\) is specified by a periodic function, i.e., \(g(x)=(\! x)\) for any \(x\). Therefore, \(Y_{t+1}^{i}\), on average, first increases and then decreases with the fraction of treated neighbors, as visualized by the Ground Truth curve in panel (a) of Figure 1. We refer to this setting as the _Non-LinearInMeans_ outcome setting.

Results.We compare FO-CMP and HO-CMP with the three benchmarks for estimating the TTE across the aforementioned outcome specifications and interference networks for long (\(T=200\)) and short (\(T=40\)) horizons. In each scenario, we perform 100 simulations of the synthetic experiment. The resulting distributions of ground truth and estimated TTEs are shown in Figures 2-5. All experiments were conducted on a MacBook Air with an Apple M1 chip and 16 GB of memory, with each setting taking about 15 minutes for 100 iterations. The key takeaways are as follows.

First, the DM and HT estimators exhibit significant bias across all cases. This is intuitive, as they estimate the TTE without accounting for the network interference.

Second, in the _LinearInMeans_ outcome setting, FO-CMP and HO-CMP achieve low estimation error and minimal bias. This holds for both long experiment durations (\(T=200\)), where outcomes reach equilibrium, and short experiment durations (\(T=40\)), where outcomes have not yet reached equilibrium, as shown in Figures 2 and 3, respectively.

Third, as expected, PolyFit's dependence on accurate estimates for each \(_{}(^{()})\) requires a large \(T\) to reduce estimation bias. This is evident when comparing Figures 2 and 3: with a smaller \(T\), PolyFit shows bias. This is also demonstrated in panel (b) of Figure 1, where the red points--which represent sample averages of outcomes at \(T^{(1)},,T^{(4)}\)--have not yet converged and are slightly lower than their ground truth (equilibrium) values. This causes PolyFit's estimation of \(_{}(1)\) to be inaccurate, leading to a large bias. In contrast, HO-CMP, as shown in panel (c) of Figure 1, is immune to this problem as it is designed to work with off-equilibrium data. Even with a larger \(T\), the degree-\(L\) polynomial estimation costs PolyFit with higher variance than both FO-CMP and HO-CMP, as shown in Figure 2. Overall, this underscores the more efficient data utilization of FO-CMP and HO-CMP through their ability to leverage off-equilibrium data.

Fourth, in the _Non-LinearInMeans_ outcome setting, HO-CMP achieves substantially lower estimation error compared to FO-CMP, as shown in Figures 4 and 5. This makes intuitive sense, as the higher

Figure 1: (a) \(_{}()\) with PolyFit and HO-CMP estimates across runs (Non-LinearInMeans). (b) and (c) show one sample estimates with observed data points.

order terms in HO-CMP better capture the nonlinearity of \(_{}()\) in \(\), while leveraging the additional data on sample variance dynamics over time, thereby enhancing the estimation accuracy.

Finally, the proposed estimation method demonstrates robustness across different experimental setups, including both _LinearInMeans_ and _Non-LinearInMeans_ outcome specifications. Additionally, robustness to graph structure--random versus Twitch graph--is evident from comparing the left and right plots in Figures 2-5. In Figure 6 of Appendix A, we also demonstrate the robustness of the proposed methods to various parameters: the number of treatment probabilities \(L\), the maximum treatment probability \(^{(L)}\), and the choice of experimental design (staggered rollout versus Bernoulli randomization).

## 5 Conclusion

Estimating causal effects under pervasive interference presents significant challenges (Sussman and Airoldi, 2017). Building on the causal message-passing framework of Shirani and Bayati (2024), we incorporate higher-order moments of observed outcomes and treatment probabilities to estimate the total treatment effect, without requiring knowledge of the interference network. Our approach leverages machine learning techniques to extract informative patterns from these higher moments, enabling our estimator to capture complex counterfactual behaviors, including non-monotonic trends in outcome means relative to treatment proportions. While we demonstrate strong performance across various outcome specifications and network structures, the framework's applicability may be limited when multiple outcome observations are unavailable.