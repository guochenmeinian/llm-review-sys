# Tree-Based Diffusion Schrodinger Bridge

with Applications to Wasserstein Barycenters

 Maxence Noble

CMAP, CNRS, Ecole polytechnique,

Institut Polytechnique de Paris,

91120 Palaiseau, France

&Valentin De Bortoli

Computer Science Department,

ENS, CNRS, PSL University

Arnaud Doucet

Department of Statistics,

University of Oxford, UK

&Alain Oliviero Durmus

CMAP, CNRS, Ecole polytechnique,

Institut Polytechnique de Paris,

91120 Palaiseau, France

Corresponding author. Contact at: maxence.noble-bourillot@polytechnique.edu.

###### Abstract

Multi-marginal Optimal Transport (mOT), a generalization of OT, aims at minimizing the integral of a cost function with respect to a distribution with some prescribed marginals. In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i.e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree. To address this problem, we develop Tree-based Diffusion Schrodinger Bridge (TreeDSB), an extension of the Diffusion Schrodinger Bridge (DSB) algorithm. TreeDSB corresponds to a dynamic and continuous state-space counterpart of the multi-marginal Sinkhorn algorithm. A notable use case of our methodology is to compute Wasserstein barycenters which can be recast as the solution of a mOT problem on a star-shaped tree. We demonstrate that our methodology can be applied in high-dimensional settings such as image interpolation and Bayesian fusion.

## 1 Introduction

In the last decade, computational Optimal Transport (OT) has shown great success with applications in various fields such as biology (Schiebinger et al., 2019; Bunne et al., 2022), shape correspondence (Su et al., 2015; Feydy et al., 2017; Eisenberger et al., 2020), control theory (Bayraktar et al., 2018; Acciaio et al., 2019) and computer vision (Schmitz et al., 2018; Carion et al., 2020). While OT commonly seeks at computing the transport plan that minimizes the cost of moving between two distributions, it can naturally be extended to the multi-marginal setting (mOT) when considering several distributions. This extension of OT has notably been studied in quantum chemistry (Cotar et al., 2013), clustering (Cuturi and Doucet, 2014) and statistical inference (Srivastava et al., 2018). In particular, a popular application in unsupervised learning of mOT with Euclidean cost consists in computing the Wasserstein barycenter of a set of probability distributions (Agueh and Carlier, 2011; Benamou et al., 2015; Alvarez-Esteban et al., 2016; Peyre et al., 2019).

Interior point methods can be used to solve OT and mOT problems but they come with computational challenges (Pele and Werman, 2009). In order to mitigate these limitations, one often considers an _entropic regularization_ of OT, known as Entropic OT (EOT). This regularized formulation can be efficiently solved in discrete state-spaces using the celebrated _Sinkhorn_ algorithm (Cuturi, 2013; Knight, 2008; Sinkhorn and Knopp, 1967), which admits a continuous state-space counterpart referredto as the _Iterative Proportional Fitting_ (IPF) procedure (Fortet, 1940; Kullback, 1968; Ruschendorf, 1995). In the case of a quadratic cost, EOT is equivalent to the _static_ formulation of the Schrodinger Bridge (SB) problem (Schrodinger, 1932). Given a reference diffusion with finite time horizon \(T\) and two probability measures, solving SB amounts to finding the closest diffusion to the reference (in terms of Kullback-Leibler divergence on path spaces) with the given marginals at times \(t=0\) and \(t=T\). This framework naturally arises in stochastic control (Dai Pra, 1991) where one aims at controlling the marginal distribution of a stochastic process at a fixed time. Recently, De Bortoli et al. (2021) introduced Diffusion Schrodinger Bridge (DSB), an approximation of a _dynamic_ version of the IPF scheme on path spaces, see also Vargas et al. (2021); Chen et al. (2022). This methodology leverages advances in the field of denoising diffusion models (Song et al., 2021; Ho et al., 2020) in order to derive a scalable and efficient scheme to solve SB, and thus EOT.

Similarly to OT, mOT admits an entropic regularization (EmOT), which can be solved via a multi-marginal generalization of Sinkhorn/IPF algorithm (Benamou et al., 2015; Marino and Gerolin, 2020). Recently, Haasler et al. (2021) proposed an extension of the _static_ SB problem in _discrete_ state-space to any multi-marginal tree-based setting. They notably made the correspondence between this formulation and EmOT, when the cost function writes as the sum of interaction energies onto the given tree structure, and introduced an efficient version of Sinkhorn algorithm to solve it.

Motivations and contributions.In this work, we investigate the _continuous_ and _dynamic_ counterpart of the tree-based framework from Haasler et al. (2021). To be more specific, we present an extension of the static SB formulation in continuous state-space to any multi-marginal tree-based setting, referred to as TreeSB. Then, we establish the equivalence between TreeSB and a formulation of EmOT relying on a (quadratic) tree-structured cost function, analogously to Haasler et al. (2021). Inspired by DSB, we develop TreeDSB, a dynamic counterpart of the multi-marginal IPF (mIPF) to solve it, by operating on path spaces and using score-based diffusion techniques. To bridge gaps in literature, we prove the convergence of mIPF iterations in a _non-compact_ setting under mild assumptions, by extending results on IPF convergence (Ruschendorf, 1995). Finally, we illustrate our approach on examples of Wasserstein barycenters from statistical inference and image processing.

Although our approach can be applied to any tree, we focus on _star-shaped trees_. In this setting, we show that TreeSB reduces to a regularized Wasserstein barycenter problem. Our method comes with several benefits compared to existing works. First, it is out-of-sample, _i.e._, it does not require re-running the full procedure when given a new data point. Second, our formulation of the Wasserstein barycenter problem obtained from TreeSB allows us to avoid numerical issues of having to choose the regularization too small, see Section 5. Finally, to the best of our knowledge, this is the first methodology to extend ideas from diffusion-based models to the computation of Wasserstein barycenters. In particular, we believe that the idea of iterative refinement, _i.e._, solving the _dynamic_ counterpart of a _static_ problem, plays a key role in the efficiency and scalability of the method.

Notation.For any measurable space \((,)\), we denote by \(()\) the space of probability measures defined on \((,)\). Unless specified, \(\) is defined as the Borel sets on \(\). For any \(\), let \(^{()}=((^{d})^{})\); we denote \(^{(1)}\) by \(\). Assume that \(=(^{d})^{}\) for some \(\). For any \(x\) and any \(m,n\{0,,\}\) such that \(m n\), let \(x_{m:n}=(x_{m},x_{m+1},,x_{n})\). Let \(\) be the Lebesgue measure. For any non-negative function \(f:_{+}\), such that \(_{}f<+\), define \((f)=-_{}f f(-,+]\). For any distribution \(()\), we define the entropy of \(\) as \(()=(/)\) if \(\) and \(()=+\) otherwise. For any two arbitrary measures \(\) and \(\) defined on \((,)\), define the Kullback-Leibler divergence between \(\) and \(\) as \((|)=_{}(/)-_{}+_{}\) if \(\) and \(()=+\) otherwise. For any \(T>0\), we denote by \(([0,T],^{d})\) the space of continuous functions from \([0,T]\) to \(^{d}\). For any path measure \((([0,T],^{d}))\), we denote by \(()^{(2)}\) the coupling between the _extremal_ distributions of \(\), _i.e._, \(()=_{0,T}\). Note that, for a given coupling \(_{0,T}^{(2)}\), there may exist several path measures \(\) verifying \(()=_{0,T}\). For any undirected tree \(=(,)\) with vertices \(\) and edges \(\), we denote by \(\{v,v^{}\}\) (or \(\{v^{},v\}\)) the undirected edge between \(v\) and \(v^{}\), if it exists. Given \(r\), we denote by \(_{r}=(,_{r})\) the directed version of \(\) rooted in \(r\), where the directed edges \(_{r}\) are uniquely defined from the edges \(\), see Appendix B for further details. In this case, the edge linking \(v\) to \(v^{}\) in \(_{r}\) is denoted by \((v,v^{})\). Finally, for any integers \((n,K)^{*}\), we define \(n(K)\) as the the remainder of the Euclidean division of \(n\) by \(K\).

## 2 Background and setting

Multi-marginal optimal transport.Let \(^{*}\). Given a cost function \(c:(^{d})^{+1}\), a subset \(\{0,,\}\) and a family of probability measures \(\{_{i}\}_{i}^{|S|}\), mOT consists in solving

\[^{}=\{ c(x_{0:})(x_{0:}): ^{(+1)},\ _{i}=_{i}\, i\},\] (mOT)

where \(_{i}\) is the \(i\)-th marginal of \(\), _i.e._, \(_{i}()=(_{i}^{-1}())\) for any \((^{d})\), with \(_{i}:x_{0:} x_{i}\). Given some weights \((w_{i})_{i\{1,,\}}(_{+})^{}\), the Wasserstein barycenter between the measures \(\{_{i}\}_{i}\) is given by \(_{0}^{}\) in (mOT), in the case where \(=\{1,,\}\) and \(c(x_{0:})=_{i=1}^{}w_{i}\|x_{0}-x_{i}\|^{2}\)(Peyre et al., 2019). In particular, when \(w_{i}=1/\), the distribution \(_{0}^{}\) can be regarded as the Frechet mean (Karcher, 2014) of the measures \(\{_{i}\}_{i}\) for the Wasserstein distance of order 2. Similarly to OT, (mOT) can be relaxed using the following entropic regularization

\[^{}=\{ c(x_{0:})(x_{0:})+ (|):^{(+1)},\ _{i}=_{i}\, i \},\] (EmOT)

where \(>0\) is a hyperparameter and \(\) is an arbitrary measure defined on \(((^{d})^{+1},((^{d})^{+1}))\).

Link with Schrodinger Bridge.We first recall the relationship between Schrodinger Bridge and EOT. Given \(T>0\), \(\) a (reference) path measure, _i.e._, \((([0,T]\,,^{d}))\) and two measures \(_{0},_{1}(^{d})\), solving the SB problem amounts to finding the path measure \(^{}\) defined by

\[^{}=\!\{(|)\ :\  (([0,T]\,,^{d})),\ _{0}=_{0},\ _{T}=_{1}\}\.\] (SB)

If \(\) is associated with a Stochastic Differential Equation (SDE)2, of the form \(_{t}=-a_{t}t+_{t}\), with \(a 0\), then it can be shown, see (Leonard, 2014, Proposition 1) that \(^{}_{0,T}\) verifies

\[^{}_{0,T}=\!\{(|_{0,T})\ :\  ^{(2)},\ _{0}=_{0},\ _{1}=_{1}\}\.\] (static-SB)

This is called the _static_ formulation of SB. It can be shown that solving (static-SB) is equivalent to solving EOT with quadratic cost and regularization \(=2(aT)/a\) if \(a>0\), \(=2T\) if \(a=0\). Moreover, since \(^{}=^{}_{0,T}_{|0,T}\), where \(_{|0,T}\) is the measure \(\) conditioned on initial and terminal conditions, solving the _dynamic_ problem (SB) is equivalent to solving (static-SB).

Similarly, (EmOT) can be easily rewritten in a _static_ multi-marginal SB fashion

\[^{}=\!\{(|^{0})\ :\ ^{(+1)},\ _{i}=_{i}\, i\}\,\] (mSB-like)

with \((^{0}/)(x_{0:})[-c(x_{0:} )/](/)(x_{0:})\), where \(^{0}\) is the _reference_ measure.

Diffusion Schrodinger Bridge.Recently, De Bortoli et al. (2021) introduced Diffusion Schrodinger Bridge (DSB), a numerical scheme to solve (SB). It approximates the iterates of a _dynamic_ version of the _Iterative Proportional Fitting_ (IPF) scheme (Sinkhorn and Knopp, 1967; Knight, 2008; Peyre et al., 2019; Cuturi and Doucet, 2014), which can be described as follows: consider a sequence of path measures \((^{n})_{n}\) such that \(^{0}=\) and for any \(n\)

\[^{2n+1}=\!\{(|^{2n})\ :\ _{T}=_{1}\},^{2n+2}=\!\{( |^{2n+1})\ :\ _{0}=_{0}\}\.\]

This procedure alternatively projects between the measures with fixed initial distribution and the ones with fixed terminal distribution. For the first iteration, we get that \(^{1}=_{1}_{|T}\). Assuming that \(\) is given by \(_{t}=f_{t}(_{t})t+_ {t}\), with \(f:\ [0,T]^{d}^{d}\), then \(^{1}\) is associated with the _time-reversal_ of this SDE initialized at \(_{1}\). The time-reversal of an SDE has been derived under mild assumptions on the drift and diffusion coefficients (Haussmann and Pardoux, 1986; Cattiaux et al., 2021). In this case, we have \((_{T-t})_{t}^{1}\), with \(_{0}_{1}\) and

\[_{t}=\{-f_{T-t}(_{t})+ p_{T-t}(_{t})\}t+_{t},\]

where \(p_{t}\) is the density of \(^{0}_{t}\) w.r.t. the Lebesgue measure. The score \( p_{t}\) is estimated using score matching techniques (Hyvarinen, 2005; Vincent, 2011). The first iterate of DSB, \(^{1}\), corresponds to a _denoising diffusion model_(Ho et al., 2020; Song et al., 2021). DSB iterates further and not only parameterizes the backward process but also the forward process. It can therefore be seen as a refinement of diffusion models drawing a bridge between generative modeling and optimal transport.

Tree-based framework.Consider an undirected tree \(=(,)\), with vertices \(\) and edges \(\), such that \(\) is identified with \(\{0,,\}\). Inspired by Haasler et al. (2021), we restrict our study of (EmOT), to the case where the cost function \(c\) is the tree-structured _quadratic_ cost derived from \(\)

\[c(x_{0:})=_{\{v,v^{}\}}w_{v,v^{}}\|x_{v}-x_{v^ {}}\|_{2}^{2}\,\] (1)

where \(w_{v,v^{}}\) is a weight on the edge \(\{v,v^{}\}\), which links \(v\) to \(v^{}\) (and \(v^{}\) to \(v\)). Furthermore, as in Haasler et al. (2021), we choose \(\), _i.e._, the set of vertices of \(\) with constrained marginals, to coincide with the _leaves_ of \(\). This framework recovers important applications, from Wasserstein barycenters to Wasserstein propagation, see Solomon et al. (2014, 2015). We emphasize that it differs from an OT problem defined on the space of graphs (Chen et al., 2016). Here, each node represents a probability measure (observed or to be inferred) and each edge represents a coupling between two distributions.

We consider an arbitrary vertex \(r\) and choose \(\) in (EmOT) such that \((/)(x_{0:})=_{r}(x_{r})\), where \(_{r}\) is a density defined on \(^{d}\). Due to the form of \(\) and \(c\), the reference measure \(^{0}\) in (mSB-like) is therefore a _probability_ distribution which factorizes along \(_{r}=(,_{r})\), the directed version of \(\) rooted in \(r\). We refer to Appendix B for more details on the notion of directed trees. In this setting, (EmOT) is equivalent to the tree-based problem

\[^{}=\{(|^{0})\,:\  ^{(|)},\ _{i}=_{i}\, i\}\,\] (TreeSB) \[^{0}=^{0}_{r}_{(v,v^{}) _{r}}^{0}_{v^{}|v}\,\] (2)

where \(^{0}_{v^{}|v}( x_{v})=(x_{v},/(2w_{v,v^ {}})_{d})\) and \(^{0}_{r}\) with density \(_{r}\). In a manner akin to Haasler et al. (2021), we thus establish, in _continuous_ state-space, the correspondence between (TreeSB), a _static_ tree-based version of SB, and a version of EmOT with tree-structured cost (1). In our work, we make the following assumption on the constrained marginals \(\{_{i}\}_{i}\).

**A0**.: _For any \(i\), \(_{i}\) and \((_{i})<\)._

In what follows, we define \(K\) as the number of leaves of \(\), denoting \(=\{i_{0},,i_{K-1}\}\), and define the horizon times \(T_{v,v^{}}=/(2w_{v,v^{}})\) for any \(\{v,v^{}\}\). For any \(i_{k}\), we will denote by \(_{k}=(,_{k})\) the directed version of \(\) rooted in the leaf \(i_{k}\). In the next section, we present our _dynamic_ method to solve (TreeSB), called _Tree-based Diffusion Schrodinger Bridge_.

## 3 Tree-based Diffusion Schrodinger Bridge

In this section, we present a method to solve (TreeSB) in the case where \(r\), _i.e._, \(r\) is a leaf of \(\). We refer to Appendix E for the extension to the case where \(r\). Without loss of generality, see Appendix E, we assume that \(r=i_{K-1}\) and choose \(_{r}=_{i_{K-1}}/\), such that \(^{0}_{i_{K-1}}=_{i_{K-1}}\).

Dynamic approach to mIPF.In order to approximate solutions of (TreeSB), we consider the _multi-marginal_ extension of the IPF algorithm, denoted by mIPF. Namely, we define a sequence of probability distributions \((^{n})_{n}\) such that for any \(n\)

\[^{n+1}=\{(|^{n})\,:\ ^{( |)},\ _{i_{k_{n}+1}}=_{i_{k_{n}+1}}\}\,\] (mIPF)

where \(k_{n}=(n-1)(K)\) and \((k_{n}+1)\) is identified with \(n(K)\). We define a _mIPF cycle_ as a sequence of \(K\) consecutive mIPF updates. In particular, each marginal constraint is considered exactly once during one mIPF cycle. In a practical setting, our main aim is to sample from the (mIPF) iterates at the lowest cost. Although these updates can be made explicit, see Marino and Gerolin (2020) for instance, direct sampling is unfeasible in practice when \(d\) is large. To overcome this limitation, we suggest to compute these iterates in a _dynamic_ fashion with equivalent path measures.

Since \(^{0}\) factorizes along \(\), see (2), one can show that the iterates of (mIPF) also factorize along \(\), see Section 4. Since these iterates all have a constrained marginal, we obtain the following decomposition for any \(n\): \(^{n}=_{i_{k_{n}}}_{(v,v^{})_{k_{n}}}^{n}_{v^ {}|v}\) where \(_{k_{n}}\) denotes the set of edges of the directed tree \(_{k_{n}}\). Then, our approach consists in computing _dynamic_ iterates, _i.e._, path measures, along the edges of \(\) that coincide on their extremal times with the _static_ iterates \((^{n})_{n}\). Namely, for any \(n\), for any edge \((v,v^{})_{k_{n}}\), we define a path measure \(^{n}_{(v,v^{})}(([0,T_{v,v^{}}], ^{d}))\) such that \((^{n}_{(v,v^{})})=^{n}_{v,v^{}}\), where \((^{n}_{(v,v^{})})\) stands for the joint distribution of \(^{n}_{(v,v^{})}\) at times 0 and \(T_{v,v^{}}\). In particular, it comes that \(^{n}_{v^{}|v}=^{n}_{(v,v^{}),T_{v,v^{}}|0}\). Using the tree-based form of the (mIPF) iterates, we can thus sample from \(^{n}\) by (i) following the directed edges of \(_{k_{n}}\), (ii) diffusing along them the corresponding path measures \((^{n}_{(v,v^{})})_{(v,v^{})_{k_{n}}}\) and (iii) picking the samples on the vertices. When \(\) is a _bridge-shaped_ tree (2 vertices, 1 edge), it simply reduces to the dynamic reformulation of the IPF scheme. In what follows, we explain how to obtain our _dynamic_ sequence.

Definition of the dynamic iterates.We first compute the iterate \(^{0}\), corresponding to the dynamic version of \(^{0}\) defined (2), in Proposition 1. Then, we build the following iterates by recursion on \(n\) and prove their well-posedness in Proposition 2.

**Proposition 1**.: _Let \(_{K-1}=(,_{K-1})\), the directed tree associated with \(=(,)\) and root \(i_{K-1}\). Then, for any \((v,v^{})_{K-1}\), there exists \(^{0}_{(v,v^{})}(([0,T_{v,v^{}}],^{d}))\) with \((^{0}_{(v,v^{})})=^{0}_{(v,v^{})}\) and such that \(^{0}_{(v,v^{})[0}\) is the distribution of \((_{t})_{t[0,T_{v,v^{}}]}\), recalling that \(T_{v,v^{}}=/(2w_{v,v^{}})\)._

Before deriving the dynamic counterpart of the (mIPF) iterates, we introduce several definitions. For any path measure \(\), we denote by \(^{R}\) the _time-reversal_ of \(\). For any directed tree and any vertex \(v\) of this tree, \(p(v)\) refers to the (unique) _parent_ of \(v\), and \(c(v)\) to the unique _child_ of \(v\) when it exists, see Appendix B for more details.

Let \(n\). Assume that we have defined the sequence of our dynamic iterates \((^{m}_{(v,v^{})})_{(v,v^{})_{k_{m}},m n}\) up to stage \(n\).

Consider the path \(_{n}=\{(v_{j},v_{j+1})\}_{j=1}^{J}\) in the directed tree \(_{k_{n}}\) such that \(v_{1}=i_{k_{n}}\) and \(v_{J+1}=i_{k_{n}+1}\). In particular, for any \((v,v^{})_{k_{n}+1}\), either \((v^{},v)_{n}\) or \((v,v^{})_{k_{n}}_{n}\). This is illustrated in Figure 1 when \(=\{0,1,2,3,4\}\), \(S=\{2,3,4\}\), \(i_{k}=3\) and \(i_{k+1}=4\): in this case, \(=\{(3,1),(1,0),(0,4)\}\) and \((1,2)\) is the only edge common to \(_{k}\) and \(_{k+1}\).

Consider now the directed tree \(_{k_{n+1}}\). We define the \((n+1)\)-th iterate of our dynamic sequence by recursion on the edges of this tree, following the breadth-first order. In this order, \((i_{k_{n}+1},c(i_{k_{n}+1}))=(v_{J+1},v_{J})\) is the first edge considered.

First, we define \(^{n+1}_{(v_{J+1},v_{J})}=_{i_{k_{n+1}}}(^{n}_{( v_{J},v_{J+1})})_{}^{R}\). In the case of a _bridge-shaped_ tree, this is exactly the \((n+1)\)-th update described in DSB. Then, for any \((v,v^{})_{k_{n}+1}\{(v_{J+1},v_{J})\}\),

1. either \((v,v^{})_{k_{n}}_{n}\), and we define \(^{n+1}_{(v,v^{})}=^{n+1}_{(p(v),v),T_{p(v),v}} ^{n}_{(v,v^{})}\),
2. or \((v^{},v)_{n}\), and we define \(^{n+1}_{(v,v^{})}=^{n+1}_{(p(v),v),T_{p(v),v}} (^{n}_{(v^{},v)})_{}^{R}\).

**Proposition 2**.: _Consider the sequence of dynamic iterates defined by (a) and (b). Then, for any \(n\) and any \((v,v^{})_{k_{n}}\), \(^{n}_{(v,v^{})}(([0,T_{v,v^{}}],^{d}))\) and we have \((^{n}_{(v,v^{})})=^{n}_{(v,v^{})}\)._

Proposition 2 highlights the equivalence between the (mIPF) iterates and our dynamic iterates. These path measures are defined iteratively, by following the updates (a) and (b) along the edges of \(\). The key observation here is that the computation of each dynamic iterate reduces to a sequence of updates (b) on a _path_ linking two leaves of \(\). We emphasize that our iterates could be similarly obtained by directly considering a dynamic formulation of (TreeSB) and introducing the formalism of deterministic time branching processes. We leave the study of this problem for future work. We now get into the details of our practical implementation, which relies on score-based methods.

Approximation of the dynamic iterates.The time-reversal operated in the update (b) can be computed explicitly, see Haussmann and Pardoux (1986) for instance. Indeed, assuming that \(^{n}_{(v^{},v)}\) is associated with \(_{t}=f_{t,v^{},v}(_{t})t+ _{t}\) with \(_{0}^{n}_{v^{}}\), then, under mild conditions, its time-reversal \((^{n}_{(v^{},v)})^{R}\) is associated with \(_{t}=\{-f_{T-t,v^{},v}+ p_{v^{},v,T-t} \}(_{t})t+_{t}\) with \(_{0}^{n+1}_{v}\), where \(p_{v^{},v,t}\) is the density of \(^{n}_{(v^{},v),t}\) w.r.t. the Lebesgue measure. The score \( p_{v^{},v,T-t}\) can then be approximated using score-matching techniques (Hyvarinen, 2005; Vincent, 2011) which are now ubiquitous in diffusion models (Song et al., 2021) and used in DSB De Bortoli et al. (2021). Therefore, at iteration \((n+1)\), the update (b) is similar to the one of DSB _for each edge_ on the path joining \(i_{k_{n}}\) and \(i_{k_{n}+1}\). In practice, we parameterize the drifts \(f_{t,v,v^{}}\) for any \(\{v,v^{}\}\) with neural networks \(f_{t,_{v,v^{}}}\) and use the _mean-matching_ loss introduced by De Bortoli et al. (2021). Note that doing so, we obtain \(2||\) neural networks. The whole procedure consisting in computing our dynamic iterates using the DSB framework is called _Tree-based Diffusion Schrodinger Bridge_ (TreeDSB) and is summarized in Algorithm 1.

Figure 1: Illustration of the change of root in a toy tree with 5 vertices.

**TreeDSB on a toy tree.** We consider a star-shaped tree with three leaves denoted \(\{1,2,3\}\) and its central node \(\{0\}\). Following (2), we define \(^{0}\) with \(r=3\) and \(_{r}=(_{3}/)\). During the first iteration of TreeDSB, \(\) is rooted at vertex \(3\) and we compute samples from the _forward_ path \(_{0}=\{(3,0),(0,1)\}\) with Brownian motions, see Proposition 1, in order to learn the _backward_ path \(\{(1,0),(0,3)\}\). In the next iteration, we re-root the tree \(\) at vertex \(1\) and consider the _forward_ path \(_{1}=\{(1,0),(0,2)\}\), where the edges \((1,0)\) and \((0,2)\) are respectively given by the first iteration and the initialisation. This highlights that _TreeDSB does not require to update the whole tree_. The following iterations are done similarly. At each iteration \(n\), we sample from \(^{n}\) by first sampling from \(_{k_{n}}\) at leaf \(i_{k_{n}}\) and then following the parameterized SDEs on the directed edges of \(_{k_{n}}\).

## 4 Theoretical properties of mIPF

In this section, we study some of the theoretical properties of the _static_ iterates \((^{n})_{n}\), that are equivalent to our _dynamic_ iterates according to Proposition 2. In the case where the cost function \(c\) is bounded in (EmOT), results of convergence of (mIPF) exist (Marino and Gerolin, 2020; Carlier, 2022). However, our setting does not satisfy their assumptions, since our transport cost is quadratic and the measures are defined on \(^{d}\). In what follows, we provide the first non-quantitative convergence results for (mIPF) in a _non-compact_ setting.

For the rest of the section, we consider a static formulation of the multi-marginal Schrodinger bridge problem which is more general than (TreeSB), defined as

\[^{}=\{(|^{0})\,:\,\, ^{(+1)},\,\,_{i}=_{i}\,\,, i\}\,\] (static-mSB)

where \(\{0,,\}\), \(^{0}\), \(\{_{i}\}_{i}^{||}\). We consider the following set of assumptions.

**A1**.: _There exists a family of measures \(\{_{i}\}_{i\{0,,\}}\) defined on \((^{d},(^{d}))\) such that \(^{0}_{i=0}^{}_{i}\) with density \(h=^{0}/(_{i=0}^{}_{i})\) and \(_{i}_{i}\) with density \(r_{i}=_{i}/_{i}\) for any \(i\)._

**A2**.: \(\{^{(+1)}:(^{0})<,\,\,_{i} =_{i},\,\, i\}\) _._

**A3**.: _There exists a family of probability measures \(\{_{j}\}_{j\{0,,\}}\) such that \(^{0}^{0}\), where \(^{0}=_{i}_{i}_{j\{0,, \}}_{j}\)._

Figure 2: Illustration of one mIPF cycle solved by TreeDSB for a toy star-shaped tree. At each iteration, our method learns the _backward_ stochastic process (dotted arrows) that goes from the target leaf (green-circled), corresponding to the constrained marginal, to the current root of the tree (red-circled) by using samples from the _forward_ stochastic process (solid arrows).

In particular, (static-mSB) recovers (TreeSB) by considering \(_{i}=\) for any \(i\{0,,\}\) and \(h(x_{0:})=_{r}(x_{r})[-c(x_{0:})/]\) in \(1\). We detail in Appendix D how \(2\) and \(3\) can be met in (TreeSB). Under these assumptions, the multi-marginal Schrodinger Bridge exists.

**Proposition 3**.: _Assume \(1\) and \(2\). Then, there exists a unique solution \(^{}\) to (static-mSB). In addition, assume \(3\). Then, there exists a family \(\{^{}_{i}\}_{i}\) of measurable functions \(^{}_{i}:^{d}\) such that_

\[(^{}/^{0})=[_{i}^{ }_{i}]^{0}\]

In order to establish the existence and uniqueness result of Proposition 3, we extend results from Nutz (2021) to the multi-marginal setting. A consequence of Proposition 3 is that the iterates of (mIPF) can be described using potentials.

**Corollary 4**.: _Assume \(1\), \(2\) and \(3\). Let \((^{n})_{n}\) be the sequence given by (mIPF). Then, for any \(n^{}\) with \(k_{n}=(n-1)\,(K)\) and \(q_{n}\) such that \(n=q_{n}K+k_{n}+1\), there exists a family of measurable functions \(\{^{n_{n}+1}_{i_{0}},,^{q_{n}+1}_{i_{k_{m}}},^{q_{n}}_{i_{k_ {m+1}}},,^{q_{n}}_{i_{K-1}}\}\) such that_

\[(^{n}/^{0})(x_{0:})=[_{j=0}^{k_{n} }^{q_{n}+1}_{i_{j}}(x_{i_{j}})_{j=k_{n}+1}^{K-1}^{q_{n}}_{i_{ j}}(x_{i_{j}})]^{0}\]

In the tree-based setting, Corollary 4 explains why the (mIPF) iterations preserve the tree-based Markovian nature of \(^{0}\). We now prove that the marginal \(^{n}_{i}\) converges to \(_{i}\) for any \(i\), as \(n\) goes to infinity, _i.e._, we have marginal convergence on the leaves of \(\).

**Proposition 5**.: _Assume \(1\) and \(2\). Let \((^{n})_{n}\) be the sequence given by (mIPF). Then, we have \(_{n}\|^{n}_{i}-_{i}\|_{}=0\) for any \(i\)._

The previous result does not ensure the convergence of \((^{n})_{n}\) to the solution to (static-mSB). In particular, Proposition 5 does not provide the convergence of the marginals on the nodes \(v\), which is key to compute regularized Wasserstein barycenters with TreeDSB. Relying on additional assumptions, we now derive the convergence of (mIPF).

**A4**.: \(_{i}^{1}(_{i})^{1}(^{ })\) _is closed._

**A5**.: _There exist \((0,)\) such that \((^{n}_{i_{k}}-^{n+1}_{i_{k}})\), for any \(n\), any \(k\{0,,K-2\}\)._

These assumptions can be seen as multi-marginal extensions of the ones of Ruschendorf (1995), see Appendix D for a discussion and examples.

**Proposition 6**.: _Assume \(1\), \(2\), \(3\), \(4\) and \(5\). Let \((^{n})_{n}\) be the sequence given by (mIPF). Then, we have \(_{n}\|^{n}-^{}\|_{}=0\), where \(^{}\) is given in Proposition 3._

To the best of our knowledge, Proposition 6 is the first convergence result of (mIPF) without assuming that the space is compact or that the cost is bounded. We highlight that traditional techniques to prove the convergence of IPF cannot be easily extended to the multi-marginal setting as pointed by Carlier (2022). In the case of bounded cost, quantitative results exist (Marino & Gerolin, 2020; Carlier, 2022). We leave the study of such results in the _unbounded_ cost setting for future work.

## 5 Application to Wasserstein barycenters

Although Algorithm 1 can be applied to trees \(\) with fixed marginals on the leaves, one case of particular interest is star-shaped trees, _i.e._, trees with a central node, denoted by index \(0\), and such that \(=\{1,,\}\) (see Figure 2 for an illustration with \(=3\)). In this section, we draw a link between (TreeSB) and regularized Wasserstein barycenters. We recall the definition of the Wasserstein distance of order \(2\) with \(\)-entropic regularization between \(\) and \(\)(Peyre et al., 2019, Chapter 4)

\[W^{2}_{2,}(,)=\{\|x_{1}-x_{0}\|^{2}(x_{0},x_{1})-():^{(2)},_{0}=,_{1}= \}\.\] (3)

In this work, we consider the \((,(-1))\)-doubly-regularized Wasserstein-2 barycenter problem (Chizat, 2023) defined as follows

\[^{}_{}=\{_{i=1}^{}w_{i}W^{2}_{2,/w_ {i}}(,_{i})+(-1)():\}\,\] (regWB)

where \((w_{i})_{i\{1,,\}}(0,+)^{}\). The following proposition shows the equivalence between the barycenter problem (regWB) and the multi-marginal Schrodinger bridge problem (TreeSB) over \(\). In particular, it allows us to use TreeDSB to estimate the solution \(^{}_{}\) of (regWB).

**Proposition 7**.: _Let \(>0\). Assume **A**0. Also assume that \(\) is a star-shaped tree with central node indexed by \(0\), and that the reference measure of \(()\) defined in (2) verifies \(r=i_{K-1}\) and \(_{r}=_{i_{K-1}}/>0\). Under **A**2, \(()\) has a unique solution \(_{0}^{}\), where \(^{}\) solves \(()\)._

The proof of this result is postponed to Appendix D. More generally, we show in Appendix D that, for any tree \(\), \(()\) is equivalent to a regularized version of the Wasserstein propagation problem (Solomon et al., 2014, 2015). Moreover, we present in Appendix E an extension of Proposition 7 in the case where the chosen root \(r\) is not a leaf of \(\). We finally emphasize that the formulation of \(()\) leads to a _minimization_ of the entropy of the barycenter. In particular, this allows us to choose \(\) reasonably large in TreeDSB, which is a stability advantage compared to other regularized methods which do not consider this further regularization.

## 6 Related work

Diffusion Schrodinger Bridge.Schrodinger Bridges (Schrodinger, 1932) have been extensively studied using tools from stochastic control and probability theory (Leonard, 2014; Dai Pra, 1991; Chen et al., 2021). More recently, algorithms were proposed to efficiently approximate such bridges in the context of machine learning. In particular, De Bortoli et al. (2021) proposed DSB while Vargas et al. (2021); Chen et al. (2022) developed related algorithms. In Chen et al. (2023), the authors study a multi-marginal version of DSB in a linear tree-based setting, where the set of observed nodes is the whole set of vertices. However, contrary to our setting, Chen et al. (2023) introduced a momentum variable. This allows for smoother trajectories which are desirable for single-cell trajectories applications and correspond to some spline interpolation in the space of probability measures (Chen et al., 2018). A general framework for tree-based static Schrodinger Bridges on discrete state-spaces was given in Haasler et al. (2021). In this work, we extend their formulation to a dynamic and continuous setting, see Appendix D for more a thorough comparison.

Wasserstein barycenters.The notion of Wasserstein barycenter was first introduced in Rabin et al. (2012) and then later studied in Agueh & Carlier (2011). The algorithms to solve this problem can be split into two families: the in-sample based approaches and the parametric ones. In-sample approaches require access to all the measures \(_{i}\) which are assumed to be empirical measures (Cuturi & Doucet, 2014; Benamou et al., 2015; Solomon et al., 2015). Related to this class of algorithms is the semi-discrete approach, which aims at computing a Wasserstein barycenter between continuous distribution but rely on a discretization of the barycenter (Claici et al., 2018; Staib et al., 2017; Mi et al., 2020). Most recent approaches do not rely on a discrete representation of the barycenter, but instead parameterize it using neural networks. These approaches can be further split into two categories. First, _measure-based optimization_ approaches parameterize the measures using a neural network. This is the case of Cohen et al. (2020), where the barycenter is given by a generative model, which is then optimized. Fan et al. (2020) introduce an optimization procedure which relies on a _min-max-min_ problem using the framework of Makkuva et al. (2020). More recently, Korotin et al. (2022) considered a fixed point-based algorithm introduced in Alvarez-Esteban et al. (2016) to update a generative model parametrizing the barycenter. On the one hand, _potential-based methods_ rely on a dual formulation of the barycenter. Korotin et al. (2021) parameterized the dual potentials using Input Convex Neural Network and considered regularizing losses imposing conjugacy and congruency. On the other hand, Li et al. (2020) consider a dual version of the _regularized_ Wasserstein barycenter problem contrary to other works. Our approach applied to start-shaped trees also approximates a _regularized_ Wasserstein barycenter. However, contrary to Li et al. (2020), we do not consider a parameterization of the potentials in the _static_ setting but instead, parameterize the drift of an associated _dynamic_ formulation using Schrodinger bridges. To the best of our knowledge TreeDSB is the first approach leveraging DSB-like algorithms to compute Wasserstein barycenters.

## 7 Experiments

In our experiments3, we illustrate the performance of TreeDSB to compute entropic regularized Wasserstein barycenters for various tasks. We choose to compare our method with state-of-the-art regularized algorithms: fast free-support Wasserstein barycenter (fsWB) (Cuturi & Doucet, 2014), and continuous regularized Wasserstein barycenter (crWB) (Li et al., 2020). In all of our settings, we consider a star-shaped tree with \(K\) leaves and edge weights that are equal to \(1/K\), resulting in asequential training procedure over \(2K\) neural networks. The initial diffusion is always a Brownian motion parameterized as explained in Proposition 1. Hence, the time horizon on each edge is defined by \(T=K/2\). The order of the leaves is randomly shuffled between the mIPF cycles. We consider 50 steps for the time discretization on \([0,T]\). We refer to Appendix G for details on the choice of the schedule, the architecture of the neural networks and the settings of our experiments.

**Synthetic two dimensional datasets.** We first illustrate TreeDSB in a synthetic two dimensional setting. We consider three different datasets _Swiss-roll_ (vertex 0, starting node \(r\)), _Circle_ (vertex 2) and _Moons_ (vertex 3) and compute their Wasserstein barycenter (vertex 1) by running TreeDSB for 50 mIPF cycles with \(=0.1\). In Figure 3, we show the estimated densities of the datasets on the leaves of the tree (we emphasize that the distributions plotted on each leaf are generated from the central barycenter measure). In Figure 4, we observe the consistency between the barycenters generated from the different leaves. In Appendix G, we present additional results for this setting.

**Synthetic Gaussian datasets.** Next, we consider three independent Gaussian distributions with zero mean and random non-diagonal covariance matrices whose conditional number is less than 10, following Fan et al. (2020). In this case, the non-regularized barycenter can be exactly computed. To evaluate the performance of the algorithms, we use the Bures-Wasserstein Unexplained Variance Percentage (UVP), following (Korotin et al., 2021, Section 5). Given a target distribution \(^{}\) and some approximation \(\), we define

\[^{2}_{2}(,^{})=100 2\, ^{2}_{2}(,^{})/\,(^{})\%\,\]

where \(^{2}_{2}(,^{})=W^{2}_{2}(([], ()),([^{}],(^{ }))\).

In this setting, we choose \(^{}\) to be the non-regularized barycenter and assess the dependency w.r.t. the dimension of the algorithms using the \(^{2}_{2}\) metric. In Table 1, we compare ourselves with the two regularized methods Li et al. (2020) (\(_{2}\)-reg. equal to \(10^{-4}\)) and Cuturi and Doucet (2014). We run TreeDSB for 10 mIPF cycles with \(=0.1\). Bold numbers represent the best values up to statistical significance. While Li et al. (2020) and Cuturi and Doucet (2014) enjoy better performance in low dimensions (\(d=2\)), TreeDSB outperforms these methods as the dimension increases.

**MNIST Wasserstein barycenter.** We then turn to an image experiment using MNIST dataset (LeCun, 1998). Here, an image is not considered as a 2D-dimensional distribution as in Cuturi and Doucet (2014) and Li et al. (2020), but as a sample from a high-dimensional probability measure (\(d=784\)). We aim at computing a Wasserstein barycenter between the digits \(2\),\(4\) and \(6\). To do so, we

   Method & \(d=2\) & \(d=16\) & \(d=64\) & \(d=128\) & \(d=256\) \\  fsWB (Cuturi and Doucet, 2014) & \(0.06_{ 0.01}\) & \(2.86_{ 0.06}\) & \(11.12_{ 0.06}\) & \(14.47_{ 0.07}\) & \(17.41_{ 0.05}\) \\ crWB (Li et al., 2020) & \(}\) & \(}\) & \(11.41_{ 0.73}\) & \(5.75_{ 0.02}\) & \(18.27_{ 0.54}\) \\ Tree DSB & \(}\) & \(}\) & \(}\) & \(}\) & \(}\) \\   

Table 1: Gaussian setting: comparison with the regularized methods crWB and fsWB.

Figure 4: From left to right: barycenter estimated from the leaves _Swiss-roll_, _Circle_ and _Moons_.

Figure 3: Estimated densities on the leaves.

run TreeDSB for 10 mlPF cycles with \(r\) that corresponds to the digit 6 and \(=0.5\). In Figure 5, we display samples from the estimated marginals on the leaves, to assess the reconstruction of the digits \(2\), \(4\) and \(6\), and samples from the barycenter, obtained by diffusing from the leaf corresponding to the digit \(6\). Our results prove the scalability of TreeDSB to the high-dimensional setting, compared to state-of-the-art regularized methods. Additional results on MNIST dataset are given in Appendix G.

Subset posterior aggregation.Finally, we evaluate TreeDSB in the context of _Bayesian fusion_(Srivastava et al., 2018), also called posterior aggregation. Given a Bayesian model and a dataset partitioned into several shards, this task aims at recovering the full data posterior distribution from the posterior distributions computed on each shard.

In particular, it has been proved that the barycenter of the subdataset posteriors is close to the full data posterior under mild assumptions (Srivastava et al., 2018). Here, we consider a logistic regression model applied to the wine dataset4(\(d=42\)) and proceed as follows. We first split this dataset into 3 subsets, with or without heterogeneity, and estimate the posterior parameters on each shard. Then, we draw samples from the obtained logistic distributions to define \(_{1},_{2},_{3}\). Then, we compute the Wasserstein barycenter of these measures, and compare it to the posterior computed on the full dataset. As in the synthetic Gaussian experiment, we run TreeDSB for 10 mlPF cycles \(=0.1\) and we compare ourselves with Li et al. (2020) (\(_{2}\)-reg. equal to \(10^{-4}\)) and Cuturi and Doucet (2014). We evaluate the methods using the \(_{2}^{2}\)-\(\) metric, where \(^{}\) is the estimated full data posterior, and report the results in Table 2. In both settings, we observe that our method outperforms existing regularized methods to compute Wasserstein barycenters.

Limitations.One of the main limitation of entropic regularized OT approach is that their behavior is usually badly conditioned as \( 0\). In our setting, we observe that if \(\), or equivalently \(T\), is too low then the algorithm becomes less stable as the training of the models slows down. In the future, we plan to mitigate this issue by incorporating fixed point techniques like the one used in Korotin et al. (2022). Finally, since our algorithm is based on DSB (De Bortoli et al., 2021), it suffers from the same limitations. In particular, training different neural networks iteratively incurs some bias in the SDE which is harmful for large number of mIPF iterations.

## 8 Discussion

In this paper, we introduced Tree-based Diffusion Schrodinger Bridge (TreeDSB) a scalable scheme to approximate solutions of entropic-regularized multi-marginal Optimal Transport (mOT) problems. Our methodology leverages tools from the diffusion model literature and extends Diffusion Schrodinger Bridge (De Bortoli et al., 2021). In particular, it approximates the iterates of the multi-marginal Iterative Proportional Fitting (mIPF) algorithm, for which we prove its convergence under mild assumptions. We illustrate the efficiency of TreeDSB for image processing and Bayesian fusion, using the link between mOT and Wasserstein barycenters. In future work, we would like to study quantitative convergence bounds for mIPF in the _unbounded_ cost setting. Another line of work would be to scale TreeDSB to higher dimensional problems building on recent developments in the diffusion model and flow matching community (Lipman et al., 2023; Pelucheti, 2023; Shi et al., 2023).

   Method & Without het. & With het. \\  fsWB (Cuturi and Doucet, 2014) & \(12.95_{ 0.35}\) & \(14.43_{ 0.51}\) \\ crWB (Li et al., 2020) & \(20.66_{ 0.71}\) & \(23.06_{ 0.12}\) \\ Tree DSB & \(}\) & \(}\) \\   

Table 2: Bayesian fusion setting: comparison with the regularized methods crWB and fsWB.

Figure 5: Samples from the estimated MNIST 2-4-6 marginals and from their Wasserstein barycenter.