# What If the Input is Expanded in OOD Detection?

Boxuan Zhang\({}^{1}\)  Jianing Zhu\({}^{2}\)  Zengmao Wang\({}^{1}\)  Tongliang Liu\({}^{3}\)  Bo Du\({}^{1}\)  Bo Han\({}^{2,4}\)

\({}^{1}\)School of Computer Science, Wuhan University

\({}^{2}\)TMLR Group, Department of Computer Science, Hong Kong Baptist University

\({}^{3}\)Sydney AI Center, The University of Sydney \({}^{4}\)RIKEN Center for Advanced Intelligence Project

{boxzhang1005, wangzengmao, dubo}@whu.edu.cn

{csjnzhu, bhanml}@comp.hkbu.edu.hk tongliang.liu@sydney.edu.cn

Equal ContributionCorrespondence to Zengmao Wang (wangzengmao@whu.edu.cn)

###### Abstract

Out-of-distribution (OOD) detection aims to identify OOD inputs from unknown classes, which is important for the reliable deployment of machine learning models in the open world. Various scoring functions are proposed to distinguish it from in-distribution (ID) data. However, existing methods generally focus on excavating the discriminative information from a single input, which implicitly limits its representation dimension. In this work, we introduce a novel perspective, i.e., employing different common corruptions on the input space, to expand that. We reveal an interesting phenomenon termed _confidence mutation_, where the confidence of OOD data can decrease significantly under the corruptions, while the ID data shows a higher confidence expectation considering the resistance of semantic features. Based on that, we formalize a new scoring method, namely, _Confidence a**Ver**age (CoVer), which can capture the dynamic differences by simply averaging the scores obtained from different corrupted inputs and the original ones, making the OOD and ID distributions more separable in detection tasks. Extensive experiments and analyses have been conducted to understand and verify the effectiveness of CoVer. The code is publicly available at: https://github.com/tmlr-group/CoVer.

## 1 Introduction

Out-of-distribution (OOD) detection [23; 28; 44] is important for reliable machine learning model deployment in open-world scenarios, where various samples from unknown classes, i.e., OOD data, are constantly emerging . Deep neural networks  (DNNs) are demonstrated to be overconfident about these OOD data, which may result in disasters for some safety-critical applications [5; 21]. Traditional OOD detection methods [23; 29; 28; 30; 45; 46; 1; 61] design various scoring functions based on the outputs or representations extracted from well-trained models. Recently, some research also extended it into a zero-shot setting , which leverages the multi-modal information based on vision-language models (VLMs) and requires no further training on in-distribution (ID) data. A series of methods [48; 36; 52; 26] are proposed for improving OOD detection based on such advances.

Although promising progress has been achieved, existing methods mainly focus on excavating the discriminative information of a single input. For instance, ReAct , DICE , and ASH  integrates the activation regularization or reshaping to the forward path of a single input in single-modal DNNs; MCM  characterizes the confidence of a single input by the similarity between visual features and text representation of ID classes in VLMs. However, specializing in a single inputmay implicitly constrain the representation dimension for detection, leaving some hard-to-distinguish OOD samples with features similar to ID samples fail to be identified (refer to the distribution overlap in the left panel of Figure 1). Therefore, it naturally motivates the following critical research question: _Can we expand the dimension of the input space to explore OOD discriminative representations?_

In this work, we introduce a novel perspective to investigate that, i.e., employing the common corruptions  in the input space. Through a systematical comparison, we reveal an interesting phenomenon termed _confidence mutation_, where the confidence of OOD data can decrease significantly under the corruptions, while ID data shows higher confidence expectation considering different input dimensions. Specifically, as shown in Figure 1, corrupted inputs result in lower confidence in both OOD and ID data. However, one critical dynamic discovery is that its confidence about overconfident OOD data is changed more than the unconfident ID data under the same corruptions (refer to Figure 2), indicating a natural difference in feature-level resistance of the originally overlapped parts (refer to Figure 3). With the original inputs, we can find that the model is overall more confident in ID data.

Based on the above, we propose a new scoring framework, namely, _Confidence a**Verage**_ (CoVer), as illustrated in Figure 4. At the high level, we expand the original single representation dimension into multiple ones to excavate discriminative information. In detail, we introduce a simple but effective method for identifying OOD data with confidence mutation, which can be formalized as an average of OOD scores (e.g., Eq. (6)) obtained by different corrupted inputs and the original one. With the expectation among multiple input dimensions, CoVer can effectively reflect the knowledge of invariant semantic features that are discriminative from ID data to OOD data. It also matches an intuition that ID data can be more likely recognized as high confidence by models considering different input views, especially with the corruptions affecting the non-semantic high-frequency parts.

We conducted extensive experiments to verify the effectiveness of our proposed method. Since CoVer is an input-side design compatible with single-modal and multi-modal networks, we adpot various benchmarks for DNN-based and VLM-based OOD detection tasks. Under extensive evaluations, our CoVer can achieve the superior performance compared with different baselines. Moreover, CoVer exhibits excellent compatibility, as evidenced by the better performance of some methods combined with CoVer. Finally, a range of ablation studies of the scoring framework and further discussions from different perspectives are provided. In summary, our main contributions can be listed as follows,

* Conceptually, we introduce a novel perspective for identifying OOD inputs by considering the common corruptions to expand the representation dimensions. (in Section 3.1)
* We reveal an interesting phenomenon termed _confidence mutation_, where the confidences of OOD data can vary to significantly lower than ID data under corruptions (in Section 3.2).
* Technically, we formalize a novel scoring method, namely, _Confidence a**verage**_ (CoVer), a simple average of the confidence estimated from extended corrupted inputs and the original one. The corresponding empirical analysis is presented to understand it (in Section 3.3).

Figure 1: Comparison of scores distributions and detection results with different inputs for representation dimension expansion. _Left panel:_ results with a single original input; _Middle panel:_ results with a single corrupted input, which perform worse but have mutated scores for some OOD samples (see Figure 2); _Right panel:_ results with multiple inputs (CoVer), which achieve the variance reduction for the ID distribution and perform a better ID-OOD separability (see Figure 3 for more explanations).

* Empirically, extensive experiments on both traditional and zero-shot OOD detection benchmarks have verified the effectiveness and compatibility of our CoVer, and we conduct various ablations and further discussions to provide a comprehensive analysis (in Section 4).

## 2 Preliminaries

In this section, we briefly introduce the preliminaries of OOD detection on basic setups and the advanced zero-shot setting on VLMs. For related works, we leave detailed discussions in Appendix B.

Problem setups.Let \(\) be the input space and \(=\{y_{1},...,y_{K}\}\) be the label space, where \(K\) is the number of ID classes. Given the ID random input \(x_{i}\) and OOD random input \(x_{o}\), we consider the ID marginal distribution \(_{}\) and those with the OOD marginal distribution \(_{}\), where \(_{}\) is defined as an irrelevant distribution of which the label set has no intersection with \(\). The goal of OOD detection is to figure out inputs with the OOD distribution \(_{}\) from those with the ID distribution \(_{}\), which can be considered as a binary classification problem. For traditional OOD detection, given a model \(f\) trained on ID data with logit outputs, a score function \(S()\) and a threshold \(\), the detection model \(g()\) can be defined as,

\[g_{}(x)=,\ \ S(x;f);\ ,\ \ g_{}(x)=.\] (1)

where \(x\) is detected as ID data if and only if \(S()\); otherwise, it is rejected as OOD data that should not be predicted by the model \(f\). Designing a practical \(S(x;f)\) is crucial for OOD detection.

CLIP-based vision-language modelsCLIP  has shown impressive performance in the zero-shot classification task by profiting from massive amounts of training data and large-size models. Here we briefly review the mechanism of CLIP-based VLMs. A CLIP-based model \(\) usually contains an image encoder \(^{}\) and a text encoder \(^{}\). Given a random input \(x_{}\) and a label \(y\), we use \(^{}\) and \(^{}\) to extract the image features \(h^{d}\) and the text features \(e_{j}^{d}\) as follows:

\[h=^{}(x), e_{j}=^{}(p(y_{j})), j=1,2,...,K,\] (2)

where \(p()\) refers to the prompt template for the input label, \(d\) is the embedding dimension. The predictions are formulated as the cosine similarity between the image features \(h\) and text features \(e_{j}\),

\[=*{arg\,max}_{y_{j}}\{(h,e_{j})\}, e_{j}=^{}(p(y_{j})).\] (3)

Figure 2: Demonstration about detailed explanations for the discovery illustrated in Figure 1. The ID and OOD data here are divided into four groups, i.e., Confident ID, Unconfident ID, Overconfident OOD, and Unconfident OOD. _First Row_: the variation of confidence scores for ID and OOD data before and after being corrupted. The critical difference lies in the greater confidence declination for overconfident OOD data compared to unconfident ID data. (see Figure 3 for further discussion). _Second Row_: scatter maps of confidence scores sampled from the four groups under the same corruption, statistically supporting the findings of the first row. See Appendix C.2 for more details.

Zero-shot OOD detectionDifferent from traditional OOD detection methods based on a classifier \(f\) well-trained on single-modal, recent zero-shot OOD detection studies  leverage a pre-trained VLM-based model (e.g. CLIP ) without any fine-tuning on ID training data. The text features from given ID label names (i.e. ID classes) as the class-wise weights functionally play the same role as the classifier. With guaranteed ID classification accuracy, the primary goal of zero-shot OOD detection in this paper is to distinguish OOD samples that do not belong to any known ID classes.

## 3 CoVer: Confidence Average

In this section, we formally present our proposed new scoring framework, i.e., _Confidence aVerage_ (CoVer). First, we introduce the motivation of representation dimension expansion and present the notable discovery (Section 3.1). Second, we conduct the exploration for the confidence mutation of overconfident OOD data considering the corrupted inputs (Section 3.2). Lastly, we provide the detailed implementation and analysis of our formalized CoVer score (Section 3.3).

### Representation Dimension Expansion

DNNs are demonstrated to be overconfident on those OOD samples, and a series of works  are dedicated to eliminating the effects through the perspective of feature representation. However, achieving that is demonstrated to be hard as it generally requires careful optimization , or additional prior knowledge  on the single input. As illustrated in the middle panel of Figure 1, adopting some agnostic corruptions on the single input may result in worse separability between the ID and OOD distribution. Specializing in a single input seems to implicitly constrain the representation dimension for detection. In this work, we naturally raise the following question,

_What if we expand the dimension of representation for the original inputs_

_to enhance OOD discriminative representations?_

Using the same corruption adopted in Figure 1, we can conduct the dimension expansion by simultaneously considering both the corrupted variant and the original input. One notable discovery is that considering multiple inputs can achieve better performance on OOD detection, even though the single corruption transformation brings negative effects on identifying OOD samples. The surprising comparison results attract us to further explore the underlying mechanism of expanding the representation dimension for the original input, especially the dynamics before and after adopting the corruptions.

Figure 3: Visual exploration of random unconfident ID samples and the confidence mutation exemplified on random overconfident OOD samples under the same corruption. For each original input and its corrupted variant, we leverage the Fast Fourier Transformation to extract their low-frequency and high-frequency parts. _Left panel:_ visual investigation on unconfident ID samples with ID semantic features at low-frequency levels that are resistant to corruptions. _Right panel:_ an intuitive comparison of overconfident OOD samples, whose confidences show significant changes due to the elimination of non-semantic features at the high-frequency level. See Appendix C.4.2 for more detailed analyses.

### Confidence Mutation under Corruptions

Although employing corruption on the single inputs leads to worse ID-OOD separability, we can find obvious shifts toward less confidence in both OOD and ID distributions. It is expected for OOD data that corruption can help the model mitigate overconfidence, while the ID data are also affected severely and enlarge the overlap on the single dimension. In contrast, considering the multiple inputs by averaging the confidence scores shows variance reduction for ID distribution, which indicates the distinguishable dynamics between ID and OOD data. To elicit the underlying mechanism, we provide a definition to characterize the change of model confidence on the inputs under corruption.

**Definition 3.1** (Confidence Difference).: _Given a well-trained model \(f\) and a score function \(S()\) measuring the confidence of \(f\) on an input \(x\), we have a basic static to characterize the differences between the original input and that under a corruption \(c()_{c}(x,S,f)(S(x;f)-S(c(x);f))\)._

Based on the comparison in Figure 1, we divide the ID and OOD data into four groups according to the model confidence on their original inputs, and present an overall comparison of the confidence differences in Figure 2. We reveal the critical dynamic differences in the corrupted variants of ID and OOD data, where both large \((x,s,f)\) exist in the data whose natural inputs own higher confidence in each part, demonstrating the model confidence on the overconfident OOD data decrease more than the unconfident ID data under the same corruption. We can get the empirical observation,

**Observation 3.2** (Confidence Mutation).: _Given the overconfidence OOD inputs \(x_{o}_{OOD}\), we can observe more significant differences in the change of confidences under the same corruption \(c()\) than the ID samples \(x_{i}_{}\) with similar model confidence (constrained by \(\)) on the natural inputs,_

\[_{x_{i}_{}}(_{c}(x_{i},S,f ))<_{x_{o}_{}}(_{c}(x_{o},S,f)).\] (4)

In Figure 3, we further visualize the samples of unconfident ID data and overconfident OOD data. Under the comparison of saliency maps and the Fast Fourier Transformation, we find the confidence mutation reflects the feature level vulnerability of OOD data compared with ID data. Intuitively, the former can be severely affected by the common corruption to eliminate the non-semantic features, which generally exist at the high-frequency level. In contrast, the semantic feature of unconfident ID data can maintain confidence as the limited effects of corruption on the low-frequency part.

**Observation 3.3** (Resistance of ID features in frequency views).: _Assuming that ID data owns the ID semantic features existing at the low-frequency level (extract by \(_{}\)) while the OOD data has some non-semantic features at the high-frequency level for activating the high confidence of the model on its prediction, we can observe the following empirical relation on adopting the same corruptions,_

\[(_{c}(x,S,f))((f(_{ }(c(x))))||f(_{}(x)).\] (5)

where \(\) indicates the Fourier transformation. We suggest that common corruptions  might act as perturbations of high-frequency features within the input representation. For OOD samples, which inherently lack ID semantic features, altering high-frequency features could potentially lead to notable changes in model confidence, while the ID data shows relatively better resistance on it (see the left panel of Figure 3). This observation tentatively supports the notion that ID data maintains an overall higher confidence expectation under conditions of expanded representation dimension. To validate its generality, additional results involving various common corruptions are presented in Appendix C.2.2.

### Scoring Function Implementation and Analysis

Based on the previous understanding of confidence mutation, we formalize our CoVer, a new scoring framework for OOD detection. The procedure of CoVer mainly contains the following _four_ parts as illustrated in Figure 4, and the final averaged multi-dimensional scores can be provided as follows,

\[S_{}=_{x d(,})}_{ i}(x)/}}{_{j=1}^{K}e^{s_{j}(x)/}}, d(, }):=\{x,c(x)|x,c C\},\] (6)

where \(_{x d(,})}\) is the confidence expecation over all scores dimensions, \(K\) is the number of ID classes, \(\) is the temperature coefficient of the softmax function. In the following, we detailedly introduce the specific operations to obtain the final \(S_{}\) and the corresponding notations.

To enlarge the dimension of the original single input for confidence average, we introduce various corrupted inputs. In this work, we employ the corruption functions defined in , which consiststotal of 90 distinct corruptions. We provide the visualization of these different corruptions in Appendix C.4.1. Given the input space \(\) and a set of corruption functions \(C\), the corrupted inputs can be formulated as \(\{c(x)|x,c C\}}\), resulting in the multi-dimensional input spaces \(d(,})\).

Given an input image \(x d(,})\), we adopt an image encoder with fixed parameters to extract the feature of the original dimension \(h_{O}\) and features of corrupted dimensions \(h_{1},...h_{N}\). Then we predict the logit output \(s(x)\) for each dimensional feature \(h_{d}, d=O,1,...,N\). For the DNN-based model \(f\), the outputs of these features are denoted as \(s(x)=f(x)=_{d}\). For the VLM-based model, the outputs are label-wise matching scores based on the cosine similarity: \(s_{j}(x)= e_{j}}{\|h_{d}\|\|e_{j}\|}\).

For the logit output \(s(x)\) predicted from a specific input dimension, we assign it with an OOD score to implement one dimension of the CoVer score. As shown in the right-middle panel of Figure 1, the OOD score can be formalized by some traditional scoring functions, like the softmax scoring function  (refer to Eq. (6)) and the free energy scoring function . In addition, the OOD score can also be formulated by variants of some novel scoring functions, like those in CLIPN  and NegLabel . The detailed implementations for alternative scoring functions can be found in Appendix C.3.

## 4 Experiments

In this section, we present the comprehensive verification of the proposed CoVer in the OOD detection benchmarks. First, we introduce several critical parts of experimental setups (in Section 4.1). Second, we provide the performance comparison and compatibility experiments of our CoVer with various DNN-based and VLM-based OOD detection methods (in Section 4.2). Third, we conduct extensive ablation studies and further discussions to understand the properties of our CoVer (in Section 4.3).

### Experimental Setups

In this part, we present the critical parts of experimental setups and leave more details in Appendix C.

Datasets.Following previous work [1; 31], we adopt the ImageNet-1K OOD benchmark , which uses the ImageNet-1K  as ID data and iNaturalist , SUN , Places , and Textures  as OOD data. For each of the OOD datasets, the classes do not overlap with the ID dataset. As the same as MCM , we also use subsets of ImageNet-1K for fine-grained analysis, like ImageNet-10 that mimics the class distribution of CIFAR-10 but with high-resolution images. For hard OOD evaluation, we exploit ImageNet-20 with 20 categories similar to ImageNet-10 in the semantic space

Figure 4: Overview of CoVer. _Left panel_: visualization of the raw input and inputs w.r.t different corruptions; _Left-middle panel_: procedures of logit outputs from single-modal and multi-modal networks; _Right-middle panel_: scoring functions that equip each dimensional output with an OOD score; _Right panel_: realization of CoVer by averaging OOD scores obtained from multiple dimensions.

(e.g., dog (ID) vs. wolf (OOD)). To have more experimental comparison, we also reproduce one setting from spurious OOD detection , whose hard OOD inputs are created to share the same background (i.e., water) as ID data but have different object labels (e.g., a boat rather than a bird). To select the most effective corruption types for each method, we use SVHN  as the validation set.

Model Setup.In this paper, we implement CoVer on various architectures, including DNN-like ResNet50, and VLM-like CLIP , AltCLIP , MetaCLIP , GroupViT . Unless otherwise instructed, for VLM-based zero-shot OOD detection, we use CLIP-B/16 which consists of an image encoder based on ViT-B/16 Transformer  and a text encoder built with the masked self-attention Transformer . We use the algorithmically generated corruptions defined in . Each type of corruption has a severity level \(\) from 1 to 5, with \(=1\) being the least severe and increasing up to \(=5\). By default, we use the CoVer score in the max-softmax form and set \(=1\) as the temperature.

Baseline Methods and Evaluation Metrics.We compare the proposed method with various competitive methods. Specifically, we adopt Maximum Softmax Probability (MSP) , ODIN , Mahalanobis , Energy , ReAct , DICE  and ASH  as traditional OOD detection baseline methods. The VLM-based OOD detection methods we compared with include MCM, a method specifically designed for zero-shot OOD detection, as well as some traditional methods including MSP, ODIN, Energy, Mahalanobis, GradNorm , ViM , KNN , ZOC  that were re-implemented using a finetuned CLIP ViT-B/16 on the ImageNet-1K, see Appendix A for more details. For a fair comparison, we keep the original hyperparameter setups of the comparative methods and adopt the following metrics to evaluate the OOD detection performance: (1) the false positive rate (FPR95) of the OOD samples when the true positive rate (TPR)  of the in-distribution samples is at 95%, (2) the area under the receiver operating characteristic curve (AUROC) .

    &  &  \\ iNaturalist \\  } &  &  &  &  \\   & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) \\  MSP & 87.74 & 54.99 & 80.86 & 70.83 & 79.76 & 73.99 & 79.61 & 68.00 & 81.99 & 66.95 \\ ODIN & 91.37 & 41.57 & 86.89 & 53.97 & 84.44 & 62.15 & 87.57 & 45.53 & 87.57 & 50.80 \\ Mahalanobis & 52.65 & 97.00 & 42.41 & 98.50 & 41.79 & 98.40 & 85.01 & 55.80 & 55.47 & 87.43 \\ Energy score & 89.95 & 55.72 & 85.89 & 59.26 & 82.86 & 64.92 & 85.99 & 53.72 & 86.17 & 58.41 \\ ReAct & 96.22 & 20.38 & 94.20 & 24.20 & 91.58 & 33.85 & 89.80 & 47.30 & 92.95 & 31.43 \\ DICE & 94.49 & 25.63 & 90.83 & 35.15 & 87.48 & 46.49 & 90.30 & 31.72 & 90.77 & 34.75 \\ DICE+ReAct & 96.24 & 18.64 & 93.94 & 25.45 & 90.67 & 36.86 & 92.74 & 28.07 & 93.40 & 27.25 \\ ASH-B & 94.25 & 28.95 & 93.02 & 40.21 & 87.52 & 95.21 & 95.33 & 34.89 & 90.91 & 39.04 \\
**ASH-B + CoVer** & 97.14 & 14.04 & 94.12 & 25.77 & 91.05 & 35.93 & 91.93 & 30.39 & 93.56 & 26.53 \\ ASH-S & 97.88 & 11.38 & 94.04 & 27.96 & 91.03 & 39.74 & **97.62** & **11.88** & 95.14 & 22.74 \\
**ASH-S + CoVer** & **98.33** & **8.73** & **94.59** & **26.63** & **91.47** & **38.06** & 97.22 & 13.92 & **95.40** & **21.83** \\   

Table 1: Comparison with competitive OOD detection baselines based on ResNet-50. The ID data are ImageNet-1K. \(\) indicates larger values are better and \(\) indicates smaller values are better.

    &  &  \\ iNaturalist \\  } &  &  &  &  \\   & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) \\   \\ MSP & 87.44 & 58.36 & 79.73 & 73.72 & 79.67 & 74.41 & 79.69 & 71.93 & 81.63 & 69.61 \\ ODIN & 94.65 & 30.22 & 87.17 & 54.04 & 85.54 & 55.06 & 87.85 & 51.67 & 88.80 & 47.75 \\ Energy & 95.33 & 26.12 & 92.66 & 35.97 & 91.41 & 39.87 & 86.76 & 57.61 & 91.54 & 39.89 \\ GradNorm & 72.56 & 81.50 & 72.86 & 82.00 & 73.70 & 80.41 & 70.26 & 79.36 & 72.35 & 80.82 \\ ViM & 93.16 & 32.19 & 87.19 & 54.01 & 83.75 & 60.67 & 87.18 & 53.94 & 87.82 & 50.20 \\ KNN & 94.52 & 29.17 & 92.67 & 35.62 & 91.02 & 39.61 & 85.67 & 64.35 & 90.97 & 42.19 \\   \\ Mahalanobis & 56.22 & 99.22 & 60.89 & 99.28 & 68.96 & 98.31 & 65.36 & 98.15 & 62.86 & 98.74 \\ Energy & 85.54 & 80.49 & 84.21 & 78.75 & 84.81 & 72.29 & 66.63 & 92.89 & 80.30 & 81.11 \\ ZOC & 86.09 & 87.30 & 81.20 & 81.51 & 83.39 & 73.06 & 76.46 & 98.90 & 81.79 & 85.19 \\ MCM & 94.61 & 30.95 & 92.57 & 37.57 & 89.77 & 44.65 & 86.10 & 57.77 & 90.76 & 42.73 \\
**CoVer (ours)** & **95.98** & **22.55** & **93.42** & **32.85** & **90.27** & **40.71** & **90.14** & **43.39** & **92.45** & **34.88** \\   

Table 2: Comparison with competitive OOD detection baselines based on CLIP-B/16. The ID data are ImageNet-1K. \(\) indicates larger values are better and \(\) indicates smaller values are better.

[MISSING_PAGE_FAIL:8]

of our CoVer on different backbones of CLIP, and the larger backbone boosts the performance of OOD detection. The second part shows that CoVer can generalize better to various VLM architectures compared to MCM. More fine-grained results on different OOD sets can be found in Appendix C.2.1.

Superiority of multi-dimensional scoring framework.To verify the superiority of our CoVer with a multi-dimensional scoring framework compared with the uni-dimensional one, we report the performance comparison using different corruption types in Figure 5(a). Here, the uni-dimensional framework is denoted as using a single corrupted input for confidence estimation. The results indicate that extended dimensions provide valuable clues for enhancing OOD discriminative representations, thus enlarging the separability between ID and OOD data. We leave the fine-grained results and further discussions in Appendix C.2.2, which provide a better understanding of the improvement.

Significance of the number of expanded measuring dimensions.As a critical aspect of our CoVer, the number of the extended confidence measuring dimensions will control the performance enhancement for OOD detection. In Figure 5(b), we present results for varying the number of expanded dimensions using various corruptions with the same severity level. The results demonstrate that an increasing number of expanded representation dimensions gradually improves the performance then probably declines, while consistently outperforming the baseline. This indicates that the addition of measuring dimensions prioritizes enhancing the distinction of OOD data with mutated confidence while ID data shows resistance. More detailed results and analyses are provided in Appendix C.2.3.

Comparison of the variation trends in different corruption severity levels.In Figure 5(c), we show the performance by varying the severity level \(\) for each specific corruption style. We can observe that three types of trends emerge with an increasing level of severity, i.e., up, down, and up then down. This phenomenon indicates that an appropriate level of corruption is critical for the optimization of CoVer. One possible reason may be that the threshold maximizing the distinction between ID and OOD data varies from different types of corruption. To further explain this observation, we provide more results on the \(\) among various corruption styles and more discussions in Appendix C.2.4.

   ID Dataset & OOD Dataset & Method & AUROC\(\) & FPR95\(\) \\   &  & MCM & 88.99 & 49.79 \\  & & **CoVer** & **89.98** & **46.18** \\   &  & MCM & **90.21** & **44.78** \\   & & **CoVer** & 91.49 & 38.17 \\   &  & MCM & 91.54 & 40.74 \\  & & **CoVer** & **93.03** & **32.15** \\   &  & MCM & 87.57 & 85.97 \\  & & **CoVer** & **88.64** & **55.68** \\   &  & MCM & 85.10 & 57.85 \\  & & **CoVer** & **86.94** & **51.19** \\   

Table 4: Zero-shot OOD detection performance comparison on hard OOD detection tasks. All methods are based on CLIP-B/16.

Figure 5: Ablation Study. (a) superiority of the multi-dimensional scoring framework; (b) exploration of different quantity of expanded input dimensions; (c) using different severity levels of a specific corruption type; (d) comparison with different realizations for each dimensional confidence score.

   Architecture & Backbone & Method & AUROC\(\) & FPR95\(\) \\   & ResNet50 & MCM & 88.99 & 49.79 \\  & & **CoVer** & **89.98** & **46.18** \\   &  & MCM & 89.82 & 45.75 \\  & & **CoVer** & **90.21** & **44.78** \\   & & **VIT-L/14** & MCM & 91.49 & 38.17 \\   & & **CoVer** & **92.61** & **32.97** \\   &  & MCM & 91.54 & 40.74 \\  & & **CoVer** & **93.03** & **32.15** \\   &  & MCM & 87.57 & 85.97 \\  & & **CoVer** & **88.64** & **55.68** \\   &  & MCM & 85.10 & 57.85 \\  & & **CoVer** & **86.94** & **51.19** \\   

Table 5: Zero-shot OOD detection performance with different VLM architecturesâ€™ representations on ImageNet-1K(ID).

Generality of integrating with different OOD detection schemes.Since the proposed CoVer is a general scoring framework with an average of confidence scores measured from multiple dimensions, the specific realization for each dimensional score have multiple choices. In Figure 5(d), we present the comparison with different realizations integrated w./w.o. CoVer (e.g., ResNet-50 based DICE  and ASH-B , CLIP-B/16 based MCM  and NegLabel ), where they have different performance improvements compared with the original baseline without constraints for the modality.

## 5 Discussion

### Broader Impact

OOD detection is crucial for deploying reliable deep learning systems in real-world applications , ensuring models can effectively identify data that differ significantly from the training distribution. This ability is vital in safety-critical areas , where incorrect predictions due to unexpected inputs can lead to severe consequences. For instance, in the field of autonomous driving, OOD detection helps the system recognize and react appropriately to novel scenarios not covered during training, such as new road signs or altered traffic conditions due to construction. This is imperative as it prevents autonomous vehicles from making potentially hazardous decisions based on learned but now irrelevant data, thereby enhancing their safety and robustness in dynamic environments.

Our research highlights a fundamental yet overlooked challenge in existing OOD detection methods, which often specialize in a single input type. This specialization may inadvertently limit the representational dimensions for detection, complicating the identification of subtle OOD samples. For effective OOD detection, it is crucial to not only improve empirical performance through enhanced OOD discriminative representations but also to address this pervasive issue within the general scoring framework. Our new scoring framework leverages expanded input dimensions and utilizes a confidence score expectation to address these concerns, which also shares similar intuitions with some related work  in adversarial defense via random transformation. Comprehensive experiments demonstrate its effectiveness and compatibility, suggesting that our method is potentially a new generalized framework and provides new insights into OOD detection from a different perspective.

### Limitation

While our method introduces a promising framework for OOD detection and provides unique insights through the use of corrupted images to enhance representational dimensions, it does face certain challenges. First, our method indeed faces several failure cases. When CoVer utilizes certain severe corruption types (e.g., Spatter, Elastic transform), its performance is worse than with single input. This is because these types are more severe compared to others, leading to excessive damages to semantic features. Effective corruption types are those only perturb non-semantic features, which generally exist at the high-frequency level, resulting in different confidence variations between ID and OOD data. Notably, except for leveraging the validation set, our approach lacks a standardized criterion for selecting the types and intensities of corruptions, which is essential for uniform effectiveness across various scenarios. Additionally, the expansion of input dimensions, though beneficial for detection accuracy, may lead to increased evaluation times. These limitations highlight areas for potential improvement, particularly in balancing detection capabilities with computational efficiency. Despite these challenges, the enhanced detection capabilities our method introduces mark a significant step forward in the reliability of machine learning models against OOD inputs.

## 6 Conclusion

In this paper, we introduce a novel perspective for OOD detection, i.e., expanding the representation dimensions. With the different common corruptions, we reveal an interesting phenomenon termed _confidence mutation_, where the confidence values of some overconfident OOD samples can vary significantly compared with the original inputs. To this end, we propose a new scoring framework, namely, _Confidence aVerge_ (CoVer), which simultaneously considers the original and expanded input dimensions. Adopting a simple but effective average operation, CoVer can capture the dynamical discrimination of OOD samples and better enhance the separability of ID and OOD distributions. We have conducted extensive experiments to present its effectiveness and compatibility with different methods. We hope our work can draw new insights from a different view on OOD detection.

## 7 Acknowledgement

BXZ, ZMW and BD were supported by the National Key Research and Development Program of China 2023YFC2705700, National Natural Science Foundation of China under Grants 62225113, 62271357, Natural Science Foundation of Hubei Province under Grants 2023BAB072, the Innovative Research Group Project of Hubei Province under Grants 2024AFA017, the Fundamental Research Funds for the Central Universities under Grants 2042023kf0134, Wuhan Natural Science Foundation 2024040801020236, and the numerical calculations in this paper have been done on the supercomputing system in the Supercomputing Center of Wuhan University. JNZ and BH were supported by NSFC General Program No. 62376235, Guangdong Basic and Applied Basic Research Foundation Nos. 2022A1515011652 and 2024A1515012399, RIKEN Collaborative Research Fund, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and HKBU CSD Departmental Incentive Scheme.