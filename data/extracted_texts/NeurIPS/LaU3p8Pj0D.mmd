# Unifying Causal Representation Learning with the Invariance Principle

Dingling Yao, Dario Rancati, Riccardo Cadei, Marco Fumero, and Francesco Locatello

Institute of Science and Technology Austria

###### Abstract

Causal representation learning aims at recovering latent causal variables from high-dimensional observations to solve causal downstream tasks, such as predicting the effect of new interventions or more robust classification. A plethora of methods have been developed, each tackling carefully crafted problem settings that lead to different types of identifiability. The folklore is that these different settings are important, as they are often linked to different rungs of Pearl's causal hierarchy, although not all neatly fit. Our main contribution is to show that _many existing causal representation learning approaches methodologically align the representation to known data symmetries_. Identification of the variables is guided by equivalence classes across different "data pockets" that are not necessarily causal. This result suggests important implications, allowing us to unify many existing approaches in a single method that can mix and match different assumptions, including non-causal ones, based on the invariances relevant to our application. It also significantly benefits applicability, which we demonstrate by improving treatment effect estimation on real-world high-dimensional ecological data. Overall, this paper clarifies the role of causality assumptions in the discovery of causal variables and shifts the focus to preserving data symmetries.

**Editors:** Marco Fumero, Clementine Domine, Zorah Lahner, Donato Crisostomi, Luca Moschella, Kimberly Stachenfeld

## 1 Introduction

Causal representation learning (CRL)  posits that many real-world high-dimensional perceptual data can be described through a simplified latent structure specified by a few interpretable low-dimensional causally-related variables. Many existing approaches in causal representation learning carefully formulate their problem settings to guarantee identifiability [2; 3; 4; 5; 6; 7]. However, some CRL works may not perfectly fit within this causal language framework; for instance, the problem setting of temporal CRL works [8; 9; 10; 11],domain generalization [12; 13; 14] and certain multi-task learning approaches [15; 16] are sometimes framed as informally related to causal representation learning. This has resulted in a variety of methods and findings, some of which rely on assumptions that are not always tailored for practical, real-world applications . This paper contributes a unified rephrasing of many existing nonparametric CRL works through the lens of invariance. We observe that _many existing causal representation approaches share methodological similarities, particularly in aligning the representation with known data symmetries_, while differing primarily in how the invariance principle is invoked. We highlight our contributions as follows:

* We propose a unified rephrasing for existing nonparametric CRL approaches leveraging the invariance principles and prove latent variable identifiability in this general setting (SS 3). We show that 31 existing identification results can be seen as special cases directly implied by our framework (Tab. 2).

* We formalize different definitions of "identifiability" highlighting their connections, and demonstrating how they can be addressed within our framework (App. C.1)
* We analyze the case of partial graph identification, drawing a distinction between the causal assumptions necessary for graph discovery and those required for variable discovery (App. C.2).
* Our framework is broadly applicable across a range of practical settings, with improved results on real-world experimental ecology data using the causal inference benchmark of  (SS 4). We demonstrate that existing methods only require a form of distributional invariance for identification, without needing access to interventions (App. F).

## 2 Problem Setting

This section defines our problem setting using standard CRL concepts and assumptions (Formal definitions are deferred to App. B, a comprehensive summary of notations is provided in App. A). While prior works in CRL typically categorize their settings using established causal language (e.g. 'counterfactual,' 'interventional,' or 'observational'), our approach introduces a more general invariance principle that aims to unify diverse problem settings. We introduce the following concepts as mathematical tools to describe our data generating process.

**Definition 2.1** (Invariance property).: Let \(A[N]\) be an index subset of the Euclidean space \(^{N}\) and let \(_{}\) be an equivalence relationship on \(^{|A|}\), with \(A\) of known dimension. Let \(:=^{|A|}/_{}.\) be the quotient of \(^{|A|}\) under this equivalence relationship; \(\) is a topological space equipped with the quotient topology. Let \(:^{|A|}\) be the projection onto the quotient induced by the equivalence relationship \(_{}\). This projection \(\) is termed the _invariant property_ of this equivalence relation. Two vectors \(,^{|A|}\) are invariant under \(\) if and only if they belong to the same \(_{}\) equivalence class, i.e.: \(()=()_{} \). and \((_{A})=(}_{A})_ {A}_{}}_{A}\).

Extending this definition to the whole latent space \(^{N}\), a pair of latents \(,}^{N}\) are _non-trivially invariant on a subset \(A[N]\) under the property \(\)_ only if (i) the invariance property \(\) holds on the indices \(A[N]\) in the sense that \((_{A})=(}_{A})\); (ii) for any smooth function \(h_{1},h_{2}:^{N}^{|A|}\), the invariance property between \(,}\)_breaks_ under the \(h_{1},h_{2}\) transformations if \(h_{1}\) or \(h_{2}\)_directly_ depends on some other component \(_{q}\) with \(q[N] A\). Taking \(h_{1}\) and \(\) as an example, we have:

\[ q[N] A,^{*}^{N}, s.t.\ }{_{q}}(^{*})(h_{1}())(h_{2}(}))\]

i.e. given that the partial derivative of \(h_{1}\) w.r.t. some latent variable \(_{q}_{[N] A}\) is non-zero at some point \(^{*}^{N}\), \(h_{1}(),h_{2}()\) violates invariance principle in the sense that \((h_{1}())(h_{2}(}))\).

We denote by \(_{}:=\{^{1},,^{K}\}\) the set of latent random vectors with \(^{k}^{N}\) and write its joint distribution as \(P_{_{}}\). The joint distribution \(P_{_{}}\) has a probability density \(p_{_{}}(z^{1},,z^{K})\). Each individual random vector \(^{k}_{}\) follows the marginal density \(p_{^{k}}\) with the non-degenerate support \(^{k}^{N}\), whose interior is a non-empty open set of \(^{N}\).

**Definition 2.2** (Observable of a set of latent random vectors).: Consider a set of random vectors \(_{}:=\{^{1},,^{K}\}\) with \(^{k}^{N}\), the corresponding set of observables \(_{}:=\{^{1},,^{K}\}\) is generated by \(_{}=F(_{})\), where the map \(F\) defines a push-forward measure \(F_{\#}(P_{_{}})\) on the image of \(F\) as: \(F_{\#}(P_{_{}})(x_{1},,x_{K})=P_{_{}}(f_{1}^{-1}(x_{1}),,f_{K}^{-1}(x_{K}))\) with the support \(:=(F)^{K D}\). Note that \(F\) satisfies the diffeomorphism assumption (Asm. B.1) as each \(f_{k}\) is a diffeomorphism onto its image according to Asm. B.1.

In the following, we denote by \(:=\{_{i}:^{|A_{i}|}_{i}\}\) a finite set of invariance properties with their respective invariant subsets \(A_{i}[N]\) and their equivalence relationships \(_{_{i}}\), each inducing as a projection onto its quotient and invariant property \(_{i}\) (Defn. 2.1). For a set of observables \(_{}:=\{^{1},,^{K}\}\) generated from the data generating process described in SS 2, we assume:

**Assumption 2.1**.: For each \(_{i}\), there exists a _unique known_ index subset \(V_{i}[K]\) with at least two elements (i.e., \(|V_{i}| 2\)) s.t. \(_{V_{i}}=F([]_{_{_{i}}})\) forms the set of observables generated from an equivalence class \([]_{_{_{i}}}:=\{}^{N}: _{A_{i}}_{_{i}}}_{A_{i}}\}\), as given by Defn. 2.2. In particular, if \(=\{\}\) consists of a single invariance property \(:^{|A|}\), we have \(_{}=F([]_{_{}})\).

**Remark:** While \(\) does not need to be fully described, which observables should belong to the same equivalence class is known (denoted as \(V_{i}[K]\) for the invariance property \(_{i}\)). Thisis a standard assumption and is equivalent to knowing e.g., two views are generated from partially overlapped latents .

Given a set of observables \(_{}\) satisfying Asm. 2.1, we show that we can simultaneously identify multiple invariant latent blocks \(A_{i}\) under a set of weak assumptions. In the best case, if each individual latent component is represented as a single invariant block through individual invariance property \(_{i}\), we can learn a fully disentangled representation and further identify the latent causal graph by additional technical assumptions.

## 3 Identifiability Theory via the Invariance Principle

**High-level overview.** This section presents a general theory for latent variable identification that brings together many identifiability results from existing CRL works, including multiview, interventional, temporal, and multitask CRL. Our theory of latent variable identifiability, based on the invariance principle, consists of two key components: (1) ensuring the encoder's sufficiency, thereby obtaining an adequate representation of the original input for the desired task; (2) guaranteeing the learned representation to preserve known data symmetries as invariance properties. The sufficiency is often enforced by minimizing the reconstruction loss [8; 9; 10; 19; 20] in auto-encoder based architecture, maximizing the log likelihood in normalizing flows or maximizing entropy [21; 22; 23; 18] in contrastive-learning based approaches. The invariance property in the learned representations is often enforced by minimizing some equivalence relation-induced pseudometric between a pair of encodings [6; 10; 18; 22] or by some iterative algorithm that provably ensures the invariance property on the output [24; 25]. As a result, all invariant blocks \(A_{i},i[n_{}]\) can be identified up to a mixing within the blocks while being disentangled from the rest. This type of identifiability is defined as _block-identifiability_ which we restate as follows:

**Definition 3.1** (Block-identifiability ).: A subset of latent variable \(_{A}:=\{_{j}\}_{j A}\) with \(A[N]\) is block-identified by an encoder \(g:^{D}^{N}\) on the invariant subset \(A\) if the learned representation \(}_{}:=[g()]_{}\) with \([N],|A|=||\) contains all and only information about the ground truth \(_{A}\), i.e. \(}_{}=h(_{A})\) for some diffeomorphism \(h:^{|A|}^{|A|}\).

**Definition 3.2** (Encoders).: The encoders \(G:=\{g_{k}:^{k}^{k}\}_{k[K]}\) consist of smooth functions mapping from the observational support \(^{k}\) to the corresponding latent support \(^{k}\) (SS 2).

**Definition 3.3** (Selection ).: A selection \(\) operates between two vectors \(a\{0,1\}^{d}\,,b^{d}\) s.t. \(a b:=[b_{j}:a_{j}=1,j[d]]\).

**Definition 3.4** (Invariant block selectors).: The invariant block selectors \(:=\{^{(i,k)}\}_{i[n_{}],k V_{i}}\) with \(^{(i,k)}\{0,1\}^{N}\) perform selection (Defn. 3.3) on the encoded information: for any invariance property \(_{i}\), any observable \(^{k},k V_{i}\) we have the selected representation:

\[^{(i,k)}}^{k}=^{(i,k)} g_{k}(^{ k})=[[g_{k}(^{k})]_{j}:^{(i,k)}_{j}=1,j[N]],\] (3.1)

with \(\|^{(i,k)}\|_{0}=\|^{(i,k^{})}\|_{0}=|A_{i}|\) for all \(_{i},k,k^{} V_{i}\).

**Constraint 3.1** (Invariance constraint).: _For any invariance property \(_{i},i[n_{}]\), the **selected** representations \(^{(i,k)} g_{k}(^{k}),k V_{i}\) must be \(_{i}\)-invariant across the observables from the subset \(V_{i}[K]\):_

\[_{i}(^{(i,k)} g_{k}(^{k}))=_{i}(^{(i,k^{ })} g_{k^{}}(^{k^{}})) i[n_{ }]\  k,k^{} V_{i}\] (3.2)

**Constraint 3.2** (Sufficiency constraint).: _For any \(_{i},i[n_{}]\), the **selected** representation \(^{(i,k)} g_{k}(^{k}),k V_{i}\) must preserve all information of the invariant partition \(_{A_{i}}\) that we aim to identify, i.e., \(I(_{A_{i}},^{(i,k)} g_{k}(^{k}))=H(_{ A_{i}})\  i[n_{}],k V_{i}\)._

**Theorem 3.1** (Identifiability of multiple invariant blocks).: _Consider a set of observables \(_{}=\{^{1},^{2},,^{K}\}\) with \(^{k}^{k}\) generated from SS 2 satisfying Asm. 2.1. Let \(G,\) be the set of smooth encoders (Defn. 3.2) and selectors (Defn. 3.4) that satisfy Constraints 3.1 and 3.2, then the invariant component \(^{k}_{A_{i}}\) is block-identified (Defn. 3.1) by \(^{(i,k)} g_{k}\) for all \(_{i},k[K]\)._

**What about the variant latents?** Intuitively, the variant latents are generally not identifiable, as the invariance constraint (Constraint 3.1) is applied only to the selected invariant encodings, leaving the variant part without any weak supervision . This result is formalized as follows:

**Proposition 3.2** (General non-identifiability of variant latent variables).: _Consider the setup in Thm. 3.1, let \(A:=_{i[n g]}A_{i}\) denote the union of block-identified latent indices and \(A^{c}:=[N] A\) the complementary set where no \(\)-invariance \(\) applies, then the variant latents \(_{A^{c}}\) cannot be identified._

Although variant latent variables are generally non-identifiable, they can be identified under certain conditions. The following demonstrates that variant latent variables can be identified under invertible encoders when the variant and invariant partitions are mutually independent.

**Proposition 3.3** (Identifiability of variant latent under independence).: _Consider an optimal encoder \(g G^{*}\) and optimal selector \(^{*}\) from Thm. 3.1 that jointly identify an invariant block \(_{A}\) (we omit subscriptions \(k,i\) for simplicity), then \(_{A^{c}}(A^{c}:=[N] A)\) can be identified by the complementary encoding partition \((1-) g\) only if: (i) \(g\) is invertible in the sense that \(I(,g())=H()\); (ii) \(_{A^{c}}\) is independent on \(_{A}\)._

## 4 Experiments

This section demonstrates the real-world applicability of causal representation learning under the invariance principle, evidenced by superior treatment effect estimation performance on the high-dimensional causal inference benchmark  using a loss for the domain generalization literature that utilizes the invariance principle  (SS 4). Additionally, we provide ablation studies on existing interventional causal representation learning methods [2; 3; 27], showcasing that non-trivial distributional invariance is needed for latent variable identification. This distributional invariance could, but does not have to arise from a valid intervention in the sense of causality (App. F).

**Case Study: ISTAnt** This experiment focuses on ISTAnt , a recent real-world ecological benchmark designed for treatment effect estimation. ISTAnt consists of video recordings of ants triplets with occasional grooming behavior. The goal is to extract a per-frame representation for supervised behavior classification (grooming or not) to estimate the Average Treatment Effect of an intervention (exposure to a chemical substance). Further details about this dataset and problem setting is provided in App. G.1

**Experiment settings.** Different videos in ISTAnt are considered different _experiments_ as the experiment settings and treatments vary. We consider hard annotation sampling criteria (more non-annotated than annotated) for both experiments (videos) and positions, as described by . For the training, we adopt a domain generalization objective that utilizes the invariance principle , which is restated as follows:

\[_{}( g)=}(\{_{1}( g),,_{K}(  g)\})}_{}+_{k}(  g)}_{}.\] (4.1)

We vary the strength of the invariant component in eq. 4.1 by setting the invariance regularization multiplier \(_{}\) from 0 (ERM) to 10 000. We repeat 20 independent runs for each \(_{}\) to estimate the statistical error. All other implementational details follow . We evaluate the performance with both _balanced accuracy_ and _Treatment Effect Relative Bias_ (TERB). TERB is defined in  as the ratio between the bias in the predictions across treatment groups and the true average treatment effect estimated with ground-truth annotations over the whole trial.

**Results.** Fig. 1 depicts the model performance regarding varying invariance regularization strength \(_{}\). As expected, the balanced accuracy initially increases with the invariance regularization strength \(_{}\), as our prediction problem benefits from the invariance, until the sufficiency component is not sufficiently balanced with the invariance, and performance decreases. Similarly, the TERB improves positively, weighting the invariance component until a certain threshold. In particular, on average with \(_{}=100\) the TERB decreases to 20% (from 100% using ERM) with experiment subsampling. In agreement with , a naive estimate of the TEB on a small validation set is a reasonable (albeit not perfect) model selection criterion. Although it performs slightly worse than model selection based on ERM loss in the position sampling case, it proves to be more reliable overall. This experiment underscores the advantages of flexibly enforcing known invariances in the data, corroborating our identifiability theory (SS 3).

## 5 Conclusions

In this paper, we take a closer look at the wide range of CRL methods. Interestingly, we find many CRL approaches share methodological similarities in aligning the representation to known data symmetrics. We identified two components involved in identifiability results: preserving information of the data and a set of known invariances (SS 3). Our results help clarify the role of causal assumptions in causal variable identification, shifting the focus from a characterization of specific assumptions for identifiability, which are not necessarily satisfied in real-world scenarios, to a general recipe that allows practitioners to specify known invariances in their problem and learn representations that align with them. We successfully exemplified the real-world applicability of CRL on ecological data, as shown in SS 4. Nevertheless, our paper leaves out certain settings concerning identifiability that may be interesting for future work, such as discrete variables and finite sample guarantees.