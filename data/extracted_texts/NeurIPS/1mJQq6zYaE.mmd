# Supplementary Material for "Exploring the Optimal Choice for Generative Processes in Diffusion Models: Ordinary vs Stochastic Differential Equations"

Exploring the Optimal Choice for Generative Processes in Diffusion Models: Ordinary vs Stochastic Differential Equations

 Yu Cao &Jingrun Chen &Yixin Luo &Xiang Zhou

Institute of Natural Sciences and School of Mathematical Sciences, Shanghai Jiao Tong University, Shanghai 200240, China, yucao@sjtu.edu.cn University of Science and Technology of China, Hefei 230026, China; Suzhou Institute of Advanced Research, University of Science and Technology of China, Suzhou 215123, China, jingrunchen@ustc.edu.cn University of Science and Technology of China, Hefei 230026, China; Suzhou Institute of Advanced Research, University of Science and Technology of China, Suzhou 215123, China, seeing@mail.ustc.edu.cn School of Data Science and Department of Mathematics, City University of Hong Kong, Kowloon, Hong Kong SAR, xizhou@cityu.edu.hk

###### Abstract

The diffusion model has shown remarkable success in computer vision, but it remains unclear whether the ODE-based probability flow or the SDE-based diffusion model is more superior and under what circumstances. Comparing the two is challenging due to dependencies on data distributions, score training, and other numerical issues. In this paper, we study the problem mathematically for two limiting scenarios: the zero diffusion (ODE) case and the large diffusion case. We first introduce a pulse-shape error to perturb the score function and analyze error accumulation of sampling quality, followed by a thorough analysis for generalization to _arbitrary error_. Our findings indicate that when the perturbation occurs at the end of the generative process, the ODE model outperforms the SDE model with a large diffusion coefficient. However, when the perturbation occurs earlier, the SDE model outperforms the ODE model, and we demonstrate that the error of sample generation due to such a pulse-shape perturbation is exponentially suppressed as the diffusion term's magnitude increases to infinity. Numerical validation of this phenomenon is provided using Gaussian, Gaussian mixture, and Swiss roll distribution, as well as realistic datasets like MNIST and CIFAR-10.

## 1 Introduction

Diffusion models have achieved remarkable success in various artificial intelligence context generation tasks, particularly in computer vision . This technique is rapidly evolving with industrial-level products like DALL-E series. The diffusion model was first proposed and studied by Sohl-Dickstein et al.  in 2015. Later, Song and Ermon  proposed score matching with Langevin dynamics (SMLD) and Ho et al.  further explored the Denoising Diffusion Probabilistic Models (DDPM). Both formalisms can be interpreted as time-discretization of stochastic differential equations (SDEs) . Since the publication of these seminal works, many techniques have been proposed to improve the efficiency and accuracy of diffusion models, such as DDIM , Analytic-DPM , gDDIM , EDM , and consistency model , among others.

The score-based diffusion model involves two steps [30; 17]. Firstly, one estimates the score function, which is the gradient of the logarithm of the probability density function, in the form of a neural network. This step uses trajectories of an Ornstein-Uhlenbeck (OU) process starting with given data samples. This process of injecting noise into structured data is usually referred to as the _inference process_. Secondly, new samples are generated by simulating a time-reversed SDE, with a drift term depending on the learned score function from the first step. This is known as the _generative process_.

In general, there are two diffusion coefficients \(g\) in the inference process and \(h\) in the generative process; see SS 2. Regardless of the choice of \(h\) and \(g\), it is always possible to design an SDE in the generative process that matches the forward inference process in the weak sense, i.e., the probability density functions match for both processes. We highlight that this function \(h\) (unlike \(g\)) does not only appear in the diffusion term, but also enters the drift term in the generative SDE. The choice of \(g\) is equivalent to time re-scaling (see Appx. B.2), while the choice of \(h\) is an important topic in practice. Two common choices of \(h\) are Probability Flow \(h=0\), which refers to as an ODE, and an SDE-based diffusion model with \(h=g\). When the score training is accurate, the choice of this function \(h\) does not affect the sample generation quality in the continuous-time setting.

In practice, numerical error is inevitable during training the score function. Recent theoretical works  have shown that the sample generation quality are affected by three aspects: (1) the truncation of simulation time to a finite \(T\); (2) the inexact score function; (3) the time-discretization error. The first error is not significantly since the forward OU process converges to the equilibrium Gaussian measure exponentially fast in \(T\). The third error can be reduced systematically by more efficient numerical schemes , such as exponential integrator proposed in . The inexact training of score function has a few important but subtle consequences. Recent works  analyzed the convergence rate of diffusion models, provided that the score training error is sufficient small. However, once the score training is not accurate, the nice equivalence of the generated distribution free of the generative diffusion coefficient \(h\) no longer holds as in the idealized situation of exact score function. This raises a key question of our interest about how the choice of \(h\) can affect the sample quality in the face of the inexact score training error. Qualitatively, there are two distinctive cases: \(h=0\) or \(h\) is large. An important question to ask is: **in the presence of non-negligible score training errors, which \(h\) will produce better sampling quality?** Is it the probability flow (\(h=0\)) or the SDE? More quantitatively, what magnitude of \(h\) is optimal?

Related worksThe impact of \(h\) on the generative process seems not yet fully investigated in recent literature, as most experiments used the default choice of this parameter. However, some authors have reported related empirical observations. For example, Song et al.  empirically observed that the choice of \(h=g\) produces better sample generation quality than the ODE case (\(h=0\)) with real datasets. On the other hand, Denoising Diffusion Implicit Models (DDIM) in  includes both deterministic and stochastic samplers and points out that the probability flow (\(h=0\)) can produce better samples with improved numerical schemes for the generative process.  generalized the DDIM and tried to explain the advantages of a deterministic sampling scheme over the stochastic one for fast sampling. Moreover, Karras et. al.,  had empirically searched for optimal coefficients which had shown to bring practical advantages. None of these empirical results delivered comprehensive investigations on the influence of the diffusion coefficient, and a consistent and affirmative answer to our question still awaits. Recently, there has been rapid progress in theoretical works on error analysis for diffusion models, as seen in  and references therein. However, these analyses usually assume specific settings of \(h\), such as \(h=g\). Furthermore, it seems that directly analyzing upper bounds based on these error estimations cannot provide adequate information about choosing the optimal \(h\); see Appx. B.4. Albergo et al. proposed a unified framework known as stochastic interpolants and slightly discussed the optimal choice between the probability flow and diffusion models [1, Sec. 2.4]. It is interesting to see how our theoretical analysis below can generalize to their promising unified settings .

Our approachTo investigate the effect of the diffusion coefficient \(h\) on sampling quality, we adopt the continuous-time framework, which precludes time discretization errors. We measure sample quality by the KL divergence between the data distribution \(p_{0}\) and the distribution of the generative SDE at the terminal time \(T\). Given the assumption that the score function carries numerical errors, we consider \(h\) as a controller and aim to minimize the KL divergence with respect to \(h\). While the optimization problem is straightforward to set up, it is challenging to draw valuable theoretical insights in a general setting of approximate score functions. Therefore, we choose the asymptotic approach, assuming that the error from the training score is reasonably small with a magnitude of \(\). Under this assumption, the leading-order term of the KL divergence takes the form

\[=L(h)\ ^{2}+ ^{3}.\]This \(^{2}\) order is known in [7; 10], but the dependence of this Gateaux differential \(L(h)\) on \(h\) and other factors has yet to be understood at all. Our contribution is to analyze how \(L(h)\) behaves as \(h\) varies; in particular, by considering the constant \(h\) in two limiting situations: \(h=0\) and \(h 1\).

Main ContributionsWe summarize main contributions below:

* We prove that when the error in score function approximation is a time-localized function only at the beginning of the inference step (i.e., at the end of the generative process), the ODE case (\(h=0\)) outperforms the SDE case (\(h\)); see Prop. 3.5. If this (time-localized) error occurs in the middle, then the SDE case has an _exponentially smaller error_ than the ODE case (\(h=0\)), as \(h\) (see Prop. 3.4). See Appx. E.4 for reasons behind the time-localized choice.
* For a **general** score training error, we prove that as \(h\), the leading-order term \(L(h)\) above converges exponentially fast to a constant, which only depends on the distribution \(p_{0}\) and the score training error at the end of the generative process; see Prop. 3.6. The conclusion about the optimal \(h\) depends on how the score training error is distributed over the time horizon \([0,T]\).

Numerically, we validate the above phenomenon for 1D Gaussian, 2D Gaussian mixture, and Swiss roll distribution, as well as realistic datasets like MNIST and CIFAR-10. Due to the tight connection between the distribution of score training error and \(h\), our results may suggest backwardly modifying loss functions during training to adapt to a particular diffusion coefficient of interest. This is a topic of independent interest and we report some preliminary experiments in Appx. 1 to validate potential applications of our theoretical analysis. A comprehensive investigation will be left as future works.

Notation conventionThe time duration \(T>0\) is a fixed parameter. For any time-dependent function \((t,x) f_{t}(x)\), where \(x^{d}\) and \(t[0,T]\), we denote \(f_{t}^{}(x) f_{T-t}(x)\). Sometimes we directly use the "arrowed" variables \(f_{t}^{}(x)\) to highlight the direction of time is from reference noise to the data distribution (i.e., the generative direction) even without referring to \(f\) first. The notation \(f g\) means that \(f cg\) where \(c 1\) in a certain limit, i.e., \(^{f}/g 1\); \(f g\) means \((f/g)=1\). The asymptotic parameter will be explained below explicitly. When two matrices \(A B\), it means \(B-A\) is positive semidefinite. \(_{d}\) is the \(d\)-dimensional identity matrix; \(_{A}\) means an indicator function of a set \(A\); Id is the identity operator. For a random variable \(X\), \((X)\) means the distribution of \(X\). Some important quantities are summarized in Appx. 1.

## 2 Background

Score-based generative modelsSuppose we have a collection of data from an unknown distribution with density \(p_{0}\), we can inject noise into data via the following SDEs:

\[X_{t}=f_{t}(X_{t})\;t+g_{t}\;W_{t},(X_{0})=p_{0},\] (1)

where the drift coefficient \(f_{()}():^{d}^{d}\) is a time-dependent vector field, and the diffusion coefficient \(g_{()}:\) is a scalar-valued function (for simplicity). A widely used example is variance-preserving SDE (VP-SDE) with \(f_{t}(x)=-}{{2}}\;g_{t}^{2}\;x\) and \(g>0\) is typically chosen as a non-decreasing function in literature . Without loss of generality, we can assume \(g_{t}=1\) since for any non-zero \(g\), its effect is simply to re-scale the time; see Appx. 2.

Denote the probability density of \(X_{t}\) as \(p_{t}\) and the score function is defined as \( p_{t}\). One main innovation in diffusion models is to find a "backward" SDE \(Y_{t}\) such that \(Y_{t}\) drives the state with distribution \(p_{T}\) back to \(p_{0}\). We adopt the arrow of time in this backward direction now and write \(Y_{t}\) as

\[Y_{t}=A_{t}^{}(Y_{t})\;t+h_{t}^{}\; W_{t}\,,(Y_{0})=p_{T},\] (2)

where \(h_{t}^{}\) is an arbitrary real-valued function of time. The distribution of \(Y_{t}\) is denoted as \(q_{t}\). Provided that the score function is available, we can select \(A^{}\) such that \(q_{t}\) is the same as \(p_{T-t}\), in particular, \(q_{T}=p_{0}\). It is not hard to derive that we can ensure \(q_{t} p_{T-t}\) if we choose

\[A_{t}^{}(x)=-f_{t}^{}(x)+^{})^{2}+ (h_{t}^{})^{2}}{2} p_{t}^{}(x).\] (3)

A self-contained proof is provided in Appx. 1. When \(h^{}=g^{}\), it refers to the backward SDE used in ; when \(h^{}=0\), it refers to the probability flow therein. More general interpolation of diffusion and flow can be found in, e.g., .

Training of score functionsThe above score function \((t,x) p_{t}^{}(x)\) needs to be trained from data. Denoising score matching  refers to the following score-matching loss (SML) function to train the score whose parameterized architecture is denoted as \(\):

\[_{}_{0}^{T}_{t}\;_{X_{0} p_{0}}_{X_{t} p_{t|0}(\|X_{0}\|}_{t}(X_{t} )- p_{t|0}(X_{t}|X_{0})^{2}t,\] (4)

where \(p_{t|0}(x_{t}|x_{0})\) is the transition probability of the state \(x_{0}\) at time \(0\) towards the state \(x_{t}\) at time \(t\) for the forward process (1). The function \(_{t} 0\) is a weight function. The default choice in many literature is that \(g_{t}=+(_{1}-_{0})t}\), \(0<_{0}<_{1}\) are parameters, and one chooses the weight function as follows:

\[_{t}=_{t}^{2},_{t}= t^{2}(_{1}-_{0})-t_{0}}}.\] (5)

The quantity \(_{t}\) has the meaning as the standard deviation of \(X_{t}\) conditioned on a fixed \(X_{0}\) in the forward process. See SS 3.7 and Appx. I for more weight functions.

Source of errorsThere is usually intrinsic error due to an inexact score function. It is not negligible in many scenarios, e.g., there is only a finite amount of samples of \(p_{0}\) available or only a small neural network architecture is achievable. However, it is reasonable to assume that this non-negligible error is reasonably small, and we decompose the trained score function \(_{t}^{}\) into

\[_{t}^{}(x)= p_{t}^{}(x)+ _{t}^{}(x),\] (6)

where \(\) is small, \(_{t}^{}\) is assumed to be \((1)\) and the total error is \(_{t}^{}\). The generative process used in practice has to use \((Y_{0})=(0,I_{d})\) instead since \(p_{T}\) is intractable in (2). By choosing \(T\) large enough so that \(p_{T}(0,I_{d})\), we can neglect this error due to the finite \(T\). Besides, we also need some numerical schemes to simulate this generative SDE, which also leads into discretization errors. **In summary**, there are three sources of errors (1) \(p_{T}(0,I_{d})\): this is the source of errors in the initial distribution of the generative process; (2) \(^{} 0\): error from imperfect score function from training; (3) numerical discretization of the generative process. The third error can be systemically eliminated by choosing a high-order scheme  or an extremely small time step. It has been observed that by choosing a more accurate numerical scheme, e.g., exponential integrator, one can reduce the computational costs [35; 36]. As for the first error, if one chooses the OU process for (1), \(p_{T}\) converges to \((0,I_{d})\) exponentially fast and thus \(T=(())\) where \(\) is the error between \(p_{0}\) and the distribution of generated samples. Therefore, the choice of \(T\) is, in practice, not hard to manage. More details about these three error sources can be found in, e.g., [7; 10] or Appx. B.3.

## 3 Asymptotic analysis of terminal errors

We use the KL divergence between the data distribution \(p_{0}\) and the distribution of generated samples to quantify the performance of generative model, which depends on the error of score function \(^{}\)

Figure 1: _Schematic illustration_ of the main message: the distribution of the score error \(_{t}^{}\) w.r.t. time also matters, in addition to the score-matching loss (4). Asymptotically, the score error can be viewed as “additive” and the error from two time regions (blue and green) might decay or magnify as the magnitude of diffusion coefficient \(h^{}\) increases (see the right picture). The yellow region is a transitional region whether the effect of h is not easy to decide.

the diffusion coefficient \(h^{}\), and data distribution \(p_{0}\). To extract the main feature, we first let \( 0\) and estimate

\[=L(h^{},^{ },p_{0})^{2}+^{3}.\]

Whenever \(p_{0}\) and \(^{}\) are obvious from the context, we simply write \(L(h^{}) L(h^{},^{},p_{0})\). Next, we formulate the main problem setup and assumptions in SS 3.1. The expression of \(L\) is shown in Prop. 3.2. Then we let \(h_{t}^{}\) be independent of time, and study how the leading order function \(L\) depends on \(\) in various settings of the error function \(_{t}^{}\). Firstly, we consider \(_{t}^{}(x)=_{t-s}E(x)\) as a time-localized function and two limiting scenarios: \(h^{}=\) where \(=0\) (ODE case) and \(\) (SDE case with large diffusion). When \(_{t}^{}(x)=_{t-s}E(x)\) is a time-localized function at the end of the generative process (i.e., \(s\) is close to \(T\)), the ODE case will outperform the SDE case (see Prop. 3.5); otherwise, the SDE case has an exponentially smaller error than the ODE case as \(\) (see Prop. 3.4). Secondly, by combing Prop. 3.4 and Prop. 3.5, the tail behavior of \( L()\) for a general \(^{}\) is described in Prop. 3.6. The reasons behind considering this pulse-shape \(_{t}^{}\) will be discussed in Appx. E.4.

### Set-up and assumptions

We fix the time \(T\) and consider the following SDE for the generative process in \(t[0,T]\),

\[_{t}=-f_{t}^{}(_{t})+ ^{})^{2}+(h_{t}^{})^{2}}{2}_{t}^{ }(_{t})\ t+h_{t}^{}\ W_{t},\ \ (_{0})=p_{T},\] (7)

which can be regarded as a perturbed equation (2) of \(Y_{t}\). Denote the distribution of \(_{t}\) as \(_{t}\). Note that \(_{T}\) depends on both \(h^{}\) and \(_{t}^{}\) (hidden inside \(_{t}^{} p_{t}^{}+ _{t}^{}\)); however, when \(=0\), by (3), \(_{T} q_{T} p_{0}\) for _any_\(h^{}\). We quantify the sample generation quality via

\[p_{0}||_{T}= p_{0}(p_{0}/ _{T}).\]

Due to the presence of \(^{}\) with non-zero \(\), in general \(p_{0}||_{T}>0\).

**Assumption 3.1**.: _Throughout this section, we assume that:_

1. _For the forward process, we assume_ \(f_{t}(x)=-x\)_,_ \(g_{t}=1\) _without loss of generality._
2. _The data distribution has the density_ \(p_{0}\)_._
3. _There exists_ \(c_{U}\) _such that_ \(U_{0}(x)-}}{{2}} c_{U}\)_, for any_ \(x^{d}\)_, where_ \(U_{0}:=- p_{0}\)_._

Recall that a generic \(g_{t}\) is equivalent to the time re-scaling (Appx. B.2). So this choice of \(g_{t}=1\) refers to the generic choice in VP-SDE . The second assumption is also mild; in practice, if \(p_{0}\) is a delta distribution, a common practice is that one tries to learn the mollified version \(p_{}(x):=_{^{d}})^{d/2}} -}}{{2^{2}}}p_{0}(y)y\) instead, as in the GAN  and early-stop techniques . The third assumption is not restrict, for example, \(U_{0}(x)=x^{2}\) and \(c_{U}=0\). As many realistic datasets are almost compactly supported, we expect that \(_{0}=e^{-U_{0}}\) decays faster than a Gaussian, namely, \(_{0}(x)e^{-|x|^{2}/2}\) for some \(>0\), which reduces to the third one.

### Asymptotic expansion of the KL divergence with respect to \(\)

We introduce a time-dependent operator

\[_{t}^{(h^{})}()(x):=- x+^{ 2}}{2} p_{t}^{}(x)(x) +^{ 2}}{2}(x),\] (8)

which is the generator in the Fokker-Planck equation of \(q_{t}\) for (2). Define an operator \(_{s,t}^{(h^{})}\) as follows: given any function \(\), define \(_{s,t}^{(h^{})}()\) to be the solution at time \(t\) of the following Fokker-Planck equation with \(r[s,t]\): \(_{r}_{r}=_{r}^{(h^{})}(_{r}),\) and with initial condition \(_{s}=\). We define \(_{s,t}^{(h^{})}():=_{t}\). Properties of this operator are collected in Appx. C.1.

We use the notation \(^{}\) to refer to \(\) since we need to calculate the its derivative for the small parameter \(\). The dependence of \(\) on \(h^{}\) is suppressed for short notations. We have the following asymptotic result with the proof given in Appx. C.3.

**Proposition 3.2**.: _Define \(v_{T}:=_{t}^{v}_{T}|_{=0}\) as the first-order perturbation of \(^{v}_{T}\). We have_

\[p_{0}||^{v}_{T}=L(h^{})^ {2}+^{3},\] (9)

_where_

\[L(h^{})=_{^{d}}^{2}(x)}{p_{0}( x)}\;x, v_{T}=-_{0}^{T}(1+h_{t}^{ -2})_{t,T}^{(h^{})}(p_{t}^{}_{t}^{})\;t.\] (10)

### The role of \(h^{}\) in the Fokker-Planck operator \(_{t}^{(h^{})}\)

Let the potential \(U_{t}:=- p_{t}\), and by the notation of time-reversal, \(U_{t}^{} U_{T-t}\). When \(h^{}>0\), we can rewrite

\[_{t}^{(h^{})}()=}}{{2}} +( V_{t}^{ }), V_{t}^{}(x):=(1+}{{h_{t }^{ 2}}})U_{t}^{}(x)-}{2h_{t}^{ 2}}.\] (11)

We now introduce a probability distribution induced by the potential \(V_{t}^{}\):

\[_{t}^{}(-V_{t}^{}).\] (12)

By convection, we also have \(V_{t}=V_{T-t}^{}\) and \(_{t}=_{T-t}^{}\). Note that \(V_{t}^{}\) depends on \(h^{}\) and when \(h^{}\), we have \(V_{t}^{,}=U_{t}^{}\). The role of \(h^{}\) in \(_{t}^{(h^{})}\) now can be viewed as the time re-scaling and the effect of \(_{t}^{(h^{})}\) at a local time \(t\) can be viewed as evolving the Fokker-Planck equation associated with the overdamped Langevin dynamics in the time-dependent potential \(V_{t}^{}\) for \(^{}}}{{2}}\) amount of time. When \(h^{}\), \(_{t}^{(h^{})}\) can be roughly viewed as constructing an "almost quasi-static" thermodynamics  bridging the initial \(p_{T}\) and the (quasi-)equilibrium \(p_{0}=e^{-U_{T}^{}}\) : for any distribution \(_{t}^{}\) (probably far away from \(_{t}^{}\)), within a short time period \( t\) slightly larger than \(1/h_{t}^{ 2}\), we have \(_{t+ t}^{}_{t+ t}^{}\), provided that \(s_{s}^{}\) evolves according to \(_{s}^{(h^{})}\); see Appx. C.2. This key finding will guide our analysis of the solution operator \(_{t,T}^{(h^{})}\).

### Score function is perturbed by a pulse

From (10), we know that \(v_{T}\) combines the averaged effect of \(_{t,T}^{(h^{})}((p_{t}^{ }_{t}^{}))\) for various \(t\). As a first result, we consider \(_{t}^{}(x)=E(x)_{t-s}\) for a fixed time instance \(s[0,T)\), where \(_{t-s}\) is the Dirac function. In this case, \(v_{T}\) no longer involves time integration and we have

\[ v_{T}&=-^{ 2})}{2}_{s,T}^{(h^ {})}(p_{s}^{ }E),\\ L(h^{})&=^{ 2})^{2}}{8} _{^{d}}_{s,T}^{(h^{})} (p_{s}^{}E)^{2}}{p _{0}}.\] (13)

To proceed, we need to make additional assumptions:

**Assumption 3.3**.:
1. _For any_ \(t[0,T]\)_,_ \(U_{t}=- p_{t}\) _is assumed to be strongly convex and the Hessian of_ \(U_{t}\) _is bounded by two positive numbers_ \(m_{t}\) _and_ \(M_{t}\) _as below_ \[m_{t}_{d}\;^{2}U_{t}(x) M_{t}_{d}, x^{d}.\] (14) _Moreover, assume that_ \[m_{t} 1, t[0,T], m_{0}>1.\] (15)
2. _For all_ \(t[0,T]\)_, we choose_ \(h_{t}^{}=\) _as constant._

Introduce

\[_{t}^{}:=(1+^{-2})m_{t}^{}-^{-2 }(1+^{-2})m_{T-t}-^{-2},\] (16)which characterizes the Hessian lower bound of \(V_{t}^{}\) (11). Note \(_{t}^{} m_{t}^{}\) when \( 1\). We would like to explain the reason behind the above assumptions, in particular, their practical relevance. **Part (1) Strong convexity:** this is a common assumption for Langevin sampling analysis [11; 14]. As the role of \(_{t}^{(h^{})}\) is essentially simulating a Langevin dynamics with time-dependent potential, it is reasonable to use this assumption as a starting point. Moreover, the algorithmic improvement in gDDIM  is highly inspired by a form with assuming the data distribution as a Gaussian; Frechet inception distance (FID) , a widely used metric to evaluate the quality of generative model, essentially treats the data (in the feature space) as Gaussians. Therefore, we believe that this assumption can still capture some main features of realistic datasets. **Part (2) \(m_{t} 1\) for any \(t[0,T]\):** The second assumption \(m_{t} 1\) means that \(p_{t}\) is more localized (smaller variance) than the standard Gaussian (unit variance), which is compatible with Assumption 3.1 (3). It can also ensure that \(V_{t}\) is strongly convex with positive Hessian lower bounds, i.e., \(_{t}^{} 1\), for any \(t[0,T]\) and \((0,)\).

**Proposition 3.4**.: _Under Assumptions 3.1 and 3.3, suppose that \(_{t}^{}(x)=E(x)_{t-s}\) for some fixed \(s[0,T)\). If \(_{lb}:=\{}{{2}},_{0 }(}{{2}}),}{(2)},_{t[s,T]}C_ {t}^{,(2)}\}}\},\) we have the upper bound of \(L(h)\) in (13):_

\[L() C_{}(1+^{2})^{2}-_{s}^{T} (^{2}-C_{r}^{,(2)})_{r}^{}-C_{r}^{ ,(1)}r,\] (17)

_where \(C_{}=(p_{s}^{ }E)^{2}/_{s}^{}\), \(C_{t}^{,(2)}=^{ 2}}{m_{t}^{  2}}\); see Appx. E.1 for details about \(C_{t}^{,(1)}\) and \(_{0}(}{{2}})\); \(c_{U}\) comes from Assumption 3.1. Moreover, \(_{}C_{}\), \(_{}C_{t}^{,(1)}\) exist._

See Appx. E.1 for proofs. We remark that the above bound focuses on capturing the scaling with respect to \(^{2}\) but may not be tight for other parameters. It remains interesting to see how we can improve the above upper bound. The _main conclusion_ is that: if the error function \(_{t}^{}\) is a pulse at time \(t=s\), then for a large \(\), \(L()\) will decay to zero exponentially fast with respect to \(\). For 1D Gaussian case, we can clearly observe such an exponential decay in Fig. 1(a), where we pick \(_{t}^{}=_{t 0.95T} p_{t}^{ }\). The intuition behind this exponential suppressed prefactor is that for large \(h\), \(_{s,T}^{(h^{})}\) can be viewed as an almost quasi-static thermodynamics dragging any positive measure towards \(_{T}^{} p_{0}\), as mentioned above in SS 3.3. As \(=(p_{s}^{}E)\) has measure zero, we can split it into positive and negative parts: \(=^{+}-^{-}\) ( assume \(^{}=1\) WLOG). Each term \(_{s,T}^{(h^{})}^{+}_{T}^{} _{s,T}^{(h^{})}^{-}\), which explains that \(_{s,T}^{(h^{})}() 0\) for large \(\).

### Score function is only perturbed near the end of the generative process

**Proposition 3.5**.: _Under Assumptions 3.1 and 3.3, suppose that \(_{t}^{}(x)=_{t[T-a,T]}E(x)\) where \(a 1\). Then when \(a 1\) and \( 1\), asymptotically,_

\[L(0)}{8}_{^{d}} (p_{0}E))^{2}}{p_{0}}, L()1-e^{-a}{2}_{0}}^{2}}{2_{0}^{2}}_{ ^{d}}(p_{0}E))^{2}}{p_ {0}},\]

Figure 2: 1D Gaussian \(p_{0}=(0,_{0}^{2})\) (with different \(_{0}\) smaller than one) and \(T=2\). Panel (a) validates the exponential decay of \(L()\) when the score function has no error near \(t T\), similar to Prop. 3.4. Panel (b) validates Prop. 3.5 that the ODE model (\(h=0\)) outperforms the SDE model when there is a large score error at \(t T\). Panel (c) validates Prop. 3.6 that \(_{}L()\) exists.

_with \(_{0}=(1+}{{h^{2}}})m_{0}-}{{h^{2}}}\) as in (16). The upper bound of \(L()\) is tight asymptotically._

We remark that we made _no assumption on how \(ah^{2}\) scales_. If \( 1\), \()}}{{L(0)}} 41-e^{-ah^{2}_{0}/2} ^{2}/a^{2}_{0}^{2}\). **Case (I):** If \(ah^{2} 1\), then \()}}{{L(0)}}}{{a^{2}_{0}^{2}}}\), which is large as \(a 1\). **Case (II):** If \(ah^{2} 1\), then \()}}{{L(0)}}^{4}\), which is still large. In either case, \()}}{{L(0)}}\) is expected to be large for a general \(E\) and the ODE model is preferred in this case. The intuition is that there is almost no time for the operator \(_{h}^{(h^{*})}\) to suppress the error \(E\), so the prefactor \(1+(h_{t}^{-})^{2}\) in \(v_{T}\) (10) dominates (which is the key difference compared with Prop. 3.4). The proof is postponed to Appx. E.3. In Fig. 1(b), we consider 1D Gaussian and only perturb the score function at the end of the generative process (\(_{t}^{}=_{t 0.995T} p_{t}^{ }\)); clearly, the SDE-based models have comparatively larger error.

### General error in score function

We can generalize Prop. 3.4 and Prop. 3.5 to a general error function \(^{}\), and observe that \(L()\) will converge to a constant exponentially fast as \(\).

**Proposition 3.6**.: _Under Assumptions 3.1 and 3.3, we consider a general error function \((t,x)_{t}^{}(x)\). Let \(=_{_{_{}}}_{t[0,T ]}_{+}^{}\). For any \((0,1)\) and \((0,2)\), when \( 1\),_

\[L() (1+^{2})+(1+^{-2})\;C\;^{-1 }(1+^{2})-^{2-},\] \[L() (1-^{2})-(^{-2}-1)C\;^{-1}(1 +^{2})-^{2-},\]

_where \(C\) is given in Appx. F.1 and \(\) (only depending on \(p_{0}\) and \(_{T}^{}\)) is upper bounded by_

\[0^{2}}_{^{d}} (p_{0}_{T}^{})^{2}}{p_{0 }}-1.422638pt^{2}}_{^{d}}(  p_{0}_{T}^{}+ {}_{T}^{})^{2}p_{0}.\] (18)

In the limit \(\), \((1-^{2}) L()(1+^{2})\), where \((0,1)\) is arbitrary. Hence, the tail behavior is that \(L()\) converges to \(\) exponentially fast as \(\). If we assume that \(_{T}^{}= p_{0}\), \(p_{0}=(0,_{0}^{2}_{d})\) in \(d\)-dimension, then the above upper bound is simply \( d\), which is independent of \(_{0}\) (see Appx. F.2). For 1D Gaussian in Fig. 1(c), we can indeed observe that \(_{}L()\) exists, and is bounded above by \(d=1\); see Appx. G for more types of error functions.

The above upper bound has an interesting tight connection to the generator of (overdamped) Langevin dynamics with drift \(- U_{0} p_{0}\). If we adopt constrained score models , namely, parameterizing \( p_{t}\) instead of the score function \( p_{t}\) during training, the error \(_{T}^{}=\) for some scalar-valued function \(\). Then the above upper bound becomes

\[^{2}}_{^{d}}(- U_{0} )^{2}e^{-U_{0}}=^{2}}_{^{d}}( ^{*})^{2}e^{-U_{0}},\] (19)

where \(^{*}():=- U_{0}\) whose adjoint operator \(()=( U_{0})+\) is the Fokker-Planck generator of the following Langevin dynamics \(X_{t}=- U_{0}(X_{t})\;t+\;W_{t}\) where \(W_{t}\) is the standard Brownian motion. We remark that this formula (19) is general for constrained score models ; see also F.2 for elaborations. An interesting open question is whether and how we can take the above upper bound into consideration when designing the loss function.

### An application: exploring the effect of training weight

The above theoretical discussions suggest that diffusion models with large diffusion coefficients are more negatively affected by score error near data's side, whereas the ODE model is more negatively affected by the score error near the noise end. This leads us to conjecture that if we can control the training (e.g., by optimizing the training weight \(_{t}\)), so that the score error distribution near the noise end is reduced and meanwhile the score-matching loss is not significantly impacted, then it will very likely improve the ODE models. We report preliminary numerical experiments to support this idea in Appx. 1, whereas a comprehensive study will be left as future works.

Numerical experiments

We present experiments on 2D Gaussian mixture model, Swiss roll, CIFAR10 to support our theoretical results: when numerical discretization error is not dominating, the sampling quality increases as h increases, a reminiscent of Prop. 3.4. Experimental details are postponed to Appx. H, as well as more numerical results (e.g., results about 1D Gaussian mixture and MNIST). Results by adopting various weight functions, a technique arising from theoretical predictions, are postponed to Appx. I. Source codes are available at https://github.com/yucaoyc/OptimalDiffusion.

Example 1: 2D 4-mode Gaussian mixture.We verify the theoretical results on 2D Gaussian mixture with a specified score error. In Fig. 3, a clear trend is that a higher h produces generated distributions that better match the marginal densities of \(p_{0}\), and it is numerically verified by the purple line of Fig. 3(a). In Fig. 4, with multiple settings of \(_{t}^{}\) and \(\), we observe a consistent phenomenon that as h increases, the KL divergence of true data and generated data converges exponentially fast, thus validating Prop. 3.6. It worths noticing that in all three settings of \(_{t}^{}\), by simply adopting a larger diffusion coefficient \(h\) in (3), we can obtain better generative models without any extra training costs.

Example 2: Swiss roll.We consider Swiss roll, a more complex distribution without exact score function available. We train the score function with the denoising score-matching objective  (Appx. H). The first plot in Fig. 4(a) shows the difference between true data and generated data measured by Wasserstein distance, which decays to zero exponentially fast, verifying Prop. 3.6. In the second plot of Fig. 4(a), we tested various \(h\) and time steps for the generative process. The ODE model (\(h=0\)) does not improve, as the number of time discretization steps increases, but near the continuous-time limit, all SDE cases (\(h>0\)) are better than the ODE model. It suggests that our conclusions here is limited to the continuous-time setting. The exploration of time discretization errors will be future works. The generated data results in Fig. 4(b) demonstrate that with increasing \(h\), the sample quality is improved; see Appx. H.6 for more results.

Figure 4: Numerical results of 2D 4-mode Gaussian mixture. The above panels show that the KL divergences between the true distribution and the generated samples overall decay as h increases for various types of error perturbation of score functions.

Figure 3: Visualization of marginal densities of 2D 4-mode Gaussian mixture, where \(_{t}^{}= p_{t}^{}\) and \(=0.2\). The top row shows the marginal distribution of the first coordinate and the bottom row for the second coordinate. The red lines are the exact marginal distributions of \(p_{0}\) and the histograms (blue) visualize the empirical densities of generated samples.

Example 3: CIFAR-10.When using a large amount of parameters for score matching in practice, we observe that SDEs appear to perform better than ODEs as discretization error descreases, a result similarly observed on Swiss roll. This implicates the practical applications on generating samples of better quality under a given (pre-trained) score-matching model.

## 5 Summary and outlook

In this work, we study the effect of the diffusion coefficient on the quality of overall sample generation in the generative process. Theoretically, we provide understandings of scenarios in which the ODE-based model and the SDE-based model is superior than the other; see Prop. 3.4 and Prop. 3.5. Numerically, these results are validated via toy examples as well as benchmark datasets.

There are many interesting directions for continuing works. (1) As we focus on the asymptotic case, a time-dependent \(h_{t}^{}\) with large magnitude (i.e., \(h_{t}^{} 1\) for all \(t\)) is essentially no different from a constant \(h_{t}^{}\) with \( 1\). Whether it is possible to use time-dependent \(t h_{t}^{}\) to combine the advantages of ODE and large diffusion cases in dealing with different types of error of score functions in the non-asymptotic region is still an open question. (2) Can we design a practical criterion that directly learn the optimal magnitude of the noise-level function \(h_{t}^{}\) by looking at the score-training error distribution? Can we develop certain theoretical understanding of the empirical results in ? (3) How can we find a stable and accurate numerical scheme to deal with the fast diffusion case? (4) How can we generalize the above theoretical results by removing the convexity assumption, and including the low-dimensional feature of datasets into the theory [8; 5; 18]?

Concerning the broad impact, though we don't foresee any negative social impact of this work, the potential improvement of generative model might relate to creation of "deep fakes".