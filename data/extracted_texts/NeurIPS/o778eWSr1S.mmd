# Label-Retrieval-Augmented Diffusion Models for Learning from Noisy Labels

Jian Chen\({}^{1}\)  Ruiyi Zhang\({}^{2}\)  Tong Yu\({}^{2}\)  Rohan Sharma\({}^{1}\)

Zhiqiang Xu\({}^{3}\)  Tong Sun\({}^{2}\)  Changyou Chen\({}^{1}\)

\({}^{1}\)University at Buffalo \({}^{2}\)Adobe Research \({}^{3}\)MBZUAI

{jchen378,rohanjag,changyou}@buffalo.edu

{ruizhang,tyu,tsun}@adobe.com zhiqiang.xu@mbzuai.ac.ae

###### Abstract

Learning from noisy labels is a long-standing problem in machine learning for real applications. One of the main research lines focuses on learning a label corrector to purify potential noisy labels. However, these methods typically rely on strict assumptions and are limited to certain types of label noise. In this paper, we reformulate the label-noise problem from a generative-model perspective, _i.e._, labels are generated by gradually refining an initial random guess. This new perspective immediately enables existing powerful diffusion models to seamlessly learn the stochastic generative process. Once the generative uncertainty is modeled, we can perform classification inference using maximum likelihood estimation of labels. To mitigate the impact of noisy labels, we propose **L**abel-**R**etrieval-**A**ugmented (LRA) diffusion model 1, which leverages neighbor consistency to effectively construct pseudo-clean labels for diffusion training. Our model is flexible and general, allowing easy incorporation of different types of conditional information, _e.g._, use of pre-trained models, to further boost model performance. Extensive experiments are conducted for evaluation. Our model achieves new state-of-the-art (SOTA) results on all standard real-world benchmark datasets. Remarkably, by incorporating conditional information from the powerful CLIP model, our method can boost the current SOTA accuracy by 10-20 absolute points in many cases.

## 1 Introduction

Deep neural networks have achieved extraordinary accuracy on various classification tasks. These models are typically trained through supervised learning using large amounts of labeled data. However, large-scale data labeling could cost huge amount of time and effort, and is prone to errors caused by human mistakes or automatic labeling algorithms . In addition, research has shown that the ability of deep neural network models to fit random labels can result in reduced generalization ability when learning with corrupted labels . Therefore, robust learning methods using noisy labels are essential for applying deep learning models to cheap yet imperfect datasets for supervised learning tasks.

There are multiple types of label noise investigated by previous research. More recent research has focused on studying the more realistic feature-dependent label noise, where the probability of mislabeling a given instance depends on its characteristics. This type of noise is more consistent with label noise in real-world datasets . To address this type of noise, a model is expected to be able to estimate the uncertainty of each training label. Many state-of-the-art methods have primarily relied on the observation that deep neural networks tend to learn simple patterns beforememorizing random noise . This means a temporary phase exists in the learning process, where the model has learned useful features but has yet not started overfitting corrupt labels. At this stage, the model predictions can be used to modify the training labels, so that they are more consistent with model predictions . By correctly modifying the labels, the number of clean training sample increases, which can further benefit the training. These type of approaches, however, is inherently risky because the point at which the model starts to overfit varies with the network structure and dataset. Starting too early can corrupt the training data, while starting too late may not prevent overfitting . Therefore, it is vital to carefully tune the hyper-parameters of the training strategy, such as the number of epochs for warm-up training, learning rate, and uncertainty threshold, to achieve successful training results.

Another class of methods adopts the assumption of label propagation in semi-supervised learning , where nearby data points in a feature space tend to have the same label. Therefore, they use _neighbor consistency2_ regularization to prevent overfitting of the model . The performance highly depends on the quality of the encoder that maps the data to the feature space, as retrieving a neighbor that belongs to a different class could further mislead the training process. Encoders are therefore required to first learn high-level features of the data that can be used for classification, which could be trained simultaneously with the classifier using noisy labels. However, the training can also lead to overfitting or underfitting.

In this paper, by contrast, we formulate the label noise problem from a generative-model perspective, which naturally provides new insights into approaching the problem. Our intuition is to view the noisy labeling process as a stochastic label generation process. Thus, we propose to adopt the powerful diffusion model as the generative building block. Figure 1 illustrates our intuition. In the generative process, we start with a noisy estimation of the label, then gradually refine it to recover the clean label, which is equivalent to the reverse denoising process of the diffusion model.

Specifically, the diffusion model takes a noisy label and some useful conditional information (to be specified) as inputs, and learns to recover/generate the ground-truth labels as outputs. One challenge in this setting is that only noisy labels are available in practice for training. To overcome this issue, we adopt the principle of _neighbor consistency_, and propose _label-retrieval augmentation_ to construct pseudo clean labels for diffusion model training, where a pre-trained image encoder is used to define the neighborhood of a sample. It is worth noting that the pre-trained image encoder would not be affected by the label noise, because they can be trained in a self-supervised manner  or on an additional clean dataset . In fact, pre-training can tremendously improve the model's adversarial robustness  and has been used to improve model robustness to label corruption . Another merit of our design is that it is general enough to allow natural incorporation of powerful large pre-trained model such as the CLIP model to further boost the performance.

In addition, the probability nature of diffusion models can also be better equipped to handle uncertainty in the data and label, thus providing more robust and accurate predictions. We call our model LRA-diffusion (label-retrieval-augmented diffusion).

Our main contributions are summarized as follows:

* We formulate learning from noisy labels as modeling a stochastic process of conditional label generation, and propose to adopt the powerful diffusion model to learn the conditional label distribution.

Figure 1: Label denoising as a reverse noising process.

* We incorporate the neighbor consistency principle into the modeling, and design a novel label-retrieval-augmented diffusion model to learn effectively from noisy label data.
* We further improve our model by incorporating auxiliary conditional information from large pre-trained models such as CLIP.
* Our model achieves the new state-of-the-art (SOTA) in various real-world noisy label benchmarks, _e.g._, 20% accuracy improvement on noisy CIFAR-100 benchmark.

## 2 Preliminary

Diffusion models were initially designed for generative modeling. Recently, it has been extended for classification and regression problems. In this section, we introduce the Classification and Regression Diffusion Models (CARD) , which our model is based on.

The CARD model transforms deterministic classification into a conditional label generation process, allowing for more flexible uncertainty modeling in the labeling process . Similar to the standard diffusion model, CARD consists of a forward process and a reverse process. In the forward process, an \(n\)-dimensional one-hot label \(_{0}\) is gradually corrupted to a series of intermediate random vectors \(_{1:T}\), which converges to a random variable with a multi-variant Gaussian distribution \((f_{q}(),)\) (latent distribution) after \(T\) steps, where the mean is defined by a pre-trained \(n\)-dimensional image encoder \(f_{q}\). The transition steps between adjacent intermediate predictions is modeled as Gaussian distributions, \(q(_{t}|_{t-1},f_{q})=(_{t};_{ t},_{t})\), with mean values \(_{1},,_{T}\) and a variance schedule \(_{1},,_{T}\), where \(_{t}=_{t-1}}+(1-})f_{q}( )\). This admits a closed-form sampling distribution, \(q(_{t}|_{0},f_{q})=(_{t};_{ t},(1-_{t})\), with an arbitrary timestep \(t\) and \(_{t}=_{t}_{0}}+(1-_{t}}) f_{q}()\). The mean term can be viewed as an interpolation between true data \(_{0}\) and the mean of the latent distribution \(f_{q}()\) with a weighting term \(_{t}=_{t}(1-_{t})\).

In the reverse (generative) process, CARD reconstructs a label vector \(_{0}\) from an \(n\)-dimensional Gaussian noise \(y_{T}(f_{q}(),)\) by approximating the denoising transition steps conditioned on the data point \(\) and another pre-trained image encoder \(f_{p}\) in an arbitrary dimension. The transition step is also Gaussian for an infinitesimal variance \(_{t}\) (define \(_{t}=_{t-1}}{1-_{t}}_{t}\)):

\[p_{}(_{t-1}|_{t},,f_{p})=( _{t-1};_{}(_{t},,f_{p},t),_{t}).\] (1)

The diffusion model is learned by optimizing the evidence lower bound with stochastic gradient descent:

\[_{}=_{q}[_{T}+_{t>1}^{T} _{t-1}+_{0}],\] (2)

\[_{0}=- p_{}(_{0}|_{1}, ,f_{p}),\ \ _{t-1}=D_{}(q(_{t-1}|_{t}, _{0},,f_{q})||p_{}(_{t-1}|_{t}, ,f_{p}))\] \[_{T}=D_{}(q(_{T}|_{0 },,f_{q})||p(_{T}|,f_{p})).\]

Following , the mean term is written as \(_{}(_{t},,f_{p},t)= }}(_{t}-}{_{t}}}_{ }(_{t},,f_{p},t))\) and the objective can be simplified to \(_{}=\|-_{}( _{t},,f_{p},t)\|^{2}\).

## 3 Label-Retrieval-Augmented Diffusion Model

Inspired by CARD, Label-Retrieval-Augmented (LRA) diffusion models reframe learning from noisy labels as a stochastic process of conditional label generation (_i.e._, label diffusion) process. In this section, we first provide an overview of the our model in Section 3.1 and then introduce the proposed label-retrieval-augmented component in Section 3.2, which can leverage label consistency in the training data. Next, we introduce an accelerated label diffusion process to significantly reduce classification model inference time in Section 3.3. Finally, a new conditional mechanism is proposed to enable the usage of pre-trained models in Section 3.4.

### Model Overview

Our overall label-retrieval-augmented diffusion model is illustrated in Figure 2, where a diffusion model is adopted for progressively label denoising, by leveraging both the retrieved labels and auxiliary information from pre-trained models. Our model employs two pre-trained networks, denoted as \(f_{q}\) and \(f_{p}\) encoders, to encode conditional information that facilitates the generation process. The \(f_{q}\) encoder serves as a mean estimator for \(_{T}\), providing an initial label guess for a given image. This encoder could be a standard classifier trained on noisy labels. On the other hand, the \(f_{p}\) encoder operates as a high-dimensional feature extractor, assisting in guiding the reverse procedure. \(_{t}\) and \(f_{p}()\) are concatenated together before being processed. Details about our neural-network architecture design are provided in Supplementary C.

During training, we use labels retrieved from the neighborhood as the generation target \(_{0}\). Then, in the forward process, the distribution of neighboring labels is progressively corrupted towards a standard Gaussian distribution centered at the estimated mean \(f_{q}()\). During testing, we employ a generalized DDIM method to efficiently compute the maximum likelihood estimation of \(_{0}\).

### Label-retrieval Augmentation for Training

The noisy nature of labels excludes the availability of clean labels for training. To mitigate the issue, we propose a training strategy based on the concept of retrieval augmented learning [30; 31], such that it is more resistant to label noise. Our main assumption is that in a latent space, data points from different classes form distinctive clusters. Therefore, the majority of a data point's neighbors are expected to have the same label as the point itself. To this end, we used a pre-trained encoder, illustrated as \(f_{p}\) in Figure 2, to map the data into an embedding space and retrieve a label \(y^{}\) from labels of the \(k\) nearest neighbors \(\{y^{(1)},,y^{(k)}\}\) in the training set. The diffusion model was then trained to learn the conditional distribution \(p(y^{}|)\) of labels within the neighborhood, rather than the distribution of labels \(p(y|)\) for the data point itself. We empirically select the value of \(k\) based on the KNN accuracy obtained on the validation data, as detailed in Supplementary Section C.

Label-retrieval augmentation enables the model to make use of the information from multiple and potentially more accurate labels to improve its prediction performance. Algorithm 1 describes the training procedure. Additionally, diffusion models are known to be effective at modeling multimodal distributions. By training the model to generate different labels from neighbors based on the same data point, the model can produce stochastic predictions based on the distribution to capture the uncertainty inherent in the data labeling process. As a result, the trained model can be used not only as a classifier, but also as a sampler that simulates the actual labeling process.

### Efficient Inference with generalized DDIM

The iterative generation nature of the classification diffusion model makes its inference efficiency not comparable to traditional classifiers. To enhance the inference efficiency, we propose to incorporate the efficient sampling methods, Denoising Diffusion Implicit Model (DDIM) , to accelerate the

Figure 2: Overview of the proposed framework for improving learning performance from noisy labels. The figure depicts the three main components, including (1) using diffusion models to imitate and inverse the label noising process; (2) using pre-trained encoders (_i.e._, \(f_{q}\) and \(f_{p}\)) within the diffusion model, and (3) the label-retrieval-augmentation approach using the \(f_{p}\) encoder to encourage neighbor consistency of image labels.

label diffusion process. However, the utilization of the mean estimator \(f_{q}\) makes DDIM incompatible with our setting, as our generation process begins with a non-zero mean Gaussian distribution \((f_{q}(),)\). Therefore, we adjust the DDIM method into a more general form that fits our framework. Analogous to DDIM, our sampling process maintains the same marginal distribution as the original \(q(_{t}|_{0},f_{q})\) closed-form sampling process. Detailed derivations can be found in Supplementary A.

With DDIM, the trained model can generate a label vector in much less steps following a pre-defined sampling trajectory of \(\{T=_{S}>,,>_{1}=1\}\), where \(S<T\). Consequently, \(_{t}\) can be computed as:

\[_{_{s}}=_{_{s}}}_{0}+(1-_{_{s}}})f_{q}()+_{_{s}}} ,\] (3)

where \((,)\). Similar to CARD , we predict the _denoised label_\(}_{0}\), a prediction of \(_{0}\) given \(_{_{s}}\), as:

\[}_{0}=_{_{s}}}}[_{ _{s}}-(1-_{_{s}}})f_{q}()-_{_{s}}}_{}(_{_{s}}, ,f_{p}(),_{s})]\;.\] (4)

When \(_{s-1}>0\), we can compute \(_{_{s-1}}\) given \(_{_{s}}\) from the non-Markovian forward process defined as:

\[_{_{s-1}}=_{_{s-1}}}}_{0 }+(1-_{_{s-1}}})f_{q}()+_ {_{s-1}}}_{}(_{_{s}}, ,f_{p}(),_{s}).\] (5)

As the dimension of label vectors is usually much lower than that of an image, the model can employ fewer steps in the reverse process without compromising generative quality. In our experiments, we use \(S=10\) and \(T=1000\), substantially reducing the time cost of the classification process. Supplementary Figure B gives an example of the label generation (classification) process on the CIFAR-10 dataset.

To further enhance the inference efficiency, we propose a simple and effective trick for computing the maximum likelihood estimation of labels. As the generative process is deterministic given \(_{T}\), which is sampled from a uni-modal Gaussian distribution, we approximate the maximum likelihood estimation of labels by initiating from the mean, _i.e._, \(_{0}=(_{T}=f_{q}(),)\). This trick circumvents the time-consuming majority voting approximation that demands repeated generation.

### Flexible conditioning with pre-trained encoders

The original CARD model employs a single model for both the \(f_{p}\) and \(f_{q}\) encoders. However, this limits their representation capacity  as the dimension of \(f_{q}()\) is typical relatively small, _i.e._, equalling the number of classes. To mitigate this and improve model performance, we abandon the assumption that \(f_{p}=f_{q}\), enabling the use of a more powerful pre-trained encoder (_e.g._, the CLIP image encoder ) with arbitrary dimensions for \(f_{p}\).

Empirically, we find that the model can still achieve satisfactory performance when the magnitude of \(f_{q}()\) is small, which means the latent representation \(_{T}=f_{q}()+\) is dominated by the noise term \((,)\). In this case, the information provided by \(f_{q}()\) to the diffusion process is limited. As a result, we simply set \(f_{q}()=\) to avoid handling an additional n-dimensional \(f_{q}\) encoder. For the \(f_{p}\) encoder, one can employ flexible pre-trained models as presented in Section 5. In this paper, we use the SimCLR model trained on the training images (without supervised information) and the pre-trained CLIP model.

Related work

Robust loss function and regularization techniques.Several noise-robust loss functions and regularization techniques have been proposed as alternatives to the commonly used cross-entropy loss (CE), which is not robust to label noise. Mean absolute error (MAE)  loss has been shown to be robust against noisy labels. Generalized Cross-Entropy (GCE)  combines CE and MAE for faster convergence and better accuracy. Symmetric cross-entropy Learning (SL)  couples CE with a noise-robust counterpart and has been found to have higher performance than GCE, particularly for high noise rates. Label Smoothing Regularization  alleviates overfitting by linearly combining labels with a uniform distribution. Bootstrapping technique  combines the labels with the current model prediction. Dynamic bootstrapping [39; 40] uses the prediction confidence to control the weighting in the combination. Neighbor Consistency Regularization (NCR)  encourages consistency of prediction based on learned similarity. Our method is also based on the principle of neighbor consistency. However, instead of encouraging consistent predictions among neighbors, our model directly learns from the labels of neighbors. This allows for estimating instance-level uncertainty by learning the label distribution among neighbors, rather than learning a point estimation.

Data recalibration.Data recalibration techniques progressively remove or correct mislabeled data during training to improve the reliability of training data. Wang et al.  used the learned similarity and label consistency to identify and discard data with noisy labels. TopoFilter  selects clean data by analyzing the topological structures of the training data in the learned feature space. Cheng et al.  defines a Bayes optimal classifier to correct labels. Zheng et al.  proposed using a likelihood ratio test (LRT) to correct training labels based on predictions. Zhang et al.  used LRT to correct labels progressively and provides a theoretical proof for convergence to the Bayes optimal classifier. Dividemix , LongReMix , and CC  treat the low confident data as unlabeled, and then employ semi-supervised learning algorithms  for further analysis. C2D  combines Dividemix with self-supervised pre-training to boost its performance by improving the quality of the extracted features. Our approach employs the same assumption as TopoFilter that data belonging to the same class should be clustered together with ideal feature representations. However, our technique isn't confined to learned features potentially distorted by label noises. Instead, similar to C2D, our method can effectively leverage the high-quality feature learned by pre-trained encoders to achieve superior accuracy.

Guided diffusion model and retrieval augmentation.Guided diffusion is a technique applied to diffusion models for conditional generation. Classifier guidance  is an cost-effective method leveraging the gradient of a classifier to steer the generative process of a trained diffusion model. On the other hand, Classifier-free guidance  learns the conditional distribution during training for improved generation quality. This approach also allows for the use of continuous guidance information, such as embedding vectors, rather than being limited to discrete labels. Classification and Regression Diffusion Models (CARD)  formulates classification and regression as a conditional generation task that generates labels or target variables conditioned on images. Our approach follows the same paradigm, and leverages the multi-modal coverage ability of diffusion models to learn the label distribution within the neighborhood. SS-DDPM  proposes a diffusion model with arbitrary noising distributions defined on constrained manifold, e.g., the probabilistic simplex for label generation. Retrieval-augmented diffusion models  used retrieved neighbors from an external database as conditional information to train diffusion models for image synthesis. Retrieval Augmented Classification  used retrieval-augmentation to train classification model using class-imbalanced training data. Our approach differs from theirs by retrieving labels instead of data to reduce label noise in training rather than increasing the training data. In addition, our model does not require an external database.

## 5 Experiments

We first evaluate the performance of our method on datasets with various types synthetic noises. Then, we perform experiments on four real-world datasets. To better understand the performance gain sources, we conduct ablation studies to measure the impacts of conditional diffusion and different pseudo-label construction strategies. All experiments were done on four NVIDIA Titan V GPUs. Comprehensive implementation details and hyper-parameters are provided in the Supplementary C.

### Results on Synthetic Noisy Datasets

We conduct simulation experiments on the CIFAR-10 and CIFAR-100 datasets  to evaluate our method's performance under various noise types. Specifically, following , we test with _polynomial margin diminishing_ (PMD) noise, a novel instance-dependent noise, at two noise levels and three hybrid noise types by adding _independent and identically distributed (i.i.d)_ noises on top of instance-dependent noise.

For instance-dependent noise, we adopt the recently proposed _polynomial margin diminishing_ (PMD) noise . Following the original paper, we train a classifier \((x)\) using clean labels to approximate the probability mass function of the posterior distribution \(p(y|)\). Images are initially labeled as their most likely class \(u_{}\) according to the predictions of \((x)\). Then, we randomly alter the labels to the second most likely class \(s_{}\) for each image with probability: \(p_{u_{},s_{}}=-[_{u_{}} ()-_{s_{}}()]^{2}+\), where \(c\) is a constant noise factor that controls the final percentage of noisy labels. Since corrupting labels to the second most likely class can confuse the "clean" classifier the most, it is expected to have the most negative impact on the performance of models learned with noisy labels. For PMD noise, we simulate two noise levels where \(35\%\) and \(70\%\) of the labels are corrupted.

For i.i.d noise, following , we use a transition probability matrix \(\) to generate noisy labels. Specifically, we corrupt the label of the \(i\)-th class to the \(j\)-th class with probability \(T_{ij}\). We adopt two types of i.i.d noise in this study: (1) Uniform noise, where samples are incorrectly labeled as one of the other \((n-1)\) classes with a uniform probability \(T_{ij}=/(n-1)\) and \(T_{ii}=1-\), with \(\) the pre-defined noise level; (2) Asymmetric noise: we carefully design the transition probability matrix such that for each class \(i\), the label can only be mislabeled as one specific class \(j\) or remain unchanged with probability \(T_{ij}=\) and \(T_{ii}=1-\). In our experiment, we generated three types of hybrid noise by adding 30%, 60% uniform, and 30% asymmetric noise on top of 35% PMD noise.

We test our proposed label-retrieval-augmented diffusion model using two pre-trained encoders: (1) SimCLR : We trained two encoders using the ResNet50  architecture on the CIFAR-10 and CIFAR-100 datasets through contrastive learning; (2) CLIP : the model is pre-trained on a large dataset comprising 400 million image-text pairs. Specifically, we used the vision transformer  encoder (ViT-L/14) with pre-trained weights, the best-performing architecture in CLIP. For

   \\   & 35\% PMD & 70\% PMD & 35\% PMD + 30\% U & 35\% PMD + 60\% U & 35\% PMD + 30\% A \\  Standard & 78.11 \(\) 0.74 & 41.98 \(\) 1.96 & 75.26 \(\) 0.32 & 64.25 \(\) 0.78 & 75.21 \(\) 0.64 \\ Co-teaching+  & 79.97 \(\) 0.15 & 40.69 \(\) 1.99 & 78.72 \(\) 0.53 & 55.49 \(\) 2.11 & 75.43 \(\) 2.96 \\ GCE  & 80.65 \(\) 0.39 & 36.52 \(\) 1.62 & 78.08 \(\) 0.66 & 67.43 \(\) 1.43 & 76.91 \(\) 0.56 \\ SL  & 79.76 \(\) 0.72 & 36.29 \(\) 0.66 & 77.79 \(\) 0.46 & 67.63 \(\) 1.36 & 77.14 \(\) 0.70 \\ LRT  & 80.98 \(\) 0.80 & 41.52 \(\) 4.53 & 75.97 \(\) 0.27 & 59.22 \(\) 0.74 & 76.96 \(\) 0.45 \\ CC  & 81.23 \(\) 0.78 & 42.43 \(\) 1.56 & 79.6 \(\) 0.44 & 70.71 \(\) 0.34 & 78.66 \(\) 0.66 \\ PLC  & 82.80 \(\) 0.27 & 42.74 \(\) 2.14 & 79.04 \(\) 0.50 & 72.21 \(\) 2.92 & 78.31 \(\) 0.41 \\  SimCLR KNN & 83.71 & 29.45 & 78.25 & 54.82 & 75.37 \\ C2D + SimCLR  & 83.84 \(\) 0.13 & 34.23 \(\) 0.45 & 85.61 \(\) 0.29 & 81.39 \(\) 0.68 & 83.06 \(\) 0.57 \\ LRA-diffusion (SimCLR) & 88.76 \(\) 0.24 & 42.63 \(\) 1.97 & 88.41 \(\) 0.37 & 84.43 \(\) 0.82 & 85.64 \(\) 0.23 \\  CLIP KNN & 91.80 & 30.66 & 84.67 & 57.03 & 81.76 \\ LRA-diffusion (CLIP) & 96.54 \(\) 0.13 & 44.62 \(\) 0.18 & 95.71 \(\) 0.17 & 87.21 \(\) 0.71 & 93.65 \(\) 0.40 \\   \\   & 35\% PMD & 70\% PMD & 35\% PMD + 30\% U & 35\% PMD + 60\% U & 35\% PMD + 30\% A \\  Standard & 57.68 \(\) 0.29 & 39.32 \(\) 0.43 & 48.86 \(\) 0.56 & 35.97 \(\) 1.12 & 45.85 \(\) 0.93 \\ Co-teaching+ & 56.70 \(\) 0.71 & 39.53 \(\) 0.28 & 52.33 \(\) 0.64 & 27.17 \(\) 1.66 & 51.21 \(\) 0.31 \\ GCE & 58.37 \(\) 0.18 & 40.01 \(\) 0.71 & 52.90 \(\) 0.53 & 38.62 \(\) 1.65 & 52.69 \(\) 1.14 \\ SL & 55.20 \(\) 0.33 & 40.02 \(\) 0.85 & 51.34 \(\) 0.64 & 37.57 \(\) 0.43 & 50.18 \(\) 0.97 \\ LRT & 56.74 \(\) 0.34 & 45.29 \(\) 0.43 & 45.66 \(\) 1.60 & 23.37 \(\) 0.72 & 52.04 \(\) 0.15 \\ CC & 59.44 \(\) 0.33 & 42.79 \(\) 1.21 & 56.58 \(\) 0.45 & 43.64 \(\) 1.71 & 54.45 \(\) 1.22 \\ PLC & 60.01 \(simplification, we refer to these configurations as LRA-diffusion (SimCLR) and LRA-diffusion (CLIP). We also investigated the performance of the KNN algorithm within the feature space defined by the SimCLR and CLIP encoders, denoted as SimCLR KNN and CLIP KNN respectively.

Table 1 lists the performance of the _Standard_ method (train classifier using noisy labels), our method, and baseline methods for learning from noisy labels. The results in white rows are borrowed directly from . We can see that using the SimCLR encoder in the LRA-diffusion method results in superior test accuracy on both CIFAR-10 and CIFAR-100 datasets compared to other baselines, without the need for additional training data. This is because the SimCLR encoder is trained in an unsupervised manner, making it immune to label noise, and it can effectively extract categorical features for accurate image retrieval. Therefore, when the correct labels dominate the label distribution in the neighborhood, training with the labels of the retrieved neighbor images allows the model to learn with more correct labels. C2D  also utilizes a pre-trained SimCLR encoder for initialization, but label noise may still affect the feature space during training. In contrast, our method freezes the feature encoder, shielding the pre-trained features from noise. Results on CIFAR-10 demonstrate that when the pre-trained feature has high KNN accuracy, our method performs better. On CIFAR-100, where the SimCLR feature has lower KNN accuracy, C2D is more effective, as it can refine the feature space through training. Moreover, freezing the feature encoder allows for efficient integration of large pre-trained encoders like CLIP, saving us from the prohibitive computational cost of fine-tuning. Notably, incorporating the CLIP encoder into our method significantly improves test accuracy over our LRA-diffusion (SimCLR) due to its excellent representation capabilities. In fact, by performing KNN in the CLIP feature space alone was able to achieve accuracy surpassing all competing methods in most experiments. This allows for the use of more clean labels during training, thus result in even higher accuracy.

### Ablation Studies

To evaluate the contribution of diffusion and the pre-trained features, we conducted ablation experiments using CARD , SS-DDPM , and linear probing to incorporate pre-trained models. It is worth noting that the SimCLR model was trained on the same training set without access to external data. Results are given in Table 2.

Linear probing with sampled labels yielded lower accuracy than using noisy labels or the mean of neighboring labels. This difference may be due to the linear layer's inability to yield stochastic outputs from a multimodal distribution. During training, conflicting gradient directions may arise if the model tries to predict different labels across gradient steps, which can impede learning. However, due to the mode coverage ability of the diffusion model, our method can effectively learn from retrieval-augmented labels to generate different labels with different probabilities. We also test a baseline using an additional ResNet encoder along with the linear layer to mimic our model architecture shown in Figure C.1. The results are comparable with linear probing with sampled labels. Our model

   &  &  &  &  \\  & & & 35\% &  & 70\% &  & 35\% &  & 70\% &  & 70\% &  & \\  Linear probing & SimCLR & noisy & 86.9 & 38.93 & 56.18 & 51.87 &  & & \\ Linear probing & SimCLR & sample & 63.8 & 35.84 & 53.34 & 52 &  & \\ Linear probing & SimCLR & mean & 86.27 & 39.94 & 55.95 & 52.61 &  & & \\ ResNet+Linear & SimCLR & sample & 86.55 & 38.06 & 56.57 & 51.36 &  & & \\ CARD & SimCLR & sample & 75.08 & 34.35 & 52.03 & 32.67 &  & & \\ SS-DDPM (Dirichlet) & SimCLR & sample & 88.13 & 40.11 & 59.3 & 51.67 &  & & \\ LRA-diffusion (ours) & SimCLR & sample & **88.96** & **42.63** & **61.38** & **53.57** &  & \\  Linear probing & CLIP & noisy & 85.35 & 37.4 & 65.02 & 53.21 &  & & \\ Linear probing & CLIP & sample & 95.61 & 40.17 & 63.98 & 58.53 &  & & \\ Linear probing & CLIP & mean & 96.19 & 35.19 & 69.05 & 62.76 &  & & \\ ResNet+Linear & CLIP & sample & 88.72 & 43.26 & 59.78 & 51.47 &  & & \\ CARD & CLIP & sample & 79.72 & 33.57 & 47.1 &  & & & \\ SS-DDPM (Dirichlet) & CLIP & sample & 96.03 & 42.03 & 80.72 &  & & & \\ LRA-diffusion (ours) & CLIP & sample & **96.55** & **44.51** & **81.92** & **74.58** &  & \\  

Table 2: Classification accuracy (%) on CIFAR-10 and CIFAR-100 datasets with PMD noises using different combinations of model, pre-trained feature, and label.

significantly outperforms CARD, mainly due to the more informative \(f_{p}\) encoder. We use the same model architecture for SS-DDPM, which uses Dirichlet distributions for noisy states. SS-DDPM performed slightly worse than our method, indicating that constraining noisy states within probability simplex may not benefit our task.

Additional ablation studies are included in the Supplementary D. The results demonstrate that in the absence of a pre-trained encoder, our model can leverage the features of a noisy classifier to enhance its accuracy. We also include results of ablation experiments using different approaches for incorporating the CLIP model. The results indicate that the superior performance of our method is not solely attributable to the strength of the CLIP features. In conclusion, our LRA-diffusion model provides an efficient approach for incorporating pre-trained encoders for learning from noisy labels.

### Results on Real-world Noisy Datasets

We further evaluate the performance of our proposed method on real-world label noise. Following previous work , we conducted experiments on four image datasets, _i.e._, WebVision , ImageNet ILSVRC12 , Food-101N , and Clothing1M . For experiments on Webvision, ILSVRC12, and Food-101N datasets, we use the CLIP image encoder as the \(f_{p}\) encoder to train LRA-diffusion models. Comprehensive dataset description and implementation details can be found in the Supplementary C. We evaluated the performance of our method against a group of state-of-the-art (SOTA) methods. The results are presented in Table 3 and Table 4. Our approach significantly outperforms all the previous methods in terms of classification accuracy. It is important to highlight that EPL  incorporates the most powerful CLIP and ConvNext-XL  encoders and cooperates with other SOTA methods such as ELR , DivideMix , and UNICON . However, our method outperforms EPL by achieving \(\)6% higher accuracy on WebVision and ILSVRC12 datasets. This improvement over EPL demonstrates that developing better ways to incorporate pre-trained models to facilitate learning from noisy labels is a non-trivial task, highlighting the valuable contribution of our approach.

For experiments on the Clothing1M dataset, we found that LRA-diffusion conditioned on the CLIP image encoder did not achieve the SOTA accuracy. A potential explanation is that the CLIP feature is too general for this domain specific task for categorizing fashion styles. However, our method is orthogonal to most traditional learning with noisy label approaches. As shown in the additional ablation study in Supplementary D.1, our method can collaborate with a trained classifier by conditioning on its feature encoder to achieve improved performance. We first use the CC  method to select clean samples and train a ResNet50 classifier, which achieved \(75.32\%\) accuracy (refer to as CC\({}^{*}\)). Then, we condition on its feature before the classification head to train our LRA-diffusion model on the selected samples, which achieved \(75.70\%\) accuracy. As Table 5 shows, our method achieved a 0.38% improvement based on CC\({}^{*}\) and beat all SOTA methods.

  Standard & CleanNet  & BARE  & DeepSelf  & PLC & LongReMix & LRA-diffusion \\ 
81.67 & 83.95 & 84.12 & 85.10 & 85.28 & 87.39 & **93.42** \\  

Table 4: Classification accuracies (%) on the Food-101N dataset.

 
**Dataset** & DivideMix & ELR & UNICON & EPL & LongReMix & C2D & CC & NCR & LRA-diffusion \\ 
**WebVision** & 77.32 & 77.78 & 77.60 & 78.77 & 78.92 & 79.42 & 79.36 & 80.5 & **84.16** \\
**ILSVRC2012** & 75.20 & 70.29 & 75.29 & 76.51 & - & 78.57 & 76.08 & - & **82.56** \\  

Table 3: Classification accuracies (%) on WebVision, ILSVRC2012 datasets.

  Standard & BARE & PLC & LongReMix & DeepSelf & C2D & NCR & CleanNet \\ 
68.94 & 72.28 & 74.02 & 74.38 & 74.45 & 74.58 & 74.60 & 74.69 \\   DivideMix & ELR & UNICON & EPL & CC\({}^{*}\) & CC & SANM  & LRA-diffusion \\ 
74.76 & 74.81 & 74.98 & 75.21 & 75.32 & 75.40 & 75.63 & **75.70** \\  

Table 5: Classification accuracies (%) on Clothing1M

### Inference Efficiency Analysis

In order to test the efficiency of our model, we perform experiments assessing the runtime on CIFAR-10 dataset and compare our method with a standard classifier that uses ResNet50. It's worth noting that our SimCLR encoder is also built on the ResNet50. Thus, the standard method's runtime also reflects the linear probing runtime on SimCLR. Table 6 shows the results.

We can see, the computation bottleneck lies on the large pre-trained encoder but not the diffusion model itself. In general, our method takes twice as long as a standard classifier (ResNet50) when using SimCLR (ResNet50) and CLIP (ViT-B/32) pre-trained encoders. Larger CLIP encoders can increase the time further. However, it can be further accelerated if the features can be pre-computed in advance or be computed in parallel (as they are only required to be computed once and can be reused later).

## 6 Limitations

Our method, while being effective in many scenarios, does have certain limitations that we acknowledge. Its performance enhancement can be compromised if a pre-trained \(f_{p}\) feature encoder isn't available or is inadequately trained. Additionally, the diffusion model introduces Gaussian noise in the forward process, leading to latent label vectors not being confined within the probability simplex, which could increase training time. Lastly, our method's performance becomes less effective when label noise levels surpass 50%. However, supervised learning can not be the optimal choice in such situations.

## 7 Conclusion

In this paper, by viewing the noisy labeling process as a conditional generative process, we leverage diffusion models to denoise the labels and accurately capture label uncertainty. A label-retrieval-augmented diffusion model was proposed to effectively learn from noisy label data by incorporating the principle of neighbor consistency. Additionally, by incorporating auxiliary conditional information from large pre-trained models such as CLIP, we are able to significantly boost the model performance. The proposed model is tested on several benchmark datasets, including CIFAR-10, CIFAR-100, Food-101N, and Clothing1M, achieving state-of-the-art results in most experiments. Future work could extend our model to multi-label settings, as it does not require a one-hot representation for labels. It is also promising to use semantic segmentation to guide the generation, potentially enhancing our model's interpretability and performance.

Acknowledgement:This work is partially supported by NSF AI Institute-2229873, NSF RIO-2223292, an Amazon research award, and an Adobe gift fund. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation, the Institute of Education Sciences, or the U.S. Department of Education.