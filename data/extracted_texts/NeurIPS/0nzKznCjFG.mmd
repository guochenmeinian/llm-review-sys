# Private and Personalized Frequency Estimation

in a Federated Setting

 Amrith Setlur

Carnegie Mellon University

asetlur@cs.cmu.edu

&Vitaly Feldman

Apple

vitaly.edu@gmail.com

&Kunal Talwar

Apple

ktalwar@apple.com

Part of the work was done during an internship at Apple.

###### Abstract

Motivated by the problem of next word prediction on user devices we introduce and study the problem of _personalized frequency histogram_ estimation in a federated setting. In this problem, over some domain, each user observes a number of samples from a distribution which is specific to that user. The goal is to compute for all users a personalized estimate of the user's distribution with error measured in KL divergence. We focus on addressing two central challenges: _statistical heterogeneity_ and _protection of user privacy_. Our approach to the problem relies on discovering and exploiting similar subpopulations of users which are often present and latent in real-world data, while minimizing user privacy leakage at the same time. We first present a non-private clustering-based algorithm for the problem, and give a provably joint differentially private version of it with a private data-dependent initialization scheme. Next, we propose a simple data model which is based on a mixture of Dirichlet distributions, to formally motivate our non-private algorithm and demonstrate some properties of its components. Finally, we provide an extensive empirical evaluation of our private and non-private algorithms under varying levels of statistical and size heterogeneity on the Reddit, StackOverflow, and Amazon Reviews datasets. Our results demonstrate significant improvements over standard and clustering-based baselines, and in particular, they show that it is possible to improve over direct personalization of a single global model.

## 1 Introduction

Federated learning algorithms jointly learn from decentralized user data, addressing statistical challenges in local learning . At the same time it presents two key challenges, among few others . Firstly, data distributions can vary across users (often called statistical heterogeneity ), which reduces the effectiveness of a single, shared model for all users. Secondly, the data may be sensitive and mutually beneficial collaboration may compromise user privacy . An important practical problem where user data distributions are diverse, and user-privacy is paramount is next-word prediction for the keyboard input on user devices. Users often have diverse vocabulary, writing styles, and topics that leads to varied data distributions . Naturally, frequency estimation is also one of the most basic statistical tasks with numerous other applications .

Motivated by personalized next-word prediction, **we introduce and study the problem of personalized frequency estimation in a federated setting**. In this problem, each user has very few (\(O(d)\)) samples from an unknown, user-specific distribution over a large, finite domain of size \(d\). The users interact with a server that needs to provide the user with a personalized estimate of their distribution. We focus on error measured in KL divergence that is common in language modeling , and is equivalent to minimizing the negative log-likelihood of samples from the user distribution. For more general loss minimization problems, numerous personalized federated learning(PFL) algorithms [67; 76], tackle statistical heterogeneity by first learning a single global model across all users (for _e.g._, FedAvg ), and then finetuning (FT) the global model locally for each user (FedAvg+FT [18; 20]), thus balancing collaboration and personalization. The downside of this approach is that it is agnostic to the structure of the user population which is highly heterogeneous, but often consists of a number of concentrated subpopulations of similar users.

**Statistical heterogeneity:** We study the personalized frequency estimation problem under an intuitive model of the user-population which consists of well-concentrated clusters of users where users in the same cluster have "similar" token distributions. For this, we propose an iterative algorithm that adapts Lloyd's clustering  to distribution estimation in KL divergence. Relying on the optimal competitive estimation rates for _local_ Good-Turing estimators, we propose to estimate _global_ cluster centers by averaging user-level Good-Turing estimates for the current users in the cluster. Furthermore, since the performance of clustering is significantly affected by the initialization  of cluster centers, we also propose a data-dependent initialization approach, also specific to estimation in KL. We improve the practicality of our algorithm by separately handling data-poor users in cases where users vary significantly in their local data sizes (size-heteogeneity).

**Privacy:** To address the challenge of user-level privacy we give a joint differentially private (DP) version of our iterative algorithm which requires that the estimator for user \(i\) is differentially private with respect to the data of all the other users (but may depend arbitrarility on user \(i\)'s data) . This definition is necessary due to the final personalization step which happens locally on user device and thus does not present a privacy risk. Specifically, we make each iteration of our clustering algorithm provably private by relying on adaptive clipping, secure aggregation, and common noise addition mechanisms . Initialization of clustering algorithms typically uses data points themselves as initial centers and hence presents a significant challenge for privacy preserving analysis. Our provably private data-dependent initialization algorithm for cluster centers runs the exponential mechanism over candidates randomly sampled around the estimated population mean.

**Empirical evaluation:** We validate both non-private and private versions of our algorithm on the real world data datasets: Reddit , StackOverflow , and Amazon Reviews , where Reddit has a token vocabulary of size 10k and the others have 32k tokens. We find that our method furnishes significant gains over standard and clustering baselines, reducing the error by over \(26\%\) and \(42\%\) (averaged over datasets) in the non-private and private settings respectively. In the private, size-heterogeneous setting, we improve over the clustering baseline IFCA  by over \(30\%\). Finally, we show that our data model inspired adjustments are pivotal in yielding the performance improvements in practice. Particularly, we justify the use of our Good-turing based estimator, and our private initialization scheme with a favorable privacy/utility tradeoff.

**Formal guarantees.** While our focus is on the empirical performance, to guide intuition and design of algorithms, we introduce a relatively simple generative model where user distributions are sampled from a mixture of Dirichlets, where Dirichlets are sufficiently separated globally and concentrated locally. We derive and analyze different estimators (_e.g._, Bayes optimal, FedAvg , Good-Turing ). Even when the cluster identities are known, we show that FedAvg (average of user empirical distributions) has poor guarantees compared to our proposed estimator (average of user Good-Turing estimates), where the minimax error rates for the latter do not scale with dimension, and is optimal for some regimes of problem parameters. Thus, using this model we demonstrate how additional structure in the user data can be exploited in the context of our more concrete frequency estimation problem while preserving the privacy of user data.

## 2 Problem definition

We use \(P\) to denote a distribution, \(P[v]\) for the probability of event \(v\), \(\) for an estimate of \(P\) (but \(\) if the estimate is computed without user collaboration), \(\) for sets. \(\) for matrices (\(_{.,i}/_{i.:}\) index into the \(i^{}\) column/row respectively), and \(\{P_{i}\}\) for a collection of elements \(P_{i}\) indexed by \(i\).

**Setup.** Let \(\) be a finite vocabulary (set) of tokens, with vocabulary size \(d=:||\), and \(()\) is the set of all probability distributions over \(\). In a federated setup we have a collection of users \(\), and each user \(u\) has an unknown distribution \(Q_{u}()\) over the tokens. The data available to each user \(u\) is a dataset \(_{u}\) comprising of \(m_{u}\) i.i.d. samples from \(Q_{u}\). We will use \(_{u}\) to refer to the empirical distribution estimated from \(_{u}\). The combined collection of datasets is referred to as meta-dataset \(=:\{_{u}\}\), and similarly \(}=:\{_{u}\}_{u}\) is the collection of all empirical distributions.

Unless specified otherwise, we assume that we are in the _size-homogeneous_ setting where all users have a dataset of the same size \(m=m_{u}\). We refer to the more general case as _size-heterogeneous_.

**Goal.** Given the meta-dataset \(\), the goal is to compute estimates \(\{_{u}\}_{u}\) such that:

1. _utility_: \(_{u}[(Q_{u}\|_{u})]\) is minimized, where the expectation is taken over sampling of meta-dataset \(\) and any randomness in computing \(\{_{u}\}_{u}\).
2. _privacy_: \(_{u}\) is computed privately with respect to all users except \(u\), _i.e._ the estimate is _joint differentially private_ (see Definition 2.2).

**Definition 2.1** (\(u\)-neighboring meta-datasets).: Meta-datasets \(\) and \(^{}\) are \(u\)-neighbors, _i.e._, \(_{u}^{}\) if they differ only in inclusion or deletion of user \(u\)'s private data. For any algorithm \(\), we denote \(_{-u}\) as the output of the algorithm to all other users except \(u\).

**Definition 2.2** (Joint Differential Privacy ).: Given \( 0\), \((0,1]\), and neighbouring relation \(_{u}\), a randomized mechanism \(:\) from the set of meta-datasets \(\) to an output space \(\) is \((,)\)-joint differentially private if for all \(u\)-neighboring \(_{u}^{}\), and all events \(E\),

\[[_{-u}() E] e^{}[_{-u}(^{}) E]+,\] (1)

where probabilities are taken over the randomness of \(\). We say that \(\) is \(-\)_zero-concentrated joint DP_ (\(\)-cJDP) if for all \(u\)-neighboring meta-datasets \(_{u}^{}\):

\[D_{}(_{-u}()\|_{-u}(^{ })),\] (2)

where \(D_{}(_{-u}()\|_{-u}(^{ }))\) is the \(\)-Renyi Divergence between the outputs of all users except \(u\).

## 3 Private algorithm for learning personalized histograms

In this section, we present our algorithm for learning private and personalized histograms in both size-homogeneous and size-heterogeneous settings. Without assumptions on the distribution of users, in the worst case, the best estimator would simply estimate each user's histogram locally, _i.e._, estimate each user's \(Q_{u}\) using their local dataset \(_{u}\). Avoiding such worst-cases, we assume that the real-world problem is more structured. Specifically, we assume that each user distribution \(Q_{u}\) is well clustered around \(K\) unknown cluster centers in the population of users. Note, we assume no knowledge of the cluster centers or number of clusters \(K\). In Section 5, we empirically validate the presence of clusters in real-world datasets by evaluating the performance of our clustering based algorithm on the same datasets, and in Section 4 we theoretically analyze some of the algorithmic design choices we make, in a stylized Bayesian setting that simulates a user-distribution with clusters.

As a warmup, we first discuss our local finetuning algorithm, where the setup is simpler. Say an algorithm runs a private collaborative protocol, and hands a distribution \(P\) to user \(u\), with the guarantee that \((Q_{u}\|P)\) is "reasonably" small, then how should the user \(u\) finetune \(P\) using the local dataset \(_{u}\) available to them? For this question, we now present our local finetuning algorithm.

### User-level local finetuning

Let \(P\) be the distribution over tokens returned by a collaborative algorithm that uses datasets across all users to estimate a single distribution for either all users in the population, or all users in a specific cluster. In the next section, we discuss how to estimate \(P\). Here, we discuss how to personalize \(P\) for each user. For a user \(u\), with empirical distribution \(_{u}\) from \(m_{u}\) samples, we use \((P,_{u})\) to denote the personalized, locally finetuned estimate of user distribution \(Q_{u}\) (see Eq. 3). Note that \(P\) is moved closer to \(_{u}\) in KL divergence (depending on choice of \(>0\)). When the population of users is well concentrated, \(\) lowers variance by relying more on the global estimate \(P\), while adding some bias (\(_{u}\) is an unbiased estimate of \(Q_{u}\), but \(P\) is biased). In Section 4, we show that \(\) is the Bayes optimal estimator in KL divergence, under certain assumptions on the user distribution.

\[(P,_{u})=:} P+} {+m_{u}}_{u}\] (3)

Next, we discuss how to collaboratively estimate \(P\). For a user-distribution with multiple clusters, a natural approach is to first identify the groups of clustered users. Then, we can use the distribution that is close in KL distance, and in expectation over the distribution of users in the cluster. We refer to these as the cluster centers. In the next Section, we present our algorithm to learn cluster centers, which we personalize for each user in the cluster using our local finetuning update (Equation 3).

### Learning clusters in the population of size-homogeneous users

As mentioned in the start of Section 3, we base our approach on the belief that the user-population comprises of unknown clusters. Thus, given the collection of size-homogeneous users \(\), the goal is to learn a user partition \(\{_{u}\}_{u}\), and the matrix of \(K\) cluster centers \(}^{d K}\). To learn cluster centers \(}\), akin to the popular clustering algorithms like Lloyds , the objective we optimize is:

\[_{\{_{c}\}_{c[K]}}\ _{u}\ _{c[K]}\ \ (Q_{u}\|_{c}),\] (4)

with the main difference being that we are concerned with the KL distance, instead of \(_{2}^{2}\). Given \(}\), user \(u\)'s assigned cluster \(_{u}\) is simply given by \(*{arg\,min}_{k}(Q_{u}\|_{:,k})\). Conversely, applying Lemma 3.1, given cluster memberships the cluster center is determined by the cluster average.

**Lemma 3.1**.: _For users with assigned cluster \(i\), i.e., \(}_{i}=:\{u:_{u}=i\}\), the following is true:_

\[_{i}|}_{u_{i}}Q_{u}\ *{arg\,min}_{P()}_{u }_{i}}(Q_{u}\|P).\]

Since, we do not have access to \(Q_{u}\), we replace \(Q_{u}\) in Lemma 3.1 and the cluster assignment step with the local Good-Turing  estimate \(_{u}^{}\). Typically, one would use the empirical distribution \(_{u}\), which is an unbiased estimate of \(Q_{u}\). But, as we will see in Section 5, most real-world distributions are long-tailed and the Good-Turing estimate's approximation of the user distribution does not suffer as heavily from the high-dimensional nature of the problem. We discuss the Good-Turing estimate and analyze its error more formally in Section 4. This simplification means that the cluster center estimator averages the local Good-Turing estimates from each user in the cluster. In theory, we can also estimate the cluster center \(P\) in a better way, _e.g._, by directly running the Good-Turing correction on the cluster level token counts. This is a possible direction of improvement in future works.

To iteratively optimize the objective in Equation 4, we present our algorithm \(\) (see Alg. 3). We start with initial center estimates \(}^{(0)}\), and run \(T\) iterations to refine them. In each iteration we peform two steps: (i) _collect_ user outputs for each user via \(\) (see Alg. 1); and (ii) _re-center_ clusters using an algorithm, which for now is the \(\) (see Alg. 2). Later, we see how we need only update the re-centering algorithm to satisfy user-level privacy contraints. From Lemma 3.1 and Alg. 1, it is not hard to see that \(\) which computes the mean of the local estimates of users in a cluster, greedily reduces the objective value in Eq. 4 after each iteration. When the misclustering rate is sufficiently low to begin with, averaging local Good-Turing estimates brings the estimated center closer (in KL divergence) to the true centers that minimize Eq. 4, thereby reducing the number of iterations for convergence.

An extension of the convergence analysis in Balakrishnan et al. , gives us an upper bound on the misclustering error of Alg. 3 which goes down exponentially with each iteration of clustering (Theorem 3.2). Similar to most clustering analyses , we make suitable conditions on the initialization of cluster centers \(}^{(0)}\) and the separation of true clusters in the user population.

```
0: Set of users \(\), initial centers \(}^{(0)}\), iterations \(T\).
0: Estimates of cluster memberships \(\{_{u}\}_{u}\) and centers \(}\).
1: Initialize \(t 1\).
2:while\(t T\)do
3:for\(j=1\) to \(K\)do
4: Collect: \(_{k}^{(t)}\{(}^{(t-1)},k,u)\}_{u}\)
5: Re-center: \(}_{:,j}^{(t)}()( _{k}^{(t)})\)
6:endfor
7:\(t t+1\)
8:endwhile
9: Return: \(\{_{u}^{(T)}\}_{u},\ }^{(T)}\). ```

**Algorithm 3** HistogramCluster

**Theorem 3.2** (Alg. 3 convergence).: _For the model in Section 4, if \( c,v\), \(n_{c}=(K^{2}),P_{c}[v]=(1)\), centers are sufficiently separated, i.e., \(=:_{i j}(P_{i}\|P_{j})=(k^{2}+ d}}{{n}})\), and \(=:_{i j}(P_{i}\|P_{j})/\). Given an initialization with assignment error \(O(}{{}}})\) for any cluster, after \(t=(||)\) iterations, w.h.p. the assignment error is \(O((-(+1)))\)._

### Learning clusters with user-level privacy

First, we note that it suffices to compute all the cluster center estimates in the usual model of DP to ensure that the personalized estimates are differentially private in the billboard model. This is true since the assigment of the user to a cluster center and finetuning can be done locally by each user. Thus, if we ensure that Alg. 2 applied to all the current clusters is differentially private in each iteration we can then bound the total privacy leak across iterations via advanced composition for DP algorithms. In our algorithm PrivateCenter (Alg. 4) we first use the Laplace mechanism in step \(1\) to privately compute the number of users in the cluster. Then, we use the Gaussian mechanism in step \(2\) to get an initial estimate of the center since all local Good-Turing estimates are distributions \(()\) and thus bounded in \(_{2}\). This initial estimate \(B\) is used to identify the quantile \(B c\), where the mean lies with high probability , so that we can then get a refined estimate in step \(3\) when we add noise (with std. deviation scaling with quantile interval \(c\)). This adaptive clipping procedure is fairly common for practical and private estimation . Finally, to ensure the noised output is still a distribution contained in \(()\), we use \(_{2}\) projection, \(_{()}(P)=:*{arg\,min}_{Q()}\|Q-P\|_{2}^{2}\). In practice, we find that projection with \(_{2}\) is comparable with a KL projection.

**Privacy preserving noisy sum.** As can be seen from the description of PrivateCenter, it only requires being able to compute a noisy sum over a subset of users. In the federated setting implementing this summation as part of algorithm \(\) may seem to require the server to know the (private) cluster membership of each user. However, this can be avoided by computing each such sum as a sum over all the users, where a user submits value \(0\) if they do not belong to the cluster, _i.e._, \(b_{u}=0\), and \(b_{u}=1\) otherwise (Alg. 1). Similarly, Alg. 1 also emits the true local estimate if it is part of the cluster and \(_{d}\) (vector of \(d\)\(0\)s) otherwise. Privacy-preserving computation of a noisy sum over all the users is one of key primitives in FL with a number of known implementations, _e.g._, Bonawitz et al. . Crucially for the privacy analysis, while each user now participates in the sum computations for every cluster, the inclusion/deletion of a single user can only affect the sums for a single cluster.

```
0: Data collection \(\{(b_{u},_{u})\}\), privacy parameter \(\), clipping parameter \(c\), projection operator \(_{()}\).
0: Private center \(\).
1:\(b_{u}b_{u}+(}{{ _{d}}}})\)
2:\(B(_{u}_{u}+(0,}{{_{d}}}_{d}))\)
3:\(}}{{_{b}}}(B)\)
4:\((_{u}_{u}+(0,\;))\), \(_{u}=:[Q_{u}]_{B-c}}^{B +c}}\)
5:\(_{()}\)
6: Return \(\) ```

**Algorithm 4** PrivateCenter

#### 3.3.1 Private initialization for our clustering algorithm

The performance of Alg. 3 is crucially determined by the proximity of initialized centers to each of the true centers (Theorem 3.2), and more critical for higher private noisy tolerance. In PrivateInit (Alg. 5), we provide a private data-dependent initialization technique, that takes as input a private center \(Q_{0}\) (private FedAvg), and samples \(K^{2}\) points around it as an initial candidate set. Then, it chooses \(K\) points iteratively from this set by sampling via the exponential mechanism. The utility function for each candidate \(Q\) is determined by the average reduction in the clustering objective when adding \(Q\) into the current set of initializations \(\), vs. not. The privacy budget \(\) controls the temperature, with lower budget enforcing higher smoothing. In the non-private case, we replace the candidate set with the set of empirical user estimates, and select a high value of \(\). This iterative procedure of selecting candidates with highest regret of omission at each step is meant to ensure that each \(_{u}\) is reasonably close to some initial center (akin to ). We remark that the execution of the sampling step does not lend itself easily for implementation in the distributed setting. In practice, one would need to use a small dataset collected centrally for this.

### Putting it all together: Algorithm for private and personalized frequency estimation

In Alg. 6 we present our complete algorithm. We first compute a private center of all user histograms using Alg. 4 and privacy parameter \(}{{3}}\). We pass this to Alg. 5 with privacy parameter \(}{{3}}\) to get initial centers for Alg. 3, where the re-centering step applies Alg. 4 with privacy parameter \(}{{3T}}\). The privately learned cluster centers from Alg. 6 are then finetuned for each user locally, using Eq. 3.

**Theorem 3.3** (End-to-end privacy guarantee).: _Algorithms 4, 5 are both user-level \(\)-zCJDP. Our end-to-end private and personalized estimation algorithm is \((+2}{{}})},)\)-JDP, \(>0\)._

```
0: Set of users \(\), dataset \(\), number of clusters \(K\), number of clustering iterations \(T\), finetuning parameter \(\), sampling parameter \(\), privacy parameter \(\), clipping parameter \(c\), projection operator \(_{()}\).
0: Private and personalized estimates \(_{u}\) for each \(u\).
1:\(Q_{0}(,,c,_{()})\)# Estimate global center
2:\(}^{(0)}\) Algorithm \((Q_{0},,K,,,c)\)# Estimate initial cluster centers
3:\(\{_{u}\}_{u}\) and centers \(}\) Algorithm \((,}^{(0)},T)\)# Estimate cluster memberships
4:\( u:\;\;_{u}(}_{z_{u}},)\)# Local finetuning using Eq. 3
5: Return \(\{_{u}:u\}\). ```

**Algorithm 6** EndToEnd Algorithm

### Extending our private clustering algorithm to the size-heterogeneous setting

When users vary in size, we need to weigh their local estimates while estimating the global center or the cluster center in the re-centering step of Alg. 3. For user \(u\), the weight \(w_{u}=:}{{_{u}^{2}}})}}{{_{u_{c}}(}{{_{u}^{2}}})}}\). Here \(_{u}^{2}\) is the variance of the user's local estimate, _i.e._, \([_{u}]\) (from Lemma 3.4). When \(P_{z_{u}}[v]\) is known this weighted estimate is optimal under \(_{2}\). Since \(P_{z_{u}}[v]\) is unknown we replace \(P_{z_{u}}[v]\) in Lemma 3.4 with a uniform average of \(_{u}\) from heavier users, following Cummings et al. .

**Lemma 3.4** (Variance of \(_{u}\)).: _For user \(u\), \([_{u}[v]]=}[v]}}{{}{{ }}}}+}{{1-}{{m_{u}}}}}+}[v] (1-P_{z_{u}}[v])}}{{}{{m_{u}}}}}\)._

In the private setting though this approach cannot be used directly since the sensitivity of the weighted mean estimate is too high for users with a lot of data, and more so for small sized clusters. Cummings et al.  propose an algorithm to estimate the private heterogeneous mean of user data from different Bernoulli distributions, but their approach does not directly transfer to our setting due to the high-dimensional nature of our user means and the relatively poor sensitivity of Alg. 3 to errors in the estimation of cluster centers at each iteration. Thus we consider a two-stage approach, split across data-rich and data-poor users. In the first stage we privately cluster users with sufficiently large datasets applying Alg. 3, and treating them as size-homogeneous data-rich users. Once cluster centers are learned privately, using Alg. 1, each data-poor user assigns itself to the closest center in KL divergence. Finally for each cluster, we apply Algorithm 2 from Cummings et al.  that re-centers each cluster privately, based on the newly added users.

## 4 Formal analysis in a stylized data model

In Section 3, we presented a clustering based iterative algorithm (Alg. 3) for our frequency estimation problem introduced in Section 2, wherein we made several key design choices. In particular, we used average of Good-Turing estimators to estimate the cluster center, and used the update in Equation 3 to locally finetune the learnt cluster centers. Now, we analyze these algorithms in a stylized model.

**Bayesian Model.** Each user \(u\) belongs to a cluster \(z_{u}[K]\) with cluster center \(P_{z_{u}}\). The user histogram \(Q_{u}( P_{z_{u}})\), and the user dataset \(_{u} Q_{u}^{_{u}}\) is sampled _i.i.d._ from \(_{u}\). We use \(_{c}=:\{u:z_{u}=c\}\) to denote the set of users from cluster \(c\), and \(n_{c}=:|_{c}|\) is the number of users in \(c\). Higher value of \(\) implies more concentrated clusters since \((Q_{u}[v])=O(}[v]}}{{1+}})\), and as \(\), \(Q_{u} P_{z_{u}}\) in weak topology . Please note that the Dirichlet assumption is mainly for simplicity and our results (_e.g.,_ Theorem 4.3) only require each cluster's user distribution to be exponentially **concentrated** along each token, _i.e._, \((|Q_{u}[v]-P_{z_{u}}[v]| t)=(e^{-t})\).

**Purely local learning.** We present two local estimators that estimate \(Q_{u}\): empirical \(_{u}\). and Good-Turing \(_{u}^{}\). The naive estimate \(_{u}\) is the average of user data in \(_{u}\). Next, we define theGood-Turing estimator. Let the frequency of token \(v\) in user's dataset \(_{u}\) (of size \(m_{u}\)) be \(_{u,v}\). We denote the local frequency of the count \(j\) as \(_{u,j}=:_{v}(_{u,v}=j)\), _i.e._, the number of token in \(_{u}\) with count \(j\). Following Orlitsky and Suresh , for a token \(v\) that appears \(j=_{u,v}\) times, the Good-Turing estimator for \(Q_{u}[v]\) is given by:

\[_{u}^{}[v]=:N_{u}}&j >_{u,j+1},\\ N_{u}}+1}{_{u,j}}&, \] (5)

where \(N_{u}\) is the normalization factor so that \(_{v}_{u}^{}[v]{=}1\). Let \(_{u}\) be the class of natural estimators that assign the same probability to tokens with equal counts in \(_{u}\). Then, following Lemma 6 in Orlitsky and Suresh  and Theorem 2 in Acharya et al.  we conclude that with respect to \(_{u}\), the Good-Turing estimate \(_{u}^{}\) has a worst case suboptimality gap of \(((}{{m}},}{{m}}})\) (see Lemma 4.1 for the full statement). The key point to note here is that when the user dataset is small, we do not suffer from the vocabulary size \(d\), unlike the empirical estimate \(_{u}\). This is mainly because Good-Turing more accurately estimates the probability of unseen words .

**Lemma 4.1**.: _(\(_{u}^{}\) suboptimality gap) For any \(Q_{u}\), the suboptimality gap of \(_{u}^{}\) with respect to \(_{u}\) is \([(Q_{u}\|_{u}^{})]-_{_{u}}[(Q_{u}\|)]=(( }{{m}}},}{{m}}))\), that matches minimax rates._

**Bayes optimal finetuning when the cluster center is given.** When \(P_{z_{u}}\) is known, FT in Eq. 3 is Bayes optimal in KL and when only an estimate of the center is known, the error of the "plug-in" estimate scales linearly with the error in the center's estimate (Theorem 4.2).

**Theorem 4.2** (Bayes optimal local learning).: _Given \(P_{z_{u}},\), the estimator \((P_{z_{u}},_{u})\) is Bayes optimal in KL divergence, for the Dirichlet prior \(( P_{z_{u}})\). When \(_{z_{u}}\) is the estimated cluster center, and \(_{u}^{}\) is the Bayes optimal estimate of \(Q_{u}\), then \((_{u}^{}\|(_{z_{u}}, _{u}))}{{+m_{u}}}\,(P_{z_{u }}\|_{z_{u}}))\)._

**Estimating the cluster center given cluster members.** Given all users in a cluster \(c\), one estimate of the cluster center \(P_{c}\) is the solution to the maximum log-likelihood objective in Eq. 6, which is typically solved with the FedAvg  algorithm. We denote this estimate as \(_{c}^{}\) and is a simple weighted average of empirical estimates (see proof in Appendix E). Similarly, for user \(u\) in cluster \(c\), the personalized output from the PFL algorithm FedAvg+FT is given by \((_{c}^{},_{u})\).

\[_{c}^{}=:_{u_{c}}( }}{{_{v^{}_{c}}m_{u^{}}}})_{u}\;\;*{arg\,max}_{Q()}\; }_{u_{c}}(_{u} Q)\] (6)

Our algorithms (Alg. 6, Alg. 2) use a different estimator. In the size-homogenous case, to estimate the cluster center we average the local Good-Turing estimates \(_{u}^{}\) for all users in the cluster:

\[_{c}^{}=:}_{u_{c}} {Q}_{u}^{}.\] (7)

To analyze the accuracy guarantees of our estimate \(_{c}^{}\), we first define the class of competing estimators for it. Let \(_{v}=:}_ {v}/_{u}m_{u}}}\) be the average count of token \(v\) across all users in a cluster. We define \(}\) to be the class of estimators that assign the same mass to tokens \(v_{1},v_{2}\) if \(_{v_{1}}=_{v_{2}}\). Such a class is natural for estimators that rely on aggregated statisitics, and includes the Good-Turing correction applied to cluster level counts. In Theorem 4.3, for any cluster center \(P_{c}\), we compare the suboptimality gap in KL divergence for our estimate \(_{c}^{}\) in Eq. 7 with FedAvg.

**Theorem 4.3** (\(_{c}^{}\) in Eq. 7 has lower suboptimality gap than FedAvg).: _For the competetive class of estimators with the same average count, i.e., \(}\) (defined above), and suboptimality gap from Lemma 4.1, the suboptimality gap for \(^{}\) in Eq. 7, w.r.t. \(}\) is \((}{{+1}}(}{{m}},}{{m}}}))\). The suboptimality gap over \(}\) for FedAvg \(^{}\) is \((}{{m(+1)}})\). \(,\) hides \(\) factors in \(m,n\)._

When \(m\) is small and comparable to the intra-cluster std. deviation, i.e., \(}{{+1}}=O(1)\), then the suboptimality gap for our estimator does not suffer from large dimension \(d\). On the other hand, FedAvg guarantees are much weaker and degrade with dimension for small user datasets (common in practice). From, Theorem 4.2, we also conclude that our final estimate for \(Q_{u}\), given by the finetuned center: \((,_{u})\) would also have stronger error guarantees than FedAvg+FT.

**Partitioning users into clusters.** In practice, neither the cluster membership \(z_{u}\) nor the center \(P_{c}\) is known. The Bayes optimal estimate for \(P_{c},z_{u}\) is the mean of the posterior \((Q_{u},)\)(see Theorem 4.2 proof), but since the posterior is intractable, we instead compute the maximum likelihood estimate (MLE). Asymptotically, MLE's accuracy is vindicated by Doob's theorem , and its variance matches the Cramer-Rao bound . Still, the joint MLE for \(P_{c},z_{u}\) is a non-concave maximization problem. Akin to solving the MLE for mixture distributions , we maximize an evidence lower bound with Expectation-Maximization (EM) . Since each \(Q_{u}\) belongs to only one cluster, it must be that \(z_{u}_{c[k]}(Q_{u}\|P_{c})\). Thus, the MLE for the cluster centers is given by objective in Eq. 4 from Section 3, which is optimized iteratively by our Algorithm 6.

**Takeaways.** We note: (i) when cluster memberships are known, average of local Good-Turings has a lower suboptimality gap than FedAvg; and (ii) solutions to the clustering objective in Eq. 4 estimates cluster centers for each user; and (iii) if the center estimates are accurate then finetuning them with \(\) yields estimates that are equally close to the Bayes optimal solution. These findings validate our algorithmic design choices for the clustering and finetuning algorithms in Section 3.

## 5 Empirical evaluation

We empirically evaluate our approach on real-world datasets and present: **(i)** contrary to popular belief , we show there are real-world distributions where clustering based algorithms (_e.g._, ours) significantly outperform the popular PFL baseline FedAvg+FT; **(ii)** our method achieves better privacy-utility tradeoff than private versions of clustering-based baselines, and the gap amplifies in the size-heterogeneous case; and **(iii)** we show our method's performance improvements can be largely attributed to algorithmic design choices influenced by our data model and analysis in Section 4.

**Datasets.** We evaluate methods on three real-world datasets: Reddit , StackOverflow , and Amazon Reviews . For Reddit, we use the NLTK tokenizer  with a vocabulary of size \(10\)k tokens, and for the other two datasets, we use the Huggingface (bert-case-uncased) tokenizer  with a vocabulary size of \(32\)k tokens. For more details on datasets and hyperparameters see Appendix C.

**Baselines.** We evaluate two baselines that learn a single global model: FedAvg  and MAML ; and a clustering-based approach which learns multiple models, one for each cluster: IFCA /HypCluster . Given a single global model (or a cluster level model), each user can finetune this locally in different ways: full batch gradient descent (GD) initialized at global model, RTFA , or with our problem specific method in Eq. 3. We compare these on FedAvg model

Figure 1: _Performance before finetuning:_ We compare the test NLL loss before local personalization (finetuning) for baselines FedAvg, MAML, IFCA with our approach. NLL is uniformly averaged over users and each value is averaged over \(50\) random runs (error bars indicate \(95\%\) confidence intervals).

Figure 2: _Performance after finetuning:_ In the size-homogeneous (a-c), and size-heterogeneous (d-f) settings, we compare the test NLL loss for baselines FedAvg+FT, MAML+FT, IFCA+FT with our Alg. 3+FT, where FT is implemented by Eq. 3. Uniformly averaged over users, each value is averaged over \(50\) random runs (error bars indicate \(95\%\) confidence intervals).

(Figure 3(d)), and fix the best one (ours) as the local finetuning approach for all algorithms. In the private setting, we adapt the baselines by using standard techniques  that privatize \(l_{2}\) bounded gradients for MAML/IFCA, and \(l_{1}\) bounded probability distributions for FedAvg.

**Evaluation metric.** For distribution \(Q_{u}\), estimate \(_{u}\), \((Q_{u},_{u})=(Q_{u},_{u})-(Q _{u})\), where \((Q_{u},_{u})=:-_{u}Q_{u,u} Q_{u,u}\) is the negative log-likelihood loss, and \((Q_{u})\) is the entropy of \(Q_{u}\). Following language modeling , we use the test set of the user to get an unbiased estimate of the NLL loss, by replacing \(Q_{u}\) with the empirical distribution on the test set. Since the test set is insufficient to get an unbiased estimate of \((Q_{u})\), as a reference point, we instead report the entropy of the global center or FedAvg estimate \((^{fa})\), which is a rough estimate of the "hardness" of estimating the user distribution. We refer to this difference in test NLL and \((^{fa})\) as _NLL sub-optimality gap_. In the private case, we ensure the algorithms satisfy \((15,10^{-10})\)-JDP.

**Our approach significantly reduces test NLL in private and non-private settings.** In Figure 1 we report a significant reduction in test NLL sub-optimality gap even before local finetuning, by atleast \(25\)-\(45\%\) in the non-private setting and upto \(50\%\) in the private case. Non-privately MAML/IFCA perform better than FedAvg on StackOverflow and Amazon, but their private versions perform similar or worse than the private FedAvg. This is because the gradient-based optimization in MAML and IFCA can incur very high per-iteration privacy overheads which only accumulates more for the latter that additionally suffers from poor convergence due to imperfect cluster initialization. On the other hand, our method achieves a privacy-utility tradeoff that is comparable to the gradient-free FedAvg, and converges in fewer iterations when clustering is initialized with centers from Alg. 5. In Figure 2 we compare the performance after we finetune the global/cluster-level estimates locally for each user (using Eq. 3), and verify that the relative gains remain consistent with pre-finetuning. In particular we note that finetuning global FedAvg/MAML models does not do better than finetuning cluster-level models, vindicating the presence of concentrated subpopulations in an otherwise highly heterogeneous real-world user distribution.

**Algorithmic design decisions influenced by our model in Section 4.** In Section 4 we identified the Good-Turing based estimator (Eq. 7) to suffer less from vocabulary size, compared to FedAvg (Theorem 4.3), and in practice too we observe a big improvement in the test NLL loss of Alg. 3 when it uses Good-Turing as the local estimate, vs. empirical (Figure 3(c)). The relative gap is particularly wider on the large vocabulary datasets Amazon and StackOverflow. In Figure 3(b), we show that our data-dependent private initialization (Alg. 5), that is also based on our mixture of Dirichlet model, plays a crucial role in lowering the final test loss, and we attribute this gain to a significant reduction in clustering iterations (from \(200\) to \(20\)), thereby reducing privacy overhead. In Figure 3(d) we note that the Bayes optimal finetuning algorithm in our data model (Eq. 3) does better than typical gradient-based (GD) or proximal term based (RTFA) approaches. Finally, in Figure 3(a), we plot test NLL as we vary the number of clusters assumed by Alg. 3. We note that for runs on all datasets we choose \(K{=}10\) which was found to be optimal on the Reddit validation set (see Appendix C), even though it is clearly (slightly) suboptimal on the other two, suggesting that Alg. 3's performance is not too sensitive to the choice of \(K\) practice.

**Size-heterogeneous case.** In Figure 4 plot test NLL in the size-heterogeneous case where our algorithm's gains (\(>40\%\) error reduction) over single global model baselines FedAvg and MAML are even more pronounced than the size-homogeneous results in Figures 1, 2. For the better suited clustering baseline IFCA, the privacy utility tradeoff worsens (compared to size-homogenous) due to poorer higher sensitivity of gradient estimates when dataset sizes vary. On the other hand, our two-stage approach reduces privacy noise in the clustering stage by partitioning users into different stages and still improves performance for data scarce users in the second stage by incorporating them

Figure 3: _Algorithmic design choices:_ We evaluate test NLL for Alg. 3 as we: (a) vary the number of clusters \(K\); (b) use Privatelnit or randomly initialize cluster centers; and (c) use average of Good-Turing or empirical average to estimate cluster centers. In (d) we evaluate different finetuning methods applied to the FedAvg model.

in the re-centering of clusters from previous stage. Compared to IFCA we observe \(>50\%\) reduction in test NLL suboptimality gap for private estimation on Amazon Reviews.

## 6 Related work

**Private and personalized federated learning.** Multiple works propose and analyze clustering based algorithms that learn a diverse set of models for heterogeneous user distributions [26; 33; 35; 54; 55; 66; 73; 77]. With the exception of  that first learns a global model and then uses it to partition users based on their losses, most works learn diverse models from scratch using gradient based algorithms, as done by FedAvg . The key difference being that they first partition clients based on their loss  or gradients  and then use the same gradients to update different models, one for each cluster. Additionally, their analysis also holds mainly for smooth/strongly convex loss functions, for _e.g._, least squares [33; 54]. This is a natural and promising approach but we are not aware of practical results showing that it can improve on the more direct combination of FedAvg and FT [19; 76]. In fact, Wu et al.  raise concerns about mode collapse with clustering iterations. Contrary to the works above, we focus on a non-gradient based approach specifically for frequency estimation in KL divergence, which can be ill-conditioned in practice, and also provide an algorithm for the more challenging size-heterogeneous setting. As we show in our work, this problem requires solutions that are different from the ones proposed for general loss families in machine learning. Moreover, unlike the above, we provide privacy guarantees for our clustering based personalization. For more discussion on related works please see Appendix B

**Distribution estimation in KL divergence.** A multitude of works on mixture of Gaussians, and mixed linear regression propose and analyze distribution estimation algorithms [9; 22; 45; 61], but their guarantees are mainly for parametric estimation errors in \(_{1}/_{2}\) metric. In contrast, we are concerned with histogram estimation in KL divergence which presents interesting challenges since this is not a proper distance metric (_e.g._, does not satisfy triangle inequality). On the other hand, [30; 34; 64] study Good-Turing estimators and give estimation error guarantees in KL divergence for categorical distributions over a fixed alphabet. Our work extends estimators of Acharya et al. , Orlitsky and Suresh  to the federated setting where the goal is to estimate a full population of distributions that share a latent structure. Relevant to our objective and metric is  that analyzes guarantees for information theoretic clustering. Their analysis shows that one can adapt analysis for other metrics (_e.g._, Hellinger) to obtain worst-case approximation guarantees. In contrast, we investigate practical and private algorithms for the federated setting.

## 7 Conclusion

We introduce the problem of private and personalized frequency estimation in KL divergence. For this, we propose an iterative algorithm that privately learns clusters in the population of all user frequencies. Each user in a cluster locally finetunes their corresponding cluster center to produce personalized and private frequency estimates with formal joint DP guarantees. We improve the privacy-utility tradeoff of our algorithm by proposing a novel data-dependent private initialization for clustering that empirically reduces number of clustering iterations. We also present a two-stage version of our approach to separately handle the harder size-heterogenous setting. In a Bayesian model where the user distributions are distributed as Dirichlets around well-separated centers, we reason about different collaborative and local estimators, and provide formal guarantees for some of our algorithmic design choices, like Good-Turing estimators, and the choice of the local finetuning algorithm. Empirically, we test our algorithm on three real-world datasets and show a significant reduction in test NLL, by \(25\)-\(45\%\) in the non-private setting and upto \(50\%\) in the private case.

Figure 4: _Size-heterogenous setting:_ Comparison of test loss for baselines FedAvg+FT, MAML+FT, IFCA+FT with our Alg. 3+FT, in the size-heterogeneous setting where each userâ€™s dataset vastly differs in size. Uniformly averaged over users, each value is averaged over \(50\) random runs (error bars indicate \(95\%\) confidence intervals).