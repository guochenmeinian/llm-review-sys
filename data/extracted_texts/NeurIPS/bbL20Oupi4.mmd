# Anonymous and Copy-Robust Delegations

for Liquid Democracy+
Footnote â€ : Part of this research was carried out while both authors were affiliated with TU Berlin and Universidad de Chile, and Markus Utke was affiliated with University of Amsterdam.

Markus Utke

Department of Mathematics and Computer Science

TU Eindhoven

Eindhoven, The Netherlands

m.utke@tue.nl

&Ulrike Schmidt-Kraepelin

Simons Laufer Mathematical Sciences

Institute (SLMath)

Berkeley, CA, United States

uschmidt@slmath.org

###### Abstract

Liquid democracy with ranked delegations is a novel voting scheme that unites the practicability of representative democracy with the idealistic appeal of direct democracy: Every voter decides between _casting_ their vote on a question at hand or _delegating_ their voting weight to some other, trusted agent. Delegations are transitive, and since voters may end up in a delegation cycle, they are encouraged to indicate not only a single delegate, but a set of potential delegates and a ranking among them. Based on the delegation preferences of all voters, a _delegation rule_ selects one representative per voter. Previous work has revealed a trade-off between two properties of delegation rules called _anonymity_ and _copy-robustness_.

To overcome this issue we study two _fractional_ delegation rules: Mixed Borda Branching, which generalizes a rule satisfying copy-robustness, and the Random Walk Rule, which satisfies anonymity. Using the _Markov chain tree theorem_, we show that the two rules are in fact equivalent, and simultaneously satisfy generalized versions of the two properties. Combining the same theorem with _Fulkerson's algorithm_, we develop a polynomial-time algorithm for computing the outcome of the studied delegation rule. This algorithm is of independent interest, having applications in semi-supervised learning and graph theory.

## 1 Introduction

Today, democratic decision-making in legislative bodies, parties, and non-profit organizations is often done via one of two extremes: In _representative democracy_, the constituents elect representatives who are responsible for deciding upon all upcoming issues for a period of several years. In _direct democracy_, the voters may vote upon every issue themselves. While the latter is distinguished by its idealistic character, it may suffer from low voter turnout as voters do not feel sufficiently informed. Liquid democracy aims to provide the best of both worlds by letting voters decide whether they want to _cast_ their opinion on an issue at hand, or prefer to _delegate_ their voting weight to some other, trusted voter. Delegations are transitive, i.e., if voter \(v_{1}\) delegates to voter \(v_{2}\), and \(v_{2}\) in turn delegates to voter \(v_{3}\), who casts its vote, then \(v_{3}\) receives the voting weight of both \(v_{1}\) and \(v_{2}\). Liquid democracy has been implemented, for example, by political parties (Kling et al., 2015) and Google (Hardt and Lopes, 2015). From a theoretic viewpoint, liquid democracy has been studied intensively by the social choice community in the last decade (Paulin, 2020).

Earlier works on liquid democracy (Christoff and Grossi, 2017; Brill, 2018) have pointed towards the issue of _delegation cycles_, e.g., the situation that occurs when voter \(v_{3}\) in the above example decides to delegate to voter \(v_{1}\) instead of casting its vote. If this happens, none of the three voters reaches acasting voter via a chain of trusted delegations, and therefore their voting weight would be lost. In order to reduce the risk of the appearance of such so-called _isolated_ voters, several scholars suggested to allow voters to indicate _back-up_ delegations (Brill, 2018; Golz et al., 2021; Kavitha et al., 2022) that may be used in case there is no delegation chain using only top-choice delegations. In _liquid democracy with ranked delegations_(Brill et al., 2022; Colley et al., 2022; Kavitha et al., 2022), voters are assumed to indicate a set of trusted delegates together with a ranking (preference order) among them. In fact, Brill et al. (2022) showed empirically that in many random graph models, one to two back-up delegations per voter suffice in order to avoid the existence of isolated voters almost entirely.

Allowing the voters to indicate multiple possible delegations calls for a principled way to decide between multiple possible delegations chains. For example, consider Figure 1: Should voter \(v_{1}\)'s weight be assigned to casting voter \(s_{1}\), via \(v_{1}\)'s second-ranked delegation, or should it rather be assigned to voter \(s_{2}\) by following \(v_{1}\)'s first-ranked delegation to voter \(v_{2}\), and then following \(v_{2}\)'s second-ranked delegation? Brill et al. (2022) introduced the concept of _delegation rules_, which take as input a _delegation graph_ (i.e., a digraph with a rank function on the edges) and output an assignment of each (non-isolated) delegating voter to a casting voter. In order to navigate within the space of delegation rules, they apply the axiomatic method (Thomson, 2001), as commonly used in social choice theory. In particular, the authors argue that the following three axioms are desirable:

* _Confluence_: A delegation rule selects one path from every delegating voter to a casting voter and these paths are "consistent" with one another. That is, when the path of voter \(v_{1}\) reaches some other delegating voter \(v_{2}\), the remaining subpath of \(v_{1}\) coincides with the path of \(v_{2}\). This was argued to increase accountability of delegates (Brill et al., 2022; Golz et al., 2021).
* _Anonymity_: A delegation rule should make decisions solely on the structure of the graph, not on the identities of the voters, i.e. it should be invariant under renaming of the voters.
* _Copy-robustness_: If a delegating voter \(v_{1}\) decides to cast her vote herself instead of delegating, this should not change the sum of the voting weight assigned to \(v_{1}\)'s representative and herself. This property was emphasized by practitioners (Behrens and Swierczek, 2015) to avoid manipulations in the system by delegating voters acting as casting voters but actually _copying_ the vote of their former representative.

For any pair of axioms (i) to (iii), Brill et al. (2022) provide a delegation rule that satisfies both of them. In contrast, we prove in Section 7 that there exists no delegation rule that satisfies all three properties simultaneously, thereby strengthening an impossibility result by Brill et al. (2022).2

Our ContributionWe show that the above impossibility is due to the restriction that delegation rules may not distribute the voting weight of a delegating voter to more than one casting voter.

* We generalize the definition of delegation rules to _fractional delegation rules_ (Section 3) and provide generalizations of all three axioms above (Section 7).
* We introduce a natural variant of the Borda Branching rule (Brill et al., 2022), which we call Mixed Borda Branching. We show that this rule is equivalent to the Random Walk Rule, a fractional delegation rule that has been suggested by Brill (2018).
* In our main result, we build upon _Fulkerson's algorithm_(Fulkerson, 1974) and the _Markov chain tree theorem_(Leighton and Rivest, 1986) and show the existence of a polynomial-time algorithm for Mixed Borda Branching. This algorithm is of independent interest, as it computes the probability of two nodes being connected, when sampling a min-cost branching in a digraph uniformly at random. This problem features in semi-supervised learning, under the name _directed power watershed_(Fita Sanmartin et al., 2021), a directed

Figure 1: Example of a delegation graph. Delegating voters (\(v_{1}\) and \(v_{2}\)) are indicated by circles and casting voters (\(s_{1}\) and \(s_{2}\)) by squares. Solid edges represent the first-ranked delegations and dashed edges second-ranked delegations.

variant of the _power watershed_(Couprie et al., 2010). To the best of our knowledge, we provide the first efficient algorithm.
* In Section 7, we show that the Random Walk Rule (and thus Mixed Borda Branching) satisfies the generalizations of all three axioms. We also formalize the impossibility for non-fractional delegation rules. Beyond that, we show that the Random Walk Rule satisfies a generalization of a further axiom (_guru participation_) which has been studied in the literature (Kotsialou and Riley, 2020; Colley et al., 2022; Brill et al., 2022) (Appendix C).

The proofs (or their completions) for results marked by (\(\)) can be found in the appendix.

Related Work_Liquid democracy._ The idea to let agents rank potential delegates in liquid democracy was first presented by the developers of the liquid democracy platform _Liquid Feedback_(Behrens and Swierczek, 2015), who presented seven properties that cannot be satisfied simultaneously. Some of these properties, such as _copy-robustness_ and _guru participation_, have been picked up in the social choice literature (Kotsialou and Riley, 2020; Brill et al., 2022; Colley et al., 2022). The connection of confluent delegation rules to branchings in a digraph was first emphasized by Kavitha et al. (2022) and later built upon in (Brill et al., 2022; Natsui and Takazawa, 2022). We base our model on (Brill et al., 2022), as their model captures all rules and axioms from the literature. Fractional delegations were studied by Degrave (2014) and Bersetche (2022), however, here agents indicate a desired distribution among their delegates instead of a ranking. While the two approaches are orthogonal, we argue in Appendix B that they could be easily combined (and our algorithm could be adjusted).

_Branchings and matrix tree theorems._ Our algorithm for computing Mixed Borda Branching is based on an algorithm for computing min-cost branchings in directed trees. This can be done, e.g., via Edmond's algorithm (Edmonds, 1967) or Fulkerson's algorithm (Fulkerson, 1974). The latter comes with a characterization of min-cost branchings in terms of dual certificates, which we utilize in Algorithm 2. We refer to Kamiyama (2014) for a comprehensive overview on the literature of min-cost branchings. Our algorithm makes use of (a directed version of) the _matrix tree theorem_(Tutte, 1948), which allows to count directed trees in a digraph. An extension of this theorem is the _Markov chain tree theorem_(Leighton and Rivest, 1986), which we use for the construction of our algorithm as well as for proving the equivalence of Mixed Borda Branching and the Random Walk Rule. A comprehensive overview of the literature is given by Pitman and Tang (2018).

_Semi-supervised learning._ There is a connection of our setting to graph-based semi-supervised learning. In particular, Algorithm 2 is related to the _power watershed algorithm_(Couprie et al., 2010) and the _probabilistic watershed algorithm_(Fita Sanmartin et al., 2019, 2021). We elaborate on this connection in Section 4.

## 2 Preliminaries

The main mathematical concepts used in this paper are directed graphs (also called digraphs), branchings, in-trees, and Markov chains, all of which we briefly introduce below.

We assume that a digraph \(G\) has no parallel edges, and denote by \(V(G)\) the set of nodes and by \(E(G)\) the set of edges of \(G\). We use \(_{G}^{+}(v)\) to indicate the set of outgoing edges of node \(v V(G)\), i.e., \(_{G}^{+}(v)=\{(v,u) E(G)\}\). For a set of nodes \(U V(G)\), we define the outgoing cut of \(U\) by \(_{G}^{+}(U)=\{(u,v) E(G) u U,v V(G) U\}\). A walk \(W\) is a node sequence \((W_{1},,W_{|W|})\), such that \((W_{i},W_{i+1}) E(G)\) for \(i\{1,,|W|-1\}\). We omit \(G\) if it is clear from the context.

**Branchings and in-trees.** Given a digraph \(G\), we say that \(B E\) is a branching (or in-forest) in \(G\), if \(B\) is acyclic, and the out-degree of any node \(v V(G)\) in \(B\) is at most one, i.e., \(|B^{+}(v)| 1\). Throughout the paper, we use the term _branching_ to refer to _maximum-cardinality branchings_, i.e., branchings \(B\) maximizing \(|B|\) among all branchings in \(G\). For a given digraph \(G\) we define \((G)\) as the set of all (max-cardinality) branchings and \(_{v,s}(G)\) as the set of all (max-cardinality) branchings in which node \(v V(G)\) has a path to the node \(s V(G)\). For any branching \(B\) in any digraph \(G\) it holds that \(|B||V(G)|-1\). If in fact \(|B|=|V(G)|-1\), then \(B\) is also called an in-tree. For every in-tree \(T E\), there exists exactly one node \(v V(G)\) without outgoing edge. In this case, we also say that \(v\) is the sink of \(T\) and call \(T\) a \(v\)-tree. For \(v V(G)\), we let \(_{v}(G)\) be the set of \(v\)-trees in \(G\).

**Matrix tree theorem.** For our main result we need to count the number of in-trees in a weighted digraph, which can be done with help of the matrix tree theorem. For a digraph \(G\) with weight function \(w:E\), we define the weight of a subgraph \(T E\) as \(w(T)=_{e T}w(e)\) and the weight of a collection of subgraphs \(\) as \(w()=_{T}w(T)\). Then, we define the _Laplacian_ matrix of \((G,w)\) as \(L=D-A\), where \(D\) is a diagonal matrix containing the weighted out-degree of any node \(v\) in the corresponding entry \(D_{v,v}\) and \(A\) is the weighted adjacency matrix, given as \(A_{u,v}=w((u,v))\) for any edge \((u,v) E\) and zero everywhere else. Moreover, we denote by \(L^{(v)}\) the matrix resulting from \(L\) when deleting the row and column corresponding to \(v\).

**Lemma 1** (Matrix tree theorem (Tutte, 1948; De Leenheer, 2020)3).: _Let \((G,w)\) be a weighted digraph and let \(L\) be its Laplacian matrix. Then,_

\[(L^{(v)})=_{T_{v}}_{e T}w(e)=w(_{v}).\]

If we interpret the weight of an edge as its _multiplicity_ in a multigraph, then \((L^{(v)})\) equals the total number of distinct \(v\)-trees.

**Markov Chains.** A Markov chain is a tuple \((G,P)\), where \(G\) is a digraph and the matrix \(P^{|V||V|}\) encodes the transition probabilities. That is, the entry \(P_{u,v}\) indicates the probability with which the Markov chain moves from state \(u\) to state \(v\) in one timestep. For a given edge \(e=(u,v) E\), we also write \(P_{e}\) to refer to \(P_{u,v}\). For all \(v V\) it holds that \(_{e^{+}(v)}P_{e}=1\). Moreover, if \((u,v) E\), we assume \(P_{u,v}=0\). We define the matrix \(Q^{|V||V|}\) as \(Q=_{}_{i=0}^{}P^{}\). If \((G,P)\) is an absorbing Markov chain, \(Q_{u,v}\) corresponds to the probability for a random walk starting in \(u\) to end in absorbing state \(v\). In contrast, if \(G\) is strongly connected and \(P\) is positive for all edges in \(G\), then \(Q_{u,v}\) corresponds to the relative number of times \(v\) is visited in an infinite random walk independent of the starting state (Grinstead and Snell, 1997).

## 3 Liquid Democracy with Fractional Delegations

A _delegation graph_\(G=(N S,E)\) is a digraph with a _cost function4\(c:E\) (called _rank function_ before), representing the preferences of the voters over their potential delegates (lower numbers are preferred). Nodes correspond to voters and an edge \((u,v) E\) indicates that \(u\) accepts \(v\) as a delegate. By convention, the set of nodes \(S\) corresponds exactly to the sinks of the digraph, i.e., the set of nodes without outgoing edges. Thus, \(S\) captures the casting voters, and \(N\) the delegating voters. We assume for all \(v N\) that they reach some element in \(S\).5 A _delegation rule_ maps any delegation graph to a _fractional assignment_, i.e., a matrix \(A^{N S}\), where, for every \(v N\), \(s S\), the entry \(A_{v,s}\) indicates the fraction of delegating voter \(v\)'s weight that is allocated to casting voter \(s S\).6 For any \(v N\) we refer to any casting voter \(s S\) with \(A_{v,s}>0\) as a _representative_ of \(v\). For assignment \(A\), the _voting weight_ of a casting voter \(s S\) is defined as \(_{s}(A)=1+_{v N}A_{v,s}\). A _non-fractional_ delegation rule is a special case of a delegation rule, that always returns assignments \(A\{0,1\}^{N S}\).

**Mixed Borda Branching.** The output of any non-fractional, confluent delegation rule can be represented as a branching: Any branching in the delegation graph consists of \(|N|\) edges, and every delegating voter has a unique path to some casting voter. Brill et al. (2022) suggested to select min-cost branchings, i.e., those minimizing \(_{e B}c(e)\). The authors call these objects Borda branchings and show that selecting them yields a copy-robust rule. As this rule is inherently non-anonymous, we suggest to mix uniformly over all Borda branchings, hoping to gain anonymity without losing the other properties7. Formally, for a given delegation graph \((G,c)\), let \(^{*}(G)\) be the set of all Borda branchings and let \(^{*}_{v,s}(G)\) be the set of all Borda branchings in which delegating voter \(v N\) is connected to casting voter \(s S\). Mixed Borda Branching returns the assignment \(A\) defined as

\[A_{v,s}=^{*}_{v,s}(G)|}{|^{*}(G)|}v V,s S.\]

**Random Walk Rule.** The second delegation rule was suggested in Brill (2018) and attributed to Vincent Conitzer. For any given delegation graph \((G,c)\) and fixed \((0,1]\), we define a Markov chain on \(G\), where the transition probability matrix \(P^{()}^{V(G) V(G)}\) is defined as

\[P^{()}_{u,v}=}{_{u}} (u,v) E,\] (1)

where \(_{u}=_{(u,v)^{+}(u)}^{c(u,v)}\) is the natural normalization factor. The Markov chain \((G,P^{()})\) is absorbing for every \((0,1]\) where the absorbing states are exactly \(S\). The Random Walk Rule returns the fractional assignment \(A\) defined as the limit of the absorbing probabilities, i.e.,

\[A_{v,s}=_{ 0}_{} _{i=0}^{}(P^{()})^{}_{v,s}v N,s S.\]

## 4 Connection to Semi-Supervised Learning

In graph-based semi-supervised learning, the input is a directed or undirected graph, where nodes correspond to data points and edges correspond to relationships between these. A subset of the nodes is _labeled_ and their labels are used to classify unlabeled data. Many algorithms compute a fractional assignment of unlabeled data points towards labeled data points, which is then used to determine the predictions for unlabeled data. In the directed case, there exists a one-to-one correspondence to our model: Delegating voters correspond to unlabeled data and casting voters correspond to labeled data.

**Power Watershed.** In the undirected case, the _power watershed_(Couprie et al., 2010) can be interpreted as an undirected analog of Mixed Borda Branching: For any pair of unlabeled data point \(x\) and labeled data point \(y\), the algorithm computes the fraction of min-cost undirected maximum forests that connect \(x\) to \(y\).8 The authors provide a polynomial-time algorithm for computing its outcome. On a high level, our algorithm (Section 5) is reminiscent of theirs, i.e., both algorithms iteratively contract parts of the graph, leading to a hierarchy of subsets of the nodes. However, while the algorithm by Couprie et al. (2010) only needs to carry out computations at the upper level of the hierarchy, our algorithm has to carry out computations at each level of the hierarchy. We believe that the increased complexity of our algorithm is inherent to our problem and do not find this surprising: Even the classic min-cost spanning tree problem can be solved by a greedy algorithm and forms a Matroid, but this structure gets lost when moving to its directed variant.

**Directed Probabilistic Watershed.** Fita Sanmartin et al. (2021) study a directed version of graph-based semi-supervised learning. The authors introduce the _directed probabilistic watershed (DProbWS)_: Similar to our model, there exists a cost function \(c\) and a weight function \(w\) on the edges. In their case, these functions are linked by \(w(e)=(- c(e))\). The paper studies a Gibbs distribution with respect to the weights, i.e., the probability of sampling a branching is _proportional_ to its weight. The parameter \(\) controls the entropy of this function, i.e., for \(=0\), any branching is sampled with equal probability, while larger \(\) places more probability on low cost branchings. The authors show: (i) For fixed \(\), the fractional allocation induced by the Gibbs distribution can be computed by calculating the absorbing probabilities of a Markov chain. (ii) For the limit case \(\), the defined distribution equals the uniform distribution over all min-cost branchings, i.e., the distribution that we study in this paper. In this limit case, the authors refer to the corresponding solution as the _directed power watershed_. Hence, the authors have shown the equivalence of the directed power watershed and the limit of a parameterized Markov chain. Since this Markov chain only slightly differs from ours, this result is very close to our Theorem 5. As its proof is very short and might be of interest for the reader, we still present it in Section 6. Importantly, Fita Sanmartin et al. (2021) do not show how to _compute_ the outcome of the directed power watershed. In particular, the algorithm from (i) makes explicit use of the weight function on the edges (which depends on \(\)). Hence, the running time of the algorithm grows to infinity in the limit case. We fill this gap by providing the (to the best of our knowledge) first polynomial-time algorithm for the directed power watershed. Maybe surprisingly, we need a significantly more complex approach to solve the limit case: While the algorithm of Fita Sanmartin et al. (2021) solves one absorbing Markov chain, our algorithm derives a hierarchical structure of subsets of the nodes by the structural insights provided by _Fulkerson's_ algorithm, and solves several Markov chains for each of the hierarchy.

## 5 Computation of Mixed Borda Branching

Our algorithm for computing the outcome of Mixed Borda Branching is an extension of an algorithm by Fulkerson (1974) for computing an arbitrary min-cost branchings in a digraph. The algorithm by Fulkerson follows a primal-dual approach and can be divided into two phases, where the first phase characterizes min-cost branchings with the help of a family of subsets of the nodes, and the second phase then constructs one arbitrary min-cost branching. Building upon the first phase, we show that, for every two nodes \(v N\) and \(s S\), we can _count_ the number of min-cost branchings that connect the two nodes by applying an extension of the matrix tree theorem (Tutte, 1948, De Leenheer, 2020) and the _Markov chain tree theorem_(Leighton and Rivest, 1986).

**Fulkerson's algorithm.9** The algorithm (described formally in Algorithm 1) maintains a function \(y:2^{N S}\) and a subset of the edges \(E_{y} E\). The set \(E_{y}\) captures edges that are _tight_ (w.r.t. \(y\)), i.e., those \(e E\) satisfying

\[_{X N S:e^{+}(X)}y(X)=c(e).\]

The algorithm takes as input a delegation graph \(G\) together with a cost function \(c:E\).

```
1: Set \(y(X)=0\) for any set \(X N S\) except \(y(\{s\})=1\) for any \(s S\), \(E_{y}=\)
2:while some node in \(N\) cannot reach any node in \(S\) in the graph \((N S,E_{y})\)do
3: let \(X N\) be a strongly connected component in \((N S,E_{y})\) with \(^{+}(X) E_{y}=\)
4: set \(y(X)\) to minimum value such that some edge in \(^{+}(X)\) is tight, add tight edges to \(E_{y}\)
5:\(=\{X N S y(X)>0\}\)
6:return (\(,E_{y},y\)) ```

**Algorithm 1** Fulkerson's Algorithm (Fulkerson, 1974, Kamiyama, 2014)

Since \(c(e) 1\) for all \(e E\), the output \(\) contains all singleton sets induced by nodes in \(N S\), and beyond that subsets of \(N\). In the following we show several structural insights that are crucial for the construction of our algorithm. While statements (ii) and (iii) have been proven in similar forms by Fulkerson (1974), we prove all of Lemma 2 in Appendix A for completeness.

**Lemma 2** (\(\)).: _Let \((G,c)\) be a delegation graph and let \((,E_{y},y)\) be the output of Algorithm 1. Then:_

1. _For every_ \((G,c)\)_, the output of the algorithm is unique, i.e., it does not depend on the choice of the strongly connected component in line_ 3_._
2. \(\) _is laminar, i.e., for any_ \(X,Y\) _it holds that either_ \(X Y\)_,_ \(Y X\)_, or_ \(X Y=\)_._
3. _Branching_ \(B\) _in_ \((G,c)\) _is min-cost iff (a)_ \(B E_{y}\)_, and (b)_ \(|B^{+}(X)|=1\) _for all_ \(X,X N\)_._
4. _For every_ \(X\)_, an in-tree_ \(T\) _in_ \(G[X]=(X,E[X])\)_, where_ \(E[X]=\{(u,v) E u,v X\}\)_, is min-cost iff (a)_ \(T E_{y}\)_, and (b)_ \(|T^{+}(Y)|=1\) _for all_ \(Y\) _such that_ \(Y X\)_._

**Intuition and notation for Algorithm 2.** For our algorithm, the crucial statements in Lemma 2 are (ii) and (iii). First, because \(\) forms a laminar family, there exists a natural tree-like structure among the sets. We say that a set \(Y\) is a _child_ of a set \(X\), if \(Y X\) and there does not exist a \(Z\), such that \(Y Z X\). Moreover, for some \(X\) or \(X=N S\), we define \(G_{X}=(V_{X},E_{X})\) as the tight subgraph that is restricted to the node set \(X\) and contracts all children of \(X\). Formally, \(V_{X}=\{Y YX\}\) and \(E_{X}=\{(Y,Y^{})(u,v) E_{y},u Y,v Y^{},Y,Y^{} V_{X}\}\). In the following we first focus on the graph corresponding to the uppermost layer of the hierarchy, i.e., \(G_{X}\) for \(X=N S\). Now, statement (iii) implies that every min-cost branching \(B\) in \(G\) leaves every child of \(X\) exactly once and only uses tight edges. Hence, if we project \(B\) to an edge set \(\) in the contracted graph \(G_{X}\), then \(\) forms a branching in \(G_{X}\). However, there may exist many min-cost branchings in \(G\) that map to the same branching in \(G_{X}\). The crucial insight is that we can construct a weight function \(w_{X}\) on the edges of \(G_{X}\), such that the weighted number of branchings in \(G_{X}\) equals the number of min-cost branchings in \(G\). This function is constructed by calculating for every child\(Y\) of \(X\) and every node \(v Y\), the number of min-cost \(v\)-trees inside the graph \(G[Y]=(Y,E[Y])\), where \(E[Y]=\{(u,v) E u,v Y\}\). This number, denoted by \(t_{Y}(v)\), can be computed by recursively applying the matrix tree theorem. Coming back to the graph \(G_{X}\), however, we need a more powerful tool since we need to compute the (relative) number of weighted branchings in \(G_{X}\) connecting any node to a sink node. Thus, we introduce the Markov chain tree theorem (in a slightly modified version so that it can deal with Markov chains induced by weighted digraphs).

For a weighted digraph \((G,w)\) we define the corresponding Markov chain \((G^{},P)\) as follows: The digraph \(G^{}\) is derived from \(G\) by adding self-loops, and for \((u,v) E(G^{})\) we let

\[P_{u,v}=&u v\\ 1-}^{+}(u)}w(e)}{}&u=v,\]

where \(=_{v V}_{e}^{+}(v)}w(e)\).

**Lemma 3** (Markov chain tree theorem (Leighton and Rivest )).: _Consider a weighted digraph \((G,w)\) and the corresponding Markov chain \((G^{},P)\) and let \(Q=_{}_{i=0}^{}P^{}\). Then, the entries of the matrix \(Q\) are given by_

\[Q_{u,v}=_{u,v}}_{e B}P_{e}}{_{B }_{e B}P_{e}}=_{u,v}}_{e B }w(e)}{_{B}_{e B}w(e)}=_ {u,v}}w(B)}{_{B}w(B)}.\]

We formalize Algorithm 2, which takes as input a delegation graph \((G,c)\) and, in contrast to the intuition above, works in a bottom-up fashion. We refer to Figure 2 for an illustration.

**Theorem 4** (\(\)).: _Algorithm 2 returns Mixed Borda Branching and runs in poly\((n)\)._

Proof sketch.: The main part of the proof, shows by induction over the laminar hierarchy of \(\), that for every \(X\) and \(v X\), the value \(t_{X}(v)\) equals the number of min-cost \(v\)-trees in \(G[X]\). Given that this is true, one can show that \(w_{X}(_{Y,\{s\}}(G_{X}))\) equals the number of min-cost branchings in \(G\) that connect any node in \(v Y\) to the sink \(s\) and that \(w_{X}((G_{X}))\) equals the number of all min-cost branchings in \(G\). Hence, we can utilize the Markov chain tree theorem on the graph \(G_{X}\) to compute

Figure 2: Two iterations of Algorithm 2. Costs are depicted by edge patterns (solid equals cost \(1\), dashed equals cost \(2\), and dotted equals cost \(3\)) and weights are depicted by numbers on the edges.

the outcome of Mixed Borda Branching.

As for the running time, the main observation is that the computation of the number of branchings in a weighted digraph can be done in time logarithmic in the highest weight of an edge (and polynomial in the number of edges). Since all of our weights are bounded by the maximum number of branchings in the original graph (which is bounded by \(|N|^{|N|}\)), we can show the polynomial running time. 

## 6 Equivalence of Mixed Borda Branching and Random Walk Rule

With the help of the Markov chain tree theorem, as stated in Section 5, we can show the equivalence of the Random Walk Rule and Mixed Borda Branching.

**Theorem 5**.: _Let \((G,c)\) be a delegation graph and \(A\) and \(\) be the assignments returned by Mixed Borda Branching and the Random Walk Rule, respectively. Then, \(A=\)._

Proof.: Let \(v N\) and \(s S\), then,

\[_{v,s} =_{ 0}_{=1}^{ }(P^{()})^{}_{v,s}=_{ 0}_{v,s}}_{ B}P_{e}^{()}}{_{B }_{ B}P_{e}^{()}}=_{  0}_{v,s}}_{(u,v) B}_{u}}}{_{B} _{(u,v) B}_{u}}}\] \[=_{ 0}(_{u})^{-1}_{B_{v,s}}^{c(B)}}{_{u  N}(_{u})^{-1}_{B}^{c(B)}}= _{v,s}^{*}}1}{_{B^{*}}1}=A_{v,s}.\]

We first use the definition of the Random Walk Rule, and then apply the Markov chain tree theorem (Lemma 3) for fixed \((0,1]\) to obtain the second equality. For the third equality, we use the definition of \(P^{()}\), and then factor out the normalization factor \(_{u}\) for every \(u N\). For doing so, it is important to note that for every \(v N\) and \(s S\), every branching in \(_{v,s}\) and every branching in \(\) contains exactly one outgoing edge per node in \(N\). We also remind the reader that \(c(B)=_{e B}c(e)\). Finally, we resolve the limit in the fifth equality by noting that the dominant parts of the polynomials are those corresponding to min-cost (Borda) branchings. 

Given Theorem 5, we can interpret Algorithm 2 as an algorithm computing limit absorbing probabilities of a class of parametric Markov chains. We explain this reinterpretation in Appendix B.

## 7 Axiomatic Analysis

In this section, we generalize and formalize the axioms mentioned in Section 1 and show that the Random Walk Rule (and hence Mixed Borda Branching) satisfies all of them. In particular, our version of confluence (copy-robustness, respectively) reduces to (is stronger than, respectively) the corresponding axiom for the non-fractional case by Brill et al. (2022) (see Appendix C.1). We first define _anonymity_, which prescribes that a delegation rule should not make decisions based on the identity of the voters. Given a digraph with a cost function \((G,c)\) and a bijection \(:V(G) V(G)\), we define the graph \(((G,c))\) as \((G^{},c^{})\), where \(V(G^{})=V(G)\), \(E(G^{})=\{((u),(v)(u,v) E(G)\}\) and \(c^{}((u),(v))=c(u,v)\) for each edge \((u,v) E(G)\).

**Anonymity:** For any delegation graph \((G,c)\), any bijection \(:V(G) V(G)\), and any \(v N,s S\), it holds that \(A_{v,s}=A^{}_{(v),(s)}\), where \(A\) and \(A^{}\) are the outputs of the delegation rule for \((G,c)\) and \(((G,c))\), respectively.

**Theorem 6** (\(\)).: _The Random Walk Rule satisfies anonymity._

We now define _copy-robustness_, which intuitively demands that if a delegating voter \(v N\) decides to cast their vote instead, the total voting weight of \(v\) and all its representatives should not change. This lowers the threat of manipulation by a voter deciding whether to cast or delegate their vote depending on which gives them and their representatives more total voting weight. This axiom was introduced (under a different name) by Behrens and Swierczek (2015) and defined for non-fractional delegation rules in Brill et al. (2022). We strengthen10 and generalize the version of Brill et al. (2022).

**Copy-robustness:** For every delegation graph \((G,c)\) and delegating voter \(v N\), the following holds: Let \((,c)\) be the graph derived from \((G,c)\) by removing all outgoing edges of \(v\), let \(A\) and \(\) be the output of the delegation rule for \((G,c)\) and \((,c)\), respectively and let \(S_{v}=\{s S A_{v,s}>0\}\) be the set of representatives of \(v\) in \((G,c)\). Then \(_{s S_{v}}_{s}(A)=_{v}()+_{s S_{v}}_{s}()\).

**Theorem 7** (\(\)).: _The Random Walk Rule satisfies copy-robustness._

_Proof sketch._ We show a statement that is slightly stronger than the condition for copy-robustness. Namely, the voting weight of every casting voter from \(S S_{v}\) remains equal when \(v\) changes from being a delegating voter to becoming a casting voter. Let \((G_{X},w_{X})\), with \(X=N S\), be the contracted graph constructed in Algorithm 2 for \((G,c)\). Analogously, let \((_{X},_{X})\) be the contracted graph constructed for \((,c)\). In order to argue about their relation, we first show: If \(y\) and \(\) are the functions returned by Algorithm 1 for \(G\) and \(\), respectively, then \((Y)=y(Y)\) for every set \(Y 2^{N\{v\}}\) not containing \(v\), \((\{v\})=1\), and \((Y)=0\) for all other sets containing \(v\). Now, let \(Y_{v}\) be the node in \(G_{X}\) containing \(v\) and let \( V(G_{X})\) be the subset of nodes in \(G_{X}\) that are not reachable from \(Y_{v}\). We argue that for any \(s S S_{v}\), the Markov chain induced by \((_{X},w_{X})\) can only reach \(\{s\}\) from a starting node in \(\). However, for all nodes in \(\), all of their walks to any \(\{s\},s S S_{v}\) are still existent in the graph \((_{X},_{X})\), and still have the same weight. Hence, the voting weight of any \(s S S_{v}\) remains unchanged when moving from \(G\) to \(\). 

To capture the requirement that the voting weight of different voters is assigned to casting voters in a "consistent" way, Brill et al. (2022) define confluence as follows: A delegation rule selects, for every voter \(u N\), one walk in the delegation graph starting in \(u\) and ending in some sink \(s S\), and assigns voter \(u\) to casting voter \(s\). A delegation rule satisfies confluence, if, as soon as the walk of \(u\) meets some other voter \(v\), the remaining subwalk of \(u\) equals the walk of \(v\).11 Below, we provide a natural generalization of the property by allowing a delegation rule to specify a probability distribution over walks. Then, conditioned on the fact that the realized walk of some voter \(u\) meets voter \(v\), the probability that \(u\) reaches some sink \(s S\) should equal the probability that \(v\) reaches \(s\).

**Confluence:** For every delegation graph \((G,c)\), there exists a probability distribution \(f_{v}\) for all \(v N\) over the set of walks in \(G\) that start in \(v\) and end in some sink, which is consistent with the assignment \(A\) of the delegation rule (i.e., \(_{W f_{v}}[s W]=A_{v,s}\) for all \(v N,s S\)), and,

\[_{W f_{u}}[s W v W]=_{W f_{v}}[s W] u,v N,s S.\]

Note that the requirement that \(A_{v,s}=_{W f_{v}}[s W]\) implies that for any \(v V\) and \(s S\) we can have \(A_{v,s}>0\) only if there is a path from \(v\) to \(s\) in \(G\).

**Theorem 8** (\(\)).: _The Random Walk Rule satisfies confluence._

_Proof sketch._ One can verify that every delegation rule that can be formalized via a Markov chain on the delegation graph \((G,c)\) satisfies confluence. In Section 5, we showed that the Random Walk Rule can be computed by solving a Markov chain \((G_{X},P)\) on the contracted graph \(G_{X}\) (for \(X=N S\)). We utilize \((G_{X},P)\) to define a probability distribution over walks in \(G\) that satisfies confluence: Every walk in \(G\) can be mapped to a walk in \(G_{X}\) (by ignoring edges inside children of \(X\)), but there may exist many walks in \(G\) that map to the same walk in \(G_{X}\). We pick, for every walk\(\) in \(G_{X}\), one representative walk \(W\) in \(G\) and give it the same probability as \(\) in \((G_{X},P)\). All other walks in \(G\) get zero probability. When picking the representative walks, we can ensure that for every two nodes \(u,v N S\), the probability that the walk of \(u\) reaches \(v\) equals the probability that \(Y_{u}\) reaches \(Y_{v}\) in \((G_{X},P)\), where \(Y_{u}\) and \(Y_{v}\) are the nodes in \(V(G_{X})\) containing \(u\) and \(v\), respectively. For the constructed probability distribution, we then show that the confluence condition is met. 

With the formal definition of confluence, anonymity, and copy-robustness we can now show that these properties altogether are impossible to achieve in the non-fractional case. Recall, that a non-fractional delegation rule is defined as a delegation rule, that returns assignments \(A\{0,1\}^{N S}\).

**Theorem 9**.: _No non-fractional delegation rule satisfies confluence, anonymity, and copy-robustness._

Proof.: Consider the graph \((G_{1},c_{1})\) in Figure 3. There are four non-fractional assignments in \((G_{1},c_{1})\): Both \(v_{1}\) and \(v_{2}\) can either be assigned \(v_{3}\) or \(v_{4}\). Suppose a rule chooses assignment \(A\) with \(A_{v_{1},v_{4}}=A_{v_{2},v_{3}}=1\). This rule cannot satisfy confluence, as any walk from \(v_{2}\) to \(v_{3}\) includes \(v_{1}\) and confluence requires \(1=A_{v_{2},v_{3}}=_{W f_{v_{2}}}[v_{3} W]=_{W f _{v_{2}}}[v_{3} W v_{1} W]=_{W f_{v_{1}}}[v_{3} W]=A _{v_{1},v_{3}}=0\). Now, suppose a delegation rule chooses assignment \(A\) with \(A_{v_{1},v_{3}}=A_{v_{2},v_{3}}=1\). We define the bijection \(\) mapping \(v_{1}\) to \(v_{2}\), \(v_{2}\) to \(v_{1}\), \(v_{3}\) to \(v_{4}\) and \(v_{4}\) to \(v_{3}\). Then, \(((G_{1},c))=(G_{1},c)\) and thus \(A^{}_{v_{1},v_{3}}=A^{}_{v_{2},v_{3}}=1\) in the assignment \(A^{}\) that the rule chooses for \(((G_{1},c))\). This contradicts anonymity, since \(1=A_{v_{1},v_{3}} A^{}_{(v_{1}),(v_{3})}=A^{}_{v_ {2},v_{4}}=0\). We can make the same argument in the case of \(A_{v_{1},v_{4}}=A_{v_{2},v_{4}}=1\). For any rule satisfying anonymity and confluence the chosen assignment \(A\) must therefore have \(A_{v_{1},v_{3}}=A_{v_{2},v_{4}}=1\).

The above arguments are independent of the cost function \(c\), so long as we have \(c(v_{1},v_{2})=c(v_{2},v_{1})\) and \(c(v_{1},v_{3})=c(v_{2},v_{4})\), needed for the equality of \(((G_{1},c))\) and \((G_{1},c)\). Thus, any rule satisfying anonymity and confluence must choose the assignment \(A\) with \(A_{v_{1},v_{2}}=A_{v_{3},v_{4}}=1\) for \((G_{2},c_{2})\).

We modify \((G_{1},c_{1})\) by making \(v_{2}\) a casting voter (as in the definition of copy-robustness) and retrieve \((G_{3},c_{3})\). Copy robustness requires that the assignment from \(v_{1}\) to \(v_{4}\) in \(G_{1}\) (which is zero) must be the same as the sum of assignments from \(v_{1}\) to \(v_{4}\) and \(v_{2}\). Thus, we have \(A_{v_{1},v_{3}}=1\) for the assignment \(A\), that any confluent, anonymous, and copy-robust rule chooses for \((G_{3},c_{3})\). However, we can also construct \((G_{3},c_{3})\) from \((G_{2},c_{2})\) by making \(v_{3}\) a casting voter. Then, analogously, copy-robustness requires \(A_{v_{1},v_{2}}=1\) for the assignment of \((G_{3},c_{3})\), leading to a contradiction. 

Since the Random Walk Rule (and thus Mixed Borda Branching) satisfies generalizations of the three axioms, the above impossibility is due to its restriction to non-fractional rules.

## 8 Concluding Remarks

We generalized the setting of liquid democracy with ranked delegations to allow for fractional delegation rules. Beyond that, we presented a delegation rule that can be computed in polynomial time and satisfies a number of desirable properties. A natural follow-up question is to understand the entire space of delegation rules satisfying these properties.

Fractional delegations have been recently implemented (see electric.vote) and studied by Degrave (2014) and Bersetche (2022). In contrast to our setting, these approaches let agents declare a desired _distribution_ over their delegates (instead of rankings). We remark that one could easily combine the two approaches by letting agents declare their desired split within each equivalence class of their ranking. Our algorithm can be extended for this setting (see Appendix B).

There exists a line of research which aims to understand liquid democracy from an epistemic viewpoint (Kahng et al., 2021; Caragiannis and Micha, 2019; Halpern et al., 2023). Here, many of the negative results stem from the fact that voting weight is concentrated on few casting voters. Since, intuitively, ranked delegations can help to distribute the voting weight more evenly, it would be interesting to study these through the epistemic lense.

Figure 3: Situation in the proof of Theorem 9. Solid edges correspond to first-choice delegations, dashed edges to second-choice delegations.