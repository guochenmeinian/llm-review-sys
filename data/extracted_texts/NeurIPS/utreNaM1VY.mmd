# Can semi-supervised learning use all the data effectively? A lower bound perspective

Alexandru Tifrea

ETH Zurich

alexandru.tifrea@inf.ethz.ch

&Gizem Yuce\({}^{*}\)

EPFL

gizem.yuce@epfl.ch

&Amartya Sanyal

Max Planck Institute for Intelligent Systems, Tubingen

amsa@di.ku.dk

&Fanny Yang

ETH Zurich

fan.yan@inf.ethz.ch

###### Abstract

Prior theoretical and empirical works have established that semi-supervised learning algorithms can leverage the unlabeled data to improve over the labeled sample complexity of supervised learning (SL) algorithms. However, existing theoretical work focuses on regimes where the unlabeled data is sufficient to learn a good decision boundary using unsupervised learning (UL) alone. This begs the question: Can SSL algorithms simultaneously improve upon both UL _and_ SL? To this end, we derive a tight lower bound for 2-Gaussian mixture models that explicitly depends on the labeled and the unlabeled dataset size as well as the signal-to-noise ratio of the mixture distribution. Surprisingly, our result implies that no SSL algorithm improves upon the minimax-optimal statistical error rates of SL or UL algorithms for these distributions. Nevertheless, in our real-world experiments, SSL algorithms can often outperform UL and SL algorithms. In summary, our work suggests that while it is possible to prove the performance gains of SSL algorithms, this would require careful tracking of constants in the theoretical analysis.1

## 1 Introduction

Semi-Supervised Learning (SSL) has recently garnered significant attention, often surpassing traditional supervised learning (SL) methods in practical applications [5; 10; 22]. Within this framework, the learning algorithm leverages both labeled and unlabeled datasets sampled from the same distribution. Numerous empirical studies suggest that SSL can effectively harness the information from both datasets, outperforming both SL and unsupervised learning (UL) approaches [21; 42; 17; 25]. This observation prompts the question: how fundamental is the improvement of SSL over SL and UL? 2

Prior theoretical results do not provide a consensus on this topic. One line of work demonstrates that under certain settings, SSL is capable of lowering the labeled sample complexity. In these settings, the unlabeled data possesses a significant amount of information about the conditional distribution (up to permutation). Some examples of this setting include distributions where unlabeled samples are enough to obtain small estimation error in mixture models [30; 18] or when the data is clusterable . Therefore, despite SSL performing provably better than SL in these settings, it is only as good as UL (up to permutation). Another line of work challenges the above literature by identifying scenarios where SSL achieves the same error rate as SL. In these scenarios, even oracle knowledge about themarginal distribution fails to improve upon the error rates of SL algorithms since the marginal does not carry any information about the labeling i.e. the conditional distribution. Therefore, these settings do not allow SSL to improve upon SL but only upon UL.

In summary, the previous bounds do not provide a conclusive answer on the benefits of SSL; the positive and negative results consider different regimes dependent on sample sizes and the "compatibility" of the marginal distribution with the conditional distribution. In particular, they either improve upon UL or upon SL, but never both simultaneously. In this paper, we provide a first answer to the following question

_Can semi-supervised classification algorithms simultaneously improve_

_over the minimax rates of both SL and UL?_

Specifically, in Sections 2 and 3, we study this question in the context of linear classification for symmetric 2-Gaussian mixture models (GMMs) as done in several works in this domain [30; 18; 2; 39]. In this setting, we derive minimax error rates for semi-supervised learning that specifically depend on the "regime", characterized by three quantities: the amount of available unlabeled data \(n_{u}\), amount of available labeled data \(n_{l}\), and the inherent signal-to-noise ratio (SNR) that quantifies the amount of information the marginal input distribution has about the conditional label distribution (see 3 for more details). An SNR-dependent minimax rate allows us to analyze the whole spectrum of problem difficulties for 2-GMMs. By contrasting the SSL minimax rates with established minimax rates for SL and UL, we find that in no regime can SSL surpass the statistical rates of both SL and UL. In conclusion, the optimal algorithm is the one that can adeptly switch between SL and UL algorithms depending on the regime and hence, it never uses the available data fully.

Nevertheless, statistical rates may not offer a complete picture for explaining the practical benefits of SSL algorithms. Several prevalent SSL algorithms, such as self-training, are more sophisticated than UL approaches and use labeled data not only for determining the sign but also for learning the decision boundary. In Section 4, we show that an SSL ensembling method and self-training [41; 7] can indeed improve upon the best of SL and UL algorithms even in proof-of-concept experiments for linear classification tasks on both synthetic and real-world datasets. Since the improvements cannot be captured by statistical rates, our results highlight the significance of the constant factors in future theoretical work that analyzes the advantage of SSL algorithms.

## 2 Problem setting and background

Before providing our main results, in this section, we first define the problem setting for our theoretical analysis, the evaluation metrics and the types of learning algorithms that we compare. We then describe how we compare the rates between SSL and supervised and unsupervised learning

### Linear classification for 2-GMM data

Data distribution.We consider linear binary classification problems where the data is drawn from a Gaussian Mixture Model consisting of two identical spherical Gaussians with identity covariance and uniform mixing weights. The means of the two components \(^{*},-^{*}\) are symmetric with respect to the origin but can have arbitrary non-zero norm. We denote this family of joint distributions as \(_{}:=\{P_{XY}^{^{*}}:^{*} ^{d}\}\) that can be factorized so that the density reads \(p_{XY}^{^{*}}(x,y)=p_{X|Y}^{^{*}}(x|y)p_{Y}(y)\) with

\[P_{Y}=\{-1,1\}P_{X|Y}^{^{*}}=(Y ^{*},I_{d}).\] (1)

This family of distributions has often been considered in the context of analysing both SSL [30; 18] and SL/UL [2; 24; 39] algorithms. For \(s(0,)\), we denote by \(_{}^{(s)}_{}\) and \(^{(s)}^{d}\) the set of distributions \(P_{XY}^{^{*}}\) and the set of parameters with \(\|^{*}\|=s\), respectively. With this definition, we will be able to obtain refined bounds that depend explicitly on \(s\). We consider algorithms \(\) that take as input a labeled dataset \(_{l}(P_{XY}^{^{*}})^{n_{l}}\) of size \(n_{l}\), an unlabeled dataset \(_{u}(P_{X}^{^{*}})^{n_{u}}\) of size \(n_{u}\), or both, and output an estimator \(}=(_{l},_{u}) ^{d}\). The estimator is used to predict the label of a test point \(x\) as \(=(},x)\).

Evaluation metricsIn this work, we consider two natural error metrics for this class of problems: prediction error and parameter estimation error3. For any vector \(\), we define its

\[\ _{}(,^{*}):=P_{XY}^{^{*}}(*{sign}( ,X) Y),\] (2) \[\ _{}(,^{*}):=\|-^{*}\|_{2}.\] (3)

When the true \(^{*}\) is clear from the context, we drop the second argument for simplicity. In our discussions, we focus on the prediction error, but include a minimax rate for the estimation error for completeness. In particular, we bound the excess risk of \(\), defined as the distance between the risk of \(\) and the Bayes optimal risk

\[\ (,^{*} ):=_{}(,^{*})- _{}_{}(,^{*} ).\]

where \(_{}_{}(,^{*})\) is achieved at \(^{*}\) but can be non-zero.

For the set of all classification algorithms, we study the minimax expected error over a set of parameters \(\). This worst-case error over \(\) indicates the limits of what is achievable with the algorithm class. For instance, the minimax optimal expected excess error of the algorithm class over \(\) takes the form:

\[\ (n_{l},n_{u},):=_{ }_{^{*}}[( (_{l},_{u}),^{*})].\] (4)

### Minimax optimal rates of supervised and unsupervised learning

We distinguish between three kinds of learning that can be used in the SSL setting to learn a decision boundary \(}\) but are designed to leverage the available data differently. For simplification, our discussion is tailored towards learning \(_{}\), though the ideas hold more generally.

1) Semi-supervised learning (SSL)SSL algorithms, denoted as \(_{}\), can utilize both labeled \(_{l}\) and unlabeled samples \(_{u}\) to learn the decision boundary and to produce an estimator \(}_{}=_{}(_{l}, _{u})\). The promise of SSL is that by combining labeled and unlabeled data, SSL can reduce both the labeled and unlabeled sample complexities compared to algorithms solely dependent on either dataset.

2) Supervised learning (SL)SL algorithms, represented by \(_{}\), can only use the labeled dataset \(_{l}\) to yield an estimator \(}_{}=_{}(_{l}, )\). The minimax rates of SL for distributions from \(_{}^{(s)}\) (see Table 1) are achieved by the mean estimator \(}_{}=}_{i=1}^{n_{l}}Y_{i}X_{i}\), for both excess risk and estimation error.

3) Unsupervised learning (UL)Traditionally, UL algorithms are tailored to learning the generative model for marginal distributions. For \(_{}\) the marginal is governed by \(^{*}\) and UL algorithms output a set of estimators \(\{}_{},-}_{}\}=_ {}(,_{u})\) one of which is guaranteed to be close to the true \(^{*}\). To evaluate prediction performance, we define the minimax rate of UL algorithms as the minimax rate for the closer (to the true \(^{*}\)) of the two estimators. This minimax rate of UL algorithms over \(_{}^{(s)}\) is known for both the excess risk and the estimation error  (see Table 1). These rates are achieved by the unsupervised estimator \(}_{}=-1)_{+}}\), where \((,)\) is the leading eigenpair of the sample covariance matrix \(=}_{j=0}^{n_{u}}X_{j}X_{j}^{T}\) and we use the notation \((x)_{+}:=(0,x)\).

   Learning paradigm & Excess risk rate & Estimation error rate \\  SL & \(e^{-s^{2}/2}}\) & \(}}\) \\  UL(+) & \(e^{-s^{2}/2}n_{u}}\) & \(n_{u}}}\) \\   

Table 1: Known minimax rates of SL and UL for learning 2-GMMs . The minimax rates for UL are up to choosing the correct sign. This rate is the same as for UL+ if \(n_{l}(n_{u})\). The notation \(f(x) g(x)\) is equivalent to \(f=(g)\).

### A "wasteful" type of SSL algorithm

Several SSL algorithms used in practice (e.g. SimCLR , SwAV ) follow a two-stage procedure: i) determine decision boundaries using only unlabeled data; and ii) label decision regions using only labeled data. We refer to this class of two-stage algorithms as **UL+** and denote them by \(_{}\). Early analyses of semi-supervised learning focus, in fact, on algorithms that fit the description of UL+ [30; 31].

For linear binary classification, the two-stage framework is depicted in Algorithm 1. The following proposition upper bounds the excess risk and estimation error incurred by the UL+ estimator given by

\[}_{}=(}_{ }^{}}_{})}_{ {UL}}}_{}=_{}( _{l}).\] (5)

**Proposition 1** (Upper bounds for \(}_{}\) ).: _Let \(}_{}\) be the estimator defined in Equation (5). For any \(s(0,1]\) the following holds when \(n_{u}(160/s)^{2}d\) and \(d 2\):_

\[[_{}(} _{},^{})] n_{u}}}+se^{-n_{ls}s^{2} (1-c_{0})}{s^{2}n_{u}}})^{2}},\] \[[(}_{}, ^{})]  e^{-s^{2}}n_{u}}+e^{-s^{2}n_{l} (1-c_{0})}{s^{2}n_{u}}})^{2}}.\]

Appendix A contains the complete statement of the proposition including logarithmic factors and the proof. Note that for \(n_{l}=o(}(n_{u}))\), the first term in the upper bound dominates, thereby resulting in the same rate as the minimax rate of UL up to choosing the correct sign. We remark that, while Algorithm 1 defines UL+ algorithms as only using the unlabeled dataset \(_{u}\) for the unsupervised learning step, one can also use the labeled dataset \(_{l}\) without labels in that step. However, typically, in practice, UL+ style algorithms (e.g. SimCLR, SwAV) do not use the labeled data in this way, as they operate in a regime where unlabeled data is far more numerous than labeled data. Thus, we analyze Algorithm 1 in this work.

Why UL+ algorithms are "wasteful"As indicated in Algorithm 1, UL+ type algorithms follow a precise structure where labeled data is used solely to select from the set of estimators output by a UL algorithm. Intuitively, such algorithms do not take full advantage of the labeled data as it is not used to refine the decision boundary. In prior empirical and theoretical studies, this inefficiency has not been a problem since they have focused on the regime \(n_{u}=(n_{l})\), where unlabeled data is often orders of magnitude more abundant than labeled data. When \(n_{u}=(n_{l})\) or even \(n_{u} n_{l}\), however, Proposition 1 shows how this two-stage approach of UL+ can become strikingly ineffective. For simplicity, consider the extreme scenario where \(n_{u}\) is finite, but \(n_{l}\). The error of a UL+ algorithm will, at best, mirror the error of a UL algorithm with the correct sign (e.g. \((}{{n_{u}}})\) for the excess risk). Thus, despite using both labeled and unlabeled data, UL+ algorithms bear a close resemblance to UL algorithms that only use unlabeled data.

``` Input :\(_{l}\), \(_{u}\) \(\{}_{},-}_{}\} _{}(_{u})\) \(}_{}\{\{}_{},-}_{}\}_{l}\}\) return\(}_{}\) ```

**Algorithm 1**UL+ algorithms \(_{}\)

### Brief overview of prior error bounds for SSL

In this section, we discuss prior theoretical works that aim to show benefits and limitations of SSL.

Upper boundsThere are numerous known upper bounds on the excess risk of SSL algorithms for \(_{2}\) distributions. However, despite showing better dependence on the labeled set size, these earlier bounds primarily match the UL+ rates [30; 31] or exhibit slower rates than UL+ . That is, we cannot conclude from existing results that SSL algorithms can consistently outperform _both_ SL and UL+, which is the question we aim to address in this paper.

Lower boundsIn contrast to the upper bounds that aim to demonstrate benefits of SSL, three distinct minimax lower bounds for SSL have been proposed to show the limitations of SSL. Each proves, in different settings, that there exists a distribution \(P_{XY}\) where SSL cannot outperform the SL minimax rate. Ben-David et al.  substantiate this claim for learning thresholds from univariate datasourced from a uniform distribution on \(\). Gopfert et al.  expand upon this by considering arbitrary marginal distributions \(P_{X}\) and a "rich" set of realizable labeling functions, such that no volume of unlabeled data can differentiate between possible hypotheses. Lastly, Tolstikhin and Lopez-Paz  set a lower bound for scenarios with no implied association between the labeling function and the marginal distribution, a condition recognized as being unfavorable for SSL improvements . Each of the aforementioned results contends that a particular worst-case distribution \(P_{XY}\) exists, where the labeled sample complexity for SSL matches that of SL, even with limitless unlabeled data.

To summarize, the upper bounds show that SSL improves upon SL in settings where \(n_{u}\) is significantly larger than \(n_{l}\). In fact, for such large unlabeled sample size even UL+ can achieve small error. On the other hand, the lower bounds prove the futility of SSL for distributions where even infinite unlabeled data cannot help i.e. \(P_{X}\) does not contain sufficient information about the conditional distribution. However these works fail to answer the question: does there exist a relatively moderate \(n_{u}\) regime where SSL is better than both SL and UL+?

In the family of \(_{}\) distributions, the above lower bounds translate to the hard setting where \(n_{u}}{{s}}\). We now aim to prove a minimax lower bound for a fixed difficulty \(s>0\), that allows us to answer the above question in different regimes in terms of \(n_{l},n_{u}\).

## 3 Minimax rates for SSL

In this section we provide tight minimax lower bounds for SSL algorithms and 2-GMM distributions in \(_{}^{(s)}\). Our results indicate that it is, in fact, not possible for SSL algorithms to simultaneously achieve faster minimax rates than both SL and UL+.

### Minimax rate

We begin by introducing tight lower bounds on the excess risk (4) of a linear estimator obtained using both labeled and unlabeled data. In addition, we also present tight lower bounds on estimation error (3) for the means of class-conditional distributions obtained similarly using labelled and unlabelled data. This is especially relevant when addressing linear classification of symmetric and spherical GMMs. In this setting, a reduced estimation error points to not only a low excess risk but also suggests a small calibration error under the assumption of a logistic noise model . Both of these results are presented in Theorem 1. We present short proof sketches here and relegate the formal conditions required by the theorem to hold as well as the full proofs to Appendices B and C (for the estimation error and excess risk, respectively).

**Theorem 1** (SSL Minimax Rate for Excess Risk and Estimation Error).: _Assume the conditions in Proposition 1 and additionally let \(n_{l}>O(}{s^{2}})\). Then for any \(s(0,1]\), we have_

\[_{}_{\|^{*}\|=s}[ (_{}(_{l},_{ u}),^{*})]  e^{-s^{2}/2}\{s,+s^{3}n_{u}}\}, \] \[_{}_{\|^{*}\|=s}[ _{}(_{}(_{l},_{u}),^{*})] \{s,+s^{2}n_{u}}}\},\]

_where the infimum is over all the possible SSL algorithms that have access to both unlabeled and labeled data and the expectation is over \(_{l}(P_{XY}^{^{*}})^{n_{l}}\) and \(_{u}(P_{X}^{^{*}})^{n_{u}}\)._

In the rest of the section, we focus solely on the bound for excess risk; however, we note that the discussion here transfers to estimation error as well. In Section 3.2, we discuss the new insights that this bound provides. A direct implication of the result is that \(_{}(n_{l},n_{u},^{(s)})( _{}(n_{l},0,^{(s)}),_{} (n_{l},n_{u},^{(s)}))\), that is, the minimax rate of SSL is the same as either that of SL or UL+, depending on the value of \(s\) and the rate of growth of \(n_{u}\) compared to \(n_{l}\). Therefore, we can conclude that _no SSL algorithm can simultaneously improve the rates of both SL and UL+ for \(^{(s)}\)_.We provide a full discussion of the rate improvements in more detail in Section 3.2.

Proof sketchThe proof of the lower bound for excess risk is presented in Appendix C. For this proof, we adopt the packing construction in Li et al.  and apply Fano's method. Since the algorithms have access to both labeled and unlabeled datasets in the semi-supervised setting, KLdivergences between both the marginal and the joint distributions appear in the lower bound after the application of Fano's method, which is the key difference from its SL and UL counterparts.

We then show that the rate can be matched by the **SSL Switching Algorithm (SSL-S)** in Algorithm 2 - an oracle algorithm that switches between using a (minimax optimal) SL or UL+ algorithm based on the values of \(s,n_{l},\) and \(n_{u}\). The upper bound then follows as a corollary from Proposition 1 and the upper bounds for supervised learning.

For the parameter estimation error lower bound, we use Fano's method with the packing construction in Wu and Zhou , who have employed this method to derive lower bounds in the context of unsupervised learning. Similar to the excess risk analysis, the lower bound reveals that the SSL rate is either determined by the SL rate or the UL+ rate depending on \(s\) and the ratio of the sizes of the labeled and unlabeled samples. Once again, the minimax error rate is matched by the SSL Switching algorithm presented in Algorithm 2.

Discussion of the details of the theoremWe note that the SSL-S algorithm chooses to output the trivial estimator \(}_{}=\) if the SNR \(s\) is low. In the low-SNR regime, the trivial estimator \(}=\) achieves a small excess risk of \((,^{})=(s)- (0) e^{-s^{2}/2}s\), where \(\) is the CDF of the standard normal distribution.

Moreover, the technical condition \(s(0,1]\) is not overly restrictive as this range for the SNR is already sufficient for seeing all the relevant regimes, e.g. SSL-S switches from using SL to UL+ within this range. Finally, while the _rates_ of either SL or UL+ cannot be improved further using SSL algorithms, it is nonetheless possible to improve the error by a constant factor, independent of \(n_{l}\) and \(n_{u}\). To see this, in Section 4 we describe an algorithm that uses both \(_{l}\) and \(_{u}\) effectively and can hence achieve a provable improvement in error over both SL and UL+.

### Comparison of SSL with UL+ and SL in different regimes

To understand whether an SSL algorithm is using the labeled and unlabeled data effectively, we compare the error rate of SSL algorithms to the minimax rates for SL and UL+ algorithms.

A gap in these rates for a certain SSL algorithm would indicate that the algorithm can obtain lower error than both SL and UL+ when presented with the same amount of (large enough) data. We study the _improvement rates_ defined below, which capture the error ratio for the worst-case distributions between the minimax rate for SSL and the minimax rate for SL or UL+.

**Definition 1** (SSL improvement rates).: _For a set of parameters \(^{d}\), we define the improvement rates of SSL over SL and UL+ as \(h_{l}\) and \(h_{u}\), respectively, where_

\[h_{l}(n_{l},n_{u},):=_{}} _{^{}}[(_{}(_{l},_{u}),^{ })]}{_{_{}}_{^{} }[(_{}( _{l},),^{})]},\] (6) \[h_{u}(n_{l},n_{u},):=_{}} _{^{}}[(_{}(_{l},_{u}),^{ })]}{_{_{}}_{^{} }[(_{}( _{l},_{u}),^{})]},\] (7)

_where the expectations are over \(_{l}(P_{XY}^{^{}})^{n_{l}}\) and \(_{u}(P_{X}^{^{}})^{n_{u}}\)._

To simplify notation, we denote the improvement rates of SL and UL+ over \(^{(s)}\) as \(h_{l}(n_{l},n_{u},s)\) and \(h_{u}(n_{l},n_{u},s)\), respectively. A straightforward upper bound for these rates is \(h_{l},h_{u} 1\), achieved when utilizing an SL and UL+ algorithm, respectively. SSL demonstrates an enhanced error rate over SL and UL+, if both \(_{n_{l},n_{u}}h_{l}(n_{l},n_{u},)=0\) and \(_{n_{l},n_{u}}h_{u}(n_{l},n_{u},)=0\). If \(h_{l}\) or \(h_{u}\) lies in \((0,1)\) without converging to zero as \(n_{l},n_{u}\), then SSL surpasses SL or UL+, respectively, only by a constant factor.

Given Theorem 1, we can directly derive the improvement rates of SSL in the following corollary.

**Corollary 1**.: _Assuming the setting of Theorem 1, the improvement rates of SSL can be written as:_

\[\ h_{l}(n_{l},n_{u},s) }{n_{l}+s^{2}n_{u}}.\] \[\ h_{u}(n_{l},n_{u},s) n_{u}}{n_{l}+s^{2}n_{u}}.\]

Based on this corollary, we now argue how no SSL algorithm can simultaneously improve the rates of both SL and UL+ for any regime of \(s,n_{l}\) and \(n_{u}\), as summarized in Table 2.

1. SSL rate is not faster than SL, but is faster than UL+.For extremely low values of SNR (i.e. \(s 0\) faster than \(}\)), we have that \(_{n_{l},n_{u}}h_{l}(n_{l},n_{u},s)=c_{SL}>0\) and hence SSL fails to improve the SL rates even with infinite unlabeled data. This setting has been the focus of previous worst-case analyses for SSL [6; 36; 20]. Alternatively, the SSL rate is also not better than the SL rate for a fixed SNR, when the labeled dataset is significantly larger than the unlabeled data, i.e. \(n_{u}=o(n_{l})\).

2. SSL rate is faster than SL, but not faster than UL+.As mentioned in Gopfert et al. , in order for SSL to lead to a rate improvement compared to SL, it is _necessary_ that the unlabeled set size is at least a superlinear function of the labeled set size, i.e. \(n_{u}=(n_{l})\). Corollary 1 shows that this condition is, in fact, _sufficient_ for 2-GMM distributions: for \(s>0\), as long as \(n_{u}\) grows superlinearly with respect to \(n_{l}\), \(h_{l}(n_{l},n_{u},s) 0\), and hence, SSL can achieve faster rates than SL. Despite the improvement over SL, for this setting, the asymptotic error ratio between SSL and UL+ does not vanish, i.e. \(_{n_{l},n_{u}}h_{u}(n_{l},n_{u},s)=c_{ UL}>0\).

3. SSL rate is not faster than either SL or UL+.Finally, in the regime where the unlabeled dataset size depends linearly on the size of the labeled set i.e. \(_{n_{l},n_{u}}}{n_{l}} c\) for some constant \(c>0\), neither of the improvement rates vanishes for \(n_{l},n_{u}\).

As explained in Section 2.2, prior UL+ algorithms that work well in practice do not use the labeled data for the unsupervised learning step. Interestingly, for the case when both the labeled and unlabeled data are used for the unsupervised step, the trends in Table 2 remain the same, with only one exception: the improvement rates in the last line of the table (i.e. \(}{n_{l}} c(0,)\)) would only change by a small constant. More importantly, the main takeaway from Table 2 remains the same: SSL cannot achieve better rates than both UL+ and SL at the same time since there is no regime for which \(h_{l}\) and \(h_{u}\) are simultaneously 0.

## 4 Empirical improvements over the rate-optimal SSL-S algorithm

Section 3 shows that the SSL minimax rates can be achieved with a simple algorithm that switches between a minimax optimal SL and a minimax optimal UL+ algorithm. Despite being optimal in terms of statistical rates, this SSL Switching algorithm does not make the most effective use of the available data: SL algorithms solely uses the labeled data whereas UL+ learns the decision boundary using just the unlabeled data and the labeled data is used to only label the different prediction regions. Alternatively, one could use both labeled and unlabeled data to learn the decision boundary. In this section, we investigate the following question: Is it possible to improve over the error of SSL-S even though the rate would be, at best, as good as the 'wasteful' SSL-S algorithm as per Section 3?In this section, we present experiments to show that, in fact, a remarkably simple algorithm (i.e. a weighted ensemble of the SL and UL+ classifiers) can outperform the minimax optimal SSL-S algorithm. We show that algorithms such as self-training, which have been shown to excel in practice , can also improve over SSL-S. Consequently, it remains an exciting avenue for future work to derive tight analyses that characterize the improvement of such algorithms over SL/UL+.

A simple algorithm more effective than SSL-SA natural approach to improve upon the naive SSL-S algorithm is to construct a weighted ensemble of an SL and a UL+ estimator, trained on \(_{l}\) and \(_{u}\), respectively, with a controllable weighting hyperparameter \(t\). We call this the **SSL Weighted algorithm (SSL-W)** shown in Algorithm 3. With an appropriate choice of \(t\), it is possible to show that the SSL-W algorithm performs better (up to sign permutation) than SSL-S. The formal statement of this result together with the proof are deferred to Appendix D. In practice, one can fix the sign permutation of the \(}_{}\) estimator using a small amount of labeled data. The intuition for this improvement is that the ensemble estimator \(}_{}\) achieves lower error than the constituent estimators of the ensemble (i.e. \(}_{}\) and \(}_{}\)), which, in turn, determine the error of the SSL-S algorithm.

### Empirical improvements over the minimax optimal SSL-S algorithm

In this section we present linear classification experiments on synthetic and real-world data to show that there indeed exist SSL algorithms that can improve over the error of the (minimax optimal) SSL Switching Algorithm. For both synthetic and real-world data, we use \(}_{}=}_{i=1}^{n_{l}}Y_{i}X_{i}\) as the SL estimator and an Expectation-Maximization (EM) algorithm for the UL algorithm (see Appendix E for details). The optimal switching point for SSL-S and the optimal weight for SSL-W, as well as the optimal \(_{2}\) penalty for logistic regression are chosen using a validation set.

Synthetic data.We consider data drawn from a symmetric and isotropic 2-GMM distribution \(P^{^{*}}_{XY}\) over \(^{2}\). The labeled and unlabeled set sizes are set to \(20\) and \(2000\), respectively. Figure 0(a) shows the gap between SSL-W and SL or UL+ as a function of the SNR \(s\) (Figure 3 in Appendix F shows the dependence of the error gap on \(n_{l}\)). There are two main takeaways. First, for varying SNR values \(s\), SSL-W always outperforms SL and UL+, and hence, also SSL-S. Second, as argued in Section 3.2, SSL-W improves more over UL+ for small values of the SNR \(s\), and it improves more over SL for large values of the SNR.

Real-world data.We consider \(10\) binary classification real-world datasets: five from the OpenML repository  and five 2-class subsets of the MNIST dataset . For the MNIST subsets, we choose class pairs that have a linear Bayes error varying between \(0.1\%\) and \(2.5\%\).4 We choose from OpenML datasets that have a large enough number of samples compared to dimensionality (see Appendix E for details on how we choose the datasets). The OpenML datasets span a range of Bayes errors that varies between \(3\%\) and \(34\%\).

In the absence of the exact data-generating process, we quantify the difficulty of SSL on real-world datasets using a notion of _compatibility_, reminiscent of Balcan and Blum . Specifically, we consider the compatibility given by \(^{-1}\) with \(:=}((^{*}_{UL+},^{*}_{ })+_{}(^{*}_{}))\), where \((^{*}_{UL+},^{*}_{}):=_{}(^{*}_{U+})-_{}(^{ *}_{})}{_{}(^{*}_{})}\), \(d\) is the dimension of the data, \(^{*}_{}\) is obtained via SL on the entire dataset and \(^{*}_{}\) determines the predictor with optimal sign obtained via UL on the entire dataset. Intuitively, this notion of compatibility captures both the Bayes error of a dataset, as well as how compatible the 2-GMM parametric assumption actually is for the given data.

In addition to SSL-S (Algorithm 2) and SSL-W (Algorithm 3) we also evaluate the performance of self-training, using a procedure similar to the one analyzed in Frei et al. . We use a logistic regression estimator for the pseudolabeling, and train logistic regression with a ridge penalty in the second stage of the self-training procedure. Note that an \(_{2}\) penalty corresponds to input consistency regularization  with respect to \(_{2}\) perturbations.

Figure (b)b shows the improvement in classification error of SSL algorithms (i.e. SSL-W and self-training) compared to SL and UL+. The positive values of the error gap indicate that SSL-W outperforms both SL and UL+ even on real-world datasets. This finding suggests that the intuition presented in this section carries over to more generic distributions beyond just 2-GMMs. Finally, Figure 4 in Appendix F shows that SSL-W improves over the error of the minimax optimal SSL-S algorithm, for varying values of \(n_{l}\). These findings provide some proof-of-concept evidence that existing SSL algorithms may already be obtaining lower error than the minimax optimal SSL-S algorithm. We hope this observation will encourage future research into characterizing this error gap for practically relevant algorithms such as self-training.

## 5 Related work

Other theoretical analyses of SSL algorithms.Beyond the theoretical studies highlighted in Section 2, there are a few others pertinent to our research. Specifically, Azizyan et al. , Singh et al.  present upper bounds for semi-supervised regression, which are contingent on the degree to which the marginal \(P_{X}\) informs the labeling function. This is akin to the results we derive in this work. However, obtaining a minimax lower bound for semi-supervised regression remains an exciting direction for future work. We refer to  for an overview of prior theoretical results for SSL.

Balcan and Blum  introduced a compatibility score, denoted as \((f,P_{X})\), which connects the space of marginal distributions to the space of labeling functions. While their findings hint that SSL may surpass the SL minimax rates, they offer no comparisons with UL/UL+. Moreover, the paper does not discuss minimax optimality of the proposed SSL algorithms.

On another note, even though SSL does not enhance the rates of UL, Sula and Zheng  demonstrate that labeled samples can bolster the convergence speed of Expectation-Maximization within the context of our study.

To conclude, Scholkopf et al.  leveraged a causality framework to pinpoint scenarios where SSL does not offer any advantage over SL. In essence, when the covariates, represented by \(X\), act as causal ancestors to the labels \(Y\), the independent causal mechanism assumption dictates that the marginal \(P_{X}\) offers no insights about the labeling function.

Minimax rates for SL and UL.The proofs in this work rely on techniques used to derive minimax rates for SL and UL algorithms. Most of these prior results consider the same distributional assumptions as our paper. Wu and Zhou  show a tight minimax lower bound for estimation error for spherical 2-GMMs from \(_{}\). Moreover, Azizyan et al. , Li et al.  derive minimax rates over \(_{}\) for classification and clustering (up to permutation).

In addition to the SL and UL algorithms considered in Section 3, Expectation-Maximization (EM) is another family of algorithms that is commonly analyzed for the same distributional setting considered in our paper. For instance, Wu and Zhou  rely on techniques from several previous seminal papers [12; 14; 15; 3; 16] to obtain upper bounds for EM-style algorithms.

Figure 1: Error gap between SL or UL+ and SSL-W for varying task difficulties. We assess problem difficulty using the SNR (for 2-GMMs) or the compatibility \(^{-1}\) (for real-world data). We see the same trends for both synthetic and real-world data. Moreover, self-training also exhibits the same trend as \(}_{}\).

Conclusions and limitations

In this paper, we establish a tight lower bound for semi-supervised classification within the class of 2-GMM distributions. Our findings demonstrate that SSL cannot simultaneously improve the error rates of both SL and UL across all signal-to-noise ratios. However, empirical evidence suggests that SSL _can_ improve upon the error of minimax optimal SL or UL algorithms. This observation calls for careful analyses of the error of SSL algorithms that also track constant factors, not only rates.

Our theoretical analysis focuses exclusively on isotropic and symmetric GMMs due to limitations in the technical tools employed for the proofs. Similar constraints can be observed in recent analyses of SL or UL algorithms [24; 39]. However, it is worth noting that whenever the bounds for SL and UL can be extended to more general distributions in the future, these results can be seamlessly used to also extend Theorem 1 to these settings.