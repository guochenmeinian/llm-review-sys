# On the Computational Complexity of Private High-dimensional Model Selection

Saptarshi Roy Zehua Wang Ambuj Tewari

Department of Statistics

University of Michigan, Ann Arbor

{roysapta, wangzeh, tewaria}@umich.edu

###### Abstract

We consider the problem of model selection in a high-dimensional sparse linear regression model under privacy constraints. We propose a differentially private (DP) best subset selection method with strong statistical utility properties by adopting the well-known exponential mechanism for selecting the best model. To achieve computational expediency, we propose an efficient Metropolis-Hastings algorithm and under certain regularity conditions, we establish that it enjoys polynomial mixing time to its stationary distribution. As a result, we also establish both approximate differential privacy and statistical utility for the estimates of the mixed Metropolis-Hastings chain. Finally, we perform some illustrative experiments on simulated data showing that our algorithm can quickly identify active features under reasonable privacy budget constraints.

## 1 Introduction

In this paper, we consider the problem of _private model selection_ in high-dimensional sparse regression which has been one of the central topics in statistical research over the past decade. Consider observations \(\{(_{i},y_{i})\}_{i=1}^{n}\) following the linear model:

\[y_{i}=_{i}^{}+w_{i}, i\{1,,n\},\] (1)

where \(\{_{i}\}_{i[n]}\) are _fixed_\(p\)-dimensional feature vectors, \(\{w_{i}\}_{i[n]}\) are i.i.d. _mean-zero_\(\)-sub-Gaussian noise, i.e., \(( w_{i})(^{2}^{2}/2)\) for all \(\) and \(i[n]\), and the signal vector \(^{p}\) is unknown but is assumed to have a sparse support. In matrix notation, the observations can be represented as

\[=+,\]

where \(=(y_{1},,y_{n})^{}\), \(=(_{1},,_{n})^{}\), and \(=(w_{1},,w_{n})^{}\). We consider the standard _high-dimensional sparse_ setup where \(n<p\), and possibly \(n p\), and the vector \(\) is sparse in the sense that \(\|\|_{0}:=_{j=1}^{p}(_{j} 0 )=s\), which is much smaller than \(p\). The main goal of variable selection is to identify the active set \(^{*}:=\{j:_{j} 0\}\).

For the past two decades, there has been ample work on model selection problem in the non-private setting for \(_{1}\)-penalized methods, concave regularized methods , \(_{0}\)-penalized/constrained methods  in high-dimensional setting. On the computational side, recent advancements related to mixed integer optimization (MIO) in  and  have pushed the computational barrier of best subset selection (BSS) in terms of solving problems of large dimensions (large \(p\)), and consequently, simulation studies in  have revealed the improved performance of BSS over its computational surrogates like LASSO, SCAD, and MCP.

Despite these theoretical and computational advancements related to BSS, to the best of our knowledge, there is no computationally efficient private algorithmic framework for BSS for high-dimensional sparse regression setup (1). This is especially surprising as private model selectionis important in many contemporary applications involving sensitive data including genetics , neuroimaging , and computer vision . One major reason for this could be the lack of DP mechanisms for MIO problems which restricts us from exploiting the MIO formulation of BSS introduced in . Secondly, the apparent computational burden stemming from the requirement of exponentially large numbers of search queries in private BSS has eluded the majority of the machine learning and statistics community. In this paper, we address the latter issue by mainly focusing on the utility and computational complexity of BSS under privacy constraints. To be specific, we make the following contributions listed below:

1. We adopt the exponential mechanism  to design a DP BSS algorithm, and we establish its good statistical or utility guarantee under high-privacy regime whenever \(_{min}:=_{j^{*}}|_{j}|\{(s p)/n\}^{1/2}\).
2. Under the low-privacy regime, we show that accurate model recovery is possible whenever \(_{min}\{( p)/n\}^{1/2}\), which is the minimax optimal \(_{min}\) requirement for model recovery under non-private setting. Therefore, this paper points out an inflection phenomenon in the signal strength requirement for the model consistency across different privacy regimes.
3. In addition, we design an MCMC chain that converges to its stationary distribution that matches the sampling distribution in the exponential mechanism. As a consequence, the model estimator generated by the MCMC also enjoys (approximate) DP. Furthermore, under certain regularity conditions on the design, we show that the MCMC chain enjoys a polynomial mixing time in \((n,p,s)\) to the stationary distribution with good utility guarantee.

In summary, this paper proposes a DP version of BSS that generates a private model estimator of \(^{*}\) with strong model recovery property within polynomial time in the problem parameters \(n,p,s\). In the next section, we will discuss some prior related works on DP model selection and discuss some of their limitations.

### Comparison with Prior Related Works

In the past decades, there has been a considerable amount of work studying DP sparse regression problems. However, most of these works focus either on empirical risk minimization [25; 44; 26; 48] or establishing \(_{2}\)-consistency rate [47; 6] which are not directly related to the task of model selection. To the best of our knowledge, there are only three works considering the problem of variable selection in sparse regression problems under the DP framework, [27; 45], and . Table 1 shows a clear comparison between those methods and our method.  proposed two algorithms under sparse regression setting. One of them is based on the exponential mechanism, which is known to be computationally inefficient due to exponentially large numbers of search queries. However, they do not analyze the algorithm under the model selection framework. Moreover, for the privacy analysis, they assume that the loss functions are bounded over the space of sparse vectors, which is rather restrictive in the linear regression setting. In comparison, our paper provides a solid model recovery guarantee (Theorem 3.5) for a similar exponential mechanism without using the bounded loss assumption. Furthermore, under a slightly stronger assumption, we design a computationally efficient MCMC algorithm that also enjoys desirable utility similar to the exponential mechanism (Theorem 4.3) under DP framework. The other algorithm in  is based on the resample-and-aggregate framework [36; 42]. Although computationally efficient, this method requires sub-optimal \(_{min}\) condition compared to Theorem 3.5. In , the authors introduced two concepts of stability for LASSO and proposed two PTR-based (propose-test-release) algorithms for variable selection. However, these methods have nontrivial probabilities of outputting the null (no result), which is undesirable in practice. Also, the support recovery probabilities for these methods do not approach 1 with a growing sample size even under the _strong irrepresentability condition_ on the design matrix. In , the authors proposed to use the Akaike information criterion or Bayesian information criterion coupled with the exponential mechanism to choose the proper model. However, the runtime of this algorithm is exponential and also requires stronger \(_{min}\) condition. As mentioned earlier, in this paper, we show that our proposed MCMC algorithm is both computationally efficient and produces approximate DP estimates of \(^{*}\) with a strong utility guarantee under a better \(_{min}\) condition. One may also apply sparse vector techniques (SVT) to choose important features . In this case, each feature can be associated with an appropriate choice of score function, and then apply SVT to choose the relevant features. However, the choice of the score function in high-dimensional sparse regression cases remains unclear, and moreover, it is also known that the exponential mechanism enjoys better accuracy compared to SVT  under such an offline setting.

## 2 Differential Privacy

Differential privacy requires the output of a randomized procedure to be robust with respect to a small perturbation in the input dataset, i.e., an attacker can hardly recover the presence or absence of a particular individual in the dataset based on the output only. It is important to note that differential privacy is a property of the randomized procedure, rather than the output obtained.

### Preliminaries

In this section, we will formalize the notion of differential privacy. Consider a dataset \(D:=\{z_{1},,z_{n}\}^{n}\) consisting of \(n\) datapoints in the sample space \(\). A _randomized_ algorithm \(\) maps the dataset \(D\) to \((D)\), an output space. Thus, \((D)\) is a random variable on the output space \(\).

For any two datasets \(D\) and \(D^{}\), we say they are _neighbors_ if \(|D D^{}|=1\). We can now formally introduce the definition of differential privacy.

**Definition 2.1** (\((,)\)-DP, ).: _Given the privacy parameters \((,)^{+}^{+}\), a randomized algorithm \(()\) is said to satisfy the \((,)\)-DP property if_

\[((D)) e^{}( (D^{}))+\] (2)

_for any measurable event \(()\) and for any pair of neighboring datasets \(D\) and \(D^{}\)._

In the above definition, the probability is only with respect to the randomness of the algorithm \(()\), and it does not impose any condition on the distribution of \(D\) or \(D^{}\). If both \(\) and \(\) are small, then Definition 2.1 essentially entails that distribution of \((D)\) and \((D^{})\) are almost indistinguishable from each other for any choices of neighboring datasets \(D\) and \(D^{}\). This guarantees strong privacy against an attacker by masking the presence or absence of a particular individual in the dataset. As a special case, when \(=0\), the notion of DP in Definition 2.1 is known as the _pure differential privacy_.

### Privacy Mechanisms

For any DP procedure, a specific randomized procedure \(\) must be designed that takes a database \(D^{n}\) as input and returns an element of the output space \(\) while satisfying the condition in (2). Several approaches exist that are generic enough to be adaptable to different tasks, and which often serve as building blocks for more complex ones. A few popular examples include the Laplace mechanism , Gaussian mechanism , and Exponential mechanism . We only provide the details of the last technique, since the other two techniques are out-of-scope for the methods and experiments in this paper.

Exponential mechanism:The exponential mechanism is designed for discrete output space, Suppose \(=\{_{i}:i\}\) for some index set \(\), and let \(u:^{n}\) be score function that measures the quality of \(\). Denote by \( u_{K}\) the global sensitivity of the score function \(u\), i.e.

\[ u_{K}:=_{}_{D,\,D^{}}|u(,D)-u(,D^{})|.\]

  Paper & Method & \(_{min}\) cond. & failure prob. \(\) 0 & runtime \\  
 & Exp-Mech & NA & NA & exp \\  & Lasso + Samp-Agg & \((}})\) & yes & poly \\ 
 & Lasso + Sub-samp. stability & \((})\) & no & poly \\  & Lasso + Pert. stability & \((\{},}{ n}\})\) & no & poly \\ 
 & Exp-Mech & \((\}})\) & yes & exp \\ 
**This paper** & Exp-Mech & \((\}})\) & yes & exp \\  & Approx. Exp-Mech via MCMC & \((\}})\) & yes & poly \\  

Table 1: Comparison of DP model selection methods.

Intuitively, sensitivity quantifies the effect of any individual in the dataset on the outcome of the analysis. The score function \(u(,)\) is called _data monotone_ if the addition of a data record can either increase (decrease) or remain the same with any outcome, e.g., \(u(,D) u(,D\{z\})\). Next, we have the following result.

**Lemma 2.2** ([8; 31]).: _Exponential mechanism \(_{E}(D)\) that outputs samples from the probability distribution_

\[(_{E}(D)=)\{\}\] (3)

_preserves \((2,0)\)-differential privacy. If \(u(,)\) is data monotone, then we have \((,0)\)-differential privacy._

In general, if the \(\) is too large, the sampling from the distribution could be computationally inefficient. However, we show below that the special structure of the linear model (1) allows us to design an MCMC chain that can generate approximate samples _efficiently_ from the distribution (3) for privately solving BSS under an appropriately chosen score function.

## 3 Best Subset Selection

We briefly review the preliminaries of BSS, one of the most classical variable selection approaches. For a given sparsity level \(\), BSS solves for \(}_{}():=_{ ^{p},\|\|_{0} {s}}\|-\|_{2}^{2}.\) For model selection purposes, we can choose the best fitting model to be \(_{}():=\{j:[}_{}()]_{j} 0\}\). For a subset \([p]\), define the matrix \(_{}:=(_{j};j)\). Let \(_{}:=_{}(_{}^{} _{})^{-1}_{}^{}\) be orthogonal projection operator onto the column space of \(_{}\). Also, define the corresponding residual sum of squares (RSS) for model \(\) as \(L_{}(,):=^{}(_{n}- _{})\). With this notation, the \(_{}()\) can be alternatively written as

\[_{}():=_{[p]: |}L_{}(,).\] (4)

Let \(_{}\) be the matrix comprised of only the columns of \(\) with indices in \(\), and \(_{}\) denotes the orthogonal projection matrix onto the column space of \(_{}\). In addition, let \(}:=n^{-1}^{}\) be the sample covariance matrix and for any two sets \(_{1},_{2}[p]\), \(}_{_{1},_{2}}\) denotes the submatrix of \(\) with row indices in \(_{1}\) and column indices in \(_{2}\). Finally, define the collection \(_{z}:=\{[p]:^{*},||=\}\), and for \(_{}\) write \(()=}_{^{*},^ {*}}-}_{^{*}, }}_{,^{*}}^{-1} }_{,^{*}}\). Then, it follows that \(_{^{*}}^{}() _{^{*}}\) is equal to the _residualized_ signal strength \(n^{-1}\|(_{n}-_{})_{^{*} }_{^{*}}\|_{2}^{2}\). Therefore, \(_{^{*}}^{}() _{^{*}}\) quantifies the separation between \(\) and the true model \(^{*}\). Ideally, a larger value of the quantity will help BSS to discriminate between \(^{*}\) and any other candidate model \(\). More details on this can be found in . Now we are ready to introduce the identifiability margin that characterizes the _model discriminative power_ of BSS.

### Identifiability Margin

The discussion in Section 3 motivates us to define the following _identifiablity margin_:

\[_{*}():=_{_{}} {_{^{*}}^{}() _{^{*}}}{|^{*}|}.\] (5)

As mentioned earlier, the quantity \(_{*}()\) captures the model discriminative power of BSS. To add more perspective, note that if the features are highly correlated among themselves then it is expected that \(_{*}()\) is very close to \(0\). Hence, any candidate model \(\) is practically indistinguishable from the true model \(^{*}\) which in turn makes the problem of exact model recovery harder. On the contrary, if the features are uncorrelated then \(_{*}()\) becomes bounded away from 0 making the true model \(^{*}\) easily recoverable. For example,  showed that under the knowledge of true sparsity, i.e., when \(=s\), the condition

\[_{*}(s)^{2},\] (6)

is sufficient for BSS to achieve model consistency. One can also view \(_{*}(s)\) as a quantifier of the coupled effect of model correlation and signal strength. If we define the minimum and maximum eigenvalues over all models to be \(_{*}=_{_{s}}_{min}(())\) and \(^{*}=_{_{s}}_{max}(())\) respectively, then it follows that

\[_{*}_{min}^{2}_{*}(s)^{*}_{min}^{2}.\]

Therefore, it suffices to have \(_{min}\{( p)/(n_{*})\}^{1/2}\) in order to satisfy condition (6). In this case, \(_{*}\) captures the degree of model correlation, and \(_{min}\) is the minimum signal strength. Similar to our previous discussion, if there is high collinearity in the model, \(_{*}\) will be typically small, and BSS needs a large value of \(_{min}\) to identify the true model \(^{*}\). On the other hand, if \(_{min}\) is too small for a given level of model correlation, i.e, if \(_{min}\{( p)/(n^{*})\}^{1/2}\), then also BSS fails to achieve model consistency as it is hard to identify active features under the presence of weak signals [17, Theorem 2.1]. As we will see in the next section, the DP BSS algorithm also requires a margin condition similar to (6) to ensure model recovery, and this is indeed an indispensable condition as it is needed even in non-private case.

### Differentially Private BSS and Utility Analysis

In order to privatize the optimization problem in (4), we will adopt the exponential mechanism discussed in Section 2.2. In particular, for a tuning parameter \(K>0\), we consider the score function

\[u_{K}(;,):=-_{^{ 2}:\|\|_{1} K}\|-_ {}\|_{2}^{2}\,\]

and for a given privacy budget \(>0\), we sample \(_{s}\) from the distribution

\[()\{(;, )}{ u_{K}}\}(_{s}\{ ^{*}\}).\] (7)

As we are concerned with the exact recovery \(^{*}\), from here on we assume \(=s\). The above algorithm is essentially the same as Algorithm 4 in ; however, they do not introduce the extra \(_{1}\)-constraint on the parameter space. Instead, their algorithm needs the loss-term \((y-_{}^{})^{2}\) to be bounded by a constant for every possible choice of \(,y,\) and \(\). This assumption is not true in general for the squared error loss, and to remedy this issue, we introduce the extra \(_{1}\)-constraint in the score function. This is a common strategy that is used to guarantee worst-case sensitivity bound and similar methods also have been adopted in  to construct private estimators. Next, we present the following lemma that shows the data-monotonicity of the proposed score function.

**Lemma 3.1**.: _The score function \(u_{K}(;)\) in (7) is data monotone._

Therefore, Lemma 2.2 automatically guarantees that the above procedure is \((,0)\)-DP. However, in practice, we need an explicit form for \( u_{K}\) to carry out the sampling method, and it is also needed to analyze the utility guarantee of the exponential mechanism. To provide a concrete upper bound on the global sensitivity of \(u_{K}(;)\), we make the following boundedness assumption on the database:

**Assumption 3.2**.: _There exists positive constants \(r,x_{}\) such that \(_{y}|y| r,_{} \|\|_{} x_{}\)._

Under this assumption, the following lemma provides an upper bound on the global sensitivity of the score function along with the DP guarantee.

**Lemma 3.3** (Sensitivity bound and DP).: _Under Assumption 3.2, the global sensitivity \( u_{K}\) is bounded by \(_{K}:=(r+x_{}K)^{2}\). Therefore, the exponential mechanism (7) with \( u_{K}\) replaced by \(_{K}\) satisfies \((,0)\)-DP._

The above lemma provides an upper bound on the global sensitivity of the score function rather than finding the exact value of it. However, to guarantee \((,0)\)-DP property of exponential mechanism, it suffices to use the upper bound of \( u_{K}\) in (7). Now we will shift towards the utility analysis of the proposed exponential mechanism. First, we require some technical assumptions.

**Assumption 3.4**.: _We assume the following hold:_

* _There exists positive constants_ \(b_{}\) _such that_ \(\|\|_{1} b_{}\)_._
* _There exists positive constants_ \(_{-},_{+}\) _such that_ \[_{-}_{}(_{}^{}_{ }/n)_{}(_{}^{}_ {}/n)_{+},\] (8) _for all_ \(_{s}\{^{*}\}\)_.__._
3. _The true sparsity level_ \(s\) _follows the inequality_ \(s n/( p)\)_._

Assumption 3.4(a) tells that the true parameter \(\) lies inside a \(_{1}\)-ball. Similar boundedness assumptions are fairly standard in privacy literature [49; 29; 6]. Assumption 3.4(b) is a well-known assumption in the high-dimensional literature [54; 22; 32] which is known as the Sparse Riesz Condition (SRC). Finally, Assumption 3.4(c) essentially assumes that the \(s=o(n)\), i.e., sparsity grows with a sufficiently small rate compared to the sample size \(n\).

**Theorem 3.5** (Utility guarantee).: _Let the conditions in Assumption 3.2 and Assumption 3.4 hold. Set \(K\{(_{+}/_{-})b_{}+(8x_{}/_{-}) \}\). Then, under the data generative model (1), there exist universal positive constants \(c_{1},C_{1}\) such that whenever_

\[_{*}(s) C_{1}^{2}\{1,}{ ^{2}}\},\] (9)

_with probability at least \(1-c_{1}p^{-2}\) we have \((^{*}) 1-p^{-2}\)._

Cost of privacy.Theorem 3.5 essentially says that whenever the identifiability margin is large enough, the exponential mechanism outputs the true model \(^{*}\) with high probability. Note that \(_{K}/^{2}=(s)\). In the low privacy regime, i.e., for \(>_{K}/^{2}\) we only require \(_{*}(s)^{2}( p)/n\) to achieve model consistency and this matches with the optimal rate for model consistency of non-private BSS. Note that, the margin condition does not depend at all on \(\) in this regime. In contrast, in a high privacy regime, i.e., for \(<_{K}/^{2}\), Condition (9) essentially demands \(_{*}(s)^{2}(s p)/(n)\) to achieve model consistency. Thus, in a high privacy regime, we pay an extra factor of \((s/)\) in the margin requirement.

**Remark 3.6**.: _The failure probability in Theorem 3.5 can be improved to \(O(p^{-M})\) for any arbitrary integer \(M>2\). However, we have to pay a cost in the universal constant \(C_{1}\) in terms of a multiplicative constant larger than 1._

**Remark 3.7**.: _Under Assumption 3.4(b), it follows that \(_{*}_{-}\). Therefore, it suffices to have \(_{j^{*}}_{j}^{2}(^{2}}{_{-} })\{1,_{K}/(^{2})\}\) in order to hold condition (9). Therefore, in high-privacy regime, our method requires \(_{j^{*}}|_{j}|\{(s p)/(n_{ -})\}^{1/2}\). In contrast, under the low-privacy regime, we retrieve the optimal requirement \(_{j^{*}}|_{j}|\{( p)/(n_{-})\}^{1/2}\)._

## 4 Efficient Sampling through MCMC

In this section, we will propose an efficient sampling method to generate approximate samples from the distribution (7). One of the challenges of sampling methods in high-dimension is their high computational complexity. For example, the distribution in (7) places mass on all \(\) subsets of \([p]\), and it is practically infeasible to sample \(\) from the distribution as we have to essentially explore over an exponentially large space. This motivates us to resort to sampling techniques based on MCMC, through which we aim to obtain approximate samples from the distribution in (7). Past works on MCMC algorithms for Bayesian variable selection can be divided into two main classes - Gibbs sampler [15; 24; 34] and Metropolis-Hastings [18; 28]. In this paper, we focus on a particular form of Metropolis-Hastings updates.

In general terms, Metropolis-Hastings (MH) random walk is an iterative and local-move based method involving three steps:

1. Given the current state \(\), construct a neighborhood \(()\) of proposal states.
2. Choose a new state \(^{}()\) according to some proposal distribution \((,)\) over the neighborhood \(()\).
3. Move to the new state \(^{}\) with probability \((,^{})\), and stay in the original state \(\) with probability \(1-(,^{})\), where the acceptance probability is given by \[(,^{})=\{1,) (^{},)}{()(,^{ })}\},\] where \(()\) is same as in Equation (7).

This procedure generates a Markov chain for any choice of the neighborhood structure \(()\) with the following transition probability:

\[_{}(,^{})=(, ^{})(,^{}),&^{} (),\\ 1-_{^{}}_{}(,^{ }),&^{}=,\\ 0,&.\]

The specific form of Metropolis-Hastings update analyzed in this paper is obtained by following the _double swap update_ scheme to update \(\).

Double swap update:Let \(_{}\{^{*}\}\) be the initial state. Choose an index pair \((k,)^{c}\)_uniformly_ at random. Construct the new state \(^{}\) by setting \(^{}=\{\}\{k\}\).

The above scheme can be viewed as a general MH update scheme when \(()\) is the collection of all models \(^{}\) which can be obtained by swapping two distinct coordinates of \(\) and \(^{c}\) respectively. Thus, letting \(d_{H}(,^{})=|^{}|+|^{ }|\) denote the Hamming distance between \(\) and \(^{}\), the neighborhood is given by \(()=\{^{} d_{H}(,^{})=2, \;\;(k,)^{c}\;\;^{ }=\{\}\{k\}\}\). With this definition, the transition matrix of the previously described Metropolis-Hastings scheme can be written as follows:

\[_{}(,^{})=|}\{1,)}{()}\},&^{}(),\\ 1-_{^{}}_{}(,^{ }),&^{}=,\\ 0,&.\] (10)

### Mixing Time and Approximate DP

Let \(\) be a Markov chain on the discrete space \(\) with a transition probability matrix \(^{||||}\) with stationary distribution \(\). Throughout our discussion, we assume that \(\) is reversible, i.e., it satisfies the balanced condition \(()(,^{})=(^{})( ^{},)\) for all \(,^{}\). Note that the previously described transition matrix \(_{}\) in (10) satisfies the reversibility condition. It is convenient to identify a reversible chain with a weighted undirected graph \(G\) on the vertex set \(\), where two vertices \(\) and \(^{}\) are connected if and only if the edge weight \((,^{}):=()(,^{ })\) is strictly positive. For \(\) and any subset \(S\), we write \((,S)=_{^{} S}(,^{ })\). If \(\) is the initial state of the chain, then the total variation distance to the stationary distribution after \(t\) iterations is

\[_{}(t)=\|^{t}(,)-()\|_{ }:=_{S}|^{t}(,S)-(S) |.\]

The \(\)-mixing time is given by

\[_{}:=_{}\{t_{ }(t^{})t^{} t\},\] (11)

which measures the number of iterations needed for the chain to be within distance \((0,1)\) of the stationary distribution.

Privacy of MCMC estimator:Now, we will show that once the MH chain in (10) has mixed with its stationary distribution \(()\) defined in (7), the model estimators at each iteration will enjoy approximate DP. To fix the notation, let \(_{t}\) be the \(t\)th iteration of the MH chain in (10). Then, we have the following useful lemma:

**Lemma 4.1**.: _The model estimator \(_{_{}}\) is \((,)\)-DP with \(=(1+e^{})\)._

The above lemma shows that smaller \(\) entails a better privacy guarantee for a fixed level \(\) as \(\) decreases with \(\). Therefore, allowing more mixing of the chain will provide better privacy protection. However, this raises a concern about how long a practitioner must wait until the chain archives \(\)-mixing. In particular, it is important to understand how \(_{}\) scales in the difficulty parameters of the problem, for example, the dimension of the parameter space and sample size. In our case, we are interested in the covariate dimension \(p\), sample size \(n\), sparsity \(s\), and the privacy parameter \(\). In the next section, we will show that the chain with transition matrix (10) enjoys rapid mixing, meaning that the mixing time \(_{}\) grows at most at a polynomial rate in \(p,s\) and the sample size \(n\).

### Rapid Mixing of MCMC

We now turn to develop sufficient conditions for MH scheme (10) to be rapidly mixing. To this end, we make a technical assumption on the design matrix. Essentially, the following assumption controls the amount of correlation between active features and spurious features.

**Assumption 4.2**.: _For every \(^{}_{s}\{^{*}\}\), there exists \(k^{*}^{}\) such that_

\[_{j^{*}^{}}_{j}^{ }(_{n}-_{^{}})_{k}|}{ \|(_{n}-_{^{}})_{k}\|_ {2}} b_{}^{-1}C_{1}^{2}/2) p},\]

_where \(C_{1}\) is the same universal positive constant as in Theorem 3.5._

First, note that Assumption 4.2 basically controls the length of the projection of the feature \(_{j}\) on the unit vector \(_{k}:=(_{n}-_{^{}})_{k }/\|(_{n}-_{^{}})_{k}\| _{2}\). Therefore, the above inequality restricts the correlation between an active feature \(_{j}\) and the spurious scaled feature \(_{k}\) from being too large. To this end, we emphasize that stronger assumptions on model correlation (on top of the SRC condition) are common in literature for establishing the computational efficiency of Bayesian variable selection methods involving MH algorithm. For example, to show the computational efficiency MH algorithm under Zellner's \(g\)-prior,  assumes

\[_{:|| s_{0}}\|(_{}^{}_ {})^{-1}_{}^{}_{^{*} }\|_{}^{2}=O(),\] (12)

where \(s_{0}\) (larger than \(s\)) is a specific tuning parameter of their algorithm that controls the model size. The assumption in the above display is akin to the well-known irrepresentability condition  which is a very strong assumption on the design. On a high level, at any given current state \(\), Assumption 4.2 or Condition (12) helps to identify a good local move towards the true model \(^{*}\) in the MH algorithm via deletion of the least influential covariate in \(\). Now, we present our main result for the mixing time of MCMC.

**Theorem 4.3** (Rapid mixing time).: _Let the conditions in Assumption 3.2, Assumption 3.4 and Assumption 4.2 hold. Then, under the data generative model (1), there exists a universal constant \(C_{1}^{}>0\) such that under the margin condition_

\[_{*}(s) C_{1}^{}^{2}\{1,}{(_{-} 1)^{2}}\},\] (13)

_there exist universal positive constants \(c_{2},C_{2}\) such that the mixing time \(_{}\) of the MCMC chain (10) enjoys the following with probability at least \(1-c_{2}p^{-2}\):_

\[_{} C_{2}p^{8}\{n^{-1}_{+}b_{}^{ 2}+(1/)\},\] (14)

_where \(=\{r+(_{+}/_{-})b_{}x_{}+(/ _{-})x_{}^{2}\}^{2}\)._

The main technical innovation in the theorem is the double swap updating scheme in the MCMC that allows us to leverage the _canonical path ensemble_ construction argument  to prove the bound (14) on the mixing time. Essentially, we show that under Assumption 4.2, there exists a canonical path in a specially weighted graph corresponding to the MCMC random walk with low path congestion. The complete proof can be found in Appendix A.5.

Regarding the statement of the theorem, note that the margin condition (13) is slightly stronger than the margin condition in Theorem 3.5. Under that condition, the above theorem shows that the \(\)-mixing time of the MCMC algorithm designed for approximate sampling from the distribution (7) grows at a polynomial rate in \((n,p,s)\). Recall that according to the previous definition (11) of the mixing time, Theorem 4.3 characterizes the _worst-case_ mixing time, meaning the number of iterations when starting from the worst possible initialization. If we start with a good initial state -- for example, the true model \(^{*}\) would be an ideal though impractical choice - then we can remove the \(n\) term in the upper bound in (14). Therefore, the bound in (14) can be thought of as the worst-case number of iterations required in the burn-in period of the MCMC algorithm. Furthermore, it is important to point out that Assumption 4.2 is only needed to ensure the "quick" mixing time of the MCMC chain. It is possible to relax this assumption, however, in that case, the MCMC chain is not guaranteed to mix under polynomial time. Nonetheless, given enough iterations, the chain will indeedconverge to the distribution (7) as MH algorithm always generates an ergodic chain that eventually mixes to its stationary distribution.

It is interesting to note that Theorem 4.3 suggests that in a large \(\) regime, the chain mixes slower compared to the small \(\) regime. The main reason for this is that Theorem 4.3 only relies on worst-case analysis. The intuition is the following: When \(\) is very large, then the target distribution is essentially fully concentrated on \(^{*}\) (assuming the score for \(^{*}\) is highest). Now, the current analysis of Theorem 4.3 does not assume any condition on the initial state of the MCMC chain. It treats the initial state \(_{0}\) as if it is chosen in a completely random manner, i.e., it is the worst case. From this point of view, it is hard for a completely uninformative distribution to converge to a target distribution that is concentrated on a single subset (very informative), and resulting in a longer mixing time. Finally, Theorem 4.3 leads to the following corollary:

**Corollary 4.4**.: _Let \(_{t}\) denote the distribution of the \(t\)th iterate \(_{t}\) of the MCMC scheme (10). Then, under the conditions of Theorem 3.5 and Theorem 4.3, there exists a universal constant \(c_{3}>0\) such that for any fixed iteration \(t\) such that \(t C_{2}p^{2}\{n^{-1}_{+}b_{}^{2}+(1/)\},\) we have \(_{t}(^{*}) 1--p^{-2}\) with probability at least \(1-c_{3}p^{-2}\)._

The above corollary is useful in the sense that it provides a quantitative choice of \(\) that yields high utility of the estimator \(_{t}\). For example, if we set \(=p^{-2}\) and \(=O(1)\), then for any \(t ps^{2}(n+ p)\) the resulting sample \(_{t}\) will match \(^{*}\) with probability \(1-c_{3}p^{-2}\).

**Remark 4.5**.: _Similar to Remark 3.6, the failure probability in Theorem 4.3 and Corollary 4.4 can be improved to \(O(p^{-M})\) for arbitrary large \(M>2\), but at the cost of paying higher values for the absolute constants \(C_{1}^{}\) and \(C_{2}\)._

## 5 Numerical experiments

In this section, we will conduct some illustrative simulations. To compare the quality of the DP model estimator, we compare F-score of the estimated model with that of the true model \(^{*}\) and the BSS estimator. As the actual BSS is computationally infeasible, we use the adaptive best subset selection (ABESS) algorithm  as a computational surrogate to BSS. Throughout this section, we assume that the true sparsity \(s\) is known, i.e., we provide the knowledge of \(s\) to the algorithm. All codes are available at https://github.com/roysaptaumich/DP-BSS.

Uniform design.We consider a random design matrix, formed by choosing each entry from the distribution \((-1,1)\) in i.i.d. fashion. In detail, we set \(n=900,p=2000\), and the sparsity level \(s=4\). We generate the entries of the noise \(\) independently from \((-0.1,0.1)\), and consider the linear model (1). We choose the design vector \(\) with true sparsity \(s=4\) and the support set \(^{*}=\{j:1 j 4\}\). We set all the signal strength to be equal, taking the following two forms: (i) **Strong signal:**\(_{j}=2\{(s p)/n\}^{1/2}\), and (ii) **Weak signal:**\(_{j}=2\{( p)/n\}^{1/2}\) for all \(j^{*}\).

Under these setups, we consider the privacy parameter \(\{0.5,1,3,5,10\}\) which are acceptable choices of \(\). Moreover, similar (or larger) choices of \(\) are common in various applications including US census study , socio-economic study , and industrial applications . For the Metropolis-Hastings random walk, we vary \(K\{0.5,2,3,3.5\}\) and initialize 10 independent Markov chains from random initializations and record the F-score of the last iteration. We use the CVXPY package  for solving the \(_{1}\)-constrained optimization problem in the updating step of MCMC. We also track the qualities of the model through its explanatory power for convergence diagnostics. In particular, we calculate the scale factor \(R_{}:=^{}_{}/\| \|_{2}^{2}\) for each model update along the random walk and compare those with \(R_{}_{}}\) to heuristically gauge the quality of mixing. More details and a set of comprehensive plots can be found in Appendix D.1 where we also discuss more about the effect of \(\) and \(K\) on the utility. For \(K=2\), Table 2 shows that F-score increases as \(\) increases both in the cases of strong and weak signals. In fact, for \( 3\), the performance of the algorithm is on par with the non-private BSS. This is consistent with the inflection phenomenon pointed out in Theorem 3.5 and Corollary 4.4. Furthermore, as expected, we see that for a fixed \(\), the F-score is generally higher in the strong signal case.

We also carry out experiments under independent Gaussian design. The details and more comprehensive discussion of the findings are deferred to Appendix D.2. In summary, in this case also, our algorithm enjoys greater utility under the strong signal case as shown in Table 2.

Computational resources and license information :All the experiments were performed in the Great Lakes cluster with 16 cores and 10 GB RAM. ABESS package is distributed under GNU General Public License, Version 3. CVXPY package is distributed under Apache License, Version 2.

## 6 Conclusion

In this paper, we study the variable selection performance of BSS under the differential privacy constraint. In order to achieve (pure) differential privacy, we adopt the exponential mechanism and establish its high statistical utility guarantee in terms of exact model recovery. Furthermore, for computational efficiency, we design a MH random walk that provably mixes with the stationary distribution within a mixing time of the polynomial order in \((n,p,s)\). We also show that the samples from the MH random walk enjoy approximate DP while retaining a high utility guarantee with experimental underpinnings. In summary, as discussed in Section 1.1, we establish both high utility and efficient computational guarantee for our model selection algorithm under privacy constraints, which is in sharp contrast with the previous works in DP model selection literature. Moreover, the proposed MCMC method is generic enough to adopt in other models beyond linear structures. For example, one can use this technique under the setup of generalized linear models with likelihood loss as the utility function. Therefore, our method can be used in diverse domains including medical studies to fast-track scientific discoveries and promote the practice of responsible AI.

To this end, we also point out some of the open problems and future directions. One limitation, of our main result Theorem 3.5 is that it requires the condition \(_{j^{*}}|_{j}|=()\) in high-privacy regime. It is still an open question whether the extra \(\) factor is necessary for model selection. Future research along this line could focus on solving BSS through DP mixed integer optimization (MIO). This would mean an important contribution in this field as commercial solvers like GUROBI or MOSEK would be capable of solving the BSS problems at an industrial scale with high computational efficiency using a general DP framework.