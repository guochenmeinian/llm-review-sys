# A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised Learning

Yiyou Sun, Zhenmei Shi, Yixuan Li

Department of Computer Sciences

University of Wisconsin, Madison

{suniyiyou,zhmeishi,sharonli}@cs.wisc.edu

###### Abstract

Open-world semi-supervised learning aims at inferring both known and novel classes in unlabeled data, by harnessing prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for this problem. This paper bridges the gap by formalizing a graph-theoretic framework tailored for the open-world setting, where the clustering can be theoretically characterized by graph factorization. Our graph-theoretic framework illuminates practical algorithms and provides guarantees. In particular, based on our graph formulation, we apply the algorithm called Spectral Open-world Representation Learning (SORL), and show that minimizing our loss is equivalent to performing spectral decomposition on the graph. Such equivalence allows us to derive a provable error bound on the clustering performance for both known and novel classes, and analyze rigorously when labeled data helps. Empirically, SORL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees. Our code is available at https://github.com/deeplearning-wisc/sorl.

## 1 Introduction

Machine learning models in the open world inevitably encounter data from both known and novel classes [2; 15; 16; 65; 79]. Traditional supervised machine learning models are trained on a closed set of labels, and thus can struggle to effectively cluster new semantic concepts. On the other hand, open-world semi-supervised learning approaches, such as those discussed in studies [7; 63; 69], enable models to distinguish _both known and novel classes_, making them highly desirable for real-world scenarios. As shown in Figure 1, the learner has access to a labeled training dataset \(_{l}\) (from known classes) as well as a large unlabeled dataset \(_{u}\) (from both known and novel classes). By optimizing feature representations jointly from both labeled and unlabeled data, the learner aims to create meaningful cluster structures that correspond to either known or novel classes. With the explosive growth of data generated in various

Figure 1: Open-world Semi-supervised Learning aims to correctly cluster samples in the novel class and classify samples in the known classes by utilizing knowledge from the labeled data. An open question is _“what is the role of the label information in shaping representations for both known and novel classes?”_ This paper aims to provide a formal understanding.

domains, open-world semi-supervised learning has emerged as a crucial problem in the field of machine learning.

**Motivation.** Different from self-supervised learning [5; 8; 11; 12; 23; 26; 68; 77], open-world semi-supervised learning allows harnessing the power of the labeled data for possible knowledge sharing and transfer to unlabeled data, and from known classes to novel classes. In this joint learning process, we argue that interesting intricacies can arise--the labeled data provided may be beneficial or unhelpful to the resulting clusters. We exemplify the nuances in Figure 1. In one scenario, when the model learns the labeled known classes (e.g., traffic light) by pushing red and green lights closer, such a relationship might transfer to help cluster green and red apples into a coherent cluster. Alternatively, when the connection between the labeled data and the novel class (e.g., flower) is weak, the benefits might be negligible. We argue--perhaps obviously--that a formalized understanding of the intricate phenomenon is needed.

**Theoretical significance.** To date, theoretical understanding of open-world semi-supervised learning is still in its infancy. In this paper, we aim to fill the critical blank by analyzing this important learning problem from a rigorous theoretical standpoint. Our exposition gravitates around the open question: _what is the role of labeled data in shaping representations for both known and novel classes?_ To answer this question, we formalize a graph-theoretic framework tailored for the open-world setting, where the vertices are all the data points and connected sub-graphs form classes (either known or novel). The edges are defined by a combination of supervised and self-supervised signals, which reflects the availability of both labeled and unlabeled data. Importantly, this graph facilitates the understanding of open-world semi-supervised learning from a spectral analysis perspective, where the clustering can be theoretically characterized by graph factorization. Based on the graph-theoretic formulation, we derive a formal error bound by contrasting the clustering performance for all classes, before and after adding the labeling information. Our Theorem 4.2 reveals the sufficient condition for the improved clustering performance for a class. Under the K-means measurement, the unlabeled samples in one class can be better clustered, if their overall connection to the labeled data is stronger than their self-clusterability.

**Practical significance.** Our graph-theoretic framework also illuminates practical algorithms with provided guarantees. In particular, based on our graph formulation, we present the algorithm called Spectral Open-world Representation Learning (SORL) adapted from Sun et al. . Minimizing this loss is equivalent to performing spectral decomposition on the graph (Section 3.2), which brings two key benefits: (1) it allows us to analyze the representation space and resulting clustering performance in closed-form; (2) practically, it enables end-to-end training in the context of deep networks. We show that our learning algorithm leads to strong empirical performance while enjoying theoretical guarantees. The learning objective can be effectively optimized using stochastic gradient descent on modern neural network architecture, making it desirable for real-world applications.

## 2 Problem Setup

We formally describe the data setup and learning goal of open-world semi-supervised learning .

**Data setup.** We consider the empirical training set \(_{l}_{u}\) as a union of labeled and unlabeled data.

1. The labeled set \(_{l}=\{_{i},y_{i}\}_{i=1}^{n}\), with \(y_{i}_{l}\). The label set \(_{l}\) is known.
2. The unlabeled set \(_{u}=\{_{i}\}_{i=1}^{m}\), where each sample \(_{i}\) can come from either known or novel classes1. Note that we do not have access to the labels in \(_{u}\). For mathematical convenience, we denote the underlying label set as \(_{}\), where \(_{l}_{}\). We denote \(C=|_{}|\) the total number of classes. 
The data setup has practical value for real-world applications. For example, the labeled set is common in supervised learning; and the unlabeled set can be gathered for free from the model's operating environment or the internet. We use \(_{l}\) and \(\) to denote the marginal distributions of labeled data and all data in the input space, respectively. Further, we let \(_{l_{i}}\) denote the distribution of labeled samples with class label \(i_{l}\).

**Learning target.** Under the setting, our goal is to learn distinguishable representations _for both known and novel classes_ simultaneously. The representation quality will be measured using classic metrics, such as K-means clustering accuracy, which we will define mathematically in Section 4.2.2. Unlike classic semi-supervised learning , we place no assumption on the unlabeled data and allow its semantic space to cover both known and novel classes. The problem is also referred to as open-world representation learning , which emphasizes the role of good representation in distinguishing both known and novel classes.

**Theoretical analysis goal.** We aim to comprehend the role of label information in shaping representations for both known and novel classes. It's important to note that our theoretical approach aims to understand the perturbation in the clustering performance by labeling existing, previously unlabeled data points within the dataset. By contrasting the clustering performance before and after labeling these instances, we uncover the underlying structure and relations that the labels may reveal. This analysis provides invaluable insights into how labeling information can be effectively leveraged to enhance the representations of both known and novel classes.

## 3 A Spectral Approach for Open-world Semi-Supervised Learning

In this section, we formalize and tackle the open-world semi-supervised learning problem from a graph-theoretic view. Our fundamental idea is to formulate it as a clustering problem--where similar data points are grouped into the same cluster, by way of possibly utilizing helpful information from the labeled data \(_{l}\). This clustering process can be modeled by a graph, where the vertices are all the data points and classes form connected sub-graphs. Specifically, utilizing our graph formulation, we present the algorithm -- Spectral Open-world Representation Learning (SORL) in Section 3.2. The process of minimizing the corresponding loss is fundamentally analogous to executing a spectral decomposition on the graph.

### A Graph-Theoretic Formulation

We start by formally defining the augmentation graph and adjacency matrix. For clarity, we use \(\) to indicate the natural sample (raw inputs without augmentation). Given an \(\), we use \((x|)\) to denote the probability of \(x\) being augmented from \(\). For instance, when \(\) represents an image, \((|)\) can be the distribution of common augmentations  such as Gaussian blur, color distortion, and random cropping. The augmentation allows us to define a general population space \(\), which contains all the original images along with their augmentations. In our case, \(\) is composed of augmented samples from both labeled and unlabeled data, with cardinality \(||=N\). We further denote \(_{l}\) as the set of samples (along with augmentations) from the labeled data part.

We define the graph \(G(,w)\) with vertex set \(\) and edge weights \(w\). To define edge weights \(w\), we decompose the graph connectivity into two components: (1) self-supervised connectivity \(w^{(u)}\) by treating all points in \(\) as entirely unlabeled, and (2) supervised connectivity \(w^{(l)}\) by adding labeled information from \(_{l}\) to the graph. We proceed to define these two cases separately.

First, by assuming all points as unlabeled, two samples (\(x\), \(x^{+}\)) are considered a **positive pair** if:

**Unlabeled Case (u):**\(x\) _and \(x^{+}\) are augmented from the same image \(\)._

For any two augmented data \(x,x^{}\), \(w^{(u)}_{xx^{}}\) denotes the marginal probability of generating the pair:

\[w^{(u)}_{xx^{}}_{} (x|)(x^{}|),\] (1)

which can be viewed as self-supervised connectivity . However, different from self-supervised learning, we have access to the labeled information for a subset of nodes, which _allows adding additional connectivity to the graph_. Accordingly, the positive pair can be defined as:

**Labeled Case (l):**\(x\) _and \(x^{+}\) are augmented from two labeled samples \(_{l}\) and \(^{}_{l}\) with the same known class \(i\). In other words, both \(_{l}\) and \(^{}_{l}\) are drawn independently from \(_{l_{i}}\)._

Considering both case (u) and case (l), the overall edge weight for any pair of data \((x,x^{})\) is given by:

\[w_{xx^{}}=_{u}w^{(u)}_{xx^{}}+_{l}w^{(l)}_{xx^{}}, w^{(l)}_{xx^{}}_{i_{l}}_{_ {l}_{l_{i}}}_{^{}_{l}_{l_ {i}}}(x|_{l})(x^{}|^{}_{l }),\] (2)and \(_{u},_{l}\) modulates the importance between the two cases. The magnitude of \(w_{xx^{}}\) indicates the "positiveness" or similarity between \(x\) and \(x^{}\). We then use \(w_{x}=_{x^{}}w_{xx^{}}\) to denote the total edge weights connected to a vertex \(x\).

**Remark: A graph perturbation view.** With the graph connectivity defined above, we can now define the adjacency matrix \(A^{N N}\) with entries \(A_{xx^{}}=w_{xx^{}}\). Importantly, the adjacency matrix can be decomposed into two parts:

(3)

which can be regarded as the self-supervised adjacency matrix \(A^{(u)}\) perturbed by additional labeling information encoded in \(A^{(l)}\). This graph perturbation view serves as a critical foundation for our theoretical analysis of the clustering performance in Section 4. As a standard technique in graph theory , we use the _normalized adjacency matrix_ of \(G(,w)\):

\[ D^{-}AD^{-},\] (4)

where \(D^{N N}\) is a diagonal matrix with \(D_{xx}=w_{x}\). The normalization balances the degree of each node, reducing the influence of vertices with very large degrees. The normalized adjacency matrix defines the probability of \(x\) and \(x^{}\) being considered as the positive pair from the perspective of augmentation, which helps derive the learning loss as we show next.

### SORL: Spectral Open-World Representation Learning

We present an algorithm called Spectral Open-world Representation Learning (SORL), which can be derived from a spectral decomposition of \(\). The algorithm has both practical and theoretical values. First, it enables efficient end-to-end training in the context of modern neural networks. More importantly, it allows drawing a theoretical equivalence between learned representations and the top-\(k\) singular vectors of \(\). Such equivalence facilitates theoretical understanding of the clustering structure encoded in \(\). Specifically, we consider low-rank matrix approximation:

\[_{F^{N k}}_{}(F,A) \|-FF^{}\|_{F}^{2}\] (5)

According to the Eckart-Young-Mirsky theorem , the minimizer of this loss function is \(F_{k}^{N k}\) such that \(F_{k}F_{k}^{}\) contains the top-\(k\) components of \(\)'s SVD decomposition.

Now, if we view each row \(_{x}^{}\) of \(F\) as a scaled version of learned feature embedding \(f:^{k}\), the \(_{}(F,A)\) can be written as a form of the contrastive learning objective. We formalize this connection in Theorem 3.1 below2.

**Theorem 3.1**.: _We define \(_{x}=}f(x)\) for some function \(f\). Recall \(_{u},_{l}\) are coefficients defined in Eq. (2). Then minimizing the loss function \(_{}(F,A)\) is equivalent to minimizing the following loss function for \(f\), which we term **Spectral Open-world Representation Learning (SORL)**:_

\[_{}(f)-2_{l}_{1}(f)-2_{u} _{2}(f)+_{l}^{2}_{3}(f)+2_{l}_{u} _{4}(f)+_{u}^{2}_{5}(f),\] (6)

_where_

\[_{1}(f) =_{i_{l}}}_{_{l}_{l_{i}},_{i}_{l_{i}},\\ x(|_{l}),x^{}(|_ {l}^{})}[f(x)^{}f(x^{+})], _{2}(f)=}_{_{u} _{l_{i}},\\ x(|_{u}),x^{}(|_ {u})}[f(x)^{}f(x^{+})],\] \[_{3}(f) =_{i,j_{l}}}_{_{l}_{l_{i}},_{l}^{}_{l_{j}},\\ x(|_{l}),x^{}(|_ {l}^{})}[(f(x)^{}f(x^{-}))^{ 2}],\] \[_{4}(f) =_{i_{l}}}_{_{l}_{l_{i}},_{u},\\ x(|_{l}),x^{-}(|_ {u})}[(f(x)^{}f(x^{-}))^{2} ],_{5}(f)=}_{_{ u},_{u}^{},\\ x(|_{u}),x^{-}(|_ {u})}[(f(x)^{}f(x^{-}))^{2} ].\]Proof.: _(sketch)_ We can expand \(_{}(F,A)\) and obtain

\[_{}(F,A)=_{x,x^{}}(}}{w_{x^{}}}}-_{x}^{}_{x^{ }})^{2}=const+_{x,x^{}}(-2w_{xx^{ }}f(x)^{}f(x^{})+w_{x}w_{x^{}}(f(x)^{ }f(x^{}))^{2})\]

The form of \(_{}(f)\) is derived from plugging \(w_{xx^{}}\) (defined in Eq. (1)) and \(w_{x}\). Full proof is in Appendix A. 

**Interpretation of \(_{}(f)\)**. At a high level, \(_{1}\) and \(_{2}\) push the embeddings of **positive pairs** to be closer while \(_{3}\), \(_{4}\) and \(_{5}\) pull away the embeddings of **negative pairs**. In particular, \(_{1}\) samples two random augmentation views of two images from labeled data with the **same** class label, and \(_{2}\) samples two views from the same image in \(\). For negative pairs, \(_{3}\) uses two augmentation views from two samples in \(_{l}\) with **any** class label. \(_{4}\) uses two views of one sample in \(_{l}\) and another one in \(\). \(_{5}\) uses two views from two random samples in \(\). This training objective, though bearing similarities to NSCL , operates within a distinct problem domain. Accordingly, we derive novel theoretical analysis uniquely tailored to our problem setting, which we present next.

## 4 Theoretical Analysis

So far we have presented a spectral approach for open-world semi-supervised learning based on graph factorization. Under this framework, we now formally analyze: _how does the labeling information shape the representations for known and novel classes?_

### An Illustrative Example

We consider a toy example that helps illustrate the core idea of our theoretical findings. Specifically, the example aims to distinguish 3D objects with different shapes, as shown in Figure 2. These images are generated by a 3D rendering software  with user-defined properties including colors, shape, size, position, etc. We are interested in contrasting the representations (in the form of singular vectors), when the label information is either incorporated in training or not.

**Data design.** Suppose the training samples come from three types, \(_{}\), \(_{}\), \(_{}\). Let \(_{}\) be the sample space with **known** class, and \(_{}\), \(_{}\) be the sample space with **novel** classes. Further, the two novel classes are constructed to have different relationships with the known class. Specifically, shares some similarity with \(_{}\) in color (red and blue); whereas another novel class \(_{}\) has no obvious similarity with the known class. Without any labeling information, it can be difficult to distinguish \(_{}\) from \(_{}\) since samples share common colors. We aim to verify the hypothesis that: _adding labeling information to \(_{}\)_(i.e., connecting \(\) and \(\)) has a larger (beneficial) impact to cluster \(_{}\) than \(_{}\)_.

Figure 2: An illustrative example for theoretical analysis. We consider a 6-node graph with one known class (cube) and two novel classes (sphere, cylinder). (a) The augmentation probabilities between nodes are defined by their color and shape in Eq. (7). (b) The adjacency matrix can then be calculated by Equations in Sec. 3.1 where we let \(_{0}=0,_{u}=6,_{l}=4\). The calculation details are in Appendix B. The magnitude order follows \(_{1}_{c}>_{s}>0\).

**Augmentation graph.** Based on the data design, we formally define the augmentation graph, which encodes the probability of augmenting a source image \(\) to the augmented view \(x\):

\[(x)=\{_{1}&(x)=(),(x)=();\\ _{c}&(x)=(),(x) ();\\ _{s}&(x)(),(x)= ();\\ _{0}&(x)(),(x)()..\] (7)

With Eq. (7) and the definition of the adjacency matrix in Section 3.1, we can derive the analytic form of \(A^{(u)}\) and \(A\), as shown in Figure 2(b). We refer readers to Appendix B for the detailed derivation. The two matrices allow us to contrast the connectivity changes in the graph, before and after the labeling information is added.**Insights.** We are primarily interested in analyzing the difference of the representation space derived from \(A^{(u)}\) and \(A\). We visualize the top-3 eigenvectors3 of the normalized adjacency matrix \(^{(u)}\) and \(\) in Figure 3(a), where the results are based on the magnitude order \(_{1}_{c}>_{s}>0\). Our key takeaway is: _adding labeling information to known class \(_{}\) helps better distinguish the known class itself and the novel class \(_{}\), which has a stronger connection/similarity with \(_{}\)._

**Qualitative analysis.** Our theoretical insight can also be verified empirically, by learning representations on over 10,000 samples using the loss defined in Section 3.2. Due to the space limitation, we include experimental details in Appendix E.1. In Figure 3(b), we visualize the learned features through UMAP . Indeed, we observe that samples become more concentrated around different shape classes after adding labeling information to the cube class.

### Main Theory

The toy example offers an important insight that the added labeled information is more helpful for the class with a stronger connection to the known class. In this section, we formalize this insight by extending the toy example to a more general setting. As a roadmap, we derive the result through three steps: **(1)** derive the closed-form solution of the learned representations; **(2)** define the clustering performance by the K-means measure; **(3)** contrast the resulting clustering performance before and after adding labels. We start by deriving the representations.

#### 4.2.1 Learned Representations in Analytic Form

**Representation without labels.** To obtain the representations, one can train the neural network \(f:^{k}\) using the spectral loss defined in Equation 6. We assume that the optimizer is capable to obtain the representation \(Z^{(u)}^{N k}\) that minimizes the loss, where each row vector \(_{i}=f(x_{i})^{}\). Recall that Theorem 3.1 allows us to derive a closed-form solution for the learned feature space by the spectral decomposition of the adjacency matrix, which is \(^{(u)}\) in the case without labeling information. Specifically, we have \(F_{k}^{(u)}=}Z^{(u)}\), where \(F_{k}^{(u)}F_{k}^{(u)}\) contains the

Figure 3: Visualization of representation space for toy example. (a) Theoretically contrasting the feature formed by top-3 eigenvectors of \(^{(u)}\) and \(\) respectively. (b) UMAP visualization of the features learned without (left) and with labeled information (right). Details are in Appendix B (eigenvector calculation) and Appendix E.1 (visualization setting).

top-\(k\) components of \(^{(u)}\)'s SVD decomposition and \(D^{(u)}\) is the diagonal matrix defined based on the row sum of \(A^{(u)}\). We further define the top-\(k\) singular vectors of \(^{(u)}\) as \(V_{k}^{(u)}^{N k}\), so we have \(F_{k}^{(u)}=V_{k}^{(u)}^{(u)}}\), where \(_{k}^{(u)}\) is a diagonal matrix of the top-\(k\) singular values of \(^{(u)}\). By equalizing the two forms of \(F_{k}^{(u)}\), the closed-formed solution of the learned feature space is given by \(Z^{(u)}=[D^{(u)}]^{-}V_{k}^{(u)}^{(u)}}\).

**Representation perturbation by adding labels.** We now analyze how the representation is "perturbed" as a result of adding label information. We consider \(|_{l}|=1^{4}\) to facilitate a better understanding of our key insight. We can rewrite \(A\) in Eq. 3 as:

\[A()_{u}A^{(u)}+^{},\]

where we replace \(_{l}\) to \(\) to be more apparent in representing the perturbation and define \(^{N},()_{x}=_{_{l} _{l_{1}}}(x|_{l})\). Note that \(\) can be interpreted as the vector of "_the semantic connection for sample \(x\) to the labeled data_". One can easily extend to \(r\) classes by letting \(^{N r}\).

Here we treat the adjacency matrix as a function of the perturbation. In a similar manner as above, we can derive the normalized adjacency matrix \(()\) and the feature representation \(Z()\) in closed form. The details are included in Appendix C.4.

#### 4.2.2 Evaluation Target

With the learned representations, we can evaluate their quality by the clustering performance. Our theoretical analysis of the clustering performance can well connect to empirical evaluation strategy in the literature  using \(K\)-means clustering accuracy/error. Formally, we define the ground-truth partition of clusters by \(=\{_{1},_{2},...,_{C}\}\), where \(_{i}\) is the set of samples' indices with underlying label \(y_{i}\) and \(C\) is the total number of classes (including both known and novel). We further let \(_{}=_{i}_{i}\) be the center of features in \(\), and the average of all feature vectors be \(_{}=_{j[N]}_{j}\).

The clustering performance of K-means depends on two measurements: **Intra-class** measure and **Inter-class** measure. Specifically, we let the intra-class measure be the average Euclidean distance from the samples' feature to the corresponding cluster center and we measure the inter-class separation as the distances between cluster centers:

\[_{}(,Z)_{}_{i }\|_{i}-_{}\|^{2},_{}(,Z)_{}||\|_{ }-_{}\|^{2}.\] (8)

Strong clustering results translate into low \(_{}\) and high \(_{}\). Thus we define the **K-means measure** as:

\[_{kms}(,Z)_{}(,Z)/ _{}(,Z).\] (9)

We also formally show in Theorem 4.1 that the K-means clustering error5 is asymptotically equivalent to the K-means measure we defined above.

**Theorem 4.1**.: _(**Relationship between the K-means measure and K-means error.**) We define the \(_{^{}}\) as the index set of samples that is from class division \(\) however is closer to \(_{^{}}\) than \(_{}\). In other word, \(_{^{}}=\{i:i,\|_{i}-_{}\|_{2} \|_{i}-_{^{}}\|_{2}\}\). Assuming \(|_{^{}}|>0\), we define below the clustering error ratio from \(\) to \(^{}\) as \(_{^{}}\) and the overall cluster error ratio \(_{,Z}\) as the Harmonic Mean of \(_{^{}}\) among all class pairs:_

\[_{,Z}=C(C-1)/(_{^{}\\ ,^{}}_{^{} }}),_{^{}}=}|}{|^{ }|+||}.\]

_The K-means measure \(_{kms}(,Z)\) has the same order of the Harmonic Mean of the cluster error ratio between all cluster pairs with proof in Appendix C.3._

\[_{,Z}=O(_{kms}(,Z)).\]

[MISSING_PAGE_FAIL:8]

## 5 Empirical Validation of Theory

Beyond theoretical insights, we show empirically that SORL is effective on standard benchmark image classification datasets CIFAR-10/100 . Following the seminal work ORCA , classes are divided into 50% known and 50% novel classes. We then use 50% of samples from the known classes as the labeled dataset, and the rest as the unlabeled set. We follow the evaluation strategy in  and report the following metrics: (1) classification accuracy on known classes, (2) clustering accuracy on the novel data, and (3) overall accuracy on all classes. More experiment details are in Appendix E.2.

**SORL achieves competitive performance.** Our proposed loss SORL is amenable to the theoretical understanding, which is our primary goal of this work. Beyond theory, we show that SORL is equally desirable in empirical performance. In particular, SORL displays competitive performance compared to existing methods, as evidenced in Table 1. Our comparison covers an extensive collection of very recent algorithms developed for this problem, including ORCA , GCD , and OpenCon . We also compare methods in related problem domains: (1) Semi-Supervised Learning [21; 37; 62], (2) Novel Class Discovery [22; 82], (3) common representation learning method SimCLR . In particular, on CIFAR-100, we improve upon the best baseline OpenCon by **3.4%** in terms of overall accuracy. Our result further validates that putting analysis on SORL is appealing for both theoretical and empirical reasons.

## 6 Broader Impact

From a theoretical perspective, our graph-theoretic framework can facilitate and deepen the understanding of other representation learning methods that commonly involve the notion of positive/negative pairs. In Appendix D, _we exemplify how our framework can be potentially generalized to other common contrastive loss functions_[11; 34; 68], and baseline methods that are tailored for the open-world semi-supervised learning problem (e.g., GCD , OpenCon ). Hence, we believe our theoretical framework has a broader utility and significance.

From a practical perspective, our work can directly impact and benefit many real-world applications, where unlabeled data are produced at an incredible rate today. Major companies exhibit a strong need for making their machine learning systems and services amendable for the open-world setting but lack fundamental and systematic knowledge. Hence, our research advances the understanding of open-world machine learning and helps the industry improve ML systems by discovering insights and structures from unlabeled data.

## 7 Related Work

**Semi-supervised learning.** Semi-supervised learning (SSL) is a classic problem in machine learning. SSL typically assumes the same class space between labeled and unlabeled data, and hence remains closed-world. A rich line of empirical works [9; 13; 21; 29; 37; 38; 39; 42; 48; 50; 53; 54; 74; 76; 78] and theoretical efforts [3; 46; 47; 51; 60; 61; 73] have been made to address this problem. An important class of SSL methods is to represent data as graphs and predict labels by aggregating proximal nodes' labels [1; 18; 80; 84; 85; 1; 1]. Different from classic SSL, we allow its semantic space to cover both known and novel classes. Accordingly, we contribute a graph-theoretic framework tailored to the open-world setting, and reveal new insights on how the labeled data can benefit the clustering performance on both known and novel classes.

    &  &  \\  & **All** & **Novel** & **Known** & **All** & **Novel** & **Known** \\ 
**FixMatch** & 49.5 & 50.4 & 71.5 & 20.3 & 23.5 & 39.6 \\
**DS\({}^{}\)L** & 40.2 & 45.3 & 77.6 & 24.0 & 23.7 & 55.1 \\
**CGDL** & 39.7 & 44.6 & 72.3 & 23.6 & 22.5 & 49.3 \\
**DTC** & 38.3 & 39.5 & 53.9 & 18.3 & 22.9 & 31.3 \\
**RankStats** & 82.9 & 81.0 & 86.6 & 23.1 & 28.4 & 36.4 \\
**SimCLR** & 51.7 & 63.4 & 58.3 & 22.3 & 21.2 & 28.6 \\ 
**ORCA** & \(88.3^{ 0.3}\) & \(87.5^{ 0.2}\) & \(89.9^{ 0.4}\) & \(47.2^{ 0.7}\) & \(41.0^{ 1.0}\) & \(66.7^{ 0.2}\) \\
**GCD** & \(87.5^{ 0.5}\) & \(86.7^{ 0.4}\) & \(90.1^{ 0.4}\) & \(46.8^{ 0.5}\) & \(43.4^{ 0.7}\) & \(69.7^{ 0.4}\) \\
**OpenCon** & \(90.4^{ 0.6}\) & \(91.1^{ 0.1}\) & \(89.3^{ 0.2}\) & \(52.7^{ 0.6}\) & \(47.8^{ 0.6}\) & \(69.1^{ 0.3}\) \\
**SORL (Ours)** & \(^{ 1.0}\) & \(^{ 0.1}\) & \(^{ 0.2}\) & \(^{ 0.3}\) & \(^{ 0.2}\) & \(68.2^{ 0.1}\) \\   

Table 1: Main Results. Mean and std are estimated on five different runs. Baseline numbers are from [7; 63].

**Open-world semi-supervised learning**. The learning setting that considers both labeled and unlabeled data with a mixture of known and novel classes is first proposed in  and inspires a proliferation of follow-up works [49; 52; 63; 69; 81] advancing empirical success. Most works put emphasis on learning high-quality embeddings [49; 63; 69; 81]. In particular, Sun and Li  employ contrastive learning with both supervised and self-supervised signals, which aligns with our theoretical setup in Sec. 3.1. Different from prior works, our paper focuses on _advancing theoretical understanding_. To the best of our knowledge, we are the first to theoretically investigate the problem from a graph-theoretic perspective and provide a rigorous error bound.

**Spectral graph theory.** Spectral graph theory is a classic research problem [10; 14; 33; 40; 44; 70], which aims to partition the graph by studying the eigenspace of the adjacency matrix. The spectral graph theory is also widely applied in machine learning [1; 6; 45; 56; 58; 64; 86]. Recently, HaoChen et al.  derive a spectral contrastive loss from the factorization of the graph's adjacency matrix which facilitates theoretical study in unsupervised domain adaptation [24; 57]. In these works, the graph's formulation is exclusively based on unlabeled data. Sun et al.  later expanded this spectral contrastive loss approach to cater to learning environments that encompass both labeled data from known classes and unlabeled data from novel ones. In this paper, our adaptation of the loss function from  is tailored to address the open-world semi-supervised learning challenge, considering known class samples within unlabeled data.

**Theory for self-supervised learning.** A proliferation of works in self-supervised representation learning demonstrates the empirical success [5; 8; 11; 12; 23; 26; 68; 77] with the theoretical foundation by providing provable guarantees on the representations learned by contrastive learning for linear probing [4; 41; 55; 59; 66; 67]. From the graphic view, HaoChen et al. [23; 24], Shen et al.  model the pairwise relation by the augmentation probability and provided error analysis of the downstream tasks. The existing body of work has mostly focused on _unsupervised learning_. In this paper, we systematically investigate how the label information can change the representation manifold and affect the downstream clustering performance on both known and novel classes.

## 8 Conclusion

In this paper, we present a graph-theoretic framework for open-world semi-supervised learning. The framework facilitates the understanding of how representations change as a result of adding labeling information to the graph. Specifically, we learn representation through Spectral Open-world Representation Learning (SORL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to analyze the clustering error difference between having vs. excluding labeled data. Our main results suggest that the clustering error can be significantly reduced if the connectivity to the labeled data is stronger than their self-clusterability. Our framework is also empirically appealing to use since it achieves competitive performance on par with existing baselines. Nevertheless, we acknowledge two limitations to practical application within our theoretical construct:

* The augmentation graph serves as a potent theoretical tool for elucidating the success of modern representation learning methods. However, it is challenging to ensure that current augmentation strategies, such as cropping, color jittering, can transform two dissimilar images into identical ones.
* The utilization of Theorems 4.1 and 4.2 necessitates an explicit knowledge of the adjacency matrix of the augmentation graph, a requirement that can be intractable in practice.

In light of these limitations, we encourage further research to enhance the practicality of these theoretical findings. We also hope our framework and insights can inspire the broader representation learning community to understand the role of labeling prior.