# Minimax Risks and Optimal Procedures for

Estimation under Functional Local Differential Privacy

 Bonwoo Lee &Jeongyoun Ahn1 &Cheolwoo Park1

Korea Advanced Institute of Science & Technology

Daejeon, 34141 South Korea

righthim@kaist.ac.kr, jyahn@kaist.ac.kr, parkcw2021@kaist.ac.kr

###### Abstract

As concerns about data privacy continue to grow, differential privacy (DP) has emerged as a fundamental concept that aims to guarantee privacy by ensuring individuals' indistinguishability in data analysis. Local differential privacy (LDP) is a rigorous type of DP that requires individual data to be privatized before being sent to the collector, thus removing the need for a trusted third party to collect data. Among the numerous (L)DP-based approaches, functional DP has gained considerable attention in the DP community because it connects DP to statistical decision-making by formulating it as a hypothesis-testing problem and also exhibits Gaussian-related properties. However, the utility of privatized data is generally lower than that of non-private data, prompting research into optimal mechanisms that maximize the statistical utility for given privacy constraints. In this study, we investigate how functional LDP preserves the statistical utility by analyzing minimax risks of univariate mean estimation as well as nonparametric density estimation. We leverage the contraction property of functional LDP mechanisms and classical information-theoretical bounds to derive private minimax lower bounds. Our theoretical study reveals that it is possible to establish an interpretable, continuous balance between the statistical utility and privacy level, which has not been achieved under the \(\)-LDP framework. Furthermore, we suggest minimax optimal mechanisms based on Gaussian LDP (a type of functional LDP) that achieve the minimax upper bounds and show via a numerical study that they are superior to the counterparts derived under \(\)-LDP. The theoretical and empirical findings of this work suggest that Gaussian LDP should be considered a reliable standard for LDP.

## 1 Introduction

It has been widely accepted that anonymization is insufficient in protecting privacy (Sweeney, 2000, 2002; Dinur and Nissim, 2003). The concerns about data privacy have grown significantly, particularly with the advancement of computer science technology and the rise in data generated by individuals and tech companies. Such concerns are shared by politics and industry, leading to the adoption of France's "Loi pour une Republique numerique (Law for the Digital Republic)" in October 2016 (Algan et al., 2016), EU's General Data Protection Regulation in May 2018, and the California Consumer Privacy Act (Wang et al., 2022), all of which regulate data protection, collection, and processing. Also, data privacy techniques have been implemented in industries such as Google (Erlingsson et al., 2014; Fanti et al., 2016), Apple (Thakurta et al., 2017; Tang et al., 2017), Microsoft (Ding et al., 2017), and SAP (Kessler et al., 2019).

Differential privacy (DP), suggested by Dwork et al. (2006b), has become a fundamental foundation of the modern privacy concept. Its core idea is that privacy can be protected not by how well the sensitive information is hidden but rather by how individuals are indistinguishable in the privatized data. Dwork et al. (2006b) first introduced the notion of \(\)-DP for a randomized mechanism that yields a likelihood ratio between its outputs from 'neighboring' data that is bounded by a privacy budget \(\). Despite its intuitive appeal, \(\)-DP has been found to lack generality in explaining some common privacy mechanisms including the Gaussian mechanism (Mironov, 2017; Dong et al., 2022). A generalized version of \(\)-DP, \((,)\)-DP, is introduced in Definition 1.1. Let \(\) be the sample space and \(M:^{n}()\) be a randomized mechanism, where \(()\) is a family of distributions over \(\). Let \(S S^{}\) denote that data sets \(S\) and \(S^{}\) are neighbors, differing only by one individual. The following definition states that the output distribution of \(M\) does not heavily depend on the presence of a specific individual. Note that \((,0)\)-DP reduces to \(\)-DP.

**Definition 1.1** (\((,)\)-DP, Dwork et al. (2006a)).: A mechanism \(M\) is \((,)\)-DP if the following holds:

\[_{S,S^{}^{},S S^{}}_{A }(M(S) A)-e^{}(M(S^ {}) A).\]

Another type of DP, local differential privacy (Duchi et al., 2013, LDP), provides strong privacy guarantees by privatizing raw data before releasing it to a data collector. It is commonly used for private statistical inference since it gives the adversary access to privatized data that is the same size as the original data. Note that unlike in Definition 1.1, the inputs of LDP mechanisms are not the whole data set \(S\) but each individual observation \(x_{i} S\).

As expected, the accuracy of statistical analysis performed on privatized data is often worse than that of non-private data. This has prompted researchers to seek a balance between privacy and utility as well as to find the optimal mechanism given privacy constraints. The efforts to balance noise contamination and utility date back to Carroll and Hall (1988), which predated the emergence of DP. Later, Duchi et al. (2013) proposed a framework for quantifying the trade-off between privacy and statistical utility using \(\)-LDP and minimax risk analysis. With the minimax framework, one can study the minimum loss that can be attained in the worst-case scenario for statistical utility, given a specific privacy constraint. Since then, numerous researchers have explored minimax risks for various inference problems under \(\)-LDP (Li et al., 2022; Chhor and Sentenac, 2023; Rohde and Steinberger, 2020; Butucea et al., 2020).

However, despite the inherent continuity in the definitions of \(\)-LDP and \((,)\)-LDP, some studies on LDP mechanisms have revealed an inexplicable discrepancy in the statistical utility achieved by the two techniques (Asoodeh et al., 2021). One possible explanation for this phenomenon is the inefficiency of the composition rule used in \((,)\)-LDP, which has been found to perform poorly in tracking privacy leakage resulting from the compositions of multiple mechanisms or subsampling, as pointed out by some studies including Dong et al. (2022); Mironov (2017). Since data are frequently reused multiple times in most data analysis scenarios, the privacy level must be calculated by taking the composition of multiple mechanisms into account. An accurate assessment of privacy under such compositions is critical, since underestimating privacy would force a mechanism to sacrifice utility to ensure the desired privacy level.

This work explores the trade-off between statistical utility and local privacy under the framework of functional differential privacy (Dong et al., 2022, FDP), which is known to provide more precise privacy control. The core idea of FDP connects the fundamental DP concept, which involves making two outputs based on different inputs indistinguishable, to the concept of statistical decision-making. Since an adversary's goal is to identify whether given privatized \(Z\) is from \(S\) or \(S^{}\) when \(S S^{}\), we consider the following hypothesis testing problem for a given output of mechanism \(M\):

\[H_{0}:Z M(S) H_{1}:Z M(S^{}).\] (1)

The difficulty of this hypothesis testing problem is directly related to the privacy level of the given mechanism. A mechanism is said to satisfy \(f\)-FDP if the above testing problem has a "trade-off" function \(f()\), which is the minimum Type II error for a given Type I error no greater than \(\). FDP, particularly in the context of Gaussian differential privacy (GDP) (see Section 2), has been found to provide superior privacy control compared to \((,)\)-DP, with better interpretation.

Another advantage of the FDP framework is its superiority in composition rules, which regards accurately measuring the privacy level when multiple mechanisms are sequentially applied. Manytypes of DP, including \((,)\)-(LDP, have been criticized for their inefficient composition rules. They tend to overestimate privacy leakage, which, in turn, leads to excessive perturbation of estimations. This is demonstrated in Section 4, in which \(\)-LDP is empirically shown to be inefficient in controlling the privacy of a high-dimensional problem. On the other hand, FDP possesses an effective composition rule that strikes the right balance between privacy protection and estimation accuracy.

### Related Works

Since DP was introduced, the trade-off between privacy and statistical utility has been studied in global DP settings as well as local DP settings. Kamath et al. (2022) and Kamath and Ullman (2020) investigated the trade-off under \(\)-DP by studying sample complexity of covariance matrix estimation of Gaussian distribution and univariate mean estimation, respectively. Cai et al. (2021) established minimax optimality under \((,)\)-DP for high-dimensional mean estimation of sub-Gaussian distributions.

In the local DP setting, analyzing minimax risks under \(\)-LDP for various estimation problems has been a main focus. Duchi et al. (2018) provided bounds of minimax optimal privacy mechanisms for some canonical estimation problems including mean and density estimation and suggested optimal estimators under \(\)-LDP. Other estimation problems that have been investigated under \(\)-LDP include the estimation of functionals of a probability distribution (Rohde and Steinberger, 2020), and discrete distribution estimation (Chhor and Sentenac, 2023). Private minimax risk of nonparametric density estimation has been addressed by Butucea et al. (2020) who observed an elbow effect in \(L^{r}\) risk over Besov spaces and by Li et al. (2022) who considered a data contamination scenario. Some efforts have also been made under \((,)\)-LDP. Asoodeh et al. (2021) studied minimax risks for mean estimation, while Kroll (2021) considered nonparametric density estimation at fixed points.

Among the existing works, Duchi et al. (2018) and Asoodeh et al. (2021) are more relevant to the present work than others, as they also studied the mean estimation and/or nonparametric density estimation. We show that the minimax optimal rates for \(f\)-FLDP, local version of \(f\)-FDP, are equivalent to those for \(\)-LDP, if \(f\) satisfies some condition (see Lemma 1). We argue that our result can also be useful for understanding \((,)\)-LDP, since \(f\)-FLDP includes \((,)\)-LDP as a special case.

### Our Contributions

We derive the minimax risk bounds under the framework of FLDP as well as Gaussian LDP (GLDP) for two classic statistical problems: univariate mean estimation (Section 3.1) and nonparametric density estimation (Section 3.2). We investigate the private minimax risks using Le Cam's (Theorem 1) and Assouad's bounds (Theorem 3), respectively. To the best of our knowledge, our work is the first to investigate the minimax risk bounds under the FLDP framework.

Our theoretical investigation yields two important results: First, we show that our bounds achieve the same rates under some conditions as those under \(\)-LDP, thereby extending the contraction inequality established by Duchi et al. (2018) under \(\)-LDP to FLDP (Theorem 2). Also, as a special case, we show that the established lower bound becomes tight under GLDP. Second, we demonstrate that \(f\)-FLDP provides a _continuous_ trade-off between privacy and statistical utility, unlike \((,)\)-LDP (Corollaries 1 and 3). In the view of \((,)\)-LDP, one can see that \(\)-LDP and non-private settings are continuously related by a quantity \(\). However, the existing results do not reflect such continuity with respect to the minimax rate. So far, any slightest privacy measure seems to increase the minimax rate with the increment rate not related to the privacy level. For example, the minimax rate of nonparametric density estimation worsens from \(n^{-}\) to \(n^{-}\) under \(\)-LDP, where \(\) denotes the degree of smoothness. But the change of rate is irrelevant to \(\) even though \(\)-LDP becomes non-private if we set \(\).

We also present optimal mechanisms that attain the minimax upper bounds (Corollaries 2 and 4), and evaluate their utilities compared to optimal mechanisms derived under \(\)-LDP. Our experiments show that the proposed minimax optimal estimators under GLDP achieve better utility for the equivalent level of privacy constraints (Section 4).

## 2 Backgrounds

We introduce some notations and review key concepts in differential privacy in this section. Let \(M:^{n}()\) be a multivariate randomized mechanism or equivalently, a collection of randomized mechanisms \(M=\{M_{i}\}_{i=1}^{n}\) such that \(Z=(z_{1},,z_{n}):=M(x_{1},,x_{n})\) where \(z_{i}=M_{i}(x_{1},,x_{n})\) for \(i=1,,n\). Here, \(M\) denotes a locally private mechanism as it prioritizes a data set \(D^{n}\), producing perturbed data with the same size as the original data. Furthermore, \(M\) is called a sequential mechanism if \(z_{i}\) depends only on \(x_{i}\) and \(z_{1},,z_{i-1}\), so \(z_{i}=M_{i}(x_{i},z_{1},,z_{i-1})\).

### Functional Local Differential Privacy

The hypothesis testing aspect of DP expressed in (1) was first discussed by Wasserman and Zhou (2010). Recently Dong et al. (2022) gave a formal treatment by formulating the difficulty of the testing as follows. Let \(\) be the rejection rule and \(\) be the level of the test. Then we define the trade-off function2 as the minimum type II error for a given \(\).

**Definition 2.1** (Trade-off function, Dong et al. (2022)).: For two distributions \(P,Q()\) and \(\), the trade-off function \(T(P,Q):\) between \(P\) and \(Q\) is defined as

\[T(P,Q)()=_{}\{1-_{}(z)dQ(z)\ |\ : ,_{}(z)dP(z) \}.\]

It is clear that the larger the trade-off function, the smaller the power, and consequently the more private the mechanism. A randomized mechanism is said to satisfy \(f\)-FDP if the corresponding trade-off function is at least \(f\) for all \(\).

**Definition 2.2** (Functional differential privacy, FDP), Dong et al. (2022).: Let \(f:\) be a trade-off function for some distributions \(P\) and \(Q\). A given mechanism \(M\) is \(f\)-FDP if

\[T(M(S),M(S^{}))() f()\]

for every \(S S^{}^{n}\) and \(\).

The following proposition shows that \((,)\)-DP defined in (1.1) is a special case of \(f\)-FDP.

**Proposition 1** (Dong et al. (2022)).: _A convex conjugate of \(f\) is defined as \(_{f}(y)=_{x}1-yx-f(x)\). Then a mechanism \(M\) satisfies an \(f\)-FDP iff it is \((,_{f}(e^{}))\)-DP for every \( 0\)._

According to Proposition 1, all information regarding the privacy of the mechanism from the perspective of \((,)\)-DP is contained in FDP. It also indicates that the privacy characterization of a mechanism may require more than just two numbers \(\) and \(\).

A useful subclass of FDP is the Gaussian differential privacy (GDP), which has the trade-off function \(G_{}=T(N(0,1),N(,1))\). That is, the hypothesis testing problem in (1) compares two normal distributions with respective means \(0\) and \(\) with unit variance. It is known that \(G_{}(x)=F(F^{-1}(1-x)-)\) where \(F\) is the cumulative distribution function of the standard normal distribution.

**Definition 2.3** (Gaussian differential privacy, GDP).: A mechanism \(M\) is \(\)-GDP if it is \(G_{}\)-FDP.

In addition to its intuitive interpretation, \(\)-GDP also possesses appealing asymptotic properties regarding compositions of different DP mechanisms. It has been shown by Dong et al. (2022) that the trade-off function of a composition of mechanisms converges to \(G_{}\) under some mild conditions. Due to these desirable features, it is suggested to be used as a standard for the comparison of different DP methods.

In this work, we focus on the utility of estimation under local \(\)-GDP, i.e., \(\)-GLDP. For all DP concepts introduced so far, their corresponding local versions are naturally defined by a locally private sequential mechanism \(M=\{M_{i}\}\), \(i=1, n\), that privatizes the \(i\)th observation, respectively. For example, \(f\)-FLDP and \(\)-GLDP are characterized by the following:

\[T(M_{i}(x),M_{i}(x^{}))() f()\ (\ G_{}( ))\]

for every \(x,x^{}\) and \(i=1,2,,n\). Some exemplary trade-off functions of \(\)-GLDP as well as those of \(\)-LDP are displayed in Fig. 0(a).

### Private Minimax Risk

Consider an estimation problem in a private setting. Suppose \(n\) i.i.d. observations \(X_{1},,X_{n}\) are drawn from a distribution \(P\) in some family of distributions \(()\). The data are privatized into \((Z_{1},,Z_{n})=M(X_{1},,X_{n})\) where \(M\) is an \(f\)-FLDP mechanism. Let \(=()\) be a parameter of interest where \(\) is the parameter space and \(:^{n}\) be an estimator. For a metric \(:^{2}_{ 0}\) and an increasing function \(:_{ 0}_{ 0}\), use \(\) as the loss function, we define the private minimax risk:

**Definition 2.4** (Private minimax risk).: \[_{n}((),,M_{f}):=_{M M_{f}} _{}_{P}_{P}[ ((M(X_{1},,X_{n})),(P))].\]

Here, \(M_{f}\) is a family of \(f\)-FLDP mechanism defined over \(^{n}\). As long as privacy is guaranteed at a certain level (i.e., given \(f\)), one wishes to find an optimal privatizing mechanism \(M\) for a given estimation problem (i.e., \(\)) that yields uniformly optimal loss over every distribution in \(\). One can also use the minimax risk not only to find the optimal achievable estimation risk but to judge the efficiency of the estimator under the given privacy level \(f\)-FLDP.

## 3 Minimax Risk Analysis Under FLDP

Minimax risks of classical, non-private estimation problems have been addressed by numerous approaches including Le Cam, Fano, and Assouad methods, among others (Tsybakov, 2009). In this section, we take Le Cam's and Assouad's approaches and apply them to mean and nonparametric density estimation, respectively, under \(f\)-FLDP. All proofs are presented in the supplementary material.

### Le Cam's Bound on Mean Estimation

Le Cam's method involves reducing an estimation problem to a two-point hypothesis testing problem, in which the minimax risk is bounded by calculating the worst-case risk for only two distributions, \(P_{1}\) and \(P_{2}\), selected from \(\), as defined in Section 2.2.

We first state the private Le Cam's lower bound under \(f\)-FLDP in the theorem below. The following quantity represents the contraction factor of the effective sample size due to the privatization:

\[c_{f,}=2^{}(1-)^{1-}_{0}^{ }(1+)t^{-1}_{f}(t)dt,\]

where \(0 1\) and \(_{f}(t)\) is the convex conjugate of \(f\), as defined in Proposition 1.

**Theorem 1** (Private Le Cam's bound).: _For given \(0 1\) and a trade-off function \(f\), if \(_{0}^{}^{-1}_{f}(t)dt\) is finite and \(((P_{1}),(P_{2})) 2>0\) for two distributions \(P_{1},P_{2}\), then_

\[_{n}((),,M_{f})[1--P_{2}\|_{TV} ^{+}}{(1-\|P_{1}-P_{2}\|_{TV})^{}}}],\]

_where \(\|\|_{TV}\) denotes total variation._

The minimax lower bound on the right-hand side can serve as an indicator of the trade-off between privacy and utility. Note that \(c_{f,} c_{g,}\) if \(f(t) g(t)\) for all \(t\), which implies higher privacy would yield greater contraction of the effective sample size. That is, the minimax lower bound on the right-hand side would become lower under a loosened privacy constraint, which coincides with the intuition that less privacy would enhance the utility.

Next, we use Le Cam's method to obtain a lower bound of minimax risk for univariate mean estimation with bounded moments under the squared loss. For \(k>1\), define a family of distributions with bounded \(k\)th moment \(_{k}=\{P()\ |\ |_{P}[X]| 1, _{P}[|X|^{k}] 1\}\). The parameter of interest is \((P)=_{P}[X]\) with loss function \(\) where \((_{1},_{2})=|_{1}-_{2}|\) and \((t)=t^{2}\). Applying Theorem 1, we obtain the following result.

**Corollary 1** (Univariate mean estimation).: _For given \(0 1\) and a trade-off function \(f\), if \(_{0}^{}t^{-1}_{f}(t)dt\) is finite, then_

\[_{n}((_{k}),||^{2},M_{f}) c_{0 }(nc_{f,})^{-},\]

_for \(n>c_{1}\) where \(c_{0}\) only depends on \(k\) and \(\), and \(c_{1}\) depends on \(c_{f,}\)._

Note that the minimax risk for mean estimation is known to be \(O(n^{-\{1,2-\}})\) in a non-private setting and \(O((n^{2})^{-})\) under \(\)-LDP (Duchi et al., 2018). Corollary 1 implies that the minimax lower bound continuously reaches the two scenarios. Specifically, the minimax risk bound of \(=0\) corresponds to that of the non-private setting, and the minimax risk bound of \(=1\) corresponds to that of the \(\)-LDP case. Moreover, the fact that for any trade-off function \(f\), there exists \(f_{}\) such that \(f_{}\)-FLDP is equivalent with \(\)-LDP implies that the minimax rate of mean estimation under \(f\)-FLDP is \(O(n^{-})\) when \(c_{f,1}\) is finite. In the following lemma, we further identify which trade-off function \(f\) would yield the private minimax risk bound of \(f\)-FLDP equivalent to that of \(\)-LDP.

**Lemma 1**.: _If a given trade-off function \(f(x) 1-c_{0}x^{c_{1}}\) for some \(c_{0}>0\) and \(c_{1}(0.5,1)\) on \(\), or \(_{f}(x) c_{3}x^{-1-c_{2}}\) for \(x>x_{0}\) and some \(c_{3},c_{2},x_{0}>0\), then \(_{0}^{}_{f}(t)dt\) is finite._

Under the condition of Lemma 1, the minimax risk of univariate mean estimation under \(f\)-FLDP is \(O(n^{-})\) by Corollary 1, which is the same rate for \(\)-LDP. Here, we note that the assumption of Lemma 1 is quite general. Fig. 0(b) shows some examples of trade-off functions satisfying Lemma 1. It can be seen that Lemma 1 requires the slope at \(x=0\) of the trade-off function should not be too steep. Nonetheless, note that there exists a trade-off function requiring \(<1\) in order to make \(c_{f,}\) finite. For example, \(f(x)=1-x^{}\) is a trade-off function with \(_{f}(t)=}{(1+)^{1+}}t^{-}\) for \(t>\). Therefore, \( t^{-1}_{f}(t)dt\) does not converge, and neither does \(c_{f,}\). Thus, there exist some mechanisms that Corollary 1 cannot guarantee the minimax rate equivalent with the optimal rate under \(\)-LDP. In other words, they may enjoy better minimax rates. In the supplementary material, it is shown that \(G_{}\) satisfies Lemma 1 for any \(>0\).

Combining it with Corollary 1, we can bound the minimax risk of univariate mean estimation under \(\)-GLDP. Denote \(M_{}\) for a family of \(\)-GLDP mechanisms.

**Corollary 2**.: _The minimax risk of univariate mean estimation under \(\)-GLDP mechanism is bounded as follows:_

\[c_{0}(ne^{^{2}})^{-(1-)} _{n}((_{k},||_{2}^{2},M_{} )) c_{1}(n^{2}(4+^{2})^{-1})^{-(1-)},\]

_for \(n>c_{2}\) where \(c_{0},c_{1}>0\) are constants depending only on \(k\), and \(c_{2}\) is a constant depending only on \(\) and \(k\)._

Figure 1: (a) Trade-off functions of \(\)-LDP with \(=0.4\) (red), 6.4 (green), \(\)-GLDP with \(=1\) (blue) and non-private setting (cyan). (b) Example of trade-off functions (not) satisfying Lemma 1.

We present the following \(\)-GLDP algorithm that can be shown to be minimax optimal, as it achieves the rate of \(O(n^{-})\). See the supplementary material for a proof and empirical comparison of other LDP mechanisms including the minimax optimal \(\)-LDP mechanism in Duchi et al. (2018).

1. \(T=[n(1+})^{-1}]^{}\).
2. \(M_{i}(X_{i})=\{-T,\{X_{i},T\}\}+_{i}\) where \(_{i} N(0,}{^{2}})\).
3. \((M(X_{1},,X_{n})):=_{i=1}^{n}M_{i} (X_{i})\).

The fact that \(\)-GLDP and \(\)-LDP have the same minimax rate might be unexpected to some, especially considering that the former is a more relaxed concept than the latter. In the following lemma, we present an interesting inequality that can shed light on their connection.

**Lemma 2**.: _Let \(M:()\) be a locally private mechanism taking only one data for its input. For \(P_{1},P_{2}()\), denote \(m_{i}\) for density of \(M(P_{i})\) for \(i=1,2\). If \(M\) is \(f\)-FLDP, then for \(a 2\),_

\[_{m_{2}}((Z)}{m_{2}(Z)}>a)_{f}(a-1).\]

Lemma 2 implies that, for sufficiently small \(_{f}(e^{}-1)\), an \(f\)-FLDP mechanism behaves like \(\)-LDP with high probability (\(1-_{f}(e^{}-1)\)). Moreover, this lemma provides a probabilistic interpretation for \((,)\)-LDP: the probability that the likelihood ratio between output distributions exceeds \(e^{}+1\) is bounded by \(\). In the DP literature (Mironov, 2017; Meiser, 2018), \((,)\)-DP is often informally explained as "an \(\)-DP with probability \(1-\)," which can cause confusion. In this regard, here we provide an accurate statement specifying the respective roles of \(\) and \(\).

In addition, the \(\)-GLDP mechanism possesses a similar contraction ability to \(\)-LDP. The term _contraction_ of a mechanism is generally used to describe the reduction of distance measures between distributions that is altered by a mechanism. In Duchi et al. (2018), it was shown that \(D_{kl}(M(P_{1})||M(P_{2}))\), the Kullback-Leibler (K-L) divergence between privatized distributions under \(\)-LDP, is bounded by \(2(e^{}-1)^{2}\|P_{1}-P_{2}\|_{TV}^{2}\). We establish a similar bound under \(f\)-FLDP. Following the notations in Lemma 2, the following theorem describes the contraction of \(f\)-FLDP mechanism in terms of K-L divergence.

**Theorem 2**.: _For given \(0 1\) and a trade-off function \(f\), if \(_{0}^{}t^{-1}_{f}(t)dt\) is finite, then_

\[D_{kl}^{sy}(m_{1}||m_{2}):=D_{kl}(m_{1}||m_{2})+D_{kl}(m_{2}||m_{1}) c_{f, }-P_{2}\|_{TV}^{1+}}{(1-\|P_{1}-P_{2}\|_{TV} )^{}}\]

_holds for any \(f\)-FLDP mechanism \(M:()\) and distributions \(P_{1}\) and \(P_{2}\) over \(\)._

In the case of \(\)-GLDP, the bound comes down to \(O(\|P_{1}-P_{2}\|_{TV}^{2})\) since \(_{0}^{}t^{-1}_{f}(t)dt\) is finite for \(=1\). Because \(f\)-FLDP includes \(\)-LDP, our result is more general than Duchi et al. (2018) and further gives an insight into why \(\)-LDP and \(\)-GLDP have indistinguishable privatizing power. Our analysis also improves the bound found by Asoudeh et al. (2021), which is expressed as a constant multiple of \(D_{kl}(P_{1}||P_{2})\) thus could be unbounded for point distributions. Our result bounds the divergence by total variation between \(P_{1}\) and \(P_{2}\), which is finite for any two arbitrary distributions. See the supplementary material for an elaborated illustration.

### Assouad's Bound for Nonparametric Density Estimation

This section aims to derive the minimax risks of private nonparametric density estimation under \(f\)-FLDP and \(\)-GLDP. While Le Cam's method is effective for many problems, it may not be suitable for high-dimensional structured problems. In such cases, Assouad's method offers a solution by reformulating the estimation problem as a multiple-binary hypothesis testing problem. Given the parameter space \(\), there exists a map \(V:\{-1,+1\}^{d}\) and a family of distributions \(\{P_{v}\}_{v\{-1,+1\}^{d}}\) for \(d\) such that

\[((,(P_{v}))) 2_{j=1}^{d}1\{[V()]_{j}  v_{j}\}\]for every \(v\{-1,+1\}^{d}\). We say \(\{P_{v}\}_{v\{-1,+1\}^{d}}\) induces a \(2\)-Hamming separation under loss \(\). Assouad's method establishes a lower bound of minimax risk by assuming not the worst case but a randomly selected case in \(\{P_{v}\}_{v\{-1,+1\}^{d}}\). We present the Assouad's bound under \(f\)-FLDP mechanisms.

**Theorem 3** (Private Assouad's bound).: _For given \(0 1\) and a trade-off function \(f\), if \(_{0}^{}t^{-1}_{f}(t)dt\) is finite and a set of distributions \(\{P_{v}\}_{v\{-1,+1\}^{d}}\) induces \(2\)-Hamming separation under \(\), then_

\[_{n}((),,M_{f}) d [1-}{d}_{j=1}^{d}-P_{-j}\|_ {TV}^{1+}}{(1-\|P_{+j}-P_{-j}\|_{TV})^{}}}]\] (2)

_where \(P_{ j}=}_{v:v_{j}= 1}P_{v}\)._

We can use Theorem 3 to obtain the lower bound of minimax risk of private nonparametric density estimation. The true density is assumed to be in the elliptical Sobolev space, as defined below:

**Definition 3.1** (Elliptical Sobolev space).: For a given orthonormal basis \(\{_{j}\}_{j=1}^{}\) of \(L^{2}()\), smoothness parameter \(>\), and radius \(r>0\), the elliptical Sobolev space is the following set:

\[_{}[r]=\{h L^{2}h=_{j=1}^{} _{j}_{j},_{j=1}^{}j^{2}_{j}^{2} r^{2} \}.\]

If we use the trigonometric basis, then \(_{}\) represents a set of distributions with the bounded norm of \(\)-derivatives with coinciding derivatives of degree\(<\) at endpoints of \(\)(Tsybakov, 2009). Applying Theorem 3, we can obtain the following lower bound.

**Corollary 3** (Nonparametric density estimation).: _For given \(0 1\) and a trade-off function \(f\), if \(_{0}^{}t^{-1}_{f}(t)dt\) is finite, then_

\[_{n}((_{}[r]),\|\|_{2}^{2},M_{f} ) r^{}c_{1}(nc_{f,})^{-}\]

_for \(n>c_{2}\) where \(c_{1},c_{2}>0\) are constant depends on \(\)._

It is known that the minimax risk in the non-private setting is \(O(n^{-})\)(Tsybakov, 2009) and \(O((n^{2})^{-})\) under \(\)-LDP (Duchi et al., 2018). Thus according to Corollary 3, the minimax rate of \(f\)-FLDP with \(=1\) is the same as that of \(\)-LDP. As in Section 3.1, we can obtain the bounds of minimax risk of nonparametric density estimation under \(\)-GLDP, using Lemma 1.

**Corollary 4**.: _The minimax risk of nonparametric density estimation under \(\)-GLDP is bounded as follows:_

\[c_{0}r^{}(ne^{^{2}})^{-}_{n}((_{}[r]),\|\| _{2}^{2},M_{}) c_{1}r^{}(n^{2})^{-}\]

_for \(n>c_{2}\) where \(c_{0},c_{1}>0\) are constants depending only on \(\), and \(c_{2}\) is a constant depending only on \(\) and \(\)._

Note that the minimax rate in Corollary 4 is essentially the same as that of \(\)-LDP. However, under \(\)-GLDP, one can find the optimal mechanism in a more straightforward way. This is in contrast to the discussion in Duchi et al. (2018) that the Laplacian mechanism, the canonical mechanism under \(\)-LDP, cannot achieve the optimal minimax rate. They instead proposed a complicated mechanism to achieve optimality. Our minimax optimal mechanism and density estimator are presented below:

Suppose that \(n\) i.i.d. data \(X_{1},X_{2},,X_{n}\) drawn from \(h_{}[r]\) are available.

1. Set \(d=(0.5n^{2}r^{2})^{}\) where \( x\) is the largest integer not exceeding \(x\).
2. \(M_{i}(X_{i}):=(_{1}(X_{i}),,_{d}(X_{i}))^{T}+\) where \( N(,}_{d d})\).
3. Define a function \(_{i}:\) as \(_{i}:=_{j=1}^{d}[M_{i}(X_{i})]_{j}_{j}\).
4. Repeat 2 and 3 for \(i=1,,n\).
5. \(=_{i=1}^{n}_{i}\) is the obtained estimator.

## 4 Empirical Comparison of Minimax Optimal Mechanisms

In this section, we compare the optimal mechanisms for nonparametric density estimation under \(\)-LDP, \(\)-GLDP, and non-private mechanisms. The simulation on univariate mean estimation is provided in the supplementary material. Our proposed mechanism in Section 3.2 under \(\)-GLDP is compared with the mechanism in Duchi et al. (2018) and the non-private mechanism, which is obtained by using \(d=(nr^{2})^{}\) with \(=\) in our \(\)-GLDP algorithm.

The true underlying density is given as the density of Beta\((5,5)\) distribution.3 We set \(\{0.4,0.8,1.6,3.2,6.4\}\) for \(\)-LDP and \(\{0.5,1\}\) for \(\)-GLDP. We vary the sample size from \(n=100\) to \(n=2000\). Estimation errors are calculated by integrated mean squared errors. We repeat the experiment 100 times for each mechanism.

The trade-off functions in Fig. (a)a show that 6.4-LDP is very close to the non-private setting and 1-GLDP is between 0.4-LDP and 6.4-LDP almost everywhere in terms of privacy levels. However, Fig. (a)a, displaying the 95% point-wise confidence intervals obtained from estimated densities by different methods, shows that estimates under 1-GLDP are more in agreement with the true density than 6.4-LDP. The performance under 0.4-LDP is much worse than the others because it is the most private mechanism. The superiority of 1-GLDP can also be seen in terms of mean squared errors. In Fig. (b)b, 1-GLDP performs better than all other \(\)-LDPs.

The utility of a private mechanism in this density estimation essentially depends on how well it approximates the estimates of Fourier coefficients that would be obtained from the original data. This task requires an efficient mechanism to estimate a multi-dimensional coefficient vector for each observation. The optimal mechanism for this task under \(\)-LDP transforms a vector of non-private Fourier coefficient estimates into a binomial vector, which limits the support in order to reduce variance and achieve privacy. However, due to the inherent variance introduced by discretization, the mean squared error is bounded by a constant multiple of \((+1}{e^{}-1})^{2}\). Explicitly, the optimal error bound of the \(\)-LDP density estimation mechanism in Duchi et al. (2018) can be derived as follows:

\[_{}(+1)(e}n( +1}{e^{}-1})^{-2})^{-}r^{}\]

where \(_{}\) is the expected error obtained from the \(\)-LDP density estimation mechanism in Duchi et al. (2018). Hence, even with a lenient privacy constraint (i.e., a large \(\)), the estimation error may not decrease significantly. In contrast, our \(\)-GLDP optimal mechanism generates an estimator by adding noise with decreasing variance as \(\) tends to infinity. Again, the explicit optimal error bound is given

Figure 2: (a) 95% confidence intervals calculated from private density estimates over 100 repetitions for three LDP and non-private mechanisms. (b) The mean squared errors with one-standard errors of density estimates for various LDP mechanisms and sample sizes.

as

\[_{}(+1)(0.5 n^{2})^{-}r^{}+O(n^{-})\]

where \(_{}\) is the expected error obtained from our \(\)-GLDP density estimation mechanism. The comparison of the coefficients of \(n^{-}\), which can be interpreted as the cost of privacy, gives the asymptotic error ratio:

\[_{}}{_{}}(}^{2}(+1}{e^{}-1})^{2})^{- },\]

which exceeds 1 when \(=1\). Therefore, the estimation under \(\)-LDP is likely to produce higher errors than the estimation under \(1\)-GLDP for any \(\). This is also evidenced by the result in Fig. 2a. The fact that private estimation error under \(\)-LDP does not approach non-private estimation error implies that \(\)-LDP adds more noise than necessary to high-dimensional data compared to \(\)-GLDP. This highlights the limitation of \(\)-LDP and the advantage of \(\)-GLDP in achieving privacy for multi-dimensional data, which can be practically beneficial for addressing other private estimation problems.

## 5 Conclusion

The present work on \(f\)-FLDP establishes the private Le Cam and Assouad bounds reflecting the continuous nature of privacy constraints. As the trade-off function \(f\) becomes more (less) private, the supremum value of \(\) satisfying the conditions of Corollaries 1 and 3 increases (decreases), leading to the \(\)-LDP (non-private, respectively) minimax rate in terms of \(n\). This is in contrast to the somewhat counter-intuitive minimax lower bounds derived under \(\)-LDP, whose utility never achieves that of non-private estimation even as \(\) approaches infinity. Our simulation study in Section 4 shows that \(\)-GLDP can offer similar or better privacy level than \(\)-LDP, while achieving higher accuracy in private estimation. This suggests that \(\)-GLDP may be a better option for achieving both privacy and accurate estimation. The results on the contraction inequality reported in Theorem 2 and in the supplementary material provide additional support for this claim based on the privatizing characteristics of the mechanisms. In summary, this work shows that \(\)-GLDP is theoretically comparable in terms of both utility and privatizing ability while enjoying the better practical performance. This supports the suggestion made by Dong et al. (2022) that we use G(L)DP as a reliable standard for (L)DP both theoretically and empirically.

Possible limitations of this work are as follows: Although we establish lower bounds that connect privacy and utility in a continuous manner through \(\), the suggested optimal mechanisms only achieve the minimax rates for \(=1\). It will be desirable to identify private mechanisms and estimators that can achieve minimax rates between the non-private and \(\)-LDP minimax rates, if such mechanisms exist. Additionally, the condition in Theorems 1 and 3 does not hold for all possible trade-off functions. Also, the bounds in Corollaries 1 and 3 require \( t^{-1}_{f}(t)dt\) to be finite, which restricts the potential application of the theory, even though most commonly used privatization mechanisms, such as the Gaussian and Laplace mechanisms, satisfy this condition. Nevertheless, these bounds only coincide with the true minimax rates for only limited categories of privacy. Hence, we plan to explore whether there exists an optimal mechanism that enjoys a better minimax rate for mean and density estimation. Additionally, our theoretical minimax bound for estimations under \(\)-GLDP is tight in terms of the sample size \(n\), but it notably lacks tightness with respect to the privacy parameter \(\). Our lower bound converges to a finite value when \(\) goes to \(0\) incompatible with the upper bound. Hence, further efforts are required to establish a rigorous minimax rate in terms of privacy constraints for local FDP. Finally, our results in Section 3.1 are restricted to univariate mean estimation, and extending them to high-dimensional estimation under non-\(\)-LDP would be a non-trivial task.