# Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity

Metod Jazbec

UvA-Bosch Delta Lab

University of Amsterdam

m.jazbec@uva.nl

&James Urquhart Allingham

University of Cambridge

jua23@cam.ac.uk

Dan Zhang

Bosch Center for AI &

University of Tubingen

dan.zhang2@de.bosch.com

&Eric Nalisnick

UvA-Bosch Delta Lab

University of Amsterdam

e.t.nalisnick@uva.nl

###### Abstract

Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of _conditional monotonicity_ in the prediction quality--an essential stepping stone towards truly anytime predictive modeling using early-exit architectures. Our empirical results on standard image-classification tasks demonstrate that such behaviors can be achieved while preserving competitive accuracy on average.

## 1 Introduction

When deployed in the wild, predictive models are often subject to dynamic constraints on their computation. Consider a vision system for an autonomous vehicle: the same system should perform well in busy urban environments and on deserted rural roads. Yet the former environment often requires quick decision-making, unlike the latter. Hence, it would be beneficial for our models to be allowed to 'think' as long as its environment allows. Deploying models to resource-constrained devices has similar demands. For example, there are roughly \(25,000\) different computing configurations of Android devices (Yu et al., 2019), and developers often need to balance poor user experience in low-resource settings with under-performance in high-resource settings.

_Anytime algorithms_ can ease, if not resolve, these issues brought about by dynamic constraints on computations. An algorithm is called _anytime_ if it can quickly produce an approximate solution and subsequently employ additional resources, if available, to incrementally decrease the approximation error (Dean and Boddy, 1988; Zilberstein, 1996).1 Anytime computation is especially valuable when resources can fluctuate during test time. Returning to the example of mobile devices, an anytimealgorithm would be able to gracefully adapt to the computational budget of whatever class of device it finds itself on: low-performing devices will depend on intermediate (but still good) solutions, while high-performing devices can exploit the model's maximum abilities.

_Early-exit neural networks_ (EENNs) (Teerapititayanon et al., 2016) have attracted attention as anytime predictors, due to their architecture that can generate predictions at multiple depths (Huang et al., 2018). However, as we demonstrate, EENNs do not exhibit _anytime_ behavior. Specifically, current EENNs do not possess _conditional monotonicity_, meaning that the prediction quality for individual data points can deteriorate with longer computation at test time. This lack of monotonicity leads to a decoupling of computation time and output quality--behavior that is decisively not _anytime_.

In this work, we improve EENNs' ability to perform anytime predictive modeling. We propose a lightweight transformation that strongly encourages monotonicity in EENNs' output probabilities as they evolve with network depth. Our method is based on a Product-of-Experts formulation (Hinton, 1999) and exploits the fact that a product of probability distributions approximates an 'and' operation. Thus by taking the product over all early-exits computed thus-far, the aggregated predictive distribution is gradually refined over time (exits) to have a non-increasing support. This transformation has an inductive bias that encourages _anytime uncertainty_: the first exits produce high-entropy predictive distributions--due to their large support--and the EENN becomes progressively confident at each additional exit (by decreasing the support and reallocating probability).

In our experiments, we demonstrate across a range of vision classification tasks that our method leads to significant improvements in conditional monotonicity in a variety of backbone models _without re-training_. Moreover, our transformation preserves the original model's average accuracy and even improves it in some cases (e.g. CIFAR-100). Thus our work allows the large pool of efficient architectures to be endowed with better anytime properties, all with minimal implementation overhead.

## 2 Background & Setting of Interest

DataOur primary focus is multi-class classification.2 Let \(^{d}\) denote the feature space, and let \(\) denote the label space, which we assume to be a categorical encoding of multiple (\(K\)) classes. \(\) denotes a feature vector, and \(y\) denotes the class (\(1\) of \(K\)). We assume \(\) and \(y\) are realizations of the random variables \(\) and \(\) with the (unknown) data distribution \(p(,)=p(|)\ p()\). The training data sample is \(=\{(_{n},y_{n})\}_{n=1}^{N}\). Our experiments focus on vision tasks in which \(\) is a natural image; in the appendix, we also report results on natural language.

Early-exit Neural Networks: Model and TrainingOur model of interest is the _early-exit neural network_(Teerapititayanon et al., 2016) (EENN). For a given data-point \(\), an EENN defines \(M\) total models--\(p(\,|\,=,\,_{m},\,_{m} ),\ m=1,,M\), where \(_{m}\) denotes the parameters for the \(m\)th classifier head and \(_{m}\) are the parameters of the backbone architecture. Each set of parameters \(_{m}\) contains the parameters of all previous models: \(_{1}_{2}_{M}\). Due to this nested construction, each model can be thought of as a preliminary 'exit' to the full architecture defined by \(_{M}\). This enables the network's computation to be'short-circuited' and terminated early at exit \(m\), without evaluating later models. Training EENNs is usually done by fitting all exits simultaneously:

\[(_{1},,_{M},_{1},,_{M};)=-_{n=1}^{N}_{m=1}^{M}w_{m} p( =y_{n}\,|\,=_{n},\,_{m},\,_{m})\] (1)

where \(w_{m}^{+}\) are weights that control the degree to which each exit is trained. The weights are most often set to be uniform across all exits. For notational brevity, we will denote \(p(=y\,|\,=,\,\,_{m},\,_{m})\) as \(p_{m}(y\,|\,)\) henceforth.

Setting of InterestAt test time, there are various ways to exploit the advantages of an EENN. For example, computation could be halted if an input is deemed sufficiently easy such that a weaker model (e.g. \(p_{1}\) or \(p_{2}\)) can already make an accurate prediction, thus accelerating inference time. Such _efficient_ computation has been the central focus of the EENNs's literature thus far (Matsubara et al., 2023) and is sometimes referred to as _budgeted batch classification_(Huang et al., 2018).

However, in this work we focus exclusively on the related, yet distinct, _anytime_ setting motivated in the Introduction. We assume computation is terminated when the current environment cannot support computing and evaluating the \((m+1)\)th model. These constraints originate solely from the environment, meaning the user or model developer has no control over them. We assume the model will continue to run until it either receives such an external signal to halt or the final--i.e., \(M\)th--model is computed (Grubb and Bagnell, 2012). Furthermore, in line with previous literature on anytime algorithms (Huang et al., 2018; Hu et al., 2019), we assume the model sees one data point at a time when deployed, i.e., the batch size is one at test time.

Anytime Predictive ModelsTo have the potential to be called 'anytime,' an algorithm must produce a sequence of intermediate solutions. In the case of classification, an anytime predictive model must hence output a series of probability distributions over \(\) with the goal of forming better and better approximations of the true conditional data distribution \(p(\,|\,)\). Specifically, we are interested in the evolution of the _conditional error_ for a given \(\), defined here as \(_{t}():=Dp(\,|\, ),\;p_{t}(\,|\,)\) where \(D\) denotes a suitable distance or divergence (e.g., KL-divergence or total-variation), and \(p_{t}\) represents a model's predictive distribution after computing for time \(t_{ 0}\). In addition to conditional, i.e., instance-level, error we can also consider the evolution of a _marginal error_ defined as \(_{t}:=_{ p()} _{t}()\). For the remainder of this section, we will use \(_{t}\) to refer to both versions of the error and revisit their difference in Section 3. Since this paper focuses on anytime EENNs,3 we use the early-exit index \(m\) as the time index \(t\).

Properties of Anytime ModelsZilberstein (1996) enumerates properties that an algorithm should possess to be _anytime_. Below we summarize Zilberstein (1996)'s points that are relevant to predictive modeling with EENNs, ordering them in a hierarchy of necessity:

1. _Interruptibility_: The most basic requirement is that the model can be stopped and produce an answer at any time. Traditional neural networks do not satisfy interruptibility since they produce a single output after evaluating all layers. However, EENNs do by returning the softmax probabilities for the \(m\)th model if the \((m+1)\)th model has not been computed yet.
2. _Monotonicity_: The quality of the intermediate solutions should not decrease with computation time. Or equivalently, expending more compute time should guarantee performance does not degrade. For EENNs, monotonicity is achieved if the error \(_{m}\) is non-increasing across early-exits: \(_{1}_{M}\).
3. _Consistency_: The quality of the intermediate solutions should be correlated with computation time. For EENNs, consistency is of most concern when the amount of computation varies across sub-models. For example, if computing the \((m+1)\)th model requires evaluating \(10\) more residual blocks than the \(m\)th model required, then a consistent architecture should produce a roughly \(10\) better solution (\(_{m+1}_{m}/10\)).
4. _Diminishing Returns_: The difference in quality between consecutive solutions is gradually decreasing, with the largest jumps occurring early, e.g. \((_{1}-_{2})(_{M-1}-_{M})\). Monotonicity and consistency need to be satisfied in order for this stronger property to be guaranteed.

For a traditional EENN (trained with Equation 1), property #1 is satisfied by construction (by the presence of early-exits). Property #2 is not explicitly encouraged by the typical EENN architecture or training objective. Hence, we begin the next section by investigating if current EENNs demonstrate any signs of monotonicity. Properties #3 and #4 are left to future work since, as we will demonstrate, achieving property #2 is non-trivial and is thus the focus of the remainder of this paper.

Estimating Anytime PropertiesThe error sequence \(\{_{m}\}_{m=1}^{M}\) is essential for studying the anytime properties of EENNs. We can equivalently consider the evolution of _prediction quality_ measures \(_{m}\) and aim for a model that exhibits increasing quality, i.e., \(_{m}_{m+1}, m\). For the remainder of the paper, we will work with the notion of prediction quality unless otherwise stated. Observe that each \(_{m}\) (and equivalently, \(_{m}\)) is always unknown, as it depends on the unknown data distribution \(p(\,|\,)\). Consequently, we must rely on estimates \(_{m}\). In the presence of a labeled hold-out dataset, we can use ground-truth labels \(y^{*}\) and consider the correctness of the prediction as our estimator:\(_{m}^{c}():=[_{y}p_{m}(y\,|\,)=y^{*}]\) where \([]\) is the Iverson bracket.4 However, such an estimator provides a crude signal (0 or 1) on a conditional level (per data point). As such, it is not congruent with conditional monotonicity or consistency. Due to this, we focus primarily on the probability of the ground-truth class \(_{m}^{p}():=p_{m}(y^{*}\,|\,)\) when examining anytime properties at the conditional level. Finally, estimating marginal prediction quality (error) requires access to \(p()\). Following common practice, we approximate \(_{ p()}\) by averaging over the hold-out dataset. Averaging \(_{m}^{c}()\) and \(_{m}^{p}()\) corresponds to the test accuracy and the average ground-truth probability at the \(m\)th exit, respectively.

## 3 Checking for Monotonicity in Early-Exit Neural Networks

In this section, we take a closer look at _state-of-the-art_ early-exit neural networks and their monotonicity, a key property of anytime models. Our results show that EENNs are marginally monotone but lack conditional monotonicity in the prediction quality. For ease of presentation, we focus here on a particular EENN (_Multi-Scale Dense Net_ (MSDNet); Huang et al. (2018)) and dataset (CIFAR-100). Section 6 shows that this observation generalizes across other EENNs and datasets.

Marginal MonotonicityThe left plot of Figure 1 reports MSDNet's test accuracy (blue) on CIFAR-100 as a function of the early exits. Accuracy has been the primary focus in the anytime EENN literature Huang et al. (2018); Hu et al. (2019), and as expected, it increases at each early exit \(m\). Thus MSDNet clearly exhibits _marginal monotonicity_: monotonicity on average over the test set. The same figure also shows that the average ground-truth probability (orange) increases at each \(m\), meaning that MSDNet demonstrates marginal monotonicity in this related quantity as well.

Conditional MonotonicityYet for real-time decision-making systems, such as autonomous driving, it is usually not enough to have marginal monotonicity. Rather, we want _conditional monotonicity_: that our predictive model will improve instep with computation _for every input_. If conditional monotonicity is achieved, then marginal monotonicity is also guaranteed. However, the converse is not true, making conditional monotonicity the stronger property.

To check if MSDNet demonstrates conditional monotonicity, examine the middle plot of Figure 1. Here we plot the probability of the true label, i.e., \(_{m}^{p}()\), as a function of the early exits for \(10\) randomly sampled test points (again from CIFAR-100). We see that--despite MSDNet being marginally monotonic--it is quite unstable in the probabilities it produces per exit. For example, the purple line exhibits confidence in the correct answer (\( 75\%\)) at the second exit, drops to near zero by the fourth exit, becomes confident again (\( 80\%\)) at exits \(5\) and \(6\), and finally falls to near zero again at the last exit. Thus MSDNet clearly does not exhibit the stronger form of monotonicity.

We next quantify the degree to which MSDNet is violating conditional monotonicity. First, we define the _maximum decrease_ in the ground-truth probability as \(^{*}():=_{m^{}>m}(_{m}^{p}( )-_{m^{}}^{p}(),0)}\). For various thresholds \(\), we count how many test instances exhibit a probability decrease that exceeds the given threshold: \(N_{}:=_{m}[^{*}(_{n})]\). The results are depicted in the right panel of Figure 1. We see that for \( 25\%\) of test points, the ground-truth probability decreases by at least \(0.5\) at some exit. In a separate analysis (see Appendix B.1.2), when examining the correctness of prediction measure \(_{m}^{c}()\), we find that \( 30\%\) of test examples exhibit decreasing trajectories across early exits.5 A similar finding was reported by Kaya et al. (2019). Both observations demonstrate that MSDNet, a state-of-the-art EENN, does not exhibit conditional monotonicity nor is it close to achieving it.

## 4 Transformations for Conditional Monotonicity

In light of the aforementioned challenges with current EENNs in the anytime setting, we explore potential lightweight modifications that could encourage, or even enforce, conditional monotonicity. We first suggest a strong baseline for encouraging monotonicity, taking inspiration from Zilberstein (1996). We then introduce our primary methodology, which is based on product ensembles.

### Caching Anytime Predictors

As noted by Zilberstein (1996), conditional monotonicity can be encouraged by caching the best prediction made so far and returning it (instead of the latest prediction). Yet this requires the ability to measure the prediction quality of intermediate results. While previously introduced quantities, such as ground-truth probability \(_{m}^{p}()\), can serve to examine anytime properties before deploying the model, their reliance on the true label \(y^{*}\) renders them unsuitable for measuring prediction quality at test time. As a proxy, we propose using the EENN's internal measure of confidence. We found that simply using the softmax confidence performs well in practice. At an exit \(m\), we compute \(C(p_{m},):=_{y}p_{m}(y|)\) and overwrite the cache if \(C(p_{j},)<C(p_{m},)\), where \(j\) is the exit index of the currently cached prediction. We call this approach _Caching Anytime_ (CA) and consider it as a (strong) baseline. While CA is rather straightforward, it has been thus far overlooked in the anytime EENN literature, as the standard approach is to return the latest prediction Huang et al. (2018); Hu et al. (2019). Note that if the anytime model displays conditional monotonicity to begin with, applying CA has no effect since the most recent prediction is always at least as good as the cached one.

### Product Anytime Predictors

Our proposed method for achieving conditional monotonicity in EENNs is motivated by the following idealized construction.

Guaranteed Conditional Monotonicity via Hard Product-of-ExpertsConsider an EENN whose sub-classifiers produce 'hard' one-vs-rest probabilities: each class has either probability \(0\) or \(1\) (before normalization). Now define the predictive distribution at the \(m\)th exit to be a Product-of-Experts Hinton (1999) (PoE) ensemble involving the current and all preceding exits:

\[p_{,m}(y\,|\,):=}_{i=1}^{m}[f_{i} ()_{y}>b]^{w_{i}}, Z_{m}=_{y^{}\{1,,K\}} _{i=1}^{m}[f_{i}()_{y^{}}>b]^{w_{i}}\] (2)

where \(b\) is a threshold parameter, \([]\) is an Iverson bracket, \(f_{i}()^{K}\) represents a vector of logits at \(i\)th exit, and \(w_{i}^{+}\) are ensemble weights. Assuming that a class \(y\) is in the support of the final classifier for a given \(\), i.e. \(p_{,M}(y\,|\,)>0\), then such a model is _guaranteed_ to be monotone in the probability of \(y\):

\[p_{,m}(y\,|\,)\ \ p_{,m+1}(y\,|\, ),\ \ m\.\] (3)

The formal proof can be found in Appendix A. Consequently, if the true class \(y^{*}\) is in the final support, an EENN with this construction is conditionally monotonic in the ground-truth probability \(_{m}^{p}()\) (as defined in Section 2).

The intuition behind this construction is that at each exit, the newly computed ensemble member casts a binary vote for each class. If a class has received a vote at every exit thus far, then it remains in the support of \(p_{,m}(\,|\,)\). Otherwise, the label drops out of the support and never re-enters. At each

Figure 1: Multi-Scale Dense Network (MSDNet; Huang et al. (2018)) results on the test set of CIFAR-100. _Left_: test accuracy and average ground-truth probability at each early exit, the two measures of marginal monotonicity we study in this work. _Middle_: ground-truth probability trajectories (i.e., \(\{_{m}^{p}()\}_{m=1}^{M}\)) for 10 random test data points. _Right_: aggregation of analysis on conditional monotonicity for MSDNet. Specifically, we compute the maximum decrease in ground-truth probability for each test data point and then plot the percentage of test examples where the drop exceeds various thresholds. A red dashed line denotes the performance of an oracle model with perfect conditional monotonicity, i.e., none of the data points exhibit any decrease in the ground-truth probability.

exit, the set of candidate labels can only either remain the same or be reduced, thus concentrating probability in a non-increasing subset of classes. This construction also has an _underconfidence bias_: the probability of all labels starts small due to many labels being in the support at the earliest exits. Consequently, the model is encouraged to exhibit high uncertainty early on and then to become progressively confident at subsequent exits.

A Practical Relaxation using ReLUAlthough the above construction provides perfect conditional monotonicity (for labels in the final support), it often results in a considerable decrease in marginal accuracy (see Appendix B.2). This is not surprising since the \(0-1\) probabilities result in 'blunt' predictions. At every exit, all in-support labels have equal probability, and thus the model must select a label from the support at random in order to generate a prediction. The support is often large, especially at the early exits, and in turn the model devolves to random guessing.

To overcome this limitation, first notice that using \(0-1\) probabilities is equivalent to using a Heaviside function to map logits to probabilities.6 In turn, we propose to relax the parameterization, replacing the Heaviside with the ReLU activation function. The ReLU has the nice property that it preserves the rank of the'surviving' logits while still 'nullifying' classes with low logits. Yet this relaxation comes at a price: using ReLUs allows conditional monotonicity to be violated. However, as we will show in Section 6, the violations are rare and well worth the improvements in accuracy. Moreover, the number of violations can be controlled by applying an upper limit to the logits, as detailed in Appendix B.8.

Therefore our final _Product Anytime_ (PA) method for conditional monotonicity is written as:

\[p_{,m}(y\,|\,):=}_{i=1 }^{m}(f_{i}()_{y},\;0)^{w_{i}}, Z_{m}=_ {y^{}\{1,,K\}}_{i=1}^{m}(f_{i}()_{ y^{}},\;0)^{w_{i}}\] (4)

where \((,)\) returns the maximum of the two arguments. We set the ensemble weights to \(w_{i}=i/M\) since we expect later experts to be stronger predictors. Note that PA's predictive distribution may degenerate into a _zero_ distribution such that \(p_{,m}(y\,|\,)=0,\;\;y\). This occurs when the ensemble's experts have non-overlapping support and are thus unable to arrive at a consensus prediction. If a prediction is required, we fall back on the softmax predictive distribution based on the logits of the classifier at the current exit.

Learning and Post-Hoc ApplicationEquation 4 can be used for training an EENN directly via the negative log-likelihood. However, one can also take pre-trained EENNs (e.g., as open-sourced by the original authors) and apply Equation 4 _post-hoc_. For this post-hoc application, the EENN's logits are input into Equation 4 rather than into the usual softmax transformation. As we will demonstrate in the experiments, post-hoc application endows the model with conditional monotonicity without any substantial degradation to the original model's accuracy. In cases such as CIFAR-100, we find that our method actually _improves_ the accuracy of the pre-trained model. The only metric we find to be sensitive to training from scratch vs post-hoc application is confidence calibration, with the former providing better calibration properties. This result will be demonstrated in Figure 6. Thus, we currently recommend using our method via post-hoc application, as it requires minimal implementation overhead (about three lines of code) and allows the user to easily toggle between anytime and traditional behavior.

For a visualization of how our post-hoc PA affects probability trajectories, see Figure 2. PA manages to rectify the backbone EENN's non-monotone behavior to a large extent. As a concrete example of how this can help with anytime predictions, we can consider again the scenario of Android

Figure 2: Ground-truth probability trajectories (i.e., \(\{_{m}^{p}()\}_{m=1}^{M}\)) for 10 random test data points after applying our PA method. For comparison, MSDNet’s trajectories from Figure 1 are reproduced in the background.

phones introduced in Section 1. Deploying the original MSDNet might result in certain data points receiving inferior predictions on a higher-spec device compared to a device with limited computational capabilities. However, if we apply our PA to an MSDNet, such inconsistencies become far less likely due to the model's monotonic behavior.

## 5 Related work

_Anytime Algorithms_(Dean and Boddy, 1988, Zilberstein, 1996) have long been studied outside the context of neural networks. For instance, Wellman and Liu (1994) considered Bayesian networks in anytime settings, while Grubb and Bagnell (2012) proposed an anytime Ada-Boost algorithm (Bishop, 2007) and also studied Haar-like features (Viola and Jones, 2001) for anytime object detection. More recently, modern neural networks have been used in models with only _marginal_ anytime properties (Huang et al., 2018, Hu et al., 2019, Liu et al., 2022). Our research improves upon this work by bringing these models a step closer to having per-data-point anytime prediction, a much stronger form of anytime computation.

_Early-Exit Neural Networks_(Teerapittayanon et al., 2016, Yang et al., 2020, Han et al., 2022) have been investigated for applications in computer vision (Huang et al., 2018, Kaya et al., 2019) and natural language processing (Schwartz et al., 2020, Schuster et al., 2021, Xu and McAuley, 2023). A wide variety of backbone architectures has been explored, encompassing recurrent neural networks (Graves, 2016), convolutional networks (Huang et al., 2018), and transformers (Wang et al., 2021). Furthermore, ensembling of EENNs intermediate predictions has been considered (Qendro et al., 2021, Wolczyk et al., 2021, Meronen et al., 2023), primarily to enhance their uncertainty quantification capabilities. Our objective is to leverage the recent advancements in early-exit networks and make them suitable for true (conditional) anytime predictive modeling.

Related to our critique of current EENNs, Kaya et al. (2019) and Wolczyk et al. (2021) also observed that prediction quality can decline at later exits, calling the phenomenon 'overthinking.' These works address the problem via methods for early termination. Our work aims to impose monotonicity on the ground-truth probabilities, which eliminates 'overthinking' by definition. We further examine the connection to Kaya et al. (2019) and Wolczyk et al. (2021) in Appendix B.5.

_Product-of-Experts_(Hinton, 1999, 2002) ensembles have been extensively studied in the generative modeling domain due to their ability to yield sharper distributions compared to Mixture-of-Experts ensembles (Wu and Goodman, 2018, Huang et al., 2022). However, in the supervised setting, PoE ensembles have received relatively little attention (Pignat et al., 2022). PoE is often applied only post-hoc, likely due to training difficulties (Cao and Fleet, 2014, Watson and Morimoto, 2022).

## 6 Experiments

We conduct two sets of experiments.7 First, in Section 6.1, we verify that our method (PA) maintains strong average performance while significantly improving conditional monotonicity in state-of-the-art EENNs making them more suitable for the anytime prediction task. To check that our findings generalize across data modalities, we also conduct NLP experiments and present the results in Appendix B.4. In the second set of experiments, detailed in Section 6.2, we move beyond prediction quality and shift focus to monotonicity's effect on uncertainty quantification in the anytime setting. Lastly, we point out some limitations in Section 6.3.

DatasetsWe consider CIFAR-10, CIFAR-100 (Krizhevsky et al., 2009), and ILSVRC 2012 (ImageNet; Deng et al. (2009)). The CIFAR datasets each contain \(50\)k training and \(10\)k test images, while ImageNet is a larger dataset with 1.2M training and \(50\)k test instances. The three datasets consist of 10, 100, and 1000 classes, respectively.

BaselinesWe use four state-of-the-art EENNs as baselines and backbone architectures. The first is the Multi-Scale Dense Network (MSDNet; Huang et al. (2018)), which consists of stacked convolutional blocks. To maximize performance at each early-exit, the authors introduce: (1) feature maps on multiple scales, ensuring that coarse-level features are available all throughout the network,

[MISSING_PAGE_FAIL:8]

to probabilities) when it comes to achieving more monotone behavior. We additionally explored if calibrating the backbone EENN would be enough to make the underlying model monotone. While post-hoc calibrating every exit does help with monotonicity, it does not perform as well as PA; see Appendix B.9.

Monotonicity in CorrectnessOur PA approach yields close to perfect conditional monotonicity when considering probability as the estimator of prediction quality. Yet it is also worth checking if other estimators are monotonic, such as the correctness of the prediction, i.e., \(_{m}^{c}()\). For correctness, we observe similar improvements in conditional monotonicity; see Appendix B.1.2 for a detailed analysis. For example, on CIFAR-100, MSDNet 'forgets' the correct answer in \( 30\%\) of test cases, whereas applying post-hoc PA reduces these monotonicity violations to \( 13\%\) of cases.

### Anytime Uncertainty

We also examine the uncertainty quantification abilities of these anytime models. Again consider Figure 2, the probability trajectories obtained from post-hoc PA. The probabilities start low at first few exits, indicating high uncertainty in the early stages of anytime evaluation. The left plot of Figure 5 further supports this insight, showing that the average entropy of the PA predictive distributions is high and reduces at each early exit. Lastly, in the right plot, we present the average size of _conformal sets_8 at each exit. The set size reflects the model's predictive uncertainty, with larger sets indicating more uncertainty. Thus we see that PA is best at uncertainty quantification: it is quite uncertain at the earliest exits (set size of \( 11\)) but grows twice as confident by the last exit (set size of \( 4\)). CA and regular MSDNet keep a relatively constant set size by comparison, only varying between

Figure 4: The \(\%\) of test examples with a ground-truth probability drop exceeding a particular threshold. Our PA significantly improves the conditional monotonicity of ground-truth probabilities across various datasets and backbone models. To better illustrate the different behavior of various methods, a log scale is used for the y-axis. We report average monotonicity together with one standard deviation based on \(n=3\) independent runs. For DViT (Wang et al., 2021), we were unable to perform multiple independent runs, and report the results for various models instantiations instead, see Appendix B.11. Note that for PA, the monotonicity curves on ImageNet (almost perfectly) overlap at \(y=0\) for all backbone models considered. We also report results for the L2W model in Appendix B.11, which are largely the same as for MSDNet.

Figure 5: Uncertainty measures for the MSDNet model on the CIFAR-100. _Left_: average test entropy of (categorical) predictive distributions for each early exit. _Right_: mean size of conformal sets at each exit point. To obtain conformal scores, we used Regularized Adaptive Predictive Sets algorithm (RAPS; Angelopoulos et al., 2021). \(20\%\) of test examples were used as a hold-out set to calculate conformal quantiles at each early exit.

\(11\) and \(7.5\). Hence, the monotonicity properties of PA result in an appealing link between uncertainty and computation time; and we term this property as _anytime uncertainty_. This is an appropriate inductive bias for anytime predictive models since, intuitively, making quicker decisions should entail a higher level of uncertainty. Lastly, in Appendix B.7, we present results of conditional level experiments where we find that our PA yields significantly more monotone (i.e., non-increasing) uncertainty patterns.

### Limitations

Label Sets with Small CardinalityWe observe that PA's performance in terms of conditional monotonicity improves as the number of classes \(||\) increases. For instance, PA yields fully monotone trajectories on ImageNet, but not for datasets with smaller number of classes like CIFAR-10, where we detect small violations. This finding is further supported by our NLP experiments in Appendix B.4, where \(||\) is smaller compared to the image classification datasets considered in this section. Based on this finding, we recommend using the CA approach over PA for scenarios in which \(||<5\).

Calibration GapDue to its aforementioned underconfidence bias, post-hoc PA generates poorly calibrated probabilities during the initial exits, as illustrated in the left plot of Figure 6. Yet this is primarily observed in _expected calibration error_ (ECE) and related metrics. It disappears when considering some alternative metrics to ECE, as shown in the right plot of Figure 12. Finetuning with PA as an optimization objective, as opposed to applying it post-hoc, closes the calibration gap in most cases, albeit at some cost to accuracy and monotonicity. See Figure 6 (_right_) for concrete examples of how PA with finetuning affects ground-truth probability trajectories. In addition, we experimented with adaptive thresholding in PA, using different thresholds \(b\) for distinct data points, rather than employing 0 for all data points as with ReLU, and found that it can also be beneficial in terms of calibration. For more details on finetuning and adaptive thresholding, as well as a discussion on the relevance of ECE-like metrics in the anytime setting, see Appendix B.3.

## 7 Conclusion

We have demonstrated that expending more time during prediction in current early-exit neural networks can lead to reduced prediction quality, rendering these models unsuitable for direct application in anytime settings. To address this issue, we proposed a post-hoc modification based on Product-of-Experts and showed through empirical and theoretical analysis that it greatly improves conditional monotonicity with respect to prediction quality over time while preserving competitive overall performance.

In future work, we aim to further improve EENNs by imbuing them with other critical anytime properties, such as diminishing returns and consistency. Moreover, it would be interesting to study the impact of monotonicity in other settings, such as budgeted batch classification. We report some preliminary results in Appendix B.10, finding the monotonicity to be less beneficial there compared to the anytime setting, which was the focus of our work. We also plan to delve deeper into the concept of anytime uncertainty. Although we have (briefly) touched upon it in this study, we believe a more comprehensive and formal definition is necessary for the development of robust and reliable anytime models.

Figure 6: Calibration analysis for MSDNet on CIFAR-100. _Left_: expected calibration error (ECE) during anytime evaluation. _Right_: Ground-truth probability trajectories for 10 random test data points after applying our PA with finetuning (PA-FT) method. For comparison, MSDNet’s trajectories from Figure 1 are reproduced in the background.