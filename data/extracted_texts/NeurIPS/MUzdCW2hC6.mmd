# Improvements on Uncertainty Quantification for Node Classification via Distance-Based Regularization

Improvements on Uncertainty Quantification for Node Classification via Distance-Based Regularization

Russell Alan Hart

The University of Texas at Dallas

rah150030@utdallas.edu

&Linlin Yu

The University of Texas at Dallas

linlin.yu@utdallas.edu

&Yifei Lou

University of North Carolina at Chapel Hill

yflou@unc.edu

&Feng Chen

The University of Texas at Dallas

feng.chen@utdallas.edu

corresponding author

###### Abstract

Deep neural networks have achieved significant success in the last decades, but they are not well-calibrated and often produce unreliable predictions. A large number of literature relies on uncertainty quantification to evaluate the reliability of a learning model, which is particularly important for applications of out-of-distribution (OOD) detection and misclassification detection. We are interested in uncertainty quantification for interdependent node-level classification. We start our analysis based on graph posterior networks (GPNs) that optimize the uncertainty cross-entropy (UCE)-based loss function. We describe the theoretical limitations of the widely-used UCE loss. To alleviate the identified drawbacks, we propose a distance-based regularization that encourages clustered OOD nodes to remain clustered in the latent space. We conduct extensive comparison experiments on eight standard datasets and demonstrate that the proposed regularization outperforms the state-of-the-art in both OOD detection and misclassification detection.

## 1 Introduction

In recent years, deep neural networks (DNNs) have been widely used in various fields [10; 28]. However, some neural networks provide under-confident  or over-confident  predictions, limiting their practical applications in risk-constrained and safety-critical fields, such as drug discovery , autonomous driving , and medical diagnosis . Take autonomous drug design for an example. Uncertainty estimation on the reliability of model predictions helps to support molecular reasoning and experimental design by saving considerable time and resources . It is important to estimate the predictive uncertainty of a DNN, i.e., indicating when its predictions are likely incorrect. There are two main types of uncertainty: epistemic uncertainty (knowledge uncertainty) and aleatoric uncertainty (data uncertainty) . Epistemic uncertainty is due to the lack of knowledge about unseen data. Aleatoric uncertainty is caused by the inherent complexity of the data, which cannot be reduced by increasing the training data, including sources of noise such as homoscedastic or heteroscedastic noise . These two uncertainty types are typically used for out-of-distribution (OOD) and misclassification detection, respectively.

Most models have been introduced for uncertainty estimation on i.i.d. inputs, such as image and tabular data. However, the uncertainty estimation for classifying interdependent nodes in attributed graph data, such as social networks and citation networks, is under-explored. This work focuses on the node classification tasks with great potential to generalize to others with interdependent inputs.

Among various graph neural networks (GNNs) for processing graph data structures [18; 35; 13; 8], graph posterior network (GPN) has been developed for semi-supervised node classification tasks  that achieves state-of-the-art results in uncertainty estimation.

The major **contributions** of this paper are three-fold: (1) We theoretically analyze the limitations of GPN at OOD detection when minimizing uncertainty cross-entropy (UCE), a widely used loss function for uncertainty estimation. (2) Motivated by the aforementioned limitations, we propose a distance-based regularization that considers the prior knowledge that OOD-specific features are useful for learning representational space mappings. (3) We conduct extensive experiments comparing our proposed model with five state-of-the-art baselines on eight graph datasets for two uncertainty quantification tasks: OOD detection and misclassification detection tasks. The results demonstrate that our proposed regularization can improve the quality of uncertainty quantification.

## 2 Related Work

This section reviews existing uncertainty estimation methods for i.i.d data and graph data.

**Uncertainty Quantification for i.i.d inputs** - There is plentiful research on uncertainty quantification on i.i.d. inputs as discussed in a recent survey . The first family quantifies the predictive uncertainty of a DNN via multiple forward passes, such as deep ensembles and dropout-based Bayesian neural networks (BNNs). Deep ensembles  intuitively sample multiple predictions by training an ensemble of deep neural networks and aggregate the results. Dropout-based methods  utilize multiple stochastic forward passes implemented with different dropout initializations to approximate the posterior distribution of network weights. However, the substantial memory and computational demands required for training and testing make it impractical for real-time applications. The second family quantifies uncertainty using deterministic single forward-pass neural networks, including density-based methods and distribution-based methods. The density-based approaches typically fit a distribution (e.g., class-wise Gaussian distribution [3; 20; 34]) in the representation space of a pre-trained or fine-tuned DNN, followed by the associated PDF function to quantify different uncertainty types. The distribution-based methods train a deterministic neural network that directly predicts the conjugate prior distribution of the class probabilities of the input feature vector, called Dirichlet distribution, for uncertainty quantification. The predicted Dirichlet distribution can be interpreted as an approximation of the posterior distribution of class probabilities conditioned on the input feature vector. Popular distribution-based models are prior networks , evidential networks , and posterior networks (PN) , all using UCE as the loss function with different regularizations to improve the quality of uncertainty quantification.

**Uncertainty Quantification for Graphs** - As pointed out in the survey , uncertainty quantification on GNNs and semi-supervised learning is under-explored. Most existing models for uncertainty quantification on graphs are either dropout-based or BNN-based methods that typically drop or assign probabilities to edges. There are two approaches using deterministic single-pass GNNs to quantify uncertainty. One is called graph-based kernel Dirichlet distribution estimation (GKDE) , which consists of evidential GCN, graph-based kernel, teacher network, dropout, and loss regularization. Another method is the GPN model that combines PN and personalized page rank (PPR) message passing to disentangle uncertainty with and without network effects. In addition, a recent method  used standard classification loss for OOD detection on graphs together with an energy function that is directly extracted from GNN, however, it is limited to OOD detection, not generally on the topic of uncertainty quantification.

## 3 Preliminary

We discuss the problem setting of uncertainty quantification on the task of semi-supervised node classification in Section 3.1. In particular, we use a deep neural network to predict the multinomial uncertainty for each node and evaluate the aleatoric uncertainty and epistemic uncertainty by the prediction result. In Section 3.2, we give a brief review of the GPN model , which serves as a fundamental framework for our analysis and motivation for the proposed approach.

### Problem Setting

We define a graph with attributed node-level features \(=(,,X,Y_{})\), where \(\) is a set of nodes on the graph with cardinality \(N\) and \(\) denotes a set of graph edges that can be represented by an adjacency matrix \(W\). A feature matrix is denoted by \(X=[_{1},,_{N}]^{T}^{N d}\), in which each row \(_{i}^{d}\) is a feature vector of node \(i\) with dimension \(d\). Under the semi-supervised learning setting, a set of labels is available, denoted by \(Y_{}=\{y_{i} i\}\), where \(\) and \(y_{i}\{1,,K\}\) for \(K\) classes.

Our goal is to design and learn a deterministic GNN based on \(\) that takes the feature matrix \(X\) and the adjacency matrix \(W\) as INPUT and predicts the parameters of a Dirichlet distribution for each node \(i\) as OUTPUT, denoted as \(_{i}\), which is often referred to as the concentration parameters. Therefore, the network function \(F_{}\) can be expressed as: \(=F_{}(X,W)\), where \(:=[_{i}]_{i}\) is a matrix and \(\) refers to network parameters. The statistical relations between the class label \(_{i}\), the vector of class probabilities \(_{i}\), and the Dirichlet parameters \(_{i}\) can be represented as:

\[_{i}|_{i}(_{i}),\ _{i}| _{i}(_{i}),\ \ [_{i}]_{i}=F_{}(X,W).\] (1)

Based on the predictions of \(\), the expected vector of class probabilities \(}_{i}:=[_{i}|_{i}]=[ _{i1}/_{i0},,_{iK}/_{i0}]^{T}\), where \(_{i0}=_{k=1}^{K}_{ik}\) is called the Dirichlet strength. The aleatoric and epistemic uncertainties about the classification of each node \(i\) can be calculated as:

\[u_{i}^{}=-\{_{i1},,_{iK}\} {and} u_{i}^{}=-_{i0},\] (2)

respectively. The aleatoric uncertainty is measured by the negative of the largest class probability in \(}_{i}\). This uncertainty is higher when the largest class probability in \(}_{i}\) is lower, which implies that the model is less confident and the probabilities are more evenly spread across classes. On the other hand, the epistemic uncertainty is measured by the negative of the Dirichlet strength \(_{i0}\), whose value is higher when the Dirichlet strength is lower, meaning that the model is unfamiliar with the feature vector of node \(i\) and the predicted Dirichlet distribution is less concentrated around a specific point or set of points on the probability simplex . We note that a high aleatoric uncertainty may not indicate a high epistemic uncertainty and vice versa. For example, two evidence parameters \(_{i}=[1,,1]\) and \(_{j}=[1000,,1000]\) have the same aleatoric uncertainty: \(-1/K\), since they have the same projected class probabilities; but their epistemic uncertainties differ drastically: \(K\) versus \(1000K\). Please refer to [32; 33] for rationales of aleatoric and epistemic uncertainties in (2).

### Graph Posterior Network

Our framework is based on graph posterior network (GPN) , which extends posterior network (PN)  to semi-supervised node classification. GPN consists of three main steps. First, a feature encoder maps the original features onto a low-dimensional latent space with a simple two-layer multi-layer perception (MLP) encoder. Second, a radial normalizing flow  estimates the density of the latent space per class. Lastly, a personalized page rank message passing scheme  diffuses the pseudo counts (density multiplied by the number of training nodes) by taking the graph structure into account. We summarize the three steps with notations as follows,

1. Multi-layer perceptron for representation learning: \(_{i}=f(_{i};)\) or \(f_{}\) in short.
2. Normalizing flow for density estimation: \(g_{}\) for short, and more specifically \[g_{}(_{i})_{k}=N_{k}(_{i}| k;),\] (3) where \(N_{k}\) is the number of training nodes belonging to the class \(k\), \(_{i}\) is the embedding vector of node \(i\) obtained via the first step, \((_{i}|k;)\) is the conditional density per class \(k\) estimated by a normalizing flow module, and \(\) denotes the parameters of this module. GPN also includes the evidence computed prior to the graph aggregation, defined by \[_{i}^{}=g_{}(_{i})+ .\] (4)
3. Personalized page rank (PPR) for evidence diffusion: \(_{i,k}^{}=_{j}_ {i,j}^{}g_{}(_{j})_{k},\) where \(_{i,j}^{}\) refer to the dense PPR scores implicitly reflecting the importance of node \(j\) from the perspective of node \(i\). Then we can get the predicted concentrate parameters \(\) with a uniform prior \(\) for a non-degenerated Dirichlet distribution, i.e., \[_{i}=_{i}^{}+.\] (5)As opposed to GPN, PN is designed for uncertainty estimation for i.i.d. inputs, which only considers the first two steps to predict the Dirichlet distribution \((_{i}^{})\).

Given the labels of training nodes: \(Y_{}=\{y_{i} i\}\), GPN is trained by minimizing the following Bayesian loss:

\[=(,Y)+_{i }[(_{i})].\] (6)

The first term in (6), called uncertainty cross entropy (UCE) , is defined by

\[(,Y)=_{i}_{_{i}(_{i})}[-(y_{i}| _{i})]=_{i}_{k[K]}y_ {ik}((_{i0})-(_{ik})),\] (7)

where \(Y=[_{i}]_{i[N]}\), \(_{i}\{0,1\}^{K}\) is the one-hot encoded ground-truth class of the node \(i\), and \(\) is the digamma function, in terms of the Gamma function by: \((x)=(x)}{(x)}\). Minimizing UCE is known to increase confidence in classifying observed data (training nodes in this context). The second term in (6) is based on the entropy of each node-level Dirichlet distribution \((_{i})\) that favors smooth distributions. For more details on GPN, please refer to Appendix C.

## 4 Our Contributions

This section provides a series of theoretical analyses relating to the UCE loss term and the GPN model for detecting the OOD nodes, followed by a partial remedy to derived issues via two distance-based regularizations. Specifically, we prove in Theorem 1 that under certain conditions, UCE can be made arbitrarily small with the limiting case of UCE equal to zero in Corollary 3. Theorem 4 gives a construction to make the UCE to be zero. As UCE does not involve the OOD nodes, Theorem 6 and Corollary 7 elucidate scenarios for possibly detecting the OOD nodes. Lastly, Theorem 8 presents a special situation where GPN fails to detect the OOD nodes.

### Theoretical analysis

The loss function plays a pivotal role in learning effective representation functions and density estimations. In this context, we establish several theorems (Theorems 1 and 4) to describe some demanding assumptions on \(f_{}\) and \(g_{}\) that achieve the minimum UCE loss. We then describe a limitation of UCE in separating ID and OOD nodes in Theorem 6 and Corollary 7 for PN, which means that we only consider the first two steps in GPN. The main conclusion of our analysis is that the UCE loss function alone is insufficient to learn a representation space that separates OOD from ID nodes. We take graph connectivity into account in Theorem 8 to study some scenarios where GPN is ineffective for OOD detection. Although our theorems do not completely characterize graph learning, they provide some insights into the behavior of the network parameters in PN/GPN when minimizing the UCE loss.

**Theorem 1**.: _If the underlying distribution of feature vectors belonging to class \(k,\) denoted by \(_{k}\), is disjoint to each other and both the MLP module \((f_{})\) and the normalizing flow module \((h_{})\) can be arbitrarily complex, then \(>0\) there exists a configuration of \(f_{}\) and \(g_{}\) such that \((,Y)<\)._

For the proofs, please refer to Appendix B. Here, we elaborate on the ideal configuration that satisfies the conclusion of Theorem 1. We assume the MLP function \(f_{}\) is arbitrarily complex such that it maps \(_{i}_{k}\) into a bounded ball in the representational space, i.e.,

\[\{f_{}(_{i})|i[N]_{i}_{k}\} B(_{k},r_{k}),\]

where each ball \(B(_{k},r_{k})\) is centered at a point \(_{k}\) and bounded in size with \(r_{k}<r\) for a positive value \(r\). Furthermore, we choose the normalizing flow \(g_{}\) to be

\[g_{}(;k)=(B(_{k},r_{k}) )}&d(,_{k})<r_{k}\\ 0&,\] (8)

where \(()\) refers to the volume of the ball. The conclusion in Theorem 1 states that for every \(,\) there exists a suitable upper bound \(r\) of all the balls such that \((,Y)<\).

An implication of Theorem 1 is that UCE is not sufficient to separate OOD from ID nodes. Example 2 illustrates a scenario that OOD nodes can be close to ID nodes in the learned representation space even though they can be separated in the feature space based on OOD-specific features, which are unfortunately discarded. In other words, the learned representation space by GPN based on the UCE loss is not guaranteed to preserve the distance between OOD and ID nodes in its representation learning step.

**Example 2** (Lost Features).: _Suppose two ID classes in a citation network contain bags of words for SVM and neural networks papers respectively. Additionally, the OOD nodes contain bags of words from reinforcement learning papers. Note that frequencies of keywords are used to discriminate different classes. Then the keywords, "actor critic" and "policy network" are able to separate OOD nodes from ID nodes, but are irrelevant features for discriminating between the two ID classes. UCE, as a discriminatory loss, is only applied on ID nodes, and hence it is almost impossible to learn representations that respect the OOD-specific features such as "actor-critic" and "policy networks"._

**Limitations and discussions -** The first assumption in Theorem 1 regarding the distinct class-specific distributions of feature vectors might not be realistic in practice since certain ID classes may not be clearly distinguishable due to noise in features or class labels. Nevertheless, our intuition suggests that if the UCE loss is inadequate for separating OOD from ID nodes in situations where they are separable, it is even more likely to falter in the more complex, non-separable cases. As for the second assumption in Theorem 1, it is true that arbitrary complexity of \(f_{}\) and \(g_{}\) does not fully respect the inductive bias  of the network design, such as the MLP layers with ReLU for the feature encoder \(f(;)\), our analysis remains insightful and informative about the structures these networks are likely to exhibit. For example, we may expect from Theorem 1 that the representation of each class may favor an embedded space that compresses OOD-specific features, while density estimation \(g_{}\) tends to have higher peaks over smaller volumes as the model consolidates the representation space.

We note that in [7, Theorem 1] and [32, Theorem], the authors demonstrated that PN/GPN is able to achieve reasonable uncertainty estimation when the feature encoder is a ReLU network and PPR diffusion is removed to disregard network effects. Unfortunately, the analysis is based on extreme node features, specifically as \(\),

\[(f(_{i};)|k;) 0,_{i,k}^{} 0,\]

for any node \(i\) with a high probability. Moreover, Theorem 1 in the GPN paper  holds even when the supports of disjoint ID and OOD classes in the latent space overlap. In other words, this result does not prevent distant nodes from having similar representations. In summary, the analysis based on extreme node features may provide limited insights about the issues of GPN studied in this section. See Appendix D for detailed discussions.

By taking \( 0\), Theorem 1 reduces to Corollary 3 where UCE is equal to 0.

**Corollary 3**.: _In the ideal case, where the representation function \(f_{}\) maps the support of each class, \(_{k}\), to a countable set (with measure zero), \(_{k}\) and there exists a normalizing flow that has infinite density on the point set for every class, one achieves \((,Y)=0\)._

Next, we aim for the construction of a specific case to make UCE equal to zero. As it is challenging to analyze the joint minimization on \(\) and \(\), we assume that the normalizing flow can be chosen optimally. For this purpose, we consider a simplified problem where the true density function is assumed to be known for a given \(\) and hence it can be used to replace the learning of the normalizing flow. As a result, the problem reduces to the learning of the representation network \(\).

**Theorem 4**.: _Let \(_{k}\) be the true distributions for class-\(k\) in the original feature space. Suppose the normalizing flow module \(g_{}\) obtains the true analytic solution. If the true distributions \(\{_{k}\}\) are disjoint, then the \(f_{}\) that minimizes the UCE loss projects the support of each class in the original space to a disjoint point set \(_{k}\), where \(_{k}\) is defined by the projection of \(_{k}\) to the representation space, i.e., \(_{k}=f_{}(_{k})\)._

Notice that the true analytical solution \(\) in Theorem 4 is a function of \(\), i.e., \(=()\). It is possible to know an analytical form of \(()\). For example, if the data points belonging to each class are sampled from a known Gaussian distribution in the original feature space and the representation network is a linear projection function, then the true density of the projected data points belonging to each class can be derived based on any configuration of the known Gaussian distribution in the original feature space.

Before discussing OOD detection, we start with the definition of OOD nodes.

**Definition 5**.: _We define out-of-distribution (OOD) nodes to be the nodes that do not belong to any of the \(K\) in-distribution (ID) classes. We denote all the ID distribution supports by \(_{[K]}=_{k=1}^{K}_{k}\)._

In order to detect the OOD nodes, we need a good representation, e.g., \(f_{}(_{[K]}) f_{}(-_{[K]} )=\). However, it is possible that \(_{k=1}^{K}f_{}^{-1}(_{k})=\), which implies that any OOD node in the feature space is mapped to the same distribution of an ID class in the representation space. To this end, we require the preimage, \(f_{}^{-1}\), to be well-behaved in the sense that \(f_{}^{-1}(_{k})\) must be contained within a bounded region near the support of the true distribution \(_{k}\). Explicitly, we require there exists a constant \(>0\) such that \(d(,})<,} f_{}^{ -1}(_{k})\) and \(_{k}\) for each \(k\). The choice of \(\) depends on additional information about the dataset. An excessively large \(\) causes overlap between classes, thus increasing the likelihood of improperly identifying the OOD nodes as ID. On the other hand, a relatively small \(\) forces the model to overfit, which labels the non-training nodes as OOD.

We characterize in Theorem 6 that under certain conditions, OOD can be detected correctly if they are far away from the ID distribution. One such condition is that the function \(f_{}\) is well-fit, meaning that it maps the support of \(_{k}\) inside \(B(_{k},r_{k})\) for every \(k\) in \([K]\). We denote a set of all well-fit functions by \(\). Please refer to Figure 1 for a geometric illustration of these relevant quantities.

**Theorem 6** (Far OOD).: _Under the same assumptions in Theorem 4 and two additional assumptions: (i) \(_{k}\) is bounded and (ii) for any \(} f_{}^{-1}()\) with \(_{k}\), there exists \(_{k}_{k}\) such that \(d(_{k},})<\), if the true distribution of OOD nodes does not overlap with the region \(_{}_{k}_{_{k}_{k}}\{f _{}^{-1}(z_{k})\}\), then minimizing UCE can learn a representation projection of \(f_{}\) that detect all the OOD points farther than \(\) from \(_{k}\)._

**Corollary 7** (Near OOD).: _Following Theorem 6, if \(}_{}_{k}_{z_{k} _{k}}\{f_{}^{-1}(z_{k})\}\) follows the distribution of OOD nodes, then the classification of \(}\) depends on the choice of \(\)._

The main purpose of Theorem 6 is to show a desired behavior for OOD detection is induced by point-wise effects. In practice, we suggest the careful construction of \(f_{}\)'s topology coupled with proper regularization terms to achieve the point-wise effect.

Lastly, we consider the setting of GPN to use a graph layer after the feature-wise evidence predictions.

**Theorem 8**.: _Under the following conditions: (1) The features of some class 0 and OOD nodes belong to \(S\); (2) The OOD nodes are only connected to class 0 and themselves; (3) Other nodes belong to other regions i.e. \( X-S\) if \(_{0}_{OOD}\); (4) Other nodes' features are non-degenerate in their associated region; and (5) the endowed graph neural network layer must produce evidence for each node between the highest and lowest feature evidence found among its neighbors. A graph with arbitrary homophily can achieve a global minimum on UCE with the associated OOD nodes achieving arbitrarily large evidence, while simultaneously having perfect accuracy._

**Limitations and Discussions.** In Theorem 8, we provide a special situation where the GPN architecture may fail to detect OOD nodes by predicting large evidence values for belonging to class 0. In addition, we show in Appendix B that if GPN has bad initial feature predictions, even ideal graph construction coupled with an ideal graph neural network (with a homophily degree 1.0) fails to

Figure 1: Illustration of the representation mapping in Theorem 1 with the conditions to detect far OOD nodes (Theorem 6) and near OOD nodes (Corollary 7).

prevent the OOD nodes from being misclassified as ID nodes. For homophily graphs with degrees less than 1.0, the majority of nodes for each class have similar evidence values after graph diffusion layers, except that the nodes between some pairs of classes may have different evidence values.

### Distance-Based Regularization

As discussed in Section 4.1, the UCE loss function alone is insufficient to learn a representation space that separates OOD from ID nodes using the GPN model. We propose a heuristic remedy that enforces distance minimization on the graph. Ideally, we should design a distance formula that can preserve the distance relationship among all the feature vectors. However, distance preservation likely increases variation in the latent space as we cannot compress the classes' support in the representation space to be arbitrarily small, while simultaneously preserving distances.

Instead, we consider distance minimization, as it helps prevent the model from discarding relevant features while decreasing variation between nodes in the representation space. Here we give two formulations directly. The simpler, theorem-motivated term, is the distance regularization on the latent space,

\[_{D}(f_{}(X);)=_{i,j}\|f_{ }(_{i})-f_{}(_{j})\|^{2}.\] (9)

The regularization encourages nearby points in the graph representation to remain nearby in the latent space. In other words, this regularization (9) discourages the overlap \(f_{}(_{[K]}) f_{}(-_{[K]})\).

We also minimize the "distance" on the produced evidence through a divergence-based regularization,

\[_{}(^{};)=_{(i,j) }_{}(_{i}^{},_{j}^{})+_{}(_{j}^{},_{i}^{}),\] (10)

where \(_{}\) refers to the Kullback-Leibler divergence and two symmetric terms are considered. This divergence-based formulation likely decreases the variation in evidence between neighboring nodes, because high variation in the latent space between neighboring nodes need not be mapped to similar evidence.

In summary, we augment the GPN mode with either one of the proposed regularization terms in (9) and (10), thus leading to the objective function as follows,

\[=(,Y)-_{1}}((_{i}))}_{}+_{2}(f_{}(X); )}_{},\] (11)

with two positive parameters \(_{1},_{2}\). The first term is the standard UCE loss function. The second term is regarded by GPN as an entropy regularizer. The last term, R, is chosen to be either \(_{D}\) or \(_{}\), a decision implemented through hyperparameter tuning. We have included a theoretical result in Appendix B that provides a rationale for the proposed distance regularizations.

## 5 Experiments

In this section, we conduct extensive experiments on two tasks of OOD detection and misclassification detection. We compare the proposed framework (11) for uncertainty estimation of semi-supervised node classification using 8 datasets with a comparison to 5 baseline methods. The code is available at https://github.com/neoques/Graph-Posterior-Network.

### Experiment Setup

DatasetsWe use three citation networks (i.e. CoraML, CiteSeer, Pubmed) , two co-purchase datasets  (i.e. AmazonComputers, AmazonPhotos), two coauthor datasets  (i.e. CoauthorCS and CoauthorPhysics) and a large dataset OGBN Arxiv . A detailed description of these datasets is in Appendix E. We show the result of three citation datasets in the main paper and the remaining results in Appendix F.

BaselinesWe present the results for uncertainty estimation using five baseline methods. Among these, two evidence collection models, namely graph kernel density estimation (GKDE)  and label propagation (LP) , assuming that OOD nodes are located far away from the training nodes, while easily misclassified nodes reside near the boundaries between classes. We compare to a modified GCN model, referred to as VGCN-Energy , a Bayesian-based model, called GKDE-GCN , and GPN  as baselines in our evaluation. We also introduce a Graph Neural Network called APPNP  as one baseline for the misclassification detection task and report the ROC score. Details of these baselines can be found in Appendix D.

MetricsTo assess the classification performance of ID nodes, we rely on the metric **ID-ACC**, which calculates the fraction of correct predictions among all predictions. As for evaluating uncertainty estimation, we employ the metrics **AUC-ROC** and **AUC-PR** as evaluation measures. The rankings are based on the scores of epistemic or aleatoric uncertainty. OOD detection is treated as a binary classification task, where the positive class corresponds to OOD nodes and the negative class pertains to ID nodes. Please refer to (2) for the calculation of aleatoric uncertainty and epistemic uncertainty. For the Dirichlet-based models, the epistemic uncertainty has a similar practical interpretation to vacuity in the belief theory, assessed using AUC scores. On the other hand, in VGCN-Energy, the calculation of epistemic uncertainty is based on the energy value and is represented as \(u_{i}^{}=\). The misclassification detection task is also a binary classification problem, where the positive cases correspond to wrongly classified nodes and the negative cases represent correctly classified nodes. The calculation of uncertainty for misclassification detection is performed in the same manner as OOD detection except that \(u_{i}^{}=-_{k}_{i}^{k}\). Prior studies [32; 39] has indicated that aleatoric uncertainty is generally more effective for identifying misclassifications, whereas epistemic uncertainty is more appropriate for detecting out-of-distribution instances.

Model SetupFor all the baseline methods, we maintain consistency by employing the same set of model hyperparameters as provided by GPN. Specifically for some model hyperparameters such as latent dimension and weight decay, we adopt the same settings as GPN. Inspired by , we explore multiple choices of activation functions in the representation networks. In addition to the default ReLU used in GPN, we experiment with Sigmoid and GELU activation functions. Through empirical evaluation, we discover that the choice of activation function significantly impacts the performance of certain datasets, which is demonstrated in Appendix E.4. Besides, hyperparameters that we tune include entropy regularization weight, distance-based regularization format (whether R\({}_{D}\) or R\({}_{}\)), and weighting parameters (\(_{1},_{2}\)), which are optimized based on the validation cross-entropy for each specific dataset. For a comprehensive overview of the hyperparameter configuration and ablation study, please refer to Appendix D.

### Results

OOD DetectionOOD detection aims to detect whether an input example is OOD given the predicted uncertainty estimation. For the semi-supervised node classification, we adopt the **Left-Out-Classes** setting where we assume several categories as OOD (details can be found in Appendix D), as considered in [7; 39]. Different from the independent input setting, we retain the OOD nodes in the graph but exclude their labels from the training and validation sets. This implies that the loss function does not involve OOD labels, but the model has encountered the OOD node features during the training phase. Similarly to , we also remove the last graph propagation layer for comparison as "w/o network" where the final result only depends on the node features and no graph structure involved. This configuration, referred to as the "w/o network" setting, results in a final output that solely relies on the node features, with no involvement of the graph structure.

The results on CoraML, Citeseer, and PubMed are presented in Table 1 and the results on the other 5 datasets are shown in Table 6 in Appendix E. Our model achieves the best ID accuracy for four datasets and demonstrates comparable performance to GPN for the remaining four datasets Furthermore, we observe an improvement in the ROC (Receiver Operating Characteristic) rankings based on predicted epistemic uncertainty with propagation, ranging from +1% to +8% compared to GPN. Consistent with previous studies , our results demonstrate that prediction models incorporating evidence propagation consistently outperform those without propagation across all datasets. This observation highlights the significant impact of graph structure on uncertainty estimation. Moreover, when comparing aleatoric uncertainty and epistemic uncertainty as ranking scores, we find that epistemic uncertainty outperforms aleatoric uncertainty in the OOD detection task. This finding aligns with literature [39; 32] and emphasizes the superiority of epistemic uncertainty for OOD detection.

Misclassification DetectionIn addition to OOD detection, we conduct misclassification detection on the clean graph for evaluating the predictive uncertainty estimation. Table 2 presents the results for three datasets, while Table 7 in Appendix D is for the other 5 datasets. We observe a significant improvement ranging from +12% to +50% in our model's AUC-PR scores. While it is true that our method performs worse than the best of the baselines in terms of AUROC, the differences are within approximately 3% for six of the eight datasets.: Amazon Computers, Amazon Photos, Coauthor CS, Coauthor Physics, and ODBG Arxiv, and PubMed. Despite having a lower AUROC compared to the best of the baselines, our method exhibits a higher AUPR. This suggests that our method may excel at identifying true positives among the top-ranked nodes when compared to GPN, while the best baselines may be more effective at distinguishing between true positives and negatives among the lower-ranked nodes.

### Ablation Study

Our proposed model differs from the GPN model in three main aspects. First, we use validation cross entropy (CE) instead of hold-out datasets to select hyperparameters. Second, we consider the

   &  &  &  &  \\  & & & Alea w/ & Epi w/ & Epi w/o & Alea w/ & Epi w/ & Epi w/o \\   & LP & 86.40 & 83.78 & 80.86 & n.a. & 74.80 & 71.15 & n.a. \\  & GKDE & 83.02 & 74.46 & 71.86 & n.a. & 66.19 & 64.05 & n.a. \\  & VGG-ENergy & 89.66 & 81.70 & 83.15 & n.a. & 75.67 & 78.44 & n.a. \\  & GKDE-GCN & 83.83 & 82.82 & 82.09 & n.a. & 75.88 & 77.03 & n.a. \\  & GPN & 88.51 & 83.25 & 86.28 & **80.95** & 75.79 & 79.97 & **72.81** \\  & Ours & **90.06** & **83.94** & **87.20** & 76.12 & **76.26** & **80.36** & 63.32 \\   & LP & 57.34 & 65.99 & 67.54 & n.a. & 48.12 & 48.59 & n.a. \\  & GKDE & 49.62 & 63.75 & 63.91 & n.a. & **56.74** & 56.79 & n.a. \\  & VGG-ENergy & 70.79 & 72.16 & 76.08 & n.a. & 53.71 & 58.35 & n.a. \\  & GKDE-GCN & 70.76 & 73.34 & 76.19 & n.a. & 54.25 & **59.07** & n.a. \\  & GPN & 69.79 & 72.46 & 70.74 & 66.65 & 55.14 & 50.52 & 44.93 \\  & Ours & **72.51** & **75.22** & **78.98** & **73.21** & 62.30 & 58.63 & **52.73** \\   & LP & 89.18 & **80.32** & 79.64 & n.a. & **71.01** & 72.98 & n.a. \\  & GKDE & 88.16 & 69.66 & 68.47 & n.a. & 55.81 & 54.33 & n.a. \\  & VGG-ENergy & **94.77** & 72.58 & 72.63 & n.a. & 60.54 & 60.63 & n.a. \\  & GKDE-GCN & 94.66 & 73.53 & 74.47 & n.a. & 61.36 & 61.96 & n.a. \\  & GPN & 94.08 & 71.84 & 73.91 & 71.2 & 57.92 & 67.19 & 59.72 \\  & Ours & 93.84 & 75.23 & **81.76** & **77.79** & 60.75 & **78.16** & **69.19** \\      &  &  &  &  \\  & & Alea w/ & Epi w/ & Alea w/ & Epi w/ \\   & APPNP & **83.64** & n.a & 48.39 & n.a \\  & VGG-ENergy & 81.02 & n.a & 48.30 & n.a \\  & GKDE-GCN & 80.80 & 76.83 & 49.61 & 45.87 \\  & GPN & 81.19 & **78.10** & 49.51 & 44.42 \\  & Ours & 75.8 & 69.85 & **89.95** & **88.20** \\   & APPNP & 73.55 & n.a. & 51.70 & n.a. \\  & VGG-ENergy & 74.64 & n.a & 48.30 & n.a. \\  & GKDE-GCN & 75.45 & 73.83 & 54.78 & 53.57 \\  & GPN & **75.89** & **74.16** & 60.78 & 59.32 \\  & Ours & 69.15 & 68.62 & **72.67** & **72.36** \\   & APPNP & 80.98 & n.a. & 37.79 & n.a. \\  & VGG-ENergy & **81.16** & n.a. & 38.24 & n.a \\   & GKDE-GCN & 80.95 & 73.99 & 39.64 & 33.19 \\   & GPN & 80.46 & **75.88** & 40.74 & 35.11 \\   & Ours & 80.13 & 72.87 & **95.41** & **92.79** \\   
   \\ 

Table 1: AUROC and AUPR for the OOD Detectionactivation function for the MLP layers as one of the hyperparameters for selection. We expect feature value rescaling through non-linear activation of feature values to affect the density predictions. Third, we incorporate one of the proposed distance-based regularization terms to the loss function used in GPN.We conduct an ablation study to demonstrate the contribution of these three components. The results for CiteSeer and PubMed are shown in Table 3 and the remaining datasets are included in Appendix E. Hyperparameter tuning using validation cross-entropy improves GPN's performance, especially in cases where the choice of activation function has a significant impact on specific datasets. Additionally, we consistently observe performance enhancements from the distance-based regularization in both datasets, demonstrating the effectiveness of the proposed distance awareness regularization term.

## 6 Limitations

Our theoretical analyses mainly study the limitations of the UCE loss function when separating OOD from ID nodes in the learned representation space. If we include the entropy-based regularization term in Equation (6) with a sufficiently large weight \(\), some of our theoretical findings may not remain applicable. However, the entropy-based regularization term is designed to favor smooth Dirichlet distributions but not to preserve the distance between OOD and ID nodes. We conjecture that the resulting loss function is still insufficient to learn a representation space that separates OOD from ID nodes, even though they are separable in the original feature space. In addition, our proposed regularization terms in Section 4.2 are more effective for homophily graphs than heterophily graphs, as neighboring nodes are less likely to belong to the same class in a heterophily graph than those in a homophily graph.

## 7 Conclusion

This paper contributed to a better understanding of uncertainty quantification for node classification. We investigated the limitations of the widely used UCE loss function. Motivated by the theoretical analysis, we proposed a distance-based regularization that helps learn a representation network that is more effective for the uncertainty quantification task. Experimentally, we demonstrated our approach outperforms the state-of-the-art in two specific applications of uncertainty quantification for node classification: OOD detection and misclassification detection.

## 8 Acknowledgments

This work is supported by the National Science Foundation (NSF) under Grant No #2220574, #2107449, #1846690, and #1750911. The work of Feng Chen is also supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior/Interior Business Center (DOI/IBC) contract number 140D0423C0026. The US Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA DOI/IBC or the U.S. Government.

   &  &  &  &  \\  & & & Alea w/ & Epi w/ & Epi w/o & Alea w/ & Epi w/ & Epi w/o \\   & GPN & 69.79 & 72.46 & 70.74 & 66.65 & 55.14 & 50.52 & 44.93 \\  & GPN-CE & 70.98 & 74.20 & 73.75 & 68.41 & 58.12 & 53.55 & 46.60 \\  & GPN-CE-ACT & 71.96 & 74.72 & 77.97 & 72.28 & 60.41 & 56.04 & 50.73 \\  & GPN-CE-GD & **72.51** & **75.22** & **78.98** & **73.21** & **62.30** & **58.63** & **52.73** \\   & GPN & **94.08** & 71.84 & 73.91 & 71.2 & 57.92 & 67.19 & 59.72 \\  & GPN-CE & 93.84 & 74.19 & 78.32 & 74.50 & 59.85 & 74.11 & 64.55 \\   & GPN-CE-ACT & 93.84 & 74.19 & 78.32 & 74.50 & 59.85 & 74.11 & 64.55 \\   & GPN-CE-GD & 93.84 & **75.23** & **81.76** & **77.79** & **60.75** & **78.16** & **69.19** \\  

* Alea: Aleatoric, Epi.: Epistemic, w/ with propagation
* GPN refers to the original GPN paper with its default hyperparameters and ReLU as the middle activation function, GPN-CE is the original GPN model with re-tuned Dirichlet entropy regularization weight based on validation cross-entropy; GPN-CE-ACT is the original GPN model with re-tuned entropy regularization weight and activation function based on cross-entropy; GPN-CE-GD(Ours) adds the distance-based regularization term while tuning the two weights and activation function.

Table 3: Ablation Study with OOD Detection task