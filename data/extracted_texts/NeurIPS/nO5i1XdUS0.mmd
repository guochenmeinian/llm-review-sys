# Eliminating Domain Bias for Federated Learning in Representation Space

Jianqing Zhang\({}^{1}\), Yang Hua\({}^{2}\), Jian Cao\({}^{1}\), Hao Wang\({}^{3}\),

**Tao Song\({}^{1}\) Zhengui Xue\({}^{1}\), Ruhui Ma\({}^{1}\)*, Haibing Guan\({}^{1}\)**

\({}^{1}\)Shanghai Jiao Tong University \({}^{2}\)Queen's University Belfast \({}^{3}\)Louisiana State University

{tsingz, cao-jian, songt333, zhenguixue, ruhuima, hbguan}@sjtu.edu.cn

Y.Hua@qub.ac.uk, haowang@lsu.edu

Corresponding authors.

###### Abstract

Recently, federated learning (FL) is popular for its privacy-preserving and collaborative learning abilities. However, under statistically heterogeneous scenarios, we observe that biased data domains on clients cause a _representation bias_ phenomenon and further degenerate generic representations during local training, _i.e._, the _representation degeneration_ phenomenon. To address these issues, we propose a general framework _Domain Bias Eliminator_ (DBE) for FL. Our theoretical analysis reveals that DBE can promote bi-directional knowledge transfer between server and client, as it reduces the domain discrepancy between server and client in representation space. Besides, extensive experiments on four datasets show that DBE can greatly improve existing FL methods in both generalization and personalization abilities. The DBE-equipped FL method can outperform ten state-of-the-art personalized FL methods by a large margin. Our code is public at https://github.com/TsingZO/DBE.

## 1 Introduction

As a popular distributed machine learning paradigm with excellent privacy-preserving and collaborative learning abilities, federated learning (FL) trains models among clients with their private data kept locally . Traditional FL (_e.g._, the famous FedAvg ) learns one single global model in an iterative manner by locally training models on clients and aggregating client models on the server. However, it suffers an accuracy decrease under statistically heterogeneous scenarios, which are common scenarios in practice .

Due to statistical heterogeneity, the data domain on each client is biased, which does not contain the data of all labels . As the received global model is locally trained on individual clients' biased data domain, we observe that this model extracts biased (_i.e._, forming client-specific clusters) representations during local training. We call this phenomenon "_representation bias_" and visualize it in Figure 1. Meanwhile, by training the received global model with missing labels, the generic representation quality over all labels also decreases during local training . Furthermore, we ob

Figure 1: t-SNE  visualization and per-layer MDL (bits) for representations before/after local training in FedAvg. We use _color_ and _shape_ to distinguish _labels_ and _clients_ respectively for t-SNE. A large MDL means low representation quality. _Best viewed in color and zoom-in._serve that this "_representation degeneration_" phenomenon happens at every layer, as shown in Figure 1(c). We estimate the representation quality via minimum description length (MDL) [62; 65; 74], a metric independent of data and models, measuring the difficulty of classifying target labels according to given representations.

To tackle the statistical heterogeneity, unlike traditional FL that learns a single global model, personalized FL (pFL) comes along by learning personalized models (or modules) for each client besides learning a global model among clients [20; 22; 69]. Typically, most of the existing pFL methods train a personalized classifier2 for each client [3; 14; 20; 61], but the feature extractor still extracts all the information from the biased local data domain, leading to representation bias and representation degeneration during local training.

To address the representation bias and representation degeneration issues in FL, we propose a general framework _Domain Bias Eliminator_ (DBE) for FL including two modules introduced as follows. Firstly, we detach the representation bias from original representations and preserve it in a _Personalized Representation Bias Memory_ (PBRM) on each client. Secondly, we devise a _Mean Regularization_ (MR) that explicitly guides local feature extractors to extract representations with a consensual global mean during local training to let the local feature extractor focus on the remaining unbiased information and improve the generic representation quality. In this way, we turn one level of representation between the feature extractor and the classifier on each client into two levels of representation with a client-specific bias and a client-invariant mean, respectively. Thus, we can eliminate the _conflict_ of extracting representations with client-specific biases for clients' requirements while extracting representations with client-invariant features for the server's requirements in the same representation space. Our theoretical analysis shows that DBE can promote the bi-directional knowledge transfer between server and client with lower generalization bounds.

We conduct extensive experiments in computer vision (CV) and natural language processing (NLP) fields on various aspects to study the characteristics and effectiveness of DBE. In both generalization ability (measured by MDL) and personalization ability (measured by accuracy), DBE can promote the fundamental FedAvg as well as other representative FL methods. Furthermore, we compare the representative FedAvg+DBE with ten state-of-the-art (SOTA) pFL methods in various scenarios and show its superiority over these pFL methods. To sum up, our contributions are:

* We observe the representation bias and per-layer representation degeneration phenomena during local training in the representative FL method FedAvg.
* We propose a framework DBE to memorize representation bias on each client to address the representation bias issue and explicitly guide local feature extractors to generate representations with a universal mean for higher generic representation quality.
* We provide theoretical analysis and derive lower generalization bounds of the global and local feature extractors to show that DBE can facilitate bi-directional knowledge transfer between server and client in each iteration.
* We show that DBE can improve other representative traditional FL methods including FedAvg at most **-22.35%** in MDL (bits) and **+32.30** in accuracy (%), respectively. Furthermore, FedAvg+DBE outperforms SOTA pFL methods by up to **+11.36** in accuracy (%).

## 2 Related Work

Traditional FL methods that focus on improving accuracy under statistically heterogeneous scenarios based on FedAvg including four categories: update-correction-based FL [25; 38; 60], regularization-based FL [1; 17; 40; 46], model-split-based FL [35; 45], and knowledge-distillation-based FL [27; 33; 88; 96]. For pFL methods, we consider four categories: meta-learning-based pFL [13; 22], regularization-based pFL [47; 67], personalized-aggregation-based pFL [21; 52; 87; 21], and model-split-based pFL [3; 14; 20; 61; 85]. Due to limited space, we only introduce the FL methods that are close to ours and leave the _extended version of this section_ to Appendix A.

**Traditional FL methods.** MOON  utilizes contrastive learning to correct the local training of each client, but this input-wise contrastive learning still relies on the biased local data domain, so it still suffers from representation skew. Although FedGen  learns a shared generator on the server and reduces the heterogeneity among clients with the generated representations through knowledge distillation, it only considers the local-to-global knowledge for the single global model learning. On the other hand, FedGen additionally brings non-negligible communication and computation overhead for learning and transmitting the generator.

pFL methods.FedPer  and FedRep  keep the classifier locally, but the feature extractor still learns biased features without explicit guidance. Besides, their local feature extractors are trained to cater to personalized classifiers thus losing generality. FedRoD  reduces the discrepancy of local training tasks among clients by using a balanced softmax (BSM) loss function , but the BSM is useless for missing labels on each client while label missing is a common situation in statistically heterogeneous scenarios [50; 86; 89]. Moreover, the uniform label distribution modified by the BSM cannot reflect the original distribution. Differently, FedBABU  trains a global feature extractor with a naive and frozen classifier, then it fine-tunes the classifier for each client to finally obtain personalized models. However, the post-FL fine-tuning study is beyond the FL scope, as almost all the FL methods have multiple fine-tuning variants, _e.g._, fine-tuning the whole model or only a part of the model. Like FedAvg, FedBABU still locally extracts biased features during the FL process.

## 3 Notations and Preliminaries

### Notations

In this work, we discuss the statistically heterogeneous scenario in typical multi-class classification tasks for FL, where \(N\) clients share the same model structure. Here, we denote notations following FedGen  and FedRep . The client \(i,i[N]\), has its own private data domain \(_{i}\), where the data are sampled from \(_{i}\). All the clients collaborate to train a global model \(g\) parameterized by \(\) without sharing their private local data.

Since we focus on representation learning in FL, we regard \(g\) as the sequential combination of a feature extractor \(f\) that maps from the input space \(\) to a representation space \(\), _i.e._, \(f:\) parameterized by \(^{f}\) and a classifier \(h\) that maps from the representation space to the output space \(^{}\), _i.e._, \(h:^{}\) parameterized by \(^{h}\). Formally, we have \(g:=h f\), \(:=[^{f};^{h}]\), \(^{D}\) and \(^{K}\). \(^{}\) is the simplex over label space \(\). With any input \(\), we obtain the feature representation by \(=f(;^{f})\).

### Traditional Federated Learning

With the collaboration of \(N\) clients, the objective of traditional FL, _e.g._, FedAvg , is to iteratively learn a global model that minimizes its loss on each local data domain:

\[_{}\ _{i[N]}[_{_{i}}()],\] (1)

\[_{_{i}}():=_{(_{i},y_{i}) _{i}}[(g(_{i};),y_{i})]=_{( {x}_{i},y_{i})_{i}}[(h(f(_{i};^{f});^{h}),y_{i})],\] (2)

where \(:^{}\) is a non-negative and convex loss function. Following FedGen, we assume that all clients share an identical loss function \(\) and a _virtual_ global data domain \(\), which is the union of all local domains: \(:=_{i=1}^{N}_{i}\). In practice, traditional FL methods [45; 46; 56] optimize Eq. (1) by \(_{}_{i=1}^{N}}{n_{i}}_{}_{i}}()\), where \(}_{i}\) is an observable dataset, \(n_{i}=|}_{i}|\) is its size, and \(n=_{i=1}^{N}n_{i}\).

In each communication iteration, clients conduct local updates on their private data to train the global model \(\) by minimizing their local loss. Formally, for client \(i\), the objective during local training is \(_{}\ _{_{i}}()\). The empirical version of \(_{_{i}}()\) is \(_{}_{i}}():=}_{j=1}^{n _{i}}(h(f(_{ij};^{f});^{h}),y_{ij})\), which is optimized by stochastic gradient descent (SGD) [56; 90] in FedAvg.

## 4 Method

### Problem Statement

pFL iteratively learns a personalized model or module for each client with the assistance of the global model parameters from the server. Our objective is (with a slight reuse of the notation \(_{_{i}}\))

\[_{_{1},,_{N}}\ _{i[N]}[_{ _{i}}(_{i})],\] (3)where \(_{i}\) is a model consisting of global and personalized modules. The global modules are locally trained on clients and shared with the server for aggregation like traditional FL, but the personalized modules are preserved locally on clients. Following traditional FL, we empirically optimize Eq.3 by \(_{_{1},,_{N}}_{i=1}^{N}}{n} _{}_{i}}(_{i})\).

### Personalized Representation Bias Memory (Prbm)

Due to the existence of statistical heterogeneity in FL, the local feature extractor intends to learn biased representations after being overwritten by the received global model parameters. To detach and store the representation bias locally, we propose a personalized module PRBM that memorizes representation bias for client \(i\). Originally, the feature representation \(_{i}^{K}\) is directly fed into the predictor in Eq.2. Instead, we consider \(_{i}\) as the combination of a global \(_{i}^{g}^{K}\) and a personalized \(}_{i}^{p}^{K}\), _i.e._,

\[_{i}:=_{i}^{g}+}_{i}^{p}.\] (4)

We let the feature extractor output \(_{i}^{g}\) instead of the original \(_{i}\), _i.e._, \(_{i}^{g}:=f(_{i};^{f})\) and keep the trainable vector \(}_{i}^{p}\) locally. \(}_{i}^{p}\) is specific among clients but identical for all the local data on one client, so it memorizes client-specific mean. The original feature extractor is trained to capture the biased features for \(_{i}\). Instead, with the personalized mean stored in \(}_{i}^{p}\), the feature extractor turns to capture \(_{i}^{g}\) with less biased feature information. We illustrate the difference between the original approach and our method in Figure2 (PRBM). Then, we define the local objective as \(_{_{i}}~{}_{_{i}}(_{i})\), where \(_{i}:=[^{f};}_{i}^{p};^{h}]\),

\[_{_{i}}(_{i}):=_{(_{i},y_{i} )_{i}}[(h(f(_{i};^{f})+}_{i}^{p };^{h}),y_{i})].\] (5)

From the view of transformation, we rewrite Eq.5 to

\[_{_{i}}(_{i}):=_{(_{i},y_{i} )_{i}}[(h((f(_{i};^{f}); {}_{i}^{p});^{h}),y_{i})],\] (6)

where \(:\) a personalized _translation_ transformation  parameterized by \(}_{i}^{p}\). Formally, \((_{i}^{g};}_{i}^{p})=_{i}^{g}+} _{i}^{p},~{}_{i}^{g}\). With PRBM, we create an additional level of representation \(_{i}^{g}\) besides the original level of representation \(_{i}\). We call \(_{i}^{g}\) and \(_{i}\) as the _first and second levels of representation_, respectively. For the original local model (Figure2(a)), we have \(_{i}^{g}_{i}\).

### Mean Regularization (Mr)

Without explicit guidance, it is hard for the feature extractor and the _trainable_ PRBM to distinguish between unbiased and biased information in representations automatically. Therefore, to let the feature extractor focus on the unbiased information and further separate \(_{i}^{g}\) and \(}_{i}^{p}\), we propose an MR that explicitly guides the local feature extractor to generate \(_{i}^{g}\) with the help of a client-invariant mean, which is opposite to the client-specific mean memorized in \(}_{i}^{p}\), as shown in Figure2 (MR). Specifically, we regularize the mean of \(_{i}^{g}\) to the consensual global mean \(}^{g}\) at each feature dimension independently. We then modify Eq.6 as

\[_{_{i}}(_{i}):=_{(_{i},y_{i} )_{i}}[(h((f(_{i};^{f}); {}_{i}^{p});^{h}),y_{i})]+(}_ {i}^{g},}^{g}),\] (7)

where \(}_{i}^{g}=_{(_{i},y_{i})_{i}}[f(_{i};^{f})]\). We obtain the consensus \(}^{g}=_{i=1}^{N}}_{i}^{g}\)_during the initialization period before FL (see Algorithm1)_. We measure the distance of \(}_{i}^{g}\) and \(}^{g}\) by mean squared error (MSE) , and \(\) is a hyperparameter to control the importance of MR for different tasks. Empirically,

\[_{}_{i}}(_{i}):=}_{j=1} ^{n_{i}}(h((f(_{ij};^{f});}_{i}^{ p});^{h}),y_{ij})+(}_{j=1}^{n_{i}}f( _{ij};^{f}),}^{g}),\] (8)

which is also optimized by SGD following FedAvg.

Figure 2: The illustration of the local model. We emphasize the parts that correspond to PRBM and MR with red and green, respectively.

In Eq. (8), the value of the MR term is obtained after calculating the empirical version of \(}_{i}^{g}\): \(}_{i}^{g}=}_{j=1}^{n_{i}}f(_{ij};^ {f})\) over the entire local data, but the loss computing in SGD cannot see all the local data during one forward pass in one batch. In practice, inspired by the widely-used moving average [48; 90] in approximating statistics over data among batches, in each batch, we obtain

\[}_{i}^{g}=(1-)}_{i,old}^{g}+}_ {i,new}^{g},\] (9)

where \(}_{i,old}^{g}\) and \(}_{i,new}^{g}\) are computed in the previous batch and current batch, respectively. \(\) is a hyperparameter called momentum that controls the importance of the current batch. The feature extractor is updated continuously during local training but discontinuously between adjacent two iterations due to server aggregation. Thus, we only calculate \(}_{i}^{g}\) via Eq. (9) during local training and recalculate it in a new iteration without using its historical records. We consider the representative FedAvg+BBE as an example and show the entire learning process in Algorithm 1.

```
0:\(N\) clients with their local data; initial parameters \(^{f,0}\) and \(^{h,0}\); \(\): local learning rate; \(\) and \(\): hyperparameters; \(\): client joining ratio; \(E\): local epochs; \(T\): total communication iterations.
0: Global model parameters \(\{^{f},^{h}\}\) and personalized model parameters \(\{}_{1}^{p},,}_{N}^{p}\}\).
1:Server sends \(\{^{f,0},^{h,0}\}\) to all clients to initialize their local models. \(\)Initialization Period
2:\(N\) clients train their local models without DBE for one epoch and collect client-specific mean \(\{}_{1}^{g},,}_{N}^{g}\}\) over their data domain.
3:Server generates a consensual global mean \(}^{g}\) through weighted averaging: \(}^{g}=_{i=1}^{N}}{n}}_{i}^{g}\).
4:Client \(i\) initializes \(}_{i}^{p,0}\), \( i[N]\). \(\)Federated Learning Period
5:for communication iteration \(t=1,,T\)do
6: Server samples a client subset \(^{t}\) based on \(\).
7: Server sends \(\{^{f,t-1},^{h,t-1}\}\) to each client in \(^{t}\).
8:forClient \(i^{t}\) in parallel do
9: Initialize \(f\) and \(h\) with \(^{f,t-1}\) and \(^{h,t-1}\), respectively.
10: Obtain \(\{_{i}^{f,t},}_{i}^{p,t},_{i,t}^{h,t}\}\) using SGD for \(_{_{i}}\ _{}_{i}}(_{i})\) with \(\), \(\) and \(\) for \(E\) epochs.
11: Upload \(\{_{i}^{f,t},_{i}^{h,t}\}\) to the server.
12: Server calculates \(n^{t}=_{i^{t}}n_{i}\) and obtains
13:\(^{f,t}=_{i^{t}}}{n}^{f,t}\);
14:\(^{h,t}=_{i^{t}}}{n}_{i}^{h,t}\);
15:return\(\{^{f,T},^{h,T}\}\) and \(\{}}_{1}^{p,T},,}}_{N}^{p,T}\}\) ```

**Algorithm 1** The Learning Process in FedAvg+BBE

### Improved Bi-directional Knowledge Transfer

In the FL field, prior methods draw a connection from FL to domain adaptation for theoretical analysis and consider a binary classification problem [21; 55; 69; 96]. The traditional FL methods, which focus on enhancing the performance of a global model, regard local domains \(_{i},i[N]\) and the virtual global domain \(\) as the source domain and the target domain, respectively , which is called local-to-global knowledge transfer in this paper. In contrast, pFL methods that focus on improving the performance of personalized models regard \(\) and \(_{i},i[N]\) as the source domain and the target domain, respectively [21; 55; 69]. We call this kind of adaptation as global-to-local knowledge transfer. The local-to-global knowledge transfer happens on the server while the global-to-local one occurs on the client. Please refer to Appendix B for details and proofs.

#### 4.4.1 Local-To-Global Knowledge Transfer

Here, we consider the transfer after the server receives a client model. We guide the feature extractor to learn representations with a global mean and gradually narrow the gap between the local domain and global domain at the first level of representation (_i.e._, \(_{i}^{g}\)) to improve knowledge transfer:

**Corollary 1**.: _Consider a local data domain \(_{i}\) and a virtual global data domain \(\) for client \(i\) and the server, respectively. Let \(_{i}=_{i},c^{*}\) and \(=,c^{*}\), where \(c^{*}:\) is a ground-truthlabeling function. Let \(\) be a hypothesis space of VC dimension \(d\) and \(h:,\,h\). When using DBE, given a feature extraction function \(^{g}:\) that shared between \(_{i}\) and \(\), a random labeled sample of size \(m\) generated by applying \(^{g}\) to a random sample from \(_{i}\) labeled according to \(c^{*}\), then for every \(h^{g}\), with probability at least \(1-\):_

\[_{}(h^{g})_{}_{i}}(h^{g}) +(d+)}+d_{}( }_{i}^{g},}^{g})+_{i},\]

_where \(_{}_{i}}\) is the empirical loss on \(_{i}\), \(e\) is the base of the natural logarithm, and \(d_{}(,)\) is the \(\)-divergence between two distributions. \(_{i}:=_{h^{g}}_{}(h^{g})+_{ _{i}}(h^{g})\), \(}_{i}^{g}\), \(}^{g}\), and \(d_{}(}_{i}^{g},}^{g}) d_{ }(}_{i},})\). \(}_{i}^{g}\) and \(}^{g}\) are the induced distributions of \(_{i}\) and \(\) under \(^{g}\), respectively. \(}_{i}\) and \(}\) are the induced distributions of \(_{i}\) and \(\) under \(\), respectively. \(\) is the feature extraction function in the original FedAvg without DBE._

As shown in Figure 2, given any \(_{i}\) on client \(i\), one can obtain \(_{i}\) via \(\) in original FedAvg or obtain \(_{i}^{g}\) via \(^{g}\) in FedAvg+DBE. With \(d_{}(}_{i}^{g},}^{g}) d_{ }(}_{i},})\) holds, we can achieve a lower generalization bound in local-to-global knowledge transfer than traditional FL, thus training a better global feature extractor to produce representations with higher quality over all labels. A small gap between the local domain and global domain in \(\) promotes the knowledge transfer from clients to the server [82; 92; 94].

#### 4.4.2 Global-To-Local Knowledge Transfer

The global-to-local knowledge transfer focuses on the assistance role of the global model parameters for facilitating local training, _i.e._, the transfer ability from \(\) to \(_{i}\). After the client receives the global model and equips it with PRBM, for the second level of representation (_i.e._, \(_{i}\)), we have

**Corollary 2**.: _Let \(_{i}\), \(\), \(^{g}\), and \(_{i}\) defined as in Corollary 1. Given a translation transformation function \(:\) that shared between \(_{i}\) and virtual \(\), a random labeled sample of size \(m\) generated by applying \(^{}\) to a random sample from \(_{i}\) labeled according to \(c^{*}\), \(^{}=^{g}: \), then for every \(h^{}\), with probability at least \(1-\):_

\[_{_{i}}(h^{})_{}}(h^ {})+(d+)}+d_{ }(}^{},}_{i}^{})+ _{i},\]

_where \(d_{}(}^{},}_{i}^{}) =d_{}(}^{g},}_{i}^{g}) d_{ }(},}_{i})=d_{}( }_{i},})\). \(}^{}\) and \(}_{i}^{}\) are the induced distributions of \(\) and \(}_{i}\) under \(^{}\), respectively._

Given \(_{i}\) on client \(i\), we can obtain \(_{i}\) via \(^{}\) in FedAvg+DBE. \(h^{g}=h^{}\), so PRBM does not influence the value of \(d_{}(,)\) for the pair of \(h^{g}\) and \(h^{}\) (see Appendix B.3), then we have \(d_{}(}^{},}_{i}^{}) =d_{}(}^{g},}_{i}^{g})\). The inequality \(d_{}(}^{},}_{i}^{})  d_{}(},}_{i})\) shows that the information aggregated on the server can be more easily transferred to clients with our proposed DBE than FedAvg. We train PRBM on the local loss and preserve it locally, so the local feature extractors can generate representations suitable for clients' personalized tasks. According to Corollary 1 and Corollary 2, adding DBE facilitates the bi-directional knowledge transfer in each iteration, gradually promoting global and local model learning as the number of iterations increases.

### Negligible Additional Communication and Computation Overhead

DBE only modifies the local training, so the downloading, uploading, and aggregation processes in FedAvg are unaffected. In FedAvg+DBE, the communication overhead per iteration is the same as FedAvg but requires fewer iterations to converge (see Appendix D). Moreover, PRBM only introduces \(K\) additional trainable parameters, and the MSE value in the parameterless MR is computed for two representations of \(K\) dimension. \(K\) is the representation space dimension, typically a smaller value than the dimension of data inputs or model parameters [8; 83]. Thus, DBE introduces no additional communication overhead and negligible computation overhead for local training in any iteration.

### Privacy-Preserving Discussion

Compared to FedAvg, using DBE requires client \(i\) to upload one client-specific mean \(_{i}^{g}\) (one \(K\)-dimensional vector) to the server _only once before FL_, which solely captures the magnitude of the mean value for each feature dimension within the context of the given datasets and models. Thanks to this particular characteristic, as shown in Section 5.1.4, the performance of FedAvg+DBE can be minimally affected while enhancing its privacy-preserving capabilities by introducing proper Gaussian noise with a zero mean to \(_{i}^{g}\) during the initialization phase.

## 5 Experiments

Datasets and models.Following prior FL approaches [14; 20; 45; 50; 56], we use four public datasets for classification problems in FL, including three CV datasets: Fashion-MNIST (FM-NIST) , Cifar100 , and Tiny-ImageNet (100K images with 200 labels) , as well as one NLP dataset: AG News . For three CV datasets, we adopt the popular 4-layer CNN by default following FedAvg, which contains two convolution layers (denoted by CONV1 and CONV2) and two fully connected layers (denoted by FC1 and FC2). Besides, we also use a larger model ResNet-18  on Tiny-ImageNet. For AG News, we use the famous text classification model fastText .

Statistically heterogeneous scenarios.There are two widely used approaches to construct statistically heterogeneous scenarios on public datasets: the pathological setting [56; 66] and practical setting [45; 50]. For the pathological setting, disjoint data with 2/10/20 labels for each client are sampled from 10/100/200 labels on FMNIST/Cifar100/Tiny-ImageNet with different data amounts. For the practical setting, we sample data from FMNIST, Cifar100, Tiny-ImageNet, and AG News based on the Dirichlet distribution  (denoted by \(Dir()\)). Specifically, we allocate a \(q_{c,i}\) (\(q_{c,i} Dir()\)) proportion of samples with label \(c\) to client \(i\), and we set \(=0.1\)/\(=1\) by default for CV/NLP tasks following previous FL approaches [50; 75].

Implementation Details.Following pFedMe and FedRoD, we have 20 clients and set client participating ratio \(=1\) by default unless otherwise stated. We measure the generic representation quality across clients and evaluate the MDL [65; 74] of representations over all class labels. To simulate the common FL scenario where data only exists on clients, we split the data among each client into two parts: a training set (75% data) and a test set (25% data). Following pFedMe, we evaluate pFL methods by averaging the results of personalized models on the test set of each client and evaluate traditional FL methods by averaging the results of the global model on each client. Following FedAvg, we set the batch size to 10 and the number of local epochs to 1, so the number of local SGD steps is \(}{10}\) for client \(i\). We run three trials for all methods until empirical convergence on each task and report the mean value. For more details and results (_e.g._, fine-tuning FedAvg on new participants and a real-world application), please refer to Appendix D.

### Experimental Study for Adding Dbe

#### 5.1.1 How to Split the Model?

A model is split into a feature extractor and a classifier, but there are various ways for splitting, as each layer in a deep neural network (DNN) outputs a feature representation and feeds it into the next layer [8; 44][8; 44]. We focus on inserting DBE between the feature extractor and the classifier, but which splitting way is the best for DBE? Here we answer this question by comparing the results regarding MDL and accuracy when the model is split at each layer in the popular 4-layer CNN. We show the MDL of the representation \(_{i}^{g}\) outputted by the prepositive layer of DBE (with underline here) and show MDL of \(_{i}\) for other layers. Low MDL and high accuracy indicate superior generalization ability and superior personalization ability, respectively.

In Table 1, the generic representation quality is improved at each layer for all splitting ways, which shows that no matter how the model is split, DBE can enhance the generalization ability of the global feature extractor. Among these splitting ways, assigning all FC layers to the classifier, _i.e._, CONV2\(\)DBE\(\)FC1, achieves almost the lowest MDL and highest accuracy. Meanwhile, FC1\(\)DBE\(\)FC2 can also achieve excellent performance with **only**\(4.73\%\) trainable parameters for DBE.

Since FedRep, FedRoD, and FedBABU choose the last FC layer as the classifier by default, we follow them for a fair comparison and insert DBE before the last FC layer (_e.g._, FC1\(\)DBE\(\)FC2). In Table 1, our FC1\(\)DBE\(\)FC2 outperforms FedPer, FedRep, FedRoD, FedBABU, and FedAvg with lower MDL and higher accuracy. Since feature extractors in FedPer and FedRep are locally trained to cater to personalized classifiers, they extract representations with low quality.

#### 5.1.2 Representation Bias Eliminated for the First Level of Representation

We visualize the feature representations using t-SNE  in Figure 3. Compared to the representations outputted by the feature extractor in FedAvg, \(_{i}^{g}\) in FedAvg+DBE is no longer biased to the local data domain of each client after local training. With the personalized translation transformation PRBM, \(_{i}\) can fit the local domain of each client either before or after local training. According to Figure 3(b), Figure 3(e) and Figure 3(f), \(_{i}\) in FedAvg+DBE can fit the local domain better than FedAvg.

#### 5.1.3 Ablation Study for Dbe

We further study the contribution of MR and PRBM in terms of generalization and personalization abilities by applying only one of them to FedAvg. From Table 2, we find that for 4-layer CNN and ResNet-18, +DBE gives a larger improvement in both MDL and accuracy than just using MR or PRBM, which suggests that MR and PRBM can boost each other in bi-directional knowledge transfer. The contribution of MR is greater than that of PRBM in improving the generalization ability in MDL, while +PRBM gains more accuracy improvement for personalization ability than MR.

#### 5.1.4 Privacy-Preserving Ability

Following FedPAC , we add Gaussian noise to client-specific means \(_{1}^{g},,_{N}^{g}\) with a scale parameter (\(s\)) for the noise distribution and perturbation coefficient (\(q\)) for the noise. Adding the unbiased noise sampled from one distribution is beneficial for representation bias elimination and can further improve the performance of DBE to some extent, as shown in Table 3. Besides, adding too much noise can also bring an accuracy decrease. However, setting \(s=0.05\) and \(q=0.2\) is sufficient to ensure privacy protection according to FedPCL.

  
**Metrics** &  &  &  \\   & CONV1\(\)CONV2 & CONV2\(\)FC1 & FC1\(\)FC2 & Logits & & \\  FedPer  & 5143 & 4574 & 3885 & 4169 & 33.84 & — \\ FedRep  & 5102 & 4237 & 3922 & 4244 & 37.27 & — \\ FedRoD  & 5063 & 4264 & 3783 & 3820 & 36.43 & — \\ FedABBU  & 5083 & 4181 & 3948 & 3849 & 16.86 [36.82] & — \\  Original (FedAvg) & 5081 & 4151 & 3844 & 3895 & 19.46 & 0 \\ CONV1\(\)DBE\(\)CONV2 & 4650 (-8.48\%) & 4105 (-1.11\%) & 3679 (-4.29\%) & 3756 (-3.5\%) & 21.81 (+2.35) & 28800 \\ CONV2\(\)DBE\(\)FC1 & **4348 (-14.43\%)** & 3716 (-10.48\%) & **3463 (-9.91\%)** & **3602 (-7.52\%)** & **47.03 (+27.57)** & 10816 \\ FC1\(\)DBE\(\)FC2 & 4608 (-9.31\%) & **3689 (-11.13\%)** & 3625 (-5.70\%) & 3688 (-5.31\%) & 43.32 (+23.86) & 512 \\   

Table 1: The MDL (bits, \(\)) of layer-wise representations, test accuracy (%, \(\)), and the number of trainable parameters (\(\)) in PRBM when adding DBE to FedAvg on Tiny-ImageNet using 4-layer CNN in the practical setting. We also show corresponding results for the close pFL methods. For FedBABU, “[36.82]” indicates the test accuracy after post-FL fine-tuning for 10 local epochs.

  
**Models** &  &  \\ 
**Components** & FedAvg & +MR & +PRBM & +DBE & FedAvg & +MR & +PRBM & +DBE \\  MDL & 3844 & 3643 & 3699 & **3625** & 3560 & 3460 & 3471 & **3454** \\ Accuracy & 19.46 & 22.21 & 26.70 & **43.32** & 19.45 & 20.85 & 38.27 & **42.98** \\   

Table 2: The MDL (bits, \(\)) and test accuracy (%, \(\)) when adding DBE to FedAvg on Tiny-ImageNet using 4-layer CNN and ResNet-18 in the practical setting.

Figure 3: t-SNE visualization for representations on Tiny-ImageNet (200 labels). “B” and “A” denote “before local training” and “after local training”, respectively. We use _color_ and _shape_ to distinguish _labels_ and _clients_, respectively. _Best viewed in color and zoom-in_.

#### 5.1.5 Dde Improves Other Traditional Federated Learning Methods

A large number of FL methods design algorithms based on the famous FedAvg . Although we describe DBE based on FedAvg for example, DBE can also be applied to other traditional FL methods to improve their generalization and personalization abilities. Here, we apply DBE to another four representative traditional FL methods: SCAFFOLD , FedProx , MOON , and FedGen . They belong to four categories: update-correction-based FL, regularization-based FL, model-split-based FL, and knowledge-distillation-based FL, respectively. In Table 4, DBE promotes traditional FL methods by at most -**22.35%** in MDL (bits) and **+32.30** in accuracy (%), respectively. Based on the results of Table 2 and Table 4 on Tiny-ImageNet, FedAvg+DBE achieves lower MDL and higher accuracy than close methods MOON and FedGen.

### Comparison with Personalized Federated Learning Methods

#### 5.2.1 Personalization Ability on Various Datasets

To further show the superiority of the DBE-equipped traditional FL methods to existing pFL methods, we compare the representative FedAvg+DBE with ten SOTA pFL methods, as shown in Table 5. Note that APPLE is designed for cross-silo scenarios and assumes \(=1\). For Per-FedAvg and FedBABU, we show the test accuracy after post-FL fine-tuning. FedAvg+DBE improves FedAvg at most **+47.40**

  
**Metrics** &  &  \\ 
**Datasets** & Cifar100 & TINY & TINY* & AG News & Cifar100 & TINY & TINY* & AG News \\  SCAFFOLD  & 1499 & 3661 & 3394 & 1931 & 33.08 & 23.26 & 24.90 & 88.13 \\ FedProx  & 1523 & 3701 & 3570 & 2092 & 31.99 & 19.37 & 19.27 & 87.21 \\ MOON  & 1516 & 3696 & 3536 & 1836 & 32.37 & 19.68 & 19.02 & 84.14 \\ FedGen  & 1506 & 3675 & 3551 & 1414 & 30.96 & 19.39 & 18.53 & 89.86 \\  SCAFFOLD+DBE & **1434** & **3549** & **3370** & **1743** & **63.61** & **45.55** & **45.09** & **96.73** \\ FedProx+DBE & **1439** & **3587** & **3490** & **1689** & **63.22** & **42.28** & **41.45** & **96.62** \\ MOON+DBE & **1432** & **3580** & **3461** & **1683** & **63.26** & **43.43** & **41.10** & **96.68** \\ FedGen+DBE & **1426** & **3563** & **3488** & **1098** & **63.26** & **42.54** & **41.87** & **97.16** \\   

Table 4: The MDL (bits, \(\)) and test accuracy (%, \(\)) before and after adding DBE to traditional FL methods on Cifar100, Tiny-ImageNet, and AG News in the practical setting. TINY and TINY* represent using 4-layer CNN and ResNet-18 on Tiny-ImageNet, respectively.

    &  &  \\  Original & \(s=0.05\) & \(s=0.5\) & \(s=1\) & \(s=5\) & \(q=0.1\) & \(q=0.5\) & \(q=0.8\) & \(q=0.9\) \\ 
43.32 & 44.10 & 44.15 & 43.78 & 36.27 & 43.81 & **44.45** & 43.30 & 41.75 \\   

Table 3: The test accuracy (%, \(\)) using FedAvg+DBE on TINY in the practical setting with noise.

  
**Settings** &  &  \\   & FMNIST & Cifar100 & TINY & FMNIST & Cifar100 & Cifar100\({}^{}\) & TINY & TINY* & AG News \\  Per-FedAvg  & 99.18 & 56.80 & 28.06 & 95.10 & 44.28 & 38.28 & 25.07 & 21.81 & 87.08 \\ pFedMe  & 99.35 & 58.20 & 27.71 & 97.25 & 47.34 & 31.13 & 26.93 & 33.44 & 87.08 \\ Ditto  & 99.44 & 67.23 & 39.90 & 97.47 & 52.87 & 39.01 & 32.15 & 35.92 & 91.89 \\ FedPer  & 99.47 & 63.53 & 39.80 & 97.44 & 49.63 & 41.21 & 33.84 & 38.45 & 91.85 \\ FedRep  & 99.56 & 67.56 & 40.85 & 97.56 & 52.39 & 41.51 & 37.27 & 39.95 & 92.25 \\ FedRoD  & 99.52 & 62.30 & 37.95 & 97.52 & 50.94 & 48.56 & 36.43 & 37.99 & 92.16 \\ FedBABU  & 99.41 & 66.85 & 40.72 & 97.46 & 55.02 & 52.07 & 36.82 & 34.50 & 95.86 \\ APFL  & 99.41 & 64.26 & 36.47 & 97.25 & 46.74 & 39.47 & 34.86 & 35.81 & 89.37 \\ FedFomo  & 99.46 & 62.49 & 36.55 & 97.21 & 45.39 & 37.59 & 26.33 & 26.84 & 91.20 \\ APPLE  & 99.30 & 65.80 & 36.22 & 97.06 & 53.22 & — & 35.04 & 39.93 & 84.10 \\  FedAvg & 80.41 & 25.98 & 14.20 & 85.85 & 31.89 & 28.81 & 19.46 & 19.45 & 87.12 \\ FedAvg+DBE & **99.74** & **73.38** & **42.89** & **97.69** & **64.39** & **63.43** & **43.32** & **42.98** & **96.87** \\   

Table 5: The test accuracy (%, \(\)) of pFL methods in two statistically heterogeneous settings. Cifar100\({}^{}\) represents the experiment with 100 clients and joining ratio \(=0.5\) on Cifar100.

on Cifar100 in the pathological setting and outperforms the best SOTA pFL methods by up to **+11.36** on Cifar100\({}^{}\) including the fine-tuning-based methods that require additional post-FL effort.

#### 5.2.2 Personalization Ability Under Various Heterogeneous Degrees

Following prior methods [45; 50], we also evaluate FedAvg+DBE with different \(\) on Tiny-ImageNet using 4-layer CNN to study the influence of heterogeneity, as shown in Table 6. Most pFL methods are specifically designed for extremely heterogeneous scenarios and can achieve high accuracy at \(=0.01\), but some of them cannot maintain the advantage compared to FedAvg in moderate scenarios. However, FedAvg+DBE can automatically adapt to all these scenarios without tuning.

#### 5.2.3 MR Improves Personalized Federated Learning Methods

Since pFL methods already create personalized models or modules in their specific ways, applying personalized PRBM to the local model might be against their philosophy. To prevent this, we only apply the MR to pFL methods. Besides, the local training schemes (_e.g._, meta-learning) in Per-FedAvg, pFedMe, and APPLE are different from the simple SGD in FedAvg, which requires modification of the mean calculation in MR, so we do not apply MR to them. According to Corollary 1, MR can promote the local-to-global knowledge transfer between server and client. Therefore, pFL methods can benefit more from a better global model achieving higher accuracy on Tiny-ImageNet with the 4-layer CNN, as shown in Table 6. However, their MR-equipped variants perform worse than FedAvg+DBE (Table 5, TINY) since the representation bias still exists without using PRBM.

#### 5.2.4 Computation Overhead

We evaluate FedAvg+DBE in total time and time per iteration on Tiny-ImageNet using ResNet-18, as shown in Table 6. The evaluation task for one method monopolizes one identical machine. FedAvg, FedBABU, and FedAvg+DBE cost almost the same and have the lowest time per iteration among these methods, but FedAvg+DBE requires less total time than FedAvg and FedBABU. Note that the fine-tuning time for FedBABU is not included in Table 6. Since pFedMe and Ditto train an additional personalized model on each client, they cost plenty of time per iteration.

## 6 Conclusion

Due to the naturally existing statistical heterogeneity and the biased local data domains on each client, FL suffers from representation bias and representation degeneration problems. To improve the generalization and personalization abilities for FL, we propose a general framework DBE including two modules PRBM and MR, with a theoretical guarantee. Our DBE can promote the bi-directional knowledge transfer in each iteration, thus improving both generalization and personalization abilities. Besides, we conduct extensive experiments to show the general applicability of DBE to existing FL methods and the superiority of the representative FedAvg+DBE to ten SOTA pFL methods in various scenarios.

  
**Items** &  &  &  \\   & \(=0.01\) & \(=0.5\) & \(=5\) & Accuracy & Improvement & Total time & Time/iteration \\  Per-FedAvg  & 39.39 & 21.14 & 12.08 & — & — & 121 min & 3.56 min \\ pFedMe  & 41.45 & 17.48 & 4.03 & — & — & 1157 min & 10.24 min \\ Ditto  & 50.62 & 18.98 & 21.79 & 42.82 & 10.67 & 318 min & 11.78 min \\ FedPer  & 51.83 & 17.31 & 9.61 & 41.78 & 7.94 & 83 min & 1.92 min \\ FedRep  & 55.43 & 16.74 & 8.04 & 41.28 & 4.01 & 471 min & 4.09 min \\ FedRD  & 49.17 & 23.23 & 16.71 & 42.74 & 6.31 & 87 min & 1.74 min \\ FedBABU  & 53.97 & 23.08 & 15.42 & 38.17 & 1.35 & 811 min & 1.58 min \\ APFL  & 49.96 & 23.31 & 16.12 & 39.22 & 4.36 & 156 min & 2.74 min \\ FedFomo  & 46.36 & 11.59 & 14.86 & 29.51 & 3.18 & 193 min & 2.72 min \\ APPLE  & 47.89 & 24.24 & 17.79 & — & — & 132 min & 2.93 min \\  FedAvg & 15.70 & 21.14 & 21.71 & — & — & 365 min & 1.59 min \\ FedAvg+DBE & **57.52** & **32.61** & **25.55** & — & — & 171 min & 1.60 min \\   

Table 6: The test accuracy (%, \(\)) and computation overhead (\(\)) of pFL methods.