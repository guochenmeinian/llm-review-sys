# Neural Processes with Stability

Huafeng Liu, Liping Jing, Jian Yu

Beijing Key Lab of Traffic Data Analysis and Mining, Beijing Jiaotong University

The School of Computer and Information Technology, Beijing Jiaotong University

{hfliu1, lpjing, jianyu}@bjtu.edu.cn

###### Abstract

Unlike traditional statistical models depending on hand-specified priors, neural processes (NPs) have recently emerged as a class of powerful neural statistical models that combine the strengths of neural networks and stochastic processes. NPs can define a flexible class of stochastic processes well suited for highly non-trivial functions by encoding contextual knowledge into the function space. However, noisy context points introduce challenges to the algorithmic stability that small changes in training data may significantly change the models and yield lower generalization performance. In this paper, we provide theoretical guidelines for deriving stable solutions with high generalization by introducing the notion of algorithmic stability into NPs, which can be flexible to work with various NPs and achieves less biased approximation with theoretical guarantees. To illustrate the superiority of the proposed model, we perform experiments on both synthetic and real-world data, and the results demonstrate that our approach not only helps to achieve more accurate performance but also improves model robustness.

## 1 Introduction

Neural processes (NPs) [9; 10] constitute a family of variational approximation models for stochastic processes with promising properties in computational efficiency and uncertainty quantification. Different from traditional statistical modeling for which a user typically hand-specifies a prior (e.g., smoothness of functions quantified by a Gaussian distribution in Gaussian process ), NPs implicitly define a broad class of stochastic processes with neural networks in a data-driven manner. When appropriately trained, NPs can define a flexible class of stochastic processes well suited for highly non-trivial functions that are not easily represented by existing stochastic processes.

NPs meta-learn a distribution over predictors and provide a way to select an inductive bias from data to adapt quickly to a new task. Incorporating the data prior into the model as an inductive bias, NPs can reduce the model complexity and improve model generalization. Usually, an NP predictor is described as predicting a set of data (target set) given a set of labeled data (context set). However, the number of noise in data introduces challenges to the algorithmic stability. In NPs, models are biased to the meta-datasets (a dataset of datasets), so small changes in the dataset (noisy or missing) may significantly change the models. As demonstrated in previous work [9; 10; 14; 11], existing NPs cannot provide stable predictions under noisy conditions, which may introduce high training error variance, and minimizing the training error may not guarantee consistent error reduction on the test set, i.e. low generalization performance . In this case, algorithmic stability and generalization performance have strong connections and an unstable NP model has low generalization performance.

A stable model is one for which the learned solution does not change much with small changes in training set . In general, heuristic techniques, such as cross-validation and ensemble learning, can be adopted to improve the generalization performance. Cross-validation needs to sacrifice the limited training data, while ensemble learning is computationally expensive on training sub-models. Recently, there are several improved NPs focused on considering model stability andimproving generalization performance empirically, such as hierarchical prior , stochastic attention mechanism , bootstrap , and Mixture of Expert . However, most of them are unable to investigate the theoretical bound of the generalization performance of NPs. It is desirable to develop robust algorithms with low generalization error and high efficiency.

In this paper, we investigate NP-related models and explore more expressive stability toward general stochastic processes by proposing a stable solution. Specifically, by introducing the notion of stability into NPs, we focus on developing theoretical guidelines for deriving a stable NPs solution. We propose a method to find out subsets that are harder to predict than average, which is a key step for constructing this optimization problem. Based on it, a new extension of NPs with stable guarantees is formulated, which can be flexible to work with various NPs and achieves less biased approximation with theoretical guarantees. Considering the model adaptivity, an adaptive weighting strategy is proposed. To illustrate the superiority of the proposed stable solution, we perform experiments on synthetic 1D regression, system identification of physics engines, and real-world image completion tasks, and the results demonstrate that NPs with our stable solution are much more robust than original NPs.

## 2 Related Work

In this section, we briefly review two different areas which are highly relevant to the proposed method, neural processes, and algorithmic stability.

**Neural Processes** Neural processes are a well-known member of the stochastic process family by directly capturing uncertainties with deep neural networks, which are not only computationally efficient but also retain a probabilistic interpretation of the model [9; 10; 14; 13]. Starting with conditional neural processes (CNP) , there have been several follow-up works to improve NPs in various aspects . Vanilla CNP combines neural networks with the Gaussian process to extract prior knowledge from training data. NP  introduces a global latent variable to model uncertainty in a variational manner. Considering the problem of underfitting in the vanilla NP, Attentive NP  introduces the attention mechanism to improve the model's reconstruction quality.  introduced convolutional conditional neural process (ConvCNP) models translation equivariance in the data. Wang and Van Hoof  presented a doubly stochastic variational process (DSVNP), which combines both global and local latent variables. Lee et al.  extended NP using Bootstrap and proposed the bootstrapping neural processes (BNP). Kawano et al.  presented a group equivariant conditional neural process by incorporating group equivariant into CNPs in a meta-learning manner. Wang and van Hoof  proposed to combine the Mixture of Expert models with NPs to develop more expressive exchangeable stochastic processes. Kim et al.  proposed a stochastic attention mechanism for NPs to capture appropriate context information. Although there are many NP variants to improve the model performance, those do not consider stability to yield high generalization performance.

**Algorithmic Stability** Stability, as known as algorithmic stability, is a computational learning theory of how a machine learning algorithm is perturbed by small changes to its inputs . Many efforts have been made to analyze various notions of algorithmic stability and prove that a broad spectrum of learning algorithms are stable in some sense [2; 3; 29; 12].  proved that \(l_{2}\) regularized learning algorithms are uniformly stable and able to obtain new bounds on generalization performance.  generalized 's results and proved that regularized learning algorithms with strongly convex penalty functions on bounded domains. Hardt et al.  showed that parametric models trained by stochastic gradient descent algorithms are uniformly stable. Li et al.  introduced the stability notation to low-rank matrix approximation. Liu et al.  proved that tasks in multi-task learning can act as regularizers and that multi-task learning in a very general setting will therefore be uniformly stable under mild assumptions. This is the first work to investigate the stability of NPs from theoretical guidelines and derive NPs solutions with high stability.

## 3 Preliminary

Let calligraphic letters (e.g., \(\)) indicate sets, capital letters (e.g., \(A\)) indicate scalars, lower-case bold letters (e.g., \(\)) denote vectors, and capital bold letters (e.g., \(\)) indicate matrices. Suppose there is a dataset \(=(,)=\{(_{i},y_{i})\}_{i=1}^{N}\) with \(N\) data points \(=[_{1},_{2},,_{N}]^{} ^{N D}\), and corresponding labels \(=[y_{1},y_{2},,y_{N}]^{N}\). Considering an arbitrary number of data points \(^{c}=(^{c},^{c})=\{(_{i},y_{i})\}_{i }\), where \(\{1,2,,N\}\) is an index set defining context information, neural processes model the conditional predictive distribution of the target values \(^{}=\{y_{i}\}_{i}\)at some target data points \(^{}=\{_{i}\}_{i}\) based on the context \(^{}\), i.e. \(P(^{}|^{},^{})\). Usually, target set is defined as \(=\{1,2,,N\}\). Only in CNP , \(\{1,2,,N\}\) and \(=\). In this paper, we define \(=\{1,2,,N\}\) for all NPs, i.e. conditional predictive distribution is \(P(|,^{})=_{i=1}^{N}P(y_{i}| _{i},^{})\).

Fundamentally, there are two NP variants: deterministic and probabilistic. Deterministic NP , i.e. CNP, models the conditional distribution as \(P(|,^{})=P(|, ^{})\), where \(^{}^{d}\) is an aggregated feature vector processed by a function that maps \(^{}\) into a finite-dimensional vector space in a permutation-invariant way. In probabilistic NPs , a latent variable \(^{d}\) is introduced to capture model uncertainty and the NPs infer \(P_{}(|^{})\) given context set using the reparameterization trick  and models such a conditional distribution as \(P_{}(y_{i}|_{i},^{})= P_{}(y_ {i}|_{i},^{},)P_{}(|^{})d\) and it is trained by maximizing an ELBO: \(_{ P_{}(|,)}[  P_{}(|)]-KL[P_{}(|, )|\|P_{}(|^{})]\).

**Meta Training NP Prediction** To achieve fast prediction on a new context set at test time, NPs meta-learn a distribution over predictors. To perform meta-learning, we require a meta-dataset (dataset of datasets). We consider an unknown distribution \(\) on an instance space \(\), and a set of independent sample \(=\{(_{i},y_{i})\}_{i=1}^{N}\) drawn from \(\): \((_{i},y_{i})\) and \(^{N}\). Suppose meta-dataset contains \(M\) datasets \(_{1:M}=\{_{m}\}_{m=1}^{M}\) with \(_{m}=\{_{m}^{},_{m}^{}\}\), we assume that all \(M\) datasets drawn from a common environment \(\), which is a probability measure on the set of probability measures on \(\). The draw of \(\) indicates the encounter of a specific learning task \(\) in the environment \(\). For simplicity, we assume that each dataset has the same sample size \(N\). Following the previous work related to multi-task learning  and meta learning , The environment \(\) induces a measure \(_{N,}\) on \(()^{N}\) such that \(_{N,}(A)=_{}[^{N}(A)], A( )^{N}\). Thus a dataset \(_{m}\) is independently sampled from a task \(\) encountered in \(\), which is denoted as \(_{m}_{N,}\) for \(m[M]\).

Suppose there exists a meta parameter \(\) indicating the shared knowledge among different tasks. In this case, a meta learning algorithm \(_{meta}\) for NPs takes meta-datasets \(_{1:M}\) as input, and then outputs a meta parameter \(=_{meta}(_{1:M}) P_{|_{1:M}}\). When given a new test dataset \(\), we can evaluate the quality of the meta parameter \(\) by the following true risk:

\[R_{}()=_{_{N,}}_{U P_{ |_{1:M}}}[R_{}()]\] (1)

where \(R_{}()=-_{(_{i},y_{i})} P_{}(y_ {i}|_{i},^{})\). Usually, \(\) and \(\) are unknown, we can only estimate the meta parameter \(\) from the observed data \(_{1:M}\). In this case, the empirical risk w.r.t \(\) is:

\[R_{_{1:M}}()=}{{M}}_{m=1}^{M} _{ P_{|_{m}^{}}}R_{_ {m}}()\] (2)

where \(R_{_{m}}()=-(1/N)_{i=1}^{N} P_{}(y_{i}|_{i},^{})\).

NPs have various strengths: 1) _Efficiency_: meta-learning allows NPs to incorporate information from a new context set and make predictions with a single forward pass. The complexity is linear or quadratic in the context size instead of cubic as with Gaussian process regression; 2) _Flexibility_: NPs can define a conditional distribution of an arbitrary number of target points, conditioning an arbitrary number of observations; 3) _Permutation invariance_: the encoders of NPs use set property  to make the target prediction permutation invariant. Thanks to these properties, NPs are widely-used in lots of tasks, e.g., Bayesian optimization , recommendation [20; 21], physics engines controlling  etc. While there are many NP variants to improve the performance of NPs [9; 10; 14; 13; 15; 28], those do not take model's stability into consider account yet, which is the key to the robustness of the model.

## 4 Problem Formulation

**Stability of NP** A stable learning algorithm has the property that replacing one element in the training set does not result in a significant change to the algorithm's output . Therefore, if we take the training error as a random variable, the training error of a stable learning algorithm should have a small variance. This implies that stable algorithms have the property that the training errors are close to the testing error . Based on the defined risks, the algorithmic stability of approximate \(\{y_{i}\}_{i}\) in NPs is defined as follows.

**Definition 4.1**.: (Algorithmic Stability of Neural Processes) For any measure \(_{N,}\) on \(()^{N}\) such that \(_{N,}(A)=_{}[^{N}(A)], A( )^{N}\), sample \(M\) datasets \(_{1:M}\) from \(_{N,}\) randomly. For a given \(>0\), we say that \(R_{_{1:M}}()\) is \(\)-stable if the following holds:

\[P(|R_{}()-R_{_{1:M}}()|) 1-.\] (3)The above stability for NPs has the property that the generalization error is bounded, which indicates that minimizing the training error will have a high probability of minimizing the testing error. This new stability notion makes it possible to measure the generalization performance between different NP approximations. For instance, for any two meta-datasets \(^{1}_{1:M}\) and \(^{2}_{1:M}\) from \(_{N,}\), train NPs on \(^{1}_{1:M}\) and \(^{2}_{1:M}\) are \(_{1}\)-stable and \(_{2}\)-stable, respectively. Then \(R_{^{1}_{1:M}}()\) is more stable than \(R_{^{1}_{1:M}}()\) if \(_{1}<_{2}\). This implies that \(R_{^{1}_{1:M}}()\) is close to \(R_{}()\) with higher probability than \(R_{^{2}_{1:M}}()\), i.e. minimizing \(R_{^{1}_{1:M}}()\) will lead to solutions that are of high probabilities with better generalization performance than minimizing \(R_{^{2}_{1:M}}()\).

Based on the above analysis, we can see that the reliability of data points is crucial to the success of NPs and frail NPs are susceptible to noise.

**Stability vs. Generalization Error** The sparsity of the data, incomplete and noisy introduces challenges to the algorithm stability. NP models are biased to the quality of context data and target data, so small changes in the training data (noisy) may significantly change the models. In this case, unstable solutions will introduce high training error variance, and minimizing the training error may not guarantee consistent error reduction on the testing dataset, i.e., low generalization performance. In other words, the algorithm stability has a direct impact on generalization performance, and an unstable NP solution has low generalization performance. We take NPs with 1D regression task as an example  to investigate the relationship between generalization performance and stability of NPs. The total number of training and testing datasets is \(200\) and \(100\). We trained the NPs model with curves generated from the Gaussian process with RBF kernels by replacing the normal data dataset with a noisy dataset, i.e. the number of replaced datasets is turned in \(\{1,10,20,50,80,100\}\). We quantify stability changes of NPs with the generalization error when the number of replaced datasets increases from \(1\) to \(100\). We compute the difference between training error and test error to measure generalization error. We define the difference between test error and training error as \(R_{}()-R_{_{1:M}}()\), and compute \(P(|R_{}()-R_{_{1:M}}()|)\) with 100 different runs to measure stability. Here we choose \(\) in Definition 4.1 as 0.0015 to cover all error differences when the number of replaced datasets is \(1\). As shown in Figure 1, the generalization error increases when the number of replaced points increases since the testing error becomes lower. On the contrary, the stability of NP decreases with the number of replaced points increases. This indicates that stability decreases with generalization error increases. This study demonstrates that existing NPs suffer from lower generalization performance due to low algorithmic stability. Therefore, it is important to develop a stable solution for NPs that offers good generalization performance.

## 5 Method

In this section, inspired by the previous work , we present a stable solution for NPs with stability and high generalization. Algorithmic stability provides an intuitive way to measure the changes in the outputs of a learning algorithm when the input is changed. Various ways have been introduced to measure algorithmic stability. Following the definition of uniform stability , given a stable NP, the approximation results remain stable if the change of the datasets. For instance, we can remove a subset of easily predictable data points from \(_{1:M}\) to obtain \(^{}_{1:M}\). It is desirable that the solution of minimizing both \(_{1:M}\) and \(^{}_{1:M}\) together will be more stable than the solution of minimizing \(_{1:M}\) only. The following Theorem formally proves the statement.

**Theorem 5.1**.: _Let \(_{1:M}\) (\(M 2\)) be a sampled meta-dataset of measure \(_{N,}\). Let \(_{s}_{1:M}\) be a subset of the meta-dataset, which satisfy that \((_{i},y_{i})_{s},- P_{}(y_{i}| _{i},^{C}) R_{_{1:M}}()\). Let \(^{}_{1:M}=_{1:M}-_{s}\), then for any \(>0\) and \(1>w_{0}>0\), \(1>w_{1}>0\) (\(w_{0}+w_{1}=1\)), \(w_{0}R_{_{1:M}}()+w_{1}R_{^{}_{1:M}}()\) and \(R_{_{1:M}}()\) are \(_{1}\)-stable and \(_{2}\)-stable, respectively, then \(_{1}_{2}\)._

Proof.: Let's assume that \(R_{}()-R_{_{1:M}}()[-a_{1},a_{1}]\) and \(R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{^{ }_{1:M}}())[-a_{2},a_{2}]\) are two random variables with zero mean, where \(a_{1}=\{R_{}()-R_{_{1:M}}()\}\) and

Figure 1: Stability vs. generalization error with different numbers of replaced noisy datasets.

\(\{R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{^{ }_{1:M}}())\}\). Based on Markov's inequality1, for any \(t>0\), we have

\[P(R_{}()-R_{_{1:M}}())[e^{t(R_{}()-R_{_{1:M}}()) ]}}{e^{t}}.\] (4)

Based on Hoeffding's lemma2, we have \([e^{t(R_{}()-R_{_{1:M}}())}] e^{ t^{2}a_{1}^{2}}\), i.e. \(P(R_{}()-R_{_{1:M}}())t^{2}a_{1}^{2}}}{e^{t}}\). Similarly, we have \(P(R_{}()-R_{_{1:M}}()-)t^{2}a_{1}^{2}}}{e^{t}}\). Combining those two inequalities, we have \(P(|R_{}()-R_{_{1:M}}()|)t^{2}a_{1}^{2}}}{e^{t}}\), i.e.

\[P(|R_{}()-R_{_{1:M}}()|) 1-t^{2}a_{1}^{2}}}{e^{t}}.\] (5)

Similarly, we have

\[P(|R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{^{}_{1:M}}())|) 1-t^{2}a_{ 2}^{2}}}{e^{t}}.\] (6)

In this case, the relationship between \(a_{1}\) and \(a_{2}\) is

\[a_{2} =R_{}()-R_{_{1:M}}()+w_{1} (R_{_{1:M}}()-R_{^{}_{1:M}}() )}\] (7) \[=a_{1}+_{1}R_{_{1:M}}()-R_{ ^{}_{1:M}}()}\]

Since \((_{i},y_{i})_{s}\), \(- P_{}(y_{i}|_{i},^{}_{})  R_{_{1:M}}()\), we have \(-(1/N)_{i=1}^{N} P_{}(y_{i}|_{i},^{ }_{}) R_{_{1:M}}()\). Then, since \(_{1:M}=_{s}^{}_{1:M}\). This means that \(\{R_{_{1:M}}()-R_{^{}_{1:M}}()\} 0\). Thus, we have \(a_{2} a_{1}\). This turns out that \(t^{2}a_{2}^{2}}}{e^{t}} t^{2}a_{1}^{2}}}{e^{t}}\), i.e. \(_{1}_{2}\). 

Theorem 5.1 indicates that, if we remove a subset that is easier to predict than average from \(_{1:M}\) to form \(^{}_{1:M}\), then \(w_{0}R_{_{1:M}}()+w_{1}R_{^{}_{1:M}}()\) has higher probability of being close to \(R_{}()\) than \(R_{_{1:M}}()\). Therefore, minimizing \(w_{0}R_{_{1:M}}()+w_{1}R_{^{}_{1:M}}()\) will lead to solutions that have better generalization performance than minimizing \(R_{_{1:M}}()\).

However, Theorem 5.1 only proves that it is beneficial to remove an easily predictable dataset from \(_{1:M}\) to obtain \(^{}_{1:M}\), but does not show how many datasets we should remove from \(_{1:M}\). Actually, removing more datasets that satisfy \(- P_{}(y_{i}|_{i},^{}) R_{ _{1:M}}()\) can obtain better \(^{}_{1:M}\), as shown in following Theorem 5.2.

**Theorem 5.2**.: _Let \(_{1:M}\) (\(M 2\)) be a sampled meta-dataset of measure \(_{N,}\). Let \(_{s1}\) and \(_{s2}\) be two subsets of \(_{1:M}\), which satisfy \(_{s2}_{s1}_{1:M}\). \(_{s2}\) and \(_{s1}\) satisfy that \((_{i},y_{i})_{s1},\)\(- P_{}(y_{i}|_{i},^{}) R_{ _{1:M}}()\). Let \(^{}_{1:M}=_{1:M}-_{s1}\) and \(^{}_{1:M}=_{1:M}-_{s2}\), then for any \(>0\) and \(1>w_{0}>0\), \(1>w_{1}>0\) (\(w_{0}+w_{1}=1\)), \(w_{0}R_{_{1:M}}()+w_{1}R_{^{}_{1:M}}()\) and \(w_{0}R_{_{1:M}}()+w_{1}R_{^{}_{1:M}}()\) are \(_{1}\)-stable and \(_{2}\)-stable, respectively, then \(_{1}_{2}\)._

Proof.: Let's assume that \(R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{^{ }_{1:M}}())[-a_{1},a_{1}]\) and \(R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{^{ }_{1:M}}())[-a_{2},a_{2}]\) are two random variables with \(0\) mean, where \(a_{1}=\{R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{ ^{}_{1:M}}())\}\) and \(a_{2}=\{R_{}()-(w_{0}R_{_{1:M}}()+w_{1}R_{ ^{}_{1:M}}())\}\).

Then, based on Markov's inequality and Hoeffding's lemma, we have

\[& P(|R_{}()-w_{0}R_{ _{1:M}}()+w_{1}R_{^{}_{1:M}}() |) 1-t^{2}a_{1}^{2}}}{e^{t}},\\ & P(|R_{}()-w_{0}R_{_{1:M}}( )+w_{1}R_{^{}_{1:M}}()| ) 1-t^{2}a_{2}^{2}}}{e^{t}}.\] (8)

Since \((_{i},y_{i})_Theorem 5.2 indicates that removing more data points that are easy to predict will obtain more stable NPs. Therefore, it is desirable to choose \(^{}_{1:M}\) (i.e. \(_{1:M}-_{s}\)) as the whole set which is harder to predict than average, i.e. the whole set satisfying \((_{i},y_{i})^{}_{1:M}\), \(- P_{}(y_{i}|_{i},^{c}) R_{_{1:M }}()\). Without loss of generality, we can extend Theorem 5.2 by considering several harder predicted sets to obtain a more stable solution by minimizing them all together. In this case, we need to prove that the stability of a model with \(K\) subsets is better than the model with \(K-1\) subsets, as shown in Theorem 5.3.

**Theorem 5.3**.: _Let \(_{1:M}\) (\(M 2\)) be a sampled meta-dataset of measure \(_{N,}\). Let \(_{s1},_{s2},,_{sK}_{ 1:M}\) be \(K\) subsets and satisfy \((_{i},y_{i})_{sk}(k[K])\), \(- P_{}(y_{i}|_{i},^{c}) R_{_{1: M}}()\). Let \(^{k}_{1:M}=_{1:M}-_{sk}\) for all \(k[K]\), then for any \(>0\) and \(1>w_{k}>0\) for all \(k[K]\), \((w_{0}+w_{1}++w_{K}=1)\), \(w_{0}R_{_{1:M}}()+_{k=1}^{K}w_{k}R_{^{k}_{1:M} }()\) and \((w_{0}+w_{K})R_{_{1:M}}()+_{k=1}^{K-1}w_{k}R_{^ {k}_{1:M}}()\) are \(_{1}\)-stable and \(_{2}\)-stable, respectively, then \(_{1}_{2}\)._

Proof.: For simplicity, we denote \(w_{0}R_{_{1:M}}()+_{k=1}^{K}w_{k}R_{^{k}_{1:M} }()\) as \(R_{1}\) and \((w_{0}+w_{K})R_{_{1:M}}()+_{k=1}^{K-1}w_{k}R_{^ {k}_{1:M}}()\) as \(R_{2}\). Let's assume that \(R_{}()-R_{1}[-a_{1},a_{1}]\) and \(R_{}()-R_{2}[-a_{2},a_{2}]\) are two random variables with \(0\) mean, where \(a_{1}=\{R_{}()-R_{1}\}\) and \(a_{2}=\{R_{}()-R_{2}\}\). Then, based on Markov's inequality and Hoeffding's lemma, we have

\[P(|R_{}()-R_{1}|) 1-a_{2}^{2}}}{e ^{t}},(|R_{}()-R_{2}|) 1-a_{2}^{2}}}{e^{t}}.\] (9)

Similar to the proof of Theorem 5.3, we have \(R_{^{k}_{1:M}}() R_{_{1:M}}()\), which indicates that \(\{R_{_{1:M}}()-R_{^{k}_{1:M}}()\} 0\). Since \(a_{2}=a_{1}+w_{K}\{R_{_{1:M}}()-R_{^{K}_{1:M}} ()\}\), we know that \(a_{2} a_{1}\). Thus we can conclude that \(a_{2}a^{2}}}{e^{t}}a_{2 }^{2}}}{e^{t}}\), i.e. \(_{1}_{2}\). 

Based on Theorem 5.3, we know that optimization on \(_{1:M}\) and more than one hard predictable subsets of \(_{1:M}\) can achieve more stable prediction. However, how to select data points that are difficult to predict from \(_{1:M}\) is still a challenging problem, especially, since we need to select \(K\) subsets.

### The Proposed Solution

According to the analysis of stability in NPs, we propose a stable solution for NPs to achieve model stability with the aid of hard predictable subsets selection. Specifically, we introduce a solution to obtain those hard predictable subsets based on _only one_ set of easily predicted data points which can be broken into four steps:

1. Selecting a existing NP model (e.g., CNP , NP) and training it with meta-dataset \(_{1:M}\);
2. Selecting an easily predicted subset \(_{s}_{1:M}\), which satisfies that \((_{i},y_{i})_{s}\), \(- P_{}(y_{i}|_{i},^{c}) R_{_{1:M} }()\);
3. Dividing \(_{s}\) into \(K\) non-overlapping subsets \(_{s1},_{s2},,_{sK}\) and satisfying \(_{k=1}^{K}_{sk}=_{s}\);
4. Defining \(K\) subsets that are difficult to predict, i.e. \(^{k}_{1:M}=_{1:M}-_{sk}\) for all \(k[K]\);

Thus, a new extension of NPs is given as

\[=_{}w_{0}R_{_{1:M}}()+_{k=1}^{K}w _{k}R_{^{k}_{1:M}}(),\] (10)

where \(w_{0},w_{1},,w_{K}\) indicate the contributions of each component and satisfy \(_{k=0}^{K}w_{k}=1\).

The whole learning algorithm is given in Algorithm 1. From steps 1 to 12, we obtain \(K\) different hard predictable subsets, and the complexity of lines 1 to 12 is \(O(MN)\). The complexity of line 11 is related to the applied NP models (such as CNP, NP, ANP, etc). Thus, the computational complexity of NPs with our stable solution is similar to the original NPs. As shown in Algorithm 1, we need to pre-train the base model to select samples. In fact, the pre-trained model can not only be used for sample selection but its model parameters can be used as the initialization of the stable version model. At this time, the training of the stable version can converge faster.

**Stability Guarantee** Here we give a theoretical guarantee of the proposed stable solution.

**Theorem 5.4**.: _Let \(_{1:M}\) (\(M 2\)) be a sampled meta-dataset of measure \(_{N,}\). Let \(_{s}_{1:M}\) which satisfies that \((_{i},y_{i})_{s}\), \(- P_{}(y_{i}|_{i},^{c}) R_{_{1:M} }()\). By dividing \(_{s}\) into \(K\) subsets\(_{s1},_{s2},,_{sK}\) which satisfy that \(_{k=1}^{K}_{sk}=_{1:M}\). Let \(_{1:M}^{0}=_{1:M}-_{s}\) and \(_{1:M}^{k}=_{1:M}-_{sk}\) for all \(k[K]\), then for any \(>0\) and \(1>w_{k}>0\) for all \(k[K]\), (\(w_{0}+w_{1}++w_{K}=1\)), \(w_{0}R_{_{1:M}}()+_{k=1}^{K}w_{k}R_{_{1:M}^{k} }()\) and \(w_{0}R_{_{1:M}}()+(1-w_{0})R_{_{1:M}^{0}}()\) are \(_{1}\)-stable and \(_{2}\)-stable, respectively, then \(_{1}_{2}\)._

Proof.: For simplicity, we denote \(w_{0}R_{_{1:M}}()+_{k=1}^{K}w_{k}R_{_{1:M}^{k} }()\) as \(R_{1}\) and \(w_{0}R_{_{1:M}}()+(1-w_{0})R_{_{1:M}^{0}}()\) as \(R_{2}\). Let's assume that \(R_{}()-R_{1}[-a_{1},a_{1}]\) and \(R_{}()-R_{2}[-a_{2},a_{2}]\) are two random variables with \(0\) mean, where \(a_{1}=\{R_{}()-R_{1}\}\) and \(a_{2}=\{R_{}()-R_{2}\}\). Then, based on Markov's inequality and Hoeffding's lemma, we have

\[P(|R_{}()-R_{1}|) 1-t^{2}a_{1} ^{2}}}{e^{ t}}, P(|R_{}()-R_{2}|) 1- t^{2}a_{2}^{2}}}{e^{ t}}.\] (11)

\( k[K]\), \(_{sk}_{s}\) and \((_{i},y_{i})_{s}\), \(- P_{}(y_{i}|_{i},^{}) R_{ _{1:M}}()\), we have \(R_{_{1:M}^{k}}() R_{_{1:M}^{0}}()\). By combining the above inequalities over all \(k[K]\), we have

\[_{k=1}^{K}w_{k}R_{_{1:M}^{k}}()_{k=1}^{K}w_{k}R_{ _{1:M}^{0}}()=(1-w_{0})R_{_{1:M}^{0}}().\] (12)

Thus, \(\{R_{}()-R_{1}\}\{R_{1:M}()-R_{2}\}\), i.e. \(a_{1} a_{2}\). Thus we have \(_{1}_{2}\). 

According to the above theorem, we can achieve model stability by selecting only one easily predicted subset.

## 6 Experiments

We started with learning predictive functions on synthetic datasets, and then high-dimensional tasks, e.g., system identification on physics engines, image completion, and Bayesian optimization, were performed to evaluate the properties of the NP-related models.

### 1D Regression

To verify the proposed stable solution, we combined the stable solution with different baseline NP classes (CNP , NP , ANP ,ConvCNP , ConvNP , and their bootstrapping versions ) and compared them on 1D regression task. Among them, BCNP, BNP, BANP, BConvCNP, and NConvNP are recently proposed stable strategies for NPs with Bootstrap. Specifically, the stochastic process (SP) initializing with a \(0\) mean Gaussian Process (GP) \(y^{(0)} GP(0,k(,))\) indexed in the interval \(x[-2.0,2.0]\) were used to generate data, where the radial basis function kernel and Matern Kernel were adopted for model-data mismatch scenario. More detailed information can be obtained in the Appendix. We investigated the model performance in terms of different noise settings. We introduced Gaussian noise \((0,1)\) and added noise to different proportions of the data, such as \(\{0\%,5\%,10\%,15\%\}\). Table 1 lists the average log-likelihoods comparison in terms of different noise proportions. The best result is marked in bold. First, we can see that if we adopt the robust solution in baselines, the model achieves the best results on all the datasets, showing the effectiveness of the 

[MISSING_PAGE_FAIL:8]

[MISSING_PAGE_FAIL:9]

### Predator-prey Models

Following  and , we consider the Lotka-Volterra model , which is used to describe the evolution of predator-prey populations. We first trained the models using simulated data generated from a Lotka-Volterra model and tested them on real-world data (Hudson's Bay hare-Iynx data), which is quite different from the simulated data and can be considered as a mismatch scenario. Table 5 lists the results on both simulated and real data. Similar to the previous observation, our stable version still outperforms the original version. Among stable versions, SConvNP achieves the best performance.

### Ablation Study

The key parameter in our stable solution is the number of hard predictable subsets \(K\). Taking SANP as an example, we investigated the average log-likelihood in terms of different \(K\) on the 1D regression task, as shown in Figure 3. We can see that SANP performs better as \(K\) increases, reaches the best value at around \(K=4\), and then becomes stable in performance as \(K\) grows larger. As proved in Theorem 5.3, optimization on \(_{1:M}\) and more than one hard predictable subset of \(_{1:M}\) can achieve more stable prediction. We also conducted different experiments to explore the impact of different \(w_{k}\). Taking the 1D regression task with RBF-GP data as an example, we set \(K=3\) and different \(w_{k}\) for experiments, as shown in Table 6. It can be seen from the table below that when different weights are set, the model using a stable strategy is better than the original model, and when the weight is set to be equal, its performance is optimal. In addition, when the value of \(w_{k}(k 1)\) is significantly different from \(w_{0}\), such as \((0.625,0.125,0.125,0.125)\) and \((0.0625,0.3125,0.3125,0.3125)\), its performance is more significantly reduced compared to \((0.25,0.25,0.25,0.25)\), but it still has a significant improvement compared to the original non-stable model.

## 7 Conclusion and Future Work

In this paper, we provided theoretical guidelines for deriving stable solutions for NPs, which can obtain good generalization performance. Experiments demonstrated the proposed stable solution can help NPs to achieve more accurate and stable predictions. Although the theoretical analysis we give is based on regression models, it is still open to question whether this conclusion is appropriate for classification models. Therefore, we are interested in extending our theory, expecting it to apply to more different types of tasks.

  Weights & \((0.25,0.25,0.25,0.25)\) & \((0.40,0.22,0.2)\) & \((0.625,0.125,0.125,0.125)\) & \((0.1,0.3,0.3,0.3)\) & \((0.0625,0.3125,0.3125)\) \\  SCNP & \((0.9255,0.4125)\) & \((0.9127,0.4019)\) & \((0.9035,0.3998)\) & \((0.9149,0.4086)\) & \((0.8927,0.3991)\) \\ SNP & \((0.8955,0.3925)\) & \((0.8877,0.3817)\) & \((0.8716,0.3809)\) & \((0.8831,0.3859)\) & \((0.8657,0.3775)\) \\ SANP & \((1.2831,0.5215)\) & \((1.2776,0.5187)\) & \((1.2738,0.5196)\) & \((1.2791,0.5203)\) & \((1.2712,0.5193)\) \\ SConvNP & \((1.3991,0.5996)\) & \((1.3916,0.5933)\) & \((1.3841,0.5915)\) & \((1.3934,0.5946)\) & \((1.3854,0.5919)\) \\ SConvNP & \((1.4036,0.6015)\) & \((1.3991,0.6004)\) & \((1.3931,0.5992)\) & \((1.4012,0.6015)\) & \((1.3957,0.5995)\) \\  

Table 6: Log-likelihood comparisons with different \(w_{k}\) on 1D regression task.

  Model & SANP & RANP & CANP & SANP & SConvNP & SConvNP & BConvNP & SConvNP \\  Simulated-context & \(2.8013_{0.01}\) & \(2.9912_{0.000}\) & \(2.6217_{0.000}\) & \(2.9129_{0.000}\) & \(2.2608_{0.000}\) & \(2.2616_{0.000}\) & \(2.2952_{0.000}\) & \(2.6125_{0.000}\) & \(2.6231_{0.000}\) \\ Simulated-target & \(1.8265_{0.000}\) & \(1.8055_{0.000}\) & \(1.8848_{0.000}\) & \(1.8323_{0.000}\) & \(1.8513_{0.000}\) & \(1.9516_{0.000}\) & \(1.9232_{0.000}\) & \(1.9442_{0.000}\) & \(1.9624_{0.000}\) \\ Real-context & \(1.7234_{0.000}\) & \(1.8406_{0.000}\) & \(_{0.000}\) & \(_{0.000}\) & \(1.8052_{0.000}\) & \(_{0.000}\) & \(1.3842_{0.000}\) & \(1.8426_{0.000}\) & \(_{0.000}\) \\ Real-target & \(.7304_{0.000}\) & \(.5406_{0.000}\) & \(_{0.000}\) & \(_{0.000}\) & -5.1525_{0.000}\) & \(_{0.000}\) & \(_{0.000}\) & \(-5.2615_{0.000}\) & \(-5.2418_{0.000}\) \\  

Table 5: Predator-prey model

Figure 3: Log-likelihood (SANP) comparisons with different \(K\) on 1D regression task.