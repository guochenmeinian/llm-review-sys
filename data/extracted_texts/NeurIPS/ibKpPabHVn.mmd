# DeepDRK: Deep Dependency Regularized Knockoff for Feature Selection

Hongyu Shen\({}^{1}\) Yici Yan\({}^{2}\) Zhizhen Zhao\({}^{1}\)

Department of Electrical and Computer Engineering\({}^{1}\),

University of Illinois at Urbana Champaign.

Department of Statistics\({}^{2}\),

University of Illinois at Urbana Champaign.

{hongyu2, yiciyan2, zhizhenz}@illinois.edu

###### Abstract

Model-X knockoff has garnered significant attention among various feature selection methods due to its guarantees for controlling the false discovery rate (FDR). Since its introduction in parametric design, knockoff techniques have evolved to handle arbitrary data distributions using deep learning-based generative models. However, we have observed limitations in the current implementations of the deep Model-X knockoff framework. Notably, the "swap property" that knockoffs require often faces challenges at the sample level, resulting in diminished selection power. To address these issues, we develop "Deep Dependency Regularized Knockoff (DeepDRK)," a distribution-free deep learning method that effectively balances FDR and power. In DeepDRK, we introduce a novel formulation of the knockoff model as a learning problem under multi-source adversarial attacks. By employing an innovative perturbation technique, we achieve lower FDR and higher power. Our model outperforms existing benchmarks across synthetic, semi-synthetic, and real-world datasets, particularly when sample sizes are small and data distributions are non-Gaussian.

## 1 Introduction

Feature selection (FS) has garnered significant attention over the past few decades due to the rapidly increasing dimensionality of data, as well as the associated computational, storage, and noise challenges . Successfully identifying the true informative features among inputs can significantly enhance the performance of analysis frameworks and drive advancements in fields such as biology, neuroscience, medicine, economics, and social sciences . However, the task of accurately pinpointing informative features is often considered nearly impossible, particularly due to the limited availability of data relative to the increasing dimensionality . A practical approach to address this challenge is the development of algorithms designed to select features while maintaining controlled error rates. Targeting this goal, Model-X knockoffs, a novel framework, is proposed in  to select relevant features while controlling the false discovery rate (FDR). In contrast to the classical setup, where assumptions on the correlations between input features and the response are imposed , the Model-X knockoff framework only requires a linear relationship between the response and the features. With a strong finite-sample FDR guarantee, Model-X knockoff saw broad applications in domains such as biology, neuroscience, and medicine, where the sample size is limited .

There have been considerable developments of knockoffs since its debut. In scenarios where feature distributions are complex, various deep learning methods  have been proposed. However, we observe major limitations despite improved performance. First, the performance of existing methods varies across different data distributions. Second, the quality of selection declineswhen the sample size is relatively small. Third, training the deep knockoff generation models can be challenging due to competing loss terms in the training objective. We elaborate on the drawbacks in Sections 2.2 and 3.2.

In this paper, we address these issues by proposing the Deep Dependency Regularized Knockoff (DeepDRK), a deep learning-based pipeline. We formulate the knockoff generation as an adversarial attack problem involving multiple sources. By optimizing a model against the adversarial environments, we achieve better "swap property"  compared to the baseline models. DeepDRK is also equipped with a novel perturbation technique to reduce "reconstructability" , which in turn controls FDR and boosts selection power. The experiments conducted on synthetic, semi-synthetic, and real datasets demonstrate that our pipeline outperforms existing methods across various scenarios.

## 2 Background and Related Works

### Model-X Knockoffs for FDR control

The Model-X knockoffs framework consists of two main components. Given the explanatory variables \(X=(X_{1},X_{2},,X_{p})^{}^{p}\) and the response variable \(Y\) (\(Y\) continuous for regression and categorical for classification), the framework requires: 1. a knockoff \(=(_{1},_{2},,_{p})^{}\) that "fakes" \(X\); 2. the knockoff statistics \(w_{j}\) for \(j[p]\) that assess the importance of each feature \(X_{j}\). The knockoff \(\) is required to be independent of \(Y\) conditioning on \(X\), and must satisfy the swap property:

\[(X,)_{(B)}(X,), B [p].\] (1)

Here swap\((B)\) exchanges the positions of any variable \(X_{j}\), \(j B\), with its knockoff \(_{j}\). The knockoff statistic \(w_{j}((X,),Y)\) (for \(j[p]\)) depends on the concatenated variable \((X,)\) and \(Y\) and must satisfy the flip-sign property:

\[w_{j}((X,)_{(B)},Y)=\{w _{j}((X,),Y)j B\\ -w_{j}((X,),Y)j B.\] (2)

The functions \(w_{j}()\) with \(j[p]\) have many candidates, for example \(w_{j}=|_{j}|-|_{j}|\), where \(_{j}\) and \(_{j}\) are the corresponding regression coefficients of \(X_{j}\) and \(_{j}\) with the regression function \(Y=_{j=1}^{p}(X_{j}_{j}+_{j}_{j})+\), where \(\) is independently drawn from the normal distribution.

When the two knockoff conditions (i.e., Eq. (1) and (2)) are met, one can select features by \(=\{w_{j}_{q}\}\), where

\[_{q}=_{t>0}t:-t\}|}{(1,|\{j:w_{j}  t\}|)} q}.\] (3)

To assess the feature selection quality, FDR is commonly used as an average Type I error of selected features , which is defined as follows. Let \([p]\) be an arbitrary set of selected indices, and let \(\)* denote the underlying true regression coefficients. The FDR for the selection \(\) is

\[=[^{*}=0j\}}{\#\{j:j\}\, 1}]\] (4)

The control of FDR is guaranteed by the following theorem from :

**Theorem 2.1**.: _Given the knockoff that satisfies the swap property in Eq. (1), the knockoff statistic that satisfies Eq. (2), and \(=\{w_{j}_{q}\}\), we have \( q\)._

### Related Works

Model-X knockoff is first studied under Gaussian design. Namely, the original variable \(X(,)\) with \(\) and \(\) known. Since Gaussian design does not naturally generalize to complex data distributions, several methods are proposed to weaken the assumption. Among them, model-specific onessuch as AEknockoff , Hidden Markov Model (HMM) knockoff , and MASS  all propose parametric alternatives to Gaussian design. These methods can better learn the data distribution, while keeping the sampling process relatively simple. Nevertheless, they pose assumptions to the design distribution, which can be problematic if actual data does not coincide. To gain further flexibility, various deep-learning-based models are developed to generate knockoffs from distributions beyond parametric setup. DDLK  and sRMMD  utilize different metrics to measure the distances between the original and the knockoff covariates. They apply different regularization terms to impose the "swap property". He et al.  introduced a KnockoffScreen procedure to generate multiple knockoffs to improve the stability by minimizing the variance during knockoff construction. KnockoffGAN  and Deep Knockoff  take advantage of the deep learning structures to create likelihood-free generative models for the knockoff generation.

Despite the flexibility to learn the data distribution, deep-learning-based models suffer from a major drawback. Knockoff generations based on distribution-free sampling methods such as generative adversarial networks (GAN) [21; 3] tend to overfit, namely to learn the data \(X\) exactly. The reason is that the notion of swap property for continuous distributions is not well defined at the sample level. To satisfy the swap property, one needs to independently sample \(_{j}\) from the conditional law \(P_{X_{j}}(|X_{-j})\), where \(X_{-j}\) denotes the vector \((X_{1},,X_{j-1},X_{j+1},,X_{p})\). At the sample level, each realization of \(X_{-j}=x_{-j}^{i}\) is almost surely different and only associates to one corresponding sample \(X_{j}=x_{j}^{i}\), causing the conditional law to degenerate to sum of Diracs. As a result, minimizing the distance between \((X,)\) and \((X,)_{(B)}\) will push \(\) towards \(X\) and introduce high collinearity that makes the feature selection powerless, i.e., with high type II error. To tackle this issue, DDLK  suggests an entropic regularization. Yet it still lacks power and is computationally expensive.

### Boost Power by reducing reconstructability

The issue of lacking power in the knockoff selection is solved in the Gaussian case . Assuming the knowledge of both mean and covariance of \(X(,)\), the swap property is easily satisfied by setting \(_{j}(_{j},_{jj})\) and \(_{ij}=(X_{i},_{j})\), for \(i j\), \(i,j[p]\). Barber & Candes  originally propose to minimize \((X_{j},_{j})\) for all \(j[p]\) using semi-definite programming (SDP), to prevent \(_{j}\) to be highly correlated with \(X_{j}\). However, Spector & Janson  observed that the SDP knockoff still lacks feature selection power, as merely decorrelating \(X_{j}\) and \(_{j}\) is not enough, and \((X,)\) can still be (almost) linearly dependent in various cases. This is referred to as high reconstructability 1 in their paper, which can be considered as a population counterpart of collinearity (see Appendix A for more details). To tackle the problem,  proposed to maximize the expected conditional variance \((X_{j} X_{-j},)\), which admits close-form solution whenever \(X\) is Gaussian.

## 3 Method

DeepDRK in Figure 1 provides a novel way to generate knockoff \(\) while reducing the reconstructability (see Section 2.3) between the generated knockoff \(\) and the input \(X\) for data with

Figure 1: The illustration of the DeepDRK pipeline, which consists of two components: 1. the training stage that optimizes the knockoff Transformer and swappers by \(_{}\) and \(_{}\); 2. the post-training stage that generates the knockoff \(^{_{}}\) via dependency regularized perturbation.

complex distributions. The generated knockoff can then be used to perform FDR-controlled feature selection following the Model-X knockoff framework (see Section 2.1). Overall, DeepDRK contains two main components. It first trains a transformer-based deep learning model, referred to as Knockoff Transformer (KT), to obtain the swap property and reduce the reconstructability of the generated knockoff. This is achieved by incorporating adversarial attacks with multi-swappers. Secondly, a dependency regularized perturbation technique (DRP) is developed to further reduce the reconstructability for \(\) post training. We will elaborate on these two components in the following two subsections. In this section, we slightly abuse the notation such that \(X\) and \(\) also denote the corresponding data matrices.

### Training with Knockoff Transformer and Swappers

The KT aims to generate knockoffs, denoted by \(_{}\), which are parameterized by a transformer network with parameters \(\). The loss for training the KT contains a swap loss (SL) \(_{}\), which enforces the swap property, and a dependency regularization loss (DRL) \(_{}\), which controls the reconstructibility of the knockoff. \(K\) different neural network parameterized swappers, denoted by \(\{S_{_{i}}\}_{i=1}^{K}\), are used to test whether the generated knockoffs satisfy the swap property. Thus, the KT is trained adversarially according to the following objective,

\[_{}_{_{1},,_{K}}_{ }(X,_{},\{S_{_{i}}\}_{i=1}^{K})+_{} (X,_{})}.\] (5)

Note that we use \(_{}\) and \(\) interchangeably; however, the former emphasizes that the knockoff depends on the model weights \(\). We discuss each loss function below. Details on the network architectures for KT and swappers are deferred to Appendix B.1. The training algorithm is in Appendix B.2.

#### 3.1.1 Swap Loss

The swap loss is designed to enforce the swap property and is defined as follows:

\[_{}(X,_{},\{S_{_{i}}\}_ {i=1}^{K})=_{i=1}^{K}((X,_{}),(X, {X}_{})_{S_{_{i}}})\] \[+_{1}(X,_{},\{S_{_{i} }\}_{i=1}^{K})+_{2}_{}(\{S_{_{i}} \}_{i=1}^{K}),\] (6)

where \(_{1}\) and \(_{2}\) are hyperparameters.

The first term in Eq. (6) uses the sliced Wasserstein distance (SWD, see Appendix C for definition) to measure the distance between a pair of joint distributions for \((X,_{})\) and \((X,_{})_{S_{_{i}}}\), where the swapper is parameterized by \(_{i}\). We sum over \(K\) SWDs computed for the distributions modified under different swappers to capture the effects of multiple swap attacks. We utilize SWD to compare distributions because it excels in handling complex data distributions and is computationally efficient .

Sudarshan et al.  introduced a single swap attack parameterized by a neural network. However, we observe that minimizing the worst case swap for all \(B[p]\), as suggested by , cannot guarantee the swap property of \(_{}\). To address this limitation, we introduce a "multi-swapper" setup that uses multiple swappers to enforce the swap property. And this leads to the introduction of the second and the third terms in the objective in Eq. (6).

The second term in Eq. (6), \((X,_{},\{S_{_{i}}\}_{i=1}^{K})\) evaluates the variance of the sliced Wasserstein distances \(((X,_{}),(X,_{})_{S_{_{i}}})\) with \(K\) realizations of \(\). When \((X,_{},\{S_{_{i}}\}_{i=1}^{K})=0\), the sliced Wasserstein distances are identical across all swappers. Therefore, complementary to the first term, minimizing this term improves the adherence of swap property for the generated \(_{}\).

The third term in Eq. (6) is introduced to avoid mode collapse on the parameters \(_{i}\) of different swappers and ensure each swapper characterizes a different adversarial environment:

\[_{}(\{S_{_{i}}\}_{i=1}^{K})=|}_{(i,j) C}(S_{_{i}},S_{_{j}}),\] (7)where \(C=\{(i,j)|i,j[K],i j\}\), and \((,)\) is the cosine similarity between the weights \(\) of a pair of different swappers. Without this regularization, all swappers could collapse to a single mode such that the multi-swapper scheme reduces to a single-swapper setup.

Overall, the swap loss \(_{}\) enforces the swap property via the novel multi-swapper design. Such design provides a more robust assurance of the swap property through multiple adversarial swap attacks, which is shown in the ablation studies in Appendices I.2 and I.3.

#### 3.1.2 Dependency Regularization Loss

As discussed in Section 2.2, pursuing the swap property at the sample level often leads to severe overfitting of \(_{}\), i.e., pushing \(_{}\) towards \(X\), which results in high collinearity in feature selection. To address this, the DRL is introduced to reduce the reconstructability between \(X\) and \(\):

\[_{}(X,_{})=_{3}(X, _{}),\] (8)

where \(_{3}\) is a hyperparameter. The SWC term in Eq. (8) refers to the sliced Wasserstein correlation , which quantitatively measures the dependency between two random vectors in the same space. More specifically, let \(Z_{1}\) and \(Z_{2}\) be two \(p\)-dimensional random vectors. \((Z_{1},Z_{2})=0\) indicates that \(Z_{1}\) and \(Z_{2}\) are independent, while \((Z_{1},Z_{2})=1\) suggests a linear relationship between each other (see Appendix D for more details on SWC). In DeepDRK, we minimize SWC to reduce the reconstructability, a procedure similar to . The intuition is as follows. If the joint distribution of \(X\) is known, then for each \(j[p]\), the knockoff \(_{j}\) should be sampled from \(P_{j}(|X_{-j})\), making \(X_{j}\) and \(_{j}\) less dependent. In such case the swap property is ensured, and collinearity/reconstructability is reduced due to independence. As we do not have access to the joint law, we want the variables to be less dependent. Since collinearity exists with in \(X\), merely decorrelate \(X_{j}\) and \(_{j}\) is not enough. Thus, we minimize SWC to reduce the dependence between \(X\) and \(\). We refer readers to Appendix A for more discussions.

### Dependency Regularization Perturbation

Empirically we observe a competition between \(_{}\) and \(_{}\)in Eq. (5), which adds difficulty to the training procedure. Specifically, the \(_{}\) is dominating and the \(_{}\) increases quickly after a short decreasing period. We are the first to observe this phenomenon in all deep-learning based knockoff generation models when one tries to gain power [47; 55; 38; 27]. We include the experimental evidence in Appendix E. We suggest the following explanation: minimizing the swap loss, which corresponds to FDR control, is the same as controlling Type I error. Similarly, minimizing the dependency loss is to control Type II error. With a fixed number of observations, it is well known that Type I error and Type II error can not decrease at the same time after reaching a certain threshold. In the framework of model-X knockoff, we aim to boost as much power as possible given the FDR is controlled at a certain level, a similar idea as the uniformly most powerful (UMP) test . For this reason, we propose DRP as a post-training technique to further boost power.

DRP is a sample-level perturbation that further eliminates dependency between \(X\) and and the knockoff. More specifically, DRP perturbs the generated \(_{}\) with the row-permuted version of \(X\), denoted as \(X_{}\). After applying DRP, the final knockoff \(_{,n}^{}\) becomes:

\[_{,n}^{}=(1-_{n})_{}+ _{n} X_{},\] (9)

where \(_{n}\) is a preset perturbation weight, \(n\) is the sample size, and \(_{n} 0\) when \(n\). In the following, we remove \(n\) or \(\) whenever the context is clear. \(^{}\) has a smaller SWC with \(X\), since \(X_{}\) is independent of \(X\). Despite the perturbation increases the swap loss, such impact is negligible when the sample size is large. More specifically, we present the following Lemma 3.1 and Proposition 3.2. Let \(_{n}\) and \(_{n}^{B}\) denote the empirical joint distribution of the sample \(X\) and \(\) before and after the swap: \((X,)_{n}\), \((X,)_{(B)}_{n}^{B}\). And \(P\) and \(P^{B}\) denote their corresponding population distributions.

**Lemma 3.1**.: _Under mild conditions, the slice Wasserstein distance between the empirical distributions of \((X,)\) and \((X,)_{(B)}\) and their corresponding population distributions is of scale \((n^{-1/2})\), i.e., \((_{n},_{n}^{B})=(P,P^{B})+(n^{-1/2})\)._

**Proposition 3.2**.: _Let \(_{n}(n^{-1/2})\) in Eq. (9), and denote \((X,^{})_{n,}\), \((X,^{})_{(B)}_{n,}^{B}\). Then \((_{n,},_{n,}^{B})=(P,P^{ B})\) when \(n\)._

The proofs can be found in Appendix F. Lemma 3.1 suggests a general case where the swap loss enforced at the sample level differs from that of the population level from a term of scale \(n^{-1/2}\), which vanishes when \(n\). Proposition 3.2 provides the rationale on the proposal of the perturbation technique in Eq. (9), such that the DRP term is negligible asymptotically. Besides the theoretical justification, we also empirically show in Appendix G that the perturbation is beneficial.

## 4 Experiment

We assess the performance of DeepDRK against several benchmark models under three experimental setups: 1. a fully synthetic setup where both the input variables and the response variable follow predefined distributions; 2. a semi-synthetic setup, in which the input variables are derived from real-world datasets and the response variable is generated based on known relationships with the inputs; and 3. feature selection (FS) using a real-world dataset. The experiments are designed to encompass a range of datasets with varying \(p/n\) ratios and distributions of \(X\), aiming to provide a comprehensive evaluation of model performance. The benchmark models are Deep Knockoff 2, DDLK 3, KnockoffGAN 4 and sRMMD 5, with links of the code implementation listed in the footnote. The implementation details for the training, feature selection, and data preparation are available in Appendix H. In the following, we describe the datasets and the associated experimental results. We also consider the ablation study to illustrate the benefits obtained by having the following proposed terms: REx, \(_{}\), the multi-swapper setup, and the dependency regularization perturbation. Empirically, these terms help to improve power and control the FDR. Due to space limitation, we defer details for the ablation studies to Appendix I.2 and I.3. DeepDRK is implemented in PyTorch and is accessible at: https://github.com/nowonder2000/DeepDRK.

### The Synthetic Experiments

To properly evaluate the performance, we follow a well-designed experimental setup by  to generate different datasets specified by \((X,Y)\). Here \(X^{p}\) is the collection dependent variables that follows pre-defined distributions. \(Y\) is the response variable that is modeled as \(Y(X^{T},1)\). The underlying true \(\) is a \(p\)-dimensional vector, where each entry is drawn independently from the distribution \(}(0.5)\).

Figure 3: Power and FDR for different knockoff models on the mixture of Gaussian data on different \(_{}\) setups. The red horizontal line indicates the 0.1 FDR threshold. This figure is complementary to Figure 2 for including two additional Gaussian mixture data with higher \(_{}\) values.

Figure 2: Power and FDR for different knockoff models on the synthetic datasets with \(}(0.5)\). The red horizontal line indicates the 0.1 FDR threshold.

Compared to the previous works , which consider \(}\) as the scaling factor for the Rademacher distribution, we reduce the magnitude of \(\) by a factor of 15. This is because we find that in the original setup, the \(\) scale is too large such that the feature selection enjoys high powers and low FDRs for all models. To compare the performance of the knockoff generation methods on various data, we consider the following distributions for \(X\):

Gaussian mixture: We consider a Gaussian mixture model \(X_{k=1}^{3}_{k}(_{k},_{k})\), where \(\) is the proportion of the \(k\)-th Gaussian with \((_{1},_{2},_{3})=(0.4,0.2,0.4)\). \(_{k}^{p}\) denotes the mean of the \(k\)-th Gaussian with \(_{k}=_{p} 20(k-1)\), where \(_{p}\) is the \(p\)-dimensional vector that has universal value 1 for all entries. \(_{k}^{p p}\) is the covariance matrices whose \((i,j)\)-th entry taking the value \(_{k}^{|i-j|}\), where \(_{k}=_{}^{k-0.1}\) and \(_{}=0.6\). Besides this experiment, we further perform two additional tests. The first one focuses on a mixture of Gaussians data of various \(_{}\) to study the feature selection performance with highly correlated features. Namely, we consider additional \(_{}\{0.7,0.8\}\). The second one explores the effect of \((_{1},_{2},_{3})\) to the feature selection performance. In this case, we uniformly draw 10 sets of \((_{1},_{2},_{3})\), and evaluate the FS performance of all the models considered in this paper. The values of the mixture weights are presented in Table 4 in Appendix H.3.1.

Copulas: We further use copula to model complex correlations within \(X\). To the best of our knowledge, this is a first attempt to consider complex distributions other than the Gaussian mixture model in the knockoff framework. Specifically, we consider two copula families: Clayton, Joe with the consistent copula parameter of 2 in both cases. For each family, we consider two candidates for the marginal distributions: a uniform distribution (using the identity conversion function) and an exponential distribution with a rate of 1. We implement the copulas according to PyCop.

We consider the following \((n,p)\) setups: \((200,100)\) and \((2000,100)\). This is in contrast to existing works, which consider only the \((2000,100)\) as the smallest sample size setup . Our goal is to demonstrate the consistent performance of DeepDRK across various \(p/n\) ratios, particularly when the sample size is small.

Results: Figure 2 compare FDRs and powers for all models across the datasets with two different setups for \(\). Figure 2 shows that DeepDRK consistently controls the false discovery rate (FDR) compared to other benchmark models across various data distributions and \(p/n\) ratios, with the exception of a few cases where the FDR exceeds the \(0.1\) threshold in the small sample size (\(n=200\)) scenarios. Other models, though being able to reach higher power, comes at a cost of sacrificing FDR, which contradicts to the UMP philosophy (see Section 3.2). We also evaluate the performance on a mixture of Gaussians with increasing \(_{}\), indicating a higher correlation among the input variables. Note that the mixture of Gaussians example in Figure 2 has \(_{}=0.6\). The results for \(_{}\{0.7,0.8\}\) are presented in Figure 3. Compared to other baseline models, DeepDRK maintains the lowest FDRs while achieving competitive powers across all \(_{}\) values, highlighting its robustness to correlations in \(X\). Overall, the results demonstrate the ability of DeepDRK in consistently performing FS with controlled FDR compared to other models across a range of different datasets, \(p/n\) ratios, and feature correlations in \(X\). In addition, we present common statistics for the FDR and power on the mixture of Gaussians experiment with 10 different sets of \((_{1},_{2},_{3})\) in Table 1. It is clear that DeepDRK improves the robustness in maintaining FDR across various configurations of the Gaussian mixture models compared to existing approaches.

   \(n\) & Method &  &  \\   & mean & std & median & 5\% quantile & 95\% quantile & mean & std & median & 5\% quantile & 95\% quantile \\   & DDLK & 0.772 & 0.025 & 0.781 & 0.726 & 0.791 & 0.971 & 0.033 & 0.983 & 0.911 & 0.995 \\  & Deep Knockoff & 0.735 & 0.028 & 0.740 & 0.692 & 0.769 & 0.999 & 0.001 & 0.999 & 0.997 & 1.000 \\  & KnockoffGAN & 0.390 & 0.110 & 0.396 & 0.230 & 0.550 & 0.971 & 0.038 & 0.986 & 0.904 & 0.997 \\  & skMMD & 0.720 & 0.047 & 0.741 & 0.640 & 0.752 & 0.998 & 0.002 & 0.998 & 0.994 & 1.000 \\  & **DeepDRK** & 0.116 & 0.040 & 0.100 & 0.086 & 0.187 & 0.791 & 0.039 & 0.804 & 0.720 & 0.824 \\   & DDLK & 0.725 & 0.050 & 0.734 & 0.667 & 0.778 & 1.000 & 0.000 & 1.000 & 1.000 & 1.000 \\  & Deep Knockoff & 0.626 & 0.092 & 0.672 & 0.460 & 0.694 & 1.000 & 0.001 & 1.000 & 0.997 & 1.000 \\   & KnockoffGAN & 0.118 & 0.014 & 0.114 & 0.102 & 0.139 & 0.973 & 0.012 & 0.978 & 0.953 & 0.986 \\   & **sRMD** & 0.658 & 0.060 & 0.644 & 0.583 & 0.736 & 1.000 & 0.001 & 1.000 & 0.998 & 1.000 \\   & **DeepDRK** & 0.081 & 0.018 & 0.076 & 0.059 & 0.110 & 0.973 & 0.011 & 0.978 & 0.956 & 0.983 \\   

Table 1: Comparison of different methods on FDR and power across different \((_{1},_{2},_{3})\) for the components in the Gaussian mixture setup.

To understand why DeepDRK outperforms other baseline models, we consider measuring the distribution of the knockoff statistics, i.e., \(w_{j}\), for both nonnull and null features of \(X\). Fan et al.  and Candes et al.  pointed out that a good knockoff requires the corresponding knockoff statistics to concentrate symmetrically around zero for the null features and to maintain high positive values for the nonnulls. However, theoretical analysis on the goodness of FDR or power requires access to the true knockoff \(\) to compare the distribution of \(w_{j}\)'s with the ground truth, which is infeasible for non-Gaussian data. Nevertheless, we can still examine the distribution of the knockoff statistics as a surrogate to analyze model performance in terms of false discovery rate (FDR) or power, given the necessary properties of the knockoff statistics mentioned earlier.

Figure 4 shows the means and standard deviations of the empirical distributions of the knockoff statistics \(w_{j}\) for both null and nonnull variables across different datasets and models. Clearly, compared to other benchmarks, DeepDRK maintains high values of \(w_{j}\) for the nonnulls and relatively symmetric values around zero for the nulls. All other models experience positive shifts to the null statistics to some extent. Positive shifts in the null statistics lead to a degeneracy in performance because the threshold selection rule for false discovery rate (FDR) is based on the negative values of \(w_{j}\)'s (see Eq. (3)). This has two negative impacts, one on the FS threshold and the other on its subsequent FS process. First, according to Eq. (3), the shift causes the chosen threshold to approach zero, as there are fewer null statistics remaining on the negative side, and those that do remain have smaller amplitudes. Subsequently, a lowered threshold leads to an increase in false positives, a phenomenon that becomes more pronounced with positive shifts in the null statistics. As shown in Figure 4, the \(w_{j}\) values calculated using DeepDRK are centered around zero for the nulls, while exhibiting large positive values for the nonnulls. This aligns with the results in Figure 2, which demonstrate that DeepDRK effectively achieves good FDR control and high power. Due to space limit, we defer the results for \(n=2000\) and the comparison of \(w_{j}\) statistics for the Gaussian correlation setup to Appendix I.3.

To further verify the performance consistency of the proposed method, we include a comparison on different \(\) scales. Specifically, we consider 4 different sets of \(\) scales, i.e., \(}\), \(}\), \(}\) and \(}\), for the previously considered data distributions. The results are summarized in Figure 5. It is observed that in all cases considered with various \(\) scale, the proposed DeepDRK successfully

Figure 4: The knockoff statistics (\(w_{j}\)) for different knockoff models on the synthetic datasets with \(}\). Each bar in the plot represents the mean of the null/nonnull knockoff statistics averaging on 600 experiments. The error bar indicates the standard deviation. The sample size is 200.

Figure 5: Scatter plots of Power against FDR for different datasets and models. The red vertical line indicates the 0.1 FDR threshold. Different scales for \(\) (e.g., \(}\), \(}\), \(}\) and \(}\)) are indicated by different marker styles. Different models are indicated by different colors.

maintains relatively low FDRs with a higher power, compared to baseline methods. This phenomenon is especially pronounced with a low sample size (\(n=200\)).

In addition to the above results, we provide the measurement of the swap property in Appendix I.1. The evaluation of model runtime is also included in Appendix I.4.

### The Semi-synthetic Experiments

We consider a semi-synthetic study with design \(X\) drawn from two real-world datasets and use \(X\) to simulate response \(Y\). The first dataset contains single-cell RNA sequencing (scRNA-seq) data from \(10\) Genomics 7. Each entry in \(X^{n p}\) represents the observed gene expression of \(p\) genes in \(n\) cells. We refer readers to  and  for more background. Following the same preprocessing in , we obtain the final dataset \(X\) with \(n=10000\) and \(p=100\)8. The preprocessing of \(X\) and the synthesis of \(Y\) (denoted as "Linear" and "Tanh" cases) are deferred to Appendix H.3.2.

The second publicly available dataset9 is from a real case study entitled "Longitudinal Metabolomics of the Human Microbiome in Inflammatory Bowel Disease (IBD)" . The study seeks to identify important metabolites of two representative diseases of the inflammatory bowel disease (IBD): ulcerative colitis (UC) and Crohn's disease (CD). Specifically, we use the C18 Reverse-Phase Negative Mode dataset that has 546 samples and 91 metabolites. To mitigate the effects of missing values, we preprocess the dataset following a common procedure to remove metabolites that have over 20% missing values, resulting in 80 metabolites. We normalize the data matrix entry-wise to have zero mean and unit variance after a log transform and an imputation via the \(k\)-nearest neighbor algorithm following the same procedure in . Finally, we synthesize the response \(Y\) with the real dataset of \(X\) via \(Y(X^{T},1)\), where the entries of \(\) drawn independently from one of the following three distributions: Unif(0, 1), \((0,1)\), and Rademacher\((0.5)\), in three separate experiments.

Results: Figure 6 and 7 compare the feature selection performance on the RNA data and the IBD data respectively. In Figure 6, we observe that all but DDLK are bounded by the nominal 0.1 FDR threshold in the "Tanh" case. However, KnockoffGAN and sRMMD have almost zero power. The power for Deep Knockoff is also very low compared to that of DeepDRK. Although DDLK provides high power, the associated FDR is not controlled by the threshold. In the "Linear" case, almost all models have well controlled FDR, among which DeepDRK provides the highest power. Similar observations can be found in Figure 7. For the IBD data generated under the aforementioned synthesis rules, it is clear that all models except DDLK achieve well-controlled FDR. Apart from DDLK, DeepDRK consistently demonstrates the highest power. These results further underscore the potential of DeepDRK for real-world data applications.

### A Case Study

Besides (semi-)synthetic setups, we carry out a case study with real data for both design \(X\) and response \(Y\), in order to qualitatively evaluate the selection performance of DeepDRK. In this subsection, we use the IBD dataset  with the empirical response. The response variable \(Y\) is categorical: \(Y\) equals 1 if a given sample is associated with UC/CD and 0 otherwise. The covariates \(X\) is identical to the second semi-synthetic setup considered in Section 4.2. To properly evaluate results with no ground truth available, we search for the evidence of the IBD-associated metabolites using the existing literature. Specifically, we use three sources: 1. metabolites that are explicitly

Figure 6: Power and FDR for different knockoff models on the semi-synthetic RNA dataset. The red horizontal line indicates the 0.1 FDR threshold.

documented to have associations with IBD, UC, or CD in the PubChem database 10; 2. metabolites that are reported in the existing peer-reviewed publications; 3. metabolites that are reported in pre-prints. We identify 47 metabolites that are reported to have association with IBD. All referenced metabolites are included in Table 5 in Appendix H.3.3.

Our DeepDRK model training and knockoff generation are the same as before (see Table 3 in Appendix H.1). Likewise, to generate knockoff for the benchmark models, we follow their default setups. During the FS step, however, we use 0.2 as the FDR threshold instead of 0.1, and apply a different algorithm--DeepPINK  that is included in the knockpy 11 library--to generate \(w_{j}\). The values are subsequently used to identify metabolites. We choose DeepPINK over the previously considered ridge regression due to the nonlinear relationships between metabolites \(X\) and responses \(Y\) in this case study.

We compare the FS results with the 47 literature-supported metabolites and report the number of selections in Table 2. A detailed list of selected features for each model can be found in Table 9 in Appendix I.5. From Table 2, it is clear that, compared to the benchmark models, DeepDRK identifies the largest number of referenced metabolites while effectively limiting the number of metabolites not reported in existing literature (see Table 5 in Appendix H.3.3). The sRMMD model achieves the lowest false discovery rate, but this comes at the cost of missing a significant number of documented metabolites. Since there is no ground truth available, the results here should be viewed and analyzed qualitatively.

## 5 Conclusion

In this paper, we introduce DeepDRK, a deep learning-based knockoff generation pipeline consisting of two steps. First, it trains a Knockoff Transformer with multiple swappers to achieve the swap property while reducing reconstructability. In the post-training stage, a dependency-regularized perturbation is applied to further enhance power with controlled FDR. DeepDRK effectively balances FDR and power, which compete with each other at the sample level. To the best of our knowledge, this relationship has not been previously reported in the literature. Empirically, DeepDRK demonstrates the ability to maintain both controlled false discovery rates (FDR) and high power across various data distributions and different \(p/n\) ratios. Additionally, we provide insights into the distribution of knockoff statistics, which elucidate the reasons behind DeepDRK's consistently strong performance. The numerical results indicate that DeepDRK outperforms existing deep learning-based benchmark models. Experiments with real and semi-synthetic data further highlight the potential of DeepDRK for feature selection tasks involving non-Gaussian data.

   Model & DeepDRK & Deep Knockoff & sRMMD & KnockoffGAN & DDLK \\   & 19/23 & 15/20 & 5/5 & 12/14 & 17/25 \\   

Table 2: The number of literature-supported metabolites among the identified metabolites vs. the number of identified metabolites.

Figure 7: Power and FDR for different knockoff models on the semi-synthetic IBD dataset. The red horizontal line indicates the 0.1 FDR threshold.