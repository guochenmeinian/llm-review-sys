# This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian Optimization

Anthony Bardou

IC, EPFL

Lausanne, Switzerland

anthony.bardou@epfl.ch

&Patrick Thiran

IC, EPFL

Lausanne, Switzerland

patrick.thiran@epfl.ch

&Giovanni Ranieri

IC, EPFL

Lausanne, Switzerland

giovanni.ranieri@epfl.ch

###### Abstract

Bayesian Optimization (BO) has proven to be very successful at optimizing a static, noisy, costly-to-evaluate black-box function \(f:\). However, optimizing a black-box which is also a function of time (_i.e._, a _dynamic_ function) \(f:\) remains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has to keep track of the optimum over time. This changes the nature of the optimization problem in at least three aspects: (i) querying an arbitrary point in \(\) is impossible, (ii) past observations become less and less relevant for keeping track of the optimum as time goes by and (iii) the DBO algorithm must have a high sampling frequency so it can collect enough relevant observations to keep track of the optimum through time. In this paper, we design a Wasserstein distance-based criterion able to quantify the relevancy of an observation with respect to future predictions. Then, we leverage this criterion to build W-DBO, a DBO algorithm able to remove irrelevant observations from its dataset on the fly, thus maintaining simultaneously a good predictive performance and a high sampling frequency, even in continuous-time optimization tasks with unknown horizon. Numerical experiments establish the superiority of W-DBO, which outperforms state-of-the-art methods by a comfortable margin.

## 1 Introduction

Many real-world problems require the optimization of a costly-to-evaluate objective function \(f:^{d}\) with an unknown closed form (_i.e._, either the closed form expression of \(f\) exists but remains unknown to the user, or it does not exist). Such a setting occurs frequently, and examples can be found in hyperparameters tuning , networking [2; 3], robotics  or computational biology . In such applications, \(f\) can be seen as a black-box and cannot be optimized by usual first-order approaches. Bayesian Optimization (BO) is an effective framework for black-box optimization. Its core idea is to leverage a surrogate model, usually a Gaussian Process (GP), to query \(f\) at specific inputs. By doing so, a BO algorithm is able to simultaneously discover and optimize the objective function.

Since its inception, BO has proven to be very effective at optimizing black-boxes in a variety of contexts, such as high-dimensional input spaces [6; 7; 8], batch mode  or multi-objective optimization . However, few works study BO in dynamic contexts (_i.e._, with a time-varying objective function), despite its critical importance. Indeed, dynamic black-box optimization problems arise whenever an optimization task is conducted within an environment that comprises exogenous factors that may vary with time and significantly impact the objective function. Dynamic black-boxes are found in network management , unmanned aerial vehicles tasks , hyperparameter tuning in online deep learning , online clustering  or crossing waypoints location in air routes .

In a dynamic context, \(f:\) is a time-varying, black-box, costly-to-evaluate objective function with spatial domain \(^{d}\) and temporal domain \(\). Unlike common black-box

[MISSING_PAGE_FAIL:2]

Exploiting the usual acquisition functions in a dynamic context is also straightforward. Since a DBO algorithm can only query an input at the current running time \(t_{0}\), the next queried input is simply \((_{n+1},t_{0})\), with \(_{n+1}=*{arg\,max}_{}(,t_{0})\). Some DBO algorithms (e.g., ) extend the querying horizon to the near future, that is, from \(t_{0}\) to a time interval \([t_{0},t_{0}+_{t}]\). In that case, the next queried input is \((_{n+1},t_{n+1})=*{arg\,max}_{(,t) [t_{0},t_{0}+_{t}]}(,t)\).

BO is an active field of research, but relatively few works address DBO, despite the natural extension of BO to dynamic problems described above. We conclude this section by reviewing them. In , the objective function is allowed to evolve in time according to a simple Markov model, controlled by a hyperparameter \(\). On the one hand, the authors propose R-GP-UCB, which handles data staleness by resisting the dataset every \(N()\) iterations. On the other hand, the authors also propose TV-GP-UCB that incorporates data staleness by weighing the covariance of two queries \(_{i}=(_{i},t_{i})\) and \(_{j}=(_{j},t_{j})\) by \((1-)^{|i-j|/2}\). In , the authors use the same model with an event-triggered reset of the dataset. Although less relevant to this work, let us mention  and  for the sake of completeness. Under frequentist assumptions, they also propose DBO algorithms that forget irrelevant observations by either resetting their datasets or by using decreasing covariance weights. However, they assume that the variational budget of the objective function is fixed, which has the drawback of requiring the objective function to become asymptotically static. This is a very different setting than the one of interest in this paper, which does not make this requirement.

The aforementioned algorithms all work with discrete, evenly-spaced time steps. This setting simplifies the regret analysis of DBO algorithms through the use of proof techniques similar to the ones used for static BO. However, it also overlooks a critical effect of the response times of their algorithms. In fact, the response time of a BO algorithm heavily depends on its dataset size \(n\), since BO inference is in \((n^{3})\). Although it is reasonable to ignore this for classical BO because the objective function \(f\) is static, DBO algorithms cannot make this simplification as it directly impacts their ability to track the optimal argument of the objective function through time. Many algorithms (e.g., see [21; 23; 24]) recommend to keep all the collected observations in their datasets, whereas in practice, their response times would asymptotically become prohibitive. Other algorithms (e.g., see [21; 22; 23]) propose to reset their datasets, either periodically or once an event is triggered. This probably deletes some relevant observations in the process. More importantly, these algorithms necessarily estimate their covariance function hyperparameters beforehand and keep them fixed during the optimization. This lack of adaptivity of the estimation might lead to severely under-optimal characterization of the function by the hyperparameters, especially when optimizing an ever-changing objective function on an infinite time horizon.

To the best of our knowledge, only one work acknowledges these problems. It proposes ABO , an algorithm that uses a decomposable spatio-temporal covariance function \(k((,t),(^{},t^{}))=k_{S}(||-^{}||_{2} )k_{T}(|t-t^{}|)\) to accurately model complex spatio-temporal correlations and samples the objective function only when deemed necessary. Although this reduces the size of ABO's dataset, ABO does not propose a way to remove stale observations, it only adds new observations less frequently. Therefore, using ABO will still become prohibitive in the long run.

The most relevant methods to quantify the relevancy of an observation can be found in the sparse GPs literature (e.g., see [25; 26]). However, they require non-trivial adjustments to account for the particular nature of the time dimension. As far as we know, there is no method in the DBO literature able to quantify the relevancy of an observation in an online setting. As mentioned before, such a method is much needed as it would allow a DBO algorithm to remove stale data on the fly while preserving the predictive performance of the algorithm. We bridge this gap by providing a sound criterion to measure the relevancy of an observation and an algorithm exploiting this criterion to remove stale data from its dataset.

## 3 A Wasserstein Distance-Based Criterion

### Core Assumptions

To address the DBO problem under suitable smoothness conditions, let us make the usual assumption of BO, using a Gaussian Process (GP) as a surrogate model for \(f\) (see ).

**Assumption 3.1**.: \(f\) _is a \((0,k((,t)\,,(^{},t^{})))\), whose mean is \(0\) (without loss of generality) and whose covariance function is denoted by \(k: _{+}\)._In order to accurately model complex spatio-temporal dynamics, we make the same assumption on the decomposition and isotropy in time and space of the covariance function \(k\) as in .

**Assumption 3.2**.: \[k((,t),(^{},t^{}))= k_{S}(||-^{ }||_{2},l_{S})k_{T}(|t-t^{}|,l_{T}),\] (5)

with \(>0\), \(k_{S}:_{+}\) and \(k_{T}:_{+}\) two positive correlation functions, parameterized by lengthscales \(l_{S}>0\) and \(l_{T}>0\), respectively. The factor \(>0\) scales the product of the two correlation functions and hence, controls the magnitude of the covariance function \(k\). The lengthscales \(l_{S}\) and \(l_{T}\) control the correlation lengths of the GP (see  for more details) in space and in time, respectively.

Although the covariance function \(k\) is able to model temporal correlations with \(k_{T}\), it does not accurately measure the relevancy of an observation. The next section addresses this question.

### Measuring the Relevancy of an Observation

By definition, when an irrelevant observation gets removed from the dataset, the GP posterior experiences hardly any change. Therefore, we propose to measure the relevancy of an observation \(_{i}=((_{i},t_{i}),y_{i})\) by measuring the impact that the removal of \(_{i}\) has on the GP posterior.

Let \(}\) be the GP conditioned on the dataset \(=\{((_{i},t_{i}),y_{i})\}_{i 1,n}\), with \((_{i},t_{i})\) and \(y_{i}=f(_{i},t_{i})+,(0,^{2})\). Without loss of generality, let us measure the impact of removing \(((_{1},t_{1}),y_{1})\) from the dataset on the GP posterior. Clearly, the measure should be defined on the domain of future predictions at time \(t_{0}\), denoted by \(_{t_{0}}\), which must include the whole space \(\) and only the future time interval \([t_{0},+)\):

\[_{t_{0}}=[t_{0},+).\] (6)

We compare a GP conditioned on the whole dataset, denoted by \(}\), with a GP conditioned on \(}\), the dataset without \((_{1},t_{1},y_{1})\), denoted by \(}}\). For an arbitrary point \((,t)_{t_{0}}\), \(}\) provides a posterior distribution \(}(,t)=(_{}(,t), _{}^{2}(,t))\), and so does \(}}\) with \(}}(,t)=(_{}} (,t),_{}}^{2}(,t))\). We compare these two distributions by using the 2-Wasserstein distance , given by

\[W_{2}(}(,t),}}(,t)) =((_{}(,t)-_{}}(,t) )^{2}+(_{}(,t)-_{}} (,t))^{2})^{}.\] (7)

A natural extension of the 2-Wasserstein distance from a point \((,t)_{t_{0}}\) to the domain \(_{t_{0}}\) is

\[W_{2}(},}})=(_{ }_{t_{0}}^{}W_{2}^{2}(}(,t), }}(,t))ddt)^{}.\] (8)

Observe that (8) is a criterion that effectively captures the impact of removing the observation \(_{1}=((_{1},t_{1}),y_{1})\) from the dataset on the GP posterior. However, as discussed in Appendix F, the covariance function hyperparameters \(=(,l_{S},l_{T})\) control the magnitude of (8). This is illustrated by Figure 1, which depicts two couples of GP posteriors that achieve the same value (8). Depending on the lengthscale magnitude, the posteriors may be quite different or, conversely, very similar. As a result, (8) cannot be directly used as a gauge of observation relevancy.

To remove this ambiguity, we normalize (8) by \(W_{2}(},})\) (_i.e._, the 2-Wasserstein distance between the GP conditioned on \(\) and the prior GP), and we obtain the ratio

\[R(},}})=(}, }})}{W_{2}(},})}.\] (9)

Intuitively, \(W_{2}(},})\) measures the impact of resetting the whole dataset \(\) on the GP posterior and serves as a baseline that puts into perspective the distance measured by (8). Technically, taking the ratio (9) successfully cancels out the influence of the covariance function hyperparameters on the magnitude of the Wasserstein distances, as further discussed in Appendix F. As a direct consequence,Figure 2: Normalized Wasserstein distances. Similarly to Figure 1, a few couples of GP posterior means \((_{},_{}})\) are depicted. The top (resp., bottom) row depicts couples of posteriors that yield a small (resp., large) ratio (9). The left (resp., right) column depicts couples of posteriors controlled by a small (resp., large) lengthscale. The prior GP mean \(_{}}=0\) is shown as a black dashed line, and the Wasserstein distance between the posterior and the prior as a gray shaded area.

Figure 1: Similar values of Wasserstein distance, different effect on posteriors. For visualization purposes, only the posterior means of two posterior GPs (blue for \(_{}\) and orange for \(_{}}\)) are depicted, along a single dimension (e.g., time). The Wasserstein distance between the two posteriors is shown by the green shaded area. The GPs have a small lengthscale (left) or, conversely, a large lengthscale (right) for the chosen dimension.

(9) is an unambiguous indication of how relevant an observation is. This is illustrated by Figure 2, which depicts couples of GP posteriors under different contexts. When (9) is small (resp., large), the posteriors are similar (resp., dissimilar) regardless of the magnitude of the lengthscale.

Exploiting this criterion is straightforward. When (9) is small, one can infer that the observation \(_{1}\) can be safely removed from the dataset since it will have virtually no impact on the posterior. Conversely, when (9) is large, one can infer that removing \(_{1}\) would alter the posterior too much, and conclude that it is a relevant observation that must remain in the dataset. The exploitation of (9) is discussed in more details in Section 4.2.

The criterion (9) is useful for a DBO algorithm if and only if it can be computed on the fly, in an online setting. In the next section, we show that (9) can be approximated efficiently, and we describe a DBO algorithm able to exploit the criterion.

## 4 Using the Criterion in Practice

### Computational Tractability

In , the authors provide an algorithm to approximate the 2-Wasserstein distance between two GPs up to an arbitrary precision level. However, the computational cost of this algorithm is too expensive in an online setting, where it is crucial to keep the per-iteration cost as small as possible to ensure a high sampling frequency. In this section, we put this issue to rest by deriving an explicit approximation of (9). These formulas are computationally cheap enough to be exploited on the fly.

In Appendix A, we show that (7) can be computed efficiently. Next, in Appendix B, we apply these results to obtain an upper bound of (8). The key observation for deriving this result is to approximate the integrals in (8) by a convolution of the covariance functions with themselves in space and time. The same trick can be used for approximating \(W_{2}(_{},_{})\).

**Theorem 4.1**.: _Let \(t_{0}\) be the present time and \(=\{((_{i},t_{i}),y_{i})\}_{i[\![1,n]\!]}\) be a dataset of observations made before \(t_{0}\). Let \(}=\{((_{i},t_{i}),y_{i})\}_{i[\![2,n]\!]}\) be the dataset without the first observation and \(_{t_{0}}=[t_{0},+)\) be the domain of future predictions. Then, an upper bound for \(W_{2}^{2}(_{},_{}})\) on \(_{t_{0}}\) is_

\[_{2}^{2}(_{}, _{}})=^{2}(a^{2}+)C((_{ 1},t_{1}),&(_{1},t_{1}))+^{2}(2a+) C((_{1},t_{1}),})\\ &+^{2}((^{}+ )\,C(},}))\] (10)

_where \(C(,)=((k_{S}*k_{S})(_{j}-_{i})(k_{ T}*k_{T})_{t_{0}-t_{i}}^{+}(t_{j}-t_{i}))_{(_{i},t_{i}) ,\\ (_{j},t_{j})}\), where \((f*g)\) denotes the convolution between \(f\) and \(g\), and \((f*g)_{}^{b}\) denotes the convolution between \(f\) and \(g\) restricted to the interval \([a,b]\). The terms \(a\), \(\), \(\), \(\) and \(\) are explicited in Appendices A and B._

_Moreover, an upper bound for \(W_{2}^{2}(_{},_{})\) on \(_{t_{0}}\) is_

\[_{2}^{2}(_{},_{} )=^{2}(^{}^{-}C(, )^{-1}+(^ {-1}C(,))).\] (11)

This theorem provides the analytic form of an upper bound for the Wasserstein distance between \(_{}\) and \(_{}}\) and the Wasserstein distance between \(_{}\) and \(_{}\) on the domain of future predictions \(_{t_{0}}\). Using it, we can compute an approximation \(\) of the relative criterion (9), that is

\[(_{},_{}})=_{2}(_{},_{}})}{ _{2}(_{},_{})}.\] (12)

In Appendix C, we study the error between the criterion (9) and the approximation (12). In essence, we bound the approximation error caused by estimating the integrals in (8) by a self-convolution of the covariance functions \(k_{S}\) and \(k_{T}\) (i.e., \(k_{S}*k_{S}\) and \(k_{T}*k_{T}\)). Furthermore, we provide numerical evidence that the approximation errors in the numerator and the denominator of (12) compensate each other at least in part, making (12) a decent approximation for (9).

In practice, the upper bounds (10) and (11) can only be computed efficiently if the convolutions of the covariance functions can themselves be computed efficiently. The analytic forms for the convolution of two usual covariance functions listed in Table 1, namely Squared-Exponential (SE) and Matern , are provided in Appendix D together with Tables 3 and 4 that list the self-convolutions for the spatial (resp., temporal) covariance function. Their detailed computations are also provided in this appendix. In a nutshell, the formulas are obtained first in the Fourier domain by computing the square of the spectral densities of the covariance functions, and next by computing their inverse Fourier transform.

Together, Tables 3, 4 in Appendix D and Theorem 4.1 show that the approximation of (9) given by (12) can be computed efficiently in an online setting. In an effort to generalize our results to a class of covariance functions that extends beyond Assumption 3.2, we also discuss how to compute the self-convolution of an anisotropic spatial SE covariance function in Appendix E. We now leverage (12) to propose a DBO algorithm able to pinpoint and remove irrelevant observations in its dataset.

### W-Dbo

The metric (9) and its approximation (12) can be seen as a relative error (or drift), expressed as a percentage, that separates \(_{}\) and \(_{}}\). Indeed, the Wasserstein distance \(W(_{},_{}})\) is scaled by the Wasserstein distance \(W(_{},_{})\), that is, the distance between \(_{}\) and the prior. In other words, (9) and its approximation (12) measure the relative drift from \(_{}\) to \(_{}}\) caused by the removal of one observation. When removing multiple observations, the relative drifts naturally accumulate in a multiplicative way (similarly to the way relative errors accumulate). As a consequence, removing multiple observations could, in the worst case, make \(_{}}\) drift exponentially fast from \(_{}\). To keep this exponential drift under control, one can use a removal budget \(b(t)=(1+)^{t}\) that allows a maximal relative drift from \(_{}\) of \(\) per unit of time (e.g., if \(=0.1\), the allowed maximal drift is 10 % per unit of time). The cost of removing an observation is given by (12).

Algorithm 1 describes W-DBO, a DBO algorithm exploiting (12) to remove irrelevant observations on the fly. As described above, the removal budget is controlled by a single hyperparameter \(\) and grows exponentially as time goes by (see line 24). At each iteration, (12) is used to compute the relevancy of each observation in the dataset (see lines 10-13). The relevancy of the least relevant observation is then compared to the removal budget, and the observation is removed if the budget allows it (see lines 14-17). This process is repeated until all the budget is consumed. Such a greedy observation removal policy causes W-DBO to overestimate the impact of removing multiple observations3. We discuss and motivate the expression of the removal budget in Appendix G. The sensitivity analysis conducted in Section 5.1 supports this removal budget, by showing that the same value of the hyperparameter \(\) is valid for a large set of different objective functions.

Finally, note that using (12) to remove irrelevant observations on the fly can be performed in conjunction with any BO algorithm, because it can be appended at the end of each optimization step as a simple post-processing stage. This agnostic property of W-DBO is supported by the ability of Algorithm 1 to take as inputs any GP model \(\) and any acquisition function \(\). Similarly, observe that lines 5-8 in Algorithm 1 describe the usual BO optimization loop, without any modification.

## 5 Numerical Results

In this section, we study the empirical performance of W-DBO. To measure the quality of the queries made by the DBO solutions, we compute the average regret (lower is better). For the sake of realistic evaluation, two iterations of a solution are seperated by its response time (_i.e._, the time taken to infer its hyperparameters and optimize its acquisition function). Furthermore, all covariance function

   Covariance Function & \(k()\) \\  Squared-Exponential (\(l\)) & \(e^{-||_{2}^{2}}{2l^{2}}}\) \\ Matern (\(,l\)) & \(}{()}(||||_{2}}{l_{S}} )^{}K_{}(||||_{2}}{l_{S}})\) \\   

Table 1: Usual covariance functions. \(\) is the Gamma function and \(K_{}\) is a modified Bessel function of the second kind of order \(\).

parameters and the noise level are estimated on the fly. Please refer to Appendix H.1 for further experimental details, and to Appendix H.2 for a detailed description of the dynamic benchmarks.

### Sensitivity Analysis

We start by studying the impact of the W-DBO hyperparameter \(\) on the average regret. Recall that we take into account the response time of the algorithm. This evaluation protocol reveals that a trade-off must be achieved between having an accurate model of the objective function (which requires a large dataset) and being able to track the optimal argument of the function as it evolves (which requires a high sampling frequency, thus a moderately-sized dataset).

Figure 3: (Left) Sensitivity analysis on the Eggholder function. (Right) Aggregation of sensitivity analyses of W-DBO made on 10 synthetic functions and a real-world experiment. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of W-DBO over all the experiments is shown in black. Standard errors are depicted with colored bars (left) and shaded areas (right).

To study this trade-off, we compare the performance of W-DBO with several values of its hyperparameter \(\), as illustrated by the left side of Figure 3. We apply this protocol on 11 different benchmarks (described in Appendix H.2). The aggregated results (see the right side of Figure 3) show that achieving a trade-off between the size of the dataset and the sampling frequency can significantly improve the performance of W-DBO. Clearly, the sweet spot is reached for \(=\). This hyperparameter value is used to evaluate W-DBO in the next section.

### Comparison with Baselines

The competing baselines are the relevant algorithms reported in Section 2, namely R-GP-UCB and TV-GP-UCB , ET-GP-UCB  and ABO . We also consider vanilla BO with the GP-UCB acquisition function, which only considers spatial correlations. For comparison purposes, all the results are gathered in Table 2. The benchmarks comprise ten synthetic functions and two real-world experiments. All figures (including standard errors) are provided in Appendix H.2, and the performance of each DBO solution is discussed at length in Appendix H.3. Furthermore, the provided supplementary animated visualizations are discussed in Appendix H.4.

In this section. we only depict the performance of the DBO solutions on the Ackley synthetic function in Figure 4, because it illustrates best the singularity of W-DBO. The Ackley function is known for its almost flat outer region (with lots of local minima) and its deep hole at the center of its domain. Observe that most DBO solutions miss that hole, as their average regrets skyrocket between 200 and

  Experiment (\(d+1\)) & GP-UCB & R-GP-UCB & TV-GP-UCB & ET-GP-UCB & ABO & W-DBO \\  Rastrigin (5) & \(\) & \(53.67\) & \(26.50\) & \(19.54\) & \(36.16\) & \(18.54\) \\ Schwefel (4) & \(469.10\) & \(954.03\) & \(520.40\) & \(428.97\) & \(662.32\) & \(\) \\ StyblinskiTang (4) & \(18.83\) & \(45.82\) & \(15.74\) & \(22.16\) & \(58.40\) & \(\) \\ Eggholder (2) & \(542.53\) & \(273.60\) & \(287.01\) & \(559.61\) & \(256.92\) & \(\) \\ Ackley (4) & \(4.10\) & \(4.45\) & \(3.27\) & \(3.96\) & \(3.63\) & \(\) \\ Rosenbrock (3) & \(31.37\) & \(25.99\) & \(17.55\) & \(28.79\) & \(171.04\) & \(\) \\ Shekel (4) & \(2.56\) & \(2.21\) & \(2.03\) & \(2.70\) & \(2.06\) & \(\) \\ Hartmann3 (3) & \(1.17\) & \(\) & \(0.82\) & \(1.06\) & \(0.55\) & \(0.35\) \\ Hartmann6 (6) & \(1.33\) & \(1.25\) & \(0.44\) & \(1.46\) & \(0.61\) & \(\) \\ Powell (4) & \(1992.1\) & \(1167.6\) & \(1223.4\) & \(534.2\) & \(9888.6\) & \(\) \\  Temperature (3) & \(1.02\) & \(0.69\) & \(1.36\) & \(1.25\) & \(1.21\) & \(\) \\ WLAN (5) & \(1.46\) & \(4.84\) & \(1.33\) & \(4.98\) & \(12.94\) & \(\) \\  Avg. Perf. & \(0.48\) & \(0.47\) & \(0.29\) & \(0.54\) & \(0.62\) & \(\) \\  

Table 2: Comparison of W-DBO with competing methods. The average regret over 10 independent replications is reported (lower is better). The performance of the best algorithm is written in **bold text**. The performance of algorithms whose confidence intervals overlap the best performing algorithm’s confidence interval is underlined.

Figure 4: (Left) Average regrets of the DBO solutions during the optimization of the Ackley synthetic function. (Right) Dataset sizes of the DBO solutions during the optimization of the Ackley function.

400 seconds. In contrast, W-DBO manages to rapidly exploit the hole at the center of the function domain, thereby maintaining a low average regret.

This performance gap can be explained by studying the dataset size of W-DBO (see the right side of Figure 4). At first, the dataset size increases since most collected observations are relevant to predict the outer region of the Ackley function. After \(200\) seconds, the dataset size plateaus as W-DBO begins to realize that some previously collected observations are irrelevant to predict the shape of the hole that lies ahead. Between \(300\) and \(400\) seconds, the dataset size is halved because most previously collected observations are deemed irrelevant. Eventually, after \(400\) seconds, W-DBO explores the flatter outer region of the Ackley function again. Consequently, its dataset size increases again.

For a summary of the performance of the DBO solutions across all our benchmarks, please refer to the last row of Table 2, and to the visual summary in Figure 5. In our experimental setting, ABO and ET-GP-UCB obtain roughly the same performance as vanilla BO. R-GP-UCB shows slightly better average performance than GP-UCB, while TV-GP-UCB appears significantly better than the aforementioned algorithms. Remarkably, W-DBO shows significantly better performance than TV-GP-UCB and outperforms the other DBO solutions by a comfortable margin. In fact, it obtains the lowest average regret on almost every benchmark.

## 6 Conclusion

The ability to remove irrelevant observations from the dataset of a DBO algorithm is essential to ensure a high sampling frequency while preserving its predictive performance. To address this difficult problem, we have proposed (i) a criterion based on the Wasserstein distance to measure the relevancy of an observation, (ii) a computationally tractable approximation of this criterion to allow its use in an online setting and (iii) a DBO algorithm, W-DBO, that exploits this approximation. We have evaluated W-DBO against the state-of-the-art of DBO on a variety of benchmarks comprising synthetic functions and real-world experiments. The evaluation was conducted in the most challenging settings, where time is continuous, the time horizon is unknown, as well as the covariance functions hyperparameters. We observe that W-DBO outperforms the state-of-the-art of DBO by a comfortable margin. We explain this significant performance gap by the ability of W-DBO to quantify the relevancy of each of its observations, which is not shared with any other DBO algorithm, to the best of our knowledge. As a result, W-DBO can remove irrelevant observations in a smoother and more appropriate way than by simply triggering the erasure of the whole dataset. By doing so, W-DBO simultaneously ensures a high sampling frequency and a very good predictive performance.

In addition to its impact on DBO itself, we believe that W-DBO can have a significant impact on the fields that make heavy use of DBO (e.g., computer networks, robotics). As a future work, we plan on exploring these applications of W-DBO. Furthermore, we plan on better understanding the excellent performance of W-DBO by addressing the difficult problem of deriving a regret bound that holds in a continuous time setting and incorporates the effect of the sampling frequency of the DBO algorithm as well as the deletion of irrelevant observations.

Figure 5: Visual summary of the results reported in Table 2. For aggregation purposes, the average regrets in each experiment have been normalized between 0 (lowest average regret) and 1 (largest average regret). The average performance of the DBO solutions is shown in black.