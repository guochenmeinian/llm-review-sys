# Neural Model Checking

Mirco Giacobbe

University of Birmingham, UK

&Daniel Kroening

Amazon Web Services, USA

&Abhinandan Pal

University of Birmingham, UK

&Michael Tautschnig

Amazon Web Services, USA and

Queen Mary University of London, UK

The authors are listed alphabetically.

###### Abstract

We introduce a machine learning approach to model checking temporal logic, with application to formal hardware verification. Model checking answers the question of whether every execution of a given system satisfies a desired temporal logic specification. Unlike testing, model checking provides formal guarantees. Its application is expected standard in silicon design and the EDA industry has invested decades into the development of performant symbolic model checking algorithms. Our new approach combines machine learning and symbolic reasoning by using neural networks as formal proof certificates for linear temporal logic. We train our neural certificates from randomly generated executions of the system and we then symbolically check their validity using satisfiability solving which, upon the affirmative answer, establishes that the system provably satisfies the specification. We leverage the expressive power of neural networks to represent proof certificates as well as the fact that checking a certificate is much simpler than finding one. As a result, our machine learning procedure for model checking is entirely unsupervised, formally sound, and practically effective. We experimentally demonstrate that our method outperforms the state-of-the-art academic and commercial model checkers on a set of standard hardware designs written in SystemVerilog.

## 1 Introduction

Electronic design is complex and prone to error. Hardware bugs are permanent after production and as such can irremediably affect the correctness of software--which runs on hardware--and can compromise the safety of cyber-physical systems--which embed hardware. Correctness assurance is core to the engineering of digital circuitry, with the median FPGA and IC/ASIC projects spending respectively \(40\,\) and \(60\,\) of time in verification . Verification approaches based on directed or constrained random testing are easy to set up but are inherently non-exhaustive . Testing cannot show the absence of bugs which, for systems the safety of which is critical, can have serious consequences; notably, over \(40\,\) of hardware development projects must satisfy at least one functional safety standard . In contrast to testing, _model checking_ a design against a formal specification of correctness answers the question of whether the design satisfies the specification with mathematical certainty, for every possible execution of the system .

The EDA industry has heavily invested in software tools for symbolic model checking. Early symbolic model checking algorithms utilise fixed-point computations with binary decision diagrams (BDDs) , where each node specifies the Boolean assignment for a circuit's flip-flop or input bit . BDDs struggle to scale when applied to complex arithmetic data paths, prompting a shift towards iterative approximation of fixed points using propositional satisfiability (SAT) solving , whichis now the state-of-the-art technique. Both BDD and SAT-based model checking, despite extensive research, remain computationally demanding; even small circuit modules can require days to verify or may not complete at all. Consequently, verification engineers often limit state space exploration to a bounded time horizon through bounded model checking, sacrificing global correctness over the unbounded time domain.

We present a machine learning approach to hardware model checking that leverages neural networks to represent proof certificates for the compliance of a given hardware design with a given linear temporal logic (LTL) specification . Our approach avoids fixed-point algorithms entirely, capitalises on the efficient word-level reasoning of satisfiability solvers, and delivers a formal guarantee over an unbounded time horizon. Given a hardware design and an LTL specification \(\), we train a word-level neural certificate for the compliance of the design with the specification from test executions, which we then check using a satisfiability solver. We leverage the observation that checking a proof certificate is much simpler than solving the model checking problem directly, and that neural networks are an effective representation of proof certificates for the correctness of systems . We ultimately obtain a machine learning procedure for hardware model checking that is entirely unsupervised, formally sound and, as our experiments show, very effective in practice.

Our learn-and-check procedure begins by generating a synthetic dataset through random executions of the system alongside a Buchi automaton that identifies counterexamples to \(\). We then train a _neural ranking function_ designed to strictly decrease whenever the automaton encounters an accepting state and remain stable on non-accepting states. After training, we formally check that the ranking function generalises to all possible executions. We frame the check as a cost-effective one-step bounded model checking problem involving the system, the automaton, and the quantised neural ranking function, which we delegate to a satisfiability solver. As the ranking function cannot decrease indefinitely, this confirms that the automaton cannot accept any system execution, effectively proving that such executions are impossible. Hence, if the solver concludes that no counterexample exists, it demonstrates that no execution satisfies \(\), thereby affirming that the system satisfies \(\).

We have built a prototype that integrates PyTorch, the bounded model checker EBMC, the LTL-to-automata translator Spot, the SystemVerilog simulator Verilator, and the satisfiability solver Bitwuzla . We have assessed the effectiveness of our method across 194 standard hardware model checking problems written in SystemVerilog and compared our results with the state-of-the-art academic hardware model checkers ABC and nuXmv , and two commercial counterparts. For any given time budget of less than 5 hours, our method completes on average \(60\,\%\) more tasks than ABC, \(34\,\%\) more tasks than nuXmv, and \(11\,\%\) more tasks than the leading commercial model checker. Our method is faster than the academic tools on \(67\,\%\) of the tasks, 10X faster on \(34\,\%\), and 100X faster on \(4\,\%\); when considering the leading commercial tool, our method is faster on \(75\,\%\), 10X faster on \(29\,\%\), and 100X faster on \(2\,\%\) of them. Overall, with a straightforward implementation, our method outperforms mature academic and commercial model checkers.

Our contribution is threefold. We present for the first time a hardware model checking approach based on neural certificates. We extend neural ranking functions, previously introduced for the termination analysis of software, to LTL model checking and the verification of reactive systems. We have built a prototype and experimentally demonstrated that our approach compares favourably with the leading academic and commercial hardware model checkers. Our technology delivers formal guarantees of correctness and positively contributes to the safety assurance of systems.

## 2 Automata-theoretic Linear Temporal Logic Model Checking

An LTL model checking problem consists of a model \(\) that describes a system design and an LTL formula \(\) that describes the desired temporal behaviour of the system . The problem is to decide whether all traces of \(\) satisfy \(\).

Our formal model \(\) of a hardware design consists of a finite set of bit-vector-typed variables \(X_{}\) with fixed bit-width and domain of assignments \(S\), partitioned into input variables \(X_{} X_{}\) and state-holding register variables \(X_{} X_{}\); we interpret primed variables \(X^{}_{}\) as the value of \(X_{}\) after one clock cycle. Then, a sequential update relation \(_{}\) relates \(X_{}\) and \(X^{}_{}\) and computes the next-state valuation of the registers from the current-state valuation of all variables; we interpret \(_{}\) as a first-order logic formula encoding this relation. A state \( S\) is a valuation for the variables \(X_{}\). We denote as \(,,\) the restriction of \(\) to the respective class of variables. For two states \(\) and \(}\), the state \(}\) is a successor of \(\), which we write as \(_{}}\), if \(_{}(,\,})\) evaluates to true. We call \(_{}\) the transition relation of \(\) and say that an infinite sequence of states \(}_{0},}_{1},}_{2},\) is an execution of \(\) if \(}_{i}_{}}_{i+1}\) for all \(i 0\); we say that an execution is initialised in \(s_{0} S\) when \(}_{0}=s_{0}\).

We specify the intended behaviour of systems in LTL, which is the foundation of SystemVerilog Assertions. LTL extends propositional logic with temporal modalities \(\), \(\), \(\), and \(\). The modality \(\)\(_{1}\) indicates that \(_{1}\) holds immediately after one step in the future, \(\)\(_{1}\) indicates that \(_{1}\) holds at all times in the future, \(\)\(_{1}\) indicates that \(_{1}\) holds at some time in the future, and \(_{1}\)\(_{2}\) indicates that \(_{1}\) holds at all times until \(_{2}\) holds at some time in the future. We refer the reader to the literature for the formal syntax and semantics of LTL . The atomic propositions of the LTL formulae we consider are Boolean variables of \(\), which we call the observables \(\,X_{} X_{}\) of \(\). We note that any first-order predicate over \(X_{}\) can be bound to a Boolean observable using combinational logic (cf. Figure 4, where observable \(\) corresponds to predicate \(\) == \(\)).

We call a trace of \(\) a sequence \(\,}_{0},\,}_{1},\, }_{2},\) where \(}_{0},}_{1},}_{2},\) is an execution of \(\). We define the language \(L_{}\) of \(\) as the maximal set of traces of \(\). Every LTL formula \(\) is interpreted over traces and as such defines the language \(L_{}\) of traces that satisfy \(\). The model checking problem corresponds to deciding the language inclusion question \(L_{} L_{}\).

As is standard in automata-theoretic model checking, we rely on the result that every LTL formula admits a non-deterministic Buchi automaton that recognises the same language . A non-deterministic Buchi automaton \(\) consists of a finite set of states \(Q\), an initial start state \(q_{0} Q\), an input domain \(\) (also called alphabet), a transition relation \( Q Q\), and a set of fair states \(F Q\). One can interpret an automaton \(\) as a hardware design with one register variable \(\,X_{}=\{\}\) having domain \(Q\), input and observable variables \(\,X_{}=\,X_{}\) having domain \(\), and sequential update relation \(_{}(,,^{})(,,^{})\) governing the automaton state transitions. We say that an execution of \(\) is _fair_ (also said to be an accepting execution) if it visits fair states infinitely often. We define the fair language \(L^{t}_{}\) of \(\) as the maximal set of traces corresponding to fair executions initialised in \(q_{0}\). Given any LTL formula \(\), there are translation algorithms and tools to construct non-deterministic Buchi automata \(_{}\) such that \(L^{t}_{_{}}=L_{}\).

The standard approach to answer the language inclusion question \(L_{} L_{}\) is to answer the dual language emptiness question \(L_{} L_{}=\). For this purpose, we first construct a non-deterministic Buchi automaton \(_{}\) for the complement specification \(\) where \(\,X_{_{}}=\,X_{}\), then we reason over the synchronous composition (over a shared clock) of \(\) and \(_{}\) as illustrated in Figure 0(a). We direct the reader to the relevant literature for general definitions of system composition . In this context, the synchronous composition results in the system \(_{}\) with input variables \(\,X_{_{}}=\,X_{ }\), register variables \(\,X_{_{}}=\,X_{ }\{\}\), observable variables \(\,X_{_{}}=\,X_{ }\), and sequential update relation \(_{_{}}(s,q,r^{},q^{})=_{}(s,r^{})_{ _{}}(\,s,q,q^{})\). We extend the fair states of \(_{}\) to \(_{}\), i.e., we define them as \(\{(s,q) s S,q F\}\), and as a result we have that \(L^{t}_{_{}}=L_{} L^{t}_{ _{}}=L_{} L_{}\). This reduces our language emptiness question to the equivalent _fair emptiness_ problem \(L^{t}_{_{}}=\).

Figure 1: Automata-theoretic neural model checking via fair termination

The fair emptiness problem amounts to showing that all executions of \(_{}\) are unfair, and we do so by presenting a ranking function that witnesses fair termination . A ranking function for fair termination is a map \(V:\,\,S Q R\) where \((R,)\) defines a well-founded relation and, for all system and automaton states \(,^{} S,,^{} Q\), the following two conditions hold true:

\[(,)_{_{ }}(^{},^{}) V(\,, {q}) V(\,^{},^{})\] (1) \[(,)_{_{ }}(^{},^{}) F V(\,,) V(\,^{},^{})\] (2)

A ranking function \(V\) strictly decreases every time a transition from a fair state is taken, and never increases in any other case. Since every strictly decreasing sequence must be bounded from below (well-foundedness), every fair state can be visited at most finitely many times; the intuition is presented in Figure 0(b), where \(_{F}(q)\) denotes the indicator function of \(F\), returning 1 if \(q F\) and 0 otherwise. The existence of a valid ranking function represented in some form establishes that every execution of \(_{}\) is necessarily unfair . In this work, we represent ranking functions as neural networks, the parameters of which we train from generated sample executions.

## 3 Neural Ranking Functions for Fair Termination

We approach the problem of computing a ranking function for fair termination by training a neural network \(^{n}\), with \(n\) input neurons where \(n=|\,\,X_{}|\) is the number of register variables of the system, one output neuron, and with a space of learnable parameters \(\) for its weights and biases. We associate a distinct trainable parameter \(_{q}\) to each state \(q Q\) of the Buchi automaton. We train these parameters on sampled executions of \(_{}\) to ultimately represent a ranking function as a neural network \(V(r,q)(r;_{q})\), which we call a neural ranking function. This scheme is illustrated in Figure 1, where we denote the set of all parameters by the unindexed \(\).

We define our training objective as fulfilling conditions (1) and (2) on our synthetic dataset of sampled executions which, by analogy with reinforcement learning, can be viewed as a special case of episodes . Subsequently, we verify the conditions symbolically over the full state space \(S Q\) using satisfiability solving modulo theories (SMT) , to confirm the validity of our neural ranking function or obtain a counterexample for re-training. Overall, our approach combines learning and SMT-based checking for both efficacy and formal soundness, as illustrated in Figure 2.

For a system \(\) and a specification \(\), we train the parameters \(\) of a neural network \(\) from a sample dataset \(D\,S Q\,S Q\) of subsequent transition pairs, which we construct from random executions of the synchronous composition \(_{}\). Each execution \((}_{0},}_{0}),(}_{1},}_{1}),,( }_{k},}_{k})\) initiates from a random system and automaton state pair and is then simulated over a finite number of steps; the inputs to \(\) and the non-deterministic choices in \(_{}\) are resolved randomly. Our dataset \(D\) is constructed as the set of all quadruples \((\,}_{i},}_{i},\,}_{i+1 },}_{i+1})\) for \(i=0,,k-1\) from all sampled executions, capturing consecutive state pairs along each execution; notably, the order in which quadruples are stored in \(D\) is immaterial for our purpose, as our method reasons and trains locally on each transition pair regardless of their order of appearance along any execution.

We train the parameters of our neural network \(\) to satisfy the ranking function conditions (1) and (2) over \(D\). For each quadruple \((,,^{},^{}) D\), this amounts to minimising the following loss function:

\[_{}(,,^{},^{};) =((^{};_{^{}})-(;_{})+_{F}()).\] (3)

where \(>0\) is a hyper-parameter that denotes the margin for the decrease condition. When \(_{}\) takes its minimum value--which is zero--then the following two cases are satisfied: if \( F\), then \(\) does not increase along the given transition, i.e., \((;_{})(^{};_{^{ }})\), which corresponds to satisfy condition (1); if otherwise \( F\), then \(\) decreases by at least the margin \(>0\) along the given transition, i.e., \((;_{})(^{};_{^{ }})+\), which corresponds to satisfy condition (2).

Figure 2: Learn-and-check workflow for _provably sound_ neural ranking function learning

Overall, our learning phase ensures that the total loss function \((D;)\) below takes value zero:

\[(D;)=_{(,,^{},^{})  D}[_{}(,,^{},^{}; )]\] (4)

Unlike many other machine learning applications, for our purpose it is essential to attain the global minimum; if this fails, there are counterexamples to \(\) being a ranking function in the dataset \(D\) itself. To facilitate the optimisation process, we train the parameters associated to each automaton state independently, one after the other, as opposed to training all parameters at once. Iteratively, we select one automaton state \(q Q\) and optimise only \(_{q}\) for a number of steps, while keeping all other parameters \(_{q^{}}\) fixed to their current value, for all \(q^{} q\). We repeat the process over each automaton state, possibly iterating over the entire set of automaton states \(Q\) multiple times, until the total loss \((D;)\) takes value zero.

Our neural network \(\) follows a feed-forward architecture as depicted in Figure 3: for a given automaton state \(q Q\) and associated parameter \(_{q}\), it takes an \(n\)-dimensional input \(r^{n}\) where each input neuron corresponds to the value of a register variable in \(X_{}\), and produces one output for the corresponding ranking value \((r;_{q})\). Our architecture consists of a normalisation layer, followed by an element-wise multiplication layer, in turn followed by a multi-layer perceptron with clamped ReLU activation functions. The first layer applies a scaling factor to each input neuron independently to ensure consistent value ranges across inputs, implemented via element-wise multiplication with a constant vector of scaling coefficients derived from the dataset \(D\) before training; this integrates data normalisation into the network, enables \(\) to use raw data from \(\) and simplifies the symbolic encoding of the normalisation operation during the verification phase. The second layer applies a trainable scaling factor to each individual neuron and is implemented via element-wise multiplication with a \(n\)-dimensional vector with trainable coefficients. Finally, this is followed by a fully connected multi-layer perceptron with trainable weights and biases, with the activation function defined as the element-wise application of \((x;u)=(0,(x,u))\); the upper bound \(u\) and the depth and width of the hidden layers of the multi-layer perceptron component are hyper-parameters chosen to optimise training and verification performance.

Attaining zero total loss \((D;)\) guarantees that our neural ranking function candidate \(\) satisfies the ranking criteria for fair termination over the dataset \(D\) but not necessarily over the entire transition relation \(_{\|A_{-}}\), as required to fulfil conditions (1) and (2) and consequently to answer our model checking question (cf. Section 2). To formally check whether the ranking criteria are satisfied over the entire transition relation, we couple our learning procedure with a sound decision procedure that verifies their validity, as illustrated in Figure 2.

We check the validity of our candidate ranking neural network using satisfiability modulo the theory of bit-vectors. While the sequential update relation Update\({}_{\|A_{-}}\) is natively expressed over the theory of bit-vectors, the formal semantics of the neural network \(\) is defined on the reals. Hence, encoding \(\) and Update\({}_{\|A_{-}}\) within the same query would result in a combination of real and bit-vector theories, which is supported in modern SMT solvers but often leads to sub-optimal performance . Therefore, to leverage the efficacy of specialised solvers for the theory of bit-vectors , we quantise our neural network using a standard approach for this purpose ; this converts all arithmetic operations within the neural networks into fixed-point arithmetic, which are implemented using integer arithmetic only. We quantise our parameters to their respective integer representation \( 2^{f}\), where \(f\) is a hyper-parameter for the number of fractional digits in fixed-point representation, and we replace linear layers and activation functions by their quantised counterpart; readers may consult the relevant literature for more detailed information on neural

Figure 3: Neural ranking function architecture

network quantisation [49; 57]. This results in a quantised neural network \(^{n}\) that approximates our trained network \( 2^{f}\), where \(\) denotes the space of integer parameters. fractional digits introduced by the linear layers [49; 57]. We consider the quantised network \(\) as our candidate proof certificate for fair termination.

We reduce the validity query--whether our quantised neural network \(\) satisfies the ranking criteria for fair termination (1) and (2) over the entire transition relation of \(_{}\)--to the dual satisfiability query for the existence of a counterexample to the criteria. Specifically, we delegate to an off-the-shelf SMT solver the task of computing a satisfying assignment \(s S,r^{}S\) for which the following quantifier-free first-order logic formula is satisfied:

\[_{q,q^{} Q}_{ _{}}(s,q,r^{},q^{})( {reg}s;}_{q})-_{F}(q)<(r^{};}_{q^{}})\] (5)

where \(}\) is the (constant) parameter resulting from training and quantisation. We encode the quantised neural network \(\) using a standard translation into first-order logic over the theory of bit-vectors , supplementing it with specialised rewriting rules to enhance the solver's performance, as detailed in Appendix A. We additionally note that \(\) is guaranteed to be bounded from below as \(S\) is finite, albeit potentially very large, i.e., exponential in the combined bit-width of \(X_{}\).

If the solver finds a satisfying assignment, then the assignment represents a transition of \(\) that refutes the validity of \(\); in this case, we extend it to a respective transition in \(_{}\), we add it to our dataset \(D\) and repeat training and verification in a loop. Conversely, if the solver determines that formula (5) is unsatisfiable, then our procedure concludes that \(\) is formally a valid neural ranking function and, consequently, system \(\) satisfies specification \(\).

We note that LTL model checking of hardware designs is decidable and PSPACE-complete [9; 13; 35]. While it is theoretically possible for our approach to achieve completeness when a ranking function exists by enumerating all transitions and employing a sufficiently large neural network as a lookup table over the entire state space, this is impractical for all but toy cases. In this work, we employ tiny neural networks and incomplete but practically effective gradient descent algorithms to train neural ranking functions. We experimentally demonstrate on a large set of formal hardware verification benchmarks that this solution is very effective in practice.

## 4 Illustrative Example

Modern hardware designs frequently incorporate word-level arithmetic operations, the simplest of which being counter increments/decrements, which are a staple in hardware engineering [71; 98]. One such example is illustrated as part of the SystemVerilog module in Figure 4. This represents a simplified buffer controller that counts the number of packets stored in the buffer and indicates when the buffer is full or empty with the \(\) and \(\) signals, respectively. This specific controller internally coordinates read-and-write operations through the \(\) signal: iteratively, the system signals \(\) = 1 until the buffer is full and then \(\) = 0 until the buffer is empty.

The design satisfies the property that both our observables \(\) and \(\) are true infinitely often, captured by the LTL formula \(=\,\,\). Dually, this specification says that the system

Figure 4: Illustrative hardware design, BÃ¼chi automaton, and respective ranking function

does not eventually go into a state from where \(\)ful holds indefinitely nor \(\)emp holds indefinitely, that is, \(=\). Equivalently, this amounts to proving that no system trace is in the fair language of the automaton \(_{}\) given in Figure 4.

A neural ranking function \(\) for the fair termination of this system and automaton has 5 input neurons for the register variables cnt, m, ful, emp, and rw, and one hidden layer with three neurons in the multi-layer perceptron component. As illustrated in Figure 4, each automaton state is associated with a ranking function defined in terms of this architecture and their respective parameters. The sequence below gives an execution of model states alongside the respective ranking function values:

 \)} & \)} & \)} & \)} \\  cnt & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\  m & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 \\  rw & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 0 \\  \((;_{q_{0}})\) & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 & 14 \\  \((;_{q_{1}})\) & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 14 & 13 & 12 & 11 & 10 & 9 & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\  \((;_{q_{2}})\) & 1 & 14 & 13 & 12 & 11 & 10 & 9 & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 & 14 & 13 & 12 & 11 & 10 & 9 & 8 \\  

One can observe that all transitions throughout this execution satisfy conditions (1) and (2). This assessment is based on the (not explicitly presented) synchronous composition with the automaton. First, we note that every transition originating from \(q_{0}\) has a non-increasing ranking value, as \((;_{q_{0}})=14\) is an upper bound to all other values. Furthermore, every transition leaving \(q_{1}\)--that is, every transition whose source state satisfies \(\)ful--exhibits a strictly decreasing value \((;_{q_{1}})\). Similarly, the same observation applies to \(q_{2}\) and the condition \(\)emp. We note that the transitions that exhibit increasing values from 1 to 14 in this execution are impossible over the synchronous composition; this is because they are originating from states that satisfy both ful and \(q_{1}\), and similarly states that satisfy both emp and \(q_{2}\), and which do not have corresponding transitions in the automaton.

This neural ranking function admits no increasing transition originating from \(q_{0}\) and no non-decreasing transitions originating from \(q_{1}\) or \(q_{2}\) on the synchronous composition of the system and the automaton. Therefore, it is a valid proof certificate for every system trace to satisfy specification \(\).

## 5 Experimental Evaluation

We examine 194 verification tasks derived from ten parameterised hardware designs, detailed in Appendix B. By adjusting parameter values, we create tasks of varying complexity, resulting in different logic gate counts and state space sizes, thus offering a broad spectrum of verification complexity for tool comparison. The parameter ranges for each design are given as "all tasks" in Figure 5. These tasks serve as benchmarks to evaluate the scalability of our method relative to conventional model checking.

ImplementationWe have developed a prototype tool for neural model checking2, utilising Spot 2.11.6  to generate the automaton \(_{}\) from an LTL specification \(\). As depicted in Figure 1, the circuit model \(\) and the automaton \(_{}\) synchronise over a shared clock to form a product machine. Using Verilator version 5.022 , we generate a dataset \(D\) from finite trajectories of this machine. This dataset trains a neural network using PyTorch 2.2.2, as outlined in Section 3. To ensure formal guarantees, the network is quantised and subsequently translated to SMT, following the process outlined in Appendix A. The SystemVerilog model is converted to SMT using EBMC 5.2 . We check the satisfiability problem using the Bitwuzla 0.6.0 SMT solver .

State of the ArtWe benchmarked our neural model checking approach against two leading model checkers, nuXmv  and ABC . ABC and nuXmv were the top performers in the liveness category of the hardware model checking competition (HWMCC) . Our comparison employed the latest versions: nuXmv 2.0.0 and ABC's Super Prove tool suite , which were also used in the most recent HWMCC'20 . We further consider two widely used industrial formal verification tools for SystemVerilog, anonymised as industry tool X and industry tool Y. Tool Y fails to complete any of the 194 tasks and is therefore not referenced further in this section.

Experimental SetupEvaluations were conducted on an Intel Xeon 2.5 GHz processor with eight threads and 32 GB of RAM running Ubuntu 20.04. Bitwuzla and nuXmv utilise one core each, ABC used three cores, and PyTorch leveraged all available cores. Each tool was allotted a maximum of five hours for each verification task, as detailed in Appendix C.

Hyper-parametersWe instantiate the architecture described in Section 3 and illustrated in Figure 3, employing two hidden layers containing 8 and 5 neurons. The normalisation layer scales the input values to the range . We train with the AdamW optimiser , typically setting the learning rate to 0.1 or selecting from 0.2, 0.05, 0.03, 0.01 if adjusted, with a fixed weight decay of 0.01, demonstrating minimal hyperparameter tuning for training.

Dataset GenerationIn hardware design, engineers utilise test benches to verify safety properties through directed testing or Constraint Random Verification (CRV), aiming for high coverage and capturing edge cases . We apply CRV to the SystemVerilog file, generating random trajectories. As outlined in Section 3, we start these trajectories by selecting the internal states of model \(\) (e.g., module BufferCtr and automaton \(A_{}\); in Figure 4) using a uniform distribution. At each step, we assign random inputs to model \(\) and handle the non-determinism in automaton \(A_{}\) by making choices from uniform or skewed distributions. We skew the distribution when a particular event is too predominant or too rare. In our experiments, such skewing is rare and limited to the reset and enable signals in \(\), as well as the non-determinism in the automaton \(A_{}\).

Solved TasksTable 1 presents the number of completed tasks for each tool across the ten hardware designs, while Figure 5 shows the range of state-space sizes and logic gate counts each tool successfully handled. Overall, our tool performs favourably in comparison to others, with the notable exception of the VGA design, where training a ranking function failed due to local minima, preventing convergence to zero loss--a known limitation of gradient descent-based methods.

Aggregate Runtime ComparisonFigure 5(a) displays a cactus plot with a \(5\,\) limit, we consider our configuration with 8 and 5 hidden neurons as detailed in the section, along with the aggregate of the best time on individual tasks obtained from our ablation study, as detailed in Appendix D. While the default architecture performs the best across all tasks, on some tasks a smaller network is sufficient, and leads to lower verification time. At the same time, larger networks often succeed on tasks that otherwise fail, making the "our best" line strictly better than "our (5, 8)". This shows that improvement can be obtained by tuning the width of the hidden layers; note that this analysis considers three additional configurations (i.e, (3, 2), (5, 3), (15, 8)) that adhere to the architecture introduced in Section 3. For the rest of our experiments, we continue using the default architecture.

Figure 5: Solved tasks in terms of state space size and logic gate count (log scale)

   & LS & LCD & Tmcp & i2cS & 7-Seg & PWM & VGA & UARTIt & Delay & Gray & Total \\  Tasks & 16 & 14 & 17 & 20 & 30 & 12 & 10 & 10 & 32 & 33 & 194 \\   ABC & 2 & 3 & 7 & 3 & 8 & 2 & 3 & **10** & 6 & 13 & 57 \\  nuXmv & 8 & 9 & 12 & 10 & 10 & 7 & 3 & **10** & 24 & 24 & 117 \\  our & 15 & **14** & **17** & **18** & **30** & 11 & 0 & **10** & **32** & **33** & 180 \\   Ind. X & **16** & **14** & **17** & **18** & 18 & **12** & **10** & **10** & 19 & 22 & 156 \\  Ind. Y & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\  

Table 1: Number of verification task completed by academic and industrial tool, per design The plot further shows that our tool completes \(93\,\%\) of tasks, outperforming ABC, nuXmv, and industry tool X, which completes \(29\,\%\), \(60\,\%\), and \(80\,\%\), respectively. At any point in the time axis, we compute the difference between the percentage of tasks completed by our tool with each of the others in the figure. Then, taking the average of these differences across the time axis, showing that our method is successful in \(60\,\%\) more tasks than ABC, \(34\,\%\) more than nuXmv, and \(11\,\%\) more than the leading commercial model checker at any given time. Furthermore, the number of tasks completed by nuXmv in \(5\,\) are finished by our tool in less than \(8\,\), and those completed by ABC in \(5\,\) take just under \(3\,\) with our method.

Individual Runtime ComparisonFigure 5(b) presents a scatter plot where each point represents a verification task, with size and brightness indicating the state-space size. Points are plotted horizontally by the lesser of time taken by nuXmv or ABC and vertically by our method's time. The plot reveals that academic tools time out on \(39\,\%\) of tasks, while our method times out on \(7\,\%\). Moreover, we are faster than the academic tools on \(67\,\%\) of tasks, 10 times faster on \(34\,\%\), and 100 times faster on \(4\,\%\). These results demonstrate that we generally outperform the state of the art on this benchmark set (see Appendix 3 for individual runtimes). However, we perform relatively worse on the UARTt design. This design involves an \(N\)-bit register for data storage and a counter for transmitted bits, enabling sequential outputs. Since there is no word-level arithmetic over the \(N\)-bit register, increasing its size minimally affects the complexity of symbolic model checking. Consequently, ABC, nuXmv, and industry tool X complete all UARTt tasks in under a second, while our tool takes a few minutes due to overhead from the sampling, learning, and SMT-check steps, making us slower on trivial model-checking problems.

Learning vs. Checking TimeFigure 5(c) illustrates the time split between learning the neural network--which involves dataset generation and training--and verifying it as a valid ranking function. The lower line indicates learning time; the upper line represents total time, with the gap showing the time spent on SMT checking. Extensive sampling across a broad range of trajectories covering most edge cases led our method to learn the network directly without needing retraining due to counterexamples in the SMT-check phase, except in four tasks. The plot shows that \(93\,\%\) of tasks were trained successfully, generally within five minutes, and remarkably, the \(70\,\%\) were completed in under a minute. For tasks that did not train to zero loss, the \(5\,\) time limit was not fully utilised; the loss function stabilised at local maxima in just a few minutes. Moreover, training was faster than verification on \(97\,\%\) tasks--10 times faster on \(46\,\%\) and 100 times faster on \(6\,\%\).

LimitationsThe primary limitation of our approach arises from the extended SMT-check times and the risk of getting trapped in local minima. Despite these challenges, our method consistently outperforms traditional symbolic model checkers while relying on off-the-shelf SMT solvers and machine learning optimisers. Additionally, our neural architecture requires numerical inputs at the word level, which limits its application to bit-level netlists. This limitation is not high-impact, as modern formal verification tools predominantly utilise Verilog RTL rather than netlist representations.

Threats to ValidityThe experimental results may not generalise to other workloads. As any work that relies on benchmarks, our benchmarks may not be representative for other workloads. We mitigate this threat by selecting extremely common hardware design patterns from the standard literature. We remark that our data sets we use to train the neural nets do not suffer from the common threat of training data bias, and the common out-of-distribution problem: we train our neural net from scratch for each benchmark using randomly generated trajectories, and do not use any pretraining.

Figure 6: Runtime comparison with the state of the art (all times are in log scale)

[MISSING_PAGE_FAIL:10]