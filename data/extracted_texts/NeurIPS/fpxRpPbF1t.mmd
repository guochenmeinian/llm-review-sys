# Differentiable Modal Synthesis for Physical Modeling

of Planar String Sound and Motion Simulation

 Jin Woo Lee

Seoul National University

jinwlee@snu.ac.kr

&Jaehyun Park

Seoul National University

lotussoh@snu.ac.kr

Min Jun Choi

Seoul National University

choimj21@snu.ac.kr

Music and Audio Research Group (MARG), Department of Intelligence and Information

Yahehyun Park

Seoul National University

lotussoh@snu.ac.kr

Michael Jun Choi

Seoul National University

choimj21@snu.ac.kr

&Kyogu Lee

Seoul National University

kglee@snu.ac.kr

Music and Audio Research Group (MARG), Department of Intelligence and Information

Yahehyun Park

Seoul National University

lotussoh@snu.ac.kr

Michael Jun Choi

Seoul National University

choimj21@snu.ac.kr

&Kyogu Lee

Seoul National University

kglee@snu.ac.kr

###### Abstract

While significant advancements have been made in music generation and differentiable sound synthesis within machine learning and computer audition, the simulation of instrument vibration guided by physical laws has been underexplored. To address this gap, we introduce a novel model for simulating the spatio-temporal motion of nonlinear strings, integrating modal synthesis and spectral modeling within a neural network framework. Our model leverages physical properties and fundamental frequencies as inputs, outputting string states across time and space that solve the partial differential equation characterizing the nonlinear string. Empirical evaluations demonstrate that the proposed architecture achieves superior accuracy in string motion simulation compared to existing baseline architectures. The code and demo are available online. 1

## 1 Introduction

The investigation of wave propagation along strings, encompassing both theoretical and experimental dimensions, has persisted for well over a century . In the relentless pursuit of verisimilitude and expressive fidelity in simulating wave phenomena, numerous studies have been investigated to bridge the gap between theoretical underpinnings and empirical sound measurements . Advancements leveraging computational power to mimic the intricate physical processes in musical instruments have given rise to numerical sound synthesis, now a cornerstone in the field of virtual sound synthesis . Schwarz  presents a systematic study of parametric and physical models for music audio synthesis. Parametric models include signal models, such as spectral modeling synthesis . Physical models encompass techniques such as modal synthesis, digital waveguides , or finite-difference time-domain (FDTD) methods .

Over recent years, the advancement of hardware acceleration for artificial intelligence has enabled the emergence of numerous techniques for neural audio synthesis , including autoregressive generation , adversarial training  with phase coherence , and approximated physical models . The concept of differentiable digital signal processing (DDSP) was first introduced by Engel et al. , aiming to incorporate a known signal model into neural networks to achieve a domain-appropriate inductive bias. While the DDSP model can be considered a differentiableversion of spectral modeling synthesis, a wide variety of works have explored the differentiable implementation of other audio signal processing methods, such as the subtractive method , waveshaping , and frequency modulation [19; 20]. Subsequent research has demonstrated various applications of DDSP, including music performance synthesis , speech synthesis and voice conversion [22; 23], and sound effect generation . Renault et al.  extended DDSP to create a polyphonic synthesizer, explicitly modeling properties specific to piano strings, such as inharmonicity and detuning induced by string stiffness, based on a parametric model of these phenomena . This model efficiently synthesizes piano sound from MIDI input, achieving a high mean opinion score on naturalness. However, it still shows room for improvement compared to sampling-based methods  and physical modeling methods .

Despite the growing recognition of DDSP as a promising sound synthesis methodology, its extension to physical modeling remains underexplored. Schlecht et al.  have presented physical modeling using Fourier Neural Operator (FNO). They train recurrent-type FNOs to learn state transitions from data spanning a few initial timesteps in the simulation and then test generalization to the subsequent long-range data. Although they have demonstrated encouraging outcomes, their approach has room for improvement in that it is unconditional, meaning that it is challenging to generalize over dynamic scenarios (_e.g._, glassando, vibrato). In the context of rigid-body contact sound synthesis [30; 31; 32], a few studies investigated the efficacy of training neural networks supervised by finite-element method (FEM) solvers. Jin et al. [33; 34] propose a neural network that predicts contact sounds from voxelized objects, inspired by the modal technique that synthesizes sound using eigenvalues and eigenvectors. Diaz et al.  leverage a differentiable infinite impulse response filter to synthesize contact sounds from rasterized occupancy grids in an end-to-end manner. These methods can interactively synthesize sounds for various contact conditions and materials with notable efficiency, circumventing the need for an offline optimization process typical of modal techniques. However, these methods, which resort to the FEM solver, are vulnerable in modeling the dynamic behavior or in simulating the motion of the object.

In this regard, we propose a novel model for simulating the spatio-temporal motion of nonlinear strings, integrating modal synthesis and spectral modeling within a neural network framework. The proposed model leverages physical properties and fundamental frequencies as inputs, outputting string states across time and space that solve the partial differential equation (PDE) characterizing the nonlinear string. Empirical evaluations demonstrate that the proposed architecture achieves superior accuracy in string motion simulation compared to the baseline architectures. The main contributions are as follows:

* We present differentiable modal synthesis for physical modeling (DMSP) that simulates dynamic nonlinear string motion by synthesizing sound using the physical properties of the string.
* To the best of our knowledge, this is the first differentiable approach that can synthesize the motion and the sound of musical strings with a dynamic control over the pitch and the material properties.
* We provide an extensive empirical evaluation demonstrating the importance of modal decomposition and the proper choice of loss function.

Figure 1: **System overview**. The DMSP model encodes the physical properties of a string (e.g., tension, stiffness, damping, and initial conditions) to estimate the displacement of the string plucked at pitch \(f_{0}\) at a given time \(t[0,)\) and position \(x\). By concatenating the DMSP outputs over the domain \((x,t)[0,)\), the simulated motion of the string can be visualized. Reading the outputs at a particular position \(x\) allows hearing the synthesized string sound, akin to listening with a stethoscope at the pickup position.

Background

### Physical Modeling of Musical String Instrument

**Linear Damped Stiff String.** The string model discussed in this paper is a damped nonlinear stiff string. To introduce the nonlinear string, we first formulate the governing equations for the damped linear stiff string system and derive the corresponding modal solution.

\[_{tt}u=^{2}_{xx}u-^{2}_{xxxx}u-2_{0} _{t}u\] (1)

The linear string of its length \(L\), vibrating with wave speed \(\), stiffness \(\), and frequency-independent damping factor \(_{0}\), is described by Equation 1. Given the initial conditions (IC) for \(x=[-L/2,+L/2]\) as \(u(x,0)=u_{0}(x)\) and \(_{t}u(x,0)=0\), and appropriate boundary conditions (BC), the corresponding solution \(u(x,t)\) represents the motion of a damped linear stiff string. Particularly, for a clamped boundary condition, _i.e._, \(u( L/2,t)=_{x}u( L/2,t)=0\) for all \(t[0,)\), a modal solution can be obtained as follows.

\[u(x,t) =_{n=1}^{}X_{n}(x)T_{n}(t)\] (2a) \[X_{n}(x) =c_{1}(_{n}x-L/2}{_{n}L/2} _{n}x)+c_{2}(_{n}x-L/2}{_{n }L/2}_{n}x)\] (2b) \[T_{n}(t) =e^{-_{0}t}^{4}^{2}+ _{n}^{2}^{2}-_{0}^{2}}}_{_{n}}t\] (2c)

The derivation of Equation 2 can be found in Appendix A. The allowed values of \(_{n}\) and \(_{n}\) are determined by the boundary conditions, while the coefficients \(c_{1}\) and \(c_{2}\) are determined using the initial condition \(_{n=1}^{}X_{n}(x)=u_{0}(x)\). Determining these values typically requires an offline numerical solving process, where the obtained values can be stored in memory for real-time computation of \(u(x,t)\). The stiffness modeled by the 4th order derivative induces a hyperbolic solution, resulting in non-integer multiples of the mode frequencies \(_{n}\), which leads to physical inharmonicity. The damping factor \(_{0}\) causes an exponential decay in the temporal amplitude.

**Nonlinear Damped Stiff String.** The generalization of the linear wave Equation 1 to nonlinear string vibrations is first introduced by Kirchhoff  and Carrier . The Kirchhoff-Carrier system models elastic strings in two dimensions, and when extended so that transverse and longitudinal motions are coupled, phantom partials can be exhibited, resulting in a richer timbre . A model of such planar string vibration is as follows [39; 40].

\[_{tt}u =^{2}_{xx}u-^{2}-1}{2} _{x}(q^{3}+2pq)-^{2}_{xxxx}u-2_{0} _{t}u+2_{1}_{t}_{xx}u\] (3a) \[_{tt} =^{2}^{2}_{xx}-^{2}-1}{2}_{x}(q^{2})-2_{0}_{t}+2_{ 1}_{t}_{xx}\] (3b)

Here, \(u(x,t)\) and \((x,t)\) represent the transverse and longitudinal displacements of a string, respectively, for all \((x,t)[0,)\). \(q=_{x}u\) and \(p=_{x}\) serves as the auxiliary coupling system, as \(_{t}q=_{x}_{t}u\) and \(_{t}p=_{x}_{t}\). A more detailed background on the derivation of Equation 3 can be found in Appendix B. The boundary condition, which may vary depending on the string being modeled, is chosen to be that of the clamped boundary condition:

\[u(x,t)=_{x}u(x,t)=0,(x,t)[0,).\] (4)

Given an initial condition \(u_{0}:=u(x,0)\) defined on \(x\), the solution \(u(x,t)\) associated with the condition of Equation 4 simulates the motion of the string for physical modeling and sound synthesis of string instruments. Due to the coupling between Equation 3a and Equation 3b, the obtained solution exhibits features found in elastic strings, such as pitch glide and phantom partials. These features become more pronounced for larger displacements and are difficult to approach separately as in the linear case. The solution can be approximated through various physical modeling techniques such as finite-difference time-domain , digital waveguides , or functional transformation method .

Figure 2: The planar string system.

**Finite-difference Time-domain.** One straightforward approach to tackling nonlinear PDEs such as Equation 3 would be employing finite difference approximation. This method, commonly known as finite-difference time-domain (FDTD), has a long and distinguished history and is widely accepted in fields such as fluid dynamics  and electromagnetics . FDTD is particularly effective in solving nonlinear, multidimensional, and dynamic systems. The extensive literature on its applications encompasses a diverse range of domains, including musical acoustics . A recent contribution by Lee et al.  introduces StringFDTD-Torch, an FDTD simulator tailored for modeling planar damped stiff strings akin to Equation 3. Leveraging PyTorch C++ extension, StringFDTD-Torch facilitates FDTD computations on both CPUs and GPUs. However, its current iteration lacks support for gradient backpropagation through the FDTD module, leaving room for enhancement, particularly in optimizing the gradient computation process, which is hindered by the substantial number of temporal recursions involved (evident by the large \(N_{t}\) in \((N_{x}N_{t})\) of Table 1).

**Modal Synthesis.** As a more efficient approach to solve the nonlinear wave equations, the modal synthesis [48; 49; 50] decomposes the complex dynamics into contributions from a set of modes, whose spatial bases are eigenfunctions of the pertinent problem. Each mode exhibits distinct oscillations at complex frequencies, contingent upon the boundary conditions. For problems with real-valued parameters, these complex frequencies occur in conjugate pairs, and the "mode" is thus defined as the pair of such eigenfunctions and frequencies . Modal synthesis involves two primary steps. Initially, in an offline phase (also labeled as 'Pre-computation' in Table 1), modal shapes and frequencies are discerned from the PDE system, considering both boundary and initial conditions. This information is encapsulated in what is known as a shape matrix. Subsequently, the solution is derived by combining the modal functions, each progressing at its natural frequency. Pre-computation requires \((N_{m})\) of recursions because \(N_{m}\) shape matrices need to be computed, but a typical \(N_{m}\) is typically hundreds to thousands of times less for \(N_{t}\). Modal synthesis after this off-line process is very efficient as it allows us to obtain a solution for a given \(x\) and \(t\) without any recursion, but it is clear that the range of solutions that can be covered is bounded in that it relies on the ansatz \(u(x,t)=X(x)T(t)\) for the separation of variables.

### Differentiable Digital Signal Processing

In the field of neural networks, numerous audio researchers have been engaged in the development of techniques that leverage the ease of automatic gradient backpropagation in neural networks for the purpose of audio parameter estimation. To address the challenge of estimating the latent parameters of a sound, some approaches implement the synthesis part as-is using automatic differentiation package [20; 47] so that the gradient can back-propagate through it to update the parameters directly, while the majority of approaches train neural networks to estimate the parameters in an auto-encoder framework [16; 22; 51]. As one of the most seminal studies of the latter approach, DDSP is widely used to efficiently synthesize nonlinear and dynamic sounds. Based on the spectral modeling synthesis framework, the time-domain signal is modeled via short-time Fourier transforms (STFTs) divided into deterministic (harmonic) and stochastic (noisy) parts to synthesize the sound. As the causality of STFT frames is modeled through gated recurrent units (GRUs), DDSP requires as many recursions as \(N_{r}\), the number of frames. The harmonics of a DDSP are given by an integer multiple of the fundamental frequency (\(f_{0}\)), and the noise is synthesized from filtered noise. These DDSPs, while still a remarkable advancement, have strong structural constraints on the deterministic part to capture enough perceptually rich tones such as inharmonicity due to stiffness or phantom partials due to nonlinearity. A study by Renault et al.  also points this out, and uses the parametric model  for inharmonicity and detune, but there is room for improvement as it is an approximation model that relies on instrument-specific modifiers rather than reflecting stiffness physics.

    &  &  \\   & Physical & Nonlinear & Differentiable & Pre-computation & Synthesis \\  Modal & ✓ & ✗ & ✗ & \((N_{m})\) & \((1)\) \\ FDTD & ✓ & ✓ & ✗ & N/A & \((N_{x}N_{t})\) \\ DDSP & ✗ & ✓ & ✓ & N/A & \((N_{r})\) \\ 
**DMSP-Hybrid** & ✓ & ✓ & ✓ & \((N_{m})\) & \((1)\) \\
**DMSP** & ✓ & ✓ & ✓ & N/A & \((1)\) \\   

Table 1: Comparison between methods. Computational complexity refers to the inference scenario.

## 3 Differentiable Modal Synthesis for Physical Modeling (DMSP)

This section introduces a novel differentiable nonlinear string sound synthesizer. Table 1 provides a summary of the methods discussed. While modal synthesis stands out for its efficiency, it is solely applicable to linear models and necessitates pre-computation to determine the number of modes denoted as \(N_{m}\). On the other hand, FDTD computes highly nonlinear and dynamic solutions but demands a substantial computational load due to iterative updates across both temporal (\(N_{t}\)) and spatial (\(N_{x}\)) samples. In contrast, differentiable audio processing methods offer efficient nonlinear sound synthesis, typically leveraging a smaller number of frames (\(N_{r}\)) compared to the total time samples (\(N_{t}\)). However, they often lack physical controllability. In this regard, we propose DMSP, which approximates the solution of Equation 3 efficiently by leveraging Equation 2 in the form of neural networks. Figure 1 provides a visual depiction of the DMSP.

### Problem Statement

The objective of this study is to establish a mapping from the parameter space to the solution space, utilizing a finite set of observations comprising parameter-solution pairs from this mapping. We delineate this objective as follows: Consider the partial differential equation depicted in Equation 3, applicable for \((x,t)\) within \([0,)\), with clamped boundary conditions as specified in Equation 4, where \(\) represents a bounded domain in \(^{N_{x}}\). We assume that the solution \(u:[0,)\) resides within the Banach space \(\). For a given PDE parameter \(\) and initial condition \(u_{0}\), let \(:\) denote a nonlinear map, specifically, the FDTD numerical solver tailored to the context of this study. Assume that we are provided with observations \(\{^{(i)},u^{(i)}\}_{i=1}^{N}\), where \(^{(i)}\) comprises independent and identically distributed (i.i.d.) samples drawn from a probability measure supported on \(\), and \(u^{(i)}=(^{(i)})\) potentially contains noise. Our goal is to construct an approximation of \(\) denoted as \(_{}:\), and select parameters \(^{*}^{N_{}}\) such that \(_{^{*}}\). Leveraging \(_{}\), one can compute the solution \(=_{}()\) corresponding to a new parameter \(\). By specifying values for \(x\) and \(t\), one can then either synthesize the sound of the string picked-up (also referred to as read-out) at a specific location \(x_{0}\) as \((x_{0},t)\), or simulate the motion of the string by concatenating \((x,t)\) across all \(x\). In practice, \(\) and \([0,)\) are bounded and discretized to form an evenly distributed spatio-temporal grid as \(^{N_{x}}^{N_{i}}[0,)\), where the spatial grid samples are uniformly distributed in space according to the length of the equally spaced intervals \(L/N_{x}\) and the temporal grid samples uniformly distributed according to the frequency of a fixed audio sampling rate.

Figure 3: **Network architecture**. DMSP synthesizes a pitch skeleton with an inharmonic structure, drawing upon overtones derived from the modes of the string. The modes can either be derived directly using the modal decomposition (DMSP-Hybrid, the hybrid of DMSP and Modal), or using the neural network trained to estimate the modes (DMSP, the fully-neural-network method). Yet, relying solely on modal frequencies and corresponding shape functions delineates a linear solution, which falls short of capturing the nuances of nonlinear string motion. To address this, DMSP introduces FM and AM blocks to modulate the modes of the linear solution. This modulation process enables DMSP to estimate the pitch skeleton of the nonlinear solution. Consequently, the output waveform is synthesized through the spectral modeling pipeline, incorporating both (in)harmonic components and the filtered noise.

### Network Architecture

**Parameter Encoder.** To effectively capture material features inherent in the PDE parameter values, the parameter encoder leverages a random Fourier feature (RFF) layer [52; 53]. Given T60 frequencies \(f_{}^{(i)}\) and their corresponding times \(t_{}^{(i)}\) for \(i=1,2\), the frequency-dependent damping coefficients \(_{0}\) (and \(_{1}\), if applicable) are derived using Equation 24. The frequency-independent damping factor \((-_{0}t)\) is computed explicitly multiplied by the mode amplitudes. All PDE parameters \(=\{,,_{0},_{1}\}^{4}\) are encoded into a feature vector \(h^{4 d}\) with a Fourier embedding size of \(d=256\).

**AM and FM Blocks.** As illustrated in Figure 3, DMSP employs amplitude modulation (AM) and frequency modulation (FM) modules 5 to modulate the mode frequencies and amplitudes of the linear solution, as depicted in Equation 2, to synthesize the solution of the nonlinear wave described in Equation 3. We utilize two multilayer perceptrons (MLPs) for the modulation layers. Although a simpler and perhaps more conventional choice of architecture would be a GRU, to the decoder architecture of DDSP , we choose MLPs for their slightly better empirical results. It's noteworthy that DDSP decodes the sinusoidal frequency envelope with fixed frequency values. In contrast, DMSP decodes both the envelope and the frequency values independently, employing two distinct MLP blocks, namely AM and FM.

**Mode Estimator.** As detailed in subsection 2.1, determining allowed values for mode frequencies and amplitudes, corresponding to specific initial and boundary conditions of the string, typically involves a root-finding process conducted offline. While these numerical solvers offer high accuracy up to a specified iterative threshold, they necessitate pre-computation, as illustrated in Table 1. The mode estimator module within DMSP estimates the modes from the initial condition using an MLP. The initial condition is parameterized by a pluck position \(p_{x}\) and its peak amplitude \(p_{}\). Subsequently, the physical properties \(\), \(\), \(_{0}\), and \(_{1}\) are encoded using a random Fourier feature (RFF) layer. The mode frequencies and amplitudes are then estimated by the MLP, followed by the application of suitable scaling activations. It's pertinent to note that the mode estimator operates independently and is trained separately from the other modules. During training, the ground truth modes (computed using the modal decomposition method) are fed into the AM and FM blocks, ensuring accurate synthesis while training the synthesis part of the model.

### Loss Function

We employ a combination of four loss terms: (1) waveform \(_{1}\) loss (\(_{1}\)) that measures the \(L_{1}\) discrepancy between the synthesized waveform and the ground truth waveform, (2) Multi-scale spectral (MSS) loss that captures spectral differences across multiple scales, ensuring fidelity in spectral representation, (3) Pitch loss (\(_{f_{0}}\)) that penalizes deviations from the ground truth fundamental frequency (\(f_{0}\)), and (4) Mode loss (\(_{m}\)), which measures the \(L_{1}\) distance of the mode frequency and mode amplitude from the output of the mode estimator (if applicable) and the mode frequency and mode amplitude obtained via modal decomposition. MSS loss has been adopted as a metric for reconstruction in most neural net-based synthesis techniques [11; 16; 21]. Concerning that measuring MSS with magnitudes is not phase-sensitive by definition, we employ the \(_{1}\) loss in the waveform to train the causality in spatio-temporal wave propagations. Challenges in optimizing the frequency parameters of sinusoidal oscillators via gradient descent over the spectral loss functions, due to the non-convex nature of the optimization problem, have been highlighted in various studies [54; 55]. Damped sinusoids offer a workaround for the issue of non-convexity concerning frequency parameters , or alternative metrics are proposed to mitigate the risk of falling into bad local minima [56; 57]. We adopt a parameter regression joint training strategy, akin to the pre-training phase of the work by Engel et al. . Among the output mode frequencies, we train the model to match one mode frequency component (denoted by \(_{0}\)) to match the fundamental frequency of the target FDTD-simulated audio (\(f_{0}\)) annotated using CREPE  as \(_{f_{0}}=\|_{0}-f_{0}\|_{1}\).

## 4 Experiments

### Experimental Setup

**Dataset.** We use the StringFDTD-Torch , the open-source nonlinear string simulator, to compute the solution of the Equation 3 in a temporal sampling rate of 48 kHz and a spatial sampling rate. The solution is upsampled to a spatial resolution of 256 using a bivariate spline approximation over a rectangular spatio-temporal mesh upto the 5th order degree. We simulate 10263 different strings by randomly augmenting the material properties, _e.g._, \(\), \(\), \(_{0}\), and \(_{1}\), with various plucking profiles \(u_{0}\). The simulation results in a total amount of 729.8 hours of wave files that corresponds to the 1-see string sounds picked up at 256 different positions for each string. For the test data, 715 strings are newly synthesized with the parameters sampled in i.i.d. The test data consists of 336 linear (\(=1\)) and 379 nonlinear (\(>1\)) strings, each of which has a 256 spatial grid size, resulting in approximately 50 hours of wave files. Table 5 specifies the range of the sampled PDE parameters.

**Baselines.** Table 2 compares the major differences between the baselines and the proposed models. As the first attempt to tackle the task of neural audio synthesis for dynamic physical properties, we compare our proposed model to three other models. We consider three baselines, namely: Modal and DDSPish, and DDSPish-xfm. Modal synthesis is the linear wave solution as in Equation 1, where the modal frequencies and the shape functions are pre-computed. DDSPish is a neural network based on the harmonic plus noise model, similar to DDSP. Yet, this -ish suffix emphasizes that this model is different from the DDSP model . DDSPish does not have a reverb module but instead adds frequency modulation, and most notably it has a parameter encoder that allows generating sounds from physical parameters. Please see Appendix D for more details of the baselines.

**Evaluation Metrics.** We report results on three metrics, signal-distortion-ratio (SDR), scale-invariant signal-distortion-ratio (SI-SDR) , multi-scale spectral (MSS) distance, and the pitch difference in Hz. As with the problem statement, we consider the FDTD-simulated results as the ground truth (GT). Both SDR and SI-SDR estimate the distortions on a spatiotemporal grid and are very strict about scoring out-of-phase cases, by directly comparing the the estimated displacements to the FDTD results without any specific transformations or interpolations. Given that the magnitudes of the estimated displacements typically distribute within the small range (approximately between \( 0.02;\) depends on the pluck amplitude \(p_{a}\), see Table 5), we compare both with scale normalization (SI-SDR) and without (SDR). The MSS metric for the evaluation is computed using the short-time Fourier transformation (STFT) with three scales of Fast Fourier Transform (FFT) points: 1024, 512, and 256, with a window length equal to the FFT point for each, and a hop length equal to a quarter of that. For each scale, the STFT magnitude is compared on both linear and log scales, weighted by 2.0 and 0.5, respectively. This choice of weighting is to help scale the loss computation with MSS and should not have a significant impact on performance, but is important to note for absolute comparisons of MSS scores. The Pitch metric is computed as the \(^{1}\) norm of the difference between \(_{0}\) and \(f_{0}\).

### Results

**Differentiable Sound Synthesis.** The efficacy of DMSP is studied as shown in Table 3. First, the modal synthesis method calculates a linear solution for a damped stiff string, and the mode for the linear test set is calculated offline. The discrepancy between the outcomes of modal synthesis and FDTD in the linear case can be attributed to the absence of frequency-dependent damping in Equation 1. In other words, the frequency information serves as an oracle for the Modal, as evidenced by its lowest pitch score, but the decay of amplitude over time is not sufficiently modeled, which is where the remaining models demonstrate superior performance. Considering the DDSPish models,

    &  &  &  \\   & & AM block & FM block & \(_{1}\) & MSS & \(_{f_{0}}\) & \(_{m}\) \\  Modal & Mode frequency & ✗ & ✗ & N/A & N/A & N/A & N/A \\ DDSPish-xfm & Integer multiples & ✓ & ✗ & ✓ & ✓ & ✗ & ✗ \\ DDSPish & Integer multiples & ✓ & ✓ & ✓ & ✓ & ✗ & ✗ \\ 
**DMSP-Hybrid** & Mode frequency & ✓ & ✓ & ✓ & ✓ & ✓ & ✗ \\
**DMSP** & Learnt estimates & ✓ & ✓ & ✓ & ✓ & ✓ & ✓ \\   

Table 2: Comparison between the baselines and the proposed models.

the MSS is approximately 1.6 dB ahead of the DMSPs, but the difference can reach up to 44 dB in the case of the SI-SDR. It is worth noting that \(\) is uniformly sampled within the range \((1,25)\) for the training data, falling into the category of the nonlinear strings. Information about the ranges for sampling PDE parameters is in Table 5. In the case of the nonlinear test set, the difference between the modal solution and the FDTD solution becomes larger. On the other hand, DDSPish models, which are based on spectral modeling synthesis but learned without using any modal information, show the lowest performance. The superiority of DMSP is even more pronounced in the nonlinear case. While Modal, which can only cover the solution to the linear case, shows attenuated performance, the DMSPs demonstrate the best performance in all metrics. In particular, DMSP-Hybrid, which precomputes the mode frequency like Modal, performs FM and AM for the nonlinear solution, showing an SI-SDR improvement of nearly 31 dB and an MSS improvement of nearly 13 dB over Modal. DMSP, which estimates the mode as a neural network without the pre-computation step, also outperforms Modal on all metrics for the nonlinear case. The primary reason for the performance discrepancy between the nonlinear case and the linear case for DMSP is that the training data is rarely precisely equal to \(1\) in the \(\) distribution when it is sampled.

**Controllable Physical Simulation.** The quantitative scores for various physical condition parameters are visualized in Figure 5. Trends show how the results of Modal synthesis and DMSP vary for different pickup positions (\(x\)), stiffness (\(\)), tension (\(\)), pluck amplitude (\(p_{a}\)), and pluck position (\(p_{x}\)). Of these, \(\) and \(p_{a}\) in particular are known to increase the nonlinearity of the string as they increase in magnitude, which can be seen by the lower Modal synthesis scores. For DMSP, we see an overall improvement in the score, with a lower propensity for nonlinearity. Figure 4 depicts the simulated state of the string as the pluck position in the initial condition is varied. The results synthesized by DMSP can reconstruct a very accurate initial condition, similar to the results simulated by FDTD. The vibration propagating through time along the string exhibits a distinct behavior contingent upon the initial condition. FDTD employs a recursive calculation of displacement, necessitating some iterations equal to the number of samples at the audio sampling rate. In contrast, DMSP is capable of obtaining the desired displacement in both time and space simultaneously.

Figure 4: Visualization of the string displacement over time (horizontal) and space (vertical). For different initial conditions, the results synthesized by DMSP are shown as solid black lines and those simulated by FDTD as dashed gray lines.

Figure 5: Objective scores over the change of physical parameters.

    &  &  \\ 
**Model** & **SI-SDR** & **SDR** & **MSS** & **Pitch** & **SI-SDR** & **SDR** & **MSS** & **Pitch** \\  & (dB, \(\)) & (dB, \(\)) & (dB, \(\)) & (Hz, \(\)) & (dB, \(\)) & (dB, \(\)) & (dB, \(\)) & (Hz, \(\)) \\  Modal & \(-\)3.191 & 0.681 & 18.449 & **0.420** & \(-\)16.611 & \(-\)1.900 & 17.254 & 2.316 \\ DDSPish & \(-\)39.478 & \(-\)2.598 & 11.047 & 5.518 & \(-\)25.951 & \(-\)2.102 & 9.745 & 3.306 \\ DDSPish-xfm & \(-\)46.609 & \(-\)2.257 & **10.911** & 11.304 & \(-\)46.858 & \(-\)2.272 & 10.299 & 14.013 \\ 
**DMSOP-Hybrid** & \(\) & **1.496** & 12.525 & 0.792 & **15.670** & **16.455** & **4.772** & 1.027 \\
**DMSOP** & \(-\)22.298 & \(-\)2.000 & 12.504 & 1.717 & \(-\)10.315 & 0.221 & 5.656 & **1.437** \\   

Table 3: Synthesis Results

**String Sound Synthesis.** Spectrograms of the test samples are visualized in Figure 6 and Figure 7. For the spectrograms, the instantaneous frequencies are identified in a rainbow color map, where the color intensities represent the logarithmic magnitude of the power spectra. Observing from Figure 6, the FDTD-simulated spectrogram clearly shows pitch glide and phantom partials at the beginning of the pluck. In contrast, modal synthesis methods that model linear solutions do not show these nonlinear characteristics. The DDSPish-xrm model employs a harmonic pitch skeleton comprising integer multiples of \(f_{0}\), thereby precluding the inhomogeneities resulting from stiffness. The DDSPish model demonstrates enhanced mode estimation capabilities through learned FM, which modulates the harmonic pitch skeleton to be inharmonic. However, there is scope for further improvement in frequency estimation, particularly in instances where the FM learning process is unstable for high frequencies. On the other hand, the DMSP model, which estimates the mode frequency and amplitude from \(u_{0}\), shows an improved pitch skeleton and stable frequency estimation. The DMSP-Hybrid model, which learns to AM and FM the sinusoidal oscillators of the modal solution that requires mode precomputation, shows the most similar results to FDTD.

Figure 7 shows a similar trend for the spectrograms. In this example, however, we reveal a key difference that is not apparent in the spectrograms, but is very important for physical modeling: It is the measure of displacement to space, namely the state plot. The timestep for the state plot can be arbitrary, but we show the initial state for ease of comparison. For methods that do not have a separate method for accurately predicting the mode information, unlike DMSP, difficulties can be found in accurately predicting the state. This partially explains the SI-SDR scores for DDSPish and DDSPish-xrm in Table 3. Considering that the major difference between DMSP and DDSPish is whether the input frequency of the FM block is the mode frequency or an integer multiple, it can be inferred that accurately estimating the mode frequency is critical from a physical modeling perspective to fit the displacement of the strings over time.

**Ablation Study.** The ablation study on the choice of the training loss functions is presented in Table 4. Overall, for linear strings, the performance does not vary much depending on which loss is used, especially for pitch. This is due to a gating applied to the FM block, which is designed to prevent FM from occurring when \(\) is 1. More specifically, we apply a gating, _e.g._, \((-1)\), in such a way that frequency modulation only occurs when the value of \(\) deviates from 1, which can directly affect pitch, and otherwise forces the mode estimation result to be used as is. This is the main factor that determines the nonlinearity of the string. For AM, there is no such masking depending on \(\), so the remaining metrics except pitch do vary. For nonlinear data, the training results vary depending on the

Figure 6: Spectrogram of the synthesized samples on the test set.

Figure 7: Spectrograms and state samples of the synthesized samples on the test set. For the spectrograms shown in the first column, the intensity of the frequency (vertical axis) component for time (horizontal axis) is expressed as brightness, and for the states shown in the second column, the displacement (vertical axis) for space (horizontal axis).

loss design. In particular, for all metrics, using \(_{f_{0}}\) loss significantly improved performance over not using it. This difference is especially noticeable in the MSS scores between DMSP-Hybrid w.o. \(_{f_{0}}\) and DMSP, where DMSP even gives better results over the model that uses precomputed mode frequencies for nonlinear MSS scores if \(_{f_{0}}\) is applied. This result reaffirms the validity of the FM block for nonlinear strings in terms of predicting dynamically varying frequencies such as pitch glide and shows that \(_{f_{0}}\) loss is the loss function to train it effectively.

**Motion Synthesis.** The main advantage of DMSP, compared to the existing sound synthesis models, is that it can synthesize not only sound but also motion, which is one of the main characteristics of physical modeling techniques. In particular, the DMSP can visualize the corresponding string motion as a video, although the receptive field and computational complexity required to obtain a solution \(u(x,t)\) for a single spatio-temporal point is of order 1, as shown in Table 1, when these solutions are pooled for a given \(x\) and \(t[0,1)\), the corresponding string motion can be visualized as a video. Figure 8 visualizes the resulting transverse displacement of the string over time (horizontal axis) and space (vertical axis). The transverse displacement of the FDTD is coupled to the longitudinal motion, which is why it differs from the Modal synthesis output, which synthesizes the motion of a linear damped stiff string. The results output by DMSP show improved accuracy.

## 5 Conclusion

We present a novel neural network-based method that efficiently simulates plucked string motions. Our differentiable modal synthesis for physical modeling (DMSP) can simulate a dynamic nonlinear string motion by synthesizing the sound using the physical properties of the string. It is an efficient approximation of existing physical modeling methods. We demonstrate the efficacy of training the neural network using mode frequency information by extending the DDSP with a modal synthesis pipeline. This opens the door to a new field of differentiable audio signal processing, extending it to the field of physical modeling for musical sound synthesis. While the proposed method offers control over several physical parameters of a musical instrument, it still faces limitations in terms of generalizing to physical parameters and sounds in real-world measurements. This study paves the way for future research in this area. To the best of our knowledge, this is the first study to simultaneously synthesize sound and motion from the properties of a stringed instrument.

    &  &  \\ 
**Model** & **SI-SDR** & **SDR** & **MSS** & **Pitch** & **SI-SDR** & **SDR** & **MSS** & **Pitch** \\  & (dB, \(\)) & (dB, \(\)) & (dB, \(\)) & (Hz, \(\)) & (dB, \(\)) & (dB, \(\)) & (dB, \(\)) & (dB, \(\)) & (Hz, \(\)) \\ 
**DMSP-Hybrid** & –2.844 & 1.496 & 12.525 & 0.792 & 15.670 & 16.455 & 4.772 & 1.027 \\ w.o. \(_{f_{0}}\) & –2.919 & 0.774 & 13.487 & 0.792 & –5.418 & 1.509 & 8.983 & 2.653 \\ 
**DMSP** & –22.298 & –2.000 & 12.504 & 1.717 & –10.315 & 0.221 & 5.656 & 1.437 \\ w.o. \(_{f_{0}}\) & –21.351 & –2.699 & 13.482 & 1.717 & –16.435 & –1.074 & 9.060 & 2.922 \\   

Table 4: Ablation Study

Figure 8: Simulated string state visualization.