# Learning to Predict Structural Vibrations

Jan van Delden

Julius Schultz

Institute of Computer Science, University of Gottingen

Christopher Blech

Institute for Acoustics and Dynamics, Technische Universitat Braunschweig

Sabine C. Langer

Institute for Acoustics and Dynamics, Technische Universitat Braunschweig

Timo Luddecke

Institute of Computer Science, University of Gottingen

###### Abstract

In mechanical structures like airplanes, cars and houses, noise is generated and transmitted through vibrations. To take measures to reduce this noise, vibrations need to be simulated with expensive numerical computations. Deep learning surrogate models present a promising alternative to classical numerical simulations as they can be evaluated magnitudes faster, while trading-off accuracy. To quantify such trade-offs systematically and foster the development of methods, we present a benchmark on the task of predicting the vibration of harmonically excited plates. The benchmark features a total of 12,000 plate geometries with varying forms of beadings, material, boundary conditions, load position and sizes with associated numerical solutions. To address the benchmark task, we propose a new network architecture, named Frequency-Query Operator, which predicts vibration patterns of plate geometries given a specific excitation frequency. Applying principles from operator learning and implicit models for shape encoding, our approach effectively addresses the prediction of highly variable frequency response functions occurring in dynamic systems. To quantify the prediction quality, we introduce a set of evaluation metrics and evaluate the method on our vibrating-plates benchmark. Our method outperforms Deep-ONets, Fourier Neural Operators and more traditional neural network architectures and can be used for design optimization. Code, dataset and visualizations: https://github.com/ecker-lab/Learning_Vibrating_Plates

## 1 Introduction

Humans are exposed to noise in everyday life, which is unpleasant and unhealthy in the long term . Therefore, designers and engineers work on reducing noise that occurs, for example, in cars, airplanes, and houses. In this work, we specifically consider vibrations in mechanical structures as a source of sound. Vibrating structures radiate sound into the surrounding air. For example in a car, the engine causes the chassis to vibrate, which then radiates sound into the interior of the car. By reducing the vibration energy of the chassis, the noise can be reduced.

Vibrations of mechanical structures depend on the frequency of the excitation force (e.g. by the engine). A special case occurs when the excitation frequency matches an eigenfrequency of a given structure. In this case, the external force adds energy in phase with the structure's natural vibration and amplifies the motion with each cycle. This continues until the energy added equals the energy lost due to damping, resulting in large vibration amplitudes. This effect is called resonance and leads to characteristic resonance peaks in the dynamic response of the system. At resonance frequencies, due to the higher vibration amplitudes, more noise is emitted. A second distinctive feature of structural vibrations is the vibration pattern, i.e. the spatial field of vibration velocity amplitudes. With increasing frequency, these vibration patterns become more complex and exhibit more local maxima and minima (Figure 1, left) .

To reduce noise, the vibration patterns of a mechanical structure can be influenced through modifications to its design. One method is the placement of damping elements, that absorb vibrational energy and thereby reduce sound emission, but this adds weight and requires space. Another approach is introducing beadings, which are indentations in plate-like structures (Figure 1, right). Beadings increase the local stiffness of a structure, resulting in a shift in the structure's eigenfrequencies and subsequent resonance peaks. When they are well-placed, beadings can reduce the vibration energy for a range of excitation frequencies by shifting the resonance peaks out of the range. Reducing the vibration energy for a specific range of frequencies is a goal in many applications, e.g. in automotive design, where a motor excites vibrations in a range of frequencies .

In this work, we focus on a crucial prerequisite for targeted modifications to a design: Computing its vibrational behavior. The finite element method (FEM) is an established approach for numerically solving partial differential equations. The geometry of a design is discretized into small elements and the solution of the PDE is approximated by simple functions, e.g. polynomial functions, defined on these elements. . This method enables the numerical simulation of vibration patterns, but is computationally expensive. With increasing frequency and decreasing wavelength, finer meshes are required to accurately resolve the vibrations. This leads to a high increase in computational load and limits the number of designs and value of the frequencies that can be evaluated. Deep learning surrogate models could accelerate the evaluation of design candidates by several magnitudes.

Related work on predicting the solution of partial differential equations with deep learning has mostly focused on time-domain problems [e.g. 6, 7, 8]. In contrast, for our problem the change over time is not of interest. Instead, we predict steady-state vibration patterns in the frequency domain. Steady-state refers to the fact that the system vibrates harmonically and the amplitude and frequency remain constant over time since the system is in a dynamic equilibrium. Despite being practically relevant in acoustics and structural dynamics in general this problem is so far under-explored by machine learning research.

Contributions.To explore the potential of vibration prediction with deep learning methods, we (1) introduce a benchmark and define evaluation metrics on it, (2) evaluate a range of machine learning methods on the benchmark and (3) introduce our own method.

Our novel benchmark dataset consists of 12,000 instances of an exemplary structural mechanical system, a plate excited by a harmonic force, and their numerically computed vibrations given a range of excitation frequencies. Given a plate instance, the task is to predict the vibration patterns and frequency response. We vary material properties and the boundary conditions of the plate as well as the geometry by adding beadings. Plates with beadings are abundant in technical systems

Figure 1: Left: We introduce the Vibrating Plates dataset of 12,000 samples for predicting vibration patterns based on plate geometries. A harmonic force excites the plates, causing them to vibrate. The vibration patterns of the plates are obtained through numerical simulation. Diverse architectures are evaluated on the dataset. Right: Beadings are indentations and used in many vibrating technical systems. Here, on an oil filter, a washing machine and a disk drive. They increase the structural stiffness and alter the vibration.

(Figure 1, right). Plates are also often a component of more complex mechanical systems and their vibrational behavior on their own is similar to more complex systems [9; 10], making them a well-posed and scalable initial benchmark problem for deep learning methods.

To address the benchmark task, we propose a novel network architecture named Frequency-Query Operator (FQO). This model is trained to predict the resulting vibration pattern from plate geometries together with an excitation frequency query. This approach is inspired by work on operator learning for predicting the solution to partial differential equations  and implicit models for shape representation [e.g. 12; 13; 14], both techniques enable evaluating any point in the domain instead of a fixed grid. In our case, this enables predictions for any excitation frequency, including those not seen during training. On our vibrating-plates benchmark, the proposed FQO can accurately predict the highly variable resonances occurring in vibration patterns and outperforms DeepONet , Fourier Neural Operators  and other baselines.

## 2 Dataset and Benchmark Construction

### Vibrating Plates Dataset

We introduce a dataset consisting of instances of aluminum plate geometries and their vibration patterns. The plates are simply supported, i.e. the edges cannot move up and down. Depending on the dataset setting, the rotational stiffness at the boundary is varied, which corresponds to free rotation or clamped edges. The plate is excited by a harmonic point force at varying positions with the excitation frequency varied between 1 and 300 Hz. While the specific setting in other mechanical engineering design tasks may differ, this setup functions as an exemplary engineering design problem. Analogous problems are the design of an air-conditioning enclosure , a washing machine  or parts of a car chassis . Compared to these problems, our plate setup has two differences that allow for a comparatively easy experimental real world validation of the computed vibration patterns and do not change typical vibrational characteristics: First, exciting the plate with a point force is a common experimental setup, where a plate is excited via a shaker. Second, the condition of no rotational stiffness at the edges in comparison to clamped edges does not introduce additional uncertainty and parameters into the measurement and mirrors e.g. a bonnet of a car that rests on the chassis. Other typical types of fixation include screws or welding. In the following, we describe the specific quantity of interest of the vibration patterns, how the vibration patterns of the plate are obtained via numerical simulation and how the plate geometry and parameters are varied.

Vibration patterns and frequency response function.Our benchmark is designed to address a vibroacoustic engineering design problem. Therefore, the goal is to predict a quantity that best reflects the noise emitted by a mechanical structure. For a plate, a natural choice is the maximum velocity field \(v_{z}(x,y|f)\) for a specific frequency \(f\). Here, \(v_{z}(x,y|f)\) represents the component of the velocity field orthogonal to the plate surface (in the following \((f)\) denotes the velocity field on the discrete grid). This component closely relates to how much sound is radiated, but specific details about where the velocity on the plate is highest are superfluous. Therefore, we use the mean of the squared velocity as a more compact representation and express it in a frequency response function \(\), which is a function of the excitation frequency:

\[(f)=10_{10}(_{A}v_{z}(x,y|f)^{2}\,dA)\] (1)

The square velocity is proportional to the kinetic energy and is therefore closely related to how strongly the vibration couples into a surrounding fluid and can then be perceived as airborne sound. In the above expression, \(A\) is the plate area over which the velocity is averaged. The result is scaled by a reference value \(r\) and converted to a decibel scale.

Numerical simulation.Historically, plate structures have been the subject of intense research regarding their vibrational behavior [e.g. 18; 19]. A common approach in plate modeling is to reduce the model to a two-dimensional problem with the goal to accurately describe the vibrational behavior while being computationally efficient . To model the vibrational behavior of plates in this work, we use a shell formulation based on Mindlin's plate theory . This theory is applicable for moderately thin plates and represents the plate using a mid-plane with constant thickness. Mindlin s plate theory is a standard choice in many engineering applications and has been experimentally validated .

We apply the finite element method to solve the shell formulation and simulate the vibrational behavior of the plate  (Figure 2). This involves partitioning the plate geometry into discrete elements and approximating the solution on these elements by simple ansatzfunctions. By choosing a sufficiently large number of elements, the solution converges to the exact solution of the model . We discretize the plate with a regular grid and use triangular elements in the domain to allow a flexible representation of beadings. The discretization is sufficient to resolve wave lengths in the plate structure, but limits the detail that can be represented with the beading patterns. After discretizing the plate, the PDE is integrated over the elements and a linear system of equations is derived. This linear system describes the dynamics of the discretized structure and is solved with a direct solver. We perform the computations with a specialized FEM software for acoustics . Further details on the setup and mechanical model are given in Appendix A.1.

Dataset variations.The plate instances are varied in two settings: For the V-5000 setting, we generate random heading patterns consisting of 1 - 3 lines and 0 - 2 ellipses. Also, the width of the heading-elements is randomly varied. The size of the plates as well as material, boundary and loading parameters are fixed. For the G-5000 setting, we apply the same leading pattern variation and additionally vary the plate geometry (length, width and thickness) as well as the damping loss factor, rotational stiffness at the boundary and forcing position. For each setting, 5000 instances for training and validation are generated. 1000 further instances are generated as a test set and are not used during training or to select a model. Further details are given in Appendix A.2.

Dataset analysis.The mean plate design shows a close to uniform distribution, with a margin at the plate's edge (see Figure 2(b)). With a greater proportion of beaded area in a given plate, the number of peaks tends to decrease (see Figure 2(a)). This is due to additional beadings stiffening the plates, and it represents an interesting trait specific to our problem. The density of peaks is related to the frequency. As the frequency increases, so does the peak density. Starting from around 120 Hz the peak density plateaus (see Figure 2(d)). The average number of peaks in the G-5000 setting is smaller than in the V-5000 setting. This is influenced by the on average smaller plates being stiffer and therefore having less peaks in the frequency range (see Figure 2(c)).

### Evaluation

Before computing our metrics, we perform the following preprocessing steps to address numerical issues as well as facilitate an easier interpretation of the evaluation metrics. We normalize the fre

Figure 3: Dataset analysis. (a) shows two discretized plate geometries with their corresponding frequency response, the red crosses mark the detected peaks. (b) shows the mean plate design and frequency response. (c) shows number of peaks in different dataset settings. (d) shows the distribution of the peaks over the frequencies.

Figure 2: Process of the finite element solution in frequency domain in order to compute the velocity field at each frequency query.

quency response and the velocity fields. To do this, we first take the log of the velocity fields, to align it with the dB-scale of the frequency response. Then, we subtract the mean per frequency over all samples (depicted in Figure 2(b) for frequency response) and then divide by the overall standard deviation across all frequencies and samples. Small changes in the leading pattern can cause frequency shifts, potentially pushing peaks out of the considered frequency band. To reduce the effect of such edge cases, we predict frequency responses between 1 and 300 Hz but evaluate on the frequency band between 1 and 250 Hz.

We propose three complementary metrics to measure the quality of the frequency response predictions.

Mean squared error.The _mean squared error (MSE)_ is a well-known regression error measure: For the global deviation we compare the predicted \(}(f)\) and numerically computed frequency response \((f)\) by the MSE error \(_{}=_{i}(}(f_{i})-(f_{i}) )^{2}\).

Earth mover distance.The _earth mover distance_ expresses the work needed to transmute a distribution \(P\) into another distribution \(Q\). As a first step, the optimal flow \(\) is identified. Based on \(\) the earth mover distance is expressed as follows:

\[_{}(P,Q)=_{ij} d_{ij}}{ _{i,j}_{ij}}=_{}_{i,j}_{ij} d_{ij}\]

where \(d_{ij}\) is the distance between bins \(i\) and \(j\) in \(P\) and \(Q\). Correspondingly, \(_{ij}\) is the flow between bins i and j. We calculate the \(_{}\) based on the original amplitudes in \(m/s\) that have not been transformed to the log-scale (dB) and normalize these amplitudes with the sum over all frequencies. As a consequence and unlike the MSE, \(_{}\) is invariant to the mean amplitude and only considers the shape of the frequency response. In this form, our metric is equivalent to the \(W_{1}\) Wasserstein metric .

Peak frequency error.To specifically address the prediction of resonance peaks, which are particularly relevant for noise emission, we introduce a third metric called _peak frequency error_. The metric answers two questions: (1) Does the predicted frequency response contain the same number of resonance peaks as the true response? (2) How far are corresponding ground truth and prediction peaks shifted against each other? To this end, we set up an algorithm that starts by detecting a set of peaks \(K\) in the ground truth and a set of peaks \(\) in the prediction using the find_peaks function in scipy  (examples in Appendix B). Then, we match these peaks pairwise using the Hungarian algorithm  based on the distance between the frequencies of the peaks \(_{}\). This allows us to determine the ratio between predicted and actual peaks \(|}{|K|}\) and \(\). To equally penalize predicting too many and too few peaks we consider the minimum of both ratios: \(_{}=1-\{|}{|K|},|}{| |}\}\).

## 3 Predicting Vibrations with Neural Networks

We propose a method to predict the frequency response, \(_{,}(f)\), for plates characterized by their geometry \(\) (influenced by leading patterns) and scalar parameters \(\) (height, width, thickness, damping loss factor, rotational stiffness at boundary, loading position). This process involves two steps: (1) First, the input \(\) and \(\) are encoded by an encoder \(\). Because \(\) is defined on a regular grid, standard image processing architectures are suitable. (2) Frequency response predictions are generated for specific excitation frequencies \(f\) by a decoder \(\) (Figure 4). The computation can then be expressed as:

\[((,),f)=}_{,} (f)\] (2)

This problem formulation, training a neural network to predict a function and evaluating this function, given some input values, is a common paradigm in operator learning . It allows for the evaluation of any frequency query \(f\), even if it has not been part of the training data. In contrast, predicting frequencies on a fixed grid only allows for the evaluation of those frequencies. This formulation shares similarities with implicit models, for instance by  in the context of 3d shape prediction. Based on this, we investigate the following central aspects of our architecture:

**Q1 - Frequency-query approach:** Vibrations are dominated by resonance peaks at specific frequencies. The resonance frequencies vary strongly across instances. An implicit or operator learning approach has been shown to be able to deal with high variation better in other contexts. In the context of vibration prediction, a frequency-query approach could be employed to generate predictions for one specific frequency.

**Q2 - ViT encoder:** Image processing architectures based on convolutions encode local features. In contrast, vision transformers have a global receptive field size from early layers. As vibrations are determined by the full geometry, we expect vision transformers to perform better.

**Q3 - Velocity field prediction:** We can train networks to either directly predict the aggregate frequency response \(\) or to predict the velocity field \(\) and compute \(\) from \(\) via Equation 1. For predicting the velocity field, much richer training data is available, since it describes a field over the plate instead of the scalar frequency response. Most of this information is not represented in the frequency response.

In the following, we describe architectural variations explored for these aspects.

### Geometry Encoder \(\)

To parse the plate geometry into a feature vector, we employ three variants: ResNet18 , a vision transformer [32, 33, ViT] and the encoder part of a UNet . For the RN18, we replace batch normalization with layer normalization , as we found this to work substantially better. Compared to the CNN-based RN18, the ViT architecture supports interactions across different image regions in early layers. For both, the RN18 and the ViT encoder, we obtain a feature vector \(\) by average pooling the last feature map. Since the UNet generates velocity fields, no pooling is applied.

**FiLM conditioning.** For including the scalar parameters \(\), we introduce a film layer . The film layer first encodes the scalar parameters with a linear layer. The resulting encoding is then multiplied element-wise with the feature of the encoder and a bias is added. This operation is applied before the last layer of the geometry encoder (UNet) or after it (RN18, ViT).

### Decoder \(\)

**FQO-RN18 and FQO-ViT: Predicting \((f)\) directly.** Having obtained an encoding of the plate geometry and properties x, a decoder now takes this as well as a frequency query as input and maps them towards a prediction. For the RN18 and ViT geometry encoders, the decoder is implemented by an MLP taking both \(\) and a scalar frequency value \(f\) as input to predict the response for that specific query frequency, i.e. \((,f)\). The frequency query is merged to \(\) by a film layer . By querying the decoder with all frequencies individually, we obtain results for the frequency band between 1 and 300 Hz. The MLP has six hidden layers with 512 dimensions each and ReLU activations.

**FQO-UNet: Predicting \((f)\) through the velocity field \((f)\).** To incorporate physics-based contraints and take advantage of the larger amount of available data, we employ a UNet to predict the velocity fields, \((f)\). From \((f)\), we derive the frequency response \((f)\) (analogous to Equation 1). A frequency query, introduced via a FiLM layer after the encoder, enables frequency-specific predictions. To reduce the memory and computation demands per geometry during training, we select a random subset of \(k\) frequency queries per geometry in a batch, with \(k<300\). If not otherwise specified, \(k\) is set to 50.

Figure 4: Frequency-Query Operator method. The geometry encoder takes the mesh geometry and the scalar properties as input. The resulting feature volume along with a frequency query is passed to the query decoder, that either predicts a velocity field or directly a frequency response. The velocity field is aggregated to arrive at the frequency response at the query frequency \(f\).

Grid-Unet and Grid-RN18: Predicting \(\) for a fixed grid of frequencies.To ablate the frequency-query approach, we employ two variations of the FQO-RN18 and FQO-UNet architectures, that do not employ frequency queries. They instead generate predictions for 1-300 Hz at once. This is done by setting the output size of the respective last layer to 300.

### Baseline Methods

We further report baseline results on the following alternative methods: A \(k\)-Nearest Neighbors regressor, that finds the nearest neighbors in the latent space of an autoencoder. DeepONet , with a RN18 as backbone and a MLP to encode the query frequencies as a branch net. Two architectures based on Fourier Neural Operators . One employing an FNO as a replacement for the query-based decoder based on RN18 features. The second directly takes the input geometry and is trained to map it to the velocity fields.

### Training

All methods are trained in a data-driven fashion for 500 epochs on the training dataset of 5000 samples. 500 samples from the training dataset are excluded and employed for validation. We report evaluation results on the previously unseen test set consisting of 1000 additional samples.

For methods that predict \((f)\), i.e. UNet based methods and the FNO variation, the training loss is set to \(L_{}\) where \(L_{}\) represents the MSE on the log-transformed, normalized squared velocity field (Ablation on loss function in Appendix D). For methods that directly predict \(\), the loss is set to \(L_{F}\), the MSE on the normalized frequency response. Choosing the log-transformed quantities enables the loss to be sensitive to errors outside of resonance frequencies. Otherwise, such errors would have little influence on the total loss, as their magnitude is much lower. See Appendix C for further details on the architectures and training procedure.

## 4 Experiments

We train the architecture variations and baseline methods on the Vibrating Plates dataset (see Table 1). To assess which architecture aspects described in Section 3 are beneficial, we perform the following comparisons. Regarding Q1 (frequency-query approach), the Frequency-Query Operator variations consistently yield better predictions than equivalent grid-based methods, where responses for all frequencies are predicted at once: The \(_{}\) and the \(_{}\) are lower, more peaks are reproduced, and the peak positions are more precise. Regarding Q3 (velocity field prediction), predicting the velocity fields and then transforming them to the frequency response leads to better results than directly predicting the frequency response. Specifically, the UNet based architectures strongly outperform all alternatives, which we attribute to the richer training data of velocity fields. Regarding Q2, the ViT encoder leads to worse results than the CNN-based encoders.

All evaluated baseline methods achieve comparatively worse results than our proposed methods. Despite using the same RN18 geometry encoder as FQO-RN18, DeepONet  performs worse. We assume that this is due to incorporating frequency information through a single weighted summation, which limits the model's expressivity . In contrast, FQO-RN18 introduces the queried frequency

    & &  &  \\   & **FQ** & **VF** & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) \\   \\ \(k\)-NN & - & - & 0.63 & 21.50 & 0.45 & 8.7 & 0.88 & 32.48 & 0.68 & 21.0 \\ RN18 + FNO & - & - & 0.42 & 10.76 & 0.34 & 5.6 & 0.28 & 14.12 & 0.21 & 6.1 \\ DeepONet & ✓ & - & 0.49 & 16.91 & 0.48 & 5.4 & 0.44 & 23.05 & 0.57 & 9.9 \\ FNO (velocity field) & - & ✓ & 0.47 & 13.10 & 0.36 & 6.3 & 0.49 & 21.16 & 0.39 & 10.7 \\  Grid-RN18 & - & - & 0.44 & 13.29 & 0.36 & 5.4 & 0.30 & 14.95 & 0.26 & 6.5 \\ FQO-RN18 (Q1) & ✓ & - & 0.32 & 10.70 & 0.17 & 5.3 & 0.24 & 13.51 & 0.13 & 5.1 \\ FQO-ViT (Q2) & ✓ & - & 0.68 & 20.96 & 0.54 & 7.1 & 0.52 & 24.34 & 0.49 & 11.5 \\  Grid-UNet & - & ✓ & 0.19 & 7.57 & 0.24 & 2.7 & 0.17 & 9.41 & 0.14 & 4.6 \\
**FQO-UNet** & ✓ & ✓ & 0.08 & 4.24 & 0.07 & 1.7 & 0.11 & 7.47 & 0.08 & 3.1 \\   

Table 1: Test results for frequency response prediction. Column **VF** indicates if \(\) is indirectly predicted through the velocity field (Q3), column **FQ** indicates if frequency queries (Q1) are used. Q1 to Q3 refer to the model components described in Section 3.

earlier into the model. Two Fourier Neural Operator  baseline methods are evaluated: the first, RN18 + FNO, which substitutes the query-based decoder with an FNO decoder, underperforms compared to FQO-RN18 on both datasets. The second FNO baseline, trained directly to predict velocity fields, yields poorer results.

Results for the G-5000 setting are slightly worse than for the V-5000 setting. The difference is surprising small considering the seven additional varied parameters in the G-5000 setting. One reason might be the average number of peaks in the frequency response: the plates in G-5000 are on average smaller and because of this stiffer, leading to fewer peaks (on average 3.9 in G-5000 and 5.9 in V-5000). This interpretation is supported by the fact that the average error becomes higher with increasing frequency and thus increasing peak density (Figure 3d).

Looking at a prediction example (Figure 5a-d) for our best model, FQO-UNet, the predicted velocity field has subtle differences to the ground truth. The prediction captures the two modes and their shape quite well, but the shape is slightly less regular than in the reference. Despite that, the resulting frequency response prediction at \(f=131\) is close to the FEM reference. In comparison to the grid-based prediction, where peaks tend to be blurry, the frequency response peaks generated by FQO-UNet are more pronounced. Additional visualizations are provided in Appendix E.3 and in the code repository. For the best architecture in our experiments, FQO-UNet, we report mean and standard deviation results for multiple runs in Appendix E.2 and provide an ablation of model size for the FQO-UNet and Grid-UNet architectures in Appendix D.

Transfer learning.To quantify to which degree features learned on a subset of the design space transfer to a different subset, the V-5000 setting is split into two equally-sized parts based on the number of mesh elements that are part of a heading. The "more beadings" set contains only 5.1 peaks on average because the plates are stiffened by the beadings, compared to 6.7 peaks on average for the "less beadings" set. The training on plates with less beadings leads to a smaller drop in prediction quality (see Table 2). This indicates that training on data with more complex frequency responses might be more efficient. In addition, we train a single model on both G-5000 and V-5000. Performance increases, indicating that training can benefit from training with data based on similar mechanical models (Table 3).

Sample efficiency.We train the FQO-UNet and the FQO-RN18 with reduced numbers of samples (see Figure 5e). It is notable, that the FQO-UNet with a quarter of the training data achieves nearly the same prediction quality as the FQO-RN18 with full training data. This highlights the benefit of including the velocity fields into the training process. Quantitative results are given in Appendix E.1 for both dataset settings.

Figure 5: Results. (b) to (d) show the velocity field at one frequency and prediction for the plate geometry in (a) from FQO-UNet. (e) shows the test MSE for training two methods with reduced numbers of samples from V-5000. (f) shows effects of different data generation strategies. The blue line is an isoconture for a fixed compute budget of 150,000 data points, with varying number of frequencies per plate geometry. The green star represents using a larger dataset at 15 frequencies per plate (half of V-5000). The red cross represents a model trained on V-5000. Training with fewer frequencies per plate is more efficient.

We further investigate the optimal ratio of numbers of frequencies per geometry and total number of geometries, by generating an additional dataset in the V-5000 setting consisting of 50,000 plate geometries but with only 15 frequency evaluations per geometry. These frequencies are uniformly spaced with a random starting frequency. Reducing the frequencies per geometry drastically increases the data efficiency of our method. With a tenth of data points compared to our original dataset, the MSE metric approaches the original value (Figure 5f, quantitative results in Appendix E.1).

Design optimization.We investigate the potential of our FQO-UNet to be used for optimizing a beating pattern for reduced vibrations in a specified frequency range. Following the approach described in , to generate plates with reduced vibrations, a diffusion model trained to generate novel leading patterns is combined with gradient information from our FQO-UNet as follows: A gradient on the pixels of the input heading pattern is obtained by passing a leading pattern through the network, computing the sum of the predicted frequency response as a loss and then performing backpropagation to the input beading pattern. This gradient is then used to guide the diffusion model to generate beading patterns with reduced vibrations. We optimize beading patterns to reduce vibrations between 100 and 200 Hz using the FQO-UNet trained on the V-5000 dataset (Figure 6). Resulting plates have a lower mean frequency response in the targeted range than any plate in the training dataset.

## 5 Related Work

Acoustics.While research on surrogate models for the spatio-temporal evolution of vector fields is fairly common [39; 40; 41], directly predicting frequency responses through neural networks is an understudied problem. A general CNN architecture is applied in  to calibrate the parameters of an analytical model for a composite column on a shake table. The data includes spectrograms representing the structural response in time-frequency domain. The frequency-domain response of acoustic metamaterials is considered in a material design task by conditional generative adversarial networks or reinforcement learning [43; 44; 45]. The frequency response of a multi-mass oscillator is

    &  &  \\   & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) & \(_{}\) \\  FQO-RN18 & 0.61 & 16.19 & 0.20 & 9.3 & 0.82 & 15.79 & 0.36 & 8.3 \\ (origin) & 0.33 & 10.48 & 0.18 & 5.0 & 0.42 & 12.00 & 0.29 & 5.8 \\  FQO-UNet & 0.39 & 11.17 & 0.21 & 5.6 & 0.54 & 12.02 & 0.25 & 5.5 \\ (origin) & 0.18 & 8.68 & 0.19 & 2.6 & 0.17 & 7.83 & 0.13 & 3.0 \\   

Table 2: Transfer learning performance: We split V-5000 into two halves based on amount of beadings and evaluate transfer learning performance across these splits: training subset \(\) test subset. The gray rows denote test results on the original subset that has been used for training.

Figure 6: Design optimization. Exemplary generation result with lowest mean response between \(100\) Hz and \(200\) Hz out of 32 generations (left, mean response below). Plate with lowest response out of all 5000 training examples from V-5000 (middle left). Comparison of responses from left plates (middle right). Responses from 16 generated plates (right).

predicted with transformer-based methods . Within the context of aeroacoustics, the propagation of a two-dimensional acoustic wave while considering sound-scattering obstacles is predicted in time-domain by a CNN [47; 48]. A review of machine learning in acoustics is given by . Several acoustic benchmarks for numerical methods are available , however, these benchmarks do not systematically vary input geometries, making them not directly applicable to data-driven models.

Scientific machine learning.Data-driven machine learning techniques were successfully applied in many different disciplines within engineering and applied science; for example for alloy discovery , crystal structure prediction , climate modeling  and protein folding . A popular use case for data-driven methods is to accelerate fluid dynamics, governed by the Navier-Stokes equations [39; 40; 55; 56; 57].

The question of how to structure and train neural networks for predicting the solution of partial differential equations (PDE) has been the topic of intense research. Many methods investigate the inclusion of physics informed loss terms [58; 59; 60; 56; 61]. Some methods directly solve PDEs with neural networks as a surrogate model [62; 63]. Graph neural networks are often employed, e.g. for interaction of rigid and deformable objects as well as fluids [64; 65].

Operator learning and implicit models.A promising avenue of research for incorporating inductive biases for physical models has been operator learning [11; 15; 66; 37; 41]. Operator learning structures neural networks such that they implement a function that can be evaluated at real values instead of a fixed discrete grid. DeepONet  implements operator learning by taking the value at which it is evaluated as an input and processes this value in a separate branch. Fourier Neural Operators  use a point-wise mapping to a latent space which is processed through a sequence of individual layers in Fourier space before being projected to the output space.

Implicit models (or coordinate-based representation) are models where location is utilized as an input to obtain a location-specific prediction, instead of predicting the entire grid at once and thus fit in the operator learning paradigm. Such models were used to represent shapes [12; 67; 68; 13], later their representations were improved [69; 70] and adapted for representing neural radiance fields (NeRFs) [71; 14]. Our method applies techniques from these implicit models to operator learning.

## 6 Conclusion

We introduced the problem of predicting structural vibrations and associated frequency response functions of mechanical systems. Unlike other benchmarks for deep learning surrogate models, this task necessitates predicting a steady-state solution that remains constant over time, but varies across different excitation frequencies. To this end, we created the Vibrating Plates dataset and benchmark and provide reference scores for several methods. Our Frequency-Query Operator method addresses the benchmark and achieves better results than the DeepONet and FNO baselines. We find that query-based approaches and the indirect prediction of a mean frequency response through predicted field quantities lead to better results. Surrogate models as shown in this work can greatly accelerate the prediction of physical quantities over the finite element method: Our models achieved a speed-up of around 4 to 6 orders of magnitude (see Appendix C), which makes tasks such as design optimization feasible. This efficiency, however, depends on the availability of enough pre-generated training data and requires model training. We further investigated effects of changing the composition of the training dataset and found that using less frequencies per plate and more different plates positively impacts prediction accuracy.

Limitations and future work.Our dataset and method serve as an initial step in the development of surrogate models for vibration prediction. The dataset focuses on plates, a common geometric primitive used in a great number of applications. However, many structures beyond plates exist, involving curved shells, multi-component geometries and complex material parameters. While some results from our study might transfer to these cases, more flexible architectures, able to deal with 3D data, would be needed. Different mechanical models, might also produce more complex frequency responses with e.g. more closely spaced modes, making the prediction task more challenging. As more complex geometries incur higher computational costs of FEM simulations, key questions are how to enhance sample-efficiency further, for example through transfer learning. A further limitation is the manufacturability of the considered beating patterns. The plate beadings could in principle be manufactured by deep drawing of sheet metal, but would require specifically designed stamps.

Acknowledgements.This research is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation), project number 501927736, within the DFG Priority Programme2353: Daring More Intelligence - Design Assistants in Mechanics and Dynamics'. The authors gratefully acknowledge the computing time made available to them on the high-performance computers HLRN-IV at GWDG at the NHR Centers NHR@Gottingen. These centers are jointly supported by the German Federal Ministry of Education and Research and the German state governments participating in the NHR (www.nhr-veretin.de/unesre-partner).