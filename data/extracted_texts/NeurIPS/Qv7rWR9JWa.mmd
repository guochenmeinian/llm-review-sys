# Sorting with Predictions

Xingjian Bai

Department of Computer Science

University of Oxford, UK

xingjian.bai@sjc.ox.ac.uk &Christian Coester

Department of Computer Science

University of Oxford, UK

christian.coester@cs.ox.ac.uk

###### Abstract

We explore the fundamental problem of sorting through the lens of learning-augmented algorithms, where algorithms can leverage possibly erroneous predictions to improve their efficiency. We consider two different settings: In the first setting, each item is provided a prediction of its position in the sorted list. In the second setting, we assume there is a "quick-and-dirty" way of comparing items, in addition to slow-and-exact comparisons. For both settings, we design new and simple algorithms using only \(O(_{i}_{i})\) exact comparisons, where \(_{i}\) is a suitably defined prediction error for the \(i\)th element. In particular, as the quality of predictions deteriorates, the number of comparisons degrades smoothly from \(O(n)\) to \(O(n n)\). We prove that this comparison complexity is theoretically optimal with respect to the examined error measures. An experimental evaluation against existing adaptive and non-adaptive sorting algorithms demonstrates the potential of applying learning-augmented algorithms in sorting tasks.

## 1 Introduction

Sorting is one of the most basic algorithmic problems, commonly featured as one of the initial topics in computer science education, and with a vast array of applications spanning various domains. In recent years, the emerging field of algorithms with predictions (Lykouris and Vassilvitskii, 2021, Mitzenmacher and Vassilvitskii, 2022), also known as learning-augmented algorithms, has opened up new possibilities for algorithmic improvement, where algorithms aim to leverage predictions (possibly generated through machine learning, or otherwise) to improve their performance. However, the classical sorting problem with predictions, along with the discussion of different types of predictors for sorting, appears to have been largely overlooked by this recent movement. This paper explores the problem of sorting through the lens of algorithms with predictions in two settings, aiming to overcome the classical \((n n)\) barrier with the aid of various types of predictors.

The first setting involves each item having a prediction of its position in the sorted list. This type of predictor is commonly found in real-world scenarios. For instance, empirical estimations of element distribution can generate positional predictions. Another example is that a fixed set of items has their ranking evolve over time, with minor changes at each timestep. Here, an outdated ranking can serve as a natural prediction for the current ranking. As re-evaluating the true relation between items can be costly, the provided positional predictions offer useful information. The positional prediction setting is closely related to _adaptive sorting_ of inputs with existing presortedness (Estivill-Castro and Wood, 1992), but we consider different measures of error on the predictor, resulting in algorithms with a more fine-grained complexity.

In the second setting, a "dirty" comparison function is provided to assist sorting. In biological experiments, for instance, some "indicating factors" might be used to approximately compare two molecules or drugs. Despite potential errors due to the oversight of minor factors, these comparisons can still offer preliminary insights into the properties of the subjects. More broadly, in experimental science, researchers often carry out costly experiments to compare subject behaviours. By utilizing aprofficient sorting algorithm that capitalizes on dirty comparisons, the need for costly experiments can be reduced and substituted by less expensive, albeit noisier, experiments.

We propose sorting algorithms to leverage either type of predictor. In the positional prediction setting, we design two deterministic algorithms with different complexity bounds, while in the dirty comparisons setting, we develop a randomized algorithm. In all settings, we provide bounds of the form \(O(_{i=1}^{n}(_{i}+2))\) on the number of exact comparisons, for different notions of element-wise prediction errors \(_{i}[0,n]\). In particular, all three proposed algorithms only require \(O(n)\) exact comparisons if predictions are accurate (_consistency_), never use more than \(O(n n)\) comparison regardless of prediction quality (_robustness_), and their performance degrades slowly as a function of prediction error (_smoothness_). Moreover, we show that all algorithms have optimal comparison complexity with respect to the error measures examined.

Finally, through experiments on both synthetic and real-world data, we evaluate the proposed algorithms against existing (adaptive and non-adaptive) algorithms. Results demonstrate their superiority over the baselines in multiple scenarios.

### Preliminaries

Let \(A= a_{1},,a_{n}\) be an array of \(n\) items, equipped with a strict linear order \(<\). Let \(p[n][n]\) be the permutation that maps each index \(i\) to the position of \(a_{i}\) in the sorted list; that is, \(a_{p^{-1}(1)}<a_{p^{-1}(2)}<<a_{p^{-1}(n)}\). We consider two settings of sorting with predictions.

Sorting with Positional Predictions.In _sorting with positional predictions_, the algorithm receives for each item \(a_{i}\) a prediction \((i)\) of its position \(p(i)\) in the sorted list. We allow \(\) to be any function \([n][n]\), which need not be a permutation (i.e., it is possible that \((i)=(j)\) for some \(i j\)).

Positional predictions can be generated by models that roughly sort the items, e.g. focusing on major factors while neglecting minor ones. Or they can stem from past item rankings, while the properties of the items evolve over time. In such cases, the objective is to obtain the latest ranking of items.

The error of a positional prediction can be naturally quantified by the displacement of each element's prediction; that is, the absolute difference of the predicted ranking and the true ranking. We define the _displacement error_ of item \(a_{i}\) as

\[_{i}^{}:=|(i)-p(i)|.\]

The following notion of one-sided error provides an alternative perspective to evaluate the complexity of algorithms with positional predictions. We denote the left-error and right-error of item \(a_{i}\) as

\[_{i}^{l} :=|\{j[n](j)(i) p(j)>p(i)\}|\] \[_{i}^{r} :=|\{j[n](j)(i) p(j)<p(i)\}|\,.\]

In certain contexts, it may be impossible to obtain a predictor with small displacement error, but possible to obtain one with a small one-sided error. By developing algorithms for this setting, we expand the space of problems where sorting algorithms with predictions can be applied.

Sorting with Dirty and Clean Comparisons.The other setting we consider involves a predictor that estimates which of two elements is larger without conducting a proper comparison, providing a faster but possibly inaccurate result. This type of predictor is applicable in scenarios where exact comparisons are costly but a rough estimate of the comparison outcome can be obtained more easily.

Formally, in _sorting with dirty comparisons_, the algorithm has access to a complete, asymmetric relation \(\) on the items, while still also having access to the exact comparisons \(<\). That is, for any two distinct items \(a_{i}\) and \(a_{j}\), either \(a_{i}\ \ a_{j}\) or \(a_{j}\ \ a_{i}\). We think of \(\) as an unreliable, but much faster to evaluate prediction of \(<\). We also refer to the (fast) comparisons according to \(\) as _dirty_ whereas the (slow) comparisons according to \(<\) are _clean_. We emphasize that the relation \(\) need _not be transitive_, so it is not necessarily a linear order. Instead, \(\) induces a tournament graph on the items of \(A\), containing a directed edge \((a_{i},a_{j})\) if and only if \(a_{i}\ \ a_{j}\), and in many applications, we expect this graph to have cycles.

We denote by \(_{i}\) the number of incorrect dirty comparisons involving \(a_{i}\), that is,

\[_{i}:=\{j[n](a_{i}<a_{j})(a_{i}\ \ a_{j})\}\,.\]

### Main Results

Our main result for the dirty comparison setting is given by the following theorem:

**Theorem 1.1**.: _Augmented with dirty comparisons, there is a randomized algorithm that sorts an array within \(O(n n)\) running time, \(O(n n)\) queries to dirty comparisons, and \(O(_{i=1}^{n}(_{i}+2))\) clean comparisons in expectation._

By the classical lower bound, the total number of dirty + clean comparisons must be at least \((n n)\) regardless of prediction quality, but for sufficiently good predictions the theorem allows us to replace most clean comparisons with dirty ones. The case where dirty comparisons are probabilistic is discussed in Section B.1.

The following theorem generalizes the previous one to the case that there are \(k\) different dirty comparison operators:

**Theorem 1.2**.: _Augmented with \(k 2^{O(n/ n)}\) dirty comparison predictors, where the error of the \(ph\) predictor is denoted by \(^{p}\), there is a randomized algorithm that sorts an array with at most \(O(_{p}_{i=1}^{n}(_{i}^{p}+2))\) clean comparisons._

In other words, the number of clean comparisons is as good as if we knew in advance which of the \(k\) predictors is best. The bound on \(k\) is almost tight, since already \(k 2^{n n}\) would mean there could be one predictor for each of the \(n!\) possible sorting outcomes, which would render them useless. The proof of Theorem 1.2 is given in Appendix B.2.

The next two theorems capture our algorithms for the positional prediction setting:

**Theorem 1.3**.: _Augmented with a positional predictor, there is a deterministic algorithm that sorts an array within \(O(_{i=1}^{n}(_{i}^{}+2))\) running time and comparisons._

**Theorem 1.4**.: _Augmented with a positional predictor, there is a deterministic algorithm that sorts an array within \(O(_{i=1}^{n}(\{_{i}^{l},_{i}^{r}\}+2 ))\) comparisons._

We remark that there exist instances where the bound of Theorem 1.3 is stronger than that of Theorem 1.4 and vice versa.1

The following theorem, proved in Appendix E, shows tightness of the aforementioned upper bounds.

**Theorem 1.5**.: _Augmented with dirty comparisons, no sorting algorithm uses \(o(_{i=1}^{n}(_{i}^{}+2))\) clean comparisons. Augmented with a positional predictor, no sorting algorithm uses \(o(_{i=1}^{n}(_{i}^{}+2))\) or \(o(_{i=1}^{n}(\{_{i}^{l},_{i}^{r}\}+2))\) comparisons._

Bounds in Terms of Global Error.One may wonder how the above bounds translate to a global error measure such as the number of item pairs where the larger one is incorrectly predicted to be no larger than the smaller one. Writing \(D\) for this error measure, in the dirty comparison setting we simply have \(D=_{i}_{i}\), and in the positional prediction setting \(D_{i}_{i}^{}\) by (Rohatgi, 2020, Lemma 11). Thus, concavity of logarithm and Jensen's inequality yield an upper bound of \(O(n(+2))\) for both settings. This bound is tight2 as a function of \(D\) and corresponds to the optimal complexity of adaptive sorting as a function of the number of inversions (Mannila, 1985).

However, our guarantees in terms of element-wise error are strictly stronger whenever Jensen's inequality is not tight, i.e., when the \(_{i}\) are non-uniform. Furthermore, it is reasonable to expect predictors to exhibit varying levels of error for different items, especially when the error originates from element-wise noise.

### Related Works

Algorithms with Predictions.Our study aligns with the broader field of learning-augmented algorithms, also known as algorithms with predictions. The majority of research has focused onclassical online problems such caching (Lykouris and Vassilvitskii, 2021, Rohatgi, 2020, Wei, 2020, Bansal et al., 2022), rent-or-buy problems (Purohit et al., 2018, Gollapudi and Panigrahi, 2019, Angelopoulos et al., 2020, Wang et al., 2020, Antoniadis et al., 2021), scheduling (Purohit et al., 2018, Lattanzi et al., 2020, Mitzenmacher, 2020, Azar et al., 2021, 2022, Lindermayr and Megow, 2022) and many others. In comparison, research on learning-augmented algorithms to improve running time for offline problems is relatively sparser, but examples include matching (Dinitz et al., 2021, Sakaue and Oki, 2022), clustering (Ergun et al., 2022), and graph algorithms (Chen et al., 2022, Davies et al., 2023). Motivated by (Kraska et al., 2018), (Lykouris and Vassilvitskii, 2021) describes a simple method to speed up binary search with predictions, which has been inspirational for our work. Learning-augmented algorithms have also been applied to data structures such as binary search trees (Lin et al., 2022, Cao et al., 2023), and empirical works demonstrate the benefits of ML-augmentation for index structures (Kraska et al., 2018) and database systems (Kraska et al., 2019). There has also been increasing interest in settings where algorithms have access to multiple predictors (Gollapudi and Panigrahi, 2019, Wang et al., 2020, Bhaskara et al., 2020, Almanza et al., 2021, Emek et al., 2021, Dinitz et al., 2022, Anand et al., 2022, Antoniadis et al., 2023).

Related to sorting, Lu et al. (2021) studied learning-augmented _generalized_ sorting, a variant of sorting where some comparisons are allowed while others are forbidden. The predictions they consider are similar to our dirty comparisons. They proposed two algorithms with comparison complexities \(O(n n+w)\) and \(O(nw)\), where \(w\) is the total number of incorrect dirty comparisons. In the classical (non-generalized) setting with all comparisons allowed, only the second bound theoretically improves upon \(O(n n)\), but the dependence on the error is exponentially worse than for our algorithms; even with a single incorrect dirty comparison per item, the \(O(nw)\) bound becomes \(O(n^{2})\), whereas ours is \(O(n)\). A recent work of Erlebach et al. (2023) studies sorting under explorable uncertainty with predictions, where initially only an interval around the value of each item is known, the exact values can be queried, a prediction of these values is given, and the goal is to minimize the number of queries needed to sort the list.

Deep Learning-Based Sorting.The thriving development of deep learning has inspired research into new sorting paradigms. A DeepMind study (Mankowitz et al., 2023) recast sorting as a single-player game, training agents to perform effectively, thus uncovering faster sorting routines for short sequences. Kristo et al. (2020) proposed a sorting algorithm that uses a learning component to improve the empirical performance of sorting numerical values. Their algorithm tries to approximate the empirical CDF of the input by applying ML techniques to a small subset of the input. This setting diverges from ours: If inputs are non-numeric (and no monotonous mapping to numbers is known), then one has to rely on a comparison function, and the approach of Kristo et al. (2020) would not be well-defined, whereas our algorithms can sort arbitrary data types.

Conversely, the input in (Kristo et al., 2020) is solely the item list, without any additional predictions. Note that predictions (or other assumptions) are necessary to beat the entropic \((n n)\) lower bound. 3

Noisy Sorting.Noisy sorting contemplates scenarios where comparison results may be incorrect. This model is useful to simulate potential faults in large systems. Two noisy sorting settings have primarily been considered: In _independent_ noisy setting, each query's result is independently flipped with probability \(p(0,)\). Recently, Gu and Xu (2023) provided optimal bounds on the number of queries to sort \(n\) elements with high probability. _Recurrent_ noisy setting (Braverman and Mossel, 2008) further assumes any repeated comparisons will yield consistent results. Geissmann et al. (2019) present an optimal algorithm that guarantees \(O(n n)\) time, \(O( n)\) maximum dislocation, and \(O(n)\) total dislocation with high probability. While the recurrent noisy setting is closely related to dirty comparisons, studies in that field focus primarily on approximate sorting; to the best of our knowledge, no _exact_ sorting algorithms that use both dirty and clean comparisons have been studied.

Adaptive Sorting.Adaptive sorting algorithms leverage various types of existing order in the input, achieving better complexity for partially sorted data. Examples include TimSort (Peters, 2002), which is the standard sorting algorithm in a variety of programming languages, Cook-Kim division (Cook and Kim, 1980), and Powersort (Munro and Wild, 2018), which recently replaced TimSort in Python's standard library. We refer to the survey of Estivill-Castro and Wood (1992) for a broader overview. The concept of pre-sortedness is closely related to positional predictions; however, without the motivation from predictors, the complexity bound on adaptive sorting algorithms was often considered under error measures on the entire array, instead of on each element. In contrast, our error measure is element-wise, allowing algorithms with stronger complexity bounds.

## 2 Sorting with Dirty Comparisons

Given a dirty predictor \(\), our goal is to sort \(A\) with the least possible number of clean comparisons. Note that, if \(\) is accurate, \(A\) can be sorted using only \(O(n)\) clean comparisons and \(O(n n)\) dirty comparisons. This could be achieved, for example, by performing Merge Sort with dirty comparisons and then validating the result through clean comparisons between adjacent elements. This observation motivates us to consider that not all \(O(n^{2})\) dirty comparisons are necessary, and we should devise an algorithm minimizing the number of both clean and dirty comparisons.

We propose a randomized algorithm that sorts \(A\) with expected \(O((2+_{i}))\) clean comparisons, expected \(O(n n)\) dirty comparisons, and expected \(O(n n)\) running time. The key idea consists of three parts: 1) Sequentially insert each element of \(A\) into a binary search tree, following random order; 2) Guide each insertion primarily with dirty comparisons, while verifying the correctness of it using a minimal number of clean comparisons. 3) Correct the mistake induced by the dirty insertion, ensuring that the clean comparisons needed for correction is \(O(_{i})\) in expectation.

We describe the algorithm in Section 2.1 and prove its performance guarantees in Section 2.2. In Appendix B we discuss extensions of the dirty comparison setting.

### Algorithm

We now describe the sorting algorithm with dirty comparisons in detail (Algorithm 1). We initialize \(B\) as an empty binary search tree (BST). For any vertex \(v\), we denote by \((v)\) and \((v)\) its left and right children, and by \((B)\) the root of \(B\). Slightly abusing notation, we write \(v\) also for the item stored at vertex \(v\). If any of these vertices is missing, the respective variable has value nil.

``` Input:\(A= a_{1},,a_{n}\), dirty comparator \(\), clean comparator \(<\)
1\(B\) empty binary tree
2for\(i[n]\) in uniformly random order do
3\((L_{1},C_{1},R_{1})(-,(B),)\)
4\(t 1\) while\(C_{t}\)do\(\) Dirty search
5if\(a_{i} C_{t}\)then\((L_{t+1},C_{t+1},R_{t+1})(L_{t},(C_{t}),C_{t})\)
6else\((L_{t+1},C_{t+1},R_{t+1})(C_{t},(C_{t}),R_{t})\)
7\(t t+1\)
8\(C C_{t^{*}}\), where \(t^{*} t\) is maximal s.t. \(L_{t^{*}}<a_{i}<R_{t^{*}}\)\(\) Verification
9while\(C\)do\(\) Clean search
10if\(a_{i}<C\)then\(C(C)\)
11else\(C(C)\)
12 Insert \(a_{i}\) at \(C\)
13return inorder traversal of \(B\) ```

**Algorithm 1**Sorting with dirty and clean comparisons

Within each iteration of the for-loop starting in line 2, we select one item \(a_{i}\) of \(A\) uniformly randomly from the items that have not been processed yet. Then, we insert this item \(a_{i}\) into \(B\), while maintaining the invariant that \(B\) remains a BST with respect to clean comparisons \(<\).

Inserting item \(a_{i}\) into \(B\) requires three phases, as illustrated in Figure 2.1. The first phase involves performing a search for the insertion position using dirty comparisons \(\), keeping track of the search path. Here, we denote by \(C_{t}\) the \(t\)th vertex on this path, and by \(L_{t}\) and \(R_{t}\) the lower and upper bounds on items that can be inserted in the subtree rooted at \(C_{t}\) without violating the BST property with respect to \(<\). Correctness of the choice of \(L_{t}\) and \(R_{t}\) follows from the fact that \(B\) was a BST with respect to \(<\) before the current insertion. This dirty procedure stops when the search path reaches a nil-leaf, regarded as the predicted position for \(a_{i}\)'s insertion. However, since we used dirty comparisons to trace the path, \(a_{i}\) might violate one of the boundary conditions \(L_{t}<a_{i}\) or \(a_{i}<R_{t}\) at some recursion step \(t\). We call a recursion step \(t\)_valid_ for \(a_{i}\) if \(L_{t}<a_{i}<R_{t}\). Then, we enter the verification phase in line 9. We traverse the dirty search path _in reverse order_ to locate the last valid step \(t^{*}\). A naive method to do this (which is sufficient for our asymptotic guarantees) is to repeatedly decrease \(t\) by \(1\) until \(t\) is valid; we discuss an alternate, more efficient method in Remark A.6, which yields a better constant factor.

The final phase involves performing a clean search starting from \(C_{t^{*}}\) to determine the correct insertion position for \(a_{i}\). After inserting \(a_{i}\) into that position, \(B\) remains a BST with respect to \(<\). Once all items of \(A\) are inserted into \(B\), we can obtain the sorted order through the inorder traversal of \(B\).

### Complexity Analysis

The idea is to show that the dirty search path has expected depth \(O( n)\), whereas the verification path and the clean search path only have expected depth \(O(_{i})\). Therefore, the algorithm only needs \(O( n)\) dirty and \(O(_{i})\) clean comparisons for inserting each \(a_{i}\); Theorem 1.1 is established consequently. The full proof is given in Appendix A.

## 3 Sorting with Positional Predictions

In this section, we propose two algorithms that are capable of leveraging positional predictions. The first one has complexity bounds in terms of the displacement error measure, and the second one has complexity bounds in terms of \(^{l}\) and \(^{}\), the one-sided error measures. Each algorithm is effective in some tasks, where the given prediction is accurate with respect to its corresponding error measure.

### Displacement Sort

We present a sorting algorithm with positional prediction, whose comparison and time complexity rely solely on the displacement error of the predictor. The algorithm is adapted from Local Insertion Sort (Mannila, 1985), an adaptive sorting algorithm proven to be optimal for various measures of presortedness.

We use a classic data structure called finger tree (Guibas et al., 1977), which is a balanced binary search tree (BBST) equipped with a pointer ("finger") pointing towards the last inserted vertex. When a new value \(v\) is to be inserted, rather than searching for insertion position from the root, the insertion position is found by moving the finger from the last inserted vertex \(u\) to the suitable new position. By the balance property of BBST, the insertion can be performed in \(O( d(u,v))\) amortized time, where \(d(u,v)\) is the number of vertices in the tree whose value lies in the closed interval from \(u\) to \(v\).

Algorithm 2 details the proposed method. We first bucket sort (in time \(O(n)\)) the items in \(A\) based on their predicted positions, such that we may assume for all \(i<j\) that \((i)(j)\). Following the

Figure 2.1: The insertion process in dirty comparison sorting.

rearranged order, items in \(A\) are sequentially inserted into an initially empty finger tree \(T\). After all insertions, we obtain the exactly sorted array by an inorder traversal of \(T\).

``` Input:\(A= a_{1},,a_{n}\), prediction \(\)
1BucketSort\((A,)\); \(\) Bucket Sort \(A\) according to \(\), so that \((1)(2)(n)\)\(T\) an empty one-finger tree;
2for\(i=1,,n\)do
3Insert \(a_{i}\) into \(T\);
4return nodes in \(T\) in sorted order (via inorder traversal); ```

**Algorithm 2**Sorting with complexity on \(_{i}^{}\)

The full proof of run time and comparison complexity of Algorithm 2 is in Appendix C.

### Double-Hoover Sort

Now we turn our focus to settings where one-sided errors are small. We first describe a simple algorithm with comparison complexity as a function of _either \(^{l}\) or \(^{r}\)_. Following this, we introduce our algorithm Double-Hoover Sort, which has comparison complexity as claimed in Theorem 1.4. Both algorithms begin by bucket sorting \(A\) with respect to the positional prediction in \(O(n)\) time. Thus, we may subsequently assume that \(A\) is rearranged such that \( i<j,(i)(j)\).

A First Approach.A left-sided sorting complexity of \(O(_{i=1}^{n}(2+_{i}^{l}))\) can be easily achieved using the standard technique of learning-augmented binary search, as described in Lykouris and Vassilvitskii (2021); Mitzenmacher and Vassilvitskii (2022). Specifically, a sorted array \(L\) is maintained, and \(a_{1},,a_{n}\) are sequentially inserted into \(L\). During each insertion, we perform a learning-augmented binary search starting from the rightmost position of \(L\), taking \(O((_{i}^{l}+2))\) comparisons to find the correct insertion position. In total, \(O(_{i}(_{i}^{l}+2))\) comparisons are taken among all insertions. By replacing the array \(L\) with an appropriate data structure (e.g., a BBST with a finger that always returns to the rightmost element), one can achieve the same bound also for time complexity. A reversed "right-sided" version of this algorithm achieves complexity \(O(_{i}(_{i}^{r}+2))\). By simultaneously running the left-sided and right-sided algorithms, one can achieve the complexity bound of \(O(\{_{i=1}^{n}(2+_{i}^{l}),_{i=1}^{n }(2+_{i}^{r})\}\)). However, moving the \(\) operator inside the summation requires more elaborate approach.

Double-Hoover Sort.The basic idea is that, to utilize a similar insertion scheme to that employed in the one-sided algorithm, we maintain two sorted structures \(L\) and \(R\) at the same time, and insert each item into one of them, depending on which operation is faster, hereby achieving a complexity bound of \(O(((_{i}^{l},_{i}^{r})+2))\). Then, a final sorted list is attained by merging \(L\) and \(R\) in linear time. However, a significant issue yet to be addressed is how to decide the insertion order of different items.

Consider two items \(a_{u}\) and \(a_{v}\) with \(u<v\) (so \((u)(v)\) by Bucket Sort). In our algorithm, if both are to be inserted into \(L\), it is crucial that \(a_{u}\) is inserted prior to \(a_{v}\). Otherwise, the insertion complexity of \(a_{u}\) could exceed the bound of \((_{u}^{l}+2)\). Conversely, if both \(a_{u}\) and \(a_{v}\) are to be inserted into \(R\), then \(a_{v}\) should be inserted prior to \(a_{u}\). Since we cannot predict whether an item will be inserted into \(L\) or \(R\), formulating an appropriate insertion order that respects the constraints on both sides is impossible.

We tackle this issue of insertion order with a _strength-based, \( n\)-rounds insertion scheme_. Intuitively, we think of \(L\) and \(R\) as two "hoovers", with their "suction power" increasing simultaneously over time. Each item (as "dust") is extracted from the array and inserted into one hoover once the suction power reaches the required strength: a hoover with suction power \(\) is able to absorb items that can be inserted into it with \(O()\) comparisons. Details are illustrated in Algorithm 3.

The sorted structures \(L\) and \(R\) can be implemented by arrays, though alternative data structures could provide better time complexity.

We conduct insertions in \( n\) rounds, setting \(\) to be \(1,2,4,,2^{ n}\). In each round, we iterate over \(a_{1},,a_{n}\) to decide if they should be inserted to \(L\) in the current round. Then, we iterate over \(a_{n},,a_{1}\) reversely, to decide if they should be inserted to \(R\) in the current round. Note that if an item is inserted into either \(L\) or \(R\), it is omitted in later rounds. The insertion process of an item in one round is depicted in Figure 3.1.

To decide whether \(a_{i}\) should be inserted into \(L\) with strength \(\), let \(l_{}^{i}\) denote the \(\)th largest item in \(L\) with index smaller than \(i\), representing the "boundary value" in this round. If there are less than \(\) eligible items in \(L\), set \(l_{}^{i}\) to be \(-\). Let \(l^{i}\) represent \(_{^{}<}l_{^{}}^{i}\), the minimum boundary value in previous rounds. If \(l_{}^{i}\) is smaller than \(a_{i}\), we employ binary search to insert \(a_{i}\) into \(L\), starting with the interval \(\{x L l_{}^{i} x l^{i}\}\). Conversely, to decide whether \(a_{i}\) should be inserted into \(R\), we adopt a symmetrical approach as depicted in lines 11 to 15 of Algorithm 3.

``` Input:\(A= a_{1},,a_{n}\), prediction \(\)
1BucketSort\((A,)\); \(\) Bucket Sort \(A\) according to \(\), so that \((1)(2)(n)\)\(L,R\);
2for\(=2^{0},2^{1},,2^{ n}\)do
3for\(i=1,,n\)if\(a_{i}\) has not been inserteddo
4\(L^{<i}\{a_{j} L:j<i\}\);
5\(l_{}^{i}\)if\(|L^{<i}|<\)then\(-\)else\(\)th largest item in \(L^{<i}\) ;
6if\(a_{i}>l_{}^{i}\)then
7 Insert \(a_{i}\) into \(L\) by binary search, starting on interval \(\{x L l_{}^{i} x l^{i}\}\),
8
9where \(l^{i}:=_{^{}<}l_{^{}}^{i}\)
10
11
12
13 end if
14
15return merge(L, R); ```

**Algorithm 3**Double-Hoover Sort

After all insertion rounds, we merge \(L\) and \(R\) in linear time to obtain the sorted result.

Correctness.The correctness of the Double-Hoover Sort arises from the invariance that both \(L\) and \(R\) remain sorted after all insertions. It is sufficient to show that the initial insertion intervals at line 8 and line 14 always cover the value of \(a_{i}\). At line 8, \(l_{}^{i}<a_{i}\) holds trivially by conditioning. Since \(a_{i}\) is not inserted into \(L\) in any previous round, \(a_{i}<l_{^{}}^{i}\) for all \(^{}<\). Since the minimum operation preserves inequality, \(a_{i}<l^{i}\) also holds. A similar argument can be made for the interval at line 14.

To discern the comparison complexity of the proposed algorithm, we propose the following lemma.

**Lemma 3.1**.: _Upon the insertion of an item \(a_{i}\) into \(L\), all items in \(L L^{<i}\) are larger than \(l_{i}\). Similarly, when an item \(a_{i}\) is inserted into \(R\), all items in \(R R^{>i}\) are smaller than \(r_{i}\). As a result, the initial interval at line 8 and line 14 are subsets of \(L^{<i}\) and \(R^{<i}\), and hence have sizes no larger than \(\)._

**Theorem 3.2**.: _For each item \(a_{i}\), its insertion process takes \(O((\{_{i}^{l},_{i}^{r}\}+2))\) comparisons._

The full proof of Lemma 3.1 and Theorem 3.2 are given in Appendix D.

Figure 3.1: An example of the insertion process in the Double-Hoover sort.

Then, Theorem 1.4 can be obtained from Theorem 3.2, by summing up the number of comparisons in the insertion process of each \(a_{i}\).

## 4 Experiments

In this section, we conduct experiments both on synthetic data, crafted to simulate predictions in real-world settings, and also on real-world data of countries' population ranking. The source code used for experiments is available at https://github.com/xingjian-bai/learning-augmented-sorting.

We assess the performance of our proposed sorting algorithms against five well-established baselines. Quick Sort and Merge Sort are classic sorting algorithms with \(O(n n)\) complexity; Tim Sort (Peters, 2002) is a popular hybrid sorting algorithm designed to perform efficiently on real-world datasets and widely adopted in standard libraries. Further, we choose two adaptive sorting algorithms, Odd-Even Straight Merge Sort (Estivill-Castro and Wood, 1992) and Cook-Kim division (Cook and Kim, 1980), which are proven to be optimal with respect to several measures of disorderness. They serve as adaptive variants of Merge Sort and Quick Sort. To apply adaptive sorting algorithms in positional prediction settings, we first execute bucket sort on the items by their predicted ranking, breaking ties arbitrarily. This "sorted-by-prediction" array is then inputted into the baselines. In Appendix F.2, we also show results of an experimental comparison against Insertion Sort.

Positional Predictions.First, we elaborate on our synthetic data generation process. In many sorting tasks, items belong to different "grades", which represent a coarse version of the ranking. For example, students are classified into grades A, B, C, and D based on their exam scores; with their grades in hand, we want to find out their accurate ranking. We denote this scenario as the _class setting_. Specifically, we divide an array of \(n\) items into \(c\) classes, sampling the thresholds \(t_{0}=0 t_{1}<t_{2}<,t_{c}=n\) uniformly at random. Then, for items \(a_{i}\) with \(t_{k-1}<i t_{k}\), we say that they belong to the \(k\)th class, and their predicted position is uniformly generated from \((t_{k-1},t_{k}]\).

To model the tasks where we have an "outdated" ranking, we design the _decay setting_. The accurate ranking is obtained as the prediction at time \(0\). Then, during each time step, one item is randomly selected to be perturbed: its predicted position is shifted by 1, towards either left or right, with uniform probability. We then ask the sorting algorithms to retrieve the original ranking of items based on the prediction at each time step.

We also utilize data from a real-world setting. We draw the annual population ranking of countries and smaller regions from 1960 to 2010 from World Bank (2023). Then, we feed in the ranking in year \(x=1960,,2010\) respectively as the prediction, and ask the sorting algorithm to predict the ranking in year \(2010\).

In all the plots, the X-axis indicates the quality of predictions, and the Y-axis indicates the number of comparisons used. The red dotted line is \(n_{2}n\). The bold curves represent the proposed algorithms. All experiments are repeated 30 times, with the standard deviation indicated by shade. A scapegoat tree implementation of Double-Hoover Sort is used for synthetic settings, while an array implementation is used for population ranking given the small sample size.

Figure 4.1: Sorting with positional predictions (left: class setting; middle: decay setting; right: country population ranking). \(n=1,000,000\) for class and decay settings, \(n=263\) for country population ranking.

As depicted in Figure 4.1, our algorithms consistently outperform the baselines in all settings with various task sizes. Specifically, in the class setting with \(n=1,000,000\), Displacement Sort and Double-Hoover Sort outperform all baselines when the number of classes is larger than \(0.05n\). In the decay setting, both our algorithms perform better than the others as time progresses. In the real-world dataset, country population ranking, Displacement Sort needs the fewest comparisons when the given prediction is within 5 years, and Double-Hoover Sort dominates the rest when the prediction is obtained 6 to 60 years ago. These experiments illustrate that the proposed algorithms can leverage positional predictions more effectively than traditional adaptive and non-adaptive sorting algorithms in a variety of settings.

Dirty Comparisons.In some sorting scenarios, some "indicating factors" can be used to cheaply compare two items. For instance, in biology, we can compare the binding affinities of two molecules for a specific target protein and provide information about their potential efficacy as drugs. However, comparisons based on indicating factors may have error induced by element-wise noise. Hence, we consider a two dirty-comparison settings in which a ratio \(r\) of items is damaged. We say a dirty comparison is _perturbed_ if its outcome is uniformly random. In the _Good-Dominating setting_, a dirty comparison between two items is perturbed if both are damaged; in the _Bad-Dominating setting_, a dirty comparison between two items is perturbed if either item is damaged.

In dirty comparisons settings, we use the 3-approximation feedback arc set algorithm proposed by Ailon et al. (2008) to preprocess the dirty comparisons. This algorithm uses \(O(n n)\) dirty comparisons, the same order of magnitude as our Dirty-Clean Sort, to construct a positional prediction that roughly aligns with the given dirty comparisons. Then, we feed in the induced positional prediction to the baselines.

As showcased in Figure 4.2, when \(n=100,000\), in the Good-Dominanting setting, our proposed Dirty-Clean Sort outperforms baselines when \(r 0.7\); in the Bad-Dominating setting, it outperforms other algorithms when \(r 0.25\). If the damage ratio is large, the prediction becomes chaotic, but still performs essentially no worse than Quick Sort for reasons discussed in Remark A.6 in the Appendix.

## 5 Limitations and Future Work

In the dirty-clean setting, our algorithm still requires a time complexity of \(O(n n)\) due to the processing of \(O(n n)\) dirty comparisons. Consequently, the algorithm is more appropriate for situations where exact comparisons are expensive than for those where comparisons are fast. In the positional prediction setting, Displacement Sort achieves a bound of \(O(_{i}(_{i}^{}+2))\) for both comparison _and_ time complexity, whereas the Double-Hoover sort achieves its guarantee \(O(_{i}(\{_{i}^{i},_{i}^{r}\}+2))\) only for comparison complexity. An intriguing question is whether the latter bound can be achieved for time complexity as well. Another potential limitation is that predictions might not be learnable in some sorting settings; future work could focus on exploring the conditions under which predictions are learnable.

Broader Impact.Our paper proposes efficient sorting algorithms when a predictor is available. We do not expect any negative societal impact.

Figure 4.2: Sorting with dirty comparisons, good- and bad-dominating settings.

Acknowledgments.We thank the anonymous reviewers at NeurIPS and Luke Melas-Kyriazi for their valuable comments.