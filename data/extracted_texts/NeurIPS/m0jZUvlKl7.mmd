# AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties

Xiayan Ji  Anton Xue  Eric Wong Oleg Sokolsky Insup Lee

Department of Computer and Information Science

University of Pennsylvania

Philadelphia, PA 19104

{xjiae,antonxue,exwong,sokolsky,lee}@seas.upenn.edu

Equal contribution.

###### Abstract

Anomaly detection is widely used for identifying critical errors and suspicious behaviors, but current methods lack interpretability. We leverage common properties of existing methods and recent advances in generative models to introduce counterfactual explanations for anomaly detection. Given an input, we generate its counterfactual as a diffusion-based repair that shows what a non-anomalous version _should have looked like_. A key advantage of this approach is that it enables a domain-independent formal specification of explainability desiderata, offering a unified framework for generating and evaluating explanations. We demonstrate the effectiveness of our anomaly explainability framework, AR-Pro, on vision (MVTec, VisA) and time-series (SWaT, WADI, HAI) anomaly datasets. The code used for the experiments is accessible at: https://github.com/xjiae/arpro.

## 1 Introduction

Anomaly detectors measure how much their inputs deviate from an established norm, where too much deviation implies an instance that warrants closer inspection . For example, unusual network traffic may indicate potential malicious attacks that necessitate a review of security logs , irregular sensor readings in civil engineering may suggest structural weaknesses , and atypical financial transactions point to potential fraud . As a benign occurrence, unexpected anomalies in scientific data can also lead to new insights and discoveries .

Although state-of-the-art anomaly detectors are good at catching anomalies, they often rely on black-box models. This opacity undermines reliability: inexperienced users might over-rely on the model without understanding its rationale, while experts may not trust model predictions that are not backed by well-founded explanations. This limitation of common machine learning techniques has led to growing interest in model explainability , particularly in domains such as medicine  and law . We refer to  and the references therein for recent surveys on explainability.

While many anomaly detection methods can localize which parts of the input are anomalous, this may not be a satisfactory explanation, especially when the data is complex. In medicine , heart sound recordings  and EEG brain data  can differ greatly between individuals; in industrial manufacturing, it can be hard to understand subtle defects of PCB for inexperienced workers . Thus, even when the location of the anomaly is known, it may be hard to articulate _why_ it is anomalous. In such cases, it can be helpful to ask the **counterfactual** question: "What _should_ a non-anomalous version look like?" For example, a doctor might ask what changes in a patient's chest X-ray might improve diagnostic outcomes , while a quality assurance engineer may ask what changes would fix the defect .

To answer such counterfactual questions, we begin with two observations. First, anomalies are commonly localized to small regions of the input [13; 38; 73]. Second, recent generative models, e.g., diffusion  models, can be trained to produce high-quality, non-anomalous examples. These observations motivate us to _repair anomalies_ as a _counterfactual explanation_. However, simply generating a repair is not sufficient; we must also ensure its quality. For example, it may be undesirable for a repair to significantly improve the anomaly score but barely resemble the original input. Therefore, it is important to measure the quality of repairs using _formal properties_.

However, formalizing broadly applicable properties is challenging, as different domains (e.g., vision, time series) and tasks (e.g., manufacturing, security) have unique considerations. To overcome this, we further observe that many anomaly detectors in practice  satisfy a condition that we call _linear decomposability_: the overall anomaly score is an aggregation of feature-wise anomaly scores. Importantly, this is a strong but common condition with which we may formalize the desiderata of counterfactual explanations. Conveniently, many of these desiderata are, in fact, domain-independent. We leverage these conditions to formalize a general, domain-independent framework for counterfactual anomaly explanation: we use a generative model to produce a repair and then evaluate this repair with respect to the detector model.

We present an overview of our anomaly explainability framework, AR-Pro, in Figure 1. While anomaly repair [21; 31; 70] and counterfactual explanations  have been explored in the literature, we are the first to study this in a unified context. We summarize our contributions as follows:

* We observe that many anomaly detectors satisfy _linear decomposability_ and use this condition to define general, domain-independent properties for counterfactual explanations. This approach lets us measure explanation quality with respect to the anomaly detector, as shown in Figure 1.
* We use these properties to guide diffusion models towards a high-quality repair of the anomalous input. Such a repair serves as the counterfactual explanation of the anomaly.
* Our framework, AR-Pro, can produce semantically meaningful repairs that outperform off-the-shelf diffusion models with respect to our explainability criteria. Our vision anomaly benchmarks include MVTec  and VisA . Our time-series anomaly benchmarks include SWaT , HAI , and WADI .

## 2 Overview and Formal Properties

In Section 2.1, we first observe that many anomaly detector paradigms are _linearly decomposable_. Intuitively, this condition means that the overall anomaly score is an aggregation of feature-wise anomaly scores. Next, we use linear decomposability in Section 2.2 to formalize general, domain-independent properties of counterfactual explanations. We will use the terms _counterfactual_, _explanation_, and _repair_ interchangeably throughout this paper.

Figure 1: Overview of the AR-Pro framework. We first identify an inputâ€™s anomalous region and then use property-guided diffusion to repair it. This repair is the counterfactual anomaly explanation, where the following properties are defined with respect to a _linearly decomposable_ anomaly detector (AD). (_Overall Improvement_) The repair has a lower anomaly score. (_Similarity_) The repair should resemble the original. (_Localized Improvement_) The score over the repaired region should improve. (_Non-degradation_) The score over the non-anomalous region should not significantly worsen.

### Common Anomaly Detectors are Linearly Decomposable

Many anomaly detection techniques use a scoring function \(s:^{n}\) to measure the anomalousness an input \(x^{n}\), where \(s(x)\) is called the _anomaly score_ of \(x\). This is commonly done in a two-stage process: the _feature-wise anomaly scores_\(_{1}(x),,_{n}(x)\) are first computed and then aggregated . We observe that this aggregation often satisfies the following form:

**Definition 2.1** (Linear Decomposition).: The feature-wise anomaly scores \(:^{n}^{n}\) and regularizer \(:^{n}\)_linearly decomposes_ the anomaly score \(s:^{n}\) if for all \(x^{n}\):

\[s(x)=_{1}(x)++_{n}(x)+(x).\]

While linear decomposability appears to be a strong assumption, it is common in practice. We show a number of examples below, where we also flexibly refer to \(:^{n}^{n}\) as the _feature scores_.

**Example 2.2**.: In reconstruction-based anomaly detection [8; 29], the input \(x\) is passed through an encoder-decoder architecture to generate a _reconstruction_\(\). The motivation is that it should be harder to reconstruct out-of-distribution (anomalous) inputs. Empirically, it is observed that if \(x\) is anomalous, then \(\) will have a large reconstruction error when feature \(i\) is in the anomalous region, e.g., a pixel in the defect area of a manufacturing artifact image. A typical example of such an anomaly score is:

\[s(x)=|_{1}-x_{1}|^{2}++|_{n}-x_{n}|^{2},\]

which is also known as the \(^{2}\) reconstruction error. This lets us define the feature-wise anomaly scores by \(_{i}(x)=|_{i}-x_{i}|^{2}\), and we illustrate this example in Figure 2.

**Example 2.3**.: In maximum likelihood-based anomaly detection , one measures the likelihood of a test input \(x\) with respect to a set of non-anomalous training examples. Intuitively, an out-of-distribution (anomalous) \(x\) should be unlikely with respect to the non-anomalous training examples and will thus have a lower likelihood. In variants such as normalizing flow-based anomaly detection for images , it is common to define a joint probability distribution over all the features:

\[s(x)=- p_{1}(x)++ p_{n}(x)+ J(x) ,\]

where \(p_{1}(x),,p_{n}(x)\) are the probabilities of each feature that lets us define \(_{i}(x)=- p_{i}(x)\), while the change-of-variable Jacobian \( J(x)\) may be viewed as a regularization term.

**Example 2.4**.: In language modeling , it is common to measure the anomaly of a token sequence based on the likelihood of each token . Although similar to the vision case, the standard formulation for language models is different: given a token sequence \(x_{1},,x_{n}\{1,,\}\), its measure of unlikeliness (anomalousness) may be defined as:

\[s(x)=- p(x_{1})+ p(x_{2}|x_{1})+ p(x_{3}|x_{1},x _{2})++ p(x_{n}|x_{1},,x_{n-1}),\]

where \(p\) is a probabilistic generative model, and so \(_{i}(x)=-(1/n) p(x_{i}|x_{1},,x_{i-1})\). This is also known as a _preplexity measure_, which has been used to detect jailbreak against LLMs .

Beyond the above examples, anomaly detectors for time-series data [29; 60; 63] and text  also commonly use this convention. We further remark that the feature-wise anomaly scores \(\) are related to _feature attribution scores_ in explainability literature [33; 51; 55].

Figure 2: Reconstruction-based anomaly detection exemplifies linear decomposition. The anomalous input \(x^{n}\) is first reconstructed into \(^{n}\), and the feature-wise anomaly scores are given by \(_{i}(x)=|_{i}-x_{i}|^{2}^{n}\) for \(i=1,,n\). Then, the standard \(^{2}\) reconstruction-based anomaly score is a linear combination of the feature scores: \(s(x)=_{1}(x)++_{n}(x)\).

### Formal Properties for Counterfactual Explanations

We now present the formal properties of counterfactual explanations. We will assume a given anomaly score function \(s\) that is linearly decomposed by the feature-wise score function \(\) and regularizer \(\). Given some input \(x\), it is common to convert \((x)^{n}\) into a binary-valued vector \((x)\{0,1\}^{n}\) to classify which input feature is anomalous, and this is commonly done by a threshold:

\[(x)=(_{1}(x)_{1},,_{n}(x)_{n}), ^{n}.\]

A binarization of the feature-wise scores suggests the need for region-specific anomaly scores, which we implement with the following indexing scheme on \(s(x)\):

\[s_{z}(x)=(x)+_{i:z_{i}=1}_{i}(x),z\{0,1\}^{n}.\]

Then, the anomalous and non-anomalous regions have scores \(s_{(x)}(x)\) and \(s_{(x)}(x)\), respectively, where \((x)=1-(x)\) denotes non-anomalous region. We next enumerate some common desiderata of counterfactual explanations, where we will refer to the anomalous input as \(x_{}\) and the repaired version as \(x_{}\).

**Property 1** (Overall Improvement): The anomaly score should improve.: Because a "repaired" version should fix the anomaly by definition, one would reasonably expect that:

\[s(x_{})<s(x_{}).\] (P1)

**Property 2** (Similarity): The repair should resemble the original.: When \(s\) is generated by a complex machine-learning model, it may be the case that it has a value \(x_{}\) where \(s(x_{}) s(x_{})\), but \(x_{}\) and \(x_{}\) bear little resemblance. In the case of vision models, \(x_{}\) may even resemble static noise. Such extreme dissimilarities between \(x_{}\) and \(x_{}\) are not desirable because a user cannot be expected to feasibly interpret this information. Thus, we desire a similarity condition as:

\[(x_{}) x_{} (x_{}) x_{},\] (P2)

where \(\) denotes element-wise vector multiplication. This similarity condition states that the non-anomalous regions of the original and the repair, as given by \((x_{})\), should remain similar.

**Property 3** (Localized Improvement): The anomalous region should improve.: However, P1 and P2 are not sufficient. For example, one might have \(s(x_{})<s(x_{})\), but have a higher score on the anomalous region \((x_{})\). This is not desirable because it means that \(x_{}\) has not actually fixed the anomalous region of \(x_{}\). To ensure progress, we would like:

\[s_{(x_{})}(x_{})<s_{(x_{})}(x_{ }).\] (P3)

**Property 4** (Non-degradation): The non-anomalous region should not significantly worsen.: Even when the above properties are satisfied, it is possible that the proposed repair could inadvertently increase the anomaly score on the non-anomalous region \((x_{})\). This would mean repairing the anomalous region at the cost of corrupting the non-anomalous parts. We thus state the property against this as follows, where \(_{4}>0\) is a given tolerance threshold:

\[s_{(x_{})}(x_{}) s_{ (x_{})}(x_{})+_{4}.\] (P4)

The benefit of our above formulation is that it encapsulates general, domain-independent desiderata of anomaly repairs. Importantly, this is achieved under the mild assumption of a linearly decomposable anomaly detector. We comment that some overlap among our proposed formal properties may arise in certain scenarios, and alternative sets could be more tailored for specific applications. Our goal, however, is to provide a foundational set of properties that ensures broad applicability, allowing further customization to suit individual application needs.

## 3 Property-guided Generation of Counterfactual Explanations

We now outline the process of conducting a property-guided repair for an anomalous input. In Section 3.1, we first introduce the generalized setup, where we define the four previously outlined properties as objective functions and frame the problem using risk-constrained optimization. Although this formulation clarifies the objectives, it is generally intractable. Therefore, in Section 3.2, we propose a diffusion-based algorithm to approximate the solution and achieve high-quality repairs.

### A Generalized Formulation with Properties as Loss Functions

We first present a generalized setup for generating repairs. We conceptualize this in terms of a repair model \(_{s,}\) parametrized by an anomaly score function \(s:^{n}\) with known linear decompositions \(,\) and a feature-wise binarization \(\). To generate a repair, we sample the model:

\[x_{}_{s,}(x_{}),\]

where a probabilistic formulation is relevant in the context of variational auto-encoders  or diffusion models . However, it is important that \(x_{}\) obeys the formal properties as outlined in Section 2.2. To do this, we cast these properties as loss functions listed below:

\[L_{1} =s(x_{})\] (P1 loss) \[L_{2} =(x_{})(x_{}-x_{})_{2}\] (P2 loss) \[L_{3} =0,\,s_{(x_{})}(x_{})-s_{ (x_{})}(x_{})}\] (P3 loss) \[L_{4} =0,\,s_{(x_{})}(x_{ {fix}})-s_{(x_{})}(x_{})-_{4}}\] (P4 loss)

Our rationale is as follows. First, because the primary objective of anomaly repair is to reduce the anomaly score, we set \(L_{1}\) as simply the score of \(x_{}\). Second, we would like to ensure that \(x_{}\) and \(x_{}\) are similar in the non-anomalous region, and so formulate \(L_{2}\) as the \(^{2}\) distance between \(x_{}\) and \(x_{}\) over \((x_{})\). Third, we formulate \(L_{3}\) to apply a penalty when the anomalous region degrades in performance. Fourth, we allow for a degradation of score in the non-anomalous region \((x_{})\), up to some tolerance threshold \(_{4}\). We cast these as a risk-constrained optimization problem as follows:

\[} *{}_{x_{}_{s, }(x_{};)}s(x_{})\] (1) subject to \[*{}_{x_{}_{s, }(x_{};)}L_{2}_{2},\,\,\,L_{3} 0,\,\,\,L_{4} 0 1-\]

where \(\) is a parameter of the repair model, \(_{2}>0\) is a given threshold for \(L_{2}\) and \(>0\) is a given failure probability for the violation of at least one of (P2), (P3), or (P4). We acknowledge that multiple formulations for property-based losses are valid; however, the chosen approach is optimally suited to our context.

### Formal Property-guided Diffusion

We adopt techniques from guided diffusion  to generate repairs \(x_{}\). We first give a brief overview of a standard diffusion process and then adapt it to perform property-guided generation. We refer to  for a comprehensive guide on diffusion but attempt to make the exposition self-contained.

**Background.** A basic variant of diffusion models takes the form:

\[p(x_{t-1}|x_{t})=(_{}(x_{t},t),b_{t}^{2}I),t=T,,1,\] (2)

where \(_{}\) is the _denoising model_ with parameters \(\), and \(b_{1}<<b_{T}\) is the variance schedule. When \(_{}\) is trained on non-anomalous data (see  for training details), one can generate non-anomalous samples of the training distribution by running the following iterative process:

\[x_{T}(0,I), x_{t-1}=_{}(x_{t},t)+b_{t}z_{t}, z _{t}(0,I),t=T,,1,\] (3)

where \(x_{T}\) is the initial noise and \(x_{0}\) is the output sample. The idea is to repeatedly remove noise from a Gaussian \(x_{T}\) using \(_{}\) until the final \(x_{0}\) resembles a high-resolution image without defects, for instance. The iterations (3) is also known as _backward process_.

**Property-guided Diffusion.** We next show how to adapt the denoising iterations (3) to produce repairs. We use two main ideas: first, we use guidance  to slightly nudge the iterates \(x_{t-1}\) of (3)

Figure 3: We run property-guided diffusion with masked in-filling.

at every step using a property-based loss, to encourage that the final iterate \(x_{0}\), which we take to be \(x_{}\), is more amenable to our properties. Second, we used masked-infilling  to ensure that the non-anomalous region \((x_{})\) is generally preserved by the iterates. We implement this modified iteration as follows: beginning from the initial noise \(x_{,T}(0,I)\), let:

\[_{,t-1} =(x_{,t},t)+b_{t}z_{t}}_{ {Denoising step}}- L(x_{,t})}_{}, z_{t}(0,I),\] (4) \[x_{,t} =}x_{}+}_{t}, _{t}(0,I),\] (5) \[x_{,t-1} =(x_{}) x_{,t}+ (x_{})_{,t-1},\] (6)

for \(t=T,,1\), where \(a_{t}=_{i=1}^{t}(1-b_{i})\) and \(_{1}<<_{T}\) is the guidance schedule. The property-based loss is given by:

\[L(x_{,t})=_{1}L_{1}+_{2}L_{2}+_{3}L_{3}+ _{4}L_{4},\] (7)

with \(L_{1},L_{2},L_{3},L_{4}\) as in Section 3.1 and weights \(_{1},_{2},_{3},_{4}>0\). In the above, (4) first generates \(_{,t-1}\) from \(x_{,t}\) by combining a standard denoising step with a guidance term. Then, (6) combines \(_{,t-1}\) with \(_{,t}\), from (5), in a masked-infilling operation  to yield \(x_{,t-1}\). This masked in-filling ensures similarity between \(x_{}\) and \(x_{}\) (i.e., \(x_{,0}\)) over the non-anomalous region \((x_{})\).

We emphasize that the diffusion iterations given by (4), (5), (6), and do not guarantee the satisfaction of our formal properties. Rather, these iterations tend toward an output that better respects these properties -- as we later shown in our experiments. In particular, our property-based losses define a way to evaluate the quality to which each property is satisfied or violated.

## 4 Experiments

Our experiments evaluate the performance of AR-Pro across vision and time-series datasets. In particular, we aim to address the following research questions:

* **(RQ1) Empirical Validation**: How well does AR-Pro repair anomalies for different domains? In particular, we investigate how well the four properties are satisfied when the diffusion process is guided or unguided, as in the baseline.
* **(RQ2) Ablation Study**: How do the different hyper-parameters affect the repair quality? We focus on the weights \(_{1},_{2},_{3},_{4}\) for the four property-based losses.

**Vision Anomaly Models and Datasets.** For anomaly detectors, we used the anomalib  implementation of Fastflow  (with ResNet-50-2 backbone ) and Efficient-AD . For datasets, we used the VisA  and MVTec-AD  datasets. VisA and MVTec-AD involve anomaly detection in the context of industrial manufacturing, where VisA consists of 12 image classes, and MVTec-AD consists of 15 image classes. Both FastFlow and Efficient-AD were trained with AdamW and a learning rate of \(10^{-4}\) until convergence.

**Time-series Anomaly Datasets and Models.** For anomaly detectors, we used the GPT-2  and Llama2  architectures for time-series anomaly detection. In particular, we use only the first 6 layers of GPT-2 and the first 4 layers of Llama-2 (with an embedding dimension of 1024) to accelerate training. For datasets, we used the SWat (51 features) , HAI (86 features) , and WADI (127 features)  datasets, split into sliding windows of size 100. Both our versions of GPT-2 and Llama-2 were trained with AdamW and a learning rate of \(10^{-5}\) until convergence.

**Diffusion-based Repair Models.** We used the HuggingFace implementation of DDPM  for vision data and Diffusion-TS  for time-series data. Both models were trained on the non-anomalous instances of their respective datasets using AdamW and a learning rate of \(10^{-4}\) until convergence.

**Evaluation Metrics.** We use the four property-based loss functions defined in Section 3.1 as our evaluation metrics. In particular, we measure the improvement of property-guided diffusion over un-guided diffusion. We adapt these metrics below, where we write \(\) to mean \((x_{})\) for brevity:

* **Property 1 (Overall Improvement):**\(M_{s} s(x_{})\).
* **Property 2 (Similarity):**\(M_{d}\|(x_{}-x_{})\|_{2}\)
* **Property 3 (Localized Improvement):**\(M_{} s_{}(x_{})-s_{}(x_{})\)
* **Property 4 (Non-degradation):**\(M_{} s_{}(x_{})-s_{}(x_{})\)

[MISSING_PAGE_FAIL:7]

example in Figure 4, we observe that for categories PCB 1, PCB 2, PCB 3, and PCB 4, the baseline fails to rigorously repair the anomaly: the orientation of the board is reversed for PCB 1; unintended white marks appear on the lower left of PCB 2; the dark lines in the potentiometer change for PCB 3; and the "FC-75" label is missing for PCB 4. However, by integrating formal property guidance, our approach accurately reconstructs all these details while effectively removing the anomalies. For the MVTec-AD examples, AR-Pro produces repairs that more closely resemble the original inputs compared to those generated by the baseline. This demonstrates that our method's generated repairs adhere more rigorously to the formal properties.

In Figure 6, we present examples from our time-series repair, where the anomalous time segment is shaded in red. Our results demonstrate that AR-Pro generates a signal that resembles the original signal better, as shown in the first two plots of Figure 6. In addition, we recover the sensor time series to non-anomalous values when the baseline fails to repair the anomaly, as shown in the last two plots of Figure 6.

More repair examples are available in Appendix D. However, although the quality of the generated repairs has improved, we notice that this enhancement comes with a trade-off of increased inference time. Further details can be found in Appendix E.

### (RQ2) Ablation Study

We randomly sampled 100 instances to compute the mean of each metric in order to evaluate the effect of hyper-parameters \(_{1},_{2},_{3},_{4}\) associated with each property-based loss. Each line in the plots represents results obtained while keeping the other hyper-parameters at 1.0. The ablation results for the time series are presented in Figure 7, with additional plots in Appendix F.

   &  & ()\)} & ()\)} & ()\)} & ()\)} \\   & & Baseline & Guided & Baseline & Guided & Baseline & Guided & Baseline & Guided \\   & SWAT & 0.83 \(\) 0.05 & 0.99 \(\) 0.04 & 3.05 \(\) 0.61 & 7.25 \(\) 2.50 & 0.084 \(\) 0.026 & 0.026 \(\) 0.008 & 0.19 \(\) 0.02 & 0.05 \(\) 0.012 \\  & WADI & 0.97 \(\) 0.00 & 0.26 \(\) 0.01 & 0.98 \(\) 0.01 & 0.00 \(\) 0.00 & 0.087 \(\) 0.005 & 0.000 \(\) 0.000 & 0.61 \(\) 0.01 & 0.00 \(\) 0.000 \\  & HAI & 0.92 \(\) 0.00 & 0.58 \(\) 0.01 & 0.75 \(\) 0.00 & 0.00 \(\) 0.00 & 0.166 \(\) 0.008 & 0.000 \(\) 0.000 & 0.18 \(\) 0.01 & 0.00 \(\) 0.000 \\   & \(()\) & **-46.36\%** & **-42.77\%** & **-410.32\%** & **-491.23\%** & **+91.23\%** \\   & SWAT & 0.68 \(\) 0.06 & 0.57 \(\) 0.05 & 12.81 \(\) 15.82 & 16.28 \(\) 16.30 & -0.029 \(\) 0.041 & -0.094 \(\) 0.038 & 0.13 \(\) 0.04 & 0.09 \(\) 0.031 \\  & WAID & 0.71 \(\) 0.04 & 0.32 \(\) 0.00 & 34.45 \(\) 0.06 & 0.42 \(\) 0.94 & 0.018 \(\) 0.003 & 0.019 \(\) 0.002 & 0.43 \(\) 0.04 & 0.07 \(\) 0.002 \\  & HAI & 0.92 \(\) 0.02 & 0.61 \(\) 0.11 & 3.69 \(\) 9.72 & 5.67 \(\) 18.80 & 0.136 \(\) 0.050 & -0.005 \(\) 0.018 & 0.21 \(\) 0.03 & 0.01 \(\) 0.127 \\   & \(()\) & **+34.93\%** & **-34.37\%** & **+177.79\%** & **+37.24\%** \\   &  &  &  &  &  &  &  & \\ 

Table 2: Comparison of baseline and guided performance across four metrics for SWAT, WADI, and HAI dataset categories with Llama2 and GPT2 model. \(\) is the median improvement percentage of the guided result from baseline.

  Dataset & Category & Baseline TNR (\(\)) & Guided TNR (\(\)) & Category & Baseline TNR (\(\)) & Guided TNR (\(\)) \\   & Candle & **1.00** & **1.00** & Fryum & 0.66 & **1.00** \\  & Capsules & 0.00 & **1.00** & Pipe Fryum & **1.00** & **1.00** \\  & Cashew & **1.00** & **1.00** & PCB 1 & **1.00** & 0.96 \\  & Chewinggum & **1.00** & **1.00** & PCB 2 & 1.00 & **1.00** \\  & Macaroni 1 & 0.11 & **1.00** & PCB 3 & 0.90 & **1.00** \\  & Macaroni 2 & 0.52 & **1.00** & PCB 4 & 0.18 & **1.00** \\   & Bottle & **1.00** & **1.00** & Grid & 0.00 & **1.00** \\  & Cable & **1.00** & **1.00** & Hazelnut & **1.00** & **1.00** \\  & Capsule & **1.00** & **1.00** & Leather & **1.00** & **1.00** \\  & Carpet & **1.00** & **1.00** & Metal Nut & **1.00** & **1.00** \\  & Pill & **1.00** & **1.00** & Screw & **1.00** & **1.00** \\  & Tile & **1.00** & **1.00** & Toothbrush & **1.00** & 0.96 \\  & Transistor & 0.56 & **1.00** & Wood & **1.00** & **1.00** \\  & Zipper & **1.00** & **1.00** & & \\   & VisA & 0.95 & **1.00** & MVTec-AD & **1.00** & **1.00** \\  & SWAT & 0.08 & **0.86** & HAI & 0.00 & **1.00** \\   & WADI & 0.00 & **1.00** & & \\  

Table 3: True Negative Rate (TNR) for categories in the vision (VisA, MVTec) and time-series (SWaT, HAI, and WADI) anomaly detection datasets.

Our observations indicate that variations in the scale of property hyperparameters do not significantly impact the formal metrics, as the range of change remains relatively small. In addition, no consistent trends were observed when varying the \(_{1},_{2},_{3},_{4}\) hyper-parameters. This suggests that our framework demonstrates robust performance, and extensive tuning may be unnecessary.

## 5 Related Work

Numerous techniques have been developed for anomaly detection across various domains [3; 49]. Traditional approaches to anomaly detection include clustering [43; 57] and statistical methods  such as ARIMA  and Gaussian models . However, these methods often struggle with high-dimensional data. More recently, deep learning-based anomaly detection [20; 28], including autoencoders  and GANs , can detect high-dimensional anomalies via reconstruction error. For time-series data, LSTMs  and transformer-based models [60; 63; 69; 72] have shown exceptional performance. Additionally, diffusion models are emerging as promising tools for visual anomaly detection [42; 71]. While these methods vary in strengths and are continually improving, explaining

Figure 4: The original input and ground truth anomaly mask are displayed in the first two columns. The baseline method fails to preserve close similarity to the input PCB boards, as highlighted in the third column. Guided vision repair examples in the fourth column address these deficiencies.

Figure 5: MVTec repairs with AR-Pro; better resemble the original compared to the baseline.

anomalies remains a challenge . Most current methods rely on feature importance scores or visualizations , such as gradients or reconstructions , which often fail to provide actionable insights. The lack of formal frameworks  and consistent evaluation metrics  complicates this issue. For example, the absence of formal metrics leads to inconsistencies in evaluation , underscoring the need for more rigorous approaches and reliable criteria . Most similar to our work is , which also performs time series-specific generation of counterfactual explanations in the form of anomaly repairs but considers a different set of properties and does not use diffusion. Our work also focuses on generative modeling to produce counterfactual explanations in the form of anomaly repairs. For vision, the current leading paradigms are diffusion models  and generative adversarial networks . Diffusion models are also applicable to time-series data , and we refer to  for a survey on other techniques.

## 6 Discussion

The main theoretical contribution of our work is the identification of common counterfactual explanation desiderata for linearly decomposable anomaly detectors. While we have identified four formal properties, we acknowledge that other valid ones may also exist. Moreover, we recommend that practitioners evaluate and choose the properties necessary for the particular problem, and this is made possible by the form of our diffusion guidance function in (7). The quality of anomaly repairs depends on the performance of the anomaly detector and the generative model. While there may have been limitations in our efforts, we found it challenging to use variational auto-encoders  for generating high-quality repairs. Furthermore, our implementation is focused on diffusion models, but the ideas presented can also be extended to other generative techniques.

## 7 Conclusion

We present AR-Pro, a framework for generating and evaluating counterfactual explanations in anomaly detection. We use the fact that common anomaly detectors are linearly decomposable, which lets us define formal, general, domain-independent properties for explainability. Using these properties, we show how to generate high-quality counterfactuals using a property-guided diffusion setup. We demonstrate the effectiveness of AR-Pro on vision and time-series datasets and showcase our improvement over off-the-shelf diffusion models.

AcknowledgementThis work was supported in part by ARO MURI W911NF2010080, NSF-2125561, and NSF-2143274.

Figure 6: Original input is the blue line, property guided fix is the green line, and the baseline is the red line. The first image shows that the baseline generates a spurious signal when there is no anomaly. The second image shows that the baseline repairs the anomaly, but not as effectively as with guidance. The last two images show instances where the baseline fails to repair the anomaly.

Figure 7: Varying the hyper-parameters does significantly change \(M_{s}\), \(M_{d},M_{}\), and \(M_{}\).