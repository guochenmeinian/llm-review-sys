# [MISSING_PAGE_EMPTY:1]

[MISSING_PAGE_EMPTY:1]

except in cases where the student guesses correctly. Representative neural-based CD models, such as NCDM , KaNCD  and KSCD , explicitly model the explicit relationship between exercise and knowledge concepts to constrain student proficiency during diagnostic processes. Despite the success of these models, they share a common assumption that the knowledge concepts of each exercise are fully labeled. However, the annotation of exercises is a labor-intensive task that requires the expertise of professionals. There are always many exercises involved in intelligent education systems, and the workload for annotation significantly increases with the number of exercises. Thus, a more practical scenario is cognitive diagnosis with limited exercise labels.

Performing cognitive diagnosis using limited exercise labels is indeed an under-explored area in current research. When faced with the few labeled exercise, a straightforward approach is to prefill the Q-matrix in order to provide a complete Q-matrix as input to an existing CD model. One limitation of this method is that its effectiveness largely depends on the accuracy of the pre-filling algorithm. If the pre-filling algorithm fails to identify the knowledge concepts associated with each exercise correctly, the resulting filled Q-matrix may be inaccurate or incomplete, which can negatively impact the model's diagnostic performance. Therefore, how to achieve interpretable diagnosis on specific knowledge concepts with limited exercise labels remains a challenge.

In this work, we propose _Disentanglement based Cognitive Diagnosis (DCD)_ to address the challenges posed by limited exercise labels. Specifically, DCD is a semi-supervised disentanglement method to model the students' proficiency with limited exercise labels. To achieve this, we utilize historical practice records to model student proficiency, exercise difficulty, and exercise relevance on each knowledge concept. Then, we introduce two novel modules - the group-based disentanglement module and the limited-labeled alignment module - to disentangle factors relevant to knowledge concepts and align them with real limited exercise labels. Particularly, we introduce the tree-like structure of concepts (shown in Fig. 1-(b)) for group-based disentangling, as concepts of different levels exhibit different independence relationships. The knowledge concept tree reduces the workload required for annotating knowledge concepts, as there are far fewer concepts than exercises to annotate. These modules work together can deal with the limited exercise labels and diagnose the student's proficiency on each concept with interpretability. The main contributions of this work are summarized as follows:

* Our work represents one of the few attempts to focus on the problem of limited exercise labels in cognitive diagnosis, which is common in real-world practice.
* We propose a semi-supervised disentanglement approach to address the challenge of cognitive diagnosis with limited exercise labels.
* We conduct extensive experiments under different few-labeled settings on three real-world datasets, which demonstrates the effectiveness of our proposed DCD model.

## 2 Related Work

### Cognitive Diagnosis in Intelligent Education Systems

The early CD works like IRT  and MIRT  focus on modeling students' answering process by predicting the probability of a student answering a question correctly, which utilizes latent factors as

Figure 1: Example of cognitive diagnosis. (a) We show an example to demonstrate the CD process, using a fully-labeled Q-matrix annotated by domain experts. (b) Tree-like structure of concepts is easily annotated with negligible cost as the number of concepts is far fewer than that of exercises.

the student's ability. IRT and MIRT are also known as Latent Factor Models (LFM). The obvious limitation of the above models is the lack of interpretability, i.e., the inability to obtain an explicit multidimensional diagnostic report on each knowledge concept. To achieve better interpretability, later diagnostic models focus on incorporating knowledge concepts of exercises to diagnose students' proficiency in all knowledge concepts [8; 38; 6; 47; 21]. Representative NCDM  adopts neural networks to model non-linear interactions instead of handcrafted interaction functions in previous works [10; 35]. However, researchers find that the free student proficiency vector learning paradigm in NCDM is not capable of tackling weak-knowledge-coverage scenario and model relation among knowledge concepts implicitly to address the problem [39; 30].

**Cognitive Diagnosis in Few-labeled Scenarios.** Most existing CD models are unable to directly deal with the few-labeled scenarios, and assume that the exercises are fully labeled. NCDM+  fills the missing knowledge concepts by TextCNN  from the exercise's text information, which regards it as a previous task for CD. Therefore, the performance of CD lies in the accuracy of pre-filled knowledge concepts. In this work, we focus on a more challenging scenario of missing exercise textual information and infer missing knowledge concepts from response records only.

### Disentangled Representation Learning

Disentangled Representation Learning (DRL) is an important learning paradigm that aims to disentangle the underlying generative factors hidden in the observed data into the latent variables in the representation . One notable benefit attributed to DRL is its ability to extract latent factors that embody semantic meanings, thus enhancing the interpretability of machine learning models. Both VAE  and GAN  based DRL are widely adopted techniques. Considering that the training of VAE is more stable than that of GAN [17; 45], in this work, we extend the VAE framework and focus on learning interpretable disentangled representations to help cognitive diagnosis.

**VAE-based Disentangled Representation Learning.**\(\)-VAE  modifies the Evidence Lower Bound (ELBO) of VAE  by adding a hyperparamter \(\) on KL term and find that a larger \(\) corresponds to the better disentanglement of latent code. However, the increasing \(\) would also lead to the worse reconstruction error dramatically [17; 36]. To analyze the trade-off between reconstruction accuracy and the quality of disentangled representation, both FactorVAE  and \(\)-TCVAE  show that the success of \(\)-VAE in learning disentangled representations can be attributed to penalizing the Total Correlation (TC) term. \(\)-TCVAE decomposes the expected KL term in ELBO into index-code MI term, TC term, and dimension-wise KL term. The TC term would decrease the mutual information among factors and improve independence among latent factors, which results in better disentanglement. However, some researchers claim that the above unsupervised learning of disentangled representations is fundamentally impossible without inductive biases as sometimes the target dataset is not semantically clear and well-structured to be disentangled . Hence, more works focus on weak-supervised approaches [28; 37] and semi-supervised [29; 16]. A theoretical framework is provided to assist in analyzing the disentanglement guarantees by weak supervision methods (e.g. restricted labeling, match pairing, and rank pairing) . Some researchers validate that with little and imprecise supervision (e.g. manual labeling of factors) it is possible to reliably learn disentangled representations . In this work, we regard limited exercise labels as a semi-supervision to help disentangle knowledge concepts-related factors.

**Disentangled Representation Learning for User Modeling.** User modeling  aims to capture a number of attributes of each user, with the help of items, item features and/or user-item response matrix , etc. DRL has a wide range of applications in user modeling to disentangle attributes. For example, recommendation with several aspects of users' interests [23; 31; 46; 40], fair user representation to disentangle sensitive attributes [7; 34].

## 3 Problem Formulation

Let \(=\{u_{1},u_{2},,u_{N}\}\), \(=\{v_{1},v_{2},,v_{M}\}\), and \(=\{k_{1},k_{2},,k_{K}\}\) denote the sets of students, exercises, and knowledge concepts, respectively, where \(N\), \(M\), and \(K\) represent the size of each set. The response records are denoted as \(=\{X_{ij}\}_{N M}\), where \(X_{ij}\) equals 1, 0 or -1 representing that the student answered the exercise correctly, incorrectly, or did not answer the exercise, respectively. The relationship between exercises and knowledge concepts is represented by the Q-matrix \(=\{Q_{ij}\}_{K M}\). Typically, each exercise is related to multiple knowledge concepts.

\(Q_{ij}\) equals 1 or 0 representing that exercise \(v_{j}\) is related to the knowledge concept \(k_{i}\) or not. In this work, we explore the few-labeled situation, that is, there are only a few exercises that are labeled. Thus, we split exercise set \(\) into the labeled set \(_{1}\) and the unlabeled set \(_{2}\).

There are correlations and independence among different knowledge concepts. In our work, we introduce the knowledge concept tree  to model their relations at different levels. By utilizing this tree structure, we can effectively capture knowledge concepts' interrelationships. For convenience, we transform the knowledge concept tree into a standard tree (the height of all subtrees of any node in the tree is equal). For more details about knowledge concept tree, please see Appendix C. Suppose we construct a standard tree \(G\) with \(L\) levels, wherein its leaf nodes are denoted by the set \(=\{k_{1},k_{2},,k_{K}\}\). Each level of knowledge concept can be regarded as a grouping of the last level of knowledge concepts. The deeper the level, the finer the granularity of the grouping. Let \(G^{i}=\{G_{1}^{i},G_{2}^{i},,G_{|G^{i}|}^{i}\}\) denote grouping method of the \(i\)-th level knowledge concepts, where \(i=1,2,,L\) and \(|G^{i+1}||G^{i}|\). Therefore, \(G^{1}=\{G_{1}^{1}=\}\) and \(G^{L}=\{G_{1}^{L}=\{k_{1}\},G_{2}^{L}=\{k_{2}\},,G_{K}^{L}=\{k_{K}\}\}\).

**Problem Definition.** In an intelligent education system, given student set \(U\), exercise set \(=_{1}_{2}\), knowledge concepts \(\), response records \(\), knowledge concept tree \(G\) and incomplete Q-matrix, our goal is to diagnose students' cognitive states on knowledge concept set \(\) with few-labeled exercises, and predict the scores of students doing exercises.

## 4 The Proposed Model

In cognitive diagnosis, it is crucial to determine whether a student has the proficiency in knowledge concepts required to answer an exercise correctly. This becomes even more challenging when there are limited exercise labels available. To model students' proficiency with few-labeled exercises, we design disentanglement and alignment modules that can effectively utilize the weak supervision of a few labeled exercises.

The overall framework of DCD is illustrated in Fig. 2, including input, encoder, disentanglement, alignment, and decoder. The input of DCD contains the student-exercise interaction matrix \(\) and the few-labeled matrix \(\). For diagnosing students' cognitive states, we first utilize the encoder module to model three important components from \(\): student proficiency, exercise difficulty, and exercise relevance. Then, we leverage the group-based disentanglement module to separate the factors related to knowledge concepts from the three components mentioned above. Next, the limited-labeled alignment module associates each decoupled factor with a knowledge concept semantic with the missing matrix \(\). Finally, the decoder module predicts the scores based on the student proficiency, exercise difficulty, and exercise relevance. Overall, DCD provides an effective approach for cognitive diagnosis under limited exercise labels.

### Encoder Module

The interaction matrix \(\) provides valuable information regarding student proficiency, exercise difficulty, and exercise relevance from different perspectives. Specifically, 1) From a student-centric (row-wise) perspective, the response records of a student reflect his proficiency on all knowledge concepts. 2) From an exercise-centric (column-wise) perspective, the response records of an exercise reflect exercise difficulty and exercise relevance on all knowledge concepts. On the one hand, to effectively model from two perspectives, we design the student proficiency encoder, exercise difficulty encoder, and exercise relevance encoder modules. On the other hand, following existing cognitive models, an interaction function (corresponding to our decoder) to predict the answering result with student traits and exercise traits as input (corresponding to our encoders), which ensures the interpretability of student proficiency representation. Traditional single encoder is not applicable for cognitive diagnosis.

**Student Encoder.** The student encoder module is intended to infer student's proficiency on each knowledge concept from \(\), which models true posterior distribution \(p(_{u}|_{u})\) by constructing an inference network \(f_{_{u}}(_{u})\) corresponding to approximate posterior distribution \(q_{_{u}}(_{u}|_{u})\), parameterized by \(_{u}\). We assume student's proficiency on all knowledge concepts \(_{u}\) follows a multivariate standard Gaussian distribution prior, i.e., \(p(_{u})(,)\). The approximate posterior for \(K\)-dimensional latent code \(_{u}^{K}\) is expressed as follows:

\[q_{_{u}}(_{u}|_{u})=_{k=1}^{K}(_{u}[k];_{u}[k],_{u}[k]),\] (1)

where \(_{u}^{K}\) and \(_{u}^{K}_{>=0}\) are generated from student encoder \(f_{_{u}}(_{u})\). The \([]\) indicates the index selection operation.

**Exercise Encoders.** We design two encoders at exercise side: exercise difficulty and exercise relevance encoders. The two encoders aim to infer exercise's difficulty and exercise's relevance on each knowledge concept from \(\), respectively. For exercise difficulty encoder, we assume exercise's difficulty on all knowledge concepts \(_{o}^{_{o}^{}}\) follows a multivariate standard Gaussian distribution prior similar to the student encoder, i.e., \(p(_{v}^{})(,)\).

We assume exercise's relevance on all knowledge concepts \(_{v}^{r}\) follows a multivariate Bernoulli prior, i.e. \(p(_{v}^{r}) Bernoulli()\), where \(\) is a hyperparameter. The exercise relevance encoder models true posterior distribution \(p(_{v}^{r}|_{v})\) by constructing an inference network \(f_{_{v}^{r}}(_{v})\) corresponding to approximate posterior distribution \(q_{_{v}^{r}}(_{v}^{r}|_{v})\), parameterized by \(_{v}^{r}\). The approximate posterior for K-dimensional latent code \(_{v}^{r}\{0,1\}^{K}\) is expressed as:

\[q_{_{v}^{r}}(_{v}^{r}|_{v})=_{k=1}^{K}Bernoulli( _{v}^{r}[k];_{v}^{r}[k]),\] (2)

where \(_{v}^{r}^{K}\) are generated from exercise encoder \(f_{_{v}}(_{v})\).

### Group-based Disentanglement Module

The representations obtained by the encoder module do not relates to the knowledge concepts, which makes it difficult to perform an accurate cognitive diagnosis. To address this issue, we assume the entire response records as evolving from three groups of generative factors: student proficiency factors on each knowledge concept, exercise difficulty factors on each knowledge concept, and exercise relevance factors on each knowledge concept. We desire to disentangle these factors following existing DRL methods.

Figure 2: The overall framework of the proposed DCD. We first encode student proficiency, exercise difficulty, and relevance vectors from studentsâ€™ historical response records. Then, we devise two novel modules ( i.e., the group-based disentanglement and the limited-labeled alignment modules) to disentangle factors relevant to knowledge concepts and align them with real limited exercise labels. Finally, the decoder module predicts the scores based on the student proficiency, exercise difficulty, and exercise relevance.

Inspired by the outstanding performance of \(\)-TCVAE  in disentanglement, we introduce the structure of \(\)-TCVAE to obtain a better trade-off between the reconstruction accuracy and the quality of disentangled representation. We find the index-code term of \(\)-TCVAE plays a side effect on performance and drop it during optimization like [32; 7]. Take student proficiency factors as an example, the eventual Total Correlation (TC) constraint on \(_{u}\) can be expressed as follows:

\[_{d}(_{u})=D_{KL}(q(_{u})||_{i=1}^{K}q( _{u}[i]),\] (3)

where \(q(_{u})=_{i=1}^{N}q(_{u}|_{u_{i}})p( _{u_{i}})\) is the aggregated posterior of \(_{u}\). The TC term would decrease the mutual information among latent factors and improve independence among latent factors. The dimension-wise KL constraint on \(_{u}\) can be written as follows:

\[_{p}(_{u})=_{i=1}^{K}D_{KL}(q(_{u}[i])||p( _{u}[i])),\] (4)

where \(p(_{u}[i])\) follows the prior standard Gaussian distribution. The dimension-wise KL term prevents each latent variable from deviating too far from specified priors.

However, some CD works argue that the knowledge concepts are not independent and employ relation among knowledge concepts to improve CD [11; 39]. The direct independence constraint for each knowledge concept may be not applicable for cognitive diagnosis, which is also verified in our experiment. To address the challenge, we propose to utilize the easy-labeled knowledge concept tree to capture underlying independence among knowledge concepts. We assume there is less independence among groups of knowledge concepts grouped by their parent nodes in the knowledge concept tree. Corresponding to the real world, knowledge concepts in the same chapter would be related more than knowledge concepts in different chapters. Therefore, each level concept in the tree is a kind of grouping method for the last level concepts. The deeper the level, the finer the granularity of the grouping. Considering the grouping methods at the \(i\)-th level, the Eq. (3) can be rewritten as follows:

\[_{d}^{i}(_{u})=D_{KL}(q(_{u})||_{j=1}^{|G ^{i}|}q(_{u}[G_{j}^{i}])),\] (5)

where \(G_{j}^{i}\) is the knowledge concepts that belong to \(j\)-th group according to the grouping method of \(i\)-th level in the tree. The Eq. (5) allows dependence in intra-group knowledge concepts and maintains independence among inter-group knowledge concepts.

### Limited-Labeled Alignment Module

After applying the group-based disentanglement module, it is important to correspond each latent factor with an actual knowledge concept to ensure the interpretability. However, there are only a few labeled exercises with knowledge concepts, making it challenging to perform the accurate alignment. Inspired by semi-supervised DRL, to address this issue, we devised an alignment module that aligns both few labeled and numerous unlabeled exercises separately. For convenience, we use \(_{j}\{0,1\}^{K}\) to denote \(j\)-th column of matrix \(\) corresponding to exercise \(v_{j}\) that belongs to \(_{1}\).

**Few Labeled Exercises.** For an exercise \(v_{j}_{1}\), we utilize the Mean Square Error (MSE) loss to constraint similarity between \(_{j}\) and \(_{v_{j}}^{r}\), which can be defined as follows:

\[_{l}=_{v_{j}_{1}}\|_{j}-_{v_{j}}^{r}\|_{2}^{2},\] (6)

where \(_{1}\) means labeled exercise set. For semi-supervised DRL in the vision field, it's usually enough with a single alignment module for a few labeled samples. However, for cognitive diagnosis, the annotation vector (i.e., the column of Q-matrix) of exercise is very sparse with only one or two knowledge concepts per exercise. The challenge is that utilizing a few labeled exercises to do alignment is too hard to keep such sparsity in relevance representation for unlabeled exercises. To this end, the alignment of unlabeled exercises is necessary.

**Numerous Unlabeled Exercises.** For an exercise \(v_{j}_{2}\), we have no idea any knowledge concept of it. But we know there are only a few knowledge concepts of each exercise. The feature of sparsity in \(^{r}_{v_{j}}\) would help infer missing knowledge concepts. We just need to guarantee that there are only a few elements to be one and other elements to be zero in \(^{r}_{v_{j}}\). In this work, we employ a margin loss and an L2 loss to achieve this target, which can be expressed as follows:

\[_{ul}=_{v_{j}_{2}}(_{1}max(0,m-(^{r }_{v_{j}}[max\#d_{1}]-^{r}_{v_{j}}[max}(d_{1}+d_{2}+1)])) +_{2}\|^{r}_{v_{j}}\|_{2}^{2}),\] (7)

where \(m\) is the margin, \(_{1}\) is the hyperparameter to control margin loss, and \(_{2}\) is the hyperparameter to control L2 loss. We use \(^{r}_{v}[max}k]\) and \(^{r}_{v}[max\#k]\) to denote the \(k\)-th largest element of \(^{r}_{v}\) and the top \(k\) largest elements of \(^{r}_{v}\), respectively. In Eq. (7), we first sort \(^{r}_{v_{j}}\) by descending order and then split the sorted one into three parts of length \(d_{1},d_{2},K-d_{1}-d_{2}\). We argue that knowledge concepts in the last part are the least likely to be the ground-truth knowledge concepts and knowledge concepts in the first part are the most likely to be the ground-truth knowledge concepts of exercise \(v_{j}\). Therefore, we adopt a margin loss between knowledge concepts in the first part and knowledge concepts in the last part, which requires that all values in the first part (i.e., \(^{r}_{v_{j}}[max\#d_{1}]\)) is at least m greater than the largest value in the last one (i.e., \(^{r}_{v_{j}}[max}(d_{1}+d_{2}+1)]\)). For the middle part, we do not constrain anything on it. Intuitively, it's reasonable that adopt an L1 loss to constraint the value in the last part (i.e., \(^{r}_{v_{j}}[min\#(K-d_{1}-d_{2})]\)) to be 0. In our initial attempt, we first directly try to use L1 loss for numerous unlabeled exercises, and we find it does not show competing performance (detailed in Appendix A.3). We speculate a possible reason is as follows: with L1 loss, after model initialization, it is very hard to revise these incorrectly labeled exercises. In contrast, L2 loss are sensitive to outliers, and would have a larger loss when the corresponding knowledge is incorrectly predicted.

### Decoder Module

After aligning the exercise relevance representation with the real knowledge concepts, the decoder module predicts scores of students doing exercises, which could be described as a triplet set \(T=\{(u_{i},v_{j},X_{ij})|X_{ij}-1\}\). The object function can be described as follows:

\[_{m} =-_{q_{_{u}}(_{u}|_{u}),q_{ _{v}^{}}(^{}_{v}|_{v}),q_{v_{v}^{}}(^{}_{v}|_{v})}[ p(|_{u}, ^{}_{v},^{}_{v})]\] (8) \[=_{(u_{i},v_{j},X_{ij}) T}BCE(((_{u_{i}}- ^{}_{v_{j}})^{}_{v_{j}}),X_{ij}),\]

where \(BCE(,)\) is the binary cross entropy loss function, \(\) and \(()\) denote inner product operation and sigmoid function, respectively.

Similar to existing CD works [38; 39; 21], the interaction function (i.e., the decoder) keeps the monotonicity assumption , which guarantees the interpretability of student proficiency representation (i.e., the higher the value of the latent factor means the better proficiency on the corresponding knowledge concept, detailed in Appendix A.4). In addition, the element-wise operation in the decoder module propagates the alignment (i.e., each latent factor corresponds to each real knowledge concept) on exercise relevance representation to both student proficiency representation and exercise difficulty representation, which is also the same as existing works.

**Optimization.** We summarized all object functions in all modules and combine them for final optimization. We set different hyperparameters to balance each loss function. The final object function can be summarized as follow:

\[*{arg\,min}_{=[_{u},_{v}^{},_{v}^{ }]}=_{m}+_{l}+_{ul} +_{i=1}^{L}(^{i}_{\{_{u},^{ }_{v},^{}_{v}\}}^{i}_{d}())+ _{\{_{u},^{}_{v},^{ }_{v}\}}_{p}(),\] (9)

where \(=[_{u},_{v}^{},_{v}^{}]\) is the parameter set in the whole model, \(\) is the hyperparameter for alignment of labeled exercises, and \(^{i}\) denotes the weight for disentanglement term corresponding to the \(i\)-th level in the knowledge concept tree.

Experiments

### Experimental Settings

**Datasets.** Our experiments are conducted on three real-world datasets, i.e., Matmat2, Junyi  and NIPS2020EC , all of which contain knowledge concepts of the tree structure. The statistics of these datasets are summarized in Table 1. We adopt five-fold cross-validation to avoid randomness. The details about datasets and implementation3 are depicted in the Appendix B.

**Metrics.** To evaluate the effectiveness of DCD in terms of score prediction and interpretability, we adopt three widely used prediction metrics: AUC , ACC, RMSE, and one interpretability metric: Degree of Agreement (DOA) . DOA is the most commonly used interpretability metric in the CD, which measures the degree of agreement between cognitive results and response records.

**Baselines.** The baselines including the classical data mining model Probabilistic Matrix Factorization (PMF) , the latent factor models IRT , MIRT , and the representative CD models DINA , NCDM , KaNCD  and KSCD . In addition, we also explore a simplified version of our method. Specifically, we remove the exercise difficulty module and margin loss, and focus solely on the fine-grained disentanglement module. This simplified version serves as a baseline, which we refer to as \(\)-TCVAE in the following analysis.

Existing non-interpretable models such as PMF, IRT, and MIRT cannot obtain a student's proficiency for each knowledge concept . Consequently, DOA cannot be calculated for these models. Interpretable models such as DINA, NCDM, KaNCD, and KSCD cannot directly apply to few-labeled scenarios. To ensure fairness in comparison, we propose a pre-filling algorithm (detailed in Appendix B.2) for the missing Q-matrix before applying these models.

### Performance Comparison

To evaluate the effectiveness of our proposed DCD model in few-labeled scenarios, we have conducted experiments on datasets with 10% Q-matrix (few-labeled exercises), 20% Q-matrix (few-labeled exercises) and 100% Q-matrix (fully-labeled exercises). The detailed performance comparison on three datasets is displayed in Table 2.

**Prediction Comparison.** 1) Our proposed model consistently outperforms all interpretable baseline models across the different scenarios, demonstrating its effectiveness. DINA, which only considers binary space, performs the worst. Both KSCD and KaNCD implicitly model relation among knowledge concepts and has a better performance than NCDM. 2) However, all non-interpretable models achieve the best prediction metrics over interpretable models on Junyi and NIPS2020EC datasets except Matmat dataset. This may be because there are far fewer knowledge concepts in the Matmat dataset than in the other two datasets. To meet the interpretability of larger knowledge concept space, interpretable models lose partial prediction accuracy. This explanation is supported by the fact that the prediction results of interpretable models show a noticeable improvement in the few-labeled scenario compared to the fully labeled scenario, indicating that the trade-off between interpretability and accuracy is more significant in a larger knowledge concept space.

**Interpretability Comparison.** 1) Table 2 demonstrates that our method achieves the best interpretability in all scenarios. Especially, for the 10% and 20% Q-matrix (few-labeled scenarios), our model significantly outperforms interpretable baselines in terms of DOA, demonstrating its superior interpretability in this scenario. 2) In few-labeled scenarios, KaNCD and KSCD show a remarkable improvement in DOA compared to DINA and NCDM. This is because DINA and NCDM can only

   dataset & \#students & \#exercises & \#concepts & \#leaf concepts & \#right records : \\  & & at different level & per exercise & \#error records & \\  Matmat & 7,067 & 1,847 &  & 1.00 & 5.50 & 97.7\% \\ Junyi & 8,852 & 720 &  & 1.00 & 2.16 & 87.4\% \\ NIPS202EC & 11,857 & 6,509 &  & 1.05 & 2.00 & 99.1\% \\   

Table 1: The statistics of three datasets.

diagnose knowledge concepts labeled in the training set. When incorrect knowledge concepts are filled in, KaNCD and KSCD are less affected, while DINA and NCDM cannot accurately diagnose the true knowledge concepts. In contrast, our model avoids this issue by modeling the distribution of students' proficiency overall knowledge concepts.

### Disentanglement Analysis

To investigate the effectiveness of disentanglement, we conducted an experiment where we compared our method at different disentanglement weights \(\) in the few-labeled scenario. Fig. 3 (a-d) illustrates the results, the x-axis shows the value of \(\) from 0 to 2, which corresponds to the strength of disentanglement. The AUC is displayed on the left y-axis and the DOA is displayed on the right y-axis. The AUC(i) and DOA(i) denote the results by disentanglement only according to i-th level of knowledge concept tree. There are some observations from Fig. 3: 1). The disentanglement according to the last level of tree (i.e., the most fine-grained disentanglement) can not have an improvement in terms of DOA as the rise of \(\). The phenomenon is consistent with the assumption that knowledge concepts are correlated. Despite there being an improvement in AUC, we assume it's the result of interpretability losses, as mentioned in the prediction comparison in section 5.2. 2) The coarse-grained disentanglement could simultaneously improve the AUC and DOA compared to no disentanglement. We observe that the performance increased initially with the implementation of disentanglement and then decreased as the strength of disentanglement became excessive, leading to counterproductivity.

### Alignment Analysis

To evaluate the effectiveness of the limited-labeled alignment module, we conducted an experiment with different hyperparameters on Junyi dataset with 10% Q-matrix, namely \(\), \(_{1}\), \(_{2}\) and \(d_{2}\), as shown in Fig. 3 (e-h). Due to the number of leaf concepts per exercise being close to 1 for all datasets,

    &  &  &  \\  & AUC\(\) & ACC\(\) & RMSE\(\) & DOA\(\) & AUC\(\) & ACC\(\) & RMSE\(\) & DOA\(\) & AUC\(\) & ACC\(\) & RMSE\(\) & DOA\(\) \\   \\  PMF & **0.759** & **0.857** & **0.334** & - & **0.759** & **0.857** & **0.334** & - & **0.759** & **0.857** & **0.334** & - \\ IRT & 0.747 & 0.851 & 0.339 & - & 0.747 & 0.851 & 0.339 & - & 0.747 & 0.851 & 0.339 & - \\ MIRT & 0.750 & 0.853 & 0.337 & - & 0.750 & 0.853 & 0.337 & - & 0.750 & 0.853 & 0.337 & - \\   DINA & 0.696 & 0.816 & 0.368 & 0.828 & 0.698 & 0.774 & 0.380 & 0.766 & 0.700 & 0.720 & 0.735 \\ NCDM & 0.742 & 0.839 & 0.348 & 0.850 & 0.738 & 0.837 & 0.350 & 0.781 & 0.740 & 0.846 & 0.346 & 0.738 \\ \(\)-TCVAE & 0.753 & 0.847 & 0.337 & 0.847 & 0.733 & 0.843 & 0.342 & 0.743 & 0.730 & 0.842 & 0.343 & 0.733 \\ KSCD & 0.753 & 0.824 & 0.348 & 0.833 & 0.745 & 0.828 & 0.348 & 0.789 & 0.744 & 0.838 & 0.345 & 0.769 \\ KaNCD & 0.760 & **0.857** & 0.335 & 0.860 & 0.752 & 0.852 & 0.338 & 0.800 & 0.751 & 0.852 & 0.338 & 0.783 \\
**DCD** & **0.763** & **0.857** & **0.334** & **0.861** & **0.767** & **0.857** & **0.333** & **0.819** & **0.764** & **0.855** & **0.334** & **0.796** \\   \\  PMF & 0.817 & 0.776 & 0.394 & - & 0.817 & 0.776 & 0.394 & - & 0.817 & 0.776 & 0.394 & - \\ IRT & **0.822** & **0.779** & **0.391** & - & **0.822** & **0.779** & **0.391** & - & **0.822** & **0.779** & **0.391** & - \\ MIRT & 0.820 & 0.777 & 0.392 & - & 0.820 & 0.777 & 0.392 & - & 0.820 & 0.777 & 0.392 & - \\   DINA & 0.737 & 0.684 & 0.462 & 0.862 & 0.748 & 0.658 & 0.459 & 0.638 & 0.754 & 0.663 & 0.456 & 0.599 \\ NCDM & 0.760 & 0.715 & 0.445 & 0.851 & 0.791 & 0.743 & 0.418 & 0.632 & 0.804 & 0.753 & 0.409 & 0.594 \\ \(\)-TCVAE & 0.770 & 0.732 & 0.423 & 0.827 & 0.803 & 0.764 & 0.406 & 0.699 & 0.805 & 0.763 & 0.407 & 0.673 \\ KSCD & 0.767 & 0.725 & 0.426 & 0.809 & 0.804 & 0.754 & 0.409 & 0.670 & 0.809 & 0.760 & 0.405 & 0.650 \\ KaNCD & 0.775 & **0.754** & 0.422 & 0.835 & 0.807 & 0.767 & **0.400** & 0.719 & **0.815** & **0.773** & **0.395** & 0.691 \\
**DCD** & **0.787** & **0.754** & **0.414** & **0.873** & **0.811** & **0.768** & **0.400** & **0.733** & 0.814 & 0.771 & 0.397 & **0.717** \\   \\  PMF & 0.814 & 0.760 & 0.407 & - & 0.814 & 0.760 & 0.407 & - & 0.814 & 0.760 & 0.407 & - \\ IRT & 0.819 & 0.762 & 0.402 & - & 0.819 & 0.762 & 0.402 & - & 0.819 & 0.762 & 0.402 & - \\ MIRT & **0.822** & **0.765** & **0.400** & - & **0.822** & **0.765** & **0.400** & - & **0.822** & **0.765** & **0.400** & - \\   DINA & 0.764 & 0.705 & 0.451 & 0.856 & 0.767 & 0.687 & 0.453 & 0.740 & 0.766 & 0.684 & 0.453 & 0.693 \\ NCDM & 0.795 & 0.730 & 0.423 & 0.853 & 0.803 & 0.751 & 0.411 & 0.736 & 0.805 & 0.750 & 0.411 & 0.687 \\ \(\)-TCVAE & 0.792 & 0.744 & 0.417 & 0.854 & 0.797 & 0.740 & 0.416 & 0.781 & 0.801 & 0.745 & 0.413 & 0.774 \\ KSCD & 0.798 & 0.716 & 0.421 & 0.830 & 0.809 & 0.754 & 0.410 & 0.787 & 0.809 & 0.755 & 0.410 & 0.777 \\ KaNCD & 0.797 & 0.750 & 0.423 & 0.856 & 0.811 & 0.759 & 0.403 & 0.783 & 0.812 & 0.760 & **0.404** & 0.761 \\
**DCD** & **0.801** & **0.752** & **0.415** & **0.861** & **0.812** & **0.761** & **0.405** & **0.793** & **0.813** & **0.762** & **0.404** & **0.786** \\  set the \(d_{1}=1\) as the default value. The default margin is 0.5. There are some observations: 1) \(\) is the weight of the alignment loss corresponding to labeled exercises. Fig. 3 (e) shows that the performance of our model initially improves and eventually stabilizes as \(\) increases. 2) \(_{1}\) is the weight of margin loss for unlabeled exercises. As illustrated in Fig. 3 (f), the employment of margin loss is effective according to results from zero to non-zero of \(_{1}\). The excessive \(_{1}\) would decrease the performance. 3) \(_{2}\) is the weight of L2 loss of unlabeled exercises exercise relevance representation. We can observe that the employment of the L2 loss plays an essential role from Fig. 3 (g). 4) We can observe that the employment of \(d_{2}\) is effective from Fig. 3 (h). As \(d_{2}\) increases from 0 to 8, the performance increases first and then drops. Overall, the limited-labeled alignment module has a positive effect on performance, and the hyperparameters of the alignment module need to be certainly adjusted.

### Ablation Study

As shown in Table 3, to prove the effectiveness of our proposed disentanglement and alignment modules, we conduct the ablation study on Junyi dataset under the 10% Q-matrix scenario. The margin Loss in alignment module ensures few elements to be one in exercise relevance representation, which achieves an improvement of 0.53% in terms of DOA. The L2 loss in alignment module ensures the sparsity of exercise relevance representation, which achieves an improvement of 13.48% in terms of DOA. It proves that utilizing a few labeled exercises to do alignment is too hard to keep such sparsity in relevance representation for unlabeled exercises. The disentanglement module alone achieves 0.56% in terms of DOA. Overall, both the proposed disentanglement and alignment modules achieve an improvement in terms of prediction and interpretability metrics.

## 6 Conclusion

In this paper, we present a novel approach, called DCD, to tackle the interpretability problem of cognitive diagnosis with limited exercise labels. Inspired by semi-supervised DRL, we learn disentangled representations and align them with real limited labels by group-based disentanglement and limited-labeled alignment. Extensive experiments on widely used benchmarks demonstrate the superiority of our proposed method in few-labeled scenarios.

Figure 3: AUC and DOA results of DCD with hyper-parameters in the group-based disentanglement (a-d) and limited-labeled alignment (e-h) modules.

   &  \\   & AUC\(\) & ACC\(\) & RMSE\(\) & DOA\(\) \\  DCD w/o Alignment-Margin & 0.8140 & 0.7692 & 0.3796 & 0.7136 \\ DCD w/o Alignment-L2 loss & 0.8010 & 0.7881 & 0.3977 & 0.6322 \\ DCD w/o Disentanglement & 0.8130 & 0.7682 & 0.3983 & 0.7134 \\ DCD & **0.8143** & **0.7713** & **0.3965** & **0.7174** \\  

Table 3: Ablation study of DCD on Junyi.