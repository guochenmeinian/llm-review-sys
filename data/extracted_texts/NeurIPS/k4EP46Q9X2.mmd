# Unveiling the Potential of Robustness in Selecting Conditional Average Treatment Effect Estimators

Yiyan Huang

The Hong Kong Polytechnic University

yiyhuang3-c@my.cityu.edu.hk

&Cheuk Hang Leung

City University of Hong Kong

chleung87@cityu.edu.hk

&Siyi Wang

City University of Hong Kong

siyi.wang@my.cityu.edu.hk

&Yijun Li

City University of Hong Kong

yijunli5-c@my.cityu.edu.hk

&Qi Wu

City University of Hong Kong

qi.wu@cityu.edu.hk

The co-first authors.Corresponding author.

###### Abstract

The growing demand for personalized decision-making has led to a surge of interest in estimating the Conditional Average Treatment Effect (CATE). Various types of CATE estimators have been developed with advancements in machine learning and causal inference. However, selecting the desirable CATE estimator through a conventional model validation procedure remains impractical due to the absence of counterfactual outcomes in observational data. Existing approaches for CATE estimator selection, such as plug-in and pseudo-outcome metrics, face two challenges. First, they must determine the metric form and the underlying machine learning models for fitting nuisance parameters (e.g., outcome function, propensity function, and plug-in learner). Second, they lack a specific focus on selecting a robust CATE estimator. To address these challenges, this paper introduces a Distributionally Robust Metric (DRM) for CATE estimator selection. The proposed DRM is nuisance-free, eliminating the need to fit models for nuisance parameters, and it effectively prioritizes the selection of a distributionally robust CATE estimator. The experimental results validate the effectiveness of the DRM method in selecting CATE estimators that are robust to the distribution shift incurred by covariate shift and hidden confounders.

## 1 Introduction

The escalating demand for decision-making has sparked an increasing interest in _Causal Inference_ across various research domains, such as economics , statistics , healthcare , and financial application . The primary goal in personalized decision-making is to quantify the causal effect of a specific treatment (or policy/intervention) on the target outcome, and understanding such causal effects is closely connected with identifying the _Conditional Average Treatment Effect (CATE)_. In observational studies, identifying the CATE faces a significant and fundamental challenge: the absence of _counterfactual_ knowledge. According to Rubin Causal Model , the CATE is determined by comparing _potential outcomes_under different treatment assignments (i.e., treat and control) for a specific covariate. Nonetheless, in real-world applications, we can only observe the potential outcome under the actual treatment (i.e., _factual outcome_), while the potential outcome under the alternative treatment (i.e., _counterfactual outcome_) remains unobserved. The unavailability of the counterfactual outcome is widely recognized as the fundamental problem in causal inference , making it difficult to accurately determine the true value of the CATE.

The advancement of machine learning (ML) has opened up a promising opportunity to improve the CATE estimation from observational data. Several innovative CATE estimation approaches, such as meta-learners and causal ML models, have been proposed to tackle the fundamental challenge in causal inference and enhance the predictive accuracy of CATE estimates (as discussed in Section 3). Nevertheless, the emergence of various CATE estimation methods has brought forth a new question: _Given multifarious options for CATE estimators, which should be chosen?_ In observational data, treatment is often non-random and propensity scores remain unknown. Conventional model validation procedures, unfortunately, are not suitable for CATE estimator selection in this case due to the absence of ground truth CATE labels. Therefore, exploring proper metrics for CATE estimator selection remains an essential yet challenging research topic in causal inference.

Recent research has emphasized the significance of model selection for CATE estimators, as highlighted in . These works have proposed and summarized two types of criteria for CATE estimator selection, the _plug-in_ metric \(^{plug}_{}()\) and the _pseudo-outcome_ metric \(^{pseudo}_{}()\):

\[^{plug}_{}()=_{i=1}^{n} ((X_{i})-(X_{i}))^{2}},^{pseudo}_{ }()=_{i=1}^{n}((X_{i})- {Y}_{i})^{2}}.\] (1)

One can establish a plug-in estimator \(\) or construct a pseudo-outcome estimator \(\) using the validation data to select CATE estimator \(\). The previous studies  have shown that these metrics offer some assistance in identifying well-performing CATE estimators. However, two additional challenges are still encountered in these two metrics.

Challenge 1: How to determine the metric form and underlying ML models for nuisance parameters?As previously discussed, plug-in and pseudo-outcome metrics have various forms, and both of them rely on estimating nuisance parameters \(\) using ML algorithms such as linear models, tree-based models, etc. Plug-in metrics even need to fit an additional ML model for the plug-in learner \(\). However, selecting the suitable metric form and ML algorithms can be very difficult without the knowledge of true data generating process. Consequently, we might go round in circles as this challenge leads us back to the original estimator selection problem .

Challenge 2: These metrics are not well-targeted for selecting a robust CATE estimator.In potential outcome framework , the factual distribution \(P^{F}\) and the counterfactual distribution \(P^{CF}\) for \(t\{0,1\}\) can be defined as follows:

\[ P^{F}:=P(X,Y^{t}|T=t)&=P(Y^{t}|X,T =t)P(X|T=t);\\ P^{CF}:=P(X,Y^{t}|T=1-t)&=P(Y^{t}|X,T=1-t)P(X|T=1- t).\] (2)

The above (2) reveals that the covariate shift \(P(X|T=t) P(X|T=1-t)\) leads to a distribution shift between \(P^{F}\) and \(P^{CF}\) - and such distribution shift can be further exacerbated once the unconfounded assumption \(P(Y^{t}|X,T=t)=P(Y^{t}|X,T=1-t)\) is violated. It is widely recognized that ML models often struggle when the training and test data do not adhere to the same distribution. Therefore, it becomes essential to select a CATE estimator learned on \(P^{F}\) that demonstrates robust performance to the counterfactual distribution \(P^{CF}\). This need for robustness holds even greater significance than the pursuit of an ideal "stellar" estimator because striving for the perfect estimator can be futile in the absence of ground truth counterfactual labels.

Contributions.In this paper, we propose a Distributionally Robust Metric (DRM) for CATE estimator selection. The main contributions are summarized as follows: (1) The proposed DRM method is nuisance-free, eliminating the need to fit models for nuisance parameters (outcome function, propensity function, and plug-in learner). (2) The DRM method is designed to prioritize selecting a distributionally robust CATE estimator. (3) We provide a finite sample analysis of the proposeddistributionally robust value \(}^{t}()\) for \(t\{0,1\}\), showing it decays to \(^{t}()\) at a rate of \(n^{-1/2}\). (4) Experimental results validate the effectiveness of the DRM method in selecting a CATE estimator that is robust to the distribution shift incurred by covariate shift and hidden confounders.

## 2 Background of CATE Estimator Selection

Suppose the observational data contain \(n\) i.i.d. samples \(\{(x_{i},t_{i},y_{i})\}_{i=1}^{n}\), with the associated random variables being \(\{(X_{i},T_{i},Y_{i})\}_{i=1}^{n}\). For each unit \(i\), \(X_{i}^{d}\) is \(d\)-dimensional covariates and \(T_{i}\{0,1\}\) is the binary treatment. Potential outcomes for treat (\(T=1\)) and control (\(T=0\)) are denoted by \(Y^{1},Y^{0}\). The observed (factual) outcome is \(Y=TY^{1}+(1-T)Y^{0}\). The propensity score  is defined as \((x):=P(T=1 X=x)\). The conditional mean potential outcome surface is defined as \(_{t}(x):=[Y^{t} X=x]\) for \(t\{0,1\}\). The true CATE is defined as

\[_{true}(x):=[Y^{1}-Y^{0} X=x]=_{1}(x)-_{0 }(x).\]

Following the standard and necessary assumptions in potential outcome framework , we impose Assumption 2.1 that ensure treatment effects are identifiable.

**Assumption 2.1** (Consistency, Overlap, and Unconfoundedness).: Consistency: If the treatment is \(t\), then the observed outcome \(Y\) equals \(Y^{t}\). Overlap: The propensity score is bounded away from \(0\) to \(1\), i.e., \(0<(x)<1\), \( x\). Unconfoundedness 3: \(Y^{t}\!\!\! T X,\  t\{0,1\}\).

The goal of CATE estimator selection is to select the best CATE estimator, denoted by \(_{best}\), from a set of \(J\) candidate estimators \(\{_{1},,_{J}\}\):

\[_{best}=*{arg\,min}_{\{_{1}, ,_{J}\}}^{oracle}(),^{ oracle}():=_{i=1}^{n}((X_{i})-_{true}(X_{i} ))^{2}}.\] (3)

Here, \(^{oracle}()\) is associated with \([((X)-_{true}(X))^{2}]\), known as the Precision of Estimating Heterogeneous Effects (PEHE) w.r.t. \(\). Note that \(^{oracle}()\) cannot be employed to evaluate CATE estimators' performances in real applications as we do not have access to \(_{true}\). Previous studies have introduced plug-in and pseudo-outcome metrics to aid in CATE estimator selection, as shown in equation (1). Then, the CATE estimator \(_{select}\) is selected on validation data by

\[_{select}=*{arg\,min}_{\{_{1}, ,_{J}\}}_{}^{plug}() {or}_{select}=*{arg\,min}_{\{_{1},,_{J}\}}_{}^{pseudo}().\] (4)

Notably, both the plug-in and pseudo-outcome metrics necessitate the fitting of nuisance parameters \(\) (e.g., \(=(_{1},_{0},)\)) using off-the-shelf ML models. While some papers like  address the selection of nuisance parameters for Aerate Treatment Effect (ATE) estimators, e.g., the doubly robust estimator , our paper focuses on the selection of CATE estimators rather than nuisance parameters. For the plug-in metric, \(\) can be constructed using any CATE estimator discussed in Appendix A.1, yielding metrics such as plug-T, plug-DR, etc. For the pseudo-outcome metric, \(\) can be constructed using a specific formula discussed in Appendix A.2, yielding metrics such as pseudo-DR, pseudo-R, etc. The metrics based on the influence function  and the R-learner objective  are categorized into the pseudo-outcome metric. The categorization of plug-in and pseudo-outcome metrics maintains consistency with .

## 3 Related Work

CATE estimation.Recent advancements in ML have emerged as powerful tools for estimating CATE from observational data, and researchers pay particular attention to _meta-learners_ and _causal ML_ models. Existing meta-learners mainly include traditional learners such as S-learner, T-learner, PS-learner, and IPW-learner, as well as new learners such as X-learner , U-learner , DR-learner , R-learner , and RA-learner . The specific details of these meta-learners are stated in Appendix A.1. Additionally, some studies also focus on developing innovative causal MLmodels for CATE estimation, such as Causal BART , Causal Forest [70; 8; 58], generative models like CEVAE  and GANITE , representation learning nets including SITE , TARNet , Dragonnet , FlexTENet , and HTCE , disentangled learning nets like D\({}^{2}\)VD [44; 45], DeR-CFR , and DR-CFR , and representation balancing nets such as BNN , CFRNet , DKLITE , IGNITE , BWCFR , DRRB , and DIGNet . Recent surveys [28; 75; 56] have also conducted a systematic review of various causal inference methods.

CATE estimator selection.Compared to the diverse range of CATE estimation methods, selecting CATE estimators has received limited attention in existing causal inference research. Current methods for selecting CATE estimators can be broadly classified into two main categories. **The first category**, which is also considered in this paper, involves using plug-in and pseudo-outcome methods to evaluate CATE estimators. These methods share two common characteristics: 1) Both methods require fitting ML models for nuisances (e.g., outcome function, propensity function, CATE function) on a validation set and then implementing the learned ML models in either the plug-in surrogate or the pseudo-outcome surrogate; 2) Both methods serve as surrogates for the expected error between the CATE estimator and the true CATE, i.e., \(^{oracle}()\) in equation (3). The difference between the two methods is that the plug-in method directly approximates the true CATE function, where only covariate variables are involved, while the pseudo-outcome method typically constructs a specific formula incorporating covariates, treatment, and outcome variables. For example, the pseudo-DR proposed in  is constructed by the outcome predictors learned with representation balancing objective [68; 40]. Recent research [66; 20; 53] has conducted thorough empirical investigations into exploring these two methods for selecting CATE estimators. Their findings suggest that no single selection criterion can universally outperform others in all scenarios in the task of selecting CATE estimators. More details of the two selection methods are stated in Appendix A.2. **The second category** considers leveraging the data generating process (DGP) to generate synthetic data with the known true CATE function, allowing the validation of CATE estimators' performance on this synthetic data. For example, authors in  find that placebo and structured empirical Monte Carlo methods are helpful for estimator selection under some restrictive conditions. In addition, researchers in [67; 7; 59] focus on training generative models to enforce the generated data to approximate the distribution of the observed data. However, the DGP-based method still faces some limitations in CATE estimator selection: 1) it only guarantees the resemblance of the generated data to the factual distribution, without considering the counterfactual distribution; and ii) there is a potential risk of the method favoring estimators that closely resemble the generative models .

## 4 The Distributionally Robust Metric

In this section, we introduce the Distributionally Robust Metric (DRM) for CATE estimator selection. First, we capture the uncertainty in PEHE in a distributionally robust manner (Section 4.1). We then establish the DRM based on the distributionally robust value of PEHE (Section 4.2).

### Capturing the Uncertainty in PEHE

**Proposition 4.1**.: _The PEHE w.r.t. the CATE estimator \(\) can be decomposed as follows:_

\[[((X)-_{true}(X))^{2}]=[(X)^{2}]+ 2[(X)Y^{0}]+2[-(X)Y^{1}]+,\] (5)

_where \(=[(_{1}(X)-_{0}(X))^{2}]\). The proof is deferred to Appendix B.1._

Proposition 4.1 indicates that the PEHE is equal to four terms, where \([(X)^{2}]\), \([(X)Y^{0}]\), and \([-(X)Y^{1}]\) depend on \(\), while \(\) is a constant that is independent of \(\). The term \([(X)Y^{t}]\) for \(t\{0,1\}\) can be further decomposed as follows:

\[[(X)Y^{t}]=[(X)Y^{t}|T=t]}_ {}P(T=t)+[(X)Y^{t}| T=1-t]}_{}P(T=1-t).\] (6)

Equation (6a) can be computed empirically since the potential outcome \(Y^{t}\) is observable in the group of \(T=t\). However, equation (6b) is empirically uncomputable due to the unavailability of \(Y^{t}\) in the group of \(T=1-t\). The unknown term \([(X)Y^{t}|T=1-t]\) therefore determines the uncertainty in PEHE. To capture such an uncertainty, we therefore establish distributionally robust values for \([(X)Y^{0}|T=1]\) and \([-(X)Y^{1}|T=0]\) based on a Kullback-Leibler (KL) ambiguity set.

**Definition 4.2** (KL ambiguity set).: Given two distributions \(Q\) and \(P\) and the ambiguity radius \(>0\). The KL ambiguity (uncertainty) set \(_{}(P)\) is defined as

\[_{}(P):=\{Q:D_{KL}(Q||P)\},D_{KL}(Q||P)=_{}q(x)dx.\] (7)

Here, \(D_{KL}(Q||P)\) denotes the KL divergence of some arbitrary distribution \(Q\) from the reference distribution \(P\). Now we define the distribution of \((X,Y^{0},Y^{1})\) in the treated and controlled groups as

\[P_{T}:=P(X,Y^{0},Y^{1}|T=1);\ P_{C}:=P(X,Y^{0},Y^{1}|T=0).\] (8)

By setting an adequately large ambiguity radius in Definition 4.2, the following inequalities hold for \([(X)Y^{0}|T=1]=^{P_{T}}[(X)Y^{0}]\) and \([-(X)Y^{1}|T=0]=^{P_{C}}[-(X)Y^{1}]\):

\[[(X)Y^{0}|T=1]=^{P_{T}}[(X)Y^{0}] _{Q B_{_{0}}(P_{C})}^{Q}[(X)Y^{0}]=: ^{0}();\] (9)

To provide a clearer understanding, let us consider the example of \(^{P_{T}}[(X)Y^{0}]\). Since the term \([(X)Y^{0}]\) is computable on its factual distribution \(P_{C}\) but uncomputable on its counterfactual distribution \(P_{T}\), we can construct an ambiguity set centered around the distribution \(P_{C}\) such that it is large enough to contain the distribution \(P_{T}\). By doing so, we can capture the uncertainty of \(^{P_{T}}[(X)Y^{0}]\) w.r.t. \(\). In other words, the value of the uncomputable quantity \(^{P_{T}}[(X)Y^{0}]\) will be **at most**\(^{0}()\). Similarly, the value of the uncomputable quantity \(^{P_{C}}[-(X)Y^{1}]\) will be **at most**\(^{1}()\). Obviously, the uncertainty in PEHE will be larger if the distribution shift between factual and counterfactual distribution is severer. Consequently, we can obtain the distributionally robust value of PEHE in Corollary 4.3, which measures the uncertainty in PEHE.

**Corollary 4.3**.: _Let \(^{0}()\) and \(^{1}()\) be the quantities defined in equation (9), \(\) be the constant given in Proposition 4.1, \(u_{1}:=P(T=1)\), and \(u_{0}=1-u_{1}=P(T=0)\). The distributionally robust value of PEHE w.r.t. \(\) is defined as \(_{PEHE}()\) such that_

\[[((X)-_{true}(X))^{2}]_{ PEHE}()\] (10) \[=[(X)^{2}]+2(u_{0}^{P_{C}}[ (X)Y^{0}]+u_{1}^{P_{T}}[-(X)Y^{1}])+2 (u_{0}^{1}()+u_{1}^{0}()) +.\]

### Establishing Distributionally Robust Metric

As Corollary 4.3 provides the distributionally robust (worst-case) value of PEHE, it can naturally measure the robustness of the CATE estimator \(\) against distribution shift between counterfactual distribution and factual distribution. In this section, we will provide two steps involved in using Corollary 4.3 to construct the DRM method for CATE estimator selection.

Step 1: Establishing computational tractability of \(^{t}()\).The distributionally robust values \(^{0}()\) and \(^{1}()\) in equation (10) are initially defined as supremum problems over infinite support, presenting a substantial computational challenge. Theorem 4.4 reformulates the infeasible supremum problems into tractable minimum problems.

**Theorem 4.4**.: _The distributionally robust values \(^{0}()\) and \(^{1}()\) in equation (9) are equivalent to_

\[^{0}() =_{_{0}>0}_{0}_{0}+_{0} ^{P_{C}}[((X)Y^{0}/_{0})];\] (11) \[^{1}() =_{_{1}>0}_{1}_{1}+_{1} ^{P_{T}}[(-(X)Y^{1}/_{1})].\]

_The proof is deferred to Appendix B.3._

In the finite-sample scenario, \(^{0}()\) and \(^{1}()\) can be empirically approximated as follows:

\[}^{0}() =_{_{0}>0}_{0}_{0}+_{0} }_{i=1}^{n}(1-T_{i})((X_{i})Y_{i}/_{0});\] (12) \[}^{1}() =_{_{1}>0}_{1}_{1}+_{1} }_{i=1}^{n}T_{i}(-(X_{i})Y_{i}/_{1}).\]Note that in equation (12), the potential outcomes \(Y^{0}\) and \(Y^{1}\) are replaced by the observed outcome \(Y\) due to the fact that \((1-T)Y^{0}=(1-T)Y\) and \(TY^{1}=TY\), which aligns with the Consistency assumption in Assumption 2.1. We then provide a finite-sample analysis of the gap between \(}^{t}()\) and \(^{t}()\) in the following Theorem 4.5, which suggests the gap decays at a rate of \(n^{-1/2}\).

**Theorem 4.5**.: _Let \(u_{t}:=P(T=t)\) for \(t\{0,1\}\). Assume \(0<_{0},_{1}\) and \((X)Y\) is bounded within the range of \(M\) to \(\). Define \(C_{exp}=_{\{ 0\}}(/-M/)+_{\{ 0, 0\}} (/-M/)+_{\{0 M \}}(/-M/)\). For \(n 2/u^{2}(2/)\) and \(t\{0,1\}\), with probability \(1-\), we have_

\[|}^{t}()-^{t}()|(^{2}}{nu_{t}^{2}}C_{exp} ^{2}})+(^{2}()}{nu_{t}^{2}}}).\] (13)

_The proof is deferred to Appendix B.4._

Step 2: Finalizing Distributionally Robust Metric for CATE estimator selection.We first define two functions that are useful in obtaining \(^{0}()\) and \(^{1}()\):

\[_{0}(_{0},_{0};)=_{0} _{0}+_{0}}_{i=1}^{n_{c}}e^{ _{i}}{_{0}}},\;_{1}(_{1},_{1};)= _{1}_{1}+_{1}}_{i=1}^{n_{t}}e^{_{i}}{_{1}}};\] (14a) \[_{0}}{_{0}}=_{0}+ _{i=1}^{n_{c}}_{i}}{_{0}}}}{n_{c}}-^{n_{c}}Z_{i}e^{_{i}}{_{0}}}}{_{0}_{i =1}^{n_{c}}e^{_{i}}{_{0}}}},\;_{1}}{ _{1}}=_{1}+_{i=1}^{n_{t}}_{i}}{_{1}}}}{n_{t}}-^{n_{t}}-Z_{i}e^{_{i}}{ _{1}}}}{_{1}_{i=1}^{n_{t}}e^{_{i}}{_{1 }}}}.\] (14b)

Here, \(Z\) denotes \((X)Y\) for notational simplicity. We then use the Newton-Raphson method to find the empirical solution for \(}^{t}()\), exploiting the convexity of \(_{t}(_{t},_{t};)\) w.r.t. \(_{t}\). Based on the distributionally robust value of PEHE, i.e., \(}_{PEHE}()\) in equation (10), we finally obtain the selected estimator \(_{select}=_{\{_{1},,_ {j}\}}^{DRM}()\) such that

\[^{DRM}()=_{i=1}^{n}(X_{i})^{2}+ (_{i=1}^{n_{c}}(X_{i})Y_{i}+_{i=1}^{n_{t}}- (X_{i})Y_{i}+n_{c}}^{1}()+n_{t}}^{0}()).\] (15)

Algorithm 1 provides complete procedure of using the DRM method for CATE estimator selection.

Discussion on the ambiguity radius \(\).The ambiguity radius \(\) plays a critical role in real-world applications . However, determining an appropriate value for \(\) can be challenging as it requires striking a balance between ensuring the bound in equation (9) holds and maintaining its tightness. Specifically, if \(\) is set too small, it fails to guarantee that the counterfactual distribution is contained within the ambiguity set centered at factual distribution (the bound in Corollary 4.3 can hold). On the other hand, if \(\) is set too large, even though the ambiguity set can encompass more distributions to ensure the counterfactual distribution is contained, the bound in Corollary 4.3 can be less tight. In general, selecting a proper ambiguity radius is an open problem in distributioanlly robust optimization (DRO) literature [34; 54; 46; 48; 72].

In this paper, we provide a guidance for determining the ambiguity radius for our DRM method. Based on the above discussion, an ideal radius should be \(_{1}^{*}=D_{KL}(P_{C}||P_{T})\) and \(_{0}^{*}=D_{KL}(P_{T}||P_{C})\), which ensures that the bound in Corollary 4.3 holds and is tight. However, as defined in equation (8), both \(P_{C}\) and \(P_{T}\) involve counterfactual information, making it unattainable to directly compute \(D_{KL}(P_{C}||P_{T})\) and \(D_{KL}(P_{T}||P_{C})\). To overcome this challenge, we demonstrate that Proposition 4.6 provides an intriguing alternative approach to acquire \(D_{KL}(P_{C}||P_{T})\) and \(D_{KL}(P_{T}||P_{C})\) when unconfoundedness in Assumption 2.1 is satisfied.

**Proposition 4.6**.: _Let \(P_{X}^{T}:=P(X|T=1)\) and \(P_{X}^{C}:=P(X|T=0)\) denote the covariates distribution in the treat and control group, respectively. Assuming that random variables \((X,T,Y^{1},Y^{0})\) satisfy the unconfoundedness in Assumption 2.1, we have_

\[D_{KL}(P_{C}||P_{T})=D_{KL}(P_{X}^{C}||P_{X}^{T}); D_{KL}(P_{T}||P_{C})=D _{KL}(P_{X}^{T}||P_{X}^{C}).\] (16)

_The proof is deferred to Appendix B.2._

Proposition 4.6 provides an important insight that the uncomputable term \(D_{KL}(P_{C}||P_{T})\) (or \(D_{KL}(P_{T}||P_{C})\)) can be replaced by a computable quantity \(D_{KL}(P_{X}^{C}||P_{X}^{T})\) (or \(D_{KL}(P_{X}^{T}||P_{X}^{C})\)), where \(P_{X}^{C}\) and \(P_{T}^{T}\) are empirically observable. Consequently, the ideal ambiguity radius can be set as \(_{1}^{*}=D_{KL}(P_{X}^{C}||P_{X}^{T})\) and \(_{0}^{*}=D_{KL}(P_{X}^{T}||P_{X}^{C})\). While the KL divergence can be approximated using empirical algorithm (e.g, Nearest-Neighbror [73; 57]), we recommend setting the ambiguity radius larger than the empirically approximated KL divergence (see specific explanations in Appendix C.1). This is necessary because it ensures that the ambiguity set is large enough to contain the target distribution. It is also important to note that though the Algorithm 1 involves approximating \(_{1}^{*}=D_{KL}(P_{X}^{C}||P_{X}^{T})\) and \(_{0}^{*}=D_{KL}(P_{X}^{T}||P_{X}^{C})\), the DRM itself remains free of nuisances, as this approach only determines the ambiguity radius but does not involve learning any nuisance function such as the outcome function, propensity function, and plug-in learner.

## 5 Experiments

### Experimental Setup.

Estimators & Selectors.We consider a total of **36 CATE estimators**, comprising the combination of 4 base ML models and 9 meta-learners. Specifically, the base ML models are Linear Regression (LR), Support Vector Machine (SVM), Random Forests (RF), and Neural Net (Net). We consider these ML models for CATE estimators because they are representative of both rigid and flexible models, with each encoded distinct inductive biases, as highlighted by [19; 20]. Note that for the LR method, we employ Ridge regression for regression tasks and Logistic regression for classification tasks. As for the remaining methods, we utilize their corresponding regressors and classifiers for regression and classification tasks, respectively. Regarding the meta-learners, we select a set of both traditional basic learners (S-, T-, PS-, and IPW-learners) and recently developed learners (X-, DR-, U-, R-, and RA-learners), as detailed in Appendix A.1. We consider **14 CATE selectors**, consisting of 9 plug-in methods that rely on the above 9 learners, 3 pseudo-outcome methods (pseudo-DR, -R, and -IF), the random selection, the factual selection (from the 6-learner pool with S-, T-), the Nearest-Neighbor Matching , and our proposed DRM. The specific details of baseline selectors are stated in Appendix A.2. We employ the eXtreme Gradient Boosting (XGB)  as the underlying ML model for both plug-in and pseudo-outcome methods. We choose XGB because: i) it demonstrates superior performance in various scenarios, ensuring a good performance of baseline selectors; ii) the need to avoid potential congeniality bias that may arise from using the similar ML models employed in CATE estimators ; iii) aligning with  where XGB is used for their proposed pseudo-IF metric. The details of hyperparameters for nuisance models are stated in Section C.2 of Appendix.

Dataset.Since the ground truth of CATE is unavailable in real-world data, previous studies commonly utilize semi-synthetic datasets to compare model performance. In line with [19; 20], we collect the covariates with \(n=4802\) data points from AIC2016 dataset . Then, we generate treatment with \(T_{i}|X_{i} Bern(1/(1+(-(_{i}^{t}X_{i}+3))))\), where \(Bern\) indicates the Bernoulli

[MISSING_PAGE_FAIL:8]

exhibit better PEHE as the CATE complexity decreases, aligning with the findings in . In setting B, the DRM selector demonstrates robustness against selection bias (controlled by \(\)) compared to many baselines. However, for the case \(=2\), DRM selects a poor estimator 1 or 2 times out of 100 experiments, as shown in Figure 1. Although this weakens its overall performance, DRM still outperforms many baselines in this scenario. In the scenario \(=0\) where no selection bias is present, the factual selection criterion performs better in this specific setting. In this case, DRM does not demonstrate a significant advantage, as there is no distribution shift caused by selection bias. In setting C where the unconfoundedness assumption is violated, most selectors exhibit inferior performance. In contrast, DRM demonstrates consistent outperformance across all three cases, and its superiority becomes particularly significant as \(m\) increases to 0.9, showcasing its robustness against the distribution shift arising from unobserved confounders.

Ranking ability.In Table 2, the DRM method demonstrates favorable performance in ranking estimators, surpassing certain Plug- (e.g., U, T, IPW, DR, RA) and Pseudo- (e.g., DR, IF) selectors.

    & A (\(=0\)) & A (\(=0.1\)) & A (\(=0.3\)) & B (\(=0\)) & B (\(=2\)) & C (\(m=0.1\)) & C (\(m=0.5\)) & C (\(m=0.9\)) \\  Plug-U & 0.69\(\)0.34 & 0.70\(\)0.35 & 0.75\(\)0.29 & **0.95\(\)**0.04 & 0.53\(\)0.30 & 0.68\(\)0.33 & 0.73\(\)0.34 & 0.83\(\)0.24 \\ Plug-S & 0.95\(\)0.06 & 0.95\(\)0.06 & 0.95\(\)0.05 & **0.95\(\)**0.04 & **0.95\(\)**0.05 & 0.95\(\)0.03 & 0.95\(\)0.05 & 0.91\(\)0.07 \\ Plug-PS & 0.95\(\)0.06 & 0.95\(\)0.06 & 0.95\(\)0.05 & **0.95\(\)**0.04 & **0.95\(\)**0.05 & 0.95\(\)0.03 & 0.95\(\)0.05 & 0.91\(\)0.07 \\ Plug-T & 0.54\(\)0.18 & 0.54\(\)0.18 & 0.54\(\)0.16 & 0.89\(\)0.07 & 0.57\(\)0.16 & 0.51\(\)0.16 & 0.58\(\)0.21 & 0.59\(\)0.21 \\ Plug-X & 0.94\(\)0.05 & 0.94\(\)0.04 & 0.94\(\)0.04 & 0.93\(\)0.05 & 0.93\(\)0.05 & 0.93\(\)0.04 & 0.92\(\)0.06 & 0.85\(\)0.13 \\ Plug-DW & 0.72\(\)0.19 & 0.71\(\)0.19 & 0.71\(\)0.19 & 0.92\(\)0.06 & 0.68\(\)0.15 & 0.69\(\)0.19 & 0.76\(\)0.18 & 0.77\(\)0.17 \\ Plug-DR & 0.65\(\)0.19 & 0.63\(\)0.20 & 0.63\(\)0.18 & 0.93\(\)0.06 & 0.59\(\)0.16 & 0.61\(\)0.18 & 0.71\(\)0.21 & 0.73\(\)0.18 \\ Plug-R & **0.96\(\)**0.03 & **0.96\(\)**0.03 & **0.96\(\)**0.03 & **0.95\(\)**0.04 & 0.93\(\)0.07 & **0.96\(\)**0.03 & **0.96\(\)**0.05 & **0.96\(\)**0.04 \\ Plug-RA & 0.55\(\)0.19 & 0.54\(\)0.17 & 0.55\(\)0.17 & 0.92\(\)0.06 & 0.57\(\)0.15 & 0.53\(\)0.17 & 0.60\(\)0.22 & 0.62\(\)0.21 \\ Pseudo-DR & 0.54\(\)0.18 & 0.53\(\)0.18 & 0.53\(\)0.16 & 0.87\(\)0.10 & 0.55\(\)0.15 & 0.50\(\)0.17 & 0.54\(\)0.24 & 0.58\(\)0.23 \\ Pseudo-R & 0.86\(\)0.11 & 0.87\(\)0.09 & 0.88\(\)0.08 & 0.93\(\)0.06 & 0.83\(\)0.13 & 0.85\(\)0.13 & 0.85\(\)0.12 & 0.80\(\)0.16 \\ Pseudo-IF & 0.52\(\)0.17 & 0.52\(\)0.17 & 0.51\(\)0.15 & 0.66\(\)0.18 & 0.64\(\)0.16 & 0.52\(\)0.16 & 0.53\(\)0.19 & 0.62\(\)0.18 \\ Random & 0.26\(\)0.13 & 0.26\(\)0.13 & 0.27\(\)0.13 & 0.47\(\)0.11 & 0.23\(\)0.13 & 0.28\(\)0.10 & 0.28\(\)0.11 & 0.24\(\)0.14 \\ Fact & 0.35\(\)0.08 & 0.36\(\)0.08 & 0.35\(\)0.09 & 0.48\(\)0.08 & 0.31\(\)0.10 & 0.35\(\)0.07 & 0.33\(\)0.09 & 0.29\(\)0.11 \\ Matching & 0.53\(\)0.17 & 0.51\(\)0.18 & 0.52\(\)0.16 & 0.89\(\)0.08 & 0.58\(\)0.15 & 0.51\(\)0.16 & 0.55\(\)0.21 & 0.60\(\)0.21 \\ DRM & 0.81\(\)0.08 & 0.80\(\)0.08 & 0.80\(\)0.08 & 0.85\(\)0.06 & 0.77\(\)0.15 & 0.79\(\)0.09 & 0.81\(\)0.10 & 0.80\(\)0.08 \\   

Table 2: Comparison of rank correlation for different selectors across Settings A, B, and C (Note that B (\(=1\)) matches A (\(=0.1\))). Bold denotes the best three results among all selectors. Reported values (mean \(\) standard deviation) are computed over 100 experiments. Larger is better.

Figure 1: The stacked bar chart showing the distribution of the selected estimator’s rank for each evaluation metric across rank intervals: [1-3], [4-11], [12-19], [20-27], and [28-36]. The greener (or redder) color indicates that the selected estimator ranks higher (or lower). For example, the **dark red** (or green) indicates the percentage of cases (out of 100 experiments) where the selected estimator ranks among the worst 9 estimators, specifically as ranks 28, 29,..., or 36 (or among the best 3 estimators, specifically as ranks 1, 2, or 3).

In comparison to other nuisance-free baselines (Random, Fact, and Matching), DRM achieves significantly superior ranking ability. However, compared to Plug-S, -PS, -X, and -R, it does not exhibit remarkable performance in ranking CATE estimators, possibly due to the fact that DRM selects estimators based on their distributionally robust (worst-case) performance. Indeed, the definition of ranking inherently involves the concept of expected (average) performance, which is not determined solely by either the best or worst performance. While distributionally robust performance serves as a suitable criterion for selecting players to participate in the Olympics, it may not be a reasonable standard for ranking players' average performance. Therefore, it would be intriguing to explore some ways in future research that can enhance the ranking ability of our DRM selector.

Variance analysis.Table 1 indicates that baseline selectors tend to exhibit higher variances in Regret performance. This is primarily due to the wide range of PEHE performances across the 36 CATE estimators. If a selector consistently selects either good or bad estimators, the variance would not be very large. To investigate this further, we sorted all 36 estimators in ascending order based on their \(^{oracle}()\) values, resulting in the sorted list: \([^{oracle}(_{1}),,^{oracle}(_ {J})]\). We then determine the actual rank of the selected estimator within this list and visualize the distribution of these 100 ranks using a stacked bar chart. Figure 1 shows that many baseline methods tend to select CATE estimators from various percentile ranges, leading to high variance across the 100 selections. Notably, the DRM selector consistently chooses higher-ranked (i.e., better performing in PEHE) estimators, demonstrating its robustness in CATE estimator selection.

Potential improvements.There are several potential improvements based on the current experimental settings. First, the existing results suggest that Plug-S performs better than Plug-T, indicating that the complexity of CATE function is relatively simple. It would help to provide more comprehensive analysis if investigating how DRM compares to baselines when the CATE function is more complex. Second, since the impact of selection bias can vary with sample size , it is important to compare different selectors when the sample size is sufficiently large. Third, considering baselines that are specifically designed for addressing hidden confounders could provide valuable insights for testing different selectors under such conditions. We encourage deeper investigation of causal model selection without assuming unconfoundedness. Finally, it would be good if future studies will apply DRM and other selectors in Healthcare, Economics, and Business applications with real-world data, as CATE estimator selection plays an important role in personalized decision makings.

## 6 Conclusion

This paper sheds lights on the potential of robustness in CATE estimator selection. We propose a distributionally robust metric (DRM). The proposed metric is nuisance-free, eliminating the need to fit models for nuisance parameters (outcome function, propensity function, and plug-in learner). Additionally, it is well-targeted for selecting a robust CATE estimator. We provide a finite sample analysis that demonstrates the gap between \(}^{t}()\) and \(^{t}()\) reduces at a rate of \(n^{-1/2}\) for \(t\{0,1\}\). The experimental results showcase that the CATE estimator selected by DRM demonstrate robustness to the distribution shift incurred by covariate shift and hidden confounders.

Limitations and future work.This paper explores the potential of robustness in CATE estimator selection. However, we must acknowledge that our DRM method is not a silver bullet, as consistent estimation on the CATE are never attainable . Here, we outline some challenges and suggest future research directions. First, while Proposition 4.6 provides useful guidance for setting ambiguity radius in the DRM algorithm, we cannot guarantee that the empirically-computed radius is optimal due to potential bias in the algorithm's approximation of KL-divergence. Second, as discussed in Section 5.2, enhancing the ranking capability of DRM is a promising area for further research. Moreover, our findings are based on KL-divergence. However, using other divergences, such as the Wasserstein distance, to construct the ambiguity set could incorporate more diverse distributions, despite the challenges in solving the dual formulation of the Wasserstein distributionally robust value. Simultaneously, exploring whether alternative divergences can yield a tighter bound for the PEHE error is also interesting . Finally, inspired by , understanding how nuisance parameters influence metrics like plug-DR and pseudo-DR might be helpful in CATE estimator selection. We hope our methods and findings will spur interest in model selection for causal inference, as well as in related fields like domain adaptation and out-of-distribution generalization.