# A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs

Yan Sun

The University of Sydney

ysun9899@uni.sydney.edu.au &Li Shen

Shenzhenen Campus of Sun Yat-sen University

mathshelni@gmail.com &Dacheng Tao

Nanyang Technological University

dacheng.tao@ntu.edu.sg

Li Shen is the corresponding author.

Li Shen is the corresponding author.

###### Abstract

As a popular paradigm for juggling data privacy and collaborative training, federated learning (FL) is flourishing to distributively process the large scale of heterogeneous datasets on edged clients. Due to bandwidth limitations and security considerations, it ingeniously splits the original problem into multiple subproblems to be solved in parallel, which empowers _primal dual_ solutions to great application values in FL. In this paper, we review the recent development of classical _federated primal dual_ methods and point out a serious common defect of such methods in non-convex scenarios, which we say is a "dual drift" caused by dual hysteresis of those longstanding inactive clients under partial participation training. To further address this problem, we propose a novel _Aligned **Fed**erated **Primal Dual** (**A-FedPD**) method, which constructs virtual dual updates to align global consensus and local dual variables for those protracted unparticipated local clients. Meanwhile, we provide a comprehensive analysis of the optimization and generalization efficiency for the _A-FedPD_ method on smooth non-convex objectives, which confirms its high efficiency and practicality. Extensive experiments are conducted on several classical FL setups to validate the effectiveness of our proposed method.

## 1 Introduction

Since McMahan et al. (2017) propose the _federated average_ paradigm, FL has gradually become a promising approach to handle both data privacy and efficient training on the large scale of edged clients, which employs a global server to coordinate local clients jointly train one model. Due to privacy protection, it disables the direct information interaction across clients. All clients must only communicate with an accredited global server. This paradigm creates an unavoidable issue, that is, bandwidth congestion caused by mass communication. Therefore, FL advocates training models on local clients as much as possible within the maximum bandwidth utilization range and only communicates with a part of clients per communication round in a partial participation manner. Under this particular training mechanism, FL needs to effectively split the original problem into several subproblems for local clients to solve in parallel. Because of this harsh limitation, general algorithms are often less efficient in practice. But the _primal dual_ methods just match this training pattern, which empowers it with huge application potential and great values in FL.

_Primal dual_ methods, which are specified as _Lagrangian primal dual_ in this paper, solve the problem by penalizing and relaxing the constraints to the original objective via non-negative Lagrange multipliers, which make great progress in convex optimization. It benefits from the consideration of splitting a large problem into several small simple problems to solve, which has been widely developed and applied in the distributed framework as a global consensus problem. This solution is also well suited to the FL scenarios for its effective split characteristic. Recent studies revealed the application potential of such methods. Since Tran Dinh et al. (2021) propose the _Randomized Douglas-Rachford Splitting_ in FL, which unblocks the study of this important branch. With further exploration of Zhang et al. (2021); Durmus et al. (2021); Zhang and Hong (2021), _federated primal dual_ methods are proven to achieve the fast \((1/T)\) convergence rate. Then it is expanded to the more complicated scenarios and incorporated with several novel techniques to achieve state-of-the-art (SOTA) performance in the FL community, which further confirms the great contributions.

However, as studies go further, a series of problems of _federated primal dual_ methods in the experiments are also exposed. Sensitivity to hyper-parameters and fluctuations affected by the large scale makes it extremely unstable in practice, especially in the partial participation manner which is one of the most important concerns in FL. Specifically, _primal dual_ methods successfully solve the problems by alternately updating each primal variable and each dual variable. When it is grafted onto the partial participation training in FL, most clients will remain inactive for a long time, which means most of the dual variables will be stagnant and very outdated in the training. As the training process continues, when one long-term inactive client is reactivated to participate in training, the solving process of its local subproblem will become extremely unstable due to excessive differences between the primal and dual variables, and sometimes even fail. We call this a "_dual drift_" problem, which is also one of the most formidable challenges in practice in FL. In Fig.1, we clearly show how the "_dual drift_" deteriorates as the participation ratio decreases.

To efficiently expand the _primal dual_ methods to partial participation scenarios while enhancing the training stability in practice, and further alleviate the "_dual drift_" problem, we propose a novel algorithm, named _Aligned Federated Primal Dual (A-FedPD)_, which constructs the virtual dual updates for those unparticipated clients per communication round to align with primal variables. Concretely, after each communication round, we first aggregate the local solutions received from active clients as the unbiased approximation of the local solution of those unparticipated clients. Then we provide a virtual update on the dual variables to align with the primal variable in the training. Updating errors for dual variables will be diminished as global consensus is achieved. The proposed _A-FedPD_ method enables unparticipated clients to keep up-to-date, which approximates the quasi-full-participation training, which can efficiently alleviate the "_dual drift_" in practice.

Furthermore, we provide a comprehensive analysis of the optimization and generalization efficiency of the proposed _A-FedPD_ method, which also could be easily extended to the whole _federated primal dual family_. On smooth non-convex objectives, compared with the vanilla _FedAvg_ method, the _A-FedPD_ could achieve a fast \((1/T)\) convergence rate which maintains consistent with SOTA _federated primal dual_ methods. Moreover, it could support longer local training without affecting stability. Under the same training costs, the _A-FedPD_ method achieves less generalization error. We conduct extensive experiments to validate its efficiency across several general federated setups. We also test a simple variant to show its good scalability incorporated with other novel techniques in FL.

We summarize our major contributions as follows:

* We review the development of _federated primal dual family_ and point out one of its most formidable challenges in the practical application in FL, which is summarized as the "_dual drift_" problem in this paper.
* We propose a novel _A-FedPD_ method to alleviate the "_dual drift_", which constructs the virtual update for dual variables of those unparticipated clients to align with primal variables.

Figure 1: “_Dual drift_” issue of the _federated primal dual_ method under different participation ratios. When the participation ratio is low, _dual drift_ introduces a very large variance, yielding divergence.

* We provide a comprehensive analysis of the optimization and generalization efficiency of _A-FedPD_. It could achieve a fast convergence rate and a lower generalization error bound than the vanilla _FedAvg_ method.
* Extensive experiments are conducted to validate the performance of the _A-FedPD_ method. Furthermore, we test a simple variant of it to show its good scalability.

## 2 Related Work

_Federated primal average._ Since McMahan et al. (2017) propose the _FedAvg_ paradigm, a lot of _primal average_-based methods are learned to enhance its performance. Most of them target strengthening global consistency and alleviating the "client drift" problem (Karimireddy et al., 2020). Li et al. (2020) propose to adopt proxy terms to control local updates. Karimireddy et al. (2020) propose the variance reduction version to handle the biases in the _primal average_. Similar implementations include (Dieuleveut et al., 2021; Jhunjihunwala et al., 2022). Moreover, momentum-based methods are also popular for correcting local biases. Ozfatura et al. (2021); Xu et al. (2021) propose to adopt the global consistency controller in the local training to force a high consensus. Remedios et al. (2020) expand the local momentum to achieve higher accuracy in the training. Similarly, Wang et al. (2019); Kim et al. (2022) incorporate the global momentum which could further improve its performance. Wang et al. (2020) tackle the local inconsistency and utilize the _weighted primal average_ to balance different clients with different computing power. Based on this, Horvath et al. (2022) further select the important clients set to balance the training trends under different heterogeneous datasets. Liu et al. (2023) summarize the inertial momentum implementation which could achieve a more stable result. Qu et al. (2022) utilize the _Sharpeness Aware Minimization_ (_SAM_) (Foret et al., 2020) to make the loss landscape smooth with higher generalization performance. Then Caldarola et al. (2022, 2023) propose to improve its stability via _Adaptive SAM_ and window-based model averaging. In summary, _Federated primal average_ methods focus on alleviating the local inconsistency caused by "client drift" (Malinovskiy et al., 2020; Wang et al., 2020; Charles and Konecny, 2021). However, as analyzed by Durmus et al. (2021), the _federated primal dual_ methods will regularize the local objective gradually close to global consensus by dynamically adjusting the dual variables. This allows "client drift" to be effectively translated into a dual consistency problem on cross-silo devices.

_Convex optimization of federated primal dual._ The primal-dual method was originally proposed to solve convex optimization problems and achieved high theoretical performance. In the FL setups, this method has also made significant advancements. Grudzien et al. (2023) compute inexactly a proximity operator to work as a variant of primal dual methods. Another technique is loopless instead of an inner loop of local steps. Mishchenko et al. (2022) propose the _Scaffiwe_ method to achieve the higher optimization efficiency, which is interpreted as a variant of primal dual approach (Condat and Richtarik, 2022). These techniques can also be easily combined with existing efficient communication methods, e.g. compression and quantization (Grudzien et al., 2023; Condat et al., 2023).

_Non-convex optimization of federated primal dual._ Since Tran Dinh et al. (2021) adopt the _Randomized Douglas-Rachford Splitting_, which unblocks the study of the important branch of utilizing _primal dual_ methods in FL (Pathak and Wainwright, 2020). With further exploration of Zhang et al. (2021), _federated primal dual_ methods are proven to achieve the fast convergence rate. Yuan et al. (2021) learn the composite optimization via a _primal dual_ method in FL. Meanwhile, Sarcheshmehpour et al. (2021) empower its potential on the undirected empirical graph. Shen et al. (2021) also study an agnostic approach under class imbalance targets. Then, Gong et al. (2022), Wang et al. (2022) expand its theoretical analysis to the partial participation scenarios with global regularization. Durmus et al. (2021) improve its implementation by introducing the global dual variable. Moreover, Zhou and Li (2023) learn the effect of subproblem precision on training efficiency. Sun et al. (2023, 2023) incorporate it with the _SAM_ to achieve a higher generalization efficiency. Niu and Wei (2023) propose hybrid _primal dual_ updates with both first-order and second-order optimization. Wang et al. (2023) propose a variance reduction variant to further improve the training efficiency. Li et al. (2023) expand it to a decentralized approach, which could achieve comparable performance in the centralized. Tyou et al. (2023) propose a localized _primal dual_ approach for FL training. Li et al. (2023) further explore its efficiency on the specific non-convex objectives with non-smooth regularization. Current researches reveal the great application value of the _primal dual_ methods in FL. However, most of them still face the serious "_dual drift_" problem at low participation ratios. Our improvements further alleviate this issue and make the _federated primal dual_ methods perform more stably in the FL community.

## 3 Methodology

We first review the _primal dual_ methods in FL and demonstrate the "_dual drift_" issue. Then, we demonstrate the _A-FedPD_ approach to eliminate the "_dual drift_" challenge. Notations are stated in Table 1. Other symbols are defined when they are first introduced. We denote \(\) as the real set and \(\) as the expectation in the corresponding probability space. Other notations are defined as first stated.

### Preliminaries

**Setups.** In the general and classical federated frameworks, we usually consider the general objective as a finite-sum minimization problem \(F():^{d}\),

\[_{}F()=_{i}F_{i}(), F _{i}()_{_{i}}f_{i}(,).\] (1)

In each client, there exists a local private data set \(_{i}\) which is considered a uniform sampling set of the distribution \(_{i}\). In FL setups, \(_{i}\) is unknown to others for the privacy protection mechanism. Therefore, we usually consider the local _Empirical Risk Minimization (ERM)_ as:

\[_{}f()=_{i}f_{i}(), f _{i}()_{_{i}}f_{i}(,).\] (2)

Our desired optimal solution is \(^{*}=*{arg\,min}F()\). However, we can only approximate it on the limited dataset as \(^{*}_{}=*{arg\,min}f()\), which spontaneously introduces the unavoidable biases on its generalization performance. This is one of the main concerns in the field of the current machine learning community. Motivated by this imminent challenge, we conduct a comprehensive study on the performance of _primal dual_-based algorithms in FL and further propose an improvement to enhance its generalization efficiency and stability performance.

### _Primal Dual_-family in FL

_Primal Dual_ methods optimize the global objective by decomposing it into several subproblems and iteratively updating local variables incorporated by Lagrangian multipliers (Boyd et al., 2011), which gives it a unique position in solving FL problems. Due to local data privacy, we have to split the global task into several local tasks for optimization on their private dataset. This similarity also provides an adequate foundation for their applications in the FL community. A lot of studies extend it to the general FL framework and achieve considerable success.

We follow studies (Zhang et al., 2021; Durmus et al., 2021; Wang et al., 2022; Gong et al., 2022; Sun et al., 2023; Zhou and Li, 2023; Sun et al., 2023; Fan et al., 2023; Zhang et al., 2024) to summarize the original objective Eq.(2) as the global consensus reformulation:

\[_{,_{i}}_{i}f_{i}(_{i}), _{i}=, i.\] (3)

By relaxing equality constraints \(_{i}=\), Eq.(3) is separable across different local clients. Wang et al. (2022) demonstrate the difference between the solution on the primal problem and dual problem in detail and confirm the equivalence of these two cases in FL. By penalizing the constraint on the local objective \(f_{i}\), we can define the augmented Lagrangian function associated with Eq.(3) as:

\[(_{i},,_{i})=_{i} [f_{i}(_{i})+_{i},_{i}-+\|_{i}-\|^{2}],\] (4)

where \(\) denotes the penalty coefficient. To train the global model, each local client should first minimize the local augmented Lagrangian function and solve for local parameters. Based on updated local parameters, we then update the dual variable to align the Lagrangian function with the consensus

   Symbol & Notations \\  \(\) / \(C\) & client set / size of client set \\ \(\) / \(P\) & active client set / size of active client set \\ \(_{i}\) / \(S\) & local dataset / size of local dataset \\ \(\) / \(_{i}\) & global parameters / local parameters \\ \(\) / \(_{i}\) & global dual parameters / local dual parameters \\ \(T\) / \(t\) & training round / index of training round \\ \(K\) / \(k\) & local interval / index of local interval \\ \(\) & proxy coefficient \\   

Table 1: Notations adopted in this paper.

constraints. Finally, we minimize the augmented Lagrangian function and solve for the consensus. Objective Eq.(3) could be solved after multiple alternating updates as:

\[\{^{t+1}_{i}&=&_{_{i}}\ ( ^{t}_{i},^{t},^{t}_{i}) i,\\ ^{t+1}_{i}&=&^{t}_{i}+(^{t+1}_{i}-^{t}),\\ ^{t+1}&=&_{i}(^{t+1}_{i}+^{t+1}_{i})..\] (5)

We then review the classical _federated primal dual_ methods.

_FedPD_. Zhang et al. (2021) propose a general federated framework from the primal-dual optimization perspective which can be directly summarized as Eq.(5). As an underlying method in the federated _primal dual_-family, it requires all local clients to participate in the training per round, which also significantly reduces communication efficiency.

_FedADMM_. Wang et al. (2022) extend the theory of the primal-dual optimization in FL and prove the equivalence between _FedDR_(Tran Dinh et al., 2021) and _FedADMM_. Furthermore, it considers the complete format of composite objective \(f(_{i})+g()\). To optimize the composite objective, after the iterations of Eq.(5), it additionally solves the proximal step on the function \(g()\):

\[\{^{t+1}_{i}&=&_{_{i}}\ ( ^{t}_{i},^{t},^{t}_{i})+g(^{t}) i ^{t},\\ ^{t+1}_{i}&=&^{t}_{i}+(^{t+1}_{i}-^{t}),\\ ^{t+1}&=&_{i^{t}}(^{t+1 }_{i}+^{t+1}_{i}),\\ ^{t+1}&=& g(^{t})+\|^{t}-^{t+1}\|^{2}..\] (6)

_FedADMM_ introduces a more general update with the regularization term \(g()\) and supports the partial participation training mechanism, which also brings a great application value of primal-dual methods to the FL community. When \(g() 0\), it degrades to the partial _FedPD_ by \(^{t+1}=^{t+1}\). When \(^{t}\), "_dual drift_" brings great distress for training.

_FedDyn_. Durmus et al. (2021) utilize the insight of primal-dual optimization to introduce a dynamic regularization term to solve the local augmented Lagrangian function, which is actually the dual variable in _FedADMM_. Differently, they propose a global dual variable \(^{t}\) to update global parameters \(^{t}\) instead of only active local dual variables \(^{t}_{i}\) (\(i^{t}\)):

\[\{^{t+1}_{i}&=&_{_{i}}\ ( ^{t}_{i},^{t},^{t}_{i}) i^{t},\\ ^{t+1}_{i}&=&^{t}_{i}+(^{t+1}_{i}-^{t}),\\ ^{t+1}&=&^{t}+_{i^{t}}(^{ t+1}_{i}-^{t}),\\ ^{t+1}&=&_{i^{t}}^{t+1}_{i}+^{t}..\] (7)

Compared with _FedADMM_, although the global dual variable further corrects the primal parameters, it still hinders the training efficiency, which must rely on the anachronistic historical directions of the local dual variables. Moreover, the global dual variable always updates slowly, which results in consensus constraints that are more difficult to satisfy when solving local subproblems.

_Dual drift_. Kang et al. (2024) have indicated that the update mismatch between primal and dual variables leads to a "drift". Here, we provide a detailed analysis of the key differences caused by this mismatch. When adopting partial participation, each client is activated at a very low probability, especially on a large scale of edged devices, which widely leads to very high hysteresis between global parameters \(\) and local dual variable \(_{i}\). For instance, at round \(t\), we select a subset \(^{t}\) to participate in current training and then update the global parameters by \(^{t+1}=_{}\ (^{t+1}_{i},^{t}, ^{t}_{i})\) for \(i^{t}\). Then at round \(t+1\), when a client \(i\{^{}\}_{=t_{0}+1}^{t}\ (t_{0} t)\) that has not been involved in training for a long time is activated, its local dual variable \(^{t_{0}}_{i}\) may severely mismatch the current global parameters \(^{t}\). This triggers that the local subproblem \((^{t+1}_{i},^{t+1},^{t_{0}}_{i})\) fail to be optimized properly and even become completely distorted in extreme scenarios, yielding a "_dual drift_" issue.

### A-FedPD Method

As introduced in the last part, "_dual drift_" problem usually results in the unstable optimization of each local subproblem under partial participation. To further mitigate the negative effects of _dual drift_ problems and improve the training efficiency, we propose a novel _A-FedPD_ method (see Algorithm 1), which aligns the virtual dual variables of unparticipated clients via global average models.

Specifically, we solve dual variables for unified management and distribution. At round \(t\), we select an active client set \(^{t}\) and send the corresponding variables to each active client. Then local client solves the subproblem with \(K\) stochastic gradient descent steps and sends the last state \(^{t}_{i,K}\) back to the global server. On the global server, it first aggregates the updated parameters as \(^{t+1}\). Then it performs the updates of the dual variables. For each active client \(i^{t}\), it equally updates the local dual variable as vanilla _FedPD_. For the unparticipated clients \(i^{t}\), they update the virtual dual variable with the aggregated parameters \(^{t+1}\). Finally, we can update the global model with the aggregated parameters and averaged dual variables. Since each client virtually updates, we can directly use the global average as the output. Repeat this training process for a total of \(T\) communication rounds to output the final global average model.

Because of the central storage and management of the dual variables on the global server, it significantly reduces storage requirements for lightweight-edged devices, i.e., mobile phones. For the unparticipated clients, we use their unbiased estimations \([w^{t+1}_{i}\,|\,w^{t}]=_{^{t}}[ _{i^{t}}w^{t+1}_{i}|\,w^{t}]\) to construct the virtual dual update, which maintains a continuous update of local dual variables. For the global averaged dual variable \(\), we can reformulate its update as \(^{t+1}=^{t}+(^{t+1}- ^{t})\) which also could be approximated as a virtual all participation case. This efficiently alleviates the _dual drift_ between \(^{t}\) and \(^{t}_{i}\) and also ensures fast iteration of the global dual variable in the training, which constitutes an efficient federated framework.

## 4 Theoretical Analysis

In this part, we mainly introduce the theoretical analysis of the optimization and generalization efficiency of our proposed _A-FedPD_ method. We first introduce the assumptions adopted in our proofs. Optimization analysis is stated in Sec.4.1 and generalization analysis is stated in Sec.4.2.

**Assumption 1** (Smoothness): _The local function \(f_{i}()\) satisfies the \(L\)-smoothness property, i.e., \(\| f_{i}(_{1})- f_{i}(_{2})\| L\|_{1}- _{2}\|\)._

**Assumption 2** (Lipschitz continuity): _For \(\ _{1},_{2}^{d}\), the global function \(f()\) satisfies the Lipschitz-continuity, i.e., \(\|f(_{1})-f(_{2})\| G\|_{1}-_{2}\|\)._

Optimization analysis only adopts Assumption 1. Generalization analysis adopts both assumptions that were followed from the previous work on analyzing the stability (Hardt et al., 2016; Lei and Ying, 2020; Zhou et al., 2021; Sun et al., 2023;,c). Moreover, we consider that the minimization of each local Lagrangian problem achieves the \(\)-inexact solution during each local training process, i.e. \(\|_{i}\|^{2}\)(Zhang et al., 2021; Li et al., 2023; Gong et al., 2022; Wang et al., 2022). This consideration is more aligned with the practical scenarios encountered in the empirical studies for non-convex optimization. In fact, it is precisely because the errors from local inexact solutions can be excessively large that the _dual drift_ problem is further exacerbated.

### Optimization

In this part, we introduce the convergence analysis of the proposed _A-FedPD_ method.

**Theorem 1**: _Let non-convex objective \(f\) satisfies Assumption 1, let \(\) be selected as a non-zero positive constant, \(\{^{t}\}_{t=0}^{T}\) sequence generated by algorithm 1 satisfies:_

\[_{t=1}^{T}\| f(^{t})\|^{2} {[f(^{1})-f^{}]+R_{0}}{T}+( ),\] (8)

_where \(f^{}\) is the optimum and \(R_{0}=_{i}_{t}\|_{i}^{1}-^{ 0}\|^{2}\) is the first local training volumes._

**Remark 1.1**: _To achieve the \(\) error, the A-FedPD requires \((^{-1})\) rounds, yielding \((1/T)\) convergence rate. Concretely, the federated primal dual methods can locally train more and communicate less, which empowers it a great potential in the applications. Our analysis is consistent with the previous understandings (Zhang et al., 2021; Durmus et al., 2021; Gong et al., 2022; Li et al., 2023a)._

**Remark 1.2**: _Generally, the federated primal-dual methods require a long local interval. Zhang et al. (2021); Gong et al. (2022); Wang et al. (2022) have summarized the corresponding selections of \(K\) for different local optimizers. To complete the analysis, we just list a general selection of the local interval \(K\). Specifically, to achieve the \(\) error, local interval \(K\) of A-FedPD can be selected as \((^{-1})\) with total \((^{-2})\) sample complexity in the training. Due to the page limitation, we state more discussions in the Appendix B.2.2._

### Generalization

In this part, we explore the efficiency of _A-FedPD_ from the stability and generalization perspective, which could also be extended to the common _primal dual_-family in the federated learning community. We first introduce the setups and assumptions and then demonstrate the main theorem and discussions.

**Setups.** To understand the stability and generalization efficiency, we follow Hardt et al. (2016); Lei and Ying (2020); Zhou et al. (2021); Sun et al. (2023) to adopt the uniform stability analysis to measure its error bound. To learn the generalization gap \([F(^{T})-f(^{T})]\) where \(^{T}\) is generated by a stochastic algorithm, we could study its stability gaps. We consider a joint client set \(\) (union dataset) for training. Each client \(i\) has a private dataset \(_{i}\) with total \(S\) samples which are sampled from the unknown distribution \(_{i}\). To explore the stability gaps, we construct a mirror dataset \(}\) that there is at most one different data sample from the raw dataset \(\). Let \(^{T}\) and \(^{T}\) be two models trained on \(\) and \(}\) respectively. Therefore, the generalization of a uniformly stable method satisfies:

\[[|F(^{T})-f(^{T})|]_{} [|f(^{T},)-f(^{T},)|].\] (9)

**Key properties.** From the local training, we can first upper bound the local stability. To compare the difference between vanilla _SGD_ updates and _primal dual_-family updates, we can reformulate them:

\[_{i,k+1}^{i}-^{t}&=(_{i,k}^{t}-^{t})+ ^{t}g_{i,k}^{t},\\ _{i,k+1}^{i}-^{t}&=(1-^{t})(_{i,k}^{t}-^{t})+ ^{t}(g_{i,k}^{t}+_{i}).\] (10)

The above update is for vanilla _FedAvg_ and the below update is for _primal dual_-family. When the dual variables are ignored, local update \(_{i,k}^{t}-^{t}\) in _primal dual_ could be considered as a stable decayed sequence with \(1-^{t}\) that has a constant upper bound. Based on this, we can provide a tighter generalization error bound for the _primal dual_-family methods in FL than the vanilla _FedAvg_ method.

**Theorem 2**: _Let non-convex objective \(f\) satisfies Assumption 1 and 2 and \(H=_{,}f(,)\), after \(T\) communication rounds training with Algorithm 1, the generalization error bound achieves:_

\[[F(^{T})-f(^{T})]}{CS} (HPT)^{},\] (11)

_where \(\) is a constant related to the learning rate and \(_{c}=4(G^{2}/L)^{}\) is a constant._

**Remark 2.1**: _We assume that the total number of data samples participating in the training is \(CS\) and the total iterations of the training are \(KT\). Hardt et al. (2016) prove that on non-convex objectives, vanilla SGD method achieves \(((TK)^{}/CS)\) error bound. Compared with SGD, FLadopts the cyclical local training and partial participation mechanism which further increases the stability error. Sun et al. (2023) learn a fast rate on sample size as \(((PKT)^{}}/CS)\) under the Lipschitz assumption only. However, primal dual-family can achieve faster rate \(((PKT)^{}}/CS)\) in FL, which is due to the stable iterations in Eq.(10). It guarantees that the local training could be bounded in a constant order even under the fixed learning rate. From the local training perspective, primal dual-family in FL can support a very long local interval \(K\) without losing stability. This property is also proven in its optimization progress, that the primal dual-family could adopt a larger local interval to accelerate the training and reduce the communication rounds. In general training, especially in situations where communication bandwidth is limited and frequent communication is not possible, the primal dual-family in FL could achieve a more stable result than the general methods. Our analysis further confirms its good adaptivity in FL. Due to page limitation, we summarize some recent results of the generalization error bound in Appendix B.3.2.

## 5 Experiments

In this section, we introduce the experiments conducted to validate the efficiency of our proposed _A-FedPD_ and a variant _A-FedPDSAM_ (see details in Appendix A.1). We first introduce experimental setups and benchmarks, and then we show the empirical studies.

**Backbones and Datasets.** In our experiments, we adopt LeNet LeCun et al. (1998) and ResNet He et al. (2016) as backbones. We follow previous work to test the performance of benchmarks on the CIFAR-10 / 100 dataset Krizhevsky et al. (2009). We introduce the heterogeneity to split the raw dataset to local clients with independent Dirichlet distribution Hsu et al. (2019) controlled by a concentration parameter. In our setups, we mainly test the performance of the IID, Dir-1.0, and Dir-0.1 splitting. The Dir-1.0 represents the low heterogeneity and Dir-0.1 represents the high heterogeneity. We also adopt the sampling with replacement to further enhance the heterogeneity.

**Setups.** We test the accuracy experiments on \(C=100\) and \(P/C=10\%\), which is also the most popular setup in the FL community. In the comparison experiments, we test the participated ratio \(P/C=[5\%,10\%,20\%,50\%,80\%,100\%]\) and local interval \(K=\) respectively. In each setup, for a fair comparison, we freeze the most of hyperparameters for all methods. We fix total communication rounds \(T=800\) except for the ablation studies.

**Baselines.**_FedAvg_(McMahan et al., 2017) is the fundamental paradigm in FL scenarios. _FedCM_(Xu et al., 2021), _SCAFFOLD_(Karimireddy et al., 2020) and _FedSAM_(Qu et al., 2022) are three classical SOTA methods in the federated primal average family. _FedDyn_(Durmus et al., 2021) and

    & &  &  \\   & Family & Local Opt & ID & Dir-1.0 &  &  &  &  \\   & & & Dir-1.0 & Dir-0.1 &  &  &  &  \\  FedAvg & P & SGD & 81.87\(_{1.2}\) & 80.58\(_{1.5}\) & 75.57\(_{2.7}\) & 40.11\(_{1.1}\) & 39.65\(_{0.7}\) & 38.37\(_{1.4}\) \\ FedCM & P & SGD & 80.34\(_{1.4}\) & 79.31\(_{2.5}\) & 72.89\(_{3.7}\) & 43.33\(_{1.3}\) & 42.35\(_{2.5}\) & 37.11\(_{1.51}\) \\ SCAFFOLD & P & SGD & 84.25\(_{1.6}\) & 83.61\(_{1.4}\) & 78.66\(_{2.9}\) & 49.65\(_{0.6}\) & 49.11\(_{1.4}\) & 46.36\(_{3.00}\) \\ FedSAM & P & SAM & 83.22\(_{0.9}\) & 81.94\(_{1.3}\) & 77.41\(_{1.6}\) & 43.02\(_{0.9}\) & 42.83\(_{2.9}\) & 42.29\(_{2.32}\) \\ FedDyn & PD & SGD & 84.94\(_{2.2}\) & 84.20\(_{1.4}\) & 79.51\(_{1.3}\) & 50.27\(_{1.1}\) & 49.64\(_{2.1}\) & 46.30\(_{2.06}\) \\ FedSpeed & PD & SAM & 86.01\(_{1.8}\) & 85.11\(_{1.2}\) & 80.86\(_{1.8}\) & 54.01\(_{1.5}\) & 53.45\(_{2.32}\) & 51.28\(_{1.88}\) \\  A-FedPD & PD & SGD & 85.31\(_{1.4}\) & 84.94\(_{1.3}\) & 80.28\(_{2.0}\) & 51.41\(_{1.5}\) & 51.17\(_{1.7}\) & 48.15\(_{2.8}\) \\ A-FedPDSAM & PD & SAM & **86.47\(_{1.8}\)** & **85.90\(_{2.9}\)** & **81.96\(_{1.9}\)** & **55.56\(_{2.7}\)** & **54.62\(_{1.6}\)** & **53.15\(_{1.9}\)** \\  FedAvg & P & SGD & 81.67\(_{1.2}\) & 80.94\(_{1.7}\) & 76.24\(_{2.5}\) & 44.68\(_{2.1}\) & 44.27\(_{1.4}\) & 41.64\(_{2.7}\) \\ FedCM & P & SGD & 84.22\(_{1.1}\) & 88.25\(_{2.2}\) & 76.93\(_{2.32}\) & 50.04\(_{1.6}\) & 48.66\(_{2.8}\) & 44.07\(_{3.00}\) \\ SCAFFOLD & P & SGD & 84.31\(_{1.4}\) & 83.70\(_{1.1}\) & 78.70\(_{2.1}\) & 50.69\(_{2.1}\) & 50.28\(_{2.1}\) & 47.12\(_{3.4}\) \\ FedSAM & P & SAM & 83.79\(_{2.8}\) & 82.85\(_{1.9}\) & 78.37\(_{2.7}\) & 48.66\(_{2.9}\) & 48.42\(_{1.9}\) & 45.03\(_{2.2}\) \\ FedDyn & PD & SGD & 83.71\(_{1.26}\) & 826.65\(_{1.5}\) & 79.44\(_{2.5}\) & & & & \\ FedSpeed & PD & SAM & 86.90\(_{1.8}\) & 85.92\(_{2.4}\) & 81.47\(_{1.9}\) & 53.22\(_{2.8}\) & 52.75\(_{1.6}\) & 49.66\(_{1.3}\) \\  A-FedPD & PD & SGD & 85.11\(_{1.2}\) & 84.33\(_{1.6}\) & 81.05\(_{2.8}\) & 48.15\(_{2.2}\) & 48.02\(_{2.9}\) & 46.24\(_{2.6}\) \\ A-FedPDSAM & PD & SAM & **87.44\(_{1.3}\)** & **86.46\(_{2.5}\)** & **82.48\(_{2.1}\)** & **55.30\(_{2.3}\)** & **53.49\(_{1.7}\)** & **50.31\(_{2.3}\)** \\   

Table 2: Test accuracy on the CIFAR-10 / 100 dataset. We fix the total client \(C=100\) and \(P=10\) under training local 50 iterations. We test 3 setups of IID, Dir-1.0, and Dir-0.1 dataset. Each group is tested on LeNet (upper portion) and ResNet-18 (lower portion) models. Each results are tested with 4 different random seeds. “\(-\)” means can not stably converge. “Family” distinguishes whether the algorithm is a primal method (P) or a primal method (PD) and “Local Opt” distinguishes whether the algorithm adopts SGD-based or SAM-based local optimizer.

_FedSpeed_Sun et al. (2023b) are relatively stable federated primal dual methods. A more detailed introduction of these methods is presented in Table 2, including the family-basis and local optimizer.

### Experiments

In this part, we introduce the phenomena observed in our empirical studies. We primarily investigated performance comparisons, including settings with different participation rates, various local intervals, and different numbers of communication rounds. Then we report the comparison of wall-clock time.

**Performance Comparison.** Table 2 shows the test accuracy on CIFAR-10 / 100 dataset. The vanilla _FedAvg_ provides the standard bars as the baseline. In the _federated primal average_ methods, The _FedCM_ is not stable enough and is largely affected by different backbones, which is caused by the forced consistency momentum and may introduce very large biases. _SCAFFOLD_ and _FedSAM_ performs well. However, both are less than the _primal dual_-based methods. In summary, _SCAFFOLD_ is on average 3.2% lower than _FedSpeed_. As heterogeneity increases, _SCAFFOLD_ drops on average about 5.6% on CIFAR-10 and 3.43% on CIFAR-100. In the _federated primal dual_ methods, we can clearly see that _FedDyn_ is not stable in the training. It performs well on the LeNet, which could achieve at least 1% improvements than _SCAFFOLD_. However, when the task becomes difficult, i.e., ResNet-18 on CIFAR-100, its accuracy is affected by the "dual drift" and drops quickly. To maintain stability, we have to select some weak coefficients to stabilize it and finally get a lower accuracy. Our proposed _A-FedPD_ could efficiently alleviate the negative impacts of the "dual drift". It performs about on average 0.8% higher than _FedDyn_ on the CIFAR-10 dataset. When _FedDyn_ has to compromise the hyperparameters and becomes extremely unstable on ResNet-18 on the CIFAR-100 dataset, _A-FedPD_ still performs stably. It's also very scalable. When we introduce the _SAM_ optimizer to replace the vanilla _SGD_, it could achieve higher performance.

**Different Participation Ratios.** In this part we compare the sensitivity to the participation ratios. In each setup, we fix the scale as 100 and the local interval as 50 iterations. Active ratio is selected from \([5\%,10\%,20\%,50\%,80\%,100\%]\) as shown in Figure 2 (a). Under frozen hyperparameters, all methods perform well on each selection. The best performance is approximately located in the range of \([20\%,80\%]\). Our proposed methods achieve high efficiency in handling large-scale training, which performs more steadily than other benchmarks across all selections.

**Different Local Intervals.** In this part we compare the sensitivity to the local intervals. In each setup, we fix the scale as 100 and the participation as 10%. Local interval \(K\) is selected from \(\) as shown in Figure 2 (b). More local training iterations usually mean more overfitting on the local dataset, which leads to a serious "client drift" issue. All methods will be affected by this and drop accuracy. It is a trade-off in selecting the local interval \(K\) to balance both optimization efficiency and generalization stability. Our proposed methods still could achieve the best performance even on the very long local training iterations.

**Different Communication Rounds.** In this part, we compare the sensitivity to the communication rounds. In each setup, we fix total iterations \(TK=40,000\). Communication round \(T\) is selected from \(\) as shown in Figure 2 (c). We always expect the local clients can handle more and communicate less, which will significantly reduce the communication costs. In the

Figure 2: Test of the proposed _A-FedPD_ method on setups of different participation ratios, different local intervals, and different rounds. In these experiments, we fix the total training data samples and total training iterations and then learn their variation trends.

experiments, our proposed methods could achieve higher efficiency than the benchmarks. _A-FedPD_ saves about half the communication overhead compared to _SCAFFOLD_, and about one-third of _FedDyn_. Under favorable communication bandwidths, they can achieve SOTA performance.

**Wall-clock Time Efficiency.** In this part we test the practical wall-clock time comparisons as shown in Figure 3. Though some methods are communication-efficiency, complicated calculations hinder the real efficiency in wall-clock training time. Though _FedSpeed_ and _AFedPDSAM_ perform well at the end, additional calculations per single round make their early-stage competitiveness lower. _AFedPD_ and _SCAF-FOLD_ consume fewer time costs, hence achieving better results at the early stage. Without considering training time costs, _AFedPDSAM_ achieves the SOTA results at the end. Detailed comparisons are stated in Sec.A.4.4.

## 6 Conclusion

In this paper, we first review the development of the _federated primal dual_ methods. Under the exploration of the experiments, we point out a serious challenge that hinders the efficiency of such methods, which is summarized as the "dual drift" problem due to the mismatched primal and dual variables in the partial participation manners. Furthermore, we propose a novel _A-FedPD_ method to alleviate this issue via constructing virtual dual updates for those unparticipated clients. We also theoretically learn its convergence rate and generalization error bound to demonstrate its efficiency. Extensive experiments are conducted to validate its significant performance.

Figure 3: Wall-clock time test of training process after total of 600 communication rounds.