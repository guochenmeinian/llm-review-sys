# Multi-Task Learning with Summary Statistics

Parker Knight

Department of Biostatistics

Harvard University

Boston, MA

pknight@g.harvard.edu &Rui Duan

Department of Biostatistics

Harvard University

Boston, MA

rduan@hsph.harvard.edu

###### Abstract

Multi-task learning has emerged as a powerful machine learning paradigm for integrating data from multiple sources, leveraging similarities between tasks to improve overall model performance. However, the application of multi-task learning to real-world settings is hindered by data-sharing constraints, especially in healthcare settings. To address this challenge, we propose a flexible multi-task learning framework utilizing summary statistics from various sources. Additionally, we present an adaptive parameter selection approach based on a variant of Lepski's method, allowing for data-driven tuning parameter selection when only summary statistics are available. Our systematic non-asymptotic analysis characterizes the performance of the proposed methods under various regimes of the sample complexity and overlap. We demonstrate our theoretical findings and the performance of the method through extensive simulations. This work offers a more flexible tool for training related models across various domains, with practical implications in genetic risk prediction and many other fields.

## 1 Introduction

The growing availability of extensive and intricate datasets presents an opportunity to integrate data from multiple sources. Multi-task learning has emerged as a promising machine learning approach that enables the simultaneous learning of multiple related models, leveraging shared structure between tasks to enhance the performance on each task individually . In healthcare and biomedical research, the practical application of multi-task learning is often hindered by data-sharing constraints, which stem from concerns about the ownership and privacy of individual-level data . Patient data in these domains is typically sensitive and less likely to be publicly available or shared across study sites, limiting researchers' access to individual-level data from different domains.

To overcome this limitation, researchers have increasingly integrated summary statistics into analysis pipelines as a substitute for individual-level data . Summary statistics are straightforward, interpretable measures derived from raw data that can offer insights into data distribution, variability, and relationships among variables. Furthermore, they can be aggregated across studies to facilitate data integration and reused in various research projects. Recently, the use of summary statistics has garnered interest in healthcare and biomedical research. For example, many genetic risk prediction methods rely on summary-level statistics such as associations from Genome-wide Association Studies (GWAS), Linkage Disequilibrium estimations (LD), and minor allele frequencies (MAFs) . These summary statistics can help predict an individual's likelihood of developing specific diseases based on their genetic profile.

Inspired by a potential use case in genetic risk prediction, we propose a multi-task learning framework that enables simultaneous learning of multiple genetic risk prediction models using only publicly available summary statistics. Our proposed framework can be used in the context of predicting genetic risks for multiple traits leveraging potentially shared genetic pathways, and can also be usedto develop trans-ethnic genetic risk prediction models that account for potential heterogeneity across populations, improving generalizability and real-world applicability. Beyond genetic risk prediction, the ability to learn from summary statistics offers a versatile tool for developing models across a wide range of domains, including healthcare, finance, and marketing.

To summarize, the contributions of this work are threefold: First, we propose a flexible multi-task learning framework which allows training multiple models simultaneously using basic summary statistics characterizing marginal relationship between outcomes and features, which are often publicly available. We allow summary statistics corresponding to each task to be generated from distinct or potentially overlapping samples. Secondly, we conducted a systematic non-asymptotic analysis which characterizes how the performance of the proposed methods are influenced by the characteristics of summary statistics. In particular, we show that there are multiple regimes of performance depending on the sample complexity of the source datasets and their overlap. The theoretical results are supported with extensive simulations. Lastly, We propose an adaptive scheme for tuning parameter selection based on the variant of Lepski's method  given in . This allows us to select a data-driven tuning parameter when only summary statistics are available and cross-validation is not feasible. We prove that tuning parameters chosen by this method satisfy an oracle inequality with high probability, and demonstrate the effectiveness of the method via simulations.

### Related work

The use of summary statistics for regression modeling has been considered in the statistical genetics literature . The lassosum method for polygenic risk prediction was introduced by , which considered fitting a \(L_{1}\) penalized linear regression with summary statistics, and its theoretical properties were studied in depth by . In , the authors extend these ideas to polygenic risk prediction with binary traits. The summary statistics used in these methods include the marginal associations between genetic variants and phenotypes, and statistics summarizing the covariance structures among all genetic variants oftentimes derived from a reference genotype dataset. Empirical studies have demonstrated that the efficacy of such models is significantly influenced by the choices of the GWAS summary statistics and the reference dataset . However, there's still limited theoretical understanding regarding how the overlap of samples and the inherent heterogeneity between datasets impact the model performance. Moreover, most current approaches devise models for a single trait within a single ancestral population. Considering shared genetic architectures could potentially enhance performance by employing a multi-task learning strategy .The authors of  take this approach, and describe a multi-task estimator for multi-ancestry pQTL analysis. However, they do not consider the setting when only summary statistics are available for each task.

Our methods build upon classical multi-task learning techniques, and enable fitting models only using basic summary statistics which are often made publicly available. The sparse regularized estimator extends the group-sparse estimators studied in [19; 18], while the nuclear norm estimator expands on the low-rank regression model described in . The nuclear norm approach is closely related to the linear representation learning problem [7; 31], which constrains the regression coefficients to a shared low-dimensional subspace.

Another recent line of work studies the multi-task learning problem under data-sharing constraints. In , the authors describe a federated multi-task learning linear regression model for privacy-preserving data analysis. Similarly,  presents a computational framework for multi-task learning under DataSHIELD  constraints. The formulation of these methods is conceptually similar to ours, but they do not provide theoretical guarantees for their estimators, and we consider a more flexible setting where the summary statistics can be derived from different sources.

Finally, our methods are closely related to the one-shot federated learning paradigm, in which only one round of communication is permitted between the primary local research site and additional sites.  presents an algorithm for fitting logistic regression models using summary statistics from different research sites. The works of [20; 34] extend these ideas to linear mixed effects models and generalized mixed effects models, respectively.  presents a federated algorithm for fitting the Cox proportional hazards model, and  studies federated transfer learning methods for fitting generalized linear models. Nevertheless, the summary statistics addressed in our research are frequently reported in existing studies and can be employed across various models. This is in contrast to the one-shot federated algorithm, where the summary statistics are model specific and the implementation relies on the infrastructure of a collaborative environment.

Problem setup and methods

Consider the setting where we are interested in learning a total of \(Q\) tasks simultaneously. For each \(q[Q]\), we posit the linear model

\[^{(q)}=^{(q)}^{(q)}+^{(q)}\]

where \(^{(q)}^{n_{q}}\), \(^{(q)}^{n_{q} p}\), and \(^{(q)}\) is mean-zero random noise. Each index \(q\) corresponds to the \(q_{th}\) task. The dataset \(^{(q)}=(^{(q)},^{(q)})\) contains the individual-level observations of the outcome and features respectively for the \(q_{th}\) task. We consider the generic setting where the features \(^{(q)}\) might be collected from either overlapping or non-overlapping samples across tasks. Our estimand of interest is the matrix \(^{*}=[^{(1)},...,^{(Q)}]^{p Q}\), where the \(q_{th}\) column of \(^{*}\) is \(^{(q)}\). Furthermore, let \(e_{i}\) denote the \(i_{th}\) standard basis vector, so that \(^{(q)}=^{*}e_{q}\).

If all the individual-level observations \(^{(q)}\) are available, a natural estimator of \(^{*}\) is the regularized multi-task least-squares estimator

\[}=*{arg\,min}_{}\{_{q[ Q]}}\|^{(q)}-^{(q)}e_{q} \|_{2}^{2}+()\}\] (1)

where \(\) is a suitable penalty, chosen to enforce similarity structure between tasks, with tuning parameter \(>0\). However, in many applications, we are less likely to observe \(^{(q)}\). Rather, summary statistics which contains information of the feature-outcome and feature-feature relationships may be more likely to be made publicly available. Motivated by the use case in genetic risk prediction, we assume that only summary statistics \(}^{(q)}\) and \(}^{(q)}\) are observable, where \(}^{(q)}=}^{(q)}{}^{T}^{(q)}\) are derived from \(\{^{(q)},^{(q)}\}\), which we termed as the discovery data, and \(}^{(q)}=}}^{(q)}{} ^{T}}^{(q)}\) is a sample covariance matrix computed from the proxy data \(}^{(q)}^{_{q} p}\), which may or may not have overlap with \(^{(q)}\).

Our goal is to estimate \(^{*}\) using two sets of summary statistics \(}^{(q)}\) and \(}^{(q)}\). We note that \(}^{(q)}\) is not necessarily equal to \(^{(q)}\). In practice, the studies which report \(}^{(q)}\) may not be the same as the ones reporting \(}^{(q)}\). Intuitively, we hope that \(}^{(q)}\) is generated from a similar population as \(^{(q)}\), but this may not hold in general. In Section 3, our theoretical analysis reveals how the overlap between \(}^{(q)}\) and \(^{(q)}\) and their distributional shift can influence the accuracy of multi-task learning.

To construct an estimator that uses only the information provided by \(}^{(q)}\), we notice that the least-squares loss can be written as

\[()=\|-\|_{2}^{2}=^{T}-2,^{T}+^{T} ^{T}\]

By dropping the constant term, we arrive at a loss function that can be computed using only summary-level information, namely the matrices \(^{T}\) and \(^{T}\). This motivates our general strategy for constructing an estimator only using summary statistics: we substitute \(}^{(q)}\) and \(}^{(q)}\) where appropriate in each least-square loss function in Equation 1 and arrive at the following optimization problem.

\[}=*{arg\,min}_{}\{_{q[Q] }\|}^{(q)}{}^{1/2}e_{q} \|_{2}^{2}-}^{(q)},e_{q}+ ()\}\] (2)

There are many possible choices of \(\) for enforcing structure similarities across tasks. For instance, the recent works of  and  study low-rank and angle-based penalties for enforcing a shared orientation among the task-specific parameters. In this work, we study two estimators obtained under the \(_{2,1}\) norm penalty, denoted \(\|.\|_{2,1}\), and the nuclear norm penalty, denoted \(\|.\|_{s}\). These penalties are chosen for their intuitive interpretation: the \(_{2,1}\) penalty is more likely to be effective if a common set of variables are active across the tasks. If the task-specific parameters tend to be "correlated",in the sense that they lie in a low-dimensional subspace, the nuclear norm penalty is preferred. In practice, certain domain knowledge can be incorporated to determine the penalty structure, or it can be chosen in a data-driven way in the existence of a validation dataset.

The corresponding estimators are expressed as follows:

\[}^{(sp)}=*{arg\,min}_{}\{_{q [Q]}\|}^{(q)1/2}e_{q} \|_{2}^{2}-}^{(q)},e_{q}+ \|\|_{2,1}\}\] (3)

\[}^{(lr)}=*{arg\,min}_{}\{_ {q[Q]}\|}^{(q)1/2}e_{q }\|_{2}^{2}-}^{(q)},e_{q}+ \|\|_{*}\}\] (4)

The superscripts \((sp)\) and \((lr)\) stand for "sparse" and "low-rank" respectively.

## 3 Theoretical guarantees

Before presenting our theoretical results, we first introduce the relevant notation. Let \(N\) denote the total size of discovery observations and proxy observation across all \(Q\) tasks. Formally,

\[N=_{q=1}^{Q}(n_{q}+_{q})\]

We note that \(N\) may double-count individuals who are part of both the proxy data and the discovery data. Define the subset \(_{q}[N]\) as the index set for the discovery data points in the \(q_{th}\) task; in other words \(i_{q}\) implies \(X_{i}^{p}\) is a row of \(^{(q)}\). We define \(}_{q}\) analogously for the proxy data; \(i}_{q}\) implies \(X_{i}\) is a row of \(}^{(q)}\). Let \(_{q}=|_{q}}_{q}|/_ {q}\) denote the proportion of proxy samples which are also in the discovery dataset for the \(q_{th}\) task. In the results that follow, let

\[_{q}=1+\|^{(q)}\|_{2}^{2}(}{_{q}}+1 -2_{q})\]

and take \(=_{q}_{q}\). Additionally, let \(^{p Q}\) be the matrix with its \(q_{th}\) column equal to \((_{1}^{(q)}-_{2}^{(q)})^{(q)}\), where \(_{1}^{(q)}\) and \(_{2}^{(q)}\) are the population-level covariance matrices of \(^{(q)}\) and \(}^{(q)}\) respectively. The quantities \(\) and \(\) play important roles in our results that follow. In particular, \(\) is a multiplicative factor in our bounds that represents the cost of using proxy data rather than individual-level data. Similarly, \(\) will represent the cost of using a proxy dataset with a distributional shift from the discovery data. Finally, we will let \(n_{}\) and \(_{}\) denote the smallest sample size of discovery and proxy data, respectively. All proofs are given in the supplement.

### Guarantees for \(_{2,1}\)-norm estimator

In this section, we formally state our assumptions and results for the \(}^{(sp)}\) estimator. The assumptions are standard for high-dimensional regularized estimators, see  for a deeper discussion of these conditions.

**Assumption 3.1** (Sub-gaussian design and noise).: _The following holds for each \(q[Q]\): The rows of \(^{(q)}\) are independent and identically distributed according to a sub-Gaussian distribution with covariance matrix \(_{1}^{(q)}^{p p}\). Similarly, the rows of \(}^{(q)}\) are independent and identically distributed according to a sub-Gaussian distribution with covariance \(_{2}^{(q)}^{p p}\). The matrices \(_{1}^{(q)}\) and \(_{2}^{(q)}\) have bounded eigenvalues. The entries of \(^{(q)}\) are independent and identically distributed according to a sub-Gaussian distribution with parameter \(^{2}\). The \(^{(q)}\) and \(^{(q)}\) are independent of one another._

**Assumption 3.2** (Shared support).: _There exists a subset \(S^{*}[p]\) such that \((^{(q)})=S^{*}\) for each \(q\)._

**Definition 3.1** (Sparse cone).: _For any \(S[p]\), let_

\[_{}(S)=\{^{p Q}:\|_{ S^{c}}\|_{2,1}\|_{S}\|_{2,1}\}\]

**Assumption 3.3** (Restricted strong convexity).: _There exists a constant \(>0\) and a sequence \(a_{N} 0\) as \(N\) such that the following inequality holds for each \(_{3}(S^{*})\) with probability at least \(1-a_{N}\):_

\[_{q=1}^{Q}\|}^{(q)1/2} e_{q}\|_{2 }^{2}\|\|_{F}^{2}\]

**Theorem 3.1**.: _Under assumptions 3.1, 3.2, and 3.3, there exist constants \(c_{1}\) and \(c_{2}\) depending only on the \(^{2}\) and the eigenvalues of \(_{1}^{(q)}\) and \(_{2}^{(q)}\) such that if \(n_{}_{} c_{1}\|^{*}\|_{,}(Q+ p)\) and \(=O(}+\|\|_{2,})\), the following inequality holds with probability at least \(1-e^{- p}-a_{N}\):_

\[\|}^{(sp)}-^{*}\|_{F} c_{2}( }}+\|\|_{2, })\]

In the subsequent discussion, we take \(q^{*}=_{q[Q]}_{q}\) and \((n,n,)=(n_{q^{*}},_{q^{*}},_{q^{*}})\) so that the triplet \((n,,)\) corresponds to the same sizes and overlap factor used to compute \(\).

There are three main quantities in this upper bound that are of novel interest: the ratio of discovery data size to proxy data size \(n/\), the proportion of overlap between the discovery and proxy data \(\), and the error in specifying the proxy data distribution \(=(^{(1)}-^{(2)})\). The first two of these are captured by the factor \(\). Our results show that with fixed \(n\) and \(\), the larger proportion of overlap leads to better estimation accuracy. When the proxy data and discovery data are precisely the same, meaning that \(_{q}=}_{q}\) for all \(q\), we recover the minimax rate of estimation for the \(_{2,1}\) penalized multi-task learning problem established by Theorem 6.1 of . If the proxy data and the discovery data are disjoint, meaning that \(_{q}}_{q}=\) for all \(q\), the error is increased relative to the minimax rate by a factor of \((1+n/)\|\|_{2}^{2}\). This recovers the result of Theorem 2.1 in  up to a constant factor, assuming that \(=0\). The novelty of Theorem 3.1 is that we are able to characterize the convergence rate of \(}^{(sp)}\) for any values of \(n/,\), and \(\). Additionally, we emphasize that the form of the \(\) term implies that a price is paid anytime when \(^{(q)}\) is not fully contained in \(}^{(q)}\). Indeed, if \(<1/2\) and we take \(\) we still have that \(>1\) as long as the signal is nonzero. Counter-intuitively, this indicates that an oracle model which has full access to the population-level covariance matrix of the covariates will perform worse in terms of estimation error than an estimator which has access to individual-level data. Furthermore, if \(>1/2\), our theorem predicts that the estimator will out-perform the oracle estimator that uses the population covariance matrix. These phenomena are validated in our simulation studies in Section 5.

### Guarantees for the nuclear norm estimator

Now we state our results for the low-rank proxy data estimator, when the penalty is taken to be the nuclear norm. Once again, these assumptions are standard for high-dimensional regression problems with the nuclear norm .

**Assumption 3.4** (Low rank).: _The matrix \(^{*}\) has rank \(r<<p Q\). Let \(^{*}\) and \(^{*}\) denote the column space and row space of \(^{*}\) respectively. Note that \(^{*}\) and \(^{*}\) each have dimension \(r\)._

**Definition 3.2** (Subspaces).: _Let \(\) denote a dimension \(k p Q\) subspace of \(^{p}\), and let \(\) denote a dimension \(k p Q\) subspace of \(^{Q}\). Define_

\[=(,):=\{^{p  Q}:()=,()=\}\]\[^{}=^{}(,)=\{ ^{p Q}:(),() \}\]

_Furthermore, for any subspace \(\) of \(^{p Q}\), let \(_{}\) denote the projection of \(\) onto \(\)._

_We will denote \(^{*}=(^{*},^{*})\)._

**Definition 3.3** (Low rank cone).: _For any set \(\) as defined above, let_

\[_{}()=\{^{p Q}:\| _{^{}}\|_{*}\|_{} \|_{*}\}\]

**Assumption 3.5** (Restricted strong convexity).: _There exists a constant \(>0\) and a sequence \(b_{N} 0\) as \(N\) such that the following inequality holds for each \(_{3}(^{*})\) with probability at least \(1-b_{N}\):_

\[_{q=1}^{Q}\|^{(q)/1/2} e_{q}\|_{2}^{2} \|\|_{F}^{2}\]

**Theorem 3.2**.: _Under assumptions 3.1, 3.4, and 3.5, there exist constants \(c_{1}\) and \(c_{2}\) depending only on \(^{2}\) and the eigenvalues of \(_{1}^{(q)}\) and \(_{2}^{(q)}\) such that if \(n_{}_{} c_{1}\|^{*}\|_{, }(Q+p)\) and \(=O(}+\|\|_{})\), the following inequality holds with probability at least \(1-e^{-p}-b_{N}\):_

\[\|}^{(lr)}-^{*}\|_{F} c_{2}( }}+\|\|_{})\]

This theorem recovers precisely the same behavior with respect to \(\) and \(\) as Theorem 3.1. As \( 1\), we achieve the minimax rate of estimation for low-rank regression as derived in  as long as \(=0\).

## 4 Tuning parameter selection with Lepski's method

A key challenge of applying penalized regression models to summary statistics is that model tuning based on data splitting (e.g., training and validation) is no longer an option. Model selection methods based on information criteria require knowing the log squared loss \(\|^{(q)}-^{(q)}\|_{2}^{2}\), which cannot be recovered from \(}^{(q)}\) and \(}^{(q)}\). To address this, we propose to use a tuning scheme based on Lepski's method , a classical tool of nonparametric statistics for adaptive estimation with unknown tuning parameters. The authors of  apply the ideas of Lepski to the LASSO, providing a fast algorithm for model tuning with non-asymptotic guarantees. In this section, we extend the methods in  to tune the multi-task estimators described in the present work.

The results and ideas in this section apply to both \(}^{(sp)}\) and \(}^{(lr)}\), so without loss of generality, let \((}_{},)\) denote a generic estimator-regularizer pair with tuning paramter \(\), which may refer to either \((}_{}^{(sp)},\|.\|_{2,1})\) or \((}_{}^{(lr)},\|.\|_{*})\). Additionally, let \(^{*}\) denote the dual of \(\), meaning that

\[^{*}(X)=_{Y:(Y) 1} X,Y\]

Finally, we let \(\) denote the loss function for both estimators and let \(\) denote its gradient.

The intuition behind the adaptive tuning procedure is that the tuning parameter should be chosen large enough to control fluctuations in the gradient of the loss function, but not too large such that too much bias is incurred.  articulates that the performance of regression estimator with a convex penalty is contingent on the following event occurring with high probability:

\[()=\{^{*}((^{*}) )\}\]where we use our problem's notation for continuity. The proofs of Theorem 3.1 and 3.2 involve showing that \(()\) holds with high probability under our stated conditions. It is straightforward to prove the following proposition, which states that conditional on \(\), the gradient of the loss function at our generic estimator \(}\) is close to the gradient at the true parameter \(^{*}\).

**Proposition 4.1**.: _Let \((}_{},)\) denote a generic estimator-regularizer pair. Conditional on the event \(()\), there exists a constant \(C>0\) such that the following inequality is satisfied almost surely:_

\[^{*}((}_{})- (^{*})) C\]

This proposition motivates the following definition, which we adopt from .

**Definition 4.1**.: _Let \(=\{_{1},_{2},...,_{M}\}\) denote a grid of potential tuning parameters ordered such that \(0<_{1}<_{2}<...<_{M}<\). Fix \((0,1)\). The oracle tuning parameter \(_{}^{*}\) is defined as_

\[_{}^{*}=*{arg\,min}_{}\{ \{()\} 1-\}\]

The oracle tuning parameter provides the tightest upper bound in Proposition 4.1, but is unknowable in practice, since we do not observe \(^{*}\) and hence cannot verify \(\). The aim of our Lepski-type method is to mimic the performance of \(_{}^{*}\) in an entirely data-driven fashion. Letting \(\) denote our ordered grid of potential tuning parameters, we follow  and choose the tuning parameter \(\) that satisfies

\[=*{arg\,min}_{}\{ _{^{},^{},^{}, ^{}}^{*}((}_{^{}})-(}_{ ^{}}))(^{}+^{})\}\] (5)

where \(\) is a constant chosen by the statistician. The following theorem states that \(\) recovers the behavior of \(_{}^{*}\) with high probability, as long as \(\) is sufficiently large.

**Theorem 4.1**.: _Let \(C\) denote the constant in Proposition 4.1. If \(\) is chosen as in Equation 5 with \( C\), then the following inequalities hold simultaneously with probability at least \(1-\):_

1. \(_{}^{*}\)__
2. \(^{*}((}_{})- (^{*})) C^{*}_{}^{*}\)__

_where \(C^{*}\)._

This theorem is a generalization of Theorem 3 in , adapted to our setting. The primary advantage of this Lepski-style tuning scheme is that it can be performed using only the gradient of the loss function, which in our setting consists only of summary-level statistics. This is a marked improvement over other summary statistic-based estimators, which typically require an additional set of individual-level data for tuning.

The adaptive tuning scheme does hold some disadvantages. First of all, it requires a choice of constant \(\), which should be taken to be as close to the constant in Proposition 4.1 as possible. Remark 10 in  offers some guidance as to how to choose \(\) but unfortunately their analysis corresponds only to the LASSO. Deriving the exact constant in Proposition 4.1 may be possible under stronger assumptions on the data-generating process (i.e. Gaussianity), and we view this as an area of future work. Furthermore, Theorem 4.1 offers only a bound on \((})-(^{*})\). Translating this to a bound on \(}-^{*}\) will require strong element-wise conditions on each of the matrices \(}^{(q)}\), which we do not explore in the present work. Nevertheless, our simulations in Section 5 indicate that the adaptive tuning method performs well in terms of the MSE of \(}\), suggesting that adaptive tuning is a good option for model selection when only summary statistics are available.

## 5 Numerical experiments and real data application

We validate our theory and demonstrate the effectiveness of multi-task learning in proxy data settings via extensive experiments. In each experiment, we take the proxy dataset to be well-specified;in other words, we assume that \(=0\). When \(\) is nonzero, this predictably leads to worse performance, which we demonstrate in the supplement. The code, further implementation details, and additional simulations which explore the use of our adaptive tuning procedure are also available in the supplement.

First, we consider the effect of varying proxy data size on empirical MSE per task. We generate synthetic Gaussian data with \(n_{}=100,p=100\), \(_{}= n_{}\) for \(\{0.5,1,2,5,10\}\), and \(_{q}=0\) for each \(q\). The number of tasks was fixed at 8. Furthermore, we generate a row-sparse \(^{*}\) matrix with 10 nonzero rows and a \(^{*}\) with rank 2 for the sparse and low-rank multi-task estimators, respectively. We then fit the proxy data multi-task learning estimator and compare the prediction MSE per task to the estimator that has access to all of the individual level data and to the estimator that uses the true covariance matrix \(\). The results of this simulation are given in Figure 1.

We observe a performance gap between the estimators that use the true covariance matrix and the individual level estimators, as predicted by our theory in Section 3. The performance of the proxy data estimators increase with increasing proxy sample size, but are unable to match the performance of the individual level estimator, as expected.

Next we study the effect of varying the proportion of overlapping samples between the discovery and proxy datasets. Similarly, we generate synthetic data with \(n==100\), and vary \(\), which indicates the proportion of proxy data points that are also in the discovery dataset. With \(Q=8\), we generate \(^{*}\) in the same way as in the previous simulation. These results are given in Figure 2.

Once again, we observe the expected performance gap between the estimators with the true covariance and the individual-level estimators. As the proportion of overlap between the proxy dataset and the discovery dataset grows, we see that the performance of the proxy data estimator converges to that of the individual level estimator. This is anticipated by Theorems 3.1 and 3.2.

Figure 1: Average prediction MSE per task after 100 repetitions plotted against \(=/n\). The left hand side corresponds to the sparse estimator, and the right hand side is the low-rank estimator. The red boxes indicate the estimator that uses all of the individual-level data (IL_Cov), the blue boxes indicate the estimator that uses the true covariance matrix of the features (true_Cov), and the green boxes correspond to the estimator that uses just the proxy data (Proxy_Cov).

Figure 2: Average MSE per task after 100 repetitions plotted against \(\). The orientation and colors are the same as in Figure 1.

Finally, we have applied our method to analyze real genetic data to demonstrate the real-world applicability of our method. We use a multi-site data obtained from the electronic Medical Records and Genomics (eMERGE) network , which includes individual-level genotype data from multiple research sites in the United States. Our goal is to predict levels of low-density lipoprotein (LDL) across five adult sites, treating the data from each site as a separate task. We split the data (with sample sizes \(n_{1}=3813,n_{2}=546,n_{3}=2666,n_{4}=1435,n_{5}=525\)) at each task into a training and test set (with a test set data size of 100 for each task) and evaluate the performance of our method using the prediction MSE on the test set. The training data from each site is used to construct the discovery summary statistics \(}^{(q)}\) for each task. For approximating \(^{(q)}\), we choose two different approaches: one is to use the half of the genotype data from each site (this approach is labeled as Proxy_MTL1); the other approach is to use \(_{1}\) (genotype data from site 1) to approximate \(^{(q)}\) for all the sites. This approach is labeled as Proxy_MTL2. We use these two approaches to demonstrate a potential trade-off in the construction of the reference panel: Proxy_MTL1 uses a well-specified reference dataset with a smaller sample size; Proxy_MTL2 uses a larger reference dataset that may suffer from a distribution shift. For comparison, we also fit a multi-task learning estimator that uses all of the individual level training data for each task, which is labeled 'Individual_MTL', and we fit a ridge regression estimator that models each task separately, for comparison to our multi-task learning approach. The ridge estimator uses the proxy sample covariance instead of the individual level covariance matrix for a fair comparison with our method. We repeat the train-test split process 10 times, which admits the distribution of prediction MSE values that we report in the figure. We use the nuclear norm penalized multi-task learning estimators in this application, because we believe that the genetic effects in this dataset are dense.

Our results in Figure demonstrate that our method is highly practical when only summary-level information is available, as the prediction MSE of our method is nearly the same as the estimator which uses the individual-level data, despite a slight cost in performance. Furthermore, all multi-task learning estimators outperform the ridge-estimator, confirming that multi-task learning is a strong approach when there is shared structure between tasks.

## 6 Discussion, Limitations, and Broader Impacts

We have described a flexible multi-task framework incorporating summary statistics from distinct sources with a general data-driven tuning scheme for selecting tuning parameters. Our theoretical analysis sheds light on the intrinsic price of using summary-level information from distinct sources for statistical analysis, and suggests that more overlap between the sources, less distributional shift, and larger proxy data sample sizes can alleviate this cost. Our data-driven tuning scheme allows

Figure 3: Prediction MSE per task after 10 splits of the eMERGE data.

models to be trained without sample splitting, making it more applicable to real-world settings with only summary statistics available.

The limitations of our work are summarized as follows. First of all, our methods depend on a linear relationship between the covariates and the outcomes. This assumption is often satisfied in our target application of genetic risk prediction , but it does limit the applicability of our method to other domains. To extend our framework to non-linear models, we may use the second-order Taylor approximation of the loss function as in . However, the summary statistics used by such an algorithm are not found in existing literature or publicly available databases. Additionally, our theoretical results provide only upper bounds on the estimation error of the two estimators that we consider in this work. To fully characterize the cost of using summary statistics for multi-task learning, lower bounds resembling Theorem 2.2 of  are needed. We conjecture that our estimators converge at a minimax optimal rate, and we view the proof of this conjecture as an important future direction. Finally, we may also extend the framework of  to our summary statistic based setting to adjust for potential differences between tasks.

Nevertheless, our results have important implications beyond high-dimensional statistical theory. The trade-off between proxy data sample size and discovery-proxy overlap may inform how polygenic risk models are built in real-world applications: Practitioners should prioritise alignment between the sources of summary statistics that they use to build these models, rather than optimizing for large sample sizes. This guidance may lead to more accurate polygenic scores, which have emerged as an important predictive tool in the field of precision medicine.

We recognize that the development of polygenic risk scores, if done without care, may worsen existing health disparities . This is a potential negative societal impact of our work. We hope that our multi-task learning framework may be used to incorporate data from diverse populations to improve generalizability and transportability of genetic risk predictions to overcome these negative impacts.