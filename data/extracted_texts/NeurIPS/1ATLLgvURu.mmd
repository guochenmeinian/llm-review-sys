# Learning-Augmented Priority Queues

Ziyad Benomar

ENSAE, Ecole Polytechnique,

FairPlay joint team

ziyad.benomar@ensae.fr &Christian Coester

Department of Computer Science

University of Oxford, UK

christian.coester@cs.ox.ac.uk

###### Abstract

Priority queues are one of the most fundamental and widely used data structures in computer science. Their primary objective is to efficiently support the insertion of new elements with assigned priorities and the extraction of the highest priority element. In this study, we investigate the design of priority queues within the learning-augmented framework, where algorithms use potentially inaccurate predictions to enhance their worst-case performance. We examine three prediction models spanning different use cases, and we show how the predictions can be leveraged to enhance the performance of priority queue operations. Moreover, we demonstrate the optimality of our solution and discuss some possible applications.

## 1 Introduction

Priority queues are an essential abstract data type in computer science  whose objective is to enable the swift insertion of new elements and access or deletion of the highest priority element. Their applications span a wide range of problems within computer science and beyond. They play a crucial role in sorting , in various graph algorithms such as Dijkstra's shortest path algorithm  or computing minimum spanning trees , in operating systems for scheduling and load balancing , in networking protocols for managing data transmission packets , in discrete simulations for efficient event processing based on occurrence time , and in implementing hierarchical clustering algorithms .

Various data structures can be used to implement priority queues, each offering distinct advantages and tradeoffs . However, it is established that a priority queue with \(n\) elements cannot guarantee \(o( n)\) time for all the required operations . This limitation can be surpassed within the learning augmented framework , where the algorithms can benefit from machine-learned or expert advice to improve their worst-case performance. We propose in this work learning-augmented implementations of priority queues in three different prediction models, detailed in the next section.

### Problem definition

A priority queue is a dynamic data structure where each element \(x\) is assigned a key \(u\) from a totally ordered universe \((,<)\), determining its priority. The standard operations of priority queues are:

1. \(()\): returns the element with the smallest key without removing it,
2. \(()\): removes and returns the element with the smallest key,
3. \((x,u)\): adds a new element \(x\) to the priority queue with key \(u\),
4. \((x,v)\): decreases the key of an element \(x\) to \(v\).

The elements of the priority queue can be accessed via their keys in \(O(1)\) time using a HashMap. Hence, the focus is on establishing efficient algorithms for key storage and organization, facilitating the execution of priority queue operations. For any key \(u\) and subset \(\), we denote by \(r(u,)\) the rank of \(u\) in \(\), defined as the number of keys in \(\) that are smaller than or equal to \(u\),

\[r(u,)=\#\{v:v u\}\;.\] (1)

The difficulty lies in designing data structures offering adequate tradeoffs between the complexities of the operations listed above. This paper explores how using predictions can allow us to overcome the limitations of traditional priority queues. We examine three types of predictions.

Dirty comparisons.In the first prediction model, comparing two keys \((u,v)^{2}\) is slow or costly. However, the algorithm can query a prediction of the comparison \((u<v)\). This prediction serves as a rapid or inexpensive, but possibly inaccurate, method of comparing elements of \(\), termed a _dirty_ comparison and denoted by \((u v)\). Conversely, the true outcome of \((u<v)\) is referred to as a _clean_ comparison. For all \(u\) and \(\), we denote by \((u,)\) the number of inaccurate dirty comparisons between \(u\) and elements of \(\),

\[(u,)=\#\{v\;:\;(u v) (u<v)\}\;.\] (2)

This prediction model was introduced in  for sorting, but it has a broader significance in comparison-based problems, such as search , ranking , and the design of comparison-based ML algorithms . Particularly, it has great theoretical importance for priority queues, which have been extensively studied in the comparison-based framework . Comparison-based models are often used, for example, when the preferences are determined by human subjects. Assigning numerical scores in these cases is inexact and prone to errors, while pairwise comparisons are absolute and more robust . Within such a setting, dirty comparisons can be obtained by a binary classifier, and used to minimize human inference yielding clean comparisons, which are time-consuming and might incur additional costs.

Pointer predictions.In this second model, upon the addition of a new key \(u\) to the priority queue \(\), the algorithm receives a prediction \(}(u,)\) of the predecessor of \(u\), which is the largest key belonging to \(\) and smaller than \(u\). Before \(u\) is inserted, the ranks of \(u\) and its true predecessor in \(\) are equal, hence we define the prediction error as

\[(u,)=|r(u,)-r(} (u,),)|\;.\] (3)

In priority queue implementations, a HashMap preserves a pointer from each inserted key to its corresponding position in the priority queue. Consequently, \(}(u,)\) provides direct access to the predicted predecessor's position. For example, this prediction model finds applications in scenarios where concurrent machines have access to the priority queue . Each machine can estimate, within the elements it has previously inserted, which one precedes the next element it intends to insert. However, this estimation might not be accurate, as other concurrent machines may have inserted additional elements.

Rank predictions.The last setting assumes that the priority queue is used in a process where a finite number \(N\) of distinct keys will be inserted, i.e., the priority queue is not used indefinitely, but \(N\) is unknown to the algorithm. Upon the insertion of any new key \(u_{i}\), the algorithm receives a prediction \((u_{i})\) of the rank of \(u_{i}\) among all the \(N\) keys \(\{u_{j}\}_{j[N]}\). Denoting by \(R(u_{i})=r(u_{i},\{u_{j}\}_{j[N]})\) the true rank, the prediction error of \(u_{i}\) is

\[^{}(u_{i})=|R(u_{i})-(u_{i})|\;.\] (4)

The same prediction model was explored in  for the online list labeling problem. Bai and Coester  investigate a similar model for the sorting problem, but in an offline setting where the \(N\) elements to sort and the predictions are accessible to the algorithm from the start.

Note that \(N\) counts the distinct keys added with \(\) or \(\) operations. An arbitrarily large number of \(\) operations thus can make \(N\) arbitrarily large although the total number of insertions is reduced. However, with a lazy implementation of \(\), we can assume without loss of generality that \(N\) is at most quadratic in the total number of insertions. Indeed, it is possible to omit executing the \(\) operations when queried, and only store the new elements' keys to update. Then, at the first \(\) operation, all the element's keys are updated by executing for each one only the last queried \(\) operation involving it. Denoting by \(k\) the total number of insertions, there are at most \(k\)\(\) operations, and for each of them, there are at most \(k\)\(\) operations executed. The total number of effectively executed \(\) operations is therefore \(O(k^{2})\). In particular, this implies that a complexity of \(O( N)\) is also logarithmic in the total number of insertions.

### Our results

We first investigate augmenting binary heaps with predictions. To leverage dirty comparisons, we first design a _randomized binary search_ algorithm to find the position of an element \(u\) in a sorted list \(L\). We prove that it terminates using \(O(|L|)\) dirty comparisons and \(O((u,L))\) clean comparisons in expectation. Subsequently, we use this result to establish an insertion algorithm in binary heaps using \(O( n)\) dirty comparisons and reducing the number of clean comparisons to \(O((u,))\). However, \(\) still mandates \(O( n)\) clean comparisons. In the two other prediction models, binary heaps and other heap implementations of priority queues appear unsuitable, as the positions of the keys are not determined solely by their ranks.

Consequently, in Section 3, we shift to using skip lists. We devise randomized insertion algorithms requiring, in expectation, only \(O((u,))\) time and comparisons in the pointer prediction model, \(O( n)\) time and \(O((u,))\) clean comparisons in the dirty comparison model, and \(O( N+_{i[N]}^{}(u_{i}))\) time and \(O(_{i[N]}^{}(u_{i}))\) comparisons in the rank prediction model, where we use in the latter an auxiliary van Emde Boas (vEB) tree [van Emde Boas et al., 1976]. Across the three prediction models, \(\) and \(\) only necessitate \(O(1)\) time, and the complexity of \(\) aligns with that of insertion. Finally, we prove in Theorem 3.4 the optimality of our data structure. Table 1 summarizes the complexities of our learning-augmented priority queue (LAPQ) in the three prediction models compared to standard priority queue implementations. The complexity of \(\) is \(O(1)\) for all the listed priority queues.

Our learning-augmented data structure enables additional operations beyond those of priority queues, such as the _maximum priority queue_ operations \(\), \(\), and \(\) with analogous complexities, and removing an arbitrary key \(u\) from the priority queue, finding its predecessor or successor in expected \(O(1)\) time.

Furthermore, we show in Section 4.1 that it can be used for sorting, yielding the same guarantees as the learning-augmented sorting algorithms presented in [Bai and Coester, 2023] for the positional predictions model with _displacement error_, and for the dirty comparison model. In the second model, our priority queue offers even stronger guarantees, as it maintains the elements sorted at any time even if the insertion order is adversarial, while the algorithm of [Bai and Coester, 2023] requires a random insertion order to achieve a sorted list by the end within the complexity guarantees. We also show how the learning-augmented priority queue can be used to accelerate Dijkstra's algorithm.

Finally, in Section 5, we compare the performance of our priority queue using predictions with binary and Fibonacci heaps when used for sorting and for Dijkstra's algorithm on both real-world city maps and synthetic graphs. The experimental results confirm our theoretical findings, showing that adequately using predictions significantly reduces the complexity of priority queue operations.

 
**Priority queues** & \(\) & \(\) & \(\) \\  Binary Heap & \(O( n)\) & \(O( n)\) & \(O( n)\) \\  Fibonacci Heap (amortized) & \(O( n)\) & \(O(1)\) \\  Skip List (average) & \(O(1)\) & \(O( n)\) \\  LAPQ with dirty comparisons (average) & \(O(1)\) & \(O((u,))\) \\  LAPQ with pointer predictions (average) & \(O(1)\) & \(O((u,))\) \\  LAPQ with rank predictions (average) & \(O(1)\) & \(O(_{i[n]}^{}(u_{i}))\) \\  

Table 1: Number of comparisons per operation used by different priority queues.

### Related work

In this section, we briefly discuss related works on learning-augmented algorithms and priority queues. For a more extensive review of related work, please refer to Appendix A.

Learning-augmented algorithms.Learning-augmented algorithms, introduced in (Lykouris and Vassilvitskii, 2018; Purohit et al., 2018), have captured increasing interest over the last years, as they allow breaking longstanding limitations in many algorithm design problems. Assuming that the decision-maker is provided with potentially incorrect predictions regarding unknown parameters of the problem, learning-augmented algorithms must be capable of leveraging these predictions if they are accurate (consistency), while keeping the worst-case performance without advice even if the predictions are arbitrarily bad or adversarial (robustness). While many fundamental online problems were studied in this setting (see Appendix A), the design of data structures with predictions remains relatively underexplored. The seminal paper by (Kraska et al., 2018) shows how predictions can be used to optimize space usage. Another study by (Lin et al., 2022) demonstrates that the runtime of binary search trees can be optimized by incorporating predictions of item access frequency. Recent papers have extended this prediction model to other data structures, such as dictionaries (Zeynali et al., 2024) and skip lists (Fu et al., 2024). The prediction models we study in the current paper deviate from the latter, and are more related to those considered respectively in (Bai and Coester, 2023) for sorting, and (McCauley et al., 2024) for online list labeling. An overview of the growing body of work on learning-augmented algorithms (also known as algorithms with predictions) is maintained at (Lindermayr and Megow, 2022).

Priority queues implementations.Binary heaps, introduced by Williams (1964), are one of the first efficient implementations of priority queues. They allow all the operations in \(O( n)\) time, where \(n\) is the number of items in the queue. A first improvement was introduced with Binomial heaps (Vuillemin, 1978), reducing the amortized time of insertion to \(O(1)\). A breakthrough came later with Fibonacci heaps (Fredman and Tarjan, 1987), which allow all the operations in constant amortized time, except for \(\), which takes \(O( n)\) time. However, Fibonacci heaps are known to be slow in practice (Larkin et al., 2014), and other implementations with weaker theoretical guarantees such as binary heaps are often preferred. Another possible implementation uses _skip lists_(Pugh, 1990), which are probabilistic data structures, guaranteeing in expectation a constant time for \(\) and \(\), and \(O( n)\) time for \(\) and \(\).

## 2 Heap priority queues

A common implementation of priority queues uses binary heaps, enabling all operations in \(O( n)\) time. Binary heaps maintain a balanced binary tree structure, where all depth levels are fully filled, except possibly for the last one, to which we refer in all this section as the _leaf level_. Moreover, it satisfies the _heap property_, i.e., any key is smaller than all its children. To maintain these two structure properties, when a new element is added, it is first inserted in the leftmost empty position in the leaf level, and then repeatedly swapped with its parent until the heap property is restored.

### Insertion in the comparison-based model

Insertion in a binary heap can be accomplished using only \(O( n)\) comparisons, albeit \(O( n)\) time, by doing a binary search of the new element's position along the path from the leftmost empty position in the leaf level to the root, which is a sorted list of size \(O( n)\). To improve the insertion complexity with dirty comparisons, we first tackle the search problem in this setting.

Search with dirty comparisons.Consider a sorted list \(L=(v_{1},,v_{k})\) and a target \(u\), the position of \(u\) in \(L\) can be found using binary search with \(O( k)\) comparisons. Extending ideas from Bai and Coester (2023) and Lykouris and Vassilvitskii (2018), this complexity can be reduced using dirty comparisons. Indeed, we can obtain an estimated position \((u,L)\) through a binary search with dirty comparisons, followed by an exponential search with clean comparisons, starting from \((u,L)\) to find the exact position \(r(u,L)\). However, the positions of inaccurate dirty comparisons can be adversarially chosen to compromise the algorithm. This can be addressed by introducing randomness to the dirty search phase. We refer to the _randomized binary search_ as the algorithm that proceedssimilarly to the binary search, but whenever the search is reduced to an array \(\{v_{i},,v_{j}\}\), instead of comparing \(u\) to the pivot \(v_{m}\) with index \(m=i+\), it compares \(u\) to a pivot with an index chosen uniformly at random in the range \(\{i+,,j-\}\).

**Theorem 2.1**.: _A dirty randomized binary search followed by a clean exponential search finds the target's position using \(O( k)\) dirty comparisons and \(O((u,L))\) clean comparisons in expectation._

Randomized insertion in a binary heap.In a binary heap \(\), any new element \(u\) is always inserted along the path of size \(O( n)\) from the root to the leftmost empty position in the leaf level. If all the inaccurate dirty comparisons are chosen along this path, then the insertion would require \(O((u,))\) clean comparisons by Theorem 2.1. This complexity can be reduced further by randomizing the choice of the root-leaf path where \(u\) is inserted, as explained in Algorithm 1.

``` Input: Binary heap \(\) with randomly filled positions in the leaf level, new key \(u\)
1\(L\) keys path from a uniformly random empty position in the leaf level to the root;
2\((u,L)\) outcome of a dirty randomized binary search of \(u\) in \(L\);
3\(r(u,L)\) outcome of the clean exponential search of \(u\) in \(L\) starting from index \((u,L)\);
4Insert \(u\) in the chosen leaf empty position, then swap it with its parents until position \(r(u,L)\); ```

**Algorithm 1**Randomized insertion in binary heap

**Theorem 2.2**.: _The insertion algorithm 1 requires \(O( n)\) time, \(O( n)\) dirty comparisons and \(O((u,))\) clean comparisons in expectation._

### Limitations

The previous theorem demonstrates that accurate predictions can reduce the number of clean comparisons for insertion in a binary heap. However, for the \(\) operation, when the minimum key, which is the root of the tree, is deleted, its two children are compared and the smallest is placed in the root position, and this process repeats recursively, with each new empty position filled by comparing both of its children, requiring necessarily \(O( n)\) clean comparisons in total to ensure the heap priority remains intact. Improving the efficiency of \(\) using dirty comparisons would therefore require bringing major modifications to the binary heap's structure.

Similar difficulties arise when attempting to enhance \(\) using dirty comparisons or the other prediction models in different heap implementations, such as Binomial or Fibonacci heaps. Consequently, we explore in the next section another priority queue implementation, using skip lists, which allows for an easier and more efficient exploitation of the predictions.

## 3 Skip lists

A priority queue can be implemented naively by maintaining a dynamic sorted linked list of keys. This guarantees constant time for \(\), but \(O(n)\) time for insertion. Skip lists (see Figure 1) offer a solution to this inefficiency, by maintaining multiple levels of linked lists, with higher levels containing fewer elements and acting as shortcuts to lower levels, facilitating faster search and insertion in expected \(O( n)\) time. In all subsequent discussions concerning linked lists or skip lists, it is assumed that they are doubly linked, having both predecessor and successor pointers between elements.

The first level in a skip list is an ordinary linked list containing all the elements, which we denote by \(v_{1},,v_{n}\). Every higher level is constructed by including each element from the previous level independently with probability \(p\), typically set to \(1/2\). For any key \(v_{i}\) in the skip list, we define its height \(h(v_{i})\) as the number of levels where it appears, which is an independent geometric random variable with parameter \(p\). A number \(2h(v_{i})\) of pointers are associated with \(v_{i}\), giving access to the previous and next element in each level \([h(v_{i})]\), denoted respectively by \((v_{i},)\) and \((v_{i},)\). Using a HashMap, these pointers can be accessed in \(O(1)\) time via the key value \(v_{i}\). For convenience, we consider that the skip list contains two additional keys \(v_{0}=-\) and \(v_{n+1}=\), corresponding respectively to the head and the \(\) value. Both have a height equal to the maximum height in the queue \(h(v_{0})=h(v_{n+1})=_{i[n]}h(v_{i})\).

Since the expected height of keys in the skip list is \(1/p\), deleting any key only requires a constant time in expectation, by updating its associated pointers, along with those of its predecessors and successors in the levels where it appears. In particular, \(\) and \(\) take \(O(1)\) time, and \(\) can be performed by deleting the element and reinserting it with the new key, yielding the same complexity as insertion. Furthermore, by the same arguments, inserting a new key \(u\) next to a given key \(v_{i}\) in the skip list can be done in expected constant time.

Therefore, implementing efficient Insert and \(\) operations for skip lists with predictions is reduced to designing efficient search algorithms to find the predecessor of a target key \(u\) in the skip list, i.e., the largest key \(v_{i}\) in the skip list that is smaller than \(u\). In all the following, we denote by \(\) a skip list containing \(n\) keys \(v_{1} v_{n}\), and \(u\) the target key. As explained in Appendix C.1, we can assume without loss of generality that the keys \((u,v_{1},,v_{n})\) are pairwise distinct. In the following, we present separately for each model an insertion algorithm leveraging the predictions.

### Pointer prediction

Given a pointer prediction \(v_{j}=}(u,)\), we describe below an algorithm for finding the true predecessor of \(u\) starting from the position of the key \(v_{j}\), then inserting \(u\). We assume in the algorithm that \(v_{j} u\). If \(v_{j}>u\), then the algorithm can be easily adapted by reversing the search direction.

``` Input: Skip list \(\), source \(v_{j}\), and new key \(u\)
1\(w v_{j}\); \(\) Bottom-Up search
2while\((w,h(w)) u\)do
3\(w(w,h(w))\); \( h(w)\); \(\) Top-Down search
4while\(>0\)do
5while\((w,) u\)do
6\(w(w,)\);
7\(-1\);
8Insert \(u\) next to \(w\); ```

**Algorithm 2**\((,v_{j},u)\)

Algorithm 2 is inspired by the classical exponential search in arrays. The first phase consists of a bottom-up search, expanding the size of the search interval by moving to upper levels until finding a key \(w\) satisfying \(w u<(w,h(w))\). The second phase conducts a top-down search from level \(h(w)\) downward, refining the search until locating the position of \(u\). It is worth noting that the classical search algorithm in skip lists, denoted by \((,u)\), corresponds precisely to the top-down search, starting from the head of the skip list instead of \(w\).

**Theorem 3.1**.: _Augmented with pointer predictions, a skip list allows \(\) and \(\) in expected \(O(1)\) time, and \((u)\) in expected \(O((u,))\) time using Algorithm 2._

### Dirty comparisons

We devise in this section a search algorithm using dirty and clean comparisons. Algorithm 3 first estimates the position of \(u\) with a dirty top-down search starting from the head, then performs a clean exponential search starting from the estimated position to find the true position.

``` Input: Skip list \(\), new key \(u\)
1\((,u)\) with dirty comparisons; \((,,u)\) with clean comparisons; ```

**Algorithm 3**Insertion with dirty and clean comparisons

The dirty search concludes within \(O( n)\) steps, and Theorem 3.1 guarantees that the exponential search terminates within \(O(|r(,)-r(u,)|)\) steps. Combining these results and relating the distance between \(u\) and \(\) in \(\) to the prediction error \((u,)\), we derive the following theorem.

**Theorem 3.2**.: _Augmented with dirty comparisons, a skip list allows \(\) and \(\) in \(O(1)\) expected time, and \((u)\) with Algorithm 3 in \(O( n)\) expected time, using \(O( n)\) dirty comparisons and \(O((u,))\) clean comparisons in expectation._

### Rank predictions

In the rank prediction model, each \((u)\) request is accompanied by a prediction \((u)\) of the rank of \(u\) among all the distinct keys already in, or to be inserted into the priority queue. If the predictions are accurate and the total number \(N\) of distinct keys to be inserted is known, the problem reduces to designing a priority queue with integer keys in \([N]\), taking as keys the ranks \((R_{i})_{i[N]}\). This problem can be addressed using a van Emde Boas (vEB) tree over \([N]\)(van Emde Boas et al., 1976), which requires \(O( N)\) time for insertion, deletion, finding the minimum or maximum, and finding the predecessor or successor of any element, guaranteeing in particular \(O( N)\) time for all priority queue operations. More details on its structure can be found in Appendix C.5.

To leverage rank predictions, we use an auxiliary vEB tree \(\) along with the skip list \(\). All the insertion and deletion operations are made simultaneously on \(\) and \(\). However, the priorities used in \(\) are the predicted ranks \(\{(u_{i})\}_{i[N]}\). Whenever a new key \(u_{i}\) is to be added, Algorithm 4 inserts it first in \(\) at position \((u_{i})\), gets its predecessor \(\) in \(\), i.e., the element in \(\) with the largest predicted rank smaller than or equal to \((u_{i})\), then uses \(\) as a pointer prediction to find the position of \(u_{i}\) in \(\). If the predecessor is not unique, the algorithm chooses an arbitrary one.

``` Input: Skip list \(\), vEB tree \(\) on \([N]\), new element \(u_{i}\), prediction \((u_{i})[N]\)
1 Insert \(u_{i}\) in \(\) with key \((u_{i})\); \(\) of \(u_{i}\) in \(\); \((,,u_{i})\); ```

**Algorithm 4**Insertion with rank prediction

We explain in Appendix C.5 how the data structure can be adapted when \(N\) is unknown and the rank predictions are not necessarily in \([N]\), and we prove the following theorem, giving both the runtime and comparison complexities of the priority queue operations using this data structure.

**Theorem 3.3**.: _If \((u_{i})=O(N)\) for all \(i[N]\), then there is a data structure allowing \(\) and \(\) in \(O(1)\) amortized time, and \(\) in \(O( N+_{i[N]}^{}(u_{i}))\) amortized time using \(O(_{i[N]}^{}(u_{i}))\) comparisons in expectation._

In contrast to other prediction models, the complexity of inserting \(u_{i}\) is not impacted only by \(^{}(u_{i})\), but by the maximum error over all keys \(\{u_{j}\}_{j[N]}\). This occurs because the exponential search conducted in Algorithm 4 starts from the key \(\), whose error also affects insertion performance. A similar behavior is observed in the online list labeling problem (McCauley et al., 2024), where the bounds provided by the authors also depend on the maximum prediction error for insertion.

With perfect predictions, the number of comparisons for insertion becomes constant, and its runtime \(O( N)\). It is not clear if the runtime of all the priority queue operations can be reduced to \(O(1)\) with perfect predictions. Indeed, the problem in that case is reduced to a priority queue with all the keys in \([N]\). The best-known solution to this problem is a randomized priority queue, by Thorup (2007), supporting all operations in \(O()\) time. However, in our approach, we use vEB trees beyond the classical priority queue operations, as we also require fast access to the predecessor of any element. A data structure supporting all these operations solves the dynamic predecessor problem, for which vEB trees are optimal (Patrascu and Thorup, 2006). Reducing the runtime of insertion below \(O( N)\) would therefore require omitting the use of predecessor queries.

### Lower bounds

As explained earlier, \(\) requires only \(O(1)\) expected time in skip lists. Furthermore, we presented insertion algorithms for the three prediction models and provided upper bounds on their complexities. The following theorem establishes lower bounds on the complexities of \(\) and \(\) for any priority queue augmented with any of the three prediction types.

**Theorem 3.4**.: _For each of the three prediction models, the following lower bounds hold._

1. _[label=()]_
2. _Dirty comparisons: no data structure_ \(\) _can support_ \(\) _with_ \(O(1)\) _clean comparisons and_ \((u)\) _with_ \(o((u,))\) _clean comparisons in expectation._
3. _Pointer predictions: no data structure_ \(\) _can support_ \(\) _with_ \(O(1)\) _comparisons and_ \((u)\) _with_ \(o((u,))\) _comparisons in expectation._
4. _Rank predictions: no data structure_ \(\) _can support_ \(\) _with_ \(O(1)\) _comparisons and_ \((u_{i})\) _with_ \(o(_{i[N]}^{}(u_{i}))\) _comparisons in expectation, for all_ \(i[N]\)_._

These lower bounds with Theorems 3.2 and 3.1 prove the tightness of our priority queue in the dirty comparison and the pointer prediction models. In the rank prediction model, the comparison complexities proved in Theorem 3.3 are optimal, whereas the runtimes are only optimal up to an additional \(O( N)\) term. In particular, they are optimal if the maximal error is at least \(( N)\).

## 4 Applications

### Sorting algorithm

Our learning-augmented priority queue can be used for sorting a sequence \(A=(a_{1},,a_{n})\), by first inserting all the elements, then repeatedly extracting the minimum until the priority queue is empty. We compare below the performance of this sorting algorithm to those of (Bai and Coester, 2023).

Dirty comparison model.Denoting by \(_{i}=(a_{i},A)\), Bai and Coester (2023) prove a sorting algorithm using \(O(n n)\) time, \(O(n n)\) dirty comparisons, and \(O(_{i}(_{i}+2))\) clean comparisons. Theorem 3.2 yields the same guarantees with our learning-augmented priority queue. Moreover, our learning-augmented priority queue is a skip list, maintaining elements in sorted order at any time, even if the elements are revealed online and the insertion order is adversarial, while in (Bai and Coester, 2023), it is crucial that the insertion order is chosen uniformly at random.

Positional predictions.In their second prediction model, they assume that the algorithm is given offline access to predictions \(\{(a_{i})\}_{i[n]}\) of the relative ranks \(\{R(a_{i})\}_{i[n]}\) of the \(n\) elements to sort, and they study two different error measures. The rank prediction error \(_{i}^{}=|R(a_{i})-(a_{i})|\) matches their definition of _displacement error_, for which they prove a sorting algorithm in \(O(_{i}(_{i}^{}+2))\) time. The same bound can be deduced using our results in the pointer prediction model. Further discussion on this claim can be found in Appendix E.

Online rank predictions.If \(n\) is unknown to the algorithm, and the elements \(a_{1},,a_{n}\) along with their predicted ranks are revealed online, possibly in an adversarial order, then by Theorem 3.3, the total runtime of our priority queue for maintaining all the inserted elements sorted at any time is \(O(n n+n_{i}_{i}^{})\), and the number of comparisons used is \(O(n_{i}_{i}^{})\). No analogous result is demonstrated in (Bai and Coester, 2023) in this setting.

### Dijkstra's shortest path algorithm

Consider a run of Dijkstra's algorithm on a directed positively weighted graph \(G\) with \(n\) nodes and \(m\) edges. The elements inserted into the priority queue are the nodes of the graph, and the corresponding keys are their tentative distances to the source, which are updated over time. During the algorithm's execution, at most \(m+1\) distinct keys \(\{d_{i}\}_{i[m+1]}\) are inserted into the priority queue. Given online predictions \(((d_{i}))_{i[m+1]}\) of their relative ranks \((R(d_{i}))_{i[m+1]}\), the total runtime using our priority queue augmented with rank predictions is

\[Om n+m_{i[m+1]}|R(d_{i})-(d_{i})|\.\]

In contrast, the shortest path algorithm of Lattanzi et al. (2023) (which also works for negative edges) has a linear dependence on a similar error measure. Even with arbitrary error, our guarantee is never worse than the \(O(m n)\) runtime with binary heaps. Using Fibonacci heaps results in an \(O(n n+m)\) runtime, which is surpassed by our learning-augmented priority queue in the case of sparse graphs where \(m=o()\) if predictions are of high quality. However, it is known that Fibonacci heaps perform poorly in practice, even compared to binary heaps, as supported by our experiments.

## 5 Experiments

In this section, we empirically evaluate the performance of our learning-augmented priority queue (LAPQ) by comparing it with Binary and Fibonacci heaps. We use two standard benchmarks for this evaluation: sorting and Dijkstra's algorithm. For the sorting benchmark, we also compare our results with those from Bai and Coester (2023). For Dijkstra's algorithm, we assess performance on both real city maps and synthetic random graphs. In all the experiments, each data point represents the average result from 30 independent runs. Additional experiments and a detailed discussion on the prediction models and the obtained results can be found in Appendix F. The code used for conducting the experiments is available at github.com/Ziyad-Benomar/Learning-augmented-priority-queues.

Sorting.We compare sorting using our LAPQ with the algorithms of Bai and Coester (2023) under their same experimental settings. Given a sequence \(A=(a_{1},,a_{n})\), we evaluate the complexity of sorting it with predictions in the _class_ and the _decay_ setting. In the first, \(A\) is divided into \(c\) classes \(((t_{k-1},t_{k}])_{k[c]}\), where \(0=t_{0} t_{1} t_{c}=n\) are uniformly random thresholds. The predicted rank of any item \(a_{i}\) with \(t_{k} i<t_{k+1}\) is sampled uniformly at random within \((t_{k},t_{k+1}]\). In the decay setting, the ranking is initially accurate but degrades over time. Each time step, one item's predicted position is perturbed by 1, either left or right, uniformly at random.

In both settings, we test the LAPQ with the three prediction models. First, assuming that the rank predictions are given offline, we use pointer predictions as explained in Appendix E. In the second case, the elements to insert along with their predicted ranks are revealed online in a uniformly random order. Finally, we test the dirty comparison setting with the dirty order \((a_{i}\ \ a_{j})=((a_{i})<(a_{j}))\).

Figures 2 and 3 show the obtained results respectively in the class and the decay setting for \(n\{10^{4},10^{5}\}\). In the class setting with offline predictions, the LAPQ slightly outperforms the _Double-Hoover_ and _Displacement_ sort algorithms of Bai and Coester (2023), which were shown to outperform classical sorting algorithms. In the decay setting, the LAPQ matches the performanceof the Displacement sort, but is slightly outperformed by the Double-Hoover sort. With online predictions, although the problem is harder, LAPQ's performance remains comparable to the previous algorithms. In both settings, the LAPQ with offline predictions, online predictions, and dirty comparisons all yield better performance than binary or Fibonacci heaps, even with predictions that are not highly accurate.

Dijkstra's algorithm.Consider a graph \(G=(V,E)\) with \(n\) nodes and \(m\) edges, and a source node \(s V\). In the first predictions setting, we pick a random node \(\) and run Dijkstra's algorithm with \(\) as the source, memorizing all the keys \(=(_{1},,_{m})\) inserted into the priority queue. In subsequent runs of the algorithm with different sources, when a key \(d_{i}\) is to be inserted, we augment the insertion with the rank prediction \((d_{i})=r(d_{i},)\). We call these _key rank predictions_. This model aims at exploiting the topology and uniformity of city maps. As computing shortest paths from any source necessitates traversing all graph edges, keys inserted into the priority queue--partial sums of edge lengths--are likely to exhibit some degree of similarity even if the algorithm is executed from different sources. Notably, this prediction model offers an explicit method for computing predictions, readily applicable in real-world scenarios.

In the second setting, we consider rank predictions of the nodes in \(G\), ordered by their distances to \(s\). As Dijkstra's algorithm explores a new node \(x V\), it receives a prediction \((x)\) of its rank. The node \(x\) is then inserted with a key \(d_{i}\), to which we assign the prediction \((d_{i})=(x)\). Unlike the previous experimental settings, we initially have predictions of the nodes' ranks, which we extend to predictions of the keys' ranks. Similarly to the sorting experiments, we consider _class_ and _decay_ perturbations of the node ranks.

In the context of searching the shortest path, rank predictions in the class setting can be derived from subdividing the city into multiple smaller areas. Each class corresponds to a specific area, facilitating the ordering of areas from closest to furthest relative to the source. However, comparing the distances from the source to the nodes in the same class might be inaccurate. On the other hand, the decay setting simulates modifications to shortest paths, such as rural works or new route constructions, by adding or removing edges from the graph. These alterations may affect the ranks of a limited number of nodes, which corresponds to the time steps in the decay setting.

We present below the experiment results obtained with the maps of Paris and London. More experiments with additional city maps and synthetic graphs are in Appendix F. The city maps were obtained using the Python library Osmnx (Boeing, 2017). Figures 5 and 5 respectively illustrate the results in the _class_ and the _decay_ settings with _node rank predictions_. In both figures, for each city, we present the numbers of comparisons used for the same task by a binary and Fibonacci heap, and the number of comparisons used when the priority queue is augmented with _key rank predictions_.

In both settings, the performance of the LAPQ substantially improves with the quality of the predictions, and notably, _key rank predictions_ yield almost the same performance as perfect _node rank predictions_, affirming our intuition on the similarity between the keys inserted in runs of Dijkstra's algorithm starting from different sources.