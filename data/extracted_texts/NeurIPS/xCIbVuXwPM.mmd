# Trading off Consistency and Dimensionality of Convex Surrogates for Multiclass Classification

Enrique Nueve

Department of Computer Science

University of Colorado Boulder

enrique.nueveiv@colorado.edu

&Bo Waggoner

Department of Computer Science

University of Colorado Boulder

bwag@colorado.edu

&Dhamma Kimura

Department of Computer Science

University of Colorado Boulder

dhamma.kimpara@colorado.edu

&Jessie Finocchiaro

Department of Computer Science

Boston College

finocch@bc.edu

Most of this work was completed while author was at Harvard University CRCS

###### Abstract

In multiclass classification over \(n\) outcomes, we typically optimize some _surrogate loss_\(L:^{d}\) assigning real-valued error to predictions in \(^{d}\). In this paradigm, outcomes must be embedded into the reals with dimension \(d n\) in order to design a _consistent_ surrogate loss. Consistent losses are well-motivated theoretically, yet for large \(n\), such as in information retrieval and structured prediction tasks, their optimization may be computationally infeasible. In practice, outcomes are typically embedded into some \(^{d}\) for \(d n\), with little known about their suitability for multiclass classification. We investigate two approaches for trading off consistency and dimensionality in multiclass classification while using a convex surrogate loss. We first formalize _partial consistency_ when the optimized surrogate has dimension \(d n\). We then check if partial consistency holds under a given embedding and low-noise assumption, providing insight into when to use a particular embedding into \(^{d}\). Finally, we present a new method to construct (fully) consistent losses with \(d n\) out of multiple problem instances. Our practical approach leverages parallelism to sidestep lower bounds on \(d\).

## 1 Introduction

Multiclass classification, due to its combinatorial and discontinuous nature, is intractable to optimize directly, which drives machine learners to optimize some nicer _surrogate loss_. To ensure these surrogates properly "correspond" to the discrete classification task, we seek to design _consistent_ surrogates. If one uses a consistent surrogate loss, in the limit of infinite data and model expressivity, one ends up with the same classifications as if one had solved the original intractable problem directly with probability \(1\).

Surrogate losses form the backbone of gradient-based optimization for classification tasks. Optimizing a surrogate is easier than direct optimization, but a large dimension \(d\) of the surrogate loss \(L:^{d}\) can make gradient-based optimization intractable. Therefore, previous literature has operated under the premise that the prediction dimension \(d\) should be as low as possible, subject to consistency for the classification task [Ramaswamy and Agarwal, 2016, Finocchiaro et al., 2024, 2020]. For multi-class classification over \(n\) outcomes, the lower bound on \(d\) is \(n-1\)[Ramaswamy and Agarwal, 2016].

These previous works implicitly focus on a binary approach to consistency: a surrogate is either consistent for every possible label distribution, or it is not consistent. But there is a way out: lower bounds on the surrogate dimension \(d\) rely on edge-cases that rarely show up in reality (Ramaswamy and Agarwal, 2016). As a result, practitioners are often willing to trade-off the guarantee of consistency in order to improve the computational tractability of optimization. However, we currently lack rigorous analysis tools to analyze many of the partially-consistent surrogates commonly used in practice. Thus, _unlike previous works, our work focuses on this more realistic paradigm of partial consistency._ We apply our unique approach to rigorously analyze a popular surrogate construction that encompasses methods such as one-hot and binary encoding. Our approach allows for fine-grained control of the trade-off between consistency and dimension.

Prior works have informally brushed upon the proposed partial-consistency paradigm, without rigorous study. For example, Agarwal and Agarwal (2015) impose a low-noise assumption to construct a surrogate for classification with \(d=(n)\). However, their work does not provide any way to control the consistency-dimension trade-off. Similarly, Struminsky et al. (2018) characterize the excess risk bounds of inconsistent surrogates, which teaches us about the learning rates for inconsistent surrogates, but not _under which distributional assumptions_ we can recover consistency guarantees.

Using different techniques than both of these approaches, we seek to understand the tradeoffs of consistency, surrogate prediction dimension, and number of problem instances through the use of polytope embeddings which are common in the literature (Wainwright et al., 2008; Blondel et al., 2020). When embedding outcomes into \(d n\) dimensions, we first show there always exists a set of distributions where _hallucinations_ occur: where the report minimizing the surrogate leads to a prediction \(\) such that the underlying true distribution has no weight on the prediction; that is, \(Pr[Y=]=0\) (Theorem 3). Following this, we show that every polytope embedding is partially consistent under strong enough low-noise assumptions (Theorem 5). Finally, we demonstrate through leveraging the embedding structure and multiple problem instances that the mode (in particular, a full rank ordering) over \(n\) outcomes embedded into a \(\) dimensional surrogate space is elicitable over all distributions via \(O(n^{2})\) problem instances (Theorem 10). This alternative approach to recovering consistency is parallelizable, detangling the complexity of gradient computation of one high-dimensional surrogate.

## 2 Background and Notation

Let \(\) be a finite label space, and throughout let \(n=||\). Define \(^{}_{+}\) to be the nonnegative orthant. Let \(_{}=\{p^{}_{+}\|p\|_{1}=1\}\) be the set of probability distributions on \(\), represented as vectors. We denote the point mass distribution of an outcome \(y\) by \(_{y}_{}\). Let \([d]:=\{1,,d\}\). In general, we denote a discrete loss by \(:_{+}\) with outcomes denoted by \(y\) and a surrogate loss by \(L:^{d}\) with surrogate reports \(u^{d}\) and outcomes \(y\). The surrogate must be accompanied by a link \(:^{d}\) mapping the convex surrogate model's predictions back into the discrete target space, and we discuss consistency of a _pair_\((L,)\) with respect to the target \(\).

For \(>0\), we define an epsilon ball via \(B_{}(u)=\{x^{d}\|u-x\|_{2}<\}\) and \(B_{}:=B_{}()\). Given a closed convex set \(^{d}\), we define a projection operation onto \(\) via \(_{}(u):=_{x}\|u-x\|_{2}\). Given a closed convex set \(^{d}\) and \(u^{d}\), we let the set-pointwise distance to be defined as \(\|u-\|_{2}:=\|u-_{}(u)\|_{2}\). Full tables of notation are found in Appendix A.

### Property Elicitation, Consistency, and Prediction Dimension

Discrete label prediction requires optimization of a target loss function, \(\), e.g. multi-class classification and 0-1 loss. When designing surrogate losses, consistency is the key notion of correspondence between surrogate and target loss. Intuitively, consistency implies that minimizing surrogate risk corresponds to solving the target problem. Finocchiaro et al. (2021) show that surrogate loss consistency is a necessary precursor to excess risk bounds and convergence rates.

Consistency is generally a difficult condition to work with directly. Hence, we will use the notion of _calibration_, which is equivalent to consistency in our setting with finite outcomes. Our approach follows from the property elicitation literature, which allows us to abstract away from the feature space \(\) and focus on the conditional distributions over the labels, \(p=[Y X=x]_{}\). In this approach, the central object of study is a _property_ which maps label distributions to reports that minimize the loss.

**Definition 1** (Property, Elicits, Level Set).: _Let \(\) be an arbitrary report set. For \(_{}\), a property is a set-valued function \(: 2^{}\{\}\), which we denote \(:\). A loss \(L:\) elicits the property \(\) on \(\) if_

\[\;p,\;(p)=*{arg\,min}_{u}_{Y p}[L(u,Y)]\;.\]

_If \(L\) elicits a property, it is unique and we denote it \([L]\). The level set of \(\) for report \(r\) is the set \(_{r}:=\{p r=(p)\}\). If \([L]=\) and \(|(p)|=1\) for all \(p\), we say that \(L\) is strictly proper for \(\)._

In this work, \(=\) for target losses and \(=^{d}\) for surrogate losses.

Once a model is optimized wrt. a surrogate \(L\), it predicts reports in the surrogate space, \(^{d}\). Then, to map surrogate reports to discrete labels, the surrogate loss must be paired with a link, \(:^{d}\). Intuitively, a surrogate and link pair \((L,)\) are calibrated with respect to a target loss \(\), if the optimal expected surrogate loss when making the _incorrect classification_ (by \(\)) is strictly greater than the optimal surrogate loss.

**Definition 2** (\(\)-Calibrated Loss).: _Given discrete loss \(:_{+}\), surrogate loss \(L:^{d}\), and link function \(:^{d}\). We say that \((L,)\) is \(\)-calibrated over \(_{}\) if, for all \(p\),_

\[_{u^{d}:(u)[](p)} _{Y p}[L(u,Y)]>_{u^{d}}_{Y p}[L(u,Y)]\;.\]

_If \(\) is not specified, then we are discussing calibration over \(_{}\). In general, when \((L,)\) is \(\)-calibrated over \(\) such that \(_{}\), we say partial calibration holds with respect to \(\)._

Our analysis crucially relies on the ability to specify \(\) when invoking the definition of calibration. This is because the surrogates we analyze break the \(d=n-1\) lower bound on the dimension of any consistent surrogate loss. So the surrogates will not be calibrated over the whole simplex \(_{}\). To aid in our analysis, we use a condition that shows that converging to a property value implies calibration for the target loss itself .

**Definition 3** (\(\)-Calibrated Property).: _Let \(_{}\), \(:^{d}\), discrete loss \(:_{+}\), and \(:^{d}\). We will say \((,)\) is \(\)-calibrated for all \(p\) and all sequences in \(\{u_{m}\}\) in \(^{d}\) if,_

\[u_{m}(p)_{Y p}[((u_{m}),Y)] _{r}_{Y p}[(r,Y)]\;.\]

**Theorem 1** ([1, Theorem 3]).: _Let \(:_{+}\) and \(_{}\). Let \(:^{d}\) and \(:^{d}\) be such that \(\) is elicitable and \((,)\) is an \(\)-calibrated property over \(\). Let \(L:^{d}\) be a convex function for all \(y\) and strictly proper for \(\) i.e. \([L]=\) and \(|(p)|=1\) for all \(p\). Then, \((L,)\) is \(\)-calibrated over \(\)._

Finally, we present the 0-1 loss that we analyze, which is the target loss for multiclass classification.

**Definition 4** (0-1 Loss).: _We denote the 0-1 loss by \(_{0-1}:\{0,1\}\) such that \(_{0-1}(y,):=_{y}\). Observe \(^{}(p):=[_{0-1}](p)=\{y |y_{y}p_{y}\}\)._

## 3 Polytope Embedding and Existence of Calibrated Regions

Often, discrete outcomes are embedded in continuous space onto the vertices of the simplex via one-hot encoding, or the vertices of the unit cube via binary encoding . Generalizing, we introduce an approach to surrogate construction inspired by  and Blondel et al.  that encompasses the aforementioned embedding methods. This construction utilizes embeddings onto the vertices of arbitrary low-dimensional polytopes \(:^{d}\). Then, an embedding scheme naturally induces a large class of loss functions \(L_{}^{G}\) defined by the embedding, any \(G\)-Bregman Divergence, and a link function \(^{}\).

Our analysis begins by defining a condition stronger than inconsistency that arises when embedding into \(d<n-1\) dimensions for multiclass classification. To this end, we introduce the notion of _hallucination_ as a means to characterize the "worst case" behavior of a surrogate pair (SS 3.2). In a positive manner, we characterize the _calibration regions_ of various embeddings (SS 3.3), which are sets \(_{}\) such that our surrogate and link pair \((L^{G}_{},^{})\) are \(\)-calibrated over \(\). We refer the reader to the Appendix B for omitted full proofs.

### Polytope Embedding Construction

A Convex Polytope \(P^{d}\), or simply a polytope, is the convex hull of a finite number of points \(u_{1},,u_{n}^{d}\). An extreme point of a convex set \(A\), is a point \(u A\) such that if \(u= y+(1-)z\) with \(y,z A\) and \(\), then \(y=u\) and/or \(z=u\). We shall denote by \((P)\) a polytope's set of extreme points. A polytope can be expressed by the convex hull of its extreme points, i.e. \(P=((P))\)(Bronsted, 2012, Theorem 7.2). Additional definitions pertaining to polytopes are used for proofs that are omitted to the appendix, we refer the reader to (SS B.1) for said definitions.

We propose the following embedding procedure that allows one to construct surrogate losses with almost _any_ polytope, and _any_ Bregman divergence.

**Construction 1** (Polytope Embedding).: _Given \(\) outcomes, \(||=n\), choose a polytope \(P^{d}\) such that \(|(P)|=n\). Choose a bijection between \(\) and \((P)\). According to this bijection, assign each vertex a unique outcome so that \(\{v_{y}^{d}|y\}=(P)\). Then the polytope embedding \(:_{} P\) is \((p):=_{y}p_{y}v_{y}\), which is the sum of \(p\)-scaled vectors_

Following the work of Blondel (2019) and their proposed Projection-based losses, we use the extremely general class of Bregman divergences (Definition 5) and a polytope embedding \(\) to define an induced loss \(L^{G}_{}\) (Definition 6).

**Definition 5** (Bregman Divergence).: _Given a strictly convex function \(G:^{d}\), \(D_{G}(u,v):=G(v)-[G(u)+ dG_{v},u-v]\) is a Bregman divergence where \(dG_{v}\) denotes a subgradient of \(G\) at \(v\). For this work, we shall always assume that \((G)=^{d}\)._

**Definition 6** (\((D_{G},)\) Induced Loss).: _Given a Bregman divergence \(D_{G}\) and a polytope embedding \(\), we say \((D_{G},)\) induces a loss \(L^{G}_{}:^{d}_{+}\) defined as_

\[L^{G}_{}(u,y):=D_{G}(u,v_{y})=G(v_{y})-[G(u)+ dG_{v_{y}},u-v_{y} ]\.\]

_Note, that for any fixed \(y\), \(L^{G}_{}(u,y)\) is convex with respect to \(u^{d}\)._

We show that for any \(p_{}\), the report that uniquely minimizes the expectation of the loss \(L^{G}_{}\) is \((p)\), the embedding point of \(p\). Furthermore, the polytope \(P\) contains all of, and only the minimizing reports in expectation under \(L^{G}_{}\).

**Proposition 2**.: _For a given induced loss \(L^{G}_{}\), the unique report which minimizes the expected loss is \(u^{*}:=*{arg\,min}_{u^{d}}_{  p}[L^{G}_{}(u,Y)]=(p)\) such that \(u^{*} P\). Furthermore, every \( P\) is a minimizer of \(_{}[L^{G}_{}(u,Y)]\) for some \(_{}\)._

We now define the maximum a posteriori (MAP) link, which will be used in conjunction with an induced loss \(L^{G}_{}\) to form a surrogate pair for the 0-1 loss. The MAP link projects surrogate predictions onto the polytope \(P\), then links to the nearest vertex of \(P\), and is commonly used in the literature (Tsochantaridis et al., 2005; Blondel, 2019; Xue et al., 2016). Since the MAP link performs a projection, one may ask if this is computationally challenging; fortunately this operation is computationally feasible due to the convexity of the polytope (Blondel, 2019).

**Definition 7** (MAP Link).: _Let \(\) be a polytope embedding from \(_{}\) to \(P\). The MAP link \(^{}:^{d}\) is defined as \(^{}(u)=*{arg\,min}_{y}\|_{P}(u )-v_{y}\|_{2}\). The level set of the link for \(y\) is \(^{}_{y}=\{u^{d}|y=^{}(u)\}\). We break ties arbitrarily but deterministically._

### Hallucination Regions

Since our polytope embedding violates surrogate dimension bounds, calibration for 0-1 loss will not hold for all distributions. In particular, we show there always exists some distribution \(p\) such that \(p_{y}=0\) yet \(_{ p}[L^{G}_{}(u,Y)]\) is minimized at some \(u\) such that \(^{}(u)=y\). This implies a "worst case" inconsistency where the reported outcome could never actually occur with respect to our embedding of \(n\) events via \(\) into \((P)\).

**Definition 8** (Hallucination).: _Given \((L,)\) such that \(L:^{d}_{+}\), \(||=n\), \(d<n\), and \(:^{d}\), we say that a hallucination occurs at a surrogate report \(u^{d}\) if, for some \(p_{}\), \(u*{arg\,min}_{^{d}}_{ p}[L(,Y)]\) and \((u):=y\) but \(p_{y}=0\). We denote by \( P^{d}\) as the hallucination region as the elements of \(P\) at which hallucinations can occur._

We express the subspace of the surrogate space where hallucinations can occur as the hallucination region denoted by \(\). In Theorem 3, we characterize the hallucination region for any polytope embedding while using the surrogate pair \((L^{G}_{},^{})\) and show that \(\) is never empty.

**Theorem 3**.: _For any given pair \((L^{G}_{},^{})\) and \(_{0-1}\) with embedding dimension \(d<n-1\); it holds that \(=_{y}\,((P) \{v_{y}\})^{}_{y}\) and furthermore \(\)._

_Sketch._ Fix \(y\). We abuse notation and write \((P_{-y}):=(P)\{v_{y}\}\). Observe \(\,((P_{-y}))^{}_{y} \) since any point in this set can be expressed as a convex combination without needing vertex \(v_{y}\) implying there is a distribution embedded by \(\) to said point which has no weight on \(y\). We seek to show that \(_{y}\,((P_{- y}))^{}_{y}\). Assume there exists a point \(u\,((P) v_{y})^{}_{y}\) such that there exists some \(p_{}\) where \((p)=u\), \(p_{y}=0\), and \(^{}(u)=y\). Since \(^{}(u)=y\) and \(u\,((P_{-y}))^{}_{y}\), it must be the case that \(u\,((P_{-y}))\). However, that implies that \(u\) is strictly in the vertex figure and thus must have weight on the coefficient for \(y\). Thus, forming a contradiction that \(p_{y}=0\) which implies that \(_{y}\,((P_{- y}))^{}_{y}\). Finally, using Helly's Theorem [14, Corollary 21.3.2] we show that \(_{y}\,((P) v_{y})\), which implies the non-emptiness of \(\) as well. 

Theorem 3 suggests that using machine learning in high-risk settings such as medical and legal applications while violating the known \(n-1\) dimensional bound for surrogate losses in multiclass classification is inherently ill-advised without human intervention given the possibility for hallucinations. Furthermore, hallucinations may be forced by the target loss, as in the case of Hamming loss (see Appendix C). In these cases practitioners should carefully consider the choice of target loss. We conjecture that hallucinations are common for many structured prediction losses. However this is not a concern in our primary loss of study of multi-class classification.

### Calibration Regions

Ideally, we would like calibration to hold over the entire simplex since that would imply minimizing surrogate risk would always correspond to solving the target problem regardless of the true underlying

Figure 1: (Left) Mode level sets of \(_{}\) where \(=\{a,b,c,d\}\) embedded into a two dimensional unit cube. The center red point denotes the origin \((0,0)\) which is the hallucination region. (Right) An embedding of \(_{}\) where \(=\{a,b,c,d,e,f\}\) into a three-dimensional permutahedron: the beige region expresses strict calibration regions, the light pink regions expresses regions with inconsistency, and the auburn region expresses regions with hallucinations. For example, consider the report \(u=\). Since losses are convex, if \(p=(0,,0,0,,0)\), then \(\,(\{b,e\})\) (dashed grey) is optimal, which includes \(u\). However, \(\) is also contained in \(\,(\{a,d\})\) which is optimal for the distribution \(p^{}=(,0,0,,0,0)\). Therefore, we cannot distinguish the optimal reports for a hallucination at \(\).

distribution. We observe that the mode's embedded level sets in the polytope overlap (see Figure 1L), which is unsurprising given that we are violating the lower bounds on surrogate prediction for the mode and hence calibration does not hold over the entire simplex. Since \(|2^{}\{\}|\) is a finite set, we know that the number of unique mode level sets is finite. Although every point in the polytope is a minimizing report for some distribution, if multiple distributions with non-intersecting mode sets are embedded to the same point, there is no way to define a link function that is correct in all cases. However, if the union of mode sets for the \(p\)'s mapped to any \(u P\) is a singleton, regardless of the underlying distribution+, a link \(\) would be calibrated over the union if it mapped \(u\) to the mentioned singleton. Given \((L,)\), \(\), and a target loss \(\), we define strict calibrated regions as the points for which calibration holds regardless of the actual distribution realized, which are possible at said points.

Footnote †: We leave the more general case of linking \(u\) when \(_{p^{-1}(u)}(p)\) to future work.

**Definition 9** (Strict Calibrated Region).: _Suppose we are given \((L,)\), \(\), and a target loss \(\). We say \(R P\) is a strict calibrated region via \((L,)\) with respect to \(\) if \((L,)\) is \(\)-calibrated for all \(p^{-1}(R):=\{p_{}:(p) R\}\)._

_For any \(y\), we define \(R_{y} R_{y}\). We let \(R_{}_{y}R_{y}\)._

By violating lower bounds, we are in a partially consistent paradigm where surrogate reports do not necessarily correspond to a unique distribution \(p\). However, strict calibration regions allow us to check whether or not the loss is calibrated for the distribution \(p\) generating the data -- even without explicit access to \(p\). One simply has to check whether the report \(u\) is in \(R_{}\).

In Theorem 4, regardless of one's chosen \(P\), we show that there always exists a non-zero Lebesgue measurable strict calibration region and that \((L_{}^{G},^{})\) is calibrated for the 0-1 loss overall distributions embedded into the strict calibration region. This result shows that our surrogate and link construction for _any_\(d\), always yields discernible calibration regions -- lending support to the practical use and study of these surrogates.

**Theorem 4**.: _Let \(D_{G}\) be a Bregman divergence, \(\) be any polytope embedding, \(^{}\) be the MAP link, and \(L_{}^{G}\) be the loss induced by \((D_{G},)\). There exists a \(_{}\) with non-zero Lebesgue measure and \(() R_{}\) via \((L_{}^{G},^{})\) with respect to \(_{0-1}\)._

Although strict calibration regions \(R_{y}\) exist for each outcome \(y\) via the polytope embedding, tightly characterizing strict calibration regions is non-trivial. Since the level sets of elicitable properties are convex within the underlying simplex, characterizing the strict calibration regions becomes a collision detection problem, which is often computationally hard.

## 4 Restoring Inconsistent Surrogates via Low-Noise Assumptions

Looking towards application, we refine our results on the existence of strict calibration regions by examining a low-noise assumption, which provides an interpretable calibration region (SS 4.1). We show which low-noise assumptions imply calibration when embedding \(2^{d}\) outcomes into \(d\) dimensions and \(d!\) outcomes into \(d\) dimensions (SS 4.2). We refer the reader to Appendix B for omitted proofs.

### Calibration via Low Noise Assumptions

We demonstrate that every polytope embedding leads to calibration under some low-noise assumption. Our results enable practictioners to choose the dimension \(d\), unlike in previous works. Following previous work , we define a low noise assumption to be a subset of the probability simplex on the label distribution parameterized by \(\): \(_{}=\{p_{}_{y}p_{ y} 1-\}\) where \(\). This noise assumption can be understood as Massart noise  in the multiclass setting.

Given \(\) and \(y\), we define the set \(^{y}_{y}=\{(1-)_{y}+_{} \}\). With an embedding \(\) onto \(P\), we define the set \(P^{y}_{}:=((^{y}_{}))\), a scaled version of \(P\) anchored at \(v_{y}\), that moves vertices \((1-)\) proportionally towards \(y\), (Figure 2R).

**Theorem 5**.: _Let \(D_{G}\) be a Bregman divergence, \(\) be any polytope embedding, and \(L_{}^{G}\) be the loss induced by \((D_{G},)\). There exists an \([0,.5)\) such that for the link \(^{,}(u)=*{arg\,min}_{y}\|u-P^{y}_{ }\|_{2},\,(L_{}^{G},^{,})\) is \(_{0-1}\)-calibrated over the distributions \(_{}:=\{p_{}_{y}p_{y} 1- \}\)._Proof.: **Part 1 (Choosing \([0,.5)\))**: By Theorem 4, there exists an \(>0\) such that \(B_{}(v_{y}) P R_{y}\) for all \(y\). Given that \((P)\) are unique points, there exists a sufficiently small \(^{}>0\) such that \(B_{^{}}(v) B_{^{}}()=\) for all \(v,(P)\) where \(v\). Let \(^{}=(,^{})\). For any \(y\), observe the set \((_{}^{y})\), defined using any \([0,.5)\), is a scaled-down translated unit simplex and that for all \(p(_{}^{y})_{}\) it holds that \(y=(p)\).

We shall show that for some sufficiently small \([0,.5)\), \(P_{}^{y}\) is a scaled down version of \(P\) positioned at the respective vertex \(v_{y}\). Furthermore, we shall show that \(P_{}^{y} B_{^{}}(v_{y}) P R_{y}\) for all \(y\). Observe that by linearity of \(\),

\[P_{}^{y}:=((_{}^{y}))= ((\{(1-)_{y}+_{} |\}))=(\{(1-)v_{y}+  v_{}|\})\]

and hence, \(P_{}^{y}\) is a scaled version of \(P\) positioned at \(v_{y}\). Hence for some sufficiently small \(\), \((1-)v_{y}+ v_{} B_{^{}}(v_{y})\) for all \(\) and hence \(P_{}^{y} B_{^{}}(v_{y}) R_{y}\). With said sufficiently small \(\), define \(^{,}\) and the respective sets \((_{}^{y})\) for each \(y\). Using the previous \(\), define the set \(_{}\) as well.

**Part 2 (Showing Calibration)**: Recall, by Proposition 2, for any \(p_{}\), \(u=(p)\) minimizes the expected surrogate loss \(_{ p}[L_{}^{G}(u,Y)]\). For any fixed \(y\), observe that \(\{(1-)_{y}+_{} \}=\{p_{}:p_{y} 1-\} _{}\) and hence, by Proposition 2, \(_{y}P_{}^{y}\) contains all of the minimizing surrogate reports with respect to \(_{}\). By our choice of \(\) and the construction of \(_{}^{P}\), every \(u_{y}P_{}^{y}\) is linked to the proper unique mode outcome since \(_{y}P_{}^{y} R_{}\). Assuming a low-noise condition where \(p_{}\), any \(u_{y}P_{}^{y}\) is never optimal for any low-noise distribution. In such cases, we project the point to the nearest \(P_{}^{y}\) as a matter of convention. Given that calibration is a result pertaining to minimizing reports, this design choice is non-influential. Finally, since every \(_{y}P_{}^{y} R_{}\), by the definition of strict calibration region, it holds that \((L_{}^{G},^{,})\) is \(_{0-1}\)-calibrated for \(_{}\). 

### Embedding into the Unit Cube and Permutahedron under Low-Noise

In this section, we demonstrate embedding onto the unit cube and the permutahedron (Blondel et al., 2020; Seger, 2018). We show that by embedding \(2^{d}\) outcomes into a \(d\) dimensional unit cube \(P^{}\), \((L_{}^{G},^{P^{},})\) is calibrated over \(_{}\) for all \([0,)\). Furthermore, we found that by embedding \(d!\) outcomes into a \(d\) dimensional permutahedron \(P^{w}\), \((L_{}^{G},^{P^{w},})\) is calibrated for \(_{}\) for \([0,)\). Theorem 6 enables us to simultaneously study the aforementioned embeddings.

**Theorem 6**.: _Let \(D_{G}\) be a Bregman divergence, \(\) be any polytope embedding, and \(L_{}^{G}\) be the loss induced by \((D_{G},)\). Fix \([0,.5)\) and with it define \(_{}\). If for all \(y,\) such that \(y\) it holds that \(P_{}^{y} P_{}^{}=\), then \((L_{}^{G},^{,})\) is \(_{0-1}\)-calibrated for \(_{}\) where \(^{,}(u)=*{arg\,min}_{y}\|u-P_{ }^{y}\|_{2}\)._

Proof.: Pick an \(\) such that for all \(y,\), \(P_{}^{y} P_{}^{}=\). Define \(_{}\) and \(^{,}\) accordingly. For \(p_{}\) and some \(y\), say a sequence \(\{u_{m}\}\) converges to \([L_{}^{G}](p)=(p) P_{}^{y}\), where the equality follows from Proposition 2. Given that each \(P_{}^{y}\) is closed and pairwise disjoint, there exists some \(>0\) such that for all \(y,\) where \(y\), it also holds that \((P_{}^{y}+B_{})(P_{}^{}+B_{})=\) where \(+\) denotes the Minkowski sum. Since \(\{u_{m}\}\) converges to \((p)\), there exists some \(N\) such that for all \(n N\), \(\|u_{n}-(p)\|_{2}<\). By the definition of \(^{,}\), any \(u_{n}\) where \(n N\) will be mapped to \(y\), the correct unique report given that \([L_{}^{G}](p) P_{}^{y}\). Hence, \(([L_{}^{G}],^{,})\) is \(_{0-1}\)-calibrated property with respect to \(_{}\). Finally, since \(L_{}^{G}\) is strictly proper for \([L_{}^{G}]\), by Theorem 1, we have that \((L_{}^{G},^{,})\) is \(_{0-1}\)-calibrated for \(_{}\). 

Unit CubeDefine a unit cube in \(d\)-dimensions by \(P^{}:=(\{-1,1\}^{d})\). Binary encoding outcomes into the elements of \(\{-1,1\}^{d}\) (the vertices of a unit cube) is a commonly used method in practice (e.g., (Seger, 2018; Yu and Blaschko, 2018)). We show that calibration holds under a low noise assumption of \(_{}\) when \(<.5\).

**Corollary 7**.: _Let \(\) be an embedding from \(2^{d}\) outcomes into the vertices of \(P^{}\) in \(d\)-dimensions and define an induced loss \(L_{}^{G}\). Fix \([0,.5)\) and define \(_{}\). \((L_{}^{G},^{P^{},})\) is \(_{0-1}\)-calibrated for \(_{}\)._Corollary 7 suggests that binary encoding is an appropriate methodology when one has a prior over the data that the mode of the label distribution \([Y X=x]\) is greater than half for all \(x\). Interestingly, the bound of \(\) is not dependent on the dimension of \(d\). We now present a result for embedding outcomes into a factorially lower dimension via the permutahedron. Intuitively, ranking can be recast as a multiclass classification problem, in which case the outcomes are orderings of the \(d\) possible labels.

PermutahedronLet \(_{d}\) express the set of permutations on \([d]\). The permutahedron associated with a vector \(w^{d}\) is defined to be the convex hull of the permutations of the indices of \(w\), i.e., \(P^{w}:=(\{(w)_{d}\}) ^{d}\). The permutahedron may serve as an embedding from \(d!\) outcomes into \(d\)-dimensions; it is a natural choice for embedding full rankings over \(d\) items.

**Corollary 8**.: _Let \(\) be an embedding from \(d!\) outcomes into the vertices of \(P^{w}\) in \(d\) dimensions such that \(w=(0,,,,)^{d}\) where \(=\). Fix \([0,)\). Then \((L^{G}_{},^{P^{w},})\) is \(_{0-1}\)-calibrated over \(_{}\)._

The calibration region in Corollary 8 show that consistency in \(_{}\) shrinks exponentially in \(d\). Unless one has a prior that the data follows some form of a power distribution, Corollary 8 suggests not to factorially embed outcomes.

## 5 Elicitation in Low Dimensions with Multiple Problem Instances

The tools developed in previous sections now enable us to address the setting in which we require full consistency, \(=_{}\), but also desire surrogate prediction dimension \(d n-1\). We side-step the \(n-1\) lower bound by utilizing multiple problem instances and aggregation of the outputs. Although cumulatively we have a larger surrogate prediction dimension than \(n-1\), each individual problem instance has a less than \(n-1\) surrogate prediction dimension. This approach is well-motivated since it allows for distributed computing of separate, smaller models which leads to faster convergence overall since in general optimization is at least \(poly(d)\). Previous work such as Ramaswamy et al. (2014) has explored the consistency of multiclass problem reductions; however, we take a different, geometrically motivated, approach.

**Definition 10**.: _Extending Definition 1, we say a loss and link pair \((L,)\), where \(L:^{d}\) and \(:^{d}\), elicits a property \(:\) on \(_{}\) if \(\ p,\ (p)=(_{u^{d}}_{Y p}[L(u,Y)])\)._

**Definition 11** (\((n,d,m)\)-Polytope Elicitable).: _Suppose we are given a property \(:\) such that \(_{}\) and \(||=n\) finite outcomes. Say we have \(m\) unique polytope embeddings \(\{_{j}:_{}^{d}\}_{j=1}^{m}\) where \(d<n-1\), and a set of induced losses \(\{L^{G}_{_{j}}\}_{j=1}^{m}\) and links \(_{j}:^{d}_{j}\) defined wrt. \(_{j}\), where \(_{j}\) is an arbitrary report set. For each \(j[m]\), assume the pair \((L^{G}_{_{j}},_{j})\) elicits the property \(_{j}:_{j}\). If there exists a function \(:_{1}_{m} \) such that for any \(p_{}\) it holds that \((_{1}(p),,_{m}(p))=(p)\), we say that \(\) is \((n,d,m)\)-Polytope Elicitable over \(\)._Equivalently, we will also say that the pair \((\{(L^{G}_{_{j}},_{j})\}_{j=1}^{m},)\)\((n,d,m)\)-Polytope elicits the property \(\) with respect to \(\).

We shall express a \(d\)-cross polytope by \(P^{}:=(\{(( 1,0,,0))_{d}\})\) where \(( 1,0,,0)^{d}\). Observe that a \(d\)-cross polytope has \(2d\) vertices. For any vertex of a d-cross polytope \(v(P^{})\), we shall say that \((v,-v)\) forms a diagonal vertex pair.

**Lemma 9**.: _Say we are given a cross-polytope embedding \(:_{2d} P^{}\) and induced loss \(L^{G}_{}\). Let \((v_{a_{i}},v_{b_{i}})\), be the \(i^{th}\) diagonal pair (i.e. \((_{a_{i}})=v_{a_{i}}\)). Define the property \(^{}:_{2d}\) element-wise by_

\[^{}(p)_{i}:=\{(<,a_{i},b_{i})&p_{a_{i}}<p_{b_{i}}\\ (>,a_{i},b_{i})&p_{a_{i}}>p_{b_{i}}\\ (=,a_{i},b_{i})&p_{a_{i}}=p_{b_{i}}..\]

_Furthermore define the link \(^{P^{}}:^{d}\) with respect to each diagonal pair as_

\[(u;v_{a_{i}},v_{b_{i}})_{i}^{P^{}}:=\{(<,a_{ i},b_{i})&||u-v_{a_{i}}||_{2}>||u-v_{b_{i}}||_{2}\\ (>,a_{i},b_{i})&||u-v_{a_{i}}||_{2}<||u-v_{b_{i}}||_{2}\\ (=,a_{i},b_{i})&.\]

_Then \((L^{G}_{},^{P^{}})\) elicits \(^{}\)._

The following theorem states that by using multiple problem instances, based on Lemma 9, we can Polytope-elicit the mode. Algorithm 1 outlines how to aggregate the individual solutions to infer the mode. We defer the proof to Appendix B.

**Theorem 10**.: _Let \(d 2\). The mode is \((2d,d,m)\)-Polytope Elictable for some \(m[2d-1,d(2d-1)]\)._

**Require:**: \(M=\{(L^{G}_{_{j}},^{P^{}}_{j})\}_{j=1}^{m}\)

Learn a model \(h_{j}:^{d}\) for each instance \((L^{G}_{_{j}},^{P^{}}_{j}) M\)

For some fixed \(x\), collect all \(B_{j}^{P^{}}_{j}(h_{j}(x))\) where \(B_{j}_{j}\)

Report \(R^{}(B_{1},,B_{m})\)

**Algorithm 1** Elicit mode via comparisons and the \(d\)-Cross Polytopes

Although Theorem 10 states that the mode is \((2d,d,m)\)-Polytope Elictable for some \(m[2d-1,d(2d-1)]\), it does not state how we select said \(\{(L^{G}_{_{j}},^{P^{}}_{j})\}_{j=1}^{m}\) problem instances in an optimal manner. Unfortunately, selecting the min number of problem instances reduces to a a minimum set cover problem which is computationally hard. Even so, through a greedy approach, one can choose

Figure 3: Four outcomes embedded in \(^{2}\) in two different ways, with the minimizing reports \(\) for a distribution \(p\).” (Left) Configuration \(_{1}\) with \(\) at \((-.5,.3)\) implying \(p_{a}>p_{d}\) and \(p_{b}>p_{c}\). (Right) Configuration \(_{2}\) with \(\) at \((0,0)\) implying \(p_{a}=p_{b}\) and \(p_{c}=p_{d}\). This implies the true distribution is \(p=(0.4,0.4,0.1,0.1)\).”

problem instances that are log approximate optimal relative to the true best configuration. In practice using real data, given that these are asymptotic results, we may have conflicting logic for the provided individual reports. In Appendix D, we discuss an approach of how to address this in practice.

## 6 Discussion and Conclusion

This work examines various tradeoffs between surrogate loss dimension, restricting the region of consistency in the simplex when using the 0-1 loss, and number of problem instances. Since our analysis is based on an embedding approach commonly used in practice, our work provides theoretical guidance for practitioners choosing an embedding. We see several possible future directions. The first is a deeper investigation into hallucinations. Future work could investigate the size of the hallucination region in theory, and the frequency of reports in the hallucination region in practice. Another direction would be to construct a method that efficiently identifies the strict calibration regions and the distributions embedded into them. This would provide better guidance on whether or not a particular polytope embedding aligns with one's prior over the data. Another possible direction would be to explore whether concepts from this paper could be applied to the underlying problem of cost-sensitive multiclass classification. Finally, another direction is to identify other properties that can be elicited via multiple problem instances while also reducing the dimension of any one instance.

**Broader Impacts:** Our work broadly informs the selection of loss functions for machine learning. Thus our work may influence practitioners' choice of loss function. Of course, such loss functions can be used for ethical or unethical purposes. We do not know of particular risks of negative impacts of this work beyond risks of machine learning in general.