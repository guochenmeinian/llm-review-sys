# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

Despite the empirical evidence of topological vulnerabilities of graph representations, theoretical explanations delineating the effectiveness of such attacks remain largely unexplored: As demonstrated in previous studies [11; 17], similarity-based attacks are remarkably effective against _sparse_ graphs that exhibit a generalized homophily pattern, i.e., there exists a significant correlation between the similarity of node features and edge adjacency information. This phenomenon posits that _feature similarity_ may serve as a confounding factor, potentially impacting the efficacy of similarity-based attacks. It is therefore valuable to understand the influence of graph properties, such as feature similarity and sparsity, on the edge reconstruction process of the attacking procedures.

Beyond their capability in characterizing the vulnerabilities of representations, attacking algorithms may also function as empirical attestations of privacy-preserving inference protocols that fulfill formal privacy guarantees such as differential privacy [9; Section 4]. As an illustrative case, membership inference attacks can be employed for auditing differential privacy . Since edge reconstruction is equivalent to edge membership inference on graphs , it is thus pertinent to explore the performance of similarity-based attacks when confronted with privacy-preserving graph representations [30; 36].

In this paper, we take initial steps toward a principled understanding of structural vulnerabilities of graph representations under the similarity-based edge reconstruction attack (hereafter abbreviated as SERA) which forms a realistic threat in many practical scenarios such as vertical federated learning . In particular, we establish the following theoretical as well as empirical findings:

1. **Success modes of SERA** Through applying SERA to sparse random graphs equipped with independent random node features, we show that SERA provably reconstructs the input graph via a non-asymptotic analysis. The result indicates that feature similarity is not necessary for SERA to succeed. We conduct both synthetic experiments as well as real-world data evaluations to empirically validate our theory.
2. **Failure modes of SERA** We show, through theoretical analysis and corroborative synthetic experiments, performance lower bounds when applying SERA to stochastic block models (SBM) with independent random node features: When the underlying SBM has \((1)\) intra-group connection probability, edge recovery through graph representations becomes provably hard.
3. **Mitigation of SERA** We assess the resilience of SERA using noisy aggregation (NAG) as the privacy protection mechanism. Theoretical guarantees of NAG are established which further extends previous results, accompanied by extensive empirical evaluations to corroborate our theoretical assertions. Intriguingly, our findings reveal instances wherein NAG provides significant resistance to SERA, even under some scenarios where it only guarantees very weak privacy. Such discoveries delineate the circumstances that elucidate both the strengths and limitations of SERA as a privacy auditing tool.

## 2 Related works

Typically, there exist two categories of private information that may potentially be compromised during the training or deployment phases of graph neural network models: The (sensitive) node attributes and the adjacency relation between nodes. In this paper we focus on the later category since edge adjacency relations are less informative, i.e., for each pair of nodes, the existence of an edge constitutes only a single bit of information.

### Edge reconstruction attacks on graph-structured data

Contemporary developments on edge reconstruction attacks differ significantly in their conceptualization of adversaries, particularly in terms of their capabilities [45; 44] and the extent of prior knowledge they possess about the GRL model and the underlying graph dataset . The mechanism of SERA was first proposed in  and later studies in . Empirical evidences suggest that with only black-box access to node representations, the SERA mechanism obtains a high success rate (AUC \(>0.9\) for the Citeseer dataset). Subsequent developments have explored stronger attacks under more powerful adversaries. In  the authors investigated the impact of an adversary's prior knowledge, including the possession of node features, partial graph structure, and access to a shadow dataset, on the success rate of corresponding attack strategies. Inspire by information bottleneck, improves SERA via carefully exploiting intermediate representations produced by GNNs. Notably,despite the adversaries in [17; 46] being equipped with substantially more information compared to SERA, the resulting enhancement in attack performance exhibited by these adversaries demonstrates only marginal improvements relative to SERA. The GraphMI attack  disables the adversary from being able to acquire node representations but instead requires access to node features and labels, as well as white-box access to the GNN model. Recent works explored influence-based attacking schemes, wherein the adversary is allowed to alter the graph information: The LinkTeller attack  manipulates node features while  infiltrates the underlying graph with malicious nodes.

### Theoretical explorations in graph recovery from neural representations

In , the authors proposed an algorithm that provably recovers graph structure based on representations generated via DeepWalk, which is a factorizaton-based procedure and different from GNN-produced representations. In  the authors showed that when block structure exists in the underlying graph, the performance of SERA is uneven across node in different blocks. In , the authors use information-theoretic arguments to construct more powerful attacks than SERA. Nevertheless, the aforementioned studies did not provide a theoretical rationale for the practical vulnerabilities manifested as a result of the SERA. In a contemporary work , the authors derived generalization bounds of linear GNN under the link prediction context assuming the underlying graph generated by a moderately sparse graphon model.

### Privacy protection against edge reconstruction attacks

Edge differential privacy (EDP)  is the most popular privacy notion that offers a formal protection against edge reconstruction attacks. Standard private training algorithms like DPSGD  may produce GNN models that is provably private in the sense that membership information of any individual training sample is limitly disclosed. 2 However, such approaches do not provide privacy during _inference_ time . Protection mechanisms against inference-time adversaries are mostly based on noisy version of GNN encoding such as edge-wise randomized response  that provides very strong privacy protection yet being overly destructive to model utility. Noisy aggregation (NAG) mechanisms [30; 36; 7] are recently proposed that empirically achieves better privacy-utility trade-offs. Inspired by the information bottleneck principle, [33; 46] proposed to use regularization or saddle-point optimization techniques to control privacy leakage. Yet these proposals are not principled in theory.

## 3 Preliminaries

**Setup and notations** Consider an undirected graph \(G=(V,E)\) with \(n=|V|\) nodes associated with node features \(X^{n d}\). Denote \(A\) as the corresponding adjacency matrix and \(D\) as the diagonal matrix with the \(v\)-th diagonal entry being the degree of node \(v\). In this paper, we will study _victim models_ taking forms of graph neural encoders. Our vulnerability analysis predominantly centers on the _linear graph neural network_ architecture which has been widely adopted in previous theoretical studies on graph neural networks [3; 39; 37; 8]. Specifically, the node representation matrix of an \(L\)-layer linear GNN is computed as:

\[H^{(L)}=((D+I)^{-1}(A+I))^{L}XW,\] (1)

where the identity matrix is added for ensuring self-loops, and \(W^{d d}\) is the weight matrix. Throughout this paper, we will assume the node feature dimension and the hidden dimension to be equal to \(d\) and refer to this as the feature dimension, as otherwise we may add an extra input projection to fulfill this requisite. We further denote \(\|\|_{}\) and \((W)\) as the operator norm (i.e., largest singular value) and condition number (i.e., the ratio of largest and smallest singular value) of matrix \(W\).

**Threat model** We assume the adversary knows the node set \(V\) and is able to inquire node representations of an arbitrary node subset \(V_{} V\). Hereafter we will refer to the subgraph induced via \(V_{}\) as the _victim subgraph_\(G_{}=(V_{},E_{})\). The goal of the adversary is to recover an arbitrary fraction of \(E_{}\) based on the acquired node representations\(H_{}^{(L)}=\{h_{v}^{(L)},v V_{}\},L>0\). We identify two representative scenarios that underscore the potential threat by such adversaries: The first scenario is API-style deployments of graph representations , wherein an adversary might query the node representations for a set of nodes using their node identifiers, with this particular subset of nodes constituting the victim nodes. The second scenario pertains to a two-party vertical federated learning (VFL) context , wherein the graph topology retained by party A is deemed confidential. Under such a setup, the privacy threat materializes as party B might adhere to the VFL protocol while simultaneously being curious about the topology. Note that the capabilities of the adversaries posited herein are intentionally constrained by denying them access to both the raw node features \(X\) and the model parameters. Additionally, the objectives of the adversary are decidedly ambitious, aiming at the potential recovery of the entire suite of edges within the victim subgraph. A more in-depth discussion regarding the threat model and the potent capabilities of the adversary is deferred to appendix B.1.

The SERA is based on a similarity measure \(\), with the adjacency relation between node \(u\) and node \(v\) inferred as

\[_{uv}^{}()=((h_ {u}^{(L)},h_{v}^{(L)})),\] (2)

where we denote \(()\) as the indicator function. In this paper we will be primarily interested in two similairty measures: The cosine similarity \((x,y)= x,y/( x_{ 2} y_{2})\) and correlation similarity \((x,y)= x-,y-/( x -_{2} y-_{2})\), which is essentially a centered version of cosine similarity (\(,\) are coordinate-wise averages of \(x\) and \(y\)) defined for node representations with dimension greater than \(1\). The cutoff threshold \(\) is allowed to depend on the embedding set \(H_{}\) but is uniform across all edge decisions. Hereafter without misunderstandings, we will drop the superscript and denote \(()\) as the reconstructed adjacency matrix under threshold \(\). To measure the performance of the attack, we use false positive rate (\(\)) and false negative rate (\(\)) defined as

\[_{}()=( _{uv}()=1)(A_{uv}=0)}{_{u,v} (A_{uv}=0)},_{}()= (_{uv}()=0) (A_{uv}=1)}{_{u,v}(A_{uv}=1)}.\] (3)

We further define the error rate \(\) as the summation of \(\) and \(\). Employing these metrics facilitates a more nuanced characterization of attack performance, particularly when the underlying graph is sparse. An alternate metric that is often used in practice  is the area under the receiver operating characteristic curve (\(\)) metric

\[_{}=_{0}^{1}(1-_{} (_{}^{-1}(s)))ds\] (4)

which quantifies the aggregate performance of \(\) by integrating the trade-off between the false positive rate and the false negative rate across different thresholds.

Intuitively, the success of SERA is determined by the correlation between node representation similarity and edge presence. Previous empirical observations demonstrate the effectiveness of SERA against graphs that exhibit strong correlations between node feature similarity and edge presence . We will refer to such kinds of graphs as being homophilous in a generalized sense [18; 22]. We defer a more formal introduction to homophily measrues to appendix B.2. Due to the message-passing nature of GNN encoders, it is intuitively reasonable that recursive aggregation of node representations strengthens the correlation and results in successful edge reconstructions. However, it is non-trivial whether SERA mechanism may succeed in the absence of the aforementioned generalized homophily pattern, which motivates our first analysis.

## 4 SERA against sparse random graphs

In this section, we study the behavior of SERA with the underlying (victim) graph generated according to a _sparse random graph_. Here, the adjacency matrix is generated such that each entry is independently distributed (up to symmetric constraints \(A_{uv}=A_{vu}\)) following a Bernoulli distribution \(A_{uv}(p_{uv})\). We focus on the sparse regime and allow \(p_{uv}\) to depend on \(X_{u}\) and \(X_{v}\). We further assume that the node features \(X_{v}\)'s are generated i.i.d. according to an isotropic Gaussian distribution \(X_{v} N(0,I_{d})\). It follows that the correlation of node feature similarity and edge presence is zero. The following theorem characterizes the effectiveness of SERA under the sparse random graph setup.

**Theorem 4.1**.: _Let \(C_{1},C_{2}\) be a universal constants. Assume the following:_

1. _The graph generation mechanism satisfies_ \(_{u V}p_{uv}<C_{1} n\) _holds for all_ \(v V\)_._
2. _The depth of GNN encoder_ \(L\) _and the feature dimension_ \(d\) _satisfies_ \(d(C_{2} n)^{6L+2} n\)_._
3. _The condition number of the GNN encoder weight satisfies_ \[((W))^{2} n)^{3L}}}.\] (5)

_Then there exists a threshold \(=( n)^{2L}})\) such that with probability at least \(1-}\), the following holds for SERA with the similarity measure chosen either as cos or corr:_

\[}_{}()=0,\ }_{} () n)^{2L}}{n}.\] (6)

_Consequently, on the above set of events we have \(}_{} 1- n)^{2L}}{n}\)._

Theorem 4.1 implies that, even when SERA can not borrow strength from the homophily nature of the underlying graph, it is able to produce accurate reconstructions when the graph is sufficiently _large and sparse_, with the sparsity defined in the sense that each node has at most \(O( n)\) neighbors on average. An additional intriguing implication from theorem 4.1 pertains to the dependence of reconstruction performance on the GNN encoder depth \(L\): Provided that the node feature dimension is sufficiently large, the reconstruction performance degrades when the depth of the encoder increases, which is related to the renowned phenomenon of oversmoothing in GNN literature . Intuitively, as the depth of GNN encoders increases, the resulting node representations tend to converge , becoming less distinct from one another. This convergence diminishes the discriminative capacity of similarity metrics, thereby affecting the attack performance.

_Remark 4.2_ (Practicality).: Theorem 4.1 requires the node feature dimension \(d\) to grow in a \((n)\) rate, a condition which may not consistently align with practical scenarios. At present, this requirement is a byproduct of our proof strategy. In section 7.1 we will further examine the implications of feature dimensionality. The existence of a threshold that theorem 4.1 manifests might not guide the choice of threshold in practice. Instead, we may rely on heuristics or side-information  to determine the threshold. Furthermore, Theorem 4.1 posits that the efficacy of SERA is contingent upon a reasonable conditioned weight matrix \(W\). We will empirical validate this claim in section 7, wherein we demonstrate robust reconstruction capabilities of the SERA across diverse scenarios including when the weight matrix \(W\) is a fixed entity, when it is subject to random initialization, or when it has undergone extensive training iterations utilizing datasets from real-world supervised learning contexts.

## 5 SERA against dense SBMs

In this section, we reveal the limitation of SERA by constructing a reconstruction problem that is provably hard. We consider the following stochastic block model (SBM) , where each node is assigned a community membership from one of \(K\) groups \(k(v)[K]\). The \((u,v)\)-th entry of the adjacency matrix is generated as

\[A_{uv}(p),&k(u)=k(v)\\ (q),&.\] (7)

For ease of presentation, we further assume that the groups share the same size, i.e., \(n\) is a multiple of \(K\). Denote the generation mechanism as \(G_{}(n,K,p,q)\). We have the following result:

**Theorem 5.1**.: _Let \(G_{}(n,K,p,q)\) and \(p=(1)\). Assume the GNN encoder to be of depth \(L\) and feature dimension \(d\{ n/p^{2},K^{2}^{3}n\}\) with the weight matrix being the identity matrix. Then with probability at least \(1-1/n^{2}\), for any fixed \(\), one of the following three statements must hold for SERA with similarity measure chosen either as cos or corr:_1. \(}_{}()\) and \(}_{}()\).
2. \(}_{}()+\).
3. \(}_{}()+\).

According to theorem 5.1, given any cutoff threshold if the within-group connection probability is of the order \((1)\) and the number of groups \(K\) does not diverge (Otherwise, we will return to the sparse regime in section 4), the performance of SERA measured by error rate ERR is lower bounded by non-vanishing constants when the feature dimension is sufficiently large. The theorem characterizes the inherent limitations of SERA when the underlying graph is dense. As \(K\) gets large, the lower bound of false positive/negative rate decreases. It indicates that SERA is more successful when the graph is less connected.

_Remark 5.2_.: Alternatively, we may interpret theorem 5.1 as unveiling instances where SERA is constrained to revealing only population-level relational information--such as the affiliation of two nodes to a common group--rather than identifying the existence of specific edges when the underlying graph is dense and admits certain group structures.

## 6 Defense by noisy aggregation: From theory to practice

Having demonstrated the susceptibility of GNN representations to SERA, it becomes an intriguing research question to examine the behavior of SERA within the context of privacy-preserving GRL: In this section, we explore the defensive efficacy of noisy aggregation (NAG), which has been proposed recently as a provably privacy-preserving algorithm [30; 36] under the edge differential privacy model . Concretely, we study an \(L\)-layer noisy GNN with the \(l\)-th layer computed recursively as:

\[H_{v}^{(l)}=}(}(W_{l}H_{u}^{(l-1)}/\|H_{ u}^{(l-1)}\|_{2},u)+), N (0,^{2}I_{d}),\] (8)

where \(:=N(v)\{v\}\) denotes node \(v\)'s extended neighborhood and \(H_{v}^{(l)}\) denotes the representation of node \(v\) at the \(l\)-th layer. The aggregation mechanism AGG is a permutation invariant function that defines the message-passing process and Act is some (possibly) non-linear transform. Intuitively, the NAG methodology can be understood as a privatization protocol that incorporates both a normalization step and an additive Gaussian perturbation phase into the conventional message-passing framework, which typically forms the backbone of a GNN. In this paper, we consider \(5\) representative GNN architectures that allows NAG privatization: GCN , GAT , SAGE  with mean or max pooling, and GIN  with their formal definition deferred to appendix B.3. The following theorem characterizes the defensive capability of NAG:

**Theorem 6.1**.: _For any graph \(G\) and SERA under any type of similarity measures, the inference error regarding any specific edge is lower bounded by:_

\[_{u V,v V}[(_{uv}=1|A_{uv}=0) +(_{uv}=0|A_{uv}=1)] 1-\|W_{l}^{2}}{^{2}})}.\] (9)

_Here the constant \(C\) depends on the AGG mechanism of the GNN. In particular, for some standard GNN architectures we have: \(C_{}=C_{}}=C_{}}=1\) and \(C_{}}=C_{}}=4\)._

Theorem 6.1 augments existing literature in the sense that it extrapolates upon prior analyses [30; 36] by generalizing to a broader range of aggregation mechanisms, thereby encompassing the vast majority of foundational components integral to modern GNN models. Theorem 6.1 indicates that for _any_ node pairs in any graph, the summation of type-I error and type-II error (in the language of binary hypothesis testing ) incurred by _any_ SERA adversary is lower bounded by a constant, which will be significantly above zero when the noise scale is of the same order to the operator norms of the weight matrices of the GNN encoder. In fact, theorem 6.1 holds against a much stronger family of adversaries, which we discuss in appendix C.3.

**Empirical protection of NAG** implementing NAG with a large noise scale according to theorem 6.1 may seriously degrade model efficacy. Contemporary insights  suggest that strict adherence to theoretical prescriptions may not always be necessary, especially in the face of empirical adversaries whose capabilities may not rise to the level presumed by the defense mechanisms postulated. In this paper we conduct a careful empirical investigation to assess the privacy-utility trade-off of NAG, with privacy evaluated by the SERA adversary. This investigation could also provide empirical evidence of the SERA's viability as a tool for auditing private GRL algorithms . Furthermore, theorem 6.1 identifies a key determinant of the theoretical privacy bound for NAG --the relative scale of the weight norms regarding the noise intensity. In light of this observation, we propose two distinct noise-infused training paradigms:

**Unconstrained scheme** We choose a fixed noise scale \(\) during both training and inference no constraints over the weights. The resulting model might not produce meaningful privacy guarantees in the sense of theorem 6.1 as the operator norms of weights are determined by the training dynamics.

**Constrained scheme** We choose a fixed noise scale \(\) during both training and inference and use normalization techniques  to provide a priori control of model weights, thereby providing tighter control of formal privacy level according to theorem 6.1.

We will empirically inspect the protection of NAG representations trained via both unconstrained and constrained schemes against SERA in section 7.3.

_Remark 6.2_ (Alternative defenses).: Beyond the scope of NAG, alternative defense mechanisms offer demonstrable protection assurances, one notable example being edge-wise randomized response (EdgeRR). A comparison with such alternatives is reported in appendix D.5. Preliminary experimental comparisons indicate that NAG customarily realizes a more favorable balance between privacy and utility.

_Remark 6.3_ (Impact of depth \(L\)).: Theorem 6.1 posits that the privacy guarantees furnished by NAG diminishes with an increment in model depth, which is underpinned by the composition theorems of privacy analysis [12; 24]. An extensive discussion concerning the implications of GNN architectural design on the privacy-utility trade-off, particularly as it pertains to the depth of GNN models trained with NAG, will be provided in appendix E.

## 7 Experiments

In this section, comprehensive empirical studies are conducted to evaluate the effectiveness of SERA against both non-private and private node representations. By default, cos is employed as the standard measure of similarity across all experiments. The results corresponding to the use of corr as a metric were found to align with those obtained from cos, a concurrence that aligns with observations from . This investigation is oriented around three core research questions:

**RQ1 (Efficacy of SERA on Sparse Graphs):** We evaluate SERA on synthetic datasets generated according to theorem 4.1, in addition to \(8\) real-world datasets to substantiate the effectiveness of SERA.

**RQ2 (Deficiency of SERA on Dense Graphs):** We evaluate SERA on synthetic stochastic block models to corroborate the theoretical assertions in theorem 5.1.

**RQ3 (Mitigation of SERA through NAG):** We evaluate SERA on privacy-enhanced node representations across three benchmark datasets generated using NAG with varied levels of noise. The outcomes affirm NAG's capacity for privacy preservation while concurrently delineating the limitations of SERA as a tool for privacy auditing.

**Evaluation Metrics:** Predominantly, this section documents the performance of attacks using the AUROC metric. A more expansive presentation of the results, inclusive of both AUROC and ERR, is postponed to appendix D.

### Efficacy of SERA on sparse graphs

**Erdos-Renyi experiments** In our first experiment, we test SERA on graph representations produced by (1) over Erdos-Renyi graphs with edge probability \(p=\) with graph size \(n\{100,500,1000\}\), which is a representative random graph model with controllable sparsity level. We set the weight to be the identity matrix and further present results under random weights in appendix D.1. We vary the feature dimension \(d\{2^{j},2 j 11\}\) and network depth \(1 L 10\) in order to obtain a fine-grained assessment of SERA. We present the evaluations in figure 4. The results corroborate with our theoretical developments: We demonstrate that SERA is able to achieve near-perfect reconstruction of all edges _only_ in the "large \(d\), small \(L\)" regime. Notably, we find SERA to be less successful under relatively deep network architectures (i.e., \(L 5\)) when the feature dimension is sufficiently large. Yet the behaviors in small \(d\) regimes appear to be less predictable. 3 Furthermore, the influence of the feature dimension appears to be more pronounced than that of the network depth. This suggests that a greater number of features, despite their independence from graph topology, lead to potentially more privacy risks as transmitted through GNN representations. Conversely, augmenting the network depth does not necessarily correlate with an elevation in the success rate of SERA.

**Real-world data experiments** Given that the Erdos-Renyi model may not sufficiently capture the complexity of real-world graph structures, we evaluated the SERA algorithm on \(8\) diverse real-world graph datasets that exhibit contrasting patterns of feature similarity and edge formation. The analysis comprises the well-known Planetoid datasets , which are distinguished by their high homophily; the heterophilic datasets Squirrel, Chameleon, and Actor , which demonstrate a weak feature-edge correlation; and two larger-scale datasets, namely Amazon-Products  and Reddit . Dataset statistics are comprehensively detailed in appendix B.2. Half of the datasets analyzed manifest a strong positive correlation of feature similarity and edge presence, which is measured via the AUROC of the estimator \(_{uv}^{}()=((X_{u},X_{v} ))\), while the other half show negligible correlations, an observation underscored in the baseline (\(^{}\)) row of table 1. In all evaluations, we standardize the hidden dimension to \(d=128\), with the number of GNN layers adjusted to \(L 2,5\). Our analysis extends beyond the linear aggregation scheme (1) to encompass four additional prominent GNN architectures: GCN , GAT , GIN , and SAGE . To discern the effect of training dynamics on the potency of attacks, we delineate results for both pre-training (i.e., random initialization) and post-training stages. A precise account of training methodologies can be found in appendix D.2. Results pertaining to the linear GNN (LIN) and GCN are presented in table 1, with a comprehensive evaluation reserved for appendix D.2. We have the following observations:

**Homophily is not necessary for SERA to succeed:** The efficacy of SERA on the Planetoid datasets aligns with expectations. However, the outcomes from \(4\) heterophilic datasets illuminate significant privacy risks, despite a vacuous association between feature resemblance and edge formation. Notably, the Squirrel and Actor datasets, which demonstrate a mild negative feature-edge correlation, are still subject to substantial privacy breach, particularly with nonlinear models. These empirical findings support our theoretical assertion that a graph's sparsity plays a more pivotal role in its susceptibility to edge reconstruction attacks than the degree of homophily it exhibits. Moreover, in instances of

    & Squirrel & Chameleon & Actor & Cora & Citeseer & Pubmed & Products & Reddit \\  \(_{}\) & \(0.01\) & \(0.01\) & \(0.16\) & \(0.17\) & \(0.19\) & \(0.27\) & \(0.01\) & \(0.12\) \\  \(^{}\) & \(46.2\) & \(55.2\) & \(44.7\) & \(80.3\) & \(87.4\) & \(87.6\) & \(52.0\) & \(95.9\) \\  Victim model & ^{}\), non-trained} \\  LIN(\(L=2\)) & \(72.8_{ 0.0}\) & \(76.1_{ 0.2}\) & \(73.1_{ 0.1}\) & \(93.1_{ 0.4}\) & \(92.5_{ 0.9}\) & \(93.9_{ 1.2}\) & \(97.2_{ 0.3}\) & \(96.4_{ 0.1}\) \\ LIN(\(L=5\)) & \(72.6_{ 0.0}\) & \(76.0_{ 0.3}\) & \(73.0_{ 0.2}\) & \(95.9_{ 0.6}\) & \(93.8_{ 0.4}\) & \(96.0_{ 0.6}\) & \(99.2_{ 0.1}\) & \(95.4_{ 0.1}\) \\ GCN(\(L=2\)) & \(87.3_{ 0.3}\) & \(87.9_{ 0.4}\) & \(87.1_{ 0.6}\) & \(99.8_{ 0.1}\) & \(99.9_{ 0.0}\) & \(99.7_{ 0.0}\) & \(99.6_{ 0.0}\) & \(97.3_{ 0.1}\) \\ GCN(\(L=5\)) & \(82.1_{ 0.3}\) & \(84.3_{ 0.9}\) & \(84.1_{ 0.9}\) & \(99.4_{ 0.2}\) & \(99.9_{ 0.0}\) & \(99.5_{ 0.1}\) & \(99.2_{ 0.1}\) & \(96.1_{ 0.2}\) \\  Victim model & ^{}\), trained} \\  LIN(\(L=2\)) & \(74.6_{ 0.0}\) & \(75.0_{ 0.3}\) & \(59.9_{ 0.7}\) & \(94.6_{ 0.1}\) & \(93.7_{ 0.1}\) & \(89.0_{ 0.1}\) & \(91.6_{ 0.2}\) & \(94.7_{ 0.1}\) \\ LIN(\(L=5\)) & \(74.1_{ 0.3}\) & \(76.9_{ 0.2}\) & \(61.6_{ 0.7}\) & \(94.8_{ 0.3}\) & \(93.3_{ 0.3}\) & \(88.4_{ 0.9}\) & \(98.6_{ 0.1}\) & \(92.3_{ 0.2}\) \\ GCN(\(L=2\)) & \(79.4_{ 0.4}\) & \(82.3_{ 0.3}\) & \(78.5_{ 0.8}\) & \(97.8_{ 0.1}\) & \(99.0_{ 0.0}\) & \(89.2_{ 0.3}\) & \(94.5_{ 0.1}\) & \(95.1_{ 0.1}\) \\ GCN(\(L=5\)) & \(77.4_{ 0.6}\) & \(80.6_{ 0.8}\) & \(78.4_{ 0.6}\) & \(97.4_{ 0.3}\) & \(98.7_{ 0.2}\) & \(92.6_{ 0.4}\) & \(98.4_{ 0.1}\) & \(95.0_{ 0.1}\) \\   

Table 1: Performances of SERA on eight datasets measured by AUROC metric (%). The feature homophily \(_{}(G,X)=_{(u,v) E}(X_{u},X_{v})\) is an alternate measure of correlation between feature similarity and edge presence. For each setup, the results (in the form of mean\({}_{}\)) are obtained via \(5\) random trials.

comparatively denser networks, such as the Reddit dataset, the homophily of features can be exploited to mount more sophisticated attacks.

**Efficacy of Linear GNNs as Proxies for Nonlinear Counterparts:** Evidence presented in table 1 suggests that the trends exhibited by linear GNN models are broadly reflective of those displayed by their nonlinear, GCN equivalents. It is typically observed that the attack efficacy is modestly reduced in the linear GNN setting, with further details deferred to Appendix D.2.

**Influence of Network Depth and Training Dynamics:** Table 1 indicates that the post-training performance of SERA is frequently less effective compared to the scenarios with randomly initialized weights. This observation may be attributed to the notion that supervised training tends to adversely affect the conditioning of weight matrices relative to their initialized state. Additionally, augmenting model depth does not correspond with enhanced attack efficacy, an outcome that is in alignment with our theoretical predictions.

### Deficiency of SERA on dense graphs

**SBM experiments** In this section, we test SERA graph representations over SBM graphs with \(K=3,p=0.3,q=0.05\), with the rest of the experimental setups analogous to that in the Erdos-Renyi experiments. The evaluations are presented in figure 7. The results reveal the presence of a pronounced barrier that hinders the success of the attack across a wide range of configurations corresponding to different network depths and feature dimensions. Furthermore, we observe that the results tend to stabilize as the size of the graph increases. We provide a further study on the impact of SBM structure in appendix D.1.

### Mitigation of SERA through NAG

In this section, we empirically study the defensive performance of noisy aggregation (8) against SERA We will use the Planetoid datasets  for evaluation. We consider a transductive node classification setting and use the standard train-test splits. The GNN models are trained using the training labels and evaluated on the test nodes. The performances of SERA are evaluated on the subgraphs induced by the test nodes. We report the configuration of GNN encoding, as well as the attacking pipeline and training hyperparameters in appendix D.3.1. Due to space limits, we report results on the Cora dataset under GCN and GAT in the main text and postpone the complete report in appendix D.3. We use the following two types of training configurations as proposed in section 6:

**Under the unconstrained scheme**, we use aggressive perturbation plans by applying noise with scale range \(\{0,1,2,4\}\), with \(=0\) indicating no protection, and \(d\{2^{i},5 i 13\}\).

**Under the constrained scheme**, we adopt the spectral normalization technique  to control the spectral norm of each layer at approximately \(1\) (with relative error \(<10\%\)). We use conservative perturbation plans by applying noise with scale range \(\{0,0.01,0.05,0.1,0.5,1\}\), and \(d\{2^{i},5 i 13\}\). Note that with \(=1\), we obtain a non-vacuous lower bound according to (9). We present the evaluations in figure 2 and summarize our observations and findings as follows:

**SERA empirically elicits privacy-utility trade-off under the constrained scheme** When the noise level is moderate, i.e., \(\{0.01,0.05\}\). The result demonstrates that privacy and utility are, at least to some extent, at odds: Under lower noise level, SERA is able to achieve non-trivial success especially when \(d\) is small. Furthermore, raising the feature dimension \(d\) results in both a decrea

Figure 1: Attacking efficacy of SERA over sparse Erdős–Rényi graphs and dense SBM graphs, with performance measured in AUROC metric averaged over \(5\) random trials for each configuration.

in utility as well as an increase in privacy. This is actually predictable: Since we explicitly control the operator norm to be around \(1\), a larger \(d\) implies a smaller "signal-to-noise ratio" with the signal being (loosely) defined as the magnitude of the aggregated node representations.

**SERA losses power against NAG using larger \(d\)s in the unconstrained scheme** A surprising evidence according to figure 2 is that when the feature dimension \(d\) is sufficiently raised, i.e., \(d>1024\), the attacking performances degrade. Consequently, we are able to achieve decent protection against SERA (AUROC \(<0.6\)) while at the same time incurring slight degradation in model utility (\(>0.7\) Accuracy in Cora) Moreover, the phenomenon is more evident for higher noise levels. While the outcome seems favorable insofar as we have identified GNN solutions that manifest both high performance and a degree of privacy since the training procedure is unrelated to the attacking mechanism, these solutions may exhibit diminished robustness, as the corresponding Lipschitz constants are likely to be inadequately regulated . Due to space limits, we postpone a more detailed discussion to appendix D.4.

## 8 Discussion and conclusion

In this paper, we have studied the behavior of the SERA adversary by characterizing its performance against different kinds of underlying graph structures as well as encoding mechanisms. Theoretically, we first identify sparse random graphs where SERA provably reconstructs the input graph, which ascertains the empirical findings of previous works. We then reveal limitations of SERA by showing its performance lower bounds when the input graph follows a dense SBM. Additionally, we discuss protection mechanisms to SERA by exploiting both theoretically and empirically the defensive capability of NAG. Empirical investigations corroborate with our theoretical findings, while suggesting intriguing phenomenons that questions the viability of SERA as a formal privacy auditing procedure for private graph representations. Notwithstanding, several research problems warrant further study, which we discuss in appendix E alongside with the limitations of this paper.

Figure 2: Privacy and utility assessments on the Cora dataset with underlying model of NAG being GCN and GAT. The first row contains attack performances of SERA measured using AUROC metric under both constrained and unconstrained training scheme. The second row presents corresponding model performances.

Acknowledgements

The authors from Ant Group are supported by the Leading Innovative and Entrepreneur Team Introduction Program of Hangzhou (Grant No.TD2022005). Guanhua Fang is partly supported by the National Natural Science Foundation of China (nos. 12301376).