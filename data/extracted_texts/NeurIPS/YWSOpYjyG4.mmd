# Predicting a Protein's Stability

under a Million Mutations

 Jeffrey Ouyang-Zhang

UT Austin

jozhang@utexas.edu

&Daniel J. Diaz

UT Austin

danny.diaz@utexas.edu

&Adam R. Klivans

UT Austin

klivans@cs.utexas.edu

&Philipp Krahenbuhl

UT Austin

philkr@cs.utexas.edu

###### Abstract

Stabilizing proteins is a foundational step in protein engineering. However, the evolutionary pressure of all extant proteins makes identifying the scarce number of mutations that will improve thermodynamic stability challenging. Deep learning has recently emerged as a powerful tool for identifying promising mutations. Existing approaches, however, are computationally expensive, as the number of model inferences scales with the number of mutations queried. Our main contribution is a simple, parallel decoding algorithm. Our _Mutate Everything_ is capable of predicting the effect of all single and double mutations in one forward pass. It is even versatile enough to predict higher-order mutations with minimal computational overhead. We build our _Mutate Everything_ on top of ESM2 and AlphaFold, neither of which were trained to predict thermodynamic stability. We trained on the Mega-Scale cDNA proteolysis dataset and achieved state-of-the-art performance on single and higher-order mutations on S669, ProTherm, and ProteinGym datasets. Our code is available at https://github.com/jozhang97/MutateEverything.

## 1 Introduction

Protein engineering is the discipline of mutating a natural protein sequence to improve properties for industrial [5; 78] and pharmaceutical applications [2; 25; 41]. However, evolution simultaneously optimizes several properties of a protein within its native environment, resulting in proteins with marginal thermodynamic stability (\(\) 5-15 kcal/mol)  which become non-functional in an industrial setting. Therefore, repurposing a natural protein for biotechnological applications usually begins with identifying non-deleterious mutations that stabilize the structure. With a stabilized structure, downstream engineering goals, which often require exploring destabilizing mutations, become tractable. Historically, this process has been bottlenecked by the requirements of extensive laboratory characterization of rational designs [33; 79] or directed evolution libraries [4; 12; 21; 22]. The recent explosion in biological data [9; 29; 72; 73] has enabled deep learning frameworks to accelerate the identification of stabilizing mutations. A successfully stabilized protein often requires several mutations. However, current frameworks do not take into account epistatic interactions between multiple mutations. Thus, to significantly accelerate protein engineering, it is critical to efficiently navigate the epistatic landscape of higher-order mutations [10; 69]. However, due to its combinatorial nature, thorough exploration quickly becomes computationally prohibitive.

In this paper, we introduce _Mutate Everything_ to directly predict changes in thermodynamic stability (\( G\)) for all single and higher-order mutations jointly. _Mutate Everything_ is a parallel decoding algorithm that works in conjunction with a sequence model for predicting thermodynamic stability.

Prior models for predicting thermodynamic stability work by producing an embedding or representation of the input sequence. Our decoder takes this representation and uses a linear network to create further representations, one for every possible single mutation. These mutation-level representations are then further aggregated to form representations for higher-order mutations. We feed these higher-order representations into a lightweight multi-layer perception (MLP) head to output predicted \( G\) measurements. Since the mutation-level representations are computed only once, we are able to scale to millions of (higher-order) mutations, as the aggregation and MLP-head computations are inexpensive. As such, given a fixed computational budget, our model evaluates millions more potential mutations than prior methods.

_Mutate Everything_ estimates the effects of all single and double mutations for a single protein in seconds on one GPU. This can efficiently compute the stability of _all_ single and double mutants across _all_\(\)20,000 proteins in the human proteome within a short time frame. To the best of our knowledge, _Mutate Everything_ is the first tool that renders the computational analysis of double mutants across the entire proteome tractable. _Mutate Everything_ can be used in conjunction with any model that generates representations for protein sequences. In this paper, we use AlphaFold  as a backbone architecture and fine-tune it on a dataset labeled by experimentally derived \( G\) measurements. This results in the first accurate model of stability prediction based on AlphaFold.

We evaluate the performance of our _Mutate Everything_ on well-established benchmarks for predicting experimentally-validated \( G\) measurements of mutations: ProTherm , S669 , and ProteinGym . On ProTherm high-order mutations (PTMul), our model achieves a Spearman of 0.53, compared to 0.50 in the next best method. On S669 single mutations, our model achieves a Spearman of 0.56, outperforming the state-of-the-art at 0.53. On ProteinGym, the _Mutate Everything_ outperforms state-of-the-art methods from 0.48 to 0.49. Our model makes finding the most stabilizing double mutations computationally tractable. We show on the double mutant subset of the cDNA-proteolysis dataset (cDNA2) , where only 3% of known mutations are stabilizing, that _Mutate Everything_ effectively ranks stabilizing mutations ahead of destabilizing ones.

## 2 Related Works

### Protein Engineering

Protein engineering is the process of mutating a natural protein to improve particular phenotypes, such as thermodynamic stability and function. The field has historically relied on rational design and stochastic methods, such as error-prone PCR , DNA shuffling , and directed evolution (DE) , to identify gain-of-function mutations. Rational design is limited to proteins with solved structures and requires an extensive understanding of biochemistry and specific knowledge of the particular protein to select mutations highly likely to improve the target phenotypes . Directed evolution requires little to no knowledge of the protein and instead generates a library of protein variants that are then screened for the target phenotypes (e.g. fluorescence brightness, antibiotic

Figure 1: _Mutate Everything_ efficiently predicts \( G\), the change in thermodynamic stability of folding, for over a million mutations (e.g. all single, double mutations) in a single inference step. This helps identify and prioritize stabilizing mutations (\( G<0\)) in protein engineering efforts. The notation for a mutation is \(AA_{from}\), pos, \(AA_{to}\) (e.g. “P1K” mutates from P to K at position 1)

resistance, stability, activity) [4; 27]. The library can be generated via site-saturated mutagenesis of a handful of positions in the sequence  or DNA shuffling, in which the gene is digested into random fragments and reassembled into full-length sequences . After screening the library, the most "fit" variant is then selected as the initial sequence for the next round of directed evolution. This iterative process repeats until it obtains a protein variant with the desired phenotypes.

Machine learning has demonstrated its ability to augment rational design and accelerate the stabilization of a variety of proteins [20; 28; 40; 52; 68]. Separately, machine learning-guided directed evolution (MLDE) has been shown to improve the likelihood of obtaining the global fitness maximum by 81-fold compared to traditional DE . MLDE has accelerated the engineering of several proteins, such as the enantioselectivity of enzymes for kinetic resolution of epoxides  and the activity and expression of a glutathione transferase . _Mutate Everything_ empowers the experimentalist to accelerate the stabilization of a protein for both rational design and MLDE.

### Machine Learning for Protein Structure Prediction

Recent advances in machine learning have led to remarkable progress in protein structure prediction. AlphaFold  has demonstrated that deep learning is highly effective at predicting protein structures from a sequence by using evolutionary history via a multiple sequence alignment (MSA). AlphaFold passes the MSA and a pairwise representation of the sequence into Evoformer to capture the co-evolutionary patterns between residues. The Evoformer output is then processed by the Structure Module, which predicts the protein's structure. We challenge prior works postulating that AlphaFold cannot be used for stability prediction and show that fine-tuning these rich co-evolutionary and structural features yield highly performant stability predictors .

Evolutionary Scale Modeling (ESM) [38; 62] has shown that protein structure prediction can be performed without MSAs and specialized architectures by leveraging large transformers pre-trained on masked token prediction. Other works extended this masked pre-training framework, including MSA-Transformer  which incorporates a sequence's MSA as input, and Tranception , which develops a hybrid convolution and attention based autoregressive architecture. We show that fine-tuning these evolutionary representations excels at protein stability assessment without MSAs.

### Protein Stability Assessment

Traditional approaches to protein stability assessment relied on a combination of physics-based methods, statistical analysis, and traditional machine learning techniques. Physics-based tools, such as FoldX, Rosetta, and SDM, utilize energy functions and statistical patterns to assess how mutations affect a protein's stability [32; 67; 77]. DDGun  directly inferred \( G\) from heuristics, including Blosum substitution scores, differences in interaction energy with neighboring residues, and changes in hydrophobicity. Many traditional machine learning approaches used support vector machines and decision trees with physics-based feature engineering [11; 14; 15; 17; 37; 66]. Others ensemble existing machine learning methods [35; 56; 59; 63; 64].

Recently, deep learning-based approaches have recently begun to outperform existing physics and traditional machine learning approaches [13; 19; 34]. ACDC-NN  trains an asymmetric convolutional neural network for predicting forward and reverse mutation effects. Thermonet  voxelizes and feeds both the wild-type and mutant protein structures into a 3D-CNN to regress a \( G\) value. PROSTATA feeds the wild-type and mutant protein sequence into a pre-trained ESM2 model and then regresses a \( G\) value . Stability Oracle takes the native and mutant amino acid type along with the local structure as input and regresses \( G\). Several deep learning frameworks [64; 80; 81] model multiple mutations in addition to single mutations. In this paper, we develop a framework that models the protein to enable efficient enumeration of all mutation candidates.

## 3 Preliminary

**Problem Setup.** A protein \(w=(w_{1},...,w_{L})\) is a sequence of amino acids \(w_{l} AA\), where \(AA=\{A,C,...,Y\}\) are the 20 different amino acid types encoded by genetic information. Let \(=(p,t)\) denote a mutation substituting the amino acid \(w_{p}\) at position \(p[1,...,L]\) to amino acid type \(t AA\). Our goal is to determine the change in thermodynamic stability \( G\) for a protein \(w\) under a large number of mutation sets \((M_{1},...,M_{N})\) where a mutation set \(M_{i}=\{_{k}\}_{k=1}^{K_{i}}\).

The mutation sets include higher-order mutations (\(K>1\)), which is beyond the scope of state-of-the-art single mutation predictors (\(K=1\)) [18; 36; 74]. These higher-order mutations are strictly more challenging than single mutations. The model must understand the effect of each single mutation and also the epistatic interactions that arise between individual mutations. We introduce a method that captures these interactions for any mutation set and decodes a corresponding \( G\).

Furthermore, existing paradigms cannot efficiently scale to a large number of mutations. Higher-order mutation models [16; 35; 44; 64] take a protein and its mutant as input and predict the change in stability. These methods would need to enumerate and sort over a million model evaluations to find the most stabilizing mutations for a small protein of 75 amino acids. Our model runs a fine-tuned backbone only once and a lightweight decoder once for each mutation in parallel.

**Feature Extraction.** We fine-tune AlphaFold and other pre-trained models to alleviate the scarcity of labeled data. AlphaFold's Evoformer learns co-evolutionary patterns, such as residue interactions, and the Structure Module learns structural information, such as solvent accessibility or residue-residue distance. We demonstrate this is connected to a protein's stability and how mutations affect stability.

Each element of the protein sequence is tokenized by its amino acid type \(w_{l}\) and positionally encoded. This produces a set of high-dimensional tokens for the transformer to take as input. The tokens are fed into a pre-trained model, which extracts per-position features \((x_{l})_{l=1}^{L}\) where \(x_{l}^{d}\). The transformer feature extractor is finetuned with our training objective. This is illustrated in Figure 1(a).

## 4 Methodology

Our model uses per-position features \((x_{l})_{l=1}^{L}\) to determine the stability of a mutation set \(M\). We distinguish between single point mutations \(K=|M|=1\), and higher-order mutations \(K>1\).

Both single and higher-order mutations share the same backbone architecture and encoding scheme, see Figure 1(b). For each mutation \(=(p,t)\) at position \(p\) to amino acid \(t\), we compute a latent mutation representation \(z()^{d}\), which captures the effect of the mutation on the protein. We decompose the mutation representation \(z()=f^{t}(x_{p})+h^{t}\), where sequence-dependent features \(f^{t}\{f^{A},...,f^{Y}\}\) project the per-position feature according to the mutated amino acid type, and sequence-independent features \(h^{t}\{h^{A},...h^{Y}\}\) are embeddings unique to the amino acid types \(A,C,...,Y\). Intuitively, \(f^{t}\) captures a contextualized feature at the position, and \(h^{t}\) captures information about the mutated amino acid type. This mutation representation builds up a feature representing the amino acid substitution.

**Decoding single mutations.** Figure 1(b) illustrates single mutation decoding. The change in thermodynamic stability \( G\) for a single mutation \(\) is read out from its mutation representation \(z()\). A lightweight linear head \(g^{1}:^{d}\) decodes this representation into the change in thermodynamic stability: \( G^{pr}=g(z())\).

Figure 2: **Mutate Everything decodes any mutation. The model takes a protein sequence of length \(L\) as input. (a) A pre-trained feature extractor (e.g. ESM , AlphaFold ) computes per-position features for each amino acid in the sequence (yellow). Each token is reshaped by an MLP into an array of all possible mutations at that location. (b) A single mutation is directly decoded to its \( G\). (c) For a mutation set containing multiple mutations, selected mutations are aggregated and decoded to obtain a predicted \( G\).**

**Decoding higher-order mutations.** Figure 2c illustrates higher-order mutation decoding. The \( G\) for a higher-order mutation \(M=\{_{k}\}_{k=1}^{K}\) is read out from its \(K\) corresponding single point mutation representations \(\{z(_{k})\}_{k=1}^{K}\). _Mutate Everything_ aggregates the representations for each single point mutation within a higher-order mutation. By aggregating the single mutations in the latent space, the model learns to account for the interactions between them. We aggregate with summation for its simplicity. A lightweight head \(g:^{d}\) then decodes the higher-order mutation \( G^{pr}=g(_{k}z(_{k}))\). This formulation allows us to seamlessly parameterize any higher-order mutation. For higher-order mutations (e.g. \(K>1\)), we empirically find that it is beneficial to predict the residual to the sum of single mutation \( G\)s from our single mutation decoder (see Table 5d).

**Decoding a million mutations in one forward pass.** This decoding scheme efficiently compute \( G\) for _millions_ of mutations, whether single or higher-order (see Figure 3). Our insight is to precompute all mutation features and reuse them for all predictions. First, we compute all \(L{}20\) mutation representations \(Z=\{z((p,t)):p[1,...,L],t AA\}\). This expands each token \(x_{l}\) to 20 representations that each capture the effect of mutating to one specific amino acid (including the wild-type amino acid). The backbone and this expansion are executed once for a protein sequence.

A lightweight head decodes \( G\) for any higher-order mutation (a mutation set). For each mutation set, we index and add the relevant mutation representations in \(Z\). Index and sum operations are parallelized with outer-summation for \(K=2\) and the "gather" operation for \(K>2\). Finally, the lightweight decoder \(g\) computes the \( G\) for each mutation set in parallel.

**Training.** Our model is fine-tuned using supervised learning. We optimize the Huber loss.

\[(w,(M_{i}, G_{i}^{exp})_{i=1}^{N})=_{i=1 }^{N}|| G^{pr}(w,M_{i})- G_{i}^{exp}||_{H}\] (1)

where \(w\) is a protein sequence and \((M_{i}, G_{i}^{exp})_{i=1}^{N}\) are the mutation sets for this protein with experimentally validated \( G\). This approach efficiently backpropagates the loss through _all_ labeled mutations for a given protein in a single pass, unlike prior work which backpropagates through only one mutation in a single pass. We train on single and double mutants with on average 2000 mutations for each protein. When training on double mutants, we learn the residual to the sum of the experimental (ground truth) \( G\) for the constituent single mutations. Note that we use the _experimental_\( G\) of the single mutants to train double mutants but during testing, we use the model's _predicted_\( G\) of the single mutants to infer double mutant \( G\). Thus, we do not need experimental data for single effects to predict combined effects.

Only 3% of the double mutants in our training set are stabilizing (\( G\) < -0.5 kcal/mol ). To improve our performance on stabilizing mutations, we subsample the number of destabilizing double mutations to at most \(8\) times the number of stabilizing double mutations.

Figure 3: **Mutate Everything decodes many mutations.** Each token output by the backbone \(x_{l}\) is expanded to \(20\) tokens \(z()\), each corresponding to one unique amino acid type (yellow with amino acid types). For each mutation set \(M\), we first aggregate the features corresponding to each mutation’s position and amino acid being mutated to (arrows). A lightweight head \(g\) then decodes the aggregated features to obtain the predicted \( G\). These heads are illustrated in Figure 2b and Figure 2c. Parallel feature aggregation and decoding enable efficient stability prediction for millions of mutations.

## 5 Results

### Implementation Details

Our primary feature extractor is AlphaFold, implemented in OpenFold [3; 31]. The multiple sequence alignment (MSA) is computed using Colabfold . Sequence features from the Evoformer and Structure Module are aggregated as input to the decoder. An adapter maps the backbone hidden dimension to \(D=128\). Our amino acid projections and single mutation decoders are implemented with a linear layer. The higher-order mutation decoder transforms the previous embedding with a 2-layer MLP. These representations are aggregated and fed into a 3-layer MLP to predict \( G\).

We train on the **cDNA** display proteolysis dataset , which leverages a high throughput proteolysis screen enabled by next generation sequencing (NGS) to extract noisy \( G\) values for 100 mini-proteins totaling over 100,000 single and double mutations. To evaluate generalization on unseen proteins, we remove proteins from our training set that have high sequence similarity using MMSeqs2  to any protein in our evaluation benchmarks. The short protein lengths (\(<100\) amino acids) keep the memory requirement small for the higher-order decoder. See Section A.1 for more information about **cDNA** and other datasets.

We fine-tune a pre-trained backbone on single mutations for \(20\) epochs. Then, we finetune the model on both single and double mutations for \(100\) epochs using a cosine learning rate schedule with \(10\) warmup epochs. We use a batch size of \(3\) proteins due to the high memory requirements of AlphaFold. We use a learning rate of \(3 10^{-4}\) and weight decay of \(0.5\). Training takes 6 hours on 3 A100 GPUs.

### Finding Stabilizing Double Mutations

We evaluate our model's ability to find the stabilizing mutations on cDNA2. **cDNA2** is our validation split of the cDNA double mutations dataset, consisting of 18 mini-proteins totaling 22,000 double mutations. The proteins in the validation set have at most 36% homology with those in the cDNA training set. Of these mutations, only 198 or 0.8% are stabilizing with \( G<-0.5\) kcal/mol . Like protein engineering, this scenario closely resembles the challenge of identifying a small number of stabilizing mutations amidst a much larger pool of destabilizing or neutral mutations.

We evaluate different methods on _stabilizing_ mutations in Table 1. Stabilizing \(_{s}\) is the Spearman coefficient on the experimentally stabilizing subset introduced in . Normalized discounted cumulative gain (nDCG)  measures the quality of the ranked mutation list by taking into account its experimentally validated \( G\) and position in the list . Detection Precision (DetPr) is the proportion of experimentally validated stabilizing mutations among the top \(K=30\) predictions. We adapt previous state-of-the-art single mutation predictors by naively adding both single mutation predictions. A detailed description of the metrics is found in Section A.2.

Our model demonstrates exceptional performance in prioritizing stabilizing double mutations over destabilizing ones, achieving a significantly higher normalized discounted cumulative gain of 0.43 compared to 0.25, as well as a superior detection precision of 0.16 compared to 0.10. Our model additionally improves classification metrics Matthews Correlation Coefficient (MCC) and Area under Precision-Recall Curve (AUC) by 0.02 and 0.03, respectively.

   Method & Stabilizing \(_{s}\) & nDCG & DetPr & AUC & MCC \\  Mean & 0.00 & 0.02 & 0.03 & 0.50 & 0.00 \\ MSA & 0.04 & 0.06 & 0.02 & 0.60 & 0.01 \\ ESM2  & 0.04 & 0.08 & 0.02 & 0.65 & 0.00 \\ PROSTATA  (Additive) & 0.08 & 0.15 & 0.05 & 0.75 & 0.05 \\  _Mutate Everything_ (Additive) & 0.08(0.03) & 0.25(0.01) & 0.10(0.01) & 0.81(0.01) & 0.25(0.02) \\ _Mutate Everything_ (Ours) & **0.14**(0.02) & **0.43**(0.02) & **0.16**(0.01) & **0.84**(0.01) & **0.27**(0.01) \\   

Table 1: **Stabilizing Double Mutation Results on cDNA2.** The metrics evaluate the model’s performance on stabilizing mutations. Our additive baseline naively adds predicted single mutation \( G\)s. Our model is state-of-the-art at finding stabilizing mutations. The proteins in cDNA2 val have at most 36% sequence similarity to those in the training set. Parenthesis indicates standard error across 7 training runs.

To the best of our knowledge, _Mutate Everything_ is the first work that models all double mutations in a computationally tractable manner. Figure 4 shows the runtime of several methods on a protein of 317 amino acids on an A100 GPU. The dashed line indicates the transition from evaluating single mutants to double mutants. _Mutate Everything_ predicts \( G\) for all single and double mutations in one pass of the model. It runs in 0.6 seconds using an ESM2 backbone, and 12.1 seconds on an AlphaFold backbone. PROSTATA  also uses the ESM2 backbone but takes a protein sequence and its mutated sequence as input and outputs the change in stability. PROSTATA takes 306 hours to evaluate all double mutations with a batch size of 768. On an 8 GPU node, this will take 1.5 days.

### Higher-order Mutation Results

We evaluate our model for predicting changes in thermodynamic stability for higher-order mutations in ProTherm. ProTherm is a database of thermodynamic (\( G\)) and thermostability (\( T_{m}\)) experimental characterization of protein mutations curated from the literature. We consider a subset of this database that contains \( G\) values for higher-order mutations, named ProTherm Multiple (**PTMul**). PTMul contains 858 mutations . We keep 846 experimentally validated \( G\) for higher-order mutants, including 536 doubles and 183 triples, after removing 4 duplicate and 8 ambiguous mutations. PTMul proteins have at most 35% homology to the proteins used in training.

Table 2 shows our results on PTMul. A description of baselines is provided in Section A.3. Our additive baselines naively add the sum of single mutation \( G\)s. This baseline rigorously evaluates our model's ability to learn epistasis, or the non-additive interactions when combining two mutations. Mean always predicts the global test dataset mean statistic. ESM and MSA perform poorly when comparing mutations across proteins. On ProTherm, _Mutate Everything_ achieves the state-of-the-art performance of 0.53 Spearman correlation \(r_{s}\), compared to 0.50 of our additive baseline. A breakdown of PTMul performance on double mutations and more (\(>2\)) mutations is found in Table 6.

While other methods also handle multiple mutations, they usually adopt a mutation- or protein-level train and test split. This results in data leakage since the same protein or a homolog will have mutations in both the training and testing sets, leading to inflated reported metrics [16; 18; 35; 64]. In our study, we use sequence similarity-based splitting where our training proteins have at most 35% homology to those in PTMul. To fairly evaluate generalization to new proteins, we exclude these inflated comparisons from our study.

   Method & r\({}_{s}\) & AUC & MCC & RMSE \({}_{}\) & Stabilizing r\({}_{s}\) \\  Mean (cDNA) & 0.00 & 0.50 & 0.00 & 2.42 & 0.00 \\ Mean (ProTherm) & 0.00 & 0.50 & 0.00 & 2.26 & 0.00 \\ MSA & 0.07 & 0.51 & -0.05 & N/A & 0.02 \\ ESM2  & 0.05 & 0.51 & 0.04 & N/A & -0.01 \\ FoldX  & 0.41 & - & - & 2.95 & - \\ DDGun  & 0.25 & 0.63 & 0.16 & 2.21 & 0.17 \\ DDGun3D  & 0.26 & 0.64 & 0.18 & 2.24 & 0.17 \\ PROSTATA  (Additive) & 0.21 & 0.60 & 0.05 & 2.25 & 0.00 \\  _Mutate Everything_ (Additive) & 0.50(0.02) & 0.76(0.01) & 0.37(0.02) & **2.02**(0.03) & 0.20(0.01) \\ _Mutate Everything_ (Ours) & **0.53**(0.01) & **0.78**(0.01) & **0.43**(0.01) & 2.04(0.01) & **0.19**(0.01) \\   

Table 2: **Multiple Mutation Results on PTMul.** Our additive baseline naively adds predicted single mutation \( G\)s. Our model presents a strong mutation assessor. The proteins in PTMul have at most 35% sequence similarity to those in the training set. Parenthesis is standard error across 7 runs.

Figure 4: **Runtime analysis. Our model’s runtime is constant.**

### Single Mutation Results

We additionally validate our model's ability to predict changes in thermodynamic stability under single mutations. We compare _Mutate Everything_ to prior works on the newly introduced **S669** dataset, which was established to address the data leakage issue and enable fair comparisons between existing methods . We also evaluate the commonly studied reverse dataset setting, in which the model takes the mutant sequence as input and predicts \( G\) for mutating back to the wild-type sequence. The experimental value is obtained by negating the original \( G\) value going from the wild-type sequence to the mutant sequence. S669 is well curated and extensive, containing 94 proteins totaling 669 mutations . S669 proteins have at most 30% sequence similarity with those in our training set to ensure separation between the training and validation sets.

Table 3 shows our comparisons with prior works. _Mutate Everything_ is state-of-the-art on S669, achieving a Spearman correlation of 0.56, where the prior art obtained 0.53. _Mutate Everything_ outperforms the existing sequence model by a large margin, with a 6-point gain on Spearman correlation and a 3-point improvement on AUC. Our method is even as powerful as the latest structure-based methods which have access to atom coordinates.

_Mutate Everything_ is competitive on the reverse dataset evaluation, in which the original and mutated sequences are flipped and \( G\) negated. Our performance drops on reverse mutations because reverse mutations are out of distribution for our model. We did not perform data augmentation to train on reversed mutations as commonly done in the literature [18; 36; 74]. We found that it was beneficial to bias our reverse predictions using \( G\) to the amino acid found in the original sequence. We found the performance to be similar across 5 runs (\(<0.01\) standard error).

    &  &  \\ Method & r\({}_{s}\) & AUC & MCC & RMSE \({}_{}\) & r\({}_{s}\) & AUC & MCC & RMSE \({}_{}\) \\   \\ mCSM  & 0.37 & 0.66 & 0.13 & 1.53 & 0.24 & 0.61 & 0.10 & 2.33 \\ I-Mutant3.0  & 0.35 & 0.64 & 0.08 & 1.53 & 0.17 & 0.59 & 0.06 & 2.35 \\ DUET  & 0.42 & 0.68 & 0.19 & 1.52 & 0.26 & 0.63 & 0.12 & 2.16 \\ FoldX  & 0.27 & 0.62 & 0.14 & 2.35 & 0.32 & 0.67 & 0.20 & 2.54 \\ MAESTRO  & 0.46 & 0.69 & 0.26 & 1.45 & 0.22 & 0.61 & 0.11 & 2.12 \\ PopMusic  & 0.42 & 0.69 & 0.22 & 1.51 & 0.24 & 0.62 & 0.12 & 2.10 \\ SDM  & 0.39 & 0.67 & 0.21 & 1.67 & 0.14 & 0.59 & 0.12 & 2.15 \\ INPS3D  & 0.44 & 0.70 & 0.20 & 1.49 & 0.36 & 0.69 & 0.23 & 1.78 \\ Dynamant  & 0.38 & 0.68 & 0.20 & 1.59 & 0.37 & 0.67 & 0.17 & 1.69 \\ ThermoNet  & 0.38 & 0.69 & 0.21 & 1.62 & 0.35 & 0.66 & 0.18 & 1.66 \\ PremPS  & 0.42 & 0.66 & 0.20 & 1.50 & 0.43 & 0.66 & 0.22 & 1.49 \\ DDGun3D  & 0.43 & 0.71 & 0.27 & 1.60 & 0.41 & 0.71 & 0.23 & 1.61 \\ ACDC-NN  & 0.46 & 0.73 & 0.23 & 1.49 & 0.45 & 0.72 & 0.22 & 1.50 \\ Stability Oracle  & **0.53** & **0.75** & **0.34** & **1.44** & **0.53** & **0.75** & **0.32** & **1.43** \\   \\ MuPro  & 0.27 & 0.61 & 0.03 & 1.60 & 0.22 & 0.64 & 0.08 & 2.41 \\ I-Mutant3.0-Seq  & 0.34 & 0.67 & 0.25 & 1.54 & 0.23 & 0.61 & 0.05 & 2.25 \\ DDGun  & 0.43 & 0.72 & 0.24 & 1.73 & 0.41 & 0.71 & 0.23 & 1.76 \\ ACDC-NN-Seq  & 0.44 & 0.72 & 0.26 & 1.52 & 0.44 & 0.72 & 0.23 & 1.52 \\ INPS-Seq  & 0.44 & 0.72 & 0.25 & 1.52 & 0.44 & 0.72 & 0.21 & 1.53 \\ PROSTATA  & 0.50 & 0.73 & 0.28 & 1.44 & **0.50** & **0.73** & 0.29 & **1.44** \\ _Mutate Everything_ (Ours) & **0.56** & **0.76** & **0.35** & **1.38** & 0.49 & **0.73** & **0.30** & 1.48 \\   

Table 3: **Comparisons on Single Mutation Thermodynamic Stability prediction in S669. We report regression and classification metrics on the forward and reverse datasets for structure-based approaches (top block) and sequence-based approaches (bottom block). r refers to Spearman correlation coefficient. Our training proteins have at most 30% sequence similarity with those in S669. _Mutate Everything_ is state-of-the-art on S669 forward.**

### Generalization to other Phenotypes

We show that stability predictors generalize to other phenotypes as well. **ProteinGym** substitutions is a dataset of 87 proteins with 1.6 million mutation sets labeled with a generic fitness score, such as activity, growth, or expression. The mutation sets have up to 20 substitutions and 14 proteins contain higher-order mutations. The ProteinGym-Stability split contains 7 proteins and 26,000 mutations with fitness labels that are known to correlate with thermodynamic stability (thermostability, abundance, expression). ProteinGym proteins have at most 45% sequence similarity with those in our training set. Due to memory constraints, we truncate proteins to at most 2000 amino acids.

Table 4 compares our work with previous works. Our MSA baseline uses the empirical amino acid distribution in the MSA at a given position to compute a likelihood ratio. The MSA retrieval prior weights the scores using the per-position first-order statistics in a multiple sequence alignment. On ProteinGym-Stability, _Mutate Everything_ obtains a Spearman correlation of 0.52, compared to 0.50 of the next best method, TranceptEVE. On the one protein with labeled stability, _Mutate Everything_ obtains 0.51 vs 0.33 of Tranception with MSA retrieval . On the full ProteinGym benchmark, we outperform the strongest methods by ensembling our predictions with Tranception . Ensembling our method with evolutionary models by averaging scores gains 0.11 points on ProteinGym and 0.01 points on ProteinGym-Stability, suggesting that our model learns complementary information to the evolutionary models. For comparison, TransEVE ensembles an evolutionary model (Transception) and a family-based model (EVE) for a 0.03 point gain . We found the performance to be similar across 5 runs (\(<0.01\) standard error). An in-depth study on how protein stability related to function can be found in .

### Ablation Studies

We ablate several architectural design choices in Table 5. Core architectural designs are evaluated on S669. Architectural designs for only multiple mutations are evaluated on cDNA2.

**Backbone.** We analyze the effect of different feature extractors on single mutation stability assessment in Table 5a. ESM2  takes only sequence as input whereas MSA-Transformer  and AlphaFold  take the sequence and its MSA as input. Both ESM2 and MSA-Transformer are trained on masking residue modeling while AlphaFold is also trained on structure prediction. MSA input improves the stability prediction performance and AlphaFold's architecture and training further improve stability prediction.

    &  &  \\ Model & r\({}_{s}\) & AUC & MCC & r\({}_{s}\) & AUC & MCC \\  DeepSequence  & 0.44 & 0.74 & 0.34 & 0.43 & 0.74 & 0.35 \\ EVE  & 0.47 & 0.75 & 0.36 & 0.46 & 0.76 & 0.36 \\ ESM1v  & 0.41 & 0.72 & 0.31 & 0.41 & 0.74 & 0.33 \\ Progen2  & 0.45 & 0.74 & 0.35 & 0.42 & 0.74 & 0.34 \\ MSA Transformer  & 0.50 & 0.77 & 0.38 & 0.44 & 0.75 & 0.35 \\  Tranception  & 0.40 & 0.71 & 0.31 & 0.40 & 0.73 & 0.32 \\ Tranception+MSA & 0.45 & 0.74 & 0.35 & 0.45 & 0.76 & 0.36 \\ TranceptEVE  & 0.50 & 0.77 & 0.38 & 0.48 & 0.77 & 0.38 \\  MSA & 0.41 & 0.72 & 0.32 & 0.39 & 0.72 & 0.31 \\ _Mutate Everything_ & 0.52 & 0.78 & 0.39 & 0.38 & 0.72 & 0.30 \\ _Mutate Everything_ +MSA & 0.52 & 0.78 & 0.41 & 0.44 & 0.75 & 0.36 \\ _Mutate Everything_ +MSA+Transception & **0.53** & **0.79** & **0.42** & **0.49** & **0.78** & **0.39** \\   

Table 4: **Comparisons on mutation fitness prediction in ProteinGym.** We report ranking and classification metrics on both a subset of ProteinGym with stability-like phenotypes and the entire ProteinGym dataset. Our stability model can generalize to all phenotypes, outperforming existing methods on stability-like phenotypes and performing similarly to existing methods otherwise. The maximum homology between our training set and ProteinGym proteins is 43%.

**Backbone Optimization** We try fine-tuning and freezing the AlphaFold backbone during stability fine-tuning in Table 4(c). We find that fine-tuning the backbone improves stability prediction performance.

**Aggregation** The technique to aggregate mutation representations for higher-order mutations is ablated in Table 4(b). To control for feature dimension size, we reduce the head dimension when aggregating with outer product and flattening. Aggregating with product and summation performs similarly on double mutations. We add the features for a natural extension to more mutations.

**Higher Order Modeling** In the direct prediction model, the multi-mutant head directly predicts \( G\). In the multiply and add models, the multi-mutant head learns how interactions among single mutations affect the higher-order mutation's \( G\). In these models, the multi-mutant head output learns an additive bias or multiplicative scaling to the sum of single mutation \( G\)s. In Table 4(d), we show that learning a bias performs the strongest among these three options.

## 6 Limitations

First, our training dataset contains biases that may affect model performance. The training set contains only small proteins, which may limit performance on larger ones. Our model may exhibit biases towards certain types of mutations due to the data imbalance in our training set. Second, the limited availability of experimental stability data poses a challenge for in-silico evaluation. Evaluation on larger and more diverse datasets is necessary to fully assess the generalizability of our model. In the future, we hope that high-throughput experimental assays will enable more rigorous evaluation and further improvements in protein stability prediction.

## 7 Conclusion

We present a method that efficiently scales thermodynamic stability prediction from single mutations to higher-order mutations. Our key insight is that the effects of mutations on the same protein are correlated. Thus, for a target protein, it suffices to run a deep backbone once and decode the effect of all mutations simultaneously using a shallow decoder. With the AlphaFold model as our backbone, our method outperforms existing methods on a variety of single and multiple mutation benchmarks. Our method scales to millions of mutations with minimal computational overhead and runs in a fraction of the time it would take prior works.

## 8 Acknowledgements

This work is supported by the NSF AI Institute for Foundations of Machine Learning (IFML).

Table 5: _Mutate Everything ablation experiments. Default Settings are marked in grey._