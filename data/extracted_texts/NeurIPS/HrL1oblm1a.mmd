# Assessor360: Multi-sequence Network for Blind Omnidirectional Image Quality Assessment

Tianhe Wu\({}^{1}\), Shuwei Shi\({}^{1,2,}\), Haoming Cai\({}^{3}\), Mingdeng Cao\({}^{2}\),

Jing Xiao\({}^{4}\), Yinqiang Zheng\({}^{2}\), Yujiu Yang\({}^{1}\)

\({}^{1}\) Shenzhen International Graduate School, Tsinghua University

\({}^{2}\) The University of Tokyo \({}^{3}\) University of Maryland, College Park \({}^{4}\) Pingan Group

{wth22, ssw20}@mails.tsinghua.edu.cn, cmd@g.ecc.u-tokyo.ac.jp

hmcai@umd.edu, xiaojing661@pingan.com.cn, yqzheng@ai.u-tokyo.ac.jp

yang.yujiu@sz.tsinghua.edu.cn

 Tianhe Wu and Shuwei Shi contribute equally to this work.Corresponding author.

###### Abstract

Blind Omnidirectional Image Quality Assessment (BOIQA) aims to objectively assess the human perceptual quality of omnidirectional images (ODIs) without relying on pristine-quality image information. It is becoming more significant with the increasing advancement of virtual reality (VR) technology. However, the quality assessment of ODIs is severely hampered by the fact that the existing BOIQA pipeline lacks the modeling of the observer's browsing process. To tackle this issue, we propose a novel multi-sequence network for BOIQA called Assessor360, which is derived from the realistic multi-assessor ODI quality assessment procedure. Specifically, we propose a generalized Recursive Probability Sampling (RPS) method for the BOIQA task, combining content and details information to generate multiple pseudo viewport sequences from a given starting point. Additionally, we design a Multi-scale Feature Aggregation (MFA) module with a Distortion-aware Block (DAB) to fuse distorted and semantic features of each viewport. We also devise Temporal Modeling Module (TMM) to learn the viewport transition in the temporal domain. Extensive experimental results demonstrate that Assessor360 outperforms state-of-the-art methods on multiple OIQA datasets. The code and models are available at https://github.com/TianheWu/Assessor360.

## 1 Introduction

With the development of VR-related techniques, viewers can enjoy a realistic and immersive experience with head-mounted displays (HMDs)  by perceiving 360-degree omnidirectional information. However, the acquired omnidirectional image, also named panorama, is not always of high quality . Degradation may be introduced in any image processing , leading to low-quality content that may be visually unpleasant for users. Consequently, developing suitable quality metrics for panoramas holds considerable importance, as they can be utilized to guide research in omnidirectional image processing and maintain high-quality visual content.

Generally, most ODIs are stored in the equirectangular projection (ERP) format, which exhibits considerable geometric deformation at different latitudes. This distortion can have a negative impact on quality assessment. Therefore, as shown in Figure 1 (a), many researchers  explore viewport-based methods by projecting the original ERP image into many undeformed viewports (actual content observed by users) and aggregate their features with 2D IQA method as the ODI quality score. However, this conventional viewport-based pipeline lacks the modeling of theobserver's browsing process, causing the predicted quality to be far from the human perceptual quality, especially when the ODI containing non-uniform distortion (such as stitching) [33; 12; 36; 61; 37]. In fact, during the process of observing ODIs, viewports are sequentially presented to viewers based on their browsing paths, forming a viewport sequence.

While the viewport sampling techniques proposed by Sui _et al._ and Zhang _et al._ can generate viewports with a fixed sequential order for ODIs, their methods lack the ability to generate versatile sequences. Specifically, their methods will produce identical sequences for a given starting point, and the sequential order of viewports will remain constant across different ODIs. This behavior is inconsistent with the observations of multiple evaluators in realistic scenarios, leading to an inability to provide subjectively consistent evaluation results. To address this issue, a logical approach is to employ the scanpath prediction model for generating pseudo viewport sequences on the ODI without an authentic scanpath. However, current scanpath prediction methods [47; 24; 32; 1; 34] are developed for undistorted ODIs and mainly focus on high-level regions. As evaluators are required to provide an accurate quality score for an ODI, their scanpaths are distributed across both low-quality and high-detail regions. This makes it potentially unsuitable for direct application in BOIQA task where all ODIs are distorted.

To move beyond these limitations, inspired by the realistic multi-assessor ODI quality assessment procedure, shown in Figure 1 (b), we first propose a multi-sequence network called Assessor360 for BOIQA, which can simulate the authentic data scoring process to generate multiple viewport sequences (corresponding to multiple scanpaths). Specifically, we propose Recursive Probability Sampling (RPS) to generate multiple pseudo viewport sequences, combining semantic scene and local distortion characteristics. In particular, based on Equator-guided Sampled Probability (ESP) and Details-guided Sampled Probability (DSP), RPS will generate different viewport sequences for the same starting point (details in Section 3.2). Furthermore, we develop Multi-scale Feature Aggregation (MFA) with Distortion-aware Block (DAB) to effectively fuse viewport semantic and distorted features for accurate quality perception. The Temporal Modeling Module (TMM) is devised by applying GRU  module and MLP layers to learn the viewports temporal transition information in a sequence and regress the aggregated features to the final score. Extensive experiments demonstrate the superiority and effectiveness of proposed Assessor360 on multiple OIQA datasets (MVAQD , OIQA , CVIQD , IQA-ODI , JUFE , JXUFE ). We summarize our contributions into four points:

* We propose Assessor360 for BOIQA, which can leverage multiple different viewport sequences to assess the ODI quality. To our knowledge, Assessor360 is the first pipeline to simulate the authentic data scoring process in ODI quality assessment.
* We propose an unlearnable method, Recursive Probability Sampling (RPS) that can combine semantic scene and local distortion characteristics to generate different viewport sequences for a given starting point.

Figure 1: Illustration of the existing ordinary viewport-based pipeline (a) and the realistic omnidirectional image quality assessment procedure (b). Plenty of existing viewport-based methods follow pipeline (a) which is inconsistent with authentic assessment procedure (b), causing the predicted quality score to be far from the human perceptual quality score.

* We design Multi-scale Feature Aggregation (MFA) and Distortion-aware Block (DAB) to characterize the integrated features of viewports and devise a Temporal Modeling Module (TMM) to model the temporal correlation between viewports.
* We apply our Assessor360 to two types of OIQA task datasets: one with real observed scanpath data and the other without. Extensive experiments show that our Assessor360 largely outperforms state-of-the-art methods.

## 2 Related Work

Omnidirectional Image Quality Assessment.Similarly to traditional 2D IQA, according to the reference information availability, OIQA can also be divided into three categories: full-reference (FR), reduced-reference (RR), and no-reference (NR) OIQA, also known as blind OIQA . Due to the structural characteristics of the panorama and the complicated assessment process, OIQA has not matured as much as 2D-IQA [48; 22; 13; 19; 15; 29]. Some researchers extend the 2D image quality assessment metrics to the panorama, such as S-PSNR , CPP-PSNR , and WS-PSNR . However, these methods are not consistent with the Human Visual System (HVS) and they are poorly consistent with perceived quality [60; 43]. Although WS-SSIM  and S-SSIM  consider some impacts of HVS, the availability of non-distortion reference ODIs severely hinders their applications in authentic scenarios.

Therefore, some deep learning-based BOIQA methods [60; 43; 36; 16; 53; 46] are devised to achieve better capabilities. Due to the geometric deformation present in ODIs in ERP format, many existing BOIQA methods [59; 46; 60; 17] follow a similar pipeline: sampling viewports in a particular way and simply regressing their features to the quality score. MC360IQA  first maps the sphere into a cubemap, then employs CNN to aggregate each cubemap plane feature and regress them to a score. ST360IQ  samples tangent viewports from the salient parts and uses ViT  to estimate the quality of each viewport. VGCN  migrates the graph convolution network and pre-trained DBCNN  to establish connections between different viewports. However, these methods ignore the vital effect of the viewport sequences generated in multiple observers' browsing process, which have been demonstrated by Sui _et al._ and Fang _et al._ on the perception of the ODI quality.

Viewport Sampling Strategies in OIQA.Existing viewport sampling strategies can be categorized into three modes: 1) Uniformly sampling without sequential order. Zhou _et al._ and Fang _et al._ uniformly extract viewports over the sphere. Jiang _et al._ and Sun _et al._ use cube map projection (CMP) and rotate the longitude to obtain several viewport groups. This sampling pattern will cover the full areas, whether they are significant or non-significant. 2) Crucial region sampling without sequential order. Xu _et al._ leverage 2D Gaussian Filter  to acquire a heatmap and generate viewports with corresponding locations. Tofighi _et al._ apply ATSal  to predict salient regions of the panorama, which gives help to sampling viewports. This mode incorporates HVS, where most of the sampled viewport might be observed in the browsing process. Nevertheless, both of the above methods only focus on the image content and do not concern the effect of the sequential order between viewports in the quality assessment process of panoramas. 3) Sampling viewports along the fixed direction. Sui _et al._ first considers the effect of sequential order between viewports in the browsing process. They default observers rotate their perspective in a specific direction along the equator. Zhang _et al._ further introduce ORB detection to capture key viewports and follow Sui _et al._ default sampling direction to extract viewports. In fact, different evaluators will produce various scanpaths when viewing a panorama. Even if the same evaluator observes the same ODI twice, the scanpath will be different. However, their sampling methods cause the sequential order of the viewport to be fixed, and even for the different image contents, the sequential order of sampled viewports is the same. This creates a significant gap with people's actual browsing process, leading to unreasonable modeling of the viewport sequence.

## 3 Method

### Overall Framework

As shown in Figure 2 (a), the proposed Assessor360 framework consists of Recursive Probability Sampling (RPS) scheme, Multi-scale Feature Aggregation (MFA) strategy, and Temporal Modeling Module (TMM). Given a degraded ODI \(\), to be consistent with the authentic multi-assessor assessment, we initialize \(N\) starting points \(=\{(u_{i},v_{i})\}_{i=1}^{N}\), where \(u_{i}[-90^{},90^{}]\) and \(v_{i}[-180^{},180^{}]\) are the corresponding latitude and longitude coordinates. Then, we apply the proposed RPS strategy \(\) with parameters \(_{g}\) to generate multiple viewport sequences \(=\{\{_{j}^{i}\}_{j=1}^{M}\}_{i=1}^{N}\), where \(\) denoteseach viewport, \(M\) denotes the length of each sequence. Next, to perceive the semantic scene and distortion in each viewport, multi-scale features are extracted from multi-stage layers of our method for quality assessment. We use MFA \(\) with parameters \(_{f}\) to represent this process. The features are aggregated from \(^{H W C}\) to \(^{1 1 D}\). In this case, \(C\) is the viewport's original dimensions, \(H\) and \(W\) are the height and width of the viewport, and \(D\) denotes the embedding dimension. Then, we use TMM \(\) with parameters \(_{h}\) to model each sequence viewport temporal transition information and predict the final viewport sequence quality score. Finally, we average all predicted scores of each sequence as the ODI's quality \(_{}\). Overall, the whole process can be described as follows:

\[_{}=^{N}}( ((,;_{g});_{f}); _{h})\] (1)

### Recursive Probability Sampling

Recursive Probability Sampling (RPS) strategy can adaptively generate the probability of scene transition direction based on prior knowledge of semantic context and degraded features in ODI. It mainly consists of Equator-guided Sampled Probability (ESP) and Details-guided Sampled Probability (DSP). The viewport sequence is generated by selecting a certain starting point and sampling viewports based on generated probabilities.

Preprocessing for generating probabilities.As illustrated in , transition direction and distance are two important factors for locating the next viewport position. We first follow the theory of Moore neighborhood  and define \(K\) neighbor (\(K=8\)) transition directions from the center coordinate of the viewport. Following [31; 33], the transition distance \(( u, v)\) is set to (\(24^{},24^{}\)), avoiding sampling overly overlapped viewports. In details, given a current position \(x_{c}^{t}=(u_{c}^{t},v_{c}^{t})\), we first generate the corresponding viewport \(_{t}\) from \(\) by rectilinear projection \(\). Then, we uniformly split \(_{t}\) into \(K+1\) overlapped patches, including \(K\) neighbor patches \(^{t}=\{^{t}_{i}\}_{i=1}^{K}\) and one central patch \(^{t}_{c}\) with height \(\) and width \(\). As shown in Figure 2 (b), the \(K\) direction sampled coordinates \(^{t}_{neighbor}=\{x_{i}^{t}\}_{i=1}^{K}\) can be calculated by the central patch \(^{t}_{c}\) coordinate \(x_{c}^{t}\) and \(( u, v)\). During the browsing process, assessors are not only drawn to the high-level scenario but also focus on low-level texture and details regions [35; 11] to give a reasonable quality score. Therefore, according to the generalized prior content information and pixel-level details metric, we present ESP and DSP for each direction sampled coordinate in \(^{t}_{neighbor}\). Then, we choose the next sampled viewport \(_{t+1}\) position \(x_{c}^{t+1}\) based on them.

Equator-guided Sampled Probability (ESP).Since the equator entails more scene information [7; 31], we introduce the prior equator bias \(\) to constrain the sampled viewport near the equator. Concretely, the prior equator bias obeys a Gaussian distribution with a mean of \(0\) and a standard deviation of \(0.2\) in latitude. Regions near the equator have higher sampled weights and regions close

Figure 2: Architecture of proposed Assessor360 for BOIQA (a). Our Assessor360 consists of Recursive Probability Sampling (RPS) scheme (b), Multi-scale Feature Aggregation (MFA) strategy, and Temporal Modeling Module (TMM).

to the poles have relatively low sampled weights. We apply the softmax function to \(\) to obtain the coordinate probability map \(_{p}\) where each coordinate corresponds to a sampled probability. Then we take \(^{t}_{neighbor}\) sampled probabilities \(\{p^{i}_{x}\}_{i=1}^{K}\) from \(_{p}\). Meanwhile, due to the inhibition of return (IOR)  where regions that have been fixated by the eyes have a lower probability of being fixated again in the near future, we multiply \(p^{k}_{x}\) with a decreasing factor \(\) where \(k\) is the index of the viewport coordinate has been generated. Finally, we apply softmax function to calculate \(p_{esp}=\{p^{i}_{esp}\}_{i=1}^{K}\). Overall, the ESP calculation function \(_{esp}()\) can be defined as:

\[_{esp}()=(Z_{p}( ^{t}_{neighbor})),Z=\{1,,,,1\}^{K}\] (2)

Details-guided Sampled Probability (DSP).To efficiently measure the texture complexity of each patch, we use pixel-level information entropy \(\). The mathematical expression is:

\[(^{t}_{i})=_{m=1}^{H^{}}_{n=1}^{W^{ }}-p(^{t}_{i}[m,n])_{2}p(^{t}_{i}[m,n])\] (3)

where \(^{t}_{i}[m,n]\) is the gray value of each pixel at position \((m,n)\) in the patch \(^{t}_{i}\), and \(p()\) is the probability of occurrence of each gray value. After calculating the entropy of each neighbor patch, we normalize it with the softmax function to obtain \(p_{dsp}=\{p^{i}_{dsp}\}_{i=1}^{K}\) for \(^{t}_{neighbor}\). The DSP calculation function \(_{dsp}()\) can be formulated as:

\[_{dsp}()=((^{t}))\] (4)

Generating viewport sequences.Ultimately, we multiply the ESP and DSP with a scale factor \(\) to get the integrated probability. We use the softmax function to obtain the final probability distribution and select the next viewport position \(x^{t+1}_{c}\) according to it, which can be written as:

\[x^{t+1}_{c}=(^{t}|(p_{dsp} p_{esp} ))\] (5)

where \((|)\) is the selecting function based on the set of probability \(\). We can recursively generate viewport \(_{t+1}\) with \(x^{t+1}_{c}\) and keep performing the RPS strategy until the number of viewports in the sequence reaches the desired length. The whole generation algorithm \(\) is shown in Algorithm 1.

```
0:\(N\) starting points \(\{x_{i}\}_{i=1}^{N}\); an ODI \(\); rectilinear projection \(\); ESP calculation function \(_{esp}()\); DSP calculation function \(_{dsp}()\); selecting function \((|)\)
0: A set of \(N\) length \(M\) viewport sequences \(\{s_{i}=\{_{t}\}_{t=1}^{M}\}_{i=1}^{N}\);
1:for\(i=1 N\)do
2: Initialize the current coordinate \(x x_{i}\)
3:for\(t=1 M\)do
4: Generate viewport by the current coordinate \((x,)\)
5: Split \(\) to obtain overlapped neighbor patches \(\) and calculate sampled coordinate \(\)
6: Calculate ESP and DSP \(p_{esp}_{esp}()\), \(p_{dsp}_{dsp}()\)
7: Generate next viewport coordinate \(x(|(p_{esp},p_{dsp}))\)
8: Sequentially gather generated \(M\) viewports \(\{_{t}\}_{t=1}^{M}\) as a viewport sequence \(s_{i}\)
9: Gather generated \(N\) viewport sequences \(\{s_{i}\}_{i=1}^{N}\) as the output ```

**Algorithm 1** Viewport Sequence Generation (RPS Algorithm)

### Multi-scale Feature Aggregation

To represent the semantic information and distortion pattern of each viewport, which are assumed as two key factors of quality assessment, we aggregate multi-scale features of the viewport. We first extract features from each stage in pre-trained Swin Transformer [23; 30]. The outputs of the first two stages \(}\), \(}\) are more sensitive to the distortion pattern, while the outputs of the last two stages \(}\), \(}\) tend to capture the abstract features (details in Supplementary Materials). Before fusing multi-scale features, we first employ four \(1 1\) convolution layers to reduce the feature dimension of the output to \(D\). Then, to further emphasize the local degradation, we devise and apply the Distortion-aware Block (DAB) which includes a \(3 3\) convolution layer following \(n\) Channel Attention (CA) operations to the reduced shallow features \(}},}}\). This operation can help the model to better perceive the distortion pattern in the channel dimension, achieving distortion-aware capacity. Finally, we concatenate and integrate these features with Global Average Pooling (GAP) and multiple \(1 1\) convolution layers to get the quality-related representation. After that, each aggregated feature \(}\) will be sent to TMM for viewport sequence quality assessment.

### Temporal Modeling Module

The browsing process of ODI naturally leads to the temporal correlation. The recency effect indicates that users are more likely to evaluate the overall image quality affected by the viewports they have recently viewed, especially during prolonged exploration periods. To model this relation, we introduce the GRU module to learn the viewport transition. Due to the fact that the last token encodes the most recent information and the representation at the last time step involves the whole temporal relationships of a sequence, we use MLP layers to regress the last feature output by the GRU module to the sequence quality score.

## 4 Experiments

### Implementation Details

We set the field of view (FoV) to the \(110^{}\) following [12; 33]. We use pre-trained Swin Transformer  (base version) as our feature extraction backbone. The input viewport size \(H W\) is fixed to \(224 224\). The number of viewport sequences \(N\) is set to \(3\) and the length of each sequence \(M\) is set to \(5\). We set the coordinates of \(N\) starting points to be \((0^{},0^{})\). The reduced dimension \(D\) is \(128\) and the number of GRU modules is set to \(6\). The number of CA operations \(n\) is \(4\). We set \(=0.7\) and \(=100\) as decreasing factor and scale factor values respectively.

For a fair comparison, we randomly split \(80\%\) ODIs of each dataset for training, and the remaining \(20\%\) is used for testing following [53; 18; 12; 17]. To eliminate bias, we run a random train-test splitting process ten times and show the median result. We train \(300\) epochs with batch size \(4\) on CVIQD , OIQA , IQA-ODI , and MVAQD  datasets without the authentic scanpath data. Respectively, we compare our RPS with two advanced learning-based scanpath prediction methods ScanGAN360  and ScanDMM  on JUFE  and JXUFE  datasets which have the authentic scanpath data. For optimization, we use Adam  and the learning rate is set to \(1 10^{-5}\) in the training phase. We employ MSE loss to train our model. We use Spearman rank-ordered correlation (SRCC) and Pearson linear correlation (PLCC) as the evaluation metrics.

### Comparing with the State-of-the-art Methods

We conduct a comparative analysis of Assessor360 with eight FR methods and thirteen NR methods. The quantitative comparison results are presented in Table 1, demonstrating significant performance

    &  &  &  &  &  \\  & & SRCC & PLCC & SRCC & PLCC & SRCC & PLCC & SRCC & PLCC \\   & PSNR & 0.8150 & 0.7591 & 0.3929 & 0.3893 & 0.4018 & 0.4890 & 0.8015 & 0.8425 \\  & SSIM  & 0.8272 & 0.7202 & 0.3402 & 0.2307 & 0.5014 & 0.5686 & 0.6737 & 0.7273 \\  & MS-SSIM  & 0.8032 & 0.7136 & 0.5750 & 0.5084 & 0.7434 & 0.8389 & 0.9218 & 0.9272 \\  & WS-PSNR  & 0.8152 & 0.7638 & 3.829 & 0.3678 & 0.3780 & 0.4708 & 0.8039 & 0.8410 \\ methods & WS-SSIM  & 0.8236 & 0.5328 & 0.6020 & 0.3557 & 0.5325 & 0.7098 & 0.8632 & 0.7672 \\  & VIF  & 0.8687 & 0.8436 & 0.4284 & 0.4158 & 0.7109 & 0.7696 & 0.9502 & 0.9370 \\  & DISTS  & 0.7911 & 0.7440 & 0.5740 & 0.5809 & 0.8513 & 0.8723 & 0.8771 & 0.8613 \\  & LPIPS  & 0.8048 & 0.7336 & 0.5844 & 0.4292 & 0.7355 & 0.7411 & 0.8236 & 0.8242 \\   & NIQE  & 0.6785 & 0.6880 & 0.8539 & 0.7850 & 0.6645 & 0.5637 & 0.9337 & 0.8392 \\  & BRISQUE  & 0.8408 & 0.8345 & 0.8213 & 0.8206 & 0.8171 & 0.8651 & 0.8269 & 0.8199 \\  & PaQ-2-PIQ  & 0.3251 & 0.3643 & 0.1667 & 0.2102 & 0.0201 & 0.0419 & 0.7376 & 0.6500 \\  & MANIQA  & 0.5531 & 0.5718 & 0.4555 & 0.4171 & 0.2642 & 0.2776 & 0.6013 & 0.6142 \\  & MUSIQ  & 0.5436 & 0.6117 & 0.3216 & 0.3087 & 0.0565 & 0.0983 & 0.3483 & 0.3678 \\  & CLIP-IQA  & 0.5862 & 0.4941 & 0.2330 & 0.2531 & 0.0927 & 0.1929 & 0.4884 & 0.4347 \\  & LIQE  & 0.6837 & 0.7539 & 0.7634 & 0.7419 & 0.8551 & 0.9020 & 0.8594 & 0.8086 \\ NR-IQA & SSP-BOIQA  & 0.7838 & 0.8406 & 0.8650 & 0.8600 & - & - & 0.8614 & 0.9077 \\  & MP-BOIQA  & 0.8420 & 0.8543 & 0.9066 & 0.9206 & - & - & 0.9235 & 0.9390 \\  & MC360IQA  & 0.6605 & 0.6977 & 0.9071 & 0.8925 & 0.8248 & 0.8629 & 0.8271 & 0.8240 \\  & SAP-net  & - & - & - & - & 0.9036 & 0.9258 & - & - \\  & VGCN  & 0.8422 & 0.9112 & 0.9515 & 0.9584 & 0.8117 & 0.8823 & 0.9639 & 0.9651 \\  & AHGCN  & - & - & 0.9647 & 0.9682 & - & - & 0.9617 & 0.9658 \\   & baseline w/ ERP & 0.9076 & 0.9240 & 0.8961 & 0.8857 & 0.9098 & 0.9196 & 0.9330 & 0.9485 \\  & baseline w/ CMP & 0.8966 & 0.9324 & 0.9216 & 0.9170 & 0.9105 & 0.9122 & 0.9390 & 0.9412 \\   & **Assessor360** & **0.9607** & **0.9720** & **0.9802** & **0.9747** & **0.9573** & **0.9626** & **0.9644** & **0.9769** \\   

Table 1: Quantitative comparison of the state-of-the-art methods and proposed Assessor360. The best are shown in **bold**, and the second best (except ours) are underlined. Two baselines w/ ERP and w/ CMP mean that we replace input viewport sequences generated by RPS with ERP and CMP.

[MISSING_PAGE_FAIL:7]

### Effectiveness of Recursive Probability Sampling

As mentioned in Section 1, there exist many learning-based scanpath prediction methods [24; 47; 32]. They seem to be able to assist in constructing viewport sequences. However, they are hardly introduced to OIOA task. In this section, we first perform the quantitative comparison of the model with RPS and two advanced 360-degree scanpath prediction methods, namely ScanGAN360  and ScanDMM  on the datasets without real observed scanpath. Subsequently, we compare the position and sequential order of viewports generated by the three methods with the ground-truth (GT) scanpaths by the metrics of scanpath prediction task and visualization to further validate the superiority of RPS on JUFE  and JXUFE  datasets with real observed scanpath.

Quantitative comparison of performance.We replace the proposed RPS method with ScanGAN360 and ScanDMM to generate sequences of viewports. The model was trained and tested using these viewport sequences on OIOA  and MVAQD  datasets, maintaining the same length and number of viewports for a fair comparison. Table 4 shows the quantitative results, demonstrating that viewports generated from RPS yield superior performance compared to ScanGAN360 and ScanDMM. Additionally, training using viewports generated from these methods outperforms those generated using random schemes, highlighting the crucial role of suitable viewport sequences in the OIOA task.

Moreover, we conduct experiments by replacing original VGCN  sampling methods with RPS in VGCN. We use RPS to sample the same number of viewports as  to train VGCN on IQA-ODI  and MVAQD datasets. The results presented in Table 7 demonstrate a substantial performance enhancement for VGCN achieved by the viewport sampled through RPS, resulting in an increase of 0.07 in SRCC for MVAQD. Additionally, this indicates that the viewport sampled with RPS closely aligns with human observations.

    &  &  &  \\  & & LEV\(\) & DTW\(\) & REC\(\) & LEV\(\) & DTW\(\) & REC\(\) \\  - & Random Baseline (lower bound) & 35.21 & 1707.45 & 0.38 & 35.08 & 1695.93 & 0.38 \\  TVCG22 & ScanGAN360  & 32.53 & 1448.65 & 1.07 & 31.89 & 1427.55 & 1.14 \\ CVPR23 & ScanDMM  & 31.23 & **1434.36** & 1.21 & 31.48 & 1438.29 & 1.12 \\ - & RPS w/o DSP (Ours) & 29.54 & 1471.2 & 2.14 & 29.99 & 1463.38 & 1.94 \\ - & **RPS (Ours)** & **29.48** & 1454.03 & **2.21** & **29.66** & **1422.85** & **2.07** \\ - & Human Baseline (upper bound) & 23.85 & 1309.29 & 3.78 & 26.73 & 1302.15 & 2.88 \\   

Table 5: Quantitative comparison of different generation methods (**RPS vs ScanGAN360  and ScanDMM **) with metrics of scanpath prediction task on JUFE  and JXUFE  datasets with authentic scanpaths.

Figure 3: Visual comparison of the generated viewport positions for different methods on ODIs with four distortion types in JUFE. The brighter the area, the more viewports are generated in that area.

[MISSING_PAGE_FAIL:9]

Impact of the number and length of the viewport sequence.We test \(N=1,3,5\) three different numbers of viewport sequences with varying sequence lengths on MVAQD  dataset. The findings, shown in Figure 4, reveal that as the sequence length increases, there is a decreasing trend in model performance across all three numbers of sequences. This suggests that an excessive number of viewports may introduce redundant information, potentially disrupting the training process of the network. Furthermore, our experiments demonstrate that incorporating multiple viewport sequences, the model can capture a broader range of perspectives of the scene, thereby better reflecting the rating process of ODIs and achieving improved robustness.

### Proximate to Human-Observed Performance

We conduct a comparative analysis between the performance achieved using ground-truth (GT) sequences and pseudo sequences generated by RPS on the JUFE dataset . In the JUFE dataset, the GT sequences are annotated based on whether they originate from good or bad starting points (details in Supplementary Materials). Therefore, for each starting point, we use RPS to generate those sequences with the same number and length of sequences compared to GT sequences. Then, we apply the generated sequences and GT sequences as the input of our proposed network. The results shown in Table 9 highlight a close gap between the contributions of GT sequences and our generated sequences. This result emphasizes the significance of proximity to human observation in enhancing the model's capabilities. Meanwhile, there is still a large exploration space for future methods to better incorporate human's sequences in OIQA task.

## 5 Conclusion

This paper introduces a novel multi-sequence network named Assessor360 for BOIQA based on a realistic assessment procedure. Specifically, we design Recursive Probability Sampling (RPS) to generate viewport sequences based on the semantic scene and the distortion. Additionally, we propose Multi-scale Feature Aggregation (MFA) with Distortion-aware Block (DAB) to combine distorted and semantic features of viewports. Temporal Modeling Module (TMM) is introduced to learn the temporal transition of viewports. We demonstrate the high performance of Assessor360 on multiple OIQA datasets and validate the effectiveness of RPS by comparing it with two advanced learning-based models used for scanpath prediction. Limitation is that the transition direction and distance in RPS are fixed, resulting in equally spaced distances between viewports. However, we have confidence that our analyses and the proposed pipeline can provide long-term valuable insights for future OIQA task.

Acknowledgments.This work was partly supported by the National Natural Science Foundation of China (Grant No. 61991451) and the Shenzhen Science and Technology Program (JSGG20220831093004008). The author would like to thank Xiangjie Sui at Jiangxi University of Finance and Economics for his inspiration.