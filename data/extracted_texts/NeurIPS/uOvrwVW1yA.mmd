# Sample Complexity of Algorithm Selection Using Neural Networks and Its Applications to Branch-and-Cut

Sample Complexity of Algorithm Selection Using Neural Networks and Its Applications to Branch-and-Cut

 Hongyu Cheng

Dept. of Applied Mathematics & Statistics

Johns Hopkins University

Baltimore, MD 21218

hongyucheng@jhu.edu

&Sammy Khalife

Dept. of Applied Mathematics & Statistics

Johns Hopkins University

Baltimore, MD 21218

khalife.sammy@jhu.edu

&Barbara Fiedorowicz

Dept. of Applied Mathematics & Statistics

Johns Hopkins University

Baltimore, MD 21218

bfiedor1@jhu.edu

&Amitabh Basu

Dept. of Applied Mathematics & Statistics

Johns Hopkins University

Baltimore, MD 21218

basu.amitabh@jhu.edu

###### Abstract

Data-driven algorithm design is a paradigm that uses statistical and machine learning techniques to select from a class of algorithms for a computational problem an algorithm that has the best expected performance with respect to some (unknown) distribution on the instances of the problem. We build upon recent work in this line of research by considering the setup where, instead of selecting a single algorithm that has the best performance, we allow the possibility of selecting an algorithm based on the instance to be solved, using neural networks. In particular, given a representative sample of instances, we learn a neural network that maps an instance of the problem to the most appropriate algorithm _for that instance_. We formalize this idea and derive rigorous sample complexity bounds for this learning problem, in the spirit of recent work in data-driven algorithm design. We then apply this approach to the problem of making good decisions in the branch-and-cut framework for mixed-integer optimization (e.g., which cut to add?). In other words, the neural network will take as input a mixed-integer optimization instance and output a decision that will result in a small branch-and-cut tree for that instance. Our computational results provide evidence that our particular way of using neural networks for cut selection can make a significant impact in reducing branch-and-cut tree sizes, compared to previous data-driven approaches.

## 1 Background and motivation

Often there are several competing algorithms for a computational problem and no single algorithm dominates all the others. The choice of an algorithm in such cases is often dictated by the "typical" instance one expects to see, which may differ from one application context to another. Data-driven algorithm design has emerged in recent years as a way to formalize this question of algorithm selection and draws upon statistical and machine learning techniques; see Balcan (2020) for a survey and references therein. More formally, suppose one has a class \(\) of instances of some computational problem with some unknown distribution, and a class of algorithms that can solve this problem parameterized by some "tunable parameters". Suppose that for each setting of the parameters, the corresponding algorithm can be evaluated by a score function that tells us how well the algorithm does on different instances (e.g., running time, memory usage etc.). We wish to find the set of parameters that minimizes (or maximizes, depending on the nature of the score) the expected score on the instances (with respect to the unknown distribution), after getting access to an i.i.d. sample of instances from the distribution. For example, \(\) could be a family of mixed-integer optimization problems and the class of algorithms are branch-and-cut methods with their different possible parameter settings, and the score function could be the size of the branch-and-cut tree.

In Balcan et al. (2021), the authors prove a central result on the sample complexity of this problem: if for any fixed instance in \(\), the score function has a piecewise structure as a function of the parameters, where the number of pieces is upper bounded by a constant \(R\) independent of the instance, the pieces come from a family of functions of "low complexity", and the regions partitioning the parameter space into pieces have "low complexity" in terms of their shape, then the sample complexity is a precise function of \(R\) and these two complexity numbers (formalized by the notion of pseudo-dimension - see below). See Theorem 3.3 in Balcan et al. (2021) for details. The authors then proceed to apply this key result to a diverse variety of algorithmic problems ranging from computational biology, computational economics to integer optimization.

Our work in this paper is motivated by the following consideration. In many of these applications, one would like to select not a _single_ algorithm, i.e., a single setting of the parameters, but would like to decide on the parameters after receiving a new instance of the problem. In other words, we would like to learn not the best parameter, but the _best mapping from instances to parameters_. We consider this version of the problem, where the mapping is taken from a class of neural network functions. At a high level, switching the problem from finding the "best" parameter to finding the "best" mapping in a parameterized family of mappings gives the same problem: we now have a new set of parameters - the ones parameterizing the mappings (neural networks) - and we have to select the best parameter. And indeed, the result from Balcan et al. (2021) can be applied to this new setting, _as long as one can prove good bounds on pseudo-dimension in the space of these new parameters_. The key point of our result is two fold:

1. Even if original space of parameters for the algorithms is amenable to the analysis of pseudo-dimension as done in Balcan et al. (2021), it is not clear that this immediately translates to a similar analysis in the parameter space of the neural networks, because the "low complexity piecewise structure" from the original parameter space may not be preserved.
2. We suspect that our proof technique results in tighter sample complexity bounds, compared to what one would obtain if one could do the analysis from Balcan et al. (2021) in the parameter space of the neural network directly. However, we do not have quantitative evidence of this yet because their analysis seems difficult to carry out directly in the neural parameter space.

One of the foundational works in the field of _selecting algorithms based on specific instances_ is Rice (1976), and recently, Gupta and Roughgarden (2016), Balcan et al. (2021) have explored the sample complexity of learning mappings from instances to algorithms for particular problems. Our approach is also related to recent work on _algorithm design with predictions_; see Mitzenmacher and Vassilvitskii (2022) for a short introduction and the references therein for more thorough surveys and recent work. However, our emphasis and the nature of our results are quite different from the focus of previous research. We establish sample complexity bounds for a general learning framework that employs neural networks to map instances to algorithms, which is suitable for handling some highly complex score functions, such as the size of the branch-and-cut tree. The introduction of neural networks in our approach bring more intricate technical challenges than traditional settings like linear predictors or regression trees Gupta and Roughgarden (2016). On the application side, as long as we know some information about the algorithms (see Theorems 2.5 and 2.6), our results can be directly applied. This is demonstrated in this paper through applications to various _cutting plane selection_ problems in branch-and-cut in Propositions 3.3, 3.5, 3.6 and 3.7. Several references to fundamental applied work in data-driven algorithm selection can be found in the Balcan (2020), Gupta and Roughgarden (2016), Balcan et al. (2021, 2021).

### Applications in branch-and-cut methods for mixed-integer linear optimization

Mixed-integer linear optimization is a powerful tool that is used in a diverse number of application domains. Branch-and-cut is the solution methodology of choice for all state-of-the-art solvers for mixed-integer optimization that is founded upon a well-developed theory of convexification and systematic enumeration Schrijver (1986); Nemhauser and Wolsey (1988); Conforti et al. (2014). However, even after decades of theoretical and computational advances, several key aspects of branch-and-cut are not well understood. During the execution of the branch-and-cut algorithm on an instance, the algorithm has to repeatedly make certain decisions such as which node of the search tree to process next, whether one should branch or add cutting planes, which cutting planes to add, or which branching strategy to use. The choices that give a small tree size for a particular instance may not be good choices for a different instance and result in a much larger tree. Thus, adapting these choices to the particular instance can be beneficial for overall efficiency. Of course, the strategies already in place in the best implementations of branch-and-cut have to adapt to the instances. For example, certain cutting plane choices may not be possible for certain instances. But even beyond that, there are certain heuristics in place that adapt these choices to the instance. These heuristics have been arrived at by decades of computational experience from practitioners. The goal in recent years is to provide a _data driven_ approach to making these choices. In a recent series of papers Balcan et al. (2021a, 2021a, 2022, 2018), the authors apply the general sample complexity result from Balcan et al. (2021a) in the specific context of branch-and-cut methods for mixed-integer linear optimization to obtain several remarkable and first-of-their-kind results. We summarize here those results that are most relevant to the cut selection problem since this is the focus of our work.

1. In Balcan et al. (2021d), the authors consider the problem of selecting the best Chvatal-Gomory (CG) cutting plane (or collection of cutting planes) to be added at the root node of the branch-and-cut tree. Thus, the "tunable parameters" are the possible multipliers to be used to generate the CG cut at the root node. The score function is the size of the resulting branch-and-cut tree. The authors observe that for a fixed instance of a mixed-integer linear optimization problem, there are only finitely many CG cuts possible and the number can be bounded explicitly in terms of entries of the linear constraints of the problem. Via a sophisticated piece of analysis, this gives the required piecewise structure on the space of multipliers to apply the general result explained above. This gives concrete sample complexity bounds for choosing the multipliers with the best expected performance. See Theorem 3.3, 3.5 and 3.6 in Balcan et al. (2021d) for details. Note that this result is about selecting a _single_ set of multipliers/cutting planes that has the best expected performance across all instances. This contrasts with selecting a good strategy to select multipliers _depending on the instance_, that has good expected performance (see point 2. below).
2. The authors in Balcan et al. (2021d) also consider the problem of learning a good strategy that selects multipliers based on the instance. In particular, they consider various auxiliary score functions used in integer optimization practice, that map a pair of instance \(I\) and a cutting plane \(c\) for \(I\) that measures how well \(c\) will perform for processing \(I\). The strategy will be a linear function of these auxiliary scores, i.e., a weighted average of these auxiliary scores, and the learning problem becomes the problem of finding the best linear coefficients for the different auxiliary scores. So now these linear coefficients become the "tunable parameters" for the general result from Balcan et al. (2021a). It is not hard to find the piecewise structure in the space of these new parameters, given the analysis in the space of CG cut multipliers from point 1. above. This then gives concrete sample complexity bounds for learning the best set of weights for these auxiliary score functions for cut selection. See Theorem 4.1 and Corollary 4.2 in Balcan et al. (2021d) for details.
3. In all the previous results discussed above, the cutting planes considered were CG cuts, or it was essentially assumed that there are only a finite number of cutting planes available at any stage of the branch-and-cut algorithm. In the most recent paper Balcan et al. (2022), the authors consider general cutting plane paradigms, and also consider the possibility of allowing more general strategies to select cutting planes beyond using weighted combinations of auxiliary score functions. They uncover the subtlety that _allowing general mappings from instances to cutting planes can lead to infinite sample complexity and learning such mappings could be impossible, if the class of mappings is allowed to be too rich_. See Theorem 5.1 in Balcan et al. (2022). This point will be important when we discuss our approach below. On the positive side, they show that the well-known class of Gomory-Mixed-Integer (GMI) cuts has a similar structure to CG cuts, and therefore, using similar techniques as discussed above, they derive sample complexity bounds for selecting GMI cuts at the root node. See Theorem 5.5 in Balcan et al. (2022). As far as we understand, the analysis should extend to the problem of learning weighted combinations of auxiliary score functions to select the GMI cuts as well using the same techniques as Balcan et al. (2021), although the authors do not explicitly do this in Balcan et al. (2022).

Our approach and results.Our point of departure from the line of work discussed above is that instead of using weighted combinations of auxiliary scores to select cutting planes, we wish to select these cutting planes using neural networks that map instances to cutting planes. In other words, in the general framework described above, the "tunable parameters" are the weights of the neural network. The overall score function is the size of the branch-and-cut tree after cuts are added at the root. We highlight the two main differences caused by this change in perspective.

1. In the approach where weighted combinations of auxiliary score functions are used, after the weights are learnt from the sample instances, for every new/unseen instance one has to compute the cut that maximizes the weighted score. This could be an expensive optimization problem in its own right. In contrast, with our neural approach, after training the net (i.e., learning the weights of the neural network), any new instance is just fed into the neural network and the output is the cutting plane(s) to be used for this instance. This is, in principle, a much simpler computational problem than optimizing the combined auxiliary score functions over the space of cuts.
2. Since we use the neural network to directly search for a good cut, bypassing the weighted combinations of auxiliary scores, we actually are able to find better cuts that reduce the tree sizes by a significant factor, compared to the approach of using weighted combinations auxiliary scores.

The above two points are clearly evidenced by our computational investigations which we present in Section A. The theoretical sample complexity bounds for cut selection are presented in Section 3. As mentioned before, these are obtained using the main sample complexity result for using neural networks for data driven algorithm design that is presented in Section 2.

Comparison with prior work on cut selection using learning techniques.As already discussed above, our theoretical sample complexity work in cut selection is closest in spirit to the work in Balcan et al. (2021, 2022, 2018). However, there are several other works in the literature that use machine learning ideas to approach the problem of cut selection; see Deza and Khalil (2023) for a survey. Tang et al. (2020) initiated the exploration of applying Reinforcement Learning (RL) to select CG cuts derived from the simplex tableau. Huang et al. Huang et al. (2022) apply supervised learning to rank a "bag of cuts" from a set of cuts to reduce the total runtime. More recently, the authors in Turner et al. (2023) propose a novel strategy that use RL and Graph Neural Networks (GNN) to select instance-dependent weights for the combination of auxiliary score functions.

Our computational investigations, as detailed in Appendix A, distinguishes itself from these prior computational explorations in several key aspects:

1. Previous methods were limited to a finite set of candidate cuts, requiring either an optimal simplex tableau or relying on a finite collection of combinatorial cuts. In contrast, our approach allows the possibility of selecting from a possibly infinite family of cutting planes. Moreover, our method eliminates the need for computing a simplex tableau which can lead to a significant savings in computation (see Table 1 and the discussion in Section A.2).
2. Many prior studies aimed at improving the objective value rather than directly reducing the branch-and-cut runtime--with the exception of Huang et al. Huang et al. (2022), who explored this through supervised learning. To the best of our knowledge, our RL-based model is the first to directly target the reduction of the branch-and-cut tree size as its reward metric, which is strongly correlated with the overall running time.
3. Prior deep learning approaches are not underpinned by theoretical guarantees, such as sample complexity bounds. Our empirical work takes the theoretical insights for the branch-and-cut problem presented in Theorem 2.3 and Proposition 3.3 as its basis.

The limitations of our approach are discussed in Section 4.

## 2 Formal statement of results

We denote \([d]\) as the set \(\{1,2,,d\}\) for any positive integer \(d_{+}\). For a set of vectors \(\{^{1},,^{t}\}^{d}\), we use superscripts to denote vector indices, while subscripts specify the coordinates in a vector; thus, \(^{i}_{j}\) refers to the \(j\)-th coordinate of \(^{i}\). Additionally, the sign function, denoted as \(:\{0,1\}\), is defined such that for any \(x\), \((x)=0\) if \(x<0\), and \(1\) otherwise. This function is applied to each entry individually when applied to a vector. Lastly, the notation \(\) is used to indicate the elementwise floor function, rounding down each component of a vector to the nearest integer.

### Preliminaries

#### 2.1.1 Background from learning theory

**Definition 2.1** (Parameterized function classes).: A _parameterized function class_ is given by a function defined as

\[h:,\]

where \(\) represents the _input space_, \(\) denotes the _parameter space_, and \(\) denotes the _output space_. For any fixed parameter setting \(\), we define a function \(h_{}:\) as \(h_{}(I)=h(I,)\) for all \(I\). The set of all such functions defines the parameterized function class, a.k.a. the _hypothesis class_\(=\{h_{}: \}\)_defined by_\(h\).

**Definition 2.2** (Pseudo-dimension).: Let \(\) be a non-empty collection of functions from an input space \(\) to \(\). For any positive integer \(t\), we say that a set \(\{I_{1},...,I_{t}\}\) is pseudo-shattered by \(\) if there exist real numbers \(s_{1},,s_{t}\) such that

\[2^{t}=|\{((f(I_{1})-s_{1}),,( f(I_{t})-s_{t})):f\}|.\]

The _pseudo-dimension of \(\)_, denoted as \(()\{+\}\), is the size of the largest set that can be pseudo-shattered by \(\).

The main goal of statistical learning theory is to solve a problem of the following form, given a fixed parameterized function class defined by some \(h\) with output space \(=\):

\[_{}\ _{I}[h(I,)],\] (1)

for an unknown distribution \(\), given access to i.i.d. samples \(I_{1},,I_{t}\) from \(\). In other words, one tries to "learn" the best decision \(\) for minimizing an expected "score" with respect to an unknown distribution given only samples from the distribution. Such a "best" decision can be thought of as a property of the unknown distribution and the problem is to "learn" this property of the unknown distribution, only given access to samples.

The following is a fundamental result in empirical processes theory and is foundational for the above learning problem; see, e.g., Chapters 17, 18 and 19 in Anthony et al. (1999), especially Theorem 19.

**Theorem 2.3**.: There exists a universal constant \(C\) such that the following holds. Let \(\) be a hypothesis class defined by some \(h:\) such that the range of \(h\) is in \([0,B]\) for some \(B>0\). For any distribution \(\) on \(\), \(>0\), \((0,1)\), and

\[t}{^{2}}(() ()+()),\]

we have

\[|_{i=1}^{t}h(I_{i},)-_{I}\ [h(I,)]|\ \ \ ,\]

with probability \(1-\) over i.i.d. samples \(I_{1},,I_{t}\) of size \(t\) drawn from \(\).

Thus, if one solves the _sample average_ problem \(_{}_{i=1}^{t}h(I_{i},)\) with a large enough sample to within \(O()\) accuracy, the corresponding \(\) would solve (1) to within \(O()\) accuracy (with high probability over the sample). Thus, the pseudo-dimension \(()\) is a key parameter that can be used to bound the size of a sample that is sufficient to solve the learning problem.

#### 2.1.2 Neural networks

We formalize the definition of neural networks for the purposes of stating our results. Given any function \(:\), we will use the notation \(()\) for \(^{d}\) to mean \([(_{1}),(_{2}),,(_{d})]^ {}^{d}\).

**Definition 2.4** (Neural networks).: Let \(:\) and let \(L\) be a positive integer. A _neural network_ with _activation_\(\) and _architecture_\(=[w_{0},w_{1},,w_{L},w_{L+1}]^{}_{L}^{L+2}\) is a paremeterized function class, parameterized by \(L+1\) affine transformations \(\{T_{i}:^{w_{i-1}}^{w_{i}}\), \(i[L+1]\}\) with \(T_{L+1}\) linear, is defined as the function

\[T_{L+1} T_{L} T_{2} T_{1}.\]

\(L\) denotes the number of hidden layers in the network, while \(w_{i}\) signifies the width of the \(i\)-th hidden layer for \(i[L]\). The input and output dimensions of the neural network are denoted by \(w_{0}\) and \(w_{L+1}\), respectively. If \(T_{i}\) is represented by the matrix \(A^{i}^{w_{i} w_{i-1}}\) and vector \(^{i}^{w_{i}}\), i.e., \(T_{i}()=A^{i}+^{i}\) for \(i[L+1]\), then the _weights of neuron_\(j[w_{i}]\) in the \(i\)-th hidden layer come from the entries of the \(j\)-th row of \(A^{i}\) while the _bias_ of the neuron is indicated by the \(j\)-th coordinate of \(^{i}\). The _size_ of the neural network is defined as \(w_{1}++w_{L}\), denoted by \(U\).

In the terminology of Definition 2.1, we define the neural network parameterized functions \(N^{}:^{w_{0}}^{W}^{w_{L+ 1}}\), with \(^{w_{0}}\) denoting the input space and \(^{W}\) representing the parameter space. This parameter space is structured through the concatenation of all entries from the matrices \(A^{i}\) and vectors \(^{i}\), for \(i[L+1]\), into a single vector of length \(W\). The functions are defined as \(N^{}(,)=T_{L+1}((T_{L}( T_{2}((T_ {1}())))))\) for any \(^{w_{0}}\) and \(^{W}\), where each \(T_{i}\) represents the affine transformations associated with \(^{W}\).

In the context of this paper, we will focus on the following activation functions:

* **sgn:** The _Linear Threshold_ (LT) activation function \(:\{0,1\}\), which is defined as \((x)=0\) if \(x<0\) and \((x)=1\) otherwise.
* **ReLU:** The _Rectified Linear Unit_ (ReLU) activation function \(:_{ 0}\) is defined as \((x)=\{0,x\}\).
* **CReLU:** The _Clipped Rectified Linear Unit_ (CReLU) activation function \(:\) is defined as \((x)=\{\{0,x\},1\}\).
* **Sigmoid:** The _Sigmoid_ activation function \(:(0,1)\) is defined as \((x)=}\).

### Our results

In this study, we extend the framework introduced by Balcan et al. Balcan et al. (2021) to explore the learnability of tunable algorithmic parameters through neural networks. Consider a computational problem given by a family of instances \(\). Let us say we have a suite of algorithms for this problem, parameterized by parameters in \(\). We also have a _score function_ that evaluates how well a particular algorithm, given by specific settings of the parameters, performs on a particular instance. In other words, the score function is given by \(S:[0,B]\), where \(B_{+}\) determines a priori upper bound on the score. The main goal of data-driven algorithm design is to find a particular algorithm in our parameterized family of algorithms - equivalently, find a parameter setting \(\) - that minimizes the expected score on the family of instances with respect to an unknown distribution on \(\), given access to a sample of i.i.d instances from the distribution. This then becomes a special case of the general learning problem (1), where \(h=S\) and one can provide precise sample complexity bounds via Theorem 2.3, if one can bound the pseudo-dimension of the corresponding hypothesis class. A bound on this pseudo-dimension is precisely the central result in Balcan et al. (2021); see the discussion in Section 1.

We assume the parameter space \(\) is a Cartesian product of intervals \([_{1},_{1}][_{},_{}]\), where \(_{i}_{i}\) for each \(i[]\). The transformation from the instance space \(\) to the parameter space \(\) is structured through the following mappings:

1. An encoder function \(:^{d}\) is defined to convert an instance \(I\) into a vector \(=(I)^{d}\), facilitating the instances to be suitably processed by a neural network.

A simple example of such an encoder could be a compilation of all the instance's numerical data into a single vector; but one can allow encodings that use some predetermined features of the instances.
2. A family of neural network mappings, denoted as \(N^{}:^{d}^{W}^{}\), is utilized. These mappings are characterized by an activation function \(\), and a fixed architecture represented by \(=[d,w_{1},,w_{L},]_{+}^{L+2}\). For any given neural network parameters \(^{W}\), this network maps an encoded instance \(^{d}\) into \(:=N^{}(,)^{}\).
3. A _squeezing activation function_, \(^{}:\), is introduced to adjust the neural network's output to the parameter space \(\). The parameter \(\) is computed by \(_{i}=_{i}+(_{i}-_{i})^{}(_{i})\) for \(i=1,,\).

The composite mapping from the instance space \(\) to the parameter space \(\) is denoted by \(_{}^{N^{},^{}}\), since the results of this study are applicable for any fixed and predetermined encoder function \(\).

The problem of learning the best neural mapping then becomes the learning problem (1) with \(h:^{W}\) defined by \(h(I,):=S(I,_{}^{N^{},^{}}( I))\). We use

\[_{N^{},^{}}^{S}:=\{S(,_{ }^{N^{},^{}}()):[0,B] ^{W}\}\]

to denote the corresponding hypothesis class (Definition 2.1).

Our first result employs linear threshold neural networks for generating algorithm parameters, inspired by their analytically tractable structure and rich expressive capabilities, as supported by findings in Khalife et al. (2023).

**Theorem 2.5**.: Consider a set \(\) of instances of a computational problem with a suite of algorithms parameterized by \(=[_{1},_{1}][_{},_{}]\), with score function \(S:[0,B]\). Suppose that, for any given instance \(I\), there exist at most \(\) polynomials on \(^{}\), each of degree at most \(\), such that within each region of \(\) where these polynomials have the same sign pattern, the function \(S(I,)\) is a polynomial on \(^{}\) with degree at most \(\). For linear threshold neural networks \(N^{}:^{d}^{W}^{}\) with a fixed architecture \(=[d,w_{1},,w_{L},]_{+}^{L+2}\), having size \(U\) and \(W\) parameters (Definition 2.4), and using a Sigmoid squeezing function, we have

\[(_{N^{},}^{S}) =(W(U(+1))).\]

In addition to this, we investigate the sample complexity associated with the use of \(\) neural networks for parameter selection.

**Theorem 2.6**.: Under the same conditions as Theorem 2.5, with ReLU neural networks \(N^{}:^{d}^{W}^{}\) having the same fixed architecture and clipped ReLU squeezing function, we have

\[(_{N^{},}^{S}) =(LW(U+)+W((+1))).\]

**Remark 2.7**.: Theorem 2.6 can be easily extended to the case where general piecewise polynomial activation functions are used instead of ReLU, with each function having at most \(p 1\) pieces and degree at most \(q 1\). By applying the same proof techniques as in the theorem above and using Theorem 7 in Bartlett et al. (2019), the pseudo-dimension changes to \((LW(p(U+))+L^{2}W(q)+W((+1) ))\). While we present the ReLU case as the main theorem due to its common use in practical applications, from a theoretical perspective, ReLU activation functions are not fundamentally different from other piecewise polynomial activation functions in the context of this paper.

It is not hard to adapt the proofs of Theorem 2.5 and Theorem 2.6 to show that if any dimension of the parameter space is all of \(\) rather than a bounded interval, the pseudo-dimension bounds will only be smaller, under the same conditions. Additionally, if \(=\{_{1},,_{r}\}\) is a finite set, the problem can be viewed as a multi-classification problem. That is, consider a neural network \(N^{}:^{d}^{W}^{r}\), where for any \(^{d}\) and \(^{W}\), \(N^{}(,)\) outputs an \(r\)-dimensional vector, and we select the parameter corresponding to the largest dimension. The pseudo-dimension of this problem is given by the following:

**Corollary 2.8**.: Under the same conditions as Theorem 2.5 and 2.6, but with \(=\{_{1},,_{r}\}\),

\[(_{N^{},}^{S})= (W(Ur))(_{N^{},}^{S})= (LW(U+r)).\]Application to branch-and-cut

### Preliminaries

**Definition 3.1** (Integer linear programming (ILP)).: Let \(m,n_{+}\) be fixed natural numbers, and let \(A^{m n},\ ^{m},\  ^{n}\). The integer linear programming problem is formulated as

\[\{^{}:A,  0,^{n}\}.\]

The most successful algorithms and solvers for integer programming problems are based on a methodology called _branch-and-cut_. In a branch-and-cut algorithm, one maintains two things in every iteration of the algorithm: 1) a current guess for the optimal solution, 2) a collection of polyhedra that are subsets of the original polyhedral relaxation of the ILP. In every iteration, one of these polyhedra are selected and the _continuous_ linear programming (LP) solution for that selected polyhedron is computed. If the solution has objective value worse than the current guess, this polyhedron is discarded from the list and the algorithm moves to the next iteration. Otherwise, if the solution is integral, the guess is updated with this integral solution and this polyhedron is removed from further consideration. If the LP solution is not integral, one decides to either add some _cutting planes_ or _branch_. In the former case, additional linear constraints are added to this polyhedron under consideration without eliminating any feasible solutions. In the latter case, one selects a fractional variable \(_{i}\) in the LP solution and partitions the current polyhedron into two polyhedra by adding constraints \(_{i} f_{i}\) and \(_{i} f_{i}+1\), where \(f_{i}\) is the value of this fractional variable. The current polyhedron is then replaced in the list by these two new polyhedra. This entire process can be tracked by a _branch-and-cut tree_ whose nodes are precisely the different polyhedra processed by the algorithm. The algorithm terminates when there are no more polyhedra left in the active list and the current guess is reported as the optimal solution. As is often done in practice, an _a priori_ bound \(B\) is set on the size of a tree; if this bound is exceeded by the algorithm at any stage, the algorithm exist early and the current guess for the solution is returned. The branch-and-cut tree size is a very good indication of how long the algorithm takes to solve the problem since the main time is spent on solving the individual LPs in the iterations of the algorithm. We will thus use the tree size as the "score" function to decide how well branch-and-cut did on any instance.

There are many different strategies to generate cutting planes in branch-and-cut Conforti et al. (2014); Nemhauser and Wolsey (1988); Schrijver (1986). We will focus on the so-called Chvatal-Gomory (CG) cutting planes and Gomory Mixed-Integer (GMI) cuts Conforti et al. (2014). There are usually several choices of such cutting planes to add (and some families are even infinite in size Conforti et al. (2014)). We wish to apply the results of Section 2 to decide which cutting plane to select so that the branch-and-cut tree size is small.

### Learnability of parameterized CG cut(s)

Let \(m,n\) be positive integers. We consider the ILP instance space \(\{(A,,):A^{m n}, ^{m},^{n}\}\), along with a fixed encoder function \(:^{d}\). A simple encoder might stack all elements of \((A,,)\) into a single vector of length \(d=mn+m+n\). We also impose the conditions that \(_{i=1}^{m}_{j=1}^{n}|A_{ij}| a\) and \(_{i=1}^{m}|_{i}| b\) for any \((A,,)\).

Following the discussion in Balcan et al. (2021), we define \(f_{}(I,)\) as the size of the branch-and-bound tree for a given ILP instance \(I\) with a CG cut parameterized by a multiplier \(^{m}\) added at the root. We interpret \(f_{}\) as a score function elaborated in Section 2.2. The piecewise structure of \(f_{}\) in its parameters is characterized by:

**Lemma 3.2** (Lemma 3.2 in Balcan et al. (2021)).: For any ILP instance \(I\), there are at most \(M:=2(a+b+n)\) hyperplanes partitioning the parameter space \(^{m}\) into regions where \(f_{}(I,)\) remains constant for all \(\) within each region.

Applying Theorem 2.5 and Theorem 2.6 to \(f_{}\) yields these pseudo-dimension bounds:

**Proposition 3.3**.: Under the same conditions as Theorem 2.5 and 2.6, with the score function \(f_{}\),

\[(_{N^{},}^{f_{}}) =(W(UM)),\] \[(_{N^{},}^{f_{}}) =(LW(U+m)+W M).\]Extending this to adding \(k\) CG cuts sequentially, we define \(f^{k}_{}(I,(_{1},,_{k}))\) as the branch-and-bound tree size after adding a sequence of \(k\) CG cuts parameterized by \(_{1},,_{k}\) at the root for a given ILP instance \(I\). The piecewise structure of \(f^{k}_{}\) in its parameters is given by:

**Lemma 3.4** (Lemma 3.4 in Balcan et al. (2021)).: _For any ILP instance \(I\), there are \((k2^{k}M)\) multivariate polynomials with \(mk+k(k-1)/2\) variables and degree at most \(k\) partitioning the parameter space \(^{mk+k(k-1)/2}\) into regions where \(f^{k}_{}(I,(_{1},,_{k}))\) remains constant for all \((_{1},,_{k})\) within each region._

Accordingly, the pseudo-dimension bounds are

**Proposition 3.5**.: Under the same conditions as Theorem 2.5 and 2.6, with the score function \(f^{k}_{}\),

\[(^{f^{k}_{}}_{N^{},})=(W(UM)+Wk),\] \[(^{f^{k}_{}}_{N^{ },})=(LW(U+mk)+W M +Wk).\]

### Learnability of cutting plane(s) from a finite set

The selection of an optimal cut from an infinite pool of candidate cuts, as discussed in Proposition 3.3 and Proposition 3.5, is often difficult and inefficient in practice. Consequently, a popular way is to select cuts based on information from the simplex tableau (such as GMI cuts), as well as some combinatorial cuts, which inherently limit the number of candidate cuts considered to be finite.

Suppose we have a finite set of cuts \(\), and we define \(f_{}(I,c)\) as the branch-and-bound tree size after adding a cut \(c\) at the root for a given ILP instance \(I\). Then Corollary 2.8 implies

**Proposition 3.6**.: Under the same conditions as Theorem 2.5 and 2.6, with the score function \(f_{}\),

\[(^{f_{}}_{N^{},})=(W(U||)) (^{f_{}}_{N^{}, })=(LW(U+||)).\]

### Learnability of cut selection policy

One of the leading open-source solvers, SCIP Gamrath et al. (2020), uses cut selection methodologies that rely on combining several auxiliary score functions. For a finite set of cutting planes \(\), instead of directly using a neural network for selection, this model selects \(c^{*}_{c}_{i=1}^{}_{i} _{i}(c,I)\) for each instance \(I\). Here, \(_{i}\) represents different heuristic scoring functions that assess various aspects of a cut, such as "Efficacy" Balas et al. (1996) and "Parallelism" Achterberg (2007), for a specific instance \(I\), and the coefficients \(^{}\) are tunable weights for these scoring models. Since \(\) is considered to be finite, the above optimization problem is solved through enumeration. The authors in Turner et al. (2023) have experimentally implemented the idea of using a neural network to map instances to weights. We provide an upper bound on the pseudo-dimension in the following proposition of this learning problem.

**Proposition 3.7**.: Under the same conditions as Theorem 2.5 and 2.6, let \(f_{S}(I,)\) denote the size of the branch-and-bound tree for \(I\) after adding a cutting plane determined by the weighted scoring model parameterized by \(^{}\). The pseudo-dimension bounds are given by:

\[(^{f_{}}_{N^{},}) =(W(U||)),\] \[(^{f_{}}_{N^{},}) =(LW(U+)+W(||)).\]

## 4 Discussions and open questions

In our study, we concentrated on adding CG cuts solely at the root of the branch-and-cut tree. However, devising a strategy that generates high quality cutting planes while being efficient across the entire branch-and-cut tree poses a significant and intriguing challenge for future research. Further, our theoretical findings are applicable to any encoder that maps instances into Euclidean spaces. Hence, utilizing a fixed encoder capable of converting ILPs with different number of constraints into a same Euclidean space can in principle enable the training of a unified neural network to generate cutting planes across the branch-and-cut tree. Moreover, an effective encoder could improve the neural network's performance beyond the one achieved with the basic stacking encoder used in our paper.

The neural network training problem (2) also requires further study. We used an RL approach (see Appendix A) to update the neural network parameters and minimize the average tree size for ILP instances sampled from a given distribution. However, this method does not guarantee convergence to optimal parameters, and relies heavily on the exploratory nature of the RL algorithm. For ILP distributions where random exploration of Chvatal multipliers is unlikely to yield smaller tree sizes, the RL algorithm may struggle to identify an effective parameter setting. Developing a more efficient and robust training methodology would greatly improve the practical value of our work.