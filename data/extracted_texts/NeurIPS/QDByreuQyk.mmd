# Nearly Tight Bounds For

Differentially Private Multiway Cut

 Mina Dalirrooyfard

Machine Learning Research

Morgan Stanley

mina.dalirrooyfard@morganstanley.com

&Slobodan Mitrovic

Department of Computer Science

UC Davis

smitrovic@ucdavis.edu

&Yuriy Nevmyvaka

Machine Learning Research

Morgan Stanley

yuriy.nevmyvaka@morganstanley.com

These authors contributed equally to this work

###### Abstract

Finding min \(s\)-\(t\) cuts in graphs is a basic algorithmic tool, with applications in image segmentation, community detection, reinforcement learning, and data clustering. In this problem, we are given two nodes as terminals and the goal is to remove the smallest number of edges from the graph so that these two terminals are disconnected. We study the complexity of differential privacy for the min \(s\)-\(t\) cut problem and show nearly tight lower and upper bounds where we achieve privacy at no cost for running time efficiency. We also develop a differentially private algorithm for the multiway \(k\)-cut problem, in which we are given \(k\) nodes as terminals that we would like to disconnect. As a function of \(k\), we obtain privacy guarantees that are exponentially more efficient than applying the advanced composition theorem to known algorithms for multiway \(k\)-cut. Finally, we empirically evaluate the approximation of our differentially private min \(s\)-\(t\) cut algorithm and show that it almost matches the quality of the output of non-private ones.

## 1 Introduction

Min \(s\)-\(t\) cut, or more generally Multiway \(k\)-cut, is a fundamental problem in graph theory and occupies a central place in combinatorial optimization. Given a weighted graph and \(k\) terminals, the multiway \(k\)-cut problem asks to divide the nodes of the graph into \(k\) partitions such that (1) each partition has exactly one terminal, and (2) the sum of the weights of edges between partitions, known as the _cut value_, is minimized . Multiway \(k\)-cut is a clustering method used in a large variety of applications, including energy minimization  and image segmentation  in vision, reinforcement learning , community detection  and many other learning and clustering tasks .

The above applications are carried on large data sets, and more and more frequently those applications are executed on sensitive data. Hence, designing algorithms that preserve the privacy of data has been given substantial attention recently. A widely used and conservative standard of data privacy is _differential privacy (DP)_ developed by Dwork  which indicates that an algorithm is differentially private if, given two _neighboring_ databases, it produces statistically indistinguishable outputs. When DP is applied to graph data, two variants of DP were introduced : in edge DP, two neighboring graphs differ in only one edge, and in node DP, two graphs are neighboring if one graph is obtainedfrom removing one node and all the edges incident to that node from the other graph. In this work, we focus on the edge DP. In a large fraction of cases, the nodes of a network are public but the edge attributes - which are the relationships between nodes - are private.

For many clustering algorithms such as \(k\)-means, \(k\)-median, and correlation clustering, tight or near-tight differentially private algorithms have already been developed . In particular, tight algorithms for differentially private _min-cut_ has been long known , where the min-cut problem asks to divide the graph into two partitions such that the cut value is minimized; in the min-cut problem, there is no restriction that two nodes must be on different sides of the cut. Even though min-cut and min \(s\)-\(t\) cut might seem similar, the algorithm techniques for min-cut do not extend to min \(s\)-\(t\) cut. A glimpse of this difference can be seen in the fact that there exist polynomially many min-cuts in any graph, but there can be exponentially many min \(s\)-\(t\) cuts for fixed terminals \(s\) and \(t\)*.

Footnote *: Take \(n-2\) nodes \(v_{1},...,v_{n-2}\) in addition to \(s\) and \(t\), and add \(v_{i}\) to both \(s\) and \(t\) for all \(i\). Suppose the weight of all edges is \(1\). There are \(2^{n-2}\) min \(s\)-\(t\) cuts, as each min \(s\)-\(t\) cut should remove exactly one edge from each \(s-v_{i}-t\) path; either \((s,v_{i})\) or \((v_{i},t)\) is fine. In this example, there are \(n-2\) min cuts: for each \(i\), remove edges \((v_{i},s)\) and \((v_{i},t)\) and this would be a cut of size \(2\). Moreover, one can show that the number of min-cuts is polynomial for any graph, there are at most \(\); please see .

Our Results and Technical OverviewIn this paper, we provide the edge-differentially private algorithm for min \(s\)-\(t\) cut and prove that it is almost tight. To the best of our knowledge, this is the first DP algorithm for the min \(s\)-\(t\) cut problem.

Our first result is an \(\)-private algorithm for min \(s\)-\(t\) cut with \(O()\) additive error.

**Theorem 1.1**.: _For any \(>0\) and for weighted undirected graphs, there is an algorithm for min \(s\)-\(t\) cut that is \((,0)\)-private and with high probability returns a solution with additive error \(O()\). Moreover, the running time of this private algorithm is the same as the running time of the fastest non-private one._

Moreover, our proof of Theorem 1.1 extends to when an edge-weight changes by at most \(\) in two neighboring graphs. In that case, our algorithm is \((,0)\)-private with \(O(n/)\) additive error.

Furthermore, our approach uses the existing min \(s\)-\(t\) cut algorithms in a black-box way. More precisely, our method changes the input graph in a specific way, i.e., it adds \(2(n-1)\) edges with special weight, and the rest of the processing is done by an existing algorithm. In other words, our approach automatically transfers to any computation setting - centralized, distributed, parallel, streaming - as long as there is a non-private min \(s\)-\(t\) cut for that specific setting. The main challenge with this approach is showing that it actually yields privacy. Perhaps surprisingly, our approach is almost optimal in terms of the approximation it achieves. Specifically, we complement our upper-bound by the following lower-bound result.

**Theorem 1.2**.: _Any \((,)\)-differential private algorithm for min \(s\)-\(t\) cut on \(n\)-node graphs requires expected additive error of at least \(n/20\) for any \( 1\) and \( 0.1\)._

Note that Theorem 1.2 holds regardless of the graph being weighted or unweighted. Given an unweighted graph \(G\), let the cut \(C_{s}(G)\) be the \(s\)-\(t\) cut where node \(s\) is in one partition and all the other nodes are in the other partition. The algorithm that always outputs \(C_{s}(G)\) is private, and has the additive error of \(O(n)\) since the value of \(C_{s}(G)\) is at most \(n-1\) in unweighted graphs. Thus one might conclude that we do not need Theorem 1.1 for a private algorithm, as one cannot hope to do better than \(O(n)\) additive error by Theorem 1.2. However, for weighted graphs, this argument fails when \(C_{s}(G)\) has a very large value due to weighted edge incident to \(s\), or when a graph has parallel unweighted edges. In Section 5, we show an application in which one computes a weighted min \(s\)-\(t\) cut while as the input receiving an unweighted graph. We further evaluate our theoretical results on private min \(s\)-\(t\) cut in Section 5 and show that despite our additive approximation, our approach outputs a cut with the value fairly close to the min \(s\)-\(t\) cut. Moreover, we show that it is in fact more accurate than more natural heuristics (such as outputting \(C_{s}(G)\)) for a wide range of the privacy parameter \(\).

Theorem 1.1 and Theorem 1.2 depict an interesting comparison to differentially private min cut algorithms. Gupta et al  provide an \(\)-private algorithm with \(O( n/)\) additive error for min cut and shows that any \(\)-private algorithm requires \(( n)\) additive error. The large gap between \(\)-private algorithms for the min cut and min \(s\)-\(t\) cut could provide another reason one cannot easily extend algorithms for one to the other problem.

While finding (non-private) Min \(s\)-\(t\) cut is polynomially solvable using max-flow algorithms [1; 7], the (non-private) Multiway \(k\)-cut problem is NP-hard for \(k 3\) and finding the best approximation algorithm for it has been an active area of research [10; 6; 2; 24]. The best approximation factor for the Multiway cut problem is \(1.2965\) and the largest lower bound is \(1.20016\)[24; 3]. From a more practical point of view, there are a few simple \(2\)-approximation algorithm for multiway \(k\)-cut such as greedy splitting  which splits one partition into two partitions in a sequence of \(k-1\) steps. Another simple \(2\)-approximation algorithm by  is the following: (1) if the terminals of the graph are \(s_{1},,s_{k}\), for each \(i\), contract all the terminals except \(s_{i}\) into one node, \(t_{i}\); (2) then run min \(s\)-\(t\) cut on this graph with terminals \(s_{i}\), \(t_{i}\); (3) finally output the union of all these \(k\) cuts. This algorithm reduces multiway \(k\)-cut into \(k\) instances of min \(s\)-\(t\) cut. Hence it is easy to see that if we use a \(\)-private min \(s\)-\(t\) cut with additive error \(r\), we get a \(k\)-private multiway \(k\)-cut algorithm with additive error \(kr\) and multiplicative error \(2\). In a similar way one can make the greedy splitting algorithm private with same error guarantees. Using _advanced composition_[15; 16] can further reduce this dependency polynomially at the expense of private parameters. We design an algorithm that reduces the dependency on \(k\) of the private multiway cut algorithm to \( k\), which is exponentially smaller dependence than applying the advanced composition theorem. We obtain this result by developing a novel \(2\)-approximation algorithm for multiway \(k\)-cut that reduces this problem to \( k\) instances of min \(s\)-\(t\) cut. Our result is represented in Theorem 1.3 and we defer the proof to supplementary materials. We note that the running time of the Algorithm of Theorem 1.3 is at most \(O( k)\) times the private min \(s\)-\(t\) cut algorithm of Theorem 1.1.

**Theorem 1.3**.: _For any \(>0\), there exists an \((,0)\)-private algorithm for multiway \(k\)-cut on weighted undirected graphs that with probability \(1-1/n\) at least returns a solution with value \(2 OPT+O(n k/)\), where \(OPT\) is the value of the optimal non-private multiway \(k\)-cut._

Finally, we emphasize that all our private algorithms output cuts as opposed to only their value. For outputting a number \(x\) privately, the standard approach is to add Laplace noise \((1/)\) to get an \(\)-private algorithm with additive error at most \(O(1/)\) with high probability.

Additional implications of our results.First, the algorithm for Theorem 1.1, i.e., Algorithm 1, uses a non-private min \(s\)-\(t\) cut algorithm in a black-box manner. Hence, Algorithm 1 essentially translates to any computation setting without asymptotically increasing complexities compared to non-private algorithms. Second, Algorithm 2 creates (recursive) graph partitions such that each vertex and edge appears in \(O( k)\) partitions. To see how it differs from other methods, observe that the standard splitting algorithm performs \(k-1\) splits, where some vertices appear in each of the split computations. There are also LP-based algorithms for the multiway \(k\)-cut problem, but to the best of our knowledge, they are computationally more demanding than the \(2\)-approximate greedy splitting approach. As a consequence, in the centralized and parallel settings such as PRAM, in terms of total work, Algorithm 2 depends only logarithmically on \(k\) while the popular greedy splitting algorithm has a linear dependence on \(k\). To the best of our knowledge, no existing method matches these guarantees of Algorithm 2.

## 2 Preliminaries

In this section, we provide definitions used in the paper. We say that an algorithm \(\) outputs an \((,)\)-approximation to a minimization problem \(P\) for \( 1, 0\), if on any input instance \(I\), we have \(OPT(I)(I)+\) where \((I)\) is the output of \(\) on input \(I\) and \(OPT(I)\) is the solution to problem \(P\) on input \(I\). We refer to \(\) and \(\) as the multiplicative and additive errors respectively.

Graph CutsWe use \(uv\) to refer to the edge between nodes \(u\) and \(v\). Let \(G=(V,E,w_{G})\) be a weighted graph with node set \(V\), edge set \(E\) and \(w_{G}:V^{2}_{ 0}\), where for all edges \(uv E\), \(w_{G}(uv)>0\), and for all \(uv E\), \(w_{G}(uv)=0\). For any set of edges \(C\), let \(w_{G}(C)=_{e C}w_{G}(e)\). If removing \(C\) disconnects the graph, we refer to \(C\) as a cut set. When \(C\) is a cut set, we refer to \(w_{G}(C)\) as the weight or value of \(C\). We drop the subscript \(G\) when it is clear from the context. For subsets \(A,B V\), let \(E(A,B)\) be the set of edges \(uv=e E\) such that \(u A\) and \(v B\).

**Definition 2.1** (Multiway \(k\)-cut).: _Given \(k\) terminals \(s_{1},,s_{k}\), a multiway \(k\)-cut is a set of edges \(C E\) such that removing the edges in \(C\) disconnects all the terminals. More formally, there exists \(k\)-disjoint node subsets \(V_{1},,V_{k} V\) such that \(s_{i} V_{i}\) for all \(i\), \(_{i=1}^{k}V_{i}=V\), and \(C=_{i,j\{1,,k\}}E(V_{i},V_{j})\). The Multiway \(k\)-cut problem asks for a Multiway \(k\)-cut with the lowest value._

In our algorithms, we use the notion of _node contractions_ which we formally define here.

**Definition 2.2** (Node contractions).: _Let \(Z V\) be a subset of nodes of the graph \(G=(V,E,w_{G})\). By contracting the nodes in \(Z\) into node \(t^{}\), we add a node \(t^{}\) to the graph and remove all the nodes in \(Z\) from the graph. For every \(v V Z\), the weight of the edge \(t^{}v\) is equal to \(_{z Z}w_{G}(vz)\). Note that if none of the nodes in \(Z\) has an edge to \(v\), then there is no edge from \(t^{}\) to \(v\)._

Differential PrivacyWe formally define neighboring graphs and differential private algorithms.

**Definition 2.3** (Neighboring Graphs).: _Graphs \(G=(V,E,w)\) and \(G^{}=(V,E^{},w^{})\) are called neighboring if there is \(uv V^{2}\) such that \(|w_{G}(uv)-w_{G^{}}(uv)| 1\) and for all \(u^{}v^{} uv\), \(u^{}v^{} V^{2}\), we have \(w_{G}(u^{}v^{})=w_{G^{}}(u^{}v^{})\)._

**Definition 2.4** (Differential Privacy).: _A (randomized) algorithm \(\) is \((,)\)-private (or \((,)\)-DP) if for any neighboring graphs \(G\) and \(G^{}\) and any set of outcomes \(O Range()\) it holds_

\[[(G) O] e^{}[(G^{ }) O]+.\]

_When \(=0\), algorithm \(\) is pure differentially private, or \(\)-private._

**Definition 2.5** (Basic composition [14; 13]).: _Let \(_{1},,_{t}>0\) and \(_{1},,_{t} 0\). If we run \(t\) (possibly adaptive) algorithms where the \(i\)-th algorithm is \((_{i},_{i})\)-DP, then the entire algorithm is \((_{1}++_{t},_{1}++_{t})\)-DP._

Exponential distribution.For \(>0\), we use \(X()\) to denote that a random variable \(X\) is drawn from the exponential distribution with parameter \(\). In our proofs, we use the following fact.

**Fact 2.1**.: _Let \(X()\) and \(z 0\). Then \([X z]=(- z).\)_

Laplace distribution.We use \(X(b)\) to denote that \(X\) is a random variable is sampled from the Laplace distribution with parameter \(b\).

**Fact 2.2**.: _Let \(X(b)\) and \(z>0\). Then_

\[[X>z]=(-)\ [|X|>z]=(-).\]

**Fact 2.3**.: _Let \(X,Y()\). Then, the distribution \(X-Y\) follows \((1/)\)._

We use \(f_{}^{b}\) to denote the cumulative distribution function of \((b)\), i.e., \(f_{}^{b}(x)=(-)\). We use \(F_{}^{b}\) to denote the cumulative distribution function of \((b)\), i.e.,

\[F_{}^{b}(x)=()& x 0\\ 1-(-)&\]

When it is clear from the context what \(b\) is, we will drop it from the superscript.

**Claim 1**.: _For any \(t\) and \( 0\) it holds_

\[}^{1/}(t+)}{F_{}^{1/}(t)}  e^{}}^{1/}(t+)}{f_{}^{1/}(t)}  e^{}.\]

The proof of this claim is standard and, for completeness, appears in the Supplementary material.

## 3 DP Algorithm for Min \(s\)-\(t\) Cut

In this section, we prove Theorem 1.1. Our DP min \(s\)-\(t\) cut algorithm is quite simple and is provided as Algorithm 1. The approach simply adds an edge between \(s\) and every other node, and an edge between \(t\) and every other node. These edges have weight drawn from \(()\). The challenging part is showing that this simple algorithm actually preserves privacy. Moreover, when we couple the approximation guarantee of Algorithm 1 with our lower-bound shown in the Supplementary material, then up to a \(1/\) factor Algorithm 1 yields optimal approximation guarantee.

_Remark:_ Technically, there might be multiple min \(s\)-\(t\) cuts that can be returned on Line 4 of Algorithm 1. We discuss that, without loss of generality, it can be assumed that there is a unique one. We elaborate on this in the Supplementary material.

### Differential Privacy Analysis

Before we dive into DP guarantees of Algorithm 1, we state the following claim that we use in our analysis. Its proof is given in the Supplementary material.

**Lemma 3.1**.: _Suppose \(x\) and \(y\) are two independent random variables drawn from \((1/)\). Let \(,,\) be three fixed real numbers, and let \( 0\). Define_

\[P(,,)}}}{{=}} [x<,y<,x+y<].\]

_Then, it holds that_

\[1 e^{4 }.\]

**Lemma 3.2**.: _Let \(\) be the edge-weight difference between two neighboring graphs. Algorithm 1 is \((4,0)\)-DP._

Proof.: Let \(G\) and \(G^{}\) be two neighboring graphs. Let edge \(e=uv\) be the one for which \(w_{e}\) in \(G\) and \(G^{}\) differ; recall that it differs by at most \(\). To analyze the probability with which Algorithm 1 outputs the same cut for input \(G\) as it outputs for input \(G^{}\), we first sample all the \(X_{s,x}\) and \(X_{t,x}\) for \(x V\{s,t,u,v\}\). Intuitively, the outcomes of those random variables are not crucial for the difference between outputs of Algorithm 1 invoked on \(G\) and \(G^{}\). We now elaborate on that.

Consider **all** the \(s\)-\(t\) cuts - not only the minimum ones - in \(G\) before \(X_{s,u}\), \(X_{s,v}\), \(X_{t,u}\) and \(X_{t,v}\) are sampled; for instance, assume for a moment that those four random variables equal \(0\). Let \(_{}(G)\) be all those cuts sorted in a non-decreasing order with respect to their weight. Observe that \(_{}(G)=2^{n-2}\). As we will show next, although there are exponentially many cuts, we will point to only four of them as crucial for our analysis. This will come in very handy in the rest of this proof. We now partition \(_{}(G)\) into four groups based on which \(u\) and \(v\) are on the same side of the cut as \(s\). Let \(_{u}(G)\) be the subset of \(_{}(G)\) for which \(u\) is on the same side of a cut as \(s\) while \(v\) is on the same side of the cut as \(t\). Analogously we define \(_{v}(G)\). We use \(_{u,v}(G)\) to represent the subset of \(_{}(G)\) for which \(s\), \(u\), and \(v\) are all on the same side. Finally, by \(_{}(G)\) we refer to the subset of \(_{}(G)\) for which \(t\), \(u\), and \(v\) are all on the same side.

Let \(C_{u}\), \(C_{v}\), \(C_{u,v}\), and \(C_{}\) be the min cuts in \(_{u}(G)\), \(_{v}(G)\), \(_{u,v}(G)\), and \(_{}(G)\), respectively, before \(X_{s,u}\), \(X_{s,v}\), \(X_{t,u}\) and \(X_{t,v}\) are sampled. It is an easy observation that sampling \(X_{s,u}\), \(X_{s,v}\), \(X_{t,u}\) and \(X_{t,v}\) and altering the weight of the edge \(e\) changes the weight of all the cuts in \(_{u}(G)\) by the same amount. This same observation also holds for \(_{v}(G)\), \(_{u,v}(G)\) and \(_{}(G)\). This further implies that the min \(s\)-\(t\) cut of \(G\) after \(X_{s,u}\), \(X_{s,v}\), \(X_{t,u}\) and \(X_{t,v}\) are sampled will be among \(C_{u}\), \(C_{v}\), \(C_{u,v}\), and \(C_{}\). Observe that these four cuts are also the minimum-weight cuts in \(_{u}(G^{})\), \(_{v}(G^{})\), \(_{u,v}(G^{})\), and \(_{}(G^{})\), respectively.

[MISSING_PAGE_FAIL:6]

### Approximation Analysis

Observe that showing that Algorithm 1 has \(O(n/ n)\) additive error is straightforward as a random variable drawn from \((b)\) is upper-bounded by \(O( n/b)\) whp. Lemma 3.3 proves the \(O(n/)\) bound. On a very high level, our proof relies on the fact that for a sufficiently large constant \(c\), it holds that only _a small fraction_ of random variables \(X_{i,j}\) exceeds \(c/\); this fraction is \(e^{-c}\).

**Lemma 3.3**.: _With probability at least \(1-n^{-2}\), Algorithm 1 outputs a min \(s\)-\(t\) cut with additive error \(O(n/)\)._

Proof.: Let \(G\) be an input graph to Algorithm 1 and let \(\) be the graph after the edges on Line 2 are added. \(\) contains \(2(n-1)\) more edges than \(G\). This proof shows that with probability at least \(1-n^{-2}\), the total sum of weights of all these edges is \(O(n/)\).

We first provide a brief intuition. For the sake of it, assume \(=1\). Whp, each \(X_{i,j}\) weighs at most \(5 n\). Also, consider only those \(X_{i,j}\) such that \(X_{i,j} 2\); the total sum of those random variables having weight less than \(2\) is \(O(n)\). It is instructive to think of the interval \([2,5 n]\) being partitioned into buckets of the form \([2^{i},2^{i+1})\). Then, the value of each edge added by Algorithm 1 falls into one of the buckets. Now, the task becomes upper-bounding the number \(c_{i}\) of edges in bucket \(i\). That is, we let \(Y_{s,u}^{i}=1\) iff \(X_{s,u}[2^{i},2^{i+1})\), which results in \(c_{i}=_{u V}(Y_{s,u}^{i}+Y_{t,u}^{i})\). Hence, \(c_{i}\) is a sum of 0/1 independent random variables, and we can use Chernoff bound to argue about its concentration.

There are two cases. If \([c_{i}]\) is more than \(O( n)\), then \(c_{i} O([c_{i}])\) by the Chernoff bound. If \([c_{i}] o( n)\), e.g., \([c_{i}]=O(1)\), we can not say that with high probability \(c_{i} O([c_{i}])\). Nevertheless, it still holds \(c_{i} O( n)\) whp.

Edges in \(E() E(G)\) with weights more than \(5\).Let \(Y()\). By Fact 2.1, \([Y>5]=(-5 n)=n^{-5}\). Since each \(X_{s,v}\) and \(X_{t,v}\) is drawn from \(()\), we have that for \(n 2\) with probability at least \(1-n^{-3}\) each of the edges in \(E() E(G)\) has weight at most \(5\).

Edges in \(E() E(G)\) with weights at most \(5\).Observe that the sum of the weights of all the edges in \(E() E(G)\) having weight at most \(2/\) is \(O(n/)\). Hence, we focus on the edge weights in the interval \([,5]\). We partition this interval into \(O( n)\) subintervals where each, except potentially the last one, of the form \([2^{i}/,2^{i+1}/)\).

Let \(Y()\). We have

\[[Y[2^{i}/,2^{i+1}/)][Y 2^{i}/ ]=e^{-2^{i}}.\]

Let \(c_{i}\) be the number of random variables among \(X_{s,v}\) and \(X_{t,v}\) whose values belong to \([2^{i}/,2^{i+1}/)\). Then, we derive

\[[c_{i}]}}}}},\]

where to obtain the inequalities, we use that \(i 1\). By the Chernoff bound, for appropriately set constant \(b>0\), it holds that \(c_{i} b( n,})\) with probability at least \(1-n^{-5}\). By the union bound, this claim holds for all the \(O( n)\) partitions simultaneously and with probability at least \(1-n^{-4}\). Hence, with probability at least \(1-n^{-4}\), the sum of the edge-weights in \(E() E(G)\) across all the \(O( n)\) partitions is at most

\[_{i=1}^{(5 n)}b( n,}) }{} n)}{}+2b_{i 0} }= n+8b O(),\]

where we used \(( n,2n/2^{2i}) n+2n/2^{2i}\). By taking the union bound over both cases, we have that with probability at least \(1-n^{-2}\) it holds that the sum of the weights of all edges added to \(G\) is \(O(n/)\). Hence, with probability \(1-n^{-2}\) at least, the min \(s\)-\(t\) cut in \(\) has weight at most the min \(s\)-\(t\) cut in \(G\) plus \(O(n/)\). This completes our analysis.

DP algorithm for multiway cut

In this section we show our approach for proving Theorem 1.3 restated below.

**Theorem 1.3**.: _For any \(>0\), there exists an \((,0)\)-private algorithm for multiway \(k\)-cut on weighted undirected graphs that with probability \(1-1/n\) at least returns a solution with value \(2 OPT+O(n k/)\), where \(OPT\) is the value of the optimal non-private multiway \(k\)-cut._

We first develop an algorithm for the non-private multiway \(k\)-cut problem and then use it to prove Theorem 1.3. The algorithm we design invokes a min \(s\)-\(t\) cut procedure \(O( k)\) times.

### Solving Multiway Cut in \( k\) Rounds of Min \(s\)-\(t\) Cut

Our new myltiway \(k\)-cut algorithm is presented in Algorithm 2. Algorithm 2 first finds a cut that separates \(s_{1},,s_{k^{}}\) from \(s_{k^{}+1},,s_{k}\). This separation is obtained by contracting \(s_{1},,s_{k^{}}\) into a single node called \(s\), contracting \(s_{k^{}+1},,s_{k}\) into a single node called \(t\), and then running min \(s\)-\(t\) cut on this new graph. Afterward, each of the two partitions is processed separately by recursion, and the algorithm outputs the union of the outputs on each of the two partitions.

``` Input :A weighted graph \(G=(V,E,w)\) Terminals \(s_{1},,s_{k}\) A min \(s\)-\(t\) cut algorithm \(\) that with probability \(1-\) is \((1,e(n))\)-approximate
1if\(k=1\)then
2return\(G\) as one partition
3else
4 Let \(k^{}=\). Let \(\) be the graph obtained by contracting \(s_{1},,s_{k^{}}\) into \(s\) and contracting \(s_{k^{}+1},,s_{k}\) into \(t\). Run algorithm \(\) on \(\) with terminals \(s,t\) to obtain cut \(C\) with partitions \(_{1}\) and \(_{2}\). For \(i=1,2\), let \(G_{i}\) be the graph obtained from \(_{i}\) by reversing the contraction of terminal nodes. Let \(C_{1}\) be the output of Algorithm 2 on \(G_{1}\) and \(C_{2}\) be the output of Algorithm 2 on \(G_{2}\). return\(C_{1} C_{2} C\). ```

**Algorithm 2** Given a weighted graph \(G\), this algorithm outputs a multiway \(k\)-cut.

We first show that in each recursion level of the algorithm, we can run the min \(s\)-\(t\) cut step (Line 6) of all the instances in that level _together_ as one min \(s\)-\(t\) cut, so that we only run \(O( k)\) many min \(s\)-\(t\) cuts.

**Lemma 4.1**.: _Algorithm 2 is a reduction of multiway \(k\)-cut on \(n\)-node graphs to \(O( k)\) many instances of min \(s\)-\(t\) cut on \(O(n)\)-node graphs. Moreover, if \(T(,n,m)\) is the running time of \(\) on an \(n\)-node \(m\)-edge graphs, Algorithm 2 runs in \(O( k[T(,n)+m])\)._

Proof.: Let \(G\) be the input graph and suppose that it has \(n\) nodes. If we consider the recursion tree of the algorithm on \(G\), we can perform the min \(s\)-\(t\) cut step (Line 6) of _all of the subproblems on one level_ of the recursion tree by a single min \(s\)-\(t\) cut invocation. To see this, assume that \(G_{1}^{r^{}},,G_{r}^{r^{}}\) are in level \(r^{}\) of the recursion tree for \(r=2^{r^{}-1}\), and for sake of simplicity, assume that \(k\) is a power of \(2\). Let \(s_{i},t_{i}\) be the two terminals in \(_{i}^{r^{}}\) (defined in Line 5) for \(i\{1,,r\}\). We can think of the collection of graphs \(_{1}^{r^{}},,_{r}^{r^{}}\) as one graph \(G^{r^{}}\). Contract \(s_{1},,s_{r}\) into \(s\), and contract \(t_{1},,t_{r}\) into \(t\), to obtain the graph \(^{r^{}}\) from \(G^{r^{}}\). Then performing a min \(s\)-\(t\) cut algorithm on \(^{r^{}}\) is equivalent to performing min \(s\)-\(t\) cut on each of \(G_{i}^{r^{}}\), as there is no edge between \(G_{i}^{r^{}}\) and \(G_{j}^{r^{}}\) for any \(i,j\). Note that since \(G_{1}^{r^{}},,G_{r}^{r^{}}\) are disjoint and are subgraphs of \(G\), \(^{r^{}}\) has at most \(n\) nodes. Moreover, the node contraction processes in each recursion level takes at most \(O(m)\) as each edge is scanned at most once.

To prove that Algorithm 2 outputs a multiway \(k\)-cut that is a \(2\)-approximation of the optimal multiway \(k\)-cut, we first present a few definitions. Given graph \(G\) with node set \(V\), a _partial_ multiway \(k\)-cut is a set of disjoint node subsets \(V_{1},,V_{k}\) such that for each \(i\), terminal \(s_{i} V_{i}\). Note that \(V_{1} V_{k}\) is not necessarily the whole \(V\). For a set of nodes \(S V\), let \(_{G}(S)\) be the sum of the weights of the edges with exactly one endpoint in \(S\), i.e., the sum of the weights of the edges in \(E(S,V S)\). Let \(w(E(S))\) be the sum of the weights of the edges with both endpoints in \(S\). Theorem 4.1 is the main result in this section and we state the proof of it the Supplementary material

**Theorem 4.1**.: _Let \(e(n)\) be a convex function and \(G=(V,E,w)\) be a weighted graph. Let \(\) be an algorithm that with probability \(1-\) outputs a \((1,e(n))\)-approximate min \(s\)-\(t\) cut for \(e(n)=cn/\) for constants \(>0\), \(c 0\). Then, for any graph with terminals \(s_{1},,s_{k}\) and any partial multiway \(k\)-cut \(V_{1},,V_{k}\) of it, Algorithm 2 outputs a multiway cut that with probability \(1- O( k)\) has a value at most \(_{i=1}^{k}(V_{i})+w(E())+O(e(n))\) where \(=V[_{i=1}^{k}V_{i}]\)._

A direct Corollary of Theorem 4.1 is a \(2\)-approximation algorithm of the optimal multiway \(k\)-cut. Recall that the novelty of this algorithm is in using \(O( k)\) many min \(s\)-\(t\) cut runs as opposed to \(O(k)\) which is depicted in Lemma 4.1.

**Corollary 4.1**.: _Given a graph \(G\), integer \(k 2\) and any exact min \(s\)-\(t\) cut algorithm, Algorithm 2 returns a multiway \(k\)-cut that is a \(2\)-approximation of the optimal multiway \(k\)-cut._

Proof.: Let \(\) be an exact \(s\)-\(t\)-cut algorithm that is part of the input to Algorithm 2. So we have \(e(n)=0\). Let \(C_{ALG}\) be the output of Algorithm 2. By Theorem 4.1, \(C_{ALG}\) is a multiway \(k\)-cut. Let \(C_{OPT}\) be the optimal multiway \(k\)-cut with partitions \(V_{1},,V_{k}\). Note that there are no nodes that are not partitioned, and hence \(w(E())=0\). So by Theorem 4.1, we have that \(w(C_{ALG})_{i=1}^{k}_{G}(V_{i})=2w(C_{OPT})\). 

### Differentially Private Multiway Cut

Our Differentially Private Multiway cut algorithm is essentially Algorithm 2 where we use a differentially private min \(s\)-\(t\) cut algorithm (such as Algorithm 1) in Line 6 to compute a differentially private multiway \(k\)-cut. This concludes the approach for Theorem 1.3 which is a direct corollary of Theorem 4.2 below.

**Theorem 4.2**.: _Let \(>0\) be a privacy parameter, \(G\) an \(n\)-node graph, and \(\) an \(\)-DP algorithm that with probability at least \(1-1/n^{2}\) computes a min \(s\)-\(t\) cut with additive error \(O(e(n)/)\) on any \(n\)-node graph. Then, Algorithm 2 is a \(( k)\)-DP algorithm that with probability at least \(1-O( k) n^{-2}\) finds a multiway \(k\)-cut with multiplicative error \(2\) and additive error \(O( k e(n)/)\)._

Proof.: The error guarantees are a direct result of Theorem 4.1 and Lemma 3.3. Hence here we prove the privacy guarantee. Consider the recursion tree of Algorithm 2 which has depth \(O( k)\). As proved by Lemma 4.1, each level of the recursion tree consists of running algorithm \(\) on disjoint graphs, and so each level is \(\)-DP. By basic composition (see Definition 2.5), since Algorithm 2 is a composition of \(O( k)\) many \(\)-DP mechanisms, it is \(( k)\)-DP. 

## 5 Empirical Evaluation

We perform an empirical evaluation on the additive error of Algorithm 1 and validate our theoretical bounds.

Set-up.As our base graph, we use email-Eu-core network  which is an undirected unweighted \(1,005\)-node \(25,571\)-edge graph. This graph represents email exchanges, where two nodes \(u\) and \(v\) are adjacent if the person representing \(u\) has sent at least one email to the person representing \(v\) or vice-versa. However, this graph does not account for multiple emails sent between two individuals. To make the graph more realistic, we add random weights to the edges from the exponential distribution with a mean of \(40\) (rounded to an integer) to denote the number of emails sent between two nodes. We take \(10\) percent of the nodes and contract them into a terminal node \(s\), and take another \(10\) percent of the nodes and contract them into another terminal node \(t\). We make different instances of the problem by choosing the nodes that contract into \(s\) or \(t\) uniformly at random. Note that node contraction into terminals is a standard practice in real-world min \(s\)-\(t\) cut instances, as there are often nodes with predetermined partitions and to make a \(s\)-\(t\) cut (or multiway \(k\)-cut) instance one needs to contract these nodes into one terminal node for each partition. We take the floor of the values \(X_{s,u}\) and \(X_{t,u}\) to obtain integral weights.

Baseline.Let \(C_{s}\) be the cut where one partition consists of only \(s\), and let \(C_{t}\) be the cut where one partition consists of only \(t\). We compare the cut value output by Algorithm 1 against \((w(C_{s}),w(C_{t}))\). Particularly, if \(C_{0}\) is the min \(s\)-\(t\) cut of an instance and Algorithm 1 outputs \(C_{alg}\), then we compare relative errors \()-w(C_{0})}{w(C_{0})}\) and \(),w(C_{t}))-w(C_{0})}{w(C_{0})}\)*. We refer to the former value as _the private cut relative error_, and to the later value as _the terminal cut relative error_.

Footnote *: As another standard heuristic one could consider a random \(s\)-\(t\) cut. We do not include this baseline here as it often has a very high error and the terminal cut does much better than a random cut.

Results.We first set \(=0.5\). We then consider \(50\) graph instances, and for each of them, we evaluate the average private error over \(50\) rounds of randomness used in Algorithm 1, see Figure 1(left) for the results. For almost all instances, the private cut error (including the error bars) is less than the terminal cut error. Moreover, the private cut error is quite stable, and far below the theoretical bound of \(n/\). We next change \(\) and repeat the set-up above for each \(\{,,,,1\}\). For each \(\) in this set we produce \(50\) graph instances, measure the average private error over \(100\) rounds of randomness for each, and then average the terminal cut error and mean private cut error for each graph instance. In this way, we obtain an average value for terminal cut and private cut errors for each of the \(\) values; we refer to Figure 1(right) for the results. The linear relationship between the private cut error and \(\) can be observed in Figure 1(right).

## 6 Conclusion And Future Work

In this work, we investigate the differential privacy of the min \(s\)-\(t\) cut and of, its generalization, the multiway \(k\)-cut problem. For the first problem, we show almost tight lower- and upper-bounds in terms of the error guarantee. Moreover, our DP algorithm is as fast as the fastest non-private one. For the multiway \(k\)-cut problem, we develop a novel approach that yields only \(O(n/ k)\) additive error, as opposed to \(O(n/ k)\) that standard algorithms lead to, in order to achieve DP. This algorithm might be of independent interest. In particular, the _total_ running time of our multiway \(k\)-cut algorithm is only \(O( k)\) more than that of the fastest non-private min \(s\)-\(t\) cut. This is in stark contrast with the prior non-private \(2\)-approximate approach, which is \(O(k)\) times slower than the fastest non-private min \(s\)-\(t\) cut algorithm.

Comparing our lower- and upper-bounds, it remains to close the gap of \(1/\) multiplicative factor in the additive error of the min \(s\)-\(t\) cut problem. It also remains open whether \(O( k)\) factor in the additive error for the multiway \(k\)-cut problem is needed. We believe that techniques relying on solving LPs might be able to avoid this dependence on \(O( k)\). Finally, it would be interesting to explore whether smaller additive error is possible for special but interesting classes of graphs.

Figure 1: (left) Terminal cut and private cut with error bars over \(50\) graph instances, for \(=0.5\). For each instance, Algorithm 1 was run \(100\) times. (right) Average terminal cut value and private cut value over different values of \(\). The \(x\) axis is \(\). For each value of \(\), the set up is the same as in the left figure.