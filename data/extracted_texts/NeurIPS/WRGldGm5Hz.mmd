# DYffusion: A Dynamics-informed Diffusion Model

for Spatiotemporal Forecasting

 Salva Ruhling Cachay Bo Zhao Hailey Joren Rose Yu

University of California, San Diego

{sruhlingcachay, bozhao, hjoren, roseyu}@ucsd.edu

###### Abstract

While diffusion models can successfully generate data and make predictions, they are predominantly designed for static images. We propose an approach for efficiently training diffusion models for probabilistic spatiotemporal forecasting, where generating stable and accurate rollout forecasts remains challenging, Our method, DYffusion, leverages the temporal dynamics in the data, directly coupling it with the diffusion steps in the model. We train a stochastic, time-conditioned interpolator and a forecaster network that mimic the forward and reverse processes of standard diffusion models, respectively. DYffusion naturally facilitates multi-step and long-range forecasting, allowing for highly flexible, continuous-time sampling trajectories and the ability to trade-off performance with accelerated sampling at inference time. In addition, the dynamics-informed diffusion process in DYffusion imposes a strong inductive bias and significantly improves computational efficiency compared to traditional Gaussian noise-based diffusion models. Our approach performs competitively on probabilistic forecasting of complex dynamics in sea surface temperatures, Navier-Stokes flows, and spring mesh systems.1

## 1 Introduction

Dynamics forecasting refers to the task of predicting the future behavior of a dynamic system, involving learning the underlying dynamics governing the system's evolution to make accurate predictions about its future states. Obtaining accurate and reliable probabilistic forecasts is an important component of policy formulation , risk management , resource optimization , and strategic planning . In many applications, accurate long-range probabilistic forecasts are particularly challenging to obtain . In operational settings, methods typically hinge on sophisticated numerical simulations that require supercomputers to perform calculations within manageable time frames, often compromising the spatial resolution of the grid for efficiency .

Generative modeling presents a promising avenue for probabilistic dynamics forecasting. Diffusion models, in particular, can successfully model natural image and video distributions . The standard approach, Gaussian diffusion, corrupts the data with Gaussian noise to varying degrees through the _"forward process"_ and sequentially denoises a random input at inference time to obtain highly realistic samples through the _"reverse process"_. However, learning to map from noise to realistic data is challenging in high dimensions, especially with limited data availability. Consequently, the computational costs associated with training and inference from diffusion models are prohibitive, requiring a sequential sampling process over hundreds of diffusion steps. For example, a denoising diffusion probabilistic model (DDPM) takes around 20 hours to sample 50k images of size 32 x 32 . In addition, few methods apply diffusion models beyond static images. Videodiffusion models [27; 24; 77; 67] can generate realistic samples but do not explicitly leverage the temporal nature of the data to generate accurate forecasts.

In this work, we introduce a novel framework to train a dynamics-informed diffusion model for multi-step probabilistic forecasting. Inspired by recent findings that highlight the potential of non-Gaussian diffusion processes [2; 28; 10], we introduce a new forward process. This process relies on temporal interpolation and is implemented through a time-conditioned neural network. Without requiring assumptions about the physical system, our approach imposes an inductive bias by coupling the diffusion process steps with the time steps in the dynamical system. This reduces the computational complexity of our diffusion model in terms of memory footprint, data efficiency, and the number of diffusion steps required during training. Our resulting diffusion model-based framework, which we call DYffusion, naturally captures long-range dependencies and generates accurate probabilistic ensemble forecasts for high-dimensional spatiotemporal data.

Our contributions can be summarized as follows:

* We investigate probabilistic spatiotemporal forecasting from the perspective of diffusion models, including their applications to complex physical systems with a large number of dimensions and low data availability.
* We introduce DYffusion, a flexible framework for multi-step forecasting and long-range horizons that leverages a temporal inductive bias to accelerate training and lower memory needs. We explore the theoretical implications of our method, proving that DYffusion is an implicit model that learns the solutions to a dynamical system, and cold sampling  can be interpreted as its Euler's method solution.
* We conduct an empirical study comparing performance and computational requirements in dynamics forecasting, including state-of-the-art probabilistic methods such as conditional video diffusion models. We find that the proposed approach achieves strong probabilistic forecasts and improves computational efficiency over standard Gaussian diffusion.

Figure 1: Our proposed framework, DYffusion, reimagines the noise-denoise forward-backward processes of conventional diffusion models as an interplay of temporal interpolation and forecasting. On the top row, we illustrate the direct application of a video diffusion model to dynamics forecasting for a horizon of \(h=3\). On the bottom row, DYffusion generates continuous-time probabilistic forecasts for \(_{t+1:t+h}\), given the initial conditions, \(_{t}\). During sampling, the reverse process iteratively steps forward in time by forecasting \(_{t+h}\) (which plays the role of the “clean data”, \(^{(0)}\), in conventional diffusion models) and interpolating to one of \(N\) intermediate timesteps, \(_{t+i_{n}}\). As a result, our approach operates in the data space at all times and does not need to model high-dimensional videos at each diffusion state.

Background

Problem setup.We study the problem of probabilistic spatiotemporal forecasting. We start with a dataset of \(\{_{t}\}_{t=1}^{T}\) snapshots with \(_{t}\). Here, \(\) represents the space in which the data lies, which may consist of spatial dimensions (e.g., latitude, longitude, atmospheric height) and a channel dimension (e.g., velocities, temperature, humidity). The task of probabilistic forecasting is to learn a conditional distribution \(P(_{t+1:t+h}_{t-l+1:t})\) that uses \(l\) snapshots from the past to forecast a subsequent _horizon_ of \(h\) snapshots. Here, we focus on the task of forecasting from a single initial condition, where we aim to learn \(P(_{t+1:t+h}_{t})\). This covers many realistic settings [50; 44] while minimizing the computational requirements for accurate forecasts .

Diffusion processes.In a standard diffusion model, the _forward diffusion process_ iteratively degrades the data with increasing levels of (Gaussian) noise. The reverse diffusion process then gradually removes the noise to generate data. We denote these diffusion step states, \(^{(n)}\), with a superscript \(n\) to clearly distinguish them from the time steps of the data \(\{_{t}\}_{t=1}^{T}\). This process can be generalized to consider a degradation operator \(D\) that takes as input the data point \(^{(0)}\) and outputs \(^{(n)}=D(^{(0)},n)\) for varying degrees of degradation proportional to \(n\{1,,N\}\). Oftentimes, \(D\) adds Gaussian noise with increasing levels of variance so that \(^{(N)}(,)\). A denoising network parameterized by \(\), \(R_{}\) is trained to _restore_\(^{(0)}\), i.e. such that \(R_{}(^{(n)},n)^{(0)}\). The diffusion model can be conditioned on the input dynamics by considering \(R_{}(^{(n)},_{t},n)\). In the case of dynamics forecasting, the diffusion model can be trained to minimize the objective

\[_{}_{n l 1,N,_{t}, ^{(0)}}[||R_{}(D(^{(0)},n), _{t},n)-^{(0)}||^{2}],\] (1)

where \(\) is the data distribution, \(||||\) is a norm, and \(^{(0)}=_{t+1:t+h}\) is the prediction target. \([a,b]\) describes the uniform distribution over the set \(\{a,a+1,,b\}\). In practice, \(R_{}\) may be trained to predict the Gaussian noise that has been added to the data point using score matching objective . The objective in Eq. (1) can be viewed as a generalized version of the standard diffusion models, see Appendix B.2 for a more comprehensive analysis.

## 3 DYffusion: DYnamics-Informed Diffusion Model

``` Input: networks \(F_{},_{}\), norm \(||||\), horizon \(h\), schedule \([i_{n}]_{i=0}^{N-1}\) Stage 1: Train interpolator network, \(_{}\)  1. Sample \(i(\{1,,h-1\})\)  2. Sample \(_{t},_{t+i},_{t+h}\)  3. Optimize \(_{}||_{}(_{t},_{t+h},i)- _{t+i}||^{2}\) Stage 2: Train forecaster network (diffusion model backbone), \(F_{}\)  1. Freeze \(_{}\) and enable inference stochasticity (e.g. dropout)  2. Sample \(n(\{0,,N-1\})\) and \(_{t},_{t+h}\)  3. Optimize \(_{}||F_{}(_{}(_{t},_{ t+h},i_{n}),i_{n})-_{t+h}||^{2}\) ```

**Algorithm 1** DYfusion, Two-stage Training

The key innovation of our method, DYffusion, is a reimaging of the diffusion processes to more naturally model spatiotemporal sequences, \(_{t:t+h}\) (see Fig. 1). Specifically, we replace the degradation operator, \(D\), with a stochastic interpolator network \(_{}\), and the restoration network, \(R_{}\), with a deterministic forecaster network, \(F_{}\).

At a high level, our forward and reverse processes emulate the temporal dynamics in the data. Thus, intermediate steps in the diffusion process can be reused as forecasts for actual timesteps in multi-step forecasting. Another benefit of our approach is that the reverse process is initialized with the initial conditions of the dynamics and operates in observation space at all times. In contrast, a standard diffusion model is designed for unconditional generation, and reversing from white noise requires more diffusion steps. For conditional prediction tasks such as forecasting, DYfusion emerges as a much more natural method that is well aligned with the task at hand. See Table 4 for a full glossary.

Temporal interpolation as a forward process.To impose a temporal bias, we train a time-conditioned network \(_{}\) to interpolate between snapshots of data. Specifically, given a horizon \(h\), we train \(_{}\) so that \(_{}(_{t},_{t+h},i) _{t+i}\) for \(i\{1,,h-1\}\) using the objective:

\[_{}_{i l 1,h-1,_{t,t+i,t+h}}[||_{}(_{t}, _{t+h},i)-_{t+i}||^{2}].\] (2)Interpolation is an easier task than forecasting, and we can use the resulting interpolator \(_{}\) during inference to interpolate beyond the temporal resolution of the data. That is, the time input can be continuous, with \(i(0,h-1)\), where we note that the range \((0,1)\) is outside the training regime, as discussed in Appendix D.5. To generate probabilistic forecasts, it is crucial for the interpolator, \(_{}\), to _produce stochastic outputs_ within the diffusion model and during inference time. We enable this using Monte Carlo dropout  at inference time.

Forecasting as a reverse process.In the second stage, we train a forecaster network \(F_{}\) to forecast \(_{t+h}\) such that \(F_{}(_{}(_{t},_{t+h},i| ),i)_{t+h}\) for \(i S=[i_{n}]_{n=0}^{N-1}\), where \(S\) denotes a schedule mapping the diffusion step to the interpolation timestep. The interpolator network, \(_{}\), is frozen with inference stochasticity enabled, represented by the random variable \(\). Here, \(\) stands for the randomly dropped out weights of the neural network and is omitted henceforth for clarity. Specifically, we seek to optimize the objective

\[_{}_{n[0,N-1],_{t,t+h} }[||F_{}(_{}(_{t},_{t+h},i_{n}|),i_{n})-_{t+h}||^{2}].\] (3)

To include the setting where \(F_{}\) learns to forecast the initial conditions, we define \(i_{0}:=0\) and \(_{}(_{t},,i_{0}):=_{t}\). In the simplest case, the forecaster network is supervised by all possible timesteps given by the temporal resolution of the training data. That is, \(N=h\) and \(S=[j]_{j=0}^{h-1}\). Generally, the interpolation timesteps should satisfy \(0=i_{0}<i_{n}<i_{m}<h\) for \(0<n<m N-1\). Given the equivalent roles between our forecaster and the denoising net in diffusion models, we also refer to them as the diffusion backbones. As the time condition to our diffusion backbone is \(i_{n}\) instead of \(n\), we can choose _any_ diffusion-dynamics schedule during training or inference and even use \(F_{}\) for unseen timesteps (see Fig. 3). The resulting two-stage training algorithm is shown in Alg. 1.

Because the interpolator \(_{}\) is frozen in the second stage, the imperfect forecasts \(}_{t+h}=F_{}(_{}(_{t}, _{t+h},i_{n}),i_{n})\) may degrade accuracy when used during sequential sampling. To handle this, we introduce a one-step look-ahead loss term \(||F_{}(_{}(_{t},}_{t+h},i _{n+1}),i_{n+1})-_{t+h}||^{2}\) whenever \(n+1<N\) and weight the two loss terms equally. Additionally, providing a clean or noised form of the initial conditions \(_{t}\) as an additional input to the forecaster net can improve performance. These additional tricks are discussed in Appendix B.

Sampling.Taken together, we can write the generative process of DYffusion as follows:

\[p_{}(^{(n+1)}|^{(n)},_{t})=F_ {}(^{(n)},i_{n})&n=N-1\\ _{}(_{t},F_{}(^{(n)},i_{n}),i_{n+1}) &\] (4)

where \(^{(0)}=_{t}\) and \(^{(n)}_{t+i_{n}}\) correspond to the initial conditions and predictions of intermediate steps, respectively. In our formulations, we reverse the diffusion step indexing to align with the temporal indexing of the data. That is, \(n=0\) refers to the start of the reverse process (i.e. \(_{t}\)), while \(n=N\) refers to the final output of the reverse process (here, \(_{t+h}\)). Our reverse process steps forward in time, in contrast to the mapping from noise to data in standard diffusion models. As a result, DYffusion should require fewer diffusion steps and data.

Similarly to the forward process in , our interpolation stage ceases to be a diffusion process. Our forecasting stage as detailed in Eq. (3), follows the (generalized) diffusion model objectives. This similarity allows us to use many existing diffusion model sampling methods for inference, such as the cold sampling algorithm from  (see Alg. 2). In Appendix C.2, we also discuss a simpler but less performant sampling algorithm. During the sampling process, our method essentially alternates between forecasting and interpolation, as illustrated in Fig. 2. \(F_{}\) always predicts the last timestep, \(_{t+h}\), but iteratively improves those forecasts as the reverse process comes closer in time to \(t+h\). This is analogous to the iterative denoising of the "clean" data in standard diffusion models. This motivates line of Alg. 2, where the final forecast of \(_{t+h}\) can be used to fine-tune intermediate predictions or to increase the temporal resolution of the forecast. DYffusion can be applied autoregressively to forecast even longer rollouts beyond the training horizon, as demonstrated by the Navier-Stokes and spring mesh experiments in section 5.

Memory footprint.DYffusion requires only \(_{t}\) and \(_{t+h}\) (plus \(_{t+i}\) during the first stage) to train, resulting in a constant memory footprint as a function of \(h\). In contrast, direct multi-step prediction models including video diffusion models or (autoregressive) multi-step loss approaches require \(_{t:t+h}\) to compute the loss. This means that these models must fit \(h+1\) timesteps of data into memory, which scales poorly with the forecasting horizon \(h\). Therefore, many are limited to predicting a small number of frames. MCVD, for example, trains on a maximum of 5 video frames due to GPU memory constraints .

Reverse process as ODE.DYffusion can be interpreted as modeling the dynamics by a "diffusion process", similar to an implicit model . This view helps explain DYffusion's superior forecasting ability, as it learns to model the physical dynamical system \((t)\). The neural networks \(_{}\) and \(F_{}\) are trained to construct a differential equation that implicitly models the solution to \((t)\).

Let \(s\) be the time variable. DYffusion models the dynamics as

\[(s)}{ds}=_{}(_{t},F_{ }(,s),s)}{ds}.\] (5)

The initial condition is given by \((t)=_{t}\). During prediction, we seek to obtain

\[(s)=(t)+_{t}^{s}_{}( _{t},F_{}(,s),s)}{ds}dss(t,t+h].\] (6)

The prediction process is equivalent to evaluating (6) at discrete points in the forecasting window \((t,t+h]\). Sampling schedules \(i_{n}\) can be thought of as step sizes in ODE solvers. Therefore, different sampling schedules can be flexibly chosen at inference time, since they are discretizations of the same ODE. Different sampling algorithms can be obtained from different ODE solvers and we prove that cold sampling is an approximation of the Euler method (derivation in Appendix C.1).

Viewing DYffusion as an implicit model emphasizes its dynamics-informed nature and reveals the relation between DYffusion and DDIM . Specifically, DDIM can be viewed as an implicit model that models the solution to the noise-removing dynamics from a random image to a clean image. In comparison, DYffusion is an implicit model that learns the solutions of a dynamical system using data from the current step \(_{t}\) to the future step \(_{t+h}\).

## 4 Related Work

Diffusion Models.Diffusion models [25; 60; 62; 63] have demonstrated significant success in diverse domains, notably images and text . While interesting lines of work explore Gaussian diffusion for multivariate time-series imputation  and forecasting , high-dimensional spatiotemporal

Figure 2: During sampling, DYffusion alternates between forecasting and interpolation, following Alg. 2. In this example, the sampling trajectory follows a simple schedule of going through all integer timesteps that precede the horizon of \(h=4\), with the number of diffusion steps \(N=h\). The output of the last diffusion step is used as the final forecast for \(_{4}}\). The **black** lines represent forecasts by the forecaster network, \(F_{}\). The first forecast is based on the initial conditions, \(_{0}\). The **blue** lines represent the subsequent temporal interpolations performed by the interpolator network, \(_{}\).

forecasting has remained unexplored. Methods such as combining blurring and noising techniques [28; 10; 2] and adopting a unified perspective with Poisson Flow Generative Models  have shown promise as alternative approaches to extend diffusion processes beyond Gaussian noise. Although intellectually intriguing, the results of cold diffusion  and other recent attempts that use different corruptions  are usually inferior to Gaussian diffusion. Our work departs from these methods in that we propose a dynamics-informed process for the conditional generation of high-dimensional forecasts that is not based on multiple levels of data corruption.

Diffusion Models for Video Prediction.Most closely related to our work are diffusion models for videos [67; 27; 77; 59; 26; 24]. The task of conditional video prediction can be placed under the multi-step notation of Eq. (1). Notably, we are interested in modeling the full dynamics and the underlying physics rather than object-centric tasks. There is also evidence that techniques tailored to computer vision and NLP do not transfer well to spatiotemporal problems . These video diffusion models also rely internally on the standard Gaussian noise diffusion process inherited from their image-generation counterparts. As such, these models miss the opportunity to incorporate the temporal dynamics of videos into the diffusion process.

Dynamics Forecasting.Deterministic next-step forecasting models can be unrolled autoregressively to achieve multi-step predictions. However, this may result in poor or unstable rollouts due to compounding prediction errors [11; 57; 9; 8; 34; 5; 33; 43]. The issue can be alleviated by unrolling the model at training time to introduce a loss term on the multi-step predictions [45; 34; 36; 23; 5]. However, this approach is memory-intensive and comes at the expense of efficiency since the model needs to be called sequentially for each multi-step loss term. It can also introduce new instabilities because the gradients have to be computed recursively through the unrolled steps. Even then, this approach may fall behind physics-based baselines for long-range horizons . Alternatively, forecasting multiple steps all at once as in video diffusion models [73; 52; 5] or conditioned on the time [37; 49; 15; 43], training separate models for each required horizon [56; 22; 68], noising the training data , and encoding physics knowledge into the ML model [11; 14; 70; 41; 9; 35; 8], can often produce better long-range forecasts, though they still require a fixed temporal resolution. For probabilistic dynamics forecasting , most methods focus on autoregressive next-step prediction models [58; 18; 29]. Some notable works target precipitation nowcasting , or short-term forecasting . Alternatively to using intrinsically probabilistic models, one can use a deterministic model to generate an ensemble forecast by perturbing its initial conditions [45; 21]. Our framework addresses primary challenges in the field , specifically realistic long-range forecasts and efficient modeling of multi-step dynamics.

## 5 Experiments

### Datasets

We evaluate our method and baselines on three different datasets:

* **Sea Surface Temperatures (SST):** a new dataset based on NOAA OISSTv2 , which comes at a daily time-scale. Similar to [11; 71], we train our models on regional patches which increases the available data (here, we choose 11 boxes of \(60\) latitude \( 60\) longitude resolution in the eastern tropical Pacific Ocean). Unlike the data based on the NEMO dataset in [11; 71], we choose OISSTv2

Figure 3: Example schedules for coupling diffusion steps to dynamical time steps. While a naive approach only uses timesteps given by the temporal resolution of the data (i.e. discrete indices), our framework can accommodate continuous indices. The additional \(k\) diffusion steps are highlighted in **green** and map uniformly between the input timestep, \(_{0}\), and earliest output timestep, \(}_{1}\). Our experiments using the SST dataset in section 5 demonstrate that increasing the number of diffusion steps with implicit intermediate timesteps can improve performance (see Appendix D.7).

as our SST dataset because it contains more data (although it has a lower spatial resolution of \(1/4^{}\) compared to \(1/12^{}\) of NEMO). We train, validate, and test all models for the years 1982-2019, 2020, and 2021, respectively. The preprocessing details are in the Appendix D.1.1.
* **Navier-Stokes flow:** benchmark dataset from , which consists of a \(221 42\) grid. Each trajectory contains four randomly generated circular obstacles that block the flow. The viscosity is \(1e\)-\(3\). The channels consist of the \(x\) and \(y\) velocities as well as a pressure field. Boundary conditions and obstacle masks are given as additional inputs to all models.
* **Spring Mesh:** benchmark dataset from . It represents a \(10 10\) grid of particles connected by springs, each with mass \(1\). The channels consist of two position and momentum fields each.

### Experimental Setup

We focus on _probabilistic multi-step forecasting_, and especially long rollouts, as opposed to attaining the best next-step or short-term forecasts. This is an important distinction because, while deterministic single-step forecasting models such as those of  are appropriate for short-term predictive skill comparison, such models tend to lack stability for long-term forecasts. We demonstrate this in the Appendix D.4.2 (see Fig. 6), where our method and baselines excel in the long-range forecasting regime while being competitive in the short-range regime compared to the baselines from .

Neural network architectures.For a given dataset, we use the _same backbone architecture_ for all baselines as well as for both the interpolation and forecaster networks in DYffusion. For the SST dataset, we use a popular UNet architecture designed for diffusion models2. For the Navier-Stokes and spring mesh datasets, we use the UNet and CNN from the original paper , respectively. The UNet and CNN models from  are extended by the sine/cosine-based featurization module of the SST UNet to embed the diffusion step or dynamical timestep.

Baselines.We compare our method against both direct applications of standard diffusion models to dynamics forecasting and methods to ensemble the "barebone" backbone network of each dataset. The network operating in "barebone" form means that there is no involvement of diffusion.

* **DDPM **: both next-step (image-like problem) as well as multi-step (video-like problem) prediction mode (we report the best model version only in the results).
* **MCVD :** conditional video diffusion model for video prediction (in "concat" mode).
* **Dropout :** Ensemble multi-step forecasting based on enabling dropout of the barebone backbone network at inference time.
* **Perturbation :** Ensemble multi-step forecasting based on random perturbations of the initial conditions/inputs with a fixed variance of the barebone backbone network.

    &  &  \\   & CRPS & MSE & SSR & Time [s] & CRPS & MSE & SSR \\  Perturbation & 0.281 \(\) 0.004 & 0.180 \(\) 0.011 & 0.411 \(\) 0.046 & 0.4241 & 0.090 \(\) 0.001 & 0.028 \(\) 0.000 & 0.448 \(\) 0.002 \\ Dropout & 0.267 \(\) 0.003 & 0.164 \(\) 0.004 & 0.406 \(\) 0.042 & 0.4241 & 0.078 \(\) 0.001 & 0.027 \(\) 0.001 & 0.715 \(\) 0.005 \\ DDPM & 0.246 \(\) 0.005 & 0.177 \(\) 0.005 & 0.674 \(\) 0.011 & 0.3054 & 0.180 \(\) 0.004 & 0.105 \(\) 0.010 & 0.573 \(\) 0.001 \\ MCVD & **0.216** & **0.161** & 0.926 & 79.167 & 0.154 \(\) 0.043 & 0.070 \(\) 0.033 & 0.524 \(\) 0.064 \\ DYffusion & 0.224 \(\) 0.001 & 0.173 \(\) 0.001 & **1.033 \(\) 0.005** & 4.6722 & **0.067 \(\) 0.003** & **0.022 \(\) 0.002** & **0.877 \(\) 0.006** \\   

Table 1: Results for sea surface temperature forecasting of 1 to 7 days ahead, as well Navier-Stokes flow full trajectory forecasting of 64 timesteps. Numbers are averaged out over the evaluation horizon. **Bold** indicates best, blue second best. For CRPS and MSE, lower is better. For SSR, closer to 1 is better. For SST, all models are trained on forecasting \(h=7\) timesteps. The time column represents the time needed to forecast all 7 timesteps for a single batch. For Navier-Stokes, Perturbation, Dropout, and DYffusion are trained on a horizon of \(h=16\). MCVD and DDPM are trained on \(h=4\) and \(h=1\), respectively, as we were not able to successfully train them using larger horizons.

MCVD and the multi-step DDPM variant predict the timesteps \(_{t+1:t+h}\) based on \(_{t}\), which is the standard approach in video (prediction) diffusion models. The barebone backbone network baselines are time-conditioned forecasters (similarly to the DYffusion forecaster) trained on the multi-step objective \(_{i[1,h]_{t,i+}}||F_{} (_{t},i)-_{t+i}||^{2}\) from scratch. We found it to perform very similarly to predicting all \(h\) horizon timesteps at once in a single forward pass (not shown). In all experiments, we observed that the single-step forecasting (\(h=1\)) version of the barebone network yielded significantly lower performance compared to any of the multi-step training approaches (see Appendix D.4.2). More details of the implementation are provided in Appendix D.2.

Evaluation.We evaluate the models on the best validation Continuous Ranked Probability Score (CRPS) , which is a proper scoring rule and a popular metric in the probabilistic forecasting literature [19; 12; 51; 48; 58]. The CRPS is computed by generating a 20-member ensemble (i.e. 20 samples are drawn per batch element), while we generate a 50-member ensemble for final model selection between different hyperparameter runs. We also use a 50-member ensemble for evaluation on the test datasets to compute the CRPS, mean squared error (MSE), and spread-skill ratio (SSR). The MSE is computed on the ensemble mean prediction. The SSR is defined as the ratio of the square root of the ensemble variance to the corresponding ensemble RMSE. It serves as a measure of the reliability of the ensemble, where values smaller than 1 indicate underdispersion (i.e. the probabilistic forecast is overconfident in its forecasts), and larger values overdispersion [16; 18]. On the Navier-Stokes and spring mesh datasets, models are evaluated by autogressively forecasting the full test trajectories of length 64 and 804, respectively. For the SST dataset, all models are evaluated on forecasts of up to 7 days. We do not explore more long-term SST forecasts because the chaotic nature of the system, and the fact that we only use regional patches, inherently limits predictability.

### Results

Quantitative Results.We present the time-averaged metrics for the SST and Navier-Stokes dataset in Table 1 and for the Spring Mesh dataset in Table 2. DYffusion performs best on the Navier-Stokes dataset, while coming in a close second on the SST dataset after MCVD, in terms of CRPS. Since MCVD uses \(1000\) diffusion steps3, it is slower to sample from at inference time than from our DYffusion  which is trained with less than \(50\) diffusion steps. The DDPM model for the SST dataset is fairly efficient because it only uses 5 diffusion steps but lags in terms of performance. Thanks to the time-conditioned nature of DYffusion's interpolator and forecaster nets, memory is not an issue when scaling our framework to long horizons. In the spring mesh dataset, we train with a horizon of \(134\) and evaluate long trajectories of \(804\) steps. Our method beats the barebone network baseline, with a larger margin on the out-of-distribution test dataset. It is worth noting that our reported MSE scores are significantly better than the ones reported in , likely due to multi-step training being superior to the single-step forecasting approach of  (see Appendix D.4.2 for more details). For the out-of-distribution test set of the Navier-Stokes benchmark, the results are almost identical to the one in Tab. 1, so we show them in Appendix D.4.1.

Qualitative Results.In dynamics forecasting, long-range forecasts of ML models often suffer from blurriness (or might even diverge when using autoregressive models). In Fig. 4 we show exemplary

    &  &  \\   & CRPS & MSE & SSR & CRPS & MSE & SSR \\  Dropout & 0.0138 \(\) 0.0006 & 7.27e-4 \(\) 6.8e-5 & **1.01 \(\) 0.02** & 0.0448 \(\) 0.0007 & 7.08e-3 \(\) 1.7e-4 & 0.70 \(\) 0.01 \\ DYffusion & **0.0103 \(\) 0.0022** & **4.20e-4 \(\) 2.1e-4** & 1.13 \(\) 0.08 & **0.0292 \(\) 0.0009** & **3.54e-3 \(\) 2.0e-4** & **0.82 \(\) 0.00** \\   

Table 2: Spring Mesh results. Both methods are trained on a horizon of \(h=134\) timesteps and evaluated how well they forecast the full test trajectories of 804 steps. Despite several attempts with varying configurations over the number of diffusion steps, learning rates, and diffusion schedules, none of the DDPM or MCVD diffusion models converged. Using the same CNN architecture, our MSE results significantly surpass the ones reported in Fig. 8 of , where the CNN diverged or attained a very poor MSE. This is likely because of the multi-step training approach that we use, while the single-step prediction approach (\(h=1\)) in  can generate unstable rollouts.

samples for the best baseline (Dropout) and DYffusion as well as the corresponding ground truth at five different timesteps from a complete Navier-Stokes trajectory forecast. Our method can reproduce the true dynamics over the full trajectory and does so better than the baseline, especially for fine-scale patterns such as the tails of the flow after the right-most obstacle. The corresponding full video can be found at this URL.

Increasing the forecasted resolution.Motivated by the continuous-time nature of DYffusion, we aim to study in this experiment whether it is possible to forecast skillfully beyond the resolution given by the data. Here, we forecast the same Navier-Stokes trajectory shown in Fig. 4 but at \(8\) resolution (i.e. 512 timesteps instead of 64 are forecasted in total). This behavior can be achieved by either changing the sampling trajectory \([i_{n}]_{n=0}^{N-1}\) or by including additional output timesteps, \(J\), for the refinement step of Alg. 2. In this case, we choose to do the latter and find the resulting forecast to be visibly pleasing and temporally consistent; see the full video at this URL.

Note that we hope that our probabilistic forecasting model can capture any of the possible, uncertain futures instead of forecasting their mean, as a deterministic model would do. As a result, some long-term rollout samples are expected to deviate from the ground truth. For example, see the velocity at \(t=3.70\) in the video. It is reassuring that our samples show sufficient variation, but also cover the ground truth quite well (sample 1).

Ablations.In Appendix D.5, we ablate various components of our method. This includes showing that inference stochasticity in the interpolation network is crucial for performance. Our experiments in Appendix D.5.1 confirm the findings of  regarding the superiority of cold sampling (see Alg. 2) compared to the naive sampling (Alg. 4) algorithm. We provide a theoretical justification in Appendix C.2, where we show that cold sampling has first-order discretization error, whereas naive sampling does not.

We also study the choice of the interpolation schedule:

For the Navier-Stokes and spring mesh datasets, it was sufficient to use the simplest possible schedule \(S=[i_{n}]_{n=0}^{N-1}=[j]_{j=0}^{h-1}\), where the number of diffusion steps and the horizon are equal. For the SST dataset, using \(k\) additional diffusion steps corresponding to floating-point \(i_{k}\), especially such that \(i_{k}<1\) for all \(k\), improved performance significantly. Similarly to the finding of DDIM  for Gaussian diffusion, we show that the sampling trajectories of DYffusion can be accelerated by skipping intermediate diffusion steps, resulting in a clear trade-off between accuracy and speed. Finally, we verify that the forecaster's prediction of \(_{t+h}\) for a given diffusion step \(n\) and associated input \(}_{t+i_{n}}\) usually improves as \(n\) increases, i.e. as we approach the end of the reverse process and \(_{t+i_{n}}\) gets closer in time to \(_{t+h}\).

The variance in the performance of the standard diffusion models across datasets may be intriguing. One possible explanation could be the size of the training dataset, since the SST dataset is more than ten times larger than the Navier-Stokes and spring mesh datasets, respectively. Sufficient training data may be a key factor that enables Gaussian diffusion models to effectively learn the reverse process

Figure 4: Qualitative forecasts for timesteps 2, 6, 24, 46, and 64 (last timestep) of the velocity norm of an example Navier-Stokes test trajectory. Here, we generate five sample trajectories for the best baseline (Dropout) and our method DYffusion, both with \(h=16\), and visualize the one with the best trajectory-average MSE for each of the methods. Our method (bottom row) can reproduce fine-scale details visibly better than the baseline (see e.g. right sides of the snapshots). The corresponding video of the full trajectory, including the velocity and pressure fields, can be found at this Google Drive URL https://drive.google.com/file/d/1xk1Vs42I1i8I88V70f12mAKR159qiHG_/view7usp=share_link.

   \# years & **2** & **4** & **37** \\  MCVD & 0.262 & 0.233 & 0.216 \\ DYffusion & 0.239 & 0.234 & 0.225 \\   

Table 3: CRPS test scores for the SST dataset using different number of training years. 2, 4, 37 refers to training from 2017, 2015, 1982 until the end of 2018, respectively. The standard deviations are around \(0.01\) or lower.

from noise to the data space. We explore this hypothesis in Table 3, where we retrain MCVD as well as DYffusion's \(F_{}\) and \(T_{}\) on small subsets of the SST training set. We find that DYffusion's performance degrades more gracefully under limited training data, especially when using only two years of data (or \( 8,000\) training data points).

We found it very challenging to train video diffusion models on long horizons. A reason could be that the channel dimension of the video diffusion backbone is scaled by the training horizon, which increases the problem dimensionality and complexity considerably (see Appendix D.6). Unlike common practice in natural image or video problems, we do not threshold the predictions of any diffusion model, as the data range is unbounded. However, this thresholding has been shown to be an important implementation detail that stabilizes diffusion model sampling for complex problems in the domain of natural images . This could be the reason why the studied diffusion model baselines produce poor predictions for the Navier-Stokes and spring mesh datasets.

## 6 Conclusion

We have introduced DYffusion, a novel dynamics-informed diffusion model for improved probabilistic spatiotemporal forecasting. In contrast to most prior work on probabilistic forecasting that often generates long-range forecasts via iterating through an autoregressive model, we tailor diffusion models to naturally support long-range forecasts during inference time by coupling their diffusion process with the dynamical nature of the data. Our study presents the first comprehensive evaluation of diffusion models for the task of spatiotemporal forecasting. Finally, we believe that our dynamics-informed diffusion model can serve as a more general source of inspiration for tailoring diffusion models to other conditional generation problems, such as super-resolution, where the data itself can natively inform an inductive bias for the diffusion model.

Limitations.While our proposed framework can be applied to any dynamics forecasting problem as an alternative to autoregressive models, it does not support, in its current form, problems where the output space is different from the input space. Additionally, although it requires fewer diffusion steps compared to Gaussian diffusion models to achieve similar performance, the need for additional forward passes through the interpolator network diminishes some of these advantages. When prioritizing inference speed, approaches that only require a single forward pass to forecast outperform sequential sampling of diffusion models, including DYffusion.

Future work.Cold Diffusion  indicates that deterministic data degradations cannot meet the performance of stochastic (i.e. Gaussian noise-based) degradations. In our work, we have experimented with using an interpolator network with Monte Carlo dropout enabled during inference time to achieve a stochastic forward process, which we have shown to be important for optimal performance. Exploring more advanced approaches for introducing stochasticity into our general framework presents an interesting avenue for future work. A more advanced approach could draw insights from the hypernetwork-based parameterization of the latent space from . Furthermore, given our finding of the equivalence of cold sampling with the Euler solver (C.1), it could be interesting to consider more advanced ODE solvers for improved sampling from DYffusion. Recent advances in neural architectures for physical systems  are complementary to our work. Using such alternative neural architectures as interpolator or forecaster networks within our framework could be a promising approach to further improve performance.