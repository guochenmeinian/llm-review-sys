# Molecule Design by Latent Prompt Transformer

Deqian Kong\({}^{1,}\), Yuhao Huang\({}^{2,}\), Jianwen Xie\({}^{3,4,}\), Edouardo Honig\({}^{1,}\),

Ming Xu\({}^{5}\), Shuanghong Xue\({}^{5}\), Pei Lin\({}^{6}\), Sanping Zhou\({}^{2}\),

Sheng Zhong\({}^{5,6}\), Nanning Zheng\({}^{2}\), Ying Nian Wu\({}^{1}\)

Equal Contribution. Project page: [https://sites.google.com/view/latent-prompt-transformer](https://sites.google.com/view/latent-prompt-transformer).

Equal Contribution. Project page: [https://sites.google.com/view/latent-prompt-transformer](https://sites.google.com/view/latent-prompt-transformer).

###### Abstract

This work explores the challenging problem of molecule design by framing it as a conditional generative modeling task, where target biological properties or desired chemical constraints serve as conditioning variables. We propose the Latent Prompt Transformer (LPT), a novel generative model comprising three components: (1) a latent vector with a learnable prior distribution modeled by a neural transformation of Gaussian white noise; (2) a molecule generation model based on a causal Transformer, which uses the latent vector as a prompt; and (3) a property prediction model that predicts a molecule's target properties and/or constraint values using the latent prompt. LPT can be learned by maximum likelihood estimation on molecule-property pairs. During property optimization, the latent prompt is inferred from target properties and constraints through posterior sampling and then used to guide the autoregressive molecule generation. After initial training on existing molecules and their properties, we adopt an online learning algorithm to progressively shift the model distribution towards regions that support desired target properties. Experiments demonstrate that LPT not only effectively discovers useful molecules across single-objective, multi-objective, and structure-constrained optimization tasks, but also exhibits strong sample efficiency.

## 1 Introduction

Molecule design plays a pivotal role in drug discovery, focusing on identifying or creating molecules with desired pharmacological or chemical properties. However, the vast and complex space of potential drug-like molecules presents significant challenges for systematically designing efficient machine learning models to navigate this space. Latent space optimization (LSO) (Maus et al., 2022; Tripp et al., 2020; Gomez-Bombarelli et al., 2018), a two-stage procedure, has emerged as a promising approach to address this challenge. The first stage involves training a deep generative model, typically a deep variational auto-encoder (VAE) (Kingma and Welling, 2014), to map low-dimensional continuous vectors to the data manifold in input space, creating a simplified and continuous analog of the original optimization problem. In the second stage, the objective function is optimized over this learned latent space using a surrogate model. While LSO has demonstrated potential in tackling high-dimensional and structured input spaces, existing LSO-based methods separate the training of the generative model from the property-conditioned optimization. This decoupling can lead to suboptimal performance, as the learned latent space may not be ideally suited to the specificoptimization task. Furthermore, LSO depends on an additional inference model during training, increasing the number of model parameters and adding complexity to the model design process.

To address the above limitations, we propose a novel generative model, the Latent Prompt Transformer (LPT), which unifies molecule generation and optimization within a single framework. The LPT can be directly trained on observed molecule-property pairs via maximum likelihood estimation (MLE) in an end-to-end fashion. We take advantage of the immediately-available Markov chain Monte Carlo (MCMC) inference engine derived from the posterior distribution, eliminating the need for an auxiliary network for variational inference. The LPT consists of three components: (1) a learnable prior model of the latent vector based on a neural transformation of Gaussian noise, (2) a molecule generation model that generates molecule sequences using a causal transformer with the latent vector serving as the prompt, and (3) a property predictor model that estimates the target property values given the latent vector. The latent prompts serve as shared representations for both molecules and properties. By incorporating the MLE of the LPT, we employ an online learning algorithm of the LPT for property optimization, formulated as a conditional generative modeling task. This algorithm progressively shifts the model distribution towards regions associated with desired properties.

To enhance the practical application of designed molecules and enable a comparative analysis of our generated designs versus those made by human experts, we introduce a new task, which is the conditional generation of molecules that bind to the NAD binding site of Phosphoglycerate dehydrogenase (PHGDH). In addition to single-objective optimization for this specific protein, we also introduce structure-constrained optimization to analyze the design pathways of learning-based models in comparison with human experts. This additional experiment aims to provide valuable insights for improving learning-based model design. We manually process the data to ensure compatibility with docking software, which is essential for facilitating precise score computation. Compared to other widely used evaluation metrics, the use of PHGDH offers greater practical significance and enables more accurate calculations in real-world drug discovery scenarios.

Our work makes the following key contributions: (1) We propose the LPT, a novel generative framework for jointly modeling molecule sequences and their target properties. This framework leverages a learnable informative prior distribution on a latent space, conceptualized as an intrinsic design representation. (2) We propose an MCMC-based MLE to train the LPT without needing an auxiliary network for variational inference. (3) We develop a novel online learning algorithm for LPT, allowing the model to gradually extrapolate to feasible regions associated with desired properties, improving computational and sample efficiency. (4) We present a new task for the conditional generation of molecules that bind to the NAD binding site of PHGDH, and introduce structure-constrained optimization to compare the design pathways of learning-based models with those of human experts. (5) Our model achieves state-of-the-art performance across a variety of molecule-based optimization tasks, including single-objective design, multi-objective design, and biological sequence design.

## 2 Background

Let \(x=(x^{(1)},...,x^{(t)},...,x^{(T)})\) be a sequence representation of molecules such as SMILES (Weininger, 1988) or SELFIES (Krenn et al., 2020; Cheng et al., 2023), where \(x^{(t)}\) is the \(t\)-th element in the vocabulary \(\), and \(\) is the space of molecules. In molecule design, the objective is to generate targeted molecules that optimize several properties of interest, represented by \(=\{y_{i}=o_{i}^{p}(x)\}\) for \(i=1,,m\), while satisfying specific constraints, \(=\{c_{j}=o_{j}^{c}(x)_{2}\}\) for \(j=1,,n\). Here, \(o^{p}(x)\) and \(o^{c}(x)\) denote oracle functions determining property values and constraint satisfaction, respectively, and these values can be obtained either by querying existing software or by conducting wet lab experiments.

The multi-objective multi-constraint optimization (MMO) problem can be formulated as follows:

\[_{x} F(x)=\{o_{1}^{p}(x),o_{2}^{p}(x),,o_{m}^{p}( x)\} o_{j}^{c}(x)=1, j=1,,n, \]

where \(o^{c}(x)=1\) denotes constraint satisfaction and \(o^{c}(x)=0\) denotes constraint violation. From a probabilistic modeling perspective, the MMO problem can be viewed as a conditional sampling problem, \(x^{*} p(x|=^{*},=)\), where \(^{*}\) represents the desired values of the target properties, and \(=\) indicates that all constraints are satisfied.

In generative molecule design, we assume access to a dataset of molecule sequences and their associated properties for offline pretraining of the generative model. During the design phase,the model queries existing software (oracle functions) to obtain single or multiple metrics for the generated molecules, with these oracle functions providing ground-truth property values to be optimized. It is important to acknowledge that developing proper software for accurate evaluation of molecule properties is of equal or even greater importance than designing molecules based on those software. However, it is beyond the scope of this paper to address the development of such software. Here, we treat the property values obtained from oracle functions as ground-truths for optimization.

## 3 Latent Prompt Transformer

### Model

Suppose \(x=(x^{(1)},...,x^{(t)},...,x^{(T)})\) is a molecule sequence, (e.g. a string-based representation like SMILES (Weininger, 1988) or SELFIES (Krenn et al., 2020; Cheng et al., 2023)), where \(x^{(t)}\) is the \(t\)-th element of sequence in the vocabulary \(\). The latent vector is \(z^{d}\) and \(y\) is the target property value, or \(y\{0,1\}\) indicates constraint satisfaction. The term _property_ refers to both real-valued properties and binary-valued constraints in the following sections. The joint distribution of a molecule and its property is defined as \(p(x,y)\).

The latent variable \(z\), conceptualized as a design representation, decouples the molecule generation from property prediction. Specifically, given \(z\), we assume \(x\) and \(y\) are conditionally independent, making \(z\) the information bottleneck. With this assumption, our Latent Prompt Transformer (LPT) is defined as,

\[p_{}(x,y,z)=p_{}(z)p_{}(x|z)p_{}(y|z), \]

where \(=(,,)\). \(p_{}(z)\) is a prior model with parameters \(\). Here, \(z\) serves as the latent prompt for the generation model \(p_{}(x|z)\) parameterized by a causal Transformer with parameters \(\). \(p_{}(y|z)\) is the predictor model with parameters \(\). As shown in Fig. 1, LPT defines the generation process as,

\[z p_{}(z),[x|z] p_{}(x|z),[y|z] p_{}(y|z). \]

For the prior model, \(p_{}(z)\) is formulated as a learnable neural transformation from an uninformative distribution, such as an isotropic Gaussian, \(z=U_{}(z_{0})\), where \(z_{0}(0,I_{d})\). \(U_{}()\) is parameterized by an expressive neural network such as a Unet (Ronneberger et al., 2015) with parameters \(\). In this way, \(p_{}(z)\) can be viewed as an implicit generator model.

The molecule generation model \(p_{}(x|z)\) is a conditional autoregressive model, \(p_{}(x|z)=_{t=1}^{T}p_{}(x^{(t)}|x^{(0)},...,x^{(t-1)},z)\), which is realized by a causal Transformer with parameters \(\). The latent vector \(z\), serving as the prompt, controls every step of the autoregressive molecule generation. We incorporate these latent prompts \(z\) into the \(p_{}(x|z)\) through cross-attention, as shown in Fig. 1.

The real-valued property predictor is a non-linear regression model \(p_{}(y|z)=(s_{}(z),^{2})\), where \(s_{}(z)\) is a small multi-layer perceptron (MLP) predicting \(y\) based on the latent prompt \(z\). The variance \(^{2}\) is treated as a hyper-parameter that balances the exploitation-exploration trade-off. For binary-valued constraints, \(p_{}(y|z)=s_{}(z)^{y}(1-s_{}(z))^{1-y}\). For multi-objective tasks, we can use heuristic-based combinations of multiple objectives to form a special single-objective function.

Figure 1: _Left_: Overview of Latent Prompt Transformer (LPT). The latent vector \(z^{d}\) is a neural transformation of \(z_{0}\), i.e., \(z=U_{}(z_{0})\), where \(z_{0}(0,I_{d})\). Given \(z\), \(x\) and \(y\) are independent. \(p_{}(x|z)\) is the molecule generation model and \(p_{}(y|z)\) predicts the property value or constraint based on \(z\). _Right_: Illustration of molecule generation model \(p_{}(x|z)\). The latent vector \(z\) is used as a prompt in the \(p_{}(x|z)\) via cross-attention.

### Maximum Likelihood Learning of LPT

Suppose we observe training examples from the dataset with molecule sequence and property pairs \(=\{(x_{i},y_{i}),i=1,...,n\}\). The log-likelihood function is \(L()=}{{n}}_{i=1}^{n} p_{}(x_{i},y_{i})\).

Since \(z=U_{}(z_{0})\), we can write the model as

\[p_{}(x,y)= p_{}(x|z=U_{}(z_{0}))p_{}(y|z=U_{} (z_{0}))p_{0}(z_{0})dz_{0}, \]

where \(p_{0}(z_{0})(0,I_{d})\). The learning gradient can be calculated as follows,

\[_{} p_{}(x,y)=_{p_{}(z_{0}|x,y)}[_ {} p_{}(x|U_{}(z_{0}))+_{} p_{}(y| U_{}(z_{0}))]. \]

For the prior model, the learning gradient is

\[_{}(x,y)=_{p_{}(z_{0}|x,y)}[_{} p_ {}(x|U_{}(z_{0}))+_{} p_{}(y|U_{}(z_{0} )))].\]

The learning gradient for the molecule generation model is

\[_{}(x,y)=_{p_{}(z_{0}|x,y)}[_{} p_{ }(x|U_{}(z_{0}))].\]

The learning gradient for the predictor model is

\[_{}(x,y)=_{p_{}(z_{0}|x,y)}[_{} p_ {}(y|U_{}(z_{0}))].\]

Estimating these expectations requires MCMC sampling of the posterior distribution \(p_{}(z_{0}|x,y)\). We use Langevin dynamics (Neal, 2011). For a target distribution \((z)\), the dynamics iterates as follows,

\[z^{+1}=z^{}+s_{z}(z^{})+^{}, \]

where \(\) indexes the time step, \(s\) is step size, and \(_{}(0,I_{d})\) is the Gaussian white noise. Here, \((z)\) is instantiated by the posterior distribution \(p_{}(z_{0}|x,y)\). With \(z=U_{}(z_{0})\), we have \(p(z_{0}|x,y) p_{0}(z_{0})p_{}(x|z)p_{}(y|z)\). The gradient is

\[_{z_{0}} p_{}(z_{0}|x,y)=_{z_{0}} (z_{0})}_{}+_{z_{0}}^{T} p_{} (x^{(t)}|x^{(<t)},z)}_{}+_{z_{0}} (y|z)}_{}.\]

We initialize \(z_{0}^{=0}(0,I_{d})\), and employ \(N\) steps of Langevin dynamics (e.g. \(N=15\)) for approximate sampling from the posterior distribution, rendering our learning algorithm as an approximate MLE. See Pang et al. (2020); Nijkamp et al. (2020); Xie et al. (2023) for a theoretical understanding of the learning algorithm based on the finite-step MCMC.

Pretrain LPTIn practical applications involving multiple molecular generation tasks, each characterized by a different target property \(y\), each model \(p_{}(x,y)\) may require separate training. To enhance efficiency, we adopt a pretaining strategy focusing solely on molecule sequences. In this case, we aim to maximize \(_{i=1}^{n} p_{}(x_{i})=_{i=1}^{n} p_{}(x_{i}, z_{i})dz_{i}\). The learning gradient is \(_{} p_{}(x)=_{p_{}(z_{0}|x)}[_{ } p_{}(x|z=U_{}(z_{0}))]\). After pretraining LPT, we finetune the model with target properties using Eq.5 for a small number of epochs. This two-stage approach is adaptable for semi-supervised scenarios where property values are limited.

### Property Conditioned Generation

After MLE learning from a collected (offline) dataset, LPT is capable of generating molecules with desired properties. Since the latent prompt is designed as the information bottleneck, we can generate the molecule given property value as \(p(x|y)= p(z_{0}|y)p(x|z_{0})dz_{0}\). We first infer the latent prompt via posterior sampling using Bayes' rule,

\[z_{0} p_{}(z_{0}|y) p_{0}(z_{0})p_{}(y|z=U_{}(z_ {0})). \]

This posterior sampling is performed using Langevin dynamics similar to the training process. Specifically, we replace the target distribution in Eq.6 with \(p_{}(z_{0}|y)\) and run MCMC for a fixed number of steps, i.e.,

\[z_{0}^{+1} =z_{0}^{}+s_{z_{0}} p(z_{0}|y)+^{ },\] \[_{z_{0}} p(z_{0}|y) =_{z_{0}}( p(z_{0})+ p(y|z_{0}))=-z_{0}+}(y-s_{}(z))_{z_{0}}s_{}(z). \]This process of sampling \(p(z_{0}|y)\) iteratively refines the latent prompts \(z\), increasing their likelihood given the desired property or constraints. This optimization of molecules is achieved in the latent space by gradient-based sampling as a form of test-time computation. Once we generate the latent prompt \(z\), the molecule generation model uses this latent prompt to sample the next element \(x^{(t)} p_{}(x^{(t)}|x^{(<t)},z=U_{}(z_{0}))\) until termination.

MLE learning of the joint model is equivalent to minimizing the \(D_{}(p_{}(x,y)\|p_{}(x,y))\). Note that Eq. (7) is reliable when condition \(y\) is supported by \(p_{}(y)\). However, in real-world molecule design, desired property values often lie far from those in the collected offline dataset. For such cases, LPT should be applied in an online learning setting, as discussed in the next section.

### Optimization via Online Learning with LPT

When the desired property value \(y\) is not supported within the learned distribution \(p_{}(z,x,y)\), we propose an online learning approach to gradually shift the model distribution towards regions supporting desired properties. We assume access to the oracle functions \(o(x)\) via software such as RDKit (Landrum et al., 2018), AutoDock-GPU (Santos-Martins et al., 2021).

As discussed in Sec. 3.3, generated molecules are reliable when the desired property value is supported by the learned model. To leverage this, we propose an iterative distribution shifting method, as shown in Alg. 2, as a form of online learning for LPT. In each iteration of distribution shifting, we

1. Sample molecules from the learned LPT, using incremental extrapolation to generate a synthetic dataset with improved desired properties.
2. Use hindsight relabeling for the sampled molecules' properties based on oracle functions.
3. Apply MLE learning of LPT based on this synthetic dataset of molecule-property pairs as described in Sec. 3.2.

This process is repeated until the model converges or budget limits are reached. This online learning method maintains a latent space generative model (LPT) and a synthetic dataset and gradually shifts both towards regions of desired targets.

In step (a), to account for small extrapolation, we use property-conditioned generation as mentioned in Sec. 3.3 by setting the desired property as \(y=y^{*}+_{y}\), where \(y^{*}\) lies on the boundary of the learned LPT in the previous shifting iteration (e.g. \(y^{*}\) can be the maximum value) and \(_{y}\) is a small increment representing extrapolation. The hyper-parameter \(_{y}\) quantifies the shifting speed. Specifically, since the latent prompts decouple the molecule generation and property prediction, we first sample the latent prompts \(z_{0} p_{}(z_{0}|y=y^{*}+_{y})\) before the molecule generation and then use \(x p_{}(x|z=U_{}(z_{0}))\) to generate the novel molecules. To sample molecules satisfying binary constraints, we use \(z_{0} p_{}(z_{0}|y=1)\). This latent space sampling scheme relieves the expensive autoregressive sampling in the data space, and allows efficient gradient-based sampling in low-dimensional latent space, such as Langevin dynamics. In step (b), after generating the novel molecules in step (a), we use the oracle function \(o(x)\) to relabel them, obtaining a synthetic dataset of molecule-property pairs with ground-truth values. This synthetic dataset serves as a replay buffer, storing generated molecules along the optimization trajectory, and is used for MLE training of the LPT in step (c). The illustration of the online learning of LPT is depicted in Fig. 2.

Compared to population-based methods such as genetic algorithms (Nigam et al., 2020) and particle-swarm algorithms (Winter et al., 2019), our method maintains both a synthetic dataset (which can be considered a small population) and a generative model to fit the dataset, enabling the improvement of generated molecules from the model. The model itself can be seen as an infinite population, as it can generate an unlimited number of new samples.

### Efficiency Analysis

In molecule design, computational efficiency and sample efficiency are crucial, with varying priorities depending on the objectives. Computational efficiency measures the ability to learn quickly with limited resources, while sample efficiency assesses the capacity to learn a good model with minimal oracle function interactions. Generative models are applied to molecular design for two purposes: obtaining starting points and optimizing them to meet specific objectives. For objectives accessible via existing software, computational efficiency is prioritized, aiming to train the model and query software as quickly as possible until convergence. For properties that are time-consuming and expensive to simulate, such as wet-lab experiments, sample efficiency is more important, minimizing the number of oracle queries for practical usage. In real-world scenarios, a combination of both may be necessary, depending on the specific requirements. We propose the following techniques for LPT to address efficiency issues accordingly.

**Computational efficiency** The computational overhead for online learning of LPT primarily arises from the iterative MCMC sampling procedure. In the posterior sampling stage of \(p_{}(z_{0}|y)\) and \(p_{}(z_{0}|x,y)\) in step (a) and (c), rather than using a Gaussian noise-initialized MCMC chain with a fixed number of MCMC steps (\(N=15\)) for each learning iteration, we employ the Persistent Markov Chain (PMC) method (Tieleman, 2008; Xie et al., 2016; Han et al., 2017; Xie et al., 2019), which amortizes sampling across shifting iterations. Specifically, for the starting point \(z_{0}^{=0}\) in Eq. (6) of each MCMC chain, its initialization is drawn from a Gaussian distribution at the first learning iteration, then subsequently from the previous iteration's sampling output. With this approach, the number of MCMC updates can be reduced to \(N=2\) steps per sampling stage, achieving an approximate \(5\) speedup in posterior sampling.

**Sample efficiency** We aim to improve sample efficiency in both steps (a) and (c) in Sec. 3.4. In step (a), property-conditioned generation, we refine the exploration strategy during test-time computation. This approach demonstrates a clear advantage of posterior inference over direct use of VAE or GAN. By guiding the learned LPT towards exploitation during generation, we encourage the latent prompts \(z\) to converge on the modes of the posterior distribution in Langevin dynamics. This concept is analogous to the intuition behind classifier guidance in conditional diffusion models (Dhariwal and Nichol, 2021; Ho and Salimans, 2022). In Eq. (8), we can adjust \(^{2}\) to balance the trade-off between exploitation and exploration: \(_{z_{0}} p(z_{0}|y)=_{z_{0}}( p(z_{0})+ p(y|z_{0}))=- z_{0}+}(y-s_{}(z))_{z_{0}}s_{}(z)\). When \(}{{^{2}}}=1\), the sampled latent prompts \(z\) represent the density of the posterior distribution, resulting in an efficient exploration scheme. As \(}{{^{2}}}\) increases, the sampled posterior \(z\) concentrates around the modes of the posterior distribution, indicating increased confidence and a stronger bias towards exploitation. In step (c), we leverage the synthetic dataset to train the LPT on the most informative samples in terms of property values. By training the LPT on a distribution that assigns higher probability mass to high-value points and lower mass to low-value points, the training objective encourages a larger fraction of the feasible region's volume to model high-value points while simultaneously using other data points to learn useful representations and avoid overfitting. We modify the standard objective \(_{i=1}^{n_{1}}}{{n}} p_{}(x_{i},y_{i})\) by assigning an importance weight \(w_{i}\) to each molecule-property pair \((x_{i},y_{i})\) in the synthetic dataset, resulting in a biased objective function, \(_{i=1}^{n}w_{i} p_{}(x_{i},y_{i})\), where \(_{i}w_{i}=1\). In our experiments, we set \(w_{i}=1/N\) if \(y_{i}\) is in the top-\(N\) property scores, and \(w_{i}=0\) otherwise. This approach is inspired by prioritized experience replay (Schaul et al., 2015) in online reinforcement learning and weighted retraining (Tripp et al., 2020) in black-box optimization, both of which prioritize learning from the most informative samples to improve sample efficiency.

## 4 Related Work

**Latent space optimization** Latent space optimization has been widely applied in generative models and high-dimensional data manipulation (Jin et al., 2018; Kusner et al., 2017; Kajino, 2019; Dai et al., 2018). This method involves representing data in a lower-dimensional space while retaining its essential characteristics. Latent space optimization improves the fidelity and quality of generated data and facilitates more efficient and effective exploration of the latent space. This leads to better generalization and robustness in various applications, such as image synthesis (Karras et al., 2019; Razavi et al., 2019; Song et al., 2020; Dhariwal and Nichol, 2021; Rombach et al., 2022), data

Figure 2: Illustration of online learning LPT. For each shift iteration, we plot the densities of docking scores \(E\) using AutoDock-GPU. The increase of the docking scores indicates better binding affinity.

compression (Balle et al., 2016; Mentzer et al., 2018), molecular optimization (Kong et al., 2023; Jain et al., 2023; Zhu et al., 2024), and automatic machine learning (Liu et al., 2018; Zhang et al., 2019). When the search space is significantly simplified in the latent space, familiar Bayesian optimization (BO) tools can be readily applied (Maus et al., 2022; Tripp et al., 2020). Unlike BO-based methods, our LPT is based on the explicit probabilistic form of \(p(z|y)\), which allows us to perform optimization as conditional generation using Bayes' rule.

**Generative molecule design** This research follows two main approaches. The first uses latent space generative models to translate discrete molecule graphs into continuous latent vectors, enabling optimization of molecular properties within the latent space (Gomez-Bombarelli et al., 2018; Kusner et al., 2017; Jin et al., 2018; Maziarz et al., 2021; Eckmann et al., 2022; Kong et al., 2023). The second directly employs combinatorial optimization methods, such as reinforcement learning, to fine-tune molecular attributes within the graph data space (You et al., 2018; De Cao and Kipf, 2018; Zhou et al., 2019; Shi et al., 2020; Luo et al., 2021; Du et al., 2022). Alternative data space methodologies, like genetic algorithms (Nigam et al., 2020), particle-swarm strategies (Winter et al., 2019), Monte Carlo tree search (Yang et al., 2020), and scaffolding trees (Fu et al., 2021), have also gained traction.

## 5 Experiments

We demonstrate the effectiveness of our approach across a wide range of optimization tasks. In the context of molecule design, this includes binding affinity maximization, constrained optimization, and multi-objective optimization (see Sec. 5.2). Additionally, we optimize protein sequences for high fluorescence and DNA sequences for enhanced binding affinity (see Sec. 5.3). Finally, we validate the sample efficiency of LPT by performing optimization with a limited number of oracle function queries (see Sec. 5.4). Additional experiments, including robustness to noisy oracles, online learning from scratch, ablation studies and a detailed discussion of related works and baselines, are provided in Apps. A.2 and A.4.

### Overview

**Molecule Sequence Design** For molecule design tasks, we use SELFIES representations of the ZINC (Irwin et al., 2012) dataset, which comprises \(250\)K drug-like molecules as our offline dataset \(\). We utilize RDKit (Landrum et al.) to compute several key metrics, including penalized logP, drug-likeness (QED), and the synthetic accessibility score (SA). Additionally, we use AutoDock-GPU (Santos-Martins et al., 2021) to derive docking scores \(E\), which serve as proxies for estimating the binding affinity of compounds to three protein targets: the human estrogen receptor (ESR1), human peroxisomal acetyl-CoA acyltransferase 1 (ACAA1), and Phosphoglycerate dehydrogenase (PHGDH). The binding affinity is expressed as the dissociation constant \(K_{D}()\), which is approximated by the formula \(K_{D} e^{-E/c}\), where \(E\) is the docking score and \(c\) is a constant. A lower \(K_{D}\) value indicates stronger binding affinity. ESR1 is a well-characterized protein with numerous known binders, making it a suitable reference point for evaluating molecules generated by our model. In contrast, ACAA1 has no known binders, providing an opportunity to test the model's capability for _de novo_ design (Eckmann et al., 2022). Additionally, we propose to design molecules that bind to PHGDH, an enzyme pivotal in the early stages of L-serine synthesis. Recently, PHGDH has gained attention as a potential therapeutic target in cancer treatment due to its involvement in various human cancers (Zhao et al., 2020). The crystal structure of PHGDH (PDB: 2G76) is well-established, and there exists a comprehensive case study on the development of PHGDH inhibitors, showcasing a structure-based progression from simpler to more complex molecules targeting its NAD binding site (Spillier and Frederick, 2021), as illustrated in Fig. 3. Furthermore, we observe that the \(K_{D}\) values estimated from wet lab experiments align closely with the trends predicted by AutoDock-GPU. This congruence makes PHGDH-NAD an excellent case study for testing LPT on single-objective, structure-constrained, and multi-objective optimization tasks using AutoDock-GPU. More details can be found in App. A.5.

**Protein and DNA Sequence Design** We further apply our method to biological sequence design via two tasks in Design-Bench (Trabucco et al., 2022): TF Bind 8 and GFP. To be specific, the TF Bind 8 task focuses on identifying DNA sequences that are 8 bases long, aiming for maximum binding affinity. This task contains a training set of 32,898 samples and includes an exact oracle function. The GFP task involves generating protein sequences of 237 amino acids that exhibit high fluorescence.

For this task, we use a subset of 5,000 samples as the training set by following the methodology outlined in Trabucco et al. (2022). Due to the unavailability of an exact oracle function for the GFP task, we follow the same oracle function preparation as in Design-Bench, and train a Transformer regression model on the full dataset with a total of 56,086 samples as the oracle function. We evaluate the design performance and diversity of the generated samples.

**Training Setup** The prior model, \(p_{}(z)\), of LPT is a one-dimensional UNet (Ronneberger et al., 2015) where \(z\) contains \(4\) tokens, each of size \(256\). The sequence generation model, \(p_{}(x|z)\), is implemented as a 3-layer causal Transformer, while a 3-layer MLP serves as the predictor model, \(p_{}(y|z)\). As described in Sec. 3.2, we pre-train LPT on molecules for 30 epochs and then fine-tune it with target properties for an additional 10 epochs, following the procedure outlined in Alg. 1 in App. A.3. We perform up to 25 iterations of online learning, generating 2,500 samples per iteration, which totals a maximum of \(62.5\)K oracle function queries. We use the AdamW optimizer (Loshchilov and Hutter, 2019; Kingma and Ba, 2014) with a weight decay of 0.1. Training was conducted on an NVIDIA A6000 GPU, requiring 20 hours for pre-training, 10 hours for fine-tuning, and 12 hours for online learning. Additional details can be found in App. A.3.

### Binding Affinity Maximization

**Single-Objective Optimization** For the single-objective binding affinity optimization task, we aim to design ligands with optimal binding affinities to ESR1, ACAA1, and PHGDH as _de novo_ design, without any constraints. LPT does not use any prior knowledge of existing binders, and exclusively uses the crystal structures of the aforementioned proteins. The predictor model \(p_{}(y|z)\) for this task is a regression model that estimates docking scores. We compare our model with several baseline methods, which are introduced in App. A.4. As shown in Tabs. 1 and 2, our model significantly surpasses other methods across all three binding affinity maximization tasks in terms of \(K_{D}\), often achieving substantial improvement. Lower \(K_{D}\) values indicate better performance. Furthermore, in Tab. 2, we report the average performance of the top 50 and top 100 molecules to demonstrate that our model can effectively generate a diverse pool of candidate molecules with the desired properties. Visualizations of generated molecules are provided in App. A.6.1.

**Structure-constrained Optimization** The structure-constrained optimization task mimics lead optimization in drug discovery, aiming to decorate a fixed core substructure to optimize activity and pharmacological properties. Our model's factorization, \(p(z,x,y)=p(z)p(x|z)p(y|z)\), enables the decoupling of molecule generation and property prediction, simplifying conditional generation.

    & _{}\) (\(\))} & _{}\) (\(\))} \\  & 1st & 2rd & 3rd & 1st & 2rd & 3rd \\  GCPN & 6.4 & 6.6 & 8.5 & 75 & 83 & 84 \\ MolDQN & 373 & 588 & 1062 & 240 & 337 & 608 \\ MARS & 25 & 47 & 51 & 370 & 520 & 590 \\ GraphDF & 17 & 64 & 69 & 163 & 203 & 236 \\ LIMQ & 0.72 & 0.89 & 1.4 & 37 & 37 & 41 \\ SGDS & 0.03 & 0.03 & 0.04 & 0.11 & 0.11 & 0.12 \\ 
**LPT** & **0.004** & **0.005** & **0.009** & **0.037** & **0.041** & **0.045** \\   

Table 1: Single-objective binding affinity optimization results for ESR1 and ACAA1. Top 3 performance in terms of \(K_{D}()\) achieved by each model are reported. The best scores are in bold.

    & _{}\) (\(\))} \\  & LIMQ & SGDS & LPT \\ 
1st & 13.87 & 3.65 & **0.07** \\
2nd & 18.79 & 6.59 & **0.16** \\
3rd & 21.15 & 7.16 & **0.19** \\ Tor-50 & 81.16 + 34.41 & 14.7 + 5.43 & **0.95 \(\) 0.46** \\ Tor-100 & \(125.06 52.59\) & \(24.5 14.0\) & **1.66 \(\) 0.82** \\   

Table 2: Single-objective binding affinity maximization results for PHGDH, reporting the 1st, 2nd, and 3rd performance, along with average performance of top 50 and top 100 molecules for each model. Performance is measured by \(K_{D}(10^{-2})\). The highest scores are in bold.

Figure 3: Illustration of the development of PHGDH inhibitors (Spillier and Frédérick, 2021). Surface Plasmon Resonance (SPR) and AutoDock \(K_{D}\) values are reported for each inhibitor. The trends observed between the experimental SPR values and the computational AutoDock values align well, validating the computational approach.

Given a substructure \(=(x^{(1)},,x^{(k)})\), we aim to sample from \(p_{}(x,y|)\). This is accomplished by sampling \(z p(z|y)\) and then \(x p(x|,z)\), which only requires rearranging \(\)'s sequence to start from the desired atom. In Fig. 3, Compound 2 (C2) is designed by humans as an extension of Compound 1 (C1), and Compound 3 (C3) is similarly an extension of C2. In Fig. 4, we show that: (1) given C1 or C2, our model is able to design compounds similar to the human-designed C2 or C3, and (2) our model can identify molecules that outperform those designed by humans. Meanwhile, we confirm that C2, C3, and LPI-generated molecules are _novel_ compared to the ZINC training set, with an average Tanimoto similarity less than \(0.5\). More generated molecules are shown in App. A.6.2.

Our model explores high-affinity PHGDH inhibitors by adding functional groups to an indole backbone, a common scaffold for such inhibitors (Spillier and Frederick, 2021). The model identifies aromatic or heteroaromatic groups, such as benzene or pyridine, at the second position as frequently occurring and exhibiting higher binding scores compared to the indole backbone itself. This finding aligns with reported data: a published molecule with a benzothiophene backbone similar to C1 exhibits a binding affinity of 470 \(\)M, while C2, which includes an aromatic group at the second position, shows a significantly improved binding affinity of 1.6 \(\)M (Spillier and Frederick, 2021; Fuller et al., 2016). Furthermore, the model introduces a second functional group at the sixth position of the indole in C2, generating inhibitors closely resembling the structure of C3. The observed trend of increasing binding affinities (1.6 \(\)M for C2 and 0.18 \(\)M for C3) aligns with the literature values, providing validation for our proposed method in identifying potential high-affinity inhibitors.

**Multi-Objective Optimization** For multi-objective optimization tasks, we aim to simultaneously maximize binding affinity and QED, while minimizing SA. These objectives are balanced as a weighted combination, with constraints of QED \(>0.4\) and SA \(<5.5\). We evaluate our method on three protein targets: ESR1, ACAA1, and PHGDH, comparing the results against two baseline methods, LIMO (Eckmann et al., 2022) and SGDS (Kong et al., 2023). As shown in Tab. 3, our method, LPT, achieves QED and SA scores comparable to those of SGDS while significantly improving binding affinity across all three protein targets, demonstrating its superior modeling capability. Examples of the generated molecules are provided in App. A.6.1.

Figure 4: (a) Structure-constrained Optimization. Conditionally generated compounds C2 and C3 closely resemble the human-designed compounds C2 and C3 shown in Fig. 3. Additionally, the right column also presents further optimized compounds that achieve improved \(K_{D}\) scores. (b) Illustration of generated molecules binding to PHGDH with docking poses generated by AutoDock-GPU. The left panel visualizes the molecule generated through multi-objective optimization, while the right panel displays the molecule generated via structure-constrained optimization.

    &  &  &  \\  & \(_{}\) & QED \(\) & SA \(\) & K \(\) & QED \(\) & SA \(\) & K \(\) & QED \(\) & SA \(\) \\  LIMO 1\({}^{}\) & 4.6 & 0.43 & 4.8 & 28 & 0.57 & 5.5 & 29.15 & 0.33 & 4.73 \\ LIMO 2\({}^{}\) & 2.8 & **0.64** & 4.9 & 31 & 0.44 & 4.9 & 42.98 & 0.20 & 5.32 \\ SGDS 1\({}^{}\) & 0.36 & 0.44 & 3.99 & 4.55 & 0.56 & **4.07** & 4.47 & **0.54** & 3.37 \\ SGDS 2\({}^{}\) & 1.28 & 0.44 & 3.86 & 5.67 & 0.60 & 4.58 & 5.39 & 0.42 & 4.02 \\ 
**LPT 1\({}^{}\)** & **0.04** & 0.58 & 3.46 & **0.18** & 0.50 & 4.85 & **0.02** & 0.50 & **3.11** \\
**LPT 2\({}^{}\)** & 0.05 & 0.46 & **3.24** & 0.21 & **0.61** & 4.18 & 0.03 & 0.43 & 3.22 \\   

Table 3: Multi-objective optimization Results. Top 2 performance, measured by \(K_{D}()\), QED and SA, are reported for each method. Baseline methods include LIMO (Eckmann et al., 2022) and SGDS (Kong et al., 2023). Best results are marked in bold, and the second best results are underlined.

### Biological Sequence Design

Our model excels in biological sequence design, a single-objective optimization application, as demonstrated by two benchmarks in Design-Bench (Trabucco et al., 2022): TF Bind 8 and GFP. Tab. 4 shows that LPT significantly outperforms other methods in these tasks. In the TF Bind 8 task, our approach surpasses the strong competitor GFlowNet-AL (Jain et al., 2022), while maintaining comparable diversity. For the GFP task, we achieve superior performance with reasonable diversity.

### Sample Efficiency

We validate LPT's sample efficiency on the Practical Molecular Optimization (PMO) benchmark (Gao et al., 2022), where multi-property objectives (MPO) are optimized within a limited oracle budget of 10K queries. Tab. 5 shows that our method, LPT, surpasses previous approaches, such as MARS (Xie et al., 2021), GFlowNet (Jain et al., 2022) and SMILES/SELFIES-VAE (Gomez-Bombarelli et al., 2018; Maus et al., 2022) with Bayesian Optimization (BO). Also, LPT achieves comparable performance to LSTM HC (Brown et al., 2019), the best generative molecule design method in PMO, and demonstrates performance on par with GP-BO (Tripp et al., 2021), the best BO-based method in PMO, under the limited budge of oracle function queries. We acknowledge that there remains a performance gap between generative model-based optimization and methods like genetic algorithms when working with a small budget. This is primarily due to the data-intensive requirements of training generative models. To ensure a fair assessment, our comparison focuses on representative generative molecule design methods within PMO. It's worth noting that generative models offer distinct advantages when maintaining relatively large budgets, as the learned model itself can be viewed as infinite populations for further exploration.

## 6 Limitation and Conclusion

In this work, we presented LPT, a novel generative model for molecule design that achieves strong performance through its offline and online learning algorithms. Contemporary work has extended the similar model to offline reinforcement learning (Kong et al., 2024). While the model demonstrates significant potential, there are opportunities to better understand how LPT handles the inherent trade-offs in multi-objective optimization scenarios, particularly in characterizing the Pareto front nature of optimal solutions. Future work could also explore alternative architectures to extend LPT's applicability beyond sequence-based optimization problems in science and engineering.

   Method &  &  \\  & Performance & Diversity & Performance & Diversity \\  DynaPPO & \(0.58 0.02\) & \(5.18 0.04\) & \(0.05 0.008\) & \(12.54 1.34\) \\ COMS & \(0.74 0.04\) & \(4.36 0.24\) & \(0.831 0.003\) & \(8.57 1.21\) \\ BO-OEI & \(0.44 0.05\) & \(4.78 0.17\) & \(0.045 0.003\) & \(12.87 1.09\) \\ CaAS & \(0.45 0.14\) & \(5.35 0.16\) & \(0.817 0.012\) & \(8.53 0.65\) \\ MINS & \(0.40 0.14\) & \(\) & \(0.761 0.007\) & \(8.31 0.02\) \\ CMA-ES & \(0.47 0.12\) & \(4.89 0.01\) & \(0.063 0.003\) & \(10.52 4.24\) \\ AmortizedBO & \(0.62 0.01\) & \(4.97 0.06\) & \(0.051 0.001\) & \(16.14 2.14\) \\ GFlowNet-AL & \(0.84 0.05\) & \(4.53 0.46\) & \(0.05 0.010\) & \(\) \\ 
**LPT** & \(\) & \(4.58 0.06\) & \(\) & \(9.45 0.23\) \\   

Table 4: Results of biological sequence design on TF Bind 8 and GFP benchmarks. Performance and diversity are evaluated on 128 samples. Results of other baselines are obtained from Jain et al. (2022). Bold highlighting indicates top scores.

   Method &  &  &  &  &  &  &  \\  GFlowNet & 0.444 \(\) 0.004 & 0.693 \(\) 0.006 & 0.784 \(\) 0.001 & 0.430 \(\) 0.010 & 0.652 \(\) 0.002 & 0.035 \(\) 0.030 & 3.038 \\ MARS & \(0.504 0.016\) & \(0.711 0.006\) & 0.777 \(\) 0.006 & 0.462 \(\) 0.006 & \(\) & 0.187 \(\) 0.046 & 3.381 \\ LSTM HC & \(0.593 0.016\) & \(\) & \(\) & \(\) & 0.714 \(\) 0.008 & 0.206 \(\) 0.006 & 3.523 \\ SMILES-VAE BO & \(0.533 0.009\) & \(0.671 0.003\) & \(0.771 0.002\) & \(0.442 0.004\) & 0.457 \(\) 0.012 & 0.039 \(\) 0.012 & 2.913 \\ SELFIES-VAE BO & \(0.516 0.005\) & \(0.670 0.004\) & \(0.765 0.002\) & \(0.429 0.003\) & \(0.452 0.025\) & 0.206 \(\) 0.015 & 3.038 \\ GP-BO & \(0.583 0.044\) & \(0.722 0.005\) & \(0.787 0.006\) & 0.493 \(\) 0.011 & 0.735 \(\) 0.013 & 0.221 \(\) 0.072 & 3.541 \\ 
**LPT** & \(\) & \(0.714 0.003\) & \(0.784 0.011\) & \(\) & \(0.682 0.007\) & \(\) & \(\) \\   

Table 5: Comparison of sample efficiency on the PMO benchmark. The mean and standard deviation of AUC Top-10 from 5 independent runs are reported. Best results are marked in bold.