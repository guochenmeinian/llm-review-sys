# Equivariant Single View Pose Prediction

Via Induced and Restricted Representations

 Owen Howell

\({}^{1}\) Department of Electrical and Computer Engineering, Northeastern University

David Klee

\({}^{1}\) Department of Electrical and Computer Engineering, Northeastern University

Ondrej Biza

\({}^{1}\) Department of Electrical and Computer Engineering, Northeastern University

Linfeng Zhao

\({}^{1}\) Department of Electrical and Computer Engineering, Northeastern University

Robin Walters

\({}^{1}\) Department of Electrical and Computer Engineering, Northeastern University

###### Abstract

Learning about the three-dimensional world from two-dimensional images is a fundamental problem in computer vision. An ideal neural network architecture for such tasks would leverage the fact that objects can be rotated and translated in three-dimensions to make predictions about novel images. However, imposing \((3)\)-equivariance on two-dimensional inputs is difficult because the group of three-dimensional rotations does not have a natural action on the two-dimensional plane. Specifically, it is possible that an element of \((3)\) will rotate an image out of the plane. We show that an algorithm that learns a three-dimensional representation of the world from two-dimensional images must satisfy certain consistency properties which we formulate as \((2)\)-equivariance constraints. We use the induced and restricted representations of \((2)\) on \((3)\) to construct and classify architectures that satisfy these consistency constraints. We prove our construction realizes all possible architectures that respect these constraints. We show that three previously proposed neural architectures for 3D pose prediction are special cases of our construction. We propose a new model that generalizes previously considered methods and contains additional trainable parameters. We test our architecture on three pose prediction tasks and achieve SOTA results on both the PASCAL3D+ and SYMSOL pose estimation tasks.

## 1 Introduction

One of the fundamental problems in computer vision is learning representations of 3D objects from 2D images [1; 2; 3]. By understanding how image features correspond to a physical object, a model can generalize better to novel views of the object, for instance, when estimating the pose of an object. In general, neural networks that respect the symmetries of a problem are more noise robust and data efficient, while also less prone to over-fitting . Three-dimensional space has a natural symmetry group of three-dimensional rotations and three-dimensional translations, \((3)\). While we would like to leverage this symmetry to design improved neural architectures, serious challenges exist in incorporating 3D symmetry when applied to image data. Specifically, a projection of a three-dimensional scene into a two-dimensional plane does not transform equivariantly under all elements of \((3)\). This is because there is no a priori model for how two-dimensional images transform under out-of-plane object rotations. Cohen and Welling  showed how to design neural networks that are explicitly \((2)\)-equivariant and accept images as inputs. However, \((2)\)-equivariant methods ignore the fact that the group \((3)\) acts on the space of pose configurations.

Equivariant neural networks are much more constrained than general multi-layer perceptrons. The requirement of equivariance to a group \(G\) places strict restrictions on the allowed linear maps and theallowed non-linear functions in each network layer [5; 6]. Because of this, the possible structures of \(G\)-equivariant neural networks can be completely classified based on the representation theory of the group \(G\)[4; 7; 8]. For compact groups, it is possible to characterize the structure of all possible kernels of \(G\)-equivariant networks .

We argue that any equivariant machine learning algorithm that builds a three-dimensional model of the world from two-dimensional images must satisfy a natural geometric consistency property. This consistency property can be stated as \((2)\)-equivariance with respect to only the \((2)\) subgroup acting along the camera viewing orientation (see Figure 1). We give a complete characterization of maps that satisfy this property. This derivation uses the so-called restricted representation of \((2)\) since the group action is restricted from the full \((3)\). Using the Frobenius Reciprocity theorem, we show that this geometric constraint can also be derived using induced representations, a type of representation of \((3)\) constructed from representations of \((2)\). The classification theorems derived in [5; 8; 4] assume that both the input and output layers are \(G\)-equivariant. The construction presented in \(4\) is different; we map \(H\)-equivariant functions to \(G\)-equivariant functions. Our arguments using induced and restricted representations give a natural generalization of equivariant maps between different groups. We derive analogies of the theorems presented in [9; 8] for the induced and restricted representations.

### Importance and Contribution

In this work, we will show how induced and restricted representations can be used to construct neural architectures that accept image data and leverage \((3)\)-equivariant methods to avoid learning nuisance transformations in three-dimensional space.

We show that our construction satisfies two desirable theoretical properties, _completeness_ and _universality_. Let \(H G\). We focus on the case \(G=SO(3)\) and let \(H=SO(2)\) but we give a theoretical analysis for general groups. Specifically, the induced representation construction is _complete_ in that all group-valued functions on \(G\) can be induced from a set of group-valued functions on \(H\). The construction is _universal_ in that all multi-linear maps that map \(H\)-equivariant functions to \(G\)-equivariant functions are specific cases of the induced representation, modulo isomorphism. Furthermore, we show that the architectures proposed in [10; 11] are special cases of our construction for the icosahedral group \(G=A_{5}\) and the construction proposed in  is a special case of our construction for the three-dimensional rotation group \(G=(3)\). Our method achieves state of the art performance for orientation prediction on PASCAL3D+  and SYMSOL  datasets.

#### Contributions:

* We propose a unified theory for learning three-dimensional representations from two-dimensional images. We show that algorithms that learn three-dimensional representations from two-dimensional images must satisfy certain consistency properties, which are equivalent to \((2)\)-steerability constraints.
* We introduce a fully differentiable layer called an _induction/restriction layer_ that maps signals on the plane into signals on the sphere. We show that the induction/restriction layer satisfies a natural consistency constraint and prove both a completeness and universal property for our construction.
* Our method achieves SOTA performance for orientation prediction on PASCAL3D+ and SYMSOL datasets.

Figure 1: A map \(:^{}\) from signals on \(^{2}\) to signals on \(S^{2}\). Let \((2)\) be the subgroup that consists of all in-plane rotations (i.e. about the axis defined by the red arrow). The map \(\) must be equivariant with respect to this \((2)(3)\) subgroup.

Related Work

Equivariant LearningIncorporating task symmetry into the design of neural networks has been effective in domains such as computer vision [15; 16], point cloud processing [17; 18], and robotics . Cohen and Welling  introduced steerable kernels which are a trainable layer that can be used to build networks that are equivariant to 2D [5; 20] and 3D transformations [21; 22]. The majority of past works have studied end-to-end equivariant models, where the input can be transformed by the action of the group and all layers are equivariant, in this work, we explore how to 'fuse' \(SO(2)\) and \(SO(3)\) equivariant layers.

There has been growing interest in leveraging 3D symmetry from 2D inputs. [23; 24] learned a 3D transformable latent space from images of a single object.  trained a convolutional network to predict pre-trained \((3)\) equivariant embeddings, while [11; 10; 12] mapped image features onto elements of the discrete group of \((3)\), using structured viewpoints or a hand-coded projections, respectively. In contrast to prior work, we provide a theoretical foundation for learned equivariant mappings from 2D to 3D, which additionally guides us to introduce a more general and effective trainable operation.

Object Pose EstimationPredicting the 3D orientation of objects is an important problem in fields like autonomous driving , robotics  and cryogenic electron microscopy . Many works [29; 30] have used a regression approach, and others [31; 32; 33] have identified ways to mitigate the discontinuities along the \((3)\) manifold. More recent works have explored ways to model orientation as a distribution over 3D rotations, which handles object symmetries and captures uncertainty. ,  and  predict parameters for Bingham, von Mises and Laplace distributions, respectively. These families of distributions can have limited expressivity, so other work explored using implicit networks  or the Fourier basis  to model more complex pose distributions. Inspired by [12; 23], we parameterize the latent object pose as a distribution on \(SO(3)\) and then ask what constraints need to be imposed to enforce \((2)(3)\)-equivariance A.0.4, which is a generalization of \((2)\)-equivariance.

## 3 Background

We introduce the induced and restricted representations. For a more extensive review of representation theory, see A.

Let \(G\) be a group and \(V\) be a vector space over \(\). A _representation_\((,V)\) of \(G\) is a map \(:G[V,V]\) such that

\[ g,g^{} G,\ \  v V,(g g^{})v= (g)(g^{})v\]

Concisely, a group representation is an embedding of a group into a set of matrices. The matrix embedding must obey the multiplication rule of the group. We now introduce the _restricted representation_ and _induced representation_.

Restricted RepresentationLet \(H G\) be a subgroup. Let \((,V)\) be a representation of \(G\). The restricted representation of \((,V)\) from \(G\) to \(H\) is denoted as \(_{H}^{G}[(,V)]\). Intuitively, \(_{H}^{G}[(,V)]\) can be viewed as \((,V)\) evaluated on the subgroup \(H\) of \(G\). Specifically,

\[ h H,\ \  v V,_{H}^{G}[](h)v=(h)v\]

For a more in depth discussion of the restricted representation, please see A.

Induced RepresentationThe induced representation is a way to construct representations of a larger group \(G\) out of representations of a subgroup \(H G\). Let \((,V)\) be a representation of \(H\). The induced representation of \((,V)\) from \(H\) to \(G\) is denoted as \(_{H}^{G}[(,V)]\). Define the space of functions

\[=\{\ f\ \ f:G V,\ \  h H,\ \ f(gh)=(h^{-1})f(g)\ \}\]

Then the induced representation is defined as \((,)=_{H}^{G}[(,V)]\) where the induced action \(\) acts on the function space \(\) via

\[ g,g^{} G,\ \  f,((g) f)(g^{ })=f(g^{-1}g^{})\]Please see A for an in depth discussion of the induced representation. The induced and restricted representations are adjoint functors .

## 4 Method

Convolutional networks or vision transformers are typically used to extract spatial feature maps from 2D images. For convenience we ignore discretization and treat the feature maps as having continuous inputs \(f:^{2}^{d}\). To leverage spatial symmetries in 3D, we would like to map our features \(f\) from a plane onto a sphere: \(g:S^{2}^{D}\). Klee et al.  proposed one such mapping, where the planar feature map is stretched over a hemisphere, but other possible mappings exist.

We formalize the equivariance property that every projection should have through the theory of induced and restricted representations. The constraints that we impose have an intuitive geometric interpretation. We give a complete characterization of _all possible_ linear and equivariant projections \(\) from planar features to a spherical representation. Our general formulation includes  as a special case, and we show that a learnable equivariant projection leads to better predictive models.

### Equivariant 2D to 3D Projection by Induced and Restricted Representations

We first derive the \((2)\)-equivariance constraint for the most general linear mapping from images to spherical signals.

Image inputsWe first describe \(\) the space of image input signals. Let \(V\) and \(V^{}\) be vector spaces. Let \(\) be the vector space of all \(V\)-valued signals defined on the plane

\[=\{\ f\ \ f:^{2} V\ \ \}.\]

Elements of \(\) are sometimes called \((2)\)-steerable feature fields . The group \((2)=^{2}(2)\) of 2D translations and rotations acts on \(\) via representation \(\). Each \(h(2)\) has a unique factorization \(h=h_{c}\) where \(^{2}\) is a translation and \(h_{c}(2)\) is a rotation. Let \((,V)\) be an \((2)\)-representation describing the transformation of the fibers of the features \(f\). Then the action \(\) is defined

\[ f,\ \ r^{2},\ \ h(2),\ \ \ \ \ (h) f(r)=(h_{c})f(h^{-1}r)\]

so that \((,)=_{(2)}^{(2)}[(,V)]\) and \((,)\) gives a representation of the group \((2)\).

Spherical outputsWe would like to map signals in \(\) to functions from \(S^{2}\) into the vector space \(V^{}\). Let \(^{}\) be the vector space of all such outputs defined as

\[^{}=\{\ f\ \ f:S^{2} V^{}\ \}\]

The group \((3)\) acts on the vector space \(^{}\) via

\[ f^{}^{},\ \  S^{2},\ \ g (3),\ \ \ ^{}(g) f^{}()=^{}(g)f^{}(g^{-1 })\]

where \(^{}(g)\) describes the \((3)\) fiber representation.

\((2)\)-equivariant image to sphereLet \(H=(2)\) be the \((2)\) subgroup of \((3)\) that corresponds to in-plane rotations of the image. Our goal is to classify \(H\)-equivariant linear maps \(:^{}\). This is equivalent to the constraint that

\[ h H=(2),\ \ f,\ \ \ ((h) f)=^{ }(h)(f)\] (1)

The constraint enforces equivariance with respect to \((2)\) transformations. By definition, the evaluation of \(^{}(h)\) at \(h(2)\) is the restricted representation \(^{}(h)=_{(2)}^{(3)}[^{} ](h)\).

### Solving the Kernel Constraint

We use tools from [38; 8] to solve for the space of all possible maps satisfying the constraint 1, giving the trainable space for the image to sphere layer.

Our conclusion is that instead of mapping arbitrary \((2)\)-input representations to arbitrary \((2)\)-output representations, the allowed input and output representations \((,V)\) and \((^{},V^{})\) must satisfy additional constraints. Specifically, not every representation can be realized as the restriction of an \((3)\) to \((2)\) representation 2. Although in this paper we focus on orientation estimation, the equivariant framework in Section C.0.1 is more general. In the Appendix D, we formulate and solve analogous equivariance constraints for both 6DoF-pose estimation and monocular volume reconstruction.

**Theorem 1**.: _The constraint in Equation 1 can be solved exactly using the results of [38; 8]. The most linear general map \(:^{}\) can be expanded as_

\[[(f)]()=_{r^{2}}dr\ (,r)f(r)\]

_where \(:^{2} S^{2}[V,V^{}]\). Then, the exact form of \(\) can be written as_

\[(,r)=_{=0}^{}F_{}(r)^{T}Y_{}()\] (2)

_where \(Y_{}()\) is the vectorization of the \(\)-type spherical harmonics and each \(F_{}(r)\) is a standard \((2)\)-steerable kernel [9; 38] that has input \((2)\)-representation \((,V)\) and output \((2)\)-representation \((^{},V^{})=(,V)_{(2)}^{(3)}[(D^{},V^{})]\)._

The proof of this statement is given in Appendix F. Note that similar to [18; 6] the tensor product structure of the \((2)\) and \((3)\) irreducible representations determine the allowed input and output representations of the matrix valued harmonic coefficients \(F_{}(r)\).

### Including Non-Linearities

In Section 4.2, we considered the most general linear maps that satisfied the generalized equivariance constraint. Adding non-linearities should allow for more expressiveness. Understanding non-linearities between equivariant layers is still an active area of research [39; 40; 41; 42].

One way to include non-linearity is to apply standard \((3)\) non-linearities after the linear induction layer. After applying the linear mapping described in C, we apply an additional spherical non-linearity  to the signal on \(S^{2}\). This is the method we employ for the results presented in 6.2. As shown in G it is also possible to include tensor-product based non-linearity analogous to the results of [18; 6].

Theory

### Universal Property

In section 4 we showed how the restriction representation arises naturally when constructing \((3)\)-equivariant architectures for image data. However, there is no a priori choice of the hidden \((3)\) representation. We show that with this choice, our construction satisfies a universal property and is unique up to isomorphism .

A standard result in group theory establishes the following universal property of induced representations, as stated in :

**Theorem 2**.: _Let \(H G\). Let \((,V)\) be any \(H\)-representation. Let \(_{H}^{G}(,V)\) be the induced representation of \((,V)\) from \(H\) to \(G\). Then, there exists a unique \(H\)-equivariant linear map \(_{}:V_{H}^{G}V\) such that for any \(G\)-representation \((,W)\) and any \(H\)-equivariant linear map \(:V W\), there is a unique \(G\)-equivariant map \(^{}:_{H}^{G}V W\) such that the diagram 3 is commutative._

This theorem can be applied to the construction proposed in 1 to prove a universality property, similar to the results of  for \(G\)-equivariant neural networks.

Factorization Property of \(H G\) Neural NetworksWe use the universal property of induced representations to show that all possible latent \(G\)-equivariant architectures can be written in terms of the induced representation. At each layer of a equivariant neural network, we have a set of functions from a homogeneous space of a group into some vector space . Let \(X_{i}^{H}\) be a set of homogeneous spaces of the group \(H\) and let \(X_{j}^{G}\) be a set of homogeneous spaces of the group \(G\). Let \(V_{i}^{H}\) and \(W_{j}^{G}\) be a set of vector spaces. Then, consider the function spaces

\[_{i}^{H}=\{f\ \ |\ \ f:X_{i}^{H} V_{i}^{H}\}, _{j}^{G}=\{f^{}\ \ |\ \ f^{}:X_{j}^{G} W_{j}^{G}\}\]

The group \(H\) acts on the homogeneous spaces \(X_{i}^{H}\) and the group \(G\) acts on the homogeneous spaces \(X_{j}^{G}\) so that the function spaces \(_{i}^{H}\) and \(_{j}^{G}\) form representations of \(H\) and \(G\), respectively

Suppose we wish to design a downstream \(G\)-equivariant neural network that accepts as signals functions that live in the vector space \(_{0}^{H}\) and transform in the \(_{0}\) representation of \(H\). Thus,

Figure 4: Factorization Identity for Universal Property of Induced Representations

[MISSING_PAGE_EMPTY:7]

frequency is set at \(=6\). The output of the induction layer is a \(64\)-channeled \(S^{2}\) signal with fibers transforming in the trivial representation of \((3)\). After the induction layer, a spherical convolution operation is performed using a filter that is parameterized in the Fourier domain, which generates an 8-channel signal over \((3)\). A spherical non-linearity is applied by mapping the signal to the spatial domain, applying a ReLU, then mapping back to the Fourier domain. One final spherical convolution with a locally supported filter is performed to generate a one-dimensional signal on \((3)\). The output signal is queried using an \((3)\) HEALPix grid (recursion level 3 during training, 5 during evaluation) and then normalized using a softmax following . \(S^{2}\) and \((3)\) convolutions were performed using the e3nn  package. The network was initialized and trained using PyTorch .

In order to create a fair comparison to existing baselines, batch size (64), number of epochs (40), optimizer (SGD) and learning rate schedule (StepLR) were chosen to be the same as that of . Numerical experiments were implemented on NVIDIA P-100 GPUs.

### Comparison to Baselines

We compare our method's performance to competitive pose estimation baselines. We include regression methods, [29; 30; 33], that perform well on datasets where objects have a single valid pose (e.g. are non-symmetric or symmetry is disambiguated in labels). We also baseline against methods that model pose with parametric families of distributions, [35; 47; 34; 36], an implicit model , and the Fourier basis of

\(SO(3)\). To make the comparison fair, all methods use the same-sized ResNet backbone for each experiment, and we report results as stated in the original papers where possible.

**SYMSOL Results** Performance on the SYMSOL dataset is reported in Table 1. Our method achieves the highest average log-likelihood on SYMSOL I. Importantly, we observe a significant improvement over Klee et al.  on all objects, which indicates that our induction layer is more effective than its hand-designed orthographic projection. On SYMSOL II, our method slightly underperforms Murphy et al. , which has much higher expressivity on the output since it is an implicit model. However, we demonstrate that our approach, which preserves the symmetry present in the images, is better with less data, as shown in Table 2.

**PASCAL3D+ Results** Our method achieves state-of-the-art performance on PASCAL3D+ with an average median rotation error of 9.2 degrees, as reported in Table 3. Even though object symmetries are consistently disambiguated in the labels, modeling pose as a distribution is beneficial for noisy images where there is insufficient information to resolve the pose exactly. Because our induction layer produces representations on the Fourier basis of \((3)\), it naturally allows for capturing this uncertainty as a distribution over \((3)\). While both our method and  leverage \((3)\) equivariant

    &  &  \\  & _avg_ & _cone_ & _cyl_ & _tet_ & _cube_ & _ico_ & _avg_ & _sphX_ & _cylO_ & _tetX_ \\  Deng et al.  & -1.48 & 0.16 & -0.95 & 0.27 & -4.44 & -2.45 & 2.57 & 1.12 & 2.99 & 3.61 \\ Prokudin et al.  & -1.87 & -3.34 & -1.28 & -1.86 & -0.50 & -2.39 & 0.48 & -4.19 & 4.16 & 1.48 \\ Gilitschenski et al.  & -0.43 & 3.84 & 0.88 & -2.29 & -2.29 & -2.29 & 3.70 & 3.32 & 4.88 & 2.90 \\ Murphy et al.  & 4.10 & 4.45 & **4.26** & 5.70 & 4.81 & 1.28 & **7.57** & **7.30** & **6.91** & **8.49** \\ Klee et al.  & 3.41 & 3.75 & 3.10 & 4.78 & 3.27 & 2.15 & 4.84 & 3.74 & 5.18 & 5.61 \\
**Ours** & **5.11** & **4.91** & 4.22 & **6.10** & **5.73** & **4.69** & 6.20 & 7.10 & 6.01 & 5.62 \\   

Table 1: Average log likelihood (the higher the better \(\)) on SYMSOL I & II. Per , a single model is trained on all classes in SYMSOL I and a separate model is trained on each class in SYMSOL II.

    &  &  \\  & _avg_ & _cone_ & _cyl_ & _tet_ & _cube_ & _ico_ & _avg_ & _sphX_ & _cylO_ & _tetX_ \\  Murphy et al.  & -7.94 & -1.51 & -2.92 & -6.90 & -10.04 & -18.34 & -0.73 & -2.51 & 2.02 & -1.70 \\ Klee et al.  & 2.98 & 3.51 & 2.88 & **3.62** & 2.94 & **1.94** & **3.61** & **3.12** & **3.87** & 3.84 \\
**Ours** & **3.01** & **3.63** & **3.01** & 3.53 & **3.02** & 1.91 & 3.54 & 2.88 & 3.71 & **4.04** \\   

Table 2: Average log likelihood on SYMSOL I & II with 10% of training data.

layers to improve generalization, we find our method achieves higher performance. We believe our induction layer is more robust to variations in how the images are rendered or captured, which is important for PASCAL3D+, since the data is aggregated from many sources. Moreover, our method does not restrict features to the hemisphere, which could be beneficial for objects, like bikes and chairs, that do not fully self-occlude their backsides.

## 7 Conclusion

In conclusion, we have argued that any network that learns a three-dimensional model of the world from two-dimensional images must satisfy certain consistency properties. We have shown how these consistency properties translate into an \((2)\)-equivariance constraint. Using the induced representation we have derived an explicit form for any neural networks that satisfies said consistency constraint. We have proposed an _induction/restriction layer_, which is a learnable network layer that satisfies the derived consistency equation. We have shown that the induction layer satisfies both a completeness property and universal property and, up to isomorphism, is unique. Furthermore, we have shown that the methods of  can be realized as specific instances of the induction layer.

The framework that we have developed is general and can be applied to other computer vision problems with different symmetries. For example, as was noted in , the cryogenic electronic microscopy orientation estimation problem has a latent \((3)\) symmetry but a manifest \((2)_{2} O(2)\) (as opposed to an \((2)\)) symmetry. With a slight modification H, the results presented in the main text allow for the construction of an induction layer that leverages this observation.

Future WorkIn many structure-from-motion tasks, one has access to multiple images of the same object, taken at either known or unknown vantage points. Our work considers only single view pose estimation. A natural generalization of our work is to include stereo measurements into the induced/restricted representation framework.  use transformer architectures to learn models of three-dimensional objects from two-dimensional images. Furthermore, in this work we have only considered supervised learning, but our framework naturally generalizes to unsupervised settings like . Another natural extension of our work would be to include transformers into the framework presented here, which only applies to convolutional networks.

In deep learning, we often wish to construct a neural network that respects a latent symmetry \(G\) that does not have an explicit action on the input data space. We have show how the induced representation can be used to construct latent \(G\)-equivariant neural networks. Our work provides a systematic way to construct neural architectures that accept any format of inputs and respect the latent symmetries of the problem.