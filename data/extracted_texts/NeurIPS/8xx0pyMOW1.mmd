# Training neural operators to preserve invariant measures of chaotic attractors

Ruoxi Jiang

Department of Computer Science

University of Chicago

Chicago, IL 60637

roxie62@uchicago.edu

&Peter Y. Lu

Department of Physics

University of Chicago

Chicago, IL 60637

lup@uchicago.edu

&Elena Orlova

Department of Computer Science

University of Chicago

Chicago, IL 60637

eorlova@uchicago.edu

&Rebecca Willett

Department of Statistics and Computer Science

University of Chicago

Chicago, IL 60637

willett@uchicago.edu

Equal contribution.

###### Abstract

Chaotic systems make long-horizon forecasts difficult because small perturbations in initial conditions cause trajectories to diverge at an exponential rate. In this setting, neural operators trained to minimize squared error losses, while capable of accurate short-term forecasts, often fail to reproduce statistical or structural properties of the dynamics over longer time horizons and can yield degenerate results. In this paper, we propose an alternative framework designed to preserve invariant measures of chaotic attractors that characterize the time-invariant statistical properties of the dynamics. Specifically, in the multi-environment setting (where each sample trajectory is governed by slightly different dynamics), we consider two novel approaches to training with noisy data. First, we propose a loss based on the optimal transport distance between the observed dynamics and the neural operator outputs. This approach requires expert knowledge of the underlying physics to determine what statistical features should be included in the optimal transport loss. Second, we show that a contrastive learning framework, which does not require any specialized prior knowledge, can preserve statistical properties of the dynamics nearly as well as the optimal transport approach. On a variety of chaotic systems, our method is shown empirically to preserve invariant measures of chaotic attractors.

## 1 Introduction

Training fast and accurate surrogate models to emulate complex dynamical systems is key to many scientific applications of machine learning, including climate modeling , fluid dynamics [2; 3], plasma physics , and molecular dynamics [5; 6]. Fast emulators are powerful tools that can be used for forecasting and data assimilation [1; 4; 7], sampling to quantify uncertainty and compute statistical properties [1; 5; 6], identifying latent dynamical parameters [8; 9], and solving a wide range of inverse problems . Specifically, neural operator architectures [2; 11; 12] have been shown to be promising physics-informed surrogate models for emulating spatiotemporal dynamics, such as dynamics governed by partial differential equations (PDEs).

One key feature of many of the dynamical systems in these applications is chaos, which is characterized by a high sensitivity to initial conditions and results in a theoretical limit on the accuracy of forecasts. Chaotic dynamics ensure that no matter how similarly initialized, any two distinct trajectories will diverge at an exponential rate while remaining confined to a chaotic attractor . At the same time, chaos is fundamental to many critical physical processes, such as turbulence in fluid flows  as well as mixing and ergodicity --properties that underpin the fundamental assumptions of statistical mechanics .

Chaos not only presents a barrier to accurate forecasts but also makes it challenging to train emulators, such as neural operators, using the traditional approach of rolling-out multiple time steps and fitting the root mean squared error (RMSE) of the prediction, as demonstrated in Fig. 1. This is because RMSE training relies on encouraging the emulator to produce more and more accurate forecasts, ideally over a long time horizon, which is severely limited by the chaotic dynamics. This problem is exacerbated by measurement noise, which, in combination with the high sensitivity to initial conditions, further degrades the theoretical limit on forecasting. Unfortunately, this is precisely the setting for many real-world scientific and engineering applications. While accurate long-term forecasts are impossible in this setting, it is still possible to replicate the statistical properties of chaotic dynamics.

Specifically, we can define a natural invariant measure on a chaotic attractor that characterizes the time-invariant statistical properties of the dynamics on the attractor . By training a neural operator to preserve this invariant measure--or equivalently, preserve time-invariant statistics--we can ensure that the neural operator is properly emulating the chaotic dynamics even though it is not able to perform accurate long-term forecasts. In this paper, we introduce two new training paradigms to address this challenge. The first uses an optimal transport-based objective to ensure the invariant measure is preserved. While effective, this approach requires expert knowledge of invariant measures to determine appropriate training losses. The second paradigm uses a contrastive feature loss that naturally preserves invariant measures without this prior expert knowledge. These new losses, which are both intended to preserve the invariant statistics that govern the long-term behavior of the dynamics, are used in combination with the standard RMSE loss evaluated over a short time horizon, which ensures any remaining predictability in the short-term dynamics is correctly captured.

We operate in the multi-environment setting, in which parameters governing the system evolution may be different for each train and test sample. This setting is more challenging than the more typical single-environment setting because it requires emulators to generalize over a broader range domain. Most practical use cases for emulators--where the computational costs of generating training data and training an emulator are outweighed by the computational gains at deployment--are in the multi-environment setting.

### Contributions

This paper makes the following key contributions. Firstly, we identify, frame, and empirically illustrate the problem of training standard neural operators on chaotic dynamics using only RMSE--namely, that the sensitivity to initial conditions in combination with noise means that any predictive model will quickly and exponentially diverge from the true trajectory in terms of RMSE. As such, RMSE is a poor signal for training a neural operator. We instead suggest training neural operators to preserve the invariant measures of chaotic attractors and the corresponding time-invariant statistics, which are robust to the combination of noise and chaos. Secondly, we propose a direct optimal transport-based approach to train neural operators to preserve the distribution of a chosen set of summary statistics. Specifically, we use a Sinkhorn divergence loss based on the Wasserstein distance to match the distribution of the summary statistics between the model predictions and the data. Next, we propose a general-purpose contrastive learning approach to learn a set of invariant statistics directly from the data without expert knowledge. Then, we construct a loss function to train neural operators to preserve these learned invariant statistics. Finally, we empirically test both of these approaches and show that the trained neural operators capture the true invariant statistics--and therefore the underlying invariant measures of the chaotic attractors--much more accurately than baseline neural operators trained using only RMSE, resulting in more stable and physically relevant long-term predictions.

### Related work

**Neural operators.** The goal of a neural operator, proposed in the context of dynamical modeling, is to approximate the semigroup relationship between the input and output function space . It is particularly effective in handling complex systems governed by partial differential equations (PDEs), where the neural operator is designed to operate on an entire function or signal. The architecture designs vary significantly in recent works, including the Fourier neural operator (FNO) which uses Fourier space convolution , the deep operator network (DeepONet) Lu et al. , which consists of two subnetworks modeling the input sensors and output locations, and other modern designs like transformers  and graph neural networks .

**Multi-environment learning.** Recent developments in multi-environment learning often involve adjusting the backbone of the neural operator. For instance, Dyad  employs an encoder to extract time-invariant hidden features from dynamical systems, utilizing a supervisory regression loss relative to the context values. These hidden features are then supplied as additional inputs to the neural operator for decoding in a new environment. In contrast, Context-informed Dynamics Adaptation (CoDA, Kirchmeyer et al. ) decodes the environment context via a hypernetwork, integrating the parameters of the hypernetwork as an auxiliary input to the neural operator. Like our approach, Dyad learns time-invariant features from dynamical systems. However, their methods require a time series of measurements instead of just initial conditions. In addition, both CoDA and Dyad alter the backbone of the neural operator, making it challenging to adapt to new neural operator architectures. In contrast, our method uses the learned time-invariant features to determine a loss function that can be applied to any neural operator architecture without changes to either the backbone or the inputs.

**Long-term predictions.** Lu et al.  try to recover long-term statistics by learning a discrete-time stochastic reduced-order system. From the perspective of training objectives, Li et al.  propose using a Sobolev norm and dissipative regularization to facilitate learning of long-term invariant measures. The Sobolev norm, which depends on higher-order derivatives of both the true process and the output of the neural operator, can capture high-frequency information and is superior to using only RMSE. However, its effectiveness diminishes in noisy and chaotic scenarios where it struggles to capture the correct statistics. The dissipative loss term, regularizes the movement of the neural operator with respect to the input, and attempts to make the emulator stay on the attractor. However, in the case of a multi-environment setup for chaotic systems, our goal is to learn a neural operator capable of modeling long-term distributions with regard to different contexts. Using the dissipative loss as a regularization will cause the neural operator to be insensitive to the context and fail to model different attractors.

Prior  and concurrent work  on training recurrent neural networks (RNNs) have suggested that using teacher forcing methods with a squared error loss on short time sequences can produce high-quality emulators for chaotic time series. Instead, we focus on training neural operators on fully observed high-dimensional deterministic chaos and find that using only an RMSE loss generally fails to perform well on noisy chaotic dynamics. Other concurrent work  has suggested using dynamical invariants such as the Lyapunov spectrum and the fractal dimension to regularize training for reservoir computing emulators. We show that emulators trained using our approaches also correctly capture the Lyapunov spectrum and fractal dimension of the chaotic attractors without explicitly including these invariants, which are difficult to estimate in high dimensions, in our loss.

**Wasserstein distance and optimal transport.** Optimal transport theory and the Wasserstein metric have become powerful theoretical and computational tools. for a variety of applications, including generative computer vision models , geometric machine learning and data analysis , particle physics , as well as identify conservation laws  and fitting parameterized models for low-dimensional dynamical systems . In particular, Yang et al.  uses the Wasserstein distance as an optimization objective to directly fit a parameterized model to data from a low-dimensional attractor. They compute the Wasserstein distance by turning the nonlinear dynamics in the original state space into a linear PDE in the space of distributions and then solving a PDE-constrained optimization problem. This has some nice theoretical properties but generally scales poorly to high-dimensional dynamical systems. Similarly, concurrent work  suggests modeling dynamics by fitting a Fokker-Planck PDE for the probability density of the state using the Wasserstein distance. However, since this also requires estimating the full probability distribution of the state on a mesh grid, it is again challenging to scale this method to high-dimensional systems. In contrast, our proposed optimal transport approach focuses on fitting deep learning-based neural operators to high-dimensional chaoticdynamical systems by first choosing a set of physically relevant summary statistics and then using the computationally efficient Sinkhorn algorithm  to compute our optimal transport loss--an entropy-regularized approximation for the (squared) Wasserstein distance--on the distribution of the summary statistics.

**Feature loss and contrastive learning.** Contrastive learning [32; 33; 34] charges an encoder with generating features that are unaffected by transformations by promoting the similarity of features between different transformations of the same image and by maximizing the feature distance between distinct images. The recent advancements in contrastive learning mainly result from using extensive data augmentation to motivate the encoder to learn semantic representations. In addition to its success in image recognition, contrastive learning has proven to be effective in modeling fine-grained structures  and in scientific applications . Training data generators or solving inverse problems generally requires output to be coherent across multiple structural measurements, a requirement that pixel-wise MSE typically fails to meet. For this reason, Johnson et al.  computes MSE on deep features of the classification models as a structural distance metric to train generative models. Tian et al.  propose the encoder of contrastive learning as an unsupervised alternative for calculating feature loss.

## 2 Problem Formulation

Consider a dynamical system with state space \(\) governed by

\[}{t}=G(,),\] (1)

where \(G\) is the governing function, and \(\) is a set of parameters that specify the dynamics. We will denote trajectories governed by these dynamics (1) as \((t)\), particular points on the trajectory as \(_{t}\), and a sequence of \(K+1\) consecutive time points on the trajectory as \(_{I:I+K}:=\{_{t_{i}}\}_{i=I}^{I+K}\). Our experiments use equally spaced time points with a time step \( t\). We refer to settings where \(\) varies as _multi-environment settings_.

**Our goal** is to learn an emulator in a multi-environment setting that approximates the dynamics (1) with a data-driven neural operator \(_{}:\) that makes discrete predictions

\[}_{t+ t}:=_{}(}_{t},),\] (2)

Figure 1: **The impact of noise on invariant statistics vs. RMSE and Sobolev norm. (a) We show the impact of noise on various error metrics using ground truth simulations of the chaotic Kuramoto–Sivashinsky (KS) system with increasingly noisy initial conditions \(_{G}(_{0}+)\) as well as with added measurement noise \(_{G}(_{0}+)+\). Here, \(_{G}()\) refers to the ground truth solution to the differential equation (1) for the KS system given an initial condition, and \((0,r^{2}^{2}I)\), where \(^{2}\) is the temporal variance of the trajectory \(_{G}(_{0})\) and \(r\) is the noise scale. Relative RMSE and Sobolev norm , which focus on short-term forecasts, deteriorate rapidly with noise \(\), whereas the invariant statistics have a much more gradual response to noise, indicating robustness. (b) The emulator trained with only RMSE degenerates at times into striped patches, while ours is much more statistically consistent with the ground truth. (c) Again, the emulator trained with only RMSE performs the worst in terms of capturing the expected energy spectrum over a long-term prediction.**

where \(\) are the parameters of the neural operator \(_{}\). In the multi-environment setting, we will have data from a variety of environments \(n\{1,2,,N\}\), and thus our training data \(\{_{0:L}^{(n)},^{(n)}\}_{n=1}^{N}\) consists of trajectories \(_{0:L}^{(n)}\) and the corresponding environment parameters \(^{(n)}\).

**Predicted sequence notation.** We will denote a sequence of \(h+1\) autonomously predicted states (using the neural operator \(_{}\)) with an initial condition \(_{t_{I}}^{(n)}\) as

\[}_{I:I+h}^{(n)}:=_{t_{I}}^{(n)},_{ }(_{t_{I}}^{(n)},^{(n)}),_{}_{ }(_{t_{I}}^{(n)},^{(n)}),,_{ }_{}(_{t_{I}}^{(n)},^{(n)})} ^{h}}.\] (3)

We will often use a concatenated sequence (with total length \(K+1\)) of these autonomous prediction sequences (each with length \(h+1\)), which we will denote as

\[}_{I:h:I+K}^{(n)}:=}_{I:I+h}^{(n)}}_{I+h+1:I+2h+1}^{(n)}}_{I+K-h:I+ K}^{(n)},\] (4)

where \(\) is concatenation.

**Chaotic dynamical systems and invariant measures of chaotic attractors.** We focus on chaotic dynamical systems that have one or more chaotic attractors, which exhibit a sensitive dependence on initial conditions characterized by a positive Lyapunov exponent . For each chaotic attractor \(\), we can construct a natural invariant measure (also known as a physical measure)

\[_{}=_{T}^{T}_{_{ }(t)}\,t,\] (5)

where \(_{(t)}\) is the Dirac measure centered on a trajectory \(_{}(t)\) that is in the basin of attraction of \(\). Note that, because \(\) is an attractor, any trajectory \(_{}(t)\) in the basin of attraction of \(\) will give the same invariant measure \(_{}\), i.e. the dynamics are ergodic on \(\). Therefore, any time-invariant statistical property \(S_{}\) of the dynamics on \(\) can be written as

\[S_{}=_{_{}}[s]= s()\,_{}()=_{T}^{T}s( _{}(t))\,t\] (6)

for some function \(s()\) and a trajectory \(_{}(t)\) in the basin of attraction of \(\). Conversely, for any \(s()\), (6) gives a time-invariant property \(S_{}\) of the dynamics.

In this work, we assume each sampled trajectory in the data is from a chaotic attractor and therefore, has time-invariant statistical properties characterized by the natural invariant measure of the attractor.

**Noisy measurements.** Because of the sensitivity to initial conditions, accurate long-term forecasts (in terms of RMSE) are not possible for time scales much larger than the Lyapunov time . This is because any amount of noise or error in the measurement or forecast model will eventually result in exponentially diverging trajectories. The noisier the data, the more quickly this becomes a problem (Fig. 1). However, in the presence of measurement noise, invariant statistics of the noisy trajectory

\[}_{}(t)=_{}(t)+,  p_{}\] (7)

can still provide a useful prediction target. The invariant statistics will be characterized by a broadened measure (the original measure convolved with the noise distribution \(p_{}\))

\[_{}=_{T}^{T}_{ }_{}(t)}\,t=_{}\,*\,p_{ }=_{T}^{T}p_{}(_{}(t ))\,t\] (8)

and are therefore given by

\[_{}=_{_{ }}[s]&= s()\,_{ }()\\ &=_{T}^{T}s(}_{ }(t))\,t=_{T}^{T}s( _{}(t))\,p_{}(_{}(t))\,t,\] (9)

which can be a good approximation for \(S_{}=_{_{}}[s]\) even in noisy conditions and does not suffer from the exponential divergence of RMSE (Fig. 1).

## 3 Proposed Approaches

### Physics-informed optimal transport

We propose an optimal transport-based loss function to match the distributions of a set of summary statistics \(()=[s^{(1)}(),s^{(2)}(),,s^{(k) }()]\) between the data \(_{i}=(_{t_{i}})_{}\) and the model predictions \(}_{j}=(}_{t_{j}})_{}}\). Here, \(_{}\) and \(_{}}\) are the probability measures of the summary statistics for the true chaotic attractor \(\) and the attractor \(}\) learned by the neural operator, respectively. Specifically, \(_{}(^{})=_{()- ^{}}\,_{}()\,\) and \(_{}}(}^{})=_{( })-}^{}}\,_{}}(})\,}\). By choosing the set of summary statistics using expert domain knowledge, this approach allows us to directly guide the neural operator toward preserving important physical properties of the system.

**Optimal transport--Wasserstein distance.** We match the distributions of summary statistics using the Wasserstein distance \(W(_{},_{}})\)--a distance metric between probability measures defined in terms of the solution to an optimal transport problem:

\[W(_{},_{}})^{2}:=_{( _{},_{}})} c(,})\, (,}).\] (10)

We use a quadratic cost function \(c(,})=\|-}\|^{2}\) (i.e., \(W\) is the 2-Wasserstein distance), and the map \((_{},_{}})\) must be a valid transport map between \(_{}\) and \(_{}}\) (i.e., a joint distribution for \(,}\) with marginals that match \(_{}\) and \(_{}}\)) .

In the discrete setting with distributions represented by samples \(=\{_{i}\}_{i=1}^{L}\) and \(}=\{}_{j}\}_{j=1}^{L}\), the Wasserstein distance is given by

\[W(,})^{2}:=_{T}_{i,j}T_{ij} C_{ij},\] (11)

where the cost matrix \(C_{ij}=\|_{i}-}_{j}\|^{2}\). The set of valid discrete transport maps \(\) consists of all matrices \(T\) such that \( i,j\), \(T_{ij} 0\), \(_{j}T_{ij}=1\), and \(_{i}T_{ij}=1\).

**Entropy-regularized optimal transport--Sinkhorn divergence.** Exactly solving the optimal transport problem associated with computing the Wasserstein distance is computationally prohibitive,

Figure 2: **Our proposed approaches for training neural operators.** (a) Neural operators are emulators trained to take an initial state and output future states in a recurrent fashion. To ensure the neural operator respects the statistical properties of chaotic dynamics when trained on noisy data, we propose two additional loss functions for matching relevant long-term statistics. (b) We match the distribution of summary statistics, chosen based on prior knowledge, between the emulator predictions and noisy data using an optimal transport loss. (c) In the absence of prior knowledge, we take advantage of self-supervised contrastive learning to automatically learn relevant time-invariant statistics, which can then be used to train neural operators.

especially in higher dimensions. A common approximation made to speed up computation is to introduce an entropy regularization term, resulting in a convex relaxation of the original optimal transport problem:

\[W^{}(,})^{2}:=_{T}_{i,j} T_{ij}C_{ij}-\,h(T),\] (12)

where \(h(T)=-_{i,j}T_{ij} T_{ij}\) is the entropy of the transport map. This entropy-regularized optimal transport problem can be solved efficiently using the Sinkhorn algorithm .

As \( 0\), the entropy-regularized Wasserstein distance \(W^{} W^{0}=W\) reduces to the exact Wasserstein distance (11). For \(>0\), we can further correct for an entropic bias to obtain the Sinkhorn divergence [39; 40]

\[_{}(,})=^{ }(,})^{2}:=(W^{}( ,})^{2}-(,)^{2} +W^{}(},})^{2}}{2}),\] (13)

which gives us our optimal transport loss. Combined with relative root mean squared error (RMSE)

\[_{}(,}):=_{ _{t},}_{t},}}_{t}-}_{t}\|_{2}}{\|_{t}\|_{2}}\] (14)

for short-term prediction consistency [2; 16; 18], our final loss function is

\[()=n\{1,,N\}\\ I\{0,,L-K\}}{}[\,_{} _{I:I+K}^{(n)},}_{I:h:I+K}^{(n)}+_{ }_{I:I+K}^{(n)},}_{I:h_{}:I+K}^{(n)}],\] (15)

where \(_{I:I+K}^{(n)}:=() _{I,I+K}^{(n)}}\), \(}_{I:h:I+K}^{(n)}:=(}) }}_{I:h:I+K}^{(n)}}\), and \(>0\) is a hyperparameter. Note that \(}_{I:h:I+K}^{(n)}\) and \(}_{I:h_{}:I+K}^{(n)}\) implicitly depend on weights \(\).

### Contrastive feature learning

When there is an absence of prior knowledge pertaining to the underlying dynamical system, or when the statistical attributes are not easily differentiable, we propose an alternative contrastive learning-based approach to learn the relevant invariant statistics directly from the data. We first use contrastive learning to train an encoder to capture invariant statistics of the dynamics in the multi-environment setting. We then leverage the feature map derived from this encoder to construct a feature loss that preserves the learned invariant statistics during neural operator training.

**Contrastive learning.** The objective of self-supervised learning is to train an encoder \(f_{}()\) (with parameters \(\)) to compute relevant invariant statistics of the dynamics from sequences \(\) with fixed length \(K+1\). We do not explicitly train on the environment parameters \(\) but rather use a general-purpose contrastive learning approach that encourages the encoder \(f_{}\) to learn a variety of time-invariant features that are able to distinguish between sequences from different trajectories (and therefore different \(\)).

A contrastive learning framework using the Noise Contrastive Estimation (InfoNCE) loss has been shown to preserve context-aware information by training to match sets of positive pairs while treating all other combinations as negative pairs . The selection of positive pairs is pivotal to the success of contrastive learning. In our approach, the key premise is that two sequences \(_{I:I+K}^{(n)}\), \(_{J:J+K}^{(n)}\) from the same trajectory \(_{0:L}^{(n)}\) both sample the same chaotic attractor, i.e. their statistics should be similar, so we treat any such pair of sequences as positive pairs. Two sequences \(_{I:I+K}^{(n)}\), \(_{H:H+K}^{(n)}\) from different trajectories are treated as negative pairs. This allows us to formulate the InfoNCE loss as:

\[_{}(;):=\\ n\{1,,N\}\\ I,J\{0,,L-K\}}{}[-( f_{}(_{I:I+K}^{(n)}),f_{}(_{J:J+K }^{(n)})/}{m n\\ H\{0,,L-K\}}{}[ f_{ }(_{I:I+K}^{(n)}),f_{}(_{H:H+K}^{(m)})/ ]})].\] (16)The term in the numerator enforces alignment of the positive pairs which ensures we obtain time-invariant statistics, while the term in the numerator encourages uniformity, i.e. maximizing mutual information between the data and the embedding, which ensures we can distinguish between negative pairs from different trajectories . This provides intuition for why our learned encoder \(f_{}\) identifies relevant time-invariant statistics that can distinguish different chaotic attractors.

**Contrastive feature loss.** To construct our feature loss, we use the cosine distance between a series of features of the encoder network \(f_{}\):

\[_{},};f_{}:=_{l} f_{}^{l}(),f_{}^{l}(}),\] (17)

where \(f_{}^{l}\) gives the output the \(l\)-th layer of the neural network. The combined loss that we use for training the neural operator is given by

\[()=*{}_{n\{1,,N\} \\ I\{0,,L-K\}}\,_{} _{I:I+K}^{(n)},}_{I:h:I+K}^{(n)};f_{}+ _{}_{I:}_{_{}}:I+K}^{(n)},\] (18)

where \(>0\) is a hyperparameter.

## 4 Experiments

We evaluate our approach on the 1D chaotic Kuramoto-Sivashinsky (KS) system and a finite-dimensional Lorenz 96 system. In all cases, we ensure that the systems under investigation remain in chaotic regimes. We demonstrate the effectiveness of our approach in preserving key statistics in these unpredictable systems, showcasing our ability to handle the complex nature of chaotic systems. The code is available at: https://github.com/roxie62/neural_operators_for_chaos.

**Experimental setup.** Our data consists of noisy observations \((t)\) with noise \((0,r^{2}^{2}I)\), where \(^{2}\) is the temporal variance of the trajectory and \(r\) is a scaling factor. **Baselines.** We primarily consider the baseline as training with RMSE . We have additional baselines in Appendix B, including Gaussian denoising and a Sobolev norm loss with dissipative regularization . **Backbones.** We use the Fourier neural operator (FNO, ). **Evaluation metrics.** We use a variety of statistics-based evaluation metrics and other measures that characterize the chaotic attractor. See Appendix C.1 for details.

### Lorenz-96

As is a common test model for climate systems, data assimilation, and other geophysical applications [43; 44; 45], the Lorenz-96 system is a key tool for studying chaos theory, turbulence, and nonlinear dynamical systems. It is described by the differential equation

\[}{dt}=(u_{i+1}-u_{i-2})u_{i-1}-u_{i}+F\] (19)

Its dynamics exhibit strong energy-conserving non-linearity, and for a large \(F 10\), it can exhibit strong chaotic turbulence and symbolizes the inherent unpredictability of the Earth's climate.

**Experimental setup.** When using optimal transport loss, we assume that expert knowledge is derived from the underlying equation. For Lorenz-96, we define the relevant statistics as \(():=\{}{dt},(u_{i+1}-u_{i-2})u_{i-1},u_{i}\}\). We generate 2000 training data points with each \(^{(n)}\) randomly sampled from a uniform distribution with the range \([10.0,18.0]\). We vary the noise level \(r\) from \(0.1\) to \(0.3\) and show consistent improvement in the relevant statistics. **Results.** The results are presented in Table 1, and predictions and invariant statistics are shown in Fig. 3 (refer to C.4 for more visualizations).

### Kuramoto-Sivashinsky

Known as a model for spatiotemporal chaos, Kuramoto-Sivashinsky (KS) has been widely used to describe various physical phenomena, including fluid flows in pipes, plasma physics, and dynamics of certain chemical reactions . It captures wave steepening via the nonlinear term \(u\), models dispersion effects through \(u}{ x^{2}}\), and manages discontinuities by introducing hyper-viscosity via \(u}{ x^{4}}\):

\[=-u-u}{ x^{2}}-u}{ x^{4}}.\] (20)

**Experimental setup.** For the KS system, we define \(():=\{,,u}{ x^{2}}\}\). We generate 2000 training data points, with each \(^{(n)}\) being randomly selected from a uniform distribution within the range of \([1.0,2.6]\). **Results.** We report our results over \(200\) test instances in Table 2 and visualize the predictions and invariant statistics in Fig. 3.

## 5 Discussion and Limitations

We have demonstrated two approaches for training neural operators on chaotic dynamics by preserving the invariant measures of the chaotic attractors. The optimal transport approach uses knowledge of the underlying system to construct a physics-informed objective that matches relevant summary statistics, while the contrastive learning approach uses a multi-environment setting to directly learn relevant invariant statistics. In both cases, we see a significant improvement in the ability of the emulator to reproduce the invariant statistics of chaotic attractors from noisy data when compared with traditional RMSE-only training that focuses on short-term forecasting.

We also find, in high-noise settings, that both of our approaches give similar or lower leading LE errors than an emulator trained on RMSE loss alone, despite the fact that our method is only encouraged to match invariant statistics of the final attractor rather than dynamical quantities. We also see evidence that the fractal dimension of the contrastive learning approach is closer to the true attractor. However, we note that the fractal dimension is difficult to reliably estimate for high-dimensional chaotic attractors .

Figure 3: **Sampled emulator dynamics and summary statistic distributions. We evaluate our proposed approaches by comparing them to a baseline model that is trained solely using relative RMSE loss. We conduct this comparison on two dynamical systems: (a) Lorenz-96 and (b) Kuramoto-Sivashinsky (KS). For each system, we show a visual comparison of the predicted dynamics (left) and two-dimensional histograms of relevant statistics (middle and right). We observe that training the neural operator with our proposed optimal transport (OT) or contrastive learning (CL) loss significantly enhances the long-term statistical properties of the emulator, as seen in the raw emulator dynamics and summary statistic distributions. The performance of the CL loss, which uses no prior knowledge, is comparable to that of the OT loss, which requires an explicit choice of summary statistics.**

**Limitations.** Because we rely on invariant measures, our current approach is limited to trajectory data from attractors, i.e. we assume that the dynamics have reached an attractor and are not in a transient phase. We also cannot handle explicit time dependence, including time-dependent forcing or control parameters. For the optimal transport approach, choosing informative summary statistics based on prior knowledge is key to good performance (Appendix B.3). For the contrastive learning approach, the quality of the learned invariant statistics also depends on the diversity of the environments present in the multi-environment setting, although our additional experiments show that we can still obtain good performance even with minimal environment diversity (Appendix B.4).

**Future work.** In the future, we may be able to adapt our approaches to allow for mild time dependence by restricting the time range over which we compute statistics and select positive pairs. This would allow us to study slowly varying dynamics as well as sharp discrete transitions such as tipping points. We can also improve the diversity of the data for contrastive learning by designing new augmentations or using the training trajectory of the neural operator to generate more diverse negative pairs. We will investigate generalizing our approaches to other difficult systems, such as stochastic differential equations or stochastic PDEs, and we would like to further study the trade-offs and synergies between focusing on short-term forecasting (RMSE) and capturing long-term behavior (invariant statistics). In addition, we would like to investigate and compare training methods  across different architectures.

**Broader impacts.** While better emulators for chaotic dynamics may be used in a wide range of applications, we foresee no direct negative societal impacts.

   Training & Histogram Error \(\) & Energy Spec. Error \(\) & Leading LE Error \(\) & FD Error \(\) \\  \(_{}\) & 0.056 (0.051, 0.062) & 0.083 (0.078, 0.090) & **0.013** (0.006, 0.021) & 1.566 (0.797, 2.309) \\
0.1 & \(_{}+_{}\) & **0.029** (0.027, 0.032) & **0.058** (0.052, 0.064) & 0.050 (0.040, 0.059) & 1.424 (0.646, 2.315) \\  & \(_{}+_{}\) & 0.033 (0.029, 0.037) & **0.058** (0.049, 0.065) & 0.065 (0.058, 0.073) & **1.042** (0.522, 1.685) \\  \(_{}\) & 0.130 (0.118, 0.142) & 0.182 (0.172, 0.188) & 0.170 (0.156, 0.191) & 2.481 (1.428, 3.007) \\
0.2 & \(_{}+_{}\) & **0.039** (0.035, 0.042) & **0.086** (0.079, 0.095) & 0.016 (0.006, 0.030) & 2.403 (1.433, 3.768) \\  & \(_{}+_{}\) & 0.073 (0.066, 0.080) & 0.131 (0.117, 0.149) & **0.012** (0.006, 0.018) & **1.681** (0.056, 2.682) \\  \(_{}\) & 0.215 (0.204, 0.234) & 0.291 (0.280, 0.305) & 0.440 (0.425, 0.463) & 3.580 (2.333, 4.866) \\
0.3 & \(_{}+_{}\) & **0.057** (0.052, 0.064) & **0.123** (0.116, 0.135) & 0.084 (0.062, 0.134) & 3.453 (2.457, 4.782) \\  & \(_{}+_{}\) & 0.132 (0.111, 0.151) & 0.241 (0.208, 0.285) & **0.064** (0.045, 0.091) & **1.894** (0.942, 3.108) \\   

Table 1: **Emulator performance on Lorenz-96 data with varying noise scale \(r=0.1,0.2,0.3\). The median (25th, 75th percentile) of the evaluation metrics (Appendix C.1) are computed on 200 Lorenz-96 test instances (each with \(1500\) time steps) for the neural operator trained with (1) only RMSE loss \(_{}\); (2) optimal transport (OT) and RMSE loss \(_{}+_{}\) (using prior knowledge to choose summary statistics); and (3) contrastive learning (CL) and RMSE loss \(_{}+_{}\) (without prior knowledge). We show significant improvements on the long-term statistical metrics including \(L_{1}\) histogram error of the chosen statistics \(():=\{}{dt},(u_{i+1}-u_{i-2})u_{i-1},u_{i}\}\); relative error of Fourier energy spectrum; and absolute error of estimated fractal dimension (FD). For high noise, OT and CL training also improve the leading Lyapunov exponent (LE) of the neural operator.**

   Training & Histogram Error \(\) & Energy Spec. Error \(\) & Leading LE Error \(\) \\  \(_{}\) & 0.390 (0.325, 0.556) & 0.290 (0.225, 0.402) & 0.101 (0.069, 0.122) \\ \(_{}+_{}\) & **0.172** (0.146, 0.197) & 0.211 (0.188, 0.250) & **0.094** (0.041, 0.127) \\ \(_{}+_{}\) & 0.193 (0.148, 0.247) & **0.176** (0.130, 0.245) & 0.108 (0.068, 0.132) \\   

Table 2: **Emulator performance on Kuramoto–Sivashinsky data with noise scale \(r=0.3\). The median (25th, 75th percentile) of the evaluation metrics (Appendix C.1) are computed on 200 Kuramoto–Sivashinsky test instances (each with \(1000\) time steps) for the neural operator trained with (1) only RMSE loss \(_{}\); (2) optimal transport (OT) and RMSE loss \(_{}+_{}\) (using prior knowledge to choose summary statistics); and (3) contrastive learning (CL) and RMSE loss \(_{}+_{}\) (without prior knowledge). We again show significant improvements in the long-term statistical metrics including \(L_{1}\) histogram error of the chosen statistics \(():=\{,, u}{ x^{2}}\}\) and relative error of Fourier energy spectrum. The fractal dimension (FD) is highly unstable in high dimensions  and could not be estimated for this dataset.**