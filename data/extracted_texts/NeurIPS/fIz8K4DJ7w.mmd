# Rethinking the Diffusion Models for Missing Data Imputation: A Gradient Flow Perspective

Zhichao Chen\({}^{1}\) Haoxuan Li\({}^{2}\) Fangyikang Wang\({}^{1}\) Odin Zhang\({}^{3}\) Hu Xu\({}^{1}\)

Xiaoyu Jiang\({}^{1}\) Zhihuan Song\({}^{1,4}\) Hao Wang\({}^{1}\)\({}^{*}\)

\({}^{1}\)Zhejiang University \({}^{2}\)Peking University \({}^{3}\)University of Washington

\({}^{4}\)Guangdong University of Petrochemical Technology

12032042@zju.edu.cn hxli@stu.pku.edu.cn wangfangyikang@zju.edu.cn odinz@uw.edu hxu_zju@zju.edu.cn jiangxiaoyu@zju.edu.cn songzhihuan@zju.edu.cn haohaow@zju.edu.cn

Corresponding author.

###### Abstract

Diffusion models have demonstrated competitive performance in missing data imputation (MDI) task. However, directly applying diffusion models to MDI produces suboptimal performance due to two primary defects. First, the sample diversity promoted by diffusion models hinders the accurate inference of missing values. Second, data masking reduces observable indices for model training, obstructing imputation performance. To address these challenges, we introduce Negative Entropy-regularized Wasserstein gradient flow for Imputation (NewImp), enhancing diffusion models for MDI from a gradient flow perspective. To handle the first defect, we incorporate a negative entropy regularization term into the cost functional to suppress diversity and improve accuracy. To handle the second defect, we demonstrate that the imputation procedure of NewImp, induced by the conditional distribution-related cost functional, can equivalently be replaced by that induced by the joint distribution, thereby naturally eliminating the need for data masking. Extensive experiments validate the effectiveness of our method. Code is available at https://github.com/JustusvLiebig/NewImp.

## 1 Introduction

Missing data is a pervasive problem for data analytics in diverse scenarios, including e-commerce , healthcare , and process industry . For instance, in healthcare, patient monitoring devices may fail or lose connection, leading to missing vital signs data. Similarly, in industrial processes, sensor signals may be incomplete due to inevitable mechanical shock. These incompletenesses hamper data integrity and impede subsequent analysis. Therefore, accurate missing data imputation (MDI) is critical for enabling reliable analysis and decision in real-world applications.

Recently, diffusion models (DMs) have emerged as a powerful tool for MDI . Specifically, these models first estimate the (Stein) score function of the missing data conditioned on the observed data, subsequently reformulating the imputation problem as a generative task grounded in the learned score function. These works are initiated from  and evolve to incorporate crafted model architecture  and learning objectives  for enhancing the accuracy of score estimation . Celebrated for their advantageous capability to model data distributions and generate high-quality synthetic data , diffusion models have been a prevalent approach to MDI.

Despite the successes of diffusion models, we argue that directly applying diffusion models to MDI results in suboptimal performance due to two primary limitations. First, diffusion models performimputation by sampling from a learned score function, which inadvertently promotes diversity in the imputed values. This increased diversity contradicts the accuracy required for precise imputation of missing data . Second, the training process involves masking a portion of the observed data as labels. The selection of masking strategy significantly impacts imputation accuracy and is inherently challenging to optimize . Moreover, the masked data during training often differ in missing mechanisms from those encountered during testing, resulting in a discrepancy between training and inference phases that degrades performance. Consequently, diffusion models introduce unintended diversity and impose data masking, both of which impede effective imputation.

To tackle these challenges, we introduce a novel DM-based MDI approach termed Negative Entropy-regularized Wasserstein Gradient Flow Imputation (NewImp). Specifically, to handle the first issue, we revisit DM-based MDI task within the Wasserstein Gradient Flow (WGF) framework, derive the associated cost functionals, and identify that they implicitly promote diversity in the imputed values. Building on this insight, we incorporate a negative entropy-regularized (NER) cost functional to suppress imputation diversity and enhance accuracy. Furthermore, we derive a closed-form imputation procedure based on the proposed cost functional within the reproducing kernel Hilbert space (RKHS). After that, we further prove that within the WGF framework, the imputation procedure of NewImp, induced from the cost functional associated with conditional distribution, can be induced from another cost functional associated with joint distribution equivalently, within which we merely need to estimate the joint distribution during the model training stage, thereby naturally eliminating the need for data masking.

**Contributions.** The main contributions of this paper are summarized as follows:

* We demonstrate that directly applying diffusion models to MDI causes suboptimal performance, as they prompt unintended diversity and require data masking, both impeding accurate imputation.
* We propose NewImp, a novel DM-based MDI approach under the WGF framework which introduces an NER cost functional to suppress unintended diversity. Based on this, we further prove that the imputation procedure of NewImp can be induced from an equivalent joint-distribution-related functional, and consequently introduce an imputation procedure that sidesteps the data masking.
* We conduct various experiments over public numerical tabular datasets to demonstrate the superiority of the NewImp method over prevalent baseline models.

## 2 Preliminaries

### Problem Formulation

Suppose \(^{}^{}\) represents an ideal numerical tabular dataset without any missing entries, where \(\) and \(\) denote the number of samples and features, respectively. The observed dataset is expressed as: \(^{}=^{}+( _{}-),\) where \(\) denotes the Hadamard product, \(_{}\) is a matrix of ones of size \(\), and \(\{0,1\}^{}\) is a binary mask that indicates the presence (1) or absence (0) of data in each entry. The task of MDI involves imputing the missing entries in \(^{}\). This is achieved by constructing a matrix \(}=^{}+^{}( _{}-),\) where \(^{}\) is the matrix containing the imputed values.

The missing mechanism can be classified into three categories : Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR) (Detailed information about missing mechanisms is given in Appendix E.1). Notably, in the MNAR setting, it is generally difficult to identify the missing data distribution without additional assumptions and constraints . Hence, our discussion primarily focuses on numerical tabular data with MAR and MCAR settings.

### Diffusion Models and Its Application for MDI Task

Diffusion models function by gradually corrupting data towards a tractable noise distribution, such as a standard Gaussian, and subsequently reversing this corruption to generate samples . Specifically, the forward corruption process is modeled as a discretization of a stochastic differential equation (SDE) over time \(\): \(_{}=f(_{})+g_{}W_{}\), where \(f(_{})\) is drift term, \(g_{}\) is volatility term, and \(W\) is standard Wiener process. The solution to this SDE creates a continuous trajectory of random variables \(_{}|_{=0}^{}\). The density function \(q_{}\) of \(_{}\) adheres to the Fokker-Planck-Kolmogorov (FPK)equation: \(}{}=-(q_{}f())+g_{}^{2} q_{}\) (see Theorem 5.4 in reference ). The reverse process is governed by: \(_{}=[f(_{})-g_{}^{2}\,p( _{})]+g_{}W_{}\), where \(\,p(_{})\) represents the score function, which is often parameterized by neural networks.

Diffusion models treat MDI as a conditional generation task. The score function, \(\,p()\), is defined specifically for MDI as \(_{^{}} p(^{}|^{})\), and the MDI task is executed by generating samples based on this conditional score function. The key challenge is to obtain an estimation \(_{^{}}(^{}|^{ })\) that approximates \(_{^{}} p(^{}|^{})\). Given that the true \(^{}\) is unknown, existing DM-based approaches utilize a mask matrix to drop some observable data as labels. However, the specification of the mask mechanism, determining the effectiveness of \((^{}|^{})\), is challenging since it should align with the data missing mechanism in the testing dataset , which may be unknown in practice.

### Wasserstein Gradient Flow

Wasserstein space \(_{2}(^{})\) is defined as the set of distributions with finite second-order moments. Consider a cost functional \(_{}:_{2}(^{})\); the celebrated Wasserstein gradient flow (WGF) is an absolutely continuous trajectory \((q_{})_{>0}\) in this space, which evolves over time \(\) to minimize \(_{}\) efficiently. This dynamic is governed by the continuity equation:

\[}{}=-(u_{}q_{}), u_ {}=-\,_{}}{ q_{}}\] (1)

where \(u_{}:^{}^{}\) is a time-dependent _velocity field_, whose input is sample \(^{}\), \(_{}}{ q_{}}\) denotes the first variation of \(_{}\) with respect to \(q_{}\). On this basis, the evolution of \(\) over time \(\) in \(_{2}(^{})\) can be modeled by the ordinary differential equation (ODE):

\[}{}=u_{}\] (2)

However, simulating this ODE is challenging since \(u_{}\) involves the estimation of \(q_{}\), which involves solving the differential equation \(}{}=-(u_{}q_{})\) that proves to be not analytically solvable .

## 3 Motivations

### Diffusion Models Secretly Foster Diversity

Based on the notations defined in Section 2.1, we can first define the following cost functional for MDI task according to the maximum likelihood estimation principle, where we want to find the value with the highest probability:

\[^{}=*{arg\,max}_{^{}}(^{}|^{}),\] (3)

where \((^{}|^{})\) is the estimation of \(p(^{}|^{})\) via neural network . Notably, we can treat \(^{}\) as samples from a 'proposal distribution' \(r(^{})\), and formulate the following optimization problem based on variational inference [70; 27]:

\[*{arg\,max}_{r(^{})}_{r(^ {})}[(^{}|^{})],\] (4)

where we aim to sample some \(^{}\) samples from proposal distribution \(r(^{})\), realize the maximum log-likelihood estimation over the sampled results, and 'optimize' the proposal distribution \(r(^{})\) that is represented by samples \(^{}\). Notably, in Eq. (4), we use the spirit from previous references represented by , where optimizing the samples \(^{}\) is equivalent to optimizing the distribution \(r(^{})\).

Figure 1: Comparison of the optimal point in green triangle and the results obtained by diffusion models in white scatters. See details in Appendix B.

Referring to Eq. (4), it is observed that the MDI task can be formulated as an optimization problem. This prompts a pertinent question: If the conditional distribution \( p(_{i}^{()}|_{i}^{()})\) is estimated accurately, _what would happen if we directly apply diffusion models to solve the optimization problem corresponding to MDI task?_ To explore this, we consider a hypothetical scenario: Suppose we are optimizing a cost functional related to a three-dimensional Dirichlet distribution on the simplex \(^{2}\):

\[*{arg\,max}_{_{h}^{2}}_{h=1}^{}\{ ^{3}_{k})}{_{k=1}^{3}(_{k})}+ _{k=1}^{3}(_{k}-1)_{k,h}\},=8,|_{k=1 }^{3}=[2.5,2.5,5.0],\]

where \(_{h}|_{1}^{}\) are variables, \(\) is variable number, \(_{k}|_{k=1}^{3}\) is concentration parameter, and \(()\) is gamma function. We compare the analytically derived optimal value with the results from diffusion models in Fig. 1. The diffusion model's results tend to surround but do not exactly reach the optimal value, suggesting that there might be _implicit_, _diversity-encouraging terms_ integrated into the diffusion models' objectives that produce the observed inaccuracies. Identifying and modifying these regularization terms is crucial for enhancing the efficacy of diffusion models for MDI tasks.

### Negative Entropy Regularization Term for Diversity Suppression

In this section, we identify and refine the terms in diffusion models' objectives that prompt unintended diversity and impede accurate imputation. We observe that the inference process in diffusion models adheres to the FPK equation, which is a specialized form of the continuity equation in WGF (see Sections 2.2 and 2.3). This alignment inspires us to reframe diffusion models within the WGF framework, enabling the derivation of their underlying cost functionals. By doing so, we can compare these functionals with the objective functional for MDI in Eq. (4)2.

**Proposition 3.1**.: _Within WGF framework, DM-based MDI approaches can be viewed as finding the imputed values \(^{()}\) that maximize the following objective:_

\[*{arg\,max}_{r(^{()})}_{r( ^{()})}[(^{()}|^{()})]+ (^{()})+,\] (5)

_where 'const' is the abbreviation of constant, and \((^{()})\) is a scalar function determined by the type of SDE underlying the diffusion models._

* _VP-SDE:_ \((^{()})=[r(^{()}) ]+_{r(^{()})}\{[^{()}] [^{()}]\} 0\)
* _VE-SDE:_ \((^{()})=[r(^{()}) ] 0\)
* _sub-VP-SDE:_ \((^{()})=[r(^{()}) ]+_{r(^{()})}\{}[^{( )}][^{()}]\} 0\)_,_

_where \([r(^{()})]:=- r(^{()}) r( ^{()})^{()}\) is the entropy term, \(_{}\) is determined by noise scale \(_{}\): \(_{}:=(1-(-2_{0}^{}_{s}s))>0,0<_{1}< <_{}<1\)._

Proposition 3.1 reveals that diffusion models inherently optimize an objective functional that largely aligns with (4), but they secretly include an additional term \((^{()})>0\). This term makes Eq. (5) an _upper bound_ on Eq. (4), i.e., maximizing the cost functional in Eq. (5) does not guarantee to maximize the MDI objective in Eq. (4). Furthermore, the entropy term included in the models fosters sample diversity, which may compromise the accuracy required in MDI tasks [53; 38]. To address this issue, we propose incorporating a negative entropy term as \((^{()})\):

\[(^{()})=-[r(^{()})],\] (6)

where \(>0\) is a predefined regularization strength, and consequently we can define our NER cost functional for MDI task as follows:

\[_{}_{r(^{()})}[ (^{()}|^{()})]-[r( {X}^{()})].\] (7)

The objective functional in Eq. (7) provides a _lower bound_ of Eq. (4). Therefore, maximizing \(_{}\) guarantees maximizing Eq. (4). Meanwhile, \(_{}\) effectively reduces the unintended diversity term, contributing to an improvement in imputation accuracy.

Implementation of the NewImp

### Optimizing the \(_{}\) within WGF Framework

In this section, we aim to optimize \(_{}\) within the WGF framework [46; 69]. To this end, we plug Eq. (7) into Eq. (1), producing the velocity field below that drives the ODE in Eq. (2):

\[u(^{})=-_{^{}}_{})}{ r(^{})}=[_{^ {}}(^{}|^{})+ _{^{}} r(^{})],\]

However, as stated in Section 2.3, implementing this ODE in computer code is intricate due to the intractability of the density function \(r(^{})\). Fortunately, by restricting the velocity field within the Reproducing Kernel Hilbert Space (RKHS) defined by the kernel function \(u(^{}) K(^{},}^{})\), an alternative ODE minimizing \(_{}\) can be implemented in Proposition 4.1[35; 31] which sidesteps the intractable \(r(^{})\)3.

**Proposition 4.1**.: _Suppose \(u(^{})\) is a velocity field regularized by the RKHS norm under the following conditions: 1). The kernel function satisfies: \(_{\|^{}\|}K(^{},}^{})=0\). 2). The density \(r(^{})\) is bounded. Then, the velocity field that minimizes the cost functional \(_{}=_{r(^{})}[( ^{}|^{})]-[r(^{ })]\) can be given by:_

\[u(^{})=_{r(}^{})}\{ -_{}^{}}K(^{}, {}^{}).\] (8)

_where the expectation term \(_{r(}^{})}\) can be efficiently estimated using Monte Carlo approximation, \(K(,})\) is set as the radial basis function (RBF) kernel._

### Sidestepping Mask Matrix: Conditional Modeling via Joint Modeling

Simulating the ODE in Eq. (2) with Eq. (8) necessitates an accurate estimation of \(p(^{}|^{})\). However, this modeling is challenging due to the diverse choices of masking matrices. More specifically, the accuracy of the estimated conditional distribution \(p(^{}|^{})\) heavily relies on the selection of these matrices, and these matrices should be consistent with the data missing mechanism in the testing dataset, which may be unknown in practice . To bypass this difficulty, we suggest substituting the conditional distribution \(p(^{}|^{})\) with the joint distribution \(p(^{})\), where \(^{}=(^{},^{})\). Building on this substitution, the velocity field is redefined based on the estimated joint distribution \((^{})\) as follows:

\[u(^{})=_{r(}^{})} \{ -_{}^{}}K(^{},}^{})\\ +[_{}^{}}(} ^{})]^{}K(^{},}^{})\},\] (9)

where \(_{}^{}}(}^{})\) can be obtained by masking the \(_{^{}}(^{})\) with the missing data indicator matrix \(\) as follows:

\[_{}^{}}(}^{})=_{}^{}}(}^{})(_{}-)+0,\] (10)

and the expression of kernel function term can be _directly_ given based on the expression of RBF:

\[K(^{},}^{})=(- ^{}-}^{}\|^{2}}{2h^{2}}),\] (11)

where \(h\) is the bandwidth, _the values of \(}^{}\) and \(^{}\) are identical_, and the tilde notation on \(}^{}\) is merely used to _distinguish the variable with respect to which the derivative is taken_. Onthis basis, similar to Eq. (10), the gradient term \(_{}^{}}K(^{},}^{ })\) can be given as follows:

\[_{}^{}}K(^{},}^{ })=_{}^{}}K(^{},}^{})(_{ }-)+0,\] (12)

and since \(K(^{},}^{})\) is a smooth function, \(_{}^{}}K(^{},}^{})\) can be _easily_ computed by automatic-differentiation-based deep learning backends like by PyTorch .

Proposition 4.2 demonstrates that the cost functional \(_{}\), associated with Eq. (10), and \(_{}\) exhibit a constant gap, indicating that optimizing \(_{}\) is equivalent to optimizing \(_{}\).

**Proposition 4.2**.: _Assume that the proposal distribution \(r(^{})\) is factorized by \(r(^{}):=r(^{})p(^{})\). The cost functional associated with the joint distribution is defined as follows:_

\[_{}:=_{r(^{})}[ (^{})]-[r(^{ })],\] (13)

_which leads to the velocity field delineated in Eq. (9) and establishes \(_{}\) as a lower bound for \(_{}\), with the difference being a constant (i.e., \(_{}=_{}-, 0\))._

The detailed justification for the factorization \(r(^{}):=r(^{})p(^{})\) is provided in Appendix C. Based on this proposition, the following corollary can be obtained:

**Corollary 4.3**.: _The following equation holds: \(u(^{})=u(^{})\)._

So far, we know that \(u(^{})\) can reduce \(_{}\) as effectively as possible, which indicates that the velocity field defined in Eq. (9) can fully substitute for Eq. (8) in optimizing \(_{}\) without loss of accuracy. Finally, the imputed value can be obtained by simulating the following ODE:

\[^{}}{}=u(^{}).\] (14)

### Estimating the Joint Distribution

The remaining problem is to determine the estimation of score function \(_{^{}}(^{})\). To achieve this, we employ Denoising Score Matching (DSM) [21; 52] to train the score function \(_{^{}}(^{})\) parameterized by a neural network. Specifically, the learning objective is designed to minimize the discrepancy between the actual score and the model's predicted score after introducing Gaussian noise to the clean \(^{}\) as \(}^{}\):

\[_{}_{q_{}(}^{}|^{})}[\|_{}^{}}(}^{})-_{}^{}} q_{}(}^{}|^{})\|^{2}].\] (15)

Notably, \(\) is variance scale, \(}^{}\) is obtained by \(}^{}=^{}+, (,^{2})\), and \(_{}^{}} q_{}(}^{}|^{})=-}^{}-^{}}{^{2}}\). Once \(_{^{}}(^{})\) is trained, we can obtain the imputation value by simulating the ODE based on Eqs. (9) and (14).

### Overall Workflow of NewImp

The computation workflow of NewImp is encapsulated in Algorithm 1. Specifically, we perform a mean imputation to the incomplete matrix \(^{}\), producing a pre-imputed dataset denoted as \(^{}\) (step 1). After that, we iteratively conduct DSM training and ODE simulation. In DSM training (steps 3-5), we form \(^{}\) and conduct DSM on it to acquire a score estimator. In ODE simulation (steps 6-8), we set the starting point and perform ODE simulation, where \(u\) is calculated with the score estimator acquired in step 5. The endpoint is treated as the imputation results at the current iteration. After completing \(\) iterations of this process, the imputed dataset \(}\) is calculated, where we preserve the observed indices in \(^{}\) (step 10).

## 5 Experiments

### Experimental Setup

**Datasets:** We conduct the case study based on eight real-world datasets from the UCI repository. To simulate missing data, we mask the dataset using a mask matrix, which is realized with a Bernoulli random variable of fixed mean. More detailed information is provided in Appendix E.1.

**Baselines:** We compare NewImp with DM-based MDI models: CSDI for Tabular Data (CSDI_T) , MissDiff . In addition, we also select other well-known MDI models like Sinkhorn (Sink) , Transform Distribution Matching (TDM) , Generative Adversarial Imputation Nets (GAIN) , Missing Data Importance-Weighted Autoencoder (MIWAE) , Missing data Imputation Refinement And Causal LEarning (MIRACLE) , and ReMasker . Details concerning experimental settings are given in Appendix E.2.

**Implementation Details:** In this study, we employ a two-layer multi-layer perceptron to model \(_{^{}}(^{})\). Each layer is configured with 256 hidden units (\(_{}\)), and the activation function is set as the 'Swish' function . For DSM training (step 5 of Algorithm 1), the variance scale \(\) is set as 0.1, the network is trained by the Adam optimizer  with the learning rate of \(1.0 10^{3}\), and the batch size is dynamically set to dataset size N. Meanwhile, for the ODE simulation part (step 7 of Algorithm 1), we specify a simulation time (T) of 500, a regularization strength of (\(\)) 10.0, a step size of (\(\)) 0.1, and a bandwidth (\(h\)) of 0.5. The loop time \(\) for NewImp is set as 2. Since only missing indices are updated, the evaluation focuses exclusively on imputation errors for these indices. To this end, we modify the mean absolute error (MAE) and squared Wasserstein-2 distance (WASS) according to reference  as follows:

\[^{}_{j=1}^{}[|^{ }_{i,j}-}_{i,j}|(_{ }-)_{i,j}]}{_{i=1}^{}_{j=1}^{}(_{}-)_{i,j}},\]

\[_{2}^{2}[_{1}}_{i=1}^{_{1}}_{[}_{_{1}}]_{i,:}},_{1}}_{i=1}^{ _{1}}_{[^{}_{_{1}}]_{i,:}}],\]

where \(_{2}^{2}\) denotes the squared Wasserstein-2 distance, \(_{1}\{i: j,_{i,j}=0\}\) represents the subset of \(_{i,j}\) with at least one missing value, \(_{1}\) is the number of data points with at least one missing value, and \(_{}\) is the Dirac distribution (measure) concentrated on \(\).

### Baseline Comparison Results

Table 1 presents the imputation quality of NewImp and other imputation approaches under the MAR and MCAR scenarios. The primary observations are detailed as follows:

* Models with neural architectures such as MIRACLE, MIWAE, and TDM demonstrate superior performance compared to models lacking such architectures. This observation suggests that integrating neural networks into MDI tasks can significantly enhance model performance.
* DM-based imputation approaches generally perform worse than other MDI methods. This outcome indicates that despite the incorporation of complex nonlinear neural architectures to boost performance, employing diversity-oriented generative approaches may not align well with the precision requirements of MDI tasks.

* Our proposed NewImp method consistently ranks as the best or second-best across most comparisons under most of the scenarios and datasets. Notably, NewImp significantly outperforms other DM-based MDI approaches, underscoring the effectiveness of our analytical enhancements and innovations in Sections 3.1, 3.2 and 4.2.

### Ablation Study Results

In this section, we conduct the ablation study to assess the contributions of two key components in NewImp: the NER term and the joint modeling strategy (referred to as 'Joint'). The results of this study are detailed in Table 2. Analysis of the data between the second and last rows of Table 2 reveals that, for most cases, in the absence of the NER, the proposal distribution \(r(^{})\) may become pathological, leading to diminished model performance. Additionally, when comparing results from the first, third, and last rows, it becomes evident that modeling the joint distribution directly, rather than inferring it from the conditional distribution, significantly enhances model performance. This finding underscores the effectiveness of the strategies we have implemented, as discussed in Section 4.2. Overall, the ablation study underscores the critical roles of both the NER term and the joint distribution learning strategy in promoting the performance of NewImp.

### Sensitivity Analysis Results

In this section, we analyze the impact of key hyperparameters within the NewImp approach, including the bandwidth \(h\) of the RBF kernel function, the hidden units \(_{}\) in the score network, the weight \(\) of the NER term, and the discretization step size \(\) for simulating the ODE defined in Eq. (9). The profound influence of these hyperparameters on learning objectives and overall performance is substantiated by the experimental results presented in Fig. 2. Initially, we explore the effects of varying

    &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\   bandwidth \(h\). We observe that an increase in bandwidth correlates with a decrease in imputation accuracy. For instance, as the bandwidth increases from 0.5 to 2.0, the MAE and WASS escalate from 0.35 and 0.25 to 0.82 and 0.74, respectively. This trend suggests that excessive bandwidth can lead to an over-smoothed velocity field, expanding the exploration space of the distribution \(r(^{})\) excessively and failing to adequately 'concentrate' this distribution, ultimately diminishing performance. Subsequently, we examine changes in the score network's hidden units. Increasing the hidden units from 256 to 512 appears to decrease imputation accuracy, likely due to overfitting issues associated with larger neural networks. Next, we adjust the strength of the NER term and find that increasing its intensity generally improves imputation accuracy. This supports the necessity of the NER term, further validating its effectiveness. Lastly, we investigate the discretization step size for the ODE. We find that accuracy initially increases with smaller step sizes but then decreases. This pattern is consistent with ODE simulation behavior, where smaller step sizes require longer to converge, potentially resulting in lower accuracy within a predefined time. Conversely, larger step sizes increase discretization errors, adversely affecting accuracy as well.

## 6 Related Works

### Diffusion Models for Missing Data Imputation

The impressive ability of diffusion models to synthesize data [54; 76; 7] has inspired extensive research into their application for MDI tasks [59; 66]. Among the pioneering efforts, the Conditional Score-based Diffusion models for Imputation (CSDI)  was the first to adapt diffusion models for time-series MDI, substituting the score function with a conditional distribution and pioneering a novel model training strategy by masking parts of the observational data. Building on this, to address categorical data in tabular datasets, CSDL_T  introduced an embedding layer within the feature extractor. To enhance inference efficiency, the conditional Schrodinger bridge method for probabilistic time series imputation proposed modeling the diffusion process as a Schrodinger bridge . Meanwhile, MissDiff  utilizes the missing data information as the mask matrix to improve the model training procedure.

Despite these advancements from the perspective of feature extraction module [1; 64], loss function , and model inference approach , as pointed out by reference , the reconciliation of the inherent diversity-seeking nature of diffusion models' generative processes and the accuracy-centric demands of MDI task remains underexplored. To our knowledge, this paper is the first to elucidate the relationship between diffusion models' generative processes and MDI tasks from an optimization perspective (Sections 3.1 and 3.2), which has not been discovered by previous reference . Based on these insights, we further propose our NewImp approach by designing the NER term to prioritize the MDI accuracy (Section 3.2).

Figure 2: Parameter sensitivity of NewImp on bandwidth for kernel function (\(h\)), hidden unit of score network \(_{}\), NER weight \(\), and discretization step \(\) for Eq. (9) on CC dataset. Mean values and one standard deviation from mean are represented by scatters and shaded area, respectively.

### Modeling Conditional Distribution by Joint Distribution

Modeling conditional distribution as joint distribution remains an opening question and has a broad potential for application [68; 8; 25]. Conditional sliced WGF  first empirically validated that the velocity field of joint distribution and conditional distribution are identical when choosing sliced Wasserstein distance as cost functional. After that, reference  extended this relationship and derived the relationship between conditional and joint distribution in various discrepancy metrics like \(f\)-divergence, Wasserstein distance, and integral probability metrics. On this basis, reference  further theoretically proved the equivalence of velocity fields for conditional and joint distribution.

However, the objective of NewImp does not belong to any kind of discrepancy metric . The most similar discrepancy metric is negative KL divergence. Notably, negative KL divergence contains diversity-encouraging 'positive' entropy as the regularization term, and the regularization term in our study is diversity-discouraging 'negative' entropy, and thus more than directly applying these results to our research is needed. On this basis, our theoretical contribution proves that this joint distribution modeling approach can still be applied when the functional is regularized by the negative entropy.

### Wasserstein Gradient Flow for Generative Modeling

WGF [2; 46] has been extensively employed in various domains of machine learning, including generative modeling [17; 12; 74; 63], posterior distribution sampling [55; 35; 32; 34], and domain adaptation [75; 36; 37; 71]. In generative modeling [4; 11; 18], the problem is framed as an optimization task, with the objective functional comprising an \(f\)-divergence term that measures the discrepancy between the proposal distribution and the data distribution, alongside an entropy term that promotes diversity in generative results.

WGF is then utilized to address the optimization of this cost functional, with models being constructed during the solution process. However, as indicated by our illustrative example (Section 3.1), and further supported by our theoretical analysis (Section 3.2), pursuing diversity in accuracy-oriented tasks such as MDI may not be appropriate. Our analysis reveals that the inclusion of an entropy term in the cost functional makes the direct application of diffusion models to MDI tasks unsuitable. Based on these insights, one of our major contributions is demonstrating that WGF can be effectively used to analyze and improve the appropriateness of applying diffusion models to non-generative tasks.

## 7 Conclusions

This work demonstrated that directly applying diffusion models to MDI resulted in suboptimal performance due to unintended diversity and the requirement for data masking, both of which impeded accurate imputation. To counteract this, we proposed NewImp, a novel diffusion model-based MDI approach within the Wasserstein gradient flow framework, designed to suppress unintended diversity. We developed an easy-to-implement form for realizing NewImp in computer code by constraining the velocity field within the reproducing kernel Hilbert space. Furthermore, we proved that the imputation procedure of NewImp could be derived from an equivalent joint-distribution-related functional, thereby obviating the need for data masking. Finally, extensive experiments demonstrated that NewImp effectively mitigates these issues and outperforms prevalent baseline models.