# Phase diagram of early training dynamics in deep networks: effect of the learning rate, depth, and width

Phase diagram of early training dynamics in deep networks: effect of the learning rate, depth, and width

 Dayal Singh Kalra

dayal@umd.edu

Condensed Matter Theory Center, University of Maryland, College ParkInstitute for Physical Science and Technology, University of Maryland, College ParkDepartment of Physics, University of Maryland, College ParkJoint Quantum Institute, University of Maryland, College Park

Maissam Barkeshli

Conditional Matter Theory Center, University of Maryland, College ParkInstitute for Physical Science and Technology, University of Maryland, College ParkDepartment of Physics, University of Maryland, College ParkJoint Quantum Institute, University of Maryland, College Park

###### Abstract

We systematically analyze optimization dynamics in deep neural networks (DNNs) trained with stochastic gradient descent (SGD) and study the effect of learning rate \(\), depth \(d\), and width \(w\) of the neural network. By analyzing the maximum eigenvalue \(_{t}^{H}\) of the Hessian of the loss, which is a measure of sharpness of the loss landscape, we find that the dynamics can show four distinct regimes: (i) an early time transient regime, (ii) an intermediate saturation regime, (iii) a progressive sharpening regime, and (iv) a late time "edge of stability" regime. The early and intermediate regimes (i) and (ii) exhibit a rich phase diagram depending on \(}{{_{0}^{H}}}\), \(d\), and \(w\). We identify several critical values of \(c\), which separate qualitatively distinct phenomena in the early time dynamics of training loss and sharpness. Notably, we discover the opening up of a "sharpness reduction" phase, where sharpness decreases at early times, as \(d\) and \(}{{w}}\) are increased.

## 1 Introduction

The optimization dynamics of deep neural networks (DNNs) is a rich problem that is of great interest. Basic questions about how to choose learning rates and their effect on generalization error and training speed remain intensely studied research problems. Classical intuition from convex optimization has lead to the often made suggestion that in stochastic gradient descent (SGD), the learning rate \(\) should satisfy \(<}{{^{H}}}\), where \(^{H}\) is the maximum eigenvalue of the Hessian \(H\) of the loss, in order to ensure that the network reaches a minimum. However several recent studies have suggested that it is both possible and potentially preferable to have the learning rate _early in training_ reach \(>}{{^{H}}}\). The idea is that such a choice will induce a temporary training instability, causing the network to 'cataput' out of a local basin into a flatter one with lower \(^{H}\) where training stabilizes. Indeed, during the early training phase, the local curvature of the loss landscape changes rapidly , and the learning rate plays a crucial role in determining the convergence basin . Flatter basins are believed to be preferable because they potentially lead to lower generalization error  and allow larger learning rates leading to potentially faster training.

From a different perspective, the major theme of deep learning is that it is beneficial to increase the model size as much as possible. This has come into sharp focus with the discovery of scaling laws that show power law improvement in generalization error with model and dataset size . This raises the fundamental question of how one can scale DNNs to arbitrarily large sizes while maintaining the ability to learn; in particular, how should initialization and optimization hyperparameters be chosen to maintain a similar quality of learning as the model size is taken to infinity ?Motivated by these ideas, we perform a systematic analysis of the training dynamics of SGD for DNNs as learning rate, depth, and width are tuned, across a variety of architectures and datasets. We monitor both the loss and sharpness (\(^{H}\)) trajectories during early training, observing a number of qualitatively distinct phenomena summarized below.

### Our contributions

We study SGD on fully connected networks (FCNs) with the same number of hidden units (width) in each layer, convolutional neural networks (CNNs), and ResNet architectures of varying width \(w\) and depth \(d\) with ReLU activation. For CNNs, the width corresponds to the number of channels. We focus on networks parameterized in Neural Tangent Parameterization (NTP) , and Standard Parameterization (SP)  initialized at criticality [55; 58], while other parameterizations and initializations may show different behavior. Further experimental details are provided in Appendix A. We study both mean-squared error (MSE) and cross-entropy loss functions and the datasets CIFAR-10, MNIST, Fashion-MNIST. Our findings apply to networks with \(}{{w}} C\), where \(C\) depends on architecture class (e.g. for FCNs, \(C}{{16}}\)) and loss function, but is independent of \(d\), \(w\), and \(\). Above this ratio, the dynamics becomes noise-dominated, and separating the underlying deterministic dynamics from random fluctuations becomes challenging, as shown in Appendix E. We use sharpness to refer to \(^{H}_{t}\), the maximum eigenvalue of \(H\) at time-step \(t\), and flatness refers to \(}{{^{H}_{t}}}\).

By monitoring the sharpness, we find four clearly separated, qualitatively distinct regimes throughout the training trajectory. Fig. 1 shows an example from a CNN architecture. The four observed regimes are: (i) an early time transient regime where loss and sharpness may drastically change and eventually settle down, (ii) an intermediate saturation regime where the sharpness has lowered and remains relatively constant, (iii) a progressive sharpening regime where sharpness steadily rises, and finally, (iv) a late time regime where the sharpness saturates around \(}{{}}\) for MSE loss; whereas for cross-entropy loss, sharpness drops after reaching this maximum value while remaining less than \(}{{}}\). Note the log scale in Figure 1 highlights the early regimes (i) and (ii); in absolute terms these are much shorter in time than regimes (iii) and (iv).

In this work, we focus on the early transient and intermediate saturation regimes. As learning rate, \(d\) and \(w\) are tuned, a clear picture emerges, leading to a rich phase diagram, as demonstrated in Section 2. Given the learning rate scaled as \(=}{{^{H}_{0}}}\), we characterize four distinct behaviors in the training dynamics in the early transient regime (i):

**Sharpness reduction phase (\(c<c_{loss}\)) :** _Both the loss and the sharpness monotonically decrease during early training. There is a particularly significant drop in sharpness in the regime \(c_{crit}<c<c_{loss}\), which motivates us to refer to learning rates lower than \(c_{crit}\) as sub-critical and larger than \(c_{crit}\) as super-critical. We discuss \(c_{crit}\) in detail below. The regime \(c_{crit}<c<c_{loss}\) opens up significantly with increasing \(d\) and \(}{{w}}\), which is a new result of this work.

**Loss catapult phase (\(c_{loss}<c<c_{sharp}\)) :** The first few gradient steps take training to a flatter region but with a higher loss. Training eventually settles down in the flatter region as the loss starts to decrease again. The sharpness _monotonically decreases from initialization_ in this early time transient regime.

Figure 1: Training trajectories of the (a) training loss, (b) sharpness, and (c) training accuracy of CNNs (\(d=5\) and \(w=512\)) trained on CIFAR-10 with MSE loss using vanilla SGD with learning rates \(=}{{^{H}_{0}}}\) and batch size \(B=512\). Vertical dashed lines approximately separate the different training regimes. Horizontal dashed lines in (b) denote the \(}{{}}\) threshold for each learning rate.

**Loss and sharpness catapult phase (\(c_{sharp}<c<c_{max}\)):** In this regime _both the loss and sharpness_ initially start to increase, effectively catapulting to a different point where loss and sharpness can start to decrease again. Training eventually exhibits a significant reduction in sharpness by the end of the early training. The report of a _loss and sharpness catapult_ is also new to this work.

**Divergent phase (\(c>c_{max}\)):** The learning rate is too large for training and the loss diverges.

The critical values \(c_{loss}\), \(c_{sharp}\), \(c_{max}\) are random variables that depend on random initialization, SGD batch selection, and architecture. The averages of \(c_{loss}\), \(c_{sharp}\), \(c_{max}\) shown in the phase diagrams show strong systematic dependence on depth and width. In order to better understand the cause of the sharpness reduction during early training we study the effect of network output at initialization by (1) centering the network, (2) setting last layer weights to zero, or (3) tuning the overall scale of the output layer. We also analyze the linear connectivity of the loss landscape in the early transient regime and show that for a range of learning rates \(c_{loss}<c<c_{barrier}\), no barriers exist from the initial state to the final point of the initial transient phase, even though training passes through regions with higher loss than initialization.

Next, we provide a quantitative analysis of the intermediate saturation regime. We find that sharpness during this time typically displays 3 distinct regimes as the learning rate is tuned, depicted in Fig. 5. By identifying an appropriate order parameter, we can extract a sharp peak corresponding to \(c_{crit}\). For MSE loss \(c_{crit} 2\), whereas for crossentropy loss, \(4 c_{crit} 2\). For \(c c_{crit}\), the network is effectively in a lazy training regime, with increasing fluctuations as \(d\) and/or \(}{{w}}\) are increased.

Finally, we show that a single hidden layer linear network - the \(uv\) model - displays the same phenomena discussed above and we analyze the phase diagram in this minimal model.

### Related works

A significant amount of research has identified various training regimes using diverse criteria, e.g., [13; 1; 15; 37; 17; 45; 35; 8; 33]. Here we focus on studies that characterize training regimes with sharpness and learning rates. Several studies have analyzed sharpness at different training times [37; 16; 35; 8; 33]. Ref.  studied sharpness at late training times and showed how _large-batch_ gradient descent shows progressive sharpening followed by the edge of stability, which has motivated various theoretical studies [9; 2; 3]. Ref.  studied the entire training trajectory of sharpness in models trained with SGD and cross-entropy loss and found that sharpness increases during the early stages of training, reaches a peak, and then decreases. In contrast, we find a sharpness-reduction phase, \(c<c_{loss}\) which becomes more prominent with increasing \(d\) and \(}{{w}}\), where sharpness only decreases during early training; this also occurs in the catapult phase \(c_{loss}<c<c_{sharp}\), during which the loss initially increases before decreasing. This discrepancy is likely due to different initialization and learning rate scaling in their work .

Ref.  examined the effect of hyperparameters on sharpness at late training times. Ref.  studied the optimization dynamics of SGD with momentum using sharpness. Ref.  classify training into 2 different regimes using training loss, providing a significantly coarser description of training dynamics than provided here. Ref.  studied the scaling of the maximum learning rate with \(d\) and \(w\) during early training in FCNs and its relationship with sharpness at initialization.

Refs. [52; 71] present phase diagrams of shallow ReLU networks at infinite width under gradient flow. Previous studies such as [41; 69] show that \(}{{_{0}^{NTK}}}\) is the maximum learning rate for convergence as \(w\). This limit results in the kernel regime as training time is restricted to \(O(1)\) in the limit of infinite width, resulting in a lazy training regime for learning rates less than \(}{{_{0}^{NTK}}}\) and divergent training for larger learning rates. In contrast, we analyze optimization dynamics at training timescales \(t_{}\) that grow with width \(w\). Specifically, the end of the early time transient period occurs at \(t_{}(w)\).

Ref.  analyzed the training dynamics at large widths and training times, using the top eigenvalue of the neural tangent kernel (NTK) as a proxy for sharpness. They demonstrated the existence of a new early training phase, which they dubbed the "catapult" phase, \(}{{_{0}^{NTK}}}<<_{max}\), in wide networks trained with MSE loss using SGD, in which training converges after an initial increase in training loss. The existence of this new training regime was further extended to quadratic models with large widths by [72; 53]. Our work extends the above analysis by studying the combined effect of learning rate, depth, and width for both MSE and cross-entropy loss, demonstrating the openingof a sharpness-reduction phase, the refinement of the catapult phase into two phases depending on whether the sharpness also catapults, analyzing the phase boundaries as \(d\) and \(}{{w}}\) is increased, analyzing linear mode connectivity in the catapult phase, examining different qualitative behaviors in the intermediate saturation regime (ii) mentioned above.

## 2 Phase diagram of early transient regime

For wide enough networks trained with MSE loss using SGD, training converges into a flatter region after an initial increase in the training loss for learning rates \(c>2\). Fig. 2(a, b) shows the first \(10\) steps of the loss and sharpness trajectories of a shallow (\(d=5\) and \(w=512\)) CNN trained on the CIFAR-10 dataset with MSE loss using SGD. For learning rates, \(c 2.82\), the loss catapults and training eventually converges into a flatter region, as measured by sharpness. Additionally, we observe that sharpness may also spike initially, similar to the training loss (see Fig. 2 (b)). However, this initial spike in sharpness occurs at relatively higher learning rates (\(c 5.65\)), which we will examine along with the loss catapult. We refer to this spike in sharpness as'sharpness catapult.'

An important consideration is the degree to which this phenomenon changes with network depth and width. Interestingly, we found that the training loss in deep networks on average catapults at much larger learning rates than \(c=2\). Fig. 2(d, e) shows that for a deep (\(d=10,w=128\)) CNN, the loss and sharpness may catapult only near the maximum trainable learning rate. In this section, we characterize the properties of the early training dynamics of models with MSE loss. In Appendix F, we show that a similar picture emerges for cross-entropy loss, despite the dynamics being noisier.

### Loss and sharpness catapult during early training

In this subsection, we characterize the effect of finite depth and width on the onset of the loss and sharpness catapult and training divergence. We begin by defining critical constants that correspond to the above phenomena.

**Definition 1**.: _(\(c_{loss},c_{sharp},c_{max}\)) For learning rate \(=}{{_{0}^{H}}}\), let the training loss and sharpness at step \(t\) be denoted by \(_{t}(c)\) and \(_{t}^{H}(c)\). We define \(c_{loss}(c_{sharp})\) as minimum learning rates constants

Figure 2: Early training dynamics of (a, b, c) a shallow (\(d=5\), \(w=512\)) and (d, e, f) a deep CNN (\(d=10,w=128\)) trained on CIFAR-10 with MSE loss for \(t=10\) steps using SGD for various learning rates \(=}{{_{0}^{H}}}\) and batch size \(B=512\). (a, d) training loss, (b, e) sharpness, and (c, f) interpolated loss between the initial and final parameters after \(10\) steps for the respective models. For the shallow CNN, \(c_{loss}=2.82,c_{sharp}=5.65,c_{max}=17.14\) and for the deep CNN, \(c_{loss}=36.75,c_{sharp}=39.39,c_{max}=48.50\).

such that the loss (sharpness) increases during the initial transient period:_

\[c_{loss}=_{c}\{c_{t[1,T_{1}]}_{t}(c)>_{0}(c )\}, c_{sharp}=_{c}\{c_{t[1,T_{1}]}_{t}^{H}(c)> _{0}^{H}(c)\},\]

_and \(c_{max}\) as the maximum learning rate constant such that the loss does not diverge during the initial transient period: \(c_{max}=_{c}\{c_{t}(c)<K, t[1,T_{1}]\},\) where \(K\) is a fixed large constant.5._

Note that the definition of \(c_{max}\) allows for more flexibility than previous studies  in order to investigate a wider range of phenomena occurring near the maximum learning rate. Here, \(c_{loss}\), \(c_{sharp}\), and \(c_{max}\) are random variables that depend on the random initialization and the SGD batch sequence, and we denote the average over this randomness using \(\).

Fig. 3(a-c) illustrates the phase diagram of early training for three different architectures trained on various datasets with MSE loss using SGD. These phase diagrams show how the averaged values \( c_{loss}, c_{sharp}\), and \( c_{max}\) are affected by width. The results show that the averaged values of all the critical constants increase significantly with \(\) (note the log scale). At large widths, the loss starts to catapult at \(c 2\). As \(\) increases, \( c_{loss}\) increases and eventually converges to \( c_{max}\) at large \(\). By comparison, sharpness starts to catapult at relatively large learning rates at small \(\), with \( c_{sharp}\) continuing to increase with \(\) while remaining between \( c_{loss}\) and \( c_{max}\). Similar results are observed for different depths as demonstrated in Appendix C. Phase diagrams obtained by varying \(d\) are qualitatively similar to those obtained by varying \(1/w\), as shown in Figure 3(d-f). Comparatively, we observe that \( c_{max}\) may increase or decrease with \(\) in different settings while consistently increasing with \(d\), as shown in Appendices F and H.

Figure 3: Phase diagrams of early training of neural networks trained with MSE loss using SGD. Panels (a-c) show phase diagrams with width: (a) FCNs (\(d=8\)) trained on the MNIST dataset, (b) CNNs (\(d=7\)) trained on the Fashion-MNIST dataset, (c) ResNet (\(d=18\)) trained on the CIFAR-10 (without batch normalization). Panels (d-f) show phase diagrams with depth: FCNs trained on the Fashion-MNIST dataset for different widths. Each data point in the figure represents an average of ten distinct initializations, and the solid lines represent a smooth curve fitted to the raw data points. The vertical dotted line shows \(c=2\) for comparison, and various colors are filled in between the various curves for better visualization. For experimental details and additional results, see Appendices A and C, respectively. The phase diagram of early training of FCNs with depth for three different widths trained on Fashion-MNIST with MSE loss using SGD.

While we plotted the averaged quantities \( c_{loss}\), \( c_{sharp}\), \( c_{max}\), we have observed that their variance also increases significantly with \(d\) and \(}{{w}}\); in Appendix C we show standard deviations about the averages for different random initializations. Nevertheless, we have found that the inequality \(c_{loss} c_{sharp} c_{max}\) typically holds, for any given initialization and batch sequences, except for some outliers due to high fluctuations when the averaged critical curves start merging at large \(d\) and \(}{{w}}\). Fig. 4 shows evidence of this claim. The setup is the same as in Fig. 3. Appendix D presents extensive additional results across various architectures and datasets.

In Appendix F, we show that cross-entropy loss shows similar results with some notable differences. The loss catapults at a relatively higher value \( c_{loss} 4\) and \( c_{max}\) consistently decreases with \(}{{w}}\), while still satisfying \(c_{loss} c_{sharp} c_{max}\).

### Loss connectivity in the early transient period

In the previous subsection, we observed that training loss and sharpness might quickly increase before decreasing ("catapult") during early training for a range of depths and widths. A logical next step is to analyze the region in the loss landscape that the training reaches after the catapult. Several works have analyzed loss connectivity along the training trajectory . Ref.  report that training traverses a barrier at large learning rates, aligning with the naive intuition of a barrier between the initial and final points of the loss catapult, as the loss increases during early training. In this section, we will test the credibility of this intuition in real-world models. Specifically, we linearly interpolate the loss between the initial and final point after the catapult and examine the effect of the learning rate, depth, and width. The linearly interpolated loss and barrier are defined as follows.

**Definition 2**.: \((_{int}(s,c),U(c))\) _Let \(_{0}\) represent the initial set of parameters, and let \(_{T_{1}}\) represent the set of parameters at the end of the initial transient period, trained using a learning rate constant \(c\). Then, we define the linearly interpolated loss as \(_{int}(s,c)=[(1-s)\;_{0}+s\;_{T_{1}}]\), where \(s\) is the interpolation parameter. The interpolated loss barrier is defined as the maximum value of the interpolated loss over the range of \(s\): \(U(c)=_{s}_{int}(s)-(_{0})\)._

Here we subtracted the loss's initial value such that a positive value indicates a barrier to the final point from initialization. Using the interpolated loss barrier, we define \(c_{barrier}\) as follows.

**Definition 3**.: _(\(c_{barrier}\)) Given the initial (\(_{0}\)) and final parameters (\(_{T_{1}}\)), we define \(c_{barrier}\) as the minimum learning rate constant such that there exists a barrier from \(_{0}\) to \(_{T_{1}}\): \(c_{barrier}=_{c}\{c\;|\;U(c)>0\}\)._

Here, \(c_{barrier}\) is also a random variable that depends on the initialization and SGD batch sequence. We denote the average over this randomness using \(.\) as before. Fig. 2(c, f) shows the interpolated loss of CNNs trained on the CIFAR-10 dataset for \(t=10\) steps. The experimental setup is the same as in Section 2. For the network with larger width, we observe a barrier emerging at \(c_{barrier}=5.65\), while the loss starts to catapult at \(c_{loss}=2.83\). In comparison, we do not observe any barrier from initialization to the final point at large \(d\) and \(}{{w}}\). Fig. 3 shows the relationship between \( c_{barrier}\) and \(}{{w}}\) for various models and datasets. We consistently observe that \(c_{sharp} c_{barrier}\), suggesting that training traverses a barrier only when sharpness starts to catapult during early training. Similar results

Figure 4: The relationship between critical constants for (a) FCNs, (b) CNNs, and (c) ResNets. Each data point corresponds to a run with varying depth, width, and initialization. The dashed line represents the \(y=x\) line.

were observed on increasing \(d\) instead of \(}{{w}}\) as shown in Appendix C. We chose not to characterize the phase diagram of early training using \(c_{barrier}\) as we did for other critical \(c\)'s, as it is somewhat different in character than the other critical constants, which depend only on the sharpness and loss trajectories.

These observations call into question the intuition of catapulting out of a basin for a range of learning rates in between \(c_{loss}<c<c_{barrier}\). These results show that for these learning rates, the final point after the catapult already lies in the same basin as initialization, and even _connected through a linear path_, revealing an inductive bias of the training process towards regions of higher loss during the early time transient regime.

## 3 Intermediate saturation regime

In the intermediate saturation regime, sharpness does not change appreciably and reflects the cumulative change that occurred during the initial transient period. This section analyzes sharpness in the intermediate saturation regime by studying how it changes with the learning rate, depth, and width of the model. Here, we show results for MSE loss, whereas cross-entropy results are shown in Appendix F.

We measure the sharpness \(_{}^{H}\) at a time \(\) in the middle of the intermediate saturation regime. We choose \(\) so that \(c 200\).6 For further details on sharpness measurement, see Appendix I.1. Fig. 5(a) illustrates the relationship between \(_{}^{H}\) and the learning rate for \(7\)-layer deep CNNs trained on the CIFAR-10 dataset with varying widths. The results indicate that the dependence of \(_{}^{H}\) on learning rate can be grouped into three distinct stages. (1) At small learning rates, \(_{}^{H}\) remains relatively constant, with fluctuations increasing as \(d\) and \(}{{w}}\) increase (\(c<2\) in Fig. 5(a)). (2) A crossover regime where \(_{}^{H}\) is dropping significantly (\(2<c<2^{3}\) in Fig. 5(a)). (3) A saturation stage where \(_{}^{H}\) stays small and constant with learning rate (\(c>2^{3}\)) in Fig. 5(a)). In Appendix I, we show that these results are consistent across architectures and datasets for varying values of \(d\) and \(w\). Additionally, the results reveal that in stage (1), where \(c<2\) is sub-critical, \(_{}^{H}\) decreases with increasing \(d\) and \(}{{w}}\). In other words, for small \(c\) and in the intermediate saturation regime, the loss is locally flatter as \(d\) and \(}{{w}}\) increase.

We can precisely extract a critical value of \(c\) that separates stages (1) and (2), which corresponds to the onset of an abrupt reduction of sharpness \(_{}^{H}\). To do this, we consider the averaged normalized sharpness over initializations and denote it by \(^{}{{H}}}_{}^{_{}^{H}}\). The first two derivatives of the averaged normalized sharpness, \(_{}=-^{}{{H}}}_{ }^{_{}^{H}}\) and \(_{}^{}=-}{ c^{2}}^{}{{H}}}_{}^{_{}^{H}}\), characterize the change in sharpness with learning rate. The extrema of \(_{}^{}\) quantitatively define the boundaries between the three stages described above. In particular, using the maximum of \(_{}^{}\), we define \( c_{crit}\), which marks the beginning of the sharp decrease in \(_{}^{H}\) with the learning rate.

Figure 5: (a) Normalized sharpness measured at \(c=200\) against the learning rate constant for \(7\)-layer CNNs trained on the CIFAR-10 dataset, with varying widths. Each data point is an average over 5 initializations, where the shaded region depicts the standard deviation around the mean trend. (b, c) Smooth estimations of the first two derivatives, \(_{}\) and \(_{}^{}\), of the averaged normalized sharpness wrt the learning rate constant. The vertical lines denote \(c_{crit}\) estimated using the maximum of \(_{}^{}\). For smoothening details, see Appendix I.2.

**Definition 4**.: _(\( c_{crit}\)) Given the averaged normalized sharpness \(_{}}}{{_{0}^{H}}}\) measured at \(\), we define \(c_{crit}\) to be the learning rate constant that minimizes its second derivative: \( c_{crit}=_{c}^{}_{}\)._

Here, we use \(.\) to denote that the critical constant is obtained from the averaged normalized sharpness. Fig. 5(b, c) show \(_{}\) and \(^{}_{}\) obtained from the results in Fig. 5(a). We observe similar results across various architectures and datasets, as shown in Appendix I. Our results show that \( c_{crit}\) has slight fluctuations as \(d\) and \(}{{w}}\) are changed but generally stay in the vicinity of \(c=2\). The peak in \(^{}_{}\) becomes wider as \(d\) and \(}{{w}}\) increase, indicating that the transition between stages (1) and (2) becomes smoother, presumably due to larger fluctuations in the properties of the Hessian \(H\) at initialization. In contrast to \( c_{crit}\), \( c_{loss}\) increase with \(d\) and \(}{{w}}\), implying the opening of the sharpness reduction phase \( c_{crit}<c< c_{loss}\) as \(d\) and \(}{{w}}\) increase. In Appendix F, we show that cross-entropy loss shows qualitatively similar results, but with \(2 c_{crit} 4\).

## 4 Effect of network output at initialization on early training

Here we discuss the effect of network output \(f(x;_{t})\) at initialization on the early training dynamics. \(x\) is the input and \(_{t}\) denotes the set of parameters at time \(t\). We consider setting the network output to zero at initialization, \(f(x;_{0})=0\), by either (1) considering the "centered" network: \(f_{c}(x;)=f(x;)-f(x;_{0})\), or (2) setting the last layer weights to zero at initialization (for details, see Appendix G). Remarkably, both (1) and (2) remove the opening up of the sharpness reduction phase with \(1/w\) as shown in Figure 6. The average onset of the loss catapult, diagnosed by \( c_{loss}\), becomes independent of \(1/w\) and \(d\).

We also empirically study the impact of the output scale [19; 5; 4] on early training dynamics. Given a network function \(f(x;)\), we define the scaled network as \(f_{s}(x;)= f(x;)\), where \(\) is a scalar, fixed throughout training. In Appendix H, we show that a large (resp. small) value of \(\|f(x;_{0})\|\) relative to the one-hot encodings of the labels causes the sharpness to decrease (resp. increase) during early training. Interestingly, we still observe an increase in \( c_{loss}\) with \(d\) and \(}{{w}}\), unlike the case of initializing network output to zero, highlighting the unique impact of output scale on the dynamics.

## 5 Insights from a simple model

Here we analyze a two-layer linear network [56; 60; 49], the \(uv\) model, which shows much of the phenomena presented above. Define \(f(x)=}v^{T}ux\), with \(x,f(x)\). Here, \(u,v^{w}\) are the trainable parameters, initialized using the normal distribution, \(u_{i},v_{i}(0,1)\) for \(i\{1,,w\}\). The model is trained with MSE loss on a single training example \((x,y)=(1,0)\), which simplifies the loss to \((u,v)=f^{2}/2\), and which was also considered in Ref. . Our choice of \(y=0\) is motivated by the results of Sec. 4, which suggest that the empirical results of Sec. 2 are intimately related to the model having a large initial output scale \(\|f(x;_{0})\|\) relative to the output labels. We minimize the loss using gradient descent (GD) with learning rate \(\). The early time phase diagram also shows similar features to those described in preceding sections (compare Fig. 7(a) and Fig. 3). Below we develop an understanding of this early time phase diagram in the \(uv\) model.

Figure 6: Phase diagrams of \(d=8\) layer FCNs trained on the CIFAR-10 dataset using MSE, demonstrating the effect of output scale at initialization: (a) vanilla network, (b) centered network, and (c) network initialized with the last layer set to zero.

The update equations of the \(uv\) model in function space can be written in terms of the trace of the Hessian \((H)\)

\[f_{t+1}=f_{t}(1-(H_{t})+f_{t}^{2}}{w} ),(H_{t+1})=(H_{t})+^{2}}{w}((H_{t})-4).\] (1)

From the above equations, it is natural to scale the learning rate as \(=}{{(H_{0})}}\). Note that \(c=_{0}^{H}=}^{H}}}{{(H_{0})}}\). Also, we denote the critical constants in this scaling as \(k_{loss}\), \(k_{trace}\), \(k_{max}\) and \(k_{crit}\), where the definitions follow from Definitions 1 and 4 on replacing sharpness with trace and use \(.\) to denote an average over initialization. Figure 7(b) shows the phase diagram of early training, with \((H_{t})\) replaced with \(_{t}^{H}\) as the measure of sharpness and with the learning rate scaled as \(=}{{(H_{0})}}\). Similar to Figure 7(a), we observe a new phase \( k_{crit}<k< k_{loss}\) opening up at small width. However, we do not observe the loss-sharpness catapult phase as \((H)\) does not increase during training (see Equation 1). We also observe \( k_{max}=4\), independent of width.

In Appendix B.3, we show that the critical value of \(k\) for which \(}}{{}_{0}}}>1\) increases with \(}{{w}}\), which explains why \( k_{loss}\) increases with \(}{{w}}\). Combined with \( k_{crit} 2\), this implies the opening up of the sharpness reduction phase as \(w\) is decreased.

To understand the loss-sharpness catapult phase, we require some other measure as \((H)\) does not increase for \(0<k<4\). As \(_{t}^{H}\) is difficult to analyze, we consider the Frobenius norm \(\|H\|_{F}=(H^{T}H)}\) as a proxy for sharpness. We define \(k_{frob}\) as the minimum learning rate such that \(\|H_{t}\|_{F}^{2}\) increases during early training. Figure 7(c) shows the phase diagram of the \(uv\) model, with \(H_{t}\|_{F}\) as the measure of sharpness, while the learning rate is scaled as \(=}{{(H_{0})}}\). We observe the loss-sharpness catapult phase at small widths. In Appendix B.4, we show that the critical value of \(k\) for which \(\|H_{1}\|_{F}^{2}-\|H_{0}\|_{F}^{2}>0\) increases from \( k_{loss}\) as \(}{{w}}\) increases. This explains the opening up of the loss catapult phase at small \(w\) in Fig. 7 (c).

Fig. 8 shows the training trajectories of the \(uv\) model with large (\(w=512\)) and small (\(w=2\)) widths in a two-dimensional slice of parameters defined by \((H)\) and weight correlation \(}{{\|u\|\|v\|}}\). The above figure reveals that the first few training steps of the small-width network take the system in a flatter direction (as measured by \((H)\)) as compared to the wider network. This means that the small-width network needs a relatively larger learning rate to get to a point of increased loss (loss catapult). We thus have the opening up of a new regime \( k_{crit}<k< k_{loss}\), in which the loss and sharpness monotonically decrease during early training.

The loss landscape of the \(uv\) model shown in Fig. 8 reveals interesting insights into the loss landscape connectivity results in Section 2.2 and the presence of \(c_{barrier}\). Fig. 8 shows how even when there is a loss catapult, as long as the learning rate is not too large, the final point after the catapult can be reached from initialization by a linear path without increasing the loss and passing through a barrier. However if the learning rate becomes large enough, then the final point after the catapult may correspond to a region of large weight correlation, and there will be a barrier in the loss upon linear interpolation.

The \(uv\) model trained on an example \((x,y)\) with \(y 0\) provides insights into the effect of network output at initialization observed in Section 4. In Appendix G, we show that setting \(f_{0}=0\) and

Figure 7: The phase diagram of the \(uv\) model trained with MSE loss using gradient descent with (a) the top eigenvalue of Hessian \(_{t}^{H}\), (b) the trace of Hessian \((H_{t})\) and (c) the square of the Frobenius norm \((H_{t}^{T}H_{t})\) used as a measure of sharpness. In (a), the learning rate is scaled as \(=}{{_{0}^{H}}}\), while in (b) and (c), the learning rate is scaled as \(=}{{(H_{0})}}\). The vertical dashed line shows \(c=2\) (\(k=2\)) for reference. Each data point is an average over \(500\) random initializations.

\(y 0\) in the dynamical equations results in loss catapult at \(k=2\), implying \( k_{loss} k_{crit} 2\), irrespective of \(w\).

## 6 Discussion

We have studied the effect of learning rate, depth, and width on the early training dynamics in DNNs trained using SGD with learning rate scaled as \(=}{{_{0}^{H}}}\). We analyzed the early transient and intermediate saturation regimes and presented a rich phase diagram of early training with learning rate, depth, and width. We report two new phases, sharpness reduction and loss-sharpness catapult, which have not been reported previously. Furthermore, we empirically investigated the underlying cause of sharpness reduction during early training. Our findings show that setting the network output to zero at initialization effectively leads to the vanishing of sharpness reduction phase at supercritical learning rates. We further studied loss connectivity in the early transient regime and demonstrated the existence of a regime \( c_{loss}<c< c_{barrier}\), in which the final point after the catapult lies in the same basin as initialization, connected through a linear path. Finally, we study these phenomena in a 2-layer linear network (\(uv\) model), gaining insights into the opening of the sharpness reduction phase.

We performed a preliminary analysis on the effect of batch size on the presented results in Appendix J. The sharpness trajectories of models trained with a smaller batch size (\(B=32\) vs. \(B=512\)) show similar early training dynamics. In the early transient regime, we observe a qualitatively similar phase diagram. In the intermediate saturation regime, the effect of reducing the batch size is to broaden the transition around \(c_{crit}\).

In Section 2, we noted that for cross-entropy loss, the loss starts to catapult around \(c 4\) at large widths, as compared to \(c_{loss}=2\) for MSE loss. Previous work, such as , analyzed the catapult dynamics for the \(uv\) model with logistic loss and demonstrated that the loss catapult occurs above \(_{loss}=4/_{0}^{NTA}\). We summarize the main intuition about their analysis in Appendix B.9. However, a complete understanding of the catapult phenomenon in the context of cross-entropy loss requires a more detailed examination.

The early training dynamics is sensitive to the initialization scheme and optimization algorithm used, and we leave it to future work to explore this dependence and its implications. In this work, we focused on models initialized at criticality  as it allows for proper gradient flow through ReLU networks at initialization [23; 58], and studied vanilla SGD for simplicity. However, other initializations , parameterizations [69; 70], and optimization procedures  may show dissimilarities with the reported phase diagram of early training.

Figure 8: Training trajectories of the \(uv\) model trained on \((x,y)=(1,0)\), with (a, b) large and (c, d) small width, in a two-dimensional slice of the parameters defined by the trace of Hessian \((H)\) and weight correlation, trained with (a, c) small (\(c=0.5\)) and (b, d) large (\(c=2.5\)) learning rates. The colors correspond to the training loss \(\), with darker colors representing a smaller loss.