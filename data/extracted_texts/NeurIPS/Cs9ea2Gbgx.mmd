# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

Introduction

Replicability and reproducibility in science are critical concerns. The fundamental requirement that scientific results and experiments be replicable/reproducible is central to the development and evolution of science. In recent years, these concerns have grown as several scientific disciplines turn to data-driven research, which enables exponential progress through data democratization and affordable computing resources. The replicability issue has received attention from a wide spectrum of entities, from general media publications (for example, The Economist's "How Science Goes Wrong," 2013 (eco13)) to scientific publication venues (for example, see (JP05; Bak16)) to professional and scientific bodies such as the National Academy of Sciences, Engineering, and Medicine (NASEM). The emerging challenges to replicability and reproducibility have been discussed in depth by a consensus study report published by NASEM (NAS19).

A broad approach taken to ensure the reproducibility/replicability of algorithms is to make the datasets, algorithms, and code publicly available. Of late, conferences have been hosting replicability workshops to promote best practices and to encourage researchers to share code (see (PVLS\({}^{+}\)21) and (MPK19)). An underlying assumption is that consistent results can be obtained using the same input data, computational methods, and code. However, these practices alone are insufficient to ensure replicability as modern-day approaches use computations that inherently involve randomness.

Computing over random variables results in a high degree of non-replicability, especially in machine learning tasks. Machine learning algorithms observe samples from a (sometimes unknown) distribution and output a hypothesis. Such algorithms are inherently non-replicable. Two distinct runs of the algorithm will output different hypotheses as the algorithms see different sets of samples over the two runs. Ideally, to achieve "perfect replicability," we would like to design algorithms that output the same canonical hypothesis over multiple runs, even when different runs observe a different set of samples from the unknown distribution.

We first observe that perfect replicability is not achievable in learning, as a dependency of the output on the data samples is inevitable. We illustrate this with a simple learning task of estimating the bias of a coin: given \(n\) independent tosses of a coin with unknown bias \(b\), output an estimate of \(b\) that is within an additive error of \(\) with high probability. It is relatively easy to argue that there is no algorithm that outputs a _canonical estimate_\(v_{b}\) with probability \( 2/3\) so that \(|v_{b}-b|\). Suppose, for the sake of contradiction, such an algorithm \(A\) exists. Consider a sequence of coins with biases \(b_{1}<b_{2}<<b_{m}\) where each \(b_{i+1}-b_{i}=1/10n\), and \(b_{m}-b_{1} 2\). For two adjacent biases \(b_{i}\) and \(b_{i+1}\), the statistical distance (denoted by \(d_{}\)) between \(D_{i+1}^{n}\) and \(D_{i}^{n}\) is \( n\), where \(_{i}^{n}\) is the distribution of \(n\) independent tosses of the \(i^{th}\) coin. Let \(v_{i+1}\) and \(v_{i}\) be the canonical estimates output by the algorithm for biases \(b_{i+1}\) and \(b_{i}\) respectively. Since \(A\) on samples from distribution \(_{i}^{n}\) outputs \(v_{i}\) with probability at least \(2/3\) and \(d_{}(D_{i}^{n},D_{i+1}^{n}) n\), \(A(D_{i+1}^{n})\) must output \(v_{i}\) with probability at least \(2/3\). Since \(A(_{i+1}^{n})\) must output a canonical value \(v_{i+1}\) with probability at least \(2/3\), this implies that \(v_{i}=v_{i+1}\) (if not the probabilities will add up to \(>1\)). Thus, on all biases \(b_{1},,b_{m}\), the algorithm \(A\) should output the same value. This leads to a contradiction since \(b_{1}\) and \(b_{m}\) are \(2\) apart. However, it is easy to see that there is an algorithm for bias-estimation that outputs one of _two canonical_ estimates with high probability using \(n=O(1/^{2})\) tosses: estimate the bias within an error of \(/2\) and round the value to the closest multiple of \(\). The starting point of our work is these two observations. Even though it may not be possible to design learning algorithms that are perfectly replicable, it is possible to design algorithms whose "non-replicability" is minimized.

We study two notions of replicability called _list replicability_ and _certificate replicability_ which quantify the _degree_ of (non)-replicability of learning algorithms. They are rooted in the pseudocdeterminism-literature (GG11; Gol19; GL19) which studied concepts known as _multi-pseudodeterminism_ (related to list replicability) and _influential bit algorithms_ (related to certificate replicability). Recently a notion of _algorithmic stability_ and its variants such as _list global stability_, _pseudo global stability_, and _\(\)-replicability_ have been studied in the context of learning algorithms (BLM20; GKM21; ILPS22). These notions are very similar to each other and Section 2 discusses the similarities and connections.

### Our Results

Informally, an algorithm \(A\) is \(k\)-list replicable if there is a list \(L\) consisting of \(k\) (approximately correct) hypotheses so that the output of the algorithms \(A\) belongs to \(L\) with high probability. This implies that when the algorithm \(A\) is run multiple times, we see at most \(k\) distinct hypotheses (withhigh probability). The value \(k\) is called the _list complexity_ of the algorithm. An algorithm whose list complexity is \(1\) is perfectly replicable. Thus, list complexity can be considered as a degree of (non) replicability. The goal in this setting is to design learning algorithms that minimize the list complexity \(k\) for various learning tasks.

In certificate replicability, the learning algorithm has access to an \(\)-bit random string that is independent of samples and the other randomness that the algorithm may use. It is required that for most \(\)-bit random strings \(r\), the algorithm must output a _canonical_ (approximately correct) hypothesis \(h_{r}\) that depends only on \(r\). Thus once we fix a good \(\)-bit random string \(r\), multiple runs of the algorithm will output the same hypothesis with high probability. We call \(\) the _certificate complexity_ of the algorithm. An algorithm with zero certificate complexity is perfectly replicable. Thus \(\) is another measure of the degree of (non) replicability of the algorithm. The goal in this setting is to design learning algorithms that minimize the certificate complexity.

A critical resource in machine learning tasks is the _sample complexity_--the number of samples that the algorithm observes. This work initiates a study of learning algorithms that are efficient in list complexity, certificate complexity as well as sample complexity. The main contribution of this work is the design of algorithms with an optimal list and certificate complexities with efficient sample complexity for a few fundamental learning tasks.

Estimating the biases of \(d\) coins.We consider the basic problem of estimating the biases of \(d\) coins simultaneously by observing \(n\) tosses of each of the coins which we call \(d\)-Coin Bias Estimation Problem. The task is to output an approximate bias vector \(\) with probability at least \((1-)\) so that \(\|-\|_{}\) where \(= b_{1}, b_{d}\) is the true bias vector, i.e., \(b_{i}\) is the true bias of the \(i\)th coin. For this task, we establish the following results.

* There is a \((d+1)\)-list replicable learning algorithm for \(d\)-Coin Bias Estimation Problem whose sample complexity (number of observed coin tosses) is \(n=O(}{^{2}})\) per coin.
* There is a \(\)-certificate replicable algorithm for \(d\)-Coin Bias Estimation Problem with sample complexity \(n=O(}{^{2}^{2}})\) per coin.
* We establish the optimality of the above upper bounds in terms of list complexity. We show that there is no \(d\)-list replicable learning algorithm for \(d\)-Coin Bias Estimation Problem.

While \(d\)-Coin Bias Estimation Problem is a basic learning task and is of interest by itself, the techniques developed for this problem are applicable in the context of PAC learning.

PAC learning.We investigate list and certificate replicable PAC learning algorithms.

* We establish the following generic result: Any concept class that can be learned using \(d\) non-adaptive statistical queries can be learned by a \((d+1)\)-list replicable PAC learning algorithm with sample complexity \(O(}{^{2}})\) where \(\) is the statistical query parameter. We also show that such concept classes admit a \(\)-certificate replicable PAC learning algorithm with sample complexity \(O(}{^{2}^{2}})\).
* We study the list complexity of the concept class \(d\)-Threshold. Each hypothesis \(h_{}\) in this concept class is described via a \(d\)-dimensional vector \(^{d}\). For a hypothesis \(h_{t}\), \(h_{t}()=1\) if and only if \(x_{i} t_{i}\), \(1 i d\)1. We establish that, under the uniform distribution, the list complexity of \(d\)-Threshold is _exactly_\(d+1\).

To establish our upper bound results we use rounding schemes induced by geometric partitions with certain properties. We use Sperner/KKM Lemma as a tool to establish the lower bound results. Due to space restrictions, most of the proofs are given in the supplementary material.

## 2 Prior and Related Work

Formalizing reproducibility and replicability has gained considerable momentum in recent years. While the terms reproducibility and replicability are very close and often used interchangeably, there has been an effort to distinguish between them and accordingly, our notions fall in the replicability definition (PVLS\({}^{+}\)21). As mentioned earlier, reproducibility, replicability, and related notions have been of considerable interest in the context of traditional randomized algorithms and learning algorithms. Here we discuss the prior work that is most relevant to the present work. A more detailed discussion of the prior and related work is provided in the supplementary material.

The seminal work of (BLM20) defined the notion of _global stability_ in the context of learning, which is similar to the notion of pseudodeterminism (GG11) in the context of traditional algorithms. They define a learning algorithm \(A\) to be \((n,)\)-globally stable with respect to a distribution \(D\) if there is a hypothesis \(h\) such that \(_{S D^{n}}(A(S)=h)\), here \(\) is called the _stability parameter_. Using this notion as an intermediate tool they established that every concept class with finite Littestone dimension can be learned by an approximate differentially private algorithm. The work in (GKM21) extended the notion of global stability to _list-global stability_ and _pseudo-global stability_. The authors of (GKM21) used these concepts to design user-level differentially private algorithms. The notion of pseudo-global stability is similar to the notion of certificate applicability, however, as defined, the notion of list-global stability differs from our notion of list replicability.

The recent work reported in (ILPS22) introduced the notion of \(\)-_replicability_. A learning algorithm \(A\) is \(\)-replicable if \([A(S_{1},r)=A(S_{2},r)] 1-\), where \(S_{1}\) and \(S_{2}\) are samples drawn from a distribution \(\) and \(r\) is the internal randomness of the learning algorithm \(A\). They designed replicable algorithms for many learning tasks, including statistical queries, approximate heavy hitters, median, and learning half-spaces. It is known that the notions of pseudo-global stability and \(\)-replicability are the same up to polynomial factors in the parameters (ILPS22; GKM21).

The present work introduces the notions of list and certificate complexities as measures of the degree of (non) replicability. Our goal is to design learning algorithms with optimal list and certificate complexities while minimizing the sample complexity. The earlier works did not focus on minimizing these quantities. The works of (BLM20; GKM21) used replicable algorithms as an intermediate step to design differentially private algorithms. The work of (ILPS22) did not consider reducing the certificate complexity in their algorithms and also did not study list replicability. The main distinguishing feature of our work from prior works is our focus on designing learning algorithms that are efficient in list, certificate, and sample complexities as well as establishing optimality results for list and certificate complexity.

A very recent and independent work of (CMY23) investigated relations between list replicability and the stability parameter \(\), in the context of distribution-free PAC learning. They showed that for every concept class \(\), its list complexity is exactly the inverse of the stability parameter. They also showed that the list complexity of a hypothesis class is at least its VC dimension. For establishing this they exhibited, for any \(d\), a concept class whose list complexity is exactly \(d\). There are some similarities between their work and the present work. We establish similar upper and lower bounds on the list complexity but for different learning tasks: \(d\)-Threshold and \(d\)-Coin Bias Estimation Problem. For \(d\)-Threshold, our results are for PAC learning under _uniform_ distribution and do not follow from their distribution-independent results. Thus our results, though similar in spirit, are incomparable to theirs. Moreover, their work did not focus on efficiency in sample complexity and also did not study certificate complexity which is a focus of our paper. We do not study the stability parameter.

Finally, we would like to point out that there notions of list PAC learning and list-decodable learning in the learning theory literature (see (CP23) and (RY20) for recent progress on these notions). However, these notions are different from the list replicable learning that we consider in this paper. List PAC learning and list-decodable learning are generalized models of PAC learning. For example, any learning task that is PAC learnable is trivially list PAC learnable with a list size of 1. However, list replicable learning is an additional requirement that needs to be satisfied by a learner. Thus the notion of list and list-decodable PAC learning are different from the notions of list/certificate replicability.

## 3 List and Certificate Replicability Notions

We define list and certificate replicability notions for general learning tasks. A learning problem is a family \(\) of distributions over a domain \(\), a set \(\) (representing hypotheses) and an error function \(:[0,)\). The goal is to learn a hypothesis from \(\) by observing samples from a distribution \(D\) where \(D\) with a small error \((D,h)\). A learning algorithm \(A\) has the following inputs: (i) \(m\) independent samples from a distribution \(D\) and (ii) \((0,)\) and (iii) \((0,1]\). It may also receive additional inputs.

**Definition 3.1** (List Replicability).: Let \(k\), \((0,)\), and \(\). A learning algorithm \(A\) is called \((k,,)\)-list replicable if the following holds: There exists \(n\) such that for every \(D\), there exists a list \(L\) of size at most \(k\) such that (i) for all \(h L\), \((D,h)\), and (ii)

\[_{D^{n}}[A(s,, ) L] 1-.\]

For \(k\), we call \(A\)_k-list replicable_ if for all \((0,)\) and \((0,1]\), \(A\) is \((k,,)\)-list replicable. We say that \(n\) is the _sample complexity_ of \(A\) and \(k\) is the _list complexity_ of \(A\).

**Definition 3.2** (Certificate Replicability).: Let \(\), \((0,)\), and \(\). A learning algorithm \(A\) is called \((,,)\)-certificate replicable if the following holds: There exists \(n\) such that for every \(D\) there exists \(h:\{0,1\}^{}\) such that

\[_{r\{0,1\}^{}^{}} _{s D^{n}}A(s,,,r)=h(r)(D,h(r)) 1-  1-.\]

We can refine the above definition by introducing another probability parameter \(\) and define a notion of \((,,,)\)-replicability. The definition is the same as above except that we require the outer probability to be \(1-\), and the inner probability is \(1-\). For simplicity, we take \(\) to be \(\) and work with the notion of \((,,)\)-replicability.

The above definitions generalize the notion of _perfect replicability_, where it is required that the learning algorithm outputs a canonical hypothesis \(h\) (with \((D,h)\)) with probability \( 1-\). A motivation for these definitions is to characterize how close we can be to perfect replicability in scenarios where if perfect replicability is not achievable. Note that for list (certificate) replicability, when \(k=1\) (respectively, \(=0\)), we achieve perfect applicability. We note that the above definitions are inspired by multi-pseudodeterminism (Gol19) and influential-bit algorithms (GL19).

## 4 Primary Lemmas

Our upper bounds are based on certain rounding schemes and the lower bound is based on Sperner/KKM lemma. In this section, we state a few key technical lemmas that will be used in the rest of the paper. The proofs are in the supplementary material. We will use the following notation. We use \(_{}\) to indicate the diameter of a set relative to the \(_{}\) norm and \(_{}^{}()\) to represent the closed ball of radius \(\) centered at \(\) relative to the \(_{}\) norm. That is, in \(^{d}\) we have \(_{}^{}()=_{i=1}^{d}[p_{i}-,p_{i}+]\).

We first state a lemma that gives a universal deterministic rounding algorithm that is used in designing list replicable algorithms. The lemma is based on the work in (VWDP\({}^{+}\)22) and is a byproduct of certain geometric partitions they call _secluded partitions_.

**Lemma 4.1**.: _Let \(d\) and \((0,)\). Let \(_{0}=\). There is an efficiently computable function \(f_{}:^{d}^{d}\) with the following two properties:_

1. _For any_ \(x^{d}\) _and any_ \(_{_{0}}^{}(x)\) _it holds that_ \(f_{}()_{}^{}(x)\)_._
2. _For any_ \(x^{d}\) _the set_ \(f_{}()_{_{0} }^{}(x)}\) _has cardinality at most_ \(d+1\)_._

Item (1) states that if \(\) is an \(_{0}\) approximation of \(x\), then \(f_{}()\) is an \(\) approximation of \(x\), and Item (2) states that \(f_{}\) maps every \(_{0}\) approximation of \(x\) to one of at most \(d+1\) possible values.

The following lemma gives a universal randomized rounding algorithm that is used in designing certificate replicable algorithms. We note that randomized rounding schemes have been used in a few prior works (SZ99; DPV18; Gol19; GL19; ILPS22). Our rounding scheme is more nuanced as it is geared towards minimizing certificate complexity.

**Lemma 4.2**.: _Let \(d\), \(_{0}(0,)\) and \(0<<1\). There is an efficiently computable deterministic function \(f:\{0,1\}^{}^{d}^{d}\) with the following property. For any \(x^{d}\),_

\[_{r\{0,1\}^{}^{}} x ^{*}_{}^{}(x)\ \ _{_{0}}^{}(x):f(r,)=x^{*}  1-\]

_where \(=\) and \(=(2^{}+1)_{0}d}{}\)._The following result is a corollary to a cubical variant of Sperner's lemma/KKM lemma initially developed in (DLPES02) and expanded on in (VWDP\({}^{+}\)22). We use this to establish our lower bound results.

**Lemma 4.3**.: _Let \(\) be a partition of \(^{d}\) such that for each member \(X\), it holds that \(_{}(X)<1\). Then there exists \(^{d}\) such that for all \(>0\) we have that \(_{}^{}()\) intersects at least \(d+1\) members of \(\)._

## 5 Replicability of Learning Coins Biases

In this section, we establish replicability results for estimating biases of \(d\) coins.

**Definition 5.1**.: The \(d\)-Coin Bias Estimation Problem is the following problem: Design an algorithm \(A\) (possibly randomized) that gets \((0,1)\), \((0,1]\) as inputs, observes independent tosses of an ordered collection of \(d\)-many biased coins with a bias vector \(^{d}\), and outputs \(\) so that \(\|-\|_{}\) with probability \( 1-\).

The \(d\)-Coin Bias Estimation Problem fits in the framework of the general learning task introduced in Section 3 so that we can talk about list and certificate replicable algorithm for \(d\)-Coin Bias Estimation Problem. We describe this now.

For \(d\)-Coin Bias Estimation Problem we have the following. \(=\{0,1\}^{d}\) (where 0 corresponds to Tail and 1 corresponds to Head) which is the set of representations of all possibilities of flipping \(d\)-many coins. The class of distributions \(\) is the set of all \(d\)-fold products of Bernoulli distributions. Each distribution \(D\) is parameterized with a vector \(v_{D}= b_{1},,b_{d}^{d}\). When sampled according to \(v_{D}\) we obtain a sample point \( x_{1} x_{d}\), where \((x_{i}=1)=b_{i}\). We take the class of hypothesis \(\) to be \(^{d}\) which is the set of all \(d\)-tuples representing biases of a collection of \(d\)-many coins. Lastly, the error function is defined as \((D,h)=\|v_{D}-h\|_{}\).

### Replicable Algorithms for \(d\)-Coin Bias Estimation Problem

In this section, we design list and certificate replicable algorithms for \(d\)-Coin Bias Estimation Problem.

**Theorem 5.2**.: _There exists an \((d+1)\)-list replicable algorithm for \(d\)-Coin Bias Estimation Problem. For a given \(\) and \(\), its sample complexity is \(n=O(}{^{2}})\), per coin._

``` Input:\(>0,(0,1]\), sample access to \(d\) coins with biases \(^{d}\) \(_{0}}}{{=}},_{0}}}{{=}}\) \(n}}{{=}}O()}{ _{0}^{2}})=O((d/)}{^{2}})\) for some constant  Let \(f_{}:^{d}^{d}\) be as in Lemma 4.1.  Let \(g:^{d}^{d}\) be the function which restricts coordinates to the unit interval (i.e. ) )  Take \(n\) samples from each coin and let \(\) be the empirical biases. return\(g(f())\) ```

**Algorithm 1**\((d+1)\)-list replicable algorithm for \(d\)-Coin Bias Estimation Problem

Proof.: Note that when \( 1/2\), a trivial algorithm that outputs a vector with \(1/2\) in each component works. Thus the most interesting case is when \(<1/2\). Our list replicable algorithm is described in Algorithm 1. We will prove its correctness by associating for each possible bias \(^{d}\), a set \(L_{}\) with the three necessary properties: (1) \(|L_{}| d+1\), (2) \(L_{}_{}^{}()\) (and also the problem specific restriction that \(L_{}^{d}\)), and (3) when given access to coins of biases \(\), with probability at least \(1-\) the algorithm returns a value in \(L_{}\).

Let \(L_{}=\{g(f_{}())_{ _{0}}^{}()\}\). By Lemma 4.1, \(f_{}\) takes on at most \(d+1\) values on \(_{_{0}}^{}()\) (which means \(g f_{}\) also takes on at most \(d+1\) values on this ball) which proves that \(|L_{}| d+1\). This proves property (1).

Next we state the following observation which says that the coordinate restriction function \(g\) of Algorithm 1 does not reduce approximation quality. The proof is straightforward.

**Observation 5.3**.: _Using the notation of Algorithm 1, if \(_{}^{}()\) then \(g()_{}^{}()\)._

We now establish Property (2). We know from Lemma 4.1 that for each \(_{_{0}}^{}()\) we have \(f_{}()_{}^{}()\), and by Observation 5.3, \(g\) maintains this quality and we have \(g(f_{}())_{}^{}()\). This shows that \(L_{}_{}^{}()\) proving property (2).

By Chernoff's bounds, for a single biased coin, with \(n=O()}{_{0}^{2}})\) independent samples of the coin we can estimate the bias within \(_{0}\) with probability at least \(1-_{0}\). Thus, by a union bound, if we take \(n\) samples of each of the \(d\) coins, there is a probability of at most \(d_{0}=\) that at least one of the empirical coin biases is not within \(_{0}\) of the true bias. Thus, by taking \(n\) samples of each coin, we have with probability at least \(1-\) that the empirical biases \(\) belong to \(_{_{0}}^{}()\). In the case that this occurs, we have by definition of \(L_{}\) that the value \(g(f_{}())\) returned by the algorithm belongs to the set \(L_{}\). This proves property (3). The sample complexity follows since \(_{0}=\) and \(_{0}=\). 

The next result is on certificate replicable algorithm for \(d\)-Coin Bias Estimation Problem.

**Theorem 5.4**.: _For every \(\) and \(\), there is a \((,,)\)-certificate replicable algorithm for \(d\)-Coin Bias Estimation Problem with sample complexity of \(n=O(}{^{2}^{2}})\) per coin._

Proof.: Let \(\) and \(\) be the input parameters to the algorithm and \(\) the bias vector. Set \(_{0}=\). The algorithm \(A\) first estimates the bias of each coin with up to \(_{0}\) with a probability error parameter \(\) using a standard estimation algorithm. Note that this can be done using \(O(}{^{2}^{2}})\) tosses per coin. Let \(\) be the output vector. It follows that \(_{_{0}}^{}()\) with probability at least \(1-\). Then it runs the deterministic function \(f\) described in Lemma 4.2 with input \(r\{0,1\}^{}\) with \(=\) and \(\) and outputs the value of the function. Lemma 4.2 guarantees that for \(1-\) fraction of the \(r\)s, all \(_{_{0}}^{}()\) gets rounded to the same value by \(f\). Hence algorithm \(A\) satisfies the requirements of the certificate-replicability. The certificate complexity is \(\). 

We remark that by using the refined definition of certificate replicability mentioned in Section 3, we can obtain a \((,,,)\)-replicable algorithm with sample complexity \(O(}{^{2}^{2}}(1/))\). Note that an \(\)-certificate replicable algorithm leads to a \(2^{}\)-list replicable algorithm. Thus Theorem 5.4 gives a \(O()\)-list replicable algorithm for \(d\)-Coin Bias Estimation Problem with sample complexity \(O(}{^{2}^{2}})\). However, this is clearly sub-optimal and Theorem 5.2 gives an algorithm with a much smaller list and sample complexities. Also from the work of Goldrecih (Gol19), it follows that \(\)-list replicable algorithm can be converted into a \(()\)-certificate replicable algorithm. However, this conversion increases the sample complexity. For example, when applied to \(d\)-Coin Bias Estimation Problem, the sample complexity becomes \(O(}{^{2}^{2}})\). In comparison, Theorem 5.4 uses a tailored rounding technique to achieve an algorithm with a much smaller sample complexity.

### An Impossibility Result

This section establishes the optimality of the list complexity for \(d\)-Coin Bias Estimation Problem.

**Theorem 5.5**.: _For \(k<d+1\), there does not exist a \(k\)-list replicable algorithm for the \(d\)-Coin Bias Estimation Problem._Before proving the theorem, we need a lemma that follows from the Data Processing Inequality; for more detail see the supplementary material. In the following, we use \(_{A,,n}\) to denote the distribution of the output of an algorithm for \(d\)-Coin Bias Estimation Problem.

**Lemma 5.6**.: _For biases \(,^{d}\) we have \(d_{}(_{A,,n},_{A,,n})  n d\|-\|_{}.\)_

Proof.: We use the basic fact that an algorithm (deterministic or randomized) cannot increase the total variation distance between two input distributions.

The distribution giving one sample flip of each coin in a collection with bias \(\) is the \(d\)-fold product of Bernoulli distributions \(_{i=1}^{d}(b_{i})\) (which for notational brevity we denote as \(()\), so the distribution which gives \(n\) independent flips of each coin is the \(n\)-fold product of this and is denoted as \(()^{ n}\)). We will show that for two bias vectors \(\) and \(\), \(d_{}(()^{ n},()^{ n}) n d\|-\|_{}.\) This suffices to establish the lemma.

Observe that we have for each \(i[d]\),

\[d_{}((b_{i}),(a_{i}))=|b_{i} -a_{i}|.\]

Hence we have

\[d_{}((),()) _{i=1}^{d} b_{i}-a_{i} d\|-\|_{}\]

and

\[d_{}(()^{ n},()^{ n}) n d\|-\|_{}.\]

Proof of Theorem 5.5.: Fix any \(d\), and choose \(\) and \(\) as \(<\) and \(\). Suppose for contradiction that such an algorithm \(A\) does exists for some \(k<d+1\). This means that for each possible bias vector \(^{d}\), there exists some set \(L_{}\) of hypotheses with three properties: (1) each element of \(L_{}\) is an \(\)-approximation to \(h_{}\), (2) \(|L_{}| k\), and (3) with probability at least \(1-\), \(A\) returns an element of \(L_{}\).

By an averaging argument, this means that there exists at least one element in \(L_{}\) which is returned by \(A\) with probability at least \((1-)(1-)= \). Let \(f^{d}^{d}\) be a function which maps each bias \(\) to such an element of \(L_{}\). Since \(>\), let \(\) be such that \(0<<-\).

The function \(f\) induces a partition \(\) of \(^{d}\) where the members of \(\) are the fibers of \(f\) (i.e. \(=\{f^{-1}()(f)\}\)). By definition, for any member \(X\) there exists some \((f)\) such that for all \( X\), \(f()=\). By definition, we have \(f() L_{}_{}^{}()\) showing that \(_{}^{}()\) and by symmetry \(_{}^{}()\). This shows that \(X_{}^{}()\), so \(_{}(X) 2<1\).

Let \(r=\). Since every member of \(\) has \(_{}\) diameter less than \(1\), by Lemma 4.3 there exists a point \(^{d}\) such that \(_{r}^{}()\) intersects at least \(d+1>k\) members of \(\). Let \(^{(1)},,^{(d+1)}\) be points belonging to distinct members of \(\) that all belong to \(_{r}^{}()\). By definition of \(\), this means for distinct \(j,j^{}[d+1]\) that \(f(^{(j)}) f(^{(j^{})})\).

Now, for each \(j[d+1]\), because \(\|-^{(j)}\|_{} r\), by Lemma 5.6 we have \(d_{}(_{A,,n},_{A,^{(j)},n}) n  d r=\). However, this gives rise to a contradiction because the probability that \(A\) with access to biased coins \(^{(j)}\) returns \(f(^{(j)})\) is at least \(\), and by Lemma 5.6, it must be that \(A\) with access to biased coins \(\) returns \(f(^{(j)})\) with probability at least \(->\); notationally, \(_{_{A,^{(j)},n}}\{f(^{(j)})\} \) and \(d_{}(_{A,^{(j)},n},_{A,,n})\), so \(_{_{A,,n}}\{f(^{(j)})\} ->\). This is a contradiction because a distribution cannot have \(d+1 k+1\) disjoint events that each have probability greater than \(\)List and Certificate Replicability in PAC Learning

In this section, we establish replicability results for the PAC model. We first note that PAC model fits in the general learning framework introduced in Section 3. Consider the PAC learning model where we have a domain \(^{}\), a concept class \(\) (a family of subsets of \(^{}\)), and a hypothesis class \(\) (a collection of functions \(^{}\{0,1\}\)). For any distribution \(D\) over \(^{}\) and any concept indicator \(f\) from \(\), let \(D_{f}\) denote the distribution over \(^{}\{0,1\}^{d}\) obtained by sampling \(x D\) and outputting \( x,f(x)\). We define the following learning problem in the general learning framework: \(=^{}\{0,1\}\), \(=\), \(=\{D_{f}:fD\) a distribution over \(^{}\}\), and \((D_{f},h)=_{x^{}}[f(x) h(x)]\).

We are interested in statistical query learning which is defined by Kearns (Kea98).

**Definition 6.1**.: A statistical query oracle \(STAT(D_{f},)\) takes as an input a real-valued function \(:X\{0,1\}(0,1)\) and returns an estimate \(v\) such that \(|v-E_{ x,y D_{f}}[(x,y)]|\)(Kea98). We say that an algorithm \(A\) learns a concept class \(\) via statistical queries if for every distribution \(D\) and every function \(f\), for every \(0<<1\), there exists \(\) such that the algorithm \(A\) on input \(\), and \(STAT(D_{f},)\) as an oracle, outputs a hypothesis \(h\) such that \((D_{f},h)\). The concept class is _non-adaptively_ learnable if all the queries made by \(A\) to the statistical query oracle are non-adaptive.

### Replicable PAC Learning Algorithms

Next we state main results of this section. Due to space limitation, all the proofs are in the supplementary material. We first show that any concept class that is learnable with \(d\) non-adpative statistical queries has a \((d+1)\)-list replicable algorithm.

**Theorem 6.2**.: _Let \(\) be a concept class that is learnable with \(d\) non-adaptive statistical queries, then \(\) is \((d+1)\)-list replicably learnable. Furthermore, the sample complexity \(n=n(,)\) of the \((d+1)\)-list replicable algorithm is \(O(}{^{2}})\), where \(\) is the approximation error parameter of each statistical query oracle._

We note that we can simulate a statistical query algorithm that makes \(d\)_adaptive_ queries to get a \(2^{d}\)-list replicable learning algorithm. This can be done by rounding each query to two possible values (the approximation factor increases by 2). The sample complexity of this algorithm will be \(O(})\). Next, we design a certificate replicable algorithm for hypothesis classes that admit statistical query learning algorithms.

**Theorem 6.3**.: _Let \(\) be a concept class that is learnable with \(d\) non-adaptive statistical queries, then \(\) is \(\)-certificate replicably learnable. Furthermore, the sample complexity \(n=n(,)\) of this algorithm is \(O(}{^{2}^{2}})\), where \(\) is the approximation error parameter of each statistical query oracle._

We can also consider the case when the statistical query algorithm makes \(d\) adaptive queries. In this case we get the following theorem. Note that the certificate complexity is close to linear in \(d\) as oppose to logarithmic in the case of non-adaptive queries.

**Theorem 6.4**.: _Let \(\) be a concept class that is learnable with \(d\) adaptive statistical queries, then \(\) is \( d\)-certificate replicably learnable. Furthermore, the sample complexity of this algorithm is \(O(}{^{2}^{2}})\), where \(\) is the approximation error parameter of each statistical query oracle._

### Impossibility Results in the PAC Model

In this section, we establish matching upper and lower bounds on the list complexity for the concept class \(d\)-Threshold in the PAC model with respect to the uniform distribution. In particular, we establish that this learning task admits a \((d+1)\)-list replicable algorithm and does not admit a \(d\)-list replicable algorithm.

**Definition 6.5** (\(d\)-Threshold).: Fix some \(d\). Let \(X=^{d}\). For each value \(^{d}\), let \(h_{}:X\{0,1\}\) be the concept defined as follows: \(h_{}()=1\) if for every \(i[d]\) it holds that \(x_{i} t_{i}\) and \(0\) otherwise. Let \(\) be the hypothesis class consisting of all such threshold concepts: \(=\{h_{^{}}^{d}\}\).

We first observe the impossibility of list-replicable algorithms in the distribution-free PAC model. This follows from known results.

**Observation 6.6**.: _There is no \(k\)-list replicable algorithm (for any \(k\)) for \(d\)-Threshold in the PAC model even when \(d=1\)._

The above observation follows from the works of (ALMM19) and (BLM20). It is known that \(d\)-Threshold has an infinite Littlestone dimension. Suppose it admits \(k\)-list replicable algorithms in the PAC model. This implies that \(d\)-Threshold is globally stable learnable with stability parameter \(1/k\) (Please see (BLM20) for the definition of global stability). The work of (BLM20) showed that any class that is globally stable learnable with a constant stability parameter is differentially private learnable. The work of (ALMM19) showed that if a concept class is differentially private learnable, then it has a finite Littlestone dimension. Putting these results together, we obtain that if \(d\)-Threshold admits \(k\)-list replicable algorithm, then it has a finite Littlestone dimension which is a contradiction.

The above result implies that for every \(k\) and every learning algorithm \(A\), there is _some_ distribution \(_{A}\) such that \(A\) is not \(k\)-list replicable with respect to \(_{A}\). However, a natural question is whether a lower bound holds for a fixed distribution, especially simple distributions such as the uniform distribution. We show that this is indeed the case.

**Theorem 6.7**.: _In the PAC model under the uniform distribution, there is a \(d+1\)-list replicable algorithm for the \(d\)-Threshold. Moreover, for any \(k<d+1\), there does not exist a \(k\)-list replicable algorithm for the concept class \(d\)-Threshold under the uniform distribution. Thus its list complexity is exactly \(d+1\)._

## 7 Conclusions

In this work, we investigated the pressing issue of replicability in machine learning from an algorithmic point of view. We observed that perfect replicability is not achievable and hence considered two natural extensions that capture the degree of (non) replicability: list and certificate replicability. We designed replicable algorithms with a small list, certificate, and sample complexities for the \(d\)-Coin Bias Estimation Problem and the class of problems that can be learned via statistical query algorithms that make non-adaptive statistical queries. We also established certain impossibility results in the PAC model of learning and for \(d\)-Coin Bias Estimation Problem. There are several interesting research directions that emerge from our work. There is a gap in the sample complexities of the list and certificate replicable algorithms with comparable parameters. Is this gap inevitable? Currently, there is an exponential gap in the replicability parameters between hypothesis classes that can be learned via non-adaptive and adaptive statistical queries. Is this gap necessary? A generic question is to explore the trade-offs between the sample complexities, list complexity, certificate complexities, adaptivity, and nonadaptivity.

## 8 Acknowledgements

We thank the NeurIPS 2023 reviewers for their comments that improved the presentation of the paper. We especially acknowledge reviewer U7Lz for very detailed and insightful comments. We thank an anonymous researcher for pointing out Observation 6.6. We thank Jamie Radcliffe for informative discussions on topics related to this work. We thank authors of (CMY23) for informing us about their work and helpful discussions. Part of this work is supported by NSF grants 2130536 and 2130608. Part of the work was done during Pavan and Vinodchandran's visit to Simons Institute for the Theory of Computing. Part of Peter's work was done while at Ben-Gurion University of Negev.