# Enhancing LLM's Cognition via Structurization

Kai Liu\({}^{1,2}\)

Zhihang Fu\({}^{2}\)

Work done during Kai Liu's research internship at Alibaba Cloud. Email: kail@zju.edu.cn.

 Chao Chen\({}^{2}\)

Wei Zhang\({}^{1}\)

Work done during Kai Liu's research internship at Alibaba Cloud. Email: kail@zju.edu.cn.

 Rongxin Jiang\({}^{1}\)

Work done during Kai Liu's research internship at Alibaba Cloud. Email: kail@zju.edu.cn.

 Fan Zhou\({}^{1}\)

Yaowu Chen\({}^{1}\)

Yue Wu\({}^{2}\)

Jieping Ye\({}^{2}\)

Zhejiang University, \({}^{2}\)Alibaba Cloud

###### Abstract

When reading long-form text, human cognition is complex and structurized. While large language models (LLMs) process input contexts through a causal and sequential perspective, this approach can potentially limit their ability to handle intricate and complex inputs effectively. To enhance LLM's cognition capability, this paper presents a novel concept of context _structurization_. Specifically, we transform the plain, unordered contextual sentences into well-ordered and hierarchically structuralized elements. By doing so, LLMs can better grasp intricate and extended contexts through precise attention and information-seeking along the organized structures. Extensive evaluations are conducted across various model architectures and sizes (including a series of auto-regressive LLMs as well as BERT-like masking models) on a diverse set of NLP tasks (_e.g._, context-based question-answering, exhaustive hallucination evaluation, and passage-level dense retrieval). Empirical results show consistent and significant performance gains afforded by a single-round structurization. In particular, we boost the open-sourced LLaMA2-70B model to achieve comparable performance against GPT-3.5-Turbo as the hallucination evaluator. Besides, we show the feasibility of distilling advanced LLMs' language processing abilities to a smaller yet effective StruXGPT-7B to execute structurization, addressing the practicality of our approach. Code is available at https://github.com/alibaba/struxgpt.

## 1 Introduction

Large language models (LLMs) have emerged with remarkable language capabilities , yet remain at a discernible distance from human-level intelligence, especially when handling long-form, sophisticated contexts as inputs . Scaling up the model size has significant benefits for boosting context-comprehension and instruction-following abilities for LLMs . However, it is generally resource-intensive on both model training and inference. This paper presents another perspective on enhancing LLMs' cognition capability without altering the models: context _structurization_.

The idea of structurization is motivated by neurocognitive science . In human cognition, as indicated in Fig. 1, sophisticated text sequences will be processed and consolidated into a structured knowledge tree, with factual elements well-organized hierarchically . This process is defined as _structurization_. People can precisely search information from general concepts to specific details and make connections and comparisons along structures. We thus aim to transform plain texts into structurized inputs, helping LLMs recognize and understand contexts in a human manner .

As Fig. 1 illustrates, input sequences are reorganized in a simple but generic three-layer structure: _scope_, _aspects_, and _descriptions_. The scope summarizes the topic and contents, unfolding into several main aspects with corresponding detailed descriptions. The structurized results can be freelyassembled into various natural language forms, depending on the specific downstream tasks. Fig. 2 provides an exemplar of our overall framework: after structurizing and reassembling the vanilla context to highlight its scope and aspects of data imbalance handling techniques, LLMs become able to grasp the target information about the dynamic weighting strategy and generate reliable responses.

We first execute the structurization by prompting advanced commercial LLMs (_e.g._, GPT-3.5-Turbo1 or Qwen-Max2) with a few examples, and then collect the results to train a smaller 7B-parameter LLAMA2  or Qwen  model as our StruXGPT. This is motivated by , where the fundamental syntactic processing ability from giant LLMs is distilled into a responsive and affordable StruXGPT-7B. Comprehensive evaluations indicate that StruXGPT-7B inherits 97% of the structurization ability from the teacher model, showing our method's feasibility.

Empirical experiments are conducted on a diverse set of NLP tasks (_e.g._, context-based question-answering, exhaustive hallucination evaluation, and passage-level dense retrieval). The results show that with a single-turn structurization by our StruXGPT, the cognition performance of vanilla large language models witnesses consistent improvements regardless of the model architecture and size variation. In particular, we boost the open-sourced LLaMA2-70B  to achieve comparable performance against GPT-3.5-Turbo as a hallucination evaluator, and demonstrate the compatibility with other advanced prompting techniques, such as CoT . We hope this paper can bring new insights to the community on building a more powerful and critical language model with human cognition.

Our contribution can be summarized as follows:

* We propose the concept of structurization, in order to enhance LLM's cognition capability without altering the models themselves.
* We present the feasibility of distilling the structurization ability from giant commercial LLMs into a responsive and affordable StruXGPT-7B model, making our approach practical.
* With structurization, we empirically demonstrate the consistent cognition enhancement for various LLMs across model architecture and size variation on diverse NLP tasks.

## 2 Related Work

**Large language models (LLMs)**. LLMs' _emergent abilities_ has recently received extensive attention in the literature [6; 61; 9; 53; 23; 1], which are found closely related to the scaling law . When the scale reaches a certain level, the performance on complex NLP tasks significantly rises due to the superior _in-context learning_, _instruction following_, and _reasoning_ abilities [71; 47]. Numerous efforts have been made to boost the model capacity with training and prompting strategies [37; 38; 59; 14], and this paper presents a new perspective, _context structurization_, to encourage LLMs to perceive, recognize, and communicate like humans [55; 71], without altering the model themselves.

**Context augmentation**. Recent studies have proposed several context augmentation methods to enhance LLM's cognition ability [59; 41] on when taking the long-form context (with thousands of tokens) as inputs [3; 36; 30]. Specifically, aspect-based summarization (ABS) and query-based summarization (QBS) [64; 69] are designed to extract important information from lengthy text data as well, but they require pre-defined or user-input aspect/query lists to conduct targeted summarization, and the detailed information will be inevitably lost during the summarization process. In contrast, the

Figure 1: **Structured cognition on sequential contexts**. Humans may easily identify a given passage’s topic/scope, break down the text sentences into several aspect points with detailed descriptions, and form a tree-like knowledge structure.

paper develops context-wise structurization to highlight the knowledge structure, running a single-turn structurization on the context to enhance LLMs' cognition abilities on a diverse set of NLP tasks.

**Structurization**. In the conventional NLP literature, the term _structured data_ usually refers to entity-relation-entity triplets or properties extracted from plain texts, which are utilized to construct knowledge graphs or databases with special data formats or schemas . On the contrary, the _structurization_ in this paper does not focus on entity-level information extraction and aggregation. Instead, it suggests reorganizing the input sentences into a three-layer structure based on their inner linguistic relations. Similar to discourse analysis and constituency parsing , the main purpose of our structurization is capturing the dependencies and relations of the elements within specific long-form text inputs, so as to enhance LLMs' cognition of the knowledge structure and relations.

**Knowledge Distillation**. In the era of large language model learning, distilling specific knowledge from giant LLMs' outputs has commonly been used to derive a more affordable but still powerful language model . Previous attempts, such as Standford Alpaca  and Vicuna , show the feasibility of collecting instruction-response pairs from GPT-3.5 or GPT-4 to train a smaller fundamental  or domain-specific (_e.g._, with reasoning  or coding  skills) language models. Our work also distills the structurization capability from the giant Qwen-Max model to a smaller yet effective StruXGPT-7B model, with extensive evaluations to show the efficiency and efficacy.

## 3 Structurization

The substantial purpose of structurization is to mimic the human cognition process and transform plain, sequential text sentences into a well-organized, hierarchical knowledge structure. Inspired by the linguistic discourse analysis , this paper develops a three-layer hierarchy exemplar to present the cognition/knowledge structure, as introduced in Fig. 1:

1. _Scope_ summarizes the topic and boundary of the textual context. It outlines the central issues of knowledge throughout the text and the scope of the discussion that will be covered.
2. _Aspect_ further subdivides the input context into several parts. It presents the aspects or dimensions that must be considered to fully understand the topic and scope.
3. _Description_ is the most specific and detailed layer. It provides in-depth descriptions and analyses to support each aspect of the context scope.

This generic three-layer structure is derived for efficacy and efficiency in dealing with diverse textual inputs. There might be some elaborated structures (such as a knowledge mindmap ) to better deconstruct specific text sources, but the difficulty and complexity of defining, extracting, and utilizing those structures to aid in practical problems are dramatically increased. We leave this exploration in our future work.

Next, we will present how to implement effective structurization with minimal cost in Sec. 3.1, and demonstrate the utilization of the structurization results to enhance LLMs' cognition abilities in different downstream tasks in Sec. 3.2.

Figure 2: **Framework overview.** When instructed to generate responses based on vanilla long-form and sophisticated contexts, LLMs often lose their focus and give unreliable answers due to their limited cognition capability. In contrast, we _structurize_ the vanilla context by using our StruXGPT to identify its main scope and aspect points, facilitating the original LLMs to comprehend the context and generate accurate responses.

### Efficient Implementation of Structurization

We have explored two approaches to execute the structurization process by leveraging the extraordinary capability of large language models: few-shot prompting on commercial LLMs and direct instructing our developed StruXGPT models.

**Few-shot commercial LLM.** In the initial stage, we use two in-context examples to query the commercial Qwen-Max model to structurize the input corpus, since it shows promising instruction-following and textual analyzing capability with over 200B parameters 3. Here is a simplified example of prompting structurization in Fig. 3, and the full template is displayed in Appendix E.1.

However, commercial LLMs are usually slow and expensive, and sending user data to LLM APIs may cause privacy and security problems due to information leakage. Thus, we train a smaller 7b-parameter model (_e.g._, LLMaA2  or Qwen ) to inherit the structurization ability from giant commercial LLMs, which can be deployed locally for efficiency and privacy.

**Fine-tuned StruXGPT.** Our tailored model is named by StruXGPT, where _Stru_ is the abbreviation of structurization, and \(X\) implies we do not specify the model architecture. We carefully curate 22,547 raw data pieces from Wikipedia4 and CAMEL-AI dataset  to ensure diversity, and collect the structurized results from Qwen-Max to train our StruXGPT via supervised fine-tuning (SFT). From the collected samples, 200 are utilized for evaluation (including human verification), and the remaining training samples are adopted to distill the structurization capability from Qwen-Max to our StruXGPT-7B. It is practical since the structurization only relies on fundamental syntactic understanding and processing ability, which has already been learned from the large-scale corpus. We merely teach the 7B-parameter models how to reorganize the input text via SFT, without introducing new memorizing or creative overloads. In addition, the ultimate StruXGPT does not require few-shot examples, and it reduces the input lengths for further efficiency. The training details are described in Appendix A.1.

### Effective Utilization of Structurization

The identified knowledge structure (_i.e._, the scope, aspect, and description hierarchy) from the raw context is initially parsed in JSON format and unsuitable for direct inputs to handle massive lengthy elements. Therefore, we use a unified template to transform the structured data back into natural language sentences as models' inputs to fit their intrinsic processing patterns, as LLMs are pre-trained and aligned with mostly natural language data. Concurrently, to preserve and highlight the knowledge structure, we harness specific linguistic markers to signal hierarchy and relationships among concept elements, such as numbered lists for order, bullet points for categorization, and indentation to depict nesting levels of information. Fig. 4 showcases some typical examples.

The first row of Fig. 4 provides a unified template to transform structurization results into natural languages. The top-level hierarchy _scope_ is presented as a standalone sentence, serving as the introduction to the structured context and highlighted with bold markers. Subsequently, the secondary _aspect_ are organized with numerical markers and bolded, attaching with its corresponding tertiary _descriptions_ through subclauses or separate sentences. This method not only signifies the rank and relation of each piece of information relative to others but also provides clear, navigable paths for the LLMs to follow and process the information efficiently (_e.g._, when examining the long-form comprehension capability). Moreover, the second row of Fig. 4 introduces another variation for transformation, where each _description_ elements are further broken down and enumerated for the delineation of fine-grained details, making it easier for language models to discern and retain specific nuances associated with each _aspect_ (_e.g._, when examining the hallucination detection capability).

Figure 3: Prompt template for structurization.

After transformation, the linguistic input retains its structured knowledge through systematic cues but is presented in a comprehensible manner for LLMs. This not only facilitates an enhanced understanding and interaction with complex data but also enables the models to leverage their existing natural language capabilities to generate more accurate and contextually relevant responses.

## 4 Experiments

In this section, we conduct extensive experiments on a series of downstream NLP tasks to comprehensively demonstrate the efficacy of structurization. We hope the results can bring new insights to enhancing LLM's cognition via structurization, regardless of model architecture and size variation.

Three representative natural language understanding and processing tasks are investigated, including context-based question-answering Sec. 4.1, exhaustive hallucination evaluation Sec. 4.2, and passage-level dense retrieval Sec. 4.3. When instructing tested LLMs to perform target tasks, we merely structurize the vanilla textual inputs, transform the results back into natural languages, and immediately feed the results to LLMs to make responses. The tested LLMs themselves are not fine-tuned on structurized data corpus. We adopt our StruXGPT-7B model to execute structurization in all experiments in this section. The evaluation and ablation of StruXGPT model are demonstrated in Sec. 4.4, Sec. 4.5, and Sec. 4.6, and more comparison with related augmentation-based methods can be found in Appendix B.3 and Appendix B.5.

### Application on Context-based Question-Answering

Question-answering based on a long-form context is an emerging research area within QA, which requires large language models to precisely seek the target information and generate reliable responses to the question [3; 30]. It is an immediate measure of LLM's cognition ability to handle intricate and sophisticated contexts. In this section, we comprehensively evaluate how structurization boosts QA ability on seven datasets from the LongBench benchmark  with a variety of LLMs to examine.

**Dataset setup.** LongBench  is a multi-task benchmark tailored for long context understanding evaluation, composed of 6 major task categories and 21 different tasks. To focus on the investigation of context structurization, we choose 7 subsets from LongBench across single-document QA, multi-document QA, and synthetic QA tasks in English, and the remaining Chinese subsets or code-orientated tasks are eliminated. Except for the _MultiFieldQA_ subset with 150 testing samples, each subset contains 200 pieces of _context-question-answer_ triplets to evaluate, resulting in 1,350 samples to test in total. Each subset has a 4K-18K context length on average. If the context length exceeds an LLM's window size, we truncate from the middle of the text and preserve information at the beginning and end, as suggested by LongBench. Detailed dataset description is displayed in Appendix B.2.

Figure 4: **Left**: templates to transform structurization results into natural languages, with special linguistic markers to preserve and highlight the extracted knowledge structure. **Right**: transformed context examples with clear information structure for long-form reading comprehension (upper) and hallucination detection (lower) tasks.

**Evaluated models.** Following , we evaluate three representative large language models on long context comprehension ability: LLaMA2-7B-4k , Qwen-7B-8k , and ChatGLM3-6B-32k , and extend the larger LLaMA2-13B-4k  model. The four LLMs have a relatively similar parameter capacity with different model architectures and window sizes. All the models to examine are pre-trained chat models, and we just employ our StruXGPT to structurize the input contexts to enhance those LLMs' cognition capabilities. To ensure reproducibility and reduce uncertainty, greedy search is adopted during LLM's decoding process when generating responses. The accuracy between models' responses and ground-truth answers is measured by ROUGE-L and F1-score.

**Experimental results.** Tab. 1 suggests structurized contexts bring consistent improvements on almost all 3 tasks and 7 subsets across the model architectures and window sizes. Specifically, structurization leads to relatively greater improvement for the MultiDoc-QA subtask (with a 3% performance gain on average), revealing the potential promotion of LLMs' multi-hop reasoning abilities. Despite the negligible decline on the _Musique_ subset (see Appendix B.2 for analysis), the advanced ChatGLM3-6B-32k is also boosted, showing structurization's efficacy for powerful models.

**Comparison with other baselines.** To further evaluate our structurization augmentation, we compare our method against the typical summarization-based methods that also employ LLMs for context augmentation. The results are presented in Appendix B.3, which further demonstrates our superiority in highlighting the knowledge structure without loss of key information.

**Investigating structurization from the attention perspective.** Fig. 5 reveals how structurization can aid LLM's cognition from the attention perspective. In particular, we compare the attention maps for the same tested LLaMA2-7B model with different contexts as input. At the position of the model's first token prediction, we average the attention maps across the 32 attention heads for each layer of LLaMA's last 16 layers , and visualize the attention scores in Fig. 5. Specifically, when handling vanilla contexts, LLaMA2-7B loses its focus on the target information of the _experts_. On the contrary, the structurized context clearly presents the content structure of the introduced _PrivacyQA dataset_, and LLaMA2-7B immediately grasps the target aspect and its detailed descriptions of _experts with legal training_. In this way, LLM's cognition capability is successfully enhanced via context structurization.

    &  &  &  &  \\    & Qasper & MFQA & HpQA & & & & & & \\  LLaMA2-7B-4k & 19.5 & 34.6 & 30.4 & 27.3 & 10.7 & 2.0 & 9.0 & 19.1 \\ **+StruXGPT (ours)** & **23.1** & **35.9** & **32.7** & **29.9** & **13.4** & **3.0** & **12.0** & **21.4** \\  LLaMA2-13B-4k & 26.9 & 34.5 & 38.9 & 34.4 & 13.9 & 2.0 & 10.0 & 22.9 \\ **+StruXGPT (ours)** & **28.5** & **35.3** & **40.0** & **39.4** & **18.9** & **3.5** & **16.0** & **26.0** \\  Qwen-7B-8k & 19.6 & 34.1 & 20.4 & 12.5 & 7.5 & 2.0 & 15.5 & 15.9 \\ **+StruXGPT (ours)** & **22.3** & **37.0** & **25.4** & **14.7** & **8.2** & **2.5** & **17.5** & **18.2** \\  ChatGLM3-6B-32k & 43.3 & 51.7 & 54.4 & 44.9 & **40.4** & 2.0 & 99.0 & 47.9 \\ **+StruXGPT (ours)** & **44.6** & **52.1** & **57.2** & **47.6** & 40.1 & **4.0** & **99.5** & **49.3** \\   

Table 1: **Performance on LongBench datasets.** The indicator +_StruXGPT_ means the data fed into LLMs is structurized by our StruXGPT-7B, while the evaluated LLMs themselves are unchanged. The results are acquired by LongBench’s official protocol. Higher is better.

Figure 5: Attention maps on vanilla and structuralized contexts for the same LLaMA2-7B. The sample comes from the QAsper subset.

### Application on Exhaustive Hallucination Evaluation

Hallucination has raised wide attention in the community [70; 56]. In general, evaluating hallucinations involves verifying atomic claims against supportive materials (_e.g._, Wikipedia passages [66; 42]), yet even advanced GPT-3.5-Turbo and GPT-4 cannot always accurately make the judge, as LLMs-evaluators often struggle to extract relevant information due to the complexity of passage contexts. We introduce how to improve LLM evaluators' assessing ability by context structurization below.

**Dataset setup.** AttrScore  and FactScore  datasets are adopted for evaluation. We take the _AttrEvalGenSearch_ test set with 245 examples from AttrScore, where each example comprises a statement and its reference passage, and is annotated by _Attributable_ (abbreviated as _Attr_), _Contradictory_ (abbreviated as _ConTRA._), and _Extrapolatory_ (abbreviated as _Extra._). FactScore collected 4,726 atomic claims/statements of people biographies generated by InstructGPT (abbreviated as InstGPT), 5,426 by ChatGPT, and 5,888 by PerplexityAI (abbreviated as PPLAI). For each input sample, we leverage StruXGPT to structurize the reference to identify its main aspects and detailed descriptions. The numerically ordered structure is preserved, as displayed in Fig. A3, since we explicitly ask the evaluator to check the information along the structure for judgment.

**Evaluated models.** We mainly investigate the open-sourced LLaMA2-7B and LLaMA2-70B models as the LLM-evaluator, and also explore the integration with the close-source GPT-3.5-Turbo-1106  via API access. The main results are presented in Tab. 2. We also report the results with Qwen models on AttrScore and FactScore and the incorporation to more powerful GPT-4 in Appendix B.4.

**Experimental results.** According to Tab. 2, our structurization brings significant enhancements to both LLaMA2-7B and 70B models (for 6.4% and 4.3% on average, respectively). And the powerful GPT-3.5 model also gains 4.1% (from 58.0% to 62.1%). Furthermore, we incorporate the Chain-of-Thought (CoT) technique into the prompt template to clarify the evaluation steps (such as _Carefully read the claim and double-check the answer._) (denoted as "GPT-3.5-1106 + CoT"). After that, the GPT-3.5 model immediately obtains an improvement of 4.0% (from 58.0% to 62.0%). Consequently, on top of the advanced CoT prompt, our method further enhances the model to a higher accuracy of 65.4% on average, demonstrating our method's compatibility with advanced prompting techniques.

### Application on Passage-level Dense Retrieval

Retrieval-augmented generation (RAG) has been empirically validated to significantly bolster LLM's domain knowledge [29; 62], where precise document retrieval plays a vital role. We now investigate how structurization can facilitate dense retrieval for BERT-like masking language models.

**Dataset setup.** BEIR dataset  is a popular benchmark for evaluating dense retrievers' zero-shot effectiveness [39; 33], where retrievers are trained on MS MARCO's passage-retrieval training split  while directly tested on the BEIR benchmark without finetuning. We focus on our evaluation of the 5 subsets from BEIR _i.e._, NFCorpus, FiQA, ArguAna, SciDocs, and SciFact.

**Evaluated models.** BERT , SimLM , and coCondenser  are chosen for evaluation, since they achieve state-of-the-art performance on MS MARCO's development split. To convert the structurized passages from our StruXGPT into natural languages, we eliminate the numerical indicators (such as "1.", "1.1", _etc._) and attach the description statements in the third layer with their aspects. Fig. A3 presents an example. We only structurize passages to enhance retrievers' cognition, and the queries remain unchanged. Following the literature, nDCG@10 results are reported in Tab. 3.

   Evaluator & _Attr._ & _Contra._ & _Extra._ & **Average** \\  GPT-4 & 87.3 & 45.0 & 89.6 & 74.0 \\ GPT-3.5-Turbo & 61.2 & 20.6 & 53.3 & 45.0 \\ Alpaca-13B & 50.6 & 6.1 & 19.3 & 25.3 \\ Alpaca-7B & 50.7 & 8.6 & 3.6 & 21.0 \\  LLaMA2-7B & 51.5 & 9.1 & 20.1 & 26.9 \\
**+StruXGPT (ours)** & **54.5** & **15.0** & **30.4** & **33.3** \\  LLaMA2-70B & 70.9 & 31.1 & 74.1 & 58.7 \\
**+StruXGPT (ours)** & **75.4** & **35.6** & **78.1** & **63.0** \\  GPT-3.5-1106 & 72.0 & 30.4 & 71.7 & 58.0 \\
**+StruXGPT (ours)** & **77.1** & **31.8** & **77.4** & **62.1** \\  GPT-3.5-1106 + CoT & 76.4 & 35.3 & 74.4 & 62.0 \\
**+StruXGPT (ours)** & **78.9** & **42.9** & **74.5** & **65.4** \\   

Table 2: **Hallucination Evaluation on AttrScore.**

**Experimental results.** Structurization boosts all three retrievers on most subsets, yielding a maximum performance improvement of 4.5% on SciFact for SimLM. The results suggest that structurization not only augments decoder-only generative LLMs with explosive parameters (at least 7B), but also benefits encoder-decoder masked language models with constrained parameters (around 110M). It implies that the patterning of linguistic and semantic structurization may be a fundamental mechanism for enhancing language models, transcending distinctions in their architectural design and scale.

### Evaluation of the Structurization Approach Itself

In this section, we assess various structurization methods through exhaustive experiments on five approaches, including prompting Qwen-max with few-shot exemplars (serves as our teacher model), few-shot Qwen-7B and LLaMA2-7B pre-trained chat models, and our fine-tuned Qwen-7B and LLaMA2-7B (student) models. As introduced in Sec. 3.1, we use 200 validation cases and have the five models generate 1,000 structurized outputs for analysis.

A good structurization should effectively deconstruct the vanilla input text to clearly identify its knowledge structure, so as to facilitate LLM's cognition. The resulting content should be faithful to the original texts, neither dismiss the factual information nor fabricate statements or opinions that do not exist. To this end, we revise four evaluation metrics to investigate the efficacy of different structurization approaches, and the results are displayed in Tab. 4.

**Lexical evaluation (LexicalEval).** We first leverage the widely-used ROUGE-L [34; 35; 25] to assess recall and precision between structured content and original text. However, lexical metrics from the methods, ranging from 0.6 to 0.7, inadequately reflect structurization quality where LLMs will paraphrase the words but lexical scores miss the semantic consistency. For instance, a statement pair "They adopt ROUGE" and "ROUGE is adopted" only receives a 0.33 f1-score for ROUGE-L. Therefore, a crucial human evaluation is developed to obtain a trustworthy conclusion.

**Human evaluation (HumanEval).** We recruited 17 well-trained natural language annotators from the PAI-iTAG platform5 to evaluate the structurization quality on a 0-5 scale across three dimensions: completeness (ensuring no loss of information from the original text), factuality (accurate three-layer deconstruction), and anti-hallucination (avoiding fabricated content). As annotating structurization

    &  &  &  &  &  \\    & & recall? & precision? & & & & & & \\   & Qwen-max & 0.63 & 0.68 & **4.58** & **4.49** & **4.57** & **+3.3** & **0.31** \\  & Qwen-7B & 0.56 & 0.67 & 3.77 & 3.67 & 3.96 & -0.1 & 0.22 \\  & LLaMA2-7B & 0.61 & 0.72 & 4.09 & 3.98 & 4.12 & +0.3 & 0.24 \\   & StruXGPT-7B-Q & 0.63 & 0.67 & **4.41** & 4.36 & **4.48** & **+3.6** & **0.31** \\  & StruXGPT-7B-L & 0.61 & 0.66 & 4.37 & **4.38** & 4.36 & +2.8 & 0.30 \\   

Table 4: **Comprehensive comparison on structurization approaches.**

   Retriever & NFCorpus & FiQA & ArguAna & SciDocs & SciFact & **Average** \\  BERT & 24.4 & 23.7 & 36.2 & 11.4 & **50.8** & 29.3 \\
**+StruXGPT (ours)** & **24.4** & **24.9** & **40.0** & **11.4** & 50.7 & **30.3** \\  SimLM & 22.2 & 17.3 & 34.2 & 11.7 & 48.2 & 26.7 \\
**+StruXGPT (ours)** & **22.9** & **19.8** & **34.6** & **11.7** & **52.7** & **28.3** \\  coCondenser & 28.2 & 22.8 & 40.5 & 12.8 & 55.6 & 32.0 \\
**+StruXGPT (ours)** & **28.8** & **23.5** & **43.4** & **13.1** & **56.8** & **33.1** \\   

Table 3: **Performance on BEIR subsets.** Retrievers are trained with MS MARCO corpus and directly evaluated on BEIR without fine-tuning.

only involves linguistic and syntactic level judgments, annotators do not need professional expertise to check the information of a given text itself. The detailed evaluation criteria are displayed in Appendix A.3, and we report the labeling results in Tab. 4.

The commercial Qwen-max shows a promising instruction-following and in-context learning ability, generally scoring 4.5 at the three dimensions. However, the pre-trained 7B models from Qwen and LLaMA2 immediately decline the scores to below 4.0, as they struggle to understand the instruction to build the three-layer structure and tend to hallucinate responses due to the limited model capacity. More structurization examples can be found in Appendix E.2. Notably, the fine-tuned StruXGPT-7B-Q(wen) and StruXGPT-7B-L(LaMA2) both obtain a 4.35 - 4.45 score on average. They inherit 97% of structurization capability from the Qwen-max teacher model, evidencing the effectiveness of training a specialized 7B-parameter model for structurization to aid in efficiency and privacy.

**Evaluation with downstream application (AppEval).** Since our main motivation is to utilize structurization to enhance LLM's cognition, a further evaluation is conducted to investigate those different structurization methods. Specifically, we compare how much improvement (\(\)) those methods can bring to downstream natural language processing applications. On the Qasper subset  from LongBench , we instruct an independent LLaMA2-7B chat model for reading comprehension with long-context structurized by different approaches. LLaMA2-7B receives a 19.6 F1-score for QA accuracy when taking the vanilla context as input, which serves as the baseline performance.

The evaluation results are displayed in Tab. 4, which are consistent with the human evaluation presented above. In particular, the few-shot Qwen-max achieves an over 3% improvement in answer quality, while the pre-trained 7B-parameter chat models fail to generate validated structurizations. Meanwhile, our fine-tuned StruXGPT-7B-LLaMA and StruXGPT-7B-Qwen models bring comparable enhancements against the few-shot Qwen-max, emphasizing the efficacy of distilling the structurization ability from giant teacher models to a more responsive and affordable student model.

**Evaluation with semantic embedding (SemEval).** At last, we explore the structurization quality evaluation in the semantic embedding perspective, as a supplementary to lexical evaluation. Following Zhang et al. , we calculate the semantic similarity between original and structurized contents with the embedding similarities, and the results in Tab. 4 show consistent measure against HumanEval and AppEval with a much lower cost. Hence, BERTScore  can be further leveraged as an effective and efficient quality-assessment tool for training-data filtering and structurization quality evaluation to derive a better StruXGPT model. Sec. 4.6 presents some preliminary investigations.

Through the comprehensive evaluation of three protocols, we demonstrate the feasibility and efficacy of training a specialized StruXGPT. It is more resource-friendly to deploy for efficiency and privacy, meanwhile inheriting 97% of the ability from giant teacher models to perform structurization.

### Ablation Studies on StruXGPT's Establishment

This section studies two major factors of training a StruXGPT model: data quality and model capacity.

**Using two few-shot examples is sufficient to collect high-quality training data.** In this work, we choose 2 in-context examples to prompt commercial LLMs (as a teacher) to generate data pairs of raw/structurized texts to train our StruXGPT-7B model (as a student). We think it is enough for teacher models to understand the structurization process and generate valid training samples, as the 2 examples respectively describe the 2 most common types of real-world text (_i.e._, with/without existing indicators like "1.", "2.", etc), which is displayed in Appendix E.2.

To further verify it, we investigate the number of in-context examples with two evaluation protocols (as in Tab. 4): AppEval (an improvement on Qasper subset with context structurization) and BERTScore (semantic similarity with raw and structurized texts in the validation set). We also report the error rate when parsing structurization results from the teacher model's outputs (denoted as "FormatError").

According to Tab. 5, 1-shot is apparently insufficient to illustrate structurization, while 2- and 3-shot achieve comparable structurization quality under AppEval and BERTScore. Notably, 3-shot receives a 2% lower FormatError than 2-shot, in trade for the increased inference cost (because of increased few-shot samples). We argue that the 2% gap (around 400 samples) does not make a difference for the final StruXGPT training, which can be verified in Appendix A.2. Therefore, we recommend users to apply 3- or even more shots when prompting teacher LLMs if available, otherwise 2-shot is also a good choice to balance the inference cost and structurization quality.

**StruXGPT-7B balances parameter capacity and structurization quality.** As Qwen  provides a series of models varying sizes, in Tab. 6, we implemented StruXGPT on Qwen-1.8B/7B/14B respectively to investigate the relationship between model capacity and structurization quality.

Compared with the 7B model capacity, the smaller 1.8B model, despite its positive enhancement on downstream applications, shows slight inferiority in both AppEval (+2.7 _v.s._ +3.6) and BERTScore (0.299 _v.s._ 0.313), and presents 5% error rate when parsing structurization results. On the other hand, the 14B model brings further improvement to BERTScore, (the structurization content is relatively more faithful to original texts), but the boost on AppEval is insignificant. Hence, the 7B model is a good trade-off between model capacity (training/inference efficiency) and structurization quality.

### Utilization of Structurization Quality Assessment

As the structurization quality simultaneously influences StruXGPT's training performance and application improvements, this section investigates the quality assessment tool BERTScore (as discussed in Sec. 4.2) on StruXGPT's training and inference stages, respectively.

On one hand, as the training data quality determines StruXGPT's upper bound, we statistic the BERTScore of the 22K training entries, and around 94.45% raw/structurized text pairs present positive scores (normalized by the baseline score of 0.83, and a positive BERTScore presents a benign similarity), demonstrating the high quality of our training data. Consequently, we eliminated around 5% of data with negative scores and trained another StruXGPT model, and the results in Tab. 7 indicate this part of data does not affect the final performance. According to Appendix A.2, data quantity may play a vital role in further improving our StruXGPT.

On the other hand, since poor structurization results can lead to suboptimal application performance, we statistic the enhancement variance in the Qasper subset from LongBench  in Tab. 8 for structurized context inputs. Our method merely causes degradation on 3.5% of samples (with relatively lower structurization quality), but ultimately receives a +3.6 improvement overall test samples. Furthermore, we filter out the structurization results with a low BERTScore (_e.g._, \(<\)0.05) and take back the original context as input. In this way, the degradation can be alleviated (from 3.5% to 3.0%), further improving the final enhancement to +3.7. The lower bound of our StruXGPT can thus be ensured.

## 5 Conclusion and Discussion

This paper presents a novel concept of context _structurization_ to enhance LLM's cognition capability. Extensive evaluations of various representative NLP tasks reveal the consistent enhancement across language model's architectural designs and capacity scales. We demonstrate the feasibility of distilling the structurization ability from giant commercial LLMs into a responsive and private StruXGPT-7B model, addressing the practicality problem. The limitation and future work are discussed in Appendix C. We hope this paper can bring new insights into how to build a more powerful and reliable language model with human cognition and intelligence.

   StruXGPT & AppEval & BERTScore & FormatError \\  Qwen-1.8B & +2.7 & 0.299 & 5.0\% \\ Qwen-7B & +3.6 & 0.313 & **0.0\%** \\ Qwen-14B & **+3.8** & **0.323** & **0.0\%** \\   

Table 6: **Parameter capacity of StruXGPT.**

   Training Data & AppEval & BERTScore \\  vanilla & **+3.6** & 0.313 \\ filtered & +3.4 & **0.316** \\   

Table 7: **Training data filtering.**

   StruXGPT & AppEval & BERTScore & FormatError \\  Qwen-1.8B & +2.7 & 0.299 & 5.0\% \\ Qwen-7B & +3.6 & 0.313 & **0.0\%** \\ Qwen-14B & **+3.8** & **0.323** & **0.0\%** \\   

Table 5: **Number of few-shot examples.**