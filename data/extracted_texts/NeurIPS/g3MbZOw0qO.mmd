# To Learn or Not to Learn, That is the Question

-- A Feature-Task Dual Learning Model

of Perceptual Learning

Xiao Liu

Muyang Lyu

Cong Yu

These authors contributed equally to this work and should be considered co-corresponding authors.

Si Wu

###### Abstract

Perceptual learning refers to the practices through which participants learn to improve their performance in perceiving sensory stimuli. Two seemingly conflicting phenomena of specificity and transfer have been widely observed in perceptual learning. Here, we propose a dual-learning model to reconcile these two phenomena. The model consists of two learning processes. One is task-based learning, which is fast and enables the brain to adapt to a task rapidly by using existing feature representations. The other is feature-based learning, which is slow and enables the brain to improve feature representations to match the statistical change of the environment. Associated with different training paradigms, the interactions between these two learning processes induce the rich phenomena of perceptual learning. Specifically, in the training paradigm where the same stimulus condition is presented excessively, feature-based learning is triggered, which incurs specificity, while in the paradigm where the stimulus condition varies during the training, task-based learning dominates to induce the transfer effect. As the number of training sessions under the same stimulus condition increases, a transition from transfer to specificity occurs. We demonstrate that the dual-learning model can account for both the specificity and transfer phenomena observed in classical psychophysical experiments. We hope that this study gives us insight into understanding how the brain balances the accomplishment of a new task and the consumption of learning effort.

## 1 Introduction

Perceptual learning refers to the practices through which human participants learn to improve their performances of perceiving sensory stimuli . Perceptual learning has been widely used as a research paradigm to ascertain the learning strategies in the brain. Over the years, two seemingly contradictory phenomena have been widely found in perceptual learning. One is specificity, referring to that after learning, the improved performance of participants is restricted to the trained location or the trained feature of the stimulus . The other is transfer, referring to that after learning, the improved performance is transferable to untrained locations or untrained features of the stimulus . In early experiments in which participants were typically trained excessively under the same stimulus condition (e.g., either at the same retinal location or presenting the same stimulus feature), specificity was predominantly found, and stimulus features used in experiments include contrast , orientation , spatial frequency , motion direction , and retinal location . Thus, once in a while, specificity was regarded as a hallmark distinguishing perceptual learning from other learning types . Later on, enriched training paradigms were used, and it was found that perceptual learning can also exhibit the dominating transfer effect. For instances, by manipulating the task difficulty , the training intensity , or the training protocol , the originally observed specificity-dominating effect become transfer-dominating.

Related works.A large volume of computational models has been proposed in the literature to unveil the mechanism of perceptual learning. Since specificity was predominantly reported in early experiments, early computational models mainly focused on exploring the neural mechanism underlying specificity. For instance, Poggio et al. proposed the hyper basis function model (HyperBF) , which considers that the enhanced perception performance comes from the changes of basis functions or connection weights of neurons; Teich and Qian proposed a model which considers that the enhanced performance comes from the changes of tuning curves of low-level neurons ; Petrov et al. proposed the reweighting model, which considers that the enhanced performance comes from the read-out weights from feature representations to decision neurons . All these models _implicitly_ assume that perceptual learning only incurs local changes in the network, and hence, the learning effect is localized and not transferable to other parts of the neural system needed for processing untrained conditions. Later on, motivated by the observation of transfer, new computational models focusing on the transfer mechanism were proposed. For examples, Dosher et al. refined their reweighting model by including an extra layer with network-wide connections to implement translation-invariant feature representation, which achieves a certain level of transfer effect ; Solgi et al. introduced an extra off-line learning procedure which generalizes the local learning result to untrained locations/features, making the learning performance transferable ; Li et al. employed a convolutional neural network (CNN) to simulate perceptual learning , utilizing that the CNN implements translation-invariant feature extraction, and hence their model can explain some transfer phenomena. While these models may solve the transfer problem, they fail to account for specificity, which was also vividly observed in experiments. Overall, perceptual learning still lacks a unified computational model accounting for both specificity and transfer that have been observed in different experiments.

In this study, we propose a novel computational model to reconcile the seemingly conflicting phenomena of specificity and transfer in perceptual learning. Our model is based on the fact that in the experiments observing specificity, participants were often excessively trained under the same stimulus condition (either at the same retinal location or presenting the same stimulus feature); while in the experiments observing transfer, the stimulus condition was varied during the training (either the location or the stimulus feature). This indicates that excessive training of the same stimulus condition is critical to induce specificity. To account for both specificity and transfer arising from different training paradigms, we propose a dual-learning framework for perceptual learning in the brain. The framework consists of two intertwined learning processes: one is task-based, and the other is feature-based. Specifically, task-based learning aims to quickly adapt to a new task by utilizing existing neural representations of the external world. It enables the brain to master new skills quickly and is transferable to untrained conditions. On the other hand, feature-based learning aims to refine neuronal representations to reflect the statistical changes of the external world. It enables the brain to represent the external world faithfully and it only takes effect when the external environment is substantially changed. We argue that in the experiments exhibiting transfer, task-based learning dominates; while in the experiments exhibiting specificity, feature-based learning dominates, and the latter is triggered by the neural system being excessively exposed to the same stimulus condition, triggering feature-based learning to catch up the statistical change of the external environment. Since featured-based learning leads to localized changes in feature representations adhered to the trained condition, its effect is not transferable to untrained conditions.

To substantialize the dual-learning framework, we built a hierarchical neural network model, which consists of three sequential stages of information processing responsible for, respectively, feature extraction, feature-based learning, and task-based learning. Specifically, we use a classical basis function network  to implement feature extraction representing preliminary image processing, a feedforward network with unsupervised Hebbian learning to implement feature-based learning, and a CNN with global max pooling to represent task-based learning. We set the rate of feature-based learning to be much smaller than that of task-based learning, such that task-based learning will dominate initially in training, and feature-based learning will take effect after the same stimulus condition is presented excessively. We demonstrate that the dual-learning model can well explain the specificity and transfer phenomena observed in classical psychophysical experiments.

## 2 Specificity vs. transfer in perceptual learning

Various tasks, ranging from the discrimination of basic visual features such as Vernier or orientation to the recognition of visual images such as motion or face, have been applied to study perceptual learning. These experiments unveiled three generic characteristics of perceptual learning, including specificity, transfer, and a transition from transfer to specificity when the number of training sessions under the same stimulus condition increases. They are reviewed below.

We use a Vernier discrimination task to introduce the specificity effect . In this task, participants learned to discern which of two vertical orientations was more leftward (or equivalently rightward) (Fig. 1A(i)). The stimuli were always presented at the same retinal location. Through intensive training, participants progressively improved their sensitivity to the offset between two orientations until reaching a threshold (the blue dashed line in Fig. 1A(ii)). After training, it was found that participants could not generalize their enhanced perceptual performances to untrained retinal locations, displaying the effect of specificity (red squares in Fig. 1A(ii)).

We use an orientation discrimination task to introduce the transfer effect . In this task, participants learned to distinguish which of two successively presented orientations was more clockwise (or equivalently more anticlockwise) (Fig. 1B(i)). By training with varied combinations of retinal location and orientation, participants progressively improved their sensitivity to the offset between two orientations until reaching a threshold (the green dashed line in Fig. 1B(ii)). After training, it

Figure 1: Specificity vs. transfer in perceptual learning. A. An example of specificity, adapted from . (i) A Vernier discrimination task: discerning the offset between two vertical orientations. (ii) The threshold of detectable offset at the training retinal location decreased with training sessions (blue diamonds), in comparison to pre-/post-training thresholds at an untrained retinal location (red squares). B. An example of transfer, adapted from . (i) An orientation discrimination task: Gabor stimuli varied across \(47\) location/orientation conditions were used for training. The red circle and arrow highlight the location/orientation not included in training but tested pre-/post-training. (ii) The orientation discrimination threshold with random Gabors over \(47\) stimulus conditions decreased with training sessions (green circles) in comparison to pre-/post-training thresholds at an untrained condition (red circles). C. Transition from transfer to specificity, adapted from . (i) An orientation discrimination task: retinal locations and orientations of visual stimuli used in training and transfer assessment. (ii) Left panel: the contrast sensitivity threshold decreased with training sessions (black, yellow, purple, and green lines denoting \(2\), \(4\), \(8\), and \(12\) numbers of training sessions, respectively). Right panel: the transfer effect decreased with the number of training sessions.

was found that participants could generalize their enhanced perceptual performances to untrained conditions, displaying the effect of transfer (red circles in Fig. 1B(ii)).

The above two experiments highlight the importance of the number of training sessions under the same stimulus condition in inducing the specificity or the transfer effect. It is expected that with the increased number of training sessions under the same condition, the learning effect should go from transfer to specificity gradually. Indeed, this was confirmed experimentally in an orientation discrimination task . In this task, participants underwent different numbers of training sessions under the same condition, followed by a switch to untrained conditions to measure the extent of transfer (Fig. 1C(i)). It was found that with the increased number of training sessions under the same condition, the perceptual performance of participants was improved (the left panel of Fig. 1C(ii)), whereas the transfer effect was decreased (the right panel of Fig. 1C(ii))

## 3 The dual-learning model

To reconcile the phenomena of specificity and transfer in perceptual learning, we propose a dual-learning model. As depicted in Fig. 2, the model consists of three sequential information processing stages, which are feature extraction, feature-based learning, and task-based learning. We use the Vernier discrimination task as an example to introduce the model.

### The model structure

Feature Extraction.This models the functions of the retina, the Lateral Geniculate Nucleus (LGN), and the input layer of V1 in the visual pathway, extracting preliminary features from input images to form retinotopic feature representations (see Fig. 2A). There is no plasticity at this stage, and we employ the HyperBF network  to model feature extraction. Denote \(I_{t}()\) the input image presented at trial \(t\) and \(F_{t}^{*}(,)\) the extracted feature representation, which is expressed as:

\[F_{t}^{*}(,)=[G(-^{ },)*I_{t}(^{})],\] (1)

where \(\) and \(\) denote the position and orientation feature in the image, respectively. The variable \(^{}\) represents the position of neighboring pixels, used in the convolution operation. The Gabor function \(G(-^{},)=1/2[-(- ^{})^{}/(2_{}^{})] [2^{}/()+]\), with \(_{g}\) the standard

Figure 2: Overview of the dual-learning model. The Vernier discrimination task is used as an example. A. Feature extraction. It involves using basis functions to transform an image \(I()\) into feature representations \(F_{t}^{*}(,)\), where \(\) and \(\) denote the position and orientation features. B. Feature-based learning. It refines feature representations to \(F_{t}(,)\) to reflect the statistical changes of external inputs. The feedforward connections are updated following the Hebbian learning rule, and they are strengthened at locations where stimuli are presented excessively, inducing location-specific changes in feature representations. C. Task-based learning. Using convolutional layers and global max pooling, it integrates the task-relevant information from feature representations \(F_{t}(,)\) to make the decision \(z^{*}\).

deviation of the Gaussian envelope, \(\) the spatial frequency, and \(\) the phase offset (for details, see Sec. A.1 in the Appendix). The symbol \(*\) represents the convolution operation and the symbol \(()\) denotes a normalization operation, i.e., \((F^{*})=(F^{*}-F^{*}_{})/F^{*}_{}\), with \(F^{*}_{}\) and \(F^{*}_{}\) the mean and standard deviation of the representation variable \(F^{*}\).

Feature-Based Learning.This models the plasticity in the early visual cortex, which refines feature representations to capture the statistical change of the external environment (see Fig. 2B). For simplicity, we employ a feedforward network with unsupervised Hebbian learning to implement this process. Denote \(F_{t}(,)\) the refined feature representations at trial \(t\), which is given by

\[F_{t}(,)=[_{^{}}W_{t}( ,^{})*F^{*}_{t}(^{},)],\] (2)

where \(W_{t}(,^{})\) represents the feedforward connection of the network (Fig. 2B). \(W_{t}(,^{})\) is updated following the competitive Hebbian learning rule, which is expressed as

\[W_{t+1}(,^{})=W_{t}(,^{}) + W_{t}(,^{}),\] (3)

with \(\) as the learning rate. The detail of \( W_{t}(,^{})\) is presented in Sec. A.2 in the Appendix. This learning rule enhances neuronal representations at locations where the stimulus is frequently presented, thereby inducing location-specific changes in feature representations.

Task-Based Learning.This models the information read-out process in the higher visual cortex (see Fig. 2C). We use a small convolutional network with three convolutional layers, followed by global max pooling, to implement this process. Denote \(z^{*}_{t}\) the decision at trial \(t\), which takes a value of \((0,1)\) representing the upper orientation is more leftward or more rightward, respectively. During decision-making, if the value is greater than \(0.5\), it is classified as \(1\); if it is less than \(0.5\), it is classified as \(0\). Its value is calculated by,

\[z^{*}_{t}=\{\{[F_{t}(,)]\}\},\] (4)

where \(()\) represents the multi-layer convolution operation that integrates task-related information from the feature representation \(F_{t}(,)\). The \(()\) function indicates the max pooling operation, which realizes translation-invariant computation and supports transferable learning. The sigmoid function, expressed as \((x)=1/[1+(x)]\) converts the output of the max pooling into a probability, representing the final decision. The true decision at each trial is denoted as \(z_{t}\), taking only binary values \(0\) or \(1\). Task-based learning updates the parameters in \(()\) by minimizing the cross entropy loss, \(L_{t}=-[z_{t}(z^{*}_{t})+(1-z_{t})(1-z^{*}_{t})]\), and backpropagation is used (for details, see Sec. A.3 in the Appendix).

### The interplay between feature- and task-based learning

We used a Vernier discrimination task to analyze the properties of the dual-learning model. The model outputs \(0\) if the upper orientation is more leftward compared to the lower one and outputs \(1\) otherwise. We trained the model at a fixed location and then tested its performances at three untrained locations having increasing distances to the trained one (Fig. 3A). For the details, see Sec. B in the Appendix. We conducted the below ablation studies.

First, we froze feature-based learning and only enabled task-based learning. As shown in Fig. 3B, the discrimination accuracies at both trained and untrained locations increase gradually with train epochs, indicating that task-based learning facilitates transfer over locations. This property comes from the fact that task-based learning employs a maxing pooling operation, which is translation-invariant.

Second, we froze task-based learning and only enabled feature-based learning. The weights of the readout layer were initialized after completing task-based learning, as described above. As shown in Fig. 3C, We see that the discrimination accuracy at the trained location keeps a relatively high value, whereas the accuracies at untrained locations drop quickly to a nearly chance level (\(50\%\)). This demonstrates that feature-based learning induces specificity, reinforcing the model's performance at the trained location while diminishing its transfer to untrained locations. To display the location-specific change in feature representation, we calculated neural representation changes at different locations during the training. As shown in Fig. 3D, we see that as the training goes on, the neural representation at the trained location remains stable (high similarity), while the neural representations at untrained locations change dramatically. This indicates that feature-based learning induces location-specific changes in feature representations.

Finally, we analyzed the model performance with both feature-based and task-based learning enabled. In particular, we set the rate of feature-based learning to be relatively much smaller than that of task-based learning. Although a direct numerical comparison between the two learning rates is not meaningful due to differences in their roles and magnitudes, the chosen configuration allows us to observe a clear distinction in the dynamics of the two learning processes. As shown in Fig. 3E, we observe that: 1). The combination of feature-based and task-based learning accelerates the training process at the train location, requiring fewer epochs to reach \(90\%\) accuracy compared to using task-based learning alone (gray line in Fig. 3, mean epochs: task-based learning \(=84.7\), combined feature- and task-based learning \(=81.3\)). This difference is statistically significant (\(t=3.90\), \(p<0.001\)), based on \(50\) repetitions for each condition. 2). The training promotes transfer to untrained locations initially, but as time goes on, the transfer effect decreases, while the specificity effect increases. This shift reflects that due to different learning rates, task-based learning dominates initially, which induces transfer; while feature-based learning gradually takes effect, which induces specificity.

## 4 Reproducing classical findings in perceptual learning

In this section, we used the dual-learning model to reproduce the classical findings in perceptual learning. We employed a Vernier discrimination task as an example, as this paradigm has been widely used in psychophysical experiments. In these experiments, the discrimination threshold, defined as the intensity of stimuli that participants can accurately discriminate with about an \(80\%\) success rate, was used to measure the learning effect. In our simulations, we adjusted the offset between two vertical orientations in the task to create a series of difficulty levels and chose the offset value corresponding to \(80\%\) model correctness as the threshold (for details, see Sec. C in the Appendix).

Figure 3: Properties of the dual-learning model. A. A Vernier discrimination task. Upper: the training stimulus. Lower: testing stimuli at three untrained locations. B. Discrimination accuracy vs. training epochs with only task-based learning on. It displays transfer effects to all untrained locations. C. Discrimination accuracy vs. training epochs with only feature-based learning on, following the completion of training in panel B. The model performances at untrained locations drop dramatically, display the effect of specificity. D. Similarity of feature representations before and after feature-based learning. Solid lines represent vertically oriented (\(0^{}\)) stimuli used in training, dashed lines represent diagonally oriented (\(45^{}\)) stimuli, and dotted lines represent horizontally oriented (\(90^{}\)) stimuli. E. Discrimination accuracy vs. training epochs with both feature-based and task-based learning on. In panels B and E, the gray lines indicate the number of epochs required to reach \(90\%\) accuracy. The results presented are averaged over \(50\) repetitions. For more details, see Sec. B in the Appendix.

In the first experiment, we adopted the training paradigm similar to that in . Specifically, we trained the model with fixed orientation and location (ori1_loc1) and evaluated model performances across various combinations of orientation and location before and after the training (Fig. 4A). The results are presented in Fig. 4B, which show that the model exhibits a significantly improved performance in the trained condition (ori1_loc1, blue diamonds), whereas this improvement is not transferable to untrained locations (ori1_loc2, light red squares), untrained orientations (ori2_loc1, medium red triangles), or combinations of untrained location and orientation (ori2_loc2, dark red circles). Fig. 4C further summarizes the learning improvements under different conditions, showing good agreement with the experimental data . The results demonstrate that our model successfully replicates the classical specificity phenomenon observed in perceptual learning.

In the second experiment, we adopted the training paradigm similar to that in . Specifically, the model was trained with stimuli presented at varying locations, either in a random or sequential order, and the transfer effect was evaluated at an untrained location (Fig. 5A). The results are presented in Fig. 5B-C, showing that the model's learning effect is successfully transferred to the untrained location. Fig. 5D further summarizes the learning improvements when trained across multiple locations either randomly or sequentially. These results agree well with the experimental data , demonstrating that our model successfully replicates the classical transfer phenomenon in perceptual learning.

In the third experiment, we adopted a training paradigm similar to that in . Specifically, the number of training sessions was varied, and the transfer effect was evaluated using a new condition that combined an untrained location and orientation (Fig. 6A). The results are shown in Fig. 6B. In the trained condition (left panel), performance thresholds gradually decreased with the increasing number of training sessions. However, in the untrained condition (right panel), the trend reversed: the more sessions completed in the trained condition, the higher thresholds were observed in the untrained condition. Fig. 6C further summarizes the progression of learning improvements during the training and transfer phases, agreeing well with the experimental data . Thus, our model successfully replicates the classical phenomenon of transition from transfer to specificity with the increasing number of training sessions.

In the fourth experiment, we adopted the training paradigm called double training similar to that in . In this experiment, following the first step training of the classical specificity task as in Fig. 1, we introduced second step training with stimulus at a new location and orientation. After double training, we evaluated the model's transfer performance under conditions untrained in either step. The results, shown in Fig. 7B, reveal that after double training, the original specificity effect in the

Figure 4: Specificity in perceptual learning via condition-specific training. A. A Vernier discrimination task similar to that in . The visual stimulus used for training (top, loc1_ori1) and an example of stimuli with the different location and orientation for transfer evaluation (bottom, loc2_ori2). B. Learning curves and thresholds for pre- and post-testing in different conditions. The threshold at the trained condition (ori1_loc1, blue diamonds) decreases significantly after training, while thresholds at untrained conditions (ori1_loc2, light red squares; ori2_loc1, medium red triangles; ori2_loc2, dark red circles) do not exhibit significant decline. C. Statistical results of training and transfer improvements. They show substantial gain at the trained condition (ori1_loc1, blue bar) and negligible or no improvement at untrained conditions (ori1_loc2, light red; ori2_loc1, medium red; ori2_loc2, dark red).

first step training now becomes transferable. The underlying reason is intuitively understandable. The second step training modified the feature representations adhered to the first step training, and hence reduced specificity (or equivalently increased transfer). Fig. 7C further summarizes the learning improvements across different training steps and conditions, demonstrating that our model successfully replicates the double training phenomenon in perceptual learning.

In summary, the adaptability of perceptual learning is governed by the interaction between specific feature-based learning at lower levels and transferable task-based learning at higher levels. Condition-specific training leads to the dominance of feature-based learning, resulting in significant specificity. In contrast, training with varied conditions allows task-based learning to dominate, enhancing transfer. This difference enables a transition from transfer to specificity as stimulus repetitions increase. Although not exclusively from the Vernier discrimination task, the observed changes in specificity and transfer are influenced by training paradigms rather than the tasks themselves. The simplicity of the Vernier discrimination task, requiring only a single stimulus presentation per trial, underscores its utility in illustrating these principles without the need for complex processing, making it ideal for our model demonstrations.

Figure 5: Transfer in perceptual learning via varied training conditions. A. A Vernier discrimination task similar to that in . During training, visual stimuli were presented at three distinct locations with two orientations: horizontal and vertical (top). For transfer evaluation, a single stimulus was presented at a new, untrained location (bottom), highlighted with a red circle. B. Random training condition. The learning curve and thresholds for training across multiple conditions randomly. The threshold at the training conditions (dark blue circles) decreases significantly, and the transfer condition (red circles) shows a similar decline. C. Rotating training condition. The learning curve and thresholds for training with stimuli rotating. The threshold at the training conditions (light blue circles) decreases significantly, and the transfer condition (red circles) shows a similar decline. D. Summary of learning and transfer improvements in different conditions.

Figure 6: Transition from transfer to specificity with the increased number of training sessions. A. A Vernier discrimination task similar to that in . Visual stimulus used for training (top, loc1_ori1) and stimuli for transfer evaluation (bottom, loc2_ori2). B. The learning curves under different training (left) and transfer (right) conditions. The thresholds are depicted with different colored curves representing different numbers of training sessions: gray (2 sessions), light red (4 sessions), medium red (8 sessions), and dark red (12 sessions). C. Summary of transfer improvements with varied training sessions. Each bar represents the improvement in transfer performance following 2, 4, 8, or 12 training sessions, respectively.

## 5 Conclusions and discussions

All learning agents, including the brain, face a fundamental challenge: balancing task performance with the cost of learning. Intuitively, if the agent does not need to account for the feature distribution in the external world, it can quickly adapt by reusing existing feature representations to complete tasks efficiently and at low cost. However, when the agent identifies meaningful statistical patterns in the environment, it can refine its feature representations to enhance precision and effectiveness. Although beneficial, this adaptation is both resource-intensive and slow, as the agent must first distinguish between genuine environmental changes and random fluctuations. In essence, to learn or not to learn, is a generic question faced by all learning agents.

In this work, starting from the goal of reconciling the conflicting phenomena of specificity and transfer in perceptual learning, we present a solution of the brain, i.e., the dual-learning framework. This framework consists of two learning processes: a task-based one and a feature-based one. Specifically, task-based learning is fast, which enables the agent to learn to accomplish a task rapidly by using existing feature representations; while feature-based learning is slow, which enables the agent to improve feature representations to reflect the statistical change of the external environment.

Our dual-learning model successfully replicates and elucidates classical experimental findings related to specificity and transfer in perceptual learning. It reveals that the interaction between the slow-changing, specific feature learning at the early visual pathway and the flexible, transferable task learning at the higher visual pathway governs the adaptability of perceptual learning. Typically, learning tends to adjust the readout of neural representations (i.e., task-based learning) rather than altering the representations themselves (i.e., feature-based learning), unless there is a significant change in the statistical properties of external information. Thus, the default state of learning favors transfer. However, in traditional experimental paradigms, the frequent repetition of stimuli leads to the dominance of feature-based learning, thereby exhibiting significant specificity; by limiting the repetition of stimuli, task-based learning can dominate, thereby enhancing transfer. As such, perceptual learning can display a transition from transfer to specificity as the number of stimulus repetitions increases.

Our dual-learning model can be regarded as a computational modeling implementation of the two-stage model theory . While the two-stage model theory aims to address the contradictions between task-related and task-unrelated perceptual learning, it posits the existence of feature-based and task-based plasticity within perceptual learning. Thus, our model is a practical realization of

Figure 7: Transfer in perceptual learning via double training. A. A Vernier discrimination task similar to that in . The visual stimulus used for the first step training (top, loc1_ori1) and the visual stimulus used for the second step training (bottom, loc2_ori2). B. Learning curves and thresholds for pre- and post-testing in different conditions. The left panel corresponds to the results of the first step training as in Fig. 4B. The right panel displays the results of double training. Notably, the threshold at the second trained condition (ori2_loc2, deep red circles) decreases significantly after double training, and thresholds at untrained locations (ori1_loc2, light red squares) or untrained orientations (ori2_loc1, medium red triangles) also exhibit notable declines. C. Statistical results of training and transfer improvements. The left panel corresponds to the results of the first step training as in Fig. 4C. The right panel displays the results of double training. A substantial gain at the second trained condition (ori2_loc2, deep red bar) and at untrained conditions (ori1_loc2, light red; ori2_loc1, medium red)this theory. Furthermore, the dual-learning framework aligns with the reverse hierarchy theory , which suggests that learning processes invert the sequence of visual information processing from top-down. As tasks become more difficult and specific, lower levels of the neural hierarchy are increasingly engaged, aligning learning outcomes with enhanced task specificity. This alignment illustrates how the dual-learning model not only accommodates but also substantiates theoretical perspectives on perceptual learning's hierarchical nature, providing a robust framework for exploring how different learning mechanisms interact within the brain's architecture.

Limitation and future work.In this study, as a first step to elucidate the notion of dual-learning, we have built a very simple network model without including many biological details of the visual pathway. In future work, we will extend the current model to include more biological details and apply the model to explain more cognitive functions of the brain. In essence, the dual-learning framework reflects that the brain employs a learning strategy to balance the accomplishment of a new task and the consumption of learning effort, that is, if the statistics of the environment are unchanged, low-cost task-based learning is applied; otherwise, high-cost feature-based learning is triggered. The same balance requirement is faced by other learning agents. We, therefore, expect that the dual-learning framework has the potential to be applied in AI applications, and we will explore this issue in future work.