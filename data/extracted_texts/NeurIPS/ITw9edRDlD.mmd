# Are Emergent Abilities of Large

Language Models a Mirage?

Rylan Schaeffer

Computer Science

Stanford University

rschaef@cs.stanford.edu &Brando Miranda

Computer Science

Stanford University

brando9@cs.stanford.edu &Sanni Koyejo

Computer Science

Stanford University

sanni@cs.stanford.edu

###### Abstract

Recent work claims that large language models display _emergent abilities_: abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their _sharpness_, transitioning seemingly instantaneously from not present to present, and their _unpredictability_, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due to the researcher's choice of metric rather than due to fundamental changes in models with scale. Specifically, nonlinear or discontinuous metrics produce seemingly emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities; (2) make, test and confirm two predictions about metric choices in a meta-analysis of emergent abilities on the Beyond the Imitation Game Benchmark (BIG-Bench); and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep network architectures. Via all three analyses, we provide evidence that emergent abilities disappear with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.

## 1 Introduction

Emergent properties of complex systems have long been studied across disciplines, from physics to biology to mathematics. The idea of emergence was popularized by Nobel Prize-winning physicist P.W. Anderson's "More Is Different" , which argues that as the complexity of a system increases, new properties may materialize that cannot be predicted even from a precise quantitative understanding of the system's microscopic details. Recently, the idea of emergence gained significant attention in machine learning due to observations that large language models (LLMs) such as GPT , PaLM  and LaMDA  exhibit so-called "emergent abilities"  (Fig. 1).

The term "emergent abilities of LLMs" was recently and crisply defined as "abilities that are not present in smaller-scale models but are present in large-scale models; thus they cannot be predicted by simply extrapolating the performance improvements on smaller-scale models" . Such emergent abilities were first discovered in the GPT-3 family . Subsequent work emphasized the discovery, writing that "[although model] performance is predictable at a general level, performance on a specific task can sometimes emerge quite unpredictably and abruptly at scale" . These quotations collectively identify the two defining properties of emergent abilities in LLMs:

1. _Sharpness_, transitioning seemingly instantaneously from not present to present

## 2 _Unpredictability_, transitioning at seemingly unforeseeable model scales

These emergent abilities have garnered significant interest, raising questions such as: What controls _which_ abilities will emerge? What controls _when_ abilities will emerge? How can we make desirable abilities emerge faster, and ensure undesirable abilities never emerge? These questions are especially pertinent to AI safety and alignment, as emergent abilities forewarn that larger models might one day, without warning, acquire undesired mastery over dangerous capabilities .

In this paper, we call into question the claim that LLMs possess emergent abilities, by which we specifically mean _sharp_ and _unpredictable_ changes in model outputs as a function of model scale on specific tasks. Our doubt stems from the observation that emergent abilities seem to appear only under metrics that nonlinearly or discontinuously scale any model's per-token error rate. For instance, as we later show, \(>92\%\) of emergent abilities on BIG-Bench tasks  (hand-annotated by ) appear under either of these two metrics:

\[\ }}{{=}} 1&\\ 0&\] \[\ }}{{=}} 1&\\ 0&\]

This raises the possibility of an alternative explanation for the origin of LLMs' emergent abilities: sharp and unpredictable changes might be induced by the researcher's choice of measurement, even though the model family's per-token error rate changes smoothly, continuously and predictably with increasing scale. Specifically, our alternative posits that emergent abilities are a mirage caused primarily by the researcher choosing a metric that nonlinearly or discontinuously deforms per-token error rates, and secondarily by possessing too few test data to accurately estimate the performance of smaller models, thereby causing smaller models to appear wholly unable to perform the task.

To communicate our alternative explanation, we present it as a simple mathematical model and demonstrate how it quantitatively reproduces the evidence offered in support of emergent abilities of LLMs. We then test our alternative explanation in three complementary ways:

Figure 1: **Emergent abilities of large language models**. Model families display _sharp_ and _unpredictable_ increases in performance at specific tasks as scale increases. Source: Fig. 2 from .

1. We make, test and confirm three predictions based on our alternative hypotheses using the InstructGPT  / GPT-3  model family.
2. We meta-analyze published benchmarks [33; 38] to reveal that emergent abilities only appear for specific metrics, not for model families on particular tasks, and that changing the metric causes the emergence phenomenon to disappear.
3. We induce never-before-seen, seemingly emergent abilities in multiple architectures across various vision tasks by intentionally changing the metrics used for evaluation.

## 2 Alternative Explanation for Emergent Abilities

How might smooth, continuous, predictable changes in model family performance appear sharp and unpredictable? The answer is that the researcher's choice of a nonlinear or discontinuous metric can distort the model family's performance to appear sharp and unpredictable.

To expound, suppose that within a model family, the test loss falls smoothly, continuously, and predictably with the number of model parameters. One reason to believe this is the phenomenon known as neural scaling laws: empirical observations that deep networks exhibit power law scaling in the test loss as a function of training dataset size, number of parameters or compute [15; 32; 13; 18;

Figure 2: **Emergent abilities of large language models are created by the researcher’s chosen metrics, not unpredictable changes in model behavior with scale.** (A) Suppose the per-token cross-entropy loss decreases monotonically with model scale, e.g., \(_{CE}\) scales as a power law. (B) The per-token probability of selecting the correct token asymptotes towards 1. (C) If the researcher scores models’ outputs using a nonlinear metric such as Accuracy (which requires a sequence of tokens to _all_ be correct), the metric choice nonlinearly scales performance, causing performance to change sharply and unpredictably in a manner that qualitatively matches published emergent abilities (inset). (D) If the researcher nested scores models’ outputs using a discontinuous metric such as Multiple Choice Grade (akin to a step function), the metric choice discontinuously scales performance, again causing performance to change sharply and unpredictably. (E) Changing from a nonlinear metric to a linear metric such as Token Edit Distance, scaling shows smooth, continuous and predictable improvements, ablating the emergent ability. (F) Changing from a discontinuous metric to a continuous metric such as Brier Score again reveals smooth, continuous and predictable improvements in task performance. Consequently, the observation of ”emergent abilities” can be explained by the researcher’s choice of metrics, and does not require fundamental changes in model family behavior on specific tasks with scale.

10, 14, 17, 39, 16, 8, 29]. For concreteness, suppose we have a model family of different numbers of parameters \(N>0\) and assume that each model's per-token cross entropy falls as a power law with the number of parameters \(N\) for constants \(c>0,<0\) (Fig. 2A):

\[_{CE}(N)=()^{}\]

To be clear, we do not require this particular functional form to hold; rather, we use it for illustrative purposes. Let \(V\) denote the set of possible tokens, \(p\) denote the true but unknown probability distribution, and \(_{N}\) denote the \(N\)-parameter model's predicted probability distribution. The per-token cross entropy as a function of number of parameters \(N\) is:

\[_{CE}(N)\ }}{{=}}\ -_{v V}p(v)_{N}(v)\]

In practice, \(p\) is unknown, so we substitute a one-hot distribution of the observed token \(v^{*}\):

\[_{CE}(N)=-_{N}(v^{*})\]

A model with \(N\) parameters then has a per-token probability of selecting the correct token (Fig. 2B):

\[p()=-_{CE}(N)= -(N/c)^{}\]

Suppose the researcher then chooses a metric that requires selecting \(L\) tokens correctly. For example, our task might be \(L\)-digit integer addition, and a model's output is scored \(1\) if all \(L\) output digits exactly match all target digits with no additions, deletions or substitutions, \(0\) otherwise. If the probability each token is correct is independent1, the probability of scoring \(1\) is:

\[(N) p_{N}()^{}=-(N/c)^{}^{L}\]

This choice of metric nonlinearly scales performance with increasing token sequence length. When plotting performance on a linear-log plot, one sees a sharp, unpredictable emergent ability on longer sequences (Fig. 2C) that closely matches claimed emergent abilities (inset). What happens if the researcher switches from a nonlinear metric like Accuracy, under which the per-token error rate scales geometrically in target length (App. A.3), to an approximately linear metric like Token Edit Distance, under which the per-token error rate scales quasi-linearly in target length (App. A.2)?

\[(N) L(1-p_{N}())=L(1--(N/c)^{})\]

The linear metric reveals smooth, continuous, predictable changes in model performance (Fig. 2E). Similarly, if the researcher uses a discontinuous metric like Multiple Choice Grade, the researcher can find emergent abilities (Fig. 2D), but switching to a continuous metric like Brier Score removes such abilities (Fig. 2F). In summary, sharp and unpredictable changes with increasing scale can be fully explained by three interpretable factors: (1) the researcher choosing a metric that nonlinearly or discontinuously scales the per-token error rate, (2) having insufficient resolution to estimate model performance in the smaller parameter regime, with resolution2 set by \(1/\) dataset size, and (3) insufficiently sampling the larger parameter regime.

## 3 Analyzing InstructGPT/GPT-3's Emergent Arithmetic Abilities

Previous papers prominently claimed the GPT  family3 displays emergent abilities at integer arithmetic tasks  (Fig. 1A). We chose these tasks as they were prominently presented, and we focused on the GPT family due to it being publicly queryable. As explained mathematically and visually in Sec. 2, our alternative explanation makes three predictions:

1. Changing the metric from a nonlinear or discontinuous metric (Fig. 2CD) to a linear or continuous metric (Fig. 2 EF) should reveal smooth, continuous, predictable performance improvement with model scale.
2. For nonlinear metrics, increasing the resolution of measured model performance by increasing the test dataset size should reveal smooth, continuous, predictable model improvements _commensurate with the predictable nonlinear effect of the chosen metric_.
3. Regardless of metric, increasing the target string length should predictably affect the model's performance as a function of the length-1 target performance: approximately geometrically for accuracy and approximately quasilinearly for token edit distance.

Figure 4: **Claimed emergent abilities evaporate upon using better statistics.** Based on the predictable effect Accuracy has on performance, measuring performance requires high resolution. Generating additional test data increases the resolution and reveals that even on Accuracy, the InstructGPT/GPT-3 family’s  performance is above chance and improves in a smooth, continuous, predictable manner that qualitatively matches the mathematical model.

Figure 3: **Claimed emergent abilities evaporate upon changing the metric.** Top: When performance is measured by a nonlinear metric (e.g., Accuracy), the InstructGPT/GPT-3  family’s performance appears sharp and unpredictable on longer target lengths. Bottom: When performance is instead measured by a linear metric (e.g., Token Edit Distance), the family exhibits smooth, predictable performance improvements.

To test these predictions, we collected outputs from the InstructGPT/GPT-3 family on two tasks: 2-shot multiplication between two 2-digit integers and 2-shot addition between two 4-digit integers.

Prediction: Emergent Abilities Disappear With Different MetricsOn both arithmetic tasks, the GPT family displays emergent abilities if the target has 4 or 5 digits and if the metric is Accuracy (Fig. 3, top) [4; 9; 38]. However, if one changes from nonlinear Accuracy to linear Token Edit Distance _while keeping the models' outputs fixed_, the family's performance smoothly, continuously and predictably improves with increasing scale (Fig. 3, bottom). This confirms our first prediction and supports our alternative explanation that the observation of emergent abilities can be explained by the researcher's choice of metric, _not changes in the model family's outputs_. We also observe that under Token Edit Distance, increasing the length of the target string from 1 to 5 predictably decreases the family's performance in an approximately quasilinear manner, confirming the first half of our third prediction.

Prediction: Emergent Abilities Disappear With Better StatisticsWe next tested our second prediction: that even on nonlinear metrics such as accuracy, smaller models do not have zero accuracy, but rather have non-zero above-chance accuracy _commensurate with choosing to use accuracy as the metric_. In order to accurately measure models' accuracy, we increased the resolution by generating additional test data, and found that on both arithmetic tasks, all models in the InstructGPT/GPT-3 family achieve above-chance accuracy (Fig. 4). This confirms our second prediction. We also observe that as the target string length increases, the accuracy falls approximately geometrically with the length of the target string, confirming the second half of our third prediction. These results additionally demonstrate that the researcher's choice of metric has the effect that one should predict accuracy to have, i.e., geometric decay with the target length.

## 4 Meta-Analysis of Claimed Emergent Abilities

Analyzing the GPT family is possible because the models are publicly queryable. However, at the time of this analysis, other model families claimed to exhibit emergent abilities are not publicly queryable, nor are their generated outputs publicly available, meaning we are limited to analyzing the published results themselves [9; 38; 37]. Our alternative explanation makes two predictions.

1. At the "population level" of Task-Metric-Model Family triplets, emergent abilities should appear predominantly on specific _metrics_, not _task-model family_ pairs, and specifically with nonlinear and/or discontinuous metrics.
2. On individual Task-Metric-Model Family triplets that display an emergent ability, changing the metric to a linear and/or continuous metric should remove the emergent ability.

To test these predictions, we used claimed emergent abilities on BIG-Bench [33; 38] due to the benchmark being pertinent and publicly available.

Prediction: Emergent Abilities Should Appear with Metrics, not Task-Model FamiliesIf emergent abilities are real, one should expect task-model family pairs to show emergence for all reasonable metrics. However, if our alternative explanation is correct, we should expect emergent abilities to appear only under certain metrics. To test this, we analyzed on which metrics emergent abilities appear. To determine whether a task-metric-model family triplet exhibits a possible emergent ability, we used a metric from previous work . Letting \(y_{i}\) denote model performance at model scales \(x_{i}\), sorted such that \(x_{i}<x_{i+1}\), the emergence score is:

\[(x_{n},y_{n})}_{n=1}^{N} }}{{=}}( _{i}y_{i}-_{i}y_{i})(_{i}y_{i}-_{i}y_{i})}{(\{(y_{i}-y_{i-1})^{2}\}_{i})}}\]

We found that most metrics used in BIG-Bench have _zero_ task-model family pairs that exhibit emergent abilities: of the 39 preferred metrics in BIG-Bench, at most 5 display emergence (Fig. 5A). Many of the 5 are nonlinear and/or discontinuous, e.g., Exact String Match, Multiple Choice Grade, ROUGE-L-Sum (App. A.4). Notably, because BIG-Bench often scores models on tasks using multiple metrics, the _lack_ of emergent abilities under other metrics suggests that emergent abilities do not appear when model outputs are scored using other metrics.

Because emergence score only _suggests_ emergence, we also analyzed hand-annotated task-metric-model family triplets , which revealed emergent abilities appear with \(4/39\) metrics (Fig. 5B), and 2 metrics account for \(>92\%\) of claimed emergent abilities (Fig. 5C): Multiple Choice Grade and Exact String Match. Multiple Choice Grade is discontinuous, and Exact String Match is nonlinear.

Prediction: Changing Metric Removes Emergent AbilitiesTo test our second prediction, we focused on the LaMDA family  because its outputs are available through BIG-Bench. We identified tasks on which LaMDA displays emergent abilities with Multiple Choice Grade, then asked whether LaMDA still displays emergent abilities on the same tasks with a different BIG-Bench metric: Brier Score . Brier Score is a strictly proper scoring rule for predictions of mutually exclusive outcomes; for a binary outcome, the Brier Score simplifies to the squared error between 1 and the model's probability mass on the outcome. LaMDA's emergent abilities on the discontinuous Multiple Choice Grade disappeared when we changed the metric to the continuous Brier Score (Fig. 6). These results support our alternative explanation that emergent abilities are induced by the chosen metric.

Figure 5: **Emergent abilities appear only for specific metrics, not task-model families.** (A) _Possible_ emergent abilities appear with _at most_ 5 out of 39 BIG-Bench metrics. (B) Hand-annotated data by  reveal emergent abilities appear only under 4 preferred metrics. (C) \(>92\%\) of emergent abilities appear under one of two metrics: Multiple Choice Grade and Exact String Match.

## 5 Inducing Emergent Abilities in Networks on Vision Tasks

To demonstrate how emergent abilities can be induced by the researcher's choice of metric, we show how to produce emergent abilities in deep networks of various architectures: fully connected, convolutional, self-attentional. We focus on vision tasks because abrupt transitions in vision models' capabilities have not been observed to the best of our knowledge; this is one reason why emergence in large language models is considered so interesting. For the convolutional example, see App. B.

Emergent Reconstruction of CIFAR100 Natural Images by Nonlinear AutoencodersWe first induce an emergent ability to reconstruct images in shallow (i.e., single hidden layer) nonlinear autoencoders trained on CIFAR100 natural images . To emphasize that the sharpness of the metric is responsible for emergent abilities, and to show that sharpness extends to metrics beyond Accuracy, we intentionally define a discontinuous metric that measures a network's ability to reconstruct a dataset as the average number of test data with squared reconstruction error below cutoff \(c\):

\[_{c}\{x_{n}\}_{n=1}^{N}\ }}{{=}}\ _{n}|x_{n}-_{n}| |^{2}<c,\] (1)

where \(()\) denotes an indicator variable and \(_{n}\) is the autoencoder's reconstruction of \(x_{n}\). The autoencoder family displays smoothly decreasing squared reconstruction error as the number of bottleneck units increases (Fig. 7B). Under our newly defined \(_{c}\) metric and for particular choices of \(c\), the autoencoder family exhibits a sharp and seemingly unpredictable image reconstruction ability (Fig. 7C) that qualitatively matches published emergent abilities (Fig. 7A).

Emergent Classification of Omniglot Characters by Autoregressive TransformersWe next induce emergent abilities in Transformers  trained to autoregressively classify Omniglot handwritten characters , in a setup inspired by recent work : Omniglot images are embedded by convolutional layers, then sequences of embedded image-image class label pairs are fed into decoder-only transformers. We measure image classification performance on sequences of length \(L\), again via _subset accuracy_: \(1\) if all \(L\) images are classified correctly (Fig. 8B), 0 otherwise. Causal transformers display a seemingly emergent ability to correctly classify Omniglot handwritten characters (Fig. 8C) that qualitatively matches published emergent abilities (Fig. 8A).

Figure 6: **Changing the metric when evaluating task-model family pairs causes emergent abilities to disappear.** Top: The LaMDA model family displays emergent abilities when measured under the discontinuous Multiple Choice Grade. Bottom: The LaMDA model family’s emergent abilities disappear when measured under a continuous BIG-Bench metric: Brier Score.

## 6 Limitations

This paper has several limitations. First, nothing in this paper should be interpreted as claiming that large language models _cannot_ display emergent abilities; rather, our message is that some previously claimed emergent abilities appear to be mirages induced by researcher analyses. Second, our experiments and analyses are limited because some LLMs with claimed emergent abilities (e.g., PaLM 1, Gopher, Chinchilla) are private and not queryable at the time of our analysis. Lastly, the best metric(s) arguably depends on human preferences, which may exhibit qualitatively different behavior; we are unaware of studies quantifying whether human judgment is thresholded in an "emergent" way.

## 7 Related Work

Srivastava et al.  observed that while accuracy at a particular task can empirically appear sharp and unpredictable, cross-entropy does not appear so; the authors then discussed whether emergent abilities may be partially attributed to the metric. Our paper converts their discussion into precise predictions, then quantitatively tests the predictions to reveal metric choice is possibly responsible for some claimed emergent abilities; well-known and widely-used metrics (including metrics used by ) capture graded improvements; emergent abilities do not appear only on tasks involving multiple steps, such as the discontinuous Multiple Choice Grade; metric choice can be used to induce emergent abilities in a novel domain (vision) in diverse architectures and tasks.

Alternative explanations exist for the origin of emergent abilities. Caballero et al.  explain emergence by assuming a piece-wise power law functional form; under this view, emergent abilities are real, caused by a "break" (or possibly multiple breaks) in the governing power law. In contrast, our work suggests that emergent abilities can be induced by the researcher under a single power law. Both

Figure 8: **Induced emergent classification ability in autoregressive Transformers.** (A) A published emergent ability on the MMLU benchmark . (B) Autoregressive transformers trained to classify Omniglot images display increasing accuracy with increasing scale. (C) When accuracy is redefined as classifying _all_ images correctly, a seemingly emergent ability appears.

Figure 7: **Induced emergent reconstruction ability in shallow nonlinear autoencoders.** (A) A published emergent ability at the BIG-Bench Periodic Elements task . (B) Shallow nonlinear autoencoders trained on CIFAR100  display smoothly decreasing mean squared reconstruction error. (C) Using a newly defined Reconstruction\({}_{c}\) metric (Eqn. 1) induces an unpredictable change.

explanations could be true: some emergent abilities might genuinely be abruptly appearing, whereas some emergent abilities might be attributable to the metric. Michaud et al.  posits that language modeling data might be comprised of discrete subtasks ("quanta") that networks learn; if larger networks have greater capacity, and are thus more capable of learning more of these quanta, then if some downstream task requires a network to learn some combination of quanta, larger networks are more likely to have all the requisite capabilities and thus are capable of performing this downstream task. We think that this is a very interesting hypothesis. Whether language modeling data can or should be understood from this quantization perspective, and whether these quanta indeed are the origin of emergent abilities, are really exciting questions that we think merit more study.

## 8 Discussion

Our paper presents an alternative explanation for the claimed emergent abilities of large language models. For a fixed task and a fixed model family, the researcher can choose a metric to create an emergent ability or choose a metric to ablate an emergent ability. Ergo, _emergent abilities may be creations of the researcher's choices, not a fundamental property of the model family on the specific task._

Our work has several implications. Firstly, a task and a metric are distinct and meaningful choices when constructing a benchmark. Secondly, when choosing metric(s), if the goal is to accurately predict scaling behavior, then one should consider the interplay between cross-entropy, transformations, and resolution-limited evaluations so that one isn't surprised. As a corollary, continuous/linear metrics are probably better for accurate scaling forecasts, but if discontinuous/nonlinear metrics are preferred, then one may need a lot of data for sufficient resolution to accurately measure performance. The key is thinking through the consequences of one's choices! Thirdly, when making claims about capabilities of large models, including proper controls is critical. In this particular setting, emergent abilities claims are possibly infected by a failure to control for multiple comparisons. In BIG-Bench alone, there are \( 220\) tasks, \( 40\) metrics per task, \( 10\) model families, for a total of \( 10^{6}\) task-metric-model family triplets, meaning the probability that _no_ task-metric-model family triplet exhibits an emergent ability by random chance might be small. Fourthly, scientific progress can be hampered when models and their outputs are not made available for independent scientific investigation.

## 9 Contributions

RS conceived of the research direction collected data, ran experiments, and analyzed results. SK supervised and guided the project. BM also provided guidance. All authors helped write the manuscript.

## 10 Acknowledgements

This work is partially supported by the National Science Foundation under grants No. 2046795, 1934986, 2205329, NIH 1R01MH116226-01A, NIFA award 2020-67021-32799, the Alfred P. Sloan Foundation, and Google Inc. RS is partially supported by a Stanford Data Science Scholarship and BM is partially supported by a Stanford School of Engineering Fellowship and a Stanford EDGE Scholar Fellowship. We thank our colleagues Professor Tatsunori Hashimoto, Eric Han, Max Lamparth, Mikail Khona, Kateryna Pistunova, Victor Lecomte, and Zane Durante for discussing our findings with us and providing much-appreciated feedback.