# Initializing Services in Interactive ML Systems for Diverse Users

Avinandan Bose

University of Washington

avibose@cs.washington.edu

&Mihaela Curmei

University of California Berkeley

mcurmei@berkeley.edu

&Daniel L. Jiang

University of Washington

danji@cs.washington.edu

&Jamie Morgenstern

University of Washington

jamiemmt@cs.washington.edu

&Sarah Dean

Cornell University

sdean@cornell.edu

&Lillian J. Ratliff

University of Washington

ratliffl@uw.edu

&Maryam Fazel

University of Washington

mfazel@uw.edu

###### Abstract

This paper investigates ML systems serving a group of users, with multiple models/services, each aimed at specializing to a sub-group of users. We consider settings where upon deploying a set of services, users choose the one minimizing their personal losses and the learner iteratively learns by interacting with diverse users. Prior research shows that the outcomes of learning dynamics, which comprise both the services' adjustments and users' service selections, hinge significantly on the initial conditions. However, finding good initial conditions faces two main challenges: (i) _Bandit feedback:_ Typically, data on user preferences are not available before deploying services and observing user behavior; (ii) _Suboptimal local solutions:_ The total loss landscape (i.e., the sum of loss functions across all users and services) is not convex and gradient-based algorithms can get stuck in poor local minima.

We address these challenges with a randomized algorithm to adaptively select a minimal set of users for data collection in order to initialize a set of services. Under mild assumptions on the loss functions, we prove that our initialization leads to a total loss within a factor of the _globally optimal total loss with complete user preference data_, and this factor scales logarithmically in the number of services. This result is a generalization of the well-known \(k\)-means++ guarantee to a broad problem class, which is also of independent interest. The theory is complemented by experiments on real as well as semi-synthetic datasets.

## 1 Introduction

We consider a setting where a provider wants to design \(k\) services for \(n\) users with diverse preferences. Each service uses a model parameterized by a vector \(^{d}\) to predict users' preferences, and users pick a service that yields the smallest loss for them. The loss incurred by user \(i\) when choosing a service parameterized by \(\) is denoted by \(_{i}(,_{i})\), where \(_{i}^{d}\) parameterizes the user's preference. We want to design \(k\) services by minimizing the sum of all losses; i.e., an optimizationproblem of the form:

\[*{minimize}_{_{1},,_{k}^{d}}\ _{i=1}^{n}\{_{i}(_{1},_{i}), _{i}(_{k},_{i})\}.\] (1)

This problem formulation is broad and includes the classical \(k\)-means clustering problem  (where \(_{i}\) are Euclidean distances and the inner'min' selects the closest among \(k\) centroids), mixed-linear regression , generalized principal component analysis (GPCA) or subspace clustering , in addition to our new, motivating problem of designing \(k\) services for \(n\) users. Even if the losses \(_{i}\) are convex in \(\), this objective is generally not convex (even in the special case of the \(k\)-means problem).

Our goal is to find a local minimum of this optimization problem with an approximation ratio (a worst-case guarantee on the achieved total loss with respect to the global optimum) under suitable yet broad assumptions on \(_{i}\). Further, an important limitation in many practical settings is that the provider/designer has only _bandit feedback_ (zeroth-order oracle access) to the loss functions (i.e., the designer doesn't know the function \(_{i}(,_{i})\), but can only evaluate its value for some \(\) corresponding to the service chosen by the user among the ones deployed), which further complicates solution methods, compared to the classical cases of clustering and facility location problems  which typically assume full information.

In this paper, we seek a novel and effective initialization scheme that vastly extends the celebrated \(k\)-means++ algorithm and its analysis . This scheme should retain the simplicity and ease of implementation of the original algorithm, yet be able to (1) handle general loss families (assumptions on \(_{i}\) are discussed in Section 2), (2) provide a tight, instance-dependent approximation ratio (details in Section 3), and (3) handle realistic information limitations such as access only to (noisy) bandit feedback, in a sample-efficient manner. Next, we describe in more detail the important use case of initialization of services for diverse users in multi-service ML systems (yet as noted above, our main result has other applications as well, and can be of independent interest).

**Motivation.** In a variety of contexts such as federated learning , crowd-sourcing  and online recommendation systems , data about user preferences is acquired through iterative interactions. This data is then used to improve the model and serve the individual needs of users. Given that users' preferences are typically heterogeneous, recent works demonstrate that using multiple specialized models can be more effective than the one-size-fits-all approach of employing a single large shared model, e.g., for clustered federated learning , meta learning , fine-tuning for specific groups of users or tasks , and in the context of fair classifiers . Here we tackle the crucial yet under-explored phase of _initializing services_ in ML systems that learn interactively from diverse users. The initialization process is crucial as it sets the stage for how effectively these systems can adapt and specialize with future user interactions. Once initialized, the services interact with users, who, in turn, choose among services based on their loss. These "learning dynamics" typically lead to the specialization of services to groups of users , and  shows experimentally that the overall social welfare achieved by the services depends on the initialization of the learning dynamics. We note that in the context of problem (1), the learning dynamics in  can be seen as updates of an alternating minimization algorithm, iteratively updating users' choices (the inner minimization) and services' parameters (update to each \(_{j}\)). Our goal is to initialize a set of services to minimize the sum of losses for all users (or equivalently, maximize total welfare), tackling the following challenges:

* **Bandit loss feedback:** In practice, offering a service often precedes data collection. Specifically, in contexts like online recommendations, it is usually not feasible to gather user preference data (knowledge about \(_{i}\) and evaluations of \(_{i}(,_{i})\) at various different parameter values in problem (1)) without first deploying the services parameterized by \(\{_{1},,_{k}\}\) and observing user interactions. This means that data collection is inherently conditional on the existence of services, challenging the conventional "data-first, model-second" paradigm.
* **Suboptimal local solutions:** Since users select the service with the lowest loss (\(\{_{i}(_{1},_{i}),_{i}(_{k}, _{i})\}\) in problem (1)), minimizing over the parameters \(\{_{1},,_{k}\}\) leads to a nonconvex problem in general, as mentioned earlier. Gradient-based learning dynamics can get stuck in local minima where the total loss can be significantly worse than the globally minimum loss. Thus, the outcomes of learning dynamics are heavily affected by initialization of service parameters.

**Contributions.** The following summarizes the contributions of this paper.

* We design a computationally and statistically efficient algorithm for _initialization of services_ prior to learning dynamics. The algorithm works by adaptively selecting a small number of users to collect data from (via queries of their loss function) in order to initialize the set of services.
* We establish an _approximation ratio_ for the designed algorithm: the expected total loss achieved by the algorithm right after initialization is within a factor of the _globally optimal total loss in the presence of complete user preference data_, and this factor scales logarithmically in the number of services. Furthermore this bound is tight, and recovers the known k-means++ approximation ratio as a special case (cf. Section 3).
* When users belong to a set of demographic groups, it is desirable that the services do not result in unfavorable outcomes towards certain demographics (e.g., based on gender or racial groups). One fair objective is to minimize the maximum average loss of users across different groups. We provide an _approximation ratio_ for this fair objective that scales logarithmically in the number of services (cf. Section 3).
* In the context of linear prediction models, we study the problem of _generalizing_ to users the provider has not interacted with before (cf. Section 4).
* We empirically demonstrate the strengths of our initialization scheme via experiments on a prediction task using 2021 US Census data, and online movie recommendation task using the Movie-lens10M dataset (cf. Section 5).

### Related Work

**Multiple Model Specialization.** In distributed learning, where data sources are users' personal devices, utilizing multiple specialized models, where users are grouped into clusters representing interests, can yield improved predictions and outcomes. For instance, in recommendation systems these clusters could represent users interested in different movie genres, or different combination of features (see Appendix B for a concrete example on Netflix recommendation clusters). This approach has been adopted recently in clustered federated learning [34; 30; 17] and online interactive learning , facility location problems , where users _choose_ models/services and for which they provide updates.

**Clustering.** Multiple model specialization leads to clustering the users into groups and centering a specialized model on each group. We provide a brief review of the \(k\)-means clustering problem and establish the connection to specialization. The \(k\)-means clustering problem is one of the most commonly encountered unsupervised learning problems. Given a set of known \(n\) points in Euclidean space, the goal is to partition them into \(k\) clusters (each characterized by a center), such that the sum of square of distances to their closest center is minimized. Dasgupta  and Aloise et al.  showed that the \(k\)-means problem is NP-Hard. The most popular heuristic for \(k\)-means is Lloyd's algorithm , which proceeds by randomly initializing \(k\) centers and then uses iterative updates to find a locally optimal \(k\)-means clustering, which can be arbitrarily bad compared to the globally optimal clustering. The performance of the \(k\)-means algorithm relies crucially on the initialization. Arthur and Vassilvitskii  and Ostrovsky et al.  proposed an elegant polynomial time algorithm for initializing centers, known as \(k\)-means++. Arthur and Vassilvitskii  proved that the expected cost of the initial clustering obtained by \(k\)-means++ is at most \(8(2+ k)\) times the cost of optimal \(k\)-means clustering. Our work generalizes the analysis of Arthur and Vassilvitskii  to the setting where _user's preferences are represented as unknown points and the loss functions are unknown with only bandit access, not necessarily identical, and general as long they satisfy Assumptions 2.1 and 2.2,_ with important examples given in Appendix C.

For a detailed discussion on more related works please see Appendix A.

**Notation and Terminology.** For a symmetric matrix \(\) and any vector \(x^{d}\), we denote its Mahalanobis norm by \(\|x\|_{}=x}\). The generalized eigenvalues for a pair of symmetric matrices \(\) and \(\) are denoted by \((,)\), defined as the solutions of \(\) for the generalized eigenvalue problems \(v=v\)[16; 14]. Specifically we use \(_{}(,)\) to denote minimum generalized eigenvalue for the matrix pair \(,\). The loss for a user \(i\) given service \(^{d}\) is denoted by \(_{i}(,_{i})\) where \(_{i}\) parameterizes the user's preference. For a set of users \(\) (e.g., \(=[n]\) denotes a set of \(n\) users) and a set of services \(=\{_{1},,_{k}\}^{d}\), the total loss is defined as \((,)=_{i}_{j[k]}_{i}(_{j},_{i})\).

Problem Setup

We make the following assumptions about the functional form of \(_{i}\), and state several examples of function classes satisfying these properties. Note that the designer/provider doesn't need to know the functional form of \(_{i}\), and knowledge about \(_{i}\) is obtained through bandit feedback via observing the scalar values \(_{i}(,_{i})\) for different \(\), where \(\) parameterizes the services.

**Assumption 2.1** (Unique Minimizer).: The loss function satisfies the following equivalence: \(_{i}(,_{i})=0=_{i}\).

This assumption implies that unless all users have identical preference parameters, there doesn't exist a single service parameter \(\) that simultaneously minimizes every user's loss. Thus providing multiple services (multiple \(\)'s) where the users choose the one best for them is strictly better than one service for all users.

**Assumption 2.2** (Approximate Triangle Inequalities).: For a pair of users \(i,j\) there exists a finite constant \(c_{ij}>0\) such that for all \(^{d}\) the following hold:

1. \(c_{ij}_{i}(,_{i})_{j}(,_{j})+ _{j}(_{i},_{j})\).
2. \(c_{ij}_{i}(_{j},_{i})_{j}(,_{j})+ _{i}(,_{i})\).

Here \(c_{ij}\) (equal to \(c_{ji}\)) captures the alignment between the preference parameters and loss geometries of two users. Lower values of \(c_{ij}\) indicate less similarity. Item \((i)\) implies that the loss for user \(i\) on any service \(^{d}\) is no worse than (up to a constant factor) the sum of (a) loss of another user \(j\) on using the same service, and (b) the loss of user \(j\) if they were to use user \(i\)'s preference parameter. The latter term (b) can be seen as measuring the similarity between the users' preferences.

For condition \((ii)\) to hold for all \(^{d}\), it must also hold for the service that minimizes the sum of losses of both users using the same service. Suppose that users \(i\) and \(j\) were to exchange preference parameters. Then their loss would be no worse than (up to a constant factor) their minimum total loss, i.e.,

\[c_{ij}_{i}(_{j},_{i})_{^{d}} (_{j}(,_{j})+_{i}(,_{i}) ).\]

Some examples of loss functions and the corresponding constants that satisfy these assumptions include the following (see Appendix C for additional examples and derivations):

* Squared error loss for linear predictors (cf. Section 4).
* The Huber loss on the prediction error: \[_{i}(,_{i})=\|-_{i}\|^ {2},&\|-_{i}\|\\ (\|-_{i}\|-),&\] This loss is used typically in robust estimation tasks. Here \(\|\|\) could be any norm, and we show \(c_{ij}=1/3\).
* The normalized cosine distance: \(_{i}(,_{i})=1-^{}_{i}\) where \(\|\|_{2}=\|_{i}\|_{2}=1\), with \(c_{ij}=\). This is commonly used as a similarity measure in natural language processing applications, for example finding similarity between two documents.
* The Mahalanobis distance: \(_{i}(,_{i})=\|-_{i}\|_{_{i}}\). Different users can have different \(_{i}\) capturing their diverse loss variation, as long as \(_{i}\) is full rank. Here \(c_{ij}=\{_{}(_{i},_{j}),_{}(_{j}, _{i})\}\).
* Any distance metric: This naturally follows from triangle inequality, hence \(c_{ij}=1\).
* Any arbitrary function \(_{i}(,_{i})\) that is \(L_{i}\)-Lipschitz and \(_{i}\)-strongly convex in \(\) with \(c_{ij}=(_{i},_{j})/(L_{i},L_{j})\).

**Objective.** Suppose the users have access to \(k\) services parameterized by \(=\{_{1},,_{k}\}^{d}\). Then, each user \(i\) selects service \(_{l}\) that minimizes their loss, i.e. \(_{i}(,_{i})=_{l[k]}_{i}(_{l}, _{i})\).

As discussed earlier, our goal is to design \(\), such that the sum of losses across users and services is minimized. We define the objective as follows:

\[(,[n])=_{i[n]}_{j[k]}_{i}(_{j},_{i})=_{i[n]}_{i}(,_{i}).\] (2)

**Definition 2.3**.: Define the unknown optimal set of \(k\) services that minimizes the objective to be

\[_{}:=*{argmin}_{||=k}(,[ n]).\]Specifically, \(_{}\) defines a "clustering", meaning a partitioning of the \(n\) users into \(k\) clusters. The cluster \(_{m}\) is the set of all users that prefer the service \(_{m}\) among all the services in the optimal set \(_{}\). In other words, \(_{m}\) is defined as the set of all points such that \(_{m}=\{i[n]_{m}=_{_{i}_{ }}_{i}(_{i},_{i})\}\). If multiple services are equally preferred by a subpopulation, the ties are broken arbitrarily. The resulting set of clusters is denoted by \((_{})=\{_{1},,_{k}\}\).

The are several statistical and computational challenges to this problem.

_Challenge 1_. Since preferences \(\{_{i}\}_{i[n]}\) and loss functions \(\{_{i}\}_{i[n]}\) are unknown and the provider only has zeroth order or bandit feedback access, estimating the objective function \((,[n])\) usually needs a lot of data collected uniformly across the users. This large amount of data is needed before services can be deployed, yet as stated earlier, we are in the situation where we have no data until we deploy services and observe user interactions. Our limited access to user information (via limited queries) makes our setting challenging.

_Challenge 2_. The loss function is non-convex and iterative minimization approaches from a random initialization are susceptible to getting stuck in arbitrarily poor local optima. This means computing the optimal clustering first and then finding the best service for each cluster is NP-Hard.

_Challenge 3_. We do _not_ assume any data separability conditions, for example user preference parameters are drawn from \(k\) well separated distributions. Thus we are unable to exploit underlying structure to reduce sample complexity.

Despite the challenges, in Section 3, we propose an algorithm that is both statistically and computationally efficient, and admits an approximation ratio with respect to the _globally optimal value_, i.e., \((_{},[n])\).

## 3 Algorithm & Main Results

In this section, we present our initialization algorithm with guarantees, Algorithm 1, and describe how the steps of the algorithm arise naturally in the interactive systems under consideration. Since collecting data uniformly across all the \(n\) users can be prohibitively expensive, our goal is to get data from a minimal number of users.

Each iteration of the loop in the algorithm adds a service sequentially and the loop terminates when there are \(k\) services, where \(k\) is a predetermined parameter for the algorithm. We focus on the loop (lines 4-8) in Algorithm 1.

Suppose at time \(t-1\), the set \(_{t-1}\) is the set of current \(t-1\) services. Then, at time step \(t\) the following steps take place.

* **User behavior (line 5).** Given the list of services \(_{t-1}\) users are assumed to choose the best service that minimizes user loss. Users report their losses with respect to the service they choose from the set of existing services \(\{_{i}(_{t-1},_{i})\}_{i[n]}\). In practice, this step requires deploying the services and collecting signals of engagement and utility to determine the loss associated with each user, under the behavioral assumption that users are rational agents that choose the best available service. The provider thus needs to measure each user's loss **only** in their single chosen service.
* **User selection (line 6)** A new user \(l\) is selected with probability proportional to \(_{i}(_{t-1},_{l})\). This ensures that users that are currently poorly served by existing services are more likely to be selected.

* **New Service (line 7-8).** Given a selected user \(l\), the algorithm queries the preference \(_{l}\) of the user and centers the new service at that preference \(_{t}=_{l}\). In practice, this step requires acquiring data about the user in order to learn their preference parameter (this is needed for only \(k\) total users throughout the algorithm). For example, data may be acquired by incentivizing the selected users, via offering discount coupons or free premium subscriptions .

With each iteration the loss of each user is non-increasing; the previous services remained fixed and a user would switch to a new service only if it improves quality or equivalently decreases loss. Since at each iteration, a new service is added, the process terminates after \(k\) steps. Since it is costly to offer and maintain too many different services, we typically have \(k n\).

We now discuss the theoretical properties of the set of services we get at the termination of Algorithm 1.

**Theorem 3.1**.: _Consider \(n\) users with unknown preferences \(\{_{1},,_{n}\}^{d}\), and associated loss functions \(_{i}(,)\) satisfying Assumptions 2.1 and 2.2, with bandit access. Let \(_{}^{d}\) be the set of \(k\) services minimizing the total loss and \((_{})\) the resulting partitioning of users (Definition 2.3). If Algorithm 1 is used to obtain \(k\) services \(_{k}\), then the following bound holds:_

\[_{_{k}}[(_{k},[n])] K_{}(2 + k)(_{},[n]),\]

_where the expectation is taken over the randomization of the algorithm and \(K_{}\) is equal to_

\[_{(_{})}}_{i}c_{ij}}(_{j}_{i}}).\] (3)

A detailed proof is presented in Appendix D; we summarize the main ideas here. The intuition is that a chosen user's preference parameter is typically a good representative for other users in its cluster. Thus adding a service parameterized by the chosen user's preferences generally reduces the losses of users in this cluster. Subsequently we are less likely to pick another user from the same cluster. The \( k\) factor is due to clusters from which users were never picked.

A similar proof approach was used by Arthur and Vassilvitskii  in the context of the \(k\)-means problem, by sequentially placing centers on _known_ points sampled with probability proportional to the point's squared distance to its closest existing center. A key novelty of our analysis is to capture the _alignment_ of diverse loss geometries across users in a large class of functions, specifically understanding how user similarities \(c_{ij}\) affect the approximation ratio.1

**Key characteristics of \(K_{}\):** The following are essential characteristics of the term \(K_{}\).

1. All terms in \(K_{}\) depend on the local clusters in the unknown optimal clustering \((_{})\).
2. The constant \(_{j}|}_{i}c_{ij}\) captures the user whose loss geometry is _least similar_ to the average loss geometry of the cluster they belong to (recall Assumption 2.2.i).
3. The constant \(_{j}|}_{i}}\) captures the user whose preference is _least similar_ to the optimal service parameter of the cluster they belong to (recall Assumption 2.2.ii).
4. Even within a cluster all terms are averages, so a few poorly aligned pairs of users don't hurt the bound if the cluster sizes are large.

**Fair objective.** While minimizing the total loss is beneficial from the provider's point of view in keeping users satisfied on average, it is undesirable in human-centric applications if the provided services result in unfavorable or harmful outcomes towards some demographic groups.

Suppose the \(n\) users come from \(m\) different demographic groups (\(m\) is typically small, say racial groups, gender). We denote the groups as \(=\{_{1},,_{m}\}[n]\). The fairness objective is defined as the maximum average loss suffered by any group:

\[(,)=_{i[m]}(,_{i})/| _{i}|.\] (4)

 defined this objective in the context of fair \(k\)-means where the points and group identities are _known_ and gave a _non-constructive_ proof that if a \(c-\)approximate solution for \(k\)-means exists, it is \(m c\)-approximate for fair \(k\)-means. For the fairness objective, we slightly modify our algorithm, by simply reweighting the probability to select an user by the inverse of the size of their demographic group to result in Fair AcQUIre (Algorithm 2 in Appendix E).

**Theorem 3.2**.: _Consider \(n\) users with unknown preferences \(\{_{1},,_{n}\}^{d}\), and associated loss functions \(_{i}(,)\) satisfying Assumptions 2.1 and 2.2 with bandit access. Suppose these users belong to \(m\) demographic groups \(=\{_{1},,_{m}\}[n]\). Let \(_{}^{d}\) be the set of \(k\) services minimizing the fairness objective \(\) given in (4). If Algorithm 2 is used to obtain \(k\) services \(_{k}\), then the following bound holds:_

\[_{_{i}}[(_{k},)] mK_{} (2+ k)(_{},),\]

_where the expectation is taken over the randomization of the algorithm and \(K_{}\) is defined in (10)._

## 4 Generalization in Linear Predictors

In practical settings, a provider would want to design services that not only keep the subscribed users satisfied but also attract new users to subscribe by generalizing the services to users it has never interacted with before. Now instead of considering \(n\) users, suppose that each \(i[N]\) represents a subpopulation with its own (sub-Gaussian) distribution of features, and the provider can interact with finite samples \(n_{i}\) from these distributions. A question that arises is whether we can deal with this finite-sample-from-subpopulations scenario, and how does the number of samples affect the algorithm's output to unseen users. In this section, we answer this question for the special case of linear predictors (i.e., regression loss).

In this section we restrict ourselves to the special case of linear prediction tasks, where the goal is to accurately predict the score of a user as a linear function of their features. The score for a user in the \(i^{}\) subpopulation with zero-mean random feature \(x^{d}\) is generated as \(y=_{i}^{}x\) where both the true linear regressor \(_{i}^{d}\) and the feature covariance \(_{x}[xx^{}]=_{i}\) are unknown. Suppose a service uses a linear regressor \(^{d}\), to predict the score for this user as \(^{}x\). The loss for this subpopulation for this service is defined as the expected squared error between the predicted and actual scores, i.e., \(_{i}(,_{i})=_{(x,y)}[(^{}x-y)^{2}]= \|-_{i}\|_{_{i}}^{2}\).

**Assumption 4.1**.: For subpopulation \(i\), features are independent draws from a zero-mean sub-Gaussian distribution. For a random feature \(x^{d}\) and for any \(u^{d}\), such that \(\|u\|_{_{i}}=1\), \(u^{}x\) is sub-Gaussian with variance proxy \(_{i}^{2}\).2

**Assumption 4.2**.: We assume that the decision to choose between different services happens at a subpopulation level and not an individual level.

To illustrate Assumption 4.1, consider the example of a provider that offers personalized services to schools (subpopulations) such as online library resources wherein the service provider queries students about the experience. Each school typically has a considerable number of students, but only a subset of them may actively respond to such queries. Once a school selects the service, it is made available to all students, and the provider could implement a system where students are encouraged to fill out a feedback form after using their service.

Suppose only \(n_{i}\) users from subpopulation \(i\) are subscribed to the services. Thus, upon choosing a service parameterized by \(^{d}\) the provider observes an _empirical loss_, which is given by

\[}_{i}(,_{i})=}_{j[n_{i}]} (^{}x_{i}^{j}-y_{i}^{j})^{2},\]

where \(\{(x_{i}^{j},y_{i}^{j})\}_{j[n_{i}]}\) are private unknown features and scores of the users. We stress that the service gets to see the value of the user loss function at the deployed \(\) (bandit feedback), but not the features of each subpopulation.

**Assumption 4.3**.: The number of users from each subpopulation is greater than the dimension of the linear predictor, i.e. \(n_{i} d\) for all \(i[N]\).

In this setting, given a set of services parameterized by \(_{t-1}=\{_{1},,_{t-1}\}\) the Steps 5-6 of Algorithm 1 proceed with these finite sample averages \(}_{i}(_{t-1},_{i})=_{j[t-1]}}_{i}(_{j},_{i})\). In

[MISSING_PAGE_EMPTY:8]

The dataset has \(N=7025\) subpopulations defined by area zip codes. We use \(k\) linear predictors (as services) with user features (education, income, transportation mode, age etc). Refer to Appendix G for details on data pre-processing. The features and commute times are _unknown a priori_ to the provider. At time step \(t k\), suppose that the provider offers a set of services parameterized by \(_{t-1}\). The provider observes the losses (squared prediction error of their commute times as discussed in Section 4) across different subpopulations \(\{}_{i}(_{t-1},_{i})\}_{i[N]}\). Then the provider selects a subpopulation \(l[N]\), to get the user feature and commute time data and then estimates \(_{l}\) via least squares regression. This selection can be done via our proposed method or one of the baseline strategies discussed later. The provider then centers its next service on \(_{l}\) and updates the list of offered services \(_{t}=_{t-1}_{l}\). Note that in this process the provider only observes features and commute times of users in the \(k\) selected subpopulations and \(k N\). In Figure 2 we compare runtimes, and observe that even with 1 billion users, AcQUIre takes 300 sec, whereas the greedy and epsilon greedy methods take \(>10^{5}\) sec even for 10 million users. With 5000 services, AcQUIre takes \(<900\) secs, whereas the runtimes for greedy and epsilon greedy are in the range of \(10^{5}\) secs.

**Movie Recommendations.** We conduct a semi synthetic experiment based on the widely used Movielens10M data set  containing 10000054 ratings across 10681 movies by 71567 viewers. We hold out the top \(m=200\) movies and pre-process the data set to divide viewers into \(N=1000\) user subpopulations based on similarity of their ratings on the remaining movies (cf. Appendix G). Our goal is to evaluate the generalization performance of the baselines to viewers that the provider has never interacted with before. Thus during the service initialization phase, only half of the users in each of the \(N\) subpopulations interact with the provider (train set), and we evaluate the performance of the algorithm by the loss incurred by the initialized services on data of the other half of the users that no prior interaction with the provider (test set). For subpopulation \(i[N]\), the solution to the following optimization problem denotes the user and item embedding:

\[(U_{i},_{i})=_{(U,)^{n_{i}x^{d}^{d  m}}}\|(U-r_{i})_{_{i}^{}}\|_{2}^{2},\] (5)

where \(r_{i}\) is the true user ratings and \(_{i}^{}\) is the list of movies rated by the users in subpopulation \(i\). Since \(r_{i}\) is a sparse matrix we consider the prediction error only on the movies they rated, i.e. \(_{i}^{}\). User loss / dissatisfaction for a recommendation model, parameterized by \(^{d m}\), is captured by the excess error, namely

\[_{i}(,_{i})=\|(U_{i}-r_{i})_{_{i}^{}}\|_{2}^{2}-\|(U_{i}_{i}-r_{i})_{_{i}^{}}\|_{2}^ {2}.\] (6)

This value typically indicates how unhappy users are with the suggested movies with respect to their preferred movies. The provider initially doesn't know the user ratings. At time step \(t k\), suppose the provider offers a set of recommendation models \(_{t-1}\). Users choose the service with the best recommendations and the provider observes the losses across different subpopulations \(\{_{i}(_{t-1},_{i})\}_{i[N]}\). Then the provider selects a subpopulation \(l[N]\) to estimate \(_{l}\) via (5). This selection can be done via our proposed method or one of the baseline strategies discussed below. The provider then centers its next model on \(_{l}\) and updates the list of offered models \(_{t}=_{t-1}_{l}\). In this process the provider only observes movie ratings of the users in the \(k\) selected subpopulations. Once the services are initialized we evaluate the performance on the movies rated in the test set denoted by \(\{_{1}^{},,_{N}^{}\}\).

**Baselines.** Both our tasks iterate through the steps of observing _User Behavior_, _User Selection_ to gather data, designing _New Service_ to update set of offered services. Through our experiments we wish to empirically evaluate different **User Selection** strategies with respect to AcQUIre (line

Figure 2: Runtimes for AcQUIre and baselines as number of users (\(N\)) and services (\(K\)) vary.

6 in Algorithm 1). The different user selection strategies result in the following baselines: (i) Random: \(P(l=i)=1/n\), (ii) Greedy: \(l=*{argmax}_{i[n]}_{i}(_{t-1},_{i})\), (iii) Epsilon Greedy: \(l=*{argmax}_{i[n]}(_{i}(_{t-1},_{i})+ _{i})\) where \(_{1},,_{n}\) denotes zero mean i.i.d. noise. Given that the Census Dataset comprises various racial demographic groups of varying sizes (with the smallest group being ten times smaller than the largest group), and considering our interest in the fairness objective (4), we explore incorporating these size imbalances into our algorithms. Consequently, we introduce three additional baselines, wherein the selection criteria are scaled by the corresponding group sizes: (iv) Balanced Random, (v) Balanced Greedy, and (vi) Balanced Epsilon Greedy. We benchmark them against Fair AcQUIre (Algorithm 2) which has guarantees as as stated in Theorem 3.2.

**Evaluation:** Each algorithm is run for 500 initialization seeds, the averages are reported in Figure 1.

**Runtimes:** We compare the runtimes of AcQUIre with the baselines, and study the affect of the number of users \((N)\) and number of services \((K)\) in Figure 2. We find the runtimes of AcQUIre to be of the similar order of magnitude of random initialization, meanwhile performing much better than random, and the much slower greedy and epislon greedy initialization schemes.

**Impact of Initialization:** Once a set of services are initialized, with more user interactions, the provider updates the services on new data to improve the quality (indicated by the reduction in total loss). To evaluate the importance of initialization, we conducted experiments using two different optimization algorithms: (i) Generalized k-means: The services are iteratively updated by training each service on the current group of subpopulations selecting it. After updating the service parameters, the subpopulations reselect their best service. This process repeats until convergence. (ii) Multiplicative weights update : Similar to k-means, but each subpopulation can have users choosing different services simultaneously. Both generalized k-means and the multiplicative weights update guarantee that the total loss reduces over time .

In our experiments, we initialize a set of services using AcQUIre and other baseline methods, then let both optimization algorithms run until convergence. We plot the total loss versus the number of iterations (Figure 3). Our results demonstrate that AcQUIre leads to: (1) faster convergence, and (2) lower final loss (initializing with AcQUIre converges to lower losses; other initialization schemes are prone to being stuck in suboptimal local minima). These findings highlight the significance of a robust initialization strategy. By starting with a better initial configuration, the optimization algorithms can more effectively reach higher quality solutions.

## 6 Conclusion

We study the problem of initializing services for a provider catering to a user base with diverse preferences. We address the challenges of unknown user preferences, only bandit (zeroth-order) feedback from the losses, and the non-convexity of the optimization problem, by proposing an algorithm that designs services by adaptively querying data from a small set of users. We also consider the fairness aspect of such design in human centric applications. Our proposed algorithm has theoretical guarantees on both the average and fair loss objectives. There are open questions relating to quantifying the robustness of the proposed initialization algorithm to noisy observations, perturbations, or outliers in the finite sample case when the feature distribution is heavy-tailed, which is a direction for future work.

Figure 3: We study the importance of initialization in both the convergence rate and quality of converged solution of optimization algorithms. We find AcQUIre converges both faster and to a lower total loss across optimization methods (kmeans and multiplicative weights) as well as datasets.