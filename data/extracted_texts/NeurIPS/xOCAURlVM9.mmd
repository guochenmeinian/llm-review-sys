# Assembly Fuzzy Representation on Hypergraph

for Open-Set 3D Object Retrieval

 Yang Xu\({}^{1}\), Yifan Feng\({}^{1}\), Jun Zhang\({}^{2}\), Jun-Hai Yong\({}^{1}\), and Yue Gao\({}^{1}\)

\({}^{1}\)BNRist, THUIBCS, KLISS, BLBCI, School of Software, Tsinghua University, China

\({}^{2}\)Tencent AI Lab

{xuyang9610,evanfeng97}@gmail.com, junejzhang@tencent.com,

{yongjh,gaoyue}@tsinghua.edu.cn

Corresponding author

###### Abstract

The lack of object-level labels presents a significant challenge for 3D object retrieval in the open-set environment. However, part-level shapes of objects often share commonalities across categories but remain underexploited in existing retrieval methods. In this paper, we introduce the Hypergraph-Based Assembly Fuzzy Representation (HAFR) framework, which navigates the intricacies of open-set 3D object retrieval through a bottom-up lens of _Part Assembly_. To tackle the challenge of assembly isomorphism and unification, we propose the Hypergraph Isomorphism Convolution (HIConv) for smoothing and adopt the Isomorphic Assembly Embedding (IAE) module to generate assembly embeddings with geometric-semantic consistency. To address the challenge of open-set category generalization, our method employs high-order correlations and fuzzy representation to mitigate distribution skew through the Structure Fuzzy Reconstruction (SFR) module, by constructing a leveraged hypergraph based on local certainty and global uncertainty correlations. We construct three open-set retrieval datasets for 3D objects with part-level annotations: OP-SHNP, OP-INTRA, and OP-COSEG. Extensive experiments and ablation studies on these three benchmarks show our method outperforms current state-of-the-art methods.

## 1 Introduction

With the growing accessibility of 3D data, 3D object retrieval (3DOR) has emerged as an important area of interest in computer vision . The key objective of 3DOR is to establish connections between query and target samples via model training. Despite significant progress in recent years enhancing the development of 3DOR, most existing methods are still based on the closed-set assumption, where all categories encountered in the testing phase have been seen during training . However, training sets can not cover all potential categories in real-world applications , which hinders accurate retrieval for unseen categories. Although object-level categories are difficult to cover, the part-level shapes of objects across object-level categories often share commonalities  among objects, which may provide sufficient semantic information of the object . However, this part-level method still remains underexploited on assembly-based representation for open-set retrieval.

3D parts, as essential components in shape representation and analysis, have the capability to represent potential information for both semantic  and geometric  level tasks. Recently, there has been an increasing application of assembly-based methods in the realm of 3D vision . From a geometric perspective, current methods for 3D part assembly impose strict constraints on thecategories or quantities of parts , presenting a substantial challenge for implementation in an open-set environment. These methods often overlook the isomorphism and correlations between parts of the same object  during semantic embedding. This oversight diminishes the generalization capabilities of the representation model and exacerbates the distribution skew of unseen categories during open-set learning [47; 27]. In this paper, we explore the part-assembly representation method from both semantic and geometric perspectives to mitigate the distribution skew of unseen categories, aiming to enhance the generalization performance for open-set 3D object retrieval.

Distinct from existing 3D shape assembly or open-set learning methods, the assembly-based open-set retrieval task emphasizes global-level semantics in object representation and requires enhanced generalization of geometric assembly. This leads to several challenges for assembly-based open-set retrieval, including: **First, the difficulty of achieving assembly isomorphism for part features**. While part features can effectively capture the categorical information of objects, direct fusion for multiple parts may lead to inconsistencies arising from geometric factors, including the order of input and the presence of repeated parts. Consequently, there is a strong motivation to achieve assembly isomorphism for part features with geometric-semantic consistency. **Second, the difficulty in achieving assembly unification across different parts** entails mapping and integrating part embeddings from the local-part space to the global-object space. **Third, the difficulty in open-set category generalization against distribution skew**, which requires spatial propagation and generalization for object embeddings from the seen certainty to unseen uncertainty space.

Addressing the aforementioned challenges, we explore a method for open-set retrieval tasks through a bottom-up lens of _Part Assembly_. As shown in Figure 1, we introduce the Hypergraph-based Assembly Fuzzy Representation (HAFR) framework for assembly-based open-set 3DOR. On one hand, to tackle the challenge of assembly isomorphism and unification, we first propose the Hypergraph Isomorphism Convolution (HIConv) layer for feature smoothing, and then we adopt the Isomorphic Assembly Embedding (IAE) module for embedding integration with geometric-semantic consistency. On the other hand, to overcome the difficulty in category generalization, we construct a leverage hypergraph based on the local-certainty and global-uncertainty correlations. This structure captures potential leveraged correlations between seen and unseen categories for propagation. Besides, we adopt the Structure Fuzzy Reconstruction (SFR) module to exploit the fuzzy representation approach for open-set category generalization. Our contributions are summarized as follows:

* We explore a method to navigate the intricacies of open-set 3D object retrieval through a bottom-up lens of _Part Assembly_, and we construct three 3D point cloud datasets with multiple part annotations for benchmarking.
* We propose the HAFR framework for assembly-based open-set 3D object retrieval tasks, including the Isomorphic Assembly Embedding (IAE) and the Structured Fuzzy Reconstruction (SFR) modules, which are designed to generate assembly embeddings with geometric-semantic consistency and overcome the distribution skew of unseen categories.

Figure 1: Illustration of the assembly-based open-set 3DOR task and proposed HAFR framework. Given 3D objects of unseen categories, our method takes several part features and generates the assembly embedding isomorphically for each object. Then fuzzy embeddings are generated via leverage propagation and fuzzy reconstruction for open-set retrieval with unseen categories generalization.

* We propose the Hypergraph Isomorphism Convolution (HIConv) and a leverage hypergraph structure to capture the high-order correlations within and among objects, utilizing them for assembly isomorphism and open-set category generalization.
* Extensive experiments are conducted on the three benchmarks for evaluation, demonstrating the superiority of HAFR over current state-of-the-art 3D object retrieval methods.

## 2 Related Work

### 3D Object Retrieval

Most current 3D object retrieval methods operate under the closed-set assumption, meaning that the training and testing sets exhibit the same distribution of categories. These methods are divided into single-modal and multi-modal types. Single-modal 3D object retrieval focuses on identifying similar objects within a single modality of 3D data. For example,  and  use a view-based graph model to generate aggregated embeddings from multi-view data.  introduces a triplet-center loss to cluster objects of the same category and separate those of different categories. HGNN  employs a hypergraph-based structure to capture high-order correlations among objects for improved embeddings. Multi-modal retrieval methods [26; 22; 43; 44; 7; 2] use weighted fusion or feature fusion networks to aggregate embeddings from different modality-specific features. Additionally, CMCL  proposes a cross-modal center loss to minimize differences across various 3D modalities using common center embeddings.

### Open-Set Learning

Open-set learning focuses on conducting machine learning research in scenarios where key factors are variable .  introduces the Semantic Shift Benchmark (SSB) for open-set recognition.  proposes a "none-of-above" classifier to determine if a sample belongs to known categories.  presents an adversarial method to minimize the overlap between known and unknown distributions. Additionally, several open-set recognition methods for 3D object learning have been proposed [3; 16; 1; 48]. However, retrieval tasks in open-set scenarios are more practical than recognition due to the fundamentals of representation. Only a few methods [8; 23; 40; 39; 38] tackle the open-set 3DOR task, focusing on structure learning networks while neglecting the intricacies of the open-set environment.

### 3D Shape Assembly

Much research in computer graphics has concentrated on assembly representation for the reconstruction , analysis , and generation  of 3D shapes. As for the assembly-related method for retrieval, most existing methods primarily focus on establishing relationships between parts of one object and parts of other objects , then utilize these connections for shape analysis  or part retrieval . Although these methods have achieved satisfactory results, they rarely concentrate on the higher-order semantic connections from parts to objects, which makes them challenging to apply in 3D object retrieval. Additionally, their geometric constraints also limit their application in open-set environments.

## 3 Problem Setup

### Open-Set 3D Object Retrieval

Given 3D objects from the query set \(_{q}\), the 3D object retrieval (3DOR) task is to find similar samples from the target set \(_{t}\). The core approach for the 3DOR task is to learn the relationship between query samples and target samples from the training set \(_{trn}\). Each 3D object can be denoted as \((s_{i},y_{i})\), the \(y_{i}=\{c_{j}\}_{j=1}^{Y}\) is the category label associated with the 3D object sample \(s_{i}\).

In the open-set environment for 3DOR, all categories of samples in the testing set have not been learned in the training set, each retrieval sample is from unseen categories for the model, termed as _Open-Set Retrieval_. Specifically, the open-set settings means that the testing set \(_{tes}=\{_{q},_{t}\}\) and the training set \(_{trn}\) are drawn from the different distributions. For the testing set \(\{(s_{i},_{i})\}_{i=1}^{T}=\{_{q},_{t}\}\) and the training set \(_{trn}=\{(s_{i},y_{i})\}_{i=1}^{L}\), the category space of them are not the same indicating \(_{i}}=\{_{j}\}_{j=1}^{}\), \(y_{i}=\{c_{j}\}_{j=1}^{Y}\), and \(}=\).

### Assembly Representation for Retrieval

Typically, each 3D object can be decomposed into multiple parts based on its shape and semantic information, and it can be regarded as a model assembled from these parts, _i.e._, the doors, roofs, hoods, and wheels of cars, the seats, backs, arms, and legs of the chairs. Face the emergence of the open-set environment with incomplete or missing class labels, the assembly representation based on multiple local parts may provide enough semantic information than global object features for retrieval. We termed this presentation for open-set 3DOR as _Assembly Representation_:

\[s_{i}=\{\{p_{i}^{r}\}_{r=1}^{P}\}_{i=1}^{N},\] (1)

where \(\) denote the set of 3D objects, \(s_{i}=\{p_{i}^{r}\}_{r=1}^{P}\) denotes a 3D object represented by \(P\) semantic parts, \(N\) denotes the number of samples in \(\).

Consequently, the assembly-based open-set 3DOR aims to design a method to retrieve similar samples of query in the testing set \(_{tes}=\{(\{p_{i}^{r}\}_{r=1}^{P},_{i})\}_{i=1}^{T}=\{ _{q},_{t}\}\), based on the data and knowledge in the training set \(_{trn}=\{(\{p_{i}^{r}\}_{r=1}^{P},y_{i})\}_{i=1}^{L}\). The assembly-based open-set 3DOR by multiple parts aims to minimize the expected risk:

\[f^{*}=}{argmin}\,_{(D_{i},D_{ j})(_{q},_{t})} [_{\{_{i}_{j}\}}e^{-\|f(\{p_{i}^{r}\}_{r=1}^{P})-f (\{p_{j}^{r}\}_{r=1}^{P})\|_{2}}.\] (2) \[.+_{\{_{i}=_{j}\}}(1-e^{-\|f(\{p_{i}^{r}\} _{r=1}^{P})-f(\{p_{j}^{r}\}_{r=1}^{P})\|_{2}})],\]

where \(D_{i}=(\{p_{i}^{r}\}_{r=1}^{P},n_{i},_{i})\) and \(D_{j}=(\{p_{j}^{r}\}_{r=1}^{P},n_{j},_{j})\) are the object samples selected from the query set \(_{q}\) and target set \(_{t}\). \(_{\{\}}\) denotes the indicator function, which evaluates to \(1\) when the specified condition holds true and \(0\) otherwise. The embedding function \(f:=\{p_{i}^{r}\}_{r=1}^{P} v_{i}\) maps multiple parts \(\{p_{j}^{r}\}_{r=1}^{P}\) of an object to an assembly representation vector \(v_{i}^{d}\), facilitating similarity-based retrieval. \(\) denotes the hypothesis space of the embedding function. The \(_{2}\) norm function \(_{2}\) is used as a distance metric to measure the Euclidean distance between two vectors.

## 4 Methodology

### Overall Framework

As shown in Figure 2, the proposed Hypergraph-Based Assembly Fuzzy Representation (HAFR) framework is composed of two modules: _Isomorphic Assembly Embedding (IAE)_ and _Structured

Figure 2: An overview of the Hypergraph-Based Assembly Fuzzy Representation (HAFR) framework for assembly-based open-set 3D object retrieval. Our framework is composed of the Assembled Isomorphism Embedding (IAE) and Structured Fuzzy Reconstruction (SFR) modules, which are designed for geometric-semantic consistent integration and fuzzy-aware generalization, respectively.

_Fuzzy Reconstruction (SFR)_. The framework takes the basic features of different parts as input. In the IAE stage, the multiple features are assembled isomorphically by the Hypergraph Isomorphism Convolution (HIConv), and the assembly embeddings are generated from multiple parts. Next, in the SFR stage, the leverage hypergraph structure is constructed based on the local-certainty and global-uncertainty correlations. Guided by this structured open-set distribution, hypergraph convolution is adopted for propagation implicitly from seen categories to unseen categories. Finally, the memory bank is adopted for fuzzy-aware reconstruction and fuzzy embedding generation to further overcome openness during open-set retrieval.

### Isomorphic Assembly Embedding

The IAE module is designed here to obtain assembly embeddings with geometric-semantic consistency from multiple parts. Specifically, the IAE comprises a hypergraph-based isomorphism layer and assembly auto-encoders as shown in the left side of Figure 2. We proposed the _Hypergraph Isomorphism Convolution (HIConv)_ in the layer to impart geometric-semantic consistency to part features, overcoming the bias introduced by the order of parts during assembly representation. The assembly auto-encoders are utilized to get the assembly embedding from multiple part features.

The IAE module takes the basic part features \(\{\{f_{i}^{r}\}_{r=1}^{P}\}_{i=1}^{N}\) (\(f_{i}^{r}^{N d_{f}}\)) of \(N\) objects with \(P\) parts. In this paper, we use the average point feature of each region extracted by 3D point cloud part segmentation network  as shown in Figure 4.1. The hypergraph isomorphism layer constructs an assembly hypergraph structure \(_{a}\) and generates isomorphism embeddings \(c_{i}^{r}\) under the guidance of this structure. The assembly auto-encoders \(_{a}\) encode the multi-part features of 3D objects and get the assembly embeddings \(u_{i}\) by integration function.

#### 4.2.1 Isomorphism Smoothing

Although part features have the potential to adequately represent the category information of every object, direct fusion for multiple parts may lead to inconsistencies arising from geometric factors, including the order of input and the presence of repeated parts. The HIConv are utilized to impart geometric-semantic consistency during part assembly, aiming to generate isomorphism embeddings from independent-part to correlated-object distribution, by the correlation-based smoothing under the guidance of the assembly hypergraph structure.

A hypergraph can be represented as \(=\{,\}\), where \(\) and \(\) are the vertex set and the hyperedge set, respectively. In the hypergraph of HIConv, the basic part features \(f_{i}^{p}\) are treated as the vertices \(_{f}=_{d=1}^{D}\{f_{i}^{d}\}_{i=1}^{N}\). Then the isomorphism hyperedges \(_{o}\) are constructed as the subset of vertices that are from the same object:

\[_{o}=\{_{v}(i) i\{1,,N\}\}\] (3)

where \(_{v}(i)\) denotes all vertices of the \(i\)-th object. In this way, we obtain \(N\) hyperedges and \(N\) is the number of objects. The assembly hypergraph is constructed as \(_{a}=\{_{f},_{o}\}\) after getting vertices and hyperedges.

After the construction of the assembly hypergraph, the HIConv is designed to bridge the geometry and semantic correlations for isomorphic smoothing. For the convenience of convolution, we use the incidence matrix \(\{0,1\}^{||||}\) to represent the hypergraph, where the hyperedges are the columns of \(\), and \((v,e)=1\) if vertex \(v\) are contained in hyperedge \(e\). Inspired by  and , the HIConv is designed to leverage the geometric-semantic collaborative information under the

Figure 3: Illustration of input basic part features for HAFR.

guidance of assembly hypergraph:

\[}_{f}=((1+)_{f}+( _{v}^{-}_{e}^{-1}^{} _{v}^{-}_{f}_{HIConv})),\] (4)

where \(\) denotes the incidence matrix of the hypergraph \(_{a}\), respectively. \(_{v}\) and \(_{e}\) are the diagonal degree matrices for vertices and hyperedges, respectively. \(\) denotes a learnable parameter and \(_{HIConv}\) is the learnable matrix for HIConv. After the HIConv, the isomorphism embeddings \(}_{f}=\{\{c_{i}^{r}\}_{r=1}^{P}\}_{i=1}^{N}\) are generated from independent-part to correlated-object space.

#### 4.2.2 Assembly Embedding

The IAE module first utilizes assembly auto-encoders \(_{a}\) to encode the isomorphism embeddings into a latent code space for each part, then employs the isomorphism loss to pull the different part codes together to ensure encoded embeddings from the same object together. Besides, the intra-part and inter-part reconstruction loss are proposed to reduce information loss during compression.

Specifically for the \(_{a}\), we have \(u_{i}^{r}=^{r}(c_{i}^{r})\) and \(_{i}^{r}=^{r}(u_{i}^{r})\), where \(c_{i}^{r}^{d_{f}}\) denote isomorphism embeddings of parts, \(u_{i}^{r}^{d_{u}}\) denote the unified embeddings compressed from isomorphism embeddings of different parts. The encoder and decoder are defined as \(^{r}:=_{p}_{a}\) and \(^{r}:=_{a}_{p}\), which map the representation between local-part space \(^{p}\) to global-assembly space \(^{a}\).

After the generation of unified embeddings \(u_{i}^{r}\) for each part, the IAE module employs an integration function \(()\) to obtain the assembly embeddings integrated from all parts of the same object:

\[u_{i}=(\{u_{i}^{r}\}_{r=1}^{P})\] (5)

#### 4.2.3 Loss Function for the IAE

For better isomorphism smoothing and assembly embedding, we adopt the Assembly Loss \(_{as}\) and the Cross-Part Loss \(_{xp}\) for the IAE module, which is designed to pull the distance and prompt the generalization performance across parts, respectively:

\[_{as}=_{k=1}^{R}_{l=k+ 1}^{R} u_{i}^{k}-u_{i}^{l}_{2},\] (6)

\[_{xp}=_{k=1,l k}^{D}(  c_{i}^{k}-_{i}^{k}_{2}+ c_{i}^{k}-^{l}( ^{k}(c_{i}^{l}))_{2}),\] (7)

where \(_{2}\) is the \(_{2}\) norm, \(u_{i}^{k}\) and \(u_{i}^{l}\) are both the unified embeddings but from different parts of the same object, \(^{k}\) is the encoder of \(k\)-th part and \(^{l}\) is the decoder of \(l\)-th part.

The loss function for IAE is constructed by the balanced combination of the two losses: \(_{IAE}=_{as}+(1-)_{xp}\), where \(\) is the hyper-parameter to trade-off between them.

### Structured Fuzzy Reconstruction

Although the IAE module generated the assembly embeddings from multiple parts, the distribution skew across seen and unseen categories still affects the performance of open-set retrieval. As shown in Figure 2, we proposed the SFR module for generalization. The SFR module first constructs a leverage hypergraph to model the local-certainty and global-uncertainty correlations. Then SFR employs hypergraph convolution for propagation from seen categories to unseen categories based on the implicit leveraged structure. After that, the memory bank is adopted to reconstruct the propagation embeddings into fuzzy space to further overcome openness during open-set retrieval.

#### 4.3.1 Leverage Propagation

To get the most out of potential correlations from seen categories, the leverage hypergraph is designed here. As shown in Figure 2, the assembly embeddings \(u_{i}\) are treated as the vertices \(_{u}=\{u_{i}\}_{i=1}^{N}\) in the leverage hypergraph, and the hyperedges are constructed from two perspectives: local-certainty and global-uncertainty correlations.

The local-certainty hyperedges \(_{c}\) are constructed based on the category observability, which is defined as \(_{c}=\{C_{v}(y) y\}\), where \(C_{v}(y)\) denotes the subset of vertices that belong to the seen categories \(\). For the global-uncertainty hyperedges \(_{u}\), we construct them by linking each vertex and its \(K-1\) neighbor vertices: \(_{u}=\{K_{_{k}}(v) v\}\), where \(K_{_{k}}(v)\) denotes the top-\(k\) nearest neighbor set of vertex \(v\). In this way, we obtain one local-certainty hyperedge and \(N\) global-uncertainty hyperedge. The leverage hypergraph is constructed by \(_{lev}=\{_{u},_{c}_{u}\}\).

After the construction of the leverage hypergraph, we utilize the modified hypergraph convolution from  for embedding propagation.

\[}_{u}=(_{v}^{-} _{e}^{-1}^{}_{v}^{-} _{u}_{lev}),\] (8)

where \(\) denotes the incidence matrix of the leverage hypergraph \(_{lev}\), \(_{v}\) and \(_{e}\) are the diagonal degree matrices for vertices and hyperedges, respectively. \(_{lev}\) denotes the learnable matrix for the HGNNConv, \(}_{u}\) are the propagation embeddings and \(}_{u}=\{p_{i}\}_{i=1}^{N}\).

#### 4.3.2 Fuzzy Reconstruction

To overcome the distribution skew caused by the open-set environment, the memory bank is adopted here to reconstruct the propagation embeddings to fuzzy space. The memory bank is designed to store a large amount of fuzzy representations with uniform distribution. Specifically, the memory bank \(\) is composed of \(Z\) invariant memory anchors \(m_{j}\) for 3D objects.

\[=\{m_{j}^{u} j=1,,Z\}\] (9)

Given the propagation embedding \(_{i}\) of the each 3D object, the activation score \(s_{i,j}\) are calculated for every memory anchor \(m_{j}\) in \(\) by \(s_{i,j}=\|_{i}-m_{j}\|_{2}\), where \(\|\|_{2}\) is the \(_{2}\) norm for distance metric, \(s_{i,j}\) denotes the activation score of each anchor. Then we use the normalization of activation scores \(s^{}_{i,j}\) to rebuild the propagation embedding into fuzzy space and get fuzzy embeddings \(z_{i}\) by:

\[z_{i}=_{j=1}^{Z}s^{}_{i,j}m_{j}\] (10)

#### 4.3.3 Loss Function for the SFR

In the SFR stage, we adopt the Cross-Entropy Loss \(_{ce}\) and Fuzzy Reconstruction Loss \(_{fz}\):

\[_{fz}=_{i}-z_{i}_{2},\] (11)

\[_{ce}=-_{k=1}^{Y}n_{i,k}(p_{i,k})+n_ {i,k}(q_{i,k}),\] (12)

where \(p_{i,k}=_{i,k}}}{_{i=1}^{Z}e^{_{i,k}}}\) and \(q_{i,k}=}}{_{k=1}^{Z}e^{z_{i,k}}}\) denote the prediction scores of fuzzy embeddings that the image belongs to the \(k\)-th category. \(n_{i,k}\) is the \(k\)-th value of one-hot encoded seen category labels, \(Y\) is the number of seen categories.

The loss function for SFR is constructed by the balanced combination of the two losses: \(_{SFR}=_{fz}+(1-)_{ce}\), where \(\) is the hyper-parameter to trade-off between them.

## 5 Experiments

### Experimental Settings

OpenPart Datasets.We construct three datasets for assembly-based open-set 3D object retrieval (OpenPart datasets), including OP-SHNP, OP-INTRA, OP-COSEG based on the public dataset ShapeNetPart , IntraA , and COSEG . We sampled the point cloud from the triangular surface for each dataset. As shown in Table 1, the classes of these datasets are split into seen and unseen classes for training and testing, respectively. Each class contains three to five parts. Specifically, the detailed descriptions of the datasets and parts segmentation are shown in Appendix B.

    & **OP-SHNP** & **OP-INTRA** & **OP-COSEG** \\   & 3.2 & 3.1 & 2.3 \\   & All & 16 & 3 & 9 \\  & Seen & 6 & 1 & 3 \\   & Unseen & 10 & 2 & 6 \\   & Train & 5804 & 116 & 240 \\   & Retrieval & 6142 & 2318 & 802 \\   & Query & 945 & 302 & 85 \\   & Target & 5197 & 2016 & 717 \\   

Table 1: The statistics of the three OpenPart datasets.

Implemental Details.The random seeds are fixed to 2024 in this paper for a fair comparison. The basic features are extracted by PointNet  and each part feature is obtained by the average point feature of each region, we use the top four parts for each object in this paper. We set \(=0.5\) in \(_{IAE}\) and \(=0.9\) in \(_{SFR}\). The IAE is trained for \(40\) epochs on learning rate \(lr=0.1\), and the SFR is trained for \(30\) epochs on \(lr=0.001\). The detailed implements of the HAFR framework are provided in Appendix C.

### Retrieval Performance

Compared Methods.Since no methods are specifically designed for assembly-based open-set 3DOR, we refine the current state-of-the-art close-set 3DOR methods (MMJN , TCL , SDML , MMSAE ), and open-set 3D learning methods (PROSER , HGM\({}^{2}\)R ), then we refine the multi-modal fusion module with multi-part fusion for each method. We provide detailed implements of compared methods in Appendix D

Evaluation Metrics.For a fair comparison, we use standard retrieval metrics, including Mean Average Precision (mAP), Normalized Discounted Cumulative Gain (NDCG), Average Normalized Modified Retrieval Rank (ANMRR), and the Precision-Recall Curve (PR-Curve). For the mAP and NDCG metrics, higher scores are better. For the ANMRR metric, a lower score is better.

Comparison Analysis.As shown in Table 2, we evaluate the assembly-based open-set retrieval results from HAFR framework and other state-of-the-art compared methods. Quantitative results demonstrate the superiority of our method over the other methods on all three datasets. In particular, on the OP-COSEG dataset, our method achieves \(0.7015\) mAP with about \(8.7\%\) improvements compared with the second-best method (HGM\({}^{2}\)R). We also compare the Precision-Recall Curves (PR-Curve) which evaluate the trade-off between precision and recall at different thresholds. A larger area between the curve and the axes indicates better performance for retrieval, our method outperforms all other retrieval methods as shown in Figure 4.

The superior performance in the comparison indicates that by the proposed IAE and SFR modules, the proposed HAFR framework can better utilize the potential semantic information among part

    &  &  &  \\   & mAP\(\) & NDCG\(\) & ANMRR\(\) & mAP\(\) & NDCG\(\) & ANMRR\(\) & mAP\(\) & NDCG\(\) & ANMRR\(\) \\  MMJN & 0.5685 & 0.5856 & 0.2599 & 0.5465 & 0.5898 & 0.5053 & 0.6394 & 0.7623 & 0.4314 \\ TCL & 0.5683 & 0.5861 & 0.2608 & 0.5467 & 0.5970 & 0.5059 & 0.6285 & 0.7543 & 0.4401 \\ SDML & 0.5699 & 0.5870 & 0.2593 & 0.5456 & 0.5944 & 0.5064 & 0.6328 & 0.7638 & 0.4422 \\ MMSAE & 0.5637 & 0.5824 & 0.2659 & 0.5452 & 0.5919 & 0.5056 & 0.6350 & 0.7555 & 0.4334 \\  PROSER & 0.5687 & 0.5861 & 0.2607 & 0.5462 & 0.5943 & 0.5059 & 0.6343 & 0.7605 & 0.4348 \\ HGM\({}^{2}\)R & 0.5736 & 0.5886 & 0.2549 & 0.5545 & 0.6019 & 0.4928 & 0.6452 & 0.7627 & 0.4355 \\ 
**Ours** & **0.5947** & **0.5916** & **0.2239** & **0.5750** & **0.6382** & **0.4797** & **0.7015** & **0.7629** & **0.3604** \\   

Table 2: Quantitative results of retrieval on the OP-SHNP, OP-INTRA, and OP-COSEG datasets.

Figure 4: The Precision-Recall Curves for comparison on the three datasets, respectively.

features to fully represent 3D objects and generalize them to unseen categories. Notably, for the OP-INTRA dataset with only one category and the least parts in the training set, our method still achieves performance improvements in the retrieval of unseen categories as shown in Table 2 and Figure 4. This indicates that our method has minimal dependence on the performance of classifiers during basic feature extraction. In open-set environments, where training on all potential categories is infeasible, our HAFR method through _Part Assembly_ demonstrates superior open-set adaptability. We provide more visualizations and results in Appendix D.

### Ablation Studies

We conduct ablation studies to verify the effectiveness of modules in the proposed framework. For the IAE stage, we first remove the Hypergraph Isomorphism Convolution (HIConv) layer for comparison. Specifically, we replace it with the Graph Isomorphism Convolution (HIConv\(\)GIN) and MLP (HIConv\(\)MLP). Then we compared it with the method without the Assembly Loss (IAE w/o \(_{as}\)) or the Cross-Part Loss(IAE w/o \(_{xp}\)). As shown in Table 3 and Figure 5, replacing HIConv or removing parts of the \(_{IAE}\) loss significantly degrades the performance of IAE. For the HIConv, this indicates that naive part assembly is dependent on geometric or semantic factors such as order and quantity. Removing isomorphism smoothing results in geometric or semantic inconsistencies, thereby degrading the retrieval performance by the worse assembly embeddings. As for the SFR module, we compare the hypergraph structure without the leveraged structure (SFR w/o \(_{lev}\)) and we also replace the hypergraph-based structure learning with MLP (MLP-based SFR) and GCN (GCN-based SFR). Besides, we remove the memory bank to verify the effectiveness of fuzzy reconstruction.

Table 3 and Figure 5 show that the proposed full SFR module outperforms all the other ablative structures, these results show that the proposed leverage propagation and fuzzy reconstruction approach can effectively utilize the high-order correlations between seen and unseen categories for open-set generalization. Besides, we can observe that the complete combination of IAE and SFR yields the best performance. These quantitative and qualitative results indicate that the proposed HAFR framework effectively achieves part-level assembly isomorphism and unification while mitigating distribution skew from seen certainty to unseen uncertainty at the object level.

Figure 5: The Precision-Recall Curves of the ablation studies on the three datasets, respectively.

    &  &  &  \\   & mAP\(\) & NDCG\(\) & ANMRR\(\) & mAP\(\) & NDCG\(\) & ANMRR\(\) & mAP\(\) & NDCG\(\) & ANMRR\(\) \\  HIConv\(\)GIN & 0.5761 & 0.5826 & 0.2465 & 0.5567 & 0.6050 & 0.4947 & 0.6782 & 0.7625 & 0.4001 \\ HIConv\(\)MLP & 0.5837 & 0.5854 & 0.2357 & 0.5523 & 0.6035 & 0.4948 & 0.6505 & 0.7664 & 0.4334 \\ IAE w/o \(_{as}\) & 0.5767 & 0.5838 & 0.2464 & 0.5560 & 0.6077 & 0.4946 & 0.6829 & 0.7542 & 0.3823 \\ IAE w/o \(_{xp}\) & 0.5767 & 0.5840 & 0.2464 & 0.5561 & 0.6078 & 0.4944 & 0.6828 & 0.7542 & 0.3824 \\  SFR w/o \(_{lev}\) & 0.5755 & 0.5825 & 0.2474 & 0.5545 & 0.6019 & 0.4928 & 0.6887 & 0.7540 & 0.3768 \\ MLP-based SFR & 0.5636 & 0.5851 & 0.2665 & 0.5429 & 0.5814 & 0.4997 & 0.6662 & 0.7610 & 0.4062 \\ GCN-based SFR & 0.5679 & 0.5845 & 0.2603 & 0.5430 & 0.5854 & 0.4982 & 0.6674 & 0.7618 & 0.4072 \\ 
**IAE+SFR** & **0.5947** & **0.5916** & **0.2239** & **0.5750** & **0.6382** & **0.4797** & **0.7015** & **0.7629** & **0.3604** \\   

Table 3: Ablation studies of retrieval on the OP-SHNP, OP-INTRA, and OP-COSEG datasets.

Conclusion

In this paper, we introduce the Hypergraph-Based Assembly Fuzzy Representation (HAFR) framework, which navigates the intricacies of open-set 3D object retrieval through a bottom-up lens of _Part Assembly_. Specifically, we propose the Hypergraph Isomorphism Convolusion (HIConv) and adopt the Isomorphic Assembly Embedding (IAE) module for assembly isomorphism and unification, generating the integration embeddings with geometric-semantic consistency. Besides, we employ the Structure Fuzzy Reconstruction (SFR) approach to exploit high-order correlations among objects and fuzzify representations for open-set category generalization. This module constructs a leveraged hypergraph based on local-certainty and global-uncertainty correlations to mitigate distribution skew. We construct three open-set retrieval datasets for 3D objects with part-level annotations, _i,e_., OP-SHNP, OP-INTRA, and OP-COSEG. Extensive experiments and ablation studies on these three benchmarks show our method outperforms current state-of-the-art methods. However, due to data limitations, this paper does not currently consider the assembly fuzzy representation for varying numbers of parts, which will be a focus of our future research. We believe this paper provides a novel perspective for open-set retrieval by exploring from local to global levels.

## 7 Acknowledgement

This work was supported by Beijing Natural Science Foundation (No. L242167), CCF-Tencent Open Research Fund, and Jiangxi Provincial Natural Science Foundation (20224ACB218002).