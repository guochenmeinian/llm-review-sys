# Curve Your Enthusiasm: Concurvity Regularization in Differentiable Generalized Additive Models

Julien Siems

University of Freiburg

siemsj@cs.uni-freiburg.de Konstantin Ditschuneit

Corresponding author

Konstantin Ditschuneit1

Seenarium AI

ko.ditschuneit@gmail.com Winfried Ripken

Mernatrix Momentum

winfried.ripken@merantix.com Alma Lindborg

Mernatrix Momentum

alma.lindborg@merantix.com Maximilian Schambach

Mernatrix Momentum

maximilian.schambach@merantix.com Johannes S. Otterbach

nyonic

johannes@nyonic.ai Martin Genzel

Mernatrix Momentum

martin.genzel@merantix.com

###### Abstract

Generalized Additive Models (GAMs) have recently experienced a resurgence in popularity due to their interpretability, which arises from expressing the target value as a sum of non-linear transformations of the features. Despite the current enthusiasm for GAMs, their susceptibility to concurity - i.e., (possibly non-linear) dependencies between the features - has hitherto been largely overlooked. Here, we demonstrate how concurity can severely impair the interpretability of GAMs and propose a remedy: a conceptually simple, yet effective regularizer which penalizes pairwise correlations of the non-linearly transformed feature variables. This procedure is applicable to any differentiable additive model, such as Neural Additive Models or NeuralProphet, and enhances interpretability by eliminating ambiguities due to self-canceling feature contributions. We validate the effectiveness of our regularizer in experiments on synthetic as well as real-world datasets for time series and tabular data. Our experiments show that concurity in GAMs can be reduced without significantly compromising their prediction quality, improving interpretability and reducing variance in the feature importances. 1

## 1 Introduction

Interpretability has emerged as a critical requirement of machine learning models in safety-critical decision-making processes and applications subject to regulatory scrutiny. Its importance is particularly underscored by the need to ensure fairness, unbiasedness, accountability and transparency inmany applications and domains [6; 42], such as medical diagnoses , loan approvals , and hiring practices . In such cases, model interpretability can even be favored over prediction accuracy .

A popular model class for interpretable machine learning is _Generalized Additive Models_ (_GAMs_) , in which the target variable is expressed as a sum of non-linearly transformed features. GAMs combine the interpretability of (generalized) linear models with the flexibility of capturing non-linear dependencies between the features and the target. GAMs have recently seen a resurgence in interest with prominent examples being _Neural Additive Models_ (_NAMs_)  and its variants [11; 19; 20; 39; 50] for tabular data, as well as _Prophet_ and _NeuralProphet_ for time-series forecasting. Both domains will be further explored in our experiments.

A significant obstacle to the interpretability of additive models is the phenomenon of _concurvity_. As a non-linear analog to multicollinearity, concurvity refers to the presence of strong correlations among the non-linearly transformed feature variables. Similarly to multicollinearity, concurvity can impair interpretability because parameter estimates become unstable when features are correlated , resulting in highly disparate interpretations of the data depending on the model initialization. Although this issue is known and addressed by various techniques such as variable selection  in traditional GAMs, it has been overlooked in more recent works. Unlike the prevalent GAM package \(mgcv\), we are not aware of any differentiable GAM implementations that include concurvity metrics.

In this work, we propose a novel regularizer for reducing concurvity in GAMs by penalizing pairwise correlations of the non-linearly transformed features. Reducing concurvity improves interpretability because it promotes the isolation of feature contributions to the target by eliminating potentially correlated or self-canceling transformed feature combinations. As a result, the model becomes easier to inspect by clearly separating individual feature contributions. In addition, our regularizer encourages the model to learn more consistent feature importances across model initializations, which increases interpretability. The trade-off between increased interpretability and prediction quality will be further explored in Section 4.

Figure 1 provides a first intuition of the practical effects of concurvity and how they can be addressed by our regularizer. We use the additive time-series model NeuralProphet  in this example, restricted to daily and weekly seasonality components. Here, each component is modeled via periodic functions with adjustable complexity. For more details on the experiment, see Section 4.2. We find that while the default NeuralProphet parameters effectively mitigate concurvity by producing a very

Figure 1: Concurvity in a NeuralProphet model: Fitting a time series composed of daily and weekly seasonalities, each represented by Fourier terms. (left) Using few Fourier terms results in uncorrelated components but a poor fit. (middle) A more complex model improves the fit but sacrifices interpretability due to self-canceling high-frequency terms. (right) The same complex model, but with our _regularizer_, achieves both good predictive performance and interpretable (decorrelated) components. See Section 4.2 for more details.

simple model, they provide a worse fit to the data than the more complex models. However, if left unregularized, a more complex model is subject to strong correlation between the seasonalities, an effect visually apparent in self-canceling periodic components in the middle column of Figure 1. In contrast, when using our regularization, the seasonalities are less correlated, resulting in a clearer separation between the components. While the predictive performance of the two complex models is comparable, the regularized model is more interpretable because daily and weekly effects are clearly separated.

This idea forms the basis of our argument: Comprehending a standard GAM typically requires answers to two questions: How do the features relate to my output? How do the features interact, possibly negating their contributions? By applying concurvity regularization, we simplify the interpretation of a GAM by eliminating the need for the second question.

Our main contributions can be summarized as follows:

1. We showcase the susceptibility of modern GAMs to concurvity and present a revised formal definition of the concept.
2. We propose a concurvity regularizer applicable to any differentiable GAM.
3. We validate our approach experimentally on both synthetic and real-world data, investigating the trade-off between concurvity and prediction quality, as well as the impact of regularization on interpretability.

## 2 Background

### Generalized Additive Models

_Generalized Additive Models_ (_GAMs_)  form a class of statistical models that extends Generalized Linear Models  by incorporating non-linear transformations of each feature. Following , GAMs can be expressed as:

\[gY|X=+_{i=1}^{p}f_{i} (X_{i})\,,\] (GAM)

where \(Y=(y_{1},,y_{N})^{N}\) is a vector of \(N\) observed values of a target (random) variable, \(X=[X_{1},,X_{p}]^{N p}\) assembles the observed feature variables \(X_{i}=(x_{i,1},,x_{i,N})^{N}\), and \(f_{i}:\) are univariate, continuous _shape functions_ modeling the individual feature transformations.4 Furthermore, \(\) is a learnable global offset and \(g:\) is the link function that relates the (expected) target value to the feature variables, e.g., the logit function in binary classification or the identity function in linear regression. The shape functions \(f_{i}\) precisely describe the contribution of each individual feature variable in GAMs, and can be visualized and interpreted similarly to coefficients in a linear model. This allows practitioners to fully understand the learned prediction rule and gain further insights into the underlying data.

While early GAMs primarily used splines  or boosted decision trees [10; 34; 35] to model \(f_{i}\), more recent GAMs such as _Neural Additive Models_ (_NAMs_)  use multilayer perceptrons (MLPs) to fit the functions \(f_{i}\), benefiting from the universal approximation capacity of neural networks  as well as the support of automatic differentiation frameworks [1; 8; 38] and hardware acceleration. As a result, one can now solve the GAM fitting problem

\[_{,(f_{1},,f_{p})} LY,+_{i=1}^{p}f_{i}(X_{i})\] (1)

by common deep learning optimization techniques such as mini-batch stochastic gradient descent (SGD). Here, \(L:\) is a loss function and \(\{(f_{1},,f_{p}) f_{i}: \}\) any function class with differentiable parameters, e.g., MLPs or periodic functions like in NeuralProphet .

### Multicollinearity and Concurvity

Multicollinearity refers to a situation in which two or more feature variables within a linear statistical model are strongly correlated. Formally, this reads as follows:5

**Definition 2.1** (Multicollinearity).: _Let \(X_{1},,X_{p}^{N}\) be a set of feature variables where \(X_{i}=(x_{i,1},,x_{i,N})^{N}\) represents \(N\) observed values. We say that \(X_{1},,X_{p}\) are (perfectly) multicollinear if there exist \(c_{0},c_{1},,c_{p}\), not all zero, such that \(c_{0}+_{i=1}^{p}c_{i}X_{i}=0\)._

According to the above definition, every suitable linear combination of features that fits a target variable, say \(Y d_{0}+_{i=1}^{p}d_{i}X_{i}\), can be modified by adding a trivial linear combination \(c_{0}+_{i=1}^{p}c_{i}X_{i}=0\), i.e., \(Y(c_{0}+d_{0})+_{i=1}^{p}(c_{i}+d_{i})X_{i}\). So there exist other (possibly infinitely many) equivalent solutions with different coefficients. This can make individual effects of the features on a target variable difficult to disambiguate, impairing the interpretability of the fitted model. However, even in the absence of _perfect_ multicollinearity, difficulties may arise.6 For example, if two features are strongly correlated, estimating their individual contributions becomes challenging and highly sensitive to external noise. This typically results in inflated variance estimates for the linear regression coefficients , among other problems .

The notion of concurvity was originally introduced in the context of GAMs to extend multicollinearity to non-linear feature transformations . In analogy with our definition of multicollinearity, we propose the following definition of concurvity:

**Definition 2.2** (Concurvity).: _Let \(X_{1},,X_{p}^{N}\) be a set of feature variables and let \(\{(f_{1},,f_{p}) f_{i}:\}\) be a class of functions. We have (perfect) concurvity w.r.t. \(X_{1},,X_{p}\) and \(\) if there exist \((g_{1},,g_{p})\) and \(c_{0}\) such that \(c_{0}+_{i=1}^{p}g_{i}(X_{i})=0\) with \(c_{0},g_{1}(X_{1}),,g_{N}(X_{N})\) not all zero._

Technically, concurvity simply amounts to the collinearity of the transformed feature variables, and Definition 2.1 is recovered when \(\) is restricted to affine linear functions. Concurvity poses analogous challenges to multicollinearity: _Any_ non-trivial zero-combination of features can be added to a solution of GAM-Fit in Equation (1), rendering the fitted model less interpretable as each feature's contribution to the target is not immediately apparent. Finally we note that, although concurvity can be considered as a generalization of multicollinearity, neither implies the other in general, see Appendix A.2(2) for more details.

## 3 Concurvity Regularizer

Concurvity easily arises in highly expressive GAMs, such as NAMs, since the mutual relationships between the functions \(f_{i}\) are not constrained while solving GAM-Fit in Equation (1). This results in a large, degenerate search space with possibly infinitely many equivalent solutions. To remedy this problem, it appears natural to constrain the function space \(\) of (1) such that the shape functions \(f_{i}\) do not exhibit spurious mutual dependencies. Here, our key insight is that _pairwise uncorrelatedness is sufficient to rule out concurvity_. Indeed, using \(\) from Definition 2.2, let us consider the subclass

\[_{}:=\{(f_{1},,f_{p}) f_{i}(X_{i}),f_{j}(X_{j})=0,\;\,i j\} \,,\]

where \((,)\) is the Pearson correlation coefficient. It is not hard to see that concurvity w.r.t. \(X_{1},,X_{p}\) and \(_{}\) is impossible, regardless of the choice of \(\) (see Appendix A.1 for a proof). From a geometric perspective, \(_{}\) imposes an orthogonality constraint on the feature vectors. The absence of concurvity follows from the fact that an orthogonal system of vectors is also linearly independent. However, it is not immediately apparent how to efficiently constrain the optimization domain of Equation (1) to \(_{}\). Therefore, we rephrase the above idea as an unconstrained optimization problem:

\[_{}_{,(f_{1},,f_{p})} LY,+_{i=1}^{p}f_{i}(X_{i})+  R_{}(\{f_{i}\}_{i},\{X_{i}\}_{i})\,,\] (2)

where \(R_{}:^{N p}\) denotes our proposed _concurvity regularizer_:

\[R_{}\{f_{i}\}_{i},\{X_{i}\}_{i}:=_ {i=1}^{p}_{j=i+1}^{p}\,f_{i}(X_{i}),f_{j}(X_{j}) \,.\]

Using the proposed regularizer, GAM-Fit\({}_{}\) simultaneously minimizes the loss function and the distance to the decorrelation space \(_{}\). In situations where high accuracy and elimination ofconcurvity cannot be achieved simultaneously, a trade-off between the two objectives occurs, with the regularization parameter \( 0\) determining the relative importance of each objective. An empirical evaluation of this objective trade-off is presented in the subsequent experimental section.

Since \(R_{}\) is differentiable almost everywhere, GAM-Fit\({}_{}\) in Equation (2) can be optimized with gradient descent and automatic differentiation. Additional computational costs arise from the quadratic scaling of \(R_{}\) in the number of additive components, although this can be efficiently addressed by parallelization (see Appendix E.3.2 for a runtime analysis). A notable difference to traditional regularizers like \(_{1}\)- or \(_{2}\)-penalties is the dependency of \(R_{}\) on the data \(\{X_{i}\}_{i}\). As a consequence, the regularizer is also affected by the batch size and hence becomes more accurate with larger batches. It is also worth noting that our regularizer does not necessarily diminish the quality of the data fit, for instance, when the input feature variables are stochastically independent, see Appendix A.2(3).

Common spline-based concurity metrics proposed in the literature [28; 47] are not directly applicable to other differentiable models such as NAMs or NeuralProphet. Thus, similarly to , we decided to report the average \(R_{}(\{f_{i}\}_{i},\{X_{i}\}_{i})\) as a model-agnostic measure of concurvity.

## 4 Experimental Evaluation

In order to investigate the effectiveness of our proposed regularizer, we will conduct evaluations using both synthetic and real-world datasets, with a particular focus on the ubiquitous applications of GAMs: tabular and time-series data. For the experiments involving tabular data, we have chosen to use Neural Additive Models (NAMs), as they are differentiable and hence amenable to our regularizer. For time-series data, we investigate NeuralProphet models which contain an additive component modeling seasonality. Further elaboration on our experimental setup, including detailed specifications and parameters, can be found in Appendix C.

### Toy Examples

In the following, we design and investigate two instructive toy examples to facilitate a deeper comprehension of the proposed regularizer as well as the relationship between the regularization strength \(\) and the corresponding model accuracy. Results for an additional toy example from  are presented in Appendix E.2.

Toy Example 1: Concurvity regularization with and without multicollinearityTo compare the effect of concurvity regularization on model training in the presence of multicollinearity, we generate synthetic data according to the linear model \(Y=1 X_{1}+0 X_{2}\), where \(X_{1}\) and \(X_{2}\) are each drawn from a uniform distribution. We consider three different settings of input feature correlation: (1) the stochastically independent case where \(X_{1}\) and \(X_{2}\) are independently sampled, (2) the strongly correlated case where \((X_{1},X_{2})=0.9\), and (3) the perfectly correlated case with \(X_{1}=X_{2}\).

We first investigate the effect of concurvity regularization on the contribution of each feature to the target by measuring the correlation of the transformed features \(f_{1}(X_{1})\), \(f_{2}(X_{2})\) with the target variable \(Y\). The results are shown in Figure 1(a). In the stochastically independent case, the NAM accurately captures the relationship between the input features and target variable regardless of the regularization setting, as observed by the high correlation for \(f_{1}(X_{1})\) and zero correlation for \(f_{2}(X_{2})\) with the target. This result emphasizes the minimal impact of the regularizer when features are independent (see Appendix A.2(2) for details). In the perfectly correlated case, the NAM trained without concurvity regularization displays a high correlation for both \(f_{1}(X_{1})\) and \(f_{2}(X_{2})\) with the target, thus using both features for its predictions. In contrast, when concurvity regularization is applied, the NAM is pushed towards approximately orthogonal \(f_{i}\), which encourages feature selection, as indicated by high correlation of either \(f_{1}(X_{1})\) or \(f_{2}(X_{2})\) with the target as there is no natural preference. Interestingly, the situation is slightly different in the strongly correlated case, as \(X_{1}\) is more likely to be selected here, which means that the model has correctly identified the true predictive feature. This nicely illustrates the impact of the proposed regularization on correlated feature contributions. A more detailed visualization of the impact of regularization under perfectly correlated features can be found in Figure 8 in Appendix E.1.

Secondly, we examine the trade-off between the validation RMSE and concurvity \(R_{}\) in the perfectly correlated case in Figure 1(b). Our findings suggest that with moderate regularization strengths \(\), we can effectively eradicate concurvity without compromising the accuracy of the model. Only when 

[MISSING_PAGE_EMPTY:6]

Finally, a trade-off curve of the validation RMSE and \(R_{}\) is shown in Figure 2(b), illustrating that even in the case of non-linearly dependent features, our proposed regularizer effectively mitigates the measured concurity \(R_{}\) with minimal impact on the model's accuracy as measured by the RMSE.

### Time-Series Data

In this section, we provide more context and additional results for the motivational example in Figure 1 on time-series forecasting using NeuralProphet , which decomposes a time-series into various additive components such as seasonality or trend. In NeuralProphet, each seasonality \(S_{p}\) is modeled using periodic functions as

\[S_{p}(t)=_{j=1}^{k}a_{j}(2 jt/p)+b_{j}( 2 jt/p)\]

where \(k\) denotes the number of Fourier terms, \(p\) the periodicity, and \(a_{j}\), \(b_{j}\) are the trainable parameters of the model. In the synthetic example of Figure 1, we restrict the NeuralProphet model to two components, namely a weekly and daily seasonality. Our overall reduced model is therefore given by \(_{t}=S_{2}(t)+S_{7}(t)\).

If \(k\) is sufficiently large, it can cause the frequency ranges of \(S_{24}\) and \(S_{7}\) to overlap, leading to concurity in the model. The default values of \(k\) provided by NeuralProphet for \(S_{24}\) (\(k=6\)) and \(S_{7}\) (\(k=3\)) are intentionally kept low to avert such frequency overlap, as demonstrated in Figure 1 (left). However, this "safety measure" comes at the cost of prediction accuracy due to reduced model complexity.

Analogously to the above toy examples, we present a trade-off curve between RMSE and concurity, averaging over 10 random initialization seeds per regularization strength \(\). In this experiment, we choose \(k=\) 400 components for both daily and weekly seasonality, to allow concurity to occur and fit the data almost exactly. Our findings are identical to the toy examples, demonstrating a steep decline in concurity when increasing \(\) with only a small increase in RMSE.

Finally, we note that concurity can often be identified by visual inspection for additive univariate time-series models as each component is a function of the same variable, see Figure 1. In contrast, on multivariate tabular data, concurity may go unnoticed if left unmeasured and hence lead to false conclusions, as we investigate next.

### Tabular Data

In our final series of experiments, we investigate the benefits of the proposed regularizer when applied to NAMs trained on real-world tabular datasets - a domain often tackled with conventional machine learning methods such as random forests or gradient boosting. We concentrate our analysis on six well-studied datasets: Boston Housing , California Housing , Adult , MIMIC-II , MIMIC-III  and Support2 . These datasets were selected with the aim of covering different dataset sizes (ranging between \(N=506\) for Boston Housing and \(N=48,842\) for Adult) as well as target variables (binary classification for Adult, MIMIC-II & -III, and Support2, and regression for California and Boston Housing). NAMs are used throughout the evaluation, subject to a distinct hyperparameter optimization for each dataset; more details are presented in Appendix B.1. Additionally, we provide a traditional, spline-based GAM using pyGAM  for comparison; details on the HPO for pyGAM can be found in Appendix B.2.

First, we explore the trade-off between the concurity measure \(R_{}\) and validation fit quality when employing the proposed concurity regularization. Figure 5 displays the results for the tabular datasets, including the pyGAM baseline. It is clear that the concurity regularizer effectively reduces the concurity measure \(R_{}\) without significantly compromising the model fit quality across all considered datasets, in particular in the case of small to moderate regularization strengths. For example, on the California Housing dataset, we are able to reduce \(R_{}\) by almost an order of magnitude from around 0.2 to 0.05, while the validation RMSE increases by about 10% from 0.59 to 0.66. Additionally, we

Figure 4: Trade-off curve for NeuralProphet model trained on step-function data.

observe the variation in the scale of \(R_{}\) across the datasets, exemplified by the Adult dataset where the transformed features are nearly decorrelated even in the unregularized case, potentially implying a reduced necessity for regularization. In practice, trade-off curves between concurvity and model accuracy can serve as a valuable tool for identifying the optimal level of regularization strength. As expected, pyGAM obtains similar levels of concurvity as the unregularized NAM at equally similar levels of model performance. We refer to Appendix E.3.1 for more verbose trade-off curves.

**Case study: California Housing** Our preceding experiments demonstrated that concurvity reduction can be achieved when training NAMs on tabular data. However, the practical significance of this observation in relation to interpretability remains unclear so far. To address this, we perform a more detailed analysis of NAMs trained on the California Housing dataset (see Appendix E.3.3 for similarly detailed results on the other datasets). In the following analysis, we compare NAMs trained with and without concurvity regularization. More specifically, we evaluate \(=0.1\) (determined based on Figure 5) and \(=0.0\) both for 60 random weight initializations.

First, we assess the effect of the regularizer on the model fit, finding that regularization increases the mean test RMSE by about 10% from about 0.58 to 0.64 and slightly decreases the spread between the seeds, as shown in Figure 6d. Note that the result in the non-regularized case is on par with the original NAM evaluation  serving as a sanity check of our experimental setup.

Second, we juxtapose the feature correlations of non-linearly transformed features for models trained with and without regularization. The results, as displayed in Figure 6a (upper right triangular matrices), are contrasted with the raw input feature correlations (lower left triangular matrices). It is evident that without regularization, high input correlations tend to result in correlated transformed features, as seen in the left correlation matrix. Conversely, the right correlation matrix reveals that concurvity regularization effectively reduces the correlation of transformed features. This effect is especially pronounced for previously highly correlated features such as _Longitude_ and _Latitude_, or _Total Bedrooms_ and _Households_.

Third, we investigate how concurvity impacts the estimation of the individual feature importances, which is of key interest for interpretable models such as NAMs. Following , we measure the importance of feature \(i\) as \(_{j=1}^{N} f_{i}(x_{i,j})-}\) where \(}\) denotes the average of the shape function \(f_{i}\) over the training datapoints. We visualize the distribution of feature importances over our regularized and unregularized ensembles of NAMs in Figure 6b.7 It is apparent that feature importances tend to have a larger variance in the unregularized case compared to the regularized case, a pattern which is

Figure 5: Trade-off curves between model fit quality and measured concurvity \(R_{}\) for 50 levels of concurvity regularization strength \(\). Each regularization strength is evaluated over 10 initialization seeds to account for training variability, particularly noticeable in smaller datasets. The results of a conventional GAM are shown for comparison.

particularly clear for the strongly correlated features which we identified in Figure 5(a). Such variance in feature importance can detrimentally impair the interpretability of the models, due to potential inconsistencies arising in absolute importance orders. However, our proposed concurvity regularizer effectively counteracts this issue, resulting in more consistent and compact feature importances across different random seeds. With regards to the varying effect of regularization on the respective features, two observations are particularly interesting: (1) Features that are mostly uncorrelated remain unaffected by the regularization - an effect we have previously seen in Toy Example 1 - which can, for example, be observed in the case of the _Median income_ feature. (2) Input correlations lead to a bi-modal distribution in the corresponding feature importance as, for example, observable in the case of the _Longitude_ and _Latitude_ or _Total bedrooms_ and _Households_ features. Similarly to Toy Example 1, we see that the regularizer encourages feature selection for correlated feature pairs.

Finally, to visualize the impact of the regularization on model interpretability in more detail, the shape functions of three features are shown in Figure 5(c). Here, the features _Households_ and _Population_ are strongly negatively correlated (see Figure 5(a)) which leads to their feature contributions largely canceling each other out. This problem is effectively mitigated by the proposed regularization, revealing naturally low contributions for both features. For comparison, the contribution of the mostly non-correlated _Median income_ feature remains virtually unchanged by the regularization. Due to the concurvity in the data, the shape functions of the pyGAM model exhibit large variance which impedes their interpretability . A similar behavior can be observed for the remaining feature contributions, which are depicted in Figure 11 in Appendix E.3.3.

In a supplementary experiment in Appendix E.3.4, we compare concurvity regularization to classical L1 regularization on the California Housing dataset. We find that L1 more strongly prunes features and removes finer details of each feature's contribution, which are more gently preserved for concurvity regularization.

In summary, our case study on the California Housing dataset establishes that concurvity regularization significantly enhances interpretability and consistency of a GAM in terms of shape functions and feature importance, whilst maintaining high model accuracy.

Figure 6: Results for the California Housing dataset. The considered NAMs were trained with and without concurvity regularization using 60 model initialization seeds each.

Related Work

**Classical works on concurvity in GAMs** The term concurvity was first introduced in ; for a well-written introduction to concurvity, we refer the reader to . Numerous subsequent works have developed techniques to address concurvity, such as improving numerical stability in spline-based GAM fitting [25; 48] and adapting Lasso regularization for GAMs . Partial GAMs  were proposed to address concurvity through sequential maximization of Mutual Information between response variables and covariates. More recently,  compared several feature selection algorithms for GAMs and found algorithms selecting a larger feature set to be more susceptible to concurvity, a property first noticed in . In addition,  proposes a novel feature selection algorithm that chooses a minimal subset to deal with concurvity. We refer to  for a thorough comparison of different concurvity measures. In contrast, our proposed regularizer adds no additional constraints on the feature set size and does not explicitly enforce feature sparsity.

**Modern neural approaches to GAMs** Recent advancements in neural approaches to GAMs, such as Neural Additive Models (NAMs)  and NeuralProphet , have provided more flexible and powerful alternatives to classical methods . These have spurred interest in the subject leading to several extensions of NAMs [11; 19; 39]. Our approach is compatible with the existing methodologies and can be readily integrated if they are implemented in an automatic differentiation framework.

**Regularization via decorrelation** Similar types of decorrelation regularizers have previously been proposed in the machine learning literature but in different contexts.  found that regularizing the cross-covariance of hidden activations significantly increases generalization performance and proposed DeCov. OrthoReg  was proposed to regularize negatively correlated features to increase generalization performance by reducing redundancy in the network. Similarly,  proposes to add a regularizer enforcing orthonormal columns in weight matrices. More recent approaches, such as Barlow Twins , leverage decorrelation as a self-supervised learning technique to learn representations that are invariant to different transformations of the input data.

## 6 Conclusion

In this paper, we have introduced a differentiable concurvity regularizer, designed to mitigate the often overlooked issue of concurvity in differentiable Generalized Additive Models (GAMs). Through comprehensive empirical evaluations, we demonstrated that our regularizer effectively reduces concurvity in differentiable GAMs such as Neural Additive Models and NeuralProphet. This in turn significantly enhances the interpretability and reliability of the learned feature functions, a vital attribute in various safety-critical and strongly regulated applications. Importantly, our regularizer achieves these improvements while maintaining high prediction quality, provided it is carefully applied. We underscore that while the interpretability-accuracy trade-off is an inherent aspect of concurvity regularization, the benefits of increased interpretability and consistent feature importances across model initializations are substantial, particularly in real-world decision-making scenarios.

Nonetheless, our study is not without its limitations. The validation of our approach, while diverse, was limited to three real-world and three synthetic datasets. As such, we acknowledge that our findings may not fully generalize across all possible datasets and use cases.

An intriguing avenue for future work could be to examine the impact of our regularizer on fairness in GAMs. While prior work  suggests that GAMs with high feature sparsity can miss patterns in the data and be unfair to minorities, our concurvity regularizer does not directly enforce feature sparsity. Thus, a comparison between sparsity regularizers and our concurvity regularizer in unbalanced datasets would be of high interest. In addition, future work could explore how the joint optimization of concurvity and model fit could be improved by framing it as a multi-objective problem. Finally, our concurvity regularizer could be adapted to differentiable GAMs that incorporate pairwise interactions. Specifically, it would be interesting to contrast such an extension with the ANOVA decomposition proposed in  in terms of single and pairwise interactions.

We conclude by encouraging researchers and practitioners to "curve your enthusiasm" - that is, to seriously consider concurvity in GAM modeling workflows. We believe this will lead to more interpretable models and hence more reliable and robust analyses, potentially avoiding false conclusions.