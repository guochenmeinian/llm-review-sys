# Private Distribution Learning with Public Data:

The View from Sample Compression+
Footnote â€ : Authors are listed in alphabetical order. Full paper: https://arxiv.org/abs/2308.06239.

Shai Ben-David

University of Waterloo

Vector Institute

shai@uwaterloo.ca

&Alex Bie

University of Waterloo

yabie@uwaterloo.ca

&Clement L. Canonne

University of Sydney

clement.canonne@sydney.edu.au

Gautam Kamath

University of Waterloo

Vector Institute

g@csail.mit.edu

&Vikrant Singhal

University of Waterloo

vikrant.singhal@uwaterloo.ca

###### Abstract

We study the problem of private distribution learning with access to public data. In this setup, which we refer to as _public-private learning_, the learner is given public and private samples drawn from an unknown distribution \(p\) belonging to a class \(\), with the goal of outputting an estimate of \(p\) while adhering to privacy constraints (here, pure differential privacy) only with respect to the private samples.

We show that the public-private learnability of a class \(\) is connected to the existence of a sample compression scheme for \(\), as well as to an intermediate notion we refer to as _list learning_. Leveraging this connection: (1) approximately recovers previous results on Gaussians over \(^{d}\); and (2) leads to new ones, including sample complexity upper bounds for arbitrary \(k\)-mixtures of Gaussians over \(^{d}\), results for agnostic and distribution-shift resistant learners, as well as closure properties for public-private learnability under taking mixtures and products of distributions. Finally, via the connection to list learning, we show that for Gaussians in \(^{d}\), at least \(d\) public samples are necessary for private learnability, which is close to the known upper bound of \(d+1\) public samples.

## 1 Introduction

Statistical analysis of sensitive data, and specifically parameter and density estimation, is a workhorse of privacy-preserving machine learning. To provide meaningful and rigorous guarantees on algorithm for these tasks, the framework of _differential privacy_ (DP)  has been widely adopted by both algorithm designers and machine learning practitioners , and is, by and large, one of the past decade's success stories in principled approaches to private machine learning, with a host of results and implementations  for many of the flagship private learning tasks.

Yet, however usable the resulting algorithms may be, DP often comes at a steep price: namely, many estimation tasks simple without privacy constraints provably require much more data to be performed privately; even more dire, they sometimes become _impossible_ with any finite number of data points, absent some additional strong assumptions.

The prototypical example in that regard is learning a single \(d\)-dimensional Gaussian distribution from samples. In this task, a learner receives i.i.d. samples from an unknown \(d\)-dimensional Gaussianand is tasked with finding an estimate \(q\) close to \(p\) in total variation (\(\)) distance. Without privacy constraints, it is folklore that this can be done with \(O(d^{2})\) samples; yet once privacy enters the picture, in the form of pure differential privacy, _no finite sample algorithm for this task can exist_, unless a bound on the mean vector and covariance matrix are known.

This "cost of privacy" is, unfortunately, inherent to many estimation tasks, as the positive results (algorithms) developed over the years have been complemented with matching negative results (lower bounds). In light of these strong impossibility results, it is natural to wonder if one could somehow circumvent this often steep privacy cost by leveraging other sources of _public_ data to aid the private learning process.

Recent work in finetuning machine learning models has tried to address the question whether, in situations where a vast amount of public data is available, one can combine the public data with a relatively small amount of _private_ data to somehow achieve privacy guarantees for the private data and learning guarantees that would otherwise be ruled out by the aforementioned impossibility results. We, on the other hand, address the same question, but in the opposite setting, i.e., when the amount of public data available is much smaller than the amount of private data available. In other words, we answer the following question from new perspectives.

_Can one leverage small quantities of public data to privately learn from sensitive data, even when private learning is impossible?_

This question was the focus of a recent study of Bie, Kamath, and Singhal , the starting point of our work. In this paper, we make significant strides in this direction, by obtaining new "plug and play" results and connections in this public-private learning setting, and using them to obtain new sample complexity bounds for a range of prototypical density estimation tasks.

### Our results

First, we establish a connection between learning (in the sense of _distribution learning_ or _density estimation_) with public and private data (Definition 2.4) and _sample compression schemes for distributions_ (Definition 2.5; see [1, Definition 4.2]), as well as an intermediate notion we refer to as _list learning_ (Definition 3.2).

**Theorem 1.1** (Sample compression schemes, public-private learning, and list learning (Informal; see Theorem D.1)).: _Let \(\) be a class of probability distributions and \(m(,)\) be a sample complexity function in terms of target error \(\) and failure probability \(\). Then the following are equivalent._

1. \(\) _has a sample compression scheme using_ \(O(m(,))\) _samples._
2. \(\) _is public-privately learnable with_ \(O(m(,))\) _public samples._
3. \(\) _is list learnable with_ \(O(m(,))\) _samples._

Despite its technical simplicity, this sample complexity equivalence turns out to be quite useful, and allows us to derive new public-private learners for an array of key distribution classes by leveraging known results on sample compression schemes. In particular, from the connection to sample compression schemes we are able to obtain new public-private learners for: (1) high-dimensional Gaussian distributions (Corollary E.1); (2) arbitrary mixtures of high-dimensional Gaussians (Theorem 1.2/Corollary E.2); (3) mixtures of public-privately learnable distribution classes (Theorem 4.3/E.5); and (4) products of public-privately learnable distribution classes (Theorem 4.3/E.7). For instance, the following is a consequence of the above connection.

**Theorem 1.2** (Public-private learning for mixtures of Gaussians (Informal; see Corollary E.2)).: _The class of mixtures of \(k\) arbitrary \(d\)-dimensional Gaussians is public-privately learnable with \(m\) public samples and \(n\) private samples, where_

\[m=()\ \ \ \ \ n=(}{^{2}}+}{ }),\]

_in which \(\) is the target error and \(\) the privacy parameter._

We also examine public-private distribution learning in a setting with relaxed distributional assumptions, in which the distributions underlying the public and private data: (1) may differ (the case of public-private _distribution shift_); and (2) may not be members of the reference class of distributions, and so we instead ask for error close to the best approximation of the private data distribution by a member of the class (the _agnostic_ case). We show that _robust_ sample compression schemes for a class of distributions can be converted into public-private learners in this _agnostic and distribution-shifted_ setting. As a consequence, we have the following result for learning distributions that can be approximated by Gaussians under public-private distribution shift.

**Theorem 1.3** (Agnostic and distribution-shifted public-private learning for Gaussians (Informal; see Corollary F.1)).: _There is a public-private learner that takes \(m\) public samples and \(n\) private samples from any pair of distributions \(\) and \(p\) over \(^{d}\) respectively, with \((,p)\), where_

\[m=O(d) n=(}{}+ }{}),\]

_in which \(\) is the target error and \(\) the privacy parameter. With probability \(\), the learner outputs \(q\) with \((q,p)+\), where \(\) is the total variation distance between \(p\) and the closest \(d\)-dimensional Gaussian to it._

Next, using the aforementioned connection to list learning, we are able to establish a fine-grained lower bound on the number of public data points required to privately learn high-dimensional Gaussians.

**Theorem 1.4** (Almost tight lower bound on privately learning Gaussians with public data (Informal; see Theorem 6.1)).: _The class of all \(d\)-dimensional Gaussians is not public-privately learnable with fewer than \(d\) public samples, regardless of the number of private samples._

 showed that \(d\)-dimensional Gaussians are public-privately learnable with \((}{^{2}}+}{})\) private samples, _as soon as \(d+1\) public samples are available_. Thus, our result shows a very sharp threshold for the number of public data points necessary and sufficient to make private learning possible.

We also provide a general result for public-privately learning classes of distributions whose _Yatracos class_ has finite VC dimension.

**Theorem 1.5** (VC dimension bound for public-private learning (Informal; see Theorem 7.2)).: _Let \(\) be a class of probability distributions over a domain \(\) such that the Yatracos class of \(\), defined as_

\[\{\{x f(x)>g(x)\}:f,g\}  2^{}\]

_has bounded VC dimension. Denote by \(()\) and \(^{*}()\) the \(\) and dual \(\) dimensions of \(\) respectively. Then \(\) is public-privately learnable with \(m\) public samples and \(n\) private samples, where_

\[m=(()}{})  n=(()^{2} ^{*}()}{^{3}}),\]

_in which \(\) is the target error and \(\) the privacy parameter._

The \((()}{})\) public sample requirement is less than the known \(O(()}{^{2}})\) sample requirement to learn with only public data via the non-private analogue of this result .

### Related work

The most closely related work is that of Bie, Kamath, and Singhal , which initiated the study of distribution learning with access to both public and private data. That work studied algorithms for specific canonical distribution classes, while the present paper aims to broaden our understanding of public-private distribution learning in general, via connections to other problems and providing more general approaches for devising sample efficient public-private learners. In addition, we prove the first lower bounds on the amount of public data needed for private distribution learning.

There is a long line of work on private distribution learning, especially with regards to Gaussians and mixtures of Gaussians.  studied univariate Gaussians, showing that logarithmic dependencies on parameter bounds are necessary and sufficient in the case of pure DP, but can be removed under approximate DP. The same is true in the multivariate setting .

KMV22, LKO22]. For mixtures of Gaussians, most studies have focused on _parameter estimation_ of mixture components , and employ component separation and mixing weight assumptions. For _density estimation_ (the setting studied in this work)  give learnability results under various structural assumptions. The concurrent work of Azfali, Ashtiani, and Lia  gives the first learnability result for general high-dimensional mixtures of Gaussians under approximate differential privacy.

Outside of distribution learning, there is a significant interest in using public data to improve private algorithms. Some problems studied include private query release, synthetic data generation, classification, mean estimation, empirical risk minimization, and stochastic convex optimization . The definition of public-private algorithms that we adopt is from , which studied classification in the PAC model. The VC dimension bound we give for public-private distribution learning relies on results from public-private classification  and uniform convergence .

On the technical side, we establish connections with distribution compression schemes as introduced by , and directly apply their results to establish new results for public-public learning. Related compression schemes for PAC learning for binary classification have been shown to be necessary and sufficient for learnability in those settings . For further discussion of related work, please see Appendix A.

### Limitations

Our work investigates the sample complexity of public-private learning, and does not give computationally efficient learners, or in some cases, _algorithmic_ learners that run in finite time.1 In particular, all public-private learners we obtain from sample compression run in time exponential in the sample complexity. Also, for our VC dimension upper bounds, we enumerate all realizable labellings of the input sample as per the relevant Yatracos class \(\), which is not computable for general \(\). Finally, dependence on \(^{*}()\) in sample complexity is not ideal, as \(^{*}() 2^{()+1}-1\) is the best possible upper bound in terms of \(()\) for general \(\).

## 2 Preliminaries

### Notation

We denote by \(\) the _domain of examples_. For a domain \(\), denote by \(()\) the set of all probability distributions over \(\). We refer to a set \(()\) as a _class of distributions over \(\)_.

We equip \(()\) with the _total variation_ metric, which is defined as follows: for \(p,q()\), \((p,q):=_{B}|p(B)-q(B)|\), where \(\) are the measurable sets of \(\). For \(p()\) and a set of distributions \(L()\), we denote their _point-set distance_ by \((p,L):=_{q L}(p,q)\).

We will let \(}=(_{1},,_{m})^{m}\) denote a _public dataset_ and \(=(x_{1},,x_{n})^{n}\) denote a _private dataset_. Their respective capital versions \(}\), \(\) denote random variables for datasets realized by sampling from some underlying distribution. For \(p()\), we denote by \(p^{m}\) the distribution over \(^{m}\) obtained by concatenating \(m\) i.i.d. samples from \(p\).

### Public-private learning

**Definition 2.1** (Differential privacy ).: Fix an input space \(\) and an output space \(\). Let \(,>0\). A randomized algorithm \(:^{n}()\) is _\((,)\)-differentially private (\(,\))-DP_, if for any private datasets \(,^{}^{n}\) differing in one entry,

\[*{}_{Y()}\{Y B \}()*{}_{Y^{} (^{})}\{Y^{} B\}+ $.}\]The case where \(=0\) is referred to as _pure_ differential privacy or \(\)-DP.

Our focus is on understanding the public data requirements for privately learning different classes of distributions. We seek to answer the following question:

_For a class of distributions \(\), how much public data is necessary and sufficient to render \(\) privately learnable?_

To do so, we give the formal notion of "public-private algorithms" - algorithms that take public data samples and private data samples as input, and guarantee differential privacy with respect to the private data - as studied previously in the setting of binary classification . We restrict our attention to public-private algorithms that offer a pure DP guarantee to private data.

**Definition 2.2** (Public-private \(\)-Dp).: Fix an input space \(\) and an output space \(\). Let \(>0\). A randomized algorithm \(^{m}^{n}()\) is _public-private \(\)-DP_ if for any public dataset \(}^{m}\), the randomized algorithm \((},):^{n}()\) is \(\)-DP.

**Definition 2.3** (Public-private learner).: Let \(()\). For \(,(0,1]\) and \(>0\), an \((,,)\)-_public-private learner for \(\)_ is a public-private \(\)-DP algorithm \(:^{m}^{n}(())\), such that for any \(p\), if we draw datasets \(}=(_{1},...,_{m})\) and \(=(X_{1},...,X_{n})\) i.i.d. from \(p\) and then \(Q(},)\),

\[*{}_{} p ^{m}, p^{n}\\ Q(},)}\{ (Q,p)\} 1-.\]

**Definition 2.4** (Public-privately learnable class).: We say that a class of distributions \(()\) is _public-privately learnable with \(m(,,)\) public and \(n(,,)\) private samples_ if for any \(,(0,1]\) and \(>0\), there exists an \((,,)\)-public-private learner for \(\) that takes \(m=m(,,)\) public samples and \(n=n(,,)\) private samples.

When \(\) satisfies the above, we may omit the private sample requirement, and say that \(\) is _public-privately learnable with \(m(,,)\) public samples_.

Denote by \(_{}(,)\) the sample complexity of learning \(\). Our primary interest lies in determining when non-privately learnable \(\) can be public-privately learned with \(m(,,)=o(_{}(,))\) public samples (at a target \(\)).

### Sample compression schemes

One of the main techniques that we use in this work to create public-private learners for various distribution families is the _robust sample compression scheme_ from . Roughly speaking, if every member \(q\) of a class of distributions \(\) admits a way to encode enough information about itself in a small number of samples from \(q\) and extra bits, such that it can be approximately reconstructed by a fixed and deterministic decoder, \(\) can be learned.

**Definition 2.5** (Robust sample compression [1, Definition 4.2]).: Let \(r 0\). We say \(()\) admits \(((,),t(,),m(,))\)_\(r\)-robust sample compression_ if for any \(,(0,1]\), letting \(=(,)\), \(t=t(,)\), \(m=m(,)\), there exists a decoder \(g^{r}\{0,1\}^{t}()\), such that the following holds:

For any \(q\) there exists an encoder \(f_{q}^{m}^{}\{0,1\}^{t}\) satisfying for all \(^{m}\) that for all \(i[]\), there exists \(j[m]\) with \(f_{q}()_{i}=_{j}\), such that for every \(p()\) with \((p,q) r\), if we draw a dataset \(=(X_{1},...,X_{m})\) i.i.d. from \(p\),

\[*{}_{ p^{m}}\{(g(f_{q}( )),q)\} 1-.\]

When \(\) satisfies the above, we may omit the compression size complexity function \((,)\) and bit complexity function \(t(,)\), and say that \(\) is _\(r\)-robustly compressible_ with \(m(,)\) samples. When \(r=0\), we say that \(\) admits \(((,),t(,),m(,))\)_realizable compression_ and is _realizably compressible_ with \(m(,)\) samples.

Both robust and realizable compression schemes satisfy certain useful properties that we use to develop public-private distribution learners in different settings. For example, the existence of a realizable compression scheme is closed under taking mixtures or products of distributions.

The connection to sample compression schemes

In this section we prove Theorem 1.1/D.1, the sample complexity equivalence between _sample compression_ (Definition 2.5), _public-private learning_ (Definition 2.4), and an intermediate notion we refer to as _list learning_ (Definition 3.2). We do so by giving sample-efficient reductions between the three notions (Propositions 3.1, 3.4, and 3.5). The propositions state the quantitative translations between: compression size \(\) and number of bits \(t\), number of private samples \(n\), and list size \(\).

### Compression implies public-private learning

We start by establishing that the existence of a sample compression scheme for \(\) implies the existence of a public-private learner for \(\).

**Proposition 3.1** (Compression \(\) public-private learning).: _Let \(()\). Suppose \(\) admits \(((,)\), \(t(,),m_{C}(,))\) realizable sample compression. Then \(\) is public-privately learnable with \(m(,,)=m_{C}(,)\) public and \(n(,,)=O((}+)(t(,)+(,)(m_{C}(,))+()))\) private samples._

Proof sketch.: The full proof is given in Appendix D.1, and mirrors that of Theorem 4.5 from  (albeit adapted to the public-private setting). Fix \(,(0,1]\) and \(>0\). Let \(=(,)\), \(t=t(,)\), and \(m=m_{C}(,)\). We draw a public sample \(}\) of size \(m\), and enumerate all combinations of a size \(\) subset of \(}\) with a binary string of length \(t\). Essentially, we "guess" the encoding of the unknown distribution \(p\). Running the decoder on this set of possible encodings gives us a set of distributions; some of them are close to \(p\). Then, with private samples only, we use the pure DP \(3\)-agnostic learner for finite classes (Fact C.2) to pick one such out. 

### Public-private learning implies list learning

Next, we show that the existence of a public-private learner for a class of distributions implies the existence of a _list learner_ for the class. A list learner for a class \(\) takes input samples from any \(p\) and outputs a finite list of distributions, one of which is close to \(p\).

**Definition 3.2** (List learner).: Let \(()\). For \(,(0,1]\) and \(\), an \((,,)\)_-list learner for \(\)_ is an algorithm \(^{m}\{L():|L|\}\), such that for any \(p\), if we draw a dataset \(=(X_{1},,X_{m})\) i.i.d. from \(p\), then

\[}_{ p^{m}}\{(p,())\} 1-.\]

**Definition 3.3** (List learnable class).: A class of distributions \(()\) is _list learnable to list size \((,)\) with \(m(,)\) samples_ if for every \(,(0,1]\), letting \(=(,)\) and \(m=m(,)\), there is an \((,,)\)-list-learner for \(\) that takes \(m\) samples.

If \(\) satisfies the above, irrespective of the list size complexity \((,)\), we say \(\) is _list learnable with \(m(,)\) samples_.

Now, we state our reduction of list learning to public-private learning. The key step of our proof is showing that, upon receiving samples \(}\), outputting a finite cover of the list of distributions that a public-private learner would succeed on _given public data_\(}\) is a successful strategy for list learning.

**Proposition 3.4** (Public-private learning \(\) list learning).: _Let \(()\). Suppose \(\) is public-privately learnable with \(m_{P}(,,)\) public and \(n(,,)\) private samples. Then for all \(>0\), \(\) is list-learnable to list size \((,)=( n(,,))\) with \(m(,)=m_{P}(,,)\) samples._

Proof.: Let \(>0\) be arbitrary. Fix any \(,(0,1]\). By assumption, \(\) admits a \((,,)\)-public-private learner \(\), which uses \(m m_{P}(,,)\) public and \(n n(,,)\) private samples. We use \(\) to construct a \((,,( n))\)-list learner that uses \(m\) samples. Consider any \(}=(_{1},,_{m})^{m}\) and the class

\[_{}}=\{q:}_{  q^{n}}_{Q(},)}\{( Q,q)\}\}.\]Note that by definition, \(_{}}\) has a \((,)\)-learner under \(\)-DP that takes \(n\) samples. Hence, by Fact C.1 it follows that any \(\)-packing of \(_{}}\) must have size \(( n)=\). Let \(_{}}\) be such a maximal \(\)-packing, hence it is also an \(\)-cover of \(_{}}\) with \(|_{}}|\). We define our list learner's output, \((})=_{}}\). It remains to show that for any \(p\), with probability \( 1-\) over the sampling of \(} p^{m}\), \((p,(}))\). Suppose otherwise, that is, there exists \(p_{0}\), such that

\[*{}_{} p_{0}^{m}}\{ (p_{0},(}))>\}>.\]

Since \((})\) is a \(\)-cover of \(_{}}\), we have that with probability \(>\) over the sampling of \(} p_{0}^{m}\), \(p_{0}_{}}\). This contradicts the success guarantee of \(\):

\[*{}_{}  p_{0}^{m}, p_{0}^{m}\\ Q(},)}\{(Q,p_{0})>\} *{}\{(Q,p_{0})> p_{0}_{}}\} *{}\{p_{0}_{}}\}\] \[>=.\]

The second inequality follows by the definition of \(Q_{}}\): conditioned on the event \(p_{0}_{}}\), the probability, over the private samples \( p_{0}^{n}\) and the randomness of the algorithm \(\), that the output \(Q\) of our algorithm satisfies \((Q,p_{0})\) is \(<\). 

### List learning implies compression

We state the final component of Theorem 1.1/D.1: the existence of a list learner for a class of distributions \(\) implies the existence of a sample compression scheme for \(\). This follows from the definitions: given samples \(}\), the encoder of the sample compression scheme runs a list learner \(\) on \(}\). It passes along \(\), and, with knowledge of the target distribution \(q\), the index \(i\) of the distribution in \((})\) that is close to \(q\). The decoder receives this information and outputs \((})_{i}\). The proof can be found in Appendix D.2.

**Proposition 3.5** (List learning \(\) compression).: _Let \(()\). Suppose \(\) is list learnable to list size \((,)\) with \(m_{L}(,)\) samples. Then \(\) admits \(((,),t(,),m(,))=(m_{L}(,),_ {2}((,)),m_{L}(,))\) realizable sample compression._

## 4 Applications

Here, we state a few applications of the connections obtained via Theorem 1.1/D.1. First, we recover and extend results on the public-private learnability of high-dimensional Gaussians and mixtures of Gaussians, using known results on sample compression schemes. Second, we describe the closure properties of public-private learnability: if a class \(\) is public-privately learnable, the class of mixtures of \(\) and the class of products of \(\) are also public-privately learnable.

### Public-private learnability of Gaussians and mixtures of Gaussians

There are known realizable sample compression schemes for the class of Gaussians in \(^{d}\), as well as for the class of all \(k\)-mixtures of Gaussians in \(^{d}\). Hence, these classes are public-privately learnable.

**Fact 4.1** (Robust compression scheme for Gaussians [1, Lemma 5.3]).: _The class of Gaussians over \(^{d}\) admits \((O(d),O(d^{2}()),O(d())\)-robust sample compression._

**Fact 4.2** (Realizable compression scheme for mixtures of Gaussians [1, Lemma 4.8 applied to Lemma 5.3]).: _The class of \(k\)-mixtures of Gaussians over \(^{d}\) admits \((O(kd),O(kd^{2}()+()),O())\) realizable sample compression._

Gaussians.From Theorem 1.1/D.1 and Fact 4.1, we get a public-private learner for Gaussians over \(^{d}\) using \(O(d())\) public and \((+(1/)}{^{2}}++(1/)}{ })\) private samples (Corollary E.1). This recovers the result of  on Gaussians up to a factor of \(O(())\) in public sample complexity, and improves the private sample complexity by a \((1/)\) factor.

Mixtures of Gaussians.From Theorem 1.1/D.1 and Fact 4.2, we get a public-private learner for the class of \(k\)-mixtures of Gaussians in \(^{d}\) using \(((1/)}{})\) public and \((+(1/)}{^{2}}++(1/)}{ })\) private samples (Theorem 1.2/Corollary E.2).

In terms of \(k,d\), and \(\), the public sample complexity of this learner is less than the \((}{^{2}})\) necessary and sufficient sample complexity for the problem non-privately . This also implies that in the regime where \(>\), having more public samples (but still \((}{^{2}})\)) cannot improve private sample complexity. Under pure DP, no finite sample size suffices; under approximate DP, \((d^{4}(1/)}{^{2}})\) has been shown to suffice .

Algorithms for _parameter estimation_, like the mixture of Gaussians estimators from  cannot be directly compared as they target a strictly stronger success criteria under stronger assumptions on the underlying distribution.  gives an estimator for separated Gaussian mixtures that uses \((})\) public and \((}{w_{*}^{2}}+}{w_{*}^{2}})\) private samples satisfying \(}{2}\)-zCDP, where \(w_{*}\) is the minimum component mixing weight. In terms of the privacy guarantee and private sample complexity, our result is a strict improvement for density estimation, since \(k=O(})\). In the setting where \(w_{*}=()\), 's algorithm uses \(\)-factor fewer public samples. Furthermore, their algorithm runs in time polynomial in the sample complexity.

### Public-private learnability of mixture and product distributions

If a class is realizably compressible, the class of its \(k\)-mixtures and the class of its \(k\)-products are also realizably compressible. Being realizably compressible with \(O(m(,))\) samples is equivalent to being public-privately learnable with \(O(m(,))\) public samples. Hence, we have black-box reductions of public-private learnability of mixture/product classes to public-private learnability of their base classes.

**Theorem 4.3** (Public-private learning for mixture and product distributions (Informal; see Theorems E.5 and E.7)).: _Let \(k 1\). If \(()\) is public-privately learnable with \(m(,,)\) public samples, then for any \(_{0}>0\):_

1. _The class of_ \(k\)_-mixtures of_ \(\) _is public-privately learnable with_ \(O( m(,,_{0}))\) _public samples._
2. _The class of_ \(k\)_-products of_ \(\) _(over_ \(^{k}\)_) is public-privately learnable with_ \(O(() m(/k,,_{0}))\) _public samples._

The full statements and proof can be found in Appendix E.2. Here, we use the non-constructive reduction of list learning to public-private learning, and hence this does not yield a finite time algorithm. Note also that the target privacy \(\) does not appear in the public sample complexity (it only affects the amount of private samples required).

## 5 Agnostic and distribution-shifted public-private learning

The setting we have examined thus far makes the following assumptions on the data generation process: (1) _same distribution_ - public and private data are sampled from the same underlying distribution; and (2) _realizability_ - public and private data are sampled from members of the class \(\).

 shows that for Gaussians over \(^{d}\), the first condition can be relaxed: they give an algorithm for the case where the public and the private data are generated from different Gaussians with bounded TV distance. However, they do not remove the second assumption.

We show that for general classes of distributions that _robust_ compression schemes yield public-private learners, which: (1) can handle public-private distribution shifts (i.e., the setting where the public data and the private data distributions can be different); and (2) are agnostic, i.e., they do not require samples to come from a member of \(\), and instead, promise error close to the best approximation of the private data distribution by a member of \(\). Since Gaussians admit a robust compression scheme (Fact 4.1), we obtain public-private Gaussian learners that work under relaxed forms of these assumptions on the data generating process (Theorem 1.3/F.1).

We first formally define the notion of _agnostic and distribution-shifted public-private learning_, and then prove the main result of this section.

**Definition 5.1** (Agnostic and distribution-shifted public-private learner).: Let \(()\). For \(,(0,1]\), \(>0\), \(\), and \(c 1\) a \(\)_-shifted \(c\)-agnostic \((,,)\)-public-private learner for \(\)_ is a public-private \(\)-DP algorithm \(:^{m}^{n}(())\), such that for any \(,p()\) with \((,p)\), if we draw datasets \(}=(_{1},,_{m})\) i.i.d. from \(\) and \(=(X_{1},,X_{n})\) i.i.d. from \(p\), and then \(Q(},)\),

\[\\ }^{m}, p^{n}}_{Q( },)}\\ \{(Q,p) c(p,)+ \} 1-.\]

**Theorem 5.2** (Robust compression \(\) agnostic and distribution-shifted public-private learning).: _Let \(()\) and \(r>0\). If \(\) admits \(((,),t(,),m_{C}(,))\)\(r\)-robust compression, then for every \(,(0,1]\) and \(>0\), there exists a \(\)-shifted \(\)-agnostic \((,,)\)-public-private learner for \(\) that uses \(m(,,)=m_{C}(,)\) public samples and \(n(,,)=O((}+)(t(,)+(,)(m_{C}(,))+( )))\) private samples._

Proof.: The proof again mirrors the proof of Theorem 4.5 in . The key observation (and difference from the proof in Appendix D.1) is the following: for the unknown distribution \(p()\), consider \((p,)\). If \((p,)\), the output \(Q\) of any algorithm satisfies \((p,Q) 1(p,)\). Hence, we can assume \((p,)<\), and let \(q_{*}\) with \((p,q_{*})<\{,(p,)+ {}{12}\}\) as guaranteed by such.

By triangle inequality, \((,q_{*})<r\). This implies that when we generate hypotheses \(}\) to choose from using the \(r\)-robust sample compression with samples from \(\), with high probability there will be some \(q}\) with \((q,q_{*})\). We have

\[(p,q)(p,q_{*})+(q_{*},q)(p,)++=.\]

Applying the 3-agnostic \(\)-DP learner for finite classes from  (Fact C.2) with the above setting of \(n\) gives us the result. 

## 6 Lower bounds

We give a lower bound on the number of public samples required to public-privately learn Gaussians in \(^{d}\). We know that Gaussians in \(^{d}\) are public-privately learnable with \(d+1\) public samples from . We show that this is within \(1\) of the optimal: the class of Gaussians in \(^{d}\) is _not public-privately learnable_ with \(d-1\) public samples. The following is the formal statement of Theorem 1.4.

**Theorem 6.1**.: _The class \(\) of all Gaussians in \(^{d}\) is not public-private learnable with \(m_{P}(,,)=d-1\) public samples, regardless of the number of private samples. That is, there exists \(_{d},_{d}>0\) such that for any \(n\), \(\) does not admit a \((_{d},_{d},1)\)-public-private learner using \(d-1\) public and \(n\) private samples._

Our result leverages the connection between public-private learning and list learning. The existence of such a public-private learner described above would imply the existence of a list learner for \(d\)-dimensional Gaussians taking \(d-1\) samples as input. We show, using a "no-free-lunch"-style argument (e.g. Theorem 5.1 from ) that such a list learner cannot exist. The proof of Theorem 6.1, given in Appendix G, goes through the following steps.

1. We reduce list learning to public-private learning, via Proposition 3.4;
2. We establish a technical lemma that relates the PAC guarantee of a list learner with its average performance over a set of problem instances, via a "no-free-lunch"-style argument (Lemma G.1);
3. For every \(d 2\), we find a sequence of hard subclasses of Gaussians over \(^{d}\), which satisfy the conditions of Lemma G.1. This forms the set of hard problem instances that imply a lower bound on the error of any list learner for the class (does not receive enough samples);4. Since list learning to arbitrary error with few samples is impossible, public-private learning to arbitrary error with few public samples must also be impossible.

## 7 Learning when the Yatracos class has finite VC dimension

In this section, we describe a public-private learner for classes of distributions whose _Yatracos class_ has finite VC dimension. We start by defining the Yatracos class of a family of distributions.

**Definition 7.1** (Yatracos class).: For \(()\), the _Yatracos class_ of \(\) is given by

\[=\{\{x:p(x)>q(x)\}:p q\}.@note{ footnote}{This is for when the distributions in $$ are discrete. For classes of continuous distributions, we substitute $p$ and $q$ for their respective density functions.}\]

**Theorem 7.2**.: _Let \(()\). Let \(\) be the Yatracos class of \(\), denote by \(()\) and \(^{*}()\) the \(\) and dual \(\) dimension of \(\). \(\) is public-privately learnable with \(m\) public and \(n\) private samples, where_

\[m=O(()()+ ()}{}) n=O( ()^{2}\,^{*}()+()}{^{3}}).\]

Theorem 7.2/1.5 says that classes of distributions whose Yatracos class have finite VC dimension can be public-privately learned. Note that the number of public samples used is indeed fewer than the \(O(()}{^{2}})\) sample requirement in the non-private analogue of the result (Fact H.1).

The proof is given in Appendix H. The result is a consequence of a known public-private uniform convergence result [BCM\({}^{+}\)20, Theorem 10]. To adapt it to our setting, we (1) modify their result for pure DP (rather than approximate DP); and (2) conclude that uniform convergence over the Yatracos sets of \(\) suffices to implement the learner from Fact H.1.

## 8 Conclusion

In this work, we connect public-private distribution learning to the notions of sample compression and list learning. In doing so, for broad classes of distributions, we introduce approaches to: (1) design sample-efficient public-private learners; (2) prove lower bounds on how much public data is required for public-private learnability. In the following, we list several questions for future study.

**Question 8.1**.: _For a class \(\), our work examines the minimal amount of public data needed to render \(\) pure privately learnable. How much do we need to render \(\) approximate DP learnable?_

**Question 8.2**.: _The VC bound of Theorem 1.5/7.2, although more general, is "qualitatively" loose. For Gaussians, it yields a \(O(}{})\) public sample complexity, though we know \(O(d)\) is possible, notably with no dependence on \(\). On the other hand, \((1/)\) public samples are required for public-privately learning mixtures of Gaussians. What qualities of a distribution admit public-private learning with \(\)-independent public sample complexity? Stronger: can we find more illuminating characterizations of the sample complexity of list learning?_

**Question 8.3**.: _Our work studies sample complexity improvements from using public data. Can public data lead to algorithmic improvements, that is, runtime efficiency or simpler algorithms?_