# Necessary and Sufficient Conditions for Optimal Decision Trees using Dynamic Programming

Jacobus G. M. van der Linden  Matthijs M. de Weerdt  Emir Demirovic

Delft University of Technology, Department of Computer Science

{J.G.M.vanderLinden, M.M.deWeerdt, E.Demirovic}@tudelft.nl

###### Abstract

Global optimization of decision trees has shown to be promising in terms of accuracy, size, and consequently human comprehensibility. However, many of the methods used rely on general-purpose solvers for which scalability remains an issue. Dynamic programming methods have been shown to scale much better because they exploit the tree structure by solving subtrees as independent subproblems. However, this only works when an objective can be optimized separately for subtrees. We explore this relationship in detail and show the necessary and sufficient conditions for such separability and generalize previous dynamic programming approaches into a framework that can optimize any combination of separable objectives and constraints. Experiments on five application domains show the general applicability of this framework, while outperforming the scalability of general-purpose solvers by a large margin.

## 1 Introduction

Many high-stake domains, such as medical diagnosis, parole decisions, housing appointments, and hiring procedures, require human-comprehensible machine learning (ML) models to ensure transparency, safety, and reliability . Decision trees offer such human comprehensibility, provided the trees are small . This motivates the search for _optimal_ decision trees, i.e., trees that globally optimize an objective for a given maximum size.

The aforementioned application domains wildly differ from one another, and therefore the objective and constraints also differ, leading to a variety of tasks: e.g., cost-sensitive classification for medical diagnosis ; prescriptive policy generation for revenue maximization ; or ensuring fairness constraints are met . For broad-scale application of optimal decision trees, we need methods that can _generalize_ to incorporate objectives and constraints such as the ones from these application domains, while remaining _scalable_ to real-world problem sizes.

However, many state-of-the-art methods for optimal decision trees lack the required scalability, for example, to optimize datasets with more than several thousands of instances or to find optimal trees beyond depth three. This includes approaches such as mixed-integer programming (MIP) , constraint programming (CP) , boolean satisfiability (SAT)  or maximum satisfiability (MaxSAT) .

Dynamic programming (DP) approaches show scalability that is orders of magnitude better  by directly exploiting the tree structure. Each problem is solved by a recursive step that involves two subproblems, each just half the size of the original problem. Additional techniques such as bounding and caching are used to further enhance performance.

However, unlike general-purpose solvers, such as MIP, DP cannot trivially adapt to the variety of objectives and constraints mentioned before. For DP to work efficiently, it must be possible to solve the optimization task at hand _separately_ for every subtree.

Therefore, the main research question considered here is to what extent can this separability property be generalized? In answering this question we provide a generic framework called _STreeD_ (Separable Trees with Dynamic programming). We push the limits of DP for optimal decision trees by providing conditions for separability that are both necessary and sufficient. These conditions are less strict and extend to a larger class of optimization tasks than those of state-of-the-art DP frameworks [52; 66]. We also show that any combination of separable optimization tasks is also separable. We thus attain generalizability similar to general-purpose solvers, while preserving the scalability of DP methods.

In our experiments, we demonstrate the flexibility of STreeD on a variety of optimization tasks, including cost-sensitive classification, prescriptive policy generation, nonlinear classification metrics, and group fairness.

As is commonly done, we assume that features are binarized beforehand. Therefore, STreeD returns optimal _binary_ decision trees under the assumption of a given binarization.

In summary, our main contributions are 1) a generalized DP framework (STreeD) for optimal decision trees that can optimize any _separable_ objective or constraint; 2) a proof for necessary and sufficient conditions for separability; and 3) extensive experiments on five application domains that show the flexibility of STreeD, while performing on par or better than the state of the art.

The following sections introduce related work and preliminaries. We then further define separability, show conditions for separability, and provide a framework that can find optimal decision trees for any separable optimization task. Finally, we provide five diverse example applications and test the performance of the new framework on these applications versus the state-of-the-art.

## 2 Related Work

Decision tree learningBecause optimal decision tree search is an NP-Hard problem , most traditional solution methods for decision tree learning were heuristics. These heuristics, such as CART  and C4.5 , often employ a top-down compilation, splitting the tree based on a local information gain or entropy metric. However, for each new objective, new splitting criteria need to be devised, and often this splitting criterion only indirectly relates to the real objective.

With increasing computational power, optimal decision tree search for limited depth has become feasible. Bertsimas and Dunn  and Verwer and Zhang  showed that optimal trees better capture the information of the dataset than heuristics by directly optimizing the objective at hand, resulting on average in a 1-5% gain in out-of-sample accuracy for trees of similar or smaller size.

However, their MIP models -and also the state-of-the-art MIP models [2; 37; 86; 93]- may often take several hours for medium-sized datasets, even when considering small trees up to depth three. Others have proposed to use SAT [8; 42; 64], MaxSAT [34; 76], and CP . These methods also lack scalability , or -in the case of SAT- solve a different problem: finding a minimal tree with no misclassifications. Because scalability is such an issue for these methods, many propose to solve the problem with variants of local search, such as coordinate descent [11; 26], tree alternating optimization  and a heuristic SAT approach .

In contrast, DP approaches find globally optimal trees while achieving orders of magnitude better scalability , so the survey by Costa and Pedreira  concludes that specialized DP methods are the most promising future direction for optimal decision trees. Nijssen and Fromont  proposed DL8, the first dynamic programming approach for optimal decision trees, which they later generalized to a broader set of objectives and constraints . Aglin et al. [3; 4] improved the scalability of DL8 by adding branch and bound and new caching techniques to the updated algorithm DL8.5. Hu et al.  and Lin et al.  added sparsity-based pruning and new lower bound techniques. Demirovic et al.  improved scalability by adding a special solver for trees of depth two, a similarity lower bound, and other techniques. Recent developments include an anytime algorithm [21; 67] and learning under memory constraints .

Objectives and constraintsDecision tree learning can be extended by considering a variety of constraints. Nanfack et al.  categorized these constraints into structure, attribute, and instance constraints. Structure constraints limit the structure of the tree, such as its depth or size. Attribute constraints impose limits based on the attribute values. Examples are monotonicity constraints , cost-sensitive classification  and group fairness constraints . Instance constraints operate on pairs of instances, such as robustness constraints , individual fairness constraints , and must- or cannot-link constraints in clustering . Among these, structure constraints are most widely included in decision tree learning methods.

Many of these constraints or objectives can be added to MIP models. Therefore, the literature shows a multitude of MIP models for a variety of applications, such as fairness , algorithm selection , and robustness . However, scalability remains an issue.

Nijssen and Fromont  show how the DP-based DL8 algorithm  can be generalized for a variety of objectives, provided that the objectives are _additive_, i.e., the value of an objective in a tree node is equal to the sum of the value in its children. Constraints are required to be _anti-monotonic_, i.e., a constraint should always be violated for a tree whenever it is violated for any of its subtrees. They consider constraints and objectives such as minimum support in a leaf node, C4.5's estimated error rate, Bayesian probability estimation, cost-sensitive classification, and privacy preservation.

Since then, new DP approaches have improved on the runtime performance of DL8. This, however, reduced the generalizability of those methods. DL8.5 [3; 4], for example, can optimize any additive objective but does not support constraints. MurTree  provides new algorithmic techniques that result in much better scalability but only considers accuracy. GOSDT  can optimize additive objectives that are linear in the number of false positives and negatives but also does not support constraints. When the objective is nonlinear, they no longer use DP. Demirovic and Stuckey  show how DP can be used to optimize even nonlinear functions, provided the objective is monotonically increasing in terms of the false positives and negatives, but they also do not consider constraints.

SummaryDecision tree learning is often approached through top-down induction heuristics, which depend on developing complex custom splitting criteria for each new learning task and may perform suboptimally in terms of classification accuracy. Optimal methods often outperform heuristics in accuracy but typically lack scalability. Optimal DP approaches have better scalability but lack generalizability to other objectives and constraints. In the next sections, we address this by pushing the limits of what can be solved by a general yet efficient DP framework for optimal decision trees.

## 3 Preliminaries

This section introduces notation, defines the problem, and explains how dynamic programming solutions for optimal decision trees work.

Notation and problem definitionLet \(\) be a set of features and let \(\) be a set of labels that are used to describe an instance. Let \(\) be a dataset consisting of instances \((x,k)\), with \(x\{0,1\}^{||}\) the feature vector and \(k\) the label of an instance. Because the features are binary, we introduce the notation \(f\) and \(\) for every feature \(f\) to denote whether an instance satisfies feature \(f\) or not. In the same way, let \(_{f}\) describe the set of instances in \(\) that satisfy feature \(f\), and \(_{}\) the set of instances that does not.

Let \(=(B,L,b,l)\) be a binary tree with \(B\) the internal branching nodes, \(L\) the leaf nodes, \(b:B\) the assignment of features to branching nodes and \(l:L\) the assignment of labels to leaf nodes. The left and right child nodes of a branching node \(u B\) are given by \(u_{L}\) and \(u_{R}\), respectively. Instances that satisfy a feature branching test are sent to the right subtree, and the rest to the left.

Then, for example, when minimizing misclassification score (the number of misclassified instances), the cost \(\) of a decision tree can be computed by the recursive formulation:

\[(,u)=_{(x,k)}(k  l(u))&u L\\ (_{},u_{L})\,+(_{b(u)},u_{R })&u B\] (1)

The task is to find an optimal decision tree \(\) that minimizes the objective value over the training data given a maximum tree depth \(d\). We now explain how this can be optimized with DP, and in the next section, we generalize this to any separable decision-tree optimization task.

Dynamic programmingDP simplifies a complex problem by reducing it to smaller repeated subproblems for which solutions are cached. For example, minimizing misclassification score with a binary class can be solved with DP as follows (adapted from ):

\[T(,d)=\{|^{+}|,|^{-}|\}&d=0\\ _{f}\{\ T(_{f},d-1)\ +\ T(_{f},d-1)\}&d>0 \] (2)

This equation computes the minimum possible misclassification score for a dataset \(\) and a given maximum tree depth \(d\). Recursively, as long as \(d>0\), a feature \(f\) is selected for branching such that the sum of the misclassification score of the left and right subtree is minimal. In the leaf node (when \(d=0\)), the label of the majority class is selected: either the positive (\(^{+}\)) or negative (\(^{-}\)) label. This approach is further optimized by using caching and bounds.

As is common with DP notation, Eq. (2) returns the solution value (or cost) and not the solution (the tree). In the remainder of the text, we refer to solution values and solutions interchangeably, with one implying the other and vice versa.

While Eq. (2) yields a single optimal solution, Demirovic and Stuckey  investigated the use of DP for nonlinear bi-objective optimization by searching for a Pareto front of optimal solutions: i.e., the set of solutions that are not Pareto dominated (\(\)) by any other solution:

\[()=\{v\ v^{}\ (v^{} v)\}\] (3)

Consequently, every subtree search also no longer returns just one solution but a Pareto front. For this, they introduce a \(\) function that combines every solution from one subtree with every solution from the other subtree, resulting in a new Pareto front.

## 4 Framework for separable objectives

In this section, we generalize previous DP methods for optimal decision trees to a new general framework that can solve any separable optimization task. First, we define the problem. Second, we formalize what is meant by separability in the context of learning decision trees and then we prove necessary and sufficient conditions for optimization tasks to be separable. Third, we present the generalized framework. Finally, we show separable optimization task formulations for four example domains.

### Problem definition and notation

We now generalize the previously introduced problem of minimizing misclassification score to any decision tree optimization task by using common DP notation. Given a state space \(\) and a solution space \(\), we define:

**Definition 4.1** (Optimization task).: An _optimization task_ is described by six components:

1. a cost function \(g:\ ()\) that returns the cost of action \(a\) in state \(s\), where the action is either assigning label \(\) or branching on feature \(f\);
2. a transition function \(t:\ \{0,1\}\) that provides the next state after branching left or right on feature \(f\), denoted by \(f\) or \(\{0,1\}\);
3. a comparison operator \(\ :\ \{0,1\}\) that determines Pareto dominance;
4. a combining operator \(\ :\ \) that combines solution values to one value;
5. a constraint \(c:\ \{0,1\}\) that determines feasibility of a given solution \(v\) and state \(s\);
6. and an initial state \(s_{0}\).

For all optimization tasks in this paper, the state \(s\) can be described by the dataset \(\) and the branching decisions \(F\) in parent nodes. The transition function is given by \(t(,F,f)=_{f},F\{f\}\), and the initial state \(s_{0}\) is \(,\). But our framework extends beyond this as well.

When minimizing misclassifications, the cost function is \(g(,F,)=|\{(x,k)\ \  k\}|\); the comparison operator \(\) is \(<\); the combining operator \(\) is addition and the constraint \(c\) returns all solutions as feasible. Similarly, more complex objectives, such as F1-score and group fairness, which do not fit the conditions of DL8 , can be defined by using these building blocks. We show four examples in Section 4.4.

he final cost of a tree \(=(B,L,b,l)\) with root node \(r\) is now given by calling \((s_{0},r)\) on the following recursive function, which generalizes Eq. (1):

\[(s,u)=g(s,l(u))&u L\\ (t(s,b(u)),u_{L})\;\;(t(s,b(u)),u_{R})\;\;g(s,b(u))&u B\] (4)

In leaf nodes, the cost of a tree is given by cost function \(g\). In branching nodes, the combining operator \(\) combines the cost of the left and right subtree and the branching costs.

Given an optimization task \(o= g,t,,,c,s_{0}\) and a maximum tree depth \(d\), the aim is to find a tree (or a Pareto front of trees) that satisfies the constraint \(c\) and optimizes (according to the comparison operator \(\)) the cost \(\).

With this definition of an optimization task, we can generalize several of the concepts introduced in the preliminaries. Let \(\) describe a set of possible solutions and let

\[(,s)=\{v c(v,s)=1\}\] (5)

be the subset of all feasible solutions in \(\) for state \(s\). The optimal set of solutions is given by

\[\,(,s)=((,s)),\] (6)

the Pareto front of feasible solutions in \(\), with \(\) depending on the comparison operator \(\). Furthermore, we generalize the definition for \(\) from :

\[(_{1},_{2},s,f)=\{v_{1} v_{2} g(s,f)  v_{1}_{1},v_{2}_{2}\}\] (7)

This returns all combinations of solutions from sets \(_{1}\) and \(_{2}\) by using the combining operator \(\).

### Separability

An optimization task is separable if optimal solutions to subtrees can be computed independently of other subtrees. For example, in the tree in Fig. 1, the optimal label L3 should be independent of the branching decision F2 and labels L1 and L2. Label L2 should be independent of L1 and L3.

**Definition 4.2** (Separable).: An optimization task is _separable_ if and only if the optimal solution to any subtree can be determined independently of any of the decision variables that are not part of that subtree or the parent nodes' branching decisions.

The general idea to prove that an optimization task satisfies Def. 4.2 is to use complete induction over the maximum tree depth \(d\). For the base step (\(d=0\)) it is sufficient to require the cost and transition functions to be _Markovian_: their output should depend only on the current state and the chosen decision. For the induction step (\(d>0\)), we need to show that the optimization task satisfies the _principle of optimality_: that optimal solutions for trees of depth \(d\) can be constructed from only the optimal solutions to its subtrees and the new decision (see Def. A.1). In summary:

**Proposition 4.3**.: _An optimization task \(o= g,t,,,c,s_{0}\) is separable if and only if its cost function \(g\) and transition function \(t\) are Markovian and the task \(o\) satisfies the principle of optimality._

A full proof for this and all subsequent propositions and theorems can be found in Appendix A.

To satisfy the _principle of optimality_, the combining operator \(\) must _preserve order_ over \(\), and the constraint \(c\) must be _anti-monotonic_. These two notions are explained next.

We introduce the new notion _order preservation_ that guarantees that any combination of optimal solutions using the combining operator \(\) always dominates a combination with at least one suboptimal solution. Many objectives, such as costs, are _additive_ with \(<\) as the \(\) operator. Addition preserves order over \(<\). However, _addivity_ is not a necessary condition. We present _order preservation_ instead as a necessary condition (see Appendix A.2).

Figure 1: An example tree of depth two with five decision variables: two branching decisions F1 and F2, and three leaf node label assignments: L1, L2, and L3.

**Definition 4.4** (Order preservation).: A combining operator \(\)_preserves order_ over a given comparator \(\), if for any given state \(s\), feature \(f\) and solution sets \(_{1}\) and \(_{2}\), with \(s_{1}=t(s,f)\), \(s_{2}=t(s,)\), \(v_{1}(_{1},s_{1}),v_{1}^{} _{1}\) and \(v_{2}(_{2},s_{2})\), with \(v_{1} v_{1}^{}\), then \(v_{1} v_{2} v_{1}^{} v_{2}\) (and \(v_{2} v_{1} v_{2} v_{1}^{}\), if \(\) is not commutative).

To guarantee that applying \(\) as defined in Eq. (5) does not prune any partial solution that is part of the final optimal solution, constraint \(c\) must be _anti-monotonic_: if a constraint is violated in a tree, it is also violated in any tree of which this tree is a subtree. However, in order to speak of a _necessary_ condition, we redefine anti-monotonicity to require that any solution which is constructed from at least one subsolution that is infeasible, cannot be an optimal solution.

**Definition 4.5** (Anti-monotonic).: A constraint \(c\) is _anti-monotonic_ if for any state \(s\), feature \(f\) and solution sets \(_{1}\) and \(_{2}\), with \(s_{1}=t(s,f)\), \(s_{2}=t(s,)\), with \(v_{1}_{1}\) and \(v_{2}_{2}\), if \( c(v_{1},s_{1})\) or if \( c(v_{2},s_{2})\), then \(v_{1} v_{2}(,s)\).

Minimum support (minimum leaf node size) is an example of an anti-monotonic constraint .

With these conditions and definitions in place, we have the necessary and sufficient conditions for separability and can present the main theoretical result of this paper:

**Theorem 4.6**.: _An optimization task \(o= g,t,,,c,s_{0}\) is separable if and only if its cost function \(g\) and transition function \(t\) are Markovian, its combining operator \(\) preserves order over its comparison operator \(\) and the constraint \(c\) is anti-monotonic._

### Dynamic programming formulation

We now present the general DP framework _STreeD_ (Separable Trees with Dynamic programming, pronounced as _street_):

\[T(s,d)=(_{} \{\,g(s,)\,\},s)&d=0\\ (_{f}(T( t(s,f),d-1),T(t(s,),d-1),s,f),s)&d>0\] (8)

Pseudo-code for STreeD and additional algorithmic techniques for speeding up computation, such as a special depth-two solver, caching, and upper and lower bounds, as well as techniques for sparse trees and hypertuning, can be found in Appendix B. The appendix also provides the conditions for the use of these techniques. Furthermore, in Appendix A we prove the following Theorem:

**Theorem 4.7**.: _STreeD, as defined in Eq. (8), finds the Pareto front for any optimization task that is separable according to Def. 4.2._

### Examples of separable optimization tasks

To illustrate the flexibility of STreeD, we present four diverse example applications for which separable optimization tasks can be formulated. The first two are also covered by the _additivity_ condition from . The last two do not fit this condition but are covered by our framework.

Cost-sensitive classificationCost-sensitive classification considers costs related to obtaining (measuring) the value of features in addition to misclassification costs . Typical applications are in the medical domain when considering expensive diagnostic tasks and asymmetrical misclassification costs. See Appendix C for a more comprehensive introduction and related work.

Let \(\) be the instances in a leaf node and let \(M_{k,}\) be the misclassification costs when an instance with true label \(k\) is assigned label \(\), and let \(m(F,f)\) be the costs of obtaining the value of feature \(f\) (this value also depends on the set of previously measured features \(F\), because we consider that some tests can be performed in a group and share costs). This results in the following cost function:

\[g(,F,)=_{(x,k)}M_{k,}  56.905512ptg(,F,f)=|| m(F,f)\] (9)

This optimization task is separable because the function \(g\) is Markovian, the combination operator \(\) is addition, and the comparison operator is \(<\).

Prescriptive policy generationDecision trees can also be used to prescribe policies based on historical data, to maximize the expected reward (revenue) of the policy [12; 45]. An example is medical treatment assignment based on historical treatment response. This is done by reasoning over counterfactuals (the expected outcome if an action other than the historical action was taken).

In Appendix D we provide related work and show three different methods for calculating the expected reward from the literature: regress and compare, inverse propensity weighting, and the doubly robust method. The cost function for each of these is Markovian and the combining operator is addition. Therefore, prescriptive policy generation can be formulated as a separable optimization task. It is also possible to add constraints to the policy, for example, when maximizing revenue under a capacity constraint. We show in Appendix A.4 that capacity constraints are also separable.

Nonlinear classification metricsNonlinear objectives such as F1-score and Matthews correlation coefficient are typically used for unbalanced datasets. Demirovic and Stuckey  provide a globally optimal DP formulation for optimizing such nonlinear objectives for binary classification. STreeD can also optimize for these metrics. For F1-score, for example, one can formulate a combined optimization task that measures the false positive rate for each class \(k\{0,1\}\) as a separate optimization task:

\[g_{k}(,)=|\{(x,k^{}) k ^{}\}|&=k\\ 0&\] (10)

Both of these tasks are separable, and in Appendix A.5 we show that multiple separable tasks can be combined into a new separable optimization task that results in the Pareto front for misclassifications for each class. This Pareto front can then be used to find the decision tree with, e.g., the best F1-score. See Appendix E for more related work and other details.

Group fairnessOptimizing for accuracy can result in unfair results for different groups and therefore several approaches have been recommended to prevent discrimination , one of which is demographic parity , which states that the expected outcome for two classes should be the same. Previous MIP formulations for group fairness have been formulated [1; 44] and recently also a DP formulation, even though at first hand a group fairness constraint does not seem separable .

Let \(a\) denote a discrimination-sensitive binary feature and \(y\) a binary outcome, with \(y=1\) the preferred outcome and \(\) the predicted outcome; then demographic parity can be described as satisfying \(P(=1 a=1)=P(=1 a=0)\). This requirement is typically satisfied by limiting the difference to some percentage \(\). Let \(N(a)\) be the number of people in group \(a\), and \(N()\) the people not in group \(a\). The demographic parity requirement can now be formulated as two separable threshold constraints:

\[g_{a}(,)=_{a}|}{N(a)}&=1\\ _{a}|}{N()}&=0 g_{}(,)=_{a}|}{N(a)}&=0\\ _{a}|}{N()}&=1\] (11)

These cost functions with the two threshold constraints that limit both to \(1+\), and an accuracy objective can be combined into one separable optimization task as shown in Appendix A.4 and A.5, and therefore it can be solved to optimality with STreeD. We show the derivation of these constraints, a similar derivation for equality of opportunity, and more related work in Appendix F. Note that we require demographic parity on the whole tree and not on every subtree. In fact, requiring demographic parity on every subtree is an example of a constraint that does not satisfy anti-monotonicity.

### Comparison to previous theory and methods

Dynamic programming theoryIn contrast to what is common in general DP theory, our theory does not assume solution values to be real valued  or totally ordered . For example, Karp and Held  formulate the _monotonicity_ requirement of a DP as follows: for a given state \(s\), action \(a\), cost \(c\) and data \(p\), let \(h(c,s,a,p)\) be the cost of reaching state \(t(s,a)\) through an input sequence that reaches state \(s\) with cost \(c\). Monotonicity holds iff \(c_{1} c_{2}\) implies \(h(c_{1},s,a,p) h(c_{2},s,a,p)\). In words: if a partial input sequence \(A_{1}\) with cost \(c_{1}\) dominates another input sequence \(A_{2}\) with \(c_{2}\), then any other input sequence that starts with \(A_{1}\) dominates any other input sequence that starts with \(A_{2}\), thus satisfying the principle of optimality. This notion is similar to our _order preservation_, but we do not assume that the costs are real valued or that the costs are totally ordered.

Similarly, Li and Haimes  show how multiple optimization tasks can be combined into one, as we also show in Appendix A.5. They construct a separable DP formulation for optimization tasks that can be deconstructed into a series of optimization tasks, each of which is separable and monotonic. Their method also returns the set of nondominated solutions. However, their theory assumes that the solution value for each sub-objective is real, completely ordered, and additive. This limits their theory to element-wise additive optimization tasks. Our theory does not share these limitations.

Dynamic programming approachesIn comparison to the DP methods DL8  and GOSDT , STreeD covers a wider variety of objectives and constraints. Both STreeD and DL8 require constraints to be _anti-monotonic_. GOSDT does not support constraints. DL8 and GOSDT require _additivity_, whereas STreeD requires the less restrictive condition _order preservation_ (see Def. 4.4). Moreover, STreeD can cover a range of new objectives by also allowing for objectives and constraints with a partially defined comparison operator, and by allowing to combine several such objectives and constraints. Examples of problems that could not be solved to global optimality by DL8 and GOSDT, but can be solved with our framework, are group fairness constraints, nonlinear metrics, and revenue maximization under a capacity constraint. Moreover, compared to DL8 and GOSDT, STreeD implements several algorithmic techniques for increasing scalability, such as a specialized solver for trees up to depth two (see Appendix B).

Other approachesMIP can be used to model many optimization tasks, including non-separable optimization tasks. For example, optimizing decision tree policies for Markov Decision Processes can be optimized with MIP , but it is not clear how to do this with DP. However, MIP cannot deal with separable, but non-linear objectives, such as F1-score. Moreover, as our experiments also show, DP outperforms the scalability of MIP for the considered optimization tasks by several orders of magnitude.

CP so far has only been applied to maximizing accuracy  and (Max)SAT only to maximizing accuracy [34; 76] or finding the smallest perfect tree [42; 64].

Dunn  proposes a framework that can optimize many objectives for decision trees (see also ). Because of MIP's scalability issues, they propose a local search method based on coordinate descent. However, this method does not guarantee a globally optimal solution. Moreover, their method is not able to find a Pareto front that optimizes multiple objectives at the same time.

## 5 Experiments

To show the flexibility of STreeD, we test it on the four example domains introduced in Section 4.4. Additionally, we compare STreeD with two state-of-the-art dynamic programming approaches for maximizing classification accuracy. STreeD is implemented in C++ and is available as a Python package.1 All experiments are run on a 2.6 GHz Intel i7 CPU with 8GB RAM using only one thread. MIP models are solved using Gurobi 9.0 with default parameters .

In our analysis, we focus on scalability performance in comparison to the state-of-the-art optimal methods (if available). The following shows a summary of the results. The setup of all experiments, more extensive results, and related work of the application domains is provided in the appendices C-G.

### Cost-sensitive classification

For cost-sensitive classification, we compare STreeD with TMDP  both in terms of average expected costs and scalability. A direct fair comparison with TMDP is difficult, because TMDP provides no guarantee of optimality, allows for multi-way splits, and is run without a depth limit. We test STreeD and TMDP on three setups for 15 datasets from the literature and report normalized costs. We tune STreeD with a depth limit of \(d=4\). In Appendix C we show extended results and also compare with several heuristics from the literature. To our knowledge, no MIP methods for cost-sensitive classification including group discounts (i.e., when certain features are tested together, the feature cost decreases) exist, and therefore are not considered here.

For 21 out of 45 scenarios STreeD generates trees with significantly lower average out-of-sample costs than TMDP (\(p\)-value \(<5\%\)). TMDP has lower costs in 1 out of 45 scenarios. In all other scenarios,there is no significant difference. Both methods return trees that perform better and are smaller than those constructed by heuristics. Fig. 1(a) shows that STreeD is significantly faster than TMDP. Thus, it can be concluded that STreeD on average has slightly better out-of-sample performance than TMDP, returns trees of similar size, and is significantly faster than TMDP.

### Prescriptive policy generation

For prescriptive policy generation, we compare our method with the MIP model Jo-PPG-MIP  and the recursive tree search algorithm CAIPWL-opt . Jo et al.  show both analytically and through experiments the benefit of their method over  and . Their method constructs optimal binary trees based on three different teacher models: regress and compare, inverse propensity weighting, and a doubly robust method. CAIPWL-opt constructs optimal binary trees based on the doubly robust method. Our method implements the same teacher models; thus, all methods find the same solution. Therefore, we compare here only the runtime performance.

As described in detail in Appendix D, we test on the Warfarin dataset  and generate 225 training scenarios with 3367 instances and 29 binary features and run each algorithm with a given maximum depth of \(d\). We also generate 275 synthetic datasets with 10, 100, and 200 binary features, each with 500 training samples, and run each algorithm on every scenario with a given maximum depth of \(d=1,2\) and \(3\). When Jo-PPG-MIP hits the timeout of 300 seconds, we report the MIP gap.

Fig. 1(b) shows that STreeD can find optimal solutions orders of magnitude faster than both Jo-PPG-MIP and CAIPWL-opt while obtaining the same performance in maximizing the expected outcome.

### Nonlinear classification metrics

For assessing STreeD's performance on optimizing nonlinear metrics such as F1-score, we first compare it with the existing nonlinear MurTree method . We tasked both methods to find optimal trees of depth 3-4 according to an F1-score metric for 25 binary classification datasets from the literature. Fig. 1(c) shows that STreeD, while being more general, is on average seven times faster than MurTree (computed with geometric mean). This performance gain is in part due to a more efficient computation of the lower and upper bounds, as explained in Appendix B.

Figure 2: The percentage of instances for which the algorithm returns the (optimal) tree within the given runtime (higher is better). When MIP methods hit the timeout, the plot shows which percentage of problems are solved within the reported MIP gap. Instances for which all methods return a tree within one second are left out. Note the logarithmic x-axis.

This shows that STreeD can be applied to nonlinear objectives and even improves on the performance of a state-of-the-art specialized DP method for this task.

### Group fairness

For group fairness, we follow the experiment setup from  as explained in Appendix F. The task is to search for optimal trees for 12 datasets and for trees of depth \(d\) under a demographic parity constraint with at most \(1\%\) discrimination on the training data. We compare to the DP-based method DPF  and the MIP methods Aghaei-Fair-MIP  and Jo-Fair-MIP . When the MIP methods hit the timeout of 600 seconds, we report the MIP gap.

Fig. 1(d) shows the runtime results. As expected, DPF performs best since it is a DP method specifically designed for this task. STreeD is more general and yet remains close to DPF, while being several orders of magnitude faster than both MIP methods. In Appendix F we further show how STreeD is the first optimal DP method for optimizing an equality-of-opportunity constraint.

It can be concluded that STreeD allows for easy modeling of complex constraints such as demographic parity and equality of opportunity while outperforming MIP methods by a large margin.

### Classification accuracy

Finally, we compare STreeD with two state-of-the-art dynamic programming approaches for optimal decision trees that maximize classification accuracy: DL8.5 [3; 4] and MurTree . All three methods find optimal decision trees for maximum depth four and five for 25 binary classification datasets from the literature. The results in Appendix G show that on average STreeD is more than six times faster than DL8.5 and is close to MurTree, with MurTree being 1.25 faster (computed with the geometric mean). Since DL8.5 outperforms DL8  and MurTree outperforms GOSDT by a large margin , we can conclude that STreeD not only allows for a broader scope of optimization tasks than DL8 and GOSDT, but is also more scalable.

## 6 Conclusion

We present STreeD: a general framework for finding optimal decision trees using dynamic programming (DP). STreeD can optimize a broad range of objectives and constraints, including nonlinear objectives, multiple objectives, and non-additive objectives, provided that these objectives are separable. We apply DP theory to provide necessary and sufficient requirements for such separability in decision tree optimization tasks and introduce the new notion order preservation that guarantees the principle of optimality . We show that these results are more general than the state-of-the-art general DP solvers for decision trees [52; 66].

We illustrate the generalizability of STreeD in five application domains, two of which are not covered by the previous general DP solvers. For each, we present a separable optimization formulation and compare STreeD's scalability to the domain-specific state-of-the-art. The results show that STreeD sustains or improves the scalability performance of DP methods, while being flexible, and outperforms mixed-integer programming methods by a large margin on these example domains.

STreeD allows for a much broader set of applications than presented here. Therefore, future work should further investigate STreeD's performance on, for example, regression tasks and other non-additive objectives. STreeD could also be used to further develop optimization of trees that lack explanation redundancy . Finally, STreeD could further be improved by adding multi-way branching and allowing for continuous features.