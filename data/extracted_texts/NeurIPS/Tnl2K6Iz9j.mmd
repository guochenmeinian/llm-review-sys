# Dynamic Service Fee Pricing under Strategic Behavior:

Actions as Instruments and Phase Transition

 Rui Ai

MIT

ruiai@mit.edu &David Simchi-Levi

MIT

dslevi@mit.edu &Feng Zhu

MIT

fengzhu@mit.edu

###### Abstract

We study a dynamic pricing problem for third-party platform service fees under strategic, far-sighted customers. In each time period, the platform sets a service fee based on historical data, observes the resulting transaction quantities, and collects revenue. The platform also monitors equilibrium prices influenced by both demand and supply. The objective is to maximize total revenue over a time horizon \(T\). Our problem incorporates three practical challenges: (a) initially, the platform lacks knowledge of the demand side beforehand, necessitating a balance between exploring (learning the demand curve) and exploiting (maximizing revenue) simultaneously; (b) since only equilibrium prices and quantities are observable, traditional Ordinary Least Squares (OLS) estimators would be biased and inconsistent; (c) buyers are rational and strategic, seeking to maximize their consumer surplus and potentially misrepresenting their preferences. To address these challenges, we propose novel algorithmic solutions. Our approach involves: (i) a carefully designed active randomness injection to balance exploration and exploitation effectively; (ii) using non-i.i.d. actions as instrumental variables (IV) to consistently estimate demand; (iii) a low-switching cost design that promotes nearly truthful buyer behavior. We show an expected regret bound of \(}(_{S}^{-2})\) and demonstrate its optimality, up to logarithmic factors, with respect to both the time horizon \(T\) and the randomness in supply \(_{S}\). Despite its simplicity, our model offers valuable insights into the use of actions as estimation instruments, the benefits of low-switching pricing policies in mitigating strategic buyer behavior, and the role of supply randomness in facilitating exploration which leads to a phase transition of policy performance.

## 1 Introduction

A large number of transactions nowadays take place on third-party platforms, such as shopping on Amazon, taking rides on Uber, and ordering takeout food on DoorDash . For these platforms, deciding how to set the service fee is an important issue  that not only affects the platform's short-term revenue but also impacts long-term user retention. Therefore, understanding buyers' demand curve is of significant importance for platforms aiming to maximize their revenue.

**Example 1.1**.: As an illustrative example, as a ride-hailing platform, Uber possesses information on the supply side (drivers), specifically the number of drivers available on the road at any given moment. Simultaneously, when buyers (passengers) request a ride, it matches drivers with passengers and charges a certain fee. Uber charges a booking fee for each reservation. Over a certain time period,Uber's booking fee remains approximately the same, as shown in Figure 1. However, over a longer period of time, an exploratory dynamic pricing strategy can be beneficial to acquire more demand information.

Meanwhile, consumers often refrain from taking rides when prices are high even if these prices are within their willingness to pay, aiming at inducing Uber to reduce the price or offer them coupons (which can be understood as a negative service fee) to reduce future purchase expenses. This phenomenon is common in both the psychology  and the economics  literature.

For third-party platforms, pricing service fees can face three challenges:

1. _Demand information needs to be learned._ Typically platforms can observe the number and quoted prices of sellers on the platform, i.e., the supply curve, but the preference of buyers, or the demand curve, is not observable. At the same time, due to legal restrictions , platforms in many cases cannot personalize pricing for different buyers but can only set a uniform price for a group of buyers. Therefore, it is crucial to learn about the buyer group's willingness to pay.
2. _Only equilibria can be observed._ Regarding buyer information, platforms can only observe the equilibrium price and quantity, say \(P^{e}\) and \(Q^{e}\) respectively, which depend on the service fee set by the platform itself and the changing supply curve. Thus, due to changes in the demand curve, \((P^{e},Q^{e})\) may only reveal partial information about the demand curve and thus can fail to recover the full demand curve. In the absence of randomness in the supply curve, \((P^{e},Q^{e})\) could even form an upward-sloping curve, far from the characteristics of a demand curve.
3. _Buyers may exhibit strategic behavior._ When buyers interact with the platform over an extended period, they may present a false demand curve to the platform, hoping to gain more benefits in future purchases, as shown in Example 1.1. The strategic behavior of buyers increases the difficulty for the platform to accurately estimate demand, and at the same time, causes the service fee to deviate from its optimal value, resulting in revenue loss. Pessimistically, Amin et al.  demonstrated that when the buyer possesses patience comparable to that of the seller, no learning algorithm can achieve sub-linear regret (cf. Appendix F.6).

In this paper, we address the above challenges by establishing the first set of theories for pricing service fees on third-party platforms. We summarize our contributions in the following.

* To the best of our knowledge, we are the first to attempt applying non-i.i.d. actions as instrumental variables in the problem of online pricing. In the traditional econometric framework , researchers often seek external instrumental variables to estimate the demand curve. However, this method has significant limitations because good instrumental variables are hard to find. We demonstrate that even when actions are not independent and identically distributed (i.i.d.) random variables, or even possess strong correlations with

Figure 1: _Uber._ Above are two Uber rides from the same city in February 2024. The price of the two rides differs by nearly double, yet the booking fee remains at $1.27 for both, suggesting that a fixed booking fee mechanism might be employed in February. However, over a longer period of time, Uber may switch to a dynamic pricing strategy.

one another, they still lead to excellent estimate of the demand curve. In Theorems 3.1, 3.2 and 4.3, we show our algorithms' optimal regret bounds.
* We discover that the randomness in supply can effectively assist us in learning the demand curve. This counterintuitive fact reveals why, in Theorem 3.2, we can achieve a regret of \(}(1)\), but in the case where there is no noise in supply, in Theorem 3.1, we can only expect a regret of \(}()\). We explain in Section 4 via lower bound results (Theorem 4.1 and 4.2) that these orders of magnitude differences are fundamental and unavoidable. Additionally, we detailed the phase transition points of regret bounds regarding supply randomness.
* We investigate robust pricing in the absence of prior knowledge of the buyer's discount rate. Our AaI and AAaI algorithms don't require the input of a discount rate to initiate, but can instead universally motivate buyers whose time has value to nearly truthfully report the demand curve. Specifically, our algorithm is also applicable in scenarios where the discount rate varies. The robustness of our algorithm is benign both in theory and applications.

### Related Work

This work is closely related to instruments in machine learning [4; 5; 12; 56; 73; 47; 24; 69; 23], pricing with strategic buyers [55; 2; 29; 37; 1; 38], and demand learning under uncertainty [14; 26; 46; 21; 7; 48; 20; 50; 28]. Due to space constraints, additional references are provided in Appendix A for readers' reference. Detailed discussion of the relation and comparison between our work and previous work is also presented in Appendix A.

**Notations.** For any positive integer \(n\), we let \([n]\) denote the set \(\{1,...,n\}\) and \(n_{1}:n_{2}\) represent \(\{n_{1},...,n_{2}-1\}\). We use \((,^{2})\) to represent a Gaussian random variable with mean \(\) and variance \(^{2}\). Moreover, we use \(()\) when ignoring constant terms while \(}()\) when ignoring constants and logarithmic terms. Similarly, we have \(()\), \(()\), \(()\) and \(()\).

## 2 Model and Assumptions

We consider an online dynamic pricing problem faced by a platform interacting with a representative buyer for \(T\) rounds. The platform aims to maximize its revenue against the rational and strategic buyer by dynamically adjusting the service fees.

**Information structure of platform pricing.** In each round \(t\), multiple sellers pose different portfolios on the platform and thus form the cumulative supply curve, denoted by \(P_{St}=P_{St}(Q)\) as a function of \(Q\). For example, Uber can observe in real-time how many different types of drivers are available on the platform, such as UberX, UberXL, Black SUV, etc. Similarly, Ticktemaster knows how many tickets are still available in each area. Then, the platform sets a service fee \(a_{t}_{ 0}\). Here we assume the sellers are not strategic: as the platform formulates the fee-charging plan after observing \(P_{St}(Q)\), there is no issue concerning trustfulness for sellers. In each round \(t\), the representative buyer may receive a private signal, such as a shock on income, and form a time-dependent demand curve, denoted by \(P_{Dt}=P_{Dt}(Q)\). However, the buyer may behave as if her demand is \(P^{}_{Dt}\) rather than \(P_{Dt}\) because of her forward-looking strategic behavior, elaborating below. Together with service fee \(a_{t}\), the platform observes an equilibrium price and equilibrium quantity in the market, denoted by \((P^{e}_{t},Q^{e}_{t})\), satisfying

\[P^{e}_{t}:=P_{St}(Q^{e}_{t})+a_{t}=P^{}_{Dt}(Q^{e}_{t}).\] (1)

Then, the platform receives revenue \(_{t}=a_{t} Q^{e}_{t}(P_{St},P^{}_{Dt},a_{t})\) in this round. As a result, across the time horizon of \(T\), the platform has a cumulative revenue: \(_{t=1}^{T}a_{t} Q^{e}_{t}(P_{St},P^{}_{Dt},a_{t})\). As a concrete setting, we study the case when both the supply and demand curves have linear forms following canonical literature of both demand learning [19; 61; 44; 74] and instrumental variable models .

**Assumption 2.1**.: Assume that the supply curve in round \(t\) has the form of

\[P_{St}(Q)=_{0}+_{1}Q+_{St}\]

and the demand curve is

\[P_{Dt}(Q)=_{0}+_{1}Q+_{Dt}.\]

The independent noise terms \(_{St}\) and \(_{Dt}\) follow normal distributions, \((0,^{2}_{S})\) and \((0,^{2}_{D})\), respectively.

To avoid nuisance from market feasibility, we assume that \(_{0}>_{0} 0\), \(_{1} 0>_{1}\), and that all equilibrium prices and quantities are positive and bounded. We note from Equation (1) that if \(Q_{t}^{e}\) is negative, then optimal \(Q_{t}^{e}\) shall be truncated as \(0\). For simplicity of analysis, we will not make truncation throughout the paper. This shall not influence the validity of our analysis and results.

**Utility-maximizing buyer.** We assume the representative buyer fully knows the learning policy used by the platform to set service fees . Note that the buyer is only aware of the policy beforehand. If the policy involves randomization, the buyer knows in advance the policy but not the realization of the policy. In fact, previous behavior-based pricing literature  has suggested that committing to a pricing strategy can help the platform earn more revenue.

In each time period \(t\), the buyer receives a surplus, say \(_{t}(P_{St},P_{Dt},P_{t}^{e},Q_{t}^{e},a_{t})\), which depends on the supply curve, demand curve, equilibrium price, equilibrium quantity, and the service fee. For brevity, we will write \(_{t}\) as an abbreviation of \(_{t}(P_{St},P_{Dt},P_{t}^{e},Q_{t}^{e},a_{t})\). We utilize the Ramsey model , which originates from the economic literature, to calculate the surplus. More rigorously, we employ Assumption 2.2. We postpone the discussion of the economic intuition behind Assumption 2.2 and its implications for calculating the surplus to Appendix B for interested readers.

**Assumption 2.2**.: We assume a private market where all sellers are civilian-run enterprises.

The representative buyer has a discount rate \([0,1)\). When \(=0\), the buyer is myopic and only considers her surplus in the current round \(t\). She truthfully purchases the optimal quantity of items she needs. That is, her realized demand curve \(P_{Dt}^{}\) coincides with \(P_{Dt}\). However, when \((0,1)\), i.e., the buyer is far-sighted , she may choose to _misreport_ her demand curve \(P_{Dt}^{} P_{Dt}\) in exchange for increasing long-term expected cumulative utility: \([_{s=t}^{T}^{s-t}_{s}]\), where again \(_{s}\) is the surplus gained at time \(s\). The expectation is taken over the randomness for all time \(s>t\): supply randomness \(_{Ss}\), demand randomness \(_{Ds}\), and potential randomness from the platform pricing policy. Here, we use the general economic term "misreport" to represent that the equilibrium price and quantity are not aligned with the buyer's true demand. They can be either larger or smaller. Note that the buyer won't show her demand curve \(P_{Dt}(Q)\) to the platform at all, and all the information the platform can learn is through observing equilibrium prices and quantities. Thus, it is important for the platform to design a careful service charging mechanism to motivate a truthful disclosure of the demand curve from the buyer.

**Performance metric.** With the help of the revelation principle , there is an incentive-compatible-direct mechanism for pricing to achieve the highest revenue. So, we can define optimal service fee from Equation (1) by

\[a_{t}^{*}=*{argmax}_{a_{t} 0}[a_{t} Q_{t}^{e} (P_{St},P_{Dt},a_{t})].\]

The expectation is taken over \(P_{Dt}\) since the platform needs to set \(a_{t}\) before the realization of \(P_{Dt}\). Define the suboptimality at time \(t\) as

\[_{t}(a_{t})=[a_{t}^{*} Q_{t}^{e}(P_{St},P_{Dt},a_ {t}^{*})-a_{t} Q_{t}^{e}(P_{St},P_{Dt}^{},a_{t})].\]

Our evaluation metric is then the revenue regret against a clairvoyant policy attained over the whole \(T\) rounds, namely,

\[(T)=_{t=1}^{T}_{t}(a_{t}).\]

**Remarks on the model.** We would like to provide some further remarks on the model as follows.

1. _Platform is patient while buyer's discount rate is \([0,1)\)._ In practice, platforms are usually less time-sensitive compared with individuals, for instance, in a sponsored search auction, where the platform usually auctions off large numbers of ad slots each time while buyers usually urgently need advertisement and value future rewards less. On the other hand, the platform is not especially concerned with slight decreases in immediate rewards and maybe more on user stickiness. Readers can refer to Drutsa , Golrezaei et al.  for more information on different time values for different market forces. Additionally, from a theoretical standpoint, achieving sub-linear regret is impossible when the buyer discount rate is one . Therefore, our paper focuses on strategic buyers whose discount rates fall within the \([0,1)\) range, accommodating both real-world scenarios and theoretical constraints.

_2. On and beyond the linear model._ In this paper, we focus on linear models. In practical scenarios, particularly when considering a localized segment of the market to avoid eliciting competitive reactions, there often emerges a pattern of linearity (which also serves as the cornerstone for the application of the so-called "Delta method" ). Further, Besbes and Zeevi  also suggests that in certain circumstances, misspecification stemmed from assuming a linear model is less detrimental than anticipated. We note that although we explicitly assume the linearity of the demand curve and the supply curve in the model, it should not be difficult to extend to some variations of non-linear models (e.g. log-log, semi-log model in hedonic pricing  and logistic model in click prediction ) like Ban and Keskin  with some extra assumption on non-linear factors, by utilizing the generalized method of moments (GMM). Our technique also has the potential to work in high-dimensional cases and even non-parametric Reproducing Kernel Hilbert Space (RKHS). Despite such extensions, we will adopt the linear model throughout this work for brevity and clarity. We leave further generalizations for future work.

## 3 Regret Upper Bounds: Actions as Instruments

In this section, we present our main algorithm AaI (Action-as-Instruments) and demonstrate its theoretical guarantees. We assume that \(T\) and \(_{S} 0\) are both known (\(_{D}\) need not be known a priori). This assumption will be further relaxed in the next section.

``` Input:\(T\). Initialization:\(\), \(\) and \(t 0\). for episode \(m=1,2,\)do  Estimate unknown parameters: \((_{0},_{1})(, )\) (Algorithm 4 in Appendix C.1).  Form estimate for the demand curve \(_{D}=_{0}+_{1}Q\).  Initialize datasets \(\) and \(\). for\(=t+1\)to\(t+2^{m}\)do  Observe the supply curve \(P_{St}=_{t}+_{1}Q\).  Select the action \(a_{t}(P_{St},_{D})\) using Algorithm 2.  Observe equilibrium \(o_{t}=(P_{t}^{*},Q_{t}^{*})\).  Update \( o_{t}\) and \( a_{t}\). endfor  Update round index: \(t t+2^{m}\). endfor ```

**Algorithm 1** AaI Algorithm.

We now elaborate on the design of AaI and how it overcomes the main challenges mentioned in Section 1. We first demonstrate the design of our low-switching regime. In Algorithm 1, to deal with the far-sighted buyer, we update our policy when \(t\) is a power of \(2\). The intuition behind the low-switching cost update is that since the buyer has a discount rate strictly lower than \(1\), long-run benefits will be hard to compensate for short-run loss. Under a low-switching regime, the gap between the buyer's behavior \(P_{D}^{}\) and the true demand curve \(P_{D}\) becomes small. In the existing literature, Ai et al.  utilizes explicit "buffer" periods against far-sighted buyers while other works such as Golrezaei et al. [37; 38] use implicit methods to motivate truthfulness. In Algorithm 1, we adopt an implicit way to punish untruthful behavior so that we don't need information about the buyer's discount rate, thus enhancing the robustness and universality of our algorithm. We note that the use of low-switching cost algorithms may not be necessary when facing a myopic buyer, though indispensable for a far-sighted buyer [34; 71].

Second, the proof of Theorem 3.1 and 3.2 relies on solving the challenge that the platform can only observe equilibrium prices and quantities. The novel approach we take here is to utilize the service fee price as an instrumental variable (reflected in Algorithm 4). Despite the fact that the service fees as actions are correlated, we prove they provide valid estimates of the true coefficients \((_{0},_{1})\), which is rigorously shown in Lemma 3.1 (in the lemma only \(_{1}\) is analyzed; a similar result also holds for \(_{0}\)).

**Lemma 3.1**.: _Let \(_{1t}\) be the estimated slope after round \(t\). Then, under Assumptions 2.1 and 2.2, with high probability, it holds that_

\[|_{1t}-_{1}|(}{t ^{}}+})t[T]_{S}=0,\]

_and_

\[|_{1t}-_{1}|(}{ _{S}}+^{2}(1-)t})t[T]_{S}>0.\]

Now let's discuss the magnitude of the artificially added noise (see Algorithm 2) -- which serves as an exploration step to learn demand information. Combined with our previous discussion, we will present our main theorems in this section. We differentiate between two cases: \(_{S}=0\) and \(_{S}>0\).

### \(_{S}=0\): \(}()\) Regret

We first consider the case when there is no supply randomness. At the beginning of each episode \(m\), we add a \((1)\) noise to the service fee. Then, we decay the magnitude of noise variance at an inverse square root rate. There are two key points when implementing the algorithm.

First, there is a trade-off between utilizing early data and recent data -- the more data we use, the better estimate we will have, but the early data may have bad data-generating processes which may cause extra nuisances. Therefore, we choose only to use data from the last episode, whose length is roughly half of all available data and we reset the magnitude of noise as long as we start a new episode to ensure sufficient exploration.

Second, there is a trade-off between adding larger and smaller randomness -- the more randomness we add to the service fee, the more accurate estimate we will obtain, whereas higher noise leads to larger revenue loss. In our design, in episode \(m\), the variance level of noise added is designed to be \((}})\) on average where \(2^{m}\) is the length of the episode. It decays at a relatively slow rate, aiming at exploration without losing much exploitation. We note that a special case of \(_{S}=0\) is when the supply curve coincides with the \(Q\)-axis (\(P_{St}(Q)=0\)) and the buyer has no strategic behavior (\(=0\)). This degenerates to the standard dynamic pricing problem  where a \(}()\) regret holds. The following theorem shows that with the additional features in our model (equilibrium observation, strategic behavior), an \(}()\) regret bound still holds.

**Theorem 3.1** (\(_{S}=0\)).: _Under Assumptions 2.1 and 2.2, for any fixed failure probability \((0,1)\), with probability at least \(1-\), Algorithm 1 achieves at most \((()+})\) regret against any buyer whose discount rate \([0,1)\) when supply doesn't have noise, i.e. \(_{S}^{2}=0\). Here, \(()\) hides only absolute constants._

### \(_{S}>0\): Noise Helps Learning

We then consider the case when there is supply randomness. In contrast to Section 3.1, here no random noise is injected into the empirical optimal action \(^{*}\) (see Algorithm 2). The following theorem shows that noise helps learning -- an \(}(1)\) regret is obtainable.

**Theorem 3.2** (\(_{S}>0\)).: _Under Assumptions 2.1 and 2.2, for any fixed failure probability \((0,1)\), with probability at least \(1-\), Algorithm 1 achieves at most \(()}{_{S}^{2}}+^{3}(1-)})\) regret against any buyer whose discount rate \([0,1)\). Here, \(()\) hides only absolute constants._

The regret upper bound in Theorem 3.2 contains two parts. The first \(( T)\) term is the main regret incurred by learning the demand curve -- which illustrates how noise helps learning. Although the platform can only observe equilibrium prices and quantities, the extra randomness in the supply curve automatically generates exploration and pushes the empirical optimal action \(^{*}\) from Algorithm 2 to vibrate around some intrinsic number. As a result, the estimation of \(\) generates a fast convergence rate of \((1/)\) (see Lemma 3.1) even if no active exploration is presented. As a comparison, in Section 3.1 when the supply curve is deterministic, the problem becomes "degenerate" to some extent. The equilibrium prices on the supplier side and equilibrium quantities lie on one line (the fixed supply curve) in the \(2\)-dimensional space, which forces us to do active exploration that leads to a \(()\) regret.

The second term is the extra regret due to the strategic behavior of the buyer. Golrezaei et al.  achieves an extra \((T}{^{2}(1/)})\) regret in repeated auction pricing when the discount rate is approaching one. Since \((1/) 2(1-)\) for \([0,1)\), we obtain better results in both the order of \( T\) and order of \(\). We note that since the implementation of Algorithm 1 doesn't depend on the buyer's discount rate \(\), it can achieve \(( T T)\) regret even if the discount rates are changing in different rounds -- as long as the discount rate \(_{t}\) has a uniform upper bound \(\) and \(<1\), which is widely observed in the real-world market, especially online advertising , Algorithm 1 remains good permanence.

From Theorems 3.1 and 3.2, we know the key to achieve \(}(1)\) regret is the internal randomness of the supply curve. Therefore, we have the following corollary.

**Corollary 3.2**.: _If the platform needs to set a uniform service fee in multi-markets, such as Order Processing Fee on Tickettmaster , the demand curve goes to_

\[_{Dt}=_{0}+_{1}+_{Dt},\]

_where \(\) is the Kronecker product of two matrices. Then, as long as in one market, the corresponding supply has internal randomness, Algorithm 1 can achieve \(}(1)\) regret by utilizing \(a_{t}\) as an instrument for all markets. Otherwise, it will suffer \(}()\) regret._

## 4 Regret Lower Bounds: Phase Transition

In this section, we present results on regret lower bounds. We will focus on the case when \(=0\) and investigate how the regret intrinsically scales as a function of \(T\) as well as \(_{S}\). We will show that there exhibits a phase transition phenomenon with respect to \(T\) and an inverse square law with respect to \(_{S}\). We first present a result when there is no supply randomness.

**Theorem 4.1**.: _Given any time horizon \(T\), when the supply doesn't have noise, the worst-case expected regret is lower bounded by \(()\). In \(()\) we are hiding a constant term irrelevant with \(_{S}\) and \(T\)._

Next, we provide a lower bound when \(_{S}\) can take any general positive number.

**Theorem 4.2**.: _Given any time horizon \(T\) and the supply noise level \(_{S}\), the worst-case expected regret is lower bounded by_

\[(^{2}(1+_{ +}(1/_{S}))}),\]

_where \(_{+}()=\{0,()\}\). In \(()\) we are hiding a constant term irrelevant with \(_{S}\) and \(T\)._

The proof of Theorem 4.1 depends on constructing two hard-to-differentiate instances such that the demand curves deviate with each other while the supply curves remain the same. The proof of Theorem 4.2 relies on the multivariate Van Trees inequality . An important step in both of the proof is when considering the magnitude of demand noise \(_{D}\), it should be dependent on \(_{1}\) and \(_{1}\). The reason is that if the noise magnitude is irrelevant with the slope parameters, the standard deviation of equilibrium prices and quantities observed by the platform can provide additional information on the true parameters -- this will make it possible for a policy to learn more quickly by "cheating". Only when the noise magnitude posits a delicate dependence on the true parameters, the equilibrium prices/quantities exhibit constant deviation across all instances without information leakage.

Now we give some remarks for the theorems. Theorem 4.1 states that the regret order in Theorem 3.1 is tight. It also implicitly provides some intuition for our choice of the magnitude of the artificially introduced noise in our algorithm design. The total variance of noise we add is proportional to \(\) -- this shall be the largest noise magnitude we shall use for sufficient exploration to match the \(()\) lower bound.

Theorem 4.2 shows that if \(_{S}>0\) is a constant irrelevant with \(T\), then our regret upper bound in Theorem 3.2 is tight up to a \( T\) factor. Moreover, Theorem 4.2 gives a valid lower bound if \(_{S}\) is entangled with \(T\). To be precise, if \(_{S}^{2}(1/)\), then the best we can hope is an \(}()\) regret. Only when \(_{S}^{2}(1/)\) can we expect a regret bound better than \(}()\).

Readers may immediately notice that there is a gap between our regret upper bounds (see Theorem 3.2) and the regret lower bound (see Theorem 4.2) when \(_{S}^{2}(1/)\). It raises the following question whether we can achieve the same regret upper bounds without knowing \(_{S}\) in advance. The answer is YES! We have the following theorem.

**Theorem 4.3**.: _Under Assumptions 2.1 and 2.2, there exists an algorithm, e.g., Algorithm 3, whose expected regret is at most \(}(_{S}^{-2})\) against any buyer with discount rate \([0,1)\). Here, \(}()\) hides only constants and logarithmic terms._

``` Input:\(T\). for\(t=1\)to\(T_{0}( T)\)do  Observe market randomness \(_{St}\)or supply intercept \(_{0}+_{St}\). endfor  Hypothesis Test:\(_{0}:_{S}^{2}(})\) and \(_{1}:_{S}^{2}(})\), denoting the result as \(\).  Conduct \((T-T_{0})\) with \((,,)\) (Algorithm 5 in Appendix C.2) replacing \((,)\). ```

**Algorithm 3** AAaI (Adaptive Action-as-Instruments) Algorithm.

In Algorithm 3, Act-HT is essentially a generalized version of Act: if \(_{0}\) holds, we treat \(_{S}\) as if it is \(0\); if not, we treat \(_{S}\) as it is. When \(T\) is unknown or infinite, we can leverage the well-known doubling trick [9; 16] to achieve the same order of regret. From Theorem 4.3, we know that when the supply randomness is small enough, namely, \(_{S}^{2}(1/)\), the expected regret has a fixed rate \(()\), whereas when the supply randomness is large enough, namely \(_{S}^{2}(1/)\), the expected regret is inversely proportional with respect to \(_{S}^{2}\) -- an inverse square law ignoring constants and logarithmic terms. Therefore, there exists an essential phase transition when \(_{S}^{2}(1/)\) (see Figure 4) -- this tells us that we should take market randomness into consideration whenever solving pricing problems.

## 5 Numerical Study

In this section, we conduct two simulation experiments. The goal is to test the performance of our algorithms as well as numerically demonstrate the phase transition phenomenon. We provide detailed experimental descriptions in Appendix G.

In the first experiment, we consider regret attained in Algorithm 1 under two scenarios. Here, we set \(T=10^{5}\). We replicate 10 times in each setting and draw the average regrets and their 95% confidence regions. We consider both constant \(_{S}^{2}\) and zero randomness in Figure 2. It's obvious that when \(_{S}^{2}(1)\), the growth rate of regret is significantly smaller than the growth rate when \(_{S}^{2}=0\). The first regret is slightly larger than 200 and the second one is more than 1200, validating the respective \((^{2}T)\) and \(( T)\) expected regrets. Numerically, when \(_{S}^{2}=1\), we find that the regrets when \(T=20000,40000,60000,80000,100000\) (\( T\) = 9.90,10.60,11.00,11.29,11.51) are 220, 230, 234, 236, and 237, respectively. These points are even slightly sublinear. So, the actual performance is even better than the theoretical bound. In addition, when there is no randomness in the supply, i.e., \(_{S}^{2}=0\), we have \(()\) = 6.43, 6.75, 6.95, 7.10, 7.17, respectively. The estimated slope by linear regression is 0.47, testifying our regret bound.

Moreover, we increase the number of trajectories to 100 and observe that the bandwidth of the corresponding confidence region significantly decreases (cf. Figure 3 (top, right)). Additionally, we test the regret under different \(_{S}^{2}\) values, say 0.5, 1, 1.5 and 2. We notice that the larger the \(_{S}^{2}\), the smaller the regret, which confirms our theoretical results (cf. Figure 3).

Then, we conduct the second experiment examining the dependency of regret on supply randomness \(_{S}^{2}\). We set \(T=10^{4}\) and range \(_{S}^{2}\) from 0.001 to 1. We replicate the simulation 20 times and use quantile statistics to enhance the robustness (see raw results in Figure 5, i.e., blue points). There are around 100 points choosing \(_{0}\) and we can observe the phase transition when \(_{S}^{2} 0.1\). Notice that Algorithm 3 has a \(( T)\) expected regret for \(_{0}\) but \((^{2}T)\) for \(_{1}\) when \(_{S}^{2}(})\) (cf. Appendix F.5). This additional \( T\) factor explains why there is increasing fluctuation in regret near the phase transition point, as Algorithm 3 engages in a mixture of applying \(_{0}\) and \(_{1}\). Finally, we employ locally weighted scatterplot smoothing (LOWESS)  to approximate regret for each level of randomness \(_{S}^{2}\), with the fitting depicted by a red line. We notice that regret first reaches a plateau and keeps nearly constant and then gradually decreases, testifying Theorem 4.3.

Figure 3: 95% confidence region of regret of Algorithm 1 over 100 trajectories: \(_{S}^{2}=0.5,1,1.5,2\) (top to bottom, left to right).

Figure 2: 95% confidence region of regret of Algorithm 1 over 10 trajectories: \(_{S}^{2}=1\) (left) and \(_{S}^{2}=0\) (right).

## 6 Conclusion

In this paper, we study the dynamic pricing problem for third-party platforms. Our model incorporates practical challenges involving lack of demand knowledge, limited observation of equilibria, and buyer strategic behavior. We design an effective policy that obtains optimal performance guarantees to address the challenges by injecting carefully chosen randomness, using non-i.i.d. actions as instruments, and forcing a low-switching design. Specifically, in the case of supply fluctuations, we achieve a regret upper bound of \(}(1)\), and when supply is fixed, we achieve a regret bound of \(}()\), both of which match the information-theoretical lower bounds. Additionally, we demonstrate the relationship between regret and supply randomness, and provide their optimal dependency and phase transition points.

Questions arise for future explorations. What is the dependence of regret on the discount rate \(\)? Our conjecture is that a discount rate strictly less than \(1\) will introduce inevitable \(()\) regret universally, meaning the regret upper bound in Theorem 3.2 is optimal with respect to \(\) but the bound in Theorem 3.1 may not. Unfortunately, the analysis can be very challenging, which we leave as an open question. Furthermore, one future work is to extend the linear model to more complex models and investigate whether the insights in this paper (e.g., phase transition) still hold. Despite the simplicity of our model, we hope our results offer valuable insights into solving general service fee pricing problems for third-party platforms.