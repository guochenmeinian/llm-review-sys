# Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training

Yefan Zhou* 1, Tianyu Pang*2, Keqin Liu2, Charles H. Martin3, Michael W. Mahoney4, and Yaoqing Yang1

First two authors contributed equally.

###### Abstract

Regularization in modern machine learning is crucial, and it can take various forms in algorithmic design: training set, model family, error function, regularization terms, and optimizations. In particular, the learning rate, which can be interpreted as a temperature-like parameter within the statistical mechanics of learning, plays a crucial role in neural network training. Indeed, many widely adopted training strategies basically just define the decay of the learning rate over time. This process can be interpreted as decreasing a temperature, using either a global learning rate (for the entire model) or a learning rate that varies for each parameter. This paper proposes TempBalance, a straightforward yet effective layer-wise learning rate method. TempBalance is based on Heavy-Tailed Self-Regularization (HT-SR) Theory, an approach which characterizes the implicit self-regularization of different layers in trained models. We demonstrate the efficacy of using HT-SR-motivated metrics to guide the scheduling and balancing of temperature across all network layers during model training, resulting in improved performance during testing. We implement TempBalance on CIFAR10, CIFAR100, SVHN, and TinyImageNet datasets using ResNets, VGGs and WideResNets with various depths and widths. Our results show that TempBalance significantly outperforms ordinary SGD and carefully-tuned spectral norm regularization. We also show that TempBalance outperforms a number of state-of-the-art optimizers and learning rate schedulers.

## 1 Introduction

Having a learning rate schedule that gradually decreases over time is crucial for the convergence and performance of state-of-the-art machine learning algorithms. Indeed, many optimization algorithms essentially boil down to designing a progression of parameter updates, as realized by different learning rate schedules [1; 2; 3; 4]. Common schedules assign a global learning rate per epoch, where the same learning rate is used for all layers in the model. This includes the family of cyclical learning rates , and parameter-wise learning rate schedules like Adam  and its variants [5; 6]. However, such a global learning rate schedule does not take into account the structural characteristics of neural networks (NNs). At the same time, parameter-wise learning rate schedules are sometimes used, but they have long been conjectured to have worse generalization performance than carefully tunedstochastic gradient descent (SGD) optimizers , and storing both first and second-order moments for each parameter can lead to substantially increased memory consumption . As mentioned in , storing the whole Megatron-Turing NLG requires 10 terabytes of aggregate memory, and the Adam optimizer's first and second-order moments  consume 40% of the memory. Nonetheless, improving parameter-wise learning rate schedules is an active field of study [4; 5; 10; 11].

A largely under-explored idea to reconcile the two extremes of setting a single global learning rate or assigning fine-grained parameter-level learning rates is to assign layer-wise learning rates. Such a learning rate assignment method does not require much storage cost, and it can assign very different training speeds to different layers. However, existing layer-wise schemes are often introduced as an additional part of hyperparameter sweeping, thus substantially increasing computational cost; and most lack a strong (or any) theoretical foundation. For instance, layer-wise learning rates can increase test accuracy in transfer learning  and domain adaptation , but these learning rates are often empirically tuned. More recently, motivated by the intuition that lower-level layers should be domain-specific and higher-level layers should be task-specific,  automates the search for an optimal set of learning rates. However, the authors find the nested, bi-level optimization scheme to be too computationally expensive in practice . AutoLR also automatically tunes its layer-wise learning rates according to the "role" of each layer . The method is validated almost entirely by empirical results, further explained by layer-wise weight variations. While the authors attempt to assign a different initial learning rate to each layer, the learning rate for each layer continues to stay largely constant throughout training. LARS [17; 18] is another method to assign layer-wise learning rate. It is based on the "trust ratio," defined as the ratio of weight norm to gradient update norm of each layer, and it is specifically used in large batch training to avoid gradient divergence.

In this paper, we propose TempBalance, a simple yet effective layer-wise learning rate assignment (and regularization) method, grounded in Heavy-Tail Self Regularization (HT-SR) Theory [19; 20; 21; 22; 23; 24]. Our approach leverages HT-SR Theory to assess the quality of each network layer. This is achieved through an analysis of the heavy-tail (HT) structure present in the Empirical Spectral Density (ESD) of NN weight matrices. Given this information, TempBalance meticulously adjusts the _temperature-like parameter_ to control each layer's quality, with the objective of ensuring consistently high quality across all layers of the network. From the _statistical physics viewpoint_ on learning and optimization [24; 25; 26; 27; 28], a temperature-like parameter refers to some quantity related to the empirical noise/stochasticity of the learning process. This is the noise scale described by [29; 30], and it can be written as a function of learning rate, batch size, and momentum. Prior research [19; 31] has shown that temperature-like parameters significantly influence HT structure in the ESD. Our approach, TempBalance, focuses on the strategic adjustment of the learning rate as the temperature-like parameter, thereby facilitating accurate control of the quality across each network layer, as characterized by its HT ESD structure. The following paragraph will delve deeper into the importance of HT-SR, highlighting its connection to the concept of layer-wise temperature.

**HT-SR Theory.** HT-SR Theory [19; 20; 21; 22; 23; 24] relies on the empirical fact that very well-trained models tend to exhibit strong correlations, resulting in HT structure in the ESD of each layer. To obtain this ESD, we take a NN with \(L\) layers and the corresponding weight matrices \(_{1},_{2},,_{L}\) with shape \(n m\) (where \(n m\)). For the \(i\)-th layer, we calculate the eigenvalues of its correlation matrix \(_{i}=_{i}^{T}_{i}\), and then we plot the ESD for that layer. Upon training, the ESD will typically gradually change to have an HT structure [19; 22]. We can then fit a power law (PL) distribution to the HT part of the ESD, and extract its exponent as, namely, PL_Alpha. The fitted PL will have the following formula:

\[p()^{-},_{}<<_{ }.\] (1)

The PL_Alpha metric measures the PL exponent of the weight matrices' ESD. Its underlying motivation stems from random matrix theory and statistical physics, as well as the empirical observation that HT ESDs are ubiquitous in well trained NN models [20; 22].

The PL_Alpha metric has been shown to predict the trends in the test accuracy of state-of-the-art models in computer vision (CV) and natural language processing (NLP), without even the need for access to training or testing data [22; 32]. According to , one can aggregate PL_Alpha's for different layers either by simple averaging or weighted averaging, and each can predict test accuracy in different cases [22; 32]. Furthermore, the _layer-wise_ nature of PL_Alpha makes it a fine-grained metric that can be used to assess the quality of individual layers of the network. Thus, in this paper, we extend and apply HT-SR Theory (originally designed as a predictive diagnostic for analyzingpre-trained NN models) to NN training, and we exploit the layer-wise information provided by PL_Alpha to determine the layer-wise learning rates for better test accuracy.

We note that, while it provides perhaps the most principled approach, the PL_Alpha metric is not the only way to try to measure the HT structure in NN models. Several recent papers  use different HT metrics to try to measure the spectral properties of other matrices (such as input/output covariance matrices, Fisher Information Matrices, and the Hessian). We show in Appendix A that these HT phenomena, measured in different ways on different matrices, are closely related to each other. On the other hand, this also means that (for the problems considered in this paper) the absolute numerical value of PL_Alpha is less important, as optimal PL exponents estimated by different algorithms can be different . What matters the most, as we show in this paper, is the layer-wise quality _ranked_ by the PL exponent: layers with a smaller PL_Alpha tend to be relatively more "overtrained," and layers with a larger PL_Alpha tend to be relatively more "undertrained." (We emphasize that this is true for the training problem we consider in this paper--for prior HT-SR work, the actual numerical value of PL_Alpha mattered _a lot._)

This observation leads to a simple and efficient way to _balance_ layer-wise learning rates: assign a lower learning rate to more overtrained layers and a larger learning rate to more undertrained layers, using PL_Alpha (see Figure 1). In implementing this learning rate balancing approach, we use a _scale-free_ method to map the PL_Alpha value of each layer to a predefined learning rate. This range is established in relation to a _global_ learning rate. Rather than depending on the absolute numerical values of PL_Alpha for each layer, this method emphasizes the importance of their relative differences and quality ranking. As a result, the learning rates assigned to individual layers remain stable and unaffected by arbitrary linear scaling of PL_Alpha estimates, whether they arise from the choice of the estimator or the presence of noisy measurements. On top of this, we can perform a grid search on the global learning rate. This is standard practice, and it is more efficient than grid-searching the layer-wise learning rates. We use this combination of assigning layer-wise learning rates using PL_Alpha and grid-searching the base global learning rate to avoid having to decide the "optimal" PL exponent, as this can be tricky due to different ways of measuring HT properties. Indeed, there are different ways to measure PL_Alpha, and we use the Hill estimator . While not necessarily the best estimate (see ), it shows stable performance in our experiments. We refer to our version of the PL_Alpha metric as the PL_Alpha_Hill metric, and we use it for the remainder of the paper.

Another popular way to change the ESD of weights is to constrain the spectral norm (i.e., the largest eigenvalue) using spectral norm regularization (SNR) . SNR provides a different form of regularization, compared to HT-SR, because it regulates the largest eigenvalue instead of the ESD slope (i.e., the PL_Alpha_Hill metric). It has been demonstrated that the spectral norm

Figure 1: Examples of PL fitting. Blue histograms depict the ESDs. Vertical black lines indicate the lower threshold \(_{}\) used to truncate the full ESDs and extract the tail portion. Solid red curves represent the tail part of the ESDs truncated by \(_{}\), while dashed red curves represent the fitted HT distributions. The left shows a more HT ESD, which requires a relatively lower learning rate. The right one shows a less HT ESD, which requires a relatively higher learning rate. Unlike prior work, we do not aim to find the “optimal” PL exponent. (Thus, we are less interested in obtaining a precise estimate than in obtaining a robust estimate.) Instead, we use the PL exponent to _rank_ ESDs to find layers that need higher/lower learning rates. These two ESDs correspond to two layers of a ResNet18 model trained on TinyImageNet.

and PL_Alpha_Hill serve distinct roles in evaluating model quality, and their combined form yields optimal predictions for test accuracy trends [19; 22; 23; 32]. To complement this, our results demonstrate that TempBalance outperforms SNR in training deep NNs in most cases. Moreover, when these two regularization methods are combined during training, they result in optimal test accuracy, thereby confirming their complementary roles. As described in [23; 32], the spectral norm and PL_Alpha_Hill measure the scale and the shape of a ESD, respectively; and regulating both the scale and shape is crucial for achieving better ESD regularization. We provide ablation studies on several layer-wise metrics for assigning layer-wise learning rates, including spectral norm, and we show that PL_Alpha_Hill performs the best among them.

**Our main contributions.** The following summarizes our main contributions.2

* We propose a simple yet effective layer-wise learning rate schedule, TempBalance, which is motivated by HT-SR Theory. Based on our empirical results, we obtain two main high-level insights. First, the mapping from PL_Alpha_Hill to learning rates should be scale-free, meaning that arbitrary linear scaling on the estimated PL exponent should not change the learning rate assignment. Second, searching for the minimum eigenvalue \(_{}\), a standard practice in PL fitting [19; 39; 40], leads to unstable training. To improve stability, we instead fix \(_{}\) as the median of the ESD.
* We compare TempBalance to ordinary SGD and SNR on various training tasks. This includes (1) different network architectures, such as ResNet, VGG, WideResNet, (2) different datasets, such as CIFAR10, CIFAR100, SVHN, TinyImageNet, and (3) ablation studies, such as varying widths, depths, initial learning rates, HT-SR layer-wise metrics, and PL fitting methods. Compared to ordinary SGD, TempBalance achieves higher test accuracy by setting layer-wise learning rates. Compared to SNR, TempBalance performs better by providing a more fine-grained regularization on _shape/slope_ instead of norm. We also show that combining TempBalance and SNR leads to further improved accuracy, verifying their complementary roles in informing deep learning training.
* We compare TempBalance to a range of state-of-the-art optimizers and learning rate schedulers, including SGDR , SGDP , Lookahead  and LARS [17; 18] on ResNet18 and ResNet34 trained on CIFAR100. We show that TempBalance achieves the highest test accuracy. We do careful hyperparameter tuning for all baselines. All results are obtained from five random seeds.
* We use ablation studies to show that PL_Alpha_Hill provides the best test accuracy among several layer-wise metrics considered by HT-SR [22; 32]. We also show that TempBalance maintains stable performance over SGD baselines when the model size changes. Furthermore, we show visualization results in Appendix B, verifying that TempBalance controls ESDs during training.

## 2 Related Work

Here, we give an overview of the statistical mechanics of learning and recent progress in theoretical and empirical studies on generalization metrics and their applications.

Statistical mechanics of learning and HT-SR.Our paper is motivated by statistical mechanics of learning [43; 44; 45], and especially by works that connect load-like [43; 46; 47] and temperature-like parameters [25; 48] to NNs. According to prior works in this area [24; 49], a _temperature-like parameter_ represents the amount of noise/variance in an iteration of SGD, such as learning rate, weight decay parameters, and batch size. A _load-like parameter_ represents the quantity and/or quality of data relative to the size of the learning model. To measure the quality of publicly-available pre-trained NNs, Martin and Mahoney  introduce HT-SR Theory, showing that the weight matrices of deep NNs exhibit HT ESDs, and they show that a decay coefficient of ESD, PL_Alpha, effectively gauges model quality. Subsequently, [31; 50; 51; 52; 53; 54] provide rigorous bounds for HT phenomenon and generalization, further adding support to HT-SR Theory. HT-SR has also been applied to predicting trends in test accuracy of large-scale NNs, in both CV and NLP [22; 23; 32], but it has yet to be systematically incorporated to novel training algorithms. Recently, more papers realize the important connections between deep NNs and statistical mechanics of learning . To name a few, Yang et al.  use load and temperature parameters to study a wide range of loss landscapes, providing a taxonomy from the perspective of global structure of a loss landscape. On the theory side, Baity-Jesi et al.  investigates the glassy behavior of NNs, and Barbier et al.  derives the optimal generalization error of generalized linear systems. More recently, Sorscher et al.  studies easy versus hard samples used in training and design a "data-pruning" method; and Zhou et al.  establishes a "three-regime model" in network pruning, unifying multiple practical hyperparameter tuning methods in a principled way.

Generalization measures.The search for effective and robust generalization metrics (which, importantly, can be very different than model quality metrics ) has been the focus of several recent theoretical and empirical works . Several recent papers apply metric-informed training and architecture search, such as those based on the Hessian , spectral norm , stable rank , and the spectrum of the neural tangent kernel . However, most generalization metrics, such as those based on the PAC-Bayes bounds , do not straightforwardly transfer to layer-wise quality metrics, because such generalization metrics often study the whole NN as an architecture-free function, and they lack the fine granularity to unveil the quality of each layer. Also, it has been mentioned in the literature  that (1) directly regularizing generalization metrics can lead to difficulty in training, (2) evaluating these regularization methods may be hard due to the existence of _implicit regularization_ in SGD, and (3) these metrics, especially norm-based metrics, cannot be expected to correlate with test accuracy causally , making the link between these generalization metrics and practical training methods nuanced. It will be clear in the next section that we do not regularize ESD metrics directly. Instead, we change learning rates to modify ESDs.

## 3 The TempBalance Algorithm

In this section, we introduce our simple yet effective method TempBalance, based on the PL_Alpha_Hill metric from HT-SR Theory. For a NN, different layers tend to have different values for PL_Alpha_Hill, : a layer with a larger PL_Alpha_Hill indicates that layer is relatively undertrained, while a layer with a smaller PL_Alpha_Hill indicates that layer is relatively overtrained. A natural idea is to adjust the degree of learning among different layers to get a balance: for a layer whose PL_Alpha_Hill is too large, we could assign a larger learning rate to accelerate its learning, and vice versa. The intuition of our method is transferring one layer's learning rate to another and hence, TempBalance. The pipeline is in Figure 2.

Figure 2: The pipeline diagram of TempBalance. In each epoch, TempBalance undergoes two steps: (a) Performing ESD analysis on all layers and employing PL fitting to derive the layer-wise PL_Alpha_Hill, and (b) Using the layer-wise PL_Alpha_Hill to assign learning rates to each layer using an assignment function.

We provide the details of TempBalance in Algorithm 1. Based on PL_Alpha_Hill in different layers, we use the learning rate schedule function \(f_{t}\) to map the \(i\)-th layer to a particular learning rate \(f_{t}(i)\) in epoch \(t\). We adopt \(f_{t}\) as a linear map between the layer-wise PL_Alpha_Hill and the final layer-wise learning rate, which has the following formula:

\[f_{t}(i)=_{t}[^{i}-_{t}^{}}{ _{t}^{}-_{t}^{}}(s_{2}-s_{1})+s_{1}],\] (2)

where \(_{t}\) means the base global learning rate in epoch \(t\), \((s_{1},s_{2})\) are the minimum and maximum learning rate scaling ratio relative to \(_{t}\), \(_{t}^{i}\) represents the layer \(i\)'s PL_Alpha_Hill at the beginning of epoch \(t\), and \((_{t}^{},_{t}^{})\) denote the minimum and maximum PL_Alpha_Hill across all the layers in epoch \(t\). Using (2), we ensure that the new learning rate \(f_{t}(i)\) is a scaled version of the original base learning rate \(_{t}\) and is always inside the interval \([s_{1}_{t},s_{2}_{t}]\). Note that \((s_{1},s_{2})\) serves as tunable hyperparameters in our method. We conducted ablation studies on it, which are detailed in Appendix C. The hyperparameter values used across all experiments can be found in Appendix D. Our studies reveal that the optimal results are usually achieved around (0.5, 1.5).

To fit the PL distribution \(p()\) defined in (1), we use the Hill estimator [36; 71]. (It is not the best estimator for fine-scale diagnostics based on HT-SR Theory [19; 22], but it is robust, and it suffices for our purposes.) For the \(i\)-th layer, suppose the weight matrix is \(_{i}\) and the correlation matrix \(_{i}^{}_{i}\) has ascending eigenvalues \(\{_{i}\}_{i=1}^{n}\). Then, the Hill estimator calculates PL_Alpha_Hill using the following:

\[=1+^{k}ln^{}{ _{n-k}}})},\] (3)

where \(k\) is the adjustable parameter. We adopt \(k=\) in our experiments. Note that changing \(k\) essentially changes the lower eigenvalue threshold \(_{}\) for (truncated) PL estimation, as shown by the vertical black line in Figure 1. Choosing \(k=\) means using the largest half of the eigenvalues to estimate the slope. We empirically find that fixing \(k\) for all layers leads to more stable performance than searching \(k\) for different layers (e.g., optimizing \(k\) using the Kolmogorov-Smirnov test , as is needed for other applications of HT-SR Theory [19; 22]).

One advantage of mapping PL_Alpha_Hill to learning rates using (2) is that the scale of PL_Alpha_Hill is unimportant, i.e., linearly scaling PL_Alpha_Hill arbitrarily does not change the learning rate assignment because the linear scaling cancels each other in (2). This can maximally reduce the artifact of estimating the ESD PL exponent/slope due to estimation noise, which has been found to be a tricky issue in practice [19; 23].

## 4 Empirical results

In this section, we give full details of the experimental setup (Section 4.1) and compare our method TempBalance to a few baselines (Section 4.2), and then (Section 4.3) we perform ablation studies on varied initial learning rates, model widths, HT-SR layer-wise metrics, and PL fitting methods.

### Experimental setup

**Datasets.** We consider CIFAR100, CIFAR10, SVHN and Tiny ImageNet (TIN) . CIFAR100 consists of 50K pictures for training and 10K pictures for testing with 100 categories. CIFAR10 consists of 50K pictures for training and 10K pictures for testing with 10 categories. SVHN consists of around 73K pictures for training and around 26K pictures for testing with 10 categories. Tiny ImageNet consists of 10K pictures for training and 10K images for testing with 200 classes.

**Models.** We mainly consider three types of NNs: VGG, ResNet, and WideResNet (WRN) . For each network, we consider two different size options. For VGG, we consider VGG16 and VGG19. For ResNet, we consider ResNet18 and ResNet34. For WideResNet, we consider WRN16-8 and WRN28-6. Also, for ResNet and VGG, we consider three different widths for ablation studies.

**Hyperparameters.** One baseline is ordinary SGD training with a cosine annealing learning rate schedule (CAL), which follows the formula: \(_{t}=}{2}(1+())\), where \(t\) is the current epoch, \(T\) represents the total training epochs, and \(_{0}\) is the initial learning rate. We grid search the optimal initial (base) learning rate \(_{0}\) for the CAL baseline, using the grid \(\{0.05,0.1,0.15\}\) for ResNet and \(\{0.025,0.05,0.1\}\) for VGG. The momentum and weight decay are \(0.9\) and \(5 10^{-4}\), respectively, which are both standard choices.

Another baseline is spectral norm regularization (SNR). Prior work  uses the SNR objective:

\[_{i=1}^{n}l(f_{}( _{i}),_{i})+}{2} _{l=1}^{L}(W_{l})^{2},\] (4)

where \(_{sr}\) is the SNR coefficient, \((W_{l})\) is the largest eigenvalue, i.e., spectral norm of weight matrix \(_{l}\), and \(L\) is the number of layers. We use the power iteration method to calculate \((W_{l})\) in our experiments. For SNR, we grid search the optimal regularization coefficient \(_{sr}\), and we again adopt the CAL schedule for SNR, similar to the CAL baseline.

To make our results fully reproducible, we report in Appendix D all hyperparameters, random seeds, and all numerical values of experimental results shown in the figures.

### Comparing TempBalance and multiple baseline methods.

First, we compare TempBalance to two baseline training methods. See results in Figure 3. In the figure, CAL means SGD training with a CAL learning rate schedule, and SNR means SGD trained

Figure 3: **(Main result).** Comparing our method TempBalance (TB) to CAL and SNR. Our method TempBalance outperforms CAL and SNR in almost all the settings except for VGG19 and ResNet 34 on CIFAR 100. For all experiments, combining TempBalance and SNR (TB+SNR) yields the best performance. All baselines are carefully tuned. All results are obtained by running five random seeds. See Appendix D for the details in all hyperparameters.

with spectral norm regularization. TB means our method TempBalance, and TB + SNR means TempBalance combined with SNR. All error bars are obtained from five random seeds. From Figure 3, we see that TempBalance outperforms the CAL baseline in all settings. In almost all cases, it performs better than SNR baseline. When TempBalance does not outperform SNR, combining SNR with TempBalance leads to better test accuracy.

Second, we compare our method to a number of optimizers and learning rate schedulers that are not necessarily related to ESD of weights. These include SGDR, SGDP, Lookahead and LARS[17; 18], and we compare these baselines with TempBalance for ResNet18 and ResNet34 trained on CIFAR100. SGDR is stochastic gradient descent with warm restarts. SGDP modifies the ordinary SGD to compensate for the effect of increasing weight norm. Lookahead modifies SGD by letting each gradient update approximate the future trajectory of multiple updates. LARS assigns layer-wise learning rates based on the so-called "trust-ratio" and is the closest to our method. Results in Figure 4 show that TempBalance outperforms these baselines, and TempBalance combined with SGDP is the best-performing method. The crosses on each column represent training runs with different hyperparameters. Note that there are several other methods based on modifying the Adam optimizer , such as AdamW, AdamP and LAMB. However, we do not find them to provide better results than the SGD baseline with cosine annealing (CAL in Figure 4). The results are detailed in Appendix E.

### Corroborating results and ablation studies.

In addition to the main results (Figures 3 and 4), we provide corroborating results and ablation studies.

**Experiment one: tuning initial learning rate \(_{0}\).** We train models from scratch using TempBalance versus CAL with various initial learning rates, comparing TempBalance and the CAL baseline when both methods are allowed to search for the optimal hyperparameters. We again use ResNet18, ResNet34, VGG16 and VGG19 as our architectures and show results on CIFAR100. Results in Figure 5 show that TempBalance achieves a higher test accuracy than CAL for both ResNet and VGG.

**Experiment two: varying channel width.** We view the fraction of model width in Experiment one as "\(100\%\)," and we experiment with models with varied widths in \([50\%,100\%,150\%]\). We again used ResNet18, ResNet34, VGG16 and VGG19, and trained on CIFAR100, and we grid search for the optimal learning rate for each width to get the best accuracy. Results in Figure 6 show we find that TempBalance outperforms the baseline for all widths.

**Experiment three: varying HT-SR metric**. We use different HT-SR metrics to assign layer-wise learning rates. That is, we replace the layer-wise PL_Alpha_Hill in (2) with other HT-SR metrics including SpectralNorm and AlphaWeighted. Results in Figure 7 show that PL_Alpha_Hill achieves the optimal test accuracy.

Figure 4: (**More baseline optimizers).** Comparing our method TempBalance (TB) to cosine annealing (CAL) baseline and other state-of-the-art optimizers and learning rate schedulers for ResNet18 and ResNet34 trained on CIFAR100. Crosses for the same method represent different hyperparameter settings. Each cross represents the mean test accuracy of five random seeds. The best performing model thus far is TB combined with SGDP.

**Experiment four: varying PL fitting methods.** The HT-SR metric PL_Alpha_Hill is derived through PL fitting, which is influenced by the choice of hyperparameter \(_{}\). More specifically, this involves determining the adjustable parameter \(k\) as per Equation 3. Past research has employed various methods to select \(_{}\) based on the task, such as performance prediction. For instance, Martin et al. , Clauset et al.  choose \(_{}\) that aligns with the best fit according to the Kolmogorov-Smirnov statistic , a method termed Goodness-of-fit. Meanwhile, Yang et al.  adopted the Fix-finger approach, which identifies \(_{}\) at the peak of the ESD. In our study, we designate \(_{}\) as the median of all eigenvalues present in the ESD for TempBalance. As depicted in Figure 8, our fitting method, termed Median, not only ensures optimal test accuracy but also notably decreases computation time. This shows that this PL fitting method is suited for the design of learning rate schedulers that demand low computation overhead.

**Empirical analysis results.** We conduct an empirical analysis of TempBalance to discuss why it provides improvement. Our first analysis involves visualization to demonstrate how TempBalance

Figure 5: **(Tuning initial learning rate). Comparing the test accuracy of TempBalance (red) and CAL baseline (blue) for varying initial learning rate. Our method TempBalance outperforms CAL for both ResNet and VGG trained on CIFAR100. All results are obtained by running five random seeds.**

Figure 6: **(Different widths). Comparing TempBalance and the CAL baseline for different network widths. Our method TempBalance consistently outperforms the CAL baseline across various network widths for both ResNet and VGG trained on CIFAR100. All results are obtained by running five random seeds.**

Figure 7: **(Different HT-SR metrics). Comparing PL_Alpha_Hill with multiple HT-SR metrics. PL_Alpha_Hill achieves the best test accuracy among these metrics. All results are obtained by running five random seeds.**effectively regularizes ESDs by scheduling the learning rate (see Appendix B). The second analysis strengthens the connections between TempBalance and HT structure, illustrating that the observed improvements are not due to indirectly addressing other training issues, such as gradient excursions  (see Appendix F).

**Corroborating results on other tasks.** We extend our evaluation of TempBalance to two additional tasks: object detection and language modeling, the details of which can be found in Appendix G. Across these tasks, TempBalance consistently outperforms the baseline CAL in terms of generalization.

## 5 Conclusion

Our extensive empirical evaluations demonstrate that TempBalance offers a straightforward yet effective layer-wise learning rate schedule. Our approach for balancing layer-wise temperature confirms the following: (i) HT-SR-motivated metric PL_Alpha_Hill helps layers achieve temperature balance during training, exhibits strong correlations with model quality, and yields improved performance during testing; (ii) temperature balancing is a novel and essential aspect of NN training, and HT-SR Theory provides a strong theoretical support for balancing temperatures; and (iii) layer-wise learning rate schedules are cheap and effective to apply, and it is useful to study these layer-wise learning rate schedules further. Our method provides insights into the study of layer-wise tuning approaches and load-temperature balancing in deep NN training, as it serves both as a layer-wise learning rate schedule and an effective regularization technique based on HT-SR Theory.

**Future directions, limitations, and societal impacts.** Our paper leaves many future directions to explore, of which we mention just a few.

* Can HT-SR metrics be extended to parameter-wise learning rate schedules, global learning rate schedules, or other hyperparameters? It would be of interest to observe how HT-SR can assist in acquiring a comprehensive set of hyperparameter tuning tools.
* Is it possible to accelerate the computation of ESDs and PL_Alpha_Hill to achieve a more adaptive learning rate scheduler? Currently, we calculate layer-wise PL_Alpha_Hill once per epoch, resulting in a minimal increase in computational cost. Consider the example of training ResNet18 for 200 epochs on CIFAR100. Calculating layer-wise PL_Alpha_Hill takes 1.14 seconds for each epoch, leading to 3.8 minutes in total. Training CIFAR100 on 1 Quadro RTX 6000 takes 59 minutes, and thus using TB increases 6% of training time. However, if we can significantly decrease the expense of computing ESDs, it might enable an optimizer that adjusts the learning rate every few gradient updates. A study on computation overhead is detailed in Appendix H.

Our research centers around developing a generic algorithm for optimizing NNs. Although TempBalance could be applied to learning models with adverse applications, we do not see any immediate negative societal impacts stemming from the algorithm itself. Indeed, we see a lot of societal value in using a practical, predictive, and quantitative theory, such as HT-SR Theory, as opposed to developing a method that relies on a theory that provides vacuous upper bounds and then relies on extremely expensive hyperparameter tuning to obtain good results.

Figure 8: **(Varying PL fitting method to determine the \(_{}\)). Results of using different PL fitting methods. The blue bar plot and the left \(y\)-axis label denote the test accuracy (higher the better), and the red line plots and the right \(y\)-axis label denote the time in seconds of using TempBalance once (lower the better). Our design (Median) used in the proposed method achieves higher test accuracy and takes lower computation times compared to Goodness-of-fit and Fix-finger. The test accuracy is averaged over five random seeds and computation time is averaged over ten times.**

**Acknowledgements.** WeightWatcher is a publicly available tool distributed under Apache License 2.0 with a copyright held by Calculation Consulting. Our conclusions do not necessarily reflect the position or the policy of our sponsors, and no official endorsement should be inferred.