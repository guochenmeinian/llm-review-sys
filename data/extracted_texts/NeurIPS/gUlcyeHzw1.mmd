# Learning Provably Robust Estimators for Inverse Problems via Jittering

Anselm Krainovic

Technical University of Munich

anselm.krainovic@tum.de &Mahdi Soltanolkotabi

University of Southern California

soltanol@usc.edu &Reinhard Heckel

Technical University of Munich

reinhard.heckel@tum.de

###### Abstract

Deep neural networks provide excellent performance for inverse problems such as denoising. However, neural networks can be sensitive to adversarial or worst-case perturbations. This raises the question of whether such networks can be trained efficiently to be worst-case robust. In this paper, we investigate whether jittering, a simple regularization technique that adds isotropic Gaussian noise during training, is effective for learning worst-case robust estimators for inverse problems. While well studied for prediction in classification tasks, the effectiveness of jittering for inverse problems has not been systematically investigated. In this paper, we present a novel analytical characterization of the optimal \(_{2}\)-worst-case robust estimator for linear denoising and show that jittering yields optimal robust denoisers. Furthermore, we examine jittering empirically via training deep neural networks (U-nets) for natural image denoising, deconvolution, and accelerated magnetic resonance imaging (MRI). The results show that jittering significantly enhances the worst-case robustness, but can be suboptimal for inverse problems beyond denoising. Moreover, our results imply that training on real data which often contains slight noise is somewhat robustness enhancing.

## 1 Introduction

Deep neural networks achieve state-of-the-art performance for image reconstruction tasks including compressive sensing, super-resolution, and denoising. Due to their excellent performance, deep networks are now used in a variety of imaging technologies, for example in MRI and CT. However, concerns have been voiced that neural networks can be sensitive to worst-case or adversarial perturbations. Those concerns are fuelled by neural networks being sensitive to small, adversarially selected perturbations for prediction tasks such as image classification (Szegedy et al., 2014).

Recent empirical work for image reconstruction tasks (Huang et al., 2018; Antun et al., 2020; Genzel et al., 2022; Darestani et al., 2021) found that worst-case perturbations can have a significantly larger effect on the image quality than random perturbations. This sensitivity to worst-case perturbations is not unique to neural networks, classical imaging methods are similarly sensitive (Darestani et al., 2021).

This raises the question of whether networks can be designed or trained to be worst-case robust. A successful method proposed in the context of classification is adversarial training, which optimizes a robust or adversarial loss during training (Madry et al., 2018). However, the robust loss requires finding worst-case perturbations during training which is difficult and computationally expensive.

In this work, we study jittering, a simple regularization technique that adds noise during training as a robustness-enhancing technique for inverse problems. It is long known that adding noise during training has regularizing effect and can be beneficial for generalization (Bishop, 1995; Holmstrom and Koistinen, 1992; Reed and Marks II, 1999). Prior work also studied adding noise for enhancing adversarial robustness for classification (Zantedeschi et al., 2017; Kannan et al., 2018; Gilmer et al., 2019). However, jittering has not been systematically studied as a robustness enhancing technique for training robust networks for inverse problems.

We consider the following signal reconstruction problem. Let \(f^{m}^{n}\) be an estimator (a neural network in practice) for a signal (often an image) \(^{n}\) based on the measurement \(=+^{m}\), where \(\) is a measurement matrix and \(\) is random noise. We want to learn an estimator that has small robust risk defined as

\[R_{}(f)=_{(,)}[_{\| \|_{2}}\|f(+)- \|_{2}^{2}].\] (1)

The robust risk is the expected worst-case error with respect to a \(_{2}\)-perturbation of norm at most \(\) of \(f\) measured with the mean-squared error.

Theoretical results.We start with Gaussian denoising of a signal lying in a subspace, and first characterize the optimal linear robust denoiser, i.e., the estimator that minimizes the robust risk \(R_{}(f)\). While the resulting estimator is quite intuitive, proving optimality is fairly involved and relies on interesting applications of Jensen's inequality.

Second, we show that the optimal linear robust estimator minimizes the Jittering-risk

\[J_{_{w}}(f)=_{(,),}[\| f(+)-\|_{2}^{2}],\] (2)

where \((0,_{w}^{2})\) is Gaussian jittering noise with noise variance \(_{w}^{2}\) that depends on the desired robustness level \(\). This finding implies that instead of performing robust training via minimizing an empirical version of robust risk, we can train a denoiser via jittering, i.e., injecting Gaussian noise during training, at least for denoising a signal lying in a subspace. Figure 1, left panel, demonstrates the equivalence of training via minimizing a jittering risk and robust training numerically for the subspace model. It is evident that both methods of training yield an equally robust estimator.

Moreover, we discuss extensions of our theory for linear inverse problems \(=+\) and find that jittering can result in suboptimal worst-case robust estimators for some classes of forward operators.

Figure 1: **Jittering yields worst-case robust reconstruction methods.** The plots show the pixel-wise empirical robust risks \(_{}/n\) of models trained to minimize the robust risk \(R_{}\) and jittering risk \(J_{_{w}}\), respectively, with suitable choices of jittering levels \(_{w}()\). The optimal robust risk is approximated via adversarial training. The shaded areas are \(66\%\) confidence intervals. Left panel is for subspace denoising where jittering and robust training are provably equivalent, the panels from second left to right are for image reconstruction problems with the U-net, where jittering is particularly effective for denoising.

Empirical results for real-world denoising, deconvolution and compressive sensing.Jittering is also effective for learning robust neural network estimators for solving inverse problems in practice. Figure 1, second from left to right, depicts the worst-case risk achieved by training a U-net model for denoising, compressive sensing, and deconvolution, with standard training (blue), with jittering (purple), and with adversarial training (orange). For denoising, we see that jittering is as effective for obtaining a worst-case robust estimator as adversarial training, as suggested by theory. For compressive sensing and deconvolution, we find that jittering can be suboptimal beyond denoising, but is still effective for enhancing robustness.

Those findings make jittering a potentially attractive method for learning robust estimators in the context of inverse problems, since jittering can also be implemented easily and needs far less computational resources than adversarial training. Moreover, those findings imply that training on real data which often contains slight noise is somewhat robustness enhancing.

## 2 Related work

Empirical investigation of worst-case robustness for imaging.Several works investigated the sensitivity of neural networks for image reconstruction tasks to adversarial perturbations, for limited angle tomography (Huang et al., 2018), MRI and CT (Antun et al., 2020; Genzel et al., 2022; Darestani et al., 2021), and image-to-image tasks (colorization, deblurring, denoising, and super-resolution) (Choi et al., 2022; Yan et al., 2022; Choi et al., 2019). Collectively, those works show that neural networks for imaging problems are significantly more sensitive to adversarial perturbations than to random perturbations, as expected. The effect of adversarial \(_{2}\)-perturbations measured in mean-squared-error is roughly proportional to the energy of the perturbations in most of those problems, demonstrating that up to a constant (that might be large) neural networks can be relatively stable for imaging tasks. Classical reconstruction methods, in particular \(_{1}\)-regularized least-squares, are similarly sensitive to adversarial perturbations (Darestani et al., 2021).

Learning robust methods with robust optimization.To learn robust classifiers, Madry et al. (2018) proposed to minimize a robust loss and to find worst-case perturbations during training with projected gradient descent. Adversarial training can be effective for learning robust methods, but is computationally expensive due to the cost of finding adversarial perturbations. A variety of heuristics exist to lower the computational cost of robust training for neural networks. For example, Raj et al. (2020) consider compressive sensing and CT reconstruction problems and propose to generate adversarial perturbations for training with an auxiliary network instead of solving a maximization problem. As another example, Wong et al. (2020) considers adversarial training of classifiers and propose to calculate adversarial perturbations during training by first randomly perturbing the initial point and then applying a single step of projected gradient descent.

Jittering for enhancing robustness in inverse problems.The literature is somewhat split on whether jittering is effective for enhancing worst-case robustness for imaging. Genzel et al. (2022) suggested that jittering can enhance worst-case robustness of networks trained on compressive sensing and CT tasks. Contrary, Gandikota et al. (2022) consider the robustness to \(_{}\)-perturbations for neural-network based deblurring and observed that the DeepWiener architecture, trained via Jittering with noise levels sampled from a fixed interval, is sensitive to adversarial perturbations. In this work, we present the first systematic study on the effectiveness of jittering as a robustness-enhancing technique for inverse problems.

Robustness for inverse problems versus robustness for classification problems.Robustness in general and adding noise during training in particular, has been intensively studied in the classification setting. However, inverse problems and classification/prediction problems are very different. Adversarial robustness for classifiers is defined as the (average) minimal distance to the decision boundary, and random noise robustness as the minimal noise strength (for example the radius of Gaussian noise sphere) such that one likely crosses the decision boundary (Fawzi et al., 2018). For inverse problems, there is no notion of a decision boundary. Therefore, results and intuitions from classification, which are often based on geometric insights on distances to surfaces (see for example Fawzi et al. (2016) and Shafahi et al. (2019)) do not apply to inverse problems.

Jittering for enhancing robustness in classification.Prior work in classification considered Gaussian data augmentation or adding Gaussian noise during training (which is conceptually very similar to jittering) as an robustness-enhancing technique and found that adding noise enhances adversarial robustness, but reported mixed results on its effectiveness. Fawzi et al. (2018) proved for linear classifiers that adding Gaussian noise during training increases adversarial robustness, and Gilmer et al. (2019) demonstrated that empirically adding Gaussian noise during training also increases adversarial robustness for neural networks in the context of classification. Rusak et al. (2020) also found Gaussian noise addition beneficial for corruption robustness (including noise, compression and weather artifacts). Furthermore, Kannan et al. (2018) and Zantedeschi et al. (2017) considered adding Gaussian noise during training together with other regularization methods and report that adding noise at a fixed noise level alone yields a noticeable increase in robustness. Contrary, Carlini and Wagner (2017) reevaluated the methods proposed by Zantedeschi et al. (2017) and reported that the robustness gains are small compared to adversarial training.

Randomized smoothing.Randomized smoothing is a very successful technique for obtaining robust classifiers (Cohen et al., 2019; Carlini et al., 2023), and is based on constructing a smoothed classifier from a base classifier by averaging the base classifier's outputs under Gaussian noise perturbation. The smoothed classifier is provably robust within a specified radii, without making any restrictions on the base classifier. Despite similarities at first sight, randomized smoothing considers surrogate smoothed models, whereas jittering is a training technique (see the appendix on a detailed discussion).

## 3 Theory for robust reconstruction of a signal lying in a subspace

In this section, we characterize the optimal robust estimator for denoising a signal in a subspace. While the resulting estimator is quite intuitive, proving optimality is fairly involved and relies on interesting applications of Jensen's inequality. We then show that the optimal robust estimator is also the unique minimizer of the jittering loss. Finally, we conjecture a precise characterization of optimal estimators for linear inverse problems beyond denoising, and show that jittering can result in suboptimal estimators for linear inverse problems beyond denoising.

### Problem setup

We consider a signal reconstruction problem, where the goal is to estimate a signal \(\) based on a noisy measurement \(=+\), where \((0,_{z}^{2}1/m)\) is Gaussian noise and \(^{m n}\) a measurement or forward operator. The random noise is scaled so that the expected noise energy is \([\|\|_{2}^{2}]=_{z}^{2}\). The random noise is denoted by \(\), to distinguish it from the adversarial noise or worst-case error, denoted by \(\). We assume that the signal is (approximately) chosen uniformly from the intersection of a sphere and a subspace. Specifically, the signal is generated as \(=\), where \((0,_{c}^{2}1/d)\) is Gaussian and \(^{n d}\) is an orthonormal basis for a \(d\)-dimensional subspace of \(^{n}\). The expected signal energy is \([\|\|_{2}^{2}]=_{c}^{2}\).

We consider a linear estimator of the form \(f()=\) for estimating the signal from the measurement. For the standard reconstruction problem of estimating the signal \(\) from the measurement \(\), performance is often measured in terms of the expected least-squared error. We are interested in robust reconstruction and consider the expected worst-case reconstruction error with respect to an \(_{2}\)-perturbation, defined in equation (1), and given by

\[R_{}(f)=_{(,)}[_{\| \|_{2}}\|(+)- \|_{2}^{2}].\]

For \(=0\), the robust risk reduces to the standard expected mean-squared error.

### Denoising

We start with denoising where the forward map is the identity, i.e., \(=\). The following theorem characterizes the optimal worst-case robust denoiser.

**Theorem 3.1**.: _For \(d\), the optimal worst-case estimator, i.e., the estimator minimizing the worst-case risk \(R_{}(f)\) amongst all estimators of the form \(f()=\), is \(=^{T}\), where_

\[=^{2}-_{z} }}{^{2}+_{z}^{2}-^{2 }}}}{_{c}^{2}+_{z}^{2}}&_{c}^{2}> ^{2}\\ 0&\]

The worst-case optimal estimator projects onto the signal subspace, and then shrinks towards zero, by a factor determined by the noise variance \(_{z}^{2}\) and the worst-case noise energy \(^{2}\). We consider the asymptotic setup where \(d\) only for expositional convenience; our proof shows that the estimator in the theorem is also near optimal for finite \(d\).

To understand the implications of the theorem, let us first consider the case where the worst-case perturbation is zero. Then, the optimal estimator simply projects on the signal-subspace and shrinks towards zero, by a factor of \(=^{2}}{_{c}^{2}+_{z}^{2}}\). The larger the noise, the more shrinkage.

Next, consider the most interesting regime, where non-zero adversarial noise is present. If the adversarial noise energy is larger than the signal energy, the estimator projects onto zero. However, this is an extreme regime since the adversarial noise can cancel the signal, and no good estimate of the signal can be achieved.

For the more practical regime where the adversarial noise energy is smaller than the signal energy, the theorem states that the optimal estimator projects onto the signal-subspace and shrinks towards zero--just like the optimal estimator for the noise-free case--but this time by a factor \(\), that decreases in the adversarial noise energy \(^{2}\).

The proof of Theorem 3.1 is in the appendix. Note that for estimators \(=^{T}\), a worst-case perturbation can be computed in closed form for a fixed \(\) and \(\): a worst-case perturbation is the vector that points into the direction of the signal plus noise lying in the signal subspace, i.e., \(=+^{T} }{\|(1-)+^{T}\| _{2}}\). However, for a general estimator \(\), the perturbation can not be written in closed form, which makes proving optimality quite challenging. Our proof relies on a characterization of the inner maximization problem as the solution to an optimization problem in one variable, and several unusual applications of Jensen's inequality.

#### 3.2.1 Robust denoisers via jittering

An important consequence of the characterization of the worst-case optimal estimator in Theorem 3.1 is that, at least for the linear setup considered in this section, a worst-case optimal estimator can be obtained by regularization with jittering.

Figure 2: **Robust reconstruction of signals lying in a subspace. The left panel shows the scaling factor \(\) of the optimal robust denoiser according to Theorem 3.1 at noise levels \(_{z}\{0,0.4,1.2\}\) and signal energy \(_{c}^{2}=1\). The right panel depicts the robust risks of standard training and jittering as well as the optimal robust risk for an inverse problem beyond denoising, with the details stated in subsection 3.3.**Recall from the introduction that regularization via jittering simply adds Gaussian noise \((0,_{w}^{2})\) to the measurement during training. The jittering risk (2) of the estimator \(f()=\) for denoising is \(J_{_{w}}(f)=_{(,),}[\| f(+)-\|_{2}^{2}]\). Choosing the variance of the jittering noise level accordingly as a function of the desired robustness level \(\) yields an optimal worst-case robust estimator by minimizing the jittering loss, as formalized by the following corollary of Theorem 3.1.

**Corollary 3.2**.: _For \(^{2}<_{c}^{2}\), the linear estimator \(f()=\) that minimizes the jittering risk \(J_{_{w}}\) with noise level chosen as a function of the desired noise level \(\) as \(_{w}()=_{}^{2}+_{z}}_{c}^{2}- ^{2}+_{}^{2}}}{d(_{c}^{2}-^{2})}}\) also minimizes the worst-case risk \(R_{}\)._

Hence, if we aim for a robustness level \(<_{c}\), we can simply apply training via Jittering instead of adversarial training by choosing the Jittering noise level using the explicit formula for the jittering noise level \(_{w}()\) in corollary 3.2.

Figure 1, left panel, shows the results of numerical simulation for adversarial training and jittering. In the implementation we treat the linear reconstructions as neural networks with a single layer without bias and perform adversarial training and jittering for each perturbation level. The simulations show that the robust risk performance of the models are identical, as predicted by the theory. Details on how adversarial training is performed are in Section 4.

#### 3.2.2 Robustness accuracy trade-off

Another consequence of Theorem 3.1 is an explicit robustness-accuracy trade-off: increased worst-case robustness comes at a loss of accuracy. In the practically relevant regime of \(0^{2}<_{c}^{2}\) the standard risk of the optimal worst-case estimator \(f_{()}\) is \(R_{0}(f_{()})=_{c}^{2}^{2}}{_{c}^{2}+_{}^{2}-^{2}}\). This expression yields the optimal standard error for \(=0\) and is strictly monotonically increasing in \(\), hence showing the loss of accuracy when increasing robustness. Robustness-accuracy tradeoffs can also be observed in other machine learning settings, for classification and regression settings, see for example (Tsipras et al., 2019). For linear inverse problems with applications in control, robustness accuracy-tradeoffs were recently characterized by Lee et al. (2021) and Javanmard et al. (2020).

### General linear inverse problems

In the previous section, we characterized the optimal worst-case robust estimator and found that jittering yields optimal robust denoisers. In this section, we derive a conjecture for the worst-case optimal robust estimator for more general linear inverse problems of reconstructing a signal \(\) from a measurement \(=+\), with a forward operator \(\) (with \(\) in general), and show that this estimator is in general not equal to the estimator obtained with jittering, thus jittering is in general suboptimal.

Optimal robust estimator.Let \(=^{T}\) be the singular value decomposition of the matrix \(\) with singular values \(_{i}\). As formalized by Lemma A.1 of the appendix, the robust-risk (1) of the estimator \(f\) can be written as an expectation involving a minimization problem over a single variable (instead of a maximization over an \(n\)-dimensional variable, as in the original definition):

\[R_{}()=_{}[_{ _{}^{2}}^{2}+^{T}(- {}^{T})^{-1}],=( -)+.\] (3)

Here, \(_{}\) is the largest singular value of the matrix \(\). In order to find the optimal robust estimator we wish to solve the optimization problem \(_{}R_{}()\). The difficulty in solving this optimization problem is that we can't solve the minimization problem within the expectation (3) in closed form. In order to prove Theorem 3.1 for denoising (i.e., for \(=\)) we derived an upper and a matching lower bound of the risks using several unusual applications of Jensen's inequality. The proof does not generalize in a straightforward manner to the more general case where \(\). However, for large \(d\), the random variable \(^{T}(-^{T})^{-1} \) concentrates around it's expectation, and thus we conjecture that for large \(d\), we can exchange expectation and minimization, which yields:

\[R_{}()=_{_{}^{2}} ^{2}+_{}[^{T}(-^{T})^{-1}].\] (4)The expectation in the risk expression (4) can be explicitly computed, which yields the following conjecture for the worst-case optimal estimator:

**Conjecture 3.3**.: For \(d\) the optimal worst-case estimator, i.e., the estimator minimizing the worst-case risk \(R_{}(f)\) amongst all estimators of the form \(f()=\), is \(=(_{i})^{T}\) with

\[_{i}=^{2}}{2_{i}}+}^{2}}{_{c}^{2}}-^{2}}{2_{i}}+ }^{2}}{_{c}^{2}})^{2}-},\]

if \(_{i} 0\) and \(_{i}=0\) otherwise. Here, the parameter \(\) is a solution of:

\[*{argmin}_{ 0}^{2}+_{i=1}^{d} ^{2}}{2}^{2}}{d}- ^{2}}{m}+^{2}}{2}^{2}}{d}+^{2}}{m})^{2}- _{i}^{2}^{4}}{d^{2}}}.\]

The optimization problem involved is convex and box-constrained and can thus be solved numerically. Besides the argument above, we confirmed our conjecture with numerical simulations.

Optimal jittering estimator.Unlike for denoising, for general inverse problems, the jittering-risk minimizing estimator is in general not equal to the optimal worst-case estimator, but the two estimators are often close. The optimal estimator minimizing the jittering risk is given as (see Appendix C):

\[_{J}(_{w})=(^{2}_{i}}{_{c}^{2}_{i}^{2}+_{z}^{2}+ _{w}^{2}d})^{T},\] (5)

where as before \(=^{T}\) is the singular value decomposition with singular values \(_{i}\). While the estimator (5) has the same form as the worst-case optimal estimator in Conjecture 3.3, the diagonal matrix in the two estimators is in general slightly different.

Numerical Simulation.The worst-case suboptimality of the jittering-risk optimal estimator (5) depends on the singular values of the matrix \(\); if they are equal the jittering-risk estimator is optimal, and if they are not equal there is typically a small gap. To illustrate the gap, we consider a forward operator \(\) with linearly decaying singular values \(\), for \(1 i n\) with signal energy \(_{c}^{2}=1\) and noise level \(_{z}=0.2\). We compare the (conjectured) optimal robust estimator specified by Conjecture 3.3 with the optimal Jittering estimator (5) at noise level \(_{w}\), where \(_{w}\) is optimized such that one obtains minimal robust risk \(R_{}\) at a given perturbation level \(\). The results in Figure 2, right panel, show a small gap in robust risk, which implies that Jittering is suboptimal for this case. However, simulations with varying forward operators and noise levels indicate that the gap is small relative to the robust risk of the standard estimator. Experiments on image deconvolution using U-Net presented in Section 4 show similar results.

## 4 Experiments

In this section, we train standard convolutional neural-networks with standard training, adversarial training, and jittering for three inverse problems: denoising images, image deconvolution, and compressive sensing, and study their robustness. We find that Jittering yields well-performing robust denoisers at a computational cost similar to standard training, which is significantly cheaper than adversarial training. We also find that jittering yields robust estimators for deconvolution and compressive sensing. This indicates that training on real data which often contains slight measurement noise is robustness enhancing.

### Problem setup

We start by describing the datasets, networks, and methodology.

Natural images.We consider denoising and deconvolution of natural images, where our goal is to reconstruct an image \(^{n}\) from a noisy measurement \(=+\), where \((0,_{z}^{2}1/n)\) is Gaussian noise and \(\) a measurement matrix, which is equal to identity for denoising, and implementsa convolution for deconvolution. For deconvolution we use a \(8 8\)-sized discretization of the \(2\)-dimensional Gaussian normal distribution with standard deviation \(2\). The kernel is visualized in Figure 3 in the appendix. We obtain train and validation datasets \(\{(_{1},_{1}),,(_{N},_{N})\}\) of sizes \(34\)k and \(4\)k, respectively, from colorized images of size \(n=128 128 3\) generated by randomly cropping and flipping ImageNet images. The methods are tested on \(2\)k original-sized images.

Medical data.We also perform experiments on accelerated singlecoil magnetic resonance imaging (MRI) data, where the goal is to reconstruct an image \(^{n}\) from a noisy and subsampled measurement in the frequency domain \(=+^{2m}\). We use the fastMRI singlecoil knee dataset (Zbontar et al., 2018), which contains the images \(\) and fully sampled measurements (\(=\)). We process it by random subsampling at acceleration factor \(4\) and obtain train, validation and test datasets with approximately \(31\)k, \(3.5\)k and \(7\)k slices, respectively. While perturbations are sought in frequency domain, the inverse Fourier transform is applied to the measurements before feeding the \(320 320\) cropped and normalized images into the network.

Network architecture.We use the U-net architecture (Ronneberger et al., 2015) since it gives excellent performance for denoising (Brooks et al., 2019) and medical image reconstruction tasks, such as computed tomography (Jin et al., 2017) and is used as a building block for state-of-the-art methods for magnetic resonance imaging (Zbontar et al., 2018; Sriram et al., 2020). For natural images, we use a U-net with \(3 3\) padded convolutions with ReLU activation functions, \(2 2\) max-pooling layers for downscaling and transposed convolutions for upscaling. The network has \(120\)k parameters. For MRI reconstruction we use a U-Net architecture similar to Zbontar et al. (2018) with \(3 3\) padded convolutions, leaky ReLU activation function, \(2 2\) average pooling and transposed convolutions (\(480\)k learnable parameters). We denote the U-Net by the parameterized mapping \(f_{}^{m}^{n}\) in the following.

Evaluation.We evaluate networks by measuring its robustness via the empirical robust risk defined as \(_{}()=_{i=1}^{N}_{ _{i}_{2}} f_{}( _{i}+_{i})-_{i}_{2}^{2}\), For evaluation, the robust empirical risk is computed over the test set. We assess the accuracy by computing the standard empirical risk \(_{0}()\). Computing the robust empirical risk is non-trivial since it requires finding adversarial perturbations for solving the inner maximization problem. This is explained next. We also study the computational cost of the different methods, which we measure in terms of GPU cost and time.

Finding adversarial perturbations.To evaluate the empirical risk and for robust training, we need to compute adversarial perturbations \(=_{_{2}}  f_{}(+)-_{2}^{2}\). We find the perturbations by running \(N_{a}\) projected gradient ascent steps, starting with initial perturbation \(^{0}=0\) and iterate

\[^{j+1}=_{B(0,)}(^{j}+2.5}^{j}}{^{j} _{2}}),^{j}=_{ ^{j}} f_{}(^{j}+)- _{2}^{2}.\]

Here, \(_{B(0,)}\) is the projection into the \(_{2}\)-ball \(B(0;)\) of radius \(\) around the origin. The gradient is normalized to facilitate step size optimization with multiplier \(2.5\) such that the iteration can reach and move along the boundary, as suggested by Madry et al. (2018).

Training methods.Standard training minimizes the standard empirical risk \(_{0}\). Adversarial training minimizes the empirical robust risk \(_{}\). To minimize the empirical robust risk, we approximate the inner maximization, \(_{_{2}} f_{ }(_{i}+)-_{i}_{2}^{2}\), with \( f_{}(}_{i})-_{i}_{2} ^{2}\), where \(}_{i}\) is the adversarially perturbed measurement computed as described above. Training via jittering minimizes

\[_{_{w}}()=_{i=1}^{N}_{ (0,_{w}^{2})}[ f_{}(_{i}+)-_{i}_{2}^{2}],\]

where the jittering level \(_{w}\) is chosen depending on the desired robustness level. We treat the jittering noise level as a hyperparameter optimized using the validation dataset (shown in the appendix). Jittering is practically implemented via performing the SGD update rule \(_{i+1}=_{i}-_{i=1}^{M}_{}\|f_{}(_{i}+_{i})-_{i}\|^{2}\), with \(M\) samples per batch and learning rate \(\). For jittering, the network output is calculated on the noisy input \(_{i}+_{i}\), instead of \(_{i}\) (standard training) or \(_{i}+_{i}\) (adversarial training). To approximate the expectation in the jittering risk we draw independent jittering noise samples \(_{i}\) in each iteration of SGD.

Throughout, we use PyTorch's Adam optimizer with learning rate \(10^{-3}\) and batch size \(50\) for natural images, and \(10^{-2}\) and \(1\) for MRI data. As perturbation levels, we consider values within the practically interesting regime of \(^{2}/[\|\|_{2}^{2} ]<0.3\) for natural images and \(0.03\) for MRI data. Note that for \(^{2}>[\|\|_{2}^{2}]\), Theorem 3.1 predicts for denoising (\(=\)) that the optimal robust estimator is zero everywhere. Figure 7 in the appendix shows that for large perturbations \(\) the trained U-net denoiser also maps to zero.

### Results

We now discuss the results of the denoising, deconvolution, and compressive sensing experiments.

Robust and standard performance.Figure 1, shows that the standard estimator is relatively robust for Gaussian denoising and increasingly sensitive for more ill-posed problems (deconvolution and compressive sensing). The experiments further show that jittering is effective for enhancing robustness, in particular relative to the sensitivity of the standard estimator. Nevertheless, as suggested by theory, we see a gap between the robust risk of adversarial training and jittering for image deconvolution and compressive sensing. For Gaussian denoising, however, Jittering is particularly effective and yields increasingly better performing networks in terms of standard risks for larger perturbations.

Choice of the jittering level.The results are based on choosing the jittering noise levels via hyperparameter search for each task. Figure 3 shows the results for Gaussian denoising: It can be seen that the choice of noise level is important for minimizing the robust risk. The estimated noise levels also aligns well the theoretical prediction. Details on this and the parameter choices for deconvolution and the compressive sensing experiments are in the appendix.

Computational complexity.We measured the GPU time until convergence and memory utilization of the methods and present the results in the Table 1 of the appendix. Performing adversarial training is by a factor of the projected gradient ascent steps more expensive than standard training. Moreover, training via jittering has similar computational cost as standard training, since it solely consists of drawing and adding Gaussian noise on the training data.

Figure 3: **Estimating the optimal jittering noise levels for the denoising task.** The left panel shows the results of training networks via Jittering, at noise levels \(_{w}\), and calculating the empirical robust risk \(_{}\) of each model. Each green line corresponds to robust risks at one perturbation level. The optimal jittering noise levels are shown in the middle panel and follow well the prediction from theory (Cor. 3.2, details in appendix). The jittering estimators are similarly robust as adversarial training (Figure 1), but attain lower standard risks (right panel).

Visual reconstructions.For the linear subspace setting adversarial training and jittering are equivalent. For Gaussian denoising with a neural network, however, they perform differently. For larger perturbations jittering tends to yield smoother images than networks trained adversarially, as can be seen in the example reconstructions shown in Figure 4. This effect is particularly noticeable for the Gaussian deconvolution task. We quantified the effect using the total variation norm and present the results in the appendix. Moreover, we discuss an approximation to jittering, Jacobian regularization, which similarly enhances robustness. It is computationally more expensive, but yields less smooth reconstructions.

## 5 Conclusion

In this paper, we characterized the optimal worst-case robust estimator for Gaussian subspace denoising and found that the optimal estimator can be provably learned with jittering. Our results for training neural networks for Gaussian denoising of images show that jittering enables the training of neural networks that are as robust as neural networks trained adversarially, but at a fraction of the computational cost, and without the hassle of having to find adversarial perturbations. While we demonstrated that jittering can yield suboptimal robust estimators in general, in practice, jittering is effective at improving the robustness for compressive sensing and image deconvolution. Moreover, our results imply that training on real data that contains slight measurement noise is robustness enhancing.

ReproducabilityThe repository at https://github.com/MLI-lab/robust_reconstructors_via_jittering contains the code to reproduce all results in the main body of this paper.

AcknowledgmentsA.K. and R.H. are supported by the Institute of Advanced Studies at the Technical University of Munich, the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - 456465471, 464123524, the DAAD, and the German Federal Ministry of Education and Research, and the Bavarian State Ministry for Science and the Arts. M.S. is supported by the Packard Fellowship in Science and Engineering, a Sloan Research Fellowship in Mathematics, an NSF-CAREER under award #1846369, DARPA FastNICS programs, and NSF-CIF awards #1813877 and #2008443.

Figure 4: Example reconstructions using measurements (second column) and separately calculated perturbed measurements. The reconstructions are denoted as clean and perturbed, respectively. The perturbation levels are \(^{2}/[\|\|_{2}^{2}]=0.03\) for denoising, \(0.003\) for compressive sensing and \(0.001\) for deconvolution. We can see that the standard estimator is visibly sensitive to perturbations. Jittering yields robust estimators, but at the same time yields smoother reconstructions.