# Symmetric Linear Bandits with Hidden Symmetry

Nam Phuong Tran

Department of Computer Science

University of Warwick

Coventry, United Kingdom

nam.p.tran@warwick.ac.uk &The Anh Ta

CSIRO's Data61

Marsfield, NSW, Australia

theanh.ta@csiro.au &Debmalya Mandal

Department of Computer Science

University of Warwick

Coventry, United Kingdom

debmalya.mandal@warwick.ac.uk &Long Tran-Thanh

Department of Computer Science

University of Warwick

Coventry, United Kingdom

long.tran-thanh@warwick.ac.uk

###### Abstract

High-dimensional linear bandits with low-dimensional structure have received considerable attention in recent studies due to their practical significance. The most common structure in the literature is sparsity. However, it may not be available in practice. Symmetry, where the reward is invariant under certain groups of transformations on the set of arms, is another important inductive bias in the high-dimensional case that covers many standard structures, including sparsity. In this work, we study high-dimensional symmetric linear bandits where the symmetry is hidden from the learner, and the correct symmetry needs to be learned in an online setting. We examine the structure of a collection of hidden symmetry and provide a method based on model selection within the collection of low-dimensional subspaces. Our algorithm achieves a regret bound of \(O(d_{0}^{2/3}T^{2/3}(d))\), where \(d\) is the ambient dimension which is potentially very large, and \(d_{0}\) is the dimension of the true low-dimensional subspace such that \(d_{0} d\). With an extra assumption on well-separated models, we can further improve the regret to \(O(d_{0})\).

## 1 Introduction

Stochastic bandit is a sequential decision-making problem in which a player, who aims to maximize her reward, selects an action at each step and receives a stochastic reward, drawn from an initially unknown distribution of the selected arm, in response. Linear stochastic bandit (LSB)  is an important variant in which the expected value of the reward is a linear function of the action. It is one of the most studied bandit variants and has many practical applications .

Actions in LSB are specified as feature vectors in \(^{d}\) for very large feature dimension \(d\), with performance i.e. the resulting regret scaling with \(d\). Many works have addressed this curse of dimensionality by leveraging different low-dimensional structures as inductive biases for the learner. For example, sparsity, which assumes that the reward is a sparse linear function, has been used extensively in LSB to design bandit algorithms with better performance . However, when the reward function lacks the structure for sparsity (which may occur in many real-world situations), a question arises: Are there different structures in the features of LSB that we can exploit to overcome the curse of dimensionality and design bandit algorithms with better performance?

In this paper, we study the inductive bias induced by symmetry structures in LSB, which is a more general model inductive bias than sparsity, and can facilitate efficient and effective learning . Symmetry describes how, under certain transformations of the input of the problem, the outcomeshould either remain unchanged (_invariance_) or shift predictably (_equivariance_). In supervised learning, it has been empirically observed  and theoretically proven  that explicitly integrating symmetry into models leads to improved generalization error. However, in the literature on sequential decision-making, unlike sparsity, symmetry is rarely considered to date. This leads us to the following research question: Can one leverage _symmetry in sequential decision-making_ tasks to enable effective exploration, and eventually break the curse of dimensionality?

In the machine learning literature, especially in supervised learning, most studies on symmetry assume prior knowledge of symmetry structures of the tasks under consideration . However, in numerous practical scenarios, the learner can only access to partial knowledge of the symmetry, necessitating the incorporation of symmetry learning mechanisms into the algorithms to achieve better performance. Examples of hidden symmetry can be found in multi-agent learning with cooperative behavior. As a motivating example, consider a company undertaking a large project that consists of several subtasks. The company must hire subcontractors with the goal of maximizing project quality while staying within budget constraints. Symmetry may arise in this situation when coalitions form among subcontractors, where members of a coalition work together to complete their allocated tasks using shared resources. In particular, the allocation of tasks within a coalition can be swapped without affecting overall team performance, inducing symmetry (i.e., performance remains invariant under permutation) in the task assignments. Coalitions among subcontractors often arise since sharing labor and resources reduces operational costs, making their work more efficient and cost-effective. However, these coalitions are typically _hidden_ from the hiring company. One reason is that if the hiring company were aware of these collaborations, they could use this information to negotiate lower prices, knowing that the subcontractors are benefiting from shared resources. Another reason is that coalitions may raise concerns about collusion. In particular, in a competitive market, such as when subcontractors are hired through a bidding platform, coalition members can collaborate to manipulate the bidding process, which is considered unfair and could undermine the integrity of the bidding. For more practical examples of hidden symmetry in multi-agent reinforcement learning  and robotics , we refer the reader to Appendix D.2. Motivated by these examples, we believe that hidden symmetry is much more relevant in the context of sequential decision-making because the environment and its symmetry structure may not be readily available to the learner, as opposed to supervised learning and offline settings where data are provided during the training phase. As the learner has the power to freely collect data, it is expected that they will learn the hidden symmetry structures as they explore the environment.

Against this background, we ask the question of whether learner can leverage symmetry to enable effective exploration, and break the curse of dimensionality _without a prior knowledge_ of the symmetry structure? Moreover, in the presence of symmetry, when can we design learning algorithms with optimal regret bounds? Towards answering this question, we investigate the setting of symmetric linear stochastic bandit in \(^{d}\), where \(d\) is potentially very large, and the expected reward function is invariant with respect to the actions of a _hidden_ group \(\) of coordinate permutations. Our contributions are summarised as follows:

1. We first give an impossibility result that _no algorithm can get any benefit by solely knowing that \(\) is a subgroup of permutation matrices_. We achieve this by formally establishing a relation between the class of subgroup to the partition over the set \(\{1,...,d\}\). A direct implication of this impossibility result is that it is necessary to have further information about the structure of the hidden subgroup in order to achieve improved regret bounds.
2. Given this, we establish a cardinality condition on the class of symmetric linear bandits with hidden \(\), in which the learner can learn the true symmetry structure and overcome the curse of dimensionality. Notably, this class includes a sparsity as a special case, and therefore inherits all the computational and statistical complexities of sparsity. Apart from sparsity, this class includes many other practically relevant classes, such as partitions that respect underlying hierarchies, non-crossing partitions, and non-nesting partitions (see Subsection 4.2.1 and Appendix D.2).
3. We cast our problem of learning with hidden subgroup \(\) into model selection with collection of low-dimensional subspaces . To address the polynomial scaling of regret bounds with respect to the number of models and arms in previous works, we depart from model aggregation, which is typically used in LSB model selection, and introduce a new framework inspired by Gaussian model selection 1 and compressed sensing . Based on this framework, we introduce a new algorithm, called EMC (for Explore Models then Commit). Under the assumption that the set of arm is exploratory, we prove that the regret bound of the EMC algorithm is \(O(d_{0}^{2/3}T^{2/3}(d))\), and \(O(d_{0}(d))\) with an additional assumption on well-separated partitions, where \(d_{0} d\) is the dimension of the low-dimensional subspace associated with group \(\).

To the best of our knowledge, our work is the first in the linear stochastic bandits literature that leverages symmetry in designing provably efficient algorithms. To save space, all proofs in this paper are deferred to the Appendix.

### Related Work

We now briefly outline related work and compare them with our results. We refer the reader to Appendix F for a more in-depth literature review.

**Sparse linear bandits.** As we will explain in Section 4.2, sparsity is equivalent to a subset symmetry structures, and thus, can be seen as a special case of our setting. As such, we first review the literature of sparsity. Sparse linear bandits were first investigated in , where the authors achieve a regret of \(()\), with \(\) disregarding the logarithmic factor, and \(s\) representing the sparsity level, and \(T\) is the time horizon. This matches the regret lower bound for sparse bandits, which is \(()\). More recently, the contextual version of linear bandits has gained popularity, where additional assumptions are made regarding the context distribution and set of arms  to avoid polynomial dependence on \(d\). Notably, with the assumption on exploratory set of arms,  propose an Explore then Commit style strategy that achieves \((s^{}T^{})\), nearly matching the regret lower bound \((s^{}T^{})\) in the data-poor regime. As sparsity is equivalent to a subclass of hidden symmetry, all the lower bounds for sparse problems apply to our setting of learning with hidden symmetry.

**Model selection.** Our problem is also closely related to the problem of model selection in linear bandits, as the learner can collect potential candidates for the hidden symmetry model. Particularly, in model selection, there is a collection of \(M\) features, and different linear bandits running with each of these features serve as base algorithms. By exploiting the fact that the data can be shared across all the base algorithms, the dependence of regret in terms of the number of features can be reduced to \((M)\). In particular,  propose a method that concatenates all \(M\) features of dimension \(d\) into one feature of dimension \(Md\), and uses the Lasso estimation as a aggregation of models. Their algorithm achieves a regret bound of \(O(T^{})\) under the assumption that the Euclidean norm of the concatenated feature is bounded by a constant. However, in our case, the Euclidean norm of the concatenated feature vector can be as large as \(\), which leads to a \(\) multiplicative factor in the regret bound. Besides,  uses the online aggregation oracle approach, and is able to obtain regret of \(O()\), where \(K\) is the number of arms. In contrast, _we use algorithmic mechanisms that are different from aggregation of models_. In particular, we explicitly exploit the structure of the model class as a collection of subspaces and invoke results from Gaussian model selection  and dimension reduction on the union of subspaces . With this technique, we are able to achieve \(O(T^{}(M))\), which is rate-optimal in the data-poor regime, has logarithmic dependence on \(M\) without strong assumptions on the norm of concatenated features, and is independent of the number of arms \(K\). We refer the reader to Section 4.2 for a more detailed explanation.

**Symmetry in online learning.** The notion of symmetry in Markov decision process dates back to works such as . Generally, the reward function and probability transition are preserved under an action of a group on the state-action space. Exploiting known symmetry has been shown to help achieve better performance empirically  or tighter regret bounds theoretically . However, all these works requires knowledge of symmetry group, while our setting consider hidden symmetry group which may be considerably harder. Hidden symmetry on the context or state space has been studied by few authors, with the term context-lumpable bandits , meaning that the set of contexts can be partitioned into classes of similar contexts. It is important to note that the symmetry group acts differently on the context space and the action space. As we shall explain in detail in Section 3, while one can achieve a reduction in terms of regret in the case of hidden symmetry acting on context spaces , this is not the case when the symmetry group acts on the action space. The work closest to ours is , where the authors consider the setting of a \(K\)-armed bandit, where the set of arms can be partitioned into groups with similar mean rewards, such that each group has at least \(q>2\) arms. With the constrained partition, the instance-dependent regret bounds are shown asymptotically to be of order \(O( T)\). Comparing to , we study the setting of stochastic linear bandits with similar arms, in which the (hidden) symmetry and linearity structure may intertwine, making the problem more sophisticated. We also impose different constraints on the way one partitions the set of arms, which is more natural in the setting of linear bandits with infinite arms.

## 2 Problem Setting

For any \(k^{+}\), denote \([k]=\{1,,k\}\). For \(^{d}\), let \(()\) denote the set of all probability measures supported on \(\). Given a set \(S^{k}\), for some \(k>1\), denote \(_{S}(x)\) as the Euclidean projection of \(x^{k}\) on \(S\), and \((S)\) as the convex hull of \(S\).

We denote by \(T\) the number of rounds, which is assumed to be known in advance. Each round \(t[T]\), the agent chooses an arm \(x_{t}^{d}\), and nature returns a stochastic reward \(y_{t}= x_{t},_{}+_{t},\) where \(_{t}\) is an i.i.d. \(\)-Gaussian random variable. Now, denote \(f(x_{t})=[y_{t} x_{t}]\). A bandit strategy is a decision rule for choosing an arm \(x_{t}\) in round \(t[T]\), given past observations up to round \(t-1\). Formally, a bandit strategy is a mapping \(:()^{T}()\).

Let \(x_{}=_{x}f(x)\), and let \(_{T}=[_{t=1}^{T} x_{}-x_{t}, _{}]\) denote the expected cumulative regret. In this paper, we investigate the question whether one can get any reduction in term of regret, if the reward function is invariant under the action of a hidden group of transformations on the set of arms. We define the notion of group of symmetry as follows:

Group and group action.Given \(d^{+}\), let \(_{d}\) denote the symmetry group of \([d]\), that is, \(_{d}:=\{h:[d][d] h\}\) the collection of all bijective mappings from \([d]\) to itself. We also define the group action \(\) of \(_{d}\) on the vector space \(^{d}\) as

\[:_{d}^{d}& ^{d}\\ &(g,(x_{i})_{i[d]})&(x_{g(i)})_{i [d]}\] (1)

In other words, a group element \(g\) acts on an arm \(x^{d}\) by permuting the coordinates of \(x\). In the setting of linear bandit, the permutation group action also acts on the set of parameters via coordinate permutation. For brevity, we simply denote \(g\) and \(g x\) as \((g,)\) and \((g,x)\), respectively. Denote by \(A_{g}\) the permutation matrix corresponding to \(g\). We write \(_{d}\) to denote that \(\) is a subgroup of \(_{d}\). Given any point \(^{d}\), we write \(=\{g g\}\) to denote the orbit of \(\) under \(\). It is well known that the orbit induced by the induced action of a subgroup \(_{d}\) corresponds to a set partition of \([d]\). We denote this partition as \(_{}\).

Let \(\) be a subgroup of \(_{d}\) that acts on \(^{d}\) via the action \(\). In a symmetric linear bandit, the expected reward is invariant under the group action of \(\) on \(\), that is, \(f(g x)=f(x)\). Due to the linear structure of \(f\), this is equivalent to \(g_{}=_{}\) for all \(g\). We assume that, _while the group action \(\) is known to the learner, the specific subgroup \(\) is hidden and must be learned in an online manner_.

## 3 Impossibility Result of Learning with General Hidden Subgroups

We now show how to frame the learning problem with hidden symmetry group as the problem of model selection. We further analyse the structure of the collection of models, and show that no algorithm can benefit by solely knowing that \(_{d}\), which implies that further assumptions are required to achieve significant improvement in term of regret.

### Fixed Point Subspace and Partition

The analysis of learning with hidden subgroup requires a group-theoretic notion which is referred to as fixed-point subspaces . As we shall explain promptly, there is a tight connection between the collection of fixed-point subspaces and set partitions.

Fixed-point subspaces.For a subset \(^{d}\), denote \(_{}():=\{x g x=x, \  g\}\) as the fixed-point subspace of \(\); and \(_{_{d}}():=\{_{ }()_{d}\}\) as the collection of all fixed-point subspaces of all subgroups of \(_{d}\). We simply write \(_{_{d}}=_{_{d}}(^{d})\) and \(_{}=_{}( ^{d})\) for brevity.

Set partition.Given \(d^{+}\), we denote \(_{d}\) as the set of all partitions of \([d]\). Let \(_{d,k}\) as the set of all partitions of \([d]\) with exactly \(k\) classes, and \(_{d, k}\) be the set of all partitions of \([d]\) with at most \(k\) classes. The number of set partitions with \(k\) classes \(|_{d,k}|\) is known as the Stirling number of the second kind, and \(|_{d}|\) is known as Bell number.

### Impossibility Result

Problem with known symmetry.Before discussing the problem of hidden symmetry, let us explain why the learner with an exact knowledge of \(\) can trivially achieve smaller regret. The reason is that \(_{}_{}\) by the assumption that \(_{}\) is invariant w.r.t the action of group \(\). If \(\) is known in advance, the learner can restrict the support of \(_{}\) in \(_{}\), and immediately obtains that the regret scales with \((_{})\) instead of \(d\), which can be significantly smaller (e.g., if \(=_{d}\), then \((_{})=1\)).

For any subgroup, there exists a fixed point subspace, and some subgroups may share the same fixed point subspace. Therefore, instead of constructing a collection of subgroups, one can create a smaller collection of models using the collection of fixed point subspaces. As \(\) is hidden, one must learn \(_{}\) within the set of candidates \(_{_{d}}\), leading to the formulation of the model selection.

From the setting with hidden subgroup to the setting with hidden set partition.Now, we discuss the structure of the collection of models \(_{_{d}}\). First, we show the equivalent structure between the collection of fixed point subspaces and the set partitions as follows.

**Proposition 1**.: _There is a bijection \(\) between \(_{d}\) and \(_{_{d}}\)._

As there is a bijection between \(_{d}\) and \(_{_{d}}\), we can count the number of subspaces of each dimension \(k\) explicitly using the following.

**Proposition 2** ('s Theorem 14).: _Given a subgroup \(_{d}\) and its fixed-point subspace \(_{}\), suppose that \(_{}\) partitions \([d]\) into \(k\) classes, then \((_{})=k\)._

By Proposition 2, we have that the number of subspaces of dimension \(k\) in \(_{_{d}}\) is exactly the number of set partitions with \(k\)-classes. Suppose that the learner knows that the orbit under action of \(\) partitions the index of \(_{}\) into 2 equivalent classes that is, \((_{})=2\). The learner cannot get any reduction in terms of regret.

**Proposition 3**.: _Assume that the action set is the unit cube \(=\{x^{d}\|x\|_{} 1\}\), and \(f\) is invariant w.r.t. action of subgroup \(_{d}\), such that \((_{})=2\). Then, the regret of any bandit algorithm is lower bounded by \(_{T}=(d)\)._

The implication of Proposition 3 is that even if the learner knows \(_{}\) lies in an extremely low-dimensional subspace within the finite pools of candidates, they _still suffer a regret that scales linearly with the ambient dimension \(d\)_. This suggests that _further information about the group \(\)_ must assumed to be known in order to break this polynomial dependence on \(d\) in the regret bound.

## 4 The Case of Hidden Subgroups with Subexponential Size

As indicated by Proposition 3, there is no improvement in terms of regret, despite the learner having access to a collection of extremely low-dimensional fixed point subspaces. Therefore, we assume that the learner can access only a reasonably small subset of the collection of low-dimensional fixed point subspaces. Let \(d_{0}\) be the upper bound for the dimension of fixed point subspaces; that is, we know that the orbit of \(\) partitions \([d]\) into at most \(d_{0}\) classes. Now, let us assume that the learner knows that \(\) does not partition \([d]\) freely, but must satisfy certain constraints, that is, \(_{}_{d, d_{0}}_{d, d_{0}}\). Here, \(_{d, d_{0}}\) is a small collection of partitions with at most \(d_{0}\) classes, which encodes the constraints on the way \(\) partitions \([d]\). We introduce an assumption regarding the cardinality of \(_{d, d_{0}}\), which is formally stated in Section 4.2. Using the Proposition 1, we can define the collection of fixed point subspaces associated with the collection of partition \(_{d, d_{0}}\) via the bijection \(\) as

\[:=(_{d, d_{0}})  M:=||.\]

In addition, let us define the extension of the collection \(\) as \(}:=\{(m m^{} ) m,\,m^{}\},\) where \((S)\) is the convex hull of the set \(S^{n}\)We have that \(}\) is a collection of subspaces, that is, \((m m^{})\) is indeed a subspace . Denote \(:=|}|\), then we have \(=(M^{2}-M)/2\). Moreover, if dimension of subspace in \(\) is at most \(d_{0}\), then the dimension of subspace in \(}\) is at most \(2d_{0}\).

### The Explore-Models-then-Commit Algorithm

Given some \(n[T]\), we define

\[Y=X_{}+,\] (2)

where \(Y^{n}\), \(X=[x_{1},,x_{n}]^{}^{n d}\) is the design matrix, \(_{}^{d}\) is the true model; \(=[_{1},,_{n}]\). We have the information that \(_{}\) must be contained in some (not necessarily unique) subspace \(m\). Denote by \(d_{m}\) the dimension of \(m\), we have \(d_{m} d_{0}\) for any \(m\). Let \(X_{m}=[_{m}(x_{t})]_{t[n]}^{},\) and \(S_{m}\) be the column space of \(X_{m}\), one has \((S_{m}) d_{m}\). For any \(m\), and given \(Y\), let \(_{S_{m}}()\) be the projection onto \(S_{m}\). Define

\[}_{m}:=_{S_{m}}(Y);_{m}:= {arg\,min}_{ m}\|Y-X\|_{2}^{2}.\] (3)

Now, given \(n\) data points, we can choose the model \(\) that minimises the least square error

\[*{arg\,min}_{m}\|Y-}_ {m}\|_{2}^{2}.\] (4)

Based on the framework of model selection, we now introduce our Algorithm 1, Explore-Models-then-Commit (EMC). Our algorithm falls into the class explore-then-commit bandit algorithms. The exploration phase consists of \(t_{1}\) rounds. During this phase, one samples data independently and identically distributed (i.i.d.) from an exploratory distribution \(\). After the exploration phase, one computes the solution to the model selection problem and then commits to the best arm corresponding to the chosen model.

**Remark 4**.: The key step of Algorithm 1 that may incur significant costs is solving equation (4) (line 6). Without additional information about \(\), one might need to enumerate all models in \(\) and optimize among them, which would induce a time complexity of \(O(nd^{cd_{0}})\). However, if we have more information about the partitions, e.g., if they are non-crossing or non-nesting partitions, their lattice structures can be exploited to speed up the optimization process of solving equation (4). Due to space limitations, we refer readers to Appendix D.3 for a detailed explanation of a subroutine that leverages these lattice structures for more efficient computation. Additionally, Section 6 demonstrates that our Algorithm 1, when using the lattice search algorithm for non-crossing partitions and non-nesting partitions as a subroutine, achieves polynomial computational complexity of \(O(nd^{5})\) and guarantees low regret.

### Regret Analysis

The regret analysis of Algorithm 1 uses results from the Gaussian model selection literature [7; 21] as a basis. As such, we first state the assumptions that are common in the Gaussian model selection literature on the collection of models \(\) and the set of arms \(\) (Section 4.2.1). We then provide our main analysis in Section 4.2.2, highlighting the key technical novelties of our approach.

#### 4.2.1 Assumptions

Recall that due to our lower bound in Proposition 3, further assumptions are required on the collection of fixed-point subspaces to achieve a reduction in terms of regret. As suggested by the model selection literature [25; 35], one can achieve regret in terms of \((M)\) for a collection of \(M\) models. Adopting this idea, we make the following assumption regarding the number of potential fixed-point subspaces and the set of arms.

**Assumption 5** (**Sub-exponential number of partitions**).: _The partition corresponding to \(\) belongs to a small subclass of partitions \(_{d, d_{0}}_{d, d_{0}}\). In particular, \(_{}_{d,d_{}},\) for some \(d_{} d_{0}\), and for each \(k[d_{0}]\), there exists a constant \(c>0\), such that \(|_{d,k}| O(d^{})\)._

**Assumption 6** (**Bounded set of arms**).: _There are positive numbers \(K_{x},R_{}\), such that, for all \(x\) and \(m}\), \(\|_{m}(x)\|_{2}^{2} K_{x}\), and \(| x,_{}.| R_{}.\)_

As a consequence of Assumption 5, the cardinality of the collection of fixed point subspaces is not too large, particularly, \(M=O(d^{0})\). First, we note that this class includes interval partitions, a structure equivalent to sparsity as a _strict_ subset, as explained below.

**Remark 7** (**Equivalence between sparsity and interval partition**).: A set partition of \([d]\) is an interval partition or partition of interval if its parts are interval. We denote \(_{d}\) as the collection of all interval partition of \(d\). \(_{d}\) admits a Boolean lattice of order \(2^{d-1}\), making it equivalent to the sparsity structure in \(d-1\) dimensions. Specifically, consider the set of entries of parameters \(^{d}\) with a linear order, that is, \(_{1}_{2}_{d}\). Then define the variable \(^{d-1}\) such that \(_{i}=(_{i}-_{i+1})\). Each interval partition on the entries of \(\) will determine a unique sparse pattern of \(\). Therefore, it is clear that the cardinality of the set of interval partition with \(d_{0}\) classes is bounded as \([_{d, d_{0}}]=O(d^{d_{0}})\). Moreover, as a result, symmetric linear bandit is strictly harder than sparse bandit and inherits all the computational complexity challenges of sparse linear bandit, including the _NP-hardness_ of computational complexity.

Apart from sparsity, class of partitions with sub-exponential size also naturally appears when there is a hierarchical structure on the set \([d]\), and the partitioning needs to respect this hierarchical structure. A partition that respects an ordered tree groups the children of the same node into a single equivalence class, for example, see Figure 1. It is shown in  and the cardinality of the set of partitions that respect ordered trees is sub-exponential. Furthermore, as shown in  there is a bijection between partitions that respect ordered trees and the set of non-crossing partitions.

A real-life example that meets these assumptions is the subcontractor example in the introduction: A hierarchical structure may exist, where a hired subcontractor can further subcontract parts of the work to others. A tree represents the hierarchical order among subcontractors, where subcontractors hired by another contractor can be grouped into one class. Further real-life examples of non-crossing partitions and other structured partitions that satisfy sub-exponential cardinality, such as non-nesting partitions and pattern-avoidance partitions , can be found in Appendix D.2.

Next, similar as , we define the exploratory distribution as follows.

**Definition 8** (**Exploratory distribution**).: The exploratory distribution \(()\) is solution of the following optimisation problem

\[=*{arg\,max}_{()}_{} (_{x}[xx^{}]), V:=_{x }[xx^{}], C_{}():=_{}(V).\] (5)

Since our setting includes sparsity as a special case, the regret lower bound in  applies to our setting as well. In particular, we have:

**Proposition 9** (**Regret lower bound**).: _There exist symmetric linear bandit instances in which Assumption 5, 6 hold with \(K_{x}=8d_{0}\), such that, any bandit algorithm must suffer regret \(_{T}=((C_{}()^{-}d_{0} ^{}T^{},))\)._

We note that the lower bound can be relaxed if we have a stronger assumption on the group \(\), which allows algorithm to go beyond the lower bound in Proposition 9 of the sparsity class. For example, if we consider a collection of fixed-point subspaces with a nested structure, similar to those discussed in , the algorithm may achieve a \(O(d_{0})\) rate. The key takeaway is that symmetry exhibits significant flexibility in structure. Depending on the specific class of symmetry, one may achieve either no reduction at all or significant reduction in terms of regret bound.

Figure 1: Partition that respects the underlying ordered tree.

#### 4.2.2 Main Regret Upper Bound Result

We now state the main result of the regret upper bound for Algorithm 1.

**Theorem 10** (**Regret upper bound**).: _Suppose the Assumptions 5, 6 hold. With the choice of \(t_{1}=R_{}^{-}^{}C_{}^{-}()K_{x}^{}d_{0}^{}T^{}((dT))^{}\), then the regret of Algorithm 1 is upper bounded as_

\[_{T}=O(R_{}^{}^{}C_{}^{- }()K_{x}^{}d_{0}^{}T^{} ((dT))^{})\] (6)

**Remark 11**.: We note that when \(K_{x}=O(d_{0})\), as in the lower bound instances, our upper bound is \((C_{}^{-}()d_{0}^{}T^{ {2}{3}})\), which matches the lower bound in Proposition 9.

The main idea is to bound the risk error after exploration rounds, as stated in the following lemma which implies the regret bound after standard manipulations.

**Lemma 12**.: _Suppose the Assumptions 5, 6 hold. For \(t_{1}=(K_{x}^{2}d_{0}C_{}^{-2}()(d/))\), with probability at least \(1-\), one has the estimate_

\[\|_{}-_{t_{1}}\|_{2}=O(d_{0}(d/)}{C_{}()t_{1}}}).\] (7)

**Remark 13** (**Non-triviality of Lemma 12**).: At the first glance, it seems that we can cast the problem of learning with a collection of \(M\) subspaces into a model selection problem in linear bandit with \(M\) features. This leads to a question: _Can we apply the model selection framework based on model aggregation in  to our case?_

First, let us explain how to cast our problem into a model selection problem in linear bandit. For each subspace \(m\), let \(_{m}:^{d}^{d_{0}}\) be the feature map that computes the image of the projection \(_{m}\) with respect to the orthogonal basis of subspace \(m\). Thus, we then have a collection of \(M\) features \(\{_{m}\}_{m}\). Consider the algorithm introduced in , which concatenates the feature maps into \((x)=[_{1}(x),,_{M}(x)]^{Md_{0}}\), and the regret bound depends on \(\|(x)\|_{2}\).

However, in our case where \(\|_{m}(x)\|_{2}<1\), we can only bound \(\|(x)\|_{2}\), which leads to a \(\) dependence on regret, if we use their algorithm. Regarding , their algorithm aggregates the predictions among models for each arm, and based on that, they compute the distribution for choosing each arm. This leads to the regret scaling with the number of arms \(K\), which is not feasible in our case when \(K=\).

We note that the similarity with the model selection technique in  is that they use model aggregation among \(\) to bound the prediction error \(_{t=1}^{T} x_{t},-_{}^ {2}\), but this does not necessarily guarantee the risk error \(\|-_{}\|_{2}\). The reason is that, although model aggregation can guarantee a small prediction error, it imposes no restriction on the estimator \(\), which limits its ability to leverage the further benign property of designed matrix \(X\). Instead of model aggregation, our algorithm explicitly picks the best model from the pool \(\), ensuring the following two properties: (1) The prediction error is small, similar to model aggregation; and (2) We can guarantee that \(\) lies in one of the subspaces of \(\). The second property gives us control over \((-_{})\) by ensuring it lies in at most \(M^{2}\) subspaces. Then, exploiting the restricted isometry property (see Definition 15) of designed matrix \(X\), we can guarantee that with \(O((M))\) exploratory samples, we can bound the risk error \(\|-_{}\|_{2}\). This is crucial for eliminating polynomial dependence on \(M\) and the number of arms \(K\).

Proof sketch of Lemma 12.We provide a proof sketch here and defer their full proof to Appendix B.1. Our proof borrows techniques from Gaussian model selection  and the compressed sensing literature . There are two steps to bound the risk error as in Lemma 12:

Step 1 - Bounding the prediction error.We can bound the prediction error \(\|X_{}-X_{t_{1}}\|_{2}\) using the Gaussian model selection technique  as follows.

**Proposition 14**.: _Let \(_{}=X_{}\). For the choice of \(}_{}\) as in Eqn. (3) & Eqn. (4), with probability at least \(1-\), there exists a constant \(C>1\) such that_

\[\|}_{}-_{}\|_{2}^{2} C ^{2}(M^{-1}).\] (8)Step 2 - Bounding the risk error from prediction error.To bound the risk error from the prediction error, we invoke the restricted isometry property on the union of subspaces of a sub-Gaussian random matrix as in . Note that \(\) and \(_{}\) can belong to two different subspaces of \(\), and \(-_{}\) may not lie in any subspace of \(\), but in \(}\). An important property of the design matrix \(X\), which allows one to recover \(_{}\) with the knowledge that \(_{}\) is in a subspace \(m\), can be captured by the following notion of restricted isometry property (RIP):

**Definition 15** (Restricted isometry property).: For any matrix \(X\), any collection of subspaces \(}\) and any \( m}\), we define \(}\)-restricted isometry constant \(_{}}(X)\) to be the smallest quantity such that

\[(1-_{}}(X))\|\|_{2}^{2}\|X\|_{2}^{ 2}(1+_{}}(X))\|\|_{2}^{2}.\] (9)

We have the minimum number of samples required so that a random matrix \(X\) satisfies RIP for a given constant with high probability as Proposition 16 below. Then, Lemma 12 is followed by combining Proposition 16 and Proposition 14.

**Proposition 16**.: _Let \(X=[x_{t}]_{t[n]}\), where \(x_{t}\)'s are is i.i.d. drawn from \(\), and let \(n=(C_{}^{-2}()K_{x}^{2}((2d_{0} ^{-1}))).\) Then, with probability at least \(1-\), and for any \(_{1},_{2}\) in subspaces of \(\), one has that_

\[\|_{1}-_{2}\|_{2}^{2} 2C_{}^{-1}()n^ {-1}\|X(_{1}-_{2})\|_{2}^{2}.\] (10)

## 5 Improved Regret Upper Bound with Well-Separated Partitions

We now show that by adding more structure (i.e., well-separatedness) to the setting, we can further improve the regret upper bound to \(O()\). In particular, we will introduce the notion of well-separatedness in this section, and show that this notion can lead to improved (i.e., \(O()\)) regret bounds.

For each partition \(p_{d}\), there is a unique equivalence relation on \([d]\) corresponding to \(p\). Denote by \(\) the equivalence relation corresponding to \(p\). Next, we define well-separatedness.

**Assumption 17** (**Well-separated partitioning)**.: _Given the true subgroup \(\), and the corresponding partition \(_{}\). For all \((i,j)\) such that \(i\)\(}}{}j\), it holds that \(|_{,i}-_{,j}|_{0}\), for some \(_{0}>0\)._

The implication of Assumption 17 is that the projection of \(_{}\) to any subspace \(m\) not containing \(_{}\) will cause some bias in the estimation error. In particular, one can show that for any \(m\) such that \(_{} m\), it holds that

\[\|_{}-_{m}(_{})\|_{2}^{2}_ {0}^{2}/2.\] (11)

We now show that under the Assumption 17, after the exploring phase, the algorithm returns a true fixed-point subspace \(_{}\) with high probability.

**Theorem 18**.: _Suppose the Assumptions 5, 6, 17 hold. Let \(t_{2}=(K_{x}^{2}d_{0}(dT)}{C_{}^{2}( )_{0}^{2}})\). Then, Algorithm 2 returns \(_{}\) with probability at least \(1-1/T\), and its regret is upper bounded as_

\[_{T}=O(^{2}K_{x}^{2}d_{0}(dT)}{C_{} ^{2}()_{0}^{2}}+ d_{0}T)}).\] (12)

That is, if the separating constant \(_{0}\) is known in advance and \(_{0} T^{-1/4}\), then we can achieve \(O(d_{0}(K_{x}T))\) regret upper bound.

**Remark 19**.: A weakness of Algorithm 2 is that without knowing that \(_{0} T^{-1/4}\) is true a priori, there may be possible mis-specification error, which leads to linear regret if one applies the algorithm naively. On the other hand, Algorithm 1 can always achieve regret \(O(T^{2/3})\) in the worst case. As such, the following question arises: _Does there exist an algorithm that, without the knowledge of \(_{0}\), can achieve regret \(O()\) whenever \(_{0} T^{-1/4}\), but guarantees the worst-case regret of \(O(T^{2/3})\)?_ Toward answering this question, we propose a simple method which has \(O()\) regret whenever the separating constant is large, and enjoys a worst-case regret guarantee of \(O(T^{3/4})\) (slightly worse than \(O(T^{2/3})\)). We refer the reader to Appendix C.2 for a detailed description of the algorithm, its regret bound and further discussion.

## 6 Experiment

To illustrate the performance of our algorithm, we conduct simulations where the entries of \(_{}\) satisfy three cases: sparsity, non-crossing partitions and non-nesting partitions. We refer readers to Appendix D.1 for a more formal description of non-crossing partitions, non-nesting partitions, and why the interval partition (i.e., the partition structure equivalent to sparsity) is a strict subset of both non-crossing and non-nesting partitions. Since sparsity is equivalent to a strict subset of non-crossing and non-nesting partitions, we compare our Algorithm 1 with the sparse-bandit ESTC algorithm proposed in  as a benchmark in all environments. The set of arms \(\) is \(^{d-1}\), \(=0.1\), and \(d=100\), \(d_{0}=15\). The ground-truth sparse patterns, partitions and \(_{}\) are randomized before each simulation.

The regret of both algorithms is shown in Figure 2, which indicates that our algorithm performs competitively in the sparsity case and significantly outperforms the sparse-bandit algorithm in cases of non-crossing and non-nesting partitions. Due to space limitations, we refer the reader to Appendix E for a detailed description of the experiments, including how we applied the sparse-bandit algorithm in the cases of non-crossing and non-nesting partitions, and how we ran Algorithm 1 in the case of sparsity. Additionally, we explain how we exploited the particular structure of non-crossing and non-nesting partitions to enable efficient computation in Appendix E.

## 7 Conclusion and Future Work

In this paper, we study symmetric linear stochastic bandits in high dimensions, where the linear reward function is invariant with respect to some hidden subgroup \(_{d}\). We first prove that no algorithm can gain any advantage solely by knowing \( S_{d}\). Given this, we introduce a cardinality condition on the hidden subgroup \(\), allowing the learner to overcome the curse of dimensionality. Under this condition, we propose novel model selection algorithms that achieve regrets of \((d_{0}^{2/3}T^{2/3})\) and \((d_{0})\) with an additional assumption on the well-separated partition. For future work, we will explore convex relaxation techniques for efficient computation, leveraging specific structures of symmetries.

Figure 2: Regret of EMC (Algorithm 1) and of ESTC proposed in , in cases of sparsity, non-crossing partitions, and non-nesting partitions.