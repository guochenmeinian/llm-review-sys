# Characterizing Graph Datasets for Node Classification:

Homophily-Heterophily Dichotomy and Beyond

Oleg Platonov

HSE University

Yandex Research

olegplatonov@yandex-team.ru

&Denis Kuznedelev

Yandex Research

Skoltech

dkuznedelev@yandex-team.ru

Artem Babenko

Yandex Research

artem.babenko@phystech.edu

&Liudmila Prokhorenkova1

Yandex Research

ostroumova-la@yandex-team.ru

Equal contributionCorresponding author

###### Abstract

_Homophily_ is a graph property describing the tendency of edges to connect similar nodes; the opposite is called _heterophily_. It is often believed that heterophilous graphs are challenging for standard message-passing graph neural networks (GNNs), and much effort has been put into developing efficient methods for this setting. However, there is no universally agreed-upon measure of homophily in the literature. In this work, we show that commonly used homophily measures have critical drawbacks preventing the comparison of homophily levels across different datasets. For this, we formalize desirable properties for a proper homophily measure and verify which measures satisfy which properties. In particular, we show that a measure that we call _adjusted homophily_ satisfies more desirable properties than other popular homophily measures while being rarely used in graph machine learning literature. Then, we go beyond the homophily-heterophily dichotomy and propose a new characteristic that allows one to further distinguish different sorts of heterophily. The proposed _label informativeness_ (LI) characterizes how much information a neighbor's label provides about a node's label. We prove that this measure satisfies important desirable properties. We also observe empirically that LI better agrees with GNN performance compared to homophily measures, which confirms that it is a useful characteristic of the graph structure.

## 1 Introduction

Graphs are a natural way to represent data from various domains such as social networks, citation networks, molecules, transportation networks, text, code, and others. Machine learning on graph-structured data has experienced significant growth in recent years, with Graph Neural Networks (GNNs) showing particularly strong results. Many variants of GNNs have been proposed [16; 10; 43; 45], most of them can be unified by a general Message Passing Neural Networks (MPNNs) framework . MPNNs combine node features (attributes) with graph topology to learn complex dependencies between the nodes. For this, MPNNs iteratively update the representation of each node by aggregating information from the previous-layer representations of the node itself and its neighbors.

In many real-world networks, edges tend to connect similar nodes: users in social networks tend to connect to users with similar interests, and papers in citation networks mostly cite works from the same research area. This property is usually called _homophily_. The opposite of homophily is _heterophily_: for instance, in social networks, fraudsters rarely connect to other fraudsters, while in dating networks, edges often connect the opposite genders. Early works on GNNs mainly focus on homophilous graphs. However, it was later discovered that classic GNNs typically do not perform well on heterophilous graphs, and new GNN architectures have been developed for this setting [1; 4; 32; 48; 49].

To measure the level of homophily, several _homophily measures_ are used in the literature [1; 20; 32; 48], but these measures may significantly disagree with each other. In this work, we start by addressing the problem of how to properly measure the homophily level of a graph. For this, we formalize some desirable properties of a reasonable homophily measure and check which measures satisfy which properties. One essential property is called _constant baseline_ and, informally speaking, it requires a measure to be not biased towards particular numbers of classes or their size balance. Our analysis reveals that commonly used homophily measures do not satisfy this property and thus cannot be compared across different datasets. In contrast, a measure that we call _adjusted homophily_ (a.k.a. _assortativity coefficient_) satisfies most of the desirable properties while being rarely used in graph ML literature. Based on our theoretical analysis, we advise using adjusted homophily as a better alternative to the commonly used measures.

Then, we note that heterophilous datasets may have various connectivity patterns, and some of them are easier for GNNs than others. Motivated by that, we propose a new graph property called _label informativeness_ (LI) that allows one to further distinguish different sorts of heterophily. LI characterizes how much information the neighbor's label provides about the node's label. We analyze this measure via the same theoretical framework and show that it satisfies the constant baseline property and thus is comparable across datasets. We also observe empirically that LI better agrees with GNN performance than homophily measures. Thus, while being very simple to compute, LI intuitively illustrates why GNNs can sometimes perform well on heterophilous datasets -- a phenomenon recently observed in the literature. While LI is not a measure of homophily, it naturally complements adjusted homophily by distinguishing different heterophily patterns.

In summary, we propose a theoretical framework that allows for an informed choice of suitable characteristics describing graph connectivity patterns in node classification tasks. Based on this framework, we suggest using adjusted homophily to measure whether similar nodes tend to be connected. To further characterize the datasets and distinguish different sorts of heterophily, we propose a new measure called label informativeness.

## 2 Homophily measures

Assume that we are given a graph \(G=(V,E)\) with nodes \(V\), \(|V|=n\), and edges \(E\). Throughout the paper, we assume that the graph is simple (without self-loops and multiple edges) and undirected.3 Each node \(v V\) has a feature vector \(_{v}^{m}\) and a class label \(y_{v}\{1,,C\}\). Let \(n_{k}\) denote the size of \(k\)-th class, i.e., \(n_{k}=|\{v:y_{v}=k\}|\). By \(N(v)\) we denote the neighbors of \(v\) in \(G\) and by \(d(v)=|N(v)|\) the degree of \(v\). Also, let \(D_{k}:=_{v\,:\,y_{v}=k}d(v)\). Let \(p()\) denote the empirical distribution of class labels, i.e., \(p(k)=}{n}\). Then, we also define degree-weighted distribution as \((k)=d(v)}{2|E|}=}{2|E|}\).

### Popular homophily measures

Many GNN models implicitly make a so-called _homophily_ assumption: that similar nodes are connected. Similarity can be considered in terms of node features or node labels. Usually, _label homophily_ is analyzed, and we also focus on this aspect, leaving _feature homophily_ for further studies. There are several commonly used homophily measures in the literature. _Edge homophily_[1; 48] is the fraction of edges that connect nodes of the same class:

\[h_{edge}= E:y_{u}=y_{v}\}|}{|E|}\,.\] (1)_Node homophily_ computes the fraction of neighbors that have the same class for all nodes and then averages these values across the nodes:

\[h_{node}=_{v V}=y_{v}\}|}{d(v)}\,.\]

These two measures are intuitive but have the downside of being sensitive to the number of classes and their balance, which makes them hard to interpret and incomparable across different datasets . For example, suppose that each node in a graph is connected to one node of each class. Then, both edge homophily and node homophily for this graph will be equal to \(\). Thus, these metrics will produce widely different values for graphs with different numbers of classes, despite these graphs being similar in exhibiting no homophily. To fix these issues, Lim et al.  propose another homophily measure sometimes referred to as _class homophily_. Class homophily measures excess homophily compared to a null model where edges are independent of the labels. More formally,

\[h_{class}=_{k=1}^{C}[=k}|\{u N(v): y_{u}=y_{v}\}|}{_{v:y_{v}=k}d(v)}-}{n}]_{+},\]

where \([x]_{+}=\{x,0\}\). The factor \(\) scales \(h_{class}\) to the interval \(\); larger values indicate more homophilous graphs and non-homophilous ones are expected to have close to zero values.

However, there are still some issues with class homophily. First, when correcting the fraction of intra-class edges by its expected value, class homophily does not consider the variation of node degrees. Indeed, if nodes of class \(k\) have, on average, larger degrees than \(2|E|/n\), then the probability that a random edge goes to that class can be significantly larger than \(n_{k}/n\). Second, only positive deviations from \(n_{k}/n\) contribute to class homophily, while classes with heterophilous connectivity patterns are neglected. Let us illustrate these drawbacks of class homophily with a simple example.

**Example** Let us construct non-homophilous graphs for which class homophily is significantly larger than zero. First, we take a clique of size \(r\) with all nodes belonging to the red class; then, for each node in the clique, connect it to \(r-1\) leaves, all of which belong to the blue class (example for \(r=4\) is shown on the right). Note that all blue nodes are strictly heterophilous (i.e., only connect to nodes of the opposite class), while all red nodes are class-agnostic (i.e., have the same number of neighbors of both classes). Such graphs are clearly non-homophilous, and a meaningful homophily measure should not produce a value significantly greater than zero for them. However, class homophily for such graphs is positive and can become as large as \( h_{class}=-\) as \(r\).

### Desirable properties for homophily measures

Above, we discussed some disadvantages of existing homophily measures. In this section, we formalize and extend this discussion: we propose a list of properties desirable for a good homophily measure. Our analysis is motivated by recent studies of clustering and classification performance measures , but not all their properties can be transferred to homophily measures. For instance, we do not require _symmetry_ -- a property that a measure does not change when we swap the compared objects -- since homophily compares entities of different nature (a graph and a labeling). For the same reason, the _distance_ property (requiring a measure to be linearly transformed to a metric distance) cannot be defined. On the other hand, some of our properties are novel.

Maximal agreementThis property requires that perfectly homophilous graphs achieve a constant upper bound of the measure. Formally, we say that a homophily measure \(h\) satisfies maximal agreement if for any graph \(G\) in which \(y_{u}=y_{v}\) for all \(\{u,v\} E\) we have \(h(G)=c_{}\). For all other graphs \(G\), we require \(h(G)<c_{}\).

Minimal agreementWe say that a homophily measure \(h\) satisfies minimal agreement if \(h(G)=c_{}\) for any graph \(G\) in which \(y_{u} y_{v}\) for all \(\{u,v\} E\). For all other graphs \(G\), we require \(h(G)>c_{}\). In other words, if all edges connect nodes of different classes, we expect to observe a constant minimal value.

Constant baselineThis property ensures that homophily is not biased towards particular class size distributions. Intuitively, if the graph structure is independent of labels, we would expect a low homophily value. Moreover, if we want a measure to be comparable across datasets, we expect to observe the same low value in all such cases. There are several ways to formalize the concept of independence, and we suggest the one based on the so-called _configuration model_.

**Definition 1**.: _Configuration model_ is defined as follows: take \(n\) nodes, assign each node \(v\) degree \(d(v)\), and then randomly pair edge endpoints to obtain a graph.4

Assuming that we are given \(n\) labeled nodes and the graph is constructed according to the configuration model (independently from the labels), we expect to observe a fixed (small) homophily independently of the number of classes and class size balance. We formalize this property as follows and refer to Appendix B.2 for other possible definitions.

**Definition 2**.: A homophily measure \(h\) has _asymptotic constant baseline_ if for \(G\) generated according to the configuration model and for any \(>0\) with probability \(1-o(1)\) we have \(|h(G)-c_{base}|<\) for some constant \(c_{base}\) as \(n\).

In combination with maximal agreement, asymptotic constant baseline makes the values of a homophily measure comparable across different datasets: the maximal agreement guarantees that perfectly homophilous graphs have the same value, while constant baseline aligns the uninformative cases with neither strong homophily nor strong heterophily.

Empty class toleranceSince homophily measures are used to compare different graph datasets, they have to be comparable across datasets with varying numbers of classes. For this, the following property is required.

**Definition 3**.: A measure is tolerant to empty classes if it is defined and it does not change when we introduce an additional dummy label that is not present in the data.

For instance, edge homophily and node homophily are empty class tolerant, while class homophily is not. Empty class tolerance is a new property that was not discussed in  since classification and clustering evaluation measures are used within one given dataset, see Appendix B.3 for more details.

MonotonicityAs we discuss in Appendix B.3, it can be non-trivial to define _monotonicity_ for homophily measures and there can be different possible options. In this paper, we use the following definition that aligns especially well with edge-wise homophily measures discussed below in Section 2.5.

**Definition 4**.: A homophily measure is _monotone_ if it is empty class tolerant, increases when we add an edge between two nodes of the same class (except for perfectly homophilous graphs) and decreases when we add an edge between two nodes of different classes (except for perfectly heterophilous graphs).

In contrast to Gosgens et al. , our notion of monotonicity requires the property to hold across graphs with different numbers of classes. This is caused by the empty class tolerance property.

### Properties of popular homophily measures

Below we briefly discuss the properties of popular homophily measures. In most cases, the proofs are straightforward or follow from Section 2.5 below. Table 1 summarizes the results.

_Edge homophily_ satisfies maximal and minimal agreement and is empty class tolerant and monotone. However, it does not satisfy asymptotic constant baseline, which is a critical drawback: one can get misleading results in settings with imbalanced classes.

_Node homophily_ satisfies maximal and minimal agreement. It is empty class tolerant, but not monotone: adding an edge between two perfectly homophilous nodes of the same class does not change node homophily. Similarly to edge homophily, node homophily does not satisfy the asymptotic constant baseline and thus is incomparable across different datasets.

_Class homophily_ satisfies maximal agreement with \(h_{class}=1\), but minimal agreement is not satisfied: not only perfectly heterophilous graphs may have \(h_{class}=0\). Class homophily is not empty class tolerant and thus is not monotone. Additionally, it does not have the asymptotic constant baseline. See Appendix B.1 for the proofs and discussions. Interestingly, removing the \([]_{+}\) operation from the definition of class homophily solves the problem with the asymptotic constant baseline, but minimal agreement, empty class tolerance, and monotonicity are still violated.

### Adjusted homophily

Let us discuss a much less known homophily measure that by construction satisfies two important properties -- maximal agreement and constant baseline. To derive this measure, we start with edge homophily and first enforce the constant baseline property by subtracting the expected value of the measure. Under the configuration model, the probability that a given edge endpoint will be connected to a node with a class \(k\) is (up to a negligible term) \(d(v)}{2|E|}\). Thus, the adjusted value becomes \(h_{edge}-_{k=1}^{C}^{2}}{4|E|^{2}}\). Now, to enforce maximal agreement, we normalize the measure as follows:

\[h_{adj}=-_{k=1}^{C}(k)^{2}}{1-_{k=1}^{C}( k)^{2}},\] (2)

where we use the notation \((k)=}{2|E|}\). This measure is known in graph analysis literature as _assortativity coefficient_. While assortativity is a general concept that is often applied to _node degrees_, it reduces to (2) when applied to categorical node attributes on undirected graphs. Unfortunately, this measure is rarely used in graph ML literature (Suresh et al.  is the only work we are aware of that uses it for measuring homophily), while our theoretical analysis shows that it satisfies many desirable properties. Indeed, the following theorem holds (see Appendix B.4 for the proof).

**Theorem 1**.: _Adjusted homophily satisfies maximal agreement, asymptotic constant baseline, and empty class tolerance. The minimal agreement is not satisfied. Moreover, this measure is monotone if \(h_{adj}>(i)^{2}}{_{i}(i)^{2}+1}\) and we note that the bound \((i)^{2}}{_{i}(i)^{2}+1}\) is always smaller than 0.5. When \(h_{adj}\) is small, counterexamples to monotonicity exist._

While adjusted homophily violates some properties, it still dominates all other measures and is comparable across different datasets with varying numbers of classes and class size balance. Thus, we recommend using it as a measure of homophily in further works.

### Edge-wise homophily vs classification evaluation measures

We conclude the analysis of homophily measures by establishing a connection between them and classification evaluation measures . For this, let us first define _edge-wise_ homophily measures. We say that a homophily measure is edge-wise if it is a function of the _class adjacency matrix_ that we now define. Since we consider undirected graphs, each edge \(\{u,v\} E\) gives two ordered pairs of nodes \((u,v)\) and \((v,u)\). We can define a class adjacency matrix \(\) as follows: each matrix element \(c_{ij}\) denotes the number of edges \((u,v)\) such that \(y_{u}=i\) and \(y_{v}=j\). Since the graph is undirected, the matrix \(\) is symmetric. Note that monotonicity can be naturally put in terms of the class adjacency matrix: adding an edge between two nodes of the same class \(i\) corresponds to incrementing the

   Measure & Max & Min & ACB & ECT & Mon \\  Edge homophily & ✓ & ✓ & ✗ & ✓ & ✓ \\ Node homophily & ✓ & ✓ & ✗ & ✓ & ✗ \\ Class homophily & ✓ & ✗ & ✗ & ✗ & ✗ \\ Adjusted homophily & ✓ & ✗ & ✓ & ✓ & ✗* \\   

Table 1: Properties of homophily measures: maximal agreement (Max), minimal agreement (Min), asymptotic constant baseline (ACB), empty class tolerance (ECT), monotonicity (Mon). ✗* denotes that the property is not satisfied in general, but holds for large \(h_{adj}\) (see Theorem 1).

diagonal element \(c_{ii}\) by two, and adding an edge between two nodes of different classes \(i\) and \(j\) corresponds to incrementing \(c_{ij}\) and \(c_{ji}\) by one.

Now, for each edge \((u,v)\), let us say that \(y_{u}\) is a _true label_ (for some object) and \(y_{v}\) is a _predicted label_. Then, any classification evaluation measure (e.g., accuracy) applied to this dataset is a measure of homophily. Based on that, we get the following correspondence.

Clearly, _accuracy_ corresponds to _edge homophily \(h_{edge}\)_.

Interestingly, both _Cohen's Kappa_ and _Matthews correlation coefficient_ correspond to _adjusted homophily_. As argued in , the Matthews coefficient is one of the best classification evaluation measures in terms of its theoretical properties. Our extended analysis confirms this conclusion for the corresponding homophily measure: we prove a stronger version of asymptotic constant baseline and also establish a stronger variant of monotonicity in the interval of large values of \(h_{adj}\). The latter result is essential since in  it was only claimed that monotonicity is violated when \(C>2\).

Another measure advised by  is _symmetric balanced accuracy_. Since in our case the class adjacency matrix is symmetric, it gives the same expression as _balanced accuracy_: \(h_{bal}=_{k=1}^{C}}=y_{v}=k|}{D_{k}}\). The obtained measure satisfies the maximal and minimal agreement properties. However, it is not empty class tolerant and thus is not monotone. The asymptotic constant baseline is also not satisfied: the value \(c_{base}=1/C\) depends on the number of classes. Thus, despite this measure being suitable for classification evaluation, it cannot be used as a homophily measure. This difference is caused by the fact that homophily measures have to be comparable across datasets with different numbers of classes, while for classification evaluation it is not required.

Finally, note that similarly to our derivations in Section 2.4, the value \(h_{bal}\) can be adjusted to have both maximal agreement and constant baseline. Interestingly, this would lead to a slightty modified class homophily with \([]_{+}\) operation removed. As discussed in Section 2.3, the obtained measure satisfies only the maximal agreement and constant baseline.

To conclude, there is a correspondence between edge-wise homophily measures and classification evaluation measures. Adjusted homophily corresponds to both Cohen's Kappa and Matthews coefficient. In terms of the satisfied properties, adjusted homophily dominates all other measures derived from this correspondence.

Finally, we also note that homophily measures can be directly related to _community detection evaluation measures_ including the well-established characteristic in graph community detection literature called _modularity_. See Appendix B.5 for a detailed discussion.

## 3 Label informativeness

In the previous section, we discussed in detail how to properly measure the homophily level of a graph. While homophily indicates whether similar nodes are connected, heterophily is defined as the negation of homophily. Thus, heterophilous graphs may have very different connectivity patterns. In this section, we characterize such patterns.

To give an example, among strictly heterophilous graphs in which nodes never connect to nodes of the same class, there can be those where edges are drawn between particular pairs of classes (Figure 0(a)) and those where the class of a node cannot be derived from the class of its neighbor (Figure 0(b)). While adjusted homophily correctly captures the absence of homophily in these graphs, it is not designed to identify which type they belong to. However, distinguishing such graphs is practically important: informative neighbors can be very useful for models accounting for the graph structure.

Figure 1: Non-homophilous graphs with different connection patterns

We define a characteristic measuring the informativeness of a neighbor's label for a node's label. For example, in Figure 0(a), the neighbor's label uniquely defines the node's label. Thus, the node classification task is simple on this dataset, and we want our informativeness to be maximal for such graphs. Let us formalize this idea. Assume that we sample an edge \((,) E\) (from some distribution). The class labels of nodes \(\) and \(\) are then random variables \(y_{}\) and \(y_{}\). We want to measure the amount of knowledge the label \(y_{}\) gives for predicting \(y_{}\). The entropy \(H(y_{})\) measures the 'hardness' of predicting the label of \(\) without knowing \(y_{}\). Given \(y_{}\), this value is reduced to the conditional entropy \(H(y_{}|y_{})\). In other words, \(y_{}\) reveals \(I(y_{},y_{})=H(y_{})-H(y_{}|y_{})\) information about the label. To make the obtained quantity comparable across different datasets, we say that _label informativeness_ is the normalized mutual information of \(y_{}\) and \(y_{}\):

\[:=I(y_{},y_{})/H(y_{})\,.\] (3)

We have \(\). If the label \(y_{}\) allows for unique reconstruction of \(y_{}\), then \(=1\). If \(y_{}\) and \(y_{}\) are independent, \(=0\).

Depending on the distribution used for sampling an edge \((,)\), one can obtain several variants of \(\). For instance, if the edges are sampled uniformly at random (which is a natural approach), the mutual distribution \((y_{},y_{})\) for a randomly sampled edge is \(p(c_{1},c_{2})=_{(u,v) E}\{y_{}=c_{1},y_{} =c_{2}\}}{2|E|}\). Then, the marginal distribution of \(y_{}\) (and \(y_{}\)) is the degree-weighted distribution \((c)\). Thus, (3) becomes:

\[_{edge}=-,c_{2}}p(c_{1},c_{2}),c_{ 2})}{(c_{1})(c_{2})}}{_{c}(c)(c)}=2-,c_{2}}p(c_{1},c_{2}) p(c_{1},c_{2})}{_{c}(c) (c)}\,.\]

For brevity, we further denote \(_{edge}\) by \(\) and focus on this version of the measure. However, note that another natural approach to edge sampling is to first sample a random node and then sample a random edge incident to this node. For a discussion of this approach, we refer to Appendix C.2.

To claim that \(\) is a suitable graph characteristic, we need to show that it is comparable across different datasets. For this, we need to verify two properties: maximal agreement and asymptotic constant baseline. Recall that \(\) is upper bounded by one and equals one if and only if the neighbor's class uniquely reveals the node's class. This property can be considered as a direct analog of the maximal agreement defined in Section 2.2. The following theorem shows that \(\) satisfies the asymptotic constant baseline; see Appendix C.1 for the proof.

**Theorem 2**.: _Assume that \(|E|\) as \(n\) and that the entropy of \(()\) is bounded from below by some constant. Let \(_{min}=_{k}(k)\) and assume that \(_{min} C/\) as \(n\). Then, for the random configuration model, we have \(=o(1)\) with high probability._

In summary, \(\) is a simple graph characteristic suitable for comparing different datasets. We note that \(\) is not a measure of homophily. \(\) naturally complements homophily measures by distinguishing different types of heterophilous graphs.

## 4 Empirical illustrations

In this section, we first characterize some existing graph datasets in terms of homophily and \(\) to see which structural patterns are currently covered. Then, we show that \(\), despite being a very simple graph characteristic, much better agrees with GNN performance than homophily.5

### Characterizing real graph datasets

We first look at the values of homophily and label informativeness for existing graph datasets. For this analysis, we choose several node classification datasets of different sizes and properties. Statistics of these datasets and values of all the measures discussed in this paper are provided in Table 5 in Appendix E, while Table 2 shows selected results.

Recall that both node and edge homophily are sensitive to the number of classes and class size balance. Indeed, they may indicate high homophily levels for some heterophilous datasets. Anextreme example is questions: \(h_{edge}=0.84\), while more reliable adjusted homophily shows that the dataset is heterophilous: \(h_{adj}=0.02\). In fact, all binary classification datasets in Table 5 could be considered homophilous if one chooses \(h_{edge}\) or \(h_{node}\) as the measure of homophily. In contrast, \(h_{adj}\) satisfies the constant baseline property and shows that most of the considered binary classification datasets are heterophilous.

It is expected that datasets with high homophily \(h_{adj}\) also have high LI since homophily implies informative neighbor classes. For medium-level homophily, LI can behave differently: for instance, ogbn-arxiv and twitter-hate have similar homophily levels, while the neighbors in ogbn-arxiv are significantly more informative. For heterophilous datasets, LI can potentially be very different, as we demonstrate in Section 4.2 on synthetic and semi-synthetic data. However, most existing heterophilous datasets have LI \( 0\). This issue is partially addressed by new heterophilous datasets recently proposed in . For the proposed roman-empire dataset, \(=0.11\) and \(h_{adj}=-0.05\). Thus, while being heterophilous, this dataset has non-zero label informativeness, meaning that neighboring classes are somewhat informative. We believe that datasets with more interesting connectivity patterns will be collected in the future.

### Correlation of LI with GNN performance

Recently, it has been shown that standard GNNs can sometimes perform well on non-homophilous datasets [22; 24]. We hypothesize that GNNs can learn more complex relationships between nodes than just homophily, and they will perform well as long as the node's neighbors provide some information about this node. Thus, we expect LI to better correlate with the performance of GNNs than homophily. To illustrate this, we use carefully designed synthetic and semi-synthetic data. First, it allows us to cover all combinations of homophily levels and label informativeness. Second, we can control that only a connection pattern changes while other factors affecting the performance are fixed.

Synthetic data based on SBM modelTo start with the most simple and controllable setting, we generate synthetic graphs via a variant of the _stochastic block model_ (SBM) . In this model, the nodes are divided into \(C\) clusters, and for each pair of nodes \(i,j\), we draw an edge between them with probability \(p_{c(i),c(j)}\) independently of all other edges. Here \(c(i)\) is a cluster assignment for a node \(i\), which in our case corresponds to the node label \(y_{i}\).

We set the number of classes to \(C=4\) and the class size to \(l=n/4\). We define the probabilities as follows: \(p_{i,j}=p_{0}K\) if \(i=j\), \(p_{i,j}=p_{1}K\) if \(i+j=5\), and \(p_{i,j}=p_{2}K\) otherwise. Here \(K>0\) and we require \(p_{0}+p_{1}+2p_{2}=1\). Note that the expected degree of any node is (up to a negligibly small term) \(p_{0}Kl+p_{1}Kl+2p_{2}Kl=Kl\).

This model allows us to explore various combinations of dataset characteristics. Indeed, \(p_{0}\) directly controls the homophily level, while the relation between \(p_{1}\) and \(p_{2}\) enables us to vary LI. To see this, we note that the condition \(i+j=5\) gives two pairs of classes: \((1,4)\) and \((2,3)\). Thus, if \(p_{2}=0\) and \(p_{1}>0\), knowing the label of any neighbor from another class, we can uniquely restore the node's label. In contrast, for given \(p_{0}\), the case \(p_{1}=p_{2}\) gives the smallest amount of additional information. The following proposition characterizes the covered combinations of LI and homophily; the proof follows from the construction procedure.

**Proposition 1**.: _As \(n\), the dataset characteristics of the proposed model converge to the following values (with high probability): \(h_{adj}=p_{0}-\), \(=1-,p_{1},p_{2},p_{2})}{ 4}\), where \(H()=-_{i}x_{i}(x_{i})\)._

Thus, \(h_{adj}\) ranges from \(-1/3\) to \(1\) and \(\) can be between 0 and 1. If \(=0\), then we always have \(h_{adj}=0\); if \(h_{adj}=1\), then \(=1\). However, if \(=1\), then either \(h_{adj}=-1/3\) or \(h_{adj}=1\).

   Dataset & \(C\) & \(h_{edge}\) & \(h_{adj}\) & LI \\  lastfm-asia & 18 & 0.87 & 0.86 & 0.74 \\ cora & 7 & 0.81 & 0.77 & 0.59 \\ ogbn-arxiv & 40 & 0.65 & 0.59 & 0.45 \\ twitter-hate & 2 & 0.78 & 0.55 & 0.23 \\ wiki & 5 & 0.38 & 0.15 & 0.06 \\ twitch-gamers & 2 & 0.55 & 0.09 & 0.01 \\ actor & 5 & 0.22 & 0.00 & 0.00 \\ questions & 2 & 0.84 & 0.02 & 0.00 \\ roman-empire & 18 & 0.05 & -0.05 & 0.11 \\   

Table 2: Characteristics of some real graph datasets, see Table 5 for the full results

[MISSING_PAGE_FAIL:9]

models and both datasets. The correlation coefficients for homophily measures are all negative, while for LI they are positive and sufficiently large. This again confirms that LI indicates whether graph structure is helpful for GNNs.

Additionally, we conduct experiments with other datasets: Appendix F.4 describes the results for the LFR benchmark  and Appendix F.5 presents an experiment on synthetic data from .

## 5 Conclusion

In this paper, we discuss how to characterize graph node classification datasets. First, we revisit the concept of homophily and show that commonly used homophily measures have significant drawbacks preventing the comparison of homophily levels between different datasets. For this, we formalize properties desirable for a good homophily measure and prove which measures satisfy which properties. Based on our analysis, we conclude that _adjusted homophily_ is a better measure of homophily than the ones commonly used in the literature. We believe that being able to properly estimate the homophily level of a graph is essential for the future development of heterophily-suited GNNs: we need a characteristic that reliably differentiates homophilous and heterophilous graphs.

Then, we argue that heterophilous graphs may have very different structural patterns and propose a new property called _label informativeness_ (LI) that allows one to distinguish them. LI characterizes how much information a neighbor's label provides about a node's label. Similarly to adjusted homophily, this measure satisfies important properties and thus can be used to compare datasets with different numbers of classes and class size balance. Through a series of experiments, we show that LI correlates well with the performance of GNNs.

To conclude, we believe that adjusted homophily and label informativeness will be helpful for researchers and practitioners as they allow one to easily characterize the connectivity patterns of graph datasets. We also hope that new realistic datasets will be collected to cover currently unexplored combinations of \(h_{adj}\) and LI. Finally, our theoretical framework can be helpful for the further development of reliable graph characteristics.

LimitationsWe advise using adjusted homophily as a reliable homophily measure since it is the only existing measure having constant baseline and thus it dominates other known alternatives in terms of desirable properties. However, it still violates minimal agreement, and monotonicity is guaranteed only for sufficiently large values of \(h_{adj}\). It is currently an open question whether there exist measures dominating adjusted homophily in terms of the satisfied properties.

Regarding LI, we do not claim that this measure is a universal predictor of GNN performance. We designed this measure to be both informative and simple to compute and interpret. For instance, LI considers all edges individually and does not account for the node's neighborhood as a whole. As a result, LI can be insensitive to some complex dependencies. Such dependencies can be important for some tasks, but taking them into account is tricky and would significantly complicate the measure. However, we clearly see that despite its simplicity, LI correlates with GNN performance much better than homophily.

Let us also note that our analysis of both homophily and LI is limited to graph-label interactions. In future work, it would be important to also analyze node features. Indeed, node features may have non-trivial relations with both graph and labels. For example, a graph can be heterophilous in terms of labels but homophilous in terms of node features or vice versa. These interactions may allow one to understand the properties and performance of GNNs even better. However, analyzing feature-based homophily or informativeness can be much more difficult since the features can differ in nature, scale, and type.