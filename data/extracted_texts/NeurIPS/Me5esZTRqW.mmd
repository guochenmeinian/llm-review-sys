# Covariate Shift Corrected Conditional Randomization Test

Bowen Xu

Harvard University

bowenxu@g.harvard.edu

&Yiwen Huang*

Department of Statistics

Peking University

2000010773@stu.pku.edu.cn

&Chuan Hong

Department of Biostatistics and Bioinformatics

Duke University

chuan.hong@duke.edu

&Shuanging Li

Booth School of Business

University of Chicago

shuangning.li@chicagobooth.edu

&Molei Liu

Department of Biostatistics

Columbia Mailman School of Public Health

ml4890@cumc.columbia.edu

These authors contributed equally to this work.Corresponding author. To whom correspondence should be addressed.

###### Abstract

Conditional independence tests are crucial across various disciplines in determining the independence of an outcome variable \(Y\) from a treatment variable \(X\), conditioning on a set of confounders \(Z\). The Conditional Randomization Test (CRT) offers a powerful framework for such testing by assuming known distributions of \(X Z\); it controls the Type-I error exactly, allowing for the use of flexible, black-box test statistics. In practice, testing for conditional independence often involves using data from a source population to draw conclusions about a target population. This can be challenging due to covariate shift--differences in the distribution of \(X\), \(Z\), and surrogate variables, which can affect the conditional distribution of \(Y X,Z\)--rendering traditional CRT approaches invalid. To address this issue, we propose a novel Covariate Shift Corrected Pearson Chi-squared Conditional Randomization (csPCR) test. This test adapts to covariate shifts by integrating importance weights and employing the control variates method to reduce variance in the test statistics and thus enhance power. Theoretically, we establish that the csPCR test controls the Type-I error asymptotically. Empirically, through simulation studies, we demonstrate that our method not only maintains control over Type-I errors but also exhibits superior power, confirming its efficacy and practical utility in real-world scenarios where covariate shifts are prevalent. Finally, we apply our methodology to a real-world dataset to assess the impact of a COVID-19 treatment on the 90-day mortality rate among patients.

## 1 Introduction

Conditional independence tests are important across diverse fields for determining whether an outcome variable \(Y\) is independent of a treatment variable \(X\), conditioning on a potentially highdimensional vector of confounding variables \(Z.\) This type of testing is critical for understanding the complex relationships among variables. For instance, scientists may hope to understand whether a specific genetic feature influences disease outcomes, whether a particular treatment effectively extends life expectancy, or whether certain demographic factors impact college admissions.

Traditionally, these conditional testing problems are approached by modeling \(Y\) against \(X\) and \(Z\) through some parametric or semiparametric model. However, this strategy has been criticized due to potential model misspecification and limited observations of \(Y\). As an alternative strategy, the model-X framework and Conditional Randomization Test (CRT) propose testing for the general conditional independence hypothesis \(H_{0}:X\!\!\! Y Z,\) free of any specific effect parameters . The CRT assumes the distribution of \(X Z\) to be known and can control the type-I error exactly, allowing for the choice of any flexible, black-box test statistic. This strategy is particularly useful when there is either strong and reliable scientific knowledge of the distribution of \(X Z\) or an auxiliary dataset of \((X,Z)\) of large sample size, known as the semi-supervised setting.

In practice, testing for conditional independence frequently involves using data from a source population to draw conclusions about a target population. This situation presents challenges due to potential differences in the distribution of variables between the two populations. For example, economists may be interested in whether college admission (\(Y\)) is independent of family income (\(X\)), conditioning on variables such as GPA, extracurricular activities, geographic location, and other demographics (\(Z\)). In the source population, the relationship might be influenced by factors like wealthy parents investing in SAT preparation, which boosts admission rates--a relationship that may not exist in a target population where such preparation is less common. Although \(Y\) may not appear independent of \(X\) given \(Z\) in the source population, the conclusion could vary significantly in the target population. This discrepancy underscores the need for a robust and flexible testing procedure that can adapt to shifts in distributions.

More specifically, we address the _covariate shift_ scenario, where the distributions of the treatment variables \(X\), the confounding variables \(Z\), and some surrogate or auxiliary variables \(V\) (e.g., SAT scores) may differ between the source and target populations. However, the conditional distribution of \(Y\) given \(X,Z,\) and \(V\) remains the same between them. In such scenarios, our goal is to leverage information from the source to accurately test for conditional independence in the target population without the observation of \(Y\) on target. In the scenario we consider, the presence of \(V\) and potential differences in \(P(V X,Z)\) between the source and target populations may lead to the conditional independence \(X\!\!\! Y Z\) not holding simultaneously in the two populations. Specifically, because

\[P(Y X,Z)= P(Y X,Z,V)P(V X,Z)\,dV,\]

the conditional distribution of \(Y\) given \(X\) and \(Z\) can vary between populations. This underscores why the problem is non-trivial.

See Figure 1 for an example of the consequences of such covariate shift.

In this paper, we propose a novel conditional independence test suitable for covariate shift scenarios. Our method builds upon the Pearson Chi-Squared Conditional Randomization (PCR) test, a powerful model-X testing procedure that effectively addresses a broader range of alternative \(p\)-value distributions than the vanilla CRT . Methodologically, we make two major contributions. First, we introduce importance weights into the label counting steps of the original PCR test, making the new test valid under covariate shift. These weights adjust the importance of each sample according to its density ratio, effectively rebalancing the source data to match the target population's distribution. Second, we introduce a power enhancement method that employs the control variates method to reduce variance in the test statistics. Although importance weights can increase the variance in test statistics, especially when the density ratio can become extremely high, potentially reducing power, our power enhancement method effectively addresses this issue. Together, these innovations enable us to develop a PCR test that is both powerful and valid under covariate shifts.

Figure 1: Type-I Error rates of our proposed csPCR and the source-only PCR on a simulated example. The Type-I error inflation of PCR demonstrates that source analysis is not valid or generalizable on the target due to covariate shift.

The rest of the paper is organized as follows: In Section 2, we provide a formal introduction to the problem setup. In Section 3, we introduce the proposed Covariate Shift Corrected Pearson Chi-squared Conditional Randomization (csPCR) test and establish that the proposed csPCR test controls the Type-I error asymptotically. In Section 4, we demonstrate the empirical performance of the csPCR test through simulation studies. In Section 5, we apply the proposed csPCR test to a real-world dataset to assess the impact of a COVID-19 treatment on the 90-day mortality rate among patients.

### Related Work

Our work builds upon the model-X framework and the conditional randomization test proposed by Candes et al. . The particular method we develop is based on a variant of the vanilla CRT, the Pearson Conditional Randomization (PCR) test . Recent advances in the CRT include improving computation time [7; 10], studying robustness [6; 11], and examining statistical power . The focus of this paper, different from the above, is on how to build a valid CRT procedure when there is covariate shift. The paper is also complementary to the above literature: for example, we hope that future work can conduct theoretical power analysis for our procedure or develop a double robust version of the procedure just like in . Finally, we note that surrogate variables play a crucial role in this paper: because the distribution of the surrogate variables is different in the source and the target population, naively testing the conditional independence hypothesis in the source population can yield invalid conclusions for the target population. A surrogate or silver standard label is a variable that is more feasible and accessible than \(Y\) in data collection and can be viewed as a noisy measure of \(Y\). For example, tumor response rate is often used as an early endpoint surrogate for the long-term survival outcome , and blood pressure is commonly used as a surrogate for heart attacks. Surrogate variables are also commonly used in environmental studies and economics. Surrogate variables also play an important role in the paper by , albeit in a different way, where the surrogate variables are used to learn the distribution of \(Y X,Z\) and to further improve the robustness of the CRT procedure.

Statistical learning and inference under covariate shift has been extensively studied over the past years. As a seminal work in addressing covariate shift bias,  proposed a density ratio weighting approach using kernel mean matching to characterize the adjusting weights. Their key idea of importance (re)weighting is intrinsically connected with early work in broader contexts like importance sampling [15, e.g.] and semiparametric inference [13; e.g.].  extended this idea to a doubly robust framework accommodating surrogate variables like \(V\) and being more robust to the misspecification or poor quality of the density ratio models.  handled a more challenging scenario with severe shift and poor overlap between the source and target populations. Among this track of literature,  is the most closely related to our work as they also considered conditional independence testing under distributional shifts and proposed a general testing procedure base on importance sampling (IS) allowing for the use of CRT. Different from us, their work does not accommodate the covariate shifts of some surrogate or auxiliary \(V\). Moreover, as will be shown in our numerical studies, their general IS testing strategy can encounter the loss of effective sample sizes and be less powerful than ours.

## 2 Problem Setup

### Conditional Independence Testing under Covariate Shift

Let \(Y\) denote the outcome variable, \(X\) the treatment variable, \(Z^{p}\) a vector of confounding variables, and \(V^{d}\) a vector of surrogate variables. To make the problem more concrete, consider the following two examples:

**Example 1** (College Admission).: \(Y\) _is college admission, \(X\) is family income, \(Z\) includes a number of factors such as GPA, extracurricular activities, geographic location, and demographic information, \(V\) is the SAT score. In this case, \(V\) is easier to collect compared to \(Y\) as the college admission requires individual-level surveys._

**Example 2** (Health Outcome).: \(Y\) _is a long-term health outcome, \(X\) is a medical treatment, \(Z\) includes factors such as age, gender, and health history, \(V\) includes surrogate variables like blood pressure, BMI, and duration of hospital stays post the treatment, which can be measured within a much shorter term than \(Y\)._Consider a scenario involving two distinct populations: the source population \(\) and the target population \(\). We collect data from the source population with the goal of making inferences about the target population. The source data contains \(n\) independent and identically distributed samples of \((Y_{i},X_{i},Z_{i},V_{i})\) for \(i=1,,n\). Let \(=(Y_{1},Y_{2},,Y_{n})^{}^{n}\), \(=(X_{1},X_{2},,X_{n})^{}^{n}\), \(=(Z_{1}.,Z_{2}.,,Z_{n}.)^{}^{n p}\), and \(=(V_{1}.,V_{2}.,,V_{n}.)^{}^{n d}\). We are interested in testing the following conditional independence hypothesis in the target population:

\[_{0}:X\!\!\! Y Z.\] (1)

We assume that the conditional distribution of \(Y X,Z,V\) is the same in both populations; however, the distribution of \((X,Z,V)\) varies between \(\) and \(\). More precisely, the joint distribution of \(Y,X,Z,V\) can be described as follows:

\[ P_{}(Y,X,Z,V)&=P_{ }(X,Z,V)P(Y|X,Z,V)&,\\ P_{}(Y,X,Z,V)&=P_{}(X,Z,V)P( Y|X,Z,V)&.\] (2)

This situation is referred to as the _covariate shift_ scenario because the distribution of the covariates \(X\), \(Z\), and \(V\) in the source population \(\) does not match that in the target population \(\).

Let's understand the above assumption and its implications through the two examples above. In the college admissions example, it is plausible to assume that the rate of college admissions remains consistent across the two populations when conditioned on the SAT score, family income, and other confounding variables. However, the joint distribution of \(X,V\) and \(Z\) can differ: in the source population, if wealthy parents frequently invest in SAT preparation, boosting admission rates, this relationship may not hold in a target population where such preparation is uncommon. In such cases, it is thus possible that \(X\!\!\! Y Z\) in the source population but \(X\!\!\! Y Z\) in the target population (see Figure 2 for such an example). In the health outcomes example, it is again plausible that the conditional distribution of long-term health outcomes given the treatment variable, confounding variables, and surrogates remains the same across the two populations. However, the assignment of the treatment may depend differently on the surrogate variables across the two populations. Therefore, it's possible that \(X\!\!\! Y Z\) in one population, but not in the other.

In both examples, we can see that the result of naively applying a valid conditional independence test on the source population cannot guarantee a valid conclusion for testing \(_{0}\) in the target population. Therefore, we need to develop new tools for addressing covariate shifts in conditional independence tests.

### Model-X Framework

In this paper, we operate within the model-X framework, as described by Candes et al. , which assumes that the joint distributions of covariates \(X,V,Z\) are perfectly known in both the source and target populations. This framework is particularly suited for scenarios where: (1) there is substantial prior domain knowledge about the covariates \(X,V,\) and \(Z\), or (2) there is a significant amount of unsupervised data for these covariates in both populations, in addition to \(n\) labeled observations in the source population, characterizing a semi-supervised setting.

An example of the first scenario can be seen in genetics, where researchers have well-established models for the joint distributions of single nucleotide polymorphisms (SNPs). For the second scenario, consider our earlier example involving health outcomes. Here, the outcome variable \(Y\) represents a long-term health outcome that is more costly or sensitive to measure compared to the shorter-term

Figure 2: Direct acyclic graphs illustrating possible differences between the source and the target populations.

variables \(X,V,\) and \(Z\). In such cases, the variables \(X,V,\) and \(Z\) are typically easier and less costly to collect, frequently resulting in a semi-supervised setting in these health-related studies.

## 3 Method: Covariate Shift Corrected PCR Test

### Incorporating the Density Ratio into the PCR Test

In Section 2.1, we discussed how naively applying conditional independence tests to the source data cannot guarantee valid conclusions for the target population. To address this issue, we must incorporate information about the differences between the two populations into our testing procedure. In particular, we will make use of the density ratio defined as:

\[e(X,Z,V)=}(X,Z,V)}{P_{}(X,Z,V)}.\] (3)

This ratio measures the relative likelihood of observing each combination of variables \((X,Z,V)\) in the target population compared to the source population. By reweighting the data points in the source population using this density ratio, we effectively transform the source distribution to match the distribution of the target population, thereby addressing the covariate shift problem.

More specifically, we build our method upon the recently proposed Pearson Chi-Squared Conditional Randomization (PCR) test . Compared to the vanilla CRT, the PCR test is designed to be more powerful across a broader range of alternative \(p\)-value distributions. At a high level, the PCR test assigns a label to each data point following a counterfeit sampling step and a subsequent score computation step. Under the null hypothesis that \(X\!\!\! Y Z\), the distribution of these labels should be uniform across all possible labels. The PCR test then rejects the null hypothesis if the empirical distribution of the labels deviates significantly from uniformity, as determined by a Pearson's chi-squared test.

Under distributional shift, if the data points were sampled from the target population, then the distribution of the labels would be uniform. However, since the data points are actually sampled from the source population, they must be reweighted using the density ratio. More specifically, in the final step of the PCR test, where the Pearson's chi-squared test is applied, we consider not the count of data points for each label, but the sum of the density ratios of the data points for each label instead. Under the null hypothesis, each sum should approximate \(n/L\), where \(L\) is the total number of labels. Consequently, we modify the Pearson's chi-squared test to determine whether these weighted sums deviate significantly from \(n/L\).

Based on the above intuition, we propose the Covariate Shift Corrected PCR (csPCR) Test, as outlined in Algorithm 1.

In Algorithm 1, lines 1-7 correspond to those in the original PCR test. These lines initiate the test by generating counterfeit samples \(_{j}^{(m)}\). Assuming the source and target populations were identical, under the null hypothesis, the random variables \((X_{j},Y_{j},Z_{j}),(_{j}^{(1)},Y_{j},Z_{j}),,(_{j}^{(M)},Y_{j},Z_{j})\) would be exchangeable. Consequently, the rank \(R_{j}\) would be uniformly distributed over \(\{1,,M+1\}\) in the absence of ties, leading to a uniform distribution of the labels as well.

Lines 8-10 in Algorithm 1 address the covariate shift by incorporating density ratios as importance weights into \(W_{j}\). Due to this redefinition of \(W_{}\), the null distribution of the final test statistic \(U_{n,L}\) is also different. Therefore, we also adjust the rejection threshold from the quantile of a chi-squared distribution, as in the original PCR test, to the quantile of the weighted sum of chi-squared distributions.

### Power Enhancement

To effectively address covariate shift, incorporating density ratios as importance weights into the PCR test is essential. However, when these ratios become large, they can increase the variance of the statistics \(W_{l}\). This elevated variance can diminish the test's power. Therefore, developing methods to reduce this variance is crucial for maintaining the power of the test.

To this end, we introduce a control variate function \(a\), allowing \(a(X,Z,V)\) to serve as a control variate in reducing variance in \(W_{l}\). Specifically, for a chosen \(_{}\), we define

\[_{}=_{j=1}^{n}w_{j}[\{_{j} =\}-_{}a(X_{j},Z_{j},V_{j})]+n_{}_{ }[a(X,Z,V)].\] (5)

We can then use \(_{}\) instead of \(W_{}\) in our algorithm.

We note that for any arbitrary choice of the function \(a\) and the parameter \(_{}\), the expectation of \(_{}\) would be the same as that of \(W_{}\):

\[[_{}]& =_{j=1}^{n}[w_{j}\{_{j} =\}]-_{j=1}^{n}_{}[w_{j}a(X_{j},Z_{j},V_{j})]+n_{}_{}[a(X,Z,V) ]\\ &=[W_{}]-n_{}( _{}[e(X,Z,V)a(X,Z,V)]-_{}[a(X,Z,V)])=[W_{}].\] (6)

Therefore, even if we make a sub-optimal choice of the function \(a\) and the parameter \(_{}\) in practice, the resulting test (under certain assumptions) will still remain asymptotically valid (see Section 3.3 for more details).

However, for effective variance reduction, it is preferable to have the control covariates \(a(X,Z,V)\) well-correlated with the outcome (See Section 4 for practical discussions on choices of the function \(a\)). This is quite feasible, especially since the surrogate variable \(V\) is likely to be predictive of \(Y\).

We would also like to discuss the choice of \(_{}\). According to the control covariate literature, with a fixed function \(a\), the optimal choice of \(_{}\) that minimizes variance is given by:

\[_{}=[w_{j}\{_{j}= \},w_{j}a(X_{j},Z_{j},W_{j})]}{[w_{j}a(X_{ j},Z_{j},W_{j})]}.\] (7)

This coefficient is also the same as that obtained from a linear regression . Thus, when implementing the algorithm, we take \(_{}\) to be the regression coefficient obtained by running a weighted linear regression of the indicator function \(\{\{_{j}=\}\}_{j=1}^{n}\) on the control variate \(\{a(X_{j},Z_{j},V_{j})\}_{j=1}^{n}\) with weights \(\{w_{j}\}_{j=1}^{n}\).

We have outlined the new csPCR test, including this power enhancement step, in Algorithm 2.

```
0: Data \(D_{}=(,,,)\), the density ratio \(e\), the test statistics \(T\), the control variate function \(a\), integers \(K,L 1\), and the significance level \(\).
1:for each data point \(j=1\) to \(n\)do
2: Compute the labels \(_{j}\) as in Algorithm 1.
3:endfor
4: Let \(w_{j}=e(X_{j},Z_{j},V_{j})\) for each \(j\{1,2,,n\}\).
5:for each label \(\{1,2,,L\}\):do
6: Compute \(_{}\), the regression coefficient obtained by a weighted linear regression of the indicator function \(\{1\{_{j}=\}\}_{j=1}^{n}\) on the control variate \(\{a(X_{j},Z_{j},V_{j})\}_{j=1}^{n}\) with weights \(\{w_{j}\}_{j=1}^{n}\).
7: Compute the augmented version of \(W_{}\) as \[_{}=_{j=1}^{n}w_{j}[\{_{j}=\}- _{}a(X_{j},Z_{j},V_{j})]+n_{}_ {}[a(X,Z,V)].\]
8:endfor
9: Let \(=(w_{j}[\{_{j}=\}-_{ }a(X_{j},Z_{j},V_{j})]+_{}_{} [a(X,Z,V)])_{,j}\) for \(1 L,\,1 j n\).
10: Calculate the sample covariance matrix \(_{n}=(-_{L  n})(-_{L n})^{}\).
11: Calculate the test statistic \(U_{n,L}\) as follows \(_{n,L}=_{=1}^{L}(_{} -)^{2}.\)
12: Reject the null hypothesis if \(_{n,L}_{_{n,}}\); otherwise, accept the null hypothesis. Here, \(_{_{n,}}\) is the \(1-\) quantile of the distribution \(_{_{n}}^{2}\), where \(A_{}^{2}\) denotes that \(A=x^{}x\) for \(x(0,)\). ```

**Algorithm 2** Covariate Shift Corrected PCR Test with Power Enhancement.

We would also like to discuss the choice of \(_{}\). According to the control covariate literature, with a fixed function \(a\), the optimal choice of \(_{}\) that minimizes variance is given by:

\[_{}=[w_{j}\{_{j}= \},w_{j}a(X_{j},Z_{j},W_{j})]}{[w_{j}a( X_{j},Z_{j},W_{j})]}.\] (8)

This coefficient is also the same as that obtained from a linear regression . Thus, when implementing the algorithm, we take \(_{}\) to be the regression coefficient obtained by running a weighted linear regression of the indicator function \(\{\{_{j}=\}\}_{j=1}^{n}\) on the control variate \(\{a(X_{j},Z_{j},V_{j})\}_{j=1}^{n}\) with weights \(\{w_{j}\}_{j=1}^{n}\).

We have outlined the new csPCR test, including this power enhancement step, in Algorithm 2.

### Theoretical Properties

In this section, we establish that the proposed tests control the type-I error asymptotically. Furthermore, we show that the power enhancement step effectively reduces the variance of the statistics \(W_{}\), which can typically improve the power.

**Assumption 1** (Fourth moment).: _The fourth moment of the density ratio \(e(X,Z,V)\) is finite: \(_{}[e(X,Z,V)^{4}]<\). Furthermore, the fourth moment of product of the density ratio and the control variate function is also finite: \(_{}[e(X,Z,V)^{4}a(X,Z,V)^{4}]<\)._

**Theorem 1** (Valid Tests).: _Under Assumption 1, assume that the null hypothesis of \(X\!\!\! Y Z\) holds in the target population, then_

\[_{n}[] =.\] (9) \[_{n}[] =.\]

**Theorem 2** (Variance Reduction).: _Let \(W_{l}\) be the statistics computed in line 10 in Algorithm 1, and \(_{l}\) be the statistics computed in line 7 in Algorithm 2. Under Assumption 1,_

\[_{n}([_{l}]/ [W_{l}]) 1.\] (10)

## 4 Numerical Simulation

In this section, we present simulation studies to assess the performance of our proposed csPCR method and its power enhancement version denoted csPCR(pe), and compare them to a benchmark method. The benchmark method adopted is an importance-resampling based method , denoted as the IS method. For fair comparison, we used the same PCR statistic as our method for the testing with IS. We use a significance level of \(=0.05\).

### Simulation Setup

We consider a semi-supervised setting where we have a large volume of unlabeled data of \((X_{j},Z_{j},V_{j})\) from both the source and target populations. In addition, we have a small number of labeled data of \((Y_{j},X_{j},Z_{j},V_{j})\) from the source population.

We separate confounding variables \(Z\) into two sets: \(Z=(Z_{},Z_{})\), where \(Z_{}\) is the relevant set and \(Z_{}\) is the null set. The relevant confounding variables \(Z_{}\) are generated as i.i.d. multivariate normal, with mean 0 for the source population and \(1\) for the target population to simulate the distributional shift in \(Z\), where \(Z_{}^{p}\) and we set \(p=5\). Null confounding variables \(Z_{}\) are generated independently with no correlation to other variables, modeled as \((0.1,I_{q})\) with \(q=50\) for sparse high-dimensional settings in both populations.

The treatment variable \(X\) and the surrogate variable \(V\) are conditionally generated based on \(Z\). Specifically, \(X\) is modeled identically across both the source and target populations as \((u^{}Z_{},1)\), where \(u\) is a predefined parameter vector that remains the same for both populations.

For \(V\), it is modeled differently in the two populations, represented as \((v_{/}^{}Z_{}+(1-)a_{ /}X+_{a_{/}}(X),1)\). Here, \(v_{}\) and \(v_{}\) are predefined parameter vectors for the source and target populations, respectively. The parameter \(a\) varies between populations (\(a_{}\) for the source and \(a_{}\) for the target), controlling the effect of \(X\) on \(V\), modeling the indirect effect. The factor \(\) modulates the nonlinear component of this relationship.

The outcome variable \(Y\) is generated for both populations using the same conditional model over \((X,Z,V)\):

\[Y|(X,Z,V)_{/}((v^{}Z_{})^ {2}+ V+ X,1),\]

where \(\) and \(\) control the effects of \(V\) (indirect) and \(X\) (direct) on \(Y\), respectively.

We generate 1000 unlabeled source and target samples to estimate the density ratio and generate 500 labeled source samples for testing. Moreover, in the simulation, we assume we have full knowledge of the joint distribution of \((X,Z)\) and estimate \(V|X,Z\) using an Elastic net regression model with 5-fold cross-validation . For the test statistic \(T\) in the algorithm, we choose a simple function \(T(,Z,V,Y)=Y\). For each parameter iteration, we conduct 1000 Monte Carlo simulations to estimate the Type-I error and power. We estimate the covariance matrix of the sequence of \(W_{i}\)'s using the Monte Carlo method and use the momentchi2 package  for calculating the \(p\)-value. Additionally, we empirically choose the best hyperparameter \(L=3\) for all our experiments through additional experiments shown in Appendix B.2.

### Simulation Results

In Figure 3, we choose \(a_{}=1\) and \(a_{}=0\) to compare the Type-I error control of our methods with the benchmark. The left panel shows the Type-I error rate as the sample size of the data used to estimate the density ratio, \(n_{e}\), varies from small to large. There appears to be a slight Type-I error inflation for all three methods when the sample size \(n_{e}\) is small, but the Type-I error quickly converges to the ideal level of 0.05 as \(n_{e}\) grows larger. Moreover, our methods show more stable Type-I error control than the benchmark method when the estimation sample size is low. The rightpanel shows that when the density ratio is well approximated, all three methods attain good Type-I error control regardless of the change in \(\), i.e., the strength of the indirect effect, but the csPCR and csPCR(pe) methods have more stable control.

To evaluate the statistical power of our csPCR test, we choose \(a_{}=0\) and \(a_{}=2\), so that the null hypothesis holds true in the target population but not in the source population. As Figure 3(a) shows, both the csPCR and the csPCR(pe) methods have uniformly higher power than the benchmark method as we vary the indirect method as the power of 0.33, the csPCR method has a power of 0.44, and the csPCR(pe) method can attain a power of 0.8.

When we fix the indirect effect \(=2\) and vary the direct effect of \(X\) (\(\)), as shown in Figure 3(b), our methods still exceed the benchmark, and the power enhancement significantly improves the original version of the test. For example, when \(=1\), the benchmark IS method has a power of 0.4, the csPCR method has a power of 0.62, and the csPCR(pe) method can attain a power of 0.86.

We also test how adding a nonlinear component to the indirect effect affects the power when we assume a linear model of \(V Z,X\) in the estimation stage. This can be helpful in assessing the performance of our methods under model misspecification. As Figure 3(c) indicates, as the nonlinear effect increases, the power of all three methods decreases, though our methods still significantly exceed the benchmark. Interestingly, we observe that as \( 1\), i.e., there is a full nonlinear component without a linear component, the advantage of the power-enhanced version over the original csPCR test disappears. This occurs because when the \(V X,Z\) model is misspecified and the density ratio estimation is inaccurate, the variance reduction in the control variates step reduces variance in the "wrong" direction, and thus does not improve the power of the original method.

### Effective Sample Size

We notice a series of work in measuring the effective sample size (ESS) of the density ratio reweighting approaches . Among them, one of the most common measure is \(n_{}=(_{i=1}^{}w_{i})^{2}/_{i=1}^{n}w_{i}^{2}\). When the covariate shift between the source and target becomes stronger, the variance of the importance weight \(w_{i}\) tends to be large and \(n_{}\) will become smaller, which could result in lower power. We carry out simulation studies on the relationship between the power of csPCR and the ESS determined by the degree of covariate shift as discussed in Appendix B.3.

## 5 Real-World Application

The COVID-19 pandemic has presented unprecedented challenges to global health systems, with high variability in outcomes based on demographic and clinical characteristics. Early identification of patients at high risk for severe outcomes, such as mortality within 90 days of hospital admission, is crucial for timely and effective treatment interventions. This study leverages extensive hospital data to develop models predicting 90-day mortality following hospital admission due to COVID-19.

Figure 4: Comparison of statistical power of the three methods as the effect size varies: (a) indirect effect \(\), (b) direct effect \(\), and (c) nonlinear effect size \(\).

Figure 3: Comparison of Type-I error control across three methods.

For this study, we extract patient data spanning from January 2020 to December 2023 from Duke University Health System (DUHS), focusing on individuals admitted with COVID-19. This period encompasses multiple waves of the pandemic, influenced by various circulating variants.

Our dataset comprises patient records for a total of \(N=3,057\) individuals admitted with COVID-19. The outcome \(Y\) is defined as mortality within 90 days since hospital admission due to COVID-19. The treatment variable \(X\) is defined as binary, where 1 indicates the administration of any COVID-19 specific medication (explained in Appendix C) and 0 otherwise. The covariates \(Z\) include comorbidity indices (renal disease, diabetes without complication, diabetes with complication, local tumor, and metastatic tumor), age, gender, and race, which are critical for adjusting the risk models due to their known influence on COVID-19 outcomes. The length of hospitalization, denoted as \(V\), is standardized to follow a standard normal distribution (with a mean of zero and a standard deviation of one), facilitating comparisons and integration into predictive models regardless of original scale or distribution.

The dataset is segmented into two distinct groups based on the date of hospital admission to align with pivotal changes in virus strain predominance and public health guidelines. The source data comprises COVID-19 admissions prior to November 30, 2021, with a sample size of \(N_{1}=1,131\) patients. The target data includes admissions from November 30, 2021, through December 2023, totaling \(N_{2}=792\) patients. This temporal division allows for the analysis of trends and outcomes associated with the evolving pandemic landscape. Prevalence of the 90-day mortality outcome within the source data is 14.3%, reflecting the impact of earlier virus strains and treatment protocols, while in the target data, the prevalence is substantially lower at 3.7%, possibly indicating the effect of improved treatments and vaccines, as well as the influence of different virus variants over time.

For the analysis, we divide 50% of the source data, comprising 565 individuals, alongside the entirety of the target data, to estimate the density ratio. Density ratios of \(X,Z\) are estimated using probabilistic classification method , while the density ratio of \(V|X,Z\) is determined through Elastic Net regression. For all three methods, the test statistic \(T\) is chosen to be \(T(,Z,V,Y)=Y\). As indicated in Table 1, both csPCR and csPCR(pe) give statistically significant results, whereas the IS method does not. The statistically significant results are consistent with biomedical literature. For example, through systematic review and meta-analysis,  reported that Bamlanivimab is effective in reducing the mortality rates of COVID patients. In a cohort study,  also found similar effectiveness for Nirmatrelvir-ritonavir.

These results align with our findings from the simulation study and demonstrate that our method has increased power compared with the benchmark IS method.

  
**Method** & **csPCR** & **csPCR(pe)** & **IS** \\  \(p\)-value & \(0.025\) & \(0.032\) & \(0.663\) \\   

Table 1: \(p\)-values of different methods on COVID-19 dataset