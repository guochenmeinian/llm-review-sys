# Interventionally Consistent Surrogates for

Complex Simulation Models

 Joel Dyer

University of Oxford

&Nicholas Bishop

University of Oxford

&Yorgos Felekis

University of Warwick

&Fabio Massimo Zennaro

University of Bergen

&Anisoara Calinescu

University of Oxford

&Theodoros Damoulas

University of Warwick

&Michael Wooldridge

University of Oxford

###### Abstract

Large-scale simulation models of complex socio-technical systems provide decision-makers with high-fidelity testbeds in which policy interventions can be evaluated and _what-if_ scenarios explored. Unfortunately, the high computational cost of such models inhibits their widespread use in policy-making settings. Surrogate models can address these computational limitations, but to do so they must behave consistently with the simulator under interventions of interest. In this paper, we build upon recent developments in causal abstractions to develop a framework for learning interventionally consistent surrogate models for large-scale, complex simulation models. We provide theoretical results showing that our proposed approach induces surrogates to behave consistently with high probability with respect to the simulator across interventions of interest, facilitating rapid experimentation with policy interventions in complex systems. We further demonstrate with empirical studies that conventionally trained surrogates can misjudge the effect of interventions and misguide decision-makers towards suboptimal interventions, while surrogates trained for _interventional_ consistency with our method closely mimic the behaviour of the original simulator under interventions of interest.

## 1 Introduction

Large-scale, complex simulators are powerful tools for modelling distributed socio-technical systems and emergent phenomena across application domains, including the social sciences (Wiese et al., 2024), epidemiology (Kerr et al., 2021), and finance (Cont, 2007). Many such systems consist of a multitude of autonomous, interacting, and decision-making agents, whose individual behaviours and interactions can be captured more readily and at a higher degree of fidelity in a computer program than through conventional modelling paradigms. This level of granularity can, in turn, allow for more effective control of the potentially deleterious effects that can arise from the endogenous dynamics of real-world systems by providing a testbed for experimentation with policy interventions. In economics, for example, such interventions may take the form of limits on loan-to-value ratios in housing markets to attenuate housing price cycles (Baptista et al., 2016), while in epidemiology they may be (non-)pharmaceutical interventions that aim to inhibit disease transmission (Kerr et al., 2021).

Whilst simulation modelling of this kind promises many benefits, the intricacy and multi-scale nature of the simulators that result from these modelling efforts can result in large computational costs evenfor single forward simulations (Jagiella et al., 2017; Fadai et al., 2019; Wright and Davidson, 2020; Heppenstall et al., 2021). Since extensive simulation studies are often required to aid decision-making with these models, such costs present a barrier to their use as synthetic test environments for potential policy interventions in practice. Moreover, the high-fidelity data generated by detailed simulation models can be difficult for decision-makers to interpret and relate to policy interventions that act system-wide (Haldane and Turrell, 2018). This motivates the development of simpler _surrogate_ models that model the underlying system at a higher level of abstraction. Such surrogates can also be used in place of the complex model for downstream tasks where computational resources are limited. In addition, surrogates may be viewed as interpretable explanations for the complex simulator, and they allow for rapid testing of population-wide interventions which may be difficult to implement or test within the orginal model.

However, for surrogates to be useful in downstream tasks involving experimentation with possible policy interventions, they must preserve the complex simulator's dynamics under the external interventions of interest. Without imposing this condition on the constructed surrogate, there is no guarantee that the surrogate will behave similarly under external policy interventions, which in turn may lead policy-makers away from effective policies and towards suboptimal interventions. Existing methods typically apply off-the-shelf machine learning methods to learn surrogates through observation (Lamperti et al., 2018; Platt, 2022), which fails to account for interventional consistency.

Our contribution.To address this, we build on recent developments in _causal abstraction_(Beckers and Halpern, 2019; Zennaro et al., 2023). We view the complex simulator and its surrogate as _structural causal models_(Pearl, 2009), and propose a framework for constructing and learning surrogate models for expensive simulators of complex socio-technical systems that are _interventionally consistent_, in the sense that they (approximately) preserve the behaviour of the simulator under equivalent policy interventions. This perspective enables _treating the surrogate model as a causal abstraction of the simulator_. We motivate our proposed methodology theoretically, and demonstrate with simulation studies that our method permits us to learn an abstracted surrogate model for an epidemiological agent-based model that behaves consistently in multiple interventional regimes.

Our approach establishes, for the first time, a connection between complex simulation models and causal abstraction, and a practical approach to learning interventionally consistent surrogates for complex simulators. Our work provides an avenue for researchers modelling complex socio-technical systems to draw on the rich literature in causality for integrating causal knowledge, evaluating _what-if_ scenarios, and learning new abstracted models with guarantees about interventional consistency. Our contribution lays the groundwork for surrogate modelling methods that facilitate rapid experimentation with different scenarios and interventions, with assurances that the error introduced by experimenting at a higher level of abstraction is low. This line of work has the potential to enable decision- and policy-makers to use simulation models to quickly identify life-saving policy strategies during novel and rapidly unfolding emergencies, such as pandemics and economic crises. Indeed, a recent World Health Organisation report (World Health Organization et al., 2024) emphasises the importance of integrated modelling to concurrently address interdependent policy objectives, such as reducing disease transmission, mitigating hospital admissions overload, and minimising the economic costs of service closures on society during pandemics. It further discusses the intense time pressures involved in these efforts. Our work addresses these points by taking steps towards facilitating rapid experimentation with large and computationally expensive integrated simulation models.

## 2 Background

We first recall the key elements of causal inference, following Pearl (2009), and elucidate the connection between structural causal models (SCMs) and complex simulators. We also review the notion of exact transformations between SCMs, which theoretically motivates our framework.

### Structural causal models

A SCM is a rigorous model describing a causal system:

**Definition 1** (Sms(Pearl, 2009)).: _A structural causal model \(\) is a tuple \(,,,()\) where:_

* \(=\{X_{i}\}_{i=1}^{n}\)_, is a finite set of endogenous random variables_ \(X_{i}\) _each with domain_ \([X_{i}]\)* \(=\{U_{i}\}_{i=1}^{n}\)_, is a finite set of exogenous random variables, each with domain_ \([U_{i}]\) _and each associated with an endogenous variable;_
* \(=\{f_{i}\}_{i=1}^{n}\)_, is a finite set of measurable structural functions, one for each endogenous variable defined as_ \(f_{i}:[PA(X_{i})][U_{i}][X_{i}]\)_, where_ \(PA(X_{i}) X_{i}\)_._
* \(_{}()\) _is a joint probability distribution over the exogenous variables factorizing as_ \(_{i=1}^{n}_{}(U_{i})\)_._

_The model \(\) is associated with a Directed Acyclic Graph (_D4_)_\(_{}=,\) where the set \(\) of vertices is given by \(\) and the set \(\) of edges is given by \(\{(S_{j},X_{i}) S_{j} PA(X_{i})\{U_{i}\}\}_{i=1}^{n}\)._

Definition 1 conforms to the standard definition of a _Markovian \(\)_ (see Appendix A for an explanation of the underlying assumptions). Thanks to the measurability of the structural functions in \(\), the probability distribution \(_{}()\) over the exogenous variables can be pushed forward over the endogenous variables, defining the probability distribution \(_{}()=_{\#}(_{}())\). Joint distributions \(_{}()\) can then be defined for any subset \(\).

External interventions on the system by an experimenter can be represented in an \(\) through changes in the structural functions. Here, we restrict our attention to hard interventions, in which fixed values are assigned to subsets of endogenous variables:

**Definition 2** (Interventions ).: _Given an \(\), \(\), and a set of values \(\) realizing \(\), an intervention \(=(=)\), is an operator that replaces each function \(f_{i}\) associated with \(S_{i}\) with constant \(s_{i}\)._

The intervention \(=(=)\) induces a new _post-intervention_\(\), \(_{}=,,_{}, ()\), identical to the original one, except that in \(_{}\) the functions \(f_{i}\) are replaced with the constants \(s_{i}\). The probability distribution of \(_{}\) is computed as \(_{_{}}()\). Graphically, the intervention \(\) transforms the \(\) of \(\) by removing incoming edges in each variable \(S_{i}\).

We use \(\) to denote a set of feasible interventions on the \(\) that are relevant to a policymaker. Intervention sets are equipped with a natural partial ordering: let \(_{1}=(=)\) and \(_{2}=(=)\); then \(_{1}_{2}\) iff (i) \(\), and (ii) for each \(S_{i}=T_{i}\) it holds \(s_{i}=t_{i}\); informally, \(_{1}\) intervenes on a subset of the variables that \(_{2}\) intervenes on, and it sets the same values as \(_{2}\).

### Complex simulators as structural causal models

Many simulation models of complex systems - such as, for example, agent-based models (ABMs) - can be modelled as a \(\) by expressing its implicit underlying causal structure. Practically, this entails encoding quantities of interest as endogenous variables, deterministic dynamics into structural equations, and factoring sources of randomness into exogenous variables. The following example illustrates how a common \(\) from epidemiology can be cast as a \(\).

**Example 1** (Spatial SIRS \(\)).: _We consider a susceptible-infected-recovered-susceptible (SIRS) epidemic model on an \(L L\) lattice of cells, each of which represents one of \(N=L^{2}\) agents. The state of each agent can be 0, 1, or 2, respectively, indicating that the agent is disease-free and susceptible to infection, infected, or is recovered from a recent injection. The infection status of all agents at discrete time step \(t 0,T\) is written as \(_{t}\{0,1,2\}^{N}\), where \(T\) is the total number of simulated time steps, and \( l,m=\{l,l+1,,m-1,m\}\) for integers \(l m\). The states \(_{t,n}\) of each of the agents \(n 1,N\) are updated synchronously as follows for \(t 0,T-1\):_

* _If_ \(_{t,n}=0\)_, then_ \(_{t+1,n}=1\) _with probability_ \[p_{t,n}(_{t+1})=1-(1-_{t+1})^{_{n^{}_{n}} [_{t,n^{}}=1]}\] (1) _where_ \(_{n}\) _is the von Neumann neighbourhood for cell_ \(n\)_; else remain susceptible._
* _If_ \(_{t,n}=1\)_, then_ \(_{t+1,n}=2\) _with probability_ \(_{t+1}\)_; else remain infected._
* _If_ \(_{t,n}=2\)_, then_ \(_{t+1,n}=0\) _with probability_ \(_{t+1}\)_; else remain recovered._

_In the above, \(_{t}=(_{t},_{t},_{t})^{3}\) are the model parameters determining the transition probabilities between states. While these may vary over time, the simplest case consists of assigning all \(_{t}\) the same vector,_

\[_{t}= t 1,T.\] (2)_The model is initialised by infecting each agent in the model at initial time \(t=0\) with probability \(I_{0}\). The value of \(I_{0}\) for any forward simulation of the model can be chosen by drawing a random variable \(a\) from some distribution on \(\) and setting_

\[I_{0}=a.\] (3)

_With this model in place, lockdowns over some time period \(t_{l}:t_{l}+\) of length \( 0\) can be modelled (crudely) by setting \(_{t_{l}:t_{l}+}=(0,,)\) for \(,\). To express this ABM as an SCM, we define the following:_

**Endogenous variables** _These consist of the variables of interest that may be set by the policymaker: \(I_{0}\), \(\{_{t}\}_{0 t T}\), and \(\{_{t}\}_{1 t T}\)._

**Exogenous variables** _The model as described above is initialised randomly according to \(a\), \(\), and a collection \(_{0}=(_{0,n})_{1 n N}\) of \(N\) random variables distributed as \((0,1)\), the \(n\)th of which helps determine whether agent \(n\) is infected at time \(t=0\). Similarly, further collections \(_{t},t 1,T\) of \((0,1)\) random variables decide how each agent updates their state at each time step. Thus the exogenous variables for the model are \(a\), \(\), and the \(_{t}\) for \(t 0,T\)._

**Structural equations** _Equations 2 and 3, respectively, define the structural equations \(f_{_{t}}\) and \(f_{I_{0}}\) for the endogenous variables \(_{t}\) and \(I_{0}\). The structural equation \(f_{_{0,n}}\) for each \(_{0,n},n 1,N\) can furthermore be written as_

\[_{0,n}=f_{_{0,n}}(_{0,n},I_{0})=[ _{0,n}<I_{0}].\] (4)

_Finally, update rules (**U1**)-(**U3**) can be written in the following way for \(t 0,T-1\):_

\[_{t+1,n} =f_{_{t+1,n}}(_{t+1,}_{t+1,n}, _{t,n})\] \[=[_{t,n}=0][ _{t+1,n}<p_{t,n}(_{t+1})]+[_{t, n}=1](1+[_{t+1,n}<_{t+1}])\] \[+2[_{t,n}=2] (1-[_{t+1,n}<_{t+1}]),\] (5)

**Distribution over exogenous variables** _The (random) behaviour of the exogenous variables is fully specified by the distribution over \(a\) and \(\), along with \((0,1)\) distributions over the \(_{t,n}\)._

**The underlying graph** _The DAG corresponding to this SCM is shown in Figure 1 for \(T=3\)._

_In this model, interventions in the form of, for example, lockdowns can be (crudely) modelled by intervening on one or more of the \(_{t}\) as \((_{t}=(0,,))\) for some \(,\), while in the observational regime the \(_{t}\) will all be assigned the same value._

We emphasise that the above example is intended only to illustrate that complex simulators, such as ABMs, can be seen as SCMs; explicitly representing a given simulator as an SCM as in the example above is not required in the sequel.

### Causal abstractions

Beside expressing interventions more rigorously, viewing complex simulation models as SCMs allows one to take advantage of the theory of _causal abstraction_ to formalise the relationship between the simulator and its surrogate model. Indeed, causal abstraction provides a framework for relating SCMs representing an identical system at different levels of granularity. The notion of exact transformation formalizes this relation, providing a framework to relate complex models, such as ABMs, to simpler top-down models, while preserving causal structure.

**Definition 3** (\(\)-\(\) Exact Transformation (Rubenstein et al., 2017)).: _Given two SCMs, \(\) and \(^{}\), with respective intervention sets \(\) and \(^{}\), a \(\)-\(\) transformation is a pair \((,)\) consisting of a

Figure 1: The directed acyclic graph induced by the structural causal model for the spatial SIRS agent-based model for \(T=3\) time steps.

map \(:[][^{}]\) and a surjective, order-preserving map \(:^{}\). An exact \(\)-\(\) transformation is a \(\)-\(\) transformation such that_

\[_{\#}(_{_{}})=_{^{}_{ ()}},.\] (6)

An exact \(\)-\(\) transformation constitutes a form of abstraction between probabilistic causal models (Beckers et al., 2020) with the guarantee of commutativity between intervention and transformation as detailed in Figure 2: intervening via \(\) and then abstracting produces the same result as abstracting first and then intervening via \(()\). The map \(\) describes corresponding states in each of the models, while the map \(\) describes corresponding interventions in each model. Whenever the map \(\) is clear from context, we herein shorthand the pushforward measure \(_{\#}(_{_{}})\) as \(_{_{}}^{\#}\).

An exact \(\)-\(\) transformation between the SCM\(\) underlying a complex simulation model and the SCM\(^{}\) underlying the candidate surrogate model would (a) certify that the surrogate preserves the causal behaviour of interest, guaranteeing interventional consistency when policy-makers study interventions through the surrogate, and (b) allow to interpret the emergent causal structure of the simulator through \(^{}\).

## 3 Abstraction error

It is often unrealistic to assume that an exact \(\)-\(\) transformation exists between a complex simulator and its surrogate A more pragmatic goal is to find an approximate abstraction (Beckers et al., 2020) from the simulator to the surrogate. We therefore define the _abstraction error_:

**Definition 4** (Abstraction error).: _Let \((,)\) be a \(\)-\(\) transformation between two SCMs\(\) and \(^{}\) with respective intervention sets \(\) and \(^{}\). Given a statistical divergence \(d\) between distributions, and a distribution \(\) over the intervention set \(\), we define the abstraction error as follows:_

\[d_{,}(,^{})=_{} [d(_{\#}(_{_{}}),\,_{ ^{}_{()}})].\] (7)

_A \(\)-\(\) transformation is \(\)-approximate for some \(_{ 0}\) if \(d_{,}(,^{})\)._

A \(\)-\(\) abstraction with low abstraction error implies that \(_{\#}(_{_{}})\) is close to \(_{^{}_{()}}\) in expectation with respect to the interventional distribution \(\). If the \(d(_{\#}(_{_{}}),\,_{^{ }_{()}})\) is zero for all interventions \(\), then \((,)\) is an exact transformation (see Figure 3).

Definition 4 differs from previously defined notions of abstraction error in the causal abstraction literature. Whilst Beckers et al. (2020) employ a maximum over interventions, we instead take an expectation over a fixed interventional distribution \(\). This is motivated by the fact that policymakers will often hold preferences over possible interventions, which may, for example, reflect the cost or feasibility of implementing each intervention in the real world. Through the specification of \(\), one may implicitly favour surrogates which perform well with respect to interventions of high interest. Further discussion is provided in Appendix B.

## 4 Method

The definitions of abstraction and abstraction error provide us with a framework for learning surrogates, and, in the remainder, we assume that the base model \(\) is implicitly represented by a simulation model of a complex socio-technical system. Our goal is then to identify a surrogate model which is interventionally consistent with this simulator. Specifically, from a set of candidate surrogate models \(\), we seek a surrogate and a \(\)-\(\) transformation that minimises the abstraction error.

To proceed, we assume that \(\) is a parameterised family \(^{}:=\{^{}\,:\,\}\) of differentiable surrogate simulators with tractable probability mass or density function \(q^{}\). Here, \(^{}\) denotes the causal model induced by a surrogate whose structural equations are parameterised by \(\), and \(\) denotes the set of feasible parameter values. Such a family of surrogate models can be constructed through a composition of differential equation- or deep learning-based modelling, in combination with probability distributions with reparameterisable sampling procedures; an example is a latent neural ordinary differential equation model (Rubanova et al., 2019), which we use in the experiments in Section 5. We further assume only the ability to sample from \(_{\#}(_{})\), amounting to running the simulator and applying \(\) to the output.

Generally speaking, policymakers know what macroscopic quantities are of interest when modelling a complex system, and how to aggregate the microscopic variables into global statistics. For example, in macroeconomic settings, policymakers will often be concerned with aggregate quantities such as unemployment rates or aggregate demand, which can be derived from the state of the agents. Further specific examples are discussed in Appendix C.1. We thus assume that the map \(\), which defines the aggregate, emergent quantities of interest to the policymaker, is pre-specified.

Hence, to find an appropriate \(\)-\(\) transformation, we need only to identify an intervention map \(^{}\) between \(\) and \(^{}\). For computational tractability, we select \(^{}\) from a parameterised family \(^{}:=\{^{}\,:\,\}\) with parameters \(\) ranging over the set \(\). For example, \(\) may be the weights of a neural network. We then select \(^{}\) and \(^{}\) jointly by minimising \(d_{,}(,^{})\) over \(^{}^{}\). Since each element of \(\) has a differentiable and tractable distribution, a convenient choice of discrepancy \(d\) is the Kullback-Leibler (KL) divergence, such that out problem becomes:

\[^{},^{}=*{arg\,min}_{,}d_ {,^{}}(,^{}) d_{ ,^{}}(,^{})=_{}_{_{_{}}^{\#}}[_ {_{}}^{\#}}{_{_{^{} ()}^{}}}].\] (8)

The KL divergence can be minimised using Monte Carlo estimates of the gradient

\[G(,)=_{,}\,d_{,^{}}(,^{})_{b=1}^{B}-_{,} q_{ ^{}(^{(b)})}^{}(^{(b)})\] (9)

where \(^{(b)}\), \(^{(b)}_{\#}(_{_{^{(b)}}})\), \(q_{^{}()}^{}\) is the probability mass/density function for \(_{^{}()}^{}\), and \(B 1\) is the size of a batch drawn from \(R B\) training examples from the joint distribution over the \(^{(b)}\) and \(^{(b)}\). Once \((^{},^{})\) has been selected, we may generate data from the macromodel for ABM intervention \(\) by sampling from \(_{_{^{^{}()}}^{^{}}}\). Algorithm 1 summarises the training procedure.

```
0: Budget \(R\); batch size \(B 1,R-1\); \(\); intervention distribution \(\); \(^{}\); abstraction map \(^{}\) Result: Trained surrogate and abstraction map \(,^{}\) and \(^{}\)  Set \(=\); for\(r=1\)to\(R\)do  Sample \(^{(r)}\), \(^{(r)}_{_{^{(r)}}}\); \((^{(r)},(^{(r)}))\)  end for while not convergeddo  Sample minibatch \(\{(^{(b)},(^{(b)}))\}_{b=1}^{B}\)  uniformly from \(\);  Take gradient step in \(,\) using Equation 9  end for ```

**Algorithm 1**Summary of the training procedure.

function: minimising Equation 8 induces \(\) and \(\) to produce a surrogate that behaves the same way as the simulator under interventions of interest.

Definition 4 employs an expectation over an interventional distribution \(\). As a result, even when the abstraction error is low, there may still be a large discrepancy between \(_{\#}(_{_{}})\) and \(_{^{}_{()}}\) for some fixed intervention \(\). Proposition 2 provides an upper bound on the error associated with any intervention sampled from \(\) when \(d\) is the KL divergence and the simulator state space is finite:

**Proposition 2**.: _Let \(d\) be the KL divergence and \(_{}=_{_{\#}(_{_{}})}[- q_{()}( )]\) denote the cross-entropy of \(_{^{}_{()}}\) with respect to \(_{\#}(_{_{}})\). Assume \([]\) is finite. Then for all \(>0\),_

\[_{}(d(_{\#}(_{_{}}),\, _{^{}_{()}})) _{}[_{}]}{ }.\]

The proof is in Appendix D.2. This shows that it is only with low probability that the effects of individual interventions are captured poorly by the surrogate when the surrogate and abstraction map parameters, \(\) and \(\), are found by minimising Equation 8.

## 5 Case study

Here, we outline a case study2 in which we learn interventionally consistent surrogates for the spatial SIRSABM from Example 1, allowing us to experiment more rapidly with policy interventions while remaining confident that the causal behaviour of the original SIRSABM is approximately preserved. Further experimental details and results are given in Appendix E. We consider three families of surrogate models with endogenous variables \(_{0}\), \(}_{t}^{3}_{ 0}\) for \(t 1,T\), and \(}_{t}\{(a,b,c) a,b,c 0,N,a+b+c=N\}\) for \(t 0,T\), where \(a,b,c\) denote, respectively, the number of susceptible, infected, and recovered individuals in the population. The DAGs underlying the SCMs of each of these families are as in Figure 4, and the three families differ only in the form of the structural equations mapping from \(_{0}\) and \(}_{0:t}\) to the \(}_{t}\). Throughout, we let \(q^{}\) be a Multinomial emission distribution and \(\) be trainable parameters of these structural equations.

**Surrogate family 1**: consists of a latent ODE (LODE) built by feeding the classical SIRS ODE's three state variables (which take values in the two-simplex) in as the class probabilities of \(q^{}\). Here, \(=\).

**Surrogate family 2**: consists of a latent ODE-RNN (LODE-RNN), where we run a recurrent network (RNN) with parameters \(\) over the output of the SIRS ODE. The RNN outputs the class logits of \(q^{}\).

**Surrogate family 3**: consists of a latent RNN (LRNN) constructed by running an RNN with trainable parameters \(\) over the \(}_{t}\), and the output of the RNN at each \(t 0,T\) indexes the class logits of \(q^{}\).

Given \(}_{1:T},_{0}\), these surrogates enjoy tractable likelihood functions, which factorise as \(q^{}(}_{0:T}}_{1:T}, {I}_{0})=q^{}(}_{0}_{0})_{t=1}^{T}q^{ }(}_{t}}_{1:t},_ {0})\).

**Interventions & the \(\)-\(\) transformation.** Denoting

\[_{,a} =(_{1:T}=,I_{0}=a ),\] (10) \[_{,a,t_{t}} =(_{1:t-1}=_{t+6:T}=,_{t_{t}:t_{t}+5}=(0,1,1 ),I_{0}=a),\]

we define two subsets \(=_{}_{}\) of interventions for the ABM:

\[_{}=\{_{,a}(,a)^{ 4}\}_{}=\{_{,a,t_{t}}(,a,t_{t})^{4} 5,10\}.\] (11)

Figure 4: The DAG induced by the SCMs corresponding to the surrogate families for \(T=3\).

The first of these is a subset of interventions that fix the initial proportion of infected individuals in the ABM, as well as its parameter values. The second subset of interventions is the set of interventions that fix (a) the initial proportion of infected individuals in the ABM, (b) the values of the ABM's parameters before, during, and beyond a lockdown beginning at time \(t_{l}[\!\!]\) with duration equal to 5 time steps, and (c) the value of \(t_{l}\). Similarly defining

\[^{}_{},} =(}_{1:T}=}, _{0}=),\] (12) \[^{}_{},,_{l}} =(}_{1:_{l}-1}=}_{_{l}+6:T}=},}_{ {t}_{l};_{l}+5}=}(0,1,1),=}, _{0}=),\]

we define \(^{}=^{}_{}^{ }_{}\) for the surrogates, where, letting \(=_{ 0}^{3}\), we have

\[^{}_{}=\{^{}_{},}(},)\} ^{}_{}=\{^{}_{ },,_{l}}(},, _{l})[\!\!]\}.\] (13)

The map \(\) is taken to map: \(_{t}\) identically to \(}_{t}\) for each \(t[\![1,T]\!]\); the microstate \(_{t}\) of the ABM at each time step to the \(}_{t}\) through an aggregation map that counts the number of agents in \(_{t}\) in each of the three states (susceptible, infectious, and recovered); and the initial proportion \(I_{0}\) of infected agents in the ABM identically to \(_{0}\). Further, for a neural network \(f^{}:^{3}_{ 0}^{3}\), we take

\[^{}:_{,a}^{}_{f^{}( ),a},_{,a,t_{l}}^{}_{f^{ }(),a,t_{l}}.\] (14)

The benefits of training for interventional consistencyWe use Algorithm 1 to jointly learn the parameters \(,\) of the surrogates and the map \(^{}\) described above in two different ways: training the surrogate models with \(\) taken to be a uniform distribution \((_{})\) over \(_{}\), which entails comparing the behaviour of the surrogate and ABM without lockdowns at different parameters; and training with \(\) instead taken to be a uniform distribution \(()\) over \(\), which entails comparing the behaviour of the surrogate and ABM under different lockdowns, or no lockdowns at all, at different parameters. We indicate the two approaches to training the surrogates with, respectively, bold uppercase \(\) and \(\). Appendix E details the training procedure and network architectures. We assess the interventional consistency of the surrogates trained in these two ways by computing error metrics on a hold-out test dataset \(^{}=\{(^{(r^{})},_{0:T}^{(r^{})})\}_ {r^{}=1}^{R^{}}\) of size \(R^{}=1000\), generated as \(^{(r^{})}=()\), \(_{0:T}^{(r^{})}_{\#}(_{_{(r^ {})}})\). Specifically, we inspect the average mean squared error (AMSE) between trajectories from the trained surrogates and \(_{0:T}^{(r^{})}\), and the average negative log-likelihood (ANLL) of this test data under the likelihood of the learned surrogates. Observational consistency is checked on a different hold-out test set \(^{}\), generated by instead taking \(=(_{})\).

Table 1 shows these performance metrics evaluated on \(^{}\) and \(^{}\) for all surrogate families and training schemes. We observe that far lower values of the error metrics are obtained by the interventionally, rather than observationally, trained surrogates when assessing interventional consistency. This suggests that training on interventional data can result in more accurate predictions about the effect of interventions in the ABM, and that data drawn from the relevant interventional distributions associated with the ABM should be included during training if the policy-maker intends to perform policy experiments with the surrogate. We also report a minor drop in observational consistency when training with data from the combined intervention set \(\) instead of \(_{}\), which can be explained by the overfit of the observationally-trained model on the observational distribution. We also observe

  
**Test** &  **Model** \\ **Train** \\  &  **LRNN** \\ **I** \\  &  **LODE-RNN** \\ **O** \\  &  **LODE** \\ **I** \\  &  **O** \\  & 
 **LODE** \\ **O** \\  \\  ^{}\)} & AMSE (\( 10^{-1}\)) & \(_{}^{}\) & \(49.45_{}^{}\) & \(_{}^{}\) & \(18.52_{}^{}\) & \(_{}^{}\) & \(22.42_{}^{}\) \\  & ANLL (\( 10^{3}\)) & \(_{}^{}\) & \(21.82_{}^{}\) & \(_{}^{}\) & \(8.40_{}^{}\) & \(_{}^{}\) & \(10.0_{=7\), while in the left (resp. right) panel we show corresponding trajectories from the interventionally (resp. observationally) trained surrogates under the equivalent intervention learned through our training procedure. While the interventionally trained LODE-RNN correctly predicts that the lockdown effectively impedes the spread of the disease in the ABM, the observationally trained surrogate predicts that the lockdown will temporarily _increase_ infections, before approximately reverting to the behaviour of the model without a lockdown.

The use of such a surrogate model in policy experiments when limited computational resources do not permit use of the accurate, high-fidelity ABM of the underlying complex system may therefore have misdirected policy-makers towards suboptimal, and away from effective, interventions. Indeed, while the SIRS ABM predicts that any lockdown is better than no lockdown at all for reducing the number of infections occurring over the simulated time horizon, we see that the observationally trained surrogates often do not predict that no lockdown is the worst intervention in this respect, and in some cases mistakenly predict that no lockdown is the _best_ intervention. For example, the observational LRNN predicts that no lockdown was the best intervention in 1 of 5 training repeats, and was not the worst option in all 5 of 5 training repeats. In contrast, none of the interventionally trained surrogates predict that no lockdown is the best intervention, and only the interventional LODE model predicts that no lockdown is not the worst option (in only 2 out of 5 training repeats). This highlights the potential importance of training surrogate models for interventional consistency when their purpose is to help inform downstream decision-making tasks. Furthermore, this suggests that a possible benchmark criterion in further research on interventional surrogates could be the degree to which different surrogates preserve the ordering of interventions with respect to those downstream tasks of interest.

## 6 Related work

Surrogates are often used to expedite simulation-based inference when modelling complex systems (Heppenstall et al., 2021). Modern approaches rely on established machine learning methods such as random forests (Lamperti et al., 2018; De Leeuw et al., 2023), artificial neural networks (Anirudh et al., 2022; De Leeuw et al., 2023), support vector machines (ten Broeke et al., 2021), kriging (Salle and Yilduzoglu, 2014), and mixture density networks (MDNs) (Platt, 2022). Our experiments also rely on established machine learning methods to construct surrogates; for example, our LRNN surrogate family resembles that of Platt (2022), in which MDNs are used to approximate an ABM's transition density. However, in such works, the _causal/interventional_ consistency of the surrogate with respect to the simulator and policy interventions of interest is not considered. In contrast to prior work, our work explicitly details the causal relation between the surrogate and the underlying simulator via

Figure 5: Example trajectories from the ABM (middle) and the LODE-RNN trained interventionally (left) and observationally (right). A lockdown is imposed at the dashed vertical line. Solid (resp. dot-dash) lines show trajectories under (resp. without) the lockdown. The transmission-inhibiting effect of the lockdown is vastly underestimated in the observationally trained surrogate, while the interventionally trained surrogate accurately predicts a reduction in disease transmission.

causal abstraction, which broadens the scope of surrogate modelling beyond its current use case of expediting calibration to also enable the use of surrogates for policy experimentation.

Causal abstraction and exact transformations were introduced by Rubenstein et al. (2017). Beckers and Halpern (2019) extended this work by proposing stricter definitions of causal abstraction, and in Beckers et al. (2020), where approximate abstractions are introduced to account for uncertainty and simplification. Causal abstraction found practical application in Geiger et al. (2021) for learning interpretable neural networks. Rischel and Weichwald (2021) discusses an alternative category-theoretical definition of abstraction; this was used to learn abstractions to transfer data between models at different levels of abstraction in Zennaro et al. (2023). Further related work includes a multi-marginal Optimal Transport solution to the abstraction learning problem (Felekis et al., 2024), as well as constructive abstraction learning in neural causal models (Xia et al., 2023) and cluster DAGs (Anand et al., 2023). However, none of these approaches reduce the state space of the SCM or the cost of simulation, as our approach does.

## 7 Conclusion

We propose a rigorous framework for learning interventionally consistent surrogates for complex simulation models, formalised with casual abstraction. This is the first application of causal abstraction to surrogate modelling. Our approach applies to any simulator corresponding to any DAG, and does not require explicit knowledge of the simulator's SCM. Through experiments, we highlight the efficacy of our method against purely observational surrogates that do not learn to match interventional data under equivalent interventions. Using our framework, policy-makers may be able to more rapidly draw insights from complex simulators about the possible effects of interventions - in our experiments, our surrogates simulate approximately three times faster than the original complex simulators - and swiftly prepare effective responses to future crises.

Our work naturally suffers limitations. Investigating the sample complexity of abstraction learning would be desirable in future work. Our definition of abstraction error involves an expectation over interventions rather than a maximum as in Beckers et al. (2020); this produces a computationally tractable optimisation problem, but introduces the possibility that one or more interventions is captured poorly by the learned abstraction map, even for a low abstraction error. In our experiments, we have assumed surrogate models with tractable and differentiable density functions, permitting us to use a KL divergence within our definition of abstraction error; future work might extend our approach by considering different surrogate families with these properties, such as families based on normalising flows (Tabak and Vanden-Eijnden, 2010), or alternative divergences that relax the requirement for tractable densities, such as maximum mean discrepancies (Gretton et al., 2012). Finally, our method does not directly exploit knowledge of the simulators' causal graphs to accelerate abstraction learning. It is possible that exploiting access to the base SCM/DAG may expedite abstraction by allowing us to focus on minimal intervention sets (Aglietti et al., 2020; Lee and Bareinboim, 2018), or leverage the identifiability of interventional distributions to reduce the number of simulations required from the base model (Lattimore et al., 2016; Bilodeau et al., 2022). However, it is unclear whether or not applying the do-calculus on large causal graphs is more efficient than simulating interventions directly. The "black-box" nature of our approach may be beneficial for this reason, and since it does not require the modeller to explicitly write their simulator as an SCM, making it generically applicable.

JD, NB, AC, and MW acknowledge funding from a UKRI AI World Leading Researcher Fellowship awarded to Wooldridge (grant EP/W002949/1). MW and AC also acknowledge funding from Trustworthy AI - Integrating Learning, Optimisation and Reasoning (TAILOR), a project funded by European Union Horizon2020 research and innovation program under Grant Agreement 952215. YF: This scientific paper was supported by the Onassis Foundation - Scholarship ID: F ZR 063-1/2021-2022. TD acknowledges support from a UKRI Turing AI Acceleration Fellowship [EP/V02678X/1].