# Learning Cortico-Muscular Dependence through Orthonormal Decomposition of Density Ratios

Shihan Ma\({}^{1}\) Bo Hu\({}^{2}\) Tianyu Jia\({}^{1}\) Alexander Kenneth Clarke\({}^{1}\)

**Blanka Zicher\({}^{1}\) Arnault H. Caillet\({}^{1}\) Dario Farina\({}^{1}\) Jose C. Principe\({}^{2}\)**

\({}^{}\)_Equal Contribution_

\({}^{1}\)Department of Bioengineering, Imperial College London

\({}^{2}\)Department of Electrical and Computer Engineering, University of Florida

###### Abstract

The cortico-spinal neural pathway is fundamental for motor control and movement execution, and in humans it is typically studied using concurrent electroencephalography (EEG) and electromyography (EMG) recordings. However, current approaches for capturing high-level and contextual connectivity between these recordings have important limitations. Here, we present a novel application of statistical dependence estimators based on orthonormal decomposition of density ratios to model the relationship between cortical and muscle oscillations. Our method extends from traditional scalar-valued measures by learning eigenvalues, eigenfunctions, and projection spaces of density ratios from realizations of the signal, addressing the interpretability, scalability, and local temporal dependence of cortico-muscular connectivity. We experimentally demonstrate that eigenfunctions learned from cortico-muscular connectivity can accurately classify movements and subjects. Moreover, they reveal channel and temporal dependencies that confirm the activation of specific EEG channels during movement. Our code is available at https://github.com/bohu615/corticomuscular-eigen-encoder.

## 1 Introduction

The brain communicates with muscles by sending information to the spinal cord. Part of this information is directly transmitted from the cortex to spinal motor neurons via the cortico-spinal neural pathway, which is vital for motor control and movement execution. Because motor neurons are directly connected to muscles, cortical oscillations traveling through the cortico-spinal pathway are coherent with oscillations in muscle electrical activities, both in humans and non-human primates . This relationship, known as functional cortico-muscular connectivity, is critical in neuroscience and is typically studied using concurrent recordings of neural signals such as electroencephalography (EEG) and electromyography (EMG)  (Fig. 1). Practical applications include diagnosing and monitoring of neuromuscular disorders, such as amyotrophic lateral sclerosis , stroke , and Parkinson's disease , as well as developing brain-computer interfaces (BCIs) for individuals with motor impairments .

Figure 1: The cortico-muscular pathway allows brain-muscle communication with coherent cortical and peripheral oscillations. This paper models this connectivity through the statistical dependence between their concurrent recordings of EEG and EMG.

Despite several applications, there is still a lack of proper statistical tools to model the relationship between EEG and EMG. The predominant method, Cortico-Muscular Coherence (CMC), measures temporal and spectral coherence by computing the normalized cross-spectrum in time intervals . From this analysis, it is generally accepted that the EEG's beta band (13-30 Hz) is linked to steady motor control, while the gamma band (>30 Hz) is associated to motor planning and execution [11; 12; 5; 13].

While CMC provides some relevant information on cortico-muscular connectivity, there remains a lack of generalized and higher-order statistical measures that quantify nonlinear and high-level connectivity. Can high-level contextual information, such as muscle movements and participant identifiers, be directly learned from modeling cortico-muscular connectivity? Our paper explores the potential of using statistical dependence estimators to address this problem.

Statistical dependence estimators typically follow a procedure of defining a measure preferably by probabilistic distributions, deriving a variational bound, and optimizing a variational cost of this bound using a function approximator, such as mutual information estimators [14; 15; 16] and Kernel Independent Component Analysis (KICA) [17; 18]. These measures are defined for realizations.

However, statistical dependence estimators above have rarely been successfully applied to cortico-muscular analysis, mainly due to three reasons: instability and poor scalability, lack of spatio-temporal resolution, and lack of practical contextual connections. As these estimators typically quantify dependence at the trial level, they overlook the importance of channel and temporal dependence in cortico-muscular analysis. More importantly, these measures only produce a scalar-valued score, but how this score should be used and its connection to the desired contextual factors are unclear.

This paper successfully applies statistical dependence estimators to EEG-EMG pairs using the concept of _orthonormal decomposition of the density ratio_. Recently, there has been a shift from scalar-valued measures to decomposing density ratio as a positive definite function, and learning its eigenvalues, eigenfunctions, and associated projection spaces through neural network optimization with matrix cost functions such as \(\) and nuclear norm [19; 20; 21]. This decomposition, known as the Functional Maximal Correlation Algorithm (FMCA), addresses the fundamental issue of relating dependence to contextual information: Eigenvalues define a multivariate dependence measure, and eigenfunctions span a feature projection space that captures the contextual factors affecting dependence.

This paper expands on this idea, addressing interpretability, scalability, and local-level dependence that are missing in existing dependence analyses. Sec. 2.1 explains why eigenfunctions, learned from cortico-muscular connectivity, can capture contextual factors for motor control and participant identification. Sec. 2.2 introduces FMCA-T, optimizing a new matrix trace cost for the theory, which demonstrates greater efficiency and stability than the \(\) cost. Sec. 2.3 shows that while the objective estimates global dependence from trial realizations, localized channel-level and temporal-level dependencies can also be formed in a top-down manner, which are important in EEG as they indicate channel activations and synchronization of activities. Our framework is illustrated in Fig. 2.

Our main experiment demonstrates that the learned eigenfunctions, without labels, effectively capture factors such as movements and subjects that contribute to high-level cortico-muscular connectivity. After training, using EEG's eigenfunction as a feature projector noticeably improves classification accuracy over various baselines. Additionally, channel-level and temporal-level dependencies indicate that specific EEG channels are selectively activated during movements, corroborating neuroscientific findings. Simulated data further confirm that our proposed measure is invariant to nonstationary noise, including pink noise and random delays.

## 2 Methods

### Density ratio decomposition for EEG-EMG signal pairs

**Problem formulation.** Consider EEG signals \(:=_{1:T}\) and EMG signals \(:=_{1:T}\). Denote \(\) as the subject, \(\) as the type of movement, and \(\) as other auxiliary contextual factors. These are factors that could potentially affect the statistical dependence between EEG and EMG signals. Each signal is conditioned on these parameters. Denote these factors as \(:=\{,,\}\) with distribution \(()\). Distributions for EEG and EMG given these conditions are \(p(=X|z)\) and \(p(=Y|z)\), respectively. Their joint distribution is given by \(p(X,Y)= p(X|z)p(Y|z)p(z)dz\). Similarly, the marginal distributions are given by \(p(X)= p(X|z)p(z)dz\), and likewise \(p(Y)= p(Y|z)p(z)dz\)Our goal is to extract factors \(\), \(\), \(\) that affect the dependence between two modalities, from available sample pairs of \(\) and \(\), even when \(\), \(\), and \(\) are not given. We propose that this can be achieved by decomposing the density ratio of this probabilistic system.

**Decomposition of EEG and EMG density ratios.** Following the work on FMCA, we propose an orthonormal decomposition of the density ratio to measure the dependence between EEG and EMG:

\[:==_{k=1}^{} }\,_{k}(X)_{k}(Y),\\ _{}_{i}(X)_{j}(X)\,d(X)= 1,&i=j\\ 0,&i j,_{}_{i}(Y)_{j}(Y)\,d (Y)=1,&i=j\\ 0,&i j,\] (1)

for any \(i,j=1,2,\) The density ratio \((X,Y)\) is treated as a positive definite function associated with a linear operator \(f:=(X,)f(X)\,dX\) for any measurable scalar function \(f\). According to Mercer's theorem, this operator has a spectral decomposition with eigenvalues \(_{1},_{2},\), and orthonormal basis functions \(_{1},_{2},\) and \(_{1},_{2},\). In scenarios where \(\) and \(\) are statistically independent, all eigenvalues are zero. Conversely, larger eigenvalues suggest stronger dependence.

Such eigenfunctions form a linear span. Our hypothesis is that this span captures shared contextual factors such as \(\) and \(\) across two modalities, stated as follows.

**Lemma 1**.: _Assuming conditional independence given \(:=\{,,\}\), we have \(p(X,Y|z)=p(X|z)p(Y|z)\). Hence, the ratio \((X,Y):=\) decomposes as \((X,Y)=  p(z)dz\). Assuming \(\) is discrete (e.g., movement patterns \(\) and participant identities \(\)), the information of \(\) is contained in the span of the basis functions for the density ratio \((X,Y)\)._

Proof.: Define the ratios \(_{X}(X,z)=\) and \(_{Y}(Y,z)=\). Considering the sample space \(\), the sets \(_{X}(X,z)\) and \(_{Y}(Y,z)\) for \(z\) are discrete. Under the conditional independence assumption, these ratios satisfy \((X,Y)=_{z}p(z)_{X}(X,z)_{Y}(Y,z)\).

This indicates that the sets \(_{X}(X,z)\) and \(_{Y}(Y,z)\) decompose \((X,Y)\), similar to the eigenfunctions \(_{k}\) and \(_{k}\). Since both decompositions represent \((X,Y)\), the functions \(_{X}(X,z)\) and \(_{Y}(Y,z)\) must lie within the span of these basis functions. Hence, there exist coefficients \(_{z,k}\) and \(_{z,k}\) such that \(_{X}(X,z)=_{k}_{z,k}_{k}(X)\) and \(_{Y}(Y,z)=_{k}_{z,k}_{k}(Y)\) for each \(z\). Thus, learning the

Figure 2: Diagram for learning cortico-muscular dependence by decomposing density ratios: (a) Network \(_{}\) is applied to EEG \(_{1:T}\) and \(_{}\) to EMG \(_{1:T}\) to minimize a matrix trace cost. (b) EEG-EMG pairs are sampled from a joint distribution, from which a density ratio \((X,Y)\) is defined and considered a positive definite function. Its linear operator has a spectral decomposition of eigenfunctions \(\{,\}\) and eigenvalues \(\{_{k}\}\). The networks provably approximate the dominant eigenvalues and eigenfunctions of this decomposition with network outputs \(\{_{},_{}}\}\), and SVD results \(\{_{k}\}\). Eigenvalues here measure multivariate statistical dependence; eigenfunctions are optimal feature projectors. (c) After training, the eigenfunctions, specifically those from EEG, form a projection space containing contextual information for motor control and participant identification. (d) To provide channel activation and activity synchronization for cortico-muscular analysis, we compute density ratios between channel-level \(_{c}\) and temporal-level features \(_{c,s}\) against global features \(_{F}\) to quantify channel-level and temporal-level dependencies.

dependence between \(\) and \(\) is implicitly learning the dependence between each of them relative to the factors \(\), even when \(\) is not observed. 

### FMCA-T: Learning decomposition for the matrix trace

When probability densities are unavailable, we approximate eigenvalues and eigenfunctions using a learning system with two neural networks and a cost function, typically a matrix cost like \(\) or nuclear norm . These costs optimize an aggregation of eigenvalues. The networks learn the dominant eigenvalues and eigenfunctions when optimized.

Aggregation of eigenvalues.To measure the total power of the eigenspectrum, define a scalar-valued measure using a convex function \(:\) with \((0)=0\). Assume the eigenvalues are ranked \(_{1}_{2}\). The truncated total statistical dependence measure of the top \(K\) eigenvalues is defined by \(T_{}:=_{k=1}^{K}(_{k})\). Function \((x)=-(1-x)\) corresponds to the \(\) cost.

Prior work: log-determinant cost.Consider two networks, \(_{}:^{K}\) and \(_{}:^{K}\), mapping realizations of \(\) and \(\) to \(K\)-dimensional outputs, respectively. Assume \(_{}\) is for EEG and \(_{}\) for EMG. The autocorrelation (ACFs) and cross-correlation functions (CCFs) are defined as:

\[_{F}=_{}[_{}()_{}^{ }()],\ _{G}=_{}[_{}()_{}^{ }()],\ _{FG}=_{,}[_{}()_{}^ {}()],\ _{FG}=_{F}&_{FG}\\ _{FG}^{}&_{G}.\] (2)

FMCA minimizes a \(\) cost, which reaches the negative value of the total measure \(T_{}\) of \((x)=-(1-x)\) when minimized. The cost is defined by:

\[_{,}\ r_{L}(,)=_{FG}- _{F}-_{G},\ \ r_{L}^{*}=_{k=1}^{K}(1-_{k}).\] (3)

Normalization trick.After training, normalizations are needed to obtain eigenfunctions. The first step is to ensure orthonormality: \(_{}}=_{F}^{-}_{},_{}}=_{G}^{-}_{}\). The second step is a singular value decomposition: \(_{FG}}=[_{}}()_{}}^{}()]=^{}\), where \(=(_{1},,_{K})\). The third step is to normalize functions such that they are invariant to the linear operator: \(_{}}=^{}_{}},\ \ _{ }}=^{}_{}}\). Functions \(_{}},_{}}\) are the top eigenfunctions of the density ratio, and \(_{1},_{2},\) are the top eigenvalues. An approximation of the density ratio is given by \(=_{}}^{}^{} _{}}\).

Newly proposed: matrix trace cost.This paper explores alternative convex functions, specifically the simplest case \((x)=x\), The cost, in the form of a matrix trace, is described below.

**Lemma 2**.: _Denote \(:=_{FG}\). Given neural nets \(_{}\) and \(_{}\), minimizing the matrix trace_

\[_{,}\ r_{T}(,)=-(_{F}^{-1}_{G}^{-1}^{}),\] (4)

_yields \(r_{T}^{*}(,)=-_{k=1}^{K}_{k}\), where \(r_{T}^{*}(,)\) is the optimal cost, reaching the sum of the top \(K\) eigenvalues of the density ratio when minimized. We name this algorithm FMCA-T._

Proof.: Applying the Schur complement to \(r_{L}\), we obtain \(r_{L}=(-_{F}^{-}_{G}^{-1}^{ }_{F}^{-})\). Denoting eigenvalues of a matrix as \(_{1}(),,_{K}()\), the cost becomes \(r_{L}=_{k}(1-_{k}())\), where \(=_{F}^{-}_{G}^{-1}^{}_ {F}^{-}\). Optimizing the sum of eigenvalues instead, we use \(Trace()\) and, based on the trace property \(Trace()=Trace()\), derive the trace cost for learning multivariate statistical dependence as \(r_{T}=-Trace(_{F}^{-1}_{G}^{-1}^{})\). 

FMCA-T is more computationally efficient as it uses only matrix operations of dimension \(K\). Directly optimizing the sum of the eigenvalues is also more stable than optimizing their logarithm.

### Channel-level and temporal-level dependencies

**Motivations.** For EEG \(_{1:T}\) and EMG \(_{1:T}\), FMCA-T applies two networks, \(_{}\) and \(_{}\), to minimize the matrix trace cost. Dependence is measured at two levels: _random-process level_, measured by eigenvalues for the overall dataset dependence, and _trial level_, measured by the density ratio--the higher the ratio, the greater the contribution of this pair of realizations to overall dependence. In cortico-muscular analysis, it is vital to understand how individual channels and time steps contribute to connectivity, especially in EEG signals, as they represent the temporal and spatial dynamics of brain. Hence, we propose localized density ratios to measure _temporal-level dependence_ and _channel-level dependence_. The core idea is computing density ratios between channel-level and temporal-level features against the global trial-level features.

**Channel-level features.** We design a specialized network topology to generate features for individual channels and time intervals, ensuring that the internal layers of this network quantify channel-level and temporal-level features, similar to .

Given \(_{1:T}=[_{1:T}(1),,_{1:T}(C)]^{}\) for channels \(c=1,,C\), we define a temporal network \(_{TN}:^{T}^{K}\) that maps single-channel signals to a \(K\)-dimensional feature space, and a channel network \(_{CN}:^{L K}^{K}\) that maps concatenated channel features to global features:

\[_{c}=_{TN}(_{1:T}(c)), c=1,,C; _{F}=_{CN}([_{1},_{2},,_{C }]^{}),\] (5)

where \(_{1},_{2},,_{C}\) are channel-level features, and \(_{F}\) is global trial-level features.

**Channel-level dependence \(}(c)\)**. The density ratio of \(_{1},_{2},,_{C}\) relative to \(_{F}\) measures channel-level dependence. Post-training and with fixed parameters, we compute the ACF of the channel features \(_{C}=[_{c=1}^{C}_{c}_{c}{}^{ }]\), the ACF of the global features \(_{F}=[_{F}_{F}^{}]\), and the CCF between them \(_{C,F}=[_{c=1}^{C}_{c}_{F}^{ }]\).

Next, the features are normalized as in the Sec. 2.2: \(_{c}\) and \(_{F}\) are normalized to \(_{c}}=_{C}^{-}_{c}\) and \(_{F}}=_{F}^{-}_{F}\) for orthonormality. The SVD of \(_{C}^{-}_{C,F}_{F}^{-}=^{ }\) is computed. The outputs are further normalized to \(_{c}}=^{}_{c}}\) and \(_{F}}=^{}_{F}}\) to guarantee invariance in the linear operator. Finally, the density ratio can be constructed as \(}(c)=_{c}}^{}_{F}}\).

This ratio \(}(c)\) is a function of channel \(c\) and trial \(\), implying the dependence between channel and global features. The greater the value, the stronger the activation of the channels, showing which channels contribute the most to the cortico-muscular connectivity.

**Temporal-level features and dependence.** To measure time-domain dependence, we compute density ratios between the internal features of the temporal network \(_{TN}\) and the global features, in two steps: first, computing density ratios between _adjacent_ network layers; second, aggregating these ratios to consider all layers.

**Step 1: Construct density ratios \(}(_{1},_{2})\) between _adjacent_ layers.** Fix a channel \(c\) and feature \(_{c}\). Consider a simple temporal network with \(S\) convolution layers with nonlinaer activation functions: \(_{TN}^{(1)},_{TN}^{(2)},,_{TN}^{(S)}\), with kernel sizes \(_{1},_{2},,_{S}\), and their outputs \(_{c,1},_{c,2},,_{c,S}\). Suppose the time dimensions of these layers are \(T_{1},T_{2},,T_{S}\). Fix any layer \(s\). The \(\)-th element of \(_{c,s}\), denoted as \(_{c,s}()\), is obtained by applying a nonlinear operation to a segment of the previous layer's output:

\[_{c,s}()=_{TN}^{(s-1)}(_{c,s-1}(:+ _{s-1})).\] (6)

* Define the ACF of layer \(s-1\): \(_{c,s-1}=}[_{}_{c,s-1}()_{c,s-1}^{}()]\)
* Define the ACF of layer \(s\): \(_{c,s}=}[_{}_{c,s}()_{c,s} ^{}()]\)
* Define the CCF between them: \(_{c,s-1,s}=}[_{}_{=1}^{_{ s}}_{c,s-1}(+)_{c,s}^{}()]\).

Normalization with \(_{c,s-1}\), \(_{c,s}\), and \(_{c,s-1,s}\) yields density ratios \(}(_{1},_{2})\), which quantify the dependence between time \(_{1}\) and \(_{2}\) across two layers \(s-1\) and \(s\), for a given trial and channel \(c\). A higher value indicates a stronger dependence between adjacent network layers.

**Step 2: Aggregate layer-wise ratios for localized responses \(}()\).** While \(}(_{1},_{2})\) quantifies dependence between two layers, we aggregate these ratios to account for all network layers.

Again, fix the element \(_{c,s}()\) in layer \(s\). We focus on its mapping to the next layer \(s+1\). Based on Eq. (6), elements in layer \(s+1\) that are mapped from \(_{c,s}()\) by \(_{FP}^{(s)}\) are within a window of size \(_{s}\) (the kernel size). To ensure this window stays within the feature vector's boundary, we define coordinates \(_{s}=[+1)},-1)}]\). Feature elements in layer \(s+1\) that are mapped from \(_{c,s}()\) fall within these coordinates.

We then create a series of functions \(}()\) with \([1,T_{s}]\) for each layer \(s\) as the aggregations of the ratios. Starting from \(}()=}(c)\) (channel-level density ratio), compute recursively

\[}(_{1})=_{_{2} I_{s}}}(_{2})}(_{1},_{2}),\ \ _{1}[1,T_{s}]\] (7)

That is, starting from the top layer of the network, we aggregate the density ratios within the window \(_{s}\), layer-by-layer, until we generate a localized measurement for each element of the function \(}()\) at layer \(s\), channel \(c\), and time \([1,T_{s}]\), considering all neural network layers.

The final localized responses of the density ratio, \(}()\), obtained in a top-down manner, are functions of the EEG trial \(_{1:T}\), time step \(\), and channel \(c\), providing both temporal and channel-level resolution. The same analysis applies to EMG signals, differing only in the number of channels.

## 3 Experiments

Our experiments have three key findings: (1) Dependence measured by FMCA-T is stable against nonstationary noises and delays in simulated dataset; (2) Learning from unlabeled EEG-EMG pairs extracts movement and subject information from EEG's eigenfunctions; (3) EEG's spatio-temporal dependencies are consistent with ground truth brain activations in simulated dataset and match theoretical evidence in experimental dataset.

### Datasets and baselines

**Dataset 1: SinWav.** We construct a simulated dataset where each data pair \(\{_{1:T}\), \(_{1:T}\}\) has a clean sinusoidal signal \(_{t}=A( t)\) and a noisy counterpart \(_{t}\) superimposed with various types of noise: stationary white noise \(_{t}(0,^{2})\), nonstationary Gaussian noise \(_{t}^{2}|_{t}|\), and nonstationary pink noise \(S(f) 1/f^{a}\). Random delays are added by padding the start and end of the signal with noise such that \(_{t}=_{t}\) is white for \(1 t_{1}\) and \(T-_{2}<t T\), and \(_{t}=_{t-_{1}}\) is sinusoidal for \(_{1}<t T-_{2}\), where \(_{1}+_{2}=\) is fixed. Since these noises do not change the underlying sinusoid, the signal pairs are statistically independent when conditioned on the sinusoid. Thus, we expect the dependence measure to be unaffected by the noise level.

**Dataset 2: EEG-EMG-Fusion.** We use a public dataset  (approved by the Institutional Review Board at Korea University, 1040548-KU-IRB-17-181-A-2) with paired 60-channel EEG and 7-channel EMG recordings from 25 subjects. The subjects perform three _main movements_: arm-reaching, hand-grapsing, and wrist-twisting. Each main movement contains _sub-movements_: arm-reaching along six directions, hand-grasping three objects, and wrist-twisting with two motions, and thus 11 movements in total. Subjects perform one sub-movement per trial, and 50 trials are collected per sub-movement. The same recordings are repeated for three sessions at one-week intervals. Both EEG and EMG are recorded at 2,500 Hz and downsampled to 1,000 Hz. The dataset is cleaned by removing eye-blinking artifacts and baseline wandering, and segmented into 4-second intervals, creating 41,250 paired samples of complete movement cycles.

**Dataset 3: Simulated EEG-EMG Dataset.** We simulate 128-channel EEG signals and 7-channel EMG signals for left/right motor and sensory activations from 20 subjects using EEGSourceSim. Motor sources are used to simulate the corresponding EMG signals. Both EEG and EMG are sampled at 1,000 Hz. White Gaussian noise at 5 dB is added to the EEG and EMG signals. FMCA-T is trained on 16 subjects and tested on 4 subjects to compare FMCA-T's spatial-level dependence representation with the ground truth activations, as shown in Fig. 6.

**Classification tasks.** We conduct three classification experiments: _3-class_ (three main movements), _11-class_ (11 sub-movements), and _Subj_ (25 subjects). We also compare _inter-subject_ and _cross-subject_ classifications. Cross-subject means the test set contains only unseen subjects. Inter-subject uses an 80-20 split of trials from all subjects for training and testing, while cross-subject uses 20 subjects for training and 5 for testing with five-fold cross-validation.

**Statistical dependence baselines.** We compare our proposed dependence measure with established baselines: (1) KICA  and HSIC , which solve the generalized eigenvalue problem of two kernel Gram matrices, using \(_{i}_{i}\) for HSIC and \(-_{i}(1-_{i})\) for KICA; (2) MINE , which optimizes the Donsker-Varadhan representation with a three-layer MLP; (3) CC: Pearson correlation coefficient averaged over time; (4) MIR (KNN estimator ), which optimizes entropies using k-nearest neighbor distances, and then computes mutual information; (5) Our method uses density ratios for trial-level dependence and eigenvalue aggregations \(T_{}\) for random-process-level dependence.

For the EEG-EMG dependence study, we compare with CMC, the correlation coefficient between EEG and EMG spectra of windowed data on the alpha band of channel C4 . We extend CMC by replacing linear correlation with nonlinear measures, computing CMC-KICA and CMC-MIR.

**EEG feature projector baselines.** After training \(_{}\) and \(_{}\) networks for dependence estimation, with parameters fixed, we train a three-layer MLP on EEG's eigenfunctions (\(_{}}(X)\)) for classification. This is compared with baseline EEG classifiers trained from scratch: (1) Supervised: _Vanilla Classifier_, with the same topology as ours but using a standard log-likelihood cost; _EEG-Net_, a specialized network for EEG-based BCI; _EEG-Conformer_, a compact convolutional transformer for EEG decoding and visualization; _Deep4_, a deep ConvNet for classification using raw EEG; and _CSP-RLDA_, using common spatial pattern (CSP) for feature extraction and regularized linear discriminant analysis (RLDA), adapted for multi-class classification with majority voting. (2) Self-Supervised: contrastive costs using 1-second windows from the same signal as positive pairs and from different signals as negative pairs, including _Barlow Twins_, _SimCLR_, and _VicReg_. Experimental and implementation details can refer to the App. C.

### Main results

**Robustness of FMCA-T.** Fig. 3 shows the robustness of our proposed measure in the SinWav dataset, when there are increasing levels of nonstationary noise and delays. Since EEG and EMG signals are often damaged and distorted by environmental noise and the functional coupling occurs with time delays, an effective measure should maintain its robustness against these factors.

In Fig. 3, FMCA-T is first trained on noisy data pairs with all four noise types and magnitudes (Sec. 3.1). Using the trained models, we measure the dependence between a clean sinusoid and its noisy counterpart. A noise level of \(1.0\) means the noise magnitude matches the sinusoid. The delay level determines the extent to which the clean sinusoid is shifted from its original position. A delay

Figure 3: Density ratios from FMCA-T are robust to various noise types: (a) stationary white Gaussian noise, (b) nonstationary Gaussian noise, (c) nonstationary pink noise, and (d) random delays. FMCA-T proves the most robust estimations across all noise types and outperforms all linear and nonlinear baselines. Note that as delays increase, estimations using CC produce negative values given the opposite phase between the paired sinusoids.

level of \(1.0\) shifts the sinusoid to have no intersection with the original one. FMCA-T consistently shows invariance to noise and delays, as the dependence is determined by their frequency but not by the noise and phase shift. MINE fails to converge and produce stable results for this dataset.

**Applying FMCA-T to EEG-EMG-Fusion.** We confirm our primary hypothesis that the projection space defined by EEG eigenfunctions, derived from modeling the statistical dependence between EEG-EMG recordings, captures essential contextual factors like movements and subjects without requiring labels. We visualize the learned eigenfunctions and density ratios in Fig. 4.

**Fig. 4(a), Fig. 4(b): eigenfunctions \(}\).** EEG's eigenfunctions effectively capture relevant contextual information. After training eigenfunctions using the entire dataset, we extract a subset of eigenfunctions that belong to a specific subject or a movement and apply t-SNE to visualize them.

Fig. 4(a) visualizes the eigenfunctions of all trials for one subject (SUB1). Each trial is color-coded by the type of movement (MOV1\(\)MOV3). Notably, the eigenfunctions form nine clusters, which are verified to correspond to the three movements recorded over three sessions. This demonstrates that the eigenfunctions contain motion-related information. The consistent clustering patterns across all 25 subjects are detailed in the App. B.

Fig. 4(b) visualizes the eigenfunctions from a single type of movement (reaching, labeled as MOV1) across ten different subjects (SUB1\(\)SUB10). Each color represents a subject. Distinct clustering patterns are observed, showing that the eigenfunctions also contain subject information which could be useful for participant identification.

**Fig. 4(c), 4(d): density ratio \(\).** Based on the t-SNE plot for SUB1 trials, we plot the estimated density ratio values between each EEG-EMG pair in Fig. 4(c). In Fig. 4(d), we extract the mean of density ratios for trials in each cluster (C1\(\)C9), rank them from smallest to largest, and plot them alongside the standard deviation. These figures show that the density ratios remain consistent within each cluster (a movement during a session) while vary across different clusters. We find the highest dependence in reaching, followed by grasping, and the lowest in twisting. Our results are consistent with existing literature that links cortico-muscular connectivity with movement types . The results are consistent across all subjects, detailed in the App. B.

**Fig. 4(e)\(\)(h)** presents the results of MINE and CMC measures for SUB1 trials. Only MINE produces a comparable measure that shows difference across clusters, but with higher variance and instability.

**EEG's eigenfunctions as optimal feature projector.** Table 1 validates the claims in Fig. 4 with classification accuracy comparisons. We extract EEG eigenfunctions from the training set after the networks are trained on EEG-EMG pairs. The eigenfunctions are used to train a three-layer MLP for classification. This classifier predicts the class of any EEG test samples using its eigenfunctions

Figure 4: Visualizing eigenfunctions and density ratios in EEG-EMG fusion with FMCA-T: (a) t-SNE of EEG’s eigenfunctions for a single subject (SUB1) show nine clusters specific to three movements (MOV1\(\)MOV3) across three sessions. (b) t-SNE of EEG’s eigenfunctions for reaching movement (MOV1) across 10 subjects (SUB1\(\)SUB10) shows clusters specific to subjects, where each color is a subject. (c) Density ratios and (d) their mean and std of each cluster (C1\(\)C9) demonstrate intra-cluster consistency and inter-cluster separability. (e-h) Comparison of baseline measures, where only MINE is comparable but with higher variance and instability.

(output of \(}_{}\)), without requiring EMG samples. As detailed in the Sec. 3.1, scores for _3-class_, _11-class_, and _subj_ are presented in both _inter-subject_ and _cross-subject_ settings.

In inter-subject 3-class classification (80-20 split across trials from 25 subjects), FMCA-T exceeds the supervised baseline (EEGNet) by 7.2%, the classical EEG decoding method (CSP-RLDA) by 1.0%, and self-supervised methods by over 9.5%. Notably, CSP-RLDA is trained and tested on each individual subject, with the accuracy averaged across 25 subjects, thereby representing an upper bound for classical methods. All other methods are trained and tested on the combined subject data. For the 11-class classification task, FMCA-T surpasses all baselines with a classification accuracy of 0.32, significantly higher than the chance level of 0.09. Since CSP-RLDA uses binary classification with majority voting, it is computationally infeasible for 11 sub-movements classification.

In the more challenging cross-subject classification (trained on 20 subjects, tested on 5), FMCA-T with trace loss outperforms all baselines by over 10%, achieving an accuracy of 0.54 in the 3-class task. The highest scores from 10,000 iterations are recorded, and experiments are repeated with five-fold validation. The superior performance of FMCA-T in the cross-subject setting suggests that learning EEG-EMG dependence is robust against distribution shifts and nonstationary noise, which is consistent with the observation that self-supervised methods outperform supervised ones.

Comparing FMCA-LD (\(\)) and FMCA-T (matrix trace), we find that trace cost has greater stability and reduced variance. The sum of eigenvalues, especially during prolonged training, is more stable. While both costs show similar performance at the initial training stages, FMCA-T has notably reduced variance during the convergence stage of training.

**Spatio-temporal dependencies - real data.** We visualize the local density ratio responses of cluster SUB3-C1 (reaching movement) in both spatial (\(}(c)\)) and temporal domains (\(}()\)) in Fig. 5. The channel-level dependence is averaged across all trials and displayed in Fig. 5(a). We also randomly select nine trials from the same cluster and visualize them in Fig. 5(b). The temporal-level dependence for the first trial T1 in SUB3-C1 is shown in Fig. 5(c). Consistent activations are observed in other subjects, details in the App. B.

As illustrated in Fig. 5, the localized density ratio remains stable throughout the 4-second movement, corroborating the consistency of brain-muscle connectivity during stable states . We also find that in channel-level dependence, the density ratio activates the fronto-central (FC) areas. The sensorimotor area is crucial for movement control, with EEG data from these regions often used to decode motor intentions. However, motor control also relies on cognitive processes , especially during movement planning, complex tasks, and collaborations . Thus, the region of Brodmann area 6, well acknowledged to playing a role in movement planning may contribute differently during various movement tasks . Our findings show that the features extracted from these fronto-central areas play an important role in classification.

**Spatio-temporal dependencies - simulated data.** We implement FMCA-T on paired EEG-EMG samples from the simulated dataset, using 16 subjects for training and 4 subjects for testing. We compare FMCA-T's spatial-level dependence maps for these 4 testing subjects with their ground truth brain activations computed by the motor ROI and forward matrices, shown in Fig. 6. FMCA-T's spatial-level dependencies are highly similar to the ground truth activations, indicating that the learned density ratios effectively captured the real brain activations.

  
**Methods** &  &  \\   & _3-Class_ & _11-Class_ & _Subj_ & _3-Class_ & _11-Class_ \\    \\ Vanilla & 0.907\(\)0.020 & 0.220\(\)0.015 & 0.980\(\)0.010 & 0.427\(\)0.021 & 0.110\(\)0.005 \\ EEGNet & 0.904\(\)0.015 & 0.246\(\)0.028 & 0.988\(\)0.007 & 0.405\(\)0.019 & 0.095\(\)0.021 \\ EEG-Conformer & 0.949\(\)0.001 & 0.268\(\)0.001 & 0.976\(\)0.002 & 0.415\(\)0.002 & 0.105\(\)0.001 \\ Deep4 & 0.901\(\)0.001 & 0.274\(\)0.001 & 0.941\(\)0.001 & 0.429\(\)0.001 & **0.140\(\)0.000** \\ CSP-RLDA & 0.985\(\)0.019 & / & / & 0.408\(\)0.018 & / \\    \\ Barlow Twins & 0.893\(\)0.018 & 0.269\(\)0.012 & 0.987\(\)0.008 & 0.437\(\)0.018 & 0.115\(\)0.004 \\ SimCLR & 0.890\(\)0.019 & 0.257\(\)0.013 & 0.979\(\)0.011 & 0.441\(\)0.020 & 0.117\(\)0.006 \\ VicReg & 0.899\(\)0.016 & 0.274\(\)0.014 & 0.980\(\)0.009 & 0.449\(\)0.016 & 0.115\(\)0.005 \\    \\ FMCA-L & 0.985\(\)0.003 & 0.257\(\)0.011 & 0.989\(\)0.007 & 0.509\(\)0.014 & 0.115\(\)0.003 \\ FMCA-T & **0.994\(\)0.002** & **0.320\(\)0.009** & **0.998\(\)0.004** & **0.540\(\)0.012** & **0.121\(\)0.002** \\   

Table 1: Comparison of classification accuracies: supervised, self-supervised, and our EEG-EMG dependence learning. FMCA-T’s eigenfunctions, trained with trace cost without labels, are optimal feature projectors for EEG. EMG is not required for testing, but only used for training.

## 4 Conclusion

This paper introduces a novel approach for estimating cortico-muscular dependence through the orthonormal decomposition of the density ratio. By treating the density ratio as a positive definite function and learning its projection space from EEG and EMG, we unveil the relationship between statistical dependence, contextual factors impacting connectivity, and the spatio-temporal information shared between the brain and muscles. While our method shows promising results, challenges remain. For example, performance drops in cross-subject classification, likely due to the limited dataset of 25 participants. Future work will focus on applying our framework to larger datasets and incorporating additional bio-signal modalities to model a broader common space in neural data.