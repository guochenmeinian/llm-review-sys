# Supplemental Material

[MISSING_PAGE_EMPTY:1]

conditions, especially involving multiple image modalities such as RGB and infrared images, the system needs to intricately handle the differences in images from different modalities [18; 19; 20]. This is essential to ensure that the system exhibits better robustness across different modalities. Hence, cross-modality ReID is considered more challenging due to the need for addressing these modality differences [21; 22].

Cross-modal ReID [23; 24; 21; 25] plays a crucial role in significantly expanding the applicability of traditional ReID methods, focusing on addressing complex matching issues between different image modalities. In practical surveillance systems, the simultaneous use of multiple sensors, such as RGB cameras and infrared cameras, is a common scenario. This task requires innovative solutions to effectively bridge the differences between various modalities, ensuring robust and accurate re-identification of pedestrians in heterogeneous sensor outputs.

Currently, most research on the security of ReID focuses on single-modality systems based on RGB images [26; 27; 28; 29; 30; 31], while the security of cross-modality ReID systems has received insufficient attention. The challenge in cross-modality attacks arises from significant visual differences among different modality inputs, requiring attackers to effectively capture shared features from each modality for perturbation implementation. However, as shown in Fig. 1, existing attack methods in cross-modal scenarios require optimizing perturbations separately for each modality, lacking an intrinsic mechanism to capture shared knowledge between different modalities, which limits the success rate of the attacks. To address this issue, we propose a synergistic optimization method combined with triplet loss, utilizing information from different modalities to optimize the universal perturbation. This method pushes the features of different samples into a common sub-region that affects the model's accuracy, as shown in Fig. 2.

Specifically, we propose the Cross-Modality Perturbation Synergy (CMPS) method, a universal perturbation approach designed specifically for cross-modality ReID systems. This method simultaneously leverages gradient information from multiple modalities to jointly optimize universal perturbations across visible and infrared images. CMPS incorporates cross-modality triplet loss to ensure feature consistency across different modalities, enhancing the generality of the perturbation. During the synergistic optimization process, CMPS iteratively updates gradients from various modalities within a unified optimization framework, effectively capturing and utilizing shared features across modalities. To further reduce visual differences between modalities, we introduce cross-modality attack augmentation, converting images into grayscale to standardize their visual representation and facilitate the learning of modality-agnostic perturbations. As a result, these universal perturbations push the features of different samples toward a common region in the feature space, significantly diminishing the model's ability to accurately distinguish identities in cross-modality scenarios, thereby successfully deceiving the model.

Figure 1: Comparison between traditional and proposed methods: Fig.(a) illustrates traditional attack methods (e.g., FGSM , PGD ), which are primarily designed for single-modal tasks and lack mechanisms to associate multiple modalities, making them ineffective in simultaneously misleading retrieval results across different modalities. Fig.(b) illustrates the proposed method, which employs an intrinsic mechanism to effectively associate different modalities, thereby misleading retrieval results across multiple modalities simultaneously.

In our experiments on widely utilized cross-modality ReID datasets, including RegDB , SYSU  and LLCM , we not only showcase the effectiveness of our proposed method but also provide insights for fortifying the robustness of cross-modality ReID systems in the future. This research contributes by bridging gaps in current studies and introducing novel perspectives to study the security challenges in cross-modality ReID systems.

The main contributions of our work can be summarized as:

\(\) To the best of our knowledge, our work is the first to investigate vulnerabilities in cross-modality ReID models. By explicitly incorporating cross-modality constraints into the synergistic optimization process, we enhance the universality of the learned cross-modality perturbations. Additionally, we provide mathematical analysis to demonstrate the superiority of our proposed method over traditional approaches.

\(\) We propose a cross-modality attack augmentation method, utilizing random grayscale transformations to narrow the gap between different modalities, aiding our cross-modality perturbation synergy attack in better capturing shared features across modalities.

\(\) Extensive experiments conducted on three widely used cross-modality ReID benchmarks demonstrate the effectiveness of our proposed cross-modality attack. Our method exhibits good transferability even when attacking different models. The code will be available at https://github.com/finger-monkey/cmps_attack.

## 2 Related Works

**Adversarial Attack.** Adversarial attacks are a technique involving the clever design of small input perturbations with the aim of deceiving machine learning models, leading them to produce misleading outputs. This form of attack is not confined to the image domain but extends to models in various fields, including speech  and text [35; 36; 37]. Typically, the goal of adversarial attacks is to tweak input data in a way that causes the model to make erroneous predictions when handling these subtly modified samples [16; 38; 39; 40]. In the early stages of research, adversarial attacks had to

Figure 2: Illustration of the CMPS attack framework. We generate homogeneous grayscale images through random grayscale transformations to reduce the differences between modalities, aiding in the learning of a universal perturbation. The process is as follows: first, the gradient from one modality is used to optimize the universal perturbation, which is then applied to another modality’s images to generate adversarial samples for attacks. The new modality’s gradient is then used to further optimize the perturbation and attack the next modality. By aggregating feature gradients from different modalities, we iteratively learn a universal perturbation, pushing samples toward a common region in the manifold. The manifold is represented as a sphere, with identical shapes but different colors representing the same person’s features across modalities. This method captures shared knowledge between modalities, enabling more effective learning of cross-modal universal perturbations.

be customized for each specific sample. However, with the evolution of related studies, universal perturbation  attacks were introduced, aiming to find perturbations effective across multiple samples rather than tailored to individual instances. Research on universal perturbation attacks seeks to expose vulnerabilities in models, prompting designers to enhance their robustness to withstand a broader range of adversarial challenges.

**Adversarial Attacks in ReID.** Some ReID attack methods have been proposed, with current research predominantly focusing on RGB-RGB matching. These methods mainly include: Metric-FGSM  extends some techniques, inspired by classification attacks, into a category known as metric attacks. These encompass Fast Gradient Sign Method (FGSM) , Iterative FGSM (IFGSM), and Momentum IFGSM (MIFGSM) . The Furthest-Negative Attack (FNA)  integrates hard sample mining  and triple loss to employ pushing and pulling guides. These guides guide image features towards the least similar cluster while moving away from other similar features. Deep Mis-Ranking (DMR)  utilizes a multi-stage network architecture to pyramidally extract features at different levels, aiming to derive general and transferable features for adversarial perturbations. Gong et al.  proposed a local transformation attack (LTA) method specifically aimed at attacking color features without requiring additional reference images, and discussed effective defense strategies against current ReID attacks. The Opposite-direction Feature Attack (ODFA)  exploits feature-level adversarial gradients to generate examples that guide features in the opposite direction with an artificial guide. Yang et al.  introduced a combined attack named Col.+Del., which integrates UAP-Retrieval  with color space perturbations . While this method also explores universal perturbations in ReID, its generality is limited due to the inability to leverage color information in cross-modality problems and the lack of a mechanism for associating different modality information. In contrast to the aforementioned approaches, our focus lies on addressing cross-modality challenges.

```
1:Input: Visible images \(I_{RGB}\) and infrared (or thermal) images \(I_{ir}\) from dataset \(S\), cross-modality ReID model \(f\) trained on \(S\), adversarial bound \(\), momentum value \(\), iteration step size \(\), iteration epoch iter_epoch.
2:Output: Cross-modality universal perturbation \(\).
3: Initialize \(\) with random noise \( Rand(0,1)\), \(^{0}=0\).
4:for\(i\) in iter_epochdo
5:repeat
6: Sample a mini-batch of visible images \(I_{RGB}\) and infrared (or thermal) images \(I_{ir}\) with \(n\) samples
7:\(_{RGB} I_{RGB}+\)
8: Use infrared images to compute the triplet loss \(L_{RGB}\) for visible images (Eq. 4)
9: Compute gradient \(_{RGB}\) of \(L_{RGB}\) w.r.t. \(\):
10:\(_{RGB}^{i-1}+}{ }\)
11: Update perturbation \(\):
12:\((+(_{RGB}),-,)\)
13:\(_{ir} I_{ir}+\)
14: Use visible images to compute the triplet loss \(L_{ir}\) for infrared images (Eq. 7)
15: Compute gradient \(_{ir}\) of \(L_{ir}\) w.r.t. \(\):
16:\(^{i}_{RGB}+}{}\)
17: Update perturbation \(\):
18:\((+(^{i}),-,)\)
19:until all mini-batches are processed
20:endfor
21:return\(\) ```

**Algorithm 1** Procedure of CMPS attack

## 3 Methodology

In this section, we introduce a universal perturbation designed for cross-modality attacks, referred to as the Cross-Modality Perturbation Synergy (CMPS) attack. Considering the significant differences between different modalities, we propose a attack augmentation method to bridge the gap between modalities, aiding in enhancing the perturbation's universality across different modalities. Ourobjective in addressing this problem is to find a universal adversarial perturbation, denoted as \(\), capable of misleading the retrieval ranking results of cross-modality ReID models. The adversarial operation involves adding \(\) to a query image \(I\). The perturbed query image, denoted as \(I_{adv}=I+\), is then used to retrieve from the gallery and deceive the cross-modality ReID model \(f\). The algorithm is summarized in Alg. 1.

### Overall Framework

In Fig. 2, we illustrate the overall framework of the proposed CMPS attack. During the training phase, we optimize \(\) using our cross-modality attack augmentation method, which leverages images from different modalities to bridge their inherent differences and enhance cross-modality universality. In the attack phase, the optimized \(\) deceives reID models, leading to inaccurate ranking lists. Section 3.2 outlines the framework and overall optimization objective, providing a macro-level overview. Section 3.4 delves into the specific process of perturbation optimization across different modalities.

### Optimizing Loss Functions for Attacking

Our study aims to deceive cross-modality ReID models using a universal perturbation. We have specifically designed a triplet loss tailored for our proposed attack method, which can correlate different modalities and influence the distance relationships between images from different modalities.

We follow the approach of  to optimize the perturbation using cluster centroids. This method directly impacts the similarity between pedestrian identities in the ReID model's feature space (rather than the similarity between individual samples), making it more effective. Subsequently, leveraging the acquired cluster centroids, we apply our triplet loss to distort the pairwise relations between pedestrian identities. This process can be represented as follows:

\[L =[(\|C_{g}^{n}-f_{RGB}^{adv}\|_{2}-\|C_{ir}^{p}-f_ {RGB}^{adv}\|_{2}+),0]\] (1) \[+[(\|C_{ir}^{n}-f_{g}^{adv}\|_{2}-\|C_{RGB}^{p}- f_{g}^{adv}\|_{2}+),0]\] \[+[(\|C_{RGB}^{n}-f_{ir}^{adv}\|_{2}-\|C_{g}^{p}- f_{ir}^{adv}\|_{2}+),0].\]

As shown in Fig. 3, the loss function mentioned above fully leverages the triplet-wise relationships across different modality. Through this loss, we are able to pull the negative samples of each modality closer to the adversarial samples and push the positive samples of each modality away from the adversarial samples. Here, \(C_{RGB}^{p}\) and \(C_{RGB}^{n}\) represent the cluster centroids of the positive samples to push and negative samples to pull, respectively, in the original visible (RGB) image feature space of the training data. Similar definitions apply to other modalities. \(f_{RGB}^{adv}\), \(f_{g}^{adv}\), and \(f_{ir}^{adv}\) denote the perturbed features of the disturbed image in the visible, grayscale, and infrared (or thermal) modalities, respectively.

### Cross-Modality Attack Augmentation Method

Intuitively, as illustrated in Fig. 4, maximizing the overlap of common factors across different modalities facilitates the capture of shared features by the learned perturbation. Grayscale images, being inherently homogeneous, serve as effective mediators between diverse modalities. Consequently, we introduce random grayscale transformations into adversarial attack methods, referred to as Cross-Modality Attack Augmentation. This approach guides cross-modality perturbations by leveraging homogeneous grayscale images sourced from diverse modalities. The primary objective is to explore the underlying structural relationships across heterogeneous modalities.

The process of grayscale transformation can be represented as follows:

\[t(R,G,B)=0.299R+0.587G+0.114B,\] (2)

The function t(\(\)) represents the grayscale transformation using ITU-R BT.601-7 standard weights, combining the RGB channels of each pixel into a single grayscale channel. From this, we construct a 3-channel grayscale image \(x_{g}\) by replicating the grayscale channel:

\[x_{g}=[t(R,G,B),t(R,G,B),t(R,G,B)].\] (3)

### Cross-Modality Perturbation Synergy Attack

To synergistically utilize gradient information from diverse modalities for perturbation optimization, narrow the gap between different modalities to better capture shared knowledge, we adopt the following training process to generate a universal perturbation:

**(1) Learning the visible modality.** For a given batch of visible images with \(n\) samples, we extract and perturb their features using the cross-modality ReID model. We update the temporary perturbation \(\) iteratively using Momentum-Inertia Stochastic Gradient Descent (MI-SGD), expressed as:

\[ L_{RGB}(f_{RGB}^{adv},)&= [(\|C_{g}^{n}-f_{RGB}^{adv}\|_{2}..\\ &..-\|C_{ir}^{p}-f_{RGB}^{adv}\|_{2}+), 0],\\ _{RGB}&=_{ir}^{}+L_{RGB}}{\|_{}L_{RGB}\|_{1}},\\ &=(+( _{RGB}),-,).\] (4)

Here, \(\) represents the momentum value (set as \(=1\)), and \(_{ir}^{}\) is derived from the previous iteration. The iteration step size is denoted by \(\) (set as \(=\) ), where \(\) is the adversarial bound (\(=8\), unless otherwise specified). We set the margin \(=0.5\) in our triplet loss.

**(2) Learning the grayscale modality.** This part is executed through data augmentation. It is not considered as a separate module and is therefore not explicitly listed in Alg. 1. Specifically, during the perturbation learning process, we randomly transform visible or infrared (or thermal) images into homogeneous grayscale images, participating in the iterative optimization of adversarial perturbations. It is employed to bridge the gap between different modalities, thereby improving the universality of the perturbation across diverse modalities. In order to investigate the impact of different grayscale conversion probabilities on attack performance, we conducted a series of ablation experiments. For details, please refer to Fig. 5 in supplementary material.

**(3) Learning the infrared (or thermal) modality.** This step is similar to (1). We utilize the infrared (or thermal) images to learn the perturbation \(\) with the our loss functions:

\[ L_{ir}(f_{ir}^{adv},)&= [(\|C_{RGB}^{n}-f_{ir}^{adv}\|_{2}..\\ &..-\|C_{g}^{p}-f_{ir}^{adv}\|_{2}+),0 ],\\ _{ir}&=_{RGB}+ L_{ir}}{\|_{}L_{ir}\|_{1}},\] (8)\[=(+(_{ir}),-,).\] (9)

Here, \(_{RGB}\) derived from step (1). The main difference compared to the previous step lies in the perturbation applied to the input and the gradients related to momentum.

**Theoretical Analysis.** In traditional optimization, optimizing for one modality can render the perturbation suboptimal for the other, leading to a bias toward a single modality. In contrast, the proposed aggregated optimization method jointly optimizes both modalities, ultimately identifying a universal perturbation that enhances cross-modality attack performance. In the supplementary material 7, we provide a mathematical analysis demonstrating the effectiveness of this method compared to traditional attack methods that lack intrinsic correlations between different modalities.

## 4 Experiments

In this section, we compare our approach with several methods, including traditional classification attack methods FGSM  and PGD , traditional metric attack methods like Metric-FGSM , as well as state-of-the-art ReID attack methods such as LTA 1, ODFA and Col.+Del..

**Datasets**. We evaluate our proposed method on two commonly used cross-modality ReID datasets: SYSU-MM01 , RegDB  and LLCM . SYSU-MM01 is a large-scale dataset with 395 training identities, captured by 6 cameras (4 RGB, 2 near-infrared) on the SYSU campus. It comprises 22,258 visible and 11,909 near-infrared images. The testing set consists of 95 identities with two evaluation settings. The query sets include 3803 images from two IR cameras. We conduct ten trials following established methods  and report the average retrieval performance. Please refer to  for the evaluation protocol. RegDB  is a smaller-scale dataset with 412 identities, each having ten visible and ten thermal images. we randomly select 206 identities (2,060 images) for training and use the remaining 206 identities (2,060 images) for testing. LLCM is a dataset designed specifically for cross-modality ReID in low-light environments. Compared to other datasets, its diverse scenarios and low-light conditions present greater challenges for attackers. This complexity and uncertainty make adversarial attacks more difficult to execute. We assess our model in two retrieval scenarios: visible-thermal and thermal-visible performance.

**Evaluation Metrics**. Following existing works , we employ Rank-k precision and Cumulative Matching Characteristics (CMC) and mean Average Precision (mAP) as evaluation metrics. Rank-1 represents the average accuracy of the top-ranked result corresponding to each cross-modality query image. mAP represents the mean average accuracy, where the query results are sorted based on similarity, and the closer the correct result is to the top of the list, the higher the precision. Please note that, for adversarial attacks, a lower accuracy indicates a more successful attack.

### Performance on Cross-Modality ReID

We used AGW  and DDAG  as baseline models for testing on the RegDB and SYSU cross-modality ReID datasets. AGW (Attention Generalized mean pooling with Weighted triplet loss) enhances the learning capability of crucial features by integrating non-local attention blocks, learnable GeM pooling, and weighted regularization triplet loss. DDAG (Dynamic Dual-Attentive Aggregation) improves feature learning by combining intra-modality weighted-part attention and cross-modality graph structured attention, considering both part-level and cross-modal contextual cues. Additionally, we use DEEN  (Diverse Embedding Expansion Network) as baseline models for testing on the LLCM  cross-modality ReID datasets. The core idea of DEEN is to enhance the feature representation capability by introducing a diversity embedding mechanism. The network expands the embedding space, allowing features from visible and infrared images to align better in a high-dimensional space, thereby improving the accuracy of cross-modality matching.

The experiments encompass two scenarios: 1) Perturbing visible images (query) to disrupt the retrieval of infrared or thermal non-visible images (gallery). This is denoted as "Visible to Infrared" in Tab.1 and "Visible to Thermal" in Tab.2. 2) Perturbing infrared or thermal non-visible images (query) to interfere with the retrieval of visible images (gallery). This is indicated as "Infrared to Visible" in Tab.1 and "Thermal to Visible" in Tab.2.

From Tab.1, it can be seen that the proposed method reduces the rank-1 accuracy to below 2% in both the 'Visible to Infrared' and 'Infrared to Visible' cases. Similarly, from Tab.2, the rank-1 accuracy drops below 3% in both the 'Visible to Thermal' and 'Thermal to Visible' scenarios. In contrast, traditional metric-based attacks, such as Metric-FGSM (M-FGSM), LTA  and ODFA, lead to attacked models with significantly higher rank-1 accuracy, whereas traditional classification attacks (such as FGSM  and PGD ) perform even worse, with rank-1 accuracy remaining over 60%. This is because ReID relies on metric learning for feature matching rather than category classification, requiring attacks specifically tailored for metric learning. These results indicate that, compared to traditional methods that optimize perturbations separately for each modality without considering the inherent correlations between different modalities, our proposed approach demonstrates significant attacking effectiveness across different modalities.

**Comparison with State-of-the-Art.** Col.+Del., as a universal perturbation method, was fairly compared by first optimizing with one modality's dataset and then fine-tuning with the other modality. Since universal perturbations capture shared patterns across the entire data distribution, Col.+Del. is

    &  &  \\  Method & Venue & \(r=1\) & \(r=10\) & \(r=20\) & mAP & \(r=1\) & \(r=10\) & \(r=20\) & mAP \\  AGW baseline  & TPAMI 2022 & 47.50 & 84.39 & 92.14 & 47.65 & 54.17 & 91.14 & 95.98 & 62.97 \\ FGSM attack  & ICLR 2015 & 42.64 & 81.21 & 89.32 & 43.67 & 48.05 & 86.73 & 92.11 & 53.22 \\ PGD attack  & ICLR 2018 & 39.14 & 76.80 & 85.42 & 40.91 & 43.68 & 82.54 & 89.14 & 48.56 \\ M-FGSM attack  & TPAMI 2020 & 25.79 & 49.04 & 57.96 & 19.24 & 20.56 & 38.91 & 46.35 & 15.89 \\ LTA attack  & CVPR 2022 & 8.42 & 21.25 & 27.98 & 9.16 & 20.92 & 32.18 & 36.80 & 15.24 \\ ODFA attack  & IJCV 2023 & 25.43 & 47.49 & 56.38 & 19.00 & 14.62 & 29.92 & 36.42 & 11.35 \\ Col.+Del. attack  & TPAMI 2023 & 3.23 & 14.48 & 20.15 & 3.27 & 4.12 & 16.85 & 21.27 & 3.89 \\ Our attack & NeurIPS 2024 & 1.11 & 8.67 & 16.14 & 1.41 & 1.31 & 7.47 & 10.36 & 1.23 \\  DDAG baseline  & ECCV 2020 & 54.75 & 90.39 & 95.81 & 53.02 & 61.02 & 94.06 & 98.41 & 67.98 \\ FGSM attack  & ICLR 2015 & 48.27 & 86.02 & 91.34 & 49.55 & 53.87 & 90.15 & 94.58 & 57.84 \\ PGD attack  & ICLR 2018 & 50.62 & 88.30 & 93.12 & 51.89 & 56.10 & 91.54 & 96.13 & 59.22 \\ M-FGSM attack  & TPAMI 2020 & 28.36 & 52.47 & 60.76 & 23.11 & 24.85 & 40.74 & 49.23 & 18.40 \\ LTA attack  & CVPR 2022 & 10.54 & 23.08 & 30.47 & 12.28 & 18.93 & 34.12 & 41.52 & 15.04 \\ ODFA attack  & IJCV 2023 & 27.75 & 50.26 & 59.14 & 22.30 & 17.62 & 32.64 & 40.03 & 14.83 \\ Col.+Del. attack  & TPAMI 2023 & 4.28 & 16.12 & 21.36 & 3.97 & 6.28 & 19.53 & 25.61 & 5.21 \\ Our attack & NeurIPS 2024 & 1.62 & 7.59 & 14.46 & 1.84 & 1.45 & 7.71 & 10.72 & 1.25 \\   

Table 1: Results for attacking cross-modality ReID systems on the SYSU  dataset. It reports on visible images querying infrared images and vice versa. Rank at \(r\) accuracy (%) and mAP (%) are reported. For the ”Visible to Infrared” scenario, we used the all-search mode. For the ”Infrared to Visible” scenario, we used the indoor-search mode.

    &  &  \\  Method & Venue & \(r=1\) & \(r=10\) & \(r=20\) & mAP & \(r=1\) & \(r=10\) & \(r=20\) & mAP \\  AGW baseline  & TPAMI 2022 & 70.05 & 86.21 & 91.55 & 66.37 & 70.49 & 87.21 & 91.84 & 65.90 \\ FGSM attack  & ICLR 2015 & 66.79 & 83.14 & 88.46 & 61.05 & 65.42 & 81.98 & 87.20 & 60.12 \\ PGD attack  & ICLR 2018 & 62.14 & 80.28 & 85.10 & 57.34 & 63.71 & 78.82 & 84.05 & 58.42 \\ M-FGSM attack  & TPAMI 2020 & 29.34 & 52.90 & 61.44 & 23.35 & 23.64 & 40.36 & 48.61 & 18.57 \\ LTA attack  & CVPR 2022 & 12.65 & 25.24 & 34.02 & 12.80 & 10.51 & 22.93 & 31.79 & 9.74 \\ ODFA attack  & IJCV 2023 & 28.57 & 51.42 & 60.58 & 21.84 & 17.26 & 33.27 & 42.92 & 15.27 \\ Col.+Del. attack  & TPAMI 2023 & 5.12 & 16.83 & 22.10 & 4.94 & 4.92 & 14.47 & 23.04 & 4.86 \\ Our attack & NeurIPS 2024 & 2.29 & 9.06 & 18.35 & 3.92 & 1.93 & 11.44 & 19.30 & 3.46 \\  DDAG baseline  & ECCV 2020 & 69.34 & 86.19 & 91.49 & 63.46 & 68.06 & 85.15 & 90.31 & 61.80 \\ FGSM attack  & ICLR 2015 & 61.83 & 80.12 & 86.47 & 55.78 & 60.94 & 78.35 & 84.09 & 56.91 \\ PGD attack  & ICLR 2018 & 64.58 & 81.39 & 87.20 & 58.45 & 62.17 & 79.02 & 85.27 & 57.69 \\ M-FGSM attack  & TPAMI 2020 & 30.86 & 54.16 & 61.98 & 24.01 & 25.83 & 42.12 & 49.76 & 19.33 \\ LTA attack  & CVPR 2022 & 11.65 & 23.20 & 32.73 & 11.41 & 9.76 & 21.53 & 29.96 & 9.23 \\ ODFA attack  & IJCV 2023 & 29.64 & 52.74 & 60.74 & 23.88 & 24.06 & 39.75 & 46.25 & 18.64 \\ Col.+Del. attack [27capable of achieving some level of attack effectiveness in cross-modality scenarios. However, by comparing Tab.1, Tab.2, and Tab.3, we observe that although Col.+Del. performs better than other methods, its effectiveness is still noticeably limited due to the lack of intrinsic correlation mechanisms between modalities. Moreover, as shown in Fig.6, our method outperforms Col.+Del. in transfer attacks across different baselines in cross-modality ReID. The conclusions from these experiments are as follows: 1) In cross-modality attacks, Col.+Del. demonstrates the feasibility of universal perturbations. However, its performance is limited by its failure to account for modality differences and inherent correlations. 2) Our method better bridges the gap between different modalities, more effectively capturing shared features across them.

### Transferability of CMPS

From Fig.6 in supplemental material, the results of the proposed method's transfer attacks on two baseline models, AGW and DDAG, can be observed. For example, on the SYSU dataset, the original attack result of the proposed method on DDAG is mAP=1.84% (refer to Tab. 1). When the perturbation is transferred from AGW to DDAG, the attack result becomes mAP=3.41%. This indicates that the proposed attack method exhibits good generalization across different models, and thus, the attack performance does not degrade significantly. This consistent result is observed on both the RegDB and SYSU datasets. Similarly, in Fig.7 of the supplemental material, we evaluate the cross-dataset transferability of perturbations in comparison with Col.+Del. The results demonstrate a significant advantage of our method. Additionally, we conducted adversarial transferability experiments on IDE , PCB , and ResNet18 . The rank-1 transfer attack success rates are presented in Tab.4. It can be observed that our method consistently achieves higher transfer attack success rates across all model combinations compared to Col.+Del., indicating that our method demonstrates stronger robustness in generating more universal adversarial perturbations.

### Ablation Study

Our method is implemented based on UAP-Retrieval . To validate the effectiveness of the proposed method, we conducted experiments by adding augmentation (Cross-Modality Attack Augmentation) and CMPS to the baseline. Results with AGW baseline model are reported in Tab. 5. The No.1 line represents the UAP-Retrieval algorithm. In the table, 'Aug' indicates the use of the Cross-Modality Attack Augmentation proposed in this paper.

**The effectiveness of CMPS**. Comparing No.1 with No.3 and No.4, we observe the following: 1) The direct use of UAP-Retrieval's yields limited performance. 2) Training with the CMPS strategy

   Source Target Model & IDE (Ours/Col.+Del.) & PCB (Ours/Col.+Del.) & ResNet18 (Ours/Col.+Del.) \\  IDE  & 98.7\% / 94.3\% & 84.5\% / 81.2\% & 87.4\% / 86.1\% \\ PCB  & 85.1\% / 80.4\% & 97.6\% / 92.8\% & 88.3\% / 85.7\% \\ ResNet18  & 81.0\% / 78.5\% & 77.5\% / 74.9\% & 98.2\% / 95.6\% \\   

Table 4: Comparison of transfer attack success rates between our method and Col.+Del. across models, with higher values indicating better transferability.

    &  &  \\  Method & Venue & \(r=1\) & \(r=10\) & \(r=20\) & mAP & \(r=1\) & \(r=10\) & \(r=20\) & mAP \\  DEEN baseline  & CVPR 2023 & 62.53 & 90.31 & 94.73 & 65.84 & 54.96 & 84.92 & 90.91 & 62.95 \\ M-FGSM attack  & TPAMI 2020 & 28.48 & 64.92 & 75.12 & 32.88 & 25.64 & 61.45 & 78.31 & 30.46 \\ LTA attack  & CVPR 2022 & 15.16 & 56.42 & 67.53 & 21.47 & 19.54 & 58.25 & 70.72 & 24.86 \\ ODFA attack  & IJCV 2023 & 26.34 & 65.24 & 76.92 & 30.85 & 23.73 & 62.46 & 73.57 & 29.63 \\ Col.+Del. attack  & TPAMI 2023 & 8.61 & 22.73 & 36.07 & 15.72 & 9.13 & 20.76 & 38.02 & 16.31 \\ Our attack & NeurIPS 2024 & 5.83 & 18.14 & 27.56 & 12.47 & 6.42 & 19.53 & 28.54 & 12.23 \\   

Table 3: Results for attacking cross-modality ReID systems on the LLCM  dataset. It reports on visible images querying thermal images and vice versa. Rank at \(r\) accuracy (%) and mAP (%) are reported.

proposed in this paper consistently improves the performance of attack results and the universality of learned perturbations.

**The effectiveness of augmentation method**. Our approach includes cross-modality attack augmentation. Comparing results of No.1, No.2, and No.4 shows its benefits. For example, on the RegDB dataset, augmentation (No.2) reduces mAP from 6.87% to 5.11%, 1.76% lower than without augmentation (No.1). Similarly, with CMPS, mAP drops from 3.98% to 3.46% (No.4), a 0.52% decrease compared to No.3. These findings suggest that using appropriate augmentation enhances cross-modality ReID adversarial attacks' universality. If not specified, our experiments default to using CMPS augmentation. Fig. 5 in the supplementary materials displays the experimental results of our augmentation performed at different probabilities. It can be observed that when the probability value is around 20%, it achieves optimal effectiveness in assisting the attack. If not specified, a probability value of 20% for augmentation is used by default in experiments.

**Impact of adversarial boundary size.** We conducted an ablation study on different adversarial boundary sizes (\(\)), as shown in the supplementary material 6. In practical applications, \(\) is typically kept moderate to balance perturbation visibility and attack effectiveness. To maintain consistency with previous work , we set \(=8\) for comparison unless otherwise specified.

## 5 Conclusion

In this study, we have proposed a cross-modality attack method known as Cross-Modality Perturbation Synergy (CMPS) attack, aimed at evaluating the security of cross-modality ReID systems. The core idea behind the CMPS attack is to capture shared knowledge between visible and non-visible images to optimize perturbations. Additionally, we proposed a Cross-Modality Attack Augmentation method, utilizing grayscale images to bridge the gap between different modalities, further enhancing the attack performance. Through experiments conducted on the RegDB, SYSU and LLCM datasets, we demonstrated the effectiveness of the proposed method while also revealing the limitations of traditional attack approaches. The primary objective of this study has been to assess the security of cross-modality ReID systems. In future research, on the one hand, we will continue to improve the transferability of cross-modality attacks across different datasets and models; on the other hand, we plan to develop robust ReID methods specifically tailored for cross-modality attacks, aimed at defending against adversarial samples. This study not only contributes to advancing the understanding of the security of cross-modality ReID systems but also provides strong motivation for ensuring the reliability and security of these systems in real-world applications.