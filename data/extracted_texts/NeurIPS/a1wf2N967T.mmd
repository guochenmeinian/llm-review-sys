# Graph-based Unsupervised Disentangled Representation Learning via Multimodal Large Language Models

Baao Xie\({}^{1}\) Qiuyu Chen\({}^{1,2}\) Yunnan Wang\({}^{1,2}\) Zequn Zhang\({}^{1,3}\) Xin Jin\({}^{1,*}\) Wenjun Zeng\({}^{1}\)

\({}^{1}\)Ningbo Institute of Digital Twin, Eastern Institute of Technology, Ningbo, China

\({}^{2}\)Shanghai Jiao Tong University, Shanghai, China

\({}^{3}\) University of Science and Technology of China, Hefei, China

bxie@idt.eitech.edu.cn jinxin@eitech.edu.cn

*Xin Jin is the corresponding author. Code is available at here.

###### Abstract

Disentangled representation learning (DRL) aims to identify and decompose underlying factors behind observations, thus facilitating data perception and generation. However, current DRL approaches often rely on the unrealistic assumption that semantic factors are statistically independent. In reality, these factors may exhibit correlations, which off-the-shelf solutions have yet to properly address. To tackle this challenge, we introduce a bidirectional weighted graph-based framework, to learn factorized attributes and their interrelations within complex data. Specifically, we propose a \(\)-VAE based module to extract factors as the initial nodes of the graph, and leverage the multimodal large language model (MLLM) to discover and rank latent correlations, thereby updating the weighted edges. By integrating these complementary modules, our model successfully achieves fine-grained, practical and unsupervised disentanglement. Experiments demonstrate our method's superior performance in disentanglement and reconstruction. Furthermore, the model inherits enhanced interpretability and generalizability from MLLMs.

## 1 Introduction

Disentangled representation learning (DRL) is a major goal of artificial intelligence (AI), acclaimed for its enhancement of model robustness, interpretability, and generalizability. Essentially, DRL methods imitate the understanding processes of biological intelligence, wherein comprehension of real-world is achieved by separating observations into distinct factors . In this form, specific attributes (e.g., object color, shape, and size) exhibit exclusive sensitivity to the changes of specific factors. Learning of such disentangled representations is of great importance across various domains, e.g., computer vision [2; 3; 4; 5; 6], natural language processing [7; 8; 9], and AI generated content [10; 11; 12; 13]. In the current phase, unsupervised DRL methods primarily utilize the Variational Autoencoder (VAE) framework , a probabilistic model learning representations through a regularization term. This term involves the Kullback-Leibler divergence between the posterior distribution of latent factors and a standard multivariate Gaussian prior, thereby encouraging the factorized representations. To strengthen disentanglement, co-current research [15; 16; 17; 18] focus on the optimization and refinement of the original VAE regularizers, resulting in the family of VAE-based DRL approaches.

Despite the advanced results of the simple and synthetic datasets, VAE-based DRL methods still fall short in interpretability and robustness that are required for effective disentanglement in complex data . This limitation mainly stems from the unrealistic assumption that underlying factorsare countable, independent, and can be fully disentangled in an unsupervised manner (refer to the top-left of Figure 1). In contrast, the real-world variables are pervasively correlated: red apples are more common than yellow ones; elderly people are more frequent with white hair and a receding hairline. Accordingly, an increasing number of recent studies [20; 21; 19; 22] showcases that purely unsupervised DRL is fundamentally impossible without extra priors and inductive biases.

The struggle of typical DRL methods on the complex data returns us back to the essential goal of DRL, i.e., understanding the world as biological intelligence does. This cognitive process can be naturally segmented into three phases: attribute extraction, interrelation perception, and knowledge combination [23; 24], where the latter two stages should not be neglected. From this perspective, several structured DRL approaches, typically known as Hierarchical DRL [25; 26; 12] and Causal DRL [21; 27; 28; 29], have involved the correlations between attributes. However, these approaches usually require extra supervision, and their relations are invariably represented by binary and unidirectional fusion, thus limiting the model performance in practical scenarios (refer to the bottom-left of Figure 1). Inspired by the analysis above, we argue that an effective and practical disentanglement framework should meet the following criteria: (i) the framework should be fully unsupervised; (ii) the framework should be able to disentangle factors while concurrently discovering logical interrelations among them; (iii) the interrelations should be modeled as bidirectional, with corresponding impact scores assigned to each, thereby improving model performance in complex scenarios. On this basis, we propose a novel **G**raph-based **dis**E**ntanglement framework with **M**ultimodel large language models, dubbed **GEM**. Specifically, our model employs two complementary branches: a \(\)-VAE based disentanglement branch for the attribute extraction, and a multimodal large language model (MLLM) based branch for the interrelation discovery. The relation-aware representations are further embedded into a disentangled bidirectional weighted graph (DisGraph), which presents distinct factors as nodes, interrelations as edges, and impact scores as weights. The parameters of the graph are dynamically updated and refined via a graph learner. The experimental results show that GEM achieves superior performance on fine-grained and relation-aware disentanglement, while preserving the reconstruction quality. Furthermore, the model is endowed with superior interpretability and generalizability that derived from MLLMs. All in all, our main contributions can be summarised as:

* To our best knowledge, we are the first to leverage the commonsense reasoning of MLLMs to discover and rank the semantic interrelations from the perspective of DRL.
* We propose a novel and practical disentanglement framework built upon \(\)-VAE and MLLMs to learn the independent factors and their interrelations in an unsupervised way.
* We introduce a bidirectional and self-driven graph architecture to encode the relation-aware representations, thus facilitating practical and controllable disentanglement.

## 2 Related Work

### Standard Disentangled Representation Learning

The definition of DRL is intuitively given by Bengio et al.  as a technique to separate semantic factors behind observational data. This approach assumes that individual data attributes are sensitive to changes in single latent factors, while not being affected by other factors. The disentanglement of

Figure 1: The comparison of typical DRL frameworks with our GEM. The limitations of conventional DRL methods are presented on the left. Conversely, the right-hand side illustrates the advantages of our framework, which benefited from the integration of the \(\)-VAE and MLLMs.

attributes is believed helpful for downstream tasks, e.g., generative models [3; 30; 5; 31; 32], medical imaging [33; 34; 35], image editing [36; 37; 38; 39], and 3D reconstruction [40; 41; 42].

Traditional DRL methods primarily utilizes the VAE framework, achieving a measure of disentanglement on static datasets. This framework has been further enhanced by extensive models such as \(\)-VAE , \(\)-TCVAE , DIP-VAE , FactorVAE , RF-VAE , and \(\)-TCVAE  through the optimizations of regularization terms. Despite the successes on simple and static datasets, standard DRL approaches still encounter challenges in complex data. It is mainly due to the flat and unrealistic assumption: data properties are independent and can be factorized into distinct factors [1; 21; 45; 46]. Locatello et al.  have proven that unsupervised DRL is fundamentally impossible without extra priors. Thus, subsequent studies have demonstrated that a practical DRL model with appropriate inductive biases can enhance the disentanglement in real scenes [47; 48; 49; 50].

### Structured Disentangled Representation Learning

In contrast to the flat and VAE-based DRL methods, recent research gradually realize that latent factors might naturally involve semantic interrelations, deriving to the branch of structured disentangled representation learning . Within this domain, Hierarchical DRL and Causal DRL are mostly relevant to our work. Hierarchical DRL presumes that underlying factors have different levels of semantic abstraction, either dependent  or independent  across levels. While straightforward, Li et al.  propose a hierarchical VAE-based model to learn semantic representations. Furthermore, Singh et al.  introduce FineGAN, a three-tier hierarchical framework for controllable object generation. Li et al.  also propose a hierarchical DRL framework aimed at facilitating image-to-image translation. Differently, our framework aims to achieve fine-grained disentanglement, where the targeted attributes are always flat, e.g., the wrinkle, lipstick, and mustache of faces. Therefore, we rely on the flat representations, but place a strong emphasis on the mutual relations between attributes.

Similarly, Causal DRL methods endeavor to capture the causal relations between disentangled factors. As the first, Yang et al.  propose CausalVAE to discover relations from the perspective of causality. Further, Shen et al.  propose a weakly supervised framework DEAR with the structured causal model (SCM) as prior. However in our view, current Causal DRL methods have at least three unpractical issues: (i) rely on various degrees of supervision; (ii) aim to model a specific event rather than a common scenario; (iii) the causal relationship is often overly simplistic, being impractically binary and unidirectional, i.e., paired variables A and B only have two possible causal relations: either A \(\) B or A \(\) B (otherwise unrelated). In practical, it is common for paired variables to exhibit bidirectional influence, and the impact of such bidirectional relations should be properly ranked.

### Multimodal Large Language Models

Recent years have witnessed the remarkable advancements in Multimodal Large Language Model (MLLM) [53; 54; 55; 56]. Since the release of Generative Pre-trained Transformer (GPT) , there has been a research trend over MLLMs regarding to its demonstrated potential in processing multimodal data [58; 59; 60]. As the variants of GPT-4, GPT-4 with Vision (GPT-4V)  and GPT-4 omni (GPT-4o)  enhance to process textual and visual data, enabling richer, context-aware interactions across a range of multimodalities. Concurrently, following works such as Gemini , Claude , NExT-GPTs  and GLM-4  have strengthen the support to additional modalities.

The powerful capacities of MLLMs gradually make researchers aware of its latent perceptual knowledge embedded within networks. Gandelsman et al.  investigate the way that CLIP encoder understands visual data, by decomposing representations into individual components. In addition, Basu et al.  propose a mechanistic localization approach to explore how the visual properties are encoded in MLLMs. However, to our best knowledge, there is limited exploration into leveraging the commonsense reasoning of MLLMs from the perspective of DRL. And we are the first to employ MLLMs to discover and rank interrelations between semantic factors in the DRL framework.

## 3 Methodology

To achieve fine-grained and relation-aware disentanglement, we propose GEM, a novel and practical framework that synergizes the strengths of DRL and MLLMs by a bidirectional weighted DisGraph. As depicted in Figure 2, GEM is comprised of two complementary modules: a \(\)-VAE based branch dedicated to extract attributes (Section 3.1), and a MLLM-based branch to discover and rank interrelations (Section 3.2). The relation-aware representations are then embedded into the DisGraph (Section 3.3), which presents factors as nodes, interrelations as edges, and impact scores as weights.

### \(\)-VAE based Attribute Determining Branch

The fundamental objective of vanilla VAE is to approximate data distributions by employing a maximum likelihood estimation framework as outlined in Eq. 1:

\[ p_{}()=D_{KL}(q_{}(|)\|p_{ }(|))+(,),\] (1)

where the variational posterior distribution \(q_{}(|)\) is utilized to represent the probability distribution of the latent variable \(z\) given the observation \(x\). The key of Eq. 1 is maximizing the approximation log \(p_{}()\) of the true posterior distribution \(p_{}(|)\) and \(q_{}(|)\).

Specifically, the first term of Eq. 2 corresponds to the Kullback-Leibler (KL) divergence measuring the distance between distribution \(q_{}(|)\) and \(p_{}(|)\). The second term is denoted as the variational evidence lower bound (ELBO). Empirically, the maximization of ELBO is employed to provide a stringent tight lower bound for the original log-likelihood log \(p_{}()\). ELBO can be reformulated as:

\[(,)=_{q_{}(|)}[  p_{}(|)]- D_{KL}(q_{}( |)\|p_{}()),\] (2)

where the initial term, i.e., conditional logarithmic likelihood \(_{q_{}(|)}[ p_{}(| )]\) is responsible for the reconstruction. Typically, the latent variable \(z\) is assumed to follow a standard Gaussian distribution \((0,1)\) for \(p_{}(z)\), so that the KL term actually imposes independent constraints on the representations. Furthermore, subsequent studies  highlight that a extra penalty coefficient prior to the KL term, denoted by \(\), can significantly strengthen disentanglement. When \(\) is set to 1, the \(\)-VAE reverts to the standard VAE framework. And an increase in \(\) encourages more disentangled representations but harms the performance of reconstruction as a trade-off. As per the Information Bottleneck (IB) theory , constraining the information input to DRL models (e.g., via \(\) penalty coefficient) inherently enables them to identify and learn the most representative factors for successful reconstruction. For instance, when trained on the Shapes3D (a collection of synthetic objects) with a merely three-dimensional latent variable, the attribute determining branch tends to learn the most critical factors, observed to be "object color", "object shape", and "background shape". These attributes are organized in the three dimensions, ordered by their reconstruction contribution.

Specifically, within the processes of this branch, the input image is firstly subjected to a pre-processing step utilizing landmark detection functions as instructed by  and  (see Figure 2). It serves as a regularization phase, to remain the key features through targeted cropping. Additional derivations of this process are documented in the appendix. Then, the pre-processed \(I_{0}\) is fed into a \(\)-VAE based branch, designed to disentangle factors associated with each dimension in the latent variable \(z Z\). However, the input of decoder \(D_{rec}\) is the relation-aware variable \(z_{rel}=^{T}z\) from the DisGraph, rather than the \(z\). It means the prior assumption of \(p_{}(z)(0,1)\) is no longer hold. To address this issue, we reformulate the loss function in \(\)-VAE as follows:

\[L_{gem}(,,)=D_{}(q_{}(x,z),p_{,}(x, z))\] (3)

\[_{}L_{gem}(,,)(z)}{=}-E_{z  q(z)}_{x}[((x,z)}{q_{}(x, z)})]_{}x\] (4)

Figure 2: Pipeline of our GEM. The model consists of two complementary branches, termed as a \(\)-VAE branch (blue) and a MLLM branch (brown). The former utilizes \(\)-VAE based semantic encoder \(E_{sem}\) to disentangle underlying factors, while the latter employs prompt engineering to discover and rank interrelations. The bidirectional weighted DisGraph \(G\) is further proposed to embed relation-aware representations, with its parameters optimized constantly by a GNN network \(E_{gnn}\).

\[_{}L_{gem}(,,) (x)}}{{=}}E_{x p(x)}_{z} [((x,z)}{q_{}(x,z)})]_ {}z\] (5) \[_{}L_{gem}(,,) (z)}}{{=}}E_{x p(x)} _{z}[((x,z)}{q_{}(x,z)}) ]_{}z\] (6)

where the \(\), \(\) and \(\) are the learnable parameters of \(E_{sem}\), \(D_{rec}\) and DisGraph \(G\), respectively. Let's say \(D(x,y)=((x,z)}{ q_{}(x,z)})\), and the the gradients with respect to \(x\) and \(z\) can be obtained during backpropagation by the cross-entropy:

\[_{adv}=_{D(x,y)}=N_{m}}[_{i=0}^ {N_{bc}}(-D(x_{i},z_{i}))+_{i=0}^{N_ {bc}}(D(x_{i},z_{i}))]\] (7)

where \(N_{bc}\) and \(N_{m}\) represent the number of samples and the posterior samples in a batch, respectively. Obviously, this loss resembles the adversarial loss utilized in Generative Adversarial Networks (GAN) . Therefore, we employ the adversarial training strategy to optimize \(D(x,y)\). Combined with the disentanglement term from the original \(\)-VAE indicated as \(_{dis}\), the total loss for the attribute determining branch can be expressed as:

\[_{total}=_{adv}_{adv}+_{dis}_{ dis}+_{gem}_{gem}\] (8)

where the \(_{adv}\), \(_{dis}\) and \(_{gem}\) serve as hyperparameters to balance the disentanglement capability and reconstruction quality, with default values set to 0.8, 0.6 and 0.6, respectively. The detailed derivation process of the adversarial training strategy is provided in the supplementary material.

### MLLM-based Interrelation Discovery Branch

Given a pre-processed image \(I_{0}\) with \(n\) targeted attributes \(=\{1,2,3,...,n\}\) initialized by the \(\)-VAE branch, our objective is to discover and rank the mutual relations for each pair within \(\). As represented by the brown blocks in Figure 2, we employ MLLMs as a relation predictor \(P_{rel}\) to discover and rank interrelations. Initially, the MLLM is required to score from 0 to 5 for each attribute, where 0 indicates the attribute's absence, and 5 denotes its highest expression. As shown in Figure 3, the queries can be formulated as a question in natural language with the input image \(I_{0}\).

Based on the attribute scores, we subsequently employ Somers' D algorithm  to rank the bidirectional impact scores of interrelations. For the attribute pair (\(A_{i}\),\(A_{j}\)), we determine the number of concordant pairs \(N_{C}\) and discordant pairs \(N_{D}\), as delineated by Kendall's Tau  algorithm. Subsequently, the impact score \(_{ij}\) within \(=\{1,2,3,...,k\}\) can be denoted as:

\[_{ij}=-N_{d}}{N_{c}+N_{d}+T_{i}}\] (9)

For the reversed relation of \((A_{i},A_{j})\), the impact score can be denoted as \(_{ji}\) or \(^{}_{ij}\):

\[^{}_{ij}=_{ji}=-N_{d}}{N_{c}+N_{d}+T_{j}}\] (10)

where \(T_{i}\) and \(T_{j}\) is the number of ties only for the independent variable \(A_{i}\) and \(A_{j}\), respectively. The calculated \(\) and \(^{}\) are used for initialization and refinement of DisGraph (see Section 3.3). As illustrated in Figure 4, it is important to clarify that the primary goal of the MLLM branch in GEM is to discover interrelations, where the statistical relativity between two attributes is of primary concern, rather than the absolute scores for the individual attribute. For example, given a collection of facial images, it is acceptable if the scores of "age" and "bald" exhibit a positive correlation, even if the specific score values are fluctuating. To ascertain the reliability of MLLMs for interrelation discovery, extra experiments are performed as shown in Section 4.4.

Figure 3: A simplified example of the template for prompting MLLMs to evaluate attributes. Specifically, <text> is the interactive token, while <BOS> and <EOS> are tokens denoting the start and end of the input to MLLMs, respectively.

### Bidirectional Weighted DisGraph

Based on the extracted factors and interrelations, we then propose the bidirectional weighted DisGraph \(=(,,)\) to integrate the semantic representations. Specifically, \(\) is the set of \(n=||\) nodes, embodying the disentangled attributes as factors. Besides, \(\) is the set of \(k=||\) edges, and \(\) stands for the weights of these edges. An \(e\) and its corresponding impact score \(s\) are embedded. Consequently, \(\) can be presented as the learnable weighted adjacency matrix \(^{n n}\).

According to the definitions above, the model firstly constructs a sketched adjacency matrix \(_{0}^{n n}\) upon the factors and relations initialized by the \(\)-VAE branch and MLLM branch. Specifically, we treat the averaged impact scores of the first 1,500 images processed by MLLMs, as initial weights of relations. We further employ an unsupervised graph learner \(E_{gnn}\) to dynamically refine the parameters of DisGraph by the structure bootstrapping mechanism  and multi-view graph contrastive learning . The optimization function of \(E_{gnn}\) can be formulated as:

\[^{(l)}=h_{w}^{(l)}(^{(l-1)},)= (}^{-}} }^{-}^{(l-1)}^{(l)}),\] (11)

It converts the sketched adjacency matrix \(_{0}\) into node embedding \(\) via the GNN-based multilayer network, where \(h_{w}^{(l)}()\) is the embedding function with learnable parameters \(w\) of the \(l\)-th layer and \(^{(l)}\) is the output matrix. The augmented adjacency matrix \(}=+\) incorporates self-loops based on the initial matrix \(_{0}\), and \(}\) is the degree matrix of \(\). Further, \(w^{(l)}=^{(l)}^{n n}\) denotes the parameter matrix of the \(l\)-th layer, with \(()\) as a non-linear function that enhances training stability.

Figure 5 illustrates the comprehensive training algorithm of our model. The encoder processes input images and outputs the disentangled latent variable \(z\), which subsequently initializes the embeddings of nodes in DisGraph. The adjacency matrix of DisGraph is calculated using Somer's D algorithm, which processes the attribute scores outputted by the MLLM. Following this initialization, a Graph Neural Network (GNN) refines the structure of DisGraph. The average of the feature matrix within DisGraph is then forwarded to the decoder to reconstruct images. Concurrently, the discriminator is trained to approximate the gradient of the loss function. Assuming that the model's performance is upper bounded by the norm of its gradient, which satisfies the Polyak-Lojasiewicz (PL) condition, this configuration ensures the suboptimality of the model.

Figure 4: Our aim is using the commonsense knowledge behind MLLMs to equip GEM with ability of interrelations discovery, where a certain degree of fluctuations on absolute scores are acceptable.

Figure 5: Overall training algorithm of GEM.

Experiments

**Datasets.** We evaluate the GEM on two datasets: 1) **CelebA** contains over 200,000 high-quality facial images. Each image is annotated with 40 binary attribute labels, making it a widely used benchmark for supervised DRL methodologies. Operating in an unsupervised manner, we do not utilize ground-truth labels from this dataset, yet we still conduct comparisons against the supervised approaches; 2) **LSUN** consists of about one million images across various object categories such as cars, buildings, animals, etc. We select a typical subset from both scene categories and object categories, as bedroom and horse, respectively. We believe these two datasets are diverse enough to assess our method covering complex data of different object types.

**Implementation details.** We implement GEM with PyTorch . The landmark pre-processing settings follow the instructions of  and . In addition, we employ the latest GPT-4o  as the interrelation predictor. For every experiment, the latent dimension size is set to 6. Concentrating on the disentanglement capacity of the framework, all experimental images are resized to a resolution of 64\(\)64 to minimize computational resources. For high-definition outcomes at 256\(\)256, refer to Appendix A.7. All the experiments are processed using the Adam optimizer with a learning rate of 1e-4, and conducted on the Nvidia Tesla A100 GPUs, with a batch size of 32.

**Baselines for Comparison.** We evaluate the GEM with state-of-the-art DRL methods on the disentanglement capacity, reconstruction quality, and computational efficiency. The comparison encompasses supervised and unsupervised models, including standard VAE , \(\)-VAE , \(\)-TCVAE , FactorVAE  and DEAR . All baselines are trained using the complete CelebA dataset under the configurations previously specified.

### Qualitative Results

To evaluate the GEM's effectiveness of relation-aware and fine-grained disentanglement, we perform qualitative analyses with FactorVAE  and DEAR . The experiments are conducted on CelebA, a standard benchmark that has been previously validated as compatible with these methods. We select the six fine-grained facial attributes from the database including _Bangs_, _Bald_, _Gender_, _Beard_, _Blond_, and _Makeup_. The disentanglement results are represented by traversals across various latent dimensions, where each dimension corresponds to distinct attributes.

Figure 6: Qualitative comparisons between GEM and typical DRL Methods. Each row in facial images corresponds to the traversal results on a specific attribute, as indicated adjacent to the images (i.e. _Bangs_, _Bald_, _Gender_, _Beard_, _Blond_, and _Makeup_). GEM exhibits superior ability in fine-grained disentanglement with discovered practical and bidirectional relations (illustrated by the heatmap).

As illustrated in Figure 6, GEM effectively achieves fine-grained and relation-aware disentanglement, via the integration of DRL and MLLMs. The interrelations determined by MLLMs are depicted as a heatmap in the bottom-right of Figure 6, where deeper colors reflect stronger relations. Since DisGraph is bidirectional, the impact scores for bidirectional relations between a pair of attributes may vary, resulting in an asymmetric matrix. Specifically, in the first row of GEM's result, a person with heavier _Bangs_ is less likely to be _Bald_, and the hair tends to be _Blond_, which is considered logical by MLLMs. Furthermore, as shown in the second and third rows, males (_Gender_) are more likely to be _Bald_ and less likely to have _Blond_ hair. The attribute _Makeup_ is considered as relatively independent, with lower impacts scores among other attributes.

In comparison, DEAR demonstrates limitations in learning specific attributes such as _Bald_ (second row) and _Gender_ (third row), while the relations between attributes appear to be tenuous. To our knowledge, this underperformance may stem from the stringent nature of causal relations, which are single-directional and heavily rely on the quality of prior. For FactorVAE, since it is a flat DRL framework, we employ the same causal relations used in DEAR to make it relation-aware. As shown in Figure 4, GEM surpasses FactorVAE in both attribute disentanglement and relation discovery, which indicates the importance of specially-designed modules within our framework.

### Quantitative Results

Table 1 reports the results of Frechet Inception Distance (FID)  and Kernal Inception Distance (KID)  scores to verify the quality of reconstructed images. To ensure statistical significance, each comparison model undergoes three rounds of evaluations in the same configuration. The results indicate that GEM outperforms both typical unsupervised (VAE, \(\)-VAE, \(\)-TCVAE, FactorVAE) and supervised approaches (DEAR) in terms of reconstruction quality. To our understanding, this superior performance is attributed to the specialized training strategy implemented in the framework.

As shown in Table 1, GEM surpasses baseline models in reconstruction quality on the datasets of CelebA, LSUN-horse, and LSUN-bedroom. However, the use of the disentanglement coefficient in the \(\)-VAE branch leads to an inevitable trade-off in reconstruction quality, making the model less comparable to the models focused on generation quality (e.g., GAN and Diffusion ). Therefore, the integration with leading generative models can be a direction for our future work. For additional comparison results, please refer to Appendix A.1.

Furthermore, we evaluate four relation-aware models: FactorVAE, DEAR, GEM (Single), and GEM (Full), on quantitative comparisons of computational resources. Notably, GEM (Single) is the variant of GEM that incorporates single attribute determination branch (we only provide the initial relations to make it relation-aware). Table 2 shows that GEM outperforms DEAR and is comparable to FactorVAE on computational efficiency. This is mainly attributed to FactorVAE's utilization of a simple convolutional encoder, whereas GEM employs a \(\)-VAE based encoder to strengthen disentanglement. In addition, the efficiency of full GEM is slightly inferior to GEM (Single), due to the extra modules for relation discovery and refinement.

    &  &  &  \\   & FID \(\) & KID \( 10^{3}\) & FID \(\) & KID \( 10^{3}\) & FID \(\) & KID \( 10^{3}\) \\  VAE  & \(53.3 0.6\) & \(51.4 0.4\) & \(172.8 1.7\) & \(181.7 2.1\) & \(195.8 4.1\) & \(226.4 5.4\) \\ \(\)-VAE  & \(136.2 1.6\) & \(107.0 2.7\) & \(272.4 3.2\) & \(294.2 5.3\) & \(288.1 5.7\) & \(225.7 6.0\) \\ \(\)-TCVAE  & \(139.1 0.8\) & \(113.2 4.1\) & \(173.0 4.8\) & \(217.35 9.2\) & \(191.0 5.0\) & \(179.2 7.4\) \\ FactorVAE  & \(134.5 0.3\) & \(92.0 0.5\) & \(248.5 5.5\) & \(155.3 3.7\) & \(235.7 3.2\) & \(172.8 3.9\) \\ DEAR  & \(70.7 0.3\) & \(52.6 0.1\) & \(136.4 1.6\) & \(113.7 0.9\) & \(177.6 3.5\) & \(157.8 2.3\) \\
**GEM (Ours)** & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Quantitative comparison results with typical DRL approaches in FID and KID.

  
**Models** & Params(M) & GFLOPs(B) & Mem(M) & TT(s) \\  FactorVAE & 55.9 & 3.8 & 200.5 & 63.9 \\ DEAR & 53.4 & 3.5 & 267.2 & 91.8 \\ GEM (Single) & 44.7 & 2.8 & 173.6 & 51.5 \\
**GEM (Full)** & 49.6 & 3.2 & 222.8 & 78.9 \\   

Table 2: Computational efficiency report in parameters size, FLOPs, memory cost and training time.

### Evaluations of Interpretability and Generalizability

As a by-product, GEM inherits the interpretability and generalizability of MLLMs. Theoretically, owing to the commonsense reasoning faculties of MLLMs, our model can be generalized to discover any attributes and interrelations across various real-world objects and scenes. To demonstrate the robustness and generalizability of GEM, we perform extra experiments on more complex scenes in LSUN, specifically targeting the typical object subset LSUN-horse and the scene subset LSUN-bedroom. Furthermore, we test the attributes beyond the 40 specified in CelebA, collectively showcasing the model's superiority. To highlight the characteristics of bidirectional weighted DisGragh, we intentionally select paired fine-grained attributes exhibiting inconsistent bidirectional relations.

As depicted in Figure 7, GEM successfully achieve fine-grained disentanglement on complex scenes, while identifying bidirectional and weighted relations among attributes. Furthermore, the artifacts observed in the results of LSUN datasets are mainly due to the datasets' clutter (evidenced by the increase of FID and KID scores in Table 1). Nonetheless, despite the ambiguous and challenging nature of the data, GEM still obtain commendable disentanglement outcomes, affirming its robustness.

### Evaluations of MLLMs

Our model leverages the commonsense knowledge embedded in MLLMs to predict interrelations. This is predicated on the assumption that MLLMs, including their future iterations, are powerful and reliable enough to comprehend the physical rules of the real world (e.g., aging brings wrinkles, sunrise brings light, etc.). Therefore, before utilizing the interrelation discovery branch, it is imperative to evaluate the reliability of MLLMs. This evaluation guarantees that the identified interrelations and their associated impact scores are dependable and can be effectively applied to downstream modules. To this purpose, we evaluate three latest MLLMs including GPT-4o, GPT-4v and GLM-4--against the ground truth attributes of the CelebA dataset. The horizontal axis presents the targeted attributes selected from the CelebA, where the vertical axis presents the percentage of scoring accuracy.

Figure 8: Evaluation experiments on the various MLLMs for attributes scoring.

Figure 7: Relation-aware disentanglement results on LSUN and the attributes beyond CelebA. Paired fine-grained attributes with inconsistent bidirectional relations are chosen to indicate effectiveness.

As reported in Figure 8, GPT-4o outperforms other models on individual attribute scoring, achieving accuracy exceeding 90% for the majority of attributes. Specifically, it exhibits superior performance on attributes like _Beard_, _Young_, and _Eyebrows_, where other models yield significantly lower scores. In addition, GPT-4o achieves the highest average accuracy of 88.4% and the lowest zero-scoring rate at 0.25%, indicating a minimal rate of the meaningless predictions where all attributes are scored as zero. We conducted further evaluations on individual attributes, where GPT-4o also demonstrated superior performance (see Appendix A.7). Based on the evaluations, we employ GPT-4o as the interrelation predictor in the model.

### Ablation Study

To analyze the effectiveness of individual components in GEM, we perform an ablation study focusing on the importance of the \(\)-VAE based branch, GNN-based graph learner \(E_{gnn}\), and adversarial training strategy. The CelebA dataset served as the experimental platform for the investigations. It is worth noting that the complete removal of \(\)-VAE branch is infeasible, as it would prevent the model from extracting attributes. Therefore to evaluate the importance of independent attribute extraction, we replace the \(\)-VAE with the vanilla VAE, which does not enforce the independence of factors.

As depicted in Figure 9, replacing \(\)-VAE encoder results in a declined disentanglement capability, albeit with an improvement in reconstruction quality. In addition, the removal of GNN-based graph learner prevents the parameter updating of DisGraph, leading to the inaccurate determination of relations (e.g., the relation between _Bald_ and _Gender_ weakens). It is worth noting that the removal of both graph learner and initialization process within the framework precludes the learning of interrelations. Furthermore, eliminating the adversarial training strategy in GEM and relying solely on the standard VAE loss function results in a significant decline in reconstruction quality. The aforementioned results highlight the effectiveness of each part of our framework.

## 5 Conclusion

In this paper, we aim to explore the logical interrelations between semantic attributes within complex data, which is a critical challenge that existing DRL have yet to properly address. To this end, we introduce GEM, a \(\)-VAE and MLLMs-based framework, designed to achieve fine-grained and relation-aware disentanglement. In this framework, DRL and MLLMs are integrated via a bidirectional and self-driven graph. Both qualitative and quantitative experiments demonstrate GEM's superior disentanglement and reconstruction capacities over typical DRL models. In addition, the model shows its enhanced interpretability and generalizability inherited from MLLMs.

## 6 Acknowledgments

This research is supported by the IDT Foundation of Youth Doctoral Innovation [Grant S203.2.01.32.002], the National Natural Science Foundation of China [Grant 62302246] and the Zhejiang Provincial Natural Science Foundation of China [Grant LQ23F010008].

Figure 9: Ablation on replacing \(\)-VAE with VAE, w/o graph learner, and w/o adversarial strategy.