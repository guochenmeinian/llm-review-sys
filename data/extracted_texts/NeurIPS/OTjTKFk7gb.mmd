# AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games

Kefan Su1,2,*, Yusen Huo2, Zhilin Zhang2, Shuai Dou2, Chuan Yu2, Jian Xu2,

Zongqing Lu1, Bo Zheng2

1School of Computer Science, Peking University

2Alibaba Group

2{sukefan,zongqing.lu}@pku.edu.cn

2{huoyusen.huoyusen,zhangzhilin.pt,doushuai.ds,

yuchuan.yc,xiyu.xj,bozheng}@alibaba-inc.com

This work is done during internship at Alibaba Group.Corresponding author.Alibaba Group retains full ownership rights to this benchmark.

###### Abstract

Decision-making in large-scale games is an essential research area in artificial intelligence (AI) with significant real-world impact. However, the limited access to realistic large-scale game environments has hindered research progress in this area. In this paper, we present AuctionNet, a benchmark for bid decision-making in large-scale ad auctions derived from a real-world online advertising platform. AuctionNet is composed of three parts: an ad auction environment, a pre-generated dataset based on the environment, and performance evaluations of several baseline bid decision-making algorithms. More specifically, the environment effectively replicates the integrity and complexity of real-world ad auctions through the interaction of several modules: the ad opportunity generation module employs deep generative networks to bridge the gap between simulated and real-world data while mitigating the risk of sensitive data exposure; the bidding module implements diverse auto-bidding agents trained with different decision-making algorithms; and the auction module is anchored in the classic Generalized Second Price (GSP) auction but also allows for customization of auction mechanisms as needed. To facilitate research and provide insights into the environment, we have also pre-generated a substantial dataset based on the environment. The dataset contains 10 million ad opportunities, 48 diverse auto-bidding agents, and over 500 million auction records. Performance evaluations of baseline algorithms such as linear programming, reinforcement learning, and generative models for bid decision-making are also presented as a part of AuctionNet. AuctionNet has powered the NeurIPS 2024 Auto-Bidding in Large-Scale Auctions competition, providing competition environments for over 1,500 teams. We believe that AuctionNet is applicable not only to research on bid decision-making in ad auctions but also to the general area of decision-making in large-scale games. Code3: https://github.com/alimama-tech/AuctionNet.

## 1 Introduction

Decision-making in large-scale games is a fundamental area of research in artificial intelligence. Agents in a large-scale game need to make strategic decisions to fulfill their objectives under certain constraints in a competitive environment. The research advances in this area have a profound impact on a broad range of real-world applications [13; 34; 35; 37]. Online advertising, with a market size ofmore than $600 billion in 2023, is perhaps one of the most representative applications that calls for sophisticated decision-making solutions in large-scale games. More specifically, as shown in Figure 1, a significant part of online advertising is based on real-time bidding (RTB), a process in which advertising inventory is bought and sold in real-time ad auctions. The auto-bidding agents strategically bid for impressions on behalf of the advertisers across a large number of continuously arriving ad opportunities to maximize performance, subject to certain constraints such as return-on-investment (ROI) .

Bid decision-making in large-scale ad auctions is a concrete example of decision-making in large-scale games. However, researchers usually only have limited access to realistic large-scale ad auction environments, hindering the research proccess in this area. Although a few existing works provide certain environments, there remains a considerable gap between these environments and the real-world environments. For instance, AuctionGym  overlooks changes in advertiser budgets across multiple auction rounds, while AdCraft  models competing bidders by sampling from a parameterized distribution, an approach that falls short of fully capturing the essence of the multi-agent dynamics inherent to this problem.

In this paper, we present AuctionNet, a benchmark for bid decision-making in large-scale ad auctions derived from a real-world online advertising platform. AuctionNet is composed of three parts: an ad auction environment, a pre-generated dataset based on the environment, and performance evaluations of a couple of baseline bid decision-making algorithms. More specifically, the environment effectively replicates the integrity and complexity of real-world ad auctions with the interaction of several modules: the ad opportunity generation module employs deep generative networks to bridge the gap between simulated and real-world data while mitigating the risk of sensitive data exposure; the bidding module implements diverse auto-bidding agents trained with different decision-making algorithms; and the auction module is anchored in the classic and popular Generalized Second Price (GSP) [9; 23; 7] auction but also allows customization of auction mechanisms as needed. To facilitate research and provide insights into the game environment, we also pre-generated a substantial dataset based on the environment. The dataset contains 10 million ad opportunities, 48 diverse auto-bidding agents, and over 500 million auction records. Performance evaluations of baseline algorithms such as linear programming, reinforcement learning, and generative models for bid decision-making are also presented as a part of AuctionNet.

We believe that AuctionNet is applicable not only to research on bid decision-making algorithms in ad auctions but also to the general area of decision-making in large-scale games. It can also benefit

Figure 1: Overview of typical large-scale online advertising platform. Numbers 1 through 5 illustrate how an auto-bidding agent helps advertiser \(i\) optimize performance. For each advertiser’s unique objective (I), auto-bidding agent make bid decision-making (II) for continuously arriving ad opportunities, and compete against each other in the ad auction (III). Then, each agent may win some impressions (IV), which may be exposed to users and potentially result in conversions. Finally, the agents’ performance (V) will be reported to advertisers.

researchers in a broader range of areas such as reinforcement learning, generative models, operational research, and mechanism design.

## 2 The Decision-Making Problem Concerned

In this paper, we are concerned with the auto-bidding problem in ad auctions. We use a Partially Observable Stochastic Game (POSG) to formulate the problem. A POSG \(\) can be represented as a tuple \(=\{S,A,P,,,Z,O,I,T\}\), where \(I=\{1,2,,n\}\) is the set of all the agents, \(T\) is the horizon, _i.e._, the number of time steps in one episode, \(S\) is the state space and \(A\) is the action space, \(P(|s,a):S A(S)\) is the transition probability, \(\) is the discount factor, \(Z\) is the observation space, \(O(s,i):S I Z\) is the mapping from state to observation for each agent \(i\), \(=r_{1} r_{2} r_{n}\) is the joint reward function of all the agents, and \(r_{i}(s,):S A\) is the individual reward function for each agent \(i\), where \(=(a_{1},a_{2},,a_{n}) A=A_{1} A_{2} A_ {n}\) is the joint action of all the agents.

Specifically, the interaction in one time step is as follows: The state \(s=(,,,)\) consists of budgets \(\), ad opportunity features \(\), advertiser features \(\) such as industry category, corresponding value matrix \(=\{v_{ij}\}\), where \(v_{ij}\) is the value of ad opportunity \(j\) for agent \(i\). Agent \(i\)'s observation \(o_{i}=(_{i},_{i},q_{i},_{i}) Z\) contains only part of the information in state \(s\), _i.e._, agent \(i\) may not know the budgets of other agents. A convention in the auto-bidding area  proves that the optimal bid is proportional to the ad opportunity value. Following this convention, the action of agent \(i\) is a coefficient \(_{i}\), and the bids of agent \(i\) for all the ad opportunities of this time step are \(_{i}=(b_{i1},b_{i2},,b_{im})=(_{i}v_{i1},_{i}v_{i2}, ,_{i}v_{im})\), where \(m\) is the number of ad opportunities within this time step. Given the bids of all the agents, determined by the auction mechanism, agent \(i\) will receive the auction result \(_{i}=(x_{i1},x_{i2},,x_{im})\), where \(x_{ij}=1\) if and only if agent \(i\) wins opportunity \(j\). Agents will only receive rewards and incur costs from the winning impressions, _i.e._, reward \(r_{i}(s,)=_{j=1}^{m}x_{ij}v_{ij}\) and budget for the next time step \(_{i}^{}=_{i}-_{j=1}^{m}x_{ij}c_{ij}\), where \(c_{ij}\) is the cost of impression \(j\) for agent \(i\).

Taking a typical auto-bidding scenario as an example, given the definition above, the optimization objective from the perspective of agent \(i\) is as follows:

\[^{}\}}{}_{t=1}^{T} _{i}^{t},_{i}^{t}_{t=1}^{T} _{i}^{t},_{i}^{t}_{i},\] (1)

where \(_{i}^{t}=(x_{i1}^{t},x_{i2}^{t},,x_{im}^{t})\), \(_{i}^{t}=(v_{i1}^{t},v_{i2}^{t},,v_{im}^{t})\), \(_{i}^{t}=(c_{i1}^{t},c_{i2}^{t},,c_{im}^{t})\), \(_{i}\) is the budget of agent \(i\), and \(\) denotes the inner product. As for the implementation, we know from our problem formulation that \(r_{i}(s_{t},_{t})=_{i}^{t},_{i}^{t}\), so the objective in the optimization formulation is the same as \(_{t=1}^{T}r_{i}(s_{t},_{t})\). For more complex scenarios, we can add the CPA constraint to ensure effective utilization of the budget. More details on these CPA-constrained problems are included in Appendix E. The decision-making formulation above can be easily extended to various real-world scenarios.

## 3 Ad Auction Environment

To comprehensively demonstrate large-scale games from real-world online advertising platforms, we have developed an ad auction environment. To standardize the auto-bidding process, we divide ad opportunities within a period into \(T\) decision time steps. Given the objective, the auto-bidding agent sequentially bids at each step, using the results from step \(t\) and prior historical information to refine its strategy for step \(t+1\). This design philosophy enables agents to continuously optimize their bidding strategies in order to adapt to the changing environment. Within each step, all ad opportunities are executed independently and in parallel. At the end of the period, the environment provides the final performance for the agent.

The environment effectively replicates the integrity and complexity of real-world ad auctions through the interaction of several modules: the ad opportunity generation module, the bidding module, and the auction module. To better simulate large-scale auctions in reality, a substantial number of ad opportunities are fed into the environment and configured with dozens of bidding agents. These ad opportunities are generated using deep generative networks to reduce the gap between the simulation environment and reality while avoiding the risks of sensitive data exposure. The agents are equipped with diverse and sophisticated auto-bidding algorithms.

### The Ad Opportunity Generation Module

The target of the ad opportunity generation module is to generate diverse ad opportunities similar to real online advertising data with deep generative networks, as shown in Figure 2. We aimed to adopt the diffusion model to generate ad opportunity but encountered difficulties with the denoising operation, which can yield unreasonable outputs. Therefore, we followed the approach of the Latent Diffusion Model (LDM)  to generate ad opportunity. LDM adds noise and performs denoising in the latent space using a diffusion model, and then generates data from the latent space with an encoder and decoder. Specifically, LDM maps the ad opportunity feature \(u\) to a latent vector \(y\) with the encoder and reconstructs this feature with the decoder during training. For generation, LDM samples a random latent vector from a normal distribution and then generates an ad opportunity feature based on this vector. Let \(U^{d}\) be the space of ad opportunity feature data \((u_{1},u_{2},,u_{K})\), where \(d\) is the dimension of the original data and \(K\) is the number of ad opportunities. Let \(Y^{d^{}}\) be the latent space (\(d^{}<d\)). The encoder and decoder are represented as \(g_{}\) and \(h_{}\), respectively, where \(\) and \(\) are the parameters. The function of the encoder \(g_{}\) is to obtain a latent representation of the original data as \(g_{}(u_{k})=(_{k},_{k})\), where \(y_{k}(_{k},_{k}^{2})\) and \(y_{k} Y\) is the latent representation. In practice, the reparameterization trick  is applied to ensure that this operation is differentiable during backpropagation.

Given the latent representation \(y_{k}\), the decoder is responsible for reconstructing the original data from \(y_{k}\), _i.e._, \(h_{}(y_{k})=_{k} U\). In addition to the reconstruction, the latent distribution \((_{k},_{k}^{2})\) is expected to approximate the standard Gaussian distribution \((0,1)\). Therefore, we have the following loss function for the encoder and decoder:

\[_{}=_{k=1}^{K}\|u_{k}-h_{}(y_{ k})\|_{2}^{2},_{}=_{k=1}^{K}D_{ }((_{k},_{k}^{2})(0,1 )),\]

where \(_{}\) is the reconstruction loss and \(_{}\) is the regularization loss for the latent distribution.

Different from the original idea of VAE , where the latent variable \(y Y\) is sampled from \((0,1)\) in the generation process, LDM uses a diffusion model in the latent space to generate the latent variable. In general, the idea behind the diffusion model is to add Gaussian noise to the original data to obtain variables that follow \((0,1)\) and to denoise from \((0,1)\) for generation. Given a

Figure 2: Overview of the pipeline of the ad opportunity generation network. The generation process consists of two stages. In the first stage, ad opportunity features are generated through a latent diffusion model. In the second stage, the value prediction for the generated ad opportunity features is performed, incorporating both the time feature and the advertiser feature. Moreover, the volume of ad opportunities fluctuates over time, mirroring that of real-world online advertising platforms.

latent variable \(y\), we denote its noisy version after \(p\) iterations as \(y_{p}\). The diffusion model includes a network to predict noise \(_{}(y_{p},p)\), and the loss function can be represented as

\[_{LDM}=_{k=1}^{K}\|_{k}-_{ }(y_{k,p_{k}},p_{k})\|_{2}^{2},\]

where \(_{k}(0,1)\), \(y_{k}\) is the latent embedding of \(u_{k}\), and \(p_{k}\) is uniformly sampled from the set \(\{1,2,,p_{}\}\). The network \(_{}(y_{p},p)\) is the only learnable component in the diffusion model, which enables the process of adding noise and denoising through basic operations.

As for the generation process, a latent variable \(\) is sampled from \((0,1)\), and \(\) is obtained through \(p_{}\) denoising steps from \(\) using the noise prediction network \(_{}\). Finally, the decoder generates an ad opportunity feature based on \(\) as \(=h_{}()\).

Given an ad opportunity feature \(u_{k}\), we also need to determine the value of this ad opportunity combined with the category information of the corresponding advertiser \(q_{k}\) and the time information \(u_{k}^{}\), where \(q_{k}\) is the advertiser information in the real-world data associated with \(u_{k}\). We use Multi-head Attention (MHA)  as the network architecture for information integration. Let \(v_{}\) represent the value prediction module, and \(v_{}(u_{k},q_{k},u_{k}^{})\) denote the predicted value of the ad opportunity feature \(u_{k}\) for a specific advertiser at a specific time step. The loss of the value prediction model is shown below:

\[_{}=_{k=1}^{K}\|v_{k}-v_{}(u_{k },q_{k},u_{k}^{})\|_{2}^{2},\]

where \(v_{k}\) is the true value of the ad opportunity in the record associated with \(u_{k}\).

### The Bidding Module

The bidding module replicates the dynamic competition between advertisers, each of whom has distinct advertising objectives and utilizes a separate auto-bidding agent, while remaining unaware of their competitors' strategies. Researchers can control a subset of the agents in the environment, while other agents remain uncontrollable, thereby better reflecting the complex and dynamic game in real-world online advertising.

Several algorithms in the auto-bidding area have been implemented as baselines, including the PID Controller , Online LP , IQL , Behavior Cloning , and Decision Transformer . This facilitates researchers who are interested in quickly starting up and evaluating these baselines in a unified environment.

### The Auction Module

The task of the auction module is to determine the winner and the winning price given all the bids from agents for ad opportunities. The costs for agents will vary depending on the different auction rules. The most commonly discussed auction rule is the Generalized Second-Price (GSP) Auction, which stipulates that the winner pays a cost slightly higher than the second-highest bid rather than the highest bid. The auction module internally supports several popular auction rules, including GSP, for the convenience of researchers. Additionally, researchers can design specific auction rules tailored to their purposes using the interface of the auction module.

Additionally, the property of multiple slots has been implemented in the environment. Multiple slots arise from applications in the industry, meaning that a single ad opportunity may have multiple ad slots for display. A slot with a higher exposure rate is more valuable to advertisers. Suppose the number of slots is \(l\), then the auction module will allocate \(l\) slots to the top \(l\) bidders, and these bidders will receive different values according to the varying exposure rates of the slots. In summary, the multiple slots feature increases the complexity of the optimal bidding strategy, as the exposure rate serves as a discount factor for both cost and value.

### Api

The code of the environment is implemented in Python. The environment API is similar to OpenAI Gym, so the construction and interactions of the environment may be familiar to related researchers. We included an example code as follows:

## 4 Pre-Generated Dataset Based on the Environment

In this section, we first verify whether the ad opportunity generation module can generate ad opportunity features similar to those in real-world data. Next, we briefly introduce and analyze the dataset generated from the AuctionNet environment.

### Verification of the Ad Opportunity Generation Module

In order to better demonstrate that the generated data can reflect the properties of real-world data, the effectiveness of the ad opportunity generation module itself was verified. The ad opportunity

Figure 3: The 3D PCA results of 100K generated data and 100K real-world data.

generation module comprises two components: a feature generation model and a value prediction model. Experiments were conducted to verify the effectiveness of these models.

We randomly sample 100K real-world online advertising data points to compare with 100K generated data points. The details of the generated data can be found in Appendix D. First, we perform PCA  to visualize the similarity between the real-world and generated data. The 3D PCA results are illustrated in Figure 3. For better presentation, we use six different views in the 3D space. We observe that the generated data overlap with the original data in the 3D space. Moreover, the generated data points form four main separate clusters in the 3D space, similar to the real-world data points. These visualization results demonstrate that the generated data generally resemble the real-world data.

To further compare these two datasets, we study the value distributions of identity information and consumption behavior information in both datasets. The empirical results are included in Figure 4 and Figure 5. The feature vector contains over 20 fields, as described in Appendix D, so we only select a subset of these fields for our experiments. Regarding identity information, the generated value distributions are similar to the real-world value distributions overall, although biases exist for certain terms, such as 'level 7' for the Taobao VIP Level. Distributions with more categories are more challenging to match, while the gender distributions are nearly identical in both datasets. For consumption behavior information, we observe that the distributions in the selected fields share a strong resemblance and exhibit long-tail characteristics. A long-tail distribution indicates that most users do not engage in frequent consumption, and users with a high volume of consumption behavior are rare. This phenomenon aligns with our experience in online advertising.

We investigate whether the generated data can capture the connections between different fields. Based on the observation that users with higher VIP levels typically exhibit a higher volume of consumption behavior, we examine the connection between the Taobao VIP level and consumption behavior. We select four consumption behavior fields. The mean values of these fields across different VIP levels are shown in Figure 6. We find that the overall monotonically increasing trend is captured by the generated data, although biases exist in the specific values. Moreover, the drop in values from 'level 7' to 'level 8' is also captured by the generated data in three out of the four fields, except for the consumption amount. The rarity of 'level 8' data points may be the reason why the generative model is unable to distinguish different trends for different fields.

In real-world online advertising, the metrics for bidding strategy evaluation are Click-Through Rate (CTR) and Conversion Rate (CVR). Bidding strategies make decisions based on the predicted CTR (pCTR) and predicted CVR (pCVR), which are the estimated values of CTR and CVR, respectively. For simplicity, in this environment, we assume that the estimations are accurate and define the value as \(=\). Our value prediction model learns to predict pCTR and pCVR and subsequently calculates the value. We predict the pCTR, pCVR, and value for 100K real-world data points and compare these predictions with the real-world ground truth.

We hope that the value prediction model can capture the value variation over changes in category and time. The means of predicted pCTR, pCVR, and values across different categories and time steps,

Figure 4: The distribution of identity information including the Taobao VIP level, the preferred phone price, the buyer level, and the gender in 100K generated data and 100K real-world data.

Figure 5: The distribution of consumption behavior information including the number of collected items, the number of visited items, the number of collected sellers, and the consumption amounts in 100K generated data and 100K real-world data.

compared with the ground truth, are illustrated in Figure 7. The empirical results show that, in general, the variation trends in predictions over changes in category and time are similar to the ground truth.

To present the results more intuitively, we provide additional quantitative results. We compare the mean squared error (MSE) between the generated and original distributions with the standard deviation of the original distribution. The quantitative results are shown in Table 1. It can be observed that the MSEs are all smaller than the original standard deviations (original_stds), indicating that our prediction model can capture the patterns of value variation and is accurate.

### Pre-Generated Dataset

The dataset is derived from game data generated within the environment, where numerous auto-bidding agents compete against each other. We have pre-generated large-scale game data to assist researchers in gaining deeper insights into the auction ecosystem. This data can be used to model the environment and to train the auto-bidding agents effectively.

The dataset contains 10 million ad opportunities, including 21 advertising episodes. Each episode contains more than 500,000 ad opportunities, divided into 48 steps. Each opportunity includes the top 48 agents4 with the highest bids. The dataset comprises over 500 million records, totaling 80 GB in size. Each record includes information such as the predicted value, bid, auction, and impression results, among other details. The specific data format and data samples of the dataset are included in Appendix C.

We have conducted an analysis of the AuctionNet Dataset to provide some insights. We first investigate the variation of impression values over time within a single day. We selected five categories from the AuctionNet Dataset and denote them as Category 1, Category 2, and so on. As shown in Figure 8, the impression values of different categories exhibit distinct patterns of variation. Given the budget constraint, agents should consider the variation in impression values over time to bid for appropriate impressions at the optimal times. Furthermore, we examine the relations between the values of different categories. The relations between Category 1 and other categories are illustrated in Figure 9.

   & original\_std & MSE \\  pCVR\_category & 0.0685 & **0.0341** \\  pCTR\_category & 0.0517 & **0.0280** \\  value\_category & 0.00573 & **0.00496** \\  pCVR\_time & 0.0637 & **0.0313** \\  pCTR\_time & 0.0590 & **0.0259** \\  value\_time & 0.00625 & **0.00176** \\  

Table 1: The comparison of the MSE between the generated and original distribution with the standard deviation of the original distribution.

Figure 6: The mean values of consumption behavior information including the number of cart items, the number of collected items, the consumption amounts, and the number of visited categories in different VIP levels in 100K generated data and 100K real-world data.

Figure 7: The means of the predicted pCTR, pCVR, and value in different categories and time steps compared with the ground truth. The shaded areas are related to the standard deviation.

The impression values of Category 1 and Category 3 are positively correlated, indicating that the corresponding advertisers are competitors for similar ad opportunities. Therefore, considering the preferences of other agents may be beneficial for developing better bidding strategies. The full datasheet of the dataset is included in Appendix B.

## 5 Performance Evaluations of Baseline Algorithms

In this section, we evaluate the performance of baseline algorithms, such as linear programming, reinforcement learning, and generative models. It is important to note that we used the original algorithms from the papers and did not perform any special optimization on the methods specifically for the auto-bidding tasks. We provide a brief introduction to these baselines. The idea of the PID Controller is straightforward: it uses three parameters, \(_{P}\), \(_{I}\), and \(_{D}\), for Proportional Control, Integral Control, and Derivative Control, respectively. In this baseline, the PID Controller is employed to control the cost or bids of agents. Online LP utilizes linear programming for the auto-bidding problem. At each time step, Online LP solves a knapsack problem using a greedy algorithm. IQL is an offline RL algorithm. The core idea behind IQL is to evaluate the offline Q-function only on actions that appeared in the offline data, thereby avoiding overestimation in out-of-distribution data. Behavior Cloning (BC) is a supervised learning algorithm that uses expert trajectories. The agent's policy is learned by predicting the expert's actions in the state of given trajectories. Decision Transformer (DT) leverages the capabilities of the Transformer model for sequential decision-making. DT treats the trajectories in a MDP as sequences and predicts actions based on previous transitions. More generative models such as AIGB  will also be integrated into baseline algorithms in the future. To better illustrate the performances, we add a heuristic method, Aibid, to the experiments. Aibid means the agent will give a fixed bid rate for all impressions. Its performance can be seen as a reference in comparison. More details of the evaluation can be found in Appendix A.

The empirical results are included in Figure 10. For better illustration, we normalize the performances of all baselines by the mean episode reward of the heuristic baseline Aibid. Therefore, the mean relative performance of Aibid is $1.0$ in the basic task. Online LP achieves the best performance, possibly because it is relatively robust and does not require special adaptation for auto-bidding tasks to achieve good results. Although methods like IQL and BC perform not as well as Online LP, we observe that proposing optimized solution [12; 22]can significantly optimize the performance, proving that such methods have great potential for optimization. In addition, the drop in rewards observed for all baselines during the target CPA task is due to the CPA penalty for exceeding constraints in (4).

## 6 Applications

AuctionNet has powered the the NeurIPS 2024 competition "Auto-bidding in Large-Scale Auctions" . The competition addressed the critical issue of making high-frequency bid decision-making in uncertain and competitive environments and attracted more than 1,500 teams

Figure 8: The joint value distribution between different categories and time in the dataset.

Figure 9: The joint value distribution between Category 1 and other categories in the dataset.

from around the world to participate, lasting for 4 months. The ad auction environment, dataset, and baseline bid decision-making algorithms used in the competition are derived from this benchmark. The ad auction environment provided nearly ten thousand evaluations for the competition, offering participants accurate and fair performance assessments. The dataset and baseline algorithms allowed participants to quickly start the task and stimulated their creativity, leading to more diverse and innovative solutions, thus driving technological development in this area.

## 7 Related Work

Simulation environments have been widely applied in decision-making research and have successfully promoted the development of related studies [6; 24; 32; 27; 29]. However, simulation environments for real-world online advertising platforms are relatively scarce in the bid decision-making field. AuctionGym  models the bidding problem as a contextual bandit problem , where the advertiser decides the bidding value given the information of the ad opportunity as context. The contextual bandit has only one time step per episode, meaning that AuctionGym does not consider budget constraints in auto-bidding. Moreover, AuctionGym describes the auto-bidding problem from a single-agent perspective and ignores the influence of other agents. AdCraft  is a simulation environment for the bidding problem in Search Engine Marketing (SEM). Although AdCraft explicitly models the influences of other agents, these agents' policies are sampled from parameterized distributions, which cannot fully reflect the multi-agent nature of this problem. Despite the points discussed above, these existing simulation environments lack data-driven methods for modeling real-world online advertising platforms.

## 8 Conclusion and Limitations

We present AuctionNet, a benchmark for bid decision-making in large-scale ad auctions derived from a real-world online advertising platform. AuctionNet consists of three components: an ad auction environment augmented with verified deep generative networks, a pre-generated dataset based on this environment, and performance evaluations of several baseline bid decision-making algorithms. The AuctionNet not only provides researchers with the opportunity to study auto-bidding algorithms in large-scale auctions, but also helps researchers and practitioners in game theory, reinforcement learning, generative models, operations optimization, and other fields to solve a wide range of decision-making research problems. Regarding limitations, while the generated data in the AuctionNet environment and the real-world data are similar in general, there are biases in some details, and the performance of the generative model can be improved.

## 9 Acknowledgments

This work was supported in parts by NSFC under grants 62450001 and 62476008 and Alibaba Group through Alibaba Innovative Research Program. The authors would like to thank the anonymous reviewers for their valuable comments and advice.

Figure 10: The empirical results of baseline algorithms on the basic task and Target CPA task.