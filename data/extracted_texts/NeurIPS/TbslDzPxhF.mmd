# Job-SDF: A Multi-Granularity Dataset for Job Skill Demand Forecasting and Benchmarking

Xi Chen\({}^{1}\), Chuan Qin\({}^{2}\), Chuyu Fang\({}^{3}\), Chao Wang\({}^{1}\),

**Chen Zhu\({}^{1}\)**, **Fuzhen Zhuang\({}^{4,5}\)**, **Hengshu Zhu\({}^{2}\)\({}^{}\)**, **Hui Xiong\({}^{6,7}\)**

\({}^{1}\)University of Science and Technology of China

\({}^{2}\)Computer Network Information Center, Chinese Academy of Sciences

\({}^{3}\)Baidu Inc. \({}^{4}\)Institute of Artificial Intelligence, Beihang University

\({}^{5}\)SKLSDE, School of Computer Science, Beihang University

\({}^{6}\)AI Thrust, The Hong Kong University of Science and Technology (Guangzhou)

\({}^{7}\)Department of Computer Science and Engineering,

The HongKong University of Science and Technology, Hong Kong SAR

chenxi0401@mail.ustc.edu.cn,

{chuanqin0426, fangchuyu2022, chadwang2012, zc3930155}@gmail.com,

zhuangfuzhen@buaa.edu.cn, zhuhengshu@gmail.com, xionghui@ust.hk

Equal contributionsCorresponding Authors

###### Abstract

In a rapidly evolving job market, skill demand forecasting is crucial as it enables policymakers and businesses to anticipate and adapt to changes, ensuring that workforce skills align with market needs, thereby enhancing productivity and competitiveness. Additionally, by identifying emerging skill requirements, it directs individuals towards relevant training and education opportunities, promoting continuous self-learning and development. However, the absence of comprehensive datasets presents a significant challenge, impeding research and the advancement of this field. To bridge this gap, we present Job-SDF, a dataset designed to train and benchmark job-skill demand forecasting models. Based on millions of public job advertisements collected from online recruitment platforms, this dataset encompasses monthly recruitment demand. Our dataset uniquely enables evaluating skill demand forecasting models at various granularities, including occupation, company, and regional levels. We benchmark a range of models on this dataset, evaluating their performance in standard scenarios, in predictions focused on lower value ranges, and in the presence of structural breaks, providing new insights for further research. Our code and dataset are publicly accessible via the https://github.com/Job-SDF/benchmark.

## 1 Introduction

Job skills encompass a range of abilities and competencies essential for performing tasks effectively in the workplace. These skills are broadly categorized into hard skills, such as technical and analytical abilities, and soft skills, including communication, teamwork, and adaptability . Accurate forecasting of skill demand helps businesses and policymakers anticipate and address skill shortages and mismatches, and promotes skill development in high-demand areas, thereby supporting economic growth and stability [2; 3]. By identifying emerging skill requirements, individuals are directed towards relevant training and education opportunities, fostering continuous self-learning and development to stay competitive in the labor market [4; 5; 6; 7; 8; 9; 10]. By tracking skill demand trends,employers gain deeper insight into recruits' priorities, enhancing person-job fit. [11; 12; 13; 14; 15; 16; 17; 18; 19; 20; 21]. Moreover, forecasting informs educational and training programs, ensuring that curricula align with the labor market's evolving needs [22; 23; 24].

Traditionally, skill demand analysis has relied on labor-intensive, survey-based methods limited to specific companies or occupations [25; 26; 27]. However, over the past decade, the rapid evolution of the internet has spurred the emergence of online recruitment platforms. These platforms have become the primary channels for job advertisements for numerous enterprises and organizations, accumulating vast amounts of job advertisement data. By leveraging this data, researchers have formulated skill demand forecasting as a time series task, utilizing various machine learning models such as autoregressive integrated moving average (ARIMA) , recurrent neural networks (RNNs) , and dynamic graph autoencoders (DyGAEs) , to predict future skill needs.

A major challenge impeding progress in this field is the lack of comprehensive and publicly accessible datasets. Existing studies do not provide open-source datasets, making it difficult for researchers to replicate experimental results and identify bottlenecks in current research. Furthermore, these datasets primarily focus on predicting skill demand variations across different occupations, with a notable lack of modeling and prediction at other granularities, such as companies or regions. This limitation hinders comprehensive comparisons between different models and impedes the exploration of potential downstream applications, such as human capital strategy development and regional policy formulation. Additionally, the significant variations in skill demand present further challenges. Existing studies, which rely on metrics such as Mean Squared Error (MSE), struggle to evaluate the performance of skill demand forecasting models for low-frequency skill terms. For instance, some emerging skills, such as large language models (LLMs), may initially show low demand but are crucial for the job market due to their potential to reshape existing occupations.

To this end, in this paper, we propose Job-SDF, a multi-granularity dataset designed for job skill demand forecasting research. Specifically, we collected millions of public job advertisements from online recruitment platforms. By extracting skill terms from job advertisement texts, we quantified the monthly skill demand at various granularities, including occupations, companies, and regions, to construct our dataset. This dataset encompasses 2,324 types of skills, 52 occupations, 521 companies, and 7 regions. We then use the Job-SDF dataset to benchmark a wide range of models for job skill demand forecasting tasks at various granularities. These models include statistical time series models (e.g., ARIMA ), deep learning-based methods such as RNN-based models [32; 30], Transformer-based models [33; 34; 35; 36; 37], MLP-based models [38; 39], as well as several state-of-the-art time-series forecasters [40; 41]. Performance is evaluated using regression metrics such as Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Additionally, we use the Symmetric Mean Absolute Percentage Error (SMAPE)  and Relative Root Mean Squared Error (RRMSE)  metrics to account for the significantly varying nature of skill demand values, which is particularly useful for evaluating model performance in predicting lower value ranges. Moreover, we further investigate the impact of structural breaks in job skill demand time series data on model performance. The Job-SDF dataset, along with data loaders, example codes for different models, and evaluation setup, are publicly available in our GitHub repository: https://github.com/Job-SDF/benchmark.

## 2 Related Work

Skill demand forecasting can analyze how skills evolve over time, aiding experts in evaluating technological advancements [44; 45; 46], assessing wage inequality [47; 48; 49], and generating employment opportunities . Furthermore, the skills required in the 21st-century workplace will differ significantly from those in previous eras . Predicting skill demands benefits personal career transitions and corporate management strategies.

Recently, with the rapid accumulation of data and continuous advancements in technology, skill demand forecasting has demonstrated significant vitality. _Das et al._ proposed a method for dynamic task allocation to investigate the evolution of job task requirements over a decade of AI innovation across different salary levels . Given the effectiveness of RNN in multi-step prediction, some researchers have integrated skill demand forecasting with RNN algorithms, achieving promising results [29; 32]. In addition, considering the supply-demand dynamics of the labor market concurrently, CHGH designed a joint prediction model based on the encoder-decoder architecture to achieve trend prediction for both skill supply and demand sides . Moreover, to capture the dynamic information of occupations, a pretraining-enhanced dynamic graph autoencoder has been developed to efficiently forecast skill demand at the occupational granularity .

However, the predominance of closed-source datasets has significantly elevated the barrier of researchers and constrained the pace of methodological advancements. While open-source skill-related datasets such as O*NET  and ESCO  provide skill taxonomies, they do not quantify skill demand. Furthermore, the current research data focuses either on macro-market skill demand predictions or analyses at a specific granularity, neglecting multi-level labor market analysis. This limitation generally hampers the transferability of the modeling approaches.

## 3 Job-SDF Dataset

The Job-SDF dataset is built from job advertisements collected on online recruitment platforms, encompassing dynamic job skill demand time series data at various granularities, recorded monthly. The dataset is CC BY-NC-SA 4.0 licensed, accessible via the URL https://github.com/Job-SDF/benchmark. We summarize the dataset construction process, task description, and dataset analysis below, with supplementary details provided in the Appendix F.

### Data Collection and Processing

**Job Advertisement Collection.** We collected public job advertisements for 52 occupations from 521 companies on online recruitment platforms. We obtained unique records after removing identical job advertisements posted simultaneously by different companies on various platforms. Each record contains five types of information: (1) _Job Requirement_, which is a text segment that outlines the specific skills required of candidates applying for the job; (2) _Company_, which identifies the company that posted the job advertisement; (3) _Occupation_, which specifies the job advertisement's category. Our dataset encompasses 52 detailed occupations (L2-level), such as front-end development engineer and financial investment analyst. Additionally, these 52 occupations are grouped into 14 broader categories (L1-level); (4) _Region_, which indicates the primary geographic divisions in China where the job postings are located. These regions are classified based on their geographical orientation; (5) _Posting Time_, which records the date when the job was posted, including the year, month, and day.

**Job Skill Extraction.** After acquiring the job advertisement data, we utilized a Named Entity Recognition (NER) model, as referenced in , to explicitly extract skill requirements from the _Job Requirement_ of each advertisement. Specifically, we first annotated a dataset for training the NER model by identifying skill terms within the job requirement texts. To achieve this, we devised a set of regular expressions tailored to the characteristics of skill descriptions and used these to match skill words in job advertisements. Subsequently, we merged all matched skill words to formulate a raw skill dictionary, including their corresponding frequencies across job advertisements. We then filtered out low-frequency words and manually annotated the raw skill dictionary to create a refined skill dictionary. Along this line, we excluded unreasonable skill words matched by the regular expressions that did not appear in the refined skill dictionary, establishing an initial correspondence between the _Job Requirement_ and the skill requirements.

Based on this annotated data, we trained an NER model to extract required skills from the _Job Requirement_ section for all job advertisements. Experts then aggregated the skills extracted by the NER model based on their meaning and content, grouping together those with similar meanings or repeated expressions. This process resulted in a skill dictionary \(\) of 2,324 standardized skill words, mapping original skill word descriptions to standardized skill words. The skill dictionary was then used to filter and map the skill words extracted by the NER model, ultimately obtaining standardized skill requirements for each job requirement. These standardized requirements were added to the job advertisement data as a new field, _Skill Requirements_.

**Job Skill Demand Estimation.** Generally, the demand for different skills in the job market can be estimated by the volume of job advertisements listing these specific skills as requirements within a given time period . Formally, given job advertisement data \(=\{_{1},...,_{t},...,_{T}\}\), where each \(_{t}\) represents the job advertisements posted at timestamp \(t\), we use \(D_{s,t}=_{p_{t}}(s p)\) to estimate the demand for skill \(s\) at time \(t\). \(s p\) indicates that job advertisement \(p\) requires skill \(s\).

Along this line, we can calculate skill demand at various granularities, such as occupation and company levels. We define the sets of L1-level occupations, L2-level occupations, companies, and regions as \(^{o_{1}}\), \(^{o_{2}}\), \(^{c}\), and \(^{r}\), respectively. The demands for skill \(s\) at time \(t\) under granularity \(i\{o_{1},o_{2},c,r\}\) is then defined as follows:

\[D^{i}_{s,t}=[D^{i}_{s,t,a^{i}}]_{a^{i}^{i}},\;\;D^{i}_{s,t,a^{i}}= _{p_{t}}(s p)(a^{i} p),\] (1)

where \(a^{i} p\) represents a job advertisement \(p\) containing the attribute \(a^{i}\) under granularity \(i\). Similarly, we can further define skill demands \(D^{i,j,...,k}_{s,t}\) across multiple granularities \(\{i,j,...,k\}\) by calculating:

\[D^{i,j,...,k}_{s,t,}=_{p_{t}}(s p )(a^{i} p a^{j} p... a^{k} p),\] (2)

where \(=\{a^{i},a^{j},...,a^{k}\}\), \(a^{i}^{i},a^{j}^{j},...,a^{k}^{k}\), and \(D^{i,j,...,k}_{s,t}^{|^{i}||^{j}|...| ^{k}|}\).

### Job Skill Demand Forecasting Tasks

We study model performance through job skill demand forecasting tasks at different granularities, including single and multiple levels. The primary goal of these tasks is to predict future job skill demands based on historical time series data of various skills. Formally, we have:

**Definition 1** (Job Skill Demand Forecasting): _Given a granularity or a set of granularities \(g\) and the observed job skill demand series from the previous \(K\) timestamps, i.e., \(\{D^{g}_{:,t-K+1},...,D^{g}_{:,t}\}\), the goal of job skill demand forecasting is to learn a forecasting model \(\) to predict the demand values for the next \(H\) timestamps, denoted by \(\{^{g}_{:,t+1},,^{g}_{:,t+H}\}\)._

Our dataset includes skill demand time series data for L1-level occupations, L2-level occupations, companies, regions, and their combinations. We follow a standard protocol  that categorizes all time-series data into training, validation, and test sets in chronological order with a ratio of 9:1:2. In the main text, we demonstrate results with \(K\) set to 6 months and consider \(H\) as 3 months to evaluate the performance of different forecasting models. More settings and results can be found in the Appendix D and our project repository. Based on the Job-SDF dataset, other researchers can easily adjust the parameters to suit their research objectives.

### Dataset Analysis

**Varying Nature of Skill Demand.** The values of skill demand exhibit significant differences and generally follow a long-tail distribution. This indicates that, at a specific granularity, only a few skills have high demand, while a wide range of skills are required by a limited number of jobs. For instance,

Figure 1: Data analysis on Job-SDF. (a) illustrates the long-tail phenomenon of skill demands under the product manager and doctor occupations. (b) illustrates the results under the Chow test for the absence (left) and presence (right) of structural breaks.

[MISSING_PAGE_FAIL:5]

69]. Notably, _LSTM_ have demonstrated their effectiveness in predicting changes in skill shares over time . However, conventional RNNs often encounter performance degradation when handling excessively long look-back windows and forecast horizons. To address this challenge, _SegRNN_ introduces segment-wise iterations, which reduce the recurrence count within RNNs, thereby significantly enhancing performance in time series forecasting tasks.

**Transformer-based Model.** Recently, Transformer-based models  have gained widespread recognition in long-term time series forecasting due to their global modeling capabilities. Leveraging the attention mechanism, _Reformer_ introduces locally sensitive hashing to approximate attention by grouping similar queries. _Informer_ incorporates low-rank matrices in self-attention mechanisms to accelerate computation. _Autoformer_ employs block decomposition and autocorrelation mechanisms to more effectively capture the intrinsic features of time series data. _FedFormer_ utilizes DFT-based frequency-enhanced attention, obtaining attentive weights through the spectrums of queries and keys and calculating the weighted sum in the frequency domain. To address the challenges of non-stationary time series, the _Non-stationary Transformer (NSTransformer)_ introduces a sequence stabilization module and proposes a de-stationary attention mechanism. Additionally, _PatchTST_ is a channel-independent patch time series transformer model that features patching and channel-independence as its key design elements.

**MLP-based Model.** Multiple Layer Projection (MLP) has been introduced in time series forecasting, demonstrating superior performance compared to transformer-based models in both accuracy and efficiency . Specifically, _DLinear_ uses series decomposition as a pre-processing step before linear regression. _FreTS_ explores a novel approach by applying MLPs in the frequency domain for time series forecasting. _TSMixer_ employs MLPMixer blocks, segments input time series into fixed windows, and applies gated MLP transformations and permutations to enhance accuracy.

**Graph-based Models.** Graph Neural Networks (GNNs) can learn non-Euclidean relationships, making them effective for identifying associations in structured data and generating joint representations from different perspectives . CHGH  uses an adaptive graph enhanced by skill co-occurrence relationships to link skill supply and demand sequences. This fusion of representations across views improves the performance of joint skill supply and demand prediction tasks. Pre-DyGAE  targets skill demand prediction from an occupational perspective. It builds an occupation-skill bipartite graph based on the skill demands of occupations and captures the dynamic changes in these relationships. This method allows for predicting both potential occupational skills and skill demands, leveraging a dynamic graph perspective.

**Fourier-based Models.** By utilizing Fourier projection, _FiLM_ not only captures long-term time dependencies but also effectively reduces noise in forecasting. To address the challenge of non-stationary time-series forecasting, _Koopa_ disentangles time-variant and time-invariant components from complex non-stationary series using a Fourier Filter and designs the Koopman Predictor to forecast dynamics.

### Evaluation Metrics

To evaluate the performance of various benchmark models in job skill demand forecasting tasks, we selected two commonly used regression metrics: MAE and RMSE. MAE is calculated over \(H\) observations using the formula: \(_{i=1}^{H}|y_{i}-_{i}|\), where \(y_{i}\) represents the ground truth value and \(_{i}\) is the predicted value. RMSE is calculated as: \(_{i=1}^{H}(y_{i}-_{i})^{2}}\). Both MAE and RMSE are scale-dependent metrics, which makes them unsuitable for comparison across different granularities. Additionally, these metrics are less sensitive to prediction errors at lower skill demand values. Therefore, we additionally applied SMAPE  and RRMSE  to assess the performance of various forecasting models. SMAPE considers both the magnitude and direction of errors, making it suitable for comparing forecasts across different scales. RRMSE measures the square root of the average of the squared percentage errors.

\[SMAPE=*_{i=1}^{H}-_{i}|}{|y_ {i}|+|_{i}|},\ \ RRMSE=_{i=1}^{H}(y_{i}-_{i} )^{2}}{_{i=1}^{H}(_{i})^{2}}}.\] (3)

### Benchmark Results

**Overall Performance.** In Table 1, we present the performance of various models evaluated using two metrics: MAE and RMSE. The following conclusions can be drawn: (1) The traditional statistical method, Prophet, demonstrates relatively poor predictive performance. This may be due to seasonal and holiday factors not being the primary influencers in skill demand prediction. (2) Most Transformer-based models, including Transformer, Autoformer, Informer, and Reformer, exhibit subpar overall predictive performance. This is likely because these models are designed to address long-range temporal dependencies, which are not well-suited for the current shorter time series context. (3) In contrast, PatchTST, unlike these Transformer-based models that perform point-wise modeling of time series, segments the time series into patches and inputs them into the Transformer. This allows the model to focus on more local information. A similar idea is also employed in the SegRNN. This strategy significantly enhances the performance of these models in predicting job skill demand. (4) The performance of different linear models on our dataset varies significantly. For instance, DLinear outperforms most Transformer-based models, while TSMixer performs poorly. This discrepancy may be due to the tendency of more complex MLP-based models to overfit our dataset. (5) CHGH and Pre-DyGAE exhibit poor performance in the separate skill demand forecasting scenario, likely due to a mismatch between their model design and the context of our dataset. Specifically, CHGH relies on sequential data from the supply side of skills, which is lacking in our dataset. Conversely, Pre-DyGAE focuses more on predicting whether a skill will be required by an occupation in the future. (6) Finally, FiLM achieved the best performance in most cases, demonstrating the robustness of the denoising-based model.

**Low-Demand Skill Prediction Performance.** Considering the varying nature of skill demand values, we further employed SMAPE and RRMSE metrics to focus on the predictive performance of different models for low-demand skills. As shown in Table 2, the experimental results indicate the following: (1) PatchTST achieved the best SMAPE performance in most cases, validating its ability to more accurately predict the trends of low-demand skills. (2) Based on scale-independent metrics, we can compare the performance of models at different granularities. It can be observed that RRMSE exhibits a significant trend of variation across different granularities; specifically, as the granularity becomes finer, the RRMSE performance deteriorates. This indicates that predicting skill demand at finer granularities is more challenging. Additionally, FiLM shows the least variation across multiple granularities, further validating its ability to provide stable and reliable predictions under varying granularities and demand value ranges. (3) Although Koopa performs averagely on MAE and RMSE metrics, it excels in predicting low-demand skills, particularly in terms of SMAPE. Similarly, NStransformer also performs well in scenarios focusing on low-demand skill predictions. This success can be attributed to both methods being designed to handle non-stationary time series. They effectively filter noise from historical sequences and restore intrinsic non-stationary information

    &  &  &  &  &  \\  & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE \\  ARIMA & 20.27 & 256.89 & 6.46 & 115.79 & 3.98 & 58.65 & 1.31 & 27.42 & 1.31 & 38.88 \\ Prophet & 29.15 & 356.67 & 8.95 & 161.01 & 5.08 & 72.21 & 1.62 & 33.02 & 1.55 & 41.19 \\  LSTM & 19.05 & 194.67 & 7.09 & 116.36 & 3.92 & 51.59 & 1.29 & 23.31 & 1.35 & 26.47 \\ SegRNN & 12.28 & 108.28 & 5.01 & 68.83 & 3.14 & 34.26 & 1.05 & 15.96 & 1.01 & 16.03 \\  CHGH & 22.09 & 261.49 & 7.09 & 116.58 & 3.91 & 51.46 & 1.28 & 23.24 & 1.34 & 26.52 \\ Pre-DyGAE & 22.98 & 187.90 & 7.04 & 82.97 & 4.24 & 38.62 & 1.37 & 17.39 & 1.24 & 18.24 \\  Transformer & 22.06 & 215.09 & 7.58 & 118.21 & 4.01 & 52.04 & 1.35 & 23.44 & 1.26 & 24.99 \\ Autoformer & 23.06 & 186.76 & 8.22 & 100.02 & 6.45 & 57.77 & 2.41 & 24.10 & 3.31 & 38.55 \\ Informer & 22.21 & 205.24 & 7.43 & 117.38 & 3.88 & 50.13 & 1.30 & 23.07 & 1.26 & 24.92 \\ Reformer & 22.11 & 204.35 & 7.46 & 116.60 & 3.91 & 50.95 & 1.25 & 22.81 & 1.54 & 27.37 \\ FEDformer & 22.87 & 181.93 & 7.46 & 88.97 & 4.63 & 43.21 & 1.98 & 21.73 & 2.43 & 26.92 \\ NStransformer & 17.36 & 149.46 & 5.75 & 86.24 & 3.45 & 37.09 & 1.15 & 17.45 & 2.13 & 34.83 \\ PatchTST & 14.91 & 141.06 & 5.15 & 78.86 & 3.10 & 35.38 & 1.04 & 16.57 & 1.01 & 19.09 \\  DLinear & 16.61 & 154.88 & 5.44 & 81.61 & 3.24 & 36.67 & 1.07 & 16.79 & 1.05 & 18.85 \\ TSMixer & 21.34 & 192.85 & 8.14 & 106.65 & 5.81 & 62.14 & 5.95 & 68.26 & 13.96 & 144.96 \\ FreTS & 16.47 & 167.61 & 6.52 & 106.39 & 3.65 & 47.81 & 1.22 & 21.92 & 1.26 & 25.39 \\  FiLM & 12.95 & 117.17 & 5.08 & 65.65 & 3.24 & 29.90 & 1.14 & 14.01 & 1.17 & 15.87 \\ Koopa & 19.91 & 179.30 & 6.05 & 91.87 & 3.53 & 40.73 & 1.15 & 18.71 & 1.08 & 20.18 \\   

Table 1: Performance comparison on MAE and RMSE.

into time-dependent relationships, making them more adept at handling the fluctuating nature of low-demand skill time series data.

**Performance on Skill Demand Series with Structural Breaks.** As described in Section 3.3, in the dynamically changing job market, skill demand time series data exhibit structural breaks. To assess the impact of this phenomenon on different models in the skill demand forecasting task, we used the Chow test to detect structural breaks in the skill demand time series. The corresponding predictive performance of different models is presented in Tables 3 and 4. We observe the following phenomena: (1) Compared to the predictive performance on the full dataset, the performance on time series data with structural breaks is significantly worse. This finding underscores the complexity and unpredictability of skill trends that experience structural breaks. (2) FiLM has achieved results close to the overall skill demand prediction in terms of SMAPE and RRMSE metrics. This validates that FiLM can effectively mitigate the disruptive impact of structural breaks on skill demand forecasting. (3) Furthermore, while the overall predictive performance of skill demand forecasting at both the Region&L2-O and Company granularity levels is similar, significant differences emerge when forecasting skills experiencing structural breaks. This suggests that skills undergoing structural breaks display more predictable patterns at the Region&L2-O granularity level compared to the Company level, making them relatively easier to forecast.

   Model &  &  &  & } &  \\  & SMAPE & RRMSE & SMAPE & RRMSE & SMAPE & RRMSE & SMAPE & RRMSE & SMAPE & RRMSE \\  ARIMA & 35.72 & 47.89 & 25.00 & 58.87 & 23.86 & 58.07 & 13.58 & 73.57 & 20.17 & 147.94 \\ Prophet & 41.22 & 67.78 & 28.35 & 88.47 & 26.75 & 71.60 & 15.07 & 93.04 & 22.31 & 167.77 \\  LSTM & 41.38 & 57.90 & 32.85 & 83.70 & 31.58 & 68.40 & 22.93 & 87.36 & 30.26 & 174.40 \\ SegRNN & 39.81 & 37.58 & 33.35 & 50.53 & 35.30 & 48.53 & 23.84 & 61.90 & 33.07 & 86.27 \\  CHGH & 40.27 & 66.05 & 29.60 & 84.10 & 28.11 & 68.42 & 17.42 & 87.45 & 26.72 & 176.70 \\ PreDyGAE & 49.87 & 83.67 & 60.54 & 83.60 & 59.32 & 66.56 & 72.67 & 98.09 & 26.21 & 145.73 \\  Transformer & 55.59 & 64.25 & 44.23 & 84.27 & 31.15 & 76.16 & 33.04 & 86.87 & 27.61 & 164.36 \\ Autofomer & 70.28 & 53.75 & 74.37 & 63.40 & 90.14 & 65.57 & 91.51 & 74.46 & 107.05 & 99.60 \\ Informer & 56.85 & 58.18 & 44.04 & 88.72 & 34.75 & 69.59 & 29.29 & 90.15 & 32.41 & 164.37 \\ Reformer & 56.58 & 61.35 & 40.58 & 83.70 & 32.21 & 72.87 & 20.86 & 90.85 & 45.25 & 169.87 \\ FEDformer & 69.30 & 54.03 & 69.29 & 60.00 & 73.17 & 52.69 & 81.73 & 70.06 & 94.19 & 97.97 \\ NStransformer & 38.11 & 47.19 & 26.30 & 60.73 & 24.98 & 48.89 & 14.55 & 63.29 & 24.20 & 100.78 \\ PatchTST & 34.70 & 51.17 & 24.52 & 58.80 & 25.15 & 44.96 & 13.50 & 67.48 & 19.89 & 115.34 \\  DLinear & 41.84 & 52.89 & 34.35 & 60.22 & 33.47 & 51.05 & 25.77 & 64.65 & 30.71 & 108.66 \\ TSMixer & 56.59 & 61.17 & 72.29 & 99.35 & 82.48 & 87.29 & 120.85 & 96.49 & 155.20 & 102.14 \\ FreTS & 39.76 & 54.42 & 30.18 & 80.44 & 28.58 & 66.11 & 17.62 & 85.04 & 27.24 & 174.56 \\  FiLM & 39.51 & 37.55 & 29.65 & 43.86 & 28.79 & 37.66 & 17.24 & 47.75 & 25.72 & 76.92 \\ Koopa & 37.84 & 58.30 & 25.72 & 65.34 & 24.41 & 57.81 & 13.98 & 74.00 & 20.43 & 123.96 \\   

Table 2: Performance comparison on SMAPE and RRMSE.

   Model &  &  &  & &\& &  \\  & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE \\  LSTM & 87.30 & 554.46 & 57.95 & 400.22 & 18.99 & 149.53 & 7.91 & 52.38 & 24.40 & 159.02 \\ SegRNN & 61.92 & 390.54 & 43.97 & 276.57 & 15.85 & 114.04 & 6.56 & 37.84 & 17.98 & 112.13 \\  CHGH & 94.30 & 629.32 & 58.06 & 401.45 & 19.00 & 149.75 & 7.90 & 52.50 & 24.37 & 159.44 \\ PreGyGAE & 78.35 & 493.83 & 48.69 & 336.15 & 17.49 & 136.66 & 7.31 & 38.88 & 19.76 & 164.43 \\  Transformer & 98.66 & 580.58 & 61.73 & 404.17 & 19.37 & 151.12 & 8.45 & 55.46 & 22.41 & 152.27 \\ Autoformer & 107.22 & 533.06 & 67.66 & 350.97 &

## 5 Conclusion

In this work, we introduced Job-SDF, a dataset designed for training and benchmarking job-skill demand forecasting models. Compiled from millions of public job advertisements collected from online recruitment platforms, this dataset includes monthly recruitment demand for 2,324 types of skills across 52 occupations, 521 companies, and 7 regions. Using this dataset, we validated a wide range of time-series forecasting approaches, including statistical models, RNN-based models, Transformer-based models, MLP-based models, Graph-based models, and Fourier-based models. Furthermore, we conducted extensive experiments to compare the performance of various methods in predicting skill demand at different granularities. We hope that Job-SDF will facilitate further research in this field.