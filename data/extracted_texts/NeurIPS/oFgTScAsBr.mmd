# Masked Pre-training Enables Universal

Zero-shot Denoiser

 Xiaoxiao Ma\({}^{1}\)1 Zhixiang Wei\({}^{1}\)1 Yi Jin\({}^{1}\)1 Pengyang Ling\({}^{1,2}\) Tianle Liu\({}^{1}\)

**Ben Wang\({}^{1}\)**Junkang Dai\({}^{1}\)**Huaian Chen\({}^{1}\)2

\({}^{1}\) University of Science and Technology of China \({}^{2}\) Shanghai AI Laboratory

{xiao_xiao,zhixiangwei,lyyang27,tleliu,wblzgrsn,junkangdai,anchen}@mail.ustc.edu.cn

{jinyi08}@ustc.edu.cn

Equal contribution.Corresponding author.

###### Abstract

In this work, we observe that model trained on vast general images via masking strategy, has been naturally embedded with their distribution knowledge, thus spontaneously attains the underlying potential for strong image denoising. Based on this observation, we propose a novel zero-shot denoising paradigm, i.e., **M**asked **P**re-train then **I**terative fill (**MPI**). MPI first trains model via masking and then employs pre-trained weight for high-quality zero-shot image denoising on a single noisy image. Concretely, MPI comprises two key procedures: **1) Masked Pre-training** involves training model to reconstruct massive natural images with random masking for generalizable representations, gathering the potential for valid zero-shot denoising on images with varying noise degradation and even in distinct image types. **2) Iterative filling** exploits pre-trained knowledge for effective zero-shot denoising. It iteratively optimizes the image by leveraging pre-trained weights, focusing on alternate reconstruction of different image parts, and gradually assembles fully denoised image within limited number of iterations. Comprehensive experiments across various noisy scenarios underscore the notable advances of MPI over previous approaches with a marked reduction in inference time. Code available at https://github.com/krennic999/MPI.

Introduction

Image denoising , as a branch of image restoration, has been the subject of extensive exploration. The prevalent approach to restore noise-degraded images is learning from multiple noisy instances. Nonetheless, both supervised learning from noisy-clean pairs  and unsupervised training  necessitate the collection of additional noisy datasets. Moreover, such methods may foster dependencies on specific patterns or intensities of training noise, hindering their performance in unfamiliar noise situations .

As an alternative, zero-shot approaches  attempt to train network on a single noisy image for denoised output, negating the need for additional noisy data collection. Dedicated to obviating concerns about generalization issues, these techniques include blind-spot networks that reconstruct from corrupted inputs , DIPs  which exploit the characteristics of deep networks to learn the mapping from random noise to noisy images, as well as sub-sample based strategies  utilize spatial correlations to generate training pairs from sub-sampled instances.

However, current zero-shot methods train new networks from scratch for each noisy image, which presents two major issues: 1) Despite success in current zero-shot approaches rely on regularization or designed priors such as noise perturbations , under-parameterized networks , dropout-ensemble  and blind-spot networks , the limited information from a single image to train network often lead to overly blurred content, noise artifacts or sub-optimal quality. Several methods tend to rely on known noise distribution  for more information, but their applicability is limited. 2) Training a new network from scratch for each noisy image is time-consuming. Existing zero-shot methods typically require several minutes  or more . And attempts at faster zero-shot denoising  often compromise on performance.

Compared to previous zero-shot approaches, learning the feature distribution from vast natural images offers a more intuitive approach. This is grounded in two considerations: Real natural images are both abundant and readily available, and despite variations in noise patterns, many natural images share common characteristics . We seek to enhance zero-shot denoising with minimal reliance on pre-defined priors or regularization, aiming for a better startpoint for various noise patterns instead of from scratch. To this end, we delve into the potential of masked image modelling  on natural images with no assumptions about noisy patterns and intensities . Specifically, we make the following observation: combined with a simple ensemble operation, **a masked pre-trained model can naturally denoise images with unseen noise degradation**.

Building upon above observation, we introduce a zero-shot denoising paradigm, _i.e._, Masked Pre-train then Iterative fill (MPI). MPI first pre-trains a model on ImageNet with pixel-wise masking strategy, then the pre-trained model is optimized on a single image with unseen noise for denoised prediction in zero-shot inference stage. The optimization goal in inference is designed to predict masked regions, and only predictions of masked areas are preserved for denoised prediction, thereby minimizing the gap between pre-training and inference. The pre-trained weights provide more generic knowledge, preventing premature over-fitting during inference and reducing the need for strong regularization. We are able to handle a wider range of noise scenarios with less information about noise patterns or intensities. Remarkably, we find that extracted representation can even generalize to medical images that distinctly different from natural ones . It also offers a better startpoint than scratch training, enabling high-quality denoising around 10 seconds, underscoring the potential of our method in practical application. The main contributions of this paper are as follows:

* We introduce a novel zero-shot denoising paradigm, _i.e._, Masked Pre-train then Iterative fill (MPI), which introduces masked pre-training in this context for the first time, simultaneously improving both image quality and inference speed on unseen noisy images.
* We develop a pre-training scheme with pixel-wise random masks to capture distribution knowledge of natural images. Based on pre-trained knowledge, we propose iterative filling for zero-shot inference on a specific noisy image. This process is optimized using pre-trained weights, and focuses on alternatively reconstruct different parts of noisy image, predictions in iterations are sequentially assembled for high-quality denoised output with efficiency.
* Extensive experiments demonstrate MPI's superiority, efficiency and robustness in diverse noisy scenarios. In nutshell, MPI achieves significant performance gains across various noise types with reduced inference time, highlighting its potential for practical applications.

Methods

In Sec. 2.1, we first investigate the properties of models trained with masking, proving that models trained with masking strategy can learn representations beneficial for denoising. Our observation lead us to propose a zero-shot denoising paradigm that includes pre-training (Sec. 2.2) and iterative optimizing (Sec. 2.3). We further illustrate how to remove spatially correlated real noise in Sec. 2.4.

### Motivation

Masked Image Modeling  has significantly advanced computer vision by training on vast natural image sets to grasp their knowledge distributions. It shows great potential applicability under diverse scenarios and have been proven beneficial for high-level downstream tasks .

To further explore its capability in denoising, we train a model on natural images with pixel-wise random masks (for details, see Sec. 2.2) and assess its performance against a target image with unseen noise distribution. Surprisingly, we observe that a simple average of predictions from a fixed-state trained model can denoise on unseen noise, as shown in Fig. 3, sometimes achieve remarkably good performance, as an example is presented in Fig. 3. This observation suggests that **a masked pre-trained model can serve as a natural image denoiser.** However, artifacts exist in the results, which can be attributed to lack of knowledge about specific degradation patterns in the target image.

Drawing on prior insight, we develop an efficient zero-shot denoising pipeline, leveraging pre-trained knowledge by incorporating noise characteristics from a single noisy image (Fig. 4), _i.e._, Masked Pre-train then Iterative fill. The model is firstly pre-trained with random masks \(M\) and corresponding element-wise negation \(\) to acquire natural image distributions, formulated as:

\[_{}p(I|I M;),\] (1)

for \(I\) indicates natural image without any degradation priors, typically sourced from extensive datasets (_e.g._ImageNet ). We use element-wise multiplication (\(\)). For denoising on specific noisy image \(x\), pre-trained parameter \(\) is loaded and further optimized with known \(x\) from \(t\)=1 to \(t\)=\(T\) for \(T\) iterations, and predictions are aggregated for final prediction \(\):

\[=Ensemble\{_{_{t}}(x)\}_{t=1}^{T},\] (2)

where \(_{_{t}}()\) is network parameterized by \(_{t}\), optimized from pre-trained \(\). Masked Pre-training process is detailed in Sec. 2.2 and Ensemble in Sec. 2.3.

### Masked Pre-training

**Masking strategy.** Given the distinct requirements between low-level and high-level tasks in "semantics" , we implement specialized masking strategy to achieve finer-grained image representations, _i.e._, a pixel-wise masking strategy. Specifically, given an input image \(I^{H C}\) divided into random patches of size 1, a subset of them are randomly replaced by mask token with probability \(p\) (for further discussion of \(p\), see Sec. 4). When the mask token is set to 0, the masked image \(M I\) with random mask \(M^{H W C}\) corresponds to a bernoulli sampling of the input image \(I\). For each element \(M_{[k]}\) in \(M\), we have:

\[M_{[k]}=\{0,&with\ prob.\ \ p;\\ 1,&with\ prob.\ \ 1-p..\] (3)

**Pre-training scheme.** During pre-training, the network \(_{}()\) is trained to learn recovering natural image \(I\) itself with random mask \(M\):

\[=_{}(M I).\] (4)

We set the same optimization strategy outlined in , focusing loss computation on masked prediction areas \(\). This directs network efforts towards reconstructing these specific regions, with the reconstruction loss denoted as \(L_{rec}\):

\[L_{rec}(,I)=\|- I\|_{2}.\] (5)

The Mean Squared Error (MSE) loss is adopted to learn relatively smoother representation. For the architecture of network \(()\), we employ the same U-shaped hourglass architecture as in DIP , which has been proven a powerful zero-shot denoising architecture . Furthermore, its relatively small parameter configuration enables accelerated training, alleviating potential inference computational costs and rendering it more appropriate for zero-shot denoising tasks.

``` Input: Noisy image \(x\), pre-trained parameter \(\), network \(()\), exponential weight \(\), masking ratio \(p\). Output: denoised ensemble \(\) from predictions of iteration \(\{y_{t}\}\).  load pre-trained parameter \(\) for \(()\) as \(_{1}\)  initialize \(\) for\(t\) from \(1\) to \(T\)do  generate random mask \(M_{t}\) with mask ratio \(p\) \(y_{t}=_{_{t}}(M_{t} x)\) \(_{t}= M_{t}\) \(_{t+1}=_{t}-_{}\|_{t} y_{t}-_ {t} x\|_{2}\) \(_{t}(+(1-) y _{t})+M_{t}\) return\(\) ```

**Algorithm 1****Iterative filling.** Pipeline designed to leverage pre-trained representation \(\) for zero-shot denoising.

Figure 4: An overview of the proposed MPI paradigm consisting Masked Pre-training and Iterative filling. During pre-training \(_{}()\) learns to reconstruct masked natural images. And the pre-trained weights \(\) are saved for zero-shot denoise, _i.e._, Iterative filling, to denoise a specific noisy image \(x\). During zero-shot inference, network is initialized with pre-trained weights \(\), then the weights are further optimized on \(x\) for \(T\) steps, results from \(t\)-th (\(t\)=\(1,2,,T\)-\(1\)) optimizing steps are gathered to obtain final denoised prediction \(\). Compared to current zero-shot methods, just adding one more step to load a pre-trained model enables faster and high-quality zero-shot denoising.

### Iterative Filling

**Overall design.** As observed in Sec. 2.1, an iterative optimization process is designed to leverage pre-trained knowledge for zero-shot denoising. Unlike other MIM approaches [26; 27] that fine-tune with entire images as input, since only one noisy image is accessible, we employ a self-supervised manner to learn the mapping from a noisy image to itself. However, this direct self-mapping approach introduces significant gap between the zero-shot inference stage and pre-training stage and lacks constraints for learning a noise identity mapping.

Considering above challenges, we retain the same masking strategy in Sec. 2.2 for both input and loss computation, _i.e._, network still learns to reconstruct masked regions, but from single noisy image rather than natural images. This leads to a pixel-based iterative refinement process, which resembles mechanism of blind-spot networks . Specifically, for input noisy image \(x\), random mask \(M_{t}\) and its element-wise negation \(}\) in \(t\)-th iteration, prediction \(y_{t}\) and aggregated result \(\) can be derived:

\[y_{t} =_{_{t}}(M_{t} x);\] (6a) \[ =_{t}a_{t} y_{t}},\] (6b)

where \(_{t}\) denotes network parameter at iteration \(t\), \(a_{t}\) is corresponding coefficient where \(_{t}a_{t}=1\). The optimization objective at each iteration is as follows:

\[*{arg\,min}_{_{t}}\|} y_{t}-} x\|_{2}.\] (7)

The optimization task, represented by \(L_{rec}(y_{t},x)\), learns to reconstruct noisy image cropped by random masks, aligns with pre-training. The alignment minimizes the gap between pre-training and zero-shot inference to avoid over-fitting, and reduces the inference steps required, thus accelerating the denoising process. Thanks to the well-crafted mechanism, we can accomplish high-quality results with preserved details in reduced time **without any other regularization**.

**Pixel-based iterative refinement.** For a lower mask ratio and reconstruction of more detailed images, we abandon constraints on unmasked regions in previous optimization goals (Eq. 5 and Eq. 7), thus

    & \(\) & DIP  & N2V*  & N2S*  & ZS-N2N  & FasterDIP  & Ours (faster) & Ours \\   & 10 & 32.05/0.829 & 31.55/0.885 & 28.04/0.819 & 33.87/0.883 & 31.59/0.815 & 33.82/0.889 & **34.91/0.909** \\  & 25 & 30.42/0.795 & 29.39/0.814 & 28.19/0.777 & 29.55/0.765 & 30.19/0.766 & 30.83/0.824 & **31.61/0.841** \\  & 50 & 24.73/0.533 & 27.35/0.694 & 26.62/0.699 & 26.10/0.624 & 26.09/0.669 & 28.14/0.715 & **28.26**/0.710 \\   & 10 & 32.48/0.878 & 39.08/0.877 & 28.61/0.839 & 34.19/0.908 & 31.48/0.842 & 34.35/0.921 & **35.46/0.937** \\  & 25 & 31.07/0.856 & 29.11/0.833 & 27.59/0.776 & 29.37/0.786 & 29.47/0.794 & 30.99/0.862 & **31.90/0.879** \\  & 50 & 25.72/0.639 & 24.65/0.676 & 24.89/0.673 & 25.82/0.634 & 24.75/0.663 & 28.15/**0.779** & **28.37**/0.770 \\   & 10 & 31.18/0.685 & 31.18/0.918 & 28.17/0.853 & 33.73/0.923 & 30.89/0.857 & 34.20/0.935 & **35.14/0.947** \\  & 25 & 29.29/0.828 & 27.51/0.812 & 26.93/0.796 & 29.01/0.815 & 28.57/0.806 & 30.00/0.854 & **30.58/0.865** \\  & 50 & 23.06/0.540 & 25.74/0.700 & 24.78/0.695 & 25.37/0.657 & 24.75/0.669 & **27.05/0.712** & 26.85/0.703 \\   & 451.9 & 153.9 & 147.9 & 16.8 & 149.2 & **10.1** & 51.6 \\   

Table 1: Quantitative comparison on CSet, McMaster & CBSD for **Gaussian noise removal**. Best results **highlighted** and second underlined. See Supp. for poisson noise removal.

Figure 5: Qualitative denoising results on Gaussian and Poisson noise. The quantitative PSNR/SSIM results are provided underneath. Noisy patches are from CBSD-44 and McMaster-14, respectively. Best viewed in color (zoom-in for better comparison).

making information under these areas unreliable, we preserve only the results corresponding to \(\) for final denoised outcome \(\). However, as one forward pass provide partial denoising results, an ensemble process is crucial. Specially, we employ an Exponential Moving Average (EMA) strategy to optimize the use predictions during iterations with little increase in inference time (Sec. 4):

\[=_{t}(+(1-) y_{t})+M_{t }.\] (8)

For an in-depth look at proposed ensemble algorithm, see Alg. 1. During inference, the pre-trained weights not only provide a better startup but also act as regularization for the network, preventing from over-fitting too early and leading to better performance with less inference time (Sec. 4).

### Adaptation to Real-world Noise Removal

Real-world noise exhibit strong spatial correlations, _i.e._the noise is correlated across adjacent pixels. In such scenarios, employing a straightforward masking mechanism still allows the model to learn information related to noise patterns. To address this problem, we apply larger masking ratios than that used for synthetic noise. Additionally, we integrate a simple Pixel-shuffle Down-sampling (PD) mechanism during zero-shot inference to reduce spatial correlation in noise.

Specifically, instead of directly processing noisy image \(x^{1 C H W}\) in Eq. 6a, we handle its down-sampled versions \(Down(x)^{d^{2} C}\) using simple Pixel-shuffle with factor \(d\), and \(d^{2}\) sub-samples are concatenated along patch dimension for joint denoising. Following the same iterative filling mechanism described above, we apply pixel unshuffle to the denoised result \(\) to obtain final denoised outcome \(Up()\). We add minimal PD operations to address spatial correlated noise, illustrating the effect of pre-trained weights, performance on real-world noisy dataset can be improved by applying better sub-sampling approaches  (Sec. 4.2) as they have been intensively studied.

## 3 Experiments

We assess our method against typical methods including DIP , Noise2Void (N2V) , Noise2Self (N2S) , Zero-Shot Noise2Noise (ZS-N2N) , and FasterDIP . We modify N2V and N2S to single-image version (N2V* and N2S*). EMA ensemble result of DIP and FasterDIP are reported with their official code. Refer to supplementary material (Supp.) for EMA results of N2V* and N2S*, and comparison with more DIP-based , diffusion-based , zero-shot modifications from unsupervised methods . Only non-ensemble ZS-N2N is presented due to negligible performance differences with EMA version. We compare Peak Signal-to-Noise Ratio (PSNR) and

   &  &  &  \\   & SwinIR  & Restformer  & NB2Nb  & B2U  & DIP  & ZS-N2N  & Ours (faster) & Ours \\  Gaussian \(\)=25 & 32.890/8.995 & **33.040/8.97** & 32.060/8.80 & 32.260/8.80 & 30.050/8.06 & 29.460/7.775 & 30.940/8.848 & 31.780/8.655 \\ Gaussian \(\)=1(10,50) & 27.290/6.28 & 30.000/7.29 & 28.680/7.13 & 29.240/7.26 & 29.560/7.783 & 29.360/7.53 & 30.890/8.372 & **31.66/0.846** \\ Poisson \(\) & 25.060/8.062 & 32.56/8.63 & 27.31/7.03 & 28.220/7.18 & 28.670/7.58 & 28.170/7.32 & 29.940/8.26 & **35.07/8.032** \\ NLT-from  & 32.52/8.062 & 31.710/8.857 & 31.880/8.859 & 31.890/8.59 & 27.10/7.082 & 31.20/8.54 & 32.260/8.836 & **33.15/8.901** \\ Speckle \(\) & 31.97/8.0841 & 33.52/8.884 & 31.31/8.037 & 31.65/8.47 & 30.730/8.18 & 33.780/8.91 & 34.790/9.242 & **35.790/9.933** \\ Seq \(d\)\([0.02,0.05]\) & 23.96/0.614 & 23.63/0.613 & 27.04/0.656 & 29.44/0.796 & 29.540/8.00 & 35.25/0.952 & 35.05/0.953 & **36.87/0.964** \\  Average & 28.940/7.44 & 29.730/7.77 & 29.710/8.00 & 30.470/8.04 & 29.710/7.098 & 31.17/0.823 & 23.10/8.729 & **33.30/8.990** \\  

Table 2: Quantitative **generalization evaluation** results on Kodak. All supervised/unsupervised methods trained on \(\)=25 Gaussian, tested on 5 unseen noise types. (Average from all 6 settings.)

Figure 6: Qualitative results on unseen noise types. Restformer is trained with Gaussian \(\)=25. Noisy patches are from kodim07 and kodim12.

Structure Similarity Index Measure (SSIM) on synthetic (Sec. 3.2, Sec. 3.3) and real noise (Sec. 3.4). Additional tests on medical images (Sec. 3.5) show our method's adaptability beyond natural images.

### Experimental Setup

**Pre-training.** Pre-training is performed on two Nvidia RTX 3090 GPUs using Adam optimizer with \(_{1}\)=0.9 and \(_{2}\)=0.9. Initial learning rate is \(2e^{-3}\) and decays to \(1e^{-5}\) with cosine annealing strategy over 80K iterations with a batch size of 64. We initiate pre-training on randomly cropped 256\(\)256 patches from subset of ImageNet  with around 48,000 images. Two sets of pre-trained weights with masking probability \(p\) (\(p\)=0.3 for synthetic noise and a higher ratio of 0.8\(\)0.95 for spatially correlated noise) are trained. Further discussion of \(p\) is in Sec. 4.

**Zero-shot inference.** We set learning rate during inference to \(2e^{-3}\), and same masking ratio \(p\) as pre-training (0.3 for synthetic, 0.8\(\)0.95 for real noise) is set. EMA weight \(\)=0.99 for 1000 iterations (specially, 800 iterations for SIDD). Additionally, with \(\)=0.9, we achieve performance surpassing most zero-shot methods within 200 iterations, denoted as **"faster"**. See Supp. for detailed setting.

### Gaussian & Poisson Noise

We investigate Gaussian Noise with \(\)\(\) and Poisson noise with \(\)\(\) separately on three datasets: CSet , McMaster  and CBSD , with 9, 18 and 68 high-quality images, respectively. Results are shown in Table 1. The model is tested across various noise types with same experimental setups, without prior knowledge of noise distribution or intensity.

**Analysis.** DIP tends to produce over-blurry results and struggles especially with intense noise. While ZS-N2N manages to remove weak noise, its simple down-sample approach falters with stronger noise and cause artifacts. As Fig. 5 illustrates, under Gaussian noise \(\)=25 and Poisson noise \(\)=25, our method excels in both noise reduction and detail preservation. In some cases, we see an improvement of over 1dB, highlighting the effectiveness of our zero-shot paradigm.

Average inference time is listed in Table 1. Our "faster" version achieve the fastest inference speed while surpassing comparing methods in most cases. Even with \(=0.99\), our method exhibits competitive inference time and significantly better performance. Params and FLOPs are in Supp.

    &  &  &  & Avg. Infer. \\    & validation & & & & time (s) \\  DIP  & 33.68/0.802 & 33.67/0.863 & 37.91/0.952 & 32.85/0.840 & 333.2 \\ N2V*  & 26.74/0.627 & 25.34/0.595 & 35.04/0.921 & 29.79/0.817 & 98.1 \\ N25*  & 26.78/0.573 & 26.93/0.658 & 32.82/0.930 & 31.61/0.759 & 114.4 \\ ZS-N2N  & 25.59/0.422 & 25.61/0.559 & 36.04/0.915 & 31.65/0.768 & 15.1 \\ FasterDIP  & 33.55/0.795 & 33.55/0.859 & 37.99/0.957 & 32.07/0.821 & 138.2 \\ Ours (faster) & 33.68/0.828 & 33.60/0.896 & 37.62/0.957 & 32.68/0.846 & **7.9** \\ Ours & **34.43/0.844** & **34.32/0.903** & **38.11/0.962** & **32.97/0.847** & 37.2 \\   

Table 3: Quantitative comparison on SIDD, PolyU and FMD for **real noise removal**.

Figure 7: Qualitative results on real noise removal from SIDD and PolyU. Noisy patches are from SIDDval31_1 and Canon80D_8\(8\)3200_ball_16.

### Generalization on Unseen Noise

We believe zero-shot denoising with natural image knowledge offers new perspectives on improving generalizability of denoising methods. We select several recent supervised (SwinIR , Restormer ) and unsupervised (Neighbor2Neighbor , Blind2Unblind ) methods trained on Gaussian with \(\)=25 for demonstration. Testing them on 5 unknown noise types on Kodak .

**Analysis.** As illustrated in Table 2 and Fig. 6, although methods trained on multiple noisy images achieve better results on noisy cases with the same distribution, they exhibit poor generalization performance. In contrast, zero-shot methods often perform better generalization capabilities, especially our method which achieves the best performance across all types of generalization noise.

### Real Noisy Datasets

We assess denoising capability of MPI on synthetic noise in previous experiments. However, real-world noise is more complicated and challenging. We test on SIDD  and PolyU  datasets, including 1280 patches from the SIDD validation and 1280 from SIDD benchmark, and all 100 official patches from PolyU to show our paradigm on real images. Due to the differences between synthetic and real noise, we report results from comparison methods from their optimal iteration.

**Analysis.** As shown in Table 3, our method excels over other zero-shot approaches on both datasets. This underlines our method's effectiveness on real-world noise removal. Fig. 7 show our method's capability to balance noise removal and detail retention. In essence, our method is adept at real-world denoising, offering a robust solution for image quality enhancement in challenging situations.

### Generalization to Medical Images

The pre-trained model, which has learned the feature distributions of natural images, raises a question: Can this knowledge be applied to other image types? To answer this question, we select a fluorescence microscopy dataset (FMD)  characterized by colors and textures distinctly different from natural images, using all released 48 images in testset for evaluation. See Supp. for more image types.

**Analysis.** Our method still excels in denoising performance, as seen in Table 3. Despite such monochromatic microscopic images are not included in pre-training dataset and exhibits large differences between natural images, pre-trained knowledge still enhances zero-shot denoising performance, as evidenced in Fig. 8 and Table 4, demonstrating the generalizability of pre-trained weights.

Figure 8: Validation of pre-trained representations on image content differs from natural images. Comparing between “Baseline” (w/o pre-train) and “Ours” (w pre-train). Noisy patch is from TwoPhoton_MICE_3. See quantitative comparison at Table 4.

Figure 9: Effect of pre-trained model. Examples using Gauss \(\)=25 removal on F_16 with \(\)=0.99. Pre-trained results are labeled in orange, while default initialized results are labeled in blue.

[MISSING_PAGE_FAIL:9]

**Over-fitting.** Although pre-training mitigates over-fitting for synthetic and real noise, the over-parameterized network may still learn noise patterns over time due to lack of explicit mechanisms to avoid identity mapping. This is common challenge in many zero-shot models, we suggest early-stopping  (Table 6,"ES" for early-stopping) to avoid over-fitting and reduce inference time.

Additionally, we compare with other over-fitting prevention methods, _e.g._, TV regularization of output and augmentation to input image. These approaches either resulted in suboptimal performance or longer inference times. More details on over-fitting and prevention strategies can be found in Supp.

**Sub-sampling.** Shown in Sec. 2.4, minimal pixel-shuffle is used to reduce spatial correlation in real-world noise, but may cause chessboard artifact and reduce performance due to its regular downsampling strategy. Better down-sampling strategies have been widely studied, and here we choose RSG  to illustrate, see results at Table 7. For more comparison and visual comparison, see Supp.

## 5 Acknowledgements

This work was supported in part by the National Natural Science Foundation of China under Grant 62401532, in part by the Anhui Provincial Key Research and Development Plan 202304a05020072, and in part by the Anhui Provincial Natural Science Foundation 2308085QF226, in part by the Fundamental Research Funds for the Central Universities WK2090000065, and in part by the China Postdoctoral Science Foundation under Grant 2022M720137.

   Methods/ &  & Avg. Infer. \\ PSNR & 1,000 & 1,100 & 1,500 & time (s) \\  Ours & 31.61 & 31.58 & 31.35 & 62.6 \\ Ours+ES  & 31.66 & 31.65 & 31.66 & 51.7 \\   

Table 6: Discussion on over-fitting.

   Ensemble strategy & PSNR/SSIM & Time (s) \\  Avg after 500e & 30.88/0.793 & 48.3 \\ Average & 31.28/0.835 & 49.7 \\ EMA w/o mask & 23.48/0.441 & 52.1 \\ w/o Ensemble & 30.23/0.797 & 51.7 \\ Last & 13.73/0.154 & 49.0 \\ EMA & 31.61/0.841 & 53.5 \\   

Table 5: Ablation of ensemble strategy. “Time (s)” denotes Infer. time (s)