# Chicks4FreeID: A Benchmark Dataset for Chicken Re-Identification

Daria Kern\({}^{1,2}\)1

Tobias Schiele\({}^{1,2}\)1

Ulrich Klauck\({}^{1,3}\)

Winfred Ingabire\({}^{2}\)

\({}^{1}\)Aalen University, Germany

{daria.kern, tobias.schiele, ulrich.klauck}@hs-aalen.de

\({}^{2}\)Glasgow Caledonian University, United Kingdom

winfred.ingabire@gcu.ac.uk

\({}^{3}\)University of the Western Cape, South Africa

###### Abstract

To address the need for well-annotated datasets in the field of animal re-identification, and particularly to close the existing gap for chickens, we introduce the Chicks4FreeID dataset. This dataset is the first publicly available re-identification resource dedicated to the most farmed animal in the world. It includes top-down view images of individually segmented and annotated chickens, along with preprocessed cut-out crops of the instances. The dataset comprises 1215 annotations of 50 unique chicken individuals, as well as a total of 55 annotations of 2 roosters and 2 ducks. In addition to re-identification, the dataset supports semantic and instance segmentation tasks by providing corresponding masks. Curation and annotation were performed manually, ensuring high-quality, nearly pixel-perfect masks and accurate ground truth assignment of the individuals using expert knowledge. Additionally, we provide context by offering a comprehensive overview of existing datasets for animal re-identification. To facilitate comparability, we establish a baseline for the re-identification task testing different approaches. Performance is evaluated based on mAP, Top-1, and Top-5 accuracy metrics. Both the data and code are publicly shared under a CC BY 4.0 license, promoting accessibility and further research. The dataset can be accessed at [https://huggingface.co/datasets/dariakern/Chicks4FreeID](https://huggingface.co/datasets/dariakern/Chicks4FreeID) and the code at [https://github.com/DariaKern/Chicks4FreeID](https://github.com/DariaKern/Chicks4FreeID).

Figure 1: Excerpt from the Chicks4FreeID dataset.

Introduction

### Motivation

Chickens struggle to recognize other individuals after visible changes are applied to the comb or plumage . Much like chickens are able to use visual cues to differentiate each other, artificial intelligence (AI) is capable of utilizing image or video inputs for re-identification purposes. AI-driven re-identification and tracking systems hold great potential for enhancing animal husbandry and livestock farming. These systems may allow for the observation of social structures and behavior, enhance welfare, and potentially lead to more efficient animal management with minimal disruption to the livestock . They also may help assess health and well-being, i.e., by providing crucial traceability during disease outbreaks. Furthermore, they offer a cost-effective and non-invasive alternative to manual tagging methods.

Despite the significant potential, there is a notable gap in publicly available datasets for such technologies, especially for chickens -- the most farmed animal globally. Remarkably, to our knowledge, no publicly available dataset for chicken re-identification exists, highlighting an urgent need for development in this field. Public datasets for the task of individual animal re-identification in general are scarce [3; 2]. In particular, well-annotated datasets . The practice of openly sharing data and code should be encouraged to enhance result comparability, yet not all research data are currently made public. In their work,  emphasize the importance of creating and sharing publicly available and well-annotated benchmark datasets for the task of animal re-identification.

Establishing a benchmark dataset involves evaluating how well existing methods solve the dataset. The reported metrics serve as a baseline for future researchers to report their improvements. Given the diverse nature of research, it is important for the baseline to cover common approaches and common metrics. This ensures that the achievements of future researchers can be effectively compared, facilitating a standardized assessment of advancements in the field.

### Contribution

We address the existing gap and present our Chicks4FreeID dataset, which does not only support the task of re-identification but also semantic and instance segmentation. We make this thoroughly documented dataset freely accessible to the research community and the public. The dataset includes 54 individuals, of which 50 are chickens. Each occurrence is nearly pixel-perfectly segmented, resulting in 1270 instance masks. Based on the cut-out crops of 1215 chicken instance masks, we provide an initial baseline for the task of closed set re-identification. This allows the research community to compare their methods and results effectively. In summary:

1. We provide a comprehensive overview of publicly available datasets for animal re-identification.
2. We introduce the first publicly available dataset for chicken re-identification.
3. We establish a baseline for closed set re-identification on the introduced dataset.

## 2 Related work

### Animal re-identification

Animal re-identification, the task of identifying individual animals within one (or sometimes several) species, finds applications in various fields. Particularly in wildlife conservation efforts, where monitoring endangered species is crucial [6; 7; 8; 9]. But also in livestock management, notably cattle [10; 11; 12; 13; 14] and yak . Honeybees  and bumblebees [16; 17] have also been subject to investigation.

Re-identification falls into one of two categories: closed set and open set. In closed set re-identification, all individuals are known from the beginning, and those to be identified can be matched with identities of a predefined set. In open set re-identification, the identity of the individual 

[MISSING_PAGE_FAIL:3]

## 3 The Chicks4FreeID dataset

### Data

The Chicks4FreeID dataset contains top-down view images of individually segmented and annotated chickens, with some images also featuring roosters and ducks. Each image is accompanied by a color-coded semantic segmentation mask that classifies pixel values by animal category (chicken, rooster, duck) and background, as well as binary segmentation mask(s) for the animal instance(s) depicted. Additionally, the dataset includes preprocessed cut-out crops (detailed in Section 3.5) of the respective animal instances. Figure 2 gives a first overview of the dataset.

   Year & Publ. & Dataset & IDs & Species & Annot. & Avail. at \\   & ours & Chicks4FreeID & 50, 2, 2 & chicken, duck, rooster & 1215, 40, 15 &  \\
2024 &  & SaFurtleID2022 & 438 & sea turtle & 8729 &  \\
2023 &  & Mammal Club (IISD) & 218 & 11 terrestrial mammal species* & 33612 &  \\
2023 &  & Multi-pose dog dataset & 192 & dog & 1657 &  \\
2023 &  & PolarBeraVidID & 13 & polar bear* & 138363 &  \\
2023 &  & Sea Star Re-ID & 39, 56 & common starfish, Australian cushion star & 1204, 983 &  \\
2022 &  & Animal-Identification- & 58, 26, 9 & pigeon*, pig*, Koi fish* & 12671, 6184, &  \\  & from-Video & & & & 1635 & \\
2022 & n.a. & Beluga ID & 788 & beluga whale & 5902 &  \\
2022 & n.a. & Happywhale & 15587 & 30 different species of whales and dolphins & 51033 &  \\
2022 & n.a. & Hyiem ID & 256 & spotted hyena & 3129 &  \\
2022 & n.a. & Leopard ID & 430 & African leopard & 6805 &  \\
2022 &  & SealID & 57 & Saiman ringed seal & 2080 &  \\
2022 &  & SeaTurtleIDHeads & 400 & sea turtle & 7774 &  \\
2022 & n.a. & Turtle Recall & 100 & sea turtle & 2145 &  \\
2021 &  & Cow Dataset & 13 & cow & 3772 &  \\
2021 &  & Cow2021 & 182 & Holstein-Friesian cattle* & 13784 &  \\
2021 &  & GinfaDataset & 62 & giraffe & 624 &  \\
2021 &  & iPanda-50 & 50 & giant panda & 6874 &  \\
2020 &  & AuxJ Zebrafish Dataset & 6 & zebrafish* & 6672 &  \\
2020 &  & Animal Face Dataset & 1040 & 41 primate species & 102399 &  \\
2020 &  & ATRW & 92 & Amur tiger* & 3649 &  \\
2020 &  & Lion Face Dataset & 94 & lion & 740 &  \\
2020 &  & NDD20 & 44, 82 & bottlenose and white-beaked dolphin, & 2201, 2201 &  \\  & & & & white-beaked dolphin (underwater)* & & \\
2020 &  & Nyala Data & 237 & nyala & 1942 &  \\
2020 &  & OpenCows2020 & 46 & Holstein-Friesian cattle* & 4736 &  \\
2019 &  & Bird individualID & 30, 10,10 & sociable weaver, great tit, zebra finch & 51934 &  \\
2019 &  & Dog Face Dataset & 1393 & dog & 8363 &  \\
2018 &  & Cat Individual Images & 518 & cat & 13536 &  \\
2018 &  & Fruit Fly Dataset & 60 & fruit fly* & 2592000 &  \\
2018 & n.a. & HumpekWhaleID & 5004 & humpback whale & 15697 &  \\
2018 &  & MacaqueFace & 34 & rhesus macaque* & 6280 &  \\
2017 &  & AerialCattle2017 & 23 & Holstein-Friesian cattle & 46340 &  \\
2017 &  & FriesianCattle2017 & 89 & Holstein-Friesian cattle* & 940 &  \\
2017 &  & GZGC & 2056 & pizins zebra and Masiá giraffe & 6925 &  \\
2016 &  & C-Tai & 78 & chimpanzee & 5078 &  \\
2016 &  & C-Zoo & 24 & chimpanzee & 2109 &  \\
2016 &  & FriesianCattle2015 & 40 & Holstein-Friesian cattle* & 377 &  \\
2015 & n.a. & Right Whale Recognition & 447 & North Atlantic right whale & 4544 &  \\
2011 &  & StripeSpotter & 45 & plains and Grevy’s zebra & 820 &  \\
2009 &  & Whale Shark ID & 543 & whale shark & 7693 &  \\   

Table 1: Publicly available animal re-identification datasets, arranged by date of publication. An asterisk (*) marks data derived from video footage.

Figure 2: Dataset overview.

### Collection

Various coops of private households were visited to photograph chickens. Among these coops, two additionally accommodate a rooster each, while another houses two ducks. A total of 677 images were captured using two similar models of cameras: the "Sony CyberShot DSC-RX100 VI" and the "Sony CyberShot DSC-RX100 I". The resolution of the images stands at 3648x5472 pixels. Every image includes at least one chicken, ensuring no images without chickens are part of the dataset. It was collected over the span of one year, however all images of a coop were shot within one day. In other words, all photos of a given individual were taken on the same day. The images were captured from a top-down view perspective, aiming to capture the plumage. The dataset is not limited to a single breed of chicken, ensuring a certain level of variability.

### Annotation

We utilized Labelbox  under a free educational license for manual data annotation.

Instances and backgroundFor each animal instance appearing within an image, a segmentation was meticulously hand-crafted by a human annotator. No AI has been used during the annotation process to ensure high-quality, nearly pixel-perfect instance masks. The instance masks include the comb, head, beak, and plumage. Feet were excluded as rings could give away the identity. Feet and scattered feathers are considered part of the background, along with any visible objects or living beings that are not chickens, roosters, or ducks. Compared to conventional bounding boxes, instance masks offer the advantage of better supporting the subsequent re-identification process. The background can be easily removed as it might contain unwanted clues about the identity of the chickens. Furthermore, the provided masks render the dataset well-suited for instance segmentation tasks as well.

Animal categoriesEach instance of an animal was assigned to one of three animal categories. These are "chicken", "rooster", and "duck". Roosters and especially ducks serve as exceptions within the predominantly chicken-based collection. This characteristic potentially positions the dataset as a resource for anomaly detection as well.

Identities and coopsThe identities of the subjects were meticulously studied prior to photography, closely monitored throughout the image capture process, and ultimately assigned by a human annotator. The ground truth annotation was performed without the use of any algorithm. In cases where the human annotator could not assign an identity, the instance was labeled as identity "Unknown". It is essential to clarify that the label "Unknown" does not imply the presence of a new individual. Instead, it represents an unidentified individual from the closed set, more precisely, from the annotated coop. Each image contains one or more chickens, all of which are individually identified by their unique names. Roosters and ducks are each also uniquely named. Furthermore, each instance is explicitly annotated to indicate the specific coop to which it belongs.

Visibility ratingAcknowledging varying visibility of the subjects (chickens, roosters, ducks) within the images, each appearance has been manually assigned a visibility rating, categorized as either "bad", "good", or "best". The "best" rating includes segmentation instances that fully display the subject from the desired top-down perspective, and those where only an insignificant part is missing, such as the very tip of the tail feathers. Instances that include only small parts of the subject and on which the subject is difficult to recognize fall under the "bad" rating. All remaining segmentation instances, that do not qualify as "bad" or "best", are rated as "good".

### Composition

The dataset comprises a collection of 677 images, featuring a total of 50 distinct chicken, 2 rooster, and 2 duck identities distributed across 11 different coops. A total of 1270 instances were obtained by segmenting 1215 appearances (instances) of chickens, alongside 15 roosters and 40 ducks.

Each instance is of a certain animal category ("chicken", "rooster", "duck") and was assigned the corresponding coop (1-11), visibility ("best", "good", "bad") and identity (1 of 54 names or "Unknown"). It is important to mention that no "Unknown" instances are present in the "best" or "good" subset. The ground truth identity for all instances in these subsets is, therefore, known. Figure 3 illustrates the number of instances for each individual, as well as the visibility rating of the instances. It starts with the individual with the most instances in the "best" subset and is arranged in descending order. The most represented chicken in the "best" subset is Mirmir with 27 instances, whereas Isolde is the least represented chicken with 4 instances.

### Preprocessing

The following steps describe the preprocessing procedure to obtain the cut-out crops for the re-identification task. For all individuals captured in an image, a bounding box is created based on the instance masks. In the first step, both the image and the mask are cropped (to the area of interest contained in the bounding box) to focus solely on the individual (see Figure 4: Step 1). The cropped mask is then used to remove the background from the cropped image (Step 2). Finally, the resulting image is adjusted to a square shape for ease of use and consistency (Step 3). The resulting resolutions remain as is, with no resizing taking place.

Figure 4: Data preprocessing pipeline for subsequent re-identification.

Figure 3: Visibility distributions for all instances of each individual. Ducks and roosters are marked with an asterisk (*).

Experiments

### Dataset, split and augmentation

For the closed set re-identification experiments, we utilize preprocessed cut-out crops as described in Section 3.5. To focus solely on all 50 chicken identities, the four identities of ducks and roosters were excluded. By removing instances of visibility level "good" and "bad", we ensure that only instances with "best" visibility are included. The utilized "best" subset does not contain any "Unknown" instances. The number of chicken instances contained in the "best" subset is 793.

The employed data is split into 630 train pairs and 163 test pairs of cut-out crops and the assigned identities. To ensure that the testing set does not introduce any new identities, we include all possible identities in the training set. For a fair evaluation on all identities, the train/test split is stratified, i.e., each identity has the same fixed percentage of its cut-out crops allocated to the test set. Consequently, identities with a higher total number of crops will contribute more to the test set compared to identities with fewer crops, ensuring proportional representation across all identities. The corresponding subset on Hugging Face is "chicken-re-id-best-visibility".

To avoid data leakage, it is important to apply data augmentation only after a train-test split is established. This ensures that augmented versions of the same original image do not appear in both sets. We dynamically apply the following data augmentation during training on the "chicken-re-id-best-visibility" subset: rotation, flip, RandAugment , and random color-jitter. No data augmentation is applied to the test set.

### Baseline approaches

To establish a baseline for the closed set re-identification task, we test three different approaches on our dataset. Each approach involves two steps. First, a feature extractor generates embeddings for the cut-out crops. Second, the resulting feature vectors (embeddings) are then passed to a classifier to ultimately assign the identities. We test each approach with a variation of two classifiers: k-Nearest Neighbor (k-NN) and a linear classifier adapted from the Lightly library  (MIT License). All feature extractors were fed with images at an input resolution of 384 x 384 pixels and each approach was run three times. The baseline results were obtained on 64GB shared memory Apple M3 Max Chips (2023) running PyTorch 2.3.0 with MPS acceleration.

MegaDescriptorThe employed MegaDescriptor-L-384  (CC BY-NC 4.0 license ) is a state-of-the-art feature extractor for animal re-identification from the WildlifeDatasets toolkit (MIT license). It is based on the Swin Transformer architecture  and was pretrained on diverse datasets featuring various animal species. However, it has not been trained on chicken data and we did not fine-tune it either. A notable hyperparameter choice made by the MegaDescriptor-L384 authors is the ArcFace  loss function, which aims to aid in building meaningful embeddings. We selected the frozen MegaDescriptor-L-384 model over DINOv2  and CLIP  due to its better performance on unseen animal domains, as reported by the authors. Their evaluation included cattle as an example of an unseen domain .

Swin TransformerWe utilize the swin_large_patch4_window12_384 architecture  as implemented in . We train it from scratch on the Chicks4FreeID dataset in a fully supervised manner. The training process and hyperparameters mirror those used to build the MegaDescriptor-L384, which also employs the same Swin Transformer architecture. Unlike the frozen MegaDescriptor-L384, which was trained on a variety of animal datasets, we now train the Swin architecture exclusively on our own dataset. The Swin Transformer itself is based on the Vision Transformer architecture.

Vision TransformerFinally, we employ the ViT-B/16  architecture, as implemented in , and train it on the Chicks4FreeID dataset in a fully supervised manner with a simple cross-entropy loss. We adopted the effective hyperparameter settings as used in Lightly's benchmarks , including optimizer and scheduler choices, for our experiments. The difference between the Swin Transformerand the Vision Transformer lies in how they handle image data; the Swin Transformer uses a hierarchical structure with shifted windows to capture local and global features, while the Vision Transformer treats images as sequences of patches, relying on self-attention mechanisms throughout.

### Evaluation

For all baselines, we provide three of the most common metrics for closed set animal re-identification. These are: mAP (mean Average Precision), Top-1 accuracy (ratio of correct predictions versus total predictions), and Top-5 accuracy (accuracy of the correct class being within the top 5 predictions) as implemented in TorchMetrics .

### Baseline results and discussion

The results for all baseline approaches and the respective variations are summarized in Table 2. Overall, the experiments yield good results but still leave room for improvement.

Both the Swin Transformer and Vision Transformer architectures, when trained from scratch, outperformed the frozen MegaDescriptor model. Additionally, linear classifiers consistently outperformed k-NN classifiers. This indicates that performance scales with the level of supervision, which aligns with expectations.

The gap between the MegaDescriptor, a model from a different domain (trained on different species), and those trained from scratch on the target species suggests that the Chicks4FreeID dataset likely has unique characteristics not present in the datasets used to pretrain the MegaDescriptor. Thus, our dataset could enhance the underlying data distribution used to train general animal re-identification models like the MegaDescriptor.

Additionally, there is a small improvement in scores between the Vision Transformer over the Swin architecture, which was used to train the MegaDescriptor. The slightly better performance of the Vision Transformer might be due to two reasons: First, we observed a more stable training process for the Vision Transformer (cross-entropy loss) than for the Swin Transformer (ArcFace loss). Therefore we believe that training a more straightforward approach allows for easier convergence on a small dataset like ours. Second, we replaced the standard classification head of the Vision Transformer with a simple linear layer. Since a simple linear layer has limited discriminative power, achieving good overall performance suggests the presence of good embeddings, which was confirmed by the embedding evaluation using k-NN.

## 5 Conclusion

### Findings

The Chicks4FreeID benchmark dataset was introduced. To the best of our knowledge, it is the very first publicly available dataset for chicken re-identification. The dataset is well-annotated and released under the relatively unrestrictive CC BY 4.0 license. It contains 1270 instance annotations of 54 individuals - 50 individuals and 1215 of the instances are chicken. The 677 images, which depict mainly chickens from 11 different coops and various breeds, were individually captured rather than

  
**Feature extractor** & **Training** & **Epochs** & **Classifier** & **mAP** & **Top-1** & **Top-5** \\  MegaDescriptor  & pretrained, frozen & - & k-NN & \(0.649 0.044\) & \(0.709 0.026\) & \(0.924 0.027\) \\ MegaDescriptor  & pretrained, frozen & - & linear & \(0.935 0.005\) & \(0.883 0.009\) & \(0.985 0.003\) \\ Swin Transformer  & from scratch & 200 & k-NN & \(0.837 0.062\) & \(0.881 0.041\) & \(0.983 0.010\) \\ Swin Transformer  & from scratch & 200 & linear & \(0.963 0.022\) & \(0.922 0.042\) & \(0.987 0.012\) \\ Vision Transformer  & from scratch & 200 & k-NN & \(0.893 0.010\) & \(0.923 0.005\) & \(0.985 0.019\) \\ Vision Transformer  & from scratch & 200 & linear & \(0.976 0.007\) & \(0.928 0.002\) & \(0.990 0.012\) \\   

Table 2: Baseline results for the closed set re-identification experiments. The highest scores for each metric are in blue.

derived from video. The dataset was created systematically, with manual annotation and instance-to-individual assignments based on expert knowledge, without the use of automated methods, ensuring reliable ground truth annotations. Instead of providing merely bounding boxes that might include parts of the background or other individuals, we offer preprocessed cut-out crops based on precise segmentations of the instances. While the main use case of the dataset is the re-identification of chickens, it also supports semantic and instance segmentation. In addition to instance and semantic segmentation masks, information on identity, animal category, and coop, the dataset also includes a visibility rating of the instances, accounting for occlusions. For the task of closed set chicken re-identification, we established a baseline on the dataset, achieving Top-1 accuracy scores up to \(0.928\), Top-5 accuracy scores up to \(0.990\), and mAP scores up to \(0.976\) with the Vision Transformer. The experiments suggest that the introduced dataset could be a valuable resource for training more robust (general) animal re-identification systems.

### Limitations

One clear limitation of the dataset is its size. With 1215 instance annotations of 50 chicken individuals, it is comparatively small. There also exists an imbalance within the classes (individuals), with the number of instances ranging from 4 to 27 in the "best" visibility subset. For chicken breeds with minimal inter-individual variability (e.g., uniform plumage), having more individuals and more instances of each individual would likely aid in re-identification. Additionally, all images of a given chicken were taken on the same day, so changes in appearance over time were not captured. An open question is the dataset's applicability to industrial farming, where thousands of chickens of a single breed are typically kept. A specialized dataset for such breeds could potentially be more suitable for commercial applications. Furthermore, the chicken breeds included in the chicks4FreeID dataset are not exhaustive, despite their variability. The specific breeds were not annotated because they could not always be accurately determined.

### Future work

To further enhance the chicks4FreeID dataset and address its current limitations, future work could focus on several promising directions. Expanding the dataset to include a larger number of individuals and an even broader range of breeds would enhance its robustness and generalizability. Enriching the metadata with detailed breed-specific information could provide additional context. Methods to automatically create new labeled samples from existing data using generative AI, as proposed in , could be evaluated for their potential to aid in expanding the dataset. To capture changes in appearance over time due to factors such as molting, growth, and environmental conditions, individuals from the dataset may be photographed again, provided they are still alive. Similarly, new individuals added to the dataset could be photographed repeatedly over time. The versioning system of the dataset facilitates potential expansions and continuous improvements, ensuring its ongoing relevance and applicability for future research. However, the challenge of long-term data collection persists, as free-range chickens often fall prey to wild predators (e.g., foxes or raccoons). Another interesting direction for future work would be the investigation of models trained on the dataset and their applicability to industrial farming settings with crowded conditions and chickens of a single breed. On a final note, we envision the Chicks4FreeID dataset being utilized by established and aspiring researchers alike, i.e., in future research, contributing to the development of chicken-specific and multi-species re-identification systems, as well as being used for practicing purposes.