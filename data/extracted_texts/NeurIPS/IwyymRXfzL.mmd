# Perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning

Austin Xu

Georgia Institute of Technology

&Andrew D. McRae

EPFL

&Jingyan Wang

Georgia Institute of Technology

&Mark A. Davenport

Georgia Institute of Technology

&Ashwin Pananjady

Georgia Institute of Technology

Contact: axu@gatech.edu. The full version of this work can be found on arXiv.

###### Abstract

We introduce a new type of query mechanism for collecting human feedback, called the perceptual adjustment query (PAQ). Being both informative and cognitively lightweight, the PAQ adopts an inverted measurement scheme, and combines advantages from both cardinal and ordinal queries. We showcase the PAQ in the metric learning problem, where we collect PAQ measurements to learn an unknown Mahalanobis distance. This gives rise to a high-dimensional, low-rank matrix estimation problem to which standard matrix estimators cannot be applied. Consequently, we develop a two-stage estimator for metric learning from PAQs, and provide sample complexity guarantees for this estimator. We present numerical simulations demonstrating the performance of the estimator and its notable properties.

## 1 Introduction

Should we query cardinal or ordinal data from people? This question arises in a broad range of applications, such as in conducting surveys , grading assignments , evaluating employees , and comparing or rating products , to name a few. _Cardinal_ data are numerical scores. For example, teachers score writing assignments in the range of \(0\)-\(100\), and survey respondents express their agreement with a statement on a scale of \(1\) to \(7\). _Ordinal_ data are relations between items, such as pairwise comparisons (choosing the better item in a pair) and rankings (ordering all or a subset of items). There is no free lunch, and both cardinal and ordinal queries have pros and cons.

On the one hand, collecting ordinal data is typically more efficient in terms of worker time and cognitive load , and surprisingly often matches or exceeds the accuracy of cardinal data . The information contained in ordinal queries, however, is fundamentally limited and lacks expressiveness. For example, pairwise comparisons elicit binary responses where two items are compared against each other, but the absolute placement of these items with respect to the entire pool is lost. On the other hand, cardinal data are more expressive . For example, assigning two items scores of \(1\) and \(2\) convey a very different message from assigning them scores of \(9\) and \(10\), or \(1\) and \(10\), although all yield the same pairwise comparison outcome. However, the expressiveness of cardinal data often comes at the cost of miscalibration: Prior work has shown that different people have different scales , and even a single person's scale can drift over time (e.g., ). These inter-person and intra-person discrepancies make it challenging to interpret and aggregate raw scores effectively.

The goal of this paper is to study whether one can combine the advantages of cardinal and ordinal queries to achieve the best of both worlds. Specifically, we pose the research question:_Can we develop a new paradigm for human data elicitation that is expressive, accurate, and cognitively lightweight?_

Towards this goal, we extract key features of both cardinal and ordinal queries, and we propose a new type of query scheme that we term the _perceptual adjustment query_ (PAQ). As a thought experiment, consider the task of learning an individual's preferences between modes of transport. The query can take the following forms:

* **Ordinal:** Do you prefer a $2 bus ride that takes 40 minutes or a $25 taxi that takes 10 minutes?
* **Cardinal:** On a scale of \(0\) to \(1\), how much do you value a $2 bus ride that takes 40 minutes?
* **Proposed approach:** To reach the same level of preference for a $2 bus trip that takes 40 minutes, a taxi that takes 10 minutes would cost $_x_.

A user interface for the proposed approach is shown in Figure 1 (top). We present the user a reference item (a $2 bus ride that takes 40 minutes) and a sliding bar representing the number of dollars (\(x\)) for the 10-minute taxi cost. As the user adjusts the slider, the value of \(x\) starts with \(0\) and gradually increases on a continuous scale. The user is instructed to place the slider at a point where they equally prefer a $2 bus ride and a taxi ride of \(x\) dollars.2 The PAQ thus combines ordinal and cardinal elicitation in an intuitive fashion: We obtain ordinal information by asking the user to make cognitive judgments in a relative sense by comparing items, and cardinal information can be extracted from the location of the slider. The ordinal reasoning endows the query with accuracy and efficiency, while the cardinal output enables a more expressive response. Moreover, this cardinal output mitigates miscalibration, because instead of asking the user to rate on a subjective and ambiguous notion (i.e., preference), we provide the user a reference object (i.e., the $2 bus ride) to anchor their rating scale.

Beyond combining the strengths of cardinal and ordinal queries, PAQs have additional advantages that are well illustrated with the example in Figure 1 (bottom). First, PAQs provide users with the _context_ of a specific (continuous) dimension along which items vary. For example, consider a pairwise comparison between the reference item and the "yellow apple " selected in Figure 1. They have similar shapes, but different colors. If these two items are shown to the user in isolation, the user lacks context to judge whether they should be considered similar or dissimilar. In contrast, the full spectrum provided in PAQs tells the user that the similarity judgment is apples vs. pears. The access to such context improves self-consistency in user responses . Second, PAQs provide "hard examples" by design and thus enable effective learning. Consider Figure 1 (bottom): Items on the left of the spectrum are apples (clearly similar to the reference), and items on the right are pears (clearly dissimilar to the reference), and only a small subset of items in the middle appear ambiguous. PAQs collect information precisely about "confusing" items in this ambiguous region. On the other hand, if ordinal queries are constructed by selecting uniformly at random from the items shown, an item in the ambiguous region will rarely be presented to the user.

Figure 1: The user interface for perceptual adjustment query (PAQ) for preference learning (top) and similarity learning (bottom).

The advantages of PAQs makes their deployment appealing in a variety of problem settings. For example, practitioners may deploy PAQs to learn human preferences, like in the taxi and bus example in Figure 1 or more complex settings such as housing preferences, where multiple features (price, square footage, proximity to employment etc.) vary as the slider is moved. PAQs can also be used to learn models for human perception, such as characterizing the extent of color blindness for a given user. One can present a user with red-green color blindness a sequence of colors that slowly transitions between red and green, and ask them to drag the slider until they perceive a difference in colors. An extended discussion of applications is provided in the full version of this paper on arXiv. In this paper, we focus on learning metrics to characterize human perception. In this problem, items are represented by points in a (possibly high-dimensional) space, and the goal is to learn a distance metric such that a smaller distance between a pair of items means that they are semantically and perceptually closer, and vice versa. Figure 1 (bottom) presents a PAQ for collecting similarity data for metric learning, where the user is instructed to place the slider at the precise point where the object appears to transition from being similar to dissimilar. To construct a sequence of images as shown in Figure 1 (bottom), one can traverse a path in the latent space of a generative model -- given a latent feature vector, the generative model synthesizes a corresponding image.

### Do PAQs improve upon ordinal queries? A simulation vignette

Consider the problem of Mahalanobis metric learning, which forms the focus of this paper. In this setting, items are represented as points in the vector space \(^{d}\), which is in turn endowed with a Mahalanobis metric parametrized by a symmetric positive semidefinite matrix \(^{}^{d d}\). The (dis-)similarity of two items is determined by their distance under the metric: The larger the (squared) distance \(\|-^{}\|_{^{}}^{2}=(-^{}) ^{}^{}(-^{})\) between two items \(\) and \(^{}\), is the more dissimilar the items are. We are particularly interested in the setting in which \(^{}\) is _low-rank_. Established approaches in metric learning use ordinal queries, such as pairwise comparisons ("Are items \(\) and \(^{}\) similar?") [15; 16; 17; 18], triplet comparisons  ("Which of the two items \(_{1}\) and \(_{2}\) is closer to reference item \(_{0}\)?"), and ranking\(-k\) queries ("Given a reference item \(_{0}\), rank the set of items \(_{1},,_{k}\) in terms of similarity to \(_{0}\)") .

We compare the performance of such queries against PAQs in a toy metric learning setup. In particular, we choose a random low-rank matrix \(^{}\) in dimension \(50\) with rank \(10\) (see Appendix B for our precise construction) and use the models and state-of-the-art algorithms of [19; 14] to produce pairwise, triplet, and ranking-\(k\) queries and estimate the low-rank metric. In addition to these ordinal queries, we simulate PAQ responses under the model presented in Section 2 and use our algorithm (see Section 3) for estimation. To simplify the example, all query responses are generated in a _noiseless_ fashion--for example, the triplet comparison always returns the closer item to the reference. We present our results in Figure 2, which illustrates a significant gap in information richness between PAQs and a variety of ordinal queries. The number of PAQ responses needed to attain a reasonable normalized error is dramatically lower than those of typical ordinal queries, illustrating that PAQs can greatly improve upon the performance of existing ordinal queries for metric learning. The rest of our paper explores this opportunity: It aims to make the deployment of PAQs theoretically grounded by designing provable methodology for learning a low-rank metric from PAQ responses.

### Our contributions and organization

In addition to introducing the _perceptual adjustment query_ (PAQ), we demonstrate its applicability to metric learning under a Mahalanobis metric. We first present a mathematical formulation of this estimation problem in Section 2. We then show that the sliding bar response can be viewed as an _inverted measurement_ of the metric matrix that we want to estimate, which allows us to restate our problem as that of estimating a low-rank matrix from a specific type of trace measurement (Section 3). However, our PAQ formulation differs from classical matrix estimation due to two technical challenges: (a) the sensing matrices and noise are correlated, and (b) the sensing matrices are heavy-tailed. As a result, standard matrix estimation algorithms give rise to _biased estimators_. We propose a query procedure and an estimator that overcome these two challenges, and we prove statistical error bounds on the estimation error (Section 4). The unconventional nature of the sensing model and estimator causes unexpected behaviors in our error bounds; in Section 5, we present simulations verifying that these behaviors also appear in practice.

### Related work

We discuss related work on metric learning and the statistical techniques that we use.

**Metric learning.** As discussed in Section 1.1, prior work in metric learning  considers a wide variety of ordinal queries. PAQ can be viewed as extending a discrete set of items presented to users to a continuous spectrum, which is natural when one uses a generative model such as a GAN [21; 22]. However, the goal of tuple queries is to rank the items, whereas in PAQ the ranking is provided by the feature space and we ask people to identify a transition point (similar vs. dissimilar) in this ranking.

**Statistical techniques.** In our theoretical results, we apply techniques from the high-dimensional statistics literature. Our theoretical formulation (presented in Section 3) resembles the problem of low-rank matrix estimation from trace measurements (e.g., [23; 24; 25; 26; 27; 28]; see  for a more complete overview), and, in particular, when the sensing matrix is of rank one [30; 31; 32; 33]. However, as discussed in Section 3, our model presents two important distinctions from prior literature. In our case, the sensing matrices are both heavy-tailed and correlated with the measurement noise. The heavy-tailed matrices violate the assumptions of much prior work that relies on sub-Gaussian or sub-exponential assumptions on the sensing matrices. Prior work has attempted to address the challenge of heavy tails with methods such as robust loss functions [34; 35] or the "median-of-means" approach [36; 37; 38]. We draw particular inspiration from Fan et al. , which considers truncation to control heavy-tailed behavior for a variety of problems. However, in the low-rank matrix estimation setting, Fan et al.  only analyze the case of heavy-tailed noise under a sub-Gaussian design, meaning their methodology and results are not applicable to our problem setting.

## 2 Model

In this section, we present our model for the perceptual adjustment query (PAQ) in the context of its application to metric learning.

### Mahalanobis metric learning

We consider a \(d\)-dimensional feature space where each item is represented by a point in \(^{d}\). The distance metric model for human similarity perception posits that there is a metric on \(^{d}\) that measures how dissimilar items are perceived to be. A recent line of work [40; 41] has modeled the distance metric as a Mahalanobis metric. If \(^{}^{d d}\) is a symmetric positive semidefinite (PSD) matrix, the squared Mahalanobis distance with respect to \(^{}\) between items \(\) and \(^{}^{d}\) is \(\|-^{}\|_{^{}}:=(-^{})^{ }^{}(-^{})\). The distance represents the extent of dissimilarity between items \(\) and \(^{}\): If we further have a perceptual boundary value \(y>0\), this model posits that items \(,^{}\) are perceived as similar if \(\|-^{}\|_{^{}}^{2}<y\) and dissimilar if \(\|-^{}\|_{^{}}^{2}\), \( y\). We adopt a high-dimensional framework and, following [19; 41], assume that the matrix \(^{}\) is low-rank.

Note that if the goal is to predict whether two items are similar or dissimilar via computing the relation \(\|-^{}\|_{^{}}^{2}\), \( y\), then this problem is scale-invariant, in the sense that two items are predicted as similar (or dissimilar) according to \((^{},y)\), if and only if they are predicted as similar (or dissimilar)according to \((c_{}^{},c_{}y)\) for any scaling factor \(c_{}>0\). We are thus interested in finding the equivalence class of solutions \(\{(c_{}^{},c_{}y):c_{}>0\}\). Therefore, in practice, one can set \(y\) to be any positive scalar and then estimate the corresponding \(^{}\). Indeed, our theoretical error bounds on \(\|}-^{}\|_{F}\) exhibit a natural scale-equivariant property (see Section 4, Scale Equivariance).

### The perceptual adjustment query (PAQ)

We assume that every point in our feature space \(^{d}\) corresponds to some item. Recall from Figure 1 that a PAQ collects similarity data between a pair of items, where a reference item is fixed, and a spectrum of target items is generated from a one-dimensional path in the feature space. Denote the reference item by \(^{d}\). The target items can be generated by any path in \(^{d}\), but, for simplicity, we consider straight lines. For any vector \(^{d}\), we construct the line \(\{+:[0,)\}\). We call this vector \(\) the _query vector_. As shown in Figure 3, the user moves the slider from left to right, and the value of \(\) increases proportionally to the distance traversed by the slider. Note that the value \(\) is _dimensionless_.

The user is instructed to stop the slider at the transition point where the target item transitions from being similar to dissimilar with the reference item. According to our model, this transition point occurs when the \(^{}\)-Mahalanobis distance between the target item and the reference item is \(y\). The (noiseless) transition point, denoted by \(_{}\), satisfies the equation

\[y=\|-(+_{})\|_{^{}}^{2}=_ {}^{2}^{}^{}.\] (1)

Note that the ideal PAQ response \(_{}\) does not depend on the specific reference item \(\) but rather only on the query direction \(\) and the (unknown) metric matrix \(^{}\). When querying users with PAQs, the practitioner has control over how the query vectors \(\) are selected, which we discuss in Section 3.2.

### Noise model

We model the noise in human responses as follows: In the PAQ response (1), we replace the boundary value \(y\) by \(y+\), where \(\) represents noise. Thus the user provides a noisy response \(\) whose value satisfies \(^{2}^{}^{}=y+\). Substituting in (1), we have \(^{2}=_{}^{2}+^{}^{} {a}}\). This model captures qualitatively how we would expect the variance of \(\) due to noise to scale. To see why, recall that \(\) is proportional to the distance traversed by the slider in the user interface Figure 1 (bottom). If \(^{}^{}\) is large, then the semantic meaning of the item changes rapidly as the user moves the slider, and the slider will stop at a position that is close to the true transition point. On the other hand, if \(^{}^{}\) is small, then the item changes slowly as the user moves the slider. It is then hard to determine where exactly the transition occurs, so the slider may stop in a larger interval around the transition point.

## 3 Methodology

In this section, we formally present the statistical estimation problem for metric learning from noisy PAQ data, and we develop our algorithm for estimating the true metric matrix \(^{}\).

### Statistical estimation

Assume we collect \(N\) PAQ responses, using \(N\) query vectors \(\{_{i}\}_{i=1}^{N}\) that we select3. Denote the noise associated with these queries by random variables \(_{1},,_{N}\). We obtain PAQ responses, denoted by \(_{1},,_{N}\), that satisfy

\[_{i}^{2}_{i}^{}^{}_{i}=y+_{i},\ \ i=1,,N.\] (2)

We assume the noise variable \(\) is independent4of the query \(\), has zero mean and variance \(_{}^{2}\), and is bounded, with \(-y^{}\) for some constant \(^{} 0\). Note that we must have \(+y 0\) since \(^{2} 0\); in addition, we place an upper bound \(^{}\) on the noise.

Given the query directions \(\{_{i}\}_{i=1}^{N}\) and the PAQ responses \(\{_{i}\}_{i=1}^{N}\), we want to estimate the matrix \(^{}\). We first rewrite our measurement model as follows: Recall that the matrix inner product is denoted by \(,:=(^{})\) for any two matrices \(\) and \(\) of compatible dimension. Then from (2), we write

\[^{2}=^{}^{}}.\] (3)

Plugging (3) once more into (2), we have

\[y+=^{},^{},\]

where

\[^{}:=^{2}^{}=^{}^{}}^{}.\] (4)

Hence, our problem resembles trace regression, and, in particular, low-rank matrix estimation from rank-one measurements (because the matrix \(^{}\) has rank 1) . We call \(^{}\) the sensing matrix, and \(\) the sensing vector. Classical trace regression assumes that we make (noisy) observations of the form \(y=,^{}+\) where \(\) is fixed before we make the measurement; in our problem, the sensing matrix \(^{}\) depends on our observed response \(\) and associated sensing vector \(\). Hence, the process of obtaining a PAQ response can be viewed as an _inversion_ of the standard trace measurement process. The inverse nature of our problem makes estimator design more challenging, as we discuss in the following section.

### Algorithm

As our first attempt at a procedure to estimate \(^{}\), we follow the literature  and consider randomly sampling i.i.d. vectors \(_{i}(,_{d})\). We then use standard least-squares estimation of \(^{}\). Since we expect \(^{}\) to be low-rank, we add nuclear-norm regularization to promote low rank. In particular, we solve the following program:

\[_{ 0}\;_{i=1}^{N}(y- _{i}^{},)^{2}+_{N}\| \|_{*},\] (5)

where \(_{N}>0\) is a regularization parameter. This is a convex semidefinite program and can be solved with standard off-the-shelf solvers. However, the inverted form of our measurement model creates two critical issues when naively using (5):

* **Bias of standard matrix estimators due to dependence.** Note that the sensing matrix (4) depends on the noise \(\). Quantitatively, we have \([^{}]\) (see Appendix D.1). Standard trace regression analyses require that this quantity be zero, typically assuming (at least) that \(\) is zero-mean conditioned on the sensing matrix \(\). The failure of this to hold in our case introduces a bias that does not decrease with the sample size \(N\).
* **Heavy-tailed sensing matrix.** The factor \(^{}^{}}\) in \(^{}\) (see Equation (4)) makes \(^{}\) heavy-tailed in general. When \(\) is Gaussian, the term \(^{}^{}}\) is an inverse weighted chi-square random variable, whose higher-order moments are infinite (and the number of finite moments depends on the rank of \(^{}\)). This makes error analysis more difficult, as standard analyses require the sensing matrix \(\) to concentrate well (e.g., be sub-exponential).

To overcome these challenges, we make two key modifications to the procedure (5).

**Step 1: Bias reduction via averaging.** First, we want to mitigate the bias due to the dependence between the sensing matrix \(^{}\) and the noise \(\). The bias term \([^{}]\) scales proportionally to \([(y+)]=[^{2}]\). Therefore, to reduce this bias in the least-squares estimator (5), we need to reduce the noise variance. We reduce the effective noise variance (and hence the bias) by _averaging_ i.i.d. samples. Operationally, instead of obtaining \(N\) measurements from \(N\) distinct sensing vectors \(\{_{i}\}_{i=1}^{N}\), we draw \(n\) sensing vectors \(\{_{i}\}_{i=1}^{n}\), and collect \(m\) measurements, denoted by \(\{_{i}^{(j)}\}_{j=1}^{m}\), corresponding to each sensing vector \(_{i}\). We refer to \(n\) as the number of (distinct) sensing vectors.

To keep the total number of measurements constant, we set \(n=\), where the value of \(m\) is specified later. For each sensing vector \(_{i}\), we compute the empirical mean of the \(m\) measurements:

\[_{i}^{2}:=_{j=1}^{m}(_{i}^{(j)})^{2}=_{j=1}^{m}^{(j)}}{_{i}^{}^{*}_{ i}}=_{i}}{_{i}^{}^{*}_{i}},\] (6)

where we define the average noise by \(_{i}:=_{j=1}^{m}_{i}^{(j)}\). This averaging operation reduces the effective noise variance from \((_{i})=_{}^{2}\) to \((_{i})=^{2}}{m}\). If \(n\) is small, we may have large error due to an insufficient number of query vectors \(_{i}\). On the other hand, a small \(m\) leads to a large bias. Therefore, we set the value of \(m\) carefully to balance these two effects. This is studied theoretically in Section 4 and demonstrated empirically in Section 5.

**Step 2: Heavy tail mitigation via truncation.** Next, we need to control the heavy-tailed behavior introduced by the \(^{}^{*}}\) term in the sensing matrix \(^{}\). Note that the sample averaging procedure (6) does not mitigate this problem. We adopt the approach in  and truncate the observations. Specifically, we truncate the averaged measurements \(_{i}^{2}\) to \(^{2}:=^{2}\), where \(>0\) is a truncation threshold that we specify later. We then construct the truncated sensing matrices

\[}_{i}=_{i}^{2}_{i}_{i}^{} =(_{i}}{_{i}^{}^{*}_{i}} )_{i}_{i}^{}, i=1,,n.\] (7)

While truncation mitigates heavy-tailed behavior, it also introduces additional bias in our estimate. The truncation threshold \(\) therefore gives us another tradeoff, and in our analysis to follow, we carefully set the value of \(\) to balance the effects of heavy-tailedness and bias.

**Final algorithm.** Before presenting our final optimization program, we summarize our assumptions and sensing model below.

**Assumption 1**.: _The noise values \(_{i}\) are i.i.d copies of the random variable \(\), which is independent of the random sensing vector \(\). The random noise is (1) zero-mean: \([]=0\), and (2) bounded: There exists a positive constant \(^{}\) such that \(-y^{}\) with probability \(1\)._

We choose the sensing vector distribution to be the standard multivariate normal distribution and collect, average, and truncate \(N\) PAQ responses following Algorithm 1. This process yields \(n\) truncated responses \(_{1}^{2},_{n}^{2}\). We then use these truncated responses to form the averaged and truncated matrices \(\{}_{i}\}_{i=1}^{n}\), which we substitute into the original least-squares problem (5). To estimate \(^{*}\), we solve

\[}*{arg\,min}_{} \ _{i=1}^{n}(y-}_{i}, )^{2}+_{n}\|\|_{*},\] (8)

where, again, \(_{n}\) is a regularization parameter that we specify later.

```
0: number of total measurements \(N\), averaging parameter \(m\) (that divides \(N\)), truncation threshold \(\), measurement value \(y\)
1: Compute the number of sensing vectors \(n=\)
2:for\(i=1\)to\(n\)do
3: Draw sensing vector \(_{i}\) from standard multivariate normal distribution
4: Obtain \(m\) PAQ measurements \((_{i}^{(1)})^{2},,(_{i}^{(m)})^{2}\) with \(_{i}\) and \(y\).
5: Bias elimination via averaging: compute averaged response \(_{i}^{2}=_{j=1}^{m}(_{i}^{(j)})^{2}\).
6: Heavy tail mitigation via truncation: compute truncated response \(_{i}^{2}=_{i}^{2}\).
7:endfor
8: truncated responses \(_{1}^{2},_{n}^{2}\) ```

**Algorithm 1** Inverted measurement sensing, averaging, and truncation.

**Practical considerations.** In the averaging step, we collect \(m\) measurements for each sensing vector \(_{i}\). These measurements could be collected from \(m\) different users. Furthermore, recall from Section 2.2 that the measurements do not depend on the reference item \(\). As a result, one may also collect multiple responses from the same user by presenting the same query vector \(_{i}\) with different reference items. In addition, recall from Section 2.1 that user responses are scale-invariant. Practitioners are hence free to set the boundary \(y\) to be any positive value of their choice without loss of generality, and the noise \(\) scales accordingly with \(y\). The user interface does not depend on the value of \(y\).

## 4 Theoretical results

We now present our main theoretical result, which is a finite-sample error bound for estimating a low-rank metric from inverted measurements with the nuclear norm regularized estimator (8). Our error bound is generally stated, and depends on the averaging parameter \(m\) and the truncation threshold \(\). Recall that \(_{}^{2}\) denotes the variance of \(\). We define the quantities \(y^{}:=y+^{}\) and \(_{y}=y+()\). We further denote by \(_{1}_{r}>0\) the non-zero singular values of \(^{}\).

**Theorem 1**.: _Suppose \(^{}\) is rank \(r\), with \(r>8\). Assume that we choose the sensing vector distribution the be the standard multivariate normal distribution, that Assumption 1 holds on the noise, and that we collect, average, and truncate measurements following Algorithm 1. Further, assume that the truncation threshold \(\) satisfies \(}{(^{})}\). Then there are positive constants \(c,C,C_{1}\), and \(C_{2}\), such that if the regularization parameter and the number of sensing vectors satisfy_

\[_{n} C_{1}[y^{}(}{ _{r}r}}++(}{ _{r}r})^{2})+r}^{ 2}}{m}] n C_{2}rd,\] (9)

_then any solution \(}\) to the optimization program (8) satisfies_

\[\|}-^{}\|_{F} C( (^{})}{_{y}})^{2} _{n}\] (10)

_with probability at least \(1-4e^{-d}-e^{-cn}\)._

The proof of Theorem 1 is presented in Appendix E. The two sources of bias discussed in Section 3.2 appear in the expression (9) for the regularization parameter \(_{n}\) (and consequently in the error bound (10)). The term scaling as \(1/\) corresponds to the bias induced by truncation, and decreases as the truncation gets milder (i.e., as the threshold \(\) gets larger). The term scaling as \(_{}^{2}/m\) corresponds to the bias arising from dependence between the noise and sensing matrix. As discussed in Section 3.2, in this model, \(m\)-averaging results in a bias that scales like \(1/m\). Given the dependence of the estimation error bound on the parameters \(m\) and \(\), we carefully set these parameters to obtain a tight bound as a function of the number of _total measurements_\(N=mn\). These choices for \(m\) and \(\), along with the final estimation error, are presented in the following corollary, proved in Appendix F.

**Corollary 1**.: _Recall that \(N=mn\). Assume that the conditions of Theorem 1 hold, and set the values of the constants \((c,C,C_{1},C_{2})\) according to Theorem 1. Suppose that the number of total measurements satisfies_

\[N\{2C_{2}^{}{{2}}}^{2}}{ (y^{})^{2}}r^{}{{2}}}d\}\{C_{2}rd\}.\] (11)

_Set the averaging parameter \(m\) and truncation threshold \(\) to be_

\[m=(^{2}}{(y^{})^{2}} )^{}{{3}}}()^{}{{3}}} =}{_{r}r}},\] (12)

_and set \(_{n}\) equal to its lower bound in (9). With probability at least \(1-4e^{-d}-e^{-cN/m}\), we have:_

1. _If_ \(^{2}}{(y^{})^{2}}>},\) _then any solution_ \(}\) _to the optimization program (_8_) satisfies_ \[\|}-^{}\|_{F} C^{} \,^{2}}{_{r}})^{}{{3}}} (_{}^{2})^{}{{3}}}}{_{y}^{2}}\,r^{}{{2}}} ()^{}{{3}}}.\] (13)_._
2. _If_ \(^{2}}{(y^{})^{2}}},\) _then any solution_ \(}\) _to the optimization program (_8_) satisfies_ \[\|}-^{}\|_{F} C^{}\,^{2}}{_{r}}(}{_{y}})^{2}r^{}{{2}}}()^{}{{2}}}.\] (14)

_In both cases, \(C^{}=3C C_{1}\)._

A few comments are warranted about our error bounds (13) and (14):

**Error rates and noise regimes.** Under the standard trace measurement model, it is known that if the measurement matrices are i.i.d. according to some sub-Gaussian distribution and the number of measurements satisfies \(N rd\), then nuclear norm regularized estimators achieve an error that scales like \(}\)(e.g., ). Such a result is also known to be minimax optimal . Allowing heavier-tailed assumptions on the sensing matrices, such as sub-exponential  or bounded fourth moment , typically results in additional \( d\) factors but does not impact the exponent \(1/2\) in the error rate. However, a crucial assumption in these results is that \([^{}]=\), and thus there is no bias due to measurement noise. Our inverted measurement sensing matrix is not only heavy-tailed but also leads to bias (see Lemma 1 in Appendix D.1). Nevertheless, we are able to reduce the bias and trade it for variance, ensuring consistent estimation in all regimes.

In Corollary 1, there are two distinct cases for error rate which correspond to two different noise regimes induced by the quantity \(}{{3}}}}}{{(y^{})^{2}}}\), which captures the noise level in our measurements. In particular, the two cases in Corollary 1 correspond to two regimes with distinct bias behavior:

1. High-noise regime: In this setting, the bias due to measurement noise is non-negligible. As a result, we employ averaging with large \(m\), which results in the rate scaling as \((d/N)^{}{{3}}}\).
2. Low-noise regime: In this setting, the measurement noise bias is dominated by the variance, and thus has negligible impact on the estimation error. As a result, we are able to achieve a rate of order \((d/N)^{}{{2}}}\), which is consistent with established results for low-rank matrix estimation.

**Sample complexity.** Since the degrees of freedom in a rank-\(r\) matrix of size \(d d\) is of order \(rd\), one expects that the minimum number of measurements to identify a rank-\(r\) matrix is of order \(rd\). This is reflected in Theorem 1, which assumes that the number of _distinct_ sensing vectors \(\{_{i}\}\) satisfies \(n rd\). In the high-noise regime, from (12) in Corollary 1, we have that \(m\) scales like \((N/d)^{}{{3}}}\). Thus, the total number of measurements is \(N=mn(N/d)^{}{{3}}} rd N^{}{{3}}}d ^{}{{3}}}r\), and hence \(N r^{}{{2}}}d\). Given that the rank is assumed to be relatively small compared to the dimension, the extra factor of \(\) is a relatively small price to pay to obtain consistent estimation. In the low-noise regime, it can be verified that \(m=1\) in (12) due to the low-noise condition \(}{{3}}}}}{{(y^{})^{2}}}\). No averaging is needed, and we only require \(N=n rd\).

**Dependence on rank.** When compared to standard results, Corollary 1 differs in its dependence on rank. First, the matrix \(^{}\) is assumed to have rank \(r>8\). This prevents the term \(^{}^{}}\) from making the sensing matrices so heavy-tailed that even truncation does not help. We empirically show that the assumption of \(r>8\) is necessary in Section 5. Second, there is an additional factor of \(r\) in our rate for both noise regimes. To interpret this, note that if \(^{}\) has non-zero singular values in a fixed range, then \([^{}^{}]=(^{}) r.\) Since the "magnitude" of the sensing matrix \(^{}\) is inversely proportional to \(^{}^{}\), increasing \(r\) decreases the magnitude of \(^{}\) and thus also (for a fixed noise level) the signal-to-noise ratio.

**Scale equivariance.** As discussed in Section 2.1, the metric learning from PAQs problem aims to find an equivalence class \(\{(c_{},c_{}y):c_{}>0\}\), and the ground-truth \(^{}\) is defined with respect to a particular choice of \(y\). Accordingly, our error bounds are scale-equivariant: If we instead replaced \(y\) with \(c_{}y\), the bounds (13) and (14) would scale linearly in \(c_{}\). This fact is precisely verified in Appendix C and relies on the fact that the noise also scales appropriately in \(c_{}\). Thus practitioners may simply set \(y\) to be _any_ positive number.

## 5 Numerical simulations

In this section, we provide numerical simulations investigating the effects of the various problem and estimation parameters. For all results, we report the normalized estimation error \(\|}-^{}\|_{F}/\|^{}\|_{F}\) averaged over 20 trials. Shaded areas (sometimes not visible) represent standard error of the mean. For all experiments, we follow  and generate the ground-truth metric matrix as \(^{}=}^{}\), where \(^{d r}\) is a randomly generated matrix with orthonormal columns. The noise \(\) is sampled from a uniform distribution on \([-^{},^{}]\) (where \(^{} y\)). We set the regularization parameter, truncation threshold, and averaging parameter in a manner consistent with our theoretical results (see Eqs. (9) and (12)), cross-validating to choose the constant factors. We solve the optimization problem using cvxpy. Code for all simulations is provided at https://github.com/austinxu87/paq.

**Effects of dimension and rank.** Our first set of experiments characterizes the effects of dimension \(d\) and matrix rank \(r\). For all experiments, unless we are sweeping a specific parameter, we set \(y=200\), \(d=50\), \(r=15\), and \(^{}=10\). Fig. 3(a) shows the performance for varying values of \(d\) plotted against the normalized sample size \(N/d\). For all dimensions \(d\), the error decays to zero as the total number of measurements \(N\) increases. Furthermore, the error curves are well-aligned when the sample size is normalized by \(d\) with fixed \(r\), empirically aligning with Corollary 1. Fig. 3(b) shows the performance for varying values of rank \(r\). Recall that for our theoretical results we assume \(r>8\) to ensure that the quadratic term \(^{}^{}\) in the denominator of our sensing matrices does not lead to excessively heavy-tailed behavior. When \(r>8\), the number of measurements required for the same estimation error increases as the rank increases. A clear phase transition occurs at \(r=8\). The error still decreases with \(N\) for \(r 8\), but at a markedly slower rate than when \(r>8\). This empirically demonstrates that when \(r 8\), the sensing matrix tails are too heavy to be mitigated by truncation.

**Effect of averaging parameter \(m\).** Equation (12) suggests that the averaging parameter \(m\) should scale proportionally to \((N/d)^{}{{3}}}\). To test this, we set \(y=200\), \(d=50\), \(r=9\), and \(^{}=200\). We vary values of \(m\) for different choices of the \((N,d)\) pair, as shown in Fig. 3(c). The empirically optimal choice of \(m\) is observed to be the same when \(N/d\) is fixed, regardless of the particular choices of \(N\) or \(d\) (the green and red curves overlap, and the blue and orange curves overlap). Moreover, the optimal \(m\) is smaller when \(N/d=400\) compared to when \(N/d=1000\).

## 6 Discussion

In this paper we introduced the perceptual adjustment query, a cognitively lightweight way to obtain expressive responses from humans. We specifically investigate using PAQs for human perceptual similarity learning. We use a Mahalanobis distance-based model for human similarity perception and use PAQs to estimate the unknown metric. Using random measurements to learn an unknown Mahalanobis metric gives rise to the new inverted measurement scheme for high dimensional low rank matrix estimation which violates commonly held assumptions for existing estimators. We developed a two-stage estimator and provide corresponding sample complexity guarantees. This work opens up many interesting lines of future work in inverted measurements. One key direction is to characterize their fundamental limits with information-theoretic lower bounds.

Figure 4: Simulations quantifying the effect of dimension \(d\), rank \(r\), and averaging parameter \(m\) on estimation error. Shaded areas correspond to standard error of the mean but sometimes not visible.