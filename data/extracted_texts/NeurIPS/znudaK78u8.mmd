# Active Learning for Semantic Segmentation

with Multi-class Label Query

 Sehyun Hwang Sohyun Lee Hoyoung Kim Minhyeon Oh Jungseul Ok Suha Kwak

Pohang University of Science and Technology (POSTECH), South Korea

{sehyun03, lshig96, cskhy16, minhyeonoh, jungseul.ok, suha.kwak}@postech.ac.kr

###### Abstract

This paper proposes a new active learning method for semantic segmentation. The core of our method lies in a new annotation query design. It samples informative local image regions (_e.g._, superpixels), and for each of such regions, asks an oracle for a multi-hot vector indicating all classes existing in the region. This multi-class labeling strategy is substantially more efficient than existing ones like segmentation, polygon, and even dominant class labeling in terms of annotation time per click. However, it introduces the class ambiguity issue in training as it assigns partial labels (_i.e._, a set of candidate classes) to individual pixels. We thus propose a new algorithm for learning semantic segmentation while disambiguating the partial labels in two stages. In the first stage, it trains a segmentation model directly with the partial labels through two new loss functions motivated by partial label learning and multiple instance learning. In the second stage, it disambiguates the partial labels by generating pixel-wise pseudo labels, which are used for supervised learning of the model. Equipped with a new acquisition function dedicated to the multi-class labeling, our method outperforms previous work on Cityscapes and PASCAL VOC 2012 while spending less annotation cost. Our code and results are available at https://github.com/sehyun03/MulActSeg.

## 1 Introduction

Supervised learning of deep neural networks has driven significant advances of semantic segmentation for a decade. At the same time, however, it has limited practical applications of the task as it demands as supervision pixel-level class labels that are prohibitively expensive in general. To address this limitation, label-efficient learning approaches such as weakly supervised learning , self-supervised learning , and active learning (AL)  have been investigated.

This paper studies AL for semantic segmentation, where a training algorithm selects informative samples from training data and asks an oracle to label them on a limited budget. In AL, the design of annotation query, _i.e._, the granularity of query samples and the annotation format, is of vital importance for maximizing the amount and quality of supervision provided by the oracle within a given budget. Early approaches consider an entire image as a sample and ask for its pixel-wise class labels , or select individual pixels and query the oracle for their class labels ; they turned out to be suboptimal since the former lacks the diversity of samples  and the latter is less budget-efficient as a query provides supervision for only a single pixel.

As a compromise between these two directions, recent AL methods treat non-overlapped local image regions as individual samples . These region-based methods guarantee the diversity of samples by selecting local regions from numerous images with diverse contexts. Also, their queries are designed to obtain region-wise segmentation labels efficiently. For instance, theyask the oracle to draw segmentation masks in the form of polygons within an image patch , or to estimate the dominant class label of a superpixel so that the label is assigned to the entire superpixel . Although the existing region-based methods have achieved great success, we argue that there is still large room for further improvement in their query designs: Polygon labeling  still requires a large number of clicks per query, and dominant class labeling  provides wrong supervision for part of a multi-class region. Note that the latter issue cannot be resolved even using superpixels since they frequently violate object boundaries and include multiple classes.

In this context, we first introduce a new query design for region-based AL of semantic segmentation. The essence of our proposal is to ask the oracle for a multi-hot vector that indicates all classes existing in the given region. This _multi-class labeling_ strategy enables to prevent annotation errors for local regions capturing multiple classes, and works the same as dominant class labeling (and thus inherits its advantages) for single-class region queries. Moreover, our user study revealed that multi-class labeling demands less annotation time per click and results in more accurate labels compared with dominant class labeling as demonstrated in Fig. 1. However, such region-wise multi-class labels introduce a new challenge in training, known as the _class ambiguity_ issue, since they assign _partial labels_ (_i.e._, a set of candidate classes) to individual pixels of the selected regions.

To address the ambiguity issue, we propose a new AL method tailored to learning semantic segmentation with partial labels. Fig. 2 illustrates the overall pipeline of the proposed method. Given a set of local regions and their multi-class labels, our method trains a segmentation network in two stages. In the first stage, the network is trained directly with the region-wise multi-class labels. To this end, we propose two new loss functions for the label disambiguation based on the notions of partial-label learning  and multiple instance learning , respectively. In the second stage, our method disambiguates the partial labels through pseudo segmentation labels, which are used to train the segmentation network in the supervised learning fashion. To be specific, it finds a set of class prototype features from each local region using the model of the first stage, and employs the prototypes as a region-adaptive classifier to predict pixel-wise pseudo labels within the region. In addition, we propose to propagate the pseudo labels to neighboring local regions to increase the amount of supervision given per query; this strategy benefits by multi-class labeling that enables to propagate pseudo labels of multiple classes, leading to larger expansion of pseudo labels.

Last but not least, we introduce an acquisition function designed to maximize the advantage of multi-class labels in the region-based AL. Our acquisition function considers both uncertainty  and class balance  of sampled regions so that local regions where the model finds difficult and containing underrepresented classes are chosen more frequently. It shares a similar motivation

Figure 1: Dominant class labeling  versus our multi-class labeling. (_left_) Given a local region as query, an oracle is asked to select the most dominant class by a single click in dominant class labeling, and all existing classes by potentially more than one click in multi-class labeling. As shown here, multi-class labeling often takes less _annotation time per click_ because, to determine the dominant one, the oracle has to infer every class in the region after all and sometimes should very carefully investigate the region when the classes occupy areas of similar sizes. (_right_) We conducted a user study to compare the two strategies in terms of actual labeling cost and accuracy versus the number of classes in region queries; the results are summarized in the right plot with one standard deviation. Multi-class labeling took less time per click on average due to the above reason. Furthermore, it resulted in more accurate labels by annotating non-dominant classes ignored in dominant class labeling additionally. Details of this user study are given in Appendix A.

with an existing acquisition function , but different in that it considers multiple classes of a region and thus better aligns with multi-class labeling.

The proposed framework achieved the state of the art on both Cityscapes  and PASCAL VOC 2012 . Especially, it achieved 95% of the fully supervised learning performance on Cityscapes with only 4% of the full labeling cost. In addition, we verified the efficacy and efficiency of multi-class labeling through extensive empirical analyses: Its efficacy was demonstrated by experiments with varying datasets, model architectures, acquisition functions, and budgets, while its efficiency was examined in real-world annotation scenarios by measuring actual labeling time across a large number of human annotators. In short, the main contribution of this paper is five-fold:

* We introduce a new query design for region-based AL in semantic segmentation, which asks the oracle for a multi-hot vector indicating all classes existing within a particular region.
* We propose a novel AL framework that includes two new loss functions effectively utilizing the supervision of multi-class labels and a method for generating pseudo segmentation labels from the multi-class labels, resulting in enhanced supervision.
* To maximize the advantage of multi-class labels, we design an acquisition function that considers multiple classes of a local region when examining its uncertainty and class balance.
* The effectiveness of multi-class labeling was demonstrated through extensive experiments and user study in real-world annotation scenarios.
* The proposed framework achieved the state of the art on both two public benchmarks, Cityscapes and PASCAL VOC 2012, with a significant reduction in annotation cost.

## 2 Related Work

**Active learning (AL).** In AL, a training algorithm samples informative data and asks an oracle to label them on a limited budget so as to maximize performance of a model trained with the labeled data. To this end, AL methods have suggested various sampling criteria such as uncertainty [5; 26; 50], diversity [53; 56], or both [64; 65; 30; 6]. Also, since most of existing AL methods for vision tasks have focused on image classification, the granularity of their annotation queries has been an entire image in general. However, for structured prediction tasks like semantic segmentation, queries should be more carefully designed to optimize cost-effectiveness of annotation.

**Active learning for semantic segmentation.** Most AL methods for semantic segmentation can be categorized into image-based [17; 68; 56] and region-based methods . The image-based methods consider an entire image as the sampling unit and query an oracle for pixel-wise labels of sampled images. These methods have been known to be less cost-effective due to the limited diversity of sampled data; adjacent pixels in an image largely overlap in their receptive fields and thus fail to provide diverse semantics during training. On the other hand, the region-based methods divide each image into non-overlapping local regions, which are considered as individual samples to be selected; As such local regions, image patches [10; 47; 14] and superpixels [9; 35; 55] have been employed. Our paper proposes a new cost-effective region query that allows more accurate and faster annotation, and a new training algorithm taking full advantage of the query design.

**Partial label learning.** Partial label learning [8; 16; 29; 46] is a branch of weakly supervised learning where a set of candidate classes is assigned to each of training data, leading to ambiguous supervision. One primitive yet common approach to partial label learning is to train a model while regarding its top-1 prediction as true labels [8; 46]. However, this approach could be vulnerable to class imbalance  and strong correlation between different classes . In contrast, our two-stage training algorithm addresses these issues by disambiguating partial labels by pseudo labeling.

## 3 Proposed Method

We consider an AL process with \(R\) rounds. At each round, local regions of a batch are selected using an acquisition function, and then a multi-hot vector (_i.e._, multi-class label) is assigned to each of them by an oracle. Given the labeled regions, our training algorithm operates in two stages as illustrated in Fig. 2. In the first stage, a segmentation model is trained directly with the region-wise multi-class labels by two loss functions specialized to handle the ambiguity of the labels (Sec. 3.2). In the second stage, the ambiguity is mitigated by generating pixel-wise pseudo labels and using them for training the model further (Sec. 3.3). The remainder of this section describes details of our framework.

### Acquisition of region-wise multi-class labels

For an unlabeled image set \(\), we partition each image \(I\) into a set of non-overlapping regions, denoted by \(S(I)\), such that a pixel \(x I\) belongs to only a unique region \(s S(I)\). Such a non-overlapping partition can be obtained by a superpixel algorithm as in . Let \(:=_{I}S(I)\) be the set of all the partitions for \(\). For each round \(t\), we issue a batch of regions, denoted by \(_{t}\), each of which is queried to acquire a multi-class label \(Y\{1,2,,C\}\), where \(|Y| 1\) and \(C\) is the number of classes. Then the model \(_{t}\) is trained using the labeled regions obtained so far, denoted as \(:=_{t}_{t}\), where \(_{t}\) consists of pairs of region and associated multi-class label, \(_{t}:=\{(s,Y):s_{t}\}\). The model \(_{t}\) includes a feature extractor \(f_{t}()\) and a classifier with a weight matrix \([_{t,1},_{t,2},,_{t,C}]^{d  C}\). The predictive probability of pixel \(x\) being class \(c\) is computed by

\[P_{_{t}}(y=c|x)=(x)^{}_{t,c}}{\|f_{t}(x)\|\,\|_{t,c}\|}\,\] (1)

where \(\) is a temperature term.

**Acquisition function.** We introduce an acquisition function for selecting a batch of regions \(_{t}\) at round \(t\) that aims to optimize the benefits of multi-class labels, while adhering to the principles of previous studies  for uncertain and class-balanced region selection. We adopt best-versus-second-best (BvSB)  as an uncertainty measure, defined as

\[u_{_{t}}(x):=}(y=c_{}|x)}{P_{_{t}}(y=c _{}|x)}\,\] (2)

where \(c_{}\) and \(c_{}\) are the classes with the largest and second-largest predictive probabilities for \(x\) under \(_{t}\), respectively. For class-balanced sampling, we first estimate the label distribution \(P_{_{t}}(y)\) as

\[P_{_{t}}(y=c)=_{x X}P_{_{t}}(y=c|x)\,\] (3)

where \(X\{x s,\ x s\}\). Our acquisition function, favoring uncertain regions of rare classes, is defined as

\[a(s;_{t}):=_{x s}}(x)}{1+ \,P_{_{t}}(c_{b})^{2}}\,\] (4)

Figure 2: Our two-stage training algorithm using partial labels. (_left_) In the first stage, a model is trained using region-wise multi-class labels through two losses: the merged positive loss that encourages the model to predict any of the annotated classes for each pixel of the region, and the prototypical pixel loss that ensures at least one pixel in the region corresponds to each annotated class. (_right_) The second stage disambiguates the region-wise multi-class labels by generating pixel-wise pseudo labels, which are then used for training the final model. To this end, it first assigns pseudo class labels to individual pixels within the region (_i.e._, intra-region label localization), and then propagates the pseudo labels to adjacent regions (_i.e._, label expansion).

where \(\) is a hyperparameter regulating the class balancing effect. Distinct from an existing acquisition function  that considers the dominant class only, our function considers classes of all pixels in a region and thus better aligns with multi-class labeling. For the remainder of this section, we will omit the round index \(t\) from \(_{t}\) and \(_{t}\) for simplicity.

### Stage 1: Learning with region-wise multi-class labels

During training of the segmentation model, regions labeled with a single class are used for the conventional supervised learning using the pixel-wise cross-entropy (CE) loss. The set of local regions equipped with single-class labels is defined as

\[_{}:=(s,\{c\}):(s,Y),\,|Y|= 1,\,c Y}\;.\] (5)

The pixel-wise CE loss is then given by

\[_{}=}_{(s,\{c\})_{}}_{x s}-P_{}(y=c|x)\;.\] (6)

On the other hand, regions labeled with multiple classes, denoted as \(_{}:=-_{}\), cannot be used for training using the pixel-wise CE loss, since a multi-class label lacks precise correspondence between each pixel and class candidates, making it a weak label . To effectively utilize the supervision of \(_{}\), we introduce two loss functions.

**Merged positive loss.** Each pixel in a region is assigned with partial labels , _i.e._, a set of candidate classes. The per-pixel prediction in each region should be one of these candidate classes. This concept is directly incorporated into the merged positive loss, which is defined as

\[_{}:=}_{(s,Y)_{}} _{x s}-_{c Y}P_{}(y=c|x)\;.\] (7)

This loss encourages to predict any class from the candidate set since the predictive probability of every candidate class is considered as positive.

**Prototypical pixel loss.** Learning with regions assigned with multi-class labels can be considered as an example of multiple instance learning (MIL) , where each region is a bag, each pixel in the region is an instance, and at least one pixel in the region must be positive for each candidate class. We call such a pixel _prototypical pixel_, and the pixel with the most confident prediction for each candidate class within the region is chosen as a prototypical pixel:

\[x^{*}_{s,c}:=_{x s}P_{}(y=c|x)\;,\] (8)

where \(c Y\) and \((s,Y)_{}\). The segmentation model is trained by applying the CE loss to each prototypical pixel with the assumption that the class associated with it is true. To be specific, the loss is defined as

\[_{}:=}_{(s,Y)_{}} _{c Y}-P_{}(y=c|x^{*}_{s,c})\;.\] (9)

As reported in the literature of MIL , although the prototypical pixels may not always match the ground truth, it is expected that training with numerous prototypical pixels from diverse regions enables the model to grasp the underlying concept of each class. Moreover, this loss mitigates the class imbalance issue as it ensures that every candidate class equally contributes to training via a single prototypical pixel in a region, leading to a balanced class representation.

In summary, the total training loss of the first stage is given by

\[=_{}\,_{}+_{} \,_{}+_{}\;,\] (10)

where \(_{}\) and \(_{}\) are balancing hyperparameters.

### Stage 2: Learning with pixel-wise pseudo labels

In the second stage, we disambiguate the partial labels by generating and exploiting pixel-wise one-hot labels. The pseudo label generation process comprises two steps: _intra-region label localization_ that assigns pseudo class labels to individual pixels within each labeled region, and _label expansion_that spreads the pseudo labels to unlabeled regions adjacent to the labeled one. This process is illustrated in Fig. 3, and described in detail below.

**Intra-region label localization.** For each of the labeled regions, we define a _prototype_ for each annotated class as the feature vector located at the prototypical pixel of the class, which is estimated by Eq. (8) using the model of the first stage. The set of such prototypes is then used as a region-adaptive classifier, which is dedicated to pixel-level classification within the region. To be specific, we assign each pixel the class of its nearest prototype in a feature space; the assigned pseudo label for \(x s\) where \((s,Y)\), is estimated by

\[(x):=*{arg\,max}_{c Y}f_{}(x),f_ {}(x_{s,c}^{*})\,\] (11)

where \(x_{s,c}^{*}\) is the prototypical pixel of class \(c\) and \((f,f^{})=f^{}}{\|f\|\|f^{}\|}\) is the cosine similarity between two feature vectors \(f\) and \(f^{}\).

**Label expansion.** The rationale behind the label expansion step is that the class composition \(Y\) of a region \((s,Y)\) may provide clues about classes of its adjacent regions \(s^{}(s)\), where \(()\) denotes a set of unlabeled regions adjacent to \(s\), _i.e._, \((s)=\). Similar to label localization, the label expansion step aims to assign pixels in \((s)\) the class labels of their nearest prototypes. However, since \((s)\) may contain irrelevant classes, propagating the labels to all pixels in \((s)\) could cause incorrect pseudo labels, leading to performance degradation of the final model. Hence, the pseudo labels are proposed only to relevant pixels that are sufficiently close to at least one prototype in the feature space. More specifically, to compute the relevance in a region- and class-adaptive manner, we propose to use prototype-adaptive thresholds: the prototype-adaptive threshold for class \(c Y\) in \((s,Y)\) is defined as

\[_{c}(s)=f_{}(x),f_{ }(x_{s,c}^{*}):x s,\,(x)=c}\,\] (12)

where \(()\) yields the median value of a set, \(x_{s,c}^{*}\) is the prototypical pixel of class \(c\) (Eq. (8)), and \((x)\) is the pseudo label of \(x\) (Eq. (11)). We propagate pseudo labels of the labeled region \(s\) in \(\) to pixels of an adjacent region \(\{x: s^{}(s),\ x s^{}\}\) by

\[(x):=*{arg\,max}_{c(x)}\ f_{ }(x),f_{}(x_{s,c}^{*})\ |(x)| 1\,\] (13)

where \((x):=c:f_{}(x),f_{}(x_{s,c}^{*}) >_{c}(s),\ c Y}\); \(x\) is a relevant pixel if \(|(x)| 1\). By using the prototype-adaptive threshold for filtering, we can adjust the amount of label expansion in each region without the need for hand-tuned hyperparameters.

The segmentation model is then further trained using the pixel-wise CE loss with pseudo segmentation labels generated by both of the label localization and expansion steps.

Figure 3: The pseudo label generation process (_left_) and its qualitative results (_right_). In each of the labeled regions, the feature vector located at the prototypical pixel of an annotated class is considered the prototype of the class, and the set of such prototypes is used as a region-adaptive classifier for pixel-wise pseudo labeling within the region (label localization). The pseudo labels of the region are propagated to adjacent unlabeled regions similarly (label expansion), but for conservative propagation, only relevant pixels that are close to at least one prototype will be assigned pseudo labels.

## 4 Experiments

### Experimental setup

**Datasets.** Our method is evaluated on two semantic segmentation datasets, Cityscapes  and PASCAL VOC 2012 (VOC) . The former contains 2975 training, 500 validation, and 1525 test images with 19 semantic classes. The latter consists of 1464 training and 1449 validation images with 20 semantic classes. We evaluated models on validation splits of these datasets.

**Implementation details.** We adopt DeepLabv3+  with ResNet-50/101 pretrained on ImageNet  as our segmentation models, AdamW  for optimization. The balancing hyper-parameters \(_{}\) and \(_{}\) of Eq. (10) are set to 16 and 8, respectively, and the temperature \(\) was fixed by 0.1. In both datasets we utilize \(32 32\) superpixel regions given by SEEDS . For Cityscapes, initial learning rates are set to \(2\) (stage 1) and \(4\) (stage 2), and \(\) in Eq. (4) is set to 6. The models are trained for 80K iterations with mini-batches of four \(769 769\) images. We assign an extra _undefined_ class for pixels not covered by the original 19 classes. For VOC, we configure \(\) to 12 and train the models for 30K iterations using a learning rate of \(1\) in both stages. Each mini-batch consists of twelve \(513 513\) images. More details are given in the Appendix B.

**Active learning protocol.** Following the previous work , we consider the number of clicks as the labeling cost. While this protocol assumes a uniform cost per click, it does not hold in reality as shown in Fig. 1. It is adopted for comparisons with the prior art using dominant class labeling , but is _adverse to_ the proposed method since our multi-class labeling takes less cost per click than dominant class labeling. We conduct 5 rounds of consecutive data sampling and model updates, with a budget of 100K and 10K clicks per round on Cityscapes and VOC, respectively. The models are evaluated for each round in mean Intersection-over-Union (mIoU)  on the validation sets. At the first round, regions are selected at random, and the models are reinitialized with ImageNet pretrained weights per round. We conduct all experiments three times and report the average performance.

**Baseline methods.** We compare our multi-class labeling (Mul) with the dominant class labeling (Dom) in combination with various data selection strategies. Following the established strategies in the previous study , we employ Random, which randomly selects superpixels, and the uncertainty-based EvSB given in Eq. (2). ClassBal is EvSB sampling with additional class balancing term proposed in the previous work , and PixBal is our sampling method based on Eq. (4).

### Experimental results

**Impact of multi-class labeling.** In Fig. 4, we evaluate the performance of multi-class and dominant class labeling across varying budgets, using ResNet50 and ResNet101 backbones, on both Cityscapes and VOC with different acquisition functions. Multi-class labeling constantly outperforms dominant class labeling in every setting across all the compared architectures and datasets. In particular, the

Figure 4: Accuracy in mIoU (%) versus the number of clicks (budget) for dominant class labeling (Dom)  and multi-class labeling (Mul) equipped with four different acquisition functions (Random, EvSB, ClassBal, PixBal). The reported accuracy scores are averaged across three trials.

multi-class labeling model, with just 200K clicks, outperforms the dominant class labeling counterpart that uses 500K clicks on Cityscapes. When using ResNet50, the multi-class labeling model equipped with PixBal sampling, achieves 95% mIoU of the fully-supervised model using only 200K clicks on Cityscapes and 20K clicks on VOC, respectively.

**Impact of the proposed sampling method.** Fig. 4 also demonstrates the efficacy of PixBal. On Cityscapes, PixBal consistently outperforms all the other sampling methods regardless of budget size. It also enhances the performance of dominant class labeling. On VOC, PixBal generally surpasses the baselines, although its improvement over BvSB, which lacks class balancing, is marginal at times since VOC less suffers from class imbalance than Cityscapes. Further analysis on these sampling methods are provided in Appendix C.4.

**Comparison with various query designs.** In Table 1, we evaluate multi-class labeling against baseline methods employing different query designs: drawing polygon mask within an image patch (Patch+Polygon), clicking dominant class within superpixel (Spx+Dominant), and clicking all classes within superpixel (Spx+Multi-class). Following the prior work , in this experiment, we measure the ratio of clicks used, relative to the total number of clicks required to draw polygon masks on all images (_i.e._, full supervision). We then measure the ratio of clicks each method needs to achieve 95% mIoU of the fully-supervised model. As indicated in Table 1, superpixel-based methods typically outperform the baselines using patch or polygon queries. Among these, our multi-class labeling stands out, achieving 95% mIoU of the fully-supervised model using only 4% of its required data.

### In-depth analysis on the proposed method

**The number of classes in selected regions.** The histogram and cumulative distribution of Fig. 5 summarize the number of classes within regions selected at round-5 using PixBal sampling method on Cityscapes. We observe that more than 50% of the selected regions contain two or more classes, explaining the necessity of multi-class labeling. This also suggests that, regarding labeling cost in reality (_i.e._, actual annotation time), multi-class labeling holds potential for further improvement in efficiency as it requires less labeling time for multi-class regions (Fig. 1).

**Contribution of each component.** Table 2 quantifies the contribution of each component in our method over five rounds: merged positive loss in Eq. (7), prototypical pixel loss in Eq. (9), intra-region label localization, and label expansion. The results show that all components improve performance at every round. The performance gap between (c) and (e) in the table verifies the efficacy of merged

   Query & Sampling & Clicks (\%) \\   & EntropyBox+\({}^{}\) & 10.5 \\  & MetaBox+\({}^{}\) & 10.3 \\   & ClassBal\({}^{}\) & 7.9 \\  & ClassBal  & 9.8 \\  & PixBal & 7.9 \\   & PixBal (Ours) & **4.0** \\   

Table 1: The ratio of clicks (%) needed to reach 95% mIoU of the fully-supervised model, relative to full supervision. Results with \(\) are from the prior work  using Xception-65 as backbone.

positive loss for learning with multi-class labels. Meanwhile, the gap between (c) and (d) in the table shows the efficacy of prototypical pixel loss, particularly at the initial round with severe class imbalance due to random sampling. The largest mIoU gain is achieved by intra-region label localization, as shown by the gap between (b) and (c) of the table. Lastly, label expansion further boosts the performance by 1.2%p on average.

**Qualitative analysis on pseudo labels.** Fig. 6 qualitatively compares region-wise dominant class labels and pixel-wise pseudo labels given by the proposed method to show the label disambiguation ability of our method. Regions labeled with dominant classes overlook areas occupied by minor classes. In contrast, our intra-region localization accurately identifies various classes within each region as shown in the second column of Fig. 6. Moreover, label expansion augments the amount of supervision by referencing the class composition within the region. Notably, minor classes within a region often significantly enhance the quality of pseudo labels via label expansion.

**Ablation study of pseudo labeling.** Fig. 7 presents our ablation study on pseudo labeling with ResNet50 on Cityscapes. Fig. 7(a) compares performance improvement by the intra-region label localization (w/ prototypes) and that by a baseline assigning the most confident class among multi-class labels as a pixel-wise pseudo label (w/o prototypes). The result suggests that using prototypes consistently surpasses the baseline across different budgets due to their adaptability to local regions. In Fig. 7(b), we investigate the improvement when label expansion is applied to multi-class and dominant class labels across varying budgets. It turns out that label expansion is more effective with multi-class labeling, as it enables the propagation of pseudo labels belonging to multiple classes, leading to a more extensive expansion of pseudo labels.

**Impact of region generation algorithm.** In Fig. 8(a), we evaluate both dominant class labeling (Dom) and multi-class labeling (Mul) across two superpixel generation algorithms: SLIC  and SEEDS . Both labeling methods show better performance when combined with SEEDS. This is because SEEDS is better than SLIC in terms of boundary recall  and thus regions generated by SEEDS better preserves the class boundary. Note that the dominant class labeling shows significant performance degradation when combined with SLIC, while the multi-class labeling only shows a modest performance drop. This result suggests that the proposed multi-class labeling is more robust to the quality of the superpixel generation algorithm.

Figure 6: Qualitative comparisons between different labeling strategies. (a) Dominant class labels. (b) Label localization. (c) Label localization + label expansion. (d) Ground-truth.

Figure 7: mIoU gain (%) from intra-region label localization and label expansion varying budgets. (a) Gain of label localization with vs. without prototype. (b) Gain of label expansion on dominant and multi-class labels.

**Impact of region size.** In Fig. 8(b), we evaluate dominant class labeling (Dom) and multi-class labeling (Mul) across different superpixel sizes: 16\(\)16 (SP16), 32\(\)32 (SP32), and 64\(\)64 (SP64). Both methods achieve their best with the 32\(\)32 region size. Note that dominant class labeling leads to a large performance drop when the region size increases from 32\(\)32 to 64\(\)64 since a larger region is more likely to contain multiple classes, which violates the key assumption of dominant class labeling. In contrast, multi-class labeling is more robust against such region size variations.

**Impact of hyperparameters.** In Fig. 9, we evaluate the sensitivity of our stage 1 model to variations in the hyperparameters: \(\), \(_{}\), and \(_{}\). This evaluation is conducted on Cityscapes using ResNet50 backbone and combined with PixBal sampling. Our model demonstrates robustness to these hyperparameter changes, with accuracy fluctuations of less than 1.5%. It's noteworthy that our final model does not use the optimal hyperparameter values. This indicates that we did not exhaustively tune these parameters using the validation set.

## 5 Conclusion

We have introduced a novel multi-class label query for AL in semantic segmentation. Our two-stage training method and new acquisition function enabled an AL framework with the multi-class label query to achieve the state of the art on two public benchmarks for semantic segmentation by improving label accuracy and reducing labeling cost. Some issues still remain for further exploration. As it stands, our method depends on off-the-shelf superpixels and does not transfer the pseudo labels to the next rounds. Next on our agenda is to address these issues by learning image over-segmentation and developing an advanced AL pipeline.

Figure 8: Accuracy in mIoU (%) versus the number of clicks (budget) for dominant class labeling (Dom) and multi-class labeling (Mul) equipped with PixBal evaluated on Cityscapes using ResNet50. (a) Impact of superpixel generation algorithm: SEEDS  and SLIC . (b) Impact of superpixel size: 16\(\)16 (SP16), 32\(\)32 (SP32), and 64\(\)64 (SP64).

Figure 9: Average accuracy of our stage 1 model over 5 rounds, in mIoU (%), as a function of varying hyperparameters. The model is evaluated on Cityscapes using ResNet50 backbone with PixBal sampling. (a) The class balancing regulation term \(\). (b) Loss balancing term \(_{}\). (c) Loss balancing term \(_{}\). The blue diamond marker indicates the value selected for our final model.