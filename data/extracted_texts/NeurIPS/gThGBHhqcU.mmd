# Rethinking Conditional Diffusion Sampling with Progressive Guidance

Anh-Dung Dinh

School of Computer Science

The University of Sydney

dinhanhdung1996@gmail.com &Daochang Liu

School of Computer Science

The University of Sydney

daochang.liu@sydney.edu.au &Chang Xu

School of Computer Science

The University of Sydney

c.xu@sydney.edu.au

Corresponding authors

###### Abstract

This paper quantifies and tackles two critical challenges encountered in classifier guidance for diffusion generative models, i.e., the lack of diversity and the presence of adversarial effects. These issues often result in a scarcity of diverse samples or the generation of non-robust features. The underlying cause lies in the mechanism of classifier guidance, where discriminative gradients push samples to be recognized as conditions aggressively. This inadvertently suppresses information with common features among relevant classes, resulting in a limited pool of features with less diversity or the absence of robust features for image construction. We propose a generalized classifier guidance method called Progressive Guidance, which mitigates the problems by allowing relevant classes' gradients to contribute to shared information construction when the image is noisy in early sampling steps. In the later sampling stage, we progressively enhance gradients to refine the details in the image toward the primary condition. This helps to attain a high level of diversity and robustness compared to the vanilla classifier guidance. Experimental results demonstrate that our proposed method further improves image quality while offering a significant level of diversity as well as robust features. Source code is available at: https://github.com/dungdinhan/prog-guided-diffusion.

## 1 Introduction

Diffusion model  has emerged as a state-of-the-art technique for generating high-fidelity images without relying on adversarial training techniques like GANs . This approach has gained popularity among researchers because it avoids mode collapse and training instability. For diffusion models, the generated samples can be further enhanced with improved quality and controllable attributes using guidance techniques for sampling. _Classifier guidance_ is one of these techniques which offers numerous benefits. Conditional information can be provided to unconditional diffusion models using noise-aware classifiers' gradients to guide towards pre-defined conditions during sampling. This technique is able to not only improve image quality significantly but also trade-off between diversity and conditional information to fit with the application design. More critically, the flexible nature of classifier guidance allows easy extensions of off-the-shelf diffusion models at the sampling stage without any expensive re-training.

In spite of all of its benefits, the classifier guidance still suffers from two critical flaws. The first flaw is the _adversarial effect_ where the model fails to produce samples belonging to the target condition. Guiding the model with the gradient and maximizing the probability of the target condition may lead to shortcut learning that generates samples attacking the classifier. Examples can be found in Figure 1(a), where samples achieve very high confidence in the conditional class but result in very poor features. The second flaw is the _diversity suppression_ caused by the conflict between the diffusion model's generative nature and the classifier's discriminative nature. The optimization towards the condition overly encourages the model to generate only image features that can be easily recognized by the classifier while neglecting other features relevant to the condition, which can reduce the diversity of the generation. Figure 1(b) shows that common features among classes are suppressed since they are harder to classify, resulting in a lack of diversity. These two problems of the classifier guidance come from its underlying guidance mechanism. Specifically, this approach assumes that the objective of the generative task is the same as that of the discriminative task. By utilizing the gradient \( p(y=y_{c}|x)\), the guidance aims to create an image with features that can be distinguished by the classifier as belonging to the label \(y_{c}\). However, when this approach maximizes the probability of the condition class, it also undesirably suppresses important information relevant but in other classes, causing the lack of diversity and the adversarial effect, as examples mentioned.

This paper proposes a new guidance approach for diffusion models, which generalizes the classifier guidance to tackle the above problems while maintaining its flexibility and efficiency. Our core idea is to alter the aggressive gradients towards a single target in the naive classifier guidance by the gradients that are _progressive_ along two dimensions, i.e. the class dimension and the temporal dimension as illustrated in Figure 1(c). Along the class dimension, our method tolerates the gradients from other classes relevant to the condition of the generative task. Along the temporal dimension, we expect the gradients to construct shared features among relevant classes when the image is noisy, and the gradients focus on features more specific to the condition after the image becomes clearer. This scheme allows a larger feature pool, which circumvents information suppression and lack of diversity. Besides, the help from relevant information and the less aggressiveness toward one condition also results in more robust features in the samples.

In summary, our contributions are as follows: (1) Proposing a generalized classifier guidance method with progressive gradients that consider relevant information associated with multiple classes depending on the noise level at each timestep. (2) In-depth analysis on reducing the adversarial effects and the diversity suppression of classifier guidance sampling quantitatively and qualitatively. (3) Improvement on image generation task to reach State-of-the-art (SOTA) on different metrics with different datasets.

## 2 Background

**DDPM**: The Denoising Diffusion Probabilistic Model (DDPM) is represented by the probability distribution function \(p_{}(_{0}):= p_{}(_{0:T})d_{1:T}\), where \(_{1},_{2},...,_{T}\) are latent variables having

Figure 1: _(a) Samples generated by vanilla classifier guidance achieve high confidence in the condition class but have suspicious features. (b) Images generated by vanilla guidance (left) show a lack of diversity where front-face features are over-exploited. Features shared among breed classes are often lacked, such as action pose and background details depicted in the ground truth images (right). The vanilla guidance has exploited the most distinguishable features to satisfy the classifier while suppressing common features. (c) Our proposed guidance scheme allows gradients from relevant classes to join the sampling process. \(c_{1}\) is the condition. The darkness of the gradients represents the gradients’ weights (information degree) during sampling. More examples can be found in Supplementary. Dataset: ImageNet64x64_

the same dimensionality as the data \(_{0} q(_{0})\). The variable \(_{T}\) follows the distribution \(p(_{T})=(_{T};,)\). The process of \(p_{}(_{0:T})\) is known as the _reverse process_ and is a the Markovian chain: \(p_{}:=p(_{T})_{t=1}^{T}p_{}(_{t-1}| _{t}),\) where \(p_{}(_{t-1}|_{t}):=(_{t-1}; _{}(x_{t},t),_{}(x_{t},t)).\) This process is also known as the diffusion model's sampling process or inference process.

In contrast to the _reverse process_, the _forward process_ corrupts the original data \(_{0}\) to \(_{T}\) with a predefined schedule of Gaussian noise. This process is a fixed Markovian chain: \(q(_{1:T}|_{0}):=_{t=1}^{T}q(_{t}|_{t-1}),\) where \(q(_{t}|_{t-1}):=(_{t};}_{t-1},_{t}).\)\(_{t}\) is the fixed variance scheduled for both _forward_ and _reverse_ process.

There are a number of ways to define the output of the network \(\) such as noise predictor \(_{}(_{t},t)\), mean predictor \(}_{}(_{t},t)\). The most common method is the noise predictor \(_{}(_{t},t)\). After the \(\) are trained to match \(_{}(_{t},t)\) with \(\), we have the sampling equation:

\[_{t-1}=}}(_{t}-}{_{t}}}_{}(_{t},t))+_{t} ,\] (1)

with \(\) as the random noise, \(_{t}\) is the variance of the of \(p_{}(_{t-1}|_{t})\) and \(_{}\) is the predicted noise.

**Classifier Guidance**: The guidance aims to provide conditional information during the sampling process so that the output image satisfies the predefined conditions. From Eq. 1, we denote \(_{t}:=}}(_{t}-}{ {1-_{t}}}_{}(_{t},t))\). Given condition \(y_{c}\), \( p_{}(y_{c}|_{t})\) is the log of conditional distribution of the class \(y_{c}\) through observing \(_{t}\). The sampling equation for \(_{t-1}\) given \(_{t}\) with guidance scale \(s\) is as below:

\[_{t-1}(_{t}+s_{t}^{2}_{_{t} } p_{}(y_{c}|_{t}),_{t}).\] (2)

Where \(\) is the parameters of the pretrained classifier.

## 3 Methodology

We first present a scheme allowing relevant information gradients to join the sampling process. After that, the progressive schedule is proposed to adapt the relevant gradients taking the noise level in samples into account. From the Eq. 2, the short form of sampling with guidance is as below:

\[_{t-1}=_{t}+_{t}*+s_{t}^{2}_{_{t}} p_{}(y_{c}|_{t}).\] (3)

The expected output of \(_{t-1}\) is to maximize \(p_{}(y_{c}|_{t})\). Due to the probability property of \(_{i=1}^{C}p(y_{i}|_{t})=1\), the increase in \(p(y_{c}|_{t})\) will result in the reduction in other probability for other classes \(p(y_{i}|_{t}), i c\) with \(c\) is the condition, and \(C\) is the total number of classes. This results in the suppression of other classes of information which contributes to harmful effects, as mentioned in Figure 1(a) and (b). We propose to generalize the Eq. 3 as follows:

\[_{t-1}=_{t}+_{t}*+w_{i=1}^{C}s_{i}_{t} ^{2}_{_{t}} p_{}(y_{i}|_{t}),\] (4)

with \(s_{i} 0\) is the degree of information injected into the diffusion sampling process by class \(y_{i}\). We further constraint \( s_{i}=1\) and \(s_{c}>s_{i}, i c\). Note that the Eq. 3 is a special case of Eq. 4 where \(s_{i}=0, i c\) with \(c\) is the condition for the sampling process of diffusion models. Similar to [14; 15; 11], a guidance scale \(w\) is added to balance denoising signals and classification gradients.

**Remark 3.1**: _By incorporating gradients from other classes during sampling, the conflict between the sampling and discriminative objectives can be decreased, resulting in diverse generated samples._

_Explain._ The use of only the condition class's gradient limits the feature pool's space to some specific features that are the most distinguishable from other classes. This results in the lack of common features shared among relevant classes, which causes a trade-off in the diversity of generated samples. We hypothesize that solely pushing condition gradient suppresses other classes' information since we have \(_{i}p(y_{i}|_{t})=1\) and the increase in \(p(y_{c}|_{t})\) result in the reduction from others. As a result, the inclusion of other classes' gradients avoids this pitfall.

**Remark 3.2**: _Using other classes' gradients beyond the conditional class gradient helps avoid adversarial effects._

_Explain._ A substantial number of generated images achieve high confidence in the condition class; however, they possess peculiar features unrecognizable to the human eye. Relying solely on conditional class gradients for information construction presents several robustness problems. Firstly, the gradients associated with the conditional class may contain noise that is specific to that class. Depending solely on this information opens a shortcut for the sampling process to exploit the model by utilizing the noise rather than satisfying semantic features. Secondly, suppressing information from other classes has detrimental effects on robust features. Datasets often consist of numerous classes that share common features that play vital role in constructing meaningful images. When these features are suppressed, the image becomes unrecognizable to the human eye.

Using gradients of other classes, in terms of formulation, first helps avoid adversarial attack-like generation through exploiting the sum of gradients \(_{i} p(y_{i}|_{t})\). Furthermore, the use of relevant class information forces the model to generate features that satisfy many classes at the same time. This helps avoid specific noise in a class and can utilize the common features shared among classes to avoid the failure of constructing key features. In-depth discussion about the Remark 3.1 and 3.2 are shown in section 4. The rest of this section will discuss the techniques and algorithms to bring the Eq. 4 into the practical sampling process.

### Information Degree vector

The information degree \(=\{s_{1},s_{2},...,s_{C}\}\) is the set of weights associated with the gradients from classes that contribute to the information construction of the image. In order to balance between gradients, we set a constraint \( s_{i}=1\). Given \(c\) is a main condition, \(s_{c}>s_{i}\  1 i C\).

From the Eq. 4, for a given condition \(c\), the aim is to provide the most relevant features that help avoid information suppression. However, not all labels in the \(C\) classes help construct the condition \(c\). Instead, for a given class \(c\), if the \(i^{th}\) class has higher relevance to class \(c\) than \(j^{th}\) class, we expect to have information degree \(s_{i}>s_{j}\). There are several ways to satisfy the requirement to have a correlation between labels' features and their degree of information \(=\{s_{1},s_{2},...,s_{C}\}\), such as Label Enhancement  or Partial Multi-label [17; 18]. However, a simple technique, which does not require any training, is preferred due to concerns about the complexity of the whole sampling process. Inspired by the prompt engineering section in CLIP , we propose to model the correlation between labels via the description text of labels. Instead of using fixed templates similar to CLIP, we need more details about each class to have more generative features. In this work, we utilize ChatGPT  to generate text descriptions for each class. After removing stop words and other preprocessing text, we use a CLIP model to obtain each class's embedding information \(v_{i}\). The embedding information is then utilized to calculate the similarity based on cosine similarity, i.e., \(_{i,j}=v_{j}}{\|v_{i}\|\|v_{j}\|}\). Given the conditional label \(c\), we have the information degree for each label as \(s_{i}=_{c,i}}{_{j=1}^{C}_{c,j}}, 1  i C\). We denote \(_{c}=\{s_{1}^{c},s_{2}^{c},...,s_{C}^{c}\}\) as the vector of information degree for sampling the image from condition \(c\). To avoid complication in formulation, later in the manuscript, we will only denote \(=\{s_{1},s_{2},...,s_{C}\}\) for the information degree vector for the condition \(c\) without losing generality.

### Progressive Information Degree

The subsection 3.1 describes a combination of gradients among classes. In the diffusion sampling, the image \(_{t-1}\) is less chaotic and more meaningful than the sample \(_{t}\). Therefore, we also progressively adapt the \(\) at every timestep to be less chaotic. We index the \(\) at each timestep as \(_{t}=\{s_{1,t},s_{2,t},...,s_{C,t}\}, 0 t T\). A simple heuristic schedule is proposed to reduce the chaos of \(\) at each step. At every timestep, for the condition \(c\), the degree of information \(s_{c,t}\) is increased by a small amount \( s_{c,t}\). At the same time, the \( s_{c,t}\) is distributedly deducted from information degrees \(s_{i,t}\) of other classes, ensuring condition \(_{i=1}^{C}s_{i,t}=1\). \(_{t}\) is formulated as:

\[ s_{i,t}=-*(1-s_{i,t}),& i=c\\ - s_{c}*}{_{j=1,j c}^{C}s_{j,t}},& i  c,\] (5)with \(0 1\) as the updating rate. After obtaining \(_{t}\), we update the \(\) following \(_{t-1}=_{t}-_{t}\). From the above equations, if \(=1\), the sampling process is primarily similar to the vanilla guidance diffusion sampling as in Eq. 2 where only features from class \(c\) join in the sampling process.

Next, we use an entropy perspective to interpret the mechanism of our method. With the sampling equation 4, we can generalize the sampling with Kullback-Leibler divergence as:

\[_{t-1}=_{t}+_{t}*-w_{t}^{2}_{_{t}}D_{KL}(||p_{}(|_{t})).\] (6)

When \(_{t}\) is fixed, the optimization of \(D_{KL}(||p_{}(|_{t}))\) totally depends on \( p_{}(y_{i}|_{t})\). However, when \(_{t}\) is varying, the minimization of KL divergence term will take the full form as \(D_{KL}(_{t}||p_{}(|_{t}))=_{i=1}^{C}s_ {t,i} s_{t,i}-s_{t,i} p_{}(y_{i}|_{t})\). Therefore, the process of transforming the vector of information degree can be formulated as below:

\[_{_{t}}-_{i=1}^{C}s_{i,t} s_{i,t},\] (7)

so that **(1)**\(s_{c,t}>s_{i,t}, i c,1 i C,\)**(2)**\(_{i=1}^{C}s_{i,t}=1,\)**(3)**\(0 s_{i,t}<1, 1 i C,\) and **(4)**\(|s_{i,t}^{*}-s_{i,t}| l, 1 i C\). With \(_{t}^{*}\) as the optimal solution, we have \(_{t-1}=_{t}^{*}\). Because it is hard to optimize the objective 7 and the \(D_{KL}(_{t}||p_{}(|_{t}))\) at the same time, the constraint (4) is added with an upperbound \(l\) to avoid the mitigation of the minimization of \(D_{KL}(||p_{}(|_{t}))\) regarding \(_{t}\). Using the proposed schedule, the upperbound becomes \(l=*\).

Throughout the diffusion model's sampling process, the information degree vector will gradually converge near to one-hot vector, leading to the minimization of objective 7. From this point of view, we have formulated the sampling as the problem of matching two distributions between conditional probability \(p(|_{t})\) with information degree vector \(_{t}\). The schedule aims to do the reverse entropy regularization on target \(_{t}\), which is opposite to the classic entropy regularization [21; 22]. The formal discussion about reverse entropy regularization is in Supplementary.

## 4 Analysis

The previous section has shown our method to guide image generation through a progressive scheme. We now provide further analysis to visualize how our algorithm solves the problems in detail. We set up this analysis on ImageNet4x64 using ADM  with or without Progressive Guidance (ProG) to investigate the diversity suppression and the adversarial effect.

**Diversity suppression alleviation**: As the process commences, incorporating information from relevant classes of the conditions into the sampling process is crucial to overcome the issue of information suppression among labels, as illustrated in Figure 2. The Brittany Spaniel is the main condition in this example. We demonstrate that by introducing gradients solely from the Brittany

Figure 2: _Diversity Suppression alleviation. Britany Spaniel is the condition. Conventional guidance approach often collapses generated samples to primarily exhibit the facial features of Britany Spaniel. However, by incorporating features from other classes, such as English Springer and Welsh Sprinter Spaniel, the sampling can capture common characteristics shared between classes such as backgrounds, poses and actions._

Spaniel, the process converges towards the features that benefit the pretrained classifier the most, focusing primarily on simple and easily classifiable characteristics -- the front face features of the dog. In contrast, by providing information about the English Springer and Welsh Springer Spaniel, we encourage the model to sample images with lower confidence in identifying them as Brittany Spaniels and to tolerate a certain degree of confidence in them belonging to other breeds during the initial stage of the sampling process. This scheme allows the process to search and sample in the pool of common features between classes, facilitating the diverse samples. We further do an analysis of this feature collapse problem on different types of breeds in section B.1 of the Supplementary. We found out that besides _Front-face features_ over-exploitation as in Figure 2, the vanilla guidance scheme also suffers from _Front stretching pose_ and _Green grass background_ problems. Similar to Figure 2, our proposed ProG scheme shows that it can solve these problems.

**Robustness features construction**: Figure 3 provides a visual example of how support from gradients of other classes can effectively reduce non-robust features. In the example, the naive classifier guidance suppresses the representation of _tiger_ features, resulting in a significantly degraded image quality due to the lack of facial features of the _leopard_. In contrast, our proposed method promotes the emergence of _tiger_, _panther_ and _leopard_ features during the early stages of the sampling process. It gradually diminishes _tiger_ and _panther_ towards the end, ultimately achieving the desired _leopard_ features. Additional instances are also demonstrated where our proposed methods effectively address failure cases due to non-robustness features associated with the conventional classifier guidance. More examples with high-resolution images can be found in section C of the Supplementary.

## 5 Related works

The field of generative models has seen a significant surge in the use of diffusion models. Specifically, the Denoising Diffusion Probabilistic Model (DDPM) and its variants [1; 3; 2; 23; 24; 11; 25] have emerged as prominent models for generative tasks which provides better stability than GANs [26; 27; 28; 29; 30; 9; 31; 32]. Not only for generative tasks, but discriminative tasks also benefit from diffusion scheme [33; 34]. In addition to the DDPM series, score-based models [4; 35] are developed as a theoretical counterpart to the DDPM series. Despite having different optimization objectives and motivations, these two types of models are closely related . In addition to diffusion models, conditional generative models have gained significant attention in the generative model's research community [6; 30]. DGMs [1; 5] offer a conditional version by connecting a classification head to the diffusion model. These models benefit from conditional information [11; 36]. Recent research has focused on achieving controllable samplers/generators without retraining DGMs. Classifier guidance  proposes to use classifier gradient signals for guidance, which has been further generalized by  to adapt different types of modality. Classifier-free guidance  has shown that guidance properties can also be achieved without a classifier. CompDiffusion  proposes to guide the diffusion model by combining different conditions given by a pretrained model. However, most guidance works suffer from the trade-off between sample quality, diversity, and conditional

Figure 3: _Robustness Features Construction. The vanilla guidance fails at conditioning the sample as leopard (top-left). The tiger, panther and leopard helps to influence the image content in the initial state to form the critical features of the leopard to overcome the failure (bottom-left), where clear tiger features are observed in the early images. The right part shows more failure cases corrected using our proposed ProG. The darkness of the gradients shows their associated information degree values._

information.  has handled this problem by including a scoring model during the training of a noise-aware classifier, causing an increase in the running time. Discriminator Guidance  finetunes the sampling process by training a Discriminator, which also faces the problem of large training time similar to . In contrast, our work addresses this problem without retraining the diffusion or noise-aware classifier models.  solves the problems of conflict during the sampling process of diffusion models, yet this work ignores the problem of robustness features construction. Adversarial white-box attack [40; 41; 42; 43; 44] shares common technique with classifier guidance to exploit the gradient \( p(y_{c}|X)\) to construct the features, leading to concerns in the community about the use of \( p(y_{c}|X)\) in classifier guidance that causes adversarial effects. One of the main targets of our work is to solve this concern.

## 6 Experiments

**Setup.** Extensive experiments are conducted on CIFAR10, ImageNet (64x64, 128x128, 256x256). We denote Progressive Guidance (ProG) as our proposed method, which is first evaluated on ADM  and IDDPM  to verify our claims on improving the performance of the vanilla guidance method. Subsequently, ProG is combined with the EDS , an advanced guidance method to solve the gradient vanishing problem, to achieve the state-of-the-art. Other baselines are taken from BigGAN, ADM , EDS, IDDPM , VAQ-VAE-2, LOGAN , DCTransformers  and DiT (latent diffusion). The ADM with a conditional pretrained diffusion model is denoted as CADM. We utilize five standard scores, which are IS, FID/sFID , Precision , and Recall , to evaluate the image quality and diversity of the generated samples.

   Model & IS (\(\)) & FID (\(\)) & sFID (\(\)) & Prec (\(\)) & Rec (\(\)) \\  
**ImageNet 64x64** & & & & & \\  ADM & 25.64 & 9.95 & 6.58 & 0.60 & 0.65 \\ ADM-G & 46.90 & 6.40 & 9.67 & 0.65 & 0.54 \\
**ADM-G + ProG** & 46.88 & **5.16** & **6.72** & **0.72** & **0.56** \\  IDDPM & 16.02 & 18.35 & 5.08 & 0.60 & 0.57 \\ IDDPM-G & 18.89 & 13.62 & 4.43 & 0.63 & 0.55 \\
**IDDPM-G + ProG** & **21.60** & **11.12** & **4.25** & **0.67** & **0.55** \\  CADM & 53.79 & 2.07 & 4.35 & 0.73 & 0.63 \\ CADM-G & 66.52 & 2.02 & 4.62 & 0.78 & 0.59 \\
**CADM-G + ProG** & 65.65 & **1.87** & **4.33** & 0.77 & **0.60** \\  
**ImageNet 128x128** & & & & & \\  CADM & 92.53 & 6.14 & 4.96 & 0.69 & 0.65 \\ CADM-G & 141.55 & 2.98 & 5.10 & 0.77 & 0.59 \\
**CADM-G + ProG** & **157.24** & **2.77** & **5.09** & **0.80** & **0.59** \\  
**ImageNet 256x256** & & & & & \\  ADM & 39.7 & 26.21 & 6.35 & 0.61 & 0.63 \\ ADM-G & 96.15 & 11.96 & 10.28 & 0.75 & 0.45 \\
**ADM-G + ProG** & **99.45** & **11.21** & **8.67** & **0.76** & **0.46** \\  CADM & 100.98 & 10.94 & 6.02 & 0.69 & 0.63 \\ CADM-G & 188.91 & 4.58 & 5.21 & 0.81 & 0.52 \\
**CADM-G + ProG** & **222.09** & **4.53** & **5.08** & **0.85** & 0.49 \\  
**CIFAR10 32x32** & & & & & \\  ADM & 9.55 & 2.87 & 4.36 & 0.69 & 0.60 \\ ADM-G & 9.58 & 2.85 & 4.30 & 0.68 & 0.60 \\
**ADM-G + ProG** & 9.45 & **2.81** & **4.28** & **0.69** & **0.60** \\   

Table 1: _ProG helps to achieve better IS/FID/sFID in general. The improvement is significant on both IDDPM  and CADM/ADM  (both unconditionally or conditionally trained). “-G” postfix attached to diffusion model stands for vanilla classifier guidance. Bold values are the performance our proposed ProG helps achieve better than vanilla guidance. The underlined values are the cases where diffusion models without guidance achieve the best value. \({}^{}\) is denoted for the score evaluated by the samples provided by the paper. \(\) means the values are directly used from the papers due to the unavailability of the pretrained model._

**Robustness metric**: The issue of quantifying the adversarial effects caused by the classifier guidance method has not been adequately addressed in previous works [1; 15] since it is challenging due to the trade-off between diversity, feature quality, and robustness. We propose to leverage a bank of off-the-shelf pretrained classification models to evaluate the robustness features based on the assumption that it is much more difficult for the non-robust image to trick a set of separately pretrained classifiers than only a single guidance classifier. Specifically, the robustness features are quantified by averaging Top-1 accuracy using pretrained models ResNet34, ResNet50, ResNet151 , DenseNet169, DenseNet201 , SqueezeNet, SqueezeNet . To ensure a fair comparison between the two generative schemes, we adjust the guidance scale to achieve similar diversity and feature quality, measured by similarity in the Frechet Inception Distance (FID).

### Improvement over Classifier Guidance

In this section, we show that applying the ProG method helps achieve better performance quantitatively over vanilla guidance regarding image quality, diversity, and robustness. Table 1 shows a clear improvement in all the guidance sampling models on image quality and diversity. ProG achieve lower recall values in some datasets than the ADM baseline without guidance. However, this is expected as conditional generative schemes limit the search space resulting in less freedom in sampling features.

**Diversity trend when increasing \(w\)**: By increasing guidance scale \(w\), the FID scores and diversity scores such as Recall are less sacrificed in ProG to achieve a higher IS score and conditional information compared to vanilla guidance (Figure 4). When increasing the guidance scale, our proposed method mostly has a slower degeneration rate in FID and Recall than the vanilla guidance.

**Robustness improvement** We show that utilizing the ProG method can achieve more robust features than vanilla guidance, with the robustness performance shown in Table 2. We first adjust \(w\) so that the two generative processes (vanilla and our proposed) have the same FID scores. After that, we calculate the robustness score as described previously.

**Key takeaway**: The ProG helps to improve the guidance to achieve three targets. Firstly, we achieve better image quality and diversity than the vanilla guidance scheme, which can be observed through IS, FID, sFID, Precision, and Recall. Secondly, we alleviate the diversity suppression qualitatively and quantitatively even when the guidance scale is set to be very large. Finally, we achieved better robustness than the original guidance scheme quantitatively and qualitatively.

### State-of-the-Art Comparision

To compare with other state-of-the-art methods, we combine our proposed method with EDS . While our method aims to solve information suppression, the EDS will help amplify the guidance signals at the end of the sampling process. The result shows favorable outcomes in Table 3. Our ProG achieves the state-of-the-art IS/FID on ImageNet64x64 and ImageNet128x128. On ImageNet256x256, the ProG helps to improve DiT-G slightly but consistently over all metrics. Furthermore, we can achieve a comparable level of robustness to classifier-free guidance in Table 4, which is a method

  Model & Robustness (\(\)) & FID \\
**ImageNet 256x256** & & \\  CADM-G & 79.65 & 4.58 \\
**CADM-G + ProG** & **85.04** & **4.56** \\  

Table 2: \(w\) _are adjusted between CADM-G and CADM-G + ProG to achieve similar FID to evaluate robustness. The ProG significantly improves the robustness of the samples._

Figure 4: _FID and Recall trend of guidance sampling with (a) ImageNet64x64 unconditional ADM (b) ImageNet64x64 conditional ADM. For vanilla guidance, it becomes evident that the guidance scale increase leads to a rapid decline in both Recall value and FID, indicating a degradation in the diversity of the samples. Conversely, our method sustains a stable trend associated with \(w\) increase._that does not share common techniques with adversarial attacks while also exhibiting a significantly improved diversity trend compared to vanilla classifier guidance, as shown in Table 4. It is worth noting that in the diffusion ADM model, classifier-free guidance outperforms classifier guidance; however, this comes at the cost of nearly twice the computational burden due to the need for forwarding to diffusion twice at each timestep. Moreover, classifier-free guidance lacks the flexibility offered by the classifier guidance method. We also discuss in-depth the benefits of using classifier guidance with ProG compared to classifier-free guidance in section E in Supplementary. Section F in the Supplementary will discuss several techniques to extend ProG into Text-to-Image Generation. The section D in Supplementary will provide the settings for all experiments.

### Ablation Study

**Effects of schedule**: ProG schedule relies on a single hyperparameter \(\) to determine the speed of convergence towards the one-hot vector. A larger \(\) leads to faster convergence, while a smaller \(\) results in slower convergence. Table 5 demonstrates the sensitivity of \(\), showing that varying it does not significantly impact the results. Results obtained with \(\) values of \(0.04\) or \(0.06\) are similar. When \(\) becomes larger, the model is more likely to achieve a higher Inception Score (IS), but trade-off with FID/sFID scores, indicating a decrease in sample quality. It is worth noting that without the schedule (\(=0\)), the guidance method fails, underscoring the importance of the proposed scheduler.

   Model & Robustness@1 (\(\)) & FID & & \\
**ImageNet256x256** & & & & \\  CADM-G + EDS & 83.31 & 3.96 & & \\
**CADM-G + EDS + ProG** & **86.60** & **3.90** & & \\ CADM + CLS-FREE & 87.14 & 3.95 & & \\   

Table 4: _FID and Recall trend for guidance sampling with ImageNet256x256 conditional diffusion. ProG not only helps to achieve better FID but also a higher robustness score. Besides, the diversity trend is also better preserved than vanilla guidance when the guidance scale is increased._

   Model & IS (\(\)) & FID (\(\)) & sFID (\(\)) & Prec (\(\)) & Rec (\(\)) \\  
**ImageNet64x64** & & & & \\  BigGAN\({}^{}\) & 44.99 & 4.06 & 3.96 & 0.79 & 0.48 \\ IDDPM\({}^{*}\) & 46.31 & 2.90 & 3.78 & 0.73 & 0.62 \\  CADM + CLS-FREE\({}^{*}\) & 63.39 & 1.93 & 4.49 & 0.77 & 0.60 \\ CADM-G + EDS & 61.91 & 1.85 & 4.36 & 0.76 & 0.61 \\
**CADM-G + EDS+ ProG** & **65.89** & **1.77** & **4.25** & **0.77** & **0.61** \\  
**ImageNet128x128** & & & & \\  BigGAN\({}^{}\) & 145.93 & 6.02 & 7.18 & 0.86 & 0.35 \\ LOGAN\({}^{}\) & 148.2 & 3.36 & & & \\ CADM-G + EDS & 160.2 & 2.58 & 4.92 & 0.78 & 0.58 \\
**CADM-G + EDS+ ProG** & **175.31** & **2.47** & **4.92** & **0.80** & **0.58** \\  
**ImageNet256x256** & & & & \\  BigGAN\({}^{}\) & 202.77 & 7.03 & 7.29 & 0.87 & 0.27 \\ DCTrans\({}^{}\) & - & 36.51 & 8.24 & 0.36 & 0.67 \\ VQ-VAE\({}^{}\) & - & 31.11 & 17.38 & 0.36 & 0.57 \\ IDDPM\({}^{}\) & - & 12.26 & 5.42 & 0.70 & 0.62 \\ CADM + CLS-FREE\({}^{*}\) & 191.31 & **3.76** & **4.87** & 0.80 & **0.55** \\ CADM-G + EDS & 212.51 & 3.96 & 5.0 & 0.82 & 0.52 \\
**CADM-G + EDS+ ProG** & **232.86** & 3.84 & 5.0 & **0.83** & 0.51 \\ DiT (latent diffusion) & 122.62 & 9.62 & 6.89 & 0.66 & 0.670 \\ DiT-G & 274.69 & 2.27 & 4.58 & 0.82 & 0.58 \\
**DiT-G + ProG** & **278.77** & **2.25** & **4.56** & **0.82** & **0.58** \\   

Table 3: _Combining with the EDS  to solve the gradient vanishing problem, our proposed method helps achieve state-of-the-art on IMAGENET64x64 and IMAGENET128x128. On latent diffusion models such as DiT, we can achieve slightly better performance to reach SOTA on this dataset._

**Correlations between labels**: Fixing the same schedule, we change the initial vector of information degree \(_{T}\) via different ways. We denote our ChatGPT-generated text as CGT. Based on CGT, we use CLIP or Word2Vec to obtain the similarity matrix mentioned in section 3. We compare with the uniform label smoothing (Uni. LS), where the \(_{T}\) is uniformly distributed. We also provide the performance of Label Smoothing without our progressive schedule noted as LS (NO SCHE.) to have a comprehensive understanding of the method. Table 6 shows that the CLIP + CGT performs the best among different schemes. This shows the importance of the initial state of the \(_{T}\), which helps to decide the relevant information for the main condition.

**Computational cost**: Considering the comparable FID/sFID results between ProG and classifier-free guidance, we uncovered several advantages of ProG over classifier-free guidance, as detailed in Section E of the Supplementary. Notably, one of these advantages pertains to computational efficiency. Table 7 illustrates the GPU hours required for generating 50,000 images at a resolution of 256x256. When ProG is incorporated into the standard classifier guidance framework, the computational cost remains on par with vanilla classifier guidance. In contrast, utilizing classifier-free guidance substantially escalates computational expenses. It's worth noting that the computational cost of classifier guidance is predominantly influenced by the architecture of the noise-aware classifier, which is typically simpler than the network architectures used in generative models. Consequently, the observations in Table 7 are broadly applicable in most scenarios.

## 7 Conclusion

This work quantifies two problems of the classifier guidance method: dramatic diversity suppression and non-robustness feature construction. The results show better robustness features than the classifier guidance baseline and a similar level to the classifier-free guidance method. Besides, we also achieve a significantly better diversity trend when increasing the guidance scale quantitatively and qualitatively. We can achieve the SOTA on ImageNet64x64 and ImageNet128x128 on FID/sFID. Our method can be combined with DiT-G  to achieve a new SOTA for ImageNet256x256. Our current research demonstrates successful solutions to address the adversarial effects, particularly in cases where high-confidence generated samples exhibit minimal features relevant to the given condition. However, we acknowledge that we have not yet resolved the scenario where diffusion signals dominate and conflict with the classification signals. The resulting images have low confidence and fail to contain any discernible features related to the specified condition. It is worth noting that these features can no longer be considered adversarial due to low confidence and often be wrongly classified by the pretrained classifier used in the sampling process. Resolving the conflict between diffusion and classification gradients remains an open challenge and an area for future investigation.