# Analyzing and Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization via Steepest Descent in the 1-Norm.

Analyzing and Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization via Steepest Descent in the 1-Norm.

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

We consider minimizing a smooth function subject to a summation constraint over its variables. By exploiting a connection between the greedy 2-coordinate update for this problem and equality-constrained steepest descent in the 1-norm, we give a convergence rate for greedy selection under a proximal Polyak-Lojasiewicz assumption that is faster than random selection and independent of the problem dimension \(n\). We then consider minimizing with both a summation constraint and bound constraints, as arises in the support vector machine dual problem. Existing greedy rules for this setting either guarantee trivial progress only or require \(O(n^{2})\) time to compute. We show that bound- and summation-constrained steepest descent in the L1-norm guarantees more progress per iteration than previous rules and can be computed in only \(O(n n)\) time.

## 1 Introduction

Coordinate descent (CD) is an iterative optimization algorithm that performs a gradient descent step on a single variable at each iteration. CD methods are appealing because they have a convergence rate similar to gradient descent, but for some common objective functions the iterations have a much lower cost. Thus, there is substantial interest in using CD for training machine learning models.

**Unconstrained coordinate descent:** considered CD with random choices of the coordinate to update, and proved non-asymptotic linear convergence rates for strongly-convex functions with Lipschitz-continuous gradients. It was later shown that these linear convergence rates are achieved under a generalization of strong convexity called the Polyak-Lojasiewicz condition . Moreover, greedy selection of the coordinate to update also leads to faster rates than random selection . These faster rates do not depend directly on the dimensionality of the problem due to an equivalence between the greedy coordinate update and steepest descent on all coordinates in the 1-norm. For a discussion of many other problems where we can implement greedy selection rules at similar cost to random rules, see  Sections 2.4-2.5].

**Bound-constrained coordinate descent**: CD is commonly used for optimization with lower and/or upper bounds on each variable.  showed that the unconstrained rates of randomized CD can be achieved under these separable constraints using a projected-gradient update of the coordinate.  generalize this result to include a non-smooth but separable term in the objective function via a proximal-gradient update; this justifies using CD in various constrained and non-smooth settings, including least squares regularized by the 1-norm and support vector machines with regularized bias. Similar to the unconstrained case, show that several forms of greedy coordinate selection lead to faster convergence rates than random selection for problems with bound constraints or separable non-smooth terms.

**Equality-constrained coordinate descent**: many problems in machine learning require us to satisfy an equality constraint. The most common example is that discrete probabilities must sum to one. Another common example is SVMs with an unregularized bias term. The (non-separable) equality constraint cannot be maintained by single-coordinate updates, but it can be maintained if we update two variables at each iteration.Necoara et al. (2011) analyze random selection of the two coordinates to update, whileFang et al. (2018) discuss randomized selection with tighter rates. The LIBSVM packageChang and Lin (2011) uses a greedy 2-coordinate update for fitting SVMs which has the same cost as random selection. But despite LIBSVM being perhaps the most widely-used CD method of all time, current analyses of greedy 2-coordinate updates either result in sublinear convergence rates or do not lead to faster rates than random selection Tseng and Yunl (2009)Beck (2014).

**Our contributions**: we first give a new analysis for the greedy 2-coordinate update for optimizing a smooth function with an equality constraint. The analysis is based on an equivalence between the greedy update and equality-constrained steepest descent in the 1-norm. This leads to a simple dimension-independent analysis of greedy selection showing that it can converge substantially faster than random selection. Next, we consider greedy rules when we have an equality constraint and bound constraints. We argue that the rules used by LIBSVM cannot guarantee non-trivial progress on each step. We analyze a classic greedy rule based on maximizing progress, but this analysis is dimension-dependent and the cost of implementing this rule is \(O(n^{2})\) if we have both lower and upper bounds. Finally, we show that steepest descent in the 1-norm with equalities and bounds guarantees a fast dimension-independent rate and can be implemented in \(O(n n)\). This rule may require updating more than 2 variables, in which case the additional variables can only be moved to their bounds, but this can only happen for a finite number of early iterations.

## 2 Equality-Constrained Greedy 2-Coordinate Updates

We first consider the problem of minimizing a twice-differentiable function \(f\) subject to a simple linear equality constraint,

\[_{x^{n}}f(x),\;_{i=1}^{n}x_{i}=,\] (1)

where \(n\) is the number of variables and \(\) is a constant. On iteration \(k\) the 2-coordinate optimization method chooses a coordinate \(i_{k}\) and a coordinate \(j_{k}\) and updates these two coordinates using

\[x_{i_{k}}^{k+1}=x_{i_{k}}^{k}+^{k}, x_{j_{k}}^{k+1}=x_{j_{k}}^{k}- ^{k},\] (2)

for a scalar \(^{k}\) (the other coordinates are unchanged). We can write this update for all coordinates as

\[x^{k+1}=x^{k}+d^{k},d_{i_{k}}^{k}=^{k},d_{j_{k}}^{k}=- ^{k},d_{m}^{k}=0m\{i_{k},j_{j}\}.\] (3)

If the iterate \(x^{k}\) satisfies the constraint then this update maintains the constraint. In the coordinate gradient descent variant of this update we choose \(^{k}=-}{2}(_{i_{k}}f(x^{k})-_{j_{k}}f(x^{k}))\) for a step size \(_{k}\). This results in an update to \(i_{k}\) and \(j_{k}\) of the form

\[x_{i_{k}}^{k+1}=x_{i_{k}}^{k}-}{2}(_{i_{k}}f(x^{k})- _{j_{k}}f(x^{k})),\;x_{j_{k}}^{k+1}=x_{j_{k}}^{k}-}{2}( _{j_{k}}f(x^{k})-_{i_{k}}f(x^{k})).\] (4)

If \(f\) is continuous, this update is guaranteed to decrease \(f\) for sufficiently small \(^{k}\). The greedy rule chooses the coordinates to update by maximizing the difference in their partial derivatives,

\[i_{k}*{arg\,max}_{i}_{i}f(x^{k}), j_{k} *{arg\,min}_{j}_{j}f(x^{k}).\] (5)

At the solution of the problem we must have partial derivatives being equal, so intuitively this greedy choice updates the coordinates that are furthest above/below the average partial derivative. This choice also minimizes the set of 2-coordinate quadratic approximations to the function (see AppendixA.1)

\[*{arg\,min}_{i,j}\{_{d_{ij}|d_{i}+d_{j}=0}f(x^{k})+ _{ij}f(x^{k})^{T}d_{ij}+}\|d_{ij}\|^{2}\},\] (6)

which is a special case of the Gauss-Southwell-q (GS-q) rule of Tseng and Yunl (2009).

We assume that the gradient of \(f\) is Lipschitz continuous, and our analysis will depend on a quantity we call \(L_{2}\). The quantity \(L_{2}\) bounds the change in the \(2\)-norm of the gradient with respect to any two coordinates \(i\) and \(j\) under a two-coordinate update of any \(x\) of the form 3.

\[\|_{ij}f(x+d)-_{ij}f(x)\|_{2} L_{2}\|d\|_{2}.\] (7)

Note that \(L_{2}\) is less than or equal to the Lipschitz constant of the gradient of \(f\).

### Connections between Greedy 2-Coordinate Updates and the 1-Norm

Our analysis relies on several connections between the greedy update and steepest descent in the 1-norm, which we outline in this section. First, we note that vectors \(d^{k}\) of the form 3 satisfy \(\|d^{k}\|_{1}^{2}=2\|d^{k}\|_{2}^{2}\), since

\[\|d^{k}\|_{1}^{2} =(|^{k}|+|-^{k}|)^{2}\] \[=(^{k})^{2}+(^{k})^{2}+2|^{k}||^{k}|\] \[=4(^{k})^{2}\] \[=2((^{k})^{2}+(-^{k})^{2})\] \[=2\|d^{k}\|_{2}^{2}.\]

Second, if a twice-differentiable function's gradient satisfies the 2-coordinate Lipschitz continuity assumption 1 with constant \(L_{2}\), then the full gradient is Lipschitz continuous in the \(1\)-norm with constant \(L_{1}=L_{2}/2\) (see Appendix B). Finally, we note that applying the 2-coordinate update 4 is an instance of applying steepest descent over all coordinates in the \(1\)-norm. In particular, in Appendix A.2 we show that steepest descent in the \(1\)-norm always admits a greedy 2-coordinate update as a solution.

**Lemma 2.1**.: _Let \(>0\). Then at least one steepest descent direction with respect to the \(1\)-norm has exactly two non-zero coordinates. That is,_

\[_{d^{n}|d^{T}1=0} f(x)^{T}d+||d||_{1}^{ 2}=_{i,j}\{_{d_{ij}^{2}|d_{i}+d_{j}=0}_{ij}f(x )^{T}d_{ij}+||d_{ij}||_{1}^{2}\}.\] (8)

This lemma allows us to equate the progress of greedy 2-coordinate updates to the progress made by a full-coordinate steepest descent step descent step in the 1-norm.

### Proximal-PL Inequality in the 1-Norm

For lower bounding sub-optimality in terms of the 1-norm, we introduce the proximal-PL inequality in the 1-norm. The proximal-PL condition was introduced to allow simpler proofs for various constrained and non-smooth optimization problems . The proximal-PL condition is normally defined based on the \(2\)-norm, but we define a variant for the summation-constrained problem where distances are measured in the \(1\)-norm.

**Definition 2.2**.: A function \(f\), that is \(L_{1}\)-Lipschitz with respect to the \(1\)-norm and has a summmation constraint on its parameters, satisfies the proximal-PL condition in the \(1\)-norm if for a positive constants \(_{1}\) we have

\[(x,L_{1})_{1}(f(x)-f^{*}),\] (9)

for all \(x\) satisfying the equality constraint. Here, \(f^{*}\) is the constrained optimal function value and

\[(x,L)=-2L_{\{y y^{T}1=\}}[ f(x),y-x +||y-x||_{1}^{2}].\] (10)

It follows from the equivalence between norms that summation-constrained functions satisfying the proximal-PL condition in the 2-norm will also satisfy the above proximal-PL condition in the 1-norm. In particular, if \(_{2}\) is the proximal-PL constant in the \(2\)-norm, then we have \(}{}_{1}_{2}\) (see Appendix C). Functions satisfying these conditions include any strongly-convex function \(f\) as well as relaxations of strong convexity, such as functions of the form \(f=g(Ax)\) for a strongly-convex \(g\) and a matrix \(A\). In the \(g(Ax)\) case \(f\) is not strongly-convex if \(A\) is singular, and we note that the SVM dual problem can be written in the form \(g(Ax)\).

### Convergence Rate of Greedy 2-Coordinate Updates under Proximal-PL

We analyze the greedy 2-coordinate method under the proximal-PL condition based on the connections to steepest descent in the 1-norm.

**Theorem 2.3**.: _Let \(f\) be a twice-differentiable function whose gradient is 2-coordinate-wise Lipschitz \(}\) and restricted to the set where \(x^{T}1=\). If this function satisfies the proximal-PL inequality in the 1-norm \(\) for some positive \(_{1}\), then the iterations of the 2-coordinate update \(\) with \(^{k}=1/L_{2}\) and the greedy rule \(\) satisfy:_

\[f(x^{k})-f(x^{*})(1-}{L_{2}})^{k}(f(x^{0})-f^{*}).\] (11)

Proof.: Starting from the descent lemma restricted to the coordinates \(i_{k}\) and \(j_{k}\) we have

\[f(x^{k+1})  f(x^{k})+_{i_{k}j_{k}}f(x^{k})^{T}d_{i_{k}j_{k}}+ {L_{2}}{2}\|d_{i_{k}j_{k}}\|^{2}\] \[=f(x^{k})+_{i,j}\{_{d_{i_{j}} ^{2}\\ d_{i}+d_{j}=0}_{ij}f(x^{k})^{T}d_{ij}+}{2}\|d_ {ij}\|^{2}\} ()\] \[=f(x^{k})+_{i,j}\{_{d_{i_{j}} ^{2}\\ d_{i}+d_{j}=0}_{ij}f(x^{k})^{T}d_{ij}+}{4}\|d_ {ij}\|_{1}^{2}\} (\|d\|_{1}^{2}=2\|d\|^{2})\] \[=f(x^{k})+_{i,j}\{_{d_{i_{j}} ^{2}\\ d_{i}+d_{j}=0}_{ij}f(x^{k})^{T}d_{ij}+}{2}\|d_ {ij}\|_{1}^{2}\} (L_{1}=L_{2}/2)\] \[=f(x^{k})+_{d|d^{T}1=0}\{ f(x^{k})^{T}d+}{2}\|d\|_{1}^{2}\} ().\]

Now subtracting \(f^{*}\) from both sides and using the definition of \(\) from the proximal-PL assumption,

\[f(x^{k+1})-f(x^{*})  f(x^{k})-f(x^{*})-}(x^{k},L_{1})\] \[=f(x^{k})-f(x^{*})-}{L_{1}}(f(x^{k})-f^{*})\] \[=f(x^{k})-f(x^{*})-}{L_{2}}(f(x^{k})-f^{*})\] \[=(1-}{L_{2}})(f(x^{k})-f^{*})\]

Applying the inequality recursively completes the proof. 

Note that the above rate also holds if we choose \(^{k}\) to maximally decrease \(f\), and the same rate holds up to a constant if we use a backtracking line search to set \(^{k}\).

### Comparison to Randomized Selection

If we sample the two coordinates \(i_{k}\) and \(j_{k}\) from a uniform distribution, then it is known that the 2-coordinate descent method satisfies She and Schmid (2017)

\[[f(x^{k})]-f(x^{*})(1-}{n^{2}L_{2}})^{k }(f(x^{0})-f^{*}).\] (12)

A similar result for a more-general problem class was shown by Necoara and Patrascu (2014). This is substantially slower than the rate we show for the greedy 2-coordinate descent method. This rate is slower even in the extreme case where \(_{1}\) is similar to \(_{2}/n\), due to the presence of the \(n^{2}\) term.

There also exist analyses for cyclic selection in the equality-constrained case but existing rates for cyclic rules are slower than the random ratesWang and Lin (2014).

In the case where \(f\) is a dense quadratic function of \(n\) variables, which includes SVMs under the most popular kernels, both random selection and greedy selection cost \(O(n)\) per iteration to implement. If we consider the time required to reach an accuracy of \(\) under random selection using the rate 12 we obtain \(O(n^{3}(1/))\) where \(=L_{2}/_{2}\). While for greedy selection under 11 it is between \(O(n^{2}(1/))\) if \(_{1}\) is close to \(_{2}/n\) and \(O(n(1/))\) if \(_{1}\) is close to \(_{2}\). Thus, the reduction in total time complexity from using the greedy method is between a factor of \(O(n)\) and \(O(n^{2})\). This is a large difference which has not been reflected in previous analyses.

There exist faster rates than 12 in the literature, but these require additional assumptions such as \(f\) being separable or that we know the coordinate-wise Lipschitz constantsNecoara et al. (2011)Necoara and Patrascu (2014)Necoara et al. (2017)Fang et al. (2018). However, these assumptions restrict the applicability of the results. Further, unlike convergence rates for random coordinate selection, we note that the new linear convergence rate 11 for greedy 2-coordinate method avoids requiring a direct dependence on the problem dimension. The only previous dimension-independent convergence rate for the greedy 2-coordinate method that we are aware of is due to Beck (2014)Theorem 5.2b]. Their work considers functions that are bounded below, which is a weaker assumption than the proximal-PL assumption. However, this only leads to sublinear convergence rates and only on a measure of the violation in the Karush-Kuhn-Tucker conditions. Beck (2014)Theorem 6.2] also gives convergence rates in terms of function values for the special case of convex functions, but these rates are sublinear and dimension dependent.

## 3 Equality- and Bound-Constrained Greedy Coordinate Updates

Equality constraints often appear alongside lower and/or upper bounds on the values of the individual variables. This results in problems of the form

\[_{x^{n}}f(x),\;_{i=1}^{n}x_{i}=, \;l_{i} x_{i} u_{i}.\] (13)

This framework includes our motivating problems of optimizing over the probability simplex (\(l_{i}=0\) for all \(i\) since probabilites are non-negative), and optimizing SVMs with an unregularized bias (where we have lower and upper bounds). With bound constraints we use a \(d^{k}\) of form 3 but where \(^{k}\) is defined so that the step respects the constraints,

\[^{k}=-}{2}(_{i_{k}}f(x^{k})-_{j_ {k}}f(x^{k})),x_{i_{k}}^{k}-l_{i_{k}},u_{j_{k}}-x_{j_{k}}^{k}},\] (14)

Unfortunately, analyzing the bound-constrained case is more complicated. There are several possible generalizations of the greedy rule for choosing the coordinates \(i_{k}\) and \(j_{k}\) to update, depending on what properties of 3 we want to preserve (seeNutin (2018)Section 2.7). In this section we discuss several possibilities, and how the choice of greedy rule affects the convergence rate and iteration cost.

### GS-s: Minimizing Directional Derivative

Up until version 2.7, the greedy rule used in LIBSVM was the Gauss-Southwell-s (GS-s) rule. The GS-s rule chooses the coordinates resulting in the \(d^{k}\) with the most-negative directional derivative. This is a natural generalization of the idea of steepest descent, and the first uses of the method that we aware of are byKeerthi et al. (2001) for SVMs and byShevade and Keerthi (2003) for 1-norm regularized optimization. For problem 13 the GS-s rule chooses

\[i_{k}*{arg\,max}_{i\;|\;x_{i}^{k}>l_{i}}_{i}f(x^{k}),  j_{k}*{arg\,min}_{j\;|\;x_{j}^{k}<u_{i}}_{j}f(x^{k}).\] (15)

This is similar to the unbounded greedy rule 3 but excludes variables where the update would immediately violate a bound constraint.

Unfortunately, the per-iteration decrease in \(f\) obtained by the GS-s rule can be arbitrarily small. In particular, consider the case where the variable \(i\) maximizing \(_{i}f(x^{k})\) has a value of \(x_{i}^{k}=l_{i}+\) for an arbitrarily small \(\). In this case, we would choose \(i_{k}\) and take an arbitrarily small step of \(^{k}=\). Steps like this that truncate \(^{k}\) are called "bad" steps, and the GS-s rule does not guarantee a non-trivial decrease in \(f\) on bad steps. If we only have bound constraints and do not have an equality constraint (so we can update on variable at a time),  show that at most half of the steps are bad steps. Their argument is that after we have taken a bad step on coordinate \(i\), then the next time \(i\) is chosen we will not take a bad step. However, with an equality constraint it is possible for a coordinate to be involved in consecutive bad steps. It is possible that a combinatorial argument similar to  Theorem 8] could bound the number of bad steps, but it is not obvious that we do not require an exponential total number of bad steps.

### GS-q: Minimum 2-Coordinate Approximation

A variant of the Gauss-Southwell-q (GS-q) rule of  for problem 1.3 is

\[*{arg\,min}_{i,j}_{d_{ij}|d_{i}+d_{j}=0}\{f(x^{k})+ _{ij}f(x^{k})^{T}d_{ij}+}\|d_{ij}\|^{2}:x^{k}+d[l,u]\}.\] (16)

This minimizes a quadratic approximation to the function, restricted to the feasible set. For problem 1.3, the GS-q rule is equivalent to choosing \(i_{k}\) and \(j_{k}\) to maximize 1.3, the distance that we move. We show the following result for the GS-q rule in Appendix D.

**Theorem 3.1**.: _Let \(f\) be a differentiable function whose gradient is 2-coordinate-wise Lipschitz 1.3 and restricted to the set where \(x^{T}1=\) and \(l_{i} x_{i} u_{i}\). If this function satisfies the proximal-PL inequality in the 2-norm  for some positive \(_{2}\), then the iterations of the 2-coordinate update 1.3 with \(^{k}\) given by , \(^{k}=1/L_{2}\), and the greedy GS-q rule 1.3 satisfy:_

\[f(x^{k})-f(x^{*})(1-}{L_{2}(n-1)})^{k}(f(x^{0})-f^ {*}).\] (17)

The proof of this result is more complicated than our previous results, relying on the concept of conformal realizations used by . We prove the result for general block sizes and then specialize to the two-coordinate case. Unlike the GS-s rule, this result shows that the GS-q guarantees non-trivial progress on each iteration. Note that while this result does have a dependence on the dimension \(n\), it does not depend on \(n^{2}\) as the random rate 1.3 does. Moreover, the dependence on \(n\) can be improved by increasing the block size.

Unfortunately, the GS-q rule is not always efficient to use. As discussed by , there is no known algorithm faster than \(O(n^{2})\) for computing the GS-q rule 1.3. One special case where this can be solved in \(O(n)\) given the gradient is if we only have lower bounds (or only have upper bounds) . An example with only lower bounds is our motivating problem of optimizing over the probability simplex, which only requires variables to be non-negative and sum to 1. On the other hand, our other motivating problem of SVMs requires lower and upper bounds so computing the GS-q rule would require \(O(n^{2})\). Beginning with version 2.8, LIBSVM began using an approximation to the GS-q rule that can be computed in \(O(n)\). In particular, LIBSVM first chooses one coordinate using the GS-s rule, and then optimizes the other coordinate according to a variant of the GS-q rule  while other rules have been proposed, the LIBSVM rule remains among the best-performing methods in practice . However, similar to the GS-s rule we cannot guarantee non-trivial progress for the practical variant of the GS-q rule used by LIBSVM.

### GS-1: Steepest Descent in the 1-Norm

Rather than using the classic GS-s or GS-q selection rules, the Gauss-Southwell-1 (GS-1) rule performs steepest descent in the 1-norm. For problem 1.3 this gives the update

\[d^{k}*{arg\,min}_{l_{i} x_{i}+d_{i} u_{i}|d^{T}1=0} \{ f(x^{k})^{T}d+}||d||_{1}^{2}\}.\] (18)

The GS-1 rule was proposed by  for (unconstrained) 1-norm regularized problems. To analyze this method, we modify the definition of \((x,L)\) in the proximal-PL assumption to be

\[(x,L)=-2L_{\{l_{i} y_{i} u_{i} y^{T}1=\}} \{ f(x),y-x+||y-x||_{1}^{2}\}.\] (19)

We then have the following dimension-independent convergence rate for the GS-1 rule.

**Theorem 3.2**.: _Let \(f\) be a differentiable function whose gradient is 2-coordinate-wise Lipschitz 2 and restricted to the set where \(x^{T}1=\) and \(l_{i} x_{i} u_{i}\). If this function satisfies the proximal-PL inequality in the 1-norm 3 for some positive \(}\) with the definition 19, then the iterations of the update \(x^{k+1}=x^{k}+d^{k}\) with the greedy rule 18 and \(_{k}=1/L_{1}=_{2}\) satisfy:_

\[f(x^{k})-f(x^{*})(1-}{L_{2}})^{k}(f(x^{0})-f^{*}).\] (20)

Proof.: The proof follows the same reasoning as Theorem2.3 but beginning after the application of Lemma2.1 since we are directly computing the steepest descent direction. 

This GS-1 convergence rate is at least as fast as the convergence rate for GS-q, and thus by exploiting a connection to the 1-norm we once again obtain a faster dimension-independent rate. In Algorithm1 we give a method to construct a solution to the GS-1 rule 18 in \(O(n n)\) time (due to sorting the \(_{i}f(x^{k})\) values). Thus, our new GS-1 update guarantees non-trivial progress at each step (unlike the GS-s rule) and is efficient to compute (unlike the GS-q rule). The precise logic of Algorithm1 is somewhat complicated, but it can intuitively be viewed as a version of GS-s that fixes the bad steps where \(^{k}\) is truncated. Roughly, if the GS-s rule gives a bad step then the GS-1 moves the violating variable to its boundary and then may also update the variable with the next largest/smallest \(_{i}f(x^{k})\).

The drawback of the GS-1 update is that it is not strictly a 2-coordinate method. While the GS-1 update moves at most 2 variables within the interior of the bound constraints, it may move additional variables to their boundary. The iteration cost of the method will be higher on iterations where more than 2 variables are updated. However, by using an argument similar toSun et al.(2019), we can show that the GS-1 rule will only update more than 2 variables on a finite number of early iterations. This is because, after some finite number of iterations, the variables actively constrained by their bounds will remain at their bounds. At this point, each GS-1 update will only update 2 variables within theinterior of the bounds. In the case of SVMs, moving a variable to its lower bound corresponds to removing it as a potential support vector. Thus, this "bug" of GS-1 that it may update more than 2 variables can allow it to quickly remove many support vectors. In our experiments, we found that GS-1 identified the support vectors more quickly than other rules and that most GS-1 updates only updated 2 or 3 coordinates.

## 4 Greedy Updates using Coordinate-Wise Lipschitz Constants

Up until this point, we have measured smoothness based on the maximum blockwise Lipschitz-constant \(L_{2}\). An alternative measure of smoothness is Lipschitz continuity of individual coordinates. In particular, coordinate-wise Lipschitzness of coordinate \(i\) requires that for all \(x\) and \(\)

\[|_{i}f(x+ e_{i})-_{i}f(x)| L_{i}||,\]

where \(e_{i}\) is a vector with a one in position \(i\) and zeros in all other positions. For twice-differentiable convex functions, the Lipschitz constant with respect to the block \((i,j)\) is upper bounded by the sum of the coordinate-wise constants \(L_{i}\) and \(L_{j}\) Lemma 1. For equality-constrained optimization,  uses the coordinate-wise Lipschitz constants to design sampling distributions for \(i_{k}\) and \(j_{k}\). Their analysis gives rates that can be faster than uniform sampling .

In AppendixE we consider greedy rules that depend on the \(L_{i}\) values for the equality-constrained case. In particular, we show that the equality-constrained GS-q rule chooses \(i_{k}\) and \(j_{k}\) by solving

\[*{arg\,max}_{i,j}\{f(x)-_{j}f(x))^{2 }}{L_{i}+L_{j}}\},\] (21)

which yields the standard greedy rule 5 if all \(L_{i}\) values are equal. We show that the coordinate descent update with this selection rule and

\[^{k}=-(_{i_{k}}f(x^{k})-_{j_{k}}f(x^{k}))/(L_{i_{k}}+L_{j_{k }}),\] (22)

can be written as steepest descent in the norm defined by \(||d||_{L}_{i}}|d_{i}|\). This yields a convergence rate that can be faster than the greedy rate 11.

Unfortunately, it is not obvious how to solve 21 faster than \(O(n^{2})\). Nevertheless a reasonable approximation is to use

\[i_{k}*{arg\,max}_{i}_{i}f(x^{k})/}, j_{ k}*{arg\,min}_{j}_{j}f(x^{k})/}.\] (23)

which we call the ratio approximation. This approximation is 21 after re-parameterizing in terms of variables \(x_{i}/}\) so that all coordinate-wise Lipschitz constants are 1 in the transformed problem. We can also use this re-parameterization to implement variations of the GS-s/GS-q/GS-1 rules if we also have bound constraints. While the ratio approximation 23 performed nearly as well as the more expensive 21 in our experiments, we found that the gap could be improved slightly if we choose one coordinate according to the ratio approximation and then the second coordinate to optimize 211.

## 5 Experiments

Our first experiment evaluates the performance of various rules on a synthetic equality-constrained least squares problem. Specifically, the objective is \(f(x)=||Ax-b||^{2}\) subject to \(x^{T}1=0\). We generate the elements of \(A^{1000 1000}\) from a standard normal and set \(b=Ax+z\) where \(x\) and \(z\) are generated from standard normal distributions. We also consider a variant where each column of \(A\) is scaled by a sample from a standard normal to induce very-different \(L_{i}\) values. In Figure1 we compare several selection rules: random \(i_{k}\) and \(j_{k}\), the greedy rule 5, sampling \(i_{k}\) and \(j_{k}\) proportional to \(L_{i}\), the exact greedy \(L_{i}\) rule 21, the ratio greedy \(L_{i}\) rule 23, and a variant where we set one coordinate using 23 and other using 21 (switching between the two). All algorithms use the update 22. In these experiments we see that greedy rules lead to faster convergence than random rules in all cases. We see that knowing the \(L_{i}\) values does not significantly change the performance of the random method, nor does it change the performance of the greedy methods in the case when the \(L_{i}\) were similar. However, with different \(L_{i}\) the (expensive) exact greedy method exploiting \(L_{i}\) works much better. We found that the ratio method worked similar to or better than the basic greedy method (depending on the random seed), while the switching method often performed closer to the exact method.

Our second experiment considers the same problem but with the additional constraints \(x_{i}[-1,1]\). Figure2 compares the GS-s, GS-q, and GS-1 rules in this setting. We see that the GS-s rule results in the slowest convergence rate, while the GS-q rule rule takes the longest to identify the active set. The GS-1 rule typically updates 2 or 3 variables, but on early iterations it updates up to 5 variables.

## 6 Discussion

Despite the popularity of LIBSVM, up until this work we did not have a strong justification for using greedy 2-coordinate methods over simpler random 2-coordinate methods for equality-constrained optimization methods. This work shows that greedy methods may be faster by a factor ranging from \(O(n)\) up to \(O(n^{2})\). This work is the first to identify the equivalence between the greedy 2-coordinate update and steepest descent in the 1-norm. The connection to the 1-norm is key to our simple analyses and also allows us to analyze greedy rules depending on coordinate-wise Lipschitz constants.

For problems with bound constraints and equality constraints, we analyzed the classic GS-q rule but also proposed the new GS-1 rule. Unlike the GS-s rule the GS-1 rule guarantees non-trivial progress on each iteration, and unlike the GS-q rule the GS-1 rule can be implemented in \(O(n n)\). We further expect that the GS-1 rule could be implemented in \(O(n)\) by using randomized algorithms, similar to the techniques used to implement \(O(n)\)-time projection onto the 1-norm ball(Duchi et al., 2008; van den Berg et al., 2008). The disadvantage of the GS-1 rule is that on some iterations it may update more than 2 coordinates on each step. However, when this happens the additional coordinates are simply moved to their bound. This can allow us to identify the active set of constraints more quickly. For SVMs this means identifying the support vectors faster, giving cheaper iterations.

Figure 1: Random vs greedy coordinate selection rules, including rules using the coordinate-wise Lipschitz constants \(L_{i}\). The \(L_{i}\) are similar in the left plot, but differ significantly on the right.

Figure 2: Comparison of GS-1, GS-q and GS-s under linear equality constraint and bound constraints. The left plot shows the function values, the middle plot shows the number of interior variables, and the right plot shows the number of variables updated by the GS-1 rule.