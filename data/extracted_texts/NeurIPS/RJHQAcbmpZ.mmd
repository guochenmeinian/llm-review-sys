# A survey and benchmark of high-dimensional Bayesian optimization of discrete sequences

Miguel Gonzalez-Duque

University of Copenhagen

&Simon Bartels

Paul Sabatier University Toulouse

&Richard Michael

University of Copenhagen

&Soren Hauberg

Technical University of Denmark

&Voveen Zainchkovskyy

Technical University of Denmark

&Souer Boomsma

University of Copenhagen

emails: miguelgondu@gmail.com, sohau@dtu.dk, wb@di.ku.dk

###### Abstract

Optimizing discrete black box functions is key in several domains, e.g. protein engineering and drug design. Due to the lack of gradient information and the need for sample efficiency, Bayesian optimization is an ideal candidate for these tasks. Several methods for high-dimensional continuous and categorical Bayesian optimization have been proposed recently. However, our survey of the field reveals highly heterogeneous experimental set-ups across methods and technical barriers for the replicability and application of published algorithms to real-world tasks. To address these issues, we develop a unified framework to test a vast array of high-dimensional Bayesian optimization methods and a collection of standardized black box functions representing real-world application domains in chemistry and biology. These two components of the benchmark are each supported by flexible, scalable, and easily extendable software libraries (poli and poli-baselines), allowing practitioners to readily incorporate new optimization objectives or discrete optimizers. Project website: https://machinelearninglifiescience.github.io/hdbo_benchmark.

## 1 Introduction

Optimizing an unknown and expensive-to-evaluate function is a frequent problem across disciplines (Shahriari et al., 2016), examples are finding the right parameters for machine learning models or simulators, drug discovery (Gomez-Bombarelli et al., 2018; Griffiths and Hernandez-Lobato, 2020; Pyzer-Knapp, 2018), protein design (Stanton et al., 2022; Gruver et al., 2023), hyperparameter tuning in Machine Learning (Snoek et al., 2012; Turner et al., 2021) and train scheduling. In some scenarios, evaluating the black box involves an expensive process (e.g. training a large model, or running a physical simulation); Bayesian Optimization (BO, Mockus (1975)) is a powerful method for sample efficient black box optimization. High dimensional (discrete) problems have long been identified as a key challenge for Bayesian optimization algorithms (Wang et al., 2013; Snoek et al., 2012) given that they tend to scale poorly with both dataset size and dimensionality of the input.

High-dimensional BO has been the focus of an entire research field (see Fig. 1), in which methods are extended to address the curse of dimensionality and its consequences (Binois and Wycoff, 2022; Santoni et al., 2023). Within this setting, discrete sequence optimization has received particular focus,due to its applicability in the optimization of molecules and proteins. However, prior work often focuses on sequence lengths and number of categories below the hundreds (see Fig. 2), making it difficult for practitioners to judge expected performance on real-world problems in these domains. We contribute (i) a survey of the field while focusing on the real-world applications of high-dimensional discrete sequences, (ii) a benchmark of several optimizers on established black boxes, and (iii) an open source, unified interface: poli and poli-baselines.2

## 2 Preliminaries

Bayesian Optimization and Gaussian processes.Bayesian optimization requires a surrogate model and an acquisition function (Garnett, 2023). Given both, the objective function is sequentially optimized by fitting a model to the given observations and numerically optimizing the acquisition function with respect to the model to select the next configuration for evaluation. Frequently, the model is a Gaussian process (GP, Rasmussen and Williams (2006)), and popular choices for the acquisition function are _Expected Improvement_(Jones et al., 1998; Garnett, 2023) and the _Upper Confidence Bound_(Srinivas et al., 2012). A GP allows to express a prior belief over functions.

Figure 1: A timeline of high-dimensional Bayesian optimization methods, with arrows drawn between methods that explicitly augment or use each other. References can be found in supplementary Table 4. The figure is inspired by Justesen et al. (2020). An interactive version can be found in our project page.

Formally, it is a collection of random variables, such that every finite subset follows a multivariate normal distribution, described by a mean function \(\), and a positive definite covariance function (kernel) (Rasmussen and Williams, 2006, p. 13). Assuming that observations of the function are distorted by Gaussian noise, the posterior over the function conditioned on these observations is again Gaussian. The prediction equations have a closed form and can be evaluated in \((N^{3})\) time where \(N\) is the number of observations.

Is high-dimensional Bayesian Optimization difficult?There are three reasons why BO is thought to scale poorly with dimension. The first reason is that GPs fail to properly fit to the underlying objective function in high dimensions. Secondly, even if the GPs were to fit well there is still the problem of optimizing the high-dimensional acquisition function. Finally, Gaussian Processes are believed to scale poorly with the size of the dataset, limiting us to low-budget scenarios (Binois and Wycoff, 2022). Folk knowledge suggests that GPs fail to fit functions above the meager limit of \( 10^{1}\) dimensions (Santoni et al., 2023) and \( 10^{4}\) datapoints.

Hvarfner et al. (2024) recently disputed these well-entrenched narratives by showing that poor GP fitting could be caused by a poor choice of regularizer; mitigating the curse of dimensionality could be as easy as including a dimensionality-dependent prior over lengthscales. Furthermore, Xu and Zhe (2024) argues that even the simplest BO outperforms highly elaborate methods.

Optimization of discrete sequences & applicationsMost HDBO methods are tested on toy examples, hyperparameter tuning, or reinforcement learning tasks (Binois and Wycoff, 2022; Penubothula et al., 2021). We focus on discrete sequence optimization, which has several applications beyond the usual examples (e.g. MaxSAT, or PestControl) (Papenmeier et al., 2024), and is key in applications to biology and bioinformatics (Gomez-Bombarelli et al., 2018; Stanton et al., 2022; Gruver et al., 2023). Drug design and protein engineering can be thought of as sequence optimization problems, if we consider the SMILES/SELFIES representation of small molecules (Weininger, 1988; Krenn et al., 2020), or the amino acid sequence representation of proteins (Needleman and Wunsch, 1970).

Related workBinois and Wycoff (2022) initially surveyed the field of high-dimensional GPs, focusing on applications to BO, and proposed a taxonomy of structural assumptions for GPs that includes _variable selection_, _additive models_, _linear_, and _non-linear embeddings_. This work has since been updated by Wang et al. (2023) and Santoni et al. (2023). The latter presents an empirical study on the continuous, toy-problem setting up to 60 dimensions and refines the taxonomy (Binois and Wycoff, 2022) into five categories, separating _trust regions_ from the rest. Griffiths et al. (2023) compare different kernel functions used with binary vector representations of molecules and for the same application Kristiadi et al. (2024) study the use of different large language models. Our work is most similar to Dreczkowski et al. (2023)'s comprehensive overview of discrete BO (MCBD), and Gao et al. (2022)'s benchmark of small molecule optimization. In both, HDBO is not in focus.

Figure 2: Existing BO methods tackle problems with insufficiently low effective dimensions. This figure shows sequence length and nr. of categories of the highest search space in the original tests. For reference, the discrete optimization problems usually tackled by practitioners in chemistry and biology are of the order of \(10^{2}\) in sequence length, and \(>10^{1}\) in nr. of categories. Methods that optimize directly in discrete space (e.g. BODi, ProbRep, Bounce; Sec. 3.7) are tested in lower sequence lengths and dictionary sizes; methods that rely on unsupervised information (e.g. LaMBO, etc.; Sec. 3.5) are able to optimize more complex problems, like protein engineering or small molecule optimization.

A taxonomy of high-dimensional Bayesian Optimization

We describe the field of high dimensional BO and the large number of related publications through a refined taxonomy building on previous work, discussing _variable selection_, _additive models_, _trust regions_, _linear embeddings_, _non-linear embeddings_, _gradient information_, _structured spaces_, and others in turn. While encompassing taxonomies over fields may initially appear ill-advised (Wilkins, 1668, pp.22), we highlight commonalities in strategies that give structure to the HDBO problem-space.

We expand previous surveys (Binois and Wycoff, 2022; Santoni et al., 2023) and identify a finer taxonomy of seven method groups and new families of _structured spaces_ (i.e. methods that work directly on mixed representations, or Riemannian manifolds, previously categorized as _non-linear embeddings_), and methods that rely on predicted _gradient information_. This new separation emphasizes the heterogeneous nature of discrete solvers: some optimizers work directly on discrete space (_structured spaces_), while others optimize using latent representations (_non-linear embeddings_); gradient-based methods are separated to show alternatives when first-order information is available or modelable. Fig. 1 presents a timeline of HDBO methods, split into these families, and all methods are detailed in supplementary Table 4; methods are grouped according to their most dominant feature.

### Variable selection

To solve a high-dimensional problem, one approach is to focus on a subset of variables of high interest.3 One selects the variables either by using domain expertise, or by Automatic Relevance Detection (ARD) (Rasmussen and Williams, 2006, pp.106-107) i.e. large lengthscales indicate independence under the covariance matrix for GPs. Examples of this approach include Hierarchical Diagonal Sampling (HDS) (Chen et al., 2012) and the Dimension Scheduling Algorithm (DSA) (Ulmasov et al., 2016). The former determines the active variables by a binary tree of subsets of \(\{1,,D\}\), and fits GPs in lower-dimensional projections. DSA constructs a probability distribution by the principal directions of the training inputs \(\{(_{n},y_{n})\}_{n=1}^{N}\) and subsamples the dimensions accordingly. In contrast Li et al. (2018) randomly sample subsets of active dimensions.

Other methods rely on placing priors on their lengthscales, followed by a Bayesian treatment of the training. In Sequential Optimization of Locally Important Directions (SOLID), lengthscales are weighted by a Bernoulli distributed parameter, and coordinates are removed when their posterior probability goes below a user-specified threshold. (Winkel et al., 2021). Eriksson and Jankowiak (2021) consider the Sparse Axis-Aligned Subspace (SAAS) model of a GP, restricting the function space through a (long-tailed) half-Cauchy prior on the inverse-lengthscales of the kernel.

### Additive models

Additive models assume that the objective function \(f\) can be decomposed into a sum of lower-dimensional functions. Symbolically, the coordinates of a given input \(=(x_{1},,x_{D})\) are split into \(M\) usually disjoint subgroups \(g_{1}, g_{M}\) of smaller size, called a decomposition. Instead of fitting a GP to \(D\) variables in \(f\), the algorithm fits \(M\) GPs to the restrictions \(f|_{g_{1}}, f|_{g_{M}}\) and adds their Upper Confidence Bound. The differences between the algorithms in this family are on how the subgroups are constructed, how the additive structure is approximated, the training of the Gaussian Process, or leveraging special features (Mutny and Krause, 2018).

Han et al. (2021) select the decomposition which maximizes the marginal likelihood from a collection of randomly sampled decompositions, updating it every certain number of iterations. Alternatives include: leveraging a generalization based on restricted projections (Li et al., 2016), discovering the additive structure using model selection and Markov Chain Monte Carlo (Gardner et al., 2017), considering overlapping groups (Rolland et al., 2018), ensembles of Mondrian space-tiling trees (Wang et al., 2018), or use random tree-based decompositions (Ziomek and Bou Ammar, 2023).

### Trust regions

Some BO algorithms restrict the evaluation of the acquisition function to a small region of input space called a _trust region_, which is centered at the incumbent and is dynamically contracted or expanded according to performance (Regis, 2016; Pedrielli and Ng, 2016; Eriksson et al., 2019).

Contemporary variants extend to the multivariate setting (e.g. MORBO (Daulton et al., 2022)), to quality-diversity (Maus et al., 2023) and to the optimization of mixed variables (CASMOPOLITAN by Wan et al. (2021)), including categorical. Since the trust region framework involves only the optimization of the acquisition function, several other methods leverage it alongside other structural assumptions like linear/non-linear embeddings (e.g. Tripp et al. (2020); Papenmeier et al. (2022)).

### Linear embeddings

Instead of optimizing directly in input space \(^{D}\), several methods rely on optimizing in a lower-dimensional space \(^{d}\), which is linearly embedded into data space using a linear transformation \(A^{D d}\)(Wang et al., 2016). The matrix \(A\) can be either selected at random (Wang et al., 2016; Qian et al., 2016), computed as a low-rank approximation of the input data matrix (Djolonga et al., 2013; Zhang et al., 2019; Raponi et al., 2020), constructed using gradient information and active subspaces (Palar and Shimoyama, 2017; Wycoff et al., 2021), or through the minimization of variance estimates (Hu et al., 2024).

These methods are limited by how low-dimensional exploration translates into high dimensions. One choice of embedding matrix \(A\) spans a _fixed_, highly-restricted subspace of \(^{D}\). For this approach several issues regarding back-projections need to be addressed. Indeed, projecting from bounded domains \(^{d}\) to \(^{D}\) might render points outside the bounded domain in the input (Binois and Wycoff, 2022). Finally, the transformation \(A\) is not injective, meaning a point in input space can correspond to several latent points (Binois et al., 2015; Moriconi et al., 2020).

Binois et al. (2015) propose a kernel that alleviates these issues by including a back-projection to the bounded domain that respects distances in the embedded space. _Hashing matrices_\(S^{D d}\) are an alternative way to reconstruct an input data point in a bounded domain \([-1,1]^{D}^{D}\) from a latent point \(^{D}\), whose entries are either 0, 1, and -1. Thus, the result of multiplying \(S\) is a linear combination of the coordinates of \(\) where the coefficients are 1 and -1 (Nayebi et al., 2019). These ideas have been combined with trust regions both in the continuous (Papenmeier et al., 2022) and mixed-variable settings (Papenmeier et al., 2024). A natural extension considers a family of nested subspaces, progressively growing the embedding matrix until it matches the input dimensionality (Papenmeier et al., 2022). An alternative that does not deal with reconstruction mappings (thus circumventing the aforementioned issues) uses the information learned in the lower dimensional space to perform optimization directly in input space (Horiguchi et al., 2022).

### Non-linear embeddings

Several methods have considered non-linear embeddings to incorporate learned latent representations. One set of examples are deep latent variable models like Generative Adversarial Networks (Goodfellow et al., 2014), or variants of Autoencoders (Kingma and Welling, 2014; Stanton et al., 2022; Maus et al., 2022), algorithms that allow for modelling arbitrarily structured inputs. This is highly relevant for optimizing sequences, which are modeled as samples from a categorical distribution.

Gomez-Bombarelli et al. (2018) pioneered latent space optimization (LSBO) by learning a latent space of small molecules through their SMILES representation using a Variational Autoencoder (VAE, Kingma and Welling (2014); Rezende et al. (2014)), and optimizing metrics such as the qualitative estimate of druglikeness (QED) therein. Several approaches have followed, including usage of _a-priori_ given labelled data (Eissman et al., 2018) or decoder uncertainty (Notin et al., 2021), smart retraining schemes that focus on promising points (Tripp et al., 2020), metric-learning approaches that match promising points together (Grosnit et al., 2021), constraining the latent space (Griffiths and Hernandez-Lobato, 2020), latent spaces mapping to graphs (Kusner et al., 2017; Jin et al., 2018) and jointly learning the surrogate model and the latent representation (Maus et al., 2022; Lee et al., 2023; Chen et al., 2024; Kong et al., 2024). Stanton et al. (2022) take this further by learning multiple representations: one shared and required for both the decoder and surrogate, and one discriminative encoding as input for a GP used in the acquisition function. A prerequisite for these methods is a large dataset of _unsupervised_ inputs, which may not be available in all applications. The methods that rely on training both the representation and the regression at the same time need _supervised_ labels, which may be potentially unavailable. Optimization in embedding spaces greatly increases the complexity of problems that can be tackled, making it an appealing alternative for discrete sequence optimization in real-world tasks (see Fig. 2).

### Gradient information

High-dimensional problems can become significantly easier when derivative information is available. Even when the objective's derivatives are not available, the gradient information from the surrogate model can guide exploration. In our case, the referenced approaches cannot be applied directly, as they assume a differentiable kernel. For methods that rely on a continuous latent representation (see Secs. 3.4 and 3.5), gradient information of the surrogate model in latent space can be used.

Ahmed et al. (2016) mention how several Bayesian optimization methods could leverage gradient information and encourage the community to augment their optimization schemes with gradients, supported by strong empirical results even with randomly sampled directional derivatives. Eriksson et al. (2018) alleviate the computational constraints that come from using supervised gradient information using structured kernel interpolation and computational tricks like fast matrix-vector multiplication and pivoted Cholesky preconditioning. Other avenues for mitigating the computational complexity involve using structured automatic differentiation (Ament and Gomes, 2022). Instead of using the gradient for taking stochastic steps, Penubothula et al. (2021) aim to find local critical points by querying where the predicted gradient is zero.

As mentioned above, fitting a Gaussian process to the objective allows for predicting gradients without having seen them _a priori_(Rasmussen and Williams, 2006, Sec 9.4); Muller et al. (2021) propose _Gradient Information with BO_ (GIBO), in which they guide local policy search in reinforcement learning tasks, exploiting this property. Nguyen et al. (2022) address that expected gradients may not lead to the best performing outputs and compute the _most probable descent direction_.

### Structured spaces

Some applications work over structured spaces. For example, the angles of robot arms and protein backbones map to Riemannian manifolds (Jaquier et al., 2020; Penner, 2022), and input spaces might also contain mixed variables (i.e. products of real and categorical spaces). To compute non-linear embeddings (see Sec. 3.5) followed by standard Bayesian optimization (or small variations thereof) can allow us to work over such spaces. Jaquier et al. (2020) use kernels defined on Riemannian manifolds (Feragen et al., 2015; Borovitskiy et al., 2020) and optimize the acquisition function using tools from Riemannian optimization (Boumal, 2023). The authors expand their framework to high-dimensional manifolds by projecting to lower-dimensional submanifolds, which is roughly the equivalent to _linear embeddings_ in the Riemannian settings (Jaquier and Rozo, 2020).

In the categorical and mixed-variable setting, kernels over string spaces (Lodhi et al., 2000; Shervashidze et al., 2011), can be applied to BO (Moss et al., 2020). Other methods construct combinatorial graph and diffusion kernels-based GPs (Oh et al., 2019). Deshwal and Doppa (2021) combine latent space kernels with combinatorial kernels in an autoencoder-based approach.

Recently, Daulton et al. (2022b) have proposed a continuous relaxation of the discrete variables to ease the optimization of the acquisition function. Deshwal et al. (2023) propose another way to map discrete variables to continuous space, relying on Hamming distances to make a dictionary for embeddings. Papemmeier et al. (2024) extend previous work to both continuous and categorical variables: BAxUS learns an increasing sequence of subspaces using hash matrices which, when combined with the CoCaBo kernel (Ru et al., 2020), renders an algorithm for the mixed-variable setting. Finally, through a continuous relaxation of the objective that incorporates _prior_ pretrained models, Michael et al. (2024) propose a surrogate on the probability vector space to optimize either the discrete input space or a continuous latent one.

**Other.** Some methods evade our taxonomy but are worth mentioning: some focus on the optimization of the acquisition function and the impact of initializations (Zhao et al., 2024; Ngo et al., 2024). Other methods balance both active learning (i.e. building a better surrogate model) and optimization (Hvarfner et al., 2023). Most recently, two articles claimed that the standard setting for Bayesian optimization or slight variations of it perform as well as the state-of-the-art of all the aforementioned families (Hvarfner et al., 2024; Xu and Zhe, 2024) - begging the question, can these methods optimize in high dimensional discrete problem spaces in a sample efficient manner?

## 4 Benchmarking the performance of HDBO methods

Practitioners that decide on what Bayesian optimization algorithm to use for their application will face several challenges. While surveying the field, we noticed two key discrepancies in the reported experimental set-ups: (i) the initialization varies from as low as _none_ randomly/SOBOL sampled points to over \(10^{3}\), (ii) evaluation budgets also vary for the same types of tasks. Fig. 3 visualizes these different experimental set-ups as swarmplots. Moreover, our survey covered code availability. The state-of-the-art is being pulled by workhorses, which have democratized access to GP and BO implementations: GPyTorch(Gardner et al., 2018) and BoTorch(Balandat et al., 2020), and GPFlow(Matthews et al., 2017; van der Wilk et al., 2020) and Trieste(Picheny et al., 2023). These libraries are highly useful and impactful, yet one can obtain cross-dependency conflicts between them especially if third-party dependencies are introduced or if very specific versions are required for solver setups. As a particular example, solvers like ProbRep cannot co-exist with Ax-based solvers like SAASBO or Hvarfner's VanillaBO. There is a need for _isolating_ optimizers, specifying up-to-date environments in which they can run. These issues led to the development of poli.

### poli and poli-baselines: a framework for benchmarking discrete optimizers

We want to solve truly high dimensional problems that are relevant for domains like biology and chemistry. To make the outcomes comparable, we require a unified way of defining the problem which includes consistent starting points, budgets, runtime environments, relevant assets (i.e.models used for the black box), and a logging backend invoked for every oracle observation. To that end, we implement the _Protein Objectives Library_ (poli) to provide potentially isolated black box functions. Building on open source tools, poli currently provides 35 black box tasks; besides the Practical Molecular Optimization (PMO) benchmark (Huang et al., 2021; Gao et al., 2022; Brown et al., 2019), it includes Dockstring(Garcia-Ortegon et al., 2022) as well as other protein-related black boxes like stability and solvent accessibility (Delgado et al., 2019; Blaabjerg et al., 2023; Chapman and Chang, 2000; Stanton et al., 2022).4 The majority of black box functions can be queried with any string that complies with the corresponding alphabet making the oracles available for free-form optimization. This is an important distinction compared to pre-existing benchmarks that rely on pools of precompiled observations (Notin et al., 2023).

Figure 3: Initialization, evaluation budget, and nr. of replications using different seeds reported in the experimental set-ups of several HDBO methods. We see heterogeneity in the evaluation of optimizers.

We further provide an interface for the solvers used for the individual optimization tasks: poli-baselines. Consistent, stable (and up to date) environments of individual optimizers can be found therein, as well as a standardized way to query them and solve the problems raised in the previous section. These environments and optimizers are tested weekly through GitHub actions, guaranteeing their usability. An example of how poli and poli-baselines work is provided above. A problem containing a black box, an initial input, and potentially a data package is created through problem factories/a create method. A solver takes as input a black box and optionally supervised data, and uses the solve method to run the optimization for a given number of iterations. Such an interface can accommodate any optimizer that provides a method for running the optimization for a given amount of steps, as well as optimizers that do not accept custom initializations (e.g. Bounce or BAxUS). Sec. A.4 provides an introduction to this software's technical details, including a description of the logging logic though observers that keep track of every black box call.

### Benchmarking HDBO in discrete sequences

Using the black boxes provided in poli, as well as the solvers provided in poli-baselines, we benchmark the performance of high-dimensional Bayesian optimization solvers on discrete sequences. Such optimization can take place either at the sequence level (as solvers in the _Structured Spaces_ do), or in a continuous version via either one-hot representations or learned latent spaces. Benchmarks on both fronts are presented in this paper: from sequence design tasks of varying complexity (mimicking protein engineering) in one-hot/sequence space using Ehrlich functions (Stanton et al., 2024), to latent space optimization of small molecules on the Practical Molecular Optimization (PMO) benchmark (Gao et al., 2022; Huang et al., 2021; Brown et al., 2019).5

#### 4.2.1 Sequence design problems of varying complexity

Ehrlich functions (Stanton et al., 2024) are closed-form procedurally-generated oracles in which a certain collection of motifs needs to be satisfied in a sequence of a pre-selected length. The oracle's score is between 0 and 1, and determined by how much of the individual motifs are satisfied. The number of motifs and their length are hyperparameters specified by the user. Sec. A.5.1 provides a detailed introduction. In particular, we test on 4 different configurations: a PestControl equivalent6 with an alphabet size of 5 and a sequence length of 25 (i.e. one motif of length 25). Further, 3 different configurations imitating protein design using the alphabet of 20 amino acids and sequence lengths of 5, 15, and 64 are tested. The motif lengths and number of motifs are (4, 1), (7, 2) and (10, 4) respectively. We initialize PestControlEguiv, and the two small Ehrlich problems with 10 supervised samples, and the latter with 1000, and all methods have an evaluation budget of 300.

We optimize these oracles with representatives from the taxonomy that are frequently tested in the HDBO literature. We select Hvarfner's VanillaBQ, RandomLineBO, Turbo, BAxUS, SAASBQ, Bounce, and ProbRep, including also baselines like DirectedEvolution (i.e. greedily mutating

   Solver/Oracle & PestControlEguiv & Ehrlich(L=5) & Ehrlich(L=15) & Ehrlich(L=64) & Sum (normalized per row) \\  DirectedEvolution & 0.968\(\)0.03 & 1.000\(\)0.00 & 0.448\(\)0.16 & 0.114\(\)0.07 & 2.236\(\)0.27 \\ BiL1imbing & 0.640\(\)0.12 & 0.500\(\)0.25 & 0.392\(\)0.20 & 0.089\(\)0.07 & 0.56\(\)0.64 \\ CMAES & 0.816\(\)0.86 & 0.750\(\)0.18 & 0.312\(\)0.13 & 0.077\(\)0.08 & 1.244\(\)0.45 \\ GeneticAlgorithm & 0.712\(\)0.02 & 0.950\(\)0.11 & 0.336\(\)0.10 & 0.083\(\)0.08 & 1.50\(\)0.31 \\  Hvarfner’s VanillaBQ & 0.928\(\)0.08 & 0.650\(\)0.14 & 0.328\(\)0.18 & 0.079\(\)0.08 & 1.26\(\)0.47 \\ RandomLineBO & 0.621\(\)0.11 & 0.700\(\)0.27 & 0.472\(\)0.14 & 0.084\(\)0.08 & 1.04\(\)0.60 \\ SAASBQ & 0.792\(\)0.05 & 0.600\(\)0.14 & 0.328\(\)0.21 & 0.075\(\)0.06 & 0.92\(\)0.46 \\ Turbo & 0.896\(\)0.04 & 0.850\(\)0.14 & 0.480\(\)0.12 & 0.124\(\)0.11 & 1.860\(\)0.90 \\ BAxUS & 0.712\(\)0.08 & 0.550\(\)0.11 & 0.400\(\)0.11 & 0.077\(\)0.08 & 0.79\(\)0.39 \\  Bounce & 1.000\(\)0.00 & 0.900\(\)0.14 & 0.416\(\)0.13 & 0.076\(\)0.06 & 2.000\(\)0.33 \\ ProbRep & 0.896\(\)0.04 & 0.950\(\)0.10 & 0.328\(\)0.08 & 0.076\(\)0.08 & 1.80\(\)0.31 \\   

Table 1: Sequence design problems using Ehrlich functions. Solver’s performance (measured as the average best value achieved during an optimization campaign of 300 iterations) is colored according to their closeness to the known optimal value (1.0). All problems except for Ehrlich with sequence length 64 were initialized with 10 supervised samples. The remaining one was initialized with 1000.

[MISSING_PAGE_FAIL:9]

[MISSING_PAGE_FAIL:10]

[MISSING_PAGE_FAIL:11]

Brown, N., Fiscato, M., Segler, M. H., and Vaucher, A. C. (2019). Guacamol: benchmarking models for de novo molecular design. _Journal of chemical information and modeling_, 59(3):1096-1108.
* Chapman and Chang (2000) Chapman, B. and Chang, J. (2000). Biopython: Python tools for computational biology. _SIGBIO Newsl._, 20(2):15-19.
* Chen et al. (2012) Chen, B., Castro, R. M., and Krause, A. (2012). Joint optimization and variable selection of high-dimensional gaussian processes. In _Proceedings of the 29th International Conference on Machine Learning (ICML)_.
* Chen et al. (2020) Chen, J., Zhu, G., Yuan, C., and Huang, Y. (2020). Semi-supervised embedding learning for high-dimensional bayesian optimization.
* Chen et al. (2024) Chen, T., Duan, Y., Li, D., Qi, L., Shi, Y., and Gao, Y. (2024). Pg-lbo: Enhancing high-dimensional bayesian optimization with pseudo-label and gaussian process guidance. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 38, pages 11381-11389.
* Cowen-Rivers et al. (2022) Cowen-Rivers, A. I., Lyu, W., Tutunov, R., Wang, Z., Grosnit, A., Griffiths, R. R., Maraval, A. M., Jianye, H., Wang, J., Peters, J., et al. (2022). Hebo: Pushing the limits of sample-efficient hyper-parameter optimisation. _Journal of Artificial Intelligence Research_, 74:1269-1349.
* Daulton et al. (2022a) Daulton, S., Eriksson, D., Balandat, M., and Bakshy, E. (2022a). Multi-objective bayesian optimization over high-dimensional search spaces. In Cussens, J. and Zhang, K., editors, _Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence_, volume 180 of _Proceedings of Machine Learning Research_, pages 507-517. PMLR.
* Daulton et al. (2022b) Daulton, S., Wan, X., Eriksson, D., Balandat, M., Osborne, M. A., and Bakshy, E. (2022b). Bayesian optimization over discrete and mixed spaces via probabilistic reparameterization. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, _Advances in Neural Information Processing Systems_, volume 35, pages 12760-12774. Curran Associates, Inc.
* Delbridge et al. (2020) Delbridge, I., Bindel, D., and Wilson, A. G. (2020). Randomly projected additive Gaussian processes for regression. In III, H. D. and Singh, A., editors, _Proceedings of the 37th International Conference on Machine Learning_, volume 119 of _Proceedings of Machine Learning Research_, pages 2453-2463. PMLR.
* Delgado et al. (2019) Delgado, J., Radusky, L. G., Cianferoni, D., and Serrano, L. (2019). FoldX 5.0: working with RNA, small molecules and a new graphical interface. _Bioinformatics_, 35(20):4168-4169.
* Deshwal et al. (2023) Deshwal, A., Ament, S., Balandat, M., Bakshy, E., Doppa, J. R., and Eriksson, D. (2023). Bayesian optimization over high-dimensional combinatorial spaces via dictionary-based embeddings. In Ruiz, F., Dy, J., and van de Meent, J.-W., editors, _Proceedings of The 26th International Conference on Artificial Intelligence and Statistics_, volume 206 of _Proceedings of Machine Learning Research_, pages 7021-7039. PMLR.
* Deshwal et al. (2021a) Deshwal, A., Belakaria, S., and Doppa, J. R. (2021a). Bayesian optimization over hybrid spaces. In Meila, M. and Zhang, T., editors, _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 2632-2643. PMLR.
* Deshwal et al. (2021b) Deshwal, A., Belakaria, S., and Doppa, J. R. (2021b). Mercer features for efficient combinatorial bayesian optimization. In _Proceedings of the AAAI Conference on Artificial Intelligence_, volume 35, pages 7210-7218.
* Deshwal and Doppa (2021) Deshwal, A. and Doppa, J. (2021). Combining latent space and structured kernels for bayesian optimization over combinatorial spaces. In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W., editors, _Advances in Neural Information Processing Systems_, volume 34, pages 8185-8200. Curran Associates, Inc.
* Diouane et al. (2023) Diouane, Y., Picheny, V., Riche, R. L., and Perrotolo, A. S. D. (2023). Trego: a trust-region framework for efficient global optimization. _Journal of Global Optimization_, 86(1):1-23.
* Diouane et al. (2020)Djolonga, J., Krause, A., and Cevher, V. (2013). High-dimensional gaussian process bandits. In Burges, C., Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K., editors, _Advances in Neural Information Processing Systems_, volume 26. Curran Associates, Inc. 5, 22
* Dreczkowski et al. (2023) Dreczkowski, K., Grosnit, A., and Ammar, H. B. (2023). Framework and benchmarks for combinatorial and mixed-variable bayesian optimization.
* Eissman et al. (2018) Eissman, S., Levy, D., Shu, R., Bartzsch, S., and Ermon, S. (2018). Bayesian optimization and attribute adjustment. In _Proc. 34th Conference on Uncertainty in Artificial Intelligence_.
* Eriksson et al. (2018) Eriksson, D., Dong, K., Lee, E., Bindel, D., and Wilson, A. G. (2018). Scaling gaussian process regression with derivatives. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc.
* Eriksson and Jankowiak (2021) Eriksson, D. and Jankowiak, M. (2021). High-dimensional Bayesian optimization with sparse axis-aligned subspaces. In de Campos, C. and Maathuis, M. H., editors, _Proceedings of the Thirty-Seventh Conference on Uncertainty in Artificial Intelligence_, volume 161 of _Proceedings of Machine Learning Research_, pages 493-503. PMLR.
* Eriksson et al. (2019) Eriksson, D., Pearce, M., Gardner, J., Turner, R. D., and Poloczek, M. (2019). Scalable global optimization via local bayesian optimization. In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alche-Buc, F., Fox, E., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc.
* Feragen et al. (2015) Feragen, A., Lauze, F., and Hauberg, S. (2015). Geodesic Exponential Kernels: When Curvature and Linearity Conflict. In _Proceedings of the IEEE conference on computer vision and pattern recognition_, pages 3032-3042.
* Gao et al. (2022) Gao, W., Fu, T., Sun, J., and Coley, C. (2022). Sample efficiency matters: A benchmark for practical molecular optimization. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, _Advances in Neural Information Processing Systems_, volume 35, pages 21342-21357. Curran Associates, Inc.
* Garcia-Ortegon et al. (2022) Garcia-Ortegon, M., Simm, G. N., Tripp, A. J., Hernandez-Lobato, J. M., Bender, A., and Bacallado, S. (2022). Dockstring: easy molecular docking yields better benchmarks for ligand design. _Journal of chemical information and modeling_, 62(15):3486-3502.
* Gardner et al. (2017) Gardner, J., Guo, C., Weinberger, K., Garnett, R., and Grosse, R. (2017). Discovering and Exploiting Additive Structure for Bayesian Optimization. In Singh, A. and Zhu, J., editors, _Proceedings of the 20th International Conference on Artificial Intelligence and Statistics_, volume 54 of _Proceedings of Machine Learning Research_, pages 1311-1319. PMLR.
* Gardner et al. (2018) Gardner, J., Pleiss, G., Weinberger, K. Q., Bindel, D., and Wilson, A. G. (2018). Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc.
* Garnett (2023) Garnett, R. (2023). _Bayesian Optimization_. Cambridge University Press.
* Garnett et al. (2013) Garnett, R., Osborne, M. A., and Hennig, P. (2013). Active learning of linear embeddings for gaussian processes.
* Garrido-Merchan and Hernandez-Lobato (2020) Garrido-Merchan, E. C. and Hernandez-Lobato, D. (2020). Dealing with categorical and integer-valued variables in bayesian optimization with gaussian processes. _Neurocomputing_, 380:20-35.
* Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N., and Weinberger, K., editors, _Advances in Neural Information Processing Systems_, volume 27.
* Griffiths and Hernandez-Lobato (2020) Griffiths, R.-R. and Hernandez-Lobato, J. M. (2020). Constrained bayesian optimization for automatic chemical design using variational autoencoders. _Chemical Science_, 11(2):577-586.
* Ghahramani et al. (2018)Griffiths, R.-R., Klarner, L., Moss, H., Ravuri, A., Truong, S., Du, Y., Stanton, S., Tom, G., Rankovic, B., Jamasb, A., Deshwal, A., Schwartz, J., Tripp, A., Kell, G., Frieder, S., Bourached, A., Chan, A., Moss, J., Guo, C., Durbolt, J. P., Chaurasia, S., Park, J. W., Strieth-Kalthoff, F., Lee, A., Cheng, B., Aspuru-Guzik, A., Schwaller, P., and Tang, J. (2023). Gauche: A library for gaussian processes in chemistry. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S., editors, _Advances in Neural Information Processing Systems_, volume 36, pages 76923-76946. Curran Associates, Inc. 3, 23
* Grosnit et al. (2021) Grosnit, A., Tutunov, R., Maraval, A. M., Griffiths, R.-R., Cowen-Rivers, A. I., Yang, L., Zhu, L., Lyu, W., Chen, Z., Wang, J., Peters, J., and Bou-Ammar, H. (2021). High-dimensional bayesian optimisation with variational autoencoders and deep metric learning. 5, 22
* Gruver et al. (2023) Gruver, N., Stanton, S., Frey, N., Rudner, T. G. J., Hotzel, I., Lafrance-Vanasse, J., Rajpal, A., Cho, K., and Wilson, A. G. (2023). Protein design with guided discrete diffusion. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S., editors, _Advances in Neural Information Processing Systems_, volume 36, pages 12489-12517. Curran Associates, Inc. 1, 3, 23
* Gomez-Bombarelli et al. (2018) Gomez-Bombarelli, R., Wei, J. N., Duvenaud, D., Hernandez-Lobato, J. M., Sanchez-Lengeling, B., Sheberla, D., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., and Aspuru-Guzik, A. (2018). Automatic chemical design using a data-driven continuous representation of molecules. _ACS Central Science_, 4(2):268-276. PMID: 29532027.
* Han et al. (2021) Han, E., Arora, I., and Scarlett, J. (2021). High-dimensional bayesian optimization via tree-structured additive models. _Proceedings of the AAAI Conference on Artificial Intelligence_, 35(9):7630-7638.
* Harris et al. (2020) Harris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del Rio, J. F., Wiebe, M., Peterson, P., Gerard-Marchant, P., Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant, T. E. (2020). Array programming with NumPy. _Nature_, 585(7825):357-362.
* Hebbal et al. (2019) Hebbal, A., Brevault, L., Balesdent, M., Talbi, E.-G., and Melab, N. (2019). Multi-objective optimization using deep gaussian processes: application to aerospace vehicle design. In _AIAA Scitech 2019 Forum_, page 1973.
* Hebbal et al. (2021) Hebbal, A., Brevault, L., Balesdent, M., Talbi, E.-G., and Melab, N. (2021). Bayesian optimization using deep gaussian processes with applications to aerospace system design. _Optimization and Engineering_, 22:321-361.
* Hellsten et al. (2023) Hellsten, E. O., Hvarfner, C., Papenmeier, L., and Nardi, L. (2023). High-dimensional bayesian optimization with group testing. 23
* Horiguchi et al. (2022) Horiguchi, S. A., Iwata, T., Tsuzuki, T., and Ozawa, Y. (2022). Linear embedding-based high-dimensional batch bayesian optimization without reconstruction mappings. 5, 23
* Hu et al. (2024) Hu, S., Li, J., and Cai, Z. (2024). An adaptive dimension reduction estimation method for high-dimensional bayesian optimization. 5, 23
* Huang et al. (2021) Huang, K., Fu, T., Gao, W., Zhao, Y., Roohani, Y. H., Leskovec, J., Coley, C. W., Xiao, C., Sun, J., and Zitnik, M. (2021). Therapeutics data commons: Machine learning datasets and tasks for drug discovery and development. In _Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1)_. 7, 8, 9, 30
* Hvarfner et al. (2023) Hvarfner, C., Hellsten, E., Hutter, F., and Nardi, L. (2023). Self-correcting bayesian optimization through bayesian active learning. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S., editors, _Advances in Neural Information Processing Systems_, volume 36, pages 79173-79199. Curran Associates, Inc. 6, 23
* Hvarfner et al. (2024) Hvarfner, C., Hellsten, E. O., and Nardi, L. (2024). Vanilla bayesian optimization performs great in high dimensions. 3, 6, 22Irwin, J. J., Tang, K. G., Young, J., Dandarchuluun, C., Wong, B. R., Khurelbataar, M., Moroz, Y. S., Mayfield, J., and Sayle, R. A. (2020). Zinc20--a free ultralarge-scale chemical database for ligand discovery. _Journal of chemical information and modeling_, 60(12):6065-6073.
* Jaquier and Rozo (2020) Jaquier, N. and Rozo, L. (2020). High-dimensional bayesian optimization via nested riemannian manifolds. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H., editors, _Advances in Neural Information Processing Systems_, volume 33, pages 20939-20951. Curran Associates, Inc.
* Jaquier et al. (2020) Jaquier, N., Rozo, L., Calinon, S., and Burger, M. (2020). Bayesian optimization meets riemannian manifolds in robot learning. In Kaelbling, L. P., Kragic, D., and Sugiura, K., editors, _Proceedings of the Conference on Robot Learning_, volume 100 of _Proceedings of Machine Learning Research_, pages 233-246. PMLR.
* Jin et al. (2018) Jin, W., Barzilay, R., and Jaakkola, T. (2018). Junction tree variational autoencoder for molecular graph generation. In Dy, J. and Krause, A., editors, _Proceedings of the 35th International Conference on Machine Learning_, volume 80 of _Proceedings of Machine Learning Research_, pages 2323-2332.
* Jones et al. (1998) Jones, D. R., Schonlau, M., and Welch, W. J. (1998). Efficient global optimization of expensive black-box functions. _Journal of Global optimization_, 13:455-492.
* Justesen et al. (2020) Justesen, N., Bontrager, P., Togelius, J., and Risi, S. (2020). Deep learning for video game playing. _IEEE Transactions on Games_, 12(1):1-20.
* Khan et al. (2023) Khan, A., Cowen-Rivers, A. I., Grosnit, A., Robert, P. A., Greiff, V., Smorodina, E., Rawat, P., Akbar, R., Dreczkowski, K., Tutunov, R., et al. (2023). Toward real-world automated antibody design with combinatorial bayesian optimization. _Cell Reports Methods_, 3(1).
* Kim et al. (2022) Kim, J., Choi, S., and Cho, M. (2022). Combinatorial bayesian optimization with random mapping functions to convex polytopes. In Cussens, J. and Zhang, K., editors, _Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence_, volume 180 of _Proceedings of Machine Learning Research_, pages 1001-1011. PMLR.
* Kingma and Welling (2014) Kingma, D. P. and Welling, M. (2014). Auto-encoding variational bayes. In Bengio, Y. and LeCun, Y., editors, _2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings_.
* Kirschner et al. (2019) Kirschner, J., Mutny, M., Hiller, N., Ischebeck, R., and Krause, A. (2019). Adaptive and safe Bayesian optimization in high dimensions via one-dimensional subspaces. In Chaudhuri, K. and Salakhutdinov, R., editors, _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 3429-3438. PMLR.
* Kong et al. (2024) Kong, D., Huang, Y., Xie, J., Honig, E., Xu, M., Xue, S., Lin, P., Zhou, S., Zhong, S., Zheng, N., and Wu, Y. N. (2024). Dual-space optimization: Improved molecule sequence design by latent prompt transformer.
* Krenn et al. (2020) Krenn, M., Hase, F., Nigam, A., Friederich, P., and Aspuru-Guzik, A. (2020). Self-referencing embedded strings (selfies): A 100% robust molecular string representation. _Machine Learning: Science and Technology_, 1(4):045024.
* Kristiadi et al. (2024) Kristiadi, A., Strieth-Kalthoff, F., Skreta, M., Poupart, P., Aspuru-Guzik, A., and Pleiss, G. (2024). A sober look at LLMs for material discovery: Are they actually good for Bayesian optimization over molecules? In Salakhutdinov, R., Kolter, Z., Heller, K., Weller, A., Oliver, N., Scarlett, J., and Berkenkamp, F., editors, _Proceedings of the 41st International Conference on Machine Learning_, volume 235 of _Proceedings of Machine Learning Research_, pages 25603-25622. PMLR.
* Kusner et al. (2017) Kusner, M. J., Paige, B., and Hernandez-Lobato, J. M. (2017). Grammar variational autoencoder. In Precup, D. and Teh, Y. W., editors, _Proceedings of the 34th International Conference on Machine Learning_, volume 70 of _Proceedings of Machine Learning Research_, pages 1945-1954.
* Krizhevsky et al. (2014)Lee, S., Chu, J., Kim, S., Ko, J., and Kim, H. J. (2023). Advancing bayesian optimization via learning correlated latent space. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S., editors, _Advances in Neural Information Processing Systems_, volume 36, pages 48906-48917. Curran Associates, Inc. 5, 22
* Letham et al. (2020) Letham, B., Calandra, R., Rai, A., and Bakshy, E. (2020). Re-examining linear embeddings for high-dimensional bayesian optimization. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H., editors, _Advances in Neural Information Processing Systems_, volume 33, pages 1546-1558. Curran Associates, Inc. 22
* Li et al. (2018) Li, C., Gupta, S., Rana, S., Nguyen, V., Venkatesh, S., and Shilton, A. (2018). High dimensional bayesian optimization using dropout. 4, 22
* Li et al. (2016) Li, C.-L., Kandasamy, K., Poczos, B., and Schneider, J. (2016). High dimensional bayesian optimization via restricted projection pursuit models. In Gretton, A. and Robert, C. C., editors, _Proceedings of the 19th International Conference on Artificial Intelligence and Statistics_, volume 51 of _Proceedings of Machine Learning Research_, pages 884-892, Cadiz, Spain. PMLR. 4, 23
* Lodhi et al. (2000) Lodhi, H., Shawe-Taylor, J., Cristianini, N., and Watkins, C. (2000). Text classification using string kernels. In Leen, T., Dietterich, T., and Tresp, V., editors, _Advances in Neural Information Processing Systems_, volume 13. MIT Press.
* Loeffler et al. (2024) Loeffler, H. H., He, J., Tibo, A., Janet, J. P., Voronov, A., Mervin, L. H., and Engkvist, O. (2024). Reinvent 4: Modern ai-driven generative molecule design. _Journal of Cheminformatics_, 16(1):20.
* Lu et al. (2018) Lu, X., Gonzalez, J., Dai, Z., and Lawrence, N. (2018). Structured variationally auto-encoded optimization. In Dy, J. and Krause, A., editors, _Proceedings of the 35th International Conference on Machine Learning_, volume 80 of _Proceedings of Machine Learning Research_, pages 3267-3275. PMLR. 22
* Matthews et al. (2017) Matthews, A. G. d. G., van der Wilk, M., Nickson, T., Fujii, K., Boukouvalas, A., Leon-Villagra, P., Ghahramani, Z., and Hensman, J. (2017). GPflow: A Gaussian process library using TensorFlow. _Journal of Machine Learning Research_, 18(40):1-6.
* Maus et al. (2022) Maus, N., Jones, H., Moore, J., Kusner, M. J., Bradshaw, J., and Gardner, J. (2022). Local latent space bayesian optimization over structured inputs. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, _Advances in Neural Information Processing Systems_, volume 35, pages 34505-34518. Curran Associates, Inc. 5, 22
* Maus et al. (2023) Maus, N., Wu, K., Eriksson, D., and Gardner, J. (2023). Discovering many diverse solutions with bayesian optimization. 5, 22
* Michael et al. (2024) Michael, R., Bartels, S., Gonzalez-Duque, M., Zainchkovskyy, Y., Frellsen, J., Hauberg, S., and Boomsma, W. (2024). A continuous relaxation for discrete bayesian optimization. 6, 23
* Moriconi et al. (2020a) Moriconi, R., Deisenroth, M. P., and Sesh Kumar, K. (2020a). High-dimensional bayesian optimization using low-dimensional feature spaces. _Machine Learning_, 109:1925-1943.
* Moriconi et al. (2020b) Moriconi, R., Kumar, K. S., and Deisenroth, M. P. (2020b). High-dimensional bayesian optimization with projections using quantile gaussian processes. _Optimization Letters_, 14:51-64.
* Moss et al. (2020) Moss, H., Leslie, D., Beck, D., Gonzalez, J., and Rayson, P. (2020). Boss: Bayesian optimization over string spaces. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H., editors, _Advances in Neural Information Processing Systems_, volume 33, pages 15476-15486. Curran Associates, Inc. 6, 23
* Mockus (1975) Mockus, J. (1975). On bayesian methods for seeking the extremum. In Marchuk, G. I., editor, _Optimization Techniques IFIP Technical Conference Novosibirsk, July 1-7, 1974_, page 400-404, Berlin, Heidelberg. Springer.
* Mockus (2018)Muller, S., von Rohr, A., and Trimpe, S. (2021). Local policy search with bayesian optimization. In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W., editors, _Advances in Neural Information Processing Systems_, volume 34, pages 20708-20720. Curran Associates, Inc.
* Mutny and Krause (2018) Mutny, M. and Krause, A. (2018). Efficient high dimensional bayesian optimization with additivity and quadrature fourier features. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc.
* Nayebi et al. (2019) Nayebi, A., Munteanu, A., and Poloczek, M. (2019). A framework for Bayesian optimization in embedded subspaces. In Chaudhuri, K. and Salakhutdinov, R., editors, _Proceedings of the 36th International Conference on Machine Learning_, volume 97 of _Proceedings of Machine Learning Research_, pages 4752-4761. PMLR.
* Needleman and Wunsch (1970) Needleman, S. B. and Wunsch, C. D. (1970). A general method applicable to the search for similarities in the amino acid sequence of two proteins. _Journal of Molecular Biology_, 48(3):443-453.
* Ngo et al. (2024) Ngo, L., Ha, H., Chan, J., Nguyen, V., and Zhang, H. (2024). High-dimensional bayesian optimization via covariance matrix adaptation strategy.
* Nguyen et al. (2022) Nguyen, Q., Wu, K., Gardner, J., and Garnett, R. (2022). Local bayesian optimization via maximizing probability of descent. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, _Advances in Neural Information Processing Systems_, volume 35, pages 13190-13202. Curran Associates, Inc.
* Notin et al. (2021) Notin, P., Hernandez-Lobato, J. M., and Gal, Y. (2021). Improving black-box optimization in vae latent space using decoder uncertainty. In Ranzato, M., Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W., editors, _Advances in Neural Information Processing Systems_, volume 34, pages 802-814. Curran Associates, Inc.
* Notin et al. (2023) Notin, P., Kollasch, A., Ritter, D., van Niekerk, L., Paul, S., Spinner, H., Rollins, N., Shaw, A., Orenbuch, R., Weitzman, R., Frazer, J., Dias, M., Franceschi, D., Gal, Y., and Marks, D. (2023). Proteingym: Large-scale benchmarks for protein fitness prediction and design. In Oh, A., Naumann, T., Globerson, A., Saenko, K., Hardt, M., and Levine, S., editors, _Advances in Neural Information Processing Systems_, volume 36, pages 64331-64379. Curran Associates, Inc.
* Oh et al. (2018) Oh, C., Gavves, E., and Welling, M. (2018). BOCK : Bayesian optimization with cylindrical kernels. In Dy, J. and Krause, A., editors, _Proceedings of the 35th International Conference on Machine Learning_, volume 80 of _Proceedings of Machine Learning Research_, pages 3868-3877. PMLR.
* Oh et al. (2019) Oh, C., Tomczak, J., Gavves, E., and Welling, M. (2019). Combinatorial bayesian optimization using the graph cartesian product. In Wallach, H., Larochelle, H., Beygelzimer, A., d'Alche-Buc, F., Fox, E., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 32. Curran Associates, Inc.
* Palar and Shimoyama (2017) Palar, P. S. and Shimoyama, K. (2017). Exploiting active subspaces in global optimization: how complex is your problem? In _Proceedings of the Genetic and Evolutionary Computation Conference Companion_, GECCO '17, page 1487-1494, New York, NY, USA. Association for Computing Machinery.
* Papenmeier et al. (2022) Papenmeier, L., Nardi, L., and Poloczek, M. (2022). Increasing the scope as you learn: Adaptive bayesian optimization in nested subspaces. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, _Advances in Neural Information Processing Systems_, volume 35, pages 11586-11601. Curran Associates, Inc.
* Papenmeier et al. (2024) Papenmeier, L., Nardi, L., and Poloczek, M. (2024). Bounce: Reliable high-dimensional bayesian optimization for combinatorial and mixed spaces.
* Pedrielli and Ng (2016) Pedrielli, G. and Ng, S. H. (2016). G-star: A new kriging-based trust region method for global optimization. In _2016 Winter Simulation Conference (WSC)_, pages 803-814.
* Penner (2022) Penner, R. (2022). Protein geometry, function and mutation.
* Penninger et al. (2019)Penubothula, S., Kamanchi, C., and Bhatnagar, S. (2021). Novel first order bayesian optimization with an application to reinforcement learning. _Applied Intelligence_, 51(3):1565-1579.
* Picheny et al. (2023) Picheny, V., Berkeley, J., Moss, H. B., Stojic, H., Grants, U., Ober, S. W., Artemev, A., Ghani, K., Goodall, A., Paleyes, A., Vakili, S., Pascual-Diaz, S., Markou, S., Qing, J., Loka, N. R. B. S., and Couckuyt, I. (2023). Trieste: Efficiently exploring the depths of black-box functions with tensorflow.
* Pyzer-Knapp (2018) Pyzer-Knapp, E. O. (2018). Bayesian optimization for accelerated drug discovery. _IBM Journal of Research and Development_, 62(6):2:1-2:7.
* Qian et al. (2016) Qian, H., Hu, Y.-Q., and Yu, Y. (2016). Derivative-free optimization of high-dimensional non-convex functions by sequential random embeddings. In _IJCAI_, pages 1946-1952.
* Rana et al. (2017) Rana, S., Li, C., Gupta, S., Nguyen, V., and Venkatesh, S. (2017). High dimensional Bayesian optimization with elastic Gaussian process. In Precup, D. and Teh, Y. W., editors, _Proceedings of the 34th International Conference on Machine Learning_, volume 70 of _Proceedings of Machine Learning Research_, pages 2883-2891. PMLR.
* Raponi et al. (2020) Raponi, E., Wang, H., Bujny, M., Boria, S., and Doerr, C. (2020). High dimensional bayesian optimization assisted by principal component analysis. In _Parallel Problem Solving from Nature-PPSN XVI: 16th International Conference, PPSN 2020, Leiden, The Netherlands, September 5-9, 2020, Proceedings, Part I 16_, pages 169-183. Springer.
* Rasmussen and Williams (2006) Rasmussen, C. E. and Williams, C. K. I. (2006). _Gaussian processes for machine learning_. Adaptive computation and machine learning. MIT Press, Cambridge, Mass.
* Regis (2016) Regis, R. G. (2016). Trust regions in kriging-based optimization with expected improvement. _Engineering Optimization_, 48(6):1037-1059.
* Rezende et al. (2014) Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. In Xing, E. P. and Jebara, T., editors, _Proceedings of the 31st International Conference on Machine Learning_, volume 32 of _Proceedings of Machine Learning Research_, pages 1278-1286, Bejing, China. PMLR.
* Rolland et al. (2018) Rolland, P., Scarlett, J., Bogunovic, I., and Cevher, V. (2018). High-dimensional bayesian optimization via additive models with overlapping groups. In Storkey, A. and Perez-Cruz, F., editors, _Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics_, volume 84 of _Proceedings of Machine Learning Research_, pages 298-307. PMLR.
* Ru et al. (2020) Ru, B., Alvi, A., Nguyen, V., Osborne, M. A., and Roberts, S. (2020). Bayesian optimisation over multiple continuous and categorical inputs. In III, H. D. and Singh, A., editors, _Proceedings of the 37th International Conference on Machine Learning_, volume 119 of _Proceedings of Machine Learning Research_, pages 8276-8285. PMLR.
* Santoni et al. (2023) Santoni, M. L., Raponi, E., Leone, R. D., and Doerr, C. (2023). Comparison of high-dimensional bayesian optimization algorithms on bbob.
* Shahriari et al. (2016) Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., and de Freitas, N. (2016). Taking the human out of the loop: A review of bayesian optimization. _Proceedings of the IEEE_, 104(1):148-175.
* Shekhar and Javidi (2021) Shekhar, S. and Javidi, T. (2021). Significance of gradient information in bayesian optimization. In Banerjee, A. and Fukumizu, K., editors, _Proceedings of The 24th International Conference on Artificial Intelligence and Statistics_, volume 130 of _Proceedings of Machine Learning Research_, pages 2836-2844. PMLR.
* Shervashidze et al. (2011) Shervashidze, N., Schweitzer, P., Van Leeuwen, E. J., Mehlhorn, K., and Borgwardt, K. M. (2011). Weisfeiler-lehman graph kernels. _Journal of Machine Learning Research_, 12(9).
* Shmakov et al. (2023) Shmakov, A., Naug, A., Gundecha, V., Ghorbanpour, S., Gutierrez, R. L., Babu, A. R., Guillen, A., and Sarkar, S. (2023). Rtdk-bo: High dimensional bayesian optimization with reinforced transformer deep kernels. In _2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)_, pages 1-8.
* Shmakov et al. (2017)Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical bayesian optimization of machine learning algorithms. In Pereira, F., Burges, C., Bottou, L., and Weinberger, K., editors, _Advances in Neural Information Processing Systems_, volume 25. Curran Associates, Inc.
* Song et al. (2022) Song, L., Xue, K., Huang, X., and Qian, C. (2022). Monte carlo tree search based variable selection for high dimensional bayesian optimization. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A., editors, _Advances in Neural Information Processing Systems_, volume 35, pages 28488-28501. Curran Associates, Inc.
* Springenberg et al. (2016) Springenberg, J. T., Klein, A., Falkner, S., and Hutter, F. (2016). Bayesian optimization with robust bayesian neural networks. In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 29. Curran Associates, Inc.
* Srinivas et al. (2012) Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. W. (2012). Information-theoretic regret bounds for gaussian process optimization in the bandit setting. _IEEE Transactions on Information Theory_, 58(5):3250-3265.
* Stanton et al. (2024) Stanton, S., Alberstein, R., Frey, N., Watkins, A., and Cho, K. (2024). Closed-form test functions for biophysical sequence optimization algorithms.
* Stanton et al. (2022) Stanton, S., Maddox, W., Gruver, N., Maffettone, P., Delaney, E., Greenside, P., and Wilson, A. G. (2022). Accelerating Bayesian optimization for biological sequence design with denoising autoencoders. In Chaudhuri, K., Jegelka, S., Song, L., Szepesvari, C., Niu, G., and Sabato, S., editors, _Proceedings of the 39th International Conference on Machine Learning_, volume 162 of _Proceedings of Machine Learning Research_, pages 20459-20478. PMLR.
* Swersky et al. (2020) Swersky, K., Rubanova, Y., Dohan, D., and Murphy, K. (2020). Amortized bayesian optimization over discrete spaces. In Peters, J. and Sontag, D., editors, _Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence (UAI)_, volume 124 of _Proceedings of Machine Learning Research_, pages 769-778. PMLR.
* Tripp et al. (2020) Tripp, A., Daxberger, E., and Hernandez-Lobato, J. M. (2020). Sample-efficient optimization in the latent space of deep generative models via weighted retraining. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H., editors, _Advances in Neural Information Processing Systems_, volume 33, pages 11259-11272. Curran Associates, Inc.
* Tripp and Hernandez-Lobato (2023) Tripp, A. and Hernandez-Lobato, J. M. (2023). Genetic algorithms are strong baselines for molecule generation.
* Turner et al. (2021) Turner, R., Eriksson, D., McCourt, M., Kiiii, J., Laaksonen, E., Xu, Z., and Guyon, I. (2021). Bayesian optimization is superior to random search for machine learning hyperparameter tuning: Analysis of the black-box optimization challenge 2020. In Escalante, H. J. and Hofmann, K., editors, _Proceedings of the NeurIPS 2020 Competition and Demonstration Track_, volume 133 of _Proceedings of Machine Learning Research_, pages 3-26. PMLR.
* Ulmasov et al. (2016) Ulmasov, D., Baroukh, C., Chachuat, B., Deisenroth, M. P., and Misener, R. (2016). Bayesian optimization with dimension scheduling: Application to biological systems. In Kravanja, Z. and Bogataj, M., editors, _26th European Symposium on Computer Aided Process Engineering_, volume 38 of _Computer Aided Chemical Engineering_, pages 1051-1056. Elsevier.
* Urbina et al. (2022) Urbina, F., Lentzos, F., Invernizzi, C., and Ekins, S. (2022). Dual use of artificial-intelligence-powered drug discovery. _Nature Machine Intelligence_, 4(3):189-191.
* van der Wilk et al. (2020) van der Wilk, M., Dutordoir, V., John, S., Artemev, A., Adam, V., and Hensman, J. (2020). A framework for interdomain and multioutput Gaussian processes. _arXiv:2003.01115_.
* Verma et al. (2022) Verma, E., Chakraborty, S., and Griffiths, R.-R. (2022). Highdimensional bayesian optimization with invariance. In _ICML Workshop on Adaptive Experimental Design and Active Learning_.
* Wan et al. (2021) Wan, X., Nguyen, V., Ha, H., Ru, B., Lu, C., and Osborne, M. A. (2021). Think global and act local: Bayesian optimisation over high-dimensional categorical and mixed search spaces. In Meila, M. and Zhang, T., editors, _Proceedings of the 38th International Conference on Machine Learning_, volume 139 of _Proceedings of Machine Learning Research_, pages 10663-10674. PMLR.
* Wax et al. (2020)Wang, X., Jin, Y., Schmitt, S., and Olhofer, M. (2023). Recent advances in bayesian optimization. _ACM Comput. Surv._, 55(13s).
* Wang et al. (2018) Wang, Z., Gehring, C., Kohli, P., and Jegelka, S. (2018). Batched large-scale bayesian optimization in high-dimensional spaces. In Storkey, A. and Perez-Cruz, F., editors, _Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics_, volume 84 of _Proceedings of Machine Learning Research_, pages 745-754. PMLR.
* Wang et al. (2016) Wang, Z., Hutter, F., Zoghi, M., Matheson, D., and De Feitas, N. (2016). Bayesian optimization in a billion dimensions via random embeddings. _Journal of Artificial Intelligence Research_, 55:361-387.
* Wang et al. (2013) Wang, Z., Zoghi, M., Hutter, F., Matheson, D., and De Freitas, N. (2013). Bayesian optimization in high dimensions via random embeddings. In _Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence_, IJCAI '13, page 1778-1784.
* Weininger (1988) Weininger, D. (1988). Smiles, a chemical language and information system. 1. introduction to methodology and encoding rules. _J. Chem. Inf. Comput. Sci._, 28(1):31-36.
* Wilkins (1668) Wilkins, J. (1668). _An Essay towards a Real Character And a Philosophical Language_. Royal Society, London.
* Winkel et al. (2021) Winkel, M. A., Stallrich, J. W., Storlie, C. B., and Reich, B. J. (2021). Sequential optimization in locally important dimensions. _Technometrics_, 63(2):236-248.
* Wu et al. (2017) Wu, J., Poloczek, M., Wilson, A. G., and Frazier, P. (2017). Bayesian optimization with gradients. In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., and Garnett, R., editors, _Advances in Neural Information Processing Systems_, volume 30. Curran Associates, Inc.
* Wycoff et al. (2021) Wycoff, N., Binois, M., and Wild, S. M. (2021). Sequential learning of active subspaces. _Journal of Computational and Graphical Statistics_, 30(4):1224-1237.
* Xu and Zhe (2024) Xu, Z. and Zhe, S. (2024). Standard gaussian process can be excellent for high-dimensional bayesian optimization.
* Yenicelik (2020) Yenicelik, D. (2020). Parameter optimization using high-dimensional bayesian optimization.
* Yin et al. (2024) Yin, Y., Wang, Y., and Li, P. (2024). High-dimensional bayesian optimization via semi-supervised learning with optimized unlabeled data sampling.
* Zhan (2024) Zhan, D. (2024). Expected coordinate improvement for high-dimensional bayesian optimization.
* Zhang et al. (2019) Zhang, M., Li, H., and Su, S. (2019). High dimensional bayesian optimization via supervised dimension reduction.
* Zhao et al. (2024) Zhao, J., Yang, R., Qiu, S., and Wang, Z. (2024). Unleashing the potential of acquisition functions in high-dimensional bayesian optimization.
* Zhou et al. (2021) Zhou, J., Yang, Z., Si, Y., Kang, L., Li, H., Wang, M., and Zhang, Z. (2021). A trust-region parallel bayesian optimization method for simulation-driven antenna design. _IEEE Transactions on Antennas and Propagation_, 69(7):3966-3981.
* Zhu et al. (2022) Zhu, Z., Shi, C., Zhang, Z., Liu, S., Xu, M., Yuan, X., Zhang, Y., Chen, J., Cai, H., Lu, J., Ma, C., Liu, R., Xhonneux, L.-P., Qu, M., and Tang, J. (2022). Torchdrug: A powerful and flexible machine learning platform for drug discovery.
* Ziomek and Bou Ammar (2023) Ziomek, J. K. and Bou Ammar, H. (2023). Are random decompositions all we need in high dimensional Bayesian optimisation? In Krause, A., Brunskill, E., Cho, K., Engelhardt, B., Sabato, S., and Scarlett, J., editors, _Proceedings of the 40th International Conference on Machine Learning_, volume 202 of _Proceedings of Machine Learning Research_, pages 43347-43368. PMLR.

## Checklist

1. For all authors... 1. Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]  MGD: yes, RM: yes, SB: yes, YZ: yes, SH: yes, WB: yes 2. Did you describe the limitations of your work? [Yes]  MGD: yes, RM: yes, SB: yes, YZ: yes, SH: yes, WB: yes 3. Did you discuss any potential negative societal impacts of your work? [Yes]  MGD: yes, RM: yes, SB: yes, YZ: yes, SH: yes, WB: yes 4. Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]  MGD: yes, RM: yes, SB: yes, YZ: yes, SH: yes, WB: yes
2. If you are including theoretical results... 1. Did you state the full set of assumptions of all theoretical results? [N/A]  No theoretical results. 2. Did you include complete proofs of all theoretical results? [N/A]  No theoretical results.
3. If you ran experiments (e.g. for benchmarks)... 1. Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? [Yes] In the project URL you can find a link to our repository with instructions. 2. Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? [Yes]  See Sec. A.3. 3. Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [Yes]  See Tables 2 and 3. 4. Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? [Yes]  See Sec. A.6 in the appendix
4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets... 1. If your work uses existing assets, did you cite the creators? [Yes] We use the PMO benchmark, for which we cite not only the original developers, but also the work they are based on plus their TDC framework. Plus, we cite the authors of every HDBO solver we could find, let alone use. For Ehrlich functions, we cite the relevant paper. 2. Did you mention the license of the assets? [Yes]  Yes, see Sec. A.2 in the appendix. 3. Did you include any new assets either in the supplemental material or as a URL? [Yes] In the project website. https://machinelearninglifescience.github.io/hdbo_benchmark/ 4. Did you discuss whether and how consent was obtained from people whose data you're using/curating? [N/A]  We are not using data on people. 5. Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [N/A]  We are not using data on people.
5. If you used crowdsourcing or conducted research with human subjects... 1. Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A]  We are not crowdsourcing experiments, nor conducting research on humans. 2. Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A]  We are not crowdsourcing experiments, nor conducting research on humans. 3. Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]  We are not crowdsourcing experiments, nor conducting research on humans.

Appendix

### Methods Overview

### Methods Overview

 
**Method** & **Date** & **Reference** & **Code** \\  & (first occurrence) & & **Available** \\  SOLID & January 23, 2019 & Winkel et al. (2021) & ✗ \\ Deep GPs & May 7, 2019 & Hebbal et al. (2021) & ✗ \\ ASM & July 15, 2017 & Palar and Shimoyama (2017) & ✗ \\ Add-GP-UCB & May 13, 2015 & Han et al. (2021) & ✓ \\ TuRBO & December 8, 2019 & Eriksson et al. (2019) & ✓ \\ LOL-BO & January 28, 2022 & Maus et al. (2022) & ✓ \\ ROBOT & October 20, 2022 & Maus et al. (2023) & ✓ \\ REMBO & January 9, 2013 & Wang et al. (2016) & ✓ \\ SAASBO & June 10, 2021 & Eriksson and Jankowiak (2021) & ✓ \\ Dropout & August 19, 2017 & Li et al. (2018) & ✗ \\ BAxUS & November 28, 2022 & Papenmeier et al. (2022) & ✓ \\ LineBO & June 10, 2019 & Kirschner et al. (2019) & ✓ \\ ALEBO & December 6, 2020 & Letham et al. (2020) & ✓ \\ HeSBO & May 24, 2019 & Nayebi et al. (2019) & ✓ \\ BORING & October 5, 2020 & Yenicelik (2020) & ✗ \\ REMBO 2.0 & October 18, 2019 & Binois et al. (2020) & ✗ \\ Quantile-GP BO & February 1, 2020 & Moriconi et al. (2020b) & ✗ \\ Warped REMBO & January 1, 2015 & Binois et al. (2015) & ✗ \\ closed-from ASM & September 22, 2020 & Wycoff et al. (2021) & ✓ \\ Active manifolds & May 24, 2019 & Bridges et al. (2019) & ✗ \\ Deep GPs (MO) & January 1, 2019 & Hebbal et al. (2019) & ✗ \\ LADER & December 6, 2021 & Deshwal and Doppa (2021) & ✓ \\ Attr. Adjustment & August 6, 2018 & Eissman et al. (2018) & ✗ \\ VAEs DML & November 1, 2021 & Grosnit et al. (2021) & ✓ \\ LSBO & February 28, 2018 & Gomez-Bombarelli et al. (2018) & ✓ \\ Weigh. Retraining & October 25, 2020 & Tripp et al. (2020) & ✓ \\ MORBO (MO) & September 22, 2021 & Daultton et al. (2022a) & ✓ \\ TREGO & October 10, 2022 & Diouane et al. (2023) & ✗ \\ TRIKE & August 8, 2015 & Regis (2016) & ✗ \\ TRPRO & November 21, 2020 & Zhou et al. (2021) & ✗ \\ D-SKIP & December 3, 2018 & Eriksson et al. (2018) & ✓ \\ RDUCB & May 29, 2023 & Ziomek and Bou Ammar (2023) & ✓ \\ G-Add-GP-UCB & April 9, 2018 & Rolland et al. (2018) & ✗ \\ QFF & December 3, 2018 & Mutny and Krause (2018) & ✗ \\ SI-BO & December 5, 2013 & Djolonga et al. (2013) & ✗ \\ SRE-IMGPO & July 9, 2016 & Qian et al. (2016) & ✗ \\ HDS & June 27, 2012 & Chen et al. (2012) & ✗ \\ AL of LEs & October 24, 2013 & Garnett et al. (2013) & ✓ \\ SG-VAE & July 3, 2018 & Lu et al. (2018) & ✗ \\ BO+MCMC & April 10, 2017 & Gardner et al. (2017) & ✓ \\ Ensemble BO & March 31, 2018 & Wang et al. (2018) & ✓ \\ BOCK & March 3, 2018 & Oh et al. (2018) & ✓ \\ COMBO & December 8, 2019 & Oh et al. (2019) & ✓ \\ MGPC-BO & September 1, 2020 & Moriconi et al. (2020a) & ✓ \\ G-STAR & December 1, 2016 & Pedrielli and Ng (2016) & ✗ \\ CASMOPOLITAN & June 18, 2021 & Wan et al. (2021) & ✓ \\ Vanilla BO & February 25, 2024 & Hvarfner et al. (2024) & ✓ \\ Bounce & July 2, 2023 & Papenmeier et al. (2024) & ✓ \\ EGP & August 7, 2017 & Rana et al. (2017) & ✗ \\ CoBO & December 10, 2023 & Lee et al. (2023) & ✓ \\ DSO & February 27, 2024 & Kong et al. (2024) & ✗ \\ MPD & January 16, 2023 & Nguyen et al. (2022) & ✓ \\  

#### a.1.1 On how HDBO can be applied to discrete sequences

Fig. 4 shows an overview of the different ways in which HDBO could be applied to discrete sequences. On the left, we have the original sequence space with inputs being a list of categorical variables belonging to some alphabet; methods like Bounce, Prob. Rep and those that work on mixed/categorical inputs in the _Structured Spaces_ family (see Sec. 3.7) work in this space. Since the original sequence space is large for the problems we are interested in, several other methods rely on subspaces from the original problem. Such subspaces can be constructed either as linear projections (Sec. 3.4) or as

 GIBO & November 22, 2021 & Müller et al. (2021) \\ PR & October 18, 2022 & Daulton et al. (2022b) \\ RPP & May 9, 2016 & Li et al. (2016) \\ MCTS-VS & October 31, 2022 & Song et al. (2022) \\ Standard BO & February 5, 2024 & Xu and Zhe (2024) \\ Scalable FOBO & June 16, 2022 & Ament and Gomes (2022) \\ FOBO & December 6, 2017 & Ahmed et al. (2016) \\ BOSS & October 2, 2020 & Moss et al. (2020) \\ SILBO & May 29, 2020 & Chen et al. (2020) \\ SCoreBO & April 21, 2023 & Hvarfner et al. (2023) \\ HEBO & December 7, 2020 & Cowen-Rivers et al. (2022) \\ Tree Add-GP-UCB & May 1, 2021 & Han et al. (2021) \\ SIR/SDR & July 21, 2019 & Zhang et al. (2019) \\ GaBO & November 22, 2021 & Jaquier et al. (2020) \\ ECI & April 18, 2024 & Zhan (2024) \\ MAVE-BO & March 8, 2024 & Hu et al. (2024) \\ CMA-BO & February 5, 2024 & Ngo et al. (2024) \\ RTDK-BO & October 5, 2023 & Shmakov et al. (2023) \\ PG-LBO & December 28, 2023 & Chen et al. (2024) \\ TSBO & May 4, 2023 & Yin et al. (2024) \\ BODi & March 3, 2023 & Deshwal et al. (2023) \\ Mahismobis BatchBO & November 2, 2022 & Horiguchi et al. (2022) \\ KPCA-BO & April 28, 2022 & Antonov et al. (2022) \\ PCA-BO & July 2, 2020 & Raponi et al. (2020) \\ DSA & November 18, 2015 & Ulmasov et al. (2016) \\ RPA-GP & June 12, 2020 & Delbridge et al. (2020) \\ HD-GaBO & December 6, 2020 & Jaquier and Rozo (2020) \\ Amortized BO & May 27, 2020 & Swersky et al. (2020) \\ d-KG & December 4, 2017 & Wu et al. (2017) \\ Prabuchandra’s FOBO & March 1, 2021 & Penubothula et al. (2021) \\ AlgFOO & March 18, 2021 & Shekhar and Javidi (2021) \\ GTBO & October 5, 2023 & Hellsten et al. (2023) \\ CoCaBo & June 12, 2020 & Ru et al. (2020) \\ MercBO & February 2, 2019 & Deshwal et al. (2021b) \\ HyBO & July 18, 2021 & Deshwal et al. (2021a) \\ BOCS & July 10, 2018 & Baptista and Poloczek (2018) \\ LaMBO & July 22, 2022 & Stanton et al. (2022) \\ LaMBO-2 & December 12, 2023 & Gruver et al. (2023) \\ G.M. \& Lobato & March 1, 2020 & Garrido-Merchan and Hernández-Lobato (2020) \\ BOHAMIANN & December 5, 2016 & Springenberg et al. (2016) \\ AIBO & February 16, 2023 & Zhao et al. (2024) & ✓ \\ CoRel & April 26, 2024 & Michael et al. (2024) & ✓ \\ VAE-BO+Inv & July 22, 2022 & Verma et al. (2022) & ✗ \\ Uncert & November 09, 2021 & Notin et al. (2021) & ✓ \\ GAUCHE & September 21, 2023 & Griffiths et al. (2023) & ✓ \\ LLMs & July 21, 2024 & Kristiadi et al. (2024) & ✓ \\ AntBO & January 23, 2023 & Khan et al. (2023) & ✓ \\ RMF & May 20, 2022 & Kim et al. (2022) & ✗ \\  

Table 4: References for the methods presented in the taxonomylearned non-linear latent variables (Sec. 3.5). Once a latent continuous representation is available, all other families in the taxonomy become available and could be leveraged for latent space optimization. In these cases, there is usually a mapping between the subspace and the original high-dimensional space which allows for computing objective functions. In the linear case an up-projection is given by multiplying with a matrix of the right shape, and in the case of non-linear representations it is usually a decoding process.

In this paper, we explore applying the discrete optimizers of the _Structured Spaces_ family in the sequence spaces of several Ehrlich problems (Sec. 4.2.1), as well as small molecule optimization using SELFIES representations. The continuous optimizers chosen from the other families are applied directly in one-hot space in the case of Ehrlich, or in the latent space of a Variational Autoencoder learned for SELFIES strings (Sec. 4.2.2).

### Reproducing results

Bounce.We forked the official open source implementation of Bounce8 and added an interface between poli's black boxes and their optimizer. Moreover, we made their implementation pip-installable. Bounce's implementation is originally provided with an MIT license.

Probabilistic Reparametrizationprovides an open-source implementation built on GPyTorch and BoTorch.9 They provide a pip installable Python package which did not install until the dependencies mentioned above were fixed (to 1.11 and 0.7 respectively); further, the environment provided had to be updated by replacing the deprecated scikit-learn installation in a fork of their repository. After implementing an interface for poli black boxes, we relied on their script run_one_replication.py to implement a custom solver. The original PR code is provided with an MIT License.

SAASBO, Hvarfner's Vanilla BOwere all implemented by following the tutorials in Ax. Ax provides models for SAASBO, and we implemented a BoTorch model following the original implementation. We also provide an implementation of ALEBO using Ax. Ax is provided with an MIT License, and Hvarfner's original code does not have a license in GitHub yet.

Turbo was implemented by following the tutorial on BoTorch,10 which can be found on GitHub under MIT License.

Figure 4: Overview of problem-space (x-axis) and how the categories act on the space. The black box ultimately maps from the discrete sequences of alphabet elements to a real value. The BO methods can act on the original (discrete) space, linear or non-linear mappings of it or selected variables of the input space or a mapping of it. These continuous versions can also accommodate one-hot representations.

#### b.2.2 BAxUS

is implemented using the Python package provided by the authors.11 Since their work builds on the original TuRBO code from Uber, it inherits their license.

#### a.3 Training VAEs on SELFIES

Models.We use PyTorch to implement a VAE with [one_hot_input, 1024, 512, 256, latent_dim] encoder and a symmetric decoder, using ReLU activations. The latent space prior used is a standard Gaussian, and the decoded distribution is a categorical. We use torch.distributions to compute ELBO losses without any \(\) weighting.12

Training regimes.We train for a maximum of 1000 epochs using early stopping with a patience of 50 epochs. Our batch sizes are \(512\), learning rates are \(5 10^{-4}\), and optimizer is AdamW.13

### Technical details on poli and poli-baselines

This section gives a short overview on the possibilities of poli and poli-baselines. For further information please refer to the full online documentation under https://machinelearninglifescience.github.io/poli-docs/.

Figure 5: poli’s isolation process for complex environmentsThe aim of poli is to make it easier to benchmark new algorithms on new problems. There are three components to our framework: **problems** created by problem factories which contain black boxes, **solvers** that optimize these problems (aiming always at maximization), and **observers** which get attached to black boxes and log every single black box call. Fig. 5 shows these three components and their relationships. poli provides a unified numpy (Harris et al., 2020) interface, with inputs being numpy arrays of strings, and outputs being numpy arrays of floats. Finally, poli makes sure to log every call to the black box, as well as handling evaluation budgets--**function calls are measured transparently and consistently across algorithms**.

A major issue on the endeavour of benchmarking on new problems are often conflicting package dependencies. When evaluating a brand-new solver on an older benchmark problem, it can simply be impossible to create a Python environment in which both can run. One may re-implement one or the other, though this is not only cumbersome but also error-prone. With the isolation mechanisms provided by poli this is no longer a problem. In particular, the isolation of the different components in the system (the black box, or the observer that is used for logging) allows an easy comparison to additional algorithms or on other problems, without the need to change plotting scripts.

Listing 1 shows the general workflow:14 a user instantiates a black box by calling create with the corresponding black box's name, and the name of an observer. poli then takes care that both black box and observer are instantiated, in different conda environments if necessary. create returns an object inheriting from Problem which provides access to all things necessary: the black box function, initial observations, the observer and problem information like the alphabet and if sequences are aligned or not.15 The black box is a function that takes and returns a numpy array, and the observer is informed automatically of any such calls. Each component of this workflow (black box, algorithm, and observer) can be easily exchanged by user-developed classes more specifically tailored to the need at hand. We refer to our online documentation16 for the most recent information on how to do this.

To analyze an experiment a user has to define an observer, inheriting from AbstractObserver. Listing 2 shows how to quickly set up a simple text-file logger. The philosophy is to define the quantities of interest independent of problem or algorithm. We provide standard observers, for example an mlflow observer, and we encourage users to implement their own, to log other metrics of interest. Just as black boxes, observers can run in isolation, such that the environment is independent of problem and, or solver, to facilitate consistent recording of metrics. Whenever observers can run directly in the same environment as the solver, they could be attached directly to the black box using the set_observer method. Listing 3 shows an example using the same workflow as above, and the SimpleObserver presented in listing 2.

To expand on the suite of available black boxes, the user has to implement a subclass of the core object of poli: AbstractBlackBox. The method to implement is _black_box, which takes as input an array of strings x (as well as an optional context), and outputs the result of evaluating it as an array of floats. Listing 4 shows an example code snippet. At run time, another user wanting to test an algorithm just imports the relevant black box object from poli's repository, and gets an interface to a dynamically instantiated black box potentially running in a different conda environment. The _call_ method then takes care of communication with the caller and logging to an observer. Some of these black boxes require additional assets (_e.g._ the weights of a neural network, or csv files). They are all either already provided or dynamically downloaded when the black box is used.

Optimization algorithms can be oblivious to any requirements a black box might have. Solvers have only access to the AbstractBlackBox interface. They communicate with the problem only indirectly via a local network socket provided by python's native multiprocessing library. This is the **isolation mechanism** that allows both algorithm and problem to run in different python environments.

#themainfunctioninstantiateproblems frompolimimortcreate
#anexamplesolverfrompoli-baselines frompoli_baselines.solvers.simple.random_mutationimport RandomMutation
#Tocreateaproblem,auserhashstoprovideitsname.
#Insomecases,furtherparametersneedtobespecified.
#Optionally,theusercanattachanobservrethroughits
#name,orbyusingtheproblem.black_box.set_observer
#method. problem=create( name="aloha", observername="", seed=0, observer_init_info={"CALLER":RandomMutation.__name__} )
#Theproblemholdstheblackbox,initialdata,
#andotherinformation. f,x0=problem.black_box,problem.x0
#Evaluatetheinitialinputsifdesired. y0=f(x0)
#poli-baselinessolverssimplytaketheblackbox... solver=RandomMutation(black_box=f,x0=x0,y0=y0)
#...andtherytosolve(maximize)theproblem. solver.solve(max_iter=1000)
#Ifdesired,analgorithmcanalsosendinformationotheobserver.
#problem.observer.log({"FO0","BAR"}) ```

Code Listing 1: For poli-integrated problems and algorithms setting up an experiment is easy. This listing shows an example of running an experiment using the create method. In the main document, you can find another example that imports the problem factories directly.

### Benchmark Introduction

#### a.5.1 Ehrlich functions

Ehrlich functions (Stanton et al., 2024) were proposed as a closed-form alternative to black boxes like FoldX or RaSP, which could potentially raise licensing issues and, before poli, were not readily available for querying. This section explains how Ehrlich functions are constructed and queried from a bird's eye view. The details can be found in the original paper.

These functions are procedurally generated from a random seed and hyperparameters like alphabet size \(||\), sequence length \(L\), number of motifs \(n_{m}\) and motif length \(l\). The following are the steps that are followed to construct the problem:

1. A sparse transition matrix \(A\) of size \(||||\) is constructed. This transition matrix spans a finite Markov chain: sequences in the problem are constructed by starting with a random symbol and following the probabilities determined by \(A\). The rows of this transition matrix are probability vectors which determine how likely it is to go from one symbol in the alphabet to another. Such a transition matrix needs to satisfy that (i) the probability of going from one symbol to itself is non-zero, and (ii) it is always possible to go from any symbol to any other symbol after following a sequence of finite steps (irreducibility). In other words, we need the Markov chain spanned by \(A\) to be ergodic. \(A\) defines the search space of feasible sequence: the fact that \(A\) is sparse means that some of the transitions are impossible.

``` frompathlibimportPath fromuuidiimportuuid4 importjson importnumpyasnp frompoli.core.black_box_informationimportBlackBoxInformation frompoli.core.util.abstract_observerimportAbstractObserver frompoli.core.registryimportregister_observer classSimpleObserver(AbstractObserver): #Theinitandinitialize_observermethods definitialize_observer( self, problem_setup_info:BlackBoxInformation, caller_info:object, seed:int, )->object: #Definingtheexperimentpath self.experiment_path=caller_info["experiment_path"]
#Savingthemetadataforthisexperiment metadata=problem_setup_info.as_dict()
#Savingthemitialevaluationsandseed metadata["seed"]=seed
#Savingthemetadata withopen(self.experiment_path/"metadata.json","w")asf: json.dump(metadata,f) defobserve(self,x:np.ndarray,y:np.ndarray,context=None)-> None: #Appendingtheseresultsoftheresultsfile. withopen(self.experiment_path/"results.txt","a")asfp:fp.write(f"{x.tolist()}") if__name__=='_main__': #Thispartneedstobeddonenlyonce. #polinetodesdownthelocationofthecurrentcondaenvironment, sothatifnecessary,theobserver canbeinstantiatedin isolation. register_observer( observer=SimpleObserver(),observer_name="simple_observer" ) ```

Code Listing 2: Observing an experiment 

#Creatingafreshproblemproblem=create( name="aloha", seed=0, )
#Gettingtheblackboxandinitialinput f,x0=problem.black_box,problem.x0
#Initializinganobserverobserver=SimpleObserver( observer.initialize_observer( problem_setup_info=f.info, caller_info={ "experiment_path":Path().parent, }, seed=0, )
#Settingit f.set_observer(observer)
#Evaluatetheinitialinputsifdesired. y0=f(x0)
#poli-baselinessolverssimplytaketheblackbox... solver=RandomMutation(black_box=f,x0=x0,y0=y0)
#...andthentrytosolve(maximize)theproblem. solver.solve(max_iter=1000) ```

Code Listing 3: Attaching an observer directly.

``` fromstringimportasci_uppercase importnumpyasnp frompoli.core.abstract_black_boximportAbstractBlackBox frompoli.core.black_box_informationimportBlackBoxInformation classOurAlohaBlackBox(AbstractBlackBox): #Theonlymethodyoumeedtodef def_black_box(self,x,context=None): matches=x==np.array(["A","L","0","H","A"]) returnnp.sum(matches,axis=1,keepdims=True) defget_black_box_info(self)->BlackBoxInformation: returnour_aloha_information#Couldbedynamic our_aloha_information=BlackBoxInformation( name="our_aloha", max_sequence_length=5, aligned=True, fixed_length=True, deterministic=True, alphabet=list(ascii_uppercase), discrete=True, ) f=OurAlohaBlackBox() f(np.array([["A","L","0","0","F"]]))#returns[] ```

Code Listing 4: Implementing a black box2. Once \(A\) has been constructed, \(n_{m}\) motifs of length \(l\) are sampled according to it by sampling a sequence of length \(n_{m} l\) and splitting it. This ensures that the motifs are feasible and easily within reach from one to the next.
3. These motifs are to be satisfied in certain positions in the string. These positions are constructed using random offsets of size \(l\). For example, the motif "ADER" with offsets of \(\) is satisfied if the sequence contains "ADXEXR" where "X" can be any other member of the alphabet: "D" is at distance 1 of "A", "E" is at a distance 3 of "A" and "R" is at distance 5 of "A". These random offsets are randomly constructed to maximize slackness in the sequence.

We take the original implementation17 and wrap our black box logic around it, making it compatible with solvers in poli-baselines. We also include a data package made by using the original utilities for sampling the underlying transition matrix.

#### a.5.2 Pmo

The _Practical Molecular Optimization_ (PMO) benchmark contains a representative set of tasks defined on small molecule inputs with respective computational oracles. The input to the black box functions are alphabet representation for small molecules as either tokenized SMILES (Weininger, 1988) or SELFIES (Krenn et al., 2020) (see below) for the exact alphabets used - in principle one can be converted into the other. While _small_ molecule sequences usually contain fewer elements in a sequence than for example proteins, the alphabet can contain more tokens making this yet another high dimensional discrete optimization space. We build upon the work by Gao et al. (2022), who propose molecular optimization focused on validity, diversity, synthesizability - using computational values for all metrics and a budget of 10.000 evaluations. The PMO suite itself is based on the existing benchmarks Guacamol (Brown et al., 2019), and elements of the TDC (Huang et al., 2021). The types of optimization tasks for small molecules can be differentiated into: optimizing for simple metrics like QED, LogP18 qualitative tasks, such as scaffold hopping, rediscovery of particular substances (e.g. troglitazone), and more complex tasks such as docking surrogates and classifiers on fingerprint representations of molecules (GSK3, JNK3, DRD2) (Huang et al., 2021). We evaluate a selection of solvers across all tasks with multiple seeded runs on a fixed budget and report the average of the best observations, weighing all functions equally.19 Altogether, these tasks constitute a set of functions which can be optimized and which have previously been used to assess algorithm performance in the bio-chemical domain, allowing a comparisons to previous results and reported benchmarks. We make these environments accessible and solvable in a unified way through the poli infrastructure.

["[mpg]"The remaining solvers (BAxUS, Turbo and Bounce) ran in a Google Cloud instance with one Tesla T4 with 16Gb.

#### a.6.2 Pmo

HillClimbing, Hvarfner's VanillaBO, RandomLineBO, SAASB0 and ProbRep experiments ran in an HPC cluster on CPUs using equivalent SLURM scripts (max 24h of runtime).

Turbo ran on an M2 Max Mac with 32Gb of memory using MPS.

BAxUS and Bounce ran on a Deep Learning compute server using the marketplace solutions of Google Cloud Platform, using a Tesla T4 (approx. 16Gb of memory).