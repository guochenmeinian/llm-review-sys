# _ContextGS:_ Compact 3D Gaussian Splatting with Anchor Level Context Model

_ContextGS:_ Compact 3D Gaussian Splatting with Anchor Level Context Model

  
**Yufei Wang\({}^{1}\)** & **Zhihao Li\({}^{1}\)** & **Lanqing Guo\({}^{1}\)** & **Wenhan Yang\({}^{2}\)** & **Alex C. Kot\({}^{1}\)** & **Bihan Wen\({}^{1}\)** \\ \({}^{1}\) & \(\) & \({}^{2}\) & PengCheng Laboratory, China & & \\ \{yufei001, zhihao.li, lanqing.guo, eackot, bihan.wen}@ntu.edu.sg & yangwh@pcl.ac.cn & Homepage: https://github.com/wyf0912/ContextGS & & \\   

###### Abstract

Recently, 3D Gaussian Splatting (3DGS) has become a promising framework for novel view synthesis, offering fast rendering speeds and high fidelity. However, the large number of Gaussians and their associated attributes require effective compression techniques. Existing methods primarily compress 3D Gaussians individually and independently, _i.e._, coding all the 3D Gaussians at the same time, with little design for their interactions and spatial dependence. Inspired by the effectiveness of the context model in image compression, we propose the first autoregressive model at the anchor level for 3DGS compression in this work. We divide anchors into different levels and the anchors that are not coded yet can be predicted based on the already coded ones in all the coarser levels, leading to more

Figure 1: An illustration of the necessity of using autoregressive model in the anchor level. While Scaffold-GS  greatly reduces the spatial redundancy among adjacent 3D Gaussians by grouping them and introducing a new data structure _anchor_ to capture their common features, spatial redundancy still exists among anchors. Our method, **ContextGS**, first proposes to reduce the spatial redundancy among anchors using an autoregressive model. We divide anchors into levels as shown in Fig. (b) and the anchors from coarser levels are used to predict anchors in finer levels, _i.e._, \(\) predicts \(\) then \(\) together predict \(\). Fig. (c) verifies the spatial redundancy by calculating the cosine similarity between anchors in level 0 and their context anchors in levels \(1\) and \(2\). Fig. (d) displays the bit savings using the proposed anchor-level context model evaluated on our entropy coding based strong baseline built on Scaffold-GS . Compared with Scaffold-GS, we achieve better rendering qualities, faster rendering speed, and great size reduction of up to \(15\) times averaged over all datasets we used.

accurate modeling and higher coding efficiency. To further improve the efficiency of entropy coding, _e.g._, to code the coarsest level with no already coded anchors, we propose to introduce a low-dimensional quantized feature as the hyperprior for each anchor, which can be effectively compressed. Our work pioneers the context model in the anchor level for 3DGS representation, yielding an impressive size reduction of over 100 times compared to vanilla 3DGS and 15 times compared to the most recent state-of-the-art work Scaffold-GS, while achieving comparable or even higher rendering quality.

## 1 Introduction

Over the past few years, novel view synthetic has rapidly progressed. As a representative work, Neural Radiance Field (NeRF)  uses a Multilayer Perceptron (MLP) to predict the attributes of quired points in the 3D scene. While good rendering qualities are achieved, the dense querying process results in slow rendering, which greatly hinders their applications in practical scenarios. Significant efforts have been made to enhance training and rendering speeds, achieving notable progress through various techniques, such as factorization [4; 8; 10; 13] and hash grids [24; 12]. However, they still face challenges in the real-time rendering of large-scale scenes due to the intrinsic limitations of volumetric sampling. Recently, 3D Gaussian Splatting (3DGS)  has achieved state-of-the-art (SOTA) rendering quality and speed. As an emerging alternative strategy for representing 3D scenes, 3DGS represents a 3D scene using a set of 3D Gaussians initiated from Structure-from-Motion (SfM) with learnable attributes such as color, shape, and opacity. The 2D images can be effectively rendered using differentiable rasterization and end-to-end training is enabled. Meanwhile, benefiting from efficient CUDA implementation, real-time rendering is achieved.

Despite its success, 3DGS still encounters limitations in storage efficiency. Representing large scenes requires millions of 3D Gaussian points, which demand several GBs of storage, _e.g._, an average of 1.6 GB for each scene in the BungeeNert  dataset. The huge storage overhead greatly hinders the applications of 3DGS , thus an efficient compression technique is required. However, the unorganized and sparse nature of these 3D Gaussians makes it highly challenging to effectively reduce data redundancy. To address this issue, various techniques have been proposed to enhance the storage efficiency of 3D Gaussian models. For example, [7; 18; 25; 26] proposed to discretize continuous attributes of 3D Gaussians to a cluster of attributes stored in the codebooks; [7; 18] proposed to prune neural Gaussians with little effect. Entropy coding is also used to reduce the storage overhead by further encoding neural Gaussian features into bitstream [11; 5; 18; 23]. Although space utilization has greatly improved, they focus more on individually compressing each Gaussian point and do not well explore the relationship and reduce the spatial redundancy among neural Gaussians. To further reduce the spatial redundancy, most recently,  proposed to divide anchors into voxels and introduced an anchor feature for each voxel to grasp the common attributes of neural Gaussians in the voxel, _i.e._, the neural Gaussians are predicted by the anchor features. While the spatial dependency has been significantly reduced, as shown in Fig. 1 (c), the similarity among anchors remains high in certain areas, indicating that spatial redundancy still exists.

To further enhance the coding efficiency of 3D scenes, we propose a novel framework named _ContextGS_ for 3DGS compression. Inspired by the effectiveness of context models  in image compression , we introduce an autoregressive model at the anchor level into 3DGS. Specifically, building on Scaffold-GS , we divide anchors into hierarchical levels and encode them progressively. Coarser level anchors are encoded first, and their decoded values are used to predict the distribution of nearby anchors at finer levels. This approach leverages spatial dependencies among adjacent anchors, allowing already decoded anchors to better predict the distribution of subsequent anchors, leading to significant improvements in coding efficiency. Additionally, anchors decoded at coarser levels can be directly used in the final fine-grained level, reducing storage overhead. To further enhance coding efficiency, especially for encoding the coarsest level anchors without already decoded ones, we employ a quantized hyperprior feature as an additional prior for each anchor. It is worth noting that the proposed method can also support vanilla 3DGS renderers by simply removing the view-dependent features from the anchor feature. Our contributions can be summarized as follows:

* We propose the first context model for 3DGS at the anchor level. By predicting the properties of anchors that are not coded yet given already coded ones, we greatly eliminate the spatial redundancy among anchors.

* We propose a unified compressing framework with the factorized prior, enabling end-to-end entropy coding of anchor features. Besides, a strategy for anchor layering is proposed, which allows already decoded anchors to quickly locate adjacent anchors that are to be decoded. Meanwhile, the proposed method avoids redundant coding of anchors by the proposed anchor forward.
* The experimental results on real-world datasets demonstrate the effectiveness of the proposed method compared with SOTA and concurrent works. On average across all datasets, our model achieves a compression ratio of 15\(\) compared to the Scaffold-GS model we used as the backbone and 100\(\) compared to the standard 3DGS model, while maintaining comparable or even enhanced fidelity.

## 2 Related works

### Neural radiance field and 3D Gaussian splatting

Early 3D scene modeling often employs the Neural Radiance Field (NeRF)  as a global approximator for 3D scene appearance and geometry. These approaches [2; 29; 30] use a multi-layer perceptron (MLP) to implicitly represent the 3D scene by predicting attributes of queried points. However, the dense querying process results in extremely slow rendering. Various methods have been developed to speed up the rendering process significantly [6; 9; 27], such as plane factorization-based techniques like K-Planes  and TensoRF , and the use of hash grid features in InstantNGP . While these methods enable high-quality rendering with a much smaller MLP compared to the vanilla NeRF, rendering a single pixel still requires numerous queries. This can lead to increased storage requirements for the grid-based features and difficulties in efficiently rendering empty space or large-scale scenes. To achieve real-time and efficient rendering while maintaining high fidelity, 3DGS  introduces an innovative approach by representing the scene explicitly with numerous learnable 3D Gaussians. By employing differentiable splatting and tile-based rasterization , 3DGS  optimizes these Gaussians during training in an end-to-end manner.

### Deep compression

Despite the effectiveness of 3DGS  in rendering speed and fidelity, the large number of Gaussians and their associated attributes result in significant storage overhead. Many techniques are proposed to reduce the storage requirements of 3DGS. For example, [7; 18] proposes to prune neural Gaussians (aka 3D Gaussians) with minimal impact. [7; 18; 25; 26] propose to utilize codebooks to cluster Gaussian parameters. Entropy coding is also used in [11; 5; 18; 23] to encode neural Gaussians into bit streams by modeling their distributions. While remarkable performances are achieved, they mainly focus on improving the efficiency of a single neural Gaussian and neglect the spatial redundancy among neighbor neural Gaussians. Most recently, Scaffold-GS  proposes to introduce an anchor level to capture common features of nearby neural Gaussians in the same voxel, and successive work  demonstrates its effectiveness by further introducing hash-feature as a prior for entropy coding. However,  codes all the anchors at the same time, and its spatial redundancy can be further reduced. In the image compression task, an important category of methods to improve the coding efficiency is the context model [21; 31], which greatly reduces the spatial redundancy by predicting the distribution of latent pixels based on an already coded one. Inspired by the context models used in compression, we propose to encode the anchor features in an autoregressive way, _i.e._, predict the anchor points from already coded ones at coarser levels. As far as we know, we are the first to reduce the storage redundancy of 3DGS using a context model at the anchor level.

## 3 Preliminary

**3DGS** utilizes a collection of anisotropic 3D neural Gaussians to depict the scene so that the scene can be efficiently rendered using a tile-based rasterization technique. Beginning from a set of Structure-from-Motion (SfM) points, each Gaussian point is represented as follows

\[G()=e^{-(-)^{T}^ {-1}(-)},\] (1)

where \(\) is the coordinates in the 3D scene, \(\) and \(\) are the mean position and covariance matrix of the Gaussian point, respectively. To ensure the positive semi-definite of \(\), \(\) is represented as \(=^{T}^{T}\), where \(\) and \(\) are scaling and rotation matrixes, respectively. Besides, each neural Gaussian has the attributes of opacity \(^{1}\) and view-dependent color \(^{3}\) modeled by spherical harmonic . All the attributes, _i.e._, \([,,,,]\), in neural Gaussian points are learnable and optimized by the reconstruction loss of images rendered by the tile-based rasterization.

**Scaffold-GS .** While representing scenes with neural Gaussians greatly accelerates the rendering speed, the large amount of 3D Gaussians leads to significant storage overhead. To reduce the redundancy among adjunct 3D Gaussians, the most recent work, Scaffold-GS , proposes to introduce _anchor points_ to capture common attributes of local 3D Gaussians as shown in Fig. 2 (a). Specifically, the _anchor points_ are initialized from neural Gaussians by voxelizing the 3D scenes. Each anchor point has a context feature \(^{32}\), a location \(^{3}\), a scaling factor \(^{3}\) and \(k\) learnable offset \(^{k 3}\). Given a camera at \(_{c}\), anchor points are used to predict the view-dependent neural Gaussians in their corresponding voxels as follows,

\[\{^{i},^{i},^{i},^{i}\}_{i=0}^{k}=F( ,_{c},}_{c})\] (2)

where \(_{c}=||-_{c}||_{2}\), \(}_{c}=-_{c}}{||-_{c}||_{2}}\), the superscript \(i\) represents the index of neural Gaussian in the voxel, \(^{i},^{i}^{3}\) are the scaling and color respectively, and \(^{i}^{4}\) is the quaternion for rotation. The positions of neural Gaussians are then calculated as

\[\{^{0},...,^{k-1}\}=+\{^{0},...,^{k-1}\},\] (3)

where \(\) is the learnable positions of the anchor and \(\) is the base scaling of its associated neural Gaussians. After decoding the properties of neural Gaussians from anchor points, other processes are the same as the 3DGS . By predicting the properties of neural Gaussians from the anchor features and saving the properties of anchor points only, Scaffold-GS  greatly eliminates the redundancy among 3D neural Gaussians and decreases the storage demand.

## 4 Methodology

The overall framework is shown in Fig. 3. We first introduce how to divide anchors into levels with traceable mapping relationships among adjacent levels in Sec 4.1. Based on that, we present the entropy coding in an autoregressive way in Sec 4.2, and the overall training objective in Sec 4.3.

### Anchor partitioning strategy

We attempt to divide \(N\) anchors \(=\{_{i}\}_{i=0}^{N}=\{(_{i},_{i}, _{i},_{i})\}_{i=0}^{N}\) into \(K\) disjoint levels, _i.e._, \(=^{0}^{1}...^{K-1}\) and \(^{i}^{j}=\), \( i j\). For each anchor set \(^{i}\), it is expected to spawn over the whole scene, and be a relatively uniform downsampling of a finer set \(^{i-1}\). Assume that we encode/decode the scene using the order from level \(K-1\) to level \(0\) where level \(K-1\) is

Figure 2: **(a)**: An illustration of the data structure we used following Scaffold-GS , where anchor points are used to extract common features of their associated neural Gaussians. **(b)**: The proposed multi-level division of anchor points. The decoded anchors from higher (coarser) levels are directly forwarded to the lower (finer) level to avoid duplicate storage. Besides, taking decompression as an example, the already decoded anchors are used to predict anchors that are not decompressed yet, which greatly reduces the spatial redundancy among adjacent anchors. (Best zoom in for details.)

the coarsest level, we expect the mapping from \(^{i}\) to \(^{i-1}\) is traceable and easy to obtain. In other words, given an anchor \(^{k}_{i}=(^{k}_{i},^{k}_{i},^{k}_{i}, ^{k}_{i})\) from a coarser level \(k\), we expect to quickly locate \(^{k}_{i}\)'s adjacent anchor set \(\{^{k-1}_{i}\}_{i=0}^{N^{k-1}_{i}}\) in level \(k-1\), where \(N^{k-1}_{i}\) is the number of adjacent anchors, _i.e._, the anchors in the same voxel of level \(k-1\) with \(^{k}_{i}\). As such, after decoding anchors at a coarser level, we can scatter the already decoded features to to-be-processed anchors as the prior for better coding efficiency.

To achieve the requirements above, we propose to utilize a simple yet effective way to divide anchors into levels using a "bottom-up" method. As shown in Fig. 2 (b), given a set of anchors of the scene, we partition them into different fine-grained sets based on different voxel sizes \(_{i}\) as follows

\[}^{k}=\{M(\{^{k-1}_{i}:}^{k}_{i} =}\}):}\{}^{k}_{i}:i=1,2,...,|}^{k-1}|\}\},\] (4)

where \(||\) is the counting operation, \(}^{k}_{i}\) is the anchor position after quantization using the voxel size of level \(k\), and \(M:(}^{k-1})}^{k-1}\) (where \(\) is the power set) is a mapping function that selects a representative anchor to level \(k-1\) from a set of anchors \(\{^{k-1}_{i}:}^{k}_{i}=}\}\) that has the same position after quantization. The definition of \(}^{k}_{i}\) and \(M\) are as follows

\[}^{k}_{i}=^{k-1}_{i}}{ ^{k}}^{k},^{k-1}_{i}}^{k-1}\] (5) \[M(\{^{k-1}_{i}:}^{k}_{i}=}\})=^{k-1}_{j}j=\{i:}^{k}_{i}=}\},\]

where \(}^{0}\) is initialized as the whole anchor set \(\). We select the anchor with the minimum index \(\{i:}^{k}_{i}=}\}\) among a set of anchors in level \(k-1\) that are in the same voxel. Besides, we filter out the repeated anchors among different levels as follows

\[^{2}=}^{2},^{1}=}^{1} }^{2},^{0}=}^{0}}^{1}\] (6)

where \(\) is the set difference operation. We keep the voxel size \(_{0}\) of the finest level (level \(0\)) the same as the initial value \(\), and set the voxel size of level \(i\) to \(_{i}=_{i}\). Since different scenes have different initial voxel sizes and anchor point distributions, using a fixed set of voxel scaling parameters \(\{_{i}\}_{i=1}^{K}\) leads to a suboptimal performance. To avoid finetuning hyper-parameters for each scene, we propose to conduct a one-time parameter search after initializing anchors. Instead of

Figure 3: The overall framework of the proposed method includes three levels, _i.e._, \(K=3\), to encode the anchors. The decoded anchors from a coarser level \(i+1\) are used to encode the anchors in level \(i\). Besides, hyperprior features are used to predict the properties of anchors at all levels. For training, after finishing the coding of all levels, the anchor features after adaptive quantization are used to predict properties of neural Gaussians. The rendering loss is calculated and optimized together with the entropy coding loss \(_{entropy}\). For testing, after we decode anchor features from the bit stream, the rendering is exactly the same with Scaffold-GS  without introducing overhead.

directly setting the scale \(_{i}\), we set a target ratio between level \(i\) and \(i+1\) and expect \(^{i+1}|}{|^{i}|}\). Since \(|^{i}|\) decreases monotonically with \(_{i}\), we can easily and efficiently determine the values of \(\{_{i}\}_{i=1}^{K}\) using a binary search. We empirically find that the performance of models among different senses is relatively robust to the selection of \(\) (refer to Fig. 6).

### Coding with entropy models

After dividing the anchors into multi-levels, in this section, we discuss how we use the already decoded anchors to predict ones that are not decompressed yet and how to encode attributes of anchors to improve the coding efficiency.

**Context modeling in anchor levels.** To encode an anchor point \(_{i}=(_{i},_{i},_{i},_{i})\) into bitstreams efficiently using entropy coding, we need to estimate its distributions accurately. The core idea of the proposed method is to predict the properties of anchors additionally conditioned on already decompressed anchors. Taking the modeling of anchor feature \(_{i}^{k}\) from the anchor \(_{i}^{k}\) as an example, the details are as follows

\[p_{^{k}}(_{i}^{k}|_{i}^{k})=( (_{i}^{k},_{i}^{k})*(-_{i}^{k},_{i}^{k}))(_{i}^{k}), _{i}^{k},_{i}^{k},_{i}^{k}=F_{ _{i}}^{k}(_{i}^{k}),\] (7)

where \(F_{_{i}}^{k}\) is a MLP belonging to the level \(k\), and \(_{i}^{k}\) is the prior of the anchor \(_{i}^{k}\) as follows

\[_{i}^{k}=[_{i}^{k}] &k=K-1\\ [_{j}^{k+1};_{j}^{k+1};_{i}^{k }],&k<K-1,\] (8)

where \([]\) is the concatenation operation among the channel dimension, \(_{j}^{k+1},_{j}^{k+1}\) are the feature and scaling from the adjacent anchor \(_{j}^{k+1}\) in level \(k+1\) that are already decoded as shown in Fig. 2 (b).

**Hyperprior feature for anchor.** While introducing the position \(_{i}^{k}\) contributes to predicting the distribution of anchor features, it still lacks enough freedom to eliminate spatial redundancy. Therefore, we introduce a learnable hyperprior vector \(_{i}^{50/h_{c}}\) for each anchor \(_{i}\) where \(h_{c}\) is a hyper-parameter to control the length of the hyperprior features. The hyperprior \(_{i}\) is modeled using the non-parametric, fully factorized density model  as follows:

\[p_{}|}(}_{i}|)=_{j=0}^{50/ h_{c}-1}(p_{z_{j}^{j}|^{(j)}}(^{(j)})*(-,))(_{i}^{j}),\] (9)

where \(}_{i}\) represents \(_{i}\) with quantization noise, \(j\) is the channel index and \(\) is the network parameters for modeling the hyperprior. Since the hyperprior feature \(_{i}\) is quantized into integers \(}\) and jointly optimized to reduce the size of the bitstream, it only occupies a small portion of storage as shown in Table 4. The final prior for coding features of the anchor \(_{i}^{k}\) is \(}_{i}^{k}=[}_{i}^{k};_{ i}^{k}]\).

### Training objective

The training objective of the proposed method is to jointly optimize the bitrate of coded anchor features and rendering loss measured by SSIM and L1 loss. The final training loss is

\[=_{scaffold}+_{e}_{entropy}+_{m} _{m}\] (10)

where \(_{scaffold}\) is the training loss of , \(_{m}\) is the masking loss from  to regularize the masking loss of offsets of neural Gaussians \(_{v}\), and \(_{entropy}\) is the overall entropy loss that measures the cost of storing anchor properties defined as follows,

\[_{entropy}=[-_{2}p_{}|}( {}_{i}|)]+_{i=0}^{K-1}[-_{2}[_{\{^{k},^{k},^{k}\}}p_{}(_{i}|}_{i}^{k})]]\] (11)

where the first term measures the cost of coding the hyperprior feature while the second term is the cost of coding features of anchor points in all the levels, and \(}_{i}^{k}\) is the context feature that includes both the hyperprior feature \(_{i}^{k}\) and the feature from already coded nearby anchor in level \(k+1\) as illustrated in Eq. 8.

## 5 Experiments

### Implementation details

We build our method based on Scaffold-GS . The number of levels is set to \(3\) for all experiments and the target ratio among two adjacent iterations is \(0.2\). \(h_{c}\) is set to \(4\), _i.e._, the dimension of the hyper-prior feature is a fourth of the anchor feature dimension. For a fair comparison, the dimension of the anchor feature \(\) is set to \(50\) following  and we set the same \(_{m}=5e-4\). The setting of \(_{e}\) is discussed in Appendix A.3 since different values are used to evaluate different rate-distortion tradeoffs. For a fair comparison, we use the same training iterations with Scaffold-GS  and HAC , _i.e._, \(30000\) iterations. Besides, we use the same hyperparameters for anchor growing as Scaffold-GS  so that the final model has a similar or even smaller number of anchors, leading to faster rendering speed. More implementation details are in the supplementary materials.

### Comparison with baselines

**Baseline, metric, and benchmark.** We compare our method with 3DGS , Scaffold-GS  and some representative 3DGS compression works, including Compact3DGS , Compressed3D , EAGLES , LightGaussian , Morgenstern _et al._, Navaneet _et al._, and HAC . The baseline methods include existing mainstream techniques, _e.g._, pruning [7; 18], codebooks [7; 18; 25; 26], and entropy coding [11; 5; 18; 23], and includes the most recent works. We utilize PSNR, SSIM, and LPIPS  to evaluate the rendering qualities of different methods and report the storage size measured in MB. We evaluate the performance of the models on several real-scene datasets, including BungeeNeRF , DeepBlending , Mip-NeRF360 , and Tanks&Temples . To more comprehensively evaluate the performance of our method, following the previous prototype , we use all \(9\) scenes in Mip-NeRF360 . The detailed results of each scene are reported in the Appendix A.3. To further evaluate the performance models among a wide range of compression ratios, we use Rate-Distoration (RD) curves as an additional metric.

    &  &  &  &  \\  &  &  &  &  &  &  &  &  &  &  \\ 
3DGS  (SIGGRAPH+2) & 27.49 & **0.813** & 0.222 & 224.74 & 7.29 & 0.844 & 4.47 & 43.10 & 29.24 & 0.899 & 0.267 & 66.93 & 5.47 & 8.74 & 0.841 & 20.05 & 16.16 \\ Scaffold-GS  (CVPR-24) & 27.50 & 0.806 & 0.252 & 253.9 & 23.96 & 0.853 & 0.177 & 86.50 & 30.21 & 0.906 & 0.254 & 66.00 & 2.62 & 0.865 & 0.241 & 183.0 \\  EAGLES  & 27.15 & 0.58 & 0.238 & 0.238 & 58.93 & 24.80 & 0.230 & 34.00 & 23.40 & 0.872 & 0.919 & 0.260 & 25.00 & 2.52 & 0.24 & 0.843 & 0.22 & 117.7 \\ LightGaussian  & 27.00 & 0.790 & 0.294 & 44.54 & 23.80 & 0.822 & 0.242 & 22.71 & 0.872 & 0.308 & 33.94 & 24.52 & 0.825 & 0.258 & 57.28 \\ Computer3DGS  (CVPR-24) & 27.08 & 0.798 & 0.247 & 48.80 & 23.32 & 0.831 & 0.204 & 39.43 & 29.79 & 0.290 & 0.258 & 43.21 & 33.66 & 0.788 & 20.51 & 82.60 \\ Compressed3D  (CVPR-24) & 26.98 & 0.801 & 0.258 & 28.80 & 23.32 & 0.832 & 0.194 & 17.28 & 29.38 & 0.898 & 25.35 & 23.14 & 3.03 & 0.802 & 0.245 & 55.79 \\ Morgenstern _et al._ & 26.01 & 0.727 & 0.259 & 23.90 & 22.78 & 0.817 & 0.211 & 13.05 & 28.92 & 0.891 & 0.276 & 8.40 & - & - & - \\ Navaneet _et al._ & 27.16 & 0.808 & 0.228 & 0.237 & 20.347 & 0.840 & 0.188 & 27.97 & 29.75 & 0.293 & 0.294 & 24.27 & 24.63 & 0.823 & 0.293 & 104.3 \\ HAC  & 27.53 & 0.807 & 0.238 & 15.26 & 24.04 & 0.867 & 18.70 & 29.89 & 0.902 & 26.39 & 24.56 & 24.84 & 0.84 & 0.250 & 18.49 \\  Ours (low-rate) & 27.62 & 0.808 & 0.237 & 12.68 & 24.20 & 0.852 & 0.184 & 27.05 & 30.11 & 0.907 & 0.265 & 38.45 & 26.90 & 0.866 & 0.22 & 140.00 \\ Ours (high-rate) & 22.758 & 0.811 & 0.231 & 18.41 & 24.29 & 0.855 & 0.176 & 11.80 & 30.39 & 0.909 & 0.258 & 6.60 & 27.15 & 0.875 & 0.208 & 21.80 \\   

Table 1: The quantitative results obtained from the proposed method _ContextGS_ and other competitors. Baseline methods, namely 3DGS  and Scaffold-GS , are included for reference. The intermediary approaches are specifically designed for 3DGS compression. Our methodology showcases two results representing varying size and fidelity tradeoffs, achieved through adjustment of \(_{e}\). Highlighted in \(\) and \(\) cells are the best and second-best results, respectively. Size measurements are expressed in megabytes (MB).

Figure 4: The Rate-Distortion (RD) curves for quantitative comparison between our method with most recent SOTA competitors. It is worth noting that the x-axis is in \(\) scale for better visualization.

**Results.** As shown in Table 1, the proposed method achieves significant improvement compared to our backbone method Scaffold-GS  in terms of the size of the model, with a size reduction of \(15\) in average. Besides, the proposed method also achieves higher storage efficiency compared to the most recent competitors for the 3DGS compression, _e.g._, HAC , Compressed3D , and Compact3DGS . It is worth noting that the proposed method also significantly improves rendering quality, even compared with the backbone model we use, _i.e._, Scaffold-GS . This further verifies the observation from previous works that appropriate constraints on neural Gaussians can contribute to the rendering quality, _e.g._, entropy constraints  and pruning . Visual comparisons between the proposed method and other competitors are shown in Fig. 5. As shown in the figure, the proposed method achieves better rending quality with greatly reduced size compared with most recent 3D compression works and also the backbone model. Besides, a comparison of the RD curves among the proposed method and most recent competitors is shown in Fig. 4, where the proposed method achieves better performance in a wide range of compression ratios.

### Ablation studies and discussions

**Evaluation of target ratio \(\) among adjacent levels.** To evaluate the performance of the proposed strategy that encodes anchors in a progressive way, we evaluate the performance of models trained under different ratios among adjacent levels. We disable the hyperprior feature to better explore the effect of different target ratios \(\). As shown in Fig. 6, the PSNR remains relatively stable and the size gets relatively converged at the low ratio area. We select \(=0.2\) for all experiments.

**Ablation of each component.** We verify the effectiveness of two main components in our methods, _i.e._, anchor level context model and hyperprior features, and the results are shown in Table 2. We build all the models on Scaffold-GS  and set the model with the entropy constraint and the

    & Size (MB) & PSNR & SSIM & LPIPS \\  Scaffold-GS  & 183.0 & 26.62 & 0.865 & 0.241 \\  Ours w/o HP w/o CM & 18.67 & 26.93 & 0.867 & 0.222 \\ Ours w/o CM & 15.03 & 26.91 & 0.866 & 0.223 \\ Ours w/o HP & 15.41 & 26.92 & 0.867 & 0.221 \\ Ours & 14.00 & 26.90 & 0.866 & 0.222 \\   

Table 2: The ablation study of each component we proposed measured on BungeeNerf  dataset. “HP” and “CM” represent the **hyperprior** and anchor level context model respectively. Ours w/o HP w/o CM can be roughly regarded as a Scaffold-GS  model with entropy coding and masking loss .

Figure 5: Visual comparisons between our method and baselines including Scaffold-GS , HAC , and Compact3DGS  on Bungeenerf  and Tank&Temples . We report the PSNR (dB) of the image and the size of the 3D scene. (Best zoom in for details.)

Figure 6: The ablation of different target ratio \(\) among different scenes. The PSNR remains relatively stable while the size of the scenes keeps increasing when increasing the \(\), which demonstrates the effectiveness.

masking loss  as our baseline model, _i.e._, "Ours w/o HP w/o CM". It is worth noting that our baseline model significantly improves the storage efficiency compared with Scaffold-GS  and even the latest SOTA methods. Both the proposed anchor-level context model and hyperprior feature for anchors significantly improve the compression rate compared with our strong baseline model, reducing the file size by 21% and 10.17%, respectively. Besides, using them together can further boost the performance with storage savings of 26.1% and 92.5% compared with the baseline we introduced above and Scaffold-GS  respectively.

**Ablation of anchor forward.** A main difference between the proposed method and existing works for Level-of-Detail (LOD) techniques  is that the proposed method can reuse the anchors of different levels, _i.e._, anchor forward in Fig. 2 (b). For example, the anchors from different levels in  are stored separately. In contrast, the anchors from coarser levels are used in the final level (level 0) in our method, _i.e._, in an autoregressive manner. To verify the effectiveness of the proposed method that reuses the anchors in coarser levels, we do an ablation study in Table 3. As shown in the table, the model w/o reusing anchors of coarser levels to the finest level leads to serious redundancy, even slightly worse than the model w/o dividing anchors into different levels. This demonstrates the effectiveness of the proposed anchor forward technique for the anchor-level context model.

**Discussion on compressing anchor positions.** One can utilize the hyperprior feature \(\) to predict the distribution of anchor positions and the anchor position can thereby be compressed using entropy coding. However, we find that the precision of the anchor position is essential to the performance of the model and an adaptive quantization strategy leads to serious performance degradation. While a fixed quantization width is feasible and can retain the fidelity performance while effectively compressing the size of anchors, it leads to a greatly increased number of symbols that greatly decreases the coding speed. Since the anchor position only occupies a small portion of bitstreams as shown in Table 4, we do not encode anchors into bitstreams in all the experiments.

**Analysis of inference and decoding time.** The rendering speed after decompression is the same as or even faster than Scaffold-GS  when the number of anchors is the same since we use the same data structure. However, as shown in Table 4, we can achieve higher rendering quality with fewer anchors due to the use of masking loss  therefore achieving faster rendering speed. For the decoding time, while the proposed method involves autoregressive coding, which is usually very slow in image compression tasks  due to its serial characteristics, it adds neglectable overhead to our method in both training and decompression compared to other entropy-coding-based 3DGS compression methods, such as HAC . This is because, unlike autoregressive coding in image compression that predicts pixels/latent features one by one, introducing a loop of at least thousands of operations, we perform autoregressive coding group by group, introducing only a loop of 3 iterations. Additionally, there is no overlap of anchors among the coding of different levels, so the overall number of anchors to be processed remains the same as without dividing into levels.

    & Number of &  &  & Speed (s) \\   & Anchors (K) & Hyper & Position & Feature & Scaling & Offset & Mask & MLPs & Total & PSNR & SSIM & Encode & Decode \\  Scaffold-GS  & 61.9 & N/A & 7.08 & 75.16 & 14.18 & 70.88 & N/A & 0.047 & 184.4 & 26.25 & 0.872 & N/A & N/A \\ Ours (w/ APC) & 52.3 & 1.026 & **1.954** & 5.708 & 1.603 & 2.556 & 0.452 & 0.320 & **13.62** & 26.38 & 0.871 & 41.33 & 51.58 \\ Ours & 52.5 & 0.778 & 2.543 & 5.808 & 1.586 & 2.563 & 0.452 & 0.316 & 14.06 & 26.38 & 0.871 & **20.40** & **17.85** \\   

Table 4: The storage cost of each component and rending qualities of our method and baselines evaluated on the scene _rome_ in BungeeNeRF  dataset. “w/ APC” represents using **anchor** position coding, _i.e._, using the hyperprior features to code the anchor positions. (The encoding/decoding time is measured on an RTX3090.)

    & Size (MB) & PSNR & SSIM & LPIPS \\  Ours w/o dividing into levels & 14.73 & 26.91 & 0.867 & 0.222 \\ Ours w/o reusing anchors & 15.54 & 26.91 & 0.862 & 0.230 \\ Ours & 13.80 & 26.89 & 0.867 & 0.222 \\   

Table 3: The ablation study of our method w/ and w/o reusing anchors from coarser levels, _i.e._, anchor forward technique, measured on BungeeNerf  dataset.

Conclusion

In this work, we introduce a pioneer study into utilizing the anchor-level context model in the compression of 3D Gaussian splitting models. We divide anchors into different levels and the anchors from coarser levels are first coded and then used to predict anchors that are not coded yet. Additionally, a hyperprior feature is used for each anchor that further reduces the channel-wised redundancy. Besides, we demonstrate that utilizing the proposed anchor forward technique, _i.e._, directly reusing the anchors from coarse levels to the final level, can achieve better performance than just using anchors of coarse levels as a prior. Extensive experiments demonstrate that the proposed methods achieve better performance than SOTA and concurrent works.