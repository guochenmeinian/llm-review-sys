# Weak Supervision Performance Evaluation

via Partial Identification

 Felipe Maia Polo

Department of Statistics

University of Michigan

&Subha Maity1

Department of Statistics and Actuarial Science

University of Waterloo

Mikhail Yurochkin

MIT-IBM Watson AI Lab

&Moulinath Banerjee

Department of Statistics

University of Michigan

&Yuekai Sun

Department of Statistics

University of Michigan

Equal contribution. Corresponding author: Felipe Maia Polo <felipemiaapolo@gmail.com>

###### Abstract

Programmatic Weak Supervision (PWS) enables supervised model training without direct access to ground truth labels, utilizing weak labels from heuristics, crowd-sourcing, or pre-trained models. However, the absence of ground truth complicates model evaluation, as traditional metrics such as accuracy, precision, and recall cannot be directly calculated. In this work, we present a novel method to address this challenge by framing model evaluation as a partial identification problem and estimating performance bounds using Frechet bounds. Our approach derives reliable bounds on key metrics without requiring labeled data, overcoming core limitations in current weak supervision evaluation techniques. Through scalable convex optimization, we obtain accurate and computationally efficient bounds for metrics including accuracy, precision, recall, and F1-score, even in high-dimensional settings. This framework offers a robust approach to assessing model quality without ground truth labels, enhancing the practicality of weakly supervised learning for real-world applications.2

## 1 Introduction

Programmatic weak supervision (PWS) is a modern learning paradigm that allows practitioners to train their supervised models without the immediate need for ground truth labels \(Y\). In PWS, practitioners first acquire cheap and abundant weak labels \(Z\) through heuristics, crowdsourcing, external APIs, and pretrained models, which serve as proxies for \(Y\). Then, they fit a _label model_, _i.e._, a graphical model for \(P_{Y,Z}\), which, under appropriate modeling assumptions, can be fitted without requiring \(Y\)'s. Finally, a predictor \(h:\) is trained using samples \((X_{i},Z_{i})\)'s and a _noise-aware loss_ constructed using this fitted label model .

One major unsolved issue with the weak supervision approach is that even if we knew \(P_{Y,Z}\), evaluation metrics such as accuracy, recall, precision, or \(F_{1}\) cannot be estimated for model validation without any ground truth labels. In fact, these quantities are not identifiable (not uniquely determined) since we only have partial information about the joint distribution \(P_{X,Y}\) through the marginals \(P_{X,Z}\) and \(P_{Y,Z}\). As a consequence, any performance metric based on \(h\) cannot be estimated without making extra strong assumptions, _e.g._, \(X\!\!\! Y Z\). Unfortunately, these conditions are unlikely to arise in many situations. A recent work  investigated the role and importance of ground truth labels on model evaluation in the weak supervision literature. They determined that, under the current situation,the _good performance and applicability of weakly supervised classifiers heavily rely on the presence of at least some high-quality labels, which undermines the purpose of using weak supervision_ since models can be directly fine-tuned on those labels and achieve similar performance. Therefore, in this work, we develop new evaluation methods that can be used without any ground truth labels and show that the performance of weakly supervised models can be accurately estimated in many cases, even permitting successful model selection. Our solution relies on partial identification by estimating Frechet bounds for bounding performance metrics such as accuracy, precision, recall, and \(F_{1}\) score of classifiers trained with weak supervision.

**Frechet bounds:** Consider a random vector \((X,Y,Z)\) is drawn from an unknown distribution \(P\). We assume \(^{d}\) is arbitrary while \(\) and \(\) are finite. In this work, we develop and analyze the statistical properties of a method for estimating Frechet bounds [53; 54] of the form

\[L_{}_{}[g(X,Y,Z)]U _{}_{}[g(X,Y,Z)]\] (1.1)

when \(g\) is a fixed bounded function, with \(\) being the set of distributions \(\) for \((X,Y,Z)\) such that the marginal \(_{X,Z}\) (resp. \(_{Y,Z}\)) is identical to the prescribed marginal \(P_{X,Z}\) (resp. \(P_{Y,Z}\)). Our proposed method can efficiently obtain estimates for the bounds by solving convex programs, with the significant advantage that the computational complexity of our algorithm does not scale with the dimensionality of \(X\), making it well-suited for applications dealing with high-dimensional data. In previous work, for example, Frechet bounds were studied in the financial context (_e.g._, see Ruschendorf , Bartl et al. ). However, our focus is on applying our methods of estimating Frechet bounds to the problem of assessing predictors trained using programmatic weak supervision (PWS). For example, the upper and lower bounds for the accuracy of a classifier \(h\) can be estimated using our method simply by letting \(g(x,y,z)=[h(x)=y]\) in (1.1). At a high level, our method replaces \(P_{Y,Z}\) with the fitted label, and \(P_{X,Z}\) with its empirical version in the Frechet bounds in (1.1), and reformulates the problem in terms of a convex optimization problem.

**Contributions:** Our contributions are

1. Developing a practical algorithm for estimating the Frechet bounds in (1.1). Our algorithm can be summarized as solving convex programs and is scalable to high-dimensional distributions.
2. Quantifying the uncertainty in the computed bounds due to uncertainty in the prescribed marginals by deriving the asymptotic distribution for our estimators.
3. Applying our method to bounding the accuracy, precision, recall, and \(F_{1}\) score of classifiers trained with weak supervision. This enables practitioners to evaluate classifiers in weak supervision settings _without access to ground truth labels_.

### Related work

**Weak supervision:** With the emergence of data-hungry models, the lack of properly labeled datasets has become a major bottleneck in the development of supervised models. One approach to overcome this problem is using programmatic weak supervision (PWS) to train predictors in the absence of high-quality labels \(Y\)[50; 48; 47; 49; 58; 64]. PWS has shown the potential to solve a variety of tasks in different fields with satisfactory performance. For example, some works have applied weak supervision to named-entity recognition [32; 21; 57], video frame classification , bone and breast tumor classification . More recently, Smith et al.  proposed a new approach to integrating weak supervision and pre-trained large language models (LLMs). Rather than applying LLMs in the usual zero/few-shot fashion, they treat those large models as weak labelers that can be used through prompting to obtain weak signals instead of using hand-crafted heuristics. Recently, Zhu et al.  showed that in many situations, the success of weakly supervised classifiers depends on the availability of ground truth validation samples, undermining the purpose of weak supervision. Then, we develop a new method for model evaluation that does not depend on the availability of any ground truth labels.

A relevant line of research within the realm of weak supervision that is closely related to this work is adversarial learning [4; 5; 42; 41]. Often, adversarial learning aims to learn predictors that perform well in worst-case scenarios. For example, Mazzetto et al.  develops a method to learn weakly supervised classifiers in the absence of a good label model. In their work, the authors use a small set of labeled data points to constrain the space of possible data distributions and then find a predictor that performs well in the worst-case scenario. Our work relates to this literature in the sense that we are interested in the worst and best-case scenarios over a set of distributions. However, we focus on developing an evaluation method instead of another adversarial learning strategy.

**Partial identification:** It is often the case that the distributions of interest cannot be fully observed, which is generally due to missing or noisy data . In cases where practitioners can only observe some aspects of those distributions, _e.g._, marginal distributions or moments, parameters of interest may not be identifiable without strong assumptions due to ambiguity in the observable data. Partial identification deals with the problem without imposing extra assumptions. This framework allows estimating a set of potential values for the parameters of interest (usually given by non-trivial bounds) and has been frequently considered in many areas such as microeconometrics , causal inference , algorithmic fairness . Our work is most related to Ruschendorf , Bartl et al. , which study bounds for the uncertainty of a quantity of interest for a joint distribution that is only partially identified through its marginals, _i.e._, Frechet bounds. Compared to the aforementioned works, the novelty of our contribution is proposing a convex optimization algorithm that accurately estimates the Frechet bounds with proven performance guarantees in a setup that is realized in numerous weak-supervision applications.

### Notation

We write \(_{Q}\) and \(_{Q}\) for the expectation and variance of statistics computed using i.i.d. copies of a random vector \(W Q\). Consequently, \(_{Q}(A)=_{Q}_{A}\), where \(_{A}\) is the indicator of an event \(A\). If the distribution is clear by the context, we omit the subscript. If \((a_{m})_{m}\) and \((b_{m})_{m}\) are sequences of scalars, then \(a_{m}=o(b_{m})\) is equivalent to \(a_{m}/b_{m} 0\) as \(m\) and \(a_{m}=b_{m}+o(1)\) means \(a_{m}-b_{m}=o(1)\). If \((V^{(m)})_{m}\) is a sequence of random variables, then (i) \(V^{(m)}=o_{P}(1)\) means that for every \(>0\) we have \((|V^{(m)}|>) 0\) as \(m\), (ii) \(V^{(m)}=_{P}(1)\) means that for every \(>0\) there exists a \(M>0\) such that \(_{m}(|V^{(m)}|>M)<\), (iii) \(V^{(m)}=a_{m}+o_{P}(1)\) means \(V^{(m)}-a_{m}=o_{P}(1)\), (iv) \(V^{(m)}=o_{P}(a_{m})\) means \(V^{(m)}/a_{m}=o_{P}(1)\), and (v) \(V^{(m)}=_{P}(a_{m})\) means \(V^{(m)}/a_{m}=_{P}(1)\).

## 2 Estimating Frechet bounds

A roadmap to our approach follows. We first reformulate the Frechet bounds in (1.1) into their dual problems, which we discuss in (2.1). Then, we replace the non-smooth dual problems with their appropriate smooth approximations, as discussed in (2.2). Finally, we propose estimators for the smooth approximations (2.3) and derive their asymptotic distributions in Theorem 2.5.

### Dual formulations of the bounds and their approximations

This section presents a result that allows us to efficiently solve the optimization problems in (1.1) by deriving their dual formulations as finite-dimensional convex programs. Before we dive into the result, let us define a family of matrices denoted by

\[a^{||||}\ :\ _{y}a_{yz}=0z}.\]

With this definition in place, we introduce the dual formulation in Theorem 2.1.

**Theorem 2.1**.: _Let \(g:\) be a bounded measurable function. Then,_

\[L=_{a}[f_{l}(X,Z,a)]U=_{a }[f_{u}(X,Z,a)]\] (2.1)

_where_

\[f_{l}(x,z,a) _{}[g(x,,z)+a_{z} ]-_{P_{Y|Z}}[a_{Yz}|Z=z]\] \[f_{u}(x,z,a) _{}[g(x,,z)+a_{z} ]-_{P_{Y|Z}}[a_{Yz}|Z=z].\]

_Moreover, \(L\) and \(U\) are attained by some optimizers in \(\)._

Theorem 2.1 remains valid if we maximize/minimize over \(^{||||}\) instead of \(\). However, this is not necessary because the values of \(f_{l}\) and \(f_{u}\) remain identical for the following shifts in \(a\): \(a_{ z} a_{ z}+b_{z}\) where \(b_{z}\). By constraining the set of optimizers to \(\), we eliminate the possibility of having multiple optimal points. The proof of Theorem 2.1 is placed in Appendix B and is inspired by ideas from Optimal Transport; see Appendix A.

The computation of these bounds entails finding a minimum or maximum over a discrete set, meaning that straightforward application of their empirical versions could result in optimizing non-smooth functions, which is often challenging. To mitigate this, we consider a smooth approximation of the problem that is found to be useful in handling non-smooth optimization problems [3; 6]. We approximate the \(\) and \(\) operators with their "soft" counterparts:

\[\{b_{1},,b_{K}\}-[ _{k}(}{})],\ \ \{b_{1},,b_{K}\} [_{k}(}{})]\,,\]

where \(>0\) is a small constant that dictates the level of smoothness. As \(\) nears zero, these soft versions of \(\) and \(\) converge to their original non-smooth forms. Using these approximations, we reformulate our dual optimization in (2.1) into smooth optimization problems:

\[L_{}_{a}[f_{l,}( X,Z,a)]U_{}_{a}[f_{u,}(X,Z,a)]\] (2.2)

where

\[f_{l,}(x,z,a) -[|}_{y }(}{-})] -_{P_{Y|Z}}[a_{Yz} Z=z]\] \[f_{u,}(x,z,a) [|}_{y }(}{})]- _{P_{Y|Z}}[a_{Yz} Z=z]\]

and \(>0\) is kept fixed at an appropriate value. As a consequence of Lemma 5 of An et al. , we know that \(L_{}\) and \(U_{}\) are no more than \(||\) units from \(L\) and \(U\). Thus, that distance can be regulated by adjusting \(\). For example, if we are comfortable with an approximation error of \(10^{-2}\) units when \(||=2\), we will set \(=10^{-2}/(2).014\).

### Estimating the bounds

In practice, it is not usually possible to solve the optimization problems in (2.2), because we may not have direct access to the distributions \(P_{X,Z}\) and \(P_{Y|Z}\). We overcome this problem by assuming that we can estimate the distributions using an available dataset.

To this end, let us assume that we have a sample \(\{(X_{i},Z_{i})\}_{i=1}^{n}}}{{}}P_{X,Z}\), and thus we replace the relevant expectations with \(P_{X,Z}\) by its empirical version. Additionally, we have a sequence \(\{_{Y|Z}^{(m)},m\}\) that estimates \(P_{Y|Z}\) with greater precision as \(m\) increases. Here, \(m\) can be viewed as the size of a sample to estimate \(P_{Y|Z}\). Although the exact procedure for estimating the conditional distribution is not relevant to this section, we have discussed in our introductory section that this can be estimated using a _label model_[49; 22] in applications with weak supervision or in a variety of other ways for applications beyond weak supervision. Later in this section, we will formalize the precision required for the estimates. To simplify our notation, we omit the superscript \(m\) in \(_{Y|Z}^{(m)}\), whenever it is convenient to do so.

Thus, the Frechet bounds are estimated as

\[_{}=_{a}_{i=1}^{n}_{l,}(X_{i},Z_{i},a)\ \ \ _{}=_{a}_{i=1}^{n} _{u,}(X_{i},Z_{i},a)\] (2.3)

where

\[_{l,}(x,z,a) -[|}_{y }(}{-})]- _{_{Y|Z}}[a_{Yz} Z=z]\] \[_{u,}(x,z,a) [|}_{y }(}{})]- _{_{Y|Z}}[a_{Yz} Z=z]\]

In our practical implementations we eliminate the constraint that \(_{y}a_{yz}=0\) for all \(z\) by adding a penalty term \(_{z}(_{y}a_{yz})^{2}\) to \(_{}\) (and its negative to \(_{}\)) and then solve unconstrained convex programs using the L-BFGS algorithm . Since the penalty term vanishes only when \(_{y}a_{yz}=0\) for all \(z\), we guarantee that the optimal solution is in \(\).

### Asymptotic properties of the estimated bounds

In the following, we state the assumptions required for our asymptotic analysis of \(_{}\) and \(_{}\). We start with some regularity assumptions.

**Assumption 2.2**.: \(L_{}\) _and \(U_{}\) are attained by some optimizers in \(\) (2.2)._

**Assumption 2.3**.: _Let \(\) represent the optimizer for any problem in (2.3), which is assumed to exist. Suppose \(\|\|_{}=_{P}(1)\) as \(m\)._We show in Lemmas C.4, C.5, and C.6 that Assumptions 2.2 and 2.3 can be derived in the binary classification case (\(||=2\)) if \((Y=y Z=z)\) is bounded away from both zero and one, _i.e._\(<(Y=y Z=z)<1-\) for some \(>0\) for every \(y\) and \(z\).

In our next assumption, we formalize the degree of precision for the sequence \(\{_{Y|Z}^{(m)},m\}\) of estimators that we require for desired performances of the bound estimates.

**Assumption 2.4**.: _Denote the total variation distance (TV) between probability measures as \(d_{}\). For every \(z\), for some \(>0\), we have that \(d_{}_{Y|Z=z}^{(m)},P_{Y|Z=z}=_{P}( m^{-})\)._

From Ratner et al. 's Theorem 2 and a Lipschitz property of the label model3, we can conclude \(=1/2\) for a popular label model used in the PWS literature. The asymptotic distributions for the estimated bounds follow.

**Theorem 2.5**.: _Assume 2.2, 2.3, and 2.4, and let \(n\) be a function of \(m\) such that \(n\) and \(n=o(m^{2})\) when \(m\). Then, as \(m\)_

\[(_{}-L_{}) N(0,_{l, }^{2})(_{}-U_{})  N(0,_{u,}^{2})\]

_where \(_{l,}^{2}f_{l,}(X,Z,a_{l, }^{*})\), \(_{u,}^{2}f_{u,}(X,Z,a_{u, }^{*})\), and \(a_{l,}^{*}\) and \(a_{u,}^{*}\) are the unique optimizers to attain \(L_{}\) and \(U_{}\) (2.2)._

Theorem 2.5 tells us that, if the label model is consistent (Assumption 2.4), under some mild regularity conditions (Assumption 2.2 and 2.3), our estimators and will be asymptotically Gaussian with means \(L_{}\) and \(U_{}\) and variances \(_{l,}^{2}/n\) and \(_{u,}^{2}/n\). The above theorem requires \(m^{2}\) to grow faster than \(n\) implying that, through assumption 2.4, \(P_{Y|Z}\) is estimated with a precision greater than the approximation error when we replace \(P_{X,Z}\) with \(_{i}_{X_{i},Z_{i}}\). In the case which \(=1/2\), this condition translates to \(n/m 0\) as \(n\). This allows us to derive the asymptotic distribution when combined with classical results from M-estimation (see proof in Appendix C).

**Construction of confidence bounds:** One interesting use of Theorem 2.5 is that we can construct an approximate confidence interval for the estimates of the bounds. For example, an approximate \(1-\) confidence interval for \(L_{}\) can is constructed as

\[=_{}-_{l, }}{},\ \ _{}+_{l, }}{},\]

where \(_{}=^{-1}(1-/2)\) and \(_{l,}\) is the empirical standard deviation of \(f_{l,}(X,Z,)\), substituting the estimate \(\) (solution for the problem in 2.3). For such interval, it holds \(L_{} 1-\), _i.e._, with approximately \(1-\) confidence we can say that the true \(L_{}\) is in the interval above. An interval for \(U_{}\) can be constructed similarly.

## 3 Evaluation of model performance in weak supervision

In this section, we describe how to use the ideas presented in Section 2 to estimate non-trivial bounds for the evaluation metrics of a weakly supervised classifier \(h\) when no high-quality labels are available. In the standard weak supervision setup, only unlabeled data (\(X\)) is available, but the practitioner can extract weak labels (\(Z\)) from the available data. More specifically, we assume access to the dataset \(\{(X_{i},Z_{i})\}_{i=1}^{m}\), i.i.d. with distribution \(P_{X,Z}\), used in its entirety to estimate a label model \(_{Y|Z}\)[49; 22] and where part of it, _e.g._, a random subset of size \(n\), is used to estimate bounds4. To simplify the exposition, we assume the classifier \(h\) is fixed5.

### Risk and accuracy

Let \(\) be a generic classification loss function. The risk of a classifier \(h\) is defined as \(R(h)=[(h(X),Y)]\), which cannot be promptly estimated in a weak supervision problem, where we do not observe any \(Y\). In this situation, we can make use of our bound estimators in Section 2.2, where we set \(g(x,y,z)=(h(x),y)\) to obtain bounds for \(R(h)\). Furthermore, we can estimate an uncertainty set for the accuracy of the classification simply by letting \(g(x,y,z)=[h(x)=y]\).

### Precision, recall, and \(F_{1}\) score

For a binary classification problem, where \(=\{0,1\}\), the precision, recall, and \(F_{1}\) score of a classifier \(h\) are defined as

\[p(Y=1 h(X)=1)=(h(X)=1,Y= 1)}{(h(X)=1)},\;\;r(h(X)=1 Y=1)=(h(X)=1,Y=1)}{(Y=1)},\] \[F+p^{-1}}=(h(X)=1,Y= 1)}{(h(X)=1)+(Y=1)}\,.\]

The quantities \((h(X)=1)\) and \((Y=1)\) in the above definitions are identified, since the marginals \(P_{X,Z}\) and \(P_{Y,Z}\) are specified in the Frechet problem in (1.1). The \((h(X)=1)\) can be estimated from the full dataset \(\{(X_{i},Z_{i})\}_{i=1}^{m}\) simply using \(}(h(X)=1)_{i=1}^{m}[h(X_{ i})=1]\). On the other hand, in most weak supervision applications, \((Y=1)\) is assumed to be known from some prior knowledge or can be estimated from an auxiliary dataset, _e.g._, using the method described in the appendix of Ratner et al. . Estimating or knowing \((Y=1)\) is required to fit the label model  in the first place, so it is beyond our scope of discussion. Then, we assume we have an accurate estimate \(}(Y=1)\).

The probability \((h(X)=1,Y=1)\), which is the final ingredient in the definition of precision, recall, and F1 score is not identifiable as \(P_{X,Y}\) is unknown. The uncertainty bounds for this quantity can be estimated using our method simply by letting \(g(x,y,z)=[h(x)=1y=1]\). Let \(_{}\) and \(_{}\) denote the estimated lower and upper bounds for \((h(X)=1,Y=1)\) obtained using (2.3). Naturally, the lower bound estimators for precision, recall, and \(F_{1}\) score are

\[_{l,}_{}}{(h(X )=1)},\;_{l,}_{}}{ (Y=1)},_{l,}_{ }}{(h(X)=1)+(Y=1)}\,,\]

while the upper bound estimators \(_{u,}\), \(_{u,}\), and \(_{u,}\) are given by substituting \(_{}\) by \(_{}\) above. In the following corollary, we show that the bounds converge asymptotically to normal distributions, which we use for calculating their coverage bounds presented in our applications.

**Corollary 3.1**.: _Let \(n\) be a function of \(m\) such that \(n\) and \(n=o(m^{(2) 1})\) when \(m\). Assume the conditions of Theorem 2.5 hold. Then as \(m\)_

\[_{l,}-p_{l,}  N(0,_{p,l,}^{2})p_{l,}=}{(h(X)=1)},\; _{p,l,}^{2}^{2}}{ (h(X)=1)^{2}},\] \[_{l,}-r_{l,}  N(0,_{r,l,}^{2})r_{l,}=}{(Y=1)},\;_{r,l}^{2} ^{2}}{(Y=1)^{2}},\] \[_{l,}-F_{l,}  N(0,_{F,l,}^{2})F_{l,}=}{(h(X)=1)+(Y=1)} \;\&\;_{F,l,}^{2}^{2} }{[(h(X)=1)+(Y=1)]^{2}},\]

_where \(L_{}\), \(_{l,}^{2}\) are defined in Theorem 2.5. Asymptotic distributions for \(_{u,}-p_{u,}\), \(_{u,}-r_{u,}\), and \(_{u,}-F_{u,}\) are obtained in a similar way by changing \(L_{}\) to \(U_{}\) and \(_{l,}^{2}\) to \(_{u,}^{2}\)._

Reiterating our discussion in the final paragraph in Section 2.2, asymptotic distributions are important for constructing confidence intervals for the bounds, which can be done in a similar manner.

## 4 Experiments

All experiments are structured to emulate conditions where high-quality labels are inaccessible during training, validation, and testing phases, and all weakly-supervised classifiers are trained using the noise-aware loss . To fit the label models, we assume \(P_{Y}\) is known (computed using the training set). Unless stated, we use \(l_{2}\)-regularized logistic regressors as classifiers, where the regularization strength is determined according to the validation noise-aware loss.

**Wrench datasets:** To carry out realistic experiments within the weak supervision setup and study accuracy/F1 score estimation, we utilize datasets incorporated in Wrench (**W**eak Supervision **B**enchmark) . This standardized benchmark platform features real-world datasets and pre-generated weak labels for evaluating weak supervision methodologies. Most of Wrench's datasets are designed for classification tasks, encompassing diverse data types such as tabular, text, and image; all contain their pre-computed weak labels. Specifically, we utilize Census , YouTube , SMS , IMDB , Yelp , AGNews , TREC , Spouse , SemEval , CDR , ChemProt , Commercial , Tennis Rally , Basketball . For text datasets, weemploy the paraphrase-MiniLM-L6-v2 model from the _sentence-transformers_6 library for feature extraction . Features were extracted for the image datasets before their inclusion in Wrench.

**Hate Speech Dataset :** This dataset contains sentence-level annotations for hate speech in English, sourced from posts from white supremacy forums. It encompasses thousands of sentences classified into either Hate (1) or noHate (0) categories. This dataset provides an ideal ground for examining recall and precision estimation. Social media moderators aim to maximize the filtering of hate posts, _i.e._, increasing recall, while ensuring that non-hate content is rarely misclassified as offensive, maintaining high precision. Analogously to the Wrench text datasets, we utilize paraphrase-MiniLM-L6-v2 for feature extraction.

### Bounding the performance of weakly supervised classifiers

In this section, we conduct an empirical study using some of the Wrench and Hate Speech datasets to verify the validity and usefulness of our methodology. We compare results for which \(P_{Y|Z}\) is estimated using the true labels \(Y\) ("Oracle") and those derived using Snorkel's  default label model with no hyperparameter tuning and a thousand epochs. Such a comparison facilitates an evaluation of our method's efficacy, especially in cases where the label model could be incorrectly specified. Results for other Wrench datasets and one extra label model (FlyingSquid, ) are presented in Appendix F.

In Figure 1, we demonstrate our approaches for bounding test metrics, such as accuracy and F1 score (shown in green), when no true labels are available to estimate performance at various classification thresholds for binary classification tasks on Wrench datasets. In the first row ("Oracle"), true labels are used to estimate the conditional distribution \(P_{Y|Z}\), representing a (close to) ideal scenario with a well-specified label model. In the second row ("Snorkel"), however, we use a label model to estimate \(P_{Y|Z}\) without relying on any true labels. Despite potential inaccuracies in Snorkel's label model, it achieves results close to those obtained using true labels to estimate \(P_{Y|Z}\), yielding approximate but useful bounds. This indicates that even if Snorkel's label model is imperfectly specified, its effectiveness in estimating bounds remains similar to that of the "Oracle" approach, underscoring the value of bounding metrics regardless of label model accuracy. Delving deeper into Figure 1, results for "youtube", "commercial", and "tennis" highlight that our uncertainty about out-of-sample performance is small, even without labeled samples. However, there is a noticeable increase in uncertainty for "imdb" and "cdr", making weakly supervised models de

   Dataset & Lab model & Lo. bound & Up. bound & Test acc \\   & Oracle & \(0.46_{ 0.01}\) & \(0.95_{ 0.01}\) & \(0.80_{ 0.01}\) \\  & Snorkel & \(0.42_{ 0.01}\) & \(0.9_{ 0.01}\) & \(0.76_{ 0.01}\) \\   & Oracle & \(0.54_{ 0.04}\) & \(0.78_{ 0.03}\) & \(0.72_{ 0.04}\) \\  & Snorkel & \(0.36_{ 0.03}\) & \(0.70_{ 0.03}\) & \(0.56_{ 0.04}\) \\   

Table 1: Bounding accuracy in multinomial classification.

Figure 1: We apply our method to bound test metrics such as accuracy and F1 score (in green) when no true labels are used to estimate performance. In the first row (“Oracle”), we use true labels to estimate the conditional distribution \(P_{Y|Z}\), thus approximating a scenario in which the label model is reasonably specified. On the second row (“Snorkel”), we use a label model to estimate \(P_{Y|Z}\) without access to any true labels. Despite potential misspecification in Snorkel’s label model, it performs comparably to using labels to estimate \(P_{Y|Z}\), giving approximate but meaningful bounds.

additional validation. Yet, the bounds retain their informative nature. For instance, for those willing to accept the risk, the "imdb" classifier's ideal threshold stands at \(.5\). This is deduced from the flat worst-case and peaking best-case accuracy at this threshold. Table 1 presents some results for "agnews" (4 classes) and "semeval" (9 classes). From Table 1, we can see that both "Oracle" and "Snorkel" approaches produce valid bounds.

Now, we present bounds on the classifiers' precision and recall across different classification thresholds for the hate speech dataset. This dataset did not provide weak labels, so we needed to generate them. We employed four distinct weak labelers. The initial weak labeler functions are based on keywords and terms. Should words or phrases match those identified as hate speech in the lexicon created by Davidson et al. , we categorize the sentence as \(1\); if not, it's designated \(0\). The second weak labeler is based on TextBlob's sentiment analyzer : a negative text polarity results in a \(1\) classification, while other cases are labeled \(0\). Our final pair of weak labelers are language models, specifically BERT  and RoBERTa , that have undergone fine-tuning for detecting toxic language or hate speech [35; 28]. Figure 2 presents both recall and precision bounds and test estimates for the weakly-supervised hate speech classifier. Mirroring observations from Figure 1, Snorkel's standard label model gives valuable bounds analogous to scenarios where we employ labels to estimate \(P_{Y|Z}\). If used by practitioners, Figure 2 could help trade-off recall and precision by choosing an appropriate classification threshold in the absence of high-quality labels.

### Choosing a set of weak labels

In this experiment, we examine how our approach performs under the influence of highly informative weak labels as opposed to scenarios with less informative weak labels. Using the YouTube dataset provided by Wrench, we attempt to classify YouTube comments into categories of SPAM or HAM, leveraging Snorkel to estimate \(P_{Y|Z}\). Inspired by Smith et al. , we craft three few-shot weak labelers by prompting7 the large language model (LLM) Llama-2-13b-chat-hf. For each dataset entry, we pose three distinct queries to the LLM. Initially, we inquire if the comment is SPAM or HAM. Next, we provide clear definitions of SPAM and HAM, then seek the classification from LLM. In the third prompt, leveraging in-context learning ideas , we provide five representative comments labeled as SPAM/HAM prior to requesting the LLM's verdict on the comment in question. In cases where LLM's response diverges from SPAM or HAM, we interpret it as LLM's abstention.

After obtaining this triad of weak labels, we analyze two situations. Initially, we integrate the top five8 weak labels ("high-quality" labels) from Wrench. In the subsequent scenario, we synthetically generate weak labels ("low-quality" labels) that do not correlate with \(Y\). The first plot in Figure 3 depicts the bounds of our classifier based solely on weak few-shot labels, which unfortunately do not provide substantial insights. Enhancing the bounds requires the inclusion of additional weak labels. Yet, as indicated by the subsequent pair of plots, it becomes evident that only the incorporation of "high-quality" weak labels results in significant shrinkage and upward shift of the bounds. As confirmed by the test accuracy, if a practitioner had used our method to select the set of weak labels, that would have led to a significant boost in performance.

### Model selection strategies using the Frechet bounds

In Sections 4.1 and 4.2, we implicitly touched on the topic of model selection when discussing the classification threshold and weak label selection. Here, we explicitly discuss the use of our Frechet bounds for model selection purposes. Consider a set of possible models \(\{h_{1},,h_{K}\}\) from which we wish to find the best model according to a specific metric, _e.g._, accuracy, or F1 score. We consider three approaches for model selection using the Frechet bounds: choosing the model with the best possible (i) lower bound, (ii) upper bound, and (iii) average of lower and upper bounds on the metric of interest. Strategy (i) works well for the worst-case scenario and can be seen as the

Figure 2: Precision and recall bounds for hate speech detection.

distributionally robust optimization (DRO)  solution when the uncertainty set is given by \(\) in (1.1), while (ii) is suitable for an optimistic scenario, and (iii) is suggested when one wants to balance between the worst- and best-case scenarios. Please check Appendix E for more details.

In this experiment, we select multilayer-perceptrons (MLPs). The considered MLPs have one hidden layer with a possible number of neurons in \(\{50,100\}\). Training is carried out with Adam , with possible learning rates in \(\{.1,.001\}\) and weight decay (\(l_{2}\) regularization parameter) in \(\{.1,.001\}\). For those datasets that use the F1 score as the evaluation metric, we also tune the classification threshold in \(\{.2,.4,.5,.6,.8\}\) (otherwise, they return the most probable class as a prediction). In total, \(\) is composed of \(8\) trained models when evaluating accuracy and \(40\) models when evaluating the F1 score. We also consider directly using the label model (Snorkel ) to select models. For example, when the metric considered is accuracy, _i.e._, we use select the model \(_{h_{k}}_{i=1}^{n}_{_{Y |Z}}[h_{k}(X)=Y Z=Z_{i}]\), which is a natural choice when \(X\!\!\! Y Z\). As baselines, we consider having a few labeled samples.

In Table 2, we report a subset of our results (please check Appendix E for the full set of results). In this table, we report the average test scores of the chosen models over \(10\) repetitions for different random seeds (standard deviation report as subscript). We can extract some lessons from the table. First, using metrics derived from the Frechet bounds is most useful when our uncertainty about the model performance is low, _e.g._, "'commercial" and "tennis" in Figure 1. In those cases, using our metrics for model selection gives better results even when compared to a labeled validation set of size \(n=100\). Moreover, once the practitioner knows that the uncertainty is low, using the label model approach also does well.

## 5 Discussion

### Extensions

An extension we do not address in the main text is the evaluation of end-to-end weak supervision methods [62; 56; 52], where the separation between the label model and the final predictor is less clear than in our primary setting. Our approach remains compatible with these methods as long as we can fit a label model (_e.g._, Snorkel) separately and utilize it solely for the evaluation step. Another possible extension is the application of the ideas presented in this work in different fields of machine learning or statistics. One could consider applying our ideas to the problem of "statistical matching" (SM) [18; 10; 19; 30; 11], for example. The classic formulation of SM involves observing two distinct datasets that contain replications of \((X,Z)\) and \((Y,Z)\), but the triplet \((X,Y,Z)\) is never observed. The primary goal is to make inferences about the relationship between \(X\) and \(Y\). For instance, if our focus is on bounding \(((X,Y) B)=[_{B}(X,Y)]\) for a certain event \(B\), we could define \(g(x,y,z)=_{B}(x,y)\) and apply our method.

    & metric & Lowr bound & Bounds avg & Label model & Label (\(n=100\)) \\  apnews & acc & \(0.77_{ 0.00}\) & \(0.78_{ 0.00}\) & \(0.77_{ 0.00}\) & \(0.77_{ 0.00}\) \\ imdb & acc & \(0.72_{ 0.00}\) & \(0.73_{ 0.00}\) & \(0.73_{ 0.00}\) & \(0.72_{ 0.01}\) \\  yely & acc & \(0.81_{ 0.00}\) & \(0.81_{ 0.00}\) & \(0.81_{ 0.00}\) & \(0.82_{ 0.01}\) \\ tennis & F1 & \(0.76_{ 0.01}\) & \(0.76_{ 0.01}\) & \(0.75_{ 0.01}\) & \(0.71_{ 0.02}\) \\  commercial & F1 & \(0.96_{ 0.00}\) & \(0.96_{ 0.00}\) & \(0.96_{ 0.00}\) & \(0.91_{ 0.01}\) \\   

Table 2: Performance of selected models

Figure 3: Performance bounds for classifiers on the YouTube dataset, initially relying solely on few-shot weak labels obtained via prompts to the LLM L1ama-2-13b-chat-hf. The progression of plots illustrates the comparative impact of integrating “high-quality” labels from Wrench versus synthetically generated “low-quality” labels. Evidently, the addition of “high-quality” labels significantly enhances the bounds, underscoring their superior utility over “low-quality” labels for optimal classification of SPAM and HAM comments.

### Limitations

We discuss some limitations of our methods. Firstly, our method and theoretical results are only applicable to cases where \(\) and \(\) are finite sets, such as in classification problems. Extending the dual formulation in Theorem 2.1 to general \(\) and \(\) is possible but would require optimizing over function spaces, which is computationally and theoretically challenging. Additionally, if \(||\) is large, convergence may be slow, necessitating a large unlabeled dataset for accurate bounds. Using a smaller, curated set of weak labels, may be more effective for bounds estimation and performance. We end this subsection with two other limitations related to misspecification in the label model and informativeness of the bounds. The proofs of the results introduced in this section are placed in Appendix D.

**Label model misspecification:** In our asymptotic results we assumed that the label models are well-specified, _i.e._, the estimates \(\{_{Y|Z}^{(m)},m\}\) converge to the true label model \(P_{Y|Z}\) at \(m\). To understand the qualities of our bound when this assumption is violated, we introduce the misspecification: \(_{Y|Z}^{(m)} Q_{Y|Z}\) and \(Q_{Y|Z} P_{Y|Z}\). In our investigation on the misspecification of the label model, we control the level of misspecification as \(d_{}(Q_{Y|Z=z},P_{Y|Z=z})\) and then study the subsequent errors in our Frechet bounds. The following theorem formalizes the result.

**Theorem 5.1**.: _Recall from equation (2.2) that \(L_{}\) and \(U_{}\) are the smoothened upper and lower Frechet bounds with the true \(P_{Y|Z=z}\). Additionally, let us define similar \(_{}\) and \(_{}\) bounds, but with a misspecified \(Q_{Y|Z=z}\), i.e._

\[&_{}_{ }[_{l,}(X,Z,a)]\ \ \ \ _{}_{a}[_{u, }(X,Z,a)]\,,\\ &_{l,}(x,z,a)-[ |}_{y}(} {-})]-_{Q_{Y|Z}}[a_{Yz} Z=z] \\ &_{u,}(x,z,a)\ [|}_{y}(}{ })]-_{Q_{Y|Z}}[a_{Yz} Z=z] \] (5.1)

_Assume \(Q_{Y|Z}\) is in a set of conditional distributions such that the optimizers for (5.1), which are assumed to exist, are uniformly bounded. If \(d_{}Q_{Y|Z=z},P_{Y|Z=z}\), then for some \(C>0\) which is independent of \(>0\), we have_

\[|_{}-L_{}|,|_{}-U_{}|  C\,.\] (5.2)

The above theorem reveals how misspecification translates to the errors in subsequent Frechet bounds. In an ideal scenario, with access to an \(\{(Y_{i},Z_{i})\}_{i=1}^{m}\) sample we can consistently estimate \(P_{Y|Z}\), leading to \(=0\). In situations when this \(\{(Y_{i},Z_{i})\}_{i=1}^{m}\) sample is not accessible and we have to rely on a label model, we require the misspecification in this model to be small.

**Informativeness of the bounds:** The bounds \(L\) and \(U\) are especially useful when their difference \(U-L\) is small because in that case, we obtain a tight bound for \([g(X,Y,Z)]\) and narrow it down with high precision even if the joint random vector \((X,Y,Z)\) is never observed. But when is this bound small? In the next theorem, we provide an upper bound on this difference.

**Theorem 5.2**.: _Let \(L\) and \(U\) be defined as in equation (1.1). Then_

\[U-L^{2}\{H(X Z),H(Y Z)\}}\]

_where \(H(X Z)\) (resp. \(H(Y Z)\)) denotes the conditional entropy of \(X\) (resp. \(Y\)) given \(Z\)._

To understand the result better, recall our setting: we do not observe the joint distribution \(P_{X,Y,Z}\) and only observe the marginals \(P_{Y,Z}\) and \(P_{X,Z}\). The only way we can infer about the joint distribution is by connecting these two marginals through \(Z\). So, readers can guess that it is more favorable when \(Z\) is informative for either \(X\) or \(Y\). For example, take the extreme case when \(Y=h(Z)\) for a function \(h:\). In this case the \(P_{X,Y,Z}=P_{X,g(Z),Z}\) is precisely known from the \(P_{X,Z}\) and we can exactly pinpoint the \([g(X,Y,Z)]\) as \([g(X,h(Z),Z)]\). In this case, \(H(Y Z)=0\), leading to \(U-L=0\), _i.e._, its Frechet bounds can precisely pinpoint it as well; ideally at least one of the \(H(X Z)\) and \(H(Y Z)\) is small.

## 6 Acknowledgements

This paper is based upon work supported by the National Science Foundation (NSF) under grants no. 1916271, 2027737, 2113373, and 2113364.