# Estimating Heterogeneous Treatment Effects by Combining Weak Instruments and Observational Data

Miruna Oprescu

Cornell University

amo78@cornell.edu &Nathan Kallus

Cornell University

kallus@cornell.edu

###### Abstract

Accurately predicting conditional average treatment effects (CATEs) is crucial in personalized medicine and digital platform analytics. Since the treatments of interest often cannot be directly randomized, observational data is leveraged to learn CATEs, but this approach can incur significant bias from unobserved confounding. One strategy to overcome these limitations is to leverage instrumental variables (IVs) as latent quasi-experiments, such as randomized intent-to-treat assignments or randomized product recommendations. This approach, on the other hand, can suffer from low compliance, _i.e._, IV weakness. Some subgroups may even exhibit zero compliance, meaning we cannot instrument for their CATEs at all. In this paper we develop a novel approach to combine IV and observational data to enable reliable CATE estimation in the presence of unobserved confounding in the observational data and low compliance in the IV data, including no compliance for some subgroups. We propose a two-stage framework that first learns _biased_ CATEs from the observational data, and then applies a compliance-weighted correction using IV data, effectively leveraging IV strength variability across covariates. We characterize the convergence rates of our method and validate its effectiveness through a simulation study. Additionally, we demonstrate its utility with real data by analyzing the heterogeneous effects of 401(k) plan participation on wealth.

## 1 Introduction

The use of observational data for individual-level causal analyses is becoming increasingly common in personalized medicine, online platforms, and any setting where understanding individualized responses is crucial and/or presents an opportunity for personalization. The key quantity for such analyses is the conditional average treatment effect (CATE), which captures how treatment effects vary according to baseline covariates (features). This measure provides insight into effect heterogeneity and enables personalization.

Using observational data can nonetheless introduce bias from unobserved confounding, where the observed relationship between outcomes and interventions is influenced not only by treatment effects but also by variables that influence both outcome and treatment, such as socioeconomic status, health, user mood, _etc._, which are not captured by baseline covariates. These biases can skew causal effect estimates, resulting in unreliable analyses or even harmful policy decisions.

Randomized trials are the gold standard for causal inference, but they are often infeasible. For instance, digital services cannot force users to view or buy a product, and clinical trials cannot require invasive treatments. A common alternative is to randomize the _encouragement_ of certain actions, such as recommending a product or treatment. These encouragements can serve as instrumental variables (IVs) which, under certain conditions, enable unbiased estimation of treatment effects .

Identification of CATEs using IVs crucially hinges on the premise that compliance - the correlation between the treatment received and the intent/encouragement - is nonzero across all baseline-covariatevalues. When compliance is nonzero but small, IV-based estimates tend to exhibit high variance, making them unreliable . In practice, the assumption of strong compliance is often violated. For example, users on digital platforms may ignore recommendations entirely or reject certain types of content, while participants on mobile health platforms may disregard prompts (_e.g._ taking 250 steps per hour) due to time constraints or lack of interest.

To address the challenge of estimating unbiased CATEs in the presence of unobserved confounding and low IV compliance, we introduce a two-stage framework. In the first stage, we estimate a biased, confounded CATE from observational data. Then, in the second stage, we utilize an IV to learn the confounding bias by weighting the samples according to their compliance levels. By assuming only that the bias can be extrapolated, this approach extends treatment effect adjustments even to groups minimally influenced by the IV, employing a transfer learning approach that leverages varying instrument strengths across covariate groups.

This framework mirrors strategies in causal inference that combine randomized trials with observational data to address low covariate overlap. Building on this body of work, we introduce two methodologies for extrapolating confounding bias within the observational dataset: a parametric estimation approach, assuming the confounding bias adheres to a parametric form, and a transfer learning strategy that assumes a shared representation between the true and biased CATE. We study the properties of our CATE estimators in finite samples and validate our approaches through comprehensive empirical studies.

## 2 Related Work

We briefly overview related work here; for a more comprehensive discussion, refer to Appendix A.

**Heterogeneous treatment effect estimation from observational data:** Recent advances in machine learning have expanded the use of observational data to estimate CATEs using diverse techniques such as random forests , Bayesian algorithms , deep learning , and meta-learners . However, these methods often unrealistically assume an absence of confounding, limiting their real-world applicability. Efforts to account for unobserved confounding either construct _bounds_ on treatment effects [17; 40] or use latent variable models and multiple/sequential treatments to debias CATE estimates [9; 36; 53], but they frequently depend on unverifiable assumptions or require accurate proxy data, reducing their practical utility.

**Heterogeneous treatment effect estimation using IVs:** Integrating machine learning with instrumental variable (IV) methods enhances CATE estimation flexibility over traditional approaches. Techniques range from advanced two-stage least squares (2SLS) that incorporate complex feature mappings via kernel methods  and deep learning  to neural networks for conditional density estimation  and moment conditions for IV estimation . Yet, these rely on the consistent relevance of instruments across covariate groups, which is not guaranteed with weak instruments.

**Treatment Effect Estimation with Weak Instruments:** Traditional IV methods like 2SLS can be unreliable when instruments are weak, leading to biased, high-variance estimates. Recent advancements include novel estimators such as bias-adjusted 2SLS, limited information maximum likelihood, and jackknife IV estimators (see  and references therein). Other techniques attempt to reduce variance by exploiting first-stage heterogeneity (variation in compliance) [1; 13]. Some approaches also combine multiple weak instruments into robust composites, useful in settings like genetic studies . Our approach extends [1; 13] by leveraging compliance weighting to estimate heterogeneous effects and address weak instruments using additional observational data.

**Combining observational and randomized data:** Increasing research focuses on integrating observational datasets with randomized control trial (RCT) data to mitigate observational bias. Strategies include imposing structural assumptions, such as strong parametric constraints , or assuming a shared structure between biased and unbiased CATE functions , as well as optimizing dual estimators from both data types for improved bias correction . Our work aligns with efforts to debias treatment effects using both observational and experimental data, but also addresses challenges such as low IV compliance, the need to debias the overall effect function rather than individual outcome functions, and the complexity of estimating CATEs from IV data using a ratio estimator.

**Where our work lies:** To the best of our knowledge, no current estimation technique effectively combines an IV study, particularly one with weak instruments or low compliance, with an observational study to derive robust and unbiased CATE estimates. We bridge this gap by introducing two robust and consistent CATE estimation techniques, building upon previous work on combining RCT and observational data [23; 29], as well as work that addresses the complexities associated with weak instruments [1; 13].

## 3 Background and Setup

We consider the standard setting of causal inference where the goal is to estimate the conditional average treatment effect of a binary treatment \(A\{0,1\}\) on an outcome \(Y\) in the presence of covariates \(X^{m}\). Our approach is grounded in Rubin's potential outcomes framework, wherein each unit is associated with two potential outcomes \(Y(0),Y(1)\) of which only \(Y=Y(A)\) is observed (causal consistency). Our objective is to learn the CATE function, which is given by:

\[(x)=[Y(1)-Y(0) X=x].\] (1)

However, we only have access to \(n_{O}\) i.i.d. samples from an observational dataset \(O=(X_{i}^{O},A_{i}^{O},Y_{i}^{O})_{i=1}^{n_{O}}(X^{O},A^{O},Y^{O})\). Thus, we face the fundamental problem of causal inference: only the outcome under the administered treatment is observed, while the counterfactual remains unobserved. Without further assumptions, there exists the possibility of unobserved confounding, leading to a situation where

\[^{O}(x)=[Y^{O} A^{O}=1,X^{O}=x]-[Y^{O} A^{O}= 0,X^{O}=x](x),\] (2)

which indicates a persistent bias in the observed treatment effects that does not diminish even with an increasing sample size. We denote this bias by \(b(x)\), that is:

\[b(x)=(x)-^{O}(x).\]

Assuming this bias is induced by a set of unobserved confounders \(U^{k}\), the discrepancy arises because the selection into treatment in the observational population is influenced by \(U\), which also impacts the outcome \(Y^{O}\). Our goal is to mitigate this bias by leveraging additional data.

Alongside the observational dataset, we have \(n_{E}\) i.i.d. samples from an experimental, intent-to-treat dataset \(E=(X_{i}^{E},Z_{i}^{E},A_{i}^{E},Y_{i}^{E})_{i=1}^{n_{E}}(X^{E},Z^{E},A^{E})\) where \(Z^{E}\) is a binary instrument taking values in \(\{0,1\}\). We let \(X^{E}\) and assume the \(p_{X^{E}}(x)=p_{X^{O}}(x)\), where \(p_{X}\) denotes the density of the random variable \(X\). Moreover, we assume that the joint distribution of covariates and unobserved confounders \((X,U)\) is consistent across both datasets. As before, we use \(Y^{E}(A,Z)\) to denote the potential outcome given treatment \(A\) and instrument \(Z\). Additionally, let \(A^{E}(Z)\) denote the potential treatment under instrument \(Z\), and define the compliance and defiance indicators \(C\) and \(D\) by \(C:=[A^{E}(1)>A^{E}(0)]\) and \(D:=[A^{E}(1)<A^{E}(0)]\), respectively. We assume that this dataset follows standard IV assumptions on the data generating process:

**Assumption 1** (Standard IV Assumptions).: _We assume the following properties hold: (Exclusion) \(Y^{E}(A,Z)=Y^{E}(A)\), i.e. the instrument affects the outcome only through the treatment; (Independence) \(Z U X\) for any unobserved confounder \(U\); and (Relevance) there exists a subset \(^{}\) with non-zero measure such that \(Z^{E} A^{E} X^{E}\) for \(X^{E}^{}\)._

**Assumption 2** (Unconfounded Compliance ).: _The individual treatment effect is independent of the compliance status given covariates: \(Y^{E}(1)-Y^{E}(0)(A^{E}(1)-A^{E}(0)) X^{E}\)._

We note that the relevance assumption in Assumption 1 is a weaker version of the standard IV assumptions since we allow for arbitrarily weak instruments in some regions of the covariate spaces. With Assumption 1 and Assumption 2, we can identify the CATE for \(x^{}\) as:

\[^{E}(x)=[Y^{E} Z^{E}=1,X^{E}=x]-[Y^{E} Z ^{E}=0,X^{E}=x]}{[A^{E} Z^{E}=1,X^{E}=x]-[A^{E} Z^ {E}=0,X^{E}=x]}:=(x)}{(x)}=(x).\] (3)

We provide the proof of Equation 3 in Appendix B. Here, \((x)\) denotes heterogeneous compliance, a measure of instrument strength, given by \((x)=P(C=1 X^{E}=x)-P(D=1 X^{E}=x)\) under Assumption 2. A _strong_ instrument (\((x) 1\)) indicates high adherence to the recommended treatment, with \((x)=1\) signifying perfect compliance, similar to a true randomized controlled trial. Conversely, a _weak_ instrument (\((x) 0\)) suggests minimal influence on treatment uptake, with \((x)=0\) indicating no compliance and a confounded selection into treatment. The relevance assumption in Assumption 1 ensures \((x) 0\) for \(x^{}^{}\), validating the estimation procedure in Equation 3. However, small \((x)\) values lead to estimates of \((x)\) with high asymptotic variance. Moreover, we wish to extend the \((x)\) estimation from \(^{}\) to \(\), our population of interest.

Thus, relying solely on observational data results in biased \((x)\) estimates, while experimental data alone can yield high variance or invalid estimates for \(x\) with low compliance. This work addresses these challenges by strategically combining the strengths of both datasets to provide a robust CATE estimation technique.

**Notation:** We denote the \(L_{2}\) norm of a function \(f\) as \(\|f\|_{L_{2}}:=_{F}[f(X)^{2}]^{1/2}\), and the \(L_{2}\) Euclidean norm of a vector \(^{d}\) as \(\|\|_{2}\). The notation \(\) represents the estimated value of a parameter or function, where \(f\) is the true value. We omit the distribution subscript when clear from context; _e.g._, \([X^{E}]\) and \([X^{O}]\) denote expectations over experimental and observational samples, respectively.

## 4 Estimation Method

To obtain robust estimates of the CATE function for the population of interest \(\), we propose a two-step framework that integrates information from both the observational data and the IV study. First, we estimate the confounded CATE function \(^{O}(x)\) using the observational data \((X_{i}^{O},A_{i}^{O},Y_{i}^{O})_{i=1}^{n_{O}}\). This is a well-established problem in both causal inference and machine learning, and it can be addressed using various existing techniques, including meta-learners (), random forests (), and neural networks ().

Next, we wish to approximate the bias function \(b(x)=(x)-^{O}(x)\) using the learned \(^{O}(x)\). Without oracle access to the true CATE function \((x)\), we instead rely on samples from the experimental (IV) study \((X_{i}^{E},Z_{i}^{E},A_{i}^{E},Y_{i}^{E})_{i=1}^{n_{E}}\) for which we can estimate an unbiased, though potentially high variance, CATE for \(x^{}\), as given in Equation 3. Our approach hinges on the following lemma:

**Lemma 1**.: _[CATE Estimation with IVs] Let \(_{Z}(x):=P(Z^{E}=1 X^{E}=x)\) be the instrument propensity. Then, the following identity holds for every \(x^{}\):_

\[[Z^{E}}{_{Z}(x)(x)}-(1-Z^{E})}{ (1-_{Z}(x))(x)}X^{E}=x]=(x)\]

We note that in the case of randomized instrument assignment, the instrument propensity is known and often given by a constant, _i.e._, \(_{Z}(x)=_{Z}>0\). By defining \(V_{Z}(x):=_{Z}(x)(1-_{Z}(x))\), Lemma 1 shows that the bias function \(b(x)\) can be expressed in terms of observable quantities as \(b(x)=[Z^{E}(1-_{Z}(X^{E}))-Y^{E}(1-Z^{E})_{Z} (X^{E})}{V_{Z}(X^{E})(X^{E})}-^{O}(x) X^{E}=x]\) for \(x^{}\). This formulation suggests that we can estimate \((x)\) and, if necessary, \(_{Z}(x)\) from data and utilize the pseudo-outcome

\[^{E}}{_{Z}(X^{E})(X^{E})}:= {Y^{E}Z^{E}(1-_{Z}(X^{E}))-Y^{E}(1-Z^{E})_{Z}(X^{E} )}{_{Z}(X^{E})(X^{E})}\]

along with the estimated \(^{O}(x)\), in a subsequent regression task to obtain an unbiased and consistent estimate of \(b(x)\) for \(x^{}\) (provided \(_{Z}\), \(\), and \(^{O}\) are estimated consistently). However, such an estimator only provides estimates for \(^{}\) where \((x) 0\). Additionally, for small values of \((x)\), \(_{Z}(x)\), and \(1-_{Z}(x)\), this method may result in high variance in the estimates \((x)\), especially for certain parametric function classes. To address these challenges, we weight the data samples by the inverse variance of \(^{E}/((x)_{Z}(x))\) given by \((^{E}|X^{E}=x)^{-1}^{2}(x)_{Z}^{2}(x)\). This approach is frequently used in generalized least squares methods (GLS, ) to confer the algorithm asymptotic efficiency. While \((^{E}|X^{E}=x)\) can be estimated from data using machine learning methods, it is generally preferable to weight the estimator solely by compliance and instrument propensity to

Figure 1: Illustration of our two-stage procedure: the first stage learns a biased CATE from observational data, while the second stage uses IV data to correct the bias.

avoid issues with small values of \((^{E}|X^{E}=x)\). Assuming the bias function belongs to a class of functions \(\), our proposed algorithm can be described by the following weighted empirical risk minimization (ERM) procedure.

\[=_{b}_{i=1}^{n_{E}}(_{i }^{E}-(X_{i}^{E})_{Z}(X_{i}^{E})^{O}( X_{i}^{E})-(X_{i}^{E})_{Z}(X_{i}^{E})b(X_{i}^{E}) )^{2}\] (4)

where the factor \(^{2}(x)_{Z}^{2}(x)\) was used for weighting the squared loss. This estimator automatically extrapolates to all of \(\) since we assign weights of \(0\) when \((x)=0\). Moreover, this method places higher emphasis on lower-variance pseudo-outcomes, thereby minimizing the risk of overfitting to data points with high variance. This weighting technique is commonly employed in other IV estimation tasks, such as local _average_ treatment effect estimation (LATE), where weighting data points by compliance yields estimators with lower variance ([1; 13]).

The weighting scheme in Equation 4 creates a weighted distribution, \(_{X^{E}}(x)\), for optimizing the ERM procedure. Since \(_{X^{E}}(x)\) differs from the target distribution \(p_{X^{E}}(x)\), this introduces a transfer learning problem. Without additional constraints on the function class \(\), the minimization in Equation 4 may yield many possible solutions. To ensure a unique or limited solution set, \(\) must have low complexity or require further structural assumptions. We explore two function classes \(\): a parametric class defined by \(b(x)=^{T}(x),^{d}\) with a known mapping \(:^{d}\), and a second parametric class where \(b(x)=^{T}(x)\), with \(^{d}\) and \(\) being a learned representation common to both the observational and IV datasets.

### Integrating Observational and Experimental Data via Parametric Extrapolation

We consider a parametric class \(_{}=\{^{T}(x):^{d}\}\) for a known mapping \(:^{d}\). Since the compliance factor \((x)\), instrument propensity \(_{Z}(x)\), and the parameter of interest \(^{T}\) are learned from the same dataset \(E\), we propose the following \(K\)-fold cross-fitted estimation procedure:

\[=_{^{d}}_{k=1}^{K}_{i _{k}^{E}}(_{i}^{E}-^{(k)}(X_{i}^{E}) ^{O}(X_{i}^{E})-^{T}^{(k)}(X_{i}^{E})(X_{i }^{E}))^{2}\] (5)

where \(^{(k)}(X_{i}^{E}):=^{(k)}(X_{i}^{E})_{Z }^{(k)}(X_{i}^{E})\), and the compliance factor \(^{(k)}\) and instrument propensity \(_{Z}^{(k)},k[K]\) are trained on \(E\) excluding the \(k^{}\) fold containing indices \(_{k}^{E}\). K-fold cross-fitting is crucial because it ensures that the weights are learned from data distinct from that used in the ERM algorithm. This separation is essential for maintaining desirable theoretical properties as we remain methodologically agnostic to the techniques used for learning \(\) and \(_{Z}\).

The compliance factor \((x)=[A^{E} Z^{E}=1,X^{E}=x]-[A^{E} Z^{E}=0,X ^{E}=x]\) can be estimated using standard machine learning classification algorithms, either by training separate classifiers for \(A^{E} Z^{E}=1,X^{E}=x\) and \(A^{E} Z^{E}=0,X^{E}=x\) or by using one classifier with \(Z^{E}\) as an additional feature. Similarly, instrument propensity estimation is a straightforward classification task with \(Z^{E}\) as the target. Given estimates \(^{O}\), \(^{(k)}\), and \(_{Z}^{(k)}\), the result in Equation 5 is obtained by performing an OLS procedure with the targets \(_{i}^{E}-^{(k)}(X_{i}^{E})^{O}(X_{i}^{E})\) and the design matrix \(}=W(X^{E})(X^{E})\). Here, \(W(X^{E})=(^{(k)}(X^{E}_{i}),,^{(k)}(X^{E} _{n_{E}}))\), and \((X^{E})=((X^{E}_{1}),,(X^{E}_{n_{E}}))^{T}\). The two-step procedure is detailed in Algorithm 1.

Next, we provide theoretical guarantees for our parametric extrapolation approach. We begin by describing the regularity assumptions that enable the consistency of our estimator.

**Assumption 3** (Regularity Assumptions).: _The following claims are true:_

1. _(Treatment Positivity in_ \(O\)_)_ \( P(A^{O}=1 X^{O}=x) 1-\) _for some_ \(>0\)_._
2. _(Instrument Positivity in_ \(E\)_)_ \(_{Z}(X^{E}),_{Z}(X^{E}) 1-\) _for some_ \(>0\)_._
3. _(Boundedness)_ \(Y^{E}\)_,_ \(Y^{O}\)_,_ \(\|X^{E}\|_{2}\)_,_ \(\|(X^{E})\|_{2}\)_,_ \(^{O}(x)\)_,_ \((x)\) _are uniformly bounded._
4. _(Realizability of_ \(b(x)\)_)_ \(b(x)_{}\)_, i.e._ \((x)-^{O}(x)=^{T}(x)\) _for some_ \(^{d}\)_._
5. _(Identifiability of_ \(\)_)_ \([(X^{E})(X^{E})^{T}]\) _is invertible._

The first two conditions in Assumption 3 are standard in causal inference, ensuring that both treatments (or instruments) and controls are observable for every \(x\), enabling CATE estimation. The third condition imposes a common boundedness assumption to control the growth of estimands. The fourth condition ensures our model for the bias function \(b(x)\) is well-specified given \(_{}\). The final condition requires that the design matrix has rank \(d\), ensuring we can learn the parameter \(\) from data. Given Assumption 3, we present the following theoretical result:

**Theorem 2** (Estimator Consistency for Parametric Extrapolation).: _Let \(r_{}(n)\), \(r_{_{Z}}(n)\), and \(r_{^{O}}(n)\) be \(o_{p}(1)\) functions of \(n\) such that \(\|-^{(k)}\|_{L_{2}} r_{}(n_{E})\), \(\|_{Z}-^{(k)}_{Z}\|_{L_{2}} r_{_{Z}}(n_{E})\), and \(\|^{O}-^{O}\|_{L_{2}} r_{^{O}}(n_{O})\). Furthermore, assume the conditions of Assumption 1, Assumption 2, and Assumption 3 hold. Then, the parameter \(\) returned by Algorithm 1 is consistent and satisfies_

\[\|-\|_{2}=O_{p}(r_{}(n_{E})+r_{ _{Z}}(n_{E})+r_{^{O}}(n_{O})+1/}).\]

_Moreover, \(\) is consistent on \(\) with convergence rate given by_

\[\|-\|_{L_{2}}=O_{p}(r_{}(n_{E})+r_{_{Z}}(n_{E })+r_{^{O}}(n_{O})+1/}).\]

We include the proof of Theorem 2 in Appendix B. The core insight is that weighted OLS remains consistent as long as the estimates for \(\), \(_{Z}\), and \(^{O}\) are themselves consistent. However, the overall convergence rate is constrained by the slowest of these rates. In most cases, \(_{Z}\) is assumed to be known, meaning the convergence rate is primarily dictated by the rates of \(\) and \(^{O}\). This result highlights the trade-off involved in leveraging both datasets to achieve accurate effect estimation for the target population.

**Remark 1** (Impact of Realizability Violations).: _When realizability does not hold, i.e. \(b(x)\), our estimator may be inconsistent and exhibit asymptotic bias, proportional to the deviation of the true function from \(\). Nonetheless, conducting this analysis might still be valuable, as the resulting bias may be smaller than confounding bias in observational estimates or the variance from low compliance in IV studies. Thus, even with uncertain realizability, our method may provide more accurate CATE estimates by effectively balancing bias and variance._

### Integrating Observational and Experimental Data via a Common Representation

Without expert knowledge, the mapping \((x)\) may not be known a priori. In this section, we introduce a method to jointly learn both the unbiased CATE function and the mapping \((x)\) (hereafter referred to as the _representation_), based on the assumption that the true CATE \((x)\) and the biased CATE \(^{O}(x)\) share a common representation. This approach leverages machine learning techniques that assume a common structure across tasks, such as multi-task and transfer learning. In causal inference, it has been suggested that a shared representation can be assumed between treatment arms [47; 48] or between randomized data and confounded observational data . This framework enables us to learn the bias function \(b(x)\) even when the mapping \((x)\) is otherwise unknown.

We consider a class \(\) of representations \((x):^{d}\) and assume that there exists a shared representation \(\) between the true and biased CATEs. Specifically, there exist linear hypotheses \(h,h^{O}^{d}\) such that \((x)=h^{T}(x)\) and \(^{O}(x)=(h^{O})^{T}(x)\), resulting in the bias function \(b(x)=(h-h^{O})^{T}(x):=^{T}(x)\). For simplicity, we focus on linear-in-representation classes, but more complex hypotheses \(h\) with \((x)=h((x))\) can be considered - see . Thus, \(b(x)_{}\) for the unknown \(\), with \(_{}\) defined in Section 4.1. Suppose there exists an ERM algorithm \(\) that can jointly learn \((x)\) and \(h^{O}\) using \(\) on \(O\).

```
1:Input: Observational dataset \(O=(X_{i}^{O},A_{i}^{O},Y_{i}^{O})_{i=1}^{n_{O}}\), IV dataset \(E=(X_{i}^{E},Z_{i}^{E},A_{i}^{E},Y_{i}^{E})_{i=1}^{n_{E}}\), \((,h^{O})\) estimator \(\), \((x)\) estimator \(\), \(_{Z}(x)\) estimator \(\).
2:Lear \((x)\) and \(^{O}\) using \(\) on \(O\).
3:Call Algorithm 1 with \(=\) and \(^{O}(x)=(^{O})^{T}(x)\). Let \(\) be its output.
4:Output:\(\). ```

**Algorithm 2** CATE Estimation with Representation Learning

Our learning algorithm proceeds as follows: first, we use \(\) to learn \((x)\) and \(^{O}\) from \(O\), alongside estimates \(^{(k)}(x)\) and \(_{Z}^{(k)}(x)\) from \(E\) as described in Section 4.1. In the second stage, we apply the following ERM procedure to estimate the parameter \(\):

\[=_{^{d}}_{k=1}^{K}_{i _{k}^{E}}(_{i}^{E}-(^{O})^ {T}^{(k)}(X_{i}^{E})(X_{i}^{E})-^{T}^{ (k)}(X_{i}^{E})(X_{i}^{E}))^{2}.\] (6)

This procedure is detailed in Algorithm 2. Finally, we recover \((x)\) by setting \((x)=(^{O}+)^{T}(x)\).

**Example 1** (Representation learning with neural networks).: _Let \(\) be a class of feed-forward neural networks. Then \((x),^{O}\) and \(^{O}(x)\) can be jointly learned by composing \(\) with two linear output heads for \(Y^{O} A^{O}=1,X^{O}=x\) and \(Y^{O} A^{O}=0\), \(X^{O}=x\), respectively. By taking the difference between the two output heads, we can reconstruct \(^{O}(x)\), assuming that \([Y^{O} A^{O}=1,X^{O}=x]\) and \([Y^{O} A^{O}=0,X^{O}=x]\) are also linear in \(\) (see ). Without this assumption, we can learn \(^{O}(x)\) directly by composing \(\) with one linear output layer and considering the pseudo-outcome \(A^{O}}{_{A}(X^{O})}-(1-A^{O})}{(1-_{A}(X^{O}))}\). Here, \(_{A}(X^{O})=P(A^{O}=1 X^{O})\) is the treatment propensity in \(O\) and can be learned using any black-box machine learning classifier._

With this setup, we obtain theoretical results similar to those in Theorem 2:

**Theorem 3** (Estimator Consistency for Shared Representation Learning).: _Let \(r_{}(n)\), \(r_{_{Z}}(n)\), and \(r_{}(n)\) be \(o_{p}(1)\) functions of \(n\) such that \(\|-^{(k)}\|_{L_{2}} r_{}(n_{E})\), \(\|_{Z}-_{Z}^{(k)}\|_{L_{2}} r_{_{Z}}(n_{E})\), and \(\|-\|_{L_{2}} r_{}(n_{O})\). Additionally, assume \(\|\|_{2}\) is bounded and \((X)(X)^{T}\) is invertible. Let us also consider the conditions specified in Assumption 1 and Assumption 2 to be satisfied. Moreover, assume that \(^{O}(x)=(h^{O})^{T}(x)\) for some \(\) that is realizable within the representation class \(\) and let Assumption 3 hold for \(\). Under these conditions, the parameter \(\) returned by Algorithm 2 is consistent and satisfies_

\[\|-\|_{2}=O_{p}(r_{}(n_{E})+r_{_{Z}} (n_{E})+r_{}(n_{O})+1/}+1/}).\]

_Moreover, \(\) is consistent on \(\) with convergence rate given by_

\[\|-\|_{L_{2}}=O_{p}(r_{}(n_{E})+r_{_ {Z}}(n_{E})+r_{}(n_{O})+1/}+1/}).\]

We provide the proof of Theorem 3 in Appendix B. This result hinges on the realizability assumption in \(\) and the linear-in-representation structure of both \(\) and \(^{O}\). In Example 1, \(r_{}(n)\) bounds the generalization error for feed-forward neural networks. For ReLU activations and bounded outputs, \(r_{}(n)=C n/\), where \(W\) is the total number of weights, \(L\) is the number of layers, and \(C\) is a constant independent of \(n\) and \(W\). While this rate is parametric, it scales linearly with \(W\), which becomes problematic for over-parameterized networks. For 1-Lipschitz activations and bounded weights,  derive a rate of \(r_{}(n)=C^{L}M(l)}/n^{1/4}\), where \(M(l)\) bounds the Frobenius norm of layer \(l\)'s weight matrix.

**Practical Guidance in High-Dimensional Settings:** When \((x)\) is high-dimensional, controlling the complexity of \(_{}\) through regularization is crucial, especially since the bias function \(b(x)\) is used to extrapolate the CATE into low-variance regions where compliance is low and the risk of overfitting is high. In the parametric extrapolation approach (Section 4.1), applying \(L_{1}\) or \(L_{2}\) regularization via Lasso or Ridge regression in the final step is effective for controlling model complexity. In the shared representation approach (Example 1), regularization not only helps control the parameters \(h^{O}\) and \(\) but also prevents over-parametrization in the neural network \(\). The choice between \(L_{1}\) and \(L_{2}\) regularization, and how they are applied, should be aligned with the data-generating process and the specific characteristics of the model.

## 5 Experimental Results

We apply our method to both simulated and real-world data. First, we use the confounded synthetic data example from , along with a similar data generating process (DGP) to simulate an IV study, maintaining the same confounding structure and treatment effects. Using this DGP, we evaluate Algorithm 1 and Algorithm 2 in estimating the unbiased CATE by integrating these datasets. Next, we demonstrate our estimators on a real-world dataset examining the impact of 401(k) participation on financial wealth. Additional experiments, as well as details on model implementation, hyperparameter selection, and validation procedures are in Appendix C. The replication code is available at https://github.com/CausalML/Weak-Instruments-Obs-Data-CATE.

### Simulation Studies

We generate the observational dataset \(O=(X^{O},A^{O},Y^{O})\) as follows (see )1:

\[X(0,1), A(0.5), U X,A (X(A-0.5),0.75)\] \[Y=1+A+X+2AX+0.5X^{2}+0.75AX^{2}+U+0.5_{Y}, _{Y}(0,1)\] (7)

In this DGP, the true CATE is given by \((x)=0.75x^{2}+2x+1\), whereas the biased observational CATE is represented by \(^{O}(x)=0.75x^{2}+3x+1\). This results in a bias \(b(x)=-x\), which is linear in \(x\). We modify this DGP to generate the experimental IV dataset \(E=(X^{E},Z^{E},A^{E},Y^{E})\) as follows:

\[X(0,1), Z(0.5), A^{*} (0.5)\] \[(X)=(2X), C((X)), A=C  Z+(1-C) A^{*}\] \[U X,A,C C(0,1)+(1-C)(X (A-0.5),0.75)\]

where \(C\) is the (unknown) compliance indicator, \(\) is the logistic sigmoid and we keep the same outcome function as in Equation 7. In this modified DGP, the randomized instrument has compliance sharply determined by \(X\), with low \(X\) values indicating almost no compliance and high \(X\) values indicating near-perfect compliance.

Figure 2: Means and standard errors of estimates from 100 simulated dataset pairs \((O,E)\) using Random Forest (top) or Neural Network (bottom) learners. (2a): Biased observational CATE \(^{O}(x)\). (2b): High variance CATEs from the IV dataset using Equation 3. (2c): CATEs from Algorithm 2 using parametric extrapolation (top) or representation learning (bottom).

We generate 100 observational and IV datasets, each with 5,000 samples, from the proposed DGP. We first apply Algorithm 1 to each dataset. With a randomized instrument, \(_{Z}(x)=0.5\). We estimate \((x)\) as the difference between Random Forest (RF) classifiers trained on \((X^{E},A^{E}) Z^{E}=0\) and \((X^{E},A^{E}) Z^{E}=1\), _i.e._ one is trained the subset of data where the instrumental variable \(Z^{E}=0\) (using \(X^{E}\) and \(A^{E}\) as inputs), and another on the subset where \(Z^{E}=1\). The biased observational CATE is modeled using the T-learner approach , with RF regressors trained on \(X^{O},Y^{O} A^{E}=0\) and \(X^{O},Y^{O} A^{O}=1\). For comparison, we implement a CATE estimator for the experimental data using Equation 3. We compute \(_{Y}(x)\) as the difference between RF regressors trained on \(X^{E},Y^{E} Z^{E}=0\) and \(X^{E},Y^{E} Z^{E}=1\), then divide by \((x)\), clipping the compliance score at \(0.1\). We calculate \((x)\), \(^{O}(x)\), and \(^{E}(x)\) for each dataset pair and proceed with the second step of Algorithm 1 by setting \((x)=x\).

In Figure 2 (top row), we depict the means and standard errors of our estimators across 100 simulations. The first two plots illustrate the learned observational CATE \(^{O}(x)\) and the learned IV CATE \(^{E}(x)\). As expected, \(^{O}(x)\) shows clear bias, while \(^{E}(x)\) has high variance despite aggressive compliance score clipping. The third plot presents the results from Algorithm 1, showing that the resulting \((x)\) is both unbiased and has low variance across \(\). These findings demonstrate that our two-stage estimation procedure effectively leverages the strengths of both datasets to capture the true CATE and address the limitations of each individual study design.

We note that in our DGP, \((x)\), \(^{O}(x)\), and \(b(x)\) are linear in the polynomial representation \((x,x^{2})\). Thus, we next apply Algorithm 2 with Example 1 to learn the true CATE and the common representation from the generated dataset. For consistency, we employ feed-forward neural networks (NNs) to estimate all quantities. The estimator for \(\) uses a NN with a sigmoid activation in the output layer, trained on \(X^{E}\) with the pseudo-outcome \(2A^{E}Z^{E}-2A^{E}(1-Z^{E})\). The representation \((x)\) and the biased CATE \(^{O}(x)\) are learned using a representation network with two output heads for learning \(Y^{O} X^{O},A^{O}=0\) and \(Y^{O} X^{O},A^{O}=1\). A similar dual-head approach is used to learn \(_{Y}(x)\), by modeling \(Y^{E} X^{E},Z^{E}=0\) and \(Y^{E} X^{E},Z^{E}=1\) simultaneously. When calculating \(_{Y}(x)/(x)\), we clip the compliance score at \(0.1\). Unlike Algorithm 1, we don't guarantee the polynomial representation will be fully captured by the chosen representation class, but we expect a sufficiently flexible \(\) to adequately represent these relationships.

The means and standard errors of our estimators from 100 simulations using neural networks and Algorithm 2 are shown in Figure 2 (bottom row). As before, \(^{O}(x)\) shows bias, while \(^{E}(x)\) has high variance in low-compliance regions, despite compliance score clipping. However, Figure 1(c) shows that the \(\) returned by Algorithm 2 remains unbiased with relatively low variance across \(\). This demonstrates that combining observational and IV data, where the biased and true CATE share a representation, allows us to reliably learn both the representation and the unbiased CATE, overcoming the limitations of each individual study.

### Impact of 401(k) Participation on Financial Wealth

We demonstrate our method's effectiveness with a real-world case study on the impact of 401(k) participation on financial wealth, using data from the 1991 Survey of Income and Program Participation . The dataset includes 9,915 respondents with nine covariates: age, income, education, family size, marital status, two-earner status, pension status, IRA participation, and home ownership. The primary variable of interest is 401(k) participation (\(A\)), with eligibility (\(Z\)) as the instrumental

Figure 3: Impact of 401(k) participation on net worth by education level: Using \((x)\) from Algorithm 1, we fix age, income, and binary variables, varying education and marital status. The black line shows results from Algorithm 1, and the dashed line indicates predictions in the no-compliance region. \(^{O}(x)\) is the biased observational CATE, while \(^{E}(x)\) is the IV CATE without non-compliance.

variable. Although 401(k) eligibility is not randomly assigned, it is argued to maintain conditional independence given observed features . We assume 401(k) eligibility influences net worth only through 401(k) participation, characterizing this as an IV study with one-sided non-compliance, where non-eligible individuals cannot participate (\(A^{E}(0)=0\)). The target variable (\(Y\)) is net financial assets, calculated as the total of 401(k) balance, bank account balances, and interest-earning assets, minus non-mortgage debt.

To replicate the scenario in this paper, we split the dataset into two halves: one for the IV study and the other for the observational study (where we intentionally remove the instrument information). Our goal is to use these datasets, along with the parametric extension approach in Algorithm 1, to recover the unbiased CATEs. Due to one-sided non-compliance, the estimated compliance factor \((x)\) is high (\(0.49-0.90\), see Appendix C). To show the utility of our method, we introduce artificial non-compliance by setting \((x)\) to 0 for individuals with less than 12 years of education (13% of the population). In the first stage of Algorithm 1, we use RF regressors and classifiers to estimate \(^{O}(x)\), \((x)\), and \(_{Z}(x)\), with hyperparameters set based on other related work on this dataset . In the second stage, we define the mapping \((x)\) with an intercept term, the 9 covariates, and their interactions (46 features total). We apply a mild \(L_{1}\) regularization in the final linear regression due to the large number of resulting features.

In Figure 3, we study how the CATE function from Algorithm 1 varies with education. We focus on education as it is selected as a top feature by the compliance model, while the outcome models do not rank it as highly significant (see Appendix C). To explore this relationship, we vary education and marital status, holding age and income at their median values and setting all binary variables to zero. Since compliance in the IV study is high, we consider the estimate \(^{E}(x)\)_without_ the artificial non-compliance as the ground truth for comparison. Our analysis shows that observational data treatment effects are upwardly biased, likely due to unobserved confounders such as financial literacy. The \((x)\) from Algorithm 1, shown with a dashed line for non-compliance regions, closely aligns with \(^{E}(x)\) (excluding the artificial non-compliance). This demonstrates that combining IV and observational data can effectively estimate unbiased CATEs in real-world settings, offering a robust solution for causal inference even in the presence of low compliance and unobserved confounding.

## 6 Conclusion

This study introduces a method that combines observational and instrumental variable (IV) data to address unobserved confounders in observational studies and low compliance in IV studies. Our two-stage framework first estimates biased CATEs from the observational data, then corrects them using compliance-weighted IV samples. We explore two variations of our procedure: one that models confounding bias parametrically, and another that leverages a shared representation between the true and biased CATEs. Both methods are shown to be consistent, validated through simulations and real-world applications. Our approach holds significant promise for applications in digital platforms, personalized medicine, and economics, offering a robust tool for deriving reliable, actionable insights from complex data. Limitations of our work are discussed in Appendix D.

#### Acknowledgements

We thank the anonymous reviewers for their valuable feedback and insightful suggestions. This material is based upon work supported by the National Science Foundation under Grant No. 1846210 and by the U.S. Department of Energy, Office of Science, Office of Advanced Scientific Computing Research, under Award Number DE-SC0023112.