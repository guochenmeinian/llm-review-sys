# Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation

Jiawei Wang\({}^{1}\) &Renhe Jiang\({}^{1}\) &Chuang Yang\({}^{1}\) &Zengqing Wu\({}^{2}\)

Makoto Onizuka\({}^{2}\) &Ryosuke Shibasaki\({}^{1}\) &Noboru Koshizuka\({}^{1}\) &Chuan Xiao\({}^{2}\)

\({}^{1}\)The University of Tokyo, \({}^{2}\)Osaka University

{jiawei@g.ecc, koshizuka@iiiij}.u-tokyo.ac.jp

{jiangrh,chuang.yang,shiba}@csis.u-tokyo.ac.jp

wuzengqing@outlook.com, {onizuka,chuanx}@ist.osaka-u.ac.jp

Corresponding author.

###### Abstract

This paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and effective personal mobility generation. LLMs overcome the limitations of previous models by effectively processing semantic data and offering versatility in modeling various tasks. Our approach addresses three research questions: aligning LLMs with real-world urban mobility data, developing reliable activity generation strategies, and exploring LLM applications in urban mobility. The key technical contribution is a novel LLM agent framework that accounts for individual activity patterns and motivations, including a self-consistency approach to align LLMs with real-world activity data and a retrieval-augmented strategy for interpretable activity generation. We evaluate our LLM agent framework and compare it with state-of-the-art personal mobility generation approaches, demonstrating the effectiveness of our approach and its potential applications in urban mobility. Overall, this study marks the pioneering work of designing an LLM agent framework for activity generation based on real-world human activity data, offering a promising tool for urban mobility analysis.

Source codes are available at https://github.com/Wangjw6/LLMob/.

## 1 Introduction

The prevalence of large language models (LLMs) has facilitated a variety of applications extending beyond the domain of NLP. Notably, LLMs have gained widespread usage in furthering our understanding of humans and society in a multitude of disciplines, such as economy  and political science , and have been employed as agents in various social science studies . In this paper, we target the utilization of LLM agents for the study of personal mobility data. Modeling personal mobility opens up numerous opportunities for building a sustainable community, including proactive traffic management and the design of comprehensive urban development strategies . In particular, generating reliable activity trajectories has become a promising and effective way to exploit individual activity data . On one hand, learning to generate activity trajectory leads to a thorough understanding of activity patterns, enabling the flexible simulation of urban mobility. On the other hand, while individual activity trajectory data is abundant thanks to advances in telecommunications, its practical use is often limited due to privacy concerns. In this sense, generated data can provide a viable alternative that offers a balance between utility and privacy.

While advanced data-driven learning-based methods offer various solutions to generate synthetic individual trajectories , the generated data only imitates real-world data from the data distribution perspective rather than semantics, rendering them less effective in simulating or interpreting activities in novel or unforeseen scenarios with a significantly different distribution (e.g., a pandemic). Thus, in this study, to explore a more intelligent and effective activity generation, we propose to establish a trajectory generation framework by exploiting the emerging intelligence of LLM agents, as illustrated in Figure 1. LLMs present two significant advantages over previous models when applied to activity trajectory generation:

* **Semantic Interpretability.** Unlike previous models, which have predominantly depended on structured data (e.g., GPS coordinates-based trajectory data) for both calibration and simulation , LLMs exhibit proficiency in interpreting semantic data (e.g., activity trajectory data). This advantage significantly broadens the scope for incorporating a diverse array of data sources into generation processes, thereby enhancing the models' ability to understand and interact with complex, real-world scenarios in a more nuanced and effective manner.
* **Model Versatility.** Although other data-driven methods manage to learn such dynamic activity patterns for generation, their capacity is limited for generation under unseen scenarios. On the contrary, LLMs have shown remarkable versatility in dealing with unseen tasks, especially the ability to reason and decide based on available information . This competence enables LLMs to offer a diverse and rational array of choices, making it a promising and flexible approach for modeling personal mobility patterns.

Despite these benefits, ensuring that LLMs align effectively with real-world situations continues to be a significant challenge . This alignment is particularly crucial in the context of urban mobility, where the precision and dependability of LLM outputs are essential for the efficacy of any urban management derived from them. In this study, our aim is to address this challenge by investigating the following research questions: **RQ 1:** How can LLMs be effectively aligned with semantically rich data about daily individual activities? **RQ 2:** What are the effective strategies for achieving reliable and meaningful activity generation using LLM agents? **RQ 3:** What are the potential applications of LLM agents in enhancing urban mobility analysis?

To this end, our study employs LLM agents to infer activity patterns and motivation for personal activity generation tasks. While previous researches advocate habitual activity patterns and motivations as two critical elements for activity generation , our proposed framework introduces a more interpretable and effective solution. By leveraging the capabilities of LLMs to process semantically rich datasets (e.g., personal check-in data), we enable a nuanced and interpretable simulation of personal mobility. Our methodology revolves around two phases: (1) activity pattern identification and (2) motivation-driven activity generation. In Phase 1, we leverage the semantic awareness of LLM agents to extract and identify self-consistent, personalized habitual activity patterns from historical data. In Phase 2, we develop two interpretable retrieval-augmented strategies that utilize the patterns identified in Phase 1. These strategies guide LLM agents to infer underlying daily motivations, such as evolving interests or situational needs. Finally, we instruct LLM agents to act as urban residents according to the obtained patterns and motivations. In this way, we generate their daily activities in a specific reasoning logic.

We evaluate the proposed framework using GPT-3.5 APIs over a personal activity trajectory dataset of Tokyo. The results demonstrate the capability of our framework to align LLM agents with semantically rich data for generating individual daily activities. The comparison with baselines,

Figure 1: Personal mobility generation with an LLM agent.

such as attention-based methods [8; 22], adversarial learning methods [6; 42], and a diffusion model , underscores the advanced generative performance of our framework. The observation also suggests that our framework excels in reproducing temporal and spatio-temporal aspects of personal mobility generation and interpretable activity routines. Moreover, the application of the framework in simulating urban mobility under specific contexts, such as a pandemic scenario, reveals its potential to adapt to external factors and generate realistic activity patterns.

To the best of our knowledge, this study is _one of the pioneering works in developing an LLM agent framework for generating activity trajectory based on real-world data_. We summarize our contributions as follows: (1) We introduce a novel LLM agent framework for personal mobility generation featuring semantic richness. (2) Our framework introduces a self-consistency evaluation to ensure that the output of LLM agents aligns closely with real-world data on daily activities. (3) To generate daily activity trajectories, our framework integrates activity patterns with summarized motivations, with two interpretable retrieval-augmented strategies aimed at producing reliable activity trajectories. (4) By using real-world personal activity data, we validate the effectiveness of our framework and explore its utility in urban mobility analysis.

## 2 Related Work

### Personal Mobility Generation

Activity trajectory generation offers a valuable perspective for understanding personal mobility. Based on vast call detailed records, Jiang et al. built a mechanistic modeling framework to generate individual activities in high spatial-temporal resolutions. Pappalardo and Simini employed Markov modeling to estimate the probability of individuals visiting specific locations. Besides, deep learning has become a robust tool for modeling the complex dynamics of traffic [15; 13; 44; 9; 21]. The primary challenge involves overcoming data-related obstacles such as randomness, sparsity, and irregular patterns [8; 43; 42; 20]. For example, Feng et al. proposed attentional recurrent networks to handle personal preference and transition regularities. Yuan et al. leveraged deep learning combined with neural differential equations to address the challenges of randomness and sparsity inherent in irregularly sampled activities for activity trajectory generation. Recently, Zhu et al. proposed to utilize a diffusion model to generate GPS trajectories.

### LLM Agents in Social Science

Exploring how to treat LLMs as autonomous agents in specific scenarios leads to diverse and promising applications in social science [32; 36; 35; 10]. For instance, Park et al. established an LLM agent framework to simulate human behavior in an interactive scenario, demonstrating the potential of LLMs to model complex social interactions and decision-making processes. Moreover, the application of LLM agents in economic research has been explored, providing new insights into financial markets and economies [11; 19]. Extending beyond the realm of social sciences, Mao et al. adeptly utilized LLMs to generate driving trajectories in motion planning tasks. In the field of natural sciences, Williams et al. integrated LLMs with epidemic models to simulate the spread of diseases. These varied applications highlight the versatility and potential of LLMs to understand and model various real-world dynamics.

## 3 Methodology

We consider the generation of individual daily activity trajectories, each representing an individual's activities for the whole day. In addition, we focus on the urban context, where the activity trajectory of each individual is represented as a time-ordered sequence of location choices (e.g., POIs) . This sequence is represented by \(\{(l_{0},t_{0}),(l_{1},t_{1}),,(l_{n},t_{n})\}\), where each \((l_{i},t_{i})\) denotes the individual's location \(l_{i}\) at time \(t_{i}\).

By modeling individuals within an urban environment as LLM agents, we present LLMob, an LLM Agent Framework for Personal Mobility Generation, as illustrated in Figure 2. LLMob is based on the assumption that an individual's activities are primarily influenced by two principal factors: habitual activity patterns and current motivations. Habitual activity patterns, representing typical movement behaviors and preferences that indicate regular travel and location choices, are recognizedas crucial information for inferring daily activities [31; 7; 30]. On the other hand, motivations relate to dynamic and situational elements that sway an individual's choices at any particular moment, such as immediate needs or external circumstances during a specific period. This consideration is vital for capturing and forecasting short-term shifts in mobility patterns [1; 43]. Moreover, by formulating prompts that assume specific events of concern, this framework allows us to observe the LLM agent's responses in a variety of situations.

To construct a pipeline for activity trajectory generation, we design an LLM agent with action, memory, and planning [33; 32]. Action specifies how an agent interacts with the environment and makes decisions. In LLMob, the environment contains the information collected from real-world data, and the agent acts by generating trajectories. Memory includes past actions that need to be prompted to the LLM to invoke the next action. In LLMob, memory refers to the patterns and motivations output by the agent. Planning formulates or refines a plan over past actions to handle complex tasks, with additional information optionally incorporated as feedback. In LLMob, we use planning to identify patterns and motivations, thereby handling the complex task of trajectory generation. Plan formulation, selection, reflection, and refinement  are employed in succession, and the agent keeps updating the action plan based on its observation : The agent first formulates a set of activity plans by extracting candidate patterns from historical trajectories in the database. The agent then performs self-reflection through a self-consistency evaluation to pick the best pattern from the candidate patterns. With historical trajectories further retrieved from the database, the agent refines the identified pattern to a summarized motivation of daily activity, which is then jointly used with the identified pattern for trajectory generation. In addition to the above agentic components, we also suggest the personas of the agent, which can facilitate the LLM to simulate the diversity of real-world individuals .

### Activity Pattern Identification

Phase 1 of LLMob focuses on identifying activity patterns from historical data. To effectively leverage the extracted activity patterns as essential prior knowledge for the generation of daily activities, we introduce the following two steps.

#### 3.1.1 Pattern Extraction from Semantics and Historical Data

This step derives activity patterns based on activity trajectory data (e.g., individual check-in data). As illustrated in the left panel of Figure 2, this scheme consists of the following aspects: For each person, we start by specifying a candidate personas to the LLM agent, providing the inspiring foundation for subsequent activity pattern generation. This approach also encourages the diversity of the generated

Figure 2: LLMob, the proposed LLM agent framework for personal MÃ¶bius generation.

activity patterns, as each candidate persona acts as a unique prior for the generation process (e.g., the significance of user clustering from activity trajectory data in producing meaningful distinctions has been demonstrated ). Meanwhile, we perform data preprocessing to extract key information from the extensive historical data. This involves identifying usual commuting distances, pinpointing typical start and end times and locations of daily trips, and concluding the most frequently visited locations of the person. It is important to note that these pieces of information are widely recognized as critical features in mobility analysis . After the preprocessing procedure, both semantic elements with historical data are combined in the prompts, requiring the LLM agent to summarize the activity patterns for this person. By doing this, we set up a streamline to effectively bridge the gap between semantic persona characteristics and concrete historical activity trajectory data, which allows for a more personalized and interpretable representation of individual activities in one day. Moreover, we propose adding candidate personas to the prompt during candidate pattern generation to promote the diversity of the results. Without loss of generality, for each person, a set of \(C\) (\(C=10\)) candidate patterns, denoted as \(\), are generated according to the historical data and \(C\) candidate personas, respectively. We provide the details of these candidate personas in Appendix C.4.

#### 3.1.2 Pattern Evaluation with Self-Consistency

This step involves assessing the consistency of the candidate patterns to identify the most plausible one. We implement a scoring mechanism to evaluate the alignment of candidate patterns with historical data. To achieve this objective, we define a scoring function to gauge each candidate pattern \(cp\) in the set \(\). This function evaluates \(cp\) against two distinct sets of activity trajectories: the specific activity trajectories \(_{i}\) of a targeted resident \(i\) and the sampled activity trajectories from other residents \(_{ i}\):

\[score_{cp}=_{t_{i}}r_{t}-_{t^{}_{  i}}r_{t^{}},\] (1)

where we design an evaluation prompt to ask the LLM to generate rating scores \(r_{t}\) and \(r_{t^{}}\). Specifically, the LLM agent is prompted to assess the degree of preference for a given trajectory based on the candidate pattern. Ideally, the LLM agent should assign a higher \(r_{t}\) for data from the targeted resident and a lower \(r_{t^{}}\) for data from other residents. This scheme essentially identifies the self-consistent pattern: the activity pattern derived from the activity trajectory data of the target user should be consistent with the data from this person during the evaluation. We provide the pseudo-code of the algorithm for Phase 1 of LLMob in Appendix A.

### Motivation-Driven Activity Generation

In Phase 2 of LLMob, we focus on the retrieval of motivation and the integration of motivation and activity patterns for individual activity trajectory generation. Since the context length is limited for the LLMs, we can not expect that the LLMs can consume all the available historical information and give plausible output. Retrieval-augmented generation has been identified as a crucial factor in boosting the performance of LLM . This enhancement provides additional information that aids LLM in more effectively responding to queries. While previous studies on activity generation mainly overlook the critical factors of macro temporal information (e.g., date) or specific scenarios (e.g., harsh weather) , we propose a more sophisticated activity generation which accounts for various conditions by taking advantage of the human-like intelligence of LLM. For instance, the activity trajectory at date \(d\) can be inferred given the motivation of this date and the habitual activity pattern as:

\[_{d}=LLM(Motivation,attern).\] (2)

This generation scheme instructs the LLM agent to simulate a designated individual according to a given activity pattern, and then meticulously generate an activity trajectory in accordance with the daily motivation. To obtain insightful and reliable motivations toward different aspects of data availability and sufficiency, two retrieval schemes are proposed. Notably, we considered them as two promising directions for designing solutions to real-world applications, rather than clamping which is superior. The detail of each retrieval scheme is introduced as follows:
This scheme is related to the intuitive principle that an individual's motivation on any given day is influenced by her interests and priorities in preceding days . Guided by this understanding, our approach harnesses the intelligence of the LLM agent to understand the behavior of daily activities and the underlying motivations. As illustrated in Figure 3, for a specific date \(d\) for which we aim to generate the activity trajectory, we consider the activities of the past \(k\) days (\(k=(7,l)\), where \(l\) is the maximum value such that the trajectory for date \(d-l\) can be found in the database), and prompt the LLM agent to act as an urban resident based on the pattern identified in Section 3.1 and summarize \(k\) motivations behind these activities. Using these summarized motivations, the LLM agent is further prompted to infer potential motivation for the target date \(d\).

#### 3.2.2 Learning-based Motivation Retrieval

In this scheme, we hypothesize that individuals tend to establish routines in their daily activities, guided by consistent motivations even if the specific locations may vary. For example, if someone frequently visits a burger shop on weekday mornings, this behavior might suggest a motivation for a quick breakfast. Based on this, it is plausible to predict that the same individual might choose a different fast food restaurant in the future, motivated by a similar desire for convenience and speed during their morning meal. We introduce a learning-based scheme to retrieve motivation from historical data. For each new date on which to plan activities, the only information available is the date itself. To use this clue for planning, we first formulate a relative temporal feature \(_{d_{c},d_{p}}\) between a past date \(d_{p}\) and the current date \(d_{c}\). This feature captures various aspects, such as the gap between these two dates and whether they belong to the same month. Utilizing this setting, we train a score approximator \(f_{}(_{d_{c},d_{p}})\) to evaluate the similarity between any two dates. Notably, due to the lack of supervised signals, we employ unsupervised learning to train \(f_{}()\). Particularly, a learning scheme based on contrastive learning  is established. For each trajectory of a resident, we can scan her other trajectories and identify similar (positive) and dissimilar (negative) dates according to a predefined similarity score. This similarity score is calculated between two activity trajectories \(_{d_{a}}\) and \(_{d_{b}}\) as:

\[sim_{d_{a},d_{b}}=_{t=1}^{N_{d}}_{(_{d_{a}}(t)= _{d_{b}}(t))}|_{d_{a}}|>t|_{d_{b}}|>t,\] (3)

where \(N_{d}\) is the total number of time intervals (e.g., 10 min) in one day. \(_{d_{a}}(t)\) indicates the \(t\)th visiting location recorded in trajectory \(_{d_{a}}\). Intuitively, there should be more shared locations in the similar trajectory pair. Thereafter, the positive pair is characterized by the highest similarity score, indicative of a greater degree of resemblance between the trajectories. Conversely, the negative pairs are marked by low similarity scores, reflecting a lesser degree of commonality. After obtaining the training dataset from these positive and negative pairs, we train a model to approximate the similarity score between any two dates by contrastive learning. This procedure involves the following steps:

1. For each date \(d\), generate one positive pair \((d,d^{+})\) and \(k\) negative pairs (\(d,d^{-}_{1}\)),..., (\(d,d^{-}_{k}\)) based on the similarity score and compute \(_{d,d^{+}}\), \(_{d,d^{-}_{1}}\),..., \(_{d,d^{-}_{k}}\).
2. Forward the positive and negative pairs to \(f_{}()\) to form: \[=[f_{}(_{d,d^{+}}),f_{}(_{d,d^{-}_{ 1}}),...,f_{}(_{d,d^{-}_{k}})].\] (4)
3. Adopt InfoNCE  as the contrastive loss function: \[()=_{n=1}^{N}-(_{i}}}{_{j=1}^{k+1}e^{_{j}}})_{n},\] (5) where \(N\) is the batch size of the samples and \(i\) indicates the index of the positive pair.

Figure 3: Evolving-based motivation retrieval.

Upon training a similarity score approximation mode, it can be applied to access the similarity between any given query date and historical dates. This enables us to retrieve the most similar historical data, which is prompted to the LLM agent to generate a summary of the motivations prevalent at that time. By doing so, we can extrapolate a motivation relevant to the query date, providing a basis for the LLM agent to generate a new activity trajectory.

## 4 Experiments

### Experimental Setup

**Dataset.** We investigate and validate LLMob over a personal activity trajectory dataset from Tokyo. This dataset was obtained through Twitter and Foursquare APIs and covers the data from January 2019 to December 2022. The time frame of this dataset is insightful as it captures typical daily life prior to the COVID-19 pandemic (i.e., normal period) and subsequent alterations during the pandemic (i.e., abnormal period). To facilitate a cost-efficient and detailed analysis for different periods, we randomly choose 100 users to model their individual activity trajectory at a 10-minute interval according to the number of available trajectories. Samples are shown in the following Table 1.

We utilize the category classification in Foursquare to determine the activity category for each location. We use 10 candidate personas (Appendix C.4) as a prior for subsequent pattern generation, which captures a diverse range of activity patterns within the data of this study. For the application to other datasets, this style of candidate patterns can be easily initialized using an LLM.

**Metrics.** The following characteristics related to personal activity are used to examine the generation: (1) **Step distance (SD)**: The travel distance between each consecutive decision step within a trajectory is collected. This metric evaluates the spatial pattern of an individual's activities by measuring the distance between two consecutive locations in a trajectory. (2) **Step interval (SI)**: The time gap between each consecutive decision step within a trajectory is recorded. This metric evaluates the temporal pattern of an individual's activities by measuring the time interval between two successive locations on an individual's trajectory. (3) **Daily activity routine distribution (DARD)**: For each decision step, a tuple \((t,c)\) is created, where \(t\) represents the occurring time interval (e.g., from 0 to 144 in a day) and \(c\) identifies the activity category based on the location visited at that step. A histogram is then constructed to represent the distribution of the collected tuples. This feature presents the patterns of individual activities characterized by activity type and timing (e.g., activity type, time). It provides insight into how activities are distributed over space and time and reflects semantic information such as habitual behavior. (4) **Spatial-temporal visits distribution (STVD)**: For each decision step, a tuple \((t,,)\) is created, where \(t\) represents the occurring time interval (e.g., from 0 to 144 in a day) and latitude, longitude are the geographic coordinates of the location visited at that step. A histogram is subsequently built to represent the distribution of the collected tuples. This feature provides a granular perspective on the generated activities by assessing the spatial-temporal distribution of visited locations within each trajectory, including geographical coordinates and timestamps. It enables a detailed analysis of where and when activities occur.

After extracting the above characteristics from both the generated and real-world trajectory data, Jensen-Shannon divergence (JSD) is employed to quantify the discrepancy between them. Lower JSD is preferred.

**Methods.** LLMob is evaluated against: Markov-based mechanic model (MM) , an LSTM-based prediction model (LSTM) , two attention-based prediction models, including DeepMove  and STAN . Within the domain of deep generative models, we select two adversarial learning frameworks, including TrajGAIL  and ActSTD , as well as a diffusion model, DiffTraj .

  
**UserID** & **Latitude** & **Longitude** & **Location Name** & **Category** & **Time** \\ 
44673 & 35.008 & 139.015 & Convenience Store & Shop \& Service & 2019-12-17 8:00 \\
44673 & 35.009 & 139.018 & Ramen Restaurant & Food \& Service & 2019-12-17 8:30 \\
44673 & 35.004 & 139.060 & Italian Restaurant & Food \& Service & 2019-12-17 11:20 \\
44673 & 35.009 & 139.085 & Farmers Market & Shop \& Service & 2019-12-17 14:20 \\
44673 & 35.005 & 139.086 & Soba Restaurant & Food \& Service & 2019-12-17 18:00 \\   

Table 1: Samples of personal activity data.

We use the source codes of the baselines provided by their respective authors and adapt them to our setting.

To achieve a balance between capability and cost efficiency, we employ GPT-3.5-turbo-0613 as the LLM core. We use "LLMob-E" to represent the proposal with the **evolving-based motivation retrieval** scheme, and "LLMob-L" to denote the framework that incorporates the **learning-based motivation retrieval** scheme (parameter settings in Appendix C.3). To validate the necessity of each module proposed, we conduct ablation studies with the following configurations: "LLMob w/o \(\)" denotes the framework generating trajectories without using the pattern (i.e., directly summarizing motivations from past trajectories). "LLMob w/o \(\)" denotes the framework without the motivation (i.e., directly generating trajectories with the identified pattern). "LLMob w/o \(\)" denotes the framework without the self-consistency evaluation (in this case, a candidate pattern is randomly picked as the identified pattern). Furthermore, "LLMob w/o \(\) & \(\)" represents the framework excluding both patterns and motivations.

### Main Results and Analysis

**Generative Performance Validation (RQ 1, RQ 2).** The performance evaluation involves analyzing generation results in three distinct settings: (1) Generating normal trajectories based on normal historical trajectories in 2019, a period unaffected by the pandemic. (2) Generating abnormal trajectories based on abnormal historical trajectories in 2020, a year marked by the pandemic. (3) Generating abnormal trajectories in 2021 (pandemic) based on normal historical trajectories in 2019.

The results of these evaluations are detailed in the metrics reported in Table 2. Through the comparison, it can be observed that although LLMob may not excel in replicating spatial features (SD) precisely, it demonstrates superior performance in handling temporal aspects (DI). When considering spatial-temporal features (DARD and STVD), LLMob's performance is also competitive. In particular, LLMob achieves the best performance on DI and DARD for all three settings and is the runner-up on STVD. Baselines like DeepMove and TrajGAIL perform the best on SD and STVD, respectively, but become much less competitive when evaluated in other aspects. We suggest that the pronounced advantage of LLMob in terms of DARD (roughly 1/2 to 1/3 JSD compared to the best of baselines) can be attributed to the LLM agent's tendency to accurately replicate the motivation behind individual activity behaviors. For instance, an agent may recognize patterns like a person's habits to have breakfast in the morning, without being restricted to a specific restaurant. This phenomenon highlights the enhanced semantic understanding capabilities of the LLM agent.

**Exploring Utility in Real-World Applications (RQ 3).** We are interested in how LLMob can elevate the social benefits, particularly in the context of urban mobility. To this end, we propose an example of leveraging the flexibility and intelligence of LLM agents in understanding semantic information and simulating an unseen scenario. In particular, we enhance the original setup by incorporating an additional prompt to provide a context for the LLM agent, enabling it to plan activities during specific circumstances. For example, a "pandemic" prompt is as follows: _Now it is the pandemic period. The government has asked residents to postpone travel and events and to telecom

    &  &  &  \\  &  &  &  \\   & SD & SI & DARD & STVD & SD & SI & DARD & STVD & SD & SI & DARD & STVD \\  MM  & 0.018 & 0.276 & 0.644 & 0.681 & 0.041 & 0.300 & 0.629 & 0.682 & 0.039 & 0.307 & 0.644 & 0.681 \\ LSTM  & 0.017 & 0.271 & 0.585 & 0.652 & 0.016 & 0.286 & 0.563 & 0.655 & 0.035 & 0.282 & 0.585 & 0.653 \\ DeepMove  & **0.008** & 0.153 & 0.534 & 0.623 & 0.011 & 0.173 & 0.548 & 0.668 & **0.013** & 0.173 & 0.534 & 0.623 \\ STAN  & 0.152 & 0.400 & 0.692 & 0.692 & 0.115 & 0.092 & 0.693 & 0.691 & 0.142 & 0.094 & 0.692 & 0.690 \\ TrajGAIL  & 0.128 & 0.058 & 0.598 & **0.489** & 0.133 & 0.060 & 0.604 & **0.523** & 0.332 & 0.058 & 0.434 & **0.428** \\ ActSDT  & 0.034 & 0.436 & 0.693 & 0.692 & 0.071 & 0.469 & 0.692 & 0.692 & 0.022 & 0.093 & 0.468 & 0.692 \\ DiffTraj  & 0.052 & 0.251 & 0.318 & 0.692 & **0.008** & 0.240 & 0.339 & 0.692 & 0.101 & 0.142 & 0.218 & 0.693 \\ LLMob-E & 0.053 & **0.046** & **0.125** & 0.559 & 0.056 & **0.043** & 0.127 & 0.615 & 0.062 & 0.056 & **0.117** & 0.536 \\ LLMob-E w/o \(\) & 0.055 & 0.069 & 0.223 & 0.530 & 0.509 & 0.081 & 0.252 & 0.673 & 0.065 & 0.079 & 0.209 & 0.561 \\ LLMob-E w/o \(\) & 0.088 & 0.076 & 0.295 & 0.589 & 0.068 & 0.086 & 0.025 & 0.649 & 0.072 & 0.096 & 0.301 & 0.589 \\ LLMob-L & 0.049 & 0.054 & 0.136 & 0.570 & 0.057 & 0.051 & **0.124** & 0.609 & 0.064 & **0.051** & 0.124 & 0.531 \\ LLMob-L w/o \(\) & 0.061 & 0.080 & 0.270 & 0.600 & 0.072 & 0.081 & 0.286 & 0.641 & 0.073 & 0.091 & 0.248 & 0.580 \\ LLMob-L w/o \(\) & 0.057 & 0.074 & 0.236 & 0.602 & 0.071 & 0.084 & 0.236 & 0.642 & 0.073 & 0.094 & 0.286 & 0.622 \\ LLMob w/o \(\) & 0.059 & 0.078 & 0.264 & 0.590 & 0.066 & 0.080 & 0.274 & 0.633 & 0.074 & 0.

By integrating the above prompt, we can observe the impact of external elements, such as the pandemic and the government's measures, on urban mobility and related social dynamics. We use the activity trajectory data during the pandemic (2021) as ground truth and plot the daily activity frequency in 7 categories in Figure 4. TrajGAIL, despite delivering the best STVD in Table 2, displays very low frequencies for all the categories, and fails to reflect the tendency of each category. In contrast, a comparison between LLMob-L and the one augmented with the pandemic prompt demonstrates the impact of external factors: there is a significant decrease in activity frequency with the pandemic prompt, which semantically discourages activities likely to spread the disease (e.g., food).

Additionally, from a spatial-temporal perspective, two major activities (e.g., _Arts & entertainment_ and _Professional & other places_) are selected to observe the behavior, as shown in Figures 4(a) and 4(b). These activities are particularly insightful as they encapsulate the impact of the pandemic on the work-life balance and daily routines of residents. Specifically, with the pandemic prompt, LLMob reproduces a more realistic spatial-temporal activity pattern. This enhanced realism in the generation is attributed to the integration of prior knowledge about the pandemic's effects and governmental responses, allowing the LLM agent to behave in a manner that aligns with actual behavioral adaptations. For instance, the reduction in _Arts & entertainment_ activities reflects the closure of venues and social distancing guidelines, while changes in _Professional & other places_

Figure 4: Daily activity frequency.

Figure 5: Activity heatmaps for the pandemic scenario.

activities indicate shifts toward remote work and the transformation of professional environments. Intuitively, prompting the LLM agent to generate activities based on various priors shows great potential in real-world applications. The utility of such a conditioned generative approach, coupled with the reliable generated results, can significantly alleviate the workload of urban managers. We suggest that this kind of workflow can simplify the analysis of urban dynamics and aid in assessing the potential impact of urban policies.

### Ablation Studies

**Impact of Patterns.** In Table 2, by comparing LLMob with and without using patterns ("w/o \(\)"), we observe that the identified patterns consistently enhance the trajectory generation performance. The improvement on DARD is the most significant (reducing JSD by around 50%), showcasing the use of patterns is a key factor in capturing the semantics of daily activity. We provide example patterns in Appendix D.1 to show how the habitual behaviors of individuals are recognized by patterns.

**Impact of Self-Consistency Evaluation.** By comparing LLMob with and without self-consistency evaluation ("w/o \(\)") in Table 2, we find that self-consistency is useful in all aspects, and its impact is the most significant on DARD, especially when generating abnormal trajectories from normal data, showcasing its effectiveness in processing semantics. We also observe that "w/o \(\)" performs even worse than "w/o \(\)" in many cases, because in "w/o \(\)", a candidate pattern is randomly picked for summarizing motivations, potentially introducing inconsistency to an individual's daily activity.

**Impact of Motivations.** We compare LLMob with and without motivations ("w/o \(\)"). As can been seen in Table 2, the impact of motivations is similar to that of patterns. By comparing to LLMob with both patterns and motivations removed ("w/o \(\) & \(\)"), we observe that these two factors collectively lead to better performance. To show the motivations and the generated trajectories, we provide examples in Appendix D.2, where consistency between them can be observed.

**Impact of Motivation Retrieval Strategy.** We compare LLMob equipped with the two motivation retrieval strategies ("-E" and "-L"). Table 2 shows that no retrieval strategy always outperforms the other, though evolving-based retrieval wins in more cases (7 vs 5). Moreover, evolving-based retrieval is generally less sensitive to the removal of patterns or self-consistency evaluation, suggesting that resorting to the LLM to process historical trajectories is more robust than using contrastive learning.

## 5 Conclusion

**Contributions.** This study is believed to be the first personal mobility simulation empowered by LLM agents on real-world data. Our innovative framework leverages activity patterns and motivations to direct LLM agents in emulating urban residents, facilitating the generation of interpretable and effective individual activity trajectories. Extensive experimental studies based on real-world data are conducted to validate the proposed framework and demonstrate the promising capabilities of LLM agents to improve urban mobility analysis.

**Social Impacts.** Leveraging artificial intelligence to enhance societal benefits is increasingly promising, especially with the advent of high-capacity models such as LLMs. This study explores one of the potential avenues for applications using LLMs as reliable agents to simulate specific scenarios to assess the effects of external factors, such as pandemics and government policies. The introduced framework offers a flexible approach to enhance the reliability of LLMs in simulating urban mobility.

**Limitations.** In this study, we focused on modeling the activities of individual agents without considering interactions between them. As future work, we aim to extend this to a multi-agent scenario to capture interactions (e.g., where individuals may follow the activities of friends or family members). Given the challenges in collecting high-quality personal mobility data--many datasets lack completeness in capturing daily activities--we limited our comprehensive experimental evaluation to a single dataset. Furthermore, due to cost-efficiency considerations, only GPT-3.5 was fully evaluated. An additional analysis in a different city is provided in Appendix D.3, and Appendix D.4 includes supplementary evaluations using other LLMs.