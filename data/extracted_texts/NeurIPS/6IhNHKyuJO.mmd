# Hierarchical Randomized Smoothing

Yan Scholten\({}^{1}\), Jan Schuchardt\({}^{1}\), Aleksandar Bojchevski\({}^{2}\) & Stephan Gunnemann\({}^{1}\)

{y.scholten, j.schuchardt, s.guennemann}@tum.de, a.bojchevski@uni-koeln.de

\({}^{1}\)Dept. of Computer Science & Munich Data Science Institute, Technical University of Munich

\({}^{2}\)University of Cologne, Germany

###### Abstract

Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness certificates for discrete and continuous domains. We experimentally demonstrate the importance of hierarchical smoothing in image and node classification, where it yields superior robustness-accuracy trade-offs. Overall, hierarchical smoothing is an important contribution towards models that are both - certifiably robust to perturbations and accurate.1

## 1 Introduction

Machine learning models are vulnerable to small input changes. Consequently, their performance is typically better during development than in the real world where noise, incomplete data and adversaries are present. To address this problem, robustness certificates constitute useful tools that provide provable guarantees for the stability of predictions under worst-case perturbations, enabling us to analyze and guarantee robustness of our classifiers in practice.

Randomized smoothing (Lecuyer et al., 2019; Cohen et al., 2019) is a powerful and highly flexible framework for making arbitrary classifiers certifiably robust by averaging out small discontinuities in the underlying model. This is achieved by guaranteeing robustness of the majority vote when randomly adding noise to a model's input before classification. This typically yields a robustness-accuracy trade-off - more noise increases certifiable robustness but also reduces clean accuracy.

Recent adversarial attacks against image classifiers (Su et al., 2019; Croce and Hein, 2019; Modas et al., 2019) and graph neural networks (Ma et al., 2020) further motivate the need for more flexible robustness certificates against threat models where adversaries are bounded by both: the number of perturbed entities and perturbation strength. For example in social networks, adversaries typically cannot control entire graphs, but the perturbation of the controlled nodes may be (imperceptibly) strong.

When adversaries perturb only a subset of all entities, existing smoothing-based approaches sacrifice robustness over accuracy (or vice versa): They either add noise to entire objects (e.g. images/graphs) or ablate entire entities (e.g. pixels/nodes) even if only a small subset is perturbed and requires noising.

The absence of appropriate tools for decomposable data prevents us from effectively analyzing the robustness of models such as image classifiers or graph neural networks - raising the research question: _How can we provably guarantee robustness under adversaries that perturb only a subset of all entities?_ We propose hierarchical randomized smoothing: By only adding noise on a randomly selected subset of all entities we achieve stronger robustness guarantees while maintaining high accuracy (Figure 1).

Our hierarchical smoothing framework is highly flexible and can integrate the whole suite of smoothing distributions for adding random noise to the input, provided that the corresponding certificates exist. Notably, our certificates apply to a wide range of models, domains and tasks and are at least as efficient as the certificates for the underlying smoothing distribution.

We instantiate hierarchical smoothing with well-established smoothing distributions (Cohen et al., 2019; Bojchevski et al., 2020; Levine and Feizi, 2020; Scholten et al., 2022), yielding novel robustness certificates for discrete and continuous domains. Experimentally, hierarchical smoothing significantly expands the Pareto-front when optimizing for accuracy and robustness, revealing novel insights into the reliability of image classifiers and graph neural networks (GNNs).

In short, our main contributions are:

* We propose a novel framework for strong robustness certificates for complex data where objects (e.g. images or graphs) can be decomposed into multiple entities (e.g. pixels or nodes).
* We instantiate our framework with well-established smoothing distributions, yielding novel robustness certificates for discrete and continuous domains.
* We demonstrate the importance of hierarchical smoothing in image and node classification, where it significantly expands the Pareto-front with respect to robustness and accuracy.

## 2 Related work

Despite numerous research efforts, the vulnerability of machine learning models against adversarial examples remains an open research problem (Hendrycks et al., 2021). Various tools emerged to address adversarial robustness: Adversarial attacks and defenses allow to evaluate and improve robustness empirically (Szegedy et al., 2014; Goodfellow et al., 2015; Carlini et al., 2019; Croce and Hein, 2019). While attacks provide an upper bound on the adversarial robustness of a model, robustness certificates provide a provable lower bound. The development of strong certificates is challenging and constitutes a research field with many open questions (Li et al., 2020).

**Robustness certification via randomized smoothing.** Randomized smoothing (Lecuyer et al., 2019; Cohen et al., 2019) represents a framework for making arbitrary classifiers certifiably robust while scaling to deeper architectures. There are two main approaches discussed in the literature: Additive noise certificates add random noise to continuous (Cohen et al., 2019) or discrete (Lee et al., 2019) input data. Ablation certificates "mask" out parts of the input to hide the potentially perturbed information (Levine and Feizi, 2020). Since the input is masked, ablation certificates can be applied to both continuous and discrete data. We are the first to combine and generalize additive noise and ablation certificates into a novel hierarchical framework: We first select entities to ablate, but instead of ablating we add noise to them. By only partially adding noise to the input our framework is more flexible and allows us to better control the robustness-accuracy trade-off under our threat model.

Figure 1: Hierarchical randomized smoothing: We first select a subset of all entities and then add noise to the selected entities only. We achieve stronger robustness guarantees while still maintaining high accuracy â€“ especially when adversaries can only perturb a subset of all entities. For example in social networks, adversaries typically control only a subset of all nodes in the entire graph.

Further research directions and orthogonal to ours include derandomized (deterministic) smoothing (Levine and Feizi, 2020, 2021; Horvath et al., 2022b; Scholten et al., 2022), input-dependent smoothing (Sukenik et al., 2022), and gray-box certificates (Mohapatra et al., 2020; Levine et al., 2020; Schuchardt and Gunnemann, 2022; Scholten et al., 2022; Schuchardt et al., 2023a).

**Robustness-accuracy trade-off.** The robustness-accuracy trade-off has been extensively discussed in the literature (Tsipras et al., 2019; Raghunathan et al., 2019; Zhang et al., 2019; Yang et al., 2020; Xie et al., 2020), including works for graph data (Gosch et al., 2023b). In randomized smoothing the parameters of the smoothing distribution allow to trade robustness against accuracy (Cohen et al., 2019; Mohapatra et al., 2020; Wu et al., 2021) where more noise means higher robustness but lower accuracy. Our framework combines two smoothing distributions while introducing parameters for both, which allows us to better control the robustness-accuracy trade-off under our threat model since we can control both - the number of entities to smooth and the magnitude of the noise. Further advances in the trade-off in randomized smoothing include the work of Levine and Feizi (2020) against patch-attacks, Schuchardt et al. (2021, 2023b) for collective robustness certification, and Scholten et al. (2022) for graph neural networks. Other techniques include consistency regularization (Jeong and Shin, 2020), denoised smoothing (Salman et al., 2020) and ensemble techniques (Muller et al., 2021; Horvath et al., 2022a, c). Notably, our method is orthogonal to such enhancements since we derive certificates for a novel, flexible smoothing distribution to better control such trade-offs.

**Robustness certificates for GNNs.** Research on GNN certification is still at an early stage (Gunnemann, 2022), most works focus on heuristic defenses rather than provable robustness guarantees. But heuristics cannot guarantee robustness and may be broken by stronger attacks in the future (Mujkanovic et al., 2022). Most certificates are limited to specific architectures (Zugner and Gunnemann, 2020; Jin et al., 2020; Bojchevski and Gunnemann, 2019; Zugner and Gunnemann, 2019). Randomized smoothing is a more flexible framework for certifying arbitrary models while only accessing their forward pass. We compare our method to additive noise certificates for sparse data by Bojchevski et al. (2020), and to ablation certificates by Scholten et al. (2022) that ablate all node features to derive certificates against strong adversaries that control entire nodes. While we implement certificates against node-attribute perturbations, our framework can in principle integrate smoothing-based certificates against graph-structure perturbations as well.

## 3 Preliminaries and background

Our research is focused on data where objects can be decomposed into entities. W.l.o.g. we represent such objects as matrices where rows represent entities. We assume a classification task on a discrete or continuous \((N D)\)-dimensional space \(^{N D}\) (e.g. \(=\{0,1\}\) or \(=\)). We propose certificates for classifiers \(f:^{N D}\) that assign matrix \(^{N D}\) a label \(y=\{1,,C\}\).2 We model _evasion_ settings, i.e. adversaries perturb the input at inference. We seek to verify the robustness \(f()=f(})\) for perturbed \(}\) from a threat model of admissible perturbations:

\[^{r}_{p,}()\{} ^{N D}_{i=1}^{N}[_{i} }_{i}] r,\,||(-})||_{p} \}\]

where \(\) denotes an indicator function, \(||||_{p}\) a \(_{p}\)-vector norm and \(()\) the matrix vectorization. For example, \(||()||_{2}\) is the Frobenius-norm. Intuitively, we model adversaries that control up to \(r\) rows in the matrix, and whose perturbations are bounded by \(\) under a fixed \(_{p}\)-norm.

### Randomized smoothing framework

Our certificates build on the randomized smoothing framework (Lecuyer et al., 2019; Li et al., 2019; Cohen et al., 2019). Instead of certifying a _base classifier_\(f\), one constructs a _smoothed classifier_\(g\) that corresponds to the majority vote prediction of \(f\) under a randomized smoothing of the input. We define the smoothed classifier \(g:^{N D}\) for a smoothing distribution \(_{}\) as:

\[g()*{argmax}_{y}\,p_{,y}\,  p_{,y}*{Pr}_{_{}}\,[f( )=y]\]

where \(p_{,y}\) is the probability of predicting class \(y\) for input \(\) under the smoothing distribution \(_{}\). Let \(y^{*} g()\) further denote the majority vote of \(g\), i.e. the most likely prediction for the clean \(\).

To derive robustness certificates for the smoothed classifier \(g\) we have to show that \(y^{*}{=}g(){=}g(})\) for clean matrix \(\) and any perturbed matrix \(}_{p,}^{r}(})\). This is the case if the probability to classify any perturbed matrix \(}\) as \(y^{*}\) is still larger than for all other classes, that is if \(p_{},y^{*}}>0.5\). However, randomized smoothing is designed to be flexible and does not assume anything about the underlying base classifier, i.e. all we know about \(f\) is the probability \(p_{,y}\) for the clean matrix \(\). We therefore derive a lower bound \(p_{},y} p_{},y}\) under a worst-case assumption: We consider the least robust classifier among all classifiers with the same probability \(p_{,y}\) of classifying \(\) as \(y\):

\[},y}}  _{h}_{_{}}}[h()=y] s.t._{_{}}[h()=y]=p_{,y}\] (1)

where \(\{h:^{N D}\}\) is the set of possible classifiers with \(f\). To ensure that the smoothed classifier is robust to the entire treat model we have to guarantee \(_{}()}p_{},y^{*}}>0.5\). One can also derive tighter multi-class certificates, for which we refer to Appendix D for conciseness.

**Probabilistic certificates.** Since computing \(p_{,y}\) exactly is challenging in practice, one estimates it using Monte-Carlo samples from \(_{}\) and bounds \(p_{,y}\) with confidence intervals (Cohen et al., 2019). The final certificates are probabilistic and hold with an (arbitrarily high) confidence level of \(1-\).

### Neyman-Pearson Lemma: The foundation of randomized smoothing certificates

So far we introduced the idea of robustness certification using randomized smoothing, but to compute certificates one still has to solve Equation 1. To this end, Cohen et al. (2019) show that the minimum of Equation 1 can be derived using the Neyman-Pearson ("NP") Lemma (Neyman and Pearson, 1933). Intuitively, the least robust model classifies those \(\) as \(y\) for which the probability of sampling \(\) around the clean \(\) is high, but low around the perturbed \(}}\):

**Lemma 1** (Neyman-Pearson lower bound).: _Given \(,}^{N D}\), distributions \(_{},_{}}\), class label \(y\), probability \(p_{,y}\) and the set \(S_{}^{N D}:_{}}()_{}()}\), we have_

\[},y}}=_{_{}}}[  S_{}]_{+}_{_{}}[  S_{}]=p_{,y}\]

Proof.: See (Neyman and Pearson, 1933) and (Cohen et al., 2019).

### Existing smoothing distributions for discrete and continuous data

Our hierarchical smoothing framework builds upon certificates for smoothing distributions that apply noise independently per dimension (Lecuyer et al., 2019; Cohen et al., 2019; Lee et al., 2019). Despite being proposed for vector data \(^{D}\), these certificates have been generalized to matrix data by applying noise independently on all matrix entries (Cohen et al., 2019; Bojchevski et al., 2020; Chu et al., 2022; Schuchardt and Gunnemann, 2022). Thus, given matrix data we define the density \(_{}()_{i=1}^{N}_{j=1}^{D}_{_{ij}}( _{ij})\) given the density of an existing smoothing distribution \(\).3

**Gaussian randomized smoothing.** For continuous data \(=\), Cohen et al. (2019) derive the first tight certificate for the \(_{2}\)-threat model. Given an isotropic Gaussian smoothing distribution \(_{}()=(|,^{2})\), Cohen et al. (2019) show that the optimal value of Equation 1 is given by \(},y}}{=}(^{-1}(p_{,y})-|_{2}}{})\), where \(\) denotes the CDF of the normal distribution and \(-}\).

**Randomized smoothing for discrete data.**Lee et al. (2019) derive tight certificates for the \(_{0}\)-threat model. Certificates for discrete domains are in general combinatorial problems and computationally challenging. To overcome this, Lee et al. (2019) use the NP-Lemma for discrete random variables (Tocher, 1950) and show that the minimum in Equation 1 can be computed with a linear program (LP):

**Lemma 2** (Discrete Neyman-Pearson lower bound).: _Partition the input space \(^{D}\) into disjoint regions \(_{1},,_{I}\) of constant likelihood ratio \(_{}()/_{}}()=c_{i}\!\!\! \!\{\}\) for all \(_{i}\). Define \(}_{i}_{_{}}(_ {i})\) and \(_{i}_{_{}}(_{i})\). Then Equation 1 is equivalent to the linear program \(},y}}=_{^{I}}^{T}}\) s.t. \(^{T}=p_{,y}\), where \(\) represents the worst-case classifier._

Proof in (Tocher, 1950). The LP can be solved efficiently using a greedy algorithm that consumes regions with larger likelihood ratio first (Lee et al., 2019). If the number of regions is small and \(_{i},}_{i}\) can be computed efficiently, robustness certificates for discrete data become computationally feasible.

## 4 Hierarchical smoothing distribution

We aim to guarantee robustness against adversaries that perturb a subset of rows of a given matrix \(\). To achieve this we introduce hierarchical randomized smoothing: We partially smooth matrices by adding random noise on a randomly selected subset of their rows only. By adding noise in a more targeted manner than existing methods we will obtain stronger robustness while maintaining high accuracy. We describe sampling from the hierarchical (mixture) distribution \(_{}\) as follows:

First, we sample an indicator vector \(\{0,1\}^{N}\) from an **upper-level smoothing distribution**\(()\) that indicates which rows to smooth. Specifically, we draw each element of \(\) independently from the same Bernoulli distribution \(_{i}(p)\), where \(p\) denotes the probability for smoothing rows. Second, we sample a matrix \(\) by using a **lower-level smoothing distribution**\(\) (depending on domain and threat model) to add noise on the elements of the selected rows only. We define the overall density of this hierarchical smoothing distribution as \(_{}(,)_{}(|) ()\) with:

\[_{}(|)_{i=1}^{N}_{_{i}}( _{i}|_{i})_{_{i}}(_{i}|_{i})_{_{i}}(_{i})&_{i}=1\\ (_{i}-_{i})&_{i}=0\]

where \(N\) is the number of rows and \(\) the Dirac delta. In the case of a discrete lower-level smoothing distribution, \(_{}\) is a probability mass function and \(\) denotes the Kronecker delta \(_{_{i},_{i}}\).

## 5 Provable robustness certificates for hierarchical randomized smoothing

We develop certificates by deriving a condition that guarantees \(g()=g(})\) for clean \(\) and any perturbed \(}^{r}_{p,}()\). Certifying robustness under hierarchical smoothing is challenging, especially if we want to make use of certificates for the lower-level smoothing distribution \(\) without deriving the entire certificate from scratch. Moreover, Lemma 1 can be intractable in discrete domains where certification involves combinatorial problems. We are interested in certificates that are (**1**) **flexible** enough to make use of existing smoothing-based certificates, and (**2**) **efficient** to compute.

Our main idea to achieve both - flexible and efficient certification under hierarchical smoothing - is to embed the data into a higher-dimensional space \(\!\!^{N\!\!(D+1)}\) by appending the indicator \(\) as an additional column: \(|\) ("l" denotes concatenation, see Figure 2). We construct a new base classifier that operates on this higher-dimensional space, e.g. by ignoring \(\) and applying the original base classifier to \(\). In our experiments we also train the classifiers directly on the extended data.

Certifying the smoothed classifier on this higher-dimensional space simplifies the certification: By appending \(\) to the data the supports of both distributions \(_{}\) and \(_{}}\) differ, and they intersect only for those \(\) for which all perturbed rows are selected by \(\) (see Figure 3). This allows the upper-level certificate to separate clean from perturbed rows and to delegate robustness guarantees for perturbed rows to an existing certificate for the lower-level \(\). We further elaborate on why this concatenation is necessary in Appendix H. In the following we show robustness certification under this hierarchical smoothing mainly involves (**1**) transforming the observed label probability \(p_{,y}\), (**2**) computing an existing certificate for the transformed \(p_{,y}\), and (**3**) transforming the resulting lower bound \(p_{},y}\). We provide pseudo-code for the entire certification in Appendix C.

Figure 2: We derive flexible and efficient robustness certificates for hierarchical randomized smoothing by certifying classifiers on a higher-dimensional space where the indicator \(\) is added to the data.

[MISSING_PAGE_EMPTY:6]

**Hierarchical smoothing certificates.** Having derived a partitioning of \(^{N(D+1)}\) as above, we can apply the NP-Lemma for discrete random variables (Lemma 2) on the upper-level distribution \(\). Notably, we show that the problem of certification under hierarchical smoothing can be reduced to proving robustness for the lower-level distribution \(\) on the adversarially perturbed rows \(\) only:

**Theorem 1** (Neyman-Pearson lower bound for hierarchical smoothing).: _Given fixed \(,}^{N D}\), let \(_{}\) denote a smoothing distribution that operates independently on matrix elements, and \(_{}\) the induced hierarchical distribution over \(^{N(D+1)}\). Given label \(y\) and the probability \(p_{,y}\) to classify \(\) as \(y\) under \(\). Define \(_{}^{|| D }:_{}_{}}()_{_{ }}()}\). We have:_

\[},y}}=_{_{}_{}}}[_{}](1-)\ _{+}_{_{_{}}}[_{ }]=,y}-}{1-}\]

_where \(_{}\) and \(}_{}\) denote those rows \(_{i}\) of \(\) and \(}_{i}\) of \(}\) with \(i\), that is \(_{i}}_{i}\)._

_Proof sketch_ (Full proof in Appendix C). In the worst-case all matrices in \(_{1}\) are correctly classified. Note that this is the worst case since we cannot obtain any matrix of region \(_{1}\) by sampling from the distribution \(_{}}\). Therefore the worst-case classifier first uses the budget \(p_{,y}\) on region \(}_{1}\) and we can subtract the probability \(_{_{}}[_{1}]=\) from the label probability \(p_{,y}\).

Since we never sample matrices of region \(_{3}\) from the distribution \(_{}\), the remaining correctly classified matrices must be in region \(_{2}\), which one reaches with probability \(1-\) from both distributions \(_{}\) and \(_{}}\). In region \(_{2}\), however, we can simplify the problem to computing the certificate for \(\) on the perturbed rows to distribute the remaining probability. Since one never samples matrices of region \(_{0}\) we do not have to consider it. The remaining statement follows from the Neyman-Pearson-Lemma (Neyman and Pearson, 1933; Tocher, 1950). 

Note that we also derive the counterpart for discrete lower-level \(\) in Appendix F.

**Implications.** Notably, Theorem 1 implies that we can delegate robustness guarantees to the lower-level smoothing distribution \(\), compute the optimal value of Equation 1 under \(\) given the transformed probability \((p_{,y}-)/(1-)\) and multiply the result with \((1-)\). This way we obtain the optimal value of Equation 1 under the hierarchical smoothing distribution \(\) on the extended matrix space and thus robustness guarantees for hierarchical smoothing. This means our certificates are highly flexible and can integrate the whole suite of existing smoothing distributions with independent noise per dimension (Lecuyer et al., 2019; Cohen et al., 2019; Lee et al., 2019; Yang et al., 2020). This is in contrast to all existing approaches where one has to come up with novel smoothing distributions and derive certificates from scratch once new threat models are introduced.

**Special cases.** We discuss two special cases of the probability \(p\) for smoothing rows: First, if the probability to select rows for smoothing is \(p=1\) (intuitively, we always smooth the entire matrix), then we have \(=1-p^{||}=0\) for any number of perturbed rows \(||\) and with Theorem 1 we get \(},y}}()=},y}}()\). That is in this special case we obtain the original certificate for the lower-level smoothing distribution \(\). Note that in this case the certificate ignores \(r\). Second, if the probability to select rows is \(p=0\) (intuitively, we never sample smoothed matrices), we have \(=1-p^{||}=1\) for any \(|| 1\), and with Theorem 1 we get \(},y}}=0\), that is we do not obtain any certificates.

### Regional robustness certificates for hierarchical randomized smoothing

So far we can only guarantee that the prediction is robust for a specific perturbed input \(}^{r}_{p,}()\). To ensure that the smoothed classifier is robust to the entire treat model \(^{r}_{p,}()\) we have to guarantee \(_{}^{r}_{p,}()}p_{},y^{*}}>0.5\). In the following we show that it is sufficient to compute Theorem 1 for \(=1-p^{r}\) with the largest radius \(r\). In fact, the final certificate is independent of which rows are perturbed, as long the two matrices differ in exactly \(r\) rows the certificate is the same.

**Proposition 3**.: _Given clean \(^{N D}\). Consider the set \(^{r}_{p,}()\) of inputs at a fixed distance \(r\) (i.e. \(||=r\) for all \(}^{r}_{p,}()\)). Then we have \(_{}^{r}_{p,}()}p_{},y}=_{}^{r}_{p,}()}p_{},y}\)._

_Proof_. The probability \(1-=p^{||}\) is monotonously decreasing in the number of perturbed rows \(||\). Thus the lower bound \(p_{},y}\) is also monotonously decreasing in \(||\) (see Theorem 1). It follows for fixed \(\) that \(},y}}\) is minimal at \(||=r\), i.e. the largest possible radius under our threat model \(^{r}_{p,}()\).

Initializing hierarchical randomized smoothing

In the previous section we derive robustness certificates for hierarchical randomized smoothing for any lower-level smoothing distribution \(\) by deriving a general lower bound on the probability \(p_{},y}\) in Theorem 1. In this section we instantiate our hierarchical smoothing framework with specific lower-level smoothing distributions for discrete and continuous data.

### Hierarchical randomized smoothing using Gaussian isotropic smoothing

Concerning continuous data \(=\), consider the threat model \(^{r}_{2,}()\) for \(p=2\). We initialize the lower-level smoothing distribution of hierarchical smoothing with the Gaussian distribution (Cohen et al., 2019) (as introduced in Section 3), since it is specifically designed and tight for the well-studied \(_{2}\)-norm threat model. For our purposes we apply the Gaussian noise independently on the matrix entries. In the following we present the binary-class certificates for hierarchical randomized smoothing induced by isotropic Gaussian smoothing:

**Corollary 1**.: _Given continuous \(\), consider the threat model \(^{r}_{2,}()\) for fixed \(^{N D}\). Initialize the hierarchical smoothing distribution \(\) using the isotropic Gaussian distribution \(_{}()_{i=1}^{N}(_{i}|_{i },^{2})\) that applies noise independently on each matrix element. Let \(y^{*}\) denote the majority class and \(p_{,y^{*}}\) the probability to classify \(\) as \(y^{*}\) under \(\). Then the smoothed classifier \(g\) is certifiably robust \(g()=g(})\) for any \(}^{r}_{2,}()\) if_

\[<(^{-1}(,y^{*}}-}{1-} )-^{-1}())\]

_where \(^{-1}\) denotes the inverse CDF of the normal distribution and \( 1-p^{r}\)._

Proof in Appendix E. We also derive the corresponding multi-class certificates in Appendix E.

### Hierarchical randomized smoothing using sparse smoothing

To demonstrate our certificates in discrete domains we consider binary data \(=\{0,1\}\) and model adversaries that delete \(r_{d}\) ones (flip \(1 0\)) and add \(r_{a}\) ones (flip \(0 1\)), that is we consider the ball \(^{r}_{r_{a},r_{d}}()\) (see Appendix B for a formal introduction). We initialize the lower-level smoothing distribution of hierarchical smoothing with the sparse smoothing distribution proposed by Bojchevski et al. (2020): \(p(()_{i}_{i})=p_{+}^{1-_{i}}p_{-}^{_{i}}\), introducing two different noise probabilities to flip \(0 1\) with probability \(p_{+}\) and \(1 0\) with probability \(p_{-}\). The main idea is that the different flipping probabilities allow to preserve sparsity of the underlying data, making this approach particularly useful for graph-structured data. Note that we can consider the discrete certificate of Lee et al. (2019) as a special case (Bojchevski et al., 2020). We derive the corresponding certificates in Appendix F.

### Hierarchical randomized smoothing using ablation smoothing

Lastly, randomized ablation (Levine and Feizi, 2020) is a smoothing distribution where the input is not randomly smoothed but masked, e.g. by replacing the input with a special ablation token \(^{D}\) that does not exist in the original space. There are different variations of ablation and we carefully discuss such differences in Appendix G. By choosing a smoothing distribution \(\) that ablates all selected rows we can prove the following connection between hierarchical and ablation smoothing:

**Corollary 2**.: _Initialize the hierarchical smoothing distribution \(\) with the ablation smoothing distribution \(_{}()=1\) for ablation token \(^{D}\) and \(_{}()=0\) for \(^{D}\) otherwise (i.e. we always ablate selected rows). Define \( 1-p^{r}\). Then the smoothed classifier \(g\) is certifiably robust \(g()=g(})\) for any \(}^{r}_{2,}()\) if \(p_{,y}->0.5\)._

Proof in Appendix G. Interestingly, Corollary 1 and Corollary 2 show that hierarchical smoothing is a generalization of additive noise and ablation certificates. The additional column indicates which rows will be ablated, but instead of ablating we only add noise to them. In contrast to ablation smoothing (which just checks if \(p_{,y}->0.5\)) we further "utilize" the budget \(p_{,y}-\) by plugging it into the lower-level certificate. Notably, we are the first to generalize beyond ablation and additive noise certificates, and our certificates are in fact orthogonal to all existing robustness certificates that are based on randomized smoothing.

## 7 Experimental evaluation

In this section we highlight the importance of hierarchical smoothing in image and node classification, instantiating our framework with two well-established smoothing distributions for continuous (Cohen et al., 2019) and discrete data (Bojchevski et al., 2020). In the following we present experiments supporting our main findings. We refer to Appendix A for more experimental results and to Appendix B for the full experimental setup and instructions to reproduce our results.

**Threat models.** For images we model adversaries that perturb at most \(r\) pixels of an image, where the perturbation over all channels is bounded by \(\) under the \(_{2}\)-norm. For graphs we model adversaries that perturb binary features of at most \(r\) nodes by inserting at most \(r_{a}\) and deleting at most \(r_{d}\) ones.

**Datasets and models.** For image classification we train ResNet50 (He et al., 2016) on CIFAR10 (Krizhevsky et al., 2009) consisting of images with three channels of size 32x32 categorized into 10 classes. We certify the models on a random but fixed subset of 1,000 test images. For node classification we train graph attention networks (GATs) (Velickovic et al., 2018) with two layers on Cora-ML (McCallum et al., 2000; Bojchevski and Gunnemann, 2018) consisting of 2,810 nodes with 2,879 _binary_ features, 7,981 edges and 7 classes. We train and certify GNNs in an inductive learning setting (Scholten et al., 2022). We defer results for more models and datasets to Appendix A.

**Experimental setup.** During training, we sample one smoothed matrix each epoch to train our models on smoothed data. Note that for hierarchical smoothing we also train our models on the higher-dimensional matrices. At test time, we use significance level \(=0.01\), \(n_{0}=1,\!000\) samples for estimating the majority class and \(n_{1}=10,\!000\) samples for certification. We report the classification accuracy of the smoothed classifier on the test set (_clean accuracy_), and the _certified accuracy_, that is the number of test samples that are correctly classified _and_ certifiably robust for a given radius. For node classification we report results averaged over five random graph splits and model initializations.

**Baseline certificates.** We compare hierarchical smoothing to additive noise and ablation certificates since our method generalizes both into a novel framework. To this end, we implement the two additive noise certificates of Cohen et al. (2019) and Bojchevski et al. (2020) for continuous and discrete data, respectively. Concerning ablation certificates, we implement the certificate of Levine and Feizi (2020) for image classification, which ablates entire pixels. For node classification we implement the generalization to GNNs of Scholten et al. (2022) that ablates all node features of entire nodes. We conduct exhaustive experiments to explore the space of smoothing parameters for each method (see details in Appendix B). To compare the three different approaches we fix the threat model and investigate the robustness-accuracy trade-off by comparing certified accuracy against clean accuracy.

**Hierarchical smoothing significantly expands the Pareto-front.** Notably, hierarchical smoothing is clearly expanding the Pareto-front when optimization for both - certified accuracy and clean accuracy (see Figure 4). Especially when the number of adversarial nodes or pixels is small but the feature perturbation is large, hierarchical smoothing is significantly dominating both baselines.

Figure 4: Hierarchical smoothing significantly expands the Pareto-front w.r.t. robustness and accuracy in node and image classification. Left: Discrete hierarchical smoothing for node classification, smoothed GAT on Cora-ML (\(r=1,r_{d}=40,r_{a}=0\)). Right: Continuous hierarchical smoothing for image classification, smoothed ResNet50 on CIFAR10 (\(r=3,=0.35\)). Non-smoothed GAT achieves 80%\( 2\%\) clean accuracy on Cora-ML, ResNet50 94% on CIFAR10. Large circles and stars are dominating points for each certificate. Dashed lines connect dominating points across methods.

Interestingly, both baselines either sacrifice robustness over accuracy (or vice versa): While additive noise certificates obtain higher clean accuracy at worse certified accuracy, ablation certificates obtain strong certified accuracy at lower clean accuracy. In contrast, hierarchical smoothing allows to explore the entire space and significantly expands the Pareto-front of the robustness-accuracy trade-off under our threat model. This demonstrates that hierarchical smoothing is a more flexible framework and represents a useful and novel tool for analyzing the robustness of machine learning models in general.

**Entity-selection probability.** With hierarchical smoothing we introduce the entity-selection probability \(p\) that allows to better control the robustness-accuracy trade-off under our threat model. Specifically, for larger \(p\) we add more noise and increase robustness but also decrease accuracy. As usual in randomized smoothing, the optimal \(p\) needs to be fine-tuned against a task, dataset and radius \(r\). In our settings we found dominating points e.g. for \(p=0.81\) (Cora-ML) and \(p=0.85\) (CIFAR10).

## 8 Discussion

Our hierarchical smoothing approach overcomes limitations of randomized smoothing certificates: Instead of having to derive Lemma 1 from scratch for each smoothing distribution, we can easily integrate the whole suite of existing and future randomized smoothing certificates. Our framework is highly flexible and allows to certify robustness against a wide range of adversarial perturbations.

Hierarchical smoothing also comes with limitations: First, we inherit the limitations of ablation certificates in which the certifiable radius \(r\) is bounded by the smoothing parameters independently of the classifier (Scholten et al., 2022). The underlying reason is that we do not evaluate the smoothed classifier on the entire space \(\) since we cannot reach certain matrices as exploited in Section 5. Second, the classifier defined on the original matrix space is invariant with respect to the new dimension introduced by our smoothing distribution and not incorporating such invariances into the Neyman-Pearson-Lemma yields strictly looser guarantees (Schuchardt and Gunnemann, 2022).

Beyond that, our certificates are highly efficient: The only additional cost for computing hierarchical smoothing certificates is to evaluate the algebraic term \(=1-p^{r}\), which takes constant time (see also Appendix H). Since we train our classifiers on the extended matrices, we also allow classifiers to distinguish whether entities have been smoothed by the lower-level distribution (see Appendix A).

**Future work.** Future work can build upon our work towards even stronger certificates in theory and practice, for example by deriving certificates that are tight under the proposed threat model and efficient to compute at the same time. Future work can further (1) implement certificates for other \(_{p}\)-norms (Levine and Feizi, 2021; Voracek and Hein, 2023) and domains, (2) improve and assess adversarial robustness, and (3) introduce novel architectures and training techniques.

**Broader impact.** Our hierarchical smoothing certificates are highly flexible and provide provable guarantees for arbitrary (\(_{p}\)-norm) threat models, provided that certificates for the corresponding lower-level smoothing distribution exist. Therefore our contributions impact the certifiable robustness of a large variety of models in discrete and continuous domains and therefore the field of reliable machine learning in general: Our robustness certificates provide novel ways of assessing, understanding and improving the adversarial robustness of machine learning models.

## 9 Conclusion

With hierarchical smoothing we propose the first hierarchical (mixture) smoothing distribution for complex data where adversaries can perturb only a subset of all entities (e.g. pixels in an image, or nodes in a graph). Our main idea is to add noise in a more targeted manner: We first select a subset of all entities and then we add noise to them. By certifying robustness under this hierarchical smoothing distribution we achieve stronger robustness guarantees while still maintaining high accuracy. Overall, our certificates for hierarchical smoothing represent novel, flexible tools for certifying the adversarial robustness of machine learning models towards more reliable machine learning.