# Memory-Assisted Sub-Prototype Mining for Universal Domain Adaptation

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Universal domain adaptation aims to align the classes and reduce the feature gap between the same category of the source and target domains. The target private category is set as the unknown class during the adaptation process, as it is not included in the source domain. However, most existing methods overlook the intra-class structure within a category, especially in cases where there exists significant concept shift between the samples belonging to the same category. When samples with large concept shift are forced to be pushed together, it may negatively affect the adaptation performance. Moreover, from the interpretability aspect, it is unreasonable to align visual features with significant differences, such as fighter jets and civil aircraft, into the same category. Unfortunately, due to such semantic ambiguity and annotation cost, categories are not always classified in detail, making it difficult for the model to perform precise adaptation. To address these issues, we propose a novel Memory-Assisted Sub-Prototype Mining (MemSPM) method that can learn the differences between samples belonging to the same category and mine sub-classes when there exists significant concept shift between them. By doing so, our model learns a more reasonable feature space that enhances the transferability and reflects the inherent differences among samples annotated as the same category. We evaluate the effectiveness of our MemSPM method over multiple scenarios, including UniDA, OSDA, and PDA. Our method achieves state-of-the-art performance on four benchmarks in most cases.

## 1 Introduction

Unsupervised Domain Adaptation (UDA) [15; 22; 41; 44; 9; 19; 21] has become a crucial research area of transfer learning, as it allows models trained on a specific dataset to be applied to related but distinct domains. However, traditional UDA methods are limited by the assumption that the source and target domains have to share the same label space. This assumption is problematic in real-world scenarios where the target distribution is complex, open, and diverse. Universal Domain Adaptation (UniDA) represents a strategy to address the limitations of traditional unsupervised domain adaptation methods. In the UniDA, the target domain have a different label set than the source domain. The goal is to correctly classify target domain samples belonging to the shared classes in the source label set, while any samples not conforming to the source label set are treated as "unknown". The term "universal" characterizes UniDA as not relying on prior knowledge about the label sets of the target domain. UniDA relaxes the assumption of a shared class space while aims to learn domain-invariant features across a more broad range of domains.

Despite being widely explored, most existing universal domain adaptation methods [24; 47; 40; 39; 6; 34; 8; 26] overlook the internal structure intrinsically presented within each image category. These methods aim to align the common classes between the source and target domains for adaptation, butusually train a model to learn the class "prototype" representing each annotated category. This is particularly controversial when significant concept shift exists between samples belonging to the same category. These differences can lead to sub-optimal feature learning and adaptation if the intra-class structure is neglected during training. Since such kind of semantic ambiguity without fine-grained category labels almost happens in all the DA benchmarks, all the methods will encounter this issue.

In this paper, we aim to propose a method to learn the detailed intra-class distinction and mine "sub-prototypes" for better alignment and adaptation. This kind of sub-prototype is the further subdivision of each category-level prototype, which represents the "sub-class" of the annotated categories. The main idea of our proposed approach lies in its utilization of a learnable memory structure to learn sub-prototypes for their corresponding sub-classes. This can optimize the construction and refinement of the feature space, bolstering the classifier's ability to distinguish class-wise relationships and improve the model's transferability across domains. A comparison between our proposed sub-prototypes mining approach and previous methods is illustrated in Figure 1. In previous methods, samples within a category were forced to be aligned together in the feature space regardless of whether there exist significant differences among them because the labels were one-hot encoded. Contrastively, our sub-prototypes' feature space distinguishes sub-classes with apparent differences within the category, thus improving the model's accuracy of domain adaption and interpretability.

Our proposed approach, named memory-assisted sub-prototype mining (MemSPM), is inspired by the memory mechanism works [17; 10; 45; 36]. In our approach, the memory generates sub-prototypes that embody sub-classes learned from the source domain. During testing of the target samples, the encoder produces embedding that are compared to source domain sub-prototypes learned in the memory. Subsequently, a embedding for the query sample is generated through weighted sub-prototype sampling in the memory. This results in reduced domain shifts before the embedding give into the classifier. Our proposal of sub-prototypes mining, which are learned from the source domain

Figure 1: Illustration of our motivation. (a) Examples of concept shift and intra-class diversity in DA benchmarks. For the class of alarm clock, we find that digital clock, pointer clock and alarm bell should be set in different sub-classes. For the class of airplane, we find that images containing more than one plane, single jetliner, and turbopro aircraft should be differently treated for adaptation. (b) Previous methods utilize one-hot labels to guide classifying without considering the intra-class distinction. Consequently, the model forces all samples from the same class to converge towards a single center, disregarding the diversity in the class. Our method clusters samples with large intra-class difference into separate sub-class, providing a more accurate representation. (c) During domain adaptation by our design, the samples in the target domain can also be aligned near the sub-class centers with similar features rather than just the class centers determined by labels.

memory, improves the universal domain adaptation performance by promoting more refined visual concept alignment.

MemSPM approach has been evaluated on four benchmark datasets (Office-31 , Office-Home , VisDA ,and Domain-Net ), under various category shift scenarios, including PDA, OSDA, and UniDA. Our MemSPM method achieves state-of-the-art performance in most cases. Moreover, we design a visualization module for the sub-prototype learned by our memory to demonstrate the interpretability of MemSPM. Our contributions can be highlighted as follows:

* We study the UniDA problem from a new aspect, which focuses on the negative impacts caused by overlooking the intra-class structure within a category when simply adopting one-hot labels.
* We propose Memory-Assisted Sub-Prototype Mining(MemSPM), which explores the memory mechanism to learn sub-prototypes for improving the model's adaption performance and interpretability. Meanwhile, visualizations reveal the sub-prototypes stored in memory, which demonstrate the interpretability of MemSPM approach.
* Extensive experiments on four benchmarks verify the superior performance of our proposed MemSPM compared with previous works.

## 2 Related Work

**Closed-Set Domain Adaptation (CSDA).** To mitigate the performance degradation caused by the closed-set domain shift, [16; 29; 48] introduce adversarial learning methods with the domain discriminator, aiming to minimize the domain gap between source and target domains. Beyond the use of the additional domain discriminator, some studies [41; 23; 50; 30; 13] have explored the use of two task-specific classifiers, otherwise referred to as bi-classifier, to implicitly achieve the adversarial learning. However, the previously mentioned methods for CSDA cannot be directly applied in scenarios involving the category shift.

**Partial Domain Adaptation (PDA).** PDA posits that private classes are exclusive to the source domain. Representative PDA methods, such as those discussed in [3; 49], employ domain discriminators with weight adjustments or utilize source samples based on their resemblance to the target domain . Methods incorporating residual correction blocks in PDA have been introduced by Li et al. and Liang et al. [25; 27]. Other research [7; 11; 38] explores the use of Reinforcement Learning for source data selection within the context of PDA.

**Open-Set Domain Adaptation (OSDA).** Saito et al.  developed a classifier inclusive of an additional 'unknown' class intended to differentiate categories unique to the target domain. Liu et al.  and Shermin et al.  propose assigning individual weights to each sample depending on their importance during domain adaptation. Jang et al.  strive to align the source and target-known distributions, while concurrently distinguishing the target-unknown distribution within the feature alignment process. The above PDA and OSDA methods are limited to specific category shift.

**Universal Domain Adaptation (UniDA)** You et al.  proposed Universal Adaptation Network (UAN) to deal with the UniDA setting that the label set of target domain is unknown. Li et al.  proposed Domain Consensus Clustering to differentiate the private classes rather than treat the unknow classes as one class. Saito et al.  suggested that using the minimum inter-class distance in the source domain as a threshold can be an effective approach for distinguishing between "known" and "unknown" samples in the target domain. However, most existing methods [24; 47; 40; 39; 6; 34; 8; 26] overlook the intra-class distinction within one category, especially in cases where there exists significant concept shift between the samples belonging to the same category.

## 3 Proposed Methods

### Preliminaries

In unsupervised domain adaptation, we are provided with labeled source samples \(^{s}=\{x_{i}^{s},y_{i}^{s}\}_{i=1}^{n^{s}}\) and unlabeled target samples \(^{t}=\{(x_{i}^{t})\}_{i=1}^{n^{t}}\). As the label set for each domain in UniDA setting may not be identical, we use \(C_{s}\) and \(C_{t}\) to represent label sets for the two domains, respectively.

Then, we denote \(C=C_{s} C_{t}\) as the common label set. \(_{s}\), \(_{t}\) are denoted as the private label sets of the source domain and target domain, respectively. We aim to train a model on \(^{s}\) and \(^{t}\) to classify target samples into \(|C|+1\) classes, where private samples are treated as unknown class.

Our method aims to address the issue of intra-class concept shift that often exists within the labeled categories in most datasets, which is overlooked by previous methods. Our method enables the model to learn an adaptive feature space that better aligns fine-grained sub-class concepts, taking into account the diversity present within each category. Let \(X\) denotes the input query, \(Z\) denotes the embedding extracted by the encoder, \(L\) denotes the data labels, \(\) denotes the embedding obtained from the memory, \(\) denotes the visualization of the memory, \(\) denotes the prediction of the input query, and the \(K\) denotes the top-K relevant sub-prototypes, respectively. The overall pipeline is presented in Figure 2. More details will be described in the following sub-sections.

### Input-Oriented Embedding vs. Task-Oriented Embedding

Usually, the image feature extracted by a visual encoder is directly used for learning downstream tasks. We call this kind of feature as input-oriented embedding. However, it heavily relys on the original image content. Since different samples of the same category always varies significantly in their visual features, categorization based on the input-oriented embedding sometimes is unattainable. In our pipeline, we simply adopt a CLIP-based pre-trained visual encoder to extract the input-oriented embeddings, which is not directly used for learning our downstream task.

In our MemSPM, we propose to generate task-oriented embedding, which is obtained by serving input-oriented embedding as a query to retrieve the sub-prototypes from our memory unit. We define \(f^{fixed}_{encode}():X Z\) to represent the fixed pre-trained encoder and \(f^{UniDA}_{class}():\) to represent the UniDA classifier. The input-oriented embedding \(Z\) is used to retrieve the relevant sub-prototypes from the memory. The task-oriented embedding \(\) is obtained using the retrieved sub-prototypes for classification tasks. In conventional ways, \(=Z\), which means the \(\) is obtained directly from \(Z\). Our method obtains the \(\) by retrieving the sub-prototypes from the memory, which differencates \(\) with \(Z\), and eliminates the domain-specific information from the target domain during the testing phase. As a result, it improves the performance of \(f^{UniDA}_{class}()\) when performing UniDA.

### Memory-Assisted Sub-Prototype Mining

The memory module proposed in MemSPM consists of two key components: a memory unit responsible for learning sub-prototypes, and an attention-based addressing  operator to obtain better task-oriented representation \(\) for the query, which is more domain-invariant.

Figure 2: Our model first utilizes a fixed pre-trained model as the encoder to extract input-oriented embedding given an input sample. The extracted input-oriented embedding is then compared with sub-prototypes learned in memory to find the closest \(K\). These \(K\) are then weighted-averaged into a task-oriented embedding to represent the input, and used for learning downstream tasks. During the UniDA process, we adopt the cycle-consistent matching method on the task-oriented embedding \(\) generated from the memory. Moreover, a decoder is designed to reconstruct the image, allowing for visualizing of the sub-prototypes in memory and verifying of the effectiveness of sub-class learning.

#### 3.3.1 Memory Structure with Partitioned Sub-Prototype

The memory in MemSPM is represented as a matrix, denoted by \(M^{N S D}\), where \(N\) indicates the number of memory items stored, \(S\) refers to the number of sub-prototypes partitioned in each memory item, and \(D\) represents the dimension of each sub-prototype. For convenience, we assume \(D\) is the same to the dimension of \(Z^{C}\) ( \(^{D}\)=\(^{C}\)). Let the vector \(m_{i,j}\), \( i[N]\) denote the \(i\)-th row of \(M\), where \([N]\) denotes the set of integers from 1 to \(N\), \( j[S]\) denote the \(j\)-th sub-prototype of \(M\) items, where \([S]\) denotes the set of integers from 1 to \(S\). Each \(m_{i}\) denotes a memory item. Given a embedding \(Z^{D}\), the memory module obtains \(\) through a soft addressing vector \(W^{1 1 N}\) as follows:

\[=W M=_{i=1}^{N}w_{i,j=s_{i}} m_{i,j=s_{i}},\] (1) \[w_{i,j=s_{i}}=(w_{i,j},dim=1),\] (2)

where \(W\) is a vector with non-negative entries that indicate the max attention weight of each item's sub-prototype, \(s_{i}\) denotes the index of the sub-prototype in the \(i\)-th item and \(w_{i,j=s_{i}}\) denotes the \(i,j=s_{i}\)-th entry of \(W\). The hyperparameter \(N\) determines the maximum capacity for memory items and the hyper-parameter \(S\) defines the number of sub-prototypes in each memory item. The effect of different setting of hyper-parameters is evaluated in Section 4.

#### 3.3.2 Sub-Prototype Addressing and Retrieving

In MemSPM, the memory \(M\) is designed to learn the sub-prototypes to represent the input-oriented embedding \(Z\). We define the memory as a content addressable memory [17; 10; 45; 36] that allows for direct referencing of the content of the memory being matched. The sub-prototype is retrieved by attention weights \(W\) which are computed based on the similarity between the sub-prototypes in the memory items and the input-oriented embedding \(Z\). To calculate the weight \(w_{i,j}\), we use a softmax operation:

\[w_{i,j}=))}{_{n=1}^{N}_{s=1}^{S}(d(z,m_{ n,s}))},\] (3)

where \(d(,)\) denotes cosine similarity measurement. As indicated by Eq. 1 and 3, the memory module retrieves the sub-prototype that is most similar to \(Z\) from each memory item in order to obtain the new representation embedding \(\). As a consequence of utilizing the adaptive threshold addressing technique(Section 3.3.3), only the \(K\) can be utilized to obtain a task-oriented embedding \(\), that serves to represent the encoded embedding \(Z\).

#### 3.3.3 Adaptive Threshold Technique for More Efficient Memory

Limiting the amount of sub-prototypes retrieved can enhance memory utilization and avoid negative impacts on unrelated sub-prototypes during model parameter updates. Despite the natural reduction in the number of selected memory items, the attention-based addressing mechanism may still lead to the combination of small attention weight items into the output embedding \(\), which have negative impact on the classifier and sub-prototypes in the memory. Therefore, it is necessary to impose a mandatory quantity limit on the amount of the relevant sub-prototypes retrieved. To address this issue, we apply a adaptive threshold operation to restrict the amount of sub-prototypes retrieved in a forward process.

\[_{i,j=s_{i}}=w_{i,j=s_{i}},&w_{i,j=s_{i}}>\\ 0,&\] (4)

where \(_{i,j=s_{i}}\) denotes the \(i,j=s_{i}\)-th entry of \(\), the \(\) denotes the adaptive threshold:

\[=(topk(w)).\] (5)

Directly implementing the backward for the discontinuous function in Eq. 4 is not a easy task. For simplicity, we use the method that rewrites the operation using the continuous ReLU activation function as:\[_{i,j=s_{i}}=}-) w_{i,j=s_{i}}}{|w_{i,j= s_{i}}-|+},\] (6)

where \(max(,0)\) is commonly referred to as the ReLU activation function, and \(\) is a small positive scalar. The prototype \(\) will be obtained by \(= M\). The adaptive threshold addressing encourages the model to represent embedding \(Z\) using fewer but more relevant sub-prototypes, leading to learning more effective feature in memory and reducing the impact on irrelevant sub-prototypes.

### Visualization and Interpretability

We denote \(f^{unfixed}_{decode}():\) to represent the decoder. The decoder is trained to visualize what has been learned in the memory by taking the retrieved sub-prototype as input. From an interpretability perspective, each encoded embedding \(Z\) calculates the cosine similarity to find the top-\(K\) fitting sub-prototype representation for the given input-oriented embedding. Then, these sub-prototypes are combined to represent the \(Z\) in \(\). The sub-prototype in this process can be regarded as the visual description for the input embedding \(Z\). In other word, the input image is much like the sub-classes represented by these sub-prototypes. In this way, samples with significant intra-class differences will be matched to different sub-prototypes, thereby distinguishing different sub-classes. The use of a reconstruction auxiliary task can visualize the sub-prototypes in memory to confirm whether our approach has learned intra-class differences for the annotated category. The results of this visualization are demonstrated in Figure 3.

### Cycle-Consistent Alignment and Adaption

Once the sub-prototypes are mined through memory learning, the method of cycle-consistent matching, inspired by DCC , is employed to align the embedding \(\). The cycle-consistent matching is preferred due to it can provides a better fit to the memory structure compared to other UniDA methods. The other method, One-vs-All Network (OVANet), proposed by Saito et al. , needs to train the memory multiple times, which can lead to a significant computational overhead. In brief, the Cycle-Consistent Alignment provides a solution by iteratively learning a consensus set of clusters between the two domains. The consensus clusters are identified based on the similarity of the prototypes, which is measured using a similarity metric. The similarity metric is calculated on the feature representations of the prototypes. For unknown classes, we set the size \(N\) of our memory during the initial phase to be larger than the number of possible sub-classes that may be learned in the source domain. This size is a hyperparameter that is adjusted based on the dataset size. Redundant sub-prototypes are invoked to represent the \(\), when encountering unknown classes, allowing for an improved distance separation between unknown and known classes in the feature space.

**Training Objective**. The adaptation loss in our training is similar to that of DCC, as \(_{DA}\):

\[_{DA}=_{ce}+_{1}_{cdd}+_{2} _{reg},\] (7)

where the \(_{ce}\) denotes the cross-entropy loss on source samples, \(_{cdd}\) denotes the domain alignment loss and \(_{reg}\) denotes the regularizer. For the auxiliary reconstruction task, we add a mean-squared-error (MSE) loss function, denoted as \(_{rec}\). Thus, the model is optimized with:

\[=_{DA}+_{3}_{rec}=_{ce}+ _{1}_{cdd}+_{2}_{reg}+_{3}_{rec}.\] (8)

## 4 Experiments

### Datasets and Evaluation Metrics

We first conduct the experiments in the UniDA setting  where private classes exist in both domains. Moreover, we also evaluate our approach on two other sub-cases, namely Open-Set Domain Adaptation (OSDA) and Partial Domain Adaptation (PDA).

**Datasets**. Our experiments are conducted on four datasets: Office-31 , which contains 4652 images from three domains (DSLR, Amazon, and Webcam); OfficeHome

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

**Effect of Memory-Assisted Sub-Prototype Mining**. As the results shown in table 2, table 3, table 4 and table 5, the MemSPM+DCC evaluted on four benchmarks has surpassed the DCC on UniDA, OSDA and PDA scenarios. The MemSPM can significantly improve the performance of the DCC when using ViT-B/16 as backbone. The reason for utilizing the ViT-B/16 is that the memory module of the MemSPM with huge latent space is initialized by randomly normal distribution, which make it hard to retrieve the different sub-prototypes at early stages of training. So, we need ViT as backbone, which have learned a more global feature space.

**Sensitivity to Hyper-parameters**. We conducted experiments on the VisDA dataset under the UniDA setting to demonstrate the impact of hyperparameters \(S\) and \(N\) on the performance of our method. The impact of \(S\) are shown in Figure 3. When \(S 20\), the performance achieve a comparable level. At the same time, the performance of the model is not sensitive to the value of \(N\), when \(S=30\).

## 5 Conclusion

In this paper, we propose the Memory-Assisted Sub-Prototype Mining (MemSPM) method, which can learn the intra-class diversity by mining the sub-prototypes to represent the sub-classes. Compared with the previous methods, which overlook the intra-class structure by using one-hot label, our MemSPM can learn the class feature from a more subdivided sub-class perspective to improve adaptation performance. At the same time, the visualization of the tSNE and reconstruction demonstrates the sub-prototypes have been well learned as we expected. Our MemSPM method exhibits superior performance in most cases compared with previous state-of-the-art methods on four benchmarks.

Figure 3: (a) The tSNE visualization shows the feature space of the sub-classes belonging to the each category, which demonstrate the MemSPM mining the sub-prototypes successfully. (b) The results of different values of \(S\) and \(N\). (c) The reconstruction visualization shows what have been learned in the memory, which demonstrate the intra-class diversity have been learned by MemSPM.