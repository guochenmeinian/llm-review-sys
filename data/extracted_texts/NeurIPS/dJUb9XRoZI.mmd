# Constrained Diffusion with Trust Sampling

William Huang

Stanford University

willsh@stanford.edu

&Yifeng Jiang

Stanford University

yifengj@stanford.edu

Tom Van Wouwe

Stanford University

tvwouwe@stanford.edu

&C. Karen Liu

Stanford University

karenliu@cs.stanford.edu

###### Abstract

Diffusion models have demonstrated significant promise in various generative tasks; however, they often struggle to satisfy challenging constraints. Our approach addresses this limitation by rethinking training-free loss-guided diffusion from an optimization perspective. We formulate a series of constrained optimizations throughout the inference process of a diffusion model. In each optimization, we allow the sample to take multiple steps along the gradient of the proxy constraint function until we can no longer trust the proxy, according to the variance at each diffusion level. Additionally, we estimate the state manifold of diffusion model to allow for early termination when the sample starts to wander away from the state manifold at each diffusion step. Trust sampling effectively balances between following the unconditional diffusion model and adhering to the loss guidance, enabling more flexible and accurate constrained generation. We demonstrate the efficacy of our method through extensive experiments on complex tasks, and in drastically different domains of images and 3D motion generation, showing significant improvements over existing methods in terms of generation quality. Our implementation is available at https://github.com/will-s-h/trust-sampling.

## 1 Introduction

Diffusion models are a class of generative models that have been highly successful at modeling complex domains, ranging from the generations of images  and videos , to 3D geometries  and 3D human motion , outperforming other deep generative models, such as GANs and VAEs . Originally for unconditional generation, Diffusion models soon became used for cross-domain conditioned generation, such as text-conditioned image generations , and generating human movements from audio .

For more fine-grained conditional generation where the samples need to precisely follow specified constraints, such as generating images following a certain contour, high-level controls like text prompts become insufficient. Guided diffusion has recently emerged to be a powerful paradigm on a variety of such constraints. One category of guided diffusion uses a separately trained classifier (as in classifier guidance ) or the score of a conditional diffusion model in classifier-free guidance . For new constraints, the classifier or the conditional diffusion model must be retrained .

Alternatively, one can use the gradient of a loss function representing a constraint as guidance to achieve conditional diffusion . This flexible paradigm allows various constraints to be applied on a pre-trained diffusion model without compute cost on extra training. On this front, since the seminal works of Chung et al.  and Ho et al. , a number of techniques have been proposed to improve the quality of loss-guided diffusion, such as better step size design , multi-point MCMCapproximation , and incorporation of measurement models . Several challenges remain for the current paradigm when trying to apply loss-guided diffusion for challenging constraints. For one, performance drops significantly when using a smaller budget of inference computation with fewer neural function evaluations (NFEs) [11; 58]. The methods are also sensitive to initialization, where previous evaluations often times take the best of a few generated samples for each constraint input.

In light of these challenges in training-free guided diffusion, we introduce Trust Sampling, a novel method that strays from the traditional approach of alternating between diffusion steps and loss-guided gradient steps in favor of a more general approach, considering each timestep as an independent optimization problem. Trust Sampling allows for multiple gradient steps on a proxy constraint function at each diffusion step, while scheduling the termination of the optimization when the proxy cannot be trusted anymore. Additionally, Trust Sampling estimates the state manifold of the diffusion model to allow for early termination, if the predicted noise magnitude of the sample exceeds the expected one in each diffusion step. Our framework is flexible, efficient, and performs well, achieving higher quality across widely different domains (e.g. human motion and images). We demonstrate the generality of Trust Sampling across a large number of image tasks (super-resolution, box inpainting, Gaussian deblurring) and motion tasks (root trajectory tracking, hand-foot trajectory tracking, obstacle avoidance, etc.). When compared to existing methods, we find that Trust Sampling satisfies constraints better and achieves higher fidelity.

## 2 Background

Diffusion models.There are several equivalent formulations for diffusion models used in literature. Here, we briefly offer background on the denoising diffusion probabilistic model (DDPM)  formulation. Beginning from the data distribution \(_{0} p()\), we can use a variance schedule \(_{1},,_{T}\) to produce latent variables \(_{1},,_{T}\) through the forward diffusion process \(q(_{t}|_{0})=(}_{0}, (1-_{t}))\), where \(_{t}:=_{s=1}^{t}(1-_{s})\). In turn, a de-noising model \(_{}\) can be trained by minimizing the following loss function, which is a re-weighting of the variational lower bound :

\[()=_{t,_{0},}[||-_{}(_{t},t)||^{2}],\] (1)

where \(_{0} p()\), \(t\{1,,T\}\), \((,)\), and \(_{t}=}_{0}+}\). The diffusion model can then be sampled in the reverse process, via DDPM  or the denoising diffusion implicit model (DDIM) formulation :

\[_{t-1}=}}_{0}(_{t})+ -_{t}^{2}}_{}(_{t},t) +_{t},\] (2)

Figure 1: Trust Sampling can be applied to complex constraint problems in drastically different domains.

where \((,)\) in both DDIM and DDPM, whereas \(_{t}=)/(1-_{t})}/_{t-1}}\) is fixed in DDPM and can be chosen freely in DDIM. \(}_{0}(_{t})\) denotes the predicted \(_{0}\) at timestep \(t\), and can be written as

\[}_{0}(_{t})=}}(_{t }-}_{}(_{t},t)).\] (3)

Notably, DDPM and DDIM sampling can also be thought of a special case of gradient-based MCMC sampling (or a probability flow, in cases of DDIM without noise), where the goal is to refine the starting sample at each level \(_{t}\) towards maximizing the likelihood \(_{t-1} p(_{t-1})\). In the case of DDPM/DDIM, instead of taking multiple MCMC steps  following the score function, only one step is taken at each level.

Training-free Guided Diffusion.One important application of Diffusion models is controlled (guided) generation. Instead of sampling from the unconditional data distribution \(p()\), the goal is to sample from \(p(|)\), where \(\) is the usually under-specified guidance signal. For example, an animator may wish to use an unconditional diffusion model of human motion \(p()\) to generate motions with a constraint \(\) that the character's right hand reaches to a specific location. Previous works [13; 11] transform the maximization of \(p(_{t}|)\) at each diffusion level \(t\) with Bayes' rule:

\[_{_{t}} p(_{t}|)=_{_{ t}} p(_{t})+_{_{t}} p(|_{t }),\] (4)

where we note that \(_{_{t}} p()=0\). Existing algorithms therefore alternate between following the score function of the trained Diffusion \(_{_{t}} p(_{t})\), and following the guidance gradient \(_{_{t}} p(|_{t})\). However, directly optimizing \(p(|_{t})\) is generally intractable , as can be seen by the following probability factorization:

\[p(|_{t})=_{_{0}}p(_{0}| _{t})p(|_{0})d_{0},\] (5)

where we used the fact that given \(_{0}\), \(\) is conditionally independent from \(_{t}\). In general approximating \(p(_{0}|_{t})\) requires many denoising iterations of the Diffusion model, which is impractical when needing to alternate with optimizing \(p(_{t})\).

To address this difficulty, previous works [11; 58] approximate \(p(|_{t})\) with \(p(|}_{0}(_{t}))\). Their observation is that in many practical applications, practitioners do have access to a closed-form differentiable function \(L(_{0},)\) that can measure how good a clean (predicted or ground-truth) sample matches the desired condition \(\). For example, \(L\) can simply be the mean-squared error between target and actual positions of the right hand in our aforementioned animation application. Technically, by defining \(L(_{0},)\) such that \(p(|_{0})(-L)\), \(p(|}_{0}(_{t}))\) can be maximized by following the gradient direction \(-_{_{t}}L(}_{0},)\).

Such frameworks open the door for highly flexible guided diffusion. Using the same unconditional model trained for \(p()\), we can now plug in various different \(L\) for different \(\) during inference time, without having to train additional networks for each possible new \(\).

## 3 Trust Sampling: Formulating Guided Diffusion as Optimization

Our work revisits training-free guided Diffusion from the perspective of optimization. Previous works decouple the two terms \(p(_{t})\) and \(p(|_{t})\) in Eq. 4 - they use the unconditional Diffusion model to optimize for \(p(_{t})\), and then took one gradient step of \( p(|_{t})\) for the constraint (guidance) term. As our experiment results will demonstrate, single gradient steps for constraints can lead to less optimal samples. With previous works mitigating this issue by carefully selecting the step sizes of \(_{_{t}} p(|_{t})\) or by better approximating \(p(|_{t})\), we explore a new direction which leads to a robust practical algorithm across multiple domains and various constraint diffusion tasks. To start with, following the gradients of \( p(|_{t})\) indicates we can reformulate the constraint diffusion problem as an optimization problem:

\[_{^{}}\ p(|^{})^{} p(_{t}),\] (6)

where we replace \(_{t}\) with \(^{}\) to signify that the state variable \(^{}\) can deviate from the Diffusion-predicted \(_{t}\) during this optimization. It is important to note that, first, for optimizing \(p(_{t})\), we still follow standard diffusion inference given its widespread empirical success in multiple domains, and second, we constrain \(^{}\) to stay in the distribution of all possible \(_{t}\) at diffusion level \(t\), as to not create a train-test discrepancy for the base diffusion model. This optimization formulation opens the door for more more flexibility in algorithm design, as we are no longer limited to taking only one gradient step.

### Trust Schedules: Termination Criteria of Optimization

Our key improvement of this work is the use of iterative gradient-based optimization to solve Eq. 6. While only taking one single gradient step proves to be sub-optimal, as we will demonstrate in this section, optimizing until the objective saturates is also not ideal. To see this, recall that \(p(|_{t})\) is generally not tractable, while \(p(|}_{0}(_{t}))\) is. As we replace the optimization objective \(p(|_{t})\) with the proxy \(p(|}_{0}(_{t}))\), it is crucial to terminate in time before the proxy becomes a poor approximation of the true objective. Formally this relaxation can be written as:

\[_{^{}}\ L(}_{0}(^{}), )^{} p(_{t}), |p(|^{})-p(|}_{0})|<d,\] (7)

where readers are reminded that minimizing \(L(}_{0},)\) is equivalent to maximizing \(p(|}_{0})\), and \(d\) is a relaxation threshold newly introduced. To reason about the gap \(d\) between true and proxy objectives, note that:

\[p(|^{}) = _{_{0}}p(_{0}|^{})p( |_{0})d_{0}=_{_{0} p( _{0}|^{})}[f(_{0})],\] \[p(|}_{0}) = f(}_{0})=f(_{_{0} p( _{0}|^{})}[_{0}]),\]

where we use \(f()\) as a shorthand for \((-L(\ ;))\). While a similar but tedious analysis exist for general multivariant \(\), for the purpose of practical algorithm design, looking at the special case where \(\) is a scalar random variable is more intuitive for understanding. Let \(f^{}\) denote the curvature of \(f()\), and \(a= f^{}\) and \(b= f^{}\) denote the range of the curvature assuming \(\) has a finite span, we now have \(f-a^{2}\) and \(b^{2}-f\) both as convex functions. Applying Jensen's inequality to both functions:

\[[f(_{0})-a_{0}^{2}] f ([_{0}])-a[_{0}]^{2}, [b_{0}^{2}-f(_{0})] b[_{0}]^{2}-f([_{0}]).\] (8)

After rearranging this gives:

\[()[f(_{0})]-f([_{0}])().\] (9)

This indicates, rather intuitively, that the approximation error increases with the variance of \(\). As a result, we can **trust** the proxy optimization \(_{^{}}\ L(}_{0}(^{}), )\) more when the variance of \(\) is smaller and the proxy becomes less reliable when the variance is large. Since it is intractable to estimate the true value of the gap \(d\) during the course of optimization, we opt to design a **trust schedule** of maximally allowed gradient iterations that is correlated to the variance of \(\) at each diffusion iteration \(t\). In our experiments, we will demonstrate that simple schedules, such as a constant function \(g_{}(t)=c\), or a linear function \(g_{}(t)=m t+c\), work surprisingly well for the diverse set of tasks we attempted.

### Early Termination Using State Manifold Boundaries

The previous section reformulates constrained guided diffusion as a gradient-based optimization, with our proposed algorithm designed to timely terminate the iterations based on the trustworthiness of the proxy objective. Equations 6 and 7 additionally require us to characterize the space that a forward sample \(_{t}\) can possibly visit at diffusion level \(t\), so that we can ensure, during inference time, that \(^{}\) will not leave the state manifold where the base model is trained on. In practice, the robustness of diffusion models can produce valid samples even if the input is slightly outside of the state manifold, allowing the constraint \(^{} p(_{t})\) to be relaxed. However, stepping outside of the state manifolds might require more unnecessary "corrective" steps, affecting the run-time performance. To speed up the computation during inference time, we describe a method for early termination of the optimization when the sample leaves the estimated boundary of the state manifold at each diffusion step.

We leverage the boundaries of a Diffusion model's intermediate state manifolds \(_{t,}\), which we define per diffusion timestep \(t\) as the manifold on which a diffusion model has likely seen training data from with probability \( 1-\):

\[_{t,}=\{_{t}: q(_{t}|_{ 0})p(_{0})_{0} 1-\}.\] (10)

Given sufficiently small \(\) and a sufficiently well-trained diffusion model, the idea is that any \(_{t}_{t,}\) will converge to some point \(_{0}\) in the original data distribution \(p(_{0})\). As such, the optimization problem from Eq. 7 becomes:

\[_{^{}}\ L(}_{0}(^{}), )^{}_{t,}, |p(|^{})-p(|}_{0})|<d.\] (11)

By definition, \(M_{t,}\) is a larger manifold when \(t\) is larger, meaning it gradually shrinks to true data manifold during diffusion inference. Nevertheless, \(M_{t,}\) would be challenging to compute in closed-form given the unknown true data distribution \(p(_{0})\). Our observation is that in all formulations of Diffusion models, we do have access to the model's predicted noise \(\). For a particular \(^{}\), the ideal value for \(_{}(^{},t)\) is

\[_{}(^{},t)=^{}- }_{0}}{}}p(_{0})_{0}=_{_{0}}[^{}- }_{0}}{}}].\] (12)

If \(^{}\) is within the state manifold boundary, the integrand \(^{}-}_{0}}{}}\) for each sample of \(_{0}\) should correspond to a multivariant Gaussian \(N(,)\). This implies that we can estimate the boundary of \(_{t,}\) with \(||_{}(^{},t)||\). When \(||_{}(^{},t)||\) is far away from zero, \(^{}-}_{0}}{}}\) is unlikely to be sampled from \(N(,)\). Consequently, \(^{}\) is likely to be outside of the state manifold at the current diffusion step. In practice, we set such a threshold \(_{max}\) by observing the approximate average \(||_{}(_{t},t)||\) across several unconstrained samples running the base Diffusion model.

### Algorithm

Comparing with standard DDIM sampling, our Trust Sampling algorithm (Algorithm 1) takes multiple gradient steps of constraint guidance up to a maximum of \(J_{t}\), which denotes a max-iteration according to the trust schedule, \(g_{}(t)\). We experiment with different linear schedules, detailed in the Experiments section, to show the positive impacts of our algorithm on the quality of generated data. The inner optimization loop will also be terminated by the condition when the magnitude of the predicted noise \(\) being larger than \(_{}\). Following Yang et al. , we normalize the gradient for numerical stability. \(w\) is a constant step size which we keep either as 0.5 or 1.0 for each specific task.

```
0:\(x_{T}(,)\), \(T\), observation \(y\), trust schedule \(g_{}(t)\), norm upper bound \(_{}\), guidance weight \(w\)
1for\(t=T,,1\)do
2\(_{}}}_{0}(_{t})+ -_{t}^{2}}_{}(_{t},t)\)
3\(_{t-1}^{*},j_{},0\)
4\(J_{t} g_{}(t)\)
5while\(j<J_{t}\)and\(||_{}(_{t-1}^{*},t)||<_{}\)do
6\(_{t-1}_{t-1}^{*}-w_{_{t-1}^{*}}L(} _{0}(_{t-1}^{*}),y)/||_{_{t-1}^{*}}L(}_{0}(_ {t-1}^{*}),y)||\)
7\(j j+1\)
8 end for
9\(_{t}(,)\)
10\(_{t-1}_{t-1}^{*}+_{t}_{t}\)
11 end while ```

**Algorithm 1**Trust Sampling with DDIM

Adapting Inequality Constraints.We use the mean-squared value over all constraint violations to compose \(L\) in the case of equality constraints. However, we need to make an to handle inequality constraints. In the case of an inequality constraint \(c_{i}(x)>a\), we choose formulate \(L_{i}=(0,a-c_{i}(x))\). We then compose \(L\) as the mean-squared value over all \(L_{i}\).

Related Work

Our work is most closely related to zero-shot guided Diffusion methods for general loss functions. The seminal works of  and  introduced a method that alternates between taking one denoising step of the unconditional base diffusion model to maximize data distribution and taking one constraint gradient step to guide the model for conditional sample generation. This approach effectively balances data fidelity and conditional alignment. DSG  enhanced  by normalizing gradients in the constraint guidance term and implementing a step size schedule inspired by Spherical Gaussians. LGD-MC  addressed the inherent approximation errors in DPS by using multiple samples instead of a single point, which provided a better approximation of the guidance loss. Manifold Constrained Gradient (MCG)  and Manifold Preserving Guided Diffusion (MPGD)  use projections on the constraint gradient and predicted de-noised sample respectively to leverage the manifold hypothesis for better constraint following. In contrast, our work explores improving this paradigm using iterative gradient-based optimization.

Various methods have been developed specifically for guided diffusion of image restoration. REDDiff  extends the principles of Regularization by Denoising (RED) for image noise removal  to a stochastic setting, offering a variational perspective on solving inverse problems with diffusion models. Techniques such as [10; 27; 55; 14; 49] assume linear distortion models and utilize the measurement operator matrix to improve guidance for image restoration. To handle non-linear distortion models, approaches like  and  have been proposed. These methods can accommodate complex distortion but require specialized initialization schemes, which limits their general applicability. In contrast, our approach initializes from the standard unit Gaussian, ensuring broader applicability in general tasks. Similarly, IIGDM  addresses inverse problems for image restoration with diffusion, but it is confined to certain loss types, while RePaint  enhances diffusion-based image in-painting by repeating crucial diffusion steps to improve fidelity.

Recent advancements like  and  tackle guided diffusion tasks based on conditional models, with conditions including textual information. FreeDOM  additionally adopts an energy-based framework and generalizes the repeating strategy found in RePaint with a novel time travel strategy. DiffPIR  balances the data prior term from the unconditional diffusion model with the constraint term from measurement loss to improve image restoration tasks.

Other methods adopt additional training for controlled diffusion. Ambient Diffusion Posterior Sampling  builds upon DPS  by training the base model on linearly corrupted data.  learns a score function for the noise distribution, specifically targeting structured noise in images. ControlNet  and OmniControl  train additional Diffusion branches to process input constraints and conditions, achieving notable results in image or motion domains. DreamBooth  fine-tunes a base diffusion model to place subjects in different backgrounds using a few images, demonstrating versatility in content generation. Other notable related works include , which focuses on composing multiple diffusion models. The proposed MCMC framework replaces simple gradient addition with a more robust iterative optimization process, similar to our framework for solving guided diffusion. D-PNP  reformulates diffusion as a prior for various guidance tasks but has been observed to struggle with more complex diffusion models, such as those trained on ImageNet .

## 5 Experiments

We evaluate our method on two drastically different domains: images and 3D human motion. In both domains, we compare against recent zero-shot guided diffusion algorithms for solving general constraint diffusion: DPS , DSG , and LGD-MC .

### Image Experiments

Tasks.We evaluate our method on three challenging image restoration problems: Super-resolution, Box Inpainting, and Gaussian Deblurring. These common linear inverse problems are standard across DPS , DSG , and LGD-MC ; we note that in this paper, we do not inject noise into the initial observations. Each of these image restoration problems can be thought of as a constraint satisfaction problem, where the constraint is that the generated picture appear the same as the source image upon applying the particular distortion. Distortion for these problems, respectively, was performed via (i) bicubic downsampling by \(4\), (ii) randomly masking a \(128 128\) square region 

[MISSING_PAGE_FAIL:7]

### Human Motion Experiments

Unconditional Motion Diffusion Model.For all tasks we use the same unconditional diffusion model, which we trained on the AMASS [33; 2; 28; 16; 8; 7; 30; 37; 34; 29; 53; 25; 51; 44; 3] dataset excluding the following datasets that are used for testing: danceDB , HUMAN4D  and Weizmann . The architecture is an adapted version of the EDGE motion model , where we removed the branches handling conditions.

Metrics.We evaluate DPS, DPS+DSG, LGD-MC, and Trust on several constrained motion generation tasks. We train an autoencoder and use the encoder as a feature extractor for motion clips, to allow for calculation of motion realism and diversity metrics . We use the following metrics to evaluate performance:

* FID: We extract features using the aforementioned encoder and calculate FID between different methods vs. ground-truth, as in Action2Motion .
* Diversity: We extract features and calculate the diversity metric as in Action2Motion  for the generated and ground truth motions. A result is claimed better than others if its score is closer to the score of the ground truth.
* Constraint Violation: A task-dependent metric that describes how well the generated motion adheres to the provided constraints.

Tasks.We first evaluate on two tasks where we have ground truth motions from the test dataset: _root trajectory tracking_ and _right hand & left foot trajectory tracking_. Here the diffusion model should be guided to generate natural human movements that closely follow specified root motions or hand/foot motions. Note that the generations do _not_ need to match the ground-truth motions due to under-specification of the constraints; we are only using them for generating the control constraints which are guaranteed to be physically feasible for human movements. Specifically, we randomly select a total of 1000 slices from the mentioned three test sets, and we extract their root motion and right hand and left ankle motion as constraint signals for the respective tasks. Note also that the observation mapping, from full motion states to the constraint signals, is highly non-linear in the hand/foot tracking task. This is because the full motion state of Diffusion only uses local joint rotations, but the hand/foot trajectory is defined in the global Cartesian space (see EDGE  for more details).

Results.Our method strikes the best balance to matching the constraint without sacrificing realism nor diversity. DPS has the best FID score closely followed by ours. However, this comes at a large cost for DPS that violates the constraints. DSG satisfies constraints slightly better than our method, but it sacrifices both diversity and realism significantly. Our method outperforms DPS and DSG on the Diversity score for both _root tracking_ and _right hand & left foot tracking_. While LGD-MC balances fidelity and constraint following better, it still has worse fidelity than Trust and struggles with harder tasks such as _right hand & left foot tracking_. Note that for these tasks the constraint metric is the root-mean-square tracking error in meter. The difference between ours, DSG, and LGD-MC are hardly noticeable when performing visual comparison between the generated motions, especially for _root tracking_. Visualizations that support these observations are in Appendix D, Fig. 6, but are best viewed in the **supplementary video**.

   &  &  \\  Methods & FID \(\) & Diversity \(\) & Const. [m] \(\) & FID \(\) & Diversity \(\) & Const. [m] \(\) \\  DPS & **542.8** & 23.8 & 0.13 & **604.7** & 22.5 & 0.12 \\ DPS+DSG & 715.1 & 25.0 & 0.022 & 865.5 & 24.0 & **0.035** \\ LGD-MC \((n=10)\) & 578.6 & 21.6 & 0.031 & 715.2 & 22.6 & 0.056 \\ LGD-MC \((n=100)\) & 579.3 & 22.6 & **0.006** & 731.6 & 23.1 & 0.052 \\ Trust (ours) & 561.6 & **21.5** & 0.026 & 694.1 & **20.4** & 0.038 \\  GT & - & 17.3 & - & - & 17.3 & - \\  

Table 3: Evaluation of FID, Diversity, and Constraint Violation in meters for motion tasks: root tracking and right hand & left foot tracking. **Bold**: best, red: worst. Computational budget for all methods is 1000 NFEs.

More Challenging Tasks.We further experimented our method with more difficult tasks such as sparse spatio-temporal constraints, inequality and highly non-linear constraints, and compositing multiple constraints. This is in drastic contrast to the image tasks, where a single "dense" (closer to being fully-specified) constraint must be satisfied. We designed the following tasks with additional two composite constraints on each--a translation constraint on the initial and the final frames.

* _Obstacle Avoidance_: We add an inequality constraint to avoid penetration between any joint and three pseudo-randomly placed obstacle spheres.
* _Jump_: We add an inequality constraint at the middle frame, to impose that all joints have a vertical position that is higher than a selected value between 0.6 m and 1.0 m.
* _Angular Momentum_: We add an inequality constraint to impose different minimum values for the average angular momentum around a horizontal axis. This serves as a way to control dynamicism of a motion. Angular momentum is approximated as: \(_{i=1}^{4}_{i}_{i}\). with \(_{i},_{i}\) the relative velocity and position of an end effector (wrists and ankles) with respect to the root.

As quantitative metrics would not be informative in these tasks (for example, it is not reasonable to compute the distributional distance between ground-truth test set and jumping motions), we focus on qualitative demonstrations. We consistently found that for easier inequality constraints (e.g. lower jumping heights) all methods could match the constraints. However, our method was more robust when constraints became harder, while DSG sacrificed physical realism and DPS violated the constraints. See Fig. 6, and **supplemental videos** for more details on these observations.

### Ablations

To examine the influence of Trust sampling, we performed ablations on the same three image tasks on FFHQ. In addition to FID and LPIPS, we look at the number of neural function evaluations (NFEs) as an implementation-agnostic metric of efficiency. In our case, NFEs is the number of times a pass through the pretrained model occurs.

Trust Scheduling.We decouple just the trust schedule and do not use state manifold estimates for this part. The results (Table 4) show that our method is not sensitive to scheduling parameters as all schedules still outperform the DPS and DSG baselines on all three image tasks by significant margins. Within the different schedules, we see that linear schedules with non-zero slope (i.e. non-constant schedules) typically outperform constant schedules. This aligns with our notion of trust, as earlier diffusion steps tend to be noiser and therefore the proxy constraint function is less trustworthy, so it is less productive to take gradient steps at earlier times. Although linear trust schedule is better than constant schedules, the results indicate the best slope is dependent of the task and NFEs.

Fewer NFEs.Table 4 also shows when decreasing NFEs from 1000 (same as baselines) to 600, the performance of our method barely drops and are still significantly better than baselines. To control the desired number of NFEs (1000 or 600 in our experiments), we choose a few combinations of the slope \(m\) and the offset \(c\) of the trust schedule \(g_{}(t)=m t+c\), such that \(_{t=1}^{T}g_{}(t)\) equals the desired number of NFEs, where \(T\) is the total number of diffusion iterations.

Manifold Boundary Estimates.We examined the effect of using manifold boundary estimates on the image tasks on FFHQ and ImageNet. We compare the effect of manifold boundary estimates when added to the trust schedule, as compared to only trust scheduling. Table 5 shows the results of using manifold boundary estimates. The use of manifold boundary reduces the needed NFEs by 10-20% without any substantial loss in quality, resulting in better compute efficiency. This performance boost is evidently robust across image task, dataset, and NFEs. Table 5 also shows that if instead of adopting manifold boundary, we want to achieve the same NFE save by tuning the start and end points of the linear schedule, model quality can suffer. Table 6 shows the effect of varying \(_{}\). We observe that \(_{}\) generally has an acceptable range (e.g. 440-442 for FFHQ Super Resolution \((4)\)), within which performance varies only slightly. For the motion tasks we did not find a significant effect when introducing manifold boundary estimates.

## 6 Conclusion

We introduce trust sampling, a novel and effective method for guided diffusion, addressing the current limitations of meeting challenging constraints. By framing each diffusion step as an independent optimization problem with principled trust schedules, our approach ensures higher fidelity across diverse tasks. Extensive experiments in image super-resolution, inpainting, deblurring, and various human motion control tasks demonstrate the superior generation quality achieved by our method.

Our findings indicate that trust sampling not only enhances performance but also offers a flexible and generalizable framework for future advancements in constrained diffusion-based modeling. To further improve generation quality, future research should adopt a holistic approach by incorporating additional concepts from traditional numerical optimization into this framework, beyond just the termination criterion. This includes techniques such as step size line search and fast approximation of higher-order derivatives. Moreover, automating the setting of heuristic parameters, which are currently manually adjusted for each base diffusion model, would be beneficial.

   &  \\  \(_{}\) & Start, End & FID \(\) & LPIPS \(\) \\ 
438.0 & 15, 15 & 50.81 & 0.191 \\
439.0 & 10, 10 & 40.90 & 0.165 \\
440.0 & 5, 5 & 35.85 & 0.153 \\
441.0 & 4, 4 & **35.46** & **0.149** \\
442.0 & 4, 4 & 36.06 & 0.150 \\  

Table 6: \(_{}\) ablations. Metrics calculated on Super Resolution (\(4\)) on 100 validation images of FFHQ \(256 256\). To isolate purely the effect of \(_{}\) while keeping the number of NFEs comparable, constant linear schedules were chosen so that the number of NFEs was close to 1,000. **Bold**: best.

   &  &  &  \\  Total NFEs & Start & End & FID \(\) & LPIPS \(\) & FID \(\) & LPIPS \(\) & FID \(\) & LPIPS \(\) \\ 
1000 & 4 & 4 & 36.95 & **0.150** & 34.72 & 0.146 & 47.25 & 0.179 \\
1000 & 2 & 6 & **35.73** & 0.152 & **32.63** & **0.145** & 45.56 & **0.173** \\
1000 & 0 & 8 & 36.26 & 0.156 & 35.08 & 0.148 & **42.98** & 0.173 \\ 
600 & 2 & 2 & 45.01 & 0.153 & 44.22 & 0.178 & 57.12 & 0.199 \\
600 & 1 & 3 & 41.56 & 0.159 & 44.81 & 0.178 & 54.11 & 0.195 \\
600 & 0 & 4 & **34.94** & **0.149** & **38.70** & **0.151** & **48.94** & **0.181** \\  baseline (DPS) & & 64.66 & 0.230 & 51.25 & 0.176 & 60.91 & 0.226 \\ baseline (DSG) & & 60.23 & 0.214 & 58.30 & 0.179 & 59.59 & 0.212 \\  

Table 4: Trust scheduling ablation study on NFEs and different trust schedules. Metrics calculated on linear inverse problems on 100 validation images of FFHQ \(256 256\). “Start” and “End” indicate the boundary conditions of the trust schedule: \(g_{}(1)=\) Start and \(g_{}(T)=\) End. **Bold**: best among same NFEs, underline: second best among same NFEs.

   &  &  &  \\   &  &  & FID \(\) & LPIPS \(\) & NFEs & FID \(\) & LPIPS \(\) & NFEs & FID \(\) & LPIPS \(\) \\  ✗ & 0, 3 & 500 & 42.31 & 0.160 & **500** & 48.85 & 0.186 & 500 & 56.57 & 0.195 \\ ✗ & 1, 3 & 600 & 41.56 & 0.159 & 600 & 44.81 & 0.178 & 600 & 54.11 & 0.195 \\ ✗ & 0, 4 & 600 & **34.94** & **0.149** & 600 & **38.70** & **0.161** & 600 & **48.94** & 0.181 \\ ✓ & 0, 4 & **497** & 37.52 & 0.150 & 561 & 41.87 & 0.169 & **498** & 49.95 & **0.181** \\  

Table 5: FFHQ Manifold boundary ablations. Metrics calculated on linear inverse problems on 100 validation images of FFHQ \(256 256\). **Bold**: best, underline: second best.