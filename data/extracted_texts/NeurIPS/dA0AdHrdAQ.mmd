# ELCC: the Emergent Language Corpus Collection

Brendon Boldt

Language Technologies Insitute

Carnegie Mellon University

Pittsburgh, PA 15213

bboldt@cs.cmu.edu &David Mortensen

Language Technologies Insitute

Carnegie Mellon University

Pittsburgh, PA 15213

dmortens@cs.cmu.edu

###### Abstract

We introduce the Emergent Language Corpus Collection (ELCC): a collection of corpora collected from open source implementations of emergent communication systems across the literature. These systems include a variety of signalling game environments as well as more complex tasks like a social deduction game and embodied navigation. Each corpus is annotated with metadata describing the characteristics of the source system as well as a suite of analyses of the corpus (e.g., size, entropy, average message length). Currently, research studying emergent languages requires directly running different systems which takes time away from actual analyses of such languages, limits the variety of languages that are studied, and presents a barrier to entry for researchers without a background in deep learning. The availability of a substantial collection of well-documented emergent language corpora, then, will enable new directions of research which focus their purview on the properties of emergent languages themselves rather than on experimental apparatus.

## 1 Introduction

Emergent communication (also called _emergent language_) studies machine learning simulations that attempt to model the development of communication systems from scratch. These simulations have recently been argued to have many potential applications, both in artificial intelligence and in the scientific study of human communicative behavior . However, this potential has been stymied, due in part to the challenges--up to this point--in comparing emergent communication systems (ECSs)1 in a way that allows their properties and utility to be understood.

There have been no standard datasets, for example, that represent output from various systems across the literature. The only recourse, for researchers desiring to compare ECSs or the languages that they generate, has been to reimplement or collect code for earlier ECSs. Getting this code to run is a significant challenge, requiring the research to chase outdated versions of Python, install CUDA drivers (again), and work with sparsely documented code. The results of such efforts, too, would lack comparability and reproducibility. To our knowledge, efforts at large-scale comparison between different outputs of different ECSs are not reported in the literature.

This paper introduces the Emergent Language Corpus Collection (ELCC), a resource that addresses this glaring lacuna in the field of emergent communication research; namely, it is a set of corporaof "languages" generated by most of the prominent ECS types described in the current literature (accompanied by extensive metadata regarding the typology of the ECS, how the data were produced, and the statistical properties of the resulting corpus). With these data, it is possible for researchers, even those with limited technological expertise, to compare emergent languages, whether in their structural properties  or their utility in pretraining models for downstream NLP tasks . ELCC is published on Hugging Face Datasets at https://huggingface.co/datasets/bboldt/elcc with data and code licensed under the CC BY 4.0 and MIT licenses, respectively.

We discuss related work in Section 2. Section 3 lays out the design of ELCC while Section 4 describes the content of the collection. Section 5 presents some brief analyses, discussion, and future work related to ELCC. Finally, we conclude in Section 6.

ContributionsThe primary contribution of this paper is a first-of-its kind data resource which will enable broader engagement and new research direction within the field of emergent communication. Additionally, code published for reproducing the data resource also improve the reproducibility of existing ECS implementations in the literature, supporting further research beyond just the data resource itself.

## 2 Related Work

Emergent communicationThere is no direct precedent to this paper in the emergent communication literature that we are aware of. Perkins (2021) introduces the TexRel dataset, but this is a dataset observations for training ECSs, not data generated by them. Some papers do provide the emergent language corpora generated from their experiments (e.g., Yao et al. (2022)), although these papers are few in number and only include the particular ECS used in the paper. At a high level, the EGG framework  strives to make emergent languages easily accessible, though instead of providing corpora directly, it provides a framework for implementing ECSs. Thus, while EGG is more useful for someone building new systems entirely, it is not as geared towards research projects aiming directly at analyzing emergent languages themselves.

Data resourcesAt a high level, ELCC is a collection of different subdatasets which all represent various manifestations of common phenomenon (emergent communication, in this case). On a basic level, ELCC could is somewhat analogous to any multi-lingual dataset (where "human language" is the phenomenon). Taking the notion of "phenomenon" more narrowly (i.e., of more direct scientific interest), it could be compared to Blum et al. (2023), which presents a collection of grammar snapshot pairs for \(52\) different languages as instances of diachronic language change. Zheng et al. (2024) present a dataset of conversations from Chatbot Arena containing where "text generated by different LLMs" is the phenomenon of interest. Insofar as ELCC documents the basic typology of different ECSs, it is similar to the World Atlas of Language Structures (WALS) Dryer and Haspelmath (2013).

## 3 Design

### Format

ELCC is a collection of ECSs each of which has one or more associated _variants_ which correspond to runs with different hyperparameter settings (e.g., different random seed, message length, dataset). Each variant has metadata along with the corpus generated from its settings. Each ECS has its own metadata as well and code to generate the corpus and metadata of each variant. The structure of ELCC is illustrated in Figure 1.

ECS metadataEnvironment metadata provides a basic snapshot of a given system and where it falls in the taxonomy of ECSs. As the collection grows, this makes it easier to ascertain the contents of the collection and easily find the most relevant corpora for a given purpose. This metadata will also serve as the foundation for future analyses of the corpora looking how the characteristics of an ECS relate to the properties of its output.

* The URL of where the code for producing the data is from.
* The URL of the original repo if **source** is a fork.
* The URL of the paper documenting the ECS (if any).
* The high level category of the game implemented in the ECS; currently one of _signalling_, _conversation_, or _navigation_.
* A finer-grained categorization of the game, if applicable.
* The type of observation that the agents make; currently either _vector_ or _image_ (i.e., an image embedding).
* Whether or not the observation is continuous as opposed to discrete (e.g., image embeddings versus concatenated one-hot vectors).
* Whether the data being communicated about is from a natural source (e.g., pictures), synthetic, or does not apply (e.g., in a social deduction game).
* A dictionary where each entry corresponds to one of the variants of the particular ECS. Each entry in the dictionary contains any relevant hyperparameters that distinguish it from the other variants.
* Whether or not the ECS implements seeding the random elements of the system.
* Whether or not the ECS has multiple steps per episode.
* Whether or not agents both send and receive messages.
* Whether or not multiple utterances are included per line in the dataset.
* Whether or not the ECS has a population of \(>\)2 agents.

These metadata are stored as YAML files in each ECS directory. A Python script is provided to validate these entries against a schema. See Appendix A for an example of such a metadata file.

CorpusEach _corpus_ comprises a list of _lines_ each of which is, itself, an array of _tokens_ represented as integers. Each line corresponds to a single episode or round in the particular ECS. In the case of multi-step or multi-agent systems, this might comprise multiple individual utterances which are then concatenated together to form the line (no separation tokens are added). Each corpus is generated from a single run of the ECS; that is, they are never aggregated from distinct runs of the ECS.

Concretely, a _corpus_ is formatted as a JSON lines (JSONL) file where each _line_ is a JSON array of integer _tokens_. This is visualized in Figure 2. There are a few advantages of JSONL: (1) it is JSON-based meaning it is standardized and has wide support across programming languages, (2) it is easy to interpret and work with for those without a computer science background, and (3) it is

Figure 1: The file structure of ELCC.

line-based meaning it is easy to process with command line tools.2 Corpora are also available as single JSON objects (i.e., and array of arrays), accessible via the Croissant ecosystem.

Corpus analysisFor each corpus in ELCC we run a suite of analyses to produce a quantitative snapshot. This suite metrics is intended not only to paint a robust a picture of the corpus but also to serve as jumping-off point for future analyses on the corpora. Specifically, we apply the following to each corpus: token count, unique tokens, line count, unique lines, tokens per line, tokens per line stand deviation, \(1\)-gram entropy, normalized \(1\)-gram entropy, entropy per line, \(2\)-gram entropy, \(2\)-gram conditional entropy, EoS token present, and EoS padding. _Normalized \(1\)-gram entropy_ is computed as \(1\)_-gram entropy_ divided by the maximum entropy given the number of unique tokens in that corpus.

We consider an EoS (end-of-sentence) token to be present when: (1) every line ends with token consistent across the entire corpora, and (2) the first occurrence of this token in a line is only ever followed by more the same token. For example, 0 could be an EoS token in the corpus [,] but not [,]. EoS padding is defined as a corpus having an EoS token, all lines being the same length, and the EoS token occurs more than once in a line at least once in the corpus.

Additionally, each corpus also has a small amount of metadata copied directly from the output of the ECS; for example, this might include the success rate in a signalling game environment. We do not standardize this because it can vary widely from ECS to ECS, though it can still be useful for comparison to other results among variants within an ECS.

ReproducibilityELCC is designed with reproducibility in mind. With each ECS, code is included to reproduce the corpora and analysis metadata. Not only does this make ELCC reproducible, but it sometimes helps the reproducibility of the underlying implementation insofar as it fixes bugs, specifies Python environments, and provides examples of how to run an experiment with a certain set of hyperparameters. Nevertheless, in this code, we have tried to keep as close to the original implementations as possible. When the underlying implementation supports it, we set the random seed (or keep the default) for the sake of consistency, although many systems do not offer ways to easily set this.

   Source & Type & Data source & Multi-agent & Multi-step & \(n\) corp. \\  Kharitonov et al. (2021) & signalling & synthetic & No & No & \(15\) \\ Yao et al. (2022a) & signalling & natural & No & No & \(2\) \\ Mu and Goodman (2021b) & signalling & both & No & No & \(6\) \\ Chaabouni et al. (2022) & signalling & natural & Yes & No & \(5\) \\ Unger and Bruni (2020) & navigation & synthetic & No & Yes & \(18\) \\ Boldt and Mortensen (2022) & navigation & synthetic & No & Yes & \(20\) \\ Brandizzi et al. (2022) & conversation & — & Yes & Yes & \(7\) \\   

Table 1: Taxonomic summary the contents of ELCC.

Figure 2: Example of a three-line corpus in the JSON lines format.

## 4 Content

ELCC contains \(73\) corpora across \(8\) ECSs taken from the literature for which free and open source implementations were available. With our selection we sought to capture variation across a three distinct dimensions:

1. Variation across ECSs generally, including elements like game types, message structure, data sources, implementation details.
2. Variation among different hyperparameter settings within an ECS, including message length, vocabulary size, dataset, and game difficulty.
3. Variation within a particular hyperparameter setting that comes from inherent stochasticity in the system; this is useful for gauging the stability or convergence of an ECS.

Table 1 shows an overview of the taxonomy of ELCC based on the ECS-level metadata. In addition to this, Table 2 provides a quantitative summary of the corpus-level metrics described in Section 3.1 (full results in Appendix C). The following sections describe the individual ECSs in more detail.

### Scope

The scope of the contents of ELCC is largely the same as discussed in reviews such as Lazaridou and Baroni (2020) and Boldt and Mortensen (2024, Section 1.2). This comprises agent-based models for simulating the formation of "natural" language from scratch using deep neural networks. Importantly, _from scratch_ means that the models are not pretrained or tuned on human language. Typically, such simulations make use of reinforcement learning to train the neural networks, though this is not a requirement in principle.

One criterion that we do use to filter ECSs for inclusion is its suitability for generating corpora as described above. This requires that the communication channel is discrete, analogous to the distinct words/morphemes which for the units of human language. This excludes a small number of emergent communication papers have approached emergent communication through constrained continuous channels like sketching (Mihai and Hare, 2021) or acoustic-like signals (Eloff et al., 2023). Other systems use discrete communication but are in essence one token per episode (e.g., Tucker et al. (2021)) which would not form a suitable corpus for addressing most research questions.

### Signalling games

The _signalling game_ (or _reference game_) (Lewis, 1969) represents a plurality, if not majority, of the systems present in the literature. A brief, non-exhaustive review of the literature yielded \(43\) papers

    & min & \(25\%\) & \(50\%\) & \(75\%\) & max \\  Token Count & \(48616\) & \(67248\) & \(110000\) & \(1061520\) & \(42977805\) \\ Line Count & \(999\) & \(5765\) & \(10000\) & \(10000\) & \(2865187\) \\ Tokens per Line & \(5.87\) & \(7.00\) & \(11.00\) & \(33.53\) & \(7212.72\) \\ Tokens per Line SD & \(0.00\) & \(0.00\) & \(2.31\) & \(13.81\) & \(445.84\) \\ Unique Tokens & \(2\) & \(7\) & \(10\) & \(20\) & \(902\) \\ Unique Lines & \(18\) & \(1253\) & \(2440\) & \(4911\) & \(309405\) \\
1-gram Entropy & \(0.36\) & \(2.12\) & \(2.80\) & \(3.37\) & \(6.60\) \\
1-gram Normalized Entropy & \(0.16\) & \(0.71\) & \(0.82\) & \(0.90\) & \(1.00\) \\
2-gram Entropy & \(0.42\) & \(3.16\) & \(4.11\) & \(5.88\) & \(12.88\) \\
2-gram Conditional Entropy & \(0.06\) & \(0.85\) & \(1.41\) & \(2.54\) & \(6.29\) \\ Entropy per Line & \(4.38\) & \(21.23\) & \(30.80\) & \(71.85\) & \(30233.52\) \\   

Table 2: Five-number summar of the analyses across corpora of ELCC. Entropy in bits.

which use minor variations of the signalling game, a large number considering the modest body of emergent communication literature (see Appendix B). The basic format of the signalling game is a single round of _sender_ agent making an observation, passing a message to the _receiver_ agent, and the receiver performing an action based on the information from the message. The popularity of this game is, in large part, because of its simplicity in both concept and implementation. Experimental variables can be manipulated easily while introducing minimal confounding factors. Furthermore, the implementations can entirely avoid the difficulties of reinforcement learning by treating the sender and receiver agents as a single neural network, resulting in autoencoder with a discrete bottleneck which can be trained with backpropagation and supervised learning.

The two major subtypes of the signalling game are the _discrimination game_ and the _reconstruction game_. In the discrimination game, the receiver must answer a multiple-choice question, that is, select the correct observation from among incorrect "distractors". In the reconstruction game, the receiver must recreate the input directly, similar to the decoder of an autoencoder.

VanillaFor the most basic form of the signalling game, which we term "vanilla", we use the implementation provided in the Emergent of LanGuage in Games (EGG) framework . It is vanilla insofar as it comprises the signalling game with the simplest possible observations (synthetic, concatenated one-hot vectors), a standard agent architecture (i.e., RNNs) and no additional dynamics or variations on the game. Both the discrimination game and the reconstruction game are included. This system provides a good point of comparison for other ECSs which introduce variations on the signalling game. The simplicity of the system additionally makes it easier to vary hyperparameters: for example, the size of the dataset can be scaled arbitrarily and there is no reliance on pretrained embedding models.

Natural images"Linking emergent and natural languages via corpus transfer"  presents a variant of the signalling game which uses embeddings of natural images as the observations. In particular, the system uses embedded images from the MS-COCO and Conceptual Captions datasets consisting of pictures of everyday scenes. Compared to the uniformly sampled one-hot vectors in the vanilla setting, natural image embeddings are real-valued with a generally smooth probability distribution rather than being binary or categorical. Furthermore natural data distributions are not uniform and instead have concentrations of probability mass on particular elements; this non-uniform distribution responsible for various features of human language (e.g., human languages' bias towards describing warm colors ).

Differing observations"Emergent communication of generalizations"  presents a variant of the discrimination signalling game which they term the _concept game_. The concept game changes the way that the sender's observation corresponds with the receiver's observations. In the vanilla discrimination game, the observation the sender sees is exactly the same as the correct observation that the sender sees. In the concept game, the sender instead observes a set of inputs which share a particular concept (e.g., red triangle and red circle are both red), and the correct observation (among distractors) shown to the receiver contains the same concept (i.e., red) while not being identical to those observed by the sender. The rationale for this system is that the differing observations will encourage the sender to communicate about abstract concepts rather than low-level details about the observation. This ECS also presents the vanilla discrimination game as well as the _sertef game_, which is similar to the reference game except that the whole object is consistent (e.g., different sizes and locations of a red triangle).

Multi-agent population"Emergent communication at scale"  presents a signalling game system with populations of agents instead of the standard fixed pair of sender and receiver. For each round of the game, then, a random sender is paired with a random receiver. This adds a degree of realism to the system, as natural human languages are ways developed within a population and not just between two speakers (cf. idioglossia). More specifically, language developing among a population of agents prevents some degree "overfitting" between sender and receiver; in this context, having a population of agents functions as an ensembling approach to regularization.

### Other games

Considering that the signalling game is close to the simplest possible game for an ECS, moving beyond the signalling game generally entails an increase in complexity. There is no limit to the theoretical diversity of games, although some of the most common games that we see in the literature are conversation-based games (e.g., negotiation, social deduction) and navigation games. These games often introduce new aspects to agent interactions like: multi-step episodes, multi-agent interactions, non-linguistic actions, and embodiment.

These kinds of systems, as a whole, are somewhat less popular in the literature. On a practical level, more complex systems are more complex to implement and even harder to get to converge reliably--many higher-level behaviors, such as planning or inferring other agent's knowledge, are difficult problems for reinforcement learning in general, let alone with discrete multi-agent emergent communication. On a methodological level, more complexity in the ECS makes it harder to formally analyze the system as well as eliminate confounding factors in empirical investigation. With so many moving parts, it can be difficult to prove that some observed effect is not just a result of some seemingly innocent hyperparameter choice (e.g., learning rate, samples in the rollout buffer) (Boldt and Mortensen, 2022). Nevertheless, we have reason to believe that these complexities are critical to understanding and learning human language as a whole (Bisk et al., 2020), meaning that the difficulties of more complex systems are worth overcoming as they are part of the process of creating more human-like, and therefore more useful, emergent languages.

Grid-world navigation"Generalizing Emergent Communication" (Unger and Bruni, 2020, BSD-3-clause license) introduces an ECS which takes some of the basic structure of the signalling game and applies it to a navigation-based system derived from the synthetic Minigrid/BabyAI environment (Chevalier-Boisvert et al., 2018, 2023). A sender with a bird's-eye view of the environment sends messages to a receiver with a limited view who has to navigate to a goal location. Beyond navigation, some environments present a locked door for which the receiver must first pick up a key in order to open.

What distinguishes this system most from the signalling game is that it is multi-step and embodied such that the utterances within an episodes are dependent on each other. Among other things, this changes the distribution properties of the utterances. For example, if the receiver is in Room A at timestep \(T\), it is more likely to be in Room A at timestep \(T+1\); thus if utterances are describing what room the receiver is in, this means that an utterance at \(T+1\) has less uncertainty given the content of an utterance at \(T\). Practically speaking, the multiple utterances in a given episode are concatenated together to form a single line in the corpus in order to maintain the dependence of later utterances on previous ones.

Continuous navigation"Mathematically Modeling the Lexicon Entropy of Emergent Language" (Boldt and Mortensen, 2022, GPL-3.0 license) introduces a simple navigation-based ECS which is situated in a continuous environment. A "blind" receiver is randomly initialized in an obstacle-free environment and must navigate toward a goal zone guided by messages from the center which observes the position of the receiver relative to the goal. The sender sends a single discrete token at each timestep, and a line in the dataset consists of the utterances from each timestep concatenated together. This system shares the time-dependence between utterances of the grid-world navigation system although with no additional complexity of navigating around obstacle, opening doors, etc. On the other hand, the continuous nature of this environment provides built-in stochasticity since there are (theoretically) infinitely many distinct arrangements of the environment that are possible, allowing for more natural variability in the resulting language.

Social deduction"RLupus: Cooperation through the emergent communication in The Werewolf social deduction game" [14, GPL-3.0 license] introduces an ECS based on the social deduction game _Werewolf_ (a.k.a., _Mafia_) where, through successive rounds of voting and discussion, the "werewolves" try to eliminate the "villagers" before the villagers figure out who the werewolves are. In a given round, the discussion takes the form of all agents broadcasting a message to all other agents after which a vote is taken on whom to eliminate. As there are multiple rounds in a given game, this system introduces multi-step as well as multi-speaker dynamics into the language. Furthermore, the messages also influence distinct actions in the system (i.e., voting). These additional features in the system add the potential for communication strategies that are shaped by a variety of heterogeneous factors rather than simply the distribution of observations (as in the signalling game).

## 5 Discussion

Work enabled by ELCCIn the typical emergent communication paper, only a small amount of time and page count is allocated to analysis with the lion's share being taken up by designing the ECS, implementing it, and running experiments (see Figure 3). Even if one reuses an existing implementation, a significant portion of work still goes towards designing and running the experiments, and the analysis is still limited to that single system. ELCC, on the other hand, enables research which can not only be dedicated wholly to analysis but analysis across a variety of system. Furthermore, removing the necessity of implementing and/or running experiments allows researchers without machine learning backgrounds to contribute to emergent communication research from more linguistic angles that otherwise would not be possible.

In particular, ELCC enable work that focuses on the lexical properties of emergent communication, looking at the statical properties and patterns of the surface forms of a given language (e.g., Zipf's law). Ueda et al.  is a prime example of this; this paper investigates whether or not emergent languages obey Harris' Atticulation Schema relating conditional entropy to the presence of word boundaries. The paper finds mixed evidence for HAS in emergent languages but only evaluated a handful of settings in a single ECS; ELCC could be used in such a case to radically extend the scope emergent languages evaluated. Additionally, ELCC can similarly extend the range of emergent languages evaluated in the context of machine learning, such as Yao et al. , Boldt and Mortensen  which look at emergent language's suitability for deep transfer learning to downstream NLP tasks.

ECS implementations and reproducibilityIn the process of compiling ELCC, we observed a handful of trends in the implementations of emergent communication systems. A significant proportion of papers do not publish the implementations of experiments, severely limiting the ease reproducing the results or including such work in a project such as ELCC, considering that a large amount of the work in creating an ECS is not in the design but in the details of implementation. Even when a free and open source implementation is available, many projects suffer from underspecified Python dependencies (i.e., no indication of versions) which can be difficult to reproduce if the project

Figure 3: Typical allocation of resources to an emergent communication paper (time-wise and page count-wise): analysis is a relatively small component. ELCC enables research which can focus primarily on analysis.

is older than a few years. Furthermore, some projects also fail to specify the particular hyperparameter settings or commands to run the experiments presented in the paper; while these can often be recovered with some investigation, this and the above issue prove to be obstacles which could easily be avoided. For an exemplar of a well-documented, easy-to-run implementation of an ECS and its experiments, see Mu and Goodman (2021b) at https://github.com/jayelm/emergent-generalization/ which not only provides dependencies with version and documentation how to download the data but also a complete shell script which executes the commands to reproduce the experiments.

Future of ELCCWhile ELCC is a complete resource as presented in this paper, ELCC is intended to be an ongoing project which incorporates further ECSs, analyses, and taxonomic features as the body of emergent communication literature and free and open source implementations continues to grow. This approach involves the community not only publishing well-documented implementation of their ECSs but also directly contributing to ELCC in the spirit of scientific collaboration and free and open source software. ELCC, then, is intended to become a hub for a variety of stakeholders in the emergent communication research community, namely a place for: ECS developers to contribute and publicize their work, EC researchers to stay up-to-date on new ECSs, and EC-adjacent researchers to find emergent languages which they can analyze or otherwise use for their own research.

LimitationsWhile ELCC provides a representative sample of the ECSs present in the literature, it is not comprehensive collection of all of the open source implementations let alone all ECSs in the literature. This limitation is especially salient in the case foundational works in EC which have no open source implementations (e.g., Mordatch and Abbeel (2018)). Additionally, ELCC only provides unannotated corpora without any reference to the semantics of the communication, which limits the range of analyses that can be performed (e.g., measures of compositionality are precluded because since it fundamentally a relationship between surface forms and their semantics). In terms of compute resources, we estimate that on the order of 150 GPU-hours (NVIDIA A6000 or equivalents) on an institutional cluster were used in the development of ELCC.

## 6 Conclusion

In this paper, we have introduced ELCC, a collection of emergent language corpora annotated with taxonomic metadata and suite of descriptive metrics derived from free and open source implementations of emergent communication systems introduced in the literature. ELCC also provides code for running these implementations, in turn, making those implementations more reproducible. This collection is the first of its kind in providing easy access to a variety of emergent language corpora. Thus, it enables new kinds of research on emergent communication as it serves as a foundation for research focused on the analysis of emergent languages themselves.