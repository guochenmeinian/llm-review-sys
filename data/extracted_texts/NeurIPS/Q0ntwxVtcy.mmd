# Near-optimal learning with average Holder smoothness

Steve Hanneke

Department of Computer Science

Purdue University

steve.hanneke@gmail.com &Aryeh Kontorovich

Department of Computer Science

Ben-Gurion University of the Negev

karyeh@cs.bgu.ac.il &Guy Kornowski

Department of Computer Science and Applied Mathematics

Weizmann Institute of Science

guy.kornowski@weizmann.ac.il

###### Abstract

We generalize the notion of average Lipschitz smoothness proposed by Ashlagi et al. (2021) by extending it to Holder smoothness. This measure of the "effective smoothness" of a function is sensitive to the underlying distribution and can be dramatically smaller than its classic "worst-case" Holder constant. We consider both the realizable and the agnostic (noisy) regression settings, proving upper and lower risk bounds in terms of the average Holder smoothness; these rates improve upon both previously known rates even in the special case of average Lipschitz smoothness. Moreover, our lower bound is tight in the realizable setting up to log factors, thus we establish the minimax rate. From an algorithmic perspective, since our notion of average smoothness is defined with respect to the unknown underlying distribution, the learner does not have an explicit representation of the function class, hence is unable to execute ERM. Nevertheless, we provide distinct learning algorithms that achieve both (nearly) optimal learning rates. Our results hold in any totally bounded metric space, and are stated in terms of its intrinsic geometry. Overall, our results show that the classic worst-case notion of Holder smoothness can be essentially replaced by its average, yielding considerably sharper guarantees.

## 1 Introduction

A fundamental theme throughout learning theory and statistics is that "smooth" functions ought to be easier to learn than "rough" ones -- an intuition that has been formalized and rigorously established in various frameworks (Gyorfi et al., 2002; Tsybakov, 2008; Gine and Nickl, 2021). Holder continuity is a natural and well-studied notion of smoothness that measures the extent to which nearby points can differ in function value and includes Lipschitz continuity as an important special case.

These global moduli of smoothness, while convenient for theoretical analysis, suffer from the shortcoming of being overly pessimistic. Indeed, being distribution-independent, they fail to distinguish a function that is highly oscillatory everywhere from one that is smooth over most of the probability mass; see Figure 1 for a simple illustration. Moreover, classically studied classes of _average smoothness_ (e.g. Besov space) typically fix some distribution in advance (predominantly uniform), and then turn to consider smooth functions with respect to that single distribution. Thus, from a distribution-free statistical learning perspective -- where the underlying distribution is assumed to be unknown -- such classes fall short.

Seeking to address these drawbacks, Ashlagi et al. (2021) proposed a natural notion of average Lipschitz smoothness with respect to a distribution. Their average Lipschitz modulus can be considerably (even infinitely) smaller than the standard Lipschitz constant, while still being able to control the excess risk. However, the risk bounds obtained by Ashlagi et al. are far from optimal, while the optimal rates for distribution-free learning of average smoothness classes remained unknown. In particular, the cost of adapting to the smoothness with respect to the underlying distribution (in contrast to using classic worst-case smoothness) remained unclear so far.

Our contributions.In this work, we generalize the aforementioned notion of average Lipschitz smoothness by extending it to Holder smoothness of any exponent \((0,1]\). After formally defining the average Holder smoothness of a function with respect to a distribution in Section 2.1, our contributions can be summarized as follows:

* **Bracketing numbers upper bound (Theorem 3.1).** We establish a nearly-optimal distribution-free bound on the bracketing entropy of our proposed average-smooth function class, serving as the main crux on which we base our analyses throughout the paper. In particular, although it is known that asymptotically empirical covering numbers yield sharper bounds than bracketing numbers,1 in the case of average smoothness we reveal that the latter are tight up to a logarithmic factor. * **Realizable sample complexity (Theorem 3.4).** We derive a nearly-optimal sample complexity required for uniform convergence of average-Holder functions in the realizable case, which was not previously known even in the special case of average Lipschitz functions.
* **Optimal realizable learning algorithm (Theorem 4.1).** Since our notion of average smoothness is defined with respect to the unknown sampling distribution, the learner does not have an explicit representation of the function class, and hence is unable to execute ERM.2 We are able to overcome this obstacle by constructing a realizable nonparametric regression algorithm with a nearly-optimal learning rate. Such a rate was not previously known even in the special case of average Lipschitz smoothness. * **Agnostic learning algorithm (Theorem 5.1).** We provide yet another learning algorithm for the fully agnostic (i.e. noisy) regression setting. Once again, our derived rate was not previously known even in the special case of average Lipschitz smoothness.
* **Matching lower bound (Theorem 6.1).** We prove a lower bound, showing that all the results mentioned above are tight up to logarithmic factors in the realizable case, establishing the (nearly) minimax risk rate for average-smooth classes.
* **Illustrative comparisons (Section 7).** Finally, we illustrate the extent to which the proposed smoothness notion is sharper than previously studied notions. We provide examples in which

Figure 1: Illustration of a function and a measure \(\) exhibiting a large gap between “worst-case” smoothness (occurring in low density regions) and average-smoothness with respect to \(\).

the "optimistic" average-Holder constant is infinitely apart from both its "pessimistic" worst-case counterpart, or even the average-Lipschitz (\(=1\)) constant, exemplifying the substantial (possibly infinite) speed-ups in terms of learning rates.

### Related work.

The sample complexities associated to distribution-free learning of (classic) Holder classes is well covered in the literature, see for example the books by Gyorfi et al. (2002); Tsybakov (2008).

Previous notions of average smoothness include Bounded Variation (BV) (Appell et al., 2014) in dimensions one and higher (Kuipers and Niederreiter, 1974; Niederreiter and Talay, 2006). One-dimensional BV has found learning-theoretic applications (Bartlett et al., 1997; Long, 2004; Anthony and Bartlett, 1999), but to our knowledge the higher-dimensional variants have not. Moreover, the positive results require \(\) to be uniformly distributed on a segment, and the aforementioned results break down for more general measures -- especially if \(\) is not known to the learner.

Sobolev spaces, and the Sobolev-Slobodetskii norm in particular (Agranovich, 2015), bear some resemblance to our average Holder smoothness. However, Ashlagi et al. (2021, Appendix I) demonstrate that from a learning-theoretic perspective this notion is inadequate for general (i.e., non-uniform or Lebesgue) measures, as it cannot be used to control sample complexity. Results for controlling bracketing in terms of various measures of average smoothness include Nickl and Potscher (2007), who bound the bracketing numbers of Besov- and Sobolev-type classes and Malykhin (2010), who used the _averaged modulus of continuity_ developed by Sendov and Popov (1988); again, these are all defined under the Lebesgue measure. While it is easy to define these smoothness notions with respect to arbitrary distributions, we are not aware of any existing work to bound their corresponding sample complexity (or even their covering or bracketing numbers) in a distribution-independent manner. Moreover, the smoothness notion studied in this paper is defined over arbitrary metric spaces, whereas previous notions are typically restricted to Euclidean structures (or variants thereof). Despite of the considerable generality of our setting, we are able to provide tight bounds for all metric spaces alike, without requiring specialized analyses.

A seminal work on recovering functions with spatially inhomogeneous smoothness from noisy samples is Donoho and Johnstone (1998). Arguably in the spirit of \(\)-dependent Holder smoothness, some of the classic results on \(k\)-NN risk decay rates were refined by Chaudhuri and Dasgupta (2014) via an analysis that captures the interplay between the metric and the sampling distribution. Another related notion is that of _Probabilistic Lipschitzness_ (PL) (Urner and Ben-David, 2013; Urner et al., 2013; Kpotufe et al., 2015), which seeks to relax a hard Lipschitz condition on the regression function. While PL is in the same spirit as our notion, one critical distinction from our work is that, while existing analyses of learning under PL have focused specifically on binary classification, our interest in the present work is learning real-valued functions.

As previously mentioned, the main feature setting this work apart from others studying regression under average smoothness is that our notion is defined with respect to a _general, unknown_ measure \(\). The notable exception is, of course, Ashlagi et al. (2021) -- who introduced the framework of efficiently learning smooth-on-average functions with respect to an unknown distribution. Although extending their definition from Lipschitz to Holder average smoothness was straightforward, optimal minimax rates are likely inaccessible via their techniques, which relied on empirical covering numbers. Estimating the magnitude of these random objects was a formidable challenge, and Ashlagi et al. were only able to do so to within an additive error decaying with sample size; this sampling noise appears to present an inherent obstruction to optimal rates. Thus, our results required a novel technique to overcome this obstruction, which we did by tightly controlling the bracketing entropy. Our Holder-type extension is a direct adaptation of the Pointwise Minimum Slope Extension (PMSE) developed for the Lipschitz special case by Ashlagi et al., which in turn is closely related to the one introduced by Oberman (2008).

## 2 Preliminaries.

Setting.Throughout the paper we consider functions \(f:\) where \((,)\) is a metric space. We will consider a distribution \(\) over \(\) with marginal \(\) over \(\), such that \((,,)\) forms a metric probability space (namely, \(\) is supported on the Borel \(\)-algebra induced by \(\)). We associate to any measurable function \(f:\) its \(L_{1}\) risk \(L_{}(f):=_{(X,Y)}\,|f(X)-Y|\), and its empirical risk \(L_{S}(f):=_{i=1}^{n}|f(X_{i})-Y_{i}|\) with respect to a sample \(S=(X_{i},Y_{i})_{i=1}^{n}^{n}\). More generally, we associate to any measurable function its \(L_{1}\) norm \(\|f\|_{L_{1}()}:=_{X}\,|f(X)|\), and given a sample \((X_{1},,X_{n})^{n}\) we denote its \(L_{1}\) norm with respect to the empirical measure \(\|f\|_{L_{1}(_{n})}:=_{i=1}^{n}|f(X_{i})|\).

We say that a distribution \(\) over \(\) is _realizable_ by a function class \(^{}\) if there exists an \(f^{*}\) such that \(L_{}(f^{*})=0\). Thus, \(f^{*}(X)=Y\) almost surely, where \((X,Y)\).

Metric notions.The diameter of \(A\) is \((A):=_{x,x^{} A}(x,x^{})\), and we denote by \(B(x,r):=\{x^{}:(x,x^{}) r\}\) the closed ball around \(x\) of radius \(r>0\). For \(t>0,\;A,B\), we say that \(A\) is a _\(t\)-cover_ of \(B\) if \(B_{a A}B(a,t)\), and define the _\(t\)-covering number_\(_{B}(t)\) to be the minimal cardinality of any \(t\)-cover of \(B\). We say that \(A B\) is a \(t\)-_packing_ of \(B\) if \((a,a^{}) t\) for all \(a a^{} A\). We call \(V\) a \(t\)-_net_ of \(B\) if it is a \(t\)-cover and a \(t\)-packing. The induced _Voronoi partition_ of \(B\) with respect to a net \(V\) is its partitioning into subsets sharing the same nearest neighbor in \(V\) (with ties broken in some consistent arbitrary manner). A metric space \((,)\) is said to be _doubling_ if there exists \(d\) such that every \(r\)-ball in \(\) is contained in the union of some \(d\)\(r/2\)-balls. The _doubling dimension_ is defined as \(_{d 1}_{2}d\) where the minimum is taken over \(d\) satisfying the doubling property.

Bracketing.Given any two functions \(l,u:\), we say that \(f:\) belongs to the _bracket_\([l,u]\) if \(l f u\). A set of brackets \(\) is said to cover a function class \(\) if any function in \(\) belongs to some bracket in \(\). We say that \([l,u]\) is a \(t\)-bracket with respect to a norm \(\|\|\) if \(\|u-l\| t\). The \(t\)-_bracketing number_\(_{[]}(,\|\|,t)\) is defined as the minimal cardinality of any set of \(t\)-brackets that covers \(\). The logarithm of this quantity is called the _bracketing entropy_.

**Remark 2.1** (Covering vs. bracketing).: _Having recalled two notions that quantify the "size" of a normed function space \((,\|\|)\) -- namely, its covering and bracketing numbers -- it is useful to note they are related through_

\[_{}()_{[]}( ,\|\|,2)\;,\] (1)

_though no converse inequality of this sort holds in general. On the other hand, the main advantage of using bracketing numbers for generalization bounds is that it suffices to bound the ambient bracketing numbers with respect to the distribution-specific metric, as opposed to the empirical covering numbers which are necessary to guarantee generalization [van der Vaart and Wellner, 1996, Section 2.1.1]._

Strong and weak mean.For any non-negative random variable \(Z\) we define its _weak mean_ by \([Z]:=_{t>0}t[Z t]\), and note that \([Z][Z]\) by Markov's inequality. In the special case where \(Z\) has finite support of size \(N 3\) where each atom has mass \(1/N\) we have the reverse inequality \([Z] 2(N)[Z]\)[Ashlagi et al., 2021, Lemma 22].

### Average smoothness.

For \((0,1]\) and \(f:\), we define its \(\)-slope at \(x\) to be \(_{f}^{}(x):=_{y\{x\}}}\). Recall that \(f\) is called \(\)-Holder continuous if \(\|f\|_{^{}}:=_{x}_{f}^{}(x)<\), with this quantity serving as its Holder seminorm. In particular, when \(=1\) these are exactly the Lipschitz functions equipped with the Lipschitz seminorm. For a metric probability space \((,,)\), we consider the _average_\(\)-slope to be the mean of \(_{f}^{}(X)\) where \(X\). Namely, we define

\[_{f}^{}() :=_{X}[_{f}^{}(X)]\;,\] \[_{f}^{}() :=_{X}[_{f}^{}(X)]=_{t>0}\,t (x:_{f}^{}(x) t)\;.\]

Notably,

\[_{f}^{}()_{f}^{}() \|f\|_{^{}}\;,\] (2)where each subsequent pair can be infinitely apart -- as we demonstrate in Section 7. Having defined notions of averaged smoothness, we can further define their corresponding function spaces

\[}_{L}^{}() :=\{f:\,:\,\|f\|_{}^{ }} L\},\] \[}}_{L}^{}(,) :=\{f:\,:\,_{f}^{}( ) L\},\] \[}}_{L}^{}(,) :=\{f:\,:\,_{f}^{}( ) L\}.\]

We occasionally omit \(\) when it is clear from context. Note that \(}_{L}^{}()}}_{L}^{}(,)}}_{L}^{}( ,)\) due to Eq. (2), where both containments are strict in general. The special case of \(=1\) recovers the average-Lipschitz spaces \(_{L}()}_{L}( ,)}_{L}(,)\) studied by Ashlagi et al. (2021).

## 3 Generalization bounds

Our first goal is to bound the bracketing entropy (namely, the logarithm of the bracketing number) of average-Holder classes. We present this bound in full generality in terms of the underlying metric space, as captured by its covering number (see Corollary 3.5 for the typical scaling of covering numbers). As we will soon establish, this bound implies nearly-tight generalization guarantees in terms of the average smoothness constant.

**Theorem 3.1**.: _For any metric probability space \((,,)\), any \((0,1]\) and any \(0<<L\), it holds_

\[_{[})(}}_{ L}^{}(,),L_{1}(),) _{[}( }}_{L}^{}(,),L_{1}(),)\] \[_{}(()^{1/})((1/ )}{})\.\]

Crucially, the bound above does not depend on \(\), allowing us to obtain distribution-free generalization guarantees. We defer the proof of Theorem 3.1 to Appendix B.1. We start by showing that bounding the bracketing entropy implies a generalization bound in the realizable case:

**Proposition 3.2**.: _Suppose \((,)\) is a metric space, \(^{}\) is a function class, and let \(\) be a distribution over \(\) which is realizable by \(\), with marginal \(\) over \(\). Then with probability at least \(1-\) over drawing a sample \(S^{n}\) it holds that for all \(f:\)_

\[L_{}(f) 1.01L_{S}(f)+_{ 0}(+_{[}(,L_{1}(),)}{n})+\.\]

**Remark 3.3** (Constant is arbitrary).: _In Proposition 3.2 and in what follows, the constant multiplying \(L_{S}(f)\) is arbitrary, and can be replaced by \((1+)\) for any \(>0\) at the expense of multiplying the remaining summands by \(^{-1}\). In the next section we will provide a realizable regression algorithm that returns an approximate empirical risk minimizer \(f\) for which \(L_{S}(f) 0\), thus this constant will not matter for our purposes._

We prove Proposition 3.2 in Appendix B.2. By combining Theorem 3.1 with Proposition 3.2 and setting \(=/2\), we obtain the following realizable sample complexity result.

**Theorem 3.4**.: _For any metric space \((,)\), any \((0,1]\) and any \(0<<L\), let \(\) be a distribution over \(\) realizable by \(}}_{L}^{}(,)\). Then there exists \(N=N(,,)\) satisfying_

\[N=(_{}(( {256L(1/)})^{1/})+(1/)}{})\]

_such that as long as \(n N\), with probability at least \(1-\) over drawing a sample \(S^{n}\) it holds that for all \(f}}_{L}^{}(,):\)_

\[L_{}(f) 1.01L_{S}(f)+\.\]

_The same claim holds for the smaller class \(}}_{L}^{}(,)\)._

**Corollary 3.5** (Doubling metrics).: _In most cases of interest, \((,)\) is a doubling metric space of some dimension \(d\),3 e.g. when \(\) is a subset of \(^{d}\) (or more generally a \(d\)-dimensional Banach space). For \(d\)-dimensional doubling spaces of finite diameter we have \(_{}()()^{d}\)(Gottlieb et al., 2016; Lemma 2.1), which, plugged into Theorem 3.4, yields the simplified sample complexity bound_

\[N=(}{^{(d+)/}})\,\]

_or equivalently_

\[L_{}(f) 1.01L_{S}(f)+(}{ n^{/(d+)}})\,\]

_up to a constant which depends (exponentially) on \(d\), but is independent of \(L,n\)._

**Remark 3.6** (Tightness).: _The bounds in Theorem 3.1 and Theorem 3.4 are both tight up to logarithmic factors, as we will prove in Section 6._

## 4 Realizable learning algorithm

Recall that without knowing \(\), the underlying distribution over \(\), we cannot know for sure whether a function \(f\) belongs to \(}_{L}^{}(,)\) (except for the trivial case \(f_{L}^{}()\)). This gives rise to the challenge of designing a fully empirical algorithm -- since standard empirical risk minimization is not possible. To that end, we provide the following algorithmic result with optimal guarantees (up to logarithmic factors).

**Theorem 4.1**.: _For any metric space \((,)\), any \((0,1]\) and any \(0<<L\), let \(\) be a distribution over \(\) realizable by \(}_{L}^{}(,)\). Then there exists a polynomial time learning algorithm \(\), which, given a sample \(S^{n}\) of size \(n N\) for some \(N=N(,,)\) satisfying_

\[N=(_{}(( {256L(1/)})^{1/})+(1/)}{} ),\]

_constructs a hypothesis \(f=(S)\) such that \(L_{}(f)\) with probability at least \(1-\)._

**Remark 4.2** (Doubling metrics).: _As mentioned in Corollary 3.5, in most cases of interest we have \(_{}()()^{d}\). In that case, the algorithm above has sample complexity_

\[N=(}{^{(d+)/}})\,\]

_or equivalently_

\[L_{}(f)=(}{n^{/(d+ )}})\,\]

_up to a constant which depends (exponentially) on \(d\), but is independent of \(L,n\)._

**Remark 4.3** (Computational complexity).: _The algorithm constructed in Theorem 4.1 involves a one-time preprocessing step after which \(f(x)\) can be evaluated at any given \(x\) in \(O(n^{2})\) time. We note that the computation at inference time matches that of (classic) Lipschitz/Holder regression (e.g. Gottlieb et al., 2017). Furthermore, the computational complexity of the preprocessing step is similar to that in Ashlagi et al. (2021, Theorem 7) for the average Lipschitz case, where it is shown to run in time \((n^{2})\). The complexity analysis of our prepossessing step is entirely analogous to theirs, and we forgo repeating it here._

We will now outline the proof of Theorem 4.1, which appears in Appendix B.3. The key idea is to analyze a natural fully-empirical quantity that will serve as an estimator of the true unknown averagesmoothness. To that end, given a sample \(S=(X_{i},Y_{i})_{i=1}^{n}^{n}\) and a function \(f:\), consider the following quantity which can be established directly from the data:

\[_{f}^{}:=_{i=1}^{n}_{X_{j} X_{i}} )-f(X_{j})|}{(X_{i},X_{j})^{}}\;.\]

Namely, this is the empirical average smoothness with respect to the sampled points. It would suit us well if the empirical average smoothness of a function did not greatly exceed its true average smoothness, with high probability. The fact something like this turns out to be true is somewhat surprising and may be of independent interest:

**Proposition B.1**.: _(Informal) Let \(f^{*}:\). Then with high probability \(_{f^{*}}^{}_{f^{*}}^{}\;.\)_

The proposition above implies that restricting to the sample, and letting \((X_{i}):=Y_{i}\) yields a function over \(\{X_{1},,X_{n}\}\) which is empirically average-smooth over the sample (with high probability). We then turn to show that any such function can be approximately extended to the whole space, in a way that guarantees its average smoothness with respect to the _underlying distribution_.

**Proposition B.3**.: _(Informal) Let \(:\{X_{1},,X_{n}\}\) where \((X_{i})_{i=1}^{n}^{n}\). Then it is possible to construct \(f:\) such that with high probability \(f(X_{i})(X_{i})\) for all \(i[N]\), and \(_{f}^{}()_{}^{}\)._

We will now sketch the procedure described in Proposition B.3, which serves as the main challenge in proving Theorem 4.1. Roughly speaking, the algorithm sorts the sampled points with respect to their relative slope to one another. Then, it discards a fraction of the sampled points with largest relative slope, which can be thought of as "outliers". Then, the algorithm proceeds to extend the function in a smooth fashion among the remaining "well-behaved" samples. A careful probabilistic analysis shows that disregarding just the right amount of samples induces small error, while being average-smooth with high probability.

Overall this procedure yields a function \(f:\) which is an approximate empirical-minimizer (since \(f(X_{i})(X_{i})=Y_{i}\)), while guaranteed to be averagely-smooth with respect to the unknown distribution. Thus we can apply the uniform convergence of Theorem 3.4, proving Theorem 4.1.

## 5 Agnostic learning algorithm

Noticeably, up to this point, both the uniform convergence result we derived (Theorem 3.4) as well as the algorithmic result (Theorem 4.1) are tailored for the realizable regression setting. Inspired by a recent result of Hopkins et al. (2022) that showed a reduction from agnostic learning to realizable learning, we provide an algorithm for agnostic (i.e. noisy) regression of average-smooth functions. It is worth noting that the following algorithm does not require any prior assumption on the noise model, unlike many nonparametric regression methods, due to our distribution free analysis.

**Theorem 5.1**.: _There exists a learning algorithm \(\) such that for any metric space \((,)\), any \((0,1],\;0<<L\), and any distribution \(\) over \(\), given a sample \(S^{n}\) of size \(n N\) for some \(N=N(,,)\) satisfying_

\[N=(_{}(()^{1/})+(1/)}{^ {2}}),\]

_the algorithm constructs a hypothesis \(f=(S)\) such that \(L_{}(f)_{f^{*}}_{L}^{}(,)}L_{}(f^{*})+\) with probability at least \(1-\)._

**Remark 5.2** (Doubling metrics).: _As mentioned in Corollary 3.5, in most cases of interest we have \(_{}()()^{d}\). In that case, the algorithm above has sample complexity_

\[N=(}{^{(d+2)/}} )\;,\]_or equivalently_

\[L_{}(f)=_{f^{*}}^{}_{L}(,)}L _{}(f^{*})+(}{n^{/(d+2 )}})\,\]

_up to a constant which depends (exponentially) on \(d\), but is independent of \(L,n\)._

Though our agnostic algorithm is similar in spirit to that obtained by the reduction of Hopkins et al. (2022), our analysis is self-contained and crucially relies on the bracketing bound given by Theorem 3.1, as well as analyzing the empirical smoothness estimator as provided by Proposition B.1. We also note that unlike our algorithm for realizable learning, the agnostic algorithm is not computationally efficient. This seems to be inherent for such reductions, and we do not know whether this blow-up in running time can be avoided or not.

We will now describe the proof of Theorem 5.1 which appears in Appendix B.4. Given a sample \(S\) of size \(n\), consider dividing it into two sub-samples \(S_{1} S_{2}=S\) of size \(n/2\) each. We first use \(S_{1}\) in order to construct an empirical \(\)-net \(h_{1},,h_{N}:S_{1}\), namely a set of functions which are sufficiently empirically smooth over the sample, yet far away enough from one another when averaged over the sample. Recalling that bracketing numbers upper bound covering numbers (Eq. (1)), and since Theorem 3.1 holds true for every measure (in particular for the empirical measure), we can bound \( N_{}((/L)^{1/})\). Moreover, using Proposition B.1 we know that \(f^{*}:=_{f}^{}_{L}(,)}L_{ }(f)\) is likely to be \((L)\) average-smooth over \(S_{1}\), so there must exist some \(h_{j}\) with \(\) excess empirical loss (since \(f^{*}\) is in the class we are \(\)-covering). Thus running the realizable algorithm of Theorem 4.1 over all \(\{h_{1},,h_{N}\}\), producing \(f_{1},,f_{N}:\), yields at least one function which has both small excess empirical error, while being smooth with respect to the underlying distribution. Finally, running ERM over \(\{f_{1},,f_{N}\}\) with respect to the fresh sample \(S_{2}\) reveals such a good candidate function within \(}\) samples by applying standard uniform convergence for finite classes (i.e. Hoeffding's inequality with the union bound).

## 6 Lower bound

We now turn to show that the bounds proved in Theorem 3.1, Theorem 3.4 and Theorem 4.1 are all tight up to logarithmic factors. In fact, since the bracketing entropy bound of Theorem 3.1 implies the generalization bound of Theorem 3.4 and the latter implies the sample complexity in Theorem 4.1, it is enough to show that the latter is nearly optimal.

**Theorem 6.1**.: _For any \((0,1],\;(0,1)\) any metric space \((,)\) and \(L()}\), there exists a distribution \(\) over \(\) which is realizable by \(}^{}_{L}()\) such that any learning algorithm that produces \(f=A(S)\) with \(L_{}(f)\) with constant probability, must have sample complexity_

\[n=(_{}((/L)^{1/})}{ })\.\]

**Remark 6.2** (Typical case).: _In most cases of interest it holds that \(_{}()()^{d}\) for some constant \(d\), e.g. when \(\) is a subset of non-empty interior in \(^{d}\) (or more generally in any \(d\)-dimensional Banach space).4 That being the case, Theorem 6.1 yields the simplified sample complexity lower bound of_

\[n=(}{^{(d+)/}})\]

_Equivalently, we obtain an excess risk lower bound of_

\[L_{}(f)=(}{n^{/(d+)}} )\.\]

We will now provide a proof sketch of Theorem 6.1, while the full proof appears in Appendix B.5. Suppose \(K\) is a \((/L)^{1/}\)-net of _most_ of \(\), yet \(x_{0}\) is some "isolated" point at constant distance away from \(K\) (we show that such \(x_{0},K\) always exist). Let \(\) be the measure that assigns \(1-\) probability mass to \(x_{0}\), while the rest of the probability mass is distributed uniformly over \(K\). Now consider a (random) function that independently assigns either \(0\) or \(1\) to each point in \(K\) uniformly, and is constant over \(x_{0}\). Since points in \(K\) are \((/L)^{1/}\) away from one another, the local \(\)-slope at each point in \(K\) is roughly \(1/((/L)^{1/})^{}=L/\), while the slope at \(x_{0}\) is small since it is far enough from other points. Averaging over the space with respect to \(\), we see that the function is \((K) L/=L\) average-Holder. Now, we imitate the standard lower bound proof for VC classes over \(K\): Since any point in \(K\) is sampled with probability \(/|K|\), any learning algorithm with much fewer than \(|K|/_{}((/L)^{1/})/\) examples will guess wrong a large portion of \(K\), suffering \(L_{1}\)-loss of at least order of \((K)=\).

## 7 Illustrative examples

Having established the control that average-Holder smoothness has on generalization, we illustrate the vast possible gap between the average smoothness and it's "worst-case" classic counterpart. Indeed, in the examples we provide, the gap is infinite. Moreover, we also show that classes of average-Holder smoothness are significantly richer than the previously studied average-Lipschitz, motivating the more general Holder framework considered in this work. Finally, it is illuminating to notice that both claims to follow actually consist of the same simple function \(f(x)=[x>]\) though with respect to different distributions, emphasizing the crucial role of the underlying distribution in terms of establishing the function classes.

**Claim 7.1**.: _For any \(L>0,(0,1)\), there exist \(f:\) and a probability measure \(\) such that_

* \(f\) _is average-Holder:_ \(fl}}^{}_{L}(,)\) _._
* \(f\) _is not Holder with any finite Holder constant: For all_ \(M>0:\ fl}^{}_{M}()\) _._
* \(f\) _is not (even) weakly-average-Lipschitz with any finite modulus: For all_ \(M>0:f}_{M}(,)\) _._

_Thus, \(l}}^{}_{L}(,)_{M= 0}^{}l}^{}_{M}()}_{M}(,)\)._

**Claim 7.2**.: _For any \(L>0,(0,1)\), there exist \(f:\) and a probability measure \(\) such that_

* \(f\) _is weakly-average-Holder:_ \(fl}}^{}_{L}(,)\) _._
* \(f\) _is not strongly-average-Holder with any finite modulus: For all_ \(M>0:\ fl}}^{}_{M}()\) _._
* \(f\) _is not (even) weakly-average-Lipschitz with any finite modulus: For all_ \(M>0:f}_{M}(,)\) _._

_Thus, \(l}}^{}_{L}(,)_{M= 0}^{}l}}^{}_{M}(,) }_{M}(,)\)._

We prove both of the claims above in Appendix B.6.

## 8 Discussion

In this work, we have defined a notion of an average-Holder smoothness, extending the average-Lipschitz one introduced by Ashlagi et al. (2021). Using proof techniques based on bracketing numbers, we have established the minimax rate for average-smoothness classes in the realizable setting with respect to the \(L_{1}\) risk up to logarithmic factors, and have provided a nontrivial learning algorithm that attains this nearly-optimal learning rate. Moreover, we have also provided yet another learning algorithm for the agnostic setting. All of these results improve upon previously known rates even in the special case of average-Lipschitz classes.

A few notes are in order. First, the choice of focusing on \(L_{1}\) risk as opposed to general \(L_{p}\) losses is merely a matter of conciseness, as to avoid introducing additional parameters. Indeed, the only place throughout the proofs which we use the \(L_{1}\) loss is in the proof of Proposition 3.2, where we show that the loss-class \(_{}:=\{x|f(x)-f^{*}(x)|:f\}\) satisfies

\[_{[}(_{},L_{1}(),) _{[}(,L_{1}(),)\;.\]

It is easy to show via essentially the same proof that for any \(p[1,)\), the \(L_{p}\)-composed loss-class satisfies \(_{[}(_{},L_{1}(),) _{[}(,L_{1}(),^{1/p})\), and the remaining proofs can be invoked verbatim. This yields a realizable sample complexity (in the typical, \(d\)-dimensional case) of order \(N=(}{^{(d+p)/p}})\), or equivalently \(L_{p}\)-risk decay rate of \(L_{}(f)=(}{n^{p/(d+p )}})\) which are also easily translatable to their corresponding agnostic rates.

Focusing again on \(L_{1}\) minimax rates of average-Holder classes, it is interesting to compare them to the minimax rates of "classic" (i.e., worst-case) Holder classes. Schreuder (2020) has shown the minimax risk to be of order \(n^{-/d}\), whereas we showed the average-smooth case has the slightly worse rate of \(n^{-/(d+)}\) (which cannot be improved, due to our matching lower bound). However, comparing the rates alone is rather misleading, since both risks are multiplied by a factor depending on their corresponding Holder constant, which can be considerably smaller in the average-case result. Still, it is interesting to note that in the asymptotic regime there is a marginal advantage in case the learned function is worst-case Holder, as opposed to Holder on average.

Our work leaves open several questions. A relatively straightforward one is to compute the minimax rates and construct an optimal algorithm for the _classification_ setting, which is not addressed by this paper. Moreover, there is a slight mismatch between our established upper and lower bounds in the agnostic setting, ranging between \((n^{-/(d+2)})\) and \((n^{-/(d+)})\). Closing this gap is an interesting problem which we leave for future work.