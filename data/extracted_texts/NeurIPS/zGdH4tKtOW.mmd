# Optimal Treatment Regimes for Proximal

Causal Learning

 Tao Shen

National University of Singapore

&Yifan Cui

Zhejiang University

Correspondence to Yifan Cui <cuiyf@zju.edu.cn>

###### Abstract

A common concern when a policymaker draws causal inferences from and makes decisions based on observational data is that the measured covariates are insufficiently rich to account for all sources of confounding, i.e., the standard no confoundedness assumption fails to hold. The recently proposed proximal causal inference framework shows that proxy variables that abound in real-life scenarios can be leveraged to identify causal effects and therefore facilitate decision-making. Building upon this line of work, we propose a novel optimal individualized treatment regime based on so-called outcome and treatment confounding bridges. We then show that the value function of this new optimal treatment regime is superior to that of existing ones in the literature. Theoretical guarantees, including identification, superiority, excess value bound, and consistency of the estimated regime, are established. Furthermore, we demonstrate the proposed optimal regime via numerical experiments and a real data application.

## 1 Introduction

Data-driven individualized decision-making has received tremendous attention nowadays due to its applications in healthcare, economics, marketing, etc. A large branch of work has focused on maximizing the expected utility of implementing the estimated optimal policy over a target population based on randomized controlled trials or observational studies, e.g., Athey and Wager (2021); Chakraborty and Moodie (2013); Jiang et al. (2019); Kitagawa and Tetenov (2018); Kosorok and Laber (2019); Murphy (2003); Qian and Murphy (2011); Robins (1986, 1994, 1997); Tsiatis et al. (2019); Wu et al. (2019); Zhao et al. (2012, 2019).

A critical assumption commonly made in these studies, known as unconfoundedness or exchangeability, precludes the existence of unmeasured confounding. Relying on an assumed ability of the decision-maker to accurately measure covariates relevant to a variety of confounding mechanisms present in a given observational study, causal effects, value functions, and other relevant quantities can be nonparametrically identified. However, such an assumption might not always be realistic in observational studies or randomized trials subject to non-compliance (Robins, 1994, 1997). Therefore, it is of great interest in recovering confounding mechanisms from measured covariates to infer causal effects and facilitate decision-making. A prevailing strand of work has been devoted to using instrumental variable (Angrist et al., 1996; Imbens and Angrist, 1994) as a proxy variable in dynamic treatment regimes and reinforcement learning settings (Cui, 2021; Cui and Tchetgen Tchetgen, 2021b, a; Han, 2023; Liao et al., 2021; Pu and Zhang, 2021; Qiu et al., 2021; Stensrud and Sarvet, 2022).

Recently, Tchetgen Tchetgen et al. proposed the so-called proximal causal inference framework, a formal potential outcome framework for proximal causal learning, which while explicitly acknowledging covariate measurements as imperfect proxies of confounding mechanisms, establishes causalidentification in settings where exchangeability on the basis of measured covariates fails. Rather than as current practice dictates, assuming that adjusting for all measured covariates, unconfoundedness can be attained, proximal causal inference essentially requires that the investigator can correctly classify a subset of measured covariates \(L\) into three types: i) variables \(X\) that may be common causes of the treatment and outcome variables; ii) treatment-inducing confounding proxies \(Z\); and iii) outcome-inducing confounding proxies \(W\).

There is a fast-growing literature on proximal causal inference since it has been proposed (Cui et al., 2023; Dukes et al., 2023; Ghassami et al., 2023; Kompa et al., 2022; Li et al., 2023; Mastouri et al., 2021; Miao et al., 2018; Shi et al., 2020, 2021; Shpitser et al., 2023; Singh, 2020; Tchetgen Tchetgen et al., 2020; Ying et al., 2023, 2022 and many others). In particular, Miao et al. (2018); Tchetgen Tchetgen et al. (2020) propose identification of causal effects through an outcome confounding bridge and Cui (2023) propose identification through a treatment confounding bridge. A doubly robust estimation strategy (Chernozhukov et al., 2018; Robins et al., 1994; Rotnitzky et al., 1998; Scharfstein et al., 1999) is further proposed in Cui et al. (2023). In addition, Ghassami et al. (2022) and Kallus et al. (2021) propose a nonparametric estimation of causal effects through a min-max approach. Moreover, by adopting the proximal causal inference framework, Qi et al. (2023) consider optimal individualized treatment regimes (ITRs) estimation, Sverdrup and Cui (2023) consider learning heterogeneous treatment effects, and Bennett and Kallus (2023) consider off-policy evaluation in partially observed Markov decision processes.

In this paper, we aim to estimate optimal ITRs under the framework of proximal causal inference. We start with reviewing two in-class ITRs that map from \(\) to \(\) and \(\) to \(\), respectively, where \(\) denotes the binary treatment space. The identification of value function and the learning strategy for these two optimal in-class ITRs are proposed in Qi et al. (2023). In addition, Qi et al. (2023) also consider a maximum proximal learning optimal ITR that maps from \(\) to \(\) with the ITRs being restricted to either \(\) or \(\). In contrast to their maximum proximal learning ITR, in this paper, we propose a brand new policy class whose ITRs map from measured covariates \(\) to \(\), which incorporates the predilection between these two in-class ITRs. Identification and superiority of the proposed optimal ITRs compared to existing ones are further established.

The main contributions of our work are four-fold. Firstly, by leveraging treatment and outcome confounding bridges under the recently proposed proximal causal inference framework, identification results regarding the proposed class \(^{}_{}\) of ITRs that map \(\) to \(\) are established. The proposed ITR class can be viewed as a generalization of existing ITR classes proposed in the literature. Secondly, an optimal subclass of \(^{}_{}\) is further introduced. Learning optimal treatment regimes within this subclass leads to a superior value function. Thirdly, we propose a learning approach to estimating the proposed optimal ITR. Our learning pipeline begins with the estimation of confounding bridges adopting the deep neural network method proposed by Kompa et al. (2022). Then we use optimal treatment regimes proposed in Qi et al. (2023) as preliminary regimes to estimate our optimal ITR. Lastly, we establish an excess value bound for the value difference between the estimated treatment regime and existing ones in the literature, and the consistency of the estimated regime is also demonstrated.

## 2 Methodology

### Optimal individualized treatment regimes

We briefly introduce some conventional notation for learning optimal ITRs. Suppose \(A\) is a binary variable representing a treatment option that takes values in the treatment space \(=\{-1,1\}\). Let \(L\) be a vector of observed covariates, and \(Y\) be the outcome of interest. Let \(Y(1)\) and \(Y(-1)\) be the potential outcomes under an intervention that sets the treatment to values \(1\) and \(-1\), respectively. Without loss of generality, we assume that larger values of \(Y\) are preferred.

Suppose the following standard causal assumptions hold: (1) Consistency: \(Y=Y(A)\). That is, the observed outcome matches the potential outcome under the realized treatment. (2) Positivity: \((A=a|L)>0\) for \(a\) almost surely, i.e., both treatments are possible to be assigned.

We consider an ITR class \(\) containing ITRs that are measurable functions mapping from the covariate space \(\) onto the treatment space \(\). For any \(d\), the potential outcome under a hypothetical intervention that assigns treatment according to \(d\) is defined as

\[Y(d(L))}{{=}}Y(1)\{d(L)=1\}+Y(-1) \{d(L)=-1\},\]

where \(\{\}\) denotes the indicator function. The value function of ITR \(d\) is defined as the expectation of the potential outcome, i.e.,

\[V(d)}{{=}}[Y(d(L))].\]

It can be easily seen that an optimal ITR can be expressed as

\[d^{*}(L)=\{(Y(1)-Y(-1)|L)\}\]

or

\[d^{*}=_{d}[Y(d(L))].\]

There are many ways to identify optimal ITRs under different sets of assumptions. The most commonly seen assumption is the unconfoundedness: \(Y(a) A|L\) for \(a= 1\), i.e., upon conditioning on \(L\), there is no unmeasured confounder affecting both \(A\) and \(Y\). Under this unconfoundedness assumption, the value function of a given regime \(d\) can be identified by (Qian and Murphy, 2011)

\[V(d)=[\{A=d(L)\}}{f(A|L)}],\]

where \(f(A|L)\) denotes the propensity score (Rosenbaum and Rubin, 1983), and the optimal ITR is identified by

\[d^{*}=_{d}V(d)=_{d}[ \{A=d(L)\}}{f(A|L)}].\]

We refer to Qian and Murphy (2011); Zhang et al. (2012); Zhao et al. (2012) for more details of learning optimal ITRs in this unconfounded setting.

Because confounding by unmeasured factors cannot generally be ruled out with certainty in observational studies or randomized experiments subject to non-compliance, skepticism about the unconfoundedness assumption in observational studies is often warranted. To estimate optimal ITRs subject to potential unmeasured confounding, Cui and Tchetgen Tchetgen (2021b) propose instrumental variable approaches to learning optimal ITRs. Under certain instrumental variable assumptions, the optimal ITR can be identified by

\[_{d}[\{A=d(L)\}}{\{ (A=1|M=1,L)-(A=1|M=-1,L)\}f(M|L)}],\]

where \(M\) denotes a valid binary instrumental variable. Other works including Cui (2021); Cui and Tchetgen Tchetgen (2021a); Han (2023); Pu and Zhang (2021) consider a sign or partial identification of causal effects to estimate suboptimal ITRs using instrumental variables.

### Existing optimal ITRs for proximal causal inference

Another line of research in causal inference considers negative control variables as proxies to mitigate confounding bias (Kuroki and Pearl, 2014; Miao et al., 2018; Shi et al., 2020; Tchetgen Tchetgen, 2014). Recently, a formal potential outcome framework, namely proximal causal inference, has been developed by Tchetgen Tchetgen et al. (2020), which has attracted tremendous attention since proposed.

Following the proximal causal inference framework proposed in Tchetgen Tchetgen et al. (2020), suppose that the measured covariate \(L\) can be decomposed into three buckets \(L=(X,W,Z)\), where \(X\) affects both \(A\) and \(Y\), \(W\) denotes an outcome-inducing confounding proxy that is a potential cause of the outcome which is related with the treatment only through \((U,X)\), and \(Z\) is a treatment-inducing confounding proxy that is a potential cause of the treatment which is related with the outcome \(Y\) through \((U,X,A)\). We now summarize several basic assumptions of the proximal causal inference framework.

**Assumption 1**.: _We make the following assumptions: (1) Consistency: \(Y=Y(A,Z),\;W=W(A,Z)\). (2) Positivity: \((A=a U,X)>0,\; a\). (3) Latent unconfoundedness: \((Z,A)(Y(a),W) U,X,\; a\)._

The consistency and positivity assumptions are conventional in the causal inference literature. The latent unconfoundedness essentially states that \(Z\) cannot directly affect the outcome \(Y\), and \(W\) is not directly affected by either \(A\) or \(Z\). Figure 1 depicts a classical setting that satisfies Assumption 1. We refer to Shi et al. (2020); Tchetgen Tchetgen et al. (2020) for other realistic settings for proximal causal inference.

We first consider two in-class optimal ITRs that map from \(\) to \(\) and \(\) to \(\), respectively. To identify optimal ITRs that map from \(\) to \(\), we make the following assumptions.

**Assumption 2**.: _Completeness: For any \(a,x\) and square-integrable function \(g\), \([g(U) Z,A=a,X=x]=0\) almost surely if and only if \(g(U)=0\) almost surely._

**Assumption 3**.: _Existence of outcome confounding bridge: There exists an outcome confounding bridge function \(h(w,a,x)\) that solves the following equation_

\[[Y|Z,A,X]=[h(W,A,X)|Z,A,X],\]

_almost surely._

The completeness Assumption 2 is a technical condition central to the study of sufficiency in foundational theory of statistical inference. It essentially assumes that \(Z\) has sufficient variability with respect to the variability of \(U\). We refer to Tchetgen Tchetgen et al. (2020) and Miao et al. (2022) for further discussions regarding the completeness condition. Assumption 3 defines a so-called inverse problem known as a Fredholm integral equation of the first kind through an outcome confounding bridge. The technical conditions for the existence of a solution to a Fredholm integral equation can be found in Kress et al. (1989).

Let \(_{}\) be an ITR class that includes all measurable functions mapping from \(\) to \(\). As shown in Qi et al. (2023), under Assumptions 1, 2 and 3, for any \(d_{z}_{}\), the value function \(V(d_{z})\) can be nonparametrically identified by

\[V(d_{z})=[h(W,d_{z}(X,Z),X)].\] (1)

Furthermore, the in-class optimal treatment regime \(d_{z}^{*}_{d_{z}_{}}V(d_{z})\) is given by

\[d_{z}^{*}(X,Z)=\{[h(W,1,X)-h(W,-1,X)|X,Z]\}.\]

On the other hand, to identify optimal ITRs that map from \(\) to \(\), we make the following assumptions.

**Assumption 4**.: _Completeness: For any \(a,x\) and square-integrable function \(g\), \([g(U) W,A=a,X=x]=0\) almost surely if and only if \(g(U)=0\) almost surely._

**Assumption 5**.: _Existence of treatment confounding bridge: There exists a treatment confounding bridge function \(q(z,a,x)\) that solves the following equation_

\[(A=a|W,X)}=[q(Z,a,X)|W,A=a,X],\]

_almost surely._

Figure 1: A causal DAG under the proximal causal inference framework.

Similar to Assumptions 2 and 3, Assumption 4 assumes that \(W\) has sufficient variability relative to the variability of \(U\), and Assumption 5 defines another Fredholm integral equation of the first kind through a treatment confounding bridge \(q\).

Let \(_{}\) be another ITR class that includes all measurable functions mapping from \(\) to \(\). As shown in Qi et al. (2023), under Assumptions 1, 4 and 5, for any \(d_{w}_{}\), the value function \(V(d_{w})\) can be nonparametrically identified by

\[V(d_{w})=[Yq(Z,A,X)\{d_{w}(X,W)=A\}].\] (2)

The in-class optimal treatment regime \(d_{w}^{*}_{d_{w}_{}}V(d_{w})\) is given by

\[d_{w}^{*}(X,W)=\{[Yq(Z,1,X)\{A=1\}-Yq(Z,-1,X) \{A=-1\}|X,W]\}.\]

Moreover, Qi et al. (2023) consider the ITR class \(_{}_{}\) and propose a maximum proximal learning optimal regime based on this ITR class. For any \(d_{z w}_{}_{}\), under Assumptions 1-5, the value function \(V(d_{z w})\) for any \(d_{z w}_{}_{}\) can be identified by

\[V(d_{z w})=\{d_{z w}_{}\}[h(W,d_{z w}(X,Z),X)]+\{d_{z w}_{} \}[Yq(Z,A,X)\{d_{z w}(X,W)=A\}].\] (3)

The optimal ITR within this class is given by \(d_{z w}^{*}_{d_{z w}_{} _{}}V(d_{z w})\), and they show that the corresponding optimal value function takes the maximum value between two optimal in-class ITRs, i.e.,

\[V(d_{z w}^{*})=\{V(d_{z}^{*}),V(d_{w}^{*})\}.\]

### Optimal decision-making based on two confounding bridges

As discussed in the previous section, given that neither \([Y(a)|X,U]\) nor \([Y(a)|X,W,Z]\) for any \(a\) may be identifiable under the proximal causal inference setting, one might nevertheless consider ITRs mapping from \(\) to \(\), from \(\) to \(\), from \(\) to \(\) as well as from \(\) to \(\). Intuitively, policy-makers might want to use as much information as they can to facilitate their decision-making. Therefore, ITRs mapping from \(\) to \(\) are of great interest if information regarding \((X,W,Z)\) is available.

As a result, a natural question arises: is there an ITR mapping from \(\) to \(\) which dominates existing ITRs proposed in the literature? In this section, we answer this question by proposing a novel optimal ITR and showing its superiority in terms of global welfare.

We first consider the following class of ITRs that map from \(\) to \(\),

\[_{}^{}}{{=} }\{d_{zw}^{*}:d_{zw}^{*}(X,W,Z)=(X)d_{z}(X,Z)+(1-(X))d_{w}(X,W),d_{z} _{},d_{w}_{},\},\]

where \(\) is the policy class containing all measurable functions \(:\{0,1\}\) that indicate the individualized predicletion between \(d_{z}\) and \(d_{w}\).

**Remark 1**.: _Note that \(_{},_{}\) and \(_{}_{}\) are subsets of \(_{}^{}\) with a particular choice of \(\). For example, \(_{}\) is \(_{}^{}\) with restriction on \((X)=1\); \(_{}\) is \(_{}^{}\) with restriction on \((X)=0\); \(_{}_{}\) is \(_{}^{}\) with restriction on \((X)=1\) or \((X)=0\)._

In the following theorem, we demonstrate that by leveraging the treatment and outcome confounding bridge functions, we can nonparametrically identify the value function over the policy class \(_{}^{}\), i.e., \(V(d_{zw}^{})\) for \(d_{zw}^{}_{}^{}\).

**Theorem 1**.: _Under Assumptions 1-5, for any \(d_{zw}^{}_{}^{}\), the value function \(V(d_{zw}^{})\) can be nonparametrically identified by_

\[V(d_{zw}^{})=[(X)h(W,d_{z}(X,Z),X)+(1-(X))Yq(Z,A,X)\{d_{w}(X,W)=A\}].\] (4)

One of the key ingredients of our constructed new policy class \(_{}^{}\) is the choice of \(()\). It suggests an individualized strategy for treatment decisions between the two given treatment regimes. Because we are interested in policy learning, a suitable choice of \(()\) that leads to a larger value function is more desirable. Therefore, we construct the following \((X;d_{z},d_{w})\),

\[(X;d_{z},d_{w})}{{=}}\{ [h(W,d_{z}(X,Z),X)|X][Yq(Z,A,X)\{d_{w}(X,W)=A \}|X]\}.\] (5)In addition, given any \(d_{z}_{}\) and \(d_{w}_{}\), we define

\[d_{zw}^{}(X,W,Z)}{{=}}(X;d_{z },d_{w})d_{z}(X,Z)+(1-(X;d_{z},d_{w}))d_{w}(X,W).\]

We then obtain the following result which justifies the superiority of \(\).

**Theorem 2**.: _Under Assumptions 1-5, for any \(d_{z}_{}\) and \(d_{w}_{}\),_

\[V(d_{zw}^{})\{V(d_{z}),V(d_{w})\}.\]

Theorem 2 establishes that for the particular choice of \(\) given in (5), the value function of \(d_{zw}^{}\) is no smaller than that of \(d_{z}\) and \(d_{w}\) for any \(d_{z}_{}\), and \(d_{w}_{}\). Consequently, Theorem 2 holds for \(d_{z}^{*}\) and \(d_{w}^{*}\). Hence, we propose the following optimal ITR \(d_{zw}^{*}\),

\[d_{zw}^{*}(X,W,Z)}{{=}}(X;d _{z}^{*},d_{w}^{*})d_{z}^{*}(X,Z)+(1-(X;d_{z}^{*},d_{w}^{*}))d_{w}^{*}( X,W),\]

and we have the following corollary.

**Corollary 1**.: _Under Assumptions 1-5, we have that_

\[V(d_{zw}^{*})\{V(d_{z}^{*}),V(d_{w}^{*}),V(d_{z w}^{*})\}.\]

Corollary 1 essentially states that the value of \(d_{zw}^{*}\) dominates that of \(d_{z}^{*}\), \(d_{w}^{*}\), as well as \(d_{z w}^{*}\). Moreover, the proposition below demonstrates the optimality of \(d_{zw}^{*}\) within the proposed class.

**Proposition 1**.: _Under Assumptions 1-5, we have that_

\[d_{zw}^{*}_{d_{zw}^{*}_{ }^{*}}V(d_{zw}^{*}).\]

Therefore, \(d_{zw}^{*}\) is an optimal ITR of policymakers' interest.

## 3 Statistical Learning and Optimization

### Estimation of the optimal ITR \(d_{zw}^{*}\)

The estimation of \(d_{zw}^{*}\) consists of four steps: (i) estimation of confounding bridges \(h\) and \(q\); (ii) estimation of preliminary ITRs \(d_{z}^{*}\) and \(d_{w}^{*}\); (iii) estimation of \((X;d_{z}^{*},d_{w}^{*})\); and (iv) learning \(d_{zw}^{*}\) based on (ii) and (iii). The estimation problem (i) has been developed by Cui et al. (2023); Miao et al. (2018) using the generalized method of moments, Ghassami et al. (2022); Kallus et al. (2021) by a min-max estimation (Dikkala et al., 2020) using kernels, and Kompa et al. (2022) using deep learning; and (ii) has been developed by Qi et al. (2023). We restate estimation of (i) and (ii) for completeness. With regard to (i), recall that Assumptions 3 and 5 imply the following conditional moment restrictions

\[[Y-h(W,A,X)|Z,A,X]= 0,\] \[[1-\{A=a\}q(Z,a,X)|W,X]= 0, a.\]

respectively. Kompa et al. (2022) propose a deep neural network approach to estimating bridge functions which avoids the reliance on kernel methods. We adopt this approach in our simulation and details can be found in the Appendix.

To estimate \(d_{z}^{*}\), we consider classification-based approaches according to Zhang et al. (2012); Zhao et al. (2012). Under Assumptions 1, 2 and 3, maximizing the value function in (1) is equivalent to minimizing the following classification error

\[[\{h(W,1,X)-h(W,-1,X)\}\{d_{z}(X,Z) 1\}]\] (6)

over \(d_{z}_{}\). By choosing some measurable decision function \(g_{z}_{}:\), we let \(d_{z}(X,Z)=(g_{z}(X,Z))\). We consider the following empirical version of (6),

\[_{g_{z}_{z}}_{n}[\{(W,1,X)-(W,-1,X) \}\{g_{z}(X,Z)<0\}].\]Due to the non-convexity and non-smoothness of the sign operator, we replace the sign operator with a smooth surrogate function and adopt the hinge loss \((x)=\{1-x,0\}\). By adding a penalty term \(_{z}||g_{z}||^{2}_{_{Z}}\) to avoid overfitting, we solve

\[_{z}_{g_{z}_{z}}_{n}[\{(W,1,X) -(W,-1,X)\}(g_{z}(X,Z))]+_{z}||g_{z}||^{2}_{_{Z}},\] (7)

where \(_{z}>0\) is a tuning parameter. The estimated ITR then follows \(_{z}(X,Z)=(_{z}(X,Z))\). Similarly, under Assumptions 1, 4 and 5, maximizing the value function in (2) is equivalent to minimizing the following classification error

\[[\{Yq(Z,1,X)\{A=1\}-Yq(Z,-1,X)\{A=-1\}\}\{d_{w}(X,W) 1\}]\]

over \(d_{w}_{}\). By the same token, the problem is transformed into minimizing the following empirical error

\[_{w}_{g_{w}_{}}_{n}[\{Y (Z,1,X)\{A=1\}-Y(Z,-1,X)\{A=-1\}\}(g_{w} (X,W))]+_{w}||g_{w}||^{2}_{_{}}.\] (8)

The estimated ITR is obtained via \(_{w}(X,W)=(_{w}(X,W))\).

For problem (iii), given two preliminary ITRs, we construct an estimator \((X;_{z},_{w})\), that is, for \(x\),

\[(x;_{z},_{w})=\{(x;_{z}, _{w}) 0\},\]

where \((x;_{z},_{w})\) denotes a generic estimator of

\[(x;_{z},_{w})}{{=}} [h(W,_{z}(X,Z),X)-Yq(Z,A,X)\{_{w}(X,W)=A\}|X =x],\]

where the expectation is taken with respect to everything except \(_{z}\) and \(_{w}\). For example, the Nadaraya-Watson kernel regression estimator (Nadaraya, 1964) can be used, i.e., \((x;_{z},_{w})\) is expressed as

\[^{n}\{(W_{i},_{z}(x,Z_{i}),x)-Y_{i}(Z_{i},A_{i},x)\{_{w}(x,W_{i})=A_{i}\}\}K(||_{2}}{ })}{_{i=1}^{n}K(||_{2}}{})},\]

where \(K:\) is a kernel function such as Gaussian kernel, \(||||_{2}\) denotes the \(L_{2}\)-norm, and \(\) denotes the bandwidth.

Finally, given \(_{z},_{w}\) and \((X;_{z},_{w})\), \(_{zw}^{}\) is estimated by the following plug-in regime,

\[_{zw}^{}(X,W,Z)=(X;_{z},_{w})_ {z}(X,Z)+(1-(X;_{z},_{w}))_{w}(X,W).\] (9)

### Theoretical guarantees for \(_{zw}^{}\)

In this subsection, we first present an optimality guarantee for the estimated ITR \(_{zw}^{}\) in terms of its value function

\[V(_{zw}^{})=[(X;_{z},_{w})h(W,_{z}(X,Z),X)+(1-(X;_{z},_{w}))Yq(Z,A,X)\{_{w}(X,W)=A\}],\]

where the expectation is taken with respect to everything except \(\), \(_{z}\) and \(_{w}\).

We define an oracle optimal ITR which assumes \((X;_{z},_{w})\) is known,

\[_{zw}^{}(X,W,Z)}{{=}}(X;_{z},_{w})_{z}(X,Z)+(1-(X;_{z},_{w}))_{w}(X,W).\]

The corresponding value function of this oracle optimal ITR is given by

\[V(_{zw}^{})=[(X;_{z},_{w})h(W,_{z}(X,Z),X)+(1-(X;_{z},_{w}))Yq(Z,A,X)\{_{w}(X,W)=A\}],\]

where the expectation is taken with respect to everything except \(_{z}\) and \(_{w}\).

Then the approximation error incurred by estimating \((X;_{z},_{w})\) is given by

\[()}{{=}}V(_{zw}^{ })-V(_{zw}^{}).\]

Moreover, we define the following gain

\[()}{{=}}\{V(_{ zw}^{})-V(_{z}),V(_{zw}^{})-V(_{w})\}.\]

It is clear that this gain \(()\) by introducing \(\) is always non-negative as indicated by Theorem 2. Then we have the following excess value bound for the value of \(_{zw}^{}\) compared to existing ones in the literature.

**Proposition 2**.: _Under Assumptions 1-5,_

\[V(_{zw}^{})=\{V(_{z}),V(_{w})\}-( )+()=V(_{z w})-()+ ().\]

Proposition 2 establishes a link between the value function of the estimated ITR \(_{zw}^{}\), and that of \(_{z}\), \(_{w}\), and \(_{z w}\). As shown in Appendix G, \(()\) diminishes as the sample size increases, therefore, \(_{zw}^{}\) has a significant improvement compared to other optimal ITRs depending on the magnitude of \(()\).

Furthermore, we establish the consistency of the proposed regime based on the following assumption, which holds for example when \(_{z}\) and \(_{w}\) are estimated using indirect methods.

**Assumption 6**.: _For \(_{z},_{w}\), \(E[h(W,_{z}(X,Z),X)|X]-E[h(W,d_{z}^{}(X,Z),X)|X]=o_{p}(n^{-})\) almost surely and \(E[Yq(Z,A,X)\{_{w}(X,W)=A\}|X]-E[Yq(Z,A,X)\{d_{w}^{ }(X,W)=A\}|X]=o_{p}(n^{-})\) almost surely._

**Proposition 3**.: _Under Assumptions 1-6, we have \(V(_{zw}^{})}{{}}V(_{ zw}^{})\)._

## 4 Numerical Experiments

The data generating mechanism for \((X,A,Z,W,U)\) follows the setup proposed in Cui et al. (2023) and is summarized in Appendix I. To evaluate the performance of the proposed framework, we vary \(b_{1}(X)\), \(b_{2}(X)\), \(b_{3}(X)\), \(b_{a}\) and \(b_{w}\) in \([Y|X,A,Z,W,U]\) to incorporate heterogeneous treatment effects including the settings considered in Qi et al. (2023). The adopted data generating mechanism is compatible with the following \(h\) and \(q\),

\[h(W,A,X)=b_{0}+\{b_{1}(X)+b_{a}W+b_{3}(X)W\}+b_{w}W+b_{2}(X)X,\]

\[q(Z,A,X)=1+\{At_{0}+At_{z}Z+t_{a}+At_{x}X\},\]

where \(t_{0}=0.25,t_{z}=-0.5,t_{a}=-0.125\), and \(t_{x}=(0.25,0.25)^{T}\). We derive preliminary optimal ITRs \(d_{z}^{}\) and \(d_{w}^{}\) in Appendix J, from which we can see that \(X,Z,W\) are relevant variables for individualized decision-making.

We consider six scenarios in total, and the setups of varying parameters are deferred to Appendix I. For each scenario, training datasets \(\{Y_{i},A_{i},X_{i},Z_{i},W_{i}\}_{i=1}^{n}\) are generated following the above mechanism with a sample size \(n=1000\). For each training dataset, we then apply the aforementioned methods to learn the optimal ITR. In particular, the preliminary ITRs \(_{z}\) and \(_{w}\) are estimated using a linear decision rule, and \((x;_{z},_{w})\) is estimated using a Gaussian kernel. More details can be found in the Appendix K.

To evaluate the estimated treatment regimes, we consider the following generating mechanism for testing datasets: \(X(_{x},_{x})\),

\[(Z,W,U)|X(_{0}+_ {a}p_{a}+_{x}X\\ _{0}+_{a}p_{a}+_{x}X\\ _{0}+_{a}p_{a}+_{x}X), 28.452756pt =(_{z}^{2}&_{zw}&_{zu}\\ _{zw}&_{w}^{2}&_{wu}\\ _{zu}&_{wu}&_{u}^{2})},\]where the parameter settings can be found in Appendix I. The testing dataset is generated with a size \(10000\), and the empirical value function for the estimated ITR is used as a performance measure. The simulations are replicated 200 times. To validate our approach and demonstrate its superiority, we have also computed empirical values for other optimal policies, including existing optimal ITRs for proximal causal inference, as discussed in Section 2.2, along with optimal ITRs generated through causal forest (Athey and Wager, 2019) and outcome weighted learning (Zhao et al., 2012).

Figure 2 presents the empirical value functions of different optimal ITRs for the six scenarios. As expected, \(_{z},_{w},_{z w},\) and \(_{zw}^{}\) consistently outperform \(_{cf}\) and \(_{owl}\), which highlights their effectiveness in addressing unmeasured confounding. Meanwhile, across all scenarios, \(_{zw}^{}\) yields superior or comparable performance compared to the other estimated treatment regimes, which justifies the statements made in Sections 2 and 3. In addition, as can be seen in Scenario 5, all ITRs relying on the proximal causal inference framework perform similarly, which is not surprising as \(_{z}(X,Z)\) and \(_{w}(X,W)\) agree for most subjects. To further underscore the robust performance of our proposed approach, we include additional results with a changed sample size and a modified behavior policy in Appendix L.

## 5 Real Data Application

In this section, we demonstrate the proposed optimal ITR via a real dataset originally designed to measure the effectiveness of right heart catheterization (RHC) for ill patients in intensive care units (ICU), under the Study to Understand Prognoses and Preferences for Outcomes and Risks of Treatments (SUPPORT, Connors et al. (1996)). These data have been re-analyzed in a number of papers in both causal inference and survival analysis literature with assuming unconfoundednss (Cui and Tchetgen Tchetgen, 2023; Tan, 2006, 2020, 2019; Vermeulen and Vansteelandt, 2015) or accounting for unmeasured confounding (Cui et al., 2023; Lin et al., 1998; Qi et al., 2023; Tchetgen Tchetgen et al., 2020; Ying et al., 2022).

There are 5735 subjects included in the dataset, in which 2184 were treated (with \(A=1\)) and 3551 were untreated (with \(A=-1\)). The outcome \(Y\) is the duration from admission to death or censoring. Overall, 3817 patients survived and 1918 died within 30 days. Following Tchetgen Tchetgen et al. (2020), we collect 71 covariates including demographic factors, diagnostic information, estimated survival probability, comorbidity, vital signs, physiological status, and functional status (see

Figure 2: Boxplots of the empirical value functions (\(_{cf}\) and \(_{owl}\) denote estimated ITRs using causal forest and outcome weighted learning respectively).

Hirano and Imbens (2001) for additional discussion on covariates). Confounding in this study stems from the fact that ten physiological status measures obtained from blood tests conducted at the initial phase of admission may be susceptible to significant measurement errors. Furthermore, besides the lab measurement errors, whether other unmeasured confounding factors exist is unknown to the data analyst. Because variables measured from these tests offer only a single snapshot of the underlying physiological condition, they have the potential to act as confounding proxies. We consider a total of four settings, varying the number of selected proxies from 4 to 10. Within each setting, treatment-inducing proxies are first selected based on their strength of association with the treatment (determined through logistic regression of \(A\) on \(L\)), and outcome-inducing proxies are then chosen based on their association with the outcome (determined through linear regression of \(Y\) on \(A\) and \(L\)). Excluding the selected proxy variables, other measured covariates are included in \(X\). We then estimate \(_{z},_{w},_{z w}\), and \(_{zw}^{}\) using the SUPPORT dataset in a manner similar to that described in Section 4, with the goal optimizing the patients' 30-day survival after their entrance into the ICU.

The estimated value functions of our proposed ITR, alongside existing ones, are summarized in Appendix M. As can be seen, our proposed regime has the largest value among all settings. For a visual representation of the concordance between the estimated optimal ITRs, we refer to Figure 3 (results from Setting 1). The horizontal ordinate represents the 50 selected subjects and the vertical axis denotes the decisions made from corresponding ITRs. The purple and yellow blocks stand for being recommended treatment values of -1 and 1 respectively. For the subjects with purple or yellow columns, \(_{z}(X,Z)=_{w}(X,W)\), which leads to the same treatment decision for the other two ITRs. For columns with mixed colors, \(_{z}(X,Z)\) and \(_{w}(X,W)\) disagree. We see that in this case \(_{z w}(X,W,Z)\) always agree with \(_{z}(X,Z)\), while \(_{zw}^{}(X,W,Z)\) take values from \(_{z}(X,Z)\) or \(_{w}(X,W)\) depending on the individual criteria of the subjects as indicated by \(\). In addition to the quantitative analysis, we have also conducted a qualitative assessment of the estimated regime to validate its performance. For further details, please refer to Appendix M.

## 6 Discussion

We acknowledge several limitations of our work. Firstly, the proximal causal inference framework relies on the validity of treatment- and outcome-inducing confounding proxies. When the assumptions are violated, the proximal causal inference estimators can be biased even if unconfoundedness on the basis of measured covariates in fact holds. Therefore, one needs to carefully sort out proxies especially when domain knowledge is lacking. Secondly, while the proposed regime significantly improves upon existing methods both theoretically and numerically, it is not yet shown to be the sharpest under our considered model. It is still an open question to figure out if a more general policy class could be considered. Thirdly, our established theory provides consistency and superiority of our estimated regime. It is of great interest to derive convergence rates for Propositions 2 and 3 following Jiang (2017). In addition, it may be challenging to develop inference results for the value function of the estimated optimal treatment regimes, and further studies are warranted.