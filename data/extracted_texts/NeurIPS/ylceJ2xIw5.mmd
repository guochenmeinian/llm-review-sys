# Fair Wasserstein Coresets

Zikai Xiong

Operations Research Center, Massachusetts Institute of Technology, zikai@mit.edu

Niccolo Dalmasso

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

Shubham Sharma

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

Freddy Lecue

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

Daniele Magazzeni

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

Vamsi K. Potluru

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

Tucker Balch

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

Manuela Veloso

J.P.Morgan AI Research, {niccolo.dalmasso, shubham.x2.sharma, freddy.lecue, daniele.magazzeni, vamsi.k.potluru, tucker.balch, manuela.veloso}@jpmchase.com

###### Abstract

Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. While current approaches focus on creating fair synthetic representative samples by optimizing local properties relative to the original samples, their impact on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC uses an efficient majority minimization algorithm to minimize the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equivalent to Lloyd's algorithm for k-medians and k-means clustering. Experiments conducted on both synthetic and real datasets show that FWC: (i) achieves a competitive fairness-utility tradeoff in downstream models compared to existing approaches, (ii) improves downstream fairness when added to the existing training data and (iii) can be used to reduce biases in predictions from large language models (GPT-3.5 and GPT-4).

## 1 Introduction

In the last decade, the rapid pace of technological advancement has provided the ability of collecting, storing and processing massive amounts of data from multiple sources . As the volume of data continues to surge, it often surpasses both the available computational resources as well as the capacity of machine learning algorithms. In response to this limitation, dataset distillation approaches aim to reduce the amount of data by creating a smaller, yet representative, set of samples; see [80; 40] for comprehensive reviews on the topic. Among those approaches, coresets provide a weighted subset of the original data that achieve similar performance to the original dataset in (usually) a specific machine learning task, such as clustering [26; 21], Bayesian inference , online learning  and classification , among others.

In tandem with these developments, the adoption of machine learning techniques has seen a surge in multiple decision-making processes that affect society at large [69; 81]. This proliferation of machine learning applications has highlighted the need to mitigate inherent biases in the data, as these biases can significantly impact the equity of machine learning models and their decisions . Among many definitions of algorithmic fairness, demographic parity is one of the most prominently used metric , enforcing the distribution of an outcome of a machine learning model to not differ dramatically across different subgroups in the data.

Current methodologies for generating a smaller set of fair representative samples focus on the local characteristics of these samples with respect to the original dataset. For instance, [13; 30; 4; 24] obtain representative points by clustering while enforcing each cluster to include the same proportion of points from each subgroup in the original dataset. In another line of work, [33; 44; 53; 72; 12] create representative points by ensuring that points in the original dataset each have at least one representative point within a given distance in the feature space. While these methods can successfully reduce clustering cost and ensure a more evenly spread-out distribution of representative points in the feature space, it is unclear whether such representative samples can positively affect performance or discrimination reduction in downstream learning processes. As the induced distribution of the representative points might be far away from the original dataset distribution, downstream machine learning algorithm might lose significant performance due to this distribution shift, without necessarily reducing biases in the original data (as we also demonstrate empirically in our experiments).

ContributionsIn this work, we introduce **F**air **W**asserstein **C**oresets (FWC), a novel coreset approach that not only generates synthetic representative samples but also assigns sample-level weights to be used in downstream learning tasks. FWC generates synthetic samples by minimizing the Wasserstein distance between the distribution of the original datasets and that of the weighted synthetic samples, while simultaneously enforcing an empirical version of demographic parity. The Wasserstein distance is particularly suitable to this task due to its various connections with downstream learning processes and coresets generation (Section 2). Our contributions are as follows:

1. we show how the FWC optimization problem can be reduced to a nested minimization problem in which fairness constraints are equivalent to linear constraints (Section 3);
2. we develop an efficient majority minimization algorithm [56; 39] to solve the reformulated problem (Section 4). We analyze theoretical properties of our proposed algorithm and FWC (Section 5) and show that, in the absence of fairness constraints, our algorithm reduces to an equivalent version of Lloyd's algorithm for k-means and k-medians clustering, extending its applicability beyond fairness applications (Section 6);
3. we empirically validate the scalability and effectiveness of FWC by providing experiments on both synthetic and real datasets (Section 7). In downstream learning tasks, FWC result in competitive fairness-utility tradeoffs against current approaches, even when we enhance the fairness of existing approaches using fair pre-processing techniques, with an average disparity reduction of \(53\%\) and \(18\%\), respectively. In addition, we show FWC can correct biases in large language models when passing coresets as examples to the LLM, reducing downstream disparities by \(75\%\) with GPT-3.5  by \(35\%\) with GPT-4 . Finally, we show FWC can improve downstream fairness-utility tradeoffs in downstream models when added to the training data (via data augmentation, see Appendix C.2).

Finally, we refer the reader to the Appendix for more details on the optimization problem (Section A), theoretical proofs (Section B) and further experiments and details (Section C).

## 2 Background and Related Work

NotationWe indicate the original dataset samples \(\{Z_{i}\}_{i=1}^{n}\), with \(Z_{i}=(D_{i},X_{i},Y_{i})=( )^{d}\), where \(X\) indicates the non-sensitive features, \(D\) indicates one or more protected attributes such as ethnicity or gender, and \(Y\) is a decision outcome. In this work, we assume \(D\) and \(Y\) to be discrete features, i.e., to have a finite number of levels so that \(|| n\) and \(|| n\). For example, \(Y\) might indicate a credit card approval decision based on credit history \(X\), with \(D\) denoting sensitive demographic information. Given a set of weights \(\{\}_{i=1}^{n}\), define \(p_{Z;}\) the weighted distribution of a dataset \(\{Z_{i}\}_{i=1}^{n}\) as \(p_{Z;}=_{i=1}^{n}_{i}_{Z_{i}}\), where \(_{x}\) indicates the Dirac delta distribution, i.e., the unit mass distribution at point \(x\). Using this notation, we can express the empirical distribution of the original dataset by setting \(_{i}=e_{i}=1\) for any \(i\), i.e., \(p_{Z;e}=_{i=1}^{n}e_{i}_{Z_{i}}\). For a matrix \(A,A^{}\) denotes its transpose. For two vectors (or matrices) \( u,v}}{{=}}_{i}u_{i}v_{i}\) is the canonical inner product (the Frobenius dot-product for matrices). We define \(_{m}}}{{=}}(1,,1)_{+}^{m}\).

Wasserstein distance and coresetsGiven two probability distributions \(p_{1}\) and \(p_{2}\) over a metric space \(\), the Wasserstein distance, or optimal transport metric, quantifies the distance between the two distributions as solution of the following linear program (LP):

\[_{c}(p_{1},p_{2})}}{{=}}_{ (p_{1},p_{2})}_{}c(x_{1},x_{2})(x_{1},x_{2}),\] (1)

with \((p_{1},p_{2})\) indicating the set of all joint probability distributions over the product space \(\) with marginals equal to \((p_{1},p_{2})\). The operator \(c(x,y)\) represents the "cost" of moving probability mass from \(x\) and \(y\), and reduces to a matrix \(C\) if the underlying metric space \(\) is discrete.

The Wasserstein distance has several connections with downstream learning processes and coresets. Firstly, the higher the Wasserstein distance between the weighted representative samples \(p_{;}\) and the original dataset \(p_{Z;e}\), the higher the distribution shift, the more degradation we might expect in terms of downstream learning performance . Secondly, the Wasserstein distance between two probability distributions can also be used to bound the deviation of functions applied to samples from such distributions. Define the following deviation:

\[d(p_{;},p_{Z;e})}}{{=}}_{ f}|_{z p_{;}}f(z)-_{z  p_{Z;e}}f(z)|\.\]

When \(\) is the class of Lipschitz-continuous functions with Lipschitz constant equal or less than \(1\), the deviation \(d(p_{;},p_{Z;e})\) is equal to 1-Wasserstein distance \(_{1}(p_{;},p_{Z;e})\). The connection with learning processes and the downstream deviation \(d(p_{(,);},p_{(X,D);e})\) is immediate when considering Lipschitz continuous classifiers with Lipschitz constant less than 1 (such as logistic regression or Lipschitz-constrained neural networks )3. For other classifiers, we note that the 1-Wasserstein distance still bounds the downstream discrepancy: in Proposition 2.1 we show that the 1-Wasserstein distance bounds the downstream discrepancy for ReLu-activated multilayer perceptrons (MLPs), which we use in our experiments on real datasets (Section 7).

**Proposition 2.1**.: _Let \(g_{}^{K}\) be the class of \(K\)-layer multilayer perceptrons with ReLu activations. Then, the downstream discrepancy in downstream performance of \(g_{}\) applied to samples from \(p_{(,);}\) and \(p_{(X,D);e}\) is bounded by the 1-Wasserstein distance :_

\[d(p_{(,);},p_{(X,D);e})=\\ _{g_{}^{K}}|_{(x,d) p_{ (,);}}g_{}(x,d)-_{(x,d) p_{(X,D);e}}g_{ }(x,d)| L_{k}_{1}(p_{;},p_{Z;e}),\] (2)

_where \(L_{k}\) is the MLP Lipschitz constant upper bound defined in [75, Section 6.1, Equation (8)]._

We point out that minimizing the Wasserstein distance, hence bounding the downstream performance as in Equation (2), is equivalent to the definition of a measure coresets proposed by . The Wasserstein distance is also connected to coresets in the sense of the best discrete approximation of a continuous distributions. Considering a feature space endowed with a continuous distribution, minimizing the \(p\)-Wasserstein distance across all the distributions of size \(m\) is topologically equivalent to identify the samples of size \(m\) that provide the best Voronoi tessellation of the space in \(L_{p}\) sense . Although other definitions of coresets using Wasserstein distance have been proposed in the literature, they require either to solve the underlying optimal transport problems or the knowledge of the downstream classifier and loss function . FWC is agnostic to any downstream model or loss function, and uses an efficient implementation that does not actually incur in the usual high cost connected to optimal transport. By adapting the approach proposed by , we solve an equivalent re-formulated linear optimization problem, which is more computationally tractable than classic approaches such as the simplex or the interior point method (see Section 4.1).

Demographic parityAlso known as statistical parity, demographic parity (DP) imposes the decision outcome and protected attributes to be independent . Using a credit card approval decision example, demographic parity enforces an automatic decision process to approve similar proportion of applicants across different race demographics. DP is one of the most extensively analyzed fairness criterion; we refer the reader to  for a review. In this work, we use the demographic parity definition by , which enforces the ratio between the conditional distribution of the decision outcome across each subgroups \(p(y|D=d)\) and the marginal distribution of the decision outcome \(p(y)\) to be close to \(1\) in a given dataset. We refer to the "empirical version" of demographic parity to indicate that the conditional and marginal distributions are quantities estimated from the data. Note that the demographic parity definition we adopt enforces a condition on the weighted average of the conditional distributions across groups, which is different from a more recent approach of using Wasserstein distance, and specifically Wasserstein barycenters, to enforce demographic parity [25; 32; 23; 78].

## 3 FwC: Fair Wasserstein Coresets

Given a dataset \(\{Z_{i}\}_{i=1}^{n}\), our goal is to find a set of samples \(\{_{j}\}_{j=1}^{m}\) and weights \(\{_{j}\}_{j=1}^{m}\) such that \(m n\) and that the Wasserstein distance between \(p_{Z;e}\) and \(p_{;}\) is as small as possible. In addition, we use the fairness constraints proposed by  to control the demographic parity violation for the \(p_{;}\) distribution. Let \(p_{;}(y|d)\) indicate the conditional distribution \(p_{;}(=y|=d)\). Imposing a constraint on the demographic disparity violation then reduces to requiring the conditional distribution under the weights \(\{_{i}\}_{i[n]}\) to be close to a target distribution \(p_{Y_{T}}\) across all possible values of the protected attributes \(D\),

\[J(p_{;}(y|d),p_{Y_{T}}(y))=|; }(y|d)}{p_{Y_{T}}(y)}-1|,\ \ d,y,\] (3)

where \(\) is a parameter that determines the maximum fairness violation, and \(J(,)\) is the probability ratio between distributions as defined in .

Using the notation above, our goal can then be formulated as the following optimization problem:

\[_{_{m},^{m} }_{c}(p_{;},p_{Z;e})\\ & J(p_{;}(y|d),p_{Y_{T} }(y)),\ \ d,y,\] (4)

where \(_{m}\) indicates the set of valid weights \(\{_{+}^{m}:_{i=1}^{m}_{i}=m\}\). Note that the optimization problem in (4) shares some similarities with the optimization problem in  in using the Wasserstein distance as a distance metric between distributions and using (3) to enforce demographic parity. However,  only provide sample-level integer weights for the original dataset and do not generate any new samples, while our approach provides a separate set of samples \(\{_{j}\}_{j=1}^{m}\) with associated real-valued weights \(\{_{j}\}_{j=1}^{m}\), with \(m n\).

We now take the following steps to solve the optimization problem in (4): (i) we reduce the dimensionality of the feasible set by fixing \(\) and \(\) a priori, (ii) we formulate the fairness constraints as linear constraints, (iii) we add artificial variables to express the objective function and (iv) we simplify the optimization problem to minimizing a continuous non-convex function of the \(\{_{j}\}_{j=1}^{m}\).

Step 1. Reduce the feasible set of the optimization problemAs in practice all possible \(Y_{i}\) and \(D_{i}\) are known a priori, and there are only a limited number of them, we can avoid optimizing over them and instead manually set the proportion of each combination of \(\) and \(\). This reduces the optimization problem feasible set only over \(_{m}\) and \(^{m}\). The following lemma shows that this in fact does not affect the optimization problem:

**Lemma 3.1**.: _For any \(m>0\), the best fair Wasserstein coreset formed by \(m\) data points \(\{_{i}:i[m]\}\) is no better (i.e., the optimal Wasserstein distance value is no lower) than the best fair Wasserstein coreset formed by \(m||||\) data points \(\{(d,X_{i},y)_{i}:i[m],d,y\}\)._Hence, we simply set the proportions of \(\{(_{i},)_{i}\}_{i[m]}\) in the coresets to be similar to their respective proportions in the original dataset. The optimization problem then reduces to

\[_{_{m},^{m}}& _{c}(p_{,},p_{;e})\\ & J(p_{,}(y|d),p_{Y_{T} }(y)),\;\;d,y\;,\] (5)

whose solutions are the features in the coreset \(\{_{j}\}_{j=1}^{m}\) and the corresponding weights \(\{_{j}\}_{j=1}^{m}\).

Step 2. Equivalent linear constraintsFollowing , the fairness constraint in Equation (3) can be expressed as \(2||||\) linear constraints on the weights \(\), as the disparity reduces to the following for all \(d,y\):

\[_{i[m]:_{i}=d,_{i}=y}_{i}(1+) p_{ Y_{T}}(y)_{i[m]:_{i}=d}_{i}\;,_{i[m]: _{i}=d,_{i}=y}_{i}(1-) p_{Y_{T}}(y)_{i [m]:_{i}=d}_{i}\;.\]

We can express these by using a \(2||||\)-row matrix \(A\) as \(A\).

Step 3. Reformulate the objective function by introducing artificial variablesWhen keeping the samples \(\) fixed, we can follow  to derive an equivalent formulation of the Wasserstein distance in the objective as a linear program with \(mn\) variables. By indicating the transportation cost matrix \(C()\), we define its components as follows,

\[C()_{ij}\;}}{{=}}\;c(Z_{i},_ {j}),\;\;i[n],j[m]\;.\]

Note that \(C()\) is a convex function of \(\) when, e.g., using any \(L^{p}\) norm to define the transportation cost. Therefore, now the problem (5) is equivalent to

\[_{^{m},_{m},P^{n m}}& C(),P\\ & P_{m}= _{n},\;P^{}_{n}=,\;P,\;A\;.\] (6)

Step 4. Reduce to an optimization problem of \(\)As from one of the constraints we get \(=m P^{}_{n}\), we further simplify problem (6) as:

\[_{^{m},P^{n  m}}& C(),P\\ & P_{m}= _{n},\;P,\;AP^{}_{n}\;. \] (7)

Let \(F(C)\), as a function \(F\) of \(C\), denote the optimal objective value of the following optimization problem

\[_{P^{n m}}&  C,P\\ & P_{m}= _{n},\;P,\;AP^{}_{n}\] (8)

and then problem (7) is equivalent to

\[_{^{m}}\;F(C())\;.\] (9)

In (9) the objective is continuous but nonconvex with respect to \(\). Once the optimal \(^{}\) is solved, then the optimal \(P^{}\) of the problem (7) is obtained by solving problem (8) with \(C\) replaced with \(C(^{})\). Finally, the optimal \(^{}\) follows by the equation \(^{}=m(P^{})^{}_{n}\). We now provide a majority minimization algorithm for solving problem (9).

Majority Minimization for Solving the Reformulated Problem

Majority minimization aims at solving nonconvex optimization problems, and refers to the process of defining a convex surrogate function that upper bounds the nonconvex objective function, so that optimizing the surrogate function improves the objective function [56; 39]. As the algorithm proceeds, the surrogate function also updates accordingly, which ensures the value of the original objective function keeps decreasing. Following this framework, we define the surrogate function \(g(;^{k})\) as follows for the \(k\)-th iterate \(^{k}^{m}\):

\[g(;^{k})\ }}{{=}}\  C(),P_{k}^{}\,\] (10)

in which \(P_{k}^{}\) is the minimizer of problem (8) with the cost \(C=C(^{k})\)4.

With this surrogate function, Algorithm 1 summarizes the overall algorithm to minimize problem (9). In each iteration of Algorithm 1, line 3 is straightforward since it only involves computing the new cost matrix using the new feature vectors \(^{k}\). We separately discuss how to solve the optimization problems in lines 4 and 5 below.

```
1:Initial feature vectors \(^{k}\) and \(k=0\)
2:while True do
3:\(C C(^{k})\); \(\) update the cost matrix \(C\)
4:\(P_{k}^{}\) optimal solution of problem (8); \(\) updating the surrogate function (Section 4.1)
5:\(^{k+1}_{^{m}}g(;^{ k})\); \(\) updating feature vectors (Section 4.2)
6:if\(g(^{k+1};^{k})=g(^{k};^{k})\)then
7:\(_{k}^{} m(P_{k}^{})^{}_{n}\); \(\) if algorithm has converged, compute optimal weights
8:return\(^{k}\), \(_{k}^{}\)\(\) return coresets and sample-level weights
9:endif
10:\(k k+1\);
11:endwhile ```

**Algorithm 1** Majority Minimization for Solving (9)

### Updating the Surrogate Function (Line 4)

To update the surrogate function, we need to solve problem (8), which is a large-scale linear program. Rather than solving the computationally prohibitive dual problem we solve a lower-dimensional dual problem by using a variant of the FairWASP algorithm proposed by . We adapt FairWASP for cases where \(m n\) to find the solution of (8) via applying the cutting plane methods on the Lagrangian dual problems with reduced dimension5. We choose FairWASP over established commercial solvers due to its computational complexity being lower than other state of the art approaches such as interior-point or simplex method; see Lemma A.2 in Appendix A for more details.

### Updating Feature Vectors (Line 5)

To update the feature vectors, we need to obtain the minimizer of the surrogate function \(g(;^{k})\), i.e.,

\[_{^{m}}g(;^{k})\.\] (11)

The above can be written as the following problem:

\[_{_{j};j[m]}_{i[m]}_{j[m]}c(Z_{i}, _{j})P_{ij}\] (12)

for \(P=P_{k}^{}\), in which each component of \(P\) is nonnegative and \(_{j}=(_{j},_{j},_{j})\), for the known fixed \(_{j}\) and \(_{j}\). Furthermore, the matrix \(P\) is sparse, containing at most \(n\) non-zeros (as when updating \(P_{k}^{*}\) for problem (8), see Appendix A). Moreover, problem (12) can be separated into the following \(m\) subproblems,

\[_{_{j}}_{i[n]}c(Z_{i},_{j})P_{ ij}j[m]\] (13)

Each subproblem computes the weighted centroid of \(\{Z_{i}:i[n],P_{ij}>0\}\) under the distance function \(c\). Therefore, (11) is suitable for parallel and distributed computing. Additionally, since the cost matrix \(C()\) is a convex function of \(\), each subproblem is a convex problem so gradient-based methods could converge to global minimizers. Furthermore, under some particular conditions, solving these small subproblems can be computationally cheap:

1. If \(\) is convex and \(c(Z,)}}{{=}}\|Z-\|_{2}^{2}\), then the minimizer of (13) is the weighted average \(_{i[n]}P_{ij}X_{i}/_{i[n]}P_{ij}\).
2. If \(\) is convex and \(c(Z,)}}{{=}}\|Z-\|_{1}\), then the minimizer of (13) requires sorting the costs coordinate-wisely and finding the median.
3. If creating new feature vectors is not permitted and \(=\{X_{i}:i[n]\}\), solving (13) requires finding the smallest \(_{i[n]:P_{ij} 0}c(Z_{i},(_{j},X,_{j}))P_{ij}\) for \(X\) within the finite set \(\). The matrix \(P\) is highly sparse so this operation is not computationally expensive.

## 5 Theoretical Guarantees

In this section we provide theoretical insights on FWC complexity, convergence behavior of Algorithm 1 as well as generalizability of FWC performance on unseen test sets.

### Computational Complexity

First, we consider the FairWASP variant used in Algorithm 1, line 4. The initialization requires \(O(mn)\) flops and uses \(O(n|Y||D|)\) space for storing the cost matrix. After that, the per-iteration time and space complexities are both only \(O(n|Y||D|)\). Lemma 5.1 analyzes the computational complexity of our adaptation of the FairWASP algorithm when solving problem (8).

**Lemma 5.1**.: _With efficient computation and space management, the cutting plane method has a computational complexity of_

\[(nm+||^{2}||^{2}n(R/ ))\] (14)

_flops and \(O(n||||)\) space. Here \(R\) denotes the size of an optimal dual solution of (8), and \(()\) absorbs \(m\), \(n\), \(||\), \(||\) in the logarithm function._

Hence, the overall complexity of FWC is \((mn+||^{2}||^{2}n(R/))\). Note that in practice, both \(||\) and \(||\) are very small compared with the coreset size \(m\) and dataset size \(n\), so the overall complexity is almost as low as \(O(mn)\).

### Convergence Guarantees

First, we establish that our proposed surrogate function is indeed convex and a valid upper bound. We then show Algorithm 1 converges to a first-order stationary point, within finite iterations if the minimizer of problem (11) is unique. Note that because \(g(;^{k})= C(),P_{k}^{*}\), the minimizer is unique whenever the cost matrix \(C()\) is strongly convex.

**Lemma 5.2**.: _The function \(g(;^{k})\) is convex function of \(\) and a valid upper bound, i.e., \(g(;^{k}) F(C())\). This inequality holds at equality when \(=^{k}\)._

**Theorem 5.3**.: _The objective value is monotonically decreasing, i.e., \(F(C(^{k+1})) F(C(^{k}))\) for any \(k 0\). And once the algorithm stops and \(C(^{k})\) is smooth at \(^{k}\), then \(^{k}\) is a first-order stationary point of (9)._

**Theorem 5.4**.: _When the minimizer of (11) is unique, Algorithm 1 terminates within finite iterations._

### Generalization Guarantees

Proposition 5.5 below bounds the distance and demographic parity between the FWC samples and the true underlying distribution of the data, from which the original dataset of size \(n\) was observed. This generalizes the performance of FWC to unseen test sets sampled from the data generating distribution.

**Proposition 5.5**.: _Let \(\) indicate the distance between \(p_{;}\) and \(p_{Z;e}\) after convergence of FWC i.e., \((p_{;},p_{Z;e})=\). Let \(q_{Z}\) be the true underlying distribution of the data supported over \(^{d}\), with marginal distribution over \(y\) bounded away from zero, so that \(=_{y}q_{Z}(y)>0\). Then with probability \(1-\):_

\[_{c}(p_{},q_{Z}) +((1/)^{1/d}n^{-1/d})\] (15) \[_{y,d}J(p_{}(y|d),q_{Y}(y)) +(}})\] (16)

In addition, in Appendix B.1 we consider the task of learning using FWC samples. We show that the error in downstream learning tasks can be seen as the sum of (i) the approximation error FWC samples make with respect to the original dataset and (ii) how well \(\) can be learnt from \(\) and \(\) from FWC samples. However, as FWC samples \(\{_{j}\}_{j=1}^{m}\) are not i.i.d., standard sample complexity results in e.g., empirical risk minimization, do not apply, highlighting the hardness in developing finite-sample learning bounds in this setting.

## 6 An Alternative View: Generalized clustering algorithm

When the fairness constraints are absent, problem (8) reduces to:

\[_{P^{n m}}& C,P\\ &P_{m}=_{n},\;P_ {n m}\;.\] (17)

The minimizer \(P^{}\) of (17) can be written in closed form. For each \(i[n]\), let \(C_{ij}\); denote a smallest component on the \(i\)-th row of \(C\). Then the components of a minimizer \(P^{}\) can be written as \(P^{}_{ij}=(j=j^{}_{i})\) (where \(\) is the indicator function). Hence, without fairness constraints, FWC corresponds to Lloyd's algorithm for clustering. Specifically, Lloyd's algorithm iteratively computes the centroid for each subset in the partition and subsequently re-partitions the input based on the closeness to these centroids ; these are the same operations FWC does in optimizing the surrogate function and solving problem (17). Thus, when \(c(x,y)\) is correspondingly defined as \(\|x-y\|_{1}\) or \(\|x-y\|_{2}^{2}\), FWC corresponds to Lloyd's algorithm applied to k-medians or k-means problems, except the centroids have fixed values for \(\) and \(\) (see Section 3).

Comparison with k-means and k-medoids FWC and Lloyds' algorithm for k-means or k-median share similar per-iteration complexity, with the main difference in complexity due to solving problem (8). We solve this problem efficiently by utilizing a variant of the FairWASP approach by  (Section 4.1), hence avoiding the usual complexity in solving optimal transport problems. As shown in Section 5, the leading term in the runtime complexity is \((nm)\), which comes from calculating and storing the cost matrix \(C\). This level of complexity is the same as those in k-means and k-medoids. In addition, from our experiments we also see that the per-iteration complexity of FWC is roughly linear with the original dataset size \(n\) (see the runtime experiment in Section 7 and Appendix C).

## 7 Experiments

Runtime analysisWe evaluate the runtime performance of FWC by creating a synthetic dataset of dimension \(n\) and features of dimension \(p\), with the goal of creating a coreset of size \(m\) (see Appendix C.1 for details). We fix two out of the three parameters to default values \((n,m,p)=(5000,250,25)\) and vary the other across suitable ranges, to analyse the runtime and total number of iterations. Figure 1, top left, and Table 2, in Appendix C.1, show the runtime and number of iterations when increasing the dataset size \(n\) from 1,000 to 1,000,000, with averages and standard deviations over 10 separate runs; both the runtime and number of iterations grow proportionally to the sample size \(n\). Figure 2 in Appendix C.1 also shows that requiring a larger coreset size \(m\) implies the need of fewer iterations but longer iteration runtime, as more representatives need to be computed.

Real datasets resultsWe evaluate the performance of FWC on 4 datasets widely used in the fairness literature : (i) Adult , (ii) German Credit , (iii) Communities and Crime  and (iv) Drug . For each dataset, we consider 3 different coreset sizes \(m=5\%,10\%,20\%\) (apart from the Adult dataset, in which we select \(m\) equal to 0.5%, 1% and 2% due to the large dataset size). We compare our approach with: (a) Fairlets and IndFair, two fair clustering approaches by  and , (b) K-Median Coresets, a coreset approach by , (c) k-means  and k-medoids , two classic clustering approaches and (d) Uniform Subsampling of the original dataset. For FWC, we consider three different values of the fairness violation hyper-parameters \(\) for the optimization problem in (5). We compute the fairness-utility tradeoff by first training a 2-layer multilayer perceptron (MLP) classifier with ReLu activations on the coresets created by each approach and then evaluating the classifier demographic disparity (fairness) and AUC (utility). Figure 1 shows the model with the best fairness-utility tradeoff across the three coreset sizes \(m\), for each approach. FWC obtains equal or better fairness-utility tradeoffs (smaller disparity at the same level of utility, higher utility with the same disparity, or both) across all datasets, and performance remains competitive even when using a fairness pre-processing approach . Appendix C.2 includes more experiments and details, which highlight that: (a) FWC consistently achieves coresets that are closer in distribution to the original dataset with respect to the other methods and, although not natively minimizing clustering cost, also provide competitive performance for smaller datasets (Tables 3 and 4); (b) when added to the training data using the data augmentation schema proposed by [68, Section 2.1] FWC generally either increase the performance or reduce the demographic disparity in the downstream learning process.

Using FWC to improve fairness for LLM evaluate GPT-3.5 and GPT-4 for fairness on predictive tasks for the UCI Adult dataset in a zero and few shot setting. We use a similar evaluation setup and use FWC in the few shot setting as examples and evaluate the results for the gender protected attribute. Specifically, we transform the tabular data into language descriptions, and ask GPT-3.5 Turbo and GPT-4 to perform classification tasks on it. We select \(200\) samples to construct the test set and use a set of 16 samples found using FWC as examples. Further details on this experiment are provided in the appendix. The results are shown in Table 1. Examples provided by FWC help reduce demographic disparity more than providing balanced few shot examples, while losing on predictive accuracy (note that the drop in accuracy is similar to the drop observed in  and is representative of the fairness-utility trade-off). Owing to the token limitation of LLM's, these representative coresets

Figure 1: _Top left:_ FWC runtime when changing the original dataset size \(n\). _Others_: Fairness-utility tradeoff on real datasets for a downstream MLP classifier, selecting the model with the best fairness-utility tradeoff across three different coreset sizes \(m\), with averages taken over 10 runs. FWC consistently achieves a comparable/better tradeoff as shown by the Pareto frontier (dashed red line, computed over all models and coreset sizes), even when adjusting the other coresets with a fairness pre-processing technique . See text and Appendix C.2 for more details.

can evidently be valuable to provide a small set of samples that can help mitigate bias. When accounting for the standard deviations for demographic parity in Table 1, FVC reduces the LLM bias when compared to zero shot prompting for GPT-4 across all runs. For GPT-3.5 Turbo, while the average disparity is reduced across runs, such consistency is indeed not observed, owing to a diverse set of outputs from the large language model. Due to limited availability of computational resources (associated with querying these models), we leave a more thorough evaluation across different datasets and models to future work.

## 8 Discussion and Conclusions

We introduce FWC, a novel coreset approach that generates synthetic representative samples along with sample-level weights for downstream learning tasks. FWC minimizes the Wasserstein distance between the distribution of the original datasets and that of the weighted synthetic samples while enforcing demographic parity. We demonstrate the effectiveness and scalability of FWC through experiments conducted on both synthetic and real datasets, as well as reducing biases in LLM predictions (GPT 3.5 and GPT 4). Future extensions include: (i) targeting different fairness metrics such as equalized odds  as well as robustness of fairness-performance tradeoff over distribution shifts , (ii) exploring privacy and explainability properties of FWC, (iii) utilizing coresets for accelerating gradient descents algorithms and test their convergence  (iv) reformulating the optimization framework to target deep neural network pruning  and (v) investigate applications of fair synthetic data in the financial sector .

## Disclaimer

This paper was prepared for informational purposes by the Artificial Intelligence Research group of JPMorgan Chase & Co. and its affiliates ("JP Morgan") and is not a product of the Research Department of JP Morgan. JP Morgan makes no representation and warranty whatsoever and disclaims all liability, for the completeness, accuracy or reliability of the information contained herein. This document is not intended as investment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale of any security, financial instrument, financial product or service, or to be used in any way for evaluating the merits of participating in any transaction, and shall not constitute a solicitation under any jurisdiction or to any person, if such solicitation under such jurisdiction or to such person would be unlawful.