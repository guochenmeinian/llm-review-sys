# Optimizing Detection Time and Specificity:

Early Classification of Time Series with

Sensitivity Constraint

 Jiaming Qiu Ying-Qi Zhao Yingye Zheng

###### Abstract

From the perspective of sequential decision making, we propose a novel approach for early classification of time series under the Neyman-Pearson paradigm that incorporates a sensitivity constraint. We explicitly formulate the optimal solution, which can be practically obtained utilizing plug-in estimators such as recurrent neural networks. Cast as a constrained multi-objective optimization problem, we establish the Pareto optimality balancing earliness and classification accuracy. Our approach visualizes the inherent trade-off between earliness and specificity, ensuring informed decision making without compromising sensitivity. Experimental validation confirms the feasibility of our approach, demonstrating its potential in various real-world applications.

## 1 Introduction

Early classification of time series (ECTS) is critical for real-time decision-making in domains such as healthcare, finance, and industrial monitoring, where timely interventions can significantly mitigate risks and costs. Unlike traditional time series classification that relies on complete data, ECTS aims to classify based on partial data, allowing for prompt actions.

A wide array of methods has been proposed (see, e.g., Gupta et al., 2020, for a review), focusing on the balance of classification accuracy and earliness. For instance, Mori et al. (2018, 2019) tackle ECTS from the perspective of multi-object optimization to balance earliness and accuracy. However, the consequence of false classification conditioning on actual outcome could be drastically different. For example, in certain medical settings, higher sensitivity is desired even at the cost of lower specificity so as not to miss lethal disease. The classic Neyman-Pearson paradigm (Neyman et al., 1933) has been successful balancing the trade-off between sensitivity and specificity, yet rarely explored in the setting of ECTS.

In sequential analysis where confidence accumulates along increased number of i.i.d. observations, Wald's sequential probability ratio test (SPRT) provides the earliest decision among all tests of the same power (Wald and Wolfowitz, 1948) by thresholding on the cumulative product of probability ratios. However, its optimality weakens given dependent samples (e.g., Schmitz, 1985). The requirement of unlimited observability also makes it less ideal for classifying time series with finite horizon, where decision must be made before certain terminal time.

In this study, we take the perspective of sequential decision making under finite horizon. For each time \(t\) before the terminal time \(T\), the classifier either conclude positively/negatively based on the seriestill \(t\) or wait for further information from next time step. We evaluate the classifier by three criteria: sensitivity (true positive rate, TPR), specificity (equivalently 1 - false positive rate, FPR), and earliness (or equivalently cost) of decision. We propose a novel ECTS approach under the Neyman-Pearson paradigm motivated by multi-objective optimization. The proposed method incorporates a sensitivity constraint while seeks to simultaneously maximize the specificity and earliness.

By framing ECTS as a constrained multi-objective optimization problem, we demonstrate the inherent trade-offs among earliness and classification power. Such trade-off is quantified by the Pareto front, where neither earliness or specificity can be improved without sacrificing the other criteria. By decomposing accuracy into two separate metrics (sensitivity and specificity), we offer a more nuanced characterization of the trade-off that is otherwise unavailable in existing ECTS approaches. Based on a straight forward Lagrange dual problem, we explicitly formulate the optimal solution, which is tractable via plugging-in neural networks as showcased by numeric experiments.

## 2 Explicit Form of the Pareto Optimal Classifier

Denote the covariate process (i.e., time series to classify) as \(X=X_{1:T}\) with \(X_{t}\) for \(t=1,,T\)1 and the associated binary outcome (i.e., class label) as \(Y\{0,1\}\).2 A sequential decision rule is

\[(X_{1},,X_{T})=(f_{1}>0)+(f_{1}= 0,f_{2}>0)++(f_{1:T-1}=0,f_{T}>0),\] (2.1)

where \(()\{0,1\}\) takes \(1\) if the condition is true, and \(0\) otherwise. We write \(f_{t}=f_{t}(X_{1:t})\) as the score at time \(t\) based on the history \(X_{1:t}=(X_{1},,X_{t})\); write \(f_{1:t}\) as the scores till time \(t\) with the convention that \(f_{1:T-1}=0\) means \(f_{1},,f_{T-1}\) are all zero. Denote the natural filtration spanned by \(X_{1:T}\) as \(\). The score \(f_{1:T}\) is a stochastic process that is \(\)-_adapted_, i.e., \(f_{t}\) is \(_{t}\)-measurable (equivalently, is measurable function of \(X_{1:t}\)) for all \(t=1,,T\).

The decision process could stop early before the terminal time \(T\) once receiving a non-zero score. Denote \(=\{1 t T:f_{t} 0\}\) as the _associated stopping time_ at which rule (2.1) makes a decision, so that \(\) is the same as an early-stopped rule denoted as \(_{}{:=}(f_{}>0)\). To characterize the earliness of decision, we associate time steps with operational cost, either time or monetary. Denote the _accumulated cost_ of running the decision process till time \(t\) as \(C_{t}\) for some increasing \(0<C_{1}<<C_{T}\). The actual cost of the early-stopped decision rule is hence \(C_{}\). The introduction of cost allows more flexible modeling: setting \(C_{t}=t/T\) for regularly sampled time series corresponds to the conventional _earliness_ notion; one can also encourage earlier or later decision by adjusting cost accordingly.

We say a sequential rule is _efficient under Neyman-Pearson paradigm_ if it is the optimum of the multi-objective optimization (MOO) problem:

\[([_{} Y=0],[C_{} ]),[_{} Y=1]\] (2.2)

for some \((0,1)\), where \(_{}{:=}(f_{}>0)\), with expectations taken over \(X_{1:T}\). Here, \([_{} Y=1]\) and \([_{} Y=0]\) are the true and false positive rate, while \([C_{}]\) is the expected cost.

Usually multiple optima of a multi-objective problem exists, where none of the objectives could be further improved without sacrificing some other objectives, the collection of which is called the _Pareto front_ (e.g., Pardalos et al., 2017). One common way to approximate MOO is the \(\)-constraints approach that translates all but one objectives into constraints, formulated as

\[[_{} Y=0],[C_{}][_{} Y=1]\] (2.3)

for some \(0<<1\). Tackling problem (2.3) utilizing Lagrangian multipliers provides explicit form of the optimal score functions. In fact, under mild conditions, the optimum of (2.3) is also Pareto optimal for problem (2.2), which is outlined in the following and detailed in Appendix A.

**Proposition 2.1**.: _Denote the dual function of the Lagrangian function \((f;a,b)\) of (2.3) as \((a,b){:=}_{f}(f;a,b)\) with the infimum is taken over all \(\)-adapted process \(f_{1:T}\). Then_

\[(a,b)=b-a-[S_{1}].\] (2.4)_Here, \(S_{1}\) is defined recursively. Writing \(p_{1}=(Y=1)=1-p_{0}\), we define \(_{t}\!:=[Y X_{1:t}]\) and \(_{t}\!:=\!(bp_{1}^{-1}+p_{0}^{-1})_{t}-p_{0}^{-1}\). Then \(S_{T}\!:=\!\!_{T}^{+}-aC_{T}\) and_

\[S_{t}\!:=\!(_{t}^{+}-aC_{t},_{t}),_{t}\!:=\! [S_{t+1} X_{1:t}]\] (2.5)

_for \(t=1,,T\). Here \(_{t}^{+}\!:=\!(_{t},0)\). Moreover, the infimum over \(f\) is achieved at \(_{1:T}(a,b)\) with \(_{T}(X_{1:T};a,b)=_{T}\), and_

\[_{t}(X_{1:t};a,b)=1,&_{t}-aC_{t}> (-aC_{t},_{t}),\\ 0,&_{t}_{t},\\ -1,&-aC_{t}>(_{t}-aC_{t},_{t})\] (2.6)

_where \(_{t}\!:=\!\!_{t}^{+}-aC_{t}\) for \(t=1,,T-1\)._

Therefore, the dual problem of (2.3) is

\[(a,b)a,b 0.\] (2.7)

To connect the primal and dual, one key assumption is that \(_{t}\) are continuous functions of \(X_{1:t}\) for all \(t\), similar to that in a non-randomized likelihood ratio test which ensures any desired sensitivity is achievable. With few other mild assumptions, there always exists some dual optimal \(a^{*},b^{*}\) with no duality gap, i.e., _strong duality condition_ holds. By plugging-in \(f^{*}(X)=(X;a^{*},b^{*})\) and subsequently \(^{*}\), the primal-dual pair \((f^{*},a^{*},b^{*})\) optimizes problem (2.3) and (2.7) satisfying the constraints by equalities, as shown in Proposition A.1. Further, such optima of problem (2.3) is in fact also Pareto optimal for the MOO, so that we transform the MOO (2.2) into a convex optimization of (2.4). The Pareto front is obtained by solving multiple primal-dual problems looping over \(\).

**Theorem 2.1**.: _Suppose for \(t=1,,T\), the \(X_{t}\) are continuous r.v. admits density, and \(X_{1:t}_{1:t}\) are continuous functions bounded away from zero, then for any \(,(0,1)\) there exists some \(^{*}\) whose scores take the form of (2.6) such that i) \(^{*}\) minimizes problem (2.3) satisfying the constraints by equality; ii) \(^{*}\) is a Pareto optimum for problem (2.2) as well as the MOO problem that seeks to simultaneously minimize \(([_{} Y=0],\,[C_{}])\) and maximize \([_{} Y=1]\)._

The preceding optimality guarantee partly generalizes the Neyman-Pearson lemma to sequential setting by providing an optimal form for the classifier that maximizes specificity, earliness, and sensitivity.

## 3 Plug-in Estimation via Recurrent Neural Network

It suffices to recursively estimate the \(\)-adapted processes \(_{1:T}\) and \(_{1:T-1}\) then plug into (2.6). Recurrent neural networks (RNN) are suitable candidates as they handle sequence-to-sequence tasks by recurrent evaluation without the need of stacking a list of models. Most importantly, their only utilize \(X_{1:t}\) at time \(t\), making the output sequence inherently \(\)-adapted. For added flexibility (especially for \(\)), we follow the RNNs by a time-specific layer, essentially one fully connected linear layer for each \(t=1,,T\) that do not share parameters across time.

Denote \((X_{1:t},_{})\) and \((X_{1:t},_{})\) as neural network models for \(_{t}\) and \(_{t}\) respectively, and subsequently \(,,\), \(\), and \(\) by plugging-in \(\) and \(\) into corresponding definitions. To track conditional expectation, suppose \(S\) is known, it suffices to minimize mean squared errors

\[Q_{}(_{})=_{t=1}^{T}[(_{t}-Y)^{ 2}], Q_{}(_{}|_{},a,b,S_{1:T})=_{t=1 }^{T-1}[(_{t}-S_{t+1})^{2}],\] (3.1)

and maximize the dual function \(}(a,b|_{},_{},S)=b-a- [S_{1}]\). Invoking stochastic gradient descent iteratively admits estimated parameters denoted as \(_{},_{},\), and \(\); and subsequently the optimal rule \(\). While \(Q_{}\) and \(}\) both rely on \(\) and \(\), we suppress those arguments for simpler notation. Note that \(Q_{}\) essentially tracks a many-to-one classification but utilizing the entire output sequence. It is simple to obtain \(_{} Q_{}\), hence decoupled from the iterative update of \(Q_{}\) and \(}\). Similarly \(Q_{}\) tracks a many-to-many regression if \(S\) is available, it suffices to update \(_{}\)iteratively, leading to Algorithm 1. In practice, it suffices to replace the expectations by sample/batch averages. See Appendix B for additional implementation details.

The proposed algorithm effectively parameterize \(\) by \((,)\), i.e., the desired sensitivity and expected cost, making it possible to dynamically adjust \((,)\) according to the sensitivity and average cost on validation data. This seamlessly incorporates into Algorithm 1 by slightly increasing or decreasing the \(\) or \(\) used for computation every few epochs.

## 4 Experiments

We now validate the proposed methods as a feasible approach for early classification. Since the proposed method is not directly comparable to existing ECTS approaches that focus on the accuracy combining sensitivity and specificity into one objective, we resort to Wald's SPRT (see Appendix C) for a baseline comparison.

We considered two simulated examples based on stationary autoregressive AR(1) time series, a sensory example (Ford-A, Dau et al., 2018), and a bivariate example from online handwritten recognition (Pendigits, E. Alpaydin, 1996). For simplicity, across all our experiments we set cost \(C_{t}=t/T\) and only targeted sensitivity level of 0.9. All experiments were repeated 100 times, where for each repeat data were randomly split to create training, validation, and testing sets (70%:10%:20% unless otherwise specified). The classifiers were trained on the training set with the \((,)\) tuned by their performance on the validation set. The final performance were assessed on the testing set and reported. Figure 4.1 pictures the estimated Pareto front, while Figure 4.2 validates the constraints in problem (2.3). We refer to Appendix D for details of the experiments setup.

Apparently the FPR decreases with increased cost, yet interestingly we observe that the reduction of FPR diminished when the average cost exceeded 75% of total sequence length for simulated examples and 50% for the two real data. Recalling that the sensitivity (TPR) were always retained at 0.9, this suggests an oracle possibility for the proposed classifier to achieve performance similar to a full-length classifier (e.g., the horizontal dashed lines in the upper panels of Figure 4.1) but on average utilizing shorter sequences.

It is clear that for the simulated AR(1) examples, the proposed method outperformed the Wald's SPRT by achieving a smaller FPR at the same cost (green curves and the crosses are lower than the white pixels, upper panels of Figure 4.1), yet admittedly not quite for the Ford-A and Pendigits examples. However the key distinction is that the SPRT tended to decide prematurely. Under our setup where sensitivity restricted around 0.9, no SPRT reached an average cost of more than 0.8 in all four examples (even no more than 0.63 for the AR(1)-logistic examples), so that it rushed the decisions and failed to demonstrate the diminishing benefits in FPR of larger cost. Such limitation appears more apparent for harder tasks (e.g., the AR(1) examples) where FPR is higher and/or longer sequences are necessary to achieve an oracle performance.

## 5 Discussion

Several limitations necessitate future research, such as the reliance on the assumptions, the lack of tailored neural network architectures, and the accumulated errors during recursive estimation that potentially caused suboptimality in the presented real data examples. Additionally, generalization across diverse datasets mandates comprehensive validation efforts. Though, instead of extensive benchmarking on diverse data and/or against state-of-the-art methods, our contribution primarily focuses on the feasibility of early decision making under Neyman-Pearson paradigm, which, we hope, could shed new light on early time series classification and its practical applications.

Figure 4.1: Under a desired TPR of 0.9, the estimated Pareto front (green lines and black crosses) in comparison to Waldâ€™s SPRT (red-white-blue pixels) on simulated and real data over 100 repeats. The panels from top left to bottom right show: univariate AR(1) of length 10 and autoregressive correlation 0.75 with logistic or unimodal responses probability; the Ford-A data; and the Pendigits data. The black crosses show 90% interval for the achieved FPR (vertical) and cost (horizontal), while the green lines are the average estimated Pareto fronts pooling repeats. The horizontal dashed lines in the upper panels show, under the same 0.9 TPR restriction, the FPR of full-length classifiers when the true class probability (i.e., \(_{T}\)) is available.

Figure 4.2: The boxplot of the deviance in the achieved v.s. desired cost (varying from 0.1 to 0.9) and TPR (0.9) over the 100 repeated experiments under the setup of Figure 4.1, grouped by the desired cost (x-axis).

## Appendix A Proofs

Proof of Proposition 2.1.: The Lagrangian function of (2.3) is, with the convention that \(f_{0} 0\),

\[(f_{1:T},) =b-a+[(f_{0:T-1}=0)(aC_{T}- _{T}(f_{T}>0))]\] \[+_{t=1}^{T-1}[(f_{0:t-1}=0)(aC _{t}(f_{t} 0)-_{t}(f_{t}>0))]\] (A.1)

for non-negative \(=(a,b)\), where \(\) is a \(\)-adapted process defined in Section 2.

The infimum over \(f\) in \(\) can be taken recursively as \(_{f_{1}}_{f_{2}}_{f_{T}}(f,)\). Thus by (A.1), with the convention that \(_{0} 0\) and \(M_{T+1} 0\), denote

\[L_{t}(f_{1:t},) =[(f_{1:t-1}=0)(_{t}(f_{t }>0)-aC_{t}(f_{t} 0))],\] \[M_{t}(f_{1:t-1},) =_{f_{t:T}}(L_{t}++L_{T})=_{f_{t}} (L_{t}+M_{t+1}(f_{1:t},)).\]

Clearly \(M_{T}(f_{1:T-1},)=[(f_{1:T-1}=0)S_{T}]\) at \(_{T}=_{T}\). Then by induction we claim \(M_{t}(f_{1:t-1},)=[(f_{1:t-1}=0)S_{t}]\) at \(_{t:T}\) of (2.6). Indeed,

\[L_{t}(f_{1:t},)+M_{t+1}(f_{1:t},)\] \[=[(f_{1:t-1}=0)(_{t}( f_{t}>0)-aC_{t}(f_{t} 0)+[S_{t+1} X_{1:t}](f_{t }=0))]\]

for \(t=T-1,T-2,,1\). In the end, note that \(()=b-a-M_{1}\). 

**Proposition A.1** (Feasibility).: _Suppose for \(t=1,,T\), the \(X_{t}\) are continuous r.v. admits density, and \(X_{1:t}_{1:t}\) are continuous functions bounded away from zero, there always exists some \(^{*}\) that maximize problem (2.7). Define \(f^{*}(X)=(X;^{*})\) and \(^{*}\) by plugging-in \(f^{*}\) to (2.1), then \(^{*}\) optimizes problem (2.3) satisfying the constraints by equality, and that \((^{*})=[^{*} Y=0]\)._

proof of Proposition a.1.: First show the concave function \(\) has stationary point(s), then by definition of \(f^{*}\) there is no duality gap. It is not difficult to conclude that almost surely,

\[}{ a} =[C_{t}_{t} 0+C_ {t+1}_{t}=0,_{t+1} 0++C_{T} _{t:T-1}=0 X_{1:t}],\] \[}{ b} =p_{1}^{-1}\,[_{t}_{t}=1 +_{t+1}_{t}=0,_{t+1}=1+ +_{T}_{t:T-1}=0,_{T}=1  X_{1:t}],\] (A.2)

so that \(/ a=[C_{}]-\) and \(/ b=-[ Y=1]\), where \(\) is the rule (2.1) with \(=(X,)\) of (2.6) plugged-in.

Next it suffices to show there exists some \(a^{*}\) and \(b^{*}\) such that zeros the previous two equations utilizing the connectedness of the solution sets \(_{}(a^{*}){:=}\{b:[|_{a^{*}} Y=1]=\}\) and \(_{}(b^{*}){:=}\{a:[C_{}|_{b^{*}}]=\}\). Here \(|_{a^{*}}\) means a plug-in classifier fixing \(a=a^{*}\), similarly \(C_{}|_{b^{*}}\) fixes \(b=b^{*}\).

For any fixed \(b 0\), we can let \(_{t} 0\) for all \(t\) by setting \(a 0\), so that \([C_{}]=C_{T}\). On the other hand, by \([_{T}^{+} X_{1:T-1}]([_{T} X_{1:T-1}] )=_{T-1}^{+}\), there is always some \(a_{T-1}>0\) so that \(S_{T-1}=_{T-1}\) for all \(a a_{T-1}\). Inductively, there exists \(a_{t}>0\) such that \(S_{t}=_{t}\) for all \(a a_{t}\), i.e., \(_{t} 0\), so that \([C_{}] C_{t}\). In other words, one can increase \(a\) from zero, and the expected cost would reduce from \(C_{T}\) to \(C_{1}\). Hence, for any \(b 0\), there always exists some \(a_{b}\) such that \([C_{}]=\), i.e., \(_{}(b)\). Further, by continuity of \(X_{1:t}_{1:t}\), the mapping \(a[C_{}]\) is a continuous non-increasing function, implying \(_{}(b)\) is a closed interval.

Similarly given \(a 0\), note that \( 0\) for \(b<p_{1}/p_{0}(1/_{x}_{t}-1)\) and that \( 1\) for \(b>p_{1}/p_{0}(1/_{x}_{t}-1)\). Thus for any given \(a\) the mapping \(b[ Y=1]\) is a continuous non-decreasing function, hence \(_{}(a)\) is also closed interval.

Further, the continuity of \((a,b)[C_{}]\) implies that \(A_{}{:=}\{(a,b):b_{}(a)\}\) is a non-empty connected set, similarly \(A_{}{:=}\{(a,b):a_{}(b)\}\) is also non-empty and connected. In combine \(a^{*}\) and \(b^{*}\) that zero out (A.2) exist since \(A_{}\) and \(A_{}\) must intersect.

In sum, \(f^{*}=(^{*})\) is a feasible solution to problem (2.3) that satisfies the constraints by equality. It then suffices to show strong duality by showing that \((f^{*},^{*})\) is a saddle point of \(\), i.e., \((f^{*},)(f^{*},^{*})(f, ^{*})\) for any \(a,b 0\), and \(\)-adapted \(f\). The second inequality is obvious by definition of \(f^{*}=(^{*})\). For the first inequality, by definition of Lagrangian function, \((f,)[ Y=0]\) for all \(a,b\), and any feasible \(f\) (and corr. \(\)). Moreover, \((f^{*},^{*})=[^{*} Y=0]\) since \(f^{*}\) satisfies the constraints of problem (2.3) by equality. In combine we have \((f^{*},)[^{*} Y=0]=(f^{* },^{*})(f,^{*})\), implying that \((f^{*},^{*})\) is a saddle point for \(\).

proof of Theorem 2.1.: This is a direct implication of Proposition A.1 under Theorem 3.2.2 in part II of Miettinen (1999). Technically, it suffices to repeat the previous steps with some reparameterization of the \(a^{*}\) and \(b^{*}\) to see that \(^{*}\) also optimizes

\[\ [C_{}],\ \ [_{}  Y=0]\ \ [_{} Y=1]\] (A.3)

for \(=[^{*} Y=0]\). I.e., the performance of \(^{*}\) in terms of the objectives in problem (2.3) cannot be further improved in either direction without sacrificing another. 

## Appendix B Remarks on the Neural Networks Plug-in

Note that one shall not use the bidirectional RNNs which also utilize future information, violating the \(\)-adapted requirement.

It is important to note that \(_{},a,b,\) and \(S\) are treated as constant in \(Q_{}\), so are \(_{}\), \(_{}\), and \(S\) in \(}\). In other words, \((a,b)\) are not updated when computing \(_{}\), so is \(_{}\) not updated when computing \((a,b)\). Furthermore, gradient shall not flow through \(S_{t+1}\) in \(Q_{}\), and not through \(\), \(\), and \(S\) in \(}\) despite implicit dependency. For backpropagation we utilize the gradients in (A.2) so \(}/ a=[C_{}]-\) and \(}/ b=-[  Y=1]\); i.e., the average cost and true positive rate of the plugged-in rule.

In the typical task of estimating the Pareto front for some pre-specified sensitivity level of \(\), it suffices to initialize Algorithm 1 with small but gradually increasing \(\) (or vice versa), and record the results. While in theory \(0, 1\), we found it practically convenience to allow greater upper bounds for better performance. Similarly \(a,b\) are allowed to be negative.

## Appendix C Wald's Sequential Probability Ratio Test

Wald's SPRT was originally proposed based on cutoffs determined by the desired type I and II error rate upon the cumulative product of probability ratio for i.i.d. observations (Wald, 1947). For binary time series classification, it suffices to impose cutoff on \(_{t}\), noting that \(P(X_{1:t}|Y=0)/P(X_{1:t}|Y=1)(1-_{t})/_{t}\). We adopted a truncated SPRT (see Wald, 1947, section 3.8) to account for the finite horizon situation. In sum, we write \(_{}\) following (2.1) where \(f_{T,}=1\) if \(_{T}(Y=1)\) and \(-1\) otherwise; while for \(t T-1\),

\[f_{t,}=1,\ _{t}>,\\ -1,\ _{t}<,\\ 0\ ,\]

for some cutoffs \(0<<<<1\). To account for the impact of non-iid sequence and truncation, among a grid of \((,)\)-pairs, those admit validation TPR closest to the desired level (deviation smaller than 0.01) were selected and evaluated on test sample for cost, TPR, and FPR.

We re-used the existing neural network estimate \(\) for SPRT.

## Appendix D Additional Experiment Details

1. For the two AR(1) examples, \(X_{1},,X_{10}\) is a stationary univariate AR(1) process of length 10 with standard Gaussian innovation and a correlation coefficient of 0.75; while \(E(Y|X_{1:T})\) equals \((c_{t}X_{t})\) (i.e., the logistic example) or \((-c(_{t}X_{t})^{2})\) (the unimodal example). We generated 5120, 1280, and \(10^{4}\) series for training, validating, and testing respectively.
2. The Ford-A dataset includes sensor data with 500 time points and a binary response for 3601 instances. The time series were down-sampled to \(T=50\) by block: every 10 consecutive time points are pooled as a 10-dimensional covariate. It provides an example to showcase the multivariate capability of the proposed framework.
3. The Pendigits data (E. Alpaydin, 1996) consists of 10992 series of 2-dimensional coordinates of pen strokes when writing digits (downsampled to 8 points) and we relabeled the outcome to whether the digit written is 1, 2, 3, 5, 7.

We implemented the proposed method with Pytorch. Both \(\) and \(\) were modeled by a single layer GRU with 16 hidden features, followed by a time-specific, single-layered fully connected linear layer to provide scalar prediction, totaling around 2000 parameters.