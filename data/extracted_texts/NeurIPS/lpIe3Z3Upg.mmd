# Permute-and-Flip: An optimally stable and watermarkable decoder for LLMs

Xuandong Zhao

UC Berkeley

xuandongzhao@berkeley.edu

&Lei Li

Carnegie Mellon University

leili@cs.cmu.edu

&Yu-Xiang Wang

UC San Diego

yuxiangw@ucsd.edu

###### Abstract

In this paper, we propose a new decoding method called Permute-and-Flip (PF) decoder. It enjoys stability properties similar to the standard sampling decoder, but is provably up to 2x better in its quality-stability tradeoff than sampling and never worse than any other decoder. We also design a cryptographic watermarking scheme analogous to Aaronson (2023)'s Gumbel watermark, but naturally tailored for PF decoder. The watermarking scheme does not change the distribution to sample, while allowing arbitrarily low false positive rate and high recall whenever the generated text has high entropy. Our experiments show that the PF decoder (and its watermarked counterpart) significantly outperform(s) naive sampling (and its Gumbel watermarked counterpart) in terms of perplexity, while retaining the same stability (and detectability), hence making it a promising new approach for LLM decoding.

## 1 Introduction

Large language models (LLMs) (OpenAI, 2022, 2023, Bai et al., 2022, Touvron et al., 2023) have become increasingly popular in recent years due to their ability to generate human-like text and solve many tasks through a natural chatbot interface.

A language model predicts the next word in a sentence using a real-value function \(u(;,):\), known as _logits_, which encodes the model's preferences on which word to choose. Here \(\) is the vocabulary space (typically a large discrete set of words); the "prompt" describes the task of interest; and "prefix" includes all preceding words that have been generated so far. A language model _decoder_ refers to a possibly randomized function that takes a prompt text \(x\), API access to the _logits_ function as input, and outputs a sentence \(y_{1:n}\).

**The main thrust of this paper** is to introduce a new decoder, termed _Permute-and-Flip decoding_, work out some of its intriguing properties with an application to watermarking LLM text, and hopefully convince readers that it deserves a shot at your next LLM application.

## 2 Problem Setup and Summary of Results

Before diving in, let's set up the stage with a quick tour of existing decoding methods and have a brief look into how a language model decoder can be evaluated.

**Popular existing decoding methods**: fall into three categories: (1) Planning-based methods such as beam search that aims at maximizing the sequence likelihood; (2) sampling-based methods that recursively sample from the next-word distribution, e.g., the soft(arg)max transform of the logits

\[\,y_{t} p(y)=)/T}}{ _{}e^{u(|x,y_{1:t-1})/T}}\] (1)where \(T\) is the _temperature_ parameter; and (3) greedy methods such as greedy decoding that simply outputs \(y_{t}=_{y}u(y|x,y_{1:t-1})\) as well as its Top \(p\)[Holtzman et al., 2019] and Top \(k\) sampling variants that interpolate greedy and sampling methods.

Performance metrics.How do we compare different decoding methods? More generally, how do we evaluate LLM-generated text? These are questions far from being settled. Naturally, if there is a (possibly task-dependent) performance metric \(U_{x}:^{n}\) one can define, then the optimal decoder would be the one that outputs \(y_{1:n}^{*}=_{y_{1:n}^{n}}U_{x}(y_{1:n})\). Often \(U_{x}\) is instantiated to be the sequence likelihood \(_{t=1}^{n} p(y_{t}|x,y_{1:t-1})\) which is equal to \(_{t=1}^{n}u_{t}(y_{t})\).

Recent works [Ippolito et al., 2019, Winer et al., 2022], however, report that strategies that aim at maximizing sequence likelihood often result in texts that are more repetitive and less effective in some downstream tasks than those from the sampling-based methods [Holtzman et al., 2019]. Depending on what the task is, there is not a one-size-fits-all performance metric, therefore is no single decoding method that works well for all tasks.

For the moment, let us stash the disputes on how to best evaluate an LLM-generated text and focus on designing methods that maximize any user-specified utility function. In fact, we will also give up on solving the sequence-level utility maximization problem1 and simply maximize a _per-step_ utility function \(u_{t}:\).

\(u_{t}\) can simply be the logits function that LLMs output, which may have already accounted for potential future utility (like the \(Q\) function in reinforcement learning) since the transformer-based language model had access to future texts during pre-training. Or \(u_{t}\) can be explicitly augmented with structure-inducing regularizers such as a lookahead heuristic as in A* decoding [Lu et al., 2021], a retrieval-based term for fact-checking [Lewis et al., 2020], or an entropy bonus for promoting diversity [Meister et al., 2020].

Our goal is thus to construct a possibly randomized algorithm \(\) that takes \(u_{t}\) as an input and outputs \(y_{t}\) that aims at maximizing \(_{y_{t}_{u_{t}}}[u_{t}(y_{t})]\) as much as possible. In the remainder of the paper, we will simply take \(u_{t}\) as "logits" for a concrete exposition -- all results are valid when \(u_{t}\) is instantiated otherwise.

Other constraints / consideration.Why doesn't the trivial greedy decoder work? That's because there are other considerations besides text quality when selecting LLM decoders. For example, **computational efficiency and latency** are hugely important, since each API call to the _logits_ function is costly. The **diversity** of the generated text is also important, especially for creative tasks.

Moreover, the decoding procedure should be **watermarkable**[Aaronson, 2023, Kirchenbauer et al., 2023, Zhao et al., 2023, Kuditipudi et al., 2023] in the sense that one should be able to inject subtle statistical signals that can be retrieved when given a secret key, to _prove_ that the text is generated by this particular language model. Being watermarkable prevents the LLM from being used for malicious purposes such as scams [Weidinger et al., 2021], fake news [Zellers et al., 2019], and plagiarism [Stokel-Walker, 2022].

In addition to the above, one may also hope the decoding algorithm to be **stable against small perturbations** to the _logits_. Specifically,

**Definition 2.1** (Stability).: We say a decoding algorithm \(\) is \(L\)-stable if for any prompt \(x\), prefix \(y_{ t}\), and for any perturbed \(\) such that \(\|-u\|_{}\), the log-probability ratio satisfies

\[|\{((|x,y_{ t}))}(y)}{p_{ (u(|x,y_{ t}))}(y)}\}| L\ \  y .\]

The stability helps to avoid catastrophic failure in the scenarios where the logits may be subject to data poisoning [Zhang et al., 2021, Lin et al., 2021] or jailbreaking attacks [Zhang et al., 2023, Zhao et al., 2024b]. Furthermore, _stability_ implies an intuitive notion of _diversity_, suggesting that tokens with similar logits should have comparable probabilities of being selected. For further discussion and examples, please refer to Appendix C.

Inspecting the decoding methods along the aforementioned dimensions, we notice that planning-based methods fail to be computationally efficient. While greedy decoding is efficient and has relatively low perplexity, its generated texts are neither diverse nor watermarkable (at least not using existing techniques). The sampling-based methods, however, are both watermarkable and diverse. In addition, softmax sampling is known to be \(2\)-stable, while the others that we have discussed are not stable.

**Fact 2.2**.: _Softmax sampling decoding using (1) with temperature \(T\) satisfies \((2/T)\)-stability._

Proof.: The result is implied by the differential privacy guarantee of exponential mechanism (McSherry and Talwar, 2007, Theorem 6). 

The pros and cons of different decoding methods are summarized in Table 1. From the table, we can see that there is a clear tradeoff between minimizing perplexity and preserving other properties. In particular, softmax sampling is the only method that checks all boxes, and the only one that is stable among existing decoders. This observation begs the following research question: _Is there a decoding method that is as stable as softmax sampling, but has lower perplexity?_

In this paper, we answer this question affirmatively by bringing in a technique called Permute-and-Flip sampling. Our contributions are fourfold.

1. We introduce Permute-and-Flip decoding -- a new decoding algorithm for language models based on recent development in a very different context (McKenna and Sheldon, 2020).
2. We demonstrate that existing results from McKenna and Sheldon (2020) already imply that:

* Permute-and-Flip decoding is provably stable.
* The stability-perplexity tradeoff of the PF decoding is Pareto-optimal. In particular, when compared to softmax sampling, PF decoding has up to 2x smaller expected suboptimality while having the same stability parameter \(L\).
3. We designed an analog of Aaronson (2023)'s Gumbel-Watermark for PF decoder, called the PF watermark. We show that the watermarked PF decoder samples from a distribution that is computationally indistinguishable from the non-watermarked PF decoder, and the detection procedure has precisely controlled false positive rate (FPR) and high power in identifying watermarked texts.
4. We empirically demonstrate that on open-generation tasks, PF watermark achieves the best balance of the highest detection accuracy and lowest perplexity compared to the baselines.

Overall, our proposed permute-and-flip decoding method provides a promising approach to balancing the tradeoff between perplexity and stability in LLM decoding while also admitting watermarking capabilities.

Related work and novelty.PF sampling was invented in the differential privacy (DP) literature (McKenna and Sheldon, 2020). Its stability properties are well-understood. The stability of Softmax sampling is also well-known (McSherry and Talwar, 2007). Our contribution is in applying this method to LLM decoding and connecting these known theoretical results to the broader ML audience. To our knowledge, the PF watermark is new to this paper. The design of the watermark leverages the Report-Noisy-Max interpretation of the PF sampling (Ding et al., 2021) which allows a similar pseudo-random function like the work of Aaronson (2023) to be applied. A more thorough discussion of the related work is given in Appendix A.

## 3 Permute-and-Flip Decoding its Properties

The Permute-and-Flip decoding iteratively generates the next token by a simple procedure that uses only the logits. It involves first randomly permuting the vocabulary, then flipping a sequence of biased coins according to the permuted sequence until the first "head" is seen (see Algorithm 1).

   Methods & Perplexity & Computational Efficiency & Diversity & Watermark & Stability \\  Search (e.g., Beam) & Lowest & ✗ & ✗ & ✗ \\ Greedy & Low & ✓ & ✗ & ✗ & ✗ \\ Softmax Sampling & Moderate & ✓ & ✓ & ✓ & ✓ \\ Top-\(p\) Sampling & Low (for small \(p\)) & ✓ & Depends on \(p\) & ✓ & ✗ \\ Top-\(k\) Sampling & Low (for small \(k\)) & ✓ & Depends on \(k\) & ✓ & ✗ \\  PF Sampling (ours) & Lower than Softmax & ✓ & ✓ & ✓ & ✓ \\   

Table 1: Comparison of different decoding methods against five desiderata.

ducing \(y^{*}\).

PF sampling was initially proposed in McKenna and Sheldon (2020) as a differentially private selection mechanism that has better utility than the more well-known exponential mechanism (McSherry and Talwar, 2007). McKenna and Sheldon (2020) also derived a plethora of theoretical properties of the PF sampling. The following theorem summarizes these results in the language of LLM decoding.

**Theorem 3.1**.: _Let the logits function be \(u\) and \(u^{*}=_{y}u(y)\). Let \((u)\) be the distribution of PF-sampling, and \((u)\) be the distribution in (1), both with temperature parameter \(T\). The following statements are true._

1. _(_**Same stability**_) PF-Sampling is_ \((2/T)\)_-stable._
2. _(_**Nearly greedy**_) PF-sampling obeys,_ \(_{y(u)}[u(y)] u^{*}-T||\)_._
3. _("_**Never worse"**_) For the same_ \(T\)_, PF-sampling is never worse than Softmax-sampling._ \[*{}_{y(u)}[u(y)]*{ }_{y(u)}[u(y)]\]
4. _("_**Up to 2x better"**_) There exists logits_ \(u\) _such that PF-sampling is 2x smaller in terms of suboptimality,_ \(_{y(u)}[u^{*}-u(y)]\,_{y (u)}[u^{*}-u(y)]\)_._
5. _(_**Optimal stability-perplexity tradeoff**_) For any decoder_ \(P\) _that is_ \(2/T\)_-stable, if there exists_ \(u\) _such that_ \(_{y P(u)}[u(y)]>_{y(u)}[u(y)]\) _then there must be another_ \(\) _such that_ \(_{y P()}[(y)]<_{y()}[(y)]\)_._

Proof.: The theorem follows directly from McKenna and Sheldon (2020), specifically Theorem 1, Corollary 1, Theorem 2, Proposition 4, and Proposition 6. 

The first statement shows that the PF decoder enjoys exactly the same stability parameter as in Fact 2.2. The second statement provides a worst-case bound on how far PF-sampling is away from greedy-decoding as a function of the temperature \(T\) in terms of the likelihood achieved. The third and fourth statements show that PF-sampling is always "more greedy" than softmax-sampling. The last statement shows that PF-sampling is not dominated by any other decoder that is equally stable (as in Definition 2.1), thus _Pareto optimal_. These results provide strong justification on the superiority of the permute-and-flip decoder over the standard softmax sampling in minimizing perplexity.

Let's consider a simple example to compare PF decoder and Softmax decoder.

**Example 3.2**.: Let the \(||=2\) and the corresponding logits be \([,0]\) for gap \(>0\). Softmax decoder chooses the suboptimal token with probability \(1/(1+e^{/T})\), while PF decoder chooses it w.p. \(1/(2e^{/T})\).

Since \(1/(1+x)>1/(2x)\) for all \(x>1\), the probability that the suboptimal token is chosen in PF sampling is strictly smaller than that of Softmax sampling. As shown in Figure 1, the left, we fix the Gap

Figure 1: Comparing PF decoder vs Softmax decoder using Example 3.2 shown in Figure 1, the left, we fix the Gap

\(=3.0\) and vary the temperature \(T\). On the right, we fix \(T=1.0\) and vary \(\). PF beats Softmax in all cases.

## 4 Report-Noisy-Max and Watermarking

Next, we turn to the well-motivated problem of watermarking LLM generated text. The watermarking problem aims at embedding a secret message in the generated text that (essentially) reads "Beware! I am written by an AI!". The hope is that this message can be seen by anyone who has access to a _secret key_, while ensuring that the watermarked version of the LLM generates text that has _almost the same_ distribution as (or at least very similar) to the original LLM.

More formally, a watermarking scheme includes a "Watermark" function that injects the watermark and a "Detect" function that takes a suspect text sequence \(y_{1:n}\) as input and outputs a prediction of \(1\) ("It is watermarked!") or \(0\) ("It is not!"). A wrong accusation of non-watermarked text as watermarked is called a _false positive_. A failure to detect a watermarked text is called a _false negative_. The performance of a watermark is measured by its detection _power_ (i.e., \(1\)_-false negative rate_) at a given _false positive rate_.

There are many other necessary properties for a watermarking scheme to be useful, such as _low-overhead_, _model-agnostic_ detection, and _resilience to edits_ and other evasion attacks. We refer readers to the slide deck of Aaronson (2023) and the related work section of (Zhao et al., 2024) for a review of these desiderata and known results. Among the recent attempts, two popular watermarking schemes perform satisfactorily on all the above criteria.

**Gumbel Watermark Aaronson, 2023**: that uses a "traceable" pseudo-random softmax sampling when generating the next word.
**Green-Red Watermark Kirchenbauer et al., 2023**: that randomly splits the vocabulary into Green and Red then slightly increases the logits for green tokens.

Both of them determine their pseudo-random seeds chosen according to the \(m\) preceding tokens of the current token being generated. We will focus on explaining the Gumbel watermark as it is more closely related to our approach.

**Aaronson (2023)'s Gumbel watermark.** The key idea of the Gumbel watermark leverages the "Gumbel-Max Trick", which states that:

**Fact 4.1**(Gumbel, 1948).: _The softmax sampling in (1) is equivalent to the following procedure_

\[y_{t}=*{arg\,max}_{y}(y)}{T}+G_{t}(y)\] (2)

_where \(G_{t}(y)(0,1)\) i.i.d for each \(t,y\)._

Gumbel noise can be generated using a uniform r.v.

\[(0,1)-((1/())).\]

So given a random vector \(r_{t}(())^{||}\), we can write \(G_{t}(y)=-(-(r_{t}(y)))\).

The Watermark stage for the Gumbel-watermark essentially replaces \(()\) with a _pseudo-random function_\(r_{t}(y)=F_{y_{t-m:t-1},}(y)\). Given the secret key \(\), the _pseudo-random function_ is a deterministic function with range \(^{}\), but over the distribution of the secret key \(\), \(r_{t}\) is computationally indistinguishable from sampled from truly i.i.d. uniform distribution, which ensures that the distribution of \(y_{t}\) in the watermarked model is computationally indistinguishable to the unwatermarked distribution (1).

At Detect phase of the the Gumbel watermark, the auditor who has access to the key \(\) may compute

\[_{}(y_{1:n})=_{t=m+1}^{n}-(1-r_{t}(y_{ t})).\]

If \(y_{1:n}\) is _not_ generated from the watermarked model, then the test statistic is a sum of exponential random variable thus \([(y_{1:n})]=n-m\). Meanwhile, if \(y_{1:n}\) is generated by the Gumbel watermarked model, \([(y_{1:n})]=_{t=m+1}^{n}[_ {y}p_{t}(y)H_{(y)}}]\) (3)\((n-m)+(}{6}-1)_{t=m+1}^{n}[[p_{t}()]],\) where \(p_{t}:=(u_{t})\), \(H_{}:=_{0}^{}}{1-x}dx\) is Euler's Harmonic number and Entropy denotes the standard Shannon entropy (in nats) for a discrete distribution, i.e., \([p]=-_{y}p(y) p(y)\).

Permute-and-Flip as ReportNoisyMax.It turns out that the Permute-and-Flip sampling has a similar equivalent Report-Noisy-Max form. Instead of Gumbel noise, it is the exponential noise that are added to the logits. This less-known fact is due to Ding et al. (2021)

**Fact 4.2** (Ding et al., 2021, Theorem 5).: _Permute-and-Flip Sampling in Algorithm 1 with parameter \(T\) is equivalent to_

\[y_{t}=*{arg\,max}_{y}(y)}{T}+E_{t}(y).\] (4)

_where \(E_{t}(y)(1)\) i.i.d. for each \(t,y\)._

Leveraging this fact, in the remainder of the section, we develop a watermarking scheme for Report-NoisyMax that is analogous to the Gumbel-watermark.

Permute-and-Flip watermark.The natural idea is to replace the exponential noise \(E_{t}(y)\) with a pseudo-random version that depends on a secret key and a prefix with length \(m\). Observe that \((1)-(())\), thus the standard pseudo-random function that generates uniform random variables can be used. In the detection phase, we compute:

\[_{}(y_{1:n})=_{t=m+1}^{n}-(r_{t}(y_{t})).\]

Note that this is a simple change of sign of \(r_{t}(y_{t})\) comparing to the test score of the Gumbel watermark. Detailed pseudo-code for how the watermark works are given in Algorithm 2 and Algorithm 3.

```
1:Preparation: Randomly sample a watermark key k
2:Input: Prompt \(x\), language model \(\), pseudo-random function \(F\), watermark key k, temperature \(T\)
3:for\(t=1,2,\)do
4: Compute logits: \(u_{t}([x,y_{1:t-1}])\)
5: Generate a pseudo-random vector \(r_{t}()\) using \(r_{t}(y):=F_{y_{t},m,t-1}(y)\) for \(y\)
6: Select the next token \(y_{t}\) using \[y_{t}=*{arg\,max}_{y}((y)}{T}- r _{t}(y))\] (5)
7:endfor
8:Output: Watermarked sequence \(y=[y_{1},...,y_{n}]\) ```

**Algorithm 2** PF watermarking: Watermark

**Theorem 4.3**.: _Assume the pseudo-randomness is perfect2, i.e., \(F_{w_{1:m},}(y)()\) i.i.d. \([w_{1:m},y]^{m+1}\)._

_The following are true about PF watermark scheme._

1. _If_ \(y_{1:n}\) _is_ statistically independent _to the secret key_ \(\)_,_ \([_{}(y_{1:n})|y_{1:n}]=n-m\)_._
2. _If in addition, all_ \(m\)_-grams in_ \(y_{1:n}\) _are unique, then conditioning on_ \(y_{1:n}\)_,_ \(_{}(y_{1:n})(n-m,1)\)_. The choice_ \(=_{(n-m,1)}^{-1}(1-)\) _ensures the false positive rate in Algorithm_ 3 _is equal to_ \(\)_._
3. _Assume_ \(y_{1:n}\) _is drawn from Algorithm_ 2_, then_The above expression in (7) may appear messy, but it is the exact calculation and captures the entropy of the distribution PF-induces for a given \(u_{t}\). To see this, let us instantiate the bound for two special cases that admit more explicit forms. We show that in Appendix B.

In conclusion, we showed that the watermarked version of PF-decoder is computationally indistinguishable from the original version of PF-decoder. Meanwhile, the test score of the PF watermark is qualitatively similar to that of the Gumbel-watermark (and identical in some cases). It is likely to produce similar detectability to the Gumbel watermark, while enjoying the performance boost that comes from replacing softmax sampling with PF.

## 5 Experiments

**Datasets and models.** We utilize two long-form text datasets in our experiments: the Colossal Clean Crawled Corpus (C4) dataset (Raffel et al., 2020) for open-ended text completion generation, and the Alpaca dataset (Taori et al., 2023) for question-answering tasks. Our primary language model is the state-of-the-art open-source model Llama-2 with 7 billion parameters. Specifically, we use the Llama-2-7B-chat model for question-answering tasks on the Alpaca dataset. For text completion tasks on the C4 dataset, we employ the base model Llama-2-7B. Furthermore, to evaluate the universal applicability of smaller models, we also assess the performance of the TinyLlama-1.1B model3(Zhang et al., 2024).

**Evaluation metrics.** We calculate perplexity scores from different models, using Llama2-7B to compute PPL1 and Llama2-13B to compute PPL2. We also compute MAUVE scores to measure the distributional similarity between model generations and human text as another metric for text quality (Pillutla et al., 2021). To evaluate repeitiveness, we compute seq-rep-5 across generations, which is the average repetition rate of duplicate 5-grams in a sequence (Welleck et al., 2019). For the watermark evaluation, maintaining a low false positive rate is crucial to avoid misclassifying unwatermarked text as watermarked. Therefore, we set the false positive rates at 1% and 10% for all watermark detection algorithms, adjusting the detection threshold accordingly. We report true positive rate (TPR) and F1 scores to measure the watermark detectability. We compared the well-known Gumbel Watermark (Gumbel WM) and Green-Red Watermark (KGW WM) as our main baselines. Experiments were conducted using Nvidia A600 GPUs. For the details of the experiment setting, please refer to the Appendix D.

**Text generation performance.** Table 2 shows the text perplexity of generated samples from different LLMs evaluated on two datasets. Using the same temperature, we find that PF decoding produces significantly lower perplexity compared to sampling. Although greedy decoding has the lowest perplexity, it suffers from heavy repetition, as indicated by its high seq-rep-5 score and low MAUVE score. We observe that for question-answering tasks, the perplexity is lower, likely due to the fixed form of answers and lower entropy of the text generation. Table 8 shows an example prompt and responses generated by different decoding methods.

  
**Method** & **AUC1** & **TPR1** & **PPL2** & **Seq-rep-5** & **MAUVE** & **Method** & **AUC1** & **TPR1** & **PPL1** & **Seq-rep-5** & **MAUVE** \\ 
**C4, T-10, Llama2-7B** & & & & & **C4, T-0, Llama2-7B** & & & & & & \\ Greedy & - & - & 1.14\({}_{0.1}\) & 1.24\({}_{0.01}\) & 0.56 & 0.05 & Greedy & - & - & 1.28\({}_{0.16}\) & 1.75\({}_{0.03}\) & 0.12 & 0.93 \\ Sampling & - & 1.24\({}_{0.21}\) & 1.5\({}_{0.31}\) & 0.02 & 0.98 & Sampling & - & - & 2.43\({}_{0.48}\) & 4.91\({}_{0.03}\) & 0.06 & 1.00 \\ PF & - & - & 8.9\({}_{0.42}\) & 1.75\({}_{0.23}\) & 0.03 & 0.90 & PF & - & 3.54\({}_{0.46}\) & 4.11\({}_{0.08}\) & 0.10 & 0.92 \\ KGW WM & 0.989 & 0.991 & 1.66\({}_{0.38}\) & 2.06\({}_{0.20}\) & 0.61 & 1.00 & KGW WM & 0.995 & 0.991 & 5.73\({}_{0.68}\) & 6.71\({}_{0.11}\) & 0.03 & 0.99 \\ Gumbel WM & 0.997 & 0.988 & 11.4\({}_{12.36}\) & 1.24\({}_{12.36}\) & 0.04 & 0.93 & Gumbel WM & 0.993 & 0.982 & 4.03\({}_{0.47}\) & 4.17\({}_{0.10}\) & 1.00 & 1.00 \\ PF WM & 0.995 & 0.984 & 8.3\({}_{3.20}\) & 10.28\({}_{0.29}\) & 0.05 & 0.99 & PF WM & 0.993 & 0.980 & 3.38\({}_{0.37}\) & 3.99\({}_{0.10}\) & 0.13 & 1.00 \\ 
**Alpaca, T-10, Llama2-7B** & & & & & **Alpaca, T-10, TinyLlama-1.1B-Chat** & & & & & & & \\ Greedy & - & 1.28\({}_{0.02}\) & 1.75\({}_{0.03}\) & 0.12 & 0.93 & Greedy & - & - & 1.41\({}_{0.14}\) & 1.66\({}_{0.02}\) & 0.30 & 0.99 \\ Sampling & - & - & 1.74\({}_{0.02}\) & 2.41\({}_{0.04}\) & 0

**Watermarking results.** We compare the results of our proposed PF watermarking method with those of the Gumbel Watermark (Gumbel WM) and the Green-Red watermark (KGW WM). In Figure 1(a), we present the distribution of detection scores for the PF watermark. The PF watermark demonstrates clear detectability between positive and negative samples. The results of the watermark generation are shown in Table 2 and Figure 1(b). The PF watermark achieves the best balance of the highest detection accuracy and lowest perplexity, compared to the KGW WM and the Gumbel WM. Notably, the perplexity of the PF watermark is close to that of the PF sampling, indicating that the watermarking process does not significantly impact the quality of the generated text. All watermarking methods achieved near-perfect detection accuracy on the C4 dataset. Besides, the detection results for the small TinyLlama model are also good, demonstrating the universal applicability of the PF watermark.

**Controlling the false positive rate.** The key strength of PF watermark is its ability to precisely control the false positive rate (FPR) during detection. We validate this by conducting experiments using negative examples from diverse datasets (C4, Alpaca, unwarmarked) and different random keys. As Figure 3 shows, the empirical false positive rates align tightly with the theoretical \(\) values across different settings. This demonstrates PF watermark's effectiveness in controlling the FPR as intended.

**Additional watermarking results.** For a text watermarking design to be effective, it should be able to withstand paraphrasing attacks that an adversary may attempt to modify the watermarked text. Furthermore, the watermark should be detectable even with shorter text lengths. In Appendices D.1.1 and D.2.2, we present additional empirical results for the PF watermark, demonstrating its robustness to paraphrasing and editing attacks. The results also show that the PF watermark can still be detected even when the length of the text is reduced to only 30 tokens.

## 6 Conclusion

We introduce Permute-and-Flip (PF) decoding, a new decoding method for large language models that enjoys the same - perturbation-stability guarantees as softmax sampling while achieving substantially lower perplexity. We design a tailored watermarking scheme (PF watermark) for PF decoding that enables precise control over false positive rates while retaining high true positive rates. Our experiments demonstrate that the PF watermark achieves the best balance of the highest detection accuracy and lowest perplexity. All these intriguing properties make PF decoding a promising new approach for practical applications of large language models.

Figure 3: Comparison of empirical and theoretical false positive rates with different watermark keys. We can see that the second statement of Theorem 4.3 correctly controls the Type I error in practice.

Figure 2: Comparison of PF and Gumbel watermarks on real data.