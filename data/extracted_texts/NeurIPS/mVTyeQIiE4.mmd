# Hierarchical Gaussian Mixture based Task Generative Model for Robust Meta-Learning

Yizhou Zhang\({}^{1}\), Jingchao Ni\({}^{2}\)\({}^{+}\), Wei Cheng\({}^{3}\), Zhengzhang Chen\({}^{3}\), Liang Tong\({}^{4}\),

Haifeng Chen\({}^{3}\), Yan Liu\({}^{1}\)

\({}^{1}\)University of Southern California \({}^{2}\)AWS AI Labs

\({}^{3}\)NEC Laboratories America \({}^{4}\)Stellar Cyber Inc.

\({}^{1}\){zhangyiz,yanliu.cs}@usc.edu; \({}^{2}\)nijingchao@gmail.com;

\({}^{3}\){weicheng,zchen,haifeng}@nec-labs.com; \({}^{4}\)ltong@stellarcyber.ai

This work was done primarily at NEC Laboratories America. \({}^{1}\)Corresponding author.

###### Abstract

Meta-learning enables quick adaptation of machine learning models to new tasks with limited data. While tasks could come from varying distributions in reality, most of the existing meta-learning methods consider both training and testing tasks as from the same uni-component distribution, overlooking two critical needs of a practical solution: (1) the various sources of tasks may compose a multi-component mixture distribution, and (2) novel tasks may come from a distribution that is unseen during meta-training. In this paper, we demonstrate these two challenges can be solved jointly by modeling the density of task instances. We develop a meta-training framework underlain by a novel Hierarchical Gaussian Mixture based Task Generative Model (HTGM). HTGM extends the widely used empirical process of sampling tasks to a theoretical model, which learns task embeddings, fits the mixture distribution of tasks, and enables density-based scoring of novel tasks. The framework is agnostic to the encoder and scales well with large backbone networks. The model parameters are learned end-to-end by maximum likelihood estimation via an Expectation-Maximization (EM) algorithm. Extensive experiments on benchmark datasets indicate the effectiveness of our method for both sample classification and novel task detection.

## 1 Introduction

Training models in small data regimes is of fundamental importance. It demands a model's ability to quickly adapt to new environments and tasks. To compensate for the lack of training data for each task, meta-learning (_a.k.a._ learning to learn) has become an essential paradigm for model training by generalizing meta-knowledge across tasks . While most existing meta-learning approaches were built upon an assumption that all training/testing tasks are sampled from the same distribution, a more realistic scenario should accommodate training tasks that lie in a mixture of distributions, and testing tasks that may belong to or deviate from the learned distributions. For example, in recent medical research, a global model is typically trained on the historical medical records of a certain set of patients in the database . However, due to the uniqueness of individuals (_e.g._, gender, age, genetics) , patients' data have a substantial discrepancy, and the pre-trained model may demonstrate significant demographic or geographical biases when testing on a new patient . This issue can be mitigated by personalized medicine approaches , where each patient is regarded as a task, and the pre-trained model is fine-tuned (_i.e._, personalized) on a support set of a few records collected in a short period (_e.g._, a few weeks) from every patient for adaptation. In this case, the training tasks (_i.e._, patients) could be sampled from a mixture of distributions (_e.g._, different agegroups), and a testing task may or may not belong to any of the observed groups. Similar examples can be found in other applications such as the detection of fake news dissemination [7; 55; 57], where a task is a post, whose support set consists of a few profiles of users who have disseminated it in a short period. The training posts may be drawn from a mixture of topics, and a testing post may not belong to any of the topics. As such, a meta-training strategy that is able to fit a model to a mixture of task distributions and enable the identification of novel tasks during inference time is desirable for making meta-learning a practical solution.

One way to tackle the mixture distribution of tasks is to tailor the transferable knowledge to each task by learning a task-specific representation [33; 48; 25], but as discussed in , the over-customized knowledge prevents its generalization among closely related tasks (_e.g._, tasks from the same distribution). The more recent methods try to balance the generalization and customization of the meta-knowledge by promoting _local generalization_ either among a cluster of related tasks , or within a neighborhood in a meta-knowledge graph of tasks . Neither of them explicitly learns the underlying distribution from which the tasks are generated, rendering them infeasible for detecting novel tasks that are out-of-distribution. However, detecting novel tasks is crucial in high-stake domains, such as medicine and finance, which provides users (_e.g._, physicians) confidence on whether to trust the results of a testing task or not, and facilitates downstream decision-making.

In , a task-specific tuning variable was introduced to modulate the initial parameters learned by the optimization-based meta-learning method MAML , so that the impacts of the meta-knowledge on different tasks are adjusted differently, _e.g._, novel tasks are less influenced than the known tasks. Whereas, this method focuses on improving model performance on different tasks (either known or novel), but neglects the critical mission of detecting which tasks are novel. In practice, providing an unreliable accuracy on a novel task, without differentiating it from other tasks may be meaningless.

Since the aforementioned methods cannot simultaneously handle the mixture distribution of tasks and novel tasks, a practical solution is in demand. In this work, we consider tasks as instances, and demonstrate the dual problem of modeling the mixture of task distributions and detecting novel tasks are two sides of the same coin, _i.e._, density estimation on task instances. To this end, we propose a Hierarchical Gaussian Mixture based Task Generative Model (HTGM) to explicitly model the generative process of task instances. Our contributions are summarized as follows.

* We extended the widely used empirical process of generating tasks to a theoretical process specified by a hierarchy of Gaussian mixture (GM) distributions. HTGM generates a _task embedding_ from a _task-level_ GM, and uses it to define the task-conditioned mixture probabilities for a _class-level_ GM, from which the data samples are drawn. To allow realistic classes per task, a new Gibbs distribution was proposed to underlie the class-level GM.
* HTGM is an encoder-agnostic framework, thus is flexible to different domains. It inherits metric-based meta-learning methods, and only introduces a small overhead to an encoder for parameterizing its distributions, thus is efficient for large backbone networks. The model parameters are learned end-to-end by maximum likelihood estimation via a principled EM algorithm. The bounds of our likelihood function were also theoretically analyzed.
* In the experiments, we evaluated HTGM on benchmark datasets regarding its scalability to large networks, effectiveness in modeling the mixture distribution of tasks, and usefulness in identifying novel tasks. The results demonstrate HTGM outperforms the state-of-the-art (SOTA) baselines with significant improvements in most cases.

## 2 Related Work

To the best of our knowledge, this is the first work to explicitly model the generative process of task instances from a mixture of distributions for meta-learning with novel task detection. Meta-learning aims to handle the few-shot learning problem, which derives memory-based , optimization-based [8; 26], and metric-based methods [47; 41], and often considers an artificial scenario where training/test tasks are sampled from the same distribution. To enable more varying tasks, task-adaptive methods facilitate the customization of meta-knowledge by learning task-specific parameters [37; 25], temperature scaling parameters , and task-specific modulation on model initialization [48; 52; 53; 21]. Among them, there are methods tackling the mixture distribution of tasks by clustering tasks [52; 13; 14; 17], learning task similarity and graphs [58; 53], and relocating the initial parameters for different tasks so that they use the meta-knowledge differently . As discussedbefore, none of these methods jointly handles the mixture of task distributions and the detection of novel tasks in meta-testing stage. A more detailed discussion is in Appendix B.1.

Our model is built upon metric-based methods and learns task embeddings to model task distributions. Achille et al.  proposed to learn embeddings for tasks and introduced a meta-learning method, but not for few-shot learning. Their embeddings are from a pre-specified set of tasks (rather than episode-wise sampling), and the meta-learning framework is for model selection. The model in  has an augmented encoder for task embedding, but it does not model task generation, and is not designed for novel task detection (an empirical comparison is in Sec. 4.1).

The conventional novelty detection aims to identify and reject samples from unseen classes . It relates to open-set recognition , which aims to simultaneously identify unknown samples and classify samples from known classes. Out-of-distribution (OOD) detection [27; 28] can be seen as a special case of novelty detection where novel samples are from other problem domains or datasets, thus are considered to be easier to detect than novelties . These methods are for large-scale training. In contrast, we want to detect novel tasks, which is a new problem in the small data regime.

Hierarchical Gaussian Mixture (HGM) model has appeared in some traditional works [9; 32; 3; 50] for hierarchical clustering by applying GM agglomeratively or divisively, which do not pre-train models for meta-learning, and is remarkably different from the topic in this paper. The differences are elaborated in Appendix B.2. Moreover, the idea of learning groups/clusters of tasks also appeared in some multi-task learning (MTL) models. The key difference between these methods and our method HTGM lies in the difference between MTL and meta-learning. In an MTL method, all tasks are known _a priori_, _i.e._, the testing tasks are from the set of training tasks, and the model is inductive at the sample-level but non-inductive at the task-level. More discussions are in Appendix B.3.

## 3 Hierarchical Gaussian Mixture based Task Generative Model (HTGM)

### Problem Statement

Meta-learning methods typically use an _episodic learning_ strategy, where the meta-training set \(^{}\) consists of a batch of episodes. Each episode samples a task \(\) from a distribution \(p()\). Task \(\) has a support set \(^{}_{}=\{(^{}_{i},y^{}_{i}) \}_{i=1}^{n_{}}\) for training, and a query set \(^{}_{}=\{(^{}_{i},y^{}_{i}) \}_{i=1}^{n_{}}\) for testing, where \(n_{}\) is a small number to denote a few training samples. In particular, in a commonly used \(N\)-way \(K\)-shot \(Q\)-query task , \(^{}_{}\) and \(^{}_{}\) contain \(N\) classes, with \(K\) and \(Q\) samples per class respectively, _i.e._, \(n_{}=NK\) and \(n_{}=NQ\).

Let \(f_{}(^{}_{i}) y^{}_{i}\) be a base model (\(\) denotes \(\) or \(\)), and \(f_{}(;^{}_{})\) be the adapted model on \(^{}_{}\). The training objective on \(\) is to minimize the average test error of the adapted model, _i.e._, \(_{(^{}_{i},^{}_{i})^{}_{}}(y^{}_{i},f_{}(^{}_{i};^{}_{}))\), where \((,)\) is a loss function (_e.g._, cross-entropy loss), and the meta-training process aims to find the parameter \(\) that minimizes this error over all episodes in \(^{}\). Then, \(f_{}\) is evaluated on every episode of a meta-test set \(^{}\) that samples a task from the same distribution \(p()\). Usually, \(p()\) is a simple distribution [8; 21]. In this work, \(p()\) is generalized to a mixture distribution consisting of multiple components \(p_{1}()\),..., \(p_{r}()\), and a test episode may sample a task either in or out of any component of \(p()\). As such, given the training tasks in \(^{}\), our goal is to estimate the underlying density of \(p()\), so that once a test task is given, we can (1) identify if it is a novel task, and (2) adapt \(f_{}\) to it with optimal accuracy. Specifically, the base model \(f_{}\) can be written as a combination of an encoder \(g_{_{c}}\) and a predictor \(h_{_{p}}\), _i.e._, \(f_{}(^{}_{i})=h_{_{c}}(g_{ _{c}}(^{}_{i}))\). In this work, we focus on a metric-based non-parametric learner, _i.e._, \(_{p}=\) (_e.g._, prototypical networks ), not only because metric-based classifiers were confirmed as more effective than probabilistic classifiers for novelty detection , but also for its better training efficiency that fits large backbone networks than the costly nested-loop training of optimization-based methods .

Formally, our goal is to find the model parameter \(\) that maximizes the likelihood of observing a task \(\). In other words, let \(f_{}(^{}_{i})=^{}_{i}^{d}\) be sample embedding, we want to maximize the likelihood of the joint distribution \(p_{}(^{}_{i},y^{}_{i})\) on the observed data in \(_{}=\{^{}_{},^{}_{ }\}\). We consider each task \(\) as an instance, with a representation \(_{}^{d}\) in the embedding space (the method to infer \(_{}\) is described in Sec. 3.3). To model the unobserved mixture component, we associate every task with a latent variable \(z_{}\) to indicate to which component it belongs. Suppose there are \(r\) possible components, and let \(n=n_{}+n_{}\) be the total number of samples in \(_{}\), the log-likelihoodto maximize can be written by hierarchically factorizing it on \(y_{i}^{*}\) and marginalizing out \(_{}\) and \(z_{}\).

\[(_{};) =_{i=1}^{n}[p_{}(_{i}^ {*},y_{i}^{*})]=_{i=1}^{n}[p_{}( _{i}^{*}|y_{i}^{*})p(y_{i}^{*})]\] (1) \[=_{i=1}^{n}[p_{}(_{i} ^{*}|y_{i}^{*})[_{_{}}p(y_{i}^{*}|_{})p(_{})d_{}]]\] \[=_{i=1}^{n}[p_{}(_{i }^{*}|y_{i}^{*})_{_{}}p(y_{i}^{*}|_{}) _{z_{}=1}^{r}p(_{}|z_{})p(z_{})d _{}]\]

where \(p_{}(_{i}^{*}|y_{i}^{*})\) specifies the probability of sampling \(_{i}^{*}\) from the \(y_{i}^{*}\)-th class, \(p(y_{i}^{*}|_{})\) is the probability of sampling the \(y_{i}^{*}\)-th class for task \(\), and \(p(_{}|z_{})\) indicates the probability of generating a task \(\) from the \(z_{}\)-th mixture component. \(p(z_{})\) is a prior on the \(z_{}\)-th component. Hence, Eq. (1) implies a generative process of task \(\): \(z_{}_{} y_{i}^{*}_{i}^{*}\). Next, we define each of the aforementioned distributions and propose our HTGM method.

### Model Specification and Parameterization

In Eq. (1), the _class-conditional distribution_\(p_{}(_{i}^{*}|y_{i}^{*})\), the _task-conditional distribution_\(p(y_{i}^{*}|_{})\), and the _mixture distribution of tasks_ defined by \(\{p(_{}|z_{}),p(z_{})\}\) are not specified. To make Eq. (1) optimizable, we introduce our HTGM that models the generative process of tasks. Because \(_{}^{}\) and \(_{}^{}\) follow the same distribution, in the following, we ignore the superscript \(*\) for simplicity.

**Class-Conditional Distribution.** First, similar to [22; 23], we use Gaussian distribution to model the embeddings \(_{i}\)'s in every class. Let \(_{y_{i}}^{}\), and \(_{y_{i}}^{}\) be the mean and variance of the \(y_{i}\)-th class, then \(p_{}(_{i}|y_{i})=(_{i}|_{y_{ i}}^{},_{y_{i}}^{})\). In fact, the samples in all of the classes of task \(\) comprise a Gaussian mixture distribution, where \(p(y_{i})\) is the _mixture probability_ of the \(y_{i}\)-th class. In Eq. (1), \(p(y_{i})\) is factorized to be task-specific, _i.e._, \(p(y_{i}|_{})\), which resorts to another mixture distribution \(p(_{})\) of tasks, and establishes a structure of hierarchical mixture.

**Task-Conditional Distribution.** A straightforward definition of \(p(y_{i}|_{})\) is the density at \(_{y_{i}}^{}\) in a Gaussian distribution with \(_{}\) as the mean, where \(_{y_{i}}^{}\) is the mean (or prototype) of the \(y_{i}\)-th class. However, doing so exposes two problems: (1) the density function of Gaussian distribution is log-concave with one global maximum. Given the mean and variance, maximizing its log-likelihood tends to collapse the prototypes \(_{y_{i}}^{}\)'s of all classes in \(\), making them indistinguishable and impairing classification; (2) given \(_{}\), this method tends to sample classes with small \(D_{_{}}(_{y_{i}}^{})\), where \(D_{_{}}()\) measures the Mahalanobis distance between a data point and the Gaussian distribution centered at \(_{}\). However, in most of the existing works, classes are often uniformly sampled from a domain without any prior on distances . Fitting the distance function with such "uniform" classes naively leads to an ill-posed learning problem with degenerated solutions. In light of these issues, we seek to define \(p(y_{i}|_{})\) as a (parameterized) density function with at least \(N\) global optimums so that it can distinguish the \(N\) different class prototypes of \(N\)-way tasks. The \(N\) equal (global) optimums also allow it to fit \(N\) classes uniformly sampled from a domain. To this end, let \(_{k}^{}\) be the _surrogate embedding_ of the \(k\)-th class, we propose a Gibbs distribution \((_{k}^{}|_{},)\) defined by \(_{}\) and trainable parameters \(\) with an energy function. Then we write \(p(y_{i}=k|_{})\) as

\[p_{}(y_{i}=k|_{})=(_{k}^{}|_{},)=}(_{k}^{}; _{})]}{_{_{k}^{}}[-E_{}(_{k}^{};_{})]}\] (2)

where \(E_{}(_{k}^{};_{})=(\{||_{k}^{}-_{j}_{}||_{2}^{2}\})_{j=1}^{N}\) is our energy function, and the denominator in Eq (2) is a normalizing constant (with respect to \(_{k}^{}\)), _a.k.a._ the partition function in an energy-based model (EBM) . \(=\{_{1},...,_{N}\}\) are trainable parameters, with \(_{i}^{d d}\). Given \(\) and \(_{}\), Eq. (2) has \(N\) global maximums at \(_{k}^{}=_{1}_{}\),..., \(_{k}^{}=_{N}_{}\). More interpretations of the proposed task-conditional distribution can be found in Appendix B.4.

**Mixture Distribution of Tasks.** In Eq. (1), the task distribution \(p(_{})\) is factorized as a mixture of \(p(_{}|z_{}=1)\),..., \(p(_{}|z_{}=r)\), weighted by their respective mixture probability \(p(z_{})\). Thus we specify \(p(_{})\) as a Gaussian mixture distribution. We introduce \(_{z_{}}^{}\) and \(_{z_{}}^{}\) as the mean and variance of each component, _i.e._, \(p(_{}|z_{})=(_{}|_{z_{}}^{ },_{z_{}}^{})\), and let \(=[_{1},...,_{r}]\) be the mixture probabilities, where \(_{r}=p(z_{}=r)\) and \(\) can be Uniform\((r)\). Then \(_{}\) is generated in two steps: (1) draw a latent task variable \(z_{}\) from a categorical distribution on \(\), and (2) draw \(_{}\) from \((^{}_{z_{}},^{}_{z_{}})\). As such, our HTGM generative process of an \(N\)-way \(K\)-shot \(Q\)-query task \(\) can be summarized as following, and Fig. 1 illustrates the corresponding graphical model:

1. Draw \(z_{}([_{1},...,_{r}])\)
2. Draw a task embedding \(_{}(^{}_{z_{}}, ^{}_{z_{}})\)
3. For \(k=1,...,N\): 1. Draw a class prototype \(^{}_{k}(^{}_{k}|_{}, )\) from the proposed Gibbs distribution in Eq. (2) 2. For \(i=1,...,K+Q\): 1. Set \(y_{i}=k\), draw a sample \(_{i}(_{i}|^{}_{y_{i}}, ^{}_{y_{i}})\) 2. Allocate \((_{i},y_{i})\) to the support set \(^{}_{}\) if \(i K\); else allocate \((_{i},y_{i})\) to the query set \(^{}_{}\)

To reduce complexity, we investigate the feasibility of using isotropic Gaussian with tied variance, _i.e._, \(^{}_{1}=...=^{}_{N}=^{2} \), for class distributions, which turned out to be efficient in our experiments. Here, \(\) is an identity matrix, \(\) is a hyperparameter. Tied variance is also a commonly used trick in Gaussian discriminate analysis (GDA) for generative classifiers . For task distributions, the variances \(^{}_{1},...,^{}_{r}\) can be automatically inferred by our algorithm, as elaborated in Sec. 3.3.

Finally, in Eq. (1), substituting \(p_{}(_{i}|y_{i})=(_{i}|^{ }_{y_{i}},^{2})\), \(p_{}(y_{i}|_{})=(^{}_{y_{i}}| _{},)\), \(p(_{}|z_{})=(_{}|^{ }_{z_{}},^{}_{z_{}})\), whose probabilities are specified and parameterized, and letting \(=(r)\) be a uniform prior, we get our HTGM induced loss \(_{}(_{};,)\). The class means \(^{}_{y_{i}}\), task means \(^{}_{z_{}}\) and variances \(^{}_{z_{}}\) are inferred in the E-step of our EM algorithm (the details can be found in Sec. 3.3 and A.6).

### Model Optimization

It is hard to directly optimize \(_{}(_{};,)\), because the exact posterior inference is intractable (due to the integration over \(_{}\)). To solve it, we resort to variational methods, and introduce an approximated posterior \(q_{}(_{}|^{}_{})\), which is defined by an inference network \(\), and implies we want to infer \(_{}\) from its observed support set \(^{}_{}\). The query set \(^{}_{}\) is not included because it is unavailable during model testing. Then we propose to maximize a lower-bound of Eq. (1), which is (the derivation can be found in Appendix A.1)

\[_{}(_{};,)= _{i=1}^{n} p_{,}( _{i}|y_{i})+_{_{} q_{}( _{}|^{}_{})}[ p_{}(y_{i} |_{})+_{z_{}=1}^{r}p(_{}|z_{})p(z_ {})]\] (3) \[+Hq_{}(_{}|^{} _{})\]

where \(H(q_{}(_{}|^{}_{}))=-_{ _{}}q_{}(_{}|^{}_{ }) q_{}(_{}|^{}_{})d _{}\) is the entropy function. Similar to VAE , Eq. (3) estimates the expectation (in the second term) by sampling \(_{}\) from \(q_{}(_{}|^{}_{})\), instead of the integration in Eq. (1), hence facilitates efficient computation. Next, we elaborate on the inference network, the challenges of maximizing Eq. (3), and our workarounds.

**Inference Network.** Similar to VAE, \(q_{}(_{}|^{}_{})\) is defined as a Gaussian distribution \((^{}_{z_{}},^{2})\), where \(^{}_{z_{}}\) is the output of the inference network, which approximates \(^{}_{z_{}}\) in Step 2 of the generative process, and \(\) is a hyperparameter for the corresponding variance. As illustrated by Fig. 2(a), the inference network is built upon the base model \(f_{}()\) with two non-parametric aggregation (_i.e._, mean pooling) functions, thus \(=\). The first function aggregates class-wise embeddings to prototypes \(^{}_{y_{i}}\)'s, similar to prototypical networks . Differently, the second aggregates all prototypes to \(^{}_{z_{}}\). During model training, we used the reparameterization trick  to sample \(_{}\) from \((^{}_{z_{}},^{2})\). It is noteworthy that \(H(q_{}(_{}|^{}_{}))\) in Eq. (3) becomes a constant because \(^{2}\) is a constant.

**Challenge 1: Trivial Solution.** In Eq. (3), since the first term \( p_{,}(_{i}|y_{i})=- }\|_{i}-^{}_{y_{i}}\|^{2}_{2}\) (constants were ignored) only penalizes the distance between a sample \(_{i}\) and its own class mean \(^{}_{y_{i}}\) (_i.e._, intra-class distances_) without considering inter-class relationships, different class means \(^{}_{1}\),...,

Figure 1: Graphical model of the proposed generative process for \(B\) tasks with \(N\) ways, \(K\) shots and \(Q\) queries.

[MISSING_PAGE_FAIL:6]

infer the posterior \(p(z_{}|_{})\) (_i.e._, the mixture membership of \(_{}\)) and solve the model parameters \(\{,\}\) through an Expectation-Maximization algorithm. In E-step, we infer \(p(z_{}|_{})\) when fixing model parameters. In M-step, when fixing \(p(z_{}|_{})\), \(\{,\}\) can be efficiently solved by optimizing Eq. (5) with stochastic gradient descent (SGD). The detailed optimization algorithm of HTGM can be found in Appendix A.6.

### Model Adaptation

Fig. 2(b) illustrates the adaptation process of HTGM. Given a new \(N\)-way task \(^{}\) from the meta-test set \(^{}\), its support set \(^{}_{^{}}\) is fed to the inference network to generate (1) class prototypes \(^{}_{1}\),..., \(^{}_{N}\)2 (similar to prototypical networks), and (2) distribution \(q_{}(_{^{}}|^{}_{^{}})\), from which we draw the average task embedding \(_{^{}}=^{}_{z_{^{}}}\). Recall that the inference network is the base model \(f_{}()\) with class-pooling and task-pooling layers, as illustrated in Fig. 2(b), and \(=\). Then \(_{^{}}\) is projected to \(_{1}_{^{}}\),..., \(_{N}_{^{}}\) which represent the \(N\) optimal choices of class prototypes for task \(^{}\) as learned by the Gibbs distribution in Eq. (2) from the training tasks. They are used to adapt \(^{}_{1}\),..., \(^{}_{N}\) so that the adapted prototypes are drawn towards the closest classes from the mixture component that task \(^{}\) belongs to. Specifically, the adaptation is performed by selecting the closest optimum for each prototype \(^{}_{j}\) (\(1 j N\)), that is

\[}^{}_{j}=^{}_{j}+(1-)_{l^{*}}_{^{}},\ \ \ \ \ l^{*}=*{arg\,min}_{1 l N}D(^{}_{j}, _{l}_{^{}}),\] (7)

and \(D(,)\) is the Euclidean distance, \(\) is a hyperparameter. The following theorem confirms the effectiveness of the this adaptation method (the proof can be found in Appendix A.4).

**Theorem 3.2**.: _The adapted prototypes \(}^{}_{1}\),..., \(}^{}_{N}\) from Eq. (7) maximizes the lower-bound \(_{}\) in Eq. (3) of the likelihood in Eq. (1) when \(=}\)._

Theorem 3.2 suggests an automatic setup of \(\), which can also be tuned empirically for optimal value using validation datasets. We evaluated the empirical values of \(\) in our experiments and discussed their relationships with the theoretical values in Appendix A.4.

Finally, we (1) assess if \(^{}\) is a novelty by computing the likelihood of \(_{^{}}\) in a pre-fitted GMM on the embeddings \(_{}\)'s of the training tasks in \(^{}\), and (2) perform classification on each sample \(^{}_{i}\) in the query set \(^{}_{^{}}\) using the adapted prototypes by

\[p(y^{}_{i}=j^{}|^{}_{i})=}(^{}_{i}),}^{}_{j^{}}) )}{_{j=1}^{N}(-D(f_{}(^{}_{i}), }^{}_{j}))}\] (8)

which is the posterior probability. The derivation of Eq. (8) is in Appendix A.5.

## 4 Experiments

In this section, we evaluate HTGM's effectiveness on few-shot classification and novel task detection on benchmark datasets, and compare it with SOTA methods.

**Datasets.** The first dataset is the _Plain-Multi_ benchmark . It includes four fine-grained image classification datasets, _i.e._, CUB-200-2011 (Bird), Describable Textures Dataset (Texture), FGVC of Aircraft (Aircraft), and FGVCx-Fungi (Fungi). In each episode, a task samples classes from one of the four datasets, so that different tasks are from a mixture of the four domains. The second dataset is the _Art-Multi_ benchmark , whose distribution is more complex than Plain-Multi. Similar to , each image in Plain-Multi was applied with two filters, _i.e._, _blur_ filter and _pencil_ filter, respectively, to simulate a changing distribution of few-shot tasks. Afterward, together with the original four datasets, a total of 12 datasets comprise the Art-Multi, and each task is sampled from one of them. Both benchmarks were divided into the meta-training, meta-validation, and meta-test sets by following their corresponding papers. Moreover, we used the Mini-ImageNet dataset  to evaluate the case of uni-component distribution of tasks, which is discussed in Appendix D.6.

**Baselines.** We compared HTGM with the relevant SOTA methods on meta-learning, including (1) optimization-based methods: MAML  and Meta-SGD  learn globally shared initializationamong tasks. MUMOMAML  is a task-specific method. TAML  handles imbalanced tasks. HSML  and ARML  learn locally shared initial parameters in clusters of tasks and neighborhoods of a meta-graph of tasks, respectively; and (2) Metric-based methods: ProtoNet  is the prototypical network. MetaOptNet  uses an SVM classifier with kernel metrics. ProtoNet-Aug , FEATS  and NCA  were built upon ProtoNet by augmenting images (_e.g._, rotation, jigsaw), adding prototype aggregator (_e.g._, Transformer), and using contrastive training loss (instead of prototype-based loss), respectively. The detailed setup of these methods is in Appendix C.1.

**Implementation.** Following , the optimization-based baselines used the standard four-block convolutional layers as the base learner, and the metric-based methods used ResNet-12. The output dimension of these networks is 640 (MetaOptNet uses 16000 as in its paper). In our experiments, we observed the optimization-based methods reported out-of-memory errors when using ResNet-12, indicating their limitation in using large backbone networks. To test them on ResNet-12, we followed the ANIL method  by pre-training ResNet-12 via ProtoNet, freezing the encoder, and fine-tuning the last fully-connected layer. In this case, HSML and ARML cannot model the mixture task distribution properly as they require joint training of the encoder and other layers. The details are in Appendix D.5. For training, Adam optimizer was used. Each batch contains 4 tasks. Each model was trained with 20000 episodes. The learning rate of the metric-based methods was \(1e^{-3}\). The learning rates for the inner- and outer-loops of the optimization-based methods were \(1e^{-3}\) and \(1e^{-4}\). The weight decay was \(1e^{-4}\). For HTGM, we set \(=1.0\), \(=0.1\), \(=0.5\) (\(0.9\)) for 1-shot (5-shot) tasks. The number of mixture components \(r\) varies _w.r.t._ different datasets, and was grid-searched within \(\). All hyperparameters were set using the meta-validation sets.

### Experimental Results

**Few-shot classification.** Following , we report the mean accuracy and 95% confidence interval of 1000 random tasks with 5-way 1-shot/5-shot, 5/25-query tests. Following , we report the accuracy of each domain and the overall average accuracy for Plain-Multi, and report the accuracy of each image filtering strategy and the overall average accuracy for Art-Multi. Table 1 and 2 summarize the results. From the tables, we have several observations. First, metric-based methods generally outperform optimization-based methods. This is because of the efficiency of metric-based methods, enabling them to fit a larger backbone network, which is consistent with the results in . Built upon the metric-based method, HTGM only introduces a few distribution-related parameters and thus has the flexibility to scale with the encoder size. Second, the baselines designed for dealing

  Setting & Model & Bird & Texture & Aircraft & Fungi & Avg. \\   & TAML & 55.77\(\)1.43 & 31.78\(\)1.30 & 48.56\(\)1.37 & 41.00\(\)1.50 & 44.28 \\  & MAML & 53.94\(\)1.45 & 31.66\(\)1.31 & 51.37\(\)1.38 & 42.12\(\)1.36 & 44.77 \\  & Meta-SGD & 55.58\(\)1.43 & 32.38\(\)1.32 & 52.99\(\)1.36 & 41.74\(\)1.34 & 45.67 \\  & MUMOMAML & 56.82\(\)1.49 & 33.81\(\)1.36 & 53.14\(\)1.39 & 42.22\(\)1.40 & 46.50 \\  & HSML & 60.98\(\)1.50 & 35.01\(\)1.36 & 57.38\(\)1.40 & 44.02\(\)1.39 & 49.35 \\  & ARML & 62.33\(\)1.47 & 35.65\(\)1.40 & 58.56\(\)1.41 & 44.82\(\)1.38 & 50.34 \\  & ProtoNet & 61.54\(\)1.27 & 38.84\(\)1.42 & 73.42\(\)1.23 & 46.52\(\)1.42 & 55.08 \\  & MetaOptNet & 62.80\(\)1.29 & 44.30\(\)1.45 & 68.64\(\)1.29 & 47.04\(\)1.38 & 55.70 \\  & ProtoNet-Aug & 65.04\(\)1.29 & 44.68\(\)1.43 & 70.44\(\)1.32 & 49.30\(\)1.40 & 57.37 \\  & NCA & 62.58\(\)1.25 & 40.98\(\)1.44 & 68.70\(\)1.26 & 46.36\(\)1.34 & 54.66 \\  & FEATS & 62.60\(\)1.31 & 44.12\(\)1.49 & 68.86\(\)1.28 & 47.92\(\)1.34 & 55.88 \\   & HTGM (ours) & **70.12\(\)1.28** & **47.76\(\)1.49** & **75.52\(\)1.24** & **52.06\(\)1.41** & **61.37** \\   & TAML & 69.50\(\)0.75 & 45.11\(\)0.69 & 65.92\(\)0.74 & 50.99\(\)0.87 & 57.88 \\  & MAML & 68.52\(\)0.79 & 44.56\(\)0.68 & 66.18\(\)0.71 & 51.85\(\)0.85 & 57.78 \\  & Meta-SGD & 67.87\(\)0.74 & 45.49\(\)0.68 & 66.84\(\)0.70 & 52.51\(\)0.81 & 58.18 \\  & MUMOMAML & 70.49\(\)0.76 & 45.89\(\)0.69 & 67.31\(\)0.68 & 53.96\(\)0.82 & 59.41 \\  & HSML & 71.68\(\)0.73 & 48.08\(\)0.69 & 73.49\(\)0.68 & 56.32\(\)0.80 & 62.39 \\  & ARML & 73.34\(\)0.70 & 49.67\(\)0.67 & 74.88\(\)0.64 & 57.55\(\)0.82 & 63.86 \\  & ProtoNet & 78.88\(\)0.72 & 57.93\(\)0.75 & 86.42\(\)0.57 & 62.52\(\)0.79 & 71.44 \\  & MetaOptNet & 81.66\(\)0.71 & **61.97\(\)0.78** & 84.03\(\)0.56 & 63.80\(\)0.81 & 72.87 \\  & ProtoNet-Aug & 80.62\(\)0.71 & 58.30\(\)0.77 & 87.05\(\)0.53 & 63.62\(\)0.81 & 72.39 \\  & NCA & 79.16\(\)0.75 & 58.69\(\)0.76 & 85.27\(\)0.53 & 61.68\(\)0.80 & 71.20 \\  & FEATS & 78.37\(\)0.72 & 57.02\(\)0.73 & 85.55\(\)0.54 & 61.56\(\)0.80 & 70.63 \\   & HTGM (ours) & **82.27\(\)0.74** & 60.67\(\)0.78 & **88.48\(\)0.52** & **65.70\(\)0.79** & **74.28** \\  

Table 1: Results (accuracy\(\)95% confidence) of the compared methods on Plain-Multi dataset.

with mixture distributions of tasks, _i.e._, HSML and ARML, outperform their counterparts without such design, demonstrating the importance to consider mixture task distribution in practice. Finally, HTGM outperforms the SOTA baselines in most cases by large margins, suggesting its effectiveness in modeling the generative process of task instances.

**Novel task detection.** We also evaluate HTGM on the task of detecting novel \(N\)-way-\(K\)-shot tasks (\(N=5\), \(K=1\)) that are drawn out of the training task distributions. To this end, we train each compared model in the Original domain in Art-Multi dataset, and test the model on tasks drawn from either Original domain (_i.e._, known tasks), or {Blur, Pencil} domains (_i.e._, novel tasks), and evaluate if the model can tell whether a testing task is known or novel.

For comparison, since none of the baselines detects novel tasks, we adapt them as follows. For metric-based methods, since they use a fixed encoder for all training/testing tasks, we averaged the sample embeddings in each task to represent the task. Then a separate GMM model was built upon the training task embeddings, and its likelihood was adapted to score the novelty of testing tasks (some details of the setup are in Appendix C.2).

However, optimization-based models perform gradient descent on the support set of each task, leading to varying encoders per task. As such, sample embeddings of different tasks are not comparable, and we cannot obtain task embeddings in the same way as before. Among them, only HSML has an augmented task-level encoder for task embedding, allowing us to include it for comparison. For a fair comparison, our HTGM also trains a GMM on its task embeddings for detecting novel tasks. Moreover, two HTGM variants were included for ablation analysis to understand some design choices: (1) HTGM-Gaussian replaces the Gibbs distribution in Eq. (2) with a Gaussian distribution; (2) HTGM w/o GMM removes the task-level GM, _i.e._, the third term in Eq. (3). The classification results of the ablation variants are in Appendix D.4. Following [6; 46; 56], we report Area Under ROC (AUROC), Average Precision (AP), and Max-F1. Table 3 summarizes the results, from which we observe HTGM outperforms all

  Setting & Model & Original & Blur & Pencil & Avg. \\   & TAML & 42.22\(\)1.39 & 40.02\(\)1.41 & 35.11\(\)1.34 & 39.11 \\  & MAML & 42.70\(\)1.35 & 40.53\(\)1.38 & 36.71\(\)1.37 & 39.98 \\  & Meta-SGD & 44.21\(\)1.38 & 42.36\(\)1.39 & 37.21\(\)1.39 & 41.26 \\  & MUMOMAML & 45.63\(\)1.39 & 41.59\(\)1.38 & 39.24\(\)1.36 & 42.15 \\  & HSML & 47.92\(\)1.34 & 44.43\(\)1.34 & 41.44\(\)1.34 & 44.60 \\  & ARML & 45.68\(\)1.34 & 42.62\(\)1.34 & 39.78\(\)1.34 & 42.69 \\  & ProtoNet & 55.23\(\)1.31 & 51.70\(\)1.42 & 49.22\(\)1.44 & 52.05 \\  & MetaOptNet & 56.10\(\)1.35 & 52.33\(\)1.43 & 49.08\(\)1.45 & 52.50 \\  & ProtoNet-Aug & 57.63\(\)1.34 & 55.00\(\)1.40 & 49.73\(\)1.53 & 54.12 \\  & NCA & 56.12\(\)1.35 & 50.80\(\)1.49 & 47.99\(\)1.45 & 51.64 \\  & FEATS & 54.33\(\)1.33 & 50.90\(\)1.48 & 47.96\(\)1.48 & 51.07 \\   & HTGM (ours) & **61.18\(\)1.34** & **58.80\(\)1.42** & **53.23\(\)1.48** & **57.74** \\   & TAML & 58.54\(\)0.73 & 55.23\(\)0.75 & 49.23\(\)0.75 & 54.33 \\  & MAML & 58.30\(\)0.74 & 55.71\(\)0.74 & 49.59\(\)0.73 & 54.50 \\  & Meta-SGD & 57.82\(\)0.72 & 55.54\(\)0.73 & 50.24\(\)0.72 & 54.53 \\  & MUMOMAML & 58.60\(\)0.75 & 56.29\(\)0.72 & 51.15\(\)0.73 & 55.35 \\
5-way, & HSML & 60.63\(\)0.73 & 57.91\(\)0.72 & 53.93\(\)0.72 & 57.49 \\
1-shot & ARML & 61.78\(\)0.74 & 58.73\(\)0.75 & 55.27\(\)0.73 & 58.59 \\  & ProtoNet & 71.34\(\)0.73 & 67.28\(\)0.75 & 64.32\(\)0.76 & 67.65 \\  & MetaOptNet & 72.33\(\)0.72 & 68.90\(\)0.78 & 63.89\(\)0.71 & 68.37 \\  & ProtoNet-Aug & 72.87\(\)0.71 & 70.50\(\)0.72 & 63.98\(\)0.73 & 68.78 \\  & NCA & 72.44\(\)0.72 & 67.33\(\)0.71 & 62.98\(\)0.78 & 67.58 \\  & FEATS & 71.99\(\)0.71 & 67.54\(\)0.72 & 63.09\(\)0.76 & 67.54 \\   & HTGM (ours) & **74.67\(\)0.70** & **71.24\(\)0.73** & **65.22\(\)0.77** & **70.37** \\    &  &  &  &  & \\ 

Table 2: Results (accuracy\(\)95% confidence) of the compared methods on Art-Multi dataset.

  Model & AUROC & AP & Max-F1 \\  HSML & 55.96 & 37.94 & 50.17 \\ ProtoNet & 65.17 & 41.51 & 56.07 \\ MetaOptNet & 72.71 & 63.77 & 58.33 \\ NCA & 66.28 & 51.45 & 52.74 \\ ProtoNet-Aug & 72.67 & 57.93 & 59.07 \\ FEATS & 59.35 & 42.57 & 49.31 \\  HTGM w/o GMM & 70.24 & 62.45 & 57.75 \\ HTGM-Gaussian & 74.06 & 66.18 & **60.62** \\ HTGM & **75.66** & **68.03** & 60.51 \\  

Table 3: Comparison between HTGM, its variants and applicable baselines on novel task detection.

baselines over all evaluation metrics, indicating the superior quality of task embeddings learned by our model. The embeddings follow the specified mixture distribution of tasks \(p(_{})\) as described in Sec. 3.2, which fits the mixture data well hence allowing to detect novel tasks that are close to the boundary. Since the baselines learn embeddings without explicit constraint, they don't fit the post-hoc GMM well. Moreover, HTGM outperforms HTGM w/o GMM, which is even worse than some other baselines. This further validates the necessity to introduce the regularization of task-level mixture distribution \(p(_{})\). Also, the drops of AUROC and AP of HTGM-Gaussian demonstrate the importance of our unique design of the Gibbs distribution for the task-conditional distribution in Eq. (2). Similar to , in Fig. 3, we visualized the normalized likelihood histogram of known and novel tasks for HSML, MetaOptNet (the best baseline), ProtoNet-Aug (near-best baseline), and HTGM. To better interpret the figures, we calculated the ratio between the non-overlapped area of the two distributions and the total-area in Fig. 3 for HSML: 0.1379, MetaOpt: 0.4952, ProtoNet-Aug: 0.4806, and HTGM: 0.5578. As can be seen, the ratio of the non-overlapped area of HTGM is higher than other methods, which indicates the likelihoods (_i.e._, novelty scores) of HTGM are more distinguishable for known and novel tasks than the baseline methods. We also analyzed the hyperparameters \(\), \(\), and \(r\) of HTGM in Appendix D.1, D.2, and D.3.

## 5 Conclusion

In this paper, we proposed a novel Hierarchical Gaussian Mixture based Task Generative Model (HTGM). HTGM models the generative process of task instances, and performs maximum likelihood estimation to learn task embeddings, which can help adjust prototypes acquired by the feature extractor and thus achieve better performance. Moreover, by explicitly modeling the distribution of tasks in the embedding space, HTGM can effectively detect the tasks that are drawn from distributions unseen during meta training. The extensive experimental results indicate the advantage of HTGM on both few-shot classification and novel task detection.

## 6 Broader Impact and Limitation

Our proposed method enables better novel task detection for meta-learning. In many areas requiring robust decisions, such as healthcare (as described in Sec. 1) and auto-driving, where the accuracy drop and uncertainty on novel tasks is inevitable, our model can raise an alarm to users (_e.g._, doctors and human drivers) for diagnosis and decision-making. However, as a probabilistic machine learning model, HTGM does not guarantee 100% accuracy. Also, it is noteworthy that the entropy of \((_{y_{i}}^{}|_{},)\) (in Eq. (2)) is proportional to the partition function (_i.e._ the denominator in Eq. (2)). Thus, our approximation in Sec. 3.3 that replaces the partition function with its upper bound increases the entropy, leading to increased noise in the inferred class prototypes. As such, in scenarios such as serious disease treatment and auto-driving in complex environments, to avoid potential wrong decisions from the model, human intervention is still necessary.