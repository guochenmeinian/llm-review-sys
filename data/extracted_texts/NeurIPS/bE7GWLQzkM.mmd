# Disentangling and mitigating the impact of task similarity for continual learning

Naoki Hiratani

Department of Neuroscience

Washington University in St Louis

St Louis, MO 63110

hiratani@wustl.edu

###### Abstract

Continual learning of partially similar tasks poses a challenge for artificial neural networks, as task similarity presents both an opportunity for knowledge transfer and a risk of interference and catastrophic forgetting. However, it remains unclear how task similarity in input features and readout patterns influences knowledge transfer and forgetting, as well as how they interact with common algorithms for continual learning. Here, we develop a linear teacher-student model with latent structure and show analytically that high input feature similarity coupled with low readout similarity is catastrophic for both knowledge transfer and retention. Conversely, the opposite scenario is relatively benign. Our analysis further reveals that task-dependent activity gating improves knowledge retention at the expense of transfer, while task-dependent plasticity gating does not affect either retention or transfer performance at the over-parameterized limit. In contrast, weight regularization based on the Fisher information metric significantly improves retention, regardless of task similarity, without compromising transfer performance. Nevertheless, its diagonal approximation and regularization in the Euclidean space are much less robust against task similarity. We demonstrate consistent results in a permuted MNIST task with latent variables. Overall, this work provides insights into when continual learning is difficult and how to mitigate it.

## 1 Introduction

Artificial neural networks surpass human capabilities in various domains, yet struggle with continual learning. These networks tend to forget previously learned tasks when trained sequentially--a problem known as catastrophic forgetting [44; 16; 23; 32]. This phenomenon affects not only supervised training of feedforward networks but also extends to recurrent neural networks , reinforcement learning tasks , and fine-tuning of large language models . Many algorithms for mitigating catastrophic forgetting have been developed previously, including rehearsal techniques [48; 49; 59], weight regularization [30; 36; 67], and activity-gating methods [15; 54; 42; 56], among others [57; 50; 63; 21]. However, these methods often hinder forward and backward knowledge transfer [28; 39; 29], and thus it remains unclear how to achieve knowledge transfer and retention simultaneously.

A key factor for continual learning is task similarity. If two subsequent tasks are similar, there is a potential for a knowledge transfer from one task to another, but the risk of interference also becomes high [47; 28; 35; 11; 39]. The impact of task similarity on transfer and retention performance is particularly complicated because two tasks can be similar in different manners [65; 32]. Sometimes familiar input features need to be associated with novel output patterns, but at other times, novel input features need to be associated with familiar output patterns. Previous works observed that thesetwo scenarios influence continual learning differently , yet the impact of the input and output similarity on knowledge transfer and retention has not been well understood. Moreover, it remains unknown how the task similarity interacts with algorithms for continual learning such as activity gating or weight regularization.

To gain insight into these questions, in this work, we investigate how transfer and retention performance depend on task similarity, task-dependent gating, and weight regularization in analytically tractable teacher-student models. Teacher-student models are simple, typically linear, neural networks in which the generative model of data is specified explicitly by the teacher network [18; 66; 3]. These models have provided tremendous insights into generalization property [55; 45; 19; 1], convergence rate [61; 58; 38], and learning dynamics [51; 52; 4; 25] of neural networks, due to their analytical tractability. Several works also studied continual learning using teacher-student settings [2; 35; 27; 11; 20; 37; 13] (see Related works section for details).

We develop a linear teacher-student model with a low-dimensional latent structure and analyze how the similarity of input features and readout patterns between tasks affect continual learning. We show analytically that a combination of low feature similarity and high readout similarity is relatively benign for continual learning, as the retention performance remains high and the transfer performance remains non-negative. However, the opposite, a combination of high feature similarity and low readout similarity is harmful. In this regime, both transfer and retention performance become below the chance level even when the two subsequent tasks are positively correlated. Furthermore, transfer performance depends on the feature similarity non-monotonically, such that, beyond a critical point, the higher the feature similarity is, the lower the transfer performance becomes.

We further analyze how common algorithms for continual learning, activity and plasticity gating [15; 42; 46], activity sparsification , and weight regularization [30; 36; 67], interact with task similarity in our problem setting, deriving several non-trivial conclusions. Activity gating improves retention at the cost of transfer when the gating highly sparsifies the activity, but helps both transfer and retention on average if the activity is kept relatively dense. Plasticity gating and activity sparsification, by contrast, do not influence either transfer or retention performance at the over-parameterized limit. Lastly, weight regularization in the Fisher information metric helps retention without affecting knowledge transfer and achieves perfect retention regardless of task similarity in the presence of low-dimensional latent. However, its diagonal approximation and the regularization in the Euclidean metric are much less robust against both task similarity and regularizer amplitude.

Furthermore, we test our key predictions numerically in a permuted MNIST task with a latent structure. When the input pixels are permuted from one task to the next, the retention performance remains high. However, when the mapping from the latent to the target output is changed, both the retention and transfer performance go below the chance level, as predicted. Random task-dependent gating of input and hidden layer activity improves retention at the cost of knowledge transfer, but adaptive gating mitigates this tradeoff. We also show that in a fully-connected feedforward network, there exists an efficient layer-wise approximation of the weight regularization in the Fisher information metric, which outperforms its diagonal approximation and the regularization in the Euclidean metric. Nevertheless, the performance of the diagonal approximation is much closer to the layer-wise approximation of the Fisher information metric than to the Euclidean weight regularization.

Our theory thus reveals when continual learning is difficult, and how different algorithms mitigate these challenging situations, providing a basic framework for analyzing continual learning in artificial and biological neural networks.

## 2 Related works

Previous works on continual learning in linear teacher-student models found that forgetting is most prominent at the intermediate task similarity [11; 40; 13] as observed empirically . However, these works did not address the tradeoff between forgetting and knowledge transfer, and these simple settings did not disentangle the effect of the similarity in input feature and readout pattern. Forward and backward transfer performance in continual learning were also analyzed in linear and deep-linear networks [33; 8], yet its relationship with catastrophic forgetting has not been well characterized. Lee et al.  analyzed dynamics of both forgetting and forward transfer in one-hidden layer nonlinear network under a multi-head continual learning setting. However, their analysis of readout similarity and its comparison to feature similarity were conducted numerically and it did not address the effect of common heuristics, such as gating or weight regularization, either.

By comparison, we introduce a low-dimensional latent structure into a linear teacher-student model, which enables us to decouple the influence of feature and readout similarity on knowledge transfer and retention. Moreover, this low-dimensionality assumption on the latent enables us to evaluate the transfer and retention performance analytically even in the presence of gating or weight regularization in the Fisher information metric.

Continual learning has been studied from many theoretical frameworks beyond teacher-student modeling, including neural tangent kernel [5; 9; 27], PAC learning [6; 60], and computational complexity . Learning of low-dimensional latent representation has also been studied in the context of multi-task learning [43; 62]. In addition, several works investigated the effect of weight regularization on continual learning in analytically tractable settings [30; 12; 24]. In particular, Evron et al.  investigated effect of weight-regularization in Fisher-information metric in continual linear regression scenario.

## 3 Teacher-student model with low-dimensional latent variables

Let us consider task-incremental continual learning of regression tasks. For analytical tractability, we consider a teacher-student setting where the target outputs are generated by the teacher network (Fig. 1A). We define the student network, which learns the task, as a linear projection from a potentially nonlinear transformation of the input, \(=W()\), where \(^{N_{x}}\) is the input, \(^{N_{y}}\) is the output, \(W^{N_{y} N_{x}}\) is the trainable weight matrix, and \(():^{N_{x}}^{N_{x}}\) is an input transformation. We use \(()=\) for the vanilla and weight regularization models, \(()=\) for the task-dependent gating model, and \(()=sgn()\{0,||-\}\) for the soft-thresholding model, where \(\) and \(\) are gating and thresholding vectors, respectively. Here, \(\) is an element-wise multiplication, and \(sgn(x)\) is a function that returns the sign of the input. Throughout the paper, we use bold-italic letters for vectors, capital-italic letters for matrices.

We generate the input \(\) and target output \(^{*}\) of the \(\)-th task using a latent variable \(^{N_{s}}\):

\[(0,I_{s}),=A_{}, ^{*}=B_{},\] (1)

for \(=1,2\), where \(A_{}^{N_{x} N_{s}}\) and \(B_{}^{N_{y} N_{s}}\) are mixing matrices hidden from the student network, and \(I_{s}\) is the size \(N_{s}\) identity matrix. We introduce this latent structure, \(\), to decouple the effect of feature and readout similarity on the transfer and retention performance. Below, we set the latent space to be low-dimensional compared to the input space (i.e., \(N_{s} N_{x}\)). This is motivated by the presence of low-dimensional latent structure in many machine learning datasets [64; 7] and the tasks used in neuroscience experiments [17; 26], but also aids analytical tractability.

We generate the mixing matrices for the first task, \(A_{1}\) and \(B_{1}\), by sampling elements independently from a Gaussian distribution with mean zero and variance \(}\). The subsequent task matrices \(A_{2}\) and \(B_{2}\) are also generated randomly, but with element-wise correlation with the previous matrices \(A_{1}\) and \(B_{1}\) (see Appendix A for the details). We denote the element-wise correlation between \(A_{1}\) and

Figure 1: **(A)** Schematic representation of the continual linear regression model with low-dimensional latent variables. **(B-D)** Examples of continual learning with two tasks in the MNIST setting. The tasks have low feature similarity in panel C (input pixels are partially permuted) and low readout similarity in panel D (output labels are partially permuted). Panels C and D correspond to the green and orange points in panel B, respectively.

\(A_{2}\) by \(_{a}\) and refer it as feature correlation, because \(A_{1}\) and \(A_{2}\) specify the input features. Similarly, we denote the correlation between \(B_{1}\) and \(B_{2}\), the readout correlation, by \(_{b}\). Figs. 1B-D illustrate the difference between \(_{a}\) and \(_{b}\) in an image classification setting. When \(_{a}<1.0\) and \(_{b}=1.0\), input features are partially modified in the second task compared to the first task (Green point on Fig. 1B and Fig. 1C). For example, permuted MNIST task  corresponds to this low feature similarity setting with \(_{a}=0.0\) and \(_{b}=1.0\). By contrast, when \(_{a}=1\) and \(_{b}<1\), the readouts are changed partially (Orange point on Fig. 1B and Fig. 1D). When \(_{a}=1\) and \(_{b}=-1\), the same input features are associated with the opposite readout in the new task, which is known as the reversal learning paradigm. In this reversal scenario, the network fails to achieve knowledge transfer rather trivially. Thus, we focus on the scenario when tasks have non-negative correlation in terms of both input features and readout (i.e., \(0_{a},_{b} 1\)) below.

We measure the performance of the student network with weight \(W\) on the \(\)-th task by mean-squared error \(_{}[W]}\|B_{}-W(A_{ })\|\|^{2}_{}\), where \(_{}\) is the expectation over latent variable \(\). The transfer and retention performance are defined by

\[_{TF}_{2}[W_{o}]-_{2}[W_{1}] _{A,B},_{RT}_{1}[W_{ o}]-_{1}[W_{2}]_{A,B}.\] (2)

Here, \(_{A,B}\) is the expectation over randomly generated task matrices \(A_{1},A_{2},B_{1}\) and \(B_{2}\) under a given feature and readout correlation \(_{a},_{b}\). As illustrated in Fig. 2A, the transfer performance \(_{TF}\) measures how much performance the model achieves on task 2 by learning task 1, whereas the retention performance \(_{RT}\) measures how well the model can perform task 1 after learning task 2 (here, the task switch occurs at the 100th iteration). Below, we study how knowledge transfer and retention, the two key objectives of continual learning, depend on task similarity, and how to optimize the performance through gating and weight regularization.

## 4 Impact of task similarity on knowledge transfer and retention

Let us first investigate the vanilla model without gating or weight regularization, to examine how task similarity affects knowledge transfer and retention. Given \(()=\), at the infinite sample limit, learning by gradient descent follows \(=-(WA_{}-B_{})A_{}^{T}\). The fixed point of this dynamics, as detailed in Appendix B.1, is:

\[W_{}=W_{-1}(I-U_{}U_{}^{T})+B_{}A_{}^{+},\] (3)

where \(W_{-1}\) is the weight after learning of the previous task, \(U_{}\) is the semi-orthogonal matrix from singular value decomposition (SVD) of \(A_{}=U_{}A_{}V_{}^{T}\), and \(A_{}^{+}\) is the pseudo-inverse of matrix \(A_{}\)

Figure 2: Transfer and retention performance of the vanilla model. **(A)** Illustration of \(_{TF}\) and \(_{RT}\). Red and blue lines represent the error on task 1 and task 2, respectively. Here, the model was trained on task 1 for 100 iterations and then trained on task 2 for another 100 iterations. **(B, C)** Transfer performance under various task similarity. Points in panel **B** are numerical results (the means and the standard deviations over ten random seeds), while solid lines are analytical results (Eq. 4). **(D-G)** Retention performance under various task similarity. Panel **G** magnifies the \(0.9_{b} 1.0\) region of panel **E**, and the white dashed line in panel **G** represents local minima/maxima.

Inserting Eq. 3 into Eq. 2 and taking the expectation over randomly generated tasks \(A_{1},B_{1},A_{2},B_{2}\), the transfer and retention performance are written as (see Appendix B.1)

\[_{TF}=_{a}(2_{b}-_{a}),_{RT}=1- _{a}^{2}(_{a}^{2}-2_{a}_{b}+1).\] (4)

Recall that \(_{a}\) is the feature similarity defined by the correlation between \(A_{1}\) and \(A_{2}\), while \(_{b}\) is the readout similarity, representing the correlation between \(B_{1}\) and \(B_{2}\). The derivation of the above equations relies on (correlated) random generation of \(A_{1},B_{1},A_{2},B_{2}\) and the low-rank latent assumption: \(N_{s} N_{x}\). These two equations, despite their simplicity, capture the transfer and retention performance in numerical simulations well (Figs. 2B, D, and F; see Appendix E.1 for the details of numerical estimation). Furthermore, they reveal asymmetric and non-monotonic impact of the feature and readout similarity on the performance.

Fig. 2B depicts the knowledge transfer from task 1 to task 2, \(_{TF}\), under various \((_{a},_{b})\) conditions. As expected, \(_{TF}=0\) when the two tasks are independent (i.e., \((_{a},_{b})=(0,0)\)), and \(_{TF}=1\) when the tasks are identical (i.e., \((_{a},_{b})=(1,1)\)). At intermediate levels of similarity, there is clear asymmetry in the influence of feature and readout similarities on transfer performance; particularly, a combination of high feature similarity and low readout similarity leads to negative transfer, while the opposite scenario results in a modest positive transfer (lower-right vs upper-left of Fig. 2B).

Notably, under a fixed readout similarity \(_{b}\), the knowledge transfer depends non-monotonically on the feature similarity \(_{a}\). When \(_{a}<_{b}\), the higher the feature similarity the better transfer becomes, as implied from Eq. 4. However, once the feature similarity exceeds the readout similarity, counter-intuitively, high feature similarity worsens the transfer performance (Figs. 2B and C). This is because, when the feature similarity is high, inputs are aligned with learned features, resulting in a large output regardless of readout similarity. Particularly, under a low readout similarity, performance becomes below zero because extracted features are mostly projected to the incorrect directions.

The retention performance also exhibits asymmetric dependence on feature and readout similarity. When feature similarity \(_{a}\) is low, the network barely forgets the previous task regardless of readout similarity (Fig. 2D left). By contrast, when the feature similarity is high, the retention performance can either be positive or negative depending on the readout similarity. Moreover, in the high readout similarity regime, the retention performance is the lowest at an intermediate feature similarity (Figs. 2E and F). This is because high retention is possible when either interference is low, or similarity between two tasks is high. Note that, this last point on the non-monotonic dependence on feature similarity under \(_{b}=1\) has been investigated both empirically  and analytically [35; 11; 13]. Indeed, at \(_{b}=1\), \(_{RT}\) in Eq. 4 coincides with Eq. (5) in .

Therefore, the knowledge transfer and retention performance depend on feature and readout similarities in an asymmetric and non-monotonic manner. Specifically, a combination of high feature similarity and low readout similarity is detrimental to continual learning, resulting in negative transfer and retention performance, even in the presence of a positive correlation between the two tasks in both input features and readout patterns. Moreover, under a fixed readout similarity, the knowledge transfer performance depends on the feature similarity in a non-monotonic manner. Thus, the continual learning in the vanilla model is sensitive to task similarity and limited in performance. These results make us wonder whether we can mitigate the sensitivity to task similarity and improve the overall transfer and retention performance by modifying the learning algorithm. To this end, we next investigate how task-dependent gating and weight regularization methods, two popular strategies in continual learning, alleviate knowledge transfer and retention.

## 5 Task-dependent gating

### Random activity gating

One popular method for mitigating forgetting in continual learning is activity gating [15; 54; 42; 21; 56]. With gating of input activity, the network is written as \(=W(_{})\), where \(_{}\{0,1\}^{N_{x}}\) is a binary gating vector for task \(\). We first consider a random gating scenario where elements of \(_{}\) are randomly sampled from a Bernoulli distribution with rate \(\) which we denote as the gating level. All units are active at \(=1\), while no units are active at \( 0\) limit.

From a parallel argument with the vanilla model, when \(N_{s} N_{x}\), the transfer and retention performance are estimated as (see Appendix B.1):

\[_{TF} =_{a}(2_{b}-_{a}),\] (5a) \[_{RT} =1-^{2}_{a}^{2}(^{2}_{a}^{2}-2_{a} _{b}+1).\] (5b)

Thus, random gating scales the feature similarity from \(_{a}\) to \(_{a}\). This scaling lowers the knowledge transfer if \(_{b}_{a}\) because random gating reduces the fraction of input neurons active in two subsequent tasks (line line in Fig. 3A). However, if \(_{b}<_{a}\), gating with \(}{_{a}}\) enhances the transfer by reducing the effective feature similarity (blue lines in Fig. 3A; also compare Fig. 3B with Fig. 2C). The optimal gating level \(^{*}\) for knowledge transfer is \(\{}{_{a}},1\}\), indicating that the input activity typically needs to be dense. By contrast, the retention performance is optimized at \( 0\) limit where tasks do not interfere with each others (Fig. 3C). At this limit, we have \(_{RT} 1\). Note that, in reality, \(\) has to be non-zero to optimize the retention (Eq. 5b holds only when \(}{N_{x}}\)).

These results indicate that random activity gating improves the retention at the cost of forward knowledge transfer, as suggested previously [28; 39; 29]. This tradeoff between knowledge transfer and retention is especially critical when the network doesn't know the task similarities. Suppose that the task similarity is distributed uniformly over \(0_{a},_{b} 1\). Then, the average transfer performance is maximized at \(=\), while the average retention performance decreases monotonically as a function of \(\) (Fig. 3D). Thus, a moderate gating (\(\)) benefits both transfer and retention on average. However, retention performance in this regime is significantly below one, implying that the network cannot reliably achieve high retention performance without sacrificing the transfer performance.

### Adaptive activity gating

One way to overcome the tradeoff between transfer and retention performance is to consider adaptive gating. Let us introduce a probe trial at the beginning of the task 2, in which the model tests how well it performs if it uses the gating for task 1, \(_{1}\), for task 2 as well. If the error in the probe trial is small, the model should keep using the same gating vectors to achieve a good knowledge transfer. Otherwise, it should resample the gating vector for retaining the knowledge on task 1. Using the

Figure 4: Transfer and retention performance of the adaptive activity gating (**A, B**), random plasticity gating (**C**), and input soft-thresholding (**D**) models. Dashed and solid lines in panels **A** and **B** represent the performance of the random and adaptive activity gating models, respectively.

Figure 3: Random task-dependent activity gating model. **(A)** Knowledge transfer performance under \(_{a}=1.0\). The gating level \(\) is defined as the fraction of active input neurons (i.e., \(=[g_{i}=1]\)). **(B)** The transfer performance under the optimal gating level \(^{*}=\{}{_{a}},1\}\). **(C)** Retention performance under \(_{a}=1.0\). **(D)** Average transfer and retention performance over uniform prior on \(0_{a},_{b} 1\). Horizontal dashed lines are the performance of the vanilla model, while solid lines are the performance of the random gating model. Points are numerical estimations.

probe error \(_{pb}\), we set the probability of using the same gating as \(_{g}=1-_{pb}/_{o}\). This adaptive gating indeed improves the average transfer performance compared to the random gating (solid vs dashed lines in Fig. 4A) with only a relatively small reduction in the retention performance (Fig. 4B).

### Plasticity gating and input soft-thresholding

Previous works have also explored other gating mechanisms, such as plasticity gating  and activity sparsification . However, their benefits over the activity gating discussed above have not been fully understood. We implement task-dependent plasticity gating into our problem setting by making only the synaptic weights projected from a subset of input neurons plastic. Unexpectedly, we found that both transfer and retention performance are independent of the fraction of plastic synapses in the \(N_{s} N_{x}\) limit, potentially due to over-parameterization (Fig. 4C; see Appendix B.2 for details).

Similarly, when the input activity is sparsified using soft-thresholding \((x)=sgn(x)\{0,|x|-h\}\), with a fixed threshold \(h=^{-1}()\), the transfer and retention performance remain independent of the resultant input sparsity \(\) (Fig. 4D; see Appendix B.3 for the details). These results imply that plasticity gating and input sparsification are not effective in our model, which operates in an over-parameterized regime (i.e., \(N_{s} N_{x}\)), but do not exclude their potential benefits for many continual learning tasks.

## 6 Weight regularization

### Weight regularization in Euclidean metric

Another popular method is weight regularization, which keeps the synaptic weights close to those learned from previous tasks [30; 67; 36]. Let us first consider regularization of the Euclidean distance between the current weight \(W\) and the weight learned in the previous task \(W_{-1}\):

\[_{}=\|B_{}-WA_{}\|_{F}^{2}+}{ 2N_{s}}(-1)\|W-W_{-1}\|_{F}^{2}.\] (6)

Here, we parameterize the regularizer amplitude by \(}{N_{s}}(-1)\) using a non-negative parameter \(\) for brevity. \(=1\) corresponds to zero regularization, while \(=0\) is the infinite regularization limit. Under this parameterization, if \(N_{s} N_{x}\), the transfer and retention performance follow simple expressions as below (see Appendix C.1):

\[_{TF} =_{a}(2_{b}-_{a}),\] (7a) \[_{RT} =1-^{2}_{a}^{2}(1-2_{a}_{b}+^{2} _{a}^{2})+2_{a}(1-)(_{b}-_{a})-(1-)^{2}.\] (7b)

The expression of the transfer performance is equivalent to Eq. 5a if we change \(\) to \(\). Thus, the Euclidean weight regularization with amplitude \(}{N_{s}}(-1)\) is mathematically equivalent with random activity gating with sparsity \(\), in terms of knowledge transfer (compare Fig. 5A with Fig. 3A). By contrast, the expression of the retention performance contains two additional terms compared to 5b. In particular, the last term, \((1-)^{2}\), indicates that strong weight regularization not only prevent forgetting, but also impairs task acquisition. Thus, the retention performance is optimized at an intermediate regularizer strength (Figs. 5B and C).

Figure 5: Performance of weight regularization in Euclidean metric. **(A,B)** Transfer **(A)** and retention **(B)** performance. The amplitude of the weight regularization scales with \(-1\). **(C)** Regularizer coefficient \(\) that optimizes the retention performance. **(D)** Average performance over uniform task similarity distribution in \(0_{a},_{b} 1\). Horizontal dashed lines are the performance of the vanilla model.

Because strong regularization (i.e., small \(\)) impairs both retention and transfer, unlike the random activity gating model, there isn't a tradeoff between knowledge transfer and retention in terms of the average performance over \(0_{a},_{b} 1\) (Fig. 5D). However, the retention performance at the optimal parametric regime is relatively low (Fig. 5D with Fig. 4B).

### Weight regularization in Fisher information metric

Previous works proposed that the synaptic weights should be regularized in the Fisher information metric to allow flexibility in the non-overlapping weight space [30; 67]. Applying it to our model setting, the regularizer term in Eq. 6 instead becomes \((-1)\|(W-W_{-1})A_{-1}\|_{F}^{2}\) (see Appendix C.2). If \(_{a},<1\) and \(N_{s} N_{x}\), optimization of the weight under this regularization yields

\[W_{}=W_{-1}(I-}{N_{s}(1-_{a}^{2})}A_{}[A_{ }^{T}-_{a}A_{-1}^{T}])+}{N_{s}(1-_{a}^{2 })}B_{}(A_{}^{T}-_{a}A_{-1}^{T}),\] (8)

where \(W_{-1}\) is the weight after the previous task learning. Notably, the weight becomes independent of the regularizer's amplitude \(\). Furthermore, the retention performance under arbitrary task similarity \((_{a},_{b})\) is derived as \(_{RT}=1-(}{N_{s}(1-_{a}^{2})})\). Thus, under the Fisher information metric, the retention performance is perfect as long as the condition \(N_{s} N_{x}(1-_{a}^{2})\) is satisfied (Figs. 6A-C). Intuitively, assuming over-parameterization (\(N_{s} N_{x}\)), the network can freeze the weight changes in a low-dimensional subspace, while maintaining sufficient plasticity for new tasks, unless the two tasks share the same feature. Notably, if the first task is learned with weight regularization in an orthogonal direction, the transfer performance remains the same with the vanilla model (Fig. 6C).

Importantly, this invariance no longer holds when the Fisher information metric is approximated by its diagonal component (Figs. 6D vs 6C), as is done in the elastic weight methods . This is because the diagonal approximation makes the metric full-rank even when the true metric has a low-rank structure. Thus, weight regularization in the Fisher information metric robustly helps retention without harming transfer, but diagonal approximation attenuates its robustness.

## 7 Numerical experiments

Our theory so far has revealed when continual learning is difficult and when activity gating and weight regularization can ameliorate the transfer and retention in a simple problem setting. Let us next examine how much these insights are applicable to more realistic datasets and neural architectures.

To this end, we consider the permuted MNIST dataset [34; 22], but with a latent structure (see Appendix E.2). For each output label, we constructed a four-dimensional latent variable \(\) using the binary representation of the corresponding digit (e.g., \(_{9}=^{T}\)). The target output was then generated by a random fixed projection of the latent variable: \(^{*}=B_{}(-)\). Note that, although here we introduced an explicit latent structure for a direct comparison with the theory, qualitatively similar results holds in the vanilla permuted MNIST setting depicted in Figs. 1B-D (see Fig. 12). We controlled the readout similarity between tasks using the element-wise correlation between two matrices \(B_{1}\) and \(B_{2}\). The feature similarity was controlled by permuting a subset of input pixels, as in the previous permuted MNIST tasks. We used a one-hidden-layer fully-connected network with rectified-linear nonlinearity at the hidden layer, and trained the network using stochastic gradient descent.

Figure 6: Weight regularization in the Fisher information metric. **(A,B)** The retention performance under various task similarities and regularizer coefficients. **(C,D)** Average transfer and retention performance under the regularization with the exact Fisher information metric **(C)** and its diagonal approximation **(D)**.

As predicted from our theory, both transfer and retention performance, measured by the test error, exhibited asymmetric and non-monotonic dependence on the task similarity. When \((_{a},_{b})=(1.0,0.0)\), both transfer and retention performance were below zero (lower-right of Figs. 7A and B vs. Figs. 2C and E). By contrast, the model achieved high retention and zero transfer under \((_{a},_{b})=(0.0,1.0)\) as expected (upper-left). Notably, around \(_{b}=0.5\), the transfer performance exhibited a non-monotonic dependence on \(_{a}\) in accordance with the theory. The retention performance also exhibited non-monotonic dependence on \(_{a}\) under \(_{b} 1\), but the dependence became monotonic after a long training (see Figs. 9C and D in Appendix). We observe consistent results even when feature and readout similarity are adjusted by permuting input pixels and output labels, respectively, provided the loss is measured by cross-entropy (Fig. 12B, corresponding to the examples depicted in Figs. 1C and 1D).

Random activity gating, implemented in both input and hidden layers, improved the retention performance at the cost of low knowledge transfer as predicted (compare Fig. 7D and Fig. 4B). Moreover, adaptive gating based on a probe trial improved the transfer performance under a low gating level, especially when the readout similarity is high (solid vs dashed lines in Figs. 7C and D).

In a deep neural network, weight regularization using the Fisher information metric is typically computationally expensive. However, an efficient layer-wise approximation exists for fully-connected networks (see Appendix E.2). This layer-wise approximation enabled high retention performance across a wide range of regularization amplitudes and consistently outperformed weight regularization in the Euclidean metric under various task similarities (red vs. gray lines in Figs. 7F-H). Nevertheless, the retention performance under the diagonal approximation was closer to that of the layer-wise approximation of the Fisher information metric and was slightly better when both methods performed poorly (red vs. orange lines). This is because the sparsity of hidden layer weights and activity makes the diagonal components sparse.

## 8 Discussion

Here, we analyzed the impact of task similarity on continual learning in a linear teacher-student model with low-dimensional latent structures. We showed that, a combination of high feature similarity and low readout similarity lead to poor outcomes in both retention and transfer, unlike the opposite combination. We further explored how continual learning algorithms such as gating mechanisms, activity sparsification, and weight regularization interact with task similarity. Results indicate that weight regularization in the Fisher information metric significantly aids retention regardless of task similarity. Numerical experiments in a permuted MNIST task with latent supported these findings.

Figure 7: Permuted MNIST with latent variables. (**A,B**) Transfer and retention performance of the vanilla model. (**C,D**) Performance of random (dashed lines) and adaptive (solid lines) activity gating models. (**E-H**) Performance of the weight regularization in the Euclidean metric, and approximated Fisher information metrics (red: layer-wise approximation; orange: synapse-wise/diagonal approximation). Here, lines are linear interpolations and error bars are standard errors over random seeds, not standard deviations.

Our findings on the interaction between task similarity and continual learning algorithms have several implications. Firstly, when tasks are known to have high feature similarity and low readout similarity, adaptive activity gating and weight regularization in the Fisher information metric help retention without sacrificing transfer (Figs. 4, 6, 7). In the context of neuroscience, our results indicate that simple non-adaptive activity or plasticity gating mechanisms are not sufficient for good continual learning performance, especially when familiar sensory stimuli need to be associated with novel motor actions. Indeed, a previous study reported catastrophic forgetting among rats learning timing estimation tasks . Lastly, it also implies the potential importance of studying wider benchmarks beyond permuted image recognition tasks for continual learning, because image permutation belongs to a class of relatively harmless task similarity according to our theory. As a simple extension, here we developed an image recognition task with a latent variable and showed that a vanilla deep network exhibits more forgetting under readout remapping than under input permutation (Figs. 7A and B).

LimitationsOur theoretical results from a teacher-student model come with limitation in direct applicability. The presence of low-dimensional latent generating both input and target output is a reasonable assumption for many real-world tasks , but the linear projection assumption is not. While we replicated most key results in a deep nonlinear network solving permuted MNIST task, we found that the diagonal approximation of Fisher information metric performs much better than the prediction from the teacher-student model. This is potentially because sparse activity at the hidden layer effectively makes the regularization low-rank even under the diagonal approximation. More generally, the presence of hidden layers should enable a distinctive adaptation for feature and readout similarity, which is an important future direction. It is also important to apply our theoretical framework for analyzing continual learning in more complicated neural architectures and datasets.

## 9 Acknowledgments

The author thanks Liu Ziyin and Ziyan Li for discussion. This work was partially supported by The Swartz Foundation.