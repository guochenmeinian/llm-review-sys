# WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off

Eva Giboulot

Inria, CNRS, IRISA

University of Rennes

Rennes, France

eva.giboulot@inria.fr &Teddy Furon

Inria, CNRS, IRISA

University of Rennes

Rennes, France

teddy.furon@inria.fr

###### Abstract

Watermarking is a technical means to dissuade malfeasant usage of Large Language Models. This paper proposes a novel watermarking scheme, so-called WaterMax, that enjoys high detectability while sustaining the quality of the generated text of the original LLM. Its new design leaves the LLM untouched (no modification of the weights, logits, temperature, or sampling technique). WaterMax balances robustness and complexity contrary to the watermarking techniques of the literature inherently provoking a trade-off between quality and robustness. Its performance is both theoretically proven and experimentally validated. It outperforms all the SotA techniques under the most complete benchmark suite.

## 1 Introduction

The availability of powerful large-language models (LLMs) allows users to produce texts that look like human writings. The risk for misuse of these models is critical, ranging from the impersonation of individuals to the large-scale generation of fake news. Identifying the provenance of a given piece of text is paramount to limit the impact of such 'weaponization' of LLMs. New initiatives or regulations impose technical means for AI traceability .

Forensics passive methods generally leverage a priori knowledge about the statistics of texts generated by a given class of LLMs . Despite their versatility, these methods offer low performance. The reported probabilities of errors are only validated empirically on some datasets, and because of this, they are never lower than \(10^{-3}\).

In contrast, active methods like watermarking are only limited by the fact the LLM owner must integrate the watermarking within the generation processes. This is done by embedding an imperceptible signal in the generated text, which can be retrieved by a detector sharing the secret key of the model owner. Current watermarking methods for generative texts  provide low and guaranteed false positives rates. Yet, the trade-off between the detectability and the text quality crucially depends on the entropy of the text to be generated, which in turn depends on the prompt and the LLM, as illustrated in Fig. 1. This implies that the distortion-free property  ensures that watermarking does not degrade text quality but inherently limits the detectability.

This paper presents WaterMax, a watermarking technique that trades off robustness not for quality, but for complexity. It obeys the regular constraints found in the literature: it can be integrated into any standard LLM without fine-tuning the weights, the detection does not need the original LLM, and it can spot the watermark on a slice of generated text with some guarantee on the false positive rate. Our contributions are the following:* WaterMax is based on a new design not relying on the usual mechanisms of the literature; especially, it keeps the next token distribution and sampling (temperature and method) intact. Moreover, it better utilizes the text entropy by working over sub-sequences of tokens, so-called chunks hereafter, rather than token by token.
* This new design makes WaterMax almost distortion-free, as shown experimentally (Sect. 7.3) and justified theoretically (App. H), and yet enjoys higher robustness than the state-of-the-art, consistently over several LLMs. Figure 1 shows that the other methods need to boost the watermark strength to be as detectable as WaterMax, inevitably degrading the quality.
* This new design facilitates building up a theoretical model of the watermark robustness characterizing the true positive rates under attack (see Prop. 5.2).

## 2 Related Work

Watermarking texts generated by LLMs is mainly performed by changing either the distribution  or the sampling [1; 23; 8] of the next token. Critically, the false-positive rate of these methods can be reliably controlled . Furthermore, the computational cost of most of these methods is negligible relative to the text generation itself. On the other hand, they all suffer from similar weaknesses:

Text entropy limitSome theoretical works [8; 17; 21; 1] show that the watermark detectability is highly dependent on the entropy of the text to be generated. In practice, this makes the text length necessary for reliable watermark detectability dependent on the type of the text, and also the LLM. One may increase the watermark strength or the temperature in the LLM to increase the entropy artificially [19; 26]. Both solutions degrade text quality compared to the original LLM.

Distortion-freeness and qualityKuditipudi et al.  define that a watermark is distortion-free if it does not modify the probability distribution of the next token _on average_ over the keys. This is guaranteed in schemes like [1; 23; 8]. Yet, these schemes rely heavily on the entropy of the token distribution, leading to possibly low detectability without any means to increase it without losing distortion-freeness. Appendix J illustrates the dependence of Aaronson's scheme on the original LLM. Moreover, a scheme that is not distortion-free does not necessarily lead to texts with lower _empirical_ quality, but foreseeing the impact of the watermark strength on the quality is an issue.

Watermark robustness characterizationThe watermark must resist text editing ranging from a simple insertion of words to a complete paraphrasing of the text. At the time of writing, there are only two watermarking schemes designed from the ground up to be robust [23; 35]. Yet, other state-of-the-art methods have experimentally shown resiliency to attacks against long-form texts  under a precise control of the false-positive rate . However, none of these methods can theoretically guarantee its robustness. Only bounds on the moments of the detection score are provided in  and .

Figure 1: Detectability as a function of text quality for different LLM architectures. WaterMax always reaches a detectability close to \(1\) despite a negligible loss of quality. Probability of false-alarm fixed at \(10^{-6}\), nucleus sampling (\(top_{p}=0.95\)) at temperature \(1.0\). Text quality is measured as the relative perplexity of the watermarked text over the non-watermarked text.

This work presents a scheme that **empirically** incurs a negligible loss while reaching an arbitrarily high detectability even on small texts. The parameter tuning trades robustness for complexity but has almost no impact on the text quality. Moreover, we characterize its performance under a large attack range by expressing both false-alarm and true-positive rates. Its drawback is a large computational cost, which we show how to limit throughout the paper.

## 3 Main Idea: Watermarking by generating multiple texts

This section first presents a simplified and inefficient version of the method for a pedagogical purpose. The driving idea is that a LLM is a randomized algorithm. In its simplest implementation, the LLM computes a probability distribution of the next token and _randomly_ samples according to this distribution. The chosen token is appended to the context, and the process iterates. Our main idea is to let the LLM generate several texts for a given prompt and select the one that is the most suitable from the watermarking point of view.

Initially, we select a sound watermark detection algorithm in the sense that it can output a \(p\)-value for any piece of text under scrutiny. Usually, such detection computes a score and then 'normalizes' it in a \(p\)-value defined as the probability that a non-watermarked text yields a score equal to or higher. Appendix A lists some candidates from the literature and presents our own design.

Our watermarking embedding lets the LLM generate \(n\) texts for a given prompt. Since all pieces of text are generated normally, _i.e._ without being degraded by a watermark, their qualities are likely high. From the \(n\) generated texts, the LLM outputs the text with the lowest \(p\)-value.

The advantages are that the text quality is not degraded and that any sound detection may be used. The price to pay is high complexity and long latency. Suppose that a text is deemed watermarked if its \(p\)-value evaluated by the detector is lower than the required false alarm probability \(P_{FA}\). This raises the question of the number \(n\) of generated texts for successfully embedding the watermark.

**Proposition 3.1**.: _The detectability measured by the power of the test, i.e. the probability \(P_{D}\) of detecting a watermarked text is the following increasing function w.r.t. \(n\):_

\[P_{D}(P<P_{FA}|_{1})=1-(1-P_{FA})^{n}. \]

Appendix B gives a sketch of the proof. We point the reader to two important advantages:

* The performance does not depend on the choice of score function used to obtain the \(p\)-value.
* The performance does not depend on the length of the text. Consequently, even an extremely small text can be watermarked in theory.

Figure 2 plots the power of the test as a function of \(n\) for various probabilities of false alarm. Whatever the choice of \(P_{FA}\), one can clearly observe that a huge number of generated texts (\( 50\)) is required to obtain a power greater than \(0.5\), which is unacceptable in practice. Section 4 shows how to improve this base algorithm to reach arbitrarily high power with a smaller computational power.

Another weakness is the assumption that the LLM can create \(n\) texts whose \(p\)-values are independent. For some prompts, the diversity (_i.e._ entropy) is indeed small, which implies that the LLM creates similar texts or even duplicates of text among the \(n\) outputs. Section 6 investigates how self-synchronization mitigates this issue.

## 4 Watermarking chunks of text

This section devises ways to efficiently explore the space of possible texts to find a low \(p\)-value. The idea is to split the generation into \(N\) iterations, each iteration creating a chunk of the text. The aim is to reduce the computational burden by generating small chunks while exploring many possible texts.

### Exploring the text space

For each chunk, a batch of \(n\) text drafts is generated independently based on the text candidates of the previous iteration. Ideally, one would generate \(n\) drafts at each chunk for each previous candidate, resulting in a tree of \(n^{N}\) texts from which to choose the lowest \(p\)-value. Obviously, this is not tractable. We reduce the complexity by keeping only the \(m\) best candidates at each step, akin to a Viterbi algorithm . The pseudo-code is summarized in Alg. 1 in App. F. This is suboptimal because the candidates minimizing the \(p\)-value at a given step may not be the best once completed at iteration \(N\). Other exploration strategies range from greedy search to Monte Carlo Tree Search . The pseudo-code is summarized in Alg. 1 within Appendix F.

### Cumulative scores

This paper considers detection schemes that share the following process. The vocabulary \(\) is a list of \(||\) admissible tokens, and a text is decomposed into a sequence of \(L\) tokens. Depending on the secret key \(k\), the detection associates to the \(i\)-th token a variable \(u_{i}\). The score is computed as the sum over the tokens \(s=_{i=1}^{L}u_{i}\). This is translated into a \(p\)-value assuming that, under \(_{0}\), i) the scores of the tokens are independent and identically distributed random variables \((U_{i})_{i=1}^{L}\), giving birth to a random score \(S\), ii) whose c.d.f. \(F_{S}(;L)\) is known so that the \(p\)-value is simply:

\[p=(S>s)=1-F_{S}(s;L). \]

Appendix A lists some detection schemes of the literature following this procedure. Our choice is simply \(U_{i}}}{{}}(0;1)\) so that \(F_{S}(s;L)=(s/)\).

For the sake of clarity, suppose that the chunks are composed of \(\) tokens. At iteration \(i\), the \(j\)-th candidate has a score denoted \(s_{i,j}\) and \(n\) drafts for its following chunk are proposed. This produces \(n\) incremented scores per candidate, thus \(mn\) variables: \(s_{i,j}+ s_{i,j,k}\), \(1 j m\), \(1 k n\). Since these scores are converted into \(p\)-values by the same function, _i.e_. \(p=1-F_{S}(s;(i+1))\), selecting the \(m\) lowest \(p\)-values amounts to keep the \(m\) maximal cumulative scores, hence the name WaterMax.

### Low latency

One issue is the latency: the final text cannot be issued until all candidates reach an end of sequence. This problem is fixed with the drastic choice \(m=1\). It amounts to a greedy search appending to the text at iteration \(i\) the chunk draft yielding the biggest incremental score \( s_{i,1,k}\). This choice enables the output of a chunk of text at the end of each iteration, hence reducing latency. Of note, this also corresponds to the draft with the lowest local \(p\)-value \(1-F_{S}( s_{i,1,k};)\).

### Optimal detection without attack

This section introduces a simple detector to reveal the advantage of our watermark embedding. The idea is that the received text is composed of chunks whose local \(p\)-values are distributed as beta distributions \(B(1,1)\) (_i.e_. \(_{}\)) under \(_{0}\) or \(B(1,n)\) under \(_{1}\) (see Appendix. B). This is a generalization of the algorithm of the previous section, the only difference being that the likelihood ratio (12) now aggregates a vector \(\) of \(N\) observed local \(p\)-values:

\[_{}()=-_{i=1}^{N}(1-p_{i})_{ _{1}}^{_{0}}. \]

**Proposition 4.1**.: _The optimal detector \(_{}\) has the following performances when there is no attack:_

\[P_{FA}=_{N,1}(), P_{D}=_{N,}( _{N,1}^{-1}(P_{FA})), \]

_where \(_{x,y}\) is the lower incomplete gamma function with shape parameter \(x\) and scale parameter \(y\)._

Appendix C gives a sketch of the proof. The power of the test \(P_{D}\) is an increasing function of \(n\). Again, note that neither the token variables distribution nor the chunk length s affects the detectability.

Figure 3 illustrates the efficiency of our exploration strategy of the text space. Contrary to Sect. 3, we can easily reach a power close to \(1\) even at \(P_{FA}=10^{-6}\). For example, using \(N=9\) chunks of \(n=15\) drafts, assuming a medium-size text of \(L=512\) tokens and chunks of equal length, one only needs to generate \(Nn=135\) chunk drafts of \(= L/N=57\) tokens to obtain a power of \(0.96\). This is equivalent to generating \(15\) texts of size \(512\). This is to compare to Sect. 3 where more than 3 million texts of \(512\) tokens are necessary to reach this power at \(P_{FA}=10^{-6}\).

## 5 Robust watermark detection

Until this point, our detector assumed that the text it receives is the generated text. Yet, before reaching the detector, a text might have been modified for legitimate or malicious reasons: it may be translated, curated, locally modified _etc._ This section assumes that the scores of individual tokens are distributed as standard Gaussian random variables to allow the derivation of closed-form solutions.

### Robust detection

Detector (3) is neither optimal nor robust under attack because the insertion or the removal of tokens provokes a desynchronization: The detector no longer knows where each chunk starts and ends, which is necessary for computing the local \(p\)-value of individual chunks. More robustness comes with a global score simply summing up over all the tokens:

\[_{}()=_{i=1}^{N}_{j=1}^{}u_{(i-1) +j}=_{i=1}^{L}u_{i}. \]

**Proposition 5.1**.: _The robust detector has the following test performance when there is no attack:_

\[P_{FA}=(-/), P_{D}((P_{FA} )+e(n)}{}). \]

_where \(e(n)\) (resp. \(v(n)\)) is an increasing (resp. decreasing) quantity computed in Tab. 1._

Appendix D gives a sketch of the proof. Figure 3 shows that the robust test (5) is slightly less powerful than the optimal test (3) when there is no attack. On the other hand, the next section shows that its power degrades smoothly under attacks contrary to (3).

### A model of the robustness against attack

Despite the variety of modifications that can be performed on a watermarked text, all attacks have the same end effect: modifying the tokens and potentially the number of tokens. This amounts to modifying a proportion of scores to be distributed following \(_{0}\) instead of \(_{1}\) in the global score. Formally, the score \(_{}()\) for a text of \(L\) tokens becomes: (assuming \( L\) is an integer)

\[_{}()=_{i=1}^{ L}U_{_{0}(i)}+_{i =1}^{(1-)L}_{_{1}(i)}, \]

where \(1-\) is the proportion of scores impacted by the attack whose variables are denoted \(\{_{i}\}\), and \(_{0}\) (resp. \(_{1}\)) is mapping to the indices of the untouched scores (resp. modified tokens). It is important to note that it does not matter if the size of the attacked text differs from the generated text.

**Proposition 5.2**.: _The robust detector has the following test performance under attack:_

\[P_{FA}=(-/), P_{D}((P_{FA})+ e(n)}{(v(n)-1)}}). \]

Appendix E gives a sketch of the proof. In the end, the power of the test decreases smoothly with the strength \((1-)\) of the attack. Once again, the power of the test does not depend on the text size.

## 6 Independence

This section discusses the assumptions made so far on the independence of the token and draft scores.

### Token scores independence

All random variables \((U_{i})\) associated with tokens must be independent and identically distributed within a text. This assumption has an impact on the power of the test and especially on the probability of false alarm. It must hold for non-watermarked text. Otherwise, the score of a chunk (or of a full text) is not properly normalized into a \(p\)-value.

We use the same technique as in  to enforce the token variable independence: the variable \(U_{i}\) of the \(i\)-th token of a text depends not only on the secret key but also on the hashing of the current token and the \(h-1\) previous tokens in the text (a window of size \(h\)). Furthermore, this \(h\)-gram is appended to a list. If the \(h\)-gram is already stored in that list, the variable of the current token is discarded. By doing so, we ensure that _for a given text_, the \((U_{i})\) are always different. Contrary to , this mechanism is enforced at the generation and the detection stages to ensure that both sides compute the same score.

### Draft score independence

At the embedding, the scores of the \(n\) drafts of a chunk are assumed to be independent. Yet, some correlations occur when parts of texts repeat across different drafts. For example, in a prompt asking "Who are you?", many drafts of the first chunk of the response likely start with "I am." This assumption only plays a role in the power of the detector, not its false-positive rate.

Causal hashing windowAt first sight, hashing the whole chunk draft for seeding each token variable brings draft score independence if the drafts differ at least by one token. Sadly, this creates a watermark that breaks even for a single modified token. _This forces us to use a causal window_: the score of each token depends only on itself and the previous tokens. The longer the hash window, the more likely a \(h\)-gram is new and the more diverse the scores. Yet, this diversity is obtained at the cost of robustness. Indeed, changing a single token in a text removes the watermark of \(h\) tokens because their variables depend on the modification. Another weakness: at a given iteration, the \(j\)-th token (\(j<h\)) of every draft always refers to the same \(h-j\) tokens since the previous chunk is identical for all these drafts. This means that the effective window size for this token is always smaller than \(h\).

Beam-searched enforced diversityThis weakness can be tackled by modifying the sampling procedure. It is important to guarantee a high diversity at the beginning of the chunk since this is where the effective window size is the smallest. We propose to generate the first \(b\) tokens using a standard beam-search procedure, which deterministically returns \(n\) different beginnings of the chunk. The rest of the draft is sampled normally. However, there is a trade-off. The smaller \(b\), the more diversity between the chunks and the closer to the independence assumption we get, the more likely the beam-search procedure selects tokens in the tail of the distribution (for a large enough number of drafts \(n\)), the poorer the text quality.

### Experimental validation

For the independence of the score variables, the experiment runs the detector on 100k Wikipedia entries from 2018 for ten different keys. Since the text of Wikipedia is free of any watermark, one should observe the \(p\)-values to be uniformly distributed, _i.e._ the empirical false alarm rate shouldmatch the theoretical probability of false alarm. Figure 3(a) demonstrates that this assumption holds for any window size \(h\). On the other hand, the robustness highly depends on the hashing window size, with \(h=6\) being a good trade-off between performance and robustness.

The second experiment measures how much we deviate from the draft score independence assumption. It generates \(296\) texts of \(256\) tokens on the three tasks from . The entropy of the generated texts may be low for a given chunk so that some parts of a text may be redundant among the drafts. Figure 3(b) reports how much our scores under \(_{1}\) deviate from the theoretical distribution.

This experiment demonstrates that the closer to \(1\) the number of tokens generated by beam search \(b\), the closer the scores match the theoretical distribution. Notice that even for a large \(b\), such as \(b=6\), there is a large improvement compared to a baseline WaterMax with \(b=0\). In Appendix I, we provide a more thorough experimental study of the parameters \(h\) and \(b\). In particular we show the trade-off between quality and detectability. In the rest of the paper, we select \(b=4\) where a small loss of quality is acceptable and \(b=6\) if a virtually lossless scheme is warranted.

## 7 Experiments

### Experimental protocol

The evaluation is performed on the three long-form creative writing tasks of the '_Mark My Words_' benchmark : news article generation, summarization of existing books, and writing of an invented story. This leads to the generation of \(296\) texts. We fix the maximum text size \(L\) to \(256\) tokens for all tasks (see App. K for larger text sizes). The length of a chunk \(\) is fixed _a priori_ to \(L/N\) where \(L\) is the maximum number of tokens allowed in the benchmark and \(N\) the number of chunks.

All the evaluations in this section use the model Llama3-8b-Instruct  (more models are tested in App. J). Its temperature \(\) varies to measure the impact of the text entropy on the watermark detectability. The watermarking scheme is not allowed to modify \(\) compared to the original LLM.

The evaluation of a watermarking scheme is based on three quantities: 1) the quality of the watermarked text relative to the non-watermarked text, 2) the detectability, and 3) the robustness.

For KGW and Aaronson's scheme, we use the implementation provided by  at [https://github.com/facebookresearch/three_bricks](https://github.com/facebookresearch/three_bricks). For the attack suite, we use the implementation of the '_Mark My Words_' benchmark found at [https://github.com/wagner-group/MarkMyWords](https://github.com/wagner-group/MarkMyWords).

Text qualityA number of metrics have been proposed to evaluate the quality of generated watermarked texts empirically. We tested the vast majority of these metrics: rating by LLM , similarity between BERT's embeddings , MAUVE , ROUGE  and perplexity measured by an oracle . We arrived at the conclusion that perplexity and ROUGE-L are currently the only reliable

Figure 4: Independence of token scores (a) and draft scores (b).

measures of watermarked text quality - in the sense that they are the only ones that consistently vary alongside watermark strength. This section reports the relative perplexity as measured by opt-2.7b as an oracle, computed as the average ratio between the perplexity of a watermarked text and the corresponding non-watermarked text. The text quality is evaluated by comparing the text generation with and without watermarking at the same LLM temperature \(\).

DetectabilityThe increasing use of LLM necessitates the use of small false-positive rates. In this section, we settled on reporting the true-positive rate at a conservative false-positive rate of \(10^{-6}\). For a more complete picture, Appendix K also reports the median false-positive rate of each watermark algorithm at different text lengths, akin to the measure of "watermark size" recently proposed in .

RobustnessWe use the attack suite of the '_Mark My Words_' (MMW) benchmark . We report robustness by measuring the detectability \(P_{D}\) of the watermark at \(P_{FA}=10^{-6}\) for each attack.

Error bars are reported using one standard error for perplexity, using the standard methodology, and detectability, computed using \(5000\) bootstrap samples for power at \(P_{FA}=10^{-6}\).

### State-of-the-art methods

The recent MMW benchmark considers four techniques names as 'binary' , KGW , Aaronson  and 'inverse transform' . It concludes that today's best methods are KGW and Aaronson, we thus restrict our comparisons to them. Except when specified otherwise, the watermark schemes all use a window size of \(h=6\) for hashing.

A fair comparison considers watermarking schemes at an equivalent level of text quality. Aaronson's scheme is theoretically distortion-free and experimentally almost lossless with respect to empirical relative perplexity and the ROUGE-L score. We should ideally tune WaterMax and KGW such that they are also almost lossless. This is not a problem for WaterMax as long as the number of tokens generated by a beam-search \(b\) is small enough. We choose the setting \((N,n)=(16,10)\), which provides a good compromise between robustness and complexity. As for KGW , we fix \(=2.0\) for an acceptable loss of quality, or \(=3.0\) for a tangible loss of quality. This gives a clear advantage to KGW. We set its green-list ratio \(=0.5\) following the recommendation of Piet et al. .

### Results

Quality vs detectabilityFigure 5 summarizes the benchmark outcomes. They confirm that WaterMax achieves a detectability close to the theoretical prediction - in our case close to \(1\) at \(P_{FA}=10^{-6}\) - while, at the same time, incurring a minimal loss in text quality. In particular, for a number of tokens generated by beam-search \(b=6\), there is virtually no observed loss in terms of perplexity. Furthermore, its performance is independent of the temperature of the LLM, demonstrating the efficient use of the entropy by working on chunks instead of individual tokens. On the other hand, Aaronson's scheme achieves high detectability only for high temperatures (seldom used in practice), whereas KGW achieves high detectability at the price of a text quality loss: at \(=3.0\) despite a relative perplexity significantly larger than WaterMax, KGW is still far less detectable.

RobustnessFigure 6 summarizes the results for the attack suite of the MMW benchmark. The watermark parameters are fixed to ensure the most negligible quality loss possible: \(b=6\) for WaterMax and \(=2.0\) for KGW. Without many surprises, no algorithm can resist the powerful re-translation attacks at this \(P_{FA}\) regime since most words, as well as their order, are modified. The 'typos' attacks can safely be disregarded as they modify every token and make the text barely legible in practice. This leaves the attacks that modify only parts of the text. For low temperatures, WaterMax is by far the most robust. Notably, the robust detector (5) can resist far more attacks, with significantly higher detectability against'synonym','misspelling' and'swap' attacks.

Interestingly, for temperatures starting at \(1.0\), Aaronson's scheme is more robust than WaterMax for specific attacks. This is explained by the high reliance of this method on entropy as we show in Appendix J as well as the high variance of its \(p\)-values. Given enough entropy, some portions of the watermarked text present unusually low \(p\)-values, statistically leading to more robustness. On the other hand, WaterMax produces texts with \(p\)-values that are more concentrated around their mean.

### Computational complexity

At face value, the computational cost of our scheme is nothing more than \(Nn\) text generations, the computation of the scores being negligible. However, the cost of adding one more chunk is higher than the cost of generating one more draft. Indeed, the \(n\) drafts of a chunk are sampled independently (or by a beam search), making their computation highly parallelizable on modern GPUs. On the other hand, we cannot parallelize the computations over the chunk. Since \(N\) has the highest impact on the power of WaterMax, it is the main limiting factor for its performance.

See Figure 7 for experimental running times. As a rule of thumb, we advise to use parameters fixed as \((n,N,b)=(10,16,6)\) as good trade-off between computational complexity and detectability. This still incurs a high cost compared to classic watermarking schemes. Under these settings, a text generated with WaterMax takes on average five times longer to generate than KGW or Aaronson's scheme.

However, despite a higher total computational cost, the latency can be kept relatively low since the text is generated chunk by chunk. Each chunk can be delivered to the user gradually (e.g. using a buffer) in order to make the method practical in a real-life setting. Note that more chunks lead to lower latency **and** better detectability with a negligible cost to text quality. We report, under the same settings, the generation time for one chunk as a measure of latency in Figure 7. In particular, we

Figure 5: Detectability against quality of watermarking schemes using Llama-3-8b-Instruct with nucleus sampling (\(top_{p}=0.95\)) and hashing window \(h=6\).

Figure 6: Robustness against the attacks of MMW benchmark. Llama-3-8b-Instruct with nucleus sampling (\(top_{p}=0.95\)). WaterMax parameters \((N,n,b)=(16,10,6)\). The hashing window size is fixed to \(h=6\) for all schemes.

show that under the advised parameters, the latency of WaterMax is only twice as long as that of the original LLM.

## 8 Conclusion

Contrary to previous art, the design of WaterMax starts from a detector and then constructs the generator to maximize the detection power. As a result, our watermark scheme offers a host of compelling benefits. It achieves high quality and robustness even on short texts, and importantly, it does not modify any component of the LLM, preserving its integrity and functionality. This design also complies with common add-ons in the literature, like adapting the sampling temperature  or embedding short messages .

These advantages come at the cost of computational complexity, which stays limited thanks to the exploration strategy and the parallelization possibilities of modern GPUs. Another idea left for future work is the distillation of WaterMax, a process that involves fine-tuning an LLM to natively produce watermarked text. This would definitively get rid of the only drawback of WaterMax.