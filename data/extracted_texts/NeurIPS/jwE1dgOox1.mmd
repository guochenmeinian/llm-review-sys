# Node-Level Topological Representation Learning on Point Clouds

**Anonymous Author(s)**

Affiliation

Address

email

**Abstract**

Topological Data Analysis (TDA) allows us to extract powerful topological, and higher-order information on the global shape of a data set or point cloud. Tools like Persistent Homology or the Euler Transform give a _single_ complex description of the _global structure_ of the point cloud. However, common machine learning applications like classification require _point-level_ information and features to be available. In this paper, we bridge this gap and propose a novel method to extract node-level topological features from complex point clouds using discrete variants of concepts from algebraic topology and differential geometry. We verify the effectiveness of these topological point features (TOPF) on both synthetic and real-world data and study their robustness under noise.

Figure 1: **Schematic of Computing Topological Point Features (TOPF). Input.** A point cloud \(X\) in \(n\)-dimensional space. **Step 1.** To extract global topological information, the persistent homology is computed on an \(\)/VR-filtration. The most significant topological features \(\) across all specified dimensions are selected. **Step 2.**\(k\)-homology generators associated to all features \(f_{i,k}\) are computed. For every feature, a simplicial complex is built at a step of the filtration where \(f_{i,k}\) is alive. **Step 3.** The homology generators are projected to the harmonic space of the simplices. **Step 4.** The vectors are normalised to obtain vectors \(_{}^{}\) indexed over the \(k\)-simplices. For every point \(x\) and feature \(f\), we compute the mean of the entries of \(_{}^{}\) corresponding to simplices containing \(x\). The output is a \(|X|||\) matrix which can be used for downstream ML tasks. **Optional.** We weigh the simplicial complexes resulting in a topologically more faithful harmonic representative in **Step 3**.

Introduction

In modern machine learning , objects are described by feature vectors within a high-dimensional space. However, the coordinates of a single vector can often only be understood in relation to the entire data set: if the value \(x\) is small, average, large, or even an outlier depends on the remaining data. In a \(1\)-dimensional (or low-dimensional) case this issue can be addressed simply by normalising the data points according to the global mean and standard deviation or similar procedures. We can interpret this as the most straight-forward way to construct _local_ features informed by the _global_ structure of the data set.

In the case where not all data dimensions are equally relevant, or contain correlated and redundant information, we can apply (sparse) PCA to project the data points to a lower dimensional space using information about the _global structure_ of the point cloud . For even more complex data, we may first have to learn the encoded structure itself: indeed, a typical assumption underpinning many unsupervised learning methods is the so-called "manifold hypothesis" which posits that real world data can be described well via submanifolds of \(n\)-dimensional space . Using eigenvectors of some Laplacian, we can then obtain a coordinate system intrinsic to the point cloud (see e.g. ). Common to all these above examples is the goal is to construct locally interpretable point-level features that encode _globally meaningful positional information_ robust to local perturbations of the data. However, none of these approaches is able to represent higher-order topological information, making point clouds with these kind of structure inaccessible to point-level machine learning algorithms.

Instead of focussing on the interpretation of individual points, topological data analysis (TDA), , follows a different approach. TDA extracts a global description of the shape of data, which is typically considered in the form of a high-dimensional point cloud. This is done measuring topological features like persistence homology, which counts the number of generalised "holes" in the point cloud on multiple scales. Due to their flexibility and robustness these global topological features have been shown to contain relevant information in a broad range of application scenarios: In medicine, TDA has provided methods to analyse cancer progression . In biology, persistent homology has been used to analyse knotted protein structures , and the spectrum of the Hodge Laplacian has been used for predicting protein behaviour .

This success of topological data analysis is a testament to the fact that relevant information is encoded in the global topological structure of point cloud data. Such higher-order topological information is however invisible to standard tools of data analysis like PCA or \(k\)-means clustering, and can also not be captured by graph models of the point cloud. We are now faced by a situation where **(i)** important parts of the global structure of a complex point cloud can only be described by the language of applied topology, however **(ii)** most standard methods to obtain positional point-level information are not sensitive to the higher-order topology of the point cloud.

ContributionsWe introduce TOPF (Figure 1), a novel method to compute node-level topological features relating individual points to global topological structures of point clouds. TOPF **(i)**_outperforms_ other methods and embeddings for clustering downstream tasks on topologically structured data, returns **(ii)**_provably meaningful representations_, and is **(iii)**_robust to noise_. Finally, we introduce the topological clustering benchmark suite, the first benchmark for topological clustering.

Related WorkThe intersection of topological data analysis, topological signal processing and geometry processing has many interesting related developments in the past few years. On the side of homology and TDA, the authors in  and  use harmonic _c_ohomology representatives to reparametrise point clouds based on circular coordinates. This implicitly assumes that the underlying structure of the point cloud is amenable to such a characterization. In , the authors develop and use harmonic persistent homology for data analysis. However, among other differences their focus is not on providing robust topological point features.  uses the harmonic space of the Hodge Laplacians to cluster point clouds respecting topology, but is unstable against some form of noise, has no possibility for features selection across scales and is computationally far more expensive than TOPF. For a more in-depth review of related work, see Appendix A

Organisation of the paperIn Section 2, we give an overview over the main ideas and concepts behind of TOPF. In Section 3, we describe how to compute TOPF. In Section 4, we give a theoretical result guaranteeing the correctness of TOPF. Finally, we will apply TOPF on synthetic and real-world data in Section 5. Furthermore, Appendix A contains a brief history of topology and a detailed discussion of related work. Appendix B contains additional theoretical considerations, Appendix C describes the novel topological clustering benchmark suite, Appendix D contains details on the implementation and the choice of hyperparameters, Appendix E gives a detailed treatment of feature selection, Appendix F discusses simplicial weights, and Appendix G discusses limitations in detail.

## 2 Main Ideas of TOPF

A main goal of algebraic topology is to capture the shape of spaces. Techniques from topology describe globally meaningful structures that are indifferent to local perturbations and deformations. This robustness of topological features to local perturbations is particularly useful for the analysis of large-scale noisy datasets. To apply the ideas of algebraic topology in our TOPF pipeline, we need to formalise and explain the notion of _topological features_. An important observation for this is that high-dimensional point clouds and data may be seen as being sampled from topological spaces -- most of the time, even low-dimensional submanifolds of \(^{n}\).

In this section we provide a broad overview over the most important concepts of topology and TDA for our context, prioritising intuition over technical formalities. The interested reader is referred to  for a complete technical account of topology and  for an overview over TDA.

Simplicial ComplexesSpaces in topology are _continuous_, consist of _infinitely_ many points, and often live in _abstract space_. Our input data sets however consist of _finitely_ many points embedded in _real space_\(^{n}\). In order to bridge this gap and open up topology to computational methods, we need a notion of discretised topological spaces consisting of finitely many base points with finite description length. A _Simplicial Complex_ is the simplest discrete model that can still approximate any topological space occuring in practice :

**Definition 2.1** (Simplicial complexes).: A _simplicial complex_ (SC) \(\) consists of a set of vertices \(V\) and a set of finite non-empty subsets (simplices, \(S\)) of \(V\) closed under taking non-empty subsets, such that the union over all simplices \(_{ S}\) is \(V\). In the following, we will often identify \(\) with its set of simplicies \(S\) and denote by \(_{k}\) the set of simplices \( S\) with \(||=k+1\), called _\(k\)-simplices_. We say that \(\) is \(n\)-dimensional, where \(n\) is the largest \(k\) such that the set of \(k\)-simplices \(_{k}\) is non-empty. The _\(k\)-skeleton_ of SC contains the simplices of dimension at most \(k\). If the vertices \(V\) lie in real space \(^{n}\), we call the convex hull in \(^{n}\) of a simplex \(\) its _geometric realisation_\(||\). When doing this for every simplex of \(\), we call this the _geometric realisation of \(\)_, \(||^{n}\).

Concretely, we can construct an \(n\)-dimensional SC \(\) in \(n+1\) steps: First, we start with a set of vertices \(V\) which we can identify with the \(0\)-simplices \(_{0}\). Second, we connect certain pairs of vertices with edges, which constitute the set of \(1\)-simplices. We can then choose to fill in some triples of vertices which are fully connected by \(1\)-simplices with triangles, i.e. \(2\)-simplices. More generally, in the \(k^{}\) step, we can add a \(k\)-simplex for every set \(_{k}\) of \(k+1\) vertices such that every \(k\)-element subset \(_{k-1}\) of \(_{k}\) is already a \((k-1)\)-simplex.

Vietoris-Rips and \(\)-complexesWe now need a way to construct a _simplicial complex_ that approximates the _topological structure_ inherent in our data set \(X^{n}\). Such a construction will always depend on the scale of the structures we are interested in. When looking from a very large distance, the point cloud will appear as a singular connected blob in the otherwise empty and infinite real space, on the other hand when we continue to zoom in, the point cloud will at some point appear as a collection of individual points separated by empty continuous space; all interesting information can be found in-between these two extreme scales where some vertices are joined by simplices and others are not. Instead of having to pick a single scale, the _Vietoris-Rips (VR) filtration_ and the \(\)-_filtration_ take as input a point cloud and return a nested sequence of simplicial complexes indexed by a scale parameter \(\) approximating the topology of the data across all possible scales.

**Definition 2.2** (VR complex).: Given a finite point cloud \(X\) in a metric space \((,d)\) and a non-negative real number \(_{ 0}\), the associated VR complex \(VR_{}(X)\) is given by the vertex set \(X\) and the set of simplices \(S=\{ X, x,y:d(x,y)\}\)

Intuitively, a VR complex with parameter \(\) consists of all simplices \(\) where all vertices \(x\) have a pair-wise distance of at most \(\). For \(r r^{}\), we obtain the canonical inclusions \(i_{r,r^{}}(X) VR_{r}(X)\)\(VR_{r^{}}(X)\). The set of VR complexes on \(X\) for all possible \(r_{ 0}\) together with the inclusions then form the _VR filtration_ on \(X\). For large point clouds, using the VR complex for computations becomes expensive due to its large number of simplices. In contrast, the more sophisticated \(\)-complex approximates the topology of a point cloud using far fewer simplices and thus we will make use of it. For a complete account and definition of \(\)-complexes and our reason to use them, see Appendix B.

Boundary matricesSo far, we have discussed a discretised version of topological spaces in the form of SCs and a way to turn point clouds into a sequence of SCs indexed by a scale parameter. However, we still need an _algebraic representation_ of simplicial complexes that is capable of encoding the structure of the SC and enables extraction of the _topological features_: The _boundary matrices_\(_{k}\) associated to an SC \(\) store all structural information of SC. The rows of \(_{k}\) are indexed by the \(k\)-simplices of \(\) and the columns are indexed by the \((k+1)\)-simplices.

**Definition 2.3** (Boundary matrices).: Let \(\) be a simplicial complex and \(\) a total order on its vertices \(V\). Then, the \(i\)-th face map in dimension \(n\)\(f_{i}^{n}_{n}_{n-1}\) is given by

\[f_{i}^{n}\{v_{0},v_{1},,v_{n}\}\{v_{0},v_{1},, {v}_{i},,v_{n}\}\]

with \(v_{0} v_{1} v_{n}\) and \(_{i}\) denoting the omission of \(v_{i}\). Now, the \(n\)-th _boundary operator_\(_{n}[_{n+1}][_ {n}]\) with \([_{n}]\) being the real vector space over the basis \(_{n}\) is given by

\[_{n}_{i=0}^{n+1}(-1)^{i}f_{i}^{n+1}().\]

When lexicographically ordering the simplex basis, we can view \(_{n}\) as a _matrix_. We call \([_{n}]\) the space of \(n\)-chains. Now, \(_{0}\) is the vertex-edge incidence matrix of the associated graph consisting of the \(0\)- and \(1\)-simplices of \(\) and \(_{1}\) is the edge-triangle incidence matrix of \(\)

Betti Numbers and Persistent HomologyWe now turn to the notion of _topological features_ and how to extract them. _Homology_ is one of the main algebraic invariants to capture the shape of topological spaces and SC. From a technical point of view, the \(k\)-th homology module \(H_{k}()\) of an SC \(\) with boundary operators \(_{k}\) is defined as \(H_{k}()_{k-1}/ _{k}\). The _generator_ or representative of a homology class is an element of the kernel \(_{k-1}\). In dimension \(1\), these are given by formal sums of \(1\)-simplices forming closed loops in the SC. Importantly, the rank \(H_{k}()\) is called the \(k\)-th _Betti number_\(B_{k}\) of \(\). In dimension \(0\), \(B_{0}\) counts the number of connected components, \(B_{1}\) counts the number of loops around 'holes' of the space, \(B_{2}\) counts the number of \(3\)-dimensional voids with \(2\)-dimensional boundary, and so on.

If we are now given a filtration of simplicial complexes instead of a single SC, we can track how the homology modules evolve as the simplicial complex grows. The mathematical formalisation, _persistent homology_, thus turns a point cloud via a simplicial filtration into an algebraic object summarising the topological feature of the point cloud. For better computational performance, the computations are usually done in one of the small finite fields \(/p\). Because we will later be interested in the sign of numbers to distinguish different simplex orientations, we will use \(/3\)-coefficients, with \(/3\) being the smallest field being able to distinguish \(1\) and \(-1\).

The Hodge Laplacian and the Harmonic SpaceIn the previous part, we have introduced a language to characterise the global shape of spaces and point clouds. However, we still need to find a way to relate these _global characterisations_ back to _local properties_ of the point cloud. We will do so by using ideas and concepts from differential geometry and topology: The simplicial Hodge Laplacian is a discretisation of the Hodge-Laplace operator acting on differential forms of manifolds:

**Definition 2.4** (Hodge Laplacian).: Given a simplicial complex \(\) with boundary operators \(_{k}\), we define the \(n\)-th Hodge Laplacian \(L_{n}[_{n}][_{n}]\) by setting

\[L_{n}_{n-1}^{}_{n-1}+_{n} _{n}^{}.\]

The Hodge Laplacian gives rise to the Hodge decomposition theorem:

Figure 2: Sketch of Persistent Homology, 

**Theorem 2.5** (Hodge Decomposition [34; 46; 44]).: _For an SC \(\) with boundary matrices \((_{i})\) and Hodge Laplacians \((L_{i})\), we have in every dimension \(k\)_

\[[_{k}]=_{k-1}^{ }}_{}}_{}_{k}}_{}\,.\]

This, together with the fact that the \(k\)-th harmonic space is isomorphic to the \(k\)-th real-valued homology group \( L_{k} H_{k}()\) means that we can associate a _unique harmonic representative_ to every homology class. The harmonic space encodes higher-order generalisations of smooth flow around the holes of the simplicial complex. Intuitively, this means that for every abstract global homology class of persistent homology from above we can now compute one unique harmonic representative in \( L_{k}\) that assigns every simplex a value based on how much it contributes to the homology class. Thus, the Hodge Laplacian is a gateway between the _global topological features_ and the _local properties_ of our SC. It is easy to show that the kernel of the Hodge Laplacian is the intersection of the kernel of the boundary and the coboundary map \( L_{k}=_{n-1}_{n}^{}\). Because we have finite SCs we can identify the spaces of chains and cochains. This leads to another characterisation of the harmonic space: The space of chains that are simultaneously homology and cohomology representatives.

## 3 How to Compute Topological Point Features

In this section, we will combine the ideas and insights of the previous section to give a complete account of how to compute Topological point features (TOPF). A pseudo-code version can be found in Algorithm 1 and an overview in Figure 1. We start with a finite point cloud \(X^{n}\).

``` Input: Point cloud \(X^{n}\), maximum homology dimension \(d\), interpolation coeff. \(\).
1. Compute persistent homology with generators in dimension \(k d\).
2. Select set of significant features \((b_{i},d_{i},g_{i})\) with birth, death, and generator in \(_{3}\) coordinates.
3. Embed \(g_{i}\) into real space and project into harmonic subspace of SC at step \(t= b_{i}+(1-)d_{i}\).
4. Normalise projections to \(_{i}^{k}\) and compute \(F_{k}^{i}(x)_{x}(_{i}^{k}l( ))\) for all points \(x X\). Output: Features of \(x X\) ```

**Algorithm 1** Topological Point Features (TOPF)

Step 1: Computing the persistent homologyFirst, we need to determine the _most significant persistent homology classes_ which determine the shape of the point cloud. By doing this, we can also extract the "interesting" scales of the data set. We will later use this to construct SCs to derive local variants of the global homology features. Thus we first compute the persistent \(k\)-homology modules \(P_{k}\) including a set of homology representatives \(R_{k}\) of \(X\) using an \(\)-filtration for \(n 3\) and a VR filtration for \(n>3\). We use \(/3\) coefficients to be sensitive to simplex orientations. In case we have prior knowledge on the data set, we can choose a real number \(R_{>0}\) and only compute the filtration and persistent homology connecting points up to a distance of at most \(R\). In data sets like protein atom coordinates, this might be useful as we have prior knowledge on what constitutes the

Figure 3: **TOPF pipeline applied to NALCN channelosome, a membrana protein .**_Left:_ Steps **1&2a**, when computing persistent \(1\)-homology, three classes are more prominent than the rest. _Centre:_ Step **2b**: The selected homology generators. _Right:_ Step **3**: The projections of the generators into (weighted) harmonic are now each supported on one of the three rings.

"interesting" scale, reducing computational complexity. See Figure 3_left_ for a persistent homology diagram.

Step 2: Selecting the relevant topological featuresWe now need to select the relevant _homology classes_ which carry the most important _global information_. The persistent homology \(P_{k}\) module in dimension \(k\) is given to us as a list of pairs of birth and death times \((b_{i}^{k},d_{i}^{k})\). We can assume these pairs are ordered in non-increasing order of the durations \(l_{i}^{k}=d_{i}^{k}-b_{i}^{k}\). This list is typically very long and consists to a large part of noisy homological features which wish right after they appear. In contrast, we are interested in connected components, loops, cavities, etc. that _persist_ over a long time, indicating that they are important for the shape of the point cloud. Distinguishing between the relevant and the irrelevant features is in general difficult and may depend on additional insights on the domain of application. In order to provide a heuristic which does not depend on any a-priori assumptions on the number of relevant features we pick the smallest quotient \(q_{i}^{k} l_{i+1}^{k}/l_{i}^{k}>0\) as the point of cut-off \(N_{k}_{i}q_{i}^{k}\). The only underlying assumption of this approach is that the band of "relevant" features is separated from the "noisy" homological features by a drop in persistence. If this assumption is violated, the only possible way to do meaningful feature selection depends on application-specific domain knowledge. We found that our proposed heuristics work well across a large scale of applications. See Figure 3_left_ and _centre_ for an illustration and Appendix E for more technical details and ways to improve and adapt the feature selection module of TOPF. We call the chosen \(k\)-homology classes including \(k\)-homology generators in dimension \(f_{k}^{i}\).

Step 3: Projecting the features into harmonic space and normalisingIn this step, we need to relate the _global topology_ extracted in the previous step to the simplices which we will use to compute the _local_ topological point feature. Every selected feature \(f_{k}^{i}\) of the previous step comes with a birth time \(b_{i,k}\) and a death time \(d_{i,k}\). This means that the homology class \(f_{k}^{i}\) is present in every SC of the filtration between step \(=b_{i,k}\) and \(=d_{i,k}\) and we could choose any of the SCs for the next step. Picking a _small_\(\) will lead to _fewer_ simplices in the SC and thus to a very _localised_ harmonic representative. Picking a _large_\(\) will lead to _many_ simplices in the SC and thus to a very _smooth_ and "blurry" harmonic representative with large support. Finding a middle ground between these regimes returns optimal results. For the interpolation parameter \((0,1)\), we will thus consider the simplicial complex \(^{t_{i,k}}(X)\) at step \(t_{i,k} b_{i,k}^{1-}d_{i,k}^{}\) for \(k>0\) and at step \(t_{i,k} d_{i,k}\) for \(k=0\) of the simplicial filtration. At this point, the homology class \(f_{k}^{i}\) is still alive. We then consider the real vector space \([^{t_{i,k}}_{k}(X)]\) with formal basis consisting of the \(k\)-simplices of the SC \(^{t_{i,k}}\). From the persistent homology computation of the first step, we also obtain a generator of the feature \(f_{k}^{i}\), consisting of a list \(_{k}^{i}\) of simplices \(_{j}^{b_{i,k}}_{k}\) and coefficients \(c_{j}/3\). We need to turn this formal sum of simplices with \(/3\)-coefficients into a vector in the real vector space \([^{t_{i,k}}_{k}(X)]\): Let \(/3\) be the map induced by the canonical inclusion of \(\{-1,0,1\}\). We can now define an indicator vector \(e_{k}^{i}[^{t_{i,k}}_{k}(X)]\) associated to the feature \(f_{k}^{i}\).

\[e_{k}^{i}()(c_{j})&_{j} _{k}^{i}:=_{j}\\ 0&.\]

While this homology representative lives in a real vector space, it is not unique, has a small support, and can differ largely between close simplices. All of these problems can be solved by projecting the homology representative to the harmonic subspace \( L_{k}\) of \([^{t_{i,k}}_{k}(X)]\). Rather than directly projecting \(e_{k}^{i}\) to the harmonic subspace, we make use of the Hodge decomposition theorem (Theorem 2.5) which allows us to compute the gradient and curl projections solving computationally efficient least square problems:

\[e_{k,}^{i}_{k-1}^{}*{arg\, min}_{x[_{k-1}]}\|e_{k}^{i}-_{k-1}^{ }x\|_{2}^{2} e_{k,}^{i} _{k}*{arg\,min}_{x[_{k+1}]} \|e_{k}^{i}-e_{k,}^{i}-_{k}x\|_{2}^{2}\]

and then setting \(_{k}^{i} e_{k}^{i}-e_{k,}^{i}-e_{k,}^{i}\). (Cf. Figure 3_right_ for a visualisation.) Because homology representatives are gradient-free, we only need to consider the projection of \(e_{k}^{i}\) into the curl space.

Step 4: Processing and aggregation at a point levelIn the previous step, we have computed a set of simplex-valued harmonic representatives of homology classes. However, these simplices likely have no real-world meaning and the underlying simplicial complexes differ depending on the birth and death times of the homology classes. Hence in this step, we will collect the features on the point-level after performing some necessary preprocessing. Given a simplex-valued vector \(^{i}_{k}\) and a hyperparameter \(\), we now construct \(^{i}_{k}^{t_{i,k}}_{k}(X)\) by setting \(^{i}_{k}\{|^{i}_{k}()|/( _{^{}^{t_{i,k}}_{k}(X)}|^{i}_{k}(^{ })|),1\}\) such that \(^{i}_{k}\) is normalised to \(\), the values of \([0,]\) are mapped linearly to \(\) and everything above is sent to \(1\). We found empirically that a thresholding parameter of \(=0.07\) works best across at the range of applications considered below. However, TOPF is not sensitive to small changes to \(\) because entries of \(^{i}_{k}\) are concentrated around \(0\).

For every feature \(f^{i}_{k}\) in dimension \(k\) with processed simplicial feature vector \(^{i}_{k}\) and simplicial complex \(^{t_{i,k}}\), we define the point-level feature map \(F^{k}_{i} X\) mapping from the initial point cloud \(X\) to \(\) by setting

\[F^{k}_{i} v^{t_{i,k}}_{k}  v_{k}}^{i}_{k}(_{k})}{(1,|\{_{k} ^{t}_{k}:v_{k}\}|)}.\]

For every point \(v\), we can thus view the vector \((F^{k}_{i}(v) f^{k}_{i})\) as a feature vector for \(v\). We call this collection of features _Topological Point Features_ (TOPF). (Cf. Figure 4 for an example).

Choosing Simplicial WeightsBy default, the simplicial complexes of \(\)- and VR filtrations are unweighted. However, the weights determine the entries of the harmonic representatives, increasing and decreasing the influence of certain simplices and parts of the simplicial complex. We can use this observation to increase the robustness of TOPF against the influence of heterogeneous point cloud structure, which is present in virtually all real-world data sets. For a complete technical account of how and why we do this, see Appendix F.

## 4 Theoretical guarantees

In this section, we prove the relationship between TOPF and actual topological structure in datasets:

**Theorem 4.1** (Topological Point Features of Spheres).: _Let \(X\) consist of at least \((n+2)\) points (denoted by \(S\)) sampled uniformly at random from a unit \(n\)-sphere in \(^{n+1}\) and an arbitrary number of points with distance of at least \(2\) to \(S\). When we now consider the \(\)-filtration on this point cloud, with probability \(1\) we have that **(i)** there exists an \(n\)-th persistent homology class generated by the 2-simplices on the convex hull hull of \(S\), **(ii)** the associated unweighted harmonic homology representative takes values in \(\{0, 1\}\) where the 2-simplices on the boundary of the convex hull are assigned a value of \( 1\), and **(iii)** the support of the associated topological point feature (TOPF) \(^{*}_{n}\) is precisely \(S\): \((^{*}_{n})=S\). **(iv)** The same holds true for point clouds sampled from multiple \(n_{i}\)-spheres if the above conditions are met on each individual sphere._

We will give a proof of this theorem in Appendix B.

_Remark 4.2_.: In practice, datasets with topological structure consist in a majority of cases of points sampled with noise from deformed \(n\)-spheres. The theorem thus guarantees that TOPF will recover these structural information in an idealised setting. Experimental evidence suggests that this holds under the addition of noise as well which is plausible as harmonic persistent homology is robust against some noise .

## 5 Experiments

In this section, we conduct experiments on real world and synthetic data, compare the clustering results with clustering by TPCC, other classical clustering algorithms, and other point features, and demonstrate the robustness of TOPF against noise.

Topological Point Cloud Clustering BenchmarkWe introduce the topological clustering benchmark suite (Appendix C) and report running times and the accuracies of clustering based on TOPF and other methods and point embeddings, see Table 1. We see that TOPF _outperforms_ all classical clustering algorithms on all but one dataset by a wide margin. We also see that TOPF closely matches the performance of the only other higher-order topological clustering algorithm, TPCC on two datasets with clear topological features, whereas TOPF _outperforms_ TPCC on datasets with more complex structure. In addition, TOPF has a consistently lower running time with better scaling for the more 

  & &  &  &  &  &  &  &  &  \\ 
4spheres & ARI & **0.81** & 0.52\(\)0.17 & 0.37 & 0.00 & 0.45 & 0.32 & 0.20 & 0.00\(\)0.00 \\  & time (s) & 14.5 & 23.3 & 0.2 & 0.0 & 0.0 & 0.0 & 0.2 & 48.4 \\  Ellipses & ARI & **0.95** & 0.47\(\)0.04 & 0.25 & 0.19 & 0.52 & 0.29 & 0.81 & 0.02\(\)0.00 \\  & time (s) & 12.7 & 14.4 & 0.1 & 0.0 & 0.0 & 0.0 & 0.1 & 11.2 \\  Spheres+Grid & ARI & 0.70 & 0.39\(\)0.04 & **0.90** & **0.92** & **0.89** & 0.82 & 0.41 & 0.01\(\)0.00 \\  & time (s) & 13.0 & 28.5 & 0.5 & 0.0 & 0.0 & 0.0 & 0.3 & 63.8 \\  Halved Circle & ARI & **0.71** & 0.18\(\)0.12 & 0.24 & 0.00 & 0.20 & 0.16 & 0.08 & 0.00\(\)0.01 \\  & time (s) & 12.2 & 14.3 & 0.1 & 0.0 & 0.0 & 0.0 & 0.1 & 18.2 \\ 
2Spheres2Circles & ARI & **0.94** & **0.97\(\)**0.01 & 0.70 & 0.00 & 0.51 & 0.87 & 0.12 & 0.00\(\)0.00 \\  & time (s) & 38.9 & 1662.2 & 1.6 & 0.0 & 0.3 & 0.0 & 0.9 & 348.6 \\  SphereinCircle & ARI & **0.97** & **0.98\(\)**0.0 & 0.34 & 0.00 & 0.29 & 0.06 & 0.69 & 0.13\(\)0.03 \\  & time (s) & 14.5 & 8.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.08 & 20.1 \\  Spaceship & ARI & **0.92** & 0.56\(\)0.03 & 0.28 & 0.26 & 0.47 & 0.30 & **0.87** & 0.07\(\)0.00 \\  & time (s) & 16.3 & 341.8 & 16.7 & 0.0 & 0.0 & 0.0 & 0.2 & 49.8 \\ 
**mean** & ARI & **0.86** & 0.58 & 0.44 & 0.16 & 0.48 & 0.40 & 0.45 & 0.03 \\  & time (s) & 17.5 & 298.9 & 0.4 & 0.0 & 0.0 & 0.0 & 0.3 & 80.0 \\  

Table 1: **Quantitative performance comparison of clustering with TOPF and other features/clustering algorithms.** Four \(2D\) and three \(3D\) data sets of the topological clustering benchmark suite (Appendix C, cf. Figure 6 for ground truth labels and Figure 7 for clustering results of TOPF). We ran each algorithm \(20\) times and list the mean adjusted rand index (ARI) with standard deviation \(\) and mean running time. We omit \(\) for algorithms with \(=0\) on every dataset. TOPF consistently outperforms or almost matches the other algorithms while having significantly better run time than the second best performing algorithm TPCC. Spectral Clustering (SC), DBSCAN, and Agglomerative Clustering (AgCl) are standard clustering algorithms, ToM4To is a topological clustering algorithm , Geo clusters using \(12\)-dimensional point geometric features extracted by pgeof and the normal point coordinates, whereas node2vec  produces node embeddings on a \(k\)-nearest neighbour graph built upon an affinity matrix. We highlight all ARI scores within \( 0.05\) of the best ARI score.

Figure 4: **TOPF on \(3D\) real-world and synthetic point clouds.** For every point, we highlight the largest corresponding topological feature, where colour stands for the different features and saturation for the value of the feature. _(a):_ Atoms of mutated Cys123 of E. coli . We added auxiliary points on the convex hull and considered \(2\)-homology, to detect the protein pockets which are crucial for protein-environment interactions (Cf. ). _(b):_ Atoms of NaCl Chunnelosome  display three distinct loops. _(c):_ Points sampled in the state space of a Lorentz attractor. The two features correspond to the two lobes of the attractor. _(d):_ Point cloud spaceship of our newly introduced topological clustering benchmark suite (See Appendix C).

complex datasets, while also not requiring prior knowledge on the best topological scale. As for the other point embeddings, Node2Vec is not able to capture any meaningful topological information, whereas the performance of clustering using geometric features depends on the data set.

Feature GenerationIn Figure 4, we show qualitatively that TOPF constructs meaningful topological features on data sets from Biology and Physics, and synthetic data, corresponding to for example rings and pockets in proteins or trajectories around different attractors in dynamical systems. (For individual heatmaps see Figure 8)

Robustness against noiseWe have evaluated the robustness of TOPF against Gaussian noise on the dataset introduced in  and compared the results against TPCC, Spectral Clustering, Graph Spectral Clustering on the graph constructed by TPCC, and against \(k\)-means in Figure 5_Left_. We have also analysed the robustness of TOPF against the addition of outliers in Figure 5_Right_. We see that TOPF performs well in both cases, underlining our claim of robustness.

## 6 Discussion

LimitationsTOPF can -- by design -- only produce meaningful output on point clouds with a _topological structure_ quantifiable by persistent homology. In practice it is thus desirable to combine TOPF with some geometric or other point-level feature extractor. As TOPF relies on the computation of persistent homology, its runtime increases on very large point clouds, especially in higher dimensions where \(\)-filtrations are computationally infeasible. However, subsampling, either randomly or using landmarks, usually preserves relevant topological features while improving run time . Finally, selection of the relevant features is a very hard problem. While our proposed heuristics work well across a variety of domains and application scenarios, only domain- and problem-specific knowledge makes correct feature selection feasible.

Future WorkThe integration of higher-order TOPF features into ML pipelines that require point-level features potentially leads to many new interesting insights across the domains of biology, drug design, graph learning and computer vision. Furthermore, efficient computation of simplicial weights leading to the provably most faithful topological point features is an exciting open problem.

ConclusionWe introduced point-level features TOPF founded on algebraic topology relating global structural features to local information. We gave theoretical guarantees for the correctness of their construction and evaluated them quantitatively and qualitatively on synthetic and real-world data sets. Finally, we introduced the novel topological clustering benchmark suite and showed that clustering using TOPF outperforms other available clustering methods and features extractors.

Figure 5: **Performance of Clustering based on TOPF features in increasing noise/outlier levels with 95% CI.**_Left:_ We add i.i.d. Gaussian noise to every point with standard deviation indicated by the noise parameter. We see that even when compared with TPCC on a data set specifically crafted for TPCC, TOPF requires significantly less information and delivers almost equal performance. When tuned for datasets with a high noise level, the TOPF even outperform TPCC and drastically outperform all classical clustering algorithms. _Right:_ We add outliers with the same standard deviation as the point cloud to the data set. We then measure the adjusted rand index obtained restricted on the original points. We see that even when compared with TPCC on a data set specifically crafted for TPCC, TOPF requires significantly less information and delivers matching to superior performance, significantly outperforming all other classical clustering algorithms.