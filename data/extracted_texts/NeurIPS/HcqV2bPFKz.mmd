# Hierarchical Object-Aware Dual-Level Contrastive Learning for Domain Generalized Stereo Matching

Yikun Miao

Beijing Institute of Technology

joshmiao233@gmail.com

&Meiqing Wu

Nanyang Technological University

meiqingwu@ntu.edu.sg

&Siew-Kei Lam

Nanyang Technological University

assklam@ntu.edu.sg

&Changsheng Li

Beijing Institute of Technology

lcs@bit.edu.cn

&Thambipillai Srikanthan

Nanyang Technological University

astsrikan@ntu.edu.sg

Corresponding Author

###### Abstract

Stereo matching algorithms that leverage end-to-end convolutional neural networks have recently demonstrated notable advancements in performance. However, a common issue is their susceptibility to domain shifts, hindering their ability in generalizing to diverse, unseen realistic domains. We argue that existing stereo matching networks overlook the importance of extracting semantically and structurally meaningful features. To address this gap, we propose an effective hierarchical object-aware dual-level contrastive learning (HODC) framework for domain generalized stereo matching. Our framework guides the model in extracting features that support semantically and structurally driven matching by segmenting objects at different scales and enhances correspondence between intra- and inter-scale regions from the left feature map to the right using dual-level contrastive loss. HODC can be integrated with existing stereo matching models in the training stage, requiring no modifications to the architecture. Remarkably, using only synthetic datasets for training, HODC achieves state-of-the-art generalization performance with various existing stereo matching network architectures, across multiple realistic datasets.

## 1 Introduction

Stereo matching aims to find horizontal pixel-wise displacement, _i.e_.disparity, between a rectified stereo image pair to recover depth for applications including autonomous driving, robotics, and augmented reality. In recent years, deep learning based stereo matching networks have achieved state-of-the-art performance in multiple benchmarks [12; 28; 32; 33], benefiting from the expressive power of deep feature representations.

A typical stereo matching pipeline [3; 13; 51; 34] includes four stages: feature extraction, cost volume generation, cost aggregation, and disparity regression, which is usually trained in an end-to-end way, supervised by ground-truth disparity. As collecting dense annotations of disparity for real-world datasets is often costly, large-scale synthetic datasets (_e.g_., SceneFlow ) are widely adopted to train stereo matching networks. This however often leads to failures while generalizing to unseenrealistic domains (see the third column in Fig. 1 for example), as stereo matching networks will over-rely on superficial cues (_e.g_.local chromatic attributes like color distribution, illumination, texture, _etc_.) within synthetic data for disparity estimation.

Recently, several works [7; 49; 31; 4; 48; 34; 35; 16] have attempted to address the synthetic-to-real generalization gap for stereo matching networks. In order to mitigate over-reliance on the short-cut features, they either add additional regularization to enforce the feature consistency between left and right views , original images and adversarial perturbations , augmented transformations , or introduce specially designed network architectures to enlarge the reception field and extract robust structural and geometric representations [48; 34; 35; 16]. Though these approaches have shown promising results in their generalization ability, they do not exploit semantic structure directly as they depend mainly on pixel-wise loss to optimize disparity predictions.

We claim that semantic structure serves as an important cue to assist correspondence matching, especially in ambiguous areas like textureless regions and edge boundaries. For example, the disparity estimation for road and street signs in the first row, and motorcycle wheels in the second row in Fig. 1 are intuitively erroneous, as they violate the semantic consistency prior wherein disparity should have similar distribution within a local region on the same object. It is however non-trivial to incorporate semantic information to guide the stereo matching effectively. Early efforts [44; 36] have explored the semantic and structural information by introducing sub-networks for semantic segmentation  or edge detection  in a multi-task learning manner. However, multi-task joint feature learning couples the two different tasks superficially and cannot incorporate semantic structure to directly guide stereo matching at the ambiguous areas .

In this paper, we propose a novel method to effectively enhance semantically and structurally driven matching to boost the synthetic-to-real generalization capability of stereo matching networks. Inspired by the recent success of contrastive learning in learning distinctive visual representations [14; 5; 6; 39; 40; 49; 22; 38; 1; 10; 30; 15; 17; 50; 8], we introduce hierarchical object-aware dual-level contrastive learning (HODC) to incorporate the semantic guidance into the stereo matching process. Given the left and right images with object index and ground-truth disparity, we first segment the object index map at different scales to obtain hierarchical object-aware regional representations. Then, guided by the ground-truth disparity, we establish accurate correspondences between the representations of the stereo pair. Using dual-level contrastive learning, we enhance both intra- and inter-scale matching of the hierarchical object-aware regional representations from the left image to the right. Building correspondence between these representations enables us to introduce semantically and structurally driven matching in an explicit and effective manner. As illustrated in Fig. 2, the proposed method can be easily plugged into different existing stereo matching pipelines without requiring modifications to their architectures. Extensive evaluations show that the proposed method can substantially improve the synthetic-to-real generalization ability of different stereo matching networks across most stereo matching benchmarks and outperforms existing domain generalized methods by a large margin.

In summary, our main contribution is threefold:

* We demonstrate that semantically and structurally driven matching is crucial for the domain generalization ability of stereo matching networks. To achieve this, we propose a novel

Figure 1: Qualitative domain generalization results of PSMNet  baseline and HODC-PSMNet (Ours). The latter is trained with our proposed hierarchical object-aware contrastive loss. Both models are trained only on the _synthetic_ SceneFlow  dataset and evaluated directly on _realistic_ datasets KITTI-2015  and Middlebury .

hierarchical segmentation scheme on objects, enabling the extraction of hierarchical object-aware representations in a flexible manner.
* We effectively enhance the matching between hierarchical object-aware representations from the left image to the right image by introducing intra- and inter-scale dual-level contrastive loss, enabling semantically and structurally driven matching both locally and globally.
* Extensive experiments conducted on four widely used realistic stereo matching datasets using multiple network architectures underscore the effectiveness and intrinsic generality of HODC in finding semantically and structurally driven matching for generalizable stereo matching networks.

## 2 Related Work

### Learning Based Stereo Matching Networks

In the past decade, deep learning has made remarkable strides in computer vision. In stereo matching, Zbontar _et al_.first introduced convolutional neural networks (CNNs) to extract features and compute matching cost . Mayer _et al_.proposed the first end-to-end correlation-based stereo matching network DispNetC . SegStereo  and EdgeStereo  incorporated semantic and edge information to resolve ambiguities in stereo matching.

More recently, several end-to-end stereo matching architectures have emerged. GCNet  concatenated left and right features directly to form a 4D cost volume and exploit 3D CNNs to aggregate matching costs. PSMNet  proposed the spatial pyramid pooling module and stacked hourglass 3D CNNs to incorporate global context information. GwcNet  constructed cost volume with both group-wise correlation and concatenation. Differentiable semi-global aggregation [47; 48], attention mechanism [41; 43], transformers  and iterative disparity range pruning [11; 37; 34; 35; 16] were also adopted in stereo matching pipeline for better generalization ability, efficiency and accuracy. RAFT-Stereo , CREStereo , IGEV  and DLNR  estimated disparity by iterative refinement using recurrent neural networks.

### Domain Generalized Stereo Matching

In recent years, there is increasing attention towards developing stereo matching networks with domain generalization capabilities, particularly focusing synthetic-to-real generalization [48; 34; 24; 42; 16]. DSMNet  proposed the domain normalization layer and the trainable non-local graph-based filter to capture robust structural and geometric representations. CFNet  introduced a cascaded and fused multi-scale cost volume for robust stereo matching. Jing _et al_.proposed an uncertainty-guided adaptive correlation module to robustly adapt stereo matching for different scenarios .

Another line of research aims to improve synthetic-to-real generalization for existing stereo matching networks directly. MS-Net  suggested using traditional feature descriptors to build domain-invariant matching space for stereo matching. GraftNet  leveraged robust broad-spectrum features pre-trained on ImageNet and a feature adaptor to improve the generalization ability. FC-Stereo  used a stereo contrastive loss and stereo selective whitening loss to encourage stereo feature consistency across different domains. ITSA  utilized an information-theoretic approach to avoid short-cut learning in stereo matching. HVT  proposed hierarchical visual transformations to learn shortcut-invariant robust representation from synthetic images. _Our work falls within this category._

### Contrastive Learning

Contrastive learning trains visual representations by pulling features of positive pairs (_i.e_., features represent the same instance, same class, or with the same defined attribute) closer and pushing negative pairs further apart. Unsupervised contrastive learning paradigms like SimCLR  and MOCO [14; 6] have demonstrated the potential of learned features in generalizing to various downstream tasks. Recent works in computer vision have extended contrastive learning paradigm to dense vision tasks [39; 40] in a supervised [20; 38], semi-supervised , or weakly-supervised manner [10; 8].

Inspired by Zhang _et al._ that used stereo contrastive loss to enhance feature consistency between left-right views, we further propose hierarchical dual-level contrastive learning to establish semantic and structural correspondence for generalizable stereo matching.

## 3 Method

### Preliminaries

Given a rectified RGB stereo image pair \(_{l,r}^{3 H W}\), stereo matching predicts horizontal displacement \(^{H W}\) for every pixel in the left image \(_{l}\). A typical stereo matching pipeline \(_{}(,)\) can be written as:

\[}_{l}=_{}_{l},_{r}=_{}f_{} _{l},f_{}_{r},\] (1)

where \(f_{}\) denotes parameterized feature extraction network, \(\) denotes cost volume construction typically via concatenation [19; 3], correlation [27; 24] or both [13; 34], and \(_{}\) denotes parameterized cost aggregation network and disparity regression with the soft-argmin operation .

Our work aims to tackle the synthetic-to-real generalization problem for stereo matching networks, where only a _synthetic_ training dataset \(\) is available. Here, \(\) consists of stereo image pairs \(\{_{l,r}^{(i)}^{3 H W}\}_{i=1}^{||}\) and corresponding disparity maps \(\{_{l,r}^{(i)}^{H W}\}_{i=1}^{||}\). The realistic test data is strictly inaccessible during training. Additionally, we denote the object index map of \(\) as \(\{_{l,r}^{(i)}^{H W}\}_{i=1}^{||}\), with each entry denoting the instance ID of the corresponding pixel.

### Overall Pipeline

As illustrated in Fig. 2, our method operates on the left and right feature maps \(_{l,r}=f_{}(_{l,r})\) extracted by the feature extraction convolutional network \(f_{}()\) within the stereo matching pipeline. Our objective is to enhance \(f_{}()\) in order to extract more effective feature maps that allow semantically and structurally driven matching for domain generalizable stereo matching.

Figure 2: Overall illustration of the proposed **hierarchical object-aware dual-level contrastive learning (HODC)** framework. An example of hierarchical segmentation of a car within the input image is demonstrated, alongside with the illustration of inter- and intra-scale positive and negative pairs for dual-level contrastive learning.

Existing stereo matching methods primarily focus on establishing pixel-wise correspondence from the left image to the right, which is prone to learning short-cut features based on appearance cues [7; 4], as they do not exhibit intrinsic knowledge such as semantic structure directly. Intuitively, enhancing semantic and structural awareness can be achieved by finding matching between corresponding object-aware regions (_i.e._, object parts) in left-right images. These regions could vary in scale but should embody certain semantic meanings (_i.e._, much larger than a pixel), and possess a moderate size to guide stereo matching as the ambiguities of stereo matching typically occur within a certain local area. This approach promotes semantic awareness in models, allowing regions to interact directly at different scales to explore structural information. It is supported by prior works which demonstrate that incorporating higher-level knowledge [44; 36] and promoting global awareness [3; 34] are crucial for improving the performance of stereo matching networks.

Based on this intuition, it is imperative to generate object-aware regions on the feature map with flexibility in scale, and enhance the matching between them to effectively establish semantic and structural correspondence. The pipeline of HODC consists of the following steps:

(1) In Sec. 3.3, we propose a segmentation scheme on object index to flexibly generate object-aware regions. We segment the original object index map **I** using rectangular grids with adjustable height \(H/N_{h}\) and width \(W/N_{w}\) to obtain sub-object level _region index_ map \(_{N_{h},N_{w}}\) at any desired scale. Leveraging the sub-object level _region index_ map and the extracted feature maps, we generate object-aware regional representations for both left and right views by aggregating pixel representations.

(2) In Sec. 3.4, instead of directly finding correspondence of regional representations, we first warp the left feature map \(_{l}\) to the right using inverse warping guided by the ground-truth disparity of the right image \(_{r}\) to obtain \(_{l r}\). Utilizing \(_{l r}\), \(_{r}\) and _region index_ map \(_{N_{h},N_{w}}\), we construct positive and negative pairs to represent correspondence. Adjusting the segmentation _scale_\((N_{h},N_{w})\) enables us to build positive and negative pairs with multi-scale, facilitating hierarchical correspondence. Furthermore, we not only establish correspondence within representations of the same scale, but also inter-scale correspondence to enhance global feature awareness.

(3) In Sec. 3.5, we introduce intra- and inter-scale contrastive loss \(_{intra},_{inter}\) using intra- and inter-scale positive and negative pairs along with the origin smooth L1 loss \(_{smooth_{L1}}\), to optimize the stereo matching network end-to-end.

### Hierarchical Object-Aware Regional Representations

Given an arbitrary feature map \(^{C H W}\) and its corresponding object index map \(^{H W}\), we can derive object-aware regional representations by computing the mean representation of pixels with the same _region index_, where _region index_ denotes the segmentation result at **sub-object level**.

To obtain such _region index_ map, we need to further perform segmentation on the given object index map. We describe the segmentation scheme by its _scale_, which can be defined by a tuple \((N_{h},N_{w})\). The sub-object level region index \(_{N_{h},N_{w}}^{H W}\) under scale \((N_{h},N_{w})\) can be derived by the following steps:

**1)** We partition the feature map into \(N_{h} N_{w}\) rectangular grids of size \(}}\) by dividing it horizontally and vertically, numbering these grids from \(1\) to \(N_{h} N_{w}\). **2)** We then index the pixels in each grid to their corresponding grid number and denote the new grid map as \(_{N_{h},N_{w}}\{1,2,,N_{h} N_{w}\}^{H W}\). **3)** Using **I** and \(_{N_{h},N_{w}}\), we determine the region index \(_{N_{h},N_{w}}\) at scale

Figure 3: Illustration of generating regional representations for HODC with the feature map **f** and object index map **I** under scale \((4,4)\) and \((8,8)\). Different color on the image denotes pixels with different indexes, and regional representations are generated by aggregating the features of pixels with the same _region index_.

\((N_{h},N_{w})\) according to the following rule: pixels are assigned the same region index **if and only if** they belong to both the same object and the same grid (as illustrated in Fig. 3).

With the derived region index map \(_{N_{h},N_{w}}\) and the extracted feature map \(\), we employ mean aggregation \((,)\) to obtain object-aware regional representations \(_{N_{h},N_{w}}\):

\[_{N_{h},N_{w}}=(,_{N_{h},N_{w}})= \{^{(i)}\ |\ ^{(i)}=_{N_{h},N_{w}}(x,y)=i} (x,y)}{_{(x,y)}[_{N_{h},N_{w}}(x,y)=i ]}\}.\] (2)

By adjusting \(N_{h}\) and \(N_{w}\), we can flexibly control the segmentation scale, thereby obtaining **hierarchical** object-aware regional representations with different scales.

### Intra- and Inter-Scale Positive and Negative Pairs

**Inverse Warping and Non-Matching Region Removal.** To build positive and negative pairs, we first establish accurate correspondence for every pixel. We perform inverse warping to align the reference (left) feature map \(_{l}\) with the target (right) \(_{r}\) feature map using ground truth disparity of the target image:

\[_{l r}=(_{l},_{r}).\] (3)

Next, we remove the non-matching pixels in the right image by left-right geometric consistency check , applying the reprojection error constraint and exclude them in calculating regional representations in Eq. 2. Non-matching pixels are those that appear in the target image but have no corresponding pixels in the reference image due to occlusion. The reprojection error \(\) for the right image is defined as the pixel difference obtained when performing inverse warping from right to left, and then from left to right. If the reprojection error exceeds a threshold \(\), the pixel is considered to be occluded . Note that by performing inverse warping and removing non-matching regions, we expect to find correspondence of **all pixels** that appear in both left and right views, which also indicates that the direction of warping will not influence the result.

**Intra-Scale Pairs.** With the given scale \((N_{h},N_{w})\), along with the warped reference feature \(_{l r}\) and target feature \(_{r}\), we obtain object-aware regional representation for both reference image \(^{l}_{N_{h},N_{w}}=(_{l r},_{N_{h },N_{w}})\) and target image \(^{r}_{N_{h},N_{w}}=(_{r},_{N_{h},N_{ w}})\) using Eq. 2. By choosing \(=^{l}_{N_{h},N_{w}}\) as the anchor (query) set and \(=^{r}_{N_{h},N_{w}}\) as the key set, the _intra-scale_ positive sample \(_{intra}\) and negative samples \(_{intra}\) for the \(i\)-th element in \(\) can be defined as:

\[_{intra}(^{(i)})=^{(i)},_{intra}( ^{(i)})=\{^{(j)}|j i\}.\] (4)

**Inter-Scale Pairs.** The _inter-scale_ pairs are further introduced to enhance global awareness of local representations by pulling local representation towards the corresponding region with a larger scale and away from other regions. To ensure stability during the learning process and prevent collapse, we operate in a hierarchical manner where local representations only interact with regions whose scale is within a factor \(K=4\). Regarding \((N_{h},N_{w})\) as the global scale, the local scale can be written as \(((N_{h} k),(N_{w} k))\), where \(k K\) is the inter-scale factor. For instance, when the global scale is set to \((N_{h},N_{w})=(2,4)\) with an inter-scale factor \(k=2\), the corresponding local scale is \((4,8)\).

Similarly, we construct the anchor (query) set by aggregating local representations: \(=^{l}_{(N_{h} k),(N_{w} k)}=( _{l r},_{(N_{h} k),(N_{w} k)})\). The _inter-scale_ positive sample and negative samples of scale \(((N_{h} k),(N_{w} k))\) are the corresponding and non-corresponding regions at the global scale of \((N_{h},N_{w})\), respectively, which can be obtained by the following rule:

\[=}^{r}_{(N_{h} k),(N_{w} k)}= (},_{(N_{h} k),(N_{w} k )}),\] (5)

\[^{k}_{inter}(^{(i)})=^{(i)},^{k}_{ inter}(^{(i)})=\{^{(j)}|j i\},\] (6)

where \(}_{r}^{C H W}\) denotes the regional representation (under the global scale \((N_{h},N_{w})\)) that each pixel lies in:

\[}_{r}=^{-1}(^{r}_{N_{h},N_{w}}, _{N_{h},N_{w}}).\] (7)In Eq. 7, \(^{-1}(,_{N_{h},N_{w}})\) denotes inverse mapping from the aggregated regional representations \(\) to the feature map where each pixel's value is the representation of its corresponding region.

**Hard Negative Selection.** Previous studies [18; 20; 38] have demonstrated that hard negatives that are similar to the anchor, can contribute more to the discriminating power of the learned representations, thereby reducing local ambiguities in stereo matching. Inspired by this, we select the top \(10\%\) most similar negatives in \(_{inter}\) and \(_{intra}\) to calculate the contrastive loss.

**Remark.** It's important to note that we do not use memory banks or asymmetric structural design [14; 49] to obtain positive or negative pairs. Instead, all positive and negative pairs are calculated within the same batch. This is due to the effectiveness of using hierarchical regional representations for finding semantically and structurally driven matching.

### Hierarchical Dual-Level Contrast and Learning Objectives

We perform hierarchical contrastive learning by employing queries and keys at different scales. Given scale \((N_{h},N_{w})\) and the inter-scale factor \(k\), the intra-scale contrastive loss \(_{intra}\) and inter-scale contrastive loss \(_{inter}\) can be written as:

\[_{inter}^{(N_{h},N_{w}),k} =_{(N_{h} k),(N_{w} k) }^{l},_{intra},_{intra}+ _{(N_{h} k),(N_{w} k)}^{l},_{intra}, _{intra},\] (8) \[_{inter}^{(N_{h},N_{w}),k} =_{(N_{h} k),(N_{w} k) }^{l},_{inter}^{k},_{inter}^{k}.\] (9)

To enable building more flexible representations, we do not enforce \(N_{h}=N_{w}\), but instead impose weaker constraint (_i.e._, \(N_{h},N_{w}\{2^{i}|i\}\)) to stabilize the training process. Additionally, we set the maximum scale as \(M\) to reduce the computational cost, ensuring that \(N_{h} N_{w} M\). Considering inter-scale factor \(k K\) as mentioned in Sec. 3.4, the dual-level hierarchical contrastive learning objectives can be formulated as:

\[_{contrastive}=_{N_{h},N_{w}\{2^{i}|i \}}^{N_{h} N_{w} M}_{k^{*}}^{k K} _{intra}^{(N_{h},N_{w}),k}+_{inter}^{(N_{h},N_{w }),k}.\] (10)

We utilize the widely adopted InfoNCE  loss to conduct intra- and inter-scale contrastive learning:

\[(,,)=|}_ {z}-(z)/)}{(z (z)/)+_{z\_}{-(z)}(z z_{-}/ )},\] (11)

where \(=0.05\) denotes the temperature parameter. Together with the widely adopted smooth-L1 loss \(_{smooth_{L1}}\), the overall learning objective is:

\[_{overall}=_{smooth_{L1}}+ _{contrastive},\] (12)

where \(\) balances the weight between the smooth-L1 loss and contrastive loss.

## 4 Experiments

### Experiment Settings

We select four stereo matching networks with different architectures as baselines to validate the performance of HODC, including two widely studied models (PSMNet  and GwcNet ), a robust method with cascaded and fused cost volume (CFNet ) and a recently proposed iterative-based state-of-the-art method (IGEV ). We integrate HODC directly during their training stage and test their generalization performance on realistic datasets.

We train all models with _synthetic_ dataset SceneFlow  and evaluate their generalization performance on the training set of four _realistic_ datasets: KITTI-2012 , KITTI-2015 , Middlebury  and ETH3D . We use the object index map provided by the SceneFlow dataset, which can also be collected by using a pre-trained segmentation model (more discussion in Sec. 4.4). Following previous works [7; 49], we evaluate the performance of our model using the D1 metric, which calculates the percentage of outliers in the reference image with different pixel threshold \(\). The threshold is set to \(3\)px for KITTI-2012 and KITTI-2015, \(2\)px for Middlebury, and \(1\)px for ETH3D, as suggested by dataset providers and previous works.

For comparison, we include recently proposed domain generalization approaches for stereo matching networks (MS-Net , FCSetero , ITSA , GraftNet  and HVT ) as well as other robust architectures [23; 48; 35; 16].

### Overall Generalization Performance Comparison

As shown in Tab. 1, after integrating HODC, the synthetic-to-real generalization performance of all baselines substantially increases by a visible margin. Compared to other generalization methods, our approach achieves the highest generalization performance in almost every setting (except for ITSA-CFNet on KITTI-2015), which demonstrates the effectiveness of HODC. HODC is also compatible with CFNet  using specially designed robust architecture and IGEV  with iterative refinement.

Notably, the generalization performance of older baselines (PSMNet, GwcNet) is comparable with or even outperforms current SOTA methods training with HODC. This demonstrates the importance of extracting semantically and structurally aware features to improve generalization for stereo matching.

### Semantically and Structurally Driven Matching

In this section, we validate the semantically and structurally driven attributes of HODC through visualizations on the realistic Middlebury  and ETH3D  datasets. As discussed in Sec. 3.2, we select a small area in the reference image and calculate its representation to perform the query, ensuring that HODC is capable of performing accurate matching to guide the stereo matching network. We measure the similarity between this representation and the pixel representations in the target image. As shown in Fig. 4, PSMNet  exhibits ambiguity in matching by superficial chromatic features, resulting in high feature similarity in continuous local areas. FC-PSMNet  also lacks the ability to identify semantical and structural elements, showing high feature similarity in non-matching regions. Conversely, our approach accurately identifies matched regions, with limited ambiguities mainly observed in vertical areas that are not the matching candidates for stereo matching.

    &  &  &  &  &  \\    & & **2015** & **2012** & & & **Half** & **Quarter** & \\   & STTR  & 6.7 & 8.7 & 15.5 & 9.7 & 17.2 & ICCV’2021 \\  & DSMNet  & 6.5 & 6.2 & 13.8 & 8.1 & 6.2 & ECCV’2020 \\  & FC-GANNet  & 5.3 & 4.6 & 10.2 & 7.8 & 5.8 & CVPR’2022 \\  & PCWNet  & 5.6 & 4.2 & 15.8 & - & 5.2 & ECCV’2022 \\  & CRESetero++  & 5.2 & 4.7 & - & - & 4.4 & ICCV’2023 \\   & PSMNet  & 16.3 & 15.1 & 26.9 & 20.0 & 23.8 & CVPR’2018 \\  & MS-PSMNet  & 13.9 & 7.8 & 19.9 & 10.8 & 16.8 & 3DV’2020 \\  & FC-PSMNet  & 5.8 & 5.3 & 15.1 & 9.3 & 9.5 & CVPR’2022 \\  & ITSA-PSMNet  & 5.8 & 5.2 & 12.7 & 9.6 & 9.8 & CVPR’2022 \\  & Graft-PSMNet  & 4.8 & 4.3 & 9.7 & - & 7.7 & CVPR’2022 \\  & HVT-PSMNet  & 4.9 & 4.3 & 10.2 & - & 6.9 & CVPR’2023 \\  & **HODC-PSMNet** & **4.7** & **3.9** & **9.3** & **7.0** & **5.4** & **Ours** \\   & GwcNet  & 22.7 & 20.2 & 34.2 & 18.1 & 30.1 & CVPR’2019 \\  & FC-GwcNet  & 5.4 & 5.0 & 11.2 & 8.2 & 8.0 & CVPR’2022 \\  & ITSA-GwcNet  & 5.4 & 4.9 & 11.4 & 9.3 & 7.1 & CVPR’2022 \\  & HVT-GwcNet  & 5.0 & **3.9** & 10.3 & - & 5.9 & CVPR’2023 \\  & **HODC-GwcNet** & **4.9** & **3.9** & **8.4** & **5.8** & **4.3** & **Ours** \\   & CFNet  & 5.8 & 4.7 & 15.3 & 9.8 & 5.8 & CVPR’2021 \\  & ITSA-CFNet  & **4.7** & 4.2 & 10.4 & 8.5 & 5.1 & CVPR’2022 \\  & HVT-CFNet  & 4.9 & 4.0 & 10.2 & - & 4.5 & CVPR’2023 \\  & **HODC-CFNet** & 4.8 & **3.8** & **9.5** & **7.5** & **4.2** & **Ours** \\   & IGEV  & 5.6 & 5.1 & 7.1 & 6.2 & 3.6 & CVPR’2023 \\  & **HODC-IGEV** & **4.5** & **3.8** & **7.0** & **5.2** & **2.7** & **Ours** \\   

Table 1: Overall generalization performance comparison with previous works.

We further provide deeper insights into feature similarity using SceneFlow  test set (randomly select 500 image pairs) with dense annotations. We compare the feature cosine similarity of PSMNet , FC-PSMNet  and HODC-PSMNet between matching intra- and inter-scale regions at different scales. Additionally, we include the cosine similarity of the top 5% and 10% hardest negative paris. Zhang _et al_.  suggest that feature consistency between matching pixels is consistent with the model's generalization performance. However, referring to Tab. 2, we find that dissimilarity between negatives that can provide more discriminative power plays a more important role in the model's generalization ability, which is neglected in previous works. Using the HODC framework, the hardest negatives at both intra- and inter-scale can also be effectively distinguished.

### Segmentation Scale Analysis and Ablation Study

In this section, we conduct further analysis of HODC on PSMNet  and GwcNet . First, we investigate the effect of the segmentation scale by changing \(M\) in Eq. 10 (keeping \(K=4\) unchanged). As shown in Tab. 3, the performance of our method remains stable with different \(M\) in a relatively large interval. Notably, segmenting the object using fewer grids to perform contrastive learning on a larger scale can improve the performance of stereo matching networks on certain datasets (_e.g_., KITTI-2012 and KITTI-2015), while other datasets or networks benefit from a larger \(M\) to enhance performance. This can be attributed to larger \(M\) providing more accurate local matching with more negative samples and finer representations, while smaller \(M\) derives features on larger scales.

Next, we perform an ablation study to examine the effectiveness of intra- and inter-scale contrastive loss. Referring to Tab. 3, the performance of PSMNet and GwcNet decreases on all datasets without using \(_{intra}\) or \(_{inter}\). Furthermore, we analyze the robustness of the proposed dual-level contrastive learning with hierarchical representations when the object index map is inaccurate. We conduct an extreme case evaluation by omitting the object prior and performing segmentation directly on the entire image. Though a decline in performance is observed, the proposed method still achieves

    &  &  &  \\   & & _Pos \(\)_ & _Neg \(\)_ & _10\% Hard \(\)_ & _5\% Hard \(\)_ & _Pos \(\)_ & _Neg \(\)_ & _10\% Hard \(\)_ & _5\% Hard \(\)_ \\   & \(4 4\) & 0.96 & 0.47 & 0.85 & 0.88 & 0.86 & 0.47 & 0.84 & 0.87 \\  & \(8 8\) & 0.95 & 0.45 & 0.84 & 0.87 & 0.85 & 0.45 & 0.83 & 0.86 \\  & \(16 16\) & 0.95 & 0.43 & 0.83 & 0.87 & 0.83 & 0.41 & 0.80 & 0.84 \\   & \(4 4\) & 0.99 & 0.88 & 0.97 & 0.98 & 0.97 & 0.88 & 0.97 & 0.98 \\  & \(8 8\) & 0.99 & 0.87 & 0.97 & 0.98 & 0.97 & 0.87 & 0.97 & 0.97 \\  & \(16 16\) & 0.99 & 0.86 & 0.97 & 0.97 & 0.97 & 0.85 & 0.96 & 0.97 \\   & \(4 4\) & 0.95 & 0.27 & 0.66 & 0.71 & 0.78 & 0.26 & 0.64 & 0.70 \\  & \(8 8\) & 0.95 & 0.24 & 0.62 & 0.68 & 0.78 & 0.24 & 0.61 & 0.67 \\  & \(16 16\) & 0.94 & 0.22 & 0.60 & 0.65 & 0.78 & 0.21 & 0.58 & 0.62 \\   

Table 2: Cosine similarity comparison of positive and negative pairs on SceneFlow  test set.

Figure 4: Qualitative result of semantically and structurally driven matching on realistic Middlebury  and ETH3D  datasets. The first column shows the query region, which is marked red and highlighted with green box. The remaining columns show the region on the target image that has cosine similarity larger than the threshold \(=0.9\) with different methods.

considerable performance and outperforms some SOTA methods (_e.g._, FCS stereo , ITSA ) by establishing local and global correspondence with our dual-level contrastive loss.

## 5 Conclusion

We proposed a novel and effective hierarchical object-aware dual-level contrastive learning (HODC) framework aimed at enhancing stereo matching networks' ability to extract semantically and structurally meaningful features and improve their generalization performance. Our approach leveraged a flexible segmentation scheme on objects to obtain hierarchical object-aware representations, followed by intra- and inter-scale contrastive learning guided by ground-truth disparity. Through extensive experiments with visualization, we have demonstrated that our method facilitates networks in achieving better generalization by enabling them to find semantically and structurally driven matches.