# Suggesting Variable Order for Cylindrical Algebraic Decomposition via Reinforcement Learning

Fuqi Jia

Yuhang Dong

Minghao Liu

Pei Huang

Stanford University, Stanford, USA {jiafq,liumh,maff,zj}@ios.ac.cn, dongyuhang22@mails.ucas.ac.cn, huangpei@stanford.edu

Feifei Ma

Jian Zhang

These authors contributed equally.State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China Laboratory of Parallel Software and Computational Science, Institute of Software, Chinese Academy of Sciences, Beijing, China University of Chinese Academy of Sciences, Beijing, China Stanford University, Stanford, USA {jiafq,liumh,maff,zj}@ios.ac.cn, dongyuhang22@mails.ucas.ac.cn, huangpei@stanford.edu

###### Abstract

Cylindrical Algebraic Decomposition (CAD) is one of the pillar algorithms of symbolic computation, and its worst-case complexity is double exponential to the number of variables. Researchers found that variable order dramatically affects efficiency and proposed various heuristics. The existing learning-based methods are all supervised learning methods that cannot cope with diverse polynomial sets. This paper proposes two Reinforcement Learning (RL) approaches combined with Graph Neural Networks (GNN) for Suggesting Variable Order (SVO). One is GRL-SVO(UP), a branching heuristic integrated with CAD. The other is GRL-SVO(NUP), a fast heuristic providing a total order directly. We generate a random dataset and collect a real-world dataset from SMT-LIB. The experiments show that our approaches outperform state-of-the-art learning-based heuristics and are competitive with the best expert-based heuristics. Interestingly, our models show a strong generalization ability, working well on various datasets even if they are only trained on a 3-var random dataset. The source code and data are available at https://github.com/dongyuhang22/GRL-SVO.

## 1 Introduction

As learned in school, we know how to answer the question of whether a quadratic equation for \(x\) has a real root. For example,

\[x^{2}+bx+c=0,\]

where \(b,c\) are unknowns. We can answer it by checking whether the discriminant is non-negative, i.e., \(b^{2}-4c 0\). What if the number and degree of variables increase, and the formula involves the combination of the universal quantifier (\(\)), existential quantifier (\(\)), and logical operators (and(\(\)), or(\(\)), not(\(\)))? Checking whether polynomials satisfy some mathematical constraints is a difficult problem and has puzzled mathematicians since ancient times. Until the 1930s, Alfred Tarski  answered the question by proving that the theory of real closed fields admits the elimination of quantifiers and gives a quantifier elimination procedure. Unfortunately, the procedure was impractical due to its non-elementary complexity. In 1975, George Collins discovered the first relatively efficient algorithm, Cylindrical Algebraic Decomposition (CAD) . Currently, CAD (and variants) hasbecome one of the most fundamental algorithms in symbolic computation and is widely used in computational geometry , robot motion planning , constraint programming [5; 6; 7].

More precisely, CAD is an algorithm that eliminates (technically called _project_) variables one by one and finally results in a list of regions that are sign-invariant to the polynomials (technically called _cells_). CAD provides an efficient quantifier elimination in real space, thereby enabling the solution of various problems related to polynomials. For example, the space of the discriminant of the quadratic equation (i.e., \(b^{2}-4c 0\)) can be the combination of satisfied cells. We provide a detailed description in Appendix A. Due to its powerful analytical ability and great versatility, it is also accompanied by huge limitations. The theoretical worst complexity is double exponential to the number of variables .

Researchers have conducted in-depth studies on improving its efficiency. According to theoretical and practical research, there lives a very important conclusion that "variable order in CAD can be crucially important" [8; 9; 10; 11; 12; 13; 14; 15; 16]. The selection of variable orders has a great effect on the time, memory usage as well as the number of cells in CAD. As an example,  introduces a category of problems where one variable order leads to a result with double exponential complexity to the number of variables, while another order yields a constant-sized result.

In this paper, we present a Graph-based Reinforcement Learning for Suggesting Variable Order (GRL-SVO) approach for CAD. It has two variants: GRL-SVO(UP) (i.e., utilizing _project_) and GRL-SVO(NUP) (i.e., not utilizing _project_). GRL-SVO(UP) is integrated into the CAD and can select the "best" next projecting variable. Considering the high cost of interacting with the symbolic computation tool, we also propose a fast approach GRL-SVO(NUP), which will simulate the state transition (i.e., _project_) via two rules (update rule and delete rule). It can report a total variable order before the CAD process. To evaluate the effectiveness of the models, we conduct a dataset of random polynomial sets with 3 to 9 variables and collected instances from SMTLIB [13; 17] to form a real-world dataset. Experimental results show that our approaches outperform state-of-the-art learning-based heuristics and are competitive with the best expert-based heuristics. GRL-SVO also exhibits a strong generalization capability. The models are only trained on a 3-var random dataset, but they still work well on other datasets.

## 2 Background and Related Work

In this section, we briefly introduce some basic definitions of CAD [2; 18]. We classify the previous works of SVO and give an overview of the techniques used.

### Cylindrical Algebraic Decomposition (CAD)

A Cylindrical Algebraic Decomposition (CAD) is a decomposition algorithm of a set of polynomials in ordered \(^{n}\) space resulting in finite sign-invariant regions, named _cells_. As shown in Figure 0(a), there are 3 cells with different colors (two infinite regions and the curve), and any points in the cell lead to the same sign of \(y-x^{2}\). Let \([]\) be the ring of polynomials in the variable vector \(=[x_{1},,x_{n}]\) with coefficients in \(\).

Figure 1: Examples of CAD. Figure 0(a) shows cells of \(\{y-x^{2}\}\). Figure 0(b) and 0(c) are CAD with different variable orders on \(\{x^{3}y+4x^{2}+xy,-x^{2}+2xy-1\}\).

**Definition 1** (Cell).: _For any finite set \(Q[]\), a cell of \(Q\) is defined as a maximally connected set in \(^{n}\) where the sign of every polynomial in \(Q\) is constant._

CAD accepts a set of polynomials and a fixed variable order and mainly consists of three running phases: _project, root isolate_, and _lift_. The _project_ phase eliminates a variable of a polynomial set once at a time. It will result in a new _projected_ polynomial set that carries enough information to ensure possible decomposition. After repeating calls to _project_, CAD constitutes a step-like (from n-1 variables to 1 variable) set of _projected_ polynomials. The _root isolate_ procedure isolates all roots of the univariate polynomial set, and the roots split \(\) into some segmentations. The _lift_ phase samples in the segmentations and assigns the sampled value to the former _projected_ polynomial set so that the former polynomial set will become a univariate polynomial set. After repeating _root isolate_ and _lift_\(n-1\) times, CAD reconstructs the entire space via a set of cells characterized by the sample points. Since the CAD process and the _project_ operators are not prerequisites to understand our approach, we arrange more details in Appendix A. Here, we exemplify the process and the effect of different variable orders.

**Example 2.1**.: _Consider a polynomial set \(\{x^{3}y+4x^{2}+xy,-x^{2}+2xy-1\}\) as in Figure 0(b) and 0(c)._

_CAD process._ _Assume that the variable order is_ \(x y\)_. CAD eliminates_ \(y\) _first and results in a polynomial set_ \(\{x,x^{2}+1,x^{4}+10x^{2}+1\}\) _(i.e., project phase). The polynomial set has only one root_ \(x=0\) _(i.e., root isolation phase). Then_ \(\) _will be split into three segmentations:_ \(\{x<0,x=0,x>0\}\)_. We sample_ \(\{x=-5,x=0,x=5\}\) _and result in three different polynomial sets:_ \(\{-130y+100,-10y-26\}\)_,_ \(\{-1\}\)_, and_ \(\{130y+100,10y-26\}\) _(i.e., lift phase). Let's take the first polynomial set as an example, and it has two roots, i.e.,_ \(\{,-\}\) _(i.e., root isolation phase). Then_ \(\) _will be split into five segmentations:_ \(\{y<-,y=-,-<y<,y=,y>\}\)_. As shown in Figure 0(b), the sample red point_ \((-5,4)\) _can represent a sign-invariant region, the whole shaded area (i.e.,_ \(x^{3}y+4x^{2}+xy<0-x^{2}+2xy-1<0 x<0\)_)._

_Effect of different variable orders._ _Figure 0(b) first eliminates_ \(y\) _then_ \(x\) _and results in 13 cells, and Figure 0(c) first eliminates_ \(x\) _then_ \(y\) _and results in 89 cells, almost seven times that of the former._

### Suggesting Variable Order for Cylindrical Algebraic Decomposition

An **Expert-Based (EB)** heuristic is a sequence of meticulous mechanized rules. It is mainly derived from theoretical analysis or a large number of observations on practical instances and summarized by experts. The heuristics can capture the human-readable characteristics of the problem. A **Learning-Based (LB)** heuristic will suggest an order through the scoring function or a variable selection distribution given by the learning model. It can exploit features deep inside the problem statement via high-dimensional abstraction.

Another important indicator is whether invoking _project_, as the _project_ phases are time-consuming for SVO heuristics in practice. In the following, **UP** denotes heuristics utilizing _project_, and **NUP** denotes heuristics not utilizing _project_.

**EB & UP.** The heuristics _sotd_ (sum of total degree) , and _ndrr_ (number of distinct real roots)  will project utilizing all different variable orders until the polynomial sets with only one variable. Then _sotd_ will select the order with the smallest sum of total degrees for each monomial, while _ndrr_ will select the order with the smallest number of distinct real roots. Because of the combinatorial explosion of orders, the heuristics projecting all orders only work on the case with a small number of variables. Based on CAD complexity analysis, _gmods_ selects the variable with the lowest degree sum in the polynomial set after each _project_ phase.

**EB & NUP.** The heuristics _brown_, and _triangular_ introduced a series of rules about statistical features like degree, total degree, and occurrence to distinguish the importance of variables. The heuristic _chord_ also provides an efficient algorithm based on the associated graph. It makes a variable order via _perfect elimination ordering_ on the graph. Note that chord heuristic only works on the _chordal_ graph. It is a special case that, after each _project_ phase, the graph only removes the linked edges of the projected variable without changing the other components.

**LB & UP.** To the best of our knowledge, no heuristic should be classified into this category.

**LB & NUP.** The approach _EMLP_ utilizes an MLP neural network. The network takes the selected statistics of the polynomial set as input and outputs a label for variable order directly. If thepolynomial set has 3 variables, then \(3!=6\) output labels are necessary for the neural network. The approach _PVO_ combines neural network and EB & NUP heuristics like _brown_ and _triangular_. The neural network is trained to predict the best first variable while the EB & NUP heuristics decide other parts of orders. These kinds of heuristics work on 6 variables at most in their experiments.

According to the classification, our proposed approaches, GRL-SVO(UP) and GRL-SVO(NUP), can be categorized as LB & UP and LB & NUP, respectively.

### Graph Neural Network and Reinforcement Learning

Graph Neural Networks (GNNs) are a class of deep learning models for graph-structured data. GNNs include many variants according to the characteristics of the problems, such as GCN , GAT , superGAT , and so on. Reinforcement Learning (RL) is an advanced machine learning paradigm where an agent learns to make decisions by interacting with its environment. It includes various frameworks, such as REINFORCE , DQN , and so on. By leveraging the expressive power of GNNs to learn complex graph structures and the adaptability of Reinforcement Learning (RL) to find optimal decision-making policies, researchers have remarkably succeeded in combinatorial algorithm design [24; 25; 26]. GRL-SVO is based on an Advantage Actor-Critic (A2C) framework [24; 27] with a Graph Network .

## 3 Method

This section starts with the problem formulation for the framework, followed by an overview and description of the graph representation and architecture. Finally, we introduce the state transition without _project_, which is the key technique for GRL-SVO(NUP).

### Problem Formulation

We now give the formulation of SVO for CAD. Our goal is to improve CAD efficiency by suggesting a better variable order. Computation time and memory usage are important indicators, but they will be affected by random factors, such as CPU clock, usage rate, etc. As the main output of CAD, cells can be the best candidate. In order to measure the quality of the result, the number of cells is an appropriate indicator that intuitively shows the effect of CAD . In theory, a large number of cells means that the partitions are fragmented compared to a small number of cells. Usually, the polynomial set generated from _project_ phase is complex and difficult for the next phases of CAD. In practice, the number of cells also strongly correlates to the computation time and memory usage. Figures of the relation are listed in Appendix B, and we found that the computation time and memory usage increase when the number of cells increases. The objective is to minimize the number of cells \(N(Q,)\), where \(Q[]\) is a polynomial set with coefficients in \(\) and \(\) is the given variable order, i.e., \( N(Q,)\).

By analyzing the input polynomial set \(Q\), we can derive the variable order so that we ought to minimize the objective:

\[ N(Q,(Q)).\]

The difficulties of this framework mainly come from two aspects:

* Huge input space. The expression of a polynomial is compressed, and any slight change in form (such as power) will change the geometric space drastically. The EB heuristics may become inefficient when encountering characteristics beyond the summarized patterns.
* Huge output space. The number of variable orders and the number of variables have a factorial relationship, i.e., \(n\) variables resulting in \(n!\) different variable orders. For example, 10 variables lead to \(3628800\) candidate variable orders. _sotd_-like, _ndrr_-like, and _EMLP_-like heuristics become impractical due to the vast number of candidate variable orders.

### GRL-SVO Overview

In this paper, considering the challenges mentioned above, we propose the GRL-SVO approach, and Figure 2 shows the overall architectures. For huge input space, we compress the polynomial information into an associated graph  with embeddings, which is simple and can depict the relationship between variables. For huge output space, we utilize the neural network to predict the next best variable, and by repeating until no variables are left, the trajectory corresponds to a variable order. In detail, the actor neural network provides a distribution of actions, i.e., the choice of variables. The critic neural network scores the total order and stabilizes the training process as a state-dependent baseline. GNN encodes each variable of the current state as a high-dimensional embedding, and additional neural network components transform them into our policy. As for state transformation, GRL-SVO(UP) and GRL-SVO(NUP) are different in utilizing _project_. The environment of GRL-SVO(UP) projects the selected variable and reorganizes the total graph, while that of GRL-SVO(NUP) updates the graph via the update rule and delete rule.

### Graph Representation

The graph of a polynomial set can be different. We introduce a graph structure that can reflect the coupling relationship between variables.

**Definition 2** (Associated Graph ).: _Given a polynomial set \(F\), and the variable set of \(F\), \(V=var(F)\), an associated graph \(G_{F}(V,E)\) of \(F\) is an undirected graph, where \(E=\{(x_{i},x_{j})| f F,x_{i},x_{j} var(f)\}\)._

In other words, if two variables appear in the same polynomial, they will have an edge.

GNNs have invariance to permutations and awareness of input sparsity [31; 32; 33]. The strength similarly applies to our work. The associated graph is pure and simple, which only retains information related to variables and "neighbors" in the same polynomial. Note that such a graph can easily become a complete graph. For example, \(x_{1}+x_{2}+x_{3}+x_{4}\) corresponds to a complete associated graph. So, we need to distinguish nodes via rich embeddings, detailed in Appendix B. The embeddings are proposed based on former research [16; 34] and our observations. The embedding vectors of variables will be first normalized via the z-score method, i.e.,

\[E^{}_{j}[x]=[x]-mean(\{E_{j}[v]\})}{std(\{E_{j}[v]\})},v var (F^{0}),\]

where \(F^{0}\) is the corresponding polynomial set and \(E_{j}[x]\) denotes the \(j\)-th scalar of the original embedding of variable \(x\).

The graph representation is a tuple \((F^{0},A^{0},X^{0})\) where \(A^{0}\{0,1\}^{n n}\) is the adjacency matrix of the associated graph and \(X^{0}^{n d}\) is a normalized node embedding matrix for variables.

To encode the representation, we utilize a stack of \(k\) GNN layers, Formula (5.7) in . The process encodes the representations \(X^{i+1}=[X^{i+1};;X^{i+1}[n-1]]\) via

\[X^{i+1}[u]=(X^{i}[u]^{i}_{g,self}+_{v(u)}X ^{i}[v]^{i}_{g,neigh}+^{i}_{g,bias}),\]

where \(^{i}_{g,self}\) and \(^{i}_{g,neigh}\) are trainable parameter matrices in \(^{H^{i} H^{i+1}}\), and \(\) denotes the activation function. \(^{i}_{g,bias}\) is the trainable bias term in \(^{H^{i+1}}\), and \((u)\) is the set of neighbours of variable

Figure 2: The architecture of GRL-SVO(UP) and GRL-SVO(NUP) where \((,x)=MLP(CONCAT(,x))\) for updating the embedding for the neighbours of \(x\). The dashed lines represent that it will be only utilized in training mode.

\(u\). \(H^{i}\) is the dimension of hidden channels, and \(H^{0}=d\). The layer will aggregate the local information of variables and update the embedding sequentially. Finally, we obtain the intermediate tuple \((F^{k},A^{k},X^{k})\).

### Architecture

#### 3.4.1 Markov Decision Process (MDP)

**State Space and Action Space.** GRL-SVO(UP/NUP) will suggest a variable order for any polynomial set. The state space includes the graph representation of any polynomial set, i.e., \(=\{G=(F^{0},A^{0},X^{0})\}\). Although it is a very large space, the state \(s\) provides sufficient statistics to evaluate actions. Action corresponds to a candidate variable to _project_. For a given state \(s\), the action space is \(=var(F_{s})\), where \(F_{s}\) denotes the polynomial set of current state \(s\).

**Environment.** At the time \(t\), the environment of GRL-SVO(UP) takes current state \(s^{t}\) and selected variable (action \(a^{t}\)) as input and outputs a new state \(s^{t+1}\) via processing the projected polynomial set of CAD. That of GRL-SVO(NUP) only removes the selected variable and linked edges from the current state \(s^{t}\) and updates embeddings via neural networks, which is detailed in Section 3.5.

**Reward.** The number of cells is sufficient to reflect the impact of variable order on efficiency. \(R(|s^{0})=-N(F_{s^{0}},)/M\) denotes the reward for a given variable order \(\) under the initial state \(s^{0}\), i.e., the negative number of cells divided by a static normalization factor \(M\). If the order leads to running timeout and cannot obtain the number of cells, \(R(|s^{0})=-1\) directly. The reward of agent policy will increase as the training progresses.

#### 3.4.2 Neural Network Architecture

**Neural Network.** The actor network \(_{a}:^{n d}^{n}\) combines an MLP and softmax layer that transforms the \(X_{t}^{k}\) of \(s^{t}\) to the action distribution at time \(t\). The action obeys the distribution, i.e.,

\[a^{t}_{a}(X_{t}^{k})=softmax(MLP(X_{t}^{k})).\]

The critic network \(_{c}:^{n d}\) is a combination of MeanPool and MLP layers, where \(MeanPool:^{n d}^{d}\). The critic value is defined as

\[_{c}(X_{0}^{k})=MLP(MeanPool(X_{0}^{k})).\]

**Training.** The parameters of GRL-SVO \(=\{_{g},_{a},_{c}\}\) will go through an end-to-end training process via stochastic gradient descent method. Given initial state \(s\), we aim to learn the parameters of a stochastic policy \(p_{}(|s)\), which assigns high probabilities to order with a small number of cells and low probabilities to order with a large number of cells. Our neural network architecture uses the chain rule to factorize the probability of a variable order \(\) as \(p_{}(|s)=_{t=1}^{n}p_{}(^{t}|s,^{<t})\), where \(p_{}(^{t}|s,^{<t})=_{a}(X_{t}^{k})\) is current action distribution. \(^{t}\) is the \(t\)-th element in the variable order \(\) and \(^{<t}\) is the partial order from \(^{1}\) to \(^{t-1}\). The training objective is the expected reward, which is defined as \(J(|s)=_{ p_{}(|s)}R(|s)\).

Through the well-known REINFORCE algorithm , the gradient of the training objective is

\[_{}J(|s)=_{ p_{}(|s)}[(R( |s)-c(s))_{}logp_{}(|s)],\]

where \(c(s)=_{c}(X_{0}^{k})\) is the predicting critic value.

Through Monte Carlo sampling, we obtain \(N\)\(i.i.d\) polynomial sets corresponding to states \(s_{1},s_{2},,s_{N}\), and \(N\) variable orders \(_{i} p_{}(|s_{i})\). So we update the parameters of neural networks via

\[_{a} _{a}+_{i=1}^{N}{(R(_{i}|s_{i} )-c(s_{i}))_{}logp_{}(_{i}|s_{i})},\] \[_{c} _{c}+_{i=1}^{N}{(R(_{i}|s_{i} )-c(s_{i}))_{}c(s_{i})}.\]

**Inference.** At inference time, we generate an order via a greedy selection. For the \(i\)-th element of the order \(\), we select the variable \(x\) with the maximal probability, i.e., \(x=_{x V_{t-1}}(p(x|s,^{<t}))\)where \(V_{t-1}=var(F_{s^{t-1}})\) is the set of variables that have not been projected at time \(t\). After selecting variables \(n-1\) times, we obtain the total order \(\).

### State Transition without _Project_

We provide an LB & NUP heuristic to free from interaction with the symbolic computation tools. It simulates the _project_ via a neural network for embedding transformation and a delete rule.

As an example, Figure 3 shows a specific case of state transition. The polynomial set changes after _project_ phase the variable \(x_{4}\), where \(3x_{1}^{2}x_{4}-4x_{4}^{3}-1\) is reduced to a set \(\{x_{1}-1,x_{1}+1,x_{1}^{2}-x_{1}+1,x_{1}^{2}+x_{1}+1\}\) without \(x_{4}\) while the polynomial \(x_{1}^{3}-4x_{2}^{2}x_{3}+12x_{2}+3\) remains unchanged. So, the embedding of neighbors of \(x_{4}\), i.e., \(x_{1}\), will change greatly while that of other variables will change slightly. Besides, the projected variable should also be removed from the associated graph. Based on the aforementioned inspiring situations, we propose two rules for approximately simulating _project_.

At time \(t-1\), assume \(x_{i}\) is the next projecting variable. We mainly consider the projected variable's influence on its 1-hop neighbor variables.

**Update Rule.** We update the embedding \(X\) without _project_ for other variables \(x_{j}\) via

\[X[x_{j}]^{t}=\{(X[x_{j}]^{t-1},X[x_{i}]^{t-1}),&A [x_{i}][x_{j}]=1,\\ X[x_{j}]^{t-1},&otherwise,.\]

where \((a,b)=MLP(CONCAT(a,b))\) is the neural network that simulates the _project_ for embedding transformation.

**Delete Rule.** It will trivially remove \(x_{i}\) and edges linked to \(x_{i}\) and update \(A,X\) in the state correspondingly.

\[A RemoveRowColumn(A,Map(x_{i})),\] \[X RemoveRow(X,Map(x_{i})),\] \[Map(x_{j}) Map(x_{j})-1,i<j<n,\]

where the function \(Map(x):V\), maps the variable \(x\) to the index in matrix \(A\) and \(X\), the operation \(RemoveRowColumn(A,Map(x_{i}))\) removes the row and column of variable \(x_{i}\) from \(A\), and the operation \(RemoveRow(X,Map(x_{i}))\) removes the row of variable \(x_{i}\) from \(X\).

After such transitions, the state will feed the model defined by Section 3.4 and obtain the next projecting variable. After calling the model \(n-1\) times, the trajectory corresponds to a variable order suggested by GRL-SVO(NUP).

## 4 Experiments

### Setup

**Implementation and Environments.** We utilized PyTorch Geometric  for implementations of our approach. The hyper-parameters are listed in Appendix B. We utilized the NVIDIA Tesla V100 GPU for training. After the heuristics output the variable order, all instances with the given variable order are run with MAPLE 2018 on an Intel Xeon Platinum 8153 CPU (2.00GHz). The run-time limit is 900 seconds, and the time to predict a variable order is also counted.

**Dataset.** We utilize two CAD datasets: _random_ and _SMT-LIB_. The detailed parameters of _random_ generation and collecting methods for _SMT-LIB_ are presented in Appendix B.

The _random_ dataset contains 7 categories from 3-var to 9-var. We generate 20000 3-var instances and split them into training, testing, and validation sets in a ratio of 8:1:1. We pre-run all \(3!=6\) variable orders and remove non-conforming instances where some variables are eliminated due to random generation, for example, \(x-x=0\); we remove the instances that are all timeout under 6 orders. The rest sets have 14990, 1871, and 1887 instances, respectively. The other categories contain 1000 instances. They are generated by _randpoly_ of MAPLE. We also collect a _SMT-LIB_ dataset where there are from 3-var to 9-var instances with numbers \(\{5908,1371,131,123,318,41,24\}\).

**Baselines.** We compare our approach with two kinds of state-of-the-art heuristics, **UP** or **NUP**. For UP, we compare our approaches with _sotd_ and _ndrr_ implemented in the ProjectionCAD package . Besides, we also implement _gmods_ in MAPLE. For NUP, we compare our approaches with _brown_, and _triangular_ implemented in the RegularChains package . _EMLP_ approach is proposed by England  and its implementation only supports 3-var instances. _PVO(brown)_ and _PVO(triangular)_ are _PVO_ approaches combined with EB & NUP heuristics, _brown_ and _triangular_, respectively. The provided implementations  only support 4,5,6-var instances.

**Criterion.** Assume \(\) and \(\) denote the running time and number of cells. \(\) and \(\) denote the average of \(T\) and \(N\). If an instance runs timeout, we count the maximum time (900 seconds) and the maximum number of cells of this instance solved by other heuristics into the calculation. We remove the instances that all heuristics lead to CAD timeout, as such instances can not distinguish the ability of heuristics. \(\) and \(\) denote the variable order prediction time used by heuristics and the number of solved instances within the time limit. For UP heuristics, \(\) also takes _project_ time into consideration. Except for \(\), the criteria are the smaller, the better.

**Experiments.** We conduct three experiments to evaluate our approaches. First of all, we only train the models on the 3-var _random_ dataset. Then, we generalize the trained models on _random_ datasets with up to 9 variables and the _SMT-LIB_ dataset. Finally, we compare GRL-SVO(UP) and GRL-SVO(NUP) and discuss different application scenarios. We list ablation experiments in Appendix C, investigating the effect of features (of the initial embedding), network size, network structure, reward normalization factor \(M\), GNN architecture, and coefficient. We also list additional results in Appendix D, including results under other criteria and performance of fine-tuning.

### Results

**Training GRL-SVO.** Figure 3(a) and Figure 3(b) show the performance during training with the instances in the training set. GRL-SVO outperforms the other heuristics through training and shows a rapid performance improvement. The UP heuristics are better than the NUP heuristics. The inference can be more accurate because the UP heuristics obtain more information than the NUP heuristics. In the beginning, GRL-SVO(NUP) with the random initial parameters is better than GRL-SVO(UP). After training, GRL-SVO(UP) shows better performance.

**Generalization.** We only train on the 3-var dataset and generalize the models to the other datasets. After removing all timeout instances, there are 1876, 651, 416, 354, 349, 409, and 383 instances for the _random_ dataset from 3-var to 9-var; for the _SMT-LIB_ dataset, 1777, 387, 17 instances for 3-var, 4-var to 6-var and 7-var to 9-var, respectively. Table 1 shows the performance of all heuristics, and the best scores are bolded. GRL-SVO(UP) is the only LB approach with UP heuristics, achieving the best performance among most UP and NUP heuristics except for the 4-var category. GRL-SVO(NUP) also achieves competitive performance compared to other NUP heuristics. GRL-SVO also shows

Figure 4: The performance of all heuristics. Figure 3(a) and 3(b) correspond to the training phase, and the horizontal lines represent the timeout instances of corresponding heuristics on the training set. Figure 3(c) is the \(PT\) graph over number of variables.

competitive performance in the real-world dataset, _SMT-LIB_ dataset. Note that although the heuristics _sotd_ perform better than GRL-SVO(UP) on the 4-var instances, they run timeout in most instances from 5-var due to the combinatorial explosion of the number of variable orders as shown in Figure 3(c). The NUP heuristics take a short prediction time, and the polylines in Figure 3(c) overlap. For example, an instance with 7 variables leads to \(7!=5040\) variable orders to project for _sotd_ and _ndrr_.

### Discussion on GRL-SVO(UP/NUP)

As in Table 1, GRL-SVO(UP) performs better in \(\), \(\), \(\) compared to GRL-SVO(NUP). It is understandable because GRL-SVO(UP) receives more real-world information from the projected polynomial set at each step. As in Figure 3(c), GRL-SVO(NUP) is faster than GRL-SVO(UP). The inference time of GRL-SVO(NUP) is almost unchanged with the increase of variables, but there is an obvious increase of GRL-SVO(UP). As the number of variables grows, the time of _project_ and interactions between GRL-SVO(UP) and symbolic computation tools will be critical. It is also the bottleneck of UP heuristics like GRL-SVO(UP), _gmods_, _sotd_, and _ndrr_. Therefore, the application scenarios corresponding to the two models will be different.

Internalizing GRL-SVO(UP) into the CAD process is a promising option. As _project_ is an algorithm component of CAD, internalization will help reuse the results of projection and reduce the interaction time. GRL-SVO(NUP) is cheap and can extract information directly from polynomial representations. It might be applied to other tools that do not use the entire CAD process. As a canonical example, the automated reasoning tools like Z3 , YICES2 , CVC5, utilize _project_ partially only for generating lemmas when solving non-linear arithmetic problems. At the beginning of solving, they also require a fixed variable order. For tasks that are time-critical and do not utilize full CAD in the solving process, GRL-SVO(NUP) seems to be a better option.

## 5 Limitations

Our graph representation cannot embed complete information on polynomials. The associated graph is simple and only shows the relationship between variables. Through selection, we conduct the embedding of graph nodes, but they still ignore plenty of minutiae information, for example, the distribution of coefficients. Besides, the lack of sufficiently large datasets is also a matter of urgency. We can generate large amounts of random data but may lack practical instances for training. Another slight limitation is the prediction time. Python and PyTorch are both heavy techniques. The prediction time of GRL-SVO shown in Figure 3(c) is actually not much different from other heuristics.

   &  &  \\   &  &  &  &  &  \\   & _SST_ &  &  &  &  &  &  &  \\   & _sotd_ & _ST_ & 171.41 & 215.82 & 140.87 & - & - & 94.77 & 97.44 & 146.32 & 124.06 & **76.08** \\  & _AVG.N_ & 2171.74 & 215.82 & 140.88 & - & - & 246.67 & 243.80 & 247.89 & 259.18 & 219.68 \\   & _AVG.T_ & 245.73 & 207.66 & 408 & 392 & 24.03 & **42.58** & **45.83** & 257.53 & 53.58 \\  & _AVG.T_ & 3128.74 & 394.72 & - & 360.33 & 372.71 & 345.47 & **32.12** & 212.66 & 215.48 & 191.45 \\  & _AVG.N_ & 524.95 & 558.50 & 523.83 & 558.46 & 531.10 & **3925.23** & **24.68** & 648.48 & 1746.90 \\   & _AVG.T_ & 245.32 & 204.72 & - & 224.72 & 278.20 & 287 & 27.75 & 155.98 & **34.60** \\  & _AVG.N_ & 2413.70 & 2120.70 & 2148.24 & - & 1185.34 & 246.43 & 245.81 & 287.47 & 835.28 & 236.01 & **207.79** \\  & _AVG.N_ & 2123.70 & 2132.84 & - & 1179.05 & 1255.82 & 1200.49 & 489.48 & 1468.45 & 1866.79 & **974.83** \\   & _AVG.T_ & 175.75 & 149 & - & 180 & 160 & 200 & 5 & 5 & 273 & **306** \\  & _AVG.N_ & 3017.55 & 5251.44 & - & 690.72 & 578.49 & 469.72 & 289.86 & 156.39 & 899.74 & 214.58 \\  & _AVG.N_ & 2860.90 & 2040.23 & - & 2081.98 & 19290.77 & 1930.92 & 2199.23 & 2323.09 & 17561.67 & **18715.29** \\   & _AVG.T_ & 163.18 & 118 & - & - & 15 & 1 & 1 & 270 & **297** \\  & _AVG.N_ & 548.13 & 613.85 & - & - & - & 552.47 & 879.75 & 879.72 & 313.73 & **245.77** \\  & _AVG.N_ & 2779.31 & 2779.75 & - & - & 2700.28 & 3042.546 & 3046.31 & 2445.39 & **2422.39** \\   & _AVG.T_ & 173.33 & 138 & - & - & 172 & 0 & 0 & 310 & **346** \\  & _AVG.T_ & 619.00 & 564.20 & - & - & 597.90 & 900.00 & 900.32 & 324.34 & **232.80** \\  & _AVG.N_ & 30323.26 & 4607.93 & - & - & 38813.98 & 411.21 & 431.21 & 43046.19 & **3886.21** \\   & _AVG.T_ & 151.52 & - & - & - & 150 & 0 & 0 & 296 & **238** \\  & _AVG.T_ & 649.41 & 609.29 & - & - & 625.90 & 900.00 & 900.00 & 9343.11 & **374.78** \\  & _AVG.N_ & 4237.67 & 4083.28 & - & - & 40640.69 & 5271.03 & 3171.03 & 4594.25 & **422.791** \\   & _AVG.T_ & 170.73 & 163.75 & - & - & 176 & 176 & 176 & **1772** & **1772** \\  & _AVG.T_ & 233.38 & 23.68 & 63.09 & - & - & 22.38 & 34.85 & 61.00 & **18.32** & 18.53 \\  & _AVG.N_ & 4409.79 & 5070.66 & 167.07 & - & 4104.04 & **3272.12** & 4307.27 & 3872.72 & 3968.64 \\   & _AVG.T_ & 374.32 & 372 & 372 & 372 & 364 & 356 & 39 & **399** & **379** \\  & _AVG.N_ & 8603.09 & 89.55 & - & 88.32 & 88.91 & 91.17 & 105.18 & 143.22 & **599** & 67.51 \\   & _AVG.T_ & 3696.29 & 2456.08 & - & 2409.99 & 22770.

Conclusion and Future Work

In the paper, we have proposed the first RL-based approach to suggest variable order for cylindrical algebraic decomposition. It has two variants: GRL-SVO(UP) for LB & UP and GRL-SVO(NUP) for LB & NUP. GRL-SVO(UP) can suggest branching variables in the CAD process; GRL-SVO(NUP) can suggest total variable order before the CAD process. Our approaches outperform state-of-the-art learning-based heuristics and are competitive with the best expert-based heuristics. Our RL-based approaches also show a strong learning and generalization ability. Future work is to deploy our approach to practical applications, such as constructing an RL-based package for MAPLE and an algorithm component for automated reasoning tools for non-linear arithmetic solving.