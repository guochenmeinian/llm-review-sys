# Active Sequential Posterior Estimation

for Sample-Efficient Simulation-Based Inference

 Sam Griesemer\({}^{1}\)  Defu Cao\({}^{1}\)  Zijun Cui\({}^{1,2}\)1  Carolina Osorio\({}^{3,4}\)  Yan Liu\({}^{1}\)

\({}^{1}\)USC \({}^{2}\)MSU \({}^{3}\)Google Research \({}^{4}\)HEC Montreal

{samgriesemer,defucao,yanliu.cs}@usc.edu

cuizijun@msu.edu

osorioc@google.com

###### Abstract

Computer simulations have long presented the exciting possibility of scientific insight into complex real-world processes. Despite the power of modern computing, however, it remains challenging to systematically perform inference under simulation models. This has led to the rise of simulation-based inference (SBI), a class of machine learning-enabled techniques for approaching inverse problems with stochastic simulators. Many such methods, however, require large numbers of simulation samples and face difficulty scaling to high-dimensional settings, often making inference prohibitive under resource-intensive simulators. To mitigate these drawbacks, we introduce active sequential neural posterior estimation (ASNPE). ASNPE brings an active learning scheme into the inference loop to estimate the utility of simulation parameter candidates to the underlying probabilistic model. The proposed acquisition scheme is easily integrated into existing posterior estimation pipelines, allowing for improved sample efficiency with low computational overhead. We further demonstrate the effectiveness of the proposed method in the travel demand calibration setting, a high-dimensional inverse problem commonly requiring computationally expensive traffic simulators. Our method outperforms well-tuned benchmarks and state-of-the-art posterior estimation methods on a large-scale real-world traffic network, as well as demonstrates a performance advantage over non-active counterparts on a suite of SBI benchmark environments.

## 1 Introduction

High-fidelity computer simulations have been embraced across countless scientific domains, furthering the ability to understand and predict behaviour in complex real-world systems. Modern computing architectures and flexible programming paradigms have further lowered the barrier to capturing approximate models for scientific study in silico, enabling wide-spread use of computational experiments across disciplines. However, despite the relative ease of capturing real-world generative processes programmatically, the resulting black-box programs are often difficult to leverage for inverse problems. This is a common challenge in practical applications; the simulator is often computationally expensive to evaluate, its implicit likelihood function is generally intractable, and the dimensionality of high-fidelity outputs is typically prohibitive. To address these issues, likelihood-free inference methods have been introduced, operating under the broadly applicable assumption that no tractable likelihood function is available. Early success along this direction was achieved through easy-to-use methods like Approximate Bayesian Computation (ABC) , or extensions of kernel density estimation. The scale of real-world applications demands more flexible and scalable approaches, which has lead to the integration of aptly suited deep learning methods in likelihood-freesettings. Neural network-based methods  have since been proposed, introducing greater flexibility when approximating probabilistic components (e.g., the posterior, likelihood ratio, etc) in the inference pipeline. The use of the term "simulation-based inference" (SBI) has since been colloquially embraced  when referring to this emerging class of techniques.

SBI methods primarily leverage deep learning through their use of neural density estimators (NDE), neural network-based parametrizations of probability density functions. Common choices of NDE in practice include mixture density networks  and normalizing flows , along with popular extensions (e.g., Real NVP , MAE , MAF , etc). Methods also vary in the probabilistic form they elect to approximate; the posterior , the likelihood , and the likelihood ratio  are all common choices for well-established methods.

While many SBI techniques leverage basic principles from active learning (AL), they are mostly established as a helpful heuristic for increased sample efficiency, rather than an explicit optimization over a defined acquisition function. For example, methods like Sequential Neural Posterior Estimation (SNPE)  boost sample efficiency (over non-sequential methods) by iteratively updating a proposal prior \(()\), steering simulator parameters to values expected to be more useful for learning the posterior under observations \(x_{o}\) of interest.

While sequential proposal updates are an effective first-order step to more informative simulation runs, there are many key factors that remain overlooked. For example, the updated proposal does not take into account the current parameters of the NDE itself, and parameter samples in the batch are drawn from the current proposal independently. This fails to fully utilize myopic AL strategies and batch optimization, leading to large amounts of simulation runs with high expected information overlap and wasted computation. To address this issue, we formulate an active learning scheme that (1) selects samples expected to target epistemic uncertainty in the underlying probabilistic model, and (2) makes acquisition evaluation simple and efficient when using any Bayesian NDE.

We demonstrate the effectiveness of our method on the origin-destination (OD) calibration task. OD calibration aims to identify OD matrices that yield simulated traffic metrics that accurately reflect field-observed traffic conditions. It can be seen as a parameter tuning process, akin to model fitting in machine learning. From the machine learning perspective, OD calibration presents challenges due to the requirement of calibrating specific unique samples from observed traffic information, such as link flows, trip speeds, etc.

Our contributions are summarized as follows:

* Active Sequential Neural Posterior Estimation (ASNPE), an SNPE variant that incorporates active acquisition of informative simulation parameters \(\) to the underlying (direct) posterior estimation model, without the use of additional surrogate models. This helps to drive down uncertainty in parameters of the utilized NDE and improve sample efficiency, both of which are particularly important when interfacing with computationally costly simulation-based models.
* An efficient approximation to the proposed acquisition function above, along with a means of training Bayesian flow-based generative models for density estimation during posterior approximation (both with open source implementations3). Leveraging this class of models enables direct uncertainty quantification in the acquisition function, and is more flexible, efficient to train, and scalable to high-dimensional data than many traditional Bayesian model choices (e.g., Gaussian processes). * A Bayesian formulation of the OD calibration problem and coupled statistical framework for performing sequential likelihood-free inference with neural posterior estimation methods. We show ASNPE outperforms baseline methods across a wide variety of simulation scenarios on a large-scale traffic network. We also evaluate ASNPE on three broader SBI benchmark environments and find it acheives a performance advantage over non-active counterparts.

Background

### Neural posterior estimation

Given observational data of interest \(x_{o}\) and a prior \(p()\), we want to carry out statistical inference to approximate the posterior \(p(|x=x_{o})\) under the model \(p(x|)\). We assume \(p(x|)\) is defined implicitly via a simulation-based model, where direct evaluation of \(p(x|)\) is not possible but samples \(x p(x|)\) can be drawn. Conventional Bayesian inference is thus not accessible in this setting, and we instead look to approximate the posterior using \(N\) generated pairs \(\{(_{i},x_{i})\}_{i=1}^{N}\).

Neural Posterior Estimation (NPE) methods attempt to approximate the posterior directly with a neural density estimator \(q_{}(|x)\) trained on samples \(\{(_{i},x_{i})\}_{i=1}^{N}\), where \(_{i} p()\) and \(x_{i} p(x|_{i})\), by minimizing the loss

\[()=_{ p()}_{x p(x| )}[- q_{}(|x)]\]

for learnable parameters \(\). Provided \(q_{}\) is sufficiently expressive, \(q_{}(|x)\) will converge to the true posterior \(p(|x)\) as \(N\).

Sequential Neural Posterior Estimation (SNPE) methods break up the NPE process across several iterations, and can improve sample efficiency by leveraging the fact that \(p(|x=x_{o})\) is often far more narrow than \(p()\). While accurately representing \(p(|x)\) for any \(x\) is ideal (where \(\) is the simulation output space), doing so can require prohibitively large simulation samples, including outputs from parameters with low posterior density under \(x_{o}\). To combat this, SNPE methods draw \(\) expected to be more informative about \(p(|x_{o})\) by using a successively updated proposal distribution \(()\) which approximates \(p(|x=x_{o})\). Training the NDE \(q_{}\) on samples \(()\) when \(\) is not the true prior, however, will cause it to converge instead to the proposal posterior \((|x)=p(|x)()p(x)}{(x)p( )}\), rather than the true posterior (as shown in ). Existing SNPE methods correct for this in different ways: _SNPE-A_ trains \(q_{}(|x)\) to approximate \((|x)\) during each round and employs importance reweighting afterward, _SNPE-B_ directly minimizes an importance weighted loss, and _SNPE-C_ (also known as Automatic Posterior Transformation, or APT) maximizes an estimated proposal posterior that easily transforms to the true posterior.

### Bayesian active learning

Bayesian active learning is a selective data-labeling technique commonly employed in data-scarce learning environments. Active learning assesses the strength of candidate data points using a so-called acquisition function, often capturing some notion of expected utility to the underlying model given the currently available data. Given an acquisition function \(\), computing the next best point to label includes optimization of \(\) over a domain of as yet unlabeled points \(U\): \(x^{*}=*{argmax}_{x U}(x,p(|D))\), where \(x\) are input data points and \(p(|D)\) is the posterior of the Bayesian model parameters \(\) given the current training dataset, i.e., the distribution over parameters after training the model. In modern Bayesian deep learning pipelines, this model is often a Bayesian neural network [15; 21]. Many acquisition functions used in practice are extensions or approximations of expected information gain (EIG) 

\[*{argmax}_{x}(|D)-_{y p(y|x,D)} [|D\{(x,y)\}], \]

where \([|]\) is conditional entropy, and \(y\) are input labels.

Several existing works explore the use of Bayesian optimization (BO) in the likelihood-free inference setting. [18; 22] employ Gaussian processes (GPs) as surrogate models for the discrepancy as a function of \(\), and select parameter candidates by optimizing this surrogate with BO. GPs are also used as a surrogate by  to represent the proposal distribution in MCMC ABC.  further extends these principles to deep Gaussian processes and leverage these models as surrogate likelihoods. In this work, we explicitly avoid the use of likelihood surrogates and aim to leverage only the approximate posterior NDE model, with the express intent of subverting additional computational overhead and enabling the use of powerful NDEs (e.g., flow-based generative models).

### Origin-destination calibration

OD calibration is an important task for transportation agencies and practitioners who develop traffic simulation models of road networks and use them to inform a variety of planning and operational decisions. Calibrating the input parameters of these simulators is an important offline optimization problem that agencies must face on a regular basis (e.g., when new traffic data are made available, when changes to the road network have occurred, etc). These simulators are often computationally expensive to evaluate, however, and highlight the practical importance of developing sample efficient calibration methods.

Existing works primarily approach OD calibration using general-purpose simulation-based optimization (SO) algorithms, such as Simultaneous Perturbation Stochastic Approximation (SPSA) methods [5; 47; 25; 7], genetic algorithms [24; 43; 47], and neural interaction models . Many general-purpose SO algorithms tend to require large numbers of simulation evaluations, which can be computationally costly. To address this issue, recent extensions of SPSA have been proposed [10; 27; 1; 45]. Analytic metamodels have also been considered and shown to reduce the need for large numbers of function evaluations [31; 32; 49; 3].

## 3 Methodology

### Active learning for SNPE

SNPE methods produce iteratively updated proposal priors \(^{(r+1)}() p(|x=x_{o})\) from \(q_{}(|x_{o},D^{(r)})\) at each round \(r\) in the inference process, where \(D^{(r)}\) is the accumulated dataset \(\{(_{i},x_{i})\}_{i=1}^{rB}\) by round \(r\) and \(B\) is the number of newly collected pairs per round. These sequentially updated proposals provide a means of drawing parameter values \(^{(r)}^{(r)}()\) that are increasingly useful (i.e., high likelihood) to the posterior estimate of interest \(p(|x_{o})\). As such, SNPE offers a clear possible benefit for improved sample efficiency over non-sequential NPE, which cannot explicitly sample new values at expected high likelihood regions under \(x_{o}\). Despite this, it's difficult to quantify the value of any particular \(^{(r+1)}()\) and whether it's worth the computational cost to obtain \(x p(x|)\) with respect to its utility to the underlying NDE \(q_{}(|x,D^{(r)})\).

In high-cost simulation environments, we want to take every measure to sample only at highly informative regions of the parameter space to improve our estimate \(q_{}(|x_{o})\) of \(p(|x=x_{o})\). This entails a more principled analysis of candidate simulation parameters \(\) before investing in the simulation run \(x p(x|)\). In an attempt to quantify the prospective impact of any particular \(\) on our posterior estimate, we look to Bayesian active learning, and acquisition functions such as EIG. EIG considers the reduction in uncertainty of model parameters under the inclusion of new data in

Figure 1: **Depiction of the proposed active learning-integrated method.** Demonstrates the high-level ASNPE pipeline. Samples \(_{i}\) are drawn from sequentially updated proposal distributions \(()\), filtered according to the acquisition function \((_{1:N},p(|D))\), and run through the simulator \(p(x|)\) to generate \(B\) pairs \((_{i},x_{i})\) for training the approximate posterior \(q_{}\). The learned posterior is then conditioned by the target observation \(x_{o}\), producing the next round’s proposal \(()=q_{}(|x_{o})\).

expectation over the predictive posterior. Adapting Eq. (1) to our NPE context gives

\[_{}(|D)-_{x p(x|,D)} [|D\{(,x)\}],\]

which seeks to drive down uncertainty in NDE parameters \(\) by optimizing for \(\) with simulation outputs \(x p(x|,D)\) expected to be most informative. Unfortunately, EIG and related approximations require \(p(x|,D)\), which we cannot evaluate nor do we directly approximate in the NPE setting. This makes it considerably more difficult to quantify the utility of candidate \(\) values, as we have no direct means of sampling likely simulation outputs.

### Characterizing posterior uncertainty

Instead of relying on the marginal distribution \(p(x|,D)\), we seek instead to capture uncertainty across different parameterizations of the NDE. Broadly speaking, we want to simulate \(\) expected to be informative to our NDE model, reducing epistemic uncertainty as measured by \(p(|D)\) and further elucidating parameter sets \(\) likely to explain the probabilistic mapping from simulation outputs \(x\) to parameter inputs \(\). Given that \(q_{}\) models this relationship as the conditional distribution \(q_{}(|x)\), we consider the uncertainty over _distributional_ estimates induced by \(p(|D)\). This allows for the targeting of epistemic uncertainty in the NDE model according to how that uncertainty appears across feasible target posterior forms \(q_{}(|x)\). More precisely, for some divergence measure \((||)\), we represent this distributional uncertainty as

\[_{}(x)=_{|D}[(p(|x, D)||p(|x,))], \]

where \(p(|x,)\) is the corrected posterior produced by \(q_{}(|x)\) (see Section 2.1), and \(p(|x,D)\) is the NDE's marginal posterior (under model parameters \(\)) for simulation posterior estimates (parameters \(\)):

\[p(|x,D)=_{}p(|x,)p(|D)d.\]

Intuitively, \(_{}\) captures a notion of dissimilarity between the posterior estimates from different draws of \( p(|D)\). Put another way, \(_{}\) indicates how certain the NDE is in assigning likelihood values across \(\) under a chosen \(x\); a relatively low value would indicate that likely parameter draws \( p(|D)\) produce posterior estimates \(p(|x,)\) that tend to agree with the "marginal" posterior \(p(|x,D)\), for instance. Note that when we let the divergence measure be the KL divergence \(=_{}\), we have \(_{_{}}=[;|x_{o},D]\) (see proof A.1). Computing this exactly is difficult in practice, however, and we therefore seek a practically appropriate approximation below.

### Acquisition of informative parameters

Eq. (2) provides a basis for evaluating uncertainty in an NDE without relying on access to or approximations of the likelihood \(p(x|)\). Given the posterior estimation problem at hand, we're particularly interested in how to select simulation parameters \(\) expected to reduce \(_{}\) at or around \(x_{o}\). Here we take inspiration from , who seek to drive down uncertainty at \(\) with noisy estimates of the log joint probability (albeit in a context where likelihoods \(p(x|)\) are available). While \(_{}\) provides a measure of distributional uncertainty, we can target specific \(\) whose assigned likelihood is widely disagreed upon across draws of \( p(|D)\):

\[^{*}=_{}_{|D}[(p(|x_{o},D)-p (|x_{o},))^{2}]. \]

While optimization of Eq. (3) over all \(\) in the prior support may be ideal, this is computationally infeasible given the posterior estimates from all parameters \(|D\) required in expectation. Additionally, note that Eq. (3) does not explicitly account for relative likelihoods of \(\) under the posterior or available approximations, possibly leading to \(^{*}\) with high uncertainty under \(x_{o}\) but with low-likelihood under \(p(|x_{o})\) in expectation. We account for this explicitly during integration with specific SNPE approaches, as seen in the section below.

### Integration with APT

In order to tractably approximate Eq. (3), we impose two additional restrictions to bring the parameter acquisition into the SNPE loop:

1. Require the NDE be updated according to APT , i.e., trained via maximum likelihood on \(}()=-_{i=1}^{N}_{}(_{i}|x)\), where \[_{}(|x)=q_{}(|x)()}{p( )},\] and by _Proposition 1_ of  ensures \(q_{}(|x) p(|x)\) as \(N\) without requiring post-hoc updates to the NDE's distributional estimate. This allows the model parameter posterior \(p(|D)\) to be used directly in the contexts of Eq. (2) and Eq. (3), whereas otherwise the corrective terms involved would need to be accounted for explicitly.
2. To account for the likelihood of \(\) under the posterior estimate as captured by the proposal prior \(() p(|x=x_{o})\) in a given round of SNPE, we adjust Eq. (3): \[(,p(|D))=()_{|D} [(p(|x_{o},D)-p(|x_{o},))^{2}].\] (4) Further, in practice we approximate this by optimizing Eq. (4) over samples \(^{(r)}()\), straightforwardly integrating the acquisition mechanism into the standard SNPE pipeline. Round-wise proposals \(^{(r)}()=q_{}(|x)\) are set after \(N=rB\) samples are collected (for round \(r\) with \(B\) samples collected per round), and \(q_{}(|x) p(|x)\) as \(N\). All round-wise proposal distributions share the support of the prior \(p()\), which itself is established as having support over the entire parameter domain of interest \(\). Thus, optimizing \(\) over a sample of size \(N\) drawn from a proposal distribution \(^{(r)}()\) at any round \(r\) recovers the true optimum of \(\) as \(N\); each proposal's support connects back to the prior's support, which covers \(\). As a result, at each round a fixed sample size \(N\) drawn from the proposal can be used to approximate the acquisition maxima, while additionally adhering to the round-wise proposal sampling required to ensure \(q_{}(|x) p(|x)\). Refer to Section A.2 for additional discussion on the functional form of the acquisition function.
3. (Optional, depending on model) To approximate the Bayesian model parameter posterior \(p(|D)\), neural network-based NDEs (such as flow-based generative models or mixture density networks) can be trained via MC-dropout [21; 14]. See additional details regarding consistent sampling and log probability evaluation in MAFs under MC dropout in Appendix C.

Altogether, this constitutes the ASNPE method, which is more succinctly described in Algorithm 3.3. See Figure 1 for a visual depiction of this process.

### Bayesian origin-destination calibration

We now position OD calibration as a Bayesian inference problem, with a posterior density of interest to be approximated by SNPE methods. During a time interval of interest \([t_{s},t_{e}]\) on a traffic network \(G\), we consider a single OD matrix \(d=\{d_{z}\}_{z}\), where \(d_{z}\) represents the expected travel demand for the origin-destination pair \(z\). \(\) is the set of OD pair indices, i.e., \(=\{1,2,,\}\), for all pairs of interest on \(G\). OD pairs are typically defined between elements in a fixed set of Traffic Assignment Zones (TAZs) whose size may not be uniform due to variable demand density; see Figure 7 for zones drawn on two candidate networks. Figure 2 loosely depicts the acquisition pipeline for traffic data, corresponding the collection process shown in Figure 1.

Conventionally, OD calibration is formulated as a simulation-based optimization problem over a traffic simulator \((;u_{1},u_{2})\), where \(u_{1},u_{2}\) are vectors of endogenous simulation variables and exogenous simulation parameters, respectively. The goal is to obtain an OD matrix \(d^{*}\) that yields simulation results \(x^{*}=(d^{*};u_{1},u_{2})\) that are sufficiently close to available observational data \(x_{o}\).

While many pre-existing methods adopt a traditional optimization scheme and iteratively produce point estimates for \(d^{*}\), we formulate the calibration problem under the Bayesian paradigm and instead seek a posterior \(p(d|x;)\)

\[p(d|x;)=)}{p(x;)}= )}{ p(x|d)p(d;)d} \]

where \(p(d;)\) represents the prior distribution over OD matrices, often defined around a noisy historical estimate \(\). The posterior estimate under our observation \(p(d|x=x_{o};)\) can then be used to compute different point estimates for \(d^{*}\), used in other downstream tasks as an informative prior, and can represent intrinsic uncertainty in the calibration problem. This formulation achieves parity with existing approaches, where \(\) is otherwise used as a noisy starting point. Additionally, the traffic simulator \(\) is treated as a black-box that implicitly defines the likelihood \(p(x|d)\):

\[p(x|d)= p_{}(x,z|d)dz= p_{}(x,u_{1},u_{2}|d)du_{ 1}du_{2}, \]

i.e., marginalizing over all possible latent trajectories \(z\). As is typical in simulation-based inference settings, this integral is intractable for simulators of sufficient complexity.

## 4 Experimental results

We explore the performance of the proposed ASNPE method in the context of OD calibration on a challenging real-world traffic network. Our goal here is to 1) compare the general purpose utility of our approach in complex settings against tuned benchmark methods, and 2) verify ASNPE's candidacy as a sample efficient posterior estimation tool in high-dimensional, data-scarce settings. These objectives are directly in line with the needs of practitioners, both in the urban mobility community and broadly across scientific disciplines.

### Experimental setup

We conducted a case study on the large-scale regional Munich network seen in . The Munich network includes 5329 configurable origin-destination pairs (constituting simulation input), as

Figure 2: Simple depiction of the data acquisition and simulation process for the OD calibration application. The acquisition step selects parameter candidates (OD matrices) to then be simulated (via SUMO) and produce outputs (network flow observations) that are used to update the approximate posterior model.

    &  &  \\   & & Cong. level A & Cong. level B & Cong. level A & Cong. level B \\   & Prior OD & 0.178 & 0.165 & 0.181 & 0.150 \\   & Setting prior & 0.396 & 0.488 & 0.539 & 0.387 \\   & SPSA & 0.563 \(\) 0.089 & 0.521 \(\) 0.052 & 0.453 \(\) 0.078 & 0.384 \(\) 0.049 \\  \(q=0.3\) & PC-SPSA & 0.193 \(\) 0.063 & 0.185 \(\) 0.097 & **0.159**\(\) 0.036 & **0.159**\(\) 0.046 \\   & MC-ABC & 0.275 \(\) 0.047 & 0.295 \(\) 0.066 & 0.343 \(\) 0.036 & 0.305 \(\) 0.036 \\   & SNPE & 0.201 \(\) 0.085 & 0.167 \(\) 0.092 & 0.187 \(\) 0.059 & 0.314 \(\) 0.025 \\   & (ours) ASNPE & **0.147**\(\) 0.011 & **0.157**\(\) 0.097 & 0.165 \(\) 0.064 & 0.161 \(\) 0.079 \\   & Setting prior & 0.340 & 0.311 & 0.245 & 0.277 \\   & SPSA & 0.316 \(\) 0.074 & 0.342 \(\) 0.045 & 0.258 \(\) 0.061 & 0.189 \(\) 0.025 \\    & PC-SPSA & 0.180 \(\) 0.029 & 0.189 \(\) 0.055 & 0.163 \(\) 0.032 & 0.155 \(\) 0.031 \\    & MC-ABC & 0.143 \(\) 0.034 & 0.190 \(\) 0.036 & 0.169 \(\) 0.023 & 0.140 \(\) 0.010 \\    & SNPE & 0.137 \(\) 0.025 & 0.157 \(\) 0.032 & 0.142 \(\) 0.024 & 0.135 \(\) 0.016 \\   & (ours) ASNPE & **0.130**\(\) 0.024 & **0.148**\(\) 0.034 & **0.138**\(\) 0.025 & **0.132**\(\) 0.016 \\   

Table 1: RMSNE scores on the Munich traffic network, as described in Section 4.1. Note that methods like SPSA (poor convergence aside) can produce RMSNE scores larger than the reported setting prior due to noise in the starting sample. The “setting prior” value is an average RMSNE score over many \(\) draws from the shifted prior. Reported errors are empirical standard deviations computed over the five trial runs.

Figure 3: Plots of the (averaged) calibration horizons for each of the evaluated methods on the _Prior I, Hours 5:00-6:00, Congestion level A_ scenario. **(a)** RMSN(E) scores reached throughout the 128 sample simulation horizon for each evaluated method, averaged over five repeated trials (mean line plotted) and with error bars calculated as bootstrapped 95% confidence intervals. **(b)** The same scores shown in _(a)_, but instead plotted against the wallclock time passed before the score was reached (for each method’s single best run). Note that the full 128-sample method trajectories are included, and the variability in line lengths demonstrates both 1) the impact of NPE-based methods’ ability to run simulations in parallel, and 2) noisiness in simulation runtimes due to the variable inputs explored by each method. See Appendix E for all scenario plots.

well as 507 detector locations (positions of reported output traffic flows), resulting in a highly underdetermined system.

We build and evaluate a number of synthetic demand scenarios, following an established framework for fair evaluation of urban demand calibration methods ([2; 39; 9]). Each of the test demand scenarios are constructed from combinations of the following factors:

**Time interval**: a time interval of interest is specified through which to simulate traffic flows on the network. Prior ODs are chosen to reflect real-world traffic patterns for the affiliated times. We evaluate peak morning demand for hour-long intervals at 5:00am-6:00am and 8:00am-9:00am.

**Congestion level**: within a given time interval, we can further control the level of traffic congestion exposed during the hour. The distribution of frequencies present in the starting ODs plays a critical role in determining route time across the traffic network. Here we define two congestion levels, "A" and "B," to reflect different average frequencies assigned to OD pairs. Here we use a truncated normal distribution (lower bound at 0) to sample OD counts with varying means and variance: **(1)**\((=5,=25)\) for _hours 5:00-6:00, congestion level A_, **(2)**\((=10,=50)\) for _hours 5:00-6:00, congestion level B_, **(3)**\((=25,=50)\) for _hours 8:00-9:00, congestion level A_, **(4)**\((=50,=100)\) for _hours 8:00-9:00, congestion level B_.

**Prior bias and noise**: under each time interval and congestion level, we further perturb the generated OD matrices to represent realistic variance found in real-world sampling of traffic observations. Here we use the following noise model, mirroring that of : \(x_{c}=(r+q)\), where \( N(0,)\). We then formulate two perturbed settings: 1) _Prior I:_\(r=0.6\), \(q=0.3\), and 2) _Prior II:_\(r=0.75\), \(q=0.45\). Prior I constitutes a heavily under-congested estimate with relatively little added noise, while Prior II is less biased from the true OD but noisier. Both priors represent underestimations of the true demand, reflecting the fact that most prior ODs from real-world settings are constructed from historic travel demand observations.

The eight synthetic combinations constitute starting ODs/priors that span a variety of different settings important for real-world urban demand calibration tasks. Each synthetic setting yields a particular prior OD estimate \(\), which is then used to construct a prior \(p(d;)\). A fixed sample is drawn from \(p(d;)\) and passed through the open-source traffic simulator Simulation of Urban MObility (SUMO)  to generate an associated "true" network flow \(x_{o}\).

### Comparison to SOTA Calibration Methods

We evaluate the effectiveness of the proposed solution by comparing against available SOTA benchmarks commonly employed in the OD calibration space: Simultaneous Perturbation Stochastic Approximation (SPSA)  and principal component (PC)-based SPSA, or PC-SPSA . SPSA is a widely employed algorithm for travel demand calibration, and PC-SPSA is an effective extension that optimizes over parameters in a lower-dimensional subspace, as defined by the principal components of computed travel demand history matrix. Both of these methods are conventional optimization-based methods, and do not leverage neural networks. Additionally, these methods in their canonical form cannot be parallelized, requiring serial simulation evaluations across each iteration.

For NPE-based approaches, we evaluate our proposed method ASNPE alongside SNPE-C (or APT) and Approximate Bayesian Computation (ABC)[41; 6]. ABC serves primarily as a less

    & Method & C2ST & MMD & MED-DIST & MEAN-ERR \\  _Bernoulli_ & SNPE-C & 0.749 \(\) 0.017 & 0.210 \(\) 0.024 & **11.454**\(\) 0.255 & 0.188 \(\) 0.117 \\ _GLM_ & ASNPE & **0.725**\(\) 0.012 & **0.146**\(\) 0.057 & 11.993 \(\) 0.172 & **0.150**\(\) 0.085 \\  _SLCP_ & SNPE-C & 0.987 \(\) 0.001 & 0.172 \(\) 0.001 & 16.716 \(\) 1.014 & **0.899**\(\) 0.065 \\ _distractors_ & ASNPE & **0.985**\(\) 0.002 & **0.148**\(\) 0.022 & **16.547**\(\) 0.499 & 0.906 \(\) 0.220 \\  _Gaussian_ & SNPE-C & 0.773 \(\) 0.009 & 0.167 \(\) 0.006 & 1.051 \(\) 0.037 & 0.532 \(\) 0.074 \\ _mixture_ & ASNPE & **0.771**\(\) 0.006 & **0.150**\(\) 0.025 & **1.010**\(\) 0.066 & **0.440**\(\) 0.164 \\   

Table 2: Results comparing SNPE-C and ASNPE for various metrics on the _Bernoulli GLM_, _SLCP distractors_, and _Gaussian mixture_ tasks from . Experimentation details, metrics, and associated plots can be found in Appendix B.

sophisticated baseline that reflects early approaches to likelihood-free inference, and it typically faces difficulty scaling and is far less flexible compared to its NPE counterparts.

For all of the eight scenario priors \(p(d;)\), each calibration method is ran for a maximum of 128 SUMO simulations, seeking to recover \(x_{o}\). The root mean squared normalized error (RMSNE) is recorded for each method's simulation horizon, as used in  (see also Appendix A.3). To account for the stochasticity across evaluations, we report RMSNE averaged of five repeated simulation runs. See Table 1 for reported values for each method across each of the eight synthetic scenarios, as well as paired prior plots in Figure 3.

### Analyzing calibration performance

**ASNPE outperforms all other methods across most explored settings**: as can be seen in Table 1, our method outperforms both the well-tuned PC-SPSA method commonly employed by the urban mobility community, as well as popular simulation-based inference (SBI) methods like SNPE, across almost all of the explored settings. In general, PC-SPSA tends to quickly converge but demonstrates a limited ability to further improve beyond the first 10-20 encountered simulations. Both SBI methods tend to make steady improvements throughout the entire trial, however, albeit often doing so more slowly in the first 20-40 simulations than PC-SPSA. This is primarily due to the limited feedback SNPE/ASNPE receive comparatively, only incorporating new simulation data in batches (in this case, every 32 simulation draws).

Additionally, ASNPE reliably reaches better RMSNE scores than SNPE with fewer simulations, as well as Approximate Bayesian Computation (MC-ABC). This can be seen as early as the first NDE update, before which the two methods encounter the same (seeded) simulation samples. This also empirically supports our central methodological contribution, i.e., optimization over informative simulation parameters can more efficiently improve the accuracy of the inferred posterior estimate.

**ASNPE is outperformed in some cases**: ASNPE is outperformed by PC-SPSA in two of our explored settings (under Prior I, Hours 8:00-9:00). While we wouldn't expect a single method to be the best choice for all variations in such a high-dimensional setting, this particular scenario serves as an opportunity to better understand possible failure modes of the proposed method.

As alluded to above, ASNPE updates its internal model only after a batch of simulation samples is generated, whereas PC-SPSA adjusts its parameters after each simulation run. While generating samples in batches can be beneficial (and is often necessary) for early stability of ASNPE, it can mean informative simulation data is incorporated later in the trial. This explains the occasional gap that opens up between SBI methods and PC-SPSA in the first 30 simulations, only after which is ASNPE/SNPE able to incorporate the samples to improve its posterior estimate. Note, however, that most of the early advantage PC-SPSA may have over ASNPE is dwarfed by the ability to obtain its simulation draws in parallel, whereas PC-SPSA must run simulations serially. This allows for larger, more stable improvements in less time, which can be seen in subplot (b) of Figure 3.

### Performance on common SBI benchmarks

We additionally report results on several common SBI benchmark environments, and compare against the performance of (non-active) SNPE. Numerical results can be found in Table 2, along with plots and more details in Appendix B. These additional results demonstrate the wider applicability of our method beyond the travel demand calibration task.

## 5 Conclusion

In this paper, we introduced Active Sequential Neural Posterior Estimation (ASNPE), an SNPE variant that actively incorporates informative simulation parameters \(\) to drive down epistemic uncertainty in the neural density estimator and improve sample efficiency for high-quality estimates. We evaluate this method on a complex, high-dimensional problem in urban demand calibration, and show it reliably outperforms available benchmark methods across a variety of scenarios with variable bias and noise. We additionally provide results on several common SBI benchmark environments, and find ASNPE is capable of outperforming state-of-the-art SNPE methods on key posterior approximation metrics.

Acknowledgements

This work was supported in part by the National Science Foundation under awards #2226087 and #1837131.