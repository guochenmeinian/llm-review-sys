# TALoS: Enhancing Semantic Scene Completion via Test-time Adaptation on the Line of Sight

Hyun-Kurl Jang

Visual Intelligence Lab.

KAIST

jhg0001@kaist.ac.kr

&Jihun Kim

Visual Intelligence Lab.

KAIST

jihun1998@kaist.ac.kr

&Hyeokjun Kweon

Visual Intelligence Lab.

KAIST

0327june@kaist.ac.kr

&Kuk-Jin Yoon

Visual Intelligence Lab.

KAIST

kjyoon@kaist.ac.kr

denotes equal contribution.

###### Abstract

Semantic Scene Completion (SSC) aims to perform geometric completion and semantic segmentation simultaneously. Despite the promising results achieved by existing studies, the inherently ill-posed nature of the task presents significant challenges in diverse driving scenarios. This paper introduces TALoS, a novel test-time adaptation approach for SSC that excavates the information available in driving environments. Specifically, we focus on that observations made at a certain moment can serve as Ground Truth (GT) for scene completion at another moment. Given the characteristics of the LiDAR sensor, an observation of an object at a certain location confirms both 1) the occupation of that location and 2) the absence of obstacles along the line of sight from the LiDAR to that point. TALoS utilizes these observations to obtain self-supervision about occupancy and emptiness, guiding the model to adapt to the scene in test time. In a similar manner, we aggregate reliable SSC predictions among multiple moments and leverage them as semantic pseudo-GT for adaptation. Further, to leverage future observations that are not accessible at the current time, we present a dual optimization scheme using the model in which the update is delayed until the future observation is available. Evaluations on the SemanticKITTI validation and test sets demonstrate that TALoS significantly improves the performance of the pre-trained SSC model. Our code is available at https://github.com/blue-S31/TALoS.

## 1 Introduction

LiDAR is a predominant 3D sensor in autonomous vehicles, effectively capturing the 3D geometry of the surroundings as a point cloud. However, LiDAR inherently records the surface of objects, leaving the areas behind initial contact points empty. Therefore, it is crucial for safety and driving planning to predict the state of these hidden regions using only the limited information available. Addressing these challenges, Semantic Scene Completion (SSC) has emerged as a pivotal research topic, enabling simultaneous geometric completion and semantic segmentation of the surroundings.

Existing SSC studies have focused on tackling both tasks [1; 2; 3; 4; 5; 6; 7; 8; 9], mainly from an architectural perspective. By amalgamating the models specialized for each task, these approaches have shown promising results over the last few years. Nevertheless, the nature of the completiontask--filling in the unseen parts from the given observation--heavily relies on the prior structural distribution learned from the training dataset. Therefore, in our view, the classical SSC paradigm is inevitably vulnerable to handling the diverse scene structures encountered in driving scenarios.

As a remedy, this paper pioneers a novel SSC approach based on Test-time Adaptation (TTA), which adjusts a pre-trained model to adapt to each test environment. Due to the absence of ground truths (GTs) during test time, the existing TTA studies for various fields have endeavored to design optimization goals, like meta-learning or auxiliary tasks [10; 11; 12; 13; 14]. Instead, we focus on the driving scenarios assumed by SSC, excavating the information helpful for adapting the model to the scene in test time.

Our main idea is simple yet effective: **an observation made at one moment could serve as supervision for the SSC prediction at another moment**. While traveling through an environment, an autonomous vehicle can continuously observe the overall scene structures, including objects that were previously occluded (or will be occluded later), which are concrete guidances for the adaptation of scene completion. Given the characteristics of the LiDAR sensor, an observation of a point at a specific spatial location at a specific moment confirms not only the occupation at that location itself but also the absence of obstacles along the line of sight from the sensor to that location.

The proposed method, named **Test-time Adaptation via Line of Sight (TALoS)**, is designed to explicitly leverage these characteristics, obtaining self-supervision for geometric completion. Additionally, we extend the TALoS framework for semantic recognition, another key goal of SSC, by collecting the reliable regions only among the semantic segmentation results predicted at each moment. Further, to leverage valuable future information that is not accessible at the time of the current update, we devise a novel dual optimization scheme involving the model gradually updating across the temporal dimension. This enables the model to continuously adapt to the surroundings at test time without any manual guidance, ultimately achieving better SSC performance.

We verify the superiority of TALoS on the SemanticKITTI  benchmark. The results strongly confirm that TALoS enhances not only geometric completion but also semantic segmentation performance by large margins. With extensive experiments, including ablation studies, we analyze the working logic of TALoS in detail and present its potential as a viable solution for practical SSC.

## 2 Related Works

### Semantic scene completion

Starting from SSCNet , semantic scene completion task has been extensively studied [16; 2; 3; 4; 5; 6; 7; 8; 9; 17; 18; 19; 20; 21; 22; 23]. In SSC using LiDAR, as both tasks of geometric completion and semantic understanding should be achieved simultaneously, the existing studies have mainly presented architectural approaches. For example, LMSC  and UUD  utilize UNet-based structures with multi-scale connections. JS3C-Net  and SSA-SC  propose architectures consisting of semantic segmentation and completion networks to utilize them complementarily. Although these approaches show promise, handling the diversities inherent in outdoor scenes remains a challenging problem. In this light, we would like to introduce test-time adaptation to the field of semantic scene completion.

Notably, SCPNet  proposes to use distillation during the training phase, transferring the knowledge from the model using multiple scans to the model using a single scan. Although this approach also aims to use information from various moments, the proposed TALoS is distinct as it leverages such information online, adapting the model to the diverse driving sequence. Also, the recently published OccFiner  is noteworthy, as it aims to enhance the already existing SSC model. However, OccFiner is a post-processing method that refines the results of the pre-trained model, performing in an offline manner, unlike our online TTA-based approach.

### Test-time adaptation

Test-time Adaptation (TTA) aims to adapt a pre-trained model to target data in test time, without access to the source domain data used for training. One widely used method involves attaching additional self-supervised learning branches to the model [10; 11; 12]. In point cloud TTAs, using auxiliary tasks such as point cloud reconstruction [13; 14] are actively studied. However, these approaches require the model to be trained with the additional branches, primarily in the training stage on the source dataset.

To relieve the requirements on the training stage, various online optimization goals have been explored, such as information maximization [25; 26; 27] and pseudo labeling [26; 28; 29; 30] schemes. Similar approaches have also been proposed for the point cloud, as in [31; 32], using pseudo labeling.

Unfortunately, despite the natural fit between these TTA approaches and the goal of SSC, which involves completing diverse driving environments, the use of TTA has been scarcely explored in the SSC field. Against this background, we pioneer the TTA-based SSC method, especially focusing on excavating the information from the point clouds consecutively observed at various moments.

## 3 Method

### Problem definition

This section begins by defining the formulation of our approach and the notations used throughout the paper. The Semantic Scene Completion (SSC) task aims to learn a mapping function from an input point cloud to the completed voxel representation. We formally denote the input point cloud \(^{N 3}\) as a set of points, where each point represents its XYZ coordinate. Following the conventional SSC studies, the completion result is denoted as \(^{L W H}\). Here, \(L,W,H\) are the dimensions of the voxel grid, and \(=\{0,1,,C\}\) is a set of class indices indicating whether a voxel is empty (\(0\)) or belongs to a specific class (\(1,,C\)).

As our approach is based on TTA, we assume the existence of a pre-trained SSC model \(\) as follows:

\[=(),\] (1)

where \(^{(C+1) L W H}\) is the probability of each voxel belonging to each class. The final class prediction \(}\) can be obtained by applying an argmax function on \(\). In this context, the goal of TALoS is to adjust the pre-trained model to adapt to an arbitrary test sample \(\) by optimizing the parameters, making them more suitable. Here, note that the proposed approach does not have explicit requirements on \(\), such as the architectures or pre-training policies.

### Test-time Adaptation via Line of Sight (TALoS)

The proposed TALoS targets a realistic application of the pre-trained SSC model, assuming an autonomous vehicle drives through arbitrary environments in test time. In this scenario, we suppose the point clouds captured by LiDAR are continuously provided as time proceeds, and accordingly, the model should perform SSC for each given point cloud instantly. We denote the input sequence of point clouds as \(\{_{i}\}\), where \(i=\{1,\}\) indicates the moment when the point cloud is captured.

The main idea behind TALoS is that for guiding the model prediction of a certain moment (let \(i\)), the observation made at another moment (let \(j\)) can serve as supervision. However, as the ego-vehicle moves as time proceeds, the input point clouds captured at the two different moments, _i.e._, \(_{i}\) and \(_{j}\), are on different LiDAR coordinates. To handle this, we use a transformation matrix \(_{j i}\) between two coordinates to transform the \(j\)th point cloud \(_{j}\) with respect to the \(i\)th coordinate system, by

\[_{j i}=_{j i}_{j},\] (2)

where \(_{j i}\) is the transformed point cloud.

Subsequently, we exploit \(_{j i}\) to obtain a binary self-supervision for geometric completion, indicating whether a voxel is empty or occupied. We implement this process as shown in Fig. 1. For voxelization, we first define a voxel grid of a pre-defined size (\(L W H\)), initialized with an ignore index (\(255\)). Then, using \(_{j i}\), we set the value of voxels containing at least one point to 1 (green color in Fig. 1), while keeping the other voxels as \(255\). Here, note that we discard the points of the non-static classes (_e.g._, car), as such object can change their location between \(i\)th and \(j\)th observation. For this rejection, we use \(_{j}\), the model prediction at \(j\)th moment. The resulting binary mask indicates which voxels are occupied at the \(j\)th moment with respect to the \(i\)th coordinate.

Additionally, we use the Line of Sight (LoS), an idea utilized in various fields [33; 34; 35], to further identify which voxels should not be occupied. Considering LiDAR's characteristics, the space between the LiDAR and the voxels filled with 1 should be empty. To check which voxels are crossed by the LoS, we employ Bresenham's algorithm . For this process, we use the LiDAR position at the \(j\)th moment converted to the \(i\)th coordinate system, not the \(i\)th LiDAR position. Finally, we set the value of the identified voxels to 0 (red color in Fig. 1), indicating that the voxels should be empty.

The obtained \(_{j i}^{comp}\{0,1,255\}^{L W H}\) then serves as supervision for \(_{i}\), the \(i\)th prediction. Here, \(_{i}\) is obtained by the pre-trained SSC model \(\) as follows:

\[_{i}=(_{i}).\] (3)

Since \(_{i}\) is the prediction for all the classes, including the empty class, we convert it into the binary prediction for completion, denoted as \(_{i}^{comp}^{2 L W H}\). Here, the first element of \(_{i}^{comp}\) is simply \(_{i}^{0}\), and the second one is \(_{c=1,,C}_{i}^{c}\), the maximum value among the scores of the non-empty classes. Here, \(_{i}^{c}\) represents the predicted probability of the voxels belonging to \(c\)th class at \(i\)th moment.

Finally, the loss function using the binary completion map is as

\[_{j i}^{comp}(_{i})=_{ce}( _{i}^{comp},_{j i}^{comp})+_{lovasz}( _{i}^{comp},_{j i}^{comp}),\] (4)

where \(_{ce}\) and \(_{lovasz}\) are cross-entropy loss and lovasz-softmax loss , respectively.

### Extension for semantic perception

In the previous section, we described a method that leverages an observation made in one moment (\(j\)) to obtain the binary occupancy map of another moment (\(i\)). As the method mainly focuses on enhancing the model's capability of understanding the test-time scene structure, _i.e._, scene completion, this section further extends our approach to address the semantic perception of surroundings, another key goal of SSC. Specifically, we carefully identify the reliable regions from the prediction of the pre-trained model at each moment, and then build a consensus among these predictions across various moments.

To achieve this, we first define a metric similar to [25; 26; 27], based on Shannon entropy \(\), as follows:

\[=()=-_{c=0}^{C}^{c} ^{c},\] (5)

where \(^{L W H}\) is the measured reliability. As reported in conventional works based on confidence-based self-supervision, we also confirmed a high positive correlation between the reliability \(\) and the actual accuracy of voxel-wise classification, as in Fig. 2 left.

To identify the confident regions from the model predictions, we simply threshold the measured reliability by a pre-defined value \(\) (0.75 in ours) as follows:

\[(x,y,z)=*{argmax}_{c}^{c}(x,y, z)&(x,y,z)>\\ 255&,\] (6)

Figure 1: **Left**: Visualization of constructing a binary map \(_{j i}^{comp}\) from the transformed point cloud \(_{j i}\). Although we represent our process using a 2D grid for intuitive visualization, note that the real process is performed on a 3D voxel. **Right**: The real example of the binary map projected on 2D.

where \((x,y,z)\) denotes the voxel coordinate. Here, \((\{255\})^{L W H}\) is the reliable self-supervision, which can function as pseudo-GT for semantic segmentation.

Following the above process, we first acquire \(_{j}\) using \(j\)th model prediction. Subsequently, we project its coordinate to \(i\)th coordinate, similar to Equ. (2). After obtaining the projected pseudo-GT, denoted as \(_{j i}\), we aggregate it with \(_{i}\), the pseudo-GT obtained at the current moment \(i\). In detail, we replace only the unconfident voxels in \(_{i}\) (indexed as \(255\)) with the corresponding voxels of \(_{j i}\). Meanwhile, if the classes predicted by \(_{i}\) and \(_{j i}\) differ on certain voxels and both are confidently predicted, we conservatively drop those voxels as \(255\). As depicted in the colored boxes in Fig. 2 right, this aggregation helps our framework to build a consensus among the semantic perceptions performed at various moments, significantly enhancing the quality of pseudo-GT from the perspective of SSC.

We denote the result of aggregation as \(_{j i}^{sem}(\{255\})^{L W H}\). Since \(_{j i}^{sem}\) contains semantic information about all the classes, we can utilize it as direct pseudo-GT for guiding \(_{i}\). Accordingly, the loss function is defined as:

\[_{j i}^{sem}(_{i})=_{ce}(_{i}, _{j i}^{sem})+_{lovasz}(_{i},_{j  i}^{sem}),\] (7)

where the notations are similar to those of Equ. (4).

### Dual optimization scheme for gradual adaptation

The previous sections introduced how TALoS guides the prediction of a pre-trained SSC model at a certain moment (\(i\)), leveraging observations made at another moment (\(j\)). From a methodological perspective, the remaining step is to consider how to effectively adapt the model by selecting the appropriate moments.

Essentially, we cannot observe the future. Therefore, assuming TTA in real driving scenarios, we can only use past observations when updating the model at the current moment, which implies \(i>j\). However, from the perspective of the SSC task, the main region of interest is intuitively the forward driving direction of the autonomous vehicle. This implies that guidance from future observations can be more important and valuable than guidance from past observations.

So, how can we leverage future information without actually observing it at the current moment? Our key idea is to hold the model and its prediction at the current moment without updating and **delay the update until future observations become available**.

We develop this idea as in Fig. 3. In detail, our approach involves two models of \(^{M}\) and \(^{G}\). The goal of \(^{M}\) is an instant adaptation on the sample of the current moment. Therefore, we initialize \(^{M}\) every moment with the pre-trained model and discard it at the end of the moment. Here, \(^{M}\) can be instantly updated at the moment \(i\), using the past information already observed at \(j\)th moment. The loss function for \(^{M}\) is defined as:

\[_{j i}^{M}=_{j i}^{comp}(_{i}^{M})+ _{j i}^{sem}(_{i}^{M}),\] (8)

where \(_{i}^{M}\) is the output of \(^{M}\) at \(i\)th moment.

Figure 2: **Left**: Verification of the reliability metric. The voxels having higher reliability show higher semantic completion accuracy. **Right**: Examples of pseudo-GT (pGT) construction. The blue box depicts the successful rejection of misprediction using reliability, while the red boxes show the benefit of using the prediction of another moment, providing more completed pGT.

However, as aforementioned, we want to also leverage future information at \(k\)th moment, which is not available yet. For this, we define \(^{G}\), which aims to gradually learn the overall scene distribution. Therefore, \(^{G}\) is initialized only at the first step and continuously used for prediction. As in Fig. 3, the inference of \(^{G}\) for \(_{i}\) is instantly done and is used for the final output of the \(i\)th moment. On the other hand, the update of \(^{G}\) should stand by, until \(_{k}\) is available. In other words, once the model \(^{G}\) arrives at \(k\)th moment (which was future at the time of prediction), the update is performed. The loss function for \(^{G}\) is defined as:

\[^{G}_{k i}=^{comp}_{k i}(^{G}_{i})+ ^{sem}_{k i}(^{G}_{i}),\] (9)

where \(^{G}_{i}\) is the output of \(^{G}\) at \(i\)th moment.

This update cannot directly affect the prediction of \(^{G}\) made at \(i\)th moment, as it is already over in the past from the perspective of \(k\)th moment when the update occurred. However, this continuous accumulation of future information gradually enhances the model, allowing it to better learn the overall scene structure as time progresses. We provide a detailed illustration in Algorithm 1.

In summary, the proposed TALoS framework involves two models, moment-wisely adapted \(^{M}\) and gradually adapted \(^{G}\). To obtain the final prediction \(^{talos}_{i}\) of \(i\)th moment, we individually run \(^{M}\) and \(^{G}\) using \(_{i}\) as an input. Both results \(^{M}_{i}\) and \(^{G}_{i}\) are unified into a single voxel prediction. Here, we use \(^{M}_{i}\) as a base, while trusting \(^{G}_{i}\) only for the voxels predicted as static categories (such as roads or buildings) by \(^{G}_{i}\). The rationale behind this strategy is that continual adaptation makes \(^{G}\) gradually adapt to the overall sequence, leading to a better understanding of the distribution of static objects. We empirically found that the continuous adaptation is more facilitated for the static pattern than the movable objects having diverse distribution.

## 4 Experiments

### Settings

Datasets & Metrics.We primarily experiment on SemanticKITTI , the standard benchmark for SSC, comprising 22 LiDAR sequences. Sequences 00 to 10 are used for pre-training SSC models, except for 08, which is employed as a validation set. For testing, we use sequences 11 to 21. Additionally, we verify TALoS on cross-dataset evaluation from SemanticKITTI to SemanticPOSS . From the 6 sequences of SemanticPOSS, we utilize only the validation sequence (02). For more details, please refer to the supplementary material. For evaluation, we employ intersection over union (IoU), a standard metric for semantic segmentation. We report both the completion IoU (cIoU) for binary occupancy prediction and the mean IoU (mIoU) for all classes.

Figure 3: Conceptual visualization of the dual optimization scheme. \(^{M}\) is instantly updated at moment \(i\), using the past information provided from \(j\)th moment. On the other hand, the update of \(^{G}\) using \(i\)th prediction is delayed until \(k\)th moment, when the future information becomes available. We unify the predictions of the models, \(^{M}_{i}\) and \(^{G}_{i}\), to get the final prediction \(^{talos}_{i}\). The red dashed line denotes the back-propagation.

Implementation.We employ the officially provided SCPNet , which is pre-trained on the SemanticKITTI  train set, as our baseline. To apply TALoS in test time, we only update the last few layers of SCPNet. Additionally, to prevent SCPNet's architecture from automatically making the voxels far from existing points empty, we use a 3D convolution layer to expand the region of sparse tensor computation. This ensures that distant voxels are properly involved in the test-time adaptation. For optimization, we use Adam optimizers , where the learning rates are set to 3e-4 and 3e-5 for \(^{M}\) and \(^{G}\), respectively. For more details, refer to Section A.

### Ablation studies

We conducted ablation studies to evaluate the effectiveness of each component of TALoS. The configurations and results of the ablation studies are demonstrated in Table 1. First, we verify the effectiveness of the loss functions we devised. The result of Exp A confirms that minimizing \(^{comp}\) indeed increases both cIoU and mIoU performance over the baseline, helping the model adapt to each test sample. In addition, Exp B shows that using \(^{sem}\) is also effective, especially for semantic perception, resulting in better mIoU performance. Further, Exp C using both losses achieves even higher performance, demonstrating the effectiveness of the proposed TALoS.

Additionally, we check the validity of the dual optimization scheme, ablating either \(^{M}\) or \(^{G}\). The results of Exp C and Exp D show that the use of moment-wise adaptation and gradual adaptation are both effective. Further, Exp E confirms that our dual scheme effectively unifies both gains into our TALoS framework, significantly outperforming the baseline on both cIoU and mIoU.

### Results on SemanticKITTI

Table 2 provides the performance of existing SSC methods on the SemanticKITTI test set. Compared with SCPNet, which serves as our baseline, the proposed TALoS achieves significantly higher performance on both cIoU and mIoU. Considering that SCPNet also involves knowledge distillation

using future frames during training, this performance gain confirms that our TTA-based method is more effective for leveraging future information. Figure 4 provides a qualitative comparison between the baseline and ours, demonstrating the advantages of TALoS.

Additionally, it is noteworthy to mention the difference between ours and OccFiner . OccFiner is designed to refine the results of existing SSC methods in an offline manner. It first generates predictions for a LiDAR sequence using an SSC method and then fuses these predictions post-driving to refine the results. In contrast, TALoS aims to perform test-time adaptation instantly in an online manner. We assume the sequential sensing of LiDAR data during driving, and TALoS gradually enhances the model as the test-time adaptation progresses. As both methods have advantages in their respective practical settings, we simply mention it here, rather than comparing them in Table 2.

### Comparisons with the existing TTA methods

To demonstrate the benefit of our approach from the perspective of TTA, we integrated existing TTA studies into our framework and tested them. The results can be found in Table 3. First, we performed optimization via entropy minimization, as in TENT , instead of minimizing the proposed loss functions. For this experiment, we exclusively use \(^{M}\) for clear comparison. This setting achieved 37.92% and 49.86% in mIoU and cloU, respectively. Note that cloU of this setting is slightly lower than that of the baseline. Further, the setting of Exp C in Table 1, which also uses \(^{M}\) only, still outperforms TENT in both metrics. These highlight the effectiveness of our losses, which utilize observations made at various moments.

To further clarify the superiority of our dual optimization scheme, we also implemented CoTTA , a continuous TTA approach based on the widely used student-teacher scheme. We update both

   &  &  &  \\   & **COMP** & **SEM** & **MOMENT** & **GRADUAL** & **mIoU** & **eloU** \\  Baseline & & & & & 37.56 & 50.24 \\  A & ✓ & & ✓ & & 37.97 & 52.81 \\  B & & ✓ & ✓ & & 38.35 & 52.47 \\  C & ✓ & ✓ & ✓ & & 38.38 & 52.95 \\  D & ✓ & ✓ & & ✓ & 38.81 & 55.94 \\  E (Ours) & ✓ & ✓ & ✓ & ✓ & **39.29** & **56.09** \\  

Table 1: The results of ablation studies for the proposed TALoS framework, conducted on SemanticKITTI val set. COMP and SEM denote the use of loss function defined in Equ. (4) and Equ. (7), respectively. Meanwhile, MOMENT and GRADUAL represent the use of \(^{M}\) and \(^{G}\) for the optimization scheme in Sec. 3.4, respectively. All metrics are in %. Best results are in **bold**.

Figure 4: Qualitative comparisons between baseline (SCPNet) and ours TALoS on SemanticKITTI val set. The highlighted regions depict the improvements achieved by TALoS, better completing the scene while also recovering the mispredictions.

[MISSING_PAGE_FAIL:9]

[MISSING_PAGE_FAIL:10]