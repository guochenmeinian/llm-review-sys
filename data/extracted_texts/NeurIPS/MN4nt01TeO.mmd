# Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences

Saiyue Lyu\({}^{1}\), Shadab Shaikh\({}^{1*}\), Frederick Shpilevskiy\({}^{1*}\), Evan Shelhamer\({}^{2}\), Mathias Lecuyer\({}^{1}\)

\({}^{1}\)University of British Columbia, \({}^{2}\)Google DeepMind

{saiyuel, shadabs3, fshpil}@cs.ubc.ca, shelhamer@deepmind.com, mathias.lecuyer@ubc.ca

\({}^{*}\)equal contribution

###### Abstract

We propose Adaptive Randomized Smoothing (ARS) to certify the predictions of our test-time adaptive models against adversarial examples. ARS extends the analysis of randomized smoothing using \(f\)-Differential Privacy to certify the adaptive composition of multiple steps. For the first time, our theory covers the sound adaptive composition of general and high-dimensional functions of noisy inputs. We instantiate ARS on deep image classification to certify predictions against adversarial examples of bounded \(L_{}\) norm. In the \(L_{}\) threat model, ARS enables flexible adaptation through high-dimensional input-dependent masking. We design adaptivity benchmarks, based on CIFAR-10 and CelebA, and show that ARS improves standard test accuracy by \(1\) to \(15\%\) points. On ImageNet, ARS improves certified test accuracy by up to \(1.6\%\) points over standard RS without adaptivity. Our code is available at https://github.com/ubc-systopia/adaptive-randomized-smoothing.

## 1 Introduction

Despite impressive accuracy, deep learning models still show a worrying susceptibility to adversarial attacks. Such attacks have been shown for a large number of tasks and models (Costa et al., 2023; Chakraborty et al., 2018), including areas where security and safety are critical such as fraud detection (Pumsirirat and Liu, 2018) or autonomous driving (Cao et al., 2021).

Several rigorous defences have been proposed to certify robustness. Randomized Smoothing (RS) (Lecuyer et al., 2019; Cohen et al., 2019) does so by averaging predictions over noisy versions of the input at test time, and as such can scale to large deep learning models. However, RS has its limitations: it is inflexible and either degrades accuracy or only certifies against small attacks.

To address these shortcomings and improve robustness, there has been a recent push to develop defences that adapt to inputs at test time Croce et al. (2022), including for RS (Alfarra et al., 2022; Sukenik et al., 2021; Hong et al., 2022). Most such adaptive defences are heuristic, unproven, and subject to improved attacks (Croce et al., 2022; Alfarra et al., 2022; Hong et al., 2022), running the risk of reverting to a hopeless cat and mouse game with attackers (Athalye et al., 2018; Tramer et al., 2020), or only provide limited adaptivity (Sukenik et al., 2021; Hong et al., 2022) and gain (SS5).

We (re)connect RS to Differential Privacy (DP), after its abandonment for a tighter analysis via hypothesis testing (Cohen et al., 2019), and introduce **Adaptive Randomized Smoothing (ARS)** to provide test-time adaptivity while preserving rigorous bounds. Specifically, we analyze RS through the lens of \(f\)-Differential Privacy (\(f\)-DP), and use this connection to leverage a key strength of DP: the end-to-end analysis of multi-step adaptive computation using composition results (SS2).

We use ARS to design two-step defence against \(L_{}\) adversaries on image classification (Figure 1), which is a challenging setting for RS Blum et al. (2020). The first step computes an input mask thatfocuses on task-relevant information. This reduces the dimension of the input, which is then passed to the second step for prediction. Thanks to this adaptive dimension reduction, the second step makes its prediction on a less noisy image, improving the performance and certification radius (SS3).

We evaluate our adaptive randomized smoothing method in three settings (SS4). For image classification, we first design a challenging benchmark based on CIFAR-10, and we show that ARS can improve accuracy by up to \(15\%\). For spatially-localized face attribute classification on the CelebA dataset, we show that ARS improves accuracy by up to \(7.7\%\). For large-scale image classification on ImageNet, ARS maintains accuracy and improves certified accuracy by up to \(1.6\%\).

## 2 Theory for Adaptivity via Differential Privacy

After introducing the necessary background and known results on RS and DP (SS2.1), we reconnect RS to its DP roots by showing that the tight analysis of Cohen et al. (2019) can be seen as PixelDP (Lecuyer et al., 2019) using \(f\)-Differential Privacy (Dong et al., 2019, 2022), a hypothesis testing formulation of DP (SS2.2). This connection lets us leverage composition results for \(f\)-DP to analyze multi-step approaches for provable robustness to adversarial examples, which we name Adaptive Randomized Smoothing (ARS) (SS2.3). We leverage ARS to design and analyze a two-step defence against \(L_{}\)-bounded adversaries (SS2.4), which we then instantiate as a deep network (SS3).

### Related Work: Adversarial Robustness, Randomized Smoothing, and Differential Privacy

**Adversarial Examples**(Szegedy et al., 2014): Consider a classifier \(g:\), and input \(X\). An adversarial example of radius \(r\) in the \(L_{p}\) threat model, for model \(g\) on input \(X\), is an input \(X+e\) such that \(g(X+e) g(X)\), where \(e B_{p}(r)\), where \(B_{p}(r)\{x^{d}:\|x\|_{p} r\}\) is the \(L_{p}\) ball of radius \(r\). These inputs or attacks are made against classifiers at test time. For more on the active topics of attack and defence, we refer to surveys (Li et al., 2023; Costa et al., 2023; Chakraborty et al., 2018) on current attacks and provable defences. In general, provable defences do not focus on the largest-scale highest-accuracy classifiers, with the notable exception of randomized smoothing.

**Randomized Smoothing (RS)**(Lecuyer et al., 2019; Cohen et al., 2019) is a scalable approach to certifying model predictions against \(L_{2}\)-norm adversaries. Specifically, it certifies robustness to _any_ attack \( B_{2}(r_{X})\). The algorithm randomizes a base model \(g\) by adding spherical Gaussian noise to its input, and produces a smoothed classifier that returns the class with highest expectation over the noise: \(y_{+}*{arg\,max}_{y}_{z (0,^{2}l_{d})}g(X+z)=y\). The tightest analysis from Cohen et al. (2019) uses hypothesis testing theory to show that, with \(},}\) such that \((g(X+z)=y_{+})}}_{ } y_{+}}(g(X+z)=y_{-})\), the certificate size \(r_{X}\) for prediction \(y_{+}\) is:

\[r_{X}=^{-1}(})-^{-1}( {p_{-}}),\] (1)

where \(^{-1}\) is the inverse standard Gaussian CDF, \(}\) lower-bounds the probability of \(g(X+z)=y_{+}\) (the most probable class), and \(}\) upper-bounds the probability of other classes.

Figure 1: Two-step ARS for \(L_{}\)-bounded attacks. Step \(_{1}\) adds noise to input \(X\) and post-processes the result into a mask \(w(m_{1})\). Step \(_{2}\) takes masked input \(w(m_{1}) X\) and adds noise to get \(m_{2}\). Base classifier \(g\) post-processes a weighted average of \(m_{1},m_{2}\) to output a label. RS reduces to \(_{2}=\) and \(w(.)=1\) (no \(_{1}\)).

While sound, RS is static during testing even though attacks may adapt. Recent work aims to make RS adapt at test time (Sukenik et al., 2021; Alfarra et al., 2022; Hong et al., 2022). While pioneering, these works are restricted in either their soundness or their degree of adaptation and resulting improvement. Sukenik et al. (2021) soundly adapt the variance for RS by the distance between test and train inputs. However, this only provides minimal adaptivity, with only minor improvement to certification. Alfarra et al. (2022) adapt the variance for RS to each test input, but the analysis is not end-to-end, and hence not sound (Sukenik et al., 2021) (except for their memory-based edition, but this requires storage of all examples). UniCR (Hong et al., 2022) adapts the noise distribution for RS, primarily to the data distribution during training, and optionally to input during testing. The train-time adaptation is sound, but the test-time adaptation is not due to the same issue raised by Sukenik et al. (2021). We propose ARS to advance certified test-time adaptivity: our approach is sound and high-dimensional to flexibly adapt the computation of later steps conditioned on earlier steps by differential privacy theory.

**Differential Privacy (DP)** is a rigorous notion of privacy. A randomized mechanism \(\) is \((,)\)-DP if, for any neighbouring inputs \(X\) and \(X^{}\), and any subset of possible outputs \(()\), \(((X)) e^{}((X^{}))+\). Following Lecuyer et al. (2019), we define neighbouring based on \(L_{p}\) norms: \(X\) and \(X^{}\) in \(^{d}\) are \(L_{p}\) neighbours at radius \(r\) if \(X-X^{} B_{p}(r)\).

RS was initially analyzed using \((,)\)-Differential Privacy (Lecuyer et al., 2019). Intuitively, the randomized classifier \((X) g(X+z),\ z(0,^{2}^{d})\) acts as a privacy preserving mechanism (the Gaussian mechanism) that provably "hides" small variations in \(X\). This privacy guarantee yields a robustness certificate for the expected predictions.

\(f\)**-DP**(Dong et al., 2019) is a notion of privacy that extends \((,)\)-DP, and defines privacy as a bound on the power of hypothesis tests. Appendix A provides more details on \(f\)-DP. The main result we leverage is Theorem 2.7 of Dong et al. (2022) that for a Gaussian mechanism \((X)=(X)+z\), \(z(0,}{^{2}})\), such that for any neighbouring \(X,X^{}\), \((X)-(X^{}) B_{2}(r)\) (i.e., the \(L_{2}\) sensitivity of \(\) is \(r\)), we have that \(\) is \(G_{}\)-DP with the function \(G_{}\) defined as:

\[G_{}()=^{-1}(1-)-,\ \ .\] (2)

We leverage two key properties of \(f\)-DP. First, \(f\)-DP is resilient to post-processing. That is, if mechanism \(\) is \(f\)-DP, proc \(\)\(\) is also \(f\)-DP. Second, \(f\)-DP is closed under adaptive composition. We refer to SS3 in Dong et al. (2022) for the precise definition and use their Corollary 3.3: the adaptive composition of two Gaussian mechanisms \(G_{_{1}}\)-DP and \(G_{_{2}}\)-DP is itself \(G_{}\)-DP with

\[=^{2}+_{2}^{2}}.\] (3)

\(f\)-DP is distinct from the \(f\)-divergence from information theory. Dvijotham et al. (2020) use \(f\)-divergence bounds between the noise distribution centred on the original input and centred on any perturbed input. This improves RS by broadening the noise distributions and norm-bounds on the adversary that RS can support. In contrast we focus on \(f\)-DP, which captures enough information to reconstruct any divergence by post-processing (Proposition B.1. in Dong et al. (2019)). Our main objective is different: we leverage \(f\)-DP _composition_ properties to enable multi-step deep learning architectures that adapt to the input at test time with robustness guarantees.

### Randomized Smoothing from \(f\)-Dp

We reconnect RS with DP, using \(f\)-DP to yield results as strong as that of Equation (1). We start with a general robustness result on \(f\)-DP classifiers, which we later build on for our main result.

**Proposition 2.1** (\(f\)-DP Robustness).: _Let \(:\) be \(f\)-DP for \(B_{p}(r)\) neighbourhoods, and let \(M_{S}:X*{arg\,max}_{y}((X)=y)\) be the associated smoothed classifier. Let \(y_{+} M_{S}(X)\) be the prediction on input \(X\), and let \(},}\) be such that \(((X)=y_{+})}} _{y_{-} y_{+}}((X)=y_{-})\). Then:_

\[f(1-}) 1-f(}) e B_{p}(r), \ M_{S}(X+e)=y_{+}\]

Proof.: See Appendix B.1.

Let us now instantiate Proposition 2.1 for Gaussian RS (see SS2.1):

**Corollary 2.2** (RS from \(f\)-DP).: _Let \(:X g(X+z)\), \(z(0,^{2}^{d})\), and \(M_{S}:X*{arg\,max}_{y}((X)=y)\) be the associated smooth model. Let \(y_{+} M_{S}(X)\) be the prediction on input \(X\), and let \(p_{+},}\) be such that \(((X)=y_{+})}} _{y_{-} y_{+}}((X)=y_{-})\). Then \( e B_{2}(r_{x}),\;M_{S}(X+e)=y_{+}\), with:_

\[r_{X}=^{-1}(})-^{-1}( {p_{-}}).\]

Proof.: See Appendix B2. _Sketch:_\(\) is a Gaussian mechanism, and is \(G_{}\)-DP for any \(r\) (\(B_{2}(r)\) neighbourhood). We apply Proposition 2.1 and maximize \(r\) such that \(G_{}(1-}) 1-G_{}( })\). 

### Adaptive Randomized Smoothing

While Proposition 2.1 is new, so far we have only used it to reprove the known result of Corollary 2.2. So why is this connection between \(f\)-DP and robustness useful? Our key insight is that we can leverage adaptive composition results at the core of DP algorithms to _certify multi-step methods that adapt to their inputs at test time_. Such adaptive defences have seen recent empirical interest, but either lack formal guarantees, or provide only limited adaptivity in practice (SS5). For the first time we derive a _sound and high-dimensional_ adaptive method for certification.

We formalize adaptive multi-step certification as follows. Consider \(k\) randomized Gaussian mechanisms \(_{1},,_{k}\) (our adaptive steps), such that \(m_{i}_{i}(X|m_{<i})\), and for all \(r 0\) we have that \(_{i}\) is \(G_{r/_{i}}\)-DP for the \(B_{2}(r)\) neighbouring definition. Note that the computation \(_{i}\) can depend on previous results, as long as it is \(G_{r/_{i}}\)-DP. Further consider a (potentially randomized) post-processing classifier \(g(m_{1},,m_{k})=y\).

**Theorem 2.3** (**Main result: Adaptive RS)**.: _Using definitions above, let \(:X g(m_{1},,m_{k}),\;(m_{1},,m_{k})( _{1}(X),,_{k}(X|m_{<k}))\), and the associated smoothed model be \(M_{S}:X*{arg\,max}_{m}((X) =y)\). Let \(y_{+} M_{S}(X)\) be the prediction on input \(X\), and let \(},}\) be such that \(((X)=y_{+})}} _{y_{-} y_{+}}((X)=y_{-})\). Then \(e B_{2}(r_{x}),\;M_{S}(X+e)=y_{+}\), with:_

\[r_{X}=^{k}^{2}}}}^{-1} (})-^{-1}(}).\]

Proof.: By adaptive composition of Gaussian DP mechanisms (Equation (3)), \(\) is \(G_{}\)-DP with \(=^{k}}{_{i}^{2}}}=r^{k} ^{2}}}\). We can then apply Corollary 2.2 with \(=1/^{k}^{2}}}\). 

We focus on Gaussian RS, but a similar argument applies to general \(f\)-DP mechanisms for which we can compute \(f_{i}\) at any \(r\), and the composition \(f_{i} f_{k}\), potentially using numerical techniques such as that of Gopi et al. (2021). For Gaussian noise, Theorem 2.3 leverages strong results from DP to provide a perhaps surprising result: there is no cost to adaptivity, in the sense that \(k\) independent measurements of input \(X\) with Gaussian noise (without adaptivity) of respective variance \(_{i}^{2}\) can be averaged to one measurement of variance \(^{2}=1/_{i=1}^{k}_{i}^{-2}\). To show this, we can use a weighted average to minimize variance (see e.g., Equation 4 in Honaker (2015)), with \(c_{j}=_{j}^{-2}/_{i=1}^{k}_{i}^{-2}\) yielding \(^{2}=_{j=1}^{k}c_{j}^{2}_{j}^{2}=_{j=1}^{k}_{j}^{-2 }/_{i=1}^{k}_{i}^{-2}^{2}=1/_{i=1}^{k}_{i}^ {-2}\). The ARS \(r_{X}\) from Theorem 2.3 is identical to that of one step RS from Corollary 2.2 using this variance: _adaptivity over multi-step computation comes with no decrease in certified radius_.

### ARS against \(L_{}\)-Bounded Adversaries

How can we leverage the multi-step adaptivity from Theorem 2.3 to increase certified accuracy? We focus on two-step certified defence against \(L_{}\)-bounded attacks to increase accuracy by adaptivity. Previous work already notes that RS applies to \(L_{}\)-bounded attackers (Lecuyer et al., 2019; Cohen et al., 2019), using the fact that \( X^{d},\|X\|_{2}\|X\|_{}\), and hence that \(X-X^{} B_{}(r^{}) X-X^{} B_{2}(  r^{})\). Using Corollary 2.2, this yields:

\[r_{X}^{}=}^{-1}(})- ^{-1}(}).\] (4)

While \(L_{}\)-specific RS theory exists (Yang et al., 2020), further work by Blum et al. (2020) has found that Gaussian RS performs advantageously in practice. However, Blum et al. (2020); Kumar et al. (2020); Wu et al. (2021) show that the \(\) dependency cannot be avoided for a large family of distributions, leading the authors to speculate that RS might be inherently limited for \(L_{}\) certification of predictions on high dimensional images. To side-step this issue, we use two-steps adaptivity to first select subsets of the image important to the classification task (thereby reducing dimension), and then make the prediction based on the selected subset. Formally:

**Proposition 2.4** (Adaptive RS for \(L_{}\)).: _Define the following pair of (adaptive) mechanisms:_

\[_{1}:X X+z_{1} m_{1}, z_{1}(0, _{1}^{2}^{d})\] (5)

_Then, with any function \(w:^{d}^{d}\) (interpreted as a mask):_

\[_{2}:(X,m_{1}) w(m_{1}) X+z_{2} m_{2}, z _{2}(0,)\|_{2}^{2}}{d}_{2}^{2}^{ d})\] (6)

_where \(\) is the element-wise product; and the final prediction function \(g:m_{1},m_{2}\)._

_Consider the mechanism \(\) that samples \(m_{1}_{1}\), then \(m_{2}_{2}\), and finally outputs \(g(m_{1},m_{2})\); and the associated smoothed classifier \(M_{S}:X*{arg\,max}_{y}((X) =y)\). Let \(y_{+} M_{S}(X)\) be the prediction on input \(X\), and let \(},}\) be such that \(((X)=y_{+})}} _{y_{-} y_{+}}((X)=y_{-})\). Then \( e B_{}(r_{X}^{}),\ M_{S}(X+e)=y_{+}\), with:_

\[r_{X}^{}=^{2}}+ ^{2}})}}^{-1}(})-^{-1}(}).\] (7)

Proof.: Consider any \(X,X^{}\) s.t. \(X-X^{} B_{}(r^{})\). We analyze \(_{1}\) and \(_{2}\) in turn. \(\|X-X^{}\|_{2}\|X-X^{}\|_{}\), so \(X-X^{} B_{2}(r^{})\), and \(_{1}\) is \(G_{_{1}}\)-DP with \(_{1}=}{_{1}}\).

\(\|w(m_{1}) X-w(m_{1}) X^{}\|_{2}=\|w(y_{1})X-X^{ }\|_{2}\|w(y_{1})\|_{2}\|X-X^{}\|_{}\) so \(X-X^{} B_{2}(\|w(y_{1})\|_{2}r^{})\) and \(_{2}\) is \(G_{_{2}}\)-DP with \(_{2}=)\|_{2}r^{}}{\|w(y_{1})\|_{2}_{2}/}= }{_{2}}\).

Applying Theorem 2.3 with \()^{2}d}{_{1}^{2}}+)^{2}d}{ _{2}^{2}}}=r^{}^{2}}+^{2}}}\) concludes the proof. 

**Important remarks. 1.**\(w(.)\) is a masking function, adaptively reducing (if \(w_{i}(m_{1}) 1\)) the value of \(X_{i}\) and thereby the attack surface of an \(L_{}\) attacker. This reduces the effective dimension of the input to \(_{2}\). **2.** Reducing the dimension enables a reduction in the noise variance in \(_{2}\), at fixed privacy guarantee \(G_{_{2}}\). The variance reduction is enabled _for all dimensions in the input_, even those that are not masked (\(w_{i}(m_{1}) 1\)). As a result, the variance of the noise in \(_{2}\) scales as \(\|w(m_{1})\|_{2}^{2} d\). The more masking, the lower the variance. It may help to consider the change of variables \(/\) in Equation (4), and \(_{1,2}_{1,2}/\) in Proposition 2.4, to remove \(d\) from \(r_{X}^{}\) and scale the noise variance with \(d\). For RS (Equation (4)), the noise variance scales as \(d\). For ARS, only Equation (5) (the first step) suffers from variance scaled by \(d\), while the second step's variance (Equation (6)) scales as \(\|w(m_{1})\|_{2}^{2}\), which can be much smaller than \(d\) when a large part of the image is masked. Reduced variance translates into higher accuracy, as well as \(}\) and \(}\) being further apart, for a larger \(r_{X}^{}\). **3.** The variance reduction due to masking applies in the translation from the \(B_{}(r^{})\) bound on the attack to the \(B_{2}(r)\) sensitivity used in ARS. This variance reduction would not apply to an \(L_{2}\)-bounded adversary (an attack that only changes pixels with mask values of one yields no sensitivity improvement). Hence, our two-steps ARS architecture for \(L_{}\)-bounded adversaries does not reduce to bounding \(L_{}\) with \(L_{2}\) as the traditional RS application does, and our gains come explicitly from variance reduction enabled by adaptive masking against an \(L_{}\) attack.

## 3 Two-Step ARS for \(L_{}\) Certification of Image Classification

Figure 1 shows our deep learning architecture based on Proposition 2.4. The first step, \(_{1}\), adds noise to input \(X\) and post-processes the result into a mask \(w(m_{1})\). The second step, \(_{2}\), takes masked input \(w(m_{1}) X\) and adds noise. Finally, the base classifier \(g\) post-processes a weighted average of \(m_{1},m_{2}\) to output a label. The whole model is trained end-to-end on the classification task. In RS, only the path going through \(_{2}\) is present. This is equivalent to setting \(_{2}=\) and \(w(.)=1\), with no \(_{1}\). In both cases, the final predictions are averaged over the noise to create the smoothed classifier. The ARS architecture introduces several new components, which we next describe.

**Budget Splitting:** the noise budget \(\) (Figure 1; red) is split to assign noise levels to the two steps \(_{1}\) and \(_{2}\). We parameterize ARS with the same \(\) as standard RS then split it by the \(f\)-DP composition formula from Equation (3). In practice, we assign \(_{1}\) to \(_{1}\), and then \(_{2}=1/}-^{2}}}\). We set \(_{1}\) by either fixing it to a constant or learning it end-to-end.

**Masking:** the mask model \(w()\) takes the noisy image from \(_{1}\) and predicts a weighting (one value in \(\) per input pixel) that is multiplied with the input element-wise (denoted \(\) in Proposition 2.4). The model is a U-Net architecture, which makes pixel-wise predictions, and acts as a post-processing of \(_{1}\) in the \(f\)-DP analysis. Our masking enables test-time adaptivity to reduce the noise variance for \(_{2}\), via the mask's dependence on the input through \(m_{1}\).

**Mechanism output averaging:** to fully leverage both steps' information, we take a weighted average of the outputs \(m_{1}\) and \(m_{2}\) before passing the result to the base classifier \(g\). For a particular input pixel \(i\), denote \(X_{i}\) the value of pixel, \(w_{i}\) its mask weight (we omit the explicit dependency on \(m_{1}\) in \(w\) for compactness), and \(m_{1,i},m_{2,i}\) the respective values output by \(_{1}\) and \(_{2}\). Then, the final value of pixel \(i\) in the averaged input will be \(_{i} c_{1,i}m_{1,i}+c_{2,i}m_{2,i}\).

We set \(c_{1,i},c_{2,i}\) such that \(_{i}\) is the unbiased estimate of \(X_{i}\) with smallest variance. First, we set \(c_{1,i}+w_{i}c_{2,i}=1\), such that \([_{i}]=c_{1,i}X_{i}+c_{2,i}w_{i}X_{i}=X_{i}\). Second, we minimize the variance. Notice that \([_{i}]=c_{1,i}^{2}_{1}^{2}+c_{2,i}^{2}\|w\|_{2}^{2} _{2}^{2}=(1-w_{i}c_{2,i})^{2}_{1}^{2}+c_{2,i}^{2}\|w\|_{2}^{2} _{2}^{2}\): this is a convex function in \(c_{2,i}\) minimized when its gradient in \(c_{2,i}\) is zero. Plugging back into the constraint to get \(c_{1,i}\), we obtain the following weights: \(c_{1,i}=^{2}_{2}^{2}}{_{1}^{2}w_{i}^{2}+\|w\|_{2}^{ 2}_{2}^{2}}\), and \(c_{2,i}=^{2}w_{i}}{_{1}^{2}w_{i}^{2}+\|w\|_{2}^{2}_ {2}^{2}}\).

The averaged noisy input \(\) is finally fed to the base classifier \(g\) for prediction. The smoothed classifier \(M_{S}\) averages predictions (over noise draws) over the entire pipeline. The parameters of \(w\) and \(g\) (and \(_{1}\) if not fixed) are learned during training and are fixed at inference/certification time.

## 4 Experiments

We evaluate on standard and \(L_{}\)-certified test accuracy. Certified accuracy at radius \(r^{}\) is the percentage of test samples that are correctly classified **and** have an \(L_{}\) certificate radius \(r_{X}^{} r^{}\). Standard accuracy is obtained for \(r^{}=0\).

**Datasets** We evaluate on CIFAR-10 (Krizhevsky, 2009) in SS4.1, CelebA (Liu et al., 2015) (specifically the unaligned HD-CelebA-Cropper edition) in SS4.2, and ImageNet (Deng et al., 2009) in SS4.3. We measure adaptivity on CIFAR-10 and CelebA by designing challenging benchmarks requiring adaptivity, and measure scalability on ImageNet.

**Models** We choose the standard ResNet (He et al., 2016) models as base classifiers \(g\) with ResNet-110 for CIFAR-10 and ResNet-50 for CelebA and ImageNet. For ARS, our mask model \(w\) is a simplified U-Net (Ronneberger et al., 2015) (see Appendix C.1 for details). For the noise budget, we find that a fixed budget split performs reliably, and so in all experiments we split by \(_{1}=_{2}=\).

**Methods** We compare to standard and strong static methods, design a baseline specifically for our masking approach, and evaluate the only sound input-dependent methods prior to ARS. _Cohen et al._ is the standard approach to RS (Cohen et al., 2019). _UniCR_(Hong et al., 2022) learns the noise distribution for RS during training but is static during testing (while they propose an input-adaptive variant, it is not sound so we restrict our comparison to the training variant). We tune hyper-parameters, and perform a grid search for \(\) (the parameter of the noise distribution) to maximize certified accuracy. We find that \(=2\) (Gaussian), or \(=2.25\) (close to a Gaussian,with smaller tails), to perform best in high and low \((k,)\) values, respectively (see Appendix D) for details. _Static Mask_ is our baseline that learns a fixed mask during training that does not adapt during testing. The mask is directly parameterized as pixel-wise weights that we multiply with the input and optimize jointly with the base classifier. Relative to ARS in Figure 1, this removes \(_{1}\), sets \(_{2}=\), and makes \(w(.)=W\) static parameters rather than an adaptive prediction. _Sikenik et al._(_2021_) conditions the variance \(\) for RS on the input and is therefore test-time adaptive. We use code provided by the authors as is. Comparing ARS to the static baselines measures the value of test-time adaptivity, and comparing ARS to the variance adaptivity of Sukenik et al. measures the importance of more high-dimensional and expressive adaptation.

### CIFAR-10 Benchmark: Classification with Distractor Backgrounds

Input dimension is a key challenge in \(L_{}\) certification using RS (see SS2.4). We design our 20kBG benchmark to vary this parameter without affecting the task: we superimpose CIFAR-10 images onto a larger distractor background from the \(20k\) background images dataset Li et al.(2022). The backgrounds are split into train and test sets, and resized to \(k k\) pixels (where \(k 32\)). The CIFAR-10 image (of dimensions \(32 32 3\)) is then placed at random along the edges of the background image to maximize spatial variation. The spurious background increases the dimension (\(=k k 3\)) of the input when \(k>32\), making \(L_{}\) certification with RS more challenging, but is uninformative for the task of CIFAR-10 by construction. Our mask model (\(_{1}\)) needs to learn to ignore the background to reduce the effective dimension of the input. For computational reasons, we run all certification results on a 200 sample subset of the CIFAR-10 test set. Appendix D shows extended results, details about hyperparameter tuning (C.3), and results on larger test-sets (D.1). We set the failure probability of the certification procedure to 0.05, use 100 samples to select the most probable class, and 50,000 samples for the Monte Carlo estimate of \(}\).

Table 1 summarizes the standard accuracy (\(r=0\)) of each approach on the different settings. We vary \(\) in \(\{0.25,0.5,1.0\}\) and \(k\) in \(\{32,48,64,96\}\) to show the effect of noise levels and dimensionality on the accuracy of different approaches (\(k=32\) corresponds to original CIFAR-10 images). Figure 2 shows the certified test accuracy at different radii \(r^{}\) for ARS and all baselines we consider.

We make three observations. First, ARS outperforms all the baselines under distractor backgrounds (\(k>32\)). Static mask is slightly better at \(k=32\), probably because CIFAR-10 images lack enough "irrelevant" information for ARS to discard. This is precisely why we introduce this benchmark, where we explicitly add such irrelevant information to input images. Indeed, at \(k>32\), we observe that the standard accuracy of ARS improves, translating to an improved certified accuracy at all certification levels, since more accurate and confident predictions give a larger certified radius \(r^{}\).

Second, as we grow the input dimension \(k\), the accuracy of ARS remains either stable or increases, whereas that of other baselines goes down, resulting in an increasing gap. For instance, at \(=1.0\), the gap between ARS and the best baseline is \(1.3\)% points for \(k=32\), \(2.5\)% points for \(k=48\)

  Setting/Approach & Cohen et al. & Static Mask & UniCR & Sukenik et al.\({}^{}\) & ARS \({}^{}\) \\   \(=0.25,\ k=32\) & 70.6 (1.1) & **73.9 (0.8)** & 69.8 (1.4) & 68.6 (2.8) & 72.6 (0.9) \\ \(=0.5,\ k=32\) & 63.6 (2.0) & **64.8(0.9)** & 62.8 (1.4) & 59.1 (1.6) & 64 (1.4) \\ \(=1.0,\ k=32\) & 48 (0.7) & 47.3 (1.3) & 46.1 (0.9) & 44.6 (1.0) & **49.3 (0.6)** \\   \(=0.25,\ k=48\) & 71.6 (1.0) & 72 (2.0) & 69.7 (0.8) & 65 (0.7) & **75.5 (1.0)** \\ \(=0.5,\ k=48\) & 64.3 (0.2) & 64.1 (1.6) & 60.3 (0.6) & 53.5 (1.8) & **66 (1.6)** \\ \(=1.0,\ k=48\) & 42.5 (2.1) & 45.1 (1.2) & 44.3 (0.2) & 34.1 (1.0) & **47.6 (2.0)** \\   \(=0.25,\ k=64\) & 71.6 (0.9) & 73.1 (3.2) & 67.8 (0.5) & 64.1 (0.8) & **77 (1.8)** \\ \(=0.5,\ k=64\) & 63 (1.6) & 62.5 (1.7) & 58.7 (0.2) & 45.1 (1.1) & **69.9 (1.2)** \\ \(=1.0,\ k=64\) & 41.3 (1.8) & 40.0 (0.5) & 42.2 (0.6) & 26.5 (0.7) & **50.4 (2.5)** \\   \(=0.25,\ k=96\) & 65.3 (1.6) & 71.8 (1.3) & 68.8 (1.8) & 45.5 (0.9) & **78.3 (2.2)** \\ \(=0.5,\ k=96\) & 56.6 (2.4) & 59.5 (1.4) & 59.7 (1.3) & 10.8 (2.3) & **69.8 (1.2)** \\ \(=1.0,\ k=96\) & 33.8 (3.8) & 36.9 (0.5) & 41.3 (2.4) & 10.4 (0.3) & **56.3 (2.3)** \\  

Table 1: **Standard Accuracy (\(r=0\)) on CIFAR-10 (20kBG). Our 20kBG benchmark places CIFAR-10 images on larger background images. We report the mean accuracy and standard deviation over three seeds. ARS achieves higher accuracy across noise \(\) and input dimension \(k\) (\({}^{}\) indicates adaptivity). We provide results with more \(\) levels in Appendix D.**\(8.2\)% points for \(k=64\) and \(15\)% points for \(k=96\). As \(k\) grows, the amount of relevant information (\(a~{}32 32 3\) CIFAR-10 image) remains the same, whereas the amount of spurious background information increases. ARS' mask is able to rule out spurious pixels, reducing the noise in the second step (Figure 3). Thanks to this masking, ARS is much less sensitive to increases in dimensionality.

Third, we observe that except \(k=32\), ARS improves over all the baselines in low (\(=0.25\)) to high (\(=1.0\)) noise regimes. In fact, this trend continues to persist in higher noise regimes (Appendix D). Similar to previous observations, we notice that as we increase \(\), other baselines's accuracy drops significantly whereas ARS accuracy drops much less, displaying higher noise tolerance.

ARS training and inference requires additional computation. To certify a single input (\(k=32\)), Cohen et al. (2019) takes \(\)\(12\) seconds while ARS takes \(\)\(26\) seconds (as measured on an NVIDIA A100 80Gb GPU). This 2\(\) overhead does however yield improved certified accuracy.

### CelebA Benchmark: Classification Without Spatial Alignment

To evaluate ARS on a more realistic task with natural spatial variation, we use the CelebA face dataset in its unaligned version. We focus on the "mouth slightly open" (label 21) binary classification task because mouth location and shape vary. The input part relevant to this task is likely well-localized, which affords an opportunity for the mask model to reduce the effective input dimension. The dataset

Figure 3: _(left)_ Original CIFAR-10 images superimposed on backgrounds for different \(k\) (except \(k=32\) which is no background), and _(right)_ their corresponding masks (grayscale) inferred by our mask model \(w\). All masks are for \(=0.5\). Appendix D.2 shows all the corresponding images across our multi-step architecture.

Figure 2: **Certified Test Accuracy on CIFAR-10 (20kBG).** (a)-(c) show the effect of dimensionality for (a) no background / \(k=32\), (b) \(k=48\), and (c) \(k=96\) for constant \(=0.5\). (d)-(f) show the effect of noise for (d) \(=0.25\), (e) \(=0.5\) and (f) \(=1.0\) with dimensionality fixed to \(k=64\). Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.

consists of images with varied resolution, and meta-data about the position of different features, including the mouth. To create a challenging benchmark, we randomly crop all images to \(160 160\) pixels, which creates spatial variation in the mouth's position. The only crop constraint is that the mouth is \( 10\) pixels from the edge to ensure sufficient input to solve the task. Figure 5 shows example images from the test set, their respective masks from ARS and the baseline static mask.

Figure 4 shows the certified accuracy for ARS, Cohen et al. (2019), and static mask, for three levels of the noise \(\). First, both baselines perform very similarly. We can see from Figure 5 that the static mask is approximately identity (notice the \( 0.99\) scale), with only very slight dimming on the edges. This is because the mouth is not centred in our benchmark, so there is no one-size-fits-all mask. Second, ARS is able to predict a sparse mask that focuses on areas likely to have the mouth. The mask adapts to each input at test time, which is what enables the sparsity without performance degradation. Third, this sparse mask leads to a large noise reduction, enabling ARS to drastically improve both standard and certified accuracy. For instance, with \(=0.5\), ARS improves the standard accuracy from \(91.0\%\) to \(94.3\%\) (a \(3.3\) point improvement), while the certified accuracy at \(r^{}=0.004\) jumps from \(45.0\%\) to \(79.3\%\) (a more than \(30\) point improvement!). At lower noise (\(=0.25\)) there is still an increase in standard accuracy from \(94.3\%\) to \(97.0\%\), and an increase in certified accuracy from \(68.3\%\) to \(84.7\%\) at \(r^{}=0.002\)). At larger noise (\(=1.0\)), ARS sees significant increases (\(7.7\%\) points in standard accuracy, and from \(21.3\%\) to \(49.3\%\) in certified accuracy at \(r^{}=0.008\)).

### ImageNet Benchmark: Classification on the Standard Large-Scale Dataset

To evaluate the scalability of ARS we experiment on ImageNet (without any modification) with \(=0.25,0.5,1.0\). For each noise level, we compare with Cohen et al. (2019), which we reproduce for this large-scale setting. We evaluate two versions of ARS: our regular setting (End-To-End); and a version that fixes the base classifier to the model trained as in Cohen et al. (2019), and only trains our mask model for \(10\) epochs (Pretrain). The certified accuracy is plotted in Figure 6 and the standard accuracy is reported in Table 3.

When only training the mask model, certified accuracy remains close to that of Cohen et al. (2019) at all radii and noise levels. ARS trained end-to-end improves both standard and certified accuracy.

  Setting/Approach & Cohen et al. & Static Mask & ARS \\  CelebA, \(=0.25\) & 94.3 (0.5) & 93.0 (0.8) & **97.0 (0.8)** \\ CelebA, \(=0.5\) & 91.0 (0.8) & 91.7 (0.9) & **94.3 (0.9)** \\ CelebA, \(=1.0\) & 83.3 (0.9) & 84.7 (2.6) & **91.0 (1.6)** \\  

Table 2: **Standard test accuracy (\(r=0\)) on CelebA (unaligned and cropped). ARS is equal or better. Adaptivity handles the higher spatial dimensions (\(160 160\)) and variation of these inputs.**

Figure 4: **Certified test accuracy on CelebA (unaligned and cropped). We evaluate static methods and ARS to measure the value of adaptivity. Each line is the mean and the shading covers \( 1\) standard deviation across three seeds. Adaptivity helps at all noise levels.**

Figure 5: ARS masks are localized and input specific.

The standard accuracy (at \(r=0\)) increases from \(57.2\%\) to \(57.4\%\) and from \(43.6\%\) to \(44.5\%\) when \(=0.5\) and \(=1\), respectively. For \(=0.25\), standard accuracy for ARS is close but slightly lower than Cohen et al. (2019), while the pretrained ARS outperforms Cohen et al. (2019) from \(66.5\%\) to \(67.4\%\). Appendix F discusses other ARS improvements without certification.

Certified accuracy increases at larger \(\). For instance at \(=0.5\), ARS improves certified accuracy at \(r^{}=0.001\) from \(48.9\%\) to \(50.5\%\). At larger noise \(=1.0\), ARS improves certified accuracy at \(r^{}=0.005\) from \(21.7\%\) to \(23.1\%\). This shows that ARS' adaptivity generalizes outside of the specialized benchmarks we designed, and can scale to large datasets and complex classification tasks.

## 5 Discussion

**Limitations:** The multi-step adaptivity of ARS improves certification at the cost of increased model size and computation for RS. This impacts both training and testing computation, and is especially costly in the context of RS due to the Monte Carlo estimation of the model's expected predictions (over several forward passes at inference time). While we empirically show improvement by ARS, it would be interesting and important to investigate how it combines with other RS improvements such as adversarial training (Salman et al., 2019), consistency regularization (Jeong and Shin, 2020), higher order certification (Mohapatra et al., 2020), double sampling (Li et al., 2022), and denoising by diffusion (Carimi et al., 2022). Lastly, our adaptive masking technique provides improved certificates for the \(L_{}\) norm, but does not have the same effect for other norms such as \(L_{2}\) (see remarks in SS2.4). It is plausible that ARS' adaptivity can lead to improvements under alternative norms, by leveraging different DP mechanisms and updates. We leave this exploration for future work.

**Implications:** Revisiting heuristic adaptive defences (as surveyed in Croce et al. (2022)) through the lens of ARS could help improve the empirical performance of provable defences. ARS may require extensions, but could eventually enable the formal analysis of input purification (e.g., Song and Kim (2018); Nie et al. (2022); Yoon et al. (2021)), or leverage DP-SGD (Abadi et al., 2016) to analyze defences that update by test-time optimization (Alfarra et al., 2022; Hwang et al., 2022; Mao et al., 2021). Going further, one could leverage the vast DP literature to extend ARS, enabling fully-adaptive variance defences inspired by Alfarra et al. (2022) by leveraging privacy odometers (Rogers et al., 2016; Lecuyer, 2021; Whitehouse et al., 2023).

To conclude: we introduced Adaptive Randomized Smoothing (ARS) to reconnect RS with DP theory, to propose a new two-step defence for deep image classification, and to rigorously analyze such adaptive defences that condition on inputs at test time. This framework opens promising avenues for designing models that are adaptively and soundly robust with provable guarantees about their updates on natural and adversarial inputs.

Figure 6: **Certified test accuracy on ImageNet for \(=0.25,0.5,1\). We plot the mean and the shading covers \( 1\) standard deviation for three seeds. ARS is equal or better than non-adaptive RS (Cohen et al.) at large scale.**

  Setting/Approach & Cohen et al. & ARS (Pretrain) & ARS (End-To-End) \\  ImageNet, \(=0.25\) & 66.5 (0.009) & **67.4 (0.002)** & 65.7 (0.006) \\ ImageNet, \(=0.5\) & 57.2 (0.009) & 56.0 (0.003) & **57.4 (0.010)** \\ ImageNet, \(=1.0\) & 43.6 (0.005) & 43.8 (0.002) & **44.5 (0.010)** \\  

Table 3: **Standard test accuracy (\(r=0\)) on ImageNet. ARS maintains standard accuracy.**