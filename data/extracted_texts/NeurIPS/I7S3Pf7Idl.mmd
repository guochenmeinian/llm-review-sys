# Importance of non-member dataset:

[MISSING_PAGE_EMPTY:1]

sequence as a member or non-member by evaluating the semantic distance and the corresponding changes in the target model's behavior for the original input and its perturbations.

Figure 1 illustrates the pipeline of our proposed SMIA inference. The SMIA inference pipeline for a given text \(x\) and a target model \(T(.)\) includes four key steps: **(1) Neighbor Generation:** The target sequence is perturbed \(n\) times by randomly masking different positions and filling them using a masking model, such as T5 (Raffel et al., 2020), to generate a neighbour dataset \(\) (similar to Mattern et al. (2023); Mitchell et al. (2023)). **(2) Semantic Embedding Calculation:** The semantic embeddings of the input text and its neighbours are computed by using an embedding model, such as Cohere Embedding model (Cohere, 2024). **(3) Loss Calculation:** The loss values of the target model for the input text and its neighbours are calculated. **(4) Membership Probability Estimation:** The trained SMIA model is then used to estimate the membership probabilities. These scores are averaged and compared against a predefined threshold to classify the input as a member or non-member.

**Empirical Results:** We evaluate the performance of our proposed SMIA across different model families, specifically Pythia and GPT-Neo, using the Wikipedia and MIMIR (Duan et al., 2024) datasets. To underscore the significance of the non-member dataset in evaluating MIAs, we include two distinct non-member datasets in our Wikipedia analysis: one derived from the exact distribution of the member dataset and another comprising Wikipedia pages published after a cutoff date, which exhibit lower n-gram similarity with the members. Additionally, we assess SMIA under two settings: (1) verbatim evaluation, where members exactly match the entries in the target training dataset, and (2) slightly modified members, where one word is either duplicated, added, or deleted from the original member data points.

Our results demonstrate that SMIA consistently outperforms all existing MIAs by a substantial margin. For instance, SMIA achieves an AUC-ROC of 67.39% for Pythia-12B on the Wikipedia dataset. In terms of True Positive Rate (TPR) at low False Positive Rate (FPR), SMIA achieves TPRs of 3.8% and 10.4% for 2% and 5% FPR, respectively, on the same model. In comparison, the second-best attack, the Reference attack, achieves an AUC-ROC of 58.90%, with TPRs of 1.1% and 6.7% for 2% and 5% FPR, respectively.

## 2 Our Proposed SMIA

Membership inference attacks (MIAs) against LLMs aim to determine whether a given data point was part of the training dataset used to train the target model or not. Given a data point \(x\) and a trained autoregressive model \(T(.)\), which predicts \(P(x_{t}|x_{1},x_{2},...,x_{t-1})\) reflecting the likelihood of the sequence under the training data distribution, these attacks compute a membership score \(A(x,T)\). By applying a threshold \(\) to this score, we can classify \(x\) as a member (part of the training data) or a non-member. In Appendix B, we provide MIA use cases and details about how existing MIA work against LLMs.

Figure 1: Our Semantic Membership Inference Attack (SMIA) inference pipeline.

MIAs seek to determine whether a specific data sample was part of the training set of a machine learning model, highlighting potential privacy risks associated with model training. Traditional MIAs typically verify if a text segment, ranging from a sentence to a full document, was used exactly as is in the training data. Such attacks tend to filter when minor modifications are made to the text, such as punctuation adjustments or word substitutions, while the overall meaning remains intact. We hypothesize that a LLM, having encountered specific content during training, will exhibit similar behaviors towards semantically similar text snippets during inference. Consequently, a LLM's response to semantically related inputs should display notable consistency.

In this paper, we introduce Semantic Membership Inference Attack (SMIA) against LLMs. This novel attack method enables an attacker to discern whether a _concept_, defined as a set of semantically akin token sequences, was part of the training data. Examples of such semantically linked concepts include "John Doe has leukemia" and "John Doe is undergoing chemotherapy." The proposed SMIA aims to capture a broader spectrum of data memorization incidents compared to traditional MIA, by determining whether the LLM was trained on any data encompassing the targeted concept.

### SMIA Design

For the SMIA, we assume that the adversary has grey-box access to the target LLM, denoted as \(T(.)\), which is trained on an unknown dataset \(D_{}\). The adversary can obtain loss values or log probabilities for any input text from this model, denoted as \((.,T)\), but lacks additional information such as model weights or gradients. The cornerstone of our SMIA is the distinguishable behavior modification exhibited by the target model when presented with semantic variants of member and non-member data points.

As illustrated in Figure 2, consider a 2-dimensional semantic space populated by data points. Members and non-members are represented by green circles and red circles, respectively. By generating semantic neighbors for both member and non-member data points (shown as green and red diamonds, respectively), we measure the semantic distance between targeted data points and their neighbors, denoted as \(d_{i}^{m}\) and \(d_{i}^{m}\). Subsequently, we observe the target model's response to these data points by assessing the differences in loss values (y-axis for log probability of that text under the target LLM data distribution), thereby training the SMIA to classify data points as members or non-members based on these observed patterns.

### SMIA Pipeline

The SMIA consists of two primary components: initially, the adversary trains a neural network model \(A(.)\) on a dataset gathered for this purpose, and subsequently uses this trained model for inference. The training and inference processes are detailed in Algorithms 1 and 2, respectively.

During the training phase, the adversary collects two distinct datasets: \(D_{}\) (member dataset) and \(D_{}\) (non-member dataset). \(D_{}\) comprises texts known to be part of the training dataset of the target model \(T(.)\), while \(D_{}\) includes texts confirmed to be unseen by the target model during training. The adversary utilizes these datasets to develop a membership inference model capable of distinguishing between members (\( D_{}\)) and non-members (\( D_{}\)). For instance, Wikipedia articles or any publicly available data collected before a specified cutoff date are commonly part of many known datasets. Data collected after this cutoff date can be reliably assumed to be absent from the training datasets.

The SMIA training procedure, shown in Algorithm 1, involves four key stages:

Figure 2: Input features for our SMIA: semantic change and target model behaviour change for inputs and their neighbors.

[MISSING_PAGE_EMPTY:4]

\(A\) include the differences in semantic vectors \(_{i}^{m}-_{i}^{m}\) and the changes in loss values \(L_{i}^{m}-_{i}^{m}\) for each sample \(i\). Each sample is labeled '1' for members and '0' for non-members, with each training batch consisting of an equal mix of both, as suggested in prior research (Nasr et al., 2019). The model is trained over \(R\) epochs using a learning rate \(r\), culminating in a trained binary classifier that effectively distinguishes between members and non-members based on the observed data. We provide our SMIA training cost in Appendix C.

```
1:Test input \(x\), Trained SMIA Model \(A(.\,,,D_{},D_{})\) on dataset of members for training \(D_{}\) and dataset of non-members for training \(D_{}\), masking model for neighbor generation \(N(.)\), Embedding model \(E(.)\), Target model \(T(.)\), Number of neighbors in inference \(n_{}\), Number of perturbations \(k\), decision threshold \(\), loss function \(\)
2:\(x_{}(x,n_{},k)\)\(\) Masking
3:\( N(x_{})\)\(\) Neighbor generation
4:\(, E(x),E()\)\(\) Embedding
5:\(L,(x,T),(,T)\)\(\) Target model loss
6:\(_{i[t]}A(-_{i},L-_{i})\)\(\) Average of SMIA scores
7:if\(>\)then
8:return True
9:else
10:return False
11:end if
12: ```

**Algorithm 2** Our Proposed Semantic Membership Inference Attack: inference

**SMIA Inference:** Upon completing the training of the model \(A(.)\), it can be employed to assess whether a given input text \(x\) was part of the target model \(T(.)\)'s training dataset. Algorithm 2 details the inference procedure, which mirrors the training process. Initially, \(n_{}\) neighbours for \(x\) are generated using the mask model (lines 1-2). Subsequently, we compute both the semantic embedding vectors and the loss values for \(x\) and its neighbours \(\) (lines 3-4). These computed differences are then fed into the attack model \(A(-_{j},L-_{j})\), which evaluates each neighbour \(j\). The final SMIA score for \(x\) is determined by averaging the scores from all \(n_{inf}\) neighbours (line 5), and this score is compared against a predefined threshold \(\) to ascertain membership or non-membership (line 6).

## 3 Experiment Setup

In this section, we describe the models and datasets used in our experiments. Due to space constraints, we have organized additional information into appendices. We provide the details of the architecture for SMIA model in Appendix E.1, cost estimation of SMIA to Appendix C, privacy metrics used in our analysis in Appendix E.2, the hyperparameters for training the SMIA model in Appendix E.4, the baselines in Appendix B, and the computational resources utilized in Appendix E.5.

### Models

**Target Models:** In our experiments, we evaluate our proposed SMIA across a diverse set of language models to assess its effectiveness and robustness. We utilize three categories of target models: (1) Pythia Model Suite: This category includes the largest models with 12B, 6.9B, and 2.7B parameters from the Pythia model suite (Biderman et al., 2023), trained on the Pile dataset (Gao et al., 2020). (2) Pythia-Deduped: It consists of models with the same parameterization (12B, 6.9B, and 2.7B) but trained on a deduplicated version of the Pile dataset. This variation allows us to analyze the impact of dataset deduplication on the effectiveness of MIAs. (3) GPT-Neo Family: To test the generality of our approach across different architectures, we include models from the GPT-NEO family (Black et al., 2021), specifically the 2.7B and 1.3B parameter models, also trained on the Pile dataset.

Models Used in SMIA:The SMIA framework incorporates three critical components: (1) Masking Model: We employ T5 with 3B parameters (Raffel et al., 2020) for generating perturbed versions of the texts, where random words are replaced to maintain semantic consistency. (2) Semantic Embedding Model: The Cohere Embedding V3 model (Cohere, 2024) is utilized to produce a 1024-dimensional semantic embedding vector for each text, enabling us to capture nuanced semantic variations. (3) Binary Neural Network Classifier: For the SMIA model, we utilize a relatively simple neural network (details shown in Table 8) with 1.2M parameters, which is trained to distinguish between member and non-member data points. In Appendix E.4, we discuss the hyperparameters that we use in our experiments for this model.

### Datasets

To evaluate the effectiveness of the SMIA, we need to collect three datasets: training dataset \(D_{}=\{D_{-},D_{-}\}\), validation dataset \(D_{}=\{D_{-},D_{-}\}\), and test dataset \(D_{}=\{D_{-},D_{-}\}\). Each dataset comprises a member and a non-member split. We employ the training dataset for model training, the validation dataset for tuning the hyperparameters, and the test dataset for evaluating the model performance based on various metrics.

#### 3.2.1 Wikipedia Dataset

Wikipedia Training and Validation:We selected a total of 14,000 samples from Wikipedia, verified as parts of the training or test split of the Pile dataset (Gao et al., 2020). This includes 7,000 member samples from the training split of the Wikipedia portion of Pile and 7,000 non-member samples from the test split. Samples were selected to have a minimum of 130 words and were truncated to a maximum of 150 words. Consistent with prior studies (Gao et al., 2020; Duan et al., 2024), we prepended article titles to the text of each article, separated by a "\(\)n \(\)n". The split for these samples assigns 6,000 from each category to the training dataset (\(D_{}\)) and 1,000 from each to the validation dataset (\(D_{}\)). In Appendix C, we provide the cost estimation for preparing this dataset for our training. For example for Wikipedia training part, calculating the embedding vectors from Cohere model costs around $32.

Wikipedia Test:For the test member dataset (\(D_{}\)), we similarly sourced 1,000 samples from the training portion of Pile. Selecting an appropriate non-member dataset (\(D_{}\)) for testing is crucial, as differences in data distribution between member and non-member samples can falsely influence the perceived success of membership inference. Prior research (Duan et al., 2024) indicates that non-member samples drawn from post-training publications or different sections of the Pile test dataset show varied overlap in linguistic features such as n-grams, which can affect inference results. To address this, we established two non-member test datasets: the first, referred to as Wikipedia Test (\(WT=\{D_{},D_{}^{}\}\)), includes samples from Wikipedia pages before March 2020 that are part of the Pile test dataset. The second, called Wikipedia Cutoff (\(WC=\{D_{},D_{}^{}\}\)), consists of 1,000 samples from Wikipedia pages published after August 2023, ensuring they were not part of the Pile training dataset.

#### 3.2.2 MIMIR Dataset

The MIMIR dataset (Duan et al., 2024), a derivative of the Pile dataset (Gao et al., 2020), is designed to simulate real-world challenges in membership inference of LLMs. Members and non-members are drawn from the train and test splits of the Pile dataset respectively, with non-member samples designed to exhibit different n-gram overlaps. We specifically engaged with the most challenging MIMIR sub-split, where members and non-members share up to 80% overlap in 13-grams--a setting designed to rigorously test the discriminative power of our SMIA approach. We select Wikipedia.en, GitHub, PubMed Central, and ArXiv splits in our experiments. Samples were selected to have a minimum of 130 words. Each member and non-member dataset was then divided into 70% for training (\(D_{}\)), 10% for validation ( \(D_{}\)), and 20% for the test dataset (\(D_{}\)). We benchmark the performance of SMIA against other baselines on the test datasets.

## 4 Experiments

In this section, we present the experimental results of our SMIA and compare its performance to other MIAs in verbatim setting (for modified setting, see Appendix A). Due to space constraints, we defer the TPR of attacks at low FPR to Appendix D.1, the effect of deduplication in the Pythia model family to Appendix D.2, analysis of SMIA's performance with varying numbers of neighbors during inference to Appendix D.3, the effect of training size on SMIA's performance to Appendix D.4, and, the histogram of similarities between generated neighbors and their original texts in both member and non-member training datasets to Appendix D.5.

### Evaluation in Verbatim Setting

Our initial set of experiments aims to classify members and non-members without any modifications to the data, meaning that the members (\(D_{}\)) in the test dataset are verbatim entries from the training dataset of the models. This evaluation setting is consistent with prior works (Yeom et al., 2018; Carlini et al., 2021; Shi et al., 2023; Mattern et al., 2023; Zhang et al., 2024). Table 1 and Table 2 present the AUC-ROC metric for various baseline methods and our proposed SMIA approach across different trained models for Wikipedia (with two distinct test datasets) and MIMIR dataset repectively (Refer to Appendix D.2 for evaluation results on deduplicated models). Additionally, Table 4 and Table 5 in Appendix D.1 provide the True Positive Rate (TPR) at low False Positive Rates (FPR) for these methods and datasets. For MIMIR experiments, the tables include the best AUC-ROC values for Min-K and Min-K++ across different values of \(K\) and Pyhtia-1.4B as the reference model. The results demonstrate that SMIA significantly outperforms existing methods. For instance, on Pythia-12B and \(WT=\{D_{},D_{}^{}\}\) test dataset (i.e., when non-members are sampled from the same data distribution as members), SMIA achieves an AUC-ROC of 67.39% with TPRs of 3.8% and 10.4% at 2% and 5% FPR, respectively. In contrast, the LOSS method (Yeom et al., 2018) yields an AUC-ROC of 54.94% and TPRs of 2.1% and 5.8% at the same FPR thresholds. The Ref attack (Carlini et al., 2021), which utilizes Pythia 1.4B to determine the complexity of test data points on a reference model trained on the same data distribution (a challenging assumption in real-world scenarios), achieves an AUC-ROC of 58.90% with TPRs of 2% and 8.2% at 2% and 5% FPR. Furthermore, Min-K (Shi et al., 2023) and Min-K++ (Zhang et al., 2024) show better AUC-ROC compared to the LOSS attack, achieving 56.66% and 57.67% for \(K=20\%\).

On MIMIR dataset, SMIA demonstrates superior performance across multiple splits. For example, in the PubMed Central split, on Pythia-12B, it achieves an AUC-ROC of 68.39% with TPRs of 8.50%, 11.50%, and 30.50% of APRs of 2%, 5% and 10%, respectively. The second-best attack, the Nei attack (Mattern et al., 2023; Mitchell et al., 2023), achieves a lower AUC-ROC of 57.77% with corresponding TPRs of 1.0%, 6.0%, and 12.50% at these FPR thresholds. Similar to previous work (Duan et al., 2024), we find Github split as a less challenging domain emphasizing that LLMs tend to memorize the code snippets with higher probability. These evaluations were conducted under the constraint of dataset sizes, with each split containing at most 1000 examples for members and 1000 examples for non-members (before splitting them into \(\{D_{},D_{},D_{}\}\)). It is important to note that these results are achieved with the constraint of a limited size for our training, validation, and test datasets. we postulate that with an expansion in the size of these datasets, SMIA would likely achieve even higher performance metrics.

#### Why SMIA Outperforms Other MIAs:

 SMIA delivers superior performance for two key reasons: Firstly, it incorporates the semantics of the input text into the analysis, unlike the baseline methods that solely rely on the target model's behavior (e.g., log probability) for their membership score calculations. Secondly, SMIA utilizes a neural network trained specifically to distinguish between members and non-members, offering a more dynamic and effective approach compared to the static statistical methods used by previous MIAs.In the other Wikipedia test dataset (\(WC=\{D_{},D_{}^{}\}\)), where non-members are derived from Wikipedia pages published after August 2023, we observe a substantial improvement in SMIA performance, consistent with findings from other studies (Duan et al., 2024). For example, SMIA achieves an AUC-ROC of 67.39% and 93.35% for Pythia-12B on \(WT\) and \(WC\), respectively. In terms of TPR at low FPR for the same model, SMIA achieves 3.8% and 10.4% for 2% and 5% FPR with the \(WT\) dataset, while achieving 46.2% and 66.0% for 2% and 5% FPR with the \(WC\) dataset. This increase is also observed in other attack methods. For instance, Min-K++ (with \(K=10\%\)) attains 54.77% AUC-ROC for the \(WT\) dataset and 76.17% for the \(WC\) dataset. The underlying reason for this is that the member dataset (\(D_{}\)) has a higher n-gram overlap with the \(WT\) non-member dataset compared to the \(WC\) non-member dataset. A high n-gram overlap between members and non-members implies that substrings of non members may have been seen during training, complicating the distinction between members and non-members (Duan et al., 2024).

**Larger models memorize more:** Another observation from Table 1, Table 2, Table 4, and Table 5 is that larger models exhibit greater memorization, consistent with findings from previous studies (Duan et al., 2024; Carlini et al., 2022; Nasr et al., 2023). For instance, for the \(WT\) (\(WC\)) test datasets, SMIA achieves AUC-ROC scores of 67.39% (93.35%), 64.63% (92.11%), and 60.65% (89.97%) for Pythia 12B, 6.9B, and 2.7B, respectively. Similarly, SMIA achieves 59.71% (89.59%) and 58.92% (87.43%) on GPT-Neo 2.7B and 1.3B, respectively, for the \(WT\) (\(WC\)) test datasets.

## 5 Conclusion

In this paper, we introduced the Semantic Membership Inference Attack (SMIA), which leverages the semantics of input texts and their perturbations to train a neural network for distinguishing members from non-members. We evaluated SMIA in two primary settings: (1) where the test member dataset exists verbatim in the training dataset of the target model, and (2) where the test member dataset is slightly modified through the addition, duplication, or deletion of a single word.

   &  &  &  \\  & & & LOSS & Ref & Zlib & Nei & Mink & Mink++ & **SMIA** \\   & Wikipedia & 55.33 & 58.87 & 55.04 & 55.74 & 58.60 & 60.77 & **64.85** \\  & Github & 76.45 & 47.25 & 76.60 & 73.03 & 76.90 & 77.54 & **99.71** \\  & ArXiv & 48.66 & **57.63** & 47.14 & 51.83 & 49.91 & 53.12 & 54.45 \\  & PubMed & 53.20 & 56.73 & 51.86 & 57.77 & 53.28 & 55.66 & **68.39** \\    & Wikipedia & 54.20 & 57.15 & 54.14 & 54.39 & 57.89 & 57.36 & **62.86** \\  & Github & 75.72 & 47.52 & 75.87 & 73.08 & 76.17 & 77.31 & **99.64** \\   & ArXiv & 48.28 & **55.96** & 46.79 & 51.79 & 48.87 & 51.34 & 54.01 \\   & PubMed & 52.18 & 52.02 & 51.05 & 56.71 & 52.10 & 53.82 & **61.90** \\  

Table 2: AUC-ROC results for different MIAs on datasets in MIMIR dataset (Duan et al., 2024) where members and non-members share less than 80% overlap in 13-gram.

   &  &  &  &  &  &  &  &  &  &  \\    & & & & & & & & & & & \\   & 54.94 & 67.56 & 54.23 & 65.95 & 53.14 & 63.99 & 53.32 & 63.34 & 52.98 & 62.10 \\  & Ref & 52.73 & 58.29 & 51.71 & 56.42 & 49.92 & 53.74 & 50.07 & 53.86 & 49.70 & 52.91 \\
386 & Ref & 58.90 & 67.44 & 57.01 & 63.79 & 51.39 & 56.06 & 52.27 & 56.80 & 50.03 & 50.98 \\
387 & (Pythia 1.4B) & & & & & & & & & \\   & Zlib & 54.33 & 66.56 & 53.61 & 64.98 & 52.54 & 63.01 & 52.70 & 62.59 & 52.42 & 61.38 \\    & Nei & 55.83 & 72.06 & 55.17 & 70.78 & 53.87 & 69.13 & 53.51 & 68.34 & 53.08 & 67.36 \\    & Min-K (\(K=10\%\)) & 56.96 & 76.05 & 56.00 & 73.96 & 54.05 & 71.21 & 53.72 & 70.53 & 53.32 & 68.40 \\    & Min-K & 56.66 & 73.90 & 55.65 & 71.95 & 53.86 & 69.26 & 53.66 & 68.68 & 53.36 & 66.82 \\    & Min-K & 56.17 & 72.18 & 55.23 & 70.32 & 53.67 & 67.84 & 53.59 & 67.26 & 53.33 & 65.54 \\    & Min-K++ (\(K=10\%\)) & 56.83 & 78.47 & 54.77 & 76.17 & 52.37 & 72.38 & 51.73 & 72.93 & 51.57 & 69.87 \\    & Min-K++ (\(K=10\%\)) & 57.67 & 79.34 & 55.62 & 76.77 & 53.28 & 72.82 & 52.82 & 73.07 & 52.02 & 70.13 \\    & Min-K++ (\(K=30\%\)) & 57.76 & 78.96 & 55.81 & 76.21 & 53.62 & 72.27 & 53.21 & 72.46 & 52.41 & 69.52 \\    & Our SMIA & **67.39** & **93.35** & **64.63** & **92.11** & **60.65** & **89.97** & **59.71** & **89.59** & **58.92** & **87.43** \\  

Table 1: AUC-ROC performance metrics for various MIAs, including our SMIA, evaluated on different trained models (Pythia and GPT-Neo) using the Wikipedia. The table compares results for verbatim member data \(D_{}\) entries against non-member datasets \(D_{}^{}\) and \(D_{}^{}\).