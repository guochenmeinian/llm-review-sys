# Latent Neural PDE Solver for

Time-dependent Systems

Zijie Li, Saurabh Patil, Dule Shu, Amir Barati Farimani

Carnegie Mellon University

Mechanical Engineering Department

{zijieli, ssp2, dules}@andrew.cmu.edu & barati@cmu.edu

Equal contribution.

###### Abstract

Neural networks have shown promising potential in accelerating the numerical simulation of systems governed by partial differential equations (PDEs). Different from many existing neural network surrogates operating on the high-dimensional discretized field, we propose to learn the dynamics of the system in the latent space with much coarser discretization. In our proposed framework, a non-linear autoencoder is first trained to project the full-order representation of the system onto the mesh-reduced space, then a temporal model is trained to predict the future state in this mesh-reduced space. This reduction process simplifies the training of the temporal model by greatly reducing the computational cost with a fine discretization. We study the capability of the proposed framework on 2D/3D fluid flows and showcase that it has competitive performance compared to the model that operates on full-order space.

## 1 Introduction

Many intricate physical processes, from the interaction of protein dynamics to the movement of a celestial body, can be described by time-dependent partial differential equations (PDEs). The simulation of these processes is often conducted by solving these equations numerically, which requires fine discretization to resolve the necessary spatiotemporal domain to reach convergence. Deep neural network surrogates  recently emerged as a computationally less-expensive alternative, with the potential to improve the efficiency of simulation by relaxing the requirement for fine discretization and attaining a higher accuracy on coarser grids compared to classical numerical solver .

For time-dependent systems, many neural-network-based models address the problem by approximating the solution operator \(\) that maps the state \(u_{t}\) to \(u_{t+ t}\), where the input and output are sampled on discretization grid \(\{D_{i},D_{h}\}\) respectively. The input discretization grid can either remain unchanged between every layer inside the network , or fit into a hierarchical structure  that resembles the V-Cycle in classical multi-grid method. Hierarchical network structures have been a common model architectural choice in the field of image segmentation  and generation  given their capability for utilizing multi-scale information.

In contrast to the aforementioned approaches especially those that utilize a hierarchical grid structure, our work studies the effect of decoupling dynamics prediction from upsampling/downsampling processes. Specifically, the neural network for predicting the forward dynamics (which we defined as a propagator) only operates on the coarsest resolution, while a deep autoencoder is pre-trained to compress the data from the original discretization grid \(D_{i}\) to the coarse grid \(D_{l}\) (e.g. from a \(64 64\) grid to an \(8 8\) grid). As the propagator network operates on a lower dimensional space, the trainingcost is greatly reduced and can be potentially adapted to unrolled training with a longer rollout, which is often observed to be helpful to long-term stability [14; 21]. We parameterize the model with a convolutional neural network along with several other components that are popular in neural PDE solvers, including spectral convolution and several variants of attention. We test the proposed framework on 2D and 3D time-dependent PDEs with uniform grids and showcase that the model can achieve efficient data compression and accurate prediction of forward dynamics.

## 2 Related works

Neural PDE solverNeural PDE solvers can be categorized into the following groups based on their model design. The first group employs neural networks with mesh-specific architectures, such as convolutional layers for uniform meshes or graph layers for irregular meshes. These networks learn spatiotemporal correlations within PDE data without the knowledge of the underlying equations [5; 19; 28; 36; 38; 47; 58; 62; 63; 72; 75; 79; 82; 86]. Such a data-driven approach is useful for systems with unknown or partially known physics, such as large-scale climate modeling [33; 59; 66]. The second group, known as Physics-Informed Neural Networks (PINNs) [8; 9; 20; 22; 30; 40; 41; 49; 56; 65; 76; 93], treats neural networks as a representation of the solution function. PINNs incorporate knowledge of governing equations into the loss function, including PDE residuals and consistency with boundary and initial conditions. Unlike the first group, PINNs can be trained solely on equation loss and do not necessarily require input-target data pairs. The third group, known as the neural operators[1; 3; 4; 9; 17; 22; 29; 31; 32; 42; 44; 45; 48; 50; 54], is designed to learn the mapping between function spaces. For a certain family of PDEs, neural operators can generalize and adapt to multiple discretizations without retraining. DeepONet  presents a pragmatic implementation of the universal operator approximation theorem. Meanwhile, the concurrent research  in the form of the graph neural operator proposes a trainable kernel integral for approximating solution operators in parametric PDEs. Their follow-up work, Fourier Neural Operator (FNO) , has demonstrated high accuracy and efficiency in solving specific types of problems. Different function bases such as Fourier[15; 42; 80; 89] / wavelet bases, the column vectors from attention layers[9; 40], or Green's function approximation[2; 78], have been be used for operator learning. For more physically consistent predictions[46; 88], neural operator training can be combined with PINN principles.

Two-stage model for image compression and synthesisThe utilization of a two-stage model for image synthesis has gained significant attention in the field of computer vision in recent years. VQ-VAEs adopts a two-stage approach for generating images within a latent space. In the initial stage, the approach compresses images into this latent space, using model components such as an encoder, a codebook, and a decoder. Subsequently, in the second stage, a latent model is introduced to predict the latent characteristics of the compressed images, and the decoder from the first stage is used to transform the predicted latent representation back into image pixels. VQ-GANs is developed to scale autoregressive transformers to large image generation by employing adversarial and perceptual objectives for first-stage training. Most recently, several works have developed latent diffusion models with promising results ranging from image, point clouds to text generation. Within the domain of neural PDE solvers, the widely employed Encoder-Process-Decoder (EPD) scheme, used to map the input solution at time \(t\) to the subsequent time step, stands as a conventional and direct method [6; 27; 57; 61; 71; 74]. As an alternative, researchers have explored propagating the system dynamics in the latent space, aiming to diminish computational complexity and minimize memory usage [34; 90]. Evolving the system dynamics in latent space can involve utilization of recurrent neural networks like LSTM , linear propagators grounded in the assumptions of the Koopman operator [37; 51; 52; 55; 77], attention mechanism , recurrent MLPs  or state-space model . In this work, we propose to use an autoencoder to embed inputs into the latent space, and a simple yet effective convolutional propagator is employed to learn the dynamics of the time-dependent system within this latent space.

## 3 Methodology

### Problem definition

We are interested in solving time-dependent PDEs of the following form:

\[,t)}{ t} =F(u(,t),t),,t[0,T] \] \[u(,0) =u_{0}(),, \]

where \(T\) denotes the time horizon and some boundary condition for \(\) is provided _a priori_. To solve this initial value problem, a neural network is trained to approximate the following mapping:

\[u(,t+ t)=(u(,t)), \]

with a fixed \( t\), and the system is assumed to be Markovian such that \(u(,t+2 t)=((u(,t)))\).

In practice, the function of interest at a particular time step \(u(,t)\) is sampled on a \(m\)-point discretization grid \(D\). For a hierarchical model like U-Net, the grid will be altered internally between different layers and the mapping \(\) is a composition of a sequence of mapping \(\{_{0},,_{l}\}\) which operates on grids \(\{D_{0},,D_{l}\}\) with \(D_{0}=D\) and the number of grid points \(m_{l}<m_{l-1}<<m_{0}\). In contrast to the aforementioned hierarchical model, we propose to learn \(\) on the coarsest grid \(D_{l}\).

### Autoencoder for dimension reduction

One of the most straightforward ways to project the function from the original grid to a coarser grid is interpolation (_e.g._, bicubic interpolation). However, interpolation can result in significant information loss about the function, as a coarser grid can only evaluate a limited bandwidth and cannot distinguish frequencies that are higher than the Nyquist frequency. To achieve a less lossy compression of the input, we train an encoder network \(\) to project the input into latent space when coarsening its spatial grid. In the meantime, we train the decoder network \(\) to recover the input from the latent embedding that are represented on the coarse grid. The goal of training these two networks is to achieve data compression without too much loss of information such that their composition approximates an identity mapping: \(I\).

In this work, we exploit the fact that the grid structure we are dealing with is uniform and that the majority part of the autoencoder is parameterized with convolutional neural networks (CNN) which are effective for compressing imagery data [13; 69; 84]. On top of the CNNs modules, we also introduced several other modules that have been shown to be effective for PDE surrogate modeling.

Spectral convolutionSpectral convolution layer is first proposed in Fourier Neural Operator  as a parameterization of the learnable kernel integral . It applies a discrete Fourier transform to the input and then multiplies the \(k\)-lowest modes with learnable complex weights. Given input function \(u_{l}\), the spectral convolution computes the kernel integral as follows:

\[u_{l+1}(x)=_{}(x,y)u_{l}(y)dy=_{_{1}=0}^{_{1}^{ }}_{_{n}=0}^{_{n}^{}}W_{}_{j}f_{j}(x), j =_{1}_{2}_{n} \]

Figure 1: (a) An autoencoder is trained to project the input field to latent field with much coarser discretization. (b) A neural network is trained to predict the latent field at different time steps.

where \(W(_{n}^{}_{n}^{}..._{n}^{}) d_{ c} d_{c}\) is the learnable weight, \(f_{j}\) is the \(j\)-th Fourier basis function: \((2i_{d}_{d}}{m_{d}})\) with \(m_{d}\) being the resolution along the \(d\)-th dimension, \(x_{d}\) being the coordinate for \(d\)-th dimension, and \(_{j}=<u_{l},f_{j}>\) denotes the channel-wise inner product between input function and Fourier series. Unlike the CNN layer, spectral convolution is able to capture multi-scale features that correspond to different frequencies within a single layer. It is also computationally efficient on a uniform grid as the \(c_{j}\) can be efficiently computed via fast Fourier Transformation (FFT). In addition, Gupta and Brandstetter  hypothesized that suppressing high-frequency modes with spectral convolution before downsampling can further improve the performance of the network.

AttentionScaled-dot product attention  has become the state-of-the-art models for natural language processing  and computer vision tasks  with its capability to capture non-local interactions and compute data-dependent weights. Attention is also closely related to the kernel integral  defined in the previous subsection, with its theoretical property on specific PDE problems analyzed in several prior works. Given the \(i\)-th input feature vector \(_{i}\) with channel size \(d_{c}\), the (self-)attention can be defined as:

\[_{i}=_{j=1}^{m}_{ij}_{j},_{ij}= {(_{i}_{j}/})}{_{s=1}^ {m}(_{i}_{s}/})}, \]

where: \(_{i}=W_{q}_{i},_{i}=W_{k}_{i},_{i}=W_{v}_{i}\) respectively, and \(\{W_{q},W_{k},W_{v}\}^{d_{c} d_{c}}\) are learnable weights. We plug the self-attention layer into the decoder and investigate its effect on learning the latent embedding.

## 4 Experiments

We test out the proposed model on two time-dependent fluid problems and compared our model to a state-of-the-art neural PDE solver Fourier Neural Operator . For all the problems we sample the data on a spatial grid of resolution \(64\) along each axis.

### Datasets

2D incompressible flowThe 2D incompressible flow we considered here is the 2D flow dataset proposed in Li et al. , which is based on 2D Navier-Stokes equation under vorticity formulation. The vorticity form reads as:

\[,t)}{ t}+ (,t)(,t)&= ^{2}(,t)+f(),(0,1)^{2},t (0,T],\\ (,t)&=0,  (0,1)^{2},t[0,T],\\ (,0)&=_{0}(),  (0,1)^{2}, \]

where \(\) denotes vorticity: \(:= u\), the initial condition \(_{0}\) is sampled from the Gaussian random field, the boundary condition is periodic, the viscosity coefficient \(\) is \(1e-4\) and the forcing term is defined as: \(f()=0.1( 2(x_{1}+x_{2})+ 2(x_{1}+x_{2}))\). We are interested in learning to simulate the system (by predicting vorticity) from \(t=5\) to \(t=35\) with \(30\) seconds of time duration. The reference numerical simulation data is generated via the pseudo-spectral method. The dataset contains \(1000\) trajectories where we use \(900\) for training and \(100\) for testing.

3D smoke buoyancyThe second benchmark problem is 3D Navier-Stokes equation coupled with advection equation proposed in Li et al.  and similar 2D cases have been studied in prior works . The equation describes the motion of rising smoke in a closed box,

\[(,t)}{ t} +(,t)(,t)&= ^{2}(,t)- p(,t)+ (,t),(0,L)^{3},t(0,T],\\ ,t)}{ t}+(,t) d(,t)&=0,   \(d\) depicts a marker field for smoke and is subjects to the Neumann boundary condition: \( d/ n=0\), the velocity field \(\) is under Dirichlet boundary condition: \((,t)=0,\), the initial condition of the marker field \(d\) is sampled from a random field, the forcing term is based on the Bousinessq model \((,t)=[0,0, d(,t)]\) with \(\) being the buoyancy factor. We study the case with viscosity coefficient \(=0.003\) and buoyancy factor \(=0.50\). The goal is to predict the marker field and velocity field from \(t=0\) to \(t=12\), with domain size \(L=8\). The reference simulation data is generated using _phiflow_ with pressure projection and Macormack advection scheme . The dataset contains \(2200\) trajectories among which we use \(2000\) for training and \(200\) for testing.

### Implementation

AutoencoderThe encoder and decoder are mainly built upon convolutional layers. Internally they comprise a stack of downsampling/upsampling blocks, where each block downsamples/upsamples the spatial resolution by a factor of \(2\). Each block contains a residual convolution block and a downsampling/upsampling layer. The residual convolution block consists of group normalization  and two \(3 3\) convolution layers. the downsampling layer uses a \(3 3\) convolution layer with a stride of \(2\), and the upsampling layer upsamples the resolution by using nearest interpolation followed by a \(3 3\) convolution layer. We also investigate the influence of inserting spectral convolution layers into each downsampling block and add self-attention layers to the lowest resolution following prior works on image synthesis . For the \(2\)D problem, we set the latent resolution to \(8 8\) and the latent dimension to \(16\). For the \(3\)D problem, we set the latent resolution to \(16 16 16\) and the latent dimension to \(64\). In addition, on the \(3\)D problem, we use the multi-dimensional factorized attention  instead of standard attention to reduce the computational cost.

PropagatorWe use a simple residual convolution network  to forecast the forward dynamics in the latent space, where each residual block contains a group normalization layer and three convolution layers with \(3 3\) convolution kernels. We also employ dilated convolution for the middle convolution layer to capture longer-range interaction. For the \(2\)D problem, we use \(3\) residual blocks with network width \(128\). For the \(3\)D problem, we use \(4\) residual blocks.

BaselineOn the \(2\)D problem, we tested out two versions of the FNO. The first version is based on the hyperparameter provided in the original paper , where the model width is \(32\) and \(8\) lowest modes are used at each spectral convolution layer. We also test out a larger version with a width of \(64\) and use a mode number of \(16\). On the \(3\)D problem, we use a width of \(64\) and a mode number of \(12\) as increasing the mode number for 3D spectral convolution will drastically increase the model parameter (by cubic).

TrainingWe first train the autoencoder by minimizing the relative \(L^{2}\) reconstruction loss for around 150k iterations with constant learning rate \(3e-5\) using batch size of \(64/16\) respectively for 2D/3D. We then train the propagator by minimizing the mean squared error between predicted embeddings and embedding of reference data for another 150k iteration with a learning rate of \(5e-4\) and a cosine annealing schedule. For FNO we train it with a learning rate \(5e-4\) and a cosine annealing scheduling to minimize the relative \(L^{2}\) prediction loss. The total training iterations are also set to 150k. Different from the original FNO paper, we do not use full rollout during training as we observe reducing the rollout steps during training can significantly improve the performance on NS2D. * We rollout for 2 steps for all models unless stated otherwise.

Footnote *: On 2D Navier-Stokes, FNO (8 modes) has a prediction error of \(0.2596\) if using fully rollout training, whereas rolling out for 2 steps yields an error of \(0.1689\).

### Results

In this section, we present the comparison between the proposed framework and other models. We observe that the proposed model consistently outperforms FNO which operates on the full mesh space and for lower-dimensional problems like 2D fluid flow the performance gap is more significant. On more complex 3D flow, the model is able to compress the original data to a much coarser (4 times coarser) resolution and learns to predict with accuracy on par with full-order models. Furthermore, as the temporal model operates on a much coarser discretization, we can afford longer rollout training to allow gradient propagated from farther future which can further improve the model's performance on predicting the equilibriium state of the smoke marker field (Figure 1(c)). (Sample visualization of the best model's prediction are presented in Appendix A)

We also study how different training strategies will influence the model's performance (Figure 1(b)). We maintain consistent hyperparameters and explore three training strategies: the two-stage method discussed in the previous subsection (referred to as "two-stage"), training the autoencoder and propagator simultaneously by minimizing both reconstruction and prediction loss jointly (referred to as "combined"), and considering the autoencoder and propagator as an unified entity to predict the subsequent step (referred to as "autoregressive"). We also compare two-stage training to Dilated-ResNet  that employs a Encode-Process-Decode (EPD) scheme . We find that two-stage training yields the best performance compared to other strategies, which indicates the advantage of two-stage training in obtaining high-quality coarse-graining of the system.

    &  &  &  &  \\    & & Autoencoder & & & Autoencoder & Propagator \\  Fwd + Bwd time (sec) & 0.067 & 0.103 & 0.013 & 2.223 & 1.375 & 0.372 \\ Memory (GB) & 1.87 & 2.54 & 0.25 & 33.33 & 37.15 & 8.10 \\ \# of params (M) & 16.8 & 9.7 & 1.4 & 226.5 & 38.8 & 5.4 \\   

Table 1: Computational cost of different models’ training. 2D benchmark is carried out on RTX 3090, using a batch size of 64. 3D benchmark is carried out on A6000, using a batch size of 16.

Figure 2: Quantitative study on model’s performance. Latent-PDE denotes our proposed latent neural PDE solver. “Base” model contains only residual convolutional blocks and fully-connected layers. “CoarseAttn” means we add self-attention to the bottleneck part of the model. “Full-Fourier” means we add spectral convolution layers at the top two downsampling blocks in the encoder and decoder of “CoarseAttn” model. “Res” means we replace spectral convolution layer with residual convolutional blocks. x-step models are rollout for x steps during the training.

Compared to FNO that has log-linear complexity with respect to the grid size, the training of the proposed model is relatively slower when combining the time cost for autoencoder training and temporal model training. However, since the temporal model training is much more efficient in latent-pde solver, its training can be less costly on system that requires rolling out for more steps during training.

## 5 Conclusion

In this work, we study a straightforward yet effective data-driven framework for predicting time-dependent PDEs. We show that training the temporal model in the mesh-reduced space improves the computation efficiency and is beneficial for problems that feature latent dynamics distributed on a low-dimensional manifold. The observation in this study is also in alignment with the recent success of a series of image synthesis models that learn the generative model in the latent space instead of pixel space [13; 68; 83]. As this work only considers uniform mesh, an interesting future direction would be the extension to arbitrary meshes and geometries.