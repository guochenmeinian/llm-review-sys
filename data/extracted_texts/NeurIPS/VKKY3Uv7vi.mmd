# BPQP: A Differentiable Convex Optimization Framework for Efficient End-to-End Learning

Jianming Pan\({}^{1}\), Zeqi Ye\({}^{2}\),

Xiao Yang\({}^{3}\), Xu Yang\({}^{3}\), Weiqing Liu\({}^{3}\), Lewen Wang\({}^{3}\), Jiang Bian\({}^{3}\)

\({}^{1}\)University of California, Berkeley, \({}^{2}\)Nankai University

\({}^{3}\)Microsoft Research Asia

jianming_pan@berkeley.edu, lianmyzq@gmail.com

{xiao.yang, xuyang1, weiqing.liu, lewen.wang, jiang.bian}@microsoft.com

Work done during an internship at Microsoft.Corresponding Author

###### Abstract

Data-driven decision-making processes increasingly utilize end-to-end learnable deep neural networks to render final decisions. Sometimes, the output of the forward functions in certain layers is determined by the solutions to mathematical optimization problems, leading to the emergence of differentiable optimization layers that permit gradient back-propagation. However, real-world scenarios often involve large-scale datasets and numerous constraints, presenting significant challenges. Current methods for differentiating optimization problems typically rely on implicit differentiation, which necessitates costly computations on the Jacobian matrices, resulting in low efficiency. In this paper, we introduce BPQP, a differentiable convex optimization framework designed for efficient end-to-end learning. To enhance efficiency, we reformulate the backward pass as a simplified and decoupled quadratic programming problem by leveraging the structural properties of the Karush-Kuhn-Tucker (KKT) matrix. This reformulation enables the use of first-order optimization algorithms in calculating the backward pass gradients, allowing our framework to potentially utilize any state-of-the-art solver. As solver technologies evolve, BPQP can continuously adapt and improve its efficiency. Extensive experiments on both simulated and real-world datasets demonstrate that BPQP achieves a significant improvement in efficiency--typically an order of magnitude faster in overall execution time compared to other differentiable optimization layers. Our results not only highlight the efficiency gains of BPQP but also underscore its superiority over differential optimization layer baselines.

## 1 Introduction

In recent years, deep neural networks have increasingly been used to address data-driven decision-making problems and to generate final decisions for end-to-end learning tasks. Beyond explicit forward functions, some layers of the network may be characterized by behaviors of implicit outputs, such as the solutions to mathematical optimization problems, which can be described as differentiable optimization layers . These can be treated as implicit functions where inputs are mapped to optimal solutions. In this manner, the network can incorporate useful inductive biases, including domain-specific knowledge, physical structures, and priors, thereby enabling more accurate and reliable decision-making. This approach has been integrated into deep declarative networks  for end-to-end learning and has proven effective in various applications, such as energy minimization [3; 4] and predict-then-optimize [5; 6] problems. Here, we focus on convex optimization due toits broad applications in fields such as portfolio optimization , control systems , and signal processing , among others.

Optimization problems typically lack a general closed-form solution; therefore, calculating gradients for relevant parameters requires more sophisticated methods. These methods can be categorized based on whether an explicit computational graph is constructed, namely into explicit unrolling and implicit methods. Explicit methods [4; 10; 11; 12] involve unrolling the iterations of the optimization process, which incurs additional computational costs. Conversely, implicit methods leverage the Implicit Function Theorem  to derive gradients. Some of these methods [14; 1; 15] are tailored for specific problems, thus restricting the options for forward optimization and reducing efficiency. Alternatively, other approaches [2; 10] offer more general solutions for deriving gradients but face inefficiencies during the backward pass. There remains substantial potential for enhancing efficiency in these methodologies.

To enable rapid, tractable differentiation within convex optimization layers and further enhance the capabilities of the end-to-end learning paradigm, we propose a general, first-order differentiable convex optimization framework, which we refer to as the **B**ackward **P**ass as a **Q**udratic **P**rogramming (BPQP). Specifically, BPQP simplify the backward pass for the parameters of the optimization layer, by reformulating first-order condition matrix into a simpler Quadratic Programming (QP) problem. This decouples the forward and backward passes and creates a framework that can leverage existing efficient solvers (with the first-order algorithm, Alternating Direction Method of Multipliers (ADMM) , as the default) that do not require differentiability in both passes. Simplifying and decoupling the backward pass significantly reduces the computational costs in both the forward and backward passes. This key idea is summarized in Fig. 1.

Our proposed framework has several theoretical and practical advantages:

* **Novel Backward Pass Reformulation:** Our framework BPQP decouples the backward pass from the forward pass of the convex optimization layer, then reforms the backward pass process to a simple QP problem. The method avoids solving the linear system involving the Karush-Kuhn-Tucker (KKT) matrix and enables _large-scale gradients computation_ via ADMM. It leverages structural traits such as sparsity, solution polishing , and active-sets  for efficient and accurate gradients computation.
* **Efficient Gradients Computation:** Empirically, BPQP significantly improves the overall computational time, achieving up to \(13.54\), \(21.02\), and \(1.67\) faster performance over existing differentiable layers on 100-dimension Linear Programming, Quadratic Programming, and Second Order Cone Programming, respectively. Such efficiency improvements pave the way for BPQP's application in large-scale real-world end-to-end learning scenarios, such as portfolio optimization. By adopting BPQP, the enhancement of the Sharpe ratio has increased from 0.65 (\(\)0.25) to 1.28 (\(\)0.43) compared to the widely-adopted two-stage approach methods.

Figure 1: The learning process of BPQP: the previous layer outputs \(y\) and generates the optimal solution \(z^{}\) in the forward pass; the backward pass propagates the loss gradient for end-to-end learning; the process is accelerated by reformulating and simplifying the problem first and then adopting efficient solvers.

* **Flexible Solver Choice:** BPQP accommodates any general-purpose convex solver to integrate the differentiable layer for end-to-end training. This flexibility in solver choice allows for better matching of solver capabilities with specific problem structures, potentially leading to improved efficiency and performance.

## 2 Related works

Explicit methodsOptimization problems typically do not have a general closed-form solution formula that expresses the decision variable in terms of other parameters. To address this challenge, explicit methods [4; 10; 11] unroll the iterations of the optimization process and use the decision variable from the final iteration as a proxy solution for the optimization problem. This constructs an explicit computational graph from the parameters to the proxy parameters, then calculate relevant gradients. Typically, these methods are designed for unconstrained optimizations. Applying them directly to constrained optimizations is computationally expensive because it requires projecting decision variables into a feasible region. Alt-Diff  is a novel unrolling solution that decouples constraints from the optimization and significantly reduces the computational cost. While advanced unrolling methods continue to improve their efficiency, they require an additional cost in the unrolled computational graph that increases with the number of optimization iterations.

Implicit methodsIn contrast, implicit methods use the Implicit Function Theorem to relate the decision variable to other parameters. These methods specifically apply the theorem to KKT conditions in convex optimization. _Specificity-driven approaches_ are often tailored for particular problems in convex optimization such as QP, offering good efficiency but sacrificing generality. OptNet  presented a differentiable batched-GPU QP solver. An ADMM layer is also developed for QP . It facilitates implicit differentiation through a custom fixed-point mapping, reducing the cost by reducing the dimensions of the linear system to be resolved. _Generality-focused approaches_ pursued more generalized solutions but faced limitations in efficiency, performing poorly on large-scale optimization problems. Their solution processes often rely on specific methods (such as coupled forward and backward passes), which prevent the application of various optimizers, thus leading to the aforementioned efficiency issues. Diffcp [1; 15] considers computing the derivative of a convex cone program by implicitly differentiating the residual map for its homogeneous self-dual embedding. Open-source convex solver CVXPY  adopts a similar method and computes gradients by SCS . JaxOpt  proposes a simple approach to adding implicit differentiation on top of any existing solver, which significantly lowers the barrier to using implicit differentiation. Our work, BPQP, based on implicit methods, can be efficiently and broadly applied to convex optimization problems. We simplify the backward pass by reformulating it into a simpler, decoupled QP problem. This decoupling grants BPQP the freedom to choose an optimizer and, in conjunction with problem simplification, greatly reduces the computational cost in both the forward and backward passes. Notably, some work also examine discrete optimization challenges [21; 22], which are outside the purview of our study.

## 3 Background

### Differentiable convex optimization layers

We will now provide some background information for the differentiable convex optimization layers.

Suppose the differentiable convex optimization layer has its input \(y^{p}\), output \(z^{*}^{d}\), we define the layer with the standard form of a convex optimization problem parameterized by \(y\).

**Definition 1** (Differentiable Convex Optimization Layer).: Given the input \(y^{p}\), output \(z^{*}^{d}\), a differentiable convex optimization layer is defined as

\[z^{*}(y)= _{z^{d}}f_{y}(z)\] s.t. \[h_{y}(z)=0,\] \[g_{y}(z) 0,\]

where \(y\) is the parameter vector of the objective functions and the constraints, \(z\) is the optimization variable, \(z^{*}\) is the optimal solution to the problem; The functions \(f:^{p}\) and \(g:^{n}\)are convex, and the function \(h:^{m}\) is affine. The functions \(f,h,\) and \(g\) are continuously differentiable _w.r.t_ both \(y\) and \(z\), enabling the computation of \(}{ y}\),.

The gradient of the parameter vector \(y\) can be computed by combining the chain rule with the Implicit Function Theorem (IFT) . Within the deep learning architecture, optimization layers are integrated alongside explicit layers within an end-to-end framework. Given the global loss function \(\), the derivative of \(\)_w.r.t_\(y\) can be written as

\[}{ y}=}{ z ^{*}}}{ y}.\]

We can easily obtain the derivative \(}{ z^{*}}\)through conventional automatic differentiation techniques applied to explicit layers. However, challenges arise in calculating \(}{ y}\), the gradient of an implicit optimization layer. Considering the layer as an implicit function \((z^{*},y)=0\), recent studies such as OptNet  employ the IFT on the KKT conditions of the convex optimization problem to derive \(}{ y}\). We state IFT here as a lemma for reference.

**Lemma 1** (Implicit Function Theorem).: _Consider a continuously differentiable function \((z,y)\) with \((z^{*},y)=0\), and suppose the Jacobian matrix of \(\) is invertible at a small neighborhood at \((z^{*},y)\), we have_

\[}{ y}=-[_{}(z)]^{-1}_{}(y),\]

_where \(_{}(z)\) and \(_{}(y)\) are respectively the Jacobian matrix of \(\) w.r.t \(z\) and \(y\)._

It should be emphasized that the differentiation of the KKT conditions requires calculating the optimal value \(z^{*}\) in the forward pass and necessitates solving linear systems involving the Jacobian matrix in the backward pass. Both phases--forward and backward--are notably computationally intensive, particularly for large-scale problems. As a result, differentiating through KKT conditions directly does not scale efficiently to extensive optimization challenges.

### Differentiating Through KKT Conditions

To differentiate KKT conditions more efficiently, CvxpyLayer  has adopted the LSQR technique to accelerate implicit differentiation for sparse optimization problems. However, this method may not be efficient for more general cases, which might not exhibit sparsity. Although OptNet  employs a primal-dual interior point method in the forward pass, making its backward pass relatively straightforward, it is suitable only for quadratic optimization problems.

In this paper, our main target is to develop a new method that can increase the computational speed of the differentiation procedure especially for general large-scale convex optimization problems.

We consider a general convex problem as defined in Definition 1. To compute the derivative of the solution \(z^{*}\) to parameter \(y\), we follow the procedure of  to differentiate the KKT conditions using techniques from matrix differential calculus. Following this method, the Lagrangian is given by (omitting \(y\)),

\[L(z,,)=f(z)+^{}h(z)+^{}g(z),\] (1)

where \(^{m}\) and \(^{n},\)\( 0\) respectively denotes the dual variables on the equality and inequality constraints. The sufficient and necessary conditions for optimality of the convex optimization problem are KKT conditions. Applying the IFT (Lemma 1) to the KKT conditions and let \(P(z^{},^{},^{})=^{2}f(z^{})+^{2}h( z^{})^{}+^{2}g(z^{})^{}\), \(A(z^{})= h(z^{})\) and \(G(z^{})= g(z^{})\). Let \(q(z^{},^{},^{})=( f(z^{})+ h (z^{})^{}+ g(z^{})^{})/ y\), \(b(z^{})= h(z^{})/ y\) and \(c(z^{},^{})=(D(^{})g(z^{}))/ y\). Then the matrix form of the linear system can be written as:

\[[P(z^{},^{},^{})&G(z^{ })^{}&A(z^{})^{}\\ D(^{})G(z^{})&D(g(z^{}))&0\\ A(z^{})&0&0][}{ y}\\ }{ y}\\ }{ y}]=-[q(z^{},^{},^{})\\ c(z^{},^{})\\ b(z^{})],\] (2)

\(D():^{n}^{n n}\) represents a diagonal matrix that formed from a vector and \(z^{},^{},^{}\) denotes the optimal primal and dual variables. Left-hand side is the KKT matrix of the original optimization problem times the Jacobian matrix of primal and dual variables to \(y\), e.g., \(}{ y}^{d p}\). Right-hand side is the negative partial derivatives of KKT conditions to the \(y\).

We can then backpropagate losses by solving the linear system in Eq. (2). In practice, however, explicitly computing the actual Jacobian matrices \(}{ y}\) is not desirable due to space complexity; instead,  products previous pass gradient vectors \(}{ z^{*}}^{d}\), to reform it by notations \([^{d},^{m}, ^{n}]\) (see Appendix A.3):

\[[P(z^{},^{},^{})&G(z^{}) ^{}&A(z^{})^{}\\ D(^{})G(z^{})&D(g(z^{}))&0\\ A(z^{})&0&0][\\ \\ ]=-[(}{ z^{*}})^{}\\ 0\\ 0].\] (3)

And the direct gradients \(_{y}^{p}=[q(z^{},^{},^{ }),c(z^{},^{}),b(z^{})][,, ]^{}\).

## 4 Methodology

### Backward Pass as QPs

Our approach solves Eq. (3) using reformulation. Consider a general class of QPs that have \(d\) decision variables, \(m\) equality constraints and \(n\) inequality constraints:

\[*{minimize}_{}^{}P^{} +q^{} s.t.\;A^{}=b^{}, \;G^{} c^{},\] (4)

where \(P^{}^{d}_{+}\), \(q^{}^{d}\), \(A^{}^{m d}\), \(b^{}^{m}\), \(G^{}^{n d}\) and \(c^{}^{n}\). KKT conditions write down in matrix form:

\[[P^{}&G^{}&A^{}\\ D()G^{}&D(G^{}-c)&0\\ A^{}&0&0][\\ \\ ]=[-q^{}\\ D()c^{}\\ b^{}].\] (5)

We note that Eq. (5) is equivalent to Eq. (3) if and only if: (i) \(P^{}=P(z^{},^{},^{}),\;A^{}=A(z^{}), \;D()G^{}=D(^{})G(z^{}),\;[-q^{},D()c^{},b^{}]=[-(}{  z^{}})^{},0,0]\) and (ii) \(P(z^{},^{},^{})\) is positive semi-definite. However, \(D()G^{}=D(^{})G(z^{})\), which contains the unknown variable \(\), may not hold. As the backward pass solves after the forward pass, we can change inequality constraints to an accurate active-set (i.e., a set of binding constraints) of equality conditions, and then condition (i) always holds for the equality-constrained QP. From this, the following theorem can be obtained (The detailed proof can be found in Appendix A.2)

**Theorem 1**.: _Suppose that the convex optimization problem in Definition 1 is not primal infeasible and the corresponding Jacobian vector \(_{y}\) exists. It is given by \(_{y}=[q(z^{},^{},^{}),c(z^{}, ^{}),b(z^{})][,,]^{}\) and \(,,\) is the optimal solution of following equality constrained Quadratic Problem:_

\[*{minimize}_{}^{}P^{} {z}+q^{}\;A^{}=b^{}, \;G^{}_{+}=c^{}_{+}.\] (6)

_Where \(P^{}=P(z^{},^{},^{}),\;A^{}=A(z^{}), \;G^{}_{+}=G_{+}(z^{})\) and \([-q^{},c^{}_{+},b^{}]=[-(}{  z^{}})^{},0,0]\). \(^{}\) and \(\) only keep the elements according to the active-set after rewriting the inequality constraints to equality constraints. We did not create new notations for the sake of simplicity._

Though our BPQP procedure described above also applies to Jacobians with forms other than vectors, e.g., matrices, in these cases where each 1-dimension column in \([,,]^{}\) right multiply the same KKT matrix and can be viewed as QPs packed in multi-dimensions, directly calculating the _inverse_ of the KKT matrix may be more appropriate, especially when it contains a special structure like OptNet  and SATNet .

**General Gradients** The intuition of BPQP is that the linearity of IFT requires the KKT matrix left-multiply homogeneous linear partial derivative variables. Theorem 1 highlights a special situation that considers gradients at the optimal point (where KKT conditions are satisfied). Generally, BPQPprovides perspective to define gradients in parameter-solution space that preserves KKT norm. Let us consider a series of vectors denoting the \(k\)th iteration norm value of KKT conditions:

\[\|r^{(k)}\|=\|(r^{(k)}_{dual},r^{(k)}_{cent},r^{(k)}_{prim})\|=C_{k}.\] (7)

Where \(r^{(k)}^{d+m+n}\) the KKT conditions in \(k\)th iteration and \(C_{k}\) the norm value. The series \(\{C_{0},C_{1},...,C_{k}\}\) converges to \(0\) if the iteration algorithm is a contraction operator. Let \(^{(k)}\) denote standard QP problem w.r.t. parameter \(P_{k},q_{k},A_{k},b_{k},G_{k},c_{k}\) and decision variable \(z_{k}\). At each iteration, BPQP yields \(_{y}^{(k)}\) that preserves \(\|r^{(k)}\|=C_{k}\). (See in Appendix A.4)

**Time Complexity** The time complexity of solving such QP is \((N^{3})\) in the number of variables and constraints which is at the same level as directly solving the linear system Eq. (3). However, reformulation as QP provides substantial structures that can be exploited for efficiency, such that (we cover them in Section 4.2) sparse matrix, solution polishing , active-sets, and first-order methods, etc. Cleverly implementing BPQP, experiments at fairly large-scale dimensions in practice highlight BPQP's capacity in comparison to the state-of-art differentiable solver and NN-based optimization layers. Intuitively, BPQP is more efficient than previous methods because it utilizes the convex QP structural trait in the backward pass.

### Efficiently Solve Backward Pass Problem with OSQP

The solver we referenced is OSQP , which incorporates the sparse matrix method and uses a first-order ADMM method to solve QPs, which we summarize below. On each iteration, it refines a solution from an initialization point for vectors \(z^{(0)}^{d},\;^{(0)}^{m}\), and \(^{(0)}^{n}\). And then iteratively computes the values for the \(k+1\)th iterates by solving the following linear system:

\[[P+ I&A^{}\\ A&()^{-1}][z^{(k+1)} \\ v^{(k+1)}]=[ z^{(k)}-q\\ ^{(k)}-()^{-1}^{(k)}],\] (8)

And then performing the following updates:

\[^{(k+1)} ^{(k)}+()^{-1}(v^{(k+1)}- ^{(k)})\] \[^{(k+1)} (^{(k+1)}+()^{ -1}^{(k)}),\] (9) \[^{(k+1)} ^{(k)}+()(^{( k+1)}-^{(k+1)})\]

where \(_{+}\) and \(_{+}^{n}\) are the _step-size_ parameters, and \(:^{m}^{m}\) denotes the Euclidean projection onto constraints set. When the primal and dual residual vectors are small enough in norm after \(k\)th iterations, \(z^{(k+1)},^{(k+1)}\) and \(^{(k+1)}\) converges to exact solution \(z^{},^{}\) and \(^{}\).

In particular, given a backward pass problem Eq. (6) with known active constraints, as stated in OSQP, we form a KKT matrix below3:

\[[P+ I&G_{+}^{}&A^{}\\ G_{+}&- I&0\\ A&0&- I][\\ _{+}\\ ]=[-q\\ 0\\ 0],\] (10)

As the original KKT matrix is not always invertible, e.g., if it has one or more redundant constraints, we modify it to be more robust for QPs of all kinds by adding a small regularization parameter \(D(P+ I,- I,- I)\) (in Eq. (10)) as default \( 10^{-6}\). We could then solve it with the aforementioned ADMM procedure to obtain a candidate solution, denoted as \(\) and recover the exact solution \(t\) from the perturbed KKT conditions \((K+ K)=g\) by iteratively solving:

\[(K+ K)^{k}=g-K^{k}.\] (11)

where \(^{k+1}=^{k}+^{k}\) and it converges to \(t\) quickly in practice  for only one backward and one forward solve, which helps BPQP solve backward pass problems in a general but efficient way.

We have implemented BPQP with some of the use cases and have released it in the open-source library Qlib (https://github.com/microsoft/qlib).

### Examples: Differentiable QP and SOCP

Below we provide examples for differentiable QP and SOCP oracles (i.e. solutions) using BPQP. The general procedure is to first write down KKT matrix of the original decision making problem. And then apply Theorem 1. Assuming the optimal solution \(z^{}\) is already obtained in forward pass.

Differentiable QPWith a slight abuse of notation, given the standard QP problem with parameters \(P,q,A,b,G,c\) as in Eq. (4). The result is exactly the same as OptNet  since both approaches are for accurate gradients. But BPQP is capable of efficiently solving large-scale QP forward-backward pass via ADMM , as shown in Section 5.1.

\[_{Q}=(} ^{T}+{z^{}}^{T})&_{q}=&_{A }=}^{T}+^{}^{T}\\ _{b}=-&_{G_{+}}=D(_{+}^{ })}^{T}+_{+}^{}^{T}& _{c_{+}}=-D(_{+}^{})\] (12)

And \([,,]\) solves

\[*{minimize}_{}^{}P+ ^{}}{}}A=0,\ G_{+}=0.\] (13)

Differentiable SOCPThe second-order cone programming (SOCP) of our interest is the problem of robust linear program :

\[*{minimize}_{z}q^{}z\;a_{i}^{}z+\|z\|_{2 } b_{i}\;i=1,2,...,m.\] (14)

where \(q^{d}\), \(a_{i}^{d}\), and \(b_{i}\). With \(m\) inequality constraints in \(L_{2}\) norm, we give the gradients w.r.t. above parameters.

\[_{q}=_{a_{i}+}=_{i+}^{ }+_{i+}^{}_{i}{z^{}}^{} _{c_{+}}=_{i},\;i=1,2,...,m.\] (15)

And \([,,]\) are given by (\(t_{1}=_{i}_{i+}^{}\) and \(t_{0}=\|{z^{}}\|_{2}\))

\[*{minimize}_{}^{}(}{t_{0}}-}{t_{0}^{3}}{z^{}}^{})+}{}} \;(a_{i+}^{}+}{z^{}})^{T}=0,\;i=1,2,...,m.\] (16)

## 5 Experiments

In this section, we present several experimental results that highlight the capabilities of the BPQP. To be precise, we evaluate for (i) large-scale computational efficiency over existing solvers on random-generated constrained optimization problems including QP, LP, and SOCP, and (ii) performance on real-world end-to-end portfolio optimization task that is challenging for existing end-to-end learning approaches.

### Simulated Large-scale Constrained Optimization

We randomly generate three datasets (e.g. simulated constrained optimization) for QPs, LPs, and SOCPs respectively. The datasets cover diverse scales of problems. The problem scale includes \(10 5\), \(50 10\), \(100 20\), \(500 100\) (e.g., \(10 5\) represents the scale of 10 variables, 5 equality constraints, and 5 inequality constraints). Please refer to more experiment details in Appendix A.5.

QPs DatasetThe format of generated QPs follows Eq. (6) to which the notations in the following descriptions align. We take \(q\) as the learnable parameter to be differentiated and \(=^{}z^{}\) in Eq. (3). To generate a positive semi-definite matrix \(P\), \(P^{}P^{}+ I\) is assigned to \(P\) where \(P^{}^{d d}\) is a randomly generated dense matrix, \( I\) is a small regularization matrix, and \(=10^{-6}\). Potentially, we set \(c=Gz^{},\ G^{m n},\ z^{}^{n}\) to avoid large slackness values that lead to inaccurate results. All other random variables are drawn i.i.d. from standard normal distribution \(N(0,1)\).

LPs DatasetThe LP problems are generated in the format below

\[*{minimize}_{z}\;^{T}z+\|z\|_{2}^{2}\;\;\;Az=b,Gz h.\] (17)

where \(^{d}\) is the learnable parameter to be differentiated, \(z^{d}\), \(A^{n d}\), \(b^{n}\), \(G^{m d}\), \(h^{m}\) and \(_{+}\). All random variables are drawn from the same distribution as the QPs dataset.

It is noteworthy that it contains an extra item \(\|z\|_{2}^{2}\) compared with traditional LP. This item is added to make the optimal solution \(z^{}\) differentiable with respect to \(\). Without this item, \(P(z^{},^{},^{})\) is always zero and thus the left-hand side matrix becomes singular in Eq. (2). This is a trick adopted by previous work , and here we set \(=10^{-6}\) as default.

**SOCPs Dataset** For SOCP in Eq. (14), we consider a specific simple case, i.e. \(a_{i}=0\)\( i\) and this relaxations results in \(m=1\). As in QP and LP, we take \(q\) as differentiable parameter and set loss function \(=^{}z^{}\), but all variables are drawn i.i.d. from standard Gaussian distribution \(N(0,1)\).

**Compared Methods** To demonstrate the effectiveness of BPQP, we evaluate the efficiency and accuracy of state-of-the-art differentiable convex optimizers, as well as **BPQP**, on the datasets mentioned above. The following methods are compared: **CVXPY**, **qpth/OptNet**, **Alt-Diff**, **JAXOpt** and **Exact**. Exact adopts the same algorithm as BPQP for the forward pass, but attempts to calculate exact gradients using direct matrix inversion on the KKT matrix during the backward pass.

**Evaluation and Metrics** To evaluate the efficiency of the compared methods, the runtime in seconds is used for each forward pass, backward pass, and total process. To evaluate the accuracy, we first get a target solution \(z^{}\) with a high-accuracy method and then calculate the cos similarity with compared methods (\(=z^{} z^{,}/(\|z^{}\| *\|z^{,}\|)\)). We ran each instance 200 times for average and standard deviation (marked in brackets) of the metrics.

**Results** The results for efficiency evaluation are shown in Table 1. The evaluation covers three typical optimization problems with different problem scales. The results start from the QP dataset. Compared with state-of-the-art accurate methods, BPQP achieves tens to thousands of times of speedup in total time. We visualize part of the results of Table 1 in Figure 2, and perform sensitivity analysis under 500x100 setting in Figure 3, where the horizontal axis represents (tolerance, maximum iterations) of the methods. These results demonstrates the efficiency and robustness of BPQP. When the problem becomes large, such as 5000x2000, previous methods fail to generate results. CVXPY is extremely much slower because it reformulates the QP as a conic program and the reformulation is slow and has to be done repeatedly when the problem parameters change . It is worth noting that BPQP is faster even in the backward pass, where CVXPY and qpth/OptNet share information from the forward pass to reduce computational costs. Sharing this information will limit the available forward solvers and result in a coupled design. Exact falls back to a simpler implementation that does not involve sharing information between designs. It solves the KKT matrix (i.e., Eq. (3)) in the backward pass via a matrix inverse method without relying on information from the forward pass. Although Exact uses a relatively efficient implementation in the forward pass (i.e., a first-order method, same as BPQP), the fallback backward implementation becomes a bottleneck for efficiency. The results of the LP dataset lead to similar conclusions as those of the QP dataset.

   & & & &  &  \\ dataset & metric & & & & & & & & & \\  & & & & & & & & & & \\  QP & abs. time & Exact & 37.2(81.90) & 38.14(455.5) & 40.2(8110.6) & 38.27(1241.4) & 38.2(8148.1) & 157.9(856.0) & 48.2(4117.8) & 3495.5(4464.1) \\ (small) & (scale 10-60) & CVXPY & 34.1(45.15) & 34.1(262.15) & 627.6(2841.1) & 30.58(487.17) & 33.2(827.72) & 34.6(2410.13) & 100.2(824.95) & 34716.2(8148.4) \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & & & \\  LP & abs. time & Exact & 37.2(81.90) & 38.14(455.5) & 40.2(8110.6) & 38.2(110.6) & 38.2(110.6) & 38.2(110.6) & 38.42(117.8) & 3495.5(4464.1) \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\  SOP & abs. time & Exact & 3.2(81.5) & 3.4(26.6) & 3.1(210.6) & 38.1(110.6) & 37.1(110.3) & 35.2(110.6) & 38.4(110.3) & 38.2(110.6) & 38.2(1119.5) \\  & & & & & & & & & & & & \\  & & & & & & & & & & & & \\  & & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & & \\  

Table 1: Efficiency evaluation of methods by runtime in seconds based on 200 runs, with lower numbers indicating better performance.

   & & & &  &  \\ dataset & metric & & & & & & & & \\  & & & & & & & & & \\  & & & & & & & & & \\  & & & & & & & & & & \\  & & & & & & & & & \\  & & & & & & & & & \\  & & & & & & & & & \ the evaluation of the SOCP dataset, qpth/OptNet and Alt-Diff focus on QP and are excluded from this non-QP setting. Due to the specialty of SOCP, CVXPY does not require problem reformulation into conic programs, giving it an advantage. BPQP still outperforms other options in terms of total time across all problem scales.

The accuracy evaluation results are shown in Table 1. In the forward pass, all solvers give nearly the same results, which are not shown in the table. When evaluating the backward accuracy, we use a matrix inverse method with high precision to solve Eq. (3) directly to get a target solution(i.e. \(z^{Exact}\)) and compare solutions from evaluated methods against it. The \(CosSim.\) is relatively higher than that in the forward pass due to accumulated computational errors. Among them, the \(CosSim.\) of our method BPQP is the highest in QP. The \(CosSim.\) of all methods are small enough for SOCP.

### Real-world End-to-End Portfolio Optimization

Portfolio optimization is a fundamental problem for asset allocation in finance. It involves constructing and balancing the investment portfolio periodically to maximize profit and minimize risk. The problem is an important use case of end-to-end learning and can also be solved utilizing differentiable convex optimization layers . We now show how to apply BPQP to the problem of end-to-end portfolio optimization (more experiment details in Appendix A.6).

**Mean-Variance Optimization (MVO)** is a basic portfolio optimization model that maximizes risk-adjusted returns and requires long only and budget constraints.

\[}\ ^{}w-w^{} w \ \ \ \ ^{}w=1,\ w 0.\] (18)

where variables \(w^{d}\) represent the portfolio weight, \(>0\), the risk aversion coefficient, and \(^{d}\) the expected returns are the parameters to be predicted (under our setting, the input to the optimization layer) of the convex optimization problem. The covariance matrix, \(\), of all assets can be learned end-to-end by BPQP. However, it preserves a more stable characteristic than returns in time-series . Therefore, we set it as a constant.

**Benchmarks** We evaluate BPQP based on the most widely used predictive baseline neural network, MLP. For the learning approach, we compared the separately two-stage(**Two-Stage**) and differentiable convex optimization layer approaches(**qpth/OptNet**). The optimization problem in the experiment has a variable scale of 500, which cannot be handled by other layers based on CVXPY and JAXOpt. We found the tolerance level for truncation in Alt-Diff hard to satisfy the 500 inequality constraints and yield a relatively longer training time (588 minutes per training epoch) than the above benchmarks. Our implementation substantially lowers the barrier to using convex optimization layers.

#### 6.2.2 Results

The overall results are shown in Table 4. As we can see in the prediction metrics, Two-Stage performs best. Instead of minimizing multiple objectives without a non-competing guarantee, Two-Stage only focuses on minimizing the prediction error and thus avoids the trade-off between different objectives. However, achieving the best prediction performance does not equal the best decision performance. BPQP outperforms Two-Stage in all portfolio metrics, although its prediction performance is slightly compromised. qpth/OptNet shows comparable performance with BPQP. But the average training time of BPQP is 2.75x faster than OptNet. These experiments demonstrate the superiority of end-to-end learning, which minimizes the ultimate decision error, over separate two-stage learning.

## 6 Further discussion

In this section, we discuss the potential for BPQP to be applied in non-convex problems.

When addressing non-convex problems, we may encounter two challenges. Firstly, the solution is only a local minimum. Secondly, the solution represents only a proximate solution near a local minimum. If an effective non-convex method (e.g. Improved SVRG ) is employed in the forward pass, BPQP is still equipped to reformulate the backward pass as a QP. This is because our derivations and theoretical analysis are equally applicable to non-convex scenarios.

BPQP allows for the derivation of gradients that preserve the KKT norm, as elaborated in Section 4.1 under "General Gradients.", which means that when KKT norm is small, BPQP can derive a high quality gradient. Therefore, when a non-convex solver used in the forward pass successfully achieves a solution that is close to or even reaches a local or global minimum, BPQP can still compute well-behaved gradients effectively. This capability underscores the robustness of BPQP and adaptability in handling the complexities associated with non-convex optimization problems.

Additionally, many non-convex problems can be transformed into convex problems, making our approach applicable in a broader range of scenarios.

While its hard to perform experiments on non-convex problem due to the lack of baselines, we hope that future work can employ BPQP to do further analysis.

## 7 Conclusion

We have introduced a differentiable convex optimization framework for efficient end-to-end learning. Prior work in this area can be divided into explicit and implicit methods, based on the construction of an explicit computational graph.Explicit methods unroll the iterations of the optimization process, incurring additional costs. Conversely, implicit methods often struggle to achieve overall efficiency in both computing the optimal decision variable during the forward pass and solving the linear system involving KKT matrix during the backward pass. Our approach, BPQP, is grounded in implicit methods and simplify the backward pass by reformulating it into a simpler decoupled QP problem, which greatly reduces the computational cost in both the forward and backward passes. Extensive experiments on both simulated and real-world datasets have been conducted, demonstrating a considerable improvement in terms of efficiency.