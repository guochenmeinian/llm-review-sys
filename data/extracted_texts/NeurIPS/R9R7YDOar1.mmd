# PROTES: Probabilistic Optimization with Tensor Sampling

Anastasia Batsheva

Skolkovo Institute of Science and Technology

Moscow, Russia

a.batsheva@skoltech.ru

&Andrei Chertkov

Skolkovo Institute of Science and Technology

and AIRI, Moscow, Russia

a.chertkov@skoltech.ru

Equal contribution.

Sklokovo Institute of Science and Technology

and AIRI, Moscow, Russia

a.bertkov@skoltech.ru

&Gleb Ryzhakov

Skolkovo Institute of Science and Technology

Moscow, Russia

g.ryzhakov@skoltech.ru

&Ivan Oseledets

Skolkovo Institute of Science and Technology

and AIRI, Moscow, Russia

i.oseledets@skoltech.ru

Equal contribution.

###### Abstract

We developed a new method PROTES for black-box optimization, which is based on the probabilistic sampling from a probability density function given in the low-parametric tensor train format. We tested it on complex multidimensional arrays and discretized multivariable functions taken, among others, from real-world applications, including unconstrained binary optimization and optimal control problems, for which the possible number of elements is up to \(2^{1000}\). In numerical experiments, both on analytic model functions and on complex problems, PROTES outperforms popular discrete optimization methods (Particle Swarm Optimization, Covariance Matrix Adaptation, Differential Evolution, and others).

## 1 Introduction

The multidimensional optimization problem is one of the most common in machine learning. It includes the important case of gradient-free discrete optimization :

\[_{min}=_{}(), }=[n_{1},n_{2},,n_{d}], n_{i}\{1,2,,N_{i}\},\] (1)

where \(d\) is the dimensionality of the problem, and \(N_{1},N_{2},,N_{d}\) are the numbers of items for each dimension. Such settings arise when searching for the minimum or maximum element in an implicitly given multidimensional array (tensor1), including when considering the discretization of functions from a continuous argument. Multidimensional discrete optimization problems are still computationally difficult in the case of complex target functions or large dimensions, and efficient direct gradient-free optimization procedures are highly needed.

The development of methods for low-rank tensor approximations has made it possible to introduce fundamentally new approaches for the approximation, storage, and operation with multidimensionaltensors [13; 6; 7; 40]. One of the common methods for low-rank approximation is the tensor train (TT) decomposition , which allows bypassing the curse of dimensionality. Many useful algorithms (e. g., element-wise addition, multiplication, solution of linear systems, convolution, integration, etc.) have effective implementations for tensors given in the TT-format. The complexity of these algorithms turns out to be polynomial in the dimension \(d\) and the mode size \(N\). It makes the TT-decomposition extremely popular in a wide range of applications, including computational mathematics [29; 2] and machine learning [31; 19].

In the last few years, new discrete optimization algorithms based on the TT-format have been proposed: TTOpt , Optima-TT , and several modifications [34; 35; 24; 36]. However, the development of new, more accurate, and robust TT-based methods for multidimensional discrete optimization is possible. In this work, we extend recent approaches for working with probability distributions and sampling in the TT-format [10; 25] to the optimization area. That is, we specify a multidimensional discrete probability distribution in the TT-format, followed by efficient sampling from it and updating2 its parameters to approximate the optimum in a better way. This makes it possible to build an effective optimization method, and the contributions of our work are as follows:

* We develop a new method PROTES for optimization (finding the minimum or maximum3 value) of multidimensional data arrays and discretized multivariable functions based on a sampling method from a probability distribution in the TT-format; * We apply4 PROTES for various analytic model functions and for several multidimensional QUBO and optimal control problems to demonstrate its performance and compare it with popular discrete optimization algorithms (Particle Swarm Optimization, Covariance Matrix Adaptation, Differential Evolution, and NoisyBandit) as well as TT-based methods (TTOpt and Optima-TT). We used the same set of hyperparameters of our algorithm for all experiments and obtained the best result for \(19\) of the \(20\) problems considered.

## 2 Optimization with probabilistic sampling

Our problem is to minimize the given multivariable discrete black-box function f (1). It can be formulated in terms of the multi-index search in an implicitly given \(d\)-dimensional tensor

\[^{N_{1} N_{2} N_{d}}, [n_{1},\,n_{2},\,,\,n_{d}]=(),=[ n_{1},\,n_{2},\,,\,n_{d}],\]

for all \(n_{i}=1,2,,N_{i}\) (\(i=1,2,,d\)). The essence of our idea is to use a probabilistic method to find the minimum \(_{min}\). We propose establishing a discrete distribution \(()\) from which the minimum could be sampled with high probability. This distribution can be specified as a tensor \(_{}^{N_{1} N_{2} N_{d}}\) in some low-parametric representation with a set of parameters \(\), having the same shape as the target tensor \(\).

We start from a random non-negative tensor \(_{}\) and iteratively perform the following steps until the budget is exhausted or until convergence (see graphic illustration in Figure 1):

1. **Sample**\(K\) candidates of \(_{min}\) from the current distribution \(_{}\): \(_{K}=\{_{1},_{2},,_{K}\}\);
2. **Compute** the corresponding function values: \(y_{1}=(_{1})\), \(y_{2}=(_{2})\),..., \(y_{K}=(_{K})\);
3. **Select**\(k\) best candidates with indices \(=\{s_{1},s_{2},,s_{k}\}\) from \(_{K}\) with the minimal objective value, i. e., \(y_{j} y_{J}\) for all \(j\) and \(J\{1,\,2,\,,\,K\}\);
4. **Update** the probability distribution \(_{}\) (\(^{(new)}\)) to increase the likelihood of selected candidates \(\). We make several (\(k_{gd}\)) gradient ascent steps with the learning rate \(\) for the tensor \(_{}\), using the following loss function \[_{}(\{x_{s_{1}},\,x_{s_{2}},\,,\,x_{s_{k}}\})=_{i= 1}^{k}(_{}[_{s_{i}}]).\] (2). After a sufficient number of iterations, we expect the tensor \(_{}\) to represent an almost Kronecker delta-function with a pronounced peak in the value of the minimum of the target function (or several peaks if the minimum is not unique). Therefore, this value will be sampled during the steps of our algorithm since the probability of sampling other values will be sufficiently small.

From a low-parameter representation \(_{}\) we expect an efficient sampling algorithm and efficient calculation procedure for the logarithms in (2) with automatic differentiation capability to enable gradient ascent methods. As will be shown below, the TT-representation of tensors satisfies these requirements. Further, we will omit the index \(\), assuming that the parameterized representation of the tensor \(\) corresponds to the TT-format. Note that the values \(K\), \(k\), \(k_{gd}\), \(\) and the number of parameters in \(\) (i. e., rank of the TT-decomposition) are the hyperparameters of our algorithm.

## 3 Basic properties of the tensor train format

Let us dwell on the concept of the TT-format. A \(d\)-dimensional tensor \(^{N_{1} N_{2} N_{d}}\) is said to be in the TT-format  if its elements are represented by the following formula

\[[n_{1},n_{2},,n_{d}]=_{r_{1}=1}^{R_{1}}_{r_{2}=1}^{R _{2}}_{r_{d-1}=1}^{R_{d-1}}_{1}[1,n_{1},r_{1}]\ _{2}[r_{1},n_{2},r_{2}]\ \ _{d}[r_{d-1},n_{d},1],\] (3)

where \((n_{1},n_{2},,n_{d})\) is a multi-index (\(n_{i}=1,2,,N_{i}\) for \(i=1,2,,d\)), integers \(R_{0},R_{1},,R_{d}\) (with convention \(R_{0}=R_{d}=1\)) are named TT-ranks, and three-dimensional tensors \(_{i}^{R_{i-1} N_{i} R_{i}}\) (\(i=1,2,,d\)) are named TT-cores. The TT-decomposition (3) (see also an illustration in Figure 2) allows to represent a tensor or a discretized multivariable function in a compact and descriptive low-parameter form, which is linear in dimension \(d\), i. e., it has less than \(d_{i=1,,d}(N_{i}R_{i}^{2}) d {R}^{2}\) parameters, where \(\) and \(\) are effective ("average") mode size and TT-rank respectively.

Linear algebra operations (e. g., element-wise addition, solution of linear systems, convolution, integration, etc.) on tensors in the TT-format, respectively, also have complexity linear in dimension if the TT-ranks are bounded. The TT-approximation for a tensor or discretized multivariable function may be built by efficient numerical methods, e. g., TT-SVD , TT-ALS , and TT-cross . A detailed description of the TT-format and related algorithms are given in the works [26; 6; 7]. Below, we discuss only three operations in the TT-format, which will be used later in the work.

Construction of the random TT-tensor.In order to build a random non-negative TT-tensor of a given size \((N_{1},N_{2},,N_{d})\) with a constant TT-rank \(R\), it is enough to generate \(d\) TT-cores \(_{1},_{2},,_{d}\) (\(3\)-dimensional tensors) with random elements from the uniform distribution on the interval \((0,1)\). We will refer to this method as tt_random(\(R,\,[N_{1},N_{2},,N_{d}]\)).

Figure 1: Schematic representation of the proposed optimization method PROTES.

Computation of the log-likelihood in the TT-format.To calculate the logarithm \(||\) in a given multi-index \(=(n_{1},n_{2},,n_{d})\), we can use the basic formula (3) and then take the logarithm of the result. It can be shown that this operation has complexity \(\!(d^{2})\), because, roughly speaking, we \((d-1)\) times multiply a vector of length \(\) by a matrix of size \(\) to get the result. The corresponding method will be called tt_log(\(,\)).

Sampling from the tensor in the TT-format.We use the approach proposed in the work  to generate a multi-index \(\) with a probability proportional to the corresponding value \(p=[]\) of the TT-tensor \(\). The method is based on the sequential calculation of univariate conditional densities with efficient integration in the TT-format. The estimate for its complexity turns out to be the following: \(\!(K d(+) +K d())\), where \(K\) is a number of requested samples, and \((n)\) is a complexity of sampling from generalized Bernoulli distribution with \(n\) outcomes. Note that the algorithm allows sampling in the case of the initially non-normalized tensor, so we do not have to calculate the normalization factor. We will refer to this method as tt_sample(\(,K\)).

## 4 Optimization method PROTES

With the formal scheme of the proposed approach given in Section 2 and the description of operations tt_random, tt_log, and tt_sample given in Section 3, we can formulate our method PROTES for gradient-free discrete optimization in the TT-format, as presented in Algorithm 1. We denote as adam, a function that performs \(k_{gd}\) steps of gradient ascent for the TT-tensor \(\) at multi-indices \(\) by the well-known Adam method . In this case, the learning rate is \(\), the loss function is given in (2), and tt_log with automatic differentiation support is used for the log-likelihood computation.

Computational complexity of the method.Let us estimate the complexity of the proposed algorithm, assuming that the number of requests to the target function (black-box) \(M\) is fixed. With the known estimate for the complexity of the tt_sample function, we can obtain the complexity of the sampling operations: \(\!( K d((+ )+()))\). Assuming that the complexity of one gradient step coincides with the complexity of calculating the differentiated function and using the estimate for the tt_sample function, we can estimate the total complexity of the tensor updates: \(\!( k k_{gd} d^{2})\). Combining the two above estimates we obtain the complexity of the method

\[\!(M d( k_{gd}^{2}+(+)+(N))).\] (4)

Figure 2: Schematic representation of the TT-decomposition. The top picture demonstrates the calculation of the specific tensor element \(=[n_{1},n_{2},,n_{d}]\) from its TT-representation, and the bottom picture presents the related tensor network diagram.

However, it is important to note that this estimate does not consider the complexity of calculating \(M\) times the objective function f, which in practical applications can be significant and many times greater than the estimate (4).

The intuition behind the method.The proposed method PROTES, like most gradient-free optimization approaches, is empirical; however, we can establish its connection with a well-known REINFORCE trick algorithm . Let make a monotonic transformation \([]()\) of the target function f to be minimized that transforms minimum to maximum. A reasonable choice for \([]\) is the Fermi-Dirac function

\[[]()=( )-y_{}-E)/T+1},\]

where \(y_{}\) is an exact or approximate minimum of f, \(T>0\) is a parameter and \(E>0\) is some small threshold. With the function \([]\) we can find a maximum of the expectation \(_{}_{_{}}[](_{})\), where a family of random variables \(_{}\) has a parameterised distribution function \(_{}()\). Using REINFORCE trick, we can estimate the gradient of the expectation by the following Monte-Carlo-like expression

\[_{}_{_{}}[](_{}) _{i=1}^{M}[](_{i})_{ }_{}(_{i}),\] (5)

where \(\{_{i}\}_{1}^{M}\) are independent realizations of the random variable \(_{}\). If we find the optimal values of \(\), then we expect the optimal distribution \(_{}\) to peak at the maximum point for function \([]\). Thus, we can obtain the argument of its maximum by sampling from this distribution. For very small values of \(T\), only a few terms contribute to the sum (5), namely those \(_{i}\) for which \((_{i})-y_{min}<E\) is hold. For these values of \(\), \([]\) is close to \(1\), while for the other samples its value is \(0\). Hence, we can discard all other samples and keep a few with the best values. So, we come to the loss function (2), where instead of the parameter \(E\) we use a fixed number \(k\) of the best samples, i. e., the samples for which the value of the target function f is the smallest.

Application of the method to constrained optimization.A very nice property of the proposed method is that it can be adapted to efficiently handle constraints such as a specified set of admissible multi-indices. One option is just to remove invalid samples from the top-k values, but in some cases, the probability of sampling multi-indices that are admissible is very low, so this approach will not work. Instead, if the constraint permits, we use the algorithm from the work  for the constructive building of tensors in the TT-format by a known analytic function, which defines the constraints. Once the indicator tensor (\(1\) if the index is admissible and \(0\) if it is not) is built in the TT-format, we can just initialize the starting distribution \(\) by it, and it will be guaranteed that the samples almost always belong to the admissible set.

Related work

Below, we briefly analyze classical approaches for discrete optimization and then discuss the methods based on the low-rank tensor approximations, which have become popular in recent years.

Classical methods for gradient-free optimization.In many situations, the problem-specific target function is not differentiable, too complex, or its gradients are not helpful due to the non-convex nature of the problem , and standard well-known gradient-based methods cannot be applied directly. The examples include hyper-parameter selection, training neural networks with discrete weights, and policy optimization in reinforcement learning. In all these contexts, efficient direct gradient-free optimization procedures are highly needed. As for high-dimensional black-box optimization, evolutionary strategies (ES)  are one of the most advanced methods. This approach aims to optimize the parameters of the search distribution, typically a multidimensional Gaussian, to maximize the objective function. Finite difference schemes are commonly used to approximate gradients of the search distribution. Numerous works proposed techniques to improve the convergence of ES ; for example, second-order natural gradient  or the history of recent updates (Covariance Matrix Adaptation Evolution Strategy; CMA-ES)  may be used to generate updates. There is also a large variety of other heuristic methods for finding the global extremum. In particular, we note such popular approaches as NoisyBandit , Particle Swarm Optimization (PSO) , Simultaneous Perturbation Stochastic Approximation (SPSA) , Differential Evolution (DE)  and scrambled-Hammersley (scr-Hammersley) .

Tensor-based methods for gradient-free optimization.Recently, the TT-decomposition has been actively used for multidimensional optimization. An iterative method TTOpt based on the maximum volume approach is proposed in the work . TTOpt utilizes the theorem of sufficient proximity of the maximum modulo element of the submatrix having the maximum modulus of the determinant to the maximum modulo element of the tensor. Based on this observation, tensor elements are sampled from specially selected successive unfoldings of the tensor. Dynamic mapping of the tensor elements is carried out to find the minimum element, which converts the minimum values into maximum ones. The authors applied this approach to the problem of optimizing the weights of neural networks in the framework of reinforcement learning problems in  and to the QUBO problem in . A similar optimization approach was also considered in  and . One more promising algorithm, Optima-TT, was proposed in recent work . This approach is based on the probabilistic sampling from the TT-tensor and makes it possible to obtain a very accurate approximation for the optimum of the given TT-tensor. However, this method is intended for directly optimizing the TT-tensors, which means that its success strongly depends on the quality of the TT-approximation for the original multidimensional data array. Therefore, one of the related methods in the TT-format (TT-SVD, TT-ALS, TT-cross, etc.) should be additionally used for approximation.

## 6 Numerical experiments

To evaluate the effectiveness of the proposed method, we carried out a series of \(20\) numerical experiments for various formulations of model problems. The results are presented in Table 1, where we report the approximation to the minimum value for each model problem (P-1, P-2,..., P-20) and all considered optimization methods (PROTES, BS-1, BS-2,..., BS-7). Taking into account the analysis of discrete optimization methods in the previous section as baselines we consider two tensor-based optimization methods: TTOpt5 (BS1) and Optima-TT6 (BS2), and five popular gradient-free optimization algorithms from the nevergrad framework :7 OnePlusOne (BS3), PSO (BS4), NoisyBandit (BS5), SPSA (BS6), and Portfolio approach (BS7), which is based on the combination of CMA-ES, DE, and scr-Hammersley methods. The model problems and obtained results will be discussed in detail below in this section.

For all the considered optimization problems, we used the default set of parameters for baselines, and for PROTES we fixed parameters as \(K=100\), \(k=10\), \(k_{gd}=1\), \(=0.05\), \(R=5\) (the description of these parameters was presented in Algorithm 1). For all methods, the limit on the number of requests to the objective function was fixed at the value \(M=10^{4}\). As seen from Table 1, PROTES, in contrast to alternative approaches, gives a consistently top result for almost all model problems (the best result for \(19\) of the \(20\) problems considered).

### Multivariable analytic functions

First, we consider the optimization task for various tensors arising from the discretization of multivariable analytic functions. We select \(10\) popular benchmarks: Ackley (P-01), Alpine (P-02), Exponential (P-03), Griewank (P-04), Michalewicz (P-05), Piston8 (P-06), Qing (P-07), Rastrigin (P-08), Schaffer (P-09) and Schwefel (P-10). These functions have a complex landscape and are often used in problems to evaluate the effectiveness of optimization algorithms [8; 16], including tensor-based optimizers [4; 39]. We consider the 7-dimensional case (since this is the dimension of the Piston function) and discretization on a uniform grid with \(16\) nodes.

As follows from Table 1 (benchmarks P-1, P-2,..., P-10), our method, like the other two tensor approaches (BS-1 and BS-2), gave the most accurate solution for all model problems. The most sophisticated approach from the nevergrad package (BS-7) was the next in accuracy (the method did not converge only in two cases out of ten).

### Quadratic unconstrained binary optimization

QUBO is a widely known NP-hard problem  which unifies a wide variety of combinatorial optimization problems from finance and economics applications to machine learning and quantum computing. QUBO formulation in a very natural manner utilizes penalty functions, yielding exact model representations in contrast to the approximate representations produced by customary uses of penalty functions. The standard QUBO problem can be formulated as follows

\[()=^{T}Q_{},\{0,1\}^{d},\]

where \(\) is a vector of binary decision variables of the length \(d\) and \(Q^{d d}\) is a square matrix of constants. In all our experiments, we fixed the number of dimensions as \(d=50\).

   & PROTES & BS-1 & BS-2 & BS-3 & BS-4 & BS-5 & BS-6 & BS-7 \\   & P-01 & **1.3+01** & **1.3+01** & **1.3+01** & **1.3+01** & **1.3+01** & 2.1+01 & **1.3+01** & **1.3+01** \\  & P-02 & **6.5+00** & **6.5+00** & **6.5+00** & 6.9+00 & 6.8+00 & 1.5+01 & 7.5+00 & 6.8+00 \\  & P-03 & **-9.4+01** & **-9.4+01** & **-9.4+01** & **-9.4+01** & **-9.4+01** & -3.5+01 & **-9.4+01** & **-9.4+01** \\  & P-04 & **1.3+00** & **1.3+00** & **1.3+00** & **1.3+00** & **1.3+00** & **1.3+00** & 6.3+00 & **1.3+00** & **1.3+00** \\  & P-05 & **-3.7+00** & **-3.7+00** & **-3.7+00** & **-2.6+00** & -3.0+00 & -1.8+00 & -1.2+00 & -3.7+00 \\  & P-06 & **1.2+01** & **1.2+01** & **1.2+01** & **1.2+01** & **1.2+01** & 1.3+01 & 4.2+01 & **1.2+01** \\  & P-07 & **6.2+06** & **6.2+06** & **6.2+06** & 6.3+06 & 1.7+07 & 2.2+01 & 3.1+08 & **6.2+06** \\  & P-08 & **6.06+01** & **6.06** & **1.6+01** & **6.06+01** & **6.06+01** & 2.1+02 & 1.06+02 & **6.06+01** \\  & P-09 & **2.7+00** & **2.7+00** & **2.7+00** & **-3.00** & **-2.7+00** & 2.9+00 & 3.4+00 & 2.7+00 \\  & P-10 & **-8.7+02** & **-8.7+02** & **-8.7+02** & -6.1+02 & -6.9+02 & 2.7+02 & 2.6+03 & -8.5+02 \\   & P-11 & **-3.6+02** & -3.5+02 & -3.4+02 & -3.2+02 & -3.4+02 & -3.2+02 & -3.3+02 & **-3.6+02** \\  & P-12 & **-5.9+03** & **-5.9+03** & **-5.9+03** & -5.6+03 & -5.9+03 & -5.5+03 & -5.5+03 & -**5.9+03** \\  & P-13 & **-3.1+00** & -3.0+00 & -2.8+00 & 0.0+00 & 1.5+01 & 2.8+02 & -2.9+00 & -3.0+00 \\  & P-14 & **-3.1+03** & -3.2+03 & -3.0+03 & -2.6+03 & -3.0+03 & -2.7+03 & -3.6+03 & -3.0+03 \\   & P-15 & **6.7+03** & 7.4+03 & 2.3+02 & 8.4+03 & 8.9+03 & 3.1+02 & 8.7+02 & 7.3+03 \\  & P-16 & **1.4+02** & 2.6+02 & 3.5+02 & 1.7+02 & 1.7+02 & 5.3+02 & 5.2+02 & **1.4+02** \\  & P-17 & **3.00+2** & 5.7+01 & 1.5+01 & 4.8+02 & 3.6+02 & 7.7+02 & 5.3+02 & 3.7+02 \\   & P-18 & **1.4+02** & **11.02** & 1.4+02 & 3.4+02 & 6.2+02 & 2.8+01 & 6.4+02 & 2.1+02 \\  & P-19 & **6.4+02** & 5.7+01 & 6.7+02 & **Pail** & Pail** & Pail** & Pail** & Pail \\   & P-20 & **1.5+01** & Pail & 2.06+01 & Pail & Pail & Pail & Pail & Pail \\  

Table 1: Minimization results for all selected benchmarks (P-01 - P-20). The values obtained by the proposed method PROTES and by all considered baselines (BS1 – BS7) are reported.

We consider the following QUBO problems from the qubogen package:9 Max-Cut Problem (P-11; which refers to finding a partition of an undirected graph into two sets such that the number of edges between the two sets is as large as possible), Minimum Vertex Cover Problem (P-12; which refers to finding a cover with a minimum number of vertices in the subset of the graph vertices such that each edge in the graph is incident) and Quadratic Knapsack Problem (P-13; which refers to finding a subset of maximum profit that satisfies the budget limitations from a set of potential projects with specified interactions between pairs of projects).

We also consider one more benchmark (P-14) from the work  (problem \(k_{3}\); \(d=50\)), where angle-modulated bat algorithm (AMBA) was proposed for high-dimensional QUBO problems with engineering application to antenna topology optimization. This is the ordinary binary knapsack problem with fixed weights \(w_{i}\), profits \(p_{i}\) (\(i=1,2,,d\)), and the maximum capacity \(C=1000\). In experiments, we used the same values of the weights and profits as in .

For all four considered problems (P-11, P-12, P-13, P-14), the proposed method PROTES gives the best result, as seen from Table 1, and the baseline BS-7 again turned out to be the next in accuracy. We also note that several optimization methods were compared in  for the P-14 problem: BPSO (with the result \(-2854\)), BBA (with the result \(-2976\)), AMBA (with the result \(-2956\)), A-AMBA (with the result \(-2989\)), and the solution obtained using the PROTES method (the result \(-3079\)) turns out to be more accurate.

To study the stability of the proposed optimization method in the essentially multidimensional case, we also consider \(d=1000\) for the benchmark P-12. Additionally, we vary the value of the vertex connection probability in the generated random graph (i.e., the parameter in the corresponding function from the well-known networkx package), getting \(5\) different optimization problems with \(p=0.1\), \(p=0.2\), \(p=0.3\), \(p=0.4\), and \(p=0.5\) (note that in Table 1, we used the value \(p=0.5\)). We performed the calculations with PROTES and baselines BS1 - BS7 with the same settings as above. In Table 2, we report the results averaged over \(5\) runs of each optimizer for each value of \(p\). In all cases, PROTES demonstrates the best result. We note that BS2 failed for this problem because the selected dimension value is too large to construct the TT-approximation of the tensor.

In Figure 3, we plotted the convergence curves for \(p=0.1\), \(p=0.3\), \(p=0.5\), and all optimizers (except the BS2, since it failed), showing the average result and the spread of values over \(5\) restarts for P-12 (\(d=1000\)). Our optimizer PROTES has a slight variance of the solution and consistently shows the best result when the number of iterations exceeds \(2000\).

### Optimal control

Suppose we have a state variable \(z\) controlled by a binary variable \(x\) called control (i.e., it is just a switch with modes "off" = 0 and "on" = 1) over some discrete interval of time \([0,T]\). The state \(z(t+1)\) at time \(t+1\) depends on the control \(x(t)\) at time \(t\) and is obtained from the solution of the following differential equation \(()=(z(),x(t))\), \(t<t+1\), where the function \(\) is called an equation function. The optimal control problem is to find such a sequence of controls \(^{*}=[x^{*}(0),\,x^{*}(1),\,,\,x^{*}(T)]\) (optimal solution) over the given time interval \([0,T]\) that minimizes the given objective function \(}\).

   & & PROTES & BS-1 & BS-2 & BS-3 & BS-4 & BS-5 & BS-6 & BS-7 \\   & \(p=0.1\) & **-4.86\(\)0.05** & -4.40\(\)0.05 & FAIL & -4.10\(\)0.05 & -4.35\(\)0.05 & -3.54\(\)0.05 & -3.84\(\)0.05 & -4.71\(\)0.05 \\  & \(p=0.2\) & **-9.70\(\)0.05** & -8.78\(\)0.05 & FAIL & -8.24\(\)0.05 & -8.71\(\)0.05 & -7.87\(\)0.05 & -7.64\(\)0.05 & -9.38\(\)0.05 \\  & \(p=0.3\) & **-1.46\(\)0.06** & -1.32\(\)0.06 & FAIL & -1.23\(\)0.06 & -1.30\(\)0.06 & -1.18\(\)0.06 & -1.14\(\)0.06 & -1.41\(\)0.06 \\  & \(p=0.4\) & **-1.94\(\)0.06** & -1.75\(\)0.06 & FAIL & -1.64\(\)0.06 & -1.72\(\)0.06 & -1.57\(\)0.06 & -1.52\(\)0.06 & -1.88\(\)0.06 \\  & \(p=0.5\) & **-2.43\(\)0.06** & -2.19\(\)0.06 & FAIL & -2.04\(\)0.06 & -2.16\(\)0.06 & -1.96\(\)0.06 & -2.35\(\)0.06 \\  

Table 2: Minimization results for benchmark P-12 for the \(1000\) dimensional case with different random initializations. Results for each value of \(p\) are averaged over \(5\) runs of optimizers.

Formulating the problem mathematically, we need to find such a solution

\[(,)_{,},\{z(0)=z_{0},\\ ()=}(z(),(t)),&t<t+1,\\ (t)\{0,1\},&t=0,\;1,\;,\;T,.\]

where \(=[z(0),z(1),,z(T)]\) is a state variable path. In numerical experiments, we consider the nonlinear equation function \((z,x)=z^{3}-x\), and since it is nonlinear, finding an optimal solution raises a lot of difficulties. We take the objective function \(\) in the form \((,)=_{t=0}^{T}(z(t)-z_{ })^{2}\).

The initial and the reference state are fixed at values \(z_{0}=0.8,\;z_{}=0.7\). For a fixed initial value \(z_{0}\) and fixed equation function \(\), the objective function \(\) can be represented as a binary multidimensional tensor, whose elements are calculated using the following function: \(()=((),)\), hence we can apply discrete optimization methods to find \(_{min}\), which approximates the optimal solution \(^{*}\).

We considered several values for variable \(T\), such as \(25,50\), and \(100\) (benchmarks P-15, P-16, and P-17, respectively). As follows from the results presented in Table 1, PROTES gives the most accurate solution in all three cases. Note that a result comparable in accuracy to our method is obtained only in one case when using baselines (i.e., P-16, BS-7).

### Optimal control with constraints

In practical applications, some conditions or constraints may be imposed on the solution of the optimal control problem. In this work, we consider the following control constraint \(P\): _the control variable \(\{0,1\}^{N}\) can take the value "1" no less than \(3\) times in a row during the whole time interval_. Formally, this can be written as follows:

\[P=\{|x[t] x[t-1]-x[t-2]\\ x[t] x[t-1]-x[t-3]. t:1 t N+2;\;x[t] 0 t<1t>N\}.\]

To account for this condition in the PROTES algorithm, we constructively build the initial distribution in the form of an indicator tensor as described in Section 4 in the constrained optimization subsection. The details of this construction are presented in the Appendix. The numerical results for \(T=25\) (P-18), \(T=50\) (P-19), and \(T=100\) (P-20) are reported in Table 1. In two cases out of three (P-19, P-20), our method showed the best result, and in one case (P-18) slightly yielding to the TTOpt method (BS-1), which, however, in two other cases, gave a significantly worse result.

Figure 3: Minimization results for benchmark P-12 in the \(1000\)-dimensional case. The results for various values of the vertex connection probability \(p\) of the generated random graph are presented. For each of the optimizers PROTES, BS1, and BS3 – BS7 (BS2 failed for this problem), we plot the value of the solution averaged over \(5\) runs with a solid line and fill in the area between the worst and best result with the same color.

### Robustness and performance of the PROTES

The results in Table 1 relate to the "intuitive" selection of the hyperparameters for the PROTES method (as was mentioned above, we have used the values: \(K=100\), \(k=10\), \(k_{gd}=1\), \(=0.05\), and \(R=5\)). In Figure 4, we present an analysis of the dependence of the optimization result for the benchmark P-14 on the choice of hyperparameters \(K\), \(k\), and \(R\), with fixed \(k_{gd}=1\) and \(=0.05\). We report the relative error of the result for all combinations \(K=50,100,150,200,250\); \(k=5,10,15,20,25\); \(R=3,5,7\). As we can see from the plots, the hyperparameters used in the main calculations are not optimal for this particular problem, that is, additional fine-tuning of the method for specific problems or classes of problems is possible. At the same time, according to the results in Figure 4, the method remains stable over a wide range of hyperparameter values. We also note that all computations were carried out on a regular laptop, while the operating time of the considered optimizers was commensurate; for example, for the benchmark P-17, the measured operating time (in seconds) is: PROTES (641), BS-1 (607), BS-2 (4245), BS-7 (780).

A more detailed analysis of the PROTES performance and the dependence of optimization results on the values of hyperparameters are presented in the Appendix. Also, in the Appendix, we consider another promising application of our optimizer for several popular reinforcement learning problems from Mujoco / OpenAI-GYM collection.

## 7 Conclusions

In this work, we presented an optimization algorithm PROTES based on sampling from the probability density defined in the tensor train format. We used the same set of hyperparameters for all considered numerical experiments, so our algorithm is rather universal To take into account the constraints, as in the problem of optimal control with constraints, we only considered them in the form of a specially selected initial approximation (a special form of an indicator tensor in the tensor train format); further on, the algorithm did not consider the constraints explicitly. This approach allows us to extend the algorithm's capabilities by using the properties of the tensor train representation. Numerical experiments show that we outperform many popular optimization methods.

The main direction in our future work is scaling the method to large dimensions. For \(d 1000\), we have encountered numerous technical difficulties, which can be alleviated by other tensor formats (such as hierarchical Tucker, which can be parallelized over \(d\)) and more efficient implementations of the optimization method (now we use standard automatic differentiation without special tensor optimization methods such as Riemannian optimization).