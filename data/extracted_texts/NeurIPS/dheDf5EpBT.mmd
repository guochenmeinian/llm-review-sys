# Unified Gradient-Based Machine Unlearning with

Remain Geometry Enhancement

 Zhehao Huang, Xinwen Cheng, JingHao Zheng, Haoran Wang, Zhengbao He, Tao Li, Xiaolin Huang

Shanghai Jiao Tong University

[xinght_H, zinwencheng, zjh20030406, haoran_whynot, lstefamie, li.tao, xiaolinhuang]@sjtu.edu.cn

###### Abstract

Machine unlearning (MU) has emerged to enhance the privacy and trustworthiness of deep neural networks. Approximate MU is a practical method for large-scale models. Our investigation into approximate MU starts with identifying the steepest descent direction, minimizing the output Kullback-Leibler divergence to exact MU inside a parameters' neighborhood. This probed direction decomposes into three components: weighted forgetting gradient ascent, fine-tuning retaining gradient descent, and a weight saliency matrix. Such decomposition derived from Euclidean metric encompasses most existing gradient-based MU methods. Nevertheless, adhering to Euclidean space may result in sub-optimal iterative trajectories due to the overlooked geometric structure of the output probability space. We suggest embedding the unlearning update into a manifold rendered by the remaining geometry, incorporating second-order Hessian from the remaining data. It helps prevent effective unlearning from interfering with the retained performance. However, computing the second-order Hessian for large-scale models is intractable. To efficiently leverage the benefits of Hessian modulation, we propose a fast-slow parameter update strategy to implicitly approximate the up-to-date salient unlearning direction. Free from specific modal constraints, our approach is adaptable across computer vision unlearning tasks, including classification and generation. Extensive experiments validate our efficacy and efficiency. Notably, our method successfully performs class-forgetting on ImageNet using DiT and forgets a class on CIFAR-10 using DDPM in just 50 steps, compared to thousands of steps required by previous methods. Code is available at Unified-Unlearning-w-Remain-Geometry.

## 1 Introduction

Machine Unlearning (MU)  aims to remove the influence of samples from a pre-trained model, ensuring the model behaves as if it has never encountered those samples. The significance of MU research has grown following data protection regulations . It has rapidly developed in recent years, becoming an important means to help pre-trained large-scale models adapt to various trustworthy challenges  in computer vision (CV). In general, MU aids in purging outdated knowledge , mitigating biases , and preventing large text-to-image models from generating not-safe-for-work (NSFW) images .

Existing MU methods are mainly divided into two categories: _exact (or certified) MU_ and _approximate MU_. For deep neural networks, achieving exact MU necessitates retraining on a dataset excluding forgetting samples. However, retraining is computationally prohibitive for recent large-scale deep networks. Thus, in MU for deep networks, this retrained model only serves as an aspirational standard to be approached . We primarily focus on more efficient approximate MU.

Approximate MU strives to align the output distribution of unlearned models with that of retrained models. We initially explore the vanilla gradient descent of minimizing the output Kullback-Leibler(KL) divergence between the current iteration and the retrained model. Our deduction reveals that this direction consists of three parts: a weighted gradient ascent to eliminate the influence of forgetting samples, a descent gradient for fine-tuning the remaining set, and a weight saliency matrix modulating the unlearning direction. Such decomposition provides a novel perspective that unifies previous MU approaches proposed in recent years [18; 19; 20; 21; 22; 23; 24; 25], most of which only focus on one or two of these components. For example, SalUn  insightfully proposes saliency-based unlearning, which only optimizes the parameters important to forget, but lacks theoretical support. Our analysis fills this gap and provides new directions for further improvement.

In fact, the vanilla gradient descent for approximate MU actually pursues the steepest descent under _Euclidean distance_[27; 28; 29; 30]. However, constraining parameter updates within an Euclidean region is arbitrary, as it treats the importance of all parameters equally. Recent research indicates deep models' parameters and training processes are embedded in a low-dimensional manifold [31; 32]. Thus, there exist manifolds where changes in Euclidean between parameters are drastic, yet the output space remains unchanged. In MU, it is evident that the importance of model parameters varies for forgetting and remaining [33; 26], prompting the following question. _Can model parameters be embedded in a manifold that allows effective forgetting while efficiently maintaining remaining performance?_

To achieve this goal, we propose to discover the descent direction under the KL divergence on the remaining output distribution. Using such a manifold metric, the forgetting direction can be amended by a second-order Hessian on the remaining set to prevent forgetting loss from harming retained performance. Such iterative direction is dominated by the unlearning function, allowing the optimization process to focus on efficient forgetting. However, computing the second-order Hessian for large-scale models is computationally intensive, contradicting the need for efficiency in unlearning. Existing methods for estimating the second-order Hessian rely on initial parameters and keep them fixed thereafter [34; 35]. Therefore, we propose a fast-slow weight [36; 37] method (**Fig. 1**) to implicitly and dynamically approximate the salient forgetting direction with Hessian modulation, forming a unified MU approach for CV unlearning tasks including image classification and image generation. Key **contributions** of this paper include:

\(\) We provide a novel perspective to unify previous approaches by decomposing the vanilla gradient descent direction of approximate MU into three components: weighted forgetting gradient ascent, remaining gradient descent, and a weight saliency matrix.

\(\) We derive the steepest descent direction for approximate MU on the remain-preserved manifold.

\(\) We propose a fast-slow weight method to implicitly approximate online Hessian-modulated salient forgetting updates.

\(\) We conduct experiments on a wide range of CV unlearning tasks across multiple datasets and models of different architectures, verifying the effectiveness and efficiency of our method.

## 2 Preliminary

**Problem Setup.** MU aims to help a well-trained model eliminate the influence of specific data points, categories, or high-level concepts and patterns [1; 38]. Let \(=\{z_{i}\}_{i=1}^{N}\) represent a pretraining dataset of \(N\) data points, including \(z_{i}=(x_{i},y_{i})\) features and labels in supervised learning. The _forgetting dataset_, \(^{f}=\{z_{i}^{f}\}_{i=1}^{N^{f}}\), is a subset of the pretrained dataset. Its complement, \(^{r}=\{z_{i}^{r}\}_{i=1}^{N^{r}}=^ {f}\), is the _remaining dataset_ that we wish to retain. The learner is a model parameterized by \(\). \(p_{z}()=p(z;)\) represents the model output probability. The pre-trained model

Figure 1: Overview of our proposal vs. previous unlearning methods on erasing concept ‘nudity’ in diffusion models [11; 12]. Conventional methods seek the steepest descent within an Euclidean ball, often compromising general capabilities. In contrast, we reach the region around retraining along a remain-preserving manifold. To address the large cost of Hessian, we implicitly approximate the up-to-date salient unlearning direction.

is obtained by empirical risk minimization, i.e., \(_{0}=_{}(;)=_{}_{ i}(;z_{i})\), as **Pretrain**. This empirical risk can be divided into two parts based on the forgetting and retaining datasets. \((;)=_{i^{f}}_{i}( ;z_{i}^{f})+_{j^{r}}(;z_{i}^{r})=^ {f}(;)+^{r}()\), where \(=\{_{i}\}_{i=1}^{N_{f}}\) weight the former part [39; 38]. For the pre-trained model, the coefficients \(_{0}=\) are all ones. The following are the instantiations in CV unlearning tasks. In classification (Cls) problems, models output the class posterior probability \(p(z_{};)=p(y|x;)\) and the empirical risk for each sample is the cross-entropy (CE) loss \(_{}(;z)=_{}(;x,y)\). In the image generation (Gen) task of conditional diffusion models [40; 41; 42], the output is the conditional sampling probability \(p(z_{};)=p(x|y;)\), and the average loss function for each sample is the mean squared error (MSE) loss: \(_{}(;z)=_{}(;x,y)=_{t,e (0,1)}[\|-_{}(x_{t}|y)\|_{2}^{2}]\), where \(t\) represents the diffusion step, \(\) is the random noise sampled from a Gaussian distribution \((0,1)\), \(_{}\) is the conditional denoising model, and \(x_{t}\) is the noisy version of the input image. For a more detailed introduction to image generation using conditional diffusion models and latent diffusion models, please refer to Appendix B.3.

**Exact and Approximate Machine Unlearning.**_Exact MU_[15; 43; 1] ensures that the parameter distribution of the unlearned model is identical to that of a model trained from scratch without seeing the forgetting samples. For large-scale models, exact unlearning can only be achieved by retraining (**RT**) on the remaining dataset \(_{*}=_{}^{r}()\). However, the computational cost of retraining in response to every forgetting request is prohibitive. Therefore, we regard RT as _a gold standard_ to approximate rather than a competitor. A more practical approach is to guide the unlearned model output distribution to approximate the output distribution of RT, known as _approximate MU_. If we use KL divergence to measure the difference in output distributions, the objective of approximate unlearning can be expressed as: \(_{}D_{}(p_{z}(_{*})||p_{z}())=_{}  p_{z}(_{*})[p_{z}(_{*})/p_{z}()]\), starting from \(_{0}\). Therefore, a straight metric to approximate unlearning is the KL divergence from the retrained model's output distribution. In addition, we also investigate metrics related to forgetting efficacy, retained performance, and privacy protection for evaluation in image classification and generation tasks. For details of evaluation, please refer to **Sec.5** and Appendix D.

**Steepest Descent.** Approximate MU methods are usually based on gradient updates to obtain the unlearned model [18; 21]. Let's first reinterpret the gradient with _steepest descent_[29; 27; 30]. The goal of steepest descent is to find the direction \(=_{t+1}-_{t}\) that drives the objective function \(F()\) descent fastest within a \(\)-neighborhood of the current parameters \(_{t}\). This can be formulated as the following optimization problem. (See Appendix A.1 for proof.)

\[:=*{arg\,min}_{(_{t},_{t}+ )}F(_{t}+)_{t+1}:= *{arg\,min}_{_{t+1}}F(_{t+1})+(,_{t})} (_{t},_{t+1}), \]

where \((,)\) represents the manifold metric that renders the geometry of the parameter's neighborhood. To simplify the derivation, we rewrite it to the form on the right, where \(_{t}(,_{t})\) represents the learning rate required to move the distance \(\). In the following, we fix a small learning rate \(_{t}\) to approximate a search within a local neighborhood. The characterization \(\) of the underlying coordinate space of the neighborhood will determine update directions, optimization paths, and the flatness of the minimum. Vanilla gradient descent is obtained using the Euclidean metric, Newton's direction is measured by the second-order expansion of the objective function , and the KL divergence in the output space induces a natural gradient [30; 45]. Next, we will probe approximate MU through vanilla gradient descent and attempt to benefit from improved manifold metrics.

## 3 Approximate MU from Perspective of Steepest Descent

**Revisit Approximate MU Methods via Vanilla Gradient Descent.** We begin with the vanilla gradient descent direction to address approximate MU. This involves finding the steepest descent direction that minimizes the KL divergence with the retrained output within the vicinity of the current model \(_{t}\). The optimization problem can be formalized as follows:

\[_{t+1}=*{arg\,min}_{_{t+1}}D_{} (p_{z}(_{*})||p_{z}(_{t+1}))+}( _{t},_{t+1}) \] \[=*{arg\,min}_{_{t+1}}} (p_{z^{f}}(_{*})||p_{z^{f}}(_{t+1}))}{(a)}p^{f}+ }(p_{z^{r}}(_{*})||p_{z^{r}}(_{t+1}) )}_{(b)}p^{r}+},_{t +1})}_{(c)},\]

where \(p^{f}=p(^{f}|)\) and \(p^{r}=p(^{r}|)=1-p_{f}\) denote the partition of forgetting and remaining dataset, respectively. Analyzing (2), (\(a\)) seeks to eliminate the influence of the target forgetting samples, (\(b\)) aims to maintain the performance on the remaining samples, and (\(c\)) employs the metric \(\) to constrain the magnitude of each update, thereby identifying the direction of steepest descent on the manifold. To solve the optimization challenge outlined in (2), we posit that for the current model \(_{t}\), there exists a set of coefficients \(_{t}=\{_{t,i}\}_{i=1}^{N_{f}}\) that weights the forgetting loss, positioning \(_{t}\) as the minimizer of the weighted loss for the original training set. The unlearning process necessitates adaptations in coefficients of forgetting loss. Then, we can determine the vanilla gradient descent for approximate MU by using _Euclidean distance_\(_{2}\) as the manifold metric, as stated in **Prop. 1**.

**Proposition 1**.: _Under the Euclidean manifold metric, \((_{t},_{t+1})=\|_{t}-_{t+1}\|^{2}\). Assuming that the current model \(_{t}=_{}^{}(;_{t})+ ^{}()\). Let \(H_{s}^{f}=^{2}^{}(_{*};)\)and \(H_{*}^{r}=^{2}^{}(_{*})\) denote the Hessian of the retrained model on the forgetting set and the remaining set, respectively. Then, the steepest descent direction that minimizes (2) is approximately:_

\[_{t+1}-_{t}:=^{f}(H_{*}^{r})^{-1}}_{(S)}[ ^{}(_{t};_{t})}_{(F )}]p^{f}+^{}(_{t})}_{(R)}p^{r}]. \]

The proof can be found in Appendix A.2. To elucidate the effectiveness of gradient-based unlearning methods, we decompose the vanilla gradient descent direction in (3) into three components: (F), (R), and (S). (F) represents the gradient ascent direction of the weighted forgetting loss, which directs the model to discard the information of the forgetting samples. Fine-tuning (**FT**)  fails to guarantee MU due to the absence of (F). Current approximate MU methods such as Random Labeling (**RL**)  and BadTeacher knowledge distillation (**BT**)  are akin to weighted forgetting loss gradient ascent, uniformly leading to an increase in the loss on forgetting samples. The unlearning process often causes catastrophic forgetting of the retained knowledge. Thus, it is common to integrate (R) fine-tuning on the remaining set to sustain the model's general capabilities. Unlearned models via Gradient Ascent (**GA**)  usually lose usability without (R). Furthermore, (S), ignored in most of the previous literature, involves two Hessian modulation parts. \(H_{s}^{f}\) amplifies the parameter updates crucial for forgetting, while \((H_{s}^{r})^{-1}\) dampens those important for maintaining. The notion of (S) closely mirrors the _Weight Saliency_ introduced in **SalUn**. We provide theoretical support for this notion. Importantly, our framework makes no assumption regarding input modalities, allowing its flexible application across various CV unlearning tasks.

**Approximate MU in Remain-preserving Manifold.** In fact, employing Euclidean distance as the manifold metric for parameter updates is arbitrary. It treats all coordinates as equally important because the local second-order expansion is identical \(^{2}_{_{t}}(\|_{t}-_{t+1}\|^{2})=I\). This uniform treatment overlooks the varying parameter significance for forgetting and remaining. Moreover, certain manifolds of parameter space can exhibit substantial variations in Euclidean metric, yet the induced model output remains almost unchanged . Since the retrained model performance on forgetting is unpredictable, it is pragmatic to introduce manifolds related to the remaining. Therefore, a practical objective is to constrain parameter updates during unlearning within a manifold that minimally impacts the retained performance. An empirical characterization of such a manifold could be _the KL divergence on the output distribution of the remaining set_, \(D_{}^{r}\). Given that the original well-trained and the retrained model output closely match the ground-truth remaining distribution, \(^{r}(_{0})^{r}(_{*})  0\). By starting with \(_{0}\) and limiting updates to this manifold, the maintained output distribution remains almost consistent throughout the unlearning iterations, \(^{r}(_{t+1})^{r}(_{t}) ^{r}(_{0}) 0\). This consistency permits a second-order Taylor expansion at \(_{t}\) to terms (b) and (c) in (2), providing crucial curvature information for unlearning to prevent deviations in the model output on the remaining set, leading to **Prop. 2**.

**Proposition 2**.: _Using the model output KL divergence on the remaining set as the manifold metric, \((_{t},_{t+1})=D_{}(p_{z^{r}}(_{t})||p_{z^{ r}}(_{t+1})))\). Assuming that the current model \(_{t}=_{}^{r}()+^{}(; _{t})\). Let \(_{t}=_{t}p^{f}/(_{t}p^{r}+1)\), and \(H_{t}^{r}=^{2}^{r}(_{t})\) represent the Hessian w.r.t. \(_{t}\) on the remaining set, then the steepest descent direction that minimizes (2) is approximately:_

\[_{t+1}-_{t}:=-_{t}^{r})^{-1}}_{(R)} [^{f}(H_{s}^{r})^{-1}}_{(S)}[ ^{}(_{t};_{t})}_{(S)}]^{}(_{t};_{t})]}_{(F)}]. \]

  
**Approximate** &  &  &  &  \\
**MU Methods** & Cts & Gen & (S) & (F) & (R) & **Metric** & **Hessian** \\  FT  & ✓ & & & & & ✓ & \(_{2}\) & \\ GA  & ✓ & ✓ & & ✓ & ✓ & \(_{2}\) & \\ BT  & ✓ & ✓ & ✓ & ✓ & ✓ & \(_{2}\) & \\ SA  & ✓ & ✓ & ✓ & ✓ & ✓ & \(_{2}\) & \\ SA  & ✓ & ✓ & ✓ & ✓ & ✓ & \(D_{}\) & \\  SPR-on & ✓ & ✓ & ✓ & ✓ & ✓ & \(D_{}\) & ✓ \\   

Table 1: Comparison of approximate MU methods. We decompose the steepest descent direction into three parts: the weight saliency matrix (S), the forgetting part (F), and the remaining part (R) as in (3) and (4). Only SA and our method consider the remain-preserving manifold, and we further approximate up-to-date Hessian.

We defer the proof to Appendix A.3. The unlearning updates in (4) incorporated second-order Hessian concerning remaining to guide the optimization direction. Specifically, the large curvature direction of \(H_{t}^{r}\) corresponds with the weights that encapsulate remaining knowledge, while the small curvature direction encourages model updates for effective unlearning. Furthermore, the update direction in (4) primarily follows the weighted gradient ascent (F) modulated by weight saliency (S). Such unlearning iterative updates in remain-preserving manifold focus on diminishing the distributional discrepancy with exact MU concerning forgetting output.

**Challenges in Hessian Approximation.** To exploit the benefits of unlearning updates within the remain-preserving manifold, the key point is \((H_{t}^{r})^{-1}\). However, calculating the Hessian and its reverse for large-scale models is computationally demanding . Consequently, many methods have been developed to estimate the Hessian, such as Fisher information , Fisher diagonals , and Kronecker factored Laplace approximation . Regarding unlearning, Selective Amnesia (**SA**)  employs the initial model's remaining Fisher diagonals as the second-order Hessian constraint on parameter updates. However, the fixed Hessian in SA leads to progressively increasing estimation biases, exacerbated by cumulative errors in Taylor expansion, which harms the retained performance during unlearning. To address this issue, the subsequent **Sec. 4** introduces an fast-slow weight update method that implicitly approximates the direction adjusted by the up-to-date Hessian.

## 4 Proposed Method

**Implicit Online Hessian Approximation (R-on).** Given that computing the inverse of even well-approximated Hessian demands substantial computational resources, it is more practical to estimate the unlearning direction post-Hessian inversion modulation directly. Inspired by recent insights into the connection between Meta-Continual Learning and Hessian approximation , we propose a fast-slow weight [36; 37] method for implicitly approximating the desired updates. The optimization problem for fast weight updates is formulated as follows:

\[_{_{t}^{f}}^{r}(_{t}^{f}) _{t}^{f}=_{t}-_{t}^{u}(_{t}), \]

where \(^{u}\) represents an arbitrary forgetting loss and \(_{t}\) is its learning rate. The iterative process is depicted in **Fig. 1**. A step of forgetting is taken at the current model, resulting in \(_{t}^{f}\). Several gradient descent updates on the remaining set follow to obtain the minimum point \(_{t}^{r}\). This fine-tuning ensures that the updated model adheres to the remain-preserving manifold. The slow weight updates leverage the underlying connection between \(_{t}\) and \(_{t}^{r}\), as stated in **Prop. 3.**

**Proposition 3**.: _For implicit online Hessian approximation in (5), suppose \(_{t},_{t}\) is small, \(_{t}</|^{r}(_{t})-[^{r}(_{t})]^{2}|}\), \(^{r}\) is \(\)-smooth, i.e., \(\|^{r}()-^{r}(^{})\|_{2} \|-^{}\|_{2}\), and there exist an \(_{t}\)-neighborhood \((_{t}^{r},_{t})\) of the optimal model parameter \(_{t}^{r}=_{_{t}^{f}}^{r}(_{t}^{f})\), which includes \(_{t}\) and \(_{t}^{f}\). Then, the iterative update term approximately is,_

\[_{t}-_{t}^{r}:_{t}^{2}[^{2}^{r} (_{t})]^{-1}^{u}(_{t})=_{t}^{2}(H_{t} ^{r})^{-1}^{u}(_{t}). \]

The proof is in Appendix A.4. **Prop. 3** indicates that the model \(_{t}^{r}\), obtained after fine-tuning using the process described in (5), is approximately equivalent to updating the current model \(_{t}\) by one step in the Hessian-adjusted unlearning direction. We use this direction to update the outer loop.

**Comparison with the joint loss (R).** We investigate the differences in the updates between our optimization in (5) (**R-on**) and the joint optimization of forgetting and remaining losses (**R**) [23; 25]. We take the checkpoint after the first step of fine-tuning the remaining set as an example and ignore the step size.

\[^{}(_{t})=^{u}(_{t})+^{r} (_{t}),^{}=^{u}(_{t})+ ^{r}(_{t}), \]

\[^{}^{u}(_{t})+ ^{r}(_{t})+^{2}^{r}(_{t})(_{t}^{f}-_{ t})=(I-H_{t}^{r})^{u}(_{t})+^{r}( _{t}), \]

Comparison of the updates in (7) and (8) reveals that the remaining gradient is the same. Our forgetting update in fast weight is adjusted by an additional term \(-H_{t}^{r}\), which is absent in joint optimization. This modification weakens the directions that significantly impact the remain, thereby mitigating the damage of forgetting loss on the retained performance. Furthermore, certain methods  suggest two-stage unlearning that first impairs the model and then repairs it, actually paralleling a single fast-slow weight update of our method.

[MISSING_PAGE_EMPTY:6]

## 5 Experiments

**Datasets, Models, and Settings.** In image classification, we primarily focus on the **random subset unlearning** task. Evaluations are conducted using ResNet-18  on CIFAR10  and Swin-T  on TinyImageNet , with additional tests on random subset and class-wise forgetting tasks involving CIFAR100  and SVHN , detailed in Appendix F.2. In image generation, our main interest lies in **class-wise forgetting** tasks. Following [35; 26], we unlearn conditional DDPM  with the UNet architecture  on CIFAR10. Moreover, for the first time, we explore the latent diffusion model  equipped with Diffusion Transformer (DiT)  on ImageNet , which demonstrates superior scalability in learning large-scale data generation tasks. Finally, we perform **concept forgetting** tasks using the open-source Stable Diffusion (SD) V1.4  to inhibit the generation of NSFW content, specifically by targeting the prevention of nude images. Further details on unlearning setups and training are available in Appendix E.

**Baselines and Evaluation.** We regard RT as an oracle of approximate MU and compare our proposal with eight MU methods, including six gradient-based MU approaches outlined in **Sec. 3**: **FT**, **GA**, **BT**, **RL**, **SalUn**, and **SA**. We also consider **SCRUB**, an enhanced variant of BT, for image classification, and **ESD** for removing concepts in SD. For the evaluation of random subset unlearning tasks, we measure the output KL divergence \(D_{}\) between the unlearned and retrained models, which is the direct target of approximate MU. Besides, we assess the accuracy on the forgetting set (**FA**) for unlearning efficacy, and the accuracy on the remaining (**RA**) and test (**TA**) sets for preserved generalization ability. We also consider the success rate of membership inference attack (**MIA**) [60; 38] on the forgetting set as a privacy metric. Note that the smaller the disparity in these metrics against RT, the more effective the unlearning. Run-time efficiency (**RTE**) is also reported. For class-wise forgetting tasks in image generation, we evaluate the accuracy of the unlearned model's generated images on forgetting classes (**FA**) by a pre-trained classifier. The Frechet Inception Distance (**FID**)  metric assesses the retained generative capability for remaining classes. For ablating the 'nudity' concept in SD, we employ the NudeNet  detector to identify and count nude body parts in generated NSFW images. For further introduction to the baselines and detailed evaluation metrics, please refer to Appendix E.1 and D.

To assess the unlearning effectiveness and efficiency of **SFR-on**, we perform comprehensive experiments and conduct ablation studies to address the following **four key questions**:

**Q1: How does SFR-on perform on unlearning in image classification?** We first evaluate the performance of our method, SFR-on, against existing gradient-based MU methods on the image classification random subset unlearning task. In this scenario, the forgetting set, remaining, and test sets all originate from the same distribution. Consequently, even if the model undergoes unlearning on the random subset, it may still generalize to these samples. To avoid potential biases from only using FA as an unlearning metric, we incorporate MIA to assess the privacy retention of the forgetting set, enhancing the robustness of assessments. As detailed in **Tab. 2**, for forgetting 10% random subset on CIFAR-10 and TinyImageNet, SFR-on not only most closely aligns with RT in the averaging metric disparity but also exhibits the smallest output KL divergences _w.r.t._ RT. This performance underscores our effectiveness and efficiency in achieving the objective of approximate MU. The results of the increased 50% random subset unlearning task are included in Appendix F.2.

  } &  &  &  &  \\   & PA & **Ex.** & **1** & **MIA** & **[**\%**] & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** & **[**\%**]** \\    & **F** & **6.5(0.0)** & **0.0(0.0)** & **0.

[MISSING_PAGE_FAIL:8]

**Q4: How effective is SFR-on in NSFW content removal for SD?** We finally assess the efficacy of our method in removing the 'nudity' concept from the open-source SD to prevent the generation of NSFW content. Given that SD V1.4 is trained on the LAION dataset , purging all images depicting nudity and retraining the model would be prohibitively time-consuming and resource-intensive. In this unlearning task, we designate 'nudity' as the forgetting set and generate a set of clothed individuals as remaining to preserve SD's generalization capability across non-nudity themes. We utilize the inappropriate image prompts (I2P)  to query potentially NSFW content from the unlearned SD and employ NudeNet to detect exposed body parts in these images. The results in **Tab. 4** demonstrate that our method significantly prevents the generation of culturally sensitive body parts, such as breasts and genitalia, highlighting our strength to enhance the trustworthiness of machine learning applications.

## 6 Conclusion

This paper revisits gradient-based approximate MU methods from the perspective of the steepest descent. The descent direction under an Euclidean manifold metric can be divided into three integral components: weighted forgetting gradient ascent, fine-tuning remaining gradient descent, and weight saliency matrix. Our approach advances beyond the Euclidean constraints by embedding the unlearning update within a remain-preserving manifold. This novel strategy incorporates the second-order Hessian of the current model on remaining, safeguarding against detrimental impacts on retained performance. To circumvent the prohibitive computational demands of the Hessian in large-scale models, we introduce an efficient fast-slow weight update method to approximate the Hessian-adjusted direction. Furthermore, our innovative adaptive coefficient for weight forgetting loss and a forget-remain balanced weight saliency map facilitate near-retraining unlearning. Our method can be applied to popular CV unlearning tasks with empirically verified unlearning efficacy.

    & }}}}}}}}}}}}}}\)} &  \\  & I1 & I2 & C1 & C2 & C3 & C4 & C5 \\    &   } &   } &  \\  & I1 & I2 & C1 & C2 & C3 & C4 & C5 \\    &   } &   } &  \\  & I1 & I2 & C1 & C2 & C3 & C4 & C5 \\    &   } &   } &  \\  & I1 & I2 & C1 & C2 & C3 & C4 & C5 \\    & {