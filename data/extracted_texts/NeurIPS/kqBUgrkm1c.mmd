# Easy Learning from Label Proportions

Robert Busa-Fekete

Google Research

busarobi@google.com

&Heejin Choi

Coupang Inc

hechoi53@coupang.com

&Travis Dick

Google Research

tdick@google.com

&Claudio Gentile

Google Research

cgentilek@google.com

&Andres Munoz Medina

Google Research

ammmedina@google.com

Work done while at Google.

###### Abstract

We consider the problem of Learning from Label Proportions (LLP), a weakly supervised classification setup where instances are grouped into i.i.d. "bags", and only the frequency of class labels at each bag is available. Albeit, the objective of the learner is to achieve low task loss at an individual instance level. Here we propose EasyLLP, a flexible and simple-to-implement debiasing approach based on aggregate labels, which operates on arbitrary loss functions. Our technique allows us to accurately estimate the expected loss of an arbitrary model at an individual level. We elucidate the differences between our method and standard methods based on label proportion matching, in terms of applicability and optimality conditions. We showcase the flexibility of our approach compared to alternatives by applying our method to popular learning frameworks, like Empirical Risk Minimization (ERM) and Stochastic Gradient Descent (SGD) with provable guarantees on instance level performance. Finally, we validate our theoretical results on multiple datasets, empirically illustrating the conditions under which our algorithm is expected to perform better or worse than previous LLP approaches.

## 1 Introduction

In traditional supervised learning problems, a learner has access to a sample of labeled examples. This collection of labeled examples is used to fit a model - to name a few, decision trees, neural networks, random forests - by minimizing a loss over the observed sample. By contrast, in the problem of Learning from Label Proportions (LLP), the learner only observes collections of unlabeled feature vectors called _bags_, together with the proportion of positive examples in each bag. The LLP problem is motivated by a number of applications where access to individual examples is too expensive or impossible to achieve, or available at aggregate level for privacy-preserving reasons. Examples include e-commerce, fraud detection, medical databases , high energy physics , election prediction , medical image analysis , remote sensing .

As a weakly supervised learning paradigm, LLP traces back to at least , and was motivated there by learning scenarios where access to individual examples is often not available. A paradigmatic example is perhaps a political campaign trying to predict the preference of the electorate. Since voting is anonymous, a political analyst may not be able to observe individual votes, yet, they have access to aggregate voting preferences at the district level.

The problem has received renewed interest more recently (e.g., ), driven by the desire to provide more privacy to user information. For instance the ad conversion reportingsystem proposed by Apple, SKAN, allows an ad tech provider to receive information about the conversions (e.g., purchases) from customers only aggregated across multiple impressions. This aggregation is intended to obfuscate the individual customer's activity. A similar API has also been proposed by Google Chrome and Android to report aggregate conversion information (e.g., ). Given the importance of conversion modeling for online advertising, learning how to train a model using only these aggregates has become a crucial task for many data-intensive online businesses.

Research in LLP can be coarsely divided into two types of goals: Learning a bag classifier that correctly predicts label proportions, and learning an individual classifier that can correctly predict instance labels. The former has been the focus of most of the literature in this area. Representative papers include . While training classifiers to match label proportions is an obvious heuristic, little work has been done in trying to understand under which conditions these classifiers would be accurate when generating event level predictions. Yu et al.  provide guarantees that suggest that, under the absolute loss, predicting label predictions to very high accuracy can result in good predictions at event level. On the other side of this research area, finding a good instance level predictor using only label proportions has so far remained elusive and under-explored in its generality. The solutions introduced so far require either making some assumptions on the data generation process  or on the model class . Other solutions involve solving complex combinatorial problems  or require that an example belongs to multiple bags .

In this work we provide a two pronged approach towards making LLP on _randomly generated_ bags seamless. First, we contribute to a better theoretical understanding of a well-known label proportion prediction algorithm. This algorithm simply trains a model whose average prediction on a bag is as close as possible to the label proportion in that bag. This straightforward algorithm is referenced (either explicitly or implicitly) in multiple past works (e.g., ), yet is hardly analyzed theoretically, or even considered as a baseline for experimental comparisons. Here, we show under what conditions this folklore algorithm can produce good event level predictions. Moreover, we show through extensive experimentation that when those conditions are met this algorithm seems to outperform previous baselines tailored to generating event level predictions. On the flip side, when such conditions are not met, we also show that the quality of this algorithm quickly deteriorates as the bag size increases.

A more robust and flexible approach to LLP that operates at the instance level is EasyLLP, a reduction method virtually applicable to _any_ machine learning task. Unlike many algorithmic proposals in this space, the implementation of EasyLLP requires trivial modifications to current machine learning training pipelines. We elucidate the flexibility of our approach by applying it to two widely interesting algorithmic techniques, Empirical Risk Minimization (ERM) and Stochastic Gradient Descent (SGD). Our findings are complemented by an extensive experimental investigation on a diverse suite of benchmark datasets.

Main contributions.The contribution of our paper can be summarized as follows.

1. We provide a theoretical analysis of a popular label proportion matching algorithm, that is suggestive of the conditions under which this algorithm is expected to work in practical scenarios. Despite its relative simplicity, the scope of this analysis is broad and, to the best of our knowledge, original.
2. We provide a general debiasing technique for estimating the expected instance loss (or loss gradient) of an arbitrary model using only label proportions, and thoroughly quantify the variance of this estimator.
3. We provide a reduction of ERM with label proportions to ERM with individual labels, and show that when the learner observes bags of size \(k\), the sample complexity of ERM with label proportions increases only by a factor of \(k\). Likewise, we provide an analysis of SGD using only label proportions and show that for bags of size \(k\), its regret increases by only a factor of \(k\).
4. We carry out an extensive set of experiments comparing the proportion matching method and EasyLLP to known methods available in the LLP literature. The experiments are designed to encompass diverse combinations of datasets and learning models. We identify general trends in the relative performance of the tested methods when evaluated at the instance level. To the best of our knowledge, in spite of its folklore status, this is the first thorough investigation that involves the proportion matching algorithm and its comparison to event level classifiers. We believe the latter is by itself an important contribution on its own, as proportion matching turns out to be a strong baseline in a number of cases.

Related work.Interest in LLP traces back to at least . The literature in recent years has become quite voluminous, so we can hardly do justice of it here. In what follows, we comment on and contrast to the references from which we learned about LLP problems.

In  the authors consider a hierarchical model that generates labels according to the given label proportions and proposed an MCMC-based inference scheme which, however, is not scalable to large training sets.  shows how standard supervised learning algorithms (like SVM and \(k\)-Nearest Neighbors) can be adapted to LLP by a reformulation of their objective function via label proportion matching. Yet, no experiments are reported on classification tasks. In , the authors propose a theoretically-grounded way of estimating the mean of each class through the sample average of each bag, along with the associated label proportion. The authors make similar assumptions to ours, in that the class-conditional distribution of data is independent of the bags. However, their estimators rely on very strong assumptions, like conditional exponential models, which are not a good fit to nowadays Deep Neural Network (DNN) models. Similar limitations are contained in .  proposes an adaptation of SVM to the LLP setting through a scheme which can be seen as calibration on top of proportion matching. Yet, this turns out to be restricted to linear models in some feature space. Similar limitations are in the \(\)-SVM method proposed in , the non-parallel SVM formulation of , and the pinball loss SVM in . The original \(\)-SVM formulation was extended to other classifiers; e.g.,  extends the formulation to CNNs with a generative model whose associated maximum likelihood estimator is computed via Expectation Maximization, which turns out not to be scalable to sizeable DNN architectures.  proposes a method based on \(k\)-means to identify a clustering of the data which is compatible with the label proportions, but their method suffers from an extremely high computational complexity.

Many of these papers are in fact purely experimental in nature, and their main goal is to adapt the standard supervised learning formulation to an LLP formulation so as to obtain a bag level predictor.

On the learning theory side, besides the already mentioned , are the efforts contained in , the task of learning from multiple unlabeled datasets considered in , and the statistical learning agenda pursued in  (and references therein from the same authors). In  the author is essentially restricting to linear-threshold functions and heavily relies on the fact that an example can be part of multiple bags, while we are working with non-overlapping i.i.d. bags and general model classes. In  the authors consider a problem akin to LLP. Similar to our paper, the authors propose a debiasing procedure via linear transformations. Yet, the way they solve the debiasing problem forces them to impose further restrictions on the bags, like the separation of the class prior distributions across different bags. It is this diversity that allows the authors to construct unbiased estimates and then derive consistency results. On the contrary, the bags proposed in our setup are drawn i.i.d. from the same prior distribution, a scenario where many of these algorithms would fail. Hence, we work under the assumption that we cannot handcraft diverse bags out of our samples, as the aggregation into bags is done without having access to the class conditional distributions (which  and related papers heavily rely upon). Moreover, the convergence results to the event level performance are only proven in those papers with specific families of loss function (e.g., proper loss functions). See Section 5 for further in-context discussion.

The work  introduced a principled approach to LLP based on a reduction to learning with label noise. As in , their basic strategy is to pair bags, and view each pair as a task of learning with label noise, where label proportions are related to label flipping probabilities. The authors also established generalization error guarantees at the event level, as we do here.  extend their results to LLP for multiclass classification. From a technical standpoint, these two papers have similar limitations as . Besides, the risk measure they focus on is balanced risk rather than classification risk, as we do here.

In our experiments (Section 7), we empirically compare EasyLLP to a folklore label proportion matching method, to the MeanMap method from , and to a label generation approach from , the latter viewed as representative of recent applications of DNNs to LLP.

## 2 Setup and Notation

Let \(\) denote a feature (or instance) space and \(=\{0,1\}\) be a binary2 label space. We assume the existence of a joint distribution \(\) on \(\), and let \(p=_{(x,y)}(y=1)\) denote the probability of drawing a sample \((x,y)\) from \(\) with label \(y=1\). For a natural number \(n\), let \([n]=\{i i n\}\).

A labeled _bag_ of size \(k\) is a sample \(=\{x_{1},,x_{k}\}\), together with the associated _label proportion_\(()=_{j=1}^{k}y_{j}\), where \((x_{1},y_{1}),,(x_{k},y_{k})\) are drawn i.i.d. according to \(\). We assume the learner has access to a collection \(=\{(_{i},_{i}),\,i[n]\}\) of \(n\) labeled bags of size \(k\), where \(_{i}=\{x_{ij} j[k]\}\), \(_{i}=(_{i})=_{j=1}^{k}y_{ij}\) is the label proportion of the \(i\)-th bag, and all the involved samples \((x_{ij},y_{ij})\) are drawn i.i.d. from \(\). In words, the learner receives information about the \(nk\) labels \(y_{ij}\) of the \(nk\) instances \(x_{ij}\) only in the aggregate form determined by the \(n\) label proportions \(_{i}\) associated with the \(n\) labeled bags \((_{i},_{i})\) in collection \(\). Notice, however, that the instances \(x_{ij}\) are individually observed.

Given a hypothesis set \(\) of functions \(h\) mapping \(\) to a prediction space \(}\), and a loss function \(:}\,\,\,\,\,^{+}\), the learner receives a collection \(\), and tries to find a hypothesis \(h\) with the smallest _population loss_ (or _risk_) \((h)=_{(x,y)}[(h(x),y)]\) with high probability over the random draw of \(\). When clear from the surrounding context, we will omit subscripts like "\((x,y)\)" or "\(\)" from probabilities and expectations.

We shall consider two broadly used learning methods for solving the above learning problem, Empirical Risk Minimization (ERM, Section 5), or regularized versions thereof, and Stochastic Gradient Descent (SGD, Section 6). In this latter context, we will consider a parameter space \(\) and consider a learner that tries to optimize a loss \(\) iteratively over a collection of bags. Before that, we find it instructive to delve into the theoretical properties of an approach to LLP which is by now belonging to folklore.

## 3 Proportion Matching Algorithm

We now introduce a simple and very well known algorithm for learning from label proportions. Yu et al.  refers to this algorithm as Empirical Proportion Risk Minimization but different versions of the algorithm are discussed in the LLP literature without a clear reference to its origin.

**Definition 3.1**.: Given a loss function \(\,:\,^{+}\), a hypothesis set of functions \(\), and a collection \(=\{(_{i},_{i}),\,i[n]\}\) of \(n\) labeled bags of size \(k\), the PropMatch algorithm minimizes the empirical _proportion matching loss_, i.e. it solves the following optimization problem

\[_{h}_{i=1}^{n}_{j=1}^{k}h(x_ {ij}),_{i}\,.\] (1)

That is, the PropMatch algorithm creates a bag level prediction by simply averaging the predictions of a model on the bag's individual examples. Yu et al.  prove a uniform convergence guarantee implying that, given enough data, the minimizer of the empirical proportion matching loss is an approximate minimizer of the _population level_ proportion matching loss:

\[_{h}}_{,}[ (_{x}h(x),)]\,.\] (2)

In general, the minimizer of the population level proportion matching loss may not produce accurate event-level predictions. However, Yu et al.  further show that when \(\) is the absolute loss, achieving small population level proportion matching loss also leads to a classifier with small population level event loss.

We now strengthen those results and show that under some general conditions on the loss function, and if the function class \(\) is expressive enough, minimizing the population level proportion matching loss is equivalent to minimizing the population level event loss.3

**Theorem 3.2**.: _Assume \(\) is such that the function \(h^{*} x(y=1|x)\) is in \(\). Let \(\,\,:^{+}\) be such that, for any random variable \(Z\), \(q=[Z]\) is the unique solution of \(_{r}_{Z}[(r,Z)]\). Then, \(h^{*}\) is a minimizer of (2). Moreover, every other minimizer \(h\) satisfies \((h(x)\)=\(h^{*}(x))=1\)._

**Corollary 3.3**.: _Let \(\) satisfy the conditions of Theorem 3.2. Then \(h^{*}\) as defined above is the unique minimizer for the proportion matching loss when \(\) is the square loss or the binary cross-entropy loss._

The above corollary provides us with conditions for the proportion matching loss minimizer to also minimize the event level loss. It is natural to ask ourselves, what the behavior of the proportion matching loss would be when those conditions are violated. To our knowledge, this remains an open problem. However, the following example shows that if the model class \(\) is not expressive enough, then using the proportion matching loss can in fact lead to an arbitrarily bad event level predictor.

To summarize, we have shown that PropMatch can, for the most popular classification and regression losses and under some assumptions on \(\), recover a very good instance level classifier. Nonetheless, when those assumptions are violated the performance of PropMatch can drastically degrade. We believe these observations pave the way for new exciting research in fully understanding this simple algorithm.

## 4 Easy LLP

Based on the results of the previous section, we are interested in defining a robust, theoretically founded algorithm for learning from label proportions. We now introduce the main tool for our approach.

**Definition 4.1**.: Let \(g^{d}\) be any (measurable) function, for some output dimension \(d 1\). Let also \(p=[y]\) be the probability of observing a positive label. We define \(^{d}\), the _soft-label corrected function_ associated with \(g\), as

\[(x,)=k(-p)+pg(x,1)+k(p-)+( 1-p)g(x,0)\;.\] (3)

The main property of \(\), which is relevant to LLP, is that it is as unbiased estimator of \(_{(x,y)}[g(x,y)]\), as we next show.

**Proposition 4.2**.: _Given a sample \((x_{1},y_{1}),,(x_{k},y_{k})\) drawn i.i.d. according to \(\), let \((,)\) be the corresponding labeled bag of size \(k\), for some \(k 1\). Let \(g^{d}\) be any (measurable) function, for some output dimension \(d 1\), and \(^{d}\) be its associated soft-label corrected function. Then for every element \(x_{j}\) we have_

\[}_{(,)}[(x_{j},)]= }_{(x,y)}[g(x,y)]\;.\]

For empirical risk minimization (ERM), we shall apply Proposition 4.2 with the function \(g\) that computes the per-example loss of a given model, so that we obtain unbiased estimates of the model's

Figure 1: **Left: Training loss for different learning approaches. PropMatch (using (1)), EasyLLP (using (3), Section 4), and event level using regular cross-entropy loss. Right: Test loss using event level labels to measure cross-entropy loss for all methods. Notice how the PropMatch training loss decreases but the test loss continues to increase. EasyLLP tracks the event level loss as suggested by theory.**population level loss. Similarly, for gradient-based optimization, we take \(g\) to be the function that computes the per-example gradient of the loss w.r.t. the model parameters so that we obtain an unbiased gradient estimate. More details of our application of Proposition 4.2 are given at the end of this section.

Proposition 4.2 shows that we can easily obtain an unbiased estimate of the expectation of any function \(g\) by applying a simple linear transformation to the output of \(g(x,y)\), for \(y=0,1\). We would like to highlight the importance of this simple proposition. Whereas there has been a lot of research in LLP, to our knowledge this is the first expression that shows that one can recover an unbiased estimate of an arbitrary function \(g\) using only information from label proportions.

While the above result provides us with a straightforward way to estimate the expectation of a function \(g\) (which can for instance be specialized to a loss function), note that the variance of \(\) increases as the number of elements in each bag grows. Indeed, since all terms in the definition of \(\) have a factor of \(k\), we might expect the variance of the estimator to grow as \(k^{2}\), which could be prohibitively large even for moderate values of \(k\). Notice however that because \(=_{j=1}^{k}y_{j}\), and each \(y_{j}(p)\), we expect by standard concentration arguments that \(k(-p) O()\) which should imply that the variance scales like \(k\). The following theorem shows that indeed, the variance of these estimates is of order \(k\) and not \(k^{2}\). In addition, since \((x_{j},)\) is unbiased for all \(j[k]\), so is \(_{j=1}^{k}(x_{j},)\). The same theorem also shows that the variance of the latter estimator is always smaller than the variance of the former. That is, using all \(k\) samples in a bag is always better (in terms of variance) than using any single sample.

**Theorem 4.3**.: _Let \(g^{d}\) be such that \(_{x,y}\|g(x,y)\|^{2} M\), and denote by \(\) its associated soft labeled corrected function. Also, set for brevity \(g_{0}=g(x,0)\) and \(g_{1}=g(x,1)\) and, for each \(j[k]\), \(_{j}=(x_{j},)\). Then, for any size \(k 1\) and any \(j[k]\),_

\[[||_{j}||^{2}] =[||g(x_{j},y_{j})||^{2}]+(k-1)p(1-p )\,|g_{0}-g_{1}||^{2}\] \[[|_{i=1}^{k}_{i}|^{2}] [||_{j}||^{2}]\,.\] (4)

_Moreover, there exists a universal constant \(C\) such that_

\[[|_{i=1}^{k}_{i} |^{2}] C+kp(1-p)[g_{0}-g_{1}] \,^{2}\,,\]

_where \(p=_{(x,y)}(y=1)\)._

The bound in the above theorem confirms our intuition. Moreover, it shows that the variance grows slower for datasets where \(p\) is close to \(1\) or \(0\). This is intuitively clear, for very skewed datasets, we expect label proportions to provide a better description of the true labels. In the extreme cases where \(p=0\) or \(p=1\), LLP becomes equivalent to learning from individual examples.

The results of this section have demonstrated that for any function \(g\), one can obtain an estimator of its expectation using only label proportions. More importantly the variance of this estimator only scales linearly with the bag size.

Note about knowledge of population level positive rate.At this point the reader is aware that the definition of the soft label corrected function requires knowledge of the population level positive rate \(p\). While the exact value of \(p\) is unknown, one can easily estimate it from the label proportions itself. Indeed, using the fact that the generated bags are i.i.d. it is easy to see that \(=_{i=1}^{n}_{i}=_{i,j}y_{ij}\) is a very good estimator for \(p\).

EasyLLP.We now have all elements to introduce the EasyLLP framework for learning from label proportions. The framework consists of specializing the function \(g\) for particular learning tasks. Two notable instantiations of EasyLLP which we will analyze in further sections are ERM and stochastic gradient descent (SGD). For ERM, given a hypothesis \(h\) and a loss function, we let \(g_{h}(x,y)=(h(x),y)\) and the corresponding soft label corrected loss \((h(x),)=_{h}(x,)\). To provide regret guarantees using SGD over bags in a parameter space \(\) and loss function \(\), we use EasyLLP to estimate the gradient of the loss function with respect to a parameter \(\) by letting \(g_{}(x,y)=_{}(,x,y)\) and its corresponding soft label corrected function \(_{}(x,)=(,x,)\).

## 5 ERM with Label Proportions

Given a hypothesis space \(\), let \(\) be a loss function as defined in Section 2. Given a collection of bags \(=\{(_{i},_{i}),\,i[n]\}\) of size \(k\), our learning algorithm simply finds \(h\) that minimizes the empirical risk constructed via the soft label corrected loss from Eq. (3):

\[_{i=1}^{n}_{j=1}^{k}(h(x_{ij}),_{i})\;.\] (5)

The main advantage of our algorithm lies in its simplicity and generality. Indeed, our algorithm can be used for any loss function and any hypothesis set. This is in stark contrast, e.g., to the works of [22; 20], whose framework is only applicable to the logistic loss and (generalized) linear models. From a practical standpoint, our approach can also leverage existing learning infrastructures, as the only thing that needs to be specified is a different loss function -- which in frameworks like Tensorflow, JAX and PyTorch requires only minimal coding. This differs from other approaches to assigning surrogate labels which may require solving combinatorial optimization problems (or relaxations thereof) like, e.g., [32; 8].

The following theorem provides learning guarantees for minimizing the above empirical loss. Our guarantees are given in terms of the well-known Rademacher complexity of a class of functions.

**Definition 5.1**.: Let \(\) be an arbitrary input space and let \(\{g\}\) be a collection of functions over \(\). Let \(\) be a distribution over \(\) and \(=\{z_{1},,z_{m}\}\) be an i.i.d. sample. The Rademacher complexity of \(G\) is given by \(_{n}()=}_{,}[_{g}_{i=1}^{n}g(z_{i}) _{i}],\) where \(=(_{1},,_{n})\{-1,1\}^{n}\) is uniformly distributed.

**Theorem 5.2**.: _Let \(>0\), \(=\{(_{i},_{i}),\,i[n]\}\) be a collection of \(n\) bags of size \(k\).4 Let \(_{,y}(,y) B\), and \(C_{n}^{k}=2(+1)\). Then the following bound holds uniformly for all \(h\) with probability at least \(1-\):_

\[|(h)-_{i,j}(h(x_{ij}),_ {i})| C_{n}^{k}(_{kn}(_{}^{(1)})+ _{kn}(_{}^{(0)}))++4B}\;,\]

_where \(\,_{}^{(1)}=\{x(h(x),1) h\}\,\) and \(\,_{}^{(0)}=\{x(h(x),0) h\}\)._

**Corollary 5.3**.: _With the notation of the previous theorem, let \(\) denote the minimizer of (5). Then with probability at least \(1-\) over the sampling process we have_

\[()_{h}(h)+2(C_{n}^ {k}(_{kn}(H_{}^{(1)})+_{kn}(H_{}^{(0)}) )++4B})\;.\]

Comparison to event level learning.We can now compare the bound from Theorem 5.2 to standard learning bounds for instance level learning like that of . Assuming we had access to a labeled i.i.d. sample \((x_{ij},y_{ij})\) of size \(kn\), Theorem 3.3 in  ensures that with probability at least \(1-\) the following bounds holds for all \(h\):

\[|(h)-_{i,j}(h(x_{ij},y_{ij}))| 2 _{nk}(_{})+B}\;,\] (6)

where \(_{}=\{(x,y)(h(x),y) h\}\). Note that under the weak assumption that the Rademacher complexities \(_{kn}(_{}^{(r)})\), \(r\{0,1\}\), are of the same order as \(_{kn}(_{})\), the main difference between the bound in Theorem 5.2 and (6) is simply an extra factor \(C_{n}^{k}()\) in the complexity term and a factor \(k\) multiplying the confidence term. That is, we achieve similar guarantees to event level learning by increasing the sample size by a factor of roughly \(k\).

It is worth stressing the difference in flavor of the consistency result contained in Theorem 5.2 above and those in [17; 16]. For instance, in  (even with \(m=2\) bags) the consistency limit has to be interpreted "as the bag size \(n_{tr}=n_{1}+n_{2}\) goes to infinity". In our case, the bag size \(k\) has to remain constant, and it is the number of bags \(n\) that goes to infinity. This further strengthens our claim that the stream of literature that those papers are representative of are by no means subsuming our results. Moreover, unlike our paper, all results in these previous works, as presented, make assumptions about the loss function (e.g., square loss or cross entropy for , margin-based losses for ). The fact that we make no assumptions allows us to apply our debiasing procedure to any function \(g(x,y)\) of two variables, hence we can debias, e.g., also the _gradient_ of a loss function, enabling the principled usage of stochastic gradient descent procedures with only label proportion information. This is illustrated in the next section.

## 6 SGD with Label Proportions

We now focus on understanding the effect of label proportions on another very popular learning algorithm: stochastic gradient descent (SGD).

Proposition 4.2 delivers an unbiased estimate of the gradient which can be naturally plugged into any SGD algorithm (e.g., ), and one would hope for an upper bound on the excess risk if the learning task at hand leads to a convex optimization problem. The difficulty is that, even if each gradient in a given bag is individually unbiased, the gradients are correlated since they depend on the label proportion computed on the bag. A simple way around it is to pick a single item uniformly at random from the bag to update the model parameters. This is a slight departure from what we considered for ERM, but it both makes our SGD analysis easier and does not affect asymptotic performance.

In order to devise an SGD algorithm that can handle bagged data, first note that the debiasing technique introduced in Proposition 4.2 is very general and it applies to any measurable function, including the gradient of any loss function. Let us denote the gradient of the loss on example \((x,y)\) by \(g_{}(x,y)\) where \(\) is the parameter vector of the model and let its soft-label corrected version be \(_{}\). We study a version of projected SGD that picks one example per bag and uses the soft-label corrected gradient estimates (pseudocode is given in in Algorithm 1 in the Appendix). The excess risk of this algorithm depends on the squared norm of the debiased gradients, which is at most \(k\) times larger than the variance of the original instance-level gradient based on Theorem 4.3. This observation results in the following risk bound.

**Theorem 6.1**.: _Suppose that \(F()=[_{}(x,y)]\) is convex, \([\|g_{_{t}}(x,y)\|^{2}] G^{2}\) for all \(t[n]\), and \(_{,^{}}\|-^{ }\| D\). Consider Algorithm 1, run with step size \(_{t}=1/\). Then for any \(n>1\) we have_

\[[F(_{n})-F(^{*})](D^{2}+5 G^{2})}\;.\]

This theorem quantifies the deterioration in the excess of the risk in terms of bag size when the algorithm is applied with LLP data. Recall that the error of SGD with \(kn\) individually labeled samples decreases like \(O1/\). Compared with the above bound, and similar to the ERM case, the regret bound increases by a factor of \(k\).

The most predominant learning frameworks used today fit deep models to data using SGD-like methods. Even though these problems are typically non-convex, we remark that Proposition 4.2 guarantees that the expected gradient steps of Algorithm 1 are equal to the expected steps of SGD using an instance-level loss. Moreover, Theorem 4.3 guarantees that the variance of the gradient estimates used by Algorithm 1 is not much larger than that of the instance-level case. In particular, it follows that whenever SGD is an effective algorithm for learning from instance-level data, Algorithm 1 should also be effective at learning from LLP data, provided that we have enough data to overcome the increased variance. This is thoroughly demonstrated in the next section. Finally, the only required modifications to any gradient-based training infrastructure to use EasyLLP are to replace the original labels \(y_{ik}\) by label proportions and to implement the soft-label corrected loss. Taken together, these properties of EasyLLP make it especially well suited to modern machine learning pipelines.

Experiments

In this section we empirically evaluate EasyLLP, PropMatch, and two baseline methods to characterize how their performance depends on the bag size for a range of different learning tasks and underlying learning models.

LLP Methods.We evaluate EasyLLP, PropMatch, and two baselines.5 The first baseline is MeanMap, which is a method specialized for learning linear logistic regression models from label proportions. We also compare against the method described in Section 3.2 of , which we denote by DA. The DA method computes a loss for each bag by creating synthetic labels for the examples that optimize a combination of the model's loss on the synthetic labels, and a divergence between the label proportion of the synthetic labels and the bag's label proportion. The DA method has an additional hyperparameter, \(\), which controls the weights on these two objectives. Full details of our DA implementation are in Appendix A.3.

Datasets.We carry out experiments on four (binary classification) datasets: Binarized versions of MNIST  and CIFAR-10 , as well as the Higgs  and UCI adult datasets . The labels in MNIST are replaced by labels indicating whether the digit is even or odd, and the CIFAR-10 labels are replaced by whether the original class is an animal or a machine. The MNIST images are resized to have shape \(32 32 3\) to match CIFAR-10. For both image datasets, we normalize the images to have \(_{2}\) norm equal to one. No preprocessing is performed on the Higgs dataset. Finally, on UCI Adult, we rescale numerical features to the range \(\) and one-hot encode categorical features.

Models.We evaluate each LLP method on every dataset using a linear model. Additionally, for the image datasets we also evaluate using a small ConvNet, a large ConvNet, and Resnet-11 . On Higgs we also use the DNN proposed by , which has 4 hidden layers, each with 300 units. Finally, on UCI Adult, we also use a NN with one hidden layer. Since the MeanMap baseline is only applicable to learning linear models, we do not include it in the neural network experiments. Full details of the architectures are provided in Appendix A.2.

Experimental Setup.For each combination of LLP method, dataset, model, and bag size, we train the model 10 times with different seeds and report the average test accuracy. To generate the label proportion data, on each run we shuffle the training data, partition it into consecutive bags of the desired size, and replace the original labels with label proportions computed from the bags. To tune the learning rate for each method, we report the highest accuracy achieved for learning rates in \(\{0.00001,0.0001,0.0005,0.001,0.005,0.01,0.05\}\). For DA, we tune the learning rate and \(\) using a grid search with the same learning rates and \(\{0.0,0.0001,0.001,0.01,0.1,0.5\}\). Note that DA is sensitive to the choice of \(\), and it is unclear how to tune \(\) without access to event-level data. In all cases we use the Adam  optimizer, binary crossentropy loss, minibatches of size 512, and 20 training passes through the data. Finally, for the two image datasets, we decay the learning rate after 40%, 60%, 80%, and 90% of the training passes by factors 10, 100, 1000, and 5000, respectively.

Results.Figure 2 depicts the accuracy achieved by each method on a selection of datasets and models for a range of bag sizes. The selected dataset and model combinations are representative of the full set of experimental results, which are included in Appendix A.5. Across all datasets, either EasyLLP or PropMatch achieves the highest test accuracy for large bag sizes. In agreement with our theory, the performance of EasyLLP decreases predictably with the bag size (due to the increased variance of gradient estimates). On the other hand, we find that DA often performs very well for small bag sizes, but accuracy drops rapidly at a dataset-dependent threshold. PropMatch is a competitive baseline, specifically when the underlying learning model is well specified for the task, which is in line with our finding in Section 3. For instance, when using the Resnet-11 model, PropMatch has a higher performance than EasyLLP on both MNIST and CIFAR-10. A partial explanation is due to Theorem 4.3. Indeed, it is well known that models trained under logistic regression become overconfident on their predictions. However, our theory suggests that the variance of the gradient increases proportional to \(\|g(x,0)-g(x,1)\|\) which rapidly becomes unbounded as the model becomes more confident. To test this hypothesis, we trained a model using a double-sided hinge loss, labeled "EasyLLP DHL" (details in Appendix A). This loss induces a small variance term in Theorem 4.3 and indeed we see that this partially closes the gap to PropMatch. On the other hand, PropMatch's performance degrades more rapidly than EasyLLP's as the bag size increases in the presence of model mis-specification or higher noise in the data (first three plots in Figure 2).

Loss tracking.Another strength of EasyLLP is that the loss estimates computed during training are unbiased estimates of the true training loss. In comparison, the losses minimized by all other methods we consider do not have clear connections to the true training loss and it is unclear how to monitor training performance. In Appendix A.6 we demonstrate this empirically.

## 8 Conclusions and Limitations

We have studied the problem of learning from label proportions in the case where bags are drawn i.i.d. We have introduced EasyLLP, a novel and flexible approach to LLP for classification that is widely applicable and has well-developed theory. In particular, we have shown how to use EasyLLP to estimate the expected value of _any_ function of \((x,y)\) pairs from labeled data, and applied these results to proving ERM sample complexity guarantees and convergence guarantees for SGD. In both cases, we have shown that the LLP performance of EasyLLP is only a factor \(k\) worse than when learning from event-level data. We have also elucidated important theoretical properties of the folklore PropMatch algorithm which are suggestive of the practical scenarios where it is advisable to make use of it. Finally, we have carried out an extensive empirical evaluation of EasyLLP, PropMatch, and two baseline methods on diverse tasks and learning models, and identified relative performance trends.

The results in this work are limited to the special case of LLP where the examples in each bag are drawn i.i.d. from an underlying distribution. While this is a common and important special case, in future work we would like to extend our results to handle cases where the bags need not be i.i.d. Similarly, we hope to study the theoretical properties of EasyLLP more fully in the multiclass case, and to have a complete characterization of when PropMatch is consistent. We also believe that it may be possible to further decrease the variance of EasyLLP estimates by replacing the label marginal \(p\) in (3) with bag-specific predictions. Finally, while the LLP framework provides an intuitive form of privacy protection, we would like to explore connections with differential privacy where, for example, each bag's label proportion is computed by a differentially private mechanism.