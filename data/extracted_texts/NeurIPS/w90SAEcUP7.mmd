# Generation of 3D Realistic Soil Particles

with Metaball Descriptor

 Yifeng Zhao

Zhejiang University & Westlake University

&Jinxin Liu

Westlake University

&Xiangbo Gao

Westlake University

Pei Zhang

Westlake University

&Stan Z. Li

Westlake University

&Sergio Torres

Westlake University

Corresponding author: s.Torres@westlake.edu.cn

###### Abstract

The accurate representation of soil particle morphology is crucial for understanding its granular characteristics and assembly responses. However, incorporating realistic and diverse particle morphologies into modeling presents challenges, often requiring time-consuming and expensive X-ray Computed Tomography (XRCT). This has resulted in a prevalent issues in modeling: morphological particle generation. On this topic, we introduce the Metaball Variational Autoencoder. This method leverages deep neural networks to generate new 3D particles in the form of Metaballs while preserving essential morphological features from the parental particles. Furthermore, the method allows for shape control through an arithmetic pattern, enabling the generation of particles with specific shapes. We validate the generation fidelity by comparing the morphologies and shape-feature distributions of the generated particles with the parental data. Additionally, we provide examples to demonstrate the controllability of the generated shapes. By integrating these methods into the Metaball-based simulation framework proposed by the authors previously, we enable the incorporation of real particle shapes into simulations. This could facilitate the simulation of a large number of soil particles with varying shapes and behaviors, providing valuable insights into the properties and behavior of actual soil particles.

## 1 Introduction

On elucidating the impact of particle shape on the granular soil, simulation schemes based on micro-mechanical models, especially the discrete element method (DEM) , have prevailed in the past few decades. In original DEM, the particle is simplified as circles or spheres, which is hard to reflect the impact of shape, e.g. the resistance to rolling. Under this context, the key issue is how to fully reconstruct the morphology of granular matters in DEM simulations.

With the inspiring development of X-ray Computed Tomography (XRCT) and computer vision techniques, opportunities are provided to bring more accurate and sophisticated shape features into DEM simulations. Various reconstruction methods, which are called shape descriptors in this paper, are developed to compress realistic particle morphologies into a uniform mathematical representation for simulations. A good example is the Fourier descriptor, which is developed to capture particle shapes based on the average normalized Fourier spectrum of main contours from the targeted particle . Through similar pattern, the Spherical-Harmonic (SH) descriptor can also be used to capture various shapes features . However, these methods are limited to tackling star-like particles, of which all line segments between particle-center and particle-surface points are locatedwithin the particle body . Many particles, such as lunar soils and concave sand, do not follow such constraints. Recently, the Metaball descriptor was introduced by  to reconstruct non-spherical particle shapes. With proper function form, the contact detection of it can be tackled at a low cost, which enables a more efficient simulation framework . Such framework is further coupled with Lattice Boltzmann Method for simulations of more complicated physical processes in fluid-particle systems .

However, although XRCT can be used to scan all involved particles in the application, particle scanning and image processing can be economy-costly and time-consuming. In practical engineering applications, it is typical that only a small fraction of particles can be analyzed due to limited resources, as reported in [11; 12; 13]. Direct simulation with them will suffer from repetitive particle morphologies. This makes it necessary to generate realistic particles with coessential morphological features. With the development of the aforementioned shape descriptors, many attempts have been inspired to tackle generation tasks. Among them, the SH-based technique is a popular choice [14; 15]. It first incorporates geometric features into specific SH coefficients. Then, different algorithms like random field , fractal dimension , Nataf transformation , and principal component analysis [18; 13] are applied on the distilled SH coefficient to add small variances following the morphological pattern of parental particles for generation. But the above schemes suffer from some problems, including 1) underfitting and overfitting problems on shape-feature distributions of the generated particles, e.g. the distributions of surface area and volume [18; 12]. 2) Hard to obtain particles with specific morphological features [19; 14], e.g. generating non star-like particles with angled features. 3) Involving complex mixture models, which treat particle generation as a high-dimensional, multi-parameter estimation problem [20; 21]. Such a method can achieve an advance in performance, but still has a reliance on computational and human resources, which can not be obtained easily by all individuals or institutions . 4) Requiring bridging or transformation into other descriptors before practical simulations, which often results in a trade-off between accuracy and efficiency [22; 23]. Thus, a framework with a more flexible shape descriptor, to tackle the above problems, is needed.

On the above dilemmas, this paper presents Metaball-based two-step solutions. We first utilize a Metaball-Imaging (MI) algorithm to capture complex particle morphologies from XRCT images with the Metaball descriptor. Then, we develop a Metaball-based Variational Autoencoder (MetaballVAE). It can learn from the XRCT image of targeted grains and generate random Metaball-based particles retaining major morphological features from a regularized latent space, where complex calculations are converted into one-step solutions. Note that MetaballVAE can learn not only the geometric features of the single particle but also feature distributions of the particle group. The regularized latent space also makes it possible to modify particle morphologies in an arithmetic pattern, allowing for obtaining particles with specific shapes. Examined with two groups of particles different in sample number and geometric characteristics, the proposed generation algorithm has proved to be robust and effective.

## 2 Our Method

The variational autoencoder (VAE)  is a neural-network based generative model. The framework of it is to first learn the distribution \(P\) of the targeted data \(\) and then generate through sampling with some unobserved variable \(\), which is called the latent variable. And the collection of them is named the latent space. In implementation, the learning of \(P()\) is carried out with an assumed distribution \( Q()Q()d\) (\(Q\) is the assumed distribution of two parts. Since these two parts are implemented in one neural network system, they share the same notation), which is in the form of neural network. This distribution corresponds to two important components of VAE: the encoder \(=E()\)(For \(Q()\)) and decoder \(}=D()\)(For \(Q()\)), where \(\) represents the input, \(}\) for the generated(reconstructed). For particle generation, \(\) and \(}\) refer to the shape representation, for example, the Metaball descriptor \(\) or XRCT images. The encoder and decoder consist of the major steps in VAE: encoding and decoding. In encoding, the input shape representation \(\) is compressed and mapped into the latent variable \(\), a multidimensional shape-representation tensor. Then \(\) is decoded to reconstruct the input particle \(}\). Through minimizing the difference between \(\) and \(}\), morphologies and shape-feature distribution of input particles can be learned effectively (The theory behind this is briefly stated in Appendix A). Then, the trained decoder \(}=D()\) can be applied to generate particles by inputting random \(\). Assisted by the powerful learning ability of neural network,VAE can inference new particles, which are not included in the training set but maintain coessential morphological features and distributions with the parental particles. This make it have the potential to provide a more practical solution to the particle generation task than previous studies.

It is worth noting that latent variables \(\) in VAE are regularized (chosen to be multivariable normal distribution) to encourage similar input samples compress at closer positions in the latent space. This property allows the model to learn a more flexible and general distribution, rather than simply adapting to the specific patterns present in the training data. As a result, generation by sampling from sperate, regularized \(\) can help to avoid overfitting and underfitting problems on the shape-feature distributions of generated particles [21; 12]. More importantly, it enables high-level controls on the generated particle morphologies .

Based on VAE, we propose a Metaball-based particle generation framework called Metaball Variational Autoencoder (MetaballVAE). It can resolve the correlation between XRCT images and morphologies of input particles with a regularised latent space, where complex computations are transformed into one-step solutions, reducing variance in generated models and improving control over the generation process. This model requires no prior knowledge (e.g. particle shape-feature distributions), but only XRCT images of the target particles to generate non-existent style-similar avatars, particles in the form of metaballs, which can be used directly in simulations. Note that style learning is not limited to morphology, but also to shape-feature distributions.

The MetaballVAE consists of three major parts as illustrated in Figure 1: serializer, style-learner and generator. The serializer interprets and transforms XRCT images of target granular-particles into Metaball descriptors. Then, the style-leaner analyses those distilled descriptors, capture major shape characteristics, conducts inference on feature distribution and devise style-similiar avatars. In the end, the generator outputs designed style-similar, Metaball-based avatars.

### The serializer

The serializer is designed to abstract the particle morphology, extract shape-feature distributions and code them structurally. It can significantly reduce the dimension of XRCT images while keeping all the vital morphological information for generation. The reasons for implementing it are two-fold. On the one hand, structured data are more suitable for generation tasks , which can improve the generation quality. On the other hand, this enables a direct generation of particles in Metaball function form, which can be put into simulations without bridging or transformation, avoiding unnecessary information loss and computational cost.

Figure 1: MetaballVAE for generation of complex-shaped particles. Serilizer: interpreting and transforming XRCT images of granular matters. Style-learner: analysing the serialized Metaball descriptor and learning the morphological characteristics and distribution. Generator: generating style-similar granular media in Metaball form

In this paper, the serialization is accomplished with the Metaball-Imaging technique as introduced in Appendix A. The serialized particle is in MI avatar form, which is noted as \(}\).

### The style-learner

The style-learner is a modification of the aforementioned VAE. It can digest the structured data \(S\) and learn how to generate particles. Main components involved are: encoder, decoder, reparameterizator, loss function and distribution annealer.

**Encoder** and **Decoder** are multi-layer perceptions, which are connected in a bottle-neck form as shown in Figure 1. They are implemented to approximate the real distribution \(P()\) as a learnable, assumed distribution \( Q()Q()dz\). On the topic of particle generation, \(\) refers to the \(}\). The encoder takes serialized particles \(}\) as input and outputs parameters(\(\) - the mean, \(\) - the standard deviation) of the corresponding latent variable \(\), mapping morphologies and shape-feature distributions of particles into a regularized latent space. On the contrary, the decoder interprets \(\) to restore \(}}\), reconstructing particle morphologies and shape-feature distributions from that regularized space.

**Reparameterizator** locates halfway between the encoder and decoder. It is designed to regularize the latent space by creating a map between the encoded information and a normal distribution. Instead of direct sampling (Fig, 2, a), a more deterministic pattern is utilized:

\[z=+\] (1)

where the \(\) is the assumed normal distribution. This enables continuous gradient calculation on the mapping relationship, making MetaballVAE a learnable system.

**The loss function** is the global optimization objective for MetaballVAE:

\[L(})=_{k=1}^{d}\|}-}}\|^{2}}_{}+ _{k=1}^{d}(_{(k)}^{2}(})+_{(k)}^{2}(})- _{(k)}^{2}(})-1)}_{}\] (2)

where \(d\) is the dimension of \(}\). This function is modified from the original VAE theory based on the particle generation problem. The deduction of it is stated in Appendix B. It consists of two items: the distribution item and reconstruction item. The distribution Item measures the difference between real and learned distributions of particle morphologies. The Reconstruction Item evaluates the quality of learned morphological characteristics. The combination of them forces MetaballVAE to learn not only morphologies but also shape-feature distributions of the input particles.

**The distribution annealer** is proposed to tackle the training challenge of VAE. A well-trained model possesses a relatively small reconstruction item and a non-zero distribution item. However, most direct training will yield a model with a zero distribution item. Such tendency in learning is caused by the sensitivity of decoder to variation introduced by the mapping process of reparameterizator. This makes the decoder ignore the latent variable provided by the encoder and output the average

Figure 2: Visualizations of the direct sampling and reparameterization trick. The solid line stands for a relationship capable of backpropagation. The dashed line represents a relationship where backpropagation can not be carried out.

optimal with distribution item equal to zero. For this reason, the distribution annealer is implemented by adding a weight to the distribution item of the loss function(Eq. 2). This weight starts from zero, where the weighted loss function equals the reconstruction loss. Then, the weight is increased gradually to one, where this weighted function satisfies the true loss function definition. With such a process, the model will be forced to use the learned latent space to achieve good likelihood in prediction.

Figure 3 is an example of the distribution annealer in the training of the cobblestone dataset during the first 20k steps. It can be observed that the distribution item first spikes as the reconstruction item drops significantly, where the model is encoding shape features into the latent space cheaply. Then, the distribution item starts to decrease rapidly as more attention is paid to the divergence penalty. Correspondingly, the decrease of reconstruction item slows down. Finally, the distribution item gradually converges and the reconstruction item enters fluctuation, where more morphological information is compressed into the model.

### The generator

Before formal generation, the decoder of style-learner should be well-trained. The generation task requires the trained decoder and a normal distribution \(N(0,1)\), which represents the regularized latent space. A typical generation process is illustrated in Figure 1. The latent variable \(\) is sampled from a normal distribution, serving as the input matrix to the decoder. Then, the decoder can devise style-similar particles unseen in the training dataset. The distribution of shape features can be well reconstructed when the number of generated particles is large enough. It is worth noting that the generated particle is in the form of Metaball descriptor, which can be applied directly into simulations.

## 3 Experiments

### The setting of serializer and style-learner

In this evaluation, we apply the following hyper-parameter setting. In serializer, the control point number, n, is set to be 40 for both cobblestone and Ottawa sand samples. The learning rate for the gradient update is set to be 0.001. In style-learner, the encoder is a 4 layer full-connected network with leaky ReLU activation function. The size of it is: 160\(\)1024\(\)512\(\)256\(\)128. The decoder is also a 4 layer full-connected network with leaky ReLU activation function yet in reverse form. The reparameterizator is set to be one fully connected layer with size 128. The above networks are trained by Adam  with learning rate \(\) = 0.0001.

Since the setting of hyper-parameters is not a focus of this paper, how to obtain them is not included here for the sake of brevity. A detailed procedure can be referenced in .

### Dataset and Metrics

Previous studies on particle generation are often carried out on hundreds of thousands of samples [12; 20; 25]. However, particle reconstruction with XRCT requires considerable time and computational

Figure 3: The impact of the distribution annealer on the loss value of different items in the training of cobblestone dataset

resources. In actual engineering, it is very often to have only a dozen scanned particles. Therefore, it's crucial to evaluate the performance of algorithms on smaller datasets. To this end, we tested the effectiveness of the MetaballVAE model on four distinct sets of XRCT data, which included particles of different types and sizes: 290, 100, and 10 samples of Ottawa sands, as well as 20 cobblestones. For better learning performance, data augmentation are implemented on training datasets, where slightly modified synthetic data is introduced based on the real one. Here, particle rotating and parameter shuffling are implemented. Particle rotating is a popular strategy based on rotational-invariant property. For example, Shi et al.  applied nine rotations to each particle and enlarged his dataset by ten times in a particle generation task, which effectively enhanced the model performance. Parameter shuffling means random recombination of \(\{k_{i},}\}\) in the serialized particle \(}\). This is because the sequence change of control spheres will not modify the corresponding Metaball model. Such processing can effectively avoid the overfitting problem and enhance convergence performance.

Accurate evaluation is a challenge for particle generation tasks. Apart from the rationality of particle shape, another important content of evaluation is the quantitative difference between parents and clones. We select seven shape factors for evaluation: surface area \(A\), volume \(V\), Corey Shape Factor \(CSF\), nominal diameter \(D_{n}\), surface-equivalent-sphere diameter \(D_{s}\), sphericity \(\) and circularity \(C\).

The Corey Shape Factor \(CSF\) reveals the dimension feature of the studied particle, as given by:

\[=}{L_{l}}}\] (3)

where \(L_{s}\), \(L_{i}\) and \(L_{l}\) are the shortest, intermediate and longest axis lengths of particles.

The nominal diameter \(D_{n}\) and surface-equivalent-sphere diameter \(D_{s}\) are two widely used parameters[28; 29]. The \(D_{n}\) is defined as the diameter of the volume-equivalent sphere. And the \(D_{s}\) takes the following form:

\[D_{s}=}{}}\] (4)

where \(A_{p}\) = the maximum projected area of the particle. Here, they are combined as \(D_{ns}=D_{n}/D_{s}\) to form a dimensionless quantity.

The sphericity \(\) is the measure of similarity between the studied particle and the sphere, which is defined as:

\[=}{A}\] (5)

where \(A_{ve}\) = the surface area of the volume-equivalent sphere to the studied particle; \(A\) = the surface area of the studied particle.

Another frequently used metric is the circularity \(C\), which evaluates the roundness of non-spherical particle:

\[C=}{P_{p}}\] (6)

where \(P_{p}\) is the the perimeter of the particle's projected-area.

### Particle Generation

In validation, the training datasets are denoted as "Parents". And 1000 particle avatar are devised by the generator, denoted as "Clones". The number of generated particles is set to larger for better evaluation on the morphological distribution.

Figure 11 and Figure 12 displays several cloned examples of each type. It can be concluded that these clones exhibit reasonable shape features of both Ottawa sands (angled features) and cobblestones (round features). Note that these particles are in Metaball function form and the meshes are only for visualization.

To further exam the regeneration ability of the proposed method on shape-feature distributions, probability density functions (PDF) of selected metrics are calculated on both parents and their clones. A satisfying match can be observed (See details in Appendix B.)

### Latent space arithematic

A well-trained MetaballVAE can achieve integration of discrete training samples into continuous, regularized latent space, where the number of generated particles can be infinite. Such regularized latent space avoids overfitting and underfitting problems in generation, ensuring the rationality of generated morphologies . More importantly, it also realizes a certain control on the generated geometric feature .

Figure 5 illustrates that the addition of Gaussian random noises \(\) into the latent variable \(\) can introduce morphological changes of different degrees into generated avatars. Here, \(\) is set to have the same dimension of \(\), with zero mean value and different variance \(\). Then, \(\)s are added to a randomly selected latent variable \(\) to produce modified ones \(+\). Finally, these latent variables are fed into the generator as inputs. From the corresponding generated results, it can be observed that the addition of \(\)s with small \(\) can slightly adjust the particle morphologies. As the increase in \(\), the degree of modification becomes larger, resulting in less similar avatars to the original one. This is from the property of regularized latent space. The addition of \(\)s can create new latent variable adjacent to the original one, while the \(\) of \(\)s decides distances between them in the latent space. Since the latent space is regularized, such adjacent relationships control the shape similarity in generated avatars. This phenomenon is also observed in generating digital sand particles with VAE . It can be very useful when particles in certain morphologies are needed in simulations. We can first select the template avatars and then add \(\)s of small magnitude into its latent variables. In this way, slightly modified avatars can be generated, avoiding repetitive particle morphologies in simulation.

Figure 5 indicates that interpolation between latent variables can produce smooth shape transitions in corresponding generated avatars. In these examples, two latent variable \(z_{1}\) and \(z_{2}\) are randomly selected to create interpolations \(z_{1}+(z_{2}-z_{1})\). Then, these latent variables are fed as input to the generator. It is clear that as the increase of \(\), those interpolated avatars gradually transform from \(z_{1}\) avatar to \(z_{2}\) avatar. Note that such a change occurs simultaneously in multiple characteristics including shape, volume and surface area. This is also result of the regularized latent space. Those interpolated variables possess adjacent locations in the latent space with \(z_{1}\) and \(z_{2}\), resulting in avatars of similar shape. With change in the location of latent variables, the generated avatars show smooth modification in shape from \(z_{1}\) to \(z_{2}\) avatars. This phenomenon can be applied to obtain avatars of combined features. We can first select two template avatars of specific morphologies then do interpolation between them.

Figure 6 shows that the avatar shape can be modified by applying addition or subtraction in the latent space. Here, arithmetic operations are implemented on latent variables, \(z_{1}\) and \(z_{2}\), corresponding to avatars of distinct shapes. Under such operation, specific shape features can be added or removed from the generated avatar of \(z_{3}\). This also results from regularized latent space. The proper mapping between latent variables and morphological features provides a powerful method to modify the shape. Through proper arithmetic operation, avatars of specific features can be generated according to need.

## 4 Conclusion

We present a variational-autoencoder (VAE) based particle generation algorithm called MetaballVAE. It can generate style-similar particles in Metaball function form with XRCT images of parental particles. The MetaballVAE was evaluated through a comparison of two groups of particles with different sizes. It was found that the parental and cloned particles exhibited good agreement in terms of their morphologies and shape-feature distributions. These results provide evidence that MetaballVAE is a reliable and practical tool for characterizing particles with varying sizes and morphologies. The regularized latent space of MetaballVAE allows for control over the generation process. Particles with specific morphologies can be generated through arithmetic operations on the latent space. This feature makes MetaballVAE a versatile and useful tool for generating particles with desired characteristics. With previously developed metaball-based simulation frameworks that have proven to be a powerful tool in comprehending the intricacies of fluid-particle systems involving realistic soil particles [10; 8]. With the addition of reconstruction and generation methods proposed in this paper, the integration of these tools has the potential to unveil new insights into soil mechanics and provide valuable information for a wide range of applications, including soil erosion modeling, soil contamination analysis, and soil moisture modeling.