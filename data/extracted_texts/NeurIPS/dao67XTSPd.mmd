# DeltaDock: A Unified Framework for Accurate, Efficient, and Physically Reliable Molecular Docking

Jiaxian Yan\({}^{1}\), Zaixi Zhang\({}^{1}\), Jintao Zhu\({}^{2}\), Kai Zhang\({}^{1}\), Jianfeng Pei\({}^{2}\), Qi Liu\({}^{1}\)

\({}^{1}\)State Key Laboratory of Cognitive Intelligence, University of Science and Technology of China

\({}^{2}\)Center for Quantitative Biology,

Academy for Advanced Interdisciplinary Studies, Peking University

{jiaxianyan, zaixi, sa517494}@mail.ustc.edu.cn, zhujt@stu.pku.edu.cn,

jfpei@pku.edu.cn, qiliuql@ustc.edu.cn

Qi Liu is the corresponding author.All codes and data will be released on [https://github.com/jiaxianyan/DeltaDock](https://github.com/jiaxianyan/DeltaDock).

###### Abstract

Molecular docking, a technique for predicting ligand binding poses, is crucial in structure-based drug design for understanding protein-ligand interactions. Recent advancements in docking methods, particularly those leveraging geometric deep learning (GDL), have demonstrated significant efficiency and accuracy advantages over traditional sampling methods. Despite these advancements, current methods are often tailored for specific docking settings, and limitations such as the neglect of protein side-chain structures, difficulties in handling large binding pockets, and challenges in predicting physically valid structures exist. To accommodate various docking settings and achieve accurate, efficient, and physically reliable docking, we propose a novel two-stage docking framework, DeltaDock, consisting of pocket prediction and site-specific docking. We innovatively reframe the pocket prediction task as a pocket-ligand alignment problem rather than direct prediction in the first stage. Then we follow a bi-level coarse-to-fine iterative refinement process to perform site-specific docking. Comprehensive experiments demonstrate the superior performance of DeltaDock. Notably, in the blind docking setting, DeltaDock achieves a 31% relative improvement over the docking success rate compared with the previous state-of-the-art GDL model DiffDock. With the consideration of physical validity, this improvement increases to about 300%.+

Footnote †: *Qi Liu is the corresponding author.

## 1 Introduction

Recent advancement in geometric deep learning (GDL)  presents an innovative and promising molecular docking paradigm to predict and understand the interactions between target proteins and drugs, which is of paramount importance for drug discovery . Unlike traditional docking methods that employ optimization algorithms to sample and identify best binding poses , GDL methods interpret molecular docking as either a regression or generation task, eliminating the need for intensive candidate sampling . Studies have demonstrated that GDL methods outperform their traditional counterparts, delivering enhancements in both the accuracy of binding pose predictions, as measured by the root-mean-square deviation (RMSD) metric, and the inference efficiency .

According to whether a prior pocket is given, molecular docking can be divided into blind and site-specific docking . Traditional sampling methods adeptly navigate both scenarios, primarily differing in the scope of the search space they explore. In contrast, GDL methods typically specialize in either one. For instance, EquiBind , and DiffDock  are designed for blind docking, neglecting the incorporation of binding pockets. Uni-Mol  and DiffBind-FR  concentrate on site-specific docking and only protein atomic level structure within a defined radius (usually 6-12 A) of theco-crystal is modeled. Despite some progress, these methods not only fail to handle two docking settings smoothly like traditional methods, but also confronted with certain limitations. For blind docking methods, they ignore the fine-grained protein side-chain structure. Regarding the site-specific docking methods, when dealing with pockets larger than the predetermined cutoff or when there is a requirement to model extensive pocket surrounding structures to account for long-range interactions, these methods significantly deteriorate in performance  and the demand for computational resources can escalate significantly, as evidenced in Appendix.A.2 and Appendix.A.3.

Besides these challenges, current GDL methods face additional limitations due to the lack of inductive biases, such as penalties for steric clashes or constraints on ligand mobility, leading to the generation of unrealistic docking poses. Buttenschoen et al.  proposed the PoseBusters test suit to verify and highlight these problems. In addition to the RMSD between predicted and ground-truth poses, the test suite incorporates 18 checks, encompassing chemical validity and consistency, intramolecular validity, and intermolecular validity. According to the test suite, the previously highest-performing method, DiffDock, achieves a success rate of only 14%. This is significantly lower than the 38% success rate achieved when chemical validity is not taken into account.

To resolve these problems, we propose **DeltaDock**, a unified GDL framework for accurate, efficient, and physically valid docking. DeltaDock is a two-stage framework consisting of a pocket prediction stage and a site-specific docking stage. With **"Delta"**, we mean that the optimal poses are predicted by iteratively refining the input structures in the second docking stage. The first pocket prediction stage is specialized for blind docking, where a binding pocket is identified from a set of candidates through a novel contrastive pocket-ligand alignment module CPLA. Then in the second stage, within the pockets predefined or selected by CPLA, binding structures are predicted in a bi-level coarse-to-fine iterative refinement module Bi-EGMN. This module prioritizes the residue-level structure covered by a large outer box (Fig.4) for pose positioning and coarse structure prediction. And the atom-level structure, within a relatively small radius from the coarse structure, is characterized for more refined predictions. In particular, the module incorporates (i) a GPU-accelerated pose sampling algorithm generating high-quality initial structure, (ii) a training objective imposing penalties for steric clashes and constraints on ligand mobility, and (iii) a rapid post-processing step composing torsional alignment and energy minimization for structure correction.

To accommodate two different docking settings, DeltaDock is specially designed as a two-stage framework rather than an end-to-end framework. Particularly, the pocket-ligand alignment module is inspired by the observation shown in Fig.5. Existing pocket prediction methods generally achieve a recall rate of just 70%-80%. However, when combining all possible pockets predicted by multiple methods, this recall rate reaches nearly 95%. According to this result, we shift the focus from designing increasingly powerful pocket prediction models to developing strategies for the effective selection of a candidate pocket from an ensemble of predicted pockets. The pocket prediction task is thus reframed as a pocket-ligand alignment problem innovatively. Regarding the site-specific docking stage, the key idea is to accurately predict reliable poses. Based on the proposed bi-level iterative refinement model, several components presented above are introduced additionally. Among them, the pose sampling algorithm is adopted for structure initialization, as previous works on structure prediction  have demonstrated the importance of a good initial structure. Other two components, namely the physics-informed training object and the fast structure correction step, are leveraged to ensure physical validity.

To demonstrate the effectiveness of DeltaDock, we performed comprehensive experiments to evaluate its predictive accuracy, efficiency, generalizability, and ability to predict physically valid binding poses. The experimental outcomes indicate that DeltaDock consistently surpasses the baseline methods in both blind docking and site-specific docking settings while maintaining remarkable computational efficiency. Notably, in the blind docking setting, DeltaDock exceeded the performance of the previous SOTA GDL method, DiffDock, by 30.8% in terms of the docking success rate, and it required only approximately 3.0 seconds per protein-ligand pair. With the consideration of physical validity, this improvement increases to approximately 300% on the PoseBusters benchmark.

## 2 Related Work

### Sampling-based Docking

Traditional docking methods, epitomized by the likes of VINA  and SMINA , operate on a "sampling-and-scoring" paradigm to identify the best binding pose. Optimization algorithms such as BFGS  are used to sample optimal poses within the defined search space on CPUs. This process, which involves a significant number of steps and multiple copies, is rather computationally intensive. Recent studies have attempted to speed up the sampling process using GPUs. Notable examples are Vina-GPU , Uni-Dock , and DSDP , which use more copies and shorter search steps to fully leverage the parallel computational power of GPUs. This approach has demonstrated substantial efficacy, achieving a speed increase of an order of magnitude compared to prior CPU-based methods.

### Geometric Deep Learning-based Docking

GDL introduces a new paradigm in molecular docking, where the sampling process is bypassed by interpreting molecular docking as either a regression task or a generation task [8; 9]. However, recent researches have highlighted limitations of current GDL methods, such as neglect of protein side-chain structures , difficulties in handling large binding pockets, and challenges in predicting physically valid structures . Compared with physically reliable sampling-based methods, especially recent developed GPU-accelerated methods, the existing limitations hinder the practical application of GDL methods. To address these concerns, in this work, we propose DeltaDock to overcome these problems and accomplish efficient, accurate, and physical reliable docking.

### Binding Pocket Prediction

As the foundation of structure-based drug design, binding pocket prediction has attracted expansive attention. A variety of methods have been developed for this task, encompassing traditional computational methods, such as Fpocket , machine learning (ML) methods, such as P2Rank , and GDL methods, such as PUResNet . These methods generally adopt ligand-free approaches and focus on predicting all potential binding sites within individual proteins. Recent blind docking methods, DSDP and FABind, apply pocket prediction for target ligands to reduce the docking search space, which is of great help to fast and accurate blind docking. In this study, our proposed model, DeltaDock, also prioritizes defining a pocket for blind docking. However, instead of improving model architecture for pocket prediction like previous methods, DeltaDock reframe the pocket prediction task as a pocket-ligand alignment problem and employ contrastive learning to select a candidate pocket from the combined pockets set.

Figure 1: The overview of DeltaDock’s two modules. (a) The pocket-ligand alignment module CPLA. Contrastive learning is adopted to maximize the correspondence between target pocket and ligand embeddings for training. During inference, the pocket with the highest similarity of the ligand is selected. (b) The bi-level iterative refinement module Bi-EGMN. Initialized with a high-quality sampled pose, the module first performs a coarse-to-fine iterative refinement. This process generates progressively refined ligand poses utilizing a recycling strategy. To guarantee the physical plausibility of the predicted poses, a two-step fast structure correction is subsequently applied. This correction involves torsion angle alignment followed by energy minimization based on the SMINA.

## 3 DeltaDock Framework

### Preliminaries

**Notations.** In this work, the separate structures of a protein \(\) and a ligand \(\) are used as inputs (Fig. 1). Both molecules are initially encoded as graphs, and we denote a molecule graph as \(=(,)\), where \(\) and \(\) represent the node set and edge set respectively. Each node \(v_{i}\) is associated with a coordinate \(x_{i}\) and a feature vector \(h_{i}\). Each edge \((i,j)\) is associated with an edge feature vector \(e_{ij}\). For the ligand \(\) and ligand graph \(^{}\), \(v_{i}^{}\) represents the \(i\)-th atom in the ligand and \(x_{i}^{}\) corresponds to the atom's coordinate. For the protein \(\), the situation is more complex, and two graphs based on the two structural levels of the protein are constructed. One is the protein atomic graph \(^{}\), and the other is the protein residue graph \(^{*}\). \(^{}\) contains protein atomic-level information similar to ligand graph \(^{}\), while \(^{*}\) contains protein residue-level information and overlooks the side-chain structure information. In \(^{*}\), \(v_{i}^{*}\) represents the \(i\)-th residue in the protein and \(x_{i}^{*}\) corresponds to the \(C_{}\) coordinate of this residue. Details of the graph construction can be found in Appendix.A.6.

**Overview.** Our goal is to train a model \(f\) that excels in both site-specific docking and blind docking scenarios of rigid molecular docking, wherein the protein structure is fixed and only the ligand's flexibility is considered.

_As depicted in Fig. 1, DeltaDock comprises two modules: a pocket-ligand alignment module **CPLA** responsible for selecting binding pocket from a pocket candidate set, and a bi-level iterative refinement module **Bi-EGMN** dedicated to executing site-specific docking given the binding pockets. This design allows DeltaDock to handle both blind docking and site-specific docking seamlessly. In the subsequent part of this section, we will elaborate on these two modules respectively._

### Contrastive Pocket-ligand Alignment

CPLA treats the pocket prediction task as a pocket-ligand alignment problem. We employ a list of well-established ligand-free pocket prediction methods to generate candidate pocket sets, and then map these pockets and the target ligand into the same embedding space. The correct pocket embedding is expected to have higher similarity with ligand embedding than other pockets.

#### 3.2.1 Data Preprocessing

The initial step of this module involves using RDKit  to generate a 3D conformer of the input ligand, as depicted in Fig. 1. Binding site prediction models including P2Rank and DSDP are adopted to extract druggable binding sites, and the binding sites predicted by these different methods are combined to form a set of candidate binding sites, denoted as \(S=\{_{1},_{2},...\}\), where \(_{i}\) represents the geometric center of \(i\)-th binding site. For CPLA, the protein pocket \(_{i}\) is defined as the residues within 15.0 A to \(_{i}\).

#### 3.2.2 Ligand and Pocket Encoders

To map the ligand and pockets into the embedding space, the ligand encoder Attentive-FP (AFP)  and protein encoder Geometric Vector Perceptron (GVP)  are employed. These encoders first extract informative ligand node and protein node representations, and the feature extraction process can be formally expressed as:

\[H^{}=AFP(^{}),\ H^{*}=GVP( ^{*}), \]

where \(H^{}\) is the ligand embedding matrix of shape \(|^{}| d\) and \(H^{*}\) is the protein residue embedding matrix of shape \(|^{*}| d\). The ligand representations \(m^{}\) and pocket representations \(m^{}_{i}\) are then obtained by pooling ligand nodes embedding and pocket nodes embedding:

\[m^{}=Sum(H^{},^{}),\ m^{}_{i} =Sum(H^{*},^{}_{i}), \]

where \(^{}_{i}\) is the protein node set of \(i\)-th pocket \(\), and the pooling operation is sum pooling. For the pocket encoder, we input the entire protein residue graph \(^{*}\) rather than just the protein pocket residue graph, to incorporate global protein information into the pocket representation.

#### 3.2.3 Contrastive Embedding Alignment

With ligand representation \(m^{}\) and pocket representation \(m_{i}^{}\) in hand, we calculate the cosine similarity score:

\[s_{i}=} m_{i}^{}}{\|m^{}\|_{2 }\|m_{i}^{}\|_{2}}. \]

For the candidate pockets \(S=\{_{1},_{2},...\}\), the similarity score \(s_{+}\) between the target pocket and the ligand is expected to be higher than others. Thus, we propose the contrastive learning objective:

\[L=- log/)}{_{i}exp(s_{i}/)}, \]

where \(\) is the temperature paramter. For blind docking, the pocket with the highest similarity score with the ligand is selected for the next docking step.

### Bi-level Iterative Refinement

With a binding site \(\) predefined by the user or selected by CPLA, we design the bi-level iterative refinement module Bi-EGMN to predict binding pose within this pocket (Fig. 1).

#### 3.3.1 Initial Structure Sampling

For an iterative refinement module, an initial structure is needed as a starting point. Previous work on molecular 3D conformer generation  demonstrates the importance of a good initial structure. Therefore, Bi-EGMN adopts a rapid GPU-accelerated sampling method proposed by Huang et al.  to sample a high-quality initial \(^{}\). In this work, the search steps number and the search copy number are set to 40 and 384, respectively. Details about the search box setting can be found in the Appendix.B.3.1.

#### 3.3.2 Structure Refinement

With input initial structure \(^{}\), we iteratively update it to improve its accuracy. As discussed in Sec.1, the modeling of an entire binding pocket structure is crucial for the success of the process. Current methods either ignore the atom-level structure or model the full-atom pocket structure directly. The latter approach can significantly elevate the computational resource demand, particularly when dealing with large pockets. To overcome these challenges and maintain high docking accuracy and efficiency, we propose a bi-level strategy in this work. In the following sections, we first present the details of the bi-level strategy. Subsequently, we discuss the Bi-EGMN layer, which is used to perform refinement, as depicted in Fig. 1.

**Bi-level strategy.** The first refinement level is the residue level, where the protein residues within a 40.0 A cubic region centered at the geometric centers of ligands are considered as pocket \(\). Previous work demonstrates such a range is large enough to cover the binding pocket . In this context, as the full-atom structure of proteins is not considered, the pocket residue graph \(^{*}\) is adapted. The second level is the atomic level, where we set the ligand structures refined through \(T\) rounds of residue level refinement as the reference structure. In this level, protein atoms within a \(6.0\) A radius of the ligand atoms are considered to construct pocket atomic graph \(^{}\) for modeling the fine-grained interaction. The ligand coordinates \(X^{a,}\) output by the last layer of atomic level refinement correspond to the final predicted structure \(}^{}\).

**Bi-EGMN Layer**. The bi-level E(3)-equivariant graph matching network (Bi-EGMN) layer is the model designed to calculate the protein-ligand interaction and refine the structures. More specifically, this layer adheres to the message-passing paradigm  and consists of four functions: intra-message function, inter-message function, aggregate function, and update function.

The intra-message function works to extract messages \(m_{i,j}\) and \(_{i,j}\) between a node \(i\) and its neighbor nodes \(j\) from the same molecule graph. \(m_{i,j}\) is later used for the updating of node features and \(_{i,j}\) for the updating node coordinates. \((i,j)_{}_{}\), this function can be formally written as :

\[d_{i,j}^{(l)}=||x_{i}^{(l)}-x_{j}^{(l)}||,\ m_{i,j}=_{m}(h_{i}^{(l)},h_{ j}^{(l)},d_{i,j}^{(l)},),\ _{i,j}=(x_{i}^{(l)}-x_{j}^{(l)})_{ }(m_{i,j}), \]where \(d_{i,j}^{(l)}\) is the relative distance between node \(i\) and node \(j\), and \(\) is a MLP.

The inter-message function works to extract messages \(_{i,j}\) and \(_{i,j}\) between a node \(i\) and its neighbor nodes \(j\) from the other molecule graphs. Formally, \( i_{},j_{}\,or\,i _{},j_{}\):

\[_{i,j}=_{}(h_{i}^{(l)},h_{j}^{(l)},d_{i,j}^{(l)}),\;_{i, j}=(x_{i}^{(l)}-x_{j}^{(l)})_{}(_{i,j}). \]

After extracting inter-message and intra-message, the aggregation function aggregates the neighbor messages of the node \(i\). \( i_{}_{}\):

\[m_{i}=_{j(i)}m_{i,j},\;_{i}=_{j (i)}^{(l)}+1}_{i,j}, \] \[_{i}=_{j_{*}^{(l)}(i)}(_{i,j}) _{i,j},\;_{i}=_{j_{*}^{(l)}(i)}^{(l)}+1}_{i,j}, \]

where \((i)\) is the neighbor of node \(i\) in the same graph, and \(_{*}^{(l)}(i)\) is the set of nodes associated with node \(i\) in the other graph.

Finally, the update function updates the position and features of each node:

\[x_{i}^{(l+1)} = x_{i}^{(0)}+(1-)x_{i}^{(l)}+_{i}+_{i}, \; i_{}, \] \[h_{i}^{(l+1)} =(1-) h_{i}^{(l)}+(h_{i}^{(l)},m_{i}, _{i},h_{i}^{(0)}),\; i_{}_{ }, \]

where \(\) and \(\) are feature skip connection weight and coordinates skip connection weight, respectively. Through such a message-passing paradigm, our Bi-EGMN layers make to update coordinates iteratively.

#### 3.3.3 Fast Structure Correction

Lastly, as Bi-EGMN updates structures by modifying the coordinates rather than the torsional angles, as is done in methods like DiffDock  and other sampling-based methods, it is crucial to ensure the plausibility of bond lengths and bond angles of the updated structure \(}^{}\). Therefore, fast structure correction steps, torsion alignment, and SMINA-based energy minimization are designed.

**Torsion Alignment.** We employ a rapid torsion alignment for the updated structure. The target of this alignment is to align the input structure \(^{}\) with the updated structures \(}^{}\) by rotating its torsional bonds. Formally, let \((b_{i},c_{i})\) denote a \(i\)-th rotatable bond, where \(b_{i}\) and \(c_{i}\) are the starting and ending atoms of the bond, respectively. We randomly select a neighboring atom \(a_{i}\) of \(b_{i}\) and a neighbor atom \(d_{i}\) of \(c_{i}\) to calculate the dihedral angle \(_{i}=(a_{i}b_{i}c_{i},b_{i}c_{i}d_{i})\) based on updated structure coordinates \(}^{}\). Subsequently, we rotate the rotatable bond \((b_{i},c_{i})\) of input structures to match its dihedral angle \(_{i}\) the same as \(_{i}\). This simple operation can be implemented efficiently using RDKit. After all rotatable bonds have been rotated, we align the rotated input structure to the updated structures to obtain the torsionally aligned structure \(}^{}\). This process ensures the plausibility of bond lengths and bond angles in the torsionally aligned structure \(}^{}\).

**Energy Minimization.** To further enhance the reliability of DeltaDock, we implement an energy minimization on the torsionally aligned structure \(}^{}\), when an inter-molecular steric clash between the protein and ligand is detected. This energy minimization is conducted using SMINA , as it is a highly efficient tool for this process compared with specialized energy minimization tool OpenMM  (details see Appendix.A.5). The output structure of this process is \(}^{^{}}\).

### Training and Inference

#### 3.4.1 Cpla

The training object \(L\) is a contrastive object defined before (Eq. 4). For a protein and its candidate pockets set \(S=\{_{1},_{2},...\}\), the positive pair is the target pocket-ligand pair and the negative pairs are other pocket-ligand pairs. The pocket-ligand pairs across different proteins are not used. When training, we calculate the minimum center distance (\(DCC_{min}\)) between all candidate pockets and the ligand. If \(DCC_{min} 5.0\) A, we add the ligand center into \(S\) to assert the existence of positive pairs for every protein (details see Appendix.B.3.1).

#### 3.4.2 Bi-EGMN

We design a physics-informed loss function for the Bi-EGMN module for training. The coordinates \(X^{a,}\) and \(X^{r,}\) output by the last layer of atomic level and residue level are both employed in the computation of this loss. Formally, the loss function can be expressed as follows:

\[L=L_{inter}+_{1}L_{intra}+_{2}L_{vdw}+_{3}L_{bound}, \]

where \(\) are weight hyper-parameters. Among the four components, inter-distance map loss \(L_{inter}\) is responsible for the RMSD accuracy. Other three items, namely intra-distance map loss \(L_{intra}\), vdw constraint loss \(L_{vdw}\), and bound matrix constraint loss \(L_{bound}\) are employed for physical validity. When training and inferencing, we follow previous work  and employ the recycling strategy (details see Appendix.B.3.2).

## 4 Experiments

### Settings

**Dataset.** We conduct experimetns on PDBbind  v2020 and PoseBusters  datasets in this work. Our model is trained on the PDBbind dataset, where the training, validation, and testing set are constructed based on the time split strategy used in previous work . PoseBusters, which contains 428 carefully selected data released from 1 January 2021 to 30 May 2023, is directly adopted to evaluate the ability to predict physically valid poses.

**Evaluation.** Root-mean-square-deviation (RMSD) and centroid distance (CD) are used to evaluate the docking accuracy of different docking methods, and the PoseBusters  test suite is employed to evaluate the performance of predicting physically valid poses. Additionally, as pocket prediction plays an important role in our framework, the distance between the center of the predicted pocket and the center of the ground-truth ligand structure (DCC), and the volume coverage rate (VCR) are employed to evaluate the pocket prediction accuracy (details in Appendix.B).

### Overall Performance on the PDBbind

We first assess the comprehensive performance of DeltaDock on the PDBbind dataset, encompassing both blind docking and site-specific docking settings.

    &  &  &  \\  & & RMSD \% below &  & RMSD \% below &  \\  & & Seconds & 2.0Å & 5.0Å & 2.0Å & 5.0Å & 2.0Å & 5.0Å & 2.0Å & 5.0Å \\  QVINA-W & 49* & 20.9 & 40.2 & 41.0 & 54.6 & 15.3 & 31.9 & 35.4 & 47.9 \\ GNINA & 393 & 21.2 & 37.1 & 36.0 & 52.0 & 13.9 & 27.8 & 25.7 & 39.5 \\ VINA & 119* & 10.3 & 36.2 & 32.3 & 55.2 & 7.8 & 25.5 & 24.1 & 41.8 \\ SMINA & 146* & 13.5 & 33.9 & 38.0 & 55.9 & 9.0 & 25.7 & 29.9 & 41.7 \\ GLIDE & 1405* & 21.8 & 33.6 & 36.1 & 48.7 & 19.6 & 28.7 & 29.4 & 40.6 \\ DSDP & 1.22 & 40.2 & 59.0 & 59.5 & 78.2 & 37.3 & 54.9 & 55.6 & 71.8 \\  EquiBind & **0.03** & 5.5 & 39.1 & 40.0 & 67.5 & 0.7 & 18.8 & 16.7 & 43.8 \\ TANKBind & 0.87 & 17.6 & 57.8 & 55.0 & 77.8 & 3.5 & 43.7 & 40.9 & 70.8 \\ DiffDock & 80 & 36.0 & 61.7 & 62.9 & 80.2 & 17.2 & 42.3 & 43.3 & 62.6 \\ FABind & 0.12 & 33.1 & 64.2 & 60.8 & 80.2 & 19.4 & 60.4 & 57.6 & 75.7 \\ FABind+ & 6.4 & 43.8 & **73.3** & 59.1 & **86.2** & 34.7 & **63.2** & 57.6 & 75.7 \\ 
**DeltaDock-SC** & 2.58 & **47.9** & 68.0 & **70.0** & 83.2 & **40.8** & 60.6 & **65.5** & **78.9** \\
**DeltaDock** & 2.97 & 47.4 & 66.9 & 66.7 & 83.2 & **40.8** & 61.3 & 60.6 & **78.9** \\   

* The time of consumption is denoted with
* if it only consumes CPU.
* All results of baselines are taken from  for fair comparison.

Table 1: Blind docking performance on the PDBbind dataset. All methods take RDKit-generated ligand structures and holo protein structures as input, trying to predict bound complex structures. DeltaDock-SC refers to the model variant that generates structures without implementing fast structure correction. DeltaDock-Random refers to the model variant that generates structures without high-quality initial poses. The best results are **bold**, and the second best results are underlined.

#### 4.2.1 Blind Docking

As demonstrated in Table.1, DeltaDock outperforms all baseline methods. Specifically, DeltaDock achieves a remarkable success rate of 47.4% (where RMSD < 2.0 A), surpassing the previous SOTA GDL method, DiffDock, which has a success rate of 36.0%. Recent GPU-accelerated docking methods have also made significant progress in blind docking. However, when compared to DSDP, which is the top-performing sampling-based method in the PDBbind test set, DeltaDock still exhibits superior performance across all metrics. Notably, as elucidated in Section 3.3, DeltaDock employs the same sampling algorithm as DSDP for generating the initial structure. Yet, our framework allows DeltaDock to significantly outperform DSDP.

Beyond accuracy, efficiency is a critical performance measure for molecular docking methods. As indicated in Table 1, DeltaDock maintains a competitive level of efficiency, despite the inclusion of an energy minimization operation to enhance accuracy and reliability. Molecular docking methods invariably face a trade-off between efficiency and accuracy. However, the data presented in Table 1 suggest that DeltaDock could serve as a viable tool for practical applications, balancing these two crucial aspects effectively.

#### 4.2.2 Site-specific Docking

Most existing GDL methods, such as DiffDock and EquiBind, are primarily designed for blind docking scenarios and are not inherently suited for site-specific docking tasks. However, DeltaDock seamlessly integrates blind docking and site-specific docking settings. In this context, the pocket is directly provided, eliminating the need for pocket selection via CPLA. The performance of DeltaDock in site-specific docking is illustrated in Fig.2. When supplied with predefined binding sites, traditional sampling methods exhibit a significant improvement in results. For instance, the docking success rate of VINA escalates from 10.3% to 45.0%. Despite this enhancement, DeltaDock consistently surpasses all baselines. Previous research suggested that while GDL docking methods excel at pocket searching, traditional methods tend to outperform GDL models in site-specific docking tasks . However, as evidenced by the results presented in Table.1 and Fig.2, DeltaDock exhibits superior performance in both blind and site-specific docking scenarios, demonstrating its versatility and robustness in handling diverse docking settings.

### Evaluation of Pose Validity

We further investigate DeltaDock's ability to predict physically valid structures by employing the PoseBusters test suite, as designed by Buttenschoen et al. . In addition to the RMSD between predicted and ground-truth poses, the test suite incorporates 18 checks, encompassing chemical validity and consistency, intramolecular validity, and intermolecular validity. When physical validity

Figure 2: Site-specific docking performance. (a) Overall Performance of different methods on the PDBbind test set. The search space was delineated by extending the minimum and maximum of the x, y, and z coordinates of the ligand by 4 Å respectively. For TANKBind, we directly supply the protein block with a radius of 20 Å centered around the ground-truth ligand center to the model. (b) Overall performance of different methods on the PoseBusters dataset. (c) A waterfall plot for illustrating the PoseBusters tests as filters for both DeltaDock and DeltaDock-SC predictions. The evaluation results for DeltaDock are denoted above the lines, while those for DeltaDock-SC are annotated below.

is considered, the docking success rates of traditional sampling methods remain stable, while the performance of previous geometric deep learning methods significantly declines, especially for TANKBind, DeepDock, and Uni-Mol. The DeltaDock-SC variant, even without the application of the fast structure correction step, shows significant improvement over previous methods. These results substantiate DeltaDock's capacity to predict physically valid structures, thereby affirming its reliability for practical applications.

### Further Analysis

#### 4.4.1 Pocket-ligand Alignment and Iterative Refinement

Beyond the overall docking performance, the pocket-ligand alignment and iterative refinement results are explored (Fig. 3). As depicted in the figure, CPLA predicts significantly more accurate pockets than other methods and Bi-EGMN can diminish the discrepancy between ground-truth structures and input structures. Generally, the PDBbind test set poses a more significant challenge to Bi-EGMN than the PoseBusters dataset. And for CPLA, PoseBusters dataset is more challenging otherwise. The consistent good performance on the two datasets demonstrates the effectiveness and generalization capacity of CPLA and Bi-EGMN.

#### 4.4.2 Ablation Studies

In this section, ablation studies are conducted to assess the contributions of different components. We first ablate the whole CPLA or Bi-EGMN, and then the residue-level or the atom-level in Bi-EGMN (see Appendix. B.4 for implement details). As illustrated in Table 2, it becomes clear that each component, encompassing CPLA and the bi-level strategy in Bi-EGMN, plays a significant role in enhancing the overall performance of DeltaDock. Due to the space limitation, a full ablation study can be found in Appendix. C.3.

## 5 Conclusion

In this work, we proposed DeltaDock, a unified framework for accurate, efficient, and physically reliable molecular docking. DeltaDock was a two-stage docking framework, consisting of pocket prediction and site-specific docking. We innovatively reframed the pocket prediction task as a pocket-ligand alignment problem and then followed a hybrid strategy to jointly utilize both GDL and physics-informed traditional algorithms for site-specific docking. Comprehensive experiments demonstrated the superior performance of DeltaDock. Notably, in the blind docking setting, DeltaDock achieved a 31% relative improvement over the docking success rate compared with the previous state-of

    &  \\  & PDBbind & PoseBusters \\ 
**DeltaDock** & **47.4** & **49.3** \\  w/o CPLA & 41.2 & 43.7 \\ w/o Bi-EGMN & 44.6 & 41.8 \\  w/o Residue Level & 44.6 & 44.4 \\ w/o Atom Level & 44.6 & 42.1 \\   

Table 2: Results of ablation study.

Figure 3: Further analysis on the (a) PDBbind and (b) PoseBusters dataset. Left: DCC cumulative curve of top-1 pockets. Middle: VCR cumulative curve of top-1 pockets. Right: Scatter plot of RMSD of initial and updated poses. All experiments are conducted in the blind docking setting.

the-art GDL model. We hope this work will further facilitate the broad application and continued development of the molecular docking framework.

## 6 Acknowledgements

We extend our gratitude to the reviewers for their valuable and insightful feedback, which significantly improved this work. We are also grateful to Livue Cheng from Microsoft Research for her helpful suggestions and comments. This research was supported by grants from the National Natural Science Foundation of China (No.62406303, No.623B2095), the National Key R&D Program of China (No.2023YFF1205103), the Anhui Provincial Natural Science Foundation (No.2308085QF229), and the Fundamental Research Funds for the Central Universities.