# Linear Uncertainty Quantification of Graphical Model Inference

Chenghua Guo

Han Yu

Jiaxin Liu

Department of Computer Science and Engineering, Lehigh University, USA

Chao Chen

School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen), China

Qi Li

Department of Computer Science, Iowa State University, USA

Sihong Xie

Xi Zhang

Corresponding authors.

###### Abstract

Uncertainty Quantification (UQ) is vital for decision makers as it offers insights into the potential reliability of data and model, enabling more informed and risk-aware decision-making. Graphical models, capable of representing data with complex dependencies, are widely used across domains. Existing sampling-based UQ methods are unbiased but cannot guarantee convergence and are time-consuming on large-scale graphs. There are fast UQ methods for graphical models with closed-form solutions and convergence guarantee but with uncertainty underestimation. We propose _LinUProp_, a UQ method that utilizes a novel linear propagation of uncertainty to model uncertainty among related nodes additively instead of multiplicatively, to offer linear scalability, guaranteed convergence, and closed-form solutions without underestimating uncertainty. Theoretically, we decompose the expected prediction error of the graphical model and prove that the uncertainty computed by _LinUProp_ is the _generalized variance component_ of the decomposition. Experimentally, we demonstrate that _LinUProp_ is consistent with the sampling-based method but with linear scalability and fast convergence. Moreover, _LinUProp_ outperforms competitors in uncertainty-based active learning on four real-world graph datasets, achieving higher accuracy with a lower labeling budget.

## 1 Introduction

Graphical models are known for their capability to represent data with complex dependencies. These models have been extensively applied to various fields, ranging from social networks , fraud detection , recommendation  and crowdsourcing , to more recent applications in enhancing graph neural networks (GNNs)  and large language models (LLMs) . Among the many inference techniques in graphical models , Belief Propagation (BP)  stands out as a powerful iterative message-passing algorithm. BP takes an initial guess (or "prior belief") of each node and refines it using information propagation, resulting in an updated, more accurate estimate called "posterior belief". However, a crucial limitation of BP is that it only providespoint estimates for these posterior beliefs  and does not capture their potential uncertainty, leading to decisions unaware of the underlying data and model unreliability. For example, in a social network, a higher inferred probability of Alice's interest in sports over Bob's may lead to erroneous decisions if, in fact, Alice's inferred probability has high uncertainty and only a slightly higher interest.

To handle the uncertainty present in the beliefs, some well-known sampling-based uncertainty quantification (UQ) tools, such as Monte Carlo (MC) simulations, can provide unbiased UQ. However, these techniques are time-consuming for large-scale graphs and cannot ensure convergence within a reasonable time frame in practice . Existing works [7; 35], based on Bayesian theory, have derived UQ methods with provable convergence and scalability by modeling beliefs as Dirichlet distributions and treating neighboring nodes as observations. However, this means that any neighbor of a node will necessarily reduce the uncertainty, even neighbors with noise or missing information. As illustrated in Figure 1, consider a user A with no preference information about being a music enthusiast, and A has two friends who are music enthusiasts (represented by a strong preference with Beta distribution parameters like \((3,1)\), where the parameters represent positive and negative preference counts). If A gains an additional friend D who has no preference information (represented by a uniform distribution \((1,1)\)), the existing methods still reduce A's uncertainty, incorrectly suggesting increased confidence that A is a music enthusiast. This results in an underestimation of posterior uncertainty. Furthermore, none of existing works provided a theoretical relationship between the computed uncertainty and the expected model prediction error, making it difficult for decision-makers to understand and trust the UQ results.

To address the challenges mentioned above, we introduce Linear Uncertainty Propagation (_LinUProp_), a method to quantify the uncertainty in posterior beliefs resulting from multiple iterations of propagation of uncertainty in node priors, which offers the following advantages:

* Methodologically, we propose _LinUProp_ (Sec. 3), a novel linear method that spreads the uncertainty from each node to the entire graph and additively aggregates this uncertainty to avoid underestimating posterior uncertainty. _LinUProp_ offers interpretability due to the additive of neighbor uncertainty (Fig. 1), enabling tracking the contributions of other nodes to the computed uncertainty and allowing users to understand its sources.
* Theoretically, _LinUProp_ possesses a closed-form solution, provable convergence related to the spectral radius of a matrix representing the dependencies between nodes (Sec. 4.1), and proven linear scalability (Appendix A.3). Moreover, by employing the bias-variance decomposition, we demonstrate that the posterior uncertainty is a **generalized variance component** of the expected model prediction error (Sec. 4.2).
* Experimentally, we demonstrate the following with _LinUProp_: (1) The uncertainty quantified by _LinUProp_ is accurate due to its strong positive correlation with MC simulations (Fig. 7 in Appendix B.1); (2) _LinUProp_ exhibits both fast convergence and linear scalability (Fig. 4); (3) _LinUProp_ is interpretable (Fig. 3); (4) When applied to graph active learning guided by uncertainty, _LinUProp_ achieves superior accuracy with a smaller budget compared to the baseline method that underestimates uncertainty (Figs. 5-6)

Figure 1: The impact of more neighbors on posterior uncertainty. NETCONF  or SocNL  underestimates posterior uncertainty of \(A\) in \(G_{2}\) by considering high-uncertainty node \(D\) as neighbor that reduce uncertainty. _LinUProp_ represents the uncertainty of a posterior using interval widths, where increased uncertainty from more neighbors leads to higher posterior uncertainty. The proposed interval ways can be interpret as a **generalized variance component** of the expected prediction error (Sec. 4.2). Furthermore, _LinUProp_ is interpretable due to the additive of neighbor uncertainty (Eq. (12)).

Preliminaries

**Belief Propagation (BP)** iteratively passes messages on a graph to infer posterior distributions of variables on a graphical model. We focus on the uncertainty in the inferred posteriors used for node classification on Markov Random Field (MRF). Bayesian networks are another important type of graphical models that can be converted into MRF .

Consider a graph \(=(,)\) with \(n\) random variable nodes, each with \(k\) possible classes. The prior \(_{s}\) for node \(s\) is a \(k\)-dimension probability distribution and \(e_{s}(i)\) specifies the prior probability for node \(s\) belonging to class \(i\). Each edge \((s,t)\) from \(\) represents the dependencies between the two random variables \(s\) and \(t\). In particular, the dependency is represented by a pairwise potential function, which is a \(k k\)_compatibility matrix_\(\) and \(H(i,j)\) denotes the degree of association between class \(i\) of node \(s\) and class \(j\) of node \(t\). We assume that \(\) is a symmetric matrix, as in [11; 7]. Specifically, for binary classification, the compatibility matrix is assumed to be

\[=0.5+&0.5-\\ 0.5-&0.5+.\] (1)

Similarly, an example form of \(\) for multi-class problems is setting the diagonal elements to \(+(k-1)\) and the other elements to \(-\). \(||\) is typically close to 0, and a positive/negative \(\) specifies a homophily/heterophily relationship between any two connected nodes. Unlike existing methods that require all edges to have the same compatibility matrix, our proposed _LinUProp_ can handle situations where each edge has a different compatibility matrix.

BP updates the \(k\)-dimensional _message_\(_{ts}\) sent from node \(t\) to node \(s\) by:

\[m_{ts}(i)_{j=1}^{k}H(i,j)e_{t}(j)_{u(t) \{s\}}m_{ut}(j),i=1,,k,\] (2)

where \((t)\) is the set of neighboring nodes of \(t\). Eq. (2) is applied iteratively until convergence or a maximum number of iterations is reached. Then the posterior \(_{s}\) for node \(s\) is

\[b_{s}(i)}e_{s}(i)_{t(s)}m_{ts}(i), \ \ i=1,,k,\] (3)

where \(Z_{s}\) is for normalization such that \(_{i=1}^{k}b_{s}(i)=1\).

**Centered BP** is a linearized version of Eqs. (2-3):

\[_{ts}(i) k_{j=1}^{k}(i,j) (_{t}(j)-_{st}(j)) -10.0pt,\ \ \ )}-10.0pt\ \ \ _{s}(i)_{s}(i)+_{t (s)}_{ts}(i),\] (5)

where \(_{s}(i)=e_{s}(i)-\), \(_{s}(i)=b_{s}(i)-\), \(_{ts}(i)=m_{ts}(i)-1\), \((i,j)=H(i,j)-\), are the centralized version of the prior, belief, message, and compatibility matrix.

**NETCONF** models both the belief and uncertainty of each node using a Dirichlet distribution. The certainty of a node is represented by the sum of its Dirichlet parameters, where a higher sum indicates greater certainty. Each node \(u\) is initialized with a prior Dirichlet belief vector \(}_{u}\). The posterior Dirichlet belief \(}_{u}\) is updated using multinomial messages from its neighbors:

\[}_{u}}_{u}+_{v (u)}}_{vu},}_{vu} (}_{v}+_{w(v) u} }_{wv}),\]

where \(}_{vu}\) is the message from node \(v\) to \(u\), and \(\) is a modulation matrix derived from \(\).

**Problem 1** (Quantifying Uncertainty in Posteriors).: _Given: (1) An undirected graph \(=(,)\) consisting of n nodes and an adjacency matrix \(\), (2) \(||\) compatibility matrices, where each matrix illustrates the dependency relationship between a pair of connected nodes, and (3) \(n\)\(k\)-dimensional prior uncertainty vectors \(_{i}(i=1,,n)\), with each vector representing the uncertainty in prior beliefs for a node as interval widths across the \(k\) classes. Find \(n\)\(k\)-dimensional posterior uncertainty vectors \(_{i}(i=1,,n)\), where each vector represents the uncertainty of posterior beliefs for \(k\) classes of a node based on interval width, with wider interval indicating higher uncertainty._

## 3 Linear Bound Propagation

Recall that our objective is to quickly quantify the uncertainty in posterior beliefs and not assume that neighbors necessarily reduce uncertainty, in order to avoid uncertainty underestimation. Interval arithmetic  is a non-probabilistic method for quantifying uncertainty without assumptions regarding neighbors. However, it is unclear how to directly apply interval arithmetic rules to Eqs. (2-3) of BP while meeting the above objectives.

A solution to these challenges lies in linearization. The linearized BP is more amenable to interval arithmetic due to its exclusive reliance on interval addition, sidestepping the interval multiplication that may underestimate uncertainty. Consequently, this facilitates the derivation of closed-form solution, endowing the method with linear scalability, interpretability, and guaranteed convergence.

We will next introduce _LinUProp_ and its iterative variant, which is computationally efficient in practical applications. Prior to that, we need some additional notation pertinent to _LinUProp_. Let \(\) denotes the operation that vertically concatenates the rows of a given matrix into a single column vector, and let \(\) denote the transformation of an \(nk k\) block matrix into a block diagonal matrix. \(=[_{1},_{2},,_{n}]^ {T}\) and \(=[_{1},_{2},,_{n}]^ {T}\) respectively represent the uncertainties of prior and posterior beliefs for all \(n\) nodes, each of dimension \(n k\). \(\) is an \(nk k\) matrix formed by vertically stacking \(n\) identity matrices, each of size \(k k\). \(_{1}^{{}^{}}\) and \(_{2}^{{}^{}}\) are \(nk nk\) block matrices formed from \(}_{st}^{{}^{}}\) and \(}_{st}^{{}^{}2}\), respectively. For any given edge \((s,t)\), \(}_{st}^{{}^{}}\) denotes the centralized compatibility matrix corresponding to that edge, with entries \(}_{st}^{{}^{}}\) defined as \(}_{st}^{{}^{}}(i,j)=|H_{st}(i,j)-|\). In cases where the edge \((s,t)\) does not exist, the matrix defaults to zero.

\[(_{1}\\ \\ _{n})=_{1}&&\\ &&\\ &&_{n}_{1}^{{}^{}}= }_{11}^{{}^{}}&&}_{1n}^{{}^{} }\\ &&\\ }_{n1}^{{}^{}}&&}_{nn}^{{}^{} }_{2}^{{}^{}}=}_{11}^{{}^{}2}&&}_{1n}^{{}^{}2}\\ &&\\ }_{n1}^{{}^{}2}&&}_{nn}^{{}^{ }2}\]

**Theorem 3.1** (_LinUProp_).: _For a multi-class node classification task on an MRF, given the matrix \(\) which represents the prior belief uncertainty of all nodes, matrices \(_{1}^{{}^{}}\) and \(_{2}^{{}^{}}\) which denote the dependencies among these nodes. The posterior belief uncertainty for all nodes, represented by \(\) and in terms of interval widths, is determined by the linear equation system:_

\[()=()+(_{1}^{{}^{ }}+(_{2}^{{}^{}}) )().\] (6)

Figure (2) illustrates Eq. (6) using a 3-node chain as an example. From this, it can be observed that _LinUProp_ can be implemented using matrix multiplication without computing the uncertainty propagated between each pair of nodes. In practice, a more effective strategy for computing the

Figure 2: An illustration of _LinUProp_ quantifying uncertainty in posterior beliefs for each node in a 3-node chain. _Inputs_: (1) Uncertainty in prior beliefs of each node represented as interval widths (\(_{1}\),\(_{2}\),\(_{3}\)) (2) Edge potentials (\(_{12}\) and \(_{23}\), with \(_{21}=_{12}\) and \(_{32}=_{23}\) due to the undirected graph). _Outputs_: uncertainty in posterior beliefs of each node also represented as interval widths. _LinUProp_ can set a different compatibility matrix for each edge, allowing it to handle edge-dependent potentials, while previous methods cannot do this.

posterior belief interval widths \(()\) is to use an iterative update version of _LinUProp_:

\[()^{(l+1)}=()+( _{1}^{{}^{}}+(_{2}^{{}^{}} ))()^{(l)},\] (7)

where \(l\) denotes the iteration round and \(()^{(0)}\) can be set to \(()\). Although Eq. (6) is similar in form to another method, _LinBP_ (Eq. (13), ), which is a point estimation inference approach rather than a UQ method, simply replacing prior and posterior beliefs in _LinBP_ with interval widths does not yield _LinUProp_. _LinUProp_ is specifically designed to quantify uncertainty through derivations involving the upper and lower bounds of messages and beliefs. For detailed derivations, please refer to Appendix A.1. Its guaranteed convergence is proven in Sec. 4.1. The proof of its linear scalability is provided in Appendix A.3, showing that the time complexity per iteration is \((||)\) when \(||>||\), otherwise \((||)\).

## 4 Analysis

We present theoretical analyses of _LinUProp_, including the derivation of a closed-form solution, the proof of its convergence, and the provision of an interpretable approach to the uncertainty quantified by _LinUProp_. Furthermore, by employing the bias-variance decomposition, we addressed the question of what the uncertainty computed by _LinUProp_ represents and established the connection between this uncertainty and the expected prediction error.

### Theoretical Analysis of _LinUProp_

**Closed-form solution.** By simplifying Eq. (6), we can derive a closed-form solution for _LinUProp_:

\[()=-_{1}^{{}^{ }}-(_{2}^{{}^{}}))^{-1}}_{ ^{{}^{}}}(),\] (8)

where \(\) represents the identity matrix. This closed-form solution is primarily used for subsequent theoretical analysis; in practice, the iterative version Eq. (7) is employed, which does not require the computation of the matrix inverse.

**Convergence.** Let \(_{1}^{{}^{}}+(_{2}^{{}^{ }})\) be denoted as \(\). The sufficient and necessary criteria for the convergence of _LinUProp_ is that the spectral radius of \(\) is less than 1:

\[()<1\] (9)

Proof.: The closed-form solution of _LinUProp_ (Eq. (8)) conforms to a general linear equation system, \(=(-)^{-1}\), where \(\), \(\), and \(\) are generic terms. Such linear equation systems can be solved by the Jacobi method , which converges if and only if the spectral radius of \(\) is less than 1. 

From the above convergence condition, _LinUProp_ has a limitation: in large graphs with strong global (most edges) homophily/heterophily, \(()\) may be large, leading to non-convergence. However, _LinUProp_ can still converge if such strong homophily/heterophily is only local (a few edges).

**Interpretability.** When _LinUProp_ converges, with \(()<1\), we can expand the closed-form solution Eq. (8) using the Neumann series, yielding:

\[()=(++^{2}+ )().\] (10)

The uncertainty of the posterior belief for a certain class of a node, \(()_{v}\) can be expanded as

\[()_{v}=()_{v}+_{v}()+(^{2})_{v}()+,\] (11)

where \(_{v}()\), \((^{2})_{v}()\), etc. can be expanded to \(_{w}_{v,w}()_{w}\),

\(_{w}(^{2})_{v,w}()_{w}\) and so on, the subscript \(v\) represents the \(v\)-th row of matrices \(,^{2},\), while the subscript \(w\) represents the \(w\)-th column of matrices \(,^{2},\) and the \(w\)-th component of \(()\). Finally, we derive the contribution of the prior uncertainty of a certain class of any other variable node \(()_{w}\) towards the posterior belief uncertainty \(()_{v}\) as

\[c_{w v}=_{v,w}()_{w}+(^{2} )_{v,w}()_{w}+(^{3})_{v,w} ()_{w}+\] (12)This linear equation facilitates simple explanations of the uncertainty computed by _LinUProp_. Since \(()<1\) ensures convergence, the influence of higher-order terms, such as \(^{3}\) and \(^{4}\), decays rapidly. Therefore, in practice, considering only the first few terms often provides an accurate and interpretable estimate of uncertainty contributions.

### Theoretical Connection with Bias-Variance Decomposition

To delve into the theoretical understanding of the uncertainty in the node's posterior belief, we employed the bias-variance decomposition , an effective tool for analyzing prediction errors and decomposing model uncertainty . We demonstrated that the posterior uncertainty computed by _LinUProp_ is a _generalized variance component_ of the expected model prediction error, giving _LinUProp_ a solid theoretical basis. This relationship between the uncertainty computed by UQ methods and the expected model prediction error has seldom been explored by existing work [7; 36; 35]. To begin with, we first derive a linearized BP suitable for edges with distinct potential functions to facilitate bias-variance decomposition.

From the update equation of message \(}_{ts}\) as shown in Eq. (4), we can derive the update rule for the reverse message \(}_{st}\) and substitute it back. This leads us to the stable message \(}_{ts}\) when the algorithm converges. By inserting the stable message into Eq. (5) and simplifying, we can derive the closed-form solution for posterior beliefs where each edge has a distinct potential function (detailed proof in Appendix A):

\[(})=-_{1}+(_{2}))^{-1}}_{}}(}),\] (13)

\[_{1}=}_{11}&&}_{1n}\\ &&\\ }_{n1}&&}_{nn}_{2}=}_{11}^{2}&&}_{ 1n}^{2}\\ &&\\ }_{n1}^{2}&&}_{nn}^{2}\]

where vec and Diag are the same as those in Eq. (6). \(}=[}_{1},}_{2},,}_{n}]^{T}\) and \(}=[}_{1},}_{2},,}_{n}]^{T}\) are \(n k\) matrices composed of the centralized posterior and prior beliefs of all nodes. \(\) is an \(nk k\) matrix formed by vertically stacking \(n\) identity matrices, each of size \(k k\). \(_{1}\) and \(_{2}\) are \(nk nk\) block matrices formed from \(}_{st}\) and \(}_{st}^{2}\), respectively. For any given edge \((s,t)\), \(}_{st}\) denotes the centralized compatibility matrix corresponding to that edge, with entries \(}_{st}\) defined as \(_{st}(i,j)=H_{st}(i,j)-\). If the edge \((s,t)\) does not exist, the matrix defaults to zero.

This closed-form solution shows that the posterior belief can be regarded as a linear model of the prior belief. Specifically, consider the element \((})_{v}\). This element represents the centralized posterior belief of a specific class corresponding to a particular node. It is formulated as a linear combination of all centralized prior beliefs, represented by \(_{v}(})\). Here, \(_{v}\) denotes the \(v\)-th row of \(\). This linear equation enables us to derive a bias-variance decomposition of the uncertainty in the posterior belief. We define \(h(})\) as the centralized posterior belief corresponding to a specific class for a particular node in an unknown true linear model, and represent the centralized belief about \(}\) computed using Eq. (13) as \((})_{v}\). Then, the expected model prediction error can be decomposed into bias and variance as

\[[(h(})-(})_{v} )^{2}]=})-[ (})_{v}])^{2}}_{()^{2}}+ [((})_{v}-[(})_{v}])^{2}]}_{}.\] (14)

Expanding the variance term yields

\[[((})_{v}-[( })_{v}])^{2}]=_{v}_{(})}_{v}^{T},\] (15)

where \(_{(})}\) is the covariance matrix of \((})\) (proof in Appendix A.4). If we assume that the priors of different nodes and class probabilities within each node's prior are nearly independent, \(_{(})}\) can be approximated as a diagonal matrix. Consequently, the sign of the elements in will not affect the result of Eq. (15). Ignoring the small term \(()\), the variance component can be approximated as \(^{{}^{}}_{v}_{(})}^{{}^ {}T}_{v}\). The posterior interval width for \(v\) computed by \(\) is \(()_{v}=^{{}^{}}_{v}()\), leading to \(()_{v}(()^{T})_{v}=^{{}^{ }}_{v}(()()^{T})^{{ }^{}T}_{v}\). This implies that the variance component is a **special case** of _LinUProp_ where the outer product of the prior interval width \(()()^{T}\) is the covariance matrix \(_{(})}\). **In other words**, the uncertainty computed by _LinUProp_ is a _generalized variance component_ of the expected prediction error.

## 5 Experiments

We begin with a simple case study to illustrate the correctness and interpretability of quantified uncertainty. We then present quantitative evidence of our method's ability to accurately quantify uncertainty, and demonstrate the convergence and scalability of our methods on real-world datasets. Finally, we compare the efficacy of _LinUProp_ to other competitors in graph active learning tasks.

### Case Study on a Simple Graph

**Correctness of quantified uncertainty.** To verify the correctness of the uncertainty quantified by _LinUProp_ for posterior beliefs, we first qualitatively analyze the belief bounds on a simple graph. Specifically, we conduct the experiment on a 4\(\)4 grid, as shown in Figure 3(a),

with priors set to \((9,1)\) (red nodes) or \((1,9)\) (green node) for labeled nodes, and \((1,1)\) for the unlabeled nodes. We use Beta distributions as priors in binary classification because they are a natural choice for binary random variables . For each variable node, the prior interval width for each class is set to twice the standard deviation of the corresponding prior Beta distribution. For each edge, the compatibility matrix is set as in Eq. (1), with \(=0.1\).

Figure 3(b) shows that the more labeled nodes around each node \(s\), the smaller the uncertainty in the belief; the more unlabeled nodes around \(s\), the larger the uncertainty in the belief, which is intuitive. In addition to the qualitative analysis mentioned above, we also compared the uncertainty quantified by _LinUProp_ with that quantified by MC simulations. MC simulations are adopted as the ground-truth due to its ability to provide accurate approximations through a sufficient amount of sampling , which are feasible for small-scale graphs. The experimental results show a strong positive correlation between the uncertainties quantified by the two methods (PCC=0.9084), which can be found in Appendix B.1.

Figure 4: (a) Convergence of average belief bound width by _LinUProp_. (b) Scalability. Each data point represents the running time of _LinUProp_ for 10 iterations with a certain number of edges. The y-axis is the running time in seconds.

Figure 3: Case Study. (a) A 4\(\)4 grid with two classes. The nodes colored in red and green are labeled, while the rest are unlabeled. The bold unlabeled node indicates the node we aim to explain the source of uncertainty. (b) An interpretation of the uncertainty in the belief of the bold node computed by _LinUProp_. The **colors** represent the contribution of each node to the uncertainty of the bold node, with warmer colors indicating more significant contributions; the **radius** of the white circles indicates the belief bound width computed by _LinUProp_ for each node, with a larger radius indicating higher uncertainty in the beliefs.

**Interpretability.** By Eq. (12), we can compute the contribution of any node \(t\) to the uncertainty in the belief of node \(s\) computed by _LinUProp_. Figure 3(b) shows that the main source of uncertainty for the bold node is itself because it is an unlabeled node. The unlabeled nodes in the neighborhood are the secondary sources, and the unlabeled nodes within 2 hops are the tertiary sources. It demonstrates that the uncertainty in the beliefs quantified by _LinUProp_ has good interpretability, which can enhance users' trust in UQ results computed by _LinUProp_.

### Experiments on Real Data

We validate the properties of _LinUProp_ on three popular citation networks (Cora, Citeseer, and PubMed)  and a political blog hyperlink network (PolBlogs) . For further details regarding these datasets and experimental configurations, please refer to Appendix B.2. Our experimental findings can be summarized into the following three aspects.

**Convergence.** We set node priors based on classification type: Beta distributions for binary and Dirichlet distributions for multi-class (\(k\) classes), both using parameter vector \(\) of length \(k\). In datasets, 30% of nodes are randomly labeled; if labeled as class \(i\), \(_{i}=10\), otherwise, entries are 1. Unlabeled nodes have \(=\). Prior interval widths for each class are twice the standard deviation of the distribution, capturing uncertainty by representing the interval as mean\(\)std.

To simulate the diversity of dependencies between nodes, each edge's \(\) is randomly selected from {1e-4, 5e-4, 1e-3, 5e-3, 1e-2} and linked to a \(k k\) compatibility matrix. Diagonal elements are \(+(k-1)\), and other elements are \(-\). We monitor _LinUProp_'s convergence (iterative version in Eq. (7)) by measuring the average belief bound width, \(_{p=1}^{n}_{q=1}^{k}(p,q)/(n*k)\).

Figure 4(a) shows that _LinUProp_ converges within 10 iterations across all four datasets, demonstrating its rapid convergence. Using an iterative update version of _LinUProp_, the posterior belief bound width for each node increases over iterations due to uncertainty propagation from other nodes.

**Scalability.** We initialize the prior interval width for nodes and the compatibility matrix for edges following the same procedure as in the convergence experiment. Then we uniformly sampled different numbers of edges from four datasets and recorded the running time of _LinUProp_ for 10 iterations. Figure 4(b) shows that the running time scales linearly in the number of edges. For more details on the runtime comparison between NETCONF and _LinUProp_, please refer to Appendix B.4.

**Effectiveness.** For large-scale graphs, MC sampling is computationally impractical due to the significantly increased time required for each sample. Therefore, we evaluate _LinUProp_'s effectiveness using active learning as a downstream task. Specifically, we use uncertainty-based sampling to select the next node for label acquisition, as detailed in . In this context, users seek a labeled dataset with minimal uncertainty, maximum accuracy, and minimal labeling budget.

We simulate a realistic scenario as in , using training set \(_{train}\), validation set \(_{val}\), test set \(_{test}\), and unlabeled pool \(_{ulp}\) (node numbers in Table 1, Appendix B.2), with query batch size \(b\). Initially, training set nodes are labeled and others are unlabeled. Node priors follow the convergence experiment procedure. Edge compatibility matrices match the correctness experiment, enabling comparisons with existing methods that cannot handle diverse potential functions. Due to noisy labeling, the unlabeled pool remains unchanged to allow re-labeling .

For each selected node \(s\), we update its Dirichlet prior by incrementing the parameter for the given label class by 1. After each labeling iteration, all nodes undergo inference. Noisy labels may not guarantee improved inference accuracy, so we use the iteration yielding the highest validation accuracy to evaluate the test set, which determines the test accuracy for the current labeling budget. MC-based methods are unsuitable for active learning as it requires time-consuming sampling for each iteration. We use the following strategies in each iteration:

* **Random:** Select \(b\) nodes randomly.
* **Least Confidence (LC):** Calculate uncertainty as \(U_{LC}(s)=1-*{argmax}_{i}b_{s}(i)\).
* **Entropy:** Calculate uncertainty as \(U_{Entropy}(s)=-_{i}b_{s}(i) b_{s}(i)\).
* **Certainty Score (CS):** Let \(}\) be the parameter vector of the posterior Dirichlet distribution of node \(s\) inferred by NETCONF . Uncertainty is \(U_{CS}(s)=-_{i}}(i)\). Due to assumptions on distribution forms of priors, messages, and posterior beliefs, only applicable with NETCONF.

* **Belief Bound (BB):** Based on _LinUProp_ with the same prior bound width setting as in the convergence experiment, uncertainty is \(U_{BB}(s)=}\).
* **LC+CS:** Perform Min-Max normalization on \(U_{LC}(s)\) and \(U_{CS}(s)\) to obtain \(U_{LC}^{norm}(s)\) and \(U_{CS}^{norm}(s)\). Uncertainty is \(U_{LC+CS}(s)=U_{LC}^{norm}(s)+U_{CS}^{norm}(s)\).
* **LC+BB:** Combine LC and BB. Compute uncertainty as: \(U_{LC+BB}(s)=U_{LC}^{norm}(s)+U_{BB}^{norm}(s)\).

We set query batch size \(b=2k\) (\(k\) is the number of classes) and maximum labeling budget to 20\(b\). We evaluate node selection strategy performance with annotator labeling accuracy at 70%, 80%, 90%, and 100%. To reduce randomness in results, we repeat each method ten times (re-partitioning datasets and changing random seeds) and record the mean of test set inference accuracies. To demonstrate labeling budget impact, we conduct experiments evaluating various node selection strategies under different labeling budgets on four datasets, varying the budget from 2\(b\) to 20\(b\).

As shown in Figures 5 and 6, whether using BP or NETCONF for inference, the test accuracy of the _LinUProp_-based node selection strategy (BB) and its variations (LC+BB) generally grow faster than other baselines as the budget increases. This is especially the case when compared to the native UQ method in NETCONF (CS) and its variations (LC+CS). As shown in Figure 6, strategies based on NETCONF (CS/LC+CS) prioritize labeling low-degree nodes due to their inherent assumption that neighbors necessarily reduce the uncertainty. As a result, nodes with many neighbors are often mistakenly viewed as having low uncertainty and are left unlabeled, which further leads to high uncertainty in the majority of nodes. This phenomenon is more pronounced in graphs with a large number of low-degree nodes, like PolBlogs, leading to a very slow increase in accuracy. Experiments with a lower labeling accuracy yielded similar conclusions, as shown in Appendix B.3.1.

We also evaluate all strategies under a fixed labeling budget of 20\(b\) for a fair comparison, with results displayed in Appendix B.3.2. The conclusion is that whether using BP or NETCONF for inference,

Figure 5: Test accuracy for varying labeling budgets with **BP** inferring posterior beliefs. Each subplot title includes two components, which represent the labeling accuracy and dataset. Each column corresponds to a dataset. In each subplot, the node selection strategies based on _LinUProp_ and its variant are represented by red \(\) and purple \(\). Under the same labeling budget, the higher the test accuracy, the better.

Figure 6: Test accuracy for varying labeling budgets with **NETCONF** inferring posterior beliefs. Each subplot title includes two components, which represent the labeling accuracy and dataset. Each column corresponds to a dataset. In each subplot, the node selection strategies based on _LinUProp_ and its variants are represented by \(\) and purple \(\), while the strategies based on the native UQ method in NETCONF and its variants are represented by brown \(\) and pink \(\). NETCONF-based strategies (CS/LC+CS) often prioritize labeling low-degree nodes due to their assumption that neighbors serve as evidence, leading to persistent high uncertainty in most nodes and slowly increasing accuracy. Under the same labeling budget, the higher the test accuracy, the better.

BB and LC+BB outperform baselines across different labeling accuracies and datasets in most cases. From the results in active learning tasks, we see node selection strategies guided by _LinUProp_'s UQ results achieves higher labeling accuracy with lower labeling budget. This indicates that uncertainty quantified by _LinUProp_ is accurate, effective, and insensitive to the inference method.

## 6 Related Work

**Uncertainty in posterior belief.** In addition to traditional UQ methods like MC simulations, which require extensive sampling, some research focuses on modeling uncertainty in posterior belief by deriving closed-form solutions to incorporate uncertainty into inference results. Existing methods [7; 36; 35] exhibit scalability but limited as they assume uniform potential functions across all edges. Furthermore, these methods with closed-form solutions assume that any neighbor of a node will necessarily reduce the uncertainty even neighbors affected by noise or lacking information, potentially leading to uncertainty underestimation. Moreover, few existing studies have theoretically linked calculated uncertainty to the expected model prediction error, making it difficult for decision-makers to understand and trust the UQ results.

Existing works [22; 20] utilize bound propagation without the aforementioned assumptions regarding neighbors. However, they focus on quantifying the error between the posterior beliefs and the true marginal probabilities of the variable nodes, rather than quantifying uncertainty. This fundamentally differs from _LinUProp_, which quantifies the posterior uncertainty as the generalized variance component of the expected prediction error.

**Human understanding of PGM inference.** Humans are unlikely to adopt inference outcomes without reasonable interpretation . In [24; 32], the authors studied explainable Bayesian networks. Recently, explanations of inference on Bayesian network and MRF were found by differentiation [3; 5], so that a set of important network parameters (potentials) can explain the changes in the inferred posterior distribution of a target variable. Interpretable graphical models are also studied under the hood of topic models  or GNN . None of the aforementioned studies can provide an explanation for the _uncertainty_ in the inference results.

## 7 Conclusion

In this paper, we proposed _LinUProp_, a UQ method for graphical model inference that utilizes a novel linear propagation of uncertainty to model uncertainty among related nodes additively. _LinUProp_ provides linear scalability, guaranteed convergence, and is interpretable. Unlike its competitors, _LinUProp_ does not assume neighbors necessarily reduce uncertainty and thus avoids uncertainty underestimation. To gain deeper insights, we decompose the expected prediction error of the graphical model and prove that the uncertainty computed by _LinUProp_ is the generalized variance component of the decomposition. Experimental analysis shows _LinUProp_ possesses aforementioned properties and outperforms competitors in downstream tasks. However, the study has not yet explored the interpretability of uncertainty with human involvement in real-world decision-making processes, an area we aim to address in future research. We would also like to apply _LinUProp_ to more applications of graphical models to demonstrate its utility in the future.