# Characterizing the Impacts of Semi-supervised Learning for Programmatic Weak Supervision

Jeffrey Li\({}^{1}\), Jieyu Zhang\({}^{1}\), Ludwig Schmidt\({}^{1}\), Alexander Ratner\({}^{1,2}\)

\({}^{1}\)University of Washington, \({}^{2}\)Snorkel AI

{jwl2162, jieyu22, schmidt, ajratner}@cs.washington.edu

###### Abstract

Labeling training data is a critical and expensive step in producing high accuracy ML models, whether training from scratch or fine-tuning. To make labeling more efficient, two major approaches are programmatic weak supervision (WS) and semi-supervised learning (SSL). More recent works have either explicitly or implicitly used techniques at their intersection, but in various complex and ad hoc ways. In this work, we define a simple, modular design space to study the use of SSL techniques for WS more systematically. Surprisingly, we find that fairly simple methods from our design space match the performance of more complex state-of-the-art methods, averaging a 3 p.p. increase in accuracy/F1-score across 8 standard WS benchmarks. Further, we provide practical guidance on when different components are worth their added complexity and training costs. Contrary to current understanding, we find SSL is _not_ necessary to obtain the best performance on most _existing_ WS benchmarks but is more effective when: (1) end models are smaller, and (2) WS provides labels for only a small portion of training examples.

## 1 Introduction

Learning with limited labels is a fundamental challenge in machine learning (ML) applications . To address the significant costs of hand-labeling training sets, _programmatic weak supervision (WS)_ has emerged as a high impact research area , where the aim is to learn from multiple cheaper sources of _noisy labels_. Meanwhile, _semi-supervised learning (SSL)_ is a more classical direction with similar high-level motivations. Instead of generating larger quantities of noisy labels, SSL aims to directly leverage additional _unlabeled data_. It seems natural that these two fields could be applied productively with one another, yet their intersection has not been systematically studied.

In this work, we anchor on WS approaches and study whether they can be enhanced using techniques from SSL. At a high-level, most WS methods consist of two steps. First, a _label model_ aggregates a set of weak label sources to noisily label a training set. Commonly, these sources take the form of user-written heuristics (e.g., for sentiment analysis, a user may check for the keyword "great" to provide the label "positive"). Second, an _end model_ is learned on this training set. Crucially, weak sources can often abstain (e.g., the absence of "great" may not imply "negative"), leaving certain examples to remain unlabeled and thereby unused. This presents a natural opportunity to use SSL.

Indeed, this approach of using SSL in WS settings has motivated several recent methods . Though these works often attribute their observed improvements to their usage of unlabeled data , they also incorporate various algorithmic components in addition to SSL. Thus, we lack clarity about the precise contributions of SSL and whether simpler methods might also suffice. Also, while varying the amount of unlabeled data is crucial when evaluating SSL techniques , previous WS benchmarks contain little diversity along this key dimension. Here, we conduct a more systematic study of how useful SSL is in various WS settings, as well as how and when to best employ it.

Specifically, we first organize the intersection between SSL and WS by proposing an explicit design space, centered around disentangling the following key methodological considerations:

1. _Thresholding: What to treat as (un)labeled?_ Because WS uses heuristics for labeling, it often can only provide labels for a subset of examples, leaving the rest as unlabeled. Further, it can also be beneficial to _additionally_ remove some (likely) incorrect labels provided by WS, as shown by . Since unlabeled data can result in multiple ways when using WS, we view "what to treat as unlabeled" as a non-trivial and first-class axis in our design space.
2. _SSL Technique: How to use unlabeled examples_? After deciding what data should be treated as unlabeled, one can leverage these examples by simply using any existing SSL technique. Most recent proposals do so via self-training, which uses the end model to periodically provide labels for unlabeled examples; we also try other out-of-the-box SSL methods.
3. _Re-labeling: Whether to update weak labels during end model training?_ Because some labels from WS are incorrect, it can be helpful to _re-label_ a training set with the end model during training. This approach, increasingly used by WS methods [30; 11; 4], is often packaged as part of self-training-based SSL. Here, we identify that re-labeling and SSL can be _independently_ employed, and we aim to disentangle their impacts.

With our design space, we can organize previous works and modularly generate a variety of methods. We test these methods on several standard WS benchmarks, finding that our design space is sufficient for matching the performance of more complex state-of-the-art methods. We then compare methods within our design space to ablate the importance of each axis and so provide guidance on when each is worth using (and thus more carefully exploring). We summarize our key findings as follows:

* By searching over our design space, we identify two methods that at least match all previous baselines on 6 of 8 WS benchmarks, averaging a 3 p.p. increase in accuracy/F1-score.
* While previous works emphasize utilizing data left unlabeled by WS sources, we find that on 6 of 8 benchmark tasks, SSL is actually _not_ necessary for achieving high performance: thresholding and re-labeling can recover 90% of the gains achieved by also using SSL.
* To explain SSL's lack of impact, we find that the small amounts of unlabeled data in these 6 benchmarks (i.e., < 31%) are largely unnecessary for the underlying tasks; when using clean instead of weak labels, ignoring unlabeled examples drops test accuracy by < 2.5 p.p.
* In contrast, when WS sources leave more data as unlabeled (i.e., > 65%), SSL is generally worth prioritizing; using it can improve upon thresholding and re-labeling by up to 16 p.p.

## 2 Related Work

**SSL for WS tasks.** Methods in WS have increasingly turned to SSL to improve end model training. This includes DENOISE , which incorporates the temporal ensembling SSL algorithm , as well as COSINE  and KeyClass , which both use self-training . Other works [11; 18; 6; 20; 19; 23; 1] apply SSL when learning from weak labels _plus_ a small set of clean labels. However, these methods fundamentally differ in their use of SSL, i.e., they define a labeled-unlabeled split based on cleanly versus weakly labeled examples. Further, integrating clean labels into WS enables a greater variety of specialized strategies, so we do not consider this setting in our study. Likewise,  assumes additional supervision via heuristics for which examples share the same labels, similar in spirit to consistency-based SSL methods. Finally, we defer a background on SSL in its own right to Section 3.

**SSL for learning with noisy labels.** SSL techniques have been regularly applied in the literature concerning learning from noisy labels [17; 7; 13]. Though this setting is similar to WS, its main difference is that label noise comes from a single "black-box" noising process instead of from multiple explicit WS sources. Thus, the resulting label noise patterns, often also artificially injected in input-independent ways , may differ significantly from those in WS. Furthermore, the WS setting contains some examples with no labels since WS sources may abstain.

**Subset selection in WS.** showcases the broad utility of more carefully selecting subsets of weak labels before end model training. In our work, we consider subset selection in the greater context of two other trends in the WS literature, applying SSL and re-labeling. Compared to the core method of , we also try a simpler baseline, similar to , based on thresholding the existing confidences produced for weak labels. We find that this method offers a competitive alternative on most datasets.

## 3 Design Space

In this section, we first formalize WS and SSL. Then, we describe how our design space overlays three decision WS, detailing its three key axes along with the specific instantiations of each that we explore in our experiments. Finally, we contextualize which parts of existing work fit within our framework.

### Problem Formalization

**Weak supervision (WS)** starts with an unlabeled training set \(D=\{x_{i}\}_{i=1}^{n}^{n}\) drawn from an underlying distribution \((x,y) P\). Labels are provided by a set of labeling functions (LFs) \(\{_{j}\}_{j=1}^{m}\), where each \(_{j}:\{\}\) either labels or abstains (denoted as \(_{j}(x_{i})=\)) on each \(x_{i}\). The goal is to train a _discriminative end model_ (DM) \(f:\) that performs well on \(P\). Canonically, WS methods contain two components. First, a _label model_ (LM) observes \(D,\{_{j}\}_{j=1}^{m}\) and outputs a _weakly labeled_ training set \(=\{(x_{i},_{i})\}_{i=1}^{n}\). Second, \(f\) is trained using \(\). Often, the LM models \(_{i}\) probabilistically, allowing \(_{i}\) to be a soft-label, a vector of probabilities over \(\).

Problematically, \(\) may contain several _uncovered_ examples, where \(_{j}(x_{i})=\) for all \(_{j}\). Thus, the default practice is then to train \(f\) only on _covered_ examples that received at least one non-abstaining LF vote. Concurrently, \(\) may also contain several _incorrect_ labels, where \(_{i} y_{i}\) (or in the soft-label case, \(_{c}_{i}[c] y_{i}\) where \(_{i}[c]\) is the probability assigned to class \(c\)). Both issues may lead to sub-optimal performance compared to standard supervised learning. Here, we focus on whether SSL lets us more effectively learn from \(\) in light of these challenges.

**Semi-supervised learning (SSL)** assumes access to a labeled dataset \(L=\{(x_{i}^{},y_{i})\}_{i=1}^{|L|}\) as well as an unlabeled dataset \(U=\{x_{i}^{u}\}_{i=1}^{|U|}\). The goal is to obtain a model that performs well on \(L\)'s underlying distribution despite the limited size of \(L\). Though not strictly required, it is often assumed that \(|L|<<|U|\) and both are drawn from the same test distribution. Generally, each SSL method makes a core assumption about how \(P(x)\) relates to \(P(y|x)\). Popular categories of methods include _entropy-minimization_[10; 16], which assumes \(P(y|x)\) is uncertain only when \(P(x)\) is small, and _consistency regularization_[21; 27; 14], which assumes local smoothness of \(P(y|x)\) when \(x P(x)\).

### A Simple Design Space

By considering the standard WS pipeline, we anchor our design space on three natural decision points as shown in Figure 1: (1) thresholding strategy, (2) SSL technique, and (3) whether to re-label previously used weak labels. Importantly, our design space is agnostic to the specifications of label model and end model, though particular choices for each could affect which methods work best.

Figure 1: _Overview of our design space._ In WS, a label model produces a weakly labeled training set \(\) which is used to train a discriminative end model. Our design space overlays three decision points on this pipeline: (1) _thresholding_, which filters out some weak labels in \(\) to return labeled and unlabeled sets \(L\) and \(U\); (2) _SSL technique_, which defines how the end model can still use \(U\) during training; (3) _re-labeling_, which uses the end model to update previously used weak labels.

**Thresholding.** To apply SSL, we must first define which examples in \(\) should be considered as part of \(L\) and \(U\), respectively. Though this is baked into the problem definition in traditional SSL settings, it is a non-trivial choice in WS settings. As a default, standard WS pipelines select \(L\) based on labeling function _coverage_, ignoring uncovered examples on which all \(_{j}\) abstain. However, as shown by , removing additional examples from \(\) can help if they are more likely to be incorrectly labeled. In our work, we consider the following strategies for partitioning \(\) into \(L\) and \(U\):

* _Coverage-based (default):_ This removes uncovered points \(\{(x_{i},_{i}):_{j}(x_{i})=, j\}\).
* _Confidence-based:_ Since most label models can output probabilistic labels, a basic yet under-explored approach tried by  is to remove examples that have low estimated confidence, here defined as the highest probability assigned to a class. Formally, this removes the examples \(\{(x_{i},_{i}):_{c}_{i}[c]<\}\) for some threshold \(||^{-1}<<1\).
* _Cut-based:_ This is the method of , which at a high-level removes examples whose labels differ most from those of their nearest neighbors in some pre-trained embedding space.

**SSL Techniques.** After partitioning \(\) into \(L\) and \(U\), we next consider how to still make use of the examples in \(U\) to train better end models. By default, WS methods ignore \(U\) altogether, but we may instead apply a variety of strategies, such as plugging in any existing SSL technique. Like , we limit ourselves to SSL techniques that add unsupervised loss terms during training since these methods tend to achieve the best performance on traditional SSL benchmarks. We also pick representative methods from their taxonomy of approaches:

* _Entropy minimization (EM):_ A classical approach, EM  penalizes uncertain predictions on unlabeled examples, aiming to place a decision boundary in low-density regions of \(P(x)\).
* _Self-training (ST):_ Self-training, along with the closely related pseudo-labeling , are traditional SSL methods that iteratively use current predictions on unlabeled examples as true labels. Uniquely in the WS setting, we also consider self-training the label model and end model _together_. Inspired by , we try one way to do so by feeding the end model as an additional labeling function \(_{m+1}\) used to re-fit the LM. We call this ST (DM as LF).
* _Consistency regularization:_ These methods encourage similar predictions on (realistic) perturbations of unlabeled examples. We use VAT  as it does not rely on data augmentations, which are less straightforward for text datasets, the majority of WS tasks. On some tasks, we are also able to use UDA , generating perturbations via En-De backtranslations.

**Re-labeling \(L\).** Traditional SSL assumes that all labels in \(L\) are correct. However, in WS, we may also consider using the end model to correct labels in \(L\) as it trains. This increasingly popular technique in WS methods  is often packaged with traditional self-training as an overall "SSL method" : instead of using the current model to label just \(U\), these methods also do so for \(L\). However, this makes it difficult to discern whether these methods improve performance because they leverage \(U\) (i.e., apply SSL) or simply because they clean up labels in \(L\). Therefore, in our study, we explicitly decouple the use of SSL and re-labeling \(L\) as two _independent_ decisions; i.e., we can re-label \(L\)_regardless_ of whether we self-train on \(U\), or indeed use any specific SSL technique.

Specifically, we consider two forms of re-labeling analogous to the two types self-training for SSL: (i) using the end model's predictions directly; (ii) using an LM re-fit with the end model as an LF. For

 
**Method** & **Thresholding** & **SSL Technique** & **Re-labeling \(L\)** & **Novel LM** & **Add. Reg.** & **Add. Labels** \\  Vanilla WS & Coverage & – & – & – & – & – \\  Cutstat  & Cat-based (one-time) & – & – & – & – & – \\ Denoise  & Coverage & Temp. Ensembling & Self-Train LM & ✓ & – & – \\ Weael  & – & – & Agreement-based & ✓ & – & – \\ Cosine  & Confidence (dyn.) & Self-Train & DM directly & – & ✓ & – \\ KeyClass  & Confidence (dyn.) & Self-Train & DM directly & – & ✓ & – \\  ASTRA  & Coverage & Self-Train (DM as LF) & DM as LF & ✓ & – & ✓ \\ LP+WH  & – & Label Propagation & – & – & ✓ & ✓ \\ SPEAR  & – & Entropy Min & Agreement-based & ✓ & ✓ & ✓ \\  

Table 1: _Contextualizing methods within (middle columns) and outside (rightmost) our design space._ “Novel LM” refers to a method introducing its own label model. “Add. Reg.” refers to using additional regularizations, such as contrastive losses and soft-label re-normalization. “Add. Labels” refers to assuming an additional set of clean labels. For methods using clean labels, we do not compare to their results directly, but we can still place elements of their approaches in our design space.

tractability, however, we only consider re-labeling \(L\) in manner (i) when using SSL, except when the SSL technique is already ST (DM as LF). Also, since re-labeling effectively loops the two-stage WS pipeline back onto itself, \(N\) rounds of re-labeling could in principle be paired with \(N+1\) separate choices for thresholding and SSL. However, to reduce this search space, we only ever apply the same SSL method across all rounds. For thresholding, we try two possible schedules: _dynamic_, which applies the same thresholding after each re-labeling round and _one-time_, which fixes the \(L/U\) split for all rounds of end model training. Finally, some recent methods re-label by using a specialized LM that can be jointly learned with the end model [4; 18]. We do not include this type of _agreement-based_ re-labeling in our study, instead focusing on methods agnostic to the form of LM.

### Contextualizing previous works

With our design space, we can contextualize several recent WS methods, as shown in Table 1. Overall, this table demonstrates the lack of systematic exploration. For instance, few works perform any thresholding beyond coverage-based, and only  and  threshold initial LM outputs. Furthermore, assessing the impact of SSL in WS settings is muddled because methods often incorporate several different techniques. A salient example is that COSINE  was found by WRENCH  to obtain state-of-the-art performance, with both works championing the usage of unlabeled data as a key driver of improvements; however, what COSINE refers to as self-training actually involves pseudo-labeling the _whole_ dataset, thereby performing _both_ SSL and re-labeling. Further, many methods use techniques outside of our design space entirely, such as novel LMs [26; 4; 11; 18], contrastive learning , and soft-label re-normalization [30; 9]. As a result, it remains unclear whether our three axes are necessary or even sufficient to achieve optimal performance. Though our design space is by no means exhaustive, we believe it offers a useful starting point to answer such questions.

## 4 Results

We begin by describing our experiment setup and various baselines in Section 4.1. Then, Section 4.2 explores how our design space yields methods that perform at least as well as the aforementioned baselines. In Section 4.3 and Section 4.4, we conduct extensive ablations on our three axes, finding that SSL is surprisingly unnecessary on most existing WS benchmarks. Finally, Section 4.5 explains this phenomenon and explores settings in which SSL is more helpful.

### Experiment Setup

**Datasets and models.** We use 8 classification datasets (see Table 2) and largely follow the end model configurations from WRENCH  with a few changes to the hyperparameter grid (Appendix A). For NLP tasks, we both fine-tune RoBERTa pre-trained models and train MLP classification heads on (frozen) RoBERTa embeddings, deferring all results for the latter to the appendix. For tabular tasks, we just train MLPs on raw features. We tune all methods on a shared hyperparameter budget of 50 trials for full RoBERTa fine-tuning and 300 trials for MLPs. All reported test performances are then averages over over three additional test runs, while all error bars are the standard deviations over these runs. Finally, though our design space is compatible with any LM, we use the soft-labels produced by the Snorkel LM from . However, we test robustness to this choice by also trying Majority Voting when comparing with existing methods. From the conclusions of , these were most consistently the best LMs across many benchmark tasks.

 
**Datasets** & \(||\) & **Train** & **Test** & **\# LFs** & **Coverage** & **Snork. Precision** & **Metric** \\  IMDP & 2 & 20000 & 2500 & 5 & 87.6\% & 74.4\% & Acc. \\ Yelp & 2 & 30400 & 3800 & 8 & 82.8\% & 75.4\% & Acc. \\ Youtube & 2 & 1586 & 250 & 10 & 87.7\% & 87.0\% & Acc. \\ AgNews & 4 & 96000 & 12000 & 9 & 69.1\% & 82.5\% & Acc. \\ Tree & 6 & 4965 & 500 & 68 & 95.1\% & 60.0\% & Acc. \\  Spouse & 2 & 22254 & 2701 & 9 & 25.8\% & 65.6\% (on Val) & F1 (binary) \\ Chemport & 10 & 12861 & 1607 & 26 & 85.6\% & 58.0\% & Acc. \\  Census & 2 & 10083 & 16281 & 83 & 99.1\% & 58.0\% & F1 (binary) \\  

Table 2: _Statistics for the WS benchmarks that we use._ Groupings are by task type: text, relation, and tabular classification. Coverage is the percentage of training examples on which at least one LF does not abstain. “Snork. precision” refers to the accuracy of the Snorkel LM on the covered set of inputs.

[MISSING_PAGE_FAIL:6]

all _non-default_ thresholding and SSL techniques (i.e., {Conf-based, Cut-based} \(\) {EM, VAT, UDA, ST, ST w/ DM}) and then select the best of these combinations using the validation set. For "Entire Design Space," we perform this method selection procedure over all methods from the design space.1

From this analysis, we observe that SSL helps only in limited scenarios. Including SSL on _Spouse_ yields a 0.2 increase in F1-score compared to not using any form of SSL. However, on all the other six tasks, "Thresh + Re-label" performs at least within a standard deviation of the best method, making up 90% of the gap between "Vanilla" and "Thresh + SSL + Re-label." One explanation for this result is the distinctly lower coverage LF set for _Spouse_, a factor we explore in depth in Sec 4.5. Further, model size may also play a role. In the corresponding Table 9 (Appendix B) for MLPs, "Thresh + Re-label" can make up only 68% of the gap between "Vanilla" and "Thresh + SSL + Re-label."

### What are the best instantiations of each axis?

Having compared the three axes at a macro-level, we now zoom in on each. Specifically, we compare all implementations of a given axis when paired with the best possible setting of the other two. For thresholding and SSL, we find that simple or previously underexplored approaches are worth using.

**Thresholding.** Examining Table 4, we see that thresholding is significantly helpful in most cases. This extends the conclusions of , showing that removing labels still helps _even when also using SSL and re-labeling_. Interestingly, the simpler confidence-based threshold matches the cut-based method (within error bars) on all datasets except _Chemprot_.

**SSL and Re-labeling.** For these two axes, we observe largely similar trends in Tables 10 and 11 in Appendix C.2. SSL and re-labeling are each only strictly necessary for a minority of datasets, outperforming "no SSL" and "no re-labeling" (beyond error bars) on just one and two datasets, respectively. As such, all SSL methods also tend to perform similarly. For MLP models, though, where SSL is more useful, we see from Table 14 that VAT and ST (DM as LF) are the most consistent. No other method comes within error bars on four datasets.

  & **IMDB** & **Yelp** & **AGNews** & **TREC** & **Spouse** & **Chem.** \\  Cov & **0.901** & 0.953 & **0.885** & 0.702 & 0.365 & 0.593 \\  & **(0.013)** & (0.008) & **(0.002)** & (0.035) & (0.073) & (0.010) \\  & **0.907** & **0.965** & **0.887** & **0.765** & **0.531** & **0.605** \\  & **(0.004)** & **(0.000)** & **(0.005)** & **(0.012)** & **(0.007)** & **(0.002)** \\  & **0.906** & **0.965** & **0.884** & **0.741** & **0.531** & 0.593 \\  & **(0.005)** & **(0.002)** & **(0.002)** & **(0.029)** & **(0.039)** & (0.010) \\  

Table 4: _Closer look at thresholding for DM = RoBERTa._ We report the best performance of any method that uses each type of thresholding. Blue indicates the best result while bold indicates being within error bars of the best.

**Method** & **IMDB** & **Yelp** & **Youtube** & **AGNews** & **TREC** & **Spouse** & **Chem.** & **Mean** & **w/o Spouse** \\  Vanilla & 0.874 & 0.925 & **0.948** & 0.867 & 0.646 & 0.215 & 0.572 & 0.721 & 0.805 \\  & (0.002) & (0.017) & **(0.009)** & (0.008) & (0.011) & (0.012) & (0.002) & (0.004) & (0.004) \\  & 0.885 & 0.946 & **0.951** & **0.882** & 0.706 & 0.263 & 0.587 & 0.746 & 0.826 \\  & (0.002) & (0.006) & **(0.002)** & **(0.001)** & (0.015) & (0.071) & (0.005) & (0.010) & (0.003) \\  & 0.885 & 0.941 & **0.955** & **0.885** & 0.660 & 0.343 & **0.593** & 0.752 & 0.820 \\  & (0.002) & (0.008) & **(0.005)** & **(0.002)** & (0.074) & (0.075) & **(0.010)** & (0.015) & (0.013) \\  & **0.901** & 0.944 & **0.952** & 0.877 & 0.700 & 0.332 & 0.577 & 0.755 & 0.825 \\  & **(0.013)** & (0.004) & **(0.006)** & (0.002) & (0.014) & (0.105) & (0.010) & (0.015) & (0.004) \\  & **0.885** & 0.959 & **0.943** & **0.887** & 0.732 & **0.529** & **0.597** & 0.790 & 0.834 \\  & **(0.018)** & (0.002) & **(0.008)** & **(0.005)** & (0.014) & **(0.057)** & **(0.009)** & (0.009) & (0.004) \\  & **0.905** & **0.961** & **0.952** & **0.883** & **0.748** & 0.236 & **0.600** & 0.755 & 0.841 \\  & **(0.011)** & **(0.002)** & **(0.006)** & **(0.005)** & **(0.023)** & (0.085) & **(0.006)** & (0.013) & (0.005) \\  & 0.894 & 0.953 & **0.951** & **0.882** & 0.702 & 0.365 & 0.583 & 0.761 & 0.828 \\  & (0.008) & (0.008) & **(0.002)** & **(0.001)** & (0.035) & (0.073) & (0.003) & (0.012) & (0.006) \\  & **0.907** & **0.965** & **0.949** & **0.885** & **0.765** & **0.531** & **0.601** & 0.800 & 0.845 \\  & **(0.004)** & **(0.002)** & **(0.010)** & **(0.003)** & **(0.012)** & **(0.039)** & **(0.008)** & (0.006) & (0.003) \\  Entire Design Space & **0.907** & **0.965** & **0.952** & **0.885** & **0.765** & **0.531** & **0.601** & 0.801 & 0.846 \\  & **(0.004)** & **(0.002)** & **(0.006)** & **(0.002)** & **(0.012)** & **(0.039)** & **(0.008)** & (0.006) & (0.003) \\   Fully supervised & 0.932 & 0.976 & 0.967 & 0.918 & 0.966 & – & 0.894 & – & 0.943 \\  & (0.005) & (0.001) & (0.013) & (0.006) & (0.004) & – & (0.012) & – & (0.003) \\  

Table 3: _Axis ablation for LM = Snorkel, DM = RoBERTa._ Each entry corresponds to picking a specific method within our design space using validation tuning. Blue numbers are the highest for a given dataset, while bold numbers are those within error bars of the best result.

### When is SSL more useful?

To explain why SSL is largely redundant on most existing WS benchmarks, we show that the unlabeled data in each task is generally unnecessary for learning strong models. However, when using lower coverage LF sets, a setting not captured by these benchmarks, ignoring unlabeled data can significantly compromise performance, allowing SSL more room to be impactful.

**Data gaps in WS.** We can think of any WS training set \(L=\{(x_{i}^{},_{i})\}_{i=1}^{|L|}\) as suffering from:

1. _Limited size:_ Since not all examples are labeled, the quantity of labels \(|L|\) may be insufficient.
2. _Coverage bias:_ Since LFs abstain based on feature-dependent rules, the inputs in \(L\) represent a biased subpopulation of the true distribution that the test set is drawn from.
3. _Label noise:_ Since LFs are just heuristics, labels \(_{i}\) can be biased towards incorrect classes.

_We hypothesize that SSL adds more unique value within our design space when gaps (1) and (2) are more significant._ When gap (3) is the only dominating factor, there is less reason to expect SSL to outperform thresholding and re-labeling since the latter two more directly attempt to address label noise. However, these two axes still do not use the unlabeled examples, which cause gaps (1) and (2).

**Label noise (not unlabeled data) is the main gap on existing benchmarks.**

To measure the relative importance of the three data gaps, we compare the following models:

_GT (Cov)_: the model trained on the ground-truth labels for only LF-covered inputs, removing gap (3) but retaining gaps (1) and (2).

_GT (Full)_: the model trained with a clean and fully labeled version of \(D\), removing all gaps.

Given our hypothesis, we would expect these models to perform _similarly_ on WRENCH benchmarks. Indeed, as shown in Figure 3, the largest gap between them is < 2.5 p.p.2

**SSL helps more when coverage is lower.** While SSL's ineffectiveness on existing benchmarks corresponds to label noise being the predominant data gap, we would ideally also show that SSL is _more_ useful when the other two gaps are significant, i.e., when _GT (Cov)_ performs markedly worse than _GT (Full)_. One natural way to explore this would be to test on _lower coverage_ LF sets, which result in more unlabeled data. However, most existing benchmarks have high coverage, often above 80% as shown in Table 2. To overcome this limitation, we first explore a wider range of coverage levels by subsampling or generating LFs on existing datasets. We also create two new WS text classification tasks based on publicly available datasets, _Massive18_ and _Banking77_; these tasks have larger label spaces than all WRENCH tasks and therefore require more effort (i.e., LFs) to obtain high coverage. Finally, we explore the less frequently studied tabular setting, using _Mushroom_, _Spambase_, and _PhishingWebsites_ in a setup similar to that of . We defer details on all these data/LF sets to Appendix D.

From this analysis, we first see that smaller coverage levels (within the ranges we test) do not always cause _GT (Cov)_ to perform poorly. On some tasks (top two rows of Figure 4), including the three tabular and our two new ones, _GT (Cov)_ performs significantly worse as coverage decreases.3 In contrast, on _IMdb_, _Yelp_, and _AGNews_ (bottom row of Figure 4), _GT (Cov)_ surprisingly comes within 2% of _GT (Full)_ even when coverage drops to 10-20%.

Importantly, the partitioning of datasets based on the performance of _GT (Cov)_ also corresponds to the effectiveness of using SSL over not using it. For each LF set used, we run the methods within

Figure 3: _Measuring the importance of unlabeled data on WS benchmarks._ Assuming no label noise, removing unlabeled data for _GT (Cov)_ decreases performance minimally compared to _GT (Full)_.

a reduced version of our design space: we allow for confidence thresholding and try both versions of self-training to perform SSL (i.e., by labeling points in \(U\)) or to re-label (i.e., by labeling points in \(L\)). For the tabular tasks, we also try VAT for the SSL technique because of its effectiveness for MLPs. We plot the best performing methods for both "Thresh + SSL" and "Thresh + Re-label" in Figure 4.4 As shown in the top two rows, "Thresh + SSL" is enough to consistently outperform "Thresh + Re-label" at lower coverage levels. In contrast, in the bottom row, where _GT (Cov)_ drops in performance by < 2 p.p., "Thresh + SSL" continues to perform within errors of "Thresh + Re-label."

Overall, these results suggest that SSL can indeed be useful in WS settings that differ from those captured by standard benchmarks. At lower coverage levels (i.e., <35%), SSL is consistently worth trying; in practice, SSL may allow users to reduce the number of LFs they need to write in order to achieve a particular target performance. On our tabular tasks, these savings seem especially impactful; SSL allows one to achieve performance equivalent to having all 40 LFs (highest coverage plotted) with at most 20 LFs (second lowest coverage plotted).

## 5 Conclusion

We constructed a design space for combining SSL and WS, using it to both contextualize and match the performance of state-of-the-art WS methods. We show that on existing WS benchmarks, using the unlabeled data is surprisingly not essential. However, SSL can be more useful when training MLPs and when the LFs cover fewer examples. Some limitations of our work include: (1) a lack of finer-grained heuristics for more efficiently navigating our design space when given a new task; (2) relying on ground-truth labels to measure the relative importance of different data gaps; (3) using automated ways to generate low coverage LF sets which may not fully represent those written by real users. We see all of these limitations as seeding important directions for future work.

Figure 4: _Impacts of coverage level on data gaps and the effectiveness of SSL._ Plotting _GT (Full)_ (gray-dashed) and _GT (Cov)_ (blue), we measure the impacts of removing label noise across nested LF subsets. We also compare the effectiveness of Thresh + SSL (green) to Thresh + Re-label (red). For datasets more impacted by coverage bias and limited size (larger gaps between dashed and blue lines), SSL adds more unique value. “(Ours)” refers to datsets we introduce. “(Tab.)” refers to tabular tasks.