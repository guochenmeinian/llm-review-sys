# Sharpness-Aware Minimization Activates the

Interactive Teaching's Understanding and Optimization

 Mingwei Xu 1, Xiaofeng Cao 1, Ivor W. Tsang 2,3

1 School of Artificial Intelligence, Jilin University, China

2 CFAR and IHPC, Agency for Science, Technology and Research (A*STAR), Singapore

3 College of Computing and Data Science, Nanyang Technological University, Singapore

xumw23@mails.jlu.edu.cn,xiaofengcao@jlu.edu.cn,ivor_tsang@cfar.a-star.edu.sg

Equal contribution.Corresponding author.

###### Abstract

Teaching is a potentially effective approach for understanding interactions among multiple intelligences. Previous explorations have convincingly shown that teaching presents additional opportunities for observation and demonstration within the learning model, such as data distillation and selection. However, the underlying optimization principles and convergence of interactive teaching lack theoretical analysis, and in this regard co-teaching serves as a notable prototype. In this paper, we discuss its role as a reduction of the larger loss landscape derived from Sharpness-Aware Minimization (SAM). Then, we classify it as an iterative parameter estimation process using Expectation-Maximization. The convergence of this typical interactive teaching is achieved by continuously optimizing a variational lower bound on the log marginal likelihood. This lower bound represents the expected value of the log posterior distribution of the latent variables under a scaled, factorized variational distribution. To further enhance interactive teaching's performance, we incorporate SAM's strong generalization information into interactive teaching, referred as Sharpness Reduction Interactive Teaching (SRIT). This integration can be viewed as a novel sequential optimization process. Finally, we validate the performance of our approach through multiple experiments.

## 1 Introduction

Backgrounds.Teaching recognized as a pervasive mechanism for disseminating knowledge within human society, has found extensive application in contemporary deep learning methodologies. It serves as a cornerstone for various techniques such as knowledge distillation [17; 32; 15], data distillation , model compression [34; 7], and machine teaching, facilitating optimal training control [46; 47]. Recent investigations into pedagogy have illuminated the integration of large language models and multi-agent systems into educational frameworks. This novel approach emphasizes the significance of understanding interactions among multiple clients and agents. Multi-agent systems, anchored in language models, orchestrate the accomplishment of intricate tasks by assigning specific roles and prescribing behavioral norms to individual agents [18; 37]. Furthermore, they exhibit the capacity to transcend individual intelligence barriers through collaborative endeavors [24; 6], competitive dynamics, deliberative discourses [26; 12; 5], and other strategic modalities.

_Question: However, the optimization and generalization mechanisms concerning interactive teaching strategies remain at an incipient stage of exploration . Consequently, interactive teaching-basedstrategies hold promise in furnishing substantial inductive biases for further advancement in AI agent research. Especially for bidirectional interactive teaching, which lacks sufficient attention and theoretical exploration._

In the interactive teaching paradigm, the learning algorithm represented primarily by co-teaching  has demonstrated notable efficacy in achieving successful learning outcomes in the context of noisy data. This pedagogical approach can be delineated as an interactive teaching prototype wherein two networks with identical architectures serve as peer entities, engaging in interactions aimed at selecting samples with minimal loss values for parameter refinement. Despite the practical efficacy exhibited by interactive teaching methodologies like co-teaching, a notable lacuna persists in terms of theoretical comprehension and requisite convergence analyses. In light of this, we consider co-teaching as an incipient prototype for interactive learning, warranting further scholarly exploration. A more profound understanding of this interactive teaching paradigm holds the potential to yield significant insights into the dynamics governing interactions among intelligent agents . For instance, amid projections of diminishing data availability for training large-scale language models in the foreseeable future and the attendant challenges posed by synthesized data, ongoing research endeavors are directed towards facilitating collaborative engagements between disparate AI models to collectively generate data of higher fidelity and reliability .

The exploration of the loss landscape is paramount in elucidating the dynamics of interactive teaching, driving advancements in model generalization. Dinh et al.  introduce an important view that favors flat minima over sharp minima in terms of generalization. However, applying this proposition directly is hindered by overlooking the loss landscape geometric properties inherent in commonly used deep architectures. Foret et al.  introduce a pioneering methodology termed Sharpness-Aware Minimization (SAM), which entails delineating a perturbation neighborhood in parameter space, identifying the perturbation point that maximizes the loss value, and subsequently optimizing it via gradient descent. This formulation lends itself to a min-max optimization problem, effectively solvable through gradient descent techniques. The conception of SAM inspires contemplation on the interaction and update mechanisms of two networks within the context of interactive, within the framework of the loss landscape. While SAM operates on a single network, it necessitates the computation of two separate gradients at distinct locations. In this case, the initial step involves identifying the sharpest points within a specified range of data proportions within the loss landscape. While diverging from SAM's approach, interactive teaching omits the utilization of these sharp points and instead updates parameters based on the minima of the remaining loss points.

Our contributions.In this paper, we initially ascertain that interactive teaching effectively diminishes the loss landscape by strategically discarding a specific subset of high-loss data points. This process serves to optimize the training procedure, particularly beneficial in scenarios characterized by noisy data, ultimately resulting in a transition to a low-loss landscape during each iterative interaction. Such an approach may be construed as a prior induction of bias, strategically acknowledging the presence of noise within the training dataset. Subsequently, we advance the conceptualization of interactive teaching as an EM-iterative parameter estimation technique, drawing upon seminal work by Dempster et al. . The method's convergence is predicated upon the continual refinement of the lower bound of maximum likelihood estimation. This refinement targets the expectation of the noise posterior distribution pertaining to latent variables, enacted via a relaxation of inequalities. Moreover, to mitigate the inherent challenge of local optima within the interactive framework, we add a level of sharpness knowledge exchange that includes gradient information, which we refer to as **Sharpness Reduction Interactive Teaching (SRIT)**. This amalgamation delineates a novel dual-level sequential optimization paradigm. Finally, empirical validation of our proposed methodology is undertaken across diverse datasets, serving to substantiate its efficacy in augmenting model generalization capabilities. In summation, this manuscript underscores the following key contributions:

* From a perspective centered on loss sharpness, interactive teaching methodologies, such as co-teaching, serve to facilitate parameter adjustments directed at alleviating elevated loss values within the optimization landscape. This mechanism exhibits parallels with SAM optimization, notably in its emphasis on reducing sharpness.
* Our analysis establishes that interactive teaching can be delineated as a probabilistic model, with the incorporation of noisy data as latent variables shedding light on its operational intricacies. This elucidation presents a robust framework for the optimization of interactive teaching methodologies.

* Theoretically, our research confirms that the interactive teaching paradigm and the EM algorithm share certain underlying principles. Combined with the SAM method, it can effectively alleviate the issue of local optima. Therefore, this integration promotes better convergence towards reducing global sharpness in the optimization of loss landscape.

## 2 Related Work

Interactive teachingIn teaching community, the use of two networks for interactive teaching has gained prominence. Blum and Mitchell  divide examples into two views and trained separate algorithms on each, using their predictions to expand the other's training set. To address noisy labels, Malach and Shalev-Shwartz  propose a meta-algorithm with two identical predictors that update parameters based on prediction disagreements. Jiang et al.  introduce MentorNet, a neural network that guides a deep network (StudentNet) to focus on likely correct samples, reducing overfitting to corrupted labels. Co-teaching  employs two networks to combat noisy labels, with each network teaching its peer using small-loss instances. Variants like co-teaching+ , JoCoR , and CNLCU  have emerged. Co-teaching+ selects data with inconsistent predictions, JoCoR promotes prediction consistency and applies constraints, and CNLCU uses interval estimation to account for loss uncertainty. Based on these investigations, this paper adopts co-teaching as the prototype for interactive teaching research. In contrast to the exchange of loss information in a single interaction, our proposed algorithm introduces an additional level of sharpness knowledge exchange that includes gradient information. This can be viewed as a form of dual-level interactive learning.

Loss landscapeSeveral studies have explored the relationship between loss landscape flatness and optimization. Li et al.  investigate how network structures impact the loss landscape, finding that shortcut connections in ResNet lead to convergence towards better minima, while deeper models have sharper landscapes, and wider models tend to be flatter with better performance. Yao et al.  suggest that increasing batch size increases the spectrum of the Hessian matrix, resulting in convergence towards sharper solutions and higher error rates for deeper local minima. Baldassi et al.  demonstrate that the error loss function exhibits few extremely wide flat minima and propose entropy-driven algorithms for searching these regions. Bisla et al.  derive an optimization algorithm using low-pass filters to actively search for flat regions in the deep learning optimization landscape, similar to SGD.

Sharpness-Aware Minimization (SAM)SAM aims to improve the generalization performance of deep neural networks by seeking minima with flatter loss landscapes. Researchers have investigated various aspects related to the weight perturbation radius. Adaptive SAM  demonstrates that fixed-radius sharpness is sensitive to parameter rescaling, therefore incorporating scale-invariant adaptive sharpness. Surrogate Gap Minimization  defines an easily computable surrogate gap, which is equivalent to the dominant eigenvalue of the Hessian matrix. Du et al.  propose Efficient SAM, which incorporates two training strategies: Stochastic Weight Perturbation and Sharpness-Sensitive Data Selection. To alleviate high complexity, Liu et al.  propose a novel algorithm called Look-SAM that only periodically calculates the inner gradient ascent. Jiang et al.  design an adaptive policy based on the geometric structure of the loss function to enable random or periodic switching between SAM updates and ERM updates. Sparse SAM  accelerates training by introducing sparse perturbations through a binary mask. Other perspectives on SAM include Andriushchenko and Flammarion , who suggest that a smaller number of data points within each batch can result in better implicit bias of gradient descent for commonly used neural network architectures, and Zhang et al. , who propose first-order flatness to bound the maximal eigenvalue of the Hessian at local minima. Additionally, Dai et al.  point out that normalization in SAM helps stabilize the algorithm and makes it less sensitive to the choice of the hyperparameter \(\).

## 3 Preliminaries

Non-Convex Optimization for Loss FunctionFor a training dataset \(=\{(x_{i},y_{i})\}_{i=1}^{N}\), where \(x_{i}\) represents the input and \(y_{i}\) represents the outputs or targets. We use \(f_{}(x)\) to denote a commonly used neural network with \(\) representing the weight parameters of the network. \(:_{+}\) represents a per-data-point loss function, the training of neural network is typically a non-convex optimization problem, the _empirical risk minimization_ is shown as Equation 1:

\[=*{arg\,min}_{}\ _{}(f_{ })_{}(f_{})=\|}_{(x_{i},y_{i})}(f_{}(x_ {i}),y_{i}),\] (1)

we make the assumption that the function \(_{}(f_{})\) is both continuous and differentiable. During each iteration, the optimizers randomly select a mini-batch \(_{t}\) from the set \(\), using a fixed batch size.

Sharpness-Aware Minimization (SAM)SAM  expects the training process to unfold in a flatter region, resulting in smaller training losses around the neighborhood of the converged parameter \(\) and improving the model's generalization performance. The sharpness measure term is defined as the maximum change between the loss caused by parameter perturbation within a neighborhood and the previous loss, expressed as: \(_{:\|\|_{2}}_{}(f_{+ })-_{}(f_{})\). SAM optimizes a min-max problem as depicted in Equation 2:

\[=*{arg\,min}_{}_{:\|\|_{2 }}_{}^{SAM}(f_{+})+\| \|_{2}^{2},\] (2)

where \(\) represents a pre-defined constant that limits the radius of the neighborhood, while \(\) denotes the weight perturbation vector responsible for maximizing the training loss within the neighborhood constrained by \(\). \(\) denotes hyperparameter that dominates a \(L_{2}\) regularization term about weights. \(\) is obtained by approximating the first-order Taylor expansion of \(_{}(f_{+})\) at \(\) and solving it as a classical dual norm problem:

\[=*{arg\,max}_{:\|\|_{2}<} _{}(f_{+}) _{}(f_{})}{\|_{} _{}(f_{})\|_{2}^{2}},\] (3)

after obtaining \(\), the outer optimization \(_{}\) in SAM follows the usual gradient descent update for \(\): \(_{t+1}=_{t}- g(+)\), where \(\) is the learning rate. The difference lies in the computation of \(g(+)=_{}_{}(f_{}) |_{+}\), where the gradient is evaluated at \(+\).

Co-teachingThe architecture of co-teaching  consists of two models, \(f\) and \(g\), along with their corresponding weights \(_{f}\) and \(_{g}\). The algorithm starts by shuffling the training set \(\), which represents a noisy dataset. In each iteration, the algorithm fetches a mini-batch \(}\) from the shuffled dataset. Next, it selects a subset \(}_{f}\) and \(}_{g}\) of \(}\) by choosing the instances with the smallest losses based on the models \(f\) and \(g\) respectively. This selection is done by randomly sampling a fraction \(R(T)\) of the instances with the smallest losses:

\[}_{f}=*{arg\,min}_{^{}:| ^{}| R(T)|}|}(f,^{ });}_{g}=*{arg\,min}_{^{ }:|^{}| R(T)|}|}(g, ^{}),\] (4)

where \(R(t)\) is a parameter that determines the proportion of the smallest values to retain. \(|}|\) represents the number of samples in the dataset \(}\). Then, the algorithm updates the weights \(_{f}\) and \(_{g}\) by applying a gradient descent step using the selected subsets \(}_{g}\) and \(}_{f}\) respectively:

\[_{f}=_{f}-(f,}_{g}); _{g}=_{g}-(g,}_{f}).\] (5)

The algorithm updates the value of \(R(T)(0,1]\) based on the current epoch \(T\) and a predetermined parameter \(T_{k}\). The update rule is given by \(R(T)=1-\{},\}\).

## 4 Theoretical Analysis and Solution

In this section, we put forward three main points of view:

1. Interactive teaching methods like co-teaching update parameters by reducing high loss values in the landscape. By actively involving two teachers, models in interactive framework learn from each other's strengths through a collaborative filtering mechanism and focus on minimizing loss examples.
2. Our core assumption is that the cleanliness of the data distribution serves as a latent variable, as it remains unknown within the training dataset. Based on this assumption, the interactive teaching process can be effectively exemplified as a unique type of parameter iteration within the EM framework. This perspective provides a probabilistic modeling-based explanation for the iteration and convergence of interactive teaching, such as co-teaching.

3. Concerning the local convergence in EM, we observe that a flatter loss landscape facilitates the optimization process in escaping local optima. Under such conditions, we incorporate the SAM to flatten the loss landscape and promote more global convergence within the interactive teaching paradigm. Building upon the exchange of loss information in a single interaction, an additional level of sharpness knowledge exchange containing gradient information has been introduced, which can be regarded as a form of dual-level interactive learning. This interactive teaching process, augmented by SAM, enables the acceptance of flatter high-probability regions from the peer network, thereby enhancing both the predictive performance and generalization capability of the model, as illustrated in Figure 1.

The essence of the SAM method lies in a more refined exploration of the gradient space, implicitly utilizing second-order information about the parameter space in the loss landscape. In experiments, it significantly improves generalization performance but incurs some unavoidable additional computations. The computational power consumption of the current algorithm complexity can be kept within a reasonable range and does not exponentially increase with the scale of data and models. This increase in complexity, compared to computational resources, is considered acceptable.

### Analysis of parameter update mechanism

The critical first stepWhile both co-teaching and SAM update network weights in two steps per iteration, they differ fundamentally in how they compute the first step. Specifically, in co-teaching, during the selection process of data points with small losses, the network is pre-trained and kept fixed. In SAM, the training data source domain remains unchanged, but perturbations are applied to the network weights. Within a set distance \(\) neighborhood, SAM seeks the direction of maximum offset \(\) that induces the greatest change in loss values compared to the original loss, i.e., \(*{arg\,max}_{\|\|_{2}}_{}( f_{+})-_{}(f_{})\). SAM not only seeks out points within a defined domain where the loss function undergoes the greatest change, exhibiting high curvature characteristics geometrically, but also aims to minimize the value of the loss function in regions of high curvature (sharp regions). The computation \(_{}(f_{})|_{+}\), implicitly depends on the Hessian properties of \(_{}(f_{})\), as the perturbation value \(\) is determined by the gradient \(_{}(f_{})\).

Loss landscape perspectiveIn the non-convex optimization of neural networks, the relationship between the magnitude of the loss value and its gradient is not clearly causal. Let's consider network \(f_{}\) and a set of samples \((x_{i},y_{i})\), and \(i=1,..,N\). The sum of the gradients of the loss function

Figure 1: Interactive teaching, Sharpness Reduction Interactive Teaching (SRIT), the plane in the figure represents the loss landscape, which gradually becomes flat during the iterative optimization process due to the receipt of flat gradient information cues from each other.

Figure 2: Loss landscape, we can broadly assume that in each iteration, a fixed cutting plane is used to remove the peaks with high loss values.

can be represented by the following Equation 6. The network \(g\) undergoes the same process:

\[(f_{},)=_{i=1}^{N}_{i}(f_{ }(x_{i}),y_{i})=(f_{}(x_{1}),y_{1})+...+ (f_{}(x_{N}),y_{N}),\] (6)

after receiving \(K\) data points \(_{g}=(g_{},)\) from network \(g_{}\), \((x_{j},y_{j})_{g},j=1,..,K\), we have:

\[(f_{},_{g}) =(f_{}(x_{1}),y_{1})+...+(f_{}(x_{j}),y_{j})+...+(f_{}(x_{K}),y_{K}),\] (7)

further, according to Equation 6 and 7, we have:

\[(f_{},_{g})}_{R(t):\#( )} =(f_{},_{g})-[(f_{ }(x_{K+1}),y_{K+1})+...+(f_{}(x_{N}),y_{N}) ],\] (8) \[=(f_{},_{g})-(f_{},_{g})}_{(1-R(t):\#()},\] (9)

where \(_{g}=_{g}_{g}=\{(x_{K+1},y_{K+1}),...,(x_{N}, y_{N})\}\), the symbol \(\#()\) represents the quantity of data point loss values. Therefore, for the update at time \(t+1\), gradients are computed on examples with low loss values:

\[_{t+1}^{f} =_{t}^{f}-(f_{},_{g}),\] (10) \[=_{t}^{f}-((f_{},_{ g})-(f_{},_{g}))=_{t}^{f}- ((f_{},_{g})-(f_{},_{g})).\] (11)

As illustrated by the gradient decomposition discussed above, it can be observed that co-teaching segments the loss landscape by reducing high loss values and only optimizes parameters on the low loss landscape. This concept is visually depicted in the schematic diagram presented in Figure 2.

### EM iterative process in typical interactive teaching

The analysis in Section 4.1 reveals that the interactive teaching utilizes low-loss samples from a peer network as prior knowledge, subsequently refining model parameters. This approach mirrors the iterative parameter estimation of the EM algorithm, commonly employed for probabilistic models with hidden variables. To elucidate the iterative steps and convergence, we adopt the EM framework, grounded in Maximum Likelihood Estimation. In typical interactive teaching, specifically co-teaching, we treat the cleanliness of training data as hidden variables, with \(_{f}\) and \(_{g}\) representing the parameters to be estimated for two structurally identical neural networks. The iterative convergence of the interactive teaching process within the EM framework is then characterized by the following proposition.

**Proposition 4.1**.: _Given the training dataset \(=\{X_{i}=(x_{i},y_{i})\}_{i=1}^{N}\), which contains noisy samples, and assuming the samples are independent, we define the hidden variable \(Z_{c}=1\) to indicate that the \(c\)-th sample is a cleaner sample, meaning it has a lower loss value compared to noisy data. \(Z=Z_{c}^{f} Z_{c}^{g}=\{Z_{c}\}_{c=1}^{K}\) represents the set of hidden variables for all samples, and the corresponding latent distribution is denoted as \(q(Z)\). The joint probability of \(p(X_{i},Z_{c}|_{f},_{g})\) is obtained by simultaneously updating neural networks \(f\) and \(g\) for \(X_{i}\) and \(Z_{c}\). The logarithm likelihood of the observed data \(\) has the following lower bound \(L\):_

\[L(_{f},_{g},q)_{i=1}^{N}_{c=1}^{K}[q(Z_{c}) ,Z_{c}|_{f},_{g})}{q(Z_{c})}],\] (12)

_the EM algorithm approximates the maximization of \( p(|_{f},_{g})\) by maximizing this lower bound \(L(_{f},_{g},q)\). Specifically, the EM iteration process for the interactive teaching paradigm is as follows:_

_E-step:_

\[Q(_{f},_{g}^{(t)}) =_{Z,_{f}^{(t)},_{g}}[  p(Z_{c}^{f},|_{f},_{g}^{(t)})],\] (13) \[Q(_{f}^{(t)},_{g}) =_{Z,_{f},_{g}^{(t)}}[  p(Z_{c}^{g},|_{f}^{(t)},_{g})],\] (14)_The subscript \(Z_{c}^{f}|,_{f}^{(t)},_{g}\) (or \(Z_{c}^{g}|,_{f},_{g}^{(t)}\)) of the expectation represents the corresponding set of low-loss samples selected by network \(f\) (or \(g\)) and is used to update network \(g\) (or \(f\))._

_M-step:_

\[_{f}^{(t+1)} =_{_{f}}Q(_{f}^{(t)},_{g}),\] (15) \[_{g}^{(t+1)} =_{_{g}}Q(_{f},_{g}^{(t)}).\] (16)

Please refer to Appendix A for the deduction process of the proposition.

_Remark 4.2_.: (1) In the E-step, we first calculate the distribution of the hidden variable \(p(Z_{c}^{f}|,_{f}^{(t)},_{g})\) using the current fixed parameters \(_{f}^{(t)}\) and the dataset \(\). In the context of interactive teaching, this involves selecting a specific proportion of clean samples to provide to the peer network. We then utilize this posterior distribution to compute the expectation of \( p(Z_{c}^{f},|_{f},_{g}^{(t)})\).

(2) In the M-step, \(_{f}^{(t+1)}=_{_{f}}Q(_{f}^{(t)},_{g})\) optimizes the parameters of the \(f\) network to maximize the logarithm likelihood function on the subset of samples \(Z_{c}^{g}\) selected by the \(g\) network. The network \(g\) follows the same process. And as we know, maximum likelihood estimation is equivalent to minimizing the empirical loss.

(3) The key distinction of interactive teaching from the conventional EM algorithm lies in one party receiving data information on the latent variable distribution from the other party. It not only allows for a priori determination of which important information needs to be preserved but also introduces a distribution from the counterpart, thereby increasing randomness and diversity to prevent overfitting. From a probabilistic modeling perspective, one party receives the high-probability region of clean samples from the other party, which effectively enhances the overall performance.

``` Input: Initial network parameters \(_{f_{0}},_{g_{0}}\), learning rate \(\), fixed parameter \(\), iteration counts \(T_{k}\) and \(T_{}\), maximum iteration count \(N_{}\), pre-defined constant \(\). Output: Updated network parameters \(_{f}\) and \(_{g}\).
1for\(T=1\)to\(T_{}\)do
2 Shuffle the training set \(\) (noisy dataset);
3for\(N=1\)to\(N_{}\)do
4 Sample a mini-batch \(}\) from \(\);
5 Dual-level optimization: The first level of loss information exchange.
6 Compute the loss of network \(f\) on \(}\) and obtain \(}_{f}\): \(}_{f}=_{^{}:|^{}|  R(T)|}|}(f,})\); //sample \(R(T)|}|\) small-loss instances;
7 Compute the loss of network \(g\) on \(}\) and obtain \(}_{g}\): \(}_{g}=_{^{}:|^{}|  R(T)|}|}(g,})\) //sample \(R(T)|}|\) small-loss instances;
8 Dual-level optimization : The second level of sharpness element exchange.
9 Update \(}(_{f})=_{}_{g}}(f_{g})}{\|_{}_{}_{g}}(f_{g})\|_{2}^{2}}\) and \(}(_{g})=_{}_{f}}(g_{g})}{\|_{}_{}_{f}}(g_{g})\|_{2}^{2}}\) ;
10 Compute the approximate gradient for network \(f\): \(_{f}=_{_{f}}(f_{g},}_{g})|_{_ {f}+}(_{f})}\);
11 Compute the approximate gradient for network \(g\): \(_{g}=_{_{g}}(g_{g},}_{f})|_{_ {g}+}(_{g})}\);
12 Update the network parameters of \(f\) using gradient descent: \(_{f}=_{f}-_{f}\);
13 Update the network parameters of \(g\) using gradient descent: \(_{g}=_{g}-_{g}\);
14
15 end for
16 Compute \(R(T)=1-\{},\}\).
17
18 end for ```

**Algorithm 1**Sharpness Reduction Interactive Teaching (SRIT)

### Sharpness Reduction Interactive Teaching (SRIT)

Since the convergence of the EM algorithm guarantees only local optima, while SAM can flatten the loss landscape and effectively alleviate local optima, favoring global optima, we incorporate SAM into the interactive teaching process, which referred as Sharpness Reduction Interactive Teaching (SRIT) to enhance performance and generalization. We conclude the proposed method as a novel dual-level sequential optimization process. For the first level, we start by screening the required low-loss dataset \(_{}}(f_{},})\). For the second level, we transfer the loss information to the counterpart model for SAM optimization: \(^{*}=_{}}_{}}(g_{ +},})\). Among the second level, we have two crucial steps: 1).The first step estimates the direction of the change in the network weights \(}(_{f})\) and \(}(_{g})\) based on the gradient information of the loss function, and then computes the new approximate gradients \(_{f}\) and \(_{g}\),

\[_{f}=_{_{f}}(f_{},}_{g})|_{ _{f}+}(_{f})},_{g}=_{_{g}} (g_{},}_{f})|_{_{g}+} (_{g})},\] (17)

where \(}(_{f})=_{}_{g}}(f_{})}{\|_{}_{}_{g}}(f_{})\|_{2}},}(_{g})= _{}_{f}}(g_{})}{ \|_{}_{}_{f}}(g_{})\| _{2}^{2}}\). 2). The second step involves updating the parameters of networks \(f\) and \(g\) based on the estimated gradients. The detailed algorithm procedure is shown in Algorithm 1.

In summary, it involves two levels of interaction: the first level is the exchange of loss information, and the second level is the exchange of sharpness knowledge containing gradient information. The first level filters out data that are harmful to the model, while the second level flattens the optimized loss landscape, making it less prone to local optima, thereby enhancing optimization and generalization performance.

## 5 Experiments

In this section, we will conduct experiments on two core baselines, co-teaching  and CNLCU . Co-teaching has served as a foundation for the development of various optimization techniques within this framework, and CNLCU is a cutting-edge research achievement. In the experiment, we use four NVIDIA RTX 6000 GPUs with 24GB of memory each.

   Noise type &  &  &  &  \\  Noise ratio & 20\% & 40\% & 20\% & 40\% & 20\% & 40\% & 20\% & 40\% \\   \\  Co-teaching & 97.50 & 94.96 & 95.49 & 91.54 & 96.61 & 92.76 & 95.90 & 91.23 \\  & \(\)0.06 & \(\)0.07 & \(\)0.11 & \(\)0.15 & \(\)0.06 & \(\)0.09 & \(\)0.05 & \(\)0.18 \\ SRIT & **99.42** & **99.19** & **99.35** & **98.14** & **99.47** & **98.75** & **99.43** & **98.03** \\  & \(\)**0.03** & \(\)**0.03** & \(\)**0.02** & \(\)**0.07** & \(\)**0.03** & \(\)**0.05** & \(\)**0.02** & \(\)**0.10** \\   \\  Co-teaching & 82.15 & 77.38 & 82.32 & 75.37 & 82.77 & 76.41 & 81.86 & 73.61 \\  & \(\)0.09 & \(\)0.15 & \(\)0.08 & \(\)0.14 & \(\)0.07 & \(\)0.17 & \(\)0.12 & \(\)0.25 \\ SRIT & **85.64** & **79.83** & **85.10** & **76.95** & **85.39** & **78.90** & **84.77** & **74.07** \\  & \(\)**0.15** & \(\)**0.12** & \(\)**0.20** & \(\)**0.17** & \(\)**0.18** & \(\)**0.12** & \(\)**0.19** & \(\)**0.25** \\   \\  Co-teaching & 50.21 & 42.40 & 48.27 & 34.74 & 50.32 & 38.78 & 49.74 & 38.57 \\  & \(\)0.23 & \(\)0.16 & \(\)0.11 & \(\)0.13 & \(\)0.19 & \(\)0.16 & \(\)0.18 & \(\)0.12 \\ SRIT & **59.66** & **50.57** & **57.16** & **35.82** & **59.07** & **42.27** & **59.66** & **40.36** \\  & \(\)**0.16** & \(\)**0.21** & \(\)**0.10** & \(\)**0.16** & \(\)**0.15** & \(\)**0.22** & \(\)**0.16** & \(\)**0.18** \\   \\  Co-teaching & 91.13 & 87.99 & 89.83 & 85.44 & 90.42 & 86.09 & 90.27 & 85.63 \\  & \(\)0.09 & \(\)0.09 & \(\)0.10 & \(\)0.12 & \(\)0.07 & \(\)0.09 & \(\)0.12 & \(\)0.13 \\ SRIT & **92.68** & **88.77** & **92.76** & **89.25** & **91.44** & **89.97** & **91.44** & **86.02** \\  & \(\)**0.10** & \(\)**0.13** & \(\)**0.09** & \(\)**0.11** & \(\)**0.01** & \(\)**0.09** & \(\)**0.09** & \(\)**0.21** \\   \\  Co-teaching & 91.83 & 88.72 & 91.49 & 85.09 & 92.16 & 87.51 & 91.26 & 86.33 \\  & \(\)0.08 & \(\)0.10 & \(\)0.10 & \(\)0.15 & \(\)0.10 & \(\)0.13 & \(\)0.18 & \(\)0.23 \\ SRIT & **94.95** & **93.06** & **94.34** & **89.37** & **94.66** & **91.56** & **94.45** & **90.50** \\  & \(\)**0.05** & \(\)**0.05** & \(\)**0.08** & \(\)**0.20** & \(\)**0.05** & \(\)**0.12** & \(\)**0.08** & \(\)**0.10** \\   

Table 1: Test accuracy (%) on five datasets. The best results are highlighted in bold.

### Experimental Settings

Datasets and type of noiseBased on previous research [16; 44; 40], we conduct experiments on five widely used datasets to effectively demonstrate the efficacy of the co-teaching algorithm. These datasets include MNIST , FMNIST , CIFAR10 , SVHN , and CIFAR100 . In co-teaching, we do not use validation dataset as in research . However, to maintain consistency with CNLCU, we use 90% of the training data and 10% as the validation set in CNLCU. In CNLCU, we conduct experiments on three representative datasets: MNIST, CIFAR10, and CIFAR100. We utilize various types of noise commonly used in multiple studies [28; 44; 39; 49; 40], including symmetric noise, tridiagonal noise, pairflip noise, and instance noise. To facilitate comparison with previous research , we set the noise rates in the datasets to 20% and 40% respectively. On the test dataset, we consider the average test accuracy of the last ten epochs as the final test accuracy, accompanied by a 95% confidence interval.

Models and hyper-parametersFor all datasets, we utilize a 9-layer CNN architecture  with dropout and batch normalization for the classification task. In co-teaching, for all datasets, we use the Adam optimizer with a momentum of 0.9, an initial learning rate of 0.001, and trained for 200 epochs. For \(R(T)=1-\{},\}\), where \(T_{k}\) is set to 10 by default . In SAM related optimization, such as SRIT and SRCNLCU, we use an SGD optimizer with an initial learning rate of 0.1, momentum of 0.9, weight decay of 0.0001, epochs of 200, and set \(\) to 0.05 . It has been pointed out by Andriushchenko and Flammarion  that the generalization performance of a model is influenced by the number of data points within a batch. Insufficient data quantity in a batch leads to inefficient utilization of GPU accelerators, while excessively large data quantity can result in suboptimal generalization. Therefore, taking reference from , we empirically set the batch size to 128 as an optimal choice.

### Experimental results on SRIT, Co-teaching, SRCNLCU and CNLCU

In this part, our experimental results are saved in Table 1 and 2. In Figure 3, we showcase the test performance on co-teaching and SRIT, more specific details are presented in Appendix B. Under all dataset and noise conditions, SRIT and SRCNLCU with SAM both consistently achieve significantly higher test accuracy compared to using co-teaching and CNLCU alone. This advantage is evident across different types of noise and noise ratios. Additionally, it is apparent from the figures presented in Appendix B that incorporating SAM into the training process demonstrates remarkable generalization capabilities, effectively mitigating overfitting.

Performance on Different DatasetsSRIT achieves exceptional performance on the MNIST dataset. For the CIFAR10 dataset, SRIT also performs well. This indicates that even on the more complex CIFAR10 dataset, employing SAM in interactive teaching (co-teaching) can significantly enhance

   Noise type &  &  &  &  \\  Noise ratio & 20\% & 40\% & 20\% & 40\% & 20\% & 40\% & 20\% & 40\% \\   \\    } & 98.70 & 98.24 & 98.44 & 97.37 & 98.89 & 97.92 & 98.74 & 97.42 \\  & \(\)0.06 & \(\)0.06 & \(\)0.19 & \(\)0.32 & \(\)0.15 & \(\)0.05 & \(\)0.16 & \(\)0.39 \\  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   \\    } & 83.03 & 78.33 & 83.39 & 73.40 & 82.52 & 74.79 & 81.93 & 73.58 \\  & \(\)0.47 & \(\)0.50 & \(\)0.68 & \(\)1.53 & \(\)0.71 & \(\)1.13 & \(\)0.25 & \(\)1.39 \\  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\  & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   \\    } & 46.27 & 42.05 & 43.25 & 30.79 & 45.02 & 35.24 & 45.02 & 36.17 \\  & \(\)0.38 & \(\)0.87 & \(\)0.75 & \(\)0.86 & \(\)1.06 & \(\)0.93 & \(\)1.07 & \(\)1.54 \\   & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 2: Test accuracy (%) on _MNIST,CIFAR10,CIFAR100_. The best results are highlighted in bold.

the model's generalization ability and accuracy. Similarly, on the FMNIST, SVHN, and CIFAR100 datasets, SRIT outperforms co-teaching in all noise scenarios. In SRCNLCU, nearly all experiments demonstrate a significant advantage. It should be noted that we selected the experimental results of CNLCU-H directly for comparison, without any bias.

From a macro-level perspective, co-teaching and CNLCU with SAM consistently outperformed co-teaching alone across all tested datasets and noise conditions. Whether it is the simple MNIST dataset or the complex CIFAR10 and CIFAR100 datasets, SRIT demonstrate strong robustness and high accuracy. The introduction of the sharpness reduction strategy effectively improves the performance of interactive teaching methods such as co-teaching and CNLCU, particularly when faced with high noise ratios and complex types of noise, resulting in even more significant enhancements.

## 6 Conclusions

In this paper, we first analyze how the low-loss selection of noisy data for interactive teaching reduces high-loss regions. Then, we introduce the EM framework to explore the interactive teaching mechanism, using the co-teaching algorithm as an example, which is a typical algorithm within the interactive teaching paradigm. We demonstrate that the iteration process of the typical interactive teaching algorithm follows the EM algorithm, ensuring its convergence. Since SAM makes the loss landscape flatter, it helps interactive teaching to escape local optima. Finally, based on sharpness reduction, we propose a dual-level interactive strategy to further enhance performance and generalization, validating its effectiveness through experiments. In the future, we will further investigate the strategy design of interactive teaching in intelligent agents and consider how to reduce the complexity of the SAM algorithm in the context of interactive teaching.