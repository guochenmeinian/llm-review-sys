# Unleashing Region Understanding in Intermediate Layers for MLLM-based Referring Expression Generation

Unleashing Region Understanding in Intermediate Layers for MLLM-based Referring Expression Generation

 Yaoyuan Liang\({}^{1}\)

Zhuojun Cai\({}^{1}\)

Equal contribution.

Jian Xu\({}^{1}\)

Guanbo Huang\({}^{1}\)

Yiran Wang\({}^{1}\)

Xiao Liang\({}^{1}\)

Jiahao Liu\({}^{2}\)

Ziran Li\({}^{2}\)

Jingang Wang\({}^{2}\)

Shao-Lun Huang\({}^{1}\)

\({}^{1}\)Tsinghua Shenzhen International Graduate School, Tsinghua University

\({}^{2}\)Meituan Inc.

###### Abstract

The Multi-modal Large Language Model (MLLM) based Referring Expression Generation (REG) task has gained increasing popularity, which aims to generate an unambiguous text description that applies to exactly one object or region in the image by leveraging foundation models. We empirically found that there exists a potential trade-off between the detailedness and the correctness of the descriptions for the referring objects. On the one hand, generating sentences with more details is usually required in order to provide more precise object descriptions. On the other hand, complicated sentences could easily increase the probability of hallucinations. To address this issue, we propose a training-free framework, named as "unleash-then-eliminate", which first elicits the latent information in the intermediate layers, and then adopts a cycle-consistency-based decoding method to alleviate the production of hallucinations. Furthermore, to reduce the computational load of cycle-consistency-based decoding, we devise a Probing-based Importance Estimation method to statistically estimate the importance weights of intermediate layers within a subset. These importance weights are then incorporated into the decoding process over the entire dataset, intervening in the next token prediction from intermediate layers. Extensive experiments conducted on the RefCOCOg and PHD benchmarks show that our proposed framework could outperform existing methods on both semantic and hallucination-related metrics. Code will be made available in https://github.com/Glupayy/unleash-eliminate.

## 1 Introduction

Referring expression generation (REG)  is a task to generate an unambiguous text description that applies to exactly one appointed object or region in the image. A good expression should be distinguishable enough to ensure that the listener can identify the unique target among various objects within the same image. With the great success achieved by large language models (LLMs), multi-modal large language models (MLLMs)  have been introduced to perform this task and become increasingly popular in the research community. Some representative works  conduct visual instruction tuning on specialized region-involved multi-modal corpus and successfully empower MLLMs with the ability of region-level understanding.

Though certain progress has been made, MLLMs themselves suffer from object hallucination . Research suggests that the mechanism behind MLLMs' hallucinations could be related to the over-reliance on prior knowledge of LLMs rather than the multi-modal context provided by the input . Therefore, MLLM-based REG models naturally inherit the aforementioned hallucination issues. Additionally, a further complication arises in the context of region-level understanding, where models are required to generate precise and identifiable descriptions for specific regions. To achieve that, the MLLMs sometimes have to make use of the surroundings for reference while effectively avoiding out-of-region information distorting the description of the target object, e.g. incorrectly attributing characteristics of other objects to the targeted region (Figure 7 in appendix). This requirement exacerbates the issue of attribute-level hallucinations . In this paper, we aim to explore this potential trade-off between the detailed description and accurate targeting of referring objects in MLLM-based REG task. To be specific, providing precise object descriptions necessitates generating sentences with more details, which results in longer sentences. Meanwhile, the text with increased granularity (length) is more likely to contain inaccurate or spurious information, commonly defined as "hallucinations." Table 1 shows an example of quantitative analysis.

To address the trade-off between information richness and reliability, we propose a novel approach called "unleash-then-eliminate," as depicted in Figure 1. We observed that the alignment of region-level multi-modal information does not maintain a monotonic progression during inter-layer transitions. Moreover, when multi-modal hidden states are projected into the language space using the language head, the intermediate layers sometimes hold more descriptive region information than the final layer. These observations (Section 3.2) imply that the most suitable layer for each referred region should not be solely confined to the final layer. Accordingly, we adopt contrastive decoding  to unleash the object information contained in the intermediate layers. To eliminate unsuitable candidate outputs, we leverage the dual task of REG: Referring expression segmentation (RES) , which aims to segment a target object mask from the entire image given a sentence describing the object. Ideally, for the same object, the region input (formed as a mask) for the REG task and the mask output from the RES task should exhibit cycle consistency. Based on this insight, we propose a cycle-consistency-based decoding method, which enables us to choose among multiple outputs based on their descriptive quality thus reducing hallucinations while maintaining the richness of the output sentences. Furthermore, considering the need to diminish the computational load of RES, we develop a hybrid layer importance measurement strategy to select the best layer for each token during the next word prediction. This strategy leverages both the layer-wise prior importance estimated over probing subset, and the Jensen-Shannon divergence  between the logits of each candidate layer and the last layer. With the layer-wise prior importance, the MLLM-based REG model maintains promising performance in reducing hallucinations and enhancing the granularity of the generated sentences, even without the assistance of RES model. Extensive experiments conducted on the RefCOCOg  and PHD  benchmark demonstrate that our proposed framework surpasses existing methods on both semantic and hallucination-related metrics.

## 2 Related works

**Region-level understanding in Multimodal Large Language Models.** Significant progress has been made in unleashing the region-level understanding ability in MLLMs . To

Figure 1: Illustration of our method. (a) Given an image and a mask appointed to the target object, we first unleash the descriptive regional information of the middle layers and gain various candidate captions. These outputs are sent to a RES model that serves as a “listener” and the “listener” eliminates the inaccurate candidates. (b) Our proposed strategy to diminish the computational load of RES. First estimate the layer prior importance on a probe set with RES, then leverage it for the RES-free next token prediction.

incorporate region-level information into sequence generation of MLLMs, some approaches [6; 52] integrate bounding box coordinates into the language input in the form of natural language prompts. Ferret  proposes a spatial-aware visual sampler that enables the arbitrary shapes of visual prompts. The current proposed Osype  unlocked the capability of pixel understanding, alleviating the influence of irrelevant information in the visual prompt inputs. These methods have propelled the REG task into the era of MLLMs. Considering that MLLMs incorporate extensive knowledge from unimodal and multimodal pre-trained corpora, there is a potential for the REG task to leverage this inherent knowledge within the models to generate more specific and detailed expressions without additional training, thus more effectively addressing real-world applications [21; 39; 41].

**Decoding strategies to mitigate hallucination in Large Language Models.** Large language models are pre-trained on unlabeled corpora to acquire extensive world knowledge and subsequently undergo post-training to learn to follow instructions  and align with human preferences . This systematic pre- and post-training pipeline makes them powerful at solving a wide range of NLP tasks [16; 36; 40; 43]. However, some studies indicate that they may fail to accurately assess their own knowledge  and often exhibit overconfidence in their responses , which results in hallucinations . To mitigate these issues, recent research [5; 8; 20] proposes inference-time decoding strategies for trained LLMs to find latent knowledge inside the internal activations without additional training. C. Burns _et al._ introduce a Contrast-Consistent Search (CCS) algorithm to identify a direction of truth in the activation space of LLMs that remains consistent across negations, thereby reducing generated errors. Based on the discovery of CCS, TTI  does deep into attention heads and suggests shifting model activations alongside factuality-related heads during inference to help reduce hallucinations. Besides "finding the direction of truth," DoLa  proposes contrastive decoding by comparing the differences in logits between the projections of later and earlier layers to better surface factual knowledge and reduce the generation of incorrect facts. In line with the motivations of [5; 20], our investigation uncovers that well-trained MLLMs' intermediate layers differ in multi-modal alignment and region-level understanding capabilities. These observations inspire us to devise an inference-time decoding strategy that combines latent knowledge from multiple layers (with prior importance) to alleviate hallucinations.

**Hallucination in Multi-modal Large Language Models.** In the realm of MLLMs, "hallucination" typically refers to "object hallucination," where the models generate plausible outputs containing objects that are either absent from or mismatched with the images [15; 19; 24; 38; 50], and is commonly categorized into three types: category, attribute and relation hallucinations [3; 49]. Some efforts based on instruction tuning have been made to mitigate this issue in MLLMs. LRV-Instruction  introduces a dataset with positive instructions and unique negative prompts with different semantic levels to better align responses with image content. HACL  explores the vision-language embedding space, using contrastive learning to separate non-hallucinated from hallucinated texts. Without instruction tuning, Woodpecker  offers a training-free pipeline for hallucination correction, using expert models to enrich image context and ensuring each phase is interpretable by a step-by-step correction process. In another line of work, some efforts have sought new decoding strategies to avoid relying on extensive additional data and training: Opera  tackles the partial over-trust issue in decoding by applying a penalty to the model logits during beam-search decoding. VCD  links object hallucinations to biases and language priors, contrasting outputs from distorted and original visuals to ensure consistent generation. Compared to existing studies, our method initially enriches region-level context from intermediate layers rather than external expert models or knowledge base and provides a multi-layer ensembling solution to mitigate hallucinations.

## 3 Method

### Preliminary

Leveraging the nuanced language representation capabilities inherent in multi-modal large language models, recent investigations have unlocked the REG [6; 37; 52; 55] and RES [18; 37] capabilities of MLLMs. To maintain clarity and conciseness, we have omitted the discussion on instruction tuning and assume that the described tasks are well-instructed by specific prompts. In this work, we utilize a "mask" as the region prompt.

**Referring expression generation.** The MLLM-based REG model is typically structured around three principal components: a visual encoder (e.g., CLIP  with a linear adapter), a region-encoder,and an LLM base (e.g., LLaMA  or Vicuna ). Given an image \(I\), the visual encoder first extracts the visual information, then the linear adapter projects it into \(I_{f}^{HW C}\), where \(HW\) denotes the flattened visual token length and \(C\) denotes the hidden state dimension of LLM base. A referred region \(M\) (presented as a mask) is encoded as \(M_{f}^{Q C}\) by region encoder (e.g., a CNN-based extractor  or an ROI pooling layer [37; 57]), where \(Q\) denotes the length of encoded region prompt tokens. Taking the visual feature \(I_{f}\), regional feature \(M_{f}\), and an embedded instruction text \(X_{f}^{L C}\) as input, where \(L\) represents the length of the instruction in tokens, the model concatenates them and forms a multi-modal input sequence \(S^{(HW+Q+L) C}\).

Regarding the core architecture of the LLM base, the multi-modal sequence \(S\) is successively processed by the \(N\) stacked transformer layers. Eventually, an affine layer \(()\) serves as a language model head to predict the probability of the next token \(y_{t}\) over the vocabulary set \(\). The logits for the token \(y_{t}\), given the sequence \(S\) and all preceding tokens \(y_{<t}\), are computed as follows:

\[_{N}(y_{t}|S,y_{<t})=(h_{t}^{(N)}), y_{t},\] (1)

where \(h_{t}^{(N)}\) denotes the hidden state of the last transformer layer. The probability of the next token \(y_{t}\) is then given by:

\[p(y_{t}|S,y_{<t})=_{N}(y_{t}|S,y_{<t}) , y_{t}.\] (2)

Through this process, the model autoregressively generates the output text \(Y\) as the region description. For simplicity, we use \(p(y_{t}|y_{<t})\) to represent \(p(y_{t}|S,y_{<t})\), and \(_{N}(y_{t}|y_{<t})\) to represent \(_{N}(y_{t}|S,y_{<t})\) in the following.

**Referring expression segmentation.** Recent advances in MLLM-based RES models [18; 37] largely employ a similar MLLM architecture (e.g., LLaVA ) as used in the REG models, with the distinction that its input contains a description targeted at a specific region, while its output is a mask that can cover the described object.

A widely adopted strategy [17; 18; 37] incorporates a [SEG] token, enabling the model to identify the [SEG] token in the output sequence as a cue for the presence of a segmentation target. A specialized MLP head \(\) processes the output embedding of the [SEG] token \(h_{seg}^{1 C}\), mapping it into the prompt space of the segmentation fundamental model (e.g., SAM ), represented as \(_{seg}=(h_{seg})\). The segmentation model then decodes the target mask \(M_{s}\) from the query token \(_{seg}\) and provides its confidence score \(CF\).

### The intermediate layer contains descriptive information

This section focuses on our observations of intermediate layers, attempting to uncover the latent descriptive information. We adopted a region understanding model Osprey-7b  with \(N=32\) layers as REG model, and GLaMM  as RES model by default.

**Each layer has different generation tendency.** To reveal the latent information, we adopt the early-exit strategy on the REG model to generate a series of output sequences by applying the language model head (an affine layer) to the hidden states of each layer. As illustrated in Figure 2, the sequences from the early layers (layers 1 to 10) manifest as nonsensical strings of characters, indicating the suboptimal alignment between the hidden representation of shallow layers and the ultimate vocabulary space of MLLM. Interestingly, among the middle layers (about layers 20 to 25), the model begins to output sentences with semantic meaning and gradually some region-specific expressions appear. Compared with the output of the last layer, these sentences with richer semantic information can sometimes provide more discriminative descriptions for the referred object, e.g. indicating the related position between the target object and others, and/or containing high granularity of attributes. The uniqueness and descriptiveness of expressions given by the middle layers are strongly related to the objective of REG, thus the latent features of intermediate layers have notable potential to enhance the unambiguity in MLLM-based REG.

**Potential of intermediate layers.** The above observations demonstrate that different layers' understanding of the region context varies. We attempted to visualize the region-aware comprehension capabilities among the layers through two approaches. (a) With the assistance of the RES model: we randomly extracted \(K=2000\) samples from the RefCOCOg training set to form the triplets \((,,)\), which corresponds to the entire images \(\), the target regions represented by masks \(\), and the descriptions of regions \(\). \((,)\) are sent into an MLLM-based RES model, to harvest the projected features of [SEG] token \(_{seg}\). Subsequently, \((,)\) are input into the REG model, and the hidden states of the last token of each layer \(\{h_{i}\}_{i=1}^{N}\) are obtained. Inspired by FID metric  and recent investigations on the latent space communication [30; 32], we first performed PCA dimensionality reduction to project both features into the same dimension, then treat the dimension-reduced [SEG] features as the anchor to calculate the Wasserstein-2 distances [13; 44; 45] between [SEG] and each intermediate hidden states. This allowed us to estimate the relative region understanding ability of each layer for the given multi-modal context of a certain object. We then calculate the frequency with which each layer had the smallest Wasserstein-2 distance to the [SEG] token. As depicted in the right of Figure 2 (orange), except for the final layer, the intermediate layers also have the potential to contain better latent information for a more precise region-related description. (b) Solely within the REG model: we investigated the multi-modal alignment process in region-level context across intermediate layers by calculating the Wasserstein-2 distance between each layer's region-encoded token [mask] and the last language token. Results are reported in Figure 2 (blue). These analyses within a well-trained MLLM show that the tokens of different modalities do not approach monotonically during inter-layer transitions. Hence we should give more chances to the intermediate layers for better region-level understanding. Detailed information can be found in the Appendix C.

### Unleash then eliminate decoding strategy

To enhance the granularity of region-level descriptions without introducing excessive hallucinations, we propose a method that integrates contrastive decoding with cycle consistency-based ranking to screen out appropriate descriptions for the interested regions (Section 3.3.1 and 3.3.2). This approach enables us to specifically leverage the commonly overlooked latent information contained in intermediate layers and ensures the identifiable description through caption quality estimation. Under the concerns of computation efficiency, we further develop a decoding strategy to reduce the operations of cycle ranking through hybrid layer importance measurement (Section 3.3.3). It involves two kinds of layer importance calculation to influence the selection probability of candidate layers during each word prediction step. The harvest prior importance weights can be directly applied to the decoding process of the original MLLM, mitigating the hallucinations. The following subsections provide further details.

#### 3.3.1 Unleash intermediate information by contrastive decoding

As depicted in Figure 2, the manifestation of region-aware information differs across layers. To underscore descriptions related to specific regions--evident in the intermediate layers but faded in the final layer, we adopt a contrastive decoding approach [8; 22] by subtracting the log probabilities of the next token produced by the intermediate layer from those of the final layer. The resulting distribution is defined as the contrastive decoding logits of specific subractor layers. These logits instead of originally the logits from the final layer are used for generating the subsequent token. Concretely, given a set of candidate layer indices \(J=\{1,,n\}\), the probability of token \(y_{t}\) for layer \(j J\) is:

\[p_{con_{j}}(y_{t}|y_{<t})=_ {N}(y_{t}|y_{<t})-_{j}(y_{t}|y_{<t})&y_{t}_{head},\\ 0&,\] (3)

Figure 2: Different layers’ understanding of the region context varies, where early layers generate rubbish, middle layers tend to generate descriptive text with higher granularity, and the final layers tend to predict shorter and more precise text. The right part shows the frequencies with which the hidden state of each layer had the smallest Wasserstein-2 distance to the [SEG] token (in orange), and the inter-layer transitions of region-level multi-modal alignment (in blue).

where \(_{j}(y_{t}|y_{<t})=(h_{t}^{(j)})\), \(_{head}(y_{t})=\{y_{i}:p(y_{i}|y_{<t})_{w }p(w|y_{<t})\}\), \(\) is a cutoff hyperparameter that truncates the next token distribution \(p(y_{t}|y_{<t})\) of the final layer. Following the previous works [8; 22], we set \(=0.1\) in the implementation.

After contrastive decoding, each of the intermediate layers in the candidate set suggests a probability for predicting the next token \(y_{t}\). Finally, we harvest a sentence set \(A=\{a_{1},a_{2},...,a_{n}\}\) whose size equals to the size of candidate layers.

#### 3.3.2 Cycle-consistency-based intermediate sentence quality ranking

Consider the formed triplet (\(\), \(\), \(\)) in Section 3.2, where \(\) serves as the global contextual background of a region, \(\) and \(\) respectively represent two modalities of the same object. For a pair of ideal REG and RES models, it is anticipated that \(\) and \(\) can be interconverted losslessly during a cyclic operation of these two models. This implies that, due to the cycle consistency between the two modalities of the same object, feeding the output of the REG model into the RES model should yield a mask consistent with the input to the REG. If the output generated from the candidate layer is overly ambiguous or polluted by hallucinations, the RES model may struggle with accurately locating the target object against the background. Based on these assumptions and observations, we utilize RES model  to estimate the region understanding performance of the captions generated by the candidate layers, allowing us to rank these candidates effectively.

Figure 3 illustrates the pipeline of cycle-consistency-based quality ranking. The input image \(I\) and the referred region (represented as a mask) \(M\) are processed by the REG model, which continuously extracts and aligns features across successive layers for the multi-modal context. After the information elicitation of intermediate layers, we harvest a set of sequence \(A=\{a_{1},a_{2},...,a_{n}\}\). Each sequence in \(A\), paired with the image \(I\), forms an input pair \((I,a_{j})\) to feed into the RES model. The RES model then segments out the corresponding mask \(M_{j}^{}\) for each input pair.

We evaluate the quality of each layer's sentences by calculating the Intersection over Union (IoU) between \(M\) and \(M_{j}^{}\):

\[_{j}=CF_{j}^{}|}{|M M_{j}^{ }|},\] (4)

where \(CF_{j}\) refers to the output of IoU score head within the segmentation foundation model (e.g. SAM ), which can be interpreted as a confidence score of the generated mask. Subsequently, the candidate sentences from each layer are ranked by the \(_{j}\). For each sample, the \(a_{j}\) with the highest \(_{j}\) is selected as the final sentence, and its layer is deemed the best candidate layer.

Figure 3: First, we conduct contrastive decoding by subtracting the log probabilities produced by the intermediate layer from those of the final layer. Then, each of the intermediate layers in the candidate subset suggests a probability for predicting the next token. Finally, RES model is used to estimate the performance of the captions by calculating the Intersection over Union (IoU) between MASK and \(M_{j}^{}\), ranking these candidates effectively.

#### 3.3.3 Hybrid layer importance measurement

Although our cycle-consistency-based candidate ranking process improves the generation quality, it introduces additional computational load from the RES model compared to the original decoding method, significantly affecting the per-sample decoding speed. To alleviate this issue, we propose a simple yet effective strategy called _Probing-based Importance Estimation_ to speed up the decoding process. This strategy involves frequency counting of each candidate layer being the optimal layer based on their performance within a probing subset. With a subset containing \(m\) samples, the specifics of this calculation are outlined at Algorithm 1. The estimated weight \(\) is then served as prior knowledge that reflects the candidate layers' importance and is then utilized over the entire dataset in the decoding process, intervening in the next-word prediction.

Furthermore, inspired by the success of distance-guided layer selection in LLMs , we also apply this metric as a second guidance. Concretely, we first calculate the distance between the next-token probability of the final layer and each candidate layer at the current decoding step, then the calculated values are normalized across candidate layers as follows,

\[d_{j}=}{_{i=1}^{n}D_{i}},\] (5)

where \(D_{j}=(p||p_{con_{j}})\) denotes the J-S divergence between the next-token probability of the final layer \(p\) and the layer \(p_{con_{j}}\). Finally, the hybrid layer importance is obtained by adding up the probing-based prior and sample-wise distance followed by a softmax normalization:

\[}=(+),\] (6)

where \(\) is a vector of normalized divergence values across the candidate layers. We then sample from the probability distribution \(}\) to select one layer among candidates to predict the next token at each decoding step, till the generation finishes.

Overall, this decoding approach first estimates a prior layer-wise importance weight from a small subset and then applies this distribution to contrastive decoding, effectively improving decoding efficiency while preserving the ability to mitigate hallucinations. In addition, our experiments (Table 3) also show that the prior importance \(\) calculated from one (probing) dataset could be directly transferred to another dataset with similar image domain for reducing the hallucinations. This strong transferability further illuminates a new promising application scenario where the historic estimate could serve as a cold-start for inference in new environments when the probing dataset is not available.

```
1:Input:\(^{m n}\)\(\)\(m\): Number of subset samples; \(n\): Number of candidate layers
2:Output:\(^{n}\), \(_{j=1}^{n}q_{j}=1\)\(\) Importance weight of each candidate layer
3:Initialize \(^{n}\)\(\) counts of times each layer has the maximum score
4:for\(j 1\) to \(n\)do
5:\(count_{j}=_{i=1}^{m}1\) {\(j=_{j J}_{i,j}\)}
6:\(q_{j}}{m}\)
7:return\(\) ```

**Algorithm 1** Layer Prior Importance Calculation

## 4 Experiments

### Datasets and metrics

**RefCOCOg.** The RefCOCOg  dataset is a classical benchmark for referring expression generation, which contains 85,474 expressions for 54,822 objects in 26,711 images. Expressions in RefCOCOg are annotated on Amazon Mechanical Turk in a non-competitive way and tend to be longer (8.43 words per sentence on average) and more expressive than RefCOCO  and RefCOCO+ . In the MLLM-empowered REG task, the relatively short ground truth cannot fully cover the expression space of the sentences generated by the MLLM at evaluation. Therefore, our experiments focus on the METEOR metric as it is more comprehensive and flexible, allowing for a more nuanced recognition of linguistic variations.

**CHAIR Evaluation on Hallucinations**. The Caption Hallucination Assessment with Image Relevance (CHAIR) metric  is commonly used to evaluate object hallucinations that occur in image description tasks. It comprises two distinct assessment dimensions, including CHAIR\({}_{S}\) that calculates on sentence-level and CHAIR\({}_{I}\) that calculates on a more granular object-level. We observe that CHAIR only counts hallucinated objects for each "central object", which means that if the model wants to enrich the semantic information and generate new tokens, it will face the risk of increasing hallucinations compared to the shorter-sentence models. This undermines the comparability of this metric across sentences of varying lengths. Hence we propose normalized CHAIR (nCHAIR) based on CHAIR to conduct a fair comparison between sentences of different lengths. The calculation of nCHAIR\({}_{S}\) is specified as the following formula, with nCHAIR\({}_{I}\) calculated similarly:

\[_{S}=\}|}{|\{\}||\{\}|}.\] (7)

**Prompted Visual Hallucination Evaluation Benchmark (PHD)**. This benchmark  focuses on the four major types of hallucination faced by MLLMs, namely Object hallucination, Attribute hallucination, Multi-modal conflicting hallucination, and Counter-common-sense hallucination. It evaluates and explores the hallucinations through comprehensive prompt-based tasks, which also helps identify the causes of these hallucinations. While this benchmark does not explicitly evaluate region-level hallucinations, its detailed evaluating strategies for object attribute and position are closely related to region-level understanding, allowing it to effectively indicate regional-level hallucinations.

### Main result on referring expression generation

**Baseline region-level MLLM model and decoding method.** Table 1 presents the performance comparison of semantic quality and hallucination evaluation on RefCOCOg dataset, with METEOR and CHAIR metrics. Recent research  has revealed that the temperature parameter \(t\) has a notable effect on the hallucination of generated sentences. In light of this, we included an analysis of the baseline region-level MLLM model, Osprey-7b , performing at both lower (\(t=0.2\)) and higher (\(t=0.9\)) temperature settings. Meanwhile, we also compared a baseline decoding method, DoLa , which demonstrated that leveraging contrastive decoding in vanilla LLMs can enhance the authenticity of the generated results. In comparison to the Osprey-7b 1, the sentences generated by DoLa  demonstrated better performance on METEOR and nCHAIR metrics.

**Performance of cycle-consistency-based sentence quality ranking**. As introduced in Section 3.3.2, to balance the trade-off between information granularity and accuracy, we first unleashed the region description of intermediate layers by contrastive decoding, then filtered out the inaccurate sentences by cycle-consistency-based quality ranking. For each sample in RefCOCOg, we evaluated the best sentence generated by the best candidate layer. The result is reported in the fifth row of Table 1. We observed that our method not only gains more descriptive sentences but also demonstrates a reduction in the hallucination metric (measured in terms of nCHAIR) compared to Osprey-7b and DoLa. The examples of generation results are listed in Figure 4.

**Text generation via hybrid layer importance measurement.** In Section 3.3.3, we proposed a method that effectively reduces the computational overhead of the RES scoring model. In our experiment, we divided all 32 intermediate layers (including the embedding layer) into four consecutive groups (detailed in Section 4.3) and calculated the relative importance of the layers within each group

   Model & METEOR\(\) & CHAIR\({}_{S}\) & CHAIR\({}_{I}\) \(\) & Recall\(\) & Len & nCHAIR\({}_{S}\) & nCHAIR\({}_{I}\)\(\) \\  Osprey-7b (\(t\)=0.2) & 162.0 & **23.41** & **20.81** & 0.7631 & 7.15 & 3.2741 & 2.9105 \\ Osprey-7b (\(t\)=0.9) & 140.0 & 27.90 & 24.12 & 0.7514 & 8.11 & 3.4402 & 2.9741 \\ DoLa & 168.0 & 43.44 & 31.78 & 0.8196 & 23.07 & 1.8830 & 1.3775 \\ Ours (1/8) & 172.0 & 42.25 & 30.95 & 0.8211 & 22.96 & 1.8406 & 1.3484 \\ Ours (full-R) & **173.0** & 42.40 & 31.20 & **0.8237** & 23.16 & **1.8307** & **1.3472** \\   

Table 1: Comparison of generation and hallucination performance on RefCOCOg. \(t\) denotes the temperature parameter. “1/8” denotes using 1/8 samples of the total dataset to estimate the layer prior importance. “full-R” denotes quality ranking on the whole dataset.

separately. Figure 5 depicts the resulting layer importance weights of four different ranges. The result reveals that layer importance is not uniform across candidate layers and also varies among different groups. We applied the importance weights estimated from 1/8 subset to the decoding process and listed the first group's result in the fourth row of Table 1. Notably, in comparison to full-set sentence-by-sentence quality ranking, this probing-based decoding method offers comparable performance with improved efficiency, demonstrating the effectiveness of our statistical layer importance estimation.

### Performance of different candidate layer groups

As aforementioned in Section 3.2, it was observed that different layers have distinct generation preferences for the same sample, inspiring our further exploration in quantitative experiments. The first 32 layers (where layer 0 is the embedding layer) of the Osprey-7b model were organized into four groups: , , , and . In each experiment, one group was selected as the candidate layer set and contrasted with the last layer to generate the candidate sentences, followed by cycle-consistency-based ranking to choose the best. Table 2 indicates that the first group exhibits the best performance in METEOR and nCHAIR\({}_{I}\) metrics. It is also noticeable that there are considerable performance discrepancies between the different groups, with a general trend of semantic quality declining as the depth of the layer increases (after contrastive decoding). However, we found that although the fourth group had the lowest METEOR score, its nCHAIR\({}_{S}\) was slightly better than that of the first group. This observation suggests that a well-trained MLLM exhibits variations in latent knowledge across its zones, leading to differences in generation performance.

   Bucket & METEOR\(\) & CHAIR\({}_{S}\) & CHAIR\({}_{I}\) & Recall\(\) & Len & nCHAIR\({}_{S}\) & nCHAIR\({}_{I}\) \\ 
1st (0-7) & **173.0** & 42.40 & 31.20 & **0.8237** & 23.16 & 1.8307 & **1.3472** \\
2nd (8-15) & 167.0 & 40.89 & 30.49 & 0.8236 & 21.58 & 1.8948 & 1.4129 \\
3rd (16-23) & 146.0 & 37.36 & 30.07 & 0.7797 & 18.96 & 1.9705 & 1.5860 \\
4th (24-31) & 127.0 & **31.50** & **27.52** & 0.7357 & 17.35 & **1.8156** & 1.5862 \\   

Table 2: The impact of different candidate layer groups (buckets) on the performance of RefCOCOg dataset.

Figure 4: The visualization comparison of generations between Osprey-7b , DoLa  and ours. Osprey-7b’s outputs are quite brief and omit visual details of the referred objects. The generations from DoLa are more extensive but are accompanied by hallucinations. In contrast, our method increases descriptive information and curtails the generation of hallucinations.

Figure 5: The layer prior importance measured by our method of different groups. It is observable that the weight distributions of the 1/8 subset and the full dataset have similar trends.

### Transferability of layer prior importance weights

From the preceding experiments, we discovered that using layer importance in the next token prediction enhances the generated output's quality of the same dataset. Additionally, we also noticed that the determined layer prior importance can be smoothly transferred to a different dataset (different prompts) sharing a similar image domain to reduce the hallucinatory outputs. Specifically, we applied the layer importance ( group) calculated on the RefCOCOg dataset directly to the PHD dataset, where the image inputs also originate from MSCOCO , and decoded the output using the method described in Section 3.3.3. Given the absence of any region prompt in the PHD dataset, we applied a zero mask to the region encoder. The comparative results are shown in Table 3. We observe that our approach enhances the model's understanding across most tasks, which indicates that without the additional training, the estimated layer prior importance could serve as a cold-start for inference in new environments when the probing dataset is not available, helping reduce the occurrence of hallucinations during the decoding.

## 5 Conclusion

Our research on the MLLM-based Referring Expression Generation (REG) task explored a potential trade-off between information richness and reliability of the intermediate generation results. We introduced a "unleash-then-eliminate" approach that utilizes latent information from intermediate layers and employs a cycle-consistency-based decoding method to reduce hallucinations. Our method outperforms existing techniques, confirming its efficacy for enhancing REG task performance.