# Homology Consistency Constrained Efficient Tuning for Vision-Language Models

Huatian Zhang, Lei Zhang, Yongdong Zhang, Zhendong Mao

University of Science and Technology of China

huatianzhang@mail.ustc.edu.cn, {leizh23,zhyd73,zdmao}@ustc.edu.cn

Corresponding author.

###### Abstract

Efficient transfer learning has shown remarkable performance in tuning large-scale vision-language models (VLMs) toward downstream tasks with limited data resources. The key challenge of efficient transfer lies in adjusting image-text alignment to be task-specific while preserving pre-trained general knowledge. However, existing methods adjust image-text alignment merely on a set of observed samples, _e.g._, data set and external knowledge base, which cannot guarantee to keep the correspondence of general concepts between image and text latent manifolds without being disrupted and thereby a weak generalization of the adjusted alignment. In this work, we propose a Homology Consistency (HC) constraint for efficient transfer on VLMs, which explicitly constrains the correspondence of image and text latent manifolds through structural equivalence based on persistent homology in downstream tuning. Specifically, we build simplicial complex on the top of data to mimic the topology of latent manifolds, then track the persistence of the homology classes of topological features across multiple scales, and guide the directions of persistence tracks in image and text manifolds to coincide each other, with a deviating perturbation additionally. For practical application, we tailor the implementation of our proposed HC constraint for two main paradigms of adapter tuning. Extensive experiments on few-shot learning over 11 datasets and domain generalization demonstrate the effectiveness and robustness of our method.

## 1 Introduction

Large-scale vision-language models (VLMs) such as CLIP  and ALIGN  trained on web-scale data have learned broad visual concepts and demonstrated promising generalization capability on a wide range of downstream tasks, such as classification [3; 4], detection [5; 6] and segmentation [7; 8]. In transferring to downstream tasks with limited data resources, the conventional full fine-tuning on VLMs often forgets the general knowledge learned in pre-training and falls into overfitting. To mitigate this, how to efficiently transfer the knowledge from pre-trained VLMs to downstream tasks in a low-data regime has been intensively studied.

To possess both task-specific knowledge exploration and general knowledge preservation, efficient transfer learning proposes to adapt VLMs to fit downstream tasks by tuning a few parameters, which mainly exists in two paradigms: prompt tuning and adapter tuning. Prompt tuning methods adapt VLMs toward downstream tasks by introducing learnable prompts on the input side. Topics in which branch include the configuration of learnable prompts [9; 10; 11; 12; 13] and injecting semantic priors, such as external knowledge [14; 15], category distribution  or visual diversity [17; 18], in tuning. As a promising alternative, adapter tuning inserts a learnable lightweight adapter into the frozen pre-trained VLMs on the output side and the insertion manner allows modifying flexibly. By residual blending, CLIP-Adapter  tuned the image or text embeddings by appending a learnable bottleneck layerto the frozen encoder. TaskRes  added learnable parameters as prior-independent residuals to text embeddings. Another line is based on key-value cache model. Tip-Adapter  proposed to construct an adapter with training images as keys and one-hot label encodings as values for image recognition. Some work further enhanced the cache model by discriminative prior refinement  or knowledge augmentation . For efficient transfer, existing methods mainly focus on how to configure tunable parameters or the leverage of external prior knowledge in tuning.

The essence of task-specific tuning on VLMs is to adjust the semantic alignment of image and text latent manifolds to fit downstream tasks. In this view, efficient transfer learning aims to establish new semantic alignments while keeping the correspondence of pre-trained general concepts between image and text latent manifolds from being corrupted. This correspondence stems from the equivalence of semantics between the two manifolds. However, existing methods adjust image-text alignment toward downstream tasks on a set of observed samples from the latent manifolds. The discrete samples are incapable of adequately capturing the underlying structure of manifolds. The lack of perspective on latent manifolds in alignment adjusting risks devolving the desired manifold equivalence into localized closeness on the observed data, particularly in a low-data regime, which causes the unguaranteed generalization of adjusted alignment beyond the data samples.

To this end, we propose to explicitly constrain the equivalence of image and text latent manifolds in transferring VLMs toward downstream tasks. We study the structure of the image and text latent manifolds from the lens of topological data analysis . Topology encodes the connectivity of a space to describe its underlying structure, and the preservation of topology between spaces is fundamental for their structural equivalence. Topological data analysis employs homology groups to quantify the topological features of manifold structure, such as connected components, loops, voids, and higher-dimensional holes, as homology classes and tracks the survival of the topological features across multiple scales via persistent homology  to capture their size and position, which summaries the global shape of manifold. These topology insights provide an avenue to achieve a structural equivalence of image and text latent manifolds.

In this work, we propose a Homology Consistency (HC) constraint for efficient transfer on VLMs, which constrains the structural equivalence of image and text latent manifolds based on persistent homology in downstream tuning. Given image-text data samples, we construct simplicial complex on the top of data to mimic the topological structure of latent manifolds, and induce a nested sequence of subcomplexes called filtration. Through the filtration, we capture the persistence of homology classes from their appearance to non-existence and guide the homology persistences of image and text manifolds to be consistent. Specifically, we locate the births and deaths of homology classes in latent manifolds and track these homology persistences, then guide the directions of persistence tracks in image and text manifolds to coincide each other so as to achieve a homology-level structural equivalence. Additionally, we apply a deviating perturbation to persistence-related text samples to encourage their respective semantically related images to be distributed uniformly relative to them in embedding, in order to enhance the generalization of the track coincidence in adjusting image-text alignment. Further, we tailor the implementation of the proposed HC constraint for the main residual blending and key-value cache based paradigms of adapter tuning. Extensive experiments on few-shot learning over 11 benchmarks and domain generalization demonstrate the effectiveness and robustness of HC constraint in efficient transfer learning on VLMs.

Our main contributions are summarized as follows:

* We propose to explicitly constrain the structural equivalence of image and text latent manifolds in efficient transfer on VLMs, to improve the generalization of downstream image-text alignment adjusting beyond data samples in a low-data regime.
* We propose a theoretically well-founded homology consistency (HC) constraint based on persistent homology for efficient transfer on VLMs. We coincide the persistences of homology classes of topological features between image and text manifolds, and apply a deviating perturbation to generalize the persistence coincidence to unseen data.
* We tailor the implementation of the proposed HC constraint for the two main paradigms of adapter tuning respectively, showing the transferability of our method.
* We evaluate the proposed HC constraint on few-shot classification over 11 popular benchmarks. The extensive experiments demonstrate that HC constraint can boost the performance of baselines significantly and achieve state-of-the-art.

Related Work

**Efficient Transfer Learning.** To better transfer VLMs to downstream tasks especially with limited target domain data, a lot of research on efficient transfer learning has been done, which mainly exists in two types, prompt tuning and adapter tuning. Advanced than manual prompt that demands domain expertise to develop suitable format, prompt tuning methods design learnable prompts to adapt VLMs on downstream data. As a pioneer work, CoOp  for the first time composed prompts by concatenating text category embedding and learnable context vectors. The learnable prompts can be configured in text input [9; 10], image input  or jointly both [12; 13]. A line of work focuses on injecting semantic priors, such as category-related external knowledge [14; 15], category embedding distribution  and the diversity of visual concepts [17; 18], in prompt tuning. In another branch, adapter tuning methods insert a learnable lightweight adapter module into the frozen pre-trained VLMs and show excellent performance. The adapter architecture and insertion manner allow for flexible modifications. There are two main paradigms: residual blending and key-value cache based. By residual blending, CLIP-Adapter  appended learnable bottleneck layer to frozen encoder to tune embeddings. TaskRes  added a set of prior-independent parameters to frozen text category embeddings to obtain an image classifier. GraphAdapter  proposed to learn downstream knowledge with inter-class relationship of image and text samples. Based on the key-value cache model, Tip-Adapter  constructed an adapter with training images and label encodings as key-value to recognize query images. APE  refined the cache model by visual discrimination priors. CaFo  cascaded diverse external knowledge from DINO , DALL-E , and GPT-3  to assist recognition. However, although existing methods have attained remarkable achievements in VLMs transfer, they adjust the semantic alignment [31; 32; 33] of image and text latent manifolds toward downstream tasks merely on observed samples, _e.g._, data sets and external knowledge bases, and lack insight into underlying manifold structure, which may cause unguaranteed generalization beyond the data samples. In this work, we propose to explicitly constrain the structural equivalence of image and text latent manifolds in downstream tuning to facilitate the transfer of VLMs.

**Topological Data Analysis in Machine Learning.** The area of topological data analysis  infers the topological structure of data spaces using algebraic tools such as persistent homology, and has been applied in many fields of machine learning, _e.g._, image segmentation [34; 35; 36; 37], graph machine learning [38; 39; 40], molecular representation [41; 42], point cloud analysis [43; 44], etc. For instance, in image segmentation,  proposed to drive the segmentations to contain the specified topological features without requiring ground-truth labels.  used discrete Morse theory and persistent homology to learn the structural representation of images for fine-scale structure segmentation. In graph machine learning,  integrated vertex- and edge-level topological features into message-passing graph neural networks to boost their expressive power. In point cloud analysis,  developed a learnable filtration on point clouds to obtain adaptive topological features for given tasks. Besides,  preserved the topological structures of input space into latent space of autoencoders by aligning topologically relevant distances.  applied representation topology divergence  in dimensionality reduction to force closeness on topological structures. How to analyse the structure of data spaces for semantic alignment in vision-language tasks through topology remains under-explored in the literature. In this work, we characterize and align the structure of the image and text latent manifolds by means of persistent homology in efficient transfer learning on VLMs.

## 3 Methodology

### Preliminaries

#### 3.1.1 Contrastive Language-Image Pre-training (CLIP)

As a representative VLM, CLIP  is trained on massive image-text pairs and shows promising zero-shot performance on downstream tasks. CLIP adopts two separate encoders to embed images and texts into latent manifolds, and aligns the bi-modal embeddings by contrastive learning that forces paired image and text closer and unpaired ones away. For the transfer to image classification with \(N\) classes, CLIP obtains the class embedding \(w_{i}\) by feeding the prompt templates, _e.g._, "A photo of a [CLASS]", filled with class name \(c_{i}\) into text encoder, and the probability that an image \(x\) belongs to category \(c_{i}\) can be formulated as \(p(y=c_{i}|x)=(x^{}w_{i}/)/_{j=1}^{N}(x^{ }w_{j}/)\), where the embeddings are \(l_{2}\)-normalized and \(\) denotes a temperature hyper-parameter.

#### 3.1.2 Persistent Homology

Discrete data points contain only observations from the latent space in which they reside and do not have interesting topology. To peek at the topological structure of latent space, we mimic its connectivity by constructing a simplicial complex with the data points as vertices. As a basic element, simplex \(\) with dimension \(p\) is the convex hull of a set of \(p+1\) affinely independent points \((x_{0},,x_{p})\). Given a finite data point set \(X\) in metric space \((M,d)\) and a threshold \(a>0\), the commonly used Vietoris-Rips (Rips in short) complex is defined as:

\[K_{a}(X)=\{ X d(x_{i},x_{j})<a, x_{i}, x_{j}\},\] (1)

which is fully determined by the pairwise distances of \(X\). The dimension of \(K_{a}\) is the maximum dimension of any simplex within it. The formal sums of \(p\)-simplices added with \(_{2}\)-additions form a chain group \(_{p}(K_{a})\) (\(_{p}\) for brevity). Then, define a boundary operator \(_{p}\) on \(p\)-simplex \(\) as a map that sends \(\) to the \((p-1)\)-chain consisting of \(\)'s \((p-1)\)-faces referred as \(\)'s boundary. Applying \(_{p}\) to the chain groups can obtain a sequence of homomorphisms: \(_{k}}_{k-1}_{1 }}_{0}\). All \(p\)-chains whose boundaries are empty form a cycle group \(_{p}\), which is the kernel of \(_{p}\). The image of boundary operator \(_{p+1}\) on \(_{p+1}\) forms a boundary group \(_{p}\). Further, taking the quotient of the \(_{p}\) with \(_{p}\), the \(p\)-th homology group \(_{p}=_{p}/_{p}\) classifies the \(p\)-cycles in \(_{p}\) by collecting those cycles that differ by a boundary into the same homology class. In a topological view, the rank of homology group \(_{p}\) captures the number of \(p\)-dimensional holes in space.

Persistent homology offers a way to compute the quantified summary of topological structures of the latent space from sampled data. For the data point set \(X\) in space \((M,d)\), we define a function \(f:M,f((x_{0},,x_{p}))=_{i,j\{0, ,p\}}f((x_{i},x_{j}))\) on simplices. Then, given a sequence of thresholds \(a_{1} a_{2}, a_{n}\), the growing sublevel sets \(f^{-1}(-,a]\) at these values give rise to a nested sequence of subcomplexes, \(K_{a_{1}} K_{a_{2}} K_{a_{n}}\), called a filtration \(\), as shown in Fig. 1. The inclusions in \(\) induce:

\[0=_{p}(K_{0})_{p }(K_{i})^{i,j}}{}_{p}(K_{ j})_{p}(K_{n})= _{p}(K),\] (2)

where the images of the homomorphisms \(h_{p}^{i,j}\) are persistent homology groups \(_{p}^{i,j}\). A non-trivial homology class \(_{p}(K_{a})\) is born at \(K_{i}\), if \(_{p}^{i,a}\) but \(_{p}^{i-1,a}\). Likewise, the homology class \(\) dies entering \(K_{j}\), if \(_{p}^{a,j-1}\) but \(_{p}^{a,j}\). The persistence of a homology class is the lifespan from its birth to death. See Appendix A for more details.

### Homology Consistency

Given a set of pre-trained image embeddings \(X\) and text embeddings \(\), we construct a Rips complex \(K_{a_{M}}(X)\) with the maximum pairwise distance \(a_{M}\) of \(X\) and further derive a sublevel set filtration, \((K)\), as the nested family of subcomplexes \(K_{a_{0}} K_{a_{1}} K_{a_{M}}\) at the increasing scale sequence of pairwise distances \(\{a_{i}\}_{i=0}^{M}\) where \(a_{0}=0\). Then we arrive at \(p\)-th persistent homology groups that capture the survival of the homology classes of \(p\)-dimensional topological features (_e.g._, \(0\)-dimension: connected components, \(1\)-dimension: loops, \(2\)-dimension: voids, etc.) and pair the birth and death times of \(p\)-th homology classes, following . Since the edge skeleton of Rips complex fully determines all of its simplices,

Figure 1: The sublevel set filtration on a nested family of Rips complexes.

Figure 2: Schematic illustration of our proposed HC constraint. (a) TC guides the directions of the persistence tracks to coincide each other to establish the alignment of underlying structures beyond the observed samples. (b) DP encourages samples to be uniformly distributed.

under the assumption that pairwise distances of \(X\) are unique, every birth-death time pair can be mapped back to the simplices that respectively created and destroyed the unique corresponding homology class. The schematic illustration of HC constraint is shown in Fig. 2.

**Persistence Track Coincidence.** Let \(\) be a \(p\)-th homology class that is born at \(a_{b}\) and dies at \(a_{d}\), then the birth simplex \(\) forms \(\) in \(K_{a_{b}}\) and the death simplex \(\) causes \(\) to disappear entering \(K_{a_{d}}\). For example, if \(\) were to be 0-dimensional, it emerges at \(a_{0}\), and \(\) is the edge that joins it with some other point; if \(\) were to be 1-dimensional, then \(\) is the edge that forms the loop corresponding to \(\) in \(K_{a_{b}}\), and \(\) is the triangle that incurs the loop to be contractible in \(K_{a_{d}}\). Since the Rips complex is pairwise distance based, on every \(p\)-simplex we have:

\[f((x_{0},,x_{p}))=_{i,j\{0,,p\}}f((x_{i},x_ {j})).\] (3)

For the birth simplex \(\) and death simplex \(\), this means they will not be established until their longest edge \((x_{i()},x_{j()})_{ f()}\) and \((x_{i()},x_{j()})_{ f()}\) appear at time \(a_{b}\) and \(a_{d}\), which we refer to as birth edge and death edge, respectively. It can be said that the simplex \(\) is completed by the birth edge and \(\) by the death edge. Such edges mark the creation and destruction of the homology class \(\) in the image latent manifold. Defining the direction of the edges as from \(i\) to \(j\) such that \(i<j\) in the given vertex sequence of simplices, we track the persistence direction of \(p\)-th homology class \(\) from its birth edge to death edge as:

\[_{p}(,X)=(x_{i()},x_{j()})_{ f()}-(x_ {i()},x_{j()})_{ f()}.\] (4)

Then we obtain the persistence track of \(\) in text latent manifold, \(_{p}(,T)\), through determining its birth and death edges directly by taking the corresponding texts of the end-points of \(\)'s birth and death edges in image manifold accordingly. Further, for aligning the structure of image and text latent manifolds, we guide the track coincidence (TC) of \(p\)-th homology classes between the two by:

\[L_{TC}(_{p},X,T)=1-|}_{_{p}}( _{p}(,X),_{p}(,T)),\] (5)

where \(_{p}\) is the set of \(p\)-th homology classes in latent manifolds and \(\) is cosine similarity.

**Deviating Perturbation.** In a low-data regime where samples are not sufficient to fully characterize the topology of the latent manifold of interest, the sight of persistence track coinciding is confined on the given limited samples, which hinders the generalization of structural equivalence guided by track coincidence. For all end-point images of birth and death edges of \(p\)-th homology classes in \(_{p}\) and their corresponding texts, we drive every text to deviate from its semantically related images in embedding (what we consider here is that multiple images are related to the same category text in classification) without breaking the track coincidence, so as to encourage the text-related images beyond samples in latent manifold to be uniformly distributed around the text.

Specifically, since the persistence tracks of the \(0\)-th homology classes are exactly the death edges (birth edges are 0), their end-point samples are available from the given dataset. We quantify the degree of deviation as the similarity between the orientations of the text's embedding relative to the embeddings of its related images. Then, for \(0\)-th homology classes in \(_{0}\), we enlarge the deviation between end-point texts and their respective semantically related images by reducing the variation in their relative orientations, by applying a deviating perturbation (DP) as:

\[L_{DP}(_{0},X,T)=}|}_{x_{i} X_{_{0} }}(1-_{i}|}_{x^{}_{i} X^{}_{i}}( x_{i}-(x_{i})_{T},x^{}_{i}-(x_{i})_{T})),\] (6)

where \(X_{_{0}}\) denotes the set of all end-point images of \(0\)-th homology classes in \(_{0}\), \((x_{i})_{T}\) denotes \(x_{i}\)'s corresponding text, \(X^{}_{i} X_{_{0}}\) denotes a set of images of the same category that are semantically related to \(x_{i}\) and \(\) is cosine similarity. The deviating perturbation can benefit the structural equivalence to get rid of a biased reconstruction of latent topology caused by insufficient sampling.

**Homology Consistency.** To constrain the structural equivalence of image and text latent manifolds, we coincide persistence tracks of homology classes along with the deviating perturbation by:

\[L_{HC}(,X,T)=_{p=0}^{n}L_{TC}(_{p},X,T)+ L_{DP}(_ {0},X,T),\] (7)

where \(\) is the hyper-parameter controlling the perturbation strength. We mainly focus on the \(0\)-th homology classes (\(p=0\)), since higher-dimensional classes significantly increase computational cost but bring almost no additional performance benefits in VLMs tuning in practice.

### Implementation

To examine the structural equivalence constrained by our proposed homology consistency in the efficient transfer of VLMs and show its transferability, we tailor the implementation of homology consistency constraint to the two main paradigms of adapter tuning, residual blending based and key-value cache model based, respectively.

**Residual blending based** tuning methods construct an adapter to produce learnable residuals and blend them with the pre-trained features. As a representative, TaskRes  adds prior-independent parameters \(x\) as a residual to the pre-trained text embeddings \(t\) to form a learnable image classifier \(t^{}=t+ x\), where \(\) is a scaling factor, and updates the classifier by cross-entropy loss \(L_{CE}\).

In this paradigm, given frozen pre-trained image embeddings \(X\) and tunable text embeddings \(T\), our method can naturally construct a filtration on \(X\) to capture the image persistence tracks and further obtain their text tunable counterparts, and then employ the persistence track coincidence with deviating perturbation through \(L_{HC}(,X,T)\) in downstream tuning together with \(L_{CE}\).

**Key-value cache based** tuning methods build adapters via a key-value cache model with pre-trained embeddings of all training images as keys and one-hot encodings of corresponding labels as values. The image keys can be unfreezed as learnable parameters. As a representative, to recognize an image \(x\), Tip-Adapter-F  first measures its affinity weights that cached keys \(F_{}\) by \(A=(-(1-xF_{}^{T}))\), then aggregates the cached values \(L_{}\) with weights \(A\) as a prediction \(AL_{}\), and further combines \(AL_{}\) with the similarity between image \(x\) and pre-trained text category embeddings \(W_{c}\) as final classification logit \( AL_{}+xW_{c}^{T}/_{}\) in \(L_{CE}\).

In this paradigm, the cache-based adapter represents the categories as one-hot label encodings \(L_{}\), that is, the \(L_{}\) is the only textual representation of categories in this adapter. To be comparable to label encodings, we regard the affinity weights \(A\) of an image as a sparse visual representation of this image. For implementing homology consistency, we first capture the birth and death edges of image homology classes based on pre-trained image embeddings, then replace end-point images of the edges with their corresponding affinity weights \(A\) or label encoding \(L_{}\) and follow Eq. 4 to construct \(_{p}(,A)\) and \(_{p}(,L_{})\) analogically. We implement HC as \(L_{HC}(,A,L_{})\) by taking \(_{p}(,A)\) and \(_{p}(,L_{})\) as proxies for original image and text tracks.

**Optimization.** Efficient transfer learning commonly adopts the cross-entropy loss \(L_{CE}\) between labels and the predicted class probability to tune learnable parameters, _e.g._, \(\), on downstream classification tasks. We have two ways to integrate the gradient from our proposed HC constraint into parameter tuning. (1) We alter the cross-entropy gradient \(_{}L_{CE}\) toward the direction of HC by adding the gradient of HC constraint to \(_{}L_{CE}\) with a constant factor \(\) by: \(_{}L=_{}L_{CE}+_{}L_{HC}\). (2) For Tip-Adapter-F, due to its slightly complex hyper-parameter configuration, fixing a constant factor is difficult to control the contribution of each gradient. We adaptively keep the gradients at the same order of magnitude through scaling the gradient of homology consistency constraint based on gradient norm by \(_{}L=_{}L_{CE}+L_{CE}\|_ {2}}{\|_{}L_{HC}\|_{2}}_{}L_{HC}\) in optimization.

## 4 Experiments

### Experimental Settings

**Datasets.** Following previous efficient transfer learning works, we conduct the few-shot learning evaluation on 11 benchmark datasets including Caltech101 , DTD , EuroSAT , FGVCircraft , Flowers102 , Food101 , ImageNet , OxfordPets , StanfordCars , SUN397  and UCF101 . These datasets cover a wide range of visual recognition on generic objects, fine-grained categories, scenes, actions, etc. We sample 1, 2, 4, 8 and 16 shots per class, respectively, for model training and evaluate on full test sets. In addition, we evaluate the domain generalization performance of our method with the ImageNet  as source and its variants ImageNetV2 , ImageNet-Sketch , ImageNet-A  and ImageNet-R  as targets.

**Implementation Details.** In addition to HC, following TaskRes, we augment the original pre-trained text features into ones tuned on downstream tasks in HC\({}^{*}\). In implementing HC / HC\({}^{*}\) on TaskRes (HC-TR / HC\({}^{*}\)-TR), we set the values of \(\) and \(\) on different datasets according to the procedure of factor determination in ablation studies. We set the scaling factor \(\) to 1 for all datasets. The training batch size is \(256\). We employ the Adam optimizer with an initial learning rate of \(1e^{-4}\)on ImageNet and \(1e^{-3}\) on others, and the learning rates decay with cosine learning rate schedule following TaskRes. In implementing HC / HC\({}^{*}\) on Tip-Adapter-F (HC-TAF / HC\({}^{*}\)-TAF), \(\) and \(\) are also set according to the factor determination procedure in ablation studies. The \(\) here is significantly larger than the above because the magnitude difference between the \(_{}L_{TC}\) and \(_{}L_{DP}\) here is relatively large. The training batch size is \(256\). Following Tip-Adapter-F, we employ the AdamW optimizer with a cosine annealing scheduler. We set initial learning rate as \(1e^{-3}\). All experiments are conducted on a single NVIDIA A40 GPU. Note that the experiments on baseline and with the HC / HC\({}^{*}\) are conducted in the same setting for fair comparison. The code is publicly available 2.

### Performance Analysis

**Few-shot Learning.** We validate the effectiveness of our proposed HC constraint on 11 benchmark datasets using representative adapter tuning methods, the residual blending based TaskRes and key-value cache based Tip-Adapter-F, as baselines. The experimental results are shown in Fig. 3, from which it can be observed that our method brings performance improvements for 1 to 16 shots

Figure 3: The performance comparison of baselines and our proposed HC and HC\({}^{*}\) on few-shot learning, including 1-/2-/4-/8-/16-shots on 11 benchmark datasets and the average accuracy. The full numerical results are provided in the Appendix B.

consistently. Taking the 16 shots average accuracy as an example, HC-TR exceeds TaskRes by \(0.40\%\) and HC-TAF exceeds Tip-Adapter-F by \(1.04\%\). At 16-shot, HC-TAF outperforms Tip-Adapter-F by \(0.61\%\) on ImageNet. For the challenging fine-grained classification dataset FGVCAircraft, the proposed HC constraint gains \(1.38\%\) and \(1.92\%\) on TaskRes and Tip-Adapter-F, respectively. The further improvements of HC\({}^{*}\)-TR and HC\({}^{*}\)-TAF yielded by pre-tuned text classifier suggest that the HC-equipped tuning can still significantly benefit from representation enhancement.

The performance comparison of our HC constraint with the state-of-the-art adapter tuning methods on ImageNet is shown in Tab. 1. APE-T performs markedly best at 1 and 2 shots, whereas the models constrained by homology consistency, _e.g._, HC\({}^{*}\)-TAF, exceed it and other state-of-the-arts on the 8-/16-shot setting in more sample cases. This arises from the fact that the efficacy of homology consistency in vision-language aligning depends primarily on the modeling capability of the simplicial complex builded on training data towards the topological structure of latent space. The denser the data samples, the more sufficiently they summarize the structure, and the more effective the homology consistency constraint is. It is worth noting that HC boosts baselines to achieve state-of-the-art without introducing any additional training parameters. We respectively take TaskRes and Tip-Adapter-F as representative methods of residual blending based (_e.g._, CLIP-Adapter, TaskRes, GraphAdapter) and key-value cache based (_e.g._, Tip-Adapter-F, APE-T) adapter tuning for applying HC constraint. The HC constraint is verified to be effective on these two baselines by extensive experiments, and can theoretically be extended to other VLMs efficient transfer learning methods.

**Domain Generalization.** We investigate the generalization ability of the models constrained by HC under domain shift. We train the models on ImageNet with 16 shots and test the trained models on ImageNet variant datasets ImageNet-V2, ImageNet-Sketch, ImageNet-A and ImageNet-R. As

   Method &  \\  Zero-shot CLIP  & 58.18 & 58.18 & 58.18 & 58.18 & 58.18 \\ CLIP-Adapter  & 61.20 & 61.52 & 61.84 & 62.68 & 63.59 \\ TaskRes  & 61.44 & 62.28 & 62.78 & 64.30 & 65.41 \\ Tip-Adapter-F  & 61.16 & 61.74 & 62.65 & 64.07 & 65.43 \\ GraphAdapter  & 61.50 & 62.32 & 63.12 & 64.23 & 65.70 \\ APE-T  & **62.51** & **63.25** & **63.66** & 64.80 & 66.07 \\ HC-TR (Ours) & 61.46 & 62.34 & 62.86 & 64.47 & 65.90 \\ HC-TAF (Ours) & 61.17 & 61.79 & 62.73 & 64.37 & 66.04 \\ HC-TAF (Ours) & 62.15 & 62.59 & 63.60 & 64.81 & 66.25 \\ HC-TAF (Ours) & 62.04 & 62.61 & 63.28 & **64.86** & **66.40** \\   

Table 1: The performance comparison of our methods with the state-of-the-art methods on ImageNet.

   Method & Backbone &  &  & \\   & ImageNet & –V2 & –Sketch & –A & –R & Average \\  Zero-shot CLIP  & & 58.18 & 51.34 & 33.32 & 21.65 & 56.00 & 40.58 \\ Linear Probe CLIP  & & 55.87 & 45.97 & 19.07 & 12.74 & 28.16 & 28.16 \\ TaskRes  & & 65.41 & 56.84 & 35.54 & 21.68 & 59.96 & 43.51 \\ Tip-Adapter-F  & & 65.43 & 57.20 & 35.99 & **23.52** & 60.45 & 44.29 \\ HC-TR (Ours) & & 65.90 & 56.97 & 35.36 & 21.20 & 59.57 & 43.28 \\ HC-TAF (Ours) & & **66.04** & **57.44** & **36.17** & 23.49 & **60.52** & **44.41** \\  Zero-shot CLIP  & & 61.62 & **54.81** & 38.71 & 28.05 & 64.38 & 46.49 \\ Linear Probe CLIP  & & 59.75 & 50.05 & 26.80 & 19.44 & 47.19 & 35.87 \\ TaskRes  & & 68.26 & 59.94 & 41.30 & 28.91 & 67.36 & 49.38 \\ Tip-Adapter-F  & & 68.47 & 59.69 & 41.63 & 30.05 & 68.04 & 49.85 \\ HC-TR (Ours) & & 68.62 & 59.66 & 41.12 & 29.07 & 66.97 & 49.21 \\ HC-TAF (Ours) & & **68.80** & **60.30** & **41.76** & **30.08** & **68.15** & **50.07** \\  Zero-shot CLIP  & & 62.05 & 54.79 & 40.82 & 29.57 & 65.99 & 47.79 \\ Linear Probe CLIP  & & 59.58 & 49.73 & 28.06 & 19.67 & 47.20 & 36.17 \\ TaskRes  & & 68.45 & 59.54 & 42.09 & 30.60 & 68.80 & 50.18 \\ Tip-Adapter-F  & & 68.55 & 59.10 & 42.62 & 32.08 & 65.35 & 50.83 \\ HC-TR (Ours) & & 68.71 & 59.57 & 42.09 & 30.59 & 68.86 & 50.28 \\ HC-TAF (Ours) & & **69.04** & **59.75** & **42.74** & **32.16** & **69.60** & **51.06** \\  Zero-shot CLIP  & & 66.73 & 60.83 & 46.15 & 47.77 & 73.96 & 57.18 \\ Linear Probe CLIP  & & 65.85 & 56.26 & 34.77 & 35.68 & 58.43 & 46.29 \\ TaskRes  & & 73.55 & 65.81 & 48.86 & 49.85 & 77.35 & 60.47 \\ Tip-Adapter-F  & & 73.77 & 65.90 & 49.13 & **50.81** & 77.96 & 60.95 \\  HC-TR (Ours) & & 73.85 & 65.98 & 48.88 & 50.08 & 77.51 & 60.61 \\ HC-TAF (Ours) & & **74.08** & **66.18** & **49.30** & 50.75 & **78.01** & **61.06** \\   

Table 2: The performance comparison on domain generalization over four CLIP visual backbones. All methods are trained on the ImageNet in 16-shot setting and evaluated on the domain-shifted datasets, ImageNet-V2, -Sketch, -A, and -R.

shown in Tab. 2, HC-TR and HC-TAF outperform their respective baselines on the source dataset ImageNet across four different visual backbones ResNet-50, ResNet-101, ViT-B/32 and ViT-B/16. The performance of HC-TR is slightly inferior to that of TaskRes on ImageNet-Sketch, -A and -R with backbones ResNet-50, ResNet-101 and ViT-B/32, which concurs with TaskRes's reported source-overfitting pitfall. Nonetheless, HC-TR outperforms TaskRes with the more representative ViT-B/16. HC-TAF shows better generalization than Tip-Adapter-F in almost all target domains with various backbones. Experiments demonstrate that the performance improvement is not reliant on the shortcut to overfit the seen data domain.

### Ablation Studies

**Constraint terms: track coincidence and deviating perturbation.** The homology consistency constraint consists of track coincidence and deviating perturbation, and the effect of homology consistency constraint in efficient transfer comes from their collaboration. Here, we investigate the individual roles of track coincidence and deviating perturbation in tuning. The ablation on ImageNet dataset is shown in Tab. 3, from which we can observe that (1) Without the generalization enhancement in latent spaces brought by DP, the performance of TC alone decreases relative to full homology consistency constraint. (2) Conversely, if we do not guide the coincidence of persistence tracks and only apply DP to track end-point samples, the original performance of baselines will be damaged. This is because DP plays a role of regularization term for TC. Without coinciding persistence tracks by TC, not only the direct constraint on the structural equivalence of latent manifolds is lost, but also the only DP will cause the track end-point samples to randomly deviate from the hetero-modal training samples, which interferes with the downstream tuning and thus performance drop.

**Scaling factors of HC gradients in tuning.** The hyper-parameters \(\) and \(\) scale the weight of homology consistency constraint in tuning and \(\) controls the strength of deviating perturbation within the constraint (Sec. 3.3). We adopt the constant scaling (with \(\), \(\)) for TaskRes and adaptive scaling (with \(\), \(\)) for Tip-Adapter-F. In general, performance first increases and then decreases as \(\) (or \(\)) and \(\) increase, and the optimal performance is achieved by a specific combination of their values. Taking 16-shot ImageNet as an example, as shown in Tab. 4, the optimal \(\) and \(\) are \(15\) (_i.e._, \(0.15/_{}\)) and \(2.5\) on HC-TR, the optimal \(\) and \(\) are \(0.4\) and \(100\) on HC-TAF. In implementation, we first determine the values of scaling factors at 16-shot, and then migrate them to HC\({}^{*}\)-TR / HC\({}^{*}\)-TAF and other few-shot settings. The setting of hyper-parameter factors on other datasets follows a similar procedure.

## 5 Conclusions, Limitations and Future Work

In this work, we study the generalizability of image-text alignment adjusting in the efficient transfer of VLMs under a low-data regime. We propose to explicitly constrain the structural equivalence of image and text latent manifolds in downstream tuning and design a theoretically well-founded homology consistency constraint based on persistent homology for VLMs transfer. Our method constraint coincides the persistences of homology classes of topological features between image and text manifolds and applies a deviating perturbation to generalize the persistence coincidence to unseen data. Extensive experiments demonstrate the effectiveness and robustness of our method.

   \(\) (\(=2.5\)) & 5 & 10 & 15 & 20 & 25 \\  HC-TR & 65.67 & 65.83 & 65.90 & 65.79 & 65.72 \\  \(\) (\(=15\)) & 1.5 & 2.0 & 2.5 & 3.0 & 3.5 \\ HC-TR & 65.83 & 65.88 & 65.90 & 65.87 & 65.82 \\  \(\) (\(=100\)) & 0.1 & 0.2 & 0.3 & 0.4 & 0.5 \\ HC-TAF & 65.59 & 65.82 & 65.96 & 66.04 & 65.99 \\  \(\) (\(=0.4\)) & 50 & 100 & 150 & 200 & 250 \\ HC-TAF & 66.03 & 66.04 & 66.00 & 66.00 & 65.98 \\   

Table 4: The ablation studies for the scaling factors of gradients in homology consistency constraint.

   Baseline & TC & DP & 1-shot & 2-shot & 4-shot & 8-shot & 16-shot \\   & & & 61.44 & 62.28 & 62.78 & 64.30 & 65.41 \\  & ✓ & & 61.46 & 62.38 & 62.95 & 64.40 & 65.74 \\  & & ✓ & - & 62.14 & 62.67 & 64.23 & 65.33 \\  & ✓ & ✓ & - & 62.34 & 62.86 & 64.47 & 65.90 \\   & & & 61.16 & 61.74 & 62.65 & 64.07 & 65.43 \\  & ✓ & & 61.17 & 61.76 & 62.70 & 64.22 & 65.99 \\   & & ✓ & - & 61.76 & 62.63 & 63.95 & 65.17 \\   & ✓ & ✓ & - & 61.79 & 62.73 & 64.37 & 66.04 \\   

Table 3: The ablation studies for the constraint terms, track coincidence (TC) and deviating perturbation (DP).

**Limitations and Future Work.** In structural equivalence constraint, we do not explore the effects of higher-dimensional homology classes in depth. Besides, following previous work on efficient transfer learning for VLMs, we only apply the proposed homology consistency constraint on a series of few-shot recognition tasks. As a next step, we will further extend the application scenarios of our method to other VLMs downstream tasks.