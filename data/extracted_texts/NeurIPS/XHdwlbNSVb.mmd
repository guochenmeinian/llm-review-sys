# MMSite: A Multi-modal Framework for the Identification of Active Sites in Proteins

Song Ouyang\({}^{1}\) Huiyu Cai\({}^{2,3,4}\) Yong Luo\({}^{1}\) Kehua Su\({}^{1}\) Lefei Zhang\({}^{1}\) Bo Du\({}^{1}\)

\({}^{1}\)School of Computer Science, National Engineering Research Center for Multimedia Software

and Institute of Artificial Intelligence, Wuhan University, China

\({}^{2}\)BioGeometry, China \({}^{3}\)Mila - Quebec AI Institute, Canada \({}^{4}\)Universite de Montreal, Canada

{ouyangsong,luoyong,skh,zhanglefei,dubo}@whu.edu.cn

huiyu.cai@mila.quebec

Corresponding authors.

###### Abstract

The accurate identification of active sites in proteins is essential for the advancement of life sciences and pharmaceutical development, as these sites are of critical importance for enzyme activity and drug design. Recent advancements in protein language models (PLMs), trained on extensive datasets of amino acid sequences, have significantly improved our understanding of proteins. However, compared to the abundant protein sequence data, functional annotations, especially precise per-residue annotations, are scarce, which limits the performance of PLMs. On the other hand, textual descriptions of proteins, which could be annotated by human experts or a pretrained protein sequence-to-text model, provide meaningful context that could assist in the functional annotations, such as the localization of active sites. This motivates us to construct a **ProTe**in-**A**tribute text **D**ataset (**ProTAD**), comprising over 570,000 pairs of protein sequences and multi-attribute textual descriptions. Based on this dataset, we propose **MMSite**, a multi-modal framework that improves the performance of PLMs to identify active sites by leveraging biomedical language models (BLMs). In particular, we incorporate manual prompting and design a MACross module to deal with the multi-attribute characteristics of textual descriptions. MMSite is a two-stage ("First Align, Then Fuse") framework: first aligns the textual modality with the sequential modality through soft-label alignment, and then identifies active sites via multi-modal fusion. Experimental results demonstrate that MMSite achieves state-of-the-art performance compared to existing protein representation learning methods. The dataset and code implementation are available at https://github.com/Gift-OYS/MMSite.

## 1 Introduction

The identification of active sites in proteins is crucial for advancing fields such as life sciences and pharmaceutical development. Active sites are specific regions within a protein where substrate molecules undergo chemical transformations. Understanding these sites is essential for elucidating enzyme mechanisms, designing inhibitors, and developing novel drugs. Traditionally, the recognition of these sites relied on crystallographic techniques, mass spectrometry, and other labor-intensive experiments. Recently, the advent of deep learning has marked in a new era of bioinformatics, significantly enhancing the capabilities for predicting and analyzing protein functions computationally.

Recent advancements in natural language processing (NLP), particularly with the introduction of large-scale language models (LLMs) , have revolutionized the interpretation of complex data. Inspired by these developments, protein language models , trained on extensive datasetsof amino acid sequences, have significantly advanced our understanding of the intricate language of proteins. Most of the existing studies focus on utilizing PLMs to capture the overall structure and function, and predicting the global properties ("fitness") of proteins . In contrast, predicting properties at residue level for a given protein (such as identifying protein active sites) by deep learning methods is biologically meaningful but relatively less studied unfortunately, due to the scarcity of precise per-residue annotations.

On the other hand, informative textual descriptions, which can be obtained from biological experiments or a pretrained protein sequence-to-text model , are widely accessible and anticipated to provide meaningful context that could assist in residue-level tasks. Moreover, the field of multi-modal deep learning , which combines diverse data modalities like image and text, provides promising methodologies for advancing protein research. Inspired by this, integrating protein sequences and their corresponding textual descriptions enables us to leverage the strengths of both data types to achieve a more comprehensive understanding of proteins  (Figure 1). Our task, multi-modal protein active sites identification, is formally similar to multi-modal named entity recognition (MNER)  which combines text and image inputs to identify named entities, but the former is inherently more challenging because: (1) MNER deals with textual and image data, whose interactions are more intuitive and well-studied, whereas the relationship between the amino acid sequence and the textual descriptions of a protein is more implicit; (2) Identifying the active sites requires a detailed understanding of both the protein sequence and its corresponding structure, which are not readily available during inference; (3) While there is a vast amount of text and image data available for MNER, high-quality datasets for multi-modal active sites identification are less abundant.

In this paper, we build a **ProTe**in-**A**tribute text **D**ataset (**ProTAD**) containing more than 570,000 protein-text description pairs. Each textual description of a protein contains 17 different attribute fields, providing a rich semantic representation of the protein. Then, we develop a novel framework, **MMSite**, to achieve active site identification by leveraging pretrained PLMs and BLMs. Specifically, we employ prompting and design a multi-attribute cross attention module, MACross, to process the text, and achieve the identification via soft-label alignment and multi-modal fusion. Our method enforces the distribution of textual modality to be close to that of the sequential modality, improving the identification performance of PLMs. During the inference stage, we assume that there are no text descriptions, so the input is only the protein sequence, and the missing textual modality is generated with the aid of an agent model. Extensive experiments demonstrate that our method outperforms existing protein representation learning methods across three token-level and two region-level metrics, and can be seamlessly integrated with different PLMs and BLMs.

Our contributions can be summarized as follows:

* We propose a new and meaningful task in biological science: identifying active sites in proteins using both sequence and textual descriptions, and construct the ProTAD dataset.
* We introduce a framework that integrates both modalities for predicting protein active sites, utilizing a "First Align, Then Fuse" strategy.

Figure 1: Difference between our work and existing mainstream works. Left: Existing works focus on obtaining comprehensive protein representations for sequence-level prediction tasks, generating texts from sequence, or retrieving sequences based on textual descriptions. Right: Our task aims to identify active sites at the residue-level using protein sequences and multi-attribute textual descriptions.

* Our comprehensive experiments verify the effectiveness of our approach, and demonstrate that our framework can be effectively applied to different PLMs and BLMs.

## 2 Related work

Protein representation learningSignificant progress has been made in the field of protein representation learning (PRL) due to the advancements in deep learning techniques. Graph neural networks (GNNs) have emerged as powerful tools for representing protein structures or sequences by encoding them as graphs, capturing intricate interaction patterns among proteins . Additionally, self-supervised learning methods have been widely adopted, utilizing various predictive tasks to train models to learn meaningful representations of proteins. The advent of protein language models like ESMs , ProteinBERT , TAPE , and ProtTrans, trained on vast databases of protein sequences  and structures , has shown promising results in downstream tasks. They demonstrate the potential of transfer learning in protein representation . Moreover, all-atom structures  and protein surfaces  have also been explored to enhance our understanding of protein structure and function. These studies have applications in protein structure prediction  and functional annotation . Despite these advances, there remains a relative scarcity of work focusing on residue-level protein understanding, which plays a crucial role in comprehending the biochemical mechanism of proteins and drug discovery.

Multi-modal representation learningMulti-modal representation learning addresses the challenge of effectively integrating and utilizing information from diverse data modalities. In this field, significant advancements have been achieved by developing advanced algorithms and models, such as BLIP2  and PaLM-E , to improve the learning capabilities. Additionally, the introduction of highly capable language models, notably LLMs like GPT-4 , LLaMA2 , and Alpaca , has ignited fresh enthusiasm in the simultaneous modeling of biomolecules and natural language  concurrently. In the field of proteins, while "sequence-structure" multi-modal learning is successful , incorporating texts is also gain popularity. For example, OntoProtein  and InstructProtein  incorporate external knowledge graphs into protein pretraining. ProtST  enhances protein pretraining and understanding by biomedical texts with BLM, while Prot2Text  has achieved function prediction in free text format from graph and sequential inputs. ProLLaMA  utilizes the pretrained LLaMA2 to perform continual learning on protein language. Moreover, frameworks like BioT5  and BioT5+  have been proposed to capture the underlying relations and characteristics of different bio-entities. These developments not only underscore the potential for bridging natural language and protein language but also provide valuable insights for future multi-modal learning research.

Protein active sites identificationThe active site1 of a protein is a crucial region where it interacts with other molecules. It is typically composed of amino acid residues, and the arrangement determines the protein's structure and function. Thus, protein active sites identification is essential for understanding the protein's role within organisms. Over a decade ago, various methods were employed for this purpose, including statistics-based approaches , protein surface modelling , and straightforward machine learning techniques  such as Random Forest and Support Vector Machine . However, these methods were either challenging to implement or lack effectiveness. Recently, deep learning has been leveraged to predict the ligand binding sites on proteins. For instance, DeepSurf  and CrossBind  utilize 3D voxelized grids and point clouds, respectively, to generate volumetric protein representations. Meanwhile, GraphBind , ScanNet , and DeepProSite  integrate both primary sequences and tertiary structures to recognize amino acids in the binding site region. However, although active sites are directly involved in the activity of a protein and play a significant role in drug design, enzyme engineering, _etc._, they are relatively less studied.

## 3 Methods

In this section, we first give a formal definition to the multi-modal active sites identification task in Section 3.1. Then, we present our MMSite framework in Section 3.2, which comprises attributes reconstruction, feature extraction, multi-modal alignment and fusion.

### Problem definition

Here we formulate our task of predicting active sites in proteins using both protein sequences and multi-attribute textual descriptions. We define the dataset composition in our ProTAD as \(=\{,\}\), where \(=\{S_{i}\}_{i=1}^{N}\) represents the primary sequences and \(=\{T_{i}\}_{i=1}^{N}\) denotes the textual attributes associated with each protein, with \(N\) being the total number of entries in the dataset. For the \(i\)-th protein, \(S_{i}\) is a sequence of \(k_{i}\) amino acids, denoted as \(S_{i}=\{_{i}^{1},_{i}^{2},,_{i}^{k_{i}}\}\). Each \(T_{i}\) is a collection of \(M\) textual descriptions that depict protein from different perspectives. These descriptions are structured as pairs consisting of an attribute name \(^{n}\) and attribute content \(^{c}\) in raw data, specifically, \(T_{i}=\{(_{i,j}^{n},_{i,j}^{c})\}_{j=1}^{M}\). As for the annotation target at the token-level, \(_{i}=\{y_{i,j}\}_{j=1}^{k_{i}}\) indicates whether each amino acid in the sequence is an active site, where \(y_{i,j}\{0,1\}\). During the training stage, both modalities \(\) and \(\) are employed to develop our model. The likelihood that each amino acid is an active site is predicted using only the protein sequence \(\) as an input during the inference stage.

### Contrastive learning-based alignment and fusion

Attribute description reconstruction with promptIn our raw data, textual descriptions are structured with each protein having serveral distinct attribute descriptions in the form \((^{n},^{c})\), formatted as Attribute_name:Attribute_content, such as:

* Protein Name: Parkinson disease protein 7 homolog;
* Taxonomic Lineage: Cellular organisms, Opishokonta, Eumetazoa;
* Function: Multifunctional protein with controversial molecular function which plays an important role in cell protection against oxidative stress.

In order to handle this tabular-like form of data, enhancing the linkage between the content and its corresponding attribute name is important. We designed manual _prompts_ for each attribute to

Figure 2: Overview of the MMSite framework. MMSite takes paired sequences and multi-attribute textual descriptions as inputs, using PLM and BLM to extract features in Stage 1. For the text modality, manual prompting and the MACross Module process the multi-attribute descriptions. A “First Align, Then Fuse” strategy is then employed to align and fuse both modalities. Specifically, in Stage 2, a Shared Transformer Encoder and soft-label alignment align the dual modalities. In Stage 3, Fusion Attention and a skip concatenation strategy are used to predict active sites, with only the modules in Stage 3 being trainable. Note: During inference, the missing text modality is generated by an agent model and directly input into the Shared Transformer Encoder, bypassing the need to process through MACross, as it is not multi-attribute.

reconstruct the tabular text pairs into full sentences, thus \(=\{}_{j}\}_{j=1}^{M}\). Consequently, the examples above are reconstructed as follows:

\(\)_The name of protein is_ Parkinson disease protein 7 homolog.

\(\)_The taxonomic lineage of this protein includes_ Cellular organisms, Opishokonta, Metazoa.

\(\)_The function of this protein includes_ Multifunctional protein with controversial molecular function which plays an important role in cell protection against oxidative stress.

The words in _italics_ are the prompts that not only aid in reconstructing free-formed texts, but also provide a more relevant and comprehensive description of each protein.

Modality feature extractionDuring the training stage, the pretrained PLM \(f_{}\) and BLM \(f_{}\) are used to initialize the representations of protein sequence \(f_{}(S)\) and the textual descriptions \(f_{}()\), respectively. We freeze the weights of both the PLM and BLM due to the expensive computational cost and design subsequent learnable modules to adapt these models for our task.

Specifically, \(M\) reconstructed textual descriptions are fed into BLM:

\[f_{}()=\{f_{}(}_{1}),f_{}(}_{2}),,f_{}(}_{M})\},\] (1)

where \(f_{}(}_{i})^{l_{1} d}\), and the truncated length of tokenized sequence \(l_{i}\) is not same for different attributes for saving computational resources (details can be found in Appendix B.2). Given the hierarchical characteristic of textual descriptions, we design a _Multi-Attribute Cross-attention_ (MACross) module to capture the relationship among attributes. Intuitively, the Function attribute is of the greatest importance due to the rich information it carries. Thus, we first incorporate the left \(M-1\) attributes by [CLS] token  with inter-attribute attention to obtain \(_{-F}^{}\):

\[_{-F}^{}=((\{f_{}(}_{i})_{}|1 i M,_{i}^{n}\})),\] (2)

while \(_{F}^{}:=f_{}(}_{i})\) where \(_{i}^{n}=\). Then we employ multi-layer cross-attention  to query the information of \(_{F}\) by \(_{-F}\):

\[(_{-F}^{},_{F}^{}, _{F}^{})=(_{-F}_{F}^{ }}{})_{F},\] (3)

\[_{-F}=^{Q}_{-F}^{};_{F}=^{K}_{F}^{};_{F}=^{V}_{F}^{},\] (4)

where \(^{Q}\), \(^{K}\) and \(^{V}\) refer to learnable transformation matrices, and \(d\) refers to the dimension of each attention head. Similar to , we employ a residual connection by a fully connected feed-forward network (FFN) as shown in Figure 2.

Cross-modal soft-label alignmentIn order to utilize the complementary knowledge of amino acid sequence and textual descriptions to improve the performance and robustness. Inspired by , we employ the "First Align, Then Fuse" strategy to fuse two aligned modalities to predict the amino acid-level target (_i.e._, the active sites) of protein. Assume that the output of the sequence and textual description after feature extraction are \(^{}\) and \(^{}\), respectively, although both of them point to the same protein, the divergence still exists. Therefore, firstly we use a _Shared Transformer Encoder_ (STEnc, consisting of multiple Transformer encoders) to early-map \(^{}\) and \(^{}\):

\[}^{}=(^{});}^ {}=(^{}).\] (5)

In order to align paired sequence and textual descriptions, it is common practice to use contrastive learning based on InfoNCE loss . This method "pulls close" the paired samples ("positive pair") as "pushes away" the unpaired samples ("negative pair") in the high-dimension space by maximising mutual information between two modalities in self-supervised manner. However, in our case there may be a potential semantic association between unpaired sequence and textual descriptions in the same batch due to the principle "_Similar protein sequences give rise to similar structures and functions_" in biology (Appendix C). Inspired by , we adopt cross-modal soft-label alignment to make one-hot label continuous.2 Specifically, the cosine similarity between \(}_{i}^{}\) and \(}_{j}^{}\) is denoted as \(s_{ij}^{}\), and the cosine similarity between \(}_{i}^{}\) and \(}_{j}^{}\)3 is denoted as \(r_{ij}^{}\), and \(r_{ij}^{}\) is defined in the same way. \(P_{ij}^{}\) represents the semantic consistency within the same modality which is calculated in a _softmax-like_ manner:

\[P_{ij}^{}=^{})}{_{k=1}^{||} (r_{ik}^{})},\] (6)

where \(||\) is batch size. Actual distribution \(Q_{ij}^{}\) represents the probability that \(}_{i}^{}\) matches \(}_{j}^{}\), which is hoped to align with \(P_{ij}^{}\):

\[Q_{ij}^{}=^{}/)}{_{k=1}^{| |}(s_{ik}^{}/)},\] (7)

where \(\) is temperature. Thus, the loss function in the _Align_ phase can be calculated as:

\[_{}=|}{_{i=1}^{||}(D_{KL}(P_{i}^{}\|Q_{i}^{})+D_{KL}(P_{i}^{} \|Q_{i}^{}))}.\] (8)

We note that the parameters of the sequence branches are frozen, resulting in the alignment of the textual feature space to that of the sequence feature space.

Multi-modal fusion and active sites identificationIn the _Fuse_ phase, a multi-head cross-attention strategy is utilized again to integrate the protein and text modalities, where \(}^{}\) serves as "query" while \(}^{}\) serves as both "key" and "value". This setup enables the network to develop a comprehensive representation of queried text modality by sequence. Consequently, the model not only encodes protein-related knowledge but also retains insights derived from textual data, fostering a holistic comprehension. Subsequently, the unmapped \(^{}\) and the features deviated by _Fusion Attention_ are concatenated before the prediction layer. Finally, the model employs Cross Entropy Loss, denoted as \(_{}\), to predict active sites.

Although during the training stage, both sequence and text modalities are used to predict active sites, in practice, when dealing with newly discovered proteins, we might lack its high-quality textual annotations. To address this issue, we employ a state-of-the-art biomedical text generation method, such as Prot2Text , as an agent to complete the missing text modality. Some examples of generated texts are shown in Appendix B.4.

## 4 Experiments

### Experiment setups

Dataset descriptionTo obtain comprehensive and accurate protein-text data, we build the ProTAD with 570,830 samples from Swiss-Prot in UniProt4 after data cleaning and filtering. ProTAD includes the amino acid sequence and textual descriptions for each sample, covering 17 attributes such as Protein Name, Organism, Function, Caution, _etc._ as described in Appendix A.1. These descriptions are rigorously checked so that the proteins can be accurately described. Due to some proteins lacking certain attribute annotations, we select those pairs of samples with at least six attributes (of which the Function attribute is required) in our experiments. To ensure a fair comparison with other methods when conducting experiments in Section 4.2.1, we filter the proteins those could obtain tertiary structures in AlphaFold DB . In order to prevent the potential data leakage, following CLEAN , we cluster the data using MMseqS2  with different sequence identity thresholds (in our settings they are 10%, 30%, 50%, 70%, and 90%) to avoid the test sequences from being too similar to the training data. After that, we develop a _cluster-guarantee_ approach and employ _k-selected_ strategy to construct an \(8:1:1\) split dataset. The detailed preparation process can be found in Appendix A.2.

Implementation detailsOur implementation is based on PyTorch version 1.13.1, and models are trained using a single NVIDIA GeForce RTX 4090 GPU with 24GB of memory. The MMSite model in Table 1 requires approximately 7 hours to train. We retain the original feature dimensions of each PLM encoder and BLM encoder to preserve more inherent information, _e.g._, 1280 dimensions for ESM-2-650M and 768 dimensions for PubMedBERT-abs . The m 512, and extra amino acids will be removed. Details on the truncated length for each attribute can be found in Appendix B.2. We set the hyperparameter \(\) to 0.8. In MACross, we use 2-layer Transformer encoder to extract inter-attribute relations, with the number of cross-attention blocks set to 4. We also adopt 4-layer 8-head Transformer in STEnc. Before the final MLP predictor, an additional 2-layer attention mechanism integrates the original sequence modality with the fused feature. The dropout rates of all above components is consistently set at 0.1. The model undergoes a 15-epoch _Align_ phase and a 50-epoch _Fuse_ phase, using the Adam optimizer with a learning rate of 5e-5. We implement a warm-up phase comprising \(\) of the total steps, followed by a cosine annealing scheduler for the remaining steps. The batch size is set to 24 for both training and inference stages. We consider those sites as predicted active sites whose result, after the Sigmoid function of the MLP predictor output, is greater than 0.5.

### Protein active sites identification

#### 4.2.1 Comparison with baselines

SettingsTo compare with existing methods, we select 21 state-of-the-art PRL models as baselines. Their original weights are frozen, and residue-level features are obtained followed by 4-layer Transformer for prediction. Some of them utilize not only sequences but also combinations of sequences with structures, and sequences with text. Specifically, for models like MIF and PST, we obtain tertiary structures for each protein from AlphaFold DB. For ProtST, we perform comparisons w/ and w/o retraining on ProTAD. For MMSite, Prot2Text  serves as the agent model in the inference stage. Evaluation metrics include token-level F\({}_{}\), AUPRC, and MCC, following the implementation described in , as well as region-level OS (Overlap Score) and FPR (False Positive Rate) as defined in . We save the checkpoint at the epoch with the best F\({}_{}\) in validation set. Results are reported in Table 1 for the dataset with clustering threshold at 10%, using several different seeds, where ESM-1b and PubMedBERT-abs are used as the PLM and BLM encoders to initialize features. Some visualisation results are presented in Figure 3 and Appendix F.

  
**Input\({}^{}\)** & **Method** & **Version** & **F\({}_{}\)** & **AUPRC \(\)** & **MCC \(\)** & **OS \(\)** & **FPR \(\)** \\   &  & 1b  & 0.7052\(\)0.023 & 0.8452\(\)0.023 & 0.7123\(\)0.023 & 0.7211\(\)0.040 & 0.2758\(\)0.013 \\  & & 1v  & 0.6306\(\)0.053 & 0.7975\(\)0.023 & 0.6382\(\)0.033 & 0.6398\(\)0.033 & 0.3388\(\)0.025 \\  & & 2-650M  & 0.6517\(\)0.041 & 0.8230\(\)0.048 & 0.6596\(\)0.049 & 0.6652\(\)0.022 & 0.3240\(\)0.053 \\   &  & BFD & 0.4156\(\)0.057 & 0.6737\(\)0.023 & 0.4217\(\)0.003 & 0.4130\(\)0.050 & 0.5509\(\)0.053 \\  & & UnifRef & 0.4696\(\)0.043 & 0.7119\(\)0.042 & 0.4767\(\)0.040 & 0.4652\(\)0.040 & 0.4919\(\)0.053 \\   &  & BFD & 0.5610\(\)0.023 & 0.7524\(\)0.023 & 0.5715\(\)0.023 & 0.5865\(\)0.040 & 0.4115\(\)0.053 \\  & & UniRef & 0.4817\(\)0.023 & 0.6992\(\)0.021 & 0.4896\(\)0.023 & 0.4915\(\)0.011 & 0.4871\(\)0.049 \\   &  & & 0.6033\(\)0.053 & 0.7519\(\)0.023 & 0.6121\(\)0.03 & 0.6149\(\)0.03 & 0.3636\(\)0.033 \\   &  & & 0.0345\(\)0.009 & 0.0952\(\)0.023 & 0.0409\(\)0.003 & 0.0772\(\)0.011 & 0.9233\(\)0.033 \\   &  & & 0.5636\(\)0.023 & 0.7630\(\)0.023 & 0.5732\(\)0.023 & 0.5793\(\)0.034 & 0.4041\(\)0.031 \\   &  &  & 0.6533\(\)0.023 & 0.7994\(\)0.023 & 0.6603\(\)0.023 & 0.6529\(\)0.023 & 0.3134\(\)0.023 \\   & & S-PLM  & & 0.7262\(\)0.023 & 0.8712\(\)0.021 & 0.7337\(\)0.023 & 0.7322\(\)0.023 & 0.2452\(\)0.023 \\   &  & & 0.3560\(\)0.023 & 0.5413\(\)0.021 & 0.3622\(\)0.023 & 0.3523\(\)0.023 & 0.6096\(\)0.023 \\   &  & MIF & 0.1379\(\)0.023 & 0.3470\(\)0.023 & 0.1393\(\)0.023 & 0.1346\(\)0.023 & 0.8524\(\)0.023 \\  & & MIF-ST & 0.1033\(\)0.024 & 0.2883\(\)0.024 & 0.1034\(\)0.023 & 0.1030\(\)0.023 & 0.8958\(\)0.023 \\   &  &  & 0.6574\(\)0.013 & 0.8139\(\)0.013 & 0.6648\(\)0.011 & 0.6719\(\)0.011 & 0.3219\(\)0.033 \\   & & t33\(\_\)so & 0.6708\(\)0.023 & 0.8266\(\)0.023 & 0.6793\(\)0.023 & 0.6891\(\)0.023 & 0.3079\(\)0.023 \\   &  & ESM-1b & 0.4036\(\)0.003 & 0.6762\(\)0.023 & 0.4144\(\)0.023 & 0.4297\(\)0.033 & 0.5663\(\)0.023 \\  & w/ retrain & ESM-2 & 0.1865\(\)0.013 & 0.4220\(\)0.023 & 0.1918\(\)0.023 & 0.1872\(\)0.025 & 0.7897\(\)0.013 \\   &  & ESM-1b & 0.4632\(\)0.075 & 0.7040\(\)0.023 & 0.4722\(\)0.023 & 0.4779\(\)0.05 & 0.5030\(\)0.075 \\   &  & ESM-2 & 0.5483\(\)0.023 & 0.7716\(\)0.021 & 0.5562\(\)0.023 & 0.5613\(\)0.011 & 0.4239\(\)0.023 \\   & ^{}\)**} & & **0.8250\(\)0.045** & **0.8909\(\)0.045** & **0.8319\(\)0.053** & **0.8549\(\)0.023** & **0.1689\( and discussionsThe results demonstrate that MMSite outperforms individual models that only use residue sequences as input, achieving state-of-the-art performance across all metrics. Among the comparisons, S-PLM, which incorporates contrastive learning between sequences and structures during pretraining, performs slightly better than other Seq.-input methods, showing the potential of incorporating structural data. Nonetheless, MMSite still outperforms the model with Seq. & Struct. as input. Regarding ProtST w/ and w/o retrain, limited utilization of textual information in retraining process and reduced data volume for downstream application lead to decreased performance.

#### 4.2.2 BLM enhances PLM's performance

Evolutionary information is crucial in the identification of function sites, as these sites often preserve conserved patterns and structural motifs across species or among homologous proteins. In Table 2, we compare three state-of-the-art evolutionary-scale models (_e.g._, ESM-1b, ESM-1v, and ESM-2-650M) that are used as encoders for protein sequences. Additionally, BLMs such as PubMedBERT-abs and PubMedBERT-full serve as biological text encoders. It is evident that the utilization of BLM has resulted in significant enhancements of the performance of PLM.

### Ablation study

#### 4.3.1 Impact of different clustering thresholds

In order to study the impact of identity thresholds on clustering using MMSeqs2 during data partition, we set thresholds at 10%, 30%, 50%, 70%, and 90% for comparison, and the results are shown in Figure 4, where ESM-1b and PubMedBERT-abs serve as the PLM and BLM encoders respectively. Detailed quantitative comparisons for the cases of 30% and 50% are provided in Appendix D.4. It is clearly that with the increase of clustering threshold, all the performances of each metric are improved. Especially when the threshold is changed from 30% to 50%, the improvement of the model is especially obvious, and when it reaches 90%, the performance approaches near perfection.

  
**Method** & \(}\) & **AUPRC**\(\) & **MCC**\(\) & **OS**\(\) & **FPR**\(\) \\  ESM-1b & 0.7050 & 0.8443 & 0.7117 & 0.7127 & 0.7205 \\  +**MMSite-abs** & \(\) 0.120 & \(\) 0.047 & \(\) 0.120 & \(\) 0.142 & \(\) 0.102 \\ +**MMSite-full** & \(\) 0.105 & \(\) 0.044 & \(\) 0.107 & \(\) 0.145 & \(\) 0.076 \\  ESM-1v & 0.6267 & 0.8018 & 0.6340 & 0.6351 & 0.3431 \\  +**MMSite-abs** & \(\) 0.160 & 0.069 & 0.159 & 0.164 & 0.149 \\ +**MMSite-full** & \(\) 0.172 & \(\) 0.078 & \(\) 0.172 & \(\) 0.184 & \(\) 0.156 \\  ESM-2650M & 0.6402 & 0.8068 & 0.6479 & 0.6607 & 0.3434 \\  +**MMSite-abs** & \(\) 0.156 & \(\) 0.072 & \(\) 0.157 & \(\) 0.175 & \(\) 0.138 \\ +**MMSite-full** & \(\) 0.162 & \(\) 0.075 & \(\) 0.161 & \(\) 0.169 & \(\) 0.152 \\   

Table 2: Performance improvement with the addition of BLM compared to using PLM as input only.

Figure 4: Impact of clustering threshold on model performance.

Figure 3: Visualisation of an example of active site identification result for the protein _Tyrosine recombinase XerC_ (UniProt ID: Q039E1). The **palecyan** surface/sticks (residues) represent the background, while the green, **blue**, and **red** surface/sticks (residues) indicate the correctly predicted sites, unpredicted sites, and incorrectly predicted sites, respectively.

#### 4.3.2 Effectiveness of components

To figure out the contribution of each component within the MMSite framework to overall model performance, we conduct ablation experiments for each of them. The results are presented in Table 3, where "Seq-M" and "Text-M" refer to the sequence modality and the text modality, respectively. It can be found that both STEnc and MACross contribute to the performance improvement, and the _Align_ mechanism helps more obviously by aligning the text modality closer to the sequence modality. Moreover, the importance of the text modality is evident in the last row, which shows an average decline of 0.105 across all metrics when the text modality is removed, compared to MMSite.

#### 4.3.3 Single-stage _vs._ two-stage

Our framework employs a two-stage training strategy, "First Align, Then Fuse", and we also compare it with a single-stage strategy "Align While Fusing". The total loss for the single-stage strategy is calculated as \(_{}=_{}+_{ }\), where \(\) is set to the best performing 0.7 after many attempts. The comparative results are presented in Table 4. It is clear that the two-stage strategy outperforms the single-stage approach, which is more challenging due to its multi-objective nature and the potential conflicts between different objectives.

#### 4.3.4 Ablation of the attribute selection

MACross module is designed based on that the Function attribute is the most relevant attribute for predicting active sites and contains the richest information. The additional attributes, although seemingly insignificant, also contribute to improve active site predictions. Table 5 below shows the performance comparison between using only the Function attribute and using all attributes, demonstrating that incorporating all attributes leads to better performance.

#### 4.3.5 Ablation of manual prompting

To evaluate the effectiveness of manual prompting, we conducted experiments to test the impact of removing manual prompts in Table 6. The results show that manual prompting improves performance on most metrics. We believe this is because: (1) Complete sentences provide richer context for the

    &  &  &  \\   & & & **Fmax**\(\) & **AUPRC**\(\) & **MCC**\(\) & **OS**\(\) & **FPR**\(\) & **Fmax**\(\) & **AUPRC**\(\) & **MCC**\(\) & **OS**\(\) & **FPR**\(\) \\   & Single & 0.8086 & 0.8772 & 0.8158 & 0.8329 & 0.1798 & 0.8055 & 0.8766 & 0.8121 & 0.8253 & 0.1818 \\  & Two & **0.8250** & **0.8909** & **0.8319** & **0.8549** & **0.1689** & **0.8099** & **0.8882** & **0.8183** & **0.8574** & 0.1950 \\   & Single & 0.7369 & 0.8525 & 0.7440 & 0.7576 & 0.2480 & 0.7713 & 0.8589 & 0.7780 & 0.7924 & 0.2155 \\  & Two & **0.7864** & **0.8705** & **0.7933** & **0.7987** & **0.1942** & **0.7988** & **0.8795** & **0.8058** & **0.8194** & **0.1871** \\  ESM-2 & Single & 0.7522 & 0.8572 & 0.7591 & 0.7664 & 0.2296 & 0.7603 & 0.8638 & 0.7669 & 0.7677 & 0.2171 \\  & Two & **0.7965** & **0.8789** & **0.8046** & **0.8358** & **0.2052** & **0.8018** & **0.8814** & **0.8091** & **0.8294** & **0.1916** \\   

Table 4: Comparison between the single-stage and the two-stage strategy.

  
**Seq-M** & **Text-M** & **Align** & **MACross** & **STEnc** & **Fmax**\(\) & **AUPRC**\(\) & **MCC**\(\) & **OS**\(\) & **FPR**\(\) \\   ✓ & ✓ & ✓ & ✓ & ✓ & **0.8250** & **0.8909** & **0.8319** & **0.8549** & **0.1689** \\  ✓ & ✓ & ✓ & ✓ & & 0.8021 & 0.8819 & 0.8071 & 0.8027 & 0.1738 \\ ✓ & ✓ & ✓ & & & ✓ & 0.8152 & 0.8908 & 0.8214 & 0.8379 & 0.1757 \\ ✓ & ✓ & ✓ & & & & 0.8037 & 0.8850 & 0.8105 & 0.8241 & 0.1847 \\ ✓ & ✓ & & & & & 0.7911 & 0.8710 & 0.7980 & 0.8150 & 0.1978 \\ ✓ & & & & & & 0.7052 & 0.8452 & 0.7123 & 0.7211 & 0.2758 \\   

Table 3: Evaluation of the effectiveness of each component in MMSite.

  
**Textual Description** & **Fmax**\(\) & **AUPRC**\(\) & **MCC**\(\) & **OS**\(\) & **FPR**\(\) \\  
**All** attributes & **0.8250** & **0.8909** & **0.8319** & **0.8549** & **0.1689** \\ 
**Only** Function attribute & 0.8152 & 0.8866 & 0.8231 & 0.8471 & 0.1764 \\   

Table 5: Performance comparison between using all attributes and only Function attribute.

BERT-based BLM; (2) It reduces ambiguity in attribute meanings; (3) It aligns better with BLM's pretraining, leveraging its knowledge more effectively.

#### 4.3.6 Other ablation studies

In MACross, the Function and the remaining 16 attributes are utilized as K & V, and Q respectively in Cross Attention to query \(_{F}\). We attempt to swap their positions for comparison (_i.e._, \(_{F}\) serves as "query", \(_{-F}\) servers as "key" and "value"). Additionally, we also try to replace soft-label alignment with hard-label alignment (similar to InfoNCE). The results of their average performance on token-level and region-level are shown in Table 7. To compare the results, we replace FPR with 1 \(-\) FPR when calculating Avg. (region). MMSite performs best compared to the other two scenarios. We also investigated the impact of varying the hyperparameter \(\) in soft-label alignment from 0.2 to 2.0 in Figure 5, because it directly determines the information entropy of the target distribution \(Q\) in the _Align_ phase. The results shows that the model is relative optimal in both token-level and region-level metrics when \(\) is set to 0.8.

### Temporal-based evaluation

To more accurately reflect real-world scenarios in scientific applications, we conducted an extra experiment simulating the discovery of new proteins. We collected data from UniProt database recorded after March 11, 2024 as newly discovered proteins (115 samples) to evaluate the model's performance. The results in Table 8 show that MMSite maintains well performance even on newly discovered proteins.

Due to space limitations, further experiments results on performance comparisons, text quality, protein sequence input, inference performance, and related aspects are included in the Appendix D.

## 5 Conclusion

In this work, we build the ProTAD dataset that contains detail textual descriptions of proteins, and propose the MMSite framework to identify the active sites in proteins, which is crucial for understanding proteins in residue-level, designing new drugs and so on. MMSite takes both sequence and text as input in training stage, and adopts "First Align, Then Fuse" strategy to align the text representation to the sequence, enhancing PLM's performance in active sites identification. We adopt manual prompting and a designed MACross module to handle the multi-attribute descriptions, and adopt soft-label alignment in the _Align_ phase. Extensive experimental validations have been conducted to evaluate the effectiveness of our method, showing the potential of multi-modal learning in computational biology. From experience, the method works best when ESM-1b and PubMedBERT-abs are chosen as the PLM and BLM, Prot2Text is used as the agent model. We also discussed the limitations and broader impacts in Appendix E.

  
**Method** & \(}\) & **AUPRC**\(\) & **MCC**\(\) & **OS**\(\) & **FPR**\(\) \\  w manual prompting & **0.8250** & 0.8909 & **0.8319** & **0.8549** & **0.1689** \\ w/o manual prompting & 0.8157 & **0.8911** & 0.8221 & 0.8460 & 0.1793 \\   

Table 6: Ablation experiment of manual prompting.

  
**Method** & **Avg. (token)** & **Avg. (region)** \\ 
**MMSite** & **0.8493** & **0.8430** \\  Func. as Q & 0.8394 & 0.8279 \\  Hard align & 0.8334 & 0.8221 \\   

Table 7: Comparison between MMSite and other two scenarios.

Figure 5: Performance on different \(\).

  
**Test Data** & \(}\) & **AUPRC** & **MCC** & **OS** & **FPR** \\  Newly discovered proteins & 0.8432 & 0.8865 & 0.8460 & 0.8465 & 0.1420 \\   

Table 8: Performance evaluation on the newly discovered proteins.