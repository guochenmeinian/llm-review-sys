# Amortized Bayesian Workflow (Extended Abstract)

Marvin Schmitt

University of Stuttgart

Germany &Chengkun Li

University of Helsinki

Finland &Aki Vehtari

Aalto University

Finland &Luigi Acerbi

University of Helsinki

Finland &Paul-Christian Burkner

TU Dortmund University

Germany &Stefan T. Radev

Rensselaer Polytechnic Institute

United States

equal contributionWorkshop on Bayesian Decision-making and Uncertainty, 38th Conference on Neural Information Processing Systems (NeurIPS 2024).

###### Abstract

Bayesian inference often faces a trade-off between computational speed and sampling accuracy. We propose an adaptive workflow that integrates rapid amortized inference with gold-standard MCMC techniques to achieve both speed and accuracy when performing inference on many observed datasets. Our approach uses principled diagnostics to guide the choice of inference method for each dataset, moving along the Pareto front from fast amortized sampling to slower but guaranteed-accurate MCMC when necessary. By reusing computations across steps, our workflow creates synergies between amortized and MCMC-based inference. We demonstrate the effectiveness of this integrated approach on a generalized extreme value task with 1000 observed data sets, showing efficiency gains (90x faster inference) while maintaining high posterior quality.

## 1 Introduction

In statistics, we often reason about unknown parameters \(\) from observables \(y\) modeled as a joint distribution \(p(,y)\). The posterior \(p(\,|\,y)\) is the statistically optimal solution to this inverse problem, and there are different computational approaches to approximate this costly distribution.

Markov chain Monte Carlo (MCMC) methods constitute the most popular family of sampling algorithms due to their theoretical guarantees and powerful diagnostics [6; 7]. MCMC methods yield autocorrelated draws conditional on a fixed data set \(y_{}\). As a consequence, the probabilistic model has to be re-fit for each new data set, which necessitates repeating the entire MCMC procedure from scratch. For such algorithms performed conditionally on a fixed data set, the well-established _Bayesian workflow_ defines an iterative sequence of steps that encompasses model specification, fitting, evaluation, addressing computational issues, modifications, and model comparison.

Differently, _amortized Bayesian inference_ uses deep neural networks to learn a direct mapping from observables \(y\) to the corresponding posterior \(p(\,|\,y)\). Amortized inference follows a two-stage approach: (i) a training stage, where neural networks learn to distill information from the probabilistic model based on simulated examples of observations and parameters \((,y) p()\,p(y\,|\,)\); and (ii) an inference stage where the neural networks approximate the posterior distribution for an unseen data set \(y_{}\) in near-instant time without repeating the training stage. The Bayesian workflow is not directly transferable to amortized inference because the approximation step is learned over the prior predictive space (see Section 2) while only the inference step is conditional on a fixed data set.

In Bayesian inference, both MCMC (e.g., ChEES-HMC; ) and amortized inference lie at the Pareto front of methods that have a favorable trade-off between accuracy and speed. In this paper, we propose an adaptive workflow that yields high-quality posterior draws while minimizing the required compute time by _moving along the Pareto front_ to afford fast-and-accurate inference when possible, and slow-but-guaranteed-accurate inference when necessary (see Figure 1). Crucially, our workflow consistently yields high accuracy, as evaluated with tailored diagnostics in all steps. Furthermore, it re-uses computations for subsequent steps in the form of importance sampling proposals and initializations of many-short-chains MCMC. The software implementation encompasses an end-to-end workflow featuring model specification via PyMC , amortized inference with deep learning via BayesFlow, and GPU-enabled ChEES-HMC  via Tensorflow Probability .

## 2 Integrating Amortized Inference into the Bayesian Workflow

Our adaptive workflow starts with neural network training to enable subsequent amortized inference on any number of unseen data sets. While this training phase is conceptually identical to standalone amortized inference training, the inference phase features a principled control flow that guides the analysis based on tailored diagnostics in order to select the appropriate inference algorithm for each observed data set while re-using computations along the way.

### Training phase: simulation-based optimization

Since most Bayesian models are generative by design, we can readily simulate \(M\) tuples of parameters and corresponding observations from the joint model,

\[(^{(m)},y^{(m)}) p(,y)^{(m)}  p(),\ y^{(m)} p(y\,|\,)\ m=1,,M\] (1)

which results in the training set \(\{(^{(m)},y^{(m)})\}_{m=1}^{M}\).2 The total number \(M\) of example tuples is called the _training budget_, and the quality of the amortized posterior estimator hinges on a sufficient training budget. In the case study, we use flow matching  as a flexible neural estimators, but our workflow is agnostic to the exact choice of neural network architecture.

Diagnostics.At this point, there are no observed data sets yet to guide data-conditional diagnostics. However, we can easily simulate a synthetic _test set_\(\{(_{*}^{(j)},y^{(j)})\}_{j=1}^{J}\) of size \(J\) from the joint model via Eq. 1. In this _closed-world_ setting, we know which "true" parameter vector \(_{*}^{(j)}\) generated each simulated test data set \(y^{(j)}\). We evaluate the amortized posterior's bias and variance via

Figure 1: Our workflow adaptively moves along the Pareto front and re-uses previous computations.

Figure 2: Our adaptive workflow leverages near-instant amortized posterior sampling when possible and gradually resorts to slower – but more accurate – sampling algorithms. As indicated by the blue dashed arrows, we re-use the \(S\) draws from the amortized posterior in step 1 for the subsequent steps in the form of PSIS proposals (step 2) and initial values in ChEES-HMC (step 3).

the normalized root mean-squared error (NRMSE) and perform simulation-based calibration (SBC; [19; 21]) checking to evaluate the uncertainty calibration. These evaluations act as a convergence diagnostic to assert that the neural estimator yields faithful posterior draws under idealized conditions (see Appendix A for details). If these closed-world convergence diagnostics fail, we should tune the training hyperparameters (e.g., training duration, simulation budget, neural network architecture).

### Inference phase: posterior approximation on observed data sets

We now use the pre-trained neural network to achieve rapid amortized posterior inference on a total of \(K\) observed data sets \(\{y_{}^{(k)}\}_{k=1}^{K}\), which naturally do not come with known ground-truth parameters. The diagnostics in this step are evaluated conditional on each observed data set to determine whether the whole set of amortized draws is acceptable for each specific data set.

#### 2.2.1 Step 1: Amortized posterior draws

We aim to use the rapid sampling capabilities of the amortized posterior approximator \(q_{}\) whenever possible according to the diagnostics. Therefore, the natural first step for each observed data set \(y_{}^{(k)}\) is to query the amortized posterior and sample \(S\) posterior draws \(_{1}^{(k)},,_{S}^{(k)} q_{}(\,| \,y^{(k)})\) in near-instant time (see Figure 2, first panel).

Diagnostics.Amortized inference may yield unfaithful results under distribution shifts [11; 20; 23]. Therefore, we assess whether an observed data set is atypical under the data-generating process of the joint model. We define atypical data as data sets that have a larger maximum mean discrepancy (MMD; ) to the training set than 95% of the training data sets themselves and frame this decision problem as a sampling-based hypothesis test, as proposed by . The method is illustrated in Figure 3 and formalized in Appendix B. Since the amortized approximator has no accuracy guarantees for data outside of the typical set of the joint model, we propagate such atypical data sets to the next step. Additional data-conditional diagnostics (e.g., posterior predictive checking) can complement our sampling-based atypicality test to evaluate the trustworthiness of the amortized posterior draws.

#### 2.2.2 Step 2: Pareto-smoothed importance sampling

As a first pursuit to improve the quality of the amortized posterior draws with a small overhead in computation time, we use a Pareto-smoothed sampling importance sampling (PSIS) scheme  (see Figure 2, second panel). Based on the amortized posterior draws from step 1, we compute the importance weights \(w_{s}^{(k)}=p(y^{(k)}\,|\,_{s})\,p(_{s})/q_{}( {}_{s}\,|\,y^{(k)})\) conditional on each observed data set \(y^{(k)}\) and smooth the tail of the weight distribution based on fitting a generalized Pareto distribution (aka. Pareto-smoothing; ). These smoothed importance weights are then used for computing posterior expectations and for improving the posterior draws with the sampling importance resampling (SIR) scheme . While the utility of standard importance sampling for improving neural posterior draws has previously been investigated , we specifically use the PSIS algorithm which is self-diagnosing and therefore better suited for a principled workflow.

Note.Common neural architectures for amortized inference (e.g., normalizing flows, flow matching) are mode covering.3 When the neural network training stage is insufficient (e.g., small simulation budget or poorly optimized network), this may lead to overdispersed posteriors. Fortunately, this errs in the right direction, and PSIS can generally mitigate overdispersed mode-covering draws.

Figure 3: Illustration of our sampling-based hypothesis test that flags atypical data sets where amortized inference has no accuracy guarantees

Diagnostics.We use the Pareto-\(\) diagnostic to gauge the fidelity of the PSIS-refined posterior draws. According to established guidelines [22; 24], Pareto-\( 0.7\) indicates good results, whereas \(>0.7\) implies that the draws should be rejected and the respective data sets proceed to step 3.

#### 2.2.3 Step 3: ChEES-HMC with amortized initializations

If Pareto-smoothed importance sampling fails according to the diagnostics, we resort to an MCMC sampling scheme which is augmented by re-using computations from the previous steps. Concretely, we use the ChEES-HMC algorithm  that affords to launch thousands of parallel chains on a GPU. To accelerate convergence, we use the importance weights from step 2 to sample \(S\) (e.g., 16) unique draws for initializing \(S\) ChEES-HMC superchains4, each with \(L\) (e.g., 128) subchains for the nested-\(\) diagnostic below. For the purpose of ChEES-HMC initialization, it is also desirable that the amortized posterior draws are generally mode covering (cf. step 2).

Diagnostics.In this last step, we use the nested \(\) diagnostic  which is specifically designed to assess the convergence of the many-but-short MCMC chains. If the diagnostics in this step indicate unreliable inference, we recommend resorting to the overarching Bayesian workflow  and addressing the computational issues that even persist when using the (ChEES-)HMC algorithm. This could involve using the established NUTS-HMC algorithm ([3; 10]) or revising the Bayesian model.

## 3 Empirical Demonstration: Generalized Extreme Value Distribution

In this section, we illustrate the application of the proposed workflow with Bayesian inference on the parameters of a generalized extreme value (GEV) distribution. The GEV distribution is characterized by three parameters: a location parameter \(\), a scale parameter \(_{>0}\), and a shape parameter \(\), with cumulative distribution function

\[G(y)=\{-[1+()]^{-1/} \},\] (2)

and we use the prior distributions from Caprani et al.  (see Appendix C for details). Given \(N=65\)\(i.i.d.\) observations \(y=(y_{1},,y_{65})\) from the GEV distribution, we aim to compute a posterior estimate for the data-generating parameters \(=(,,)\). We first train the amortized posterior approximator on simulated parameters and verify that its closed-world performance is satisfactory, as indexed by high parameter recovery and excellent calibration (see Appendix C).

As summarized in Table 1, we perform inference on a total of \(K=1000\) test data sets which are deliberately sampled from a model with a \(2\) wider prior distribution to emulate out-of-distribution settings in real applications (see Appendix C for details). In step 1, we draw 2000 posterior samples from the amortized approximator \(q_{}\), which takes \(150\) seconds for all 1000 data sets (2 million posterior draws in total). We confirm that \(678/1000\) observed data sets are typical under the data-generating process and accept the amortized draws. The remaining 322 data sets are passed to stage 2, where we apply the PSIS algorithm, taking a total of \(130\) seconds. The Pareto-\(\) diagnostic signals acceptable results for \(228\) of the 322 data sets, which means that we propagate the remaining \(94\) data sets to stage 3. Here, we initialize the parallel ChEES-HMC sampler with the amortized draws and observe that the nested \(\) values lie below \(1.01\) for \(66\) of the data sets, leading to acceptance of the ChEES draws. This leaves only \(28\) data sets for separate inference with NUTS-HMC. In total, our amortized Bayesian workflow took \( 10\) minutes and led to high-quality posterior draws on all steps, as indicated by a small MMD to a reference posterior. In contrast, running NUTS-HMC on all 1 000 observed test data sets would have taken \(\) 955 minutes (16 hours), which underscores the efficiency gains of our integrated workflow.

Figure 4: We initialize many ChEES-HMC chains with amortized draws.

**Amortized draws can be good ChEES-HMC ints.** To further investigate whether the amortized posterior estimates are indeed beneficial for initializing ChEES-HMC chains, we randomly collect 20 test datasets that are passed to step 3 in the workflow. This indicates that both the amortized posterior draws and their Pareto-smoothed refinement are deemed unacceptable, as quantified by Pareto-\(>0.7\) in step 2. We initialize the ChEES-HMC chains with three different methods: (1) Amortized posterior draws, (2) PSIS-refined amortized draws, and (3) a random initialization scheme similar to Stan .We run the chains for different numbers of warmup iterations followed by a single sampling iteration. As described in Section 2, we use the nested \(\) value to gauge whether the chains converged appropriately during the warmup stage (as quantified by common \(-1\) thresholds of \(10^{-1}\) or \(10^{-2}\)). As shown in Figure 5, amortized posterior draws (and their PSIS-refined counterparts) can significantly reduce the required number of warmup iterations to achieve convergence of ChEES-HMC chains, _even though the draws themselves have previously been flagged as unacceptable_. This emphasizes that our amortized workflow creates synergies by re-using computations in subsequent steps. However, it is not evident whether initializing ChEES-HMC with the PSIS-refined draws from step 2 has an advantage over using the raw amortized draws from step 1, and we mainly see that PSIS improves the worst-case performance (upper error boundary in Figure 5).

## 4 Conclusion

We presented an adaptive Bayesian workflow to combine the rapid speed of amortized inference with the undisputed sampling quality of MCMC in the context of many observed data sets while maintaining a high quality of posterior draws. Our workflow efficiently uses resources by (i) using fast (amortized) inference when the results are accurate; (ii) refining draws with PSIS when possible; and (iii) amortized initializations of slow-but-guaranteed-accurate MCMC chains when needed.

#### Acknowledgments

MS and PB acknowledge support of Cyber Valley Project CyVy-RF- 2021-16, the DFG under Germany's Excellence Strategy - EXC-2075 - 390740016 (the Stuttgart Cluster of Excellence SimTech). MS acknowledges travel support from the European Union's Horizon 2020 research and innovation programme under grant agreements No 951847 (ELISE) and No 101070617 (ELSA), and support from the Aalto Science-IT project. CL and LA were supported by the Research Council of Finland (grants number 356498 and 358980 to LA). AV acknowledges the Research Council of Finland Flagship program: Finnish Center for Artificial Intelligence, and Academy of Finland project 340721.