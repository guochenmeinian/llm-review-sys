# Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery

Haonan Lin\({}^{1}\)   Wenbin An\({}^{2}\)   Jiahao Wang\({}^{1}\)   Yan Chen\({}^{1}\)   Feng Tian\({}^{1}\)

&Mengmeng Wang\({}^{3,4}\)   Guang Dai\({}^{4}\)   Qianying Wang\({}^{5}\)   Jingdong Wang\({}^{6}\)

\({}^{1}\) School of Comp. Science & Technology, MOEKLINNS Lab, Xi'an Jiaotong University

\({}^{2}\) School of Auto. Science & Engineering, MOEKLINNS Lab, Xi'an Jiaotong University

\({}^{3}\) College of Comp. Science & Technology, Zhejiang University of Technology

\({}^{4}\) SGIT AI Lab, State Grid Corporation of China

\({}^{5}\) Lenovo Research   Baidu Inc

Corresponding Authors.

Equal contribution.

This work was partly completed during the internship at SGIT AI Lab, State Grid Corporation of China.

###### Abstract

Recent advancements have shown promise in applying traditional Semi-Supervised Learning strategies to the task of Generalized Category Discovery (GCD). Typically, this involves a teacher-student framework in which the teacher imparts knowledge to the student to classify categories, even in the absence of explicit labels. Nevertheless, GCD presents unique challenges, particularly the absence of priors for new classes, which can lead to the teacher's misguidance and unsynchronized learning with the student, culminating in suboptimal outcomes. In our work, we delve into why traditional teacher-student designs falter in open-world generalized category discovery as compared to their success in closed-world semi-supervised learning. We identify inconsistent pattern learning across attention layers as the crux of this issue and introduce FlipClass--a method that dynamically updates the teacher to align with the student's attention, instead of maintaining a static teacher reference. Our teacher-student attention alignment strategy refines the teacher's focus based on student feedback from an energy perspective, promoting consistent pattern recognition and synchronized learning across old and new classes. Extensive experiments on a spectrum of benchmarks affirm that FlipClass significantly surpasses contemporary GCD methods, establishing new standards for the field.

## 1 Introduction

Teacher-Student architecture has proved its effectiveness in Semi-Supervised Learning (SSL) , which aims to take advantage of a large collection of unlabeled data, reducing the expensive costs of annotation  . Previous approaches tend to model \(p\)(student[teacher], where the teacher typically acts as a fixed point of reference, providing a form of "supervision prior" to guide the student . This supervision comes from labeled data and is asymmetrical: while the teacher has robust prior knowledge and provides a stable learning signal, the student's knowledge is incomplete and evolving. The student learns from both the teacher's supervision and the data it is exposed to, trying to emulate the teacher by aligning its predictions with those of the teacher.

Teacher-Student designs traditionally rely on a closed-world assumption, where it is expected that the teachers have supervision prior to all classes they will face while instructing students [61; 3]. However, real-world applications often involve dynamic and open environments, where instances belonging to new classes may appear [84; 30; 31; 41]. In such cases, discovering novelties could enable models to adapt new information and evolve continually as biological systems do [14; 49]. Recently, Generalized Category Discovery (GCD)  stands out by challenging models to categorize unlabeled data containing both old and new classes using only partial labels for training. Although recent GCD methods have adapted closed-world Teacher-Student strategies with notable success [75; 50], the transition is not seamless and presents several challenges.

**Challenge I: Learning gap.** Fig. 1 top left illustrates the learning evolution of student and teacher. The previous teacher-student models result in unsynchronized learning and a significant learning gap in new classes. The ideal learning dynamic between the teacher and student should be cohesive, which requires teaching students in accordance with their aptitude.

**Challenge II: Discrepancies in features.** The learning gap arises from the teacher's fast pace, leading to large discrepancies in representations between weakly-augmented data (teacher) and strongly-augmented data (student), especially for new classes (Fig. 1 middle). This causes significant prediction differences, making consistency loss optimization difficult and hindering effective student learning. Over time, the iterative learning process exacerbates this misalignment.

**Challenge III: Attention inconsistency.** Inadequate supervision for new classes leads to inaccurate instructions from the teacher, causing the student to focus on different parts than the teacher (Fig. 1 right). Imagine a classroom transitioning to a new subject. Without proper guidance, students' attention diverges from the teacher's, resulting in confusion and ineffective learning.

To sum up, the challenges of previous teacher-student models arise from inadequate supervision on new classes and the gap between weakly and strongly augmented data. This results in attention inconsistency (Chall. III), which leads to discrepancies in predictions and representations (Chall. II), ultimately causing a significant performance gap (Chall. I). Addressing these challenges requires developing teacher-student dynamics that align the evolving knowledge of both teacher and student (Fig. 1, bottom left). These findings lay the foundation for our approach, _FlipClass_, which models the teacher's posterior \(p\)(teacher|student) from the energy perspective of attention, building an adaptive teacher to bridge the learning gap. _FlipClass_ offers a plug-and-play solution to foster an interactive learning environment where the student can influence the teacher's guidance in real-time, allowing teachers to tailor their instructions based on students' current attention [7; 1]. By aligning attention, _FlipClass_ ensures that the learning pace of the teacher and student is in sync, leading to improvement on both old and new classes. Our contributions are summarized as:

Figure 1: Left: Learning effects of traditional Teacher-Student Consistency Model (TSCM, _e.g._, SimGCD ) and our Flipped Classroom Consistency Model (_FlipClass_) on Stanford Cars . Middle: Model comparison between TSCM and our FlipClass, where \(^{}\) refers to data belonging to new classes. Right: Illustration of the inner feedback mechanism in FlipClass, where teacher attention is adapted to the student, leading to the alignment of attention.

**(1) Empirical analysis**: We highlight the challenge of applying the closed-world Teacher-Student paradigm to the open-world scenario of GCD. Our in-depth analysis identifies attention misalignment between teacher and student as the key issue hindering synchronized learning between them.

**(2) Methodology**: Based on these analyses, we propose a flexible and effective method, _FlipClass_, which enables teachers to adapt and respond to student feedback to synchronize their learning progress, thereby leading to an overall improvement in teaching outcomes.

**(3) Superiority**: _FlipClass_ consistently outperforms state-of-the-art generalized category discovery methods on both coarse-grained and fine-grained datasets.

## 2 Background

We first provide some background on semi-supervised learning and generalized category discovery to better contextualize our analysis. Let us consider a data set \(\) consisting of labeled data \(_{L}=\{(_{i}^{},y_{i})\}_{i=1}^{N_{L}}\) from \(|_{K}|\) old classes and unlabeled data \(_{U}=\{_{j}^{u}\}_{j=1}^{N_{U}}\) that may contain instances from both old classes \(_{K}\) and new classes \(_{N}\), with \(=_{K}_{N}\). For a data instance \(\), let \(p_{}(y f_{}())\) denote the predicted class distribution produced by the model \(f\).

### Integrating SSL Techniques into a Consistency Loss Framework

In semi-supervised learning (SSL), the goal is to enhance model performance by leveraging unlabeled data, traditionally drawn from the same class spectrum as the labeled data . The goal of SSL can be formalized by integrating three fundamental techniques: _(1) Consistency regularization_ ensures that the model outputs consistent predictions for augmented versions of the same instance. This technique utilizes different transformations to test the robustness of the model's predictions, promoting stability across variations in the input data [8; 59; 36]. _(2) Pseudo-labeling_ utilizes the model to generate artificial labels for unlabeled data by adopting "hard" labels (that is, the argmax of the model output) and keeping only the labels where the highest class probability exceeds a predefined threshold [62; 47; 57; 37; 23]. _(3) Teacher-Student model_ incorporates a structured learning relationship where the **teacher** model, typically trained on weakly-augmented instances, generates high-quality pseudo labels. These pseudo labels are then used to guide the training of the **student** model, which processes strongly-augmented instances. This approach helps improve the generalization capabilities of the student model by learning from the refined knowledge and stable supervision signals provided by the teacher [66; 43; 77; 12; 53]. Several methods integrate some of these techniques and achieve advanced performance in SSL [63; 83; 78; 87]. We unify these SSL techniques into one consistency loss:

\[_{}=_{U}|}_{ _{U}}Hp_{}y f_{}(() ),\,p_{}y f_{}(()) ,\] (1)

Figure 2: Exploring prior gaps between SSL and GCD on SCars and CUB datasets. Left: Accuracy of sorted pseudo labels for old and new classes. Middle: Consistency loss trends over epochs, illustrating challenges in optimization and slower convergence for new classes. Right: Categorize errors , where “True Old” refers to predicting an ‘Old’ class sample to another ‘Old’ class, while ‘False Old” indicates predicting an ‘Old’ class sample as some ‘New’ class.

where cross-entropy \(H(,)\) measures _consistency for regularization_, while the prediction \(p_{}(y f_{}())\) serves as a _pseudo label_. This setup captures a _teacher-student dynamic_, where \(()\) and \(()\) represent the **teacher** (weakly-augmented) and **student** (strongly-augmented) instances, respectively.

### Class Prior Gap between SSL and GCD

The GCD task pushes the boundaries of SSL by questioning the closed-world assumption that all classes in the unlabeled dataset \(_{U}\) are previously known . Instead, GCD incorporates new classes \(_{N}\) into the unlabeled dataset, demanding that the model learn to recognize and then correctly classify them [4; 21; 80; 5]. In this open-world setting, SSL methods face obstacles with new classes due to the lack of supervision [24; 56], resulting in significantly lower quality of pseudo-labels for these new classes than for the old ones (Fig. 2 left). This gap exacerbates the complexity of optimizing the consistency loss Eq. 1 for new classes, leading to learning instability and slow convergence (Fig. 2, middle). Such optimization issues lead to severe prediction bias, resulting in new classes' performance lagging behind that of old classes (Fig. 2, right), underlining the limitations of existing SSL techniques in GCD scenarios. More empirical analysis can be found in _Appendix_B.2.

## 3 How Consistency Loss Goes Awry: Unraveling the Pitfalls

Acknowledging challenges presented by the absence of prior knowledge for new classes in traditional semi-supervised learning (SSL) methods is the first step toward addressing the complexities of open-world tasks. We further identify that the 'prior gap' manifests as issues in learning synchronization and representation discrepancy (Sec. 3.1). Our analysis targets the minimization of the energy function between teacher and student representations to bridge the 'prior gap'. We find that aligning their attention on similar patterns reduces energy, indicating effective alignment and learning (Sec. 3.2). This key understanding paves the way for the development of our proposed methods, aiming to synchronize teacher-student attentions for improved model learning dynamics (Sec. 4).

### What to Bridge the Class Prior

The challenge of optimizing consistency loss leads to a learning gap between the student and the teacher, particularly evident when dealing with new classes (Fig. 1 top left). This gap causes the student to plateau, as it cannot keep pace with the teacher's more advanced understanding, which in turn restricts the teacher's progress in new classes Moreover, this learning gap also manifests itself in the divergent representations between teacher and student (Fig. 1 middle), specifically for new classes. Based on these observations, we revisit consistency loss (Eq. 1) in the closed-world setting.

**Insight 3.1**.: _The large discrepancy between \(f_{}((x))\) and \(f_{}((x))\) complicates maintaining consistency across the model predictions. To narrow this divide, an intuitive idea is to align \(f_{}(())\) more closely with \(f_{}(())\), simplifying the optimization of \(_{cons}\):_

\[_{}=_{U}|}_{ _{U}}dp_{}y f_{}(())-,p_{}y f_{}(( )),\] (2)

_where \(\) aims to pull \(f_{}(())\) closer to \(f_{}(())\). Ideally, \(\) would be adaptive, scaling with the discrepancy between \(f_{}((x))\) and \(f_{}((x))\), while avoiding make them too similar, which enables model to find a shortcut of \(_{cons}\)._

To design it, we delve into the vision transformer, a representation encoder that has significantly advanced the performance of the GCD task. We found that the self-attention mechanism excels at capturing critical image patterns: as depicted in Fig. 3 left, deeper features (after the 8th layer) reveal semantic, high-level commonalities (_e.g._, car shell) across all images; and the shallow features are more attuned to high-frequency, low-level details (_e.g._, color and texture).

### Inconsistent Patterns Spoil the Whole Barrel

Inconsistent patterns can disrupt learning, making it crucial to align stored and queried patterns effectively. To address this, we draw inspiration from the Hopfield Network  -- an associative memory model known for its energy-based mechanism that naturally pulls similar patterns together (see _Appendix_ A.1 for details). We follow Ramsauer et al. to define the energy function for a state pattern (query) \(^{d}\), parameterized by \(N\) stored (key) patterns \(=[_{1},,_{N}]^{d N}\):

\[E(;)=^{}-}( ^{},)+c,}(,):=^{-1}(_{i=1}^{N} (_{i})).\] (3)

Minimizing \(E(;)\) resembles retrieving stored pattern \(_{i}\) that is most similar to the query \(\), and _log-sum-exp_ (\(}\)) function is parameterized by \(>0\) and \(c\) is a preset constant. Particularly, the first term ensures the finiteness of the query, while the second term measures the alignment of the query with each stored pattern. The update rule for a state pattern \(\) is equivalent to a gradient descent update of minimizing the energy \(E\) with step size \(=1\), ensures that the query moves closer to the most similar stored pattern:

\[-_{}E(;)=-}(^{})^{}.\] (4)

Moreover, the energy function is closely related to the Transformer's self-attention mechanism  (_Appendix_ A.1.2). By extending the energy model from self-attention to cross-attention, we model the dynamics between student and teacher learning patterns. Taking the student representations \(_{s}=f(())\) as examples, we have \(_{s}=_{s}_{Q}\) and \(_{s}=_{s}_{K}\). By applying Eq. 3 to key and query matrices, we set energy functions to track the teacher-student relationship:

\[E(_{s};_{t})=( _{t}_{t}^{T})-_{i=1}^{N}}(_{ s}_{t,i}^{T},)+c,\] (5a) \[E(_{t})=}(( _{t}_{t}^{T}),1)=_{i=1}^{N}(_{t,i}_{t,i}^{T})+c,\] (5b)

where \(E(_{s};_{t})\) indicates the alignment in learning patterns of the student and teacher; \(_{t,i}\) denotes the \(i\)-th row vector of \(_{t}\) and \( 0\). Intuitively, \(}(_{s}_{t,i}^{T},)\) captures the smooth maximum alignment between student queries \(_{s,i}\) and teacher keys \(_{t,i}\). Specifically, it nudges each teacher key \(_{t,j}\) towards a semantic alignment with its most corresponding student query \(_{s,j}\). The regularization term \((_{t}_{t}^{T})\) acts as a constraint on the energy levels of teacher's representation \(_{t,i}\), guarding against any disproportionate increase during the maximization of \(}(_{s}_{t,i}^{T},)\). This ensures that no individual teacher representation becomes too closely mirrored in the student's representation, maintaining a diverse learning trajectory.

**Insight 3.2**.: _When applying closed-world consistency regularization to the GCD task, it becomes difficult to gradually reduce the energy \(E(_{s};_{t})\) as training progresses (Fig. 3 right). The sustained high energy demonstrated a flaw in the previous methods: teachers and students focused on identifying patterns that were inconsistent, leading to divergent learning paths. Specifically, when teachers and students focus on similar patterns (e.g., taillights), energy is reduced, indicating better prediction consistency and effective learning. In contrast, when their attention is distracted, the energy rises, leading to severe inconsistencies in predictions and making the optimization of \(_{cons}\) more difficult._

Figure 3: Left: Attention heatmaps for teacher and student across attention layers. Right: Energy trend over epochs, with lower energy indicating less discrepancy in pattern recognition between teacher and student.

FlipClass: Teacher-Student Attention Alignment

### Teacher Attention Update Rule

Based on Insights 3.1 and 3.2, our objective is to minimize the energy function \(E(_{s};_{t})\) between teacher and student representations, thereby easing the optimization of \(_{}\).

**Theorem 4.1**.: _The minimization can be formulated as obtaining a maximum a posteriori probability (MAP) estimate of teacher keys \(_{t}\) given a set of observed student queries \(_{s}\):_

\[p(_{t}|_{s})=_{s}|_{t})p( _{t})}{p(_{s})},\] (6)

_where \(p(_{s}|_{t})\) and \(p(_{t})\) are modeled by energy functions Eq. 5a and 5b, respectively. We approximate the posterior inference by the gradient of the log posterior, estimated as:_

\[_{_{t}} p(_{t}| _{s})&=-(_{_{t}}E(_{s}; _{t})+_{_{t}}E(_{t}))\\ &=sm(_{s}_{t}{}^{T})_{s}-(+(sm(( _{t}_{t}{}^{T}))))_{t},\] (7)

_where \(sm():=(-(,1))\) and \(()\) is a vector-to-diagonal-matrix operator. Incorporating Eq. 4, the update rule of teacher keys \(_{t}\) is derived as follows:_

\[_{t}^{update}=_{t}+_{update}[\,(sm( ^{T})_{K}^{T})-_{}(+(sm( (^{T})))_{K}^{T})],\] (8)

_where \(\), \(_{update}\) and \(_{}\) are hyper-parameters._

For a proof, refer to _Appendix_ A.2. The teacher-attention update rule in Theorem 4.1 minimizes an implicit energy function determined by student queries and teacher keys. It serves as using the student queries to search for the most similar teacher patterns in the stored set. As illustrated in Fig. 4, the update rule adjusts the teacher's attention in the direction of student attention, facilitating the retrieval of related patterns and improving semantic alignment. This design establishes a bidirectional information flow: the teacher not only imparts advanced knowledge to the student, but also adjusts guidance based on the student's learning effects, achieving a more cohesive learning dynamic.

### Representation Learning and Parametric Classification

Contrastive learning plus consistency regularization under the parametric paradigm has been demonstrated effective in GCD task . Formally, given two views (random augmentations \(_{i}\) and \(_{i}^{}\)) of the same image in a mini-batch \(\), the supervised and self-supervised contrastive loss is written as:

\[_{}^{s}=^{}|}_{i ^{}}_{i}|}_{q_{i}}- _{i}^{T}z_{q}^{}/_{c})}{_{i^{} i }(_{i}^{T}z_{i^{}}^{}/_{c})},\] \[_{}^{u}=|}_{i }-_{i}^{T}_{i}^{}/_{u} )}{_{i^{} i}(_{i}^{T}z_{i^{}}^{}/_ {u})},\]

where the feature \(_{i}=f(_{i})\) and is \(_{2}\)-normalised, and \(_{u}\), \(_{c}\) are temperature values. For \(_{}^{s}\), \(_{i}\) indexes all other images in the same batch that hold the same label as \(_{i}\). The representation learning loss is balanced with \(\): \(L_{}=(1-)L_{}^{u}+ L_{}^{s}\), where \(^{}\) corresponds to the labeled subset of \(\).

Figure 4: **Framework of _FlipClass_ demonstrating teacher-student interaction, where teacher’s and student’s attention is aligned by teacher’s updating (Eq. 8). Then \(_{}\) and \(_{}\) are combined for optimization.

The consistency regularization objectives (Eq. 1) are then simply cross-entropy loss \((q^{},p)=-_{k}q^{}(k) p(k)\) between the predictions and pseudo-labels or ground-truth labels:

\[_{}=|}_{i}(q^{}_{i},p_{i})- H()&\\ |}_{i^{}}(y_{i},p_{i})&\]

The one-hot labels \(y_{i}\) correspond to \(_{i}\), and the soft pseudo-label \(q^{}_{i}\) is produced by the teacher instance \(()_{i}\). Moreover, a mean-entropy regularizer , \(H()=-_{k}(k)(k)\), is included to encourage diverse predictions. The combined classification loss, \(_{}\), balances unsupervised and supervised terms with a parameter \(\). And the overall training objective is \(_{}+_{}\).

## 5 Experiments

### Experimental Settings

**Datasets.** We evaluate the effectiveness of _FlipClass_ on three generic image recognition datasets (_i.e._, CIFAR-10/100  and ImageNet-100 ), three fine-grained datasets  (_i.e._, CUB , Stanford Cars , and FGVC-Aircraft ) contained in Semantic Shift Benchmark (SSB) , and the challenging datasets Herbarium-19 , ImageNet-1k . For each dataset, we first subsample \(|_{l}|\) seen (labeled) classes from all classes. Following GCD , we subsample 80% samples in CIFAR-100 and 50% samples in all other datasets from the seen classes to construct \(_{l}\), while the remaining images are treated as \(_{u}\) (refer to Table 9).

**Evaluation Protocols.** The performance was evaluated by measuring accuracy between the model's cluster assignments and ground-truth labels on the test set, with three aspects: all instances (All), instances from old categories (Old), and instances from new categories (New). The number of categories in the unlabeled dataset (\(|_{u}|\)) is often unknown. Following previous studies [64; 85], we set \(K\) (cluster number) equal to \(|_{u}|\), as approximate cluster estimation is usually feasible in the real world. The estimation of the number of categories in unlabeled datasets can be found in the _Appendix_ C.4. Further implementation details can be found in Appendix D.1.

   &  &  &  &  \\   & & All & Old & New & All & Old & New & All & Old & New & Avg. \\  GCD  & DINO & 51.3 & 56.6 & 48.7 & 39.0 & 57.6 & 29.9 & 45.0 & 41.1 & 46.9 & 45.1 \\ XCon  & DINO & 52.1 & 54.3 & 51.0 & 40.5 & 58.8 & 31.7 & 47.7 & 44.4 & 49.4 & 46.8 \\ CIPR  & DINO & 57.1 & 58.7 & 55.6 & 47.0 & 61.5 & 40.1 & - & - & - & - & - \\ PCAL  & DINO & 62.9 & 64.4 & 62.1 & 50.2 & 70.1 & 40.6 & 52.2 & 52.2 & 52.3 & 55.1 \\ SimGCD  & DINO & 60.3 & 65.6 & 57.7 & 53.8 & 71.9 & 45.0 & 54.2 & 59.1 & 51.8 & 56.1 \\ AdaptGCD  & DINO & 66.6 & 66.5 & 66.7 & 48.4 & 57.7 & 39.3 & 53.7 & 51.1 & 56.0 & 56.2 \\ AMEND  & DINO & 64.9 & 75.6 & 59.6 & 56.4 & 73.3 & 48.2 & 52.8 & 61.8 & 48.3 & 58.0 \\ GCA  & DINO & 68.8 & 73.4 & 66.6 & 54.4 & 72.1 & 45.8 & 52.0 & 57.1 & 49.5 & 58.4 \\ TIDA  & DINO & - & - & - & 54.7 & 72.3 & 46.2 & 54.6 & 61.3 & 52.1 & - \\ _uGCD_  & DINO & 65.7 & 68.0 & 64.6 & 56.5 & 68.1 & 50.9 & 53.8 & 55.4 & 53.0 & 58.7 \\ CMS  & DINO & 68.2 & 76.5 & 64.0 & 56.9 & 76.1 & 47.6 & 56.0 & 63.4 & 52.3 & 60.4 \\ InfoSieve  & DINO & 69.4 & **77.9** & 65.1 & 55.7 & 74.8 & 46.4 & 56.3 & 63.7 & 52.5 & 60.5 \\ SPTNet  & DINO & 65.8 & 68.8 & 65.1 & 59.0 & 79.2 & 49.3 & **59.3** & 61.8 & **58.1** & 61.4 \\  FlipClass (Ours) & DINO & **71.3** & 71.3 & **71.3** & **63.1** & **81.7** & **53.8** & **59.3** & **66.9** & 55.4 & **64.6** \\ Improvement & DINO & +5.5 & +2.5 & +6.2 & +4.1 & +2.5 & +4.5 & +0.0 & +5.1 & -2.7 & +3.2 \\   GCD  & DINOv2 & 71.9 & 71.2 & 72.3 & 65.7 & 67.8 & 64.7 & 55.4 & 47.9 & 59.2 & 64.3 \\ SimGCD  & DINOv2 & 71.5 & 78.1 & 68.3 & 71.5 & 81.9 & 64.6 & 49.9 & 60.9 & 60.0 & 63.0 \\ \(\)GCD  & DINOv2 & 74.0 & 75.9 & 73.1 & 76.1 & **91.0** & 68.9 & 66.3 & 68.7 & 65.1 & 72.1 \\  FlipClass (Ours) & DINOv2 & **79.3** & **80.7** & **78.5** & **78.0** & 88.0 & **73.2** & **71.1** & **75.1** & **69.1** & **76.1** \\ Improvement & DINOv2 & +5.3 & +4.8 & +5.4 & +1.9 & -3.0 & +4.3 & +4.8 & +6.4 & +4.0 & +4.0 \\  

Table 1: Evaluation on the Semantic Shift Benchmark (SSB). Bold values represent the best results, while underlined values represent the second-best results.

### Experimental Results

We compare SOTA methods with ours in GCD using features from both DINO  and DINOv2 . Our approach shows significant performance improvement, particularly in the recognition of 'New' classes across both the SSB fine-grained benchmark (Tab. 1) and generic image recognition datasets (Tab. 2), consistently surpassing existing SOTA methods. Moreover, in fine-grained image classification (Tab. 1), recognizing subtle differences between closely related categories is crucial, which is in contrast to coarse-grained datasets where the visual differences between classes are more obvious. In fine-grained settings, the risk of the model generating incorrect pseudo labels is higher, which makes consistency regularization counterproductive (Sec. 2.2). However, the results across these datasets demonstrate our model's capability to effectively adapt consistency regularization strategies from closed-world settings to more complex open-world scenarios. Moreover, the balanced accuracy between new and old classes on the CUB dataset (Tab. 1), also observed with methods like PCAL, CiPR, and AdaptGCD, can be attributed to the dataset's small size (6,000 images) and large class split (200). This limited data reduces the likelihood of overfitting to old classes, promoting more uniform performance across both categories. Additional results on Herbarium 19 and ImageNet-1k are detailed in the _Appendix_ C.2.

### Analysis and Discussion

**Ablation Studies.** Our ablation study, shown in Fig. 5, underscores the significance of our design choices. First, we replace the student's augmentations with the teacher's, _i.e._, using only weak augmentations, the performance on 'New' classes significantly declines (2nd set of bars). This underscores the importance of **strong augmentations** for the student, which are essential to bolster generalizability. Then we validate the importance of attention alignment in Eq. 8 (3rd set of bars), we see performance drop across both 'Old' and 'New' classes, affirming that our attention alignment strategy is crucial for maintaining a consistent learning pace between the teacher and student, leading to sustained performance gains. Finally, the 4th set of bars verifies the role of **regularization** during

   &  &  &  &  \\   & & All & Old & New & All & Old & New & All & Old & New & Avg. \\  GCD  & DINO & 91.5 & **97.9** & 88.2 & 73.0 & 76.2 & 65.5 & 74.1 & 89.8 & 66.3 & 79.5 \\ AdaptGCD  & DINO & 93.2 & 94.6 & 92.8 & 71.3 & 75.7 & 66.8 & 83.3 & 90.2 & 76.5 & 82.6 \\ InfoSieve  & DINO & 94.8 & 97.2 & 93.7 & 76.9 & 78.4 & 73.9 & 80.5 & 92.8 & 74.4 & 84.1 \\ CiPR  & DINO & 97.7 & 97.5 & 97.7 & 81.5 & 82.4 & 79.7 & 80.5 & 84.9 & 78.3 & 86.6 \\ SimGCD  & DINO & 97.1 & 95.1 & 98.1 & 80.1 & 81.2 & 77.8 & 83.0 & 93.1 & 77.9 & 86.7 \\ GCA  & DINO & 95.5 & 95.9 & 95.2 & 82.4 & 85.6 & 75.9 & 82.8 & 94.1 & 77.1 & 86.9 \\ TIDA  & DINO & 98.2 & **97.9** & 98.5 & 82.3 & 83.8 & 80.7 & - & - & - & - \\ CMS  & DINO & - & - & - & 82.3 & **85.7** & 75.5 & 84.7 & **95.6** & 79.2 & - \\ AMEND  & DINO & 96.8 & 94.6 & 97.8 & 81.0 & 79.9 & 83.8 & 83.2 & 92.9 & 78.3 & 87.0 \\ SPTNet  & DINO & 97.3 & 95.0 & 98.6 & 81.3 & 84.3 & 75.6 & 85.4 & 93.2 & 81.4 & 88.0 \\  FlipClass (Ours) & DINO & **98.5** & 97.6 & **99.0** & **85.2** & 84.9 & **85.8** & **86.7** & 94.3 & **82.9** & **90.1** \\ Improvement & DINO & +1.2 & +2.6 & +0.4 & +3.9 & +0.6 & +10.2 & +1.3 & +1.1 & +1.5 & +2.1 \\   \(*\) GCD  & DINOv2 & 95.2 & 97.8 & 93.9 & 77.3 & 82.8 & 66.1 & 81.3 & 94.3 & 74.8 & 84.6 \\ \(*\) AMEND  & DINOv2 & 97.7 & 96.6 & 98.3 & 83.5 & 83.0 & 84.5 & 87.3 & 95.1 & 83.4 & 89.5 \\  FlipClass (Ours) & DINOv2 & **99.0** & **98.2** & **99.4** & **91.7** & **90.4** & **94.2** & **91.0** & **96.3** & **88.3** & **93.9** \\ Improvement & DINOv2 & +1.3 & +1.6 & +1.1 & +8.2 & +7.4 & +9.7 & +3.7 & +1.2 & +4.9 & +4.3 \\  

Table 2: Evaluation on three generic image recognition datasets.

Figure 5: Ablation study results for FlipClass, indicate the critical role of strong augmentations, attention alignment, and regularization in model performance across multiple datasets.

the attention update, which integrates the prior energy of the teacher, preventing any single student pattern from overly influencing the teacher's attention.

**Enhanced Consistency through Attention Alignment.** To validate our assumption on modeling \(\) in Eq. 2, we showcase how distribution-based strategies (distribution alignment , FixMatch ) and our representation-based method, attention alignment, achieve consistency on new classes from CUB dataset (Fig. 6). Our method stands out by significantly reducing the discrepancy between the representations of teacher (weakly-augmented) and student (strongly-augmented) data. This representation-based alignment leads to a more consistent learning process and is evidenced by the superior accuracies we achieve for both 'Old' and 'New' classes.

**Design Choice of Attention Alignment.** We experimented with various techniques to model \(\) in Eq. 2, including scheduled data augmentation (SDA), increasing similarity between \(_{s}\) and \(_{t}\) via \(_{2}\) norm, Kullback-Leibler divergence (KLD) or CORrelation ALignment (CORAL) loss (see details in _Appendix_ D.1). As shown in Fig. 6(a), our teacher-attention update strategy outperforms these alternatives on both CUB and SCars datasets.

**FlipClass mitigates prediction bias.** We verify the effectiveness and robustness of _FlipClass_, by diagnosing the model's classification errors under four different (\(_{}\)) as defined in Eq. 8. As depicted in Fig. 6(b), both "False New" and "False Old" errors are consistently mitigated--where 'Old' class samples are mistakenly labeled as 'New' and vice-versa. Moreover, as illustrated in Fig.7(b) bottom, _FlipClass_ outperforms leading methods  by moving closer to the true class distribution, yielding higher and less biased accuracies across all classes.

**Does the improved energy dynamic make for performance gains?** Fig. 7(a) top shows that aligning attention in these deeper (9-10) layers yields the highest performance on SCars dataset. And Fig. 7(a) bottom displays a greater reduction of energy \(E(_{s};_{t})\) in deeper layers. Moreover, this trend highlights that attention alignment constantly maintains lower energy levels than without, indicating improved alignment of student patterns with teacher updating.

**How does FlipClass change the representations?** Fig. 7(b) showcases representation enhancements with _FlipClass_ against the leading method, InfoSieve , using the same t-SNE and PCA components to ensure consistent projection space and scale. FlipClass forms clusters with higher compactness and purity, demonstrating enhanced feature discrimination and less inter-class confusion. The zoom-in comparison on CUB dataset is provided in Fig. 9, which showcases that FlipClass achieves more distinct and well-separated clusters. Further, we assess prediction bias and class

Figure 6: Accuracy and representation alignment with different strategies: (1) initial state, (2) distribution alignment, (3) FixMatch, and (4) our teacher-attention update. Performance on ‘New’ and ‘Old’ classes are shown, alongside alignment of teacher (red) and student (blue) representation.

Figure 7: Attention alignment methods comparison and categorize errors with different update rates.

specific accuracies. Unlike InfoSieve's skewed predictions, _FlipClass_ aligns better with true class distributions, and significantly improves over the tail classes in CUB dataset (More experiments in _Appendix_ C.3).

## 6 Conclusion

This paper introduces _FlipClass_, a dynamic teacher-student attention alignment strategy for improving learning synchronization, providing a new view on applying closed-world models to open-world task of GCD. By aligning the attention of teacher and student, _FlipClass_ bridges the learning gap between them, resulting in performance improvement on both old and new classes. Extensive experiments and analysis demonstrate that _FlipClass_ outperforms existing state-of-the-art methods across diverse datasets by a large margin.

## 7 Acknowledgement

This work was supported by National Science and Technology Major Project (2022ZD0117102), National Natural Science Foundation of China (62293551, 62377038,62177038,62277042). Project of China Knowledge Centre for Engineering Science and Technology, Project of Chinese academy of engineering "The Online and Offline Mixed Educational Service System for 'The Belt and Road' Training in MOOC China". "LENOVO-XJTU" Intelligent Industry Joint Laboratory Project.