# Evaluating Robustness and Uncertainty of Graph Models Under Structural Distributional Shifts

Gleb Bazhenov

HSE University, Yandex Research

Correspondence to gv-bazhenov@yandex-team.ru

Denis Kuznedelev

Yandex Research, Skoltech

Andrey Malinin

Isomorphic Labs

Artem Babenko

Yandex Research, HSE University

Liudmila Prokhorenkova

Yandex Research

###### Abstract

In reliable decision-making systems based on machine learning, models have to be robust to distributional shifts or provide the uncertainty of their predictions. In node-level problems of graph learning, distributional shifts can be especially complex since the samples are interdependent. To evaluate the performance of graph models, it is important to test them on diverse and meaningful distributional shifts. However, most graph benchmarks considering distributional shifts for node-level problems focus mainly on node features, while structural properties are also essential for graph problems. In this work, we propose a general approach for inducing diverse distributional shifts based on graph structure. We use this approach to create data splits according to several structural node properties: _popularity_, _locality_, and _density_. In our experiments, we thoroughly evaluate the proposed distributional shifts and show that they can be quite challenging for existing graph models. We also reveal that simple models often outperform more sophisticated methods on the considered structural shifts. Finally, our experiments provide evidence that there is a trade-off between the quality of learned representations for the base classification task under structural distributional shift and the ability to separate the nodes from different distributions using these representations.

## 1 Introduction

Recently, much effort has been put into creating decision-making systems based on machine learning for various high-risk applications, such as financial operations, medical diagnostics, autonomous driving, _etc_. These systems should comprise several important properties that allow users to rely on their predictions. One such property is _robustness_, the ability of an underlying model to cope with _distributional shifts_ when the features of test inputs become different from those encountered in the training phase. At the same time, if a model is unable to maintain high performance on a shifted input, it should signal the potential problems by providing some measure of _uncertainty_. These properties are especially difficult to satisfy in the node-level prediction tasks on graph data since the elements are interdependent, and thus the distributional shifts may be even more complex than for the classic setup with i.i.d. samples.

To evaluate graph models in the node-level problems, it is important to test them under diverse, complex, and meaningful distributional shifts. Unfortunately, most existing graph datasets split the nodes into train and test parts uniformly at random. Rare exceptions include the Open Graph Benchmark (OGB)  that creates more challenging non-random data splits by dividing the nodesaccording to some domain-specific property. For instance, in the OGB-Arxiv dataset, the papers are divided according to their publication date, which is a realistic setup. Unfortunately, not many datasets contain such meta-information that can be used to split the data. To overcome this issue, Gui et al.  propose the Graph OOD Benchmark (GOOD) designed specifically for evaluating graph models under distributional shifts. The authors distinguish between two types of shifts: _concept_ and _covariate_. However, creating such shifts is non-trivial, while both types of shifts are typically present simultaneously in practical applications. Also, the splitting strategies in GOOD are mainly based on the node features and do not take into account the graph structure.3

In our work, we fill this gap and propose a universal method for inducing _structural_ distributional shifts in graph data. Our approach allows for creating diverse, complex, and meaningful node-level shifts that can be applied to any graph dataset. In particular, we introduce the split strategies that focus on such node properties as _popularity_, _locality_, and _density_. Our framework is flexible and allows one to easily extend it with other structural shifts or vary the fraction of nodes available for training and testing. We empirically show that the proposed distributional shifts are quite challenging for existing graph methods. In particular, the locality-based shift appears to be the most difficult in terms of the predictive performance for most considered OOD robustness methods, while the density-based shift is extremely hard for OOD detection by uncertainty estimation methods. Our experiments also reveal that simple models often outperform more sophisticated approaches on structural distributional shifts. In addition, we investigate some modifications of graph model architectures that may improve their OOD robustness or help in OOD detection on the proposed structural shifts. Our experiments provide evidence that there is a trade-off between the quality of learned representations for base classification task under structural distributional shift and the ability to separate the nodes from different distributions using these representations.

## 2 Background

### Graph problems with distributional shifts

Several research areas in graph machine learning investigate methods for solving node-level prediction tasks under distributional shifts, and they are primarily different in what problem they seek to overcome. One such area is _adversarial robustness_, which requires one to construct a method that can handle artificial distributional shifts that are induced as adversarial attacks for graph models in the form of perturbed and contaminated inputs. The related approaches often focus on designing various data augmentations via introducing random or learnable noise [30; 42; 40; 35; 22].

Another research area is _out-of-distribution generalization_. The main task is to design a method that can handle real-world distributional shifts on graphs and maintain high predictive performance across different OOD environments. Several invariant learning and risk minimization techniques have been proposed to improve the robustness of graph models to such real-world shifts [1; 19; 20; 38].

There is also an area of _uncertainty estimation_, which covers various problems. In _error detection_, a model needs to provide the uncertainty estimates that are consistent with prediction errors, _i.e._, assign higher values to potential misclassifications. In the presence of distributional shifts, the uncertainty estimates can also be used for _out-of-distribution detection_, where a model is required to distinguish the shifted OOD data from the ID data [24; 36; 2; 27; 18].

The structural distributional shifts proposed in our paper can be used for evaluating OOD generalization, OOD detection, and error detection since they are designed to replicate the properties of realistic graph data.

### Uncertainty estimation methods

Depending on the source of uncertainty, it is usually divided into _data uncertainty_, which describes the inherent noise in data due to the labeling mistakes or class overlap, and _knowledge uncertainty_, which accounts for the insufficient amount of information for accurate predictions when the distribution of the test data is different from the training one [5; 24; 23].

General-purpose methodsThe most simple approaches are standard classification models that predict the parameters of softmax distribution. For these methods, we can define the measure of uncertainty as the entropy of the predictive categorical distribution. This approach, however, does not allow us to distinguish between data and knowledge uncertainties, so it is usually inferior to other methods discussed below.

_Ensembling techniques_ are powerful but expensive approaches that providing decent predictive performance and uncertainty estimation. The most common example is _Deep Ensemble_, which can be formulated as an empirical distribution of model parameters obtained after training several instances of the model with different random seeds for initialization. Another way to construct an ensemble is _Monte Carlo Dropout_, which is usually considered as the baseline in uncertainty estimation literature. However, it has been shown that this technique is commonly inferior to deep ensembles, as the obtained predictions are dependent and thus lack diversity. Importantly, ensembles allow for a natural decomposition of total uncertainty in data and knowledge uncertainty .

There is also a family of _Dirichlet-based methods_. Their core idea is to model the point-wise Dirichlet distribution by predicting its parameters for each input individually using some model. To get the parameters of the categorical distribution, one can normalize the parameters of the Dirichlet distribution by their sum. This normalization constant is called _evidence_ and can be used to express the general confidence of a Dirichlet-based model. Similarly to ensembles, these methods are able to distinguish between data and knowledge uncertainty. There are numerous examples of Dirichlet-based methods, one of the first being _Prior Network_ that induces the behavior of Dirichlet distribution by contrastive learning against the OOD samples. Although this method is theoretically sound, it requires knowing the OOD samples in the training stage, which is a significant limitation. Another approach is _Posterior Network_, where the behavior of the Dirichlet distribution is controlled by _Normalizing Flows_, which estimate the density in latent space and reduce the Dirichlet _evidence_ in the regions of low density without using any OOD samples.

Graph-specific methodsRecently, several uncertainty estimation methods have been designed specifically for node-level problems. For example, _Graph Posterior Network_ is an extension of the _Posterior Network_ framework discussed above. To model the Dirichlet distribution, it first encodes the node features into latent representations with a graph-agnostic model and then uses one flow per class for density estimation. Then, the _Personalized Propagation_ scheme  is applied to the Dirichlet parameters to incorporate the network effects. Another Dirichlet-based method is _Graph-Kernel Dirichlet Estimation_. In contrast to _Posterior Networks_, its main property is a compound training objective, which is focused on optimizing the node classification performance and inducing the behavior of the Dirichlet distribution. The former is achieved via knowledge distillation from a teacher GNN, while the latter is performed as a regularisation against the prior Dirichlet distribution computed via graph kernel estimation. However, as shown by Stadler et al. , this approach is inferior to _Graph Posterior Network_ while having a more complex training procedure and larger computational complexity.

### Methods for improving robustness

Improving OOD robustness can be approached from different perspectives, which, however, share the same idea of learning the representations that are invariant to undesirable changes of the input distribution. For instance, the main claim in _domain adaptation_ is that to achieve an effective domain transfer and improve the robustness to distributional shift, the predictions should depend on the features that can not discriminate between the source and target domains. Regarding the branch of _invariant learning_, these methods decompose the input space into different environments and focus on constructing robust representations that are insensitive to their change.

General-purpose methodsA classic approach for domain adaptation is _Domain-Adversarial Neural Network_ that promotes the emergence of features that are discriminative for the main learning task on the source domain but do not allow to detect the distributional shift on other domains. This is achieved by jointly optimizing the underlying representations as well as two predictors operating on them: the main label predictor that solves the base classification task and the domain classifier that discriminates between the source and the target domains during training. Another simple technique in the class of unsupervised domain adaptation methods is _Deep Correlation Alignment_, which trains to align the second-order statistics of the source and target distributions that are produced by the activation layers of a deep neural model that solves the base classification task.

A representative approach in invariant learning is _Invariant Risk Minimization_, which searches for data representations providing decent performance across all environments, while the optimal classifier on top of these representations matches for all environments. Another method is _Risk Extrapolation_, which targets both robustness to covariate shifts and invariant predictions. In particular, it targets the forms of distributional shifts having the largest impact on performance in training domains.

Graph-specific methodsMore recently, several graph-specific methods for improving OOD robustness have been proposed. One of them is an invariant learning technique _Explore-to-Extrapolate Risk Minimization_, which leverages multiple context explorers that are specified by graph structure editors and adversarially trained to maximize the variance of risks across different created environments. There is also a simple data augmentation technique _Mixup_ that trains neural models on convex combinations of pairs of samples and their corresponding labels. However, devising such a method for solving the node-level problems is not straightforward, as the inputs are connected to each other. Based on this technique, Wang et al.  have designed its adaptation for graph data: instead of training on combinations of the initial node features, this method exploits the intermediate representations of nodes and their neighbors that are produced by graph convolutions.

## 3 Structural distributional shifts

### General approach

As discussed above, existing datasets for evaluating the robustness and uncertainty of node-level problems mainly focus on feature-based distributional shifts. Here, we propose a universal approach that produces non-trivial yet reasonable structural distributional shifts. For this purpose, we introduce a node-level graph characteristic \(_{i}\) and compute it for every node \(i\). We sort all nodes in ascending order of \(_{i}\) -- those with the smallest values of \(_{i}\) are considered to be ID, while the remaining ones are OOD. As a result, we obtain a graph-based distributional shift where ID and OOD nodes have different structural properties. The type of shift depends on the choice of \(_{i}\), and several possible options are described in Section 3.2 below.

We further split the ID nodes uniformly at random into the following parts:

* Train contains nodes \(_{}\) that are used for regular training of models and represent the only observations that take part in gradient computation.
* Valid-In enables us to monitor the best model during the training stage by computing the validation loss for nodes \(_{}\) and choose the best checkpoint.
* Test-In is used for testing on the remaining ID nodes \(_{}\) and represents the simplest setup that requires a model to reproduce in-distribution dependencies.

The remaining OOD nodes are split into Valid-Out and Test-Out subsets based on their \(_{i}\):

* Test-Out is used to evaluate the robustness of models to distributional shifts. It consists of nodes with the largest values of \(_{i}\) and thus represents the most shifted part \(_{}\).
* Valid-Out contains OOD nodes with smaller values of \(_{i}\) and thus is less shifted than Test-Out. This subset \(_{}\) can be used for monitoring the model performance on a shifted distribution. Our experiments assume a more challenging setup when such shifted data is unavailable during training. However, the presence of this subset allows us to further separate \(_{}\) from \(_{}\) -- the larger \(_{}\) we consider, the more significant distributional shift is created between the train and OOD test nodes.

Our general framework is quite flexible and allows one to easily vary the size of the training part and the type of distributional shift. Let us now discuss some particular shifts that we propose in this paper.

### Proposed distributional shifts

To define our data splits, we need to choose a node property \(_{i}\) as a splitting factor. We consider diverse graph characteristics covering various distributional shifts that may occur in practice. In a standard non-graph ML setup, shifts typically happen only in the feature space (or, more generally, the joint distribution of features and targets may shift). However, in graph learning tasks, there can be shifts specifically related to the graph structure. We discuss some representative examples below.

Popularity-basedThe first strategy represents a possible bias towards popularity. In some applications, it is natural to expect the training set to consist of more popular items. For instance, in the web search, the importance of pages in the internet graph can be measured via PageRank . For this application, the labeling of pages should start with important ones since they are visited more often. Similar situations may happen for social networks, where it is natural to start labeling with the most influential users, or citation networks, where the most cited papers should be labeled first. However, when applying a graph model, it is essential to make accurate predictions on less popular items. Motivated by that, we introduce a popularity-based split based on PageRank. The vector of PageRank values \(_{i}\) describes the stationary distribution of a random walk with restarts, for which the transition matrix is defined as the normalized adjacency matrix \(^{-1}\) and the probability of restart is \(\):

\[=(1-)^{-1}+ {p}.\] (1)

The vector of restart probabilities \(\) is called a personalization vector, and \(p_{i}=1/n\) by default, which describes the uniform distribution over nodes.

To construct a popularity-based split, we use PageRank (PR) as a measure of node importance. Thus, we compute PR for every node \(i\) and set \(_{i}=-_{i}\), which means that the nodes with smaller PR values (_i.e._, less important ones) belong to the OOD subsets. Note that instead of PR, one can potentially use any other measure of node importance, _e.g._, node degree, or betweenness centrality.

Figure 0(a) illustrates that the proposed shift separates the most important nodes that belong to the cores of large clusters and the structural periphery, which consists of less important nodes in terms of their PR values. We also observe that such popularity-based split agrees well with some natural distributional shifts. For instance, Figure 0(a) in Appendix shows the distribution of PageRank in train and test parts of the **OGB-Arxiv** dataset . Here, the papers are split according to their publication date. Thus, older papers naturally have more citations and, therefore, larger PageRank. Our proposed split allows one to mimic this behavior for datasets without timestamps available. We refer to Appendix A for more details and additional analysis.

Locality-basedOur next strategy is focused on a potential bias towards locality, which may happen when labeling is performed by exploring the graph starting from some node. For instance, in web search applications, a crawler has to explore the web graph following the links. Similarly, the information about the users of a social network can usually be obtained via an API, and new users are discovered following the friends of known users. To model such a situation, one could divide nodes based on the shortest path distance to a given node. However, graph distances are discrete, and the number of nodes at a certain distance may grow exponentially with distance. Thus, such an approach

Figure 1: Visualization of structural shifts for **AmazonPhoto** dataset: ID is blue, OOD is red.

does not provide us with the desired flexibility in varying the size of the train part. Instead, we use the concept of Personalized PageRank (PPR)  to define a local neighborhood of a node. PPR is the stationary distribution of a random walk that always restarts from some fixed node \(j\). Thus, the personalization vector \(\) in (1) is set to the one-hot-encoding of \(j\). The associated distributional shift naturally captures locality since a random walk always restarts from the same node.

For our experiments, we select the node \(j\) with the highest PR score as a restarting one. Then, we compute the PPR values \(_{i}\) for every node \(i\) and define the measure \(_{i}=-_{i}\). The nodes with high PPR, which belong to the ID part, are expected to be close to the restarting node, while far away nodes go to the OOD subset. Figure 0(b) confirms that the locality is indeed preserved, as the ID part consists of one compact region around the restarting node. Thus, the OOD subset includes periphery nodes as well as some nodes that were previously marked as important in the PR-based split but are far away from the restarting node. Our analysis in Appendix A also provides evidence for this behavior: the PPR-based split strongly affects the distribution of pairwise distances within the ID/OOD parts as the locality bias of the ID part makes the OOD nodes more distant from each other.

While locality-based distributional shifts are natural, we are unaware of publicly available benchmarks focusing on such shifts. We believe that our approach will be helpful for evaluating the robustness of GNNs under such shifts. Our empirical results in Section 4 demonstrate that locality-based splits are the most challenging for graph models and thus may require special attention.

Density-basedThe next distributional shift we propose is based on _density_. One of the most simple node characteristics that describe the local density in a graph is the local clustering coefficient. Considering some node \(i\), let \(d_{i}\) be its degree and \(_{i}\) be the number of edges connecting the neighbors of \(i\). Then, the local clustering coefficient is defined as the edge density within the one-hop neighborhood:

\[c_{i}=}{d_{i}(d_{i}-1)}\] (2)

For our experiments, we consider nodes with the highest clustering coefficient to be ID, which implies that \(_{i}=-c_{i}\).

This structural property might be particularly interesting for inducing distributional shifts since it is defined through the number of triangles, the substructures that most standard graph neural networks are unable to distinguish and count . Thus, it is interesting to know how changes in the clustering coefficient affect the predictive performance and uncertainty estimation.

Figure 0(c) visualizes the density-based split. We see that the OOD part includes both the high-degree _central_ nodes and the _periphery_ nodes of degree one. Indeed, the nodes of degree one naturally have zero clustering coefficient. On the other hand, for the high-degree nodes, the number of edges between their neighbors usually grows slower than quadratically. Thus, such nodes tend to have a vanishing clustering coefficient.

Finally, we note that the existing datasets with realistic splits may often have the local clustering coefficient shifted between the train and test parts. Figures 0(c) and 0(c) in Appendix show this for two OGB datasets. Depending on the dataset, the train subset may be biased towards the nodes with either larger (Figure 0(c)) or smaller (Figure 0(c)) clustering. In our experiments, we focus on the former scenario.

## 4 Experimental setup

DatasetsWhile our approach can potentially be applied to any node prediction dataset, for our experiments, we pick the following seven homophilous datasets that are commonly used in the literature: three citation networks, including **CoraML**, **CiteSeer**[26; 9; 8; 31], and **PubMed**, two co-authorship graphs -- **CoauthorPhysics** and **CoauthorCS**, and two co-purchase datasets -- **AmazonPhoto** and **AmazonComputer**[25; 32]. Moreover, we consider **OGB-Products**, a large-scale dataset from the OGB benchmark. Some of the methods considered in our work are not able to process such a large dataset, so we provide only the analysis of structural shifts on this dataset and do not use it for comparing different methods.

For any distributional shift, we split each graph dataset as follows. The half of nodes with the smallest values of \(_{i}\) are considered to be ID and split into Train, Valid-In, and Test-In uniformly at random in proportion 30% : 10% : 10%. The second half contains the remaining OOD nodes and is split into Valid-Out and Test-Out in the ascending order of \(_{i}\) in proportion 10% : 40%. Thus, in our base setup, the ID to OOD split ratio is \(50\%:50\%\). We have also conducted experiments with other split ratios that involve smaller sizes of OOD subsets, see Appendix B for the details.

ModelsIn our experiments, we apply the proposed benchmark to evaluate the OOD robustness and uncertainty of various graph models. In particular, we consider the following methods for improving the OOD generalisation in the node classification task:

* **ERM** is the _Empirical Risk Minimization_ technique that trains a simple GNN model by optimizing a standard classification loss;
* **DANN** is an instance of _Domain Adversarial Network_ that trains a regular and a domain classifiers to make features indistinguishable across different domains;
* **CORAL** is the _Deep Correlation Alignment_ technique that encourages the representations of nodes in different domains to be similar;
* **EERM** is the _Explore-to-Extrapolate Risk Minimization_ method based on graph structure editors that creates virtual environments during training;
* **Mixup** is an implementation of _Mixup_ from  and represents a simple data augmentation technique adapted for the graph learning problems;
* **DE** represents a _Deep Ensemble_ of graph models, a strong but expensive method for improving the predictive performance;

In context of OOD detection, we consider the following uncertainty estimation methods:

* **SE** represents a simple GNN model that is used in the **ERM** method, for which the measure of uncertainty is _Softmax Entropy_ (_i.e._, the entropy of predictive distribution);
* **GPN** is an implementation of the _Graph Posterior Network_ method for the node-level uncertainty estimation;
* **NatPN** is an instance of _Natural Posterior Network_ in which the encoder has the same architecture as in the **SE** method;
* **DE** represents a _Deep Ensemble_ of graph models, which allows to separate the knowledge uncertainty that is used for OOD detection;
* **GPE** and **NatPE** represent the _Bayesian Combinations_ of **GPN** and **NatPN**, an approach to construct an ensemble of Dirichlet models .

The training details are described in Appendix F. For experiments with the considered OOD robustness methods, including **DANN**, **CORAL**, **EERM**, and **Mixup**, we use the experimental framework from the GOOD benchmark,4 whereas the remaining methods are implemented in our custom experimental framework and can be found in our repository.5

Prediction tasks & evaluation metricsTo evaluate OOD robustness in the node classification problem, we exploit standard _Accuracy_. Further, to assess the quality of uncertainty estimates, we treat the OOD detection problem as a binary classification with positive events corresponding to the observations from the OOD subset and use _AUROC_ to measure performance.

## 5 Empirical study

In this section, we show how the proposed approach to creating distributional shifts can be used for evaluating the robustness and uncertainty of graph models. In particular, we compare the types of distributional shifts introduced above and discuss which of them are more challenging. We also discuss how they affect the predictive performance of OOD robustness methods as well as the ability for OOD detection of uncertainty estimation methods.

### Analysis of structural distributional shifts

In this section, we analyze and compare the proposed structural distributional shifts.

OOD robustnessTo investigate how the proposed shifts affect the predictive performance of graph models, we take the most simple **ERM** method and report the drop in _Accuracy_ between the ID and OOD test subsets in Table 1 (left). It can be seen that the node classification results on the considered datasets are consistently lower when measured on the OOD part, and this drop can reach tens of percent in some cases. The most significant decrease in performance is observed on the locality-based splits, where it reaches \(14\%\) on average and more than \(30\%\) in the worst case. This fact matches our intuition about how training on local regions of graphs may prevent OOD generalization and create a great challenge for improving OOD robustness. Although the density-based shift does not appear to be as difficult, it is still more challenging than the popularity-based shift, leading to performance drops of \(5.5\%\) on average and \(17\%\) in the worst case.

OOD detectionTo analyze the ability of graph models to detect distributional shifts by providing higher uncertainty on the shifted inputs, we report the performance of the most simple **SE** method for each proposed distributional shift and graph dataset in Table 1 (right). It can be seen that the popularity-based and locality-based shifts can be effectively detected by this method, which is proved by the average performance metrics. In particular, the _AUROC_ values may vary from \(68\) to \(92\) points on the popularity-based splits and approximately in the same range for the locality-based splits. Regarding the density-based shifts, one can see that the OOD detection performance is almost the same as for random predictions on average. Only for the citation networks the _AUROC_ exceeds \(58\) points, reaching a peak of \(81\) points. This is consistent with the previous works showing that standard graph neural networks are unable to count substructures such as triangles. In our case, this leads to graph models failing to detect changes in density measured as the number of triangles around the central node.

Thus, the popularity-based shift appears to be the simplest for OOD detection, while the density-based is the most difficult. This clearly shows how our approach to creating data splits allows one to vary the complexity of distributional shifts using different structural properties as splitting factors.

### Comparison of existing methods

In this section, we compare several existing methods for improving OOD robustness and detecting OOD inputs on the proposed structural shifts. To concisely illustrate the overall performance of the models, we first rank them according to a given performance measure on a particular dataset and then average the results over the datasets. For detailed results of experiments on each graph dataset separately, please refer to Appendix G.

OOD robustnessFor each model, we measure both the absolute values of _Accuracy_ and the drop in this metric between the ID and OOD subsets in Table 2 (left). It can be seen that a simple data augmentation technique **Mixup** often shows the best performance. Only on the density-based shift, expensive **DE** outperforms it on average when tested on the OOD subset. This proves that data

    & **Popularity** & **Locality** & **Density** \\  AmazonComputer & \(-10.01\,\%\) & \(-21.95\,\%\) & \(-7.91\,\%\) \\ AmazonPhoto & \(-8.54\,\%\) & \(-30.93\,\%\) & \(-3.58\,\%\) \\ CoauthorCS & \(-3.13\,\%\) & \(-1.22\,\%\) & \(-4.86\,\%\) \\ CoauthorPhysics & \(-3.42\,\%\) & \(-4.75\,\%\) & \(-1.41\,\%\) \\ CorAML & \(-3.94\,\%\) & \(-14.61\,\%\) & \(-17.09\,\%\) \\ CiteSeer & \(-0.02\,\%\) & \(-26.51\,\%\) & \(-8.39\,\%\) \\ PubMed & \(-3.23\,\%\) & \(-5.71\,\%\) & \(-0.78\,\%\) \\ OGB-Products & \(-2.86\,\%\) & \(-2.83\,\%\) & \(-0.12\,\%\) \\  Average & \(-4.39\,\%\) & \(-13.56\,\%\) & \(-5.52\,\%\) \\   

Table 1: Comparison of structural distributional shifts in terms of OOD robustness and OOD detection. We report the drop in predictive performance of the **ERM** method measured by _Accuracy_ (left) and the quality of uncertainty estimates of the **SE** method measured by _AUROC_ (right).

augmentation techniques are beneficial in practice, as they prevent overfitting to the ID structural patterns and improve the OOD robustness. Regarding other OOD robustness methods, a graph-specific method **EERM** outperforms **DANN** and **CORAL** on the popularity-based and locality-based shifts. However, these domain adaptation methods are superior to **EERM** on the density-based shifts, providing better predictive performance on average for both ID and OOD subsets.

In conclusion, we reveal that the most sophisticated methods that generate virtual environments and predict the underlying domains for improving the OOD robustness may often be outperformed by simpler methods, such as data augmentation.

OOD detectionComparing the quality of uncertainty estimates in Table 2 (right), one can observe that the methods based on the entropy of predictive distribution usually outperform Dirichlet methods. In particular, a natural distinction of knowledge uncertainty in **DE** enables it to produce uncertainty estimates that are the most consistent with OOD inputs on average, especially when applied to the locality-based and density-based shifts. In general, **GPN** and the combination of its instances **GPE** provide higher OOD detection performance than their counterparts based on **NatPN** when tested on the popularity-based and locality-based splits.

### Influence of graph architecture improvements

In this section, we consider several adjustments for the base GNN architecture of such methods as **ERM**, which is used to evaluate OOD robustness, and **SE**, which provides the uncertainty estimates for OOD detection. In particular, we reduce the number of graph convolutional layers from 3 to 2, replacing the first one with a pre-processing step based on MLP, apply the skip-connections between graph convolutional layers, and replace the GCN  graph convolution with SAGE .

These changes are aimed at relaxing the restrictions on the information exchange between a central node and its neighbors and providing more independence in processing the node representations across neural layers. Such a modification is expected to help the GNN model to learn structural patterns that could be transferred to the shifted OOD subset more successfully. Further, we investigate how these changes in the model architecture affect the predictive performance and the quality of uncertainty estimates of the corresponding methods when tested on the proposed structural distributional shifts.

For this, we use the win/tie/loss counts that reflect how many times the modified architecture has outperformed, got a statistically insignificant difference, or lost to the corresponding method, respectively. As can be seen from Table 3 (left), the **ERM** method supplied with the proposed modifications usually outperforms the baseline architecture both on ID and OOD, which is proved by high win counts. However, as can be seen from Table 3 (right), the same modification in the corresponding **SE** method leads to consistent performance drops, which is reflected in high loss

    &  &  &  \\  & ID & OOD & ID & OOD & ID & OOD \\  ERM & \(4.0\) & \(4.0\) & \(3.3\) & \(4.1\) & \(3.9\) & \(4.0\) \\ Mixup & \(1.4\) & \(2.1\) & \(1.4\) & \(2.4\) & \(1.9\) & \(3.3\) \\ EERM & \(3.6\) & \(3.9\) & \(4.4\) & \(3.3\) & \(5.0\) & \(4.3\) \\ DANN & \(4.3\) & \(4.3\) & \(5.0\) & \(4.1\) & \(3.0\) & \(3.6\) \\ CORAL & \(4.7\) & \(4.1\) & \(4.3\) & \(4.7\) & \(4.1\) & \(3.9\) \\ DE & \(3.0\) & \(2.6\) & \(2.6\) & \(2.3\) & \(3.1\) & \(2.0\) \\        & **Popularity** & **Locality** & **Density** \\  SE & \(1.4\) & \(2.1\) & \(4.0\) \\ GPN & \(3.3\) & \(3.9\) & \(4.3\) \\ NaPN & \(5.3\) & \(4.1\) & \(2.9\) \\ DE & \(2.1\) & \(1.1\) & \(2.7\) \\ GPE & \(3.1\) & \(4.3\) & \(3.4\) \\ NatPE & \(5.7\) & \(5.4\) & \(3.7\) \\        & **Popularity** & **Locality** & **Density** \\  SE & \(1.4\) & \(2.1\) & \(4.0\) \\ GPN & \(3.3\) & \(3.9\) & \(4.3\) \\ NaPN & \(5.3\) & \(4.1\) & \(2.9\) \\ DE & \(2.1\) & \(1.1\) & \(2.7\) \\ GPE & \(3.1\) & \(4.3\) & \(3.4\) \\ NatPE & \(5.7\) & \(5.4\) & \(3.7\) \\    
    & **Popularity** & **Locality** & **Density** \\  SE & \(1.4\) & \(2.1\) & \(4.0\) \\ GPN & \(3.3\) & \(3.9\) & \(4.3\) \\ NaPN & \(5.3\) & \(4.1\) & \(2.9\) \\ DE & \(2.1\) & \(1.1\) & \(2.7\) \\ GPE & \(3.1\) & \(4.3\) & \(3.4\) \\ NatPE & \(5.7\) & \(5.4\) & \(3.7\) \\   

Table 2: Comparison of several graph methods for improving the OOD robustness (left) and detecting the OOD inputs by means of uncertainty estimation (right). For each task, we report the method ranks averaged across different graph datasets (lower is better).

    & **Popularity** & **Locality** & **Density** \\  ERM + mod & \(4/2/1\) & \(5/2/0\) & \(4/2/1\) & \(3/2/2\) & \(4/2/1\) & \(5/2/0\) \\    
    & **Popularity** & **Locality** & **Density** \\  SE + mod & \(0/0/7\) & \(0/1/6\) & \(4/0/3\) \\   

Table 3: Comparison of the proposed architecture modifications that are used in the **ERM** method for OOD robustness (left) and **SE** method for OOD detection (right). For each task, we report the win/tie/loss counts across graph datasets for the modified GNN architecture against the base one.

counts. It means that, when higher predictive performance is reached on the shifted subset, it becomes more difficult to detect the inputs from this subset as OOD since they appear to be less distinguishable by a GNN model in the context of the base node classification problem. Our observation is very similar to what is required from _Invariant Learning_ techniques, which try to produce node representations invariant to different domains or environments. This may serve as evidence that there is a trade-off between the quality of learned representations for solving the target node classification task under structural distributional shift and the ability to separate the nodes from different distributions based on these representations.

## 6 Conclusion

In this work, we propose and analyze structural distributional shifts for evaluating robustness and uncertainty in node-level graph problems. Our approach allows one to create realistic, challenging, and diverse distributional shifts for an arbitrary graph dataset. In our experiments, we evaluate the proposed structural shifts and show that they can be quite challenging for existing graph models. We also find that simple models often outperform more sophisticated methods on these challenging shifts. Moreover, by applying various modifications for graph model architectures, we show that there is a trade-off between the quality of learned representations for the target classification task under structural distributional shift and the ability to detect the shift using these representations.

LimitationsWhile our methods of creating structural shifts are motivated by real distributional shifts that arise in practice, they are synthetically generated, whereas, for particular applications, natural distributional shifts would be preferable. However, our goal is to address the situations when such natural shifts are unavailable. Thus, we have chosen an approach universally applied to any dataset. Importantly, graph structure is the only common modality of different graph datasets that can be exploited in the same manner to model diverse and complex distributional shifts.

Broader impactConsidering the broader implications of our work, we assume that the proposed approach for evaluating robustness and uncertainty of graph models will support the development of more reliable systems based on machine learning. By testing on the presented structural shifts, it should be easier to detect various biases against under-represented groups that may have a negative impact on the resulting performance and interfere with fair decision-making.

Future workIn the future, two key areas can be explored based on our work. Firstly, there is a need to develop principled solutions for improving robustness and uncertainty estimation on the proposed structural shifts. Our new approach can assist in achieving this objective by providing an instrument for testing and evaluating such solutions. Additionally, there is a need to create new graph benchmarks that accurately reflect the properties of data observed in real-world applications. This should involve replacing synthetic shifts with realistic ones. By doing so, we may capture the challenges and complexities that might be faced in practice, thereby enabling the development of more effective and applicable graph models.