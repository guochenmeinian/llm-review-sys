# Exact Bayesian Inference on Discrete Models via Probability Generating Functions:

A Probabilistic Programming Approach

Fabian Zaiser

Department of Computer Science

University of Oxford, UK

fabian.zaiser@cs.ox.ac.uk

Andrzej S. Murawski

Department of Computer Science

University of Oxford, UK

andrzej.murawski@cs.ox.ac.uk

&C.-H. Luke Ong

School of Computer Science and Engineering

Nanyang Technological University, Singapore

luke.ong@ntu.edu.sg

###### Abstract

We present an exact Bayesian inference method for discrete statistical models, which can find exact solutions to a large class of discrete inference problems, even with infinite support and continuous priors. To express such models, we introduce a probabilistic programming language that supports discrete and continuous sampling, discrete observations, affine functions, (stochastic) branching, and conditioning on discrete events. Our key tool is _probability generating functions_: they provide a compact closed-form representation of distributions that are definable by programs, thus enabling the exact computation of posterior probabilities, expectation, variance, and higher moments. Our inference method is provably correct and fully automated in a tool called _Genfer_, which uses automatic differentiation (specifically, Taylor polynomials), but does not require computer algebra. Our experiments show that Genfer is often faster than the existing exact inference tools PSI, Dice, and Prodigy. On a range of real-world inference problems that none of these exact tools can solve, Genfer's performance is competitive with approximate Monte Carlo methods, while avoiding approximation errors.

## 1 Introduction

Bayesian statistics is a highly successful framework for reasoning under uncertainty that has found widespread use in a variety of fields, such as AI/machine learning, medicine and healthcare, finance and risk management, social sciences, climate science, astrophysics, and many other disciplines. At its core is the idea of representing uncertainty as probability, and updating prior beliefs based on observed data via Bayes' law, to arrive at posterior beliefs. A key challenge in Bayesian statistics is computing this posterior distribution: analytical solutions are usually impossible or intractable, which necessitates the use of approximate methods, such as Markov-chain Monte Carlo (MCMC) or variational inference. In this work, we identify a large class of discrete models for which exact inference is in fact possible, in particular time series models of count data, such as autoregressive models, hidden Markov models, switchpoint models. We achieve this by leveraging _probability generating functions (GFs)_ as a representation of distributions. The GF of a random variable \(X\) is defined to be the function \(G(x):=[x^{X}]\). In probability theory, it is a well-known tool to study random variables and their distributions, related to the moment generating and the characteristic functions [14, Chapter 4]. In computer science, GFs have previously been used for the analysis of probabilistic programs  and for exact inference on certain classes of graphical models .

Here we apply them uniformly in a much more general context via probabilistic programming, enabling exact inference on more expressive Bayesian models.

We characterize the class of supported models with the help of a probabilistic programming language. _Probabilistic programming_ has recently emerged as a powerful tool in Bayesian inference. Probabilistic programming systems allow users to specify complex statistical models as programs in a precise yet intuitive way, and automate the Bayesian inference task. This allows practitioners to focus on modelling, leaving the development of general-purpose inference algorithms to experts. Consequently, probabilistic programming systems such as Stan  enjoy increasing popularity among statisticians and data scientists. We describe a programming language, called SGCL (statistical guarded command language), that extends pGCL (probabilistic GCL) . This language is carefully designed to be simple yet expressive, and just restrictive enough to enable exact Bayesian inference on all programs that can be written in it.

**Contributions** We provide a new framework for exact inference on discrete Bayesian models.

1. Our method is applicable to a large class of _discrete models with infinite support_, in particular time series models of count data, such as autoregressive models for population dynamics, Bayesian switchpoint models, mixture models, and hidden Markov models. To our knowledge, no exact inference method for all but the simplest population models was known before.
2. The models are specified in a _probabilistic programming language (PPL)_, which provides flexibility in model definition, thus facilitating model construction. Our PPL supports stochastic branching, continuous and discrete priors, discrete observations, and conditioning on events involving discrete variables.
3. Every program written in the language can be _translated to a generating function_ that represents the posterior distribution in an automatic and provably correct way. From this generating function, one can extract posterior _mean, variance, and higher moments_, as well as the posterior _probability masses_ (for a discrete distribution).
4. We have built an _optimized tool_, called Genfer ("GENerating Functions for inFERence"), that takes a probabilistic program as input and _automatically computes_ the aforementioned set of descriptive statistics about the posterior distribution.
5. We demonstrate that (1) on benchmarks with finite support, Genfer's performance is often better than existing _exact inference tools_, and (2) on a range of real-world examples that no existing exact tool supports, Genfer is competitive with _approximate Monte Carlo methods_, while achieving zero approximation error.

**Related Work** Computing the exact posterior distribution of probabilistic programs is intractable in general as it requires analytical solutions to integrals . For this reason, existing systems either restrict the programming language to allow only tractable constructs (this is our approach) or cannot guarantee successful inference. In the former category are Dice , which only supports finite discrete distributions, and SPPL , which supports some infinite-support distributions but requires finite discrete priors. Both are based on probabilistic circuits  or extensions thereof, which allow for efficient and exact inference. In the latter category are the systems PSI  and Hakaru , which do not impose syntactic restrictions. They rely on computer algebra techniques to find a closed-form solution for the posterior. Such a form need not exist in general and, even if it does, the system may fail to find it and the running time is unpredictable and unscalable . None of the case studies featured in our evaluation (Section 5.2) can be handled by the aforementioned tools.

Probability generating functions are a useful tool in probability theory to study random variables with infinite support, e.g. in the context of branching processes [7, Chapter 12]. In the context of Bayesian inference, probabilistic generating circuits (PGCs) leverage them to boost the expressiveness of probabilistic circuits  and enable efficient inference . However, PGCs cannot handle random variables with infinite support, which is the focus of our approach. Generating functions have also been applied to probabilistic graphical models: Winner and Sheldon  find a symbolic representation of the generating function for a Poisson autoregressive model and extract posterior probabilities from it. Subsequently, Winner et al.  extend this model to latent variable distributions other than the Poisson distribution, where symbolic manipulation is no longer tractable. Instead they evaluate generating functions and their derivatives using automatic differentiation, which enables exact inference for graphical models. Probabilistic programming is an elegant way of generalizing graphical models, allowing a much richer representation of models . Our contribution here is a new framework for exact inference on Bayesian models via probabilistic programming.

In the context of discrete probabilistic programs without conditioning, Klinkenberg et al.  use generating functions to (manually) analyze loop invariants and determine termination probabilities. In follow-up work, Chen et al.  extend these techniques to automatically check (under certain restrictions) whether a looping program generates a specified distribution. Their analysis tool Prodigy recently gained the ability to perform Bayesian inference as well . It supports discrete distributions with infinite support (but no continuous priors) and is less scalable than our automatic-differentiation approach (see Section 5) since it relies on computer algebra.

LimitationsExact posterior inference is already PSPACE-hard for probabilistic programs involving only finite discrete distributions [16, Section 6]. It follows that our method cannot always be performed and has to restrict the supported class of probabilistic programs. Indeed, our programming language forbids certain constructs, such as nonlinear transformations and observations of continuous variables, in order to preserve a closed-form representation of the generating functions (Section 2). For the same reason, our method cannot compute probability density functions for continuous parameters (but probability masses for discrete parameters and exact moments for all parameters are fine). Regarding performance, the running time of inference is polynomial in the numbers observed in the program and exponential in the number of program variables (Section 4). Despite these limitations, our approach shows that exact inference is possible in the first place, and our evaluation (Section 5) demonstrates support for many real-world models and efficient exact inference in practice.

## 2 Bayesian Probabilistic Programming

Probabilistic programming languages extend ordinary programming languages with two additional constructs: one for _sampling_ from probability distributions and one for _conditioning_ on observed values. We first discuss a simple program that can be written in our language using a simplified example based on population ecology (cf. ).

Suppose you're a biologist trying to estimate the size of an animal population migrating into a new habitat. The immigration of animals is often modeled using a Poisson distribution. You cannot count the animals exhaustively (otherwise we wouldn't need estimation techniques), so we assume that each individual is observed independently with a certain probability; in other words, the count is binomially distributed. For simplicity, we assume that the rate of the Poisson and the probability of the binomial distribution are known, say 20 and 0.1. (For more realistic population models, see Section 5.) As a generative model, this would be written as \(X(20);Y(X,0.1)\).

Suppose you observe \(Y=2\) animals. The Bayesian inference problem is to compute the _posterior distribution_\((X=x Y=2)\) given by Bayes' rule as \((X=x Y=2)=(X=x)\ (Y=2 X=x)}{(Y=2)}\), where \((X=x)\) is called the _prior probability_, \((Y=2 X=x)\) the _likelihood_ and \((Y=2)\) the _evidence_ or _normalization constant_.

**Example 2.1**.: In our probabilistic programming language, this simplified population model would be expressed as:

\[X(20);Y(X,0.1);\,Y=2;\]

The syntax looks similar to generative model notation except that the observations are expressible as a command. Such a program denotes a joint probability distribution of its program variables, which are viewed as random variables. The program statements manipulate this joint distribution. After the first two sampling statements, the distribution has the probability mass function (PMF) \(p_{1}(x,y)=[X=x,Y=y]=(x;20)(y ;x,0.1)\). Observing \(Y=2\) restricts this to the PMF \(p_{2}(x,y)=[X=x,Y=y=2]\), which equals \([X=x,Y=2]=p_{1}(x,2)\) if \(y=2\) and \(0\) otherwise. Note that this is not a probability, but a _subprobability_, distribution because the total mass is less than 1. So, as a final step, we need to _normalize_, i.e. rescale the subprobability distribution back to a probability distribution. This corresponds to the division by the evidence in Bayes' rule, yielding the PMF \(p_{3}(x,y)=(x,y)}{_{x,y}p_{2}(x,y)}\). To obtain the posterior \([X=x Y=2]\), which is a distribution of the single variable \(X\), not the joint of \(X\) and \(Y\), we need to marginalize \(p_{3}\) and find \(_{y}p_{3}(x,y)=p_{2}(x,y)}{_{x,y}p_{2}(x,y)}=(x,2)}{_{x}p_{1}(x,2)}=[X=x,Y=2]}{[Y=2]}= [X=x Y=2]\), as desired.

Programming constructsNext we describe our probabilistic programming language more formally. It is based on the _probabilistic guarded command language (pGCL)_ from  but augmentsit with statistical features like conditioning on events and normalization, which is why we call it _Statistical GCL (SGCL)_. Each program operates on a fixed set of variables \(=\{X_{1},,X_{n}\}\) taking values in \(_{ 0}\). A program consists of a list of statements \(P_{1};P_{2};;P_{m}\). The simplest statement is skip, which does nothing and is useful in conditionals (like pass in Python). Variables can be transformed using affine maps, e.g. \(X_{2}:=2X_{1}+7X_{3}+2\) (note that the coefficients must be non-negative to preserve nonnegativity of the variables). Programs can branch on the value of a (discrete) variable (e.g. if \(X_{k}\{1,3,7\}\,\{\}\,\,\{\}\)), and sample new values for variables from distributions (e.g. \(X_{k}(10,0.5)\) or \(X_{k}(X_{j},0.5)\)). The supported distributions are Bernoulli, Categorical, Binomial, Uniform (both discrete and continuous), NegBinomial, Geometric, Poisson, Exponential, and Gamma. They need to have constant parameters except for the _compound distributions_\((X,p)\), \((X,p)\), \(( X)\), and \((X)\), where \(X\) can be a variable. One can observe events involving discrete variables (e.g. \(\,X_{k}\{3,5\}\)) and values from (discrete) distributions directly (e.g. \(\,3(X_{j},0.5)\)). Note that \(\,m D\) can be seen as a convenient abbreviation of \(Y D;\,Y=m\) with a fresh variable \(Y\). After an observation, the variable distribution is usually not a probability distribution anymore, but a _subprobability distribution_ ("the numerator of Bayes' rule").

SyntaxIn summary, the syntax of programs \(P\) has the following BNF grammar:

\[P := P_{1};P_{2} X_{k}:=a_{1}X_{1}++a_{n }X_{n}+c\,X_{k} A\,\{P_{1}\}\,\,\{P_{2}\}\] \[ X_{k} D X_{k} D(X_{j})\,X_ {k} A\,m D\,m D(X_{j})\]

where \(P\), \(P_{1}\) and \(P_{2}\) are subprograms; \(a_{1},,a_{n},c_{ 0};m\); \(A\) is a finite subset of the naturals; and \(D\) is a supported distribution. To reduce the need for temporary variables, the abbreviations \(+\), \(+=\), and if \(m D\,\{\}\,\,\{\}\) are available (see Section 4). A fully formal description of the language constructs can be found in Appendix A.

RestrictionsOur language imposes several syntactic restrictions to guarantee that the generating function of any program admits a closed form, which enables exact inference (see Section 3.1): (a) only affine functions are supported (e.g. no \(X^{2}\) or \((X)\)), (b) only comparisons between variables and constants are supported (e.g. no test for equality \(X=Y\)), (c) only observations from discrete distributions on \(\) and only comparisons of such random variables are supported (e.g. no \(\,1.5(0,1)\)), (d) a particular choice of distributions and their composites is supported, (e) loops or recursion are not supported. A discussion of possible language extensions and relaxations of these restrictions can be found in Appendix B.3.

## 3 Generating Functions

Consider Example 2.1. Even though the example is an elementary exercise in probability, it is challenging to compute the normalizing constant, because one needs to evaluate an infinite sum: \([Y=2]=_{x}[Y=2 X=x]\)\([X=x]=_{x}0.1^{2}\,0.9^{x-2} e^{-20}}{x!}\). It turns out to be \(2e^{-2}\) (see Example 3.1), but it is unclear how to arrive at this result in an automated way. If \(X\) had been a continuous variable, we would even have to evaluate an integral. We will present a technique to compute such posteriors mechanically. It relies on probability generating functions, whose definition includes an infinite sum or integral, but which often admit a closed form, thus enabling the exact computation of posteriors.

DefinitionProbability generating functions are a well-known tool in probability theory to study random variables and their distributions, especially discrete ones. The probability generating function of a random variable \(X\) is defined to be the function \(G(x):=[x^{X}]\). For a discrete random variable supported on \(\), this can also be written as a _power series_\(G(x)=_{n}[X=n] x^{n}\). Since we often deal with subprobability distributions, we omit "probability" from the name and refer to \(G(x):=_{X}[x^{X}]\), where \(\) is a subprobability measure, simply as a _generating function_ (GF). For continuous variables, it is often called _factorial moment generating function_, but we stick with the former name in all contexts. We will use the notation \(()\) or \((X)\) for the GF of \(\) or \(X\). Note that for discrete random variables supported on \(\), the GF is always defined on \([-1,1]\), and for continuous ones at \(x=1\), but it need not be defined at other \(x\).

Probability masses and momentsMany common distributions admit a _closed form_ for their GF (see Table 1). In such cases, GFs are a compact representation of a distribution, even if it has infinite or continuous support like the \(\) or \(\) distributions, respectively. Crucially, one can extract _probability masses_ and _moments_ of a distribution from its generating function. For discrete random variables \(X\), \(P[X=n]\) is the \(n\)-th coefficient in the power series representation of \(G\), so can be computed as the _Taylor coefficient_ at \(0\): \(G^{(n)}(0)\) (hence the name "_probability_ generating function"). For a discrete or continuous random variable \(X\), its expected value is \([X]=G^{}(1)\), and more generally, its \(n\)-th _factorial moment_ is \([X(X-1)(X-n+1)]=[}{x^{n}} x^{X}]|_{x=1}=G^{(n)}(1)\) (hence the name "_factorial moment_ generating function"). The raw and central moments can easily be computed from the factorial moments. For instance, the variance is \([X]=G^{}(1)+G^{}(1)-G^{}(1)^{2}\). We will exploit these properties of generating functions through automatic differentiation.

**Multivariate case**  The definition of GFs is extended to _multidimensional distributions_ in a straightforward way: for random variables \(=(X_{1},,X_{n})\), their GF is the function \(G():=[^{}]\) where we write \(:=(x_{1},,x_{n})\) and \(^{}:=x_{1}^{X_{1}} x_{n}^{X_{n}}\). We generally follow the convention of using uppercase letters for random and program variables, and lowercase letters for the corresponding parameters of the generating function. _Marginalization_ can also be expressed in terms of generating functions: to obtain the GF \(\) of the joint distribution of \((X_{1},,X_{n-1})\), i.e. to marginalize out \(X_{n}\), one simply substitutes \(1\) for \(x_{n}\) in \(G\): \((x_{1},,x_{n-1})=G(x_{1},,x_{n-1},1)\). This allows us to compute probability masses and moments of a random variable in a joint distribution: we marginalize out all the other variables and then use the previous properties of the derivatives.

### Translating programs to generating functions

The standard way of describing the meaning of probabilistic programs is assigning (sub-)probability distributions to them. An influential example is Kozen's _distribution transformer_ semantics , where each program statement transforms the _joint distribution_ of all the variables \(=(X_{1},,X_{n})\). Since Kozen's language does not include observations, we present the full semantics in Appendix A. We call this the _standard semantics_ of a probabilistic program and write \([\![P]\!]_{ std}()\) for the transformation of \(\) by the program \(P\). As a last step, the subprobability distribution \(\) has to be _normalized_, which we write \(}():=}\). This reduces the Bayesian inference problem for a given program to computing its semantics, starting from the joint distribution \(}(_{n})\) in which all \(n\) variables are initialized to \(0\) with probability \(1\). While mathematically useful, the distribution transformer semantics is hardly amenable to computation as it involves integrals and infinite sums.

Instead, we shall compute the _generating function_ of the posterior distribution represented by the probabilistic program. Then we can extract posterior probability masses and moments using automatic differentiation. Each statement in the programming language transforms the generating function of the distribution of program states, i.e. the joint distribution of the values of the variables \(=(X_{1},,X_{n})\). Initially, we start with the constant function \(G=\), which corresponds to all variables being initialized with 0 since \([x^{0}]=1\).

The _generating function semantics_ of a program \([\![P]\!]_{ f}\) describes how to transform \(G\) to the generating function \([\![P]\!]_{ f}(G)\) for the distribution at the end. It is defined in Table 2, where the update notation \([i a]\) denotes \((x_{1},,x_{i-1},a,x_{i+1},,x_{n})\) and \(_{n}\) means the \(n\)-tuple \((1,,1)\). The first five rules were already described in , so we only explain them briefly: skip leaves everything unchanged and \(P_{1};P_{2}\) chains two statements by transforming with \([\![P_{1}]\!]_{ f}\) and then \([\![P_{2}]\!]_{ f}\). To explain linear assignments, consider the case of only two variables: \(X_{1}:=2X_{1}+3X_{2}+5\). Then

\[[\![P]\!]_{ f}(G)()=[x_{1}^{2X_{1}+3X_{2}+5}x_{2}^{X_{2}} ]=x_{1}^{5}[(x_{1}^{2})^{X_{1}}(x_{1}^{3}x_{2})^{X_{2}}]=x_{1}^{5}  G(x_{1}^{2},x_{1}^{3}x_{2}).\]

For conditionals if \(X_{k} A\{P_{1}\}\{P_{2}\}\), we split the generating function \(G\) into two parts: one where the condition is satisfied (\(G_{X_{k} A}\)) and its complement (\(G-G_{X_{k} A}\)). The former is transformed

   Distribution \(D\) & \((X D(Y))(x)\) \\  \((n,p)\) & \((px+1-p)^{n}\) \\ \((p)\) & \(\) \\ \(()\) & \(e^{(x-1)}\) \\ \(()\) & \(\) \\    
  Distribution \(D(Y)\) & \((X D(Y))(x)\) \\  \((Y,p)\) & \((Y)(1-p+px)\) \\ \((Y,p)\) & \((Y)()\) \\ \(( Y)\) & \((Y)e^{(x-1)}\) \\ \((Y)\) & \(1+(x-1)((Y))^{}(1)\) \\   

Table 1: GFs for common distributions with constant (left) and random variable parameters (right)by the then-branch \([\![P_{1}]\!]_{}\), the latter by the else-branch \([\![P_{2}]\!]_{}\). The computation of \(G_{X_{k} A}\) is best understood by thinking of \(G\) as a power series where we keep only the terms where the exponent of \(x_{k}\) is in \(A\). Sampling \(X_{k} D\) from a distribution with constant parameters works by first marginalizing out \(X_{k}\) and then multiplying by the generating function of \(D\) with parameter \(x_{k}\).

The first new construct is sampling \(X_{k} D(X_{j})\) from compound distributions (see Appendix B for a detailed explanation). Observing events \(X_{k} A\) uses \(G_{X_{k} A}\) like in conditionals, as explained above. Just like the subprobability distribution defined by a program has to be normalized as a last step, we have to normalize the generating function. The normalizing constant is calculated by marginalizing out all variables: \(G(1,,1)\). So we obtain the generating function representing the normalized posterior distribution by rescaling with the inverse: \((G):=)}\). These intuitions can be made rigorous in the form of the following theorem, which is proven in Appendix B.

**Theorem 3.1**.: _The GF semantics is correct w.r.t. the standard semantics: for any SGCL program \(P\) and subprobability distribution \(\) on \(^{n}_{ 0}\), we have \([\![P]\!]_{}(())=([\![P]\!]_{}())\). In particular, it correctly computes the GF of the posterior distribution of \(P\) as \(([\![P]\!]_{}())\). Furthermore, there is some \(R>1\) such that \([\![P]\!]_{}()\) and \(([\![P]\!]_{}())\) are defined on \(^{n} Q_{i}<x_{i}<R}\) where \(Q_{i}=-R\) if the variable \(X_{i}\) is supported on \(\) and \(Q_{i}=0\) otherwise._

NoveltyThe semantics builds upon . To our knowledge, the GF semantics of the compound distributions \(( X_{j})\) and \((X_{j})\) is novel, and the former is required to support most models in Section 5. While the GF of observations has been considered in the context of a specific model , this has not been done in the general context of a probabilistic programming language before. More generally, previous works involving GFs only considered discrete distributions, whereas we also allow sampling from continuous distributions. This is a major generalization and requires different proof techniques because the power series representation \(_{i}[X=i]x^{i}\), on which the proofs in  rely, is not valid for continuous distributions.

**Example 3.1** (GF translation).: Consider Example 2.1. We can find the posterior distribution mechanically by applying the rules from the GF semantics. We start with the GF \(A(x,y)=[x^{0}y^{0}]=1\) corresponding to \(X\) and \(Y\) being initialized to 0. Sampling \(X\) changes this to GF \(B(x,y)=A(1,y)e^{20(x-1)}=e^{20(x-1)}\). Sampling \(Y\) yields \(C(x,y)=B(x(0.1y+0.9),1)=e^{2x(y+9)-20}\). Observing \(Y=2\) yields \(D(x,y)=y^{2}}{ y^{2}}C(x,0)=2x^{2}y^{2} e^{18x-20}\). To normalize, we divide by \(D(1,1)=2e^{-2}\), obtaining \(E(x,y)==x^{2}y^{2}e^{18(x-1)}\) since \(A(x,y)=1\).

As described above, we can extract from this GF the posterior probability of, for example, exactly 10 individuals \([X=10]=}{ x^{10}}E(0,1)=991 796451840e^{-18}\) and the expected value of the posterior \([X]=E(1,1)=20\).

## 4 Implementation & Optimizations

The main difficulty in implementing the GF semantics is the computation of the partial derivatives. A natural approach (as followed by ) is to manipulate symbolic representations of the generating

 Language construct \(P\) & \([\![P]\!]_{}(G)()\) \\  skip & \(G()\) \\ \(P_{1};P_{2}\) & \([\![P_{2}]\!]_{}([\![P_{1}]\!]_{}(G))()\) \\ \(X_{k}:=^{}+c\) & \(x_{k}^{c} G(^{})\) where \(x_{k}^{}:=x_{k}^{a_{k}}\) and \(x_{k}^{}:=x_{k}x_{k}^{a_{k}}\) for \(i k\) \\ if \(X_{k} A\{P_{1}\}\{P_{2}\}\) & \([\![P_{1}]\!]_{}(G_{X_{k} A})+[\![P_{2}]\!]_{}(G-G_{X_ {k} A})\) \\  & where \(G_{X_{k} A}()=_{i A}^{2}G((k  0))}{i!}x_{k}^{i}\) \\ \(X_{k} D\) & \(G([k 1])(D)(x_{k})\) \\ \(X_{k} D(X_{j})\) & \(G([k 1],j x_{j}(D(1))(x_{k})])\) \\  & for \(D[\![\) binomial\(-p),\)\((-,p),\)\((-)\)\(\!]\) \\  & \(G(x[k 1])+x_{j}(x_{k}-1)_{j}G([k 1])\) & for \(D=(-)\) \\  & \(G_{X_{k} A}()=_{i A}^{2}G((k  0))}{i!}x_{i}^{i}\) \\ Normalization & \((G):=)}\) \\  

Table 2: Generating function semantics of programming constructsfunctions and to use computer algebra for the derivatives. However this usually scales badly, as demonstrated by Winner et al. , because the size of the generating functions usually grows quickly with the data conditioned on. To see why, note that every \(\,X_{k}=d\) statement in the program is translated to a \(d\)-th partial derivative. Since probabilistic programs tend to contain many data points, it is common for the total order of derivatives to be in the hundreds. The size of the symbolic representation of a function can (and typically does) grow exponentially in the order of the derivative: the derivative of the product of two functions \(f g\) is the sum of two products \(f^{} g+f g^{}\), so the representation doubles in size. Hence the running time would be \((2^{d})\) where \(d\) is the sum of all observed values, which is clearly unacceptable.

Instead, we exploit the fact that we do not need to generate the full representation of a GF, but merely to _evaluate it and its derivatives_. We implement our own _automatic differentiation_ framework for this because existing ones are not designed for computing derivatives of order greater than, say, 4 or 5. In fact, it is more efficient to work with Taylor polynomials instead of higher derivatives directly. Winner et al.  already do this for the population model (with only one variable), and we extend this to our more general setting with multiple variables, requiring _multivariate Taylor polynomials_. In this approach, derivatives are the easy part as they can be read off the Taylor coefficients, but the composition of Taylor polynomials is the bottleneck. Winner et al.  use a naive \(O(d^{3})\) approach, which is fast enough for their single-variable use case.

Running timeFor \(n\) variables, naive composition of Taylor polynomials takes \(O(d^{3n})\) time, where \(d\) is the sum of all observations in the program, i.e. the total order of differentiation, i.e. the degree of the polynomial. Note that this is polynomial in \(d\), contrary to the symbolic approach, but exponential in the number of variables \(n\). This is not as bad as it seems because in many cases, the number of variables can be kept to one or two, as opposed to the values of data points (such as the models from Section 5). In fact, we exploit the specific composition structure of generating functions to achieve \(O(d^{3})\) for \(n=1\) and \(O(d^{n+3})\) for \(n 2\) in the worst case, while often being faster in practice. Overall, our implementation takes \(O(sd^{n+3})\) time in the worst case, where \(s\) is the number of statements in the program, \(d\) is the sum of all observed values, and \(n\) is the number of program variables (see Appendix C.3).

Reducing the number of variablesGiven the exponential running time in \(n\), it is crucial to reduce the number of variables when writing probabilistic programs. For one thing, program variables that are no longer needed can often be reused for a different purpose later. Furthermore, assignment and sampling can be combined with addition: \(X_{k}+=\) stands for \(X_{n+1}:=;X_{k}:=X_{k}+X_{n+1}\) and \(X_{k}+ D\) for \(X_{n+1} D;X_{k}:=X_{k}+X_{n+1}\). The GFs for these statements can easily be computed without introducing the temporary variable \(X_{n+1}\). Similarly, in \(\,\) statements and if-conditions, we use the shorthand \(m D\) with \(m\) for the event \(X_{n+1}=m\) where \(X_{n+1} D\). Probabilistic programs typically contain many such observations, in particular from compound distributions. Hence it is worthwhile to optimize the generating function to avoid this extra variable \(X_{n+1}\). Winner and Sheldon  can avoid an extra variable for a compound binomial distribution in the context of a specific model. We extend this to our more general setting with continuous variables, and also present optimized semantics for compound Poisson, negative binomial, and Bernoulli distributions. In fact, this optimization is essential to achieving good performance for many of the examples in Section 5. The optimized translation and its correctness proof can be found in Appendix C.2.

ImplementationOur tool _Genfer_ reads a program file and outputs the _posterior mean_, _variance_, _skewness_, and _kurtosis_ of a specified variable. For discrete variables supported on \(\), it also computes the _posterior probability masses_ up to a configurable threshold. To have tight control over performance, especially for the multivariate Taylor polynomials, Genfer is written in Rust , a safe systems programming language. Our implementation is available on GitHub: github.com/fzaiser/genfer

Numerical issuesGenfer can use several number formats for its computations: 64-bit floating point (the default and fastest), floating point with a user-specified precision, and rational numbers (if no irrational numbers occur). To ensure that the floating-point results are numerically stable, we also implemented interval arithmetic to bound the rounding errors. Initially, we found that programs with continuous distributions led to catastrophic cancellation errors, due to the logarithmic term in their GFs, whose Taylor expansion is badly behaved. We fixed this problem with a slightly modified representation of the GFs, avoiding the logarithms (details in Appendix C). For all the examples in Section 5.2, our results are accurate up to at least 5 significant digits.

## 5 Empirical Evaluation

### Comparison with exact inference methods

We compare our tool Genfer with the following tools for exact Bayesian inference: Dice , which uses weighted model counting, PSI , which manipulates density functions using computer algebra, and Prodigy , which is based on generating functions like Genfer, but uses computer algebra instead of automatic differentiation.1 We evaluate them on the PSI benchmarks , excluding those that only PSI supports, e.g. due to observations from continuous distributions. Most benchmarks only use finite discrete distributions (labeled "F"), but three feature continuous priors (labeled "C").

We measured the wall-clock inference time for each tool, excluding startup time and input file parsing, and recorded the minimum from 5 consecutive runs with a one-hour timeout.2 Dice and Genfer default to floating-point (FP) numbers, whereas Prodigy and PSI use rational numbers, which is slower but prevents rounding errors. For a fair comparison, we evaluated all tools in rational mode and separately compared Dice with Genfer in FP mode. The results (Table 3) demonstrate Genfer's speed even on finite discrete models, despite our primary focus on models with infinite support.

### Comparison with approximate inference methods

It is impossible to compare our approach with other exact inference methods on realistic models with infinite support (Section 5.3): the scalable systems Dice  and SPPL  don't support such priors and the symbolic solvers PSI  and Prodigy  run out of memory or time out after an hour.

**Truncation** As an alternative, we considered approximating the posterior by truncating discrete distributions with infinite support. This reduces the problem to finite discrete inference, which is more amenable to exact techniques. We decided against this approach because Winner and Sheldon  already demonstrated its inferiority to GF-based exact inference on their graphical model. Moreover, it is harder to truncate general probabilistic programs, and even impossible for continuous priors.

**Monte-Carlo inference** Hence, we compare our approach with Monte Carlo inference methods. Specifically, we choose the Anglican  probabilistic programming system because it offers the best built-in support for discrete models with many state-of-the-art inference algorithms. Other popular systems are less suitable: Gen  specializes in programmable inference; Stan , Turing , and Pyro  mainly target continuous models; and WebPPL's  discrete inference algorithms are less extensive than Anglican's (e.g. no support for interacting particle MCMC).

**Methodology** The approximation error of a Monte Carlo inference algorithm depends on its _settings_3 (e.g. the number of particles for SMC) and decreases with the number of samples the longer it is run. To ensure a fair comparison, we use the following setup: for each inference problem, we run several inference algorithms with various _configurations_ (settings and sampling budgets) and

  Tool & Genfer (FP) & Dice (FP) & Genfer (\(\)) & Dice (\(\)) & Prodigy & PSI \\  alarm (F) & **0.0005s** & 0.0067s & **0.0012s** & 0.0066s & 0.011s & 0.0053s \\ clickGraph (C) & **0.11s** & unsupported & **3.4s** & unsupported & unsupported & 46s \\ clinicalTrial (C) & **150s** & unsupported & **1117s** & unsupported & unsupported & timeout \\ clinicalTrial2 (C) & **0.0024s** & unsupported & **0.031s** & unsupported & unsupported & 0.46s \\ digitRecognition (F) & **0.021s** & 0.83s & **0.11s** & 2.7s & 31s & 146s \\ evidence1 (F) & **0.0002s** & 0.0057s & **0.0003s** & 0.0056s & 0.0030s & 0.0016s \\ evidence2 (F) & **0.0002s** & 0.0056s & **0.0004s** & 0.0057s & 0.0032s & 0.0018s \\ grass (F) & **0.0008s** & 0.0067s & **0.0044s** & 0.0067s & 0.019s & 0.014s \\ murderMystery (F) & **0.0002s** & 0.0055s & **0.0003s** & 0.0057s & 0.0028s & 0.0021s \\ noisyOr (F) & **0.0016s** & 0.0085s & 0.019s & **0.0088s** & 0.21s & 0.055s \\ twoCoins (F) & **0.0002s** & 0.0054s & **0.0003s** & 0.0057s & 0.0032s & 0.0017s \\ 

Table 3: Comparison of inference times of tools for exact inference on PSI’s benchmarks report the approximation error and the elapsed time. To measure the quality of the approximation, we report the _total variation distance (TVD)_ between the exact solution and the approximate posterior distribution, as well as the _approximation errors_ of the posterior mean \(\), standard deviation \(\), skewness (third standardized moment) \(S\), and kurtosis \(K\). To ensure invariance of our error metrics under translation and scaling of the distribution, we compute the error of the mean as \(-]}{}\), where \(\) is the true posterior mean, \(\) its approximation, and \(\) the true posterior standard deviation; the relative error of the standard deviation \(\) (because \(\) is invariant under translation but not scaling), and the absolute error of skewness and kurtosis (because they are invariant under both translation and scaling). To reduce noise, we average all these error measures and the computation times over 20 runs and report the standard error as error bars. We run several well-known _inference algorithms_ implemented in Anglican: importance sampling (IS), Lightweight Metropolis-Hastings (LMH), Random Walk Metropolis-Hastings (RMH), Sequential Monte Carlo (SMC), Particle Gibbs (PGibbs), and interacting particle MCMC (IPMCMC). For comparability, in all experiments, each algorithm is run with two sampling budgets and, if possible, two different settings (one being the defaults) for a total of four configurations. The _sampling budgets_ were 1000 or 10000, because significantly lower sample sizes gave unusable results and significantly higher sample sizes took much more time than our exact method. We discard the first 20% of the samples, a standard procedure called "burn-in".

Note that this setup is generous to the approximate methods because we only report the average time for one run of each configuration. However, in practice, one does not know the best configuration, so the algorithms need to be run several times with different settings. By contrast, our method requires only one run because the result is exact.

### Benchmarks with infinite-support distributions

Population ecologyOur first benchmark comes from [26; 27] and models animal populations. We have seen a simplified version in Example 2.1. Here we model a population \(N_{k}\) at time steps \(k=0,,m\). At each time step, there is a Poisson-distributed number of new arrivals, which are added to the binomially distributed number of survivors from the previous time step. Each individual is observed with a fixed probability \(\), so the number of observed individuals is binomially distributed:

\[_{k}(_{k}); _{k}(N_{k-1},);\\ N_{k}:=_{k}+_{k};_{k} (N_{k},);\]

where the model parameters \(_{k},\) are taken from ; the detection probability \(\) is set to \(0.2\) ( considers a range of values, but we pick one for space reasons); and the observed number \(y_{k}\) of individuals in the population at time step \(k\) is simulated from the same ground truth as . The goal is to infer the final number \(N_{m}\) of individuals in the population. We set the population size model parameter and hence the observed values which influence the running time to be 4 times larger than the largest in  (see details in Appendix D.3). The results (Fig. 0(a)) show that our method is superior to MCMC methods in both computation time and accuracy since it is exact.

ModificationsWhile this model was already solved exactly in , our probabilistic programming approach makes it trivial to modify the model, since the whole inference is automated and one only needs to change a few lines of the program: (a) we can model the possibility of natural disasters affecting the offspring rate with a conditional: \((0.1);\) if \(=1\{_{k}(^{ })\}\{_{k}( )\}\), or (b) instead of a single population, we can model populations of two kinds of individuals that interact, i.e. a _multitype_ branching process (see Fig. 0(c)). None

Figure 1: Comparison of the population model and its modifications with approximate inference: mean and standard error of the computation time and TVD over 20 repeated runs.

of these modifications can be handled by  or . The results of the first modification (Fig. 0(b)) are very similar. The more complex second modification takes longer to solve exactly, but less time than approximate inference with 10000 samples, and achieves zero error.

**Switchpoint model** Our second benchmark is Bayesian switchpoint analysis, which is about detecting a change in the frequency of certain events over time. We use the model from  with continuous priors and its 111 real-world data points about the frequency of coal-mining accidents. We compare both the moment errors (Fig. 3) and the TVD errors (Fig. 1(a)). In both cases, the approximations are less accurate and take longer than our exact method.

**Mixture model** We consider a binary mixture model on the same data set, with equal mixture weights and a geometric prior for the rates: each data point is observed from a mixture of two Poisson distributions with different rates and the task is to infer these rates. Due to their multimodality, mixture models are notoriously hard for approximate inference methods, which is confirmed in Fig. 1(b). Even the runs with the lowest error cover only one of the two modes (cf. the sample histogram in Fig. 1(c)).

**Hidden Markov model** We use a hidden Markov model based on [22, Section 2.2], but involving infinite (geometric) priors. It is a two-state system with known transition probabilities and the rate for the observed data depends on the hidden state. We run this model on 30 simulated data points. For this model as well, our method clearly outperforms approximate methods (Fig. 1(d)).

To our knowledge, our approach is the first to find an exact solution to these problems, except the very first problem without the modifications, which appeared in . For brevity, we only presented the most important aspects of these benchmarks, relegating their encoding as probabilistic programs to Appendix D.3. Code and reproduction instructions are provided in the supplementary material.

## 6 Conclusion

By leveraging generating functions, we have developed and proven correct a framework for exact Bayesian inference on discrete models, even with infinite support and continuous priors. We have demonstrated competitive performance on a range of models specified in an expressive probabilistic programming language, which our tool Genfer processes automatically.

**Future work** It is a natural question how our method could be integrated with a more general probabilistic programming system. For example, in a sampling-based inference algorithm, one could imagine using generating functions to solve subprograms exactly if this is possible. More generally, it would be desirable to explore how the compositionality of the GF translation can be improved. As it stands, our GF translation describes the joint distribution of all program variables - we never reason "locally" about a subset of the variables. A compositional approach would likely facilitate the application of the GF method to functional probabilistic languages like Anglican.

Figure 3: Comparison of moments for the switchpoint model: approximate inference vs our method.

Figure 2: Plots for the switchpoint, mixture, and hidden Markov model.