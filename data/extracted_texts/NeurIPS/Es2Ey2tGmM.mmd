# Constrained Diffusion Models via Dual Training

Shervin Khalafi

Dongsheng Ding1

Alejandro Ribeiro

{shervink,dongshed,aribeiro}@seas.upenn.edu

University of Pennsylvania

###### Abstract

Diffusion models have attained prominence for their ability to synthesize a probability distribution for a given dataset via a diffusion process, enabling the generation of new data points with high fidelity. However, diffusion processes are prone to generating samples that reflect biases in a training dataset. To address this issue, we develop constrained diffusion models by imposing diffusion constraints based on desired distributions that are informed by requirements. Specifically, we cast the training of diffusion models under requirements as a constrained distribution optimization problem that aims to reduce the distribution difference between original and generated data while obeying constraints on the distribution of generated data. We show that our constrained diffusion models generate new data from a mixture data distribution that achieves the optimal trade-off among objective and constraints. To train constrained diffusion models, we develop a dual training algorithm and characterize the optimality of the trained constrained diffusion model. We empirically demonstrate the effectiveness of our constrained models in two constrained generation tasks: (i) we consider a dataset with one or more underrepresented classes where we train the model with constraints to ensure fairly sampling from all classes during inference; (ii) we fine-tune a pre-trained diffusion model to sample from a new dataset while avoiding overfitting.

## 1 Introduction

Diffusion models have become a driving force of modern generative modeling, achieving ground-breaking performance in tasks ranging from image/video/audio generation  to molecular design for drug discovery . Diffusion models learn diffusion processes that produce a probability distribution for a given dataset (e.g., images) from which we can generate new data (e.g., classic models ). As diffusion models are used to generate data with societal impacts, e.g., art generation and content creation for media, they must comply with requirements from specific domains, e.g., social fairness in image generation , aesthetic properties of images , bioactivity in molecule generation , and more .

Classic diffusion models  have been extended to generate data under different requirements through either first-principle methods or fine-tuning. In image generation with fairness, for instance, first principle methods directly mitigate biases towards social/ethical identities by revising the training loss functions per biased/unbiased data ; while fine-tuning methods align biased diffusion models with desired data distributions by optimizing the associated metrics . Although these methods allow us to equip diffusion models with specific requirements, they are often designed for particular generation tasks and do not provide transparency on how these requirements are satisfied. Since diffusion models are trained by minimizing the loss functions of diffusion processes, it is natural to incorporate requirements into diffusion models by imposing constraints on these optimizationproblems. Therefore, it is imperative to develop diffusion models under constraints by generalizing constrained learning methods and theory (e.g., [9; 10; 22; 36]) for diffusion models.

In this work, we formulate the training of diffusion models under requirements as a constrained distribution optimization problem in which the objective function measures a training loss induced by the original data distribution, and the constraints require other training losses induced by some desirable data distributions to be small. This constrained formulation can be instantiated for several critical requirements. For instance, to promote fairness for unrepresented groups, the constraints can encode the closeness of the model to the distributions of underrepresented data. Compared with the typical importance re-weighting method , our constrained formulation provides an optimal trade-off between matching given data distribution and following reference distribution. Not limited to constraints with other desirable data distributions, our constrained formulation captures more general requirements. For instance, when adapting a pretrained diffusion model to new data, the constraints require the model to be close to the pretrained model, not degrading the original generation ability. Specifically, our main contribution is three-fold.

1. We propose and analyze constrained diffusion models from the perspective of constrained optimization in an infinite-dimensional distribution space, where the constraints require KL divergences between the model and our desired data distributions to be under some thresholds. We exploit the strong duality in convex optimization to show that our constrained diffusion models generate new data from a mixture data distribution that achieves the optimal trade-off among objective and constraints.
2. To train constrained diffusion models, we introduce parametrized constrained diffusion models and develop a Lagrangian-based dual training algorithm. We exploit the relation between un/parametrized problems to show that constrained diffusion models generate new data from the optimal mixture distribution, up to some optimization/parametrization errors.
3. We empirically demonstrate the merit of our constrained diffusion models in two aforementioned requirements. In the fair generation task, we show that our constrained model promotes sampling more from the minority classes compared to unconstrained models, leading to fair sampling across all classes. In the adaptation task, we show that our fine-tuned constrained model learns to generate new data without significantly degrading the original generation ability, compared to the unconstrained model which tends to overfit to new data.

**Related work.** As a first-principle method, our constrained diffusion approach is more relevant to diffusion models that incorporate requirements in distribution space [20; 35; 49; 21; 60; 28], rather than those applied in sample space [37; 53; 29; 27; 26; 17; 48; 25]. In comparison with conditional diffusion models that restrict generation through conditional information [20; 35; 1], our constrained diffusion models impose distribution constraints within the constrained optimization framework. Compared to compositional generation [49; 21; 60] and fair diffusion , our work provides a constrained learning approach to balance different distribution models using Lagrangian multipliers, which is different from equal weights [49; 21], hyperparameter  or fair guidance . Our constrained approach is also relevant to the importance re-weighting method for diffusion models  and GANs , which reduces bias in a dataset by re-weighting it with a pre-trained debiased density ratio. In contrast, we design our diffusion models to mitigate the bias in a dataset by imposing distribution constraints without pre-training. In addition to being distinct from existing methods, we provide a systematic study of our constrained diffusion models, covering duality analysis, dual-based algorithm design, and convergence analysis, which is absent in the diffusion model literature.

Our work is also pertinent to recently surging fine-tuning and alignment methods that aim to improve pre-trained diffusion models by optimizing their downstream performance, e.g., aesthetic scores of images. In reward-guided fine-tuning methods, such as supervised learning [45; 80; 76], control-based feedback learning [77; 65; 71; 70; 18], and reinforcement learning [23; 32; 24; 72; 5; 82], reward functions have to be pre-trained from an authentic evaluation dataset, and the trade-off for reward functions in pre-trained diffusion models is often regulated heuristically. In contrast, our constrained approach directly minimizes the gap between a fine-tuning model and a high-quality dataset with the desired properties, while ensuring the generated outputs being close to that of pre-trained models.

Compared to other generative models under requirements (e.g., VAEs , GANs ), and classical sampling methods (e.g., Langevin dynamics and Stein variational gradient descent ), our work is different because we focus on diffusion-based generative models.

Preliminaries

We overview diffusion models from the perspective of variational inference  by presenting forward/backward processes in Section 2.1, and the evidence lower bound in Section 2.2.

### Forward and backward processes

The forward process begins with a true data sample \(x_{0}^{d}\), and generates latent variables \(\{x_{t}\}_{t=\,1}^{T}\) from \(t=1\) to \(T\) by adding white noise recursively. The joint distribution of latent variables results from conditional probabilities \(q(x_{1:T}\,|\,x_{0})=_{t\,=\,1}^{T}q(x_{t}\,|\,x_{t-1})\), where the distribution of latent variable \(x_{t}\) conditioned on the previous latent \(x_{t-1}\) is given by a Gaussian distribution \(q(x_{t}\,|\,x_{t-1})\;=\;(x_{t};_{t},_{q}^{2}(t)I)\), where \(_{t}=}\,x_{t-1}\) and \(_{q}^{2}(t)=1-_{t}\). Since the forward process is a linear Gaussian model with pre-selected mean and variance, it is solely determined by the data distribution \(q(x_{0})\). We often refer to \(q(x_{0})\) as a forward process.

The backward process begins with the latent \(x_{T}\) sampled from the standard Gaussian \(p(x_{T})=(x_{T};0,I)\), and decodes latent variables from \(t=T\) to \(t=0\) with a joint distribution

\[p(x_{0:T})\;=\;p(x_{T})_{t\,=\,1}^{T}p(x_{t-1}\,|\,x_{t}).\] (1)

Here, \(p\) is our distribution model that can be used to generate new samples. We denote by \(\) the set of all joint distributions over \(x_{0:T}\) in form of (1), where \(p(x_{t-1}\,|\,x_{t})\) is a conditional Gaussian with a fixed variance (see Appendix A). Throughout the paper, we work in the convergent regimes of the backward process (e.g., [15; 11; 2]). Without loss of generality, we adopt the convergent regime in  by taking the scheduling parameter \(_{1}=1-1/T^{c_{0}}\) and \(_{t}=1-c_{T}((1-_{1})(1+c_{T})^{t},1)\) for \(t>1\), and the variance as \(_{p}^{2}(t)=1/_{t}-1\), where \(c_{T}:=c_{1}(T)/T\) and \(c_{0}\), \(c_{1}\) are some constants. Hence, \(_{T} 0\) implies \(q(x_{T})(x_{T};0,I)\). Thus, \(q(x_{0:T})\). Also, \(_{1} 1\) implies \(q(x_{1}) q(x_{0})\). It is ready to generalize our results to other diffusion processes (e.g., [46; 38; 3]).

### The evidence lower bound (ELBO)

Denote the KL divergence of distribution \(q\) from distribution \(p\) by \(D_{}(q\,\|\,p):=_{x q(x)}()\). Generative diffusion modeling aims to generate samples whose distribution is close to that of an observed dataset of samples. Formally, we express this objective as maximizing the log-likelihood of an observation generated by the diffusion model: \(*{maximize}_{p\,\,}_{q(x_{0})}[\, p(x _{0})\,]\), where

\[_{q(x_{0})}[\, p(x_{0})\,]\;=\;E(p;q)\;+\;_ {q(x_{0})}[\,D_{}(q(x_{1:T}\,|\,x_{0})\,\|\,p(x_{1:T}\,|\,x _{0}))\,]\] (2)

and \(E(p;q):=_{q(x_{0})}_{q(x_{1:T}\,|\,x_{0})})}{q(x_{1:T}\,|\,x_{0})}\) is known as ELBO in variational inference [7; 55]. Alternatively, we aim to minimize the KL divergence between the forward/backward processes,

\[D_{}(q(x_{0:T})\,\|\,p(x_{0:T}))\;=\;-\,E(p;q)\;+\;_{q(x_{0})}[\, q(x_{0})\,].\] (3)

Thus, we connect the log-likelihood maximization to the KL divergence minimization via ELBO.

**Lemma 1** (Equivalent formulations).: _The ELBO maximization and the KL divergence minimization are equivalent over the distribution space \(\), and the unique solution of these two problems is a solution for the log-likelihood maximization problem, i.e.,_

\[*{maximize}_{p\,\,}\;E(p;q)\;\;\; \;*{minimize}_{p\,\,}\;D_{}(q(x_{0: T})\,\|\,p(x_{0:T}))\;\;\;\;*{maximize}_{p\,\,}\; _{q(x_{0})}[\, p(x_{0})\,]\]

See Appendix B.1 for proof. Lemma 1 states that improving the ELBO score increases the likelihood of a backward process that generates the data, together with the fit of a backward process to the forward process. Hence, finding the best backward process becomes optimizing one of three equivalent objectives. In practice, ELBO serves as a loss function approximated by

\[E(p;q)\;\;-\,_{t\,=\,2}^{T}_{q(x_{0})}_{q(x_{t }\,|\,x_{0})}[\,D_{}(q(x_{t-1}\,|\,x_{t},x_{0})\,\|\,p(x_{t- 1}\,|\,x_{t}))\,].\] (4)With the variance schedule described in Section 2.1, it is known that this approximation is almost exact (see Appendix A and also ), which is our focal setting. Using standard diffusion derivations , the ELBO maximization can be shown to equal to a quadratic loss minimization,

\[\,\,}{}\ \ _{x_{0},\,t,\,x_{t}}\, \,(x_{t},t)- q(x_{t})^{2} \,\] (5)

where \(_{x_{0},t,x_{t}}\) is an expectation over the data distribution \(q(x_{0})\), a discrete distribution \(p_{}(t)\) from \(2\) to \(T\), and the forward process \(q(x_{t}\,|\,x_{0})\) at time \(t\) given the data sample \(x_{0}\); see Appendix A for details. The minimization is done to find a function \(\,\,\) that can best predict the gradient of the forward process over data \( q(x_{t})\), commonly called the (Stein) score function, where \(\) is a set of valid score functions mapping from \(^{d}\) to \(^{d}\). In practice, however, we parametrize the estimator \((x_{t},t)\) as \(_{}(x_{t},t)\) with parameter \(\), which gives our focal objective of generative modeling: \(}_{\,\, _{x_{0},\,t,x_{t}}}\,_{}(x_{t},t )- q(x_{t})^{2}\,\). A parametrized form of \(p(x_{t-1}\,|\,x_{t})\) associated with \(_{}(x_{t},t)\) is denoted by \(p_{}(x_{t-1}\,|\,x_{t})\) and the backward process has a parametrized joint distribution \(p_{}(x_{0:T})\). We remark that the prediction problem (5) can be also be formulated as data or noise prediction instead , with our results directly transferable to these formulations.

## 3 Variational constrained diffusion models

We introduce constrained diffusion models by considering the unparametrized set of joint distributions in Section 3.1, and illustrating constraints via two examples in Section 3.2.

### KL divergence-constrained diffusion model: unparametrized case

The standard diffusion model specifies a single data distribution, denoted by \(q\) in Lemma 1. To account for other generation requirements, we introduce \(m\) additional data distributions \(\{q^{i}\}_{i=\,1}^{m}\) that represent \(m\) desired properties on generated data. To incorporate new properties into the diffusion model, we formulate an unparametrized KL divergence-constrained optimization problem,

\[}{}&D _{}(q(x_{0:T})\,\|\,p(x_{0:T}))\\ &D_{}(q^{i}(x_{0:T})\,\|\,p(x_{0:T}) )\ \ b_{i}\ \ i=1,,m.\] (U-KL)

Let an optimal solution to Problem (U-KL) be \(p^{}\). Then the optimal value of the objective function is \(F^{}:=D_{}(q\,\|\,p^{})\). Problem (U-KL) aims to find a model \(p^{}\) that generates data from the original distribution \(q\) while staying close to \(m\) distributions \(\{q^{i}\}_{i=\,1}^{m}\) that encode our desired properties, e.g., unbiasedness towards minorities. Let the Lagrangian for Problem (U-KL) be

\[(p,)\ =\ D_{}(q(x_{0:T})\,\|\,p(x_{0:T})) \,+\,_{i\,=\,1}^{m}_{i}\,\,D_{}(q^{i}(x_{0:T} )\,\|\,p(x_{0:T}))-b_{i}\,\] (6)

for \( 0\). The dual function \(g()\) is given by \(g():=_{p\,\,}(p,)\), which is always concave.

To make Problem (U-KL) meaningful, we assume the constraints are strictly satisfied by some model.

**Assumption 1** (Strict feasibility).: _There exists a model \(p\,\,\) and \(>0\) such that \(D_{}(q^{i}(x_{0:T})\,\|\,p(x_{0:T})) b_{i}-\) for all \(i=1,,m\)._

Let an optimal dual variable of Problem (U-KL) be \(^{}_{\,\,0}g()\), and the optimal value of the dual function be \(D^{}:=g(^{})\). From weak duality, the duality gap is non-negative, i.e., \(F^{}-D^{} 0\). Moreover, due to the convexity of KL divergence, Problem (U-KL) is a convex optimization problem, and thus it satisfies strong duality; see Appendix B.2 for proof.

**Lemma 2** (Strong duality).: _Let Assumption 1 hold. Then, Problem (U-KL) has zero duality gap, i.e., \(F^{}=D^{}\). Moreover, \((p^{},^{})\) is an optimal primal-dual pair of Problem (U-KL)._

Let a mixture data distribution be \(q^{()}_{}:=\,q+_{i\,=\,1}^{m}^{i}q^{i}\, \,/(1+^{}1)\) for \( 0\). We denote by \(q^{()}_{}(x_{0:T})\) a joint distribution of the forward process with data distribution \(q^{()}_{}\). Leveraging strong duality, we show that an optimal model can be obtained by solving an equivalent unconstrained problem in Theorem 1 and its proof is deferred to Appendix B.3.

**Theorem 1** (Optimal constrained model).: _Let Assumption 1 hold. Then, Problem (U-KL) equals_

\[*{minimize}_{p\,\,}\;\;D_{}(q^{( ^{})}_{}(x_{0:T})\,\|\,p(x_{0:T}))\] (U-MIX)

_where \(q^{(^{})}_{}(x_{0:T})\) is the joint distribution of the forward process at an optimal dual variable \(^{}\)._

Theorem 1 states that the KL divergence-constrained problem reduces to an unconstrained KL divergence minimization problem. We notice that the KL divergence is zero if and only if two probability distributions match each other. Hence, \(q^{(^{})}_{}(x_{0:T})\) is the optimal solution to Problem (U-MIX).

**Corollary 1**.: _Let Assumption 1 hold. Then, the solution of Problem (U-MIX), i.e., \(p^{}(x_{0:T})=q^{(^{})}_{}(x_{0:T})\), is the solution of Problem (U-KL)._

Let \(^{i}:=b^{i}-_{q^{i}(x_{0})}[\, q^{i}(x_{0})\,]\). Application of Equality (3) to Problem (U-KL) yields an ELBO-based constrained optimization problem,

\[*{minimize}_{p\,\,}&-E(p;q)\\ *{subject\,to}&-E(p;q^{i})\;\;^{i}\;\;\;i=1,,m.\] (U-ELBO)

Recall the model representation in Section 2.2, we can characterize each joint distribution \(p\) with a function \(\). Moreover, ELBO reduces to the denoising matching term that has a simplified quadratic form given in Section 2.2. With this reformulation in mind, we cast Problem (U-ELBO) into a convex optimization problem over the function space \(\),

\[*{minimize}_{\,\,}& _{q(x_{0}),\,t,\,x_{t}}[\,\|(x_{t},t)-  q(x_{t})\|^{2}\,]\\ *{subject\,to}&_{q^{i}(x_{0}),\,t,\,x_{t}}[\, \|(x_{t},t)- q^{i}(x_{t})\|^{2}\,]\; \;^{i}\;\;\;i=1,,m\] (U-LOSS)

where \(^{i}:=(^{i}-v)/\). Here, the notation \(v\) is a constant shift due to the variance mismatch term; see it in Appendix A. We note that scaling or shifting objective and constraints from both sides with some constants doesn't alter the solution to a constrained optimization problem. Thus, the key difference between Problems (U-KL) and (U-LOSS) is the optimization variable (respectively, \(p\) and \(\)). Let the Lagrangian \(_{s}(,)\) for Problem (U-LOSS) be

\[_{q(x_{0}),\,t,\,x_{t}}[\|(x_{t},t)- q (x_{t})\|^{2}]+_{i\,=\,1}^{m}_{i}(_{q^{ i}(x_{0}),\,t,\,x_{t}}[\|(x_{t},t)- q^{i}(x_{t}) \|^{2}]-^{i}).\]

Let the associated dual function be \(g_{s}():=_{\,\,}_{s}(,)\) for \( 0\). Hence, \(g()\) and \(g_{s}()\) have the same maximizer \(^{}\), and the partial minimizer \(^{}=*{argmin}_{\,\,} _{s}(,^{})\) is the solution to Problem (U-LOSS). Hence, an optimal primal-dual pair \((^{},^{})\) to Problem (U-LOSS) gives an optimal primal-dual pair \((p^{},^{})\) for Problem (U-KL), where \(p^{}\) is a joint distribution of the backward process induced by \(^{}\). By this dual property, we take a dual perspective to train constrained diffusion models: we maximize the dual function \(g_{s}()\) to obtain the optimal dual variable \(^{}\), and then recover the solution \(^{}\) by minimizing the Lagrangian \(_{s}(,^{})\).

### Examples of KL divergence constraints

To illustrate our KL-divergence constraints, we provide two generation tasks of exemplary.

1. **Fairness to underrepresented classes.** We consider a fair image generation task in which some classes are underrepresented in the available training dataset. An example of this would be the Celeb-A dataset  which contains pictures of celebrity faces with those labeled as male being underrepresented (42% Male vs 58% Female). To promote representation of the under-represented classes, we can pose it as an instance of Problem (U-KL), where each \(q^{i}\) denotes the distribution of an under-represented subset or minority class of \(q\).
2. **Adapting pretrained model to new data.** Given a pretrained diffusion model over some original dataset that is no longer accessible, we aim to fine-tune the pretrained model for generating data from a new data distribution. Similarly, we can pose this as an instance of Problem (U-KL), where \(q^{1}\) denotes the distribution of the new data and \(q\) is the distribution of samples generated by the pre-trained model.

Let \(h_{i}:=-_{q^{i}(x_{0})}[\, q^{i}(x_{0})\,]\) be the differential entropy of data distribution \(q^{i}\). We relate the KL divergence constraints with the optimal dual variable through entropy in Theorem 2.

**Theorem 2**.: _Let Assumption 1 hold, and the supports of data distributions \(q\) and \(\{q^{i}\}_{i=\,1}^{m}\) be disjoint. Then, the optimal dual variables \(^{}\) to Problem (U-ELBO) are given by_

\[_{i}}{1\,+\,(^{})^{T}}\ =\ ^{h_{i}\,-\,_{i}}\ i=1,,m.\]

See Appendix B.4 for proof. Theorem 2 characterizes the mixture weights in the target distribution \(q^{(^{})}_{}\): (i) the tighter a constraint is (i.e., smaller threshold \(_{i}\)), the more the model will sample from the associated distribution; (ii) for the same constraint thresholds, the model will sample more often from the associated distributions that have higher entropy \(h_{i}\). Assumption 1 can be relaxed to a feasibility condition for Problem (U-KL); see Lemma 6 in Appendix B.4.

## 4 Parametrization and dual training algorithm

Having introduced unparametrized models, we move to parametrization for constrained diffusion models in Section 4.1, provide optimality analysis of a Lagrangian-based dual method in Section 4.2, and present a practical dual training algorithm in Section 4.3.

### KL divergence-constrained diffusion model: parametrized case

With the parametrized model \(p_{}\) for \(\), we present a parameterized constrained problem,

\[*{minimize}_{}&  D_{}(q(x_{0:T})\,\|\,p_{}(x_{0:T}))\\ *{subject\ to}& D_{}(q ^{i}(x_{0:T})\,\|\,p_{}(x_{0:T}))\ \ b^{i}\ \ i=1,,m.\] (P-KL)

Let the Lagrangian for Problem (P-KL) be \(}(,):=(p_{},)\). The associated dual function \(()\) is given by \(():=_{\,}}(,)\). Let an optimal solution to Problem (P-KL) be \(^{}\). We denote \(:=p_{}\) and \(^{}:=p_{^{}}\), and the optimal objective by \(^{}:=D_{}(q\,\|\,^{})\). Let an optimal dual variable be \(^{}*{argmax}_{\,0}()\) and the optimal value of the dual function be \(^{}:=(^{})\).

Problem (P-KL) is non-convex in parameter space, and strong duality does not hold any more. Thus, unparametrized results in Section 3.1 don't directly apply to Problem (P-KL). For instance, it's invalid to find an optimal solution via an unconstrained problem as in Theorem 1, i.e., \(^{}(^{})*{argmin}_{\, }}(,^{})\) doesn't equal \(^{}\). The effect of parametrization has to be characterized. However, regardless of parametrization, weak duality always holds, i.e., \(^{}-^{} 0\).

To quantify the optimality of \(^{}(^{})\) (closeness of it to \(q^{}_{}\)), we study a practical representation of model \(p_{}\) as a parametrized function \(_{}_{}\), where \(_{}\) is the set of all parametrized score functions. Problem (U-LOSS) is in a parametrized form of

\[*{minimize}_{}& _{q(x_{0}),\,t,\,x_{t}}[\,\|_{}(x_{t},t)-  q(x_{t})\|^{2}\,]\\ *{subject\ to}&_{q^{i}(x_{0 }),\,t,\,x_{t}}[\,\|_{}(x_{t},t)- q^{i}(x_{t}) \|^{2}\,]\ \ ^{i}\ \ i=1,,m.\] (P-LOSS)

where \(^{i}:=(^{i}-v)/\). We note that Problem (P-LOSS) is equivalent to Problem (P-KL). Thus, we let the Lagrangian of Problem (P-LOSS) be \(}_{s}(,):=_{s}(_{},)\), and the dual function \(_{s}():=*{minimize}_{\,}}(,)\). Since \(()\) and \(_{s}()\) have the same maximizer \(^{}\), \(^{}*{argmin}_{\,}}_{s}(,^{})\), which naturally gives a dual training algorithm in Algorithm 1.

Denote \(^{}:=_{^{}}\). Thus, \(^{}\)-induced diffusion model is given by \(^{}(^{})\). Algorithm 1 works as a dual ascent method with two natural steps: (i) find a diffusion model with fixed dual variable \((h)\); and (ii) update the dual variable using the (sub)gradient of the Lagrangian \(_{s}(_{}(h),)\). It is known that Algorithm 1 converges to \(^{}\) since the dual function \(_{s}()\) is concave. However, such convergence in the dual domain doesn't provide optimality guarantee on the primal solution \(^{}(^{})\) due to the non-convexity in parameter space. We next exploit the optimization properties of unparametrized diffusion models in Section 3.1 to characterize the optimality of the dual training algorithm.

### Optimality analysis of dual training algorithm

We analyze the optimality of \(^{}(^{})\) as measured by its distance to \(q^{}_{}\), i.e., \((q^{}_{},\ ^{}(^{}))\), where we denote the total variation distance between two probability distributions \(p\) and \(q\) by \((q,p):=p(x)-q(x)|dx\). We first exploit the convergence analysis of diffusion models, and then characterize the additional error induced by parametrization.

Let us begin with the difference between \(^{}(^{})\) and \(q^{(^{})}_{}\) at \(^{}\). Denote a partial minimizer of the Lagrangian by \(^{}()*{argmin}_{\,\,}}_{s}(,)\) for \( 0\). Noting that \(*{minimize}_{\,\,}}_{s}(,)\) is an unconstrained diffusion problem, we are ready to quantify the difference between \(^{}()\) and \(q^{()}_{}\) for any \( 0\) using the convergence theory of diffusion models. To do so, we assume the boundedness of samples from a mixed data distribution \(q^{()}_{}\) for \( 0\), and a small score estimation error.

**Assumption 2** (Boundedness of data).: _The data samples generated from \(q^{()}_{}\) are bounded, i.e., \((\|x_{0}\| T^{c}\,|\,x_{0} q^{()}_{} )=1\) for any \( 0\) and some large constant \(c>0\)._

**Assumption 3** (Boundedness of score estimation error).: _The score estimator \(_{}(x_{t},t)\) estimates the data samples from \(q^{()}_{}\) with bounded score matching error \(_{}\)._

\[_{q^{()}_{}(x_{0}),\,t,\,x_{t}}[\,\|_{}(x_{t},t)- q(x_{t})\|^{2}\,]\ \ _{}^{2}\]

_for any \( 0\), where \(_{q^{()}_{}(x_{0}),\,t,\,x_{t}}\) is an expectation over the mixed data distribution \(q^{()}_{}(x_{0})\), a uniform distribution over \(t\) from \(2\) to \(T\), and a forward process \(q(x_{t}\,|\,x_{0})\) given the data sample \(x_{0}\)._

Since data samples are bounded, Assumption 2 is mild in practice. Assumption 3 is the typical score matching error that is near zero if the function class \(_{}\) is sufficiently rich.

With Assumptions 2 and 3, below we bound the TV distance between \(q^{()}_{}\) and \(^{}()\) using the convergence theory of diffusion models from ; see Appendix B.5 for proof.

**Lemma 3** (Convergence of diffusion model).: _Let Assumptions 2 and 3 hold. Then, the TV distance from \(^{}()\) to \(q^{()}_{}\) is bounded by_

\[(q^{()}_{},\ ^{}())\ \ D_{}(q^{()}_{}\,\|\,^{ }())}\ \ \,^{3}T}{}\,+\,\,(^{2}T) _{}.\] (7)

Lemma 3 states that the TV distance between \(q^{()}_{}\) and \(^{}()\) decays to zero with a sublinear rate \(O(})\), up to a score matching error \(O(_{})\). When the diffusion time \(T\) is large, the TV distance between \(q^{()}_{}\) and \(^{}()\) is dominated by the score matching error. Substitution of \(=^{}\) into (7) yields an upper bound on \((q^{(^{})}_{},\ ^{}(^{}))\), which is the second term of the inequality

\[(q^{}_{},\ ^{}(^{ }))  (q^{}_{},\ q^{(^{ })}_{})\ +\ (q^{(^{})}_{},\ ^{}(^{ })).\] (8)

Next, we quantify the gap between \(^{}\) and \(^{}\), which lets us bound the first term on the RHS of (8) and complete the optimality analysis. To analyze the parametrized optimal dual variable \(^{}\), we introduce the richness of the parametrized class \(_{}\) and redundancy of constraints at \(^{}\) below.

**Assumption 4** (Richness of parametrization).: _For any function \(\), there exists parameter \(\) such that \(\|_{}-\|_{L_{2}}\), where \(\|\|_{L_{2}}\) is with respect to the forward process._

**Assumption 5** (Redundancy of constraints).: _There exists \(>0\) such that_

\[_{\|\|=1}\,\|\,_{i\,=\,1}^{m}_{i}\, _{}\,_{q^{i}(x_{0}),\,t,\,x_{t}}\,[\,^{ }(x_{t},t)- q(x_{t})\,]\,\|_{L_{2}}\ \ \] (9)

_where \(_{}\) is the Frechet derivative over the function \(\) and \(^{}\) is a solution to Problem (\(\)-\(\))._

Assumption 4 is mild since the gap is small for expressive neural networks [56; 31]. Assumption 5 captures the linear independence of constraints, which is similarly used in optimization .

Due to Assumption 2, we set the function class \(\) to be bounded \(\|\,\,\|_{L_{2}} T^{c}:=R\). Using Problem (\(\)-\(\)), we prove that the unparametrized dual function \(g_{s}()\) is differentiable, and strongly-concave over \(\) with parameter \(\), where \(:=\{^{}+(1-)^{}, \}\) and \(:=/(1+\|^{}\|_{1}, \|^{}\|_{1})^{2}\),which leads to Lemma 4; see Appendix B.6 for their proofs.

**Lemma 4**.: _Let Assumptions 4 and 5 hold. Then, \(\|^{}-^{}\|^{2}R (1+\|^{}\|_{1})\)._

Since \((q^{}_{},\ q^{(^{})}_{ })\) is bounded by \(\|^{}-^{}\|_{1}\) (see Appendix B.6), application of Lemma 3 and Lemma 4 to (8) leads to Theorem 3; see Appendix B.7 for proof.

**Theorem 3** (Optimality of constrained diffusion model).: _Let Assumptions 1-5 hold. Then, the total variation distance between \(^{}(^{})\) and \(q^{}_{}\) is upper bounded by_

\[(q^{}_{},\ ^{}(^{}))\ \ \,^{3}T}{}\,+\,\,m\,R(1+\| ^{}\|_{1})}\,+\,\,(^{2}T )\,_{}.\]

Theorem 3 states that the \(\) distance between \(^{}(^{})\) and \(q^{}_{}\) decays to zero with a sublinear rate \(O(})\), up to a parametrization gap \(O()\) and a prediction error \(O(_{})\). When the parametrization is rich enough, the parametrization gap \(\) and the prediction error \(O(_{})\) are nearly zero. In this case, if the diffusion time \(T\) is large, then \(^{}(^{})\) is close to \(q^{}_{}\) in \(\) distance, which recovers the ideal optimal constrained model in the unparametrized case in Section 3.1.

### Practical dual training algorithm

Having established the optimality of our dual training method, we futher turn Algorithm 1 into a practical algorithm. First, we relax the computation of a diffusion model \(_{}()\) in line 4 of Algorithm 1 to be approximate: \(_{s}(_{}(h),(h))_{\, \,}_{s}(_{},(h))+_{ }^{2}\), where \(_{}^{2}\) is an approximation error of training a diffusion model given \((h)\). Second, we replace the gradient in line 5 of Algorithm 1 by a stochastic gradient \(}_{x_{0}\,\,q^{i},\,t,\,x_{t}}\,\|_{}(x_{t},t)- q(x_{t})\|^{2}\,\), which enables Algorithm 1 to be a stochastic algorithm, where \(}_{x_{0}\,\,q^{i},\,t,\,x_{t}}\) is an unbiased estimate of \(_{x_{0}\,\,q^{i},\,t,\,x_{t}}\). To analyze this approximate and stochastic variant of Algorithm 1, it is useful to introduce the maximum parametrized dual function in history up to step \(h\) by \(_{}(h):=_{h^{}\,\,h}_{s}((h^{ }))\), and an upper bound of the second-order moment of stochastic gradient \(S^{2}:=_{i\,=\,1}^{m}\,}_{x_{0 }\,\,q^{i},\,t,\,x_{t}}\,\|\,_{}(h)(x_{t},t )- q(x_{t})\|^{2}\,-^{i}\,^{2}\,|\, (h)\,\).

Denote the dual variable that achieves \(_{}(h)\) by \(_{}\). To bound the \(\) distance between \(^{}(_{})\) and \(q^{}_{}\), we check the \(\) distance between \(q^{(_{})}_{}\) and \(^{}(_{})\) using Lemma 3. The rest is to analyze the convergence of \(_{}\) to \(^{}\) via application of martingale convergence. We defer their proofs to Appendix B.8 and present the optimality of \(^{}(_{})\) in Theorem 4.

**Theorem 4** (Optimality of approximate constrained diffusion model).: _Let Assumptions 1-5 hold. Then, the total variation distance between \(^{}(_{})\) and \(q^{}_{}\) is upper bounded by_

\[(q^{}_{},\ ^{}(_{}))\ \ \,^{3}T}{}+_{}\|_{1})}{}+\,(^{2}T) _{}+\,_{}^{2}+ }{}.\]Theorem 4 states that the TV distance between \(^{*}(_{})\) and \(q^{*}_{}\) decays to zero with a sublinear rate \(O(})\), up to a parametrization gap \(O()\), a score matching error \(O(_{})\), an approximation error \(O(_{})\), and stepsize \(O()\). When the parametrization is rich enough, the parametrization gap \(\) and the score matching error \(O(_{})\) are near zero. Thus, if the diffusion time \(T\) is large, then the closeness of \(^{*}(_{})\) to \(q^{*}_{}\) in TV distance is governed by the appproximation error and stepsize.

## 5 Computational experiments

We demonstrate the effectiveness of constrained diffusion models trained by our dual training algorithm in two constrained settings in Section 3.2; see Appendix C for experimental details.

**Fairness to underrepresented classes.** We train constrained diffusion models over three datasets: MNIST digits , Celeb-A faces , and Image-Net1. For MNIST and Image-Net, we create a dataset for the distribution \(q\) in (P-LOSS) by taking a subset of the dataset with equal number of samples from each class. Then we make some classes under-represented by removing their samples. For each distribution \(q^{i}\), we use samples from the associated underrepresented class. For Celeb-A, our approach is similar to MNIST except we don't remove any samples due to the existence of class imbalance in the dataset (58% female vs 42% male). For Image-Net, since the images are of high resolution, we employ the latent diffusion scheme  by imposing distribution constraints in latent space. Figures 1-3 show that our constrained model samples more often from the underrepresented classes (MNIST: 4, 5, 7; Celeb-A: male; Image-Net: 'Cassette player', 'French horn', and 'Golf ball'), leading to a more uniform sampling over all classes. This reflects our theoretical insights on promoting fairness for minority classes (see Section 3.2). Quantitatively, we observe _fairly lower FID scores_ when training over _the same dataset but with constraints_ (see Appendix C for further discussion on FID scores). Furthermore, our Image-Net experiment shows that our approach extends to the state-of-the-art diffusion models in latent space.

**Adapting pretrained model to new data.** Given a pretrained diffusion model over some original dataset \(_{}\), we fine-tune the pretrained model for generating data that resemble \(_{}\). To cast this problem into (P-KL), we let the data distribution be \(_{}\), i.e., \(q(x_{0:T})=q_{}(x_{0:T})\) and the constrained distribution be the pre-trained model, i.e., \(q^{i}(x_{0:T})=p_{_{m}}(x_{0:T})\). In our experiments, we pretrain a diffusion model on a subset of MNIST digits excluding a class of digits (MNIST: 9), and fine-tune this model using samples of the excluded digit. Figure 4 shows that our constrained fine-tuned model samples from the new class as well as all previous classes, whereas the model fine-tuned without the constraint quickly overfits to the new dataset (see Appendix C for details). Our constrained model generates much better high-quality samples than the unconstrained model.

## 6 Conclusion

We have presented a constrained optimization framework for training diffusion models under distribution constraints. We have developed a Lagrangian-based dual algorithm to train such constrained

Figure 1: Generation performance comparison of constrained and unconstrained models that are trained on MNIST with three minorities: 4, 5, 7. (Left ) Frequencies of ten digits that are generated by an unconstrained model () and our constrained model (); (Middle ) Generated digits from unconstrained model (FID 15.9 ); (Right ) Generated digits from our constrained model (FID 13.4 ).

diffusion models. Our theoretical analysis shows that our constrained diffusion model generates new data from an optimal mixture data distribution that satisfies the constraints, and we have demonstrated the effectiveness of our distribution constraints in reducing bias across three widely-used datasets.

This work directly stimulates several research directions: (i) extend our distribution constraints to other domain constraints, e.g., mirror diffusion ; (ii) incorporate conditional generations, e.g., text-to-image generation , into our constrained diffusion models; (iii) conduct experiments with text-to-image datasets to identify and address biases; (iv) improve the convergence theory using more advanced diffusion processes.

Figure 4: Fine-tuning performance comparison of constrained and unconstrained models that are trained on MNIST. (Left ) Frequencies of ten digits that are generated by a pre-trained model without digit 9 () and our fine-tuned constrained model (); (Middle ) Generated digits from unconstrained model (FID 45.9 ); (Right ) Generated digits from our constrained model (FID 25.2 ).

Figure 3: Generation performance comparison of constrained and unconstrained models that are trained on Image-Net with minority classes: ‘Cassette player’ (2), ‘French horn’ (5), and ‘Golf ball’ (8). (Left ) Frequencies of ten classes that are generated by an unconstrained model () and our constrained model (); (Middle ) Generated images from unconstrained model (FID 36.0 ); (Right) Generated images from our constrained model (FID 27.3 ).

Figure 2: Generation performance comparison of constrained and unconstrained models that are trained on Celeb-A with male minority. (Left ) Frequencies of two genders that are generated by an unconstrained model () and our constrained model (); (Middle ) Generated faces from unconstrained model (FID 19.6 ); (Right ) Generated faces from our constrained model (FID 11.6 ).