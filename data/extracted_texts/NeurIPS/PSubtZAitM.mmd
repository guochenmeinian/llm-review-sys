# Efficient Policy Evaluation Across Multiple Different Experimental Datasets

Yonghan Jung*

Purdue University

jung222@purdue.edu &Alexis Bellot*+

Independent Researcher

abellot@gmail.com

Equal contribution. Correspondence to Yonghan Jung: jung222@purdue.edu.Now at Google DeepMind. Work done partly while affiliated with Columbia University and partly in an independent capacity.

###### Abstract

Artificial intelligence systems are trained combining various observational and experimental datasets from different source sites, and are increasingly used to reason about the effectiveness of candidate policies. One common assumption in this context is that the data in source and target sites (where the candidate policy is due to be deployed) come from the same distribution. This assumption is often violated in practice, causing challenges for generalization, transportability, or external validity. Despite recent advances for determining the identifiability of the effectiveness of policies in a target domain, there are still challenges for the accurate estimation of effects from finite samples. In this paper, we develop novel graphical criteria and estimators for evaluating the effectiveness of policies (_e.g._, conditional, stochastic) by combining data from multiple experimental studies. Asymptotic error analysis of our estimators provides fast convergence guarantee. We empirically verified the robustness of estimators through simulations.

## 1 Introduction

In the empirical sciences, conclusions on the effect of actions or policies is often supported by evidence drawn from prior observations and experiments. The conditions under which such inferences can be formally justified can be traced back (in part) to Campbell, Stanley and Cook . They argued for a basic dichotomy in the kinds of questions that scientists seek to answer from experimental data. On the one hand asking whether "_in fact, the experimental stimulus made some significant difference in this specific instance?_", and on the other hand asking "_to what populations, settings, and treatments can this effect be generalized?_" [10, p. 297]. These inferences have since been labelled as _internal validity_ and _external validity_, respectively.

External validity is concerned with the extent to which findings from one population can be "reprocessed", or "re-calibrated" so as to circumvent population differences and produce valid generalizations in a target population where experiments cannot be performed (e.g., outside the laboratory, different domains, etc.). The validity of these inferences will necessarily be contingent on a careful analysis to ascertain the commonalities and differences between domains as, for example, if the target domain is completely arbitrary generalization is impossible. In the causal transportability literature, the basis for generalization (also called transportability) is justified by the stability and invariance of the causal mechanisms shared across populations and domains . Several graphical characterizations exist to delineate the conditions under which transportability is possible, with recent algorithms proposing solutions for general instances of the external validity task combining observational and experimental distributions under partial observability .

These algorithmic solutions express a target policy effect in terms of the observational and experimental source distributions. Still, then one needs to go further and estimate the resulting expression from finite samples. In practice, with a finite number of samples and potentially high-dimensional covariates, estimating causal expressions is quite challenging. Effective estimators have been developed for specific settings, starting with doubly-robust estimators for functionals given by the backdoor criterion [13; 37; 9; 45], and recently extended to cover general identification scenarios with observational and experimental samples [25; 26; 8]. These techniques also find parallels across other related disciplines, such as reinforcement learning where re-weighting [42; 31], outcome modelling , and doubly-robust estimation , are common for evaluating the effect of policies to overcome shifts in the behaviour policy. Recently,  and  have considered policy evaluation under covariate shift and selection bias, a special case of the external validity problem with a given graph. Despite their generality, existing estimators still only cover a limited portion of realistic scientific inferences. In particular, existing methods are not applicable in settings where datasets are collected in different domains.

We consider the generalization of causal claims from observational and experimental data through the task of _policy evaluation_. The target for inference is \(_{P^{0}_{}}[Y]\) where \(P^{0}_{}\) symbolizes the distribution of data in a target domain (indexed as \(0\)) in which a hypothetical policy of interest \(\) (also known as dynamic treatment regimes  or soft interventions ) has been implemented. The question then becomes how to identify and estimate \(_{P^{0}_{}}[Y]\), given finite samples from multiple observational and experimental data (e.g., \(P^{i}_{_{i}}\), a source domain indexed by \(i\) in which experimental policy is \(_{i}\) that may differ with \(_{0}\)) collected under different settings and structural assumptions, encoded in causal diagrams. We aim to bridge the gap between identification and estimation to solve general instances of external validity. Our contributions are twofold:

1. **Sec. 3:** We develop nonparametric identification criteria (Thm. 1) to determine whether the effect of a policy may be expressed through an adjustment formula from two separate distributions induced by policy interventions, collected from different populations. Based on this formulation, we develop a multiply robust estimator (Thm. 3) that enjoys multiply robustness against model misspecification and bias.
2. **Sec. 4:** We generalize these identification criteria (Thm. 4) and propose a general multiply-robust estimator (Thm. 6) applicable for the evaluation of policies from multiple source datasets.

### Preliminaries

We use bold letters (\(\)) to denote a random vector and \(X\) a random value. Each random vector is represented with a capital letter (\(\)) and its realized value with a small letter (\(\)). Given a set \(=\{X_{1},,X_{n}\}\), we denote \(^{(i)}\{X_{1},,X_{i}\}\). For a discrete vector \(\), we use \(_{}()\) to represent the indicator function such that \(_{}()=1\) if \(=\); \(_{}()=0\) otherwise. For comprehensibility, we use \(P()\) to denote a probability at \(\) at \(\) for discrete/continuous random variables \(\). In similar, we use \(_{}\) for \(\) for the summation/integration over a mixture of discrete/continuous random variables \(\) For example, we write the back-door adjustment as \(_{}_{P}[Y x,]P()\) even when \(\) is a mixture of discrete/continuous variables. We use \(_{P}[()]_{}f() P()\) for a function \(f\). For a sample set \(\{_{(i)}:i=1,,n\}\) where \(_{(i)}\) denotes the \(i\)th samples, we use \(_{}[f()](1/n)_{i=1}^{n}f(_{(i)})\). We use \(\|f\|_{P}:=_{P}[\{f()\}^{2}]}\). If a function \(\) is a consistent estimator of \(f\) having a rate \(r_{n}\), we use \(-f=o_{P}(r_{n})\). We say \(\) is \(L_{2}\)-consistent if \(\|-f\|_{P}=o_{P}(1)\). We use \(-f=O_{P}(1)\) if \(-f\) is bounded in probability, and \(-f=O_{P}(r_{n})\) when \(-f\) is bounded in probability at rate \(r_{n}\).

We use Structural Causal Models (SCMs) as our framework . An SCM \(\) is a quadruple \(=,,P(),\). \(\) is a set of latent variables following a joint distribution \(P()\). \(\) is a set of observable variables whose values are determined by functions \(=\{f_{V_{i}}:V_{i}\}\) such that \(V_{i} f_{V_{i}}(_{V_{i}},_{V_{i}})\) where \(_{i} V\) and \(_{V_{i}}\). Each SCM \(\) induces a distribution \(P()\) and a causal graph \(\) in which directed edges from every variable in \(_{i}\) to \(V_{i}\) exist. Dashed-bidirected arrows encode correlated latent variables.

Policy Evaluation Integrating Multiple Experimental Datasets

We investigate the sequential decision-making setting concerning a set of actions \(\), a series of dynamic covariates \(\), a series of static covariates \(\) and an outcome variable of interest \(Y\) in an SCM \(\). A policy vector \(\{^{i}\}\) over actions \(=\{X_{1},,X_{m}\}\) is an ordered set of decision rules for each \(X_{i}\). Actions are selected according to a topological ordering \(X_{1}<<X_{K}\) over time. Each action \(X_{i}\) is potentially associated with a set of prior static and dynamic covariates, for example, the decision rule for \(X_{k}\) could be defined as \(x_{k}(^{(k)},^{(k-1)},^{(k)})\). Every \((X_{k}^{(k)},^{(k-1)},^{(k)})\) is a probability distribution mapping from domains of the set of inputs \(\{^{(k)},^{(k-1)},^{(k)}\}\) to the domain of actions \(X_{k}\). The implementation of a policy \(\) in \(\) induces an intervened model \(_{}\), that sets values of every \(X\) to be decided by the policy \(\), replacing the functions \(\{f_{X},X\}\) that would normally set its value. We denote a distribution induced by \(_{}\) as \(P_{}\). Now, we fix the notion of the _policy evaluation_ as follows:

**Definition 1** (Policy evaluation ).: _The policy evaluation is to predict the effectiveness of a policy vector \(\) on an outcome \(Y\) in an target SCM \(^{0}\); i.e., \(_{0}:=_{P_{}^{0}}[Y]\)._

Difficulties in estimating \(_{P_{}^{0}}[Y]\) comes from that the distribution or samples from \(P_{}^{0}\) are generally not available. These discrepancies can be formalized under the rubric of SCMs as follows. In the most general setting, an investigator might leverage multiple source domains \(\{^{1},^{2},,^{K}\}\) over \(\) that entail distributions \(:\{P^{1},P^{2},,P^{K}\}\). Data or samples from these distributions may be available under different behaviour policies, _e.g._, \(_{1},_{2},,_{K}\), depending on the study or data collection protocol implemented in each domain (that might include an observational regime, _i.e._ no policy implemented). To ground the policy evaluation problem, we define graphical tools to capture commonalities and discrepancies across domains.

**Definition 2** (Domain discrepancy ).: _For every pair of SCMs \(^{i},^{j}\) (\(i,j\{0,1,2,,K\}\)) defined over \(\), the domain discrepancy set \(_{ij}\) is defined such that for every \(V_{ij}\) there might exist a discrepancy between \(f_{V}^{M^{i}} f_{V}^{M^{j}}\), or \(P^{M^{i}}(_{V}) P^{M^{j}}(_{V})\)._

**Definition 3** (Selection diagram ).: _The selection diagram \(^{}=\{^{j}\}_{j\{0,1,2,,T\}}\{ ^{_{ij}}\}_{j\{1,2,,T\}}\) is a graph constructed from \(^{i}\) (\(i\{0,1,2,,T\}\)) by adding the selection node \(S_{ij}\) to the vertex set, and adding the edge \(S_{ij} V\) for every \(V_{ij}\)._

\(_{i,j}\) locates the mechanisms where structural discrepancies between two domains are suspected to take place. \(V_{i,j}\) represents the assumption that the mechanisms for \(V\) are invariant across the two domains. The induced selection diagram is a parsimonious representation of these constraints. The following example illustrates these notions.

**Example 1** (External validity under covariate shift).: A common instance of the external validity problem in the literature considers the evaluation the effect of a policy \(:_{C}_{X}\) for assigning a treatment \(X\{0,1\}\), subject to shift in the distribution of covariates \(C\). For this example, let source and target domains \(:\{^{1},^{0}\}\) over \(=\{C,X,Y\},=\{U_{XY},U_{C}\}\) be defined as follows,

\[^{1}:&=C f_{C}(U_{C}) \\ X f_{X}(C,U_{XY})\\ Y f_{Y}(X,C,U_{XY})\\ P()&=P(U_{XY})P(U_{C})^{0}: ^{0}&=C f_{C}^{0}(U_{C})\\ X f_{X}(C,U_{XY})\\ Y f_{Y}(X,C,U_{XY})\\ P^{0}()&=P(U_{XY})P^{0}(U_{C})\]

Here, \(C_{1,0},\{Y,C\}_{1,0}\) as only the mechanism for \(C\) varies across domains. Consider the evaluation of \(:(X=1 c):=1/(1+\{-c\})\) given an experimental dataset in \(^{1}\) in which \(X\) has been randomized, _i.e._, \(X(0.5)\), and covariate data \(P^{0}(C)\) available in \(M^{0}\). Notice that we do not have access to the specification of the SCMs \(\), but only the induced diagrams \(^{}\), and a subset of entailed distributions \(:\{P^{1}_{(X)}(X,Y,C),P^{0}(C)\}\). The policy effect is expressible as

\[_{P_{}^{0}}[Y]=_{x,c,y}yP^{1}_{(x)}(y c,x)(x  c)P^{0}(c),\]

and estimated given the policy \(\) and the combination of the available data from \(P^{1},P^{0}\).

## 3 Combining experiments from two domains

Example 1 illustrates two challenges in combining data from different domains to infer the effect of a new policy in a target domain. In a first instance highlighting the challenge of _identification_, that is inferring an expression in terms of \(\) that identifies the policy effect, and in a second instance highlighting the challenge of _estimation_, that is providing efficient estimators from finite samples for the identified policy effect. The following example will serve to motivate this setting.

**Example 2** (Two-stage treatment strategies).: A team of physicians is contemplating a treatment plan \(_{0}\) against heart disease \(Y\) for their patients in \(^{0}\). They consider administrating two drugs in sequence: a drug against hypertension \(X_{1}\), followed by an anti-diabetic drug \(X_{2}\) depending on the effect of \(X_{1}\) on blood pressure \(W\). To support their evaluation, two studies exist on these drugs, from domains \(^{1},^{2}\), that, however, have only analyzed their effect in isolation (on \(X_{1}\) and \(X_{2}\) separately) and under different treatment guidelines, \(_{1},_{2}\) respectively. The data collected refers to the variables \((Y,_{1},_{2},X_{1},X_{2},W)\) in which \((_{1},_{2})\) are demographic variables. Formally, we assume physicians have access to \(:\{P_{_{1}}^{1}(),P_{_{2}}^{2}(),P^{0}( _{1},_{2})\}\). The superscripts in \(P^{0},P^{1},P^{2}\) are the index for the domain, and the subscripts \(_{0},_{1},_{2}\) denote the policies for assigning treatments. \(^{}\) in Fig. 1 encodes the structural assumptions, which include discrepancies across domains and implemented policies in the available data. For example, the graph \(_{_{1}}^{1}\) specifies the known guideline \(_{1}\) used in \(^{1}\), while no specific plan was followed for the assignment of \(X_{2}\), that in practice depends on the patient's covariates \(C_{2}\) as well as unobserved factors, e.g. mood, health awareness, etc. (summarized in the bi-directed arc). In addition, selection diagrams describe differences between domains. For example, the edge \(\{S_{C_{1}} C_{1}\}\) in \(_{_{0}}^{_{0,1}}\) indicates a potential change in the distribution of covariates \(C_{1}\) across domains \(M^{0},M^{1}\). The question then becomes how to estimate \(_{P_{_{0}}^{0}}[Y]\) given \((^{},)\). 

### Identification

Example 2 illustrates the complexity of drawing inferences from multiple datasets collected under different settings. We extend this example to provide a general identification procedure for the effect of policies when two source datasets subject to different policies and/or discrepancies with the target domain are available. Let \((Y,,X_{1},,X_{2},,Y,)\) denote a set of disjoint variables, where \(Y\) is an outcome variable, \(,(,)\) are covariates corresponding to two experiments, \((X_{1},X_{2})\) are treatment variables, and \(\) denotes the selection nodes describing discrepancies across pairs of domains. Formally, the task signature is given as follows:

* **Input**: Samples from \(=\{P_{_{1}}^{1}()\), \(P_{_{2}}^{2}()\), \(P^{0}(_{1},_{2})\}\); structural assumptions \(^{}:=\{_{_{0}}^{0},_{_{1}}^{1}, _{_{2}}^{2},_{_{0}}^{_{0,1}},_{ _{0}}^{_{0,2}}\}\).
* **Query**: Estimate \(_{P_{_{0}}^{0}}[Y]\) where \(P^{0}\) is distribution on the target domain and \(_{0}\) is a target policy assigning treatments with \(_{0}(X_{1}_{1})\) and \(_{0}(X_{2}_{2},W)\).

Given these inputs, a sufficient condition for identifying the query is given as follows:

**Definition 4** (**Adjustment criterion for combining two experiments)**.: _Given \(^{}\), the adjustment criterion for combining two experimental datasets is defined by the following d-separation statements:_

1. _Domain transfer for_ \(Y\)_:_ \((Y\!\!\!\!\!\!,X_{1},X_{2},W)\) _in_ \(_{_{0}}^{_{0,2}}\)_; i.e., the distribution over_ \(Y\) _is invariant between the source distribution from_ \(^{2}\) _and the target._

[MISSING_PAGE_EMPTY:5]

3. **Evaluation**_: The DML estimator \(\) for \(_{P_{_{0}}^{0}}[Y]\) is then given as_ \[:=_{=1}^{L}_{_{}^{2}}[ _{}^{2}\{Y-_{}^{2}\}]+_{_{ }^{1}}[_{}^{1}\{_{}^{2}-_{}^{1} \}]+_{_{}^{0}}[}_{}^{1}].\] (3)

Estimating the ratio nuisance \(\{^{1},^{2}\}\) can be challenging due to the necessity of estimating density ratios like \(}^{1}()}{P_{_{2}}^{2}()}\) or \(}^{1}(W|,X_{1})}{P_{_{2}}^{2}(W|,X_{1})}\). We employ the classification-based method for estimating the density [17, Sec. 5.4]. To illustrate this method, consider estimating \(}^{1}()}{P_{_{2}}^{2}()}\). We assign \(=1\) if samples of \(\) are from \(P_{_{1}}^{1}\) and \(=0\) if from \(P_{_{2}}^{2}\). Then, it's provable that \(}^{1}()}{P_{_{2}}^{2}()}=)}{P(=0|)}\), which can be estimated using off-the-shelf probabilistic classification estimators.

The error of the DML estimator is presented below:

**Theorem 2** (**Learning Guarantees**).: _Suppose \(_{}^{2},_{}^{1}<\) and \(0<_{}^{2},_{}^{1}<\). Define \(^{2}(;^{2},^{2}):=^{2}(,W,)\{Y- ^{2}(,W,)\}\), \(^{1}((,W,X_{1});^{2},^{1},^{1}):=^{1}( ,X_{1})\{^{2}(,W,X_{1})-^{1}(,X_{1})\}\), and \(^{0}(;^{1}):=^{1}()-_{0}\). For \(i=0,1,2\), define \(_{0}^{i}\) as \(^{i}\) equipped with true nuisances (\(_{0}^{i},_{0}^{i}\)) and \(_{}^{i}\) as \(^{i}\) equipped with estimated nuisances \(_{}^{i},_{}^{i}\). Define \(R_{i}:=(1/L)_{=1}^{L}(_{_{}^{i}}[_ {}^{i}]-_{P^{i}}[_{}^{i}])\) for \(i=0,1,2\). Then,_

1. _The error_ \(-_{0}\) _is decomposed as follows:_ \[-_{0}=_{i=0}^{2}R_{i}+_{=1}^{L}_{i=1}^ {2}_{P_{_{}}^{i}}\{_{}^{i}-_{0}^ {i}\}\{_{0}^{i}-_{}^{i}\}.\] (4)
2. _Let_ \(_{i,0}^{2}:=_{P_{_{i}^{i}}^{1}}[_{0}^{i}]\)_. With probability (W.P) greater than_ \(1-\)_,_ \[_{i=0}^{2}R_{i} 3}(^{2} }{|^{i}|}}+^{L}_{i=0}^{2} _{}^{i}-_{0}^{i}\|_{P_{_{i}}^{2}}^{2}}{| _{}^{i}|}}).\] (5)
3. _Let_ \(_{i,0}^{3}:=_{P_{_{i}}^{i}}[[_{0}^{i}]^{3}]\)_. Let_ \((x)\) _denote the standard normal CDF. W.P greater than_ \(1-\)_,_ \[|P_{_{i}}^{i}(^{i}|}}{_{k,0}}R_{i}<x )-(x)|}}{} _{=1}^{L}_{}^{i}-_{0}^{i}\|_{P_{_{i}}^ {2}}^{2}}{|_{}^{i}|}}+^{3}}{_{i,0}^ {3}^{k}|}}.\] (6)

If the nuisance parameters \(_{}^{i}\) and \(_{}^{i}\) converge at a rate of \(n^{-1/4}\) (where \(n\) is the size of the smallest sample set), the DML estimator achieves a faster convergence rate of \(n^{-1/2}\). This rapid convergence allows its asymptotic distribution to closely approximate the standard normal distribution, as is further clarified in the asymptotic analysis:

**Theorem 3** (**Asymptotic Error**).: _Suppose each nuisance estimates \(_{}^{2},_{}^{1},_{}^{2},_{ }^{1}\) are \(L_{2}\)-consistent and bounded. Then, the error of the DML estimator \(\) in Def. 5 is given as follows:_

\[-_{0}=_{i=0}^{2}R_{i}+_{=1}^{L}O_{P_{_{2}}^{2}}(\| _{}^{2}-_{0}^{2}\|_{}^{2}-_{0}^{2}\|)+ _{=1}^{L}O_{P_{_{1}}^{1}}(\|_{}^{1}-_{0}^{1}\|_{}^{1}-_{0}^{1}\|),\] (7)

_where \(R_{i}\) converges in distribution to normal\((0,_{i,0}^{2})\)._

Eq. (7) implies that the error term \(-_{0}\) converges to zero faster than the convergence rate of nuisances, which is a property known as _debiasedness_.

## 4 Combining multiple experiments

In this section, we extend our method to incorporate the combination of data from multiple experiments, specifically focusing on \(m\) different experiments derived from varied policies (\(_{i}\)) in distinct source domains (\(^{i}\)). A practical scenario for this task is the following:

**Example 3** (Multi-stage treatment strategies).: Consider a scenario involving hospitals in three different cities: New York (domain 1 with \(P^{1},^{1}\)), Los Angeles (domain 2 with \(P^{2},^{2}\)), and San Francisco (domain 3 with \(P^{3},^{3}\)). Each hospital has different guidelines, i.e., policies, for diabetes treatment. In New York, the hospital focuses on insulin therapy adjustment based on the patient lifestyle choices, primarily for Type 1 Diabetes patients (\(_{1}\)). In Los Angeles, the hospital focuses on team diet and exercise regimen adjustments, primarily for Type 2 Diabetes patients (\(_{2}\)). In contrast, San Francisco's approach involves advanced monitoring and AI-driven predictive adjustments for higher-risk diabetes patients. Now, as the leader of a new clinical team in Chicago (the target domain with \(P^{0},^{0}\)), the task is to evaluate a novel candidate treatment policy \(_{0}\), which integrates the strategies from these three domains to provide comprehensive care for both Type 1 and Type 2 Diabetes patients. The structure of the problem is captured in causal diagrams in Fig. 2, illustrating the data-generating process, the experiments in each city, and the assumed discrepancies between these source domains and Chicago. 

### Identification

We consider a sequence of variables \((,X_{1},W_{1},,X_{m},W_{m}:=Y)\) where \((,^{(i-1)})\) represent the covariates corresponding to each of the \(i\)'th experiments, and \((X_{1},,X_{m})\) are the corresponding treatment variables. We are given samples drawn from \(P^{i}_{_{i}}()\) for \(i=1,,m\) and \(P^{0}()\). We will leverage causal diagrams \(_{_{i}}\) and selection diagrams \(^{_{0,i}}\) for every \(i=1,,m\). Formally, the task signature is given as follows:

* **Input**: Samples from \(P^{i}_{_{i}}()\) for \(i=1,,m\) and \(P^{0}(_{1},_{2})\); Causal diagrams \(^{i}_{_{i}}\) and selection diagrams \(^{_{0,i}}_{_{0}}\) for \(i=1,,m\).
* **Query**: Estimate the effect of the target policy \(_{0}\) on the target domain \(^{0}\); i.e., \(_{P^{0}_{_{0}}}[Y]\).

**Definition 6** (**Adjustment criterion for combining multiple experiments)**.: _The adjustment criterion for combining multiple policies are the following d-separation criterion in the the DTRs \(_{_{0}},_{_{1}},,_{_{m}}\) and the selection diagram \(^{_{0,1}}_{_{0}},,^{_{0,m}}_{_{ 0}}\)._

1. _Domain transfer for_ \(Y\)_:_ \((Y\!\!\!,,)\) _in_ \(^{_{0,m}}_{_{0}}\)_; i.e., the distribution over_ \(Y\) _is invariant between the source distribution from_ \(^{m}\) _and the target._
2. _Domain transfer for_ \(W_{i}\) _for_ \(i=1,,m-1\)_:_ \((W_{i}\!\!\!^{(i)},^{(i-1)})\) _in_ \(^{_{0,i}}_{_{0}}\)_; i.e., the distribution over_ \(W_{i}\) _is invariant between the source distribution from_ \(^{i}\) _and the target._3. _Adjustment for \(Y\):_ \((Y\!\!\!_{i},{ W},{ X})\) _in_ \(_{_{i}}\) _for_ \(i\{0,m\}\)_; i.e., the distribution over_ \(Y\) _is invariant between regimes_ \(_{0}\) _and_ \(_{m}\)_._
4. _Adjustment for \(W_{i}\)__\(i=1,,m-1\)_:_ \((W_{i}\!\!\!_{j}^{(i)},{ X}^{(i-1)})\) _in_ \(_{_{j}}\) _for_ \(j\{0,i\}\)_; i.e., the distribution over_ \(W_{i}\) _is invariant between regimes_ \(_{0}\) _and_ \(_{i}\)_._

These conditions lead to the following identification criterion.

**Theorem 4** (**Adjustment for combining multiple experiments)**.: _Under the adjustment criterion in Def. 6, the target query \(_{0}_{P^{0}_{_{0}}}[Y]\) is identifiable from the samples from \(P^{1}_{_{1}}({ V}),,P^{m}_{_{m}}({ V})\) and \(P^{0}({ C})\). Specifically, it's expressed as follows:_

\[_{P^{0}_{_{0}}}[Y]=_{{ w},{ c},{ x}} _{P^{m}_{m}}[Y,{ w},{ x}]_{i=1}^{m-1}P^{i}_{ _{i}}(w_{i},{ x}^{(i-1)},{ w}^{(i-1)})_{j=1}^{m-1} _{0}(x_{j},{ w}^{(j-1)})P^{0}({ c}),\] (8)

### Estimation

The regression nuisance parameters are defined as follows. We first define the following nuisance.

\[_{0}^{m}({ C},{ W},{ X}) _{P^{m}_{_{m}}}[Y,{ W},{ X}]\] (9) \[_{0}^{m}({ C},{ W},{ X}^{(m-1)}) _{x_{m}}_{0}^{m}(x_{m},{ W}^{(m-1)} )_{0}^{m}({ C},{ W},{ X}^{(m-1)},x_{m})\] (10)

For \(i=m-1,,1\), the other nuisances are defined in a following manner:

\[_{0}^{i}({ C},{ W}^{(i-1)},{ X}^{(i)}) _{P^{i}_{_{i}}}[_{0}^{i+1}({ C },{ W}^{(i)},{ X}^{(i)}),{ W}^{(i-1)},{ X}^{(i)}],\] (11) \[_{0}^{i}({ C},{ W}^{(i-1)},{ X}^{(i-1)}) _{x_{i}}_{0}^{i}({ C},{ W}^{(i-1)},{ X}^ {(i-1)},x_{i})_{0}^{i}(x_{i},{ C},{ W}^{(i-1)}).\] (12)

We note that Eq. (8) can be parameterized as \(_{P^{0}_{_{0}}}[Y]=_{P^{0}}[_{0}^{1}({ C })]\). On the other hand, the ratio nuisance parameters \(_{0}^{i}\) for \(i=1,,m\) are defined as functionals satisfying the followings:

\[_{P^{0}_{_{0}}}[Y]=_{P^{i}_{_{i}}}[_{0}^{i}({ C },{ W}^{(i-1)},{ X}^{(i)})_{0}^{i}({ C},{ W}^{(i-1)},{ X} ^{(i)})],\] (13)

where the closed form is given as

\[_{0}^{i}=(X_{i},{ W}^{(i-1)}) _{j=1}^{i-1}P^{j}_{_{j}}(W_{j},{ X}^{(j-1)},{ W}^{(j- 1)})_{0}(X_{j},{ W}^{(j-1)})P^{0}({ C})}{_{0}^{0}({ C },{ W}^{(i-1)},{ X}^{(i)})}\] (14)

Eq. (8) can be parameterized as \(_{P^{m}_{_{m}}}[^{(m)}({ C},{ W}^{(m-1)},{ X}^{(m )})Y]\). Equipped with these nuisances, we define a corresponding estimator as follows.

**Definition 7** (**Dml for combining multiple experiments)**.: _Let \(^{i} P^{i}_{_{i}}({ V})\) for \(i=1,,m\) and \(^{0} P^{0}({ C})\). Let \(L 2\) denote a fixed number._

1. _Sample split: For_ \(=1,,L\)_, randomly split_ \(^{i}\) _for_ \(i\{0,1,,m\}\) _into_ \(L\)_-fold. The_ \(\)_'th partition of the sample is denoted_ \(^{i}_{}\)_. The complement is_ \(^{i}_{-}^{i}^{i}_{}\)_._
2. _Nuisance estimation__: For each_ \(=1,,L\)_, learn the estimator model_ \(_{}^{m},,_{}^{1}\) _for_ \(_{0}^{m},,_{0}^{1}\) _using samples_ \(^{m}_{-},^{1}_{-}\)_, respectively. Also, learn the estimation model for_ \(_{}^{1},,_{}^{m}\) _for_ \(_{0}^{1},,_{0}^{m}\) _using samples_ \(^{i}_{-}\) _for_ \(i=0,1,,m\)_, respectively._
3. _Evaluation__: The DML estimator_ \(\) _for_ \(_{P^{0}_{_{0}}}[Y]\) _is then given as_ \[_{=1}^{L}_{i=1}^{m}_{ ^{i}_{}}[_{}^{i}\{_{}^{i+1}-_{}^{i}\}]+_{^{0}_{}}[}_{}^{1}].\] (15)

The error of the DML estimator is presented below:

**Theorem 5** (Learning Guarantees).: _Suppose \(_{0}^{i},_{}^{i}<\) and \(0<_{0}^{i},_{}^{i}<\) almost surely for \(i=1,,m.\) Define \(^{i}((,^{(i)},^{(i)});^{i},^{i+ 1},^{i}):=^{i}\{^{i+1}-^{i}\}\) for \(i=1,,m,\) where \(^{m+1}:=Y\). Let \(^{0}(;^{1}):=^{1}-_{0}\). For \(i=0,,m\), define \(_{0}^{i}\) as \(^{i}\) equipped with true nuisances, and \(_{}^{i}\) as \(^{i}\) equipped with estimated nuisances. Define \(R_{i}:=(1/L)_{=1}^{L}(_{_{}^{i}}[_ {}^{i}]-_{P^{i}}[_{}^{i}])\) for \(i=0,1,,m.\) Then,_

1. _The error_ \(-_{0}\) _is decomposed as follows:_ \[-_{0}=_{i=0}^{m}R_{i}+_{=1}^{L}_{i=1} ^{m}_{_{_{i}}^{i}}\{_{}^{i}-_{0 }^{i}\}\{_{0}^{i}-_{}^{i}\}.\] (16)
2. _Let_ \(_{i,0}^{2}:=_{_{_{i}}^{i}}[_{0}^{i}]\)_. With probability (W.P) greater than_ \(1-\)_,_ \[_{i=0}^{m}R_{i}(m+1)}(^{ m}^{2}}{|^{i}|}}+^{L}_{i=0}^{m} _{}^{i}-_{0}^{i}\|_{_{_{i}}^{i} }^{2}}{|_{}^{i}|}}).\] (17)
3. _Let_ \(_{i,0}^{3}:=_{_{_{i}}^{i}}[|_{0}^{i}|^{3}]\)_. Let_ \((x)\) _denote the standard normal CDF. W.P greater than_ \(1-\)_,_ \[|P_{_{i}}^{i}(^{i}|}}{_{k,0}}R_{i}<x )-(x)|}_{ =1}^{L}_{}^{i}-_{0}^{i}\|_{_{_{i}}^ {i}}^{2}}{|_{}^{i}|}}+^{3}}{_{i,0}^{ 3}^{k}|}}.\] (18)

A corresponding asymptotic error analysis is following:

**Theorem 6** (**Asymptotic Error)**.: _Suppose each nuisance estimates \(_{}^{1},,_{}^{m}\) and \(_{}^{1},,_{}^{m}\) are \(L_{2}\)-consistent and bounded. Then, the error of the DML estimator \(\) in Def. 7 is given as follows:_

\[-_{0}=_{i=0}^{m}R_{i}+_{=1}^{L}_{i=1}^{m}O_{P_{ _{i}}^{i}}(\|_{}^{i}-_{0}^{i}\|\|_{}^{i}- _{0}^{i}\|),\] (19)

_where \(R_{i}\) converges in distribution to \((0,_{i,0}^{2})\)._

Similarly to Thm. 3, this result implies that the DML estimator \(\) converges fast even when the nuisance estimates converge relatively slowly.

## 5 Experiments

In this section, we demonstrate the proposed estimators in Defs. (5,7) for combining multiple experimental datasets from different domains. We first compared the estimators on synthetic data to provide evidence of the fast convergence and doubly robustness behaviours of the proposed estimators. We conclude with an analysis of the ACTG 175 clinical trial  and Project STAR. We will use \(T^{}()\) for \(\{,,\}\) to denote the estimators \(\{,,\}\) for the policy effect \(_{_{_{0}}^{0}}\)\(Y\). OM and PW estimators are purely based on the regression-based nuisances \(\) and \(\), respectively. To assess the quality of each estimator, we consider the _absolute error_ (AE) as \(^{}=|T^{}()-_{ _{_{0}}^{0}}Y|\). We used XGBoost  to estimate nuisances.

Synthetic SimulationsWe ran 100 simulations for each \(N=\{2500,5000,10000,20000\}\) where \(N\) is the sample size. We measure the \(^{}\) in the presence of the 'converging noise \(\)' in estimating the nuisance, decaying at a \(N^{-1/4}\) rate (i.e., \((N^{-1/4},N^{-1/4})\), where \(N\) is the size of samples). To enforce the convergence rate of nuisance estimates no faster than the decaying rate \(n^{-1/4}\), we add \(\) to all nuisance estimates. This scenario is inspired by the experimental design discussed in . The AE plots for combining two/multiple experiments are presented in Figs. (3a, 3b). For all examples, the proposed DML estimator outperforms the other two estimators by achieving fast convergence. This result corroborates the robustness property in Thm. (3, 6), which implies that the proposed estimator converges faster than the other counterparts.

External validity: ACTG 175To provide empirical evidence, we analyze the ACTG 175 randomized trial , which assessed therapies for reducing CD4 T cell counts in HIV patients. Participants were randomly assigned to treatments \(X_{2}\{0,1\}\), with prior anti-retroviral drug use \(X_{1}\{0,1\}\) recorded. Patient demographics \(_{1},_{2}\)--including gender, age, weight, and Karnofsky score--were collected, and CD4 T cell counts (\(W\)) were measured. To simulate an alternative study with a modified guideline for \(X_{1}\), we sub-sampled ACTG 175, adjusting covariate distributions and assignments of \(\{X_{1},X_{2}\}\). Specifically, we evaluate a stochastic policy \(_{0}=\{_{0}(x_{1}_{1}),_{0}(x_{1}_{2})\}\) for combining \(X_{1}\) and \(X_{2}\) based on \(_{1},_{2}\), with distribution \(P^{0}\) representing a location with differing covariate distributions and treatment assignments. Further details are provided in Appendix D.2.

We evaluated the AEest of all proposed estimators with and without noise (as described in the synthetic simulations). The AE plots are shown in Figs. ((c)c, (d)d). Results indicate that both the regression and DML estimators converge to the true policy effect faster under noisy conditions, whereas the PW estimator converges more slowly. However, DML does not consistently outperform at all sample sizes (see Fig. (c)c), as its error is influenced by the combined errors in the OM and PW estimators. Consequently, high error in the PW estimator may lead to increased error in the DML estimator.

External validity: Project STARWe further examine policies on teacher-student ratios (i.e., class sizes) to improve academic achievement, using a semi-synthetic adaptation of the Project STAR dataset . This longitudinal study evaluated the impact of teacher-student ratios on academic outcomes for students in kindergarten through third grade, with students randomized each year to one of three class size interventions. Here, we assess a 3-stage policy setting student-teacher ratios across Grades 0, 1, and 2, observing academic scores as intermediate outcomes, with baseline covariates (e.g., ethnicity, gender) and final academic scores at the end of Grade 3 as the primary outcome. To emulate data collected across different domains, we subsample using various probabilities to shift baseline covariate distributions, as done in ACTG 175 (see Appendix D.3 for details). We evaluated the PW, OM, and DML estimators across dataset sizes, plotting their absolute errors against the true effect of the candidate policy. Results, shown in Fig. 4, mirror earlier experiments, with all estimators improving as sample size increases and DML showing faster convergence.

## 6 Conclusion

This paper has considered the evaluation of the effectiveness of policies in settings where the available data is sampled from distributions that differ from the population in the target domain. We have illustrated this task with the problem of extrapolating the results of a clinical trial in both working examples and real-world scenarios to evaluate variations of the treatment in different populations. Our contributions are (1) introducing several identification criteria for the effectiveness of policies given experimental datasets from two or more domains and (2) developing doubly robust estimators for these settings that achieve fast convergence.

Figure 4: STAR Results.

Figure 3: Comparison of the proposed DML estimator with other counterparts (outcome-based model called ‘OM’, and the probability-weighting-based model labelled ‘PW’) for **(a,b)** synthetic data analysis for combining two and multiple experiments; and **(c,d)** real-world data analysis under the noise-free or noisy environments in learning nuisances.