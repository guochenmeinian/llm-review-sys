# Metropolis Sampling for Constrained Diffusion Models

Nic Fishman

University of Oxford

&Leo Klarner

University of Oxford

&Emile Mathieu

University of Cambridge

&Michael Hutchinson

University of Oxford

&Valentin De Bortoli

ENS Ulm

{njwfish,leojklarner}@gmail.com

###### Abstract

Denoising diffusion models have recently emerged as the predominant paradigm for generative modelling on image domains. In addition, their extension to Riemannian manifolds has facilitated a range of applications across the natural sciences. While many of these problems stand to benefit from the ability to specify arbitrary, domain-informed constraints, this setting is not covered by the existing (Riemannian) diffusion model methodology. Recent work has attempted to address this issue by constructing novel noising processes based on the reflected Brownian motion and logarithmic barrier methods. However, the associated samplers are either computationally burdensome or only apply to convex subsets of Euclidean space. In this paper, we introduce an alternative, simple noising scheme based on Metropolis sampling that affords substantial gains in computational efficiency and empirical performance compared to the earlier samplers. Of independent interest, we prove that this new process corresponds to a valid discretisation of the reflected Brownian motion. We demonstrate the scalability and flexibility of our approach on a range of problem settings with convex and non-convex constraints, including applications from geospatial modelling, robotics and protein design.

## 1 Introduction

In recent years, denoising diffusion models (Sohl-Dickstein et al., 2015; Song et al., 2019; Song et al., 2021; Ho et al., 2020) have emerged as a powerful paradigm for generative modelling, achieving state-of-the-art performance across a range of domains. They work by progressively adding noise to data following a Stochastic Differential Equation (SDE)--the forward _noising_ process--until it is close to the invariant distribution of the SDE. The generative model is then given by an approximation of the associated time-reversed _denoising_ process, which is also an SDE whose drift depends on the gradient of the logarithmic densities of the forward process, referred to as the _Stein score_. Building on the success of diffusion models for image generation tasks, De Bortoli et al. (2022) and Huang et al. (2022) have recently extended this framework to a wide range of Riemannian manifolds, enabling the specification of inherent structural properties of the modelled domain. This has broadened the applicability of diffusion models to problems in the natural and engineering sciences, including the conformational modelling of small molecules (Jing et al., 2022; Corso et al., 2022), proteins (Trippe et al., 2022; Watson et al., 2022; Yim et al., 2023) and robotic platforms (Urain et al., 2022).

However, in many data-scarce or safety-critical settings, researchers may want to restrict the modelled domain even further by specifying problem-informed constraints to make maximal use of limited experimental data or prevent unwanted behaviour (Morris, 2002; Han et al., 2006; Thiele et al., 2013; Lukens et al., 2020). As illustrated in Figure 1, such domain-informed constraints can be naturally represented as a _Riemannian manifold with boundary_. Training diffusion models on such constrained manifolds is thus an important problem that requires principled noising processes--and corresponding discretisations--that stay within the constrained set.

Recent work by Fishman et al. (2023) has attempted to derive such processes and extend the applicability of diffusion models to inequality-constrained manifolds by investigating the generative modelling applications of classic sampling schemes based on log-barrier methods (Kannan et al., 2009; Lee et al., 2017; Noble et al., 2022; Kook et al., 2022; Gatmiry et al., 2022; Lee et al., 2018) and the reflected Brownian motion (Williams, 1987; Petit, 1997; Shkolnikov et al., 2013). While empirically promising, the proposed algorithms can be computationally and numerically burdensome, and require bespoke implementations for different manifolds and constraints. Concurrently, Lou et al. (2023) have investigated the use of reflected diffusion models for image applications. They focus on the high-dimensional hypercube, as this setting admits a theoretically grounded treatment of the _static thresholding_ method which is widely used in image models such as Saharia et al. (2022). More recently, Liu et al. (2023) have investigated the use of log-barrier-based mirror maps to transform a constrained domain into an unconstrained dual space for applications in image watermarking. While both methods exhibit robust scaling properties and impressive results, they only consider convex subsets of Euclidean space and do not extend to more general manifolds.

Here, we propose a new method for generative modelling on constrained manifolds based on a Metropolis-based discretisation of the reflected Brownian motion. The Metropolised process' chief advantage is that it is lightweight: the only additional requirement over those outlined in De Bortoli et al. (2022) that is needed to implement a constrained diffusion model is an efficient binary function that indicates whether any given point is within the constrained set. This Metropolised approximation of the reflected Brownian motion is substantially easier to implement, faster to compute and more numerically stable than the previously considered sampling schemes. Our core theoretical contribution is to show that this new discretisation converges to the reflected SDE by using the invariance principle for SDEs with boundary (Stroock et al., 1971). To the best of our knowledge, this is the first time that such a process has been investigated. We demonstrate that our method attains improved empirical results on diverse manifolds with convex and non-convex constraints by applying it to a range of problems from geospatial modelling, robotics and protein design.

## 2 Background

Riemannian manifolds.A Riemannian manifold is defined as a tuple \((,)\) with \(\) a smooth manifold and \(\) a metric defining an inner product on tangent spaces. In this work, we will use the exponential map \(_{x}:_{x}\), as well as the extension of the gradient \(\), divergence \(\) and Laplace \(\) operators to \(\). All of these quantities can be defined in local coordinates in terms of the metric. The extension of the Laplace operator to \(\) is called the Laplace-Beltrami operator, also denoted \(\) when there is no ambiguity. Using \(\), we can define a Brownian motion on \(\), denoted \((_{t})_{t 0}\) and with density w.r.t. the volume form of \(\) denoted \(p_{t}\) for any \(t>0\). We refer to Appendix B for a more detailed exposition, to Lee (2013) for a thorough treatment of Riemannian manifolds and to Hsu (2002) for details on stochastic analysis on manifolds. In the following, we consider a constrained manifold \(\) defined by

\[=\{x\,:\,\,f_{i}(x)<0,\,\,i\},\] (1)

Figure 1: When operating in data-scarce settings, it may often be beneficial to specify as much prior knowledge of the modelled domain as possible. Consider a distribution over a subset \(\) of the unit sphere \(^{2}^{3}\). While a Euclidean diffusion model can approximate the distribution in \(^{3}\) (a), directly modelling it on \(^{2}\) can make learning significantly easier (b). Restricting the problem space even further by only constructing a diffusion model on \(\) can lead to even better performance (c).

where \((,)\) is a Riemannian manifold, \(\) is an arbitrary finite indexing family and for any \(i\), \(f_{i}(,)\). Since \(\) is finite and \(f_{i}\) continuous for any \(i\), \(\) is an open set of \(\) and inherits its metric \(\). This captures simple Euclidean polytopes and complex constrained spaces like Figure 1.

Denoising diffusion models.Denoising diffusion models (Song et al., 2019; Ho et al., 2020; Song et al., 2021) work as follows: let \((_{t})_{t[0,T]}\) be a _noising process_ that corrupts the original data distribution \(p_{0}\). We assume that \((_{t})_{t 0}\) converges to \((0,^{2})\), with \(>0\). Several such processes exist, but in practice we consider the Ornstein-Uhlenbeck (OU) process, also referred to as VP-SDE, which is defined by the following Stochastic Differential Equation (SDE)

\[_{t}=-_{t}t+ _{t},_{0} p_{0}.\] (2)

Under conditions on \(p_{0}\), for any \(T>0\), \((_{t})_{t[0,T]}=(_{T-t})_{t[0,T]}\) is also the (weak) solution to a SDE (Anderson, 1982; Haussmann et al., 1986; Cattiaux et al., 2021)

\[_{t}=\{_{t}+^{2} p_ {T-t}(_{t})\}t+_{t},\ _{0} p_{T},\] (3)

where \(p_{t}\) denotes the density of \(_{t}\). In practice, \( p_{t}\) is approximated with a score network \((t,x) s_{}(t,x)\) trained by minimising either a denoising score matching (\(\)) loss or an implicit score matching (\(\)) loss (Vincent, 2011)

\[()=_{t([0,T]),(_{a},_ {t})}[_{t}(\|s_{}(t,_{t})\|^{2}+(s_{})(t,_{t}))],\] (4)

where \(_{t}>0\). For a flexible score network, the global minimiser \(^{}=*{argmin}_{}()\) satisfies \(s_{^{}}(t,)= p_{t}\). De Bortoli et al. (2022) and Huang et al. (2022) have extended denoising diffusion models to the Riemannian setting. The time-reversal formula (3) remains the same, replacing the Euclidean gradient with its Riemannian equivalent. The \(\) loss can still be computed in that setting. However, the samplers used in the Riemannian setting differ from the classical Euler-Maruyama discretisation used in the Euclidean framework. De Bortoli et al. (2022) use Geodesic Random Walks (Jorgensen, 1975), which ensure that the samples remain on the manifold at every step. In this paper, we propose a sampler with similar properties in the case of _constrained_ manifolds.

Reflected SDE.We conclude this section by recalling the framework for studying reflected SDEs, which is introduced via the notion of the _Skorokhod problem_. For simplicity, we focus on Euclidean space \(^{d}\) here, but note that reflected processes can be defined on arbitrary smooth manifolds \(\). In the case of the Brownian motion, a solution to the Skorokhod problem is a process of the form \((}_{t},_{t})_{t 0}\). Locally, \((}_{t})_{t 0}\) can be seen as a regular Brownian motion \((_{t})_{t 0}\) while \((_{t})_{t 0}\) forces \((}_{t})_{t 0}\) to remain in \(\). Under mild additional regularity conditions on \(\) and \((}_{t},_{t})_{t 0}\), see Skorokhod (1961), \((}_{t},_{t})_{t 0}\) is a solution to the _Skorokhod problem_ if for any \(t 0\)

\[}_{t}=}_{0}+_{t}-_{t} ,\] (5)

\(||_{t}=_{0}^{t}_{}_{t} }||_{s}\) and \(_{t}=_{0}^{t}(}_{s})| |_{s},\) where \((||_{t})_{t 0}\) is the total variation of \((_{t})_{t 0}\)1. Let us provide some intuition on this definition. When \((}_{t})_{t 0}\) hits the boundary \(\), \(-_{t}\) pushes the process back into \(\) along the inward normal \(-(}_{t})\), according to \(_{t}=_{0}^{t}(}_{s})| |_{s}\).

Figure 2: Visual comparison of a discretisation of the unconstrained Brownian motion (blue) and two discretisations of the reflected Brownian motion: one based on a reflection scheme (green) and the other based on our Metropolis sampler (red). The Metropolised trajectory is very close to that of the reflected one while being significantly easier to implement and cheaper to compute.

The condition \(||_{t}=_{0}^{t}_{}_{s}}||_{s}\) is more technical and can be seen as imposing that \(_{t}\) remains constant so long as \((}_{t})_{t 0}\) does not hit \(\). We refer to Fishman et al. (2023) and Lou et al. (2023) for a more thorough introduction of these concepts in the context of diffusion models.

## 3 Diffusion models for constrained manifolds via Metropolis sampling

In Section 3.1, we highlight the practical limitations of existing constrained diffusion models and propose an alternative Metropolis sampling-based approach. In Section 3.2, we outline our proof that this process corresponds to a valid discretisation of the reflected Brownian motion, justifying its use in diffusion models. An overview of the samplers we cover in this section is presented in Table 1.

### Practical limitations of existing constrained diffusion models

Barrier methods.In the barrier approach, a constrained manifold is transformed into an unconstrained space via a barrier metric. This metric is defined by \(^{2}(x)\) with \((x)=_{i T}_{i}(d(x,f_{i}))\) where \(d(x,f_{i})\) is the minimum distance from the point \(x\) to the set defined by \(f_{i}(x)=0\) and \(_{i}\) is a monotonically decreasing function such that \(_{z 0}_{i}(z)=\). Under additional regularity assumptions, \(\) is called a _barrier function_ (see Nesterov et al. (1994)). This definition ensures that the barrier function induces a well-defined exponential map on the manifold, making the Riemannian diffusion model frameworks of De Bortoli et al. (2022) and Huang et al. (2022) applicable. In the log-barrier method of Fishman et al. (2023), evaluating \(\) requires computing \(d(x,)\) (and its derivatives), which can be prohibitively expensive. Furthermore, since the exponential map under the induced manifold is difficult to compute, it is approximated by projecting the exponential map on the original manifold back onto the constraint set, incurring an additional bias. Liu et al. (2023) propose a more tractable method by constructing a mirror map that transforms a constrained domain into an unconstrained dual space, in which one can train a standard Euclidean diffusion model. However, this approach is only applicable to convex subsets of \(^{d}\) and does not extend to arbitrary Riemannian manifolds. More generally, warping the geometry of the modelled domain can adversely impact the interpolative performance of log-barrier-based diffusion models, as the space between data points expands rapidly when approaching the boundary.

Reflected stochastic processes.Fishman et al. (2023) and Lou et al. (2023) introduce diffusion models based on the _reflected Brownian motion_ (RBM). In Fishman et al. (2023), the reflected SDE is discretised by (i) considering a classical step of the Euler-Maruyama discretization (or the Geodesic Random Walk in the Riemannian setting) and (ii) reflecting this step according to the boundary defined by \(\). To compute the reflection, one must check whether the step crosses the boundary. If it does, the point of intersection needs to be calculated in order to reflect the ray and continue the step in the reflected direction. This can require an arbitrarily large number of reflections depending on the step size, the geodesic on the manifold, and the geometry of the bounded region within the manifold. We refer to Appendix C for the pseudocode of the reflection step and additional comments. An alternative approach to discretising a reflected SDE is to replace the reflection with a projection (Slominski, 1994). However, the projection requires the most expensive part of the reflection algorithm: computing the intersection of the geodesic with the boundary. Lou et al. (2023) propose a more tractable approach that exploits the product structure of the unit hypercube to afford simulation-free sampling but does not extend to arbitrary Riemannian manifolds. Additionally, specifying convex constraints in their framework requires a bijection onto the hypercube, distorting the modelled geometry and incurring the same issues as outlined above.

Figure 3: Evolution of the density of the reflected Brownian motion and its Metropolis sampling-based approximation on the unit interval starting from a delta mass.

Metropolis approximation.Existing approaches to constrained (Riemannian) diffusion models either only apply to convex subsets of \(^{d}\) or require manifold- and constraint-specific implementations that become computationally intractable as the complexity of the modelled geometry increases. This limits their practicality even for relatively simple manifolds with well-defined exponential maps and linear inequality constraints such as for example polytopes. In the following, we introduce a method that aims to solve both of these problems. The sampler we propose is similar to a classical Euler-Maruyama discretisation of the Brownian motion, except that, whenever a step would carry the Brownian motion out of the constrained region, we reject it (see Algorithm 1). This is a _Metropolised_ version of the usual discretisation and is trivial to implement compared to the existing barrier, reflection and projection methods. Hence, this method enables the principled extension of diffusion models to arbitrarily constrained manifolds at virtually _no added implementational complexity or computational expense_.

### Relating the Metropolis sampler to the reflected Brownian motion

In this section, we prove that the proposed Metropolis sampling-based process (Algorithm 1) corresponds to a valid discretisation of the reflected process, justifying its use in diffusion models. Here we focus on a concise presentation of the core concepts and the main results. A full proof can be found in Appendix D. For simplicity, we restrict ourselves to the Euclidean setting. All of our results require particular assumptions on \(\), which we discuss at the end of this section. We begin with a definition of the Metropolis approximation of RBM.

**Definition 1**.: _For any \(>0\) and \(k\), let \(X_{0}^{}\) and \(X_{k+1}^{}=X_{k}^{}+Z_{k}^{}\) if \(X_{k}^{}+Z_{k}^{}\) and \(X_{k}^{}\) otherwise. The sequence \((X_{k}^{})_{k}\) is called the Metropolis approximation of RBM._

For any \(>0\), we consider \((_{t}^{})_{t 0}\), the linear interpolation of \((X_{k}^{})_{k}\) such that for any \(k\), \(_{k}^{}=X_{k}^{}\). The following result is the main theoretical contribution of our paper.

**Theorem 2**.: _Under assumptions on \(\), for any \(T 0\), \((_{t}^{})_{t[0,T]}\) weakly converges to the RBM \((}_{t})_{t[0,T]}\) as \( 0\)._

The rest of the section is devoted to a high level presentation of the proof of Theorem 2. It is theoretically impractical to work directly with the Metropolis approximation of RBM. Instead, we introduce an auxiliary process, show this converges to the RBM, and finally prove that the convergence of the auxiliary process implies the convergence of our Metropolis discretisation.

**Definition 3**.: _For any \(>0\) and \(k\), let \(_{0}^{}=x\) and \(_{k+1}^{}=_{k}^{}+Z_{k}^{}\) with \(Z_{k}^{}\) a Gaussian random variable conditioned on \(_{k}^{}+Z_{k}^{}\). The sequence \((_{k}^{})_{k}\) is called the Rejection approximation of RBM._

    &  &  Modelling \\ domain \\  } &  Preserves \\ metric of \(\) \\  } \\  Reflected Diffusions & & & & \\ Lou et al. (2023) & ✓ & ✓ & convex \(^{d}\) & ✗ \\ Fishman et al. (2023) & ✗ & \((d^{2})\) & Any \(\) & ✓ \\ Metropolis (ours) & ✗ & \((d)\) & Any \(\) & ✓ \\  Barrier Diffusions & & & & \\ Fishman et al. (2023) & ✗ & ✗ & convex \(\) any \(\) & ✗ \\ Liu et al. (2023) & ✓ & ✓ & convex \(^{d}\) & ✗ \\   

Table 1: Comparison of the advantages and disadvantages of the different constrained (Riemannian) diffusion models covered in Section 3.1.

We call this process _Rejection approximation of RBM_ since in practice, \(Z_{k}^{}\) is sampled using rejection sampling, see Algorithm 2. For any \(>0\), we also consider \((}_{t}^{})_{t 0}\), the linear interpolation of \((_{k}^{})_{k}\) such that for any \(k\), \(}_{k}^{}=_{k}^{}\). In Appendix D, we prove the following result.

**Theorem 4**.: _Under assumptions on \(\), for any \(T 0\), \((}_{t}^{})_{t[0,T]}\) weakly converges to the Reflected Brownian Motion \((}_{t})_{t[0,T]}\) as \( 0\)._

Proof.: Here we give some elements of the proof. Details and full derivations are postponed to Appendix D. Our approach is based on the invariance principle of Stroock et al. (1971). More precisely, we show that we can compute an equivalent 'drift' and 'diffusion matrix' for the discretised process and that, as \( 0\), the drift converges to zero and the diffusion matrix converges to \(\). In the Euclidean setting, this result, accompanied by mild regularity and growth assumptions, ensures that the discretization weakly converges to the original SDE. However, the case with boundary is much more complicated, primarily because the approximate drift might explode near the boundary, thus we need to verify exactly how the drift behaves as \( 0\) and as the process approaches the boundary. We show that the _normalised_ drift converges to the inward normal near the boundary. This ensures that (a) in the interior of \(\) the drift converges to zero, i.e. locally in the interior of \(\) the Brownian motion and the Reflected Brownian Motion coincide, (b) on the boundary, the drift pushes the samples inside the manifold according to the inward normal, mimicking \((_{t})_{t 0}\) in (5). Finally, with results from Stroock et al. (1971) and Kang et al. (2017), we show the convergence to the RBM. 

Our next step is to show that the approximate drift and diffusion matrix of the Metropolised process are upper and lower bounded by their counterparts in the rejection process. While the upper-bound is easy to derive, the lower-bound requires the following result.

**Proposition 5**.: _Under assumptions on \(\), \(\;>0\), \(\;>0\) such that for any \((0,)\) and for any \(x\), \((0,)\) and \(Z(0,)\) we have \((x+Z) 1/2-\), with \(Z(0,)\)._

Proposition 5 tells us that _locally_ the boundary looks like a half-space when integrating w.r.t. a Gaussian measure. A corollary is that, for \(>0\) small enough and for any \(k\), the probability that \(X_{k+1}^{}=X_{k}^{}\) is upper bounded _uniformly_ w.r.t. \(X_{k}^{}\). The proof of Proposition 5 uses Theorem 7 in Appendix D, whose proof relies on the concept of _tubular neighborhoods_(Lee et al., 2012).

Having established the lower and upper bound, we can conclude the proof by noting that the approximate drift and the diffusion matrix in the rejection and Metropolis case coincide as \( 0\). This is enough to apply the same results as before, giving the desired convergence.

Assumptions on \(\).Before concluding this section, we detail the assumptions we make on \(\). For Theorem 2 to hold, we assume that \(=\{x^{d}\;:\;(x)>0\}\) is bounded, with \(^{2}(^{d},)\) concave. We have that \(=\{x^{d}\;:\;(x)=0\}\). In addition, we assume that for any \(x\), \(\|(x)\|=1\). These assumptions match those Stroock et al. (1971) use for their study of the existence of solutions to the RBM. While it seems possible to relax the _global_ existence of \(\) to a _local_ one, the regularity assumption of the domain is key. This regularity is essential to establish Proposition 5 and the associated geometrical result on tubular neighbourhoods. We also emphasize that the smoothness of the domain is central in the results of Kang et al. (2017) on the equivalence of two definitions of RBMs which we rely on.

```
0:\(p\), \(\{f_{i}\}_{i}\) Sample \((0,)_{p}\)\(p^{}_{p}()\) while\(f_{i}(p^{}) 0\) for any \(i\)do  Sample \((0,1)_{p}\)\(p^{}_{p}()\) endwhile return\(p^{}\) ```

**Algorithm 2**_Rejection approx. of RBM_

## 4 Related work on approximations of reflected SDEs

Several schemes have been introduced to approximately sample from reflected Stochastic Differential Equations. They can be interpreted as modifications of classical Euler-Maruyama schemes used to discretise SDEs without boundary. One of the most common approaches is to use the Euler-Maruyama discretisation and project the solution onto the boundary if it escapes from the domain \(\).

In this case, mean-square error rates of order _almost_\(1/2\) have been proven under various conditions (Liu, 1995; Chitashvili et al., 1981; Pettersson, 1995; Slominski, 1994). Concretely this means that \([\|}_{t}-X_{n}^{t/n}\|^{2}]=O(n^{-1+})\) with \(>0\) arbitrary small and where \((X_{k}^{})_{k}\) is the projection scheme. The rate \(1/2\) is tight (Pacchiarotti et al., 1998). It is possible to use the Euler-Peano method to get slight improvements for a mean-square error rate of order of \(1/2\), but this is impractical as it assumes that one can solve a (simplified) Skorokhod problem, which is usually intractable. Liu (1993) introduced a _penalised_ method which pushes the solution away from the boundary and shows a mean-square error of order \(1/4\), see also Pettersson (1997). Weak errors of order \(1\) have been obtained in Bossy et al. (2004) and Gobet (2001) by introducing a reflection component in the discretisation or using some local approximation of the domain to a half-space. We refer to Pilipenko (2014) for an introduction to the discretisation of reflected SDEs. Closer to our work, Burdzy et al. (2008) consider three different methods to approximate reflected Brownian motions on general domains (two based on discrete methods and one based on killed diffusions). Only qualitative results are provided. To the best of our knowledge, no previous work in the probability literature has investigated the _Metropolised_ scheme we propose. Our Metropolis scheme is also related to the ball walk (Applegate et al., 1991), which replaces the Gaussian random variable with a uniform over the ball (or the Dikin ellipsoid). Applegate et al. (1991) and Lovasz et al. (2007) have studied the asymptotic convergence rate of the ball walk, but, to the best of our knowledge, its limiting behaviour when the step size goes to zero has not been investigated.

    &  &  &  \\  & & log-likelihood & runtime & log-likelihood & runtime \\  \)} & 2 & \(2.25_{.01}\) & \(8.95\) & \(_{.05}\) & \(\) \\  & 3 & \(3.77_{.13}\) & \(8.97\) & \(_{.15}\) & \(\) \\  & 10 & \(7.42_{.77}\) & \(10.1\) & \(_{.34}\) & \(\) \\  \)} & 2 & \(1.01_{.01}\) & \(9.17\) & \(_{.02}\) & \(\) \\  & 3 & \(2.64_{.01}\) & \(9.43\) & \(_{.17}\) & \(\) \\   & 10 & \(7.00_{.13}\) & \(10.5\) & \(_{.20}\) & \(\) \\   

Table 2: Log-likelihood (\(\)) of a held-out test set from a synthetic bimodal distribution over convex subsets of \(^{d}\) bounded by the hypercube \([-1,1]^{d}\) and unit simplex \(^{d}\). Means and standard deviations are computed over 3 different runs. Average training time is provided in hours.

Figure 4: Convergence time of the Reflected (green) and Metropolis (red) forward noising processes to the uniform distribution on the hypercube \([-1,1]^{d}\) and unit simplex \(^{d}\). The lines indicate functions fit with the PySR symbolic regression package (Cranmer, 2023) and correspond to empirical runtime complexities of \((d^{2})\) and \((d)\), respectively, matching the superimposed scaling law isocontours.

## 5 Experimental results

To demonstrate the practical utility and empirical performance of the proposed Metropolis diffusion models, we conduct a comprehensive evaluation on a range of synthetic and real-world tasks. In Section 5.1, we assess the scalability of our method by applying it to synthetic distributions on hypercubes and simplices of increasing dimensionality. In Section 5.2, we extend the evaluation to real-world tasks on manifolds with convex constraints by applying our method to the robotics and protein design datasets presented in Fishman et al. (2023). In Section 5.3, we additionally demonstrate that our method extends to constrained manifolds with highly _non-convex_ boundaries--a setting that is intractable with existing approaches.

As we found--in line with Fishman et al. (2023)--that log-barrier diffusion models perform strictly worse than reflected approaches across all experimental settings, we focus on a more detailed comparison with the latter here and postpone additional empirical results to Appendix F.1. These include additional performance metrics and a comparison to an unconstrained Euclidean diffusion model on the synthetic datasets presented in Section 5.1.

For all experiments, we use a simple 6-layer MLP with sine activations and a score rescaling function to ensure that the score reaches zero at the boundary, scaling linearly into the interior of the constrained set as in Liu et al. (2022) and Fishman et al. (2023). We set \(T=1\), \(_{0}=1 10^{-3}\) and tune \(_{1}\) to ensure that the forward process reaches the invariant distribution with a linear \(\)-schedule. We use a learning rate of \(2 10^{-4}\) with a cosine learning rate schedule and an \(\) loss with a modified loss weighting function of \((1+t)\), a batch size of 1024 and 8 repeats per batch. All models were trained on a single NVIDIA GeForce GTX 1080 GPU. Additional details are provided in Appendix F.2.

All source code that is needed to reproduce the results presented below is made available under https://github.com/oxcsml/score-sde/tree/metropolis, which requires a supporting package to handle the different geometries that is available under https://github.com/oxcsml/geomstats/tree/polytope.

### Synthetic distributions on simple polytopes

In this section, we investigate the scalability of the proposed Metropolis diffusion models by applying them to synthetic bimodal distributions over the \(d\)-dimensional hypercube \([-1,1]^{d}\) and unit simplex \(^{d}\). A quantitative comparison of the log-likelihood of a held-out test set is presented in Table 2, while a visual comparison is postponed to Appendix F.3. We find that our Metropolis models outperform reflected approaches across all dimensions and constraint geometries by a substantial and statistically significant margin while training in one tenth of the time. The degree of improvement seems to scale with the dimensionality of the problem: the larger the dimension of the experiment, the larger the gain in performance from using our proposed Metropolis scheme.

We observe a similar difference in the scaling properties of reflected and Metropolis models when measuring the convergence times of the respective forward noising processes to the uniform distribution on hypercubes \([-1,1]^{d}\) and simplices \(^{d}\) of increasing dimensionality. The results are presented in Section 4 and show that the convergence time of the Metropolis process scales linearly in the dimension, while the reflected process scales quadratically.

Figure 5: A qualitative visual comparison of \(10^{6}\) samples from the data distribution, our Metropolis diffusion model, a reflected diffusion model and the uniform distribution for the constrained configurational modelling of robotic arms on \(^{2}_{++}^{2}\).

### Modelling proteins and robotic arms under convex constraints

In addition to illustrating our method's scalability on high-dimensional synthetic tasks, we follow the experimental setup from Fishman et al. (2023) to additionally demonstrate its practical utility and favourable empirical performance on two real-world problems from robotics and protein design.

Constrained configurational modelling of robotic arms.The problem of modelling the configurations and trajectories of a robotic arm can be formulated as learning a distribution over the locations and manipulability ellipsoids of its joints, parameterised on \(^{d}^{d}_{++}\), where \(^{d}_{++}\) is the manifold of symmetric positive-definite (SPD) \(d d\) matrices (Yoshikawa, 1985; Jaquier et al., 2021). For practical robotics applications, it may be desirable to restrict the maximal velocity with which a robotic arm can move or the maximum force it can exert. This manifests in a trace constraint \(C>0\) on \(^{d}_{++}\), resulting in a constrained manifold \(\{M^{d}_{++}:_{i=1}^{d}M_{ii}<C\}\). Following Fishman et al. (2023), we parametrise this constraint via the Cholesky decomposition (Lin, 2019) and use the resulting setup to model the dataset presented in Jaquier et al. (2021).

Conformational modelling of protein backbones.Modelling the conformational ensembles of proteins is a data-scarce problem with a range of important applications in biotechnology and drug discovery (Lane, 2023). In many practical settings, it may often be unnecessary to model the structural ensembles of an entire protein, as researchers are primarily interested in specific functional sites that are embedded in a structurally conserved scaffold (Huang et al., 2016). Modelling the conformational ensembles of such substructural elements requires positional constraints on their endpoints to ensure that they can be accommodated by the remaining protein. Using the parametrisation and dataset presented in Fishman et al. (2023), we formulate the problem of modelling the backbone conformations of a cyclic peptide of length \(N=6\) as learning a distribution over the product of a polytope \(^{3}\) and the hypertorus \(^{4}\).

We quantify the empirical performance of different methods by evaluating the log-likelihood of a held-out test set and present the resulting performance metrics in Table 3. Again, we find that our Metropolis model outperforms the reflected approach by a statistically significant margin while training 7-8 times as fast. Qualitative visual comparisons of samples from the true distribution, the trained diffusion models and the uniform distribution are presented in Figures 5 and 6, with full univariate marginal and pairwise bivariate correlation plots postponed to Appendices F.4 and F.5.

   Dataset & Domain &  &  \\  & & log-likelihood & runtime & log-likelihood & runtime \\  Robotics & \(^{2}_{++}^{2}\) & \(8.39_{.06}\) & \(9.52\) & \(}\) & \(\) \\ Proteins & \(^{3}^{4}\) & \(15.20_{.06}\) & 24.80 & \(}\) & \(\) \\   

Table 3: Log-likelihood (\(\)) of a held-out test set for the robotics and protein applications. Means and standard deviations are computed over 3 different runs. Average training time is provided in hours.

Figure 6: A qualitative comparison of \(10^{5}\) samples from the data distribution, our Metropolis diffusion model, a reflected diffusion model and the uniform distribution for the constrained conformational modelling of cyclic peptide backbones. For visual clarity, the figures only show the constrained planar projections encoded by \(^{3}\).

### Modelling geospatial data within non-convex country borders

Motivated by the strong empirical performance of our approach on tasks with challenging convex constraints, we investigated its ability to model distributions whose support is restricted to manifolds with highly non-convex boundaries--a setting that is intractable with existing approaches. To this end, we derived a geospatial dataset based on wildfire incidence rates within the continental United States (see Appendix E for full details) and trained a Metropolis diffusion model constrained by the corresponding country borders on the sphere \(^{2}\). A qualitative visual comparison of samples from the true distribution, our model, and the uniform distribution is presented in Figures 6(a) to 6(c) and a quantitative comparison to a Riemannian diffusion model on \(^{2}\)(De Bortoli et al., 2022) is given in Table 4. Both demonstrate that our approach is able to successfully capture challenging multimodal and sparse distributions on constrained manifolds with highly non-convex boundaries.

## 6 Conclusion

Accurately modelling distributions on constrained Riemannian manifolds is a challenging problem with a range of impactful practical applications. In this work, we have proposed a mathematically principled and computationally tractable extension of existing diffusion model methodology to this setting. Based on a _Metropolisation_ of random walks in Euclidean spaces and on Riemannian manifolds, we have shown that our approach corresponds to a valid discretisation of the reflected Brownian motion, justifying its use in diffusion models. To demonstrate the practical utility of our method, we have performed an extensive empirical evaluation, showing that it outperforms existing constrained diffusion models on a range of synthetic and real-world tasks defined on manifolds with convex boundaries, including applications from robotics and protein design. Leveraging the flexibility and simplicity of our method, we have also demonstrated that it extends beyond convex constraints and is able to successfully model distributions on manifolds with highly non-convex boundaries. While we found our method to perform well across the synthetic and real-world applications we considered, we expect it to perform poorly on certain constraint geometries. For instance, the current implementation relies on an isotropic noise distribution which could impede its performance on exceedingly narrow constraint geometries, even with correspondingly small step sizes. In this context, an important direction of future research would be to investigate whether we can instead sample from more suitable distributions, e.g. a Dikin ellipsoid, while maintaining the simplicity and efficiency of the Metropolis approach.

   Model & Domain & MMD & runtime & \% in boundary \\  Unconstrained & \(^{2}\) & \(0.1567 0.013\) & \(\) & \(63.3\) \\ Metropolis & \(^{2}\) & \(\) & \(3.86\) & \(\) \\   

Table 4: MMD (\(\)) of a held-out test set for the geospatial modelling dataset. Means and standard deviations are computed over 3 different runs. Average training time is provided in hours.

Figure 7: Orthographic projection of \(10^{5}\) samples from (a) the data distribution, (b) our Metropolis diffusion model, and (c) the uniform distribution, for geospatial data (wildfire incidence rates) within a non-convex boundary (the continental United States). The projections are aligned with the geometric centre of the boundary and zoomed in ten-fold for visual clarity.