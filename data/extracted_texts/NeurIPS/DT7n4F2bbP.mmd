# Tensor-Based Synchronization and the

Low-Rankness of the Block Trifocal Tensor

 Daniel Miao

School of Mathematics, University of Minnesota (miao0022@umn.edu, lerman@umn.edu)

Gilad Lerman

Department of Mathematics and Oden Institute for Computational Engineering and Sciences, University of Texas at Austin (jkileel@math.utexas.edu)

Joe Kileel

Department of Mathematics and Oden Institute for Computational Engineering and Sciences, University of Texas at Austin (jkileel@math.utexas.edu)

###### Abstract

The block tensor of trifocal tensors provides crucial geometric information on the three-view geometry of a scene. The underlying synchronization problem seeks to recover camera poses (locations and orientations up to a global transformation) from the block trifocal tensor. We establish an explicit Tucker factorization of this tensor, revealing a low multilinear rank of \((6,4,4)\) independent of the number of cameras under appropriate scaling conditions. We prove that this rank constraint provides sufficient information for camera recovery in the noiseless case. The constraint motivates a synchronization algorithm based on the higher-order singular value decomposition of the block trifocal tensor. Experimental comparisons with state-of-the-art global synchronization methods on real datasets demonstrate the potential of this algorithm for significantly improving location estimation accuracy. Overall this work suggests that higher-order interactions in synchronization problems can be exploited to improve performance, beyond the usual pairwise-based approaches.

## 1 Introduction

Synchronization is crucial for the success of many data-intensive applications, including structure from motion, simultaneous localization and mapping (SLAM), and community detection. This problem involves estimating global states from relative measurements between states. While many studies have explored synchronization in different contexts using pairwise measurements, few have considered measurements between three or more states. In real-world scenarios, relying solely on pairwise measurements often fails to capture the full complexity of the system. For instance, in networked systems, interactions frequently occur among groups of nodes, necessitating approaches that can handle higher-order relationships. Extending synchronization to consider measurements between three or more states, however, increases computational complexity and requires sophisticated mathematical models. Addressing these challenges is vital for advancing various technological fields. For example, higher-order synchronization can improve the accuracy of 3D reconstructions in structure from motion by leveraging more complex geometric relationships. In SLAM, it enhances mapping and localization precision in dynamic environments by considering multi-robot interactions. Similarly, in social networks, it could lead to more accurate identification of tightly-knit groups. Developing efficient algorithms to handle higher-order measurements will open new research avenues and make systems more resilient and accurate.

In this work, we focus on a specific instance of the synchronization problem within the context of structure from motion in 3D computer vision, where each state represents the orientation and location of a camera. Traditional approaches rely on relative measurements encoded by fundamental matrices, which describe the relative projective geometry between pairs of images. Instead, we consider higher-order relative measurements encoded in trifocal tensors, which capture the projective information between triplets of images. Trifocal tensors uniquely determine the geometry of three views, even in the collinear case , making them more favorable than triplets of fundamental matricesfor synchronization. To understand the structure and properties of trifocal tensors in multi-view geometry, we carefully study the mathematical properties of the block tensor of trifocal tensors. We then use these theoretical insights to develop effective synchronization algorithms.

**Directly relevant previous works.** In the structure from motion problem, synchronization has traditionally been done using incremental methods, such as Bundler  and COLMAP . These methods process images sequentially, gradually recovering camera poses. However, the order of image processing can impact reconstruction quality, as error may significantly accumulate. Bundle adjustment , which jointly optimizes camera parameters and 3D points, has been used to limit drifting but is computationally expensive.

Alternatively, global synchronization methods have been proposed. These methods process multiple images simultaneously, avoiding iterative procedures and offering more rigorous and robust solutions. Global methods generally optimize noisy and corrupted measurements by exploiting the structure of relative measurements and imposing constraints. Many global methods solve for orientation and location separately, using structures on \(SO(3)\) and the set of locations. Solutions for retrieving camera poses from pairwise measurements have been developed for camera orientations [5; 6; 7; 8; 9; 10], camera locations [11; 12; 13], and both simultaneously [14; 15; 16; 17]. Some methods explore the structure on fundamental or essential matrices [18; 19; 20].

Several attempts to extract information from trifocal tensors include works by: Leonardos et al. , which parameterizes calibrated trifocal tensors with non-collinear pinhole cameras as a quotient Riemannian manifold and uses the manifold structure to estimate individual trifocal tensors robustly; Larsson et al. , which proposes minimal solvers to determine calibrated radial trifocal tensors for use in an incremental pipeline, handling distorted images with constraints invariant to radial displacement; and Moulon et al. , which introduces a structure from motion pipeline, retrieving global rotations via cleaning the estimation graph and solving a least squares problem, and solving for translations by estimating trifocal tensors individually by linear programs. To our knowledge, no prior works develop a global pipeline where the synchronization operates directly on trifocal tensors.

**Contribution of this work.** The main contributions of this work are as follows:

* We establish an explicit Tucker factorization of the block trifocal tensor when its blocks are suitably scaled, demonstrating a low multilinear rank of \((6,4,4)\). Moreover, we prove that this rank constraint is sufficient to determine the scales and fully characterizes camera poses in the noiseless case.
* We develop a method for synchronizing trifocal tensors by enforcing this low rank constraint on the block tensor. We validate the effectiveness of our method through tests on several real datasets in structure from motion.

## 2 Low-rankness of the block trifocal tensor

We first briefly review relevant background material in Section 2.1. Then we present the main new construction and theoretical results in Section 2.2.

### Background

#### 2.1.1 Cameras and 3D geometry

Given a collection of \(n\) images \(I_{1},\)...,\(I_{n}\) of a 3D scene, let \(t_{i}^{3}\) and \(R_{i} SO(3)\) denote the location and orientation of the camera associated with the image \(I_{i}\) in the global coordinate system. Moreover, each camera is associated with a calibration matrix \(K_{i}\) that encodes the intrinsic parameters of a camera, including the focal length, the principal points, and the skew parameter. Then, the \(3 4\) camera matrix has the following form, \(P_{i}=K_{i}R_{i}[I_{3 3},-t_{i}]\) and is defined up to nonzero scale. Three-dimensional world points \(X\) are represented as \(^{4}\) vectors in homogeneous coordinates, and the projection of \(X\) into the image corresponding to \(P\) is \(x=PX\). 3D world lines \(L\) can be represented via Plucker coordinates as an \(^{6}\) vector. Then the projection of \(L\) onto the image corresponding to \(P\) is \(l=L\), where \(\) is the \(3 6\) line projection matrix. It can be written as \(=[P^{2} P^{3};P^{3} P^{1};P^{1} P^{2}]\) where \(P^{i}\) is the \(i\)-th row of the camera matrix \(P\) and wedge denotes exterior product. Explicitly the \((i,j)\) element of the line projection matrix can be calculated as the determinant of the submatrix, where the \(i\)-th row is omitted and the column are selected as the \(j\)-th pair from \([(1,2),(1,3),(1,4),(2,3),(2,4),(3,4)]\). The elements on the second row are multiplied by \(-1\).

To retrieve global poses, relative measurement of pairs or triplets of images is needed. Let \(x_{i}\) and \(x_{j}\) be any pair of corresponding keypoints in images \(I_{i}\) and \(I_{j}\) respectively, meaning that they are images of a common world point. The fundamental matrix \(F_{ij}\) is a \(3 3\) matrix such that \(x_{i}^{T}F_{ij}x_{j}\!=\!0\). It is known that \(F_{ij}\) encodes the relative orientation \(R_{ij}\!=\!R_{i}R_{j}^{T}\) and translation \(t_{ij}\!=\!R_{i}(t_{i}-t_{j})\) through \(F_{ij}\!=\!K_{i}^{-T}[t_{ij}]\!\!R_{ij}K_{j}^{-1}\). The essential matrix corresponds to the calibrated case, where \(K_{i}\!=\!I_{3 3}\) for all \(i\).

#### 2.1.2 Trifocal tensors

Analogous to the fundamental matrix, the trifocal tensor \(T_{ijk}\) is a \(3 3 3\) tensor that relates the features across images and characterizes the relative pose between a triplet of cameras \(P_{i}\),\(P_{j}\),\(P_{k}\). The trifocal tensor \(T_{ijk}\) corresponding to cameras \(P_{i}\),\(P_{j}\),\(P_{k}\) can be calculated by

\[(T_{ijk})_{wqr}\!=\!(-1)^{w+1}\![\!P_{i} ^{w}\\ P_{j}^{d}\\ P_{k}^{r}]\!,\] (1)

where \(P_{i}^{w}\) is the \(w\)-th row of \(P_{i}\), and \(\!P_{i}^{w}\) is the \(2 4\) submatrix of \(P_{i}\) omitting the \(w\)-th row. The trifocal tensor determines the geometry of three cameras up to a global projective ambiguity, or up to a scaled rigid transformation in the calibrated case. In addition to point correspondences, trifocal tensors satisfy constraints for corresponding lines, and mixtures thereof. For example, let \(l_{i}\),\(l_{j}\),\(l_{k}\) be corresponding image lines in the views of cameras \(P_{i}\),\(P_{j}\),\(P_{k}\) respectively, then the lines are related through the trifocal tensor \(T_{ijk}\) by \(l_{j}^{T}[(T_{ijk})_{1:,:},(T_{ijk})_{2:,:},(T_{ijk})_{3:,:}]l_{k} [l]_{}=0^{T}\), where \([l]_{}\) denotes the \( 3\) skew-symmetric matrix corresponding to cross product by \(l\). We refer to  for more details of the properties of a trifocal tensor. We include the standard derivation of the trifocal tensor in Appendix A.1.

Since corresponding lines put constraints on the trifocal tensor, one advantage of incorporating trifocal tensors into structure from motion pipelines is that trifocal tensors can be estimated purely from line correspondences or a mixture of points and lines. Fundamental matrices can not be estimated directly from line correspondences, so the effectiveness of pairwise methods for datasets where feature points are scarce is limited. Furthermore, trifocal tensors have the potential to improve location estimation. From pairwise measurements, one can only get the relative direction but not the scale and the location estimation in the pairwise setting is a "notoriously difficult problem" (quoting from pages 316-317 of ). However, trifocal tensors encode the relative scales of the direction and can greatly simplify the location estimation procedure. We refer to several works on characterizing the complexity of minimal problems for individual trifocal tensors , and on developing methods for solving certain minimal problems ,, , , , , . We also refer to  for a survey paper on structure from motion, which discusses minimal problem solvers from the perspective of computational algebraic geometry.

#### 2.1.3 Tucker decomposition and the multilinear rank of tensors

We review basic material on the Tucker decomposition and the multilinear rank of a tensor. We refer to  for more details while adopting its notation. Let \(T\!\!^{I_{1} I_{2} I_{N}}\) be an order \(N\) tensor. The _mode-\(i\) flattening_ (or _matricization_) \(T_{(i)}\!\!^{I_{1}(I_{1}\!\!I_{i-1}I_{i+1}\! I _{N})}\) is the rearrangement of \(T\) into a matrix by taking mode-\(i\) fibers to be columns of the flattened matrix. By convention, the ordering of the columns in the flattening follows lexicographic order of the modes excluding \(i\). Symbols \(\) and \(\) denote the Kronecker product and the Hadamard product respectively. The norm on tensors is defined as \(\|T\|\!=\!\|T_{(1)}\|_{F}\). The \(i\)-rank of \(T\) is the column rank of \(T_{(i)}\) and is denoted as rank\({}_{i}(T)\). Let \(R_{i}\)=rank\({}_{i}(T)\). Then the _multilinear rank_ of \(T\) is defined as mlrank(\(T\)) = \((R_{1},R_{2},\)...,\(R_{N})\). The \(i\)_-mode product_ of \(T\) with a matrix \(U\!\!^{m I_{i}}\) is a tensor in \(^{I_{1} I_{i-1} m I_{i+1}  I_{N}}\) such that

\[(T\!\!_{i}U)_{j_{1} j_{i-1}k_{j}j_{i+1} j_{N}}\!=\!_{j_{i} =1}^{I_{i}}\!T_{j_{1}j_{2} j_{N}}U_{kj_{i}}.\]

Then, the _Tucker decomposition_ of \(T\!\!^{I_{1} I_{2} I_{N}}\) is a decomposition of the following form:

\[T\!=\!\!\!_{1}A_{1}\!\!_{2}A_{2}\!\!_{3}\! \!_{N}A_{N}\!=\!;\!A_{1},\!A_{2},\!...,\!A_{N} ,\]where \(^{Q_{1} Q_{N}}\) is the core tensor, and \(A_{n}^{I_{n} Q_{n}}\) are the factor matrices. Without loss of generality, the factor matrices can be assumed to have orthonormal columns. Given the multilinear rank of the core tensor \((R_{1},\)...,\(R_{N})\), the Tucker decomposition approximation problem can be written as

\[*{argmin}_{^{R_{1} R_{ N}},A_{i}^{I_{i} R_{i}}}\|T-;A_{1},A_{2},...,A_{N} \|.\] (2)

A standard way of solving (2) is the _higher-order singular value decomposition_ (_HOSVD_). The HOSVD is computed with the following steps. First, for each \(i\) calculate the factor matrix \(A_{i}\) as the \(R_{i}\) leading left singular vectors of \(T_{(i)}\). Second, set the core tensor \(\) as \(=T_{1}A_{1}^{T}_{2}_{N}A_{N}^{T}\). Though the solution from HOSVD will not be the optimal solution to (2), it satisfies a quasi-optimality property: if \(T^{*}\) is the optimal solution, and \(T^{}\) the solution from HOSVD, then

\[\|T-T^{}\|\|T-T^{*}\|.\] (3)

### Low Tucker rank of the block trifocal tensor and one shot camera retrieval

Suppose we are given a set of camera matrices \(\{P_{i}\}_{i=1}^{n}\) with \(n 3\) and scales fixed on each camera matrix. Define the _block trifocal tensor_\(T^{n}\) to be the \(3n 3n 3n\) tensor, where the \(3 3 3\) sized \(ijk\) block is the trifocal tensor corresponding to the triplet of cameras \(P_{i},P_{j},P_{k}\). We assume for all blocks that have overlapping indices, the corresponding \(3 3 3\) tensor is also calculated using the formula (1). We summarize key properties of \(T^{n}\) in Proposition 1 and Theorem 1. The proof of Proposition 1 is by direct computation and can be found in Appendix A.3.

Proposition 1: _We have the following observations for the block trifocal tensor \(T^{n}\). For all distinct \(i,j[n]\), we have the following properties:_

1. \(T^{n}_{iii}=0_{3 3 3}\)__
2. _The_ \(T^{n}_{ji}\) _blocks are rearrangements of elements in the fundamental matrix_ \(F_{ij}\) _up to signs._
3. _The_ \(T^{n}_{iji}\) _and_ \(T^{n}_{ilj}\) _blocks encode the epipoles._
4. _The horizontal slices_ \(T^{n}(i;,:)\) _of_ \(T^{n}\) _are skew symmetric._
5. _When all cameras are calibrated, three singular values of_ \(T^{n}_{(1)}\) _are equal._

Theorem 1 (Tucker factorization and low multilinear rank of block trifocal tensor).: _The block trifocal tensor \(T^{n}\) admits a Tucker factorization, \(T^{n}=_{1}_{2}_{3} \), where \(^{6 4 4}\), \(^{3n 6}\), and \(^{3n 4}\). If the \(n\) cameras that produce \(T^{n}\) are not all collinear, then \(mlrank(T^{n})=(6,4,4)\). If the \(n\) cameras that produce \(T^{n}\) are collinear, then \(mlrank(T^{n})(6,4,4)\)._

Proof.: We can explicitly calculate that \(T^{n}=_{1}_{2}_{3} \). The details of the calculation are in Appendix A.2. The specific forms for \(\),\(\),\(\) are the following. The horizontal slices of the core are

\((T^{n}_{(1)})=6\). Similarly, we can show that rank(\(T^{n}_{(2)}\)) = 4, and rank(\(T^{n}_{(3)}\)) = 4. This implies that the multilinear rank of the block trifocal tensor is \((6,\!4,\!4)\) when the \(n\) cameras are not collinear.

When the \(n\) cameras are collinear, the individual factors in each flattening may be rank deficient, so that rank(\(T^{n}_{(1)}\)) \(\) 6, rank(\(T^{n}_{(2)}\)) \(\) 4, and rank(\(T^{n}_{(3)}\)) \(\) 4. This implies mlrank(\(T^{n}\)) \(\) (\(6,\!4,\!4)\). 

The theorem inspires a straightforward way of retrieving global poses from the block trifocal tensor, which we summarize in the following claim.

**Proposition 2** (One shot camera pose retrieval).: _Given the block trifocal tensor \(T^{n}\) produced by cameras \(P_{1},\!P_{2},\)...,\(P_{n}\), the cameras can be retrieved from \(T^{n}\) up to a global projective ambiguity using the higher-order SVD. The cameras will be the leading \(4\) singular vectors of \(T^{n}_{(2)}\) or \(T^{n}_{(3)}\)._

Using the higher-order SVD on \(T^{n}\), we can get a Tucker decomposition of the block trifocal tensor \(T^{n}=}_{1}}_{2}} _{3}}^{}\). Though the Tucker factorization is not unique , as we can apply an invertible linear transformation to one of the factor matrices and apply the inverse onto the core tensor, this invertible linear transformation can be interpreted as the global projective ambiguity for projective 3D reconstruction algorithms. Thus, the cameras can be retrieved by taking the leading four singular vectors of the mode-2 and mode-3 flattenings of the block tensor.

Very importantly however, in practice each trifocal tensor block in \(T^{n}\) can be estimated from image data _only up to an unknown multiplicative scale_. The following theorem establishes the fact that the multilinear rank constraints provide sufficient information for determining the correct scales. In the statement \(_{b}\) denotes blockwise scalar multiplication, thus the \((i,\!j,\!k)\)-block of \(_{b}T^{n}\) is \(_{ijk}T^{n}_{ijk}^{3 3 3}\).

**Theorem 2**.: _Let \(T^{n}^{3n 3n 3n}\) be a block trifocal tensor corresponding to \(n 4\) calibrated or uncalibrated cameras in generic position. Let \(^{n n n}\) be a block scaling with \(_{ijk}\) nonzero iff \(i,j,k\) are not all equal. Assume that \(_{b}T^{n}^{3n 3n 3n}\) has multilinear rank \((6,\!4,\!4)\) where \(_{b}\) denotes blockwise scalar multiplication. Then there exist \(,\!,\!\!^{n}\) such that \(_{ijk}=_{i}_{j}_{k}\) whenever \(i,\!j,\!k\) are not all the same._

Sketch.: The idea is to identify certain submatrices in the flattenings of \(_{b}T^{n}\) which must have determinant \(0\), and use these to solve for \(\). A proof is in Appendix A.4. We remark that the proof technique extends that of [36, Theorem 5.1], which showed a similar result for a matrix problem. 

Theorem 2 is the basic guarantee for our algorithm development below. We stress that the ambiguities brought by \(,\!,\!\) are _not_ problematic for purposes of recovering the camera matrices by Proposition 2. Indeed, \(()_{b}T^{n}=_{1}(D_{ })_{2}(D_{})_{3}(D_{}\! )\) where \(D_{}^{3n 3n}\) is the diagonal matrix with each entry of \(\) triplicated, etc. Hence the camera matrices can still be recovered up to individual scales (as expected) and a global projective transformation, from the higher-order SVD.

## 3 Synchronization of the block trifocal tensor

In this section, we develop a heuristic method for synchronizing the block trifocal tensor \(T^{n}\) by exploiting the multilinear rank of \(T^{n}\) from Theorem 1. Let \(^{n}\) denote the estimated block trifocal tensor, and \(T^{n}\) the ground truth. Assume that there are \(n\) images and a set of trifocal tensor estimates \(_{ijk}\) where \((i,\!j,\!k)\) and \(\) is the set of indices whose corresponding trifocal tensor is estimated. Note that each estimated trifocal tensor \(_{ijk}\) will have an unknown scale \(_{ijk}^{*}\) associated with it. We always assume that we observe the \(iii\) blocks, as they will be \(0\). We formulate the block trifocal tensor \(^{n}\) by plugging in the estimates \(_{ijk}\) and setting the unobserved positions (\((i,\!j,\!k)\)) to \(3 3 3\) tensors of all zeros. Let \(W_{}\{0,1\}^{3n 3n 3n}\) denote the block tensor where the \((i,\!j,\!k)\) blocks are ones for \((i,\!j,\!k)\) and zeros otherwise. Let \(W_{^{C}}\) denote the opposite. In our experiments, we observe that the HOSVD is quite robust against noise for retrieving camera poses, which arises e.g., from numerical sensitivities when first estimating relative poses . Therefore we develop an algorithm that projects \(^{n}\) onto the set of tensors that have multilinear rank of \((6,\!4,\!4)\) while completing the tensor and retrieving an appropriate set of scales. Specifically, we can write our problem as

\[_{}^{n}-_{}( ^{n})^{2}\] (4)where \(^{3n 3n 3n}\), each \(3 3 3\) block is uniform, \(_{ijk}\) blocks are zero for \((i,j,k)\), and \(\) satisfies a normalization condition like \(\|\|^{2}=1\) to avoid its vanishing. However, we drop this normalization constant in our implementation as we never observe \(\) vanishing in practice. (For convenience, we formulate this section with the notation of \(^{3n 3n 3n}\) and Hadamard multiplication, rather than \(^{n n n}\) and blockwise scalar multiplication from Theorem 2.) Furthermore in problem (4), \(_{}\) denotes the exact projection onto the set \(=\{T^{3n 3n 3n}:(T)=(6,4,4)\}\). Note that though HOSVD provides an efficient way to project onto \(\), it is quasi-optimal and not the exact projection. The exact projection is much harder to calculate, and in general NP-hard. The algorithm below adopts an alternating projection strategy to estimate the best set of scales.

### Higher-order SVD with a hard threshold (HOSVD-HT)

The key idea for our algorithm is to use the relative scales on the rank truncated tensor as a heuristic to retrieve scales for the estimated block tensor. There are two main challenges for calculating the rank truncated tensor. First, the exact projection \(_{}\) onto \(\) is expensive and difficult to calculate. Second, many blocks in the block tensor will be unknown if the corresponding images of the block lacks corresponding point and directly projecting the uncompleted tensor will be inaccurate. We apply an HOSVD framework with imputations to tackle the challenges. Regarding the first challenge, HOSVD is a simple, efficient, and quasi-optimal (3) projection onto \(\). Though inexact, it is a reliable approximation. For the second challenge, the tensor \(^{n}\) must be completed. We adopt the matrix completion idea of HARD-IMPUTE , where the matrix is filled-in iteratively with the rank truncated matrix obtained using the hard-thresholded SVD. In other words, we complete the missing blocks with the corresponding blocks in the rank truncated tensor. We define three hyperparameters \(l_{1}\),\(l_{2}\),\(l_{3}\) that correspond to the thresholding parameters of the hard-thresholded SVD on modes \(1\),\(2\),\(3\) of the block tensor respectively. Specifically, for each mode-\(i\) flattening \(T^{n}_{(i)}\), we calculate the full SVD \(T^{n}_{(i)}=USV^{T}\). Since our tensor will scale cubically with the number of cameras, we suggest using a randomized SVD. We refer to  for different randomized strategies. Assume the singular values \(_{i}\) on the diagonal of \(S\) are sorted in descending order, as usual. We return the factor matrix \(A_{i}\) as the top \(a\) left singular vectors in \(U\), where \(a=\{i:S_{ii}>l_{i}\}\). Our adapted truncation method is summarized by Algorithm 1.

``` Input:\(^{n}^{3n 3n 3n}\): the estimated block tensor; \(l_{1}\),\(l_{2}\),\(l_{3}\): the thresholds for modes \(1\),\(2\),\(3\) respectively Output:\(_{r}^{3n 3n 3n}\): the rank truncated tensor. for i = 1 to 3 do  Perform the randomized SVD on the mode-\(i\) flattening such that \(^{n}_{(i)} USV^{T}\) \(a_{i}\{i:S_{ii}>l_{i}\}\) \(A_{i}\) first \(a_{i}\) columns of \(U\) endfor \(=^{n}_{1}A_{1}^{T}_{2}A_{2}^{T}_{3}A_{3}^{T}\) \(^{r}[\![;A_{1},A_{2},A_{3}]\!]\) ```

**Algorithm 1** HOSVD-HT

From now on, we refer to hard-thresholded HOSVD as HOSVD-HT and denote the operation as \(_{ht}\).

### Scale recovery

HOSVD-HT provides an efficient way for projecting \(^{n}\) onto the set of tensors with truncated rank. To recover scales, we use the rank truncated tensor's relative scale as a heuristic to adjust the scale on our estimated block trifocal tensor \(^{(n)}\). For each step, we solve

\[^{(t+1)}=}\| ^{n}-_{ht}(^{(t)}^{n})\|^{2}_{ijk}=0_{3 3 3}(i,j,k)^{C},\] (5)

where we drop the normalization condition on \(\) because in practice it is not needed. We solve (5) for each observed block separately. Denoting \(_{ht}(^{(t)}^{n})\) as \((^{n}_{r})^{(t)}\), we have

\[^{(t+1)}_{ijk}=}\|^ {n}_{ijk}-(^{n}_{r})^{(t)}_{ijk}\|^{2}=^{n}_{ijk})^{( t)}_{(1)}((^{n}_{r})^{(t)}_{ijk})_{(1)})}{\|((^{n}_{r})^{(t)}_{ ijk})_{(1)}\|_{F}^{2}}.\] (6)Recall that our strategy for completing the tensor is to impute the tensor with the entries from the rank truncated tensor using HOSVD-HT. Specifically, given the current imputed tensor \((^{n})^{(t)}\), we calculate \(_{ht}((^{n})^{(t)})\) and the new scales \(^{(t+1)}\). Then update with

\[(^{n})^{(t+1)}\!=\!(^{(t+1)}\!\!(^{n})^{(t)}\!\! W_{})\!+\!_{ht}((^{n})^{(t)})\!\!W_{^{C}}.\] (7)

### Synchronization algorithm

Now we summarize our synchronization framework in Algorithm 2.

``` Input:\(^{n}\!\!^{3n 3n 3n}\); \(W_{}\),\(W_{^{C}}\!\!\{0,\!1\}^{3n 3n 3n}\); \(l_{1}\),\(l_{2}\),\(l_{3}\!\!\) Output:\(\!\!^{3n 4}\): camera matrices up to a \(4 4\) projective ambiguity and camera-wise scales Initialize \(^{n}\) by imputing unobserved blocks randomly to get \((^{n})^{(0)}\) while not converged do  Calculate \(_{ht}((^{n})^{(t)})\) using HOSVD-HT  Calculate \(^{(t+1)}\) (5) using (6) \((^{n})^{(t+1)}\!\!(^{(t+1)}\!\!(^{n})^{(t )}\!\!W_{})\!+\!_{ht}((^{n})^{(t)})\!\!W_{ ^{C}}\) \(t\!\!t\!+\!1\) endwhile \((\),\(A_{1}\),\(A_{2}\),\(A_{3})\!\!HOSVD((^{n})^{(t)})\) \(\!\!\) First 4 columns of \(A_{2}\) ```

**Algorithm 2** Synchronization of the block trifocal tensor

We have observed that the algorithm can overfit, as the recovered scales will experience sudden and huge leaps. Our stopping criteria for the algorithm is when we observe sudden jumps in the variance of the new scales or when we exceed a maximum number of iterations. Another challenge in structure from motion datasets is that estimations may be highly corrupted. The HOSVD framework mainly consists of retrieving a dominant subspace from each flattening. Thus, it is natural to replace the SVD on each flattening with a more robust subspace recovery method, such as the Tyler's M estimator (TME)  or a recent extension of TME that incorporates the information of the dimension of the subspace in the algorithm . We refer to Appendix A.5.2 for more details and provide an implementation there.

## 4 Numerical experiments

We conduct experiments of Algorithm 2 on two benchmark real datasets, the EPFL datasets  and the Photo Tourism datasets . We observe that the algorithm performs better in the calibrated setting, and since the calibration matrix is usually known in practice, we restrict our scope of experiments to calibrated trifocal tensors. We compare against three state-of-the-art synchronization based on two view measurements, NRFM  and LUD . NRFM relies on nonconvex optimization and requires a good initialization. We test NRFM with an initialization obtained from LUD and with a random initialization. We also test BATA  initialized with MPLS . We refer to A.6 in the appendix for a comprehensive summary of numerical results including rotation and translation estimation errors. We include our code in the following github repository: TrifocalSync.

### EPFL dataset

For EPFL, we follow the experimental setup and adopt code from  and test an entire structure from motion pipeline. We first describe the structure from motion pipeline for EPFL experiements.

\(\) Step 1 (feature detection and feature matching). We obtain matched features across pairs of images using a modern deep learning based feature detection and matching algorithm, GlueStick . Though we do not implement this in our experiments, there have been methods developed to further screen corrupted keypoint matches or obtain matches robustly, such as [46; 47; 48]. Key points across a triplet of cameras is matched from pairs and is included only if it appears in all the pair combinations of the three images.

\(\) Step 2 (estimation and refinement of trifocal tensors). With the triplet matches, we calculate the trifocal tensors with more than 11 correspondences. To have an even sparser graph, one can skip the estimation of trifocal tensors and rely on the imputation for images that have less than a number bigger than 11 point correspondences. This can further speed up the trifocal tensor estimation process. We apply STE from  to find 40% of the correspondences as inliers, then use at most \(30\) inlier point correspondences to linearly estimate the trifocal tensor. To refine the estimates, we apply bundle adjustment on the inliers and delete triplets with reprojection error larger than 1 pixel.

* Step 3 (synchronization). We synchronize the estimated block trifocal tensor with a robust variant of SVD using the framework described in Algorithm 2. The robustness comes from replacing SVD with a robust subspace recovery method . More details can be found in Appendix A.5.2. Recall that the cameras we retrieve are up to a global projective ambiguity. When comparing with ground truth poses, we first align our estimated cameras with the ground truth cameras by finding a \(4 4\) projective transformation. Then we round the cameras to calibrated cameras and compare.

We test our full pipeline on two EPFL datasets on a personal machine with 2 GHz Intel Core i5 with 4 cores and 16GB of memory. To test NRFM , LUD  and BATA  initialized with MPLS , we estimate the corresponding essential matrices using the GC-ransac . We did not include blocks corresponding to two views in our trifocal tensor pipeline. The mean and median translation errors are summarized in Figure 1 here and more comprehensive results can be found in Table 1 and Table 2 in the appendix.

The EPFL datasets generally have a plethora of point correspondences, so that the trifocal tensors are estimated accurately. When the dataset focuses on a single scene, our algorithm retrieves locations competitively. Our algorithm achieves the best location estimation for 4 out of 6 datasets. The translation error bars are not visible for FP11, HZP8, EN10 due to the accuracy that we achieve. However, our pipeline is incapable of accurately processing CastleP19 and CastleP30. The main reason is that our algorithm relies on having a very dense observation graph to ensure high completion rate. CastleP19 and CastleP30 are datasets where the camera scans portions of the general area sequentially, so that not many triplets have overlapping features. Our method is not suitable for this type of dataset. However, it is possible to apply our algorithm in parallel on groups of neighboring frames, so that the completion rate is high in each group. Then the results can be merged to obtain a larger reconstruction. Rotations for the two view methods are estimated via rejecting outliers from iteratively applying . We also compare against  for location estimation, where we initialize with a state-of-the-art global rotation estimation method . Our algorithm achieves superior rotation estimation for only 2 out of the 6 datasets. See Table 1 and 2 in the appendix for comprehensive errors.

### Photo Tourism

We conduct experiments on the Photo Tourism datasets. The Photo Tourism datasets consist of internet images of real world scenes. Each scene has hundreds to thousands of images. The datasets

Figure 1: EPFL translation error comparison between our method, NRFM initialized by LUD, LUD, and NRFM initialized randomly. BATA(MPLS) stands for BATA initialized by MPLS. HZ8 stands for HerzP8, FP11 for FountainP11, HZ25 for Herz P25, EN10 for EntryP10, CS19 for CastleP19, CS30 for CastleP30.

 provide essential matrix estimates, and we estimate the trifocal tensors from the given essential matrices. To limit the computational cost for tensors, we downsample the datasets by choosing cameras with observations more than a certain percentage in the corresponding block frontal slice while maintaining a decent number of cameras. Note that this may not be the optimal way of extracting a dense subset in general. The maximum number of cameras we select for each dataset is 225 cameras. The largest dataset Piccadilly has 2031 cameras initially. We randomly sample 1000 cameras and then run our procedure. For Roman Forum and Piccadilly, the two view methods further deleted cameras from the robust rotation estimation process or parallel rigidity test. We rerun and report the trifocal tensor synchronization algorithm with the further downsampled data. We initialize the hard thresholding parameters for HOSVD-HT by first imputing the trifocal tensor with small random entries and then calculating the singular values for each of the flattenings. We take \(l_{i}\) to be the tertile singular value for each mode-\(i\) flattening. We then keep this parameter fixed for the synchronization process. Recall that the \(jii\) blocks in the block trifocal tensor correspond to elements in the essential matrix \(E_{ij}\). We also include these essential matrix estimations in the block trifocal tensor. The Photo Tourism experiments were run on an HPC center with 32 cores, but the only procedure that can benefit from parallel computing in a single experiment is the scale retrieval. Mean and median translation errors are summarized in Figure 2. Fully comprehensive results can be found in Tables 3 and 4 in Appendix A.6.

Our method is able to achieve competitive translation errors on 8 of the 14 datasets tested. Similar to the observation in the EPFL experiments, our algorithm performs well when the viewing graph is dense, or in other words, when the estimation percentage is high. We achieve better locations in 6 out of 8 datasets where the estimation percentage exceeds 60%, and better locations in only 2 out of 6 datasets where the estimation percentage falls below 60%. We achieve reasonable rotation estimations for 10 out of 14 datasets, but not as good as LUD. See Table 4 for a comprehensive result. Since the block trifocal tensor scales cubically with respect to the number of cameras, our algorithm runtime is longer than most two view global methods. This could be alleviated by synchronizing dense subsets in parallel and merging the results to construct a larger reconstruction.

**Additional remark:** Trifocal tensors can be estimated from line correspondences or a mix of point and line correspondences, while fundamental matrices are estimated from only point correspondences. There are many situations where accurate point correspondences are in short supply but there is a plethora of clear and distinct lines. For example, see datasets in a recent SfM method using lines . We demonstrate the potential of our method to be adapted to process datasets with only lines or very few points. Due to the limited availability of well annotated line datasets, we provide a small synthetic experiment that simulates a case where only lines correspondences are present. We first generate 20 random camera matrices, then we generate 25 lines that are projected on and shared across all images. We add about 0.02 percent of noise in terms of the relative - frobenius norms between the line equation parameters and the noise. We estimate the trifocal tensor of three different views from line correspondences linearly. One remark is that our synchronization method works well only when the signs of the initial unknown scales are mostly uniform. We manually use ground truth trifocal tensors

Figure 2: Photo Tourism translation error comparison between our method, NRFM initialized by LUD, LUD, NRFM initialized randomly, and BATA initialized with MPLS. Note that we have not been able to acquire results for Piccadilly for BATA + MPLS.

to correct the sign of the scale. This has not been an issue in the previous experiments due to bundle adjustment for EPFL and the overall good estimations in Photo Tourism. In practice, the sign of the scale on a trifocal tensor can be corrected via triangulation of points or reconstruction of lines, and correcting the sign using the depths of the reconstructed points or intersecting line segments. We synchronize the trifocal tensors with Algorithm 2 and were able to achieve a mean rotation error of 0.61 degrees, median rotation error of 0.49 degrees, mean location error of 0.76, and median location error of 0.74.

## 5 Conclusion

In this work, we introduced the block tensor of trifocal tensors characterizing the three-view geometry of a scene. We established an explicit Tucker factorization of the block trifocal tensor and proved it has a low multilinear rank of \((6,4,4)\) under appropriate scaling. We developed a synchronization algorithm based on tensor decomposition that retrieves an appropriate set of scales, and synchronizes rotations and translations simultaneously. On several real data benchmarks we demonstrated state-of-the-art performance in terms of camera location estimation, and saw particular advantages on smaller and denser sets of images. Overall, this work suggests that higher-order interactions in synchronization problems have the potential to improve performance over pairwise-based methods.

There are several limitations to our tensor-based synchronization method. First, our rotation estimations are not as strong as our location estimations. Second, our algorithm performance is affected by the estimation percentage of trifocal tensors within the block trifocal tensor. One could incorporate more robust completion methods and explore new approaches for processing sparse triplet graphs. Further, our block trifocal tensor scales cubically in terms of the number of cameras and becomes computationally expensive for large datasets. We can develop methods for extracting dense subgraphs, synchronizing in parallel, then merging results to obtain a larger reconstruction, similarly to the distributed algorithms of  and . Moreover, our synchronization method's success depends on accurate trifocal tensor estimations, and it motivates further work on robust estimation of multi-view tensors. Algorithm 2 could also be made more robust by adding outlier rejection techniques. Finally we plan to extend our theory by proving convergence of our algorithm and exploring structures for even higher-order tensors, such as quadrifocal tensors.