# Computing the Bias of Constant-step Stochastic Approximation with Markovian Noise

Sebastian Allmeier

Univ. Grenoble Alpes and Inria

F-38000 Grenoble, France.

&Nicolas Gast

Univ. Grenoble Alpes and Inria

F-38000 Grenoble, France.

###### Abstract

We study stochastic approximation algorithms with Markovian noise and constant step-size \(\). We develop a method based on infinitesimal generator comparisons to study the bias of the algorithm, which is the expected difference between \(_{n}\) --the value at iteration \(n\)-- and \(\)* --the unique equilibrium of the corresponding ODE. We show that, under some smoothness conditions, this bias is of order \(O()\). Furthermore, we show that the time-averaged bias is equal to \( V+O(^{2})\), where \(V\) is a constant characterized by a Lyapunov equation, showing that \([_{n}]\)*\(V+O(^{2})\), where \(_{n}=(1/n)_{k=1}^{n}_{k}\) is the Polyak-Ruppert average. We also show that \(_{n}\) converges with high probability around \(\)* \(+ V\). We illustrate how to combine this with Richardson-Romberg extrapolation to derive an iterative scheme with a bias of order \(O(^{2})\).

## 1 Introduction

Stochastic approximation (SA) is a widely used algorithmic paradigm to solve fixed-point problems under noisy observations. While SA was introduced in the 1950s , it is still widely used today in many applications to solve optimization problems, or to implement machine learning or reinforcement learning algorithms . A typical SA is a stochastic recurrence of the form

\[_{n+1}=_{n}+_{n}(f(_{n},X_{n})+M_{n+1}),\] (1)

where \(_{n}^{d}\) is a vector of parameters, \(X_{n}\) and \(M_{n+1}\) are sources of randomness, and \(_{n}\) is the step-size. The step-size might be decreasing to \(0\) as \(n\) grow or can be fixed to a small constant (in which case we simply call it \(\)).

The goal of running a SA algorithm is to obtain a sequence \(_{n}\) that gets close to the root \(\)* of the function \(()=[f(,X)+M]\), the expectation of the iterate (1), as \(n\) goes to infinity. The SA procedure described in (1) models many algorithms that are used in machine learning, like first-order optimization and stochastic gradient descent , and \(Q\)-learning or policy gradient algorithms .

The theory of stochastic approximation has been studied extensively and is covered by a lot of textbooks, _e.g._, . This theory shows that the limit points of \(_{n}\) as \(n\) grows are similar to the limit points of the ODE \(=(x)\). In particular, one can show that if all solutions of the ODE converge to \(\)*, then \(_{n}\) gets close to \(\)* as \(n\) grows large (under technical conditions on \(f\), the step size \(_{n}\), and the noise \(X_{n}\) or \(M_{n+1}\)). The asymptotic behavior of \(_{n}\) depends on the nature of the step-size: When the step-size \(_{n}\) depends on \(n\) and converges to \(0\) as \(n\) goes to infinity, then \(_{n}\) generally converges almost surely to \(\)*. When \(_{n}\) is kept constant and does not depend on \(n\), then \(_{n}\) will in general _not_ converge to \(\)* but keeps oscillating around \(\)*, with fluctuation amplitudes of order \(O()\). In this work, we focus on the latter case and propose a method to quantify these fluctuations.

We consider a SA algorithm with Markovian noise. That is, \(_{n}\) evolves as in (1) where the random variable \(X_{n}\) evolves as a Markov chain that depends on \(_{n}\), and the random variable \(M_{n+1}\) is a Martingale difference sequence. One thing that sets this paper apart from others is that we allow the Markovian noise to be dependent on \(_{n}\). This is particularly valuable in reinforcement learning application such as \(Q\)-learning where the exploration policy might depend on \(_{n}\) (this would for instance be the case for \(\)-greedy). It is known that when the step size \(\) is constant, then the expectation of the iterates, \([_{n}]\), does not converge to \(^{*}\) as \(n\) goes to infinity but has a _bias_. The goal of our paper is to provide a framework to characterize and compute this bias.

Our main contribution is to provide a framework based on semi-groups, to quantify the convergence rate of \(_{n}\) to \(^{*}\). This framework is similar to Stein's method, that has been recently popularized to obtain accuracy results and refinement terms for fluid limits . It allows us to quantify the distance between the stochastic recurrence (1) and its deterministic counterpart (8) as a function of the distance between the infinitesimal generators of the stochastic and deterministic systems. By using this framework, we obtain two main results. Our first result (Theorem 1) states that, under smoothness conditions on \(f\), there exists a constant \(C>0\) such that for all small enough \(\):

\[_{n}|[_{n}]-^{*}|  C_{n}| [(_{n}-^{*})^{2}]| C.\]

This guarantees that that the bias and variance of \(_{n}\) are of order _at most_\(\).

A classical way to reduce the variance of SA is to use Polyak-Ruppert tail averaging , _i.e._, to look at the convergence of \(_{n}=(1/n)_{k=1}^{n}_{n}\) instead of \(_{n}\). In this paper, we show that, for the constant step-size case, the use of Polyak-Ruppert averaging removes the variance (_i.e._\(_{n}[_{n}]=0\)), but not the bias: Theorem 2 shows that there exists a vector \(V\) and a constant \(C^{}>0\) such that:

\[_{n}|[_{n}]-^{*}- V| C^{2}.\]

This shows that the bias of the averaging is _exactly_ of order \(\). We also show in Theorem 3 that \(_{n}\) converges _in probability_ to a point in \(^{*}+V+O(^{2})\) as \(n\) goes to infinity.

We also provide numerical simulation on a synthetic example that illustrates how to combine the Polyak-Ruppert averaging with a Richardson-Romberg extrapolation  to construct a stochastic approximation algorithm whose bias is of order \(O(^{2})\). This leads to an algorithm that enjoys both a small bias and a fast converge rate, compared to using a time-step of order \(^{2}\).

_Roadmap_. The rest of the paper is organized as follows. We describe related work in Section 2. We introduce the model and give assumptions and notations in Section 3. We state the main results and provide numerical illustrations in Section 4. We give the main ingredients of the proofs in Section 5. The appendices contain technical lemmas and additional numerical examples.

## 2 Related work

Stochastic approximation algorithms were first introduced with decreasing step-size . Since these seminal papers, there has been a considerable amount of work aiming at characterizing the asymptotic properties of SA, by relating the asymptotic behavior of \(_{n}\) with the one of the ODE \(=()\). These topics are today well covered by textbooks such as .

In this original theory, the goal was to show that \(_{n}\) is close to the behavior of an ODE but not necessarily to obtain tight rates of convergence. This lead to the development of a new line of research focussing on non-asymptotic properties of SA . This paper derives a unified framework to study the rate of convergence of stochastic gradient descent by relating it to SA with decreasing step-size, and martingale noise (_i.e._, where the function \(f\) does not depend on \(X_{k}\) in (1)). This framework has been extended by a series of papers for applications in reinforcement learning, see for instance , still in the decreasing step-size case, with the goal of understanding the fluctuations of the algorithm around the equilibrium.

For the decreasing step size, the fluctuations of \(_{n}\) around \(^{*}\) vanish as \(n\) goes to infinity. This is not the case for constant step-size SA, for which understanding the magnitude of the fluctuations is therefore important. To bound the fluctuations, a part of the literature seeks to obtain bounds on the mean squared error (MSE), \([(_{n}-^{})^{2}]\) as a function of the problem's parameter and the step-size \(\). These papers show that the MSE is generally of order \(O()\), see for instance  for the case of linear model plus Markovian noise, or [13; 15; 14] for contractive stochastic approximations (with Markovian or martingale noise).

The case of constant-step size is also interesting because the \(_{n}\) has a bias that does not vanish as \(n\) goes to infinity. In particular, the Polyak-Ruppert averaging does not converge to \(^{}\): generally \(_{n}_{n}^{}\). It is shown in particular in [16; 20; 25; 32; 41; 42] that a constant step-size SA has an asymptotic bias of order \(\), which shows that \(_{n}_{n}=^{}+V+O(^{2})\). Some of these papers, and in particular [16; 20], show that this bias characterization can be coupled with a Richardson-Romberg extrapolation to obtain a more accurate algorithm. In our paper, we also study the case of constant-step size SA with Markovian noise and use the same Polyak-Ruppert and Richardson-Romberg analysis. One of the distinguishable property of our model is that we allow the evolution of the Markovian noise \(X_{n}\) to depend on \(_{n}\), whereas most of the cited paper consider \(X_{n}\) has an external source of noise. This dependence is particularly interesting when studying asynchronous \(Q\)-learning algorithms [37; 36], for which the navigation policy is often derived from the current values of the parameter (a popular example is to use an \(\)-greedy policy).

A second distinguishable feature of our paper is the methodology that we use. Our main tool is to relate the distance between the expectation of \(_{n}\) and \(^{}\) as a distance between the infinitesimal generators of the stochastic recurrence (1) and of the deterministic recurrence (8). The method that we develop is tightly connected to Stein's method  and in particular with the line of work that use this method to obtain accuracy bounds for mean-field approximation [17; 22; 39; 40]. In particular, the start of our proof, which is to study a hybrid system composed of a stochastic and a deterministic recurrence in equation (9), can be seen as a discrete-time version of what is termed as a "classical trick" in [17; 22]. Apart from this difference between discrete and continuous time, one of the major features of our model is to have a Markovian noise. Our model can be viewed as a discrete-time version of the recent paper . Some of our results (like our Theorem 1) are analogous to the results of  but others (like Theorem 2) are different and require time-averaging, mostly because of the possible periodicity of the discrete-time Markov chains. Also, the model of the current paper is slightly more general than the one of . The fact that our methodology directly studies the expectation of \(_{n}\) makes it different from convergence results that use concentration equalities .

## 3 Model and preliminaries

### Model and first assumptions

Throughout the paper \((_{n},X_{n})_{n 0}\) is a discrete-time stochastic process adapted to a filtration \((_{n})_{n 0}\). This stochastic process has two components of different nature. The first component \(\), that we call the parameter, is continuous and lives in a compact subset \(^{d}\): for each \(n\): \(_{n}^{n}\). The second component \(X\) lives in a finite set \(\), i.e., \(X_{n}\).

The evolution of \(\) and \(X\) are coupled in the following way. The parameter \(\) evolves according to the recurrence equation given by (1). At every time-step \(n\), the process \(X\) makes a Markovian transition according to a Markovian kernel \(K(_{n})\). More precisely, for all \(x,x^{}\) and \(\):

\[(X_{n+1}=x^{} X_{n}=x,_{n}=,_ {n})=(X_{n+1}=x^{} X_{n}=x,_{n}= )=:K_{x,x^{}}().\] (2)

To obtain our results, we will make the following assumptions:

* The process \(M\) is a martingale difference sequence (that is: for all \(n\): \([M_{n+1}_{n}]=0\)) and its conditional covariance is \([M_{n+1}M_{n+1}^{T}_{n}]:=Q(_{n},X_{ n})\). Moreover, we assume that \([M_{n+1}M_{n+1}^{T}_{n} X_{n+1}]=R( _{n},X_{n},X_{n+1})\).
* The functions \(f\), \(K\), \(Q\) and \(R\) are four times differentiable in \(\).
* For any given \(\), the matrix \(K()\) is unichain1. 
In addition to these three assumptions, we later add an assumption (A4) about the stability of the ODE around its fixed point. We do not state this assumption here as it needs extra definitions.

### Averaged values, average ODE and stability assumption

Assumption (A3) implies that a Markov chain with kernel \(K()\) has a unique stationary measure \(()\), and we denote by \(_{x}()\) the stationary probability of \(x\) for such a Markov chain. For any function \(g\) defined on \(\), we call \(\) its _averaged_ version, i.e., the function that associates to \(\) the value \(()\), defined as:

\[()=_{x}g(,x)_{x}().\] (3)

It is shown in [1, Lemma 4], that under Assumption (A3), for each \(\), the kernel \(K()\) has a unique stationary distribution \(()\). The value \(()\) is equal to \([g(,X)]\) where \(X\) is distributed according to the stationary distribution associated to \(K()\).

Following our notation introduced in (3), we denote by \(\) the averaged version of \(f\). By [1, Lemma 4], the function \(()\) is twice differentiable under assumptions (A2) and (A3), which implies that the function \(\) is also twice differentiable. This implies, for an initial \((0)=\), the ODE \(=()\) has a unique local solution, and we denote the value of this solution at time \(t\) by \(_{t}()\). In order to prove this result, we will need that this ODE has a unique fixed point to which all trajectories converge and that this fixed point is an exponentially stable attractor. This is summarized in the following asusmption:

* There exists a \(^{*}\) such that for any \(\), the solution of the ODE \(=()\) is defined for all \(t>0\) and converges to \(^{*}\): \(_{t}_{t}()=^{*}\) for all \(\). Moreover, the derivative of \(\) at \(^{*}\) is Hurwitz (i.e., the real parts of all of its eigenvalues are negative).

By classical results on the stability of ODES, this assumption implies that the convergence to \(^{*}\) occurs exponentially fast, that is, there exists \(a,b>0\) such that for all \(\): \(\|_{t}()-^{*}\| ae^{-bt}\,\|-^{*}\|\). To prove that, one can use [21, Theorem 4.13], that shows that \(^{*}\) is an exponentially stable point of the ODE, _i.e._, \(\|_{t}()-^{*}\| a^{}e^{-bt}\,\|-^{*}\|\) in a neighborhood \(\) of \(^{*}\), because \(D(^{*}0)\) is Hurwitz. Then, as \(\) is compact, there exists \(T\) such that \(_{T}()\) for all \(\). The result then follows by choosing \(a=a^{}e^{Tb}_{}\|-^{*}\|/ _{}\|-^{*}\|\).

### Discussion on the assumptions and limits

Most of the assumptions used in the paper are classical when studying stochastic approximation algorithms with Markovian noise. In this section, we discuss the limits of each assumption (from the most classical one to the most original one). Assumption (A3) is necessary to define the notion of average dynamics \(()\) and is therefore present in virtually all papers about Markovian noise stochastic approximation. The originality of our assumption is that we allow the transition kernel to depend on \(\). For assumption (A1), we add to the classical result the existence of a co-variance matrix \(Q\), which is needed as it appears in the expression of \(V\). Assumption (A4) imposes that the stochastic approximation has a unique exponentially stable attractor. Our results could probably be adapted to a model with multiple attractors (by using large deviation techniques similar to the one of  for a two time-scale setting as ours) but this would be another paper.

One important assumption we make is that \(\) lives in a compact set \(\). The bounded condition on \(\) simplifies greatly the proofs because it allows us to use uniform bounds that do not depend on \(\) (for instance, the identity function \(h()=\) is bounded thanks to this assumption. Similarly, the time taken by the solution of the ODE \(_{t}()\) to reach \(^{*}\) is also uniformly bounded independently on \(\)). This assumption could be relaxed by imposing high probability bounds (for instance, a large deviation result like  that would guarantee that \(_{n}\) stays close to \(^{*}\)), or a bound on the higher-order moment or exponential moments of \(_{n}\). We left this result for future work as it would greatly impact the readability of the proofs.

The most questionable of our assumption is Assumption (A2) that imposes that all parameters of the problem are four times differentiable in \(\). While this assumption might seem as technical, the fact that the parameters are twice differentiable is crucial in our analysis. In particular, the constant \(V\) does depend on the first two derivatives of the function \(\). In general, if the parameters of the systems are not differentiable, then the bias will not be of order \(O()\) but of order \(O()\). Treating a non-differentiable \(\) would need a completely different methodology. Our assumption of having_four_ times differentiable functions and not just twice has two reasons: it guarantees that the error \(\|_{n}-(^{*}+ V)\|\) is \(O(^{2})\), and it simplifies the proof by allowing us to reuse Theorem 1 to obtain the bound \(O(^{2})\) in Theorem 2. We believe that if we only impose twice differentiability, this error would be \(o()\) (and in fact probably \(^{3/2}\) as long as all derivatives are Lipschitz-continuous).

### Notations

Recall that \(\) is a compact subset of \(^{d}\). We suppose that it is equipped with a norm \(\|\|\). For a function \(h:\), where \(^{d^{}}\), we denote by \(\|h\|=_{e}\|h(e)\|\) the supremum of this function. If \(h\) is \(i\) times differentiable, we denote by \(D^{i}h\) its \(i\)th derivative. Its value evaluated in \(e\) is denoted by \(D^{i}h(e)\). It is a multi-linear map and we denote by \(D^{i}h(e)a^{ i}\) its value applied to \((a,,a)\) for a given \(a^{d}\). We denote by \(\|D^{i}h\|\) the operator norm of its \(i\)th derivative, defined as \(\|D^{i}h\|=_{e,a^{d^{}}} \|D^{i}h(e)a^{ j}\|/\|a\|^{j}\). By Taylor remainder theorem, for all \(e\) and \(a^{d^{}}\), we have: \(\|h(e+a)-h(e)-_{j=1}^{i-1}D^{j}h(e)a^{ j}\|\|D ^{i}h\|\|a\|^{i}\).

We define by \(\|D^{ i}h\|=(\|h\|,_{j i}\|D^{j}h \|)\) the maximum of the norm of the first \(i\)th derivatives of \(h\). We denote by \(^{i}(,)\) the set of functions whose first \(i\) derivatives are bounded and by \(^{i}_{ 1}(,)\) the set of functions whose first \(i\) derivatives are bounded by \(1\): \(\|D^{ i}h\| 1\). As \(\) is a discrete set, the above notions extend to functions \(h:\). For such a function, by abuse of notation, we call \(D^{i}h\) the \(i\)th derivative with respect to the continuous variable only.

In the paper, the value at time \(t\) of the solution of the ODE \(=()\) starting in \(\) is denoted by \(_{t}()\). We will introduce later a quantity \(_{n}()\) that corresponds to a Euler discretization of the ODE with constant step-size \(\). To lighten notations, we will omit the dependence on \(\) in the notation \(\) but it should be clear that \(\) depends on \(\). To help distinguishing between the solutions of the the ODE \(_{t}\) and the discrete-time recurrence \(_{n}\), we will reserve the index \(t\) for a continuous time variable and the indices \(n\), \(k\) or \(N\) for discrete-time indices.

To ease notations in some part of the proofs, we will sometimes use big-O notations, like \((1)\) or \(()\). When using this, we allow the hidden constants to depends on all parameters of the problems defined in Assumptions (A1) to (A4) but they cannot depend on varying quantities likes an index \(k\), \(n\) or \(\) or norm of functions, like \(\|g\|\) or \(\|h\|\) that are introduced in the proofs. Note that in all of our lemmas, we always consider functions whose norm is bounded by \(1\). This can, of course, be readily extended to functions not bounded by \(1\) by adding an extra factor like \(\|D^{ i}h\|\). We avoid doing this to lighten the notations.

## 4 Main results and illustrations

This section presents the main theorems and illustrate their consequence. The proof of the theorems are postponed to the next Section 5.

### Theoretical results

Our first result is Theorem 1 that shows that the expected value of \(_{n}\) is at distance at most \(()\) of the solution of the ODE. This shows that the bias of stochastic approximation is of order \(\) with respect to the ODE.

**Theorem 1**.: _Assume (A1)-(A4). Then, there exists a constant \(C>0\) and \(_{0}\) such that for all \(n\), \(_{0}\) and all \(h^{3}_{ 1}(,)\):_

\[|[h(_{n})-h(_{ n}(_{0}))] | C.\]

Note that the bound of Theorem 1 is valid independently of \(n\). As we will see in the proof, this is a consequence of Assumption (A4). Without the latter assumption, one would naturally obtain a constant \(C\) that grows exponentially with \(n\). As \(C\) does not depend on time, a direct consequence of Theorem 1 is to show that the asymptotic bias of \(_{n}\) is of order \(()\) as \(n\) goes to infinity, that is:

\[_{n}|[h(_{n})]-h(^{*}) | C.\] (4)Our second result is Theorem 2, that shows that the inequality of (4) is essentially an equality. This theorem provides an asymptotic expansion of the bias term in \(\).

**Theorem 2**.: _Assume (A1)-(A4). Then, there exists a constant \(C^{}>0\) and \(_{0}\) such that for all \(_{0}\) and \(h_{ 1}^{5}(,)\):_

\[_{n}|_{k=1}^{n}[h(_{ k})]-h(^{*})- V|^{2}C^{}.\] (5)

An important difference between Theorem 1 and 2 is that the former studies the convergence of the iterates \(_{n}\) whereas the latter provides a refinement term for the average of the iterates, i.e., \(_{n}:=_{k=1}^{n}[_{k}]\), by showing that \(_{n}\) is essentially equal to \(h(_{})\) plus a bias term \(V\). One may wonder if Theorem 2 would be true for the (non-averaged) iterates \(_{n}\). The answer is no and a counter-example is provided in Appendix A. This example illustrates that when the Markovian component \(X_{n}\) can be periodic, the \(O()\) term of \([_{n}]\) does not necessarily stabilize to a constant \(V\) but can be periodic as well.

Theorem 2 concerns the convergence of the _expectation_ of \(_{n}\) but not the value of \(_{n}\) itself. As we will see in Section 5, this is mostly due to our proof techniques that works with generators and therefore is most suitable to obtain precise convergence results for the expectation. In fact, we will prove in Section B.2 that we can obtain a high-probability convergence result as an almost-direct consequence of Theorem 2, as expressed by the following Theorem.

**Theorem 3**.: _Assume (A1)-(A4). Then, there exists a constant \(C^{}>0\) and \(_{0}\) such that for all \(_{0}\):_

\[_{n}(|_{n}-(^{*}+ V )| C^{}^{2})=0.\]

This result is illustrated on a synthetic example whose parameters are given in Appendix A.2, and for which \(^{*}=1\). We run the stochastic approximation algorithm for various values of \(\) and report the results in Figure 1. In all cases, we use the same source of randomness (the values of the Markov chain \(X_{n}\) and of the the Martingale noise \(M_{n+1}\) are the same for all trajectories). We plot a sample trajectory of \(_{n}\), \(_{n}\), and \(_{n/2:n}\) defined2 as:

\[_{n/2:n}=||_{k=|n/2|+1}^{n} _{k},\]

for \(\{0.001/4,0.001/8,0.001/16\}\) (more values of \(\) are displayed in Appendix A). We observe that if \(_{n}\) is quite noisy, the Polyak-Ruppert averaging \(_{n}\) or \(_{n/2:n}\) are much closer to \(^{*}=1\), which is a clear advantage for \(_{n/2:n}\) in terms of rate of convergence, especially for small values of \(\).

### The value of extrapolation: Illustration of Theorem 2 and 3

As we will see in the proof, the constant \(V\) of Theorem 2 can be expressed as a function of the problem's parameters, which allows one to construct a quantity \(^{*}+V\) that is a tight approximation of \(_{n}\). Yet, stochastic approximation algorithms are most used when one does not have access to the problem's parameter. Here, we illustrate how we can run two algorithms with two different step-sizes in order to obtain an algorithm that has both a fast convergence rate and a high precision.

Let \(_{n/2:n}^{(2)}\) and \(_{n/2:n}^{()}\) be two trajectories of the stochastic recurrence (1) each with respective step-size \(2\) and \(\). By Theorem 2, for large \(n\) we have:

\[_{n/2:n}^{(2)} =^{*}+2V+(^{2})\] \[_{n/2:n}^{()} =^{*}+V+(^{2})\]

We see that we can suppress the term in \(2V\) and \(V\) by using a linear combination of \(_{n/2:n}^{(2)}\) and \(_{n/2:n}^{()}\), which leads to an equation that has a distance to \(^{*}\) that is of order \((^{2})\):

\[2_{n/2:n}^{()}-_{n/2:n}^{(2)}=^{*}+ (^{2}).\] (6)

To explore the benefit of using the extrapolation (6), we plot in Figure 2 the error of the averaged iterate5\(|_{n/2:n}-^{*}|\), and the error of the extrapolation (6) for various values of \(=0.01*2^{-k}\), with \(k=\{-1 4\}\). The parameters are the same as the one of Figure 1 and the various \(\)s use the same source of randomness. As we expect by the statement of the theorems, the error \(_{n/2:n}-^{*}\) is approximately equal to \(V\) (the stars on the right are the theoretical values of \(_{n}|_{n/2:n}-^{*}|\)). On the right panel, we observe that \(2_{n}^{()}-_{n}^{(2)}\) is closer to \(^{*}\) than the corresponding \(_{n}^{()}\) (the scale of the \(y\)-axis is the same for both panels). Note that even for \(n=10^{5}\), the values of \(\) are still noisy.

## 5 Proof overview and generator method

### Proof overview

The first idea of our proof is to construct new random variables \(_{k}(_{n-k})\) that corresponds to a system where we apply the stochastic recurrence (1) for \(k\) steps and then apply the deterministic recurrence (8) up to time \(n\). By introducing these new variables and comparing their expectation for \(k\) and \(k+1\), we reduce our problem to a comparison of the generators of the stochastic and of the deterministic system. This step is done in Section 5.2. In an independent lemma, we use Assumption (A4) to show that the derivatives of the function \(_{n}\) converge exponentially fast to \(0\) as \(n\) goes to infinity. This leads to Lemma 6 whose proof is technical and postponed to Section C.

Once these two basic points are obtained, we will use them to prove Proposition 4 which shows that the expectation of \(_{n}\) is close to the solution of the deterministic ODE. More precisely, this proposition shows that there exists a bounded sequence of constants \(V_{n}^{()}\) and a constant \(C>0\) such that for all \(n\): \(|[h(_{n})-h(_{n}(_{0}))]- V _{n}^{()}| C^{2}\). A main difficulty is to show that \(V_{n}^{()}\) is bounded. For that we will use Lemmas 7 and 8 that use properties of the Poisson Equation (21) to show that if the functions \(g_{k}\) do not vary too much with \(k\), then they can be replaced by their averaged versions:

\[|_{k=0}^{n-1}g_{k}(_{k},X_{k})-_{k=0}^{n-1}[ _{k}(_{k})]| C(1+_{k=0}^{n-1}\|g_{ k+1}-g_{k}\|).\] (7)

Theorem 1 is a direct consequence of Proposition 4. by using that \(V_{n}^{()}\) are bounded.

The next step is to show that the time average versions of \(V_{n}^{()}\), \(_{n}^{()}=n^{-1}_{k=1}^{n}V_{n}^{()}\), converges (as \(n\) goes to infinity) to a term \(V^{()}\). Here, the main technical difficulty is to obtain a refinement of the averaging property of (7), which is done in Lemmas 9 and 10. We then use Theorem 1 and Lemma 11 to show that \(V^{()} V+()\) where \(V\) is given in Proposition 5. This gives Theorem 2. As a side-product, Lemma 11 also shows that the constant \(V\) can be computed by solving a linear system. The high-probability bound (Theorem 3) is a consequence of Theorem 2.

The proof structure is illustrated in Figure 3 that shows the dependencies between the lemmas.

### Deterministic recurrence and comparison of generators

To compare the stochastic variable \(_{n}\) and the solution of the ODE \(=()\), we introduce a deterministic recurrence equation, that is a first-order discretization of the ODE. This recurrence equation is obtained by replacing the sources of randomness of (1) by their expectation. The stochastic approximation (1) contains two sources of randomness: \(M_{n+1}\) and \(X_{n}\). In our analysis, we will use a deterministic counterpart of (1) that corresponds to setting the noise \(M_{n+1}\) to \(0\) and to using \(()\) instead of \(f(_{n},X_{n})\). More precisely, for an initial value \(\) and \(k^{+}\), we define \(_{n}()\) as:

\[_{n+1}()=_{n}()+(_{n}()),\] (8)

with the convention that \(_{0}()=\).

Let \(h:\) be an arbitrary function. By using the definition of the deterministic recurrence, for any \(k\{0 n\}\), we introduce the variable

\[z_{n,k}:=[h(_{n-k}(_{k}))].\] (9)

The quantity \(z_{n,k}\) is the expected value of a recurrence at time \(n\) if one starts by applying the stochastic recurrence for the first \(k\) steps and then the deterministic recurrence for the remaining

Figure 3: Overview of the proof. The dashed rectangles indicate the lemmas that are proven in Appendix C.

steps. Our proof method consists in obtaining precise bounds on the difference \([_{n}]-[_{n}(_{0})]\). By using the notation \(z_{n,k}\), this quantity is equal to \(z_{n,n}-z_{n,0}\). To obtain a bound on this quantity, we will use a trick, that essentially consists in comparing \(z_{n,k+1}-z_{n,k}\). This quantity is simpler to analyze because the only modification between the two is to replace one stochastic transition by one deterministic transition. We can then recover the original bound by using that:

\[[_{n}]-_{n}(_{0})=z_{n,n}-z_{n,0}= _{k=0}^{n-1}z_{n,k+1}-z_{n,k}.\] (10)

This method is illustrated in Figure 4 on a synthetic example whose parameters are given in Appendix A.3. In the right panel, plot two functions (for two different values of \(k\)) that are equal to \(_{n}\) for \(k n\) and to \(_{n-k}(_{k})\) for \(k>n\).

### Derivation of \(V_{n}^{()}\) and of \(V\) by comparing the generators

Using the above notations, we are now ready to prove the first proposition.

**Proposition 4**.: _Assume (A1)-(A4). Then, there exists a constant \(C>0\) and \(_{0}\) such that for all \(n\), \(_{0}\) and all \(h_{ 1}^{3}(,)\):_

\[|[h(_{n})-h(_{n}(_{0}))]-  V_{n}^{()}| C^{2},\]

_where the quantity \(V_{n}^{()}\) is given by:_

\[V_{n}^{()}:=_{k=0}^{n-1} D(h_{n-(k+1)})(_{k})(f(_{k},X_{k}) -(X_{k}))\] \[-D^{2}(h_{n-(k+1)})(_{k})((f(_{k},X _{k})-(X_{k}))^{ 2}+Q(_{k},X_{k})).\]

_Moreover, \(V_{n}^{()}\) is bounded independently of \(\) and \(n\)._

Proof.: Following the definition of the stochastic and deterministic recurrences, the difference \(z_{n,k}-z_{n,k+1}\) that appears in (10) is equal to

\[z_{n,k+1}-z_{n,k} =[h(_{n-k}(_{k}))-h(_{n-(k+1) }(_{k+1}))]\] \[=h_{n-(k+1)}(_{k}+(_{k}))\] \[-h_{n-(k+1)}(_{k}+(f(_{k},X_{k})+M_ {k+1}))\] (11)

If \(g:^{d}\) is a thrice differentiable function whose third derivative is bounded by \(\|D^{3}g\|\), by using a Taylor expansion, we have that \(g(x+a)-g(x+b)=Dg(x)(a-b)+D^{2}g(x)(a-b)^{ 2}+R\), where \(R\) is a remainder term that is smaller than \(\|a-b\|^{3}\). In our proof, we use this Taylor expansion with the function \(g=h_{n-(k+1)}\), \(x=_{k}\), \(a=(f(_{k},X_{k})+M_{k+1})\) and \(b=(_{k})\). Applying this to (11) shows that

\[z_{n,k+1}-z_{n,k}= A_{n,k}+}{2}B_{n,k}+R_{n,k},\] (12)

where \(A_{n,k}\) and \(B_{n,k}\) are equal to

\[A_{n,k} :=[D(h_{n-(k+1)})(_{k})(f( _{k},X_{k})+M_{k+1}-(X_{k}))]\] \[B_{n,k} :=[D^{2}(h_{n-(k+1)})(_{k})(f( _{k},X_{k})+M_{k+1}-(X_{k}))^{ 2}],\]

and \(R_{n,k}\) is a remainder term.

By assumption (A1), the conditional expectation and variance of the martingale term are equal to \(M_{k+1}_{k}=0\) and \([M_{k+1}^{ 2}_{k}]=Q(_{k},X_{k})\). By using the total law of expectation, this shows that \(A_{n,k}\) and \(B_{n,k}\) can be simplified as:

\[A_{n,k} :=[D(h_{n-(k+1)})(_{k})(f( _{k},X_{k})-(X_{k}))]\] \[B_{n,k} :=[D^{2}(h_{n-(k+1)})(_{k})( (f(_{k},X_{k})-(X_{k}))^{ 2}+Q(_{k},X_{k}))].\]

By definition, \(V_{n}^{()}=_{k=0}^{n-1}(A_{n,k}+ B_{n,k}/2)\). Hence, combining this with (10) shows that

\[[h(_{n})-h(_{n}(_{0}))]=V_{n}^{( )}+_{k=0}^{n-1}R_{n,k}.\]

To complete the proof, it remains to be shown that there exists a constant such that \(_{k=0}^{n-1}R_{n,k} C^{2}\) and that \(V_{n}^{()}\) is bounded independently of \(\) and \(n\). There are three terms, corresponding to \(R\), \(B\), and \(_{k=1}^{n}A_{n,k}\):

**Case of \(R\)**. In Lemma 6, we show that the norm of the derivatives of \(h_{n-k}\) are smaller than \(c_{1}e^{-c_{2}a(n-k)}\). As the derivatives of \(h\) are bounded by \(1\), this implies there exists \(c\) independent of \(\) and \(n\) such that \(\|D^{3}(h_{n-k})\| ce^{-c_{2}(n-k)}\). Hence, there exists \(c^{}>0\) such that:

\[_{k=0}^{n-1}\|R_{n,k}\| c^{}^{3}_{k=0}^{n-1 }e^{-c_{2}(n-k)} c^{}^{3}_{k=0}^{}e^{-c_{2}  k} c^{}c_{3}^{2}.\]

**Case of \(B\)**. The proof that \(_{k=1}^{n} B_{n,k}\) is bounded independently of \(n\) and \(\) is similar since the factor \(\) cancels out with the factor \(1/\) that comes out of \(_{k=0}^{}e^{-c_{2} k}\).

**Case of \(A\)** Showing that \(_{k=1}^{n}A_{n,k}\) is bounded independently of \(n\) and \(\) is more subtle and uses the fact that \(\) is the "averaged" version of \(f\) with respect to the transition kernel \(K\). The proof of this is a consequence of the first point of Lemma 8 that is stated in Section C. 

The proof of the main results is then a consequence of the next proposition, whose proof is given in Appendix B. This proposition shows that the Cesaro limit of \(V_{n}^{()}\) is approximately equal to a term \(V\) that does not depend on \(\) plus a term of order \(O()\).

**Proposition 5**.: _Assume (A1)-(A4). Then, there exist a constant \(C>0\) and \(_{0}>0\) such that for all \(h_{ 1}^{5}(,)\), there exists a vector \(V\) such that for all \(n\), \(_{0}\):_

\[|_{n}^{()}-V| C(+),\]

_where \(_{n}^{()}:=n^{-1}_{k=1}^{n}V_{k}^{()}\) with \(V_{k}^{()}\) as in Proposition 4._

## 6 Conclusion / discussion

In this paper, we presented an analysis of the bias of constant-step size algorithms with Markov noise. We developed a novel technic, based on generator comparison, that allows to obtain a very fine comparison between the expectation of the stochastic trajectory and the value of its deterministic counterpart. This methodology is quite generic and we believe that it could easily be adapted to obtain more general results. We are in particularly targeting: relaxing the bounded of \(\), and obtaining non-asymptotic results.

Acknowledgements

The authors would like to thank the three anonymous reviewers for their insightful comments about the paper. This work was supported by the ANR (Agence National de la Recherche), via the project REFINO (ANR-19-CE23-0015).