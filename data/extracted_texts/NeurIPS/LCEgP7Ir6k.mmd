# Partial observation can induce mechanistic mismatches in data-constrained models of neural dynamics

William Qian\({}^{1,2}\), Jacob A. Zavatone-Veth\({}^{3,4,5}\), Benjamin S. Ruben\({}^{1}\), Cengiz Pehlevan\({}^{2,3,4}\)

\({}^{1}\)Biophysics Graduate Program,

\({}^{2}\)Kempner Institute for the Study of Natural and Artificial Intelligence,

\({}^{3}\)John A. Paulson School of Engineering and Applied Sciences,

\({}^{4}\)Center for Brain Science, \({}^{5}\)Department of Physics,

Harvard University

Cambridge, MA 02138

jzavatoneveth@fas.harvard.edu, cpehlevan@seas.harvard.edu

###### Abstract

One of the central goals of neuroscience is to gain a mechanistic understanding of how the dynamics of neural circuits give rise to their observed function. A popular approach towards this end is to train recurrent neural networks (RNNs) to reproduce experimental recordings of neural activity. These trained RNNs are then treated as surrogate models of biological neural circuits, whose properties can be dissected via dynamical systems analysis. How reliable are the mechanistic insights derived from this procedure? While recent advances in population-level recording technologies have allowed simultaneous recording of up to tens of thousands of neurons, this represents only a tiny fraction of most cortical circuits. Here we show that observing only a subset of neurons in a circuit can create mechanistic mismatches between a simulated teacher network and a data-constrained student, even when the two networks have matching single-unit dynamics. In particular, partial observation of models of low-dimensional cortical dynamics based on functionally feedforward or low-rank connectivity can lead to surrogate models with spurious attractor structure. Our results illustrate the challenges inherent in accurately uncovering neural mechanisms from single-trial data, and suggest the need for new methods of validating data-constrained models for neural dynamics.

## 1 Introduction

In recent years, advances in recording techniques have brought forth a deluge of neural data. Simultaneous measurements of the activity of hundreds to thousands of neurons can now be obtained at high spatiotemporal resolution . These methods are increasingly deployed to perform longitudinal recordings in animals executing quasi-naturalistic behaviors or complex tasks , meaning that one may not have recourse to repeatable trial structure when analyzing these data . A critical question for contemporary systems neuroscience then arises: How can mechanistic insights about the neural dynamics underlying animal behavior be extracted from large-scale recordings ?

Given access to only a single, non-repeatable measurement of neural activity, a natural question is whether one could construct a reliable _in silico_ surrogate model for the dynamics of the measured neural circuit. As this surrogate model would not be subject to measurement limitations, it could be used to generate hypotheses about the corresponding biological neural populations, and to simulate how such populations might behave under various external inputs or perturbations. A natural approach to constructing a surrogate model is to optimize a recurrent neural network (RNN) to mimic therecorded neural activity. In recent years, this approach has gained broad popularity, and has been applied to data from many species and recording modalities .

Data-driven models of neural dynamics are constructed under a number of less-than-ideal conditions. First, in single-trial settings, one has access to measurements of dynamics only in a restricted condition or set of conditions, so it may be impossible to observe how changes in input or in internal state affect the circuit of interest . Second, the system of interest is only partially observed: one can only usually record from a subset of the neurons in a given circuit, and certainly cannot simultaneously record all of their inputs . Third, measurements of neural activity are noisy, and may be biased to capture only certain components of neural activity. For example, intrinsic indicator dynamics mean that calcium imaging may effectively low-pass filter neural activity, even if one is only interested in firing rates and not precise spike times . Fourth, it can be challenging to account for the presence and structure of intrinsic neuronal noise. Finally, there will always be a significant mismatch between the single-unit dynamics of a model and biology, as models abstract away or ignore biophysical details to enable efficient optimization and simulation .

Even in the unrealistic scenario where the activity of every relevant neuron is recorded, exactly inferring synaptic weights from dynamical measurements alone is extremely challenging . A more modest hope is that data-constrained models should be able to capture the mechanistic dynamical properties of ground-truth circuits at a qualitative level--that is, to recapitulate slow time scales, unstable directions, oscillatory dynamics, and attractors . Given a data-constrained model, one can identify attractor properties using dynamical systems analysis . These macroscopic dynamical properties are of substantial neuroscientific interest, as low-dimensional attractors are believed to underlie observed neural activity across a variety of neural circuits and tasks . In particular, line attractors--sets of stable fixed points organized along lines in neural activity space--have been proposed to underlie cognitive functions requiring short-term or working memory, including sensory integration, decision making, and even aggressive behavior . Importantly, low-dimensional structures in data should be relatively robustly detectable even under partial observation , so there is reason to be optimistic that data-constrained models could correctly recover line attractor dynamics. Indeed, several recent papers have used data-constrained models with low-dimensional latent RNN dynamics to propose that line attractors underlie the accumulation of internal drives and of external reward .

However, despite some positive examples , previous works have not mapped out how partial observation affects whether data-driven modeling can accurately recover low-dimensional attractor structure. To address this question, in this paper, we consider a teacher-student setup in which activity from one RNN is imitated by another, and show that partial observation can induce mechanistic mismatches even under relatively ideal conditions where the input to a circuit is either perfectly known or white noise, and where the single-unit dynamics of the student match the teacher. Our primary contributions are as follows:

* In SS2, we begin with a motivating example: we show that data-constrained modeling fails to distinguish between two mechanistically-distinct models in a stimulus-integration task. Both a line attractor network  and a functionally feedforward chain  are identified as line attractors.
* We then turn to the analytically-tractable setting of noise-driven linear RNNs (SS3). In SS3.1, we show that when the teacher is an approximate line attractor, the student will recover this structure. In contrast, when the teacher connectivity is non-normal, the student may learn spurious approximate attractor structure. We illustrate this with two biologically-motivated examples: functionally-feedforward integrators (SS3.2), and networks with low-rank connectivity (SS3.3).
* Then, in SS4, we explore how these insights generalize beyond the linear setting. Focusing on the example of nonlinear low-rank networks, we show that partial observation once again can induce overestimation of eigenvalue magnitude. Here, though, this can result in spurious attractor structure including additional stable fixed points and limit cycles.

Our results begin to illuminate the inductive biases of data-constrained RNNs trained under partial observation towards particular mechanisms of generating long timescales. They suggest that caution is warranted in inferring mechanism from data-constrained models, and underscore the primacy of direct activity perturbations for validating putative attractor dynamics .

## 2 A motivating example: data-constrained modeling of integrator circuits

The circuit basis for temporal integration of scalar sensory inputs is a longstanding question in systems neuroscience [12; 24; 28; 29; 32; 33; 34; 35; 36; 37; 38; 39; 40; 41]. Though many models for integrator circuits have been proposed [32; 37; 40; 42], two linear RNN models are perhaps the most prominent: the line attractor [28; 40], and the feedforward chain [32; 37]. Both of these models have extremely simple dynamics

\[}=-+J+u\]

for state \(^{D}\), recurrent weights \(J^{D D}\), and input \(u(t)\) encoded through \(^{D}\). However, they posit structurally distinct mechanisms for how memories can be maintained beyond the single-unit time constant \(\). In classic line attractor networks, the recurrent weights are chosen to be symmetric, and one eigenvalue of \(J\) is tuned to be precisely equal to one, with the rest being less than one. Then, by choosing the input weights \(\) to align with the corresponding eigenvector, one obtains a perfect integrator of the signal \(u(t)\) (App. A). However, this model suffers from a substantial fine-tuning problem: slight mis-tuning of the weights causes exponentially large deviations from perfect integration [28; 32; 37]. In contrast, a functionally feedforward chain maintains a memory by iteratively passing signals from one mode of activity to the next (Fig. 1; App. A) [32; 37]. Most

Figure 1: Data-constrained models fail to distinguish between mechanistically different sensory integration circuits. **a.** Recovery of a line attractor through data-constrained modeling. i). Schematic of integrator network, showing the subsampled neurons (blue), and its interpretation as a set of independent self-excitatory modes. ii). Input signal (_top_) and its integral (_bottom_) as estimated by the network (_green_) and computed exactly (_black_). iii). Example activity traces from the true network (_top_) and an LDS fit to observations of 5% of its neurons (_bottom_). The agreement is excellent. iv). Spectrum of time constants for the data-constrained LDS model (_main figure_) and for the top five time constants of the true circuit (_inset_). Both show a single large time constant, indicating approximate line attractor dynamics, though the data-constrained model underestimates that of the true network. v-vi). Flow field in the space of the top two principal components of activity for the LDS model (v) and line attractor network (vi). Shading indicates the magnitude of the flow, while arrows indicate its direction. Observed activity is shown by dots colored by their time. The learned flow field shows good qualitative agreement with the ground truth; both networks have a slow line along which the observed activity is driven. **b**. As in **a**, but for a functionally-feedforward integrator circuit. As diagrammed in (i), this network can be thought of as a set of non-self-exciting modes which are connected in a feedforward chain. Though this network solves the integration task (ii) and the LDS fit is good (iii), the LDS identifies a single long time constant that is not present in the true dynamics (iv). The learned (v) and ground-truth (vi) flow fields correspondingly do not match, with the activity lying off the slow line of the true dynamics. See Appendix G for detailed experimental methods.

simply, a literal feedforward chain has connectivity \(J_{ij}=_{i+1,j}\). However, one can encode modes in distributed patterns of neural activity rather than single neurons, so that this structure is not obviously apparent in recordings (see App. A for details). Such networks are more robust to mistuning of synaptic strengths than line attractor networks, but they can only sustain a memory over \(( D)\) time. Importantly, the dynamics of such a network are highly non-normal; the recurrent connectivity matrix \(J\) has all eigenvalues equal to zero. Here, inspired by , we add skip connections from each mode to the last mode in the chain (Fig. 1; App. A). This guarantees that, like the line attractor network, the activity produced by the functionally feedforward network is approximately low-dimensional.

Given the simplicity and ubiquity of these models, we first asked whether data-constrained modeling could robustly distinguish between them. We constructed a model sensory integration task, which networks of both architectures could effectively solve (Fig. 1). Using standard variational inference methods [13; 18], we fit recordings of 5% of the neurons from each network with a latent linear dynamical system (LDS), which models the neural activity as a linear projection of a low-dimensional latent RNN  (App. G).1 These models explicitly encode the prior belief that population activity is low-dimensional. In this case, we used 5 latent dimensions.

Though the data-constrained models do an excellent job of capturing the activity recorded from both the line attractor and the feedforward chain, analyzing the latent dynamics matrices reveals that both networks are interpreted as approximate line attractors (Fig. 1). In particular, the spectrum of eigenvalues \(_{i}\) of each LDS dynamics matrix induces a spectrum of decay time constants \(_{i}=/|1-_{i}|\) (in continuous time; see App. A and B.3) [13; 27]. Previous works have identified networks with large gaps between the top two timescales as approximate line attractors [13; 27]. As a simple metric, Nair et al.  defined a "line attractor score" \(_{2}(_{1}/_{2})\), and interpreted scores greater than \(1\) as indicative of approximate line attractors. The LDS models fitted to these mechanistically different integrator circuits each have a single slow direction, with a line attractor score in excess of 6 (Fig. 1). However, visualising the flow fields of the ground truth and data-constrained models shows that the dynamics of the line attractor are qualitatively recovered well, while the model fit to recordings of the feedforward chain shows a strong mismatch as it discovers a spurious line attractor (Fig. 1). Therefore, data-driven modeling fails to distinguish circuit hypotheses for this simple task.

An intuitive explanation for why the data-driven model fails to mechanistically reproduce the functionally-feedforward chain is immediate: if the single-unit time constants are fixed and the data-constrained model has fewer neurons, it cannot realize a feedforward chain with sufficiently long memory [32; 37]. The only way to manufacture long memory timescales with a small number of latent neurons is through large eigenvalues. This is potentially a fundamental obstacle to the ability of latent space models to recover neural mechanisms; we will return to this point in the Discussion.

## 3 A tractable model setting: noise-driven linear networks

Motivated by the observations of the previous section, we now seek a setting in which we can analytically study the structure of the student RNN's weight matrix. Whereas in SS2 we assumed the teacher networks were driven by a known low-dimensional signal, here we consider the case in which the teacher and student are driven by isotropic Gaussian noise. This is an optimistic assumption, as it means that the teacher network will explore all directions in its phase space evenly over the course of a single long trial .

Concretely, we consider a teacher-student setup in which both networks are rate-based linear RNNs driven by isotropic Gaussian noise, or, equivalently, their activity evolves according to multivariate Ornstein-Uhlenbeck (OU) processes . The teacher has \(D\) neurons and a recurrent weight matrix \(B\), such that the dynamics of its firing rate vector \((t)^{D}\) is

\[}=-+B+(t)\]

where \((t)\) is white Gaussian noise. The student's dynamics are identical, except that it has \(d\) neurons, recurrent weights \(A\), and driving noise \((t)\), such that its rate \((t)^{d}\) evolves as

\[}=-+A+(t).\]

Then, the task is to estimate the student's dynamics matrix \(A\) given access only to partial observations of the teacher's activity. For simplicity, we assume that we observe the first \(d\) neurons of the teacher network for time \(T\), i.e., we observe

\[^{}(t)=P(t) t[0,T]  P=(I_{d}, 0_{d(D-d)}).\]

Assuming an isotropic Gaussian prior \(A_{ij}_{}(0,1/( T))\) scaled such that the long-time limit is well-defined, we show in Appendix B that the maximum _a posteriori_ (MAP) estimate of \(A\) can be computed explicitly in terms of empirical covariances of \(^{}(t)\). To make the problem analytically tractable, we focus on the limit \(T\), where these covariances can be computed using classical results on stationary states of OU processes . We assume that the eigenvalues of the teacher's weight matrix \(B\) have real part strictly less than one, such that it admits a stable stationary state with covariance \(S=_{t}[(t)(t)^{}]\). Then, in the limit of a long observation window \(T\), the MAP estimate of the student's dynamics matrix can be written in terms of the stationary covariance \(S\) as (App. B)

\[_{}=PBSP^{}(PSP^{}+ I_{d})^{-1}.\]

This result is stated in continuous time; we also give the corresponding result for discretized dynamics in Appendix B. In the fully-observed case, the zero-ridge limit of the MAP recovers the teacher dynamics matrix, i.e., \(_{ 0}_{}|_{d=D}=B\). The stability condition means that we can consider at best approximate line attractors with arbitrarily large but not infinite time constants, but this is not a substantial limitation .

To determine when this data-driven modeling approach recovers the mechanistic structure of the teacher, our task is then to analyze the spectrum of \(_{}\) for various choices of \(B\), as for linear networks the eigenspectrum fully determines the (approximate) attractor structure . Concretely, letting \(_{i}\) and \(_{i}\) be the eigenvalues of the teacher and student dynamics matrices, respectively, we want to compare the resulting spectra of timescales \(_{i}=/|1-_{i}|\) and \(_{i}=/|1-_{i}|\). We are primarily interested in whether the existence or non-existence of slow timescales can be accurately recovered.

### Normal dynamics

We begin by considering teacher networks with normal connectivity matrices (\(BB^{}=B^{}B\)). This includes attractor networks like the idealized line attractor, which have symmetric connectivity (\(B=B^{}\)), and when driven by noise have an equilibrium stationary state . As such matrices

Figure 2: Partial observation of symmetric teacher networks does not lead to spurious attractor dynamics in a data-constrained student network. **a.** Ground truth teacher (red) and learned student (blue) dynamics matrix eigenvalues. (i),(ii): symmetric teacher without attractor structure. (iii),(iv): symmetric teacher that is an approximate line attractor. (i),(iii): for infinite observation time. (ii),(iv): for a finite observation time window. **b.** Flow fields of learned (student) and ground truth (teacher) networks for a finite observation window. (i),(ii): symmetric teacher without attractor structure. (iii),(iv): symmetric teacher that is an approximate line attractor. All plots correspond to 5% partial observation. See Appendix G for detailed experimental methods.

have orthogonal eigenspaces, the dynamics of a normal teacher network can be viewed as a set of non-interacting modes with decay timescales determined by the real parts of the eigenvalues (App. A).

For such teachers, we show in Appendix C that partial observation does not lead to overestimation of timescales under MAP inference. Ordering the eigenvalues of \(B\) in descending order of their real parts as \(1>(_{1})(_{2})(_{D})\), the eigenvalues \(_{i}\) of the student's dynamics matrix \(_{}\) satisfy \((_{1})(_{i})(_{D})\) for all \(1 i d\). However, this positive recovery result does not exclude the possibility that the spectrum of the student's dynamics matrix will have qualitatively distinct gap structure, which would lead to incorrect inference of approximate attractor mechanisms.

In the special case of an ideal line attractor, this does not happen: if the teacher is a symmetric approximate line attractor, then the student will be as well. Concretely, suppose that \(B\) is symmetric, with eigenvalues satisfying \(_{1}=1-\), \( 1\), and \(_{i} 1\) for \(i 2\), and that the eigenvector \(_{1}\) corresponding to the leading eigenvalue (the direction of the approximate line attractor) is randomly oriented or delocalized. Then, the eigenvalues of the student dynamics matrix satisfy \(_{1}_{1}-( D/d)\) and \(_{2}_{2}\) (App. C.3). This implies that approximate line attractors can be recovered even under heavy partial observation so long as the deviation \(\) of the teacher dynamics from a perfect line attractor is small. In Figure 2, we illustrate this successful recovery, and show that it is not qualitatively affected even if the observation time is finite. This successful recovery is consistent with what we found in the driven setting in Figure 1.

### Non-normal dynamics: Feedforward amplification

Our results for normal teacher dynamics in SS3.1 show that the student can correctly recover line attractor dynamics, matching our motivating observation in Figure 1. However, we recall that we found that a non-normal network performing integration through feedforward amplification was incorrectly recognized as also being a line attractor. While it is challenging to analyze general non-normal teacher matrices in the noise-driven setting , we can show that this mismatch again emerges for feedforward chains. In particular, we show in Appendix D that the dynamics of a student of fixed size approach that of a line attractor as teacher size increases. Assume that the teacher is a perfect feedforward chain with connectivity \(B_{ij}=_{i+1,j}\). Then, as \(D\) for fixed \(d\), the student dynamics matrix \(_{}\) in the limit of long observation time and vanishing regularization approaches \(_{i+1,j}+_{id}_{ij}\), hence its leading eigenvalue approaches \(1\), while the others tend to zero (App. D).

As illustrated in Figure 2, the qualitative conclusion that partial observation leads to timescale overestimation does not change even when the observation time is finite. We remark that the fact that the student becomes closer and closer to a line attractor as \(D\) increases is consistent with the intuitive argument given at the end of Section 2: if the number of observed neurons is fixed and small, the only way for the student network to capture the long integration window of the feedforward chain is through tuning its eigenvalues to create long timescales. In Figures 3 and G.3, we substantiate this intuition by showing how the estimated timescales depend on the size of the teacher network relative to the student.

Figure 3: Heavily subsampling a feedforward chain leads to line-attractor-like student dynamics. **a.** Line attractor score as a function of subsampling fraction \(d/D\) for teacher networks of varying sizes \(D\). **b.** Real parts of the top two eigenvalues of a \(d=25\) student’s dynamics matrix for varying teacher network size \(D\). **c.** As in **b.**, but showing the time constants corresponding to the top two eigenvalues. Beyond a threshold value of \(D\), the separation increases rapidly. Thus, the student shows two mechanistic mismatches: First, it learns a dynamics matrix with non-vanishing eigenvalues. Second, at sufficiently low subsampling fraction the top two eigenvalues are separated by a substantial gap, yielding line-attractor-like dynamics. See Appendix G for detailed experimental methods.

### Low-rank non-normal dynamics

As a second neuroscience-inspired example of non-normal teacher dynamics, we consider low-rank connectivity. In recent years, low-rank RNNs have emerged as popular models for cortical dynamics [15; 16; 25; 49; 50]. Importantly for our purposes, they yield low-dimensional population activity, and hence are again a relatively ideal scenario for data-constrained modeling under partial observation [7; 50]. However, we find that connectivity that is both non-normal and low-rank can also give rise to severe timescale overestimation in the student network.

As a particularly simple example of low-rank teacher dynamics, we consider the case in which \(B=MN^{}\) is rank \(r D\), with \(M,N^{D r}\) having null overlap \(M^{}N=_{r r}\) and orthogonal columns \(M^{}M=N^{}N=^{2}I_{r}\). Then, \(B\) is a non-normal matrix with all-zero eigenvalues. When \( 1\), the stationary covariance \(S\) of the teacher network's activity will have precisely \(r\) large eigenvalues of order \(^{4}\), separated from a bulk of eigenvalues that are of \((1)\) with respect to \(\) (App. E). In this large-\(\) regime where the teacher's activity is approximately low-dimensional, the student's learned dynamics matrix has \(r\) eigenvalues approaching 1, with the rest approaching zero (App. E). Therefore, the student learns an \(r\)-dimensional hyperplane attractor. Importantly, this can occur when \(^{2}\) is chosen such that \(B\) has order-1 elements. We show how this effect depends on subsampling fraction in G.4.

In simulations, we observe a finite observation time effect whereby only \(r-1\) of the learned eigenvalues are near \(1\) when process noise is small (Fig. G.1). Consequently, fitting a student network to a non-normal teacher with null overlap connectivity of rank \(r\) as described above can result in the spurious discovery of approximate \((r-1)\)-dimensional hyperplane attractors. We illustrate this explicitly for the cases \(r=2\) and \(r=3\), where observing only \(5\%\) of the neurons in the teacher network leads to the spurious discovery of approximate line attractor and plane attractor dynamics, respectively, despite nearly perfectly recapitulating the observed activity (Fig. 4). Consistent with these observations, we show that latent LDS models fit to the same teacher activity via more sophisticated variational inference methods also learn a few vastly enlarged timescales (Fig. G.5).

## 4 Mismatched attractor structure in data-constrained nonlinear networks

Though the linear networks studied in SS3 are analytically tractable, they are of course inherently limited in the types of attractor dynamics they can display. We therefore asked which qualitative insights from the linear setting carry over to nonlinear networks where one allows for a nonlinear

Figure 4: Spurious slow directions in data-constrained student models for low-rank teacher dynamics. **a.** Learning from a rank-2 teacher. i). Schematic of teacher weights. ii). Ground truth teacher (red) and learned student (blue) dynamics matrix eigenvalues at 5% subsampling. Note the presence of a single learned outlier eigenvalue with real part near 1. iii). Activity traces for the teacher (red) and student (blue) networks. iv). Example student network dynamics for 5% and 50% subsampling compared to the ground truth (GT). Here, points along the trajectory are colored by their time. The student dynamics rapidly converge to a line and then decay slowly towards the origin, consistent with the outlier eigenvalue observed in (ii). **b.** As in **a**, but for a rank-3 teacher network. Correspondingly, the student learns two outlier eigenvalues, and two slow directions. See Appendix G for detailed experimental methods.

firing rate transfer function \(\). That is, we again consider a student-teacher setup, but now the teacher and student dynamics are \(}=-+B()+(t)\) and \(}=-+A()+(t)\), respectively (App. B). Our focus is again on low-rank networks, both for their usage as models for cortical processing and for the fact that their approximately low-dimensional activity makes them a natural candidate for data-driven modeling under partial observation [15; 16; 49].

While it is less straightforward to relate attractor dynamics to the eigenspectrum of \(B\) in the nonlinear setting, one can still use spectral information to gain insight into the dynamics near the trivial fixed point at the origin. Specializing to \((z)=(z)\), the Jacobian of the teacher dynamics at the origin is simply \(-I_{D}+B\), and that of the student is analogously \(-I_{d}+A\). Therefore, connectivity matrix eigenvalues of real part greater than \(1\) would imply that the fixed point at the origin is unstable, and thus the network must support other dynamical behavior (e.g, other stable fixed points, limit cycles, and/or chaos). In the linear case, eigenvalues of real part greater than \(1\) were never spuriously discovered, as that would yield exponentially divergent activity. However, with a saturating nonlinearity, this extreme eigenvalue overestimation is no longer pathological. Indeed, when we infer the weights of a student network using MAP estimation, we find that at small subsampling fractions the student can learn eigenvalues of real part greater than one from a teacher with no such eigenvalues if the teacher connectivity is non-normal. Strikingly, this can lead to the discovery of spurious limit cycles (Fig. 5a) and fixed points (Fig. G.6).

At this point, one might ask whether the eigenvalue overestimation phenomenon we have observed is an artefact of the estimation methods (thus far, MAP and LDS variational inference) on which we have focused. The conceptual argument given at the end of SS2 suggests that this should hold more broadly for low-dimensional student networks learning from partial observations of high-dimensional teachers, but this is a heuristic argument, not a rigorous test. We therefore applied several other commonly-used inference methods [51; 14; 52] to fit student dynamics in the low-rank nonlinear teacher setting. All of the methods produced mismatched attractor structure, with many showing a propensity to overestimate eigenvalues, yielding spurious limit cycles (Fig. 5). We show that these effects persist for more general teacher weight matrices and for student networks with additional hidden units to account for unobserved neurons in Fig. G.2.

## 5 Discussion

In this paper, we have shown partial observation can lead data-constrained models to incorrectly identify the mechanistic basis for slow recorded neural dynamics. We found that, while attractor-like networks can be faithfully recovered even when only a small fraction of neurons are recorded, data-constrained models can learn spurious attractor structure from non-normal transient dynamics.

As noted in SS2, an intuitive explanation of our results for linear networks is that low-dimensional dynamical systems are limited in the longest timescales they could generate through functionally feedforward integration, and thus are inherently biased towards line-attractor-like mechanisms when fit to observations of slow dynamics. Though our focus has been on partial observation as a driver for this dimensional restriction, most approaches to data-constrained modeling with latent dynamics explicitly bias model selection towards smaller latent spaces. In particular, it is standard to select the smallest latent space dimension that captures more than a certain threshold fraction of the variance in the data [13; 18]. This will necessarily favor approximate-attractor-like solutions. Indeed, if one applied such a model selection procedure to the integrator models studied in Figure 1, one would select at most a two-dimensional latent space (see Figure G.8), and thus fall victim to the failure mode noted there. This bias in model selection procedures illustrates a wider issue: benchmarking and model selection based on explained variance for a restricted set of measured dynamics alone are not necessarily sufficient to diagnose mechanistic mismatches [23; 53]. It highlights a tension between the desire to recapitulate mechanism and our intuitive conception of low dimensionality as a signature of model parsimony.

Here, we have focused on the setting in which one measures dynamics over a single trial for inputs that are either fully known or white noise. Previous works have shown how failure to account for unobserved inputs can lead to incorrect eigenvalue estimation . Moreover, most previously-proposed methods to disentangle input-driven versus autonomous dynamics require repeatable trial structure [10; 19; 54]. Our work focuses only on the effects of unobserved neurons, and does not attempt to address this additional source of mechanistic mismatch. Observation of a network under a restricted set of input conditions poses a particularly striking challenge if it has a spectrum of heterogeneous integration timescales. If inputs drive activity along only a subset of dimensions, it is easy to imagine how a heterogeneous spectrum of time constants could be reductively interpreted as low-dimensional attractor structure . When studying circuits whose upstream inputs are not well-understood dynamically, inferences about circuit-intrinsic attractor structure become even more tenuous.

As our work shows that data-constrained models can fail to correctly distinguish between mechanistically different hypotheses for the circuit basis of slow dynamics, an important question is how one should validate putative attractor structure. Though we do not address this issue in the present work, the obvious candidate for conclusive validation of attractor dynamics is of course direct experimental perturbation of neural activity. Daie, Svoboda, and colleagues have identified feedforward amplification (in lieu of line-attractor-like dynamics) in anterior lateral motor cortex using the correlation structure of responses to optogenetic perturbations . O'Shea, Duncker, and colleagues have used targeted optogenetic perturbations to interrogate putative low-dimensional dynamics in primate motor cortex . There, they show that data-constrained models with unconstrained weight matrices do not readily predict perturbation responses, while those with weight matrices constrained to be low-rank capture the fast recovery of the dynamics to a low-dimensional subspace. After the completion of our work, Vinograd et al.  have begun to interrogate putative line attractor dynamics in hypothalamus using similar perturbations. An important question for future work will be to determine how specifically targeted a patterned optogenetic perturbation must be in order to distinguish between the line attractor and functionally-feedforward integrator networks studied here. Another important question is whether the network is a _local_ attractor structure, or whether the network is a _local_ attractor structure.

Figure 5: Eigenvalue overestimation leads to spurious limit cycle discovery across diverse inference methods. **a.** Learning from a noise-driven teacher with low-rank non-normal connectivity using MAP estimation. i). Ground truth teacher (red) and learned student (blue) dynamics matrix eigenvalues at 10% subsampling. Note the conjugate pair of learned eigenvalues with real part greater than 1. ii). Activity traces for the teacher (red) and student (blue) networks at 10% subsampling. iii). Example student network dynamics for 10% and 50% subsampling compared to the ground truth (GT). **b.** As in **a**, but for the “Convex Optimization of Recurrent Neural Networks (CORNN)” algorithm proposed by . Since CORNN was proposed for leaky-rate (as opposed to leaky-current) dynamics, we modify the student and teacher dynamics accordingly. A spurious limit cycle is fit at 5% subsampling. **c.** As in **a**, but using backpropagation through time (BPTT). **d.** As in **a**, but for the recursive-least-squares based FORCE algorithm . See Appendix G for detailed numerical methods.

question is how to relate patterned stimuli _in silico_ and _in vivo_, particularly for latent variable models where a possibly ill-posed inversion of the latent state to observed neuron mapping would be required.

Finally, we remark that our work relates to a broader question of inference for partially-observed dynamical systems. There is a substantial literature on performance guarantees for parameter estimation for linear systems, which largely focuses on predictive accuracy rather than qualitative features . There are also a host of methods which leverage delay embeddings; in addition to predictive accuracy, these methods prioritize accurately inferring the dimensionality and topological structure of an underlying system . However, such methods are "equation-free", and thus are not ideal for identifying how dynamical variables are coupled . Consequently, such methods might not be suitable for distinguishing between mechanistically distinct circuit hypotheses that generate similarly low dimensional neural activity. Indeed, delay embeddings do not appear to distinguish between the two integrator circuits studied here (Fig. G.7). We leave a more detailed investigation of delay embedding-based approaches for future work.