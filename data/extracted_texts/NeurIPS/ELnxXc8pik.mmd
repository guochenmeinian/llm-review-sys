# Hierarchy-Agnostic Unsupervised Segmentation:

Parsing Semantic Image Structure

Simone Rossetti\({}^{1,2}\)   Fiora Pirri\({}^{1,2}\)

\({}^{1}\)DIAG, Sapienza University of Rome  \({}^{2}\)DeepPlants

{rossetti,pirrij@diag.uniroma1.it

{simone,fiora}@deepplants.com

###### Abstract

Unsupervised semantic segmentation aims to discover groupings within images, capturing objects' view-invariance without external supervision. Moreover, this task is inherently ambiguous due to the varying levels of semantic granularity. Existing methods often bypass this ambiguity using dataset-specific priors. In our research, we address this ambiguity head-on and provide a universal tool for pixel-level semantic parsing of images guided by the latent representations encoded in self-supervised models. We introduce a novel algebraic approach that recursively decomposes an image into nested subgraphs, dynamically estimating their count and ensuring clear separation. The innovative approach identifies scene-specific primitives and constructs a hierarchy-agnostic tree of semantic regions from the image pixels. The model captures fine and coarse semantic details, producing a nuanced and unbiased segmentation. We present a new metric for estimating the quality of the semantic segmentation of discovered elements on different levels of the hierarchy. The metric validates the intrinsic nature of the compositional relations among parts, objects, and scenes in a hierarchy-agnostic domain. Our results prove the power of this methodology, uncovering semantic regions without prior definitions and scaling effectively across various datasets. This robust framework for unsupervised image segmentation proves more accurate semantic hierarchical relationships between scene elements than traditional algorithms. The experiments underscore its potential for broad applicability in image analysis tasks, showcasing its ability to deliver a detailed and unbiased segmentation that surpasses existing unsupervised methods.

## 1 Introduction

The advancement of image segmentation has recently taken significant steps forward. On the one hand, the foundation models are trained on increasingly large datasets, such as CLIPseg  (CLIP ), SAM , and SEEM , supervised by text and human prompts . On the other hand, there is a rising growth of unsupervised segmentation models. Unsupervised segmentation explores the feature hierarchy by leveraging self-supervised contrastive learning, as in SmooSeg , U2Seg , CUTLer , CuVLER , STEGO , ACSeg, FreeSolo , HSG , TransFgu , DeepCut , and others . Unsupervised models discover and localize image categories with no annotation aid and evaluate the quality of the pseudo-masks they predict on the datasets corpora used for testing, such as COCO-Stuff  and Cityscapes . Despite exploring human perception more closely than the foundation models, they still rely on the linguistic and conceptual relations between the images and their annotations.

Curated datasets, such as ImageNet , PascalVOC , or MSCOCO , show an extraordinary number of objects with all their components and particulars not annotated either at the image levelor densely. Why annotate this and not that? Annotation prejudice creates a bias towards a subset of the scene. Unsupervised learning, in contrast, has the potential to generate richer representations that are not restrained by annotation decisions. Without juggling annotations, unsupervised features (e.g. ) nearly mirror visual perception discovering scene parts and details; indeed, feature cues live in nested context levels and are not necessarily verbalisable [76; 66], as opposed to the Gestalt holistic view .

Following previous research [44; 19; 3; 94], our key idea is that the natural hierarchical structure of visual scenes is an essential attribute that we can actively pursue in unsupervised segmentation. We approach unsupervised semantic segmentation as an unsupervised pixel-wise feature learning problem, discretising the hierarchical semantic knowledge yielded by self-supervised learning. Our approach makes no assumption about the number of semantic granularity levels and the number of partitions in each level as in . We generate robust hierarchical segmentation for every image, solely relying on hierarchical clustering in feature space, see Figure 1. This new method achieves unsupervised segmentation by leveraging relationships between concepts hidden in the latent space of self-supervised models, across multiple levels of semantic granularity.

We propose a simple algebraic methodology based on a vast literature [20; 6; 61; 81; 75; 91], that unsupervisedly segments the scene parts. The method guarantees the construction of natural, scene-dependent classes of primitives , which can be easily used in unsupervised segmentation without surrendering to their a priori definitions. Our contributions are:

1. We introduce a deep recursive spectral clustering that maximises an unbiased semantic similarity measure at multiple granularity levels. Exposing our method to any generic group of images, we show that it results in hierarchical unsupervised semantic segmentation.

2. We introduce new metrics for estimating the quality of the semantic segmentation of the elements discovered on the different levels of the hierarchy, called _Normalised Multigranular Covering_ (\(\)) and _Normalised Hierarchical Covering_ (\(\)).

3. We integrate the method into various self-supervised learning models to enhance its flexibility for benchmarking purposes, making it suitable as a downstream task through unsupervised segmentation by inferring all scene parts in the images of any given dataset.

## 2 Related works

**Self-supervised representation learning for unsupervised segmentation.** Self-supervised learning (SSL) is about learning representations of real-world data without human supervision [14; 36; 11;

Figure 1: **Hierarchy-agnostic unsupervised segmentation.** Finer image parts are generated via over-clustering, each region colour-coded randomly. Our algorithm recursively partitions these parts, grouping them into coarser regions across multiple levels of granularity. The resulting tree represents an unsupervised hierarchical semantic segmentation. The arrangement of regions in the tree reflects their semantic distance, which is colour-coded in the heat map shown on the right.

64]. Contrastive learning (CL) [18; 63] is the most prominent method in SSL, maximising feature similarities between an image and its affine transformations while minimising similarity between randomly sampled images. Most unsupervised segmentation methods use learning representations to feed self-supervised features to graphs for clustering [58; 88; 87; 3]. Alternatively, features are used for building distillation strategies [32; 96; 51], or for designing inductive priors forcing some consistency property [51; 17; 73]. SSL representations implicitly define a distance metric in the latent space, though learning a metric space is not their primary objective.

**Unsupervised semantic segmentation.** Unsupervised semantic segmentation labels pixels that belong to specific elements in the scene, grouping all objects of the same semantic type under a single label, without supervision.

The earlier approaches, such as [41; 47; 17; 86; 77; 33] had not yet available powerful SSL features like , though used CL principles. PiCie  used equivariance to transformations; IIC  resorted to invariant information clustering, maximising mutual information, to find commonality in objects, and analogously did InfoSeg . CLD  integrated local clustering into contrastive learning;  used saliency to find the image foreground and guide CL of pixel embedding.

The availability of high-level unsupervised features triggered new strategies. DINO self distillation  inspired both STEGO  and SmooSeg . STEGO trains a segmentation head by distilling the feature correspondences to form compact clusters. SmooSeg uses the smooth prior over semantically coherent regions as a supervision cue to generate semantic maps. However, many methods suffer from the background problem and elaborate on DINO's attention to obtaining foreground objects, such as FreeSolo  and . Also, TransFGU  focuses on a top-down object-centric approach to generate pixel pseudo labels according to GradCAM . Spectral clustering, as introduced to machine learning by , is considered in [88; 58; 87; 52; 68]. In particular, CutLER  applies NCut  iteratively to a masked similarity matrix to discover foreground elements of the scene. ACSeg  uses the affinity matrix to discover concept similarities. SemPart  considers the foreground a single object saliency mask and applies graph regularisation. In , patch-level contrasting learning leverages global hidden positives to learn semantic consistency.

As grouping is the common denominator, all the mentioned methods suffer from deciding the correct level of granularity. Some methods resort to an _object-centric_ bias, such as [77; 93], CAMs , hinting self-attention [96; 79], fixed-size flat image partitioning . Others, such as , and [46; 73], resort to a _scene-centric_ prior assumption.

**Unsupervised parts discovering.** Despite hierarchically discovering parts has a long history in computer vision, it has only recently recovered and connected to unsupervised part segmentation. The first input came from , analysing the hierarchical nature of deep learning features. One of the first approaches was SCOPS  using dense self-supervised contrastive loss to discover foreground parts of single objects. In , the authors introduce self-supervised primitive hierarchical grouping. They leverage a boundary strength map (OWT-UCM ) on relatively few images to learn from a large data set. The approach formulates an ultrametric map defining a region hierarchy. Similarly, HSG  leverages region boundaries to obtain multi-level segmentation. HSG is unsupervisedly trained from scratch, performing pixel grouping with dense contrastive learning across different granularity levels. In , \(K\) fixed parts are discovered via an average part descriptor and by forcing consistency using the equivariance of affine and photometric transformations. Leopart  follows DINO self-distillation to classify pixels, obtaining detailed scene parts, further clustered via community detection. Finally, DeepCut  approaches unsupervised semantic part segmentation using both spectral clustering with NCut and GNN convolution, constructing a patch-wise correlation  matrix from DINO features.

## 3 Method

We present a flexible, unsupervised method for segmenting natural images, automatically creating data structures that organize pixels by their semantic coherence across multiple levels of detail without relying on predefined hierarchies or labels. This method is designed to segment images from coarse regions to finer parts, providing an intuitive representation of visual content; see Figure 1.

For instance, consider an urban street view. At a high level, it consists of elements such as the _sky_, a _road_, _buildings_, and _vehicles_. Among the vehicles, there might be a _bus_ or a _car_, which can be further decomposed into parts like the _body shell_, _wheels_, and other visible components.

Our approach segments an image \(I^{3 M N}\) into a hierarchy-agnostic tree \(T\) of semantic regions, with each pixel in the image assigned to a leaf node. Our model is a function \(f:I T\), represented by a deep neural network, which maps an image to its semantic regions. Notably, this is achieved in a fully unsupervised manner; we incorporate mechanisms that guide \(f\) to produce a meaningful decomposition of the image, even without labelled examples.

### Overview of the Approach

Our method discovers similar parts in an image by recursively partitioning a graph constructed from deep feature representations of the image. The key idea is to treat self-supervised models for image processing as _codebooks_ of a lower-dimensional space, with the extracted feature vectors acting as _codes_ that embed semantics of visual concepts.

The primary cue for discovering parts is a deep feature extractor \(\), a neural network pre-trained without supervision on a standard benchmark such as ImageNet. We observe that the alignment of codes leads to semantic similarity across multiple levels of granularity. A higher degree of alignment indicates semantic similarity at finer granularity levels, corresponding to indivisible object parts or _primitives_. Conversely, a lower degree of alignment reflects semantic similarity at coarser granularity levels. By discretizing the density of these alignments, we can discover scene and object parts at various levels of detail.

Let \(v_{i}=[(I)]_{i}^{d}\) be the code associated with pixel location \(i\) in the image. If pixel \(j\) belongs to the same finer part as \(i\), their codes should be similar. Conversely, if they belong to different parts, their codes will diverge. We expect this property to be consistent in each image \(I\) and should not be affected by the particular object instances.

A straightforward approach might be to cluster these codes using algorithms that minimize a distortion metric in the latent space to identify regions of high feature concentration. However, a critical flaw that can arise when using these methods in high-dimensional space is the presence of many local minima in the cost function. This would require multiple restarts of the iterative algorithms to find a suitable solution, which is impractical due to high complexity. To overcome these limitations, we adopt an efficient method to partition the image into similar regions, avoiding the pitfalls of multiple local minima and the need for iterative restarts in high-dimensional space.

Graph construction.We represent the image \(I\) as a weighted undirected graph \(G=(V,E,w)\), where \(V=\{v_{i}\}_{i=1}^{n}\) and \(n=M N\). The weight assigned to each edge \((i,j) E\) is defined by a scaled and shifted cosine similarity between feature vectors \(w_{ij}=w(v_{i},v_{j})\). These weights form the adjacency matrix \(W=[w_{ij}]^{n n}\), the degree matrix \(D=[d_{i}]^{n n}\), where \(d_{i}=_{j}w_{ij}\) and the normalized graph Laplacian \(L=D^{-1/2}(D-W)D^{-1/2}\).

We interpret the edge weights as indicators of the semantic granularity between nodes. Specifically, if \(w_{ij} 1\), pixels \(i\) and \(j\) likely belong to the same fine-grained part (primitive). Conversely, if \(w_{ij} 0\), these pixels are likely to belong to entirely different parts, indicating minimal semantic similarity even at the coarsest level of granularity.

Similarity perturbation.In an ideal scenario, at a specific granularity level, \(k^{}\) distinct connected components emerge in \(G\), resulting in a binary adjacency matrix \(W^{}\{0,1\}^{n n}\) with \(k^{}\) non-zero diagonal blocks -- indicating strong intra-component connectivity and no inter-component connections -- and normalized Laplacian \(L^{}\). However, in practice, the observed adjacency matrix is not discrete. Instead, \(W\) exhibits tightly connected components alongside others with lower connectivity, resulting in a perturbed normalized graph Laplacian \(L\). We regard the primitives of the model as affected by a _small_ symmetric perturbation \(H^{n n}\) incorporating contextual information from coarser levels of semantic granularity, i.e. \(L=L^{}+H\), making the observed adjacency real-valued.

Fortunately, the Davis-Kahan symmetric \(\) theorem  helps us manage perturbations; see also Appendix A. If the eigenvalues of \(L\) exhibit a spectral gap \(\), the corresponding eigenspaces of \(L\) and \(L^{}\) remain close despite the perturbation \(H\). The theorem quantifies this proximity by relating the angle \(\) between the eigenspaces of \(L\) and \(L^{}\), where \(\) is proportional to the norm of \(H\) and inversely proportional to \(\). By selecting the largest gap, we isolate the part of the spectrum closest to the original graph, guessing the true semantic structure at the specific granularity level.

Normalized smoothness measure.We consider a function \(g:V\) that assigns a value \(g(v_{i})\) to each node \(v_{i} V\). Since \(|V|=n\), we identify the function \(g\) with a vector in \(^{n}\). Based on the considerations from  (see also Appendix C), we define the normalized smoothness measure of \(g\) on the graph \(G\) using the functional \(S_{G}:^{n}^{+}\) induced by \(L\) through the form:

\[S_{G}(g)=(D-W)g}{g^{}Dg}=(g(v_{i})-g(v_{j}))^{ 2}w_{ij}}{_{i}g(v_{i})^{2}d_{i}}. \]

We observe that minimizing the functional yields normalized smoothest functions that assign similar values to tightly connected nodes and different values to weakly connected ones while accounting for their importance in the graph -- avoiding trivial solutions for low connectivity nodes. Therefore, if \(g\) is both normalized and smooth with respect to \(G\), then \(g(v_{i})\) is similar to \(g(v_{j})\) whenever \(v_{i}\) is similar to \(v_{j}\), where similarity is quantified by the weight \(w_{ij}\) and adjusted by the node degree \(d_{i}\).

Given these properties, we treat any function \(g\) as a _continuous partition_ function on the graph \(G\) and evaluate its correctness by a _feature density change_ criterion on the data partition, which measures variations in similarity across different regions of the graph.

Recursive partitioning with perturbation stability.We propose a recursive partitioning strategy for discovering semantic parts by progressively dividing the graph, starting from the whole and refining it into tightly connected subgraphs. At each recursion level, we examine the subgraph's granularity, identify perturbations -- contextual variations affecting node connections -- and derive the unperturbed adjacency matrix to reveal finer semantic components. By capturing relationships at multiple levels of detail, this approach yields more nuanced segmentation than methods that partition the entire graph's nodes into a fixed number \(k\) of sets.

We aim to find the smoothest normalized functions that best describe the semantic structure of a subgraph \(G\) at a specific granularity.1 We tackle the minimization of Equation (1) as a standard eigenvalue problem  using the Rayleigh-Ritz quotient form. This yields the orthonormal eigenvectors \(y_{i}\) corresponding to the smallest eigenvalues \(_{i}\) of \(L\), as guaranteed by the Courant-Fischer theorem:

\[y_{i}=_{\|y\|=1,y y_{<i}}y^{}Ly,y_{0}=D^{1/2} ^{n}. \]

The eigenvalues \(_{i}\) -- the values on the right-hand side of the problem above -- with \(0=_{0}_{1}_{n-1} 2\), quantify the normalized smoothness of the functions \(y_{i}\). Since solving the eigenvalue problem has a computational complexity of \(O(n^{3})\), in practice, we limit the computation to the \(k_{max}\) smallest eigenvalues for efficiency. We obtain the spectral gaps \(_{j}=_{j}-_{j-1}>0\) for \(2 j k_{max}-1\) and seek for the \(k\)-th gap giving the tighter \(\) bound, i.e. \(k=_{j}_{j}\).

We select up to \(k\) smoothest normalized functions on \(G\), namely the first \(k\) eigenvectors of \(L\), \(y_{1},,y_{k-1}\) -- we ignore \(y_{0}\) since it is constant. These \(k\) eigenvectors provide orthogonal graph signals based on semantic coherence, with nodes showing similar values in these functions likely belonging to the same semantic part; thus, each signal points to a distinct connected component.

As in , we recover the true semantic structure of the graph considering the matrix \(Y=[y_{1},y_{2},,y_{k-1}]^{n k-1}\). First, we perform \(_{2}\)-normalization of each row in \(Y\), \(X_{ij}=Y_{ij}/(_{j}Y_{ij}^{2})^{1/2}^{n k-1}\) -- the \(i\)-th row of \(X\) represents the normalized feature vector for the \(i\)-th node, which determines the node's membership in a cluster. Then, we take the best membership for each node -- using an algorithm that attempts to minimize distortion in a lower-dimensional space -- finding \(k\) disjoint partitions of the nodes \(V_{1},V_{2},,V_{k}\) such that \(_{i=1}^{k}V_{i}=V\) and \(_{i=1}^{k}V_{i}=\).

We determine \(L^{}\) and estimate the perturbation \(H=L-L^{}\) to compute the \(\) upper bound value.

Each recursion step splits the graph into tighter subgraphs. This process continues until one of the early stopping criteria is met: (1) if a partition is too small (less than \(k_{min}\)), (2) if the eigenvalues exceed a maximum smoothness threshold \(_{max}\), or (3) if the \(\) upper bound value becomes too large (more than \(p_{max}\)), indicating that the current estimate of \(L^{}\) is no longer reliable. These stopping conditions ensure we halt when further partitioning does not yield meaningful semantic components, thus identifying the final set of image parts or _primitives_.

Each recursive partitioning adds structure to the tree \(T\), where nodes specify semantic regions at various levels. The final output is \(T\), with each leaf node capturing a distinct part of the image at an appropriate level of granularity; see Figure 2.

The values \(k_{min}\), \(_{max}\) and \(p_{max}\) are found experimentally for the tested dataset; tables are shown in Section 4 and Appendix D. In Appendix B, we discuss the algorithm's properties and the generated \(T\), and present the complete pseudocode of our method.

### Pre and Post-Processing

Boosting computation.We introduce a preprocessing strategy that condenses the graph, dramatically reducing the algorithm's time and memory requirements by several orders of magnitude while maintaining comparable accuracy. The condensed graph simplifies the original graph into \(m\) nodes by contracting strongly connected components into vertices, where \(m n\).

We assume that the finest semantic content in natural images is inherently limited and cannot exceed the raw pixel statistics. From the input image \(I\) we extract \(m\) regions  leading to an initial undirected condensed graph \(G_{c}=(V_{c},E_{c},)\), where \(V_{c}=\{_{i}\}_{i=1}^{m}\), such that \(_{i=1}^{m}A_{i}=V_{c}\) and \(_{i=1}^{m}A_{i}=\), and the edge weights \((A_{i},A_{j})\) represent the degree of association between regions, defined as \((A_{i},A_{j})=_{u A_{i},v A_{j}}w(u,v)\). We then apply our recursive partitioning algorithm to \(G_{c}\) and its corresponding normalized Laplacian matrix \(L_{c}\). As a result, we obtain a region tree \(T\).

Ablation studies in Section 4.3 compare performances across various overclustering methods.

Boundary Sharpening.Given a predicted region tree \(T\) with \(q\) leaves, \(B_{1},B_{2},,B_{q}\), each embedding a disjoint segment of \(V\), such that \(_{j=1}^{q}B_{j}=V\) and \(_{j=1}^{q}B_{j}=\), we compute the _prototypes_ for the image \(I\). Each prototype is defined as the \(_{2}\)-normalized average of the feature codes in each leaf \(u_{j}=|B_{j}|^{-1}_{v B_{j}}v\). For each pixel, we define a conditional probability distribution over the prototypes using the softmax function with smoothing parameter \(\), namely, \(p_{ij}=v_{i}^{}u_{j}^{-1}/_{k}v_{i}^{ }u_{k}^{-1}\). We arrange the matrix \(P=[p_{ij}]^{(M N) q}\) and sharpen the region boundaries applying a Conditional Random Fields (CRF) , which refine the predicted distribution \(P\) by incorporating dependencies between pixel observations \(I\). This improves the accuracy at the boundary, ensuring sharper and more precise segmentation of leaves.

## 4 Experiments

We benchmark our algorithm on unsupervised _multi-granular_ segmentation using seven major object- and scene-centric datasets and seven hierarchically structured datasets with varying granularity levels for _hierarchy-agnostic_ segmentation. Our evaluation includes an ablation study to assess the contributions of each algorithm component and comparisons across different self-supervised backbone architectures. We only utilize publicly available datasets, SSL model checkpoints without retraining, and validation set ground-truth annotations. CRF is applied only where specified.

Each dataset provides unique characteristics essential for different segmentation challenges. PascalVOC2012  offers a broad range of object categories, making it suitable for general object segmentation tasks. With its high-level division into _things_ and _stuff_, COCO-Stuff  extends the

Figure 2: Qualitative results of our algorithm on PascalVOC2012, COCO-Stuff and Cityscapes datasets. The _Hierarchy_ columns colour-code the pixel semantic hierarchy, and the _Category_ columns are random colour-coded, helping visually discriminate hierarchically close pixels.

MSCOCO  and tests the algorithm in complex scenes with multiple objects. Potsdam and Vaihingen  datasets, focused on aerial scene parsing, are designed for remote sensing and urban planning applications. Cityscapes  is critical for autonomous driving research, providing detailed annotations of urban street scenes. Mapillary Vistats  adds diversity with street scenes from various global environments, testing the algorithm's robustness to different conditions. KITTI-STEP  and KITTI-SS , similar to Cityscapes, extend the evaluation to dynamic urban scenarios with instance detection and object tracking. For fine-grained part segmentation, Pascal-Part , PartImageNet, and PartImageNet-158  offer detailed part annotations, crucial for tasks requiring precise recognition and segmentation of object parts.

These datasets ensure a comprehensive and diverse benchmark for evaluating the performance and robustness of our segmentation algorithm across various contexts, see Figure 2. Further details about datasets are in Appendix D.1, and more quantitative and qualitative results are in Appendices D.3 and D.4, respectively.

To ensure reproducibility, we standardize our experimental setup. Unless otherwise specified, we use the DINOv2-ViT-B14-REG  backbone with parameters \(k_{}=1\), \(p_{}=20\), and \(_{}=0.8\). We apply the spectral method from Ng et al.  with \(m=300\) for superpixel clustering. The recursive partitioning depth is limited at \(10\) levels. Depending on each backbone downsampling factor, input images are resized to extract \(60 60\) codes, except for urban street scenes, where we obtain \(60 120\) codes. Further details in Appendix D.

### Evaluation Metrics

Granularity-agnostic.Following , we aim to evaluate the unbiased overlapping of regions between predicted segmentation and ground truth within each image via the _Normalized Foreground Covering_ (\(\)) metric. However, it is not well-suited for the multi-granular segmentation domain. The metric applies to a single granularity level at a time, failing to account for multiple granularity levels. Furthermore, it disregards the background as a valid semantic instance, leading to an incomplete estimate of segmentation performance.

We propose a novel evaluation metric, the _Normalized Multigranular Covering_ (\(\)), which addresses these limitations evaluating the overlap of regions between the unrolled segments in the region tree \(T\) and all the available ground-truth categorical segments in a semantic map \(S_{gt}\). This metric ensures that both foreground and background instances are considered, providing a more comprehensive and granularity-independent assessment of a semantic segmentation model's performance. We adopt a greedy heuristic that maximises the overlap of the full hierarchy with the ground truth segmentation and compute the average overlap ratio of the matching:

\[(T S_{gt})|}_{R S_{gt}} _{R^{} T}|}{|R R^{}|}. \]

Figure 3: **Comparison of segmentation metrics.** NFCovering evaluates single-level foreground overlap, \(\) extends across multiple granular levels for all categories, and \(\) integrates hierarchical consistency. Coloured arrows indicate category-specific matches.

The \(\) metric evaluates the performance of a hierarchical segmentation model considering how many ground truth objects are recognised at any granularity level and how well they are segmented. A high score indicates a high segmentation coherence between human semantic perception and unsupervised machine one.

Hierarchy-agnostic.We introduce a second accuracy metric, the _Normalized Hierarchical Covering_ (\(\)). \(\) jointly evaluates the segmentation quality and the semantic _hierarchical inclusion_ of the prediction relating to the ground-truth semantic region tree \(T_{gt}\). Hierarchical inclusion is the matching between the nodes of two distinct hierarchies preserving the lineage from the ancestors; this problem is commonly referred to in the literature as the _unordered tree inclusion problem_.

To calculate this metric, we use a greedy heuristic that computes the average overlap ratio of matching regions, weighting each match by the ratio of matched ancestors. The operator \((R)\) returns the ancestors set of the tree node \(R\), and \((R,T)\) returns the nodes set in the predicted tree \(T\) that best match the ancestors of node \(R\):

\[(T T_{gt}) |}_{R T_{gt}}_{R^{} T }|}{|R R^{}|})|}{|(R)|}, \] \[(R,T) _{P(R)}*{arg\,max}_{P^{ } T}|}{|P P^{}|}. \]

The \(\) metric computes the average weighted overlap of regions between the predicted tree \(T\) and the ground-truth tree \(T_{gt}\). The overlap weight measures the proportion of correct ancestorships with respect to the ground truth. Balancing segmentation performance with semantic ancestry consistency provides a granularity- and hierarchy-independent performance assessment. This score quantifies the coherence of segmentation and hierarchical organization of visual concepts between human perception  and unsupervised machine one.

Refer to Figure 3 for a visual insight into the metrics. A more detailed discussion is in Appendix D.2.

### Unsupervised Segmentation

Granularity-Agnostic.We adopt the \(\) metric to benchmark the performance and versatility of our algorithm across different natural image domains. As shown in Tables 1 and 5, our method achieves excellent results in segmenting object-centric images and foreground discovery. Additionally, Table 1 demonstrates our approach's strong performance on scene-centric datasets, such as remote-sensing images and urban street scenes. Table 3 compares our approach to other supervision strategies.2 Our approach achieves segmentation quality comparable to supervised methods and surpasses other supervision strategies by a large gap.

Hierarchy-Agnostic.We further benchmark the hierarchical inclusion quality of the algorithm on available datasets having hierarchical structures at a high level, such as MSCOCO, COCO-Stuff and Cityscapes, and at a low level, such as PascalPart and PartImageNet. We show in Table 2

**Dataset** & \(\) & \(\) & \(\) & \(\) & \(\) \\  _object-centric_ & & & & & \\ PascalVOC2012 & 78.1 & 82.6 & 91.2 & 78.1 & 75.4 & \\ MSCOCO & 55.7 & 93.1 & 85.0 & 78.8 & 49.6 & \\  _scene-centric_ & & & & & \\ COCO-Stuff & 58.7 & 81.1 & 80.3 & 67.3 & 42.1 & \\ Cityscapes & 48.8 & 82.8 & 76.1 & 68.8 & 44.8 & \\ KITTI-STEP & 51.2 & 79.8 & 76.5 & 65.7 & 48.4 & \\ Mapillary Vistas & 47.6 & 78.9 & 72.1 & 66.1 & 42.7 & \\ Putsdam & 58.9 & 83.4 & 83.2 & 65.0 & 56.3 & \\  

Table 1: **Granularity-agnostic.** Evaluation of our algorithm on different datasets using a maximum overlap heuristic for category matching.

**Dataset** & \(\) & \(\) & \(\) & \(\) \\  _whole-centric_ & & & & \\ COCO-Stuff & 59.5 & 75.1 & 53.5 & 42.9 \\ Cityscapes & 53.7 & 78.8 & 51.1 & 43.8 \\ KITTI-STEP & 58.3 & 79.6 & 54.2 & 46.5 \\ Mapillary Vistas & & & & \\  _part-centric_ & & & & \\ Pascal-PartImageNet & 25.8 & 80.0 & 39.5 & 38.8 \\ Part-Imagenet & 55.4 & 79.5 & 65.8 & 65.2 \\ Part-Imagenet-158 & 59.5 & 82.6 & 67.8 & 63.1 \\  

Table 2: **Hierarchy-agnostic.** Evaluation of our algorithm on different datasets using a maximum overlap heuristic for category matching.

the closeness in performance of \(\) with respect to the \(\), demonstrating the ability of the algorithm to capture hierarchical relations among the parts. The lower performance on PascalPart is due to the lower granularity of part annotations compared to PartImageNet, see .

Recent unsupervised semantic segmentation approaches, such as [44; 94], often employ mutual information maximisation between regions at multiple granularity levels. These methods typically utilise hierarchical clustering that groups low-level coherent regions via boundary potentials, such as the Ultrametric Contour Map (OWT-UCM) , of boundaries derived from low-level features like brightness, colour, and texture gradients, as in Structured Edges (SE)  or Pointwise Mutual Information (PMI) . We compare our approach with these methods in Table 4. The results indicate that low-level processes are inappropriate for the hierarchical grouping of high-level (semantic) features. In contrast, our approach excels in this area, suggesting significant room for improvement in the current state of the art. See some hierarchical grouping results in Figure 4.

### Ablation Experiments

Backbone.We evaluate in Table 5 the consistency of our approach according to the latent space induced by different SSL Imagenet pre-trained backbones on the granularity-agnostic task on the

   } & \)} & \)} \\   & \)-OWT-UCM } & 48.4 & 83.0 & 59.0 \\ PMI-OWT-UCM  & 47.0 & 86.5 & 61.3 \\    &  & & & \\
**Ours w/o CRF** & 78.1 & 86.0 & 75.4 \\
**Ours w CRF** & **80.3** & **87.3** & **76.8** \\  \)} &  & & \\
**COCO-Stuff** & mIoU & \((T T_{at})\) & \(\) \\   &  & & & \\  & 30.7 & 43.0 & 32.9 \\ PMI-OWT-UCM  & 27.5 & 43.2 & 23.1 \\   &  & & & \\
**Ours w/o CRF** & 58.7 & 53.5 & 42.1 \\
**Ours w CRF** & **59.9** & **55.6** & **43.9** \\   

Table 4: **Boundary potential methods.** All methods match unsupervised tree segments to best overlapping classes.

Figure 4: **Unsupervised parts discovering examples on PartImageNet.** The left column shows the ground truth part masks. The second to fourth column shows the predicted regions for each tree depth. Heatmap colours encode leavesâ€™ distance in the subtrees.

   } & \)} \\   &  & & & \\  & ResNet-101 & 77.7 & - \\  & VGG-16 & **43.6** \\  & ResNet-101 & **82.7** & - \\   &  & & \\  & ViT-B16 & 69.3 & 45.0 \\  & ResNet-38 & 72.0 & 44.2 \\  & DeIT-S & **74.0** & **50.3** \\   &  & & \\  & ViT-B16 & 37.2 & - \\  & ViT-S16 & 41.7 & 49.2 \\  & ResNet-50 & 41.9 & - \\  & ResNet-50 & 43.5 & - \\  & ResNet-50 & 48.9 & - \\  
**Ours w/o CRF** & ViT-S8 & \(76.2 9.9\) & \(52.1 6.0\) \\  & ViT-B14 & **80.3**\( 1.1\) & **56.5**\( 9.9\) \\   

Table 3: **Semantic segmentation.** Comparison on PascalVOC2012 _val_. Ours match unsupervised masks to best overlapping classes.

PascalVOC2012 _val_ set. The performance gap reflects the representation quality assessed by SSL downstream task benchmarks. Such a result assesses the best model and a complementary downstream task benchmark for SSL. We do not adopt superpixel clustering or CRF but utilise raw patch features as pixel codes.

Parameters \(k_{min}\), \(p_{max}\) and \(_{max}\).In Tables 5(a) to 5(c) we validate the optimal parameters of our algorithm. While \(k_{min}\) choice affects the granularity at lower levels, the \(p_{max}\) and \(_{max}\) choice affects the granularity at higher levels by controlling the stability of the partition.

Overclustering and CRF.We test different over clustering techniques in Table 5(a). Results show higher performances for a simultaneous normalised cut on SSL latent space. When applying CRF with \(=0.1\), we obtain an increase in segmentation accuracy as shown in Tables 3 and 4.

## 5 Discussion

Broader impact.Supervised learning typically relies on highly curated datasets that require expensive and time-consuming manual annotations, especially for complex tasks that demand expert knowledge, such as fine-grained semantic segmentation. As the demand for larger datasets grows and costs rise, increasing interest is in advancing image understanding with minimal or no supervision. Our approach addresses this challenge by streamlining the annotation process, reducing costs, and thereby significantly expanding the data available for supervised model training through the dynamic discovery of semantic regions.

Limitations.While our method shows promising results, it does have limitations. One major drawback is that both segmentation quality and algorithm execution time scale with the input size. Small object parts are especially difficult to detect, particularly when overclustering is used during preprocessing; the results support this. However, a trade-off between accuracy and inference time can be experimentally determined. Moreover, our approach is based on self-supervised learning, which, like all data-driven methods, is susceptible to inherent biases in the data. These biases can influence the resulting latent space of the model, potentially impacting the performance and generalization of our approach.

## 6 Conclusions

We introduce a novel method for unsupervised hierarchical decomposition of natural scenes into primitive components, without requiring prior knowledge of scene granularity. Leveraging deep feature extraction and graph partitioning, our approach constructs a tree of semantic elements from any scene for any dataset. Our core algorithm applies an innovative algebraic approach to deep spectral clustering, addressing blurring from pixel similarity across object parts. Matrix perturbation theory is employed at each tree level, ensuring stable smooth partitions. This framework not only advances unsupervised semantic segmentation but also benchmarks deep neural network representations by evaluating segmentation quality at multiple granularity levels and hierarchical consistency among them. We validate our method with novel metrics, evaluating overlap with ground-truth masks across diverse semantic segmentation datasets and semantic inclusion within hierarchical ones.

Table 6: Superpixel and parameters ablation experiments.