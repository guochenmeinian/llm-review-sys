# DALD: Improving Logits-based Detector without

Logits from Black-box LLMs

 Cong Zeng\({}^{1*}\) Shengkun Tang\({}^{1*}\) Xianjun Yang\({}^{2}\) Yuanzhou Chen\({}^{3}\)

Yiyou Sun\({}^{4}\) Zhiqiang Xu\({}^{1}\) Yao Li\({}^{5}\) Haifeng Chen\({}^{4}\) Wei Cheng\({}^{}\)\({}^{}\) Dongkuan Xu\({}^{6}\)

MBZUAI\({}^{1}\) University of California, Santa Barbara\({}^{2}\)

University of California, Los Angeles\({}^{3}\) NEC Labs America\({}^{4}\)

University of North Carolina, Chapel Hill\({}^{5}\) NC State University\({}^{6}\)

{cong.zeng, shengkun.tang, zhiqiang.xu}@mbzuai.ac.ae xianjunyang@ucsb.edu

{sunyiyou, haifengchen, weicheng}@nec-labs.com dxu27@ncsu.edu

yuanzhouchen@cs.ucla.edu yaoli@ad.unc.edu

Equal contribution. The code and data are released at [https://github.com/cong-zeng/DALD](https://github.com/cong-zeng/DALD)

###### Abstract

The advent of Large Language Models (LLMs) has revolutionized text generation, producing outputs that closely mimic human writing. This blurring of lines between machine- and human-written text presents new challenges in distinguishing one from the other - a task further complicated by the frequent updates and closed nature of leading proprietary LLMs. Traditional logits-based detection methods leverage surrogate models for identifying LLM-generated content when the exact logits are unavailable from black-box LLMs. However, these methods grapple with the misalignment between the distributions of the surrogate and the often undisclosed target models, leading to performance degradation, particularly with the introduction of new, closed-source models. Furthermore, while current methodologies are generally effective when the source model is identified, they falter in scenarios where the model version remains unknown, or the test set comprises outputs from various source models. To address these limitations, we present **D**istribution-**A**ligned **LLMs **D**etection (DALD), an innovative framework that refines the state-of-the-art performance in black-box text detection even without logits from source LLMs. DALD is designed to align the surrogate model's distribution with that of unknown target LLMs, ensuring enhanced detection capability and resilience against rapid model iterations with minimal training investment. By leveraging corpus samples from publicly accessible outputs of advanced models such as ChatGPT, GPT-4, and Claude-3, DALD fine-tunes surrogate models to synchronize with unknown source model distributions effectively. Our approach performs SOTA in black-box settings on different advanced closed-source and open-source models. The versatility of our method enriches widely adopted zero-shot detection frameworks (DetectGPT, DNA-GPT, Fast-DetectGPT) with a _plug-and-play_ enhancement feature. Extensive experiments validate that our methodology reliably secures high detection precision for LLM-generated text and effectively detects text from diverse model origins through a singular detector. Our method is also robust under the revised text attack and non-English texts.

## 1 Introduction

Large language models (LLMs) such as ChatGPT, GPT-4, Llama and Claude-3 have profoundly impacted both industrial and academic domains, reshaping productivity across varioussectors including news reporting, story writing, and academic research. Nevertheless, their misuse also raises concerns, particularly regarding the dissemination of fake news, the proliferation of malicious product reviews, and instances of plagiarism. Instances of AI-synthesized scientific abstracts deluding scientists have raised doubts about the reliability of scientific discourse. Accurate and reliable machine-generated text detection methods are necessary in order to address these issues.

Methods for detecting text generated by Large Language Models are broadly categorized into watermarking, training-based classifiers, and zero-shot detectors. Watermarking methods discreetly embed identifiable markers within the text output, striving to retain the model's linguistic integrity. However, this tactic is implementable solely by the model provider. Training-based classifiers, while effective, are costly and often lack the agility to adapt to new domains or model updates. Our emphasis is on zero-shot detectors that exploit the intrinsic differences between text written by machines and humans, offering the advantage of being generally training-free.

Most zero-shot detectors primarily depend on analyzing model output logits for detection. Notably, DetectGPT operates on probability divergence based upon principles of perturbation theory, while DNA-GPT harnesses reprompting-based probability divergence, and Fast-DetectGPT builds on variations in conditional probability distributions. In scenarios requiring the scrutiny of black-box models, these strategies commonly leverage a surrogate model to approximate the behavior of the target model. However, this approach is doubly flawed: firstly, detection efficacy is inextricably linked to a meticulously tailored surrogate model, with different surrogate models often necessary for accurate detection across various proprietary LLMs; secondly, the fleeting nature of LLM updates renders past surrogates, once effective, obsolete against new versions. For instance, our analysis of the performance of Fast-DetectGPT, using GPT-Neo-2.7B as a surrogate, against freshly updated closed-source models reveals erratic and predominantly diminishing accuracy, as contextualized in Figure 2, with particularly stark declines in performance on iterations like GPT-3.5-1106, highlighting the intrinsic limitation of static surrogate models in adapting to LLM progressions.

In our study, we seek to address the following pivotal inquiries: 1) Can we devise a feasible, cost-effective strategy to refine the probability distribution similarity between the surrogate model and opaque black-box LLMs? 2) Does enhancing the alignment of the surrogate model's probability distribution with that of the target black-box LLM improve detection outcomes for current logits-based detection methods? 3) Is it attainable to develop a universal detection model capable of adapting swiftly to updates across various target LLMs? Addressing the first question, our findings, as demonstrated in Figure 1,

Figure 1: The probability curvatures distribution of the surrogate model (GPT-2), the target model (Llama-3) and the model after alignment (GPT-2_DALD) on human-written passages and machine-generated passages from PubMed dataset.

Figure 2: The performance comparison of a static surrogate model on different target models including ChatGPT (GPT-3.5) and GPT-4. The results are based on Fast-DetectGPT with GPT-Neo-2.7B as the surrogate model.

reveal that our optimized surrogate model (GPT-2_DADD) mirrors the distribution of the target model more closely, in contrast to the original surrogate model's significantly divergent distribution from the target model.

In this paper, we introduce an innovative yet straightforward distribution-aligned framework for black-box LLM detection, dubbed DADD (**D**istribution-**A**ligned **LLM** Detection). Our methodology focuses on synchronizing the surrogate model's distribution with the proprietary target model's distribution. Concretely, we accumulate a compact dataset (<10K samples) from the publicly shared outputs of leading models and subsequently fine-tune our surrogate model using this dataset to better approximate the target model's distribution. We provide the theoretical analysis of the surrogate model distribution alignment in **Appendix 6**. Our methodology builds upon the following observation:

_In logits-based detection methods, a surrogate model that closely mirrors the probability distribution curves of the target black-box LLM is instrumental in enhancing detection accuracy._

We posit that this observed effect stems from the foundational assumptions inherent in logits-based detectors and proceed to examine the ramifications of this postulate in tackling the third question.

To sum up, our contributions are as follows:

* The introduction of DADD, a framework that significantly improves the performance of surrogate models in detecting LLM-generated text generated by both closed-source and open-source models.
* a game-changer in a domain where the source is often unknown.
* The capability of a single detector, enabled by DADD, to accurately identify text from varying sources, democratizing detection across diverse LLM outputs.
* DADD's agility in keeping pace with rapid updates of LLMs, ensuring the latest models fall within its detection capabilities without extensive retraining.

## 2 Related Work

Detection of LLMs-Generated Text.The burgeoning capabilities of advanced large language models (LLMs) underscore the imperative for robust methodologies aimed at detecting these models. Specifically, the detection is to distinguish whether a given text originates from a language model on the condition that the model is known (White-box) or unknown (Black-box). The earlier work focused on feature-based methods, like. While in the era of LLMs, the training-based methods are aroused to counter with LLMs's strong ability to produce high-quality text. They usually involve training a binary classifier using text generated by AI or humans. Besides, zero-shot detectors leverage the inherent statistical feature differences between LLMs and human-generated text without requiring training, including probability curvature (DetectGPT), N-gram divergence (DNA-GPT), and conditional probability curvature (Fast-DetectGPT), the editing distance of the output, and style representations, enhancing their ability to adapt to new data distributions and source models.

Black-box Detection.Given the proprietary nature of the latest LLMs, there is a critical need for effective black-box detection methods. Present techniques falter when direct access to the source model is restricted. The training-based methods, like OpenAI text classifier, GPTZero, G3detector, and GPT-Sentinel usually closely adhere to the specific distributions of text domains and source models during training, thereby lacking generalization ability and robustness on model updates. For zero-shot methods  in the black-box detection settings, they usually rely on a surrogate model for scoring. However, the efficacy of these surrogate models often falls short compared to white-box detection, where access to the source model is available. Moreover, these detection frameworks suffer from diminished accuracy when language models undergo updates, which intrinsically evolve through exposure to varied datasets and human input. This study presents an innovative black-box detection method for LLM-generated text, greatly enhancing surrogate model performance while adeptly accommodating the rapid evolution of LLMs. Our approach diverges from conventional training-intensive techniques by requiring only a minimal dataset for effective training.

## 3 Method

### Task and Settings

Our task is to detect whether the given input passage \(x\) = \([x_{1},...,x_{L}]\) (\(L\) is the sequence length) is produced by an AI model \(f_{}\) or a human, which can be considered as a binary classification task. Typically, there are two different task settings for LLM detection, namely white-box and black-box detection. In the black-box setting, we only have access to the generated text, treating the language model as a "black box" where we input text and receive output without knowing the internal workings or probabilities. In the white-box setting, we have additional information about the model, specifically the output probabilities \(p(x_{l}|x_{[1:l-1]})\) for each token at each position \(l\) in the text. However, in the practical scenario, it is usually difficult to get access to the source model, especially widespread but closed-source models such as ChatGPT, GPT-4 and Claude-3. Therefore, we focus on improving the black-box detection without any access to the source model logits in our setting.

### Logits-based Detection Methods

Logits-based LLM detection methods compute a metric by discrepancy gap hypothesis of humans and machines for classification. For example, based on the observation that the LLM-generated text occupies negative curvature regions of the model's log probability function, DetectGPT proposes to utilize the source model for scoring, which refers to the white-box settings. Following DetectGPT, Fast-DetectGPT replaces the perturbations-based sampling method with conditional probability sampling to accelerate the inference speed and improve the detection performance. Formally, given an input passage \(x\) and the target source model \(p_{}\), Fast-DetectGPT chooses another accessible but open-sourced model \(s_{}\) for scoring, which is called the surrogate model. Together with a sampling model \(q_{}\), Fast-DetectGPT defines the conditional probability \(p(|x)\) as

\[p(|x)=_{l}s_{}(_{l}|x_{<l}), \]

where \(\) is a sample generated by the sampling model \(q_{}\). The detection process typically consists of a three-stage procedure. The sampling step uses a sampling model to generate alternative samples \(\) conditioned on \(x\) based on the next token prediction. Following the sampling step, the process proceeds by calculating the conditional score. The conditional probability can be obtained through a single forward pass of the scoring model, utilizing \(x\) as the input. All the conditional probabilities of samples can be obtained in the same predictive distribution. Finally, compare conditional probabilities of the passage and samples to calculate the curvature.

The Challenge.In black-box settings, selecting the appropriate surrogate model in black-box settings is crucial for achieving accurate and reliable results since there is distribution misalignment

Figure 3: An overview of our proposed DADD framework. Our method aligns the distribution of the surrogate model and the target model.

between the surrogate model and the target model. Poorly chosen surrogate models may lead to bad results and a lack of explainability. Besides, with the closed-source trend of newly published LLM models, the performance can drop significantly when applied to new and advanced models, which can limit their utility and effectiveness. How to obtain a surrogate model that can fit the target models, especially closed-source models is a challenging task in black-box settings.

### Distribution-Aligned Black-Box Detection

Misalignment of Surrogate Model and Target Model.Our method is motivated by the observation that there is a distribution gap between the given surrogate model and the target source model as shown in Figure 1. The goal of our method is to obtain a surrogate model to approach the distribution of the target model by utilizing the texts generated by the target model. To achieve that, we propose a novel and simple framework to train a distribution-aligned surrogate model, which outperforms SOTA black-box methods with a small-size dataset (<10K). The architecture of our method is shown in Figure 3. Our framework consists of two steps in total. The first step is to collect small-size training data generated by the source model from the publicly shared outputs. With the training dataset, we finetune the surrogate model to align the distribution of the source model.

Alignment Data Collection.Given the target model \(f_{tar}\) and surrogate model \(f_{sur}\), in order to align the distribution of the surrogate model and target model, we collect a small-size dataset \(=\{(P_{i},X_{i})\}_{i=1}^{N}\) for a specific target model, referred as alignment dataset, where \(N\) refers to the number of collected samples, \(P_{i}\) is the text for prompting and \(X_{i}\) is the corpus generated by the target model \(f_{tar}\). The model version of the collected data should be exactly the same as the target model, especially for closed-source models such as ChatGPT and GPT-4. For example, if the test data is generated by GPT-4-0613, then all of the texts in the dataset \(\) should also be generated by GPT-4-0613. We utilize the collected dataset \(\) to finetune the surrogate model \(f_{sur}\) to align the distribution with target model \(f_{tar}\).

Distribution-Aligned Surrogate Model Training.As illustrated in Figure 3, our approach expands the scoring step of previous logits-based methods such as Fast-DetectGPT by incorporating an additional surrogate model finetuning step. Given the surrogate model \(f_{sur}\), we construct the Low-Rank Adaptation (LoRA) of surrogate model \(f_{sur}\) for faster and more stable fine-tuning. The LoRA model \(f_{sur+}\) is trained with a collected dataset while the parameter of the original surrogate model \(f_{sur}\) is frozen. With collected dataset \(=\{(P_{i},X_{i})\}_{i=1}^{K_{1}}\) where \(K_{1}\) is the number of samples, we concatenate the prompt and generated text as \(y=[P,X]\). The model \(f_{sur+}\) utilizes the tokenized \(x\) as input and is trained in a self-supervised learning manner. The training objective of our fine-tuning is:

\[_{}_{y=[P,X]}_{l=l(P)+1}^{l(P)+l(X)} p(y_{ l}|y_{<l};sur+), \]

where \(l(X)\) denotes the length of a passage \(X\), and \(y_{l}\) is the next token to be predicted. In order to disable the influence of the prompt, we follow typical instruction tuning to mask the gradient of the prompt. As shown in Figure 1, after training, the misaligned model generates a similar distribution as the target source model, demonstrating the effectiveness of our method. Following that, the distribution-aligned surrogate model can be utilized to compute the logits for downstream decisions.

Under an assumption on the sample complexity of fine-tuning with the above loss function, we theoretically demonstrate the effectiveness of fine-tuning on approximating the target model in the following theorem, using **conditional probability curvature** from Fast-DetectGPT :

**Theorem 1**.: With fine-tuning sample size \(K_{1}\) = \(((/L))\), with probability \(1-\), we have that given a text segment \(X\) with length \(l\), the conditional probability curvature between the two models is bounded by

\[(X,f_{})-(X,f_{}) /3.\]

A detailed proof of this theorem can be found in Appendix 6. Given the hypothesis that there is a positive gap \(\) in conditional probability curvature between human-generated text and machine-generated text, the corresponding gap calculated from the surrogate model will still be significant.

## 4 Experiments

### Setups

Datasets & Evaluation Metric.We follow Fast-DetectGPT using four datasets in the black-box detection evaluation, including Xsum, WritingPrompts, WMT-2016 and PubMedQA. We randomly sample 150 examples of each dataset as human-written texts. Then based on the samples, we prompt the target closed-source models by API to generate the corresponding texts using the 30 tokens of human-written text as the machine-generated text. For text diversity and quality, we employ a temperature of 0.8 which is the same setting in Fast-DetectGPT. For the training dataset, we collect the corpus from the publicly shared outputs of leading models. Following previous works, we compute the accuracy in the area under the receiver operating characteristic (AUROC) to evaluate the performance of all methods. We also provide the area under the precision and recall (AUPR) in Appendix 8.6.

Source & Surrogate Models.To validate our idea in black-box detection, we include the most advanced closed-source LLMs from OpenAI: ChatGPT, GPT-4, and Claude-3 from Anthropic. Since these models keep being updated by their owner company, we use the version GPT-3.5-turbo-0301 for ChatGPT, GPT-4-0613 for GPT-4, and claude-3-opus-20240229 for Claude-3 if not specified. We utilize Llama2-7B as the surrogate model in Table 1. Note that our method can be adapted to any open-source model. Therefore, we provide our results on other surrogate models in Table 3.

Baseline Methods.We consider training-based baselines and zero-shot baselines. We mainly consider three strong baselines for black-box detection: Detect-GPT, DNA-GPT and Fast-DetectGPT. Detect-GPT. Detect-GPT applies T5-3B as a sampling model to generate perturbed texts and utilizes GPT-Neo-2.7B as a surrogate model to compute the probability curvature of perturbed texts. After that, perturbation discrepancy is obtained to determine whether the given text is generated by AI or humans. Fast-DetectGPT uses GPT-J-6B and GPT-Neo-2.7B as the sampling model and surrogate model respectively to compute the conditional probability curvature. Finally, DNA-GPT utilizes GPT-Neo-2.7B as a surrogate model to regenerate the texts for metric computation. Details about other baselines are described in Appendix 7.

Implementation Details.We collect the data of ChatGPT and GPT-4 from WildChat while the data of Claude-3 is generated by calling Claude-3 using the prompts from WildChat. During training, we randomly choose 5K prompts and responses. We applied the instruction tuning to model training to ignore the human-written prompts. For surrogate model training, we apply parameter-efficient fine-tuning (PEFT) via Low-Rank Adaptation (LoRA). We do not tune the hyperparameters carefully. Therefore, more details about training parameters can be found in the Appendix 7. For training time, our method finetunes Llama-2-7B with 5K samples on 4 A6000.

    &  &  &  \\  & **PubMed** & **PubMed** & **XSum** & **Writing** & **PubMed** & **XSum** & **Writing** \\  RoBERTa-base & 0.6298 & 0.5327 & 0.7475 & 0.5186 & 0.4961 & 0.8564 & 0.6707 \\ RoBERTa-large & 0.7168 & 0.5898 & 0.6830 & 0.3800 & 0.5334 & 0.7888 & 0.5178 \\  Likelihood & 0.8924 & 0.8103 & 0.8096 & 0.8528 & 0.8543 & 0.9383 & 0.9542 \\ Entropy & 0.2877 & 0.3036 & 0.4451 & 0.3545 & 0.2940 & 0.3856 & 0.1844 \\ LogRank & 0.8847 & 0.7996 & 0.8041 & 0.8303 & 0.8481 & 0.9420 & 0.9437 \\ LRR & 0.7793 & 0.6860 & 0.7405 & 0.7212 & 0.7468 & 0.8989 & 0.8761 \\ NPR & 0.6917 & 0.5950 & 0.6726 & 0.8192 & 0.6610 & 0.8584 & 0.9167 \\ Detect-GPT & 0.6626 & 0.5806 & 0.6940 & 0.8270 & 0.6562 & 0.8652 & 0.9232 \\ DNA-GPT & 0.7788 & 0.7171 & 0.7100 & 0.7849 & 0.7442 & 0.9410 & 0.9471 \\ Fast-DetectGPT & 0.9309 & 0.8179 & 0.9136 & 0.9521 & 0.8900 & 0.9828 & 0.9445 \\  DADD (Ours) & **0.9853** & **0.9785** & **0.9954** & **0.9980** & **0.9630** & **0.9867** & **0.9981** \\   

Table 1: Detection accuracy comparison on three source models ChatGPT (GPT-3.5-Turbo-0301), GPT-4 (GPT-4-0613) and Claude-3 (claude-3-opus-20240229). Our method surpasses previous methods on all passages generated from different source models.

### Main Results

Black-Box Machine-Generated Text Detection.We compare our method with mainstream black-box LLM detection methods in Table 1. The detection accuracy shows that our method achieves the best performance compared with other methods including Detect-GPT, DNA-GPT and Fast-DetectGPT. Moreover, it is noteworthy that our method obtains more than 99% AUROC on XSum-GPT-4, Writing-GPT-4 and Writing-Claude-3. As shown in Figure 4, the ROC curve for DADD achieves the highest TPR at the same FPR across all three datasets compared with DNA-GPT and Fast-DetectGPT, indicating superior performance. Besides, comparing the performance across different datasets in previous methods, we can observe that the Writing dataset is much easier to detect while PubMed is the hardest. The possible reason is that PubMed is a much more medical-specific dataset while the related corpus is not comprised of surrogate model pre-training. However, our method gains significant improvement upon Fast-DetectGPT. For example, on PubMed-GPT-4, Fast-DetectGPT only obtains 0.8179 AUROC while our method achieves 0.9785, demonstrating the effectiveness of distribution alignment in our method.

### Experimental Analysis

Dataset Size.Our method requires only a small amount of data for training. The model converges quickly with the small-size dataset. To show the training efficiency of our method, we provide the results with various training dataset sizes in Figure 5. For each dataset, we use GPT-4 as the target source model while Llama-2-7B and Llama-3-8B as the surrogate model respectively. With the increasing amount of training data, the performance increases rapidly and stays stable with more data. Moreover, with around 500 (up to 1000) training samples, the performance of our method matches the baseline on both Llama-2 and Llama-3. Besides, our method achieves its best performance and exceeds the baseline with around 2000 training data, which indicates that with only a little training effort, our method can achieve incredibly better performance than the baseline, even more than 99%.

Figure 4: The FPR-TPR curve of different methods on XSum, Writing and PubMed dataset. The results show that our method achieves highest score at low FPR compared with DNA-GPT and Fast-DetectGPT.

Figure 5: AUORC results from our fine-tuned surrogate model with different training dataset size.

Generalizability.Our method aligns with the distribution between the surrogate model and source model with the texts generated by source models. In this section, we further explore the generalizability of our method where we follow several settings: 1) train the surrogate model separately using the data from the corresponding source model, 2) train the model with the single data source and evaluate it on unknown source models (one-for-all), 3) train the model with mixed data sources. We conduct a group of experiments following the settings, as shown in Table 2. We use Llama2-7B as the surrogate model and a total 5K training data in all settings. The dataset with a single data source includes 5K texts from the corresponding source model in the first setting and only GPT-4 in the one-for-all setting while two data sources consist of 2.5K ChatGPT and GPT-4 texts, respectively. Three data sources refer to the combination of 1.3K texts each from ChatGPT, GPT-4 and Claude-3. Surprisingly, the models trained with more data sources achieve better accuracy on GPT-4. However, the performance on PubMed-ChatGPT only shows negligible degradation in one-for-all and mixed data source settings. The superior performance in the one-for-all setting implies the surrogate model trained with DALD can be extended to texts of unknown source models. The results demonstrate the generalizability of our method, leading to training a universal surrogate model for all closed-source models and detecting the machine-generated texts without knowing the model source. Finally, the results in the one-for-all setting imply current closed-source models tend to have a similar distribution. Evaluation results on more unknown source models can be found in Appendix 8.2.

Surrogate Model Selection.Our method can be adapted to any open-source surrogate model. We evaluate our method with different surrogate models including on GPT-NEO-2.7B, Llama2-7B, and Llama3-8B. The experiments are conducted based on Fast-DetectGPT and trained with 5K training data. The results are shown in Table 3 with details in each dataset. In all, compared with the original surrogate models, the surrogate models with DALD obtain much higher accuracy. For example, Llama-2 and Llama-3 only obtain 0.8876 and 0.7764 on PubMed-Claude-3 while their counterparts trained with DALD achieve 0.9424 and 0.9192. The improvement across various surrogate models suggests that our approach is compatible with a range of surrogates, rather than just a particular carefully chosen surrogate model.

Ablation Study.We conduct a group of ablation studies on several datasets, as shown in Table 4. Since our method can be adapted to any previous logits-based methods such as DNA-GPT and Fast-DetectGPT, the ablation study is conducted on top of them to further demonstrate the effectiveness of our method. We choose Llama2-7B as the basic surrogate model for all experiments. We compare the results of the baseline model and the baseline model trained with our framework. In general, our method boosts the performance of the baseline model at different scales. For example, DNA-GPT achieves 0.8947 accuracy score on PubMed-GPT-4 while with the surrogate trained by our

    &  &  &  \\  & **PubMed** & **PubMed** & **XSum** & **Writing** & **PubMed** & **XSum** & **Writing** \\  Baseline & 0.9051 & 0.7995 & 0.7072 & 0.9299 & 0.8877 & 0.9143 & 0.9248 \\ DALD \({}^{}\)(1 source) & **0.9853** & 0.9785 & 0.9954 & 0.9980 & **0.9942** & 0.9994 & **0.9993** \\ DALD \({}^{*}\)(1 source) & 0.9829 & 0.9785 & 0.9954 & 0.9980 & 0.9875 & 0.9993 & 0.9977 \\  DALD \({}^{*}\)(2 sources) & 0.9832 & 0.9803 & **0.9981** & **0.9986** & 0.9875 & 0.9994 & 0.9976 \\ DALD \({}^{*}\)(3 sources) & 0.9827 & **0.9809** & 0.9968 & 0.9985 & 0.9864 & **0.9996** & 0.9982 \\   

Table 2: The results comparison of our method trained with the combination of different data sources. Our method achieves comparable results with more data sources, demonstrating the generalizability of our method and potentially leading to training a universal surrogate model for all closed-source models. \(\): Train the surrogate model separately to each test set. \(*\): Train one surrogate model for all test sets.

    &  \\  & **PubMed** & **XSum** & **Writing** \\  Llama2-7B & 0.8876 & 0.9132 & 0.9243 \\ Llama2-7B(with DALD) & **0.9424** & **0.9773** & **0.9962** \\  Llama3-8B & 0.7764 & 0.9390 & 0.8827 \\ Llama3-8B(with DALD) & **0.9102** & **0.9892** & **0.9967** \\  GPT-Neo-2.7B & 0.8900 & 0.9828 & 0.9445 \\ GPT-Neo-2.7B(with DALD) & **0.8997** & **0.9852** & **0.9515** \\   

Table 3: Results comparison of our method with different surrogate models on Claude-3. The performance improvement with our method on different surrogate models shows that our method can be adapted to any open-source surrogate model.

method, DNA-GPT obtains 0.9879 on PubMed-GPT-4. Moreover, we gain a similar conclusion on Fast-DetectGPT. For instance, on PubMed-GPT-4, the original Fast-DetectGPT only has 0.8179 accuracy. However, after training the surrogate model with our method, it achieves 0.9785 accuracy on PubMed-GPT-4. On the one hand, the improvement in baseline shows the effectiveness of our methods. On the other hand, the improvement across different methods demonstrates that our method can be utilized on any logits-based model to boost their performance on black-box detection.

Non-English Detection.Recent work finds that current AI detectors are biased for non-English languages, which hinders the application of LLM detection for non-English languages. Following, we choose English and German splits of WMT-2016 to test the ability of our method in German. We select 150 instances as human-written texts and use the first 30 tokens to regenerate by calling GPT-4 API as machine-generate texts. During training, we randomly select 1K German samples generated by GPT-4 from WildChat and trained for 5 epochs. As shown in Table 5, our method achieves the highest accuracy (> 99%) on German detection compared with DNA-GPT and Fast-DetectGPT. Due to the plug-and-play property, our method can be further used to eliminate the bias in other AI detectors.

Adversarial Attack.In practical situations, machine-generated corpus is often modified and revised by users or another language model. We consider the modified samples as adversarial samples. Evaluating LLM detectors with adversarial samples is important to real-world applications. Following and, we randomly mask \(r\%\) tokens with 5-word spans in 150 instances from the PubMed dataset regenerated by GPT-4 and apply T5-3B to do the mask-filling task to generate adversarial samples. Experiments with different mask ratios are conducted, specifically \(r\%\{0.1,0.2,0.3,0.4,0.5\}\) and results are shown in Figure 6. We compare the results of DNA-GPT, Fast-DetectGPT and their counterparts with our method. In each group, with the enhancement of our method, the model achieves better results on all mask ratios. Moreover, the models with our method obtain even better accuracy at the highest mask ratio compared with the original models on samples without adversarial attack.

Open-source Model Detection.In addition to detecting texts from closed-source models, we also evaluate our approach on the open-source model Llama-3, Llama-3.1 and Mistral comparing it with DNA-GPT and Fast-DetectGPT. We follow similar settings as closed-source models and fine-tune Llama2-7B as surrogate model. The results are shown in Table 6, where our method works best detection performance on three models compared to other methods, showing the effectiveness of our method on both closed-source and open-source models.

    &  &  &  \\  & **PubMed** & **PubMed** & **XSum** & **Writing** & **PubMed** & **XSum** & **Writing** \\  Detect-GPT & 0.6260 & 0.5291 & 0.6689 & 0.7991 & 0.6472 & 0.9184 & 0.9306 \\ Detect-GPT + DALD & **0.7388** & **0.7034** & **0.8318** & **0.9076** & **0.7550** & **0.9569** & **0.9568** \\  DNA-GPT & 0.9547 & 0.8947 & 0.6980 & 0.8537 & 0.9500 & 0.9359 & 0.9648 \\ DNA-GPT + DALD & **0.9932** & **0.9879** & **0.7524** & **0.9048** & **0.9711** & **0.9391** & **0.9675** \\  Fast-DetectGPT & 0.9309 & 0.8179 & 0.9136 & 0.9521 & 0.8900 & 0.9828 & 0.9445 \\ Fast-DetectGPT + DALD & **0.9853** & **0.9785** & **0.9954** & **0.9980** & **0.9630** & **0.9867** & **0.9981** \\   

Table 4: Ablation study. We report the results comparison of the baseline method and the method with our DALD. The improvement upon all baselines shows the effectiveness of our DALD.

Figure 6: Results comparison on samples with the adversarial attack. The performance improvement with our method on different methods shows that our method is robust to adversarial attacks.

## 5 Conclusion

The rapid evolution of potent Large Language Models (LLMs) underscores the critical necessity for robust black-box detection methods. However, previous methods which rely on surrogate models, suffer from performance degradation, especially with the frequent updates of closed-source models. Our contribution addresses this shortfall by significantly aligning the distribution of the surrogate model and source model. Additionally, we introduce a plug-and-play approach for logits-based detectors, ensuring seamless integration. This method remains versatile across diverse text sources or unknown sources, adapting to the swift evolution of LLMs. In conclusion, our innovations offer compelling solutions to the urgent demand for effective black-box detection methods within the realm of LLM development, bridging critical gaps in current methodologies.

   &  &  &  \\  & **PM** & **XSum** & **Writing** & **PM** & **XSum** & **Writing** & **PM** & **XSum** & **Writing** \\  Fast & 0.9120 & 0.9845 & 0.9906 & 0.8668 & 0.9914 & 0.9958 & 0.6880 & 0.7931 & 0.9211 \\ D\_D\_D\_D & **0.9352** & **0.9995** & **0.9972** & **0.9059** & **1.0000** & **0.9998** & **0.7733** & **0.8822** & **0.9573** \\  

Table 6: Results on open-source models Llama-3, Llama-3.1, and Mistral across three datasets: PubMed (PM), XSum, and Writing. We compare D\_D\_D\_D with Fast-DetectGPT(Fast).