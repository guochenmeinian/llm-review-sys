# TR-BEACON: Shedding Light on Efficient Behavior Discovery in High-Dimensional Spaces with Bayesian Novelty Search over Trust Regions

TR-BEACON: Shedding Light on Efficient Behavior Discovery in High-Dimensional Spaces with Bayesian Novelty Search over Trust Regions

 Wei-Ting Tang

The Ohio State University

tang.1856@osu.edu

Ankush Chakrabarty

Mitsubishi Electric Research Laboratories

achakrabarty@ieee.org

Joel A. Paulson

The Ohio State University

paulson.82@osu.edu

###### Abstract

Novelty search (NS) algorithms automatically discover diverse system behaviors through simulations or experiments, often treating the system as a black box due to unknown input-output relationships. Previously, we introduced BEACON, a sample-efficient NS algorithm that uses probabilistic surrogate models to select inputs likely to produce novel behaviors. In this paper, we present TR-BEACON, a high-dimensional extension of BEACON that mitigates the curse of dimensionality by constructing local probabilistic models over a trust region whose geometry is adapted as information is gathered. Through numerical experiments, we demonstrate that TR-BEACON significantly outperforms state-of-the-art NS methods on high-dimensional problems, including a challenging robot maze navigation task.

## 1 Introduction

Novelty search (NS) refers to a class of methods that, as opposed to minimizing or maximizing over specific objectives, aim to search for diverse system outcomes . Mathematically, we assume our system outcomes are determined by evaluating a function \(:^{D}^{M}\) that maps a \(D\)-dimensional input vector \(^{D}\) to a \(M\)-dimensional outcome space. The inputs typically represent design parameters that we can tweak in our system and the outcomes correspond to important dimensions of variation. In airplane design, \(\) would represent things like the size and shape of the wing while \(()\) represents the collection of all important measurable quantities like the drag coefficient, life, structural integrity, and fuel efficiency. For drug molecules, \(\) could represent different molecular substitution patterns while \(()\) represents the size, effectiveness, and stability of the molecules. NS has demonstrated strong potential for solving so-called _deceptive_ optimization problems where it is common for many existing optimization algorithms get stuck in local optima .

Assuming we have evaluated \(\) at \(n>0\) input values, yielding dataset \(_{n}=\{(_{i},(_{i}))\}_{i=1}^{n}\), a popular way to measure the "novelty" is the average distance to the \(k\)-nearest neighbors as follows

\[(|)=_{i=1}^{k}((), _{i}^{}),\] (1)

where \(\{_{1}^{},,_{k}^{}\}\) are the \(k\) closest outcomes to \(()\) and \(()\) is any valid distance metric in \(^{M}\). If we had knowledge of \(\), we could sequentially select inputs that maximize novelty at every iteration, i.e., \(_{n+1}=*{argmax}_{}(| _{n})\) over our design space \(^{D}\). The key challenge in practice is that \(\) is often a black-box function such that we cannot solve this optimization problem exactly. To overcome this challenge, the vast majority of existing NS methods rely on meta-heuristics, such as evolutionary algorithms, to select new evaluation points, e.g., [1; 6]. These methods can be effective when we have a large evaluation budget (e.g., can evaluate \(\) several thousand or more times); however, for many applications of interest, we have expensive evaluations. For example, in the airplane design problem, evaluating \(()\) may require a complex computational fluid dynamic simulation or physical experiment. These problems naturally require a much smaller evaluation budget for which existing NS methods are not designed.

Recently, the authors proposed an NS method, called BEACON, specifically designed for expensive black-box functions . BEACON constructs a multi-output Gaussian process surrogate model for \(\) that is combined with a novel acquisition function for trading off exploration and exploitation of the input space, which enables efficient sampling of the search space. However, BEACON relies on a global surrogate model and thus is inherently limited by the curse of dimensionality. Although we previously explored the use of custom priors and kernels to deal with this challenge, these require \(\) to exhibit special structure and are likely to fail when these assumptions do not hold.

Motivated by this challenge, we propose a _local_ variant of BEACON for high-dimensional NS (or behavior discovery) problems. Our proposed approach, TR-BEACON, leverages the notion of a trust region (TR)  to limit the size of the search space over which we need to build our surrogate model. Trust regions are commonly applied in the optimization literature and have been used within the TuRBO algorithm  for high-dimensional Bayesian optimization. A key component of TR-BEACON is the development of a new trust region management system that at every iteration (i) computes a center point based on the most novel data point observed so far and (ii) uses a variance-based measure to decide if the trust region should be enlarged or shrunk. The next section provides a detailed description of TR-BEACON, which is followed by numerical experiments on a synthetic objective and a challenging robot maze navigation problem from the NS literature that demonstrate its strong empirical performance on high-dimensional problems.

## 2 TR-BEACON: Algorithm Description

A complete description of TR-BEACON is given in Algorithm 1. The first key component is the construction of a (local) multi-output Gaussian processes (MOGPs)  to model the \(M\)-dimensional outcome space. Recall that a GP is a non-parametric model that learns a probabilistic surrogate function from (potentially) noisy data. To build an MOGP, we introduce an additional input variable \(j\{1,,M\}\) to describe the \(j^{}\) element of the outcome vector \([()]_{j}\). Given observed data \(_{n}\), the expressions for the posterior mean and variance of the MOGP can be derived analytically; see Appendix A. The second key component is the choice of the "trust region" (TR). Here, we choose the TR to be a hyperrectangle with center equal to the input that gave the output that is furthest away from its neighbors, denoted by \(_{n}^{c}\). At the start of the method, we set the base side length of the TR to \(L L_{}\). Following TuRBO, the base side length is rescaled according to the estimated average lengthscale \(_{i}\) for dimension \(i\) across the different outputs in the MOGP model such that \(L_{i}=_{i}L/(_{j=1}^{D}_{j})^{1/D}\). As commonly done in TR methods, if the optimizer "makes progress", the TR will be expanded whereas, if it "fails", the TR will be shrunk. We double and halve the size of the TR after, respectively, \(_{}\) consecutive successes and \(_{}\) consecutive failures. In addition, we do not let the TR length exceed a size \(L_{}\) and reset the length to \(L_{}\) if \(L\) falls below a minimum threshold \(L_{}\). Since the novelty measure (1) changes at every iteration (depends on the full set of collected data), we cannot define a "success" as simply improving upon the best-known value. Instead, we define a "success" as choosing a candidate that increases the total variance of the outcomes and a "failure" as choosing one that does not. The last critical component is the choice of acquisition function inside of the TR for which we use with the same approach as BEACON, i.e.,

\[_{n+1}*{argmax}_{_{n}}\ }_{k}^{}([((),_{1} ),,((),_{n})]^{}),\] (2)

where \(|_{n}\) is a Thompson sample (TS) from the MOGP posterior, \(_{n}\) denotes the TR at the current iteration \(n\), \(}_{k}\) is a vector of ones in the first \(k\) entries and zeros in the remaining entries, and \(()\) is the standard sort operator that sorts its input in descending order. The formulation can be thought of as a differentiable version of (1) where the true unknown function \(\) is replaced with a TS \(\). We let \(^{}\) and \(^{}\) denote the subset of input and output values in the dataset \(\), respectively. An illustration of the evolution of TR-BEACON is shown in Fig. 1 for a simple 2-D function. We see that our proposed approach is able to efficiently explore the space of outcomes (finding many values along the edge of the support of the distribution of outcomes), even though the MOGP model does not accurately capture the novelty metric surface especially in the early iterations.

## 3 Numerical Experiments

We compare TR-BEACON with several state-of-the-art (SOTA) baseline algorithms on a synthetic and a reinforcement learning (RL) problem. Details for all methods are included in Appendix B. All experiments can be reproduced with the code provided in https://github.com/PaulsonLab/TR-BEACON.git.

### 20-D Ackley

For the first case study, we consider a 20-D Ackley synthetic function; see Appendix C for its analytical form. We consider the domain \(x[-2,2]\) and generate 40 initial samples using the Sobol sequence  to train a GP with a standard radial basis function (RBF) kernel. We use reachability as the performance metric, which corresponds to the number of bins visited by the algorithms given a finite number of evaluations (50 equally sized bins are chosen, with each bin effectively representing a behavior we would like to discover). Results are shown in Fig. 1(a) over 10 replicates of randomly selected initial points (the dark lines represent the mean and the shaded regions correspond to 95% confidence regions). We see that TR-BEACON achieves the highest reachability of all the methods, with BEACON performing second best as the performance drops off due to the difficulty of globally modeling the outcome over a 20-D input space.

### 24-D Reinforcement Learning Problem - Maze Navigation

Next, we examine a challenging RL problem from the OpenAI Gym  environment. The task is to move a ball from its starting location to a target location within a given number of time steps (see Appendix D for details). We define the actor policy using a bias-free feed-forward neural network. We want to compute the optimal set of weight parameters that can maximize the reward of successfully getting the ball to the exit. This is known to be a deceptive problem in the sense that the algorithm can often unexpectedly push the system to have the ball get trapped on a wall when directly optimizing the objective (distance to the exit) . NS methods can overcome this challenge by considering the \((x,y)\) coordinates of the landing position as outcomes and biasing the samples toward discovering new outcomes. Fig. 1(b) shows the mean of the best reward found by all baseline methods across 30 replicates. The percentage of reaching the maximum achievable reward for all baseline methods is \(10^{-1}\).

Figure 1: Illustration of TR-BEACON on a 2-D synthetic function with \(2\) outcomes. As the algorithm proceeds (from top to bottom), TR-BEACON identifies novel outcomes from the unexplored local region and gradually shrink the TR accordingly. (_Left_) The contour for the true novelty metric by replacing \(\) in (2) with the true function. (_Middle_) The contour for the predicted novelty metric by replacing \(\) in (2) with the MOGP posterior mean. (_Right_) the scatter plot for sampled outcomes and the true function outcomes. (\(\): center point of TR; \(\): sampled features; \(\): sampled outcomes)

Figure 2: Results on (a) 20-D Ackley function and (b) 24-D RL maze navigation problem

shown in Table 1 in Appendix D. TR-BEACON substantially outperforms all considered baselines; it can in fact reach the maximum achievable reward within 300 episodes in all replicates. NS-EA has the second-best performance; however, only reaches \( 90\%\) of the best possible reward, with even lower performance in the earlier iterations. Lastly, two SOTA black-box optimizers, mainly TuRBO  and LogEI , interestingly exhibit the worst performance out of all tested methods, which is a consequence of the deceptive characteristics of this problem.