# Personalized Adapter for Large Meteorology Model on Devices: Towards Weather Foundation Models

Shengchao Chen\({}^{}\), Guodong Long\({}^{}\), Jing Jiang\({}^{}\), and Chengqi Zhang\({}^{}\)

\({}^{}\)Australian Artificial Intelligence Institute, University of Technology Sydney

\({}^{}\)Department of Data Science and AI, The Hong Kong Polytechnic University

shengchao.chen.uts@gmail.com, {guodong.long, jing.jiang}@uts.edu.au

chengqi.zhang@polyu.edu.hk

###### Abstract

This paper demonstrates that pre-trained language models (PLMs) are strong foundation models for on-device meteorological variables modeling. We present LM-Weather, a generic approach to taming PLMs, that have learned massive sequential knowledge from the universe of natural language databases, to acquire an immediate capability to obtain highly customized models for heterogeneous meteorological data on devices while keeping high efficiency. Concretely, we introduce a lightweight personalized adapter into PLMs and endows it with weather pattern awareness. During communication between clients and the server, low-rank-based transmission is performed to effectively fuse the global knowledge among devices while maintaining high communication efficiency and ensuring privacy. Experiments on real-wold dataset show that LM-Weather outperforms the state-of-the-art results by a large margin across various tasks (_e.g._, forecasting and imputation at different scales). We provide extensive and in-depth analyses experiments, which verify that LM-Weather can (1) indeed leverage sequential knowledge from natural language to accurately handle meteorological sequence, (2) allows each devices obtain highly customized models under significant heterogeneity, and (3) generalize under data-limited and out-of-distribution (OOD) scenarios. Code available on https://github.com/shengchaochen82/LM-Weather.

## 1 Introduction

Accurately modeling weather variation pattern from large amount of meteorological variables sequences is increasingly vital for providing efficient weather analysis support for disaster warning. Recently, the promise of learning to understand weather pattern from data via deep learning (DL) has led to an ongoing paradigm shift apart from the long-established physics-based methods .

Mining potential patterns from meteorological sequences that collected from different regions, including forecasting and imputation, is one of the most important problems in meteorology. Significant progress has been made by several latest time series approaches . These approaches formulate meteorological variable modeling as an end-to-end spatio-temporal learning problem. This overlooks the reality that ground weather devices distributed globally gather vast amounts of data quickly. The sheer volume of data, coupled with limited network capacity, necessitates local processing on the devices, making centralised learning challenging . On-device intelligence enables edge devices to compute independently, offering a primary solution to the problem.

Federated Learning (FL)  is a promising on-device intelligence implementation that collaboratively train a uniform model across devices without exchanging raw data. However, the model often under-perform due to data heterogeneity among clients. Personalized FL (PFL) provides new insights for on-device intelligence that allows each device obtains customized models for providing personalizedinsights [8; 9]. Albeit PFL methods showing revolutionized capability in this field, we argue that the current advancements are not necessarily at their best in on-device meteorological variable modeling as three major obstacles remain and hinder further progress:

1. **Challenge of Heterogeneity.** Weather data's heterogeneity, unlike that of images or text, arises mainly from the unique characteristics of data collected by weather devices in various regions, such as tropical or arid areas. Furthermore, sensor malfunctions or extreme events can lead to collection disruptions or inconsistent missing data, which significantly increase the differences in data distribution across devices.
2. **Underperformed Shallow Network Structures.** The vast and varied data gathered by weather devices challenge simpler neural network models to generalize effectively. Furthermore, the frequent updates of weather data (hourly or by the minute) require neural models on devices to train and infer more often. This demand is hard to meet with deeper models that, while more performant, are also more resource-intensive.
3. **Resource-constrained Weather Devices.** From a computation perspective, weather devices cannot afford of training complex neural models from scratch, especially for foundation models . From a communication perspective, transmitting complete model during the

Figure 1: _Framework Overview._**(a)** Schematic of LM-Weather, each client using _personalized adapter_ to endow the PLM for local weather awareness, only low-rank matrices are transmitted to enhance efficiency during communication; **(b)** Brief structure of PLM on each client, detailed architecture can be found in Appendix; **(c)** Task Adapter Generation, the multivariate weather series input splits into two paths. The first path isolates the trend, seasonal, and residual elements, which each go through independent generator to produce specific adapters; **(d)** Architecture of the generator for each decomposed element; **(e)** Schematic diagram of Channel-Independent Patching .

aggregation phase in FL/PFL significantly increases communication overhead, which is impractical for real-time weather modeling.

Therefore, a compact foundational model (FM) is crucial for personalized on-device weather modeling. Yet, there's a gap in FMs for observational data. Models trained on large-scale simulation data struggle in practical applications because of notable differences in data formats and parameter scales .

Inspired by the impressive progress of large language models (LLMs) in natural language processing, recent literature in time series analysis research has also demonstrated that pre-trained LMs provide excellent performance over dedicated models for time series analysis with tuning  or reprogramming . This comprehensive and thorough sequence knowledge from language models can be effortlessly transferred across domains without large-scale parameter tuning. Thus, an exciting research question naturally arises:

**Question:**_Since PLMs are powerful sequence modelers, can we leverage PLMs as foundation models to achieve personalized on-device meteorological variable modeling?_

In this paper, we show that pre-trained language models (PLMs) can as outstanding foundation models that tuned on each device with low cost can achieve personalized on-device weather pattern modeling. We propose LM-Weather, a generic approach to taming PLMs to understand heterogeneity on-device weather data. As shown in **Fig.1a**, we conduct a local tuning on an uniform PLM (e.g., GPT2), where lightweight _personalized adapters_ are implanted to endow PLMs with weather pattern awareness by decomposing weather sequence to implicit knowledge (e.g., seasonal, trend). During communication between client and server, fewer parameters are shared globally while locally retained adapters are enforced to resist heterogeneity and facilitate privacy-assured fusion of global knowledge.

We highlight our contributions and findings as follows:

* We introduce LM-Weather, a generic approach that transforms Pre-trained Language Models as the foundation model to customized on-device meteorological variable modeling via _personalized adapter_. LM-Weather yields preferable meteorological variable sequences modeling, while being parameter-, communication-, and data-efficient.
* We collect and compile four real-world versatile datasets for on-device meteorological variable modeling across regions. As opposed to simulated datasets such as ERA5 , our datasets are all real-time observations. These datasets based on real-world practice and challenging, provide a pioneer in the field of on-device meteorological variable modeling.
* Experiments show that LM-Weather advances the state-of-the-art methods by a large margin across various setting while keeping **3.7%** of parameters communication. LM-Weather also demonstrates superior communication efficiency in the context of meteorological variable modeling, beating FL baselines tailored to reduce communication overhead.
* In particular, we find that LM-Weather can accurately handle structurally non-deterministic sequences (e.g., differences in time or variable dimensions across devices) thanks to the learned sequences knowledge from pre-trained LMs. We also find that LM-Weather can indeed be spatio-temporal sequences sensitive, thereby better modeling the weather pattern specificity of those high distribution similarity.
* We find that LM-Weather can work well in data-limited environments across various few-shot settings. We further evaluate zero-shot generalizability of LM-Weather in modeling complex weather patterns of unseen data, including different group of datasets and other devices, and observe superb performance.

We highlight that the goal of this study is not to compete but instead to complement current on-device meteorological variables modeling framework. Today's climate foundation models are typically trained from scratch, utilizing exceptionally large datasets (nearly 100TB ) and incurring substantial computational costs . We hope that LM-Weather offers a cost-effective alternative for modeling meteorological variables on-device, thereby enabling accurate regional weather trend analysis. In addition, the dataset we complied can be the important resource to provide exploring chances for this field, facilitating future research.

Preliminaries

### On-device Meteorological Variable (Sequence) Modeling

The on-device meteorological variable (sequence) modeling challenge involves predicting future sequences from past observations for forecasting or predicting missing values for imputation on each device. While traditional physics-based approach this as a complex problem of solving multilevel atmospheric equations , recent deep learning techniques have shown significant potential in uncovering patterns for better weather prediction [4; 2].

Problem FormulationOn-device meteorological variable modeling can be formulated as an end-to-end sequence-to-sequence learning problem for each device without exchange raw data. Formally, a parameterized local model for \(i\)-th device \(_{}^{i}\) is tasked with predicting the weather sequence,

\[_{}^{i}:_{i}}_{i}\] (1)

where the \(_{i}^{L C}\) and \(}_{i}^{L^{} C^{}}\) denote the input and output sequences on \(i\)-device, \(L\) and \(L^{}\) is the input length and output length, \(C\) and \(C^{}\) is the number of input and output variable. Note that the \(L^{} L\) when performing imputation. The local learning objective on each device is to find the model parameter \(\) that minimize the distance between \(}_{i}\) and \(_{i}\) given sufficient weather sequence data. The overall optimization objective is based on FedAvg,

\[F():=_{i=1}^{N}}{n}F_{i}(_{i}|\{D_{i}\}),\] (2)

where \(n_{i}\) and \(n\) is the number of samples held by the \(i\)-th client and all clients1, respectively, \(F(|\{D\})\) denotes the local objective function, \(\{D\}\) is the local data.

### Language Models in Time Series

Language models (LMs) trained on large-scale sequence data have shown extraordinary advances and led to a significant paradigm shift in NLP, boosting machines in understanding human languages (BERT/MLM-style) and synthesizing human-like text (GPT/CLM-style ). Analogies between time series and human languages have long been noted . Recent advancements in time series analysis have demonstrated the effectiveness of PLMs in modeling time series [17; 11]. Although some of those have shown that PLMs can beat time series-specific models in updating a minor fraction of parameters . As such, it is exciting to expect cutting-edge techniques of language modeling can tackle weather variables sequence-related problems rather than considering train climate foundation models [4; 1] from scratch that are heavy and expensive, and are trained from simulated data.

## 3 Taming PLMs for On-device Meteorological Variable (Sequence) Modeling

OverviewWe proposed a generic framework named LM-Weather that encouraging PLMs to yield accurate prediction while keeping high efficiency for each device. The architecture is illustrated in **Fig. 1**. To endow PLMs with weather pattern awareness, we introduce a lightweight _personalized adapter_ into PLMs (e.g., GPT2 ) such that the emergent ability of sequence modeling that transferred from text into weather is activated. To achieve cross-domain knowledge transfer with minimal effort while maintaining the sequence modeling capabilities of PLMs as intact as possible, we introduce lightweight operations in it enables both clients and servers to achieve a good trade-off between performance and efficiency (e.g., computation and communication).

### Local Training on Each Device

Our LM-Weather refines PLMs for personalized weather sequence modeling on heterogeneous devices using a modular, plug-and-play architecture. Specifically, we introduce _personalized adapter_ consists of (1) _Task Adapter_ from latent weather knowledge and (2) _Parameter Adapter_ that converts representation from the PLM into weather forecasts. In addition, we employ lightweight operations in local training to boost computational efficiency.

Task Adapter.To provide PLMs with richer effective information to activate their sequence modeling capabilities in the target knowledge domain, similar to text-based prompts in language to LLMs in NLP, we constructed task adapters by decomposing the input weather sequences into multimodal latent statistical information,

\[^{k}_{}+^{k}_{}+^{k}_ {}=(^{k}),\] (3)

where \(^{k}^{L 1}\) denote the \(k\)-th variable in weather sequence \(^{L C}\), the trend component \(_{}\) and the seasonal component \(_{}\) captures the underlying long-term weather pattern and encapsulates the repeating short-term weather cycles, respectively. Furthermore, the residual component \(_{}\) represents the remainder of the sequence after the trend and seasonality have been extracted. Note that \(_{}\), \(_{}\), and \(_{}\) have the same shape as \(\). This decomposition explicitly enables the identification of unusual observation and shifts in seasonal patterns or trends. The \(_{}\), \(_{}\), \(_{}\) are used to generate _Task Adapter_ via an unified generator as **Fig. 1c & Fig. 1d** that consisting of Token Embedding, Position Embedding, and Temporal Embedding. Specially, we use one-dimensional convolution operation to map each each specific sample \(^{k}\) while keeping raw shape to generate Token Adapter \(_{}\). Additionally, we use a trainable lookup table to map each point's explicit position in the entire sequence, to generate Position Adapter \(_{}\). Furthermore, we separately encode different time attributes such as minutes, hours, days, weeks, and months, via trainable parameters to dynamically model complex temporal shifts, to generate Temporal Adapter \(_{}\). Finally, for each decomposition components, corresponding generated adapters can be obtained by aggregating Token Adapter \(_{}^{L C}\), Position Adapter \(_{}^{L C}\), and Temporal Adapter \(_{}^{L C}\) as \(_{d}=_{}^{d}+_{}^{d}+_{}^{d}\), where \(d\{,,\}\), this means that we can obtain \(_{},_{},_{}\). Details about the generator in **Appendix B.5**.

Lightweight Operations.To enhance the PLMs' ability to represent complex inputs while reducing the computational burden to adapt to low-resource devices, we introduce lightweight operations, which includes channel-independent patching (CIP, **Fig. 1e**)  for input and efficient tuning of parameters for PLMs. Among them, CIP splits the multivariate sequence into separate univariate sequences, each processed by a single model with length \(L_{p}\). This approach outperforms the original method of mixing channels by treating the variables as independent. It enables the model to capture channel interactions indirectly through shared weights, leading to improved performance without directly modeling the complexity of multiple data channels. The total number of inputs patches is \(P=)}{S}+2\), where \(S\) denotes the horizontal sliding stride. Given these patches \(^{i}_{P}^{P L_{p}}\), we use rearrange operation and a trainable FFN embed them as \(}^{i}_{P}^{P d_{m}}\), where \(d_{m}\) is dimensions created by the FFN. We also introduce a low-rank adaptation (LoRA)  inside PLMs aiming at language modeling for lightweight fine-tuning of attention layers to achieve cross-modal/-domain knowledge transfer from text sequences to weather sequences with minimal effort.

Parameter Adapter.To adapt PLM outputs for downstream weather sequence modeling, we introduce_Parameter Adapter_, a simple FFN with a single linear layer positioned after the PLM. This adapter transforms the PLM's output to match the prediction horizon, formalized as follows:

\[}=(_{}([}_ {},}_{},}_{}, }])),\] (4)

where the \(}_{}\), \(}_{}\), \(}_{}\), and \(}\) are obtained from CIP based on \(_{}\), \(_{}\), \(_{}\), and \(\). The key objectives are twofold: (1) to enrich the PLM's cross-modal representations by incorporating task-specific knowledge, and (2) to enhance the PLM's output accuracy while preserving its inherent knowledge through the integration of weather data for cross-domain knowledge transfer.

### High-efficiency Communication Between Clients and Server

To avoid data silos and counteract the performance disparities caused by data heterogeneity while ensuring efficient communication, we update personalized adapters locally and share low-rank parameters globally in each round. Specifically, the local PLM \(_{}\) can be formulated as below:

\[_{}_{,t}(Communication)+_ {,f}(Locally)\] (5)

where \(_{,t}\) denotes the trainable parameter from the low-rank matrices of _query_ and _value_ in attention modules, \(_{,f}\) is the frozen parameter (mainly the PLM backbone) and other trainable ones (primarily for the personalized adapter). During client-server communication, only \(_{,t}\) is transmitted and averaged using FedAvg . At the start of the next training round, the updated \(_{,t}\) is broadcast to clients for further updates. Privacy is further protected by sending minimal parameters.

## 4 Main Theorems

**Theorem 4.1** (**Decomposition Rationality from Time Series)**.: _Given a weather series \(=_{,t}+_{,t}+ _{,t}\), \(t[t_{1},t_{n}]\). Let \(=\{e_{1},e_{2},...,e_{n}\}\) denotes a set of orthogonal bases. Let \(_{}\) denote the subset of \(\) on which \(_{,t}\) has non-zero eigenvalues and \(_{}\) denote the subset of \(\) on which \(_{,t}\) has non-zero eigenvalues. If \(_{,t}\) and \(_{,t}\) are not orthogonal, i.e., \(_{i=1}^{n}_{,t}^{i}_{,t}^ {i} 0\), then \(_{}_{} 0\), i.e., \(\) can not disentangle the two signals onto two disjoint set of bases._

**Theorem 4.2** (**Exchange Low-Rank Matrices Ensures Privacy)**.: _Given a on-device weather modeling framework based on federated learning that gloabl optimization object is \(()=_{n}^{i=1}p_{i}f(\{D_{i}\};)\), where \(f(x;)\) is the loss function of \(i\)-th client, \(\{D_{i}\}\) is dataset of \(i\)-th client, and \(p_{i}\) and \(\) denote the data distribution weight of client \(i\) and the model parameters, respectively. Given that the parameters \(\) of the PLM \(_{}\) broadcasted by the server consist of two parts: a frozen part \(_{,f}\) and a trainable part \(_{,t}\), interacting only the low-rank matrix parameters \(_{,t}_{,t}\) is a subset of trainable part \(_{,t}\) during each round ensures privacy._

## 5 Experiments

In this section, we first present the real-world datasets that we have collected and compiled for on-device meteorological variable modeling, and second, we evaluate LM-Weather on these datasets, which involves normal scenario, a data-limited few-shot scenario, and a zero-shot scenario with no training data (OOD). Please refer to **Appendix** for more detailed information about proposed datasets and additional results of all evaluations (e.g., full results, additional findings & experiments).

### Datasets

Despite the proliferation of reanalysis data aimed at building frameworks for global climate analysis, these datasets often struggle to model regional weather trend due to: (1) they depend on numerous simulations of atmospheric equations, introducing biases inconsistent with real observations, and (2) they face challenges in refining their scale to suit specific regional applications. Hence, we collected real observational data from various weather stations across different regions. We then organized this data into two series, each comprising two distinct datasets, to underscore the heterogeneity inherent in real-world settings. For detailed information on these datasets, please see the **Appendix B.1**.

On-device Weather Series 1# (ODW1).The dataset gathered from 15 ground weather stations across China, Japan, and South Korea, encompasses over 20 variables. It has been divided into two subsets: **ODW1T** has a heterogeneous time span, meaning the data collection start and end times vary by location. and **ODW1V** extends **ODW1T** by adding variability in the observed variables; while one variable remains constant at each station, the others vary.

On-device Weather Series 2# (ODW2).This dataset consists of data from 36 weather observation stations in the United States, Canada, and Israel, covering 5 different variables with a temporal resolution of 1 hour. Following the dataset setting of **ODW1**, the dataset was also subdivided into two different dataset, including **ODW2T** and **ODW2V**.

### Setup

Baseline.Since our framework is based on a language model, we compare with DL-based SOTA time series models, including Transformer-based methods: Transformer , Informer , Reformer , Pyraformer , iTransformer , and PatchTST , and recent competitive models: GPT4TS , DLinear  and LightTS . Note that our setting is FL-based, so we place them in FL and rename them FL-(_baseline_) like FL-Transformer, etc., and all aggregation methods used in above models is FedAvg . In addition, we report a variants of LM-Weather, LM-Weather-ave that based on FedAvg without personalization. Detailed information are in **Appendix B.2**.

Basic Setup.We focus on on-device meteorological variable forecasting and imputation tasks. For forecasting, we create scenarios for predicting a single variable (multivariate-univariate) and for predicting all variables (multivariate-multivariate). The main text only includes multivariate-to-multivariate forecasting results due to page constraints. For multivariate-to-univariate forecasts, refer

[MISSING_PAGE_FAIL:7]

Setups and Results of Forecasting & Imputation.For both forecasting and imputation tasks, we evaluate the few-shot learning capability in scenarios using limited data, specifically, we use training ratios of 5% and 15% (Our full few-shot learning results (training ratio of 5% and 15%) can be found at **Appendix E.2**). The brief 5% few-shot learning results on forecasting and imputation tasks are depicted in **Tab. 3** and **Tab. 4**, respectively. LM-Weather remarkably excels over all baseline methods, and we attribute this to the successful cross-domain knowledge activation in our local dual fine-tuning for the PLM. In addition, our LM-Weather's communication mechanism also reduces the impact of data heterogeneity on performance, which is reflected in the fact that LM-Weather has an average **14.7%** and **20%** improvement relative to LM-Weather-ave, in the forecasting and imputation, respectively. In relation to recent SOTA methods such as FL-PatchTST, FL-LightTS, and FL-DLinear, our LM-Weather enhancements surpass **78%**, **14.3%**, and **72.8%** for forecasting, and **102.1%**, **122.1%**, and **96.35%** for imputation. This means that heterogeneity poses challenge to baseline and they struggle to understand weather patterns with limited data. Moreover, it implies that LM-Weather can effectively achieve cross-domain knowledge transfer to PLMs. This benfits from the personalized adapter we integrated into the PLM, coupled with lightweight operations.

### Zero-Shot Learning (Out of Distribution Modeling) Experiments

Beyond few-shot learning, PLMs hold potential as effective zero-shot reasoners. We evaluate the zero-shot learning capabilities of LM-Weather within the framework of cross-domain adaption. Specifically, we examine how well a method performs on a dataset when it is optimized on another dataset, where the model has not encountered any data samples from the original dataset. We use forecasting/imputation protocol and evaluate on various cross-domain scenarios. Note that we choose LM-Weather-ave rather than LM-Weather for

  } & } & 
   &  &  & **Aviv. Variations** &  \\   &  &  &  &  &  &  &  &  \\  LM-Weather & 45.4/46.4 & 23.1/40.0 & Original & Original & - & - & 10.38 M & 0.38 M \\  LM-Weather-A & 50.8/47.6 & 25.6/47.7 & \(\) Decompression & Original & 11.8/5 & 1.25/6 & 10.38 M & 0.38 M \\ LM-Weather-B & 50.8/47.6 & 25.4/47.1 & \(\) Decompression & Original & 12.1/5 & 1.06/5 & 10.37 M & 0.38 M \\ LM-Weather-C & 60.1/43.1 & 25.4/48.8 & \(\) Decompression & Original & 10.0/5 & 1.52/6 & 10.37 M & 0.38 M \\ LM-Weather-C & 60.1/43.1 & 25.4/48.8 & \(\) Decompression & Original & 10.0/5 & 1.52/6 & 10.37 M & 0.38 M \\ LM-Weather-C & 63.9/48.5 & 25.5/40.0 & \(\) Decompression & Original & 10.0/5 & 1.52/6 & 10.38 M & 0.38 M \\ LM-Weather-C & 64.9/49.2 & 25.1/45.0 & \(\) Decompression & 10.0/5 & 1.52/6 & 10.38 M & 10.09 M \\ LM-Weather-C & 64.9/49.2 & 22.4/45.1 & \(\) Decompression & 10.0/5 & 1.52/6 & 10.38 M & 10.09 M \\ LM-Weather-H & **42.9/71.2** & **22.0/93.3** & Original & \(\) LeRA, Local: Attention Penns, Global: the rest of multiple years. & 1.5/5 & 1.7/5 & 2.1/3 & 2.01 M & 10.09 M \\  

Table 6: Ablation results on forecasting (multivariate to multivariate) and imputation (50% masking ratio, **OWDIT** dataset). A lower value indicates better performance. **Bold**: the best, Underline: the second best, \(\) and \(\) denote performance degradation and performance improvement, respectively.

   &  &  \\   & Forecasting &  &  &  &  \\  LM-Weather & **45.4/74.6** & **23.1/42.2** & 10.38 M & 0.38 M & 3.70\% \\  FL-GPIT4S & 49.9/82.5 & 25.1/46.2 & 12.42 M & 12.42 M & 100\% \\ FL-Reformer & 78.2/98.7 & 69.9/82.5 & 19.74 M & 19.74 M & 100\% \\ FL-Performance & 73.0/91.7 & 68.0/89.7 & 153.32 M & 15.532 M & 100\% \\ FL-DLinear & 63.3/82.8 & 28.5/49.9 & 16.0 M & 16.0 M & 100\% \\ FL-PatchFT & 48.6/81.0 & 45.7/35.7 & 74.74 M & 74.74 M & 100\% \\ FL-Informer & 53.7/63.7 & 27.6/48.2 & 26.74 M & 26.74 M & 100\% \\ FL-Inflops & 67.9/34.4 & 26.1/45.7 & 1.68 M & 1.68 M & 100\% \\ FL-Transformer & 52.8/84.7 & 57.6/82.3 & 45.55 M & 45.55 M & 100\% \\ FL-Informer & 53.4/85.2 & 61.4/85.9 & 52.31 M & 52.31 M & 100\% \\  

Table 7: Experiment results on parameter comparison (ave. MAE/RMSE report), **Bold**: the best.

(i.e., FL-LightTS/DLinear), LM-Weather continues to outperform them. This underscores LM-Weather's superiority in both communication efficiency and performance.

Robustness to Number of Devices.To evaluate LM-Weather's robustness against device count variations, we assessed the percentage change in performance relative to the default device number. Our results (**Tab. 9**) reveals that LM-Weather maintains robustness across different device counts due to several factors: **(1)** Increasing device numbers during training typically yields slight performance improvements within a stable range, applicable in both regular and few-shot scenarios. **(2)** Additional devices can sometimes impair performance due to imbalances in data distribution, highlighting non-proportional gains. **(3)** Adding more devices increases communication overhead, which may not justify minor improvements, especially in resource-limited settings. These findings underscore LM-Weather's relative resilience to device count variations and its ability to strike an optimal balance between performance enhancement and communication overhead.

## 6 Conclusion and Future Works

This paper demonstrate that pre-trained language models (PLMs) are strong foundation models for personalized on-device meteorological variable modeling. We propose LM-Weather, a generic framework to taming PLMs to acquire highly customized models for heterogeneous meteorological data on devices while keeping high efficiency. Concretely, we introduce a lightweight personalize adapter into PLMs and endow it with weather pattern awareness. Experiments on real-world datasets demonstrate that LM-Weather outperforms the SOTA results by a large margin across various tasks. In addition, extensive analyses indicate that LM-Weather can (1) effectively achieve cross-domain knowledge transfers, (2) render device with highly customized model while keeping high efficiency, and (3) generalize under few-shot and zero-shot scenario. In future work, we plan to extend LM-Weather to multimodal weather data (text/image/time-series) and to finer scales.

   Method & Forecasting & Imputation & Train. & Comm. Params. & Comm. \\  FL-Pyraformer & 73.0/91.3 & 68.0/89.7 & 153.32 M & 153.32 M & 0.07\(\) \\ FL-PatchTST & 48.6/81.0 & 45.4/73.5 & 74.74 M & 74.74 M & 0.14\(\) \\ FL-LightTS & 62.7/93.4 & 26.1/45.7 & 1.68 M & 1.68 M & 6.2\(\) \\ FL-DLinear & 63.3/82.8 & 28.5/49.9 & 1.06 M & 1.06 M & 9.8\(\) \\  LM-Weather-Ave & 47.5/78.7 & 24.0/44.1 & 10.38 M & 10.38 M & 1\(\) \\  LM-Weather (Ours) & **45.4/74.6** & **23.1/42.4** & 10.38 M & **0.38 M** & **27.3\(\)** \\ LM-Weather (w FedKD) & 49.6/76.2 & 27.5/43.6 & 10.38 M & 1.68 M & 6.2\(\) \\ LM-Weather (w FedDF) & 52.1/79.0 & 25.1/44.3 & 10.38 M & 8.46 M & 1.2\(\) \\ LM-Weather (w FedBF) & 46.2/78.1 & 23.7/44.0 & 10.49 M & 10.49 M & 0.9\(\) \\ LM-Weather (w FedAP) & 47.4/79.2 & 24.3/44.7 & 10.38 M & 9.6 M & 1.1\(\) \\ LM-Weather (w PrompFL) & 46.0/78.4 & 23.8/45.1 & 10.38 M & 8.4 M & 1.2\(\) \\   

Table 8: Comparison of LM-Weather and baseline that tailored to improve communication efficiency in terms of forecasting (multivariate-multivariate)/imputation (50% masking rate) performance as well as communication efficiency, with \(\) denotes the improvement in communication efficiency relative to the standard line (LM-Weather-Ave), MAE/RMSE report. **Bold**: the best.

    &  &  &  \\  & & Forecasting & Imputation & Forecasting & Imputation \\   & 0.1 (2/round) & 44.4/73.6 & 22.6/42.0 & 64.7/100.4 & 40.2/68.2 \\  & 0.3 (5/round) & 43.7/72.5 (\(\) 1.55) & 24.2/43.7 (\(\) 5.55) & 63.4/99.7 (\(\) 1.40) & 41.4/68.7 (\(\) 1.85) \\   & 0.5 (8/round) & 42.9/72.0 (\(\) 2.85) & 21.0/42.1 (\(\) 3.90) & 63.7/99.2 (\(\) 1.40) & 42.3/68.5 (\(\) 2.8) \\   & 0.7 (1/round) & 43.9/74.1 (\(\) 0.25) & 21.8/42.1 (\(\) 2.80) & 64.5/10.1 (\(\) 0.10) & 39.5/66.7 (\(\) 2.00) \\   & 1.0 (16/round) & 44.2/74.0 (\(\) 0.2) & -21.3/41.6 (\(\) 3.10) & 63.6/102.1 (\(\) 0.95) & 40.4/68.0 (\(\) 0.1) \\   & 0.1 (4/round) & 66.2/89.1 & 37.2/54.9 & 89.7/131.8 & 7.7/2112.6 \\  & 0.3 (11/round) & 68.2/89.7 (\(\) 1.85) & 36.5/53.1 (\(\) 2.65) & 90.2/132.5 (\(\) 0.55) & 75.4/110.3 (\(\) 2.25) \\   & 0.5 (18/round) & 65.4/89.2 (\(\) 0.55) & 36.7/53.4 (\(\) 2.05) & 89.1/131.4 (\(\) 0.50) & 76.5/1112.1 (\(\) 1.10) \\   & 0.7 (25/round) & 65.7/88.8 (\(\) 0.90) & 36.1/53.9 (\(\) 2.45) & 88.9/130.9 (\(\) 0.80) & 76.9/112.3 (\(\) 0.35) \\   & 1.0 (36/round) & 65.9/89.0 (\(\) 0.25) & 36.9/55.0 (\(\) 0.30) & 89.1/130.7 (\(\) 0.75) & 76.7/112.1 (\(\) 0.50) \\   

Table 9: Results of LM-Weather under forecasting (multivariate-multivariate) and imputation (50% masking rate) at different device participation rates \([0.1,0.3,0.5,0.7,0.9]\), \(\)/\(\) implies an increase/decrease in performance relative to the original setting (0.1), MAE/RMSE report, where 15% represents the proportion of data on each client involved in training.