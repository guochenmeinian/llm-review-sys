# Diffusion-based Layer-wise Semantic Reconstruction

for Unsupervised Out-of-Distribution Detection

 Ying Yang\({}^{1*}\), De Cheng\({}^{1*{}}\), Chaowei Fang\({}^{1*{}}\), Yubiao Wang\({}^{1}\)

Changzhe Jiao\({}^{1}\), **Lechao Cheng**\({}^{2}\), **Nannan Wang**\({}^{1}\), **Xinbo Gao**\({}^{3}\)

\({}^{1}\)Xidian University

\({}^{2}\)Hefei University of Technology

\({}^{3}\)Chongqing University of Posts and Telecommunications

{yycfq, ybwang_3}@stu.xidian.edu.cn

chenglc@hfut.edu.cn,gaoxb@cqupt.edu.cn

{dcheng, cwfang, cjiao, nnwang}@xidian.edu.cn

 Equation Contribution. Corresponding authors: De Cheng and Chaowei Fang.

###### Abstract

Unsupervised out-of-distribution (OOD) detection aims to identify out-of-domain data by learning only from unlabeled In-Distribution (ID) training samples, which is crucial for developing a safe real-world machine learning system. Current reconstruction-based method provides a good alternative approach, by measuring the reconstruction error between the input and its corresponding generative counterpart in the pixel/feature space. However, such generative methods face the key dilemma, \(i.e.,\)_improving the reconstruction power of the generative model, while keeping compact representation of the ID data._ To address this issue, we propose the diffusion-based layer-wise semantic reconstruction approach for unsupervised OOD detection. The innovation of our approach is that we leverage the diffusion model's intrinsic data reconstruction ability to distinguish ID samples from OOD samples in the latent feature space. Moreover, to set up a comprehensive and discriminative feature representation, we devise a multi-layer semantic feature extraction strategy. Through distorting the extracted features with Gaussian noises and applying the diffusion model for feature reconstruction, the separation of ID and OOD samples is implemented according to the reconstruction errors. Extensive experimental results on multiple benchmarks built upon various datasets demonstrate that our method achieves state-of-the-art performance in terms of detection accuracy and speed. Code is available at https://github.com/xbyym/DLSR.

## 1 Introduction

Unsupervised Out-of-Distribution (OOD) detection aims to identify whether a data point belongs to the In-Distribution (ID) or OOD dataset, by learning only from unlabeled in-distribution training samples. OOD detection plays a vital role in developing a safe real-world machine learning system, which ensures that the model is only performed on data drawn from the same distribution as its training data. If the test data does not follow the training distribution, the model could unintentionally produce nonsensical predictions, resulting in some misleading conclusions. Naturally, OOD detection is one of the key techniques for ensuring the model's robustness and safety.

Existing research studies the OOD detection mainly under two settings, \(i.e.,\) supervised and unsupervised. The supervised OOD detection methods usually deem this task as a binary classification problem, which relies on training with data labeled as OOD from disjoint categories or adversaries[Hendrycks et al., 2018], [Ming et al., 2022]. However, in many practical applications, it is almost impossible to access representative OOD samples, as the OOD data usually can be highly diverse and unpredictable. Therefore, we prefer to study the more challenging while practical unsupervised OOD detection problem. We will build an OOD detector trained solely on unlabeled ID data, as large amounts of unlabeled data are readily available and widely utilized due to their ease of acquisition.

Current reconstruction-based methods provide a good alternative approach for OOD detection, by measuring the reconstruction error between the input and its corresponding generative counterpart in the pixel/feature space. Obviously, the generative models and metric learning evaluation strategies are the main research directions. However, such methods of the generative models always face the following key dilemma: The projected in-distribution latent feature space should be compressed sufficiently to capture the exclusive characteristics of ID images, while it should also provide sufficient reconstruction power for the large-scale ID images of various categories. Existing generative-based methods (\(e.g.\), auto-encoder (AE), variational AE [Kingma and Welling, 2013] and Generative Adversarial Network(GAN)) [Goodfellow et al., 2014], can not always fulfill these two requirements simultaneously, and a good balance between them is required. Besides, recent OOD detection methods based on diffusion models such as [Graham et al., 2023], [Gao et al., 2023] and [Liu et al., 2023] often involve the pixel-level reconstruction of distorted images, which consume much training/inference time and computation resources.

To address the above-mentioned issues, and inspired by the latent space noise addition mechanism in Latent Diffusion Models (LDM) [Rombach et al., 2022], we propose the diffusion-based layer-wise semantic reconstruction approach for unsupervised OOD detection. Specifically, the proposed method makes full use of the diffusion model's intrinsic data reconstruction ability, to distinguish in-distribution samples from OOD samples in the latent feature space. In the diffusion denoising probabilistic models (DDPM) [Ho et al., 2020], the model is trained to incrementally remove noise from the noised inputs of different levels. Clearly, we can see that, instead of faithfully reconstructing inputs from the distribution it was trained on as previous VAE [Wang et al., 2013] or GAN [Goodfellow et al., 2014], the diffusion-based model shows more powerful reconstruction capabilities. Practically, our model involves reconstructing an input image feature from multiple values of the time step, this allows a single trained model to handle large amount of noise applied to the input, obviating the need for any dataset-specific fine-tuning.

Moreover, to set up a comprehensive and discriminative feature representation, we devise a multi-layer semantic feature extraction strategy. Performing feature reconstruction on top of the multi-layer semantic features, encourages to restrict the in-distribution latent features distributed more compactly within a certain space, so as to better rebuild in-distribution samples while not reconstructing OOD comparatively. Overall, by distorting the extracted multi-layer features with Gaussian noises and applying the diffusion model for feature reconstruction, the separation of ID and OOD samples is implemented according to the reconstruction errors. Note that, the proposed Latent Feature Diffusion Network (LFDN) is built on top of the feature level instead of the traditional pixel level, which could significantly improve the computation efficiency and achieve effective OOD detection. The other potential strength of such a strategy is that it avoids the reconstruction of minor characteristics unrelated to image understanding. In summary, the contributions of this work are as follows:

* We propose a diffusion-based layer-wise semantic reconstruction framework to tackle OOD detection, based on multi-layer semantic feature distortion and reconstruction. Meanwhile, We are the first to successfully incorporate generative modeling of features within the framework of OOD detection in image classification tasks.
* The layer-wise semantic feature reconstruction encourages restricting the in-distribution latent features to be more compactly distributed within a certain space, enabling better reconstruction of ID samples while limiting the reconstruction of OOD samples.
* Extensive experiments on multiple benchmarks across various datasets show that our method achieves state-of-the-art detection accuracy and speed.

## 2 Related Work

Existing researches study the OOD detection mainly under two settings: supervised and unsupervised. The Supervised method is generally based on classification. The method usually uses the maximum softmax probability [Hendrycks and Gimpel, 2016] from the final fully connected (FC) layer as the score to judge the ID sample. But the classification-based OOD detection methods often encounter issues with assigning high softmax probability to OOD samples. Recent works (Liu et al., 2020), (Sun and Li, 2022), (Djurisic et al., 2022), (Zhao et al., 2024), attempt to alleviate this issue. The unsupervised OOD detection can be roughly categorized as the distance-based metric evaluation and the generative-based reconstruction methods.

Distance-based methods assume that OOD data lies far from ID class centroids. (Ren et al., 2021) improved OOD detection by separating image foregrounds from backgrounds and computing the Mahalanobis distance for each, then combining them. (Sun et al., 2022) used a non-parametric nearest neighbor distance for OOD detection. (Techapanurak et al., 2020) and (Chen et al., 2020) used cosine similarity to measure distances between test data features of in-distribution data to identify OOD data. (Huang et al., 2020) applied Euclidean distance, while (Gomes et al., 2022) used Geodesic distance for OOD detection. These methods often fail to capture sample distribution accurately.

Among the generative-based methods, the Likelihood-based methods can be traced back to as early as (Bishop, 1994). This method assumes that the generative model assigns high likelihood to ID data, while the likelihood for OOD data tends to be lower. Recently, several deep generative models have supported the computation of likelihood, such as VAE (Kingma and Welling, 2013), PixelCNN++ (Salimans et al., 2017), and Glow (Kingma and Dhariwal, 2018). However, some studies ((Nalisnick et al., 2018); (Choi et al., 2018); (Kirichenko et al., 2020)) have found that probabilistic generative models might also assign high likelihood to OOD data.

A series of studies have attempted to mitigate this issue. (Serra et al., 2019) explored the relationship between image complexity and likelihood values, which adjusted likelihoods based on the size of image compression. (Ren et al., 2019) enhanced OOD detection by comparing likelihood values derived from different models. Another closely related approach highlights that these indicators are not well suited for VAEs. (Xiao et al., 2020) proposed a specialized metric known as likelihood regret for OOD detection in VAEs. (Cai and Li, 2023) suggested to leverage the high-frequency information of images to improve the model's ability to recognize OOD data. Additionally, a range of studies (Nalisnick et al., 2019), (Wang et al., 2020), (Bergamin et al., 2022), (Osada et al., 2023), have proposed typicality tests, estimating layer activation distributions and other statistical measures on training data, which are then evaluated through hypothesis testing or density estimation.

Another type of OOD detection methods leverage the idea that generative networks produce different reconstruction errors for ID and OOD data. Some methods such as (Sakurada and Yairi, 2014), (Zong et al., 2018), and (Zhou and Paffenroth, 2017), used auto-encoders to analyze reconstruction errors. GAN-based methods (Schlegl et al., 2017), (Zenati et al., 2018), and (Madzia-Madzou and Kuijf, 2022) utilized reconstruction errors and discriminator confidence to detect anomalies. Recent works (Graham et al., 2023), (Gao et al., 2023), and (Liu et al., 2023) applied diffusion models to model the pixel-level distribution of images, using errors from multiple reconstructions for OOD detection. Different from previous methods, we propose to leverage diffusion models to perform multi-layer semantic reconstruction in the latent feature space, not only for their stability in generation but also for significantly reducing training and inference time costs.

## 3 Method

Unsupervised OOD detection leverages intrinsic information from an unlabeled ID dataset \(\) to train a detector. Suppose \(\) contains \(N\) images, namely \(=\{_{i}\}_{i=1}^{N}\), where \(_{i}\) denotes the \(i\)-th image.

Figure 1: Overview of proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection. It includes multi-layer semantic feature extraction, Diffusion-based Feature Distortion and Reconstruction, and OOD detection head modules.

The target is to learn an OOD detector denoted as \(()\), which can effectively evaluate an OOD score for each input image. The judgment of whether the input image belongs to ID or OOD is implemented by thresholding the OOD score. For example, given a testing image **x**, it is recognized as an ID sample if the OOD score \(()\) is lower than the pre-defined threshold \(\); otherwise, it is recognized as an OOD sample.

In this paper, we propose a diffusion-based layer-wise semantic reconstruction framework to accomplish the OOD detection task. Specifically, as illustrated in Figure 1, the proposed framework consists of the following three components: the multi-layer semantic feature extraction module, the latent feature diffusion stage, and the OOD detection head.

### Multi-layer Semantic Feature Extraction

The proposed semantic reconstruction-based method achieves OOD detection by measuring the reconstruction error between the input and its generative counterpart in the feature space. Specifically, we devise a multi-layer semantic feature extraction strategy, to set up a comprehensive and discriminative feature representation for each input image. Such multi-layer features could better rebuild the samples and encourage the ID semantic features distributed more compactly within a certain space from different semantic layers.

Specifically, given an image \(^{3 w h}\) with \(w\) and \(h\) being the width and height of the input image, passing through an image encoder \(()\), (\(e.g.\), EfficientNet ), we can extract its feature maps from different layers (\(i.e.\), low-level to high-level semantic blocks). The multi-layer intermediate feature map from the \(m\)-th block can be defined as \(^{m}^{c_{m} w_{m} h_{m}},m\{1,...,M\}\), where \(c_{m}\), \(w_{m}\) and \(h_{m}\) are the number of channels, width and height of the feature map \(^{m}\), and \(M\) is the total number of intermediate feature maps. Then, each feature map \(^{m}\) undergoes the global average pooling, obtaining the one-dimensional feature vector \(^{m}^{c_{m}}\). Afterward, Z-score normalization  is applied to each feature vector \(^{m}\), resulting in \(}^{m}=^{m}-^{m}}{(^{m})+}}\) for the \(m\)-th intermediate feature vector \(^{m}\) of the input image **x**, where \((^{m})\) is the variance of \(^{m}\) along the channel elements, and \(\) is a small constant value. Finally, we obtain the overall multi-layer feature vector for the input image **x** as: \(_{0}=()=[}^{1},, }^{m},,}^{M}]^{c}\) by concatenating all the intermediate feature vectors, where \(c=_{m=1}^{M}c_{m}\), and \(()\) denotes the whole feature extraction process.

### Diffusion-based Feature Distortion and Reconstruction

Fitting the semantic feature distribution of ID samples is crucial for identifying whether the input is an ID or OOD sample. However, it is difficult to explicitly model the semantic feature space which has moderate complexity. Existing generative-based models ,  address the modeling of complex data/feature space by transferring the original data/features into an implicit bottleneck space and learning a generator capable of recovering ID samples from the bottleneck space. Since the generator can not generalize well in recovering unseen OOD samples, it can be used as the OOD detector. Inspired by this, we set up a diffusion-based feature distortion and reconstruction framework, considering the strength of diffusion models in data reconstruction. Our framework is innovative in the introduction of diffusion models in modeling semantic features, while previous works , ,  focus on applying diffusion models for straightforward pixel-level distortion and reconstruction.

#### Semantic Feature Distortion.

The semantic feature distortion process can be conceptualized as transforming the semantic features into distorted counterparts with different levels of noise. For each step \(t\) belonging to \([1,,T]\), the

Figure 2: Residual Block Structure in LFDN.

generation of data point \(_{t}\) follows the formula:

\[_{t}=(_{0},t)=_{t}} _{0}+_{t}}, (^{c},^{c c})\] (1)

where \(^{c}\) represents a Gaussian noise vector; \((,)\) denotes the Gaussian distribution; \(^{c}\) and \(^{c c}\) denote the \(c\)-dimensional zero vector and the \(c c\) identity matrix, respectively. \(_{t}\) is a predefined noise level that controls the amount of noise added at each step.

**Semantic Feature Reconstruction.** For reconstructing the semantic features from their distorted counterparts, we build up a Latent Feature Diffusion Network (LFDN) constituted by 16 residual blocks (ResBlock), as shown in Fig. 1.

The structure of ResBlock is illustrated in Fig. 2. Its residual branch is formed with two groups of Groupnorm (Wu and He, 2018), SiLU, and linear layers, as well as a MLP used for absorbing in the time embedding.

Following the calculation process of the denoising diffusion implicit model (Song et al., 2020), we employ LFDN to remove the noises injected into the semantic features with skipping step stride denoted as \(s\). The detailed noise-removing process for \(_{t}\) is described as follows. \(s\) is set to a value randomly selected from \(\{1,2,,t\}\).

1. We first input \(_{t}\) and the time embedding of \(t\) into LFDN, generating an initial reconstruction state denoted as \(}_{t}\). The calculation formulation can be summarized as: \(}_{t}=(_{t},t)\), where \(()\) denotes the feed-forward process of LFDN.
2. Afterwards, we estimate the noise correction vector for \(_{t}\) denoted as \(}_{t}\) as follows, \[}_{t}=_{t}-_{t}} }_{t}}{_{t}}},\] (2) where \(_{t}\) is the predefined noise level of the \(t\)-th feature distortion step.
3. Then, we sample the input (\(}_{t^{}}\)) for implementing the \(t^{}\)-th step's feature reconstruction where \(t^{}=(t-s,0)\) as: \[}_{t^{}}=_{t^{}}}( _{t}-_{t}}}_{t}}{_{t}}}+_{t^{}}- _{t}^{2}}}_{t})+_{t}^{2},\] (3) where \(_{t}^{2}\) represents the variance of the additional noise at step \(t\). Regarding \(}_{t^{}}\) and time embedding of \(t^{}\) as inputs, LFDN predicts reconstruction results of the \(t^{}\)-th step as \(}_{t^{}}=(}_{t^{}},t ^{})\).
4. Repeating steps 2 and 3 until \(t^{}\) = 0, yields the final reconstructed semantic features \(}_{0}\).

We summarize the above process as \(}_{0}=(_{t},t)\). This framework ensures that \(}_{0}\) is not solely derived from the LFDN output but is continuously refined by DDIM, integrating detailed corrections to achieve high accuracy in reconstructing the original data from its noisy observations.

**Objective Function**. For optimizing the network parameters of LFDN, the mean square error is used as the loss function for pulling close the outputs of LFDN with the original semantic features. The calculation formulation is as follows:

\[L=_{}\|_{0}-( _{t},t)\|_{2}^{2}\] (4)

During training, \(t\) is randomly selected from \(\{1,2,,T\}\). The detail is illustrated in Algorithm 1.

```
1:Input: \(

Lastly, we employ the Multi-layer Semantic Feature Similarity (MFsim), \(i.e.\), the cosine similarity. We assesses the cosine similarity between the original features \(_{0}=[}^{1},,}^{m},,}^{M}]\) and the reconstructed features \(}_{0}=[}^{1},,}^{m},,}^{M}]\) at various layers: \((}^{m},}^{m})=} ^{m}}^{m}}{\|}^{m}\|\|}^{m}\|^{2}}\). The OOD detection score MFsim, is then computed as the negative average of these similarities: MFsim = \(-_{m=1}^{M}(}^{m},}^{ m})\), where \(M\) is the number of feature maps. A higher MFsim score indicates a greater likelihood of the data being OOD. Algorithm 2 details the MFsim calculation. The flows for MSE and LR calculations are provided in Appendix A.

```
1:Input: Train image \(^{3 h w}\)
2:\(_{0}=()=[}^{1},,}^{m},,}^{M}]^{c}\)
3:repeat
4: Draw \(t\{1,,T\}\)
5: Draw \((0,I)\)
6: Compute \(_{t}\) and \(L\)
7:\(_{t}=_{t}}_{0}+_{t}}\)
8:\(L=_{}\|_{0}-(_{t},t)\|_{2}^{2}\)
9: Update the parameters via the AdamW optimizer.
10:until convergence ```

**Algorithm 1** Training Algorithm

## 4 Experiments

### Datasets and Evaluation Metrics

**Datasets**: We train the OOD detection model on three in-distribution (ID) datasets: CIFAR-10 (Krizhevsky et al., 2009), CIFAR-100, and CelebA (Liu et al., 2015). When testing models learned on a specific ID dataset, we select several datasets from SVHN (Netzer et al., 2011), SUN (Xiao et al., 2010), LSUN-c (Yu et al., 2015), LSUN-r, iSUN (Xu et al., 2015), iNaturalist (Van Horn et al., 2018), Textures (Cimpoi et al., 2014), Places365 (Zhou et al., 2017), MNIST (Deng, 2012), FMNIST, KMNIST (Clanuwat et al., 2018), Omniglot (Lake et al., 2015), and NotMNIST as OOD data.

**Evaluation Metrics**: We employed the area under the receiver operating characteristic (AUROC) and the false positive rate at 95% true positive rate (FPR95) as evaluation metrics. Results in FPR95 metric are provided in Appendix C.1.

### Implementation Details

We utilize EfficientNet-b4 (Tan and Le, 2019) or ResNet50 (He et al., 2016) pre-trained on ImageNet (Deng et al., 2009) as our encoder. The main text presents results using EfficientNet-b4, while results using ResNet50 are detailed in Appendix C.2. For EfficientNet-b4, we select feature maps from the first to fifth stages (\(M=5\)) to construct the multi-layer semantic features, resulting in a feature dimension (\(c\)) of \(720\). The LFDN is consisting of 16 residual blocks. Inside each residual block, the number of groups in Groupnorm and the intermediate feature dimension of the residual branch are set to 1 and 1440, respectively. We employ the AdamW optimizer with a weight decay of \(10^{-4}\). Our method is trained on NVIDIA Geforce 4090 GPU for 150 epochs, with a batch size of 128 and a constant learning rate of \(10^{-4}\) throughout the training phase.

### Comparison with State-of-the-art Methods

**Compared Generative-based Methods:** In Table 1, regarding CIFAR-10 as the ID dataset, we compare our method against pixel-level generative-based methods including GLOW (Serra et al., 2019), PixelCNN++ (Serra et al., 2019), VAE (Xiao et al., 2020), and DDPM (Graham et al., 2023). To validate the effectiveness of LFDN, we implement a variant of our method through replacing LFDN with AutoEncoder in which MFsim is used for estimating the OOD score. In comparison with the best pixel-level method, VAE, our method achieves a 9.1% improvement in average AUROC when using MFsim for OOD score estimation. Compared to DDPM, our method variants show a significantly improvement in average AUROC. For example, when integrated with MSE, our method achieves 20.4% higher AUROC than DDPM. This indirectly indicates that performing OOD detection at the pixel level is much worse than performing OOD detection at the feature level. Generating pixels may reconstruct more content unrelated to the image's semantics, which may interfere the identification of OOD samples. Making the model focus on the reconstruction of compactly distributed semantic features benefits in separating ID and OOD samples. In terms of testing speed, our method is nearly 100 times faster than DDPM, significantly enhancing performance while reducing detection costs. Moreover, the final version of our method built upon LFDN improves average AUROC by 18.5% compared to the variant basd on AutoEncoder, as the diffusion model captures data distribution more effectively.

In Table 2, we compare our method with VAE, DDPM and AutoEncoder, using CelebA as the ID dataset. Our method integrated with MFsim achieves state-of-the-art performances, with an AUROC improvement of 19.89% compared to DDPM, and the performance of the remaining two metrics also far exceeds the baseline, demonstrating the generalizability of our approach.

**Compared Classification-based and Distance-based Methods:** In Table 3, we compare our method with classification-based methods including MSP , EBO , DICE , and ASH-S , as well as distance-based methods including 'SimCLR+Mahalanobis Distance'  and 'SimCLR+KNN' . All methods are evaluated using EfficientNet-b4 as the backbone. Compared to classification-based and distance-based methods, our approach consistently shows a clear advantage. Specifically, for CIFAR-100 as the in-distribution dataset, our method integrated with MFsim achieves an average AUROC of 13.84% higher than the classification-based method DICE. Moreover, unlike classification-based methods, our approach does not require labeled data.

The inference speed of our method based on MSE or MFsim is faster than that of distance-based methods SimCLR+Maha and SimCLR+KNN, because the computation of covariance matrix or K nearest neighbors occupies part of time. Our method is also comparable to classifier-based methods including MSP, EBO, DICE and ASH-S. This demonstrates the effectiveness of leveraging the strong ability of diffusion models to reconstruct original distributions from different noise levels for reconstructing low-dimensional features and performing OOD detection.

### Ablation Study

**Illustration of the generation ability of the diffusion model on OOD detection**. To demonstrate the evolution of the generative model's reconstruction capability for both ID and OOD samples before and after training, we compare the distributions of the MFsim scores at the first epoch and the final epoch in **Figure 3**. CIFAR-10 serves as the ID dataset, while the other six datasets listed in **Table 3** are employed as OOD data. Our observations reveal that the diffusion model's reconstruction ability enhances across most datasets, with a notably more pronounced improvement for the in-distribution samples. This indicates that ID samples are reconstructed more effectively, thereby validating the efficacy of our method.

    &  &  \\  ID & OOD & GLOW & PixelCNN++ & VAE & DDPM & AutoEncoder & our(+MSE) & ours(+LR) & ours(+MFsim) \\   & SVHN & 88.3 & 73.7 & 95.9 & 97.3 & 57.7 & 97.3\(\)0.0 & 98.2\(\)0.0 & **98.9\(\)0.1** \\  & LSUN & 21.3 & 64.0 & 40.3 & 68.2 & 81.5 & 97.6\(\)0.1 & 97.8\(\)0.1 & **99.8\(\)0.1** \\  & MNIST & 85.8 & 96.7 & **99.9** & 83.2 & 95.8 & 99.4\(\)0.0 & 98.9\(\)0.1 & **99.9\(\)0.0** \\  & FMNIST & 71.2 & 90.7 & 99.1 & 84.3 & 79.6 & 99.0\(\)0.0 & 98.8\(\)0.0 & **99.9\(\)0.0** \\  & KMNIST & 38.0 & 82.6 & **99.9** & 89.7 & 90.5 & 99.5\(\)0.0 & 99.1\(\)0.0 & **99.9\(\)0.0** \\  & Omniglot & 95.5 & 98.9 & 99.6 & 35.9 & 81.5 & 99.1\(\)0.1 & 97.1\(\)0.1 & **99.9\(\)0.0** \\  & NotMNIST & 53.9 & 82.6 & 99.4 & 88.7 & 81.6 & 99.8\(\)0.1 & 99.5\(\)0.0 & **99.9\(\)0.0** \\   & 64.9 & 84.2 & 90.6 & 78.2 & 81.2 & 98.8\(\)0.1 & 98.5\(\)0.1 & **99.7\(\)0.1** \\  Time & Num img/s (\(\)) & 38.6 & 19.3 & 0.7 & 11.4 & 1224.2 & 999.3 & 273.6 & 999.3 \\   

Table 1: The AUROC values for OOD detection, where CIFAR-10 is used as the in-distribution dataset. The results are compared with generative-based methods. Higher AUROC values indicate better performance, with the best results highlighted in bold for clarity.

[MISSING_PAGE_FAIL:8]

**Comparison of MFsim across different feature scales**. **Figure 5** displays performance comparisons of MFsim when reconstructing the last block (i.e., \(f_{4},C=448\)) versus multi-layer semantic features under an EfficientNet-b4 encoder. The results demonstrate that multi-layer semantic features generally outperform single-layer ones, indicating that multi-layer semantic features contain richer semantic information and are more representative of samples across different in-distribution datasets. Furthermore, considering the diverse semantic information represented by different layers, combing various layers of semantic features helps to boost the OOD performances of LFDN.

**Ablation study on LFDN network parameters**. We conducted ablation experiments on two groups of parameters within the LFDN network: the dimension of the linear layers and the number of ResBlocks. For each experiment, we reduced one of these parameters to half of its original size while keeping all other parameters unchanged. **Table 4** presents the results of these experiments, showing how these modifications affect the performance. It is observed that the performance of our MFsim metric remains relatively stable, indicating that it continues to provide effective OOD detection capabilities even under conditions of reduced network size.

## 5 Conclusion and Limitation

In this paper, we propose a diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection. We leverage the diffusion model's intrinsic data reconstruction ability to distinguish in-distribution and OOD samples in the latent feature space. Specially, the diffusion-based feature generation is built on top of the devised multi-layer semantic feature extraction strategy, which

  
**Metrics** &  &  &  \\  Linear & Linear=720 & Linear=1440 & Linear=720 & Linear=1440 & Linear=720 & Linear=1440 \\ 
**Average** & 83.35 & 86.35 & 84.05 & 89.17 & 96.43 & 97.20 \\  Number of Blocks & Number=8 & Number=16 & Number=8 & Number=16 & Number=8 & Number=16 \\ 
**Average** & 85.26 & 86.35 & 87.32 & 89.17 & 97.13 & 97.20 \\   

Table 4: Changes in Average AUROC Across Six Datasets listed in Table 3 for CIFAR100 as ID.

Figure 4: CIFAR-10 dataset is the ID data, the six datasets listed in Table 3 are used as OOD data. The average AUROC and FPR95 for the three metrics are evaluated at different sampling time steps.

Figure 5: Variation of Average AUROC Values across Different Scalessets up a comprehensive and discriminative feature representation benefiting the generative OOD detection methods. Finally, we hope our proposed OOD detection method could make contributions to develop a safe real-world machine learning system. Additionally, it needs to point out that the performance of our method also relies on the quality of features extracted by the encoder. Therefore, selecting an encoder with strong feature extraction capabilities is crucial for achieving good performances.

## 6 Acknowledgement

This work was supported in part by the National Key R\(\&\)D Program of China under Grant No.2023YFA1008600, in part by NSFC under Grant NO.62376206, 62176198 and U22A2096, in part by the Key R\(\&\)D Program of Shaanxi Province under Grant 2024GX-YBXM-135, in part by the Key Laboratory of Big Data Intelligent Computing under Grant BDIC-2023-A-004.

## 7 Broader Impacts

Positive Societal Impacts: The proposed diffusion-based layer-wise semantic reconstruction method for unsupervised out-of-distribution (OOD) detection can significantly enhance the security and safety of machine learning systems. By effectively identifying OOD data, the system can prevent incorrect or potentially harmful decisions, making AI applications more reliable in critical areas such as healthcare, autonomous driving, and financial systems. This method increases the robustness of AI systems by ensuring they can handle unexpected inputs gracefully. This contributes to the overall stability and trustworthiness of AI deployments in various industries, thereby promoting wider acceptance and integration of AI technologies. Negative Societal Impacts: As with any advanced detection method, there is a risk that the technology could be misused. For instance, surveillance applications, it could be employed to monitor individuals without their consent, leading to privacy violations and ethical concerns.