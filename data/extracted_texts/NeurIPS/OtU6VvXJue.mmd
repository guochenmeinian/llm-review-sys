# Learning to Augment Distributions for

Out-of-Distribution Detection

Qizhou Wang\({}^{1}\)1 Zhen Fang\({}^{2}\)1 Yonggang Zhang\({}^{1}\) Feng Liu\({}^{3}\) Yixuan Li\({}^{4}\) Bo Han\({}^{1}\)2

\({}^{1}\)Department of Computer Science, Hong Kong Baptist University

\({}^{2}\)Australian Artificial Intelligence Institute, University of Technology Sydney

\({}^{3}\)School of Computing and Information Systems, The University of Melbourne

\({}^{4}\)Department of Computer Sciences, University of Wisconsin-Madison

{csqzwang, csygzhang, bhanml}@comp.hkbu.edu.hk

zhen.fang@uts.edu.au fengliu.ml@gmail.com sharonli@cs.wisc.edu

Equal contributions.Correspondence to Bo Han (bhanml@comp.hkbu.edu.hk).

###### Abstract

Open-world classification systems should discern out-of-distribution (OOD) data whose labels deviate from those of in-distribution (ID) cases, motivating recent studies in OOD detection. Advanced works, despite their promising progress, may still fail in the open world, owing to the lack of knowledge about unseen OOD data in advance. Although one can access auxiliary OOD data (distinct from unseen ones) for model training, it remains to analyze how such auxiliary data will work in the open world. To this end, we delve into such a problem from a learning theory perspective, finding that the distribution discrepancy between the auxiliary and the unseen real OOD data is the key to affecting the open-world detection performance. Accordingly, we propose _Distributional-Augmented OOD Learning_ (DAL), alleviating the OOD distribution discrepancy by crafting an _OOD distribution set_ that contains all distributions in a Wasserstein ball centered on the auxiliary OOD distribution. We justify that the predictor trained over the worst OOD data in the ball can shrink the OOD distribution discrepancy, thus improving the open-world detection performance given only the auxiliary OOD data. We conduct extensive evaluations across representative OOD detection setups, demonstrating the superiority of our DAL over its advanced counterparts. The code is publicly available at: https://github.com/tmlr-group/DAL.

## 1 Introduction

Deep learning in the open world often encounters out-of-distribution (OOD) data of which the label space is disjoint with that of the in-distribution (ID) cases Hendrycks and Gimpel (2017); Fang et al. (2022). It leads to the well-known OOD detection problem, where the predictor should make accurate predictions for ID data and detect anomalies from OOD cases Bulusu et al. (2020); Yang et al. (2021). Nowadays, OOD detection has attracted intensive attention in reliable machine learning due to its integral role in safety-critical applications Cao et al. (2020); Shen et al. (2021).

OOD detection remains challenging since predictors can make over-confidence predictions for OOD data Hendrycks et al. (2019), motivating recent studies towards effective OOD detection. Therein, outlier exposure Hendrycks et al. (2019); Ming et al. (2022) is among the most potent ones, learning from _auxiliary OOD data_ to discern ID and OOD patterns. However, due to the openness of the OOD task objective Wang et al. (2023), auxiliary OOD data can arbitrarily differ from the (unseen) real OOD data in the open world. So, to formally understand their consequences, we model the differencebetween auxiliary and real OOD data by their distribution discrepancy, measured by the Wasserstein distance (Villani, 2021, 2008). Then, we reveal the negative impacts of such OOD distribution discrepancy on the real detection power, with a larger distribution discrepancy indicating a lower performance on real OOD data, cf., Eq. (4).

The OOD distribution discrepancy threatens the open-world detection performance for outlier exposure. Therefore, we raise a natural question in _how to alleviate such an OOD distribution discrepancy_. Hence, this paper establishes a promising learning framework named _Distributional-Augmented OOD Learning_ (DAL). Therein, we augment the auxiliary OOD distribution by crafting an _OOD distribution set_ containing all distributions in a Wasserstein ball (Villani, 2021, 2008), centered on the auxiliary OOD distribution. Then, by making the predictor learn from the worst OOD distribution in the set, cf., Eq. (8), one can alleviate the negative impacts of the distribution discrepancy. Moreover, our proposed framework enjoys the learning guarantees towards the expected risk with respect to the real OOD distribution, making OOD detection stay effective when facing unseen data (cf., Theorem 3). Figure 1 provides a conceptual explanation: learning from the worst OOD distribution ensures the uniformly well performance inside the Wasserstein ball, enlarging the influence of the auxiliary OOD distribution. Thus, one can shrink the OOD distribution discrepancy between the auxiliary and the real OOD data and improve OOD detection.

In realization, the primal learning objective in Eq. (8) is generally intractable due to the infinite-dimensional optimization for the worst OOD distribution search. Instead, we adopt the dual form with respect to the original learning problem (cf., Theorem 1), transforming it into a tractable problem of the worst OOD data search in a finite-dimensional space. Furthermore, following Du et al. (2022); Mehra et al. (2022), the data search procedure is conducted in the embedding space, which can benefit the open-world performance of OOD detection with decent costs of additional computation.

We conduct extensive experiments over representative OOD detection setups, revealing the open-world performance of our method toward effective OOD detection. For example, our DAL reduces the average FPR95 by 1.99 to 13.46 on CIFAR benchmarks compared with the conventional outlier exposure (Hendrycks et al., 2019). Overall, we summarize our contributions into three folds:

* We measure the difference between the auxiliary and the real OOD data by the Wasserstein distance, and establish an effective learning framework, named DAL, to mitigate the OOD distribution discrepancy issue. We further guarantee our performance with respect to unseen real OOD data via Theorem 3, which is new to previous works.
* DAL leads to a practical method in Algorithm 1, learning from the worst cases in the Wasserstein ball to improve the open-world detection performance. Overall, our method solves the dual problem, which performs the worst-case search in the embedding space, which is simple to compute yet effective in OOD detection.
* We conduct extensive experiments in Section 5 to evaluate our effectiveness, ranging from the well-known CIFAR benchmarks to the challenging ImageNet settings. The empirical results comprehensively demonstrate our superiority over advanced counterparts, and the improvement is mainly attributed to our distributional-augmented learning framework.

A detailed overview of existing OOD detection methods and theories can be found in Appendix A, and a summary of the important notations can be found in Appendix B.

Figure 1: A heuristic illustration for our DAL. A large distribution discrepancy between the auxiliary and the unseen OOD data will hurt the real detection effectiveness. However, by ensuring uniformly well performance inside the Wasserstein ball, we can mitigate the distribution discrepancy and thus improve the detection power in the open world.

Outlier Exposure

Let \(\) denote the feature space and \(=\{1,,C\}\) denote the label space with respect to the ID distribution. We consider the ID distribution \(D_{X_{1}Y_{1}}\), a joint distribution defined over \(\), where \(X_{}\) and \(Y_{}\) are random variables whose outputs are from spaces \(\) and \(\). We also have an OOD joint distribution \(D_{X_{0}Y_{0}}\), where \(X_{0}\) is a random variable from \(\), but \(Y_{0}\) is a random variable whose outputs do not belong to \(\), i.e., \(Y_{0}\)(Fang et al., 2022).

The classical OOD detection (Hendrycks and Gimpel, 2017; Yang et al., 2021) typically considers an open-world setting, where the real OOD data drawn from \(D_{X_{0}Y_{0}}\) are unseen during training. Recently, Fang et al. (2022) have provided several _strong_ conditions necessary to ensure the success of the classical OOD setting. Furthermore, to increase the possibility of success for OOD detection and weaken the strong conditions proposed by Fang et al. (2022), advanced works (Hendrycks et al., 2019; Chen et al., 2021) introduce a promising approach named _outlier exposure_, where a set of auxiliary OOD data is employed as a surrogate of real OOD data. Here, we provide a formal definition.

**Problem 1** (OOD Detection with Outlier Exposure).: Let \(D_{X_{1}Y_{1}}\), \(D_{X_{0}}\), and \(D_{X_{}}\) be the ID joint distribution, the OOD distribution, and the auxiliary OOD distribution, respectively. Given the sets of samples called the ID and the auxiliary OOD data, namely,

\[S=\{(_{1}^{1},y_{1}^{1}),...,(_{1}^{n},y_{1}^{n})\} D _{X_{1}Y_{1}}^{n},\ i.i.d.,\ \ \ \ T=\{_{}^{1},...,_{}^{m}\} D_{X_{ }}^{m},\ i.i.d.,\]

outlier exposure trains a predictor \(\) by using the training data \(S\) and \(T\), such that for any test data \(\): 1) if \(\) is an observation from \(D_{X_{}}\), the predictor \(\) can classify \(\) into its correct ID label; otherwise 2) if \(\) is an observation from \(D_{X_{0}}\), the predictor \(\) can detect \(\) as an OOD case.

**OOD Scoring.** Many existing methods detect OOD data by using various score-based strategies (Hendrycks and Gimpel, 2017; Lee et al., 2018; Liu et al., 2020; Sun et al., 2022). In general, given a model \(:^{C}\) and a scoring function \(s(;):\), the OOD detector \(g_{}\) is given by:

\[g_{}()=,\ \ s(;) ;\ ,\ g_{}()=,\]

where \(\) is a given threshold. For example, as a well-known baseline scoring function, the maximum softmax prediction (MSP) (Hendrycks and Gimpel, 2017) is given by:

\[s_{}(;)=_{k}\ _{k}\ (),\] (1)

with \(_{k}()\) denoting the \(k\)-th dimension of the softmax output.

**Model and Risks.** We denote \(_{}:^{C}\) the predictor with parameters \(\), with \(\) the parameter space. We consider the loss functions \(\) and \(_{}\) w.r.t. the ID and the OOD cases, respectively. Then, the expected and the empirical _ID risks_ of the model \(_{}\) can be written as:

\[R_{}()=_{(,y) D_{X_{1}Y_{1}}} (_{};,y)\ \ \ \ _{}()=_{i=1}^{n}(_{ };_{}^{i},y_{}^{i}).\]

The expected and the empirical _auxiliary OOD risks_ are then given by

\[R_{}()=_{ D_{X_{}}} _{}(_{};)\ \ \ \ _{}()=_{i=1}^{m}_{}( _{};_{}^{i}),\]

and the expected _real OOD risk_ is given by \(R_{}()=_{ D_{X_{0}}}_{ }(_{};)\). Accordingly, we can define the expected _detection risk_ with respect to real OOD data, following

\[R_{D}()=R_{}()+ R_{}(),\] (2)

where \(\) is the trade-off parameter.

**Learning Strategy.** After the scoring function is selected, one can obtain the OOD detector if the model \(_{}\) is given. Under the Problem 1 of outlier exposure, a common learning strategy is to optimize the empirical ID and auxiliary OOD risk jointly (Hendrycks et al., 2019), namely,

\[_{}\ _{}()+ _{}().\] (3)

Note that the auxiliary OOD data are employed in Eq. (3), which can arbitrarily differ from the real OOD cases. Then, it is generally expected that the predictor \(_{}\), trained over the auxiliary OOD data, can perform well even on unseen OOD data, i.e., a small value of \(R_{D}()\) is expected.

Motivation

To the general learning strategy in Eq. (3), intuitively, if the auxiliary data are sampled from a distribution similar to real ones, the predictor will perform well for real OOD data. However, auxiliary and real OOD data differ in practice, posing us to suspect their open-world detection performance. To formally study the problem, we measure the difference between auxiliary and real OOD data in the distribution level, motivating our discussion of _OOD distribution discrepancy_.

**Distribution Discrepancy.** In this paper, we adopt a classical measurement for the distribution discrepancy--Optimal Transport Cost (Sinha et al., 2018; Mehra et al., 2022).

**Definition 1** (Optimal Transport Cost and Wasserstein-1 Distance (Villani, 2021, 2008)).: Given a cost function \(c:_{+}\), the _optimal transport cost_ between two distributions \(D\) and \(D^{}\) is

\[_{c}(D,D^{})=_{(D,D^{})}_{(,^{})}c(,^{}),\]

where \((D,D^{})\) is the space of all couplings for \(D\) and \(D^{}\). Furthermore, if the cost \(c\) is a _metric_, then the optimal transport cost is also called the _Wasserstein-1_ distance.

Based on Definition 1, we use the distribution discrepancy to measure the difference between the auxiliary and the real OOD data, namely, \(_{c}(D_{X_{}},D_{X_{}})\). Then, we can formally study the impacts of such a discrepancy on the detection performance of the predictor. Under certain assumptions (cf., Corollary 1), we can prove that with high probability, the following generalization bound holds:

\[R_{D}(})_{}(R_{}()+ R_{}())+ L_{c}_{c}(D_{ X_{}},D_{X_{}})+(1/)+(1/ ),\] (4)

where \(}\) is the parameter learned by Eq. (3), i.e., \(}_{}\ _{}()+_{}( )\), \(L_{c}\) is the Lipschitz constant of \(_{}\) w.r.t. the cost function \(c(,)\) (see Theorem 3). In general, the expected detection risk \(R_{D}(})\) measures the expected performance on unseen OOD data given the predictor trained on the auxiliary OOD data. Then, due to the upper bound, the impacts of the OOD distribution discrepancy are reflected by the Wasserstein-1 distance between the auxiliary and the real OOD data, i.e., \(_{c}(D_{X_{}},D_{X_{}})\). Therefore, although classical outlier exposure can improve OOD detection to some extent, it fails to ensure reliable detection of unseen OOD data, in that a larger distribution discrepancy generally indicates a worse guarantee for open-world OOD detection.

The key to improve the detection performance is mitigating the negative impact induced by the OOD distribution discrepancy. To tackle this problem, a simple lemma inspires us:

**Lemma 1**.: _Let \(d(,)\) be the distance to measure the discrepancy between distributions. Given a space \(\) consisting of some OOD distributions, if \(D_{X_{}}\), then_

\[_{D_{X^{}}}d(D_{X^{}},D_{X_{}}) d (D_{X_{}},D_{X_{}}).\] (5)

_If \(d(,)\) is the Optimal Transport Cost in Definition 1, the cost function \(c\) is a continuous metric, and \(\) is the Wasserstein-1 ball with a radius \(>0\), i.e., \(=\{D_{X^{}}:_{c}(D_{X^{}},D_{X_{}} )\}\), then_

\[_{D_{X^{}}}_{c}(D_{X^{}},D_{X_{ }})\{_{c}(D_{X_{}},D_{X_{}})- ,0\}.\] (6)

In the light of Lemma 1, we introduce a specific set of distributions \(\), augmented around the auxiliary OOD distribution. It makes it possible to mitigate the distribution discrepancy, following Eqs. (5) and (6). Therefore, instead of choosing a model \(}\) that directly minimizes the empirical risk in Eq. (3), we target augmenting the auxiliary OOD data within the distribution space \(\), namely,

\[_{}_{}()+ _{D_{X^{}}}_{ D_{X^{ }}}_{}(};),\ _{X_{}},\] (7)

where \(_{X_{}}\) is the empirical form of \(D_{X_{}}\), i.e., \(_{X_{}}=_{i=1}^{m}_{_{ }^{}}\) and \(_{_{}^{}}\) is the dirac measure.

## 4 Learning Framework

This section proposes a general learning framework to mitigate the OOD distribution discrepancy. As aforementioned, we consider an augmented set of OOD distributions to improve OOD detection, thus named _Distributional-Augmented OOD Learning_ (DAL).

To begin with, we need to select a suitable distribution space \(\) for the tractable solutions of Eq. (7). Generally, the choice of \(\) influences both the richness of the auxiliary data as well as the tractability of the resulting optimization problem. Previous works have developed a series of distribution spaces, e.g., the distribution ball based on \(f\)-divergences (Namkoong and Duchi, 2016; Michel et al., 2021) and maximum mean discrepancy (MMD) (Staib and Jegelka, 2019). However, there are several drawbacks for the distribution balls based on \(f\)-divergences and MMD: 1) any \(f\)-divergence-based space \(\) contains only distributions within the same support set as \(_{X_{}}\); and 2) the effective solutions in the MMD-based space have not been provided (Staib and Jegelka, 2019).

Instead, motivated by Sinha et al. (2018); Mehra et al. (2022); Dai et al. (2023) and Theorem 1, we consider the Wasserstein ball. For any \(>0\), we define the augmented OOD distribution set as

\[=\{D_{X^{}}:_{c}(D_{X^{}},_{X_{ }})\},\]

and consider the following optimization problem:

\[_{}_{D}(;)=_{ }_{}()+ _{}(;),\] (8)

where

\[_{}(;)=_{_{c}(D_{X^{}},_{X_{}})}_{ D_{X^{ }}}_{}(_{};).\] (9)

However, the optimization problem in Eq. (8) is intractable due to the infinite-dimensional search for the distribution \(D_{X^{}}\). Fortunately, the following dual theorem provides a solution:

**Theorem 1** (Blanchet and KarthyekRajhahaA. (2016)).: _Let \(c(,)\) be a continuous metric and \(_{}(;)=_{^{}} \{(_{};^{})- c(^{ },)\}\) be the robust surrogate function. Then, for any \(>0\),_

\[_{D}(;)=_{}()+ _{ 0}+_{i=1}^{m}_{}( ;_{}^{i})}.\] (10)

Theorem 1 provides a feasible surrogate for the original optimization problem in Eq. (8), transforming the infinite-dimensional problem to its finite counterpart, i.e., the data feature search. We use Eq. (10) to design our algorithm, cf., Section 4.2.

### Theoretical Supports

This section provides the theoretical support for our DAL. Specifically, 1) Theorem 2 shows that the empirical model given by Eq. (8) can achieve consistent learning performance, and 2) Theorem 3 further demonstrates the expected detection risk estimation, i.e., \(R_{D}()\), with respect to the empirical model given by Eq. (8). All the proofs can be found in Appendix C. To state our theoretical results, we use the notation \(R_{D}(;)\) to represent the ideal form of \(_{D}(;)\), which is defined by

\[R_{D}(;)=R_{}()+ R_{}( ;),\]

where

\[R_{}(;)=_{_{c}(D_{X^{}},D_{X_{ }})}_{ D_{X^{}}}_{}(_{};).\]

Similar to Sinha et al. (2018), our results rely on the covering number (cf., Appendix C.1) for the model classes \(=\{(_{};):\}\) and \(_{}=\{_{}(_{}; ):\}\) to represent their complexity. Intuitively, the covering numbers \((,,L^{})\) and \((_{},,L^{})\) are the minimal numbers of \(L^{}\) balls of radius \(>0\) needed to cover the model classes \(\) and \(_{}\), respectively. Now, we demonstrate that DAL can achieve consistent performance under mild assumptions.

**Theorem 2** (Excess Generalization Bound).: _Assume that \(0(_{};,y) M_{}\), \(0_{}(_{};) M_{_{ }}\), and \(c(,):_{+}\) is a continuous metric. Let \(}\) be the optimal solution of Eq. (8), i.e., \(}_{}_{D}( ;)\). Then with the probability at least \(1-4e^{-t}>0\),_

\[R_{D}(};)-_{}R_{D}( ;)(n,m;t),\] (11)

_for any \(>0\), where_

\[(n,m;t)= M_{}}{}_{0}^{1}( ,M_{},L^{})}d+2M_{}}\] \[+  b_{1}}}^{3}}{^{2}m}}_ {0}^{1}(_{},M_{_{}} ,L^{})}+ b_{2}M_{_{}} },\]

_where \(b_{0}\), \(b_{1}\) and \(b_{2}\) are uniform constants._Furthermore, under proper conditions, one can show that the bound in Eq. (11) can attain \((1/)+(1/)\), i.e., \(R_{D}(};)-_{}R_{D}(;)(1/)+(1/)\). Corollary 1 in Appendix C.5 gives an example to support the above claim. Next, we give a learning bound to estimate the expected detection risk in Eq. (2) w.r.t. the model \(_{}}\) given by Eq. (8).

**Theorem 3** (Risk Estimation).: _Given the same conditions in Theorem 2 and let \(}\) be the solution of Eq. (8), which is given by \(}_{}_{D}( ;)\). If \(_{}(_{};)\) is \(L_{c}\)-Lipschitz w.r.t. \(c(,)\), i.e., \(|_{}(_{};)-_{}( _{};^{})| L_{c}(,^{})\), then with the probability at least \(1-4e^{-t}>0\),_

\[R_{D}(})-}R_{D}( ;)}^{}\{_{c}(D_{X_{}},D_{X_{}})-,0\}+(n,m;t)}_{ },\]

_for any \(>0\), where \((n,m;t)\) is defined in Theorem 2._

The bias term \( L_{c}\{_{c}(D_{X_{}})-,0\}=0\) when \(\) is large enough. Hence, a large \(\) implies a small estimation error. Although a larger \(\) leads to better generalization ability, the approximate risk \(_{}R_{D}(;)\) may become larger. It implies that for practical effectiveness, i.e., small \(R_{D}(})\), there is a trade-off between the approximate risk \(_{}R_{D}(;)\) and the bias \( L_{c}\{_{c}(D_{X_{}},D_{X_{}})-,0\}\) across different choices of \(\). Hence, we need to choose a proper \(\) for open-world detection with unseen data (cf., Section 5.3).

### Proposed Algorithm

In this section, we introduce the algorithm design for DAL, summarized in Algorithm 1. Due to the space limit, we provide further discussions in Appendix E.

``` Input: ID and OOD samples from \(D_{X_{1}Y_{1}}\) and \(D_{X_{}}\); for\(=1\)to num_stepdo  Sample \(S_{}\) and \(T_{}\) from \(D_{X_{1}Y_{1}}\) and \(D_{X_{}}\);  Initialize \(^{i}(, I),\ \ i\{1,,|T_{ }|\}\); for\(=1\)to num_searchdo \(^{i}=_{^{i}}[_{}(( (^{i}_{}+^{i});(^ {i}_{}))-\|^{i}\|_{1}],\ \ i\{1,,|T_{ }|\}\); \(^{i}^{i}+^{i},\ \ i\{1,,|T_{ }|\}\) endfor \(-(-}|}_{i=1}^{|T_{}|}\|^{i}\|,_{ },0\); \(-_{}}|}_{i=1}^{|T_{}|}_{}(( (^{i}_{})+^{i}))+}|}_{i=1}^{|S_{}|}(_{}; ^{i}_{},y^{i}_{}))\); endfor Output: model parameter \(\). ```

**Algorithm 1** Distribution-Augmented OOD Learning (DAL)

**Losses and Cost Function.** Following Hendrycks et al. (2019), we adopt the cross entropy loss to realize \(\) and the KL-divergence between model predictions and uniform distribution for \(_{}\). We also define the cost function \(c\) by the \(l_{1}\) norm, namely, \(c(,^{})=\|-^{}\|_{1}\).

**Algorithm Design.** By Theorem 1, we can address the primary problem in Eq. (8) by the dual problem in Eq. (9). Additionally, following Du et al. (2022), we perturb for the worst OOD data in the embedding space. Denote the model \(_{}=\) with \(\) the classifier and \(\) the feature extractor, we find the perturbation \(\) for the embedding features, i.e., \(()\), of the associated data \(\). The perturbation \(\) should lead to the worst OOD case for the surrogate function in Theorem 1, namely,

\[_{}(;())=_{} \{_{}((()+); ())-\|\|_{1}\},\]

where \(\) denotes the space of embedding features. Note that we abuse the definition of \(_{}\), emphasizing that we perturb the embedding features of \(()\) by \(\).

**Training and Inference.** Our definition of \(_{}(;())\) leads to a particular realization of Eq. (10), which is the learning objective of our DAL. It can be solved by stochastic gradient optimization for deep models, e.g., mini-batch stochastic gradient descent. After training, we use the MSP scoring function by default and discuss the possibility of other scoring functions in Appendix F.3.

**Stochastic Realization.** Algorithm 1 gives a stochastic realization of DAL, where ID and auxiliary OOD mini-batches are randomly sampled in each stochastic iteration, denoted by \(S_{}\) and \(T_{}\) respectively. Therein, we first find the perturbation \(\) that leads to the maximal \(_{}(,())\). The value of \(\) is initialized by random Gaussian noise with the standard deviation \(\) and updated by gradient ascent for num_search steps with the perturbation strength \(\). Then we update \(\) by one step of gradient descent with the learning rate \(\), and further clipping between \(0\) and \(_{}\) to avoid extreme values. Finally, given the proper perturbations for the auxiliary OOD data in \(T_{}\), we update the model parameter \(\) by one step of mini-batch gradient descent.

## 5 Experiments

In this section, we mainly test DAL on the CIFAR (Krizhevsky and Hinton, 2009) benchmarks (as ID datasets). To begin with, we introduce the evaluation setups.

**OOD Datasets.** We adopt the 80 Million Tiny Images (Torralba et al., 2008) as the auxiliary OOD dataset; Textures (Cimpoi et al., 2014), SVHN (Netzer et al., 2011), Places\(365\)(Zhou et al., 2018), LSUN (Yu et al., 2015), and iSUN (Xu et al., 2015) as the (test-time) real OOD datasets. We eliminate those data whose labels coincide with ID cases.

**Pre-training Setups.** We employ Wide ResNet-40-2 (Zagoruyko and Komodakis, 2016) trained for \(200\) epochs via empirical risk minimization, with a batch size \(64\), momentum \(0.9\), and initial learning rate \(0.1\). The learning rate is divided by \(10\) after \(100\) and \(150\) epochs.

**Hyper-parameters Tuning Strategy.** The hyper-parameters are tuned based on the validation data, separated from the training ID and auxiliary OOD data, which is a common strategy in OOD detection with outlier exposure field (Hendrycks et al., 2019; Chen et al., 2021). Specifically, we fix \(=0.001,=10\), and adopt the grid search to choose \(_{}\) from \(\{0.1,0.5,1,5,10,50\}\); \(\) from \(\{1e^{-3},5e^{-3},1e^{-2},5e^{-2},1e^{-},5e^{-},1,5\}\); \(\) from \(\{1e^{-2},1e^{-1},1,10,100\}\); \(\) from \(\{1e^{-3},1e^{-2},1e^{-1},1,10,100\}\); \(\) from \(\{0.1,0.5,1.0,1.5,2.0\}\).

**Hyper-parameters Setups.** For CIFAR-10, DAL is run for \(50\) epochs with the ID batch size \(128\), the OOD batch size \(256\), the initial learning rate \(0.07\), \(_{}=10\), \(=0.01\), \(=10\), \(=1\), and \(=1\). For CIFAR-100, DAL is run for \(50\) epochs with the ID batch size \(128\), the OOD batch size \(256\), the initial learning rate \(0.07\), \(_{}=10\), \(=0.005\), \(=10\), and \(=1\), and \(=1\). For both cases, we employ cosine decay (Loshchilov and Hutter, 2017) for the model learning rate.

**Baseline Methods.** We compare DAL with representative methods, including MSP (Hendrycks and Gimpel, 2017), Free Energy (Liu et al., 2020), ASH (Djurisic et al., 2023), ReAct (Sun et al., 2021), Mahalanobis (Lee et al., 2018), KNN (Sun et al., 2022), KNN+ (Sun et al., 2022), CSI (Tack et al., 2020), VOS (Du et al., 2022), Outlier Exposure (OE) (Hendrycks et al., 2019), Energy-OE (Liu et al., 2020), ATOM (Chen et al., 2021), DOE (Wang et al., 2023), and POEM (Ming et al., 2022). We adopt their suggested setups but unify the backbones for fairness.

**Evaluation Metrics.** The detection performance is evaluated via two representative metrics, which are both threshold-independent: the false positive rate of OOD data when the true positive rate of ID data is at \(95\%\) (FPR\(95\)); and the area under the receiver operating characteristic curve (AUROC), which can be viewed as the probability of the ID case having greater score than that of the OOD case.

Due to the space limit, we test our DAL with more advanced scoring strategies in Appendix F.3 and conduct experiments on the more complex ImageNet (Deng et al., 2009) dataset in Appendix F.10.

### Main Results

The main results are summarized in Table 1, where we report the detailed results across the considered real OOD datasets. First, we reveal that using auxiliary OOD data can generally lead to better results than using only ID information, indicating that outlier exposure remains a promising direction worth studying. However, as demonstrated in Section 3, the OOD distribution discrepancy can hurt its open-world detection power, while previous works typically oversee such an important issue. Therefore, our DAL, which can alleviate the OOD distribution discrepancy, reveals a large improvement over the original outlier exposure. Specifically, comparing with the conventional outlier exposure, our method reveals 1.99 and 0.13 average improvements w.r.t. FPR95 and AUROC on the CIFAR-10 dataset, and 13.46 and 3.65 of the average improvements on CIFAR-100 dataset. For advanced works that consider the OOD sampling strategies, e.g., ATOM and POEM, DAL can achieve much better results, especially for the CIFAR-100 case. The reason is that these methods mainly consider the situationswhere the model capacity is not enough to learn from all the auxiliary OOD data, deviating from our considered issue in OOD distribution discrepancy. Moreover, for the previous works that adopt similar concepts in the worst-case OOD learning, e.g., VOS and DOE, DAL also reveals better results, with 1.29 and 30.89 improvements on the CIFAR-10 dataset and 11.27 and 44.12 improvements on the CIFAR-100 dataset w.r.t. FPR95. It indicates that our theoretical-driven scheme can also guide the algorithm designs with practical effectiveness. Note that many previous works use advanced scoring strategies other than MSP, and thus our experiment above is not completely fair to us. Therefore, in Appendix F.3, we also combine DAL with many advanced scoring strategies other than MSP, which can further improve our performance.

### Hard OOD Detection

We further consider hard OOD scenarios (Sun et al., 2022), of which the test OOD data are very similar to that of the ID cases. Following the common setup (Sun et al., 2022) with the CIFAR-\(10\) dataset being the ID case, we evaluate our DAL on three hard OOD datasets, namely, LSUN-Fix (Yu et al., 2015), ImageNet-Resize (Deng et al., 2009), and CIFAR-\(100\). Note that data in ImageNet-Resize (\(1000\) classes) with the same semantic space as Tiny-ImageNet (\(200\) classes) are removed. We select a set of strong baselines that are competent in hard OOD detection, summarizing the experiments in Table 2. As we can see, our method can beat these advanced methods across the considered datasets, even for the challenging

    &  &  &  & _{356}\)} &  \\   & FPR95\(\) & AUROC \(\) & FPR95\(\) & AUROC \(\) & FPR95\(\) & AUROC \(\) & FPR95\(\) & AUROC \(\) & FPR95\(\) & AUROC \(\) \\    \\   &  \\  MSP & 48.59 & 91.97 & 25.53 & 96.49 & 56.44 & 98.96 & 59.68 & 88.42 & 60.19 & 88.36 & 50.15 & 91.02 \\ Free Energy & 35.21 & 91.24 & 4.42 & 99.06 & 35.84 & 92.56 & 52.46 & 85.35 & 40.11 & 90.02 & 33.21 & 91.64 \\ Asht & 33.98 & 91.79 & 4.76 & 98.98 & 34.38 & 92.64 & 50.90 & 86.07 & 40.89 & 89.79 & 32.98 & 91.85 \\ Mahalanobis & 12.21 & 97.70 & 57.25 & 93.98 & 79.74 & 77.85 & 15.20 & 95.40 & 68.81 & 82.39 & 46.64 & 88.59 \\ KNN & 26.56 & 95.93 & 27.52 & 95.43 & 33.55 & 93.15 & 37.62 & 93.07 & 41.67 & 91.21 & 33.83 & 93.36 \\ KNN+ & 3.28 & 99.33 & 2.24 & 98.90 & 71.85 & 96.65 & 10.87 & 97.72 & 30.63 & 94.98 & 12.97 & 97.32 \\ CSI & 17.37 & 97.69 & 6.75 & 98.46 & 12.58 & 97.95 & 25.65 & 94.70 & 40.00 & 92.05 & 20.47 & 96.17 \\ VOS & 36.55 & 93.30 & 9.98 & 98.03 & 28.93 & 94.25 & 52.83 & 85.74 & 39.56 & 89.71 & 33.57 & 92.21 \\   &  \\   & 2.36 & 99.72 & 1.15 & **99.08** & 2.48 & 99.34 & 5.35 & 98.88 & 11.99 & 97.23 & 4.67 & 98.88 \\ Energy-OE & 0.97 & 99.54 & 1.00 & 99.15 & 2.32 & 99.37 & 3.42 & **99.18** & 9.57 & 97.44 & 3.46 & 98.91 \\ ATOM & 1.00 & 99.53 & 0.61 & 99.53 & 2.15 & **99.0** & 2.52 & 99.10 & 7.93 & 97.27 & 2.84 & 98.97 \\ DOE & 1.80 & 99.37 & **0.45** & 99.65 & 2.00 & 99.36 & 6.95 & 87.15 & 91.58 & 97.28 & 3.97 & 98.88 \\ POGM & 1.20 & 99.53 & 0.80 & 99.10 & **1.47** & 99.26 & 2.93 & 99.13 & 7.65 & 97.35 & 2.81 & 98.87 \\ DAL & **0.80** & **99.65** & 0.90 & 99.46 & 1.70 & 99.34 & **2.30** & 99.14 & **7.65** & **97.45** & **2.68** & **99.01** \\    \\   &  \\  MSP & 84.90 & 71.18 & 60.36 & 85.59 & 82.63 & 75.69 & 83.32 & 75.39 & 83.37 & 73.69 & 78.61 & 75.95 \\ Free Energy & 85.24 & 73.71 & 23.05 & 95.89 & 81.11 & 79.02 & 96.73 & 76.35 & 80.18 & 75.65 & 69.94 & 80.12 \\ Asht & 70.09 & 83.56 & 13.20 & 97.71 & 69.87 & 52.56 & 63.69 & 83.59 & 79.70 & 78.47 & 59.31 & 84.46 \\ Mahalanobis & 51.00 & 88.70 & 91.60 & 60.69 & 38.48 & 91.96 & 47.07 & 89.09 & 82.70 & 74.18 & 72.37 & 82.70 \\ KNN & 52.10 & 88.83 & 68.82 & 70.06 & 42.17 & 90.59 & 42.79 & 89.07 & 92.21 & 61.08 & 59.62 & 81.71 \\ KNN+ & 32.50 & 93.66 & 47.41 & 84.43 & 93.92 & 91.12 & 40.50 & 88.55 & 62.76 & 79.28 & 45.20 & 87.55 \\ CSI & 64.50 & 84.62 & 25.88 & 95.93 & 70.62 & 80.83 & 61.50 & 86.74 & 83.08 & 77.11 & 61.12 & 95.05 \\ VOS & 78.06 & 92.59 & 40.40 & 92.90 & 85.77 & 70.20 & 82.46 & 77.22 & 82.31 & 75.47 & 73.80 & 91.67 \\   &  \\   &  \\  Free Energy & 6.42 & 63.78 & 98.55 & 46.46 & 89.02 & 50.47 & 87.08 \\ Asht & 4.00 & 98.20 & 46.18 & 88.55 & 54.31 & 83.71 \\ KNN+ & 24.88 & 95.75 & 30.52 & 94.85 & 40.00 & 89.11 \\ CSI & 39.79 & 93.63 & 37.47 & 93.93 & 45.64 & 87.64 \\   &  \\  OE & 1.75 & 99.47 & 6.76 & 98.85 & 29.40 & 94.20 \\ DOE & 1.97 & 98.71 & 5.98 & 98.75 & 29.75 & 94.24 \\ POGM & **1.24** & 98.93 & 6.56 & 98.37 & 35.11 & 91.80 \\ DAL & 1.39 & **99.47** & **5.60** & **98.80** & **25.45** & **94.34** \\   

Table 1: Comparison between our method and advanced methodsCIFAR-\(10\) versus CIFAR-\(100\) setting. The reason is that our distributional augmentation directly learns from OOD data close to ID pattern, which can cover hard OOD cases.

### Ablation Study

We further conduct an ablation study to demonstrate two mechanisms that mainly contribute to our open-world effectiveness, namely, OOD data generation and Wasserstein ball constraint.

**OOD Data Generation.** DAL learns from the worst OOD data to mitigate the OOD distribution discrepancy. To understand such an OOD generation scheme, we employ the t-SNE visualization (Van der Maaten and Hinton, 2008) for the ID, the auxiliary OOD, and the worst OOD data. Figure 2 summarizes the results before and after DAL training. Before training, the ID and auxiliary OOD data overlap largely, indicating that the original model is not effective at distinguishing between them. Then, DAL does not directly train the model on auxiliary OOD data but instead perturbs it to further confuse the model beyond the overlap region. After DAL training, the overlap region between ID and auxiliary OOD data shrinks. Additionally, perturbing the original OOD data becomes more difficult, indicating that the model has learned to handle various worst-case OOD scenarios.

**Wasserstein Ball Constraint.** The choice of \(\) determines the radius of the Wasserstein ball. Larger values of \(\) reduce estimation error and improve model generalization, as stated in Theorem 3. However, larger values of \(\) also increase the approximate risk \(_{}R_{D}(;)\) as it becomes more challenging to ensure uniform model performance with increased distributional perturbation. Figure 3 shows the FPR95 curves on the CIFAR-100 dataset for both the real and the surrogate OOD data, revealing the trade-off in selecting \(\). Here, we consider two setups of \(\), i.e., \(=1\) (default) and \(=10\) (large perturbation strength). First, when the perturbation strength is very large (i.e., \(=10\)), the model can easily fail for training if the value of \(\) is also large (e.g., \(=100\)), indicating that large value of \(\) can lead to a large approximation error. However, such an issue can be overcome by selecting a relatively small value of \(\) (e.g., \(=0.5\)).

## 6 Conclusion

Outlier exposure is one of the most powerful methods in OOD detection, but the discrepancy between the auxiliary and (unseen) real OOD data can hinder its practical effectiveness. To address such an issue, we have formalized it as the OOD distribution discrepancy and developed an effective learning framework to mitigate its negative impacts. Specifically, we consider a specific distribution set that contains all distributions in a Wasserstein ball centered on the auxiliary OOD distribution. Then, models trained over worst-case OOD data in the ball can ensure improved performance toward open-world OOD detection. Overall, as pioneers in critically analyzing the open-world setting with theoretical analysis, we are committed to raising attention to the OOD distribution discrepancy issue and encouraging further research in this direction.