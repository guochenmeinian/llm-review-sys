# Meek Separators

and Their Applications in Targeted Causal Discovery

 Kirankumar Shiragur

Eric and Wendy Schmidt Center,

Broad Institute of MIT and Harvard

&Jiaqi Zhang

LIDS, Massachusetts Institute of Technology

Broad Institute of MIT and Harvard

Equal contributions. Alphabetical order.

Caroline Uhler

LIDS, Massachusetts Institute of Technology

Broad Institute of MIT and Harvard

###### Abstract

Learning causal structures from interventional data is a fundamental problem with broad applications across various fields. While many previous works have focused on recovering the entire causal graph, in practice, there are scenarios where learning only part of the causal graph suffices. This is called _targeted_ causal discovery. In our work, we focus on two such well-motivated problems: subset search and causal matching. We aim to minimize the number of interventions in both cases.

Towards this, we introduce the _Meek separator_, which is a subset of vertices that, when intervened, decomposes the remaining unoriented edges into smaller connected components. We then present an efficient algorithm to find Meek separators that are of small sizes. Such a procedure is helpful in designing various divide-and-conquer-based approaches. In particular, we propose two randomized algorithms that achieve logarithmic approximation for subset search and causal matching, respectively. Our results provide the first known average-case provable guarantees for both problems. We believe that this opens up possibilities to design near-optimal methods for many other targeted causal structure learning problems arising from various applications.

## 1 Introduction

Discovering the causal structure among a set of variables is an important problem permeating multiple fields including biology, epidemiology, economics, and social science . A common way to represent the causal structure is through a _directed acyclic graph_ (DAG), where an arc between two variables encodes a direct causal effect . The goal of causal discovery is thus to recover this DAG from data. With observational data, a DAG is generally only identifiable up to its _Markov equivalence class_ (MEC) . Identifiability can be improved by performing interventions on the variables. In particular, a more refined MEC can be identified with both hard and soft interventions , where a _hard_ intervention eliminates the dependency between its target variables and their parents in the DAG and a _soft_ intervention modifies this dependency without removing it .

As intervention experiments tend to be expensive in practice, a critical problem is to design algorithms to select interventions that minimize the number of trials needed to learn about the structure. Previous works have considered both fully identifying the DAG while minimizing the total number/cost of interventions  and learning the most about theunderlying DAG given a fixed budget . While recovering the entire causal graph yields a holistic view of the relationships between variables, it is sometimes sufficient to learn only part of the causal graph for a particular downstream task. This is sometimes termed _targeted causal discovery_ and it has arisen in various different applications recently . The benefit of targeted causal discovery is that the number of required interventions can be significantly less than that needed to fully identify the DAG. In our work, we consider two such problems, _subset search_ and _causal matching_, described in the following.

**Subset Search.** Proposed by , the problem of subset search aims to recover a subset of the causal relationships between variables. Formally, let \(=(V,E)\) denote the underlying DAG. Given a subset of target edges \(T E\), the goal is to recover the orientation of edges in \(T\) with the minimum number of interventions. Subset search problems arise in many applications, including local graph discovery for feature selection , out-of-distribution generalization in machine learning , and learning gene regulatory networks . As a concrete example, consider the study of melanoma , a type of skin cancer. To understand its development for potential treatments, it may be of interest to identify the causal relationships between genes that are known to be relevant to melanoma. In this case, the problem can be formulated as recovering the subset of edges between melanoma-related genes.

**Causal Matching.** Motivated by many sequential design problems,  considered causal matching, where the goal is to identify an intervention which transforms a causal system to a desired state. Formally, let \(V\) be the system variables and \(P\) be its joint distribution which factorizes according to the underlying DAG \(\). Given a desired joint distribution \(Q\) over \(V\), the goal is to identify an intervention \(I\) such that the interventional distribution \(P^{I}\) best matches \(Q\) under some metric. Similar to , we will focus on a special form of this problem, _causal mean matching_, where the metric between \(P^{I}\) and \(Q\) is characterized by the mean discrepancy \(\|_{P^{I}}[V]-_{Q}[V]\|_{2}\). Such problems arise in, for example, cellular reprogramming in genomics, which is of great interest for regenerative medicine . The aim of this field is to reprogram easily accessible cell types into some desired cell types using genetic interventions. Since genes regulate each other via an underlying network, a targeted strategy can infer just enough about the structure in order to match the desired state.

**Contributions.** One of our primary contributions is an efficient algorithm for finding an intervention set \(\) of small size that, when intervened, decomposes the remaining unoriented edges into connected components of smaller sizes. This procedure is powerful in its flexibility to be used to design various divide-and-conquer based algorithms. In particular, we demonstrate this on the two targeted causal discovery problems of subset search and causal matching.2

* For the subset search problem, we obtain an efficient randomized algorithm that in expectation achieves a logarithmic approximation to the minimum number of required interventions (verification number; defined in Section 2).
* For the causal mean matching problem, we derive a randomized algorithm that on average achieves a logarithmic competitive ratio against the optimal number of required interventions.

For both problems, we obtain _exponential_ improvements - our analysis gives the first non-trivial competitive ratio in expectation; in contrast, prior works  show that no deterministic algorithm can achieve a better than linear approximation against the optimal solution for all instances.

Philosophically, the results in our work are a step towards the study of targeted causal discovery problems arising from various applications, where recovering the entire causal graph is unnecessary.

**Organization.** In Section 2, we provide formal definitions and useful results. In Section 3, we state all our main results. We provide our algorithm for Meek separator and its analysis in Section 4. We use the Meek separator subroutine to solve for subset search in Section 5 and causal matching in Section 6. In Section 7, we demonstrate empirically our proposed algorithms on synthetic data.

## 2 Preliminaries and Related Work

### Basic Graph Definitions

Let \(=(V,E)\) be a graph on \(|V|=n\) vertices. We use \(V()\), \(E()\) and \(A() E()\) to denote its vertices, edges, and oriented arcs respectively. When the referred graph is clear from the context, we use \(V\) (or \(E\)) instead of \(V()\) (or \(E()\)) for simplicity. The graph \(\) is fully oriented if \(A()=E()\), and partially oriented otherwise. For any two vertices \(u,v V\), we write \(u v\) if they are adjacent and \(u v\) otherwise. To specify the arc orientations, we use \(u v\) or \(u v\). For any subset \(V^{} V\) and \(E^{} E\), let \([V^{}]\) and \([E^{}]\) denote the vertex-induced and edge-induced subgraphs respectively. Consider a vertex \(v V\) in a directed graph, let \((v)\), \((v)\) and \((v)\) denote the parents, ancestors and descendants of \(v\) respectively. Let \([v]=(v)\{v\}\) and \([v]=(v)\{v\}\). The _skeleton_\(scl()\) of a graph \(\) refers to the graph where all edges are made undirected. A _v-structure_ refers to three distinct vertices \(u,v,w\) such that \(u v w\) and \(u w\). A _simple cycle_ is a sequence of \(k 3\) vertices where \(v_{1} v_{2} v_{k} v_{1}\). The cycle is directed if at least one of the edges is directed and all oriented arcs are in the same direction along the cycle. A partially oriented graph is a _chain graph_ if it contains no directed cycle. In the undirected graph \([E A]\) obtained by removing all arcs from a chain graph \(\), each connected component in \([E A]\) is called a _chain component_. We use \(CC()\) to denote the set of all such chain components, where each chain component \( CC()\) is a subgraph of \(\) and \(V=_{ CC()}V()\).3 For any partially oriented graph, an _acyclic completion_ or _consistent extension_ refers to an assignment of orientations to undirected edges such that the resulting fully oriented graph has no directed cycles.

### Graphical Concepts in Causal Models

Directed acyclic graphs (DAGs) are fully oriented chain graphs, where vertices represent random variables and their joint distribution \(P\) factorizes according to the DAG: \(P(v_{1},,v_{n})=_{i=1}^{n}P(v_{i}(v))\). We can associate a _valid permutation_ or _topological ordering_\(:V[n]\) to any (partially oriented) DAG such that oriented arcs \(u v\) satisfy \((u)<(v)\) (and assigning undirected edges \(u v\) as \(u v\) when \((u)<(v)\) is an acyclic completion). Note that such valid permutation is not necessarily unique. Two DAGs \(_{1},_{2}\) are in the same _Markov equivalence class_ (MEC) if any positive distribution \(P\) which factorizes according to \(_{1}\) also factorizes according \(_{2}\). For any DAG \(\), we denote its MEC by \([]\). It is known that DAGs in the same MEC share the same skeleton and v-structures . A _moral_ DAG is a DAG without v-structures. Figure 1 illustrates this definition. The _essential graph_\(()\) of \([]\) is a partially oriented graph such that an arc \(u v\) is oriented if \(u v\) in _every_ DAG in MEC \([]\), and an edge \(u v\) is undirected if there exists two DAGs \(_{1},_{2}[]\) such that \(u v\) in \(_{1}\) and \(u v\) in \(_{2}\). An edge \(u v\) is a _covered edge_[14, Definition 2] if \((u)\{v\}=(v)\{u\}\). We now give some useful definition and result for graph separators:

**Definition 1** (\(\)-separator and \(\)-clique separator ).: Let \(A,B,C\) be a partition of the vertices \(V\) of a graph \(\). We say that \(C\) is an _\(\)-separator_ if no edge joins4 a vertex in \(A\) with a vertex in \(B\) and \(|A|,|B||V|\). We call \(C\) is an _\(\)-clique separator_ if it is an _\(\)-separator_ and a clique.5

**Lemma 2** (Theorem 1,3 in , instantiated for unweighted graphs).: _Let \(=(V,E)\) be a chordal graph6 with \(|V| 2\). Denote \(()\) as the size of its largest clique. There exists a \(}{{2}}\)-clique separator \(C\) involving at most \(()-1\) vertices. The clique \(C\) can be computed in \((|E|)\) time._

### Interventions and Verifying Sets

An _intervention_\(I V\), associated with random variables \(V\) with joint distribution \(P\) that factorizes according to \(\), is an experiment where the conditional distributions \(P(v(v))\) for \(v I\) are changed. _Hard_ interventions refer to changes that eliminate the dependency between \(v\) and \((v)\), while _soft_ interventions modify this dependency without removing it . Let \(P^{I}\) denote the interventional distribution. Observational data is a special case where \(I=\). An intervention is _atomic_ if \(|I|=1\) and _bounded_ if \(|I| k\). We call a set of interventions \( 2^{V}\) an _intervention set_.

Figure 1: An example of moral DAGs. **(a)** a moral DAG without v-structures. **(b)** an _in_moral DAG.

With observational data, a DAG \(\) is _generally_ only identifiable up to its MEC7, i.e., \(()\). Identifiability can be improved with interventional data and it is known that intervening on \(I\) allows us to infer the edge orientation of any edge cut by \(I\) and \(V I\) and possibly additional edges given by the Meek rules (Appendix A), for both hard  and soft  interventions.8 For intervention set \(\), let the _\(\)-essential graph_\(_{}()\) of \(\) be the essential graph representing all DAGs in \([]\) whose orientations of arcs cut by \(I\) and \(V I\) are the same as \(\) for all \(I\). Figure 2 illustrates these concepts. The aforementioned results state that \(\) can be identified up to \(_{}()\) with observational and interventional data from \(\). We state some useful properties about \(\)-essential graphs from . First, every \(\)-essential graph is a chain graph with chordal chain components. This includes the case of \(=\). Second, orientations in one chain component do not affect orientations in other components. In other words, to fully orient any essential graph \(_{}()\), it is necessary and sufficient to orient every chain component in \(_{}()\).

A _verifying set_\(\) for a DAG \(\) is an intervention set that fully orients \(\) from \(()\), possibly with repeated applications of Meek rules (see Appendix A). In other words, for any graph \(=(V,E)\) and any verifying set \(\) of \(\), we have \(_{}()=\). A _subset verifying set_\(\) for a subset of _target edges_\(T E\) in a DAG \(\) is an intervention set that fully orients all arcs in \(T\) given \(()\), possibly with repeated applications of Meek rules. Note that the subset verifying set depends on the target edges _and_ the underlying ground truth DAG -- the subset verifying set for the same \(T E\) may differ across two different DAGs \(_{1},_{2}\) in the same Markov equivalence class.

For bounded interventions of size at most \(k\), the _minimum verification number_\(_{k}(,T)\) denotes the size of the minimum size subset verifying set for any DAG \(=(V,E)\) and subset of target edges \(T E\). We write \(_{1}(,T)\) when we restrict to atomic interventions. When \(k=1\) and \(T=E\) (i.e., full graph identification),  showed that it is necessary and sufficient to intervene on a minimum vertex cover of the covered edges in \(\). For any intervention set \( 2^{V}\), we denote \(R(,)=A(_{}())  E\) as the set of oriented arcs in the \(\)-essential graph of a DAG \(\). For cleaner notation, we write \(R(,I)\) for one intervention \(=\{I\}\) for some \(I V\), and \(R(,v)\) for one atomic intervention \(=\{\{v\}\}\) for some \(v V\).

**Definition 3**.: For any intervention set \( 2^{V}\), define \(^{}=[E R(,)]\) as the _fully oriented_ subgraph of \(\) induced by the unoriented edges in \(_{}()\). In addition, for \(u V\), let \(_{,}(u)=\{x V:x u R(, )\}\) as the _recovered parents_ of \(u\) by \(\).

## 3 Results

Here we state all the main results of the paper. One of the primary contributions of our work is a randomized algorithm that outputs an intervention set \(\) of small size such that all connected components in the resulting \(\)-essential graph have small sizes. We now formally define such intervention sets as Meek separators. An example of \(\)-Meek separator is shown in Figure 3.

**Definition 4** (\(\)-Meek separator).: We call an intervention set \(\) an _\(\)-Meek separator_ of \(\) if each connected component \( CC(_{}())\) satisfies: \(|V()||V()|\).

Note that Meek separators differ from the traditional graph separators in Definition 1, where in the latter we have bounds on the sizes of connected components in \(\) instead of \(CC(_{}())\). Graph separators of small size may not exist. For example, consider a fully connected DAG \(=(V,E)\)

Figure 2: An example illustrating essential graphs and connected chain components. Suppose the groud-truth DAG is given in Fig. 0(a). (a) the essential graph of \(\). (b) the \(\)-essential graph of \(\) after two atomic interventions \(=\{\{3\},\{4\}\}\), where edges oriented by \(\) are indicated in red. (c) three connected components of \(_{}()\) after removing the oriented edges.

that forms a clique. Any \(\)-graph separator in \(\) must contain at least \((1-)|V|\) vertices, since every pair of vertices in the clique is connected. In contrast, we show that small-sized Meek separators always exist for any DAG. Moreover, we can efficiently find such separators by performing very few interventions, as given by the following theorem which we prove in Section 4.

**Theorem 5** (Meek separator).: _Given an essential graph \(()\) of an unknown DAG \(\), there exists a randomized procedure \(\) (given in Algorithm 1) that runs in polynomial time and adaptively intervenes on a set of atomic interventions \(\) such that we can find a \(}{{2}}\)-Meek separator of size at most \(2\) and \([||](())\),9 where \(()\) denotes the size of the largest clique in \(\)._

Although in the above result, we intervene on \((())\) nodes, our proofs show that there always exists a Meek separator of size at most \(2\). However, to find such a Meek separator without knowing \(\)_a priori_, our algorithm needs to perform \((())\) many interventions. The above result is significant because it can be used to design divide-and-conquer based approaches for various problems. Specifically, we use the Meek separator algorithm as a subroutine to develop approximation algorithms for the subset search and causal matching problems.

**Subset Search.** Our first application of the Meek separator result is that it can be used as a subroutine for approximately solving the subset search problem, as demonstrated in Algorithm 2. The analysis of our algorithm for subset search consists of two parts: (1) a lower bound on the number of interventions required for any algorithm (even with knowledge of \(\)) to solve subset search, and (2) an upper bound on the number of interventions needed for our algorithm to solve subset search. By combining the two parts, we can bound the competitive ratio of our algorithm.

For the first part, we provide a lower bound for the subset verification number described below. Recall that the subset verification number is the minimum number of interventions needed to orient edges in \(T\) by any algorithm with full knowledge of \(\). Therefore it is a natural lower bound on the number of interventions required for any algorithm to solve subset search.

**Lemma 6** (Lower bound).: _Let \(=(V,E)\) be a DAG and \(T E\) be a subset of target edges, then, \(_{1}(,T)_{I V}_{ CC( _{1}())}(E() T ).\)_

For the upper bound, we show that our randomized algorithm, designed using the Meek separator subroutine, is competitive with respect to the aforementioned lower bound. Thus, it achieves a logarithmic approximation to the optimal number of interventions required to solve subset search.

**Theorem 7** (Upper bound).: _Let \(=(V,E)\) be a DAG with \(|V|=n\) and \(T E\) be a subset of target edges. Algorithm 2 that takes essential graph \(()\) and \(T\) as input, runs in polynomial time and adaptively intervenes on a set of atomic interventions \( V\) that satisfies, \([||] n ()_{1}(,T)\) and \(T R(,)\). Furthermore, in the special case of \(T=E\), the solution returned by it satisfies, \([||]( n)_{1}( )\) and \(E R(,)\)._

Importantly, our result provides the _first_ known competitive ratio with respect to the subset verification number \(_{1}(,T)\). Prior to our work, a full-graph identification algorithm that is competitive with respect to \(_{1}()=_{1}(,E)\) was provided by . \(_{1}()\) is not a valid lower bound for the subset search problem. In particular, the value of \(_{1}(,T)\) for certain \(T\) could be substantially smaller than \(_{1}()\). For instance, if \(\) is a clique and \(T\) is an edge incident to a particular node, then \(_{1}(,T)=1\) while \(_{1}()=}{{2}}\). Hence, the benchmark based on the full-graph verification number can be significantly weaker compared to that based on the subset search verification number.

Figure 3: An example comparing a \(}{{2}}\)-Meek separator with a \(}{{2}}\)-graph separator. **(a)** the underlying true DAG \(\). **(b)** the essential graph \(_{}()\) after intervening on the \(}{{2}}\)-Meek separator \(=\{\{2\}\}\), where edges oriented are indicated in red. **(c)** connected components of size \()|}}{{2}}\) in \(_{}()\). **(d)** the undirected version of \(\) with the \(}{{2}}\)-graph separator \(\{2,3\}\) highlighted.

Additionally, for the subset search problem,  showed that there does _not_ exist any _deterministic_ algorithm that achieves a competitive ratio better than \((n)\) with respect to \(_{1}(,T)\). Therefore, our result shows that subset search is part of the large class of problems in algorithm design where _randomization_ substantially helps. Finally, when \(T=E\), we get a \(( n)\) approximation for recovering the entire DAG, which matches the current best approximation ratio by .

**Causal Matching.** Another application of our Meek separator result is for solving the causal matching problem. We consider the same setting as  (details provided in Section 6). In , it was shown that causal mean matching has a unique solution and can be solved by iteratively finding source vertices10 of induced subgraphs of the underlying DAG (Lemma 1 and Observation 1 in ). We therefore provide an algorithm to find source vertices of any DAG, which can be used in the iterative process. Our algorithm uses the Meek separator result and is given in Algorithm 3; the iterative process of using this algorithm to solve causal mean matching is provided in Section 6 and Algorithm 4 in Appendix F.

Our analysis for causal mean matching consists of two layers. We first establish an upper bound on the number of interventions required in Algorithm 3 to identify a source vertex. Then we use this result within the iterative process to derive an upper bound on the number of interventions needed in Algorithm 4 to solve causal mean matching.

**Lemma 8** (Source finding).: _Let \(=(V,E)\) be a DAG and \(U V\) be a subset of vertices. Algorithm 3 that takes essential graph \(()\) and \(U\) as input, runs in polynomial time and adaptively intervenes on a set of atomic interventions \( V\), identifies a source vertex of the induced subgraph \([U]\) with \([||] n ()\)._

**Theorem 9** (Causal mean matching).: _Let \(\) be a DAG and \(^{*}\) be the unique solution to the causal mean matching problem with desired mean \(^{*}\). Algorithm 4 that takes \(()\) and \(^{*}\) as input, runs in polynomial time and adaptively intervenes on set \( V\), identifies \(^{*}\) with \([||] n()|^{*}|\)._

Note that for causal mean matching with unique solution \(^{*}\), \(|^{*}|\) provides a trivial lower bound on the number of interventions required to match the mean. Therefore this result shows that our algorithm achieves a logarithmic approximation to the optimal required number of interventions.

Of note, this is the _first average-case_ competitive algorithm with respect to the instance-based lower bound \(|^{*}|\). Prior to our work,  provided an efficient algorithm, which is \((n)\)-competitive with respect to any algorithm in the _worst case_. Such worst-case analysis is equivalent to the scenario where there exists an adaptive adversary when running the algorithm. This may be limited as it relies on extreme cases that may not accurately represent real-world scenarios. Furthermore, the number of interventions required by any algorithm in the worst case can be much larger than the instance-based lower bound \(|^{*}|\). For example, if \(\) is a clique and \(^{*}\) is an atomic intervention on its source vertex, then \(|^{*}|\) is 1 but the number of interventions required by any algorithm in the worst case is \(n\).11

## 4 Algorithm for Meek Separator

For any general DAG \(\), we consider the largest connected component \( CC(())\). It is well known that \(\) is a moral DAG. If \(\) is a \(1/2\)-Meek separator for \(\), we show that \(\) also serves as a \(1/2\)-Meek separator for \(\) (Appendix D). Therefore, for the remainder of the section, we make the assumption that \(\) is a moral DAG without loss of generality.

### Existence of Size-2 Meek Separator

For any vertex \(v V()\), let \(A_{v}=V()[v]\) and \(B_{v}=(v)\). Note that \(v A_{v}\) and \(v B_{v}\), therefore \(|A_{v}|+|B_{v}|+1=|V()|\). At the heart of our algorithm is the following result which shows the existence of a Meek separator of size at most \(2\) with some nice properties.

**Lemma 10** (Meek separator).: _Let \(\) be a moral DAG and \(K\) be a \(}{{2}}\)-clique separator of \(\). There exists a vertex \(u K\) satisfying the constraints \(|A_{u}||V()|/_{2}\) and \(|A_{v}|>|V()|/_{2}\) for all \(v(u) K\). Furthermore, such a vertex \(u\) satisfies one of the two conditions: 1). either \(u\) is a sink vertex12 of \([K]\), or 2). there exists a vertex \(x\) such that, \(x(u) K\) and \((V()\,[x])(u) K=\) (i.e., \(x\) and \(u\) are consecutive vertices in the valid permutation of clique \(K\)). In both the cases respectively, either \(\{\{u\}\}\) or \(\{\{u\},\{x\}\}\) is a \(}{{2}}\)-Meek separator._

**Proof Sketch.** Here we present an overview of the proof, focusing solely on the case where \(u\) is not a sink node of \(K\), since this case encompasses all the key concepts. To demonstrate the existence (Lemma 10), we begin by establishing the following crucial result.

**Lemma 11** (Connected components).: _Let \(\) be a moral DAG and \(v V()\) be an arbitrary vertex. Any connected component \( CC(_{v}())\) satisfies one of the following conditions: \(V()=v\) or \(V() B_{v}\) or \(V() A_{v}\)._

Returning to Lemma 10, consider vertices \(u\) and \(x\) and note that when we intervene on both \(u\) and \(x\), all the connected components within \(CC(_{\{u,x\}}())\) are either individual nodes or subsets of the subgraph induced by either \(A_{u}\) or \(B_{x}\) or \(B_{u}\)\(\)\(A_{x}\). Since \(|A_{u}|)|}}{{2}}\) and \(|B_{x}|)|}}{{2}}\) (as \(|A_{x}|>)|}}{{2}}\)), we can conclude that all the connected components within \(A_{u}\) or \(B_{x}\) have a maximum size of \(|V()|/2\). Therefore, all that remains now is to bound the size of connected components that are subsets of \(B_{u} A_{x}\). Notably, these connected components \(\) have no intersection with the clique \(K\) and satisfy the condition \(V() V(K)=\). To establish a size bound for these connected components, we prove the following result.

**Lemma 12** (Size of connected components).: _Let \(\) be a graph and \(K\) be an \(\)-separator of \(\). Suppose \(\) is a connected subgraph of \(\) and \(V() K=\), then \(|V()||V()|\)._

Combining all the previous analyses, we conclude that all the connected components within \(CC(_{\{u,x\}}())\) have a maximum size of \(|V()|/2\), and the set \(\{u,x\}\) is a \(1/2\)-Meek separator.

### Binary Search Algorithm

To make the existence result algorithmic, we additionally observe the following structural properties.

**Lemma 13** (Properties of connected components).: _Consider a moral DAG \(\) and let \(K\) be an \(\)-clique separator. Let \(v_{1},v_{2},,v_{k}\) be the vertices of this clique in a valid permutation. We observe that \(|B_{v_{i+1}}||B_{v_{i}}|\), which in turn implies \(|A_{v_{i+1}}||A_{v_{i}}|\). Additionally, we have \(|A_{v_{1}}||V()|\)._

To identify the Meek separator set \(\{u,x\}\), we simply need to locate two consecutive vertices in the clique where \(|A_{u}|)|}}{{2}}\) and \(|A_{x}|>)|}}{{2}}\). The aforementioned result indicates that we can utilize standard randomized binary search procedures to find these vertices efficiently.

```
1:Input: Essential graph \(()\) of a moral DAG \(\).
2:Output: A \(}{{2}}\)-Meek separator \(\).
3:Let \(K\) be a \(}{{2}}\)-clique separator (Lemma 2). Initialize \(i=0\), \(K_{0}=K\) and \(_{0}=\).
4:while\(K_{i}\) is non empty do
5: Let \(u_{i}\) be a uniform random vertex from \(K_{i}\). Intervene on \(u_{i}\).
6: Find \(_{i} CC(_{u_{i}}())\) such that \(|V(_{i})|\) is maximized.
7:if\(|V(_{i})|)|}}{{2}}\) then\(\)\(u_{i}\) is a \(}{{2}}\)-Meek separator.
8: Let \(u=u_{i}\), \(=_{j=1}^{i-1}\{\{u_{j}\}\}\), and return\(\).
9: Let \(P_{u_{i}}=\{v K v u_{i}\}\) and \(Q_{u_{i}}=\{v K v u_{i}\}\).
10:if there exists a directed path from \(u_{i}\) to \(_{i}\) then\(\)\(V(_{i})(u_{i})\) and \(|A_{u_{i}}|)|}}{{2}}\)
11: Update \(K_{i+1}=K_{i} Q_{u_{i}}\) and \(u=u_{i}\).
12:else
13: Update \(K_{i+1}=K_{i} P_{u_{i}}\) and \(x=u_{i}\).
14: Update \(i i+1\).
15: Let \(=\{\{x\}\}_{j=1}^{i-1}\{\{u_{j}\}\}\).
16:return\(\).
```

**Algorithm 1**\((,}{{2}})\)

Figure 4 gives an example of the proposed Algorithm.13 In general, at each iteration \(i\), we randomly select a vertex \(u_{i}\) and determine the connected component \(_{i}\) with the maximum cardinality. If

\(|V(_{i})|)|}}{{2}}\), we have found a Meek separator. Otherwise, we verify if a directed path exists from \(u_{i}\) to \(_{i}\). In appendix (Lemma 19), we demonstrate that if such a path exists, then \(V(_{i})(u_{i})=B_{u_{i}}\), implying that \(|A_{u_{i}}|)|}}{{2}}\) (since \(|A_{u_{i}}|+|B_{u_{i}}|+1=|V()|\)). To confirm if \(u_{i}\) is the desired vertex \(u\), we need to verify that all its descendants satisfy \(|A_{v}|>)|}}{{2}}\). Consequently, we recursively examine the vertices in \(K\) that are descendants of \(u_{i}\) in \(K_{i}\). Similarly, if the \(u_{i}\) to \(H_{i}\) path doesn't exist, then Lemma 19 implies that \(V(_{i}) V()[u_{i}]=A_{u_ {i}}\) and \(|A_{u_{i}}|>)|}}{{2}}\). Therefore, to find the desired vertex \(u\), we recursively examine the vertices in \(K\) that are ancestors of \(u_{i}\) in \(K_{i}\). A similar analysis holds for the desired vertex \(x\), and intuitively we conclude that the above algorithm outputs an intervention set that contains vertices \(u\) and \(x\) satisfying the conditions of Lemma 10. The guarantees of the above algorithm are summarized below.

**Lemma 14** (Output of \(\)).: _The algorithm \(\) performs at most \((|K|)\) interventions in expectation and finds a vertex \(u K\) that is either a \(1/2\)-Meek separator or satisfies the following conditions: \(|A_{u}|)|}}{{2}}\) and \(|A_{v}|>)|}}{{2}}\) for all \(v(u) K\)._

All proofs can be found in Appendix D. Combining Lemma 14 and Lemma 10 results in Theorem 5.

## 5 Algorithm for Subset Search

Here we present our algorithm for the subset search problem that proves Theorem 7. Our algorithm is based on the Meek separator subroutine and a description of the algorithm is given in Algorithm 2. In the remainder of this section, we present a proof sketch to establish the guarantees.

```
1:Input: Essential graph \(()\) of a DAG \(\) and a set of target edges \(T E()\).
2:Output: Atomic intervention set \(\) s.t. \(T R(,)\).
3:Initialize \(i=0\) and \(_{0}=\).
4:while\(T R(,_{i})\)do
5: Initialize \(_{i}\)
6:for\( CC(_{_{i}}())\) of size \(|| 2\) and \(E() T\)do
7: Invoke \(_{}=(,}{{2 }})\). Update \(_{i}=_{i}_{}\).
8: Update \(_{i+1}_{i}_{i}\) and \(i i+1\).
9:return\(_{i}\).
```

**Algorithm 2** Atomic adaptive subset search.

_Correctness._ Upon the termination of our algorithm, it is worth noting that all the connected components that encompass the target edges \(T\) have a size of \(1\). This observation leads to the immediate implication that all the edges belonging to \(T\) are oriented.

_Competitive Ratio._ To bound the competitive ratio, we first bound the total cost of our algorithm and then relate it to the subset verification number. To bound the total cost, we first show that the number of outer loops in our algorithm is at most \(( n)\). This holds because, in each outer loop, the size of the connected components containing the target edges \(T\) decreases at least by a multiplicative factor of \(}{{2}}\). After \(( n)\) such loops, all these connected components will have a size of \(1\), implying that all edges in \(T\) are successfully oriented, leading to the termination of our algorithm.

Next, to bound the cost per outer loop, we consider \(_{i}\), which represents the set of interventions performed during the \(i\)-th loop. It is worth noting that \(_{i}\) is a union of Meek separators \(_{}\) for

Figure 4: An example of Algorithm 1 finding the Meek separator in the ground-truth DAG in Fig. 2(a). The sets \(K_{i}\) are highlighted; oriented edges in \(_{u_{i}}()\) by intervening on \(u_{i}\) are in grey; connected components in \(CC(_{u_{i}}())\) are in black. **(a)** suppose we take \(K_{0}=K=V()\) as the \(}{{2}}\)-clique separator. **(b)** suppose we pick \(u_{0}=1\) from \(K_{0}\), then \(K_{1}=K_{0}_{u_{0}}=\{2,3,4\}\). **(c)** suppose we pick \(u_{1}=4\) from \(K_{1}\), then \(K_{2}=K_{1} P_{u_{1}}=\{2,3\}\). **(d)** suppose we pick \(u_{2}=2\) from \(K_{2}\), then Algorithm 1 terminates (line 7) returning meek separator \(=\{2\}\) and \(=\{1,4\}\) that helps find it.

each connected component \( CC(_{_{i}}())\) such that \(E() T\). Thus, the cost per loop can be expressed as \(|_{i}|=_{ CC(_{_{i}}( ))}(E() T)| _{}|\). By Theorem 5, the Meek separator we obtained for each \(\) is of size \((())(())\). We can conclude that the cost per iteration is at most: \(|_{i}|((G))_{ CC(_{_{i}}())}(E() T)\). To relate this cost to the subset verification number, we utilize the lower bound result from Lemma 6, which states that: \(_{1}(,T)_{ V}_{ CC (_{}())}(E() T )\). Combining the above equations, we obtain \(|_{i}|(())_{1}(,T)\). As there are at most \(( n)\) iterations in total, the total cost of our algorithm can be bounded by: \(( n())_{1}(,T)\). We defer the detailed proofs of Theorem 7 (upper bound) and Lemma 6 (lower bound) to Appendix E.

## 6 Algorithm for Causal Mean Matching

Here we study the causal mean matching problem. En route, we provide an algorithm that, given an essential graph \(()\) of a DAG \(\) and a subset \(U\) of vertices, finds a source vertex within the induced subgraph \([U]\). This source vertex, denoted as \(s\), satisfies the property that there exists no vertex \(v U\) such that \(v(s)\). The description is given in Algorithm 3. This algorithm identifies a source vertex of \(U\) in \(( n())\) interventions and its guarantees are summarized in Lemma 8. Below, we present a concise overview of its proof.

```
1:Input: Essential graph \(()\) of a DAG \(\) and a subset of vertices \(U V()\).
2:Output: Atomic intervention set \(\) and a source vertex in \(U\).
3:Initialize \(i=0\) and \(_{0}=\).
4: Let \(C_{0}=\{ CC(_{_{0}}()) V( ) U\}\) and let \(_{0} C\) be a connected component with no incoming directed path from any other component \( C_{0}\).
5:while\(|V(_{i}) U|>1\)do
6: Compute \(_{i}=((_{i}),}{{2}})\) and intervene on it.
7: Let \(C_{i+1}=\{ CC(_{_{i}}(_{i}))  V() U\}\) and let \(_{i+1} C_{i+1}\) be a connected component with no incoming directed path from any other component \( C_{i+1}\).
8: Let \(_{i+1}=_{i}_{i}\). Increment \(i\) by 1.
9:return\(_{i}\) and \(V(_{i})\).
```

**Algorithm 3**\(((),U)\)

As stated in the description, our algorithm invokes the Meek separator in each iteration and identifies the connected component containing a source vertex \(s\) and recurses on it. This connected component can be identified by finding the component that has no incoming directed path from any other components. Then as we invoke the Meek separator in each iteration, the size of the connected component decreases at least by a factor of \(}{{2}}\). Therefore the algorithm terminates in \(( n)\). Since we perform at most \((())\) interventions in each iteration, the total number of interventions performed by our algorithm is at most \(( n())\). This concludes our proof overview for the source-finding algorithm. In the remainder, we use it to solve the causal mean matching problem.

_Causal Mean Matching._ We consider the same setting as in  with atomic interventions, where the goal is to find a set of shift interventions \(\) such that the mean of the interventional distribution \(_{P^{}}[V]\) matches a desired mean \(^{*}\). An atomic shift intervention set \(\) with shift values \(\{a_{i}\}_{i}\) modifies the conditional distribution as \(P^{}(v_{i}=x+a_{i} v_{(i)})=P(v_{i}=x v_{ (i)})\) for \(i\). In particular,  show that there exists a unique solution \(^{*}\) such that \(_{P^{^{*}}}[V]=^{*}\) and to find such \(^{*}\), it suffices to iteratively find the source vertices of all vertices whose means differ from that of \(^{*}\). The intuition behind this is that (1) intervening on other vertices will not change the mean of the source vertex, and (2) the shift value of the source vertex equals exactly the mean discrepancy with respect to \(^{*}\). Thus, our Algorithm 3 can be used as a subroutine to solve for \(^{*}\) iteratively. We describe the full procedure in Algorithm 4 in Appendix F. Our analysis of Lemma 8 is used to derive the guarantee of Algorithm 4 in Theorem 9. Details are deferred to Appendix F.

## 7 Experiments

Here, we implement our Meek separator to solve for subset search and causal mean matching discussed in the previous sections. Details and extended experiments are provided in Appendix G.

**Subset Search.** For this experiment, we consider the local causal graph discovery problem where the goal is to identify the target edges within an \(r\)-hop neighborhood of a random vertex \(v\). We compare our method in Algorithm 2 and its variant, MeekSep and MeekSep-1, against four carefully constructed baselines. The variant MeekSep-1 runs Algorithm 2 but checks after performing every intervention inside line 7 and terminates if the subset search problem is solved. The Random baseline intervenes on a randomly sampled vertex at every step and terminates when the subset search problem is solved. The Coloring-FG baseline identifies the full causal graph using , where Coloring-NI is the variant that only identifies the subgraph induced by vertices incident to the target edges, similar to the method suggested by . Our proposed methods consistently outperform these baselines across different graph sizes in Figure 4(a). Finally, Verification shows the subset search verification number  which serves as a lower bound.

**Causal Mean Matching.** We consider Erdos-Renyi graphs  with \(50\) vertices where the ground-truth solution \(^{*}\) is randomly sampled from these vertices. We compare our Algorithm 4 and its variant, MeekSep and MeekSep-1, against four baselines proposed in . The variant is in the fashion described for the subset search. The Random and CliqueTree baselines use the same backbone as MeekSep, but search for source vertex using randomly sampled interventions and the clique-tree strategy proposed in , respectively. Coloring-FG first identifies the full graph then solves for \(^{*}\), whereas Verification is the lower bound that uses \(|^{*}|\) interventions. The number of extra interventions relative to Verification is shown in Figure 4(b), where we observe our methods to outperform Random and Coloring-FG. Empirically, our approach is competitive with the state-of-the-art method CliqueTree while providing far better theoretical guarantees.

## 8 Discussion

In this work, we introduced Meek separators. In particular, we established the existence of a small-sized Meek separator and presented efficient algorithms to compute it. Meek separators hold great potential for designing divide-and-conquer strategies to tackle various causal discovery problems. We demonstrated this by designing efficient approximation algorithms for two important problems in targeted causal discovery: subset search and causal mean matching. Our approximation guarantees are exponentially better than the guarantees achievable by any deterministic algorithm for both problems. It would be an interesting future research endeavour to explore the application of Meek separators to address other problems in the field of causal discovery.

**Limitations and Future Work.** We made several standard assumptions such as causal sufficiency and we considered the noiseless setting. In future work, it would be of interest to relax some of these assumptions. Particularly, we believe that investigating the sample complexity for conducting targeted causal discovery would be an important avenue to pursue.

In addition to these broad questions, there are some specific open problems. One such problem is understanding the weighted subset search problem. Although efficient algorithms have been proposed in  to compute weighted subset verification numbers, the weighted subset search problem remains open. Exploring its approximability would be an interesting research direction. Moreover, for the causal mean matching problem, extending the matching criteria beyond the mean to encompass other higher-order moments of the distribution would be a natural and compelling future direction.

Figure 5: Meek separator for **(a)** subset search and **(b)** causal matching. Each dot is averaged across \(20\) DAGs, where the error bar shows \(0.5\) and \(0.2\) standard deviation in (a) and (b), respectively.