# Improved Algorithms for Contextual Dynamic Pricing

Matilde Tullii

FairPlay Team, CREST, ENSAE

&Solenne Gaucher

FairPlay Team, CREST, ENSAE

&Nadav Merlis

FairPlay Team, CREST, ENSAE

&Vianney Perchet

FairPlay Team, CREST, ENSAE - Criteo AI Lab

Equal contribution.

###### Abstract

In contextual dynamic pricing, a seller sequentially prices goods based on contextual information. Buyers will purchase products only if the prices are below their valuations. The goal of the seller is to design a pricing strategy that collects as much revenue as possible. We focus on two different valuation models. The first assumes that valuations linearly depend on the context and are further distorted by noise. Under minor regularity assumptions, our algorithm achieves an optimal regret bound of \(}(T^{2/3})\), improving the existing results. The second model removes the linearity assumption, requiring only that the expected buyer valuation is \(\)-Holder in the context. For this model, our algorithm obtains a regret \(}(T^{d+2/d+3})\), where \(d\) is the dimension of the context space.

## 1 Introduction

Setting a price and devising a strategy to dynamically adjust it poses a fundamental challenge in revenue management. This problem, known as dynamic pricing or online posted price auction, finds applications across various industries and has received significant attention from economists, operations researchers, statisticians, and machine learning communities. In this problem, a seller sequentially offers goods to arriving buyers by presenting a one-time offer at a specified price. If the offered price falls below the buyer's (unknown) valuation of the item, a transaction occurs, and the seller obtains the posted price as revenue. Conversely, if the price exceeds the buyer's valuation, the transaction fails, resulting in zero gain for the seller. Crucially, the seller solely receives binary feedback indicating whether the trade happened. Her objective is to learn from this limited feedback how to set prices that maximize her cumulative gains while ensuring that transactions take place. In this paper, we study the problem of designing an adaptive pricing strategy, when the seller can rely on contextual information, describing the product itself, the marketing environment, or the buyer.

While this problem has been extensively studied, previous results either rely on strong assumptions on the structure of the problem, greatly limiting the applicability of such approaches, or achieve sub-optimal regret bounds. In this work, we aim to improve both aspects--achieving better regret bounds while making minimal assumptions about the problem. Specifically, we study two different models for the valuation of buyers as a function of the context: _1) linear valuations_, where the item valuation of buyers is an unknown noisy linear function of the context; and _2) non-parametric valuations_, where the valuation is given by an unknown Holder-continuous function of the contextual information, perturbed by noise.

### Related Work

Dynamic pricing has been extensively studied for half a century [19; 26], leading to rich research on both theoretical and empirical fronts. For comprehensive surveys on the topic, we refer the readers to [6; 12]. While earlier works assumed that the buyer's valuations are i.i.d. [18; 5; 16; 9], recent research has increasingly focused on feature-based (or contextual) pricing problems. In this scenario, product value and pricing strategy depend on covariates. Pioneering works considered valuations depending deterministically on the covariates. Linear valuations have been the most studied [3; 15; 11; 20], yet a few authors have also explored non-parametric valuations .

Recent works have extended these methods to random valuations, mainly assuming that valuations are given by a function of the covariate, distorted by an additive i.i.d. noise. As this poses more challenges, authors have mostly focused on the simplest case of linear valuation functions, under additional assumptions. Initial studies assumed knowledge of the noise distribution [11; 15; 30]. This assumption was later relaxed, albeit with additional regularity requirements on the cumulative distribution function (c.d.f.) of the noise and/or the reward function [14; 22], and then again by , that achieves a regret bound of \(}(T^{}{{4}}})\) for linear valuations, while assuming only the boundedness of the noise. Closest to our work [14; 21] also focus on the case in which the only regularity required is the Lipschitzness of the CDF. Their approaches show some similarities with our work but still achieve suboptimal regret rates. A more detailed comparison between ours an their algorithms is presented later on in the paper. Other parametric models have been explored, with, for example, generalized linear regression models , though they also require strong assumptions, including quadratic behavior of the reward function around each optimal price. Few works have considered non-deterministic valuations with non-parametric valuation functions. Among those,  consider Lipschitz-continuous valuation functions of \(d\)-dimensional covariates. They achieve a regret of order \(}(T^{d+2/d+4})\), assuming again quadratic behaviour around optimal prices. We refer to Table 1 for a comprehensive comparison between different previous works, their assumptions and regret bounds.

To improve on previous results, we design algorithms that share information on the noise distribution across different contexts. This idea relates to methods used in _cross-learning_, a research direction stemming from online bandit problems with graph feedback [23; 2]. In this framework, introduced by  and further studied in , when choosing to take action \(i\) in context \(x_{t}\), the agent observes the reward \(r_{i}(x_{t})\) along with rewards \(r_{i}(x^{}_{t})\) associated with other contexts \(x_{t^{}}\). Our algorithms leverage similar principles to learn information usable across different contexts. However, compared to the typical problems addressed by cross-learning methods (e.g., first-price auctions, sleeping bandits, multi-armed bandits with exogenous costs), the contextual dynamic problem is more complex due to the intricate dependence of the reward on the unknown valuation function.

### Outline and Contributions

In this work, we tackle the problem of dynamic pricing with contextual information. We consider two models for the expected valuations of the buyer, assuming respectively that they are given by a

  Model & Noise Assumption & Regret \\   & \(F\) is known & \((T^{}{{3}}})\) \\   & \(F\) is known or parametric, and log-concave & \(}(T^{}{{2}}})\) \\   & \(F\) has \(m\)-th order derivatives & \(}(T^{2m+1/4m-1})\) \\   & \(F^{}\) is bounded & \(}(T^{2/3})\|-\|_{1}T\) \\   & \(F\) is Lipschitz & \(}(T^{}{{4}}})\)[14; 21], \(}(T^{}{{3}}})\)**[this work]** \\   & Bounded noise & \(}(T^{}{{4}}})\) \\   & \((x,)\) is quadratic around its maximum & \(}(T^{d+2/d+4})\) \\  & for all \(x\), \(F\) and \(g\) are Lipschitz & \(}(T^{d+2/d+4})\) \\    & \(F\) is Lipschitz and \(g\) is HÃ¶lder & \(}(T^{d+2}{{4}}+3})\)**[this work]** \\  

Table 1: Summary of existing regret bounds. \(g\) is the expected valuation function, \(F\) is the c.d.f. of the noise, and \((x,p)\) is the reward for price \(p\) and context \(x\), defined in Section 2.1.

linear function, or by a non-parametric function. For both models, we present a general algorithmic scheme called Valuation Approximation - Price Elimination (VAPE), and provide bounds on its regret in both models:

* In the linear model, we obtain a regret of \((T^{2/3})\), assuming only that the c.d.f. of the noise is Lipschitz. This concludes an extensive series of papers on the topic, as it establishes the minimax optimal regret rate and proves it is attainable under minimal assumptions.
* In the non-parametric model, we obtain a regret rate of \((T^{d+2/d+3})\), assuming only the Lipschitz-continuity of the noise and the Holder one of the valuation function. This result is the first of its kind under such minimal assumptions.

The rest of the paper is organized as follows. We begin by presenting the model and summarizing the notations used throughout the paper in Section 2.1. Section 2.2 outlines our assumptions and compares them with those in previous works. In Section 2.3, we discuss the main sources of difficulty of the problem and highlight the importance of information sharing in contextual dynamic pricing. In Section 3, we present our algorithmic scheme, VAPE, and provide an initial informal result bounding its regret. Then, in Section 4, we apply this algorithmic scheme to linear valuations and provide a bound on its regret. Finally, in Section 5, we extend this algorithm to non-parametric valuations.

## 2 Preliminaries

### Model and Notations

The problem of dynamic pricing with contextual information is formalized as follows. At each step \(t T\), a context \(x_{t}^{d}\), describing a sale session (product, customer, and context) is revealed. The customer assigns a hidden valuation \(y_{t}\) to the product, and the seller proposes a price \(p_{t}\), based on \(x_{t}\) and on historical sales records. If \(p_{t} y_{t}\), the trade is successful, and the seller receives a reward \(y_{t}\); otherwise the trade fails. The seller's only feedback is the binary outcome \(o_{t}=\{p_{t} y_{t}\}\). We assume that the seller's valuation is given by

\[y_{t}=g(x_{t})+_{t}, \]

where \(g:^{d}\) is the valuation function, and \(_{t}\) is a centered, bounded, i.i.d. noise term, independent of \(x_{t}\) and of \((x_{s},p_{s},_{s})_{s<t}\). In the present paper, we consider successively linear and non-parametric valuation functions \(g\) in Sections 4 and 5. The seller's objective is to maximize the sum of her cumulative earnings. We denote by \((p,x_{t})\) the expected reward of the seller if she posts a price \(p\) for a product described by covariate \(x_{t}\):

\[(x_{t},p)=[p\{p y_{t}\}]p,x_{t}].\]

Adopting the terminology of the literature on multi-armed bandits, we measure the performance of our algorithm and the difficulty of the problem through the regret \(R_{T}\), defined as

\[R_{T}=_{t=1}^{T}_{p}(x_{t},p)-_{t=1}^{T}(x_{t}, p_{t}).\]

NotationsThroughout this paper, we make use of the following notation. We denote by \(\|\|\) the Euclidean norm. For all \(A,B\), we denote by \([A,B]\) the set \(\{A,A+1,,B\}\). \(R_{T} B_{T}\) (resp. \(R_{T}=}(B_{T})\)) means that there exists a (possibly problem-dependent) constant \(C\) such that \(R_{T} CB_{T}\) (resp. \(R_{T}=((T)^{C}B_{T})\)). Finally, \(f\) and \(F\) denote the p.d.f. and c.d.f. of the noise, respectively.

### Assumptions

For both valuation models, we make the following assumptions on the context and noise distribution.

**Assumption 1**.: _Contexts and expected valuations are bounded: \(\|x_{t}\|_{2} B_{x}\) and \(|g(x_{t})| B_{g}\) a.s._

This assumption is classical in contextual dynamic pricing problems. We underline that contexts do not need to be random. In particular, they can be chosen by an adaptive adversary, aware of the seller's strategy, and based on past realizations of \((x_{s},p_{s},_{s})_{s<t}\). Assumption 1 is milder than the i.i.d. context assumption appearing in .

Dynamic pricing strategies mostly assume that the buyer's valuations are bounded. To enforce this, we assume that the noise is bounded; moreover, we assume that its c.d.f. Lipschitz continuous.

**Assumption 2**.: _The noise \(_{t}\) is bounded: \(|_{t}| B_{}\) a.s. Moreover, its c.d.f. \(F\) is \(L_{}\)-Lipschitz continuous: for all \((,^{})^{d}\), \(|F()-F(^{})| L_{}|-^{}|.\)_

Assumption 2 is weaker than most of the assumptions in related works. For example,  require both \(F\) and \(1-F\) to be log-concave.  assume that \(F\) has \(m\)-th derivative, and that \(-}{{F^{}()}}\) is greater than some positive constant for all \(\), achieving a regret of order \(}(T^{}{{4}}})\). In the case \(m=1\), they propose a different algorithm, reaching a regret \(}(T^{}{{4}}})\).  consider Lipschitz-continuous noise, under the additional assumption that, for every \(x\), \(p^{*}(x)*{arg\,max}_{p}(x,p)\) is unique, and that \(F^{}\) is bounded.  assume quadratic behaviour around every maxima: for every \(x\), \(p^{*}(x)*{arg\,max}_{p}(x,p)\), \(p^{*}(x)\) is unique, and for all \(p\), \(C(p^{*}(x)-p)^{2}(x,p^{*}(x))-(x,p) C^{}(p^{*}(x)-p)^{2}\) for some constants \(C,C^{}\). The only work considering non-Lipschitz c.d.f. is ; however, they achieve a higher regret bound of \(}(T^{}{{4}}})\).

### Information Sharing in Contextual Dynamic Pricing

For \(\), we denote \(D()=(_{t})=1-F()\), the demand function associated with the noise \(_{t}\). Note that, under Assumption 2, \(D\) is \(L_{}\)-Lipschitz continuous. Straightforward computations show that, for any _price increment_\(\), the expected reward corresponding to the price \(p=g(x_{t})+\) in the context \(x_{t}\) is given by

\[(x_{t},g(x_{t})+)=(g(x_{t})+)D(). \]

Equation (2) highlights the intricate roles played by the expected valuation \(g(x_{t})\) and the price increment \(=p-g(x_{t})\) in the reward. An immediate consequence is that the optimal price increment \(\) depends on the value of \(g(x_{t})\). Intuitively, if \(g(x_{t})\) is large, the seller should choose \(\) to be small to ensure a high probability \(D()\) to perform a trade. However, for smaller values of \(g(x_{t})\), the seller might prefer a larger \(\) to ensure significant rewards when a trade occurs. Importantly, there is no explicit relationship between the optimal increments \(\) for different valuations \(g(x_{t})\), so knowing the optimal price for a value \(g(x_{t})\) does not allow optimal pricing for a different value \(g(x_{t^{}})\).

This reasoning suggests that the optimal price increment may span a wide range of values as the expected valuation \(g(x_{t})\) varies. Unfortunately, as is typical in bandit problems, it is necessary to estimate the reward function around the optimal price with high precision to ensure low regret. Consequently, solving the dynamic pricing problem may entail estimating the demand function precisely across a broad range of price increments. This marks a significant departure from non-contextual dynamic pricing and non-parametric bandit problems, where precise estimation of the reward function is often only necessary around its (single) maximum. Thus, the contextual dynamic pricing problem might be more challenging than its non-contextual counterpart, potentially leading to higher regret. This intuition is supported by the fact that straightforward application of basic bandit algorithms, even in the most simple linear model, leads to regret higher than the rate of order \(}(T^{}{{3}}})\) encountered in non-contextual dynamic pricing problems, as we show in the following discussion.

Naive bandit algorithms for contextual dynamic pricing.As a first attempt, one might apply a simple explore-then-commit algorithm. Such algorithms start with an exploration phase to obtain uniformly good estimates of both \(g\) and of the demand function \(D\) over a finite grid of price increments \(\{_{k}\}_{k}\). Then, in a second exploitation phase, prices are set greedily to maximize the estimated reward. To bound the regret of this approach, note that uniform estimation of \(D\) over the grid \(\{_{k}\}_{k}\) with precision \(\) requires \(^{-2}||\) estimation rounds. Moreover, the Lipschitz continuity of the reward function implies a discretization error of order \(}{{||}}\). Classical arguments suggest that the regret would be at least \(T(+}{{||}})+||^{-2}\), which is minimized for \(=}{{||}}=T^{-}{{4}}}\). Thus, this approach would lead to a regret of order \(}(T^{}{{4}}})\).

Another approach, akin to that used in , involves partitioning the covariate space into bins and running independent algorithms for non-parametric bandits (such as CAB1 ) within each bin. Let us assume, for simplicity, contexts in \(\), and that we partition this segment into \(K\) bins. Then, the discretization error is \(}{{K}}\). Classical results show that the regret in one bin is \(}(T_{K}^{}{{3}}})\), where \(T_{K}=7/k\) is the number of rounds in each bin. Consequently, the regret is \(}(}{{K}}+K(}{{K}})^{}{{3}}})\), which is minimized for \(K=T^{}{{4}}}\), resulting in a regret \(}(T^{}{{3}}})\).

Thus, both approaches - using either independent bandit algorithms over binned contexts or common exploration rounds followed by an exploitation phase - suffer a regret of order \(T^{}{{4}}}\) in the linear model. This raises the question of whether this rate is optimal for the linear model, and if the contextual dynamic pricing problem is indeed more difficult than the non-contextual one. Strikingly, we show that this is not the case. We rely on an intermediate approach, based on regret-minimizing algorithms for each valuation level \(g(x_{t})\) that _share information_ across different values of \(g(x_{t})\). We show that it achieves an optimal regret rate of order \(}(T^{}{{3}}})\) in the linear valuation model. Moreover, it achieves a rate of order \(}(T^{}{{2}}}{{3}}})\) in the non-parametric valuation model under minimal assumptions.

## 3 Algorithmic Approach

In this section, we present the general algorithmic approach that we use to tackle dynamic pricing with covariates, called **Valuation Approximation** - **Price Elimination** (VAPE). Before presenting the full scheme, described in Algorithm 1, we start with some intuition that leads to its design. Then, we provide a first analysis of the regret of this algorithm.

### Outline of the Algorithm

Equation (2) highlights how the reward is influenced by the expected valuation \(g(x_{t})\) and by the demand at the price increment \(=p_{t}-g(x_{t})\). To separate the effect of these terms, we estimate \(g\) and \(D\) independently. Hereafter, we assume that the valuations \(y_{t}\) are bounded, in \([-B_{y},B_{y}]\).

**Estimation of \(g\).** To estimate \(g(x_{t})\), we rely on the following observation: when prices \(p_{t}\) are uniformly chosen from the interval \([-B_{y},B_{y}]\), the random variable \(2B_{y}(o_{t}-1/2)\) can serve as an unbiased estimate of \(g(x_{t})\) conditioned on \(x_{t}\). Given that \(2B_{y}(o_{t}-1/2)\) is bounded, classical concentration results can be employed to bound the error of our estimates for \(g(x_{t})\). Thus, in each round, we test whether our estimate of \(g(x_{t})\) is precise enough to ensure that the error \(g(x_{t})-(x_{t})\) is small. If this is not the case, we conduct a **Valuation Approximation** round by setting a uniform price. In the next sections, we consider linear and non-parametric valuation functions, and we discuss how to ensure sufficient precision in a limited number of valuation approximation rounds.

Previous approaches for estimating valuation functions in the linear model include the regularized maximum-likelihood estimator [15; 30], which requires knowledge of the noise distribution. Another approach used in  relies on the relation between estimating a linear valuation function from binary feedback and the classical linear classification problem. The authors propose recovering the linear parameters \(\) through logistic regression; however, they do not provide an explicit estimation rate for \(\).  use the EXP-4 algorithm to aggregate policies corresponding to different values of \(\) and \(F\), thus circumventing the necessity to estimate them. In a similar vein, in the non-parametric valuation model,  avoid the need to estimate \(g(x_{t})\) by employing independent bandit algorithms for each (binned) value of \(x_{t}\). Closer to our method are the works of  and , who also set uniform prices to obtain unbiased estimates of the valuations. Nonetheless, their algorithms are significantly different from ours. First, they propose two-phased algorithms for which the phase length is set beforehand. Such an approach necessitates additional assumptions on how contexts are drawn; specifically, contexts are assumed to be i.i.d. from a distribution with a lower bound on the eigenvalues of the covariance matrix. This is needed to ensure that contexts observed in the first phase can represent the context distribution well. By contrast, our phases are adaptive, allowing our algorithm also to handle adversarial contexts and render these assumptions superfluous. Second, we obtain better regret rates by using piecewise-constant estimators, fitted in a regret-minimization sub-routine, as detailed in the next paragraph. On the other hand,  performs a phase of pure exploitation, relying on an estimate of the CDF \(F\) that is constructed using Kernel methods. , instead, re-frames the problem as a perturbed linear bandit, which exhibits a regret linear in the dimension. However, this dimension depends on the size of the discretization grid - which is horizon dependent - leading to worse rates.

**Estimation of \(D\).** If the expected valuation \(g(x_{t})\) is known with sufficient precision, we can use it to estimate the demand function over a set of candidate price increments \(\{_{k}\}_{k}\). More precisely, assume we set a price \(p_{t}=(x_{t})+_{k}\), and that \(|(x_{t})-g(x_{t})|\). Then, the observation \(o_{t}\) can be used as an almost unbiased estimate of the demand at level \(_{k}\), since

\[[o_{t}]=[\{(x_{t})+_{k} g (x_{t})+_{t}\}]=D(_{k}+(x_{t})-g(x_{t})).\]

Under Assumption 2, \(D\) is \(L_{}\)-Lipschitz, so the bias is of order \(L_{}\). Then, relying on classical bandit techniques, we show that with high probability (for \(\) small enough), \(|D(_{k})-_{t}^{k}|\) is of order \(L_{}+}{{N_{t}^{k}}}}\), where \(_{t}^{k}\) is the average of the observations \(o_{t}\) when setting a price \(p_{t}=(x_{t})+_{k}\), and \(N_{t}^{k}\) is the number of rounds in which we chose the price increment \(_{k}\) up to round \(t\). Importantly, to estimate \(_{t}^{k}\), we share information collected during _all rounds_ we chose the increment \(_{k}\) across all values of \((x_{t})\); this is necessary to obtain better regret rates. Then, using \(p_{t}_{t}^{k}\) as an estimate of the reward \((x_{t},p_{t})\) given the price \(p_{t}=(x_{t})+_{k}\), the error \(|(x_{t},p_{t})-p_{t}_{t}^{k}|\) is of order \(B_{y}(L_{}+}{{N_{t}^{k}}}})\).

The Price Elimination subroutine relies on the previous remark to select a price increment. For each increment \(_{k}\), we build a confidence bound \([_{t}(_{k}),_{t}(_{k})]=[p _{t}_{t}^{k} B_{y}(2L_{}+}{{N_{t}^{k}}}})]\) for the reward of price \(p_{t}=(x_{t})+_{k}\). Then, we use a successive elimination algorithm [13; 25] to select a good increment. More precisely, we consider increments \(_{k}\) such that \(_{t}(_{k})_{l}_{t}(_{l})\), and we choose among these increments the increment \(_{k_{t}}\) that has been selected the least frequently. By doing so, we ensure to only select potentially optimal prices and gradually eliminate sub-optimal increments.

### A First Bound on the Regret

Before discussing the application of the algorithmic scheme VAPE to linear and non-parametric valuation functions, we provide some intuition on regret bounds achievable through this scheme.

**Claim 1**.: (Informal) _Let \(_{k}=k\) for \(k--1}}{{}} ,+1}}{{}}\). Assume that, on a high-probability event, \(|(x_{t})-g(x_{t})|\) for every round \(t\) where Price Elimination is conducted. Then, on a high-probability event, the regret of \(\) verifies_

\[R_{T}^{}()+T+(1/) ^{-2}.\]

_where \(^{}()\) is a bound on the length of the Valuation Approximation phase._

Claim 1 is proved in the Appendix by combining Equations (4) and (5), and Lemma 4. We provide a sketch of proof below. To bound on regret of \(\) using Claim 1, it will suffice to bound the length of the Valuation Approximation phase, and prove high-probability error bounds on \(g(x_{t})\).

Sketch of proof.: Note that the regret in the Valuation Approximation phase scales at most linearly with its length. Then, to prove Claim 1, it is enough to bound the regret during the Price Elimination phase. We begin by bounding the sub-optimality gap of the price chosen at round \(t\), showing that it is of order \(+}{{N_{t}^{k}}}}\).

To do so, for \(p\), we define \(_{t}(x_{t},p)=_{p^{}}(x_{t},p^{})-(x_{t},p)\) the sub-optimality gap corresponding to price \(p\). Recall that \(_{k_{t}}\) is the increment chosen at round \(t\), i.e. that \(p_{t}=(x_{t})+_{k_{t}}\)Classical arguments from the bandit literature show that with high probability, for all \(k\), the upper and lower confidence bounds on \((x_{t},(x_{t})+_{k})\) given by \(_{t}(_{k})\) and \(_{t}(_{k})\) are valid. Then, the optimal increment \(_{k_{t}^{*}}\) defined by \(k^{*}=_{k_{t}}(x_{t},(x_{t})+_{k})\) belongs to the set of non-eliminated increments. Now, on the one hand, since \(_{t}(_{k_{t}})_{t}(_{k_{t}^{*}})\), and since the confidence interval are valid, the gap \((x_{t},(x_{t})+_{k_{t}^{*}})-(x_{t},p_{t})\) is of order \(+^{k_{t}}}+^{k_ {t}}}\). Our round-robin sampling scheme ensures that \(N_{t}^{k_{t}^{*}} N_{t}^{k_{t}}\), so this bound is of order \(+^{k_{t}}}\). On the other hand, our choice of grid \(\{_{k}\}_{k}\), together with the Lipschitz-continuity of the reward in Assumption 2, imply that the cost \(_{t}(x_{t},(x_{t})+_{k_{t}^{*}})\) of considering a discrete price grid is of order \(B_{y}L_{}\). Thus, at each round, the gap \(_{t}(x_{t},(x_{t})+_{k_{t}})\) is at most of order \(+^{k_{t}}}\) (up to problem-dependent constants).

Now, let us decompose the regret of the Price Elimination phase as follows:

\[_{t}(x_{t},p_{t})=_{k}_{t:k_{t}=k}(x_{t},p_{t}).\]

In order to bound \(_{t:k_{t}=k}(x_{t},p_{t})\) for \(k\), we begin by introducing further notations. Let us denote \(_{1}^{k},,_{T}^{k}\) the rounds in the Price Elimination phase where we choose \(k_{t}=k\). We also define \(_{a}=2^{-a}\) and \(\) such that \(_{}\). For all \(a\), we also define \(_{a}\) such that the bound \(+_{a}}\) is of order \(_{a}\). Then, our previous reasoning implies that if \(i_{a}\) for some \(a\{1,\}\), it must be that \(_{t}(x_{t},p_{+})_{a}\). Moreover, for \(a 1\), each phase \(\{_{a},,_{a+1}\}\) is of length approximately \((1/)(_{a+1}^{-2}-_{a}^{-2})\). Thus,

\[_{t:k_{t}=k}(x_{t},p_{t})}+ _{a=1}^{-1}_{a}(^{2}}-^{2}})+_{ }N_{T}^{k}.\]

Using the definitions of \(_{a}\) and \(\), we find that this sum is of order \((1/)/+ N_{T}^{k}\). We conclude by summing over the values of \(k\), using \(_{k}N_{T}^{k} T\) and the fact that \(||\) is of order \(^{-1}\). 

## 4 Linear Valuation Functions

In this section, we consider the linear valuation model, given by

\[g(x)=x^{}\,, \]

where \(^{d}\) is an unknown parameter. To ensure that the valuations are bounded, we assume the boundedness of the parameter \(\).

**Assumption 3**.: _The parameter \(\) is bounded: \(\|\| B_{}\)_

Note that under Assumptions 1 and 3, the expected valuations \(g(x_{t})\) verify \(|g(x_{t})| B_{g}\) for \(B_{g}=B_{x} B_{}\). Moreover, the random valuations verify a.s. \(|y_{t}| B_{y}\) for \(B_{y}=B_{g}+B_{}\).

We apply the VAPE algorithmic scheme to the problem of dynamic pricing with linear valuations. To estimate the valuation function, we use a ridge estimator for the parameter \(\). Moreover, we distinguish between phases by setting \(_{t}=1\) if \(t\) belongs to the Valuation Approximation phase and \(_{t}=0\) if \(t\) belongs to the Price Elimination one. The details are presented in Algorithm 2.

**Theorem 1**.: _Assume that the valuations follow the model given by Equations (1) and (3). Under Assumptions 1, 2, and 3, the regret of Algorithm VAPE for Linear Valuations with parameters \(=(d^{2}(T)^{2}/T)^{}{{3}}}\), \(=}{{(B_{y}T}{} )}+B_{})}}\), and \(=}{{(T+2T^{2}(3+(B_{}+1)T^{}{{3}} )})}}\) verifies_

\[R_{T} C_{B_{},B_{x},B_{},L_{}}d^{}{{3}}}

To prove the first part of the claim, note that for all rounds in the Price Elimination phase, \(\|x_{t}\|_{_{t}^{-1}}=}{{(B_{y}^{2}T/)}+B_{})}}\). Then,

\[|(x_{t})-g(x_{t})|\|-_{t}\|_{_{t }}\|x_{t}\|_{_{t}^{-1}}\|-_{t}\|_{_{t}}}{{(B_{y}^{2}T/ )}+B_{})}}.\]

Classical result on ridge regression in bandit framework  show that on a large probability event, \(\|-_{t}\|_{_{t}}(B_{y}^{2}T/)}+B_{})\), so \(|(x_{t})-g(x_{t})|\).

To prove the second part of the claim, we rely on the elliptical potential lemma to bound the number of rounds where \(\|x_{t}\|_{_{t}^{-1}}\). This Lemma states that \(_{i=1}^{||}\|x_{t_{i}}\|_{_{t_{i}^{-1}}^{-1}} |d(|}}{{d}})}\), where \(t_{i}\) is the \(i\)-th round of the Valuation Approximation phase, and \(||\) is its length. Using the fact that \(\|x_{t_{i}}\|_{_{t_{i}^{-1}}^{-1}}\), we conclude that \(||}\), which implies the result. 

Theorem 1 provides a regret bound of order \((T^{2/3})\), showing that VAPE for Linear Valuations is minimax optimal, possibly up to sub-logarithmic terms and to sub-linear dependence in the dimension. Indeed, it matches the \(T^{}{{3}}}\) lower bound established in  for linear valuation functions and Lipschitz-continuous demand functions. This result represents a clear improvement over the existing regret bounds for the same problem. Indeed, VAPE achieves the regret bound conjectured in  while at the same time removing their regularity assumption on the revenue function. On the other hand, we improve on the regret rate \((T^{3/4})\) achieved respectively in  under assumptions slightly milder than ours, and in  under stronger assumptions.

## 5 Non-Parametric Valuation Functions

In this Section, we consider the non-parametric valuation model. As usual in dynamic pricing, we assume that the valuation function \(g\) is bounded. Furthermore, we assume that it is (\(L_{g}\), \(\))-Holder continuous for some constants \(L_{g}>0\) and \(0< 1\).

**Assumption 4**.: _The valuation function \(g\) is (\(L_{g}\), \(\))-Holder: for all \((x,x^{})^{d}\), \(|g(x)-g(x^{})| L_{g}\|x-x^{}\|^{}.\)_

Under Assumptions 1 and 2, the random valuations \(y_{t}\) verify \(|y_{t}| B_{y}\) for \(B_{y}=B_{}+B_{g}\).

Next, we apply the VAPE algorithmic scheme to the non-parametric valuation model. To estimate the function g, we use a finite grid of points, on which this function is evaluated. More precisely, we consider a minimal \((}{{3L_{g}}})^{}{{}}}\)-covering \(}\) of the ball of radius \(B_{x}\) in \(R^{d}\), i.e. a finite set of points, of minimal cardinality, such that for any context \(x\) such that \(\|x\| B_{x}\), there exists a point in \(}\) at a distance at most \((}{{3L_{g}}})^{}{{}}}\) from \(x\).

At each round, we round the context \(x_{t}\) to the closest context \(\) in \(}\) by setting \(_{t}=_{^{}}}\|x_ {t}-^{}\|\), and acting as if we observed the context \(_{t}\). If this context has not been observed sufficiently, we conduct a round of Valuation Approximation: we sample a price uniformly at random and use it to update our estimate of \(g(_{t})\); otherwise, we proceed with the Price Elimination phase. To distinguish between the Valuation Approximation steps corresponding to contexts \(}\), we collect their indices in sets \(_{}\). The algorithm is presented in Algorithm 3.

```
1:Input: bounds \(B_{y}\) and \(L_{}\), finite set \(}^{d}\), parameters \(\), \(\), \(\).
2:Initialize:\(_{}=\) for all \(}\), \(K=+1}}{{}}\), \(=-K,K\), and for \(k\), \(N_{1}^{k}=_{1}^{k}=0\).
3:while\(t T\)do\(_{t}_{^{}}}\|x_{t}-^{}\|\)\(\) Price Elimination
4:if\(|_{_{t}}|<\)then
5: Post a price \(p_{t}([-B_{y},B_{y}])\)
6:\(_{_{t}}_{_{t}}\{t\}\), \((_{t})}{|_{_{t}}|}_{s}_{_{t}}}( {o_{s}-})\)
7:else\(\) Run Successive Elimination
8:\(_{t}(_{t})\), \(_{t}\{k:_{t}+k[0,B_ {y}]\}\)
9:for\(k_{t}\)do
10:\(_{t}(k)(_{t}+k)(_{t}^ {k}+}{{}})}{N_{t}^{k}}}+2L_{})\)
11:\(_{t}(k)(_{t}+k)(_{t}^ {k}-}{{}})}{N_{t}^{k}}}-2L_{})\)
12:\(_{t}\{k_{t}:_{t}(k)_{k^ {}_{t}}_{t}(k^{})\}\)
13: Choose \(k_{t}_{k_{t}}N_{t}^{k}\) and post a price \(p_{t}=_{t}+k_{t}\)
14: Update \(_{t+1}^{k_{t}}^{k_{t}}_{t}^{k_{t}}+ o_{t}}{N_{t}^{k_{t}}+1}\), \(N_{t+1}^{k_{t}} N_{t}^{k_{t}}+1\).
```

**Algorithm 3** Valuation Approximation - Price Elimination (VAPE) for Non-Parametric Valuations

_Theorem 2_.: _Assume that the valuations follow the model given by Equation (1). Under Assumptions 1, 2, and 4, with probability \(1-T^{-1}\) the regret of Algorithm VAPE for non-parametric Valuations with parameters \(=(}{{(T)}})^{}{{3+3}}}\), \(=T^{-4}\), \(=^{2}(} |}}{{}})}}{{^{2}}}\), and \(}\) a minimal \((}{{3L_{g}}})^{}{{}}}\)-covering of the ball of radius \(B_{x}\) verifies_

\[R_{T} C_{B_{x},B_{g},B_{t},L_{g},L_{t},d,}T^{ }(T)^{},\]

_where \(C_{B_{x},B_{g},B_{t},L_{g},L_{t},d,}\) is a constant that polynomially depends on \(B_{x}\), \(B_{g}\), \(B_{}\), \(L_{g}\), \(L_{}\), \(d\), and \(\)._

Sketch of proof.: [See Appendix C for the full proof] Using Claim 1, we only need to show that the length of the Valuation Approximation phase is at most of order \(T^{d+2/d+3}(T)^{}{{d+3}}}\) and that w.h.p., it allows estimating \(g\) uniformly on a ball of radius \(B_{x}\) with precision \(=(}{{(T)}})^{-}{{d+3}}}\).

To prove the first part of the claim, we note that classical results imply that the size of a minimal covering of precision \(^{}{{}}}\) of a ball in dimension \(d\) scales as \(^{-}{{}}}\). Then, the total length of the Valuation Approximation phase is of order \(^{-}{{}}} T^{d+2/d+3}(T)^{ }{{d+3}}}\). To prove the second part of the lemma, note that the Holder-continuity of \(g\) and the definition of the \((}{{3L_{g}}})^{}{{}}}\)-covering \(\) ensure that \(|g(x_{t})-g(_{t})|}{{3}}\). Then, standard concentration arguments reveal that \((|}|/)/^{2}\) samples are sufficient to estimate \(g(_{t})\) with precision \(\) with high probability. 

Theorem 2 shows that the Algorithm Valuation Approximation - Price Elimination for non-parametric valuations enjoys a \((T^{d+2/d+3})\) regret bound when the noise c.d.f. is Lipschitz and the valuation function Holder-continuous. This result is the first of its kind under such minimal assumptions. In particular, previous work by  assumes quadratic behavior around the optimal price for all values of \(g(x)\) - a very strong assumption. However, this rate is higher than the \((T^{d+/d+2})\)rates that are usually encountered in \(\)-Holder non-parametric bandits . Thus, the question of optimality of the VAPE algorithmic scheme in the non-parametric valuation problem remains open.

## 6 Conclusions

In this paper, we studied the problem of dynamic pricing with covariates. We first presented a novel algorithmic approach called VAPE, which adaptively alternates between improving the valuation approximation and learning to set prices through successive elimination. We then applied VAPE under two valuation models - when the buyer's valuation corresponds to a noisy linear function and when expected valuations follow a smooth non-parametric model. In the linear case, our regret bounds are order-optimal, while in the non-parametric setting, we improve existing results. All our results are proven under regularity assumptions that are either milder or match existing assumptions.

Our results on the linear valuation model are the first to match the existing lower bound rate of \(T^{}{{3}}}\) under our assumptions. However, the optimal dependence of this rate on the dimension of the context remains unknown. Additionally, there are no similar lower bounds for non-parametric valuations. We conjecture that our results are also tight in this setting but leave this for future work. Future research directions also include exploring other valuation models, and further relaxing our assumptions, as Lipschitz-continuity of the noise (Assumption 2). Without this, even minor increases in the price could lead to a major drop in revenue, magnifying the impact of valuation approximation errors. Another limiting assumption is that the noise is independent and identically distributed, such that its distribution can be learned across different contexts. It is of great interest to study problems where the noise distribution can change between rounds, or depends on the context.

## Broader Impacts

As all pricing problems, dynamic pricing can have both positive and negative impacts - offering prices that are more suited to the buyers on the one hand, while increasing the seller's revenue at the expense of buyers on the other hand. In addition, as with many contextual problems, there might be biases and challenges involving fairness - one should make sure that similar customers are offered similar prices. While acknowledging these issues, our work was meant to focus only on the theoretical analysis of what is considered a well-established problem in literature, leaving the study of these related topics as future work.