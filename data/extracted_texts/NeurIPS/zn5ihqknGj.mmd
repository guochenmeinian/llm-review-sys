# A Generalized Alternating Method for Bilevel Optimization under the Polyak-Lojasiewicz Condition

Quan Xiao

Rensselaer Polytechnic Institute

Troy, NY, USA

xiaoq5@rpi.edu

&Songtao Lu

IBM Research

Yorktown Heights, NY, USA

songtao@ibm.com

&Tianyi Chen

Rensselaer Polytechnic Institute

Troy, NY, USA

chentianyi19@gmail.com

###### Abstract

Bilevel optimization has recently regained interest owing to its applications in emerging machine learning fields such as hyperparameter optimization, meta-learning, and reinforcement learning. Recent results have shown that simple alternating (implicit) gradient-based algorithms can match the convergence rate of single-level gradient descent (GD) when addressing bilevel problems with a strongly convex lower-level objective. However, it remains unclear whether this result can be generalized to bilevel problems beyond this basic setting. In this paper, we first introduce a stationary metric for the considered bilevel problems, which generalizes the existing metric, for a nonconvex lower-level objective that satisfies the Polyak-Lojasiewicz (PL) condition. We then propose a Generalized Alternating mEthod for bilevel opTimization (GALET) tailored to BLO with convex PL LL problem and establish that GALET achieves an \(\)-stationary point for the considered problem within \(}(^{-1})\) iterations, which matches the iteration complexity of GD for single-level smooth nonconvex problems.

## 1 Introduction

Bilevel optimization (BLO) is a hierarchical optimization framework that aims to minimize the upper-level (UL) objective, which depends on the optimal solutions of the lower-level (LL) problem. Since its introduction in the 1970s , BLO has been extensively studied in operations research, mathematics, engineering, and economics communities , and has found applications in image processing  and wireless communications . Recently, BLO has regained interests as a unified framework of modern machine-learning applications, including hyperparameter optimization [49; 21; 22; 54], meta-learning , representation learning , reinforcement learning [62; 59], continual learning [55; 4], adversarial learning  and neural architecture search ; see .

In this paper, we consider BLO in the following form

\[_{x^{d_{x}},y S(x)} f(x,y)\ S(x) *{arg\,min}_{y^{d_{y}}}\ \ g(x,y)\] (1)

where both the UL objective \(f(x,y)\) and LL objective \(g(x,y)\) are differentiable, and the LL solution set \(S(x)\) is not necessarily a singleton. For ease of notation, we denote the optimal function value of the LL objective as \(g^{*}(x):=_{y}g(x,y)\) and call it _value function_.

Although BLO is powerful for modeling hierarchical decision-making processes, solving generic BLO problems is known to be NP-hard due to their nested structure . As a result, the majority of recent works in optimization theory of BLO algorithms are centered on nonconvex UL problems with strongly convex LL problems (nonconvex-strongly-convex), which permit the development of efficient algorithms; see e.g. [24; 27; 32; 9; 35; 10; 34; 67; 66]. The strong convexity assumption for LL ensures the uniqueness of the minimizer and a simple loss landscape of the LL problem, but itexcludes many intriguing applications of BLO. In the context of machine learning, the LL objective might represent the training loss of a neural network, which can be non-strongly-convex .

To measure the efficiency of solving nonconvex BLO problems, it is essential to define its stationarity, which involves identifying a necessary condition for the optimality of BLO. In cases where the LL problem exhibits strongly convexity, the solution set \(S(x)\) becomes a singleton, leading to a natural definition of stationarity as the stationary point of the overall objective \(f(x,S(x))\), i.e., \( f(x,S(x))=0\). However, for BLO problems with non-strongly-convex LL problems, \(S(x)\) may have multiple solutions, rendering \( f(x,S(x))\) ill-posed. This motivates an intriguing question:

**Q1: What is a good metric of stationarity for BLO with nonconvex LL problems?**

To address this question, we focus on the setting of BLO with the LL objective that satisfies the PL condition (nonconvex-PL). The PL condition not only encompasses the strongly convexity condition  and the Morse-Bott condition , but also covers many applications such as overparameterized neural networks , learning LQR models , and phase retrieval .

By reformulating the LL problem by its equivalent conditions, one can convert the BLO problem to a constrained optimization problem. Then with certain constraint qualification (CQ) conditions, a natural definition of the stationarity of the constrained optimization problem is the Karush-Kuhn-Tucker (KKT) point . For example, constant rank CQ (CRCQ) was assumed in , and linear independence CQ (LICQ) was assumed or implied in . However, it is possible that none of these conditions hold for nonconvex-PL BLO (Section 2.2). In Section 2, we study different CQs on two constrained reformulations of (1) and then identify the best combination. Based on the right CQ on the right constrained reformulation, we prove the inherent CQ and propose a new notion of stationarity for the nonconvex-PL BLO, which strictly extends the existing measures in nonconvex-strongly-convex BLO  and nonconvex-nonconvex BLO  without relaxing the problem . We emphasize the importance of defining new metric in Section 2.3.

Given a stationary metric, while \(\)-stationary point can be found efficiently in \((^{-1})\) iterations for nonconvex and smooth single-level problem , existing works on the BLO with non-strongly-convex LL problem either lack complexity guarantee , or occur slower rate . Moreover, most existing algorithms update the UL variable \(x\) after obtaining the LL parameter \(y\) sufficiently close to the optimal set \(S(x)\) by running GD from scratch, which is computationally expensive . In contrast, the most efficient algorithm for nonconvex-strongly-convex BLO updates \(x\) and \(y\) in an alternating manner, meaning that \(x\) is updated after a constant number of \(y\) updates from their previous values . Then another question arises:

**Q2: Can alternating methods achieve the \((^{-1})\) complexity for non-strongly-convex BLO?**

Addressing this question is far from trivial. First, we need to characterize the drifting error of \(S(x)\) induced by the alternating strategy, which involves the change in the LL solution sets between two consecutive UL iterations. However, we need to generalize the analysis in nonconvex-strongly-convex BLO  because \(S(x)\) is not a singleton. Moreover, we need to select an appropriate Lyapunov function to characterize the UL descent, as the nature candidate \(f(x,S(x))\) is ill-posed without a unique LL minimizer. Finally, since the Lyapunov function we choose for UL contains both \(x\) and \(y\), it is crucial to account for the drifting error of \(y\) as well.

By exploiting the smoothness of the value function \(g^{*}(x)\) and with the proper design of the Lyapunov function, we demonstrate the \(}(^{-1})\) iteration complexity of our algorithm, which is optimal in terms

    & **GALET** & V-PBGD & BOME & MGBio & BGS & IAPT-GM & IGFM \\  \(g(x,y)\) & PL + C & PL & PL & SC & Morse-Bott & Regular & PL + C \\  Non-singleton \(S(x)\) & ✓ & ✓ & ✓ & ✗ & ✓ & ✓ & ✓ \\  Provable CQ & ✓ & Relaxed & ✗ & / & / & Relaxed & / \\  Complexity & \(}(^{-1})\) & \(}(^{-1.5})\) & \(}(^{-4})\) & \(}(^{-1})\) & ✗ & ✗ & \((^{-1})\) \\   

Table 1: Comparison of the proposed method GALET with the existing BLO for non-strongly-convex LL problem (V-PBGD , BOME , MGBio , BGS , IAPTT-GM , IGFM ). The notation \(}\)mits the dependency on \((^{-1})\) terms and \((^{-1})\) hides the dependency worse than \((^{-4})\). ‘C’, ‘SC’ and ‘Regular’ stand for convex, strongly convex and Assumption 3.1 in , respectively. PL, Lipschitz Hessian and the assumption that eigenvalue bounded away from \(0\) in MGBio imply SC. ‘Relaxed’ means that they solve a relaxed problem without CQ-invalid issue and ‘\(\)’ means that CQ is not needed as it is based on the implicit function theorem.

of \(\). This result not only generalizes the convergence analysis in nonconvex-strongly-convex BLO [24; 27; 32; 9; 35; 10; 34; 67; 66] to the broader problem class, but also improves the complexity of existing works on _nonconvex-non-strongly-convex_ BLO, specifically \(}(^{-1.5})\) in  and \(}(^{-4})\) in ; see Table 1. We present our algorithm in Section 3 and analyze its convergence in Section 4, followed by the simulations and conclusions in Section 5.

### Related works

**Nonconvex-strongly-convex BLO.** The interest in developing efficient gradient-based methods and their nonasymptotic analysis for nonconvex-strongly-convex BLO has been invigorated by recent works [24; 32; 27; 9]. Based on the different UL gradient approximation techniques they use, these algorithms can be categorized into iterative differentiation and approximate implicit differentiation-based approaches. The iterative differentiation-based methods relax the LL problem by a dynamical system and use the automatic differentiation to approximate the UL gradient [21; 22; 25], while the approximate implicit differentiation-based methods utilize the implicit function theory and approximate the UL gradient by the Hessian inverse (e.g. Neumann series [9; 24; 27]; kernel-based methods ) or Hessian-vector production approximation methods (e.g. conjugate gradient descent [32; 54], gradient descent [35; 1]). Recent advances include variance reduction and momentum based methods [34; 67; 13]; warm-started BLO algorithms [1; 35]; distributed BLO approaches [63; 46; 68]; and algorithms solving BLO with constraints [64; 66]. Nevertheless, none of these attempts tackle the BLO beyond the strongly convex LL problem.

**Nonconvex-nonconvex BLO.** While nonconvex-strongly-convex BLO has been extensively studied in the literature, efficient algorithms for BLO with nonconvex LL problem remain under-explored. Among them, Liu et al.  developed a BLO method with initialization auxiliary and truncation of pessimistic trajectory; and Arbel and Mairal  generalized the implicit function theorem to a class of nonconvex LL functions and introduced a heuristic algorithm. However, these works primarily focus on analyzing the asymptotic performance of their algorithms, without providing finite-time convergence guarantees. Recently, Liu et al.  proposed a first-order method and established the first nonasymptotic analysis for non-strongly-convex BLO. Nonetheless, the assumptions such as CRCQ and bounded \(|f|,|g|\) are relatively restrictive. Huang  has proposed a momentum-based BLO algorithm, but the assumptions imply strongly convexity. Another research direction has addressed the nonconvex BLO problem by relaxation, such as adding regularization in the LL [42; 50], or replacing the LL optimal solution set with its \(\)-optimal solutions [36; 57]. Although this relaxation strategy overcomes the CQ-invalid issues, it introduces errors in the original bilevel problem . To the best of our knowledge, none of these BLO algorithms handling multiple LL solutions can achieve the optimal iteration complexity in terms of \(\).

**Nonconvex-convex BLO.** Another line of research focuses on the BLO with convex LL problem, which can be traced back to [48; 18]. Convex LL problems pose additional challenges of multiple LL solutions which hinder from using implicit-based approaches for nonconvex-strongly-convex BLO. To tackle multiple LL solutions, an aggregation approach was proposed in [56; 40]; a primal-dual algorithm was considered in ; a difference-of-convex constrained reformulated problem was explored in [72; 23]; an averaged multiplier method was proposed in . Recently, Chen et al.  has pointed out that the objective of the non-strongly-convex LL problem can be discontinuous and proposed a zeroth-order smoothing-based method; Lu and Mei  have solved it by penalized min-max optimization. However, none of these attempts achieve the iteration complexity of \(}(^{-1})\). Moreover, although some works adopted KKT related concept as stationary measure, they did not find the inherent CQ condition, so the necessity of their measure to the optimality of BLO is unknown [45; 47]. In this sense, our work is complementary to them. The comparison with closely related works is summarized in Table 1.

**Notations.** For any given matrix \(A^{d d}\), we list the singular values of \(A\) in the increasing order as \(0_{1}(A)_{2}(A)_{d}(A)\) and denote the smallest positive singular value of \(A\) as \(_{}^{+}(A)\). We also denote \(A^{-1},A^{},A^{1/2}\) and \(A^{-1/2}\) as the inverse of \(A\), the Moore-Penrose inverse of \(A\), the square root of \(A\) and the square root of the inverse of \(A\), respectively. \((A)=\{x:Ax=0\},(A)=\{Ax\}\) denotes the null space and range space of \(A\).

## 2 Stationarity Metric of Nonconvex-PL BLO

We will first introduce the equivalent constraint-reformulation of the nonconvex-PL BLO and then introduce our stationarity metric, followed by a section highlighting the importance of our results.

### Equivalent constraint-reformulation of BLO

By viewing the LL problem as a constraint to the UL problem, BLO can be reformulated as a single-level nonlinear constrained optimization problem. Based on different equivalent characteristics of the LL problem, two major reformulations are commonly used in the literature . The first approach is called value function-based reformulation, that is

\[_{x^{d_{x}},y^{d_{y}}}\ f(x,y)\ \ \ \ \ \ g(x,y)-g^{*}(x)=0.\] (2)

Clearly, \(g(x,y)-g^{*}(x)=0\) is equivalent to \(y S(x)\) so that (2) is equivalent to (1).

On the other hand, recall the definition of PL function below, which is not necessarily strongly convex or even convex .

**Definition 1** (**PL condition)**.: _The function \(g(x,)\) satisfies the PL condition if there exists \(_{g}>0\) such that for any given \(x\), it holds that \(\|_{y}g(x,y)\|^{2} 2_{g}(g(x,y)-g^{*}(x)),\  y\)._

According to Definition 1, for PL functions, \(_{y}g(x,y)=0\) implies \(g(x,y)=g^{*}(x)\). Therefore, the second approach replaces the LL problem with its stationary condition, that is

\[_{x^{d_{x}},y^{d_{y}}}\ f(x,y)\ \ \ \ \ \ \ _{y}g(x,y)=0.\] (3)

We call (3) the gradient-based reformulation. The formal equivalence of (2) and (3) with (1) is established in Theorem 3 in Appendix.

For constrained optimization, the commonly used metric of quantifying the stationarity of the solutions are the KKT conditions. However, the local (resp. global) minimizers do not necessarily satisfy the KKT conditions . To ensure the KKT conditions hold at local (resp. global) minimizer, one needs to assume CQ conditions, e.g., the Slater condition, LICQ, Mangasarian-Fromovitz constraint qualification (MFCQ), and the CRCQ . Nevertheless, Ye and Zhu  have shown that none of these standard CQs are valid to the reformulation (2) for all types of BLO.

### Stationarity metric

We will next establish the necessary condition for nonconvex-PL BLO via the calmness condition [11, Definition 6.4.1], which is weaker than the Slater condition, LICQ, MFCQ and CRCQ.

**Definition 2** (**Calmness)**.: _Let \((x^{*},y^{*})\) be the global minimizer of the constrained problem_

\[_{x,y}\ f(x,y)\ \ \ \ \ h(x,y)=0.\] (4)

_where \(h:^{d_{x}+d_{y}}^{d}\) and \(d 1\). If there exist positive \(\) and \(M\) such that for any \(q^{d}\) with \(\|q\|\) and any \(\|(x^{},y^{})-(x^{*},y^{*})\|\) which satisfies \(h(x^{},y^{})+q=0\), one has_

\[f(x^{},y^{})-f(x^{*},y^{*})+M\|q\| 0\] (5)

_then the problem (4) is said to be calm with \(M\)._

The calmness of a problem quantifies the sensitivity of the objective to the constraints. Specifically, the calmness conditions of reformulations (2) and (3) are defined by setting \(h(x,y)=g(x,y)-g^{*}(x)\) and \(h(x,y)=_{y}g(x,y)\), respectively.

The calmness condition is the weakest CQ which can be implied by Slater condition, LICQ, MFCQ and CRCQ . However, as we will show, even the calmness condition does not hold for the nonconvex-PL BLO when employing the value function-based reformulation (2).

**Example 1**.: _Considering \(x,y=[y_{1},y_{2}]^{}^{2}\), and the BLO problem as_

\[_{x,y}f(x,y)=x^{2}+y_{1}-(y_{2})\ \ \ \ y*{arg\, min}_{y}\ g(x,y)=(x+y_{1}-(y_{2}))^{2}.\] (6)

Figure 1: Example 1 under different initialization. The solid and dashed lines represent two initialization in both plots. **Top**: the distance to the global optimal set measured by (46) v.s. iteration. **Bottom**: the stationary score of (2) and (3) v.s. iteration.

**Lemma 1**.: _Considering the BLO problem in Example 1, the LL objective satisfies the PL condition and the global minimizers of it are within the set_

\[\{(,)=0.5,=[_{1},_{2}]^{},0.5+ _{1}-(_{2})=0\}\] (7)

_but the calmness condition of reformulation (2) is not satisfied under on all of the global minimizers._

Figure 1 illustrates this fact by showing that the KKT score on the value function-based reformulation does not approach \(0\) as the distance to the optimal set decreases. This observation implies that the KKT conditions associated with the value function-based reformulation (2) do not constitute a set of necessary conditions for global minimizers for the nonconvex-PL BLO problems. As a result, the KKT point of (2) is unable to serve as the stationary point for the nonconvex-PL BLO problems.

Therefore, we adopt the gradient-based reformulation (3). Unfortunately, it is still possible that the standard CQs do not hold for some of the nonconvex-PL BLO problems associated with the gradient-based reformulation (3). To see this, let \((x^{*},y^{*})\) be the global minimizer of (3). By denoting the matrix concatenating the Hessian and Jacobian as \([^{2}_{yy}g(x^{*},y^{*}),^{2}_{yx}g(x^{*},y^{*})]\), the generic CQ conditions are instantiated in the gradient-based reformulation (3) by

* LICQ, MFCQ: The rows of \([^{2}_{yy}g(x^{*},y^{*}),^{2}_{yx}g(x^{*},y^{*})]\) are linearly independent; and,
* CRCQ: \(\) neighborhood of \((x^{*},y^{*})\) such that \([^{2}_{yy}g(x,y),^{2}_{yx}g(x,y)]\) is of constant rank.

If \(g(x,y)\) is strongly convex over \(y\), then \(^{2}_{yy}g(x,y)\) is of full rank for any \(x\) and \(y\), which ensures the LICQ, MFCQ and CRCQ of the gradient-based reformulation (3). However, if \(g(x,y)\) merely satisfies the PL condition like **Example 1**, none of the standard CQs hold, which is established next.

**Lemma 2**.: _Example 1 violates Slater condition, LICQ, MFCQ and CRCQ conditions of (3)._

Remarkably, the following lemma demonstrates that the gradient-based reformulation of the nonconvex-PL BLO inherits the calmness condition.

**Lemma 3** (**Calmness of nonconvex-PL BLO)**.: _If \(g(x,)\) satisfies the PL condition and is smooth, and \(f(x,)\) is Lipschitz continuous, then (3) is calm at its global minimizer \((x^{*},y^{*})\)._

The Lipschitz smoothness of \(g(x,y)\) and Lipschitz continuity of \(f(x,y)\) over \(y\) are standard in BLO . In this sense, nonconvex-PL BLO associated with the gradient-based reformulation (3) is naturally calm so that the KKT conditions are necessary conditions for its optimality . A summary and illustration of our theory is shown in Figure 2.

To benefit the algorithm design (Section 3.2), we establish the necessary conditions of the optimality for nonconvex-PL BLO by slightly modifying the KKT conditions of (3) in the next theorem.

**Theorem 1** (**Necessary condition in nonconvex-PL BLO)**.: _If \(g(x,)\) satisfies the PL condition and is smooth, and \(f(x,)\) is Lipschitz continuous, then \( w^{*} 0\) such that_

\[_{x}(x^{*},y^{*},w^{*}):= \|_{x}f(x^{*},y^{*})+^{2}_{xy}g(x^{*},y^{*})w^{*}\|^ {2}=0\] (8a) \[_{w}(x^{*},y^{*},w^{*}):= \|^{2}_{yy}g(x^{*},y^{*})(_{y}f(x^{*},y^{*})+ ^{2}_{yy}g(x^{*},y^{*})w^{*})\|^{2}=0\] (8b) \[_{y}(x^{*},y^{*}):= g(x^{*},y^{*})-g^{*}(x^{*})=0\] (8c)

_hold at the global minimizer \((x^{*},y^{*})\) of (1)._

This necessary condition is tight in the sense that it is a generalization of stationary measures in the existing literature for BLO with LL problem exhibiting strongly convexity , PL with CRCQ , invertible Hessian and singleton solution  and Morse-Bott functions . Thanks to the inherent calmness of PL BLO, our result eliminates the CRCQ condition in . We next show the connections of our results with other works.

**Nonconvex-strongly-convex BLO or PL with invertible Hessian and singleton solution.** As \(S(x)\) is singleton and \(_{yy}g(x,y)\) is always non-singular, the solution to (8b) is uniquely given by

\[w^{*}=-(^{2}_{yy}g(x^{*},S(x^{*})))^{-1}_{y}f(x^{*},S(x^ {*})).\] (9)

Therefore, the necessary condition in (8) is equivalent to

\[ f(x^{*},S(x^{*}))=_{x}f(x^{*},S(x^{*}))-^{2}_{xy}g(x^{*},S( x^{*}))(^{2}_{yy}g(x^{*},S(x^{*})))^{-1}_{y}f(x^{*},S(x^{*}))=0\]where the first equality is obtained by the implicit function theorem. Therefore, (8) recovers the necessary condition \( f(x^{*},S(x^{*}))=0\) for nonconvex-strongly-convex BLO.

**Nonconvex-Morse-Bott BLO.** Morse-Bott functions are special cases of PL functions . In this case, \(_{yy}g(x,y)\) can be singular so that (8b) may have infinite many solutions, which are given by

\[^{*}=-(_{yy}^{2}g(x^{*},y^{*}))^{}_{ y}f(x^{*},y^{*})+(_{yy}^{2}g(x^{*},y^{*})).\]

According to [2, Proposition 6], for any \(y^{*} S(x^{*})\), \(_{xy}^{2}g(x^{*},y^{*})(_{yy}^{2}g(x^{*},y^{*}))\), which is orthogonal to \((_{yy}^{2}g(x^{*},y^{*}))\). As a result, although the solution to (8b) is not unique, all of possible solutions yield the unique left hand side value of (8a). i.e. \( w^{*}^{*}\),

\[_{xy}^{2}g(x^{*},y^{*})w^{*}=-_{xy}^{2}g(x^{*},y^{*})( _{yy}^{2}g(x^{*},y^{*}))^{}_{y}f(x^{*},y^{*}).\]

Plugging into (8a), we arrive at

\[_{x}f(x^{*},y^{*})^{2}g(x^{*},y^{*})( _{yy}^{2}g(x^{*},y^{*}))^{}}_{:=(x^{*},y^{*})}_{ y}f(x^{*},y^{*})=0_{y}g(x^{*},y^{*})=0\]

where \((x^{*},y^{*})\) is the same as the degenerated implicit differentiation in .

Based on (8), we can define the \(\)- stationary point of the original BLO problem (1) as follows.

**Definition 3** (\(\)- **stationary point)**.: _A point \((,)\) is called \(\)-stationary point of (1) if \(\) such that \(_{x}(,,),_{w}(, ,)\) and \(_{y}(,)\)._

### The importance of necessary conditions for BLO without additional CQs

Next, we emphasize the importance of deriving the necessary condition for the optimality of the nonconvex-PL BLO without additional CQs.

On the one hand, the necessary condition for the optimality of BLO is fundamental to the algorithm design and has been investigated for a long time in the optimization community [70; 71; 15; 17], but has not yet been fully understood . One of the main challenges is that traditional CQs for constrained optimization are hard to check or do not hold in BLO [16; 70]. As a result, the development of mild CQs and the identification of BLO classes that inherently satisfy these CQs are considered significant contributions to the field [70; 71; 15; 17; 69]. Among those, the calmness condition is the weakest CQ .

On the other hand, recent BLO applications in machine learning often involve nonconvex LL problems, the necessary condition for the solution of which is far less explored in either optimization or machine learning community. In the optimization community, most works focus on proving linear bilevel and sequential min-max optimization satisfy certain CQs [70; 16]. In the machine learning community, works on nonconvex-nonconvex BLO either relax the LL problem that introduces error [43; 57] or impose assumptions that are hard to verify in practice such as CRCQ  or Morse-Bott condition . To the best of our knowledge, we are the first to propose the necessary condition for the optimality of a class of nonconvex-nonconvex BLO problems with checkable assumptions. Moreover, algorithms in constrained optimization are always CQ-dependent, e.g. the convergence of an algorithm depends on whether a particular CQ condition is satisfied. As we prove that standard CQs are invalid for nonconvex-PL BLO, several existing BLO may become theoretically less grounded [37; 28].

## 3 An Alternating Method for Bilevel Problems under the PL Condition

Figure 2: Illustration of our theory: relations of different CQs and BLO reformulation (2) and (3). Slater condition fails for both BLO reformulations so we do not include it.

In this section, we introduce our Generalized ALternating mEthod for bilevel opTimization with convex LL problem, GALET for short, and then elucidate its relations with the existing algorithms.

### Algorithm development

To attain the \(\)-stationary point of (1) in the sense of Definition 3, we alternately update \(x\) and \(y\) to reduce computational costs. At iteration \(k\), we update \(y^{k+1}\) by \(N\)-step GD on \(g(x^{k},y)\) with \(y^{k,0}=y^{k}\) and \(y^{k+1}=y^{k,N}\) as

\[y^{k,n+1}=y^{k,n}- g(x^{k},y^{k,n})\] (10)

While setting \(N=1\) is possible, we retain \(N\) for generality. We then update \(w\) via the fixed-point equation derived from (8b) and employ \(_{yy}g(x,y)(_{y}f(x,y)+_{yy}g(x,y)w)\) as the increment for \(w\). This increment can be viewed as the gradient of \((x,y,w)\) defined as

\[(x,y,w)\!:=\!\|_{y}f(x,y)+_{yy}^{2}g(x, y)w\|^{2}\] (11)

which is quadratic w.r.t. \(w\), given \(x^{k}\) and \(y^{k+1}\).

However, unlike the LL objective \(g(x,y)\), the objective \((x,y,w)\) is Lipschitz smooth with respect to \(x\) and \(y\) only for bounded \(w\), which makes it difficult to control the change of solution (11) under different \(x\) and \(y\). Hence, we update \(w^{k+1}\) via \(T\)-step GD on with \(w^{k,0}=0\) and \(w^{k+1}=w^{k,T}\) as

\[w^{k,t+1}=w^{k,t}- d_{w}^{k,t},\] (12a) \[d_{w}^{k,t}:=_{yy}^{2}g(x^{k},y^{k+1})(_{y}f(x^{k},y^{k+1})+ _{yy}^{2}g(x^{k},y^{k+1})w^{k,t}).\] (12b)

After obtaining the updated \(y^{k+1}\) and \(w^{k+1}\), we update \(x^{k}\) by the fixed point equation of (8a) as

\[x^{k+1}=x^{k}- d_{x}^{k},\ \ \ \ \ d_{x}^{k}:=_{x}f(x^{k},y^{k+1})+ _{xy}^{2}g(x^{k},y^{k+1})w^{k+1}.\] (13)

We summarize our algorithm in Algorithm 1. We choose \(w^{k,0}=0\) for simplicity, but \(w^{k,0}=w^{0} 0\) is also valid. Same convergence statement can hold since the boundedness and Lipschitz continuity of limit points \(_{t}w^{k,t}\) are still guaranteed. From the algorithm perspective,  shares similarities with us. However, without recognizing the property of GD converging to the minimal norm solution , Arbel and Mairal  introduces an additional Hessian into the objective (11), resulting in the calculation of fourth-order Hessian operation, which is more complex than GALET.

```
1:Initialization \(\{x^{0},y^{0}\}\), stepsizes \(\{,,\}\)
2:for\(k=0\)to\(K-1\)do
3:for\(n=0\)to\(N-1\)do\(\)\(y^{k,0}=y^{k}\)
4: update \(y^{k,n+1}\) by (10)
5:endfor\(\)\(y^{k+1}=y^{k,N}\)
6:for\(t=0\)to\(T-1\)do\(\)\(w^{k,0}=0\)
7: update \(w^{k,t+1}\) by (12b)
8:endfor\(\)\(w^{k+1}=w^{k,T}\)
9: calculate \(d_{x}^{k}\) by (13)
10: update \(x^{k+1}=x^{k}- d_{x}^{k}\)
11:endfor ```

**Algorithm 1** GALET for nonconvex-PL BLO

### Relation with algorithms in nonconvex-strongly-convex BLO

We explain the relation between GALET and methods in the nonconvex-strongly-convex BLO.

First, if \(g(x,y)\) is strongly convex in \(y\), minimizing \((x,y,w)\) over \(w\) yields the unique solution \(w^{*}(x,y)=-(_{yy}^{2}g(x,y))^{-1}_{y}f(x,y)\). This means that optimizing \((x,y,w)\) corresponds to implicit differentiation in the nonconvex-strongly-convex BLO . Therefore, we refer the optimization of \(w\) as the _shadow implicit gradient_ level

On the other hand, if \(_{yy}^{2}g(x,y)\) is positive definite, the problem (11) over \(w\) is equivalent to

\[_{w}\ \ \ \{w^{}_{yy}^{2}g(x,y)w+w^{} _{y}f(x,y)\}\] (14)

which can be verified by their first-order necessary conditions. Thus, one can update \(w\) by GD on (14) via

\[d_{w}^{k,t}:=_{y}f(x^{k},y^{k+1})+_{yy}^{2}g(x^{k},y^{k+1})w^{k,t}.\] (15)

Note that the increment in (15) eliminates the extra Hessian in (12b) and recovers the updates for nonconvex-strongly-convex BLO in . Actually, the additional Hessian in (12b) is inevitable for an algorithm to find the stationary point of the nonconvex-PL BLO. Figure 3 shows the comparative results of our algorithm with the nonconvex-strongly-convex BLO algorithm using (15) instead of (12b) on Example 1, where the global optimality is measured by the distance to the global optimal set (7) with the explicit form stated in (46). We observe that the update (15) fails to find the global optimizer of the example in Lemma 1 so that the additional Hessian in (12b) is unavoidable.

Figure 3: The \(w\) update in (15) for nonconvex-strongly-convex does not work well for nonconvex-PL BLO.

Convergence Analysis

In this section, we provide the convergence rate analysis under convex PL LL settings. We first introduce the assumptions and the challenges. Next, we analyze the descent property and drifting error in LL, the bias of \(w^{k+1}\) to the optimal solution of \(_{w}(x^{k},y^{k+1},w)\) and the descent property of UL. Finally, we define a new Lyapunov function and state the iteration complexity of GALET.

**Assumption 1** (Lipschitz continuity).: _Assume that \( f, g\) and \(^{2}g\) are Lipschitz continuous with \(_{f,1},_{g,1}\) and \(_{g,2}\), respectively. Additionally, we assume \(f(x,y)\) is \(_{f,0}\)-Lipschitz continuous over \(y\)._

**Assumption 2** (Landscape of LL objective).: _Assume that \(g(x,y)\) is \(_{g}\)-PL over \(y\). Moreover, let \(_{g}>0\) be the lower-bound of the positive singular values of Hessian, i.e. \(_{g}=_{x,y}(_{}^{2}(_{yy}^{2}g(x,y)))\)._

**Remark 1**.: By definition, singular values are always nonnegative. We use \(_{g}\) to denote the lower bound of the **non-zero** singular values of \(_{yy}^{2}g(x,y)\). Assumption 2 means that the **non-zero** singular values are bounded away from \(0\) on the entire domain. Given Assumption 1 that the Hessian is globally Lipschitz, they together potentially rule out negative eigenvalues of the Hessian. However, different from strong convexity [9; 27; 24; 32; 28], this assumption still permits \(_{yy}^{2}g(x,y)\) to possess zero eigenvalues and includes BLO problems of multiple LL solutions. As an example, this includes the loss of the (overparameterized) generalized linear model . In addition, Assumption 2 is needed only in the convergence rate analysis along the optimization path to ensure the sequence \(\{w^{k}\}\) is well-behaved. Therefore, it is possible to narrow down either the Hessian Lipschitz condition or the lower bound of singular values to a bounded region, when the local optimal sets are bounded.

_Challenges of analyzing GALET._ The absence of strong convexity of the LL brings challenges to characterize the convergence of GALET. To see this, recall that in recent analysis of BLO such as , when \(g(x,)\) is strongly convex, the minimizer of LL is unique. Therefore, to quantify the convergence of Algorithm 1, one can use the Lyapunov function \(_{}^{k}:=f(x^{k},S(x^{k}))+\|y^{k}-S(x^{k})\|^{2}\) where \(f(x^{k},S(x^{k}))\) and \(\|y^{k}-S(x^{k})\|^{2}\) are used to account for the UL descent and LL error caused by the alternating update and the inexactness, respectively. However, \(_{}\) is not well-defined when \(S(x)\) is not unique. Therefore, it is necessary to seek for a new Lyapunov function.

### Descent of each sequence in GALET

A nature alternative of \(\|y^{k}-S(x^{k})\|^{2}\) under the PL condition is the LL optimality residual \(_{y}(x^{k},y^{k})\), the evolution of which between two steps can be quantified by

\[_{y}(x^{k+1},y^{k+1})-_{y}(x^{k},y^{k})= _{y}(x^{k+1},y^{k+1})-_{y}(x^{k},y^{k+1})}_ {(1)}+_{y}(x^{k},y^{k+1})-_{y}(x ^{k},y^{k})}_{(1)}\] (16)

where the first term characterizes the drifting LL optimality gap after updating \(x\), and the second term shows the descent amount by one-step GD on \(y\). Unlike the strongly convex case where \(S(x)\) is Lipschitz continuous, both \(g^{*}(x)\) and \(g(x,y)\) are not Lipschitz continuous, so we cannot directly bound the the first difference term in (16) by the drifting of update \(\|x^{k+1}-x^{k}\|\). Owing to the opposite sign of \(g(x,y)\) and \(g^{*}(x)\), we bound the first term in (16) by the smoothness of \(g(x,y)\) and \(g^{*}(x)\). The second term in (16) can be easily bounded by the fact that running GD on PL function ensures the contraction of function value distance.

**Lemma 4**.: _Under Assumption 1-2, let \(y^{k+1}\) be the point generated by (10) given \(x^{k}\) and the stepsize \(}\). Then it holds that_

\[_{y}(x^{k},y^{k+1})(1-_{g})^{N}_{y}(x^{k},y^{k})\] (17a) \[_{y}(x^{k+1},y^{k+1})(1+ _{g,1}}{_{g}})_{y}(x^{k},y^{k+1})+(}{2_{1}}++L_{g}}{2}^{2})\|d_{x}^{k}\| ^{2}\] (17b)

_where \(L_{g}:=_{g,1}(1+_{g,1}/2_{g})\) and \(_{1}=(1)\) is a constant that will be chosen in the final theorem._

Rearranging the terms in (17a) and using the fact that \(g(x,y) g^{*}(x)\), the second term in (16) can be upper bounded by a negative term and \((^{2})\). Adding (17a) and (17b), letting \(,\) is the same order and choosing \(_{1}=(1)\) properly yield

\[_{y}(x^{k+1},y^{k+1})-_{y}(x^{k},y^{k})- ()_{y}(x^{k},y^{k})+()\|d_{x}^{k} \|^{2}.\] (18)

When we choose \(_{1}\) large enough, the second term will be dominated by the negative term \(-()\|d_{x}^{k}\|^{2}\) given by the UL descent, so it will be canceled out.

With the iterates generated by GD initialized at \(0\) converging to the minimal norm solution of the least squares problem , we can characterize the drifting error of \(w\) using the Lipschitz continuity of its minimal norm solution. The following lemma characterizes the error of \(w^{k+1}\) to the minimal-norm solution of the shadow implicit gradient level \(w^{}(x,y):=-(_{yy}^{2}g(x,y))^{}_{y}f(x,y)\).

**Lemma 5**.: _Under Assumption 1-2, we let \(w^{k+1}\) denote the iterate generated by (12a) given \((x^{k},y^{k+1})\) and \(w^{k,0}=0\), and denote \(b_{k}:=\|w^{k+1}-w^{}(x^{k},y^{k+1})\|\). If we choose the stepsize \(^{2}}\), then the shadow implicit gradient error can be bounded by \(b_{k}^{2} 2(1-_{g}^{2})^{T}_{f,0}^{2}/_{g}\)._

Instead of using \(f(x,S(x))\) which is ill-posed, we integrate the increment of \(x\) to get \(F(x,y;w)=f(x,y)+w^{}_{y}g(x,y)\). Then by plugging the optimal minimal norm solution \(w^{}(x,y)\), we choose \(F(x^{k},y^{k};w^{}(x^{k},y^{k}))\) as the counterpart of \(f(x^{k},S(x^{k}))\) in \(_{}^{k}\). We can quantify its difference between two adjacent steps by the smoothness of \(F(x,y;w)\).

**Lemma 6**.: _Under Assumption 1-2, by choosing \(\{+8L_{w}_{g,1}},}{2L _{w}^{2}}\}\), one has_

\[F(x^{k+1},y^{k+1};w^{}(x^{k+1},y^{k+1}))-F(x^{k},y^{k};w^{ }(x^{k},y^{k}))\] \[-\|d_{x}^{k}\|^{2}+^{2 }}{2}b_{k}^{2}+_{g,1}^{2}+2NL_{w}_{g,1}^{2}+2_ {f,0}_{g,2})+L_{F}_{g,1}^{2}^{2}}{_{g}}_{y}(x^{k}, y^{k})\] (19)

_where \(L_{w}\) is the constant defined in Appendix and constant \(_{2}\) will be chosen in the final theorem._

### A new Lyapunov function

Based on (18) and (19), we can define a new Lyapunov function for the nonconvex-PL BLO as

\[^{k}:= F(x^{k},y^{k};w^{}(x^{k},y^{k}))+c_{y}(x^{k},y^ {k})\] (20)

where \(c\) is chosen to balance the coefficient of the term \(_{y}(x^{k},y^{k})\) and \(\|d_{x}^{k}\|^{2}\) such that

\[^{k+1}-^{k} -()\|d_{x}^{k}\|^{2}-()_{y}(x^{k},y^{k})+()b_{k}^{2}.\] (21)

Telescoping to (21) results in the convergence of both \(\|d_{x}^{k}\|^{2}\) and \(_{y}(x^{k},y^{k})\). By definition, \(\|d_{x}^{k}\|^{2}=_{x}(x^{k},y^{k+1},w^{k+1})\), so the convergence of \(_{x}(x^{k},y^{k},w^{k})\) is implied by the Lipschitz continuity of increments and the fact that \(\|y^{k+1}-y^{k}\|,\|w^{k+1}-w^{k}\| 0\). Likewise, the convergence of \(_{w}(x^{k},y^{k},w^{k})\) can be established by recognizing that \(b_{k}^{2}\) is sufficiently small when selecting a large \(T\), ensuring that \(_{w}(x^{k},y^{k+1},w^{k+1})\) is also small, and consequently, \(_{w}(x^{k},y^{k},w^{k})\). The convergence results of GALET can be formally stated as follows.

**Theorem 2**.: _Under Assumption 1-2, choosing \(,,=(1)\) with some proper constants and \(N=(1),T=((K))\), then it holds that_

\[_{k=0}^{K-1}_{x}(x^{k},y^{k},w^{k})\!=\! (),\ \ \!_{k=0}^{K-1}_{w}(x^{k},y^{k},w^{k})\!=\! (),\ \ \!_{k=0}^{K-1}_{y}(x^{k},y^{k})\!=\! ()\!.\]

Figure 4: Trajectories of GALET under different choices of the parameters in UL, LM and LL level for Example 1. The \(x\)-axis denotes the value of \(x^{k}\), the \(y\)-axis represents the first coordinates of \(y^{k}\). The color of the point shows the optimality gap measured by (46) with the color bar shown right. The yellow square \(\) is the starting point and the red star \(\) represent the optimal \((x^{*},y^{*})\).

From Definition 3, one need \((KT)=(^{-1}(^{-1}))=:} (^{-1})\) iterations in average to achieve \(\)-stationary point of the BLO problem (1). The next remark shows that this complexity is optimal.

**Remark 2** (Lower bound).: The iteration complexity \(}(^{-1})\) in Theorem 2 is optimal in terms of \(\), up to logarithmic factors. This is because when \(f(x,y)\) is independent of \(y\) and \(g(x,y)=0\), Assumptions 1 and 2 reduce to the smoothness assumption of \(f\) on \(x\), and thus the \((^{-1})\) lower bound of nonconvex and smooth minimization in  also applies to BLO under Assumptions 1 and 2.

## 5 Preliminary Simulations and Conclusions

The goal of our simulations is to validate our theories and test the performance of GALET on actual learning applications. The experimental setting and parameter choices are included in the Appendix.

**Our stationary measure is a necessary condition of the global optimality.** As shown in Figure 1, GALET approaches the global optimal set of Example 1 and our stationary measure also converges to \(0\), while the value-function based KKT score does not.

**UL stepsize is the most sensitive parameter in our algorithm.** As shown in Figure 4, varying UL stepsize \(\) leads to different trajectories of GALET, while varying parameters in the LL and shadow implicit gradient level only cause small perturbations. This means that \(\) is the most sensitive parameter. The fact that GALET is robust to small values of \(T\) and \(N\) makes it computationally appealing for practical applications, eliminating the need to tune them extensively. This phenomenon also occurs in the hyper-cleaning task.

**Our method converges fast on the actual machine learning application.** We compare GALET with BOME , IAPTT-GM  and V-PBGD  in the hyper-cleaning task on the MNIST dataset. As shown in Figure 5, GALET converges faster than other methods and the convergence rate of GALET is \((1/K)\), which matches Theorem 2. Table 2 shows that the test accuracy of GALET is comparable to other methods.

**Conclusions and limitations.** In this paper, we study BLO with lower-level objectives satisfying the PL condition. We first establish the stationary measure for nonconvex-PL BLO without additional CQs and then propose an alternating optimization algorithm that generalizes the existing alternating (implicit) gradient-based algorithms for bilevel problems with a strongly convex lower-level objective. Our algorithm termed GALET achieves the \(}(^{-1})\) iteration complexity for BLO with convex PL LL problems. Numerical experiments are provided to verify our theories.

One potential limitation is that we only consider the deterministic BLO problem and require second-order information, and it is unclear whether our analysis can be generalized to handle the stochastic case and whether the same iteration complexity can be guaranteed with full first-order information. Another limitation is Assumption 2. This stipulates that the singular value of the LL Hessian must be bounded away from \(0\) to ensure the stability of the \(\{w^{k}\}\).