# Functionally Constrained Algorithm Solves

Convex Simple Bilevel Problems

 Huaqing Zhang\({}^{}\)\({}^{1,2}\) Lesi Chen\({}^{}\)\({}^{1,2}\) Jing Xu\({}^{1}\) Jingzhao Zhang\({}^{1,2,3}\)

\({}^{1}\)IIIS, Tsinghua University \({}^{2}\)Shanghai Qizhi Institute

\({}^{3}\)Shanghai AI Lab

{zhanghq22, chenlc23, xujing21}@mails.tsinghua.edu.cn

jingzhaoz@mail.tsinghua.edu.cn

Equal contributions.

###### Abstract

This paper studies simple bilevel problems, where a convex upper-level function is minimized over the optimal solutions of a convex lower-level problem. We first show the fundamental difficulty of simple bilevel problems, that the approximate optimal value of such problems is not obtainable by first-order zero-respecting algorithms. Then we follow recent works to pursue the weak approximate solutions. For this goal, we propose a novel method by reformulating them into functionally constrained problems. Our method achieves near-optimal rates for both smooth and nonsmooth problems. To the best of our knowledge, this is the first near-optimal algorithm that works under standard assumptions of smoothness or Lipschitz continuity for the objective functions.

## 1 Introduction

This work focuses on the following optimization problem:

\[_{}\;f()_{g}^{}*{arg\,min}_{ }g(),\] (1)

where \(f,g\) are convex and continuous functions and \(^{n}\) is a compact convex set. Such a problem is often referred to as "simple bilevel optimization" in the literature, as the upper-level objective function \(f\) is minimized over the solution set of a lower-level problem. It captures a hierarchical structure and thus has many applications in machine learning, including lexicographic optimization [13; 15] and lifelong learning [13; 18]. Understanding the structure of simple bilevel optimization and designing efficient algorithms for it is vital and has gained massive attention in recent years [1; 5; 6; 10; 12; 13; 14; 19; 23; 24; 25; 26; 27].

To solve the problem, one may observe that Problem (1) is equivalent to the convex optimization problem \(_{_{g}^{}}f()\) with _implicitly_ defined convex domain \(_{g}^{}\). Hence, it is natural to try to design first-order methods to find \(}^{n}\) such that

\[|f(})-f^{}|_{f}, g(})-g^{ }_{g},\] (2)

where \(f^{}\) is the optimal value of Problem (1) and \(g^{}\) is the optimal value of the lower-level problem (\(_{z}g(z)\)). We highlight the **asymmetry** in \(f\) and \(g\) here. \(f^{}\) is the minimal in the constrained set \(_{g}^{}\), and hence it is possible that \(f()<f^{}\) for some \(\). On the other hand, \(g^{}\) is globally minimal and hence \(g^{} g()\) for any \(\). _Such asymmetry is natural as the role of \(f,g\) are inherently asymmetrical for bilevel problems._ We call such \(}\) a \((_{f},_{g})\)_-absolute optimal solution_.

When \(_{g}^{*}\) is explicitly given, finding such a solution is easy as we can apply methods for constrained optimization problems such as the projected gradient method and Frank-Wolfe method [4, Section 3]. Yet, somewhat surprisingly, our first contribution in this paper (Theorem 4.1 and 4.2) shows that it is generally intractable for any zero-respecting first-order method to find absolute optimal solutions for Problem (1). Our negative result shows the fundamental difficulty of simple bilevel problems compared to classical constrained optimization problems.

As a compromise, most approaches developed for simple bilevel optimization in the literature aim to find a solution \(}^{n}\) such that

\[f(})-f^{*}_{f}, g(})-g^{*} _{g},\] (3)

which we call a \((_{f},_{g})\)_-weak optimal solution_. Much progress has been achieved towards this goal . We note all the above algorithms fall in the class of zero-respecting algorithms (Assumption 3.4) and hence cannot obtain absolute optimal solutions, unless additional assumptions are made. (See Remark4.1 and Appendix D for further discussions.)

Our second contribution pushes this boundary by proposing near-optimal lower and upper bounds. We study two settings: **(a)**\(f\) is \(C_{f}\)-Lipschitz and \(g\) is \(C_{g}\)-Lipschitz, **(b)**\(f\) is \(L_{f}\)-smooth and \(g\) is \(L_{g}\)-smooth. We can extend the worst-case functions for single-level optimization to Problem (1) to show lower bounds of

1. \((\{C_{f}^{2}/_{f}^{2},C_{g}^{2}/_{g}^{2} \})\) for the setup (a);
2. \((\{/_{f}},/_{g}} \})\) for the setup (b).

Given our constructed lower bounds, we further improve known upper bounds by reducing the task of finding \((_{f},_{g})\)-weak optimal solutions to minimizing the functionally constrained problem:

\[_{}f(), () g()-^{*} 0,\] (4)

where \(^{*}\) is an approximate solution to the lower level problem \(_{}g()\). Then we further leverage the reformulation by Nesterov [20, Section 2.3.4] which relates the optimal value of Problem (4) to the minimal root of the following auxiliary function, where a discrete minimax problem defines the function value:

\[^{*}(t)=_{}\{(t,) \{f()-t,()\}\}.\] (5)

Based on this reformulation, we introduce a novel method FC-BiO (Functionally Constrained Bilevel Optimizer). FC-BiO is a double-loop algorithm. It adopts a bisection procedure on \(t\) in the outer loop and applies gradient-based methods to solve the sub-problem (5). Our algorithms achieve the following upper bounds:

1. \(}(\{C_{f}^{2}/_{f}^{2},C_{g}^{2}/ _{g}^{2}\})\) for the setup (a);
2. \(}(\{/_{f}},/ _{g}}\})\) for the setup (b),

where \(}\) hides logarithmic terms. Both complexity upper bounds match the corresponding lower bounds up to logarithmic factors. In words, we summarize our contributions as follows:

* We prove the intractability for any zero-respecting first-order methods to find a \((_{f},_{g})\)-absolute optimal solution of simple bilevel problems.
* We propose a novel method FC-BiO that has near-optimal rates for finding \((_{f},_{g})\)-weak optimal solutions of both nonsmooth and smooth problems. To the best of our knowledge, this is the first near-optimal algorithm that works under standard assumptions of smoothness or Lipschitz continuity for the objective functions. A comparison of previous results can be found in Section 2.

Related work

In the literature, various methods [1; 3; 6; 10; 12; 13; 14; 18; 19; 23; 24; 25; 26; 27] have been proposed to achieve a \((_{f},_{g})\)-weak optimal solution to simple bilevel problems defined as Equation (3). Below, we review the existing methods with non-asymptotic convergence. For ease of presentation, we state the results for \(_{f}=_{g}=\).

Prior results on Lipschitz problemsKaushik and Yousefian  proposed the averaging iteratively regularized gradient method (a-IRG) for convex optimization with variational inequality constraints, of which Problem (1) is a special case. a-IRG achieves the rate of \((1/^{4})\). Shen et al.  proposed a method for solving Problem (1) with \((1/^{3})\) complexity based on the online learning framework. When \(f\) is Lipschitz continuous and \(g\) is smooth, Merchav and Sabach  proposed a gradient-based algorithm with \((1/^{1/(1-)})\) complexity for any \((0.5,1)\). However, none of these methods can achieve the optimal rate of \((^{-2})\).

Prior results on smooth problemsSamadi et al.  proposed the regularized accelerated proximal method (R-APM) with a complexity of \((1/)\). Under the additional weak sharp minima condition on \(g\), the complexity of R-APM improves to \((1/)\). However, this condition is often too strong and does not hold for many problems. Chen et al.  extended the result of  to the more general \(\)-Holderian error bound condition. However, their method achieves the optimal rate only when \(=1\), which reduces to the weak sharp minima condition. Jiang et al.  developed a conditional gradient type algorithm (CG-BiO) with a complexity of \((1/)\), which approximates \(_{g}^{*}\) similar to the cutting plane approach. Later on, Cao et al.  proposed an accelerated algorithm with a similar cutting plane approach to achieve the rate of \((\{1/},1/_{g}\})\), which can further be improved to \((1/)\) under the additional weak sharp minima condition. Recently, Wang et al.  reduced Problem (1) to finding the smallest \(c\) such that the optimal value of the following parametric problem is \(g^{*}\): \(_{^{n}}g(),\ \ f() c\). They adopted a bisection method to find such a \(c\). To solve this parametric problem, Accelerated Proximal Gradient method is applied on \(g\) with projection operator onto the sublevel set \(_{c}=\{ f() c\}\), which we call _sublevel set oracles_. This leads to an upper bound of \(}(1/)\). Such an oracle is obtainable for norm-like functions such as \(f()=\|\|^{2}\). However, it may be computationally intractable for more general functions, such as MSE loss or logistic loss. It is a very strong oracle that is seldom used in the literature on optimization: the single-level optimization of a function \(f\) using sublevel set oracles can be completed in \(((1/))\) iterations of bisection procedure. Compared with previous work [6; 10; 24; 28], our proposed methods achieve the \(}(1/)\) rate _under standard assumptions, without assuming \(f\) is a norm-like function or \(g\) satisfies the weak sharp minima condition._

Comparison with Nesterov's methods for functionally constrained problemsBased on similar reformulation, Nesterov  has proposed algorithms for functionally constrained problems, of which Problem (4) is a special case: one for smooth problems in Section 2.3.5, and one for Lipschitz problems in Section 3.3.4. However, Nesterov's algorithm for smooth problems relies on the strong convexity of \(f\) and \(g\), which does not hold in our bilevel setups. In this case, \(_{g}^{*}\) would be a singleton, rendering the upper-level problem trivial. Our algorithm does not require the strong convexity assumption, and has a unified framework for both smooth and nonsmooth problems.

## 3 Preliminaries

For any \(^{n}\), let \(_{[j]}\) represent the \(j\)-th coordinate of \(\) for \(j=1,,n\). We use \(():=\{j[d]\ :\ _{[j]} 0\}\) to denote the support of \(\). The Euclidean ball centered at \(\) with radius \(R\) is denoted as \((,R)\{\ |\ \|-\|_{2}  R\}\). For any closed convex set \(^{n}\), the Euclidean projection of \(\) onto \(\) is denoted by \(_{}()*{arg\,min}_{y }\|-\|_{2}\). We say a function \(h\) is \(C\)-Lipschitz in domain \(\) if \(\|h()-h()\|_{2} C\|-\|_{2}\) for all \(,\). We say a differentiable real-valued function \(h\) is \(L\)-smooth if it has \(L\)-Lipschitz continuous gradients.

We now state the assumptions required in our theoretical results.

**Assumption 3.1**.: _Consider Problem (1). We assume that_

1. _Functions_ \(f\) _and_ \(g:^{n}\) _are convex and continuous.__._
2. _The feasible set_ \(\) _is convex and compact with diameter_ \(D=_{,}\|-\|_{2}\)_._

The compactness assumption ensures that the subprocesses adopted in our method have a unified upper complexity bound (see Section 5.3). We note that other works involving bisection procedures, such as Wang et al. , may also need to address this issue to derive an explicit dependence on the distance term (although it is not stated formally in their paper). For unconstrained problems, if we know that the initial distance \(\|^{*}-_{0}\|_{2}\) is upper bounded by \(R\), we can simply take \(=(_{0},R)\).

We use Assumption 3.1 throughout this paper, but distinguish the following two different settings.

**Assumption 3.2**.: _Consider Problem (1). We assume that \(f\) and \(g\) are \(L_{f}\)-smooth and \(L_{g}\)-smooth respectively. We call such problems \((L_{f},L_{g})\)-smooth problems._

**Assumption 3.3**.: _Consider Problem (1). We assume that \(f\) and \(g\) are \(C_{f}\)-Lipschitz and \(C_{g}\)-Lipschitz in \(\) respectively. We call such problems \((C_{f},C_{g})\)-Lipschitz problems._

To study the complexity of solving Problem (1), we make the following assumption on the algorithms.

**Assumption 3.4** (zero-respecting algorithm class).: _An iterative method \(\) can access the objective functions \(f\) and \(g\) only through a first-order black-box oracle, which takes a test point \(}\) as the input and returns \( f(}), g(})\), where \( f(}), g(})\) are arbitrary subgradients of the objective functions at \(}\). \(\) generates a sequence of test points \(\{_{k}\}_{k=0}^{K}\) with_

\[(_{k+1})(_{0}) (_{0 s k}( f(_{s}) )( g(_{s}))).\] (6)

This assumption generalizes the standard definition of _zero-respecting_ algorithm for single-level minimization problems [7; 20]. Many existing methods that incorporate a gradient step in the update for Problem (1) clearly fall within this class of algorithms, including those proposed by [10; 18; 19; 23; 24; 25], since the gradient step ensures that \(_{k}_{0}+\{ f(_{0}),  g(_{0}),, f(_{k-1}), g( _{k-1})\}\). In the appendix, we show that the proposed algorithm in this paper and the conditional gradient type methods [5; 13] also satisfy the condition (6) when the domain is a Euclidean ball centered at \(_{0}\) (see Proposition C.1 and Remark C.1), which suffices to establish the negative results, including the intractability results for absolute optimal solutions and lower complexity bounds for weak optimal solutions.

The following concept of _first-order zero-chain_, introduced by Nesterov [20, Section 2.1.2], plays an essential role in proving lower bounds for zero-respecting algorithms. In our paper, we leverage the chain-like structure to show the intractability of finding absolute optimal solutions.

**Definition 3.1** (first-order zero-chain).: _We call a differentiable function \(h():^{q}\) a first-order zero-chain if for any sequence \(\{_{k}\}_{k 0}\) satisfying_

\[(_{k+1})_{0 s k} ( h(_{s})),\ k 1;_{0}=,\]

_it holds that \(_{k,[j]}=0,k+1 j q\)._

Definition 3.1 defines differentiable zero-chain functions. We can similarly define non-differentiable zero-chain, by requiring \((_{k+1})\) to be in \(_{0 s k}( h(_{s}))\), where \( h()\) is a (possibly adversarial) subgradient of \(h\) at \(\).

## 4 Finding absolute optimal solutions is hard

Faced with Problem (1), a natural initial response is to seek an approximate solution \(}\) such that \(f(})\) is as close to \(f^{*}\) as possible, under the premise that \(g(})\) is close to \(g^{*}\). Such a goal is captured by the concept of \((_{f},_{g})\)-absolute optimal solutions as defined in (2). However, it turns out that finding a \((_{f},_{g})\)-absolute optimal solution is intractable for any zero-respecting first-order methods in both smooth and Lipschitz problems as shown in the following theorems.

**Theorem 4.1**.: _For any first-order algorithm \(\) satisfying Assumption 3.4 that runs for \(T\) iterations and any initial point \(_{0}\), there exists a \((1,1)\)-smooth instance of Problem (1) such that the optimal solution \(^{*}\) satisfies \(\|_{0}-^{*}\|_{2} 1\) and \(|f(_{0})-f^{*}|\). For the iterates \(\{_{k}\}_{k=0}^{T}\) generated by \(\), the following holds:_

\[f(_{k})=f(_{0}), 1 k T.\]

**Theorem 4.2**.: _For any first-order algorithm \(\) satisfying Assumption 3.4 that runs for \(T\) iterations and any initial point \(_{0}\), there exists a \((1,1)\)-Lipschitz instance of Problem (1) and some adversarial subgradients \(\{ f(_{k}), g(_{k})\}_{k=0}^{T-1}\) such that the optimal solution \(^{*}\) satisfies \(\|_{0}-^{*}\|_{2} 1\) and \(|f(_{0})-f^{*}|\). For the iterates \(\{_{k}\}_{k=0}^{T}\) generated by \(\), the following holds_

\[f(_{k})=f(_{0}), 1 k T.\]

The proofs of Theorem 4.1 and Theorem 4.2 rely on the concept of worst-case convex zero-chain (Proposition A.1 and A.2). We show that for any first-order zero-respecting algorithm that runs for \(T\) iterations, there exists a "hard instance" such that \(f(_{t})\) remains unchanged from the initial value \(f(_{0})\) throughout the entire process. The complete proof is provided in Appendix A.

The constructions of the above hardness results are motivated by the work , which demonstrated that for general bilevel optimization problems of the form \(_{^{n},^{m}}f(, )\) subject to \(_{^{m}}g(,)\), there exists a "hard instance" in which any zero-respecting algorithm always yields \(_{k}=_{0}\) for all \(1 k T\). Although our construction has a very similar high-level idea to , the \(f\) and \(g\) we construct are different from the functions in  since our desired conclusion is different.

**Remark 4.1**.: _Some previous works  provide guarantees for finding \((_{f},_{g})\)-absolute optimal solutions. However, these works assume an additional Holderian error bound condition  on \(g\). Our near-optimal methods for finding weak optimal solutions, proposed in the next section, also work well under this additional assumption and achieve the best-known convergence rate for absolute suboptimality both in smooth and Lipschitz settings. See Appendix D for further discussions._

## 5 Near-optimal methods for weak optimal solutions

Due to the intractability of obtaining \((_{f},_{g})\)-absolute optimal solutions of Problem (1), most existing works focus on developing first-order methods to find \((_{f},_{g})\)-weak optimal solutions as defined in (3). In this section, we establish the lower complexity bounds for finding weak optimal solutions and propose a new framework for simple bilevel problems named Functionally Constrained Bilevel Optimizer (FC-BiO) that achieves near-optimal convergence in both Lipschitz and smooth settings.

### Lower complexity bounds

We first establish the lower complexity bounds for finding a \((_{f},_{g})\)-weak optimal solution of \((L_{f},L_{g})\)-smooth problems and \((C_{f},C_{g})\)-Lipschitz problems. The results follow directly from existing lower bounds for single-level optimization problems, as simple bilevel optimization is a more general framework. Although the proof is straightforward, we present the results because establishing a precise lower bound is essential for demonstrating that an algorithm is truly near-optimal.

**Theorem 5.1**.: _Given \(L_{f},L_{g},D>0\). For any first-order algorithm \(\) satisfying Assumption 3.4 and any initial point \(_{0}\), there exists a \((L_{f},L_{g})\)-smooth instance of Problem (1) on the domain \(=(_{0},D)\) such that the optimal solution \(^{*}\) is contained in \(\) and \(\) needs at least \((\{}{_{f}}},}{ _{g}}}\}D)\) iterations to find a \((_{f},_{g})\)-weak optimal solution._

**Theorem 5.2**.: _Given \(C_{f},C_{g},D>0\). For any first-order algorithm \(\) satisfying Assumption 3.4 and any initial point \(_{0}\), there exists a \((C_{f},C_{g})\)-Lipschitz instance of Problem (1) on the domain \(=(_{0},D)\) such that the optimal solution \(^{*}\) is contained in \(\) and \(\) needs at least \((\{^{2}}{_{f}^{2}},^{2}}{ _{g}^{2}}\}D^{2})\) iterations to find a \((_{f},_{g})\)-weak optimal solution._

### Our proposed algorithms

We now present a unified framework applicable to both smooth and Lipschitz problems. The proposed algorithms nearly match the lower complexity bounds in both settings up to logarithmic factors.

Problem reformulationWe apply two steps of reformulation. First, we relax Problem (1) to Problem (4), where the constraint \(_{g}^{*}\) is replaced by a relaxed functional constraint \(() g()-^{*} 0\) and \(^{*}\) is an approximate solution to the lower level problem \(_{}g()\). Denoting \(^{*}\) as the optimal value of Problem (4), the following lemma holds:

**Lemma 5.1**.: _If \(g^{*}^{*} g^{*}+}{2}\) and \(}\) is a \((_{f},_{g}/2)\)-weak optimal solution to Problem (4), i.e. \(f(})^{*}+_{f},(}) _{g}/2\), then \(}\) is a \((_{f},_{g})\)-weak optimal solution to Problem (1)._

Therefore, it suffices to pursue an approximate solution of Problem (4). Second, Problem (4) is further reduced to the problem of finding the smallest root of the following auxiliary function:

\[^{*}(t)=_{}\{(t,) \{f()-t,()\}\}.\] (7)

Such reformulation is introduced in Nesterov [20, Section 2.3] with the following characterization.

**Lemma 5.2** (Nesterov [20, Lemma 2.3.4]).: _Let \(^{*}\) be the optimal value of Problem (4), and let \(^{*}(t)\) be the auxiliary function as defined in (7). The following holds:_

1. \(^{*}(t)\) _is continuous, decreasing, and Lipschitz continuous with constant_ \(1\)_._
2. \(^{*}\) _is exactly the smallest root of_ \(^{*}(t)\)_._

Bisection procedureBased on the preceding reformulation, we propose Algorithm 1 (FC-BiO), which uses a bisection procedure to estimate the smallest root of \(^{*}()\). For now, we assume that the desired accuracy on upper-level and lower-level problems is the same, (_i.e._\(_{f}=_{g}=\)). Later we will show in Corollary 5.1 that we can handle the case when \(_{f}_{g}\) by simply scaling the objectives.

```
0: Problem parameters \(_{0},D\), desired accuracy \(\), total number of iterations \(T\), initial bounds \(,u\), and a subroutine for Problem (7) \(\).
1: Set \(N=_{2}\), \(K=T/N\). Set \(}=_{0}\).
2:for\(k=0,,N-1\)do
3: Set \(t=\).
4: Solve with the subroutine \((}_{(t)},^{*}(t))=(},D,t,K)\).
5: Set \(}=}_{(t)}\)
6:if\(^{*}(t)>\)then
7: Set \(=t\).
8:else
9: Set \(u=t\).
10:endif
11:endfor
12:return\(}=}_{(u)}\) as the approximate solution. ```

**Algorithm 1** Functionally Constrained Bilevel Optimizer (FC-BiO)

Algorithm 1 applies the bisection method within an initial interval \([,u]\) which contains the smallest root, \(^{*}\), for \(N=_{2}\) iterations. Similar to , the initial interval can be obtained by applying single-level first-order methods. The lower bound \(\) is obtained by solving the global minimum of the upper-level objective \(f\) over \(x\), while \(u=f(}_{g})\) serves as a valid upper bound, where \(}_{g}\) is an approximate solution to the lower-level problem. Further details can be found in Appendix B.1. In each iteration, we set \(t=\). To approximate the function value of \(^{*}(t)\), we apply a first-order algorithm \(\) to solve the discrete minimax problem (7). For the Lipschitz setting, we let \(\) be the Subgradient Method (SGM, Algorithm 2) [4, Section 3.1]. For the smooth setting, we let \(\) be the generalized accelerated gradient method (generalized AGM, Algorithm 3) [20, Algorithm 2.3.12]. These methods guarantee to find an approximate solution \(}_{(t)}\) of Problem (7) such that

\[^{*}(t)^{*}(t)(t,}_{(t)}) ^{*}(t)+.\] (8)

If \(^{*}(t)>/2\), we update \(=t\). Conversely, if \(^{*}(t)/2\), we set \(u=t\). For the initial point of \(\), we exploit a _warm-start_ strategy (see more details in Appendix B.2). After completing \(N\) iterations, we return \(}=}_{(u)}\) as the output. As shown in Lemma 5.3, \(}\) is guaranteed to be a \((,)\)-weak optimal solution to Problem (1).

We remark that since we can only solve an approximate value of \(^{*}(t)\), the upper bound \(u\) might fall below \(^{*}\) during the bisection process. But this is acceptable since we are only in pursuit of a weak optimal solution instead of an absolute optimal solution.

**Lemma 5.3**.: _If \(^{*}\) satisfies \(g^{*}^{*} g^{*}+\) and (8) holds for every \(t\) in the process of Algorithm 1, then the approximate solution \(}\) returned by Algorithm 1 is a \((,/2)\)-weak optimal solution to Problem (4), and therefore a \((,)\)-weak optimal solution to Problem (1) by Lemma 5.1._

According to this lemma, \(((}{{}}))\) iterations of the outer loops are sufficient to find a \((,)\)-weak optimal solution. Next, we will discuss the process and complexity of the subroutines in detail.

### Subroutines and total complexity

To proceed with the bisection process, we need to invoke a subroutine \(\) to approximate the function value of \(^{*}(t)=_{ Z}(t,)\) in each outer iteration, where \((t,)=\{f()-t,()\}\). This reduces to a discrete minimax optimization problem (Problem (7)) for a given \(t\). Below we demonstrate the subroutines to solve this problem in Lipschitz and smooth settings.

Lipschitz settingWhen \(f\) and \(g\) are convex and \(C_{f}\) and \(C_{g}\)-Lipschitz respectively, it holds that \((t,)\) is also convex and Lipschitz with constant \(\{C_{f},\,C_{g}\}\). In this case, setting \(\) to be the Subgradient Method (SGM) [4, Section 3.1] applied on \((t,)\) (Algorithm 2) directly achieves the optimal convergence rate. To implement the SGM method, the subgradient of \((t,)\) needs to be computed as given in the following proposition:

**Proposition 5.1** (Nesterov [20, Lemma 3.1.13]).: _Consider \((t,)=\{f()-t,()\}\) where \(f\) and \(g\) are convex functions. For given \(t\). We have_

\[_{}(t,)= f(),& f()-t>();\\ (),&f()-t<();\\ \{ f(),()\},&f()-t=().\]

Algorithm 2 has the following convergence guarantee:

**Lemma 5.4** (Bubeck et al. [4, Theorem 3.2]).: _Suppose Assumption 3.1 and 3.3 hold. When \(KC^{2}}{^{2}}\), the approximate value \(^{*}(t)\) produced by Algorithm 2 satisfies \(^{*}(t)^{*}(t)^{*}(t)+\), where \(C=\{C_{f},C_{g}\}\)._

We refer to Algorithm 1 with SGM subroutine (Algorithm 2) as FC-BiO\({}^{}\). Combining with Lemma 5.3, we obtain the following total iteration complexity of FC-BiO\({}^{}\):

**Theorem 5.3** (Lipschitz setting).: _Suppose Assumption 3.1 and 3.3 hold and \(_{f}=_{g}=\). When_

\[T_{2}^{2},C_{g}^{2}\}}{^{2}}D^{2},\]

_the approximate solution \(}\) produced by FC-BiO\({}^{}\) is a \((,)\)-weak optimal solution to Problem (1)._

Smooth settingThe optimal first-order method for optimizing smooth objective functions is the celebrated Accelerated Gradient Method (AGM) [20, Section 2.2] proposed by Nesterov. In contrast to the Lipschitz setting, AGM cannot be applied to \((t,)=\{f()-t,()\}\) directly when \(f\) and \(g\) are convex and smooth, as the smoothness condition no longer holds for \((t,)\). However, Nesterov [20, Section 2.3] showed that by simply replacing the gradient step in standard AGM with the following _gradient mapping_ (Nesterov [20, Definition 2.3.2])

\[_{k+1}&=*{ arg\,min}_{}(t,;_{k}) f(_{k})+ f(_{k}), -_{k}+\|-_{k}\|_{2}^ {2}-t,\\ (_{k})+(_{k}),-_{k}+\|-_{k}\|_{2}^ {2}}},\] (9)

the optimal rate of \(()\) can be achieved for Problem (7). Here \(\{_{k}\},\{_{k}\}\) are the test point sequences and \(L=\{L_{f},L_{g}\}\). Solving \(_{k+1}\) for general discrete minimax problems (where the maximum is taken over potentially more than two objective functions, as studied in Nesterov [20, Section 2.2]), reduces to a quadratic programming (QP) problem and may not be efficiently solvable. However, we demonstrate that in our problem setup, \(_{k+1}\) can be expressed in the form of a projection onto the feasible set \(\), or onto the intersection of \(\) and a hyperplane. A similar subproblem also arises in Cao et al. [6, Remark 3.2]. When the structure of \(\) is simple, such as when it is a Euclidean ball, the subproblem may admit a closed-form solution. Otherwise, Dykstra's projection algorithm can be applied to solve it .

**Proposition 5.2**.: _Define the descent step candidates_

\[_{1}&=_{} (_{k}- f(_{k})),_{2}=_{}(_{k}-( _{k})),\\ _{3}&=_{} (_{k}- f(_{k})),\] (10)

_where \(^{n}\) is a hyperplane defined by_

\[=\{ f(_{k})-(_{k})+  f(_{k})-(_{k}),- _{k}-t=0\}.\]

_Then the solution to (9) is \(_{k+1}=*{arg\,min}_{\{_{i}|i\{1,2,3\}\}} (t,_{i};_{k})\)._

We present the generalized AGM subroutine (Algorithm 3) and its convergence rate below.

**Lemma 5.5** (Nesterov [20, Theorem 2.3.5]).: _Suppose Assumption 3.1 and 3.2 hold.When \(K D}\), the approximate value \(^{*}(t)\) produced by Algorithm 3 satisfies \(^{*}(t)^{*}(t)^{*}(t)+\), where \(L=\{L_{f},L_{g}\}\)._

We refer to Algorithm 1 with generalized AGM subroutine (Algorithm 3) as FC-BiO(tm), whose total iteration complexity is given by the following theorem:

**Theorem 5.4** (Smooth setting).: _Suppose Assumption 3.1 and 3.2 hold and \(_{f}=_{g}=\). When_

\[T_{2},L_{g}\}}{}}D,\]

_the approximate solution \(}\) produced by FC-BiO(tm) is a \((,)\)-weak optimal solution to Problem (1)._For more general cases when the desired accuracy for the upper-level and lower-level problems is different (_i.e._\(_{f}_{g}\)), we can simply scale the objective functions before applying FC-BiO\({}^{}\) or FC-BiO\({}^{}\), resulting in the following guarantee:

**Corollary 5.1**.: _Suppose Assumption 3.1 holds. By scaling \(^{}=}{_{g}}\) and applying FC-BiO\({}^{}\) or FC-BiO\({}^{}\) on functions \(f\) and \(^{}\), a \((_{f},_{g})\)-weak optimal solution to Problem (1) is obtained within the complexity of \(}(\{^{2}}{_{f}^{2}},^{2}}{_{g}^{2}}\}D^{2})\) under Assumption 3.3 and \(}(\{}{_{f}}},}{_{g}}}\}D)\) under Assumption 3.2._

Our proposed algorithms are near-optimal in both Lipschitz and smooth settings as the convergence results in Corollary 5.1 match the lower bounds established in Theorem 5.1 and Theorem 5.2.

## 6 Numerical experiments

In this section, we evaluate our proposed methods on two different bilevel problems with smooth objectives. We compare the performance of FC-BiO\({}^{}\) with existing methods, including a-IRG , Bi-SG , CG-BiO, AGM-BiO , PB-APG, and Bisec-BiO. The following problems are also Lipschitz on a compact set \(\), so we implement FC-BiO\({}^{}\) as well. The initialization time of FC-BiO\({}^{}\), FC-BiO\({}^{}\), CG-BiO, and Bisec-BiO is taken into account and is plotted in the figures. Our implementations of CG-BiO and a-IRG are based on the codes from , which is available online1.

### Minimum norm solution

As in , we consider the following simple bilevel problem:

\[f()=\|\|_{2}^{2}, g()=\|A-b\|_{2}^{2}.\] (11)

We set the feasible set \(=(,2)\). We use the Wikipedia Math Essential dataset , which contains \(1068\) instances with \(730\) attributes. We uniformly sample \(400\) instances and denote the feature matrix and outcome vector by \(A\) and \(\) respectively. We choose the same random initial point \(_{0}\) for all methods. We set \(_{f}=_{g}=10^{-6}\). For this problem, we can explicitly solve \(^{*}\) and \(f^{*}\) to measure the convergence. Figure 1 shows the superior performance of our method compared to existing methods in both upper-level and lower-level. The only exception is Bisec-BiO , which shows a comparable performance to our method. This also aligns well with the theory as these two methods have the same convergence rates. We remark that the output of our method satisfies that \(f(})<f^{*}\). Thus although \(|f(})-f^{*}|>_{f}\), indeed a \((_{f},_{g})\)-weak optimal solution is solved by FC-BiO\({}^{}\). See more experiment details in Appendix E.1.

### Over-parameterized logistic regression

We examine simple bilevel problems where the lower-level and upper-level objectives correspond to the training loss and validation loss respectively. Here we address the logistic regression problem

Figure 1: The performance of Algorithm 1 compared with other methods in Problem (11).

using the "rcv1.binary" dataset from "LIBSVM" [8; 16], which contains \(20,242\) instances with \(47,236\) features. We uniformly sample \(m=5000\) instances as the training dataset \((A^{tr},^{tr})\), and \(m\) instances as the validation dataset \((A^{val},^{val})\). We consider the bilevel problem with:

\[ f()&=_{i=1}^ {m}(1+(-(A_{i}^{val})^{}_{i}^{val})),\\ g()&=_{i=1}^{m}(1+ (-(A_{i}^{tr})^{}_{i}^{tr})).\] (12)

We set the feasible set \(=(,300)\). We set the initial point \(_{0}=\) for all methods. We set \(_{f}=_{g}=10^{-3}\). Since projecting to the sublevel set of \(f()\) is not practical, Bisec-BiO  does not apply to this problem, thus we only consider other methods. To the best of our knowledge, no existing solver could obtain the exact value of \(f^{*}\) and \(g^{*}\) of Problem (12). Thus we only plot function value \(f(_{k})\) and \(g(_{k})\), instead of suboptimality. As shown in Figure 2, our method converges faster than other algorithms in both upper-level and lower-level. More details are provided in Appendix E.2.

## 7 Conclusion and future work

This paper provides a comprehensive study of convex simple bilevel problems. We show that finding a \((_{f},_{g})\)-absolute optimal solution for such problems is intractable for any zero-respecting first-order algorithm, thus justifying the notion of weak optimal solution considered by existing works. We then propose a novel method FC-BiO for finding a \((_{f},_{g})\)-weak optimal solution. Our proposed method achieves the near-optmal rates of \(}(\{L_{f}^{2}/_{f}^{2},L_{g}^{2}/_ {g}^{2}\})\) and \(}(\{/_{f}},/_ {g}}\})\) for Lipschitz and smooth problems respectively. To the best of our knowledge, this is the first near-optimal algorithm that works under standard assumptions of smoothness or Lipschitz continuity for the objective functions.

We discuss some limitations unaddressed in this work. First, our method introduces an additional logarithmic factor compared to the lower bounds. We hope future works can further close this gap between upper and lower bounds. Second, our methods cannot be directly applied to stochastic problems . Establishing lower complexity bounds and developing optimal methods for stochastic simple bilevel problems remain an open question for future research.