# 3D Gaussian Splatting as

Markov Chain Monte Carlo

Shakiba Kheradmand1, Daniel Rebain1, Gopal Sharma1,

Weiwei Sun1, Yang-Che Tseng1, Hossam Isack2, Abhishek Kar2,

Andrea Tagliasacchi3,4,5, Kwang Moo Yi1

###### Abstract

While 3D Gaussian Splatting has recently become popular for neural rendering, current methods rely on carefully engineered cloning and splitting strategies for placing Gaussians, which can lead to poor-quality renderings, and reliance on a good initialization. In this work, we rethink the set of 3D Gaussians as a random sample drawn from an underlying probability distribution describing the physical representation of the scene--in other words, Markov Chain Monte Carlo (MCMC) samples. Under this view, we show that the 3D Gaussian updates can be converted as Stochastic Gradient Langevin Dynamics (SGLD) update by simply introducing noise. We then rewrite the densification and pruning strategies in 3D Gaussian Splatting as simply a deterministic state transition of MCMC samples, removing these heuristics from the framework. To do so, we revise the 'cloning' of Gaussians into a relocalization scheme that approximately preserves sample probability. To encourage efficient use of Gaussians, we introduce a regularizer that promotes the removal of unused Gaussians. On various standard evaluation scenes, we show that our method provides improved rendering quality, easy control over the number of Gaussians, and robustness to initialization.

## 1 Introduction

Neural Radiance Fields (NeRF) have been at the forefront of these advancements, providing impressive results through implicit modeling via neural networks, the landscape is further evolving with the introduction of 3D Gaussian splatting.

Neural rendering has seen a significant advancement with the introduction of Neural Radiance Fields (NeRF) , and more recently, 3D Gaussian Splatting (3DGS) . 3D Gaussian Splatting became highly popular thanks to its speed and efficiency--it can render high-quality images in a fraction of the time required by NeRF. Unsurprisingly, various extensions to 3D Gaussian Splatting have been proposed, such as extending 3D Gaussians to dynamic scenes , making them robust to aliasing effects , and generative 3D content creation .

However, despite the various extensions, a common shortcoming of these methods is that they mostly rely on the same initialization and densification strategy for placing the Gaussians: either the one originally suggested by , or other recently proposed variations . Specifically, they rely on carefully engineered cloning and splitting heuristics for placing Gaussians [19, see "adaptive density control"]. Depending on the state of each Gaussian, they are cloned, split, or pruned, which is the primary way to control the number of Gaussians within the 3DGS representation. Moreover,Gaussians are regularly'reset' by setting their opacities to small values to remove _floaters_ in the representations. This heuristic-based approach requires multiple hyperparameters to be carefully tuned and, as we will show later on in the paper, can fail in some scenes.

These heuristics further lead to various problems. It causes the method to heavily rely on good initial point clouds for it to work well, especially when applied to real-world scenes. It is also nontrivial to estimate how many 3D Gaussians will be used for a given scene from just the hyperparameters, making it difficult to control the computation and memory budget in advance without affecting reconstruction quality during inference time. Concurrent works [10; 9] thus focus on having better initialization to solve the former, or study the latter problem . However, even these recent concurrent solutions still rely on heuristics, and they do not always generalize well. In some cases, this leads to sub-optimal placement of Gaussians resulting in poor quality renderings and wasted compute.

To solve this problem, we take a step back and rethink the set of 3D Gaussians as random samples--more specifically, as Markov Chain Monte Carlo (MCMC) samples--drawn from an underlying probability distribution that is proportional to how faithfully these Gaussians reconstruct the scene. With this considered, we show in Section 3.2 that the conventional 3D Gaussian Splitting update rule is very similar to a Stochastic Gradient Langevin Dynamics update [3; 20], where the only term missing is a noise term that promotes the exploration of samples. We thus reformulate 3D Gaussian Splitting into an SGLD framework, an MCMC algorithm, which naturally explores the scene landscape, and samples Gaussians that are effective in reproducing the scene faithfully. It is important to note that while we assume an underlying distribution, this distribution does not need to be explicitly modelled, as the Gaussians themselves are already representing it.

Given this view, the heuristics involved in the densification and pruning of Gaussians, as well as resetting their opacities, are no longer necessary. 3D Gaussians are simply the samples used for MCMC, thus exploring their sample locations is naturally dealt through SGLD updates. Any modification to the set of Gaussians, including increasing or decreasing their cardinality, can be reformulated as a deterministic state transition--relocation of Gaussians--where we move our sample (the set of Gaussians) to another sample (another set of Gaussians with different configuration). Importantly, to minimally disturb the MCMC sampling chain, we make sure that the two states, before and after the move, are of similar probability. This implies that the training loss value does not change as we alter combinatorial properties, such as the number of Gaussians within the representation, preventing the training process from becoming unstable. This simple strategy, under the MCMC framework, is enough to provide renderings of high quality, beyond what is provided by the conventional heuristics.

In more detail, we propose to relocate Gaussians using a 'cloning' strategy, where we move 'dead' Gaussians (with low opacity) to where other 'live' Gaussians exist, but in a way that has minimal impact on the rendering, and thus on the probability distribution of the Gaussians. In other words, we set the composition of the cloned Gaussians to render the same images as before cloning. While a modification of cloning  was recently suggested as a way to ensure the rendering is equal at the Gaussian centers, we show that this is not enough--the whole Gaussian must be considered. Without our careful strategy MCMC sampling provides sub-optimal training. Finally, to encourage efficient use of the Gaussians, we apply L1-regularization. As the extent of a Gaussian is defined both the opacity and the scale of Gaussians, we apply our regularization to both of them. This effectively encourages them to 'disappear' if unnecessary.

We evaluate our method on standard scenes evaluated in  (NeRF Synthetic , MipNeRF 360 , Tank & Temples , Deep Blending ), as well as the OMMO  dataset that exhibit large scene context. With our method, one does not need to initialize the Gaussians carefully. Our method provides high-quality renderings, regardless of whether Gaussians are initialized randomly or from Structure-from-Motion points.

To summarize, our contributions are:

* we reveal the link between 3DGS and MCMC sampling, leading to a simpler optimization;
* we replace the heuristics in 3D Gaussian Splatting with a principled relocation strategy;
* we introduce regularizer to encourage parsimonious use of Gaussians;
* we improve robustness to initialization;
* we provide higher rendering quality.

Related Work

**Novel-view synthesis via Neural Radiance Fields.** Since the introduction of Neural Radiance Fields (NeRF) , it has become extremely popular for building and representing 3D scenes. The core idea behind the method is to learn a neural field that encodes radiance values in the modeling volume, which is then used to render via volume rendering with light rays. Since its first introduction, it has been extended to deal with few views , to generalize to new scenes without training [34; 47], to dynamic  and unbounded scenes , to roughly posed images , to speed up training [29; 46], and even to biomedical applications [7; 51] to name a few. These extensions are by no means an exhaustive list and demonstrate the impact that NeRF had. For a more in-depth survey we refer the readers to .

Amongst works on NeRF, most relevant to ours is , which also employs Stochastic Gradient Langevin Dynamics (SGLD)  to identify the most promising samples to train with, and allow faster training convergence. While we ground ourselves in the same Markov Chain Monte Carlo (MCMC) paradigm based on SGLD, the application context is entirely different. In their work, SGLD is used to perform a form of'soft mining', so to accelerate NeRF training. In our case, we are instead rethinking 3DGS as samples from an underlying distribution that represents the 3D scene.

**Gaussian Splitting.** 3D Gaussian Splitting (3DGS)  is a recent alternative to NeRF that rely on differentiable rasterization instead of volume rendering. In a nutshell, instead of querying points along the ray, it stores Gaussians, which can then be rasterized into each view to form images. This rasterization operation is highly efficient, as instead of querying hundreds of points along a light ray to render a pixel, one can simply rasterize the (few) Gaussians associated with a given pixel. Therefore, Gaussian Splatting allows 1080p images to be rendered at 130 frames per second on modern GPUs, which catalyzed the research community.

Unsurprisingly, various extensions immediately followed. These include ones that focus on removing aliasing effects [48; 42], allowing reflection  or capture of dynamic scenes [41; 43], 3D content generation [36; 52; 49], controllable 3D avatars , and prediction of 3D representations from few-shot images . Methods that focus on more compact representation, thus suitable for rendering on mobile devices, have also been proposed. These methods prune/cluster Gaussians, adaptively selecting the number of spherical harmonics to encode color , and quantize the parameters of the representation . All of these extensions are extremely recent, demonstrating the large interest sparked within the community. With the exception of , one core limitation that these methods share is that they all rely on the original _adaptive density control_ heuristics that 3DGS  proposed. As we demonstrate in this work, this does not necessarily always work, and it require either careful initialization or appropriate tuning. Even then, the rendering outcomes may be suboptimal. For additional research, we direct interested readers to a recent survey .

**Concurrent work.** Bulo _et al._ recently proposed to modify the densification strategy to address issues with cloning Gaussians, as well as densifying Gaussians at locations with high training error. Their method partially addresses the issue with cloning, but it is not enough as we will show in Section 3.4. Their error-based densification is orthogonal to our research direction and could easily be incorporated into our method as well, which we leave to future works. Other works explore how to better initialize through an auxiliary NeRF network  or via trained dense geometry estimators , such as . In our case, we tackle the source of the problem and reduce the dependence on initialization itself.

## 3 Method

We first reformulate Gaussian Splatting as Markov Chain Monte Carlo (MCMC) sampling. We then introduce the new update equations under the MCMC framework with Stochastic Gradient Langevin Dynamics [3; 20]. We then discuss how the heuristics in 3D Gaussian Splatting  can be folded into a novel relocalization scheme. Finally, we discuss the L1 regularization that we use to encourage efficient use of the Gaussians, and the implementation details.

### Brief review of 3D Gaussian Splatting

Before reformulating, we first briefly review 3D Gaussian Splatting  for completeness. 3D Gaussian Splatting represents the scene as a set of 3D Gaussians, which are then rasterized into a desired view via \(\)-blending. This can be viewed as an efficient way to perform volume rendering as in NeRFs . Specifically, for a camera pose \(\) to render a pixel \(\) we order the \(N\) Gaussians by sorting them in the order of increasing distance from the camera and write

\[()=_{i=1}^{N}_{i}_{i}() [_{j=1}^{i-1}(1-_{j}())],\] (1)

where \(_{i}\) is the color of each Gaussian stored as Spherical Harmonics that are converted to color according to the pose \(\), and if we denote their opacity as \(o\), centers as \(\), and covariance as \(\),

\[_{i}()=o_{i}\,-(-(_{i};))^{}_{}( _{i})^{-1}(-(_{i};)),\] (2)

where \(\) is the camera projection operation.

Then, with the color values for each pixel, Gaussians are trained to minimize the loss:

\[_{}=(1-_{})_{1}+ _{}_{},\] (3)

where \(_{1}\) is the average L1 error between \(()\) and the ground-truth colour \(_{}()\), and \(_{}\) is the Structural Similarity Index Metric (SSIM)  between the rendered and ground-truth image. Where \(_{}{=}0.2\) as proposed by .

### 3D Gaussian Splatting as Markov Chain Monte Carlo (MCMC)

Unlike existing approaches to 3D Gaussian Splatting, we propose to interpret the training process of placing and optimizing Gaussians as a _sampling_ process. Rather than defining a loss function and simply taking steps towards a local minimum, we define a distribution \(\) which assigns high probability to collections of Gaussians which faithfully reconstruct the training images. This choice allows us to leverage the power of MCMC frameworks to draw samples from this distribution in a way that is mathematically well-behaved, even when making discrete changes in the parameter space. As such, we can design discrete operations analogous to the original splitting and pruning heuristics of Gaussian Splatting without breaking the assumptions of continuity that underlie typical gradient-based optimization.

To achieve this, we start from the Stochastic Gradient Langevin Dynamics (SGLD) [40; 3] method, which is an MCMC framework that has also recently been applied to novel view synthesis applications . This particular choice is convenient, as SGLD already resembles the commonly used Stochastic Gradient Descent (SGD) update rule, but with additional stochastic noise. Specifically, if we consider the updates of a single Gaussian \(\) in 3DGS, and momentarily ignore their split/merge heuristics:

\[-_{}_{}\, _{}[_{}( ;)],\] (4)

where \(_{}\) is the learning rate, and \(\) is an image sampled from the set of training images \(\). Let us now compare the former to a typical SGLD update:

\[+a_{}( )+b,\] (5)

where \(\) is the data-dependent probability density function for the distribution one wishes to sample from, and \(\) is the noise distribution for exploration. The hyperparameters \(a\) and \(b\) together control the trade-off between convergence speed and exploration1 We note the striking similarity between (4) and (5). In other words, by having the loss as the negative log likelihood of the underlying distribution,

\[=(-_{}),\] (6)

the equations become identical if \(_{}{=}-a\) and \(b{=}0\). Hence, the standard Gaussian Splatting optimization could be understood as having Gaussians that are sampled from a likelihood distribution that is tied to the rendering quality. We further note that this addition of noise to optimization is highly related to traditional optimization methods that inject noise [35; 30; 8] or that perform perturbed gradient descent [17; 18]. Here, we formulate it as MCMC in favour of the probabilistic relationship that it provides in (6), and the removal of heuristics that it enables, which we discuss in Sec. 3.4.

### Updating with Stochastic Gradient Langevin Dynamics

Having revealed the link between SGLD and conventional 3DGS optimization, we rewrite (4) as:

\[-_{}_{} _{}[_{}( ;)]+_{},\] (7)

where \(_{}\) and \(_{}\) are the hyperparameters controlling the learning rate and the amount of exploration enforced by SGLD. In practice, instead of the raw gradients \(_{}_{}[_{ }(;)]\), we use the Adam  optimizer with default parameters for \(_{1}\) and \(_{2}\).

In Equation (7), it is important that the noise term \(\) is designed carefully. The noise term \(\) needs to be added in a way that it can be 'balanced' by the gradient term \(_{_{i}}_{}\), or otherwise (7) reduces to random updates. For example, it is quite common for Gaussians to be narrow when reconstructing scenes to represent lines and edges. Should the added noise force Gaussians to move to locations outside of the previous support regions, this random walk would be irrecoverable, breaking the MCMC sampling chain.

We further notice that exploration is not critical for opacity, scale, and color, and we _do not_ add noise to these parameters. In fact, we empirically found that adding noise to them to slightly harm performance; see Section 4.1. Conversely, it has been shown by  that 3DGS reconstruction can be harmed significantly when areas of space are left unexplored, e.g. due to missing points in the initialization. This suggests potential for noise-based exploration to improve results for both random initialization as well as SFM-derived initializations which suffer from missing geometry.

Finally, as we are interested in the 'converged' quality not just exploration, we reduce the amount of noise when Gaussians are well-behaved, that is, when their opacities are high enough to be guided well by the gradients. Thus, we design the noise term _only on the locations of the Gaussians_ such that it is dependent on their covariances and also its opacities, as well as the learning rate:

\[_{}=_{}-k(o-t) =[ _{},].\] (8)

where \((,)\), \(\) is the sigmoid function, and \(k\) and \(t\) are hyperparameters controlling the sharpness of the sigmoid, which we set as \(k{=}100\) and \(t{=}(1-0.005)\) to make a sharp transition function that goes from zero to one, centered around the default pruning threshold of 3D Gaussian Splatting  for the opacity values of Gaussians. In simple terms, (8) perturbs a Gaussian with anisotropic noise with the same anisotropy profile \(\) of the Gaussian, while the sigmoid term reduces the effect of noise on opaque Gaussians.

### Heuristics as state transitions via relocation

Inspired by jump and resampling moves in MCMC [26; 15], we now discuss how heuristics in 3D Gaussian Splatting can be rewritten as simple state transitions. In 3D Gaussian Splatting, heuristics are used to'move','split', 'clone', 'prune', and 'add' Gaussians to encourage more 'live' Gaussians (\(o_{i}{}0.005\)).2 We explain all of these modifications moving from one sample state \(^{old}\) to another sample state \(^{new}\). This applies also to cases where the number of Gaussians changes, as one could

Figure 1: **Illustration of different respawn strategies – We show a 1D example of rasterizing a Gaussian with opacity 0.95, before and after cloning them into four identical Gaussians and rasterizing them together, with different strategies. Existing methods cannot be used for MCMC as they broaden the extent of the selected Gaussian, significantly violating distribution invariance.**think of the state with a smaller number of Gaussians simply as the equivalent state with more Gaussians, but with those that have zero opacity, that is, dead Gaussians. Importantly, for these kinds of deterministic moves to be integrated into MCMC frameworks, it is important that they do not cause MCMC sampling to collapse. Specifically, we aim to preserve the probability of the sample state before and after the move that is, \((^{new})=(^{old})\) such that the move can be seen as simply hopping to another sample with equal probability. We now detail how we achieve this.

There can be various ways, but we opt for a simple strategy where we move 'dead' Gaussians (\(o_{i}<0.005\)) to the location of 'live' Gaussians. In doing so, we set the parameters of the Gaussians to minimize the difference between the impact on renderings that \(^{new}\) and \(^{old}\) provide. We provide the exact derivation in Appendix A and here we provide the update equation. Without loss of generality, consider moving \(N-1\) Gaussians, \(_{1,...,N-1}\), to \(_{N}\). Then, denoting the old Gaussian parameters with superscript \(old\) and the new ones with \(new\), we write

\[&^{new}_{1,...,N}=^{ old}_{N}, o^{new}_{1,...,N}=1-[N]{1-o^{old}_{N}},\\ &^{new}_{1,...,N}=(o^{old}_{N})^{2 }(_{i=1}^{N}_{k=0}^{i-1}((o^{ new}_{N})^{k+1}}{}))^{-2}^{old}_{N}. \] (9)

While, at first glance, the strategy we opt for may seem similar to 'cloning' in 3D Gaussian Splatting , the difference (9) brings is critical. In Figure 1, we illustrate this for a simplified 1D case, when \(o^{old}_{N}{=}0.95\). As shown, classical cloning and the recently proposed 'centre corrected' version  both lead to a significant difference in the rasterized Gaussian as cloning is performed. This is because in (1), the composed opacity is a product of multiple Gaussian shapes and its negation. Both existing strategies lead to the extent of the selected Gaussian growing as shown in Fig. 1, thus significantly differ in terms of likeness of these states, that is \((^{new})(^{old})\). This, in fact, leads to sub-optimal training.

**Implementation.** While our method results in \((^{new})(^{old})\), it is not exact. Hence we apply this move every 100 iterations to avoid disruptions in the training process. To choose where to move, for each dead Gaussian, we first chose a target Gaussian to move/teleport to via multinomial sampling of the live Gaussians with the probabilities proportional to their opacity values. Please note that only _after_ all movement decisions have been made we apply (9). Finally, as we rely on the Adam optimizer, moment statistics should also be adjusted. We reset the moment statistics for the target Gaussian (the original one that is cloned) so that it is biased to stay stationary, while for the new ones (source) we retain the moment statistics to encourage exploration. This is because 'dead' (source) Gaussians are dominated by the noise term in (7), and the moment statistics are hence appropriate to foster exploration.

### Encouraging fewer Gaussians

To make effective use of the memory and compute while improving the performance, we encourage Gaussians to disappear in non-useful locations and'respawn' elsewhere. As the existence of a Gaussian is effectively determined by its opacity \(o\) and covariance \(\), we apply regularization to both of these. Our full training loss is:

\[_{}=(1-_{})_{1}+ _{}_{}+_{o}_{ i}|o_{i}|_{1}+_{}_{ij}|_{j}(_{i})}|_{1},\] (10)

where \(_{j}(.)\) denotes the \(j\)-th eigenvalues of the covariance matrix (the variance along the principle axes of the covariance matrix), and \(_{o}\) and \(_{}\) are hyperparameters.

### More implementation details

We implement our method on top of the 3DGS  framework using PyTorch .

**Gradual increase in the number of Gaussians.** As in other works [19; 4], we allow the number of Gaussians to gradually grow, so that Gaussians are placed at useful locations. We do this simply by initially starting with a selected number of Gaussians, then allowing more 'dead' Gaussians to become 'alive' through our relocation strategy we previously detailed in Section 3.4. Specifically,we gradually increase the number of live Gaussians by 5% until the maximum desired number of Gaussians is met.

**Initialization and training.** We initialize our samples either randomly or from point clouds, typically from Structure-from-Motion (SfM) as in 3DGS . For random initialization, we follow 3DGS  and uniformly random sample \(100k\) Gaussians within three times the extent of the camera bounding box. We also use the same learning rate and learning-rate schedulers to enable comparisons. For the location of Gaussians, we start at a learning rate of \(1.6e^{-4}\) and decay it exponentially to \(1.6e^{-6}\). For all experiments, unless specified otherwise, we use \(_{}{=}5 10^{5}\), \(_{}{=}0.01\), and \(_{o}{=}0.01\). For Deep Blending , we use \(_{o}{=}0.001\). Following 3DGS , we start with 500 warmup iterations, during which we do not perform our relocalization in Sec. 3.4 nor increase the number of Gaussians.

## 4 Experiments

We use various datasets, both synthetic and real. Specifically, as in 3DGS , we use all scenes from NeRF Synthetic  dataset, the same two scenes used in  of Tank & Temples , and Deep Blending  and all publicly available scenes from MipNeRF 360 . We do not use 'Flower' and 'Treehill' scenes from MipNeRF 360  as they are not publicly available. We further use all scenes from the OMMO  dataset as in , for the large scenes with distant objects it provides. For MipNeRF 360 , to make our results compatible with , we downsample the indoor scenes by a factor of two, and the outdoor scenes four. For OMMO  scene \(\#01\), we downsample the images four times to keep the image size reasonable (\(1000 750\)). For all other scenes, we use the original image resolutions. In the main paper, we report our results by summarizing the average statistics for each dataset. Results for individual scenes, including the standard deviation of multiple runs, can be found in Appendix B. License information for each dataset can be found in Appendix E.

**Metrics.** We evaluate each method using three standard metrics: Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index Metric (SSIM) , and Learned Perceptual Image Patch Similarity (LPIPS) . To account for randomness, we run all experiments three times and average the results.

**Baselines.** We compare against conventional 3DGS , with both random and SfM point cloud-based initialization strategies. We use their official code for our experiments. We also report the original numbers in 3DGS , but where we correct their LPIPS scores, as reported by . We also include state-of-the-art baselines for each dataset.

### Results

**Performance with the same number of Gaussians.** As the number of Gaussians is directly related to the quality of novel-view rendering, we first compare our method with existing baselines using the _same_ number of Gaussians as 3DGS . In more details, we simply set the number of Gaussians used in the original 3DGS  and set it as our maximum number of Gaussians to be used during training and inference. We show the quantitative results in Table 1, and qualitative highlights

    &  &  &  & Deep Blending  & OMMO  \\  &  &  &  &  \\  NeRF  & 31.01 / - & - / - & - & 24.85 / 0.66 / 0.43 & - & 21.18 / 0.78 / 0.34 & - \\ Plenovsk  & 37.76 / - & / - & - & 23.63 / 0.67 / 0.44 & 21.08 / 0.72 / 0.38 & - & - \\ INGP-Big  & 33.18 / - & - & - & 26.75 / 0.75 / 0.30 & 21.92 / 0.75 / 0.31 & - & - \\ MipNeRF  & 33.09 / - & - & - & 27.60 / 0.81 / 0.25 & & 21.54 / 0.78 / 0.37 & - \\ MipNeRF360  & - & - & - & 29.23 / 0.84 / 0.21 & 22.22 / 0.76 / 0.26 & - & - \\
3DGS \(\) & 33.32 / - & - & - & 28.69 / 0.87 / 0.22 & 23.14 / 0.84 / 0.21 & - & - \\ 
3DGS  (Random) & \(33.42\) / **0.97** / **0.04** & 27.89 / 0.84 / 0.26 & 21.93 / 0.79 / 0.27 & 29.55 / **0.90** / 0.33 & 28.24 / 0.88 / 0.24 \\ Ours & (Random) & \(33.80\) / **0.97** / **0.04** & 29.72 / 0.89 / 0.19 & 24.27 / 0.86 / 0.19 & 29.71 / **0.90** / **0.32** & 29.31 / 0.90 / **0.20** \\ 
3DGS  & (SfM) & - & 29.30 / 0.88 / 0.21 & 23.67 / 0.84 / 0.22 & 29.64 / **0.90** / **0.32** & 28.83 / 0.89 / 0.22 \\ Ours & (SfM) & - & 29.89 / **0.90** / **0.19** & 24.29 / **0.86** / **0.19** & 29.67 / 0.89 / **0.32** & 29.52 / **0.91** / **0.20** \\   

Table 1: **Quantitative results with same number of Gaussians – Our method outperforms all baselines even when starting from random initialization, with a large gap in performance when compared with 3DGS  – Random. We highlight the best and second-best for each column.**in Figure 2. As shown, our method provides better performance than 3DGS . Interestingly, our method, whether initialized randomly or with SfM point clouds, only displays minor variations in performance, thanks to the exploration that our MCMC formulation provides. This allows our method to outperform 3DGS , and _regardless_ of the initialization strategy.

**Limited budget.** We further verify the effectiveness of our formulation by limiting the budget for the number of Gaussians on all the datasets (we omit NeRF Synthetic , as performance on the synthetic dataset is highly saturated, as also highlighted by 3DGS  in their initialization experiments). To limit the number of Gaussians for the conventional 3DGS , we simply stop their densification strategy from spawning more points if the limit on the number of Gaussians has been reached. Note that the pruning strategy can cause densification to resume, should some Gaussians get pruned after this threshold is met. Note also that our experiments for this setup is using 3DGS  with its default parameters, and do not perform further hyper-tuning. We use the _exact same_ hyperparameters as in Sec. 3.6 for this experiment as well. We report the summary of the results in Fig. 3. With a limited budget, the gap between our method and 3DGS  increases.

**Sensitivity to initialization.** An important benefit of our method is that it allows exploration through the MCMC sampling scheme, removing the heavy reliance of 3DGS  on initialization. To verify this, we deviate from the default initialization strategy of 3DGS , which is to randomly place Gaussians within \(3\) the camera extent as defined by . Instead, we use \(1\) the camera extent.

Figure 3: **Varying the #Gaussians – We report the PSNR of 3DGS  and our method averaged over all datasets (except NeRF Synthetic).**

Figure 2: **Qualitative highlights with the same number of Gaussians – We provide examples of novel-view rendering of 3DGS  and our approach on multiple scenes from different datasets (with either random or SFM initialization). We highlight the differences in inset figures. Our method faithfully represents details of the various regions thanks to our hybrid MCMC re-formulation that allows exploration without heuristics. Our results provide higher quality reconstructions. Please zoom-in to see details.**

[MISSING_PAGE_FAIL:9]

our method and the original 3DGS. In this case, ours takes 80 milliseconds while 3DGS takes 76 milliseconds. That is, the added time for sampling and noise addition is not substantial, even with our implementation that implements resampling naively with PyTorch 's torch.multinomial--this could be further accelerated with a CUDA implementation.

Furthermore, the configuration of Gaussians (i.e. where they are, their sizes and opacity) matters greatly to the runtime because they affect the speed of rasterization (among them the opacity regularizer affects the speed the greatest). Hence, we evaluate the runtime for the 'Room' scene in MipNeRF 360 dataset, all with SfM initializations and maximum number of 1.5M Gaussians per the original 3DGS implementation. We report the timings in Tab. 4. As shown, our method, while it may take longer to achieve the highest PSNR, trains faster when a similar PSNR is desired. An independent implementation of our method  also confirms a _20% reduction in training time_ and a _65% reduction in required memory_ when using our method.

## 5 Conclusion

In this paper, we reformulated 3D Gaussian Splatting  training as Markov Chain Monte Carlo (MCMC) and implement it via Stochastic Gradient Langevin Dynamics (SGLD). By doing so, we show that we can eliminate the need for point-cloud initialization, and avoid heuristic-based densification, pruning and reset. Not only do we show that this strategy generalizes well across various scenes, outperforming the original 3D Gaussian Splatting , but for the _first time_ we show that this leads to a 3DGS implementation that beats NeRF backbones on the challenging MipNeRF3360  dataset.