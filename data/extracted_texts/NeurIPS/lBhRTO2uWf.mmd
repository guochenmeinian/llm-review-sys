# Adversarial Learning for

Feature Shift Detection and Correction

 Miriam Barrabes 1,2,* Daniel Mas Montserrat 1,* Margarita Geleta 3

**Xavier Giro-i-Nieto 4,\({}^{}\) Alexander G. Ioannidis 1\({}^{}\)**

\({}^{1}\)Stanford University \({}^{2}\)Universitat Politecnica de Catalunya

\({}^{3}\)University of California, Berkeley \({}^{4}\)Amazon

Equal contribution.Work done prior to joining Amazon.Correspondence to A.G.I. [ioannidis@stanford.edu].

###### Abstract

Data shift is a phenomenon present in many real-world applications, and while there are multiple methods attempting to detect shifts, the task of localizing and correcting the features originating such shifts has not been studied in depth. Feature shifts can occur in many datasets, including in multi-sensor data, where some sensors are malfunctioning, or in tabular and structured data, including biomedical, financial, and survey data, where faulty standardization and data processing pipelines can lead to erroneous features. In this work, we explore using the principles of adversarial learning, where the information from several discriminators trained to distinguish between two distributions is used to both detect the corrupted features and fix them in order to remove the distribution shift between datasets. We show that mainstream supervised classifiers, such as random forest or gradient boosting trees, combined with simple iterative heuristics, can localize and correct feature shifts, outperforming current statistical and neural network-based techniques. The code is available at https://github.com/AI-sandbox/DataFix.

## 1 Introduction

Distribution shifts in multi-dimensional data, caused by one or more "corrupted" dimensions, are common in various real-world applications. Data streams from multi-sensor environments in fields like medicine, industry, finance, and defense, can experience shifts due to faulty sensors . Tabular and structured data used in domains such as economics, biology, genomics, and social sciences, can encounter distribution shifts caused by improper standardization, erroneous data processing, data collection procedures, or human entry errors . Combining databases from diverse sources is common in many fields: various hospitals collect different phenotypic characteristics from patients, and governmental institutions often capture different socio-economic indicators of citizens. However, proper standardization of data is seldom applied across data sources, and merging these poses challenges that often require data-dependent and domain-specific techniques . For example, efficient computational techniques are used to process high-dimensional genomic sequences , and domain knowledge is incorporated in processing data from social sciences . This process typically involves changing, imputing, merging, and removing both features and samples, potentially leading to complex pipelines that can originate distribution shifts between datasets. These shifts can create erroneous scientific results if present in datasets used for medical or social studies, or indicate infrastructure failure if present in sensory data in industrial applications. Therefore, detecting, localizing, and correcting such shifts is an important task that remains a relatively unsolved problem.

The "localization" of feature shifts is the task of finding which features (i.e., dimensions) of the dataset are causing the shift within multiple sets of data. This step can be critical in order to address the errorsource, by physical intervention in the multi-sensory scenario, or by data removal or fixing in tabular data-based applications. There has been extensive work on distribution shift detection and anomaly detection [7; 8], however, such methods focus mainly on detecting if two sets of data follow the same distribution, or on detecting outliers, and the task of identifying the exact components generating the shift remains partially unexplored. Recently, work combining machine learning techniques with statistical testing provided state-of-the-art results showing that localizing corrupted features can be done accurately . In this work, we explore "feature selection" methods as a mechanism to detect potential feature shifts. The "correction" of feature shifts consists of replacing corrupted feature values with new ones, ensuring that the updated dataset follows a distribution that is equal to, or more similar to, the distribution without corruptions. This can be useful in data homogenization and quality control pipelines, enabling the elimination of shifts between multiple data sources and their combination for downstream applications, including data discovery or machine learning training. Feature shift correction can be framed as a supervised problem, employing regression or classification methods to predict the new feature values; as a missing data imputation problem, by treating corrupted features as missing values [10; 11]; or as a distribution alignment problem [12; 13], where mappings between distributions are learned using adversarial learning, optimal transport, or statistical divergences. Effective techniques for correcting distribution shifts, either by learning parametric models to predict new values for corrupted features, or directly updating values without explicit model learning, can be very useful to avoid incorrect or biased results in analysis based on data containing feature shifts. We provide a more formal definition of the feature shift detection and correction tasks in the following sections.

Tools for automated shift detection, data monitoring, and feature analysis and correction are becoming more common in data quality control, data homogenization, data processing pipelines, data-centric AI, MLOps, and deployment monitoring for ML Systems [14; 15; 16; 17]. In this work, we introduce "DataFix", a framework that makes use of discriminators trained to distinguish samples coming from two different distributions, in order to estimate distribution shifts, localize which features are causing them, and modify the samples in order to reduce or remove the shift. DataFix is composed of two systems: "DF-Locate", which locates the features causing the distribution shift, and "DF-Correct", which directly modifies the samples in order to decrease the distribution shift between two datasets. DF-Locate consists of an iterative process where a discriminator combined with a feature importance estimator is used to identify the most discriminative features between samples coming from two different distributions. The detected features are removed from the dataset, a new discriminator is trained, new feature importances are estimated, and the process is repeated until no distribution shift is detected. DF-Correct replaces the values of the corrupted features detected by DF-Locate with values that exhibit a minimal probability of being corrupted when processed by a discriminator.

Our contributions are as follows: (1) we motivate, define, and formalize the problem of feature shift detection and correction and relate it to feature selection and adversarial learning frameworks; (2) we propose an iterative algorithm that makes use of feature selection techniques from discriminators to accurately detect manipulated features; (3) we propose an iterative algorithm that makes use of a discriminator to guide the correction of a corrupted dataset in order to decrease its distribution shift; (4) we provide an in-depth experimental evaluation with multiple manipulation types and datasets.

## 2 Related Work

**Distribution Shift Detection and Localization.** Distribution shift detection involves identifying if \(p q\), where \(p\) and \(q\) are the reference and query distributions respectively. While there is extensive research on detecting distribution shifts in univariate distributions [18; 19; 7], exploration in the multivariate setting is relatively limited . Multivariate distributions can exhibit various types of shifts, including covariate, label, concept, or marginal shifts, among others [21; 22; 23]. The work in  applies hypothesis testing for concept drift detection. In , two-sample hypothesis testing is explored for shift detection, and a comparison is made between multivariate hypothesis tests via Maximum-Mean Discrepancy (MMD) , univariate hypothesis tests with marginal Kolmogorov-Smirnov (KS) tests and the Bonferroni correction , and dimensionality reduction techniques, among others. However, these works focus on detecting if a distribution shift is present but do not localize which features are causing it. Recently, a conditional test method was able to identify the features originating the shift  with model-free and model-based approaches: K-Nearest Neighbors with KS statistic (KNN-KS), multivariate Gaussian with KS (MB-KS), multivariate Gaussian and Fisher-divergence test statistics (MB-SM), and deep density neural network models with Fisher-divergence test (Deep-SM). However, performing feature shift localization remains challenging.

**Feature Selection.** Feature selection methods can remove redundant features affecting efficiency or performance, and find the most relevant features, providing interpretability. Common techniques include: filtering [26; 27], wrapper [28; 29] and embedded methods [30; 31]. Filtering methods, including univariate Mutual Information statistics (MI) , ANOVA-F test , and Chi-square test , rank features based on data statistics. Minimum Redundancy Maximum Relevance (MRMR) [35; 36] selects relevant features while minimizing redundancy with the selected ones. Fast-Conditional Mutual Information Maximization (FAST-CMIM)  selects features that maximize MI, conditional to previously selected features. Wrapper methods select feature subsets by training models on them and adding and removing features through a search process that can be computationally intensive. Embedded methods use the inherent scores computed by predictive models, such as logistic regression weights  or the mean decrease of impurity (Gini index) in random forests . Most methods select the features with the highest importance scores or all that exceed a given threshold .

**Missing Data Imputation.** Missing data imputation methods can remove distribution shifts by considering the shifted features as missing and re-constructing them. Imputation methods range from simple record deletion, zero imputation, mean imputation, and deck imputation , to machine learning-based methods that apply regression and classification to reconstruct missing data including MICE , MissForest , and Matrix Completion [42; 43]. Some generative approaches include Expectation Maximization algorithms  and deep learning-based methods such as the MIWAE autoencoder . Causality-based techniques such as MIRACLE have proven to be highly accurate . HyperImpute  provides state-of-the-art imputation by using an iterative process with ML methods, including gradient boosting machines and neural networks trained to impute missing data.

**Optimal Transport, Distribution Alignment, and Adversarial Learning.** Feature shift correction can also be performed with distribution alignment methods, optimal transport, and adversarial learning. Distribution alignment and representation learning methods learn a mapping between distributions and can be used to remove shifts by projecting the shifted samples into the non-shifted distribution. Iterative Alignment Flows  and Deep Density Destructors  are neural network examples that map samples between distributions. Optimal transport-based methods reduce the Wasserstein distance between distributions. The work in  applies a Sinkhorn-based optimization process to perform imputation. Adversarial learning has been explored in generative adversarial networks such as GAIN , where the loss of a discriminator is used to improve imputation accuracies.

**Data-centric AI.** Data-centric AI focuses on systematically enriching data quality and quantity as a means to boost AI and ML performance. It covers strategies that impact every phase of the data lifecycle, from data collection , labeling [51; 52], augmentation [53; 54; 55], and integration , to the crucial processes of data cleaning [57; 58], feature extraction , and transformation . These include programmatic automation strategies, which rely on programs guided by heuristics and statistics for automatic data processing [61; 62; 63], as well as learning-based automation techniques that optimize data automation procedures, typically using machine learning [64; 65; 66]. The detection and removal of distribution shifts are becoming essential steps of the data-centric AI toolbox .

## 3 Proposed Framework

**Definition 1**.: **[Feature Shift]** _We are given two sets of \(d\)-dimensional samples \(X=\{x_{1},x_{2},...,x_{N}\}\) and \(Y=\{y_{1},y_{2},...,y_{N}\}\), with \(x_{i},y_{i}^{d}\), from distributions \(p\) and \(q\), respectively. A feature shift between \(p\) and \(q\) occurs when \(D(p,q)>\) and \(D(p_{S},q_{S})\), where \(D\) is a valid divergence or distance between distributions, \(S\) and \(C\) are the subsets of non-corrupted and corrupted features respectively, such that \(|S C|=d\), and \(p_{S}\) and \(q_{S}\) are the distributions restricted to \(S\)._

We will refer to \(X\) and \(Y\) as the "reference" and "query" datasets, and to \(p\) and \(q\) as the "reference" and "query" distributions, respectively. We will assume that the reference contains only "non-corrupted" features, while the query contains one or more "corrupted" dimensions that we will want to detect and correct. Here we consider scenarios with \(=0\), \(D(p_{S},q_{S})=0\), \(D(p,q) 0\), and \(|S|>|C| 1\). That is, there are more non-corrupted than corrupted features, the divergence becomes 0 if the corrupted features are removed, and is large enough to be empirically detected otherwise. We will consider multiple types of distribution shifts: marginal shifts with \(D(p_{i},q_{i})>\), where \(p_{i}\) and \(q_{i}\) represent the marginal distribution of the \(i\)th dimension resulting from additive and non-lineartransformations; correlation shifts where \(D(p,q)>\) but \(D(p_{i},q_{i})\) for all \(i\); and correlation shifts where \(D(p_{S},q_{S})\) and \(D(p_{C},q_{C})\) but \(D(p,q)>\). In the latter case, correlations are maintained locally, but a shift is present when considering all features simultaneously.

**Definition 2**.: **[Feature Shift Localization Task]** _The task of localizing a feature shift consists of finding the smallest subset of features \(C\), with \(=S\), that satisfies \(D(p_{},q_{})\), that is \(C=*{argmin}_{D(p_{},q_{})} |C|\)._

The number of corrupted features \(|C|\) will be assumed to be unknown a priori. Furthermore, because the distributions \(p\) and \(q\) are assumed to be unknown and only their samples are accessible, the task needs to be approximated, requiring careful consideration of trade-offs such as falsely flagging non-corrupted features (false positives) and failing to detect corrupted ones (false negatives).

**Definition 3**.: **[Feature Shift Correction Task]** _The task of correcting a feature shift consists of finding a new matrix \(Y^{}=\{y^{}_{1},y^{}_{2},...,y^{}_{N}\}\) such that \(y^{}_{i} q^{}\) and \(D(p,q^{})\), while keeping the non-corrupted features unchanged, that is \(Y^{}_{S}=Y_{S}\)._

The correction of shifted features can be done through parametric models that perform sample-wise transformations \(y^{}=(y)\), prediction or imputation methods \(y^{}_{C}=(y_{})\), or optimization procedures or heuristics \(Y^{}=(X,Y)\). Our proposed approach falls in the latter category.

## 4 Feature Shift Detection: DF-Locate

DF-Locate (Fig. 1, Algorithm 1) employs an iterative process to detect the presence of a shift and determine the features causing it. At each iteration, a classifier is trained to detect the origin (binary label indicating reference vs query) of each sample, the output predictions are used to estimate the divergence between distributions, and the feature importance scores provided by the binary classifier are used to locate the features originating the shift. At the end of each iteration, the features detected as corrupted are removed, and the process is repeated until no divergence is detected.

**Shift Detection.** We detect whether a shift is present by estimating an \(f\)-divergence between the distributions \(p\) and \(q\) by using an empirical approximation of the variational form [67; 68; 69]:

\[_{}(X,Y)=}_{i=1}^{N_{x}}f^{}(r_{}( x_{i}))-}_{j=1}^{N_{y}}f^{*}(f^{}(r_{}(y_{j})))\] (1)

where \(X=\{x_{1},...,x_{N}\}\) and \(Y=\{y_{1},...,y_{N}\}\), with \(x_{i} p\), \(y_{j} q\), and \(r_{}(x)\) is a function approximating the likelihood ratio between \(p\) and \(q\), obtained by training a binary classifier \(_{}(x)\) such that \(r_{}(x)=_{}(x)}}{{1-_{}(x)}}\). We use \(5\)-fold train-evaluation such that 80% of the samples are used to train a random forest binary classifier \(_{}(x)\), and the 20% left is used to estimate the empirical divergence with \(N_{x}\) and \(N_{y}\) testing samples of the reference and query datasets, respectively. The resulting estimates are averaged across folds to reduce variance. The function \(f\) is the generator function of the \(f\)-divergence, \(f^{}\) is its first order derivative, and \(f^{*}\) is its Fenchel conjugate . By changing \(f\), various divergences can be obtained such as the Kullback-Leibler divergence, the Jensen-Shannon divergence used in GANs, or the total variation distance, among others.

Figure 1: DF-Locate overview diagram.

The true \(f\)-divergence is recovered in expectation \(D_{f}(p,q)=_{x p,y q}[_{}(X,Y)]\) when \(r_{}(x)=r^{*}(x)=}{{q(x)}}\) is the true likelihood ratio function, defining the Bayes decision rule that optimally separates \(p\) and \(q\). In this work, we make use of the total variation distance \(0 D_{TV}(p,q) 1\), defined by setting \(f^{}(u)=(f^{*} f^{})(u)=(u-1)\). The discrete nature of \(f^{}(u)\) makes the empirical estimator robust to poorly calibrated classifiers. Furthermore, its value is proportional to the empirical balanced accuracy on the evaluation test. Intuitively, if \(_{TV}(X,Y)>0\), or equivalently, the test balanced accuracy is larger than \(0.5\) (random chance), it might indicate that \(p q\). After detecting the presence of a shift, the next step is to localize the features originating it.

**Feature Selection for Shift Localization.** Our proposed method employs feature importance and feature selection techniques in order to detect the features originating a distribution shift. These techniques often involve approximating the following estimation problem, either implicitly or explicitly:

\[C=*{argmax}_{|C| k}I(z_{C};t)\] (2)

where \(C\) is the feature subset of size up to \(k\), which maximizes the mutual information \(I\) between the input sample \(z\), restricted to the features in \(C\), and the label \(t\). By defining \(z\) as the samples coming from \(X\) and \(Y\), and \(t\) as the binary label of origin, such that \(z|_{t=0} p\) and \(z|_{t=1} q\), Fano's inequality  and LeCam's method  can be used to relate the mutual information between \(z\) and \(t\) and the total variation distance between \(p\) and \(q\):

\[1-H_{2}((p,q)+1}{2}) I(z;t) D_{TV}(p,q)\] (3)

where \(H_{2}\) is the entropy with base-2 logarithm. If the number of manipulated features is known \(|C|=k\), and \(D_{TV}(p,q)=D_{TV}(p_{C},q_{C})=1\), then \(C=*{argmax}_{|C| k}I(z_{C};t)=*{argmin}_{D_{TV}(p _{C},q_{C})=0}|C|\), thereby rendering the problem of feature selection and feature shift detection equivalent. See Section C for further discussion. In practice, the distributions are unknown making Eq. 2 intractable and most methods predict a score that approximates the amount of information relative to the label present at each feature: \(=F(Z,T)\), where \(^{d}\) and \(F()\) is a function mapping samples \(Z\) and labels \(T\) to a feature-wise importance score. Here, we use the mean decrease of impurity from the random forest classifier \(_{}\) as the feature importance scores.

**Feature removal policy.** We introduce the feature removal policy function \(\) as an heuristic to approximate Eq. 2, which utilizes the predicted feature importances \(\) and the estimated total variation distance \(=_{TV}(X,Y)\) to select likely corrupted features \(C=(,)\). First, \(\) is normalized \(^{}=^{d-1}|_{i}|}\) and sorted \(^{}_{}\), such that \(^{}_{(0)}^{}_{(1)}...^{}_{ (d-1)}\). Given the cumulative sum \((k)=_{j=0}^{d}^{}_{(j)}\), the sorted features from 0 to \(J\) are selected as corrupted, where \(J\) is the smallest index such that \((k)\) (Eq. 4), and \(\) is a hyperparameter set by hyperparameter optimization. Finally, \(\) returns the features from 0 to \(J\) with scores higher than \(\) (Eq. 5):

\[J(,,)=*{argmin}_{k:(k)} (k) 28.452756pt(4) 28.452756ptC=\{^{-1}(j):0 j J, ^{}_{(j)}>\}\] (5)

Note that \(\) acts as a threshold to select how many features are selected as corrupted. If the threshold is small, \(\) simply returns the feature with the highest feature importance, while a larger threshold will make \(\) return more features. By defining the threshold as the product of \(\) and \(\), we ensure that when the shift is small (low \(\)), a smaller number of features are flagged as corrupted.

**Iterative Process.** DF-Locate performs an iterative process that starts with the reference \(X^{(0)}=X\) and query \(Y^{(0)}=Y\) datasets. At each iteration \(i\), it trains a set of discriminators \(^{(i)}=*{argmax}_{}_{TV}(X^{(i)},Y^{(i)})\) consisting of random forest binary classifiers. The classifier predictions are used to estimate \(^{(i)}=_{TV}(X^{(i)},Y^{(i)})\) and, combined with the Gini importance from the random forests \(^{(i)}=F(X^{(i)},Y^{(i)})\), a set of corrupted features are localized using the feature removal policy \(C_{i}=(^{(i)},^{(i)})\). The selected features \(C_{i}\) are removed from the dataset, such that \(X^{(i+1)}=X^{(i)}_{}}\) and \(Y^{(i+1)}=Y^{(i)}_{}}\), and the process is repeated while \(_{TV}(X^{(i)},Y^{(i)})>0.02\) or until half of the features have been removed or no features are removed at the current iteration. After \(l\) iterations, the set of corrupted features is obtained as \(C^{}=_{i=1}^{l}C_{i}\). Finally, a refinement stage (see below and Section E.3) predicts the final set \(C\). More details are provided in Section E.

**Refinement stage.** DF-Locate stores all intermediate steps, including the indexes of the predicted corrupted feature locations and the estimated \(\) at each iteration, in order to revisit the iterative filtering process and select the optimal stopping point. To determine the optimal iteration, the elbow or knee is found from a processed curve depicting the empirical total variation distance as a function of the total number of removed features (see Section E.3). This refinement stage effectively eliminates false positives and enhances the accuracy of feature shift localization.

```
1:Inputs:\(X\); \(\) Reference \(Y\); \(\) Query \(\); \(\) Feature Selection Threshold \(e\); \(\) Divergence Threshold
2:\(X^{(0)}=X\)
3:\(Y^{(0)}=Y\)
4:\(i=0\)
5:\(k^{(0)}=0\)
6:while\(D_{}(X^{(i)},Y^{(i)})>\) and \(k^{(i)}<\) and \(k^{(i)}-k^{(i-1)}>0\)do
7:\(X^{(i)},Y^{(i)})\)\(\) Train discriminator
8:\(D_{}(X^{(i)},Y^{(i)})\)\(\) Estimate divergence
9:\(_{}(X^{(i)},Y^{(i)})\)\(\) Estimate feature importance
10:\(C_{i}_{}(,)\)\(\) Select corrupted features
11:\(X^{(i+1)},Y^{(i+1)}}{C_{i}},Y^{(i)}_{C_{i}}\)\(\) Remove detected features
12:\(k^{(i+1)} k^{(i)}+|C_{i}|\)\(\) Update detected feature counter
13:\(i i+1\)
14:endwhile
15:\(C^{}=_{j=0}^{(-1}C_{j}\)\(\) Combine all detected features
16:\(C(C^{})\)\(\) Refine detected features
17:return\(C\) ```

**Algorithm 1** DF-Locate

## 5 Feature Shift Correction: DF-Correct

After the set \(C\) of features originating the shift has been detected by DF-Locate, DF-Correct (Figure 2, Algorithm 2) is applied to generate a new query dataset \(Y^{}\) that rectifies the distribution shift. Ideally, the objective is to find \(Y^{} q^{}\) such that:

\[Y^{}=*{argmin}_{Y q^{}:||Y^{}_{C^{}} ||=0}D(p,q^{})\] (6)

where \(D\) is a valid statistical divergence. Because \(p\) and \(q^{}\) are unknown, we approximate the optimization problem by using a discriminator \(_{}\) to predict the empirical estimate of an \(f\)-divergence:

\[Y^{}=*{argmin}_{Y}_{}_{}(X,Y)\] (7)

This approach parallels the adversarial minimax optimization setting adopted in GANs, where samples are generated by a generator \(Y^{}=_{}(u)\), and a discriminator tries to accurately classify the generated samples as "fake". This training leads to the minimization of the Jenson-Shannon divergence, and the setting for GAN training can be generalized to any \(f\)-divergence . Here, instead of training a generator, we directly update the corrupted values of the query dataset by trying to minimize the predicted likelihood of the updated samples coming from \(q\), approximated with the discriminator \(_{}\). While neural network-based discriminators allow for direct optimization of the values of \(Y\) through backpropagation, these can have suboptimal performance when classifying tabular and similar structured data, which is the focus of our work. Hence, we employ tree-basedtechniques instead. Despite not being differentiable, derivative-free optimization and search heuristics can be used to update \(Y\).

Two important aspects need to be taken into consideration: (a) the allowed search space for the values of \(Y\), and (b) the frequency of training or updating the discriminator. In GANs, the space of possible values for generated samples is restricted by the complexity of the generator network, and, typically, the discriminator is updated in sync with each generator update. In our setting, if we allowed the search space to be the whole Euclidean space without updating or retraining the discriminator, we would be effectively conducting an adversarial attack , where the empirical divergence would decrease while the true divergence would not. However, frequent retraining of the discriminator is computationally infeasible for tree-based techniques due to their lack of online training capabilities, necessitating retraining from scratch. Therefore, our discriminator is retrained only once at each iteration within our iterative process. Furthermore, we limit the search space for the possible values of the features in \(Y^{}\) to a set of proposal values \(B\), generated from the reference dataset \(X\).

**Initial Imputation.** DF-Correct starts by setting the features C of the query dataset, previously detected as corrupted by DF-Locate, as missing. Initial missing data imputation is then performed with three distinct techniques: KNN, linear regression, and random sampling from the reference dataset \(X_{C}\). This yields three imputed query datasets. A set of discriminators consisting of binary CatBoost  classifiers are trained for each reference and imputed query pair, and the empirical total variation distance is estimated following the same procedure as in DF-Locate. The imputed query dataset providing the lowest empirical divergence is selected as a starting point for the iterative process of DF-Correct. If the initial empirical divergence is already lower than \(=0.1\), the correction process is finalized. If not, DF-Correct applies the iterative process described below.

**Iterative Process.** The reference, the imputed query, and augmented samples (see Section F) are used to train \(k=2\) CatBoost binary classifiers to discriminate between reference and query datasets. \(k\)-fold splitting of the datasets is used to ensure that each classifier does not see the same sample during training and inference. The set of samples to be corrected \(L\) is obtained by selecting \(|Y|/_{2}\) samples from \(Y\) with the highest probability of being corrupted (or equivalently, the lowest probability of being from the reference distribution). Then, we generate a set of new feature value proposals \(B=\{b_{1},...,b_{N}\}\), with \(b_{j}^{|C|}\). This set comprises all the feature values within positions \(C\) from the reference dataset \(X\) and the imputed query with linear regression, alongside random permutations of the reference values. In other words, each \(b B\) contains \(|C|\) values obtained from \(X\) (and imputed \(Y\)) that can be a potential replacement for the corrupted features of each query sample \(y L\). Note that the size of \(B\) is proportional to the size of \(X\). Then, for every query sample \(y L\) classified as "corrupted" by the discriminator, we replace the shifted features by all candidate values in \(B\), and select the \(b_{i}\) that provides the highest empirical likelihood of being a non-corrupted sample:

\[b_{i}=*{argmax}_{b B}r_{_{i}}(y_{i}^{(b)})\] (8)

where \(y_{i}^{(b)}\) is the query sample \(y_{i}\) with the corrupted features \(C\) replaced with the values of \(b\) such that \(y_{i_{C}}=b\), and \(r_{_{i}}\) is the likelihood ratio function from the classifier used to process the \(i\)th sample. In other words, we evaluate each sample \(y L\) a total of \(|B|\) times with the discriminator and select the \(b\) providing the highest probability that \(y^{(b)}\) is from the reference distribution. Then, we update the current corrected query dataset \(Y^{(k)}\) by replacing the corrupted sample \(y_{i}\) with \(y_{i}^{(b_{i})}\), such that \(Y^{(k+1)}=(Y^{(k)} y_{i}) y_{i}^{(b)}\). By replacing corrupted features with values from the Eq. 8, the empirical divergence is decreased such that \(_{}(X,Y^{(k+1)})_{}(X,Y^{(k)})\). After updating all the

Figure 2: DF-Correct overview diagram.

"corrupted" features within the query dataset, the classifiers are retrained and the process is repeated until no divergence is detected or until the empirical divergence stops decreasing. The iterative process of replacing corrupted features, which reduces the empirical divergence, and retraining discriminators, which allows the estimation of more accurate likelihoods and divergences, approximates the minimax optimization process in Eq. 7. More details are in Section F.

## 6 Experimental Results

**Real world datasets.** We use multiple datasets including UCI datasets such as Gas , Energy , and Musk2 , OpenML datasets including Scene , MNIST , and Dilbert , datasets with DNA sequences such as Founders  and a private Dog DNA dataset (Canine), a subset of phenotypes from the UK Biobank (Phenotypes) , Covid-19 data , and simple datasets including values generated from Cosine and Polynomial functions. The datasets range from 8 to 198,473 features, and from 1,444 to 70,000 samples, including continuous and categorical datasets. We normalize each feature to have values from 0 to 1. We randomly divide each dataset into two equally sized subsets, corresponding to the reference \(X\) and query \(Y\) samples. Multiple manipulations are applied to randomly selected features of the query dataset. A detailed description of the datasets and the pre-processing applied is available in Section B.1.

**Feature Shift Manipulations.** We apply 10 different manipulations to the real world datasets in order to generate various distribution shifts. Table 1 describes each manipulation. Manipulations 1, 2, 4, 5, 6, and 7 distort the marginal distributions, with manipulation 4 leaving the mean approximately unchanged. Manipulations 4 and 6 have different levels of strength, controlled by parameters \(\) and \(\), respectively. Manipulations 3 and 6 shuffle the feature values across samples, leaving the marginal distributions unchanged (\(p_{i}=q_{i}\)) but changing their correlations. Manipulation 3 performs a different random permutation at each feature, removing all correlation between features, while manipulation 6 performs the same permutation for all features, such that \(p_{C}=q_{C}\), but \(p q\). Manipulations 9 and 10, applied to continuous and categorical variables respectively, replace the features with values predicted by k-nearest neighbor (KNN) trying to reconstruct the corrupted features. The nature of the shifts originated by KNN will depend on the given dataset and distribution. We discuss the nature of shifts originated by predictive and imputation models in Section D. Manipulations are applied to continuous features, categorical features, or both. In total, we apply 10 manipulations on continuous features and 8 manipulations on categorical features. Each manipulation is applied to 5%, 10%, and 25% of the features in the query. This produces a reference dataset with 24 and 30 query datasets for categorical and continuous data, respectively. Each query dataset corresponds to a distinct transformation applied to a specific fraction of the features.

**Probabilistic Simulations.** We generate 15 datasets with 1000 features and 5000 samples, simulated from probabilistic distributions including multivariate Gaussians, multivariate Bernoulli distributions, Gaussian mixture models, and Bernoulli mixture models. By having full access to the generating distributions, the real distribution shift and divergence between distributions can be measured. The manipulations include marginal shifts in the mean and/or variance between distributions and shifts in

  
**Type** & **Mapping** & **Description** & **Shift** & **Data** \\ 
1 & \(x(0,1)\) & Each value is substituted by a random number between 0 and 1. & \(p_{i} q_{i}\) & Cont. \\
2 & \(1-x\) & Each value is negated. & \(p_{i} q_{i}\), \([q_{i}]=1-[p_{i}]\) & Both \\
3 & \(P_{i}X_{i}\) & \(P_{i}\) is a random permutation matrix applied to feature \(i\). & \(q_{C}=_{i C}q_{i}\) & Both \\
4.1-4.3 & \(_{0,1}(x+)\) & Add constant noise with a random sign. & \( p_{i} q_{i}\), \([p_{i}][q_{i}]\) & Cont. \\  & \((0.5)\) & \(\{0.02,0.05,0.1\}\) for 4.1-4.3 respectively. & & \\
5 & round(\(x\)) & Values are binarized. & \(p_{i}+q_{i}\) & Cont. \\
6.1-6.3 & \(b(1-x)+(1-b)x\) & Values are negated with probability \( p_{i} q_{i}\), \([q_{i}]=+(1-2)[p_{i}]\) & Cat. \\
7 & \(b()\) & Forward through an MLP with min-max normalization of binarization. & \(p_{i} q_{i}\) & Both \\
8 & \(PX_{i}\) & \(P\) is a random permutation matrix applied to all features simultaneously. & \(p_{i}=q_{i},p_{C}=q_{C},p q\) & Both \\
9 & KNN(\(x\)) & Predict feature with KNN (Regressor). & - & Cont. \\
10 & KNN(\(x\)) & Predict feature with KNN (Classifier). & - & Cat. \\   

Table 1: Manipulation types applied to continuous and/or categorical features.

the feature correlations. Note that here we do not apply the shifts described in Table 1, but instead directly simulate datasets from distributions having a shift. See Section B.2 for more details.

**Experimental Details.** In both shift localization and correction, each method only has access to the reference dataset \(X\) and the corrupted query dataset \(Y\), while ground truth information, such as actual corrupted feature locations \(C^{*}\) or the original (pre-shifted) query dataset \(Y^{*}\), is not accessible. The localization task is evaluated by comparing the localized corrupted features \(C\) and the true locations \(C^{*}\) with the F-1 score, and the correction task is evaluated by comparing the corrected query dataset \(Y^{}\) and the reference dataset with non-parametric empirical divergence estimators. We use the simulated datasets to perform hyperparameter search for DataFix and all competing methods, while the real datasets are used as a hold-out testing set (see below and Section G for more details).

**Feature Shift Localization.** We evaluate our method and 8 competing techniques, including four feature shift localization methods (MB-SM, MB-KS, KNN-KS, and Deep-SM) and four feature selection methods (MI, selectKbest, MRMR, and Fast-CMIM) (Fig. 3). We evaluate MB-SM, MB-KS, KNN-KS, and Deep-SM with both their recommended configuration, without a priory specification of the number of corrupted features \(|C|\), and with the hyperparameter configuration that yielded optimal results and includes the ground truth \(|C|\) (with \({}^{*}\)). The rest of the methods do not have access to the ground truth \(|C|\). We measure the F-1 score of feature shift localization and average it across the percentage of manipulated features and manipulation types. Figure 3 (left) shows the median and mean F-1 scores across the real and simulated datasets, respectively. We make use of the median because some F-1 scores are missing as some techniques can not process the larger datasets such as "Founders" and "Canine" given the assigned time budget of 30h. DataFix outperforms all the competing techniques, in both real and simulated datasets, even when compared with MB-SM, MB-KS, KNN-KS, and Deep-SM that make use of the ground truth \(|C|\).

Figure 3 (right) shows the median (left) and mean (right) F-1 scores divided by type of manipulation and datasets. DataFix outperforms all competing methods in all types of manipulations, except for type 10, where selectKbest provides a higher F-1 score. Techniques using univariate tests, MRMR and Fast-CMIM provide good results for manipulations causing marginal distribution shifts, but completely fail when facing manipulations affecting feature correlations (manipulations 3 and 8), while conditional testing-based techniques (MB-SM, MB-KS, KNN-KS, and Deep-SM) and DataFix are able to detect them. DataFix outperforms competing methods in most of the real datasets, with an overall lower F-1 score for datasets with a larger number of dimensions (phenotypes, founders, and canine).

**Feature Shift Correction.** We evaluate our method and 13 competing techniques, including predictive models like KNN, linear regression (LR), and multilayer perceptron (MLP), imputation methods including HyperImpute, ICE, MIRACLE, MissForest, and SoftImpute, optimal transport methods such as Sinkhorn, adversarial learning methods like GAIN, and domain adaptation techniques including deep destructors (DD) and iterative alignment flows (INB). We perform a manipulation-agnostic evaluation, where we set the corrupted features to 0 (or missing) and treat all manipulation types equally. Both the reference and the query are provided to each method, and non-parametric statistical metrics computed between the reference and the updated (corrected) queries are used to evaluate each method's performance. Specifically, we use the Wasserstein distance (\(W_{2}^{2}\)) as in , the empirical estimator of the Henze-Penrose divergence (\(D_{hp}\)) [85; 86; 87], and the empirical

Figure 3: (left) median and mean F-1 score of real and simulated datasets, and (right) median and mean F-1 score across manipulation types and datasets. Higher is better.

estimator of the symmetric Kullback-Leiber divergence (\(D_{skl}\)) . We report the metrics after subtracting the "background" divergences computed with the reference and query datasets previous to any manipulation. Figure 4 shows the median and mean metrics for the real and simulated datasets respectively. DataFix is able to provide a corrected query dataset \(Y^{}\) with the lowest empirical divergences. Despite their simplicity, KNN and linear regression provide competitive results, followed by MLP, HyperImpute, ICE, INB, and Sinkhorn. See Section J for more details.

**DataFix Analysis.** Figure 5 shows the iterative process of DF-Locate before and after performing shift correction, in simulated dataset 12 with 200 corrupted features out of 1000 (see Section B.2 for more details). Fig. 5 (left) shows the total variation distance estimated by the random forest (blue) which lower-bounds its ground truth monte carlo estimate (black) as corrupted features are detected and removed. The F-1 detection score increases until all features are detected and the iterative process is stopped. Fig. 5 (right) shows the iterative process applied to the corrected query with different methods. ICE and DD provide an updated query that leads to a lower empirical divergence, while the other methods provide an updated query that increased the shift instead of reducing it. DF-Correct (Purple) provides an accurately corrected query, with no empirical divergence detected by DF-Locate.

Extended experimental results are present in the appendix, including an analysis of the method's computational time (Section H), the effect of the classifiers used in DataFix (Section K), experimental results of using corrected datasets in downstream classification and regression (Section M), a detailed division of the quantitative results (Sections I and J), and a discussion of limitations (Section O).

## 7 Conclusions

In this paper, we introduced a new framework "DataFix" which makes use of tree-based classifiers, combined with iterative heuristics, to localize and correct feature shifts. The system, inspired by adversarial learning and feature selection frameworks, is able to accurately detect and correct a wide range of distribution shifts in many types of datasets, surpassing existing techniques.

Figure 4: \(W_{2}^{2}\), \(D_{hp}\), and \(D_{skl}\) of real and simulated datasets. Lower is better.

Figure 5: DF-Locate iterative process before and after shift correction.