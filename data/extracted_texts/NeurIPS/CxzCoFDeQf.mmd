# Salsa Verde: a machine learning attack on Learning With Errors with sparse small secrets

Cathy Yuanchen Li

FAIR, Meta

Emily Wenger

The University of Chicago

Francois Charton

FAIR, Meta

Zeyuan Allen-Zhu

FAIR, Meta

Kristin Lauter

FAIR, Meta

Co-senior authors

###### Abstract

Learning with Errors (lwe) is a hard math problem used in post-quantum cryptography. Homomorphic Encryption (HE) schemes rely on the hardness of the lwe problem for their security, and two lwe-based cryptosystems were recently standardized by NIST for digital signatures and key exchange (KEM). Thus, it is critical to continue assessing the security of lwe and specific parameter choices. For example, HE uses secrets with small entries, and the HE community has considered standardizing small sparse secrets to improve efficiency and functionality. However, prior work, Salsa and Picante, showed that ML attacks can recover sparse binary secrets. Building on these, we propose Verde, an improved ML attack that can recover sparse binary, ternary, and narrow Gaussian secrets. Using improved preprocessing and secret recovery techniques, Verde can attack lwe with larger dimensions (\(n=512\)) and smaller moduli (\(_{2}q=12\) for \(n=256\)), using less time and power. We propose novel architectures for scaling. Finally, we develop a theory that explains the success of ML lwe attacks.

## 1 Introduction

Language models have been successfully applied to numerous practical science problems in recent years. For example, transformers  have been used to solve problems in mathematics , theoretical physics , chemistry , and biology . In this paper, we present an application of transformers to computer security: the cryptanalysis of Learning With Errors (lwe) , a hard math problem underpinning leading proposals for post-quantum public key cryptography.

Public-key cryptosystems are the main solution for secure communication over the Internet. Public keys can be used to encode messages or verify digital signatures to or from a user with the corresponding private key. Security relies on the fact that recovering the private key from the public data requires solving a computationally hard math problem. Most currently deployed public-key systems are based on RSA , which relies on the hardness of factoring large numbers into products of primes. Unfortunately, large-scale quantum computers will enable implementation of Shor's algorithm , which can factor integers in quantum polynomial time and break such systems. As a result, new hard problems are sought to serve as the basis of post-quantum public key cryptography (PQC). The US National Institute of Standards and Technology (NIST) ran a 5 year competition to define future PQC standards , and standardized \(4\) PQC systems in July 2022 . Two of these rely on special cases of the same hard (and Shor-free) problem: Learning with Errors (lwe).

The Learning With Errors problem (lwe) assumes that it is hard to recover a secret vector \(\), given many lwe samples \((,b)\). In a lwe sample, each \(\) is a random vector of \(n\) integers modulo \(q\) (\(n\) is the dimension and \(q\) is the modulus), and \(b\) is a noisy modular inner product of \(\) and the secret key \(\)--that is, \(b=+e q\), with the error \(e\) drawn from a Gaussian distribution ofwidth \(_{e}\) centered at \(0\), \(e N(0,_{e}^{2})\) and \(_{e} q\). The hardness of lwe is related to the hardness of well-known lattice problems such as the (approximate) Shortest Vector Problem (SVP).

**Most classical attacks on lwe** rely on lattice reduction . For example, given \(m\) samples \((_{},b_{i})\), create a matrix \(A_{m n}\) whose \(m\) rows are the vectors \(_{}\). The unique shortest vector problem (uSVP) attack recovers the secret \(\) by finding the shortest vector in a lattice constructed from \(\), the columns of \(A_{m n}\), and other parameters. The best known algorithms for solving SVP run in time exponential in the dimension \(n\). Somewhat counter-intuitively, the smaller the modulus \(q\), the harder the lwe problem. Approximate solutions can be computed in polynomial time with LLL , but the approximation factor is exponentially bad (exponential in \(n\)). We compare our results with uSVP attacks on lwe in SSA.7.

**Machine learning (ML) attacks on lwe.**Salsa**, the seminal ML attack on lwe, uses a large collection of lwe samples \(\{(,b)\}\) with the same secret \(\) to train a transformer  that predicts \(b\) from \(\). Salsa presents methods for secret recovery via queries to the trained model, and observes that high model accuracy is not needed: secrets are recovered as soon as the transformer _starts_ to learn (training loss drops). Salsa is a proof of concept, recovering binary secrets with \(3\) or \(4\) nonzero bits for problems with dimension up to \(128\), small instances of lwe solvable via exhaustive search.

**Picante** builds on an observation from Salsa ([58, Table 4]): transformers trained on lwe samples \(\{(,b)\}\), with entries of \(\) drawn from a restricted range instead of all of \([0,q)\), can recover binary secrets with larger Hamming weights \(h\) (number of nonzero bits). So Picante introduces a data preprocessing phase during which the lwe samples \((,b)\) are processed by BKZ, a lattice reduction algorithm, to obtain lwe samples with the same secret but smaller coordinate variance (and larger error, see SS2). In addition to training the transformer on the preprocessed samples, Picante reduces the number of lwe samples required for the attack from \(4\) million in Salsa to \(4n\) (e.g. \(1400\) for \(n=350\)), and improves secret recovery. Overall, Picante can recover binary secrets for dimensions up to \(350\) and Hamming weight up to \(60\). This is a considerable improvement over Salsa, faster than the uSVP attacks we compare against, and out of reach for exhaustive search.

**Picante has several limitations**. First, it only recovers sparse binary secrets, an important but limited subclass of lwe. Homomorphic encryption (HE) may use binary secrets, but HE and other PQC schemes typically use ternary (\(s_{i}\{-1,0,1\}\)) or small (\(|s_{i}|<k\), \(k\) small) secrets. Second, Picante's preprocessing is costly as dimension increases, making it difficult to scale Picante to dimensions larger than \(350\). For \(n=512\), \(_{2}q=45\), Picante's preprocessing approach could not finish in a month with full parallelization. Third, Picante only experiments with large modulus \(q\): \(_{2}q=23\) for \(n=256\), \(_{2}q=27\) for \(n=300\), and \(_{2}q=32\) for \(n=350\). Practical lwe-based systems use small \(q\): Lizard recommends \(_{2}q=10\) for \(n=608\) with sparse binary secrets, and the HE standard  recommends \(_{2}q=25\) for \(n=1024\) with ternary secrets.

**Our work, Salsa Verde**, improves on Picante and makes the following contributions:

* We introduce a **two-bit distinguisher, a new secret recovery technique** for sparse binary, ternary and small Gaussian secrets. Verde fully recovers binary and ternary secrets equally well (SS3).
* We improve data **preprocessing techniques**, making them forty times faster and \(20\%\) more effective, enabling recovery of binary, ternary and small Gaussian secrets for dimension \(512\) (SS4).
* We **decrease the modulus \(q\)**, showing Verde outperforming uSVP attacks (SS5 and SSA.7).
* We propose **NoMod**, a framework for understanding the success of ML-based lwe attacks (SS5).
* We present a **theoretical analysis** to show heuristically that successful secret recovery depends only on \(\) and the standard deviation of the distribution of the lwe data (SS6).
* We experiment with **encoder-only models** and compare their success with seq2seq models (SS7).

**Key results.** Our main finding is that small, sparse lwe secrets are weak. For dimension \(n=256\), we can recover binary and ternary secrets with \(10\%\) sparsity (\(h/n\)) for \(_{2}q=20\), and with \(3\%\) sparsity when \(_{2}q=12\) (Table 1). For \(n=512\), \(_{2}q=41\), we recover binary and ternary secrets with \( 11\%\) sparsity. Furthermore, Verde scales well to higher dimensions for small sparse secret recovery. Training Verde models on \(n=256/350/512\) problems takes only 1.5/1.6/2.5 hours per epoch, a small proportional increase compared to the increase in \(n\). Also, we find that Verde runs faster than uSVP attacks, at the expense of using more compute resources in parallel (see A.7).

In Table 1, we report the timings for successful secret recoveries, for binary/ternary/Gaussian secrets, with varying \(n\) and \(_{q}\). The table records the highest \(h\) recovered for each column: for binary secrets,\(h\) is the Hamming weight, and for ternary and Gaussian secrets, \(h\) is the number of non-zero entries. We record the amount of time needed for each stage of the attack, preprocessing (in hours/CPU, assuming full parallelization), model training (hours/epoch \(\) (# epochs)), and total attack time. For full parallelization, the number of CPU cores required is 4 million divided by \(2n\). Source code and parameters to reproduce our main experiments are included in the supplementary material. The full code base will be open-sourced.

**Scope of results.** Instances of cryptographic problems like LWE can be broadly categorized as easy (solvable via exhaustive search), medium-to-hard (requiring significant resources to solve), or standardized (believed secure). Verde attacks _medium-to-hard_ LWE problems (parameterized by dimension \(n\), Hamming weight \(h\), modulus \(q\)). Verde does not attack toy problems (like Salsa did), nor does it attack the NIST standard directly. Rather, Verde demonstrates successful attacks on medium-to-hard LWE problems using tools from AI, improving our understanding of the security of proposed LWE-based cryptosystems.

## 2 Salsa Verde Overview

In this section we describe the Salsa Verde attack and relevant parts of its predecessor Picante.

**High-level overview.** Like Picante, Verde starts with \(4n\)lwe samples with the same secret \(\). In practice, this data would be eavesdropped. Verde then proceeds in three stages: preprocessing, model training and secret recovery (see Figure 1). The preprocessing stage augments the \(4n\) initial \((,b)\) pairs to \(2\) million, then runs lattice reduction to yield a training set of \(4\) million samples with the same secret \(\). The preprocessed data is used to train a transformer to predict \(b\) from \(\). After each training epoch (2 millionlwe samples), the model is queried to form a secret guess. The attack succeeds if the secret guess is correct, tested via statistical methods without knowledge of the actual secret. Otherwise, the model is trained for another epoch, and secret recovery is run again.

**Data preprocessing.** Verde's preprocessing is similar to Picante's, with several improvements. First, we create \(n n\) matrices \(_{i}\) by sampling without replacement \(n\) of the \(4n\) originallwe samples. Then, we apply lattice reduction to the matrices \(_{i}\) to reduce the standard deviation of their entries (initially uniformly distributed over \([0,q)\)). This process generates \(2n\) preprocessed samples \((^{},b^{})\), with the same secret and is implemented in parallel to create a training set of \(4\) million samples.

During lattice reduction, Picante applies BKZ (as implemented in _fpll_) to the \(2n 2n\) matrix: \(_{i}=_{n}&_{i} \\ 0&q_{n}\). BKZ finds a linear transformation \([_{i}_{i}]\) such that the norms of the \(2n\) rows of \([_{i}_{i}]\,_{i}=[_{i}_{i}_{i}+q_{i}]\) are small. Applying \(_{i}\) to \(_{i}\) and \(_{i}\), Picante generates \(2n\) reducedlwe pairs \((_{i}_{i},_{i}_{i})\) (modulo \(q\)). Verde instead rearranges the rows of \(_{i}\) and applies lattice reduction to \(}_{i}=0&q_{n}\\ _{n}&_{i}\). This reduces the number of operations needed for lattice reduction and allows BKZ to run with lower floating point precision. These two improvements cut the preprocessing time significantly.

  \((n,_{2}q)\) &  &  &  &  &  \\  secret distribution & b & t & g & b & t & g & b & t & g & b & t & g & b & t & g & b & t & g \\ highest \(h\) & 8 & 9 & 5 & 33 & 24 & 7 & 12 & 13 & 5 & 36 & 36 & 10 & 63 & 58 & 16 \\  preprocessing (lws/CPU) & 1.5 & 1.5 & 1.5 & 1.5 & 7.5 & 7.5 & 7.5 & 1.6 & 16 & 16 & 16 & 216 & 216 & 216 & 840 & 840 & 840 \\ training time (lws) & 1.5 & 3 & 12 & 3 & 7.5 & 1.5 & 1.6 & 25.6 & 1.6 & 1.6 & 17.6 & 3.2 & 17.5 & 27.5 & 2.5 \\ total time (lws) & 3 & 4.5 & 13.5 & 10.5 & 15 & 9 & 17.6 & 41.6 & 17.6 & 218 & 234 & 220 & 858 & 868 & 843 \\  

Table 1: Verde attack times (preprocessing, model training, and total), for dimension \(n\) and \(_{2}q\). \(h\) = # non-zero entries in recovered secrets, \(b\) = binary, \(t\) = ternary, \(g\) = Gaussian secret distributions.

Figure 1: _Overview of Verde’s attack methodology_

They also result in smaller \(_{i}\) norms (smaller error in \(_{i}_{i}\)), which can be leveraged to further reduce the norm of \(_{i}_{i}+q_{i}\) by using a lower \(\) parameter (\(=10\)) than Picante (\(=15\)). Finally, Verde replaces BKZ with two interleaved algorithms (BKZ 2.0  and the efficient reduction technique introduced in ), adaptively increases the blocksize and precision as reduction progresses, and introduces a stopping condition. For instance, for \(n=256\) and \(_{2}q=20\), Verde's preprocessing is \(45\) faster, while improving the quality of the reduction by \(20\%\) (Table 2).

Quality of reduction is measured by the standard deviation of the entries of \(_{i}\). Preprocessing time in Table 2 is the hours needed to process one matrix on a single CPU. We list the time for all \(n,q\) attempted in Tables 5 and 19. For each dimension \(n\) and modulus \(q\), we process \(2\) million\(/n\) matrices in parallel across hundreds of CPUs, see SSA.1 for details. Better preprocessing allows Verde to scale to larger dimensions and retrieve secrets with larger \(h\).

**Transformer training.** The \(4\) million reduced lwe pairs are used to train a transformer to predict \(b\) from \(\). The values \(b\) and the coordinates of \(\) are integers in \([0,q)\). They are represented in base \(B= q/8\) (for \(_{2}q>30\), \(B= q/16\)) and encoded as sequences of two tokens over a vocabulary of \(2,000\) (see SSA.1 for a discussion of these choices). Model training is framed as a translation task, from a sequence of \(2n\) tokens representing \(\) to a sequence of \(2\) tokens representing \(b\) (see  for similar uses of transformers for mathematical calculations). The model is trained to minimize the cross-entropy between model prediction and the sequence of tokens representing \(b\), using the Adam optimizer with warmup  and a learning rate of \(10^{-5}\). For \(n=256,350\) and \(512\), each epoch uses \(2\) million lwe samples and runs for \(1.5,1.6\), or \(2.5\) hours. Time/epoch doesn't vary with \(q\) or secret type. Our models train on one NVIDIA V100 32GB GPU and often succeed in the first epoch for low \(h\). Number of epochs required are included in many tables throughout, including Tables 3 and 4.

Verde uses the same architecture as Picante: a sequence to sequence (seq2seq) transformer , with a one-layer encoder (dimension \(1024\), \(4\) attention heads), and a 9-layer decoder (dimension \(512\), \(4\) heads). The last \(8\) layers of the decoder are shared (i.e. they form a Universal Transformer ). Iteration through shared loops is controlled by the copy-gate mechanism introduced in .

Seq2seq models allow output sequences to be longer than inputs, a useful feature for machine translation but not necessary in our setting. For comparison, we also implement a simpler _encoder-only_ transformer, that is 4-layer BERT-like (dimension \(512\), \(4\) heads), together with rotary word embeddings (analogous to the rotary position embeddings ) to account for the modular nature of the problem. On top of this, we also add an earth mover's distance (EMD) auxiliary objective. We compare this model's performance to that of the seq2seq model (SS7).

**Secret recovery.** Secret recovery runs after each epoch (\(2\) million lwe samples). Picante used three recovery methods: direct recovery, cross-attention and distinguisher. Direct recovery struggles as dimension increases, because it relies on accurate model evaluations at special \(\) values which are out of distribution for the training set. Cross-attention is incompatible with encoder-only architectures and is consistently outperformed by the distinguisher on Verde-preprocessed data. Thus, Verde only uses the distinguisher, which works as follows: for any test vector \(_{}\) and random \(K\), if the \(i\)-th entry of the secret \(s_{i}\) is zero, then \((_{}+K_{i})=_{}\) (where \(_{i}\) is the \(i\)-th standard basis vector). Therefore, for each \(i\), the distinguisher computes the difference between model predictions on \(_{}\) and \(_{}+K_{i}\) for different \(_{}\). If differences are small, the corresponding \(s_{i}\) is likely zero. For ternary and Gaussian secrets, the distinguisher is modified (see SS3).

For successful secret recovery, the trained model must generalize well to \(\{_{}\}\), the vectors used for testing. In Picante, the distinguisher runs on random \(_{}\), with coordinates uniform in \([0,q)\). However, the model is trained on preprocessed \(_{}\), with a non-uniform coordinate distribution. So Picante's distinguisher recovery requires that the model generalize outside its training distribution.

  
**preprocessing technique** & **reduction factor** & **time (hrs/CPU)** \\  Picante & 0.53 & 338 \\  + reordered \(_{i}\) rows & 0.47 & 136 \\  + reduced floating point precision & 0.47 & 24 \\  + reduced parameter \(\) from 15 to 10 & 0.43 & 38 \\ Verde (+ interleaved reduction, adaptive blocksize, early stopping) & **0.43** & **7.5** \\   

Table 2: **Impact of successive improvements to preprocessing.**\(n=256\), \(_{2}q=20\). Reduction factor of the standard deviation of entries of \(_{i}\): lower is better. Time: # of hours to preprocess one matrix on one CPU.

This is known to be a difficult ML task. Instead, Verde runs the distinguisher on a held-out subset of \(128\) preprocessed vectors \(_{}\). Since the test vectors have the same distribution as the training set, the trained model only needs to generalize in-distribution, a much easier task. This change in \(_{}\) improves the performance of the distinguisher (see Table 14 in SSA.4).

In practice, for each secret coordinate, the distinguisher computes the sum of the absolute difference between model predictions at \(_{}\) and \(_{}+K_{i}\), for \(128\) vectors \(_{}\) and a random \(K(0.3q,0.7q)\) for each \(_{}\). The model makes a secret prediction \(^{}\) by setting the bits to \(1\) on the \(h\) coordinates with the largest sums, and verifies \(^{}\) by computing \(^{}-b\) on the original \(4n\)LWE samples. If the secret is correctly predicted, this quantity should always be small. The statistical properties of this test are discussed in section A.2 of .

Having discussed Verde's background and described its methodology, we now present Verde's key results, as summarized in SS1. We begin with results on ternary and narrow Gaussian secrets.

## 3 Secret Distributions

One of Verde's major contributions is a method to recover secrets from sparse ternary and narrow Gaussian distributions, both of which are being considered for use in real-world cryptosystems . Prior ML-based LWE attacks (Picante and Salsa) only recovered sparse binary secrets. Here, we describe Verde's method for recovering these more general secret distributions, and its performance on ternary and small Gaussian secrets for fixed dimension \(n=256\) and \(_{2}q=20\). Throughout this paper, \(h\) denotes the number of nonzero entries in a secret, which is equal to the Hamming weight in the binary case. We define secret _sparsity_ as the percentage of nonzero secret entries \(h/n\).

Recovering ternary and small Gaussian secrets.In lattice-based cryptography, ternary secrets are vectors \(\) of dimension \(n\), with entries equal to \(0\), \(1\), or \(-1\) (with equal probability of \(1\) and \(-1\) in sparse secrets). Gaussian secrets are vectors \(\) of dimension \(n\), with entries drawn from a Gaussian distribution with small standard deviation \(\). In this paper, we use \(=3\). The Homomorphic Encryption Standard  includes secure parameter choices for Gaussian secrets with \(=3.2\).

Ternary and Gaussian secrets introduce new challenges for ML-based attacks on LWE. The recovery methods in Picante distinguish zero from nonzero bits. In the binary case, this produces one guess \(_{}\), which can be verified by checking that \(b-_{}\) is small. In the ternary case, Picante would produce \(2^{h}\) secret guesses (about \(12^{h}\) guesses for Gaussian secrets), due to the additional \(-1\) entries, and verification becomes very expensive as \(h\) increases. Verde recovers ternary secrets using a two-step approach: first, _partial recovery_ distinguishes zero from nonzero entries, then _full recovery_ guesses the sign of the nonzero bits.

Partial recovery.To identify nonzero bits, Verde uses the binary secret distinguisher from SS2 (after [42, Section 4.3]). For each secret bit, it computes a score from a sample of reduced LWE pairs. The \(h\) bits with the highest scores are candidate nonzero bits. Verde assumes \(h\) is not known and runs the next step for all reasonable possible values of \(h\), e.g. from \(1\) to \(n/20\). Partial recovery alone is a major contribution, as we are not aware of existing attacks that can identify nonzero secret bits.

Full recovery (ternary secrets).To determine whether nonzero bits of a ternary secret are \(1\) or \(-1\), Verde introduces a novel two-bit distinguisher, leveraging the following observation. If two nonzero secret bits \(s_{i}\) and \(s_{j}\) are equal, then for any \(\), exchanging the coordinates \(a_{i}\) and \(a_{j}\) will result in the same \(b\), and corresponding model predictions will be close. Otherwise, model predictions will be different (if \(s_{i} s_{j}\)). Similarly, if \(s_{i}=s_{j}\), for any \(\) and \(c 0\), changing \(a_{i} a_{i}+c\) and \(a_{j} a_{j}-c\) yields the same \(b\), and close model predictions. The two-bit distinguisher uses these techniques to compare each nonzero bit with all others, therefore defining two classes of nonzero bits. Letting one class of bits be \(1\) or \(-1\), Verde produces two secret guesses to be verified.

Full recovery (Gaussian secrets).At present, we implemented full recovery only for binary and ternary secrets. However, full recovery of small Gaussian secrets is possible via the following adaptation of the two-bit distinguisher. The two-bit distinguisher groups nonzero secret bits into \(k\) classes believed to have the same value. In our case, the nonzero bits follow a Gaussian distribution with \(=3\), so we may safely assume that all non-zero secret bits are in \([-9,9]\) (within \(3\) standard deviations) - i.e. \(k=18\). Since the secret is Gaussian, we expect the largest classes to correspond to the values \(-1\) and \(1\), followed by \(-2\) and \(2\), and so on. Therefore, we can intelligently assign values to classes based on class size, and test the corresponding \(2^{k/2}=512\) secrets. We leave implementation of this as future work and report the performance of partial Gaussian secret recovery, using knowledge of \(\) to validate correctness.

**Verde's performance across secret distributions.** Verde recovers _ternary secrets_ with sparsity up to \(10\%\), with comparable performance on binary secrets. Table 3 provides details on partial and full ternary secret recovery for \(n=256\) and \(_{2}q=20\) and \(h=5-25\). For low values of \(h\) (\(h<20\)), ternary secrets are partially recovered early during training (i.e. mostly in epoch \(0\) or \(1\), during the first pass on preprocessed data), and usually fully recovered in the same epoch or shortly after. As \(h\) increases, more training is required for recovery, and the delay between partial and full recovery increases.

For _small Gaussian secrets_, Verde only implements partial recovery (recovery of the nonzero bits). Table 4 presents results for \(n=350\) and \(_{2}q=27\). Recovered \(h\) are lower than in the binary case, and models require less training for low \(h\).

Figure 2 compares Verde's performance across secret distributions for problems with \(n=256\) and different moduli \(q\). For each setting, we run \(100\) recovery experiments and report the highest \(h\) secret recovered in those attempts. Recovery is comparable for binary and ternary secrets. Small Gaussian secrets are significantly harder.

## 4 Large Dimension

The hardness of lwe increases as \(n\) grows. Picante recovered sparse binary secrets for dimension up to \(n=350\). Verde pushes this limit to \(n=512\), for sparse binary, ternary, and narrow Gaussian secrets. For \(n=512\) and \(_{2}q=41\), Verde recovers binary and ternary secrets with sparsity up to \(0.12\) (highest \(h=63,60\)) and Gaussian secrets with \(h\) up to \(16\). The longer Verde's preprocessing step runs, the higher \(h\) secrets it can recover. Recall that real-world schemes like LIZARD operate in dimension \(n=608\) and HE in dimension \(n=1024\). Those systems use significantly smaller \(q\) where lwe is harder: \(_{2}q=10\) and \(27\), respectively, compared to Verde's \(_{2}q=41\).

**Verde's performance in large dimension.** Table 5 shows Verde's performance for dimension \(n=512\), after \(7\) to \(35\) days of preprocessing, on the same set of matrices \(_{i}\). For each preprocessing time, we measure the quality of lattice reduction via a "reduction factor," computed by taking the ratio of the standard deviation of reduced \(_{i}\) entries to the standard deviation of a random matrix with uniform coefficients \(0 a_{i}<q\), i.e. \((_{})}{(_{ {rand}})}\), with \((_{})=}\). This metric, used in Picante for selecting BKZ parameters, is discussed in SS 6. As Table 5 demonstrates, the maximum recoverable \(h\) is strongly correlated to the quality of lattice reduction.

**Preprocessing adjustments for large \(n\).** Scaling up to \(n=512\) requires a number of adjustments to our preprocessing methodology. For \(n=512\), the first loops in BKZ 2.0 are very slow. To avoid this, we use BKZ with smaller blocksizes than those used for \(n=256\) and \(350\)

   \(h\) & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\  partial recovery & 8/10 & 8/10 & 7/10 & 5/10 & 2/10 & 2/10 & 4/10 \\ training epoch & 0,0,0,0,1,1,1,1 & 0,0,0,1,2,3,3,7 & 0,0,1,2,2,5,10 & 2,2,3,7,10 & 0,2 & 1,9 & 1,5,6,12 \\   

Table 4: **Partial Gaussian secret recovery.**\(n=350,_{2}q=27\). Epoch when secret is recovered.

   \(h\) & 5 & 10 & 15 & 20 & 21 & 22 & 23 & 24 & 25 \\  partial recovery & 8/10 & 6/10 & 6/10 & 2/10 & 3/10 & 2/10 & 1/10 & 3/10 & 1/10 \\ training epoch & 0,0,0,0,0,0,1,7 & 0,1,1,1,1 & 0,0,0,1,2,8 & 0,2 & 0,1,3 & 2,5 & 9 & 0,4,7 & 2 \\  full recovery & 8/10 & 6/10 & 5/10 & 1/10 & 3/10 & 2/10 & 0/10 & 1/10 & 0/10 \\ training epoch & 0,0,0,0,0,0,1,7 & 1,2,2,6,7,8 & 1,1,6,9,11 & 5 & 4,10,17 & 8,22 & & 5,12 & \\   

Table 3: **Partial and full ternary secret recovery.**\(n=256,_{2}q=20\). Epoch when secret is recovered.

Figure 2: _Best \(h\) recovered vs. \(_{2}q\) and secret distribution_. \(n=256\).

reduction is significantly slower for larger matrices. To mitigate this, for \(n=512\), we use \(448\) lwe samples (instead of \(512\)) when generating \(_{i}\) for lattice reduction, therefore reducing the matrix size from \(1024 1024\) to \(960 960\). Experimentally, we observe that using slightly fewer samples did not negatively impact our reduction factor or attack performance.

## 5 Small Modulus

To define real-world parameters for lattice-based cryptography, standardization committees and communities (e.g. ) select a small enough modulus \(q\) (for fixed dimension \(n\)), so that all known attacks are (heuristically) predicted to run in time at least \(2^{128}\), therefore attaining the U.S. government minimum \(128\)-bit security level. For classical lattice reduction attacks, the smaller the modulus, the more difficult the attack. This is because lattice reduction algorithms such as LLL and BKZ attempt to compute short vectors in Euclidean space, but cryptosystems operate modulo \(q\). Smaller moduli result in smaller lattice volumes, meaning shorter target vectors are required to break the system. In our ML approach, we also observe that Verde is less likely to succeed when \(q\) is smaller (see Table 6). Nevertheless, Verde outperforms the uSVP attack (\(@sectionsign\)A.7).

**Picante vs. Verde's performance on small \(q\).**Picante attacks larger moduli: it can recover binary secrets with \(h=31\) for \(_{2}q=23\) and \(n=256\), and \(h=60\) for \(_{2}q=32\) and \(n=350\). Table 6 presents Verde's highest recovered \(h\) (in 10 random attempts) for dimensions \(256\) and \(350\) and different \(q\) for binary, ternary, and narrow Gaussian secrets. First, note that Verde recovers binary secrets with \(h=33\) for \(n=256\) and \(_{2}q=20\), but also, Verde succeeds for much smaller \(q\), as small as \(_{2}q=12\), a near-real-world parameter setting, demonstrating that Verde significantly outperforms Picante. However, for smaller \(q\), Verde recovers only secrets with smaller \(h\). As with classical attacks, the likely culprit is lattice reduction: the reduction factor after preprocessing is \(0.71\) for \(_{2}q=12\) versus \(0.43\) for \(_{2}q=20\), and \(h\) for recovered binary secrets drops from \(33\) to \(6\). Section 6 provides a theoretical explanation of this phenomenon.

Figure 3 visualizes Verde's success rates for \(n=256\) with binary secrets. For every value of \(q\) and \(h\), we run Verde on \(10\) binary secrets, using the same preprocessed data. Verde's success rate decreases as \(h\) increases. Attempting \(10\) random binary secrets for \(n=256,_{2}q=12\), Verde recovers secrets for up to \(h=6\) but not \(h=7,8\) (Table 6). However, with more attempts, Verde recovers \(1/100\) binary secrets for \(h=8\). Experiments with different random seeds (see \(@sectionsign\)A.2) suggest that model initialization alone is not responsible for how success rate trends with \(h\).

**Explaining success for smaller \(q\) via NoMod.** As Table 6 indicates, for given \(n\) and \(h\), secrets are harder to recover for smaller \(q\). This suggests that the modular operations in the computation of

   q\)} &  **reduction** \\ **factor** \\  } &  & \(h\) \\  & & b & t & g \\ 
256, 20 & 0.43 & 33 & 24 & 7 \\
256, 18 & 0.53 & 18 & 19 & 7 \\
256, 16 & 0.63 & 12 & 12 & 6 \\
256, 14 & 0.71 & 9 & 9 & 6 \\
256, 12 & 0.77 & 6 & 6 & 5 \\ 
350, 27 & 0.38 & 36 & 36 & 10 \\
350, 21 & 0.61 & 12 & 13 & 5 \\   

Table 6: **Highest \(h\) recovered, \(n=256,350\). Secret distributions are \(b\) = binary, \(t\) = ternary, \(g\) = Gaussian.**

Figure 3: \(h\) of recovered secrets vs. \(_{2}q\), \(n=256\). 10 random binary secrets attempted for each \(h\). One green dot represents a successful recovery.

  
**preprocess time** & **reduction factor** & **binary \(h\)** & **ternary \(h\)** & **Gaussian \(h\)** \\ 
7 days & 0.519 & 16,17,17,20 & 17,20,20,21,21 & 8,8,8,8,10,10,13 \\
10 days & 0.469 & 21,22,23,28 & 22,24,24,27,29 & 11,11,11,12,12,12,12 \\
14 days & 0.423 & 32,32,34,34,35,40 & 32,34,34,35,35 & 11,11,11,12,12,12 \\
20 days & 0.380 & 35,35,36,41,49 & 35,35,37,45,46 & 13,13,13,16,16 \\
28 days & 0.343 & 40,43,45,47,50,51,55 & 40,41,41,44,45,48,48,53 & 13,13,14,16,16 \\
35 days & 0.323 & 48,48,49,52,57,59,63 & 45,46,50,55,58,60 & 14,16 \\   

Table 5: **Data preprocessing vs performance. \(n=512\), \(_{2}q=41\). Highest values of \(h\) recovered, for different reduction factors (lower factor \(=\) better reduction).**from **a** might account for the difficulty. To investigate this, we evaluate, for a given known binary secret **s**, the percentage of samples where computing \(b\) did not require the modular operation, for the \(4\) million samples in our training set. More precisely, we represent the mod \(q\) coordinates of **a** and \(b\) in the interval \((-q/2,q/2)\), and compute \(x=-b\) without modular operations. If \(b\) was computed without modular operations, then \(x\) is equal to the error for that sample, which is small. Otherwise \(x\) is equal to the error plus a multiple of \(q\). For each \((,b)\), if \(|x|<q/2\), then no modular operation was performed. We define **NoMod** to be the percentage of such \(x\) in the training set.

Figure 4 shows the distribution of secret recoveries, for varying **NoMod**, for 210 experiments with dimension \(n=256\) and \(_{2}q=20\). Clearly, recovery occurs when **NoMod** exceeds a threshold value, empirically observed to be \(67\%\). These results confirm our hypothesis that modular arithmetic is the major cause of failure to recover secrets, and help explain the observation ([42, SS6.4] and SSA.2) that some secrets are never recovered, no matter how many model initializations are tried. For a given secret, **NoMod** is a property of the training data, not of model initialization, and multiple initializations only seem to help when **NoMod** is close to the recovery threshold.

**A trick for improving attack success.** The **NoMod** percentage can only be calculated if the secret is known, so it cannot aid real-world attack settings. However, our **NoMod** observations suggest that, if recovery fails for a given secret **s**, the failure may be due to a low **NoMod** factor in the preprocessed training set. This reveals a strategy for potentially recovering such secrets. If an initial run of Verde fails for a secret **s**, start over with the (un-preprocessed) matrices \(_{i}\), sampled from the original lwe samples. For each of these, apply a random permutation \(\) to the columns and preprocess the permuted matrices. This creates a new dataset of \(^{}\) with corresponding \(b^{}\), associated to a permuted counterpart \(^{}\) of the original secret **s**. If the **NoMod** of \(^{}\), \(b^{}\) and \(^{}\) is higher that that of **s**, \(b\) and \(\) (though this cannot be measured), \(^{}\) can be recovered. If the attack succeeds, **s** can be restored by applying the inverse of permutation \(\). Table 7 presents the impact of permutations on **NoMod** for \(10\) secrets and \(h=6,7,8\) for \(n=256\) and \(_{2}q=14\). Some secrets become recoverable after using the permutation trick.

## 6 A Theoretical Scaling Law for Verde

**Intuition.** The **NoMod** experiments provide a key insight about the hardness of secret recovery in Salsa-based attacks on lwe. They suggest that a secret \(\) can be recovered from a training set if over \(67\%\) of the \(\{x=-b\}\) are concentrated in the interval of length \(q\). If the random variable \(x\) is Gaussian (a reasonable assumption for \(h 1\), since the entries of **a** are random and bounded), \(68\%\) of its values will be within one standard deviation of its mean, i.e. spread over two standard deviations. Therefore, for the secret to be recoverable, the standard deviation of \(x\) should satisfy \(_{x} q/2\). If \(\) is a binary secret with Hamming weight \(h\), and the entries of a have standard deviation \(_{a}\), we have \(x-e\) and \(_{x}_{a}+_{e}_{a}\). Therefore, \(\) is recoverable if \(_{a} q/2\), or \(_{a}}\).

**Scaling Laws.** We now apply this insight to the experimental results of ML-based attacks on lwe. Consider the original Salsa attack, which does not utilize data preprocessing. Since the entries of **a** are uniformly distributed over \([0,q)\), \(_{a}=}\). Replacing in \(_{a}}\) yields \(h 3\), the main experimental result of Salsa. If we constrain the entries of **a** to be in \([0, q)\) (Table 4 in ), we have \(_{a}=}\), and \(h}\). Applying this formula for \( 0.6,0.55,0.5,0.45\), we obtain maximal recoverable Hamming weights of 8, 10, 12 and 15, which closely match Salsa experimental results.

   \)} &  &  \\   & & original & 56 & 61 & 60 & 61 & 56 & 52 & 67 & 67 & **76** & 67 \\  & permuted & 57 & 67 & 56 & 67 & 62 & **67** & 60 & 60 & 52 & 56 \\   & original & 60 & 60 & 52 & 49 & 60 & **75** & 55 & _60_ & 55 & 56 \\  & permuted & 67 & 52 & 60 & **75** & 60 & 73 & 60 & 71 & 59 & 66 \\   & original & 60 & **74** & **74** & 66 & 60 & 66 & 55 & 60 & 63 & 55 \\  & permuted & 55 & 55 & 60 & 52 & 55 & 60 & 55 & 49 & 60 & 60 \\   

Table 7: **NoMod \(\%\) before/after permuting the columns of \(A\). \(n=256,_{2}q=14\), binary secrets. Each column is a random secret for each \(h=6,7,8\). Entries are the **NoMod \(\%\)**. **Green \(=\) secret recovered**; _red or \(=\).

Figure 4: **Effect of NoMod data on secret recovery for \(n=256\), binary secrets.** Count = # of experiments.**

These results shed light on the role of preprocessing in Picante and Verde. When the standard deviation of \(\) is reduced by a factor \(\), maximal recoverable \(h\) increases by a factor \(}\). However, the formula \(h}\) underestimates actually recovered \(h\) by a factor of \(2\). For instance, from the reduction factors from Table 5, we should expect recovered \(h\) to range from \(11\) to \(29\) as preprocessing time increases from 7 to 35 days, but actual recovered \(h\) ranges from \(20\) to \(63\). As seen in SS5, the preprocessing step makes some secrets easier to recover for the same \(h\), so Verde performs better than predicted by theory for some secrets (at the expense of other secrets). Finally, note that the formula for the standard deviation of \(x\) is the same for ternary and binary secrets. This accounts for the observation in SS3 that ternary secrets are of similar difficulty for Verde as binary secrets.

## 7 Model architecture

Verde's baseline model uses a seq2seq architecture as in Salsa and Picante. Here, we compare it to the new encoder-only model discussed in SS2. Specifically, this new model is based on the DeBERTa  model but replaces its "relative positional embeddings" with rotary word embeddings, in the spirit of rotary positional embeddings (RoPE)  but applied to the integer words. It has 4 layers, 4 heads and 512 dimensions. On top of the cross-entropy loss, we add an auxiliary, squared earth mover's distance (EMD) loss to compare model's softmax distribution with the target \(b\). This encourages the model to make predictions that are at least close to the targets, if not exact matches. Trained with the auxiliary EMD loss, the model also replaces the beam search used in the distinguisher with a novel EMD-based distinguisher that compares the difference between the _distributions_ produced by the model on \(_{}\) and \(_{}+K_{i}\).

Overall, we find that the performance of the two models are comparable (see Table 8). The encoder-only model requires more training epochs before recovery for \(n=256,_{2}q=12\), but requires fewer epochs for \(n=512\), and may scale well to larger \(n\). Furthermore, we observe that the EMD distinguisher still enables full recovery of ternary secrets with high \(h\).

## 8 Related Work

**ML for cryptanalysis.** Numerous proposals leverage ML for cryptanalysis, either indirectly or directly. We call approaches which use ML as part of (but not the main element of) the cryptanalysis process _indirect_ approaches. Indirect approaches typically use ML models to strengthen existing cryptanalysis approaches, such as side channel or differential analysis . Most relevant to this work is a recent paper showing the successful use of ML algorithms in side-channel analysis to attack Kyber, one of the NIST standardized PQC proposals . _Direct_ ML-based cryptanalysis schemes train models to directly recover cryptographic secrets from plaintext/ciphertext pairs or similar information. Such approaches have been studied against a variety of cryptosystems, including block ciphers [29; 9; 18; 3; 53; 38; 8], hash functions , and substitution ciphers [1; 54; 7; 31]. The two ML-based LWE attacks described in SS1, Salsa and Picante, fall under this heading.

**Use of transformers for mathematics.** In recent years, language models have been used to solve math problems beyond the cryptanalysis applications explored in this work. Much prior work has considered how well language models can solve written math problems [35; 48]. More recently,  showed large transformers could achieve high accuracy on elementary/high school problems, and  explored the accuracy of GPT-3  on math word problems. Language models have also been applied to formalized symbolic math problems. After  demonstrated that transformers can solve such problems with high accuracy, follow-up work has explored transformers' use in theorem proving , dynamical systems , SAT solving , transport graphs , and symbolic regression [10; 23]. Finally, some have proposed customizing model architectures to enable specific arithmetic operations [36; 56; 44].

   \(n\), secret \(_{s}\) & **256, binary** &  &  &  \\  \(h\) & 5 & 6 & 4 & 5 & 6 & 57 & 59 & 63 & 55 & 58 & 60 \\  Seq2seq & 7 & 4,7 & 0,5,7,18 & 0,0,1 & 1 & 4 & 8 & 7 & 16 & 11 & - \\ Encoder-only & 20,23,27 & 16,23,28 & 0,16,27 & 1,1,2,6 & 2 & 2 & 3 & 3 & - & 6 & 5 \\   

Table 8: **Performances of seq2seq and encoder-only models.**\(n=256,_{2}q=12\); \(n=512,_{2}q=41\). For binary and ternary secrets, we run 10 secrets per \(h\) and indicate the epochs of full recovery.

Discussion

We present Verde, a ML-based attack on lwe with sparse small secrets. Verde improves data preprocessing and secret recovery, enabling significant performance gains over prior work, Salsa and Picante. In particular, Verde can recover secrets with more general distributions (ternary, small Gaussian), larger dimensions \(n\), smaller moduli \(q\), and higher \(h\). In our implementation, Verde outperforms the uSVP attack, requiring less time but more compute resources (details in Appendix A.7). Most importantly, this work provides key theoretical insights into observed attack performance, paving the way for targeted future work. Note that even if we recover secrets with seemingly low probability, such as one seed out of ten succeeds for that secret (\(1/10\)), or if we do not recover all secrets successfully, such as we recover one out of ten secrets with our attack, this is still enough to make these cryptosystems unsafe to use with low weight secrets (unless there is a way to check for vulnerability to our attack without running the attack).

**Limitations and broader impact.** Despite significantly advancing the state-of-the-art in ML-based lwe attacks, Verde cannot yet break standardized lwe-based PQC schemes, limiting its real-world impact. Because of this, our paper raises no immediate security concerns. Nevertheless, we have shared a copy of our paper with the NIST PQC group to make them aware of this attack.

**Future work.** Scaling Verde to attack real-world systems requires work in several directions: increasing dimension \(n\), reducing modulus \(q\), and increasing \(h\), the number of nonzero entries in recoverable secrets. Continued innovations in model architecture (a la SS7) may allow attacks in higher dimension \(n\), while the theoretical scaling law of SS6 provides helpful guidance for improving \(q\) and \(h\). Given our new insight and analysis of the importance of the **NoMod** percentage, we conclude that the reason that small \(q\) is hard for the transformers with our current approach is that they are not good at modular arithmetic (not yet, anyway--this is an area for future work and improvement). In addition, our preprocessing is not well-suited to what is precisely needed and relies on existing lattice reduction algorithms which scale poorly with \(n\) and \(q\).

This suggests two avenues for improvement: first, to develop model architectures that perform modular arithmetic better. Limited existing work has studied the application of ML to modular arithmetic more broadly , Second, alternative preprocessing techniques should be developed to directly concentrate the distribution of random vectors, without relying on lattice reduction methods. With the goal of reducing the standard deviation of the training data, around any center, techniques from the broader math community may prove helpful.

**Acknowledgements.** We thank Jana Sotakova for her contributions to developing the attack on ternary secrets, Hamming reduction techniques, and Section A.3. We also thank Mark Tygert for his helpful input.