# Exogenous Matching: Learning Good Proposals for

Tractable Counterfactual Estimation

Yikang Chen

Shanghai Key Laboratory of Trustworthy Computing, East China Normal University

Dehui Du

Lili Tian

Shanghai Key Laboratory of Trustworthy Computing, East China Normal University

###### Abstract

We propose an importance sampling method for tractable and efficient estimation of counterfactual expressions in general settings, named Exogenous Matching. By minimizing a common upper bound of counterfactual estimators, we transform the variance minimization problem into a conditional distribution learning problem, enabling its integration with existing conditional distribution modeling approaches. We validate the theoretical results through experiments under various types and settings of Structural Causal Models (SCMs) and demonstrate the outperformance on counterfactual estimation tasks compared to other existing importance sampling methods. We also explore the impact of injecting structural prior knowledge (counterfactual Markov boundaries) on the results. Finally, we apply this method to identifiable proxy SCMs and demonstrate the unbiasedness of the estimates, empirically illustrating the applicability of the method to practical scenarios.1

## 1 Introduction

Counterfactual reasoning, considered one of the advanced cognitive abilities of humans, aims to address questions about hypothetical worlds that have not been observed. Answering these questions, typically in the form of "what-if" or "why," is crucial for attribution and explanation, thus counterfactual reasoning is widely applied in generating explanations , making decisions , and evaluating fairness . A class of generative models called Structural Causal Models (SCMs) provides a semantic characterization of counterfactuals, consisting of a set of endogenous mechanisms and an exogenous distribution, from which a collection of distributions described by specific formal languages is induced. These languages are organized into a progressively refined hierarchical structure, and each is associated with human activities: language \(_{1}\) is about seeing (observational), \(_{2}\) is about doing (interventional), and \(_{3}\) is about imagining (counterfactual). This hierarchy is referred to as the causal ladder  or the Pearl Causal Hierarchy (PCH) . Fig. 1 provides a brief illustration of the relevant concepts. As the highest level of the PCH, counterfactuals entail the most subtle information

Figure 1: A brief illustration of SCM, PCH and counterfactual concepts.

in the hierarchy, making the evaluation of counterfactual languages an appealing objective that has received widespread attention in recent years.

Counterfactual reasoning consists of two subtasks: counterfactual identification and counterfactual estimation. For an expression \(\) in \(_{3}\), identification is to determine the uniqueness of the answer to \(\)[86; 17] or its bounds [114; 25; 66] under some assumptions, while estimation is to compute the specific value of \(\). A series of literature [86; 17] transforms \(\) into a combination of expressions in \(_{1}\) and \(_{2}\) through identification. However, estimating the transformed expression may be intractable. Another series of literature focuses on identifying and estimating \(\) in specific settings, such as back door [82; 115; 102; 102], front door [43; 109; 98], instrumental variables [14; 100; 35], representation decoupling [15; 97; 61], categorical exogenous , exponential family , domain counterfactuals . There are also some literature applicable to relaxed cases, such as [28; 44; 45; 46; 57], but still less developed.

In recent years, a class of methods has emerged that simulate the structure of the original SCM using neural network architectures and learn causal mechanisms based on observed or intervened distributions, which we refer to as neural proxy SCMs. These methods include the use of VAEs [110; 55; 54; 92; 23], GANs [52; 108], normalizing flows [74; 50; 4; 69; 42], DDPMs [84; 12]. Here, we focus only on models that provide identifiability results. Using bijections, [69; 42] demonstrates the identifiability of learned causal mechanisms. However, constrained by bijections, they only provide tractable counterfactual estimation methods for fully observed endogenous variables. The closest method to performing tractable counterfactual estimation in general cases is NCM [107; 108], which employs an optimization algorithm to concurrently achieve tractable counterfactual estimation and identification (or partial identifiability ). However, the counterfactual estimation depends on rejection sampling, thereby lacking scalability.

It is commonly recognized that performing tractable counterfactual estimation in general cases is challenging, even when the SCM is fully specified. From the perspective of definition , one needs to integrate over the entire exogenous space, which involves determining whether the constraints of different hypothetical worlds are simultaneously satisfied. From the perspective of complexity, although  has demonstrated that counterfactual reasoning is tractable if observational and interventional reasoning are tractable, it relies on algorithms with exponential complexity. Furthermore, according to , performing marginal inference on SCMs, including parameterized SCMs such as NCM, has been shown to be NP-hard.

This paper presents a tractable and efficient counterfactual estimation method in general settings based on importance sampling. Here, by "general settings", we mean that the exogenous variables of the SCM can be discrete or continuous, the expressions to be estimated can involve an arbitrary finite number of hypothetical worlds, and the observations and interventions can also be arbitrary.

Specifically, the contributions of this paper are as follows:

1. We propose a tractable and efficient importance sampling method for counterfactual estimation in general settings, which is based on optimizing an upper bound on the variance of the estimators, and is formulated as a conditional distribution learning problem.
2. We explore the injection of structural prior knowledge (counterfactual Markov boundaries) into neural networks used for parameter optimization.
3. The experiments conducted on different SCM settings demonstrate that the proposed method outperforms existing importance sampling methods. Ablation studies empirically highlight the effectiveness of injecting structural prior knowledge. The experiments on counterfactual estimation tasks conducted on two identifiable proxy SCMs illustrate the feasibility of applying the method in conjunction with proxy SCMs to real-world problems.

## 2 Preliminaries

In this section, we provide the necessary background and definitions for our work, which are consistent with [5; 8; 114]. To maintain consistency in notation, we use the uppercase letter \(X\) to denote random variables and the lowercase letter \(x\) to denote their values. Bold uppercase letter \(\) represents a set of variables and \(\) the corresponding set of values. The domain of the variable \(X\) is denoted as \(_{X}\), and \(_{}\) for \(=\{X_{1},,X_{n}\}\) represents the product of domains \(_{i=1}^{n}_{X_{i}}\). We use \(P_{}\) to denote a distribution over a set of random variables \(\), and \(P()\) (abbreviated as \(P()\)) to denote probability when \(\) take values \(_{}\). The lowercase \(p()\) represents the probability density function of \(P_{}\) if \(_{}\) is continuous.

Structural causal modelsAn SCM is a 4-tuple \(=,,,P_{}\), where \(\) is a set of exogenous variables; \(\) is a set of endogenous variables; \(\), which describes the causal mechanisms of \(\), is a collection of functions \(\{f_{V_{1}},f_{V_{2}},,f_{V_{n}}\}\) such that each endogenous variable \(V_{i}\) is determined by a function \(f_{V_{i}}\). Each \(f_{V_{i}}\) is a mapping from the domains of) \(_{V_{i}}_{V_{i}}\) to \(V_{i}\), where \(_{V_{i}}\) and \(_{V_{i}} V_{i}\). The entire set \(\) forms a mapping from \(\) to \(\), while the uncertainty comes from a probability distribution \(P_{}\) over exogenous variables \(\).

An SCM yields a causal graph \(\), where each \(V_{i}\) is a vertex, and the edges come in two types: there is a directed edge (\(V_{i} V_{j}\)) between each pair \(V_{i}\) and \(V_{j}_{V_{i}}\); and there is a bidirected edge (\(V_{i} V_{j}\)) between each pair \(V_{i}\) and \(V_{j}\) if \(_{V_{i}}_{V_{j}}\). This resulting graph is also known as a directed mixed graph (DMG). Here, we assume that the SCM is recursive, which means that there exists an order in \(\) such that for any pair \(f_{i},f_{j}\), if \(f_{i}<f_{j}\), then \(V_{j}_{V_{i}}\). In particular, this implies that given values for exogenous variables (also known as a unit or an individual) \(_{}\), all values of endogenous variables in \(\) are also fixed (i.e., there exists a unique solution for endogenous variables w.r.t. \(\)), and the resulting causal graph \(\) is an acyclic directed mixed graph (ADMG). We denote \(()\) as the solution for \(\) given \(\).

In the paradigm of SCM, an (perfect) intervention is described as replacing the mechanisms of some variables \(\) with constants \(\). The model after this intervention is termed a submodel, defined as

\[_{}=,,_{},P_{},\ _{}=\{f_{i}:V_{i}\}\{ \}.\] (1)

In submodel \(_{}\), the solution of \(\) given \(\), denoted as \(_{_{}}()\), is termed as the potential response, and is typically abbreviated as \(_{}()\).

Counterfactual events and probabilitiesThe random variable \(Y\) corresponding to the submodel \(_{}\) is denoted as \(Y_{}\), termed a counterfactual variable, with its domain denoted as \(_{Y_{}}\). A set of counterfactual variables from the same submodel \(_{}\) is denoted as \(_{}\), and the set of counterfactual variables from \(k\) different submodels \(_{_{1}},,_{_{k}}\) is denoted as \(_{*}=_{i=1}^{k}_{i[_{i}]}\), with the corresponding domain \(_{_{*}}=_{i=1}^{k}_{_{*}}\). Let \(\)-algebra \(_{_{*}} 2^{_{_{*}}}\), where \(2^{_{_{*}}}\) is the power set of \(_{_{*}}\). The counterfactual probability space is then a triplet \(_{_{*}},_{_{*}},P_{_{*}}\), where \(P_{_{*}}\) is a probability measure \(P_{_{*}}:_{_{*}}\), and for any measurable set \(_{*}_{_{*}}\), its value equals the Lebesgue integral,

\[P_{_{*}}(_{*})=_{_{}} _{_{}(_{*})}()\,P_{ },\] (2)

where \(_{}()\) is an indicator function, equal to 1 if \(\) and 0 otherwise. The set \(_{}(_{*})=\{_{*}()_{*}\}\), where \(_{*}()\) denotes the potential responses \(_{i=1}^{k}_{i[_{i}]}()\) of counterfactual variables in \(_{*}\) w.r.t. \(\). We refer to the random event \(_{*}_{*}\) as a counterfactual event, and its probability \(P(_{*})=P_{_{*}}(_{*})\) is termed the counterfactual probability.

Counterfactual probability is the cornerstone of the language \(_{3}\) in \(_{3}\) consist of inequalities between polynomials (and their Boolean combinations) over terms of the form \(P(_{*})\). Here, we assume that the \(_{3}\) expressions to be estimated can be represented by a finite number of \(P(_{*})\) terms (including those approximated by Monte Carlo methods). Therefore, the estimation of \(P(_{*})\) will become a focal point of the subsequent discussion.

Normalizing flowsThe normalizing flow \(_{}:^{d}^{d}\) is a transformation parameterized by \(\) that maps observable samples \(\) with \(d\) features to latent samples \(\) distributed according to a simple distribution \(P_{}\) with probability density function \(p()\). The mapping \(_{}\) is a diffeomorphism, which allows us to compute the density \(p()\) through the change-of-variables formula:

\[ p()= p(_{}())+ |(_{}_{}())|.\] (3)

When the Jacobian determinant of \(_{}()\) is tractable to compute, we can use samples from the observable distribution and maximum likelihood estimation to train the flow \(_{}\). Additionally, we can easily generate i.i.d. samples conforming to the learned observable distribution by first sampling \(^{(i)}\) from the base distribution \(P_{}\), and then evaluating the inverse transformation \(_{}^{-1}(^{(i)})\).

## 3 Exogenous Matching

In this section, we present only the final theoretical conclusions. Detailed derivations of all theories and equations can be found in App. A.

AssumptionsIn addition to assuming that the SCM \(=,,,P_{}\) is recursive, the proposed method also assumes: i) for any \(,_{}, _{}\), \(_{}()\) is computable; ii) \(P_{}\) is sampleable and computable. These assumptions imply the feasibility of counterfactual generation, meaning we can draw arbitrary counterfactual samples, with \(_{}\) and \(P_{}\) both treated as black boxes. For example, in the context of neural proxy SCMs, \(P_{}\), as the latent distribution of the generative model, is typically modeled as a simple distribution, while \(_{}\) is a neural network.

Importance sampling for Monte Carlo integrationA widely used method for estimating the Lebesgue integral is Monte Carlo integration. However, the indicator function \(_{_{}(_{*})}()\) in Eq. 2 limits the efficiency. We consider \(_{_{}(_{*})}()=1\) as a rare event. Since importance sampling is commonly used to handle Monte Carlo estimations involving rare events, we adopt the method of importance sampling on a parameterized proposal distribution \(Q_{}\) for tractable Monte Carlo integration, and the estimator can be derived as:

\[P(_{*})=_{ Q_{}}[_{ _{*}}()]_{i=1}^{n}_{ _{*}}(^{(i)}),\ _{_{*}}()=)}{q( )}_{_{}(_{*})}(),\] (4)

where for each sample \(^{(i)} Q_{}\), it is required that if \(p(^{(i)})>0\), then \(q(^{(i)})>0\). The density ratio \(p()/q()\) is also termed as the importance weight and is usually assumed to be bounded. In this section, we assume that our derivations are based on an exogenous distribution defined over a continuous space. Naturally, similar conclusions hold for discrete exogenous distributions.

### An Optimizable Variance Upper Bound

In importance sampling, a proposal distribution with low variance regarding \(_{_{*}}\) is crucial, as it implies that fewer samples are required to achieve the same effect, leading to higher sampling efficiency. Previous works have attempted to constrain variance, such as providing upper bounds [18; 49], introducing multiple proposals [16; 27], and learning from sampled data [72; 83; 11; 65]. Given that the samples are i.i.d., with the same sample size \(n\), a lower variance of \(_{_{*}}\) implies a lower estimator variance:

\[_{ Q_{}}[_{_{*}}( )]=n[_{i=1}^{n}_{ _{*}}(^{(i)})]=_{ P_{ }}[_{_{*}}()]-P^{2}(_{*}),\] (5)

It is evident that this formulation can be directly optimized, and there are several methods employing similar approaches (e.g., transforming it into cross-entropy or \(^{2}\) divergence), as shown in [32; 68]. This process is called proposal learning, which ultimately yields a proposal distribution \(Q_{}\) that is suitable for the estimator.

The learned \(Q_{}\) is typically "one-off", rendering it unsuitable for other estimators. This necessitates multiple rounds of proposal learning to estimate an \(_{3}\) expression that involves various counterfactual events, which remains inefficient. To address this issue, we propose replacing the proposal distribution \(Q_{}\) with a conditional proposal distribution \(Q_{|_{*}}\). Intuitively, the proposal distribution \(Q_{|_{*}}\) corresponding to \(_{*}_{_{*}}\) should be concentrated on the support \(_{}((_{*}))\), thus allowing for reuse across different estimators.

Building on this idea, we extend the methods from [32; 68], as illustrated in App. B.1. Additionally, we find that when certain conditions are met in \(_{*}\), for any \(_{*}_{*}\), the proposal distribution \(Q_{|_{*}}\) shares a common variance upper bound:

**Theorem 1** (Variance Upper Bound).: Let \(_{_{*}}()=(p()/q(\,|\, _{*}))_{_{}(_{*})}( )\), where \(q(\,|\,_{*})\) denote the density of the proposal distribution \(Q_{|_{*}}\), and let \(_{*}()\) be the potential response w.r.t. \(\). If for any \(_{*}_{*}\), there exists \( 1\) such that \(1/ p()/q(\,|\,_{*})\) holds almost surely on the support \(_{}(_{*})\), then for any \(Q_{|_{*}}\) where \(_{*}_{*}\):

\[_{ Q_{|_{*}}}[_{ _{*}}()]-_{ P_{}}[ q(\,|\,_{*}())]+c,\] (6)

where the constant \(c\) is solely dependent on \(\) and \(P_{}\).

It is noted that the expected term in Eq. 6 bears resemblance to cross-entropy, albeit not strictly. Intuitively, the original indicator function is now implied as potential responses within the condition, and optimizing this expected term can encourage the density of each proposal distribution at specific locations to match that of the exogenous distribution as closely as possible. Therefore, this approach is named **Exogenous Matching (EXOM)**.

The boundedness condition on the importance weights in Thm. 1 is likely to be violated for \(_{*}\) with an infinite support set. We further discuss this issue in App. A.2, where we: i) provide two relaxed versions of Thm. 1 based on concentration inequalities; ii) demonstrate how to construct a guard proposal distribution that necessarily satisfies the boundedness condition.

### Learning and Inference

**Generalize Thm. 1** Since any \(_{3}\) expression \(\) is composed of terms \(P(_{*})\), and assuming that it is expressible by a finite set of \(P(_{*})\), we can consider all \(_{*}\) involved in \(\) as outcomes of a stochastic process. To allow different forms of \(_{*}\), we extend Thm. 1 to general cases, making it potentially applicable to the estimation of any counterfactual probability term \(P(_{*})\) in an \(_{3}\) expression \(\), with only one proposal learning process is required.

**Definition 1** (Stochastic Counterfactual Process).: The collection of counterfactual variable sets \(_{*}=\{_{*}^{(s)} s\}\) is referred to as a stochastic counterfactual process w.r.t. the state space \(\). A state \(s\) is a set composed of triplets \(,,\), where \(,\) represent the intervened and observed variables, respectively, and \(\) denotes the intervened values. Each state \(s\) corresponds to a set of counterfactual variables \(_{*}^{(s)}=_{,,  s}_{}\).

**Corollary 1** (Expected Variance Upper Bound).: Let \(Q_{}\) denote an arbitrary distribution defined over the state space \(\) of a stochastic counterfactual process, and let \(P_{_{*}}^{(s)}\) denote an arbitrary distribution defined over the \(\)-algebra \(_{_{*}}^{(s)}\) corresponding to a set of counterfactual variables \(_{*}^{(s)}\) given a state \(s\). \(P_{_{*}}\) is the joint distribution induced by \(P_{_{*}}^{(s)}\) and \(Q_{}\). If the conditions in Thm. 1 are met for any \(_{*}^{(s)}\) and any \(s\), then for any \(Q_{|_{*}}\) where \(_{*}_{*}^{(s)}\) and any \(s\):

\[_{_{*}^{(s)} P_{_{*}}}[ _{ Q_{|_{*}}}[_{_{*}}( )]]-_{s Q_{}}[_{ P_{}}[ q(\!\!_{*}^{(s)}( ))]]+c,\] (7)

where the constant \(c\) is the same as in Thm. 1.

Sampling and optimizationDisregarding the constant terms of the expected variance upper bound (Eq. 7) in Cor. 1, we obtain the optimization objective as follows:

\[_{q}-_{s Q_{}}[_{  P_{}}[ q(\!\!_{*}^{(s)}( ))]].\] (8)

Based on our assumptions, \(P_{}\) and \(_{*}^{(s)}()\) are known, while the prior distribution of states \(Q_{}\) needs to be specifically designed for the particular expression in \(_{3}\). The problem is now reformulated as a conditional distribution learning problem, and we can model this conditional distribution using neural networks. The complete learning algorithm is presented in Fig. 5 in App. A.3.

InferenceGiven the conditional proposal \(Q_{|_{*}}\), we can take the expectation of the importance sampling results over \(_{*}\) to intuitively further enhance robustness. This leads to another unbiased estimator in the form of multiple importance sampling [16; 27]:

\[P(_{*})=_{_{*} Q_{_{*}}}[ _{ Q_{|_{*}}}[_{ _{*}|_{*}|}()]] _{i=1}^{n}_{_{*}|_{*}^{(i)}}(^{(i)}),\] (9)

where \(_{_{*}|_{*}^{(i)}}()=(p()/q( \!\!_{*}))\,_{_{}(_{*})}()\), and \(_{*}^{(i)} Q_{_{*}}\), \(^{(i)} Q_{|_{*}^{(i)}}\). The distribution \(Q_{_{*}}\) could be any distribution with support covering \(_{*}\).

ConditioningWe attempt to find a function that maps \(_{*}\) to the vectorized parameters \(_{_{*}}\) required for the proposal distribution \(Q_{|_{*}}\). The information provided by \(_{*}\) (i.e., the counterfactual event \(_{*}\{_{*}\}\)) can be interpreted as a set of 4-tuples, where each 4-tuple \(,,,\) expressescounterfactual information within the same submodel \(_{}\), including the observed variables \(\) and their values \(\), and the intervened variables \(\) and their values \(\). We represent it as a vector:

\[_{,,,}=( ;)() (),\] (10)

where \(\) denotes vector concatenation. The functions \(\) and \(\) map inputs to vectors, with each component of the vector corresponding to an exogenous variable \(X_{i}\), defined as follows:

\[_{i}(;)=x_{i},&X_{i} \\ 0,&_{i}()= 1,&X_{i}\\ 0,&.\] (11)

To encode the entire set \(\{_{1},_{1},_{1},_{1}, _{2},_{2},_{2},_{2}, \}\), we introduce two functions, \(h\) and \(g\). Here, \(h\) serves as an encoder, mapping the vector of a single 4-tuple \(_{,,,}\) to a latent encoding, while \(g\) acts as an aggregator, capturing the permutation invariance of the set. The vectorized parameters \(_{_{*}}\) are inferred through the interplay of these two functions:

\[_{_{*}}=g(\{h(_{_{i}, _{i},_{i},_{i}})\;|\;_{i [_{i}]}_{*}\}).\] (12)

We choose to model \(h\) using a multilayer perceptron (MLP), and model \(g\) as a function that ensures permutation invariance for encoding aggregation, such as summation or weighted summation, where we opt for attention  to enhance expressiveness.

### Injecting Markov Boundaries

This section will explore how to inject available structural prior knowledge (specifically, counterfactual Markov boundaries) into neural networks used for conditional encoding, intuitively improving the quality and efficiency of learning.

Counterfactual Markov boundaryMarkov boundaries  have been used in feature selection  and causal discovery , since they reveal the local causal structure of variables, where all elements are strongly correlated with the variable . Just as in feature selection, intuitively we can enhance the performance of distribution learning by masking redundant information. For modeling distributions defined over exogenous variables and conditioned on counterfactual variables, the structural prior information used here is named counterfactual Markov boundaries:

**Definition 2** (Counterfactual Markov Boundary).: For an exogenous variable \(U_{j}\) and a set of counterfactual variables \(\), along with their joint distribution \(P\). If \(U_{j}\) is independent of \(\) given \(\) under \(P\), i.e. \(U_{j}_{P}()\;|\;\), then \(\) is termed a Markov blanket of \(U_{j}\) on \(\). The collection of all Markov blankets of \(U_{j}\) on \(\) is denoted as \(_{j}()\). If \(_{j}()\) is a Markov blanket of \(U_{j}\) on \(\), and there exists no \(^{}\) such that \(^{}_{j}()\), then \(\) is termed a (counterfactual) Markov boundary of \(U_{j}\) on \(\), denoted as \(_{j}()\).

Methods for learning Markov boundaries based on independence in data distribution (e.g. ) cannot be directly applied to learn counterfactual Markov boundaries unless exogenous variables are observable. Moreover, these methods may have low efficiency due to their reliance on independence tests. To obtain the counterfactual Markov boundary, in this work, we assume that

Figure 2: Overview of the conditioning and masking process. \(_{*}\) serves as the input to the entire process, \(\) represents the inferred mask, and the vectorized parameters \(_{_{*}}\) of the proposal distribution \(Q_{|_{*}}\) are the output. Different colors represent information from different submodels. Both \(h\) and \(g\) represent neural networks.

another representation of SCM graphs called augmented graphs is known. Compared to causal graphs, augmented graphs incorporate exogenous variables \(\) into the nodes, then remove bidirectional edges and add unidirectional edges \((U_{j} V_{i})\) for all \(V_{i}\) and \(U_{j}_{V_{i}}\).

When the SCM is recursive, the augmented graph of any submodel is necessarily acyclic due to the closure of recursiveness under (perfect) intervention , which implies that d-separation  always holds. We additionally assume faithfulness , which means that only the variables that are d-separated in the graph are independent in the distribution, allowing us to directly compute counterfactual Markov boundary for any exogenous variable by graph algorithm.

Under the above assumptions, the following theorem indicates that the counterfactual Markov boundary of \(U_{j}\) is independent across different submodels. This not only reduces the search space of the Markov boundary, but also aligns with Eq. 12, where we encode counterfactual information according to each submodel.

**Theorem 2** (Counterfactual Markov Boundary Independence).: If \(_{*}=_{i=1}^{k}_{i[_{i}]}\) and each \(_{i[_{i}]}\) corresponds to a different submodel \(_{_{i}}\), then for each \(U_{j}\), there exists a Markov boundary \(_{j}(_{*})=_{i=1}^{k}_{j}(_{i[ _{i}]})\) on \(_{*}\), where \(_{j}(_{i[_{i}]})\) is a Markov boundary on \(_{_{i}}\).

Another theorem demonstrates how to obtain counterfactual Markov boundaries via d-separation, and indirectly proves their uniqueness:

**Theorem 3** (Counterfactual Markov Boundary on Graph).: For an exogenous variable \(U_{j}\) and a counterfactual variable set \(_{}\) from the submodel \(_{}\), the counterfactual variable \(_{}_{j}(_{})\) if and only if \(_{}_{_{ }^{a}}U_{j}_{}\{_{}\}\), i.e., when \(_{}\{_{}\}\), \(_{}\) and \(U_{j}\) are not d-separated on \(_{}^{a}\), where \(_{}^{a}\) is the augmented graph induced from the submodel \(_{}\).

The graph algorithm to determine counterfactual Markov boundaries \(_{j}(_{*})\) for \(U_{j}\) is derived simply by combining Thms. 2 and 3 with the d-separation criterion as a subroutine, which can be found in Fig. 7 in App. A.4.

MaskingWe then inject the counterfactual Markov boundary into the neural network used for conditioning by vectorizing it as a weight mask, as briefly illustrated in Fig. 2 depicting the entire conditioning and masking process. Specifically, let \(_{_{*},j}\) be any parameter corresponding to exogenous variable \(U_{j}\) in \(Q_{|_{*}}\). According to the description in Thm. 2, the Markov boundary on \(_{*}=_{i=1}^{k}_{i[_{i}]}\) can be precisely decomposed into the union of the Markov boundaries on each \(_{i[_{i}]}\). This corresponds exactly to encoding the information for counterfactual events on each submodel \(_{_{i}}\) as depicted in Eq. 10. Therefore, we can modify Eq. 12 as follows:

\[_{y_{*},j}=g(\{.h_{j}(_{(_{i},_{i},_{i},_{i})},_{ij})\,|\,_{i[ _{i}]}_{*}\}).\] (13)

In particular, \(_{ij}=(_{i}(_{j}))\), and \(_{i}(_{j})\) are obtained through algorithm derived by Thm. 3. The correspondence between the parameters \(_{_{*},j}\) and \(U_{j}\) exists in the specific design of the model, such as the mean and covariance of each component in GMMs or the element-wise transformations in normalizing flows. As used in [31; 81; 13], \(h\) is an MLP that allows weight masking, such that for all \(j\), the \(i\)-th component of \(_{}h_{j}(,_{ij}) 0\) if and only if \(_{ij}=1\). This ensures that \(_{_{*},j}\) is only related to the Markov boundary of \(U_{j}\) on \(_{*}\).

## 4 Related Works

Importance sampling with normalizing flowsIn recent years, the combination of normalizing flows and importance sampling has been widely employed in tasks related to Monte Carlo integration. For instance, a plethora of literature [70; 99; 101; 53; 60; 10; 51; 67] utilizes this combination to efficiently compute the partition function of energy. Some studies [68; 30; 36] also employ this method to solve integration problems of complex functions in high-dimensional spaces. When the integrand involves rejection sampling [6; 89], particle events [29; 9; 88], or failure events [33; 20], this method can improve the efficiency of sampling rare events. This combination is also applied for posterior inference [19; 1; 79; 21] as an alternative to integrating over the intractable distribution.

Identifiable neural proxy SCMsOur approach is applicable to pre-trained neural proxy SCMs, where causal mechanisms are modeled as neural networks. Increasing attention has been paid to the identifiability of these models. BGM  combines bijections to demonstrate the identifiability of causal mechanisms in several special cases. CausalNF  builds upon the conclusions of  to prove the identifiability of its causal mechanisms up to invertible functions. NCM  extends the findings of their previous work  and proposes a sound and complete algorithm to identify counterfactual queries.

Arbitrary conditioningIn dealing with exponentially many conditional distributions, our work establishes a connection with another unsupervised learning task, known as arbitrary conditioning. The task of this paper can be viewed as extending arbitrary conditioning from a single observational distribution to multiple counterfactual distributions. Relevant works include VAE-AC  based on VAE, NC  based on GAN, ACE  based on energy models, and ACFlow  based on normalizing flows. The most similar to our work is , which matches on the posterior distribution of VAE, akin to our matching on the exogenous distribution.

## 5 Experiments

Experiment settings and metricsWe first define the prior distribution \(Q_{}\) over the state space of a stochastic counterfactual process \(_{*}\) and train according to Eq. 8. Subsequently, based on \(Q_{}\), we construct a distribution \(P_{_{*}}\) concerning counterfactual events for the evaluation of the estimator (Eq. 4). Inspired by the metrics for rare event sampling effectiveness, we utilize Effective Sample Proportion (ESP) and Failure Rate (FR) with threshold \(m\) to measure the performance of the importance sampling, defined as:

\[=_{_{*} P_{_{*}}}[( _{*})]=_{ _{*} P_{_{*}}}[1,&(_{*}) m\\ 0,&],\] (14)

where \((_{*})=(_{i=1}^{n}_{_{}( _{*})}(^{(i)}))/n\) is the proportion of effective samples (nonzero indicator) to estimate the probability \(P(_{*})\), which indirectly reflects the sampling efficiency of a single estimate; this is equivalent to the success rate in rare event sampling. Therefore, ESP reflects the overall efficiency of the sampling method in supporting Thm. 1, while FR reflects its overall effectiveness in the state space to support Cor. 1 and Eq. 8. For further discussion on metrics, see App. C.1.

Specifically, the following two types of stochastic counterfactual processes are involved in subsequent experiments: i) \(_{*}^{}\) with state space \(^{}=\{s|s|=k\}\) (that is, with \(k\) submodels) and prior distribution \(Q_{}^{}\), where the indicators for intervention and observation follow Bernoulli distributions, and their values follow endogenous distributions; ii) \(_{*}^{}\), where \(\{,,,\}\), the design of state space \(^{}\) and prior distribution \(Q^{}\) are detailed in App. C.2.

During evaluation, the distribution of counterfactual events \(P_{_{*}}\) is contingent upon the type of counterfactual variables: for discrete, we focus on counterfactual event \(_{*}\{_{*}\}\); for continuous, we focus on counterfactual event \(_{*}_{l}(_{*})\), where \(_{l}(_{*})\) is a cube with side length \(l=0.02\) centered at \(_{*}\). The latter can be further used to estimate the counterfactual density in continuous space, as discussed in App. D.2.

Our experiments involve the following fully specified SCMs, which fall into three categories: i) Markovian diffeomorphic , where there is no hidden confounder and causal mechanisms are diffeomorphic, including SIMPSON-NLIN, TRIANGLE-NLIN and LARGEBD-NLIN; ii) Semi-Markovian continuous , where hidden confounders may exist and endogenous variables are continuous, including M and NAPKIN; iii) Regional canonical , where hidden confounders may exist and endogenous variables are discrete and finite, including FAIRNESS and FAIRNESS-XW. The consistent performance observed in experiments across these different types of SCMs will serve as a reference for evaluating the robustness of the proposed method.

Figure 3: LL (negative Eq. 8) and ESP, FR on SIMPSON-NLIN. As LL increases, ESP increases while FR decreases, until convergence.

ConvergenceWe integrated Exogenous Matching with various density estimation models (GMM, MAF , NICE , SOSPF ) to conduct experiments on the stochastic counterfactual process \(_{*}^{}\) (with \(|s|=3\)) over different SCM settings. We present the results of ESP and FR during the training process. As shown in Fig. 3 (with all results detailed in App. C.5), both the ESP and FR metrics change as expected until convergence, along with the decrease in training loss Eq. 8 (equivalent to the increase in LL in Fig. 3). This validates the effectiveness of Thm. 1 and Cor. 1, and empirically suggests that the conditions we assumed are generally not violated under our settings.

ComparisonWe compare our proposed method with three different but related sampling methods: i) Rejection Sampling (RS); ii) Cross-Entropy based Importance Sampling (CEIS, ); iii) Neural Importance Sampling (NIS, ). To apply the latter two methods under the same experimental setup, we extended them as detailed in App. B.1. As shown in Tab. 1, our method outperforms other approaches in both continuous and discrete cases. Specifically, since MAF exhibits stronger representational capabilities than GMM, it is expected that EXOM using MAF as the conditional distribution model generally outperforms EXOM using GMM.

    & &  &  &  \\  \(|s|\) & Model & ESP \(\) & FR \(\) & ESP \(\) & FR \(\) & ESP \(\) & FR \(\) \\   & RS & \(0.008\) & \(0.971\) & \(0.006\) & \(0.967\) & \(0.156\) & \(0.065\) \\  & CEIS & \(0.037\) & \(0.809\) & \(0.017\) & \(0.911\) & \(0.255\) & \(0.532\) \\  & NIS & \(0.008\) & \(0.961\) & \(0.007\) & \(0.965\) & \(0.193\) & \(0.527\) \\  & EXOM[GMM] & \(0.117\) & \(0.245\) & \(0.039\) & \(0.476\) & \(\) & \(0.009\) \\  & EXOM[MAF] & \(\) & \(\) & \(\) & \(\) & \(0.339\) & \(\) \\   & RS & \(0.000\) & \(1.000\) & \(0.000\) & \(1.000\) & \(0.038\) & \(0.281\) \\  & CEIS & \(0.000\) & \(1.000\) & \(0.000\) & \(1.000\) & \(0.122\) & \(0.704\) \\  & NIS & \(0.000\) & \(1.000\) & \(0.000\) & \(1.000\) & \(0.116\) & \(0.686\) \\  & EXOM[GMM] & \(0.024\) & \(0.500\) & \(0.011\) & \(0.613\) & \(0.247\) & \(0.056\) \\  & EXOM[MAF] & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   & RS & \(0.000\) & \(1.000\) & \(0.000\) & \(1.000\) & \(0.030\) & \(0.368\) \\  & CEIS & \(0.000\) & \(1.000\) & \(0.000\) & \(1.000\) & \(0.106\) & \(0.727\) \\   & NIS & \(0.000\) & \(1.000\) & \(0.000\) & \(1.000\) & \(0.094\) & \(0.724\) \\   & EXOM[GMM] & \(0.020\) & \(0.497\) & \(0.009\) & \(0.644\) & \(0.231\) & \(0.084\) \\   & EXOM[MAF] & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Comparison of RS, CEIS, NIS, and EXOM (ours) across 3 different SCMs, with \(|s|=1,3,5\). Among the three SCMs, SIMPSON-NLIN is Markovian diffeomorphic, NAPKIN is Semi-Markovian continuous, and FAIRNESS-XW is Regional canonical. The results are averaged over 5 runs. Higher ESP and lower FR indicate better performance.

Figure 4: Ablation study for Markov boundaries on 4 different settings of SCMs: (a) SIMPSON-NLIN, (b) LARGEBD-NLIN, (c) M, (d) NAPKIN. A higher ESP signifies greater sampling efficiency. In most cases, EXOM with Markov boundaries masked (orange bar) exhibits superior performance compared to when the Markov boundaries are not masked (blue bar).

AblationTo investigate the impact of injecting Markov boundaries, we present the improvement of ESP after injecting Markov boundaries during the training process compared to the default scenario. We conducted ablation experiments on 4 continuous SCMs and various density estimators. As shown in Fig. 4, the use of Markov boundaries as masks significantly improves the performance of EXOM under various settings. We also observed that when masks are used, the width of the hidden layers of neural networks in conditioning affects practical performance, which will be discussed in App. C.8.

Counterfactual Estimation on Proxy SCMsWe combine identifiable proxy SCMs with EXOM for counterfactual estimation. We employ CausalNF  for SIMPSON-NLIN (based on the stochastic process \(_{*}^{}\)) and NCM  for FAIRNESS (based on the stochastic process \(_{*}^{}\)). For the combination of CausalNF and SIMPSON-NLIN, we estimate the counterfactual probability on cubes \(_{l}(_{*})\) with side length \(l=0.02\) centered around 1024 randomly sampled \(_{*}\) from \(P_{_{*}}\) (this can be used further to estimate counterfactual density), measure the sampling FR, and employ a dimension-regularized 95% CI error bound. For the combination of NCM and FAIRNESS, we estimate 4 different counterfactual queries, measure the average bias of the query results relative to the ground truth, and use a 95% CI error bound to demonstrate the unbiasedness of the estimates.

The results in Tab. 2 empirically demonstrate the effectiveness of EXOM in counterfactual density and effect estimation tasks compared to RS. Specifically, when estimating the cube \(_{l}(_{*})\) (equivalent to counterfactual density), RS almost fails in high-dimensional settings, while EXOM exhibits good sampling efficiency and lower error compared to RS. When estimating counterfactual queries, the bias and error of EXOM are similar to those of RS (partly due to the lower sampling difficulty in discrete cases). Further experimental details and analysis of the conclusions can be found in App. C.9.

## 6 Conclusion

We propose Exogenous Matching for tractable estimation of expressions in \(_{3}\) in general settings. Specifically, leveraging importance sampling, we find a variance upper bound for estimators potentially applicable to any relevant counterfactual probability (Cor. 1), and then introduce an optimization objective (Eq. 8) amenable to sampling, transforming the problem into a conditional distribution learning problem. Theoretical and empirical results demonstrate that this approach can be combined with identifiable proxy SCMs to address practical problems. We also explore injecting Markov boundaries as prior knowledge and empirically validate effectiveness in several scenarios.

Limitationsi) The proposed method does not directly estimate counterfactuals through the available distribution but requires a partially specified SCM. This work explores its effectiveness in combination with identifiable proxy SCMs, which are still an active area of research; ii) It is important to emphasize that the "general case" mentioned in this paper does not cover all scenarios. For instance, our estimand, an \(_{3}\) expression \(\), requires the assumptions of finite submodels and approximability by a finite number of counterfactual probabilities; iii) Furthermore, the specific structures and tricks demonstrated in this paper (such as the injection of Markov boundaries) may not be applicable to SCMs with general parameter settings, which warrants further investigation.

    & &  &  \\  Method & SCM & \(|s|=1\) & \(|s|=3\) & \(|s|=5\) & ATE & ETT & NDE & CtfDE \\   & O & \(0.89_{0.014}\) & - & - & \(0.01_{0.013}\) & \(0.01_{0.018}\) & \(0.01_{0.015}\) & \(0.01_{0.020}\) \\  & P & \(0.90_{0.012}\) & - & - & \(0.01_{0.013}\) & \(0.01_{0.021}\) & \(0.01_{0.014}\) & \(0.01_{0.023}\) \\   & O & \(0.00_{0.005}\) & \(0.02_{0.015}\) & \(0.01_{0.021}\) & \(0.04_{0.095}\) & \(0.06_{0.168}\) & \(0.04_{0.131}\) & \(0.07_{0.236}\) \\  & P & \(0.01_{0.005}\) & \(0.40_{0.012}\) & \(0.61_{0.016}\) & \(0.01_{0.013}\) & \(0.01_{0.024}\) & \(0.01_{0.013}\) & \(0.01_{0.044}\) \\   & O & \(0.00_{0.006}\) & \(0.02_{0.016}\) & \(0.01_{0.046}\) & \(0.01_{0.018}\) & \(0.01_{0.030}\) & \(0.01_{0.020}\) & \(0.01_{0.039}\) \\  & P & \(0.01_{0.005}\) & \(0.40_{0.013}\) & \(0.61_{0.018}\) & \(0.01_{0.017}\) & \(0.01_{0.021}\) & \(0.01_{0.012}\) & \(0.01_{0.022}\) \\   

Table 2: Estimation of counterfactual densities on CausalNF and counterfactual effects on NCM. Here, “O” represents the original SCM, and “P” represents the proxy SCM. For SIMPSON-NLIN, the proxy SCM is CausalNF, and the metric used is FR (“-” indicates FR equals \(1\)); whereas for FAIRNESS, the proxy SCM is NCM, and the metric used is the average bias w.r.t. the ground truth. The subscript denotes the 95% CI error bound over 5 trials. For more details, see App. C.9