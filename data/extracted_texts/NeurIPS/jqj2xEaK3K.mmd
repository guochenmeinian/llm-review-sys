# Finding Interior Optimum of Black-box

Constrained Objective with Bayesian Optimization

 Fengxue Zhang

University of Chicago

&Zejie Zhu

University of Chicago

&Yuxin Chen

University of Chicago

Corresponding to zhangfx@uchicago.edu

###### Abstract

Optimizing objectives under constraints, where both the objectives and constraints are black box functions, is common in real-world applications such as medical therapy design, industrial process optimization, and hyperparameter optimization. Bayesian Optimization (BO) is a popular approach for tackling these complex scenarios. However, constrained Bayesian Optimization (CBO) often relies on heuristics, approximations, or relaxation of objectives, leading to weaker theoretical guarantees compared to canonical BO. In this paper, we address this gap by focusing on identifying the interior optimum of the constrained objective, deliberately excluding boundary candidates susceptible to noise perturbations. Our approach leverages the insight that jointly optimizing the objective and learning the constraints can help pinpoint high-confidence _regions of interest_ (ROI) likely to contain the interior optimum. We introduce an efficient CBO framework, which intersects these ROIs within a discretized search space to determine a general ROI. Within this ROI, we optimize the acquisition functions, balancing the learning of the constraints and the optimization of the objective. We showcase the efficiency and robustness of our proposed CBO framework through the high probability regret bounds for the algorithm and extensive empirical validation.

## 1 Introduction

Bayesian optimization (BO) has been extensively studied over the past few decades as a powerful framework for addressing expensive black-box optimization tasks in machine learning, engineering, and science. In many real-world applications, these optimization tasks often involve black-box constraints that are costly to evaluate Digabel and Wild (2015). Examples include choosing from a plethora of untested medical therapies under safety constraints (Sui et al., 2015); determining optimal pumping rates in hydrology to minimize operational costs under constraints on plume boundaries (Gramacy et al., 2016); or tuning hyperparameters of a neural network under memory constraints (Gelbart et al., 2014). It is common to model constraints analogously to the objectives via Gaussian processes (GP) and then utilize an acquisition function to trade off the learning and optimization to decide subsequent query points.

Recently, significant advancements have been made in several directions to address constrained BO (CBO). For instance, extended Expected Improvement approaches (Bernardo et al., 2011; Gelbart et al., 2014; Gardner et al., 2014; Zhang et al., 2021; Bachoc et al., 2020) learn the constraints passively and calibrate the acquisition with feasibility. The augmented lagrangian (AL) methods (Gramacy et al., 2016; Picheny et al., 2016; Ariafar et al., 2019) convert constrained optimization into unconstrained optimization with additional hyperparameters. The entropy-based methods (Takeno et al., 2022) optimize the lower bound of the mutual information concerning the underlying optimum within the feasible region.

In this paper, we propose a novel framework that integrates active learning for level-set estimation (AL-LSE) (Gotovos et al., 2013; Nguyen et al., 2021) with BO for constrained Bayesian optimization. Our approach leverages the theoretical advantages of both paradigms, allowing for a rigorous performance analysis of the CBO method. A brief illustration of the framework design is shown in figure 2. The subsequent sections of this paper are structured as follows. First, we formally state the CBO problem and discuss the definition of a probabilistic regret as a performance metric that enables rigorous performance analysis. Following the problem statement, we propose the novel CBO framework, offer the corresponding performance analysis, and provide empirical evidence for the efficacy of the proposed algorithm. Finally, we reflect on the key takeaways of our framework and discuss its potential implications for future work.

## 2 Problem Statement

This section introduces a few useful notations and formalizes the problem. Consider a compact search space \(^{d}\). We aim to find a maximizer \(^{*}_{}f()\) of a black-box function \(f:\), subject to \(M\) black-box constraints \(_{m}()\) (\(m=\{1,2,3,...,M\}\)) such that each constraint is satisfied by staying above its corresponding threshold \(h_{m}\).

For simplicity and without loss of generality, we let all \(h_{m}=0\). Thus, formally, our goal can be formulated as finding the _interior optimum_:

\[_{}f()_{m}( )>0, m\]

We maintain a Gaussian process (\(\)) as the surrogate model for each black-box function, pick a point \(_{t}\) at iteration \(t\) by maximizing the acquisition function \(:\), and observe the function values perturbed by additive noise: \(y_{f,t}=f(_{t})+\) and \(y_{_{m},t}=_{m}(_{t})+\), with \((0,^{2})\) being i.i.d. Gaussian noise.

The definition of reward plays an important role in analyzing online learning algorithms. Throughout the rest of the paper, we define the reward of CBO as the following and defer the detailed discussion of alternative reward choices to Appendix E.

\[r(_{t})=y_{f,t}&(y_{_{m} (_{t})} 0) m\\ -&\] (1)

We want to locate the global maximizer efficiently

\[^{*}=*{arg\,max}_{, m ,_{m}()>0}f()\]

## 3 The COBAR Algorithm

We start by introducing necessary notions from active learning for level-set estimation, followed by a detailed description of our proposed algorithm. The pseudocode and additional discussion are available in Appendix H.

### Active learning for level-set estimation

We follow the common practice and assume the objective and each unknown constraint is sampled from a corresponding independent Gaussian process (\(\)) (Hernandez-Lobato et al., 2015; Gelbart et al., 2014; Gotovos et al., 2013) to treat the epistemic uncertainty. We could derive pointwise confidence interval estimation with the \(\) for each black-box function. We define the upper confidence bound \(_{t}()_{t-1}()+_{t}^{1/2} _{t-1}()\) and lower confidence bound \(_{t}()_{t-1}()-_{t}^{1/2} _{t-1}()\), where \(_{t-1}()=k_{t-1}(,)^{1/2}\) and \(_{t}\) acts as a scaling factor corresponding to certain confidence.

For each unknown constraint \(_{m}\), we follow the notations from Gotovos et al. (2013) and define the superlevel-set to be the areas that meet the constraint \(_{m}\) with high confidence \(S_{_{m},t}\{_{ _{m},t}()>0\}\). We define the sublevel-set to be the areas that do not meet the constraint \(_{m}\) with high confidence \(L_{_{m},t}\{_{ _{m},t}()<0\}\), and the undecided set is defined as \(U_{_{m},t}\{_{ _{m},t}() 0,_{_{m},t}() 0\}\), where the points remain to be classified.

### Region of interest identification for efficient CBO

In the CBO setting, we only care about the superlevel-set \(S_{_{m},t}\) and undecided-set \(U_{_{m},t}\), where the global optimum is likely to lie in. Hence, we define the region of interest for each constraint function \(_{m}\) as \(}_{_{m},t} S_{_{m},t} U_{ _{m},t}=\{_{_{m},t} () 0\}\). Similarly, for the objective function, though there is no pre-specified threshold, we could use the maximum of \(_{f}()\) on the intersection of superlevel-set \(S_{,t}_{m}^{}S_{_{m},t}\)

\[_{f,t,}_{ S_{,t}}_{f,t}(),&S_{,t}\\ -,&\]

as the high confidence threshold for the \(_{f,t}()\) to identify a region of interest for the optimization of the objective. Given that \(_{f,t}(^{*}) f^{*} f()_{ f,t}()\) with the probability specified by the choice of \(_{t}\), we define the ROI for the objective optimization as \(}_{f,t}\{_{f,t} ()_{f,t,}\}\). By taking the intersection of the ROI of each constraint, we could identify the ROI for identifying the feasible region \(}_{,t}_{m}^{}}_{_{m},t}\). The combined ROI for CBO is determined by intersecting the ROIs of constraints and the objective:

\[}_{t}}_{f,t}}_{ ,t}\] (2)

### Combining acquisition functions for CBO

Acquisition function for optimizing the objectiveTo optimize the unknown objective \(f\) when \(}_{t}\) is established, we can employ the following acquisition function 2

\[_{f,t}()_{f,t}()- _{f,t,}&S_{,t}\\ _{f,t}()-_{f,t}()&\] (3)

At given \(t\), to efficiently optimize the black-box \(f\) we evaluate the point \(_{t}=_{}_{t}}_{f,t}( )\). Since at a given \(t\), when \(_{f,t,}\) is constant, the acquisition function is equivalent to \(_{f,t}()\).

Acquisition function for learning the constraintsWhen we merely focus on identifying the feasible region defined by a certain unknown constraint \(_{k}\), we could apply the following active learning acquisition function.

\[_{_{m},t}()_{_{m},t} ()-_{_{m},t}()\] (4)

At given \(t\), we evaluate the point \(_{t}=_{ U_{_{m},t}}_{t}}_{_{m},t}()\) to efficiently identify the feasible region defined by \(_{m}\). Note that the acquisition function \(_{_{m},t}()\) is not maximized on the full \(}_{_{m},t}\), but only on \(U_{_{m},t}}_{t}\). The active learning on the superlevel-set \(S_{_{m},t}}_{t}\) doesn't contribute to identifying the corresponding feasible region.

The COBAR acquisition criterionWith the two acquisitions discussed above and the ROIs discussed in section 3.2, we propose the algorithm \(}\)nstrained \(}\) through \(}\) Region of Interest Acquisition (COBAR). COBAR essentially picks a data point with the maximum acquisition function value across all the acquisition functions defined on different domains. The maximization of different acquisition functions allows an adaptive tradeoff between the active learning of the constraints and the Bayesian Optimization of the objective on the feasible region. The intersection of ROIs allows for efficient search space shrinking for CBO. The full procedure is detailed in algorithm 2. We also illustrate the detailed procedure on a 1D toy example in figure 3 of Appendix A.

### Theoretical Analysis

In the following, we show that we could bound the simple regret of COBAR after sufficient rounds. Concretely, in Theorem 1, we provide an upper bound on the width of the confidence interval for the global optimum \(f^{*}=f(^{*})\). We defer additional results and proofs to Appendix B3.

**Theorem 1**.: _Under the proper assumptions, with a constant \(=2(|T}{})\) and the acquisition function from \(algorithm\)\(2\), there exists an \(_{f}_{}\), such that after at most \(TC_{1}}{_{f}^{2}}\) iterations, we have \([|CI_{f^{*},T}|_{f},f^{*} CI_{f^{*},T}]  1-\) Here, \(C_{1}=8/(1+^{-2})\)._

## 4 Experiments

We empirically study the performance of COBAR against three baselines, including (1) cEI, the extension of EI into CBO from Gelbart et al. (2014), (2) cMES-IBO, a state-of-the-art information-based approach by Takeno et al. (2022), and (3) SCBO, a recent Thompson Sampling (TS) method tailored for scalable CBO from Eriksson and Poloczek (2021). The results are illustrated in figure 1. We abstain from comparison against Augmented-Lagrangian methods, following the practice of Takeno et al. (2022), as past studies have illustrated its inferior performance against sampling methods (Eriksson and Poloczek, 2021) or information-based methods (Takeno et al., 2022; Hernandez-Lobato et al., 2014). We defer the comparison against CONFIG Xu et al. (2023) to Appendix G, due to the difference in objective and a resulting instability on our benchmarks. We compare COBAR against the aforementioned baselines across six CBO tasks. The first two synthetic CBO tasks are constructed from conventional BO benchmark tasks (Balandat et al., 2020). Among the other four real-world CBO tasks, the first three are extracted from Tanabe and Ishibuchi (2020), offering a broad selection of multi-objective multi-constraints optimization tasks. The fourth one is a 32-dimensional optimization task extracted from the UCI Machine Learning repository (mis, 2019). Further details about the datasets are available in Appendix F.

## 5 Conclusion

Bayesian optimization with unknown constraints poses challenges in the adaptive tradeoff between optimizing the unknown objective and learning the constraints. We introduce COBAR, which is backed by rigorous theoretical guarantees, to efficiently address constrained Bayesian optimization. Our key insights include: (1) the ROIs determined through adaptive level-set estimation can congregate and contribute to the overall Bayesian optimization task; (2) acquisition functions based on independent GPs can be unified in a principled way. Through extensive experiments, we validate the efficacy and robustness of our proposed method across various tasks finding the interior optimum.

Figure 1: The input dimensionality, the number of constraints, and the approximate portion of the feasible region in the whole search space for each task are denoted on the titles. We run the algorithms on each task for at least 15 independent trials. The curves show the average simple regret after standardization, while the shaded area denotes the 95% confidence interval through the optimization.