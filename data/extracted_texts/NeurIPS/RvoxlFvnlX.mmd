# ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization

Huayang Huang\({}^{1}\), Yu Wu\({}^{1,}\)1, Qian Wang\({}^{2}\)

\({}^{1}\)School of Computer Science, Wuhan University

\({}^{2}\)School of Cyber Science and Engineering, Wuhan University

{hyhuang,wuyucs,qianwang}@whu.edu.cn

###### Abstract

Watermarking generative content serves as a vital tool for authentication, ownership protection, and mitigation of potential misuse. Existing watermarking methods face the challenge of balancing robustness and concealment. They empirically inject a watermark that is both invisible and robust and _passively_ achieve concealment by limiting the strength of the watermark, thus reducing the robustness. In this paper, we propose to explicitly introduce a watermark hiding process to _actively_ achieve concealment, thus allowing the embedding of stronger watermarks. To be specific, we implant a robust watermark in an intermediate diffusion state and then guide the model to hide the watermark in the final generated image. We employ an adversarial optimization algorithm to produce the optimal hiding prompt guiding signal for each watermark. The prompt embedding is optimized to minimize artifacts in the generated image, while the watermark is optimized to achieve maximum strength. The watermark can be verified by reversing the generation process. Experiments on various diffusion models demonstrate the watermark remains verifiable even under significant image tampering and shows superior invisibility compared to other state-of-the-art robust watermarking methods.

## 1 Introduction

Diffusion models (DMs) are revolutionizing content creation and generating stunningly realistic imagery across diverse domains [17; 33; 60]. The advent of text-to-image diffusion models [31; 30; 58], coupled with personalized generation techniques [53; 7; 32; 15; 41; 59], enables the creation of highly specific content by virtually anyone. However, it has raised concerns about authenticity and ownership, including the risk of plagiarism [34; 22] and the potential misuse of images of public figures [39; 5]. Consequently, governments and businesses are increasingly advocating for robust mechanisms to verify the origins of generative content [19; 45].

Watermarking offers a proactive approach to authenticate the source of generated content. This technique embeds imperceptible secret messages within the generated content. These messages serve as unique identifiers, confirming the image's origin while remaining invisible to the human eye. They also need to be robust enough to withstand potential distortions encountered during online sharing.

Existing watermarking techniques face a significant challenge in striking a balance between concealment and robustness. Traditional post-processing methods [46; 9] employ an empirical approach to identify an invisible and robust watermark and embed it within the generated image. They _passively_ achieve concealment by limiting the watermark strength, consequently compromising robustness. Conversely, stronger watermarks, while enhancing robustness, can introduce visible artifacts into the generated image. Recent advancements in in-processing watermarking for diffusion models expectthe generative model to learn this balance and directly produce watermarked content. However, these methods often require expensive model retraining [55; 48; 13] or can lead to unintended semantic alterations within the generated images .

Our ROBIN scheme introduces an explicit watermark hiding process to _actively_ achieve concealment. This approach reduces the invisibility limitation of the watermark itself and thus enables the embedding of more robust watermarks. Specifically, we implant a robust watermark within an intermediate diffusion state, and then directionally guide the model to gradually conceal the implanted watermark, thus achieving invisibility in the final generated image. In this way, robust watermarks can be secretly implanted in the generated content without model retraining.

We focus on the text-to-image diffusion models, which support an additional prompt signal to guide the generation process. We employ an adversarial optimization algorithm to design an optimal prompt guidance signal specifically tailored for each watermark. **The prompt embedding is optimized to minimize artifacts in the generated image, and the watermark is optimized to achieve maximum strength.** The optimized watermark and prompt signal are universally applicable to all images. During the generation process, the watermark is implanted within an intermediate state following the semantic formation stage. Subsequently, the optimized prompt guidance signal is introduced throughout the remaining diffusion steps. After image generation, following previous works [44; 49], we reverse the diffusion process to the watermark embedding point to verify the existence of the watermark. This innovative approach offers a promising way to overcome the trade-off between watermark strength and stealth by explicitly introducing an additional watermark hiding process.

In summary, our key contributions are as follows:

* We propose a novel watermarking method for diffusion models that embed a robust watermark and subsequently employ an active hiding process to achieve imperceptibility.
* We develop an adversarial optimization algorithm to generate a prompt signal for watermark hiding and a strong watermark that can be hidden and strategically select the watermarking point within the diffusion trajectory.
* Evaluations on both latent and image diffusion models demonstrate that our scheme exhibits superior robustness against various image manipulations while preserving semantic content.

## 2 Related work

Diffusion generation and inversion.Diffusion models [17; 12; 36; 37] operate by iteratively transforming pure noise \(x_{T}(0,)\) into increasingly realistic images \(x_{0} q(x)\) through \(T\) steps of denoising. The learning process involves a stochastic Markov chain in two directions. The forward process diffuses the sample \(x_{0}\) by adding random noise:

\[q(x_{t}|x_{t-1})=(\!}x_{t-1},_{t}),\] (1)

where \(\{_{t}\}_{t=1}^{T}\) is the scheduled variance. \(x_{t}\) can also be generated from \(x_{0}\) as:

\[x_{t}= _{t}}x_{0}+\!_{t}},\] (2)

where \(_{t}=_{t=1}^{T}(1-_{t})\) and \((0,)\). Then a network \(_{}\) is learned to predict the noise in each step, following the objective:

\[_{}\!E_{x_{0},t(1,T),( 0,)}\|-_{}(x_{t},t,(p))\|_{2}^ {2},\] (3)

where \(x_{t}\) is the noise latent at timesteps \(t\) and \((p)\) is the embedding of the text prompt \(p\).

DDIM (Denoising Diffusion Implicit Model)  introduces the ODE solver for deterministic sampling by constructing the original one as a non-Markov process. It computes the \(x_{t-1}\) from \(x_{t}\) by predicting the estimation of \(x_{0}\) and the direction pointing to \(x_{t}\):

\[x_{0}^{}=-_{t}}_{}(x_{t},t, (p))}{_{t}}},\] (4)\[x_{t-1}=_{t-1}}x_{0}^{}+_{t-1}}_ {}(x_{t},t,(p)).\] (5)

The deterministic generation properties of DDIM allow it to reconstruct the noise latent \(_{t}\) from the final image \(x_{0}\) as :

\[_{t}= _{t}}x_{0}+_{t}}_{ }(x_{t-1},t-1).\] (6)

This unique characteristic allows us to selectively mark and recover an inner noise representation within the diffusion process, which serves as a powerful tool for our watermarking approach.

Watermarking generative models. The content watermark of generative models can be introduced either after the generation (post-processing) or during the sampling process (in-processing). Post-processing methods can adopt traditional digital image watermarking technology. Popular methods include frequency domain watermarking, which modifies the image representation in domains like Discrete Wavelet Transform (DWT)  or Discrete Cosine Transform (DCT) . DwtDct watermarking  is applied in open sourced model Stable Diffusion. Frequency domain watermarks can be designed to be robust against common image manipulations like cropping, scaling, and even compression . HiDDeN  pioneered the end-to-end approach, utilizing an encoder-decoder architecture to directly generate watermarked images. RivaGAN  leverages adversarial training to incorporate perturbations and image processing during model training for increased robustness.

In-processing methods make the watermark become part of the generated image by interfering with the generation process. Early approaches explored adding watermarks to training data , essentially building a watermark encoder into the model. Stable Signature  simplified this process by fine-tuning only the external decoder of latent diffusion models. However, these methods all treated watermarking as a separate goal from the generation task, limiting their flexibility. The recent Tree-Ring watermarking  shares similarities with our approach, modifying the initial noise to encode information semantically within the image. However, the semantic modifications induced by Tree-Ring watermarks are random and may compromise the faithfulness of the original model. Therefore, we aim to preserve the original semantics exactly to guarantee a similar level of text alignment compared to the original generation. Our work shows that embedding the watermark within the intermediate diffusion state and guiding the model to hide it can achieve the secret embedding of strong watermarks without model retraining.

## 3 Methodology

### Overview of ROBIN

Task definition.Diffusion model watermarking aims to embed an invisible and verifiable watermark \(w_{i}\) within the generated image \(x_{0}\), using a watermark implantation function \(I\). During Internet transmission, the generated content may be subjected to various image transformation operations \(\). The model owner aims to leverage a watermark extraction algorithm \(E\) to verify the presence of \(w_{i}\) within the distorted sample \((x_{0})\), thereby establishing image ownership.

Pipeline of ROBIN._Watermark generation._ We first generate a hiding prompt guidance signal \(w_{p}\) for each watermark \(w_{i}\) using the adversarial optimization algorithm, which is detailed in Section 3.2.

Watermark implantation.ROBIN implants \(w_{i}\) into an intermediate generation state \(x_{t}\) after the semantics have been formed as

\[x_{t}^{*}=I(x_{t},w_{i},),\] (7)

where \(I\) injects \(w_{i}\) into the frequency domain of \(x_{t}\) and \(\) is the coverage area of the watermark. During the remaining DDIM generation, ROBIN incorporates the optimized prompt guidance signal \(w_{p}\) to direct the model towards hiding the watermark \(w_{i}\) to maintain the similarity between the generated image \(x_{0}^{*}\) and its unwatermarked counterpart \(x_{0}\). Let \(_{}\) be the watermark injection point, the generation of the watermarked image is as follows:

\[p_{}^{(t)}(x_{t-1}|x_{t})=_{t-1}}x_{0}^{ }+_{t-1}}_{}(x_{t},t,(p))&T t>_{}\\ _{t-1}}x_{0}^{*}+_{t-1}}_ {}(x_{t}^{*},t,(p),w_{p})&t_{} t\] (8)After embedding the watermark, the model is guided by both the original input text prompt \(p\) and the optimized prompt embedding \(w_{p}\) to achieve reliable generation with the watermark hidden. The predicted noise then becomes

\[_{}(x_{t}^{*},t,(p),w_{p}) =_{1}_{}(x_{t}^{*},t,(p))+_{2} _{}(x_{t}^{*},t,w_{p})\] (9) \[+(1-_{1}-_{2})_{}(x_{t}^{*},t, ()),\] (10)

where \(_{1},_{2}\) are the guidance scale parameters to weight the guidance of the original text prompt and the optimized prompt signal.

_Watermark verification._ To verify the watermark, we reverse the transformed watermarked image \((x_{0}^{*})\) to step \(t_{}\) and retrieve the intermediate state \(_{t}^{*}\). The watermark information \(w^{}=E(_{t}^{*},)\) is extracted from the frequency space of \(_{t}^{*}\). L1 distance \(D\) is used to measure the similarity between \(w\) and \(w^{}\). When the distance falls below a threshold as

\[D(w,w^{})=|}_{i}|w_{i}-w_{i}^{ }|,\] (11)

the presence of the watermark within the image is confirmed. Figure 1 presents the watermark generation and implantation process of ROBIN.

### Adversarial optimization algorithm

We employ an adversarial optimization algorithm to generate the watermark and the corresponding hiding prompt guidance signal. The prompt signal is optimized in the embedding space and guides the model to conceal the embedded image watermark, while the watermark tries to be as strong as possible while allowing for its targeted hiding by the prompt signal.

The objective of the prompt guiding signal is to minimize the impact of the watermark on the final generated image. We define the image retaining loss \(l_{ret}\), which penalizes excessive deviations from the original images:

\[_{ret}=(x_{0}^{*}-x_{0}),\] (12) \[x_{0}^{*}=^{*}-_{t}} _{}(x_{t}^{*},t,(p),w_{p})}{_{t}}}.\] (13)

Figure 1: The watermark optimization and implantation of ROBIN. A robust watermark is added at an intermediate state of generation, and an additional prompt guiding signal is optimized to direct the model towards hiding the embedded watermark in the generated image. The image watermark and guiding signal are optimized adversarially to improve robustness and invisibility.

\(x_{0}^{*}\) is the final image predicted from the watermarked noisy latent \(x_{t}^{*}\) through Equation (4) with an additional guidance \(w_{p}\). MSE denotes the mean squared error.

Furthermore, as the loss incurred during DDIM inversion increases proportionally with the guidance strength , we introduce a constraint term \(l_{cons}\) to prevent excessive prompt guidance:

\[_{cons}=(_{}(x_{t}^{*},t,w_{p})-_{} (x_{t}^{*},t,())).\] (14)

To achieve robustness, we embed the watermark in the frequency domain of the image . Frequency domain signals are more resistant to spatial operations compared to spatial domain signals . Similar to , we set the watermark as multiple concentric rings, but we further optimize its value to the maximum within the aforementioned constraints for greater strength and better robustness. The optimization losses of \(w_{p}\) and \(w_{i}\) become

\[_{w_{p}} =_{ret}+_{cons},\] (15) \[_{w_{i}} =_{ret}+_{cons}-\|w_{i}\|.\] (16)

Since the watermark and the prompt guiding signal are interdependent, we employ an alternating optimization method, in which we iteratively optimize one while fixing the other. More details about the watermark design and optimization algorithm are presented in Appendix A.

### Finding keypoints for implantation

The selection of the optimal stage for watermark embedding within the diffusion process is crucial for achieving both high image fidelity and semantic consistency with the input text prompt. We delve into the sensitivity of the predicted noise to frequency domain disturbances in different diffusion steps. According to classifier-free guidance method , the predicted noise in each step can be depicted as \(Full=Uncondition+s(Condition-Uncondition)\). Condition and Uncondition are predicted noise with and without text conditions. Parameter \(s\) is the scaling factor and the second term of the addition is called Guidance. Full noise is the final noise to be removed in the current step.

Figure 2(a) shows the evolution of mean values of various predicted noise terms throughout the generation process. We can find that after step 300, the slowdown in guidance rise indicates the completion of basic semantic formation and diminishing guidance influence. Additionally, Figure 2(b) presents how the predicted noise changes when perturbations are added at different timesteps. When the timestep is greater than 200, the frequency domain noise interferes with the generation process mainly by disrupting the guidance term. After 200 steps, the intrinsic unconditional term is more affected. We can conclude that early generation stages establish the foundation for image semantics and excessive intervention at this point can disrupt the intended image content. Conversely,

Figure 2: The impact of introducing frequency domain disturbances at different diffusion steps on the predicted noise. Timestep 1000 signifies the Gaussian noise state and step 0 represents the final generated image. The Uncondition curve (orange) and the Condition curve (gray) nearly overlap in both figures. Guidance is the amplified difference of Uncondition and Condition. Full is the addition of Uncondition and Guidance.

manipulating the final stages, dedicated to refining image details, may impede the model's capacity to recover from watermark-induced noise, ultimately compromising the final image quality.

Therefore, we strategically choose the watermark insertion point between steps 300 and 200. This stage offers the sweet spot: frequency perturbations have minimal impact on the mean of the predicted noise, allowing for watermark integration without sacrificing image quality and disruption to the core semantics.

### Watermark validation

In the watermark verification phase, we reverse the diffusion process to get the state \(_{t}^{*}\) at the watermark injection step. We extract the \(\) region of \(_{t}^{*}\) Fourier space and calculate its L1 distance from the implanted watermark \(w_{i}\). However, the original prompt used for image generation is unknown during verification of online images. Similar to , we use the null-text prompt as the condition text embedding and set the guidance scale to 1.0. We also found unexpectedly that introducing the optimized prompt signal during inversion hinders the watermark recovery, which we aim to explore in future work. Our watermark verification requires a reversible generation process, making it compatible with any reversible samplers such as DPM-Solver , DPM-Solver++ , PNDM , and AMED-Solver .

## 4 Experiments

### Experimental setting

Model and dataset.We conducted experiments on two distinct diffusion models operating in latent and image domains. For the latent diffusion model, we utilize the widely available Stable Diffusion-v2  and the stable-diffusion-prompts dataset from Gustavosta . We also test on a guided diffusion model  trained on the ImageNet , which operates directly on the pixel domain and can generate images of size \(256 256\) based on the category provided.

Evaluation metrics.To assess the effectiveness of ROBIN, we compute the Area Under the ROC Curve (AUC-ROC) based on the L1 distance to measure the effectiveness of watermark verification. Specifically, we compute AUC using 1,000 watermarked and 1,000 clean images. For the quality of watermarked images, we employ a suite of diverse metrics. We utilize classic measures like PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index), and MSSIM (Multiscale SSIM)  to quantify the pixel-level differences between watermarked and original images. We employ the Frechet Inception Distance (FID)  to evaluate the fidelity of the watermarked image distribution. We also leverage the CLIP score  to measure the alignment between generated images and their corresponding text prompts. More details are provided in Appendix B.1.

Implementation details.We utilize 50 steps of deterministic sampling for both models. Stable Diffusion employs the second-order multistep DPM-Solver algorithm  with a default guidance scale of 7.5. ImageNet diffusion model leverages the DDIM sampling algorithm . We optimize the watermark and the hiding prompt using 50 generated images. The learning rates for the image watermark and prompt guidance are 0.8 and 5e-04, respectively, with a total of 1,000 optimization rounds. The default image watermark covers 70% of the image frequency domain. All experiments are conducted on an NVIDIA GeForce RTX 3090 GPU.

### Effectiveness and robustness

We compare our method with five baselines: DwtDct , DwtDctSvd , RivaGAN , Stable Signature , and Tree-Ring watermarks . To ensure the watermark's resilience in real-world scenarios, we delve into its robustness under various image transformations. These include Gaussian blur with radius 4, Gaussian noise with intensity 10%, jpeg compression with quality 25, color jitter with brightness 6, random rotation of 75 degrees, and random cropping of 75% and rescaling. These settings are strict for watermark verification because the image has been significantly altered. ROBIN is also evaluated under a combination of attacks where we randomly selected various combination of the six transformations. The processed samples are shown in Figure 6 in the Appendix.

[MISSING_PAGE_FAIL:7]

watermark": seamlessly embedding the watermark within the image content without altering its semantics. Due to this fundamental shift in watermarking philosophy, we only compare the image quality with Tree-Ring watermarks.

The Tree-Ring approach aims to find another watermarked image that aligns with the text prompt, even if it differs from the original image. However, it is more akin to random semantic modifications and does not guarantee the same level of text alignment as the original generation. Figure 3 shows that the Tree-Ring approach significantly alters the generated image's semantics, sometimes even failing to fulfill the text prompt's intent. This occurs because it disrupts the essential Gaussian characteristics of the initial noise, hindering the generation process. In contrast, ROBIN excels at preserving the overall image content and semantic structure, providing a better lower bound for faithfulness by preserving the original semantics. Table 4 provides the quantitative results. ROBIN demonstrates significant improvements in PSNR, SSIM, MSSSIM, and CLIP score, while a slight increase in FID is observed. This is because the position of the watermark implanted in our scheme is at a later stage of generation, resulting in a slightly greater influence on the overall generation distribution. This implies a negligible trade-off for achieving a strong watermark with minimal degradation of the overall quality of the generated image.

   Model & Method & PSNR \(\) & SSIM \(\) & MSSIM \(\) & CLIP \(\) & FID \(\) \\   & W/o watermark & \(\) & \(1.000\) & \(1.000\) & \(0.403\) & \(25.53\) \\  & Tree-Ring  & \(15.37_{}\) & \(0.568_{}\) & \(0.626_{}\) & \(0.364_{}\) & \(}}\) \\  & ROBIN & \(}}\) & \(}}\) & \(}}\) & \(}}\) & \(26.86_{}\) \\   & W/o watermark & \(\) & \(1.000\) & \(1.000\) & \(0.271\) & \(16.25\) \\  & Tree-Ring  & \(15.68_{}\) & \(0.663_{}\) & \(0.607_{}\) & \(0.267_{}\) & \(}}\) \\   & ROBIN & \(}}\) & \(}}\) & \(}}\) & \(}}\) & \(18.26_{}\) \\   

Table 4: Quality of generated images. PSNR, SSIM and MSSIM measure the similarity between the watermarked and unwatermarked images. CLIP evaluates how well the watermarked image aligns with the user-provided textual description. FID measures the distribution similarity between the watermarked dataset and a random dataset of real images. The subscripts indicate the standard deviation of five independent experimental runs, each initialized with a different random seed.

Figure 3: The generated images with Tree-Ring and ROBIN watermarks.

### Ablation study

To gain further insights into the effectiveness of ROBIN, we conduct an ablation study, exploring the influence of different design choices. We additionally introduce the Mean Squared Error of Watermark (MSE) to represent the verification accuracy in some settings where the AUC is always equal to 1. It is calculated as the mean of L1 distance between the extracted and original watermark.

Setting variations.To explore the individual contributions of various components in our scheme, we conduct a series of experiments presented in Table 5. Experiments in Settings 1 and 2 demonstrate that the introduction of prompt-based watermark hiding signals improves image quality, as evidenced by a 1.6 increase in PSNR and a 1.44 decrease in FID score compared to Setting 1. Setting 3 emphasizes the importance of the \(_{ret}\) in controlling watermark strength. Without \(_{ret}\), ROBIN prioritizes creating a highly robust watermark, leading to significant image distortion (PSNR: 18.95, SSIM: 0.48). Setting 4 presents that removing \(_{cons}\) allows for stronger prompt guidance, but this results in increased DDIM inversion loss and a decrease of 0.13 in adversarial AUC. Setting 5 prioritizes minimal impact on the generated image by weakening the watermark. This approach leads to poorer watermark robustness and a decrease of 0.017 in adversarial AUC. Experiments under Settings 2 and 6 demonstrate that in the presence of the hiding prompt signal, the image watermark can be optimized to achieve stronger robustness while maintaining invisibility.

Point of implantation.We evaluate the impact of implanting the watermark at different stages in the diffusion process. The results are presented in Figure 4. Watermark verification accuracy improves with later implantation due to fewer DDIM inversion steps and reduced information loss. Early implantation, while initially maintaining image quality (low FID), can significantly change the image content (low SSIM/PSNR) by disrupting semantic formation. Conversely, late implantation may leave the watermark visible due to insufficient space for hiding, leading to high FID and deviation from the original image (low SSIM). This empowers us to pinpoint the optimal embedding stage (steps 15-10) for balancing visual quality and semantic preservation.

Watermark strength.We also verify the influence of different watermarking strengths and the results are shown in Figure 4. Higher watermark strength (proportional coverage in the frequency domain) generally benefits verification accuracy, as the watermark becomes more prominent. The CLIP score and FID remain stable due to strategic embedding and guided hiding. Traditional metrics (SSIM, PSNR) decrease with stronger watermarks due to increased content modification. The watermarked images under different strengths are shown in Figure 5. Compared to Tree-Ring, the quality of generated images with ROBIN watermarks is less sensitive to watermark strength. More qualitative results are presented in Appendix C.5.

## 5 Conclusion & Discussion

This paper proposes a novel watermarking method for the diffusion model, which embeds a watermark in the intermediate diffusion state and guides the model to conceal the watermark. By explicitly introducing the active hiding process, we can implant stronger watermarks without compromising image quality. We believe this method holds promise for expanding the possibilities of reliable watermarking in diffusion models.

    &  &  &  &  \\  & Image \(w_{i}\) & Prompt \(w_{p}\) & \(_{ret}\) & \(_{cons}\) & \(\|w_{i}\|\) & Clean & Adversarial & PSNR \(\) & SSIM\(\) & CLIP\(\) & FID\(\) \\  (1) & Random & None & & & 1.00 & 0.903 & 20.11 & 0.68 & 0.39 & 29.21 \\ (2) & Random & Optimized & ✓ & ✓ & & 1.00 & 0.901 & 21.70 & 0.70 & 0.39 & 27.77 \\  (3) & Optimized & Optimized & & & ✓ & ✓ & 1.00 & 0.988 & 18.95 & 0.48 & 0.30 & 32.18 \\ (4) & Optimized & Optimized & ✓ & & ✓ & 1.00 & 0.970 & 23.91 & 0.76 & 0.40 & 26.68 \\ (5) & Optimized & ✓ & ✓ & & 1.00 & 0.966 & 24.19 & 0.77 & 0.40 & 26.93 \\  (6) & Optimized & Optimized & ✓ & ✓ & ✓ & 1.00 & 0.983 & 24.03 & 0.77 & 0.40 & 26.86 \\   

Table 5: Watermark accuracy and image quality under different settings. (1) random watermarks \(w_{i}\), (2) random watermarks with prompt signal \(w_{p}\) for hiding, (3)-(5) different loss functions for optimizing \(w_{i}\) and \(w_{p}\), (6) full loss function for optimizing both \(w_{i}\) and \(w_{p}\).

Limitations.The verification of ROBIN watermarks relies on the reversible generation process, future advancements enabling the reversibility of other sampling algorithms would broaden the application of our method. Additionally, the inherent information loss during DDIM inversion can be reduced by exploring generative trajectories that can be reversed exactly .

Social impact.Our ROBIN scheme, as a watermarking method, can help creators establish ownership and discourage unauthorized use. Furthermore, ROBIN watermarks can be implanted in a one-shot manner without retraining the whole model, making it applicable to different diffusion-based text-to-image models.