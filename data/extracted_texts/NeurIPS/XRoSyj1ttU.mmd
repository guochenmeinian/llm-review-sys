# EchoQA: A Large Collection of Instruction Tuning

Data for Echocardiogram Reports

 Lama Moukheiber

Massachusetts Institute of Technology

&Mira Moukheiber

Massachusetts Institute of Technology

&Dana Moukheiber

Massachusetts Institute of Technology

&Jae-Woo Ju

Seoul National University

&Hyung-Chul Lee

Seoul National University

Equal contribution.

###### Abstract

We introduce a novel question-answering (QA) dataset using echocardiogram reports sourced from the Medical Information Mart for Intensive Care database. This dataset is specifically designed to enhance QA systems in cardiology, consisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities and their severity. We compare large language models (LLMs), including open-source and biomedical-specific models for zero-shot evaluation, and closed-source models for zero-shot and three-shot evaluation. Our results show that fine-tuning LLMs improves performance across various QA metrics, validating the value of our dataset. Clinicians also qualitatively evaluate the best-performing model to assess the LLM responses for correctness. Further, we conduct fine-grained fairness audits to assess the bias-performance trade-off of LLMs across various social determinants of health. Our objective is to propel the field forward by establishing a benchmark for LLM AI agents aimed at supporting clinicians with cardiac differential diagnoses, thereby reducing the documentation burden that contributes to clinician burnout and enabling healthcare professionals to focus more on patient care.

## 1 Introduction

Echocardiography is the most prevalent noninvasive technique for assessing heart function and detecting heart diseases. It plays a critical role in clinical cardiology, consistently guiding decision-making processes . Echocardiography is essential for diagnosing diseases, stratifying risks, and evaluating treatment efficacy. The diagnostic reports generated from these tests provide rich clinical data, vital for diagnosing and managing various cardiac conditions . The growing demand for diagnostic echocardiograms makes it difficult to manage and interpret the increasing volume of data, and utilizing AI-powered algorithms can reduce clinician workload.

The advent of large language models (LLMs) holds the potential to transform the field of cardiology. LLMs have been utilized across various natural language processing tasks, such as question-answering (QA), text summarization, and language translation, often in zero-shot and few-shot scenarios . In-context learning (ICL) enables the models to tackle new tasks with only a few task demonstrations, like in three-shot prompting, without the need to update model parameters . Moreover, transforming tasks related to understanding and generating natural language into clear instructions enhances theability of LLMs to follow domain-specific directives and improve their performance on downstream tasks[5; 6]. Open-source models like Llama  and Mistral  have demonstrated significant potential in this area.

There is a gap in developing large language models (LLMs) that are trained and evaluated on real-world medical data, such as echocardiogram reports with ground-truth answers, which stems from the reliance on synthetic data or data from medical licensing exams [9; 10]. This limitation has hindered progress of AI in the cardiology space. However, with the recent advancements in instruction-tuning capabilities of LLMs, there is now an opportunity to leverage real-world clinical datasets to create more accurate and context-aware models, addressing the specific needs of cardiologists in their diagnostic workflows[11; 12]. Tasks that cardiologists perform while interacting with patients--such as generating differential diagnoses on their computers from various clinical sources like laboratory results or echocardiographic imaging data--can now be streamlined, reducing the burden of documentation[13; 14; 15; 16; 17], improving clinician job satisfaction and allowing clinicians to focus more on patient care[19; 20; 21].

Furthermore, addressing algorithmic bias is crucial in healthcare before model deployment. Most studies have incorporated protective attributes, such as race, gender, and age, for fairness auditing of healthcare algorithms [22; 23]. Beyond these common attributes, analyzing social determinants of health could assist in mitigating disparities in patient care[24; 25; 26]. Furthermore, incorporating social determinants into fairness audits could help assist with regulations like Section 1557 of the Affordable Care Act, which mandates that healthcare providers and payers ensure their algorithms do not discriminate . Moreover, social determinants of health can help clinicians provide more individualized diagnoses in cardiac care by considering the broader context of patients' living conditions and lifestyle factors.

Based on the challenges aforementioned, our work makes the following three contributions:

* _Development of EchoQA:_ We present EchoQA, the largest open-access, real-world patient question-answering dataset for echocardiography, meticulously developed by expert clinicians. Our aim is to propel the medical field by creating a foundation for training LLM-based AI agents that will assist cardiologists in their daily workflows. EchoQA also provides researchers and practitioners with the opportunity to test and compare different machine learning approaches for differential diagnosis.
* _Zero-shot, Few-shot and Instruction Fine-Tuning Evaluations:_ Leveraging the EchoQA dataset, we validate its utility by fine-tuning a variety of LLMs, encompassing both general-purpose and medical-domain models, and comparing their performance to zero-shot setups. Additionally, for comparison we conduct zero-shot and three-shot evaluations on commercial LLMs. Furthermore, we release the best-performing echocardiogram model, _Echo-Mistral_, making it accessible to the wider research community.
* _Fairness Audits on Social Determinants of Health:_ To investigate algorithmic bias, we use social determinants of health to enable more fine-grained audits of algorithmic fairness. These evaluations provide critical insights into potential disparities often overlooked in LLM studies, promoting health equity.

## 2 Related Work

**Medical question answering datasets.** Medical question-answering benchmark datasets have been developed to address different aspects of medical information retrieval and understanding. Examples include datasets designed for medical licensing exams and conceptual medical knowledge, such as MedQA, JAMA Clinical Challenge, MedBullet, and MMLU Clinical Topics [9; 28; 29]. Additionally, literature-based QA datasets, such as PubMedQA, consist of biomedical research questions derived from PubMed abstracts . On the other hand, datasets like HealthSearchQA, LiveQA, and MedicationQA provide insights into medical information needs from a consumer perspective [31; 32; 33]. More specifically, MedicationQA addresses questions related to medications and their uses, aiding in pharmaceutical information retrieval . QA datasets utilizing real-world medical data from electronic health records include emrQA, which consists of factual questions with answers derived from discharge summary reports in the i2b2 dataset . Similarly, RadQA consists if radiology-related questions commonly encountered in clinical practice, using data extracted from radiology reports in the MIMIC database . However, none of these datasets include questionsa echocardiogram reports, which differ significantly in semantic content and vocabulary. Table 2 provides a summary of the medical QA datasets described above.

**LLM and echocardiography.** There is limited research on the use of large language models (LLMs) specifically within cardiology. One work introduced EchoGPT, a fine-tuned Llama-2 model  employing Quantized Low-Rank Adaptation (QLoRA) to assist with echocardiography report summarization and initial drafting of reports for clinician review, effectively streamlining the reporting workflow . Further, prior studies indicate that general-purpose LLMs, such as ChatGPT, struggle with echocardiography board review questions, highlighting the need for specialized training to enhance performance in cardiology applications . However, these efforts do not establish a framework for assisting clinicians in the differential diagnosis of cardiac abnormalities.

**Fairness audits.** While progress has been made in addressing algorithmic fairness in healthcare, most studies have focused primarily on biases related to protected attributes such as age, gender, and race [22; 38]. Recent research emphasizes the need to examine biases from multidimensional perspectives, evaluating fairness through the intersectionality of social determinants and social identities to provide a deeper understanding beyond the socially constructed nature of attributes like race and gender [26; 39]. Studies have also incorporated social determinants of health offering insights into the processes driving disparities in machine learning models [25; 40]. We leverage social determinants of health to conduct fine-grained audits of algorithmic fairness on general, biomedical, and closed-source LLMs for cardiac diagnostic support. With that, we hope to account for the broader context of individuals' lives focusing on the conditions in which people are born, grow, live, work, and age, as well as the broader social, economic, and environmental factors that influence health, ultimately assisting clinicians in making more informed and personalized decisions in cardiac diagnosis for individual patients.

## 3 Experimental Setup

### Dataset

We curate a question-answering dataset sourced from the Medical Information Mart for Intensive Care (MIMIC-IV) database, a de-identified clinical dataset comprising over 80,000 echocardiogram reports collected at Beth Israel Deaconess Medical Center between 2012-2019 , providing a rich resource that can support differential diagnosis and enhance diagnostic decision-making for cardiac abnormalities.

The echocardiogram reports include details on specific heart structures, such as the left atrium, right atrium/interatrial septum, left ventricle, right ventricle, mitral valve, aortic valve, and tricuspid valve. Each patient's echocardiography report is processed to extract unique sentences for each heart structure. Following , clinical experts identify diverse abnormalities described in the sentences extracted for each heart structure, and assign levels ranging from -3 to 3 for each identified abnormality. These levels are based on standardized diagnostic criteria established by the American Society of Echocardiography[43; 44; 45], indicating both the category and severity level of the abnormality. A category of -3 indicates that the study is inadequate for evaluating the cardiac abnormality. A category

 
**Dataset** & **Domain** & **QA Type** & **Real-world** \\  & & & **medical data** \\  MedQA  & Medical Board Exams (USMLE) & Multiple choice & \\  JAMA Clinical Challenge  & Exam for clinical cases (JAMACC) & Multiple choice & \\  MedBullet  & Medical Board Exams (USMLE) & Multiple choice & \\  MMLU Clinical Topics  & Medicine and biology-related topics & Multiple choice & \\  PubMedQA  & Literature-based (PubMed abstracts) & Multiple choice & \\  HealthSEARCHQA  & Consumer searched questions & Long-form & ✓ \\  LiveQA  & Consumer health & Long-form & ✓ \\  MedicationQA  & Consumer questions about medications & Long-form & ✓ \\  emrQA  & Discharge reports (i2b2 data) & Long-form & ✓ \\  RadQA  & Radiology reports (MIMIC data) & Long-form & ✓ \\ 
**EchoQA (Ours)** & Echocardiography reports (MIMIC data) & Long-form & ✓ \\  

Table 1: Overview of medical Question-Answering (QA) datasets by domain, QA type, and use of real-world data. QA types include Multiple Choice (predefined answers) and Long-form (free-text responses).

of 0 is used when the study is adequate for evaluating cardiac function but reveals no abnormalities. Sentences describing abnormal function without specifying severity are assigned a category of -2. Severity levels are categorized as 1 for mild, 2 for moderate, and 3 for severe. For specific features, such as left ventricular cavity size, left ventricular systolic function, and right ventricular cavity size, a category of -1 indicates hyperdynamic left ventricular systolic function or a small cavity size for the left or right ventricle.

The sentences in the patient's notes are then matched with the sentences categorized for each abnormality to enable the assignment of an abnormality category level for each patient. When multiple sentences for the same abnormality in the patient's notes match different severity levels--mild, moderate, or severe--the highest category level is retained to prioritize the most clinically significant finding. In cases where conflicting category levels derived from sentences in the patient's notes are identified for the same abnormality, a placeholder value of -50 is assigned to indicate ambiguity or disagreement in the abnormality categorization. As illustrated in Figure 2, using these categories, diagnostic questions, such as "Is the study adequate to assess left ventricular systolic dysfunction?" are generated. The answers to these questions are derived directly from the sentences categorized for each cardiac abnormality, resulting in more than 700,000 question-answer pairs, with the categories depicted in Table 2.

This data curation incorporates clinical expertise to establish relevant cardiac diagnostic questions and build cardiac abnormality categorizations from patients' echocardiogram notes, while addressing potential errors in medical documentation to ensure accurate answers for individualized cardiac differential diagnosis. Hence, it establishes a gold standard, enhancing the instruction-following capabilities of large language models in the differential diagnosis of cardiac abnormalities, supporting clinical decision-making, alleviating clinician burnout from documentation, and enabling more physician-patient interaction. The question-answering dataset will be hosted on PhysioNet, an NIH-funded health data repository . Figure 1 illustrates the curation, validation, and auditing process of the instruction-tuned dataset.

### Model Inference & Training

To validate the value of the training data, we employ supervised fine-tuning (SFT) on a diverse selection of recent open-source and biomedical domain-specific large language models (LLMs) and compare their performance against zero-shot setups. Additionally, we evaluate closed-source models in zero-shot and three-shot setups, exploring the potential for three-shot configurations to sustainably improve the performance of closed-source LLMs. For open-source general models, we utilize Llama-3-8B , Mistral-7B , Phi-3-mini , Zephyr-7B , and Falcon-7B . In the biomedical domain, we leverage specialized open-source models such as BioMistral-7B,

Figure 1: Workflow of the methodology.

M42-health , PMC-LLaMa-13B , and Meditron-7B , which are designed to understand biomedical terminology and context derived from medical abstracts and texts. Additionally, we include proprietary models, such as Amazon-titan , Claude , Cohere , and GPT-4o , which are designed to understand biomedical terminology and context derived from medical abstracts and texts. Additionally, we include proprietary models, such as Amazon-titan , Claude , Cohere , and GPT-4o , which are designed to understand biomedical terminology and context derived from medical abstracts and texts.

  
**Cardiac Abnormalities** & **Number of QA’s** \\ 
**Right atrial abnormalities** & \\ Right atrial enlargement & 45,254 \\ Right atrial pressure & 2,371 \\ 
**Tricuspid valve abnormalities** & \\ Tricuspid valve regurgitation & 13,332 \\ Tricuspid valve stenosis & 19,509 \\ Pulmonary hypertension & 21,376 \\ 
**Right ventricular abnormalities** & \\ Right ventricular systolic function & 74,236 \\ Right ventricular cavity & 71,971 \\ Right ventricular volume overload & 5,075 \\ Right ventricular pressure overload & 5,065 \\ Right ventricular wall & 7,316 \\ 
**Left atrial abnormalities** & \\ Left atrium cavity & 14,425 \\ 
**Mitral valve abnormalities** & \\ Mitral valve stenosis & 38,044 \\ Mitral valve regurgitation & 53,205 \\ 
**Left ventricular abnormalities** & \\ Left ventricular systolic function & 64,305 \\ Left ventricular cavity & 64,354 \\ Left ventricular wall & 64,295 \\ Left ventricular diastolic function & 5,769 \\ Left ventricular outflow tract obstruction & 40,697 \\ Left regional wall motion abnormality & 39,310 \\ 
**Aortic valve abnormalities** & \\ Aortic valve stenosis & 61,451 \\ Aortic valve regurgitation & 59,884 \\ 
**Total** & **771,244** \\   

Table 2: Cardiac abnormalities found in the echocardiogram reports.

Figure 2: Categorization of cardiac abnormalities. X represents a specific cardiac abnormality. a) The schema includes the following cardiac abnormalities: right atrial pressure; tricuspid valve regurgitation, tricuspid valve stenosis, and pulmonary hypertension; right ventricular systolic function, right ventricular cavity, and right ventricular wall; left atrial cavity; mitral valve regurgitation and mitral valve stenosis; left ventricular systolic function, left ventricular cavity, left ventricular wall, left ventricular diastolic function, left ventricular outflow tract obstruction, and left regional wall motion abnormality; and aortic valve regurgitation and aortic valve stenosis. b) The schema includes other right ventricular and atrial abnormalities: right ventricular pressure overload and right ventricular volume overload; and right atrial enlargement.

to provide a comprehensive comparison across different model types and domains. The closed-source models are deployed on Azure OpenAI  and Amazon Bedrock to ensure HIPAA compliance.

Due to computational limitations, we sample 10,000 subjects and divide the data into a 70% training set, a 10% validation set, and a 20% testing set, ensuring that the data for each subject is contained in only one set. The training set is used for fine-tuning the model, while the testing set is used for inference. Both training and inference datasets are processed and tokenized, and the model is configured with dynamic token embedding resizing to accommodate task-specific tokens effectively. The prompts used for zero-shot and three-shot questions answering are shown in Figure 6 and Figure 7 in the Appendix.

For supervised fine-tuning, we train the models for one epoch with a learning rate of 2e-4, using a cosine learning rate schedule with a 1% warm-up ratio to stabilize the initial training phase. Training is performed using the AdamW optimizer, utilizing gradient accumulation steps of 4 to simulate larger batch sizes and optimize memory usage. To enhance training efficiency, we employ Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. This includes setting the scaling factor (LoRA alpha) to 16 to control the influence of task-specific adaptations, applying a 10% dropout rate to prevent overfitting, and using a rank of 64 to enable task-specific adaptation with minimal additional parameters. Additionally, we employ the BitsAndBytes quantization technique with Normal Float 4 (NF4) for numerical stability and Brain Floating Point 16-bit (bfloat16) for faster computations. Fine-tuning is conducted on NVIDIA A100 80GB GPUs, utilizing model sharding to efficiently distribute computational resources.

### Automated Model Evaluation of LLM Responses

We conduct a comprehensive analysis of our model's performance using quantitative metrics. We employ BLEU score, to measure the precision of n-grams between the generated and reference answers . To assess the balance between precision and recall, we utilize the average F1 Score . We apply the ROUGE-1 and ROUGE-2 metrics to evaluate the overlap of unigrams and bigrams, respectively, between the generated and reference answers, thereby assessing lexical similarity across different levels of granularity. Additionally, we use the ROUGE-L metric to measure the longest common subsequence, indicating the extent to which the generated answer aligns with the reference in terms of in terms of sequential structure and lexical overlap. Lastly, we utilize the average METEOR Score, which evaluates precision and recall while incorporating linguistic features such as synonyms and stemming.

### Clinician Evaluation of LLM Responses

We identify the best model for differential diagnosis as Mistral-7b (fine-tuned). Clinicians evaluate correctness to determine whether a response is correct or incorrect in aiding differential diagnosis. In total, 1,500 notes, along with query and answer pairs, are reviewed. Of these, 1,485 responses are deemed correct, while the remaining responses are deemed incorrect. Responses are classified as incorrect under certain conditions. First, when the generated response includes a different abnormality than the one addressed in the question. For example, if the question asks about right ventricular pressure overload but the answer discusses pulmonary hypertension. Second, a response is deemed incorrect if it includes irrelevant information that does not assist with the diagnosis. For instance, if the generated answer includes "no mass on tricuspid valve" instead of describing a "normal tricuspid valve leaflet," which is more relevant to diagnosing tricuspid valve regurgitation. Another type of incorrect response occurs when the generated answer fails to prioritize the highest severity level for a specific abnormality. For example, the left ventricular wall is incorrectly classified as normal instead of mild when the note contains multiple sentences describing varying severity levels. Finally, a response is considered incorrect if it includes the correct diagnosis but also adds unrelated diagnoses, compromising the clarity and quality of the answer.

### Fairness Audits

We perform fairness audits by examining social health attributes, as these factors provide insights into the conditions in which individuals live --critical influences on a person's health and well-being. To perform these audits, we utilize census tract-level SDOH data from the MIMIC dataset . Our analysis investigates fairness disparities across subgroups defined by societal attributes, such as 

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

depicts lower performance for populations with a high percentage of individuals with disabilities, and unemployed individuals. The best-performing model in terms of overall F1 score, Mistral-7B, demonstrates moderate disparities among the four groups across all social determinants of health. Finally, for closed source general models, Figure 5 shows that GPT-4o achieves a higher F1 score for the high group compared to the low group across various social determinant attributes, including the percentage of the population with disabilities, percentage of households receiving public assistance, percentage of the population unemployed, and percentage of adults reporting binge or heavy drinking.

## 5 Conclusion

We introduce a novel question-answering dataset using the MIMIC echocardiogram reports. This dataset is designed to enhance QA systems within cardiology care. To demonstrate the dataset's utility, we validate it using 13 LLMs, showing that the instruction fine-tuned Mistral-7B open-source model performs better than biomedical-specific models and closed-source models. Given Mistral-7B's top performance, we name our fine-tuned model Echo-Mistral, which clinicians qualitatively evaluate to assess the correctness of its responses. Our fairness audit reveals variability in model performance across social determinants of health, highlighting the trade-off between performance and fairness. We hope our comprehensive benchmark, featuring multiple LLMs and various evaluation metrics, will serve as a baseline, facilitating progress in medical real-world question-answering tasks in the cardiology space.

Figure 4: Disparities in performance depicted by F1 and standard error over 3 runs between different groups (high, upper middle, lower middle, low) along the social determinants of health by each examined open-sourced general LLM.

Figure 5: Disparities in performance depicted by F1 and standard error over 3 runs between different groups (high, upper middle, lower middle, low) along the social determinants of health by each examined closed-sourced general LLM.

### Ethics Statement

The dataset originates from the MIMIC-IV database, which is a de-identified dataset accessed through the PhysioNet Credentialed Health Data Use Agreement (v1.5.0) that we have been granted permission to use. The ethics approval of the dataset follows from that of the parent MIMIC dataset.