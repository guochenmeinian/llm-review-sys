# Enhancing Feature Diversity Boosts Channel-Adaptive Vision Transformers

Chau Pham

Boston University

Boston, MA

chaupham@bu.edu

&Bryan A. Plummer

Boston University

Boston, MA

bplum@bu.edu

###### Abstract

Multi-Channel Imaging (MCI) contains an array of challenges for encoding useful feature representations not present in traditional images. For example, images from two different satellites may both contain RGB channels, but the remaining channels can be different for each imaging source. Thus, MCI models must support a variety of channel configurations at test time. Recent work has extended traditional visual encoders for MCI, such as Vision Transformers (ViT), by supplementing pixel information with an encoding representing the channel configuration. However, these methods treat each channel equally, _i.e._, they do not consider the unique properties of each channel type, which can result in needless and potentially harmful redundancies in the learned features. For example, if RGB channels are always present, the other channels can focus on extracting information that cannot be captured by the RGB channels. To this end, we propose \(\), which aims to enhance the diversity in the learned features of MCI-ViT models. This is achieved through a novel channel sampling strategy that encourages the selection of more distinct channel sets for training. Additionally, we employ regularization and initialization techniques to increase the likelihood that new information is learned from each channel. Many of our improvements are architecture agnostic and can be incorporated into new architectures as they are developed. Experiments on both satellite and cell microscopy datasets, CHAMMI, JUMP-CP, and So2Sat, report \(\) yields a \(1.5-5.0\%\) gain over the state-of-the-art. Our code is publicly available at https://github.com/chaudatascience/diverse_channel_vit.

## 1 Introduction

Most visual encoders assume they are provided with a fixed-channel representation as input (_e.g._, they take RGB inputs as input at train and test time) . However, many applications find a variety of imaging techniques beyond just the traditional RGB channels beneficial. For example, satellite images or sensors onboard a robot often contain an infrared camera in addition to traditional RGB, and microscopes can also host a significant range of potential imaging channels . Thus, Multi-Channel Imaging (MCI) models aim to learn good feature representations from datasets with heterogeneous channels, where the number and type of channels can vary for each input at test time. Training a model that is robust to changes in channel configurations can save time and resources as only a single model needs to be learned, while also helping to prevent overfitting in small datasets through transfer learning . Prior work proposed methods to make MCI models robust to missing channels by randomly masking them during training . As shown in Fig. 1(a) left and (b) top, this results in redundancies being learned across channels during training rather than encoding new information. A consequence of this repetition is a model focused on learning strong cues that are easy to identify, making it less capable of learning unique and/or challenging cues within each channel.

[MISSING_PAGE_EMPTY:2]

## 2 Related Work

**Convolutional-based models for multi-channel imaging.** Researchers have been developing convolutional-based models to keep pace with the evolving landscape of multi-channel imaging data. Bhattacharyya _et al_.  introduced \(\), which utilizes depth-wise convolutions to merge channel-wise features from infrared thermal images. Jiang _et al_.  introduced a double-channel CNN that takes into account the correlation between input channels in aerial images. This approach employs a separate sub-network for each group of channels and then performs feature fusion to aggregate features across channels. Siegismund _et al_.  presented \(\) to work with images with many channels based on imaging blending concepts. While these methods can be used for MCI, they are not designed to work on varying input channels. In a recent study, Chen _et al_.  introduced and adapted channel-adaptive models based \(\) convolutions, \(\), and \(\). These models incorporate their adaptive interface in the first layer of an otherwise shared \(\) model . While these methods provide a strong baseline, they find settings where some channels are missing during inference challenging. In our work, we aim to improve MCI model robustness by improving the diversity of learned features.

**Vision Transformers for multi-channel imaging**. Vision transformers (ViT)  have natural advantages when dealing with multiple channels, especially when the number of channels varies. ViTs treat image modeling as sequence-to-sequence problems, allowing them to be flexible in handling different numbers of image tokens. Nguyen _et al_.  introduced _variable tokenization_ and _variable aggregation_, in which they divided each input channel independently into patches and then aggregated the patch features across channels using learnable queries. Tarasiou _et al_.  proposed \(\), which incorporates a tokenization scheme and temporal position encodings to process Satellite Image Time Series. In a relevant work, Zhou _et al_.  introduced \(\), a channel reweighting design aimed at adjusting channel features based on the observation that some channels capture more significant information than others. In the medical domain, Hatamizadeh _et al_.  proposed \(\) that utilized a transformer encoder followed by a skip-connected decoder for 3-D medical image segmentation. Recently, Bao _et al_.  proposed \(\) that processes each input channel independently via a shared linear projection and incorporates a learnable channel embedding for preserving channel-specific features. In addition, the authors proposed Hierarchical Channel Sampling (HCS), a regularization technique applied to the input channels to boost robustness and reduce training time. \(\) outperforms standard ViTs in classification tasks and demonstrates its generalization ability when only a subset of the trained channels is available during inference. In a similar work, Bourriez _et al_.  introduced \(\)-\(\), a channel adaptive attention technique for handling heterogeneous microscope images. However, these methods do not adequately model the unique properties of each channel type, resulting in harmful redundancies, whereas we boost the diversity of features across channels to enhance the robustness of MCI-ViT models.

Figure 2: **An overview of DiChaViT. We introduce two regularization methods on the features and a channel sampling strategy to promote diversity in feature representations. We apply (a) Channel Diversification Loss (CDL) (Sec. 3.1) for channel tokens (b), and (b) Token Diversification Loss (TDL) (Sec. 3.2) on the patch tokens (c). Additionally, we (c) sample a subset of dissimilar channels using Diverse Channel Sampling (DCS) (Sec. 3.3).**

## 3 Encouraging Diverse Representations in multi-channel ViTs

Given a multi-channel image (MCI) \(X\) containing channels \(c_{i} C_{X}\), our goal is to train a model \(M\) that takes our input image \(X\) as input to make its predictions. Following [15; 18], we consider the MCI setting where \(M\) has seen all the channels we expect to see during inference, _i.e._, \(C_{X} C_{M}\). We leave the exploration of handling novel channels during inference for future work, as it presents significant challenges, including establishing meaningful connections between existing and new channels, and identifying informative channel weights in the presence of domain shifts. In our setting, since we do not know what \(C_{X}\) we may see during inference, prior work has focused primarily on exploring methods that are robust to different choices of \(C_{X}\) by encouraging \(M\) to redundancies across channels (_e.g._, [14; 15; 18]). Specifically, they begin with a base ViT encoder  that uses each channel-specific image patch \(_{i}\) as input. Each image patch is passed through a shared patch projection layer and concatenated with its corresponding channel token \(_{i}\). Hierarchical Channel Sampling (HCS)  encourages robustness to missing channels by randomly masking some channels during training to ensure key information can be captured in multiple channels. However, as noted in the Introduction, this can be harmful when \(M\) does not balance this repetitive feature learning to also capture distinctive channel-specific information.

As illustrated in Fig. 1, \(\) aims to better balance repetitive and distinct feature learning through three major components. First, we use a Channel Diversification Loss (CDL) to learn diverse representations to help prevent feature collapse in the channel tokens (Sec. 3.1). Second, our Token Diversification Loss (TDL) encourages patch tokens to also learn distinct features (Sec. 3.2). Finally, Diverse Channel Sampling (DCS) promotes robustness to missing channels while also encouraging that new features are also learned during training (Sec. 3.3). These components enable our approach to balance repetitive and channel-specific feature learning (overview in Fig. 2).

### Enhancing channel token separation

Recall that in Fig. 1(a), learned channel tokens \(_{i}\) from prior work show high mutual information, indicating these tokens are not well-separated. Following [49; 50; 41; 51], we partly mitigate this issue by replacing the random initialization of \(_{i}\) used by prior work [15; 18] with an orthogonal initialization. To further encourage the diversity in the features, we introduce Channel Diversification Loss (CDL) for increased separation between the channel tokens (Fig. 2(a)). Inspired by \(++\), the idea is to use a learnable vector (_i.e._, an orthogonally initialized _channel anchor_) to represent each channel in the input image during training. We promote diversity in the channel tokens by pulling channel features toward their corresponding anchors while pushing them away from all other anchors. A key benefit of this approach is that the anchors prevent channel tokens from collapsing while still allowing for flexibility in learning useful representations.

Formally, we denote \(A\) as the set of all channel anchors, \(t_{}\) as the temperature, and \(\|\|_{2}\) as the \(L2\)-Norm. We start by initializing the channel tokens \(_{i}\) and their channel anchors orthogonally. Then, we apply CDL as follows:

\[_{}=-(_{i}}{\|_{i}\|_{2}},_{i})}{\|g(_{i})\|_{2}} )}{_{g(a) A}(-d(_{i}}{\| _{i}\|_{2}},})}} )})\,,\] (1)

where \(g(_{i})\) is a function that returns a corresponding channel anchor for channel token \(_{i}\), and \(d(_{i},g())\) is the squared Euclidean distance between channel token \(_{i}\) and an anchor. In Eq. 1, the numerator calculates the distance of a channel token to its anchor, while the denominator computes all these distance pairs of the channel token to all the channel anchors. When the temperature value \(t_{}\) is set to \(1\), we get a standard \(\) function. Lowering the temperature can lead to a more focused and sharp probability distribution, but we found that the results are not very sensitive to the value of \(t_{}\). Thus, we simply use a fixed temperature \(t_{}\) of \(1/14 0.07\).

### Enhancing feature diversity for patch tokens

MCI-ViT models like \(\), \(\)-ViT  use a shared linear projection to extract features independently from each input channel in the image rather than using separate projections for each channel. With the shared projection, only the common features across channels are retained,while other channel-specific information is filtered out, which helps to reduce overfitting. However, this design can also produce similar representations for all patch tokens. This is not ideal because each patch may contain unique information that would be ignored. In our approach, we also leverage this shared projection, but we enhance it with Token Diversification Loss (TDL), a regularization applied to the patch token features to enhance the diversity of features learned by each patch in the input image (see Fig. 2(b) for an overview). Specifically, we enforce an orthogonality constraint on the tokens to ensure that each token is orthogonal to the others. Additionally, we take into account the token type information to differentiate between tokens from the same channels and across channels. The main idea is to make features from different channels more distinct while allowing for a certain level of similarity among features within the same channel.

Let \(_{i}\) be the input patch at position \(i\), and \(_{}\) be the shared linear projection at the first layer. We denote \(_{i}=_{}_{i}\) as the patch feature token of \(_{i}\), \(T=\{_{i}\}_{i=1,2,}\) as the set containing all patch feature tokens in the input image, and \(h(_{i})\) as a function that returns the corresponding channel for input patch \(_{i}\). We devise a unified loss function for each input image as follows:

\[_{}=}_{_{i},_{ j} T;\,h(_{i})=h(_{j})}_{i},_{ j}\] (2)

\[_{}=}_{_{i},_{ k} T;\,h(_{i}) h(_{k})}_{i}, _{k}\] (3)

\[_{}=_{s}|_{}|+_ {d}|_{}|\] (4)

where \(,\) represents the cosine similarity, \(||\) denotes an absolute value, and \(N_{s},N_{d}\) are the numbers of patch token pairs in the two equations respectively. Eq. 2 calculates the average cosine similarity of all feature token pairs in the same channels, while Eq. 3 calculates the average of all feature token pairs from different channels. The two losses are combined with weights \(_{s}\) and \(_{d}\) to balance the constraint of tokens belonging to the same channels (first term) and tokens belonging to different channels (second term), to form the final loss \(_{}\) in Eq. 4. Our goal is to encourage each patch token to be orthogonal to each other to promote the diversity of patch tokens.

### Diverse Channel Sampling (DCS)

Bao _et al_.  introduced HCS to reduce the training time and improve the robustness of the model. The main concept is to randomly drop some input channels and train the model only on the remaining channels. In the same spirit, we propose a novel method, Diverse Channel Sampling (DCS), to sample a more diverse subset of channels during training (Fig. 2(c)). Similar to HCS, we start by randomly sampling a number \(k\), which is the size of a subset of channels to train on. However, while HCS samples \(k\) channels randomly, DCS first samples an anchor channel \(c_{k}\). Then, we select other \(k-1\) channels that are dissimilar to the anchor channel. This idea shares similarity with Channel DropBlock , where a set of similar channels in a CNN layer is masked out to disrupt co-adapted features. However, instead of keeping a fixed number of feature map channels as in Channel DropBlock, DCS selects a flexible number of input channels for each sampling. The procedure of DCS is outlined in Algorithm 1.

In practice, Algorithm 1 can be applied to a batch of images for faster sampling. We use channel token \(_{i}\) to represent the channel feature \(f_{i}\). Refer to Sec. 4.4 and Tab. 5 for more discussion on choices of \(f\). The temperature \(t_{}\) controls the sharpness of the probability distribution. With a large \(t_{}\), DCS reduces to HCS, while with a small \(t_{}\), DCS selects a random subset of channels that are the least similar to the anchor channel.

### Training Objective

The final loss consists of the primary loss for the specific task (_e.g._, cross-entropy for classification), Channel Diversification Loss (CDL) applied to channel tokens, and Token Diversification Loss (TDL) used on patch tokens. These terms work together to promote diversity in channel and patch token features, resulting in a more robust model, as shown in Eq. 5:

\[_{}=_{}+_{}_{}+_{}\] (5)

where \(_{}\) is a weight to balance CDL. Note that TDL is balanced by \(_{s}\) and \(_{d}\) in Eq. 4.

``` Input : Image \(X\) with \(m\) channels \(c_{1},...,c_{m}\)  Channel feature \(f_{i}\) for each input channel \(c_{i}\)  Temperature \(t_{}\)
1 Sample a random variable \(k\) uniformly from the set \(\{1,2,...,m\}\)
2 Sample an anchor channel \(c_{k}\) uniformly from all \(m\) channels
3 Compute the cosine similarity between channel \(c_{k}\) and the other \(m-1\) channels: \(=[ f_{k},f_{i},...]\), \( i k(^{m-1})\)
4 Convert \(1-\) to probability using \(\) with temperature \(t_{}\): \(=((1-)/t_{})( ^{m-1})\)
5 Sample \(k-1\) distinct channels from \(m-1\) channels with probability \(\)
6 Combine the \(k-1\) channels with channel \(c_{k}\) to create a set of \(k\) sampled channels. Output : Image \(X\) with only \(k\) sampled channels ```

**Algorithm 1**Diverse Channel Sampling (DCS)

## 4 Experiments

### Experimental Setup

**Baseline methods.** We adopt the following baseline methods.

* **DepthwiseViT** utilizes a depthwise convolution layer to independently filter each input channel. The resulting features are averaged to create a new feature representation, which is then fed into a \(\) backbone.
* **TemplateMixingViT**[39; 40] generates weights for each channel by learning a linear combination of shared, learnable parameter templates. These weights are formed into a patch project layer, followed by a \(\) backbone.
* **HyperNetViT** employs a neural network (_e.g_., MLP) to independently generate weights for each channel, which are then concatenated to form a patch projection layer. This patch projection layer is subsequently used in a \(\) backbone.
* **ChAda-ViT** uses a shared projection layer to extract features from each channel separately, then feeds these tokens, together with their corresponding positional embeddings and channel embeddings, into a \(\) backbone.
* **ChannelViT** is the same general architecture as \(\), but also employs Hierarchical Channel Sampling (HCS) during training.

**Implementation details.** As HCS proves robust in multi-channel imaging , we incorporate this technique for \(\), \(\), and \(\) to ensure a fair comparison in these adaptive baselines used by Chen _et al_. 1. For \(\) and \(\), due to their similarity (primarily a difference in whether HCS is included), we use the implementation from  for both methods2. All baselines utilize a \(\) small architecture (21M parameters) implemented in \(\) as the backbone 3. We use AdamW optimizer  to train the models, minimizing cross-entropy loss on JUMP-CP and So2Sat, and proxy loss on CHAMMI. For the learning rate, we use a scheduler with linear warmup and cosine decay. Refer to Appendix Sec. A for details.

**Metrics.** We evaluated the methods by calculating their top-1 classification accuracy on the So2Sat  and JUMP-CP  datasets. For CHAMMI , we used the evaluation code4 provided by the authors, in which a 1-Nearest Neighbour classifier is used to predict the macro-average F1-score for each task separately. We report the average score on WTC and HPA, and present the detailed results in Tab. 7 of the Appendix.

### Datasets

**CHAMMI ** consists of varying-channel images from three sources: WTC-11 hiPSC dataset (WTC-11, three channels), Human Protein Atlas (HPA, four channels), and Cell Painting datasets(CP, five channels). The three sub-datasets contain a total of \(220\)K microscopy images, of which \(100\)K images are for training and the rest for testing across various tasks. The models are trained to learn feature representation and then evaluated on domain generalization tasks.

**JUMP-CP ** comprises images and profiles of cells that were individually perturbed using chemical and genetic methods. Our experiments focus on the compound perturbation plate BR00116991, which contains \(127\)K training images, \(45\)K validation images, and \(45\)K test images. Each image has eight channels, with the first five being _fluorescence_ and the remaining three containing _brightfield_ information. The dataset consists of \(161\) classes, including \(160\) perturbations and a control treatment.

**So2Sat ** contains synthetic aperture radar and multispectral optical image patches from remote sensing satellites. Each image in the dataset has \(18\) channels, of which eight _Sentinel-1_ and \(10\)_Sentinel-2_ channels. The dataset consists of \(17\) classes, each representing a distinct climate zone. We use the city-split version of the dataset, which includes \(352\)K training images and \(24\)K test images.

### Results

Tab. 1 shows that \(\) outperforms the state-of-the-art \(\) by up to \(5.0\)% points on all three datasets: CHAMMI , JUMP-CP , and So2Sat . For JUMP-CP and So2Sat, we consider two scenarios: tested on all training channels (denoted as "Full") and tested on a subset of channels (denoted as "Partial"). In the full channels setting, our model shows a \(1.5-2.5\)% point improvement compared with other baselines on JUMP-CP and So2Sat. When tested on partial channels, \(\) demonstrates its robustness by achieving a \(1.5\)% improvement compared with the baselines. This demonstrates that diversifying feature representations in MCI-ViT models boosts both performance and robustness.

Tab. 2 presents a detailed evaluation of \(\) and the best baseline model, \(\), when tested on partial channels of the JUMP-CP dataset (with a total of eight channels). For the partial channel evaluation, we exclude some of the channels that the models were trained on and only test the model on the remaining channels. Then, we calculate the average accuracy across all combinations, _e.g._, testing on seven channels, as shown in column "7", involves averaging the results of \(C_{8}^{7}=8\)

    &  \\  Method & 8 & 7 & 6 & 5 & 4 & 3 & 2 & 1 \\  ChannelViT  & 67.51 & 60.36\(\)9.1 & 52.74\(\)12.2 & 44.89\(\)13.2 & 36.88\(\)12.3 & 29.36\(\)9.3 & 23.70\(\)5.0 & 20.78\(\)1.6 \\
**DiChaViT (ours)** & 69.19 & 61.91\(\)9.3 & 54.49\(\)12.4 & 46.35\(\)13.4 & 38.00\(\)12.4 & 30.09\(\)9.3 & 23.97\(\)4.9 & 20.90\(\)1.6 \\   

Table 2: **Test accuracy of DiChaViT and ChannelViT on partial channels of JUMP-CP **. Each column represents _mean\(\)std_ for all combinations when tested on partial channels. For example, column ”7” indicates testing on \(7\) out of \(8\) channels, and, thus, the reported variance is due to the presence or absence of a channel. See to Tab. 9 in the Appendix for detailed results for each combination for column ”7” with model variance. \(\) consistently exhibits improved robustness in the presence of missing channels during inference.

    &  & JUMP-CP  &  \\  Model & Avg score & Full & Partial & Full & Partial \\  HyperNetViT  & 54.54 & 47.07 & 42.43 & 60.73 & 41.88 \\ DepthwiseViT  & 60.94 & 49.86 & 44.98 & 60.41 & 43.41 \\ TemplateMixingViT  & 57.02 & 52.48 & 43.85 & 55.86 & 37.28 \\ ChAda-ViT  & 63.88 & 65.03 & 42.15 & 56.98 & 12.38 \\ ChannelViT  & 64.90 & 67.51 & 56.49 & 61.03 & 46.16 \\
**DiChaViT (ours)** & **69.68** & **69.19** & **57.98** & **63.36** & **47.76** \\   

Table 1: **Comparison of test accuracy of channel adaptive models.** ”Full” refers to inference on all channels, while ”Partial” means testing on a subset of channels (_Sentinel-1_ channels for So2Sat, _fluorescence_ channels for JUMP-CP). We find our model outperforms other baselines, with a \(5.0\)% boost on CHAMMI and a \(1.5-2.5\)% point improvement on JUMP-CP and So2Sat.

combinations (refer to Tab. 9 in the Appendix for detailed results). Our findings consistently show that \(\) demonstrates improved robustness when some input channels are missing.

To provide more insight into the contribution of each component of \(\), Tab. 3 presents the model's performance when a component is removed. The results highlight the critical role of the DCS component, as its removal has the most detrimental effect on performance, particularly in the _Partial_ setting, with a decrease of \(16\%\) and \(30\%\) points on JUMP-CP and So2Sat, respectively. The absence of CDL and TDL results in similar performance drops across all datasets. The highest scores are achieved when all components are integrated, indicating that each component plays a crucial role in the model's design. Refer to Tab. 8 in the Appendix for a comprehensive analysis.

### Analysis and Discussion

#### 4.4.1 Role of Channel Tokens in MCI-ViT Models

**The role of channel tokens.** In MCI-ViT models such as \(\) and \(\)-ViT , channel tokens play a crucial role in learning channel-specific features, particularly when dealing with multiple channels where each contains unique information. To assess the impact of channel tokens, we compared the performance of \(\) on JUMP-CP and CHAMMI _with_ (orange bars) and _without_ channel tokens (blue bars), as shown in Fig. 3. The results indicate that \(\) demonstrates significant improvements with channel tokens, resulting in \(8.0\%\) and \(15.0\%\) point increases on JUMP-CP and CHAMMI, respectively, highlighting their importance.

**Orthogonal initialization of channel tokens boosts performance.** As shown in Fig. 3, using orthogonal initialization (green) provides a \(1.0\%\) gain on JUMP-CP and CHAMMI. This may suggest that by initializing the weights orthogonally, the model can more effectively capture diverse patterns within the data, resulting in boosting its overall performance.

#### 4.4.2 Ablation on Feature Diversification Losses (CDL and TDL)

**Impact of \(_{}\) (Eq. 5) in CDL.** Fig. 4(a) and (b) show the performance of \(\) (_mean_ and _std_) across different values of \(_{}\) on So2Sat and CHAMMI datasets. We can observe that selecting a value that is too large is not beneficial to the performance. It is worth finding a suitable value for \(_{}\). On the So2Sat, the best performance is achieved with \(_{}=0.001\), while the suitable value for CHAMMI is \(0.1\).

**Ablation on TDL (Eq. 4).** Fig. 4(c) reports the performance of our model across different ratios of \(_{d}\) and \(_{s}\) in TDL. We set a fixed value of \(_{s}\) at \(0.05\) and vary \(_{d}\). We observe that using a larger \(_{d}\) compared with \(_{s}\) leads to better performance for \(\). This suggests that knowing which channel a token comes from, _i.e._, the _same_ or _different_ channel, is necessary. The results indicate

    & CHAMMI  & JUMP-CP  &  \\  Model & Avg score & Full & Partial & Full & Partial \\ 
**DiChaViT** & **69.66** & **69.19** & **57.98** & **63.36** & **47.76** \\ w/o CDL & 68.07 & 67.66 & 56.87 & 62.20 & 45.74 \\ w/o TDL & 67.61 & 68.12 & 56.62 & 62.39 & 46.87 \\ w/o DCS & 65.32 & 66.03 & 42.37 & 59.20 & 17.88 \\   

Table 3: **Model ablations of DiChaViT. Removing any component in \(\) has a negative impact on overall performance, with significant decreases observed on the _Partial_ setting when DCS is removed. Including all components improves performance across all three datasets.**imposing stricter constraints on tokens from different channels compared with tokens from the same channel obtains the best performance. Tab. 4 shows the impact of each component in TDL. We see that considering only tokens within the same channels (denoted by "Only \(_{}\)") is insufficient, resulting in a significant drop in performance. In contrast, using both \(_{}\) and \(_{}\) in TDL yields the best performance of \(\).

#### 4.4.3 Ablations for Diverse Channel Sampling (DCS)

**Channel feature \(f\) in DCS**. Tab. 5 compares the performance of using channel tokens (\(_{i}\)) and patch tokens (, image patches after passing through the projection layer) to compute the similarity score for sampling in Algorithm 1 (line 3). We observe that using channel tokens gains better performance on So2Sat and CHAMMI datasets. Note that while channel tokens are shared across all input images, patch tokens differ for each input image.

**Impact of temperature on DCS.** Tab. 6 shows the effect of temperature \(t_{}\) used in Algorithm 1 on DCS. When \(t_{}\) is set to a very small value, as reported in the first column (denoted as "\( 0\)"), DCS selects channels with the lowest similarity scores to the anchor channel. Conversely, when \(t_{}\) is assigned a large value, denoted as "HCS" in the last column, DCS is reduced to HCS , meaning

   Temperature \(t_{}\) & \( 0\) & 0.001 & 0.01 & 0.1 & 0.2 & HCS \\  So2Sat  & 62.51 & 63.21 & 63.30 & **63.36** & 61.92 & 62.15 \\ CHAMMI  & 67.22 & 66.91 & 68.96 & **69.66** & 66.07 & 66.30 \\   

Table 6: **Effect of temperature \(t_{}\) on DCS (Algorithm 1).** The first column (\( 0\)) indicates the use of a very small value of \(t_{}\), which is reduced to selecting the lowest similarity channels. The last column indicates a large value of \(t_{}\), which is reduced to HCS . Using \(t_{}=0.1\) obtain the best results on So2Sat and CHAMMI datasets.

Figure 4: **Impact of CDL and TDL** on \(\)’s performance. **(a) & (b)** We demonstrate the average top-1 test accuracy and standard deviation over three runs for different values of \(_{}\) on So2Sat and CHAMMI. **(c)** Performance with different ratios of \(_{d}\) and \(_{}\) in TDL on So2Sat.

    & So2Sat  & CHAMMI  \\  Only \(_{}\) & 61.43 & 65.47 \\ Only \(_{}\) & 62.50 & 68.15 \\ Both & **63.36** & **69.66** \\   

Table 4: **Ablation on the two components of TDL.**_Only \(_{s}\)_ indicates using only within channel tokens (, \(_{d}=0\)), while _Only \(_{d}\)_ indicates the use of only tokens from different channels in Eq. 4. Incorporating both components in TDL gives the best performance.

that it selects the subset of channels randomly. We find that always selecting the lowest similar channels (\( 0\)) does not yield the best performance. Instead, setting the temperature to \(t_{}=0.1\) produces favorable results for both So2Sat and CHAMMI.

**DCS and HCS on the distribution of number sampling of the channels.** Fig. 5 compares the number of times each channel is sampled during training with DCS (blue bars) and HCS  (red dashed line). DCS offers a different distribution for its channels compared with HCS, with some channels receiving more training than others. For example, _Real part of Lee-filtered covariance matrix_ (_Real Lee-Cov_) in the last bar, is sampled twice as frequently as _Band B8a_ channel (first bar).

## 5 Conclusion

In this paper, we present \(\), a model aimed at enhancing feature diversity and robustness in Multi-Channel Imaging (MCI) ViTs. First, we introduce Diverse Channel Sampling, a novel channel sampling strategy that encourages the selection of more distinct channel sets during training, thereby promoting feature diversity. Additionally, \(\) incorporates Token Diversification Loss on the patch tokens and Channel Diversification Loss for channel tokens to further diversify the features learned in MCI-ViTs. Our experiments demonstrate a \(1.5-5.0\%\) point improvement over state-of-the-art methods on satellite and microscopy imaging datasets. Many of our enhancements are not tied to any specific architecture and can be incorporated into new architectures as they are developed. \(\) represents a promising advancement in addressing the challenges associated with MCI, paving the way for more effective MCI-ViT models.

**Broader Impacts and limitations.** The development of \(\) represents an advancement in MCI, with potential positive impacts such as improved medical diagnosis and accelerated healthcare research. Additionally, its versatility in satellite imaging holds promise for environmental monitoring. However, there are also potential negative impacts, including the risk of bad actors using this research to develop harmful applications, such as invasive surveillance systems. This highlights the importance of ethical considerations and responsible deployment. One of the limitations of our work is that it is not designed to handle novel channels. Generalizing to unseen channels is challenging because it requires establishing a connection between existing and new channels. This is further complicated in the presence of domain shifts, which makes finding the informative channel weights even more difficult. Thus, investigating techniques to adapt to new channels at test time is a promising research direction in MCI. In addition, our approach requires extra hyperparameter tuning, which may necessitate additional compute resources.

Figure 5: **Comparison of DCS and HCS  in terms of the frequency (%) each channel is sampled during training on So2Sat.** Unlike HCS, which provides a uniform distribution for all channels (red dashed line), some channels in DCS are trained much more than others (blue bars). For example, _Real Lee-Cov_ channel (rightmost) is sampled twice as much as _Band B8a_ (first bar).