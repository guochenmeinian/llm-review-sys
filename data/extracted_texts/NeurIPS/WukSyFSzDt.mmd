# Stabilized Proximal-Point Methods for Federated Optimization

Xiaowen Jiang

Saarland University and CISPA

xiaowen.jiang@cispa.de

&Anton Rodomanov

CISPA1

anton.rodomanov@cispa.de

&Sebastian U. Stich

CISPA1

stich@cispa.de

CISPA Helmholtz Center for Information Security, Saarbrucken, Germany

###### Abstract

In developing efficient optimization algorithms, it is crucial to account for communication constraints--a significant challenge in modern Federated Learning. The best-known communication complexity among non-accelerated algorithms is achieved by DANE, a distributed proximal-point algorithm that solves local subproblems at each iteration and that can exploit second-order similarity among individual functions. However, to achieve such communication efficiency, the algorithm requires solving local subproblems sufficiently accurately resulting in slightly sub-optimal local complexity. Inspired by the hybrid-projection proximal-point method, in this work, we propose a novel distributed algorithm S-DANE. Compared to DANE, this method uses an auxiliary sequence of prox-centers while maintaining the same deterministic communication complexity. Moreover, the accuracy condition for solving the subproblem is milder, leading to enhanced local computation efficiency. Furthermore, S-DANE supports partial client participation and arbitrary stochastic local solvers, making it attractive in practice. We further accelerate S-DANE and show that the resulting algorithm achieves the best-known communication complexity among all existing methods for distributed convex optimization while still enjoying good local computation efficiency as S-DANE. Finally, we propose adaptive variants of both methods using line search, obtaining the first provably efficient adaptive algorithms that could exploit local second-order similarity without the prior knowledge of any parameters.

## 1 Introduction

Federated learning is a rapidly emerging large-scale machine learning framework that allows training from decentralized data sources (e.g. mobile phones or hospitals) while preserving basic privacy and security . Developing efficient federated optimization algorithms becomes one of the central focuses due to its direct impact on the effectiveness of global machine learning models.

One of the key challenges in modern federated optimization is to tackle communication bottlenecks . The large-scale model parameters, coupled with relatively limited network capacity and unstable client participation, often make communication highly expensive. Therefore, the primary efficiency metric of a federated optimization algorithm is the total number of communication rounds required to reach a desired accuracy level. If two algorithms share equivalent communication complexity, their local computation efficiency becomes the second important metric.

The seminal algorithm DANE  is an outstanding distributed optimization method. It achieves the best-known deterministic communication complexity among existing non-accelerated algorithms (on the server side) . This efficiency primarily hinges upon a mild precondition regarding the Second-order Dissimilarity \(\). In numerous scenarios, like statistical learning for generalized model  andsemi-supervised learning , \(\) tends to be relatively small. However, to ensure such fast convergence, DANE requires each iteration subproblem to be solved with sufficiently high accuracy. This leads to sub-optimal local computation effort across the communication rounds, which is inefficient in practice. FedRed improves this weakness by using double regularization. However, this technique is only effective when using gradient descent as the local solver but cannot easily be combined with other optimization methods. For instance, applying local accelerated gradient or second-order methods cannot improve its local computation efficiency. Moreover, it is also unclear how to extend this method to the partial client participation setting relevant to federated learning.

On the other hand, the communication complexities achieved by the current accelerated methods typically cannot be directly compared with those attained by DANE, as they either depend on sub-optimal constants or additional quantities such as the number of clients \(n\). The most relevant and state-of-the-art algorithm Acc-Extragradient achieves a better complexity in terms of the accuracy \(\) but with dependency on the maximum Second-order Dissimilarity \(_{}\) which can in principle be much larger than \(\) (see Remark 2). Unlike most federated learning algorithms, such as FedAvg, this method requires communication with all the devices at each round to compute the full gradient and then assigns one device for local computation. In contrast, FedAvg and similar algorithms perform local computations on parallel and utilize the standard averaging to compute the global model. The follow-up work AccSVRS applies variance reduction to Acc-Extragradient which results in less frequent full gradient updates. However, the communication complexity incurs a dependency on \(n\) which is prohibitive for cross-device setting  where the number of clients can be potentially very large. Thus, there exists no accelerated federated algorithm that is uniformly better than DANE in terms of communication complexity.

Contributions.In this work, we aim to develop federated optimization algorithms that can achieve the best communication complexity while retaining efficient local computation. To this end, we first revisit the simple proximal-point method on a single machine. The accuracy requirement for solving the subproblem defined in this algorithm is slightly sub-optimal. Drawing inspiration from hybrid projection-proximal point method for finding zeroes of a maximal monotone operator , we observe that using a more stabilized prox-center improves the accuracy requirement. We make the following contributions:

* We develop a novel federated optimization algorithm S-DANE that achieves the best-known communication complexity (for non-accelerated methods) while also enjoying improved local computation efficiency over DANE .
* We develop an accelerated version of S-DANE based on the Monteiro-Svaiter acceleration . The resulting algorithm Acc-S-DANE achieves the best-known communication complexity among all existing methods for distributed convex optimization.
* Both algorithms support partial client participation and arbitrary stochastic local solvers, making them attractive in practice for federated optimization.
* We provide a simple analysis for both algorithms. We derive convergence estimates that are continuous in the strong convexity parameter \(\).
* We propose adaptive variants of both algorithms using line-search in the full client participation setting. The resulting methods achieve the same communication complexity (up to a logrithmic factor) as non-adaptive ones without requiring knowledge of the similarity constant.
* We illustrate strong practical performance of our proposed methods in experiments.

See also Table 1 for a summary of the main complexity results in the full-participation setting.

Related Work.Moreau first proposed the notion of the proximal approximation of a function . Based on this operation, Martinet developed the first proximal-point method . This method was first accelerated by Guller , drawing the inspiration from Nesterov's Fast gradient method . Later, Lin et al.  introduced the celebrated Catalyst framework that builds upon Guller's acceleration. Using Catalyst acceleration, a large class of optimization algorithms can directly achieve faster convergence. In a similar spirit, Doikov and Nesterov  propose contracting proximal methods that can accelerate higher-order tensor methods. While Guller's acceleration has been successfully applied to many settings, its local computation is sub-optimal. Specifically, when minimizing smooth convex functions, a logarithmic dependence on the final accuracy is incurred in its local computation complexity . Solodov and Svaiter  proposed a hybrid projection-proximal point method that allows significant relaxation of the accuracy condition for the proximal-point subproblems. More recent works such as Adaptive Catalyst and RECAPP successfully get rid of the additional logarithmic factor for accelerated proximal-point methods as well.

Another type of acceleration based on the proximal extra-gradient method was introduced by Monteiro and Svaiter . This method is more general in the sense that it allows arbitrary local solvers and the convergence rates depend on the these solvers. For instance, under convexity and Lipschitz second-order derivative, the rate can be accelerated to \((1/k^{3.5})\) by using Newton-type method. Moreover, when the gradient method is used, Monteiro-Svaiter Acceleration recovers the rate of Guller's acceleration and its accuracy requirement for the inexact solution is weaker. For minimizing smooth convex functions, one gradient step is enough for approximately solving the local subproblem . This technique has been applied to centralized composite optimization, known as gradient sliding [35; 36; 33]. A comprehensive study of acceleration can be found in .

  
**Algorithm** &  **\# Vectors coming** \\ **per round** \\  &  **Genard sources** \\ **\#** \\  &  \(\)**-density curves** \\ **local gradient queries** \\  &  **Genard source** \\ **\#** \\  &  **Genard source** \\ **\#** \\  &  **\#** \\  &  **\#** \\  &  **Genard source** \\ **\#** \\  &  **Genard source** \\ **\#** \\  &  **Genard source** \\ **\#** \\  &  **Genard source** \\ **\#** \\  \\  SoftEive\({}^{+}\) & n & \(}{}\) & \(1\)\({}^{+}\) & \(}}{}\) & \(}\) & in expectation \\ SONTA\({}^{+}\) & n & unknown & unknown & \(}{}\) & \(-\)\({}^{+}\) & deterministic \\ DANE & n & \(}{}\) & \(}}{}\) & \(}{}\) & \(}}{}\) & deterministic \\ FedBel & n & \(}{}\) & \(\) & \(}{}\) & \(\) & in expectation \\  S-ANE (**disk work**, Alg. 1) & n & \(}{}\) & \(}\) & \(}{}\) & \(}\) & deterministic \\  Inexact Acc-SONATA\({}^{+}\) & n & unknown & unknown & \(}}{}}{}\) & \(}}{}\) & deterministic \\ Acc-Extraplenet\({}^{+}\) & n & \(^{2}}\) & \(}\) & \(}}{}\) & \(}\) & deterministic \\  Catalyped SVEP\({}^{+}\) &   \(1\) \\ n \\  & 
 w.p. \(1-\) \\ w.p. \(1-\) \\ w.p. \(1-\) \\  & unknown & unknown & \((n+})}{}\) & \(-\)\({}^{+}\) & in expectation \\ AccS-DANE (**disk work**, Alg. 2) & n & \(}\) & \(}}{}\) & \(}\) & deterministic \\   

Table 1: Summary of the worst-case convergence behaviors of the considered distributed optimization methods (in the BigO-notation) assuming each \(f_{i}\) is \(L\)-smooth and \(\)-convex with \(()\), where \(\), \(_{}\), \(^{2}\) are defined in (2), Remark 2 and (3), and \(D\|^{0}-^{}\|\). The _'# local gradient queries’_ column represents the number of gradient oracle queries required between two communication rounds to achieve the corresponding complexity, assuming **the most efficient local first-order algorithms are used**. The column _'Guarantee'_ means whether the convergence guarantee holds in expectation or deterministically. The suboptimality \(\) is defined via \(\|}^{R}-^{}\|^{2}\) and \(f(}^{R})-f^{}\) for strongly-convex and general convex functions where \(}^{R}\) is a certain output produced by the algorithm after \(R\) number of communications.

Figure 1: Comparison of S-DANE and Acc-S-DANE with DANE for solving a convex quadratic minimization problem. All three methods use GD as the local solver. S-DANE has improved local computation efficiency than DANE while Acc-S-DANE further improves the communication complexity. Finally, the adaptive variants can leverage local dissimilarities to achieve better performance. (The definitions of local smoothness and dissimilarity can be found in Section 6.)

We defer the literature review on distributed and federated optimization algorithms to Appendix A.

## 2 Problem Setup and Background

We consider the following distributed minimization problem:

\[_{^{d}}f() _{i=1}^{n}f_{i}()},\] (1)

where each function \(f_{i}^{d}\) is \(\)-strongly convex2 for some \( 0\). We focus on the standard federated setting where the functions \(\{f_{i}\}\) are distributed among \(n\) devices. The server coordinates the global optimization procedure among the devices. In each communication round, the server broadcasts certain information to the clients. The clients, in turn, perform local computation in parallel based on their own data and transmit the resulting local models back to the server to update the global model.

**Main objective:** Given the high cost of establishing connections between the server and the clients, our paramount objective is to minimize the number of required communication rounds to achieve the desired accuracy level. This represents a central metric in federated contexts, as outlined in references such as . **Secondary objective:** Efficiency in local computation represents another pivotal metric for optimization algorithms. For instance, if two algorithms share equivalent communication complexity, the algorithm with less local computational complexity is the more favorable choice.

**Notation:** We abbreviate \([n]\{1,2,,n\}\). For a set \(A\) and an integer \(1 s|A|\), we use \(\) to denote the power set comprised of all \(s\)-element subsets of \(A\). Everywhere in this paper, \(\|\|\) denotes the standard Euclidean norm (or the corresponding spectral norm for matrices). We assume problem (1) has a solution which we denote by \(^{}\); the corresponding optimal value is denoted by \(f^{}\). For a set \(S\), we use \(f_{S}_{i S}f_{i}\) to denote the average function over this set. We use \(r\) to denote the index of the communication round and \(k\) to denote the index of the local step. Finally, we use the superscript and subscript to denote the global and local models, respectively; for instance, \(^{r}\) represents the global model at round \(r\) while \(_{i,r}\) is the local model computed by device \(i\) at round \(r\).

### Proximal-Point Methods on Single Machine

In this section, we provide a brief background on proximal-point methods , which are the foundation for many distributed optimization algorithms.

Proximal-Point Method.Given an iterate \(_{k}\), the method defines \(_{k+1}\) to be an (approximate) minimizer of the proximal-point subproblem:

\[_{k+1}*{arg\,min}_{ ^{d}}F_{k}() f()+\|-_{k}\|^{2}},\] (2)

for an appropriately chosen parameter \( 0\). This parameter allows for a trade-off between the complexity of each iteration and the rate of convergence. If \(=0\), the subproblem in each iteration is as difficult as solving the original problem because no regularization is applied. However, as \(\) increases, more regularization is added, simplifying the subproblem. For example, for a convex function \(f\), the proximal-point method guarantees \(f(}_{K})-f^{}\| _{0}-^{}\|^{2}\), where \(}_{K}_{k=1}^{K}_{k}\). However, to achieve such a convergence rate, the subproblem (2) has to be solved to a fairly high accuracy . For instance, the accuracy condition should either depend on the target accuracy \(\), or increase with \(k\): \(\| F_{k}(_{k+1})\|=(\|_ {k+1}-_{k}\|)\). Indeed, when \(f\) is Lipschitz-smooth and the standard gradient descent is used as a local solver, the number of gradient steps required to solve the subproblem has a logarithmic dependence on the iteration counter \(k\). The same issue also arises when considering accelerated proximal-point methods .

Stabilized Proximal-Point Method.One of the key insights that we use in this work is the observation that using a different prox-center makes the accuracy condition of the subproblem weaker.

The _stabilized proximal-point method_ defines

\[_{k+1}&*{ arg\,min}_{}F_{k}() f()+\| -_{k}\|^{2}},\\ _{k+1}&=*{arg\,min}_{} f(_{k+1}),+\| -_{k+1}\|^{2}+\|-_{k }\|^{2}},\] (3)

where \( 0\) is a parameter of the method and \( 0\) is the strong-convexity constant of \(f\). This algorithm updates the prox-center \(_{k}\) by performing an additional gradient step in each iteration. For instance, when \(=0\), the prox-center is updated as \(_{k+1}=_{k}- f(_{k+1})\), which is often referred to as an _extra-gradient update_. The stabilized proximal-point method has the same convergence rate as the original method (2) but requires only that \(\| F_{k}(_{k+1})\|(\|_{k+1}- _{k}\|)\). As a result, there is no extra logarithmic factor of \(k\) in the oracle complexity estimate when \(f\) is \(L\)-smooth. Specifically, by setting \(=(L)\), the previous condition can be satisfied by choosing \(_{k+1}\) as the result of one gradient step from \(_{k}\). This shows that the stabilized proximal-point method has a better overall oracle complexity than the standard proximal-point method (c.f. Theorem 1 for the special case \(n=1\)). It is worth noting that the former algorithm originates from the hybrid projection-proximal point algorithm  designed for solving the more general problem of finding zeroes of a monotone operator. In this work, we apply this algorithm in the distributed setting (\(n 2\)).

### Distributed Proximal-Point Methods

The proximal-point method can be adapted to solve the distributed optimization problem (1). This is the idea behind FedProx. It replaces the global proximal step (2) by \(n\) subproblems defined as \(_{i,r+1}*{arg\,min}_{}\{f_{i}( )+\|-^{r}\|^{2}\}\), which can be solved independently on each device, followed by the averaging step \(^{r+1}=_{i=1}^{n}_{i,r+1}\). Here we switch the notation from \(k\) to \(r\) to highlight that one iteration of the proximal-point method corresponds to a communication round in this setting. To ensure convergence, FedProx has to use a large \(\) that depends on the target accuracy as well as the heterogeneity among \(\{f_{i}\}\), which slows down the communication efficiency . DANE  improves this by incorporating a drift correction term into the subproblem:

\[_{i,r+1}*{arg\,min}_{} _{i,r}() f_{i}()+ f( ^{r})- f_{i}(^{r}),+\|-^{r}\|^{2}}.\] (4)

Consequently, DANE allows to choose a much smaller \(\) in the algorithm. Moreover, it can exploit second-order similarity and achieve the best-known communication complexity among non-accelerated methods . However, as in the original proximal-point method, the subproblem needs to be solved sufficiently accurately leading to an extra logarithmic factor in the oracle complexity estimate. To overcome this problem, we propose new algorithms described in the following section.

```
1:Input:\(>0\), \( 0\), \(s[n]\), \(^{0}=^{0}^{d}\).
2:for\(r=0,1,2\)do
3: Sample \(S_{r}\) uniformly at random without replacement.
4:for each device \(i S_{r}\) in parallel do
5:\(_{i,r+1}*{arg\,min}_{^{d }}F_{i,r}() f_{i}()+ f_{S_ {r}}(^{r})- f_{i}(^{r}),+\|-^{r}\|^{2}}\).
6:\(^{r+1}=_{i S_{r}}_{i,r+1}\).
7:\(^{r+1}*{arg\,min}_{^{d }}_{i S_{r}}[ f_{i}(_{i,r+1} ),+\|-_{i,r+1}\|^{2}]+\|-^{r}\|^{2}}\). ```

**Algorithm 1** S-DANE: Stabilized DANE

## 3 Stabilized Dane

We now describe S-DANE (Alg. 1), our proposed federated proximal-point method that employs stabilized prox-centers in its subproblems. During each communication round \(r\), the server samples a subset of clients uniformly at random and sends \(^{r}\) to these clients. Then the server collects \( f_{i}(^{r})\) from these clients, computes \( f_{S_{r}}(^{r})\) and sends \( f_{S_{r}}(^{r})\) back to them. Each device in the set then calls an arbitrary local solver (which can be different on each device) to approximately solve its local subproblem. Finally, each device transmits \( f_{i}(_{i,r+1})\) and \(_{i,r+1}\) back to the server which then aggregates these points and computes the new global model.

As DANE, S-DANE can also achieve communication speed-up if the functions among devices are similar to each other. This is formally captured by the following assumption.

**Definition 1** (Second-order Dissimilarity).: _Let \(f_{1},,f_{n}:^{d}\) be functions, and let \(s[n]\), \(_{s} 0\). Then, \(\{f_{i}\}_{i=1}^{n}\) are said to have \(_{s}\)-SOD (of size \(s\)) if for any \(,^{d}\) and any \(S\), it holds that_

\[_{i S} h_{i}^{S}()- h_{i}^{S}( )^{2}_{s}^{2}-^{2},\] (5)

_where \(h_{i}^{S} f_{S}-f_{i}\) and \(f_{S}_{i S}f_{i}\)._

Definition 1 quantifies the dissimilarity between any \(s\) functions and their average, i.e., the "internal" variation between any \(s\) functions. Clearly, \(_{1}=0\), and, when \(s=n\), we recover the standard notion of second-order dissimilarity introduced in prior works:

**Definition 2** (\(\)-SOD ).: \(\)_-SOD \(_{n}\)-SOD of size \(n\)._

When each function \(f_{i}\) is twice continuously differentiable, a simple sufficient condition for (5) is that \(_{i S}^{2}h_{i}^{S}()^{2} _{s}^{2}\) for any \(^{d}\). However, this is not a necessary condition (see  for more details).

The quantity \(V(,)\) in the left-hand side of (5) can be interpreted as the variance of the gradient difference estimator \( f_{i}()- f_{i}()\), where \(i\) is chosen uniformly at random from \(S\). In particular, it can be rewritten as \(V(,)=_{i S} f_{i}()- f_{i}()^{2}- f_{S}()- f _{S}()^{2}\). If each function \(f_{i}\) is \(L_{i}\)-smooth, then \(_{s}(_{i S}L_{i}^{2})^{1/2}\) for any \(s[n]\). However, in general, condition (5) is weaker than assuming that each \(f_{i}\) is Lipschitz-smooth.

Full Client Participation.We first consider the cross-silo setting where all the clients are highly reliable (\(s=n\)). This is typically the case with organizations and institutions having strong computing resources and stable network connection .

**Theorem 1**.: _Consider Algorithm 1 with \(s=n\). Let \(f_{i}^{d}\) be \(\)-convex with \( 0\) for any \(i[n]\). Assume that \(\{f_{i}\}_{i=1}^{n}\) have \(\)-SOD. Let \(=2\) and suppose that, for any \(r 0\), we have_

\[_{i=1}^{n} F_{i,r}(_{i,r+1})^{2}}{4}_{i=1}^{n}_{i,r+1}-^{r}^{2}.\] (6)

_Then, for any \(R 1\), it holds that3_

\[f(}^{R})-f^{}}{2[(1+ )^{R}-1]}}{R},\]

_where \(}^{R}^{n}p^{r}}_{r=1}^{R}p^{r} ^{r}\) for \(p 1+\), and \(D^{0}-^{}\). To obtain \(f(}^{R})-f^{}\) for a given \(>0\), it thus suffices to perform \(R=(1+}{ })\) communication rounds._

Theorem 1 provides the convergence guarantee for S-DANE in terms of the number of communication rounds. Note that the rate is continuous in \(\).

**Remark 2**.: _Some previous works express complexity estimates in terms of another constant, \(_{}\), defined by the inequality \( h_{i}()- h_{i}()_{ }-\) holding for any \(,^{d}\) and any \(i[n]\), where \(h_{i}=f-f_{i}\). (See for instance the second line in Table 1). Note that our \(\) is always not larger than \(_{}\), and can in principle be much smaller (up to \(\) times)._

The proven communication complexity is the same as that of DANE . However, the accuracy condition is milder. Specifically, to achieve the same guarantee, DANE requires \(_{i=1}^{n}_{i,r}(_{i,r+1})^{2} (}{r^{2}}_{i=1}^{n}_{i,r+1}- ^{r}^{2})\), where \(_{i,r}\) is defined as in (4), which incurs an \(r^{2}\) overhead in the denominator, as in the general discussion on proximal-point methods in Section 2.1. The next corollary shows that local computations in S-DANE could be computationally very efficient.

**Corollary 3**.: _Consider the same setting as in Theorem 1. Further, assume that each \(f_{i}\) is \(L\)-smooth. To ensure (6) with a certain first-order algorithm, each device \(i\) needs to perform at most \((})\) computations of \( f_{i}\) at each round \(r\)._

**Remark 4**.: _Particular examples of algorithms that could be used to achieve the result from Corollary 3 are OGM-OG by Kim and Fessler  and the accumulative regularization method by Lan et al. , both designed for the fast minimization of the gradient norm. For the standard Gradient Method (GM), the required number of oracle calls is \(()\). The standard Fast Gradient Method (FGM)  can further decrease the complexity to \((})\) (see Remark 18 for details). Thus, each device can run a constant number of standard local (F)GM steps to approximately solve their subproblems in S-DANE._

Partial Client Participation.Next, we turn our attention to the cross-device setting where a large number of clients (typically mobile phones) have either unstable network connection or weak computational power . In such scenarios, the server typically cannot expect all the clients to be able to participate in the communication at each round. Furthermore, the clients may typically be asked to communicate only once during the whole training and are stateless . Therefore, we now consider S-DANE with partial client participation and without storing any states on devices.

To prove convergence, it is necessary to assume a certain level of dissimilarity among clients. Here, we use the same assumption as in  to measure the gradient variance.

**Definition 3** (Bounded Gradient Variance ).: _Let \(f_{1},,f_{n}^{d}\) be functions, and let \( 0\). We say that \(\{f_{i}\}_{i=1}^{n}\) have \(\)-BGV if, for any \(^{d}\) and \(f_{i=1}^{n}f_{i}\), it holds that_

\[_{i=1}^{n} f_{i}()- f() ^{2}^{2}.\] (7)

Definition 3 is similar to the classical notion of uniformly bounded variance used in the context of classical stochastic gradient methods .

We also need the following assumption which complements Definition 1.

**Definition 4** (External Dissimilarity).: _Let \(f_{1},,f_{n}:^{d}\) be functions, and let \(s[n]\), \(_{s} 0\). Then, \(\{f_{i}\}_{i=1}^{n}\) are said to have \(_{s}\)-ED (of size \(s\)) if, for any \(,^{d}\) and any \(S\), we have_

\[ m_{S}()- m_{S}()_{s} -,\] (8)

_where \(m_{S} f-f_{S}\) and \(f_{S}_{i S}f_{i}\)._

Compared to Definition 1, the new Definition 4 quantifies the "external" variation of any \(s\) functions w.r.t. the original function \(f\). When each \(f_{i}\) is twice continuously differentiable, (8) is equivalent to \(^{2}m_{S}()_{s}\) for any \(^{d}\). If each \(f_{i}\) is \(L\)-smooth, then \(_{s} L\) for any \(s[n]\). Therefore, using both Assumptions 1 and 4 is still weaker than assuming that each \(f_{i}\) is \(L\)-smooth.

In what follows, we work with a new second-order dissimilarity measure defined as the sum \(_{s}+_{s}\). Note that \(_{1}+_{1}=_{}\) and \(_{n}+_{n}=\).

**Theorem 5**.: _Consider Algorithm 1. Let \(f_{i}:^{d}\) be \(\)-convex with \( 0\) for any \(i[n]\) and let \(n 2\). Assume that \(\{f_{i}\}_{i=1}^{n}\) have \(_{s}\)-SOD, \(_{s}\)-ED and \(\)-BGV. Let \(=}{}+2(_{s}+ _{s})\), and suppose that, for any \(r 0\), we have_

\[_{i S_{r}} F_{i,r}(_{i,r+1})^{2} }{4}_{i S_{r}}_{i,r+1} -^{r}^{2}.\] (9)

_Then, to ensure that \([f(}^{R})]-f(^{})\) for a given \(>0\), it suffices to perform at most the following number of communication rounds:_

\[R=+_{s}+}{}+ }{s}1+}{ }+_{s})D^ {2}}{}+D^{2}}{s^{2}},\]

_where \(}^{R}^{R}p^{r}}_{r=1}^{R}p^{r} ^{r}\) with \(p 1+\), and \(D^{0}-^{}\)._Theorem 5 provides the communication complexity of S-DANE with client sampling and arbitrary (deterministic) local solvers. The rate is again continuous in \(\). Compared with the previous case of \(s=n\), the efficiency now depends on the gradient variance \(\). Note that this error term gets reduced when \(s\) increases. Specifically, to achieve the \(()\) and \(()\) rates, it suffices to ensure that \(s=}{^{2}+n(_{s}+ _{})}\). Notably, the algorithm can reach any target accuracy even when \(n\).

Observe that the accuracy requirement (9) is the same as (6). Therefore, the discussions therein are valid in the partial-participation setting as well. In particular, if each \(f_{i}\) is \(L\)-smooth, then the number of oracle calls to \( f_{i}\) required at each round could be as small as \((})\) (see Corollary 3). At the same time, it is also possible to use a stochastic optimization algorithm as a local solver (for more details, see Section C.3.1).

## 4 Accelerated S-DANE

In this section, we present the accelerated version of S-DANE, Acc-S-DANE (Alg. 2), that achieves a better communication complexity compared to the basic method. For simplicity, we only consider the full-participation setting and defer the partial participation to Appendix D.3.

**Theorem 6**.: _Consider Algorithm 2 with \(s=n\). Let \(f_{i}:^{d}\) be \(\)-convex with \( 0\) for any \(i[n]\). Assume that \(\{f_{i}\}_{i=1}^{n}\) have \(\)-SOD (\(>0\)). Let \(=2\) and suppose that, for any \(r 0\), we have \(_{i=1}^{n} F_{i,r}(_{i,r+1})^{2}^{2} _{i=1}^{n}_{i,r+1}-^{r}^{2}\). If \( 8\), then, for any \(R 1\),_

\[f(^{R})-f^{}}{1+}^{R}-1-}^{R}\,^{2}} }{R^{2}},\]

_where \(D^{0}-^{}\). Otherwise, \(f(^{R})-f^{}}{(1+})^{2(R-1)}}\) for any \(R 1\). To ensure that \(f(^{R})-f^{}\) for a given \(>0\), it thus suffices to perform \(R=}(1+D^{2}}{}})\) communication rounds._

Let us consider the most interesting regime when \( 8\). Comparing Theorems 1 and 6, we see that Acc-S-DANE essentially extracts the square root of the corresponding communication complexity of S-DANE by improving it from \(}()\) to \(}(})\) when \(>0\), and from \(}{}\) to \((}{}})\) when \(=0\), while maintaining the same accuracy condition for solving the subproblem. Compared with Acc-Extragradient, the complexity depends on a better constant \(\) instead of \(_{}\).

Note that we can satisfy the accuracy condition in Theorem 6 in exactly the same way as in Corollary 3. In particular, if each \(f_{i}\) is \(L\)-smooth, each device \(i\) needs at most \((})\) computations of \( f_{i}\) at each round \(r\) when using a fast algorithm for the gradient norm minimization.

Finally, let us highlight that Algorithm 2 gives a distributed framework for a _generic acceleration scheme_, that applies to a large class of local optimization methods--in the same spirit as in the famous Catalyst framework that applies to the case where \(n=1\). However, in contrast to Catalyst, this stabilized version removes the logarithmic overhead present in the original method. Specifically, when applying Theorem 6 with \(n=1\) and \(=L\) for a smooth convex function \(f\), we recover the same rate as Catalyst. The accuracy condition \(\| F_{r}(^{r+1})\| L\|^{r+1}-^{r}\|\), or equivalently \( f(^{r+1}),^{r}-^{r+1} \| f(^{r+1})\|^{2}\) can be achieved with one gradient step \(^{r+1}^{r}- f(^{r})\) (see Lemma 5 in ).

## 5 Dynamic Estimation of Similarity Constant by Line Search

One drawback of Algorithms 1 and 2 is that they require the knowledge of the similarity constant \(\) to choose an appropriate value for \(\). This similarity constant is typically unknown in practice and might be difficult to estimate. One effective solution to this problem is to dynamically adjust the coefficient \(\) inside the algorithms by using the classical technique of _line search_.

The basic idea is as follows. The server first picks an arbitrary sufficiently small constant \(\) as an initial approximation to the unknown "correct" value of \(=2\). Then, at every round, the server sends the current estimate of \(\) to each client asking them to approximately solve their local subproblem. After receiving the corresponding local solutions, the server checks a certain inequality based on the obtained information. If this inequality is satisfied, the server accepts the resulting aggregated solution and goes to the next round while decreasing \(\) in two times (so as to be more optimistic in the future). Otherwise, it increases \(\) in two times, asks the clients to solve their subproblems with the new value of \(\), and checks the inequality again.

The precise versions of Algorithms 1 and 2 with line search for the full-participation setting are presented in Algorithms 3 and 4. Importantly, our adaptive schemes are not just some heuristics but are probably efficient. Specifically, their complexity estimates (in terms of the total number of communication rounds) are exactly the same as those given by Theorems 1 and 6, respectively, up to an extra _additive_ logarithmic term of \(\) (see Theorems 27 and 28).

Another significant advantage of our adaptive algorithms is their ability to exploit _local_ similarity, resulting in much stronger practical performance compared to the methods with fixed \(\). We will demonstrate this in the next section.

## 6 Numerical Experiments

In this section, we illustrate the performance of our methods in numerical experiments. The implementation can be found at https://github.com/mlolab/S-DANE.

**Convex quadratic minimization.** We first illustrate the properties of our algorithms as applied to minimizing a simple quadratic function: \(f()_{i=1}^{n}f_{i}()\) where \(f_{i}()_{j=1}^{m}_{i,j}(-_{i,j}),-_{i,j}\) where \(_{i,j}^{d}\) and \(_{i,j}^{d d}\). The experimental details can be found in Appendix F.1. From Figure 1, we see that S-DANE converges as fast as DANE in terms of communication rounds, but with much fewer local gradient oracle calls. Acc-S-DANE achieves the best performance among the three methods. We also test S-DANE and DANE with the same fixed number of local steps. The result can be seen in Figure E.1 where S-DANE is again more efficient. Finally, we report the strong performances of two adaptive variants (Algorithms 3 and 4 with initial \(=10^{-3}\)). We see from Figure 1 that the method can automatically change \(\) to adapt to the local second-order dissimilarity. (We use \(^{r+1})- f(^{r})\|}{\|^{r+ 1}-^{r}\|}\) and \(^{n}\| h_{i}(^{r+1})- h _{i}(^{r})\|^{2}}{\|^{r+1}-^{r}\|^{2}}}\) to approximate the local smoothness and dissimilarity.)

**Strongly-convex polyhedron feasibility problem.** We now consider the problem of finding a feasible point \(^{}\) inside a polyhedron: \(P=_{i=1}^{n}P_{i}\), where \(P_{i}=\{:_{i,j},_{i,j}, j=1,,m_{i}\}\) and \(_{i,j},_{i,j}^{d}\). Each individual function is defined as \(f_{i}_{j=1}^{m_{i}}[_{i,j}, -_{i,j}]_{+}^{2}\) where \(_{i=1}^{n}m_{i}=m\). We use \(m=10^{5}\) and \(d=10^{3}\). We first generate \(^{}\) randomly from a sphere with radius \(10^{6}\). We then follow  to generate \((_{i,j},_{i,j})\) such that \(^{}\) is a feasible point of \(P\) and the initial point of all optimizers is outside the polyhedron. We choose the best \(\) from \(\{10^{i}\}_{i=-3}^{3}\). We first consider the full client participation setting and use \(n=s=10\). We compare our proposed methods with GD, DANE with GD , Scaffold with control variate of option I , Scaffnew, FedProx with GD  and Acc-Extragradient. The result is shown in the first plot of Figure 2 where our proposed methods are consistently the best among all these algorithms. We next experiment with client sampling and use \(n=100\). We decrease the number of sampled clients from \(s=80\) to \(s=10\). In addition to our methods, we also report the performances of Scaffold and FedProx with client sampling. From the same figure, we see that the improvement of Acc-S-DANE over S-DANE gradually disappears as \(s\) decreases.

**Adaptive choice of \(\).** We consider the standard regularized logistic regression: \(f()=_{i=1}^{n}f_{i}()\) with \(f_{i}()_{j=1}^{m_{i}}(1+(-y_{i,j} _{i,j},))+\|\|^{2}\) where \((_{i,j},y_{i,j})^{d+1}\) are features and labels and \(M_{i=1}^{n}m_{i}\) is the total number of data points in the training dataset. We use the ijcnn dataset from LIBSVM . We split the dataset into 10 subsets according to the Dirichlet distribution with \(=2\) (i.i.d) and \(=0.2\) (non-i.i.d). From Figure 4, Adaptive (Acc-)S-DANE (Algorithm 3 and 4) converge much faster than the other best-tuned algorithms for both cases. (We set the initial \(=10^{-4}\) for non-i.i.d and \(=10^{-5}\) for i.i.d respectively.)

**Deep learning task.** Finally, we consider the multi-class classification tasks with CIFAR10  using ResNet-18 . The details can be found in Appendix F.2. From Figure 3, we see that S-DANE (DL) 5 reaches \(90\%\) accuracy within 50 communication rounds while all the other methods are still below \(90\%\) after \(80\) epochs. The effectiveness of S-DANE on the training of other deep learning models such as Transformer requires further exploration.

## 7 Conclusion

We have proposed new federated optimization methods (both basic and accelerated) that simultaneously achieve the best-known communication and local computation complexities. The new methods allow partial participation and arbitrary stochastic local solvers, making them attractive in practice. We further equip both algorithms with line search and the resulting schemes can adapt to the local dissimilarity without knowing the corresponding similarity constant. However, we assume that each function \(f_{i}\) is \(\)-strongly convex in all the theorems. This is stronger than assuming only \(\)-strongly convexity of \(f\), which is used in some prior works. Possible directions for future research include consideration of weaker assumptions as well as empirical and theoretical analyses for non-convex problems.

Figure 4: Illustration of the impact of adaptive \(\) used in (Acc-)S-DANE on the convergence of a regularized logistic regression problem on the ijcnn dataset .

Figure 3: Comparison of S-DANE without control variate against other popular optimizers on multi-class classification tasks with CIFAR10 datasets using ResNet18.

Figure 2: Comparisons of different algorithms for solving the polyhedron feasibility problem.