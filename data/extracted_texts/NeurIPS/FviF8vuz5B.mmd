# On Differentially Private Sampling from Gaussian and Product Distributions

Badih Ghazi

Google Research

Mountain View, CA, US

badihghazi@gmail.com

&Xiao Hu

University of Waterloo

Waterloo, Canada

xiaohu@uwaterloo.ca

&Ravi Kumar

Google Research

Mountain View, CA, US

ravi.k53@gmail.com

This work was done while the author was visiting Google Research.

Pasin Manurangsi

Google Research

Bangkok, Thailand

pasin@google.com

###### Abstract

Given a dataset of \(n\) i.i.d. samples from an unknown distribution \(P\), we consider the problem of generating a sample from a distribution that is close to \(P\) in total variation distance, under the constraint of differential privacy (DP). We study the problem when \(P\) is a multi-dimensional Gaussian distribution, under different assumptions on the information available to the DP mechanism: known covariance, unknown bounded covariance, and unknown unbounded covariance. We present new DP sampling algorithms, and show that they achieve near-optimal sample complexity in the first two settings. Moreover, when \(P\) is a product distribution on the binary hypercube, we obtain a pure-DP algorithm whereas only an approximate-DP algorithm (with slightly worse sample complexity) was previously known.

## 1 Introduction

Differential privacy (DP)  is a strong and rigorous notion of privacy that has been increasingly studied and deployed as protection against the leakage of personal data used to train ML models.

A basic setting widely studied in ML is _distribution learning_, where given samples drawn i.i.d. from an unknown distribution \(P\), we seek to output a distribution \(Q\) that is as close to \(P\) as possible (formal definitions are given in Section 1.1). Recent works  have studied DP distribution _learning_, whereby the output distribution is guaranteed to stay roughly the same when a single input sample is changed. A closely related setting is DP mean and covariance estimation studied by . Motivated by the fact that tasks often require much fewer samples than full-fledged learning, the very recent work of  studied the task of DP _distribution sampling_, where the goal is to generate a sample from a distribution \(Q\) that is as close as possible to the distribution \(P\) from which the input samples are drawn i.i.d. (In the non-private setting, variants of the sampling task have also been studied, e.g., in the work on sample amplification by .)

In this work, we study DP distribution sampling, and the quantitative gap with respect to the _a priori_ more challenging task of DP distribution learning. For the case of multi-dimensional Gaussians, we consider three natural settings: known covariance, unknown bounded covariance, and unknown unbounded covariance; for the first two, we obtain near-tight bounds. This answers an open question of . Moreover, we obtain near-tight bounds on sampling in the case of product distributions on \(\{0,1\}^{d}\) with pure-DP, also improving upon previous work.

**Motivation.** There are many natural settings where a sample from the underlying distribution would be sufficient (as an alternative to the possibly more expensive task of learning the distribution).

For example, if one is implementing an algorithm that would run on sensitive user data, then, as part of the usual software development cycle, unit tests  are important. Writing unit tests on real data can violate users' privacy (e.g., if the unit test code is public). On the other hand, (privately) learning the distribution of the user data could be a significant overkill for this application. A private sample of the underlying distribution would provide a sufficiently representative input for the unit testing algorithm, and this input could be revealed publicly without compromising the privacy of the users.

A second motivation arises in distributed settings. Consider the situation where algorithms are being developed on medical data provided by multiple hospitals. The algorithm designer would like a synthetic dataset that would work well for the algorithm development process. Such a dataset could be obtained if each hospital provides a few (private) samples from its underlying distribution.

Finally, we describe another distributed setting motivation where a central curator wishes to build a synthetic dataset from multiple users, each contributing multiple items, under the constraint of item-level DP (as opposed to user-level DP). A simple approach for generating such a synthetic dataset is to let each user send to the curator a private sample (satisfying item-level DP).

### Formulation

Let \(\) be a class of distributions on some domain \(\). We consider a setting where there is an unknown distribution \(D\) and an algorithm has sample access to \(D\). There are two natural problems that can be posed in this setting. In the _sampling problem_, the goal is to design an algorithm that uses samples from \(D\) (which is unknown) and outputs an element in \(\). We say that an algorithm \(\) is an \(\)-_accurate sampler for \(\)_ iff \(d_{}(D,Q_{,D})\) for all \(D\), where \(Q_{,D}\) denotes the distribution of \(()\) where \( D^{n}\) and \(d_{}(,)\) denotes the total variation distance. Here \(n\) is said to be the sample complexity of the sampler. In the _learning problem_, the goal is to design an algorithm that outputs a distribution \(D^{}\). We say that an algorithm \(\) is an \((,)\)-_accurate learner for \(\)_ if \(_{ D^{n},D^{}()}[d_{}(D^{},D)] 1-\) for all \(D\); as before, \(n\) is the sample complexity of the learner.

The DP version of the learning problem is well studied, e.g., ; in this work we study the DP version of the sampling problem. First, we recall the definition of DP. We consider the _substitution_ notion, i.e., two datasets are _neighbors_ iff they have the same number of samples and we can transform one to the other by changing a single sample.

**Definition 1.1** (Differential Privacy ).: An algorithm \(M:\) is said to be \((,)\)-_differentially private_ (\((,)\)-DP) for \(>0\), \( 0\) iff, for every \(S\) and every neighboring datasets \(Y,Y^{}\), we have \([(Y) S] e^{}[(Y^{}) S ]+\).

We abbreviate \((,0)\)-DP by \(\)-DP, aka, _pure-DP_; the \( 0\) case is _approximate-DP_. We assume that the privacy parameters satisfy \( 1\), \( 1/2\), and the accuracy parameter satisfies \(0< 1/2\).

### Our Results for Gaussian Distributions in \(^{d}\)

We focus on the \(d\)-dimensional Gaussian distribution, i.e., \(D=(,)\) with \(^{d},^{d d}\). Recall that \((,)\) is supported on \(^{d}\) with \(f_{(,)}(x)(-(x-)^{T}^ {-1}(x-))\). We study three cases that have been considered in the literature:

* _Known Covariance:_\(\) is known, but \(\) is not. More formally, the class of distributions is \(^{}_{}:=\{(,)^{d}\}\).
* _Unknown Bounded Covariance:_ Both \(,\) are unknown but with a promise that \(I I\) for a known constant \(>0\), i.e., the class of distributions is \(^{}_{}:=\{(,)^{d},^{d d}I I\}\).2

* _Unknown Unbounded Covariance:_ Both \(,\) are unknown, i.e., the class of distributions is \(^{}:=\{(,)^{d}, ^{d d}\}\).

A summary of our DP sampling results along with a comparison to known DP learning results is in Table 1. Before we describe our results in more detail, we highlight the following. (i) In all cases,the dependence of our algorithms on the accuracy parameter \(\) is only polylogarithmic, whereas for DP learning algorithms, this dependence is polynomial. (ii) In the case of known covariance and unbounded known covariance, we obtain improvements over DP learning in terms of the dependence on the dimension \(d\). (iii) All of our algorithms run in polynomial time, although we do not explicitly state the running time in the formal statements.

**Known Covariance.** While any DP learning algorithm requires \((}+)\) samples in this setting , we show that, surprisingly, only \((/)\) samples suffice for DP sampling.

**Theorem 1.2**.: _There is an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions with known covariance with sample complexity \(O(}{}()).\)_

We also show that the \(\) dependence is necessary, i.e., that our algorithm's sample complexity is tight up to polylogarithmic factors.

**Theorem 1.3**.: _Any 0.1-accurate \((,)\)-DP sampler for Gaussian distributions with known covariance must have sample complexity \((/)\)._

**Unknown Bounded Covariance.** In this setting, we obtain an algorithm with sample complexity of \(_{}()\); in contrast, the best known DP learning algorithm requires \(_{}(}{^{2}}+}{ })\) samples .

**Theorem 1.4**.: _There is an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions with unknown covariance, under the assumption \(I I\), with sample complexity \(O(^{2}()).\)_

Similar to before, we can show that the sample complexity dependence on \(d,\) is near-optimal:

**Theorem 1.5**.: _Let \(>0\) be a sufficiently small constant, and \(,\) be such that \( O(})\). Then, any \(\)-accurate \((,)\)-DP sampler for Gaussian distributions with unknown covariance, under the assumption \(I 2I\), must have sample complexity \(n=(})\)._

**Unknown Unbounded Covariance.** In this setting, the best known DP learning algorithm uses \((}{^{2}}+}{})\) samples . For DP sampling, we show that we can reduce the dependence on \(\) to polylogarithmic and the dependence on \(d\) to \(d^{1.5}\).

**Theorem 1.6**.: _There exists an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions (without any assumption) with sample complexity \(O(}{}())\)._

### Our Results for Product Distributions on \(\{0,1\}^{d}\)

For \(p\), let \((p)\) be the _Bernoulli_ distribution supported on \(\{0,1\}\) with probability mass function \(f_{(p)}(0)=1-p\) and \(f_{(p)}(1)=p\). We consider product distributions \((p_{1})(p_{d})\) where \(p_{1},,p_{d}\) are unknown. (In other words, the class of distributions is \(^{}:=\{(p_{1})(p_{d}) p_{1},,p_{d}\}\).)

   & Known Covariance & Bounded Covariance & Unbounded Covariance \\  Non-Private Learning (Folklore) & \((})\) & \((}{^{2}})\) & \((}{^{2}})\) \\  \((,)\)-DP Learning & \((}+)\) & \((}{^{2}}+}{})\) & \((}{^{2}}+}{})\) \\  &  &  &  \\  \((,)\)-DP Sampling (Our results) & \((}{})\) Theorems 1.2,1.3 Theorems 1.4, 1.5 Theorem 1.6 \\  

Table 1: Sample complexity of private learning and sampling for Gaussian distributions. Here, \(,\) hide factors that are polylogarithmic in \(d,1/,1/,1/\) (and \(1/\) in the case of learning).

We give a pure-DP sampler with sample complexity \(()\). Previously, only approximate-DP sampler with similar sample complexity was known from , which also provided a matching lower bound. In comparison, DP learning uses \((}+)\) samples [27; 10].

**Theorem 1.7**.: _There exists an \(\)-accurate \(\)-DP sampler for product distributions on \(\{0,1\}^{d}\) with sample complexity \(O()}{}+()}{}).\)_

We also note that our result above improves upon even the approximate-DP sampler in  by logarithmic factors. Specifically, for \( 1/ d\), our sample complexity is \(O()\) whereas theirs is \(O(}{}(^{9/4}d+^{ 5/4}(1/)))\).

## 2 Technical Overview

### Gaussian Distributions: Algorithms

**Known Covariance.** When \(\) is known, we may assume w.l.o.g. that \(=I\); otherwise, we can transform each sample \(X\) into \(^{-1/2}X\). We start by using known algorithms [23; 40; 33] to find a "rough" estimate for the mean. In particular, we find an estimate \(\) such that \(\|-\|_{2} R=(/)\) using \(n=(/)\) samples. By appropriately shifting the subsequent samples, this is equivalent to assuming that \(\|\|_{2} R\). We then focus on designing a DP sampler for this bounded mean case. It turns out, surprisingly, that the Gaussian mechanism suffices here. Specifically, for a parameter \(B>0\) (chosen later), we truncate each sample so that its \(_{2}\)-norm is at most \(B\). We then output their average with a (spherical) Gaussian noise \((0,^{2}I)\) added. The description is given in Algorithm 1.

``` Parameters:\(B,>0\), and \(n\). Sample \(X_{1},,X_{n} D\) for\(i=1,,n\)do \(X_{i}^{}=_{B}^{2}(X_{i})\)\(\) see (1) Sample \(Z(0,^{2}I)\) return\(Z+_{i[n]}X_{i}^{}\) ```

**Algorithm 1** SphericalGaussianSampler

The analysis of the Gaussian mechanism [e.g., 20, Appendix A] shows that the algorithm is \((,)\)-DP as long as we pick \(()\).

As for the accuracy, observe that if there were no truncation, then the output is exactly distributed as \((,(^{2}+1/n)I)\), which is precisely \((,I)\) if we set \(^{2}=(n-1)/n\). Therefore, by setting \(B=R+O()\) so that the truncation does _not_ occur with probability \(1-\), we ensure that the sampler is \(\)-accurate. The constraint that \(()\) from privacy implies that we need \(n(/)\) and hence yielding the sample complexity in Theorem 1.2.

**Unknown Bounded Covariance.** Recall that in this setting we know that \(I I\). While it might be tempting to use the above Gaussian mechanism for this setting as well, it turns out that this approach results in sample complexity that depends _polynomially_ on \(1/\).3

To circumvent this, we first consider the case where \(=0\) (i.e., "centered" Gaussians). In this case, our algorithm originates from the following attempt: output \(_{i[n]}a[i] X_{i}\), where \((a,,a[n])_{n}^{}\), the uniform distribution over points on the unit sphere in \(^{n}\). It follows from the \(2\)-stability of the Gaussian distribution  that, when \(X_{1},,X_{n}(0,)\), this results4 in an output that is distributed exactly as \((0,)\).

Unfortunately, this algorithm is not DP: if \(X_{1}==X_{n-1}=0\), then the output will reveal the direction of \(X_{n}\) in the clear. To remedy this, we build on the intuition that, if \(X_{1},,X_{n}\) "sufficiently span all directions", then there should be "enough noise" to make this algorithm DP. In particular, using the bounded covariance property, we can show that if all the eigenvalues of \(_{i[n]}X_{i}X_{i}^{T}\)

  Non-Private Learning & \((})\) \\  \(\)-DP Learning & \((}+)\)[29; 27] \\  \((,)\)-DP Sampling & \(()\) \\  \(\)-DP Sampling & \(()\) Theorem 1.7 \\ (Our result) & \(()\) Theorem 1.7 \\  

Table 2: Sample complexity for private learning and sampling for product distributions on \(\{0,1\}^{d}\). Here, \(\) hides factors that are polylogarithmic in \(d,1/\) (and \(1/\) in the case of learning).

are sufficiently large (and each \(X_{i}\) is truncated appropriately), then this algorithm is indeed "DP". This is perhaps the most technically challenging part of our work, as the noise is data-dependent and therefore poses significant hurdles in the privacy analysis (Section 4.2). Note that this is also the reason we need \(n(d)\), as otherwise \(X_{1},,X_{n}\) cannot "sufficiently span all directions" in \(^{d}\).

With the above, the last ingredient is a testing step (in the "propose-test-release" paradigm of ) that checks this eigenvalue condition. When this condition fails, we return \(\); otherwise \(_{i[n]}a[i] X_{i}\).

To handle the case where \( 0\), we take an output to be the sum of the average of \(n_{1}\) samples and \(}}(_{i[n_{2}]}a[i] U_{i})\), where each \(U_{i}\) is the difference between two fresh independent samples divided by \(\) and \((a,,a[n_{2}])_{n_{2}}^{}\). Notice here that each \(U_{i}(0,)\), while the average over \(n_{1}\) samples is \((,})\); thus, the sum is \((,)\) as desired. The full description is presented in Algorithm 2; the parameter setting and analysis can be found in Appendix B.4.

**Unknown Unbounded Covariance.**

We proceed by reducing this case to the previous setting. We do so by first applying the known DP "preconditioner" algorithm for Gaussians (with unknown unbounded covariance) from the work of  in order to obtain rough estimates \(,\) of \(,\) respectively. This allows us to transform any subsequent sample \(X\) into \(^{-1/2}(X-)\). This reduces us back to DP sampling for \((^{-1/2}(-),^{1/2}^{-1} ^{1/2})\). The guarantee of the DP preconditioner ensures that this Gaussian actually has bounded covariance. Therefore, we can apply our previous algorithm. Note that a significant part of the sample complexity is due to the DP preconditioner of the Gaussian; it turns out that the sample complexity of this task is only \(_{,}(d^{3/2})\) (compared to \(_{,}(d^{2})\) for learning). Furthermore, since we only need the preconditioner to be a rough estimate, we can set the accuracy parameter for the learning to be \((1)\) and thus avoid the polynomial dependence on \(1/\). (Note that private preconditioner is a standard ingredient in the recipe for DP learning [e.g., 27].)

### Gaussian Distributions: Lower Bounds

**Known Covariance.** Our lower bound in this setting builds on the following insight: if we take a constant number of samples from \((,I)\) (using the DP sampler) and use them to estimate \(\), then we incur an expected \(_{2}^{2}\)-error that is \(O(d)\). It turns out that known lower bounds for DP mean estimation of Gaussians with known covariance  hold for this setting and give a lower bound of \(()\), where \(^{2}\) is the \(_{2}^{2}\)-error. Plugging in \(=\) in our setting gives the desired lower bound of \((/)\). In the actual proof, one complication stems from the fact that our DP sampler does not output a sample exactly from \((,I)\). Nonetheless, we can quantify this in terms of the accuracy \(\).

**Unknown Bounded Covariance.** In this setting, we reduce from a lower bound on DP covariance estimation --rather than DP mean estimation earlier--of centered Gaussians. The challenge is that \((1)\) samples from \((0,)\) do _not_ provide a sufficiently high accuracy estimate for \(\) so that we can apply the known lower bound5. Therefore, the above approach does not work directly.

To overcome this, we will have to use many samples to estimate the covariance. Recall that the sample complexity lower bound of \((d^{2}/)\) for covariance estimation requires the accuracy in the Frobenius distance (or the Mahalanobis distance) to be constant . Due to this accuracy requirement, we need to use our DP sampler to generate \(L=(d^{2})\) samples \(Y_{1},,Y_{L}\) to achieve such an accuracy. We can draw a fresh batch \(X_{1}^{i},,X_{n}^{i}\) of samples from the underlying distribution to generate each \(Y_{i}\). However, since \(L=(d^{2})\), this would use \(Ln\) samples in total. The covariance estimation lower bound would then yield \(Ln(d^{2}/)\), implying \(n(1/)\)--even weaker than the mean estimation lower bound!

Fortunately, it turns out this can be overcome by using advanced composition of DP . In particular, we may run our sampler \(L\) times on the _same_\(n\) samples to produce \(Y_{1},,Y_{L}\). In this case, the final covariance estimation algorithm has privacy loss parameter \(()=(d)\) due to advanced composition (Theorem A.5). Therefore, we get a lower bound of \((d^{2}/(d))=(d/)\) as desired.

While the above overview seems intuitively plausible, there are certain difficulties that we need to overcome. First, the samples \(Y_{i}\) that our algorithm produces are not exactly drawn from \((0,)\); to fix this, we run an agnostic learner for Gaussians [e.g., 3] to recover the estimate of \(\). Second, since we run our DP sampler on the same \(n\) samples, the produced \(Y_{1},,Y_{L}\) are not independent. We fix this by first drawing a larger number \(N\) of samples, and then produce each \(Y_{i}\) using \(n\)-out-of-\(N\) random samples; this reduces the correlation across the \(Y_{i}\)'s. Furthermore, using amplification-by-sampling of DP  gives us the desired privacy-vs-sample complexity lower bound guarantee.

### Product Distributions: Algorithm

Our sampler follows the framework of , which is built upon the preconditioning procedure proposed by  for DP learning.

We start with a private preconditioner, which obtains a crude estimate of each \(p_{j}\) (up to a constant multiplicative factor). This is similar to that of , except that we use Laplace noise instead of Gaussian noise; this ensures that the resulting algorithm is pure-DP6. By suitably partitioning \(\) into geometrically decreasing buckets in terms of \(d/\), the goal then is to estimate \(p_{j}\) by placing it in one of these buckets. This can be done by an appropriate thresholding and the Laplace mechanism.

The next step is to obtain a refined estimate of the \(p_{i}\)'s using a fresh batch of samples. The algorithm then returns a sample randomly drawn from the product distribution given by these estimates. The earlier crude estimates are helpful in truncating and clipping the samples to make the produced sample DP, without adding any noise to the refined estimate.

## 3 Preliminaries

For convenience, we use the notation \(_{B}^{p}(X)\) for "truncation" for all \(X^{d},B>0,p 1\):

\[_{B}^{p}(X):=X&\|X\|_{p} B,\\ X B/\|X\|_{p}&\|X\|_{p}>B.\] (1)

Let \([k]\) denote \(\{1,,k\}\). For any \(X^{d}\), we use \(X[j]\) to denote the value of its \(j\)th coordinate.

### Distributions and Tail Bounds

For a discrete distribution \(D\), we use \(f_{D}\) to denote its probability mass function (PMF); for a continuous distribution \(D\), we use \(f_{D}\) to denote its probability density function (PDF). Let \((D)\) denote the support of \(D\). We let \(Z D\) denote that the random variable \(Z\) is distributed according to \(D\); throughout, we may write the random variable in place of the distribution and vice versa when convenient. Finally, when \(D_{1},,D_{d}\) are distributions, we use \(D_{1} D_{d}\) as the product distribution, i.e., the distribution of \((Z_{1},,Z_{d})\) where \(Z_{1} D_{1},,Z_{d} D_{d}\) are independent.

For a distribution \(D\) on \(^{d}\) and \(v^{d}\), we write \(D+v\) as a shorthand for the distribution of \(X+v\) where \(X D\). Furthermore, for a distribution \(D\) and a (possibly randomized) function \(h\), we write \(h(D)\) to denote the distribution of \(h(X)\) where \(X D\).

We will list a few distributions that will be useful for us.

(i) _Shifted Truncated Discrete Laplace Distribution:_ For \(>0\), let \(s(,)=(1+(1/)/)\). We define \((,,)\) to be the discrete distribution supported on \([-2s(,),0]\) such that \(f_{(,,)}(x)\).

It is known that adding \(\) noise to a low-sensitivity function results in a DP estimate [e.g., 22].

**Lemma 3.1**.: _If \(g\) is a function with sensitivity \(\), then the algorithm that outputs \(g()+(,,)\) is \((,)\)-DP._

(ii) _Beta Distribution:_ For \(,>0\), \((,)\) has the PDF \(f_{(,)}(x) x^{-1}(1-x)^{-1}\).

(iii) _Uniform Distribution over Unit Sphere:_ For \(d\), let \(_{d}^{}\) denote the distribution of a random unit vector in \(^{d}\).

(iv) _Projection of Uniform Distribution over Unit Sphere:_ For any \(d\) and \(i[d]\) and \(z^{d}\), let \(_{ i}(z)\) denote \((z_{1},,z_{i})\). Then, let \(_{d,i}^{}\) denote the distribution of \(_{ i}(Z)\) where \(Z_{d}^{}\). This distribution has the PDF (see, e.g., [34, Theorem 2]) given below.

\[f_{_{d,i}^{}}(z)(1-\|z\|^{2})^{-1}&\|z\|^{2}<1\\ 0&\] (2)

We need a tail bound on the \(_{2}\)-norm of a Gaussian-distributed vector:

**Lemma 3.2** ([42, Theorem 6.2]).: _There exists a constant \(c 1\) such that, for any \(^{d}\), \(^{d d}\) where \( I\) and any \((0,)\), \(_{X(,)}[\|X-\|_{2}>c( {d}+)]\)._

We also need a tail bound for the beta distribution:

**Lemma 3.3** (, Theorem 8).: _There exists a constant \(c(0,1)\) such that, for any \(0<<\) and any \(x 0\), we have \(_{Z(,)}[Z+ x] 2e^{-c\{x^{2}}{}, x\}}\)._

The following concentration bound on the empirical covariance will also be helpful.

**Lemma 3.4** ([27, Fact 3.4]).: _There exists a constant \(c 1\) such that for any \( I\), let \(U_{1},,U_{n}(0,)\) and \(=_{i[n]}U_{i}U_{i}^{T}\), we have \([(1-c})  I] 1-\)._

### Differential Privacy

**Hockey Stick Divergence.** We also recall the definition of \(\)_-hockey stick divergence_ between two distributions \(P,Q\): \(d_{}(P Q):=_{y(P)}[f_{P}(y)-e^{ }f_{Q}(y)]_{+}dy,\) where \([a]_{+}:=\{a,0\}\).

The following standard fact about the hockey stick divergence is often useful in proving DP guarantees of algorithms .

**Lemma 3.5**.: _For any \( 0\) and distributions \(P,Q\), \(d_{}(P Q)_{y P}[f_{P}(y)>e^{}f_{Q}(y)]\)._

It will be also useful to keep in mind the "post-processing" property of DP:

**Lemma 3.6**.: _For any distributions \(P,Q\) and any function \(h\), we have \(d_{}(h(P) h(Q)) d_{}(P Q)\)._

**DP under Condition.** Since we will use a "propose-test-release"-style algorithm , it will be convenient to use the notion of "DP under condition" together with its composition properties. The particular definition we use below is from ; similar notions have been used earlier, e.g., in .

**Definition 3.7** (DP under Condition, ).: Let \(:\{0,1\}\) be a predicate. An algorithm \(M:\) is \((,)\)_-DP under condition \(\)_ for \(,>0\) iff, for every \(S\) and every neighboring datasets \(Y,Y^{}\) both satisfying \(\), we have \([(Y) S] e^{}[(Y^{}) S ]+\).

**Lemma 3.8** (Composition for Algorithm with Halting, ).: _Let \(_{1}:_{1}\{\},_{2}: _{1}_{2}\) be algorithms. Furthermore, let \(\) denote the following algorithm: Let \(o_{1}=_{1}(Y)\) and, if \(o_{1}=\), then halt and output \(\) or else, output \(o_{2}=_{2}(o_{1},Y)\)._

_Let \(\) be any condition such that, if \(Y\) does not satisfy \(\), then \(_{1}(Y)\) always returns \(\). Suppose that \(_{1}\) is \((_{1},_{1})\)-DP and \(_{2}\) is \((_{2},_{2})\)-DP under condition \(\). Then, \(\) is \((_{1}+_{2},_{1}+_{2})\)-DP._Gaussian Distribution: Algorithms

**Reduction to the Bounded Mean Case.** As stated earlier, for the cases of known covariance and bounded covariance, we will need a preprocessing step that computes a rough private estimate for the mean. The properties of the reduction are stated below.

**Lemma 4.1**.: _Suppose that there is an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions under the assumption that \(I I,\|\| R\) with sample complexity \(n_{}(,R,,)\). Then, there exists an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions under the assumption that \(I I\) with sample complexity \((}{})+n_{ }(/2,O(),/2,/2)\)._

### Known Covariance

With the reduction in Lemma 4.1, we may assume that \(\|^{-1/2}\| R\). When the covariance is known, we give an algorithm with the following guarantees.

**Theorem 4.2**.: _Assuming \(\) is known and \(\|^{-1/2}\| R\), there is an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions with sample complexity \(O((R+) })})\)._

We assume w.l.o.g. that \(=I\); otherwise, we can consider \(X_{i}^{}=^{-1/2}X_{i}\). Before we describe the algorithm, note that Theorem 4.2 together with Lemma 4.1 implies Theorem 1.2. As stated earlier, the algorithm (Algorithm 1) is simple: take the average of the truncated input samples and add to it (spherical) Gaussian noise.

Proof.: Let \(C 1\) be the constant from Lemma 3.2, \(B=R+10^{4}C)}\), and \(n=1+ 10B/\). Let \(\) be Algorithm 1 with \(B,n\) as specified and \(=\).

**Privacy Analysis.**\(\) is the Gaussian mechanism with noise multiplier \(n/B 10/\); therefore, \(\) is \((,)\)-DP, using (20, Appendix A).

**Accuracy Analysis.** Let \(D=(,I)\) for some unknown \(\). Consider the algorithm \(^{}\) where there is no truncation, i.e., \(^{}\) simply outputs \(Y:=Z+_{i[n]}X_{i}\). Via Lemma 3.2 and a union bound, the truncation is not applied anyway in \(\) (i.e., \(X_{i}=X_{i}^{}, i[n]\)) with probability at least \(1-\). Therefore, \(d_{}(Q_{,D},Q_{^{},D})\). Note that \(^{}\) just outputs \(Y:=Z+_{i[n]}X_{i}\), so we have \(Y(,I)=D\), i.e., \(Q_{^{},D}=D\). Combining these bounds yields \(d_{}(Q_{,D},D)\). 

### Unknown Bounded Covariance

We now move on to the case where both \(,\) are unknown but under the assumption \(I I\). The main result of this section is stated below7. Again, note that Theorem 4.3 and Lemma 4.1 immediately yield Theorem 1.4.

**Theorem 4.3**.: _Assuming \(I I\) for some \(>0\) and \(\|\| R\), there is an \(\)-accurate \((,)\)-DP sampler for Gaussian distributions with sample complexity \(O((R^{2}+^{2}(d+()))).\)_

As stated in the overview, the main challenge lies in the privacy analysis. It will be proved in three steps. First, in Section 4.2.1, we will show that if we add noise that is drawn from projection of random unit vector to the first \(M\) coordinates to a low-(\(_{2}\)-)sensitivity function, then it is DP. Then, in Section 4.2.2, we use this to show that adding noise of the form \(_{i[n]}a[i] w_{i}\) (where \(a_{n}^{}\)) to a low-sensitivity function also suffices for privacy as long as the smallest eigenvalue of \(_{i[n]}w_{i}w_{i}^{T}\) is sufficiently large. Here \(w_{1},,w_{n}\) are assumed to be fixed vectors given beforehand. Note that the noises discussed so far are input _independent_. Finally, in Appendix B.4, we relate this to the 

[MISSING_PAGE_FAIL:9]

**Acknowledgment.** We thank Shyam Narayanan for pointing us to , which improves dependency on \(d\) in the sample complexity for sampling Gaussians with unknown (unbounded) covariance from \(d^{2}\) to \(d^{1.5}\).