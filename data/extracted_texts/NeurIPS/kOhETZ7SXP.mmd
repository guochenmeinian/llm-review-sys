# Seeking Truth and Beauty in Flavor Physics

with Machine Learning

 Konstantin T. Matchev

Institute for Fundamental Theory

Department of Physics

University of Florida

Gainesville, FL 32611

matchev@ufl.edu

&Katia Matcheva

Institute for Fundamental Theory

Department of Physics

University of Florida

Gainesville, FL 32611

matcheva@ufl.edu

Pierre Ramond

Institute for Fundamental Theory

Department of Physics

University of Florida

Gainesville, FL 32611

ramond@phys.ufl.edu

&Sarunas Verner

Institute for Fundamental Theory

Department of Physics

University of Florida

Gainesville, FL 32611

verner.s@ufl.edu

Corresponding and first author; remaining authors have equal contributions.

###### Abstract

The discovery process of building new theoretical physics models involves the dual aspect of both fitting to the existing experimental data and satisfying abstract theorists' criteria like beauty, naturalness, etc. We design loss functions for performing both of those tasks with machine learning techniques. We use the Yukawa quark sector as a toy example to demonstrate that the optimization of these loss functions results in true and beautiful models.

**Murdock:** Rambo, you can feel totally safe because we have the most advanced weapons in the world available to us.

**Rambo:** I've always believed that the mind is the best weapon.

**Murdock:** Times change.

**Rambo:** For some people.

_Rambo: First Blood Part II (1985)_

## 1 Introduction

Ever since ancient times, great technological progress in human society has been accompanied by equally impressive intellectual leaps by the great minds of the previous generations. With the recent boom in artificial intelligence, the machines are beginning to challenge humans even at tasks typically reserved for "deep thinkers". Nowhere is this dichotomy more evident than in the field of theoretical physics, as theoretical physicists like Isaac Newton, Albert Einstein, etc., regularly top the lists of smartest people of all time .

The task of a theoretical physicist is to develop a theory model describing a set of natural physics phenomena. There are two aspects of this process:* _Truth._ Above all, the model has to be truthful, in the sense that it can correctly account for the existing set of measurements of a number of experimental observables \(\{_{}\}\), \(=1,2,,N_{}\). This is accomplished by tuning the model parameters \(\{_{i}\}\), \(i=1,2,,N_{}\), until the model predictions fit the data. This adjustment can typically be done rather easily, since in most models the number of tunable model parameters exceeds the number of available measurements, i.e., \(N_{}>N_{}\).
* _Beauty._ After this fitting procedure, we are typically still left with a number of model parameters (namely, \(N_{}-N_{}\)) which cannot be determined from data. Instead, they can be chosen to make the model more "beautiful". However, this is the point where typically one encounters a number of different opinions (after all, beauty is in the eye of the beholder). Since beauty is an inherently subjective concept, different theorists, guided by their own theoretical prejudices, could easily disagree to what extent a given theory model is "beautiful".

From a machine learning standpoint, there is nothing mysterious about "beauty", as long as it can be quantified, i.e., there exists an agreed-upon beforehand, community-wide quantitative measure indicating the "beauty" of a model. In the past such measures have been introduced to quantify the fine-tuning in new physics models like low-energy supersymmetry [2; 3; 4; 5; 6]. Once a quantitative measure of the model's beauty is adopted, model building becomes a simple optimization problem amenable to machine learning approaches.

In this paper, we focus on the flavor sector, which is arguably the "ugliest" part of the Standard Model. New physics models can therefore offer many opportunities for improvement on the "beauty" scale. We consider several possible choices for quantitative measures of the beauty of the model. In each case, we define corresponding loss functions whose minimization by construction yields "the most truthful and beautiful" model.

Our approach should be viewed as part of a much broader program of trying to learn the laws of nature with a machine, eliminating any human intervention whatsoever [7; 8; 9; 10; 11; 12; 13; 14; 15; 16; 17]. For example, it has been demonstrated that the machine can re-derive the known classical physics laws from data [18; 19; 20; 21]. Symbolic learning was recently successfully applied to problems in a wide range of physics areas, e.g. in astrophysics [22; 19; 23], in astronomy for the study of orbital dynamics [24; 25] and exoplanet transmission spectroscopy , in collider physics [27; 28; 29; 30; 31], in materials science , and in behavioral science . Our approach is slightly less ambitious than those studies, since we already assume the mathematical framework for the description of the phenomena, and instead focus only on the determination of the "best" model parameters which, within that mathematical framework, might have been chosen by nature.

The paper is organized as follows. In Section 2, we introduce our notation and provide the minimal particle physics background needed to understand the results in the sections to follow. Then in Section 3 we consider two examples of "beautiful" quark textures. First, in Section 3.1 we consider beauty to mean uniformity, i.e., the elements in the Yukawa matrices have the same magnitude. Then in Section 3.2 we take beauty to mean sparsity, i.e., the Yukawa matrices have a large number of vanishing elements. Section 4 contains our summary and conclusions.

## 2 Standard Model Parameters

For the most part, we use the notation in the standard textbook . The Lagrangian of the quark mass sector is

\[_{ quarks}\ =\ -Y_{ij}^{d}^{i}Hd_{R}^{j}-Y_{ij}^{u}^ {i}u_{R}^{j}+{ h.c.}\] (1)

Here \(Q^{i}\), \(i=1,2,3\) are the three families of \(SU(2)_{L}\) quark doublets,

\[Q^{i}=(u_{L}^{i}\\ d_{L}^{i}),\] (2)

\(H\) is the Higgs field and \(\) is its conjugate given by

\[ i_{2}H^{*},\] (3)

where \(_{2}\) is the second Pauli matrix and \(*\) denotes complex conjugation. Explicitly,

\[H=(H^{+}\\ H^{0}),=(H^{0*}\\ -H^{-})\,.\] (4)

[MISSING_PAGE_FAIL:3]

The fit results for the magnitudes of all nine CKM elements are

\[|V_{ CKM,exp}|=(0.97435 0.00016&0.22500 0.00067 &0.00369 0.00011\\ 0.22486 0.00067&0.97349 0.00016&0.04182^{+0.00085}_{-0.000070}\\ 0.00857^{+0.00020}_{-0.00018}&0.0410^{+0.0003}_{-0.00072}&0.999118^{+0.00003}_{- 0.000036})\,.\] (13)

In addition to (13), the other inputs in our analysis will be the running quark masses evaluated at some reference energy scale. We choose the top quark mass scale  (other choices of a reference scale are possible as well, for example the \(Z\) mass scale ) and summarize the corresponding values with their experimental uncertainties in Table 1.

## 3 Quark Sector Textures

In this section, we build our loss functions and demonstrate their utility with two examples. The inputs to the original Lagrangian (1) are the Yukawa matrices \(Y^{u}\) and \(Y^{d}\), or equivalently, the corresponding mass matrices \(M_{u}\) and \(M_{d}\), which have a total of 36 degrees of freedom. Out of those, 9+6=15 are fixed by the experimental inputs in Eq. (13) and Table 1. So in principle, we could set this up as an optimization problem in 36 dimensions, subject to 15 constraints. However, to accelerate the optimization, we choose a parametrization for \(M_{u}\) and \(M_{d}\) which manifestly solves the quark mass constraints, namely the inverse relations to (9):

\[M_{u}=U_{u}^{}\,M_{u}^{}\,K_{u}, M_{d}=U_{d}^{}\,M_{ d}^{}\,K_{d}.\] (14)

By taking the diagonal entries in the matrices \(M_{u}^{}\) and \(M_{d}^{}\) to have magnitudes equal to the respective quark masses, the quark mass constraints are automatically satisfied. This leaves us with only 18-3=15 degrees of freedom in each matrix \(M_{u}\) and \(M_{d}\) (to exactly match the count of degrees of freedom between the LHS and the RHS of the equations in (14), we fix two degrees of freedom in each rotation matrix \(U_{u}\), \(U_{d}\), \(K_{u}\) and \(K_{d}\) by hand). In other words, we have equivalently reformulated the problem as optimization in 30 dimensional space subject only to the 9 constraints (13). To ensure that those are satisfied, we choose the following loss function

\[L_{ CKM}\ =\ _{ij}\,(|V_{ CKM}|_{ij}-|V_{ CKM,exp}|_{ij})^{2}\,\,.\] (15)

Each of the two examples below will be illustrated with a number of pseudo-experiments. In each pseudo-experiment, we shall start not with the central values for the inputs in Eq. (13) and Table 1, but with a set of experimental inputs sampled from split normal distributions with the left (right) standard deviation given by the lower (upper) experimental uncertainty on the corresponding experimental quantity. In what follows, we choose to quote our results in terms of the mass matrices \(M_{u}\) and \(M_{d}\) rather than the dimensionless Yukawas \(Y^{u}\) and \(Y^{d}\).

### Uniform Texture

The origin of the Yukawa matrices \(Y^{u}\) and \(Y^{d}\) is one of the major unresolved puzzles in the Standard Model (SM). This so-called flavor problem is an active area of theoretical research for the past 50 years. Many proposed solutions for these "Yukawa textures" exist on the market, and they typically involve new symmetries, new particles and new interactions. Ultimately, the fate of these new physics models will be decided by experiment, by either finding or ruling out those additional structures. Here we consider a bottom-up approach within the SM as an effective theory, where the only experimental measurements available to us are those of Eq. (13) and Table 1. In that case, our only guiding principle in choosing one model over the other is whether the resulting Yukawa sector is "beautiful" or not.

As a warm-up exercise, let us declare that a "beautiful" flavor model is one which predicts uniformity, i.e., all elements in a given Yukawa matrix have (roughly) equal magnitudes, e.g.

\[|Y^{u}_{ij}||Y^{u}_{kl}|\,, i,j,k,l\,.\] (16)

  \(m_{u}\) (MeV) & \(m_{d}\) (MeV) & \(m_{c}\) (GeV) & \(m_{s}\) (MeV) & \(m_{b}\) (GeV) & \(m_{t}\) (GeV) \\  \(1.22^{+0.28}_{-0.15}\) & \(2.76^{+0.28}_{-0.10}\) & \(0.59^{+0.01}_{-0.01}\) & \(52^{+4.79}_{-1.89}\) & \(2.75^{+0.02}_{-0.01}\) & \(162.9^{+0.28}_{-0.28}\) \\  

Table 1: Quark masses (with uncertainties) evaluated at the top quark mass scale.

This condition can be enforced by introducing the following loss function

\[L_{ const,up}\ =\ _{i,j,k,l}(|Y^{u}_{ij}|-|Y^{u}_{kl}|)^{2}\,.\] (17)

Similarly, uniformity for the down-type Yukawa matrix implies

\[|Y^{d}_{ij}||Y^{d}_{kl}|\,, i,j,k,l\,,\] (18)

and the corresponding loss function is

\[L_{ const,down}\ =\ _{i,j,k,l}(|Y^{d}_{ij}|-|Y^{d}_{kl}|)^{2}\,.\] (19)

Therefore, the full loss function for the uniform Yukawa textures is given by

\[L_{ uniform}\ =\ L_{ CKM}+}L_{ const,up}+ }L_{ const,down}\,,\] (20)

where we normalized the loss functions \(L_{ const,up}\) and \(L_{ const,down}\) with respect to the heaviest quarks to ensure that all three contributions in the loss function have similar weights. We perform \(10\) pseudoexperiments and minimize the full loss function (20). The results are shown in Fig. (1), where in addition to the trained values for the total loss we also list the individual contributions (15), (17) and (19). We observe that in each pseudo-experiment we are able to achieve very small values for the loss, indicating viable Yukawa textures.

For illustration, we quote one particular result from the \(10\) pseudoexperiments (the others are very similar). For the up-type quark mass matrix, we find

\[M_{u}\ =\ 37.4241+39.2292i&-18.2387+51.0572i&-52.4459-13.7506i \\ 37.9035+38.9229i&-17.2426+51.3899i&-52.6902-12.9535i\\ 42.4129+33.5949i&-11.5970+52.9758i&-53.7599-6.6929i\,,\] (21)

and

\[|M_{u}|\ =\ 54.3452&54.3444&54.3459\\ 54.4079&54.2766&54.3340\\ 54.2823&54.4144&54.3556\,.\] (22)

Similarly, for the down-type mass matrix \(M_{d}\), we obtain

\[M_{d}\ =\ 0.3461-0.8576i&0.5714+0.7318i&0.2355+0.8896i \\ 0.2747-0.8801i&0.6929+0.6161i&0.3569+0.8483i\\ 0.2450+0.8938i&-0.9014-0.2191i&-0.7375-0.5554i\,,\] (23)

Figure 1: The values for the trained total loss (20) and the breakdown of the three individual contributions (15), (17) and (19), in 10 representative pseudo-experiments for the uniform texture exercise considered in Section 3.1.

and

\[|M_{d}|\ =\ 0.9238&0.9260&0.9210\\ 0.9238&0.9251&0.9218\\ 0.9233&0.9251&0.9226\.\] (24)

We pictorially illustrate the results from this pseudo-experiment in Fig. 2, where the top panels correspond to (21) and the bottom panels correspond to (23). In each row, the first two panels on the left show the real and imaginary part of the respective matrix element, while the last two panels show its magnitude and phase. We see that in each mass matrix, the magnitudes of the different elements are equal to a very good approximation, which was the criterion for "beauty" in this example.

### Zero Textures

For our second example, we shall consider the so-called zero textures , where the "beauty" of the model is measured in terms of sparsity. The idea is to have as many vanishing elements in the Yukawa matrices as possible. In our study, we shall take the number of such vanishing elements \(N\) as a hyperparameter whose value can be varied, see Table 2.

Once we fix the value of \(N\), we still have the freedom to choose exactly which \(N\) elements in the matrix are zero. In general, the number of such patterns is given in the second row of Table 2, but some of them are unacceptable because they automatically result in at least one zero mass eigenvalue. The number of remaining, potentially acceptable, patterns is listed in the last row of the table.

For the purposes of this study, we focus on a few representative examples shown in Fig. 3, where circles indicate the locations of the matrix elements which are required to vanish. Let \(\) represent the set of zero locations in a given pattern, e.g., \(=\{11,22,13\}\) for the first \(N=3\) pattern in Fig. 3. The corresponding loss functions are then given by

\[L_{}\ =\ _{ij}|Y_{ij}^{u}|^{2}\,,\] (25)

   N & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\  All patterns & 9 & 36 & 84 & 126 & 126 & 84 & 36 & 9 \\  Acceptable & 9 & 36 & 78 & 81 & 36 & 6 & 0 & 0 \\   

Table 2: For a given number \(N\) of vanishing elements in the mass matrix (top row), the total number of patterns (middle row) and the number of potentially acceptable patterns (bottom row).

Figure 2: The learned mass matrices \(M_{u}\) (top panels) and \(M_{d}\) (bottom panels) for the uniform Yukawa texture example considered in Sec. 3.1. Each panel represents a learned matrix, where the values of the individual elements of the matrix are indicated by the color bar.

and

\[L_{ zeros,down}\ =\ _{ij}|Y_{ij}^{d}|^{2}\,.\] (26)

We then minimize the full loss function

\[L\ =\ L_{ CKM}+}L_{ zeros,up}+}L_{ zeros, down}\,.\] (27)

Once again, we find that viable patterns result in low loss values. In complete analogy to Fig. 1, in Fig. 4 we show the values of the trained loss and its components, for the 10 \(N=3\) zero texture patterns in Fig. 3, averaged over 10 different pseudo-experiments. As expected, all of the \(N=3\) zero texture patterns are possible. The result from one pseudo-experiment for the very first pattern in Fig. 3 is given by

\[M_{u}\ =\ (0.0001-0.0008i&-0.2209-0.0169i&0.0000+0.000 0i\\ -0.8953-0.1084i&0.0000+0.0000i&-9.2195+1.1346i\\ 15.4244+3.1818i&9.4056+0.7511i&161.3240-6.3096i)\] (28)

and

\[M_{d}\ =\ (-0.0000+0.0000i&-0.0167+0.0105i&0.0000 0+0.0000i\\ -0.0068-0.0008i&-0.0000+0.0000i&-0.0724+0.0027i\\ 0.5029+0.0106i&2.1104-0.7527i&1.5131-0.1968i).\] (29)

Figure 4: The same as Fig. 1, but for the 10 \(N=3\) zero texture patterns in Fig. 3, averaged over 10 different pseudo-experiments.

Figure 3: The zero texture patterns considered in the example of Sec. 3.2.

This result is pictorially illustrated in Fig. 5 and confirms that the entries in positions 11, 22 and 13 are very small (see the third panels in each row).

The results for higher values of \(N\) are summarized in Fig. 6, where we plot the values of the trained loss averaged over both the number of pseudo-experiments (in this case 10) and the different patterns in Fig. 3 corresponding to that particular value of \(N\). Judging by the values of the loss, we conclude that zero textures with \(N=3,4,5\) are possible, while the two patterns with \(N=6\) are ruled out.

## 4 Summary and Conclusions

In the realm of scientific inquiry, the process of developing novel theoretical physics models entails meeting the objective demands of the existing experimental data, as well as the subjective criteria like beauty and naturalness set forth by the theoretical physics community. To achieve both of these objectives, we employ machine learning techniques with suitably designed loss functions addressing the perceived deficiencies in the Yukawa sector of the Standard Model. With a couple of toy examples, we showed that this approach yields models that are not only consistent with the experimental data, but also possess the desired aesthetic elegance as defined by a quantitative benchmark.