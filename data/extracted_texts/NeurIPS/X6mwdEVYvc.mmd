# Stochastic Approximation Algorithms

for Systems of Interacting Particles

 Mohammad Reza Karimi

ETH Zurich

mkarimi@inf.ethz.ch &Ya-Ping Hsieh

ETH Zurich

yaping.hsieh@inf.ethz.ch &Andreas Krause

ETH Zurich

krausea@ethz.ch

###### Abstract

Interacting particle systems have proven highly successful in various machine learning tasks, including approximate Bayesian inference and neural network optimization. However, the analysis of these systems often relies on the simplifying assumption of the _mean-field_ limit, where particle numbers approach infinity and infinitesimal step sizes are used. In practice, discrete time steps, finite particle numbers, and complex integration schemes are employed, creating a theoretical gap between continuous-time and discrete-time processes. In this paper, we present a novel framework that establishes a precise connection between these discrete-time schemes and their corresponding mean-field limits in terms of convergence properties and asymptotic behavior. By adopting a dynamical system perspective, our framework seamlessly integrates various numerical schemes that are typically analyzed independently. For example, our framework provides a unified treatment of optimizing an infinite-width two-layer neural network and sampling via Stein Variational Gradient descent, which were previously studied in isolation.

## 1 Introduction

Dynamics of interacting particle systems are central to many challenges in modern machine learning. These range from algorithm design for approximate Bayesian inference, to the study of equilibria in games . Moreover, researchers have gained valuable insights by interpreting the training process of over-parametrized two-layer neural networks as a system of interacting particles, thereby advancing our intuition in this domain .

Analyzing the behavior of such systems poses a significant challenge. To simplify the analysis, researchers often turn to the concept of the _mean-field limit_. In this approach, the number of particles is increased to infinity, the step-size of the algorithm shrinks to zero, and results are deduced from this continuous limit. Specifically, an initial probability distribution is assigned to the infinitely many particles, and a continuous-time evolution is derived for this distribution. The resulting evolutionary equation serves as a powerful tool for gaining insights into the system's asymptotic behavior, significantly aiding in the comprehension of systems with a large number of interacting particles .

Although the mean-field limit has offered valuable insights into the aforementioned problems, its rigorous justification necessitates examining systems with both a _finite_ number of particles and the _discrete-time algorithms_ commonly used in practice. Unfortunately, to the best of our knowledge, while a substantial body of work exists on finite-particle systems (see, e.g., the review papers  and references therein), these studies are confined to analyzing continuous-time dynamics. As a result, a gap between theory and practice has emerged, and a precise link between continuous and discrete-time schemes is still largely lacking.

SS Contributions.Our paper aims to bridge this gap by rigorously establishing the convergence of discrete-time algorithms to their continuous-time counterparts in terms of long-term behavior.

To accomplish this, we draw inspiration from the field of _dynamical system_ theory, which traces its origins back to early developments in statistics  and has recently found success in various domains of machine learning, including optimization theory, games, and sampling [21; 23; 24].

This dynamical system framework offers two significant advantages. Firstly, it provides a flexible framework capable of accommodating a wide range of practical schemes commonly employed in real-world scenarios. Secondly, this framework enables a unified treatment of various machine learning tasks that were previously studied in isolation. Notably, it allows us to address tasks such as training neural networks and approximate Bayesian inference using techniques like Stein variational gradient descent in a coherent and unified manner.

In summary, our paper makes the following contributions:

1. We introduce a comprehensive framework for analyzing a broad class of algorithms called _stochastic approximation schemes_. These schemes are widely utilized in simulating systems of interacting particles, and our framework provides a unified approach to analyze their behavior.
2. Under mild assumptions on the discrete-time schemes and the mean-field dynamics, we prove the convergence of these schemes towards their respective mean-field limits. The convergence is established in terms of the _2-Wasserstein distance_, a metric commonly used to measure the dissimilarity between probability distributions.
3. Since our framework is specifically tailored to address a wide range of fields, we instantiate our main theorem and provide novel guarantees to a diverse array of interacting particle systems across domains such as the Stein variational gradient descent, the training of wide two-layer neural networks, and the examination of game equilibria.

## 2 Illustration: Training Two-Layer Neural Networks via Noisy SGD

To illustrate the particle system under study and its corresponding mean-field limit, let us consider the example of training a two-layer neural network with \(N\) neurons and squared loss using the noisy SGD algorithm. The network takes an input \(z^{d-1}\) and computes function:

\[h_{}(z)_{i=1}^{N}(^{i},z), ^{i}=(a^{i},b^{i})^{d-1}(^{i},z)=b^{i}\,( a^{i},z ).\]

Here, \(=(^{1},,^{N})\) denotes the collection of neurons' parameters, and \(\) is an activation function (such as sigmoid or tanh). To train this network, one ideally minimizes the regularized risk \(L()_{(y,z)}(y-h_{ {}}(z))^{2}+\,U()\), where \(\) is the data distribution, and \(U()=_{i}U(^{i})\) is a regularizer, such as \(U()=||^{2}\). Applying the noisy gradient descent algorithm to the regularized risk then results in the update rule:

\[^{i}_{k+1}=^{i}_{k}-_{k+1}_{^{i}}L( _{k})+}\,^{i}_{k+1}, i=1,,N,\] (SGD \[{}_{}\] )

where \(_{k+1}\) is the step-size, \( 0\) is the noise level, and \(\{^{i}_{k+1}\}\) is a collection of i.i.d. standard Gaussians. To cast this algorithm as a system of interacting particles, we define the _interaction kernel_\(W\) and the _potential_\(V\) as

\[W(,^{})=_{z}[(,z) (^{},z)] V()=_{( y,z)}[y\,(,z)]+\,U().\] (1)

It is then easily seen (cf. (36, Eqn. 4)) that the update rule (SGD\({}_{}\)) can be rewritten as

\[^{i}_{k+1}=^{i}_{k}-_{k+1}_{j=1}^{N} _{}W(^{i}_{k},^{j}_{k})+ V(^{i}_{k}) +}\,^{i}_{k+1}, i=1,,N.\] (2)

By considering neurons as particles, the equation (2) reveals that the training dynamics of each particle is influenced by the potential \(V\) and the interaction energy \(W\) with other particles. This interpretation highlights that (SGD\({}_{}\)) represents the evolution of a system of interacting particles. In a broader context, one may consider more sophisticated algorithms, several of which (see Section 4 for examples) can be formulated as

\[^{i}_{k+1}=^{i}_{k}-_{k+1}_{^{i}}L(_{k})+P^{i}_{k+1}+}\,^{i}_{k+1},  i=1,,N\] (3)

where \(P^{i}_{k+1}\) is the (random or deterministic) perturbation in evaluating the gradient. These algorithms are usually called _stochastic approximation algorithms_. For example, Noisy SGD corresponds to setting \(P^{i}_{k+1}=_{^{i}}(_{k})-_{ ^{i}}L(_{k})\), where \(\) is the loss of a random batch of data.

S Continuous-time limit and the mean-field approximation.We now go from the discrete-time algorithm (3) to a continuous-time process and then derive the mean-field approximation. First, observe that the risk \(L()\) depends on \((^{1},,^{N})\) only through their _empirical measure_\(=_{i}_{^{i}}\). For example,

\[_{j=1}^{N}_{}W(,^{j})+ V() =_{}W(,^{})\;(d^{ })+ V() b(,),\] (4)

where we have introduced the _drift_ function \(b\). To simplify the analysis, previous studies then consider the idealized setting where an infinitesimal step-size is employed, thereby further reducing (3) to the following system of stochastic differential equations (SDEs):

\[d^{i}_{t}=b(^{i}_{t},_{t})\;dt+\,dW^ {i}_{t}, i=1,,N,\] (5)

where \(_{t}=_{i}_{^{i}_{t}}\) is the empirical measure of the particles at time \(t\), and \(\{W^{i}_{}\}\) is a collection of i.i.d. standard Brownian motions. In the over-parametrized regime where the number of particles \(N\) becomes very large, one can approximate the initial setting of the particles \(_{0}\) with a probability density \(_{0}\), and consider the following _mean-field_ approximation defined over \(^{d}\) as

\[d_{t}=b(_{t},_{t})\;dt+\,dW_{t},_{t}= (_{t}).\] (6)

This dynamics captures the behavior of an individual particle \(\) within a density of particles distributed according to \(\). The analysis of (6) turns out to be considerably simpler compared to the system of SDEs in (5), e.g., via studying the evolutionary PDE \(_{t}_{t}=(_{t}\,b(,_{t}))+^{2} _{t}\). As a result, it has attracted significant interest in the field of deep learning theory .

In conclusion, the mean-field dynamics (6) offers a powerful and elegant framework, but its validity rests on two simplifying assumptions: an infinite number of particles and a step-size approaching zero. A rigorous justification of these two steps is by no means trivial. While the existing literature has made progress in addressing the infinite particle issue, the second assumption has received comparatively less attention. Bridging this gap is one of the primary objectives of our paper. Specifically, we aim to establish the Wasserstein convergence of the discrete-time dynamics (3) to the same limit sets1 as the continuous-time particle dynamics (5), under mild conditions on the drift \(b\) and perturbations \(\{P^{i}_{k+1}\}\), as well as the step-size rule \(_{k+1}\).

## 3 Dynamics of Systems of Interacting Particles

This section presents the fundamental master theorem that forms the basis for all the applications discussed in Section 4. Our objectives are two-fold. Firstly, we aim to provide a set of assumptions for the discrete-time scheme that can be easily verified by practical algorithms. Secondly, we establish a set of assumptions on the _mean-field_ dynamics, which, as demonstrated in Section 4, are readily implied by the standard assumptions in the _finite particle_ regime. The key result of our paper asserts that, under these assumptions, any discrete-time scheme converges to its continuous counterpart, thus closing the existing theoretical gap.

### The algorithmic template

In this paper, we study the _stochastic approximation algorithms_ for simulating systems of interacting particles of the form:

\[x^{i}_{k+1}=x^{i}_{k}+_{k+1}b(x^{i}_{k},_{k})+P^ {i}_{k+1}}+}(x^{i}_{k},_{k})\; ^{i}_{k+1}, i=1,,N,\] (SAA)

where \(b:^{d}_{2}(^{d})^{d}\) is the (non-local) drift,2\(:^{d}_{2}(^{d})^{d  d}\) is the (state-dependent and non-local) diffusion coefficient, \(P^{i}_{k+1}\) is the noise and bias in evaluating the drift, and \(_{k}\) is the empirical measure of the particles at iteration \(k\). The system (SAA) can be written in a more succinct way by stacking all the variables in a larger vector. That is, define \(x(x^{i})_{i[N]}(^{d})^{ N}\), and let \(_{x}\) be the empirical distribution corresponding to the \(N\) vectors in \(x\), and define the _aggregated drift and diffusion terms_ as

\[(x)(b(x^{i},_{x}))_{i[N]}(^{d})^{ N}, (x)(((x^{i},_{x}))_{i[ N]}).\] (7)

Define \(\{P_{k+1}\}\) and \(\{_{k+1}\}\) analogously. We can then rewrite (SAA) as:

\[x_{k+1}=x_{k}+_{k+1}\{(x_{k})+P_{k+1}\}+}\,(x_{k})\,_{k+1}.\] (PSAA)

### Dynamical system theory

By considering infinitesimal step-sizes and neglecting the perturbations \(P^{i}_{k+1}\), we can derive a system of corresponding SDEs as follows:

\[dX^{i}_{t}=b(X^{i}_{t},_{t})\;dt+(X^{i}_{t},_{t} )\;dW^{i}_{t}, i=1,,N,_{t}=_{i} _{X^{i}_{t}},\] (Sys-SDE)

with the corresponding aggregated version

\[dX_{t}=(X_{t})\;dt+(X_{t})\;dW_{t}.\] (PSDE)

It is important to emphasize that even though we have rearranged the particles into a unified vector and introduced the concepts of aggregated drift and diffusion, the original process retains its _exchangeability_. This property implies that the distribution of \(X^{i}_{t}\) in (Sys-SDE) remains invariant under permutations of the particles (for further details, refer to [8, Def. 2.1]).

The primary objective of our paper is to rigorously establish the convergence of the stochastic approximation scheme (PSAA) to its continuous-time counterpart (PSDE). To accomplish this, we employ the _dynamical system_ theory introduced by Benaim and Hirsch . First, we construct a continuous-time _interpolated process_ associated with the discrete-time algorithm (PSAA):

\[X_{t}=x_{k}+(t-_{k})((x_{k})+[P_{k+1}_{t}])+(x_{k})(W_{t}-W_{_{k}}),_{k} t< _{k+1}.\] (Int)

Here, \(_{k}=_{j=1}^{k}_{j}\) represents the cumulative time until step \(k\). It is worth noting that we construct (Int) in such a way that it is adapted to the same filtration \((_{t})\) as the Brownian motion.

To compare (PSAA) with (PSDE), we integrate (PSDE) using the following approach: For a fixed \(t 0\), we define \(W^{(t)}_{s}=W_{t+s}-W_{t}\) and denote the solution of (PSDE) as the _flow_:

\[^{(t)}_{s}=X_{t}+_{0}^{s}(^{(t)}_{u})\;du+_{0}^ {s}(^{(t)}_{u})\;dW^{(t)}_{u}.\] (Flow)

It is important to observe that the flow _starts at \(X_{t}\)_ and continues according to the true SDE.

We now introduce the central concept in our paper, which is the _asymptotic pseudotrajectory_ theory of Benaim and Hirsch .

**Definition 1** (Wasserstein asymptotic pseudotrajectory).: We say the stochastic process \((X_{t})_{t 0}\) is a _Wasserstein asymptotic pseudotrajectory_ (WAPT) of the flow \(\) if for any fixed \(T>0\),

\[_{t}_{0 s T}_{2}(X_{t+s},^{(t)}_{s})=0,\] (8)

where \(_{2}(,)\) denotes the 2-Wasserstein distance between two distributions.

The notion of WAPT provides a measure of "asymptotic closeness" between two stochastic processes. In particular, (8) requires that \((X_{t})_{t 0}\) closely tracks the flow \(^{(t)}_{s}\) over arbitrarily long time intervals \(T\) with arbitrary precision. The key aspect of the WAPT is that it serves as a tool specifically designed to establish the convergence of a stochastic approximation scheme to its continuous-time counterparts. In particular, it is known that proving the convergence of a stochastic approximation algorithm (PSAA) to its continuous-time counterparts (PSDE) can be accomplished by demonstrating the following two conditions :

* The interpolation (Int) satisfies the WAPT condition with respect to the corresponding flow.
* The iterates \(\{x_{k}\}_{k}\)'s in (PSAA) have bounded second moments.

Below, we present a set of general conditions that are straightforward to verify and ensure the satisfaction of the above two conditions.

_Remark_.: There are two major reasons for choosing \(_{2}\) as the distance in (8): Firstly, the 2-Wasserstein space is a _metric space_ on which McKean-Vlasov equations can be seen as a _flow_, both aspects indispensable for invoking the dynamical system theory of Benaim and Hirsch . Secondly, it is a popular metric in the propagation of chaos literature. This allows a seamless transition from convergence guarantees for stochastic approximation schemes to their mean-field limit counterparts via combining our results with the propagation of chaos results in the literature, see (13).

### Technical Assumptions

We proceed to present our technical assumptions and discuss their generality.

SS On the mean-field dynamics.We begin by introducing three assumptions that pertain to the drift and diffusion coefficients of the continuous-time dynamics (Sys-SDE):

**Assumption 1** (Lipschitzness of drift and diffusion).: _There is some \(L>0\) such that for all \(x,y^{d}\) and all \(,_{2}(^{d})\),_

\[|b(x,)-b(y,)|+\|(x,)-(y,)\|_{F} L(|x-y|+_{2}(,)).\]

**Assumption 2** (Drift growth condition).: _For all \(_{2}(^{d})\), there is some \(C_{}>0\) such that_

\[ x,b(x,)(dx) C_{}(|x|+1 )(dx).\]

**Assumption 3** (Boundedness of the diffusion).: _There is some \(K>0\) such that for all \(x^{d}\) and all \(_{2}(^{d})\), \(\|(x,)\|_{F} K\)._

We note that the first assumption is standard and is commonly used to prove existence of strong solutions for the mean-field equation (see (26, Thm. 3.3)). The other two assumptions are exceedingly weak and are satisfied by all the applications we consider.

SS On the stochastic approximation schemes.The following assumptions concern the time-discretization scheme and the induced noise and bias.

**Assumption 4** (Noise and bias).: _The perturbation \(P_{k+1}\) decomposes into noise and bias as \(P_{k+1}=U_{k+1}+_{k+1}\), where the noises \(\{U_{k+1}\}\) form a martingale difference sequence, i.e., \([U_{k+1}\,|\,U_{k}]=0\), and have second moments uniformly bounded by \(M_{U}\). In addition, the bias terms satisfy \(_{k}_{_{k}}\) and_

\[[|_{k+1}|^{2}\,|\,_{_{k}}]=( _{k+1}^{2}|(x_{k})|^{2}+_{k+1}).\] (9)

**Assumption 5** (Step-sizes).: _The step-sizes are decreasing and satisfy the Robbins-Monro summability conditions_

\[_{k}_{k+1}=_{k}_{k+1}^{2}<.\] (10)

_Moreover, we require, for some constant \(P>0\),_

\[_{k+1}/_{k}+P_{k}_{k+1} 1-_{k+1}.\] (11)

The condition specified in equation (9) is algorithm-dependent, and as we will prove in Section 4, it is satisfied by numerous practical schemes. In Assumption 5, equation (10) is a commonly used condition in the literature , while (11) imposes a mild growth condition on the step size, which remains satisfied even for slowly-decreasing step-sizes such as \(_{k+1}(\, k)^{-1}\). Therefore, this condition is not overly restrictive and accommodates a wide range of scenarios.

SS On dissipativity.In the context of dynamical system theory, it is important to ensure that the iterates of stochastic approximation schemes have bounded second moments. In the literature, this requirement is often met by imposing _dissipativity_-type conditions. Building upon this concept, we introduce the following definition:

**Definition 2** (Average Dissipativity).: We call the drift \(b\) to be _\((,)\)-dissipative on average_ for some \(>0\) and \(\), if for all probability measures \(_{2}(^{d})\), it holds

\[ x,b(x,)(dx)-|x|^{2}\,(dx) +.\]

The concept of average dissipativity, as introduced in Definition 2, provides a novel formulation specifically designed to capture the dissipativity property of a drift function that depends on _measures_, as in equation (Sys-SDE). In contrast to the traditional notion of dissipativity , which focuses on the dissipative behavior of _individual_ particles in isolation, this formulation allows for a more fine-grained control over the _collective_ behavior exhibited by \(N\) particles, each running in parallel with the same stochastic approximation scheme. In Section 4, we will provide concrete examples from the applications of machine learning to demonstrate the satisfaction of average dissipativity.

### Main Results

We are now ready to state our main theorem, whose proof can be found in Appendix B.

**Theorem 1**.: _Consider the algorithm (SAA), where the drift \(b\) and diffusion \(\) satisfy Assumptions 1-3, and the step-sizes \(\{_{k+1}\}\) and the perturbations \(\{P^{i}_{k+1}\}\) satisfy Assumptions 4 and 5. Then the following holds:_

* _The interpolation (_Int_) of iterates of the algorithm is a WAPT of the flow in (_Flow_)._
* _Moreover, if the drift_ \(b\) _is dissipative on average (see Definition_ 2_), the iterates of (_PSAA_) are bounded in second moments, and their limit set is included in that of the original SDE (_PSDE_)._

Proof sketch.: The main step of the proof is the construction of the _Picard process_, which is inspired by  and defined as follows:

\[_{s}^{(t)}=X_{t}+_{0}^{s}(X_{t+u})\,du+_{0}^{s}(X_{t+u}) \,dW_{u}^{(t)}\,.\] (Picard)

The proof is completed in four steps: first, we prove that the Picard process closely tracks the flow (Flow), and then we bound the distance between the Picard process and the interpolation (Int). By using martingale convergence arguments, employing our assumption on bias Assumption 4, and Gronwall inequality, we conclude the proof of the WAPT property. Lastly, we show that dissipativity on average ensures a uniform bound on the second moments of the iterates. The convergence is then implied by invoking [23, Theorem 3]. 

In summary, according to Theorem 1, the convergence of the stochastic approximation scheme in (SAA) can be reduced to its continuous-time counterpart in (Sys-SDE) when the assumptions stated in Section 3.3 are satisfied.

Our Theorem 1 can be combined with existing results in the finite particle regime to establish the overall convergence towards the desired mean-field limit. To see this, let \(M_{t}^{i,N}\) be \(N\) independent processes, synchronously coupled with (Sys-SDE), each starting from \(X_{0}^{i}\) and following

\[dM_{t}^{i,N}=b(M_{t}^{i,N},_{t})\,dt+(M_{t}^{i,N},_{t})\,dW_{t}^{i,N}\,,\]

where \(_{t}\) is the _mean-field solution_. A common phenomenon in the study of interacting particle systems, known as _uniform propagation of chaos_, implies the existence of a constant \(C\) such that for every \(N\):

\[_{t 0}_{i=1}^{N}_{2}^{2}(X_{t}^{i,N},M_{t}^ {i,N}),\] (12)

where \(X_{t}^{i,N}\) represents the particles following the continuous-time dynamics in (Sys-SDE). Letting \(_{}\) represent the limit of the mean-field equation, a straightforward application of the triangle inequality argument, which we defer to Appendix B.2, yields:

\[_{k}_{i=1}^{N}_{2}^{2}(x_{k}^{i},_ {}) 0 N.\] (13)

In other words, as the number of particles approaches infinity, the law of the empirical distribution of the particles following the discrete-time algorithm (SAA) also converges to the mean-field solution.

SS A note on the literature.The rich body of literature on McKean-Vlasov SDEs and interacting particle systems offers considerable insights on the convergence of Euler-Maruyama and Milstein type numerical schemes to their limiting mean-field equations, e.g., . However, it is noteworthy that our study diverges in several key respects: Firstly, our work emphasizes on generic _stochastic_ and _biased_ drift oracles. This contrasts with the deterministic and unbiased drift oracles considered in the aforementioned studies, making our algorithmic approach broader in scope. Secondly, while those studies present strong finite-time error bounds, our convergence results focus on providing asymptotic guarantees. Lastly, we incorporate different underlying assumptions. For instance, we need global Lipschitz drifts to ensure globally integrable flows, while one-sided Lipschitz drifts are allowed in the works by . However, our growth condition in Assumption 2 requires control on average, whereas the works mentioned assume stronger pointwise controls.

In the light of these distinctions, we believe that our work complements this body of literature.

Applications

The goal of this section is to demonstrate the wide-ranging applicability of our framework across diverse domains such as machine learning, game theory, and physics, which were previously analyzed in isolation. In each of these applications, we demonstrate that standard assumptions in their respective domains meet the necessary conditions to invoke Theorem 1. All proofs are deferred to Appendix C.

### Two-Layer Neural Networks and Mean-Field Langevin

Our first application is providing a rigorous guarantee for the training dynamics of wide two-layer neural networks as alluded to in Section 2. To begin, let us quickly recall the notations therein: The noisy SGD iterates in (SGD\({}_{}\)) for wide two-layer neural networks can be viewed as approximations of the mean-field dynamics (6) through the discrete-time system (SAA), whose drift term \(b(,)\) is defined in (1). The corresponding continuous-time and finite-particle dynamics is (5), which has been extensively studied in recent years; see [11; 12; 36; 37; 38; 46; 51] and references therein. Under the standard assumptions as in [11; 12; 37], a simple application of Theorem 1 then yields the convergence of (SGD\({}_{}\)):

**Corollary 1**.: _Let \(()\) denote the activation function. Assume that (1) \(\) and \(^{}\) are Lipschitz and bounded, (2) the data has bounded support, and (3) \(|a\,^{}(a)|\) is bounded. Then the discrete-time scheme (SGD\({}_{}\)) converges in \(_{2}\) to the same limit sets as the continuous-time (5)._

The mean-field dynamics for two-layer neural networks converges to a stationary point in Wasserstein space due to its gradient flow structure . In addition, it is known that under fairly mild assumptions, the resulting limit becomes a unique _global_ risk minimizer . By employing uniform propagation of chaos for neural networks , it is observed that the limit sets of the continuous-time \(N\)-particle dynamics exhibit similar generalization error to the global minimizer. Remarkably, Corollary 1 validates that noisy SGD and other discretizations following template (SAA) eventually converge to this limit set, providing justification for the observed generalization behavior in neural networks.

SS Comparison to prior work.Our result above cannot be directly compared to the existing analysis conducted on the discrete-time scheme (SGD\({}_{}\)), namely , due to the assumption A1 therein, which excludes step-size rules of the form \(_{k+1} k^{-}\) where \((1/2,1]\). Conversely, the bounds provided in  for a _constant_ step-size are non-asymptotic (albeit doubly-exponential), resulting in stronger conclusions compared to our asymptotic results. Therefore, these two analyses complement each other and contribute to a more comprehensive understanding of the training dynamics exhibited by neural networks.

### Stein Variational Gradient Descent

Sampling from a distribution \( e^{-V}\) is a crucial task in various machine learning applications. An effective method that has demonstrated practical success in this regard is the _Stein variational gradient descent_ (SVGD) [29; 30]. Intuitively, this method emulates the steepest descent for the KL divergence in _continuous-time_ with a _continuous probability measure_. In practice, the algorithm is implemented as an interacting particle system as follows (see  for a derivation). Let \(K:^{d}^{d}\) be a _positive definite kernel_. The SVGD algorithm updates the set of \(N\) particles as

\[x_{k+1}^{i}=x_{k}^{i}-}{N}_{j=1}^{N}(K(x_{k}^{i},x _{k}^{j}) V(x_{k}^{j})-_{2}K(x_{k}^{i},x_{k}^{j})), i =1,,N,\] (SVGD \[{}_{k}\] )

where \(_{2}K\) is the gradient of \(K\) with respect to its second input. The corresponding continuous-time dynamics is then:

\[X_{t}^{i}=_{j}_{2}K(X_{t}^{i},X_{t}^{j})- _{j}K(X_{t}^{i},X_{t}^{j}) V(X_{t}^{j}), i=1, ,N,\] (SVGD \[{}_{t}\] )

which is a special case of (Sys-SDE) with \(b(x,)=(_{2}K*)(x)-(K*( V))(x)\) and \( 0\) (no diffusion), where \(*\) denotes the convolution operator. We now prove:

**Corollary 2**.: _Suppose that (1) \( V(x)\) is Lipschitz, (2) \(V\) is dissipative,3 (3) for some \(C>0\), \(| V(x)| C(1+|x|^{2})\), (4) \(\|K\|_{},\|_{2}K\|_{},\|^{2}K\|_{}<\), (5) \(|_{2}K(x,y)|/|x-y|\), and (6) \(K(x,y)/|x-y|^{2}\) for some \(>0\). Then the iterates in (SVGD\({}_{k}\)) converge in \(_{2}\) to the same limit sets as the continuous-time process (SVGD\({}_{t}\))._

Similar to neural networks training discussed in Section 4.1, the mean-field SVGD also exhibits a gradient flow structure, and in this case, the target distribution \(\) serves as the only limit set for the mean-field SVGD . Combining Corollary 2 with a uniform propagation of chaos argument for SVGD then confirms that the iterates of (SVGD\({}_{k}\)), or any discretization of (SVGD\({}_{t}\)) that satisfies Assumption 4, effectively converge to a distribution that closely approximates \(\) in terms of \(_{2}\). This outcome underscores the effectiveness of these algorithms in sampling.

SS Comparison to prior work.While there has been extensive theoretical work on the convergence of SVGD, most of it focuses on either the _population limit_ (i.e., when \(N\) in (SVGD\({}_{k}\))) or the _vanishing step-size_ (which directly examines the properties of (SVGD\({}_{t}\))) [10; 14; 25; 29; 43; 45]. However, the convergence behavior of the discrete iterates (SVGD\({}_{k}\)) remains a challenging task with limited success. To the best of our knowledge, the only existing work in this direction is , but its result is not directly comparable to ours. Although our assumptions on the bounded derivatives of \(V\) and \(W\) are similar to those in , the difference lies in the requirement imposed on the target distribution \(e^{-V}\). Specifically, Shi and Mackey  assume a T1-inequality on \(e^{-V}\), whereas our work requires \(V\) to be dissipative. Notably, our approach holds a significant advantage over  in terms of simplicity: The result of  is only applicable to a highly specific and fairly complicated step-size rule (see [44, Cor 2]), whereas our sole requirement on \(_{k+1}\) is the standard Assumption 5. However, it should be noted that the bounds in  are _non-asymptotic_ (albeit doubly-exponential in \(N\) and exponential in \(k\)), while we can only handle asymptotic convergence.

_Remark_.: It is worth mentioning that Corollary 2 can be straightforwardly extended to the _Stochastic Particle-Optimization Sampling_ algorithm of Zhang et al. , which is identical to SVGD but includes a constant diffusion term \(>0\). Since the analysis remains the same, we omit the details.

### Two-Player Zero-sum Continuous Games

Min-max learning appears in several important machine learning tasks such as Generative Adversarial Networks  and adversarial training . These learning problems can be formulated as a continuous zero-sum game between a min-player and a max-player. The min-player selects strategies from the set \(^{d}\), while the max-player selects strategies from the set \(^{d}\), with the goal of finding a saddle point of a function \(K(x,y)\):

\[_{x}_{y}K(x,y).\] (14)

However, solving (14) becomes challenging and sometimes impossible when \(K\) is non-convex in \(x\) and non-concave in \(y\), as a solution to (14) may not even exist. To address this issue, _mixed Nash equilibriums_ (MNEs) are introduced, where the pure strategies are replaced by probability distributions over the sets of strategies, which exist under mild assumptions on \(K\)[13; 17].

Specifically, an MNE is represented by a pair of measures \((^{},^{})_{2}()_{2} ()\), forming a saddle point of the functional \(E(,) K(x,y)(dx)(dy)\). The quest for efficient solutions to the MNE problem in machine learning has led to the development of particle-based methods that offer approximate solutions [13; 20; 34]. However, the existing studies have primarily focused on analyzing the _continuous-time_ dynamics of these methods. Below, we shift our focus to the more practical setting of the _discrete-time_ system of interacting particles in these work:

\[x^{i}_{k+1}=x^{i}_{k}-_{k+1}_{j}_{x}K (x^{i}_{k},y^{j}_{k})+}^{i}_{k+1}\\ y^{j}_{k+1}=y^{j}_{k}+_{k+1}_{j}_{y}K(x^{j}_{ k},y^{j}_{k})+}\,^{i}_{k+1},\] (GDA \[{}_{k}\] )

where \(^{i}_{k+1}\) and \(^{i}_{k+1}\) are independent standard Gaussians, \(>0\) is a hyperparameter chosen by the user, and \(\) is the _scale_ difference between the two players . We will additionally consider the _optimistic_ version of (GDA\({}_{k}\)) in , which has shown empirical benefits over (GDA\({}_{k}\)):

\[x^{i}_{k+1}=x^{i}_{k}-_{k+1}_{j}(2 _{x}K(x^{i}_{k},y^{j}_{k})-_{x}K(x^{i}_{k-1},y^{j}_{k-1}))+ }\,^{i}_{k+1}\\ y^{j}_{k+1}=y^{j}_{k}+_{k+1}_{j}(2_{y}K( x^{j}_{k},y^{j}_{k})-_{y}K(x^{j}_{k-1},y^{j}_{k-1}))+}\,^{i}_{k+1}.\] (OGDA \[{}_{k}\] )

At first glance, it may seem that (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) are distinct algorithms that cannot be analyzed together. However, our subsequent corollary reveals that these systems actually converge to the _same_continuous-time dynamics:

\[dX_{t}^{i}=-\,_{j}_{x}K(X_{t}^{i},Y_{t}^{j})\,dt+ dW_{t}^{i}\\  M_{t}^{j}=_{j}_{y}K(X_{t}^{j},Y_{t}^{j})\,dt+ dB_{t}^{i},\] (GDA \[{}_{t}\] )

where \(W_{t}^{i}\) and \(B_{t}^{j}\) are collections of i.i.d. Brownian motions. The key enabling factor for this unified treatment is to allow for a _non-zero bias_ in the algorithmic template (SAA).

To facilitate the analysis, we introduce a pairing of players' particles by setting \(Q_{t}^{i}(X_{t}^{i},Y_{t}^{i})^{2d}\), and define the drift \(b:^{2d}_{2}(^{2d})^{2d}\) as

\[b(q,)-_{x}K(q_{1},q_{2}^{})\\ \,_{y}K(q_{1}^{},q_{2})\,(dq^{}),  q=(q_{1},q_{2}),\]

and the diffusion \((q,)(I_{d d},\,I_{d d})\). By doing so, we can then cast (GDA\({}_{t}\)) in template of (Sys-SDE).

**Corollary 3**.: _Assume that (1) \(_{x}K\) and \(_{y}K\) are Lipschitz, and (2) \(_{x}K\) and \(-_{y}K\) are dissipative, or (2') the domains \(\) and \(\) are bounded. Then the algorithms (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) converge in \(_{2}\) to the same limits of (GDA\({}_{t}\))._

We note that the assumptions in (3) are mild and are even required for analysing the _continuous-time_ dynamics; see e.g., . Consequently, our Corollary 3 provides a rigorous foundation for the consideration of continuous-time dynamics in existing studies such as [13; 20; 34].

_Remark_.: The schemes (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) above rely on _simultaneous_ updates, i.e., from \((x_{k},y_{k})\), one obtains \((x_{k+1},y_{k+1})\). However, empirical evidence suggests that _alternating_ updates i.e., following \((x_{k},y_{k})(x_{k+1},y_{k})(x_{k+1},y_{k+1})\), often preforms better. Our framework allows for this flexibility, as it is easy to cast the alternating (GDA\({}_{k}\)) and (OGDA\({}_{k}\)) as stochastic approximation schemes satisfying Assumption 4, see [24, Proposition 4] for an example of this argument.

### Kinetic Equations

In this section, we study the _kinetic equations_ defined on the space of probability measures. Initially emerging from the physics community, these equations have recently gained attention in the machine learning community due to their connection to _Wasserstein gradient flows_[15; 32; 39; 40; 48; 49; 52]. Here, we denote \(\) as a probability density, and we examine three distinct "energy" functionals: an internal energy \(\), a potential energy \(\), and an interaction energy \(\). These functionals are defined as follows:

\[()= U((x))\,dx,()=(x )\,(dx),()= W(x-y)\,(dx)(dy).\] (15)

The most interesting scenario is when \(U(s)=s s\) represents the _entropy_, in which case the Wasserstein gradient flow with finite particles becomes [5; 7]:

\[dX_{t}^{i}=- V(X_{t}^{i})\,dt-\,_{j=1}^{N} W(X_{t} ^{i}-X_{t}^{j})\,dt+\,dW_{t}^{i}, i=1,,N.\] (Kin-SDE)

By setting \(b(x,)- V(x)-( W*)(x)\) and \((x,)\), we again see that (Kin-SDE) is a special case of (Sys-SDE).

In the physics community, the equation is commonly simulated using a system of interacting particles through the _proximal point method_[6; 48]:

\[x_{k+1}^{i}=x_{k}^{i}-_{k+1} V(x_{k+1}^{i})+\, _{j=1}^{N} W(x_{k+1}^{i}-x_{k}^{j})+}\, _{k+1}^{i}.\] (Kin-Prox)

Note that the right-hand side of (Kin-Prox) involves the next iterates \(x_{k+1}^{i}\) so that, as opposed to the simple Euler discretization, it is an _implicit_ rule. The key factor that enables the application of our framework to these implicit schemes is the observation that (Kin-Prox) can be formulated as a stochastic approximation scheme in (SAA) by incorporating a _non-zero bias_ term; see Appendix C. Our next result provides a rigorous guarantee for these methods:

**Corollary 4**.: _Assume that (1) \(V\) is dissipative and \( V\) is \(L\)-Lipschitz, (2) \(W\) is symmetric and \( W\) is \(L\)-Lipschitz, (3) There exists some \(M_{W} 0\) such that for all \(x,y^{d}\), \( W(x)- W(y),x-y-M_{W}\). Then, the iterates (Kin-Prox) converge in \(_{2}\) to the same limit sets as (Kin-SDE)._We remark that the convergence of (Kin-Prox) under these standard assumptions is known [15; 48]. However,we emphasize that the aforementioned results only apply to _deterministic_ updates, while our proof is robust enough to accommodate updates with _finite-variance noise_. This flexibility sets our approach apart, allowing for a broader range of practical applications.

## 5 Conclusion and Future Directions

In conclusion, our work has successfully bridged the gap between continuous- and discrete-time schemes by establishing the convergence of discrete-time algorithms to their continuous-time counterparts, drawing inspiration from dynamical system theory. This achievement offers a flexible framework that can accommodate practical schemes and unify tasks from various domains, including machine learning, game theory, and physics. By introducing a comprehensive framework for analyzing stochastic approximation schemes, providing convergence proofs, and presenting easily verifiable conditions at the finite particle level, our contributions enhance the understanding and application of stochastic approximation schemes for simulating interacting particle systems.

In our future works, we will explore the exciting possibilities offered by the dynamical system theory of  to derive convergence rates through \(\)-pseudotrajectories. This avenue of research will allow us to establish exponential convergence for dynamics using smaller step-sizes after a "burn-in" time, thereby sharpening our understanding for the long-term behavior of these practical schemes.

Additionally, we aim to relax the Lipschitzness assumption on the drift and expand the scope of guaranteed algorithms, such as the Ensemble Kalman Sampler . We also aim to explore further applications in natural sciences, including stochastic mean-field FitzHugh-Nagumo models and networks of Hodgkin-Huxley neurons . These models are important because they provide a mathematical description of neuronal dynamics, contribute to our understanding of neurological disorders, and inform the development of brain-computer interfaces. By leveraging our novel framework, we hope to offer rigorous guarantees for the algorithms employed in these domains while also designing new, efficient approaches that can support computational neuroscience research.