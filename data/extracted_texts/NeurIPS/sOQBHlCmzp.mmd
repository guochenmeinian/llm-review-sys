# Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series

Yihe Wang

University of North Carolina - Charlotte

ywang145@uncc.edu

&Yu Han

University of Chinese Academy of Sciences

hanyu21@mails.ucas.ac.cn

&Haishuai Wang

Zhejiang University

haishuai.wang@zju.edu.cn &Xiang Zhang

University of North Carolina - Charlotte

xiang.zhang@uncc.edu

These authors contributed equally to this work.

###### Abstract

Contrastive representation learning is crucial in medical time series analysis as it alleviates dependency on labor-intensive, domain-specific, and scarce expert annotations. However, existing contrastive learning methods primarily focus on one single data level, which fails to fully exploit the intricate nature of medical time series. To address this issue, we present COMET, an innovative hierarchical framework that leverages data consistencies at all inherent levels in medical time series. Our meticulously designed model systematically captures data consistency from four potential levels: observation, sample, trial, and patient levels. By developing contrastive loss at multiple levels, we can learn effective representations that preserve comprehensive data consistency, maximizing information utilization in a self-supervised manner. We conduct experiments in the challenging patient-independent setting. We compare COMET against six baselines using three diverse datasets, which include ECG signals for myocardial infarction and EEG signals for Alzheimer's and Parkinson's diseases. The results demonstrate that COMET consistently outperforms all baselines, particularly in setup with 10% and 1% labeled data fractions across all datasets. These results underscore the significant impact of our framework in advancing contrastive representation learning techniques for medical time series. The source code is available at https://github.com/DL4mHealth/COMET.

## 1 Introduction

Time series data is crucial in various real-world applications, ranging from finance [1; 2; 3], engineering [4; 5], to healthcare [6; 7]. Unlike domains such as computer vision [8; 9] and natural language processing [10; 11], where human recognizable features exist, time series data often lacks readily discernible patterns, making data labeling challenging. Consequently, the scarcity of labeled data poses a significant hurdle in effectively utilizing time series for analysis and classification tasks.

To address the paucity of labeled data in time series analysis, self-supervised contrastive learning has emerged as a promising approach. For example, TimeCLR  proposes a DTW data augmentation for time series data; TS2vec  designs a cropping and masking mechanism to form positive pairs; ExpCLR  introduces a novel loss function to utilize continuous expert features. By leveraging the inherent consistency within unlabeled data, contrastive learning algorithms enable the extraction of effective representations without relying on explicit labels. This paradigm shift opens up possibilities for overcoming the data scarcity issue and enhancing the capabilities of time series analysis.

Despite recent advancements in contrastive learning methods for time series, existing approaches fail to exploit the full potential of medical time series data, such as electroencephalogram (EEG) signals. Unlike conventional time series data, medical time series often exhibit more data levels (Figure 1), including patient, trial, sample, and observation levels. Current contrastive learning techniques exclusively employ subsets of these levels (as illustrated in Table 1). Additionally, many of these methods are tailored to specific data types, which restricts their capacity to capture the rich complexity of medical time series. For example, CLOCS  presents a contrastive learning method for ECG using sample and patient levels. Mixing-up  captures sample-level consistency through a mixing data augmentation scheme. TNC  exploits trial-level consistency by contrasting neighbor samples in the same trial as positive pairs. Neither of them leverages all the levels exhibited in the medical time series.

After reviewing existing contrastive learning methods within the time series domain, we consistently posed a pivotal question to ourselves: Can we design a straightforward yet appliable contrastive learning framework that can be adapted to all forms of medical time series data, akin to the classical model SimCLR  in the domain of contrastive learning? Our objective is to craft an innovative framework that utilizes all information within medical time series in the context of self-supervised contrastive learning. It enables us to harness patient and trial information to learn consistency across instances while leveraging the sample and observation levels' information to facilitate conventional instance discrimination.

In this paper, we propose a hierarchical framework, COMET, that systematically leverages all four levels of medical time series, namely patient, trial, sample, and observation, to reduce the reliance on labeled data. By incorporating self-supervised contrastive learning, our method aims to bridge the gap between the limited availability of labeled data and the need for robust and generalizable models in medical time series analysis. We conduct extensive experiments with six baselines on three diverse datasets in a challenging patient-independent setting. COMET outperforms SOTAs by 14% and 13% F1 score with label fractions of 10% and 1%, respectively, on EEG-based Alzheimer's detection. Further, COMET outperforms SOTAs by 0.17% and 2.66% F1 score with label fractions of 10% and 1%, respectively, on detecting Myocardial infarction with ECG. Finally, COMET outperforms SOTAs by 2% and 8% F1 score with label fractions of 10% and 1%, respectively, in the EEG-based diagnosis of Parkinson's disease. The results of downstream tasks demonstrate the effectiveness and stability of our method.

## 2 Related Work

**Medical time series.** Medical time series [19; 20; 21; 22] is a distinct type of time series data used for healthcare (_e.g._, disease diagnosis, monitoring, and rehabilitation). It can be collected in a low-cost, non-invasive manner  or a high-cost, invasive manner .

Unlike general time series, which typically consist of sample and observation levels, medical time series introduces two additional data levels: patient and trial. These extra levels of data information in medical time series enable the development of specialized methods tailored to address the unique characteristics and requirements of medical time series analysis. Various types of medical time series, including EEG [28; 29; 30], ECG [31; 32], EMG , and EOG , offer valuable insights into specific medical conditions and play a crucial role in advancing healthcare practices.

  
**Models** & **Patient** & **Trial** & **Sample** & **Observation** \\ 
**SimCLR** & & & ✓ & \\
**TF-C** & & & ✓ & \\
**Mixing-up** & & & ✓ & \\
**TNC** & & ✓ & & \\
**TS2vec** & & ✓ & ✓ & \\
**TS-TCC** & & & ✓ & ✓ \\
**CLOS** & ✓ & & ✓ & \\
**COMET(Ours)** & ✓ & ✓ & ✓ & ✓ \\   

Table 1: Existing methods only utilize partial levels.

Figure 1: Structure of medical time series. Medical time series commonly have four levels (coarse to fine): patient, trial, sample, and observation. An observation is a single value in univariate time series and a vector in multivariate time series.

Contrastive learning for time series.Contrastive learning has demonstrated its ability to learn effective representations in various domains, including image processing [35; 18; 36], graph analysis [37; 38; 37], and time series . The key idea behind contrastive representation learning is to mine data consistency by bringing similar data closer together and pushing dissimilar data further apart.

Many existing works on contrastive learning focus on general time series, while some are designed specifically for medical data . One classic framework, SimCLR, transforms a single sample into two augmented views and performs contrastive learning . Other settings, such as using sub-series and overlapping-series, leverage sample-level consistency . TF-C  contrasts representations learned from the time and frequency domains to exploit sample-level consistency. Mixing-up  learn sample-level consistency by utilizing a mixing component as a data augmentation scheme. TS-TCC and TS2vec [27; 13] apply data augmentation at the sample-level and perform contrastive learning at the observation-level. TNC  learns trial-level consistency by contrasting neighboring and non-neighboring samples. NCL  can also be used to learn trial-level consistency if we define samples from a trial as a neighborhood. CLOCS  learns patient-level consistency in cardiac signal features by contrasting different leads over time.

Certain prior methods have implicitly utilized hierarchical structure [13; 15]. However, as shown in Table 1, none of these methods leverage all the levels present in the medical time series, potentially resulting in the loss of useful information during training. We explicitly present a hierarchical framework in the context of contrastive learning, which can be applied across diverse types of medical time series data. In our paper, we aim to leverage data consistency at all levels in medical time series. Our work plays a role in summarizing, inspiring, and guiding future works in self-supervised contrastive learning on medical time series.

## 3 Preliminaries and Problem Formulation

### Medical Time Series

In this section, we clarify the key conceptions of **observation** (or measurement), **sample** (or segment), **trial** (or recording), and **patient** (or subject) in the context of medical time series (Figure 1). For better understanding, we illustrate the concepts with an example of Electroencephalography (EEG) signals for Alzheimer's Disease diagnosis (details in Appendix A).

**Definition 1: Observation.**_An observation \(_{i,t}^{F}\) in medical time series data represents a single data point or a vector captured at a specific timestamp \(t\)._ Here we use \(i\) to denote the sample index (see **Definition 2**) and \(t\) to denote the timestamp. It may record physiological status, laboratory test results, vital signs, or other measurable health indicators. The observation is a single real value for univariate time series while vector for multivariate time series. The \(F\) is the feature dimension if it is a multivariate time series.

**Definition 2: Sample.**_A sample \(_{i}=\{_{i,t}|t=1,,T\}\) is a sequence of consecutive observations_, typically measured at regular intervals over a specified period (\(T\) timestamps). It can also be called a _segment_ or _window_. Here we use \(i\) to denote the sample index. In the medical time series, a sample might consist of a sequence of heart rate measurements or blood pressure readings.

**Definition 3: Trial.**_A trial \(_{i}\) is a collection of consecutive samples._ It can also be called a _record_. Here we use \(i\) to denote the trial ID. In medical time series, a trial is a continuous set of observations collected over a not-short period (_e.g._, 30 minutes). Therefore, a trial is generally too long (_e.g._, hundreds of thousands of observations) to feed into deep learning models for representation learning directly and is usually split into shorter subsequences (_i.e._, samples/segments). To represent the aggregate of samples stemming from a particular trial \(_{i}\) with trial ID \(i\), we employ the notation \(_{i}\).

**Definition 4: Patient.**_A patient \(_{i}\) represents a collection of multiple trials stemming from a single patient._ It can also be called a _subject_. Here we use \(i\) to denote the patient ID. It is important to note that trials for a given patient may exhibit variations due to differing data collection timeframes, sensor placements, patient conditions, and other contributing factors. As shown in **Definition 3**, a trial is typically divided into many samples for better representation learning. In practical scenarios, a patient, which constitutes a cluster of trials, is also divided into samples that may share identical or distinct trial IDs but maintain the same patient ID. To represent the aggregate of samples stemming from a particular patient \(_{i}\) with the corresponding patient ID \(i\), we employ the notation \(_{i}\).

In this work, we propose a novel hierarchical contrastive framework to learn representative and generalizable embeddings by comprehensively exploring instance discrimination at observation and sample levels and harnessing consistency across instances at trial and patient levels. Although we elaborate the proposed COMET in the context of medical time series, we note our model can possibly be extended to other time series beyond healthcare as long as extra information is available. For example, a climate dataset contains multiple meteorological satellites, each satellite contains multiple measuring units, and each unit contains multiple sensors, and every sensor can measure a specific observation at a certain timestamp. The key is to utilize all available information, excluding label data, for contrastive pre-training, such as patient ID. To adapt our approach to other domains, researchers must consider a crucial question: Does the dataset have additional information beyond sample labels? If affirmative, can this information be harnessed for contrastive learning? The example of satellite sensor application underscores the potential existence of supplementary information even in non-medical domains.

### Problem Formulation

**Problem (Self-Supervised Representation Learning For Medical Time Series).**_Let an unlabeled dataset \(\) consist of a set of patients, where each patient \(_{i}\) has multiple trials, each trial \(_{i}\) can be segmented into many samples, and each sample \(_{i}\) comprises a series of observations. We aim to pre-train an encoder \(G\) that exploits data consistency at all available levels in a self-supervised contrastive manner. For a given time series sample \(_{i}^{T F}\) with \(T\) timestamps and \(F\) feature dimensions, the encoder \(G\) learns a sample-level representation \(_{i}^{T K}\), where \(_{i,t}^{K}\) is the observation-level representation at timestamp \(t\) with K dimensions._

By exploiting hierarchical consistency at multiple data levels, we aim to learn a representation \(_{i}\) that is both representative (yielding good performance in downstream tasks) and generalizable (maintaining stability across different patients). Depending on the fine-tuning settings , a specific fraction of labels \(y_{i}\) corresponding to samples \(_{i}\) are necessary.

## 4 Method

In this section, we first present our assumption of data consistency behind designing a hierarchical contrastive framework. Then, we describe the architecture of the proposed model COMET (Figure 2).

Figure 2: **Overview of COMET approach. Our COMET model consists of four contrastive blocks, each illustrating the formulation of positive pairs and negative pairs at different data levels. In the observation-level contrastive, an observation \(_{i,t}\) and its augmented view \(}_{i,t}\) serve as a positive pair. Similarly, in the sample-level contrastive, a sample \(_{i}\) and its augmented view \(}_{i}\) form a positive pair. Moving to the trial-level contrastive, two samples \(\) and \(^{+}\) from the same trial \(_{i}\) are considered to be a positive pair. The patient-level contrastive follows a similar pattern, where two samples \(\) and \(^{+}\) from the same patient \(_{i}\) are regarded as a positive pair. Positive and corresponding negative pairs will be utilized to build contrastive loss in embedding space after being processed by encoder \(G\).**

### Hierarchical Data Consistency

Capturing data consistency is crucial in the development of a contrastive learning framework . Data consistency refers to the shared commonalities preserved within the data, which provide a supervisory signal to guide model optimization. Contrastive learning captures data consistency by contrasting positive and negative data pairs, where positive pairs share commonalities and negative pairs do not. We propose consistency across four data levels: observation, sample, trial, and patient, from fine-grained to coarse-grained in the medical time series. Although we present four levels here, our model can easily be adapted to accommodate specific datasets by adding or removing data levels.

**Observation-level data consistency.** We assume a slightly augmented observation (_e.g._, channel masked) will carry similar information as the original observation . We use \(_{i,t}\) as the anchor observation at timestamp \(t\), and \(_{i,t^{-}}\) as the observation at another timestamp \(t^{-}\) in the sample \(_{i}\). We consider the anchor observation \(_{i,t}\) and an augmented observation \(}_{i,t}\) as positive pairs \((_{i,t},}_{i,t})\) (with closer embeddings). Conversely, we consider the original observation \(_{i,t}\) and the observations \(}_{i,t^{-}}\) and \(_{i,t^{-}}\) at another timestamp \(t^{-}\) as negative pairs \((_{i,t},}_{i,t^{-}}),(_{i,t},_{i,t^{-}})\), with distant embeddings.

**Sample-level data consistency.** The sample-level consistency is based on our assumption that a slightly perturbed sample (e.g., temporally masked) should carry similar information as the original sample [18; 16; 26]. We consider the anchor sample \(_{i}\) and its augmented view \(}_{i}\) as positive pair \((_{i},}_{i})\). We regard the anchor sample \(_{i}\) and a different sample \(_{j}\) and its augmented view \(}_{j}\) as negative pairs: \((_{i},}_{j})\) and \((_{i},_{j})\).

**Trial-level data consistency.** We assume that samples sliced from the same trial should carry similar information compared to those obtained from different trials. For simplicity, we use \(\) to denote the anchor sample and \(^{+}\) to denote a sample from the same trial \(_{i}\) as the anchor sample, while \(^{-}\) to denote a sample from another trial \(_{j}\). In other words, we have \(\{,^{+}\}_{i}\) and \(^{-}_{j}\). We treat sample \(\) and the sample \(^{+}\) from the same trial as positive pair \((,^{+})\). We regard sample \(\) and the sample \(^{-}\) from different trials as negative pair \((,^{-})\).

**Patient-level data consistency.** We assume samples originating from the same patient are likely to contain similar information when compared to those from different patients . Here, we use \(\) to denote the anchor sample and \(^{+}\) to denote a sample from the same patient \(_{i}\), while \(^{-}\) from another patient \(_{j}\). In other words, there are \(\{,^{+}\}_{i}\) and \(^{-}_{j}\). We have positive pair \((,^{+})\) including samples from the same patient and negative pair \((,^{-})\) that from different patients.

**Disease-level data consistency.** For completeness, we introduce disease-level data consistency, which suggests that samples associated with the same type of disease should exhibit shared patterns, even when collected from different patients in different ways. However, capturing disease-level consistency requires ground truth labels, which are not available in a self-supervised approach. As a result, we do NOT employ disease-level consistency in this paper. Nevertheless, it can be adapted for semi-supervised or supervised contrastive learning and may prove beneficial in learning domain-adaptable representations for certain diseases across patients and even datasets.

A common principle underlying all definitions is that _the X-level data consistency refers to the positive pair belonging to the same X, where X could be observation, sample, trial, patient, or disease._ We assume that _each patient is associated with only one label_, such as suffering from a specific disease, which implies that all samples from the same patient essentially originate from the same distribution. However, in cases where data from a patient is derived from multiple distributions (e.g., a patient could perform various daily activities; associated with multiple labels), the assumptions of trial-level and patient-level consistency are not satisfied. Therefore, the user can switch on the observation-level and sample-level consistency.

Building upon the concepts of data consistency, we introduce four contrastive blocks corresponding to the four data levels. Our model is highly flexible, allowing users to enable or disable any of the blocks based on the requirements of a specific task or dataset.

### Observation-Level Contrastive Block

For a given time series sample \(_{i}\), we apply data augmentation (such as masking) to generate an augmented sample \(}_{i}\)[25; 43]. We input the original sample \(_{i}\) and its augmented view \(}_{i}\) intocontrastive encoder \(G\) to obtain their respective representations \(_{i}=G(_{i})\) and \(}_{i}=G(}_{i})\). It is important to note that we apply data augmentation to the samples, which indirectly extends to augmenting the observations, simplifying the encoding process. To capture observation-level consistency, we assume that, after being processed by encoder \(G\), the representation of observation \(_{i,t}\) is close to the representation of the augmented observation \(}_{i,t}\). In contrast, it should be distant from the representations of observations \(_{i,t^{-}}\) and \(}_{i,t^{-}}\) originating from any other timestamp \(t^{-}\). Specifically, our positive pair is \((_{i,t},}_{i,t})\) and negative pairs are \((_{i,t},_{i,t^{-}})\) and \((_{i,t},}_{i,t^{-}})\).

**Observation-level contrastive loss.** The observation-level contrastive loss \(_{}\) for the input sample \(_{i}\) is defined as:

\[_{}=_{_{i}}[_{t }[-(_{i,t}}_{i,t})}{_{t^{-}}((_{i,t} }_{i,t^{-}})+_{[t t^{-}]}(_{i, t}_{i,t^{-}}))}]]\] (1)

where \(=\{1,,T\}\) is the set of all timestamps in sample \(_{i}\) and \(\) denotes dot product. The \(_{[t t^{-}]}\) is an indicator function that equals to \(0\) when \(t=t^{-}\) and \(1\) otherwise.

### Sample-Level Contrastive Block

For an input time series sample \(_{i}\) and its augmented view \(}_{i}\), we calculate their representations through \(_{i}=G(_{i})\) and \(}_{i}=G(}_{i})\). The augmentation applied here could be the same as or different from the augmentation used in Section 4.2. We assume that after passing through the encoder \(G\), the representation of the sample \(_{i}\) is close to the representation of its augmented view \(}_{i}\), while far away from the representations of any other samples \(_{j}\) and \(}_{j}\). In specific, our positive pair is \((_{i},}_{i})\), and negative pairs are \((_{i},}_{j})\) and \((_{i},_{j})\).

**Sample-level contrastive loss.** The sample-level contrastive loss \(_{}\)[18; 43] for the input sample \(_{i}\) is defined as:

\[_{}=_{_{i}}[-(_{i}}_{i})}{_{j=1}^{| |}((_{i}}_{j})+_ {[i j]}(_{i}_{j}))}]\] (2)

where \(||\) represents the total number of samples in the dataset \(\) and \(\) denotes dot product. The \(_{[i j]}\) is an indicator function that equals \(0\) when \(i=j\) and \(1\) otherwise.

### Trial-Level Contrastive Block

For an input sample \(_{i}\), where \(_{i}\) is a collection of all samples segmented from trial \(_{i}\), we feed it into the contrastive encoder \(G\) to generate a sample-level representation \(=G()\). To seize trial-level data consistency, we assume that the representation of the anchor sample \(_{i}\) is close to the representation of sample \(^{+}\) that also come from the trial \(_{i}\). In contrast, the representation of the anchor sample \(\) is far away from the representation of sample \(^{-}\) that come from a different trial \(_{j}\), where \(^{-}_{j}\). In other words, we have positive pair \((,^{+})\) and negative pair \((,^{-})\).

**Trial-level contrastive loss.** The trial-level contrastive loss \(_{}\)[15; 18] for the input sample \(\) is defined as:

\[_{}=_{}[_{^{+}_{i}}[-((,G( ^{+}))/)}{_{j=1}^{J}_{^{-}_{j}}(((,G(^{-}))/))}]]\] (3)

where \(J\) is the total number of trials in the dataset \(\). The \((,)=^{T}/\|\|\|\|\) denotes the cosine similarity, and \(\) is a temperature parameter to adjust the scale. The \(G(^{+})\) and \(G(^{-})\) are learned representations of samples \(^{+}_{i}\) and \(^{-}_{j}\), respectively. To measure the trial-level loss for sample \(\), we iterate all the \(^{+}\) in \(_{i}\), and averaging across \(|_{i}|-1\) positive pairs.

In this block, we do NOT learn a trial-level embedding representing the entire trial. Instead, we learn a representation for each sample within the trial while considering trial-level data consistency. Similarly, we follow this protocol for the patient-level contrastive block.

### Patient-Level Contrastive Block

For an input sample \(_{i}\), where \(_{i}\) denotes all samples from patient \(_{i}\), we feed it into the contrastive encoder \(G\) to generate a sample-level representation \(=G()\). Similar to the above trial-level contrastive block, we have positive pair \((,^{+})\) and negative pair \((,^{-})\), in which \(^{+}\) come from the same patient while \(^{-}\) come from a different patient.

**Patient-level contrastive loss.** The patient-level contrastive loss \(_{}\) for the input sample \(\) is defined as:

\[_{}=_{}[_{ {x}^{+}_{i}}[-((,G(^{+}))/)}{_{j=1}^{M}_{^{-}_{j}}( {exp}((,G(^{-}))/))}]]\] (4)

where \(M\) is the total number of patients in the dataset \(\). In this block, the \(G(^{+})\) and \(G(^{-})\) are learned representations of samples \(^{+}_{i}\) and \(^{-}_{j}\), respectively.

### Overall Loss Function

The overall loss function \(\) consists of four loss terms The observation-level loss \(_{}\) and sample-level loss \(_{}\) encourage the encoder to learn robust representations that are invariant to perturbations. The trial-level loss \(_{}\) and patient-level loss \(_{}\) compel the encoder to learn cross-sample features within a trial or a patient. In summary, the overall loss function of the proposed COMET model is:

\[=_{1}_{}+_{2}_{}+_{3}_{}+_{4}_{}\] (5)

where \(_{1},_{2},_{3}\), \(_{4}\) are hyper-coefficients that control the relative importance and adjust the scales of each level's loss. Users can simply turn off specific data levels by setting \(\) of those levels to 0. We set \(_{1}+_{2}+_{3}+_{4}=1\). We calculate the total loss by taking the expectation of \(\) across all samples \(\). In practice, the contrastive losses are calculated within a mini-batch.

## 5 Experiments

We compare the COMET model with six baselines on three datasets. Following the setup in SimCLR , we use unlabeled data to pre-train encoder \(G\) and evaluate it in two downstream settings (Appendix E): partial fine-tuning (P-FT; _i.e._, linear evaluation ) and full fine-tuning (F-FT). All datasets are split into training, validation, and test sets in **patient-independent** setting (Figure 3), which is very challenging due to patient variations (More explanations in Appendix F.1).

**Datasets.** (1) **AD** has 23 patients, 663 trials, and 5967 multivariate EEG samples. There are 4329, 891, and 747 samples in training, validation, and test sets. The sampling rate (frequency) is 256Hz. Each sample is a one-second interval with 256 observations. A binary label based on whether the patient has Alzheimer's disease is assigned to each sample. (2) **PTB** has 198 patients, 6237 trials, and 62370 multivariate ECG samples. There are 53950, 3400, and 5020 samples in training, validation, and test sets. The sampling rate (frequency) is 250Hz. Each sample is a heartbeat with 300 observations. A binary label based on whether the patient has Myocardial infarction is assigned to each sample. (3) **TDBrain** has 72 patients, 624 trials, and 11856 multivariate EEG samples. There are 8208, 1824, and 1824 samples in training, validation, and test sets. The sampling rate (frequency) is 256Hz. Each sample is a one-second interval with 256 observations. A binary label based on whether the patient has Parkinson's disease is assigned to each sample. See appendix D for more details about data statistics, train-test split, and data preprocessing.

**Baselines.** We compare with 6 state-of-the-art methods: TS2vec , Mixing-up , TS-TCC , SimCLR , CLOCS  and TF-C . Since TF-C is designed for transfer learning, we implement its downstream tasks the same as ours for a fair comparison. The evaluation metrics are accuracy, precision (macro-averaged), recall(macro-averaged), F1 score(macro-averaged, AUROC(macro-averaged), and AUPRC(macro-averaged).

Figure 3: **Patient-dependent/independent Setting. In the patient-dependent setting, samples from the same patient can appear in both the training and test sets. In contrast, in the patient-independent setting, samples from the same patient are exclusively included in the training or test set.**

**Implementation.** We use a ten residual blocks dilated CNN module  as backbones for encoders \(G\). To preserve the magnitude feature of time series, which is often an important feature in time series, we utilize timestamp masking as proposed in  as an augmentation method. While many existing works apply data augmentation directly on raw time series, we use a fully connected projection layer to map the raw input into an embedding with a higher feature dimension. This strategy helps prevent situations where some parts of the raw data are zero, which could result in ineffective augmentation if timestamp masking were directly applied. Additionally, to ensure stability during training, we incorporate a hierarchical loss , which encapsulates the observation and sample-level losses. To guarantee there are samples with the same trial and patient IDs in a batch for trial and patient levels contrasting, we design two specific shuffle functions. See Appendix C for further details. For datasets whose trial level is absent or limited to one trial per patient, we provide a solution in Appendix F.2.

We conduct experiments with five seeds(41-45) based on the same data split to account for variance and report the mean and standard deviation. All experiments expect baseline SimCLR run on NVIDIA RTX 4090. Baseline SimCLR runs on Google Colab NVIDIA A100. See further implementation details in Appendix E.

### Results on Partial Fine-tuning

**Setup.** Linear evaluation is a widely used P-FT setup to evaluate the quality of representation, where a linear classifier is trained on top of a frozen network for sample classification [18; 15; 48; 49]. This evaluation method allows for a quick assessment of representation quality. In linear evaluation, we add a logistic regression classifier \(L\) on top of the pre-trained encoder \(G\). The training process utilizes 100% labeled training data for sample classification. Notably, the parameters of the encoder \(G\) are frozen during training, ensuring that only the classifier \(L\) is fine-tuned. See further details in E.1.

**Results.** We report the experimental results of the P-FT setup on AD in Table 2. On average, our COMET model claims a large margin of more than 7% over all baselines on the F1 score on AD.

### Results on Full Fine-tuning

**Setup.** In an F-FT setup, we add a two-layer fully connected network classifier \(P\) to the pre-trained encoder \(G\). The training process utilizes 100%, 10%, and 1% of the labeled training data for sample classification, respectively. Unlike the P-FT approach, both the encoder \(G\) and classifier \(P\) are trainable now, allowing for fine-tuning of the entire network structure. See further details in E.2.

**Results.** The results for F-FT on the three datasets are presented in Table 3 and Table 4. In general, COMET demonstrates success in 46 out of 54 tests conducted across the three datasets, considering six different evaluation metrics. With 100% labeled data, the F1 score of COMET outperforms the best baseline, TS2Vec, by 2% on the AD dataset and surpasses the best baseline, Mixing-up, by 4% on the TDBrain dataset. Furthermore, it achieves a result comparable to the best baseline, TF-C, on the PTB dataset.

Notably, the F1 score of COMET surpasses the best baseline, TF-C, by 14% and 13% with label fractions of 10% and 1%, respectively, on the AD dataset. Additionally, on the TDBrain dataset, the F1 score of COMET outperforms the best baseline, Mixing-up, by 2% and 8% with label fractions of 10% and 1%, respectively. Similarly, the F1 score of COMET outperforms the best baseline, CLOCS, by 0.17% and 2.66% with label fractions of 10% and 1%, respectively, on the PTB dataset. It is interesting to observe that the F1 score of COMET with label fractions of 10% and 1% outperforms a label fraction of 100% on the AD and PTB datasets. This suggests a potential overfitting of COMET to the training data. A similar phenomenon is observed with SimCLR, TF-C, CLOCS, and TS2vec, where a higher fraction of labeled data did not necessarily lead to improved performance.

  
**Models** & **Accuracy** & **Precision** & **Recall** & **F1 score** & **AUROC** & **AUPRC** \\ 
**TS2vec** & 66.48\(\)3.53 & 67.72\(\)5.09 & 67.40\(\)5.20 & 66.32\(\)5.46 & 74.12\(\)6.88 & 72.96\(\)721 \\
**TF-C** & 77.03\(\)2.88 & 75.79\(\)5.07 & 64.27\(\)5.03 & 64.85\(\)5.56 & 80.71\(\)4.03 & 79.27\(\)4.15 \\
**Mixing-up** & 46.16\(\)1.38 & 52.62\(\)4.90 & 50.81\(\)1.32 & 37.37\(\)1.98 & 64.42\(\)6.49 & 62.85\(\)6.07 \\
**TS-TCC** & 59.71\(\)8.63 & 61.69\(\)8.63 & 60.33\(\)8.26 & 58.66\(\)8.39 & 67.53\(\)10.04 & 68.33\(\)9.37 \\
**SimCLR** & 57.16\(\)2.05 & 56.67\(\)3.91 & 53.57\(\)2.12 & 49.11\(\)4.26 & 56.67\(\)3.91 & 52.10\(\)4.11 \\
**CLOCS** & 66.69\(\)9.24 & 67.17\(\)2.96 & 67.33\(\)2.99 & 66.91\(\)2.83 & 73.17\(\)3.62 & 72.58\(\)3.54 \\
**COMET (Ours)** & **76.09\(\)4.21** & **77.36\(\)3.37** & **74.68\(\)4.42** & **74.80\(\)4.33** & **81.30\(\)4.97** & **80.50\(\)5.31** \\   

Table 2: **Partial fine-tuning results.** A logistic regression(LG) classifier \(L\) is added on top of a frozen encoder \(G\) on dataset AD. Only fine-tuning the classifier \(L\).

As a result, COMET demonstrates its superiority and stability across all the datasets. Furthermore, COMET outperforms SOTAs methods significantly with 10% and 1% label fractions, highlighting the effectiveness of our contrastive pre-training approach in reducing the reliance on labeled data.

### Ablation Study, Visualization, Additional Downstream Tasks, and Heavy Duty Baseline

**Ablation study.** We verify the effectiveness of each contrastive block and other COMET variants. Besides, we study the impact of hyperparameter \(\). (Appendix G.1)

**Visualization.** We visualize the embedding space and show our model can learn more distinctive and robust representations. (Appendix G.2)

**Additional downstream tasks.** Apart from the classification tasks in Section 5.1-5.2, we show the proposed COMET outperforms baselines in a wide range of downstream tasks, including clustering and anomaly detection. (Appendix G.3)

**Heavy duty baseline.** We show the superiority of our model does NOT result from the newly added contrastive blocks (_i.e._, increased model parameters). COMET outperforms the heavy-duty SimCLR and TS2Vec with four contrastive blocks and four times pre-training epochs. (Appendix G.4)

  
**Datasets** & **Fraction** & **Models** & **Accuracy** & **Precision** & **Recall** & **F1 score** & **AUROC** & **AUPRC** \\   &  & **TS2vec** & 81.26\({}_{+2.06}\) & 81.21\({}_{+2.14}\) & 81.34\({}_{+2.04}\) & 81.12\({}_{+2.06}\) & 89.20\({}_{+1.76}\) & 88.94\({}_{+1.85}\) \\  & & **TF-C** & 75.31\({}_{+8.27}\) & 75.87\({}_{+8.73}\) & 74.83\({}_{+8.98}\) & 74.54\({}_{+8.85}\) & 79.45\({}_{+0.12}\) & 79.33\({}_{+10.57}\) \\  & & **Mixing-up** & 65.68\({}_{+7.89}\) & 72.61\({}_{+4.21}\) & 68.25\({}_{+6.97}\) & 63.98\({}_{+9.92}\) & 84.63\({}_{+5.04}\) & 83.46\({}_{+5.18}\) \\  & & **TS-TCC** & 73.55\({}_{+1.00}\) & 77.22\({}_{+2.13}\) & 73.83\({}_{+9.63}\) & 76.16\({}_{+1.99}\) & 86.17\({}_{+1.51}\) & 85.73\({}_{+5.11}\) \\  & & **SimCLR** & 54.77\({}_{+1.97}\) & 50.51\({}_{+8.72}\) & 50.58\({}_{+1.92}\) & 43.18\({}_{+4.27}\) & 50.15\({}_{+7.02}\) & 50.42\({}_{+1.66}\) \\  & & **CLOCS** & 78.37\({}_{+6.00}\) & 83.99\({}_{+2.11}\) & 76.14\({}_{+7.03}\) & 75.78\({}_{+7.93}\) & 91.17\({}_{+2.51}\) & 90.72\({}_{+0.56}\) \\  & & **COMET (Ours)** & **84.50\({}_{+4.46}\)** & **88.31\({}_{+2.42}\)** & **82.95\({}_{+8.39}\)** & **83.33\({}_{+5.18}\)** & **94.44\({}_{+2.37}\)** & **94.43\({}_{+2.48}\)** \\   & & **TS2vec** & 73.28\({}_{+4.34}\) & 74.14\({}_{+4.33}\) & 73.52\({}_{+3.77}\) & 73.00\({}_{+3.18}\) & 81.66\({}_{+5.20}\) & 81.58\({}_{+5.11}\) \\  & & **TF-C** & 75.66\({}_{+1.12}\) & 75.54\({}_{+8.14}\) & 75.58\({}_{+1.19}\) & 75.38\({}_{+1.41}\) & 81.38\({}_{+4.19}\) & 71.56\({}_{+1.08}\) \\  & & **Mixing-up** & 59.38\({}_{+5.33}\) & 64.85\({}_{+4.38}\) & 61.94\({}_{+3.42}\) & 58.17\({}_{+3.41}\) & 75.02\({}_{+6.14}\) & 73.44\({}_{+5.82}\) \\  & & **TS-TCC** & 77.83\({}_{+6.90}\) & 79.73\({}_{+7.49}\) & 76.18\({}_{+7.21}\) & 76.43\({}_{+7.56}\) & 84.12\({}_{+7.32}\) & 84.12\({}_{+7.61}\) \\  & & **SimCLR** & 56.09\({}_{+2.92}\) & 53.31\({}_{+8.74}\) & 57.13\({}_{+2.99}\) & 44.10\({}_{+4.44}\) & 53.81\({}_{+8.74}\) & 51.08\({}_{+1.53}\) \\  & & **CLOCS** & 76.97\({}_{+3.01}\) & 81.70\({}_{+3.21}\) & 74.69\({}_{+3.26}\) & 74.75\({}_{+3.61}\) & 86.91\({}_{+3.61}\) & 86.70\({}_{+3.64}\) \\  & & **COMET (Ours)** & **91.43\({}_{+3.32}\)** & **92.52\({}_{+2.36}\)** & **90.71\({}_{+3.85}\)** & **91.14\({}_{+3.31}\)** & **96.44\({}_{+2.84}\)** & **96.48\({}_{+2.82}\)** \\   & & **TS2vec** & 64.93\({}_{+5.33}\) & 65.28\({}_{+3.52}\) & 65.14\({}_{+3.97}\) & 64.64\({}_{+3.58}\) & 70.56\({}_{+5.38}\) & 68.97\({}_{+5.75}\) \\  & & **TF-C** & 75.66\({}_{+1.61}\) & 75.26\({}_{+1.91}\) & 74.77\({}_{+3.64}\) & 74.33\({}_{+4.48}\) & 79.56\({}_{+1.67}\) & 81.89\({}_{+1.20}\) \\  & & **Mixing-up** & 63.67\({}_{+1.20}\) & 65.02\({}_{+2.09}\) & 64.64\({}_{+6.13}\) & 65.53\({}_{+1.21}\) & 71.95\({}_{+3.39}\) & 70.15\({}_{+3.70}\) \\  & & **TS-TCC** & 53.04\({}_{+8.80}\) & 52.39\({}_{+1.73}\) & 52.00\({}_{+8.01}\) & 44.69\({}_{+1.24}\) & 58.89\({}_{+1.95}\) & 51.41\({}_{+7.81}\) \\  & & **SimCLR** & 55.42\({}_{+2.42}\) & 52.18\({}_{+5.55}\) & 51.37\({}_{+2.76}\) & 45.20\({}_{+4.79}\) & 52.18\({}_{+5.55}\) & 50.87\({}_{+4.5}\) \\  & & **CLOCS** & 64.50\({}_{+4.04}\) & 65.67\({}_{+4.74}\) & 74.72\({}_{+3.74}\) & 63.73\({}_{+4.86}\) & 61.05\({}_{+1.51}\) & 69.16\({}_{+6.75}\) & 68.15\({}_{+2.70}\) \\  & & **COMET (Ours)** & **88.22\({}_{+3.36}\)** & **88.55\({}_{+2.73}\)** & **88.56\({}_{+3.44}\)** & **88.14\({}_{+3.37}\)** & **86.05\({}_{+1.36}\)** & **96.12\({}_{+1.31}\)** \\   &  & **TS2vec** & 80.21\({

## 6 Conclusion

This paper introduces COMET, a hierarchical contrastive representation learning framework tailored for medical time series. COMET leverages all data levels of medical time series, including patient, trial, sample, and observation levels, to capture the intricate complexities of the data. Through extensive experiments on three diverse datasets, we demonstrate that our method surpasses existing state-of-the-art methods in medical time series analysis. Our framework also shows its effectiveness in patient-independent downstream tasks, highlighting its potential to advance medical time series analysis and improve patient care and diagnosis.

One limitation of our work is the presence of label conflicts between different levels. In patient-level consistency, we assume all samples belonging to the same patient are positive while others are negative. In trial-level consistency, we consider samples from the same trial as positive samples and others as negative. This means a positive pair at the patient level may be considered negative at the trial level, as they do not belong to the same trial.

In future research, we aim to investigate the efficacy of our method across a wider range of datasets, with a particular focus on ECG datasets. Additionally, we intend to explore approaches to integrate disease-level consistency within our self-supervised contrastive framework.

We discuss the **broader impacts** with potential negative social impacts in Appendix H.