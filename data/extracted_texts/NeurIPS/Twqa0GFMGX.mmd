# Idiographic Personality Gaussian Process for Psychological Assessment

Yehu Chen, Muchen Xi, Jacob Montgomery

Joshua Jackson, Roman Garnett

Washington University in St Louis

chenyehu,m.xi,j.jackson,jacob.montgomery,garnett@wustl.edu

###### Abstract

We develop a novel measurement framework based on a Gaussian process core-gionalization model to address a long-lasting debate in psychometrics: whether psychological features like personality share a common structure across the population, vary uniquely for individuals, or some combination. We propose the idiographic personality Gaussian process (ipgp) framework, an intermediate model that accommodates both shared trait structure across a population and "idiographic" deviations for individuals. ipgp leverages the Gaussian process coregionalization model to handle the grouped nature of battery responses, but adjusted to non-Gaussian ordinal data. We further exploit stochastic variational inference for efficient latent factor estimation required for idiographic modeling at scale. Using synthetic and real data, we show that ipgp improves both prediction of actual responses and estimation of individualized factor structures relative to existing benchmarks. In a third study, we show that ipgp also identifies unique clusters of personality taxonomies in real-world data, displaying great potential to advance individualized approaches to psychological diagnosis and treatment.

## 1 Introduction

Building models for the evaluation of latent traits from observed responses is crucial to understand long-term behaviors through repeated quantitative assessments. These are used, for example, to study emotional stability after medical treatment or the development of academic ability during secondary education . However, existing frameworks face several interrelated limitations. First, there are strong reasons to believe that standard taxonomies may over-generalize, failing to distinguish between related psychological phenomena that often differ in etiology, symptoms, and biological processes between individuals [e.g., 1, 4], and this may lead to inaccuracy when making predictions . A related issue is that measurement models are rarely individualized, instead assuming that (1) the correlation between latent traits of interest and survey responses are invariant across individuals and (2) the relationship between the latent traits themselves are the same for everyone. Lastly, current models are almost always developed for cross-sectional data that are collected only once from each respondent, which overlooks any potential dynamics of psychological processes.

To address these limitations, previous research has adopted three different approaches, each inadequate in its own way. First, recent work has proposed an _idiographic_ approach that builds a completely distinct taxonomy for each individual . However, complete personalization can sacrifice generalizability and interpretability for clinicians, as any possible population commonality is ignored. A second line of research focuses on building dynamic psychometric models of time-series data via some variant of item response theory , longitudinal structural equation modeling , vectorized autoregression  and/or Gaussian process (gp) latent trajectories . However, all these models adopt the _nomothetic_ approach, assuming that the responses of all individualsshare an identical latent structure. Finally, there is a smaller body of work that adopts intermediate approaches to create individualization while maintaining group commonality (e.g., ). However, prior research models quantitative responses directly, ignoring the latent structures that are often the actual focus of domain researchers.

In this work, we propose an idiographic personality Gaussian process (ipgp) framework for assessing dynamic psychological taxonomies from time-series survey data. This framework combines nomothetic and idiographic approaches by employing a common structure to explain typical circumstances, while allowing individual structures to accommodate deviations into distinct forms. We leverage the Gaussian process coregionalization model based on multi-task kernels to conceptualize responses of grouped survey batteries, adjusted to non-Gaussian ordinal data, and utilize ipgp for hypothesis testing of domain theories. Methodologically, our approach combines Gaussian process latent variable models (gplvm) , Gaussian process dynamic systems (gpdm) [17; 18] and gp ordinal regression for Likert-type survey data [21; 22]. Despite involving latent variables and gps, ipgp differs from gplvm in two ways: (1) it optimizes the factor loading matrix while marginalizing the latent variables, and (2) it accommodates categorical data using a non-Gaussian ordered probit likelihood. Computationally, our framework exploits stochastic variational inference for latent factor estimation, contrasting with other gp measurement models relying on Gibbs sampling that may not scale efficiently to intensive longitudinal setups [18; 23].

To our knowledge, our work presents the first multi-task Gaussian process latent variable model for dynamic idiographic assessment. While multi-task gps have found recent applications in areas such as causal inference [24; 25; 26], environmental science [27; 28; 29], and biomedical research , their potential remains largely unexplored in psychology. Current psychometric models typically focus on cross-sectional settings without dynamics [6; 31; 8] or single task settings that ignore inter-battery correlations [32; 33]. We conducted an extensive simulation study comparing ipgp against benchmark methods and analyzed an existing cross-sectional personality dataset. Our results demonstrate that ipgp simultaneously enhances the estimation of idiographic taxonomies and improves the prediction of responses. Additionally, we collected a novel irb-approved longitudinal dataset. When applied to this data, ipgp not only shows superior performance in response prediction, but also suggests unique personality taxonomies. These findings highlight ipgp's significant potential for advancing individualized approaches to psychological diagnosis and treatment.

## 2 Background

We start by laying out the ordinal factor model for building standard taxonomy from survey data [34; 35]. We then briefly discuss several existing idiographic longitudinal models in psychological assessment and review the Gaussian process model.

Ordinal factor analysis.Consider the scenario where some set of units, \(i\{1,,N\}\), repeatedly answer the same set of \(j\{i,,J\}\) survey items over \(t\{1,,T\}\) periods with ordinal observations \(y_{ijt}\{1,,C\}\) up to \(C\) levels. For example, the responses could be Likert-typed, ranging from "strongly disagree" to "strongly agree". The latent factor model posits that the \(j\)th underlying latent variable \(f^{(i)}_{j}(t)\) for unit \(i\) at time \(t\) can be recovered as \(_{j}^{T}_{i}(t)\), where \(_{i}(t)^{D}\) are unit-level latent factors and \(_{j}^{D}\) are factor loadings. The \(f^{(i)}_{j}(t)\)s are then mapped to ordinal responses via an ordered probit model: \(py_{ijt}=c f^{(i)}_{j}(t)=f=(b_{c}-f)-(b_{c-1}-f)\) with threshold parameters \(b_{0}<<b_{C}\). Usually \(b_{0}\) and \(b_{C}\) are fixed to \(-\) and \(+\) so that the resulting categorical probability vector sums to \(1\), while \(b_{1},,b_{C-1}\) are allowed to move freely. Stacking \(_{i}(t)\)s, \(_{j}\)s and \(y_{ijt}\)'s into matrices \(\), \(\) and tensor \(\), the joint likelihood can be written as \((,)=_{i}_{j}_{t}p y_{ijt}_{i}(t),_{j}\). Identification is guaranteed with standard orthogonality and normalization constraints . This factor model is also known as an item response model [37; 38], and can be estimated via maximum likelihood, weighted least squares, or an em algorithm [39; 40; 41].

Idiographic longitudinal assessment.In psychological assessment, the idiographic approach emphasizes _intrapersonal_ variation by requiring distinct loadings, while the nomothetic approach identifies general _interpersonal_ variation assuming shared factor loadings . In terms of data collection, the idiographic approach usually surveys each individual multiple times (\(N=1\) and large \(T\)) for learning personalized taxonomy rather than many individuals at a single shot (large \(N\) and \(T=1\)). To extract individualized dynamics from time-series data, recent psychometric models have utilized longitudinal structural equations by explicitly specifying any intrapersonal and temporal dynamics. However, these typically require strong model-based assumptions from domain-theory about this dynamic process, and may be sensitive to model misspecification [11; 13]. Meanwhile, hierarchical vector autoregression models may automatically learn individual trajectories over time, but are designed to model observed responses directly rather than latent traits of interest to domain scholars [14; 15].

Gaussian process.A Gaussian process (gp) can be used to define a distribution over \(f\) such that the values of \(f\) at arbitrary finite subset of \(\) have a joint multivariate Gaussian . A \((,K)\) is specified with a mean function \(\) and a positive-definite kernel function \(K\); evaluating these functions pointwise determines the mean and covariance of these finite-dimensional distributions. The most common kernel is the squared exponential (rbf) kernel \(K(_{1},_{2})=(-_{1}{}^{T} _{2})\) with precision matrix \(=(1/_{1}^{2},,1/_{d}^{2})\) and \(d=()\). The posterior of a gp can be derived analytically for a Gaussian likelihood but must be approximated in modeling latent variables with categorical indicators. We discuss the variational approximation method we use for inference in Sec. (3).

## 3 Methodology

We propose an idiographic personality Gaussian process (ipgp) framework for assessing individualized dynamic psychological taxonomies from time-series survey data. Instead of joint estimation of latent factors and their loadings that cannot guarantee rotational and scaling invariance, we marginalize out the latent variables and focus on learning taxonomies of loadings. The overall architecture of ipgp is illustrated in Figure (1), where the ordinal input observations across the indicators are modeled as ordinal transformations of latent dynamic gp with individualized rbf kernels and loading matrices.

### Multi-task learning

Typically in psychological assessment, survey questions are meticulously grouped such that each group gauges a particular latent trait (e.g. dimension of personality). Hence, we conceptualize the assessment of psychological traits as a multi-task learning problem, where each question represents a distinct task but can be correlated with other tasks. A multi-task gp is an extension of the single-task gp but for vector-valued functions . To motivate the multi-task framework, first consider the

Figure 1: Proposed ipgp model for inferring latent factors and factor loadings from dynamic ordinal data. Input ordinal observations across indicators are modeled as ordinal transformations of latent dynamic Gaussian processes with individualized rbf kernels and loading matrices.

two-task scenario with two \(T 1\) vector \(}^{(i)}\) and \(}^{(i)}\) denoting the latent temporal processes of unit \(i\) for question \(j=1,2\). To fix the scale of latent factors, a time-level Gaussian process prior is placed on \(_{i}(t)(,_{}^{(i)})\). By exploiting affine property of Gaussians, the induced joint distribution of vectorized \([}^{(i)},}^{(i)}]^{T}\) can be written as:

\[}^{(i)}\\ }^{(i)} \\ ,_{1}^{T}_{1}_{}^{(i)}&_{1}^{T}_{2}_{}^{(i)}\\ _{2}^{T}_{1}_{}^{(i)}&_{2}^{T }_{2}_{}^{(i)}\] (1)

whose covariance of shape \(2T 2T\) contains four block matrices \(_{}^{(i)}\) scaled by different \(_{j}^{T}_{j^{}}\) (\(j,j^{}\{1,2\}\)). Specifically, \(_{1}^{T}_{2}\) controls the inter-task covariance between these two tasks and \(_{j}^{T}_{j}\) (\(j\{1,2\}\)) control their intra-task variance. This multi-task structure is also known as the linear model of coregionalization (lmc) , which models output functions as linear combinations of several independent latent processes. In our case, each dimension in \(_{i}(t)\) represents one latent process, which jointly defines the functions as \(}^{(i)}=_{j}^{T}_{i}(t)\). To extend this, let \(^{(i)}=[}^{(i)},,}^{(i)}]^{T}\) represents the flattened \(JT 1\) vector consisting of all \(J\) tasks. We write \(^{(i)}\) in a formal multi-task gp notation using Kronecker product \(\):

\[^{(i)} ,_{}^{(i)} _{}^{(i)}\] (2) \[_{}^{(i)} =_{}^{T}_{}+^{ (i)}{}^{T}^{(i)}\] (3)

where \(_{}^{(i)}\) denotes the unit-specific task covariance matrix, consisting of the self inner products of \(D J\) shared interpersonal loading \(_{}\) and \(D^{*} J\) unit-specific low-rank \(^{(i)}\) (\(D^{*}<D\)) for intrapersonal deviations that serves to be the additional idiographic component, independent of \(_{}\). In our experiments, we found degraded performance for \(D^{*}=2\) but extra computational costs so we focused on \(D^{*}=1\). The Kronecker product \(\) then multiplies each entry in the \(J J\) task covariance with \(_{}^{(i)}\), and returns the stacked \(JT JT\) covariance for \(^{(i)}\). Through the use of time kernel \(_{}^{(i)}\). Properties of the latent trait trends such as periodicity or autocorrelation could be incorporated. Here we use the common rbf kernel \(_{}^{(i)}(t,t^{})=-(t-t^{ })^{2}/_{i}^{2}\) to account for dynamic changes in the latent attributes, whose bandwidth is determined by the unit-specific length scale \(_{i}\), but any other kernel can substitute rbf as practitioners see fit. Finally, the latent variables \(}\)s are further projected to response space by the ordered probit model.

### Variational inference

Due to the non-Gaussian ordinal likelihood, we adopt the variational inference technique (vi) with inducing points introduced in . Dropping superscript for demonstration, vi utilizes a variational distribution \(q()=(_{},})\) on inducing variables \(\) to approximate \(p()\) using the conditional \(p()\). Hence, the conditional log-likelihood \( p()\) can be lower bounded by the expected log-likelihood w.r.t. \(p()\), after exploiting the non-negativity of Kullback-Leibler (kl) divergence between \(p()\) and \(p()\):

\[ p()_{p()}  p()\] (4)

Furthermore, a lower bound on model evidence (elbo) can be obtained by combining Eq. (4) and an inequality derived by another kl divergence \([q() p()] 0\) (see Appendix B for details):

\[ p() _{q()} p( )-[q() p()]\] (5) \[_{q()} p( )-[q() p()]\] (6)

where the kl divergence \([q() p()]\) between the variational \(q()\) and prior \(p()\) can be computed in closed form as both distributions are Gaussians. The expectation of log-likelihood \( p()\) under the marginal distribution \(q()= p()q()d\) is intractable but can be numerically approximated using Gauss-Hermite quadrature method. The variational parameters \(_{}\) and \(}\), individualized loadings \(_{i}\) and \(()\) as well as likelihood parameters \(\{b_{c}\}\)s are then optimized to maximize this lower bound. Finally, the predictive likelihood of new \(p(^{*})= p(^{*}^{*})p(^{*} )q^{*}()d\) is obtained by marginalizing out the optimized \(q^{*}()\). Throughout our experiments, we adopt stochastic inference for computational scalability.

### Theory testing

Our ipgp framework also naturally facilitates downstream tasks such as domain theory testing between models with and without shared or idiographic components. We adopt posterior odds ratio test, using posterior \(p(_{i})=|_{i})p(_{i})}{_{i}p(|_{i})p(_{i})}\) over a pool of models \(\{_{i}\}\) conditioning on observations \(\) with prior weights \(p(_{i})\), as the hypothesis test to determine whether the latent structures for each individual are indeed distinct or are simply explainable by interpersonal commonality. Specifically, we refer the multi-task model in Eq. (3) as the _idiographic_ model, and compare it with an _nomothetic_ model without unit-specific components: \(_{}^{}=_{}_{ }^{T}\).

Note that compared to this baseline nomothetic model, our proposed idiographic model in Eq. (3) introduces additional unit-level \(JN\) loading parameters that enlarge the hyperparameter optimization space. Hence, we propose to first learn the interpersonal loading matrix \(_{}\) using the standard cross-sectional data from a nomothetic model that focuses on learning of population taxonomy, and then use the estimated \(_{}\) as informative prior in the full model. We will show empirically in Sec. (4) that with this stronger prior ipgp achieves a more precise estimation of individual taxonomies.

## 4 Experiments

We now evaluate ipgp in learning idiographic latent taxonomies and predicting actual responses against baseline methods from both psychometrics and Gaussian process literature in three experiments: a simulation study, a re-analysis of a large cross-sectional dataset, and a pilot study of repeated measures of the Big Five  personality traits.

### Simulation and ablation

Setup.Our simulation considers longitudinal data of \(N=10\) units over \(T=30\) periods. We assume that the latent traits of each unit \(i\) have dimension \(D=5\), and each latent vector is generated independently from a gp\(_{i}^{(d)}(t)(,_{}^{(i)})\) with a unit-specific length scale uniformly randomly picked from \(_{}^{(i)}\). We split \(J=20\) items into \(D\) subsets of size \(J/D=4\), such that each subset dominates one dimensional in the latent traits. Specifically, we set high value of \(3\) in the population factor loading matrix \(_{}\) for entries corresponding to the \(k\)th subset for dimension \(k\), and low values drawn from \([-1,1]\) otherwise. We also set each unit-specific loading \(_{i}\) from \([-1,1]\). To introduce sparsity and reverse coding, we randomly set half of the loadings to zero and invert the signs of the remaining half. Finally, we generate the \(y_{ijt}\)s according to the ordered probit model with \(C=5\) levels, and apply \(80\%/20\%\) splitting for training and testing.

    & **train acc\(\)** & **train ll\(\)** & **test acc\(\)** & **test ll\(\)** & **cmd\(\)** \\  grm & \(0.261 0.005\) & \(-3.556 0.092\) & \(0.261 0.006\) & \(-3.578 0.098\) & \(0.657 0.021\) \\ gPCM & \(0.562 0.017\) & \(-2.067 0.182\) & \(0.495 0.012\) & \(-2.409 0.143\) & \(0.545 0.016\) \\ srm & \(0.286 0.006\) & \(-7.408 0.063\) & \(0.289 0.008\) & \(-7.341 0.084\) & \(0.300 0.024\) \\ gPDM & \(0.687 0.010\) & \(-4.358 0.028\) & \(0.667 0.010\) & \(-4.377 0.029\) & \(0.262 0.016\) \\ LSM & \(0.539 0.021\) & \(-0.961 0.015\) & — & — & \(0.256 0.011\) \\ tvar & \(0.554 0.018\) & \(-1.168 0.014\) & — & — & \(0.987 0.013\) \\  ipgp-nom & \(0.807 0.007\) & \(-0.535 0.015\) & \(0.790 0.008\) & \(-0.555 0.017\) & \(0.257 0.009\) \\ ipgp-ind & \(0.932 0.003\) & \(-0.243 0.008\) & \(0.916 0.004\) & \(-0.267 0.009\) & \(0.530 0.005\) \\ ipgp-low & \(0.897 0.004\) & \(-0.313 0.010\) & \(0.884 0.005\) & \(-0.334 0.011\) & \(0.397 0.007\) \\ ipgp-np & \(0.898 0.003\) & \(-0.318 0.009\) & \(0.883 0.005\) & \(-0.342 0.011\) & \(0.467 0.010\) \\ 
**IPGP** & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Comparison of averaged accuracy, log-likelihood and correlation matrix distance between ipgp, baselines, and ablated models in the simulation study. The full ipgp model (indicated in bold) significantly outperforms all ablated and baseline methods. Results from ablations imply that ipgp succeeds in predicting the correct labels due to its idiographic components and proper likelihood, and a well-informed population kernel is crucial in recovering the factor loadings. “—” indicates baseline software that cannot handle missing values.

Metrics and baselines.We consider two sets of metrics for evaluation: (1) the in-sample and out-of-sample predictive accuracy (acc) and log-likelihood (ll) of the actual responses, (2) the correlation matrix distance (cmd) between the estimated factor loading matrix and the true ones, which is defined for two covariance matrices \(_{1},_{2}\) as \((_{1},_{2})=1-_{1}_{ 2})}{\|_{1}\|_{f}\|_{2}\|_{f}}\) where \(f\) is the Frobenius norm. Note that cmd becomes zero if \(_{1},_{2}\) are equal up to a scaling factor, and one if they are orthogonal after flattening. We compare ipgp to (1) various latent variable models for ordinal responses, including the graded response model (grm) , the generalized partial credit model (gpcm)  and the sequential response model (srm) , (2) Gaussian process dynamic model (gpdm) [17; 18] where the continuous predictions are rounded to the nearest ordinal level, (3) latent structural model (lsm) [13; 49] with trait-dependent latent variables and (4) time-varying vector autoregression (var) with regularized kernel smoothing . We also compare ipgp with several ablated models: (1) ipgp-not without the idiographic kernel, (2) ipgp-ind without the population kernel, (3) ipgp-low with lower-rank factors of 2 than actual rank of \(5\) in the synthetic setup and (4) ipgp-np where the population kernel is learned from scratch rather than fixed to the informative prior. Note that \(_{}\) in the full ipgp model is fixed as learned from ipgp-nom.

Results.We use \(100\) inducing points and the adam optimizer with learning rate \(0.05\) to optimize elbo for \(10\) epoches with batch size of \(256\). We repeat our simulation with \(25\) different random seeds using 300 cores on Intel Xeon 2680 CPUs. Table 1 shows the comparison of the average predictive accuracy, log-likelihood, and correlation matrix distance between ipgp and baselines and ablated models. Our ipgp model (indicated in bold) significantly outperforms all ablated models and baseline methods in estimated correlation matrix, predictive accuracy, and log-likelihood of both training and testing sets in paired-\(t\) tests. We found that ipgp is able to predict the correct labels due to its idiographic components and proper likelihood, since ipgp-nom and ipgp-gl are two of the worst ablations for all prediction metrics. In addition, ipgp-ind and ipgp-np have the worst correlation matrix estimation, implying that a well-informed population kernel is crucial in recovering the underlying factor structures.

Robustness of IPGP.To assess ipgp's robustness to rank misspecification, we conducted additional exploratory factor analysis using our simulated data. We tested model performance with ranks of 2, 5, and 8, where 5 represents the true rank of the data. As shown in Table 2, both the true-rank (5) and higher-rank (8) models significantly outperform the low-rank (2) model. However, increasing the rank beyond the true rank of 5 yields no additional performance benefits: the high-rank model is not significantly better than the true-rank model in a paired t-test. These results demonstrate two key points: first, low-rank approximations inherently lack the capacity to fully capture the underlying structure, and second, increasing the rank beyond the true rank provides no additional benefit. This underscores the importance of careful exploratory analysis in practical applications to determine the appropriate rank.

### Cross-sectional factor analysis

We next validate the popular Big Five personality theory using standard cross-sectional data via a factor analysis, where a range of factors are tested and then compared according to model evidence. This serves to show that the model works appropriately to detect known latent traits even in non-dynamic settings, and to validate the informative prior for the \(_{}\) matrix in our next experiment. We utilize an existing dataset called life outcomes of personality replication (loopr) , which is collected from 5,347 unique participants on the Big Five Inventory  consisting of \(60\) questions. Our validation considers a range of latent trait dimension counts from \(D=1,,5\). For each dimension count, we first apply principal component analysis (pca) directly on the correlation matrix

   rank & **train acc \(\)** & **train ll \(\)** & **test acc \(\)** & **test ll \(\)** & **cmd \(\)** \\ 
2 (lower) & 0.897 \(\) 0.004 & \(-\)0.313 \(\) 0.010 & 0.884 \(\) 0.005 & \(-\)0.334 \(\) 0.011 & 0.397 \(\) 0.007 \\
5 (true) & **0.957 \(\) 0.002** & _\(-\)0.159 \(\) 0.005_ & _0.942 \(\) 0.002_ & _\(-\)0.184 \(\) 0.006_ & _0.128 \(\) 0.006_ \\
8 (higher) & **0.957 \(\) 0.002** & \(-\)**0.161 \(\) 0.004** & **0.945 \(\) 0.002** & \(-\)**0.183 \(\) 0.005** & **0.124 \(\) 0.006** \\   

Table 2: Model comparison where the model rank varies from 2, 5 to 8 while the true rank is 5. The best models are indicated in bold, and models that are not significantly worse than the best model are indicated in italics.

of the cross-sectional observations to learn a vanilla population factor loading matrix. We then initialize \(_{}\) in our model with this vanilla loading matrix, and optimize the loading matrix jointly with the variational parameters. Note that \(T=1\) in loopr, so we drop the idiographic components.

Validation of Big Five.Table 3 presents the predictive accuracy and averaged log-likelihood for our method and various baselines (excluding tvar due to its lack of low-rank assumption) across different values of \(D\) in loopr. Bold numbers indicate the best model for each \(D\), while italic numbers highlight the best model across all \(D\) values. Although ipgp with \(D=5\) shows slightly lower in-sample predictive accuracy compared to the \(D=3\) model, it demonstrates significantly stronger model evidence than all alternatives. Posterior odds ratio test reveals that the second-best model is \((-79) 5 10^{-35}\) times less likely than the five-factor model.

We further evaluated ipgp's performance through exploratory analysis, testing model ranks from 1 to 10. Results shown in Table 4 provide strong support for a rank-5 model, which achieves both higher model evidence and lower bic, strengthening the evidence for the Big Five theory. The bic follows a V-shaped pattern, decreasing as the rank approaches 5 and increasing thereafter, indicating that rank-5 represents an optimal balance point: ranks below 5 provide insufficient model capacity, while higher ranks lead to overfitting. These findings demonstrate that when analyzing psychological measurements from standard cross-sectional data, ipgp successfully identifies the correct underlying factor structure, making it valuable for downstream applications.

    &  &  \\ 
**MODEL** & \(D=1\) & \(D=2\) & \(D=3\) & \(D=4\) & \(D=5\) & \(D=1\) & \(D=2\) & \(D=3\) & \(D=4\) & \(D=5\) \\  pca & 0.106 & 0.099 & 0.123 & 0.217 & 0.192 & \(-1.957\) & \(-1.990\) & \(-2.009\) & \(-2.036\) & \(-2.051\) \\ grm & 0.238 & 0.107 & 0.178 & 0.113 & 0.146 & \(-1.838\) & \(-1.832\) & \(-1.814\) & \(-1.838\) & \(-1.841\) \\ grm & 0.213 & 0.156 & 0.186 & 0.159 & 0.163 & \(-1.754\) & \(-1.761\) & \(-1.764\) & \(-1.750\) & \(-1.756\) \\ srm & 0.243 & 0.134 & 0.179 & 0.125 & 0.155 & \(-1.784\) & \(-1.784\) & \(-1.783\) & \(-1.780\) & \(-1.767\) \\ grm & 0.268 & 0.272 & 0.266 & 0.268 & 0.263 & \(-2.155\) & \(-2.158\) & \(-2.158\) & \(-2.159\) & \(-2.158\) \\ lsm & 0.188 & 0.114 & 0.110 & 0.105 & 0.104 & \(-1.997\) & \(-1.960\) & \(-1.908\) & \(-1.845\) & \(-1.775\) \\
**IPGP** & **0.322** & **0.319** & **0.323** & **0.318** & **0.318** & **\(-\)1.478** & **\(-\)1.477** & **\(-\)1.477** & **\(-\)1.476** \\   

Table 3: In-sample accuracy and averaged log lik of our method and baselines for various ranks \(D\) in loopr. Best model for each \(D\) is indicated in bold and the best model across different \(D\)s is further indicated in italic.

Figure 2: Illustration of raw correlation matrix (left) and our estimated Big Five loading matrix (right). Both correlation matrices display a _block_ pattern, where estimated interpersonal variation show strong correlation between questions within the same factor of the Big Five personalities and weak correlation across different factors. Besides, questions corresponding negative emotionality show minor negative correlation with those corresponding to extraversion and conscientiousness, suggesting trait-by-trait interaction effects.

Estimated interpersonal variation.Figure 2 compares the raw correlation matrix with our estimated Big Five correlation matrix. Both matrices exhibit a distinctive _block_ pattern, characterized by strong correlations between questions within each Big Five factor and weak correlations across different factors. We also observe that questions related to negative emotionality demonstrate slight negative correlations with questions measuring extraversion and conscientiousness, suggesting the presence of meaningful trait-by-trait interaction effects.

### Longitudinal Pilot Study

To further demonstrate ipgp in longitudinal setting for learning idiographic psychological taxonomies, we collected intensive longitudinal data using experience sampling measures (esm). We highlight the predictive ability of ipgp through a prediction and a leave-one-trait-out cross-validation task. We also illustrate how ipgp identifies unique personality taxonomies that might advance individualized approaches to psychological diagnosis and inspire new theory.

Data collection.We employed an experience sampling method (esm) design where participants completed personality assessments six times daily over a three-week period, allowing for a maximum of \(126\) assessments per person. Our study included \(93\) valid student participants, yielding 8,770 total assessments with an average of \(94\) assessments per participant. We based our assessment on the bfi-2 , which provides comprehensive coverage of the trait space and ensures proper identification of latent factors. While the original bfi-2 contains \(60\) items (four items for each of the three sub-factors within each Big-Five domain), we modified it for our esm design by removing items unsuitable for contextualized assessment. To reduce participant fatigue and minimize learning effects from repeated measures, we implemented a planned missing design: participants randomly responded to two out of three items for each sub-factor, resulting in a streamlined 30-item assessment. Note that our data is collected from a student sub-population as non-representative samples, and future studies may explore the model's applicability across diverse populations.

Comparison between nomothetic and idiographic models.We run the full ipgp model with idiographic component and unit-specific time kernel on the collected longitudinal data. Again we set the ranks of the population and individual loading matrices to \(5\) and \(1\) respectively, and incorporate prior knowledge of the cross-sectional data by fixing the population loadings as the Big Five loadings estimated in Sec. (4.2) and optimizing the individual loadings. We contrast our proposed idiographic model (ipgp) and baselines in Table 5, which shows the in-sample prediction, averaged log-likelihood and posterior odds ratio. We found that ipgp outperforms ipgp-nom with higher predictive accuracy and log-likelihood, and is decisively favored by a posterior odds ratio of \((1.06 10^{4})\).

   rank & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\ 
**LL/N \(\)** & \(-1.478\) & \(-1.477\) & \(-1.477\) & \(-1.477\) & \(-1.477\) & \(-1.477\) & \(-1.477\) & \(-1.477\) & \(-1.477\) & \(-1.477\) \\
**BIC (\( 10^{11}\))** \(\)** & 1.2736 & 1.2726 & 1.2728 & 1.2726 & **1.2722** & 1.2725 & 1.2726 & 1.2732 & 1.2732 & 1.2724 \\   

Table 4: Model performance of ipgp with model ranks from 1 to 10 in Loop data.

Figure 3: Four residual correlations as identified by our k-mean clustering. Each heatmap displays the trait-level residual correlation averaged across corresponding batteries for one cluster, with darker red and blue indicating larger positive and negative deviations. For instance, agreeableness (A) is more correlated to extraversion (E) than the population profile in the first profile, but less correlated to openness (O) in the second profile. Moreover, these two directions of deviations are even exacerbated in the third and fourth profiles.

Predictive performance of ipgp.We also evaluate the out-of-sample performance of the idiographic and nomothetic models using two prediction tasks: forecasting future responses and leave-one-trait-out cross validation. For the forecasting task, we train both models with data from the first \(40\) days and predict future responses for the last \(5\) days. For the cross-validation task, we predict responses of each trait by training on data belonging to the other four traits, where 20% of responses for one trait was held out (randomly choosing the trait and items to remove). Figure (4) shows the predictive accuracy and log-likelihood of ipgp and ipgp-nom for the forecasting task over varying horizons and for the leave-one-trait-out cross-validation task. ipgp has consistently better performance than ipgp-nom in both tasks, except for being slightly less accurate in predicting extraversion. Overall, ipgp is favored than ipgp-nom by posterior odds ratios of \((43)\) and \((716)\) in these two tasks.

Discovery of taxonomies.Despite our small cohort size (\(93\) respondents), we also explore how the profiles of personality that substantially differ from the interpersonal commonality cluster into informative groups. Specifically, we first perform a \(k\)-mean clustering using all \(93\) estimated individual correlation matrix with cmd as the distance metric, and then compute the residual correlation between each estimated clustering centroid and the population correlation. Figure (3) illustrates four residual correlations identified by our \(k\)-mean clustering. Each heatmap displays the residual correlation at the trait level averaged between the corresponding batteries for one cluster, with darker red and blue indicating larger positive and negative deviations. For instance, agreeableness (A) is more correlated to extraversion (E) than population profile in the first profile, but less correlated to openness (O) in the second profile. Moreover, these two directions of deviations are even exacerbated in the third and fourth profiles.

The discovery of unique personality taxonomies suggests a potential resolution to the longstanding idiographic versus nomothetic debate in personality and psychometric sciences. Our findings indicate that the optimal approach lies between these two extremes, rather than fully embracing either perspective. The four distinct profiles that we identified, while derived from the Big Five framework, demonstrate how individuals can meaningfully deviate from a common taxonomy. These deviations may provide valuable insights into individuals' motivations, behavioral patterns, and self-concepts. For example, individuals matching Profile 4 show a strong correlation between Extraversion and Agreeableness, possibly reflecting a tendency toward warm and socially engaging behavior (such as someone who naturally connects with and shows kindness to everyone at social gatherings). Furthermore, these distinct profiles enhance the predictive power of individual-level (\(N=1\)) models by allowing them to learn from people with similar characteristic patterns.

## 5 Related work

**Idiographic assessment** captures critical individual characteristics that are often lost in simplified taxonomies of psychological behaviors . Evidence from multiple psychometric fields demonstrates that nomothetic models, which focus solely on interpersonal variation, often lack generalizability. Researchers have proposed various solutions to address this limitation. Song and Ferrer  enhanced dynamic factor models with random effects to analyze psychological processes. Jongerling et al.  developed a multilevel first-order autoregressive model incorporating random intercepts to track daily positive effects across weeks. Beltz et al.  bridged nomothetic and idiographic approaches by introducing individual components to the group iterative multiple model (gimme) for clinical data analysis. However, these methods share a common limitation: they model in response space rather than latent space when handling ordinal survey data.

**Gaussian process latent variable model** (gplvm) is a dimensional reduction method for Gaussian data, where the latent variables are optimized after integrating out the function mappings [20; 56]. Our proposed framework differs from gplvm as we optimize the factor loading matrix while marginalizing the latent variables. In addition, our model contrasts gplvm and (variational) Gaussian process dynamical model (gpm) [16; 17] in our non-Gaussian ordered logistic observation model and the use of multi-task kernel for latent structure. Finally, our longitudinal framework with stochastic variational inference learning differs from the static gp item response theory (gpirt)  with more computationally demanding Gibbs sampling.

**Longitudinal measurement models** have gained prominence as researchers increasingly incorporate temporal dynamics into psychological theories through longitudinal survey designs [57; 58]. This development has spawned various methodological approaches. One family of methods includes longitudinal structural equation models (sem), such as multiple-group longitudinal sem and longitudinal growth curve models, designed for repeated measurement studies . The M_plus_ software later extended these capabilities by implementing dynamic sem with Bayesian Gibbs sampling [13; 49]. Another stream of research produced dynamic item response models [9; 10; 3] and time-varying vector autoregressive models [14; 15] to track latent trait trajectories. While multi-task Gaussian process time series have been successfully applied to Gaussian observations in behavioral research  and found applications in causal inference [24; 26], environmental science , and biomedical research , they remain unexplored for survey batteries with non-Gaussian likelihood where exact inference is not possible.

## 6 Conclusion

We introduce the idiographic personality Gaussian process (ipgp) model, a novel approach for personalized psychological assessment that learns intrapersonal taxonomies from longitudinal ordinal survey data, a configuration that remains underexplored in Gaussian process dynamic systems literature. Our model leverages Gaussian process coregionalization to capture the between-battery structure and employs stochastic variational inference to ensure scalable computation. Looking ahead, we envision extending ipgp to other psychological domains, such as emotion research, and enhancing it by incorporating contextual information about behaviors and activities.

Our proposed ipgp framework also provides insight for domain theory testing, contributing to the substantive debate in psychometrics surrounding the shared versus unique structures of psychological features. Our experimental results show that ipgp is decisively favored over the nomothetic baseline, and substantive deviations from the common trend persist in for many individuals.