# A\({}^{2}\)CiD\({}^{2}\): Accelerating Asynchronous Communication

in Decentralized Deep Learning

 Adel Nabli

Concordia University, Mila

Sorbonne University, ISIR, CNRS

adel.nabli@sorbonne-universite.fr

&Eugene Belilovsky

Concordia University, Mila

Edouard Oyallon

Sorbonne University, ISIR, CNRS

###### Abstract

Distributed training of Deep Learning models has been critical to many recent successes in the field. Current standard methods primarily rely on synchronous centralized algorithms which induce major communication bottlenecks and synchronization locks at scale. Decentralized asynchronous algorithms are emerging as a potential alternative but their practical applicability still lags. In order to mitigate the increase in communication cost that naturally comes with scaling the number of workers, we introduce a principled asynchronous, randomized, gossip-based optimization algorithm which works thanks to a continuous local momentum named \(^{2}^{2}\). Our method allows each worker to continuously process mini-batches without stopping, and run a peer-to-peer averaging routine in parallel, reducing idle time. In addition to inducing a significant communication acceleration at no cost other than adding a local momentum variable, minimal adaptation is required to incorporate \(^{2}^{2}\) to standard asynchronous approaches. Our theoretical analysis proves accelerated rates compared to previous asynchronous decentralized baselines and we empirically show that using our \(^{2}^{2}\) momentum significantly decrease communication costs in poorly connected networks. In particular, we show consistent improvement on the ImageNet dataset using up to 64 asynchronous workers (A100 GPUs) and various communication network topologies.

## 1 Introduction

As Deep Neural Networks (DNNs) and their training datasets become larger and more complex, the computational demands and the need for efficient training schemes continues to escalate. Distributed training methods offer a solution by enabling the parallel optimization of model parameters across multiple workers. Yet, many of the current distributed methods in use are synchronous, and have significantly influenced the design of cluster computing environments. Thus, both the environments and algorithms rely heavily on high synchronicity in machine computations and near-instantaneous communication in high-bandwidth networks, favoring the adoption of centralized algorithms .

However, several studies  are challenging this paradigm, proposing decentralized asynchronous algorithms that leverage minor time-delays fluctuations between workers to enhance the parallelization of computations and communications. Unlike centralized algorithms, decentralized approaches allow each node to contribute proportionally to its available resources, eliminating the necessity for a global central worker to aggregate results. Combined with asynchronous peer-to-peer (p2p) communications, these methods can streamline the overall trainingprocess, mitigating common bottlenecks. This includes the Straggler Problem , the synchronization between computations and communications , or bandwidth limitations , potentially due to particular network topologies like a ring graph . However, due to the large number of parameters which are optimized, training DNNs with these methods still critically requires a considerable amount of communication , presenting an additional challenge .

This work aims to address these challenges by introducing a principled acceleration method for pair-wise communications in peer-to-peer training of DNNs, in particular for cluster computing. While conventional synchronous settings accelerate communications by integrating a Chebychev acceleration followed by Gradient Descent steps , the potential of accelerated asynchronous pair-wise gossi for Deep Learning (DL) remains largely unexplored. Notably, the sophisticated theory of Stochastic Differential Equations (SDEs) offers an analytical framework for the design and study of the convergence of these algorithms . We introduce a novel algorithm \(^{2}^{2}\) (standing for **A**ccelerating **A**synchronous **C**ommunication **in **D**ecentralized **D**eep Learning) that requires minimal overhead and effectively decouples communications and computations, accelerating pair-wise communications via a provable, accelerated, randomized gossip procedure based on continuous momentum (i.e., a mixing ODE) and time [12; 34]. We emphasize that beyond the aforementioned hardware superiority, stochastic algorithms also allows us to theoretically reach sublinear rates in convex settings , which opens the possibility to further principled accelerations. In practice, our method enables a virtual doubling of the communication rate in challenging network topologies without any additional cost, simply by maintaining a local momentum variable in each worker (see Fig. 1).

Our key contributions are as follows: **(1)** We extend the continuized framework  to the non-convex setting, in order to obtain a neat framework to describe asynchronous decentralized DL training. **(2)** This framework allows us to refine the analysis of a baseline asynchronous decentralized optimization algorithm. **(3)** We propose a novel and simple continuized momentum which allows to significantly improve communication efficiency in challenging settings, which we name \(^{2}^{2}\). **(4)** We demonstrate that our method effectively minimizes the gap between centralized settings in environments hosting up to 64 asynchronous GPUs. **(5)** Our code is implemented in Pytorch , remove locks put on previous asynchronous implementations by circumventing their deadlocks, and can be found in an open-source repository: https://github.com/AdelNabli/ACiD.

This paper is structured as follows: Sec. 3.1 outlines our model for asynchronous decentralized learning, while Sec. 3.2 discusses the training dynamic used to optimize our Deep models. Sec. 3.4 offers a comprehensive theoretical analysis of our method, which is validated empirically in Sec. 4.

## 2 Related Work

Large-scale distributed DL.Two paradigms allow to maintain high-parallelization. On one side, model-parallelism [9; 25], which splits a neural network on independent machines, allowing to use local learning methods [4; 3]. On the other hand data-parallelism, which accelerates learning by making use of larger mini-batch splitted across multiple nodes  to maximally use GPU capacities. This parallelization entailing the use of larger batch-sizes, it requires an important process of adapting hyper-parameters , and in particular the learning rate scheduler. Developed for this setting, methods such as [16; 46] allow to stabilize training while maintaining good generalization performances. However, they have been introduced in the context of centralized synchronous training using All-Reduce schemes for communication, which still is the default setting of many approaches to data parallelism.

Decentralized DL.The pioneer work  is one of the first study to suggest the potential superiority of synchronous decentralized training strategies in practice. In terms of implementation in the cluster

Figure 1: Adding \(^{2}^{2}\) has the same effect as doubling the communication rates on ImageNet on the ring graph with 64 workers. See Sec. 4.

setting, decentralized frameworks have been shown to achieve higher throughput than optimized All-Reduce strategies [45; 38]. From the theoretical side,  propose a framework covering many settings of synchronous decentralized learning. However, as it consistently relies on using a global discrete iterations count, the notion of time is more difficult to exploit, which reveals crucial in our setting. Furthermore, no communication acceleration is incorporated in these algorithms.  provides a comprehensive methodology to relate the consensus distance, _i.e._ the average distance of the local parameters to the global average, to a necessary communication rate to avoid degrading performance and could be easily applied to our method.  is a method focusing on improving performance via a discrete momentum modification, which indicates momentum variables are key to decentralized DL.

Asynchronous Decentralized DL.There exist many attempts to incorporate asynchrony in decentralized training [48; 5; 8; 28; 2], which typically aim at removing lock barriers of synchronous decentralized algorithms. To the best of our knowledge, none of them introduce communication acceleration, yet they could be simply combined with our approach. Although recent approaches such as [2; 28] perform peer-to-peer averaging of parameters instead of gradients, thus allowing to communicate _in parallel_ of computing (as there is no need to wait for the gradients before communicating), they are still coupled: parameter updates resulting from computations and communications are scheduled in a specific order, limiting their speed. Furthermore, in practice, both those works only implement a periodic averaging on the exponential graph (more favorable, see ) instead of investigating the influence of the graph's topology on the convergence of a randomized gossip method, as we do. In fact, AD-PSGD , the baseline algorithm in asynchronous decentralized DL, comes with a major caveat to avoid deadlocks in practice: they _require_ a bipartite graph and schedule p2p communications in a pseudo-random manner instead of basing the decision on worker's current availability, hindering the advantage given by asynchronous methods in the mitigation of stragglers. Contrary to them, our implementation allows to pair workers in real time based on their availability, minimizing idle time for communications.

Communication reduction.Reducing communication overhead is an important topic for scalability . For instance, [19; 20] allow to use of compression factor in limited bandwidth setting, and the local SGD communication schedule of  is shown to be beneficial. Those methods could be independently and simply combined with ours to potentially benefit from an additional communication acceleration. By leveraging key properties of the resistance of the communication network ,  showed that standard asynchronous gossip  can be accelerated, even to give efficient primal algorithms in the convex setting . However, this acceleration has never been deployed in the DL context, until now. RelaySum  is an approach which allow to average exactly parameters produced by different time steps and thus potentially delayed. However, it requires either to use a tree graph topology, either to build ad-hoc spanning trees and has inherent synchronous locks as it averages neighbor messages in a specific order.

Notations:Let \(n^{*}\) and \(d^{*}\) an ambient dimension, for \(x=(x^{1},...,x^{n})_{i=1}^{n}^{d}\), we write \(=_{i=1}^{n}x^{i}\) and \(\) the tensor of ones such that \(=^{}x\). \(\) is a probability space with measure \(\). \(f(t)=(1)\) means there is a \(C>0\) such that for \(t\) large enough, \(|f(t)| C\), whereas \(}\)-notation hides constants and polylogarithmic factors..

## 3 Method

### Model for a decentralized environment

We consider a network of \(n\) workers whose connectivity is given by edges \(\). Local computations are modeled as (stochastic) point-wise processes \(N_{t}^{i}\), and communications between nodes \((i,j)\) as \(M_{t}^{ij}\). We assume that the communications are symmetric, meaning that if a message is sent from node \(i\) to \(j\), then the reverse is true. In practice, such processes are potentially highly correlated and could follow any specific law, and could involve delays. For the sake of simplicity, we do not model lags, though it is possible to obtain guarantees via dedicated Lyapunov functions . In our setting, we assume that all nodes have similar buffer variables which correspond to a copy of a common model (e.g., a DNN). For a parameter \(x\), we write \(x_{t}^{i}\) the model's parameters at node \(i\) and time \(t\) and \(x_{t}=(x_{t}^{1},...,x_{t}^{n})\) their concatenation. In the following, we assume that each worker computesabout \(1\) mini-batch of gradient per unit of time (not necessarily simultaneously), which is a standard homogeneity assumption , and we denote by \(^{ij}\) the instantaneous expected frequency of edge \((i,j)\), which we assume time homogeneous.

**Definition 3.1** (Instantaneous expected Laplacian).: We define the Laplacian \(\) as:

\[_{(i,j)}^{ij}(e_{i}-e_{j})(e_{i}-e_ {j})^{}\,.\] (1)

In this context, a natural quantity is the algebraic connectivity  given by:

\[_{1}_{\|x\|=1,x 1}} x}\,.\] (2)

For a connected graph (_i.e._, \(_{1}<+\)), we will also use the maximal resistance of the network:

\[_{2}_{(i,j)}(e_{i}-e_{j})^{}^{+}(e_{i}-e_{j})_{1}\,.\] (3)

The next sections will show that it is possible to accelerate the asynchronous gossip algorithms from \(_{1}\) to \(_{2}}_{1}\), while  or  emphasize the superiority of accelerated asynchronous gossips over accelerated synchronous ones.

### Training dynamic

The goal of a typical decentralized algorithm is to minimize the following quantity:

\[_{x^{d}}f(x)_{x^{d}} _{i=1}^{n}f_{i}(x)=_{x_{i}=x_{1}}_{i=1}^{n}f_{i}(x_{i} )\,.\]

For this, we follow a first order optimization strategy consisting in using estimates of the gradient \( f_{i}(x_{i})\) via i.i.d unbiased Stochastic Gradient (SG) oracles given by \( F_{i}(x_{i},_{i})\) s.t. \(_{_{i}}[ F_{i}(x_{i},_{i})]= f_{i}(x_{i})\). The dynamic of updates of our model evolves as the following SDE, for \(,,,\) some time-independent scalar hyper-parameters, whose values are found in our theoretical analysis and used in our implementation, and \(dN_{t}^{i}(_{i})\) some point processes on \(_{+}\) with intensity \(dt d\):

\[dx_{t}^{i}= (_{t}^{i}-x_{t}^{i})dt-_{} F_{i} (x_{t}^{i},_{i})\,dN_{t}^{i}(_{i})-_{j,(i,j)}(x _{t}^{i}-x_{t}^{j})dM_{t}^{ij}\,,\] (4) \[d_{t}^{i}= (x_{t}^{i}-_{t}^{i})dt-_{} F_{i} (x_{t}^{i},_{i})\,dN_{t}^{i}(_{i})-_{j,(i,j) }(x_{t}^{i}-x_{t}^{j})dM_{t}^{ij}\,.\]

    & **Strongly Convex** & **Non-Convex** \\  Koloskova et al.  & \(}{n^{2}}+^{+} }}{^{3/2}}+_{1}\) & \(}{n^{2}}+L^{+}} }{^{3/2}}+}{}\) \\  AD-PSGD  & - & \(L+^{2}}{^{2}}+L_{1}}{}\) \\  Baseline (**Ours**) & \(+_{1}^{2}}{^{2}}+_{1}\) & \(L+_{1}^{2}}{^{2}}+}{}\) \\  \(^{2}^{2}\) (**Ours**) & \(+_{2}^{2}}}{^{2}}+_{2}}\) & \(L+_{2}^{2}}}{^{2}}+_{2}}}{}\) \\   

Table 1: Comparison of convergence rates for strongly convex and non-convex objectives against concurrent works in the fixed topology setting. We neglect logarithmic terms. Observe that thanks to the maximal resistance \(_{2}_{1}\), our method obtains substantial acceleration for the bias term. Moreover, while our baseline is strongly related to AD-PSGD , our analysis refines its complexity when workers sample data from the same distribution.

We emphasize that while the dynamic Eq. 4 is formulated using SDEs , which brings the power of the continuous-time analysis toolbox, it is still _event-based_ and thus discrete in nature. Hence, it can efficiently model practically implementable algorithms, as shown by Algo. 1. The coupling \(\{x_{t},_{t}\}\) corresponds to a momentum term which will be useful to obtain communication acceleration as explained in the next section. Again, \(_{} F_{i}(x_{t}^{i},_{i})\,dN_{t}^{i}(_{i})\) will be estimated via i.i.d SGs sampled as \(N_{t}^{i}\) spikes. Furthermore, if \(_{0}=_{0}}\), then, \(_{t}=_{t}}\) and we obtain a tracker of the average across workers which is similar to what is achieved through Gradient Tracking methods . This is a key advantage of our method to obtain convergence guarantees, which writes as:

\[d_{t}=-_{i=1}^{n}_{} F_{i}(x_{t}^{i}, _{i})\,dN_{t}^{i}(_{i})\,.\] (5)

### Informal explanation of the dynamic through the Baseline case

To give some practical intuition on our method, we consider a baseline asynchronous decentralized dynamic, close to AD-PSGD . By considering \(=0,==\), the dynamic (4) simplifies to:

\[dx_{t}^{i}= -_{} F_{i}(x_{t}^{i},_{i})\,dN_{t}^{i}( _{i})-_{j,(i,j)}(x_{t}^{i}-x_{t}^{j})dM_{t}^{ij}\,.\] (6)

In a DL setting, \(x^{i}\) contains the parameters of the DNN hosted on worker \(i\). Thus, (6) simply says that the parameters of the DNN are updated either by taking local SGD steps, or by pairwise averaging with peers \(j,(i,j)\). These updates happen independently, at random times: although we assume that all workers compute gradients at the same speed _on average_ (and re-normalized time accordingly), the use of Poisson Processes model the inherent variability in the time between these updates. However, the p2p averaging depends on the capabilities of the network, and we allow each link \((i,j)\) to have a different bandwidth, albeit constant through time, modeled through the frequency \(^{ij}\). The gradient and communication processes are decoupled: there is no need for one to wait for the other, allowing to compute stochastic gradients uninterruptedly and run the p2p averaging in parallel, as illustrated by Fig.2. Finally, (4) adds a momentum step mixing the local parameters \(x^{i}\) and momentum buffer \(^{i}\) before each type of update, allowing for significant savings in communication costs, as we show next.

### Theoretical analysis of \(^{2}}\)

We now provide an analysis of our decentralized, asynchronous algorithm. For the sake of simplicity, we will consider that communications and gradients spike as Poisson processes:

**Assumption 3.2** (Poisson Processes).: \(N_{t}^{i}\)_, \(M_{t}^{ij}\) are independent, Point-wise Poisson Processes. The \(\{N_{t}^{i}\}_{i=1}^{n}\) have a rate of \(1\), and for \((i,j)\), \(M_{t}^{ij}\) have a rate \(^{ij}\)._

We also assume that the communication network is connected during the training:

Figure 2: Example of worker updates in synchronous (**left**) and asynchronous (**right**) optimization methods. We remark that our asynchronous algorithm reduces idle time, and allow to communicate _in parallel_ of computing gradient, only synchronizing two workers at a time for averaging parameters. Here, one p2p communication is performed per computation _in expectation_.

**Assumption 3.3** (Strong connectivity).: We assume that \(_{1}<\).

We will now consider two generic assumptions obtained from , which allow us to specify our lemma to convex and non-convex settings. Note that the non-convex Assumption 3.5 generalizes the assumptions of , by taking \(M=P=0\).

**Assumption 3.4** (Strongly convex setting).: Each \(f_{i}\) is \(\)-strongly convex and \(L\)-smooth, and:

\[_{i=1}^{n}_{_{i}}[\| F_{i}(x,_{i})- f _{i}(x)\|^{2}]^{2}_{i=1}^{n}\| f_{i}(x^{*})- f (x^{*})\|^{2}^{2}\,.\]

**Assumption 3.5** (Non-convex setting).: Each \(f_{i}\) is \(L\)-smooth, and there exists \(P,M>0\) such that:

\[ x^{d},_{i=1}^{n}\| f_{i}(x)- f (x)\|^{2}^{2}+P\| f(x)\|^{2}\,,\]

and,

\[ x_{1},...,x_{n}^{d},_{i=1}^{n}_ {_{i}}\| F_{i}(x_{i},_{i})- f_{i}(x_{i})\|^{2}^{2} +_{i=1}^{n}\| f_{i}(x_{i})\|^{2}\,.\]

We can now state our convergence guarantees. An informal way to understand our proposition, is that while gradient updates are non-convex, the communication updates are linear and thus benefit from local convexity; its proof is delayed to Appendix C.

**Proposition 3.6** (Convergence guarantees.).: _Assume that \(\{x_{t},_{t}\}\) follow the dynamic Eq. 4 and that Assumption 3.2-3.3 are satisfied. Assume that \(_{0}=x_{0}=_{0}\) and let \(T\) the total running time. Then:_

* _Non-accelerated setting, we pick_ \(=0,==\) _and set_ \(=_{1}\)_,_
* _Acceleration (_\(^{2}\)_CiD_\({}^{2}\)_), we set_ \(=_{2}}},=,= }{_{2}}}\)_, and_ \(=_{2}}_{1}\)_._

_Then, there exists a constant step size \(>0\) such that if:_

* _(strong-convexity) the Assumption_ 3.4 _is satisfied, then_ \(\) _and:_ \[[\|_{T}-x^{*}\|^{2}]=}(\| _{0}-x^{*}\|^{2}e^{-}++^{2} (1+)}{^{2}T})\,,\]
* _(non-convexity) the Assumption_ 3.5 _is satisfied, then there is_ \(c>0\) _which depends only on_ \(P,M\) _from the assumptions such that_ \(\) _and:_ \[_{0}^{T}[\| f(_{t})\|^{2}] \,dt=((f(x_{0})-f(x^{*}))+)-f(x^{*}))}{T}(^{2}+(1+)^{2})})\,.\]

_Also, the expected number of gradient steps is \(nT\) and the number of communications is \(()}{2}T\)._

Tab. 1 compares our convergence rates with concurrent works. Compared to every concurrent work, the bias term of \(^{2}\)**CiD**\({}^{2}\) is smaller by a factor \(}{_{2}}} 1\) at least. Yet, as expected, in the non-accelerated setting, we would recover similar rates to those. Compared to , the variance terms held no variance reduction with the number of workers; however, this should not be an issue in a DL setting, where it is well-known that variance reduction techniques degrade generalization during training . Comparing directly the results of  is difficult as they only consider the asymptotic rate, even if the proof framework is similar to  and should thus lead to similar rates of convergence.

### Informal interpretation and comparison with decentralized synchronous methods

Here, we informally discuss results from Prop. 3.6 and compare our communication rate with state-of-the-art decentralized synchronous methods such as DeTAG , MSDA  and OPAPC .

As we normalize time so that each node takes one gradient step per time unit in expectation, one time unit for us is analogous to one round of computation (one "step") for synchronous methods. Synchronous methods such as [31; 37; 23] perform multiple rounds of communications (their _Accelerated Gossip_ procedure) between rounds of gradient computations by using an inner loop inside their main loop (the one counting "steps"), so that the graph connectivity do not impact the total number of "steps" necessary to reach \(\)-precision. As Prop. 3.6 shows, the quantity \(1+[]_{2}[]}\) is a factor in our convergence rate. \(\) containing the information of both the topology \(\) and the edge communication rates \(_{ij}\), this is analogous to saying \([]_{2}[]}=(1)\) for our method (_i.e._, the graph connectivity does not impact the time to converge), which, given the graph's topology, dictates the communication rate, see Appendix D for more details. Tab. 2 compares the subsequent communication rates with synchronous methods.

## 4 Numerical Experiments

Now, we experimentally compare \(^{2}^{2}\) to a synchronous baseline All-Reduce SGD (AR-SGD, see ) and an _asynchronous baseline_ using randomized pairwise communications (a variant of AD-PSGD , traditionally used in state-of-the-art decentralized asynchronous training of DNNs). In our case, the _asynchronous baseline_ corresponds to the dynamic Eq. (6). Our approach is standard: we empirically study the decentralized training behavior of our asynchronous algorithm by training ResNets  for image recognition. Following , we pick a ResNet18 for CIFAR-10  and ResNet50 for ImageNet . To investigate how our method scales with the number of workers, we run multiple experiments using up to 64 NVIDIA A100 GPUs in a cluster with 8 A100 GPUs per node using an Omni-PAth interconnection network at 100 Gb/s, and set one worker per GPU.

### Experimental Setup

Hyper-parameters.Training a DNN using multiple workers on a cluster requires several adaptations compared to the standard setting. As the effective batch-size grows linearly with the number of workers \(n\), we use the learning-rate schedule for large batch training of  in all our experiments. Following , we fixed the local batch size to 128 on both CIFAR-10 and ImageNet.

Our goal being to divide the compute load between the \(n\) workers, all methods access the same total amount of data samples, regardless of the number of local steps. On CIFAR-10 and ImageNet, this

   & Method & Star & Ring & Complete \\  Accelerated Synchronous & \(n^{3/2}\) & \(n^{2}\) & \(n^{2}\) \\ (_e.g._, [31; 37; 23]) & & & \\  \(^{2}^{2}\) & \(n\) & \(n^{2}\) & \(n\) \\  

Table 2: # of communications per “step”/time unit on several graphs.

   & \(n\) & 4 & 8 & 16 & 32 & 64 \\  Ours & \(t\) (min) & **20.9** & **10.5** & **5.2** & **2.7** & **1.5** \\ AR & \(t\) (min) & 21.9 & 11.1 & 6.6 & 3.2 & 1.8 \\  

Table 3: Training times on CIFAR10 (\(\) 6s).

Figure 3: (a) Training loss for CIFAR10 with minibatch size 128 on the complete graph, w/o \(^{2}^{2}\). As the number of worker increases, the loss degrades, especially for \(n=64\). (b) Focus on the training loss for the complete graph of size \(n=64\), w/o \(^{2}^{2}\). As the rate of communication increases, the gap with All-Reduce decreases. With 2 com/\(\), a test accuracy of \(94.6 0.04\) is reached.

number is set to 300 and 90 epochs respectively, following standard practice . To circumvent the fuzziness of the notion of epoch in the asynchronous decentralized setting, we do not "split the dataset and re-shuffle it among workers at each epoch" as done with our standard All-Reduce baseline. Rather, we give access to the whole dataset to all workers, each one shuffling it with a different random seed. We use SGD with a base learning rate of \(0.1\), a momentum value set at \(0.9\) and \(5 10^{-4}\) for weight decay. As advocated in , we do not apply weight decay on the learnable batch-norm coefficients. For ImageNet training with the SGD baseline, we decay the learning-rate by a factor of 10 at epochs 30, 60, 80 (epochs 50, 75 for CIFAR-10), and apply an analogous decay schedule with our asynchronous decentralized methods. All of our neural network parameters are initialized with the default Pytorch settings, and one All-Reduce averaging is performed before and after the training to ensure consensus at initialization and before testing. For our continuous momentum, we also need to set the parameters \(,\). For all our experiments, we use the values given by Prop. 3.6. As advocated, the _asynchronous baseline_ correspond to the setting without acceleration, i.e. with \(=0\) and \(==\), whereas using \(^{2}^{2}\) leads to consider \(=_{2}}},=,= }{_{2}}}\), where \(_{1},_{2}\) are set to their theoretical value given by (2), (3) depending on the communication rate and graph's topology, assuming that each worker chose their peers uniformly among their neighbors (we verify empirically that it is the case in practice, see Appendix E.2).

Practical implementation of the dynamic.The dynamic studied in Eq. (4) is a model displaying many of the properties sought after in practice. In our implementation, described in Algo. 1, each worker \(i\) has indeed two independent processes and the DNN parameters and momentum variable \(\{x^{i},^{i}\}\) are locally stored such that both processes can update them at any time. One process continuously performs gradient steps, while the other updates \(\{x^{i},^{i}\}\) via peer-to-peer averaging. The gradient process maximizes its throughput by computing forward and backward passes back to back. Contrary to All-Reduce based methods that require an increasing number of communications with the growing number of workers, inevitably leading to an increasing time between two rounds of computations,we study the case where each worker has a fixed communication rate, given as hyperparameter in our implementation. We implement 3 different graph topologies: complete, ring, and exponential [28; 2], see Appendix E.1 for details. To emulate the P.P.Ps for the communications, each worker samples a random number of p2p averaging to perform between each gradient computation, following a Poisson law using the communication rate as mean. To minimize idle time of the communication process, workers are paired with one of their neighbors in a "First In First Out" manner in an availability queue (a worker is available when it finished its previous averaging and still has some to do before the next gradient step). To implement this, we use a central coordinator to store the availability queues and the graph topology (this is lightweight in a cluster: the coordinator only exchanges integers with the workers), but it could be done in different ways, _e.g._ by pinging each other at high frequency. As we assumed a unit time for the gradient process in our analysis, and that real time is used in our algorithm to apply our \(^{2}^{2}\)momentum (see Algo. 1), we maintain a running average measure of the duration of the previous gradient steps to normalize time.

### Evaluation on large scale datasets

Cifar10.This simple benchmark allows to understand the benefits of our method in a well-controlled environment. Tab. 4 reports our numerical accuracy on the test set of CIFAR10, with a standard deviation calculated over 3 runs. Three scenarios are considered: a complete, an exponential and a ring graph. In Fig. 3 (a), we observe that with the asynchronous baseline on the complete graph, the more workers, the more the training loss degrades. Fig. 3 (b) hints that it is in part due to an insufficient communication rate, as increasing it allows to lower the loss and close the gap with the All-Reduce baseline. However, this is not the only causative factor as Tab. 4 indicates that accuracy generally degrades as the number of workers increases even for AR-SGD, which is expected for large batch sizes. Surprisingly, even with a worse training loss for \(n=64\), the asynchronous baseline still leads to better generalization than

   \#Workers & 4 & 8 & 16 & 32 & 64 \\  AR-SGD baseline & 94.5\(\)0.1 & 94.4\(\)0.1 & 94.5\(\)0.2 & 93.7\(\)0.3 & 92.8\(\)0.2 \\ 
**Complete graph** & & & & \\ Async. baseline & 94.93\(\)0.11 & 94.91\(\)0.07 & 94.86\(\)0.01 & 94.55\(\)0.01 & 93.38\(\)0.21 \\ 
**Exponential graph** & & & & \\ Async. baseline & 95.07\(\)0.01 & 94.89\(\)0.01 & 94.82\(\)0.06 & 94.44\(\)0.02 & 93.41\(\)0.02 \\
**A\({}^{2}^{2}\)** & **95.17\(\)**0.04 & **95.04\(\)**0.01 & **94.87\(\)**0.02 & **94.56\(\)**0.01 & **93.47\(\)**0.01 \\ 
**Ring graph** & & & & \\ Async. baseline & **95.02\(\)**0.06 & **95.01\(\)**0.01 & 95.00\(\)0.01 & 93.95\(\)0.11 & 91.90\(\)0.10 \\
**A\({}^{2}^{2}\)** & 94.95\(\)0.02 & **95.01\(\)**0.10 & **95.03\(\)**0.01 & **94.61\(\)**0.02 & **93.08\(\)**0.20 \\   

Table 4: Accuracy of our method on CIFAR10 for a 128 batchsize with an equal number of pairwise communications and gradient computations per worker. We compared a vanilla asynchronous pairwise gossip approach with and without \(^{2}^{2}\), demonstrating the improvement of our method.

Figure 4: Training loss for CIFAR10 using a minibatch size of 128. We display the training loss with up to 64 workers, w/ and w/o \(^{2}^{2}\), on the challenging ring graph.

   \#Workers & \#com/\#grad & 16 & 32 & 64 \\  AR-SGD baseline & - & 75.5 & 75.2 & 74.5 \\ 
**Complete graph** & & & \\ Async. baseline & 1 & 74.6 & 73.8 & 71.3 \\ 
**Ring graph** & & & \\ Async. baseline & 1 & **74.8** & 71.6 & 64.1 \\ \(^{2}^{2}\) & 1 & 74.7 & **73.4** & **68.0** \\ Async. baseline & 2 & 74.8 & 73.7 & 68.2 \\ \(^{2}^{2}\) & 2 & **75.3** & **74.4** & **71.4** \\   

Table 5: Accuracy on ImageNet for a batchsize of 128. We compared a vanilla asynchronous pairwise gossip approach with and without \(^{2}^{2}\), demonstrating the improvement of our method. We also varied the communication rate.

AR-SGD, and consistently improves the test accuracy across all tested values of \(n\). The communication rate being identified as a critical factor at large scale, we tested our continuous momentum on the ring graph, each worker performing one p2p averaging for each gradient step. Fig. 4 shows that incorporating \(^{2}^{2}\) leads to a significantly better training dynamic for a large number of workers, which translates into better performances at test time as shown in Tab. 4.

ImageNet.For validating our method in a real-life environment, we consider the large-scale ImageNet dataset. Tab. 6 confirms the advantage of asynchronous methods by allocating less compute to the slowest workers, leading to faster training times. Tab. 5 reports our accuracy for the complete and ring graphs. As \(_{1}=_{2}\) for the complete graph, we simply run our baseline asynchronous method for reference. The case of the ring graph is much more challenging: for \(n=64\) workers, the accuracy drops by 10% compared to the synchronous baseline given by AR-SGD. Systematically, with \(^{2}^{2}\), the final accuracy increases: up to 4% absolute percent in the difficult \(n=64\) setting. This is corroborated by Fig. 5, which indicates that incorporating \(^{2}^{2}\) significantly improves the training dynamic on ImageNet. However, for reducing the gap with the AR-SGD baseline, it will be necessary to increase the communication rate as discussed next.

Consensus improvement.The bottom of Tab. 5, as well as Fig. 5 (b) study the virtual acceleration thanks to \(^{2}^{2}\). Not only increasing communications combined with \(^{2}^{2}\) allows to obtain competitive performance, but Fig. 1 shows that doubling the rate of communication has an identical effect on the training loss than adding \(^{2}^{2}\). This is verified in Fig. 5 (b) by tracking the consensus distance between workers: \(^{2}^{2}\) significantly reduces it, which validates the results of Sec. 3.4.

## 5 Conclusion

In this work, we confirmed that the communication rate is a key performance factor to successfully train DNNs at large scale with decentralized asynchronous methods. We introduced \(^{2}^{2}\), a continuous momentum which only adds a minor local memory overhead while allowing to mitigate this need. We demonstrated, both theoretically and empirically, that \(^{2}^{2}\) substantially improves performances, especially on challenging network topologies. As we only focused on data parallel methods for training Deep Neural Networks in a cluster environment, in a future work, we would like to extend our empirical study to more heterogeneous compute and data sources, as our theory could encompass local SGD methods  and data heterogeneity inherent in Federated Learning .

  Method & \(t\) (min) & \# \(\) & \# \(\) \\  & & slowest worker & fastest worker \\  AR-SGD & \(1.7\,10^{2}\) & 14k & 14k \\ Baseline (ours) & \(\,^{2}\) & 13k & 14k \\ \(^{2}^{2}\)(ours) & \(\,^{2}\) & 13k & 14k \\  

Table 6: Statistics of runs on Imagenet with 64 workers (for ours, on the exponential graph).

Figure 5: (a) Training loss for ImageNet using 128 batch size, with an equal number of communications and computations per worker. We display the training loss for various number of workers (up to 64), using \(^{2}^{2}\), for the ring graph. (b) Comparison of consensus distances when \(^{2}^{2}\) is applied versus doubling the rate of communications on the ring graph with 64 workers: applying \(^{2}^{2}\) has the same effect as doubling communications.