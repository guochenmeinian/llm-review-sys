# Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates with No Information Loss

Yi-Shan Wu

University of South Denmark

yswu@imada.sdu.dk

&Yijie Zhang

University of Copenhagen & Novo Nordisk A/S

yizh@di.ku.dk

&Badr-Eddine Cherief-Abdellatif

CNRS, LPSM, Sorbonne Universite, Universite Paris Cite

badr-eddine.cherief-abdellatif@cnrs.fr

&Yevgeny Seldin

University of Copenhagen

seldin@di.ku.dk

###### Abstract

PAC-Bayesian analysis is a frequentist framework for incorporating prior knowledge into learning. It was inspired by Bayesian learning, which allows sequential data processing and naturally turns posteriors from one processing step into priors for the next. However, despite two and a half decades of research, the ability to update priors sequentially without losing confidence information along the way remained elusive for PAC-Bayes. While PAC-Bayes allows construction of data-informed priors, the final confidence intervals depend only on the number of points that were not used for the construction of the prior, whereas confidence information in the prior, which is related to the number of points used to construct the prior, is lost. This limits the possibility and benefit of sequential prior updates, because the final bounds depend only on the size of the final batch.

We present a novel and, in retrospect, surprisingly simple and powerful PAC-Bayesian procedure that allows sequential prior updates with no information loss. The procedure is based on a novel decomposition of the expected loss of randomized classifiers. The decomposition rewrites the loss of the posterior as an excess loss relative to a downscaled loss of the prior plus the downscaled loss of the prior, which is bounded recursively. As a side result, we also present a generalization of the split-kl and PAC-Bayes-split-kl inequalities to discrete random variables, which we use for bounding the excess losses, and which can be of independent interest. In empirical evaluation the new procedure significantly outperforms state-of-the-art.

## 1 Introduction

PAC-Bayesian analysis was born from an attempt to derive frequentist generalization guarantees for Bayesian-style prediction rules (Shawe-Taylor and Williamson, 1997; McAllester, 1998). The motivation was to provide a way to incorporate prior knowledge into the frequentist analysis of generalization. PAC-Bayesian bounds provide high-probability generalization guarantees for randomized classifiers. A randomized classifier is defined by a distribution \(\) on a set of prediction rules \(\), which is used to sample a prediction rule each time a prediction is to be made. Bayesian posterior is an example of a randomized classifier, whereas PAC-Bayesian bounds hold generally for all randomized classifiers. Prior knowledge is encoded through a prior distribution \(\) on \(\), and the complexity of a posterior distribution \(\) is measured by the Kullback-Leibler (KL) divergence from the prior, \((\|)\). PAC-Bayesian generalization guarantees are optimized by posterior distributions \(\) that optimize a trade-off between empirical data fit and divergence from the prior in the KL sense.

Selection of a "good" prior plays an important role in the PAC-Bayesian bounds. If one manages to foresee which prediction rules are likely to produce low prediction error and allocate a higher prior mass for them, then the bounds are tighter, because the posterior only needs to make a small deviation from the prior. But if the prior mass on well-performing prediction rules is small, the bounds are loose. A major technique to design good priors is to use part of the data to estimate a good prior and the rest of the data to compute a PAC-Bayes bound. It is known as data-dependent or data-informed priors (Ambroladze et al., 2007). However, all existing approaches to data-informed priors have three major disadvantages. The first is that the bounds are computed on "the rest of the data" that were not used in construction of the prior. Thus, the sample size in the bounds is only a fraction of the total sample size. Therefore, empirically data-informed priors are not always helpful. In many cases starting with an uninformed prior and using all the data to compute the posterior and the bound turns to be superior to sacrificing part of the data for prior construction (Ambroladze et al., 2007; Mhammedi et al., 2019). The second disadvantage is that all the confidence information about the prior is lost in the process. In particular, a prior trained on a few data points is treated in the same way as a prior trained on a lot of data. And a third related disadvantage is that sequential data processing provides no benefit, because the bounds only depend on the size of the last chunk and all the confidence information from processing earlier chunks is lost in the process.

Our main contribution is a new (and simple) way of decomposing the loss of a randomized classifier defined by the posterior. We write it as an excess loss relative to a downscaled loss of the randomized classifier defined by the prior plus the downscaled loss of the randomized classifier defined by the prior. The excess loss can be bounded using PAC-Bayes-Empirical-Bernstein-style inequalities (Tolstikhin and Seldin, 2013; Mhammedi et al., 2019; Wu et al., 2021; Wu and Seldin, 2022), whereas the loss of the randomized classifier defined by the prior can be bounded recursively. The recursive bound can both use the data used for construction of the prior and "the rest of the data", and thereby preserves confidence information on the prior. Our contribution stands out relative to all prior work on PAC-Bayes, and in fact all prior work on frequentist generalization bounds, because it makes sequential data processing and sequential prior updates meaningful and beneficial.

We note that while several recent papers experimented with sequential posterior updates by using martingale-style analysis, in all these works the prior remained fixed and only the posterior was changing (Chugg et al., 2023; Biggs and Guedj, 2023; Rodriguez-Galvez et al., 2024). The work on sequential posterior updates is orthogonal to our contribution and can be combined with it. Namely, it is possible to apply sequential posterior updates in-between sequential prior updates. Another line of work used tools from online learning to derive PAC-Bayesian bounds (Jang et al., 2023), and in this context Haddouche and Guedj (2023) have used sequential prior updates, but their bounds hold for a uniform aggregation of sequentially constructed posteriors, which is different from standard posteriors studied in our work. The confidence bounds in their work come primarily from aggregation rather than confidence in individual posteriors in the sequence (the denominator of their bounds depends on the number of aggregated posteriors). The need to construct and maintain a large number of posteriors has a negative impact on the computational efficiency. Our work is the first one allowing sequential prior updates without loss of confidence information.

An additional side contribution of independent interest is a generalization of the split-kl and PAC-Bayes-split-kl inequalities of Wu and Seldin (2022) from ternary to general discrete random variables. It is based on a novel representation of discrete random variables as a superposition of Bernoulli random variables.

The paper is organized in the following way. In Section 2 we briefly survey the evolution of data-informed priors in PAC-Bayes and present our main idea behind Recursive PAC-Bayes; in Section 3 we present our generalization of the split-kl and PAC-Bayes-split-kl inequalities, which are later used to bound the excess losses; in Section 4 we present the Recursive PAC-Bayes bound; in Section 5 we present an empirical evaluation; and in Section 6 we conclude with a discussion.

## 2 The evolution of data-informed priors and the idea of Recursive PAC-Bayes

In this section we briefly survey the evolution of data-informed priors, and then present our construction of Recursive PAC-Bayes. We consider the standard classification setting, with \(\) being a sample space, \(\) a label space, \(\) a set of prediction rules \(h:\), and \((h(X),Y)=(h(X) Y)\) the zero-one loss function, where \(()\) denotes the indicator function. We let \(\)denote a distribution on \(\) and \(S=\{(X_{1},Y_{1}),,(X_{n},Y_{n})\}\) an i.i.d. sample from \(\). Let \(L(h)=_{(X,Y)}[(h(X),Y)]\) be the expected and \((h,S)=_{i=1}^{n}(h(X_{i}),Y_{i})\) the empirical loss.

Let \(\) be a distribution on \(\). A _randomized classifier_ associated with \(\) samples a prediction rule \(h\) according to \(\) for each sample \(X\), and applies it to make a prediction \(h(X)\). The expected loss of such randomized classifier, which we call \(\), is \(_{h}[L(h)]\) and the empirical loss is \(_{h}[(h,S)]\). For brevity we use \(_{}[]\) to denote \(_{h}[]\).

We use \((\|)\) to denote the Kullback-Leibler divergence between two probability distributions, \(\) and \(\)(Cover and Thomas, 2006). For \(p,q\) we further use \((p\|q)=((1-p,p)\|(1-q,q))\) to denote the Kullback-Leibler divergence between two Bernoulli distributions with biases \(p\) and \(q\).

The goal of PAC-Bayes is to bound \(_{}[L(h)]\). Below we present how the bounds on \(_{}[L(h)]\) have evolved. In Appendix A we also provide a graphical illustration of the evolution.

Uninformed priorsEarly work on PAC-Bayes used _uninformed priors_(McAllester, 1998). An uniformed prior \(\) is a distribution on \(\) that is independent of the data \(S\). A classical, and still one of the tightest bounds, is the following.

**Theorem 1** (PAC-Bayes-\(\) Inequality, Seeger, 2002, Maurer, 2004).: _For any probability distribution \(\) on \(\) that is independent of \(S\) and any \((0,1)\):_

\[:(_{ }[(h,S)]_{}[L(h)])(\|)+(2/)}{n},\]

_where \(\) is the set of all probability distributions on \(\), including those dependent on \(S\)._

A posterior \(\) that minimizes \(_{}[L(h)]\) has to balance between allocating higher mass to prediction rules \(h\) with small \((h,S)\) and staying close to \(\) in the \((\|)\) sense. Since \(\) has to be independent of \(S\), typical uninformed priors aim "to leave maximal options open" for \(\) by staying close to uniform.

Data-informed priorsAmbroladze et al. (2007) proposed to split the data \(S\) into two disjoint sets, \(S=S_{1} S_{2}\), and use \(S_{1}\) to construct a _data-informed prior_\(\) and compute a bound on \(_{}[L(h)]\) using \(\) and \(S_{2}\). Since in this approach \(\) is independent of \(S_{2}\), Theorem 1 can be applied. The advantage is that \(\) can use \(S_{1}\) to give higher mass to promising classifiers, thus relaxing the regularization pressure \((\|)\) and making it easier for \(\) to allocate even higher mass to well-performing classifiers (those with small \((h,S_{2})\)). The disadvantage is that the sample size in the bound (the \(n\) in the denominator) decreases from the size of \(S\) to the size of \(S_{2}\). Indeed, Ambroladze et al. observed that the sacrifice of \(S_{1}\) for prior construction does not always pay off.

Data-informed priors + excess lossMhammedi et al. (2019) observed that if we have already sacrificed \(S_{1}\) for the construction of \(\), we could also use it to construct a reference prediction rule \(h^{*}\), typically an Empirical Risk Minimizer (ERM) on \(S_{1}\). They then employed the decomposition

\[_{}[L(h)]=_{}[L(h)-L(h^{*})]+L(h^{*})\]

and used \(S_{2}\) to give a PAC-Bayesian bound on \(_{}[L(h)-L(h^{*})]\) and a single-hypothesis bound on \(L(h^{*})\). The quantity \(_{}[L(h)-L(h^{*})]\) is known as _excess loss_. The advantage of this approach is that when \(L(h^{*})\) is a good approximation of \(_{}[L(h)]\), the excess loss has lower variance than the plain loss \(_{}[L(h)]\) and, therefore, is more efficient to bound, whereas the single-hypothesis bound on \(L(h^{*})\) does not involve the \((\|)\) term. Therefore, it is generally beneficial to use excess losses in combination with data-informed priors. However, as with the previous approach, sacrificing \(S_{1}\) to learn \(\) and \(h^{*}\) means that the denominator in the bounds (\(n\) in Theorem 1) reduces to the size of \(S_{2}\), and it does not always pay off. (We note that the excess loss is not binary and not in the \(\) interval, and in order to exploit small variance it is actually necessary to apply a PAC-Bayes-Empirical-Bernstein-style inequality (Tolstikhin and Seldin, 2013, Mhammedi et al., 2019, Wu et al., 2021) or the PAC-Bayes-split-kl inequality (Wu and Seldin, 2022) rather than Theorem 1, but the point about reduced sample size still applies.)

Recursive PAC-Bayes (new)We introduce the following decomposition of the loss

\[_{}[L(h)]=_{}[L(h)-_{}[L(h^{ })]]+_{}[L(h^{})].\] (1)As before, we decompose \(S\) into two disjoint sets \(S=S_{1} S_{2}\). We make the following major observations:

* The quantity \(_{}[L(h^{})]\) on the right is "of the same kind" as \(_{}[L(h)]\) on the left.
* We can take an uninformed prior \(_{0}\) and apply Theorem 1 (or any other suitable PAC-Bayes bound) to bound \(_{}[L(h^{})]\). (The \(\) term in the bound on \(_{}[L(h^{})]\) will be \((\|_{0})\).)
* We can restrict \(\) to depend only on \(S_{1}\), but still use all the data \(S\) in calculation of the PAC-Bayes bound on \(_{}[L(h^{})]\), because \(\) is a posterior relative to \(_{0}\), and a posterior is allowed to depend on all the data, and in particular on any subset of the data. Therefore, the empirical loss \(_{}[(h^{},S)]\) can be computed on all the data \(S\), and the denominator of the bound in Theorem 1 can be the size of \(S\), and not the size of \(S_{2}\). This is what we call _preservation of confidence information on \(\)_, because all the data \(S\) are used to construct a confidence bound on \(_{}[L(h^{})]\), and not just \(S_{2}\). This is in contrast to the bound on \(L(h^{*})\) in the approach of Mhammedi et al. (2019), which only allows to use \(S_{2}\) for bounding \(L(h^{*})\). Note that while we use all the data \(S\) in calculation of the bound, we only use \(S_{1}\) and \(_{}[(h^{},S_{1})]\) in the construction of \(\). Nevertheless, we can still use the knowledge that we will have \(n\) samples when we reach the estimation phase, i.e., when constructing \(\) we can leave the denominator of the bound at \(n\), allowing more aggressive deviation from \(_{0}\).
* If we restrict \(\) to depend only on \(S_{1}\), then it is a valid prior for estimation of any posterior quantity \(_{}[]\) based on \(S_{2}\). Thus, if we also restrict \(\) to depend only on \(S_{1}\), we can use any PAC-Bayes-Empirical-Bernstein-style inequality or the PAC-Bayes-split-kl inequality to estimate the excess loss \(_{}[L(h)-_{}[L(h^{})]]\) based on \(S_{2}\), i.e., based on \(_{}[(h,S_{2})-_{}[(h^{},S_{2})]]\). If \(_{}[L(h^{})]\) is a good approximation of \(_{}[L(h)]\) and \(_{}[L(h)]\) is not close to zero, then the excess loss \(_{}[L(h)-_{}[L(h^{})]]\) is more efficient to bound than the plain loss \(_{}[L(h)]\).
* In general, since \(_{}[L(h)]\) is expected to improve on \(_{}[L(h^{})]\), it is natural to set \(<1\). However, \(\) is not allowed to depend on \(S_{2}\), because otherwise \((h,S_{2})-_{}[(h^{},S_{2})]\) becomes a biased estimate of \(L(h)-_{}[(h^{})]\). We discuss the choice of \(\) in more detail when we present the bound and the experiments.
* Biggs and Guedj (2023) have proposed a sequential martingale-style evaluation of a martingale version of \(_{}[L(h)-L(h^{*})]\) and \(L(h^{*})\) in the approach of Mhammedi et al., but it has not been shown to yield significant improvements yet. The same "martingalization" can be directly applied to our decomposition, but to keep things simple we stay with the basic decomposition.
* Finally, we note that we can split \(S_{1}\) further and apply (1) recursively to bound \(_{}[L(h^{})]\).

To set notation for recursive decomposition, we use \(_{0},_{1},,_{T}\) to denote a sequence of distributions on \(\), where \(_{0}\) is an uninformed prior and \(_{T}=\) is the final posterior. We use \(_{2},,_{T}\) to denote a sequence of coefficients. For \(t 2\) we then have the recursive decomposition

\[_{_{t}}[L(h)]=_{_{t}}[L(h)-_{t}_{ _{t-1}}[L(h)]]+_{t}_{_{t-1}}[L(h)].\] (2)

To construct \(_{1},,_{T}\) we split the data \(S\) into \(T\) non-overlapping subsets, \(S=S_{1} S_{T}\). We restrict \(_{t}\) to depend on \(U_{t}^{}=_{s=1}^{t}S_{s}\) only, and we use \(U_{t}^{}=_{s=t}^{T}S_{s}\) to estimate (recursively) \(_{_{t}}[L(h)]\) (see Figures 1 and 2 in Appendix A for a graphical illustration). Note that \(S_{t}\) is used both for construction of \(_{t}\) and for estimation of \(_{_{t}}[L(h)]\) (it is both in \(U_{t}^{}\) and \(U_{t}^{}\)), resulting in efficient use of the data. It is possible to use any standard PAC-Bayes bound, e.g., Theorem 1, to bound \(_{_{1}}[L(h)]\), and any PAC-Bayes-Empirical-Bernstein-style bound or the PAC-Bayes-split-kl bound to bound the excess losses \(_{_{t}}[L(h)-_{t}_{_{t-1}}[L(h)]]\). The excess losses take more than three values, so in the next section we present a generalization of the PAC-Bayes-split-kl inequality to general discrete random variables, which may be of independent interest. The Recursive PAC-Bayes bound is presented in Section 4.

## 3 Split-kl and PAC-Bayes-split-kl inequalities for discrete random variables

The \(\) inequality is one of the tightest concentration of measure inequalities for binary random variables. Letting \(^{-1,+}(,):=\{p:p(\|p)\}\) denote the upper inverse of \(\) and \(^{-1,-}(,):=\{p:p(\|p)\}\) the lower inverse, it states the following.

**Theorem 2** (kl Inequality (Langford, 2005; Foong et al., 2021, 2022)).: _Let \(Z_{1},,Z_{n}\) be independent random variables bounded in the \(\) interval and with \([Z_{i}]=p\) for all \(i\). Let \(=_{i=1}^{n}Z_{i}\) be the empirical mean. Then, for any \((0,1)\):_

\[\!(p^{-1,+}(,));\!(p^{-1,-}(,)).\]

While the \(\) inequality is tight for binary random variables, it is loose for random variables taking more than two values due to its inability to exploit small variance. To address this shortcoming Wu and Seldin (2022) have presented the split-kl and PAC-Bayes-split-kl inequalities for ternary random variables. Ternary random variables naturally appear in a variety of applications, including analysis of excess losses, certain ways of analysing majority votes, and in learning with abstention. The bound of Wu and Seldin is based on decomposition of a ternary random variable into a pair of binary random variables and application of the \(\) inequality to each of them. Their decomposition yields a tight bound in the binary and ternary case, but loose otherwise. The same decomposition was used by Biggs and Guedj (2023) to derive a slight variation of the inequality, with the same limitations. We present a novel decomposition of discrete random variables into a superposition of binary random variables. Unlike the decomposition of Wu and Seldin, which only applies in the ternary case, our decomposition applies to general discrete random variables. By combining it with \(\) bounds for the binary elements we obtain a tight bound. The decomposition is presented formally below and illustrated graphically in Figure 3 in Appendix A.

### Split-kl inequality

Let \(Z\{b_{0},,b_{K}\}\) be a \((K+1)\)-valued random variable with \(b_{0}<b_{1}<<b_{K}\). For \(j\{1,,K\}\) define \(Z_{|j}=(Z b_{j})\) and \(_{j}=b_{j}-b_{j-1}\). Then \(Z=b_{0}+_{j=1}^{K}_{j}Z_{|j}\). For a sequence \(Z_{1},,Z_{n}\) of \((K+1)\)-valued random variables with the same support, let \(Z_{i|j}=(Z_{i} b_{j})\) denote the elements of binary decomposition of \(Z_{i}\).

**Theorem 3** (Split-kl inequality for discrete random variables).: _Let \(Z_{1},,Z_{n}\) be i.i.d. random variables taking values in \(\{b_{0},,b_{K}\}\) with \([Z_{i}]=p\) for all \(i\). Let \(_{|j}=_{i=1}^{n}Z_{i|j}\). Then for any \((0,1)\):_

\[\!(p b_{0}+_{j=1}^{K}_{j}\,^{-1,+} (_{|j},)).\]

Proof.: Let \(p_{|j}=[_{|j}]\), then \(p=b_{0}+_{j=1}^{K}_{j}p_{|j}\) and

\[\!(p b_{0}+_{j=1}^{K}_{j}\,^{-1,+} (_{|j},)) \!( j:p_{|j}^{-1,+}(_{|j}, )),\]

where the first inequality is by the decomposition of \(p\) and the second inequality is by the union bound and Theorem 2. 

### PAC-Bayes-Split-kl inequality

Let \(f:\{b_{0},,b_{K}\}\) be a \((K+1)\)-valued loss function. (To connect it to the earlier examples, in the binary prediction case we would have \(=\) with elements \(Z=(X,Y)\) and \(f(h,Z)=(h(X),Y)\), but we will need a more general space \(\) later.) For \(j\{1,,K\}\) let \(f_{|j}(,)=(f(,) b_{j})\). Let \(_{Z}\) be an unknown distribution on \(\). For \(h\) let \(F(h)=_{_{Z}}[f(h,Z)]\) and \(F_{|j}(h)=_{_{Z}}[f_{|j}(h,Z)]\). Let \(S=\{Z_{1},,Z_{n}\}\) be an i.i.d. sample according to \(_{Z}\) and \(_{|j}(h,S)=_{i=1}^{n}f_{|j}(h,Z_{i})\).

**Theorem 4** (PAC-Bayes-Split-kl Inequality).: _For any distribution \(\) on \(\) that is independent of \(S\) and any \((0,1)\):_

\[\!(:_{}[F(h)] b_{0}+ _{j=1}^{K}_{j}\,^{-1,+}(_{}[_{ |j}(h,S)],(\|)+}{}}{n}) ),\]

_where \(\) is the set of all possible probability distributions on \(\) that can depend on \(S\)._Proof.: We have \(f(,)=b_{0}+_{j=1}^{K}_{j}f_{[j}(,)\) and \(F(h)=b_{0}+_{j=1}^{K}_{j}F_{[j}(h)\). Therefore,

\[:_{}[F(h )] b_{0}+_{j=1}^{K}_{j}^{-1,+}(_ {}[_{]j}(h,S)],(\|)+}{}}{n})\] \[ j: _{}[F_{]j}(h)]^{-1,+}(_{ }[_{]j}(h,S)],(\|)+}{}}{n}),\]

where the first inequality is by the decomposition of \(F\) and the second inequality is by the union bound and application of Theorem 1 to \(F_{]j}\) (note that \(f_{[j}\) is a zero-one loss function). 

## 4 Recursive PAC-Bayes bound

Now we derive a Recursive PAC-Bayes bound based on the loss decomposition in equation (2). We aim to bound \(_{_{t}}[L(h)-_{t}_{_{t-1}}[L(h^{})]]\), which we denote by

\[F_{_{t},_{t-1}}(h)=L(h)-_{t}_{_{t-1}}[L(h^{ })]=_{_{t-1}}[(h(X),Y)-_{t}(h^{ }(X),Y)],\]

where \(_{t-1}\) is a product distribution on \(\) and \(h^{}\) is sampled according to \(_{t-1}\). We further define

\[f_{_{t}}(h,(X,Y,h^{}))=(h(X),Y)-_{t}(h^{}(X),Y )\{-_{t},0,1-_{t},1\},\]

then \(F_{_{t},_{t-1}}(h)=_{_{t-1}}[f_{_ {t}}(h,(X,Y,h^{}))]\). In order to apply Theorem 4, we represent \(f_{_{t}}\) as a superposition of binary functions. For this purpose we let \(b_{t|0},b_{t|1},b_{t|2},b_{t|3}}=\{-_{t},0,1-_{t},1\}\) and define \(f_{_{t}|j}(h,(X,Y,h^{}))=f_{_{t}}(h,(X,Y,h^ {})) b_{t|j}\). We let \(F_{_{t},_{t-1}|j}(h)=_{_{t-1}}[f_{ _{t}|j}(h,(X,Y,h^{}))]\), then \(F_{_{t},_{t-1}}(h)=-_{t}+_{j=1}^{3}(b_{t|j}-b_{t|j-1})F_{ _{t},_{t-1}|j}(h)\).

Now we construct an empirical estimate of \(F_{_{t},_{t-1}|j}(h)\). We first let \(_{t-1}=h_{1}^{_{t-1}},h_{2}^{_{t-1}},}\) be a sequence of prediction rules sampled independently according to \(_{t-1}\). We define \(U_{t}^{}_{t-1}=X_{i},Y_{i},h_{i}^{ _{t-1}}):(X_{i},Y_{i}) U_{t}^{}}\). In words, for every sample \((X_{i},Y_{i}) U_{t}^{}\) we sample a prediction rule \(h_{i}^{_{t-1}}\) according to \(_{t-1}\) and put the triplet \((X_{i},Y_{i},h_{i}^{_{t-1}})\) in \(U_{t}^{}_{t-1}\). The triplets \((X_{i},Y_{i},h_{i}^{_{t-1}})\) correspond to the random variables \(Z\) in Theorem 4. We note that \(|U_{t}^{}|=|U_{t}^{}_{t-1}|\), and we let \(n_{t}^{}=|U_{t}^{}|\). We define the empirical estimate of \(F_{_{t},_{t-1}|j}(h)\) as \(_{_{t}|j}(h,U_{t}^{}_{t-1})=^{}}_{(X,Y,h^{}) U_{t}^{} _{t-1}}f_{_{t}|j}(h,(X,Y,h^{}))\). Note that \(_{_{t-1}}[_{_{t}|j}(h,U_{t}^{ }_{t-1})]=F_{_{t},_{t-1}|j}(h)\), therefore, we can use Theorem 4 to bound \(_{_{t}}[F_{_{t},_{t-1}}(h)]\) using its empirical estimates. We are now ready to state the bound.

**Theorem 5** (Recursive PAC-Bayes Bound).: _Let \(S=S_{1} S_{T}\) be an i.i.d. sample split in an arbitrary way into \(T\) non-overlapping subsamples, and let \(U_{t}^{}=_{s=1}^{t}S_{s}\) and \(U_{t}^{}=_{s=t}^{T}S_{s}\). Let \(n_{t}^{}=|U_{t}^{}|\). Let \(_{0}^{*},_{1}^{*},,_{T}^{*}\) be a sequence of distributions on \(\), where \(_{t}^{*}\) is allowed to depend on \(U_{t}^{}\), but not the rest of the data. Let \(_{2},,_{T}\) be a sequence of coefficients, where \(_{t}\) is allowed to depend on \(U_{t-1}^{}\), but not the rest of the data. For \(t\{1,,T\}\) let \(_{t}\) be a set of distributions on \(\), which are allowed to depend on \(U_{t}^{}\). Then for any \((0,1)\):_

\[( t\{1,,T\}_{t}_{t}: _{_{t}}[L(h)]_{t}(_{t})),\]

_where \(_{t}(_{t})\) is a PAC-Bayes bound on \(_{_{t}}[L(h)]\) defined recursively as follows. For \(t=1\)_

\[_{1}(_{1})=^{-1,+}(_{_{1}}[ (h,S)],(_{1}\|_{0}^{*})+}{}}{n}).\]

_For \(t 2\) we let \(_{t}(_{t},_{t})\) denote a PAC-Bayes bound on \(_{_{t}}[L(h)-_{t}_{_{t-1}^{*}}[L(h^{})]]\) given by_

\[_{t}(_{t},_{t})=-_{t}+_{j=1}^{3}(b_{t|j}-b_{t|j-1} )^{-1,+}(_{_{t}}[_{_{t}|j }(h,U_{t}^{}_{t-1}^{*})], (_{t}\|_{t-1}^{*})+^{}}}{}}{n_ {t}^{}})\]

_and then_

\[_{t}(_{t})=_{t}(_{t},_{t})+_{t}\, _{t-1}(_{t-1}^{*}).\] (3)Proof.: By Theorem 1 we have \((_{1}_{1}:_{_{1}}[L(h)] B_{1}( _{1}))\). Further, by Theorem 4 for \(t\{2,,T\}\) we have \(_{t}_{t}:_{_{t}}[L(h)- _{t}_{_{t-1}^{*}}[L(h^{})]]_{t}(_{ t},_{t})\). The theorem follows by a union bound and the recursive decomposition of the loss (2). 

**Discussion**

* Note that \(_{1}^{*},,_{T}^{*}\) can be constructed sequentially, but \(_{t}^{*}\) can only be constructed based on the data in \(U_{t}^{ train}\), meaning that in the construction of \(_{t}^{*}\) we can only rely on \(_{_{t}}[_{_{t}|j}(B,S_{t}_{t-1})]\), but not on \(_{_{t}}[_{_{t}|j}(h,U_{t}^{ val}_{t-1})]\). Also note that \(S_{t}\) is part of both \(U_{t}^{ train}\) and \(U_{t}^{ val}\) (see Figure 1 in Appendix A for a graphical illustration). In other words, when we evaluate the bounds we can use additional data. And even though the additional data can only be used in the evaluation stage, we can still use the knowledge that we will get more data for evaluation when we construct \(_{t}^{*}\). For example, we can take \[_{1}^{*}=_{}^{-1,+}(_{}[(h,S _{1})],(\|_{0}^{*})+}{}}{n})\] (4) and for \(t 2\) \[_{t}^{*}=_{}_{j=1}^{3}(b_{t|j}-b_{t|j-1})\,^{-1,+ }(_{}[_{_{t}|j}(h,S_{t}_{t-1 }^{*})],(\|_{t-1}^{*})+^{  val}}}{}}{n_{t}^{ val}}).\] (5) The empirical losses above are calculated on \(S_{t}\) corresponding to \(_{t}^{*}\), but the sample sizes \(n_{t}^{ val}\) correspond to the size of the validation set \(U_{t}^{ val}\) rather than the size of \(S_{t}\). This allows to be more aggressive in deviating with \(_{t}^{*}\) from \(_{t-1}^{*}\) by sustaining larger \((_{t}^{*}\|_{t-1}^{*})\) terms.
* Similarly, \(_{2},,_{T}\) can also be constructed sequentially, as long as \(_{t}\) only depends on \(U_{t-1}^{ train}\) (otherwise \(_{_{t}|j}(h,S_{t}_{t-1}^{*})\) becomes a biased estimate of \(F_{_{t},_{t-1}^{*}|j}(h)\)).
* We naturally want to have improvement over recursion steps, meaning \(_{t}(_{t}^{*})<_{t-1}(_{t-1}^{*})\). Plugging this into (3), we obtain \((_{t}^{*},_{t})+_{t}B_{t-1}(_{t-1}^{*})<B_{t-1}( _{t-1}^{*})\), which implies that we want \(_{t}\) to be sufficiently small to satisfy \(_{t}<1-_{t}(_{t}^{*},_{t})}{B_{t-1}(_{t-1} ^{*})}\). At the same time, \(_{t}\) should be non-negative. Therefore, improvement over recursion steps can only be maintained as long as \(_{t}(_{t}^{*},_{t})<B_{t-1}(_{t-1}^{*})\). We note that \(_{t}\,_{t-1}(_{t-1}^{*})\) term in (3) is linearly increasing in \(_{t}\), whereas \((_{t}^{*},_{t})\) is decreasing in \(_{t}\). The value of \(_{t}\) that minimizes the trade-off depends on the data. Even though it is not allowed to use \(U_{t}^{ val}\) for tuning \(_{t}\), it is possible to take a grid of values of \(_{t}\) and a union bound over the grid, and then select the best value from the grid based the value of the bound evaluated on \(U_{t}^{ val}\).

## 5 Experiments

In this section, we provide an empirical comparison of our Recursive PAC-Bayes (RPB) procedure to the following prior work: i) Uninformed priors (Uninformed), (Dziugaite and Roy, 2017); ii) Data-informed priors (Informed) (Ambroladze et al., 2007; Perez-Ortiz et al., 2021); iii) Data-informed prior + excess loss (Informed + Excess) (Mhammedi et al., 2019; Wu and Seldin, 2022). All the experiments were run on a laptop. The source code for replicating the experiments is available at Github1.

We start with describing the details of the optimization procedure, and then present the results.

### Details of the optimization and evaluation procedure

We constructed \(_{1}^{*},,_{T}^{*}\) sequentially using the optimization objective, (4) for \(_{1}^{*}\) and (5) for \(_{2}^{*}\) to \(_{T}^{*}\), and computed the bound using the recursive procedure in Theorem 5. There are a few technical details concerning convexity of the optimization procedure and infinite size of the set of prediction rules \(\) that we address next.

#### 5.1.1 Convexification of the loss functions

The functions \(f_{_{i}|j}(h,(X,Y,h^{}))\) defined in Section 4 are non-convex and non-differentiable: \(f_{_{i}|j}(h,(X,Y,h^{}))=f_{_{t}}(h,(X,Y,h^{ })) b_{i|j}=(h(X),Y)-_{t}(h^{ }(X),Y) b_{i|j}\). In order to facilitate optimization, we approximate the external indicator function \((z z_{0})\) by a sigmoid function \((z;c_{1},z_{0})=(1+(c_{1}(z-z_{0})))^{-1}\) with a fixed parameter \(c_{1}>0\) specified in Appendix B.3.

Furthermore, since the zero-one loss \((h(X),Y)\) is also non-differentiable, we adopt the cross-entropy loss, as in most modern training procedures (Perez-Ortiz et al., 2021). Specifically, for a \(k\)-class classification problem, let \(h:^{k}\) represent the function implemented by the neural network, assigning each class a real value. Let \(u=h(X)\) be the assignment, with \(u_{i}\) being the \(i\)-th value of the vector. To convert this real-valued vector into a probability distribution over classes, we apply the softmax function \(:^{k}^{k-1}\), where \((u)_{i}=(c_{2}u_{i})/_{j}(c_{2}u_{j})\) for some \(c_{2}>0\) for each entry. The cross-entropy loss \(^{}:^{k}[k]\) is defined by \(^{}(u,Y)=-((u)_{Y})\). However, since this loss is unbounded, whereas the PAC-Bayes-kl bound requires losses within \(\), we enforce a \(\)-valued cross-entropy loss by mixing the output distribution with a uniform distribution \((u)\), i.e., \((u)_{i}=(1-p_{})(u)_{i}+p_{}/k\) for all \(i[k]\) and for some \(p_{}>0\), and then rescaling it to \(\) by taking \(^{}(u,Y)=-((u)_{Y})/(k/p_{})\).

We emphasize that in the evaluation of the bound (using Theorem 5), we directly compute the zero-one loss and the \(f_{_{t}|j}\) functions without employing the approximations.

#### 5.1.2 Relaxation of the PAC-Bayes-kl bound

The PAC-Bayes-kl bound is often criticized for being unfriendly to optimization (Rodriguez-Galvez et al., 2024). Therefore, several relaxations have been proposed, including the PAC-Bayes-classic bound (McAllester, 1999), the PAC-Bayes-\(\) bound (Thiemann et al., 2017), and the PAC-Bayes-quadratic bound (Rivasplata et al., 2019; Perez-Ortiz et al., 2021), among others. In our optimization we have adopted the bound of McAllester (1999) instead of the kl-based bounds in Equation (5).

We again emphasize that in the evaluation of the bound we used the kl-based bounds in Theorem 5.

#### 5.1.3 Estimation of \(_{}[]\)

Due to the infinite size of \(\) and lack of a closed-form expression for \(_{_{1}}[(h,S)]\) and \(_{_{t}}[_{_{t}|j}(h,U_{t}^{}_{t-1}^{*})]\) appearing in Theorem 5, we approximate them by sampling (Perez-Ortiz et al., 2021). For optimization, we sample one classifier for each mini-batch during stochastic gradient descent. For evaluation, we sample one classifier for each data in the corresponding evaluation dataset. Due to approximation of the empirical quantities the final bound in Theorem 5 requires an additional concentration bound. (We note that the extra bound is only required for computation of the final bound, but not for optimization of \(_{t}^{*}\).) Specifically, let \(_{t}^{*}=\{h_{1}^{_{1}},h_{2}^{_{1}},,h_{m}^{_{t}}\}\) be \(m\) prediction rules sampled independently according to \(_{t}\). Then for any function \(f(h)\) taking values in \(\) (which is the case for \((h,S)\) and \(_{_{t}|j}(h,U_{t}^{}_{t-1}^{*})\)) and \(^{}(0,1)\) we have

\[_{_{t}^{*}}[f(h)]^{-1,+}( _{i=1}^{m}f(h_{i}^{_{i}^{*}}),})^{}.\]

It is worth noting that \(_{_{t}^{*}}[f(h)]\) is evaluated for a fixed \(_{t}^{*}\), meaning that there is no selection involved, and therefore no \(\) term appears in the bound above. We, of course, take a union bound over all the quantities being estimated.

### Experimental results

We evaluated our approach and compared it to prior work using multi-class classification tasks on MNIST (LeCun and Cortes, 2010) and Fashion MNIST (Xiao et al., 2017) datasets, both with 60000 training data. The experimental setup was based on the work of Dziugaite and Roy (2017) and Perez-Ortiz et al. (2021). Similar to them we used Gaussian distributions for all the priors and posteriors, modeled by probabilistic neural networks. Technical details are provided in B.

The empirical evaluation is presented in Table 1. For the Uninformed approach, we trained and evaluated the bound using the entire training dataset directly. For the other two baseline methods, Informed and Informed + Excess Loss, we used half of the training data to train the informed prior and an ERM \(h^{*}\) for the excess loss, and the other half to learn the posterior. For our Recursive PAC-Bayes, we chose \(_{t}=1/2\) for all \(t\), and conducted experiments with \(T=2,4,6,8\) to study the impact of recursion depth. (Each value of \(T\) corresponded to a separate run of the algorithm and a separate evaluation of the bound, i.e., they should not be seen as successive refinements.) We applied a geometric data split. Specifically, for \(T=2\) the split was (30000, 30000) points; for \(T=4\), it was (7500, 7500, 15000, 30000); for \(T=6\) it was (1875, 1875, 3750, 7500, 15000, 30000); and for \(T=8\), it was (469, 469, 937, 1875, 3750, 7500, 15000, 30000). This approach allowed the early recursion steps, which had fewer data points, to efficiently learn the prior, while preserving enough data for fine-tuning in the later steps. Note that with this approach the value of \(n_{t}^{ val}=|U_{t}^{ val}|=_{s=t}^{T}|S_{s}|\), which is in the denominator of the bounds in Theorem 5, is at least \(\).

Table 1 shows that even with only \(T=2\), which corresponds to the data split used in the Informed and the Informed + Excess Loss approaches, RPB achieves better test performance than prior work. As the recursion deepens, further improvements in both the test error and the bound are observed. We note that while the bound for \(T=2\) is looser compared to the Informed + Excess Loss method, deeper recursion yields bounds that are tighter. Overall, deep recursion provides substantial improvements in the bound and the test error relative to prior work.

Tables 2 and 3 provide a glimpse into the training progress of RPB with \(T=8\) by showing the evolution of the key quantities along the recursive process. Similar tables for other values of \(T\) are provided in Appendix B.4, along with training details for other methods. The tables show an impressive reduction of the KL term and significant improvement of the bound as the recursion proceeds, demonstrating effectiveness of the approach.

  &  &  \\  & Train 0-1 & Test 0-1 & Bound & Train 0-1 & Test 0-1 & Bound \\  Uninf. &.343 (2e-3) &.335 (3e-3) &.457 (2e-3) &.382 (2e-3) &.384 (2e-3) &.464 (2e-3) \\ Inf. &.377 (8e-4) &.371 (6e-3) &.408 (9e-4) &.412 (1e-3) &.413 (6e-3) &.440 (1e-3) \\ Inf. + Ex. &.157 (2e-3) &.151 (3e-3) &.192 (2e-3) &.280 (4e-3) &.285 (5e-3) &.342 (6e-3) \\ RPB \(T=2\) &.143 (2e-3) &.139 (3e-3) &.321 (3e-3) &.257 (3e-3) &.266 (5e-3) &.404 (3e-3) \\ RPB \(T=4\) &.112 (1e-3) &.109 (1e-3) &.203 (8e-4) &.203 (2e-3) &.213 (3e-3) &.293 (1e-3) \\ RPB \(T=6\) &.103 (1e-3) &.101 (1e-3) &.166 (1e-3) &.186 (4e-4) &.198 (1e-3) &.255 (1e-3) \\ RPB \(T=8\) & **.101 (1e-3)** & **.097 (2e-3)** & **.158 (2e-3)** & **.181 (1e-3)** & **.192 (3e-3)** & **.242 (1e-3)** \\ 

Table 1: Comparison of the classification loss of the final posterior \(\) on the entire training data, \(_{}[(h,S)]\) (Train 0-1), and on the testing data, \(_{}[(h,S^{ test})]\) (Test 0-1), and the corresponding bounds for each method on MNIST and Fashion MNIST. We report the mean and one standard deviation over 5 repetitions. “Unif.” abbreviates the Uniform approach, “Inf.” the Informed, “Inf. + Ex.” the Informed + Excess Loss, and “RPB” the Recursive PAC-Bayes.

 \(t\) & \(n_{t}^{ val}\) & \(_{_{t}}[_{_{t}}(h,U_{t}^{ val}_{t-1 })]\) & \((_{t}^{*}|_{t-1}^{*})}{n_{t}^{ val}}\) & \(_{t}(_{t}^{*},_{t})\) & \(B_{t}(_{t}^{*})\) & Test 0-1 \\ 
1 & 60000 &.009 (3e-4) &.612 (9e-3) &.532 (.011) \\
2 & 59532 & -0.046 (4e-3) &.031 (1e-3) &.114 (2e-3) &.421 (5e-3) &.215 (7e-3) \\
3 & 59063 &.040 (3e-3) &.013 (9e-4) &.125 (3e-3) &.336 (2e-3) &.146 (3e-3) \\
4 & 58125 &.049 (1e-3) &.005 (3e-4) &.099 (1e-3) &.267 (7e-4) &.120 (2e-3) \\
5 & 56250 &.052 (4e-4) &.002 (1e-4) &.083 (1e-3) &.217 (1e-3) &.111 (2e-3) \\
6 & 52500 &.051 (1e-3) &.001 (4e-5) &.076 (1e-3) &.185 (1e-3) &.104 (2e-3) \\
7 & 45000 &.050 (1e-3) & 8e-4 (6e-5) &.073 (1e-3) &.166 (1e-3) &.099 (1e-3) \\
8 & 30000 &.050 (1e-3) & 6e-4 (4e-5) &.074 (1e-3) &.158 (2e-3) &.097 (2e-3) \\ 

Table 2: Insight into the training process of the Recursive PAC-Bayes for \(T=8\) on MNIST. The table shows the evolution of \(_{t}(_{t}^{*},_{t})\), \(B_{t}(_{t}^{*})\), and other quantities as the training progresses with \(t\). We define \(_{_{t}}(h,U_{t}^{ val}_{t-1})=-_{t}+_{j=1}^ {3}(b_{t|j}-b_{t|j-1})_{_{t}|j}(h,U_{t}^{ val}_{t- 1})\).

## 6 Discussion

We have presented the first PAC-Bayesian bound that supports sequential prior updates and preserves confidence information on the prior. The work closes a long-standing gap between Bayesian and Frequentist learning by making sequential data processing and sequential updates of prior knowledge meaningful and beneficial in the frequentist framework, as it has always been in the Bayesian framework. We have shown that apart from theoretical beauty the approach is highly beneficial in practice.

The Recursive PAC-Bayes framework is extremely rich and powerful, and leads to numerous directions for future research, some of which we briefly sketch next.

* The decomposition in (2) applies to any loss function, including unbounded losses. It would be interesting to find additional applications to it.
* While we have restricted ourselves to the zero-one loss function to illustrate the use of PAC-Bayes-split-kl, the results can be directly generalized to any bounded loss function by replacing PAC-Bayes-split-kl with PAC-Bayes-Empirical-Bernstein or PAC-Bayes-Unexpected-Bernstein, and deriving the corresponding analogue of Theorem 5 (which is straightforward).
* We have shown that the bound works well with geometric split of the data, but there are many other ways to split the data which could be studied.
* There is also a lot of space for experimentation with optimization of \(_{t}\).
* It would be interesting to study how the bound will perform in sequential learning settings, where the data arrives sequentially, and thus the partition is dictated externally.
* There are many interesting research directions from the computational perspective. We note that for base models with linear computational complexity (e.g., neural networks) the overhead of recursion is relatively small and optimization time of Recursive PAC-Bayes is comparable to processing all data at once or in two chunks (as in data-dependent priors). For base models with superlinear computational complexity (e.g., kernel SVMs) sequential training of several small models in the recursion may actually be cheaper than training a big model based on all the data. Moreover, since the bound in Theorem 5 holds for any sequence of distributions \(_{0}^{*},_{1}^{*},,_{T}^{*}\), the optimization in equation (5) is allowed to be approximate. Considering that the improvement of the bounds and the test loss relative to prior work was very significant, there is space to look at the trade-off between statistical power and computational complexity. Namely, it may potentially be possible to relax the approximation of \(\) in equation (5) to gain computational speed-up at the cost of only a small compromise on the bounds and test losses.
* We note that it is possible to start the recursion at \(_{0}\). Namely, it is possible to use, for example, Theorem 2 to bound \(_{_{0}}[L(h)]\) using all the data, and apply the recursive decomposition (2) starting from \(_{1}\). Whether this would yield an advantage relative to starting the recursion at \(_{1}\), as we did, remains to be studied.