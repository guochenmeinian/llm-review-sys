# Conformalised Conditional Normalising Flows for

Joint Prediction Regions in time series

Eshant English

Hasso Plattner Institute for Digital Engineering, Germany

University of California, Irvine, USA

eshant.english@hpi.de

primary contact: eshant.english@hpi.de

The work was done during a research stay at UCI

Christoph Lippert

Hasso Plattner Institute for Digital Engineering, Germany

Hasso Plattner Institute for Digital Health at the Icahn School of Medicine at Mount Sinai, USA

christoph.lippert@hpi.de

###### Abstract

Conformal Prediction offers a powerful framework for quantifying uncertainty in machine learning models, enabling the construction of prediction sets with finite-sample validity guarantees. While easily adaptable to non-probabilistic models, applying conformal prediction to probabilistic generative models, such as Normalising Flows is not straightforward. This work proposes a novel method to conformale conditional normalising flows, specifically addressing the problem of obtaining prediction regions for multi-step time series forecasting. Our approach leverages the flexibility of normalising flows to generate potentially disjoint prediction regions, leading to improved predictive efficiency in the presence of potential multimodal predictive distributions.

## 1 Introduction

Recent advances in Conformal Prediction have seen its application extended to diverse domains, including Gaussian Processes (Jaber et al., 2024) and Monte-Carlo methods (Bethell et al., 2024), driven by the attractive finite-sample validity guarantees offered via conformal prediction (Vovk et al., 2005; Angelopoulos and Bates, 2022). However, direct application to generative models, such as Normalising Flows (Kobyzev et al., 2021; Papamakarios et al., 2021) or Diffusion models (Song et al., 2021; Luo, 2022), has been limited due to their primary focus on generation rather than prediction tasks.

Notably, discrete-time normalising flows offer a unique advantage over other generative models: simulation-free exact likelihood computation. This enables direct density evaluation at a given sample, naturally extending to conditional density computation. In this work, we exploit this property of normalising flows to derive prediction regions for multi-step time series forecasting.

A prediction region is defined as a volume in \(H\)-dimensional space, where \(H\) is the forecast horizon, capturing the true forecast with probability \(1-\). Constructing such regions for time series is challenging due to temporal dependencies. Existing methods, such as Stankeviciute et al. (2021), rely on Bonferroni corrections based on conditional independence assumptions on the errors, leading to overly conservative predictions as \(H\) increases. Moreover, these approaches typically yield continuousband or rectangular regions, which may not be optimal for multimodal predictive distributions present in irregular time series.

Traditional conformal methods often rely on univariate conformity scores, with residuals being a natural choice in regression settings. However, this approach does not readily generalise to multivariate prediction cases. We propose the use of conditional density as a conformity score, capitalising on its adaptability to the historical context and its ability to quantify the plausibility of a given prediction naturally.

In summary, our key contribution lies in extending conformal methods to conditional normalising flows, thereby enabling adaptive and efficient predictive inference for multi-step time series forecasting (or more generally multivariate output).

## 2 Related works

Previous research has explored normalising flows for time series forecasting (Feng et al., 2023; Rasul et al., 2021). However, existing methods for uncertainty quantification in this context either lack coverage guarantees or rely on unrealistic assumptions when dealing with multi-step or multivariate forecasts. In the univariate case, conformalisation using residuals is straightforward. However, for higher-dimensional predictions, mapping residuals to quantiles is not trivial.

Existing approaches attempt to address this issue through various means, such as transforming multivariate residuals into Euclidean distances (Messoudi et al., 2021), using Chebyshev distance after modulation (English et al., 2024; Zhou et al., 2024), or modelling interdependencies between successive time steps using copulas (Sun and Yu, 2024). Nevertheless, these methods often result in large, continuous prediction regions that may be inefficient for capturing multimodal predictive distributions in time series. Achieving predictive efficiency, where the volume of the prediction set is minimised, becomes a crucial objective in such scenarios.

A recent work Colombo (2024) also combined Normalising Flows with Conformal Prediction. However, they do not use Normalising Flows to obtain density estimates for conformal scores; instead, they train the calibration process with Normalising Flows acting on the joint distribution of the errors. To the best of our knowledge, no existing conformal method for time series forecasting can produce multiple disjoint regions when the predictive distribution is multimodal. Building upon prior work, we propose a novel approach applicable to scenarios with multiple independent time series. Our method aims to overcome the limitations of previous approaches and provide a more efficient and flexible way to quantify uncertainty in time series forecasting.

## 3 Preliminaries

### Inductive Conformal Predictors

Inductive conformal predictors provide a computationally efficient alternative to Full conformal predictors for constructing prediction intervals by training the model only once. Given a dataset \(=\{(x_{i},y_{i})\}_{i=1}^{n}\) drawn from a distribution \(P\), we divide it into a training set \(_{}\) of size \(m\) and a calibration set \(_{}\) of size \(l\), where \(n=m+l\).

A point predictor \(h\) is trained on \(_{}\), and a conformity measure \(A\) is used to assess the _conformity_ of an example relative to the calibration set. We compute conformity scores (denoted by \(\)) for both the calibration set and a test point \(x^{*}\) with a postulated label \(y\), the label space:

* \(_{i}=A(h,_{},(x_{m+i},y_{m+i}))\), for \(i=1,,l\)
* \(^{*}=A(h,_{},(x^{*},y))\)

The prediction set (\(^{}\)) at significance level \(\) is then defined as:

\[^{}(x^{*})=\{y:^{*}\}|+1}{l +1}>\}.\] (1)

This set represents the values of \(y\) that are deemed _conforming_ compared to the calibration set, with a probability of at least \(1-\). Instead of comparing all the conformity scores, one can invert the quantile function of the conformity scores on the calibration set to get a threshold conformity score.

[MISSING_PAGE_FAIL:3]

where \(g_{}\) is an invertible transformation parameterized by \(\), and \(_{T+1:T+H}^{(i)}\) is a latent variable drawn from a simple base distribution (e.g., standard Gaussian).

Our specific implementation utilises a stack of \(K\) conditional affine coupling layers for \(g_{}\), each conditioned on the hidden state \(_{T}^{(i)}\) (identity transformation on \(_{1:T}^{(i)}\) for the experiments) to accommodate the temporal dynamics. The model is trained via maximum likelihood estimation using stochastic gradient descent, and forecasts are generated by sampling from the conditional distribution.

Once a model is trained using the training set proper, we can use the calibration set to calculate the conditional density around the true prediction given the historical context by using the change of the variable formula as stated in Equation 2. We consider this as our conformity score and can apply Equation 1 for any postulated label to know if it is a part of the prediction set. Additionally, the regions formed are adaptive to the historical context by using conditional density as a conformity score.

We can also sort all the conformity scores and obtain the desired quantile \(q_{}\) of the sorted scores. To construct a region that contains the true prediction with the desired significance level \(\), we can, then, sample points from the multi-variate label space either through a grid or through other methods such as Monte-Carlo sampling, the sampled points with a conditional density larger than \(q_{}\) form cluster(s) which can be several if there are multiple modes of the predictive distribution. Unlike other baselines, a region formed like this has no geometrical restrictions.

## 5 Empirical Results

We assess the _coverage_ of our model on two synthetic time-series datasets and one real-world dataset (COVID-UK) from Kipf et al. (2018), following the experimental protocol of Sun and Yu (2024).

For both _synthetic_ datasets, we forecast 24 steps ahead (\(H=24\)) using a history of 35 steps (\(T=35\)), Each time step consists of two-dimensional data (\(^{2}\)). The datasets differ in the magnitude of the added Gaussian noise: \(=0.01\) and \(=0.05\), respectively. For the COVID-UK dataset, which is a difficult time series due to irregularity, we predict daily cases for the upcoming 10 days based on the preceding 100 days.

We computed the coverages by checking if the true value is accepted by the conditional density threshold used as a conformity score by our method. Table 1 presents results for all the datasets: (\(=0.01\)) _particle1_ and (\(=0.05\)) _particle5_ dataset. Our proposed method demonstrates coverage closest to the nominal 0.9 level (\(\) = 0.1). CRNN overcovers(except on the COVID-UK dataset), and other methods, notably MC-dropout, exhibit severe undercoverage.

## 6 Discussion and Future Work

In this work, we introduced a novel approach to conformalise conditional normalising flows for multi-step time series forecasting, enabling the construction of prediction regions without assuming specific geometric shapes like spheres, bands, or ellipses (Cleaveland et al., 2024; Xu et al., 2024). By conditioning the conformity scores on the time series history, our method also yields adaptive prediction regions, a feature not commonly found in existing approaches (English et al. (2023); Zhou et al. (2024) being notable exceptions, but can only have rectangular regions). Although our work focussed on time series forecasting, the idea is trivially applicable to multivariate regression as

  
**Method** & **Particle1** & **Particle5** & **COVID-UK** \\  MC-Dropout & 0.79 & 0.43 & 0.00 \\ CRNN & 0.99 & 0.93 & **0.87** \\ CopulaCPTS & 0.86 & 0.86 & 0.78 \\
**CCNF-JPR** & **0.91** & **0.89** & **0.87** \\   

Table 1: Comparison of the coverages (nominal) on the test set for \(=0.1\). The coverage values closer to 0.9 are highlighted in bold on each dataset. Our method achieves values close to 0.9 whereas CopulaCPTS always undercovers, MC-dropout severely undercover, and CRNN often overcovers (except on the COVID-UK dataset).

multivariate regression can be considered a special case where the time steps/indices are independent. One bottleneck is that exhaustive sampling might be computationally expensive if the label space is high-dimensional. Efficient sampling schemes can be explored for computational feasibility.

While normalising flows are often employed with neural networks, this might not always be desirable when using classical statistical methods such as ARMA models. Future research could explore extending existing kernel-based flow approaches (Meng et al., 2020; English et al., 2023) to conditional normalising flows (conditioned on prediction from the classical methods), potentially mitigating these challenges.

A further limitation is the lack of standard datasets exhibiting multimodal predictive distributions in time series, which are necessary to showcase the full potential of our approach. Future work will focus on addressing these limitations and conducting comprehensive empirical evaluations.