# NeuralSolver: Learning Algorithms For Consistent

and Efficient Extrapolation Across General Tasks

 Bernardo Esteves

INESC-ID,

Instituto Superior Tecnico,

Universidade de Lisboa &Miguel Vasco

Department of Intelligent Systems

KTH Royal Institute of Technology

Stockholm, Sweden &Francisco S. Melo

INESC-ID,

Instituto Superior Tecnico,

Universidade de Lisboa

Corresponded to: bernardo.esteves@tecnico.ulisboa.pt

###### Abstract

We contribute NeuralSolver, a novel recurrent solver that can efficiently and consistently extrapolate, i.e., learn algorithms from smaller problems (in terms of observation size) and execute those algorithms in large problems. Contrary to previous recurrent solvers, NeuralSolver can be naturally applied in both same-size problems, where the input and output sizes are the same, and in different-size problems, where the size of the input and output differ. To allow for this versatility, we design NeuralSolver with three main components: a recurrent module, that iteratively processes input information at different scales, a processing module, responsible for aggregating the previously processed information, and a curriculum-based training scheme, that improves the extrapolation performance of the method. To evaluate our method we introduce a set of novel different-size tasks and we show that NeuralSolver consistently outperforms the prior state-of-the-art recurrent solvers in extrapolating to larger problems, considering smaller training problems and requiring less parameters than other approaches. Code available at https://github.com/esteveste/NeuralSolver

## 1 Introduction

Humans can solve complex reasoning tasks by _extrapolating_: employing and combining elementary logical components to build more elaborate strategies. Machine learning models excel at pattern recognition, often outperforming humans in classification , control  and prediction tasks . However, these models still struggle at reasoning, which affects their ability to maintain their performance for increasingly harder versions of the same task . A particular type of difficulty emerges from the increase in _dimensionality_ of the input. Intuitively, learning algorithms to perform tasks, e.g., finding the goal in a maze (Figure 1), becomes increasingly harder for larger problems.

We focus on designing learning algorithms that are able to efficiently extrapolate, i.e., are able to learn algorithms to solve tasks over small problems (in terms of the dimensionality of the input) and execute over arbitrarily large problems, without a significant loss in performance nor additional fine-tuning. Recently, a novel class of methods, which we denote by _recurrent solvers_, have been proposed that employ recurrent neural networks to extrapolate . Compared to feed-forward networks, which have finite depth, recurrent networks can be iterated to an arbitrary depth at execution time. By doing so, these models can extrapolate to significantly larger problems than the ones seen during training by executing more recurrent steps. However, current recurrent solvers can only be applied to _same-size_ problems, such as the case of image generation, where the dimensionality of the input (e.g., image size) is the same as the dimensionality of the output. This limitation inhibits the use of these methods in a wide range of tasks, which we call _different-size_ tasks, where the input and output dimensions are different (e.g., classification and decision-making tasks).

We address this limitation and propose a novel recurrent solver that is able to consistently and efficiently extrapolate regardless of the size of the output and the type of problem. We name our approach NeuralSolver, a novel architecture for general tasks (same-size and different-size). Our approach introduces several architectural changes to recurrent solvers: a recurrent convolutional block that, through multiple iterations, perceives information at different scales in the input image, and a processing block (with an aggregation function) that merges information for the output of the model. Furthermore, we introduce a curriculum-based training scheme to improve the extrapolation abilities of our model. We train NeuralSolver on small observations (e.g., \(15 15\) images) using standard supervised learning techniques and apply the learned algorithm at test time with arbitrarily large observations (e.g., \(256 256\) images, or larger), with minimal loss in performance.

We evaluate NeuralSolver against prior recurrent solver in literature-standard same-size tasks and in a novel set of different-size tasks. We show across all tasks that our model significantly outperforms previous approaches in _extrapolation capability_, being able to execute learned algorithms in larger problems without loss in performance; in _training efficiency_, being able to learn algorithms from smaller problems; and in _parameter efficiency_, requiring \(90\%\) less parameters than similar approaches.

In summary, the contributions of our work are:

* NeuralSolver: We propose a novel recurrent solver that uses a recurrent convolutional module, a processing module (with an aggregation function) and curriculum-learning to train algorithms in small problems and extrapolate them to arbitrarily large problems. Contrary to previous recurrent solver, our model can be used in same-size and different-size tasks;
* **Different-size tasks**: We contribute a novel set of different-size classification tasks for recurrent solvers, with images of arbitrary size and label information;
* **Consistent and efficient extrapolation**: We show that NeuralSolver significantly outperforms the prior recurrent solvers regarding extrapolation capabilities, training efficiency and parameter efficiency.

## 2 Related Work

Schwarzschild et al.  introduce a class of recurrent neural networks that can execute at test time more iterations than the number of iterations used during training, to solve problems more complex than the ones seen during training, which we denote by _recurrent-solvers_. To do so, they propose a recurrent network architecture based on residual neural networks (ResNets)  that shows logical extrapolation abilities across same-size tasks by leveraging the spatial invariances in the inputs. However, these networks suffer from _overthinking_, where the network deteriorates in performance when the number of iterations is extended beyond the training distribution. To solve the overthinking problem Bansal et al.  introduces two new components to the previous architecture: (1) a recall module, that integrates the input directly into specific layers of the recurrent network, safeguarding against potential loss or corruption of deep features; and (2) a progressive loss (PL) training scheme that incentivizes recurrent networks to iteratively refine the feature representation, preventing the network from memorizing the number of recurrent module applications. The authors show that their improved network is able to extrapolate to problems 16 times larger than the training size with

Figure 1: Observations of the 1S-Maze environment of sizes 7\(\)7, 11\(\)11, 33\(\)33 and 129\(\)129, where the agent (green square) must go to the goal (red square). The light green arrow represents the next target action that the model needs to predict, while the purple path represents the sequence of actions required to solve the maze.

more than 95% accuracy on the same-size benchmark. We use this method as a baseline against our method. To address the problems of the computational efficiency and hyperparameter tuning of the progressive loss,  propose replacing the progressive loss with a delta loss term  and achieve similar performance to the original one. We propose a novel architecture that is able to outperform Bansal et al.  without the need of any additional loss to counter the overthinking problem (as shown in Appendix B.1). NeuralSolver is the first recurrent solver able to consistently and efficiently extrapolate learned algorithms in both same-size and different-size tasks.

## 3 The NeuralSolver Architecture

We address the challenge of designing a model that is able to efficiently learn algorithms from small problems that consistently extrapolate to larger problems. Contrary to previous recurrent solvers [5; 6; 7] we want to apply our model to both _same-size_ tasks, where the input and output have the same dimensionality, and _different-size_ tasks, where the input and output have different dimensionality. To address these challenges, we contribute NeuralSolver, depicted in Figure 2.

### Model Architecture

We design our model with three components: (i) we extract information from the input data using a _recurrent module_, responsible for iteratively processing the input observation at different scales, allowing our model to cope with arbitrarily large input data; (ii) information is then sent to a _processing module_, responsible for aggregating (if necessary) the processed information and generating the output of the network, allowing our model to be used in both same-size and different-size tasks; (iii) to train our model we employ a _curriculum-based_ scheme, that improves the extrapolation performance of NeuralSolver to larger problems.

**Recurrent Module**: This module consists of a layer normalized convolutional LSTM [9; 10; 11], a LSTM that uses convolutional layers instead of linear layers in its recurrent structure. The layer normalization is used to normalize the output of the convolutional layers and the cell state. We always provide the original input observations in the recurrent iterations of the LSTM, thus preventing the network from forgetting the input information over time, similar to the recall module in . We maintain the dimensionality of the input and output of this module constant in order to perform multiple iterations over the data, allowing our model to process arbitrarily large observations. We show in Appendix B.1 that our recurrent module allows NeuralSolver to not suffer from overthinking, despite not employing any progressive loss during training. Moreover, in Appendix C.5 we compare the effect of different choices of recurrent architectures in the performance of our model.

**Processing Module**: This module consists of a block of three convolutional layers (following ) whose input is the last hidden state of the recurrent module. Their purpose is to reduce the number of channels to a desired output number of channels. Additionally, we have an optional aggregation layer (in our case a global max-pooling layer) that can be employed in different-size tasks to reduce the variable input size of the network to a fixed output size. For example, for a two-dimensional input observation, we first reduce the input to a \(1 1 o\) tensor, where \(o\) is the desired output number of channels, and subsequently flatten the output tensor. This design allows our architecture to be used

Figure 2: We design NeuralSolver with two fundamental components: (i) a _recurrent module_ (purple), responsible for iteratively processing the input data regardless of its size; (ii) _processing module_ (green), with an optional aggregation layer (A), responsible for generating the output and allowing our architecture to be used both in same-size and different-size tasks. Additionally, we employ a _curriculum-based_ training scheme to improve the extrapolation performance of our architecture.

both in same-size and different-size tasks, with minimum changes. In Section 5.3 we compare the performance of different aggregation layers.

**Curriculum Learning Training**: We train our model on a set of smaller-size observations and test the performance of the model with larger dimensional observations (all belonging to the same task). Additionally, we employ a curriculum learning approach in different-size tasks to counter the effect of the reduced training signal (due to the smaller output dimensionality) [12; 13]: we initially train the models on lower-dimensionality observations, and then gradually increase the dimensionality of the observations every N epochs. To reduce the risk of catastrophic forgetting, we sample a minibatch of observations with a previously seen dimensionality (chosen uniformly at random) with a 20% chance, following previous work . In Section 5.3 we show the importance of the curriculum-based training scheme in the extrapolation performance of NeuralSolver.

We evaluate the role of each of these components in our overall performance in Section 5.3. For additional details on the complete architecture of the method please refer to Appendix B.

### Propagation of Information in NeuralSolver

To understand how information is processed in the recurrent module of our approach, we focus on the value of the internal state of the convolutional LSTM as a function of the number of iteration steps performed. In Figure 3, we show a maze-like environment at different iteration steps, where the task is the find the next position in the optimal path between the current position (in green) and the goal position (in red). We highlight the difference between the value of the internal state of the convolutional LSTM at each iteration step and the value of the internal state at the final iteration step (not shown in the figure). As the number of iterations increases, we observe that a larger number of positions in the maze become white as, for those positions, the value of the recurrent state does not change anymore. The speed of this convergence depends on the _receptive field of the convolution_: for example, a single convolution with a kernel size of 3 can capture the information from the adjacent pixels, propagating the information forward in one direction for a single pixel. As such, by using a convolutional recurrent neural networks we can propagate information across the input image by performing an appropriate number of iterations, regardless of the size of the problem.

This propagation of information also influences the output prediction. In Figure 3 (bottom), we highlight that the prediction of the output label is uncertain before iteration #10. However, in this iteration, the hidden state near the start goal (in green) has converged to the final value and the algorithm becomes certain of the correct label (in this case, "Down"). We provide more examples of learned algorithms in Appendix E.

## 4 Evaluation

We evaluate NeuralSolver to demonstrate how it outperforms previous state-of-the-art recurrent solvers accordingly to three main criteria: (i) _extrapolation capability_, the ability to execute learned

Figure 3: Propagation of information in NeuralSolver in a maze-like environment: the goal is for the agent (green) to find the goal position (red). Top: the difference between the value of the internal state of the recurrent module at each iteration step and the value at the final iteration. Larger differences are shown in dark blue and smaller differences in white. Bottom: additionally, we show the action probabilities predicted by the processing module of the model at different iterations, where the agent can move right (R), down (D), left (L), or up (U).

algorithms in larger problems; (ii) _training efficiency_, the ability to learn algorithms from smaller problems and still maintain a high-level of extrapolation capability; and (iii) the higher _parameter efficiency_ of the model. We compare our approach against previous recurrent solver baselines (Section 4.3), considering both same-size and different-size problems (Section 4.2). In Appendix B.3 we present the architecture of our model and training hyperparameters used in our evaluation.

### Methods

**Model Training**: We apply NeuralSolver in supervised learning scenarios with datasets of input images/features and output images/features, in the case of same-size tasks, or output labels, in the case of different-size tasks. As such, we train our models using cross-entropy loss on datasets with small image sizes and evaluate the classification performance of our models in datasets with larger input images. In different-size tasks this approach is similar to typical imitation learning .

**Model Checkpoint Selection**: We consider a training and validation set split of 80% and 20%, respectively. To select the model checkpoint to be used for evaluation, we use the one that has the best performance on the validation set. In case of ties we select the later model checkpoint.

**Evaluation Metrics**: In our evaluation we run the model for a large number of iterations (detailed in Appendix B.3) and consider the best accuracy obtained by the models at any iteration . We present the average best accuracy (in percentage) accompanied with the standard deviation. Additionally, we use the Almost Stochastic Order (ASO) test for statistical significance [15; 16], using a significance level of \(=0.05\) and employing the Bonferroni correction  for multiple comparisons. For more details on the ASO test and the statistical significance results, we refer the reader to Appendix D.

### Scenarios

For same-size tasks we use the benchmark recently proposed by Schwarzschild et al. , consisting of three tasks: a logical toy task (Prefix-Sum), a maze-solving task (Maze), and a chess puzzle task (Chess). Additionally, we modify the Maze task to allow smaller size inputs, which we denote by Thin-Maze. For a detailed description of these tasks we refer the reader to the original paper.

Due to the lack of a literature-standard set of different-size tasks for algorithm extrapolation, we introduce four new classification scenarios. These new scenarios consider as input images of arbitrary sizes and as output vectors of fixed dimensions (more details in Appendix A):

GoTo (Figure 3(a)): Inspired by the Minigrid environment , the goal of the task is to select the action that moves the agent (in green) closer to the exit position (in red). The classification target is a four-dimensional one-hot vector, corresponding to the available actions (up, down, left, right).

1S-Maze (Figure 3(b)): Inspired by the Maze environment from the same-size task benchmark, the objective of the task is to select the action that moves the agent (in green) closer to the goal position (in red). The classification target is a four-dimensional one-hot vector, corresponding to the available actions (left, right, no action).

Figure 4: We introduce a set of different-size classification tasks to evaluate the performance of recurrent solvers. In all tasks, the input is an image observation of the environment with arbitrary size. The output is an \(n\)-dimensional one-hot vector with: a) \(n=4\); b) \(n=4\); c) \(n=3\); d) \(n=4\).

Doorkey (Figure 3(d)): Inspired by the Doorkey environment in Minigrid , the goal of this multi-step task is to reach the goal position (red pixel on the bottom right) by first picking-up a key and using it to open a lock door. The classification target is a four-dimensional one-hot vector, corresponding to the available actions (forward, rotate right, grab, toggle).

### Baselines

**Bansal et al.**: The current state-of-the-art recurrent solver architecture, that combines a recurrent Resnet network with a recall module and progressive loss. We employ the original source code from the authors and suggested training hyperparameters (when available).

**FeedForward**: A non-recurrent feed-forward network, based on the ResNet architecture, that has a fixed number of layers. This baseline is used to show the importance of the recurrent module for extrapolation.

**Random**: A lower-bound baseline, that randomly samples a classification label. This model is used to help understand the worst-case performance of the models in different-size tasks.

As the baseline models cannot be applied directly in different-size tasks, we modify them by introducing a global pooling layer similar to that of our model.

## 5 Results

### Same-size Tasks

**Extrapolation Capability**: In Table 1 we present the extrapolation accuracy of NeuralSolver against the baselines in same-size tasks . NeuralSolver achieves state-of-the-art extrapolation

    & Prefix-Sum & Maze & Thin-Maze & Chess \\  & \((32,512)\) & \((24,124)\) & \((11,61)\) & \((8,8)\) \\  NeuralSolver & **100.00 \(\)0.00** & **100.00 \(\) 0.00** & **99.97 \(\) 0.09** & **84.30 \(\)0.40** \\  Bansal et al.  & 99.78 \(\)0.78 * & 86.63 \(\)28.21 * & 46.78 \(\)37.49 \(\) & 79.99 \(\)3.27 \(\) \\ Bansal et al.  + PL & **100.00 \(\)0.01** * & 91.13 \(\)27.37 * & 42.76 \(\)37.56 \(\) & 82.96 \(\)0.19 \(\) \\ FeedForward & 0.00 \(\)0.00 \(\) & 0.00 \(\) 0.00 \(\) & 0.00 \(\) 0.00 \(\) & 76.95 \(\)0.35 \(\) \\   

Table 1: Extrapolation accuracy on the same-size tasks benchmark proposed in Schwarzschild et al.  and the Thin-Maze environment, with corresponding training and evaluation sizes \((s_{t},s_{T})\). Higher is better. All results are averaged over 10 randomly-selected seeds. We highlight the best average results. We use (\(\)) to indicate stochastic dominance (\(_{}=0\)) and (*) to indicate almost stochastic dominance (\(_{}<0.5\)) of NeuralSolver over the baseline. We evaluate Bansal et al.  trained with progressive loss (PL) and without it.

Figure 5: Training efficiency of NeuralSolver and Bansal et al.  on same-size tasks: we present the accuracy of the learned algorithms on extrapolating to problems with different dimensionality (columns). Each color represents a different training size, specific to each task, detailed in Appendix A.3 In the dashed line we show the upper-bound on the performance.

performance on same-size tasks. In particular, our approach is able to achieve a 100% accuracy on the Prefix-Sum and Maze tasks, when evaluated on a scenario with observations 16 and 5 times bigger, respectively, than during training. On the more complex Chess task, our model still outperforms the other baselines, achieving an average accuracy of 84.30%. In Appendix B.1 we show that NeuralSolver also does not suffer from _overthinking_.

**Training Efficiency**: In Figure 5 we show the accuracy performance of the learned algorithm with our model when trained with different problem sizes. The results show that NeuralSolver outperforms Bansal et al.  in extrapolating when trained with smaller input observations, achieving consistent upper-bound performance when trained in problems with only 8-dimensional (Prefix-Sum) and 16-dimensional (Mazes) input observatons. The results for the other environments are in Appendix C.1.

**Parameter Efficiency**: In Table 2 we present the total parameter count of NeuralSolver against the baselines in same-size tasks . The results show that our model requires less than 10% of the total parameters of the baselines.

### Different-size Tasks

**Extrapolation capabilities**: In Table 3 we present the extrapolation performance of NeuralSolver against the baselines in different-size tasks. Our model also outperforms prior state-of-the-art recurrent solvers across all different-size tasks: our approach is able to achieve upper-bound performance when extrapolating to observation sizes 9 (1S-Maze) and 6 (GoTo, Pong, Doorkey) times larger than the ones provided during training. In Appendix C.7, we explore the setting of _extreme_ extrapolation, evaluating our model on very large image sizes (\(256 256\) and \(512 512\)). The results show that, even in such challenging conditions, NeuralSolver is able to consistently extrapolate without losing performance, while the baselines fail to do so.

**Training Efficiency**: In Figure 6 we show the performance of our model against the Bansal et al.  model with different training sizes. The results show that, while the previous state-of-the-art consistently under performs across most tasks on bigger test sizes, NeuralSolver is still able to learn algorithms with suitable extrapolation abilities (often close to the upper-bound performance) when trained with smaller observations. The observed gap of our method to upper-bound performance also highlights that the novel set of different-size tasks can be employed to benchmark the extrapolation performance of future recurrent solvers when training using only extremely small problems.

**Parameter Efficiency**: NeuralSolver employs the same architecture across all different-size tasks, with 0.23 million total parameters. This corresponds to a 92% reduction in the number of parameters

  
**Model** & Prefix-Sum & Maze & Thin-Maze & Chess \\  NeuralSolver & 0.168 & 0.053 & 0.053 & 0.699 \\ Bansal et al.  & 3.124 & 0.784 & 0.784 & 12.057 \\ FeedForward & 58.804 & 17.888 & 17.888 & 285.735 \\   

Table 2: Total parameter count of the used models on the same-size tasks benchmark proposed in Schwarzschild et al.  and the Thin-Maze environment, in the scale of millions of parameters.

  
**Model** & 1S-Maze & GoTo & Pong & DoorKey \\  & \((],129)\) & \((,128)\) & \((,128)\) & \((,128)\) \\  NeuralSolver & **100.00 \(\)0.00** & **100.00 \(\)0.00** & **100.00 \(\)0.00** & **100.00 \(\)0.00** \\ Bansal et al.  & 74.14 \(\)2.60 \(\) & 64.32 \(\)8.86 \(\) & 71.97 \(\)10.70 \(\) & 97.13 \(\)1.46 \(\) \\ FeedForward & 72.47 \(\)0.85 \(\) & 56.82 \(\)3.74 \(\) & 48.99 \(\)11.25 \(\) & 79.22 \(\)11.86 \(\) \\ Random & 29.74 \(\)0.41 \(\) & 29.46 \(\)0.40 \(\) & 37.87 \(\)0.47 \(\) & 29.52 \(\)0.58 \(\) \\   

Table 3: Extrapolation accuracy on the different-size tasks with training and evaluation sizes \((s_{t},s_{T})\). We employ curriculum learning to train all methods, with training sizes indicated in the table. Higher is better. All results are averaged over 10 randomly-selected seeds. We highlight the best average results. We use (\(\)) to indicate stochastic dominance (\(_{}=0\)) of NeuralSolver over the baseline.

against Bansal et al.  (3.15 million parameters) and a reduction of 99.6% against the FeedForward baseline (71.57 million parameters).

### Ablation Study

In Table 4 we perform an ablation study on the components of NeuralSolver, particularly on the role of: (i) the aggregation function, (ii) the depth of recurrent convolutional block, (iii) the training method and (iv) the type of recurrent layer in the convolutional block. For (i), we replace the global max-pooling layer of the processing module with an average-pooling layer (Use AvgPool). For (ii), we use 5 convolutional layers in the recurrent module (similar to Bansal et al. ) instead of the single convolutional layer (Use 5L). For (iii), we remove the curriculum-based training scheme (No CL). For (iv), we replace the LSTM with a ResNet block (No LSTM).

The results show that every component of NeuralSolver contributes to the overall extrapolation performance of the method. The use of an LSTM layer instead of a ResNet block in the recurrent convolutional module results in a significant improvement in performance. This result is aligned with previous works that have shown that gated-based recurrent neural networks empirically learn and generalize better than recurrent ResNets . The use of max pooling as the aggregation function results in better performance than average pooling. Removing curriculum learning also results in a decrease in extrapolation performance of the method in some tasks (e.g., GoTo), highlighting the need to consider multiple (small) image sizes to extract relevant information during the training procedure.

  
**Model** & 1S-Maze & GoTo & Pong & DoorKey \\  NeuralSolver & **100.00 \(\) 0.00** & **100.00 \(\) 0.00** & **100.00 \(\) 0.00** & **100.00 \(\) 0.00** \\ Use AvgPool & 81.96 \(\)28.50 \(\) & 97.00 \(\) 3.87 \(\) & 92.86 \(\)14.66 \(\) & 51.86 \(\)38.98 \(\) \\ Use 5L & 78.00 \(\) 5.73 \(\) & 84.16 \(\)16.39 \(\) & **100.00 \(\) 0.00** & 92.99 \(\) 7.62 \(\) \\ No CL & 95.26 \(\) 7.29 \(\) & 64.12 \(\)23.50 \(\) & **100.00 \(\) 0.00** & 97.23 \(\) 4.73 * \\ No LSTM & 81.87 \(\)10.09 \(\) & 67.28 \(\)14.51 \(\) & 76.12 \(\)17.63 \(\) & 93.68 \(\) 7.88 \(\) \\   

Table 4: Extrapolation accuracy of different ablated versions of NeuralSolver in the proposed different-size tasks. Higher is better. All results are averaged over 10 randomly-selected seeds. We highlight the best average results. We use (\(\)) to indicate stochastic dominance (\(_{}=0\)) and (*) to indicate almost stochastic dominance (\(_{}<0.5\)) of our default model over the ablated versions.

Figure 6: Training efficiency of NeuralSolver and Bansal et al.  on different-size tasks: we present the accuracy of the learned algorithms on extrapolating to problems with different dimensionality (columns). Each color represents a different training size, specific to each task, detailed in Appendix A.3. In the dashed line we show the upper-bound on the performance.

We also observe a performance gain in using a single convolutional layer over a module composed of five layers (as used in ), despite requiring five times more the number of iterations to compensate.

### NeuralSolver Allows Extrapolation on Sequential Decision-Making Tasks

We highlight the versatility of NeuralSolver by exploring visual imitation learning problems, in which, at each time-step, the algorithm is provided with an image of arbitrary size, and needs to output an action. These tasks can be solved through modern reinforcement learning methods . However, these methods lack the ability to _extrapolate_, i.e., are unable to learn algorithms (policies) on small problems, with lower-dimensional observations, and execute on larger problems, with higher-dimensional observations. We consider the DoorKey environment and train an imitation-learning policy algorithm using NeuralSolver with a dataset collected by a pretrained oracle agent. Subsequently, we employ the learned algorithm in the Minigrid DoorKey environment , directly as the agent's policy: at each time-step, mapping the observations of the agent (image of arbitrary size) into actions. We evaluate the performance of our method in extrapolating at execution time to larger observations against oracle policies specifically trained on each observation size.

The results in Table 5 highlight how NeuralSolver can achieve oracle-level performances in scenarios with larger observation sizes despite _never being trained on such conditions_. Moreover, the prior baselines struggle to maintain their performance for larger observations due to the accumulation of errors during task-execution, resulting in sub-optimal trajectories as shown in Figure 7.

## 6 Conclusion

We proposed NeuralSolver, a simple architecture that learns algorithms that can perform extrapolation across general tasks. We showed that our architecture consistently outperforms prior state-of-the-art recurrent solvers in regard to extrapolation performance, training efficiency and parameter efficiency. In future work, we plan on further improving the training efficiency of our method and explore it as an architecture for reinforcement learning to learn to perform sequential decision-making tasks in an online manner, while maintaining the ability to extrapolate.

  
**Model** & **20\(\)20** & **32\(\)32** & **64\(\)64** & **128\(\)128** \\  Oracle & 98.92 \(\)0.02 & 99.35 \(\) 0.01 & 99.69 \(\) 0.00 & 99.85 \(\) 0.00 \\  NeuralSolver & **98.82 \(\)0.26** & **99.12 \(\) 0.57** & **98.69 \(\) 2.44** & **98.02 \(\) 2.54** \\ Bansal et al.  & 98.47 \(\)0.48 * & 91.41 \(\)10.64 \(\) & 43.09 \(\)31.18 \(\) & 24.71 \(\)31.76 \(\) \\ FeedForward & 96.14 \(\)1.63 \(\) & 63.51 \(\) 7.63 \(\) & 23.53 \(\) 7.34 \(\) & 7.19 \(\) 3.18 \(\) \\   

Table 5: Average reward returns on the Minigrid Doorkey environment, with different sizes during execution. We show the average reward multiplied by \(10^{2}\). We employ curriculum learning with sizes (\(\)) to train all models. Higher is better. We highlight the best average results. We use (\(\)) to indicate stochastic dominance (\(_{}=0\)) and (*) to indicate almost stochastic dominance (\(_{}<0.5\)) of NeuralSolver over the baseline. All results are averaged over 10 randomly-selected seeds.

Figure 7: Example trajectories of the different methods when extrapolating to a Minigrid Doorkey environment with an image observation of size 64\(\)64. The trajectory of the agents follows the gradient of the line (from darker to brighter). Additional examples in Appendix F.