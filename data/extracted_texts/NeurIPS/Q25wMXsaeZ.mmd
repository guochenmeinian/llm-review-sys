# OneNet: Enhancing Time Series Forecasting Models

under Concept Drift by Online Ensembling

 Yi-Fan Zhang\({}^{1,2}\), Qingsong Wen\({}^{3}\), Xue Wang\({}^{3}\), Weiqi Chen\({}^{3}\), Liang Sun\({}^{3}\),

Zhang Zhang\({}^{1,2}\), Liang Wang\({}^{1,2}\), Rong Jin\({}^{3}\), Tieniu Tan\({}^{1,2}\)

\({}^{1}\)School of Artificial Intelligence, University of Chinese Academy of Sciences (UCAS)

\({}^{2}\) State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS), Institute of Automation

\({}^{3}\)Alibaba Group

Corresponding authorWork done at Alibaba Group, and now affiliated with Meta.

###### Abstract

Online updating of time series forecasting models aims to address the concept drifting problem by efficiently updating forecasting models based on streaming data. Many algorithms are designed for online time series forecasting, with some exploiting cross-variable dependency while others assume independence among variables. Given every data assumption has its own pros and cons in online time series modeling, we propose **O**nline **e**nsembling **N**etwork (OneNet). It dynamically updates and combines two models, with one focusing on modeling the dependency across the time dimension and the other on cross-variate dependency. Our method incorporates a reinforcement learning-based approach into the traditional online convex programming framework, allowing for the linear combination of the two models with dynamically adjusted weights. OneNet addresses the main shortcoming of classical online learning methods that tend to be slow in adapting to the concept drift. Empirical results show that OneNet reduces online forecasting error by more than \(\%\) compared to the State-Of-The-Art (SOTA) method. The code is available at https://github.com/yfzhang114/OneNet.

## 1 Introduction

In recent years, we have witnessed a significant increase in research efforts that apply deep learning to time series forecasting . Deep models have proven to perform exceptionally well not only in forecasting tasks, but also in representation learning, enabling the extraction of abstract representations that can be effectively transferred to downstream tasks such as classification and anomaly detection. However, existing studies have focused mainly on the batch learning setting, assuming that the entire training dataset is available beforehand, and the relationship between the input and output variables remains constant throughout the learning process. These approaches fall short in real-world applications where concepts are often not stable but change over time, known as concept drift , where future data exhibit patterns different from those observed in the past. In such cases, re-training the model from scratch could be time-consuming. Therefore, it is desirable to train the deep forecaster online, incrementally updating the forecasting model with new samples to capture the changing dynamics in the environment.

The real world setting, termed online forecasting, poses challenges such as high noisy gradients compared to offline mini-batch training , and continuous distribution shifts which can make the model learned from historical data less effective for the current prediction. While some studies have attempted to address the issues by designing advanced updating structures or learning objectives , they all rely on TCN backbones .

2018), which do not take advantage of more advanced network structures, such as transformer (Nie et al., 2023; Zhou et al., 2022b). Our studies show that the current transformer-based model, PatchTST (Nie et al., 2023), without any advanced adaption method of online learning, performs better than the SOTA online adaptation model FSNet (Pham et al., 2023), particularly for the challenging ECL task (Table.1). Furthermore, we find that variable independence is crucial for the robustness of PatchTST. Specifically, PatchTST focuses on modeling temporal dependency (cross-time dependency) and predicting each variable independently. To validate the effectiveness of the variable independence assumption, we designed Time-TCN, which convolves only on the temporal dimension. Time-TCN is better than FSNet, a state-of-the-art approach for online forecasting, and achieves significant gains compared to the commonly used TCN structure that convolves on variable dimensions.

Although variable independence enhances model robustness, the cross-variable dependency is also critical for forecasting, i.e. for a specific variable, information from associated series in other variables may improve forecasting results. As shown in Table 1 for datasets ETTm1 and ETTh2, cross-time forecasters tend to yield lower performance for datasets with a small number of variables. Surprisingly, existing models that are designed to leverage both cross-variable and cross-time dependencies such as CrossFormer (Zhang and Yan, 2023) and TS-Mixer (Chen et al., 2023), tend to perform worse than a native TCN. To investigate this phenomenon, we visualized the MSE at different time steps during the entire online adaptation process for both a Cross-Time model (Time-TCN) and a Cross-Variable model (TCN) in Figure 1. We observe a large fluctuation in MSE over online adaption, indicating a significant concept drift over time. We also observe that neither of these two methods performs consistently better than the other, indicating that neither of the two data assumptions holds true for the entire time series. This is why relying on a single model like CrossFormer cannot solve this problem. Existing work depends on a simple model, but for online time series forecasting, data preferences for model bias will continuously change with online concept drifts. Therefore, we need a data-dependent strategy to continuously change the model selection policy. In other words, **online time series forecasting should go beyond parameter updating**.

In this paper, we address the limitation of a single model for online time series forecasting by introducing an ensemble of models that share different data biases. We then learn to dynamically combine the forecasts from individual models for better prediction. By allowing each model to be trained and online updated independently, we can take the best out of each online model; by dynamically

    &  &  &  &  &  \\   & & TCN & FSNet & Time-TCN & DLinear & PatchTST & CrossFormer & TS-Mixer & Fedformer & \\  ETH2 & \(7\) & 0.910 & 0.846 & 1.307 & 6.910 & 2.716 & 5.772 & 3.060 & 1.620 & 0.609 \\ ETTm1 & \(7\) & 0.250 & 0.127 & 0.308 & 1.120 & 0.553 & 0.370 & 0.660 & 0.516 & 0.108 \\ WTH & \(21\) & 0.348 & 0.223 & 0.308 & 0.541 & 0.465 & 0.317 & 0.482 & 0.372 & 0.200 \\ ECL & \(321\) & 0.800 & 7.034 & 5.230 & 7.388 & 5.030 & 04.790 & 5.764 & 27.640 & 2.201 \\   

Table 1: **A motivating example for online ensembling, where the reported metric is MSE and forecast horizon length is set as \(48\). Cells are colored on the basis of the MSE value, from low (red) to medium (white) to high (blue). Columns titled cross-variable refer to methods that focus on modeling cross-variable dependence, and columns titled cross-time refer to methods that only exploit the temporal dependence and assume independence among covariates. All methods use the same training and online adaptation strategy.**

Figure 1: **A motivating example for online ensembling, where the reported metric is MSE and forecast horizon length is set to \(48\) during online adaptation. Cross-Time refers to a TCN backbone that assumes independence among covariates and only models the temporal dependence, and cross-variable refers to a TCN backbone that takes into cross-variable dependence.**

adjusting the combination of different models, we can take the best out of the entire model ensemble. We refer to our approach as Online Ensembling Network or **OneNet** for short. More concretely, OneNet maintains two online forecasting models, one focused on modeling temporal correlation and one focused on modeling cross-variable dependency. Each model is trained independently using the same set of training data. During testing, a reinforcement learning (RL) based approach is developed to dynamically adjust the weights used to combine the predictions of the two models. Compared to classical online learning methods such as Exponentiated Gradient Descent, our RL-based approach is more efficient in adapting to the changes/drifts in concepts, leading to better performance. The contributions of this paper are:

1. We introduce OneNet, a two-stream architecture for online time series forecasting that integrates the outputs of two models using online convex programming. OneNet leverages the robustness of the variable-independent model in handling concept drift, while also capturing the inter-dependencies among different variables to enhance forecasting accuracy. Furthermore, we propose an RL-based online learning approach to mitigate the limitations of traditional OCP algorithms and demonstrate its efficacy through empirical and theoretical analyses.

2. Our empirical studies with four datasets show that compared with state-of-the-art methods, OneNet reduces the average cumulative mean-squared errors (MSE) by \(53.1\%\) and mean-absolute errors (MAE) by \(34.5\%\). In particular, the performance gain on challenging dataset ECL is superior, where the MSE is reduced by \(59.2\%\) and MAE is reduced by \(63.0\%\).

3. We conducted comprehensive empirical studies to investigate how commonly used design choices for forecasting models, such as instance normalization, variable independence, seasonal-trend decomposition, and frequency domain augmentation, impact the model's robustness. In addition, we systematically compared the robustness of existing Transformer-based models, TCN-based models, and MLP-based models when faced with concept drift.

## 2 Preliminary and Related Work

**Concept drift.** Concepts in the real world are often dynamic and can change over time, which is especially true for scenarios like weather prediction and customer preferences. Because of unknown changes in the underlying data distribution, models learned from historical data may become inconsistent with new data, thus requiring regular updates to maintain accuracy. This phenomenon, known as concept drift (Tsymbal, 2004), adds complexity to the process of learning a model from data. In this paper, we focus on online learning for time series forecasting. Unlike most existing studies for online time series forecasting (Li et al., 2022; Qin et al., 2022; Pham et al., 2023) that only focus on how to online update their models, this work goes beyond parameter updating and introduces multiple models and a learnable ensembling weight, yielding rich and flexible hypothesis space. Due to the space limit, more related works about time series forecasting and reinforcement learning are left in the appendix.

**Online time series forecasting: streaming data.** Traditional time series forecasting tasks have a collection of multivariate time series with a look-back window \(L\): \((_{i})_{i=1}^{L}\), where each \(_{i}\) is \(M\)-channel vector \(_{i}=(x_{i}^{j})_{j=1}^{M}\). Given a forecast horizon \(H\), the target is to forecast \(H\) future values \((_{i})_{i=L+1}^{L+H}\). In real-world applications, the model builds on the historical data needs to forecast the future data, that is, given time offset \(K^{}>L\), and \((_{i})_{i=K^{}-L+1}^{K^{}}\), the model needs to forecast \(()_{i=K^{}+1}^{K^{}+H}\). Online time series forecasting (Anava et al., 2013; Liu et al., 2016; Pham et al., 2023) is a widely used technique in real-world due to the sequential nature of the data and the frequent drift of concepts. In this approach, the learning process takes place over a sequence of rounds, where the model receives a look-back window and predicts the forecast window. The true values are then revealed to improve the model's performance in the next rounds. When we perform online adaptation, the model is retrained using the online data stream with the MSE loss over each channel: \(=_{j=1}^{M}_{K^{}+1:K^{}+ H}^{j}-x_{K^{}+1:K^{}+H}^{j}\).

**Variable-independent time series forecasting.** The traditional cross-variable strategy used in most structures takes the vector of all time series features as input and projects it into the embedding space to mix the information. On the contrary, PatchTST (Nie et al., 2023) adopts a variable-independent approach, where each input token only contains information from a single channel/variable. Our research demonstrates that variable independence is crucial for boosting model robustness under concept drift. For multivariate time series samples \((x_{i}^{j})_{i=1}^{L}\), each channel \(j\) is fed into the model independently, and the forecaster produces prediction results \((x_{i}^{j})_{i=L+1}^{L+H}\) accordingly. As shown in Table 1, cross-variable methods tend to overfit when the dataset has a large number of variables, resulting in poor performance. This is evident in the poor performance of the SOTA online adaptation model FSNet (Pham et al., 2023) in the ECL dataset. However, models that lack cross-variable information perform worse on datasets with a small number of variables where cross-variable dependency can be essential. Although some existing work has attempted to incorporate both cross-variable interaction and temporal dependency into a single framework, our experiments show that these models are fragile under concept drift and perform no better than the proposed simple baseline, Time-TCN. To address this, we propose a novel approach that trains two separate branches, each focusing on modeling temporal and cross-variable dependencies, respectively. We then combine the results of these branches to achieve better forecasting performance under concept drift. We first introduce the OCP block for coherence.

## 3 OneNet: Ensemble Learning for Online Time Series Forecasting

We first examine online learning methods to dynamically adjust combination weights used by ensemble learning. We then present OneNet, an ensemble learning framework for online time series forecasting.

### Learning the best expert by Online Convex Programming (OCP)

For notation clarity, here we denote \(^{L M}\) as the historical data, \(^{H M}\) as the forecast target. Our current method involves the integration of multiple complementary models. Therefore, how to better integrate model predictions in the online learning setting is an important issue. Exponentiated Gradient Descent (EGD) (Hill and Williamson, 2001) is a commonly used method. Specifically, the decision space \(\) is a \(d\)-dimensional simplex, i.e. \(=\{_{t}|w_{t,i} 0_{t} _{1}=1\}\), where \(t\) is the time step indicator and we omit the subscript \(t\) for simplicity when it's not confusing. Given the online data stream \(\), its forecasting target \(\), and \(d\) forecasting experts with different parameters \(=[}_{i}=f_{i}()]_{i=1}^{d}\), the player's goal is to minimize the forecasting error as

\[_{}():=_{i=1}^{d}w_{i}f_{i}( )-^{2}; s.t..\] (1)

Figure 2: (a) OneNet processes multivariate data through cross-time and cross-variable branches, each responsible for capturing different aspects. The weights of these two branches are generated by the OCP block, and only the **black** arrows require execution during training. (b) The OCP block produces ensembling weights by utilizing both the long-term history of exponential gradient descent (EGD) and the short-term history of offline reinforcement learning (RL).

According to EGD, choosing \(_{1}=[w_{1,i}=1/d]_{i=1}^{d}\) as the center point of the simplex and denoting \(_{t,i}\) as the loss of \(f_{i}\) at time step \(t\), the updating rule for each \(w_{i}\) will be

\[w_{t+1,i}=(- f_{i}()- ^{2})}{Z_{t}}=(-_{t,i})}{Z_{t}}\] (2)

where \(Z_{t}=_{i=1}^{d}w_{t,i}(- l_{t,i})\) is the normalizer, and the algorithm has a regret bound:

**Proposition 1**.: _(**Online Convex Programming Bound**) For \(T>2(d)\), denote the regret for time step \(t=1,,T\) as \(R(T)\), set \(=\), the OCP updating policy have an **External regret** (See appendix B.1 for proof and analysis.)_

\[_{t=1}^{T}(_{t})-_{}_{t=1}^{T} ()_{t=1}^{T}_{i=1}^{d}w_{t,i} f_{i} ()-^{2}-_{}_{t=1}^{T}()\] (3)

That is, the exponentially weighted average forecaster guarantees that the forecaster's cumulative expected loss is not much larger than the cumulative loss of the best decision. However, an exponentially weighted average forecaster is widely known to respond very slowly to drastic changes in the distribution (Cesa-Bianchi and Lugosi, 2006). This phenomenon is sometimes referred to as the **"slow switch phenomenon"** in online learning literature, and is further illustrated in Figure 3 where the loss for \(f_{1}\) is 0 for the first 50 trials and 1 for the next 50 trials. The performance of \(f_{2}\) is the opposite. When the step size \(\) is small (e.g., \(=0.01\)), small changes are made to the weights and no clear adaptation takes place. When a large step size \(\) is applied (e.g., \(=1\)), we observe that the EGD algorithm quickly adapts to the environment change for the first \(50\) trials by increasing weight \(w_{1}\) to almost \(1\) in the first few iterations. But it takes many iterations for the EGD algorithm to adapt to the change in the next \(50\) iterations, where \(f_{2}\) works much better than \(f_{1}\). We finally note that no matter how we adjust the step size \(\), the EGD algorithm has to suffer from the trade-off between speed of switching and overall good performance throughout the horizon.

Although few algorithms have been developed to address this issue in online learning (Stoltz and Lugosi, 2005; Cesa-Bianchi and Lugosi, 2003; Blum and Mansour, 2007; Foster and Vohra, 1998), the key idea is to find an activation function that maps the original policy \(_{t}\) to a new one based on the recent loss of all experts. Despite the efforts, very limited successes have been achieved, either empirically or theoretically. In this work, we observe in our experiments that the combination weights \(\) generated by the EGD algorithm are based on historical performance over a long period of time and thus cannot adapt quickly to transient environment changes. Hence, it is better to effectively incorporate both long-term historical information and more recent changes in the environment. A straightforward idea is to re-initialize the weight \(\) per \(K\) steps. We show that such a simple algorithm can achieve a tighter bound:

**Proposition 2**.: _(**Informal**) Denote \(I=[l,,r][1,,T]\) as any period of time. We then have, the \(K\)-step re-initialize algorithm has a tighter regret bound compared to EGD at any small interval \(I\), where \(|I|<T^{}\). (See appendix B.2 for proof.)_

Proposition 2 stresses that, by considering short-term information, we can attain lower regret in short time intervals. Such a simple strategy still struggles with the hyper-parameter choice of \(K\). Besides, discarding long-term information makes the algorithm inferior to EGD for a long period of the online learning process. In this work, we address this challenge of online learning by exploiting offline reinforcement learning (Levine et al., 2020). At first, we use EGD to maintain long-term weight \(\). Besides, we introduce a different set of weights \(\) that can better capture the recent performance of individual models. By combining \(\) and \(\), our approach can effectively incorporate both long-term historical information and more recent changes in the environment.

Specifically, we adopt the RvS (Emmons et al., 2022) framework, which formulates reinforcement learning through supervised learning, as shown in Figure 2(b). At time step \(t\), our target is to learn

Figure 3: **The evolution of the weight assigned to \(f_{1}\)** where the losses for forecasters vary across the first regime \(\) and the second regime \(\).

a short-term weight conditioned on the long-term weight \(\) and experts' performances during a short period of history \(I=[l,t]\). For simplicity and computation efficiency, we just let \(l=t-1\). The agent then chooses actions using a policy \(_{_{rl}}(_{t}|\{\{_{t,i}_{i}\}_{i=1}^ {d}\}_{t I};)\) parameterized by \(_{rl}\). During training, we concatenate the product between each prediction and expert weight \((w_{t,i}*}_{i})\) with the outcome \(\) as the conditional input. We follow RvS [Emmons et al., 2022] to implement the policy network as a two-layer MLPs \(f_{rl}:^{H M(d+1)}^{d}\). Then the short-term weight and final ensembling weight will be:

\[_{t}=f_{rl}(w_{t,1}}_{1} w _{t,d}}_{d})_{t,i}=(w_{t,i}+b_{t,i})/(_{i=1}^{d}(w_{t,i}+b_{t,i}))\] (4)

However, unlike in RvS, we cannot train the decision network through simple classification tasks since the ground truth target action is inaccessible. Instead, we propose to train the network by minimizing the forecasting error incurred by the new weight, that is, \(_{_{rl}}(}):=_{i=1}^{d} _{t,i}f_{i}()-^{2}\). During inference, as concept drift changes gradually, we use \(_{t-1}+_{t-1}\) to generate the prediction and train the networks after the ground truth outcome is observed. We theoretically and empirically verify the effectiveness of the proposed OCP block in appendix B.4.

### OneNet: utilizing the advantages of both structures

The model structure is shown in Figure 2(a) and we introduce the components as follows:

**Two-stream forecasters.** The input multivariate time series data is fed into two separate forecasters, a cross-time forecaster \(f_{1}\) and a cross-variable forecaster \(f_{2}\). Each forecaster contains an encoder and a prediction head. Assuming that the hidden dimension of the models are all \(d_{m}\), the encoder of \(f_{1}\) projects the input series to representation \(z_{1}^{M d_{m}}\), and the prediction head generates the final forecasting results: \(}_{1}^{M H}\). For the cross-variable forecaster \(f_{2}\), the encoder projects \(\) to \(_{2}^{L d_{m}}\). Then, the representation of the last time step \(_{2,L}^{d_{m}}\) is selected and fed into the prediction head to generate the final forecasting results \(}_{2}^{M H}\). Compared to \(f_{1}\), whose projection head has a parameter of \(d_{m} H\), the projection head of \(f_{2}\) has a parameter of \(d_{m} M H\), which is heavier, especially when \(M\) is large. Additionally, while \(f_{1}\) ignores variable dependency, \(f_{2}\) simply selects the representation of the last time step time series, ignoring temporal dependency. These two modules yield different but complementary inductive biases for forecasting tasks. _OCP block is then used for learning the best combination weights._ Specifically, we use EGD to update a weight \(w_{i}\) for each forecaster and use offline-reinforcement learning to learn an additional short-term weight \(b_{i}\), the final combination weight for one forecaster will be \(w_{i} w_{i}+b_{i}\). Considering the difference between variables, we further construct different weights for each variable, namely, we will have \(^{M 2}\) combination weights.

**Decoupled training strategy.** A straightforward training strategy for OneNet is to minimize \((w_{1}*_{1}}+w_{2}*_{2}},)\) for both the OCP block and the two forecasters, where \(w_{i}\) here denotes the weight with the additional bias term. However, the coupled training strategy has a fatal flaw: considering an extreme case where \(f_{1}\) always performs much better than \(f_{2}\), then \(w_{1}\) will be close to \(1\) and \(w_{2} 0\). In this case, \(_{_{2}}}(w_{1}*_{1}}+w_{2}* _{2}},) 0\), that is, \(f_{2}\) is probably not trained for a long time. Under the context of concept drift, if retraining is not applied, as time goes on, the performance of \(f_{2}\) will become much inferior. In this paper, therefore, we decouple the training process of the OCP block and the two forecasters. Specifically, the two forecasters is trained by \((_{1}},)+(_{2 }},)\) and the OCP block is trained by \((w_{1}*_{1}}+w_{2}*_{2}},)\).

**Remark** Note that OneNet is complementary to advanced architectures for time series forecasting and online adaption methods under concept drift. A stronger backbone or better adaptation strategies/structure can both enhance performance.

## 4 Experiments

In this section, we will show that (1) the proposed OneNet attains superior forecasting performances with only a simple retraining strategy (reduce more than \(50\%\) MSE compared to the previous SOTA model); (2) OneNet achieves faster and better convergence than other methods; (3) we conduct thorough ablation studies and analysis to reveal the importance of each of design choices of current advanced forecasting models. Finally, we introduce a variant of OneNet, called OneNet-, which has significantly fewer parameters but still outperforms the previous SOTA model by a large margin. Due to space limitations, some experimental settings and results are provided in the appendix.

### Experimental setting

**Baselines of adaptation methods** We evaluate several baselines for our experiments, including methods for continual learning, time series forecasting, and online learning. Our first baseline is OnlineTCN (Zinkevich, 2003), which continuously trains the model without any specific strategy. The second baseline is Experience Replay (ER) (Chaudhry et al., 2019), where previous data is stored in a buffer and interleaved with newer samples during learning. Additionally, we consider three advanced variants of ER: TFCL (Aljundi et al., 2019), which uses a task-boundary detection mechanism and a knowledge consolidation strategy; MIR (Aljundi et al., 2019), which selects samples that cause the most forgetting; and DER++ (Buzzega et al., 2020), which incorporates a knowledge distillation strategy. It is worth noting that ER and its variants are strong baselines in the online setting, as we leverage mini-batches during training to reduce noise from single samples and achieve faster and better convergence. Finally, we compare our method to FSNet (Pham et al., 2023), which is the previous state-of-the-art online adaptation method. Considering different model structures, we compare the performance under concept drift of various structures, including TCN (Bai et al., 2018), Informer (Zhou et al., 2021), FEDformer (Zhou et al., 2022), PatchTST (Nie et al., 2023), Dlinear (Zeng et al., 2023), Nlinear (Zeng et al., 2023), TS-Mixer (Chen et al., 2023).

**Strong ensembling baselines.** To verify the effectiveness of the proposed OCP block, we compare it with several ensembling baselines. Given the online inputs \(\), predictions of each expert \(_{1}}\), \(_{2}}\), and the ground truth outcome \(\), the final outcome \(}\) of different baselines will be as follows: (1)

**Simple averaging**: we simply average the predictions of both experts to get the final prediction, i.e., \(}=(_{1}}+_{2}})\). (2) **Gating mechanism**Liu et al. (2021): we learn weights to the output of each forecaster, that is, \(h=Concat(},})+;w_{1},w_{2}=softmax(h)\), and the final result is given by \(}=w_{1}*}+w_{2}*}\). (3) **Mixture-of-experts**Jacobs et al. (1991); Shazeer et al. (2017): we use the mixture of experts approach, where we first learn the weights \(w_{1}\) and \(w_{2}\) by applying a softmax function on a linear combination of the input, i.e., \(h=+;w_{1},w_{2}=softmax(h)\), and then we obtain the final prediction by combining the predictions of both experts as \(}=w_{1}*}+w_{2}*}\). (4) **Linear Regression (LR)**: we use a simple linear regression model to obtain the optimal weights, i.e., \([w_{1},w_{2}]=(X^{T}X)^{-1}X^{T}y\), where \(X=[_{1}},_{2}}]\) and \(y\) is the ground truth outcome. (5) **Exponentiated Gradient Descent (EGD)**: we use EGD to update the weights \(w_{1}\) and \(w_{2}\) separately without the additional bias. (6) **Reinforcement learning to learn the weight directly (RL-W)**: we use the bias term in the OCP block to update the weights based on the predictions of both experts and the ground truth outcome, i.e., the weight is only dependent on \(_{1}}\), \(_{2}}\), and \(\), but not on the historical performance of each expert. For all baselines with trainable parameters, the training procedure is just the same as the proposed OCP block.

### Online forecasting results

**Cumulative performance** Table.2 and Table.3 present the cumulative performance of different baselines in terms of mean-squared errors (MSE) and mean-absolute errors (MAE). In particular, Time-TCN and PatchTST exhibit strong performance and outperform the previous state-of-the-art model, FSNet (Pham et al., 2023). The proposed OneNet-TCN (online ensembling of TCN and Time

    &  &  &  &  \\  & 1 & 24 & 48 & 1 & 24 & 48 & 1 & 24 & 48 & 1 & 24 & 48 & Avg \\   Informer & 7.571 & 4.629 & 5.692 & 0.456 & 0.478 & 0.388 & 0.426 & 0.380 & 0.367 & - & - & 2.265 \\ OnlineTCN & 0.502 & 0.830 & 1.183 & 0.214 & 0.258 & 0.283 & 0.206 & 0.308 & 0.302 & 3.309 & 11.339 & 11.534 & 2.522 \\ TFCL & 0.557 & 0.846 & 1.208 & 0.087 & 0.211 & 0.236 & 0.177 & 0.301 & 0.323 & 2.732 & 12.094 & 12.110 & 2.574 \\ ER & 0.508 & 0.808 & 1.136 & 0.086 & 0.202 & 0.220 & 0.180 & 0.293 & 0.297 & 2.579 & 9.327 & 9.685 & 2.110 \\ MIR & 0.486 & 0.812 & 1.103 & 0.085 & 0.192 & 0.210 & 0.179 & 0.291 & 0.297 & 2.575 & 9.265 & 9.411 & 2.076 \\ DER++ & 0.508 & 0.828 & 1.157 & 0.083 & 0.196 & 0.208 & 0.174 & 0.287 & 0.294 & 2.657 & 8.996 & 9.009 & 2.033 \\ FSNet & 0.466 & 0.687 & 0.846 & 0.085 & 0.115 & 0.127 & 0.162 & 0.188 & 0.223 & 3.143 & 6.051 & 7.034 & 1.594 \\  Time-TCN & 0.491 & 0.779 & 1.307 & 0.093 & 0.281 & 0.308 & 0.158 & 0.311 & 0.308 & 4.060 & 5.260 & 5.230 & 1.549 \\ PatchTST & 0.362 & 1.622 & 2.716 & 0.083 & 0.427 & 0.553 & 0.162 & 0.372 & 0.465 & 2.022 & 4.325 & 5.030 & 1.512 \\  OneNet-TCN & 0.411 & 0.772 & 0.806 & 0.082 & 0.212 & 0.223 & 0.171 & 0.293 & 0.310 & 2.470 & 4.713 & 4.567 & 1.253 \\ OneNet & **0.380** & **0.532** & **0.609** & **0.082** & **0.098** & **0.108** & **0.156** & **0.175** & **0.200** & **2.351** & **2.074** & **2.201** & **0.747** \\   

Table 2: **MSE of various adaptation methods**. H: forecast horizon. OneNet-TCN is the mixture of TCN and Time-TCN, and OneNet is the mixture of FSNet and Time-FSNet.

[MISSING_PAGE_FAIL:8]

effect, regardless of whether the model is adapted online or not. Instances normalization is commonly used to mitigate the distribution shift between training and testing data, which is crucial for model robustness when online adaptation is impossible. However, when online adaptation is performed, the influence of instance normalization is reduced. Interestingly, our experiments reveal that _instance normalization impedes the model adaptation process in EITH2, EITm1, and WTH datasets when the forecast horizon is long (24 or 48)_. Thus, simply normalizing time series with zero mean and unit standard deviation may not be the optimal approach under concept drift. Ablation studies of the variable independence and frequency domain augmentation are detailed in the appendix.

**Delve deep into parameter-efficient online adaptation.** Although OneNet significantly reduces the forecasting error, it also increases the number of parameters and inference time due to its two-stream framework. We also design a variant of OneNet that may have slightly lower performance than OneNet, but with fewer parameters, making it more suitable for lightweight applications, denoted by OneNet-. Specifically, we ensemble PatchTST and Time-FSNet, which are both variable-independent. In this case, denote \(_{1},_{2}\) as the generated features for one variable from two branches, we concatenate the two features and feed them into the projection head, which further avoids the offline reinforcement learning block for ensembling weight learning and reduces the parameters. For example, in the ECL dataset, the hidden dimension FSNet  is \(320\), and the sequences have \(321\) channels. When the forecast horizon is \(48\), the projection head consists of just one linear layer with \(320 321 48=4,930,560\) parameters. On the contrary, the concatenated features of OneNet- are always less than \(1024\) dimension, resulting in a final projection head with less than \(1024 48=49,152\) parameters. Figure 4(a) shows a detailed comparison of different methods on the ECL dataset. For small forecast horizons, all methods have a comparable number of parameters. As the forecast horizon increases, the number of parameters of existing adaptation methods increases rapidly. On the contrary, the number of parameters of OneNet- remains insensitive to the forecast horizon and is always less than all baselines. The performance of OneNet- is shown in Table 12, which is much better than FSNet but achieves fewer parameters.

See the appendix for the comparison of different forecasting models and more numerical results such as detailed ablation studies of different hyper-parameters and adaptation results under more settings.

Figure 4: **Visualizing the model’s prediction and parameters during online learning.** (a) Number of parameters for different models on the ECL dataset with different forecast horizons. We concentrate on a short 50-time step horizon, starting from \(t=2500\). (b), and (c) depict the model’s prediction results for the first and second channels of the ECL dataset.

    &  &  &  &  &  \\ Online & Inv & Decomp & 1 & 24 & 48 & 1 & 24 & 48 & 1 & 24 & 48 & 1 & 24 & 48 & Avg \\   & ✓ & ✗ & **0.360** & 1.625 & 2.670 & **0.083** & 0.436 & 0.555 & **0.161** & 0.370 & 0.464 & **1.988** & 4.345 & 5.060 & **1.510** \\ ✓ & ✗ & ✓ & 0.380 & 1.492 & 3.060 & 0.084 & 0.427 & **0.463** & 0.164 & 0.358 & **0.421** & 2.510 & 5.320 & 6.280 & 1.747 \\  & ✓ & ✓ & 0.362 & 1.622 & 2.716 & **0.083** & 0.427 & 0.553 & 0.162 & 0.372 & 0.465 & 2.022 & **4.325** & **5.030** & 1.512 \\  & ✗ & ✗ & 0.392 & **1.450** & **2.630** & 0.084 & **0.416** & 0.487 & 0.163 & **0.357** & 0.431 & 2.617 & 5.557 & 5.655 & 1.687 \\   & ✓ & ✗ & 0.397 & 2.090 & 3.156 & 0.084 & 0.448 & 0.553 & 0.161 & 0.372 & 0.467 & 2.000 & 4.398 & 5.100 & 1.602 \\ ✗ & ✗ & ✓ & 0.674 & 3.100 & 4.510 & 0.086 & 0.462 & 0.686 & 0.165 & 0.362 & 0.443 & 3.900 & 11.340 & 21.540 & 3.939 \\  & ✓ & ✓ & 0.427 & 2.090 & 3.290 & **0.083** & 0.433 & 0.570 & 0.163 & 0.375 & 0.467 & 2.030 & 4.395 & 5.101 & 1.619 \\  & ✗ & ✗ & 0.723 & 3.030 & 6.300 & 0.085 & 0.451 & 0.559 & 0.164 & 0.361 & 0.439 & 3.540 & 14.170 & 18.680 & 4.042 \\   

Table 5: **Ablation studies of the instances normalization (inv) and seasonal-trend decomposition (Decomp) of non-adapted PatchTST and online adapted PatchTST, where the metric is MSE.**Conclusion and Future Work

Through our investigation into the behavior of advanced forecasting models with concept drift, we discover that cross-time models exhibit greater robustness when the number of variables is large, but are inferior to models that can model variable dependency when the number of variables is small. In addition, this problem becomes more challenging due to the occurrence of concept drift, as the data preferences for both model biases are dynamically changing throughout the entire online forecasting process, making it difficult for a single model to overcome. To this end, we propose the OneNet model, which takes advantage of the strengths of both models through OCP. In addition, we propose to learn an additional short-term weight through offline reinforcement learning to mitigate the slow switch phenomenon commonly observed in traditional policy learning algorithms. Our extensive experiments demonstrate that OneNet is able to effectively deal with various types of concept drifts and outperforms previous methods in terms of forecasting performance.

We also discover that instance normalization enhances model robustness under concept drift, but can impede the model's ability to quickly adapt to new distributions in certain scenarios. This prompts further exploration of whether there exists a normalization technique that can mitigate distribution shifts while enabling rapid adaptation to changing concepts. In addition, although we design a lightened version of OneNet to address the problem of introducing additional parameters and inference time, there is potential for more efficient adaptation methods, such as utilizing prompts and efficient tuning methods from the NLP/CV community, to avoid retraining the full model.