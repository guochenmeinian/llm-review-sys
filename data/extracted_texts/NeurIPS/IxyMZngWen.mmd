# Latent Diffusion Model for DNA Sequence Generation

Zehui Li

Imperial College London

zehui.li22@imperial.ac.uk

&Yuhao Ni

Imperial College London

harry.ni21@imperial.ac.uk

Equal contribution.

Tim August B. Huygelen

University College London

thuygelen@gmail.com

&Akashaditya Das

Imperial College London

akashaditya.das13@imperial.ac.uk

&Guoxuan Xia

Imperial College London

g.xia21@imperial.ac.uk

&Guy-Bart Stan

Imperial College London

g.stan@imperial.ac.uk

&Yiren Zhao

Imperial College London

a.zhao@imperial.ac.uk

###### Abstract

The harnessing of machine learning, especially deep generative models, has opened up promising avenues in the field of synthetic DNA sequence generation. Whilst Generative Adversarial Networks (GANs) have gained traction for this application, they often face issues such as limited sample diversity and mode collapse. On the other hand, Diffusion Models are a promising new class of generative models that are not burdened with these problems, enabling them to reach the state-of-the-art in domains such as image generation. In light of this, we propose a novel _latent diffusion_ model, DiscDiff, tailored for discrete DNA sequence generation. By simply embedding discrete DNA sequences into a continuous latent space using an autoencoder, we are able to leverage the powerful generative abilities of continuous diffusion models for the generation of discrete data. Additionally, we introduce Frechet Reconstruction Distance (FReD) as a new metric to measure the sample quality of DNA sequence generations. Our DiscDiff model demonstrates an ability to generate synthetic DNA sequences that align closely with real DNA in terms of Motif Distribution, Latent Embedding Distribution (FReD), and Chromatin Profiles. Additionally, we contribute a comprehensive cross-species dataset of 150K unique promoter-gene sequences from 15 species, enriching resources for future generative modelling in genomics. We have made our code and data publicly available at https://github.com/Zehui127/Latent-DNA-Diffusion.

## 1 Introduction

Designing synthetic DNA sequences for genetic modifications is traditionally guided by organism-specific workflows derived from extensive laboratory experiments. As the amount of data generates from these workflows expand, deep generative models are well-positioned to enable a new frontier in synthetic DNA sequence generation over a wide range of potential applications [12; 37]. Generative adversarial networks (GANs)  are a popular choice for the generation of synthetic DNA sequences, as demonstrated by the studies of [18; 34; 37]. GANs can effectively generate sequences, however, it has been shown that the generated samples lack diversity  and suffer from mode collapse at training time .

Given the success of diffusion models in image generation , protein synthesis , and circuit design . The application of diffusion models for DNA sequence generation may generate sequences of higher quality. In this case, quality is a combination of sequence diversity and the ability to capture the underlying distribution/motifs. In this paper, we propose a latent diffusion model for discrete data generation and apply it to DNA sequence generation. Our contributions are as follows:

A generalisable framework for discrete data generation:We propose a latent diffusion model made from a transformation function and a denoising model. It separates the learning of latent distribution and the denoising model. A lightweight Variational Auto-encoder architecture is used for the transformation function for 1-dimensional discrete sequences.

A generative model for DNA Sequence Generation:We apply the proposed latent diffusion model to DNA sequence generation, obtaining promoter-gene samples with the properties of realistic DNA sequences across different species.

An evaluation metric for generated DNA sequences:We introduce Frechet Reconstruction Distance (FReD) as a numerical metric to evaluate the quality of the generated DNA sequences. FReD is consistent with motif distribution, the standard qualitative approach to evaluate the generated DNA sequences.

A cross-species dataset for DNA sequence generation:We curate and create a dataset containing 150K unique promoter-gene sequences across 15 species. This dataset paves the way for the construction of a generative model for promoter sequences

## 2 Background

Diffusion ModelsIntuitively, Diffusion Models (DMs) incrementally construct realistic examples from sampled noise. At each time step \(t\), a denoising function is used to predict a more realistic example \(x_{t-1}\) from \(x_{t}\). An alternative perspective by Song et al.  uses stochastic differential equations (SDE) to describe the diffusion models. This unifies previous scored-based models  and DDPM , providing a powerful formulation for analyzing DMs.

In , the process of adding noises is modelled with an SDE with a Wiener process:

\[x=f(x,t)\,t+g(t)\,w\] (1)

Figure 1: **Denoising View of Latent Diffusion Models for DNA sequences.** (a) A zoom-in view of the inference process. (b) A zoom-in view of the training process. The blue square represents the noises attached to the latent representation of the DNA sequences.

* The function \(f\) is called the drift coefficient. This indicates how the process \(x\) tends to evolve over time, ignoring any random fluctuations. Multiplying by \(t\) scales the drift by the time increment.
* \(g(t)\) is called the diffusion coefficient. It measures the volatility or variability of the process. It only depends on time \(t\).
* \(w\) represents the increment of the standard Wiener process (or Brownian motion) \(w\) over an infinitesimally small time interval.

The reverse process, which generates the realistic samples, can be represented by another SDE:

\[x=[f(x,t)-g(t)^{2}_{x} p_{t}(x)]\,t+g(t)\; \] (2)

Where \(\) represents the increment of the reverse Wiener process. \(_{x} p_{t}(x)\) is the gradient of the log Probability Density Function (PDF) of \(x\) at time \(t\). At the training time, a score function \(_{}(x(t),t)\) is trained to approximate \(_{x} p_{t}(x)\); and then realistic samples can be generated by walking through Equation (2).

Diffusion Models for Discrete DataThere are two reasons why standard DMs cannot deal with discrete data (\(x\)): 1) the diffusion process with the Wiener process defined by Equation (1) is described in terms of continuous variables, it is undefined when \(x\) is discrete. 2) the solution led by the reverse process requires a differentiable PDF \( p_{t}(x)\) to exist, but discrete variable \(x\) does not have a PDF.

To account for these challenges, two possible solutions can be used to develop DMs for discrete data. They are 1) define a diffusion-like process to model discrete data [1; 3; 32]. 2) map the discrete input into a continuous latent space [9; 13; 19]. For more details, see Appendix A.

Differing from the prior work on latent DMs for discrete data [9; 33], which is trained in an end-to-end manner, we aim to separate learning of the mapping from discrete to the latent space and score function. This facilitates the learning task by not learning the latent distribution and score-based denoising model at the same time. It also removes the need to adjust the weight of reconstruction and generation in the end-to-end training .

## 3 DiscDiff: A Latent Diffusion Model for Discrete Data

We introduce DiscDiff, a flexible latent diffusion model designed for discrete data generation. This model is structured into two main components: a transformation function and a denoising model. The transformation function is implemented with a lightweight Variational-Auto-Encoder (VAE), with an encoder \(z=(x)\), which translates discrete input \(x\) to a continuous latent variable \(z\), and a decoder \(=(z)\), which reverts \(z\) back to its discrete form \(\). The denoising model \(_{}(z(t),t)\) is employed to learn the score function \(_{z} p_{t}(z)\) for the latent variable.

In the training process, the learning phases of the transformation function and the denoising model are separated. The first phase focuses on learning the transformation function \(=((x))\), with a primary goal of minimising the reconstruction loss for discrete variable \(x\). The second phase concentrates on training the score function estimator, aiming to minimise the difference between the estimator and \(_{z} p_{t}(z)\).

### Transformation Function

ArchitectureIn order to map discrete DNA data to continuous space, we employed a lightweight Variational Autoencoder (VAE) that employs a transformation function composed of Convolutional Neural Networks (CNNs). The structure of the VAE is depicted in Figure 2, illustrating how the latent variable is modelled with a multivariate Gaussian distribution. The discrete input passes through the encoder, through multiple layers designed to increase the channel dimension while reducing the length dimension. Next, a Conv2D block is used to extract essential features from the channel-length surface, mapping the input to a higher-dimensional space. In symmetry to the Encoder, the Decoder is constructed with transConv and upsampling operations, effectively inverting the encoding process.

The proposed VAE stands out for its lightweight nature. This is attributed to the CNN-based architecture which enables it to efficiently extract information from 1D discrete data and map it to a high-dimensional continuous space. Additional details about the VAE architecture, including the incorporation of a multi-kernel design  in the Conv1D block for feature extraction at various scales, are provided in Appendix D.

Cross Entropy LossWhen training the VAE, we propose to use Cross Entropy (CE) as reconstruction loss. The loss function is given by:

\[_{,}=_{z q_{}(z|x)}[- _{t=1}^{k}_{l=1}^{n}p(x_{t},l) p_{}(x_{t}|z)]}_{ {Reconstruction Loss}}+_{x p(x)}[(q_{ }(z|x)\,||\,(z;,))}_{}]\] (3)

where \(x^{k n}\) is onehot-encode data; \(p_{}(x|z)\) is the probabilistic decoder output from \(_{}\); \(q_{}(z|x)\) is the probabilistic output from encoder \(_{}\) that represents the approximate posterior of the latent variable \(z\) given the input \(x\); \((z;,)\) is the prior on \(z\), here we use diagonal Gaussian Distribution.

### Diffusion in the Latent Space

Once the transformation function with \(_{}\) and \(_{}\) are trained in the first stage, the diffusion model is applied to the latent representation \(z=_{}(x)\). With the goal of minimizing the difference between the estimator and the score function in the latent space.

\[min(}_{}(z(t),t)-_{z} p_{t}(z))^{2}\] (4)

It is trained by sampling \(t\) from uniform distribution \(U[1,T]\) and \(z_{t}\) from \(p_{t}(z_{t}|z_{0})\) with a known transition kernel defined by Equation (1). The training process can also be interpreted as a training a noise predictor :

\[_{z,t U[1,T],e(0,1)}[\|- _{}(z(t),t)\|_{2}^{2}]\] (5)

We adopted the UNet backbone from LDM  to implement \(_{}(z(t),t)\). The UNet can capture coarse-grained features and generate samples with high qualities in various domains [16; 20]. Figure 1 illustrates the denoising view of training and inference processes for the diffusion model. The details about the UNet configuration can be found in Appendix E.

### Justification for the Two-stage Training

The separation of VAE and the denoising model training can be justified by the loss function of LSGM . LSGM jointly trains a VAE and the denoising model with a training loss consisting of a reconstruction term and KL divergence between encoder distribution \(p(z_{0}|x)\) and the prior distribution of the latent variable \(p(z_{0})\). The latter term can be expressed in terms of the score function \(_{}(x(t),t)\)

Figure 2: VAE as a transformation function. (a) shows the components of the encoder, consisting of conv1d and conv2d. It lifts the channel dimension and reduces the length dimension of the input. (b) shows the overall view, the latent variable is modelled with Diagonal Gaussian Distribution. The Decoder is symmetric to the Encoder architecture, consisting of transConv and upsampling. See Appendix D for the values of \(c,w,h,\).

The optimisation of this loss is challenging, requiring different weighting mechanisms for the training objective and variance reduction techniques for stability. The separation of training is equivalent to a special training schedule with the KL divergence term being fixed in the first stage, and then training the denoising model in the second stage. The performance gain of separating the training process has been shown in the image generation domain [25; 26]. In the section below, we provide the empirical evaluation of this method for DNA sequence generation.

## 4 DNA Sequence Generation with DiscDiff

We explored the unconditional generation of both regulatory elements and protein-encoding genes. Our problem setting is different from the previous study DDSM , where the transcription profile is provided as an input at both training and inference time. In this study, we focus on a scenario where no transcription profile is given. The generative model needs to discover the properties of regulatory elements and genes purely from DNA sequences. Identifying and generating regulatory elements is essential for successful genetic modifications . To achieve this, we constructed a dataset, trained the diffusion model for DNA generation, and provided an evaluation metric called Frechet Reconstruction Distance (FReD) to assess the quality of generated samples. For an in-depth look into the training specifics, including hyperparameters and training equipment, see Appendix B.

### Data Construction and Representation

DatasetWe created a cross-species dataset for DNA generation from the refined Eukaryotic Promoter Database (EPDnew) [10; 23], housing organism-specific promoters annotated with downstream genes, transcription starting sites, and expression levels. From EPDnew, we processed 160K unique sequences across various species, each mapping to different cell types and expression levels, detailed in Table 2 of Appendix C. This study emphasizes unconditional generation using a subset of this data. We employed a 2048-base context window centred on a gene's transcription starting site. Each sequence split evenly into an upstream promoter and a downstream DNA segment, spans 2048 bases in total.

Representation of DNA SequencesDNA sequences are composed of the nucleotide bases \(A\), \(T\), \(G\), and \(C\). For a DNA sequence of length 2048, a one-hot encoding function, denoted as \(f\), is employed:

\[f:\{A,T,G,C\}^{2048}^{4 2048}\]

It is worth noting that DNA sequences sometimes contain the \(N\) token, indicating an unknown or ambiguous nucleotide. In the encoding scheme, such a token is represented as \(\{0.25,0.25,0.25,0.25\}\). This representation allows generative models to directly model the aleatoric uncertainty arising from the data collection process when using a cross-entropy reconstruction loss for VAE training.

### Evaluation Metrics

Motif DistributionA motif in the context of molecular biology refers to a short sequence of DNA or RNA that has a specific structure or function. Motif distribution is a commonly used metric to

Figure 3: **Dataset and evaluation methods for DNA sequence generation.(a) shows the format of the curated dataset from EPDnew (b) Motif Distribution compares the distribution of subsequences in DNA and Latent Distance metrics compare the distribution of latent embedding of DNA.**

evaluate the biological relevance of generated DNA sequences, which is frequently employed in prior studies [18; 34; 37; 1]. DNA motifs with biological functions can shed light on the functionality of generated sequences. By comparing the distribution of motifs between real and generated sequences, we can measure the ability of the generative model to replicate the underlying patterning of natural DNA sequences. A high-quality generative model should exhibit a motif distribution closely mirroring that of genuine DNA sequences, ensuring that generated sequences retain crucial biological signatures.

Frechet Reconstruction DistanceWe introduce the Frechet Reconstruction Distance (FReD) to assess the quality of generated DNA samples quantitatively. Unlike the Frechet Inception Distance used for image generation evaluation , FReD leverages the encoder of a pre-trained Auto-Encoder (AE) to transform DNA sequences into embeddings. This encoding process measures the disparity between generated sample distributions and real-world sequences. For this purpose, we train an AE, following the architecture outlined in Section 3, on a reference genome distinct from the training data used for generation. The embeddings are subsequently derived from this encoder.

Evaluating Generated Sequences with the Sei FrameworkSei  is a deep-learning framework dedicated to predicting the chromatin profile of the human genome. We used Sei to evaluate the generated sequences in two ways. First, we employ Sei to encode the sequences and subsequently calculate the distribution distance. As highlighted in Section 5, there's a consistency between the results of FReD and Sei. Second, using Sei, we obtained predictions for 21,907 distinct chromatin profiles \(Sei(x)^{50000 21907}\) for 50,000 generated sequences. For each profile, we calculated the number of "hits" among our sequences. A "hit" is defined as a sequence for which the predicted likelihood of aligning with a profile exceeds 0.9.

Figure 4: **TATA-Box Distribution in Real and Generated DNA Sequences**. The left plot represents mammalian sequences, while the right showcases plant sequences. Both generated samples closely mirror the distribution of their respective real DNA sequences.

Figure 5: **TATA-Box Distribution Across Epochs Relative to Real DNA**. Subplots from left to right showcase the motif distribution by DiscDiff at epochs 0, 200, 1000, and 3000. With increasing epochs, the peak distribution around TSS converges towards that of the real DNA, but the background distribution starts to diverge after 200 epochs.

## 5 Results

Motif DistributionTo assess the quality of the generated samples, we generated 50,000 DNA sequences for both mammalian and plant species using DiscDiff. Their motif distributions are illustrated in Figure 4. The plots reveal consistency between the TATA-box  distributions of real DNA sequences and our generated promoters. Additionally, Figure 5 demonstrates the evolution of the motif distribution throughout training. Noticeably, while the peak distribution around the Transcription Starting Site (TSS) is converging to the real DNA sequences, the background distribution seems to be diverging after 200 training epochs. This trend is also captured by FReD and Sei Distance.

Latent Distribution DistanceFigure 6 presents the change of FReD and Sei Embedding Distribution Distance values relative to the training set across epochs. Notably, these metrics exhibit strong correlation to the training set: a sharp decline is observed from epoch 0 to 200, followed by a gradual increase up to epoch 3000. This trend highlights the intricacy of measuring the quality of generated DNA sequences using a singular numerical metric. We attribute the rise in these metrics (epoch 200 to 3000) to divergences in the background motif distribution. Even as the modelling of the TSS peak improves with prolonged training. Embedding-based approaches tend to prioritize the holistic representation of DNA sequences over specific details. However, latent distribution distances remain crucial as they help distinguish genuine DNA from random or subpar sequences. As per Table 1, when comparing VAE and DiscDiff, VAE-generated examples fare less favourably in motif distribution (Appendix F).

Chromatin Profiles of Generated SequencesFigure 7 presents the chromatin profiles of the 50,000 generated and real DNA sequences. The y-axis indicates the count of sequences corresponding to each profile. Among these, we highlight the top 10 profiles with the highest counts, omitting cell line names for clarity. There's a striking resemblance between the generated sequences (Figure 6(a)) and the training data (Figure 6(b)) in terms of distribution and top-ranking profiles. Notably, profiles such as H3K4me3, H3K27me3 and H3K9me3 are predominant. H3Kxxme3 markers are closely linked to promoter activity as they remodel chromatin to be more accessible to transcription factors (essential proteins for promoter regulation). This observation aligns with our expectations since our training set is derived from the promoter database.

 
**Model** & **FReD\(\)** & **Sei Embedding Distribution Distance\(\)** \\  Random & 251.7 & 250.7 \\ Sample from Training Set & 3.38 & 0.10 \\  VAE & 48.66 & 84.77 \\ DiscDiff 200 & **22.10** & **45.23** \\ DiscDiff 3000 & 29.25 & 57.28 \\  

Table 1: Comparison of FReD and Sei Embedding Distribution Distance across different models.

Figure 6: **Change of FReD and Sei Embedding Distribution Distance across epochs. Both metrics show a rapid decrease until epoch 200, then gradually rise until epoch 3000. This behaviour indicates the complexity of capturing DNA sequence quality with a single value. Despite improvements in modelling the TSS peak, divergences in background motifs appear over extended training.**

## 6 Discussion

We presented DiscDiff, a latent diffusion model for DNA sequence generation. By connecting discrete DNA sequences to continuous spaces with an autoencoder, DiscDiff taps into diffusion model capabilities. Our Frechet Reconstruction Distance (FReD) offers improved genomics evaluation, and our model's alignment with real DNA benchmarks showcases its efficacy.

Looking ahead, our approach raises important questions: How might we design general transformation functions optimally for this framework? What properties make a function particularly appealing for the diffusion model, ensuring the production of superior-quality samples? It has been shown in image generation, that the choice of auto-encoder will influence the quality of generated samples . On the practical side, exploring the conditional generation of DNA sequences influenced by factors such as cell type, expression level, and environment holds potential. We envision a scenario where one could generate a functional gene or regulatory element based solely on specified criteria. In addition, the scarcity of experimental data for certain types of DNA sequences advocates the strategy of fine-tuning pre-trained diffusion models with existing methods . Such advancements could redefine synthetic biology, and we are optimistic about delving deeper into these avenues.