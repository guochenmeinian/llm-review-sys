# NAS-\(\chi\): Neural Adaptive Smoothing via Twisting

# NAS-\(\): Neural Adaptive Smoothing via Twisting

 Dieterich Lawson\({}^{*,}\)

Google Research

dieterichl@google.com

&Michael Y. Li\({}^{*}\)

Stanford University

michaelyli@stanford.edu

&Scott W. Linderman

Stanford University

scott.linderman@stanford.edu

Equal contribution. Work performed while at Stanford University.

###### Abstract

Sequential latent variable models (SLVMs) are essential tools in statistics and machine learning, with applications ranging from healthcare to neuroscience. As their flexibility increases, analytic inference and model learning can become challenging, necessitating approximate methods. Here we introduce neural adaptive smoothing via twisting (NAS-X), a method that extends reweighted wake-sleep (RWS) to the sequential setting by using smoothing sequential Monte Carlo (SMC) to estimate intractable posterior expectations. Combining RWS and smoothing SMC allows NAS-X to provide low-bias and low-variance gradient estimates, and fit both discrete and continuous latent variable models. We illustrate the theoretical advantages of NAS-X over previous methods and explore these advantages empirically in a variety of tasks, including a challenging application to mechanistic models of neuronal dynamics. These experiments show that NAS-X substantially outperforms previous VI- and RWS-based methods in inference and model learning, achieving lower parameter error and tighter likelihood bounds.

## 1 Introduction

Sequential latent variable models (SLVMs) are a foundational model class in statistics and machine learning, propelled by the success of hidden Markov models  and linear dynamical systems . To model more complex data, SLVMs have incorporated nonlinear conditional dependencies, resulting in models such as sequential variational autoencoders [3; 4; 5; 6; 7], financial volatility models , and biophysical models of neural activity . While these nonlinear dependencies make SLVMs more flexible, they also frustrate inference and model learning, motivating the search for approximate methods.

One popular method for inference in nonlinear SLVMs is sequential Monte Carlo (SMC), which provides a weighted particle approximation to the true posterior and an unbiased estimator of the marginal likelihood. For most SLVMs, SMC is a significant improvement over standard importance sampling, providing an estimator of the marginal likelihood with variance that grows linearly in the length of the sequence rather than exponentially . SMC's performance, however, depends on having a suitable proposal. The optimal proposal is often intractable, so in practice, proposal parameters are learned from data. Broadly, there are two approaches to proposal learning: variational inference [11; 12] and reweighted wake-sleep [13; 14].

Variational inference (VI) methods for SLVMs optimize the model and proposal parameters by ascending a lower bound on the log marginal likelihood that can be estimated with SMC, an approach called variational SMC [15; 16; 17]. Recent advances in variational SMC have extended it to work with smoothing SMC [18; 19], a crucial development for models where future observations are strongly related to previous model states. Without smoothing SMC, particle degeneracy can cause high variance of the lower bound and its gradients, resulting in unstable learning [18; 10].

Reweighted wake-sleep (RWS) methods instead use SMC's posterior approximation to directly estimate gradients of the log marginal likelihood [14; 20]. This approach can be interpreted as descending the inclusive KL divergence from the true posterior to the proposal. Notably, RWS methods work with discrete latent variables, providing a compelling advantage over VI methods that typically resort to high-variance score function estimates for discrete latent variables.

In this work, we combine recent advances in smoothing variational SMC with the benefits of reweighted wake-sleep. To this end, we introduce neural adaptive smoothing via twisting (NAS-X), a method for inference and model learning in nonlinear SLVMs that uses smoothing SMC to approximate intractable posterior expectations. The result is a versatile, low-bias and low-variance estimator of the gradients of the log marginal likelihood suitable for fitting proposal and model parameters in both continuous and discrete SLVMs.

After introducing NAS-X, we present two theoretical results that highlight the advantages of NAS-X over other RWS-based methods. We also demonstrate NAS-X's performance empirically in model learning and inference in linear Gaussian state-space models, discrete latent variable models, and high-dimensional ODE-based mechanistic models of neural dynamics. In all experiments, we find that NAS-X substantially outperforms several VI and RWS alternatives including ELBO, IWAE, FIVO, SIXO. Furthermore, we empirically show that our method enjoys lower bias and lower variance gradients, requires minimal additional computational overhead, and is robust and easy to train.

## 2 Background

This work considers model learning and inference in nonlinear sequential latent variable models with Markovian structure; i.e. models that factor as

\[p_{}(_{1:T},_{1:T})=p_{}( _{1})p_{}(_{1}_{1})_{t=2}^{T}p_{}(_{t}_{t-1})p_{}(_{t} _{t}),\] (1)

with latent variables \(_{1:T}^{T}\), observations \(_{1:T}^{T}\), and global parameters \(\). By nonlinear, we mean latent variable models where the parameters of the conditional distributions \(p_{}(_{t}_{t-1})\) and \(p_{}(_{t}_{t})\) depend nonlinearly on \(_{t-1}\) and \(_{t}\), respectively.

Estimating the marginal likelihood \(p_{}(_{1:T})\) and posterior \(p_{}(_{1:T}_{1:T})\) for this model class is difficult because it requires computing an intractable integral over the latents,

\[p_{}(_{1:T})=_{^{T}}p_{}( _{1:T},_{1:T})\,_{1:T},\]

We begin by introducing two algorithms, reweighted wake-sleep [14; 13] and smoothing sequential Monte Carlo , that are crucial for understanding our approach.

### Reweighted Wake-Sleep

Reweighted wake-sleep (RWS, [13; 14]) is a method for maximum marginal likelihood in LVMs that estimates the gradients of the marginal likelihood using self-normalized importance sampling. This is motivated by Fisher's identity, which allows us to write the gradients of the marginal likelihood as a posterior expectation,

\[_{} p_{}(_{1:T})=_{p_{}( _{1:T}|_{1:T})}[_{} p_{}( _{1:T},_{1:T})],\] (2)

as proved in Appendix 8.1. The term inside the expectation is computable with modern automatic differentiation tools [21; 22], but the posterior \(p_{}(_{1:T}_{1:T})\) is unavailable. Thus, SNIS is used to form a biased but consistent Monte Carlo estimate of Eq. (2) . Specifically, SNIS draws \(N\) IIDsamples from a proposal distribution, \(q_{}(_{1:T}_{1:T})\) and weights them to form the estimator

\[_{i=1}^{N}^{(i)}_{} p_{}(_{1:T} ^{(i)},_{1:T}),_{1:T}^{(i)} q_{}(_{ 1:T}_{1:T}),^{(i)}( _{1:T}^{(i)},_{1:T})}{q_{}(_{1:T}^{(i)} _{1:T})}\] (3)

where \(^{(i)}\) are normalized weights, i.e. \(_{i=1}^{N}^{(i)}=1\).

The variance of this estimator is reduced as \(q_{}\) approaches the posterior , so RWS also updates \(q_{}\) by minimizing the inclusive Kullback-Leibler (KL) divergence from the posterior to the proposal. Crucially, the gradient for this step can also be written as the posterior expectation

\[_{}(p_{}(_{1:T}_{1:T})  q_{}(_{1:T}_{1:T}))=-_{p_{ }(_{1:T}_{1:T})}[_{} q_{ }(_{1:T}_{1:T})],\] (4)

as derived in Appendix 8.2. This allows RWS to estimate Eq. (4) using SNIS with the same set of samples and weights as Eq. (3),

\[-_{p_{}(_{1:T}_{1:T})}[_{ } q_{}(_{1:T}_{1:T})]-_{ i=1}^{N}^{(i)}_{} q_{}(_{1:T}^{(i)} _{1:T}).\] (5)

Importantly, any method that provides estimates of expectations w.r.t. the posterior can be used for gradient estimation within the RWS framework, as we will see in the next section.

### Estimating Posterior Expectations with Smoothing Sequential Monte Carlo

As we saw in Eqs. (2) and (4), key quantities in RWS can be expressed as expectations under the posterior. Standard RWS uses SNIS to approximate these expectations, but in sequence models the variance of the SNIS estimator can scale exponentially in the sequence length. In this section, we review sequential Monte Carlo (SMC) [10; 24], an inference algorithm that can produce estimators of posterior expectations with linear or even sub-linear variance scaling.

SMC approximates the posterior \(p_{}(_{1:T}_{1:T})\) with a set of \(N\) weighted particles \(_{1:T}^{1:N}\) constructed by sampling from a sequence of target distributions \(\{_{t}(_{1:t})\}_{t=1}^{T}\). Since these intermediate targets are often only known up to some unknown normalizing constant \(Z_{t}\), SMC uses the unnormalized targets \(\{_{t}(_{1:t})\}_{t=1}^{T}\), where \(_{t}(_{1:t})=_{t}(_{1:t})/Z_{t}\). Provided mild technical conditions are met and \(_{T}(_{1:T}) p_{}(_{1:T},_{1:T})\), SMC returns weighted particles that approximate the posterior \(p_{}(_{1:T}_{1:T})\)[10; 24]. These weighted particles can be used to compute biased but consistent estimates of expectations under the posterior, similar to SNIS.

SMC repeats the following steps for each time \(t\):

1. Sample latents \(_{1:t}^{1:N}\) from a proposal distribution \(q_{}(_{1:t}_{1:T})\).
2. Weight each particle using the unnormalized target \(_{t}\) to form an empirical approximation \(_{t}\) to the normalized target distribution \(_{t}\).
3. Draw new particles \(_{1:t}^{1:N}\) from the approximation \(_{t}\) (the resampling step).

By resampling away latent trajectories with low weight and focusing on promising particles, SMC can produce lower variance estimates than SNIS. For a thorough review of SMC, see Doucet and Johansen , Naesseth et al. , and Del Moral .

Filtering vs. SmoothingThe most common choice of unnormalized targets \(_{t}\) are the _filtering_ distributions \(p_{}(_{1:t},_{1:t})\), resulting in the algorithm known as filtering SMC or a particle filter. Filtering SMC has been used to estimate posterior expectations within the RWS framework in neural adaptive sequential Monte Carlo (NASMC) , but a major disadvantage of filtering SMC is that it ignores future observations \(_{t+1:T}\). Ignoring future observations can lead to particle degeneracy and high-variance estimates, which in turn causes poor model learning and inference [17; 18; 26; 27].

We could avoid these issues by using the _smoothing_ distributions as unnormalized targets, choosing \(_{t}(_{1:t})=p_{}(_{1:t},_{1:T})\), but unfortunately the smoothing distributions are not readily available from the model. We can approximate them, however, by observing that \(p_{}(_{1:t},_{1:T})\) is proportional to the filtering distributions \(p_{}(_{1:t},_{1:t})\) times the _lookahead_ distributions \(p_{}(_{t+1:T}_{t})\). If the lookahead distributions are well-approximated by a sequence of _twists_\(\{r_{}(_{t+1:T},_{t})\}_{t=1}^{T}\), then running SMC with targets \(_{t}(_{1:t})=p_{}(_{1:t},_{1:t})\,r_{}(_{t+1:T},_{t})\) approximates smoothing SMC .

Twist LearningWe have reduced the challenge of obtaining the smoothing distributions to learning twists that approximate the lookahead distributions. Previous twist-learning approaches include maximum likelihood training on samples from the model [18; 28] and Bellman-type losses motivated by writing the twist at time \(t\) recursively in terms of the twist at time \(t+1\)[18; 29]. For NAS-X we use density ratio estimation (DRE) via classification to learn the twists, as introduced in Lawson et al. . This method is motivated by observing that the lookahead distribution is proportional to a ratio of densities up to a constant independent of \(x_{t}\),

\[p_{}(_{t+1:T}_{t})=}( _{t}_{t+1:T})\,p_{}(_{t+1:T})}{p_ {}(_{t})}}(_{t} _{t+1:T})}{p_{}(_{t})}.\] (6)

Results from the DRE via classification literature  provide a way to approximate this density ratio: train a classifier to distinguish between samples from the numerator \(p_{}(_{t}_{t+1:T})\) and denominator \(p_{}(_{t})\). Then, the pre-sigmoid output of the classifier will approximate the log of the ratio in Eq. (6). For an intuitive argument for this fact see Appendix 8.3, and for a full proof see Sugiyama et al. .

In practice, it is not possible to sample directly from \(p_{}(_{t}_{t+1:T})\). Instead, Lawson et al.  sample full trajectories from the model's joint distribution, i.e. draw \(_{1:T},_{1:T} p_{}(_{1:T}, _{1:T})\), and discard unneeded timesteps, leaving only \(_{t}\) and \(_{t+1:T}\) which are distributed marginally as \(p_{}(_{t},_{t+1:T})\). Training the DRE classifier on data sampled in this manner will approximate the ratio \(p_{}(_{t},_{t+1:T})/p_{}( _{t})p_{}(_{t+1:T})\), which is equivalent to Eq. (6), see Appendix 8.3.

## 3 NAS-X: Neural Adaptive Smoothing via Twisting

The goal of NAS-X is to combine recent advances in smoothing SMC with the advantages of reweighted wake-sleep. Because SMC is a self-normalized importance sampling algorithm, it can be used to estimate posterior expectations and therefore the model and proposal gradients within a reweighted wake-sleep framework. In particular, NAS-X repeats the following steps:

1. Draw a set of \(N\) trajectories \(_{1:T}^{(1:N)}\) and weights \(_{1:T}^{(1:N)}\) from a smoothing SMC run with model \(p_{}\), proposal \(q_{}\), and twist \(r_{}\).
2. Use those trajectories and weights to form estimates of gradients for the model \(p_{}\) and proposal \(q_{}\), as in reweighted wake-sleep. Specifically, NAS-X computes the gradients of the inclusive KL divergence for learning the proposal \(q_{}\) as \[-_{t=1}^{T}_{i=1}^{N}_{t}^{(i)}_{} q_{}( _{t}^{(i)}_{t-1}^{(i)},_{t:T})\] (7) and computes the gradients of the model \(p_{}\) as \[_{t=1}^{T}_{i=1}^{N}_{t}^{(i)}_{} p_{} (_{t}^{(i)},_{t}_{t-1}^{(i)}).\] (8)
3. Update the twists \(r_{}\) using density ratio estimation via classification.

A full description is available in Algorithms 1 and 2.

A key design decision in NAS-X is the specific form of the gradient estimators. Smoothing SMC provides two ways to estimate expectations of test functions with respect to the posterior: both the timestep-\(t\) and timestep-\(T\) approximations of the target distribution could be used, in the latter case by discarding timesteps after \(t\). Specifically,

\[p_{}(_{1:t}_{1:T})_{i=1}^{N} {w}_{t}^{(i)}(_{1:t}\,;\,_{1:t}^{(i)})_{i =1}^{N}_{T}^{(i)}(_{1:t}\,;\,(_{1:T}^{(i )})_{1:t})\] (9)

where \((a\,;\,b)\) is a Dirac delta of \(a\) located at \(b\) and \((_{1:T})_{1:t}\) denotes selecting the first \(t\) timesteps of a timestep-\(T\) particle; due to SMC's ancestral resampling step these are not in general equivalent. For NAS-X we choose the time-\(t\) approximation of the posterior to lessen particle degeneracy, as in NASMC . Note, however, that in the case of NASMC this amounts to approximating the posterior with the filtering distributions, which ignores information from future observations. In the case of NAS-X, the intermediate distributions directly approximate the posterior distributions because of the twists, a key advantage that we explore theoretically in Section 3.1 and empirically in Section 5.

### Theoretical Analysis of NAS-X

In this section, we state two theoretical results that illustrate NAS-X's advantages over NASMC, with proofs given in Appendix 7.

**Proposition 1**.: Consistency of NAS-X's gradient estimates. _Suppose the twists are optimal so that \(r_{}(_{t+1:T},_{t}) p(_{t+1:T} _{t})\) up to a constant independent of \(_{t}\) for \(t=1,,T-1\). Let \(_{} p_{}(_{1:T})\) be NAS-X's weighted particle approximation to the true gradient of the log marginal likelihood \(_{} p_{}(_{1:T})\). Then \(_{} p_{}(_{1:T})[]{a.} _{} p_{}(_{1:T})\) as \(N\)._

**Proposition 2**.: Unbiasedness of NAS-X's gradient estimates. _Assume that proposal distribution \(q_{}(_{t}_{1:t-1},_{1:T})\) is optimal so that \(q_{}(_{t}_{1:t-1},_{1:T})=p( _{t}_{1:t-1},_{1:T})\) for \(t=1,,T\), and the twists \(r_{}(_{t+1:T},_{t})\) are optimal so that \(r_{}(_{t+1:T},_{t}) p(_{t+1:T} _{t})\) up to a constant independent of \(_{t}\) for \(t=1,,T-1\). Let \(_{} p_{}(_{1:T})\) be NAS-X's weighted particle approximation to the true gradient of the log marginal likelihood, \(_{} p_{}(_{1:T})\). Then, for any number of particles, \([_{} p_{}(_{1:T})]= p_{ }(_{1:T})\)._

## 4 Related Work

VI MethodsThere is a large literature on model learning via stochastic gradient ascent on an evidence lower bound (ELBO) [31; 32; 4; 33]. Subsequent works have considered ELBOs defined by the normalizing constant estimates from multiple importance sampling , nested importance sampling, [35; 36], rejection sampling, and Hamiltonian Monte Carlo . Most relevant to our work is the literature that uses SMC's estimates of the normalizing constant as a surrogate objective. There are a number of VI methods based on filtering [17; 16; 15] and smoothing SMC [18; 38; 39; 19; 27], but filtering SMC approaches can suffer from particle degeneracy and high variance [18; 19].

Reweighted Wake-Sleep MethodsThe wake-sleep algorithm was introduced in Hinton et al.  as a way to train deep directed graphical models. Bornschein and Bengio  interpreted the wake-sleep algorithm as self-normalized importance sampling and proposed reweighted wake-sleep, which uses SNIS to approximate gradients of the inclusive KL divergence and log marginal likelihood. Neural adaptive sequential Monte Carlo (NASMC) extends RWS by using filtering SMC to approximate posterior expectations instead of SNIS . To combat particle degeneracy, NASMC approximates the posterior with the filtering distributions, which introduces bias.

NAS-X vs. SIXOBoth NAS-X and SIXO  leverage smoothing SMC with DRE-learned twists, but NAS-X uses smoothing SMC to estimate gradients in an RWS-like framework while SIXO uses it within a VI-like framework. Thus, NAS-X follows biased but consistent estimates of the log marginal likelihood while SIXO follows unbiased estimates of a lower bound on the log marginal likelihood. It is not clear a-priori which approach would perform better, but we provide empirical evidence in Section 5 that shows NAS-X is more stable than SIXO and learns better models and proposals. Inaddition to these empirical advantages, NAS-X can fit discrete latent variable models while SIXO would require high-variance score function estimates.

## 5 Experiments

We empirically validate the following advantages of NAS-X:

* By using the approximate smoothing distributions as targets for proposal learning, NAS-X can learn proposals that match the true posterior marginals, while NASMC and other baseline methods cannot. We illustrate this in Section 5.1, in a setting where the true posterior is tractable. We illustrate the practical benefits on inference in nonlinear mechanistic models in Section 5.3.
* By optimizing the proposal within the RWS framework (_e.g.,_ descending the inclusive KL), NAS-X can perform learning and inference in discrete latent variable models, which SIXO cannot. We explore this in Section 5.2.
* We explore the practical benefits of this combination in a challenging setting in Section 5.3, where we show NAS-X can fit ODE-based mechanistic models of neural dynamics with 38 model parameters and an 18-dimensional latent state.

In addition to these experiments, we analyze the computational complexity and wall-clock speed of each method and the bias and variance of the gradient estimates in Sections 15 and 16 of the Appendix.

### Linear Gaussian State Space Model

We first consider a one-dimensional linear Gaussian state space model with joint distribution

\[p(_{1:T},_{1:T})=(_{1} ;0,_{x}^{2})_{t=2}^{T}(_{t+1};_{t}, _{x}^{2})_{t=1}^{T}(_{t};_{t}, _{y}^{2}).\] (10)

In Figure 1, we compare NAS-X against several baselines (NASMC, FIVO, SIXO, RWS, IWAE, and ELBO) by evaluating log marginal likelihood estimates (left panel) and recovery of the true posterior (middle and right panels). For all methods we learn a mean-field Gaussian proposal factored over time, \(q(_{1:T})=_{t=1}^{T}q_{t}(_{t})=_{t=1}^{T} (_{t};_{t},_{t}^{2})\), with parameters \(_{1:T}\) and \(_{1:T}^{2}\) corresponding to the means and variances at each time-step. For twist-based methods, we parameterize the twist as a quadratic function in \(_{t}\) whose coefficients are functions of the observations and time step. We chose this form to match the functional form of the analytic log density ratio. For details, see Section 9 in the Appendix. NAS-X outperforms all baseline methods, achieving a tighter lower bound on the log-marginal likelihood and lower parameter error.

In the right panel of Figure 1, we compare the learned proposal variances against the true posterior variance, which can be computed in closed form. See Section 9 for comparison of proposal means; we do not report this comparison in the main text since all methods recover the posterior mean. This comparison gives insight into NAS-X's better performance. NASMC's learned proposal overestimates the posterior variance and fails to capture the true posterior distribution, because it employs a filtering

Figure 1: **Comparison of NAS-X and baseline methods on inference in LG-SSM. (left)** Comparison of log-marginal likelihood bounds (lower is better), (middle) proposal parameter error (lower is better), and (right) learned proposal variances. NAS-X outperforms all baseline methods and recovers the true posterior marginals.

approximation to the gradients of the proposal distribution. On the other hand, by using the twisted targets, which approximate the smoothing distributions, to estimate proposal gradients, NAS-X recovers the true posterior.

### Switching Linear Dynamical Systems

To explore NAS-X's ability to handle discrete latent variables, we consider a switching linear dynamical system (SLDS) model [40; 41]. Specifically, we adapt the recurrent SLDS example from Linderman et al.  in which the latent dynamics trace ovals in a manner that resembles cars racing on a NASCAR track. There are two coupled sets of latent variables: a discrete state \(_{t}\), with \(K=4\) possible values, and a two-dimensional continuous state \(_{t}\) that follows linear dynamics that depend on \(_{t}\). The observations are a noisy projection of \(_{t}\) into a ten-dimensional observation space. There are 1000 observations in total. For the proposal, we factor \(q\) over both time and the continuous and discrete states. The continuous distributions are parameterized by Gaussians, and categorical distributions are used for the discrete latent variables. For additional details on the proposal and twist, see Section 10 in the Appendix and for details on the generative model see Linderman et al. .

We present qualitative results from model learning and inference in the top panel of Figure 2. We compare the learned dynamics for NAS-X, NASMC, and a Laplace-EM algorithm designed specifically for recurrent state space models . In each panel, we plot the vector field of the learned dynamics and the posterior means, with different colors corresponding to the four discrete states. NAS-X recovers the true dynamics accurately. In the Table in Figure 2, we quantitatively compare the model learning performances across these three approaches by running a bootstrap proposal with the learned models and the true dynamics and observation variances. We normalize the bounds by the sequence length. NAS-X outperforms or performs on par with both NASMC and Laplace EM across the different observation noises \(^{2}_{O}\). See Section 10, for additional results on inference.

### Biophysical Models of Neuronal Dynamics

For our final set of experiments we consider inference and parameter learning in Hodgkin-Huxley (HH) models [9; 43] -- mechanistic models of voltage dynamics in neurons. These models use systems of coupled nonlinear differential equations to describe the evolution of the voltage difference across a neuronal membrane as it changes in response to external stimuli such as injected current. Un

Figure 2: **Inference and model learning in switching linear dynamical systems (SLDS). (top) Comparison of learned dynamics and inferred latent states in model learning. Laplace EM sometimes learns incorrect segmentations, as seen in the rightmost panel. (bottom) Quantitative comparison of log marginal likelihood lower bounds obtained from running bootstrap particle filter (BPF) with learned models.**

derstanding how voltage propagates throughout a cell is central to understanding electrical signaling and computation in the brain.

Voltage dynamics are governed by the flow of charged ions across the cell membrane, which is in turn mediated by the opening and closing of ion channels and pumps. HH models capture the states of these ion channels as well as the concentrations of ions and the overall voltage, resulting in a complex dynamical system with many free parameters and a high dimensional latent state space. Model learning and inference in this setting can be extremely challenging due to the dimensionality, noisy data, and expensive and brittle simulators that fail for many parameter settings.

Model DescriptionWe give a brief introduction to the models used in this section and defer a full description to the appendix. We are concerned with modeling the potential difference across a neuronal cell membrane, \(v\), which changes in response to currents flowing through a set of ion channels, \(c\). Each ion channel \(c\) has an _activation_ which represents a percentage of the maximum current that can flow through the channel and is computed as a nonlinear function \(g_{c}\) of the channel state \(_{c}\), with \(g_{c}(_{c})\). This activation specifies the time-varying conductance of the channel as a fraction of the maximum conductance of the channel, \(_{c}\). Altogether, the dynamics for the voltage \(v\) can be written as

\[c_{m}=}}{S}-_{c}_{c}g_{c}(_{c})(v-E_{c_{}})\] (11)

where \(c_{m}\) is the specific membrane capacitance, \(I_{}\) is the external current applied to the cell, \(S\) is the cell membrane surface area, \(c_{}\) is the ion transported by channel \(c\), and \(E_{c_{}}\) is that ion's reversal potential. In addition to the voltage dynamics, the ion channel states \(\{_{c}\}_{c}\) evolve as

\[}{dt}=A(v)_{c}+b(v) c\] (12)

where \(A(v)\) and \(b(v)\) are nonlinear functions of the membrane potential that produce matrices and vectors, respectively. Together, equations (11) and (12) define a conditionally linear system of first-order ordinary differential equations (ODEs), meaning that the voltage dynamics are linear if the channel states are known and vice-versa.

Following Lawson et al. , we augment the deterministic dynamics with zero-mean, additive Gaussian noise to the voltage \(v\) and unconstrained gate states \((_{c})\) at each integration time-step. The observations are produced by adding Gaussian noise to the instantaneous membrane potential.

Proposal and Twist ParameterizationFor all models in this section we amortize proposal and twist learning across datapoints. SIXO and NAS-X proposals used bidirectional recurrent neural networks (RNNs)  with a hidden size of 64 units to process the raw observations and external current stimuli, and then fed the processed observations, previous latent state, and a transformer positional encoding  into a 64-unit single-layer MLP that produced the parameters of an isotropic Gaussian distribution over the current latent state. Twists were similarly parameterized with an RNN run in reverse across observations, combined with an MLP that accepts the RNN outputs and latent state and produces the twist values.

Integration via Strang SplittingThe HH ODEs are _stiff_, meaning they are challenging to integrate at large step sizes because their state can change rapidly. While small step sizes can ensure numerical stability, they also make methods prohibitively slow. For example, many voltage dynamics of interest unfold over hundreds of milliseconds, which could take upwards of 40,000 integration steps at the standard 0.005 milliseconds per step. Because running our models for even 10,000 steps would be too costly, we developed new numerical integration techniques based on an explicit Strang splitting approach that allowed us to stably integrate at 0.1 milliseconds per step, a 20-time speedup . For details, see Section 13 in the Appendix.

#### 5.3.1 Hodgkin-Huxley Inference Results

First, we evaluated NAS-X, NASMC, and SIXO in their ability to infer underlying voltages and channel states from noisy voltage observations. For this task we sampled 10,000 noisy voltage traces from a probabilistic Hodgkin-Huxley model of the squid giant axon , and used each method to train proposals (and twists for NAS-X and SIXO) to compute the marginal likelihood assigned to the data under the true model. As in , we sampled trajectories of length 50 milliseconds, with a single noisy voltage observation every millisecond. The stability of the Strang splitting based ODE integrator allowed us to integrate at \(dt=0.1\)ms, meaning there were 10 latent states per observation.

In Figure ((a)a) we plot the performance of proposals and twists trained with 4 particles and evaluated across a range of particle numbers. All methods perform roughly the same when evaluated with 256 particles, but with lower numbers of evaluation particles the smoothing methods emerge as more particle-efficient than the filtering methods. To achieve NAS-X's inference performance with 4 particles, NASMC would need 256 particles, a 64x increase, and NAS-X is also on average 2x more particle-efficient than SIXO.

In Figure (b)b we further investigate these results by examining the inferred voltage traces of NAS-X and SIXO. SIXO accurately infers the timing of most spikes but resamples at a high rate, which can lead to particle degeneracy and poor bound performance. NAS-X correctly infers the voltage across the whole trace with no spurious or mistimed spikes and almost no resampling events, indicating it has learned a high-quality proposal that does not generate poor particles that must be resampled away. These qualitative results support the quantitative results in Figure (a)a: SIXO's high resampling rate and NASMC's filtering approach lead to lower bound values.

These results highlight a benefit of RWS-based methods over VI methods: when the model is correctly specified, it can be beneficial to have a more deterministic proposal. Empirically, we find that maximizing the variational lower bound encourages the proposal to have high entropy, which in this case resulted in SIXO's poorer performance relative to NAS-X. In the next section, we explore the implications of this on model learning.

#### 5.3.2 Hodgkin-Huxley Model Learning Results

In this section, we assess NAS-X and SIXO's ability to fit model parameters in a more complex, biophysically realistic model of a pyramidal neuron from the mouse visual cortex. This model was taken from the Allen Institute Brain Atlas  and includes 9 different voltage-gated ion channels as well as a calcium pump/buffer subsystem and a calcium-gated potassium ion channel. In total, the model had 38 free parameters and an 18-dimensional latent state space, in contrast to the 1 free parameter and 4-dimensional state space of the model considered by Lawson et al. . For full details of the models, see Appendix Section 12.

We fit these models to voltage traces gathered from a real mouse neuron by the Allen Institute, but downsampled and noised the data to simulate a more common voltage imaging setting. We ran a hyperparameter sweep over learning rates and initial values of the voltage and observation noise variances (270 hyperparameter settings in all), and selected the best performing model via early stopping on the train log marginal likelihood lower bound. Each hyperparameter setting was run for

Figure 3: **Inference in Mechanistic HH Model**

5 seeds, and each seed was run for 2 days on a single CPU core with 7 Gb of memory. Because of the inherent instability of these models, many seeds failed, and we discarded hyperparameter settings with more than 2 failed runs.

In Figure 4 (bottom), we compare NAS-X and SIXO-trained models with respect to test set log-likelihood lower bounds as well as biophysically relevant metrics. To compute the biophysical metrics, we sampled 32 voltage traces for each input stimulus trace in the test set, and averaged the feature errors over the samples and test set. NAS-X better captures the number of spikes, an important feature of the traces, and attains a higher cross correlation. Both methods capture the resting voltage well, although SIXO attains a slightly lower error and outperforms NAS-X in terms of log-likelihood lower bound.

Training instability is a significant practical challenge when fitting mechanistic models. Therefore, we also include the percentage of runs that failed for each method. SIXO's more entropic proposals more frequently generate biophysically implausible latent states, causing the ODE integrator to return NaNs. In contrast, fewer of NAS-X's runs suffer from numerical instability issues, a great advantage when working with mechanistic models.

## 6 Conclusion

In this work we presented NAS-X, a new method for model learning and inference in sequential latent variable models, that combines reweighted wake-sleep framework and approximate smoothing SMC. Our approach involves learning twist functions to use in smoothing SMC, and then running smoothing SMC to approximate gradients of the log marginal likelihood with respect to the model parameters and gradients of the inclusive KL divergence with respect to the proposal parameters. We validated our approach in experiments including model learning and inference for discrete latent variable models and mechanistic models of neural dynamics, demonstrating that NAS-X offers compelling advantages in many settings.

Figure 4: **Model learning in HH model of a mouse pyramidal neuron (top)** Samples drawn from learned models when stimulated with a square pulse of 250 picoamps beginning at 20 milliseconds (vertical grey dashed line). NAS-X’s samples are noisier than SIXO’s, but spike more consistently. **(bottom)** A comparison of NAS-X- and SIXO-trained models along various evaluation metrics. SIXO’s models achieve higher bounds, but are less stable and capture overall spike count more poorly than NAS-X-trained models. All errors are absolute errors.