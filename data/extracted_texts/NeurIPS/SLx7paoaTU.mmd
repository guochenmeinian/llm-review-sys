# Variational Annealing on Graphs for Combinatorial Optimization

Sebastian Sanokowski\({}^{1,2}\)&Wilhelm Berghammer\({}^{2}\)&Sepp Hochreiter\({}^{1,2}\)

Sebastian Lehner\({}^{1,2}\)

\({}^{1}\) ELLIS Unit Linz and LIT AI Lab

\({}^{2}\) Institute for Machine Learning, Johannes Kepler University Linz, Austria

sanokowski@ml.jku.at

###### Abstract

Several recent unsupervised learning methods use probabilistic approaches to solve combinatorial optimization (CO) problems based on the assumption of statistically independent solution variables. We demonstrate that this assumption imposes performance limitations in particular on difficult problem instances. Our results corroborate that an autoregressive approach which captures statistical dependencies among solution variables yields superior performance on many popular CO problems. We introduce subgraph tokenization in which the configuration of a set of solution variables is represented by a single token. This tokenization technique alleviates the drawback of the long sequential sampling procedure which is inherent to autoregressive methods without sacrificing expressivity. Importantly, we theoretically motivate an annealed entropy regularization and show empirically that it is essential for efficient and stable learning. 1

## 1 Introduction

Combinatorial optimization (CO) problems are of central interest to a wide range of fields, including operations research, physics, and computational complexity (Papadimitriou and Steiglitz, 1998). Since CO problems are typically NP-hard one would not expect that one can find the solutions to all arbitrarily large CO problem instances in polynomial time. However, these restrictions are concerned with worst case scenarios over entire problem families. For instance finding the Minimum Independent Set of _any_ graph. Consequently, it is not surprising that a large body of work is focused on the design of solution strategies that yield a particularly good performance on a restricted subset of all possible instances. There is growing interest in exploring deep learning approaches to this restricted CO setting (Bello et al., 2017). These methods aim to learn how to efficiently generate high quality solutions for CO problems and rely primarily on learned algorithmic components rather than on problem-specific, hand-crafted ones (Bengio et al., 2021). Importantly, practicable methods should not rely on supervised training with solutions from other solvers since this limits the achievable performance of the learned model to that of the solver used to generate the training data (Yehuda et al., 2020). As a result the development of unsupervised methods (Karalias and Loukas, 2020; Wang et al., 2022; Qiu et al., 2022; Karalias et al., 2022; Min et al., 2022; Wang and Li, 2023) and of Reinforcement Learning (RL) methods (Bello et al., 2017; Khalil et al., 2017; Kool et al., 2019; Ahn et al., 2020; Bother et al., 2022; Mazyavkina et al., 2021) for CO is an active field of research. In this work we are interested in training models that generate solutions at inference in contrast to approachesthat require problem instance specific training. A popular approach is to take a representation of the CO problem instance as input to a deep learning model and to output the parameters of a distribution over solutions that has its probability mass concentrated on regions with high solution quality. This probabilistic optimization approach to CO is used in the recent works of e.g. (Karalias and Loukas, 2020; Min et al., 2022; Qiu et al., 2022; Sun et al., 2022). In these works the distribution over solutions is built on the assumption of mutual statistical independence of the individual solution parameters and can, consequently, be represented by a product of Bernoulli distributions for the the individual solution variables. This simplification is typically refereed to as a _mean-field approximation_ (MFA) and is frequently used in various fields including e.g. statistical mechanics (Parisi, 1988), Bayesian statistics (Wainwright and Jordan, 2008), and the analysis of neural networks (Mei et al., 2019). However, the simplifying assumption of the MFA restricts the expressivity of the corresponding distributions which limits its applicability when the target distribution represents strong correlations (Jaakkola and Jordan, 1998). However, replacing MFA with more expressive approaches is computationally expensive and requires careful regularization to ensure efficient and stable training. Based on these consideration our contributions can be summarized as follows.

We demonstrate that the frequently used MFA imposes limits on the attainable solution quality for CO problems. Importantly, we introduce _Variational Annealing on Graphs for Combinatorial Optimization (VAG-CO)_ a method that achieves new state-of-the-art performances on popular CO problems by combining expressive autoregressive models with annealed entropy regularization. We provide a theoretical motivation for this entropy regularization via considerations of the sample complexity of related density estimation problems. By introducing _sub-graph tokenization_ VAG-CO drastically reduces the number of necessary steps to generate solutions and therein significantly improves the training and inference efficiency.

## 2 Problem Description

**Ising Formulation of CO.** To introduce VAG-CO it is convenient to adopt a point of view on CO that is motivated by statistical mechanics. As shown in Lucas (2014) many frequently encountered NP-complete CO problems can be reformulated in terms of a particular class of models known as Ising models which therefore allow the representation of different CO problem types in a unified manner. In this context the CO problem is equivalent to finding the minimum of an energy function \(E:\{-1,1\}^{N}\). This function assigns an energy \(E()\) to an N-tuple of discrete solution variables \(=(_{1}_{N})\{-1,1\}^{N}\) which are often referred to as spins. The family of aforementioned Ising models is characterized by the following form of the energy function:

\[E()=_{i<j}J_{ij}_{i}_{j}+_{i}^{N}B_{i}_{i},\] (1)

where the first term represents the interaction between spins \(_{i}\{-1,1\}\) through couplings \(J_{ij}\), while the second term determines the magnitude \(B_{i}\) of the contribution of an individual spin to the energy of the system. For brevity we will denote the parameters of the energy function \((J_{ij},B_{i})\) simply as \(E\). Hence, \(E\) will represent a CO problem instance while \(E()\) will denote the energy of a solution \(\) under an energy function with parameters \(E\). The Ising formulation for the four CO problem types studied in this work is given in Tab. 1.

**Variational Learning.** Next, we specify how we approach the learning problem of approximating the optimal solution for a given problem instance. We follow the frequently taken variational learning approach of using a neural network with parameters \(\) to obtain for a given CO problem instance \(E\) as associated probability distribution \(p_{}(|E)\) over the space of possible solutions \(\{-1,1\}^{N}\). The problem instances \(E\) are assumed to be independently sampled from a probability distribution \(q(E)\) with \(=(q)\). In this setting the learning problem can be formulated as finding \(_{}_{}q(E)_{}p_{}( |E)E()\). Here \(_{}\) is a shorthand for the sum over all \(\{-1,1\}^{N}\). In practice both sums are approximated by empirical averages over samples from the corresponding distributions \(q\) and \(p_{}\). In CO \(E()\) is typically characterized by many local minima. Therefore, directly approaching the learning problem described above via gradient descent methods is prone to getting stuck at sub-optimal parameters. As we demonstrate in Fig. 1 (Right) this problem can be alleviated by adding a regularization term to the optimization objective Eq. 1 which encourages \(p_{}\) to avoid a collapse to local minima. The resulting loss function \(L:\{-1,1\}^{N}\) associated to the learning problem is given by:

\[L(;)=_{m=1}^{M}(;,E_{m}),\] (2)

where \(M\) is the number of CO problem instances \(E_{m}\) in one batch and \(\) plays the role of a regularization coefficient which is frequently referred to as the inverse temperature \(1/T\). The loss for an individual problem instance \(E_{m}\) is based on the so-called free-energy \(F(;,E_{m})\):

\[F(;,E_{m})=_{}p_{}(|E_{m})E_ {m}()+1/ p_{}(|E_{m}).\] (3)

In practice, we approximate the expectation value \(F(;,E_{m})\) with an empirical sample average \((;,E_{m})\) that is based on \(n_{S}\) samples \( p_{}(|E_{m})\). The term \(E_{m}()\) on the right-hand side of Eq. 3 encourages the concentration of \(p_{}(|E_{m})\) on low-energy solutions. Small values of the regularization parameter \(_{>0}\) encourage \(p_{}(|E_{m})\) to have a large entropy. For a given value of \(\) the free-energy in Eq. 3 is known to be minimized by the Boltzmann distribution associated to \(E_{m}\) (see e.g. ):

\[p_{B}(|E_{m},)=()}{_{ {}^{}}- E_{m}(^{})}.\] (4)

Thus by minimizing \(L\) the model learns to approximate \(p_{B}(|E_{m},)\) for a given \(E_{m}\) and \(\). For \(\) the \(p_{B}(|E_{m},)\) has its mass concentrated on the global minima of \(E_{m}\) and for \( 0\) it approaches the uniform distribution . It is, therefore, to be expected that the minimization of \(L\) becomes harder at low temperatures, i.e. as \(\), which opens the opportunity to a principled curriculum learning approach (Sec. 4). Based on these considerations we reformulate CO problems as the variational problem of approximating \(p_{B}(|E_{m},)\) in the limit \(\) with a variational ansatz \(p_{}\) that has the variational parameters \(\). This problem can be formalized as \(*{argmin}_{}_{}L(;)\).

## 3 Variational Annealing on Graphs

Our method VAG-CO addresses CO as a variational learning problem on graphs. In particular, given a set of CO problem instances it learns to approximate the Boltzmann distribution of the corresponding Ising models (Sec. 2) with an autoregressive distribution. To obtain efficient training with this expressive model we apply an annealed entropy regularization. We formulate this learning problem in an RL setting and use PPO to train our model. To alleviate the lengthy sampling process of autoregressive approaches we introduce sub-graph tokenization which allows us to generate multiple solution variables at in a single step without loosing expressive power. We further improve the memory efficiency of our approach by dynamically pruning the graph which represents the CO problem instance.

**Autoregressive Solution Generation.** In the following we specify how we represent \(p_{}(|E_{i})\) and how to sample it, i.e. how to generate solutions \(\).

1. Draw a problem instance \(E=(B_{i},J_{ij}) q(E)\) from the data distribution \(q\) and construct a graph \(G=(V,)\) based on \(E\). The nodes \(_{i} V\) correspond to the spins \(_{i}\) and the set of edges \(\) represents the non-zero components of \(J_{ij}\). The graph \(G\) is equipped with node features \(x_{i}=[B_{i},t_{i}]\) that are associated to its nodes \(_{i}\). Here \(t_{i}\) is a four dimensional one-hot encoding which indicates the four possible states (I-IV) of a node \(_{i}\) namely whether the corresponding spin \(_{i}\) is set to the value \(+1\) (I) or \(-1\) (II) or whether it is to be generated in the current step (III) or afterwards (IV). The edges between nodes \(_{i}\) and \(_{j}\) are associated with the scalar edge features \(J_{ij}\).
2. Order the graph nodes according to the breadth-first search (BFS) algorithm. The \(i\)-th node in this ordering is denoted as \(_{i}\). Now \(i=1\) and \(t_{i}\) is set to the state (III) and all \(t_{>i}\) are set to (IV).
3. A GNN is used to parameterize a Bernoulli distribution \(p_{}(_{i}|G)=*{GNN}_{}(G)\) from which the value \( 1\) of \(_{i}\) is sampled. The state encoding variables of \(G\) are updated by setting \(t_{i}\) associated to the graph is now updated accordingly and \(t_{i+1}\) is set to (III). Now \(i\) is incremented.
4. The previous step is repeated until the values of all \(_{i}\) are set.

We note that at each step \(i\) the graph \(G\) depends on the problem instance \(E\) and the already generated spins \(_{<i}\). Therefore this procedure represents an autoregressive parametrization of a distribution over the space of possible solutions \(\{-1,1\}^{N}\). By denoting the graph \(G\) at step \(i\) as \(G_{i}\) we get:

\[p_{}(|E)=_{i=1}^{N}p_{}(_{i}| _{<i},E)=_{i=1}^{N}p_{}(_{i}|G_{i}).\] (5)

This approach is more expressive than MFA and can therefore be expected to be better suited to approximate the typically complex Boltzmann distributions (Eq. 4) encountered in CO. Next we specify how we realize a stable training procedure by employing RL methods. The model architecture and hyperparameters are detailed in App. A.10.

**Reinforcement Learning Setting.** To explain how we train our model it is convenient to adopt an RL perspective where an episode corresponds to the solution generation procedure described above. For this we consider a Markov Decision Process (MDP) that is given by \((S,A,P,R)\). Here, \(S\) is the set of possible states and the state at step \(i\) is denoted by \(s_{i} S\). At each step \(s_{i}\) is represented by the graph \(G_{i}\). Given a state \(s_{i}\) an action \(a_{i}\) that represents the assignments of the spin value \(_{i}\{-1,1\}\) is sampled from a probability distribution which is parameterised by the policy \(p_{}(_{i}|G_{i})\). After sampling an action the reward \(R_{i}(G_{i},)\) is computed according to an objective that is based on Eq. 3. We use the relation \(F(;,E)=-}_{ p_{}}[ _{i=1}^{N}R_{i}(G_{i},)]\) and define the reward at step \(i\) as

\[R_{i}(G_{i},)=-[ E_{i}+\, p_{ }(_{i}|_{<i},E)],\] (6)

where \( E_{i}=_{i}[_{j<i}J_{ij}_{j}+B_{i}]\). With this definition maximising the reward is equivalent to minimizing the free-energy in Eq. 3. We approximate \(F(;,E)\) with the empirical mean of \(-_{i=1}^{N}R_{i}(G_{i},)\) based on \(n_{S}\) samples \( p_{}(_{i}|_{<i},E)\). Finally, the state is changed deterministically, i.e. the spin \(_{i}\) is set according to the sampled action \(a_{i}\). The state update corresponds to the updated of \(t_{i}\) and \(t_{i+1}\) as described in step 3 of the solution generation procedure. Our model learns to solve this MDP via the popular PPO algorithm (Schulman et al., 2017) which is described in more detail in App. A.9.

**Annealing.** As discussed in Sec. 2 our training objective is based on Eq. 3 which contains an entropy regularization term. The strength of this regularization is determined by temperature \(T\). At first, the temperature is kept constant at \(T>0\) for \(N_{}\) steps. Then, the temperature is slowly adapted for \(N_{}\) steps by following a predefined annealing schedule (see App. A.14) that converges to \(T=0\) as the end of training is reached. This reduction of the temperature throughout training is motivated from a theoretical point of view in Sec. 4.

**Subgraph Tokenization.** By introducing subgraph tokenization we decrease the number of forward passes per CO problem instance without sacrificing expressivity. Instead of modelling the probability for the two possible values \( 1\) of a single spin, we let the policy represent a probability distribution \(p_{}(_{i:i+k}|_{<i},E)\) over all \(2^{k}\) possible configurations of \(k\) consecutive spins in the BFS ordering (step 2 of the solution generation procedure). We represent \(p_{}(_{i:i+k}|_{<i},E)\) with a softmax function of a \(2^{k}\) dimensional vector that is output by the GNN (App. A.10). Subgraph tokenization represents a modification of step 3 of the solution generation procedure and yields an improvement of the performance (Sec. 6).

**Dynamic Graph Pruning.** We note that once the spin value of \(_{i}\) is sampled its interaction with adjacent spins \(_{j}\) is fixed. Therefore, assuming that we have sampled the first spin \(_{1}\), its interaction with an adjacent spin \(_{j}\), that is yet to be generated, can be expressed as \(B(1 j)_{j}_{j}\), where we introduce \(B(1 j)_{j}=J_{1j}_{1}\). Therefore, we can immediately remove generated spins from the graph and update the node embeddings \(x_{j}=[B_{j},t_{j}]\) of adjacent nodes with \(B_{j} B_{j}+B(i j)_{j}\). Reducing the graph size during the solution generation process has the benefit of reducing the memory requirements when processing graphs with a GNN as in step 3 of the solution generation procedure.

Theoretical Motivation of Annealing

In the following we show that the concept of an annealed entropy regularization in Eq. 3 can be motivated based the sample complexity of density estimation for Boltzmann distributions.

Consider the problem of approximating the probability density function of a Boltzmann distribution \(p_{B}(s;E,)\), where \(E:^{}[0,1]\) is a suitably normalized energy function. To solve this task we are given a set of samples \(=\{s_{1},,s_{m}\}\) which are independently drawn from the corresponding target Boltzmann distribution \(p_{B}(s;E,^{*})\) at a fixed inverse temperature \(^{*}\). For brevity we will denote the distribution associated to \(p_{B}(s;E,)\) from now on as \(p()\) where \(E\) is suppressed since it is a fixed function. The empirical distribution corresponding to \(\) will be denoted as \(\). Further assume that we can evaluate \(E(s_{i})\) for all \(s_{i}\).

In the present context a natural feasibility criterion for the estimated distribution is that the expectation value of the energy function for the estimated distribution should be compatible with the corresponding value \(_{p(^{*})}E(s)\) of the target distribution. We approach this problem with the maximum entropy principle (Jaynes, 1957). Informally, this principle prescribes that among all feasible distributions one should prefer the one that yields the highest entropy. Since \(\) contains only a finite number of samples we cannot determine \(_{p(^{*})}E(s)\) with arbitrary accuracy. As already stated in a similar form in (Dudik et al., 2007) one obtains with Hoeffding's inequality that with a probability of \(1-\):

\[|_{p(^{*})}E(s)-_{}E(s)|<.\] (7)

As shown in (Kazama and Tsujii, 2003) the resulting maximum entropy optimization problem with the inequality constraint Eq. (7) is equivalent to the following regularized maximum likelihood problem over the family of Boltzmann distributions: \(_{}_{}()+\), where \(_{}()=-_{} p()\) is the cross-entropy between \(\) and \(p()\). Based on a closely related result in (Dudik et al., 2007) we obtain the following bound for the approximation of maximum entropy distributions:

**Remark 1**.: _Assume a bounded energy function \(E:^{}[0,1]\) and let \(\) minimize \(_{}()+||\) where \(=\). Then with a probability at least \(1-\):_

\[D_{KL}p(^{*})||p()|}{}.\] (8)

See App. A.15.2 for further details. According to Eq. 8 the sample complexity of approximating a maximum entropy distribution at an inverse temperature \(\) is in \(O(^{2})\).

Curriculum learning is a machine learning paradigm in which the difficulty of training tasks is gradually increased as training proceeds (Bengio et al., 2009). In view of Theorem 1 the entropy annealing in VAG-CO (Sec. 3) can be regarded as a principled curriculum learning approach if an increased sample complexity is regarded as an indication of a more difficult learning problem. In supervised learning tasks Wu et al. (2021) find that the application of curriculum learning results in more resource efficient training but not necessarily in better performance. As we demonstrate in Sec. 6 our entropy annealing does actually yield better performing models.

## 5 Related Work

As pointed out in (Yehuda et al., 2020) supervised training of CO solvers faces the problem of expensive data generation and that data augmentation cannot circumvent this problem. Consequently, there is a growing interest in RL and unsupervised methods. In the following we focus on methods that attempt to learn how to generate solutions rather than how to improve existing ones.

**Unsupervised Learning and Reinforcement Learning.** The work of (Bello et al., 2017) proposes to use an actor-critic approach to learn how to solve CO problems. They were the first to show that deep RL is a promising approach for CO. Their method represents an autoregressive distribution over solutions. However, in their setting rewards are sparse since they are only available for complete solutions. In our approach rewards are dense since they are available after every state transition. Another influential work is (Khalil et al., 2017) who were the first to exploit the graph structure of CO problems by learning problem representations with GNNs. Applying GNNs to CO problem has become a common choice since then (Cappart et al., 2021). In (Tonshoff et al., 2020) the method RUN-CSP is introduced. The work of (Karalias and Loukas, 2020) proposes Erdos Goes Neural (EGN) in which the goal is to minimize a loss that can be regarded as a certificate of the existence of a CO problem solution whose cost is upper bounded by the loss. By relying on an MFA they can calculate this loss efficiently. Also (Qiu et al., 2022) use an MFA to optimize a distribution over the solution space and optimize the corresponding parameters with gradient estimates that are obtained by REINFORCE. The work of (Min et al., 2022) uses the same MFA-based concept as EGN and focuses on alleviating the oversmoothing problem of GNNs by using modified Graph Convolutional Networks (Kipf and Welling, 2017). An approach based on an entry-wise concave continuous relaxation of the discrete CO loss and a subsequent rounding procedure for integral solution generation is introduced in (Wang et al., 2022). Here the concept of (Karalias and Loukas, 2020) is generalized to a wider class of problems and rather simple rounding procedure is introduced to generate solutions efficiently. This approach is further extended by (Wang and Li, 2023) to a meta-learning setting called Meta-EGN in which network parameters are updated for individual CO problem instances. They also argue that RL based CO methods suffer from unstable training. We call this claim into question by finding no stability issues with our RL-based method. Further VAG-CO outperforms EGN and even Meta-EGN despite not updating any parameters on test problem instances. The approach of extending functions on sets to continuous supports is taken in Neural Set Function Extensions (NSFE) (Karalias et al., 2022). In NSFE the discrete CO loss function is replaced with a convex combination of the discrete loss function values at certain integral solutions. These extensions can be regarded as expectation values that can be calculated in closed form without sampling. Whether the lack of sampling noise in NSFE is beneficial for the optimization procedure is not obvious.

**Variational Annealing.** The concept of using autoregressive models in the variational problem of approximating Boltzmann distributions of Ising models was introduced by (Wu et al., 2019). They show that variational annealing (VA), i.e. the combination of the variational approach and temperature annealing, is a highly performant method. The work of (Hibat-Allah et al., 2021) compares VA to other ones like Simulated Annealing (SA) (Kirkpatrick et al., 1983) and confirms its strong performance on problems related to spin glasses. In (Khandoker et al., 2023) the strong performance of VA compared to SA is confirmed on CO problems. A crucial aspect of these works on VA with respect to ours and the ones in the previous paragraph is that they optimize the parameters of their models only for individual problem instances. They do not attempt to learn how to generalize over a family of problems. The work of (Sun et al., 2022) aims at a generalizing application of VA in CO by using an MFA. Our experiments indicate that the simplicity of MFA-based methods leads to performance limitations in particular on hard CO problem instances.

## 6 Experiments

We evaluate VAG-CO on various CO problems that are studied in the recent literature. Additionally, we evaluate VAG-CO on synthetic datasets where solving the corresponding CO problem is known to be particularly hard. Finally, we discuss experiments on the impact of entropy regularization and subgraph tokenization. Our result tables also include inference runtimes. A quantitative runtime comparison is, however, difficult since the runtimes reported from other works and for Gurobi 10.0.0 (Gurobi Optimization, LLC, 2023) were obtained with differen setups. See App. A.12 for details on the runtime measurements. For Gurobi we report results for various different runtime limits.

**Maximum Independent Set.** In the following we will compare VAG-CO on the Maximum Independent Set (MIS) problem to recently published results from (Karalias et al., 2022), where the graph datasets COLLAB, ENZYMES and PROTEINS Morris et al. (2020) are used. In the MIS problem the task is to find the largest subset of independent, i.e. unconnected, nodes in a graph. As an optimization objective for VAG-CO we use Eq. 2 with the Ising energy function for MIS (see Tab. 1). Here, the energy function \(E()\) consists of two terms \(E_{A}()\) and \(E_{B}()\), that depend on the binary representation of the solution \(=+1}{2}\) with \(\{0,1\}^{N}\). When \(q_{i}=1\) the corresponding node is defined to be included in the set and it is excluded otherwise. The first term \(E_{A}()\) is proportional to the number of nodes that are in the set, whereas \(E_{B}()\) is proportional to the number of independence violations, i.e. the number of connected nodes within the set. By selecting \(A,B_{+}\) such that \(A<B\) we ensure that all minima satisfy \(E_{B}=0\) since in this case excluding a violating node from the set always reduces the energy. In our experiments, we choose \(A=1.0\) and \(B=1.1\).

We follow the procedure of (Karalias et al., 2022) and use a \(0.6/0.1/0.3\) train/val/test split on the aforementioned datasets and use only the first 1000 graphs on the COLLAB dataset. The resultsare shown in Tab. 2 where the test set average of the best approximation ratio \(^{*}\) out of \(n_{S}=8\) sampled solutions per graph is reported (see App. A.1). This metric was originally proposed in (Karalias and Loukas, 2020). We also report results of our own implementation of an MFA-based method that is trained with REINFORCE. This method is used with (MFA-Anneal) and without (MFA) annealing (App. A.5). As in Wang and Li (2023) and Karalias and Loukas (2020) we use the conditional expectation procedure (CE, App. A.5.5) to sample solutions and report the corresponding results as (MFA: CE) and (MFA-Anneal: CE). We also add results obtained by the Degree Based Greedy (DB-Greedy) algorithm (Wormald, 1995) that is proposed by (Angelini and Ricci-Tersenghi, 2023) as a baseline for machine learning algorithms on MIS. For VAG-CO we greedily sample different states for a given problem instance by using different BSF orderings of the corresponding graph nodes. Our results show that VAG-CO significantly outperforms all competitors including the MFA on ENZYMES and PROTEINS. On IMDB-BINARY and MUTAG the MFA-based approaches and VAG-CO outperform all other machine learning methods and achieve an optimal \(^{*}\). On COLLAB MFA-Anneal and VAG-CO exhibit the best results with insignificantly better results for MFA-Anneal. We also report results based on the test set average of the approximation ratio with \(n_{S}=30\)\(}\) (App. A.1). This metric shows the performance of the learned probability distribution for each model, when no post processing is applied. Our results show that VAG-CO always achieves a significantly better performance in terms of \(}\) than MFA-based approaches.

**Minimum Vertex Cover.** We compare VAG-CO to results from Wang and Li (2023) where the Minimum Vertex Cover (MVC) problem is solved on the TWITTER (Leskovec and Krevl, 2014), COLLAB and IMDB-BINARY Morris et al. (2020) graph datasets. The MVC problem is the task of finding the smallest subset of vertices such that each edge has at least one node in the subset. As for the MIS problem we formulate this CO problem in terms using the Ising energy function that is defined in Tab. 1 and set \(A=1.0\) and \(B=1.1\). We follow the procedure of Wang and Li (2023) and use a \(0.7/0.1/0.2\) train/val/test split on these datasets. Their method Meta-EGN uses meta

 Problem Type & Ising formulation: \(_{q}E()\) where \(E()=E_{A}()+E_{B}()\) \\  MVC & \(E()=A\)\(_{i}^{N}q_{i}+B,_{(i,j)}(1-q_{i})(1-q_{j})\) \\  MIS & \(E()=-A_{i}^{N}q_{i}+B_{(i,j)}q_{i} q_{j}\) \\  MaxCl & \(E()=-A_{i}^{N}q_{i}+B_{(i,j)}q_{i} q_{j}\) \\  MaxCut & \(E()=-_{(i,j)}_{j}}{2}\)  where \(_{i}=2\,q_{i}-1\) \\ 

Table 1: Ising formulations of the MVC, MIS, MaxCl and MaxCut problem ((Lucas, 2014)). The term that includes the constant \(A\) corresponds to \(E_{A}(q)\) and the term that includes the constant \(B\) corresponds to \(E_{B}(q)\).

  & ENZYMES & PROTEINS & IMDB-BINARY & COLLAB & MUTAG \\  Evaluation metric A.1 & \(AR^{*}\) (\(\) ) & \(AR^{*}\) (\(\) ) & \(AR^{*}\) (\(\) ) & \(AR^{*}\) (\(\) ) \\  BGN (\(\)) & \(0.821 0.124\) (\(\)) & \(0.963 0.114\) (\(\)) & \(0.515 0.310\) (\(\)) & \(0.886 0.198\) (\(\)) & \(0.539 0.063\) (\(\)) \\ NSFG (\(\)) & \(0.725 0.155\) (\(\)) & \(0.729 0.205\) (\(\)) & \(0.679 0.287\) (\(\)) & \(0.836 0.253\) (\(\)) & \(0.854 0.132\) (\(\)) \\ REINFORCE (\(\)) & \(0.751 0.301\) (\(\)) & \(0.725 0.285\) (\(\)) & \(0.881 0.240\) (\(\)) & \(1.000 0.031\) (\(\)) & \(0.781 0.016\) (\(\)) \\ Straight-through (\(\)) & \(0.725 0.268\) (\(\)) & \(0.722 0.26\) (\(\)) & \(0.917 0.253\) (\(\)) & \(0.856 0.221\) (\(\)) & \(0.965 0.162\) (\(\)) \\  DB-Greedy & \(0.980 0.009\) (\(\)) & \(0.9848 0.003\) (\(\)) & \(1.000 0.007\) & \(0.9988 0.0001\) (\(\)) & \(0.994 0.001\) (\(\)) \\ MFA-CE & \(0.9875 0.001\) (\(\)) & \(0.9883 0.0007\) (\(\)) & \(1.000 0.022\) & \(0.9995 0.0004\) (\(\)) & \(1.000 0.019\) \\ MFA-Anneal & CE & \(0.9880 0.0014\) (\(\)) & \(0.981 0.0007\) (\(\)) & \(1.000 0.022\) & \(0.9991 0.0004\) (\(\)) & \(1.000 0.019\) \\ VAG-CO (\(\)) & \(0.9960 0.0007\) (\(\)) & \(0.9977 0.0052\) (\(\)) & \(1.000 0.017\) & \(0.9988 0.0009\) (\(\)) & \(1.000 0.015\) \\  Gurbin (\(t_{max}=0.01\)) & \(1.000 0.001\) & \(0.9996 0

[MISSING_PAGE_FAIL:8]

**Evaluation on Synthetic Problems for MIS.** On many of the benchmarks above nearly optimal results are obtained. Therefore, we conduct additional experiments on synthetic graph datasets that yield hard CO problems.

For graphs with a degree \(d\) larger than \(16\) the MIS problem on random regular graphs (RRGs) is known to be particularly hard . Therefore, we generate RRGs with an average size of 100 nodes (RRG-100), where we sample \(4100\) RRGs between the size of 80 to 120 with different degrees \(d\). For training, validation and testing we use \(3000/100/1000\) graphs. Results for the MIS problem on the RRG-100 dataset are shown in Fig. 1 (Left), where we plot the test set average of the best relative error \(_{}^{*}\) out of \(n_{S}=8\) sampled solutions per problem instance. Here the relative error is calculated with respect to exact solutions that are obtained with the commercial solver Gurobi. Error bars indicate the standard error over graphs with the corresponding node degree. As expected we find that for all methods \(_{}^{*}\) increases for larger degrees. MFA and MFA-Anneal outperform the DB-Greedy method. Furthermore, VAG-CO is the best performing method for all graph degrees. We also show Gurobi performance for each \(d\) at different time limits \(t_{}\). On this dataset VAG-CO outperforms Gurobi with the given compute budged (see App. A.12) by a high margin on hard instances.

**Evaluation on Synthetic Problems for MVC.** We also conduct experiments on graphs that are generated by the so-called RB method . This method allows the generation of graphs that are known to yield hard MVC problem instances . The RB model has three distinct generation parameters: \(n,k^{}\), and \(p\). Adjusting the values of \(n\) and \(k^{}\) allows us to control the expected size of the generated graphs, while \(p\) serves as a parameter to regulate the hardness of the graph instances. Specifically, when \(p\) is close to one, the generated graphs tend to be easier, whereas reducing \(p\) leads to increased difficulty. To ensure diversity in the RB dataset, we generate graphs with varying levels of hardness randomly sampling \(p\) from the range of \(0.25\) to \(1.0\). For our experiments, we utilize the RB-200 dataset, consisting of RB graphs with an average size of \(200\) nodes with a train/val/test split of \(2000/500/1000\) graphs. Following  each graph in this dataset is generated by randomly selecting values for \(n\) from the range of \(20\) to \(25\), and \(k^{}\) from the range of \(9\) to \(10\). Figure 1 (Middle) shows the corresponding results in terms of \(

   & **MDB-NNX** \\  Evaluation metric A.1 & _AR*_ (r.g/graph) & _ARP*_ (r.g/graph) \\  EGN (r) & 0.83 \(\) 0.145 (N/A) & 0.936 \(\) 0.175 (N/A) \\ NSFE (r) & 0.933 \(\) 0.148 (N/A) & 0.961 \(\) 0.143 (N/A) \\ REINFORCE (r) & 0.751 \(\) 0.301 (N/A) & 0.881 \(\) 0.240 (N/A) \\ Straight-Graph (r) & 0.725 \(\) 0.208 (N/A) & 0.917 \(\) 0.253 (N/A) \\  DB-Greedy & 0.945 \(\) 0.0034 (0.02) & 0.9875 \(\) 0.0038 (0.010) \\ MFA. CE & 0.976 \(\) 0.001 (0.04) & **0.999 \(\) 0.000** (0.025) \\ MFA-Anneal: CE & **0.9921 \(\) 0.0017** (0.04) & **0.999 \(\) 0.0001** (0.025) \\ VAG-CO (ours) & **0.987 \(\) 0.0042** (0.029) & **0.9981 \(\) 0.0013** (0.017) \\  Gurobi (\(t_{}=0.1\)) & 0.963 \(\) 0.0020 (0.04) & 0.996 \(\) 0.0020 (0.01) \\ Gurobi (\(t_{}=0.1\)) & 1.000 (0.005) & 1.003 (0.002) \\  Evaluation metric A.1 & \(}\) (time \(\)/s/mpl) & \(}\) (time \(\)/s/mpl) \\  MFA & 0.964 \(\) 0.0133 (0.001) & 0.983 \(\) 0.0094 (0.001) \\ MFA-Anneal & 0.806 \(\) 0.004 (0.001) & 0.974 \(\) 0.0041 (0.017) \\ VAG-CO (ours) & **0.943 \(\) 0.012** (0.029) & **0.993 \(\) 0.0013** (0.017) \\   
   \\  }\)Cut (s/graph)} \\  Gurobi (\(t\)) & 732.47 (1.57) \\ SDP (\(t\)) & 700.36 (4.29) \\ Greedy (\(t\)) & 688.31 (0.026) \\ EGN (\(t\)) & 693.45 (0.092) \\ Anneal (\(t\)) & 696.73 (0.09) \\ GFlowNet (\(t\)) & 704.30 (0.35) \\  VAG-CO (ours) & **722.31** (0.17) \\  Gurobi (\(t_{}=0.1\)) & 731.34 (0.1) \\ Gurobi (\(t_{}=1.)\) & 731.79 (1.) \\ Gurobi (\(t_{}=2.)\) & 732.00 (2.) \\ Gurobi (\(t_{}=10.)\) & 732.01 (10.) \\  

Table 4: Left: Results on the Maximum Clique Problem (see Tab. 1). We show test set results on the best approximation ratio \(AR\)* and the average approximation ratio \(}\) across different methods and datasets. Values that are closer to one are better. (r) indicates that these are results as reported in . The time for each algorithm is reported in round brackets as seconds per graph. Right: Results on the Maximum Cut Problem (see Tab. 1) on BA \(200-300\) graphs. We show test set results on the average maximum cut value \(}\) across different methods. Values that are larger are better. (r) indicates that these are results as reported in .

Figure 2: Study on the advantages of larger ST configuration sizes \(k\) for VAG-CO on the RB-100 MVC dataset. On the left y-axis we plot \(AR\)* (lower values are better) for VAG-CO models that are trained for values of \(k\). The left y-axis shows the inference time per graph.

of \(p\). We find that the DB-Greedy algorithm outperforms both MFA approaches. The MFA with annealing tends to perform worse than the MFA without annealing on this dataset. Here, we also add our own implementation of EGN and EGN-Anneal (Sun et al., 2022) and find that EGN performs similarly to MFA and EGN-Anneal achieves a similar performance as DB-Greedy. VAG-CO outperforms all other methods for all values of \(p\) on this dataset. We also show Gurobi performance for each \(p\) at different time limits \(t_{}\). Here, we see that at high \(p\) values Gurobi achieves close to optimal results within a very small time budged and is the best performing method. Whereas for low p values Gurobi performance drops by a high margin and VAG-CO achieves similar results within a comparable time.

**Ablation on Annealing.** In the following we investigate whether the annealed entropy regularization in Eq. 3 is indeed beneficial. These experiment are conducted for the MVC problem on RB-100 graphs that are generated with \(n\), \(k^{{}^{}}\) and \(p[0.25,1]\). We compare VAG-CO test set learning curves with three different initial temperatures \(T_{0}\{5 10^{-2},5 10^{-3},0\}\). The run with \(T_{0}=0\) is equivalent to VAG-CO without annealing (App. A.14). Figure 1 (right) shows the average relative error \(_{}\) for \(n_{S}=30\) sampled solutions per problem instance on the test set over the number of gradient update steps. We find that the run without annealing starts to converge rather quickly but at a comparably bad relative energy. In contrast to that, the runs with annealing (\(T_{0}\{5 10^{-2},5 10^{-3}\}\)) keep improving over more steps and achieve a better final performance.

**Ablation on Subgraph Tokenization.** Next we study the impact of subgraph tokenization (see Sec. 3) on the performance of VAG-CO. The same problem setting as in the annealing ablation above is used. Figure 1 (right) compares VAG-CO with the default \(k=5\) subgraph tokenization (w/ ST) to VAG-CO without subgraph tokenization (w/o ST). For a fair comparison the numbers of gradient update steps and the annealing schedules are set to be equal. We find that with subgraph tokenization we achieve a considerably better \(_{}\). These results underpin that subgraph tokenization does indeed yield an improved efficiency in terms of gradient update steps.

We additionally provide a more detailed investigation on ST, where we compare VAG-CO with four different values of \(k\{1,2,5,10\}\) on the RB-100 MVC dataset. In our experiments we keep the number of gradient update steps constant and iteratively tune for the best learning rate and the best initial temperature in each setting of \(k\). Results are shown in Fig. 2, where \(AR^{}\) and the average time per graph are plotted over \(k\). As \(k\) increases the performance in terms of \(AR^{}\) does improve and the inference time is reduced considerably. This experiment underscores the performance and scalability improvement due to ST.

## 7 Limitations

While MFA-based approaches typically generate a solution to a CO problem in a single forward pass VAG-CO requires a number of forward passes that is proportional the problem size \(N\). However, methods with solution generation in a single forward pass frequently rely on post-processing procedures like CE that have a time complexity which is also linear in \(N\). In our approach the nodes in the graph are always processed in an order that is determined by a BFS. Therefore studying the impact of other node orderings or making the algorithm invariant to such orderings might be an interesting future research direction. For the annealing schedule we report comparisons for VAG-CO with three different initial temperatures but a comprehensive study on the optimization of the annealing schedule is left to future investigations.

## 8 Conclusion

Our results show that learning to solve hard CO problems requires sufficiently expressive approaches like autoregressive models. With VAG-CO we introduce a method that enables stable and efficient training of such a model through an annealed entropy regularization. We provide a theoretical motivation for this regularization method and demonstrate its practical benefit in experiments. In addition, we demonstrate that by systematically grouping solution variables VAG-CO achieves an improved performance with respect to a naive autoregressive model. Importantly VAG-CO outperforms recent approaches on numerous benchmarks and exhibits superior performance on synthetic CO problems that are designed to be hard.

Acknowledgements

We thank Gunter Klambauer for useful discussions and comments. The ELLIS Unit Linz, the LIT AI Lab, the Institute for Machine Learning, are supported by the Federal State Upper Austria. We thank the projects AI-MOTION (LIT-2018-6-YOU-212), DeepFlood (LIT-2019-8-YOU-213), Medical Cognitive Computing Center (MC3), INCONTROL-RL (FFG-81064), PRIMAL (FFG-873979), S3AI (FFG-872172), DL for GranularFlow (FFG-871302), EPILEPSIA (FFG-892171), AIRI FG 9-N (FWF-36284, FWF-36235), AL4GreenHent eatingGrids(FFG-89943), INTEGRATE (FFG-892418), ELISE (H2020-ICT-2019-3 ID: 951847), Stars4Waters (HORIZON-CL6-2021-CLIMATE-01-01). We thank Audi.JKU Deep Learning Center, TGW LOGISTICS GROUP GMBH, Silicon Austria Labs (SAL), FILL Gesellschaft mbH, Anyline GmbH, Google, ZF Friedrichshafen AG, Robert Bosch GmbH, UCB Biopharma SRL, Merck Healthcare KGaA, Verbund AG, GLS (Univ. Waterloo) Software Competence Center Hagenberg GmbH, TUV Austria, Frauscher Sensonic, TRUMPF and the NVIDIA Corporation.