# 3D Indoor Instance Segmentation in an Open-World

Mohamed El Amine Boudjoghra\({}^{1}\), Salwa K. Al Khatib\({}^{1}\), Jean Lahoud\({}^{1}\),

**Hisham Cholakkal\({}^{1}\), Rao Muhammad Anwer\({}^{1,2}\), Salman Khan\({}^{1,3}\), Fahad Shahbaz Khan\({}^{1,4}\)**

\({}^{1}\)Mohamed Bin Zayed University of Artificial Intelligence (MBZUAI),

\({}^{2}\)Aalto University, \({}^{3}\)Australian National University, \({}^{4}\)Linkoping University

{mohamed.boudjoghra, salwa.khatib, jean.lahoud,

hisham.cholakkal, rao.anwer, salman.khan, fahad.khan}@mbzuai.ac.ae

###### Abstract

Existing 3D instance segmentation methods typically assume that all semantic classes to be segmented would be available during training and only seen categories are segmented at inference. We argue that such a closed-world assumption is restrictive and explore for the first time 3D indoor instance segmentation in an open-world setting, where the model is allowed to distinguish a set of known classes as well as identify an unknown object as unknown and then later incrementally learning the semantic category of the unknown when the corresponding category labels are available. To this end, we introduce an open-world 3D indoor instance segmentation method, where an auto-labeling scheme is employed to produce pseudo-labels during training and induce separation to separate known and unknown category labels. We further improve the pseudo-labels quality at inference by adjusting the unknown class probability based on the objectness score distribution. We also introduce carefully curated open-world splits leveraging realistic scenarios based on inherent object distribution, region-based indoor scene exploration and randomness aspect of open-world classes. Extensive experiments reveal the efficacy of the proposed contributions leading to promising open-world 3D instance segmentation performance. Code and splits are available at: https://github.com/aminebdj/3D-OWIS.

## 1 Introduction

3D semantic instance segmentation aims at identifying objects in a given 3D scene, represented by a point cloud or mesh, by providing object instance-level categorization and semantic labels. The ability to segment objects in the 3D domain has numerous vision applications, including robotics, augmented reality, and autonomous driving. Following the developments in the sensors that acquire depth information, a variety of datasets has been presented in the literature which provides instance-level annotations. In view of the availability of large-scale 3D datasets and the advances in deep learning methods, various 3D instance segmentation methods have been proposed in recent years.

The dependence of 3D instance segmentation methods on available datasets has a major drawback: a fixed set of object labels (vocabulary) is learned. However, object classes in the real world are plentiful, and many unseen/unknown classes can be present at inference. Current methods that learn on a fixed set not only discard the unknown classes but also supervise them to be labeled as background. This prevents intelligent recognition systems from identifying unknown or novel objects that are not part of the background. Given the importance of identifying unknown objects, recent works have explored open-world learning setting for 2D object detection . In the open-world setting, a model is expected to identify unknown objects, and once new classes are labeled, the new set is desired to be incrementally learned without retraining . While previous methods have been mostly suggested for open-world 2D object detection, it is yet to be exploredin the 3D domain. The main challenge lies in understanding how objects appear in 3D in order to separate them from the background and other object categories.

3D instance segmentation in the open world, illustrated in Fig. 1, offers more flexibility, allowing the model to identify unknown objects and request annotations for these novel classes from an oracle for further training. However, this approach presents several challenges: (i) the lack of annotations for unknown classes, necessitating quality pseudo-labeling techniques; (ii) the similarities between predicted features of known and unknown classes, requiring separation techniques for improved prediction; and (iii) the need for a more reliable objectness scoring method to differentiate between good and bad predicted masks for 3D point clouds.

In this work, we investigate a novel problem setting, namely open-World indoor 3D Instance Segmentation, which aims at segmenting objects of unknown classes while incrementally adding new classes. We define real-world protocols and splits to test the ability of 3D instance segmentation methods to identify unknown objects. In the proposed setup, unknown object labels are also added incrementally to the set of known classes, akin to real-world incremental learning scenarios. We propose an unknown object identifier with a probability correction scheme that enables improved recognition of objects. To the best of our knowledge, we are the first to explore 3D instance segmentation in an open-world setting. The key contributions of our work are:

* We propose the first open-world 3D indoor instance segmentation method with a dedicated mechanism for accurate identification of 3D unknown objects. We employ an auto-labeling scheme to generate pseudo-labels during training and induce separation in the query embedding space to delineate known and unknown class labels. At inference, we further improve the quality of pseudo-labels by adjusting the probability of unknown classes based on the distribution of the objectness scores.
* We introduce carefully curated open-world splits, having known vs. unknown and then incremental learning over the span of 200 classes, for a rigorous evaluation of open-world 3D indoor segmentation. Our proposed splits leverage different realistic scenarios such as inherent distribution (frequency-based) of object classes, various class types encountered during the exploration of indoor areas (region-based), and the randomness aspect of object classes in the open-world. Extensive experiments reveal the merits of the proposed contributions towards bridging the performance gap between our method and oracle.

## 2 Related Work

3D semantic instance segmentation:The segmentation of instances in 3D scenes has been approached from various angles. Grouping-based or clustering-based techniques use a bottom-up pipeline by learning an embedding in the latent space to help cluster the object points. [4; 13; 14; 17; 20; 21; 34; 38]. Proposal-based methods work in a top-down fashion, first detecting 3D bounding boxes, then segmenting the object region within the box [10; 15; 22; 36; 37]. Recently, spurred by related 2D work [5; 6], the transformer design  has also been applied for the purpose of segmenting 3D instances [29; 30]. Other methods present weakly-supervised alternatives to methods that use dense annotations in order to lower the cost of annotating 3D data [7; 16; 35]. While all these methods aim to improve the quality of 3D instance segmentation, they are trained on a known set of semantic labels. On the other hand, our proposed method aims at segmenting objects with both known and unknown class labels.

Figure 1: **3D instance segmentation in an open-world. During each iterative learning phase, the model detects _unknown_ objects, and a human operator gradually assigns labels to some of them and incorporates them into the pre-existing knowledge base for further training.**

**Open-world object recognition:** Open-world object recognition was introduced in , where the Nearest Mean Classifier was extended for an open-world setting. In the direction of open-world object detection, many studies [41; 18; 11; 25] have been conducted in the past. In, pseudo-labels for the unknowns are generated to perform contrastive clustering during training for a better unknown-known classes separation, where an energy-based unknown class identifier was proposed to detect the unknown classes, based on the energy of the logits from the known classes. For incremental learning, they adopted exemplar replay to alleviate catastrophic forgetting of old classes. In the same task as ,  used a transformer-based model and proposed another way of unknown pseudo-labels generation, by using a new method of objectness estimation, and introduced a foreground objectness branch that separates the background from the foreground. For the task of outdoor 3D point cloud semantic segmentation,  proposed a model that predicts old, novel, and unknown classes from three separate classification heads. The latter is trained on the labels of the known classes and pseudo-labels for old classes generated by the same model to alleviate catastrophic forgetting, while the unknown class is assigned the second-highest score for a better unknown class segmentation. Other methods proposed in [40; 12; 39], primarily focus on enhancing the generalizability of 3D models for novel classes by leveraging supervision from 2D Vision Language Models for object recognition and 3D semantic segmentation tasks. However, these approaches exhibit several limitations, including (i) The 3D model's performance becomes dependent on the 2D Vision Language model. (ii) The 3D geometric properties of unseen objects in the training data are neglected during the training process. (iii) There exists no avenue for enhancing the model's performance on novel classes in cases where new labels are introduced.(iv) The training process necessitates pairs of images and corresponding 3D scenes.

## 3 Closed-world 3D Instance Segmentation

We adopted the state-of-the-art 3D instance segmentation model Mask3D  as our baseline. The latter is a hybrid model that combines Convolutional Neural Networks (CNNs) with transformers to learn class-agnostic masks and labels for instance separation. The backbone of Mask3D is CNN-based and used to extract feature maps from multiple levels. Meanwhile, the decoder is transformer-based and used to refine \(n_{Q}\) instance queries \(Q=\{q_{j}^{D}~{}~{}|~{}~{}j(1,...,n_{Q})\}\), using the extracted

Figure 2: **Proposed open-world 3D instance segmentation pipeline.** From left to right: 3D instance segmentation model, where the point cloud goes through a 3D convolutional backbone. The extracted feature maps are used in the transformer decoder to refine some initial queries, which then pass through two MLPs to generate label and mask predictions. The Contrastive Clustering block takes the refined queries, the prediction masks, and labels to further process the queries by assigning a target or an _unknown_ pseudo label in the Query Processing module, and then storing them in a Query Store to finally update the class prototypes, which are finally used for contrastive clustering. During inference, the queries are used to correct the probability of the predicted labels based on their reachability to the _known_ class prototypes.

feature maps. The learning scheme consists of a Cross-entropy loss for learning semantic class labels and binary cross-entropy loss for learning instance masks during training.

## 4 Open-World 3D Instance Segmentation

### Problem formulation

We start by formulating the problem setting of open-world 3D instance segmentation. At a Task \(^{t}\), there exists a set of _known_ object categories \(^{t}=\{1,2,..,C\}\) and a set of _unknown_ object categories \(^{t}=\{C+1,...\}\) that may exist on inference time. The training dataset \(^{t}=\{^{t},^{t}\}\) includes samples from the classes \(^{t}\). The input set \(^{t}=\{_{1},..,_{M}\}\) is made of \(M\) point clouds, where \(_{i}^{N 3}\) is a quantized point cloud of \(N\) voxels each carrying average RGB color of the points within. The corresponding labels are \(^{t}=\{_{1},..,_{M}\}\), where \(_{i}=\{_{1},..,_{k}\}\) encodes \(k\) object instances. Each object instance \(_{i}=[_{i},l_{i}]\) represents a binary mask \(_{i}\{0,1\}^{N}\) and a corresponding class label \(l_{i}^{t}\).

In our problem setting, \(_{C}\) is a 3D instance segmentation model that is trained on \(C\) object categories, and, on test time, can recognize instances from these classes, in addition to instances from new classes not seen during training by classifying them as _unknown_. The detected _unknown_ instances can be used by a human user to identify a set of \(n\) new classes not previously trained on, which can be incrementally added to the learner that updates itself to produce \(_{C+n}\) without explicitly retraining on previously seen classes. At this point in Task \(^{t+1}\), the _known_ class object categories are \(^{t+1}=^{t}\{C+1,..,C+n\}\). This process repeats throughout the lifespan of the instance segmentation model, continuously improving itself by incorporating new information from new classes until it reaches its maximum capacity of classes it can learn. In the rest of the paper, We assign the _unknown_ class a label \(\).

### Open-world scenarios

In order to simulate different realistic scenarios that might be encountered in an open-world, we propose three different ways of grouping classes under three tasks. These scenarios split scenes based on the inherent distribution (frequency-based) of object classes, the various classes encountered during the exploration of various indoor areas (region-based), and the randomness aspect of object classes in the open world.

    &  &  &  \\  & Task 1 & Task 2 & Task 3 & Task 1 & Task 2 & Task 3 & Task 1 & Task 2 & Task 3 \\  Classes count & 64 & 68 & 66 & 73 & 55 & 70 & 66 & 66 & 66 \\ Train instances & 24224 & 3791 & 1612 & 15327 & 8177 & 6123 & 13483 & 8239 & 7905 \\ Validation instances & 6539 & 1000 & 428 & 4177 & 2261 & 1529 & 3776 & 2102 & 2089 \\ Train scenes & 1201 & 924 & 627 & 1201 & 1002 & 895 & 1169 & 1089 & 1159 \\ Validation scenes & 312 & 242 & 165 & 312 & 264 & 236 & 307 & 273 & 300 \\   

Table 1: **The statistics of each split across the three tasks.** The number of known classes per task is reported along with the count of instances (3D objects) in the training and validation set, we also show the number of non-empty scenes used during training and validation.

Figure 3: Point-wise count for each class across the three tasks under the three open-world scenarios

**Split A (Instance frequency-based):** We introduce a split that leverages the inherent distribution of objects, with _known_ classes being more prevalent than _unknown_ categories. Task \(^{1}\) encompasses all the head classes as defined in the ScanNet200 benchmark [8; 27], while tasks \(^{2}\) and \(^{3}\) group the common and tail classes, respectively. This division allows us to effectively capture the varying frequency and significance of object categories within the dataset.

**Split B (Region-based):** In this split, our objective is to replicate the diverse class types encountered during indoor exploration.We argue that a perfect model for a robot moving indoors should segment both classes it knows and classes it hasn't seen before. Additionally, it should keep learning and getting better at segmenting new classes over time. This partition draws inspiration from the sequence of classes that a robot might encounter when navigating indoors. To achieve this, we group classes that are likely to be encountered initially when accessing an indoor space and share similarities in scenes. Initially, we assign each class to a specific scene where it predominantly occurs. Subsequently, we divide the classes into three distinct groups, corresponding to the three tasks.

**Split C (Random sampling of classes):** This third split introduces a different challenge inspired by the randomness aspect of the open-world, where tasks can exhibit random levels of class imbalance. To create this split, we randomly shuffled the classes and sampled without replacement, selecting 66 classes three times for each task.

### Generating pseudo-labels for the unknown classes

Because of the wide range of classes in an open-world setting, the auto-labeler is used as an alternative to manual labeling. The former makes use of the existing target labels from the available ground truth classes (_known_ classes) to generate pseudo-labels for the _unknown_ class in the process of training. In , the model is assumed to be class agnostic, where _unknown_ objects are predicted as _known_ with high confidence. As a result, the authors of the paper proposed to use the predictions with top-k confidence scores that do not intersect with the ground truth as pseudo-labels for the _unknown_ class. In our study, we show that top-k pseudo-label selection can severely harm the performance of the model on the _known_ and _unknown_ classes. Hence, we propose a Confidence Thresholding (**CT**) based selection of pseudo-labels. We show that the performance on the _known_ and the _unknown_ classes increases by a large margin in terms of mean Average Precision (mAP).

The _auto-labeler_ unit, depicted in Fig. 2, is used for _unknown_ pseudo-labels generation. It takes a set of predicted binary masks \(=\{_{i}\ \ i(1,...,n_{Q})\}\), where \(n_{Q}\) is the number of queries, \(_{i}=(M_{i}>0.5)\) is a mask from a single query, and \(M_{i}=\{m_{i,j}\ \ j(1,...,N)\}\) is a heat map measuring the similarity between a query \(q_{j}^{D}\) and the features of \(N\) voxels extracted from the high-resolution level in the backbone.

Moreover, each query \(q_{j}\) encodes semantic information and can generate a class prediction \(_{cls}(q_{j})=\{_{cls}(c;q_{j})\ \ c(0,1,...,|^{c}|)\}\) using a classification head (refer to Fig. 2). Subsequently, the objectness confidence score is assigned to predictions following Eq 1.

\[s_{j}=s_{cls,j}(M_{j}>0.5)^{T}}{|(M _{j}>0.5)|_{1}}\] (1)

where \(s_{cls,j}\) is the max output probability from the classification head \(_{cls}(q_{j})\), and \(\) is the indicator function. After scoring the predictions, the auto-labeler returns \(m\) pseudo-labels \(}=\{}_{i}=[}_{i}, ]\ \ i(1,...,m)\}\) with confidence above a threshold and has a low IoU with the _known_ classes' target masks.

### Query target assignment and contrastive clustering

Similar to , we utilize contrastive clustering to enhance the separation of classes within the query embedding space. To achieve this, we employ a set of query prototypes denoted as \(_{p}=\{_{i}^{D}\ \ i(0,1,..,|^{t}|)\}\), where \(_{0}\) denotes the prototype of the class _unknown_. We apply a contrastive loss that encourages queries with similar classes to be attracted to their respective prototypes while pushing them away from those representing negative classes, as illustrated in Fig. 2. Since the queries are used to determine the class of the objects (see Fig. 2 inference block), the class prototypes are expected to hold general semantic knowledge of their corresponding classes.

_Hungarian matching_ is performed in the _Assign target to query_ module, depicted in Fig. 2, where the indices of prediction-target are used to assign a label to the queries used to generate the matched prediction. The labeled queries are then stored in a _query store_\(_{store}\), which represents a queue with a maximum capacity. This queue is employed to update the query prototypes \(_{p}\) using an exponential moving average.

Hinge embedding loss is utilized according to Eq 2. This loss ensures that queries belonging to the same class denoted as \(q_{c}\), are pulled towards their corresponding class prototype \(_{c}\), while being pushed away from other prototypes representing different classes.

\[_{cont}(q_{c})=_{i=0}^{|^{t}|}(q_{c}, _{i})\] (2)

\[(q_{c},_{i})=||q_{c}-_{i}||_{2}&i=c\\ (0,-||q_{c}-_{i}||_{2})&i c\]

where \(\) is the margin of the contrastive clustering.

### Reachability-based probability correction (PC)

In , an architecture that can deal with long-tail distribution and _unknown_ class prediction for open-world object recognition was proposed, where _unknown_ classes are assumed to be very different in color and texture from the _known_ classes without prior on the _unknown_ classes. However, we show in Fig. 6 that many _unknown_ instances hold similar features to the _known_ ones.

In our method, we relax the strict assumption of high dissimilarity of _unknown_ and _known_ classes and correct the predicted output probability following two characteristics of a feature from an _unknown_ object: (1) it has to be far from the nearest _known_ class, as features of the class _unknown_ are expected to be pushed away from the prototypes of the _known_ classes, after applying constructive clustering, and (2) the feature should correspond to an object that is not a _known_ class. We show that applying this approach during inference boosts the performance of the model on the _unknown_ class considerably by compensating for the weak pseudo-labels provided by the auto-labeler.

Our probability correction scheme is the following

\[(;q_{j})=_{cls}(;q_{j})_{corr}(;q_{j})\] (3)

where \(_{cls}\) is the probability from the classification head, and \(_{corr}\) is the correction probability. We base our intuition on the fact that _unknown_ classes have high objectness scores, which makes them not too far from the prototypes of the _known_ classes. To model this behavior we choose

\[_{corr}(;q_{j})=_{corr}(;o,q_{j}) _{corr}(o;q_{j})\]

where \(_{corr}(o;q_{j})\) is the likelihood of the query to correspond to an object that is not _known_ (either background or true _unknown_). Since the query prototypes encode class-specific information we propose the following method to measure the objectness of a query given all prototypes from the _known_ classes, where it assigns a high objectness probability if it is close to only a few _known_ classes. This probability distribution defines the objectness of _unknown_ objects around a certain boundary from the prototypes as follows.

\[_{corr}(o;q_{j})=1-_{k=1}^{|^{t}|}_{cls}(k ;q_{j})\]

Figure 4: Illustration of the region in the query embedding space where the class probability is corrected.

while \(_{corr}(;o,q_{j})\) is the probability of the query being an _unknown_ object, which has a high value the further it is from the nearest prototype of the _known_ classes.

\[_{corr}(;o,q_{j})=()-a}{b} );\ \ \ \ (q_{j})=_{_{i}}||q_{j}-_{i}||_{2}\]

Here \(\) is the sigmoid function, \((q_{j})\) is the reachability of the query \(q_{j}\), \(_{i}\) is the prototype of the \(i^{th}\) class, and \(a,b\) are the shift and scale of the sigmoid function that assure \(_{corr}(;o,q_{j},(q_{j})=0)=0.05\) and \(_{corr}(;o,q_{j},(q_{j})=)=0.95\), for a contrastive clustering margin \(\).

We finally normalize the probabilities from the classification head of the _known_ classes as follows

\[(c;q_{j})=_{cls}(c;q_{j})}{_{l^{ }}_{cls}(l;q_{j})}(1-(;q_{j}))\]

### Alleviating catastrophic forgetting for incremental learning

Following the success of exemplar replay in avoiding catastrophic forgetting of the old classes during incremental learning for object detection [18; 11; 41], we adopt it for the task of incremental learning in 3D instance segmentation where we use exemplars from the classes of the previous task to fine-tune the model trained on the novel classes. In our setting, we use the same dataset for the three tasks and mask the classes of the previous task when training on the novel classes from the current task. As a result, the novel classes of the current task might be encountered again when replaying the exemplars from the previous task, as the same scenes are being used in fine-tuning.

## 5 Experiments

### Open-world evaluation protocol

We use our proposed splits of classes which mimic the challenges that are mostly faced in the open-world to ensure a strict performance evaluation for 3D instance segmentation models.

**Evaluation metrics.** We adopt three common evaluation metrics, _wilderness impact_ (WI) , _absolute open set error_ (A-OSE) , and the _recall of the unknown classes_ (U-Recall) [1; 24; 11]

Figure 5: **Qualitative results for 3D instance segmentation results on some ScanNet200 validation scenes**. Points highlighted in blue belong to _unknown_ classes and those highlighted in green belong to _known_ classes. We show the performance of our model in retrieving the _unknown_ class objects compared to **3D-OWIS\(-\)PC\(-\)CT** for the three scenes.

to evaluate the performance of our model on the _unknown_ classes and to provide a fair comparison with and without contributions. For the _known_ classes, we use mean Average Precision (mAP). WI measures the impact of the _unknown_ classes on the precision of the model at a specific confidence level. Ideally, WI is nil, i.e., there are no _unknown_ objects predicted as _known_. For our evaluation, we report WI at 0.5 confidence. It can be computed as follows: WI \(=_{}}}{P_{_{}}}-1\).

We also report A-OSE, which represents the count of _unknown_ instances misclassified as one of the _known_ classes, and the U-Recall at 0.5 IoU, which reflects the ability of the model to recover _unknown_ objects.

### Implementation details

We adapt Mask3D  for the task of open-world instance segmentation. We add an extra prediction output for the _unknown_ class. In training, we assign an _ignore_ label to the classes of the future and previous tasks, while we keep the labels of the previous task and assign an _unknown_ class label to the classes of the future task during evaluation. For contrastive clustering, we use the indices obtained after matching the predictions with the target using _Hungarian matching_ to assign a label to the queries and store them in the _Query Store_\(_{store}\). The store is then averaged per class and used to periodically update the prototypes every 10 iterations for the hinge loss computation. Finally, we use 40 exemplars per class on average for incremental learning. The classes from the current task are kept during class exemplar replay since we are using the same dataset for the three tasks.

### Open-world results

Table 2 provides a comprehensive performance comparison between the Oracle, our implementation of  as 3D-OW-DETR, **3D-OWIS**, and **3D-OWIS\(-\)PC \(-\)CT** when excluding the Probability Correction (**PC**) and Confidence Thresholding (**CT**) components. Across all scenarios and tasks,

  
**Task IDs (\(\))** &  &  &  \\   & WI & A-OSE & U-Recall & mAP (\(\)) & WI & A-OSE & U-Recall & mAP (\(\)) &  \\  & (\(\)) & (\(\)) & (\(\)) & Current &   Current \\ known \\  \\  } &  Current \\ known \\  } &   \(\)) \\ (\(\)) \\  } &  Previously \\ Current \\ known \\  } &  Currently \\ Known \\  } \\   &  \\  Oracle & 0.129 & 227 & 55.94 & 38.75 & 38.60 & 0.03 & 112 & 45.40 & 38.25 & 20.91 & 29.40 & 29.58 & 17.78 & 26.10 \\ Mask3D  & - & - & - & 39.12 & - & - & - & 38.30 & 20.57 & 29.15 & 28.61 & 18.33 & 25.58 \\ 
3D-OW-DETR  & 0.547 & 721 & 22.14 & 35.56 & 35.05 & 0.282 & 253 & 26.24 & 18.18 & 13.62 & 15.76 & **21.56** & 08.38 & 17.67 \\
3D-OWIS\(-\)PC \(-\)CT & **1.589** & 707 & 30.72 & 37.50 & 37.00 & **0.000** & **4** & 04.75 & 11.00 & **17.30** & 14.10 & 21.40 & 08.00 & 17.50 \\
**Ours: 3D-OWIS\(\)** & **607** & **34.75** & **40.20** & **39.7** & 0.007 & 126 & **27.03** & **29.40** & 16.40 & **22.70** & 20.20 & **15.20** & **18.70** \\   &  \\  Oracle & 1.126 & 939 & 70.31 & 24.57 & 24.80 & 10.80 & 441 & 73.16 & 25.50 & 20.30 & 23.40 & 23.40 & 30.40 & 26.00 \\ Mask3D  & - & - & - & 23.48 & 23.48 & - & - & - & 21.81 & 18.91 & 20.37 & 24.20 & 29.22 & 26.06 \\
3D-OW-DETR  & 3.229 & 1935 & 17.18 & 20.00 & 19.73 & 20.53 & 1389 & **33.31** & 12.36 & 13.66 & 12.93 & 07.27 & 18.96 & 11.62 \\
3D-OWIS\(-\)PC \(-\)CT & **3.133** & 1895 & 21.67 & 18.94 & 18.70 & 3.169 & 1081 & 26.63 & 18.00 & 16.40 & 17.20 & 17.30 & 20.10 & 18.30 \\
**Ours: 3D-OWIS\(\)** & **1780** & **24.79** & **23.60** & **23.30** & **0.755** & **881** & 24.21 & **18.70** & **17.30** & **17.90** & **18.70** & **24.60** & **20.90** \\   &  \\  Oracle & 1.039 & 651 & 71.61 & 23.30 & 23.6 & 0.249 & 591 & 62.83 & 20.50 & 18.40 & 19.60 & 25.30 & 28.20 & 26.30 \\ Mask3D  & - & - & - & - & 20.82 & 2.115 & - & - & - & 22.67 & 26.67 & 24.13 & 25.41 & 25.21 & 25.35 \\
3D-OWIS\(-\)PC \(-\)CT & 2.901 & 1752 & **15.66** & 15.00 & 14.80 & 1.799 & 13.00 & 847 & **16.04** & 08.00 & 17.41 & 12.40 & 08.81 & 15.63 & 11.01 \\
**Ours: 3D-OWIS\(\)** & **1294** & 14.34 & **18.00** & **17.60** & **0.152** & **303** & 15.80 & **13.90** & **22.20** & **17.80** & **17.80** & **17.70** & **17.80** \\   

Table 2: **State-of-the-Art comparison for 3D-OWIS model.** We show a comparison of performance under the three open-world scenarios, where **3D-OWIS\(-\)PC \(-\)CT** is our model **3D-OWIS** without Probability Correction (**PC**) and Confidence Thresholding (**CT**). We rely on the metrics used in the open-world literature, A-OSE \(\)NE  which quantifies the number of unknown objects misclassified as one of the known classes, WI  which measures the impact of the unknown class on the precision of the model on the known classes, and the U-Recall  to evaluate the model’s ability to recover the unknown objects. We show that **3D-OWIS** performs remarkably better than the other models under all scenarios when dealing with the known classes, and superior performance in split A and B, and slightly less performance in split C when handling the unknown objects. We also provide a closed-setting comparison between Mask3D and Oracle (**Ours** with access to unknown labels).

**3D-OWIS\(-\)PC \(-\) CT** consistently exhibits inferior performance in terms of mAP. Additionally, it demonstrates considerably lower U-Recall performance in splits A and B, with slightly higher performance in split C. Of particular note, our **3D-OWIS** demonstrates remarkable proficiency in preserving knowledge of the previous classes after fine-tuning. This proficiency is attributed to better pseudo-label selection for the _unknown_ classes. **3D-OWIS\(-\)PO**s\(-\)PC \(-\) CT** in most cases while minimizing the impact of the _unknown_ classes on the _known_ classes, as evidenced by lower WI and A-OSE scores and higher mAP.

Table 4 presents a comparison between our model, **3D-OWIS**, and our implementation of two methods, GGN  and OLN . For both models, we adapt Mask3D and train it with mask loss only for OLN. In the case of GGN, we train a Minkowski backbone to predict affinity maps and use Connected Components to generate class-agnostic proposals. These results underscore the effectiveness and potential of our approach in addressing the three proposed open-world challenges.

### Incremental learning results

Our model's performance in incremental learning is evaluated based on its ability to preserve knowledge from previous classes. With the utilization of exemplar replay, the **3D-OWIS** model demonstrates significant improvement on previous classes mAP. Table 2 presents the results, indicating that our model consistently outperforms the others in terms of mean Average Precision (mAP) for the previous classes in all cases.

    &  &  &  \\   & & & WI & A-OSE & U-Recall & mAP (1) & WI & A-OSE & U-Recall &  &  \\ w/ Finetuning & CT & PC & (\(\)) & (\(\)) & (\(\)) &  Current \\ known \\  & All & (\(\)) & (\(\)) & (\(\)) &  Previously \\ known \\  & All & Previously & Current & 
 Previously \\ known \\  & All &  \\   &  \\  \(\) & \(\) & \(\) & 1.589 & 707 & 30.72 & 37.50 & 37.00 & 0.870 & 321 & 19.42 & 00.00 & 16.74 & 08.40 & 00.00 & 09.30 & 02.80 \\ \(\) & \(\) & \(\) & 0.237 & 443 & 30.00 & 40.39 & **37.0** & 0.306 & 129 & 14.96 & 00.00 & **21.00** & 10.50 & 00.00 & **17.45** & 05.20 \\  \(\) & \(\) & \(\) & 1.589 & 707 & 30.22 & 37.50 & 37.00 & **0.000** & **4** & 04.75 & 11.00 & 17.30 & 14.10 & **21.40** & 08.00 & 17.50 \\ \(\) & \(\) & \(\) & **0.237** & **443** & 30.00 & **40.30** & 39.70 & 0.004 & 102 & 23.62 & 29.22 & 15.00 & 23.10 & 19.70 & 15.70 & **18.50** \\ \(\) & \(\) & \(\) & 0.398 & 607 & **34.75** & 40.20 & **39.70** & 0.007 & 126 & **27.03** & **29.40** & 16.40 & **22.70** & No unknown labels \\  & & & & & & & & & & & & & & & & & & \\   \\  \(\) & \(\) & \(\) & 3.133 & 1895 & 21.67 & 18.94 & 18.70 & 1.82 & 829 & 17.20 & 00.00 & 15.40 & 06.60 & 00.00 & 20.20 & 07.50 \\ \(\) & \(\) & \(\) & 2.147 & 21.70 & 21.70 & 23.80 & 23.50 & 1.653 & **375** & 10.38 & 00.00 & **18.30** & 07.90 & 00.00 & **25.40** & 09.40 \\  \(\) & \(\) & \(\) & 3.219 & 1995 & 21.70 & 18.94 & 18.70 & 13.69 & 1081 & 26.63 & 18.00 & 16.40 & 17.20 & 17.30 & 20.10 & 18.30 \\ \(\) & \(\) & \(\) & **2.147** & **1397** & 21.70 & **23.80** & **23.50** & 0.466 & 413 & 20.90 & 18.60 & 16.90 & 17.70 & **18.50** & 24.20 & **20.60** \\ \(\) & \(\) & \(\) & 3.684 & 1780 & **24.79** & 23.6 & 23.30 & 0.755 & 581 & **24.21** & **18.70** & 17.30 & **17.90** & No unknown labels \\  & & & & & & & & & & & & & & & & & & \\   \\  \(\) & \(\) & \(\) & 2.901 & 1752 & 15.66 & 15.00 & 14.80 & 6.294 & 857 & 11.05 & 0.00 & 15.70 & 07.50 & 00.00 & 14.60 & 04.70 \\ \(\) & \(\) & \(\) & 0.227 & 828 & 11.44 & 18.70 & 18.40 & 1.361 & 365 & 10.16 & 00.00 & 19.50 & 09.40 & 00.00 & **19.10** & 6.20 \\  \(\) & \(\) & \(\) & 2.901 & 1752 & **15.66** & 15.00 & 14.80 & 1.799 & 666 & **15.99** & 13.50 & 19.70 & 16.40 & 17.50 & 17.70 & 17.50 \\ \(\) & \(\) & \(\) & **0.227** & **828** & 11.44 & **18.70** & **18.40** & **0.088** & **208** & 12.63 & **14.50** & 22.10 & **18.00** & **17.80** & 17.70 & **17.80** \\ \(\) & \(\) & \(\) & 0.419 & 1294 & 14.34 & 18 & 17.60 & 0.152 & 303 & 15.80 & 13.90 & **22.20** & 17.80 & No unknown labels \\  & & & & & & & & & & & & & & & & & & \\   \\  \(\) & \(\) & \(\) & 2.901 & 1752 & 15.66 & 15.00 & 14.80 & 6.294 & 857 & 11.05 & 0.00 & 15.70 & 07.50 & 00.00 & 14.60 & 04.70 \\ \(\) & \(\) & \(\) & 0.227 & 828 & 11.44 & 18.70 & 18.40 & 1.361 & 365 & 10.16 & 00.00 & 19.50 & 09.40 & 00.00 & **19.10** & 6.20 \\  \(\) & \(\) & \(\) & 2.901 & 1752 & **15.66** & 15.00 & 14.80 & 1.799 & 666 & **15.99** & 13.50 & 19.70 & 16.40 & 17.50 & 17.70 & 17.50 \\ \(\) & \(\) & \(\) & **0.227** & **828** & 11.44 & **

### Discussion and analysis

**Ablation study.** We show in Table 3 that **3D-OWIS\(-\)PC \(-\)CT** model performs poorly on the _known_ classes because of the high number of low-quality pseudo-labels generated by _Auto-labeler_, which is also explained by the high value of _Wilderness Impact_ and _Absolute open set error_. The U-Recall drops considerably when fine-tuning the **3D-OWIS\(-\)PC \(-\)CT**, while the WI and A-OSE either decrease or increase with the mAP on the _unknown_. On the other hand, our model limits the training only to the best pseudo-labels, which maintain good performance on the _known_ classes in all cases, before and after fine-tuning, and also achieve results on the _unknown_ class comparable to the **3D-OWIS\(-\)PC \(-\)CT** in most of the cases. Adding the probability correction module helps in improving the U-Recall while keeping the mAP of the _known_ classes much above the **3D-OWIS\(-\)PC \(-\)CT**. However, it results in an increase in WI and A-OSE because of the increase of false positives in the _known_ classes.

**tSNE analysis** The tSNE plot shown in Fig. 6 illustrates the below-par performance of the **3D-OWIS\(-\)PC \(-\)CT** in clustering the _unknown_ classes, where most queries are still maintaining features representative of the _known_ classes. This behavior is a result of the weak supervision of the _unknown_ class, which shows the need for correcting the predictions, and explains the improvement in U-Recall when applying the probability correction with nil deterioration in the _known_ classes mAP in most cases.

**Qualitative analysis.** Fig. 5 shows that 3D-OWIS is able to correctly identify background and _unknown_ objects as _unknown_. Also note the second scene, where predictions are corrected from _known_ to _unknown_ without affecting the predictions of the _known_ classes.

## 6 Limitations

Confidence Thresholding (**CT**) enhances the performance of the model on _known_ classes; nonetheless, it diminishes the model's capacity to segment _unknown_ classes, mainly due to its reliance on a smaller number of pseudo-labels during training. Additionally, the effectiveness of Probability Correction (**PC**) is contingent upon the inherent characteristics of the clusters within the _known_ classes. In scenarios characterized by data imbalance, the performance of probability correction may deteriorate when applied to the undersampled classes.

## 7 Conclusion

In this paper, we address the challenge of 3D instance segmentation in open-world scenarios, which is a novel problem formulation. We propose an innovative approach that incorporates an _unknown_ object identifier to detect objects not present in the training set. To facilitate evaluation and experimentation, we present three dataset splits of ScanNet200 based on different criteria for selecting _unknown_ objects. Our experimental results demonstrate that our proposed _unknown_ object identifier significantly improves the detection of _unknown_ objects across various tasks and dataset splits. This work contributes to advancing the localization and segmentation of 3D objects in real-world environments and paves the way for more robust and adaptable vision systems.

    \\ 
**Task ID** &  \\   & WI & A-OSE & U-Recall &  \\  & (!) & (!) & (!) & Current & \\ 
3D-GGN  & 15.68 & 1452 & 21.33 & 20.51 & 20.12 \\
3D-OLN  & - & - & 02.45 & - & - \\
**Ours: 3D-OWIS** & **0.397** & **607** & **34.75** & **40.2** & **39.7** \\   

Table 4: **Open-world instance segmentation comparison**. We provide the results of our implementation of two methods for 2D open-world instance segmentation models. We show that our model performs comparatively better than others across all metrics.

Figure 6: **tSNE visualization** of the queries for _known_ & _unknown_ classes