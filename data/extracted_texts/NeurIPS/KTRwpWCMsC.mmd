# Conformal Prediction for Time Series with

Modern Hopfield Networks

 Andreas Auer Martin Gauch\({}^{*,}\) Daniel Klotz\({}^{*}\) Sepp Hochreiter\({}^{*}\)

\({}^{*}\)ELLIS Unit Linz and LIT AI Lab, Institute for Machine Learning,

Johannes Kepler University Linz, Austria

\({}^{}\)Google Research, Zurich, Switzerland

###### Abstract

To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.

## 1 Introduction

Uncertainty estimates are imperative to make actionable predictions for complex time-dependent systems (e.g., Gneiting Katzfuss, 2014; Zhu Laptev, 2017). This is particularly evident for environmental phenomena such as flood forecasting (e.g., Krzysztofowicz, 2001), since they exhibit pronounced seasonality. Conformal Prediction (CP, Vovk et al., 1999) provides uncertainty estimates based on prediction intervals. It achieves finite-sample marginal coverage with almost no assumptions, except that the data is exchangeable (Vovk et al., 2005; Vovk, 2012). However, CP for time series is not trivial because temporal dependencies often violate the exchangeability assumption.

HopCPT.For time series models that predict a given system, the errors are typically specific to the input describing the current situation. To apply CP, HopCPT uses continuous Modern Hopfield Networks (MHNs). The MHN uses large weights for past situations that were similar to the current one and weights close to zero for past situations that were dissimilar to the current one (Figure 1). The CP procedure uses the weighted errors to construct strong uncertainty estimates close to the desired coverage level. This exploits that similar situations (which we call a regime) tend to follow the same error distribution. HopCPT achieves new state-of-the-art efficiency, even under non-exchangeability and on large datasets.

**Our main contributions are:**

1. We propose HopCPT, a CP method for time series, a domain where CP struggled so far.
2. We introduce the concept of error regimes to CP, which softens the excitability requirements and enables efficient CP for time series.
3. HopCPT uses MHN for a similarity-based sample reweighting. In contrast to existing approaches, HopCPT can learn from large datasets and predict intervals at arbitrary coverage levels without retraining.
4. HopCPT achieves state-of-the-art results for conformal time series prediction tasks from various real-world applications.

5. HopCPT is the first algorithm with coverage guarantees that was applied to hydrological prediction applications -- a domain where uncertainty plays a key role in tasks such as flood forecasting and hydropower management.

### Related Work

Regimes.In a world with non-linear dynamics, different environmental conditions lead to different error characteristics of models that predict based on these conditions. If we do not account for these different conditions, temporal changes may lead to unnecessarily large prediction intervals, i.e., to high uncertainty. For example, solar energy production is high and stable on a sunny day, fluctuates during cloudy days, and is zero at night. Often, the current environmental condition was already observed at previous points in time. The error at these time steps is therefore assumed to have the same distribution as the current error. Following Quandt (1958) and Hamilton (1990), we call the sets of time steps with similar environmental conditions _regimes_. Although conditional CP is in general impossible (Foygel Barber et al., 2021), we show that conditioning on such regimes can lead to better prediction intervals while preserving the specified coverage. Hamilton (1990) models time series regimes as a discrete Markov process and conditions a classical autoregressive model on the regime states. Sanquer et al. (2012) use a smooth transition approach to model multi-regime time series. Tajeuna et al. (2021) propose an approach to discover and model regime shifts in an ecosystem that comprises multiple time series. Further, Masserano et al. (2022) handle distribution shifts by retraining a forecasting model with training data from a non-uniform adaptive sampling. Although these approaches are not in a CP setting, their work is similar in spirit, as they also follow the general idea to condition on parts of the time series with similar regimes.

CP and extensions.For thorough introductions to CP, we refer the reader to the foundational work of Vovk et al. (1999) and a recent introductory paper by Angelopoulos & Bates (2021). There exist a variety of extensions for CP that go "beyond exchangeability" (Vovk et al., 2005). For example, Papadopoulos & Haralambous (2011) apply CP to a nearest neighbor regression setting, Teng et al. (2022) apply CP to the feature space of models, Angelopoulos et al. (2020) use CP to generate uncertainty sets for image classification tasks, and Toccaceli et al. (2017) use a label-conditional variant to apply CP to biological activity prediction. Of specific interest to us is the research regarding non-exchangeable data of Tibshirani et al. (2019) and Foygel Barber et al. (2022). Both handle potential shifts between the calibration and test set by reweighting the data points. Tibshirani et al. (2019) restrict themselves to settings with full knowledge about the change in distribution; Foygel Barber et al. (2022) rely on fixed weights. In our work, we refrain from this assumption because such information is typically not available in time series prediction. Another important research direction is the work on normalized conformity scores (see Fontana et al., 2023, and references therein). In this setting, the goal is to adapt the conformal bounds through a scaling factor in the nonconformity function. The work on normalized conformity scores does not explicitly tailor their approaches to time series.

Figure 1: Schematic illustration of HopCPT. The Modern Hopfield Network (MHN) identifies regimes similar to the current one and up-weights them (colored lines). The weighted information enriches the conformal prediction (CP) procedure so that prediction intervals can be derived.

CP for time series.Gibbs and Candes (2021) and Zaffran et al. (2022) account for shifts in sequential data by continuously adapting an internal coverage target. Adaption-based approaches like these are orthogonal to HopCPT and can serve as an enhancement. Stankevicitute et al. (2021) use CP in conjunction with recurrent neural networks in a multi-step prediction setting, assuming that the series of observations is independent. Thus, no weighting of the scores is required. Sun and Yu (2022) introduce CopulaCPTS which applies CP to time series with multivariate targets. They conformize their prediction based on a copula of the target variables and adapt their calibration set in each step. Jensen et al. (2022) use a bootstrap ensemble to enable CP on time series. NexCP (Foygel Barber et al., 2022) uses exponential decay as the weighting method, arguing that the recent past is more likely to be of the same error distribution. HopCPT can learn this strategy, but does not a priori commit to it. Xu and Xie (2022) propose EnbPI, which uses quantiles of the \(k\) most recent errors for the prediction interval. Additionally, they introduce a novel leave-one-out ensembling technique. This is specifically geared to settings with scarce data and difficult to use for larger datasets, which is why we do not apply it in our experiments. EnbPI is designed around the notion that near-term errors are often independent and identically distributed and therefore exchangeable. SPCI (Xu and Xie, 2022) softens this requirement by exploiting the autocorrelative structure with a random forest. However, it re-calculates the random forest model at each time step, which is a computational burden that prohibits its application to large datasets. Our approach relaxes the requirement even further, as we do not assume that the data for the interval computations pertains to the \(k\) most recent errors.

Non-CP methodsBeside CP there exist a wide range of approaches for uncertainty-aware time series prediction. For example, Mixture Density Networks (Bishop, 1994) directly estimate the parameters of a mixture of distributions. However, they require a distribution assumption and do not provide any theoretical guarantees. Gaussian Processes (e.g., Zhu et al., 2023; Corani et al., 2021; Sun et al., 2022) model time series by calculating posterior functions based on the samples and a prior but are computationally limited for large and high dimensional datasets.

Continuous Modern Hopfield Networks.MHN are energy-based associative memory networks. They advance conventional Hopfield Networks (Hopfield, 1982) by introducing continuous queries and states via a new energy function. The new energy function leads to exponential storage capacity, while retrieval is possible with a one-step update (Ramsauer et al., 2021). Examples for successful applications of MHN are Widrich et al. (2020); Furst et al. (2022); Dong et al. (2022); Sanchez-Fernandez et al. (2022); Paischer et al. (2022); Schaff et al. (2022); and Xu et al. (2022). MHN are related to Transformers (Vaswani et al., 2017) as their attention mechanism is closely related to the association mechanism in MHN. In fact, Ramsauer et al. (2021) show that Transformers attention is a special case of the MHN association, at which we arrive when the queries and states are mapped to an associative Hopfield space with the dimensions \(d_{k}\), and the inverse softmax temperature is set to \(=}}\). However, we use the framework of MHN because we want to highlight the associative memory mechanism as HopCPT directly ingests encoded observations. This perspective further allows HopCPT to update the memory for each new observation. For more details, we refer to Appendix H in the supplementary material.

### Setting

Our setting consists of a multivariate time series \(\{(_{t},y_{t})\}\), \(t=1,,T\), with a feature vector \(_{t}^{m}\), a target variable \(y_{t}\), and a given black-box prediction model \(\) that generates a point prediction \(_{t}=(_{t})\). The input feature matrix \(_{t+1}\) can include all previous and current feature vectors \(\{_{i}\}_{i=1}^{t+1}\), as well as all previous targets \(\{y_{i}\}_{i=1}^{t}\). Our goal is to construct a corresponding prediction interval \(_{t}^{}(_{t+1})\) -- a set that includes \(y_{t+1}\) with at least a specified probability \(1-\). In its basic form, \(_{t+1}\) will only contain \(_{t+1}\), but it can also inherit \(_{t+1}\) or other useful features. Following Vovk et al. (2005), we define the _coverage_ as

\[\{Y_{t+1}_{t}^{}(_{t+1})\} 1-,\] (1)

where \(Y_{t+1}\) is the random variable of the prediction. An infinitely wide prediction interval is 100% reliable, but not informative of the uncertainty. Thus, CP aims to minimize the width of the prediction interval \(_{t}^{}\), while preserving the coverage. A smaller prediction interval is called a more _efficient_ interval (Vovk et al., 2005) and usually evaluated as the mean of the interval width over the prediction period (_PI-Width_).

Standard split conformal prediction takes a calibration set of size \(n\) which has not been used to train the prediction model \(\). For each data sample, it calculates the so-called non-conformity score (Vovk et al., 2005). In a regression setting, this score often simply corresponds to the absolute error of the prediction (e.g., Foygel Barber et al., 2022). The prediction interval is then calculated based on the empirical \(1-\) quantile \(_{1-}\) of the calibration scores:

\[_{n}^{}(_{t+1})=(_{t+1})_{1- }(\{|y_{i}-(_{i})|\}_{i=1}^{n}).\] (2)

If the data is exchangeable and \(\) treats the data points symmetrically, the errors on the test set follow the distribution from the calibration. Hence, the empirical quantiles on the calibration and test set will be approximately equal and it is guaranteed that the interval provides the desired coverage.

The _actual marginal miscoverage_\(^{}\) is based on the observed samples of a test set. If the _specified miscoverage_\(\) differs from the \(^{}\) in the evaluation, we denote the difference as the coverage gap \(=-^{}\).

The remainder of this manuscript is structured as follows: In Section 2, we present HopCPT alongside a theoretical motivation and a synthetic example that demonstrates the advantages of the approach. In Section 3, we evaluate the performance against state-of-the-art CP approaches and discuss the results. Section 4 gives our conclusions and provides an outlook on potential future work.

## 2 HopCPT

HopCPT1 combines conformal-style quantile estimation with learned similarity-based MHN retrieval.

### Theoretical Motivation

The theoretical motivation for the MHN retrieval stems from Foygel Barber et al. (2022), who introduced CP with weighted quantiles. In the split conformal setting, the according prediction interval is calculated as

\[_{t}^{}(_{t+1})=(_{t+1})_{1- }(_{i=1}^{t}a_{i}_{_{i}}+a_{t+1}_{+} ),\] (3)

where \(\) represents an existing point prediction model, \(_{}\) is the \(\)-quantile of a distribution, and \(_{_{i}}\) is a point mass at \(|_{i}|\) (i.e., a probability distribution with all its mass at \(|_{i}|\)), where \(_{i}\) are the errors of the existing prediction model defined by \(_{i}=y_{i}-(_{i})\). The normalized weight \(a_{i}\) of data sample \(i\) is

\[a_{i}=++_{t}+1}&i=t+1,\\ }{_{1}++_{t}+1}&,\] (4)

where \(_{i}\) are the un-normalized weights of the samples. In the case of \(_{1}==_{t}=1\), this corresponds to standard split CP. Given this framework, Foygel Barber et al. (2022) show that \(\) can be bounded in a non-exchangeable data setting: Let \(D=((_{1},Y_{1}),,(_{t+1},Y_{t+1}))\) be a dataset where the last entry represents the test sample, and \(D^{i}\) be a permutation of \(D\) which exchanges the test sample at \(t+1\) with the \(i\)-th sample. Then, \(\) can be bounded from below by the weighted sum of the total variation distances \(d_{}\) between these permutations:

\[-_{i=1}^{t}a_{i}_{}(D,D^{i})\] (5)

If \(D\) is a composite of multiple regimes and the test sample is from the same regime as the calibration sample \(i\), then the distance between \(D\) and \(D^{i}\) is small. Conversely, the distance might be big if the calibration sample is from a different regime. In HopCPT, the MHN association resembles direct estimates of \(a_{i}\) -- dynamically assigning high values to samples from similar regimes.

Appendix B provides an extended theoretical discussion that relates HopCPT to the work of Foygel Barber et al. (2022) and Xu & Xie (2022), who provide the basis for our theoretical analyses of the CP interval. The latter compute individual quantiles for the upper and lower bound of the prediction interval on the errors themselves, in contrast to standard CP which uses only the highest absolute error quantile. This can provide more efficient intervals in case \(E[] 0\) within the corresponding error distribution. Applying this principle to HopCPT where the error distribution is conditional to the error regime and assuming that HopCPT can successfully identify these regimes (Appendix: Assumption B.3), we arrive at a conditional asymptotic coverage bound (Appendix: Theorem B.8) and an asymptotic marginal coverage bound (Appendix: Theorem B.9).

### Associative Soft-selection for CP

We use a MHN to identify parts of the time series where the conditional error distribution is similar: For time step \(t+1\), we query the memory of the past and look for matching patterns. The MHN then provides an association vector \(_{t+1}\) that allows to soft-select the relevant periods of the memory. The selection procedure is analogous to a \(k\)-nearest neighbor classifier for hard selection, but it has the advantage that the similarity measure can be learned. Formally, the soft-selection is defined as:

\[_{t+1}=\,m(_{t+1})\,_{q}\, _{k}\,m(_{1:t}),\] (6)

where \(m\) is an encoding network (Section 2.3) that transforms the raw time series features of the current step \(_{t+1}\) to the query pattern and the memory \(_{1:t}\) to the stored key patterns; \(_{q}\) and \(_{k}\) are the learned transformations which are applied before associating the query with the memory; \(\) is a hyperparameter that controls the softmax temperature. As mentioned above, HopCPT uses the softmax to amplify the impact of the data samples that are likely to follow a similar error distribution and to reduce the impact of samples that follow different distributions (see Section 2.1). This error weighting leads not only to more efficient prediction intervals in our experiments, but can also reduce the miscoverage (Section 3.2).

With the soft-selected time steps we can derive the CP interval using the observed errors \(\). Following Xu and Xie (2022), we use individual quantiles for the upper and lower bound of the prediction interval, calculated from the errors themselves. HopCPT computes the prediction interval \(_{t}^{}\) for time step \(t+1\) in the following way:

\[_{t}^{}(_{t+1})=(_{t+1})+q( {}{2},_{t+1}),(_{t+1})+q(1-, _{t+1}),\] (7)

where \(q(,_{t+1})=_{}(E_{t+1})\) and \(E_{t+1}\) is a multiset created by drawing \(n\) times from \([_{i}]_{i=1}^{t}\) with corresponding probabilities \([a_{t+1,i}]_{i=1}^{t}\).

### Encoding Network

We embed \(_{t}\) using a 2-layer fully connected network \(m^{L}\) with ReLU activations and enhance the representation by temporal encoding features \(_{T,t}^{}\). The full encoding network can be represented as \(m(_{t})=[m^{L}(_{t})_{T,t}^{}]\), where \(_{T,t}^{}\) is a simple temporal encoding that makes time dependent notions of similarity learnable (e.g., the windowed approach of EmbPI or the exponentially decaying weighting scheme of NexCP). Specifically, we use \(z_{T,t}^{}=\). In general, we find that our method is not very sensitive to the exact encoding strategy (e.g., number of layers), which is why we kept to a simple choice throughout all experiments.

### Training Procedure

We partition the split conformal calibration data into training and validation sets. Training MHN with quantiles is difficult, which is why we use an auxiliary task: Instead of applying the association mechanism from Equation 6 directly, we use the absolute errors as the value patterns of the MHN. This way, the MHN learns to align errors from time steps with similar regime properties. Intuitively, the observed errors from these time steps should work best to predict the current absolute error. We use the mean squared error as loss function (Equation 8). To allow for efficient training, we simultaneously calculate the association of all \(T\) time steps within a training split with each other. We mask the association from a time step to itself. The resulting association from each step to each step is \(_{1:T,1:T}\), and the loss function \(\) is

\[=T^{-1}\|(|_{1:T}|-_{1:T,1:T}| _{1:T}|)^{2}\|_{1}.\] (8)This incentivizes the network to learn a representation such that the resulting soft-selection focuses on time steps with a similar error distribution. Alternatively, one could use a loss based on sampling from the softmax. This would correspond more closely to the inference procedure. However, it makes training less efficient because each training step only carries information about a single value of \(_{i}\). In contrast, \(\) leads to more sample-efficient training. Choosing \(\) assumes that it leads to a retrieval of errors from appropriate regimes instead of mixing unrelated errors. Section 3.2 and Appendix A.3 provide evidence that this holds empirically.

### Synthetic Example

The following synthetic example illustrates the advantages of the HopCPT association mechanism. We model a bivariate time series \(D=\{(x_{t},y_{t})\}_{t=1}^{T}\). While \(y_{t}\) serves as the target variable, \(x_{t}\) represents the feature in our prediction. The series is composed of two different regimes: target values are generated by \(y_{t}=10+x_{t}+(0,}{2})\) or \(y_{t}=10+x_{t}+U(-x_{t},x_{t})\). \(x_{t}\) is constant within a regime (\(x=3\) and \(x=21\), respectively). The regimes alternate. For each regime, we sample the number of time steps from the discrete uniform distribution \((1,25)\). We create 1,000 time steps and split the data equally into training, calibration, and test sets. We use a ridge regression model as prediction model \(\). HopCPT can identify the time steps of relevant regimes and therefore creates efficient prediction intervals while still preserving the coverage (Figure 2). EnbPI, SPCI, and NexCP focus only on the recent time steps and thus fail to base their intervals on information from the correct regime. Whenever the regime changes from small to high errors, EnbPI propagates the small error signal and therefore loses coverage. Similarly, its prediction intervals for the small error regime are inefficient (Figure 2, row 3). SPCI, NexCP, and standard CP cannot properly select the relevant time steps, either. They do not lose coverage, but produce wide intervals for all time steps (Figure 2, rows 4 and 5). Lastly, if we replace the MHN with a kNN, it can retrieve information from similar regimes. However, its naive retrieval mechanism fails to focus on the informative features because it cannot learn them (Figure 2, row 2).

### Limitations

HopCPT builds upon the formal guarantees of CP, but it is able to relax the data exchangeability assumption of CP which are problematic for time series data. That said, HopCPT still relies on assumptions on how it learns to identify the respective error regimes and exchangablity within regimes (see Section 2.1 and Appendix B). Our extensive empirical evaluation suggests that these assumptions hold in practice. HopCPT is generally well-suited for very long time series because the memory requirement in the inference scales only linearly with the memory size. Nevertheless, for extremely large datasets it can be the case that not all historical time steps may be kept in the Hopfield memory

Figure 2: Synthetic example evaluation. HopCPT has the smallest prediction interval width (PI-width), while maintaining the warranted coverage (i.e., a \(\) Cov that is positive and close to zero).

anymore. HopCPT can, similar to existing methods, disregard time steps by removing the oldest entries from the memory, or alternatively use a sub-sampling strategy. On the other hand, for datasets with very scarce data it might be difficult to learn a useful embedding of the time steps. In that case, it could be better to use kNN rather than learning the similarity with MHN (Appendix D). Additional considerations regarding the potential social impact of the method are summarized in Appendix I.

## 3 Experiments

This section provides a comparative evaluation of HopCPT and analyzes its association mechanism.

### Setup

Datasets.We use datasets from four different domains: (a) Three solar radiation datasets from the US National Solar Radiation Database (Sengupta et al., 2018). The smallest one consists of 8 time series from different locations over a period of 84 days. This dataset is also used in Xu & Xie (2022a,b). In addition, we evaluate on a 1-year and a 3-year dataset, with 50 time series each. (b) An air quality dataset from Beijing, China (Zhang et al., 2017). It consists of 12 time series, each from a different measurement station, over a period of 4 years. The dataset has two prediction targets, the PM10 (as in Xu & Xie, 2022a,b) and PM2.5 concentrations, which we evaluate separately. (c) Sap flow2 measurements from the Sapfluxnet data project (Poyatos et al., 2021). Since the individual measurement series are considerably heterogeneous in length, we use a subset of 24 time series, each with between 15,000 and 20,000 data points and varying sampling rates. (d) Streamflow, a dataset of water flow measurements and corresponding meteorologic observations from 531 rivers across the continental United States (Newman et al., 2015; Addor et al., 2017). The measurements span 28 years at a daily time scale. For more detailed information about the datasets see Appendix C.

Prediction models.We use four prediction models for the solar radiation, the air quality, and the sap flux datasets to ensure that our results generalize: a random forest, a LightGBM, a ridge regression, and a Long Short-Term Memory (LSTM) (LSTM; Hochreiter & Schmidhuber, 1997) model. For the former three models we follow the related work (Xu & Xie, 2022a,b; Foygel Barber et al., 2022) and train a separate prediction model for each individual time series. The random forest and LightGBM models are implemented with the darts library (Herzen et al., 2022), the ridge regression model with sklearn (Pedregosa et al., 2011). For the LSTM model, we instead train a global model on all time series of a dataset, as is standard for state-of-the-art deep learning models (e.g., Oreshkin et al., 2020; Salinas et al., 2020; Smyl, 2020). The LSTM is implemented with PyTorch (Paszke et al., 2019). For the streamflow dataset, we deviate from this scheme and instead only use the state-of-the-art model, which is also an LSTM network (Kratzert et al., 2021, see Appendix C).

Compared approaches.We compare HopCPT to different state-of-the-art CP approaches for time series data: EnbPI (Xu & Xie, 2022a), SPCI (Xu & Xie, 2022b), NexCP (Foygel Barber et al., 2022), CopulaCPTS (Sun & Yu, 2022), and AdaptiveCI3(Gibbs & Candes, 2021). In addition, the results of standard split CP (CP) serve as a baseline, which, for the LSTM base predictor, corresponds to CF-RNN (Stankevicitute et al., 2021) in our setting (one-step, univariate target variable). Appendix A.1 describes our hyperparameter search for each method. For SPCI, an adaption of the original algorithm was necessary to provide scalability to larger datasets. Appendix A.2 contains more details and an empirical justification. Appendix G evaluates the addition of AdaptiveCI (Gibbs & Candes, 2021) as an enhancement to HopCPT and the other time series CP methods. Appendix A.3 gives a comparison to non-CP methods. Lastly, Appendix D presents a supplemental comparison to kNN that shows the superiority of the learned similarity representation in HopCPT.

    &  &  &  &  &  &  \\  &  &  &  &  &  &  &  \\   & \(\) Cov & \(0.029^{ 0.012}\) & 0.012\({}^{ 0.000}\) & -0.031 & -0.002 & 0.005 & 0.004 & \\  & PI-Width & **39.0\({}^{ 6.2}\)** & 103.1\({}^{ 0.1}\) & 131.1 & 166.6 & 174.9 & 174.6 & \\  &  & **0.73\({}^{ 0.20}\)** & 1.74\({}^{ 0.00}\) & 2.47 & 2.53 & 2.75 & 2.76 & \\   &  & \(\) Cov & \(0.001^{ 0.003}\) & 0.014\({}^{ 0.000}\) & -0.023 & -0.002 & 0.006 & 0.006 & 0.001 \\  & & PI-Width & **37.7\({}^{ 0.7}\)** & 102.2\({}^{ 0.1}\) & 133.6 & 159.9 & 169.8 & 170.2 & 67.1 \\  &  & **0.57\({}^{ 0.01}\)** & 1.75\({}^{ 0.00}\) & 2.52 & 2.55 & 2.80 & 2.81 & 1.19 \\   &  & \(\) Cov & \(0.040^{ 0.001}\) & 0.002\({}^{ 0.000}\) & -0.074 & -0.001 & 0.004 & 0.005 & \\  & & PI-Width & **44.9\({}^{ 0.5}\)** & 108.2\({}^{ 0.0}\) & 131.1 & 171.0 & 166.0 & 167.7 & \\  &  & **0.64\({}^{ 0.00}\)** & 1.82\({}^{ 0.00}\) & 2.49 & 2.66 & 2.73 & 2.74 & \\   &  & \(\) Cov & \(0.001^{ 0.006}\) & 0.014\({}^{ 0.000}\) & -0.018 & -0.001 & 0.007 & 0.007 & \\  & & PI-Width & **17.9\({}^{ 0.6}\)** & 27.8\({}^{ 0.0}\) & 24.6 & 28.2 & 31.9 & 33.0 & \\  &  & **0.30\({}^{ 0.01}\)** & 0.62\({}^{ 0.00}\) & 0.64 & 0.63 & 0.68 & 0.70 & \\   & \(\) Cov & \(0.028^{ 0.019}\) & 0.008\({}^{ 0.000}\) & -0.066 & -0.004 & -0.019 & -0.033 & \\  & PI-Width & **93.9\({}^{ 11.1}\)** & 118.5\({}^{ 0.1}\) & 202.8 & 263.5 & 243.1 & 229.8 & \\  &  & **1.50\({}^{ 0.09}\)** & 2.23\({}^{ 0.00}\) & 4.16 & 4.03 & 4.94 & 4.98 & \\   &  & \(\) Cov & \(0.017^{ 0.016}\) & 0.023\({}^{ 0.000}\) & -0.057 & -0.004 & -0.017 & -0.028 & -0.001 \\  & & PI-Width & **85.6\({}^{ 7.4}\)** & 113.2\({}^{ 0.1}\) & 178.3 & 224.8 & 206.7 & 196.5 & 186.4 \\  &  & **1.45\({}^{ 0.06}\)** & 1.94\({}^{ 0.00}\) & 3.69 & 3.64 & 4.33 & 4.36 & 3.00 \\   &  & \(\) Cov & \(0.010^{ 0.007}\) & 0.024\({}^{ 0.000}\) & -0.045 & -0.002 & 0.010 & 0.012 & \\  &  & **79.9\({}^{ 4.7}\)** & 93.9\({}^{ 0.1}\) & 120.0 & 153.3 & 153.7 & 155.3 & \\  &  & **1.35\({}^{ 0.06}\)** & 1.52\({}^{ 0.00}\) & 2.60 & 2.68 & 2.95 & 2.96 & \\   &  & \(\) Cov & -0.002\({}^{ 0.005}\) & 0.010\({}^{ 0.000}\) & -0.025 & -0.002 & 0.001 & 0.004 & \\  &  & 62.7\({}^{ 1.5}\) & 62.2\({}^{ 0.0}\) & 58.1 & 62.4 & **61.8** & 63.0 & \\  &  & 1.33\({}^{ 0.01}\) & **1.21\({}^{ 0.00}\)** & 1.32 & 1.29 & 1.34 & 1.34 & \\   & \(\) Cov & \(0.009^{ 0.019}\) & 0.007\({}^{ 0.000}\) & -0.042 & 0.000 & 0.014 & 0.005 & \\  & PI-Width & **1078.7\({}^{ 73.7}\)** & 1741.8\({}^{ 2.4}\) & 3671.6 & 6137.1 & 7131.1 & 7201.5 & \\   &  & \(\) Cov & -0.016\({}^{ 0.013}\) & 0.003\({}^{ 0.000}\) & -0.040 & -0.003 & 0.006 & -0.007 & 0.010 \\  & & PI-Width & **875.5\({}^{ 49.8}\)** & 1582.3\({}^{ 1.0}\) & 2924.1 & 4805.3 & 5588.5 & 5614.8 & 6273.5 \\  &  & **0.27\({}^{ 0.00}\)** & 0.49\({}^{ 0.00}\) & 0.96 & 1.25 & 1.43 & 1.46 & 1.50 \\   &  & \(\) Cov & -0.025\({}^{ 0.023}\) & -0.241\({}^{ 0.000}\) & -0.041 & -0.015 & -0.251 & -0.358 & \\   &  & \(\) Cov & -0.025\({}^{ 0.023}\) & 2060.5\({}^{ 1.6}\) &Metrics.In our analyses, we compute \(\)Cov, PI-Width, and the Winkler score (Winkler, 1972) per time series and miscoverage level. The Winkler score jointly elicitates miscoverage and interval width in a single metric:

\[_{}(_{t+1},y_{t+1})=_{t}^{}( {Z}_{t+1})+(y_{t+1}-_{t}^{,u}(_{t+1}))& y_{t+1}>_{t}^{,u}(_{t+1}),\\ _{t}^{}(_{t+1})+(_{t}^{,l }(_{t+1})-y_{t+1})&y_{t+1}<_{t}^{,l}(_{t+1}),\\ _{t}^{}(_{t+1})&.\] (9)

The score is calculated per time step \(t\) and miscoverage level \(\). It corresponds to the interval width \(_{t}^{}=_{t}^{,u}-_{t}^{,l}\) whenever the observed value \(y_{t}\) is between the upper bound \(_{t}^{,u}(_{t+1})\) and the lower bound \(_{t}^{,l}(_{t+1})\) of \(_{t}^{}(_{t+1})\). If \(y_{t+1}\) is outside these bounds, a penalty is added to the interval width. We evaluate the mean Winkler score over all time steps.

We repeated each experiment with \(12\) different seeds. For brevity, we only show the mean performance of one dataset per domain for \(=0.1\) in the main paper (which is the most commonly reported value in the CP literature; e.g., Xu and Xie, 2022; Foygel Barber et al., 2022; Gibbs and Candes, 2021). Appendix A.3 presents additional results for all datasets and more \(\) levels.

### Results & Discussion

HopCPT has the most efficient prediction intervals for each domain -- with only one exception (Table 1; significance tested with a Mann-Whitney \(U\) test at \(p<0.005\)) for the evaluated miscoverage level (\(=0.1\)). In multiple experiments (Solar (3Y), Solar (1Y)), the HopCPT prediction intervals are less than half as wide as those of the approach with the second-smallest PI-Width. The second-most efficient intervals are predicted most often by SPCI. This ranking also holds for the Winkler score, where HopCPT achieves the best (i.e., lowest) Winkler scores and SPCI ranks second in most experiments. Notably, these results reflect the increasing requirements posed by each uncertainty estimation method on the dataset (Section 1.1).

Furthermore, HopCPT outperforms the other methods regarding both Winkler score and PI-Width when we evaluate over additional datasets and at different miscoverage levels (see Appendix A.3). HopCPT is the best-performing approach in the vast majority of cases. The variation in size of the different solar datasets (results for Solar (1Y) and Solar (3M) in Appendix A.3) shows that HopCPT especially increases its lead when more data is available. We hypothesize that this is because the MHN can learn more generalizable retrieval patterns with more data. However, data scarcity is not a limitation of similarity-based CP in general. In fact, a simplified and almost parameter-free variation of HopCPT, which replaces the MHN with kNN retrieval, performs best on the smallest solar dataset, as we demonstrate in Appendix D.

Most approaches have a coverage gap close to zero in almost all experiments -- they approximately achieve the specified marginal coverage level. This is also reflected by the fact that the ranking of Winkler scores and PI-Widths agree in most evaluations. Appendix A.4 provides a supplementary analysis of the local coverage. The results for non-CP methods show a different picture (see Appendix A.3 and Table 7). Here, the non-CP models most often exhibit very narrow prediction intervals at the cost of high miscoverage.

Interestingly, standard CP also achieves good coverage for all experiments at the cost of inefficient prediction intervals. There is one notable exception: for the Sap flow dataset with ridge regression, we find \(=-0.358\). In this case, we argue that the bad performance of standard CP is driven by a strong violation of the (required) exchangeability assumption. Specifically, a trend in the errors leads to a distribution shift over time (as illustrated in Appendix A.3, Figure 4). HopCPT and NexCP handle this shift without substantial loss in coverage. The inferior coverage of SPCI is likely influenced by the modification to larger datasets (see Appendix A.2).

Performance gaps between the approaches differ considerably across datasets, but are generally consistent across prediction models. The biggest differences between the best and worst methods exist in Solar (3Y) and Sap flow, likely due to the distinctive regimes in these datasets. The smallest (but still significant) differences are visible in the Streamflow data. On this dataset, we also evaluated the state-of-the-art non-CP uncertainty model in the domain (Klotz et al., 2022, see Appendix A.3) and found that HopCPT outperforms it with respect to efficiency.

In terms of computational resources, SPCI is most demanding followed by HopCPT, as both methods require a learning step in contrast to the other methods. A detailed overview can be found in Appendix A.6.

To assess whether HopCPT learns meaningful associations within regimes, we conducted a qualitative study on the Solar (3Y) dataset. Figure 3 shows that HopCPT retrieves the most highly weighted errors from time steps with similar regimes. The illustrated weighting at the time step with a low prediction value retrieves previous time steps which are also in low-valued regimes. Similarly, Figure 5 (Appendix A.3) suggests that the learned distinction corresponds to the error regimes, which is crucial for HopCPT.

## 4 Conclusions

We have introduced HopCPT, a novel CP approach for time series tasks. HopCPT uses continuous Modern Hopfield Networks to construct prediction intervals based on previously seen events with similar error distribution regimes. We exploit that similar features lead to similar errors. Associating features with errors identifies regimes with similar error distributions. HopCPT learns this association in the Modern Hopfield Network, which dynamically adjusts its focus on stored previous features according to the current regime.

Our experiments with established and novel datasets show that HopCPT achieves state of the art: It generates more efficient prediction intervals than existing CP methods and approximately preserves coverage, even in non-exchangeable scenarios like time series. HopCPT comes with formal guarantees within the CP framework for uncertainty estimation in real-world applications such as streamflow prediction. Furthermore, HopCPT scales well to large datasets, provides multiple coverage levels after calibration, and shares information across individual time series within a dataset.

Future work comprises: (a) Drawing from multiple time series during the inference phase. HopCPT is already trained on the whole dataset at once, but it might be advantageous to leverage more information during inference as well. (b) Investigating direct training objectives from which learning-based CP might benefit. (c) Using HopCPT beyond time series, as non-exchangeability is also an issue in other domains which limits the applicability of existing CP methods.