# UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models

Wenliang Zhao

Equal contribution. \({}^{}\)Corresponding author.

Lujia Bai

Equal contribution. \({}^{}\)Corresponding author.

Yongming Rao

Jie Zhou

Jiwen Lu

Tsinghua University

Equal contribution. \({}^{}\)Corresponding author.

###### Abstract

Diffusion probabilistic models (DPMs) have demonstrated a very promising ability in high-resolution image synthesis. However, sampling from a pre-trained DPM is time-consuming due to the multiple evaluations of the denoising network, making it more and more important to accelerate the sampling of DPMs. Despite recent progress in designing fast samplers, existing methods still cannot generate satisfying images in many applications where fewer steps (_e.g._, \(<\)10) are favored. In this paper, we develop a unified corrector (UniC) that can be applied after any existing DPM sampler to increase the order of accuracy without extra model evaluations, and derive a unified predictor (UniP) that supports arbitrary order as a byproduct. Combining UniP and UniC, we propose a unified predictor-corrector framework called UniPC for the fast sampling of DPMs, which has a unified analytical form for any order and can significantly improve the sampling quality over previous methods, especially in extremely few steps. We evaluate our methods through extensive experiments including both unconditional and conditional sampling using pixel-space and latent-space DPMs. Our UniPC can achieve 3.87 FID on CIFAR10 (unconditional) and 7.51 FID on ImageNet 256\(\)256 (conditional) with only 10 function evaluations. Code is available at [https://github.com/wl-zhao/UniPC](https://github.com/wl-zhao/UniPC).

## 1 Introduction

Diffusion probabilistic models (DPMs)  have become the new prevailing generative models and have achieved competitive performance on many tasks including image synthesis , video synthesis , text-to-image generation , voice synthesis , _etc_. Different from GANs  and VAEs , DPMs are trained to explicitly match the gradient of the data density (_i.e._, score), which is more stable and less sensitive to hyper-parameters. However, sampling from a pre-trained DPM usually requires multiple model evaluations to gradually perform denoising from Gaussian noise , consuming more inference time and computational costs compared with single-step generative models like GANs.

Recently, there have been increasing efforts to accelerate the sampling of DPMs . Among those, training-free methods  enjoy a wider usage in applications because they can be directly applied to off-the-shelf pre-trained DPMs. Although these methods have significantly reduced the sampling steps from 1000 to less than 20 steps, the sampling quality with extremely few steps (_e.g._, \(<\)10) has been rarely investigated. Few-step sampling can be used in many scenarios where we need to efficiently obtain plausible samples, such as designing a proper prompt for a text-to-image diffusion model  and computing losses on the generated samples during the training of some diffusion-based visual systems . However, current fast samplers usually struggle to generate high-quality samples within 10 steps (see Figure 1).

In this paper, we propose a training-free framework for the fast sampling of DPMs called _UniPC_. We find that UniPC significantly outperforms existing methods within 5\(\)10 NFE (number of function evaluations), and can also achieve better sampling quality with more sampling steps. Specifically, we first develop a unified corrector (UniC) which works by using the the model output \(_{}(_{t_{i}},t_{i})\) at the current timestep \(t_{i}\) to obtain a refined \(_{t_{i}}^{c}\). Different from the predictor-corrector paradigm in numerical ODE solver that requires a doubled NFE, our UniC reuses the model output \(_{}(_{t_{i}},t_{i})\) to the next sampling step, thus introducing no extra function evaluation. UniC can be applied after any existing DPM sampler to increase the order of accuracy, while the inference speed is almost unaffected. Interestingly, we also find that by simply changing a hyper-parameter in UniC, a new family of predictors (UniP) can be further obtained.

Since our UniC is method-agnostic, we combine UniP and UniC to obtain a new family of fast samplers called UniPC. Different from previous fast solvers [26; 25; 40] that either have no higher-order (_e.g._, \(>3\)) variants or have no explicit forms, our UniPC supports arbitrary orders with a unified analytical expression and are easy to implement. Benefiting from the universal design, variants of UniPC (_e.g._, misglestpe/multistep, noise/data prediction) can be easily derived. We theoretically prove that UniPC enjoys higher convergence order and empirically demonstrate that UniPC has better sampling quality in a variety of scenarios. We also show that the inference speed and memory usage of UniPC is similar to DPM-Solver++ , indicating that UniPC can achieve superior performance under the same computational budgets.

We conduct extensive experiments with both pixel-space and latent-space DPMs to verify the effectiveness of the proposed UniPC. Our results show that UniPC performs consistently better than previous state-of-the-art methods on both unconditional and conditional sampling tasks. Notably, UniPC can achieve 3.87 FID on CIFAR10 (unconditional) and 7.51 FID on ImageNet \(256 256\) (conditional) with only 10 function evaluations. We also demonstrate that UniC can improve the sampling quality of several existing fast samplers significantly with very few NFE (number of function evaluations). Some qualitative comparisons are shown in Figure 1, where we observe that our UniPC can generate images with more visual details than other methods.

## 2 Background and Related Work

### Diffusion Probabilistic Models

For a random variable \(_{0}\) with an unknown distribution \(q_{0}(_{0})\), Diffusion Probabilistic Models (DPMs) [33; 13; 19] transit \(q_{0}(_{0})\) at time \(0\) to a normal distribution \(q_{T}(_{T})(_{T}|,^{2})\) at time \(T\) for some \(>0\) by gradually adding Gaussian noise to the observation \(_{0}\). For each time \(t[0,T]\), and given \(_{t},_{t}>0\), the Gaussian transition is

\[q_{t|0}(_{t}|_{0})=(_{t}|_{t}_{0}, _{t}^{2}),\]

where \(_{t}^{2}/_{t}^{2}\) (the _signal-to-noise-ratio_ (SNR)) is strictly decreasing w.r.t. \(t\).

Figure 1: **Qualitative comparisons between our UniPC and previous methods.** All images are generated by sampling from a DPM trained on ImageNet 256\(\)256 with only 7 number of function evaluations (NFE) and a classifier scale of 8.0. We show that our proposed UniPC can generate more plausible samples with more visual details compared with previous first-order sampler  and high-order samplers [40; 26]. Best viewed in color.

Let \(_{}(_{t},t)\) denote the noise prediction model using data \(_{t}\) to predict the noise \(\), and the parameter \(\) is obtained by minimizing

\[_{_{0},,t}[(t)\|_{}( _{t},t)-\|_{2}^{2}],\]

where \(_{0} q_{0}(_{0})\), \(t[0,T]\), and the weight function \((t)>0\). Sampling from DPMs can be achieved by solving the following diffusion ODEs :

\[_{t}}{t}=f(t)_{t}+(t)}{2 _{t}}_{}(_{t},t),t[0,T],_{T}(,^{2}) \]

where \(f(t)=_{t}}{t}\), \(g^{2}(t)=_{t}^{2}}{t}-2 _{t}}{t}_{t}^{2}\).

### Fast Sampling of DPMs

Fast samplers of DPMs can be either training-based [31; 2; 37] or training-free [25; 26; 40; 24; 41]. Training-based samplers require further training costs while training-free methods directly use the original information without re-training and are easy to implement in conditional sampling. The essence of training-free samplers is solving stochastic differential equations (SDEs)[13; 35; 3; 41] or ODEs[26; 40; 24; 34; 25]. Other fast sampling methods include modifying DPMs  and the combination with GANs [38; 36].

Among others, samplers solving diffusion ODEs are found to converge faster for the purpose of sampling DPMs [34; 35]. Recent works [40; 25; 26] show that ODE solvers built on exponential integrators  appear to have faster convergence than directly solving the diffusion ODE (1). The solution \(_{t}\) of the diffusion ODE given the initial value \(_{s}\) can be analytically computed as :

\[_{t}=}{_{s}}_{s}-_{t}_{_{s}} ^{_{t}}e^{-}}_{}(}_{}, ), \]

where we use the notation \(}_{}\) and \(}_{}\) to denote changing from the domain of time(\(t\)) to the domain of half log-SNR(\(\)), _i.e._, \(_{t}=(_{t}/_{t})\), \(}_{}:=_{t_{}()}\) and \(}_{}(,):=_{}(,t_{ }())\).

Based on the exponential integrator,  proposes to approximate \(}_{}\) via taylor expansion and views DDIM as DPM-Solver-1, i.e.,

\[}_{t_{i}}=}}{_{t_{i-1}}}}_ {t_{i-1}}-_{t_{i}}(e^{_{t_{i}}-_{t_{i-1}}}-1)_{}(}_{t_{i-1}},t_{i-1}). \]

 considers rewriting (2) using \(}_{}\) instead of \(}_{}\);  derives the taylor expansion formulae with respect to \(t\) instead of the half log-SNR(\(\)).  employs pseudo numerical methods such as Runge-Kutta method directly for the updating of \(_{}\) of (3). Although many aforementioned high-order solvers are proposed, existing solvers of diffusion ODEs can be explicitly computed for orders not greater than 3, due to the lack of analytical forms.

## 3 A Unified Predictor-Corrector Solver

In this section, we propose a unified predictor-corrector solver of DPMs called UniPC, consisting of UniP and UniC. Our UniPC is unified in mainly two aspects: 1) the predictor (UniP) and the corrector (UniC) share the same analytical form; 2) UniP supports arbitrary order and UniC can be applied after off-the-shelf fast samplers of DPMs to increase the order of accuracy.

### The Unified Corrector UniC-\(p\)

Modern fast samplers based on discretizing diffusion ODEs [25; 34; 40] aim to leverage the previous \(p\) points \(\{}_{t_{i-k}}\}_{k=1}^{p}\) to estimate \(}_{t_{i}}\) with \(p\) order of accuracy. Despite the rapid development of fast samplers, the quality of few-step sampling still has room for improvement. In this paper, we propose a corrector called UniC-\(p\) to improve the initial estimation using not only the previous \(p\) points but also the current point. Formally, after obtaining the initial estimation \(}_{t_{i}}\), we perform the correction step through the following formula:

\[}_{t_{i}}^{c}=}}{_{t_{i-1}}}}_{t_{i-1}}^{c}-_{t_{i}}(e^{h_{i}}-1)_{}(}_{t_{i-1}},t_{i-1})-_{t_{i}}B(h_{i})_{m=1}^{p}}{r _{m}}D_{m}, \]where \(}_{t_{i}}^{c}\) denotes the corrected result, \(B(h)=(h)\) is a non-zero function of \(h\), \(h_{i}=_{t_{i}}-_{t_{i-1}}\) is the step size in the half-log-SNR(\(\)) domain, \(r_{1}<r_{2}<<r_{p}=1\) are a non-zero increasing sequence, determining which previous points are used. Specifically, we use \(\{r_{i}\}_{m=1}^{p}\) to interpolate between \(_{t_{i-1}}\) to \(_{t_{i}}\) to obtain the auxiliary timesteps \(s_{m}=t_{}(r_{m}h+_{t_{i-1}}),m=1,2,,p\). The model outputs at these timesteps are used to compute \(D_{m}\) by

\[D_{m}=_{}(}_{s_{m}},s_{m})-_{}(}_{t_{i-1}},t_{i-1}). \]

We now describe how to choose \(\{a_{m}\}_{m=1}^{p}\) in UniC-\(p\) to effectively increase the order of accuracy. The main idea is to cancel out low-order terms between the numerical estimation (4) and the theoretical solution (2). In practice, we expand the exponential integrator in (2) as follows:

\[_{t_{i}}= }}{_{t_{i-1}}}_{t_{i-1}}-_{ t_{i}}(e^{h_{i}}-1)_{}(_{t_{i-1}},t_{i-1})\] \[-_{t_{i}}_{k=1}^{p}h_{i}^{k+1}_{k+1}(h_{i})}_{}^{(k)}(}_{_{t_{i-1}}},_{t_{i- 1}})+(h^{p+2}). \]

where \(}^{(k)}_{}\) denotes the \(k\)-th derivative of \(}_{}\), and \(_{k}(h)\) can be analytically computed . The \(\{a_{m}\}_{m=1}^{p}\) can be then determined by matching the coefficients between (4) and (6). In the following theorem, we show that UniC-\(p\) has an order of accuracy \(p+1\) (see Appendix E.3 for detailed proof).

**Theorem 3.1** (The Order of Accuracy of UniC-\(p\)).: _For any non-zero sequence \(\{r_{i}\}_{i=1}^{p}\) and \(h>0\), define_

\[_{p}(h)=1&1&&1\\ r_{1}h&r_{2}h&&r_{p}h\\ &&&\\ r_{1}h)^{p-1}&(r_{2}h)^{p-1}&&(r_{p}h)^{p-1}.\]

_Let \(_{p}(h)=(_{1}(h),,_{p}(h))^{}\) with \(_{n}(h)=h^{n}n!_{n+1}(h)\), where \(_{n}(h)\) is defined by the recursive relation :_

\[_{n+1}(h)=(h)-1/n!}{h},_{0}(h)=e^{h}.\]

_For an increasing sequence \(r_{1}<r_{2}<<r_{p}=1\), suppose \(_{p}:=(a_{1},,a_{p})^{}\) satisfies,_

\[|_{p}(h_{i})_{p}B(h_{i})-_{p}(h_{i})|=(h_{i}^ {p+1}), \]

_where \(||\) denotes the \(l_{1}\) norm for matrix. Then, under regularity conditions in Appendix E.2, UniC-\(p\) of (4) will have \((p+1)\)-th order of accuracy._

The monotonicity of \(\{r_{i}\}_{i=1}^{p}\) ensures the invertibility of the Vandermonde matrix \(_{p}\). Therefore, we can take \(_{p}=_{p}^{-1}(h_{i})_{p}(h_{i})/B(h_{i})\) as the coefficient vector for (4) for simplicity, where \(B(h)\)can be any function of \(h\) such that \(B(h)=(h)\), for example \(B_{1}(h)=h\), \(B_{2}(h)=e^{h}-1\). The detailed implementation of UniC is shown in Algorithm 1. Importantly, we circumvent the extra evaluation of \(_{}(}_{t_{i}}^{c},t_{i})\) by pushing \(_{}(}_{t_{i}},t_{i})\) into the buffer \(Q\) instead of \(_{}(}_{t_{i}}^{c},t_{i})\). Taking full advantage of \(_{}(}_{t_{i}},t_{i})\) of previous results enables us to increase the order of accuracy without incurring significant increment of computation cost. This makes our method inherently different from the predictor-corrector methods in ODE literature , where the computational costs are doubled because an extra function evaluation on the corrected \(}_{t_{i}}^{c}\) is required for each step.

### The Unified Predictor UniP-\(p\)

We find that the order of accuracy of UniC does not depend on the specific choice of the sequence \(\{r_{i}\}_{i=1}^{p}\), which motivates us to design \(p\)-order unified predictor (UniP-\(p\)) which only leverages the previous \(p\) data points by excluding \(D_{p}\) in (4) since \(D_{p}\) involves \(}_{t_{i}}\). The order of accuracy is guaranteed by the following corollary.

**Corollary 3.2** (The Order of Accuracy of UniP-\(p\)).: _For an increasing sequence \(r_{1}<r_{2}<<r_{p-1}<1\), the solver given in (4) dropping the term \(D_{p}\) and using coefficients that satisfies_

\[|_{p-1}(h_{i})_{p-1}B(h_{i})-_{p-1}(h_{i})|=(h _{i}^{p}) \]

_has \(p\)-th order of accuracy._

Due to the unified form of UniP and UniC, we can use UniP-\(p\) as the implementation of the Solver-p in UniC-\(p\) to obtain a new family of solvers called UniPC-\(p\). Theorem 3.1 and Corollary 3.2 ensure that UniPC-\(p\) can achieve \((p+1)\)-th order of accuracy. Moreover, under additional regularity conditions in Appendix D, based on Theorem 3.1 and Corollary 3.2, we show that the order of convergence of UniPC-\(p\) reaches \(p+1\) (see Appendix D).

### Comparison with Existing Methods

Here we discuss the connection and the difference between UniPC and previous methods. When \(p=1\), UniPC will reduce to DDIM . Motivated by linear multistep approaches, PNDM  proposes to use pseudo numerical methods for DDIM, while our UniPC makes use of information in the ODE solution (2) and is specially designed for diffusion ODEs. DEIS  is built on exponential integrators in the time domain, where the integral cannot be analytically computed and explicit formulae for high-order solvers cannot be derived. By using the half log-SNR \(\)[25; 26], it is shown that the application of integration-by-parts can simplify the integration of (2) and leads to explicit expansion of \(_{t}\). DPM-Solver-2  lies in our UniPC framework as UniP-1, where they assume \(B(h)=e^{h}-1\). We find through our numerical analysis that \(B(h)\) can be any non-degenerate function such that \(B(h)=(h)\). Furthermore, DPM-Solvers do not admit unified forms even for orders smaller than \(3\), which adds to the challenge of obtaining algorithms for higher orders. In contrast, our UniPC exploits the structure of exponential integrators w.r.t. half log-SNR and admits not only simple and analytical solutions for efficient computation but also unified formulations for easy implementation of any order.

### Implementation

By setting \(r_{m}=(_{t_{i-m-1}}-_{t_{i}})/h_{i}\), \(m=1,,p-1\), the UniPC-\(p\) updates in a multistep manner, which reuses the previous evaluation results and proves to be empirically more efficient, especially for limited steps of model evaluation [11; 26], while singlestep methods might incur higher computation cost per step. Therefore, we use multistep UniPC in our experiments by default. The detailed algorithms for multistep UniPC and the proof of convergence can be found in Appendix B. For UniPC, the choices of \(\{r_{i}\}_{i=1}^{p-1}\) determine different updating methods. If all the values are in \((0,1]\), the UniPC will switch to singlestep. Notably, we find in experiments that our UniC consistently improves different updating methods. Besides, we find UniP-2 (8) and UniC-1 (7) degenerate to a simple equation where only a single \(a_{1}\) is unknown, where we find \(a_{1}=0.5\) can be a solution for both \(B_{1}(h)\) and \(B_{2}(h)\) (see Appendix F) independent of \(h\). In Appendix C, we provide another variant of UniPC called UniPC\({}_{v}\) where the coefficients do not depend on \(h\) for arbitrary order \(p\).

In the conditional inference, guided sampling [14; 8] is often employed. Recent works [30; 26] find that thresholding data prediction models can boost the sampling quality and mitigate the problem of train-test mismatch. Our framework of UniPC can be easily adapted to the data prediction model, see Appendix A for algorithms and theoretical analysis. The detailed algorithms for multistep UniPC for data prediction are in Appendix B. Hence, UniPC with data prediction can achieve fast conditional sampling in extremely few steps through dynamic thresholding.

## 4 Experiments

In this section, we show that our UniPC can significantly improve the sampling quality through extensive experiments. Our experiments cover a wide range of datasets, where the image resolution ranges from 32\(\)32 to 256\(\)256. Apart from the standard image-space diffusion models [35; 8], we also conduct experiments on the recent prevailing stable-diffusion  trained on latent space. We will first present our main results in Section 4.1 and then provide a detailed analysis in Section 4.2.

### Main Results

We start by demonstrating the effectiveness of our UniPC on both unconditional sampling and conditional sampling tasks, with extremely few model evaluations (\(<\)10 NFE). For the sake of clarity, we compare UniPC with the previous state-of-the-art method DPM-Solver++ . We have also conducted experiments with other methods including DDIM , DPM-Solver , DEIS , and PNDM . However, since some of these methods perform very unstable in few-step sampling, we leave their results in Section 4.2 and Appendix G.

**Unconditional sampling.** We first compare the unconditional sampling quality of different methods on CIFAR10 , FFHQ , and LSUN Bedroom . The pre-trained diffusion models are from  and , including both pixel-space and latent-space diffusion models. The results are shown in Figure 2. For DPM-Solver++, we use the multistep 3-order version due to its better performance. For UniPC, we use a combination of UniP-3 and UniC-3, thus the order of accuracy is 4. As shown in Figure 3, we find that our UniPC consistently achieves better sampling quality than DPM-Solver++ on different datasets, especially with fewer NFE. Notably, compared with DPM-Solver++, our UniPC improves the FID by 6.0, 5.9, and 8.5 on CIFAR10, LSUN Bedroom, and FFHQ, respectively. These results clearly demonstrate that our UniPC can effectively improve the unconditional sampling quality with few function evaluations.

**Conditional sampling.** Conditional sampling is more useful since it allows user-defined input to control the synthesized image. To evaluate the conditional sampling performance of our UniPC, we conduct experiments on two widely used guided sampling settings, including classifier guidance and classifier-free guidance. For classifier guidance, we use the pixel-space diffusion model trained on ImageNet 256\(\)256  provided by . Following DPM-Solver++, we use dynamic thresholding  to mitigate the gap between training and testing. The results are shown in Figure 2(a) and 2(b), where we compare our UniPC with DPM-Solver++  under different guidance scale (\(s=8.0/4.0\)). For DPM-Solver++, we use the multistep 2-order version (2M), which achieves the best results

Figure 2: **Unconditional sampling results. We compare our UniPC with DPM-Solver++  on CIFAR10, LSUN Bedroom, and FFHQ. We report the FID\(\) of the methods with different numbers of function evaluations (NFE). Experimental results demonstrate that our method is consistently better than previous ones on both pixel-space DPMs and latent-space DPMs, especially with extremely few steps. For more results, we recommend refering to Table 8-10 in Appendix G.**

according to the original paper. For our UniPC, we use UniP-2 and UniC-2. It can be seen that our UniPC generates samples with better quality and converges rather faster than other methods. For classifier-free guidance, we adopt the latent-space diffusion model provided by stable-diffusion  and set the guidance scale as 1.5 following their original paper. To obtain the input texts, we randomly sample 10K captions from MS-COCO2014 validation dataset . As discussed in , the FID of the text-to-image saturates in \(<\)10 steps, possibly because the powerful decoder can generate good image samples from non-converged latent codes. Therefore, to examine how fast a method converges, we follow  to compute the \(l_{2}\)-distance between the generated latent code \(_{0}\) and the true solution \(_{0}^{*}\) (obtained by running a 999-step DDIM), _i.e._, \(\|_{0}-_{0}^{*}\|_{2}/\), where \(D\) is the dimension of the latent code. For each text input, we use the same initial value \(_{T}^{*}\) sampled from Gaussian distribution for all the compared methods. It can be seen in Figure 2(c) that our UniPC consistently has a lower \(l_{2}\)-distance than DPM-Solver++, which indicates that UniPC converges faster in guided sampling.

### Analysis

In this section, we will provide more detailed analyses to further evaluate the effectiveness of UniPC.

**Ablation on the choice of \(B(h)\).** In Section 3, we mentioned that \(B(h)\) is set to be any non-zero function of \(h\) that satisfies \(B(h)=(h)\). We now investigate how the choice of \(B(h)\) would affect the performance of our UniPC. Specifically, we test two simple forms: \(B_{1}(h)=h\) and \(B_{2}(h)=e^{h}-1\) and the results are summarized in Table 1, where we also provide the performance of DPM-Solver++  for reference. We show that UniPC with either implementation of \(B(h)\) can outperform DPM-Solver++. When the NFE is extremely small (5\(\)6), we observe that \(B_{1}(h)\) consistently outperforms \(B_{2}(h)\) by 1\(\)3 in FID. On the other hand, as the NFE increases, the performance of \(B_{2}(h)\) catches up and even surpasses \(B_{1}(h)\) in some experiments (_e.g._, on CIFAR10 and LSUN Bedroom). As for the guided sampling, we find \(B_{1}(h)\) is worse than \(B_{2}(h)\) consistently (see Appendix G for detailed results and discussions). These results also inspire us that our UniPC can be further improved by designing better \(B(h)\), which we leave to future work.

Table 1: **Ablation on the choice of \(B(h)\).** We consider two implementations of \(B(h)\) and also provide the performance of DPM-Solver++  for comparison. The results are measured by the FID(\(\)) on CIFAR10  and FFHQ . We show that while the UniPC with both the two forms of \(B(h)\) can outperform DPM-Solver++, \(B_{1}(h)\) performs better at fewer sampling steps.

Figure 3: **Conditional sampling results. (a)(b) We compare the sample quality measured by FID\(\) on ImageNet 256\(\)256 with guidance scale \(s=8.0/4.0\); (c) We adopt the text-to-image model provided by stable-diffusion  to compare the convergence error, which is measured by the \(l_{2}\) distance between the results of different methods and 1000-step DDIM. We show that our method outperforms previous ones with various guidance scales and NFE.**

**UniC for any order solver.** As shown in Algorithm 1, our UniC-\(p\) can be applied after any \(p\)-order solver to increase the order of accuracy. To verify this, we perform experiments on a wide range of solvers. The existing solvers for DPM can be roughly categorized by the orders or the updating method (_i.e._, singlestep or multistep). Since DPM-Solver++  by design has both singlestep and multistep variants of 1\(\)3 orders, we apply our UniC to different versions of DPM-Solver++ to see whether UniC can bring improvements. The results are reported in Table 2, where the sampling quality is measured by FID\(\) on CIFAR10 by sampling from a pixel-space DPM . We also provide the order of accuracy of each baseline method without/with our UniC. Apart from the DDIM , which can be also viewed as 1-order singlestep DPM-Solver++, we consider another 3 variants of DPM-Solver++ including 2-order multistep (2M), 3-order singlestep (3S) and 3-order multistep (3M). It can be found that our UniC can increase the order of accuracy of the baseline methods by 1 and consistently improve the sampling quality for the solvers with different updating methods and orders.

**Exploring the upper bound of UniC.** According to Algorithm 1, our UniC works by leveraging the rough prediction \(}_{t_{i}}\) as another data point to perform correction and increase the order of accuracy. Note that to make sure there is no extra NFE, we directly feed \(_{}(}_{t_{i}},t_{i})\) to the next updating step instead of re-computing a \(_{}(}_{t_{i}}^{c},t_{i})\) for the corrected \(}_{t_{i}}^{c}\). Although the error caused by the misalignment between \(_{}(}_{t_{i}},t_{i})\) and \(_{}(}_{t_{i}}^{c},t_{i})\) has no influence on the order of accuracy (as proved in Appendix E.7), we are still interested in how this error will affect the performance. Therefore, we conduct experiments where we re-compute the \(_{}(}_{t_{i}}^{c},t_{i})\) as the input for the next sampling step, which we name as "UniC-oracle". Due to the multiple function evaluations on each \(t_{i}\) for both \(}_{t_{i}}\) and \(}_{t_{i}}^{c}\), the real NFE for UniC-oracle is twice as the standard UniC for the same sampling steps. However, UniC-oracle is very helpful to explore the upper bound of UniC, and thus can be used in pre-experiments to examine whether the corrector is potentially effective. We compare the performance of UniC and UniC-oracle in Table 3, where we apply them to the DPM Solver++  on LSUN Bedroom  and FFHQ  datasets. We observe that the UniC-oracle can significantly improve the sampling quality over the baseline methods. Although the approximation error caused by the misalignment makes UniC worse than UniC-oracle, we find that UniC can still remarkably increases the sampling quality over the baselines, especially with few sampling steps.

**Customizing order schedule via UniPC.** Thanks to the unified analytical form of UniPC, we are able to investigate the performance of arbitrary-order solvers and customize the order schedule freely. As a first attempt, we conduct experiments on CIFAR10 with our UniPC, varying the order schedule (the order at each sampling step). Some results are listed in Table 4, where we test different order schedules with NFE=6/7 because the search space is not too big. Note that the order schedule in Table 4 represents the order of accuracy of the UniP, while the actual order is increased by 1 because of UniC. Our default order schedule follows the implementation of DPM-Solver++ , where lower-order solvers are used in the final few steps. Interestingly, we find some customized order schedules can yield better results, such as 123432 for NFE=6 and 1223334 for NFE=7. We also show that simply increasing the order as much as possible is harmful to the sampling quality.

**Sampling diversity.** Apart from the sampling quality, we are also interested in the diversity of the images generated by UniPC. In Table 6, we compare the sampling diversity of UniPC and

   Sampling Method &  \\   & 5 & 6 & 8 & 10 \\  _LSUN Bedroom, Latent-space DPM_ & & & & & \\  DPM Solver++ (126) & 17.79 & 8.03 & 4.04 & 3.63 \\ + UniC & 13.79 & 6.53 & 3.98 & 3.52 \\ + UniC-oracle & 6.06 & 4.39 & 3.46 & 3.22 \\  _FFHQ Latent-space DPM_ & & & & & \\  DPM Solver++ (126) & 27.15 & 15.60 & 8.98 & 7.39 \\ + UniC & 21.73 & 13.38 & 8.67 & 7.22 \\ + UniC-oracle & 15.29 & 11.25 & 8.33 & 7.03 \\   

Table 3: **Exploring the upper bound of UniC.** We compare the performance of UniC and UniC-oracle by applying them to the DPM Solver++. Note that the NFE of UniC-oracle is twice the number of sampling steps. Our results show that UniC still has room for improvement.

**Comparisons with more NFE.** To further evaluate the effectiveness of our UniPC, we also perform experiments with 10\(\)25 NFE. Specifically, we perform guided sampling on ImageNet 256\(\)256  with guidance scale \(8.0\) and compare our UniPC with more existing methods including DDIM, DPM-Solver, PNDM, DEIS, and DPM-Solver++. We summarize the results in Table 5, where some results of the previous methods are from . The results clearly demonstrate that our UniPC surpasses previous methods by a large margin.

**Inference speed and memory.** We test the wall-clock time of UniPC by sampling from a stable-diffusion model  using a single NVIDIA RTX 3090 GPU and the results are shown in Table 7. We find the actual inference time of UniPC is very similar to DPM-Solver++ . As for memory usage, it is only related to how many previous model outputs are stored. Therefore, our UniPC also costs similar memory to DPM-Solver++. For example, both UniPC-2 and DPM-Solver++(2M) cost about 6.3GB of memory when sampling from a stable-diffusion model.

**Visualizations.** We provide a qualitative comparison between our UniPC and previous methods with only 7 NFE, as shown in Figure 1. We use different methods to perform guided sampling with a guidance scale of 8.0 from a DPM trained on ImageNet 256\(\)256. We find DEIS  tends to crash with extremely few steps, while the sample generated by DDIM  is relatively blurry. Compared with DPM-Solver++, the state-of-the-art method in guided sampling, UniPC can generate more plausible samples with better visual details. We further compare the sampling quality of our method UniPC and DPM-Solver++ using Stable-Diffusion-XL, a newly released model that can generate \(1024 1024\) images. The results in Figure 4 show that our method consistently generates more realistic images with fewer visual flaws.

**Limitations and broader impact.** Despite the effectiveness of UniPC, it still lags behind training-based methods such as . How to further close the gap between training-free methods and training-based methods requires future efforts.

## 5 Conclusions

In this paper, we have proposed a new unified predictor-corrector framework named UniPC for the fast sampling of DPMs. Unlike previous methods, UniPC has a unified formulation for its two components (UniP and UniC) for any order. The universality of UniPC makes it possible to customize arbitrary order schedules and to improve the order of accuracy of off-the-shelf fast sampler via UniC.

    &  \\   & 5 & 6 & 8 & 10 \\  DPM-Solver++  & 7.27 & 8.62 & 9.52 & 9.69 \\ UniPC & **7.55** & **8.81** & **9.59** & **9.83** \\   

Table 6: **Comparisons of sampling diversity.** We compute the Inception Score (IS) on CIFAR10  and find UniPC can generate more diverse samples than DPM-Solver++ .

   _CIFAR10, NFE = 6_ & & & & \\  Order Schedule & 123321 & 123432 & 123443 & 123456 \\ FID\(\) & 10.33 & **9.03** & 11.23 & 22.98 \\  _CIFAR10, NFE = 7_ & & & & \\  Order Schedule & 1233321 & 1223334 & 1234321 & 1234567 \\ FID\(\) & 6.41 & **6.29** & 7.24 & 60.99 \\   

Table 4: **Customizing order schedule via UniPC.** We investigate different order schedules with UniPC and find that some customized order schedules behave better than the default settings, while simply increasing the order as much as possible is harmful to the sampling quality.

   Sampling Method \(\) NFE & 10 & 15 & 20 & 25 \\  DDMM (34) & 13.04 & 11.27 & 10.21 & 9.87 \\ DPM-Solver (25) & 114.62 & 44.05 & 20.33 & 9.84 \\ PNDM () & 99.80 & 37.59 & 15.50 & 11.54 \\ DEIS () & 19.12 & 11.37 & 10.08 & 9.75 \\ DPM-Solver++ (26) & 9.56 & 8.64 & 8.50 & 8.39 \\  UniPC (Ours) & **7.51** & **6.76** & **6.65** & **6.58** \\   

Table 5: **Comparisons with more NFE.** We compare the sampling quality between UniPC and previous methods with 10-25 NFE on ImageNet 256\(\)256 and show our UniPC still outperforms previous methods by a large margin.

Extensive experiments have demonstrated the effectiveness of UniPC on unconditional/conditional sampling tasks with pixel-space/latent-space pre-trained DPMs. We have also discovered several directions where UniPC can be further improved, such as choosing a better \(B(h)\), estimating a more accurate \(_{}(}_{t_{i}}^{c},t_{i})\), and designing a better order schedule. We hope our attempt can inspire future work to further explore the fast sampling of DPMs in very few steps.

Figure 4: Comparisons of text-to-image results between UniPC and DPM-Solver++\(\). Images are sampled from the newly released _Stable-Diffusion-XL_ (1024\(\)1024) using 15 NFE. We show that the images generated by DPM-Solver++ contain visible artifacts while UniPC consistently produces images with better quality. Please view the images in color and zoom in for easier comparison.