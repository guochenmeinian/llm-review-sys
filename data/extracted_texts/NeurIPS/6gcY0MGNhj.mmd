# Statistical Analysis of Quantum State Learning

Process in Quantum Neural Networks

 Hao-kai Zhang\({}^{1,3}\), Chenghong Zhu\({}^{2,3}\), Mingrui Jing\({}^{2,3}\), Xin Wang\({}^{2,3}\)

\({}^{1}\) Institute for Advanced Study, Tsinghua University, Beijing 100084, China

\({}^{2}\) Thrust of Artificial Intelligence, Information Hub,

Hong Kong University of Science and Technology (Guangzhou), China

\({}^{3}\) Institute for Quantum Computing, Baidu Research, Beijing, China

felixxinwang@hkust-gz.edu.cn

###### Abstract

Quantum neural networks (QNNs) have been a promising framework in pursuing near-term quantum advantage in various fields, where many applications can be viewed as learning a quantum state that encodes useful data. As a quantum analog of probability distribution learning, quantum state learning is theoretically and practically essential in quantum machine learning. In this paper, we develop a no-go theorem for learning an unknown quantum state with QNNs even starting from a high-fidelity initial state. We prove that when the loss value is lower than a critical threshold, the probability of avoiding local minima vanishes exponentially with the qubit count, while only grows polynomially with the circuit depth. The curvature of local minima is concentrated to the quantum Fisher information times a loss-dependent constant, which characterizes the sensibility of the output state with respect to parameters in QNNs. These results hold for any circuit structures, initialization strategies, and work for both fixed ansatzes and adaptive methods. Extensive numerical simulations are performed to validate our theoretical results. Our findings place generic limits on good initial guesses and adaptive methods for improving the learnability and scalability of QNNs, and deepen the understanding of prior information's role in QNNs.

## 1 Introduction

Recent experimental progress towards realizing quantum information processors [1; 2; 3] has fostered the thriving development of the emerging field of quantum machine learning (QML) [4; 5; 6; 7; 8; 9; 10; 11; 12; 13; 14; 15; 16; 17; 18], pursuing quantum advantages in artificial intelligence. Different QML algorithms have been proposed for various topics, e.g., quantum simulations [19; 20; 21; 22; 23], chemistry [24; 25; 26; 27; 28], quantum data compression [29; 30], generative learning [31; 32] and reinforcement learning , where quantum neural networks (QNNs) become a leading framework due to the hardware restriction from noisy intermediate scale quantum (NISQ)  devices. As quantum analogs of artificial neural networks, QNNs typically refer to parameterized quantum circuits which are trainable based on quantum measurement results.

However, QNNs face a severe scalability barrier which might prevent the realization of potential quantum advantages. A notorious example is the barren plateau phenomenon  which shows that the gradient of the loss function vanishes exponentially in the system size with a high probability for randomly initialized deep QNNs, giving rise to an exponential training cost. To address this issue, a variety of training strategies has been proposed, such as local loss functions , correlated parameters , structured architectures [38; 39; 40], good initial guesses [41; 42], initialization heuristics near the identity [43; 44; 45; 46], adaptive methods  and layerwise training , etc. Nevertheless, thereis a lack of scalability analyses for these strategies to guarantee their effectiveness. Especially, since the identity initialization and adaptive or layerwise training methods do not require uniformly random initialization of deep QNNs, they are out of the scope of barren plateaus and urgently need a comprehensive theoretical analysis to ascertain their performance under general conditions.

In this work, we analyze the learnability of QNNs from a statistical perspective considering the information of loss values. Specifically, given a certain loss value during the training process, we investigate the statistical properties of surrounding training landscapes. Here we mainly focus on quantum state learning tasks , which can be seen as a quantum analog of probability distribution learning and play a central role in QML. To summarize, our contributions include:

* We prove a no-go theorem stating that during the process of learning an unknown quantum state with QNNs, the probability of avoiding local minima is of order \((N^{2}2^{-N}D^{2}/^{2})\) as long as the loss value is lower than a critical threshold (cf. Fig. 1). The bound vanishes exponentially in the qubit count \(N\) while only increases polynomially with the circuit depth \(D\). The curvature of local minima is concentrated to the quantum Fisher information times a loss-dependent constant. The proof is mainly based on the technique of "subspace Haar integration" we developed in Appendix A.1. A generalized version for the local loss function is provided in Appendix C.
* We conduct extensive numerical experiments to verify our theoretical findings. We first compare our bound with practical loss curves to show the prediction ability on the statistical behavior of the actual training process. Then we sample landscape profiles to visualize the existence of asymptotic local minima. Finally, we compute the gradients and diagonalize the Hessian matrices to directly verify the correctness of our bound.
* Our results place general limits on the learnability of QNNs, especially for the training strategies beyond the scope of barren plateaus, including high-fidelity initial guesses, initialization heuristics near the identity, and adaptive and layerwise training methods. Moreover, our results provide a theoretical basis for the necessity of introducing prior information into QNN designs and hence draw a guideline for future QNN developments.

Figure 1: Sketches of our work characterizing the statistical performance of QNNs on quantum state learning tasks. (a) indicates the existence of a critical loss value \(_{c}=1-2^{-N}\) below which the local minima start to become severe to trap the training process. (b) depicts the setup of quantum state learning tasks where a QNN is used to learn an unknown target state encoding practical data. All target states with a constant distance to the output state \(|^{*}\) form our ensemble \(\), depicted by the contour on the Bloch sphere. (c) shows typical loss curves for different qubit counts of \(N=2,6,10\) and circuit depths of \(D=1,3,5\). The intensity of the background colors represents the magnitude of our theoretical bound on the probability of encountering a local minimum, which hence signifies the hardness of optimization. One can find that the theoretical bound appropriately reflects the hardness encountered by the practical loss curves.

### Related works

The barren plateau phenomenon was first discovered by , which proves that the variance of the gradient vanishes exponentially with the system size if the randomly initialized QNN forms a unitary \(2\)-design. Thereafter,  finds the dependence of barren plateaus on the circuit depth for loss functions with local observables.  proves that training QNNs is in general NP-hard.  introduces barren plateaus from uncertainty which precludes learning scramplers. [51; 52] establish connections among the expressibility, generalizability and trainability of QNNs.  and  show that apart from barren plateaus, QNNs also suffer from local minima in certain cases.

On the other hand, many training strategies have been proposed to address barren plateaus. Here we only list a small part relevant to our work. [43; 44; 45; 46] suggest that initializing the QNN near the identity could reduce the randomness and hence escape from barren plateaus.  and  propose adaptive and layerwise training methods which avoid using randomly initialized QNNs in order to avoid barren plateaus, whereas  finds counterexamples where the circuit training terminates close to the identity and remains near to the identity for subsequently added layers without effective progress.

## 2 Quantum computing basics and notations

We use \(\|\|_{p}\) to denote the \(l_{p}\)-norm for vectors and the Schatten-\(p\) norm for matrices. \(A^{}\) is the conjugate transpose of matrix \(A\). \(A\) represent the trace of \(A\). The \(\)-th component of the vector \(\) is denoted as \(_{}\) and the derivative with respect to \(_{}\) is simply denoted as \(_{}=}\). We employ \(\) as the asymptotic notation of upper bounds.

In quantum computing, the basic unit of quantum information is a quantum bit or qubit. A single-qubit pure state is described by a unit vector in the Hilbert space \(^{2}\), which is commonly written in Dirac notation \(|=|0+|1\), with \(|0=(1,0)^{T}\), \(|1=(0,1)^{T}\), \(,\) subject to \(||^{2}+||^{2}=1\). The complex conjugate of \(|\) is denoted as \(|=|^{}\). The Hilbert space of \(N\) qubits is formed by the tensor product "\(\)" of \(N\) single-qubit spaces with dimension \(d=2^{N}\). We denote the inner product of two states \(|\) and \(|\) as \(|\) and the overlap is defined as \(|||\). General mixed quantum states are represented by the density matrix, which is a positive semidefinite matrix \(^{d d}\) subject to \(=1\). Quantum gates are unitary matrices, which transform quantum states via the matrix-vector multiplication. Common single-qubit rotation gates include \(R_{x}()=e^{-i X/2}\), \(R_{y}()=e^{-i Y/2}\), \(R_{z}()=e^{-i Z/2}\), which are in the matrix exponential form of Pauli matrices

\[X=0&1\\ 1&0, Y=0&-i\\ i&0, Z=1&0\\ 0&-1.\] (1)

Common two-qubit gates include controlled-X gate \(=I X\) (\(\) is the direct sum) and controlled-Z gate \(=I Z\), which can generate quantum entanglement among qubits.

### Framework of Quantum Neural Networks

Quantum neural networks (QNNs) typically refer to parameterized quantum circuits \(()\) where the parameters \(\) are trainable based on the feedback from quantum measurement results using a classical optimizer. By assigning some loss function \(()\), QNNs can be used to accomplish various tasks just like artificial neural networks. A general form of QNNs reads \(()=_{=1}^{M}U_{}(_{})W_{}\), where \(U_{}(_{})=e^{-i_{}_{}}\) is a parameterized gate such as single-qubit rotations with \(_{}\) being a Hermitian generator. \(W_{}\) is a non-parameterized gate such as \(\) and \(\). The product \(_{=1}^{M}\) is by default in the increasing order from the right to the left. \(M\) denotes the number of trainable parameters. Note that QNNs with intermediate classical controls  can also be included in this general form theoretically. Commonly used templates of QNNs include the hardware efficient ansatz , the alternating-layered ansatz (ALT)  and the tensor-network-based ansatz [36; 58], which are usually composed of repeated layers. The number of repeated layers is called the depth of the QNN, denoted as \(D\). Fig. 2 depicts an example of the ALT circuit. The gradients of loss functions of certain QNNs are evaluated by the parameter-shift rule [59; 60; 61] on real quantum devices. Hence we can train QNNs efficiently with gradient-based optimizers .

Here we focus on quantum state learning tasks, the objective of which is to learn a given target state \(|\) encoding practical data via minimizing the distance between the target state \(|\) and the outputstate from the QNN \(|()=U()|0^{ N}\). The corresponding loss function is usually chosen as the fidelity distance

\[()=1-||()|^{2}\,.\] (2)

which can be efficiently calculated on quantum computers using the swap test . An important quantity we used below characterizing the sensitivity of the QNN output state \(|()\) regarding its parameters \(\), the quantum Fisher information (QFI) matrix \(_{}\), which is defined as the Riemannian metric induced from the fidelity distance (cf. Appendix A.4)

\[_{}()=2[_{ }|_{}-_{}| |_{}].\] (3)

If the QFI is not full-rank, we say \(|()\) is over-parameterized [65; 66] meaning that there are redundant degrees of freedom in the parameters over the manifold dimension of the state.

## 3 Statistical characterization of quantum state learning in QNNs

In this section, we develop a no-go theorem characterizing the limitation of quantum neural networks in state learning tasks from a statistical perspective. In short, we prove that the probability of avoiding local minima during the process of learning an unknown quantum state with a QNN is of order \((2^{-N}M^{2}/^{2})\), where \(N\) is the number of qubits, \(M\) is the number of trainable parameters and \(\) represents the typical precision of measurements. The detailed upper bound also depends on the overlap between the value of the loss function and the QFI of the QNN. Our bounds significantly improve existing results of the trainability analysis of QNNs, which mainly focus on the randomness from the initialization and neglect the information of the loss function value. We will first introduce our ensemble setting in Section 3.1, then present our main theorem on local minima in Section 3.2 and finally show some results beyond local minima in Section 3.4.

### Ensemble of the unknown target state

We first introduce the probability measure used in this work. The randomness studied by most of the previous work on the trainability analyzes of QNNs originates from the random initialization of trainable parameters , which usually depends on the circuit depth, specific choices of the QNN architecture and initialization strategies . Meanwhile, the randomness can also come from the lack of prior information, such as learning an unknown quantum state or an unknown scrambler like a black hole . We focus on the latter in the present work.

The usage of adaptive methods is usually not covered by common trainability analyses, however, the training process often tends to stagnate. With the aim of investigating the trainability at a specific loss function value, the ensemble is constructed by a uniform measure of overall pure states that have the same overlap with the current output state of the QNN. Specifically, suppose \(^{*}\) is the current value of the trainable parameters. The overlap, or fidelity, between the output state \(|^{*}=|(^{*})\) and the target state \(|\) equals to \(||^{*}|=p\). Thus, the target state can be decomposed as

\[|=p|^{*}+}|^{},\] (4)

where \(|^{}\) represents the unknown component in the target state \(|\) orthogonal to the learnt component \(|^{*}\). If no more prior information is known about the target state \(|\) except for the overlap

Figure 2: The quantum circuit of the alternating-layered ansatz on \(4\) qubits. The circuit starts with a \(R_{y}\) layer and a \(R_{x}\) layer, followed by \(D\) repeated layers, where each layer contains alternating \(2\)-qubit unit blocks of a \(\) gate, two \(R_{y}\) gates and two \(R_{z}\) gates.

\(p\), in the spirit of Bayesian statistics, \(|^{}\) is supposed to be a random state uniformly distributed in the orthogonal complement of \(|^{*}\), denoted as \(^{}\). Such a Haar-random state can induce an ensemble of the unknown target state via Eq. (4), which we denote as \(=\{||^{}^{}\}\). Graphically, \(\) can be understood as a contour on the Bloch sphere of an \(N\)-qubit system with a constant distance to \(|^{*}\) as shown in Fig. 1(b). We remark that \(^{*}\) can be interpreted as either an initial guess or an intermediate value during the training process so that our following results can be applied to the entire process of learning a quantum state. See Appendix A.1 for more details on the ensemble setting.

### Exponentially likely local minima

We now investigate the statistical properties of the gradient \(\) and the Hessian matrix \(H_{}\) of the loss function \((^{*})\) at the parameter point \(=^{*}\) regarding the ensemble \(\), and hence derive an upper bound of the probability that \(^{*}\) is not a local minimum. For simplicity of notation, we represent the value of a certain function at \(=^{*}\) by appending the superscript "\(*\)", e.g., \(|_{=^{*}}\), as \(^{*}\) and \(.H_{}|_{=^{*}}.\) as \(H_{}^{*}\). We define that \(^{*}\) is a local minimum up to a fixed precision \(=(_{1},_{2})\) if and only if each of the gradient components is not larger than \(_{1}\) and the minimal eigenvalue of the Hessian matrix is not smaller than \(-_{2}\), i.e.,

\[(^{*},)=_{=1}^{M}\{| _{}^{*}|_{1}\}\ \ \{H_{}^{*}-_{2}I\}.\] (5)

If \(_{1}\) and \(_{2}\) both take zero, Eq. (5) is reduced back to the common exact definition of the local minimum. However, noises and uncertainties from measurements on real quantum devices give rise to a non-zero \(\), where the estimation cost scales as \((1/^{})\) for some power \(\). Specially, if \(|(^{*})\) approaches the true target state \(|\) such that \(^{*} 0\), we say \(^{*}\) is a global minimum. That is to say, here "local minima" are claimed with respect to the entire Hilbert space instead of training landscapes created by different ansatzes. The expectation and variance of the first and second-order derivatives of the loss function are calculated and summarized in Lemma 1, with the detailed proof in Appendix B utilizing the technique we dubbed "subspace Haar integration" in Appendix A.1.

**Lemma 1**: _The expectation and variance of the gradient \(\) and Hessian matrix \(H_{}\) of the fidelity loss function \(()=1-||()|^{2}\) at \(=^{*}\) with respect to the target state ensemble \(\) satisfy_

\[_{}[^{*}]=0, _{}[_{}^{*}]=f_{1}(p,d) _{}^{*}.\] (6) \[_{}[H_{}^{*}]=-1}{d-1}^{*},_{}[_{} _{}^{*}] f_{2}(p,d)\|_{}\|_{}^{2}\| _{}\|_{}^{2}.\] (7)

_where \(\) denote the QFI matrix in Eq. (3) and \(_{}\) is the generator of the gate \(U_{}(_{})\). \(f_{1}\) and \(f_{2}\) are functions of the overlap \(p\) and the Hilbert space dimension \(d\), i.e.,_

\[f_{1}(p,d)=(1-p^{2})}{d-1}, f_{2}(p,d)=)}{d-1} [p^{2}+)}{d}].\] (8)

The exponentially vanishing variances in Lemma 1 imply that the gradient and Hessian matrix concentrate to their expectations exponentially in the number of qubits \(N\) due to \(d=2^{N}\) for a \(N\)-qubit system. Thus the gradient concentrates to zero and the Hessian matrix concentrates to the QFI \(^{*}\) times a non-vanishing coefficient proportional to \((p^{2}-1/d)\). Since the QFI is always positive semidefinite, the expectation of the Hessian matrix is either positive semidefinite \(^{*}=1-p^{2}<1-1/d\), or negative semidefinite if \(^{*}>1-1/d\), as illustrated in Fig. 1(a). The critical point \(_{c}=1-1/d\) coincides with the average fidelity distance of two Haar-random pure states, which means that as long as \(|^{*}\) has a higher fidelity than the average level of all states, the expectation of the Hessian matrix would be positive semidefinite.

Using Lemma 1, we establish an exponentially small upper bound on the probability that \(^{*}\) is not a local minimum in the following Theorem 2, where the generator norm vector \(\) is defined as \(=(\|_{1}\|_{},\|_{2}\|_{},,\|_ {M}\|_{})\).

**Theorem 2**: _If the fidelity loss function satisfies \((^{*})<1-1/d\), the probability that \(^{*}\) is not a local minimum of \(\) up to a fixed precision \(=(_{1},_{2})\) with respect to the target state ensemble \(\) is upper bounded by_

\[_{}[(^{*},)] (p,d)\|\|_{2}^{2}}{_{1}^{2}}+( p,d)\|\|_{2}^{4}}{(-1}{d-1}e^{*}+_{2} )^{2}},\] (9)

_where \(e^{*}\) denotes the minimal eigenvalue of the QFI matrix at \(=^{*}\). \(f_{1}\) and \(f_{2}\) are defined in Eq. (8) which vanish at least of order \(1/d\)._

A sketch version of the proof is as follows, with the details in Appendix B. By definition in Eq. (5), the left-hand side of Eq. (9) can be upper bounded by the sum of two terms: the probability that one gradient component is larger than \(_{1}\), and the probability that the Hessian matrix is not positive definite up to \(_{2}\). The first term can be bounded by Lemma 1 and Chebyshev's inequality, i.e.,

\[_{}[_{=1}^{M}\{|_{}^{*}|> _{1}\}]_{=1}^{M}_{}[ _{}^{*}]}{_{1}^{2}}=(p,d)}{_ {1}^{2}}^{*},\] (10)

where the QFI diagonal element is bounded as \(_{} 2\|_{}\|_{}^{2}\) by definition and thus \(^{*} 2\|\|_{2}^{2}\). After assuming \(p^{2}>1/d\), the second term can be upper bounded by perturbing \(_{}[H_{}^{*}]\) to obtain a sufficient condition of positive definiteness (see Appendix A.2), and then utilizing Lemma 1 with the generalized Chebyshev's inequality for matrices (see Appendix A.3), i.e.,

\[_{}[H_{}^{*}-_{2}I]_{ ,=1}^{M}_{}[_{}_{ }^{*}]}{(-1}{d-1}e^{*}+_{2} )^{2}}(p,d)\|\|_{2}^{4}}{(-1} {d-1}e^{*}+_{2})^{2}}.\] (11)

Combining the bounds regarding the gradient and hessian matrix, one arrives at Eq. (9). \(\)

Theorem 2 directly points out that if the loss function takes a value lower than the critical threshold \(_{c}=1-1/d\), then the surrounding landscape would be a local minimum for almost all of the target states, the proportion of which is exponentially close to \(1\) as the qubit count \(N=_{2}d\) grows. Note that \(\|\|_{2}^{2}=_{=1}^{M}\|_{}\|_{}^{2}\) scales linearly with the number of parameters \(M\) and at most polynomially with the qubit count \(N\). Because practically the operator norm \(\|_{}\|_{}\) is constant such as the generators of Pauli rotations \(\|X\|_{}=\|Y\|_{}=\|Z\|_{}=1\), or grows polynomially with the system size such as the layer with globally correlated parameters  and the global evolution in analog quantum computing . Here we focus on the former and conclude that the upper bound in Theorem 2 is of order \((2^{-N}M^{2}/^{2})\), implying the exponential training cost. The conclusion also holds for noisy quantum states (see Appendix B). A similar result for the so-called local loss function, like the energy expectation used in variational quantum eigensolvers, is provided in Appendix C.

In principle, if one could explore the whole Hilbert space with exponentially many parameters, \(^{*}\) was a saddle point at most instead of a local minimum since there must exist a unitary connecting the learnt state \(|^{*}\) and the target state \(|\). This is also consistent with our bound by taking \(M(2^{N/2})\) to cancel the \(2^{-N}\) factor such that the bound is no more exponentially small. However, the number of parameters one can control always scales polynomially with the qubit count due to the memory constraint. This fact indicates that if the QNN is not designed specially for the target state using some prior knowledge so that the "correct" direction towards the target state is contained in the accessible tangent space, the QNN will have the same complexity as the normal quantum state tomography.

**Dependence on the loss value \(^{*}\).** The dependence of the bound in Theorem 2 on the overlap \(p=^{*}}\) shows that, as the loss function value becomes lower, the local minima becomes denser so that the training proceeds harder. This agrees with the experience that the loss curves usually decay fast at the beginning of a training process and slow down till the convergence. If \(e^{*} 0\), the second term in Eq. (9) becomes larger as \(p^{2} 1/d\), suggesting that the local minima away from the critical point \(_{c}\) is more severe than that near \(_{c}\). Moreover, if \(_{2}=0\), the bound diverges as the QFI minimal eigenvalue \(e^{*}\) vanishes, which reflects the fact that over-parameterized QNNs have many equivalent local minima connected by the redundant degrees of freedom of parameters.

By contrast, if \(^{*}>_{c}\), the results could be established similarly by slightly modifying the proof yet with respect to local maxima, as depicted in Fig. 1(a). However, the critical pointmoves to \(1\) exponentially fast as \(N\) increases, i.e., the range of \(^{*}\) without severe local minima shrink exponentially. Hence for large-scale systems, even with a polynomially small fidelity, one would encounter a local minimum almost definitely if no more prior knowledge can be used.

### Implication on the learnability of QNNs

In practical cases, if the QNN is composed of \(D\) repeated layers with \(z\) trainable parameters for each layer and each qubit, then the total number of trainable parameters becomes \(M=NDz\), and hence the probability of avoiding local minima is of order \((N^{2}2^{-N}D^{2}/^{2})\), which increases quadratically as the QNN becomes deeper. This seems contrary to the conclusion from barren plateaus  where deep QNNs lead to poor trainability. But in fact, they are complementary to each other. The reason is that the ensemble here originates from the unknown target state instead of the random initialization. Similar to classical neural networks, a deeper QNN has stronger expressibility, which creates a larger accessible manifold to approach the unknown state and may turn a local minimum into a saddle point with the increased dimensions. But on the other hand, a deeper QNN with randomly initialized parameters leads to barren plateaus . In short, the local minima here arise due to the limited expressibility together with a non-vanishing fidelity while barren plateaus stem from the strong expressibility together with the random initialization.

To solve this dilemma, our results suggest that a well-designed QNN structure taking advantage of prior knowledge of the target state is vitally necessary. Otherwise, a good initial guess (i.e., an initial state with high fidelity) solely is hard to play its role. An example of prior knowledge from quantum many-body physics is the tensor network states  satisfying the entanglement area law, which lives only in a polynomially large space but generally can not be solved in two and higher spatial dimensions by classical computers. Other examples include the UCCSD ansatz  in quantum chemistry and the QAOA ansatz  in combinatorial optimization, which all attempt to utilize the prior knowledge of the target states.

Finally, we remark that our results also place general theoretical limits for adaptive  or layer-wise training methods . Relevant phenomena are observed previously in special examples . Adaptive methods append new training layers incrementally during the optimization instead of placing a randomly initialized determinate ansatz at the beginning, which is hence beyond the scope of barren plateaus . Nevertheless, our results imply that for moderately large systems with \(^{*}<_{c}\), every time a new training layer is appended, the learnt state \(|^{*}\) would be a local minimum of the newly created landscape so that the training process starting near \(|^{*}\) would go back to the original state \(|^{*}\) without any effective progress more than applying an identity. Note that in adaptive methods, one usually initializes the new appended layer near the identity to preserve the historical learnt outcomes. Similar phenomena are also expected to occur in the initialization strategies where the circuit begins near the identity [43; 44; 46]. We emphasize that our results do not imply the ineffectiveness of all adaptive methods. Instead, they only suggest that simplistic brute-force adaptive methods provide no significant benefit in terms of enhancing learnability on average.

### Concentration of training landscapes

Theorem 2 analyses the statistical properties of the vicinity of a certain point \(^{*}\), i.e., the probability distributions of the gradient and Hessian matrix of \(^{*}\). To characterize the training landscape beyond the vicinity, a pointwise result is established in Proposition 3 with the proof in Appendix B.

**Proposition 3**: _The expectation and variance of the fidelity loss function \(\) with respect to the target state ensemble \(\) can be exactly calculated as_

\[&_{}[()]=1-p^{2}+-1}{d-1}g(),\\ &_{}[()]= }{d-1}g()[4p^{2}-(2p^{2}-)}{d(d-1)})g()],\] (12)

_where \(g()=1-|^{*}|()|^{2}\)._

Since the factor \(g()\) takes its global minimum at \(^{*}\) by definition, the exponentially small variance in Proposition 3 implies that the entire landscape concentrates exponentially in the qubit count to the expectation \(_{}[()]\) with a pointwise convergence (not necessarily a uniform convergence), which takes its global minimum at \(^{*}\) with respect to the training landscape as long as \(p^{2}>1/d\). For QNNs satisfying the parameter-shift rule, the factor \(g()\) along the Cartesian axis corresponding to \(_{}\) passing through \(^{*}\) will take the form of a trigonometric function \(_{}^{*}^{2}(_{}-_{}^{*})\), which is elaborated in Appendix B. Other points apart from \(^{*}\) is allowed to have a non-vanishing gradient expectation in our setup, which leads to prominent local minima instead of plateaus .

## 4 Numerical experiments

Previous sections theoretically characterize the limitation of QNNs in state learning tasks considering the information of the loss value \(^{*}\). In this section, we verify these results by conducting numerical experiments on the platform Paddle Quantum  and Tensorcircuit  from the following three perspectives. The codes for numerical experiments can be found in .

**Comparison with loss curves.** Firstly, we show the prediction ability of Theorem 2 by direct comparison with experimental loss curves in Fig. 1(c). We create \(9\) ALT circuits for qubit counts of \(2,6,10\) and circuit depth of \(1,3,5\) with randomly initialized parameters, denoted as \(^{*}\). For each circuit, we sample \(10\) target states from the ensemble \(\) with \(p=0.2\) and then generate \(10\) corresponding loss curves using the Adam optimizer with a learning rate \(0.01\). We exploit the background color intensity to represent the corresponding bounds from Theorem 2 by assigning \(e^{*}=0.1\) and \(_{1}=_{2}=0.05\). One can find that the loss curves decay fast at the beginning and then slow down till convergence, in accordance with the conclusion that the probability of encountering local minima is larger near the bottom. The convergent loss value becomes higher as the qubit count grows and can be partially reduced by increasing the circuit depth, which is also consistent with Theorem 2.

**Landscape profile sampling.** We visualize the existence of asymptotic local minima by sampling training landscape profiles in Fig. 3. Similar to the setup above, we create an ALT circuit with randomly initialized parameters \(^{*}\), sample \(200\) target states from the ensemble \(\) and compute the loss values near \(^{*}\). Figs. 3(a) and (b) are obtained by randomly choosing a direction for each landscape sample, while Fig. 3(c) is obtained by randomly sampling \(200\) directions for one fixed landscape sample. There is no indication of local minimum in the case of few qubits and small fidelity as shown by the blue curves in Fig. 3(a). However, as the qubit number grows, the landscape profiles concentrate into a clear convex shape centered at \(^{*}\) for both \(p=0.2\) and \(p=0.8\), where the curvature for \(p=0.8\) is larger due to the factor \((p^{2}-1/d)\) in Eq. (7). Fig. 3(c) further demonstrates that beyond the convexity along a specific direction, \(^{*}\) is a highly probable local minimum in the case of large qubit counts.

**Probability evaluation.** Finally, we compute the gradients and diagonalize the Hessian matrices to directly verify the exponentially likely local minima proposed by Theorem 2 in Fig. 4. Similar to

Figure 3: Samples of training landscapes along randomly chosen directions as a function of the distance \(\|-^{*}\|\) for random target states from \(\) with the sample size \(200\), the qubit count \(N=4\) and \(N=10\) and the overlap (a) \(p=0.2\) and (b) \(p=0.8\), respectively. The setup in (c) is the same as in (b) but fixes the target state and only samples the directions. A clear convex shape is present in the samples from \(N=10\) but absent in the samples from \(N=4\). This phenomenon intuitively shows that the training landscapes from the ensemble \(\) are concentrated to a local minimum around \(^{*}\) as the qubit count increases.

the setup above, we create ALT circuits for qubit count from \(N=1\) to \(11\) with depth \(D=5\) and sample \(200\) target states from \(\) for each circuit. After specifying a certain subset of parameters to be differentiated, we estimate the probability that \(\) is a local minimum by the proportion of samples satisfying the condition \((^{*},)\), where we assign \(_{1}=_{2}=0.05\). One can find that the probability of encountering local minima saturates to \(1\) very fast as the qubit count increases for arbitrary given values of \(p\), and at the same time, it can be reduced by increasing the number of trainable parameters, which is consistent with the theoretical findings in Theorem 2.

## 5 Conclusion and outlook

In this paper, we prove that during the process of learning an unknown quantum state with QNNs, the probability of avoiding local minima is of order \((N^{2}2^{-N}D^{2}/^{2})\) which is exponentially small in the qubit count \(N\) while increases polynomially with the circuit depth \(D\). The curvature of local minima is concentrated to the QFI matrix times a fidelity-dependent constant which is positive at \(p^{2}>1/d\). In practice, our results can be regarded as a quantum version of the no-free-lunch (NFL) theorem suggesting that no single QNN is universally the best-performing model for learning all target quantum states. We remark that compared to previous works, our findings first establish quantitative limits on good initial guesses and adaptive training methods for improving the learnability and scalability of QNNs.

In the technical part of our work, our ensemble arises from the unknown target state. Alternatively, if the QNN is sufficiently deep to form a subspace \(2\)-design (cf. Appendix A.1) replacing the ensemble we used here, a different interpretation could be established with the same calculations: there are exponentially large proportion of local minima on some cross sections of the training landscape with a constant loss function value. However, it remains an open question what the scaling of the QNN depth is to constitute such a subspace \(2\)-design, given that a local random quantum circuit of polynomially depth forms an approximate unitary \(t\)-design . We would like to note that the case where the output and target states are mixed states is not covered due to the quantum nature of the hard-to-defining orthogonal ensemble of mixed states, which may be left for future research.

Future progress will necessitate more structured QNN architectures and optimization tools, where insights from the field of deep learning may prove beneficial. Our findings suggest that the unique characteristics and prior information of quantum systems must be thoughtfully encoded in the QNN in order to learn the state successfully, such as the low entanglement structure in the ground state , the local interactions in Hamiltonians [71; 77] and the adiabatic evolution from product states .

**Acknowledgement.** We would like to thank the helpful comments from the anonymous reviewers. Part of this work was done when H. Z., C. Z., M. J., and X. W. were at Baidu Research.

Figure 4: Numerical evaluation for the probability that \(\) is a local minimum up to a fixed precision \(\), i.e., \(_{}[(^{*},)]\) for different qubit count, the number of trainable parameters and the overlap \(p\), with the error bar representing the statistical uncertainty in experiments. (a) shows that the probability converges to \(1\) rapidly with the increasing qubit count. (b) shows that the probability is reduced by increasing the number of parameters, implying the local minimum phenomenon is mitigated. (c) illustrates that the probability of encountering local minima always converges to \(1\) for any fixed overlap \(p\). \(p=0.8\) for both (a) and (b) and the number of parameters in (c) is \(6\).