# Craig Boutilier\({}^{3}\) Maryam Karimzadehgan\({}^{3}\)

Density-based User Representation using Gaussian Process Regression for Multi-interest Personalized Retrieval

 Haolun Wu\({}^{1,2}\)1 Ofer Meshi\({}^{3}\) Masrour Zoghi\({}^{3}\) Fernando Diaz\({}^{3}\) Xue Liu\({}^{1,2}\)\({}^{1}\)McGill University \({}^{2}\)Mila - Quebec AI Institute \({}^{3}\)Google Research

haolun.wu@mail.mcgill.ca, xueliu@cs.mcgill.ca, diazf@acm.org

{meshi,mzoghi,choutilier,maryamk}@google.com

Work done while doing an internship at Google.

###### Abstract

Accurate modeling of the diverse and dynamic interests of users remains a significant challenge in the design of personalized recommender systems. Existing user modeling methods, like single-point and multi-point representations, have limitations w.r.t. accuracy, diversity, and adaptability. To overcome these deficiencies, we introduce _density-based user representations (DURs)_, a novel method that leverages Gaussian process regression (GPR) for effective multi-interest recommendation and retrieval. Our approach, GPR4DUR, exploits DURs to capture user interest variability without manual tuning, incorporates uncertainty-awareness, and scales well to large numbers of users. Experiments using real-world offline datasets confirm the adaptability and efficiency of GPR4DUR, while online experiments with simulated users demonstrate its ability to address the exploration-exploitation trade-off by effectively utilizing model uncertainty.

## 1 Introduction

With the proliferation of online platforms, users have ready access to content, products and services drawn from a vast corpus of candidates. Personalized _recommender systems (RSs)_ play a vital role in reducing information overload and helping users navigate this space. It is widely recognized that users rarely have a single intent or interest when interacting with an RS [1; 2; 3]. To enhance personalization, recent work focuses on discovering a user's multiple interests and recommending items that attempt to span their interests [3; 4; 5]. However, this is challenging for two reasons. First, user interests are diverse and dynamic: diversity makes it hard to detect all interests, while their dynamic nature renders determining which user interest is active at any given time quite difficult. Second, it is hard to retrieve items related to niche interests due to the popularity bias .

User representation is a fundamental design choice in any RS. The most widely used strategy for user modeling is the _single-point user representation (SUR)_, which uses a single point in an item embedding space to represent the user. The user's affinity for an item is obtained using some distance measure (e.g., inner product, cosine similarity) with the point representing the item. However, SUR can limit the accuracy and diversity of item retrieval ; hence, most RSs generally use high-dimensional embedding vectors (with high computation cost).

To address the limitations of SUR, MaxMF  adopts a _multi-point user representation (MUR)_, where each user is represented using \(K\) points in the embedding space, each reflecting a different "interest". MaxMF uses a constant, uniform \(K\) across all users (e.g., \(K\) = \(4\)), which is somewhat ad hoc and restrictive. Subsequent research uses other heuristics [3; 8; 9; 4; 10; 11] or clustering algorithms [5; 2] to determine the number of interests per user. However, these all require the manual choice of \(K\) or a specific clustering threshold, limiting the adaptability of MUR methods, since interests generally have high variability across users. Moreover, uncertainty regarding a user's interests is not well-modeled by these methods, diminishing their ability to perform effective online exploration.

To address limitations of SUR and MUR point-based representations, we propose a user representation that emphasizes (i) _adaptability_, adapting to different interest patterns; (ii) _uncertainty-awareness_, modeling uncertainty in assessing user interests; and (iii) _efficiency_, avoiding high-dimensional embeddings. Specifically, we use a _density-based_ representation, where the user's preferences are encoded using a _function_ over the item embedding space. Under this representation, the relevance score for user-item pairs should be higher in regions of embedding space where a user demonstrated more interest in the corresponding items, and lower in regions where users have shown limited interest. We propose the _density-based user representation (DUR)_, a novel user modeling method which exploits _Gaussian process regression (GPR)_[12; 13], a well-studied Bayesian approach to non-parametric regression using _Gaussian processes (GPs)_ to extrapolate from training to test data. GPR has been applied across a wide range of domains, though it has been under-explored in user modeling. Given a sequence of user interactions, GPR predicts the level of a user's interest in any item using its posterior estimates. This allows us to maintain a unique personalized GP regressor for each user, effectively capturing their evolving preferences and assessing uncertainty. Top-\(N\) item retrieval is performed using bandit algorithms, such as UCB  or Thompson sampling , based on GPR posterior estimates.

To illustrate, consider Fig. 1, which shows the prediction score (_i.e._, the inner-product between user and item embeddings) between a user and all movies from the MovieLens 1M dataset  (reduced to 2D for visualization purposes). We examine 20 movies from the recent history of a particular user, shown as triangles (\(\)). We see that these movies lie in several different regions of the embedding space. However, when we fit either SUR or MUR (\(K\) = \(4\)) models, they fail to capture the user's multiple interests and instead assign high scores only to movies from a single region (Fig. 1, top row). By contrast, we see in Fig. 1 (bottom left) that GPR fits the data well, assigning high values to all regions associated with the user's recent watches (interests). Fig. 1 (bottom right) shows that our approach can also capture uncertainty in our estimates of a user's interests, assigning high uncertainty to regions in embedding space with fewer samples.

Our approach has various desirable properties. First, it adapts to different interest patterns, since the number of interests for any given user is not set manually, but determined by GPR, benefiting from the non-parametric nature of GPs. Second, the Bayesian nature of GPs measures uncertainty with the posterior standard deviation of each item. This supports the incorporation of bandit algorithms in the recommendation and training loop to address the _exploration-exploitation trade-off_ in online settings. Finally, our method can effectively retrieve items spanning multiple user interests, including "niche" interests, while using a lower-dimensional embedding relative to SUR and MUR.

To summarize, our work makes the following contributions:

* We develop _GPR4DUR_, a density-based user representation method, for personalized multi-interest retrieval. It is the first use of GPR for user modeling in this setting.
* We propose new evaluation protocols and metrics for multi-interest retrieval that measure the extent to which a model captures a user's multiple interests.

Figure 1: The t-SNE visualization of the prediction score between a picked user to all items in the MovieLens dataset. The score is computed as the inner-product between the user embedding and item embedding. The triangles (\(\)) indicate the latest 20 items interacted by the user. We use Matrix Factorization (MF) to obtain embeddings in this toy example. As depicted, only density-based method (bottom row) can well capture user interests with uncertainty.

* We conduct comprehensive experiments on real-world offline datasets showing the adaptability and efficiency of GPR4DUR. Online experiments with simulated users show the value of GPR4DUR's uncertainty representation in balancing exploration and exploitation.

## 2 Related Work

Learning high-quality user representations is central to good RS performance. The _single-point user representation (SUR)_ is the dominant approach, where a user is captured by a single point in some embedding space [17; 18], for example, as employed by classical [19; 20; 21] and neural  collaborative filtering methods. While effective and widely used, SUR cannot reliably capture a user's multiple interests. To address this limitation, the _multi-point user representation (MUR)_ has been proposed, where a user is represented by multiple points in embedding space, each corresponding to a different "primary" interest. Selecting a suitable number of points \(K\) is critical in MUR. Existing algorithms largely use heuristic methods, e.g., choosing a global constant \(K\) for all users [1; 8; 3; 9; 4; 10; 11]. Other methods personalize \(K\) by setting it to the logarithm of the number of items with which a user has interacted . More recently, Ward clustering of a user's past items has been proposed, with a user's \(K\) determined by the number of such clusters . This too requires manual tuning of clustering thresholds.

At inference time MUR is similar to SUR, computing the inner-product of the user embedding(s) and item embedding. Some methods compute \(K\) inner products, one per interest, and use the maximum as the recommendation (and the predicted score for that item) . Others first retrieve the top-\(N\) items for each interest (\(N K\) items), then recommend the top-\(N\) items globally [3; 2]. None of these methods capture model uncertainty w.r.t. a user's interests, hence they lack the ability to balance exploration and exploitation in online recommendation in a principled way .

Our density-based user representation, and our proposed GPR4DUR, differs from prior work w.r.t. both problem formulation and methodology. Most prior MUR methods focus on _next-item prediction_[3; 11], implicitly assuming a single-stage RS, where the trained model is the main recommendation engine. However, many practical RSss consist of two stages: _candidate selection_ (or _retrieval_) followed by _ranking_[24; 25]. This naturally raises the question: _are the selected candidates diverse enough to cover a user's interests or intents?_ This is especially relevant when a user's dominant interest at the time of recommendation is difficult to discern with high probability; hence, it is important that the ranker have access to a diverse set of candidates that cover the user's _range of potential currently active interests_. In this paper, we focus on this _retrieval task_. As for methodology, almost all prior work uses SUR or MUR point-based representations, [1; 2; 3; 5]--these fail to satisfy all the desiderata outlined in Sec. 1. Instead, we propose DUR, a novel method satisfying these criteria, and, to the best of our knowledge, the first to adopt GPR for user modeling in multi-interest recommendation/retrieval. We frame our solution as a candidate generator to be used in the retrieval phase of an RS. Other candidate generators with different objectives can be used in parallel to ours.

A related non-parametric recommendation approach is \(k\)-nearest-neighbors (kNN), where users with similar preferences are identified (e.g., in user embedding space), and their ratings generate recommendations (see, e.g., ). Our approach differs by not using user embeddings, but fitting a GPR model directly to item embeddings (see Sec. 4.4), allowing for uncertainty in the user model.

## 3 Formulation and Preliminaries

In this section, we outline our notation and multi-interest retrieval problem formulation, and provide some background on GPR, which lies at the core of our DUR method.

**Notation**. We consider a scenario where each item is associated with _category_ information (e.g., genre for movies). Denote the set of all _users_, _items_, and _categories_ by \(\), \(\), and \(\), respectively. For each \(u\), whose interaction history has length \(l_{u}\), we partition the sequence of items \(_{u}\) in \(u\)'s history into two disjoint lists based on the interaction timestamp (which are monotonic increasing): (i) the _history set_\(_{u}^{}\) = [\(v_{u,1},v_{u,2},...,v_{u,_{u}}\)] serves as the model input; and (ii) the _holdout set_\(_{u}^{}\) = [\(v_{u,_{u}+1},v_{u,_{u}+2},...,v_{u,l_{u}}\)] is used for evaluation. We define \(u\)'s _interests_\((_{u})\) to be the _set of categories associated with all items in \(u\)'s history_. Our notation is summarized in Appendix A.1.

[MISSING_PAGE_FAIL:4]

[MISSING_PAGE_FAIL:5]

[MISSING_PAGE_FAIL:6]

categories using Ward clustering on the pretrained item embeddings as in . The same categories are used during training and inference. Dataset statistics are shown in Table 6, and an ablation analysis of various clustering algorithms and numbers of clusters is provided in Table 8 (See Appendix).

### Experiment Setup

Most prior work on recommendation and retrieval evaluates model performance on generalization to new items per user. Instead, similar to recent work [39; 3], we assess model performance on the ability to generalize to new users. We split users into disjoint subsets: _training users_ (\(^{}\)), _validation users_ (\(^{}\)), and _test users_ (\(^{}\)) in a ratio of 8:1:1. The last 20% of each user's interaction sequence is treated as a _holdout set_ for evaluation, and the first 80% as a _history set_ for fitting the GPR model. We cap history length to 60, 160, and 100 for the three datasets, aligning with their average user interactions. For item embedding pre-training, we train the recommendation backbones using the _history set_ of all training users and tune parameters based on the performance on the _holdout set_ for validation users (details in Appendix A.3). Training is capped at 100,000 iterations with early stopping if validation performance does not improve for 50 successive iterations. We tune GPR hyperparameters by fitting the GP regressor to the _history set_ of all training and validation users, then using the _holdout set_ to fine-tune parameters (kernel and standard deviation). Metrics are reported on the holdout set for all test users (see Appendix A.5 for hyperparameter sensitivity).

### Metrics

Metrics used in prior work on sequential recommendation are not well-suited to assess performance in our multi-interest retrieval task, for several reasons: (i) Conventional metrics, such as _precision_ and _recall_, often employed in multi-interest research, do not adequately quantify whether an item list reflects the full range of a user's (multiple) interests. A model may primarily recommend items from a narrow range of highly popular categories and still score high on these metrics while potentially overlooking niche interests. (ii) Metrics like precision and recall are overly stringent, only recognizing items in the recommendation list that appear in the holdout set. We argue that credit should also be given if a similar, though not identical, item is recommended (e.g., _Iron Man 1_ instead of _Iron Man 2_). This requires a soft version of these metrics. (iii) Multi-interest retrieval systems should expose users to niche content to address their diverse interests. However, conventional metrics may neglect the item perspective, potentially underserving users with specialized interests. Consequently, we propose the use of the following four metrics that encompass the aforementioned factors.

Interest-wise Coverage (IC)This metric is similar to _subtopic-recall_, which directly measures whether the model can comprehensively retrieve all user interests reflected in the holdout set. The higher the value of this metric the better:

\[@k =^{}|}_{u^{ }}(_{u}^{})( _{u}^{1:k})|}{|(_{u}^{})|}.\] (6)

Interest-wise Relevance (IR)To further measure the relevance of retrieved items, we introduce a "soft" recall metric, calculating the maximum cosine similarity between items in the retrieval list and the holdout set within the same category. The motivation for IR is that the success of a retrieval or recommendation list often depends on how satisfying the most relevant item is:

\[@k =^{}|}_{u^{ }}(_{u}^{})} _{v_{i}_{u}^{},v_{j}_{u}^{1:k} }S(v_{i},v_{j})}{|(_{u}^{})|},(v_{i})=(v_{j})=c,\] (7)

where \(S(v_{i},v_{j})\) is the cosine similarity between item \(v_{i}\) and \(v_{j}\). To obtain ground-truth similarities between items, and to mitigate the influence of the chosen pre-trained model, we pretrain the item embeddings using YoutubeDNN  with a higher dimension size (\(d=256\)) to compute a uniform \(_{i,j}\) for any backbone. A higher value of this metric is better.

Exposure Deviation (ED)In addition to measuring performance from the user side, we also measure from the item side to test whether exposure of different categories in the retrieval list is close to that in the holdout set. We treat each occurrence of an item category as one unit of exposure,and compute the normalized exposure vectors \(^{}_{u},^{1:k}_{u}^{||}\) for \(u\)'s holdout set and retrieval list, respectively. Lower values of this metric are better.

\[@k=^{}|}_{u^{}}||^{}_{u}-^{1:k}_{u}||^{2}_{2},^{}_{u,c}=^{}_{u}}_{c(v)}}{_{v^{}_{u}}|(v) |},^{1:k}_{u,c}=^{}_{u}}_{c(v)}}{_{v^{}_{u}}|(v) |}.\] (8)

Tail Exposure Improvement (TEI)With respect to category exposure, it is crucial to ensure that niche interests are not under-exposed. To evaluate this, we select a subset of the least popular categories and measure their exposure improvement in the retrieval list versus that in the holdout set. A higher value indicates better performance, and a positive value indicates improvement:

\[@k=^{}|}_{u^{ }}_{c^{}}(^{1:k}_{u,c}- ^{}_{u,c})_{^{}_{u,c}>0}.\] (9)

Here, \(^{}\) refers to the set of niche categories (i.e., the last 50% long-tail categories), denoting those niche interests. \(_{^{}_{u,c}>0}\) indicates that we only compute the improvement for categories that appear in the user's holdout set, reflecting their true interests.

### Methods Studied

We study the following 12 methods from four categories. _(i) Heuristic_\(\): _Random_ recommends random items, _MostPop_ recommends the most popular items. _(ii) SUR Methods_\(\): _YoutubeDNN_ is a successful deep learning model for industrial recommendation platforms. _GRU4Rec_ is the first work to use recurrent neural networks for recommendation. _BERT4Rec_ adopts the self-attention mechanism. _gSASRec_ is an improvement over SASRec that deploys an increased number of negative samples and a novel loss function. _(iii) MUR Methods_\(\): _MIND_ designs a multi-interest extractor layer based on the capsule routing. _ComiRec_ captures multiple interests from user behavior sequences with a controller for balancing diversity. _CAMI_ uses a category-aware multi-interest model to encode users as multiple preference embeddings. _PIMI_ models the user representation by considering both the periodicity and interactivity in the item sequence. _REMI_ consists of an interest-aware hard negative mining strategy and a routing regularization method. _(iv) DUR Method (Ours)_\(\): _GPR4DUR_ uses GPR as a density-based user representation tool for capturing users' diverse interests with uncertainty 2.

Overall PerformanceOur overall performance comparison addresses two central research questions (_RQs_): whether our proposed method offers superior retrieval performance for users with multiple interests (_RQ1_); and whether it induces appropriate item-sided exposure w.r.t. both popular and niche interests (_RQ2_).

_Performance on the retrieval task_. To assess _RQ1_, we evaluate the effectiveness of the retrieval phase. As shown in Table 1, GPR4DUR outperforms almost all baselines across datasets w.r.t. Interest Coverage (IC@\(k\)) and Interest Relevance (IR@\(k\)), demonstrating high degrees of retrieval coverage and relevance. Specifically, on the Amazon dataset, GPR4DUR achieves the highest performance in 4 out of 6 interest metrics, in MovieLens it leads in 5 out of 6 metrics, and in Taobao, it excels across all 6 interest metrics. This shows that GPR4DUR covers a wide range of user interests while simultaneously maintaining high relevance. To assess the statistical significance of our model's performance compared to the best baseline, we performed a paired t-test, which evaluates whether the means of two paired samples differ significantly, ensuring that the observed improvements are not due to random variation.

    &  Amazon, \\ Recall \\  } &  _MooreLens_ \\ Recall \\  } &  _TeoDUR_ \\  } \\  \(\) & Random & 0.836 & 0.848 & 0.685 & 0.716 & 0.833 & 0.866 \\ \(\) & MostPop & 0.867 & 0.867 & 0.710 & 0.741 & 0.868 & 0.896 \\ \(\) & YoutubeDNN & 0.875 & 0.888 & 0.715 & 0.748 & 0.875 & 0.904 \\ \(\) & GRU4Rec & 0.873 & 0.886 & 0.714 & 0.746 & 0.873 & 0.902 \\ \(\) & BERT4Rec & 0.881 & 0.892 & 0.723 & 0.758 & 0.883 & 0.914 \\ \(\) & SASRec & 0.880 & 0.894 & 0.725 & 0.760 & 0.884 & 0.915 \\ \(\) & MIND & 0.842 & 0.885 & 0.713 & 0.745 & 0.872 & 0.901 \\ \(\) & OMIRec & 0.887 & 0.900 & **0.731** & 0.757 & 0.886 & 0.915 \\ \(\) & CAM & 0.892 & 0.905 & 0.725 & 0.761 & 0.891 & 0.920 \\ \(\) & PIMI & 0.891 & 0.899 & 0.724 & 0.757 & 0.886 & 0.911 \\ \(\) & REMI & 0.900 & 0.902 & 0.728 & 0.760 & 0.889 & 0.916 \\ \(\) & **GPR4DUR** & **0.908** & **0.922** & 0.730 & **0.768** & **0.906** & **0.936** \\   

Table 2: Result comparison on the ranking task measured at top-50 across all methods on three datasets.

For _RQ2_, our objective is to ascertain whether item exposure is suitably balanced. We measure this using the Exposure Deviation (ED@\(k\)) and Tail Exposure Improvement (TEI@\(k\)) metrics. Lower values of ED@\(k\) suggest more satisfying category exposure, while higher values of TEI@\(k\) are indicative of enhanced exposure in the long tail item categories. GPR4DUR is highly effective on these metrics, consistently performing well across all datasets in most cases, and validating its ability to provide an optimal level of category exposure. Notably, GPR4DUR achieves the best results in 8 of 9 TEI@\(k\) metrics, indicating its superior ability to generate exposure to niche categories/interests. We point out, however, that all TEI@\(k\) values are negative, which suggests that none of the methods we tested improve exposure for niche categories relative to the exposure in the user holdout sets. This is explained by the well-known popularity bias inherent in most recommendation methods, and suggests that further work is required on diversification strategies to mitigate such effects.

_Performance on the ranking task_. While our primary emphasis is on the retrieval phase, we also present model comparisons for the ranking task. As illustrated in Table 2, GPR4DUR demonstrates competitive performance on the traditional relevance metrics relative to the baseline models. This further validates the strength of our proposed method.

Performance across User Groups_(RQ3)_ We conduct a fine-grained analysis of GPR4DUR performance on users grouped into quantiles, \(g1\) (lowest) through \(g5\) (highest), based on the number of interaction or number of interests; results are provided in Fig. 3. Due to space constraints, we show results only for IR@20 and TEI@20 on MovieLens, and only plot the _best_ SUR and MUR strategies; DUR denotes our GPR4DUR method. We see that GPR4DUR consistently outperforms the baselines w.r.t. relevance and exposure metrics. This improvement is more pronounced as the number of user interactions (resp., interests) increases. Interestingly, while no model enhances overall exposure of niche interests (see Table 1), GPR4DUR improves niche interest exposure considerably for users with large numbers of interactions (resp., interests); i.e., TEI@20 is positive for \(g4\) and \(g5\). These observations confirm the effectiveness of GPR4DUR in capturing a user's multiple interests--especially for those with non-trivial histories--and its potential to maintain fair exposure w.r.t. items.

Robustness to Dimension Size_(RQ4)_ We underscored the importance of efficiency for a good user representation in Sec. 1. To shed light on this, we examine the IC@20 and IR@20 performance of various methods on Amazon. As shown in Fig. 4, GPR4DUR is effective w.r.t. interest coverage even when operating with low-dimensional embeddings (i.e., \(d\) = \(8\) and \(d=4\)). By contrast, the performance of the SUR and MUR methods degrades as the dimensionality decreases. GPR4DUR consistently outperforms other methods w.r.t. interest relevance across all dimensionalities examined. We note that lower dimensions facilitate higher interest relevance due to increased cosine similarity (Eq. 7), explaining the inverse correlation between IR@20 and dimension size in Figure 4 (right).

## 6 Online Simulation

To demonstrate the efficacy of GPR4DUR in capturing uncertainty in user interests and support exploration, we conduct an online simulation in a synthetic setting, using a specific model of stochastic user behavior to generate responses to recommendations.

Figure 4: Robustness comparison across different dimension sizes on Amazon. Best viewed in color.

Figure 3: Methods comparison across different user groups on MovieLens. Best viewed in color.

**Data Preparation.** We assume \(||=10\) interest clusters, each represented by a \(d\)-dim (\(d=32\)) multivariate Gaussian. We randomly select a (user-specific) subset of these interests as the ground-truth interest set for each user. We set \(||=1000\) and \(||=3000\), with \(300\) items in each interest cluster. Each item belongs to a single cluster and its embedding is sampled from the corresponding interest distribution. Each user is modeled by a multi-modal Gaussian, a weighted sum of the corresponding ground-truth interest distributions. To simulate a sequence of item interactions \(_{u}\) (i.e., user history), we follow , first running a Markov Chain using a predefined user interest transition matrix to obtain the user's interest interactions for \(S=10\) steps. We do not consider the cold-start problem in this experiment, so we simply recommend one item from each generated cluster to form the user history (i.e., \(|_{u}|=S\)). The observation \(_{u}\) over items in \(_{u}\) is set to 1 if the item belongs to a ground-truth cluster, and -1 otherwise.

**GPR Fit and Prediction.** After obtaining item embeddings \(\), user history \(_{u}\), and user observations \(_{u}\), we use GPR4DUR to learn a DUR for each user, using the methods described in Sec. 4.

**User History and Observation Update.** Using a predetermined user browsing model, clicked and skipped items are generated and appended to the user interaction history (and the corresponding user observation is likewise updated, 1 for clicked, -1 for skipped). This process continues until a maximum iteration of \(T=10\) is reached. In this online setting, we adopt the _dependent click model (DCM)_ of user browsing behavior, widely used in web search and recommendation . In the DCM, users begin by inspecting the top-ranked item, progressing down the list, engaging with items of interest and deciding to continue or terminate after each viewed item.

**Experiment Results**. We compare different recommendation policies by assessing various metrics at each iteration; due to space limitations, we report results only for interest coverage, see Table 3. Specifically, we compute a "cumulative" version of interest coverage by reporting the interest coverage averaged across all users on all previously recommended items prior to the current iteration. Our goal is to test whether policies that use uncertainty models outperform those that do not, specifically, whether such policies can exploit the inherent uncertainty representation of user interests offered by GPR4DUR.

We assume each policy recommends the top-10 items to each user at each iteration. Table 3 shows that methods using uncertainty (the bottom three rows) fairly reliably outperform those that do not (the top two rows, with _Greedy_ being UCB with \(=0\), where \(\) is the scaling factor of the variance term in UCB). The observation confirms the benefit of using GPR4DUR to explicitly model uncertainty in a recommender's estimates of a user's interests and to use this to drive exploration.

## 7 Conclusion and Discussion

In this paper, we introduced a density-based user representation model, GPR4DUR, marking the first application of Gaussian process regression for user modeling in multi-interest retrieval. This innovative approach inherently captures dynamic user interests, provides uncertainty-awareness, and proves to be more dimension-efficient than traditional point-based methods. We also establish a new evaluation protocol, developing new metrics specifically tailored to multi-interest retrieval tasks, filling a gap in the current evaluation landscape. Offline experiments validate the adaptability and efficiency of GPR4DUR, and demonstrate significant benefits relative to existing state-of-the-art models. Online simulations further highlight GPR4DUR's ability to drive user interest exploration by recommendation algorithms that can effectively leverage model uncertainty. The future work and broader impacts of this study are discussed in Appendix A.9 and Appendix A.10, respectively.