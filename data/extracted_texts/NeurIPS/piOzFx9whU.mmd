# Proof of Proposition 1.

Wasserstein Distributionally Robust Optimization Through the Lens of Structural Causal Models and Individual Fairness

 Ahmad-Reza Ehyaei

Max Planck Institute for Intelligent Systems, Tubingen AI Center, Germany

ahmad.ehyaei@tuebingen.mpg.de

&Golnough Farnadi

Mila Quebec AI Institute ; McGill University, Montreal, Canada

farnadig@mila.quebec

&Samira Samadi

Max Planck Institute for Intelligent Systems, Tubingen AI Center, Germany

ssamadi@tuebingen.mpg.de

Lead scientific advisor on the project

###### Abstract

In recent years, Wasserstein Distributionally Robust Optimization (DRO) has garnered substantial interest for its efficacy in data-driven decision-making under distributional uncertainty. However, limited research has explored the application of DRO to address individual fairness concerns, particularly when considering causal structures and sensitive attributes in learning problems. To address this gap, we first formulate the DRO problem from causality and individual fairness perspectives. We then present the DRO dual formulation as an efficient tool to convert the DRO problem into a more tractable and computationally efficient form. Next, we characterize the closed form of the approximate worst-case loss quantity as a regularizer, eliminating the max-step in the min-max DRO problem. We further estimate the regularizer in more general cases and explore the relationship between DRO and classical robust optimization. Finally, by removing the assumption of a known structural causal model, we provide finite sample error bounds when designing DRO with empirical distributions and estimated causal structures to ensure efficiency and robust learning.

## 1 Introduction

Machine learning models must address discrimination because they often reflect and amplify biases present in their training datasets . These biases can significantly influence decisions in domains such as healthcare , education , recruitment , and lending services . Consequently, these decisions disproportionately affect individuals based on sensitive attributes like race or gender, perpetuating systemic discrimination.

To address and quantify unfairness, researchers have developed concepts like **group fairness** and **individual fairness**. Group fairness aims to achieve equitable outcomes across demographic groups, while individual fairness ensures that similar individuals receive similar treatment. Formally, with \(\) as the feature space and \(\) as the label space, a model \(h:\) ensures individual fairness if it satisfies the condition in :

\[d_{}(h(v),h(v^{})) Ld_{}(v,v^{})v,v^{},\] (1)

where \(d_{}\) and \(d_{}\) are dissimilarity functions, often referred to as **fair metrics** on the input and output spaces. These functions capture the proximity of individuals and \(L^{+}\) is a Lipschitz constant. The metric \(d_{}\) reflects the intuition about which instances should be considered similar by the model.

Due to challenges in defining such metrics, group fairness is often prioritized in fairness literature because it more straightforwardly addresses observable disparities among distinct groups, making measurement and implementation easier in practice . Therefore, it is crucial to study and formulate individual fairness under different assumptions in machine learning.

Individual fairness can be achieved through robust optimization methods such as **Wasserstein DRO**, which has gained significant attention for its applications in learning and decision-making [55; 43]. DRO incorporates a regularization term to mitigate overfitting [17; 26; 59]. By using a fair metric as the transportation cost function in computing the Wasserstein distance, models are designed to deliver consistent performance across varied data distributions, ensuring similar individuals receive comparable outcomes, thus satisfying individual fairness.

Incorporating causal structures and sensitive attributes into data models complicates using an individual fair metric as a cost function within the DRO framework. The fair metric must account for perturbations in sensitive attributes based on counterfactuals to ensure counterfactual fairness . This can violate the positive-definite property, where \(d(v,v^{})=0\) implies \(v=v^{}\), a key assumption in many DRO theorems [55; 43].

Although previous works [42; 67; 70; 69; 57] have attempted to apply DRO to address individual fairness, they often do not explore the implications when causal structures and sensitive attributes are present in the learning problem. These studies are typically limited to linear **Structural Causal Model (SCM)** with specific metrics and do not discuss the form of the regularizer for other classical DRO theorems when using a fair metric. To accurately compare our work with related studies, we will postpone this discussion until after presenting our results in Section 4.1.

### Our Contributions

In this work, we adopt the definition of a _fair metric_ from  to define a **Causally Fair Dissimilarity Function (CFDF)**, which delineates how to establish a fair metric through causality and sensitive attributes. Using CFDF, we introduce **Causally Fair DRO** and present a strong duality theorem for our approach. Under mild assumptions about CFDF and causal structure, we demonstrate that the DRO regularizer can be estimated, or in some cases can be explicitly solved. This estimation often leads to being more practical and computationally efficient than solving the min-max problem in (4), as supported by advancements in algorithms from previous research such as [14; 15]. Finally, Our numerical analysis of both real and synthetic data demonstrates the practicality of our theoretical framework in real-world applications. (SS 5). In summary, the main contributions of this work are:

* Define a causally fair dissimilarity function, an individual fair metric incorporating causal structures and sensitive attributes (Def. 1), along with its representation form (Prop. 1).
* Define a causally fair DRO problem with a causally fair dissimilarity function cost (SS 4).
* Present the strong duality theorem for causally fair DRO (Thm. 1).
* Provide the exact regularizer for linear SCM under mild conditions for the loss function in regression and classification problems (Thm. 2 and Thm. 3).
* Estimate the first-order causally fair DRO regularizer for non-linear SCM (Thm. 4).
* Provide the relation between classical robust optimization and causally fair DRO (Prop. 2).
* Demonstrate that under unknown SCM assumptions, by estimating the SCM or cost function, we have finite sample guarantees for convergence of empirical DRO problems (Thm. 5).

## 2 Preliminaries & Notations

Data Model.Let \(\) denote a vector of feature space (predictor variables) and let \(\) represent the response variable, such that \(=(,)\) comprises the observation variables with an underlying probability \(_{*}\). Furthermore, assume that the feature vector \(=(,)\) comprises both sensitive attributes \(\) and non-sensitive attributes \(\). Let \(\{z^{i}=(v^{i},y^{i})\}_{i=1}^{N}\) represent the observations used to construct the empirical distribution \(_{N}\), defined as \(_{N}_{i=1}^{N}_{z^{i}}\), where \(_{z}\) is the Dirac delta function. Given a loss function \(:\), the risk function for a parameter \(\) and a probability measure \(\) is \((,)=_{}[(Z,)]\). This leads to the common **empirical risk minimization** approach. This method seeks to find the minimizer \(_{N}^{}\) within the set \(_{N}^{}_{}(_{N},)\), as an empirical way to obtaining the optimal solution \(_{*}\), which is given by \(_{*}=_{}(_{*},)\).

Assume the feature space is represented by a **structural causal model** (**SCM**) \(=,,,_{}\). This model includes **structural equations**\(\{_{i}:=f_{i}(_{u(i)},_{i})\}_{i=1}^ {n}\), which delineate the causal relations among an endogenous variable \(_{i}\), its causal predecessors \(_{u(i)}\), and an exogenous variable \(_{i}\) representing unobservable factors. The model's structure is encapsulated in a directed acyclic graph \(\). Exogenous variables are posited as mutually independent, enabling \(\) to be expressed as \(_{i=1}^{n}_{_{i}}\), assuming causal sufficiency and excluding hidden confounders .

Counterfactuals.In causal structures, data perturbation is achieved through **counterfactuals**, which are derived from **interventions** in SCMs. These interventions, conducted using \(do\)-calculus, include both **hard** and **soft** types . Hard interventions fix a subset \(\{1,,n\}\) of features \(_{}\) to a constant \(\), modifying their causal connections within the causal graph while maintaining the structural equations of other features . This type of intervention is denoted as \(^{do(_{}:=)}\) and its structural equations are obtained by:

\[\{_{i}:=_{i}, i;_{i}: =f_{i}(_{(i)},_{i}), i \}.\]

Soft interventions, on the other hand, adjust the functions in the structural equations, such as through additive interventions, without disrupting existing causal links . In an **additive (or shift)** intervention, a value \(^{n}\) is added to each feature within the SCM to enact manipulation:

\[\{_{i}:=f_{i}(_{(i)},_{i})+ _{i}\}_{i=1}^{n}.\]

In SCMs, counterfactuals are computed by modifying structural equations to reflect hard interventions on specific variables, thus exploring what would occur if the intervention was applied. Under the assumption of acyclicity, a unique function \(F:\) exists such that \(F(u)=v\). Acyclicity remains unchanged by either hard or shift interventions, allowing for the existence of modified functions \(F^{do(_{}:=)}\) and \(F^{do(_{}:=)}\) corresponding to these interventions, respectively. The counterfactual outcome for a hard intervention can thus be calculated using \((v,)=F^{do(_{}:=)}(F^{-1}(v))\), and similarly, for a shift intervention, it is defined as \((v,)\). These interventions are frequently applied in this analysis.

Counterfactuals involving the modification of sensitive attributes (termed **twins**) are essential for addressing individual-level fairness . Twins are generated by altering the sensitive attribute from \(a\) to \(a^{}\) across its domain \(\). For any instance, \(v\), a set of counterfactual twins is produced as \(\{_{a}=(v,a):a\}\), facilitating the analysis of fairness by comparing outcomes under different sensitive attribute values.

Counterfactual Identifiability.To estimate the effects of interventions from observational data, counterfactuals must be **identifiable** within a causal framework. A notable example of such identifiable SCMs is the **additive noise models (ANMs)**, which suggest that structural equations can be represented as:

\[\{_{i} f_{i}(_{(i)})+_{i}\}_{i=1}^{n}=(I-f)() =(I-f)^{-1}()\] (2)

leading to a bijective mapping between \(U_{i}\) and \(V_{i}\), ensuring no loss of information from exogenous to endogenous variables. This relationship implies that \(\) can be derived from \(\) through a bijective reduced-form mapping \(F=(I-f)^{-1}\), where \(I(x)=x\) is the identity function. Besides ANM, there are other counterfactually identifiable models such as LSNM  and PNL . However, for the sake of simplicity, our focus remains on ANM. **Linear SCMs** is a specific instance of ANMs, characterized by linear functions \(f_{i}\).

Individual Fairness Through Robustness.In machine learning, individual fairness  is achieved through robustness by ensuring that similar individuals receive similar outcomes, regardless of variations in their inputs. This concept aligns with the notion of Lipschitz continuity in decision functions (Eq. 1), where small changes in input should not lead to excessively large changes in output.

Depending on how the uncertainty set is defined, various types of robust optimization can be employed. In **adversarially robust optimization**, the uncertainty set is defined by introducing a slight perturbation \(\) based on the metric \(d\) to the input data. The goal is to find the optimal \(\) that minimizes risk even under the worst-case perturbation quantity:

\[_{}^{}}(,)=}_{v}[_{d^{p}(v,v+)}(v+,y, )],\] (3)

where \(p[0,]\). This formulation ensures that the optimization considers the maximum potential loss within the defined perturbation bounds.

In **counterfactually robust optimization**, the uncertainty set is generated by twins, which are obtained by creating counterfactuals concerning all levels of the sensitive attribute. In this scenario, the worst-case loss quantity is obtained by calculating the maximum loss over the twins of the input data:

\[_{}^{}}(,)=}_{v}[_{}(_{a},y, )].\]

**Distributionally Robust Optimization** is a data-driven approach designed to minimize the discrepancies between in-sample and out-of-sample expected losses, using ambiguity sets based on Wasserstein distances. Consider a lower semi-continuous cost function \(c(,):[0,]\) that satisfies \(c(z,z)=0\) for all \(z\), serving as a fair metric. The **optimal transport cost** between two distributions \(,()\), is represented by:

\[W_{c,p}(,)_{( )}\{(}_{(z,z^{ })}[c^{p}(z,z^{})])^{}:_{1}=,_{2} =\},\]

Here, \(()\) denotes the set of all joint probability distributions, and \(_{1}\) and \(_{2}\) are the marginals of \(\) under first and second coordinates . When \(c(z,z^{})\) acts as a metric (in mathematics term) on \(\), \(W_{c,p}\) is called the **Wasserstein distance**.

An important ingredient in the DRO formulation is the description of the distributional uncertainty region \(_{}()\) that is defined by optimal transport cost:

\[_{}()\{():W_{c,p}(,)\}.\]

DRO problem minimizes worst-case loss quantity:

\[_{}(,)_{\ \ _{}()}_{}[(,)]},\] (4)

and obtained the \(_{N}^{}}*{arg\,min}_{} _{}(_{N},)\). The main tool in DRO is the **strong duality theorem**, which converts an infinite-dimensional problem into a finite optimization problem. The theorem states that:

\[_{_{}()}\{} _{v}[(v)]\}=_{ 0}\{ ^{p}+}_{v}[_{}(v)]\},\] (5)

where \(_{}(v)\) is defined as \(_{}(v)_{v^{}}\{(v^{ })- d^{p}(v,v^{})\}\).

## 3 Causally Fair Dissimilarity Function

The key to robust optimization and individual fairness is the metric that measures individual similarity. This section outlines the properties of such a metric in a causal framework to protect sensitive attributes. We begin with an illustrative example.

**Example 1**: _Let \(_{1}\) and \(_{2}\) represent two SCMs describing the relationships among the variables gender (\(\)), education (\(\)), and income (\(\)). \(_{1}\) models these variables as independent, whereas \(_{2}\) specifies a linear causal relationship:_

\[_{1}=:=_{G},&_{G} (0.5)\\ :=_{E},&_{E}(0,1)\,\\ :=_{I},&_{I}(0,1), _{2}=:=_{G},&_{G} (0.5)\\ :=+_{E},&_{E}(0,1)\\ :=+2+_{I},&_{I}(0,1),\]_Where \(_{G}\) represents the population distribution of gender, modeled by a Bernoulli distribution, while \(_{E}\) and \(_{I}\) are intrinsic talents for academic and income achievements, respectively, modeled by normal distributions. To compare individuals, let's consider the \(L_{1}\) norm on non-sensitive attributes (\(d(v,v^{})=|e-e^{}|+|i-i^{}|\)). If two individuals have less than a 0.1 unit difference, they are deemed similar. Now, consider an individual with data \(v=(M,1,1)\). Based on experience, we expect that a perturbation in educational talent by 05 units will not significantly alter this individual's status. We model this perturbation with a shift intervention \(=(0,.05,0)\). In Model 1, the result \((v,)=(M,1.05,1)\) is considered similar to \(v\). However, in Model 2, \((v,)=(M,1.05,1.1)\) results in a distance of \(d(v,(v,))=0.15\), indicating dissimilarity. In the presence of causality, one attribute can be amplified multiple times in the final feature space. Therefore, we need to control our intuition of dissimilarity between the exogenous variables and the feature space._

_To protect against gender bias, we need to ensure that people with the same intrinsic characteristics but different genders behave similarly. This is modeled by a counterfactual change in gender. In Model 1, \((v,F)=(F,1,1)\) shows no difference (\(d(v,_{F})=0\)). However, in Model 2, \((v,F)=(F,0,-2)\) results \(d(v,_{F})=4\), which means that they are not similar._

The example 1 demonstrates that in the presence of causality and protected variables, the standard \(l_{p}\)-norm or any metric fails to accurately capture the intuition of similarity. In these scenarios, a dissimilarity function should incorporate counterfactuals and uniformly control for non-sensitive perturbations to effectively capture proximity. This approach is further elaborated in the following definition. Before proceeding, we introduce some notation. For a vector \(v\) or \(u\), we define \(P_{}()\) and \(P_{}()\) as the projections onto the sensitive and non-sensitive parts, respectively.

**Definition 1** (Causally Fair Dissimilarity Function): _Let \(d:[0,]\) be a dissimilarity function defined on the feature space \(\), generated by a SCM \(\). Let \(\) denote a set of sensitive attributes, and \(\) represent their corresponding index within \(\{1,,n\}\). The metric is called a causally fair dissimilarity function or **CFDF** if it adheres to the following properties:_

* _Zero Dissimilarity for Twin Pairs:_ _For any_ \(v\) _and_ \(a\)_, the dissimilarity_ \(d(v,_{a})\) _between an instance and its twins is zero._
* _Guaranteed Similarity for Minor Perturbations:_ _For every_ \(v\) _and any_ \(>0\)_, there exists an_ \(\) _such that for any sufficiently small intervention_ \((\|\|)\) _on the non-sensitive attributes (_\(P_{}()=0\)_), the distance_ \(d(v,(v,))\) _remains less than_ \(\)_._

To understand the shape of \(d\) under the assumptions of Def. 1, we must first recognize that the CFDF needs to be defined on a larger space than \(()\). This is because, generally, when \(\) is intervened upon by some sensitive attribute level \(a\), we have \(()_{a}( ^{do(:=a)})\). The complete space encompassing all counterfactual values can be defined as follows.

**Definition 2** (Parent-Free Sensitive Attribute SCM): _Consider \(\) with sensitive attributes indexed by \(\). The parent-free sensitive attribute SCM denoted as \(_{0}\), is derived from \(\) by removing the causal effects of parents of sensitive attributes and replacing their exogenous variables with indigenous ones. The structural equations for \(_{0}\) are as follows:_

\[_{i}^{0}_{i}&_{i}:= _{i}_{_{i}},&i\\ f_{i}(_{(i)}^{0}+_{i}&_{i}_{_{i}},&i\]

_The exogenous space corresponding to \(_{0}\), denoted by \(_{0}\), includes the sensitive attributes and the non-sensitive parts of the exogenous variables of \(\). This space called the semi-latent space, is constructed as \(_{0}=_{}\), where \(_{}\) is the non-sensitive part of the exogenous space in \(\)._

If we know the structural equations of \(\), we can first map the CFDF to the exogenous space. In this space, the exogenous variables are assumed to be independent. Therefore, we can design a dissimilarity function for each variable separately and then combine them using product topology (SS.2). Following this intuition, we introduce the bijective map \(g:_{0}\) from the feature space to the semi-latent space, along with its inverse, defined as follows:

\[g_{i}(v)v_{i}&i\\ F_{i}(v)&i,\;\;\;g_{i}^{-1}(u)u_{ i}&i\\ f_{i}(g_{(i)}^{-1}(u))+u_{i}&i\] (6)If all sensitive attributes have no parents, the semi-latent space is equivalent to the exogenous space, and \(g=F^{-1}\). The counterfactual with respect to \(_{0}\) is denoted by \(_{0}(v,)\). We can now present the following proposition to determine the shape of \(d\).

**Proposition 1**: _Let \(\) be an ANM, with \(g\) as its corresponding map to the semi-latent space 6, and \(P_{}(u)\) the projection of vector \(u\) to the non-sensitive part \(_{}\). Then:_

_(i) If_ \(d_{}\) _is a continuous dissimilarity function on diagonal_ \(_{}_{}\)_, then the function_ \(d\) _defined as:_

\[d(v,v^{})=d_{}(P_{}(g(v)),P_{}(g(v^{ })))\] (7)

_satisfies the definitions of a CFDF._

_(ii) If_ \(d:[0,]\) _satisfies the CFDF definition and the triangle inequality property, then_ \(d\) _can be represented as a dissimilarity function_ \(d_{}\) _dependent solely on the non-sensitive components_ \(_{}\) _i.e.,_ \(d(v,v^{})=d_{}(P_{}(g(v)),P_{}(g(v^{ })))\)_._

Since \(d_{}\) is defined on independent coordinates, its relation to the components is less complex than the CFDF \(d\). We assume the dissimilarity function \(d_{}(x,x^{})\) is translation-invariant. Therefore, for simplicity, we assume \(d_{}(x^{},x)=\|x^{}-x\|\). The dual of \(\|\|\) is defined as \(\|x\|_{*}=_{x^{}}\{x^{T}x^{}\|x^{}\| 1\}\). Now we establish our assumptions about the SCM and its CFDF.

**Assumption 1**:
* \(\) _is an ANM with known structural equations and a semi-latent map_ \(g\)_._
* _The CFDF is defined as_ \(d(v,v^{})=\|P_{}(g(v))-P_{}(g(v^{}))\|\)_, where_ \(\|.\|\) _is a some norm._
* _Cost function over_ \(\) _has form_ \(c((v,y),(v^{},y^{}))=d(v,v^{})+|y-y^{}|\)_._
* _The ambiguity set is defined as:_ \(_{}()=\{():W_{c, p}(,)\}\)_, for_ \(p[1,)\)_._

**Remark 1**: _All results of this work apply to the **homogeneous dissimilarity function** (Def. 6), which includes a broad family of dissimilarity functions, such as norms._

## 4 Causally Fair Distributionally Robust Optimization

To find out the impact of the CFDF in DRO problems, we first consider the dual form of the worst-case loss quantity, which simplifies the infinite-dimensional primal problem into a more tractable and computationally manageable form.

**Theorem 1** (Causally Fair Strong Duality): _If Assumption 1 is satisfied, then for any reference probability distribution \(\) and any function \(:\) that is both upper semi-continuous and \(L_{1}\)-integrable, the following duality holds:_

\[_{_{}()}\{}{}[(v)]\}=_{ 0} \{^{p}+}{}[_{a }_{}(_{a})]\},\] (8)

_where \(_{}(v)\) is defined as_

\[_{}(v)_{}\{(_ {0}(v,))-^{p}d(v,_{0}(v,))\},\] (9)

_and \(_{0}\) is counterfactual regarding parent-free SCM \(_{0}\)._

**Remark 2**: _The intuition behind the above formula is as follows: In the case where all features are independent, let \(v=(a,x)\). The CFDF should exhibit no difference between \((a,x)\) and \((a^{},x)\) for each \(a,a^{}\). Consequently, the distance metric satisfies \(d((a,x),(a^{},x^{}))=d_{}(x,x^{})\). Under this condition, the classical strong duality theorem (Eq. 5) provides the following relationship:_

\[_{}(v)=_{(a^{},x^{})}\{((a^{ },x^{}))- d^{p}_{}(x,x^{})\}=_{a }\{_{}((a,x+))- d ^{p}_{}(x,x+)\}\]

_When we incorporate causal structure instead of coordinating \(a\) and \(x\), the two dimensions \(_{a}\) and \(_{0}(v,)\) are replaced accordingly._In the DRO formulation, the worst-case loss is expressed in a dual form and can act as a regularizer for parameter learning. Explicitly solving the dual problem eliminates the need to compute the worst-case distribution, resulting in faster, more efficient learning algorithms . Before presenting the general theorem, the next two theorems show that, under mild conditions, the dual formula for specific loss functions in classification and regression problems can be explicitly solved.

**Theorem 2** (Higher Order Linear Loss): _Given Assumptions 1, let \(\) be a linear SCM and the loss function \((z,)^{p}\), where \((z,)\) is of the form \(h(y-,v)\) or \(h(y,v)\) for functions \(h(t)\) such as \(|t|\), \((0,t)\), \(|t-|\), or \((0,t-)\) for some \( 0\), and \(p[1,)\). Then the DRO problem 4 can be reduced to:_

\[_{}(_{N},)=(_{ }^{cf}(_{N},)^{}+\|P_{ }(M^{T})\|_{*})^{p},&()< \\ \\ ((_{N},)^{}+\|P_{ }(M^{T})\|_{*})^{p},& P_{ }(M^{T})=0;&()=\]

_where \(M\) is the corresponding matrix for the linear map \(g^{-1}\) (see Eq. 6)._

**Remark 3**: _In real-world datasets, the sensitive part always satisfies \(()<\). According to the above theorem, \(_{}(_{N},)_{}^{cf}( _{N},)\). For practical applications, if the worst-case loss must not exceed a certain value, we can replace \(\) with some constant in the above theorem._

**Example 2**: _Here are specific examples of the above theorem. We offer a framework to study the equivalence between the worst-case loss in the DRO problem, with the cost function derived from the CFDF, and the regularization scheme for classification and regression problems._

  Regression & Lower Partial Moments \\ \(_{}[|-,|^{p}]\), \(p 1\) & \(_{}[(-,-)_{+ }^{p}]\), \(p 1\), \(\) \\  Ridge Linear Regression & \(\)-Insensitive Regression \\ \(_{}[(+,)^{2}]\) & \(_{}[(|-,|-)_{+ }^{p}]\), \(p 1\), \(\) \\  Hinge Loss Binary Classification & Support Vector Machine Classification \\ \(_{}[(1-,)_{+ }^{p}]\), \(p 1\) & \(_{}[|1-,|^{p}]\), \(p 1\) \\  

The Thm. 2 can be extended to the non-linear regression loss function.

**Theorem 3** (Nonlinear Loss): _Let assumptions 1 be satisfied, with \(p=1\), \(\) linear with matrix \(M\) corresponding to map \(g^{-1}\), and a loss function \((z,)\) of the form \(h(y-,v)\) for regression and \(h(y,v)\) for classification, where \(h\) has the following two properties:_

1. \(h\) _is Lipschitz on_ \(\) _with_ \(L_{h}\) _constant, i.e.,_ \(|h(t_{2})-h(t_{1})| L_{h}|t_{2}-t_{1}|, t_{1},t_{2}\)_._
2. _There exists sequence of_ \(\{t_{k}\}_{k=1}^{}\) _goes to_ \(\) _such that for each_ \(t_{0}\) _we have_ \( lim_{k}+t_{k})-h(t_{0})|}{|t_{k}|}=L_{h}\)_._

_By the above assumption, DRO problem 4 can be reduced as:_

\[_{}(_{N},)=_{}^{ cf}(_{N},)+ L_{h}\|P_{}(M^{T}) \|_{*},&()<\\ \\ (_{N},)+ L_{h}\|P_{}(M^{T} )\|_{*},& P_{}(M^{T})=0;&()=\]

**Example 3**: _The following forms of the loss function satisfy the conditions of \(h\) in Thm. 3:_

Now, the first-order estimation of the regularizer for non-linear SCM and loss function is ready to be stated.

**Theorem 4** (First-Order Estimation of DRO Regularizer): _Assume \(\) has structural equation \(f\), which \(f\) and loss function \(\) are both twice continuously differentiable respect to non-sensitiveattributes, \(()<\) and \(c\) satisfies the assumption 1 with \(p[2,]\). The necessary condition for the existence of a finite DRO solution is that for each \(v\):_

\[_{a}\{(_{a},y,)\}<.\]

_By these conditions, the worst-case loss quantity is equal to:_

\[_{}(_{N},)=*{}_{v _{N}}[_{a}(_{a},y,) ]+(*{}_{v_{N}} [_{a}^{}(_{a},y,) _{*}^{q}])^{1/q}+O(^{2}),\] (10)

_where the \(O(^{2})\) term is uniform over all \(\), \(q\) is p's conjugate, and the gradient \(^{}\) equals to:_

\[^{}(v,y,)=_{ 0}_{0}(v,),y,)-(v,y,)}{}\]

_where \(_{0}\) is counterfactual regarding parent-free SCM \(_{0}\)._

By applying Prop. 2 from Gao's work , the next proposition presents the relationship between classical adversarial optimization 3 and DRO for CFDF.

**Proposition 2** (Approximation by Robust Optimization): _Suppose \(\) is a finite set and let \(\{(v^{i},y^{i})\}_{i=1}^{N}\) be observational data. Under Assumption 1, assume that for the loss function \(\) there exist constants \(L,M 0\) such that_

\[(v,y,)-(v^{},y,)<^{p}(v,v^{ })+M v,v^{}p[1,).\]

_For an arbitrary \(K\), consider the adversarial loss within the setting:_

\[}_{}^{adv}(_{N}):=_{(w^{ik})_{i,k} _{}}\{_{i=1}^{N}_{k=1}^{K}_{a }(_{a}^{ik},y_{i},)\},\]

_where the uncertainty set \(_{}\) is defined as:_

\[_{}:=\{(w^{ik})_{i,k}:_{i=1}^{N}_{k=1} ^{K}d^{p}(v^{i},w^{ik}),\,w^{ik}\}.\]

_Then, the DRO can be approximated by adversarial optimization as follows:_

\[}_{}^{adv}(_{N})_{}( _{N})}_{}^{adv}(_{N})+,\]

_where \(D\) is independent of \(K\)._

One of the main challenges in designing DRO for SCMs is that the CFDF depends on the causal structure. When the functional structure is unknown, it must be estimated from data. This empirical estimation impacts the DRO learning process. Therefore, it is crucial to control the uniform convergence error of the DRO problem between the true metric and distribution and the DRO estimated from the data. The following theorem guarantees learning from sample data, but certain assumptions need to be established first.

**Assumption 2**:
1. \(\) _is an unknown ANM,_ \(()<\)_, and_ \(\) _is a compact subset of_ \(^{d}\)_._
2. _The loss function_ \(\) _is uniformly bounded: there exists a positive constant_ \(M\) _such that_ \(0(z,) M\) _for all_ \(\)_. Moreover,_ \(\) _is Lipschitz with respect to the counterfactual in_ \(_{0}\)_; that is, there exists a constant_ \(L\) _such that:_ \[|(v,y,)-(_{0}(v,),y,)|\| \|_{}).\]
3. \(\) _is an estimation of the CFDF such that, with probability_ \(1-\)_, there exists_ \(M_{d}\) _such that, at a rate of_ \(N^{-}\)_, the discrepancy is uniformly bounded by:_ \[ v,v^{}:|d(v,v^{})-(v,v^{} )| M_{d}N^{-},>0.\]

The following theorem states that the efforts to estimate the metric or causal structures and the parameter \(_{N}^{}\),

\[_{N}^{}:=_{}\{_{Q:W_{,p}(Q,_{N})}\ \ _{z Q}[(z,)]\}\]

Where \(\) is the \(\) corresponding cost on \(\), leading to the estimation of the true parameters of the DRO problem. To state our result, we need the Dudley entropy integral , which measures the complexity of the loss function class.

**Theorem 5** (Learning Finite Sample Guarantee): _With assumption 1 and 2, then for \(_{N}^{}\) we have:_

\[_{}(_{*},_{N}^{})-_{ }_{}(_{*},) N^{-1/2}[ c_{0}+c_{1}^{1-p}+c_{2}^{1-p}N^{-+1/2}+c_{3}],\]

_With probability at least \(1-2\). With \(()\) denoting the Dudley entropy integral for the function class \(\{(,):\}\), the constants \(c_{0}\), \(c_{1}\) and \(c_{2}\) are identified as follows:_

\[c_{0} 96(),\ c_{1} 96L ()^{p},\ c_{2} 2 pL()^{p-1} M_{d},\ \ c_{3} 2 M.\]

The final theorem completes our framework, enabling us to perform DRO on real-world datasets without knowing the SCM structures while providing performance bounds.

### Related Works

**Causally Fair Dissimilarity Function.** Various studies have addressed the specification and learning of individual fair metrics, such as , but their construction based on causal structure and sensitive attributes remains unclear. Our work adopts and extends the concept of a causal fair metric, as discussed in the works .

**DRO and Individual Fairness.** Previous works, such as , address the DRO problem with an individual fairness metric but are limited to linear SCMs and \(p=2\). These studies do not discuss the duality theorem or regularizers. Additionally,  studied DRO, but its connection to causality remains unclear.

**Strong Duality Theorem.** Various versions of the strong duality theorem have been explored in prior works. For instance, in , the cost function must be a metric or  has convex property. Additionally, in , the distance function \(d\) must be positive-definite, meaning \(d(v,v^{})=0\) if and only if \(v=v^{}\). However, these conditions are not met for CFDF, necessitating a new formulation of the duality theorem 1.

**DRO as Regularizer.** Previous works on using DRO as a regularizer, explicitly solved  or through k-order estimation , only consider cases where the cost function is derived from a metric or a positive-definite dissimilarity function. Therefore, their theorems do not apply directly to our CFDF. We present new results in Theorems 2, 3, and 4 tailored for our cases.

**Finite Sample Guarantee.** Various works provide bounds on the performance of DRO solutions with finite samples , but these do not apply to our CFDF due to previously mentioned reasons. The studies  offer performance bounds only for the case of linear SCMs with \(p=2\). Therefore, we present a general case in Theorem 5.

**Optimal Transport and Causality.** Recent works  on causal optimal transport focus on the causal structure of the transport map or plan, which differs from our problem. In our case, causality pertains to the transportation cost derived from SCMs.

[MISSING_PAGE_FAIL:10]