# A Comprehensive Study on Text-attributed Graphs: Benchmarking and Rethinking

Hao Yan\({}^{1}\)

Equal contribution and co-first authors.

Chaozhuo Li\({}^{2}\)

Equal contribution and co-first authors.

Ruosong Long\({}^{3}\)

Chao Yan\({}^{4}\)

Jianan Zhao\({}^{6}\)

Wenwen Zhuang\({}^{1}\)

Jun Yin\({}^{1}\)

Peiyan Zhang\({}^{5}\)

Weihao Han\({}^{7}\)

Hao Sun\({}^{7}\)

Weiwei Deng\({}^{7}\)

Qi Zhang\({}^{7}\)

Lichao Sun\({}^{8}\)

Xing Xie\({}^{2}\)

Senzhang Wang\({}^{1}\)

\({}^{1}\)Central South University, \({}^{2}\)Microsoft Research Asia, \({}^{3}\)University of Birmingham

\({}^{4}\)Peking University, \({}^{5}\)Hong Kong University of Science and Technology

\({}^{6}\)Universite de Montreal, \({}^{7}\)Microsoft, \({}^{8}\)Lehigh University

###### Abstract

Text-attributed graphs (TAGs) are prevalent in various real-world scenarios, where each node is associated with a text description. The cornerstone of representation learning on TAGs lies in the seamless integration of textual semantics within individual nodes and the topological connections across nodes. Recent advancements in pre-trained language models (PLMs) and graph neural networks (GNNs) have facilitated effective learning on TAGs, garnering increased research interest. However, the absence of meaningful benchmark datasets and standardized evaluation procedures for TAGs has impeded progress in this field. In this paper, we propose CS-TAG, a comprehensive and diverse collection of challenging benchmark datasets for TAGs. The CS-TAG datasets are notably large in scale and encompass a wide range of domains, spanning from citation networks to purchase graphs. In addition to building the datasets, we conduct extensive benchmark experiments over CS-TAG with various learning paradigms, including PLMs, GNNs, PLM-GNN co-training methods, and the proposed novel topological pre-training of language models. In a nutshell, we provide an overview of the CS-TAG datasets, standardized evaluation procedures, and present baseline experiments. The entire CS-TAG project is publicly accessible at https://github.com/sktsherlock/TAG-Benchmark.

## 1 Introduction

Graphs are ubiquitous in modeling the relational and structural aspects of real-world objects across various domains, such as social networks, transportation system networks, and biological protein-protein networks [1; 2; 3; 4]. In many real-world graphs, nodes are often associated with text attributes, giving rise to the text-attributed graphs (TAGs) [5; 6]. TAGs are prevalent in various scenarios, such as social graphs where each user is accompanied by a textual description and paper citation graphs where textual content is linked to each respective paper [7; 8]. The exploration of learning methodologies applied to TAGs has emerged as a prominent research area within multiple fields, including graph learning, information retrieval, and natural language processing .

The nucleus of learning on TAGs lies in the effective integration of both the node attributes (textual semantics) and graph topology (structural connections) to facilitate the learning of node representations. The textual information associated with each node offers a wealth of semantic content, enabling the characterization of individual node properties, which could be captured by the pre-trained language models (PLMs) [10; 11; 12; 13; 14]. Meanwhile, the structural information encodedwithin the graph topology presents the inherent proximity relationships between nodes. Graph neural networks (GNNs) have proven to be effective in capturing such structural relations based on the message-passing mechanism [7; 15; 16; 17; 18; 19; 20; 21; 22].

PLM-based and GNN-based methods are two prevalent types of learning paradigms on TAGs as illustrated in Figure 1. PLM-based methods generally input the textual content derived from the target node into a pre-trained language model. However, the knowledge of topology resulting from the high non-linearity of graph structure within TAGs is largely discarded by the PLM-based methods . Conversely, GNN-based methods are capable of preserving the intricate graph topology information with greater fidelity. Nevertheless, an inherent limitation plaguing GNN-based methods lies in the disconnected modeling process of node attributes and graph topology. Specifically, most GNNs pre-model node attributes as static representations, treating them as fixed and unlearnable parameters during the message passing process. Consequently, the gradients stemming from the learning objective of GNNs cannot be effectively back-propagated into the attribute modeling. This discrepancy in the training procedure hinders the attainment of an optimal solution, as it fails to guarantee end-to-end training, thereby impeding the overall effectiveness of the approach.

To simultaneously enjoy the merits of GNNs and LMs, several recent endeavors shed light on the co-training paradigm as shown in Figure 1. LMs and GNNs are combined in a cascaded [23; 24; 25] or nested  manner, establishing a unified end-to-end training paradigm to model the node attributes and graph topology jointly. Despite its theoretical appeal, the co-training method suffers from severe scalability issues as its memory complexity is proportional to the graph size as neighborhood texts are also encoded . Motivated by the recent advancements in pre-training techniques, a novel inquiry emerges: _Can we pre-train the language models to understand the graph topology?_ If we can effectively encode topological information into LMs through appropriate pre-training tasks, LMs could serve as the foundational model for learning on TAGs. Topological pre-trained LMs eliminate the explicit GNN aggregations, thereby circumventing the efficiency challenges encountered in the co-training paradigm. However, the design of suitable and effective pre-training tasks to encode valuable knowledge derived from intricate graph topology into LMs remains an open question.

In order to delve deeply into the intricate interplay between textual semantics and graph topology within TAGs, we embark on an unprecedented exploration to investigate the optimal training paradigm for various TAGs. Existing text-attributed graph datasets (e.g., Cora , WikiCS , Amazon-Photo ) cannot meet our requirements, as they solely offer node attribute embeddings, devoid of the original textual sentences. To overcome this limitation, we meticulously curate a novel and comprehensive dataset, dubbed CS-TAG, comprising eight distinct TAGs sourced from diverse domains. This carefully crafted dataset serves as a solid foundation for future research endeavors, facilitating in-depth investigations in this burgeoning field. Moreover, extensive experiments are conducted on the CS-TAG dataset to provide comprehensive and reliable benchmarks. All aforementioned learning paradigms are thoroughly evaluated and analyzed. Experimental results and detailed discussions further reveal the underlying correlations between graph topology and textual attributes, drawing deep insight into the inherent characteristics of the TAGs. Our contributions are summarized as follows:

1. To the best of our knowledge, CS-TAG is the first open dataset specifically designed for text-attributed graphs. TAGs from a variety of fields are collected, cleaned, and organized as the final structured dataset. We provide researchers with original links and data cleaning codes to facilitate their access and reprocessing of these datasets in accordance with their research interests and requirements. The entire CS-TAG project is publicly accessible as an open source repository on Github, accessible at https://github.com/sktsherlock/TAG-Benchmark.
2. In contrast to previous topology-driven graph learning models, our work underscores the vital significance of deep node attribute modeling. This novel perspective sheds light on the design of next-generation GNNs by emphasizing the incorporation of deep node attribute understanding.

Figure 1: The traditional text attributed graph representation learning pipeline.

3. We investigate the novel problem of topological pre-training of language models, aiming at teaching LMs to understand topological structures. This innovative training paradigm exhibits remarkable performance on the CS-TAG dataset in terms of effectiveness and efficiency, which contributes to broadening the scope of language model pre-training.
4. Extensive experiments are conducted across eight diverse datasets, focusing on two downstream tasks: node classification and link prediction. Such experiments serve as a rigorous evaluation of various learning paradigms, providing precise and dependable benchmarks for future endeavors.

## 2 Related Work

In this section, we first briefly introduce three popular learning paradigms for TAGs. After that, the comparisons between the existing graph learning benchmarks and the proposed CS-TAG are also discussed. Refer to Appendix A for more detailed reviews of the related models. We have implemented most of the algorithms discussed in this section in the repository.

**PLM-based methods.** The PLMs refer to universal language models that possess enhanced semantic understanding due to their pre-training on a vast corpus . The early works on modeling textual attributes were based on shallow networks, e.g., Skip-Gram and GloVe. In recent years, the backbone networks dominated by the pre-training-fine-tuning paradigm are rapidly scaling up: from ELMo, GPT, to BERT , RoBERTa , DeBERTa . The large-scale models, which get fully trained with massive data, demonstrate superior performances on general NLP tasks. One of the most critical usages of PLMs is text representation, where the underlying semantics of texts are captured by low-dimensional embeddings. On the TAGs, the PLMs use the local textual information of each node to learn a good representation for the downstream task .

**GNN-based methods.** As graph representation learning enjoys explosive growth in machine learning, numerous research works have been proposed for various tasks including node classification , link prediction , and so on. Graph neural networks are recognized as powerful tools for modeling graph data. Such methods (e.g., GCN , GAT , GraphSAGE , GIN , RevGAT ) learn effective message-passing mechanisms such that information between the nodes can get aggregated for expressive graph representations. GNNs generally adopt the "cascade architecture" suggested by GraphSAGE for textual graph representation: node features are encoded independently using text modeling tools (e.g. PLMs) and subsequently aggregated by GNNs to produce the final representation.

**Co-training methods.** The aforementioned two types of paradigms primarily focus on modeling partial information, which limits their ability to learn comprehensive features. Several recent endeavors propose to co-train GNNs and LMs to enjoy the merits from both sides. Specifically, LMs and GNNs are combined in the cascaded  or nested manner . The outputs generated by LMs serve as inputs for GNNs, and vice versa. The parameters of both LM and GNN are updated through the back-propagation of gradients from downstream tasks. However, this co-training paradigm suffers from serious scalability problems, as all neighbors need to be encoded from scratch by the LMs, incurring significant additional computational costs .

**Benchmarks for graph representation learning.** Several established graph benchmarks have been developed and widely adopted [34; 35; 27; 36]. However, when it comes to learning on TAGs, these benchmarks exhibit notable deficiencies. Firstly, a majority of these datasets suffer from the absence of raw textual information, limiting the investigation of attribute modeling's effectiveness. Secondly, these datasets often neglect to explore the impact of text attribute modeling on GNNs. Thirdly, these datasets are predominantly small in scale. Thus, there is a compelling necessity to construct a comprehensive large-scale dataset for TAGs.

## 3 CS-TAG: A Comprehensive Dataset and Benchmark for TAGs

In this section, we commence by providing a concise summary of the constructed CS-TAG benchmark in Section 3.1. Subsequently, we present the details of the construction of CS-TAG in Section 3.2, including data collection, cleaning, and labeling. Moreover, we elucidate the details of GNN-based, PLM-based, and Co-training learning paradigms in Section 3.3. Finally, the proposed topological pre-training of LMs is presented in Section 3.4.

### Overview of CS-TAG

In order to address the limitations inherent in prior researches, we propose the establishment of the text-attributed graph benchmark, dubbed _CS-TAG_, which serves as a standardized evaluation framework for assessing the efficacy of representation learning techniques on TAGs. To ensure scalability, CS-TAG includes datasets of varying sizes and incorporates scalable baselines consisting of PLMs, GNNs, and co-training methods. This enables researchers to evaluate the performance of their models across a broad range of dataset scales. To enhance usability, we provide a modular pipeline that simplifies the implementation of different models within the CS-TAG. Such a modular architecture enables researchers to easily integrate their novel methods and compare them with existing approaches. In addition, we are committed to maintaining a public leaderboard for TAGs, serving as a repository for the latest advancements in the field. This platform will continuously update text-attributed graph datasets that possess practical and research value, fostering ongoing progress and collaboration within the community. Overall, CS-TAG serves as a scalable, unified, modular, and consistently updated evaluation framework for assessing the performance of representation learning methods on text-attributed graphs.

### Dataset Construction

In order to thoroughly investigate the performance of different learning paradigms on TAGs, we conduct an extensive survey of various text-attributed graph datasets that have been previously utilized in the literature. Our observations reveal that many commonly employed node-level datasets are essentially text-attributed graphs. For instance, well-known citation graphs such as Cora, PubMed, Citeseer , and ogbn-arxiv  are all TAGs. These datasets derive node attributes from textual information, such as the title and abstract of papers. Additionally, academic collaboration networks such as Coauthor CS/Physics  set node attributes derived from keywords defined in the papers.

However, while these datasets are frequently employed by GNNs, they possess obvious inadequacies when exploring representation learning on TAGs. Firstly, most of these datasets lack the availability of raw textual information, bringing challenges to investigating the effectiveness of attribute modeling on these datasets. Secondly, these datasets generally overlook the exploration of text attribute modeling's impact on GNNs. A majority of these datasets employ simplistic bag-of-words models or traditional text encoding techniques like GloVe or Skip-Gram to represent text attributes, which are kind of outdated. Lastly, these datasets are predominantly small in scale, leading to a lack of differentiation between different learning models across numerous datasets.

To address these limitations, we have taken proactive steps to collect and construct some novel datasets of TAGs. Figure 2 illustrates the number of nodes/edges in the previous datasets and the proposed CS-TAG. One can clearly see that the TAGs within CS-TAG are comparatively larger than the counterparts. Here, we present the details of shopping graphs as an example. We extract datasets from the Amazon dataset , including Books-Children/History, Ele-Computers/Photo, and Sports-Fitness. Nodes represent different types of items, while edges indicate items that are frequently purchased or browsed together. Node labels are assigned based on the product category. To explore the influence of attributes in the text-attribute graphs, distinct text attributes have been provided for each of these datasets. For example, in the Books-Children/History dataset, node attributes are derived from the title and description of the respective books, such as "Description: Collection of Poetry; Title: The golden treasury of poetry". The Sports-Fitness dataset only incorporates node attributes from the title of the sports items, such as "Girls Ballet Tutu Neon Orange". In the Ele-Computers/Photo dataset, node attributes are obtained from high-rated reviews and product summaries, for instance,

Figure 2: The differences between the TAGs datasets in CS-TAG (used for node classification) and the previous datasets.

"Great camera for the price! This camera takes crystal clear photos and is cheap too!". Further details on the dataset construction process can be found in Appendix B.

Additionally, we construct two other datasets, CitationV8 and GoodReads, for the link prediction task. The CitationV8 dataset represents a citation network extracted from DBLP . Node attributes in CitationV8 are derived from the titles and abstracts of research papers. Each edge signifies a citation relationship between two papers. The GoodReads dataset, on the other hand, originates from a prominent book review website.3 This dataset captures the "similar item" linking relationship between books and provides valuable information about the attributes of each book, such as the title and description. Therefore, we leverage the GoodReads dataset to construct link prediction tasks, which involve predicting relationships between similar books. Detailed descriptions of all the aforementioned datasets can be found in Appendix B.

### Conventional Learning Paradigms on TAGs

Existing learning paradigms on TAGs can be broadly classified into three distinct categories: 1) GNN-based methods: These methods primarily leverage GNNs as the foundational model for capturing the underlying graph topology structures through message-passing mechanisms. 2) PLM-based methods: These approaches rely on prevalent pre-trained language models to capture the semantics from the textual node attributes, which excel in their ability to comprehend text semantics and exhibit strong transferability. 3) Co-training methods: This paradigm involves the joint learning of GNNs and LMs under a unified framework  to enjoy the merits from both sides. Next, we will give the formulaic definitions of these three paradigms.

**GNN-based Paradigm.** GNNs are employed to propagate information across the graph nodes, allowing for the extraction of meaningful representations via message passing, which are formally defined as follows:

\[_{u}^{(k+1)}=_{}^{(k)}(_{u}^{(k)}, _{}^{(k)}(\{_{v}^{(k)},v (u)\}))\] (1)

where \(k\) represents the layers of GNNs, \(\) denotes the set of neighbors, \(u\) denotes the target node, \(\) means the learning parameters in GNNs. Please note that, the initial node feature vector \(_{u}^{(0)}\) using pre-learned by PLMs or other shallow text encoder (e.g., Skip-Gram). Such attribute modeling phase is performed independently of the subsequent training of GNNs. Gradients from the GNN training objectives are unable to be back-propagated into the PLMs to update their parameters. And this decoupling of PLMs and GNNs impedes the overall effectiveness.

**PLM-based Paradigm.** PLM-based methods leverage the effectiveness of pre-training techniques to enhance the modeling of text within each node. The formulation of these methods is as follows:

\[_{u}^{(k+1)}=_{}^{(k)}(_{u}^{(k)})\] (2)

where \(\) denotes the learnable parameters in PLMs. PLMs advance the modeling of node text attributes. However, incorporating crucial topological context into PLM-based paradigms remains a challenge, particularly when the available textual data is limited.

    & **Dataset** & **Nodes** & **Edges** & **Class** & **Domain** & **Modeling** & **Scale** & **Tasks** & **Raw Text** \\   & **WikCS** & 11,701 & 216,123 & 10 & Wikipedia & GloVe & Medium & Node classification & ✗ \\  & **Cora** & 2,708 & 5429 & 7 & Academic & Bag of words & Small & Node classification & ✗ \\  & **Citeseer** & 3,327 & 4,732 & 6 & Academic & Bag of words & Small & Node classification & ✗ \\  & **Pubmed** & 19,171 & 44,338 & 3 & Academic & Bag of words & Medium & Node classification & ✗ \\  & **eighn-arxiv** & 169,433 & 1,166,243 & 40 & Academic & Skip-Gram & Large & Node classification & ✗ \\  & **Coauthor CS** & 18,333 & 81,894 & 15 & Academic & Bag of words & Medium & Node classification & ✗ \\  & **Cauthor Physics** & 34,493 & 247,962 & 5 & Academic & Bag of words & Medium & Node classification & ✗ \\  & **Amazon Photo** & 7,487 & 119,043 & 10 & E-commerce & Bag of words & Small & Node classification & ✗ \\  & **Amazon Computers** & 13,381 & 245,778 & 8 & E-commerce & Bag of words & Medium & Node classification & ✗ \\   & **eighn-arxiv** & 169,433 & 1,166,243 & 40 & Academic & PLMs & Large & Node classification & ✗ \\  & **Books-Children** & 76,875 & 1,554,578 & 24 & E-commerce & PLMs & Large & Node classification & ✗ \\  & **Books-History** & 41,551 & 358,574 & 12 & E-commerce & PLMs & Large & Node classification & ✗ \\  & **Ele-Computers** & 87,229 & 721,081 & 10 & E-commerce & PLMs & Large & Node classification & ✗ \\  & **Ele-Photo** & 48,362 & 500,928 & 12 & E-commerce & PLMs & Large & Node classification & ✗ \\  & **Sports-Fitness** & 173,055 & 1,773,500 & 13 & E-commerce & PLMs & Large & Node classification & ✗ \\  & **ClationV8** & 1,106,759 & 6,120,897 & - & Academic & PLMs & Large & Link Prediction & ✗ \\  & **GoodReads** & 676,084 & 8,582,324 & - & E-commerce & PLMs & Large & Link Prediction & ✗ \\   

Table 1: Statistics of text-attributed graph dataset used in CS-TAG.

**Co-training Paradigm.** GNNs and LMs are jointly trained under a unified training framework:

\[f_{}(A,T)=_{}(A,_{}(T )),=\{,\}\] (3)

where \(f\) denotes the learning function and \(\) denotes the entire learnable parameters, which are derived from both the GNN and PLM modules. The outputs generated by the LM serve as input to the GNN. Notably, the gradients obtained from the GNN can be back-propagated to the LM, enabling the update of its parameters. However, the co-training method faces significant scalability challenges. This is primarily due to the memory complexity associated with encoding neighborhood texts, resulting in a memory requirement that scales linearly with the size of the graph .

### Topological Pre-training of Language Models

The incorporation of explicit GNN aggregations in the co-training paradigm introduces inherent challenges in terms of training complexity and resource requirements. This is primarily due to the simultaneous modeling of texts from both the center node and its neighbors. Therefore, this brings us to a question: _is there a training paradigm to enjoy the merits of graph topology while avoiding the explicit GNN operations?_ Inspired by the recent advancements in pre-training techniques [39; 40], our motivation lies in teaching language models to understand the topological structures. Three topological pre-training tasks are proposed to impart graph structures into the LMs, enabling them to better comprehend and capture the underlying topology.

**Topological Masked Language Model (TMLM).** Inspired by the task of masked language modeling, we propose a novel topological masked language model (TMLM) to capture the first-order connections on the token level. Given a center node \(c\) and one of its neighbors \(n\), their corresponding text is formally defined as \(}=\{t_{1}^{(c)},t_{2}^{(c)},,t_{k}^{(c)}\}\) and \(}=\{t_{1}^{(n)},t_{2}^{(n)},,t_{u}^{(n)}\}\), respectively. We randomly replace a subset of tokens in the center node \(}\) and \(}\) with a special token [MASK]. The objective of TMLM is to predict the masked tokens. Let \(^{(s)}=\{_{1}^{(c)},_{2}^{(c)},...,_{m-1}^{(n)},_{m}^ {(n)}\}\) represents the indexes of the \(m\) masked tokens in the sentence \(}\) and \(}\). Let \(_{}}\) denote the set of masked tokens in \(}\) and \(}\), and \(_{-}}\) denote the set of observed (unmasked) tokens. The objective of TMLM is:

\[_{}(_{}}|_{-}})=_{i=1}^{m} p(t_{_{i}}|_{-}};).\] (4)

in which \(\) denotes the learnable parameters.

**Topological Contrastive Learning (TCL).** Inspired by contrastive learning [41; 42; 43; 44], we propose a novel topological contrastive learning (TCL) task to capture the first-order topological information in the node level. Given a center node \(c\) and one of its neighbors \(n\), their corresponding node-level (sentence/document-level) embedding is derived from their \(\) token in the \(_{}}\) and can be formally defined as \(^{c},^{n}\). The objective of TCL is to bring the center node \(^{c}\) closer to its neighbors \(^{n}\) while pushing itself farther away from other nodes. Denoting the cosine similarity function as \((^{c},^{n})=^{c}^{n}/\| ^{c}\|\|^{n}\|\). The objective of TCL is:

\[_{}=-((^{c},^{n})/)}{_{n^{}=1,n^{} n}^{N}( (^{c},^{n^{}})/)},\] (5)

where \(\) denotes the temperature parameter, \(N\) denotes the batch size.

**Topological Deepwalk Learning (TDK).** TMLM and TCL mainly capture low-order structural information, while the higher-order structural information still needs to be captured by designing

Figure 3: Illustrations of different topological pre-training methods.

[MISSING_PAGE_FAIL:7]

### Impact of Static Modeling of Attributes on GNNs

In this subsection, we analyze the impact of different node attribute modeling methods for downstream GNNs. Table 2 represents the effect of node classification on ogbn-arxiv-TA for different GNNs given different PLMs' features. The results on other datasets can be found in Appendix D.1. Observing Table 2, we find that RevGAT performs the best among all initial node features, while GAT and SAGE exhibit the second-best performance. They are relatively less affected by the different node features, 7.54%, 7.16%, and 7.06% respectively. JKNet, APPNP, MoNet, and MLP are more influenced by the initial node features, which all come above 20. On the other hand, the node features encoded by RoBERTa, BERT, and DistilBERT generally perform better on all types of baselines. DeBERTa, which performs better on many downstream NLP-related tasks, is less effective. This may be because DeBERTa sees less corpus during pre-training, resulting in their inability to understand the semantics well when modeling the text directly on downstream tasks. Furthermore, we compare traditional shallow text encoders (e.g., Skip-Gram) with PLMs in Appendix D.4 for a more comprehensive analysis of the impact of text modeling on downstream GNNs.

Recently, LLMs (Large-Language Models) are continuing to energize areas such as knowledge graphs  and recommender systems . It is still an open question on how to successfully apply LLMs to text-attributed graph learning. We have conducted a preliminary exploration of how to use LLMs to advance the representation learning on TAGs. Please refer to Appendix D.8 for the detailed results and discussions.

### Pitfalls of Co-Training Paradigm

In this subsection, we analyze the performance of the Co-training paradigm versus the PLM-based, GNN-based paradigm in terms of node classification tasks. Tiny and Base in the PLM column represent BERT-Tiny and BERT-Base, respectively. T-GCN, T-SAGE, and B-GCN, B-SAGE represent the node features of BERT-Tiny and BERT-Base fed to downstream GCN and GraphSAGE respectively. GCN(T) and SAGE(T) then denote co-training BERT-Tiny with GCN and SAGE, respectively. We compare GCN(T), and SAGE(T) with the corresponding T-GCN, T-SAGE respectively. As shown in Table 3, SAGE(T) improves in four of the datasets compared to the T-SAGE methods, with a maximum improvement of 3.39% on the Photo dataset. However, GCN(T) performs worse than T-GCN on most datasets and is even weaker than BERT-Tiny 1.61% on ogbn-arxiv-TA. The Co-training framework requires simultaneous training of PLMs and GNNs. The memory requirement and time cost of this paradigm are significantly increased. In order to facilitate the co-training of PLMs and GNNs, we reduce either the batch size or the number of neighbors. The limited scalability leads to a significant reduction in the number of neighbors for GNN aggregation, which may compromise the effectiveness of message passing. To analyze the impact of scalability on the Co-Training method, we analyze the effect of the number of neighbors sampled per GNN layer on Co-training in Fig 4. As can be seen from it, the effect of the model mainly tends to increase as the number of neighbors increases. The detailed discussions on efficiency and scalability can be found in Appendix D.3.

### Comparing PLM-based Methods with GNN-based Methods

In this subsection, we compare the PLM-based methods and the GNN-based methods in different datasets. As shown in Table 4, the column GNNs indicates the best results on all GNNs for a given PLM node feature. On the Children and History dataset, the PLM-based methods works better than

  
**Way** &  &  &  \\   & Tiny & Base & T-GCN & B-GCN & T-SAGE & B-SAGE & GCN(T) & SAGE(T) \\  Arxiv & 70.83 & 72.96 & 72.03 & 73.30 & 72.35 & **74.14** & 69.22\(\) & 73.57\(\) \\ Children & 49.85 & **59.91** & 57.07 & 58.11 & 57.57 & 58.74 & 54.75\(\) & 59.70\(\) \\ History & 83.06 & **86.09** & 84.52 & 85.04 & 84.79 & 85.12 & 83.52\(\) & 85.09\(\) \\ Photo & 73.75 & 77.53 & 82.42 & 82.70 & 83.25 & 83.27 & 83.32\(\) & **86.64\(\)** \\ Computers & 58.32 & 60.40 & 87.43 & 87.86 & 87.90 & **88.30** & 83.93\(\) & 86.04\(\) \\ Sports & 81.47 & 86.02 & 84.93 & 86.16 & 87.06 & **87.34** & 85.06\(\) & 85.87\(\) \\   

Table 3: Node classification of the three learning paradigms on six datasets. Sports corresponds to the F1 score as an indicator of experimental results and Accuracy for the rest of the data. We bold the best results for each dataset.

the GNN-based. This is probably because their text attributes are more fully informative and thus the text attributes largely reflect the linking relationships between the nodes. Therefore the PLM-based methods model text attributes more strongly would be more advantageous in this case. And on the Photo dataset, the GNN-based method outperforms the PLM-based method across the board. This may be because the text attributes of the Photo dataset are composed of information from user reviews of the product. Some lower-quality reviews introduce a certain amount of noise to the text attributes, which will reduce the effectiveness of the PLM-based methods. In order to analyze the importance of node text attribute selection, we further conduct relevant experiments in Appendix D.9.

### Validity of Topological Pre-training

In this subsection, we compare the three different pre-training methods with the PLM-based and GNN-based methods. We observe that on almost all PLMs and all datasets, different degrees of improvement can be achieved with the proposed pre-training methods. For these three individual pre-training tasks, we find that TCL leads to greater improvement in most cases. The difference in performance between TMLM and TCL, which both capture low-order topological structure information, indicates that learning topological structure knowledge from a node-level perspective may work better than a token-level. TDK, on the other hand, performs second only to TCL in most cases, which reflects to some extent the fact that PLMs can benefit from knowledge of the complex topology. Further, we try to combine these three pre-training tasks to optimize the model together (name TMDC). We first

    &  &  &  \\   & PLM & GNNs & TMLM & TDK & TCL & TMDC & PLM & GNNs & TMLM & TDRC & TCL & TMDC \\   & BERT-Tiny & 70.83 & **72.52** & 70.83 & 71.50 & 71.55 & 71.17 & 83.06 & 85.03 & 85.76 & 85.79 & 86.06 & **86.88** \\  & ELECTRA & 71.26 & 71.12 & 72.65 & 72.83 & 73.06 & **73.71** & 84.18 & 83.11 & 84.54 & 84.42 & 84.57 & **85.18** \\  & DistilBERT & 72.50 & 74.68 & 73.53 & 74.38 & 74.89 & **75.50** & 85.81 & 85.67 & 85.76 & 86.29 & 86.28 & **86.88** \\   & ELECTRA & 72.67 & 71.96 & 73.51 & 74.33 & 74.26 & **75.56** & 85.64 & 83.79 & 85.77 & 85.88 & **86.62** & 84.41 \\  & BERT & 72.96 & 74.59 & 73.97 & 74.23 & 74.87 & **76.11** & 86.09 & 85.28 & 86.24 & 86.46 & 86.50 & **86.82** \\  & RoBERTa & 73.10 & 74.82 & 74.25 & 74.57 & 75.37 & **75.97** & 85.85 & 85.69 & 86.19 & 86.32 & 86.95 & **86.96** \\  & DeBERTa & 73.82 & 68.26 & 74.26 & 750.17 & 75.15 & **75.59** & 86.16 & 82.31 & 86.00 & 86.46 & **87.01** & 86.94 \\   & ELECTRA & 27.42 & 72.26 & 75.46 & 77.36 & 73.82 & 74.17 & **75.58** & 86.13 & 83.56 & 86.39 & 86.49 & **86.22** & 86.28 \\  & BERT & 73.24 & 74.68 & 75.01 & 74.31 & 73.15 & **75.75** & 86.24 & 85.15 & 86.47 & 86.73 & 86.93 & **86.94** \\  & RoBERTa & 73.83 & 74.99 & 75.18 & 74.58 & 75.48 & **75.73** & 86.41 & 85.23 & 86.72 & 86.75 & 87.11 & **87.22** \\  & DeBERTa & 74.57 & 73.59 & 75.92 & 75.20 & 75.58 & **76.20** & 87.00 & 84.89 & 87.11 & 87.26 & 87.30 & **87.32** \\   &  &  &  \\   & PLM & GNNs & TMLM & TDK & TCL & TMDC & PLM & GNNs & TMLM & TDK & TCL & TMDC \\   & BERT-Tiny & 49.85 & **57.86** & 54.27 & 53.43 & 54.11 & 54.66 & 73.75 & **84.12** & 74.30 & 73.99 & 73.86 & 74.92 \\  & ELECTRA & 57.03 & 56.42 & 57.35 & 56.92 & 58.88 & **58.58** & 76.83 & **81.32** & 76.09 & 76.89 & 77.74 & 77.83 \\  & DistilBERT & 59.90 & 59.33 & 60.03 & 60.23 & 60.60 & **61.38** & 77.51 & **84.34** & 77.81 & 79.69 & 81.85 &perform token-level TMLM tasks on PLMs. The enhanced PLMs are then jointly optimized using both TCL and TDK tasks. (Detailed implementation can be found in Appendix A.2) Observing from the Table 4, we find that TMDC further improves performance in most cases. This indicates that different pre-training strategies can teach the PLM different topological knowledge from different perspectives, and this leads us to explore more pre-training tasks on TAGs in the future. To further analyze the effectiveness of these topological pre-training methods, we also test the performance of such topological pre-training models in other scenarios (e.g., semi-supervised learning and few-shot learning). Please refer to Appendix D.5 for detailed experimental results and discussions.

## 5 Discussion on the Practical Values

Text-attributed graphs have emerged as a prominent graph format, which finds extensive applications in modeling real-world tasks, such as the mentioned recommender systems. Our research concentrates on achieving a comprehensive understanding of the textual attributes embedded within a single node and the topological structural connections between nodes. For example, a famous example in recommender systems is the association between "diaper" and "beer", commonly co-purchased by customers, thereby establishing links between these items in the item-item graph. To achieve the optimal item representation, a prerequisite is to capture the inherent characteristics of a given item by modeling its metadata, such as title and descriptions. Simultaneously, it is imperative to incorporate valuable and unique signals derived from the graph's topological connections into the representation learning process. Given that real-world graph topology is usually shaped by human behaviors, there exist unique human perceptions and knowledge in the topology beyond the pure semantics (e.g., "diaper" and "beer" are semantically different but are connected in the co-purchased graph). Consequently, it is imperative to delve into the effective and efficient fusion of intrinsic semantics within individual nodes and the topological connections among different nodes on the text-attributed graphs. Moreover, the scope of our research also includes domains like user behavior-enhanced sponsored search, including AdsGNN , HBGLR , and PASS .

## 6 Conclusion

We establish the first comprehensive benchmark CS-TAG specifically designed to explore representation learning on TAGs. We collect and provide eight available text-attributed graph datasets to facilitate the NLP and GNN communities to focus and investigate the data together. Our benchmark provides a more comprehensive evaluation of different learning paradigms, validating their effectiveness and limitations. We will also continue to mine and construct more research-worthy TAGs to advance the continued healthy development of the field.