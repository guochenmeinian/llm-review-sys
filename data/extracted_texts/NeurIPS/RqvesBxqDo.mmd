# QVAE-Mole: The Quantum VAE with Spherical Latent Variable Learning for 3-D Molecule Generation

Huanjin Wu, Xinyu Ye, Junchi Yan

Dept. of CSE & School of AI & MOE Key Lab of AI, Shanghai Jiao Tong University

{whj1201,xinyu_ye,yanjunchi}@sjtu.edu.cn

Corresponding author. \({}^{}\) Equal contribution. This work was partly supported by NSFC (92370201, 62222607) and Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0102.

###### Abstract

Molecule generation ideally in its 3-D form has enjoyed wide applications in material, chemistry, life science, etc. We propose the first quantum parametric circuit for 3-D molecule generation for its potential quantum advantage especially considering the arrival of Noisy Intermediate-Scale Quantum (NISQ) era. We choose the Variational AutoEncoder (VAE) scheme for its simplicity and one-shot generation ability, which we believe is more quantum-friendly compared with the auto-regressive generative models or diffusion models as used in classic approaches. Specifically, we present a quantum encoding scheme designed for 3-D molecules with qubits complexity \((C n)\) (\(n\) is the number of atoms) and adopt a von Mises-Fisher (vMF) distributed latent space to meet the inherent coherence of the quantum system. We further design to encode conditions into quantum circuits for property-specified generation. Experimentally, our model could generate plausible 3-D molecules and achieve competitive quantitative performance with significantly reduced circuit parameters compared with their classic counterparts.

## 1 Introduction

Beyond molecule graph generation, 3-D molecule generation which can often be more challenging yet of practical value, e.g. for drug design, has received wide attention in recent years . On the one hand, the space of possible molecules and chemical compounds is vast, often described as a "chemical space" with an immense number of dimensions, and data-driven methods relying on machine learning (ML) have been introduced [2; 3]. On the other hand, quantum computing has demonstrated strong expressive capabilities in various learning and optimization applications, including solving , classification , and discovery . Particularly, it has potential advantages in tasks related to the microphysical world, such as chemistry simulation , prediction of molecular properties , and approximation of ground-state energy . Therefore, beyond classic ML, here we dive into the quantum world for 3-D molecule generation with the arrival of the so-called NISQ era. However, limited by the current development of quantum hardware, quantum machine learning (QML) models, particularly quantum generative models, are still in their infancy stages, especially when compared to the well-developed classic neural models, thus the current performance of QML models may not match that of SOTA classic counterparts [10; 11; 12; 13].

Recent efforts have been made to introduce quantum methods for molecule design. QGAN-HG  is a hybrid model based on Generative Adversarial Network (GAN), consisting of a classic discriminator and a hybrid generator. However, hybrid models cannot be implemented on NISQ devices, andQGAN-HG only utilizes quantum circuits to learn features with low dimensions, which actually decreases the performance of classic neural networks. Another work SQ-VAE , a quantum Variational AutoEncoder (VAE) approach, represents the molecular graph as a flattened adjacency matrix and converts it into a quantum state through amplitude encoding. However, it is difficult for its quantum circuit to reconstruct the topology structure by the inputted flattened adjacency matrices . Furthermore, SQ-VAE adopts a normal distributed latent space, where latent variables remain unconstrained by normalization requirements. Nevertheless, the quantum state outputs of SQ-VAE are subject to normalization, necessitating a linear mapping with classic parameters to map the output into non-normalized latent variables. This indicates the incompatibility of the normal distribution with quantum systems. In all, these two quantum methods are limited to generating molecular graphs and fall short of generating 3-D molecules.

To address the above issues and explore a quantum version of VAE for _3-D data generation_ (which is the first time in literature), we develop a full quantum VAE framework, especially for 3-D molecule generation. Firstly, we introduce a quantum encoding scheme designed for 3-D molecules to fulfill the normalization constraints by quantum states. This involves normalizing the 3-D coordinates, atom types, and an auxiliary value associated with each atom. These normalized atom vectors are then concatenated to form the initial quantum state. Secondly, we adopt von Mises-Fisher (vMF) distribution, which lies in a hyperspherical space and can inherently meet the restrictions of quantum systems (the norm of quantum state is 1).

In addition, the ultimate objective is to generate molecules directly with desired properties in various domains . For instance, there is a growing demand for molecules with a low HOMO-LUMO gap in the field of organic semiconductor development . To this end, we further present a _conditional version_ of quantum VAE named QCVAE-Mole, which have the ability to generate molecules with multiple desired properties. Specifically, we introduce condition qubits as well as condition parametric layers to encode given conditions into the proposed quantum ansatz, thus we can generate molecules with desired properties by giving specific condition vectors. **The contributions are:**

1) We propose the first fully (to our best knowledge) quantum VAE for _3-D data generation_ and detailed quantum circuits compatible with NISQ devices. For generated quantum states, we fulfill its inherent normalization requirement via the vMF distribution in a spherical latent space.

2) Our conditional VAE version manages to encode the conditions into the quantum circuit, which is, to our best knowledge, the first fully quantum circuit capable of _conditional_ VAE-based generation.

3) We conduct all the experiments in a TorchQuantum-based simulation environment in line with many QML works [8; 19; 20]. Extensive results on the QM9 benchmark show that our model outperforms all other quantum (or hybrid) methods [14; 15] and delivers comparable results to several classic methods [21; 22; 23] with significantly reduced parameters.

Figure 1: **Pipeline of QVAE-Mole and QCVAE-Mole with a vMF distributed latent space. We first use amplitude encoding to get the initial quantum state vectors from classic data of molecules. Then the quantum encoder learns the mean direction \(\) in the latent space, which is used to sample a latent variable \(z_{i}(,)\). A subsequent quantum decoder decodes \(z\) trying to match the input state vector. Then molecule is reconstructed from the output state vector of decoder. For conditional generation, we have a condition vector for both input data and latent space, then we use condition qubits as well as condition layers to encode the given conditions into the quantum circuit. Solid and dashed arrows represent the training and inference phase, respectively.**

## 2 Preliminaries

**Quantum machine learning.** A quantum bit (qubit) is the unit of quantum information and computing, which exists in the superposition state of both 0 and 1, as denoted by \(|=|0+|1\), where \(\) and \(\) are complex coefficients. \(||^{2}\) and \(||^{2}\) are the probability amplitudes for the qubit being in basis states (\(|0\) or \(|1\)). For \(n\)-qubit system, there are \(2^{n}\) basis states. Quantum gates are the building blocks that manipulate quantum states. These gates are represented by unitary matrices. Parameterized quantum gates are quantum gates with one or more parameters. See Appendix B for the single-qubit and double-qubit parameterized quantum gates used in this paper.

The concept of Variational Quantum Algorithms (VQA) was proposed by , which utilizes quantum advantages to solve ML problems on NISQ devices. Then, Parameterized Quantum Circuits (PQCs) serve as the specific implementations of these VQAs, with the parameterized quantum gates mentioned above being key components of PQCs. The parameters \(\) can be optimized by a classic optimizer to minimize loss function \(()\), which evaluates the dissimilarity between the output of QPC and the target result. Even if the measurement itself does not provide gradient information, the gradients of \(\) can be directly estimated by perturbing \(\) slightly. For instance, the Parameter Shift Rule  is a popular technique used to achieve the gradients in many QML models [19; 26]. Also using gradient backpropagation, classic learning models are adapted into their quantum version, e.g. QCNN , QRNN , QGAN , QLSTM , and etc, They are highly recognized for their intellectual novelty as well as their potential in the NISQ era.

**Variational autoencoder.** Variational autoencoders (VAEs)  are a class of generative models that combine autoencoders with variational inference techniques. VAEs provide a principled approach to learning latent representations and generating new data samples. Formally, VAE is represented by an inference network (_i.e._, encoder) \(q_{}(z|x)\) and a generator network (_i.e._, decoder) \(p_{}(x|z)\), where \(z\) denotes the latent variables. The intractable true posterior \(p_{}(z|x)\) is approximated by the inference network \(q_{}(z|x)\), which is parameterized by a neural network and outputs a probability distribution for each data point \(x\). Given the training set \(D=\{x_{i}\}_{i=1}^{N}\) and the prior \(p()\), the final objective is to minimize the negative of Evidence Lower Bound (ELBO):

\[_{,}_{}(,;x)=-_{z  q_{}(z|x)}[(p_{}(x|z))]+D_{KL}[q _{}(z|x)\|p(z)].\] (1)

It serves as a proxy for the log-likelihood of the data with a regularizer. The first term is known as reconstruction loss, and the second is the Kullback-Leibler (KL) divergence.

## 3 Methodology

We leave a detailed discussion on related works in Appendix A, including classic methods for molecule generation and quantum generative learning. In this section, we first introduce how to encode classic data into a quantum state and then elaborate on the quantum architecture of QVAE-Mole and QCVAE-Mole. Fig. 1 shows the pipeline.

### Encoding 3-D Molecule to Initial Quantum State

We use an attributed point cloud \(\{(v_{i},a_{i})\}_{i=0}^{n-1}\)to represent a 3-D molecule with \(n\) atoms, where each point represents an atom. Here \(v_{i}^{3}\) denotes the 3-D coordinates of the atom and \(a_{i}\{0,1\}^{k}\) denotes the atom type (\(k\) is the number of atom types). To encode the molecules into quantum states, we normalize them in two aspects: 1) Each 3-D molecule can undergo arbitrary translations and rotations, and there is no inherent ordering among atoms, which requires us to fix the order of atoms and the molecular conformation to obtain unique encoding. 2) The amplitudes of quantum states require us to keep the input data of the molecule within the positive octant. See details of normalization in Appendix C.

Figure 2: **Classic data encoding.** We encode 3-D molecules with 3-D coordinates and atom types through three steps: 1)introduce an auxiliary value, 2) normalize to a norm 1.0, and 3) convert into a quantum state vector via amplitude encoding.

We will introduce how to encode the normalized 3-D molecules into quantum states. It converts the given classic data sample \(x\) into its corresponding quantum state \(|_{x}\). Here, we choose amplitude encoding, which allows us to utilize the exponentially large Hilbert space compared with angle encoding. The data of length \(N\) is encoded into the amplitudes of \(q=_{2}N\) qubits. In this case, we need to encode each atom with its 3-D coordinates as well as the one-hot form of atom types.

As amplitude encoding demands a state vector with the unit norm, inspired by , here we introduce an auxiliary value \(^{2}-y_{i}^{2}-z_{i}^{2}}\) for each normalized atom \(_{i}=(x_{i},y_{i},z_{i})\) as a constant normalization factor. Therefore, we need \(4+k\) entries for each atom (3 for 3-D coordinates, \(k\) for one hot embedding, \(1\) for auxiliary value), and the total number of entries is \(n*(4+k)\). See Fig. 2 for our encoding. Furthermore, the state vector size is always a power of \(2\), so we fill the remaining entries with zeros (padding entries) and obtain a state vector of size \(2^{q}\). The norm of the state vector is 1, thus we need to normalize all values by \(2\). We get the initial quantum state of a molecule by:

\[|_{0}&=} _{i=0}^{n-1}(x_{i}|r_{i}+y_{i}|r_{i}+1+z_{i}|r_{i}+2 +1|r_{i}+3+t_{i}.\\ &.+^{2}-y_{i}^{2}-z_{i}^{2}}|r_{i}+k+3 )+_{j=(n*(4+k))}^{2^{q}-1}0|j,\] (2)

where \(r_{i}=(k+4)*i\) and \(t_{i}\) is the atom type of \(i\)-th atom. The discussion of the initial state preparation can be found in Appendix C.

**Qubits complexity analysis.** The number of qubits in our proposed framework comes to \(q=_{2}(n_{max}*(4+k))=(C n)\), where \(n_{max}\) represents the maximum number of atoms. The qubits complexity analysis of other quantum methods can be seen from Appendix C.

### Full Quantum Architecture

We propose QVAE-Mole, a fully quantum circuit-based VAE for 3-D molecule generation. Like many works on QML, e.g. QCNN ,QGAN , QLSTM , we follow the architecture of its classic design, the VAE in our case, which generally includes encoder, decoder, and latent space. In fact, proposing a quantum counterpart as well as its detailed quantum circuits compatible with NISQ devices is nontrivial, especially for 3-D data (molecule) generation.

#### 3.2.1 Encoder

We present the encoder network of our QVAE-Mole. Similar to classic neural networks, the PQC is built layer by layer, where each layer consists of the same arrangement of quantum gates with different trainable parameters. Fig. 3 depicts the general framework of the quantum encoder ansatz. Denote \(_{s}(_{s}^{l}),_{ent}(_{ent}^{l})\) as the \(l\)-th single-qubit layer and entanglement layer with trainable parameters, respectively. The unitary matrix of the proposed encoder can be formulated as follows, where \(L\) denotes the total number of layers.

\[()=_{s}(_{s}^{L+1})_{l=1}^{L} (_{ent}(_{ent}^{l})_{s}(_{s}^{ l})),\] (3)

Specifically, the \(l\)-the trainable single-qubit layer is formulated as:

\[_{s}(_{s}^{l})=_{p=1}^{q}(_{ }(_{z_{1}}^{(p,l)})_{} (_{y}^{(p,l)})_{}(_{ z_{2}}^{(p,l)})),\] (4)

Figure 3: **The ansatz of our quantum encoder**. It takes the initial quantum state \(|_{0}\) as input and outputs the mean direction \(\) of vMF distribution. Each layer includes a single-qubit layer \(_{s}\) and an entanglement layer \(_{ent}\). In the end, we trace out the state of the last \(q_{B}\) qubits: \(q_{B}=q-q_{A}\).

where \(_{z_{1}}^{(p,l)}\), \(_{z_{2}}^{(p,l)}\) denote the parameter of the first and second \(}\) gate at the \(l\)-th layer on the \(p\)-th qubit, respectively. And the \(l\)-th entanglement layer can be formulated as:

\[_{ent}(_{ent}^{l})=_{p=1}^{q}(} (p,(p+1)\%q,_{ent}^{(p,l)})),\] (5)

where \(}\) is the controlled \(}\) gate, \(p\) denotes the control qubit, \((p+1)\%q\) denotes the target qubit, and \(_{ent}^{(p,l)}\) denotes the corresponding trainable parameter. The quantum state after the encoder ansatz is \(|^{E}=()|_{0}\). Detailed discussions and the theoretical analysis of the expressive power of the designed quantum circuit are shown in Appendix E.

At the end of the encoder circuit, we introduce a measure to reduce the dimension of the output quantum state. Inspired by , we divide the encoder circuit into two subsystems, namely subsystem \(A\) with \(q_{A}\) qubits and subsystem \(B\) with \(q_{B}\) qubits, and \(q_{A}+q_{B}=q\). Therefore, the output quantum state of the encoder ansatz becomes \(|^{E}_{AB}=()|_{0}_{AB}\).

#### 3.2.2 Latent space

To convert to latent space, here we discard the information contained in the subsystem \(B\) via _tracing out_ the state of \(q_{B}\) qubits. This approach integrates quantum non-linearity into the encoder, thereby enriching the transformation process with a layer of complexity beyond that of a mere unitary transformation. Formally, the partial trace is:

\[_{A}=_{b}(_{AB})=_{j}(_{A}| j|_{B})_{AB}(_{A}|j_{B} ),\] (6)

where \(_{A}\) is the identity matrix, \(|j_{B}(^{2})^{ q_{B}}\) are all basis states of subsystem \(B\) and \(_{AB}=|_{AB}|_{AB}\). The diagonal of \(_{A}\) contains the squared amplitudes of \(|_{A}\), as can be converted into the output quantum state of encoder \(|^{E}_{A}=_{j}}}|j\). Then, we perform quantum tomography  rather than random measurements on the encoder. The output is the vector of the latent space of dimension \(2^{q_{A}}\). More discussions about tracing out and quantum state tomography are given in Appendix F.

In common VAEs, normal distributions are assumed for the distribution of the latent variables during training. However, normal distributions are unsuitable for data with a latent hyperspherical structure. The quantum state vector requires its L2 norm to be equal to 1, which lies in a hypersphere space. Instead we adopt using a von Mises-Fisher (vMF) distribution, leading to hyperspherical latent space. Formally, the distribution is:

\[q_{}(z|x)=(,)=C_{d,}e^{(x),z },\] (7)

where \(\|\|=1\) denotes the mean direction. \(\) denotes the concentration parameter, which is commonly set as a constant during training . The normalization constant \(C_{d,}\) is equal to \(1/_{S^{d-1}}e^{,x}dS^{d-1}\), where \(^{d}\) is a predefined parameter vector and \(S^{d-1}\) is the sample space \(\{x|x^{d},\|x\|=1\}\). We set that the quantum state \(|^{E}_{A}\) seamlessly functions as \(\) for learning the vMF distribution. In addition, rejection sampling  is utilized to efficiently sample latent variable \(z\) from the vMF distribution in the latent space:

\[z(||^{E}_{A}|,)=C_{d,}e^{ ||^{E}_{A}|,z},\] (8)

which represents that the latent variable \(z\) is sampled from the vMF distribution with mean direction \(=||^{E}_{A}|\) in the latent space.

#### 3.2.3 Decoder

The decoder takes \(z\) sampled from the vMF distribution as input and outputs the reconstructed quantum state, which can be further converted to a molecule. The input \(z\) has a dimension of \(2^{q_{A}}\), and the reconstructed quantum state should have the same dimension as the initial quantum state, which is \(2^{q}\). This means that the quantum decoder needs to map from a lower-dimensional space to a higher-dimensional one using a unitary transform. We achieve this by first turning \(z\) into the state \(|^{D}_{A}\) via amplitude encoding and then expanding \(|^{D}_{A}\) with qubits of \(B\), which are reset to \(|0_{B}\). Now we get the initial quantum state of the decoder:

\[|^{D}_{0}=|^{D}_{0}_{AB}=|^{D}_{A}|0 _{B}.\] (9)

We design the quantum ansatz of the decoder the same as that of the encoder, then the reconstructed quantum state results in \(|_{r}=(})|^{D}_{0}\), here \(}\) denotes the learnable parameters in decoder.

We can get the output quantum state \(|_{r}\) denoted as \((_{0},,_{2^{q}-1})\). Now, we convert this vector back into classic data, representing a molecule, which serves as the inverse process of encoding:

\[(x^{},y^{},z^{}) =(_{r_{i}},_{r_{i}+1},_{r_{i}+2}),\] (10) \[t^{}_{i} =(_{r_{i}+3},,_{r_{i}+3+(k-1)}),\] (11) \[r_{i} =(k+4)*i, i=1,,n-1,\] (12)

where \(x^{},y^{},z^{}\) are the reconstructed coordinates of each atom, \(t^{}_{i}\) is the reconstructed atom type, and \(n\) is the number of atoms. Note that \(n\) is known in training but can be arbitrary at inference. Therefore, we need to infer the number of atoms in the generated molecule from the output state vector. We set the following criteria: if \((_{r+3}++_{r+3+(k-1)})<T\) for a certain \(i\), we consider all subsequent entries to be padding items instead of carrying valid information, and the number of atoms in this generated molecule comes to \(n=i\). The hyperparameter \(T\) denotes the threshold.

**Remark.** We further discuss why choosing amplitude encoding instead of angle encoding from the perspective of encoding and reconstruction. For angle encoding, we obtain the initial quantum state by converting input information into the rotation angles of qubits. Although it is friendly to initial state preparation, it becomes intractable to reconstruct the input angles from the entangled quantum state, which is the output of the decoder. On the contrary, if we encode the input into the amplitudes of qubits, we can directly reconstruct the input information from the output quantum state vector.

#### 3.2.4 Training

Recall the objective function in Eq. 1, we use a uniform vMF prior \(p(z)=(,0)\) on the latent space. The vMF prior prevents the KL collapse typically observed in Gaussian VAE settings . In fact, the KL term in our loss term is constant and only depends on the chosen variance \(\), which is a hyperparameter in our model. Thus, we can simplify the Eq. 1 to:

\[_{,}_{}(,;x)=-_{z  q_{}(z|x)}[(p_{}(x|z)).\] (13)

In other words, we only need to calculate the reconstruction loss. Here, we can calculate the loss of \(|_{0}\) and \(|_{r}\) in two ways. One is to design the reconstruction loss based on converted classic data, while the other is to construct the loss using the fidelity of the quantum state (we denoted as _fidelity loss_ in experiments). The former can achieve better model performance but requires transferring the data to a classic computer for computation, while the latter can be computed by the quantum circuit, e.g. the swap test circuit. Details of loss function design can be found in Appendix D.

### Conditional Generation

We further propose a framework named QCVAE-Mole, extending upon our above QVAE-Mole by adding certain conditions. Unlike the classic CVAE , which achieves conditional generation by simply adding specific condition vectors to input data and latent space. We design to encode conditions into the quantum circuits of the encoder and decoder. Specifically, suppose there is a multi-condition vector \([c_{1},c_{2},,c_{m}]\), where each

Figure 4: **The ansatz of QCVAE-Mole**: it incorporates \(m\) additional condition qubits for \(m\) target properties and additional condition layers. At the end of the circuit, we further trace out the state of \(m\) condition qubits.

item corresponds to the normalized value (ranging from 0 to 1) of one specific property. Then, we use angle encoding to encode one property into the parameter of one quantum gate, and the initial quantum state becomes:

\[|_{c_{i}}=}((c_{i}-0.5) 2)|0.\] (14)

As shown in Fig 4, we extend the scale of the previous quantum circuit and encode the conditions in the last qubits to construct our condition layer. The initial quantum state of the encoder becomes:

\[|_{0}^{c}=|_{0}|_{c_{1}} |_{c_{m}}\,.\] (15)

Similarly, the input of the decoder undergoes the same change. The unitary matrix of QCVAE is:

\[()=_{s}^{L+1}()_{l=1}^{L} (_{ent}^{l}()_{s}^{l}() _{c}^{l}()),\] (16)

where the \(l\)-th condition layer can be formulated as:

\[_{c}^{l}()=_{i=1}^{m}_{p=1 }^{q}(_{x}(q+i,p,_{c}^{(i,p,l)}).\] (17)

Note that every target property requires one more qubit for QCVAE-Mole, which means we have more qubits than QVAE-Mole, but the output dimension of the encoder and decoder should remain the same as vanilla QVAE-Mole, which can be achieved by _tracing out_ the condition qubits at the end of the quantum circuit. The process of training is similar to QVAE-Mole and the decoder of the trained model generates molecules with the desired properties according to the given condition vector along with the latent vector.

**Remark.** QCVAE-Mole can be regarded as solving the inverse problem of property prediction, as particularly done in . Indeed, generation could be much more challenging than prediction.

## 4 Experiments

In line with other QML works [8; 19; 20], our experiments are conducted in a simulation environment. Specifically, we use a machine with an i9-10920X CPU, RTX 3090 GPU, and 128G RAM. The source code is written by PyTorch, and TorchQuantum  is used as the quantum simulator. In addition, the ansatz of QVAE and QCVAE are all hardware efficient, thus the model can be directly trained on NISQ devices theoretically. Although our approach may involve initial state preparation and quantum state tomography like [15; 29], there are many efficient solutions to address these two challenges, such as [38; 39; 40; 41; 42], and this is not the focus of our paper. Detailed discussions of initial state preparation and tomography can be found in Appendix C and F, respectively.

### Setting

**Data.** We evaluate QVAE-Mole and QCVAE-Mole on QM9 , which is a popular dataset that contains molecular properties and atom coordinates for 130k small molecules with up to 9 heavy atoms. We train our model to either randomly or conditionally generate molecules with 3-D coordinates and atom types (C, N, O, F). We use the train/val partitions introduced in , which consist of 100K/18K samples, respectively.

**Actual number of qubits.** When evaluating QM9, we need 7 qubits for random generation, 8 qubits for single-condition generation, and 11 qubits for multiple conditions, respectively.

**Metric.** In line with [23; 45], all the generated 3-D molecules are converted to molecular graphs by the method in , and the molecular graphs can be converted to SMILES deterministically with the rdkit  toolkit. We use the chemical validity percentage (**Valid**), uniqueness (**Unique**), and novelty (**Novel**) to evaluate the generation quality of QVAE-Mole. Validity measures the percentage of molecules that comply with chemical valency rules, ensuring chemical plausibility. Uniqueness assesses the proportion of distinct molecules generated, promoting structural diversity. Novelty evaluates the fraction of molecules not found in the training data, indicating the model's capacity to generate new compounds. To evaluate the molecular geometry, we use the average Maximum Mean Discrepancy (Avg.MMD)  distances of bond length distributions (see details in Appendix G). Note that it is unreasonable to only consider novelty and uniqueness without validity : like in the extreme case if the model's validity is only 1%, but these valid molecules are all unique from each other and different from the training set, resulting in 100% for both uniqueness and novelty. Thus, we adopt **Unique\(\)Valid** and **Novel\(\)Valid** as metrics.

**Baseline.** We adopt two kinds of methods as our baselines. One category is the classic generation model for 3-D molecules, including MLP-VAE , E-NFs , G-SchNet , G-sphereNet  and EDM . Another category contains quantum model SQ-VAE  and hybrid model QGAN-HG  (P2-QGAN-HG is a variant of QGAN-HG) for molecular graph generation. Note that SQ-VAE still introduces several classic parameters since it needs a linear mapping in latent space. As for QGAN-HG, it simply utilizes quantum circuits to output a feature vector for the classic generator of MOLGAN . To the best of our knowledge, we are the first full quantum model without any classic parameters for 3-D molecule generation.

### Random 3-D Molecule Generation

The results are shown in Table 1, reported as the mean with standard deviation across three runs. The training details and results of the MMD distance comparison are shown in Appendix G.

**Compare with classic methods.** The results show that QVAE-Mole surpasses classic MLP-VAE with a notable margin in all metrics, indicating the potential advantages of quantum circuits over classic MLPs. However, there is still a performance gap between our method and the other SOTA baselines, especially EDM, a method based on the diffusion model. On the other hand, when assessing the efficiency of the model, it is also necessary to consider the number of parameters utilized. We can see that our results are very close to the auto-regressive method G-SphereNet and even superior to E-NFs to some extent, which uses 3,148,095 and 647,117 parameters, respectively. In contrast, our model only uses 224 quantum parameters instead. Furthermore, our model has an advantage in inference speed over all the classic models except for the simple VAE. In terms of training cost, our model (even when executed on a simulator) achieves convergence within 2 hours with only a few epochs, which is significantly faster compared to classic methods (according to the original paper on EMD , it takes approximately 3.2 days on a 1080Ti GPU to complete 1100 epochs).

**Compare with quantum methods.** Our model outperforms all other quantum or hybrid approaches by a significant margin in all metrics. SQ-VAE uses amplitude encoding for molecular graphs (attributed topology), while the input of our model is a 3-D molecular structure (attributed 3-D point cloud). This indicates that amplitude encoding cannot model topology as effectively as for 3-D point clouds. Furthermore, we utilize a larger latent space compared with SQ-VAE and adopt vMF distribution instead of a normal one, with vMF distribution naturally fitting the inherent and strict normalization requirement of output vectors. The performance of QGAN-HG is poor, probably because the quantum circuits in the hybrid model are unable to fully leverage potential advantages or due to the complex and unstable training process of GAN itself.

### Conditional 3-D Molecule Generation

The objective here is to generate molecules with specific desired properties. We train QCVAE-Mole (as discussed in Sec. 3.3) conditioning on four properties: synthetic accessibility score (**SA**),

   Methods & Model & Class & Valid & Unique\(\)Valid & Novel\(\)Valid & \# C/Q Params & Time(s) \\  MLP-VAE  & VAE & One-shot & 51.26\% \(\) 1.1 & 3.43\% \(\) 6.3 & 48.66\% \(\) 0.4 & 360,448 / 0 & 0.04 \\ E-NFs  & Flow & One-shot & 41.14\% & 40.83\% & 34.91\% & 647,117 / 0 & 0.27 \\ G-SchNet  & Sampling & Autoreg. & 82.35\% & 73.29\% & 67.08\% & 902,111 / 0 & 0.41 \\ G-SphereNet  & Flow & Autoreg. & 82.63\% \(\) 1.5 & 29.75\% \(\) 1.6 & 37.77\% \(\) 0.9 & 3,148,095 / 0 & 0.55 \\ EDM  & Diffusion & One-shot & 91.93\% & 90.72\% & 75.32\% & 5,340,921 / 0 & 0.86 \\  SQ-VAE\({}^{+}\) & VAE & One-shot & 44.23\% \(\) 1.0 & 7.24\% \(\) 1.2 & 16.32\% \(\) 0.8 & 128 / 224 & 0.15 \\ QGAN-HG\({}^{+}\) & GAN & One-shot & 66.64\% \(\) 0.3 & 8.08\% \(\) 0.8 & 18.48\% \(\) 1.0 & 453,644 / 38 & 0.04 \\ P2-QGAN-HG\({}^{+}\) & GAN & One-shot & 17.64\% \(\) 1.2 & 12.38\% \(\) 2.1 & 9.54\% \(\) 0.8 & 112,524 / 14 & 0.02 \\  QVAE-Mole\({}^{}\) & VAE & One-shot & 78.13\% \(\) 0.6 & 27.39\% \(\) 0.8 & 57.38\% \(\) 0.9 & 0 / 224 & 0.08 \\ QVAE-Mole (fidelity loss)\({}^{}\) & VAE & One-shot & 74.39\% \(\) 0.8 & 26.93\% \(\) 1.0 & 31.50\% \(\) 0.7 & 0 / 224 & 0.08 \\   

Table 1: **Comparison of different methods on QM9. All metrics were evaluated on 10K randomly generated molecules. The method with \(\) denotes it generates molecular graphs, not 3-D molecules, and \(\) denotes it involves quantum computing. #C/Q denotes the number of classic and quantum parameters respectively, and time denotes the inference time to generate one molecule.**quantitative estimation of drug-likeness (**QED**), octanol-water partition coefficient (**logP**), and HOMO-LUMO gap (**gap**). See details in Appendix G.

**Single condition.** We train our model with SA, QED, logP, and gap, respectively, resulting in four models. For each model, we compare the conditional generation (QCVAE-Mole) with random generation (QVAE-Mole) and the corresponding results are shown in Table 2. Each column in Table 2 indicates the percentage of molecules whose properties, when rounded up, match the specified condition. For instance, for the condition logP = 0.0, the results show that 57.8% of generated molecules have logP values within the range [-0.5, 0.5). The results demonstrate that QCVAE-Mole can improve the proportion of generated molecules with desired properties for all given conditions, the improvement even reaches 43% when we give the condition with logP\(=1\).

**Multiple conditions.** We train the proposed QCVAE-Mole under multiple conditions, which means we give SA, QED, logP, and gap these four properties simultaneously. To evaluate under a combination of multiple conditions, following , we select a reference molecule and adopt its property values as our multi-condition. Here we choose "CC1=C=C=C(N=O)C1=0", and the property values are: \(\{=0.52,=0.38,=0.92,=4.45\}\). Fig. 5 illustrates the comparison with random generation, demonstrating that QCVAE-Mole is capable of achieving multi-condition generation, albeit with less pronounced improvement compared to single-condition generation.

    &  &  &  &  \\  Condition & 0.4 & 0.5 & 0.3 & 0.4 & 0.0 & 1.0 & 3.0 & 4.0 \\  QVAE-Mole & 29.8 & 19.8 & 40.2 & 52.5 & 49.8 & 2.6 & 0.1 & 3.1 \\ QCVAE-Mole & 44.1 & 23.4 & 42.8 & 75.2 & 57.8 & 45.6 & 6.4 & 22.7 \\  \(_{}\) & 14.3 & 3.6 & 2.6 & 22.7 & 8.01 & 43.0 & 6.3 & 19.6 \\   

Table 2: **The results of QCVAE-Mole under single condition given. Each result is the percentage of the number of molecules that, when rounded up, have the same value as the given condition.**

Figure 5: Distribution of four properties of generated molecules under multi-condition. Dashed lines represent the given condition values.

Figure 6: a) Comparison of a normal distribution (\(\)-) or a vMF one (\(\)-) in the latent space of MLP-VAE (VAE in short) and QVAE-Mole (QVAE in short). b) Different \(\) in vMF distribution.

### Ablation Study

**Normal distribution vs vMF distribution.** We study adopting normal distribution and von Mises-Fisher (vMF) distribution in classic VAE and quantum VAE, corresponding to Euclidean space and hyperspherical space, respectively. Here we conduct experiments under random generation setting. Fig. 6(a) shows QVAE with hyperspherical latent space performs the best validity, which reveals the advantages of using vMF distribution in QVAE. In addition, we found that compared to \(\)-VAE, \(\)-QVAE can generate relatively reasonable 3-D coordinates, ensuring that the distances between atoms fall within the range of chemical bond lengths. However, the atom numbers and atom types generated by \(\)-QVAE are relatively homogeneous, resulting in lower scores for novel and unique compared to \(\)-VAE. We also observe that utilizing normal distribution leads to better performance in classic VAE than using the von Mises-Fisher distribution.

**Compact of \(\).** In Sec. 3.2.2, we have mentioned the concentration parameter \(\) in vMF distribution is commonly set as a constant during training. To further explore its impact on the quality of random generation, here we vary \(\) from 0.1 to 100 and the results are shown in Fig. 6(b). We observe that the smaller the \(\) value, the higher the validity, but the uniqueness and novelty will decrease correspondingly. This indicates a trade-off in the selection of \(\): when we need high accuracy, we should choose a smaller \(\), while diverse molecules are in need, we should opt for a larger \(\).

## 5 Conclusion, Limitation, and Outlook

We have proposed the first fully quantum VAE for 3-D molecule generation, to the best of our knowledge, featuring a von Mises-Fisher distributed latent space. Moreover, we have designed a conditional version for target molecule generation. Numerical experiments show that our model could generate plausible 3-D molecules, which outperform all other quantum (or hybrid) methods, and achieve competitive performance with significantly reduced parameters compared with their classic counterparts. Though we provide detailed quantum circuits compatible with NISQ devices, due to hardware constraints, so far we have not implemented our proposed quantum circuits on real quantum devices. We leave it for future work and further collaboration with hardware groups where tailored hardware error correction may be needed.