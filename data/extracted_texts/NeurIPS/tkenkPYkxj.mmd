# Exponential Lower Bounds for Fictitious Play in Potential Games

Ioannis Panageas

University of California, Irvine

ipanagea@ics.uci.edu

&Nikolas Patris

University of California, Irvine

npatris@uci.edu

&Stratis Skoulakis

LIONS, EPFL

efstratios.skoulakis@epfl.ch

&Volkan Cevher

LIONS, EPFL

volkan.cevher@epfl.ch

Equal contribution.

###### Abstract

Fictitious Play (FP) is a simple and natural dynamic for repeated play with many applications in game theory and multi-agent reinforcement learning. It was introduced by Brown  and its convergence properties for two-player zero-sum games was established later by Robinson . Potential games  is another class of games which exhibit the FP property , i.e., FP dynamics converges to a Nash equilibrium if all agents follows it. Nevertheless, except for two-player zero-sum games and for specific instances of payoff matrices  or for adversarial tie-breaking rules , the _convergence rate_ of FP is unknown. In this work, we focus on the rate of convergence of FP when applied to potential games and more specifically identical payoff games. We prove that FP can take exponential time (in the number of strategies) to reach a Nash equilibrium, even if the game is restricted to two agents and for arbitrary tie-breaking rules. To prove this, we recursively construct a two-player coordination game with a unique Nash equilibrium. Moreover, every approximate Nash equilibrium in the constructed game must be close to the pure Nash equilibrium in \(_{1}\)-distance.

## 1 Introduction

In 1949 Brown  proposed an uncoupled dynamics called _fictitious play_ so as to capture the behavior of selfish agents engaged in a repeatedly-played game. Fictitious play assumes at round \(t=1\), each agent selects an arbitrary action. At each round \(t 2\), each player plays a best response pure action to the opponents' _empirical strategy_; empirical strategy is defined to be the average of the past chosen strategies.

Due to its simplicity and natural behavioral assumptions, fictitious play is one of the most seminal and well-studied game dynamics . Despite the fact that fictitious play does not converge to a Nash equilibrium (NE) in general normal-form games, there are several important classes of games at which the _empirical strategies_ always converge to a NE. In her seminal work, Robinson  showed that in the case of _two-player zero-sum_ games, the empirical strategy profiles converge to a min-max equilibrium of the game; Robinson's proof use a smart inductive argument on the number of strategies of the game. Later, Monderer and Shapley  established that in the case of \(N\)-player potential games, the empirical strategies also converge to a NE. Summing up, the following theorem is true:Informal Theorem,_In two-player zero-sum and \(N\)-player potential games, the empirical strategy profiles of fictitious play converge to a NE for any initialization and tie-breaking rule1_.

The above convergence results are asymptotic in the sense that they do not provide guarantees on the number of rounds needed by fictitious play to reach an approximate NE. Karlin  conjectured that in the case of two-player zero-sum games, fictitious play requires \(O(1/^{2})\) rounds to reach an \(\)-approximate NE. Daskalakis et. al.  disproved the strong version of Karlin's conjecture by providing an adversarial tie-breaking rule for which fictitious play requires exponential number of rounds (with respect to the number of strategies) in order to converge to an \(\)-approximate NE. On the other hand, for the case of potential games and despite the foundational work of Monderer et al. , no lower bound results have been established. Therefore, the central focus of our work is to address the following question."

_Q: Does fictitious play in potential games admit convergence to an approximate NE with rates that depend polynomially on the number of actions and the desired accuracy?_

Our contributionsOur work provides a negative answer on the above question. Specifically, we present a _two-player potential_ game for which fictitious play requires super-exponential time with respect to the number of actions to reach an approximate NE.

**Theorem 1.1** (Main result, formally stated Theorem 3.1).: _There exists a two-player potential game (more specifically both agents have identical payoffs) in which both agents admit \(n\) actions and for which fictitious play requires \((4^{n}((-2)!)^{4}+})\) rounds in order to reach an \(\)-approximate NE. Moreover, the result holds for any tie-breaking rule and uniformly random initialization._

**Remark 1.2**.: Daskalakis et al.  provide an exponential lower bound on the convergence of fictitious play assuming an adversarial tie-breaking rule, meaning that ties are broken in favor of slowing down the convergence rate. To this point, it is not known whether fictitious play with a consistent tie-breaking rule (e.g. lexicographic) converges in polynomial time or not, except for special cases, e.g., diagonal payoff matrices . We would like to note that our lower bound construction holds for any tie-breaking rule. The latter indicates an interesting discrepancy between two-player zero-sum and two-player potential games.

Related WorkThe work of Daskalakis et al.  provides a lower bound on the convergence rate of fictitious play for the case of two-player zero-sum games using an adversarial tie-breaking rule and is the most closely related to our. Another important work is , in which they demonstrate that when the tie-breaking rule is predetermined (e.g., using lexicographical tie-breaking), the convergence rate of fictitious play becomes polynomial in the number of strategies, specifically with a rate of \(O(})\), as Karlin's conjecture states. It is important to note that this result holds true only for diagonal matrices.

Other works include the examination of fictitious play convergence for near-potential games , and the investigation of the necessary conditions that games must meet for fictitious play to converge to a NE . We note that neither of these works provide convergence rates for fictitious play. On the other hand, fast convergence rates of _continuous time_ fictitious play for _regular_, as introduced by Harsanyi , potential games are established . Additional works on continuous-time fictitious play can be found in , and references there in.

Fictitious play has found various application in Multi-agent Reinforcement Learning as well (see  and  for a survey and references therein), extensive form games , and control theory . It possesses not only an intuitive game theoretic interpretation but also other attractive properties, such as its simplicity with no need for a step-size parameter. These traits have contributed to its status as a pivotal topic of study, leading to numerous works aiming to establish convergence in broader settings .2

Technical overviewThe technical overview of this paper provides a high-level roadmap of the key contributions. In Section 3, we outline the steps towards proving Theorem 3.1 by recursively constructing a payoff matrix of carefully crafted structural properties. In that matrix, starting from the lower-left element, the sequence of successive increments form a spiraling trajectory that converge towards the element of maximum value. We demonstrate that fictitious play has to follow the same trajectory, passing through all non-zero elements, to reach the unique pure Nash equilibrium, as illustrated in Figure 2. A crucial component of the proof is provided by an induction argument that _emulates_ the movement of fictitious play and provides a super-exponential lower bound on the number of rounds needed.

## 2 Preliminaries

### Notation and Definitions

NotationLet \(\) be the set of real numbers, and \([n]=\{1,2,,n\}\) be the set of actions. We define \(_{n}\) as the probability simplex, which is the set of \(n\)-dimensional probability vectors, i.e., \(_{n}\{x^{n}:x_{i} 0,_{i=1}^{n}x_{i}=1\}\). We use \(e_{i}\) to denote the \(i\)-th elementary vector, and to refer to a coordinate of a vector, we use either \(x_{i}\) or \([x]_{i}\). The superscripts are used to indicate the time at which a vector is referring to.

Normal-form GamesIn a _two-player normal-form_ game we are given a pair of payoff matrices \(A^{n m}\) and \(B^{n m}\) where \(n\) and \(m\) are the respective pure strategies of the _row_ and the _column_ player. If the row player selects strategy \(i[n]\), and the column player selects strategy \(j[m]\), then their respective payoffs are \(A_{ij}\) for the row player and \(B_{ij}\) for the column player.

The agents can use randomization. A _mixed strategy_ for the row player is a probability distribution \(x_{n}\) over the \(n\) rows, and a _mixed strategy_ for the column player is a probability distribution \(y_{m}\) over the \(m\) columns. After the row player selects mixed strategy \(x_{n}\), and the column player selects mixed strategy \(y_{m}\), their expected payoffs are \(x^{}Ay\) and \(x^{}By\), respectively.

Potential GamesA two-player potential game is a class of games that admit a unique function \(\), referred to as a potential function, which captures the incentive of all players to modify their strategies. In other words, if a player deviates from their strategy, then the difference in payoffs is determined by a potential function \(\) evaluated at those two strategy profiles. We can express this formally as follows:

**Definition 2.1** (Two-player Potential Game).: For any given pair of strategies \((x,y)\) and a pair of unilateral deviations \(x^{}\) by the row player and \(y^{}\) by the column player, the difference in their utility is equivalent to the difference in the potential function.

\[(x^{})^{}Ay-x^{}Ay=(x^{},y)-(x,y)  x^{}A(y^{})-x^{}Ay=(x,y^{})-(x,y)\]

**Remark 2.2**.: We note \(\) is a function that characterizes the equilibria of the game as the strategy profiles that maximize the potential function.

In this work, we focus on a specific type of potential games called _identical payoff games_, where both players receive the same payoff.

**Definition 2.3** (Identical Payoff Games).: A two-player normal-form game \((A,B)\) is called _identical payoff_ if and only if \(A=B\).

In this scenario, it is apparent that the potential function is given by \((x,y)=x^{}Ay\). Finally we provide the definition of an approximate NE.

**Definition 2.4** (\(\)-Nash Equilibrium).: A strategy profile \((x^{},y^{})_{n}_{m}\) is called an \(\)-approximate NE if and only if

\[(x^{})^{}Ay^{} x^{}Ay^{}-\;\; x _{n}(x^{})^{}By^{}(x^{})^{ }By-\;\; y_{m}\]

In words, an approximate Nash equilibrium is a strategy profile in which no player can improve their payoff significantly by unilaterally changing their strategy, but the strategy profile may not necessarily satisfy the precise definition of a Nash equilibrium.

**Remark 2.5**.: We highlight two special cases of the \(\)-NE. Firstly, when \(\) is equal to zero, it is referred to as an _exact Nash equilibrium_. Secondly, when the support of strategies is of size 1, it is called a _pure Nash equilibrium_. It is worth noting that potential games always admit a pure NE.

### Fictitious Play

Fictitious play is a natural uncoupled game dynamics at which each agent chooses a _best response_ to their opponent's empirical mixed strategy. Since there might be several best response actions at a given round, fictitious play might contain different sequences of play; see Definition 2.6.

**Definition 2.6** (Fictitious Play).: An infinite sequence of pure strategy profiles \((i^{(1)},j^{(1)}),,(i^{(t)},j^{(t)}),\) is called a fictitious play sequence if and only if at each round \(t 2\),

\[i^{(t)}*{argmax}_{i[n]}_{s=1}^{t-1}A_{ij^{(s)}}  j^{(t)}*{argmax}_{j[m]}_{s=1}^{t-1}B_{ i^{(s)}j}\] (1)

The empirical strategy profile of row and column player at time \(T\) is defined as \(^{(T)}=(_{s=1}^{T}e_{i^{(s)}})\) and \(^{(T)}=(_{s=1}^{T}e_{j^{(s)}})\) where \(e_{i^{(t)}},e_{j^{(t)}}\) are the elementary basis vectors.

**Definition 2.7** (Cumulative utility vector).: For an infinite sequence of pure strategy profiles \((i^{(1)},j^{(1)}),,(i^{(t)},j^{(t)}),\), the _cumulative utility_ vectors of the row and column player at round \(t 1\) are defined as,

\[R^{(t)}=_{s=1}^{t-1}Ae_{j^{(s)}} C^{(t)}=_{s=1}^{t -1}e_{i^{(s)}}^{}B.\]

**Remark 2.8**.: Fictitious play assumes that each agent selects at each round \(t[T]\) a strategy with _maximum cumulative utility_. The latter decision-making algorithm is also known as _Follow the Leader_. We remark that the latter alternative interpretation provides a direct generalization of fictitious play in \(N\)-player games.

In their seminal work, Monderer et al. established that in case of identical payoff games the empirical strategies of any fictitious play sequence converges asymptotically to a NE.

**Theorem 2.9** ().: _Let a fictitious play sequence \((i^{(1)},j^{(1)}),,(i^{(t)},j^{(t)}),\) for an identical payoff game described with matrix \(A\). Then, there exists a round \(T^{} 1\) such that for any \(t T^{}\), the empirical strategy profile \((^{(t)},^{(t)})\) converges to a NE with a rate of \(1/t\)._

On the positive side, Theorem 2.9 establishes that _any fictitious play sequence_ converges to a Nash equilibrium in the case of potential games * On the negative side, Theorem 2.9 does not provide any convergence rates, since the round \(T^{}\) depends on the specific fictitious play sequence and its dependence on the number of strategies is rather unclear.

Footnote *: For the sake of exposition, we have stated Theorem 2.9 only for the case of _identical payoff games_. However, we remark that the same theorem holds for general \(N\)-player potential games.

## 3 Main Result

In this section, we outline the steps towards proving Theorem 3.1, as it is stated below. Firstly, we introduce a carefully constructed payoff matrix \(A\) of size \(n n\) and analyze its structural properties in Section 3.1. Next, in Section 3.2, we investigate the behavior of fictitious play when the game is an two-player identical payoff game with this matrix \(A\). We also present a set of key statements that are necessary for proving the main theorem. Finally, in Section 3.3, we provide a proof for the fundamental Lemma 3.8.

**Theorem 3.1**.: _Let an identical payoff game defined with the matrix \(A\) of size \(n n\) and consider any fictitious play sequence \((i^{(1)},j^{(1)}),,(i^{(t)},j^{(t)}),\) with \((i^{(1)},j^{(1)})=(n,1)\). In case the empirical strategy profile \((^{(T)},^{(T)})\) is an \(\)-approximate Nash equilibrium then it holds_

\[T(4^{n}((n/2-2)!)^{4}+}).\]

_Moreover, the lower bound on \(T\) is independent of the tie-breaking rule. Finally, if the initialization is chosen uniformly at random, then the expected number of rounds to reach an \(\)-approximate Nash equilibrium is \((((n/2-2)!)^{4}+1/n}{n^{2}})\)._\[K^{n}(z)=(z+2)&0&&0&(z+3)\\ 0&&0&\\ &K^{n-2}(z+4)&0\\ 0&&(z+4)\\ (z+1)&0&&0&0 K^{6}(0)=2&0&0&0&0&3\\ 0&6&0&0&7&0\\ 0&0&10&11&0&0\\ 0&0&9&0&8&0\\ 0&5&0&0&0&4\\ 1&0&0&0&0&0\] (a) Recursive construction of \[A\]. (b) An example for \[z=0\] and \[n=6\].

### Construction and Analysis of the Payoff Matrix \(A\)

We begin by introducing our recursive construction for the payoff matrix, which we use to establish the formal statement of Theorem 3.1.

**Definition 3.2**.: For any \(z>0\) and \(n\) even, consider the following \(n n\) matrix \(K^{n}(z)\).

1. For \(n=2\), \(K^{n}(z)=z+2&z+3\\ z+1&0\).
2. For \(n 4\), * \(K^{n}_{n1}(z)=z+1\) and \(K^{n}_{nj}(z)=0\) for \(j\{1\}\). _Row_\(n\)
3. * \(K^{n}_{n1}(z)=z+1,K^{n}_{11}(z)=z+2\) and \(K^{n}_{1j}(z)=0\) for any \(j\{1,n\}\). _Column_\(1\)
4. * \(K^{n}_{11}(z)=z+2\), \(K^{n}_{1n}(z)=z+3\) and \(K^{n}_{1j}(z)=0\) for \(j\{1,n\}\). _Row_\(1\)
5. * For all \(i,j\{2,,n-1\}\{2,,n-1\}\), \(K^{n}_{ij}(z):=K^{n-2}_{i-1j-1}(z+4)\).

In Figures 0(a) and 0(b), we provide a schematic representation of Definition 3.2 and an illustrative example for \(n=6\) and \(z=0\). For the sake of simplicity, we have intentionally omitted the remaining zeros in the outer rows, and columns of the matrix.

The construction of the payoff matrix exhibits an interesting circular pattern, which begins at the lower left corner and extends along the outer layer of the matrix. More specifically, the first increment occurs in the same column as the starting point, i.e., at position \((1,1)\) on the first row. The pattern then proceeds to the next greater element on the same row but a different column, i.e., at position \((1,n)\), and the last increment before entering the inner sub-matrix is located on the same column but on the \((n-1)\)-th row.

Sequence of increments: \[(n,1)(1,1)(1,n)(n-1,n)_{K^{n-2}(z+4)}\]

The increments have been carefully selected to ensure that there are alternating changes in row and column when starting from the lower-left corner and following the successive increments, until reaching the sub-matrix in the center. Once inside the sub-matrix, a similar pattern continues. As we will explore later on, the structure of the payoff dictates the behavior of fictitious play. We denote the payoff matrix under consideration as \(A\), which is defined as \(A K_{n}(0)\). The subsequent statements establish the key properties of \(A\).

**Observation 3.3** (Structural Properties of matrix \(A\)).: Let the matrix \(A=K^{n}(0)\), then for \(i\{0,,-1\}\) the following hold:

* The only elements with non-zero values in column \(i+1\) are located at positions \(i+1\) and \(n-i\), and have values \(4i+2\) and \(4i+1\), respectively.
* The only non-zero elements of row \(i+1\) are located at positions \(i+1\) and \(n-i\), and have values \(4i+2\) and \(4i+3\), respectively.
* The only non-zero elements of column \(n-i\) are located at positions \(i+1\) and \(n-i-1\) and have values \(4i+3\) and \(4i+4\), respectively.

* The only non-zero elements of row \(n-i\) are located at positions \(i+1\) and \(n-i+1\), and have values \(4i+1\) and \(4i\), respectively.

**Observation 3.4**.: The maximum value of \(A\) is \(2n-2\) and is located at the entry \((,+1)\).

**Proposition 3.5**.: _For any non-zero element in the matrix \(A\), there is at most one non-zero element that is greater and at most one non-zero element that is smaller in the same column or row._

Proof.: By Observation 3.3, each row and column of matrix \(A\) contains at most two non-zero elements that are necessarily different to each other. Thus, if \((i,j)\) is a non-zero element of \(A\), there can be at most two additional non-zero elements in row \(i\) and column \(j\) combined. Moreover, at most one of these elements can be greater and at most one can be smaller. 

One of the central components of the main theorem is presented below. Lemma 3.6 establishes that in an identical payoff game with matrix \(A\), any approximate Nash equilibrium must distribute the majority of its probability mass to the maximum element in \(A\), which is located at the entry \((,+1)\). The proof of this theorem is based solely on the structural properties presented in Observation 3.3, and is provided in the Appendix.

**Lemma 3.6** (Unique \(^{2}\)-Ne).: _Let \( O(})\) and consider an \(^{2}\)-approximate Nash Equilibrium \((x^{*},y^{*})\). Then the following hold,_

\[x^{*}_{} 1-n y^{*}_{+1 } 1-n\]

Lemma 3.6 not only establishes that the only approximate Nash equilibrium of the identical-payoff game with matrix \(A\) corresponds to the strategies \((,+1)\), but it also implies that this is the only exact Nash equilibrium (i.e., \(=0\)). This observation follows from Observation 3.4, which states that the entry \((,+1)\) corresponds to a maximum value of \(A\) and hence it is a Nash equilibrium as it dominates both the row and the column that it belongs to. We can formally state this observation as follows.

**Corollary 3.7** (Unique pure NE).: _In an identical-payoff game with payoff matrix \(A\), there exists a unique pure Nash equilibrium at \((,+1)\)._

### Lower Bound for Fictitious Play in a Game with Matrix \(A\)

In this subsection, we present the proof of Theorem 3.1. To achieve this, we first prove that fictitious play requires super-exponential time before placing a positive amount of mass in entry \((,+1)\). This result is established by our main technical contribution of the subsection, which is Lemma 3.8.

**Lemma 3.8**.: _Let an identical-payoff game with payoff matrix \(A\) and a fictitious play sequence \((i^{(1)},j^{(1)}),,(i^{(t)},j^{(t)}),\) with \((i^{(1)},j^{(1)})=(n,1)\). Then, for all \(=\{0,,-1\}\) there exists a round \(T_{} 1\) such that:_

1. _the agents play the strategies_ \((n-,+1)\) _for the first time,_
2. _all rows_ \(r[+1,n--1]\) _admit_ \(0\) _cumulative utility,_ \(R^{(T_{})}_{r}=0\)_,_
3. _all columns_ \(c[+2,n-]\) _admit_ \(0\) _cumulative utility,_ \(C^{(T_{})}_{c}=0\)_._

_Moreover for \( 2\), the cumulative utility of row \(n-\) at round \(T_{}\) is greater than_

\[R^{(T_{})}_{n-} 4(4-1)(4-2)(4-3) R^{(T_{ -1})}_{n-}\;\;\;\;R^{(T_{1})}_{n-1} 4.\] (2)

Using Lemma 3.8 we are able to establish that for a very long period of time the row player has never played row \(\) and that the column player has never played column \(+1\).

**Lemma 3.9** (Exponential Lower Bound).: _Let an identical-payoff game with matrix \(A\) and a fictitious play sequence \((i^{(1)},j^{(1)}),,(i^{(t)},j^{(t)}),\) with \((i^{(1)},j^{(1)})=(n,1)\). In case \((i^{(T)},j^{(T)})=(,+1)\) then \(T(4^{n}((n/2-2)!)^{4})\)._Proof.: Based on Lemma 3.8, we can guarantee the existence of a round \(T^{}:=T_{n/2-1}\) when the players choose the strategy profile \((+1,)\) for the first time. In addition, at round \(T^{}\), it holds that \(R_{n/2-1}^{(T^{})}>0\) and \(C_{n/2+1}^{(T^{})}=R_{n/2}^{(T^{})}=0\). The latter condition ensures that the strategy profile \((,+1)\) has not been played up to time \(T^{}\).

As indicated by Observation 3.3, row \(\) has non-zero entries at columns \(\) and \(+1\). Therefore, if the cumulative utilities \(R_{n/2}^{(T^{})}\) at time \(T^{}\) is zero, this implies that neither of these columns has been chosen up to that point. By the same reasoning, column \(+1\) has a non-zero entry only at row \(\), indicating that this row has not been chosen as well.

In order to continue, we require an estimate of the duration during which the strategy profile \((+1,)\) will be played. Observation 3.3 guarantees that the utility vector of the row player is the following.

\[Ae_{}=(0,,0,_{},_{+1},0,,0)\] (3)

We can combine this information with the fact that \(R_{n/2+1}^{(T^{})} 0\), \(R_{n/2}^{(T^{})}=0\), and that the respective entries in the payoff vector (3) of the row player differ by exactly one. This allows us to conclude that it will take at least \(R_{+1}^{(T^{})}\) iterations for the cumulative utilities to become equal, i.e \(R_{+1}=R_{}\). Therefore, the lower bound on the number of iterations holds regardless of the tie-breaking rule.

Now, if at any time \(T\) the agents play the strategy profile \((i^{(T)},j^{(T)})=(,+1)\), we can conclude that \(T R_{+1}^{(T^{})}\). Using Equation (2) of Lemma 3.8 we obtain:

\[T R_{-1}^{(T^{})} 16^{-1}(_{=2 }^{-1}(-1))^{4}R_{n-1}^{(T_{1})}(4^{n} ((-2)!)^{4})\]

Now that we have established the necessary technical result in Lemma 3.9, we are ready to present the proof of Theorem 3.1.

Proof of Theorem 3.1.: Let \(T^{} 1\) denote the first time at which \((i^{(t)},j^{(t)})=(,+1)\). For any \(t T^{}-1\), it holds that \(_{}^{(t)}=_{+1}^{(t)}=0\). Thus, Lemma 3.6 implies that \((^{(t)},^{(t)})\) is not an approximate NE. On the other hand, at each round \(t T^{}\) we are ensured that \(_{}^{(t)},_{+1}^{(t)}\) converges to \(1\) with rate \(1/t\). Applying Lemma 3.6 for \(-\) we get that if \((^{(t)},^{(t)})\) is an \(\)-NE then \(t T^{}+}(4^{n}((n/2-2)!)^{4} )+}\). It is evident that, even with a uniformly random initialization, the probability of selecting \((n,1)\) as the starting point for fictitious play is \(1/n^{2}\) and so the claim of the theorem follows.

Figure 2: This figure shows the spiral trajectory generated by the fictitious play dynamic in a game with matrix \(A\). The starting point is the lower-left element, and as the dynamic progresses, it visits all non-zero elements in ascending order of value.

### Strategy Switches and Proof of Lemma 3.8

This subsection is dedicated to presenting the proof of Lemma 3.8. However, before delving into the proof, we first provide additional statements that serve to shed light on the sequence of strategy profiles generated by fictitious play.

According to Proposition 3.5, if the strategy \((i,j)\) is chosen by fictitious play, then either in row \(i\) or in column \(j\), there is at most one element greater than \(A_{ij}\). Therefore, in a subsequent round, fictitious play will necessarily choose this element as its strategy. Let \(i^{}\) be the row where the element of greater value is located. Intuitively, we can imagine that as fictitious play continues to play the same strategy \((i,j)\), the payoff vector \(Ae_{j}\) is repeatedly added to the cumulative vector of the row player. Since this vector has a greater value at coordinate \(i^{}\) than at coordinate \(i\), a strategy switch will eventually occur. We state this observation in Proposition 3.10 and defer the proof to the Appendix.

**Proposition 3.10** (Strategy Switch).: _Let \((i^{(t)},j^{(t)})\) be a strategy selected by fictitious play at round \(t\), and \((i^{(t)},j^{(t)})(,)\). Then, in a subsequent round, fictitious play will choose the strategy of greater value that is either on row \(i^{(t)}\) or column \(j^{(t)}\)._

As previously hinted, the structure of the payoff matrix dictates the sequence of strategy profiles chosen by fictitious play. The sequence of strategy switches alternates between rows and columns. Continuing with the example from the previous paragraph, let us assume that the row player made the most recent strategy switch from \((i,j)\) to \((i^{},j)\). This implies that the element \(A_{i^{}j}\) is greater than \(A_{ij}\), as otherwise a strategy switch would not have taken place, as established in Proposition 3.10. Moreover, by Proposition 3.5, we know that there must be an element of greater value in either row \(i^{}\) or column \(j\). Since \(A_{i^{}j}\) is greater than \(A_{ij}\), any element of greater value must be located in row \(i^{}\). The same reasoning applies for the case where the column player was the last to switch strategies. We can summarize this observation by stating that if one player is the last to switch, then the other player must switch next. We formally state this in Corollary 3.11 and defer the proof to the Appendix.

**Corollary 3.11** (Successive Strategy Switches).: _Let \(t\) be a round in which a player changes their strategy. Then exactly one of the following statements is true:_

1. _If the row player changes their strategy at round_ \(t\)_, i.e._ \(i^{(t)} i^{(t-1)}\)_, then the column player can only make the next strategy switch._
2. _If the column player changes their strategy at round_ \(t\)_, i.e._ \(j^{(t)} j^{(t-1)}\)_, then the row player can only make the next strategy switch._

Applying the same concept, we can observe that starting from the lower-left corner, fictitious play follows a spiral trajectory. The resulting spiral is illustrated in Figure 2. We now proceed with the main result of this section, Lemma 3.8.

Proof.: Since \((i^{(1)},j^{(1)})=(n,1)\) all the above claims trivially for \(T_{0}=1\). We assume that the claim holds for \(i\) and will now establish it inductively for \(i+1\).

By the induction hypothesis, agents play strategies \((n-i,i+1)\) at round \(T_{i}^{0}:=T_{i}\). Furthermore, row \(n-i\) admits cumulative utility of \(R_{n-i}^{(T_{i}^{0})}\) while row \(i+1\) admits cumulative utility of \(R_{j+1}^{(T_{i}^{0})}=0\). According to Observation 3.3, the payoff vectors of the row and column agent are highlighted in Figure 2(a). By combining these facts, we can establish the following.

Figure 3: The figure illustrates the active row and column player for each time period, with the played strategy highlighted in purple and the corresponding payoff vectors of the row and column player highlighted in green. Additionally, the time period of each played strategy is indicated for clarity.

**Proposition 3.12** (Abridged; Full Version in Proposition B.3).: _There exists a round \(T_{i}^{1}>T_{i}^{0}\) at which the strategy profile is \((i+1,i+1)\) for the first time, column \(i+1\) admits cumulative utility \(C_{i+1}^{(T_{i}^{1})}(4i+1)(R_{i+1}^{(T_{i}^{0})}+1)\), and \(C_{n-i}^{(T_{i}^{1})}=0\)._

By Proposition 3.12, at round \(T_{i}^{1}\), the agents play strategies \((i+1,i+1)\). Furthermore, the cumulative utility of column \(n-i\) equals to \(C_{n-i}^{(T_{i}^{1})}=0\). According to Observation 3.3, the payoff vectors of the row and column agent are highlighted Figure 2(b). Combining these facts, we get the following:

**Proposition 3.13** (Abridged; Full Version in Proposition B.4).: _There exists a round \(T_{i}^{2}>T_{i}^{1}\) at which the strategy profile is \((i+1,n-i)\) for the first time, row \(i+1\) admits cumulative utility \(R_{i+1}^{(T_{i}^{2})}(4i+2) C_{i+1}^{(T_{i}^{1})}\), and \(R_{n-i-1}^{(T_{i}^{2})}=0\)._

By Proposition 3.13, at round \(T_{i}^{2}\), the agents play strategies \((i+1,n-i)\). Furthermore, the cumulative utility of row \(n-i-1\) equals to \(R_{n-i-1}^{(T_{i}^{2})}=0\). According to Observation 3.3, the payoff vectors of the row and column agent are highlighted Figure 2(c). By combining these facts, we get the following:

**Proposition 3.14** (Abridged; Full Version in Proposition B.5).: _There exists a round \(T_{i}^{3}>T_{i}^{2}\) at which the strategy profile is \((n-(i+1),n-i)\) for the first time, \(R_{i+2}^{(T_{i}^{3})}=0\)._

By Proposition 3.14, at round \(T_{i}^{3}\), the agents play strategies \((n-i-1,n-i)\). the cumulative of column \(i+2\) equals to \(R_{i+2}^{(T_{i}^{3})}=0\). According to Observation 3.3, the payoff vectors of the row and column agent are highlighted Figure 2(d). By combining these facts, we can establish the following.

**Proposition 3.15** (Abridged; Full Version in Proposition B.6).: _There exists a round \(T_{i}^{4}>T_{i}^{3}\) at which the strategy profile is \((n-(i+1),(i+1)+1)\) for the first time, row \(n-i-1\) admits cumulative utility \(R_{n-(i+1)}^{(T_{i}^{4})}(4i+4) C_{n-i}^{(T_{i}^{3})}\), all rows \(k[(i+1)+1,n-(i+1)-1]\) admit \(R_{k}^{(T_{i}^{4})}=0\) and all columns \(k[(i+1)+2,n-(i+1)]\) admit \(C_{k}^{(T_{i}^{4})}=0\)._

Proposition 3.15 establishes that there exits a round \(T_{i+1} T_{i}^{4}\) at which the strategy profile \((n-(i+1),(i+1)+1)\) is played for the first time. Furthermore, Proposition 3.15 confirms that all rows \(k\{(i+1)+1,n-(i+1)-1\}\) admit \(R_{k}^{(T_{i+1}^{i})}=0\) and all columns \(k\{(i+1)+2,n-(i+1)\}\) admit \(C_{k}^{(T_{i+1}^{i})}=0\). We still need to verify the the recursive relation Equation (2). By combining Proposition 3.12, 3.13, 3.14 and 3.15, we can deduce

\[R_{n-i-1}^{(T_{i+1}^{i+1})}(4i+4)(4i+3)(4i+2)(4i+1)R_{n-i}^{(T_{i})}.\]

## 4 Experiments

In this section, we aim to experimentally validate our findings on a \(4 4\) payoff matrix. Our analysis focuses on three key aspects: the round in which a new strategy switch occurs, the Nash gap throughout the game, and the empirical strategy employed by the \(x\) player. We present the plot from the row player's perspective, which is identical to that of the column player.

In Figure 3(a), we provide the time steps of all strategy switches. As it is expected from the analysis, fictitious play _visits_ all strategies, specifically in increasing order of their utility, to reach the pure Nash equilibrium. Moreover, in Figure 3(b) we observe a recurring pattern in the Nash gap diagram, where the gap increases after the selection of a new strategy with a higher utility and decreases until the next strategy switch. However, this pattern stops after the pure Nash equilibrium is reached, which is the unique approximate Nash equilibrium in accordance with Lemma 3.8.

## 5 Conclusion

In summary, this paper has provided a thorough examination of the convergence rate of fictitious play within a specific subset of potential games. Our research has yielded a recursive rule for constructing payoff matrices, demonstrating that fictitious play, regardless of the tie-breaking rule employed, may require super exponential time to reach a Nash equilibrium even in two-player identical payoff games. This contribution to the literature differs from previous studies and sheds new light on the limitations of fictitious play in the particular class of potential games.

**Limitations and Broader Impacts:** Our work is theoretical in nature, and we do not identify any limitations or negative ethical or societal implications.