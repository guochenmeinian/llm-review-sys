# PCoTTA: Continual Test-Time Adaptation for Multi-Task Point Cloud Understanding

Jincen Jiang

Bournemouth University

jiangj@bournemouth.ac.uk

&Qianyu Zhou1

Shanghai Jiao Tong University

zhouqianyu@sjtu.edu.cn

&Yuhang Li

Shanghai University

yuhangli@shu.edu.cn

&Xinkui Zhao

Zhejiang University

zhaoxinkui@zju.edu.cn

&Meili Wang

Northwest A&F University

wml@nwsuaf.edu.cn

&Lizhuang Ma

Shanghai Jiao Tong University

lzma@sjtu.edu.cn

Equal contributions.Corresponding authors.

Jian Chang

Bournemouth University

jchang@bournemouth.ac.uk

&Jian Jun Zhang

Bournemouth University

jzhang@bournemouth.ac.uk

&Xuequan Lu

La Trobe University

b.lu@latrobe.edu.au

###### Abstract

In this paper, we present PCoTTA, an innovative, pioneering framework for Continual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding, enhancing the model's transferability towards the continually changing target domain. We introduce a multi-task setting for PCoTTA, which is practical and realistic, handling multiple tasks within one unified model during the continual adaptation. Our PCoTTA involves three key components: automatic prototype mixture (APM), Gaussian Splatted feature shifting (GSFS), and contrastive prototype repulsion (CPR). Firstly, APM is designed to automatically mix the source prototypes with the learnable prototypes with a similarity balancing factor, avoiding catastrophic forgetting. Then, GSFS dynamically shifts the testing sample toward the source domain, mitigating error accumulation in an online manner. In addition, CPR is proposed to pull the nearest learnable prototype close to the testing feature and push it away from other prototypes, making each prototype distinguishable during the adaptation. Experimental comparisons lead to a new benchmark, demonstrating PCoTTA's superiority in boosting the model's transferability towards the continually changing target domain. _Our source code is available at_: [https://github.com/Jinec98/PCoTTA](https://github.com/Jinec98/PCoTTA).

## 1 Introduction

Recent advancements in 3D point cloud understanding have marked a significant leap in the field of computer vision  and 3D processing . Current methods  primarily concentrate on training and testing on a single domain . Nevertheless, they encounter noticeable performance drops on other target data. Different datasets have domain gaps, also known as domain shifts. For instance, models trained on meticulously structured synthetic data, such as ModelNet40 , may encounter difficulties in adapting to intricate and noisy real-world data, such as ScanObjectNN .

To mitigate domain shifts, recent researchers have introduced Unsupervised Domain Adaptation (UDA) techniques  into point cloud understanding. Some studies synthesize diverse training data , and others leverage adversarial learning , pseudo labeling , consistency learning , feature disentanglement  or self-supervised learning  to align the latent features across different domains. Nonetheless, these methods still face challenges especially when the target domain is streaming online and the whole training set of the target domain is inaccessible. As such, Test-Time Adaptation is introduced into point cloud  where the model can adapt to target distributions in an online manner at test-time without requiring any prior knowledge of the whole target domain. However, these methods may still fail when the target domain is continually changing, referred to as Continual Test-Time Adaptation (CoTTA), and such an open problem is rarely explored in point cloud understanding contexts.

On the one hand, due to the lack of specific designs for 3D data, current CoTTA methods  that are designed for 2D images are inapplicable to 3D point cloud tasks or exhibit less desired performance. On the other hand, few works like MM-CCTA  target the CoTTA problem in 3D point cloud tasks. Although MM-CTTA  designs a Continual Cross-Modal Adaptive Clustering (CoMAC) approach for 3D semantic segmentation, it suffers from two primary limitations: (1) it is specifically designed for one task only, and cannot handle other point cloud tasks such as point cloud reconstruction, denoising, and registration. Redesigning and retraining a CoTTA method for each task is cost-expensive. (2) The adapted model would inevitably forget the previously learned data (catastrophic forgetting) and accumulate the model errors (error accumulation) during the continual adaptation, limiting the model's transferability toward the target domains.

Motivated by the above analysis, we present PCoTTA, an innovative, pioneering framework for Continual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding, enhancing the model's transferability towards the continually changing target domain. Also, we introduce a multi-task setting for PCoTTA, which is practical and realistic, handling multiple tasks within one unified model during the adaptation. In particular, given an off-the-shelf model pre-trained on the source domains, our PCoTTA aims to bridge the gap between the source and continually changing target domains by dynamically scheduling the shifting amplitude at test time.

Our PCoTTA mainly consists of three novel modules. Firstly, to prevent catastrophic forgetting, we propose an automatic prototype mixture (APM) strategy that automatically mixes the source prototypes with the learnable target prototypes based on the automatic similarity balancing factor (ASBF), which avoids straying too far from its original source model. Secondly, to mitigate error accumulation, we present Gaussian Splated feature shifting (GSFS) that dynamically shifts the testing sample toward the source domain based on the distance between the testing features and the shared prototype bank. In addition, we also introduce Gaussian weighted graph attention to further adaptively schedule the shifting amplitude in a learnable manner at test time. Our insight is to highlight the similarity between the target sample and its similar prototypes and suppress the dissimilar weights. It therefore mitigates the risk of catastrophic forgetting. Finally, we devise the contrastive prototype repulsion (CPR) to pull the nearest learnable prototype close to the testing feature and push it away from other prototypes, making learnable prototypes more distinguishable. Furthermore,

Figure 1: (a) Previous UDA approaches on point cloud suffer from catastrophic forgetting and error accumulation toward the continually changing target domains. (b) In contrast, we present an innovative framework PCoTTA to address these issues, enhancing the modelâ€™s transferability.

we present a new benchmark. We meticulously select a total of \(30,954\) point cloud samples from \(4\) datasets, including \(2\) synthetic datasets (ModelNet40  and ShapeNet ) and \(2\) real-world datasets (ScanNet  and ScanObjectNN ), encompassing \(7\) same object categories, and generate corresponding ground truth for \(3\) different tasks (reconstruction, denoising, and registration). Our main contributions are three-fold:

* We present PCoTTA, an innovative, pioneering, and unified framework for Continual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding, enhancing the model's transferability towards the continually changing target domain. We introduce a multi-task setting with a new benchmark for PCoTTA, which is practical and realistic in the real world.
* We devise three innovative modules for PCoTTA, _i.e.,_ automatic prototype mixture (APM), Gaussian Splatted feature shifting (GSFS), and contrastive prototype repulsion (CPR) strategies, where APM avoids straying too far from its original source model, mitigating the risk of catastrophic forgetting, and GSFS dynamically shifts the testing sample toward the source model, alleviating error accumulation, and CPR pulls the nearest learnable prototype close to the testing feature and pushes it away from other prototypes.
* Extensive experimental results with analysis demonstrate the effectiveness and superiority of our presented method, surpassing the state-of-the-art approaches by a large margin.

## 2 Related Work

**Point Cloud Understanding.** Pioneering works such as PointNet  and PointNet++  process point clouds directly, with PointNet  utilizing pooling operations for spatial encodings and PointNet++  employing hierarchical processing for capturing local structures at various scales. DGCNN  updates the graph in feature space to capture dynamic local semantic features, while PCT  addresses global context and dependencies within point clouds using order-invariant attention mechanisms. Recent methods like Point-BERT  and Point-MAE  have introduced Masked Point Modeling (MPM) for reconstructing obscured point clouds. Point-BERT  employs a BERT-style pre-training strategy for improving performance in subsequent tasks, while Point-MAE  uses masked autoencoders for self-supervised learning, enabling comprehensive representations without labeled data. PIC  explores the In-Context Learning (ICL) paradigm to enhance 3D point cloud understanding, showcasing the model's potential in multi-task learning. Despite their gratifying progress, they only consider a single data domain and suffer from performance degradation in target domains. Thus, we study continual test-time adaptation for point cloud tasks.

**Continual Test-Time Adaptation.** This task aims to adapt the pre-trained model toward the continually changing environments at test time. CoTTA  employs a weighted augmentation-averaged mean teacher framework to address this issue.  capitalizes on the temporal correlations within streamed input data through reservoir sampling and instance-aware batch normalization.  introduce domain-specific prompts and domain-agnostic prompts to preserve both domain-specific and domain-shared knowledge, respectively. Meanwhile, EATA  focuses on adapting non-redundant samples to facilitate efficient updates. Another work RMT  uses a mean teacher setup with symmetric cross-entropy and contrastive learning. More recently, MM-CTTA  designs a Continual Cross-Modal Adaptive Clustering (CoMAC) approach for 3D semantic segmentation. Despite these methods showing promising potential in 3D data, they mainly suffer from two limitations: Firstly, they are specifically designed for one task only, and they cannot handle other point cloud tasks like those in PIC . Secondly, the model would inevitably forget the previously learned knowledge (catastrophic forgetting) and accumulate prediction errors (error accumulation) during the continual adaptation, leading to undesirable results. In contrast, we present a unified model, PCoTTA, for continual test-time adaptation of multi-task point cloud understanding.

## 3 Method

We present a novel framework, namely PCoTTA, for Continual Test-Time Adaptation in point cloud understanding tasks with the practical multi-task and multi-domain setting. As depicted in Figure 2, we propose an innovative approach to effectively address the challenges of continuously changing target data in test time within a unified model. In particular, our PCoTTA consists of three novel components: Automatic Prototype Mixture (APM) to mitigate catastrophic forgetting, Gaussian Splated Feature Shifting (GSFS) to alleviate error accumulation, and Contrastive Prototype Repulsion (CPR) to make learnable prototypes distinctive across continually changing target domains.

### Point Cloud Continual Test-Time Adaptation

**Problem Formulation.** In this work, we study a practical setting of continual test-time adaptation for multi-task point cloud understanding. Suppose we have \(R\) source domains \(D_{s}=\{D_{s}^{1},D_{s}^{2},,D_{s}^{R}\}\), our PCoTTA employs the input point clouds \(\{I_{q},I_{p}\}\) (along with their targets \(\{T_{q}^{k},T_{p}^{k}\}\), where \(k\) represents the task index) from two different sources \(\{D_{s}^{i},D_{s}^{j}\} D_{s},(i j)\) to form the context pairs, facilitating the model with a comprehensive representation that effectively generalizes across all source domains. In the pre-training phase, each input sample comprises two context pairs: the input point cloud pair (query and prompt) and their corresponding target pair addressing the same task. During the test time, our PCoTTA strives to align streamed target data \(I_{t} D_{t}\) (where \(D_{t}=\{D_{t}^{1} D_{t}^{2}\}\) denotes the set of continuously varying target domains) towards sources that possess correlative features to the off-the-shelf pre-trained model.

**Multi-task Learning Objective.** We follow PIC  for three point cloud understanding tasks: (1) Reconstruction, which focuses on generating a dense point cloud from the sparse input; (2) Denoising, aiming at eliminating noise or outliers from the input point cloud; (3) Registration, dedicated to restoring the original orientation of a randomly rotated point cloud. Please note these three tasks might be slightly different from conventional definitions. They are used as they can be handled similarly given current point learning can predict point positions directly. This makes them 'unified' with position output and a single loss. We employ the MPM framework to generate query results across multiple downstream tasks, with a unified objective and a unified model. Let \(()\) denote the model shared across all domains and all tasks, and predicted masked patches \(P\) can be depicted as:

\[\{I_{q},I_{p}\} P=((I_{q})(T_{q}^{k}) (I_{p})(T_{p}^{k}),), \]

where \(()\) represents the feature encoder that produces patch-wise features, _i.e.,_ the tokens, from point cloud feature, and \(\) denotes the masked token utilized to replace the masked patches in the inputs. During the pre-training stage, \(\) is derived from the random masking among query and prompt point clouds; whereas at test time, \(\) exclusively masks the query target to generate the

Figure 2: Our PCoTTA. It addresses continually changing targets by using their nearest source sample as a prompt for multi-task learning within a unified model. We introduce Gaussian Splatted Feature Shifting (GSFS) to align unknown targets with sources, improving transferability. Source prototypes from different domains and learnable prototypes form a prototype bank. The Automatic Prototype Mixture (APM) pairs these prototypes based on the similarity to the target, preventing catastrophic forgetting. We project these prototypes as Gaussian distributions onto the feature plane, with larger weights assigned to more relevant ones. Our graph attention updates these weights dynamically to mitigate error accumulation. Additionally, our Contrastive Prototype Repulsion (CPR) ensures that learnable prototypes are distinguishable for different targets, enhancing adaptability.

task-specific query output. The Chamfer Distance (CD) is used as the loss, measuring the similarity between the predicted masked patch \(P\) and its corresponding ground truth \(G\):

\[_{cd}=_{x P}_{y G}\|x-y\|_{2}^{2}+_{y G}_{x P}\|y-x\|_{2}^{2}. \]

### Automatic Prototype Mixture

The empirical evidence perceived by the human visual system illustrates that when people are not certain about the identity of an object, they would seek to find a distinct object from other domains that share high semantic similarity with the current object in the target domain. Motivated by this, we propose Automatic Prototype Mixture (APM) that adapts to continuously changing target data by aligning it with model-familiarized prototypes of source domains at test time.

**Source Prototypes Estimation.** Our insight lies in that source prototypes can potentially represent source domains' feature distribution. Pulling the target data toward source prototypes within the feature space can effectively narrow the domain gap, bolstering the model's transferability. Accordingly, the source prototypes \(Z_{s}^{i}(i[1,R])\) can be determined by computing the average of all tokens produced by the MPM framework across all data within the sources:

\[Z_{s}^{i}=^{i}}}_{n=1}^{N_{D_{s}^{i}}}(I_{n}),  Z_{s}^{R K M C}, \]

where \(N_{D_{s}^{i}}\) denotes the sample number in domain \(D_{s}^{i}\), \(K\) represents the tasks number, and \(M\) indicates the tokens number in each sample. After pre-training on the multi-task and multi-domain setting, we save all source prototypes \(Z_{s}\) derived from the model at the last epoch, considering them as the shared common knowledge available to the target data during the test time.

**Prototype Bank.** We propose a novel prototype bank that stores not only the source prototypes \(Z_{s}\) but also a series of _learnable prototypes_\(Z_{l}^{S K M C}\), where \(S\) indicates the number of all potential target domains \(D_{t}\). The learnable prototypes \(Z_{l}\) aim to extract the current domain knowledge, thereby paving the way for handling subsequent unknown test data. We achieve the test-time adaptation of target tokens through the mixture of the paired prototypes in the prototype bank, selectively updating only the learnable prototypes while maintaining the source ones, thus mitigating the risk of catastrophic forgetting of the source domain knowledge due to the over-reliance on the adaptively learned information.

**Prototype-pair Node Mixture.** The source prototypes \(Z_{s}\) along with the learnable prototypes \(Z_{l}\) in the prototype bank are paired to form prototype-pair nodes. As illustrated in Figure 3(a), the tokens from each test data \((I_{t})\) serve as the central node in a graph structure, adjacent to all prototype-pair nodes. We propose the Automatic Prototype Mixture (APM) module, designed to merge source and

Figure 3: (a) Automatic Prototype Mixture (APM) considers both source and learnable prototypes with their similarities to the target, mitigating catastrophic forgetting by preserving source information. (b) Gaussian Spalitted-based Graph Attention enables dynamic updating weights among all prototype-pair nodes based on the Gaussian projections splatted onto the feature plane.

learnable prototypes within each node by considering their token-wise feature distances with the test data, _i.e.,_ the dot product between two feature vectors.

Firstly, we need to repeat the test data tokens \((I_{t})\) to align with the total number of prototypes:

\[(I_{t})=[(I_{t})\ (I_{t}) (I_{t})}_{\ x\ }], \]

where \(x\) equals \(R\) or \(S\). Then, the similarity \(_{s}\) between source prototypes \(Z_{s}\) and the test data \(I_{t}\) is:

\[_{s}= Diag(Norm(Z_{s}) Norm((I_{t})^{ T}))^{R K}, \]

where \(Diag()\) indicates creating a diagonal matrix, \(Norm()\) denotes normalization along the last dimension (_i.e.,_ the feature channel), and \(()^{T}\) represents transposition specifically applied to the last two dimensions. Likewise, the similarity \(_{l}^{S K}\) between the test data and the learnable prototypes can also be determined.

We further propose the Automatic Similarity Balancing Factor (ASBF) to measure the impact of the source and learnable prototypes toward the test data through the similarities \(_{s}\) and \(_{l}\), automatically prioritizing the prototypes and assigning greater weight to more similar components. The mixed prototypes (_i.e.,_ the prototype-pair nodes) \(Z_{m}\) can be defined as:

\[Z_{m}=(Z_{s},Z_{l})=_{s}}{_{s}+ _{l}} Z_{s}+_{l}}{_{s}+_{l}} Z_{l}^{R S K}. \]

APM effectively considers the two types of prototypes while ensuring that the engagement with the original pre-trained model and source prototype is maintained, preventing catastrophic forgetting.

### Gaussian Splatted Feature Shifting

Our PCoTTA considers all nodes but applies dynamically updated weights to each edge, enabling distinguishing the feature shifting in the continual test-time adaptation. To this end, we propose the Gaussian Splatted Feature Shifting (GSFS), preventing error accumulation in an online manner.

**Gaussian Splatted-based Graph Attention.** Our key insight is that prototypes within a node (_i.e.,_ the source-learnable prototypes pair) can mutually constrain each other and collaboratively determine the weight of the edge connected to this node. We interpret the similarities between the test data and these two types of prototypes as Gaussian projections onto a plane, with the source and learnable prototypes corresponding to two orthogonal axes, respectively. As illustrated in Figure 3(b), the projections of all nodes on the feature plane are treated as a blend of Gaussians, where nodes with stronger correlations to the test data (_i.e.,_ higher similarities) are assigned larger weights. In this manner, all prototype-pair nodes are seamlessly integrated into the feature adaptation process. We compute the attention coefficient of each node as follows:

\[(_{s},_{l})=-(_{ s},_{l})=-_{s}}_{ _{l}}}e^{-(_{s}-_{_{s}})^{2}}{_{_{s}}^{2}}+_{l}-_{ _{l}})^{2}}{_{_{l}}^{2}})}, \]

where \(_{_{s}},_{_{l}}\) represent the variances of \(_{s}\) and \(_{l}\), respectively, and \(_{_{s}},_{_{l}}\) denote their mean values. Note that the Gaussian function is inversely correlated with the similarity. We introduce a parameter \(\), set slightly above the maximum similarity observed, to ensure that more similar prototypes have a stronger influence.

**Attention-based Feature Shifting.** The attention coefficient \(^{i,j}\) reflects the relative importance of the source \(Z_{s}^{i}\) and the learned \(Z_{l}^{j}\) prototypes. To ensure comparability across all connected nodes, we normalize coefficients using the Softmax function. Furthermore, we adopt a learnable shared attention module to dynamically update edge weights as follows:

\[_{i,j}=_{}(Softmax(^{i,j}))=_{}( ^{i,j}}}{_{m=1}^{N_{Z_{m}}}e^{^{i,m}}}), \]

where \(_{}\) denotes a series of Convolution Layers parameterized by \(\), and \(N_{Z_{m}}\) indicates the total number of the mixed prototypes (equals \(R S\)), indexed by \(m\). Thereby, we can merge all prototype-pair nodes with the central node, _i.e.,_ the test data features, using the adaptive edge weights:

\[^{}(I_{t})=_{i,j=0}^{R,S}((1-_{i,j})(I_{t})+_{i,j} Z_{m}^{i,j}). \]The proposed GSFS dynamically updates the contribution from each node in the graph with Gaussian Splatted-based graph attention, effectively assigning distinctive weights of feature shifting according to each node's relevance to the test data. This enables the test data to effectively align with task-beneficial domains, significantly diminishing the potential for error accumulation in the model.

### Contrastive Prototype Repulsion

The learnable prototypes within the prototype bank strive to capture the domain-specific knowledge of the current test data. Instead of predicting domain pseudo-labels to all test data, a common practice in prior techniques [45; 13], our method pulls the most similar learnable prototype closer to the test data while pushing it away from the others, thereby implicitly learning the distinctive features from different samples. To this end, we introduce Contrastive Prototype Repulsion (CPR) that effectively refines the learnable prototypes in the prototype bank, ensuring their distinctiveness and preventing domain-flattening from iterative learning and settling at sub-optimal points. We form a positive pair between the test data \(^{}(I_{t})\) and their nearest learnable prototype \(Z_{l}^{t}\), and the rest serve as negative pairs. Our CPR optimization objective can be expressed as:

\[_{pr}=-_{Z_{l} S}(^{ }(I_{t}) Z_{l}^{t}/}}{e^{^{}(I_{t}) Z_{l} ^{t}/}+_{k t}e^{^{}(I_{t}) Z_{l}^{k}/}} ), \]

where \(\) is the temperature parameter, set to \(0.07\) by default. Therefore, the overall loss function of our PCoTTA in the test time adaptation can be defined as follows:

\[=_{cd}+_{pr}, \]

where \(\) is the weighting factor that balances the two loss terms.

## 4 Experiments

### Experimental Setting

**Implementation Details.** We implement our method using PyTorch and perform experiments on two NVIDIA A40 GPUs. Following PIC , we set the training batch size to \(128\) and utilize the AdamW optimizer . The learning rate is set to \(0.001\), with a cosine learning scheduler and a weight decay of \(0.05\). All models are trained for \(300\) epochs during the pertaining stage, and we train the pre-trained model for \(3\) epochs on the source domains to initialize our prototype bank. At testing time, we continuously adapt test samples to the source pre-trained model and validate the anti-forgetting capability of our method across multiple rounds. Each point cloud is sampled to \(1,024\) points and then split into \(64\) patches, with each patch consisting of \(32\) points. Within the MPM framework, the mask ratio is set to \(0.7\), consistent with prior studies [57; 33].

**New Benchmark.** We meticulously curate and select data from \(4\) distinct datasets (\(2\) synthetic and \(2\) real-world datasets), containing \(7\) identical object categories. Subsequently, we generate corresponding ground truth based on \(3\) different tasks. The synthetic datasets include ModelNet40  and ShapeNet . ModelNet40 consists of \(3,713\) samples for training and \(686\) for testing, while ShapeNet comprises \(15,001\) training samples and \(2,145\) testing samples. We also consider real-world data: ScanNet  and ScanObjectNN . ScanNet provides annotations for individual objects in real 3D scans, and we choose \(5,763\) samples for training and \(1,677\) for testing. ScanObjectNN includes \(1,577\) training samples and \(392\) testing samples. In all experiments, we employ ScanNet  and ShapeNet  as the source domains and evaluate the transferability of our method on the other two target domains, _i.e.,_ ModelNet40  and ScanObjectNN  with 3 repeated times by default.

### Main Results

Table 1 shows the comparison results of our PCoTTA against other methods across tasks of reconstruction, denoising, and registration in the introduced setting. Our method consistently outperforms others by a large margin, demonstrating superior adaptability in a multi-domain multi-task setting. Conventional methods such as PointNet , DGCNN , and PCT  often struggle with unseen data, leading to significant performance drops. Augmentation-based methods like Pointmixup  and PointCutMix , though adapted for multi-domain learning, exhibit limited performance in

[MISSING_PAGE_FAIL:8]

during aggregation, and meanwhile, our attention mechanism in GSFS also enables dynamic updating of these weights, offering greater weights to prototypes closer to the current sample. Finally, adding CPR (Ours) enables the prototype bank's learnable prototypes to be more distinct, achieving the best performance. These improvements confirm that these individual components are complementary and together they significantly promote the performance.

**Quantity of Learnable Prototypes.** We conducted an additional ablation study on the number of learnable prototypes, as shown in Table 3, and the results indicate marginal changes. Additionally, we show the case with no learnable prototypes (_i.e.,_ quantity 0), where our method degrades to aligning the target feature by solely considering source prototypes' similarities. While this case achieves some degree of test-time adaptation, its performance is less decent than our PCoTTA.

**Cross Validation.** Table 4 shows our model's effectiveness in bridging the domain gap from the synthetic to real scan data. Consistently, our method surpasses CoTTA  in all tasks, demonstrating the superiority of our method. Remarkably, our model also performs better than CoTTA  when pre-trained on the two real scan datasets which involve background interference and missing parts. This underscores our method's strong transferability between various domains.

**Efficiency Analysis.** We present an analysis of model parameters and running time in Table 5. The results show that our method achieves fast inference on target data, and our model has the fewest parameters compared to other CITA methods. As such, this shows potential for many real-world applications, _e.g.,_ autonomous driving and virtual reality, since our PCoTTA is an end-to-end test-time adaptation method without relying on a teacher-student model or pseudo-labeling technique, it is more efficient and suitable for real-time deployment.

### Visualization and Analysis

**Visualization of Different Tasks.** Figure 4 illustrates the qualitative results in the last round of our PCoTTA model. From the figure, we have two observations. Firstly, our proposed PCoTTA manages to generate quality predictions in the continually changing target domain by leveraging the proposed distinctive prototype bank, minimizing the discrepancies between source and target domains. Secondly, without retraining a CoTTA method for each task, our proposed PCoTTA is able to successfully handle multiple tasks such as point cloud reconstruction, denoising, and registration and multiple domains with a unified model, demonstrating strong practicability and transferability in the real world. We provide more visual comparisons with state-of-the-art methods in Appendix A.4.

**T-SNE Feature Visualization.** To understand how our PCoTTA aligns the domains, we visualize the feature distributions of the source and target domains via t-SNE. We display the latent features of the point cloud reconstruction task in Figure 5. From the figure, we make the following observations: The baseline model means directly deploying the source pre-trained model in the continually changing domains, resulting in an unsatisfactory alignment. Although CoTTA  aligns the source and

{l|c c target domains to some extent, there still exists some cases of miss-alignment or over-alignment. For example, some samples are either not aligned with the cluster or over-clustered. In contrast, our PCoTTA achieves a better and more even feature alignment across domains, demonstrating its superiority in narrowing domain shifts in continually changing environments.

## 5 Conclusion

In this paper, we present an innovative, pioneering, and unified framework, namely PCoTTA for Continual Test-Time Adaptation in multi-task point cloud understanding, boosting the model's transferability towards the continually changing target domains. Our approach effectively mitigates catastrophic forgetting and error accumulation issues through the three novel modules: automatic prototype mixture (APM), Gaussian Splated feature shifting (GSFS), and contrastive prototype repulsion (CPR). These three components make our model more adaptable and robust across continually changing domains by aligning the targets towards all source domains. Furthermore, we present a new benchmark in terms of the practical Continual Test-Time Adaptation for multi-task point cloud understanding. Comprehensive experiments show our PCoTTA's superior performance, proving its efficacy in significantly improving the model's transferability across various domains. We believe our work will inspire a new direction and interesting ideas in the community, in terms of Continual Test-Time Adaptation for multi-task point cloud understanding.

Figure 4: Visualization of our PCoTTAâ€™s prediction and their ground truths under \(3\) different tasks.

Figure 5: T-SNE visualization of the source and target features.