# Decomposable Transformer Point Processes

Aristeidis Panos

University of Cambridge

ap2313@cam.ac.uk

###### Abstract

The standard paradigm of modeling marked point processes is by parameterizing the intensity function using an attention-based (Transformer-style) architecture. Despite the flexibility of these methods, their inference is based on the computationally intensive thinning algorithm. In this work, we propose a framework where the advantages of the attention-based architecture are maintained and the limitation of the thinning algorithm is circumvented. The framework depends on modeling the conditional distribution of inter-event times with a mixture of log-normals satisfying a Markov property and the conditional probability mass function for the marks with a Transformer-based architecture. The proposed method attains state-of-the-art performance in predicting the next event of a sequence given its history. The experiments also reveal the efficacy of the methods that do not rely on the thinning algorithm during inference over the ones they do. Finally, we test our method on the challenging long-horizon prediction task and find that it outperforms a baseline developed specifically for tackling this task; importantly, inference requires just a fraction of time compared to the thinning-based baseline.

## 1 Introduction

Continuous-time event sequences are commonly found in real-world scenarios and applications such as financial transactions , communication in a social network , and purchases in e-Commerce systems . This abundance of data for discrete events occuring at irregular intervals has lead to an increasing interest of the community in the last decade to marked temporal point processes which are the standard way of modeling this kind of data.

Historically, Hawkes processes  and Poisson processes  have been extensively applied to various domains such as finance , seismology , and astronomy . Despite their elegant mathematical framework and interpretability, the strong assumptions of the models reduce their flexibility and fail to capture the complex dynamics of real-world generating processes.

Advances in deep learning have allowed the incorporation of neural models like LSTMs  or recurrent neural networks (RNN) into temporal point processes . As a result, these models are able to learn more complex dependencies and attain superior performance than Hawkes/Poisson processes. Recently, the introduction of the (self-) attention mechanism  to modeling temporal point processes  has led to new state-of-the-art methods with extra flexibility.

Despite the advantages of these neural-based models, their dependence on modeling the conditional intensity function creates limitations for both training and inference . Training usually requires a Monte Carlo approximation of an integral that appears in the log-likelihood.  proposed a method to circumvent this approximation; however, the main shortcomings remained as discussed in . More importantly, inference is based on the thinning algorithm  which is computationally intensive and sensitive to the choice of intensity function. To deal with these downsides,  parameterized the conditional distribution of the inter-event times by combining a log-normal mixture density networkwith an RNN. The model's performance is comparable to that of the other intensity-based methods which use RNN/LSTM architecture but still inferior to the Transformer-based methods.

A more recent work  has referred to the decomposition of the log-likelihood of a marked point process  to parameterize the distribution of marks given the time and history and the distribution of times given the history. This decomposition, as with , eliminates the need for the thinning algorithm and additional approximations, while offering a rigorous, yet flexible framework for defining different distributions for occurrence times and marks.  used two different parametric models for each distribution, and their results for the time prediction task, despite the simplicity of their framework, were competitive or superior to neural-based baselines.

Inspired by the state-of-the-art performance of the Transformer-based architectures and the computational efficiency/flexibility of the intensity-free models, we develop a model for marked point processes that combines the advantages of these two methodologies. Our contributions are summarized below:

* We propose a novel model that is defined by two distributions: a distribution for the marks based on a Transformer architecture and a simple log-normal mixture model for the inter-event times which satisfies a simple Markov property.
* Through an extensive experimental study, we show the efficiency of our model in the next-event prediction task and the suitability of the intensity-free models for correctly predicting the next occurrence time over the methods relied on the thinning algorithm.
* To the best of our knowledge, we are the first to experimentally show the limitations of the thinning algorithm on the predictive ability of the neural point processes.
* We test our model on the more challenging long-horizon prediction task and we provide strong evidence that we can achieve better results in a fraction of time compared to models that have been specifically designed to solve this task and, uncoincidentally, depend on the thinning algorithm.

## 2 Background

A marked temporal point process (MTPP), observed in the interval \((0,T)\), is a stochastic process whose realizations are sequences of discrete events occurring at times \(0<t_{1}<<t_{N}<T\) with corresponding event types (or marks) \(k_{1},,k_{N}\), where \(k_{i}\{1,,K\}\). The entire sequence is denoted by \(_{T}=\{(t_{1},k_{1}),,(t_{N},k_{N})\}\). The process is fully specified by the conditional intensity function (CIF) of the event of type \(k\) at time \(t\) conditioned on the event history \(_{t_{i}}=\{(t_{j},k_{j}) t_{j}<t_{i}\}\), \(_{k}^{*}(t):=_{k}(t_{t_{i}}) 0,t>t_{i}\); we use the asterisk \(*\) to denote the dependence on \(_{t_{i}}\). The CIF is used to compute the infinitesimal probability of event \(k\) occurring at time \(t\), i.e. \(_{k}^{*}(t)dt=(t_{i+1}[t,t+dt],k_{i+1}=k t_{i+1} (t_{i},t),_{t_{i}})\). The log-likelihood of such an autoregressive multivariate point process is given by [14; 22]

\[(_{T})=_{i=1}^{N}_{k_{i}}^{*}(t_{i})-_{k =1}^{K}_{0}^{T}_{k}^{*}(t)\;dt.\] (1)

Modeling the intensity function by a flexible model and then learning its parameters by maximizing Eq. (1) has been the standard approach of many works [5; 12; 24; 26; 29; 35; 38; 41; 42; 44].

An equivalent way of deriving the log-likelihood in (1) without the use of \(_{k}^{*}(t)\) is by following the decomposition of a multivariate distribution function in  (expression 2), expressed as

\[(_{T})=_{i=1}^{N}\{ p^{*}(k_{i} t_{i}) + f^{*}(t_{i})\}+(1-F(T_{t_{N}})),\] (2)

where \(p^{*}(k t_{i}):=p(k t_{i},_{t_{i}})\)1 and \(f^{*}(t):=f(t_{t_{i}})\) are the conditional probability mass function (CPMF) of the event types and the conditional probability density function (CPDF) for the occurrence times, respectively. \(F(t_{t_{i}})=_{t_{i}}^{t}f^{*}(t)dt\;, t>t_{i}\) is the cumulative distribution function of \(f^{*}(t)\). The last term in (2) is the logarithm of the survival function that expressesthe probability that no event occurs in the interval \((t_{N},T)\). The relation between \(_{k}^{*}(t)\) and the density/PMF is given by \(_{k}^{*}(t)=(t)p^{*}(k|t)}{1-F(t|_{t})}\); see Section 2.4 in .

We can represent the temporal part of the process in terms of the inter-event times \(_{i}:=t_{i}-t_{i-1}_{+},t_{0}=0\); the two representations are isomorphic and the relation between the conditional PDF of the inter-event time \(_{i}\) until the next event and the conditional intensity function is given by \(g^{*}(_{i}):=g^{*}(_{i}_{t_{i}})=_{k=1}^{K}_ {k}^{*}(t_{i-1}+_{i})(-_{k=1}^{K}_{0}^{_{i}}_{ k}^{*}(t_{i-1}+x)dx)=f^{*}(t_{i})\).

## 3 Decomposable Transformer Point Processes

To develop our proposed framework _Decomposable Transformer Point Process (DTPP)_, we adopt the decomposition in (2) and model \(g^{*}()\) and \(p^{*}(k t)\), separately. Despite the advantages of modeling the intensity function and the arguments in favor of this , we believe that modeling the probability density/mass function offers not only the same benefits as modeling the intensity function as discussed in , but, more importantly, it allows us not to depend on the thinning algorithm during inference. The technical details of each model are described in the next two sections.

### Distribution of Marks

The conditional distribution of the event types is parameterized by a continuous-time Transformer architecture as the one described in . More specifically, for any pair of events \((t,k)\), we evaluate an embedding \(_{k}(t)^{D}\) based on the history \(_{t}\). Assuming an \(L\)-layer architecture, \(_{k}(t)\) is given by the concatenation of the embedding of each individual layer, i.e. \(_{k}(t)=[_{k}^{(0)}(t);_{k}^{(1)}(t);; _{k}^{(L)}(t)]\). The embedding of the base layer \(_{k}^{(0)}(t)\) is independent of time and it is learned by a simple weight vector for each mark, i.e. \(_{k}^{(0)}(t):=_{k}^{(0)}^{D^{(0)}}\). The embedding of layer \(\{1,,L\}\) for \((t,k)\) is defined as

\[_{k}^{()}(t):=_{k}^{(-1)}(t)+ (_{(t_{i},k_{i})_{t}}_{k_{i}}^{()} (t_{i})\,_{k_{i}}^{()}(t_{i};t,k)}{1+C})^{D^{(t)}},\] (3)

where \(C>0\) is the normalization constant given by \(C=_{(t_{i},k_{i})_{t}}_{k_{i}}^{()}(t_{i},t,k)\) and the unnormalized attention weight is

\[_{k_{i}}^{()}(t_{i};t,k)=(} _{k_{i}}^{()}(t_{i})^{}_{k}^{()}(t))>0.\] (4)

The operation of the non-linear activation function \(\) is element-wise and \(D=_{=0}^{L}D^{()}\). The query, key, and value vectors \(_{k}^{()}(t),_{k}^{()}(t)\), and \(_{k}^{()}(t)\), respectively, can be computed by using the embedding of the previous layer and the corresponding weight matrices \(Q^{()},K^{()}^{D(D+D^{(-1)})},V^{()} ^{D^{()}(D+D^{(-1)})}\) as follows,

\[_{k}^{()}(t)=Q^{()}X_{t}^{},\ \ _{k}^{()}(t)=K^{()}X_{t}^{ },\ \ _{k}^{()}(t)=V^{()}X_{t}^{},\] (5)

where \(X_{t}^{}=[(t);_{k}^{(-1)}(t)] ^{D+D^{(-1)}}\). By \((t)^{D}\), we denote a temporal embedding of time defined as

\[[(t)]_{d}=\{(t/10^{ }),\ \ \\ (t/10^{}),\ \ .\] (6)

where \(d=0,,D-1\). This encoding is the same as in  with small differences than the one used in  where we found empirically the former to work slightly better than the latter. For a more detailed discussion regarding the architecture of the model and how it compares to previous Transformer-based methods, see Appendix A in . Finally, we note that for extra model flexibility, multi-head self-attention can be easily obtained by the three equations in (5).

Having computed the top-layer embeddings \(_{k}(t)\) for all \(k=1,,K\), we model the conditional PMF \(p^{*}(k t)\) as

\[p^{*}(k t)=_{k}^{}_{k}(t))}{ _{l=1}^{K}(_{l}^{}_{l}(t))},\] (7)

where \(_{k}\) are the learnable classifier weights. As is typical for these architectures, to avoid any data leakage from future events, we mask all future events \((t_{i},k_{i})\) where \(t<t_{i}\) and only use previous events for computing these embeddings.

### Distribution of Inter-Event Times

For the modeling of the inter-event times, since they always take positive values, we choose a mixture of log-normal distributions whose parameters depend on the value of the previously seen mark. Specifically, given that the previous occurred mark is \(k\), the PDF2 of the next inter-event time \(\) is defined as

\[g^{*}()=g( k)=_{m=1}^{M}w_{m}^{(k)}^{(k)} }(-(^{(k)}}{s_{m}^{ (k)}})^{2}),\] (8)

where \(\{w_{m}^{(k)}\}_{m=1}^{M}^{M}\) are the mixture weights, \(\{_{m}^{(k)}\}_{m=1}^{M}^{M}\) are the mixture means, and \(\{s_{m}^{(k)}\}_{m=1}^{M}^{M}_{+}\) are the standard deviations, for any \(k=1,,K\). The log-normal mixture has several desirable features that justifies our choice: (i) it efficiently approximates distributions in low dimensions such as 1-d distributions of inter-event times [23; 35] while satisfying a universal approximation property that provides theoretical guarantees regarding its approximation ability , (ii) closed-form moments are available and can be used for predicting the next time; for instance, the mean of the distribution is given as the weighted average of each of the log-normal means, i.e.

\[_{g}^{(k)}[]=_{m=1}^{M}w_{m}^{(k)}(_{m}^{(k)}+ ^{(k)})^{2}}{2}),\] (9)

(iii) learning the small number of parameters \(\{w_{m}^{(k)},_{m}^{(k)},s_{m}^{(k)}\}_{m=1}^{M}\) can be done in a fraction of time using fast off-the-shelf implementations based on the EM algorithm . Finally, note that the dependence of the model only on the most recent mark implies a Markov property since we do not need the entire history \(_{<t}\) to define our distribution.

At first glance, this assumption might seem restrictive when it comes to capturing the complex dynamics of the process. Nevertheless, this assumption holds only for \(g^{*}\) while \(p^{*}\) is modeled by the flexible Transformer architecture that models the full history up to the current time \(t\). Hence, we do not sacrifice any modeling power at all to achieve efficiency. On the contrary, we can maintain both modeling power and computational efficiency due to the decomposition in (2) and the chosen models in (8) and (7). Moreover, as our extensive experiments on the real-world data show, this assumption provides a robust predictive model which is less prone to overfitting compared to more flexible neural net architectures since the Markov property can act as a strong regularizer.

### Training and Prediction

The parameters \(\{w_{m}^{(k)},_{m}^{(k)},s_{m}^{(k)}\}_{m,k}\), of \(g^{*}()\) and the parameters \(\{_{k},_{k}^{(0)},Q^{()},K^{()},V^{()}\}_{,k}\) of \(p^{*}(k t)\) can be estimated by maximizing the log-likelihood in (2) using any stochastic gradient method. A crucial benefit of using the decomposition in (2) is that it permits us to learn the above parameters separately as follows:

\[\{w_{m}^{(k)^{*}},_{m}^{(k)^{*}},s_{m}^{(k)^{*}}\}_{m,k} =*{argmax}_{i=1}^{N} g^{*}(_{i})+ (1-G(T_{T}))\] (10) \[\{_{k}^{*},_{k}^{(0)^{*}},Q^{()^{*}},K^{ ()^{*}},V^{()^{*}}\}_{,k} =*{argmax}_{i=1}^{N} p^{*}(k_{i} t_{i}),\] (11)where \(G(T_{T})=_{0}^{T-t_{N}}g^{*}()d\). This is a major difference from previous work where the parameters of the neural net parameterizing the conditional intensity function had to be learned all at once. By dividing the main objective function into two sub-objectives, since there is no parameter-sharing between the two models, we can maximize the two objectives independently, and thus, having an easier optimization task than maximizing a single set of parameters of a given objective, such as (1).

The trained models \(g^{*}\) and \(p^{*}\) can now be used to predict either the time/type of the next event (next-event prediction) or the next \(P>1\) events (long-horizon prediction). For the next-event-prediction, the predicted time \(\) given the history \(_{t_{i}}\) is computed by using the mean of the appropriate mixture of log-normals while the corresponding predicted type of this event \(\) is evaluated based on \(_{t_{i}}\) and the true time \(t_{i+1}\), i.e.

\[=t_{i}+_{g}^{(k_{i})}[],\ \ \ \ \ =*{ argmax}_{k}p^{*}(k t_{i+1}).\] (12)

The above procedure is based on the minimum Bayes risk (MBR) principle  which aims to predict the time and type that minimizes the expected loss. This is an average \(L_{2}\) loss in the case of time prediction (deriving a root mean squared error) and an average 0-1 loss for the type prediction (deriving an error rate).

For the long-horizon prediction task [11; 40], we need to predict a sequence of events where, unlike the next-event prediction task, we do not have access to the true time when we predict the next event type. This could potentially lead to a cascading error effect due to the autoregressive nature of the models designed for the less challenging task of next-event prediction. This is because after an error is made in the sequence of the predictions, it cannot be corrected, and thus the error accumulates and affects all subsequent predictions. We argue that this pathology can be alleviated by using a model of times that provides accurate and robust predictions given the history. This assumption is verified experimentally in Section 5.2. To generate a predicted sequence, we require the trained models \(g()\) and \(p()\) to sequentially predict events as in (12). Since we have no access to the true time \(t_{i+1}\), we use as a proxy the prediction \(\) to predict \(\) in turn. After the prediction of the new event, we append it to the history and then we repeat the same step given the updated history until we generate a sequence of \(P\) events. The exact procedure is described in Algorithm 1 in the Appendix.

The main advantage of Algorithm 1 over other methods  that are based on the thinning algorithm is its computational efficiency. The algorithm is fully parallelizable, and it can produce single steps in parallel for a batch of event sequences. This is not possible for thinning-based methods that require one to consider single sequences each time . Consequently, our method is able to generate sequences orders of magnitude faster, which is verified by our experiments. Unlike other competitors  that are based on the thinning algorithm and therefore require random sampling, our algorithm is fully deterministic; for comparison the thinning algorithm is described in Algorithm 2 of the Appendix.

## 4 Related Work

The decomposition in (2) has been used in the past to provide both expressive and interpretable models [27; 30]. For instance,  model the mark distribution with a parametric model, inspired by the exponential intensity function of a Hawkes process and the time distribution with a single log-normal; however, they use the mode instead of the mean of the distribution for predicting the time of the next event. They learn the parameters of their models separately, as we describe in (10) and (11), but they use Variational Inference  to learn the parameters of \(p^{*}\). They attain competitive results in terms of next-time prediction, but the model lacks the flexibility of a Transformer-based architecture, as our experiments show.

 is another work that takes advantage of the mixture of log-normal distributions to model the distribution of the inter-event times. The model is based on an RNN architecture that produces a fixed-dimensional embedding of the event history, which is used to generate the parameters of the mixture model, and the same embedding is employed to define the CPMF of the marks. In our case, we use a Transformer architecture to obtain this history embedding, which is utilized by the CPMF, exclusively. Finally, the proposed model in  assumes that the marks are conditionally independent of the time given the history, which is not the case for our framework, as is evident in (2).

Finally, the CPMF of the marks for our DTPP model shares the same architecture as the Attentive Neural Hawkes Process (A-NHP) . Nevertheless, they use it to model the CIF while in our case we model \(p^{*}\).

## 5 Experiments

We considered two different tasks to assess the predictive performance of our proposed method: Goodness-of-fit/next-event prediction and long-horizon prediction. We compared our method DTPP to several strong baselines over five real-world datasets and three synthetic ones. Description and summary statistics for all datasets used in this section are given in Appendix A.1. For the competing methods, we used their published implementations; more details are given in A.3. Experimental details not available in this section can be found in Appendix A. Our framework was implemented with PyTorch  and scikit-learn ; the code is available at https://github.com/aresPanos/dtpp.

### Goodness-of-Fit / Next-Event Prediction

We evaluated our **DTPP** model to determine how well it generalizes and predicts the next event given the history on the held-out dataset. For comparison, we used five state-of-the-art baselines where the three of them model the CIF using Transformers, while the other two model the CPDF of inter-event times and the CPMF of marks (see Section 4). The CIF-based baselines are the **Transformer Hawkes Process (THP)**, the **Self-Attentive Hawkes Process (SAHP)**, and the **Attentive Neural Hawkes Process (A-NHP)**. The CPDF-based ones are the **Intensity-Free Temporal Point Process (IFTPP)**, and the **VI-Decoupled Point Process (VI-DPP)**.

We fit the above six models on a diverse collection of five popular real-world datasets, each with varied characteristics: **MIMIC-II**, **Amazon**, **Taxi**, **Taobao**, and **StackOverflow-V1**. Training details are given in Appendix A.2.

Goodness-of-Fit.Figure 1 shows the average log-likelihood for each model on the held-out data of the five real-world datasets. Our DTPP model consistently outperforms the simple parametric

Figure 1: Goodness-of-fit evaluation over the five real-world datasets. We compare our DTPP model against five strong baselines. Results (larger is better) are accompanied by 95% bootstrap confidence intervals.

VI-DPP, indicating the flexibility of using the self-attention mechanism to model the CPDF. Except Mimic-II, DTPP achieves the highest or the second highest log-likelihood across the remaining datasets. Therefore, the separate parameterization of \(p^{*}\) and \(g^{*}\) does not hurt performance compared to the models with a common set of learnable parameters. Finally, notice that DTPP outperforms all the CPDF-based methods on average, while the two CPDF-based methods that employ deep learning architectures, i.e., DTPP and IFTPP, exhibit better performance than the CIF-based baselines. A plausible explanation is that the log-likelihood computation for the CIF-based baselines requires Monte Carlo integration, which could cause approximation errors; for the CPDF-based methods, this computation is exact. A-NHP is the clear winner among the CIF-based methods, as also shown in .

Next-Event Prediction.We evaluate the predictive capacity of all models by predicting each event \((t_{i},k_{i})\) given its history \(_{t_{i}},i=2,,N\) on held-out data. Event time prediction is measured by root mean squared Error (RMSE) and event type prediction by error rate; Table 1 summarizes the results. DTPP outperforms all the baselines in both tasks. The wider performance gaps in RMSE between our model and the other baselines justify our choice of a inter-event distribution satisfying a Markov property; this result also implies that we do not need long event histories to capture the dynamics of these datasets. We also compare the average performance between CIF-based and CPDF-based (excluding VI-DPP) methods. We see that for the CIF-based baselines the average RMSE is 0.58 and the average error rate is 35.39% while for the CPDF-based ones we have 0.95 and 37.0%, respectively. These results support our argument that the thinning algorithm tends to harm the time prediction accuracy; they also highlight the efficiency of using a separate model for the inter-event times. Additional results on Mimic-II can be found in Appendix B.1.

Synthetic datasets.To extra investigate the capabilities of our model in a more controlled manner, we created a dataset by generating sequences from a randomly initialized SAHP model. Although, each event has strong dependence on its history, Figure 2 shows that our model approximates the true log-likelihood as well as A-NHP. Moreover, DTPP's mixture model is more accurate than the thinning-based A-NHP in time prediction. Moreover, we found that the only case that DTPP was significantly outperformed by A-NHP was on a synthetic dataset generated by a 1-d Hawkes process. Since no event types are present we only use a single mixture of log-normals which apparently is the wrong model for this data. The results are illustrated in Figure 4 of the Appendix.

### Long-Horizon Prediction

To test the performance of our model for this task, we followed the experimental setup of . From the same work, we used the proposed **HYPRO**, which is the state-of-the-art method for the long-horizon prediction task, to compare with DTPP. HYPRO is a globally normalized model that aims to address cascading errors that occur in auto-regressive and locally normalized models, such as the models in Section 5.1. HYPRO and DTPP are based on the same Transformer architecture of

    &  &  &  &  \\ 
**Methods** & **RMSE** & **Error** & **RMSE** & **Error** & **RMSE** & **Error** & **RMSE** & **Error** \\  THP\({}^{}\) & 0.62 \(\)0.03 & 65.06 \(\)1.04 & 0.37 \(\)0.02 & 8.55 \(\)0.65 & 0.13 \(\)0.02 & 41.43 \(\)0.78 & 1.32 \(\)0.03 & 53.86 \(\)0.76 \\ SAHP\({}^{}\) & 0.58 \(\)0.01 & 62.58 \(\)0.32 & 0.28 \(\)0.04 & 8.37 \(\)0.43 & 2.26 \(\)0.59 & 45.63 \(\)0.58 & 1.93 \(\)0.04 & 53.00 \(\)0.32 \\ A-NHP\({}^{}\) & 0.42 \(\)0.01 & 65.94 \(\)0.31 & 0.29 \(\)0.02 & 7.67 \(\)0.44 & 1.44 \(\)0.53 & 43.96 \(\)0.55 & 1.18 \(\)0.01 & 52.17 \(\)0.32 \\ IFTPP\({}^{}\) & 0.41 \(\)0.05 & 64.08 \(\)0.34 & 0.39 \(\)0.09 & 8.17 \(\)0.46 & 0.33 \(\)0.00 & 41.92 \(\)0.54 & 1.91 \(\)0.10 & 53.68 \(\)0.30 \\ VI-DPP\({}^{}\) & 0.38 \(\)0.00 & 65.49 \(\)0.34 & 0.11 \(\)0.02 & **9.49** \(\)0.42 & 0.07 \(\)0.00 & 41.89 \(\)0.57 & 1.68 \(\)0.04 & 55.06 \(\)0.32 \\ DTPP\({}^{}\) & **0.12** \(\)0.00 & **59.06** \(\)0.35 & **0.08** \(\)0.01 & **7.12** \(\)0.40 & **0.05** \(\)0.00 & **40.12** \(\)0.59 & **1.07** \(\)0.03 & **50.41** \(\)0.31 \\   

Table 1: Performance comparison between our model DTPP and various baselines in terms of next-event prediction. The root mean squared error (RMSE) measures the error of the predicted time of the next event, while the error rate (ERROR-\(\%\)) evaluates the error of the predicted mark given the true time. The results (lower is better) are accompanied by 95% bootstrap confidence intervals. \({}^{}\), \({}^{}\), denote the CIF-based methods, the CPDF-based methods that use a single model, and the ones using a seperate model, respectively.

A-NHP so the main difference is that HYPRO is a CIF-based method, and thus, it requires the thinning algorithm to sample sequences. For our experiments, we use the distance-based regularization variant of HYPRO with a Multi-NCE loss as this method attains the best results in . As DTPP and HYPRO share the same Transformer architecture, so we used the exact same hyperparameters for fair comparison. Note that even in this case, HYPRO has more than double number of parameters compared to DTPP since HYPRO requires an extra Transformer to model the energy function used for global normalization. More details on HYPRO training and hyperparameters can be found in the Appendix A.

We used three of the previous real-world datasets for evaluation because of their long sequences. These are **Taxi**, **Taobao**, and **StackOverflow-V2**. For each dataset, our goal is to predict the last 20 events in a sequence, denoted by \(_{P}\), given the history; that is, \(P=20\) in Algorithm 1. As is typical for the long-horizon prediction, the standard scores used for evaluating the model's performance are the The optimal transport distance (**OTD**)  and the long-horizon RMSE (**RMSE\({}^{*}\)**) .

In Figure 3, we see that our DTPP method outperforms HYPRO across all datasets in terms of average OTD and RMSE. HYPRO achieves a lower RMSE score only in StackOverflow. These results provide corroborating evidence on our argument that the thinning algorithm might negatively affect the performance of a neural point process even in the case of globally normalized models as HYPRO. It is also evident that a locally normalized CPDF-based model such as DTPP is much more robust against the cascading error which CIF-based methods are vulnerable . We believe that this robustness stems from the accurate predictions of the log-normal mixture model.

Apart from the predictive performance, we investigated the time required for the two methods to generate all the predicted sequences of the held-out dataset. Since HYPRO's inference time is heavily relied on the thinning algorithm and a hyperparameter that indicates the number of proposal sequences (denoted as \(M\) in ), we conducted an ablation study for a varied number of proposals to investigate the inference time and performance of HYPRO against DTPP. For HYPRO's inference time, apart from the prediction time, we included the time required to generate the noise sequences so the energy function can be trained on. The inclusion of this time is justified by the importance the energy function has as a component of the framework, and it can be seen as a necessary pre-inference

Figure 3: Performance comparison over the three real-world datasets measured by RMSE\({}^{*}\) and average OTD (lower is better). The reported results for HYPRO are based on 16 weighted samples, i.e. \(M=16\) for Algorithm 2 in .

Figure 2: Performance comparison between DTPP and A-NHP over the SAHP-Synthetic dataset.

step. However, for completeness, we compute only the prediction time of HYPRO and report it in Table 6 of the Appendix.

The results are presented in Table 2 where we measure the performance using the average OTD; a similar table for RMSE\({}^{*}\) is in Appendix B.3. We see that our parallelizable framework takes advantage of modern GPU hardware and performs inference in a few seconds. Instead, the thinning algorithm constitutes HYPRO extremely slow and impractical for inference on large datasets. In some cases like the Taxi dataset, HYPRO needs \(8,130\) more time than DTPP to perform inference. Moreover, DTPP attains better performance across all datasets even for a larger number of proposals in HYPRO. These results verify our assumption about the robustness of the mixture model to predict accurately the next time; they also highlight the inaccurate predictions and computational burden of the thinning algorithm.

## 6 Discussion

We have presented DTPP, a Transformer-based probabilistic model for continuous-time event sequences. The model has been derived using the decomposability of the likelihood of a MTPP in terms of its CPDF and CPMF. We have used a mixture of log-normals and a Transformer architecture to model CPDF and CPMF, respectively. Our model satisfies some desirable properties compared to previous works that tried to model the CIF such as closed-form computation of the log-likelihood and inference without resorting to the thinning algorithm. Extensive experiments on the standard task of next-event prediction showed that our method outperformed all state-of-the-art autoregressive models, The results also reveal a more robust performance of the methods that do not require the thinning algorithm to generate event sequences over those they do. Finally, we have tested our model on the challenging task of long-horizon prediction of event sequences. Although our model has not been designed for this task, it outperformed the state-of-the-art baseline HYPRO which is also based on the thinning algorithm. This performance for DTPP was achieved in orders of magnitude faster than HYPRO.

Limitations and future work.The main limitation of the model stems from the modeling of \(p^{*}\) using a deep learning architecture which is usually data-hungry and thus requires large amount of data to learn the model's parameters. For this reason, the model might be unsuitable for data-scarce regimes since it could be prone to overfit. Regarding future work, the limitations of the thinning algorithm revealed by the experiments raise many interesting questions on how can we improve this pathology for the CIF-based methods so they match the performance of the CPDF-based ones since their representations are equivalent. Another interesting research direction would be the development of a globally normalized model similar to HYPRO for CPDF-based models.

    & &  &  &  \\ 
**Methods** & **params** & **avg OTD** & **Time** & **avg OTD** & **Time** & **avg OTD** & **Time** \\  HYPRO-2 & & 20.35 \( 0.24\) & 44.81 \( 0.01\) & 39.73 \( 0.37\) & 43.53 \( 0.03\) & 39.84 \( 0.12\) & 46.32 \( 0.01\) \\ HYPRO-4 & & 19.86 \( 0.18\) & 47.31 \( 0.04\) & 38.93 \( 0.22\) & 46.57 \( 0.08\) & 39.57 \( 0.17\) & 48.84 \( 0.06\) \\ HYPRO-8 & 850 & 19.25 \( 0.30\) & 52.61 \( 0.20\) & 37.30 \( 0.48\) & 53.10 \( 0.17\) & 39.37 \( 0.30\) & 54.14 \( 0.22\) \\ HYPRO-16 & & 18.90 \( 0.34\) & 62.36 \( 0.27\) & 37.08 \( 0.39\) & 65.63 \( 0.44\) & 38.99 \( 0.16\) & 64.82 \( 0.34\) \\ HYPRO-32 & & 18.81 \( 0.16\) & 81.30 \( 0.23\) & 36.96 \( 0.19\) & 89.11 \( 0.71\) & 38.84 \( 0.20\) & 83.05 \( 0.45\) \\ DTPP & 400 & **15.00**\( 0.30\) & **0.01**\( 0.00\) & **28.83**\( 0.26\) & **0.17**\( 0.01\) & **36.75**\( 0.40\) & **0.03**\( 0.00\) \\  Speedup & &  &  &  \\   

Table 2: Performance comparison between our model DTPP and HYPRO for the long-horizon prediction task. For HYPRO, we use \(\{2,4,8,16,32\}\) weighted proposals (Algorithm 2 in ). We report the average optimal transport distance (avg OTD) and the time (in minutes) required for predicting all the long-horizon sequences of the held-out dataset (lower is better). “Params” denotes the number (\( 10^{3}\)) of trainable parameters of each method. We include error bars based on five runs.