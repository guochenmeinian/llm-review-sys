# Expressive probabilistic sampling in recurrent neural networks

Shirui Chen

Department of Applied Mathematics

University of Washington, Seattle

sc256@uw.edu

&Lixing Preston Jiang

Paul G. Allen School of Computer Science

& Engineering

University of Washington, Seattle

prestonj@cs.washington.edu

&Rajesh P. N. Rao

Paul G. Allen School of Computer Science

& Engineering and Center for Neurotechnology

University of Washington, Seattle

rao@cs.washington.edu

&Eric Shea-Brown

Department of Applied Mathematics

Computational Neuroscience Center

University of Washington, Seattle

etsb@uw.edu

Corresponding author

###### Abstract

In sampling-based Bayesian models of brain function, neural activities are assumed to be samples from probability distributions that the brain uses for probabilistic computation. However, a comprehensive understanding of how mechanistic models of neural dynamics can sample from arbitrary distributions is still lacking. We use tools from functional analysis and stochastic differential equations to explore the minimum architectural requirements for _recurrent_ neural circuits to sample from complex distributions. We first consider the traditional sampling model consisting of a network of neurons whose outputs directly represent the samples (_sampler-only_ network). We argue that synaptic current and firing-rate dynamics in the traditional model have limited capacity to sample from a complex probability distribution. We show that the firing rate dynamics of a recurrent neural circuit with a separate set of output units can sample from an arbitrary probability distribution. We call such circuits _reservoir-sampler networks_ (RSNs). We propose an efficient training procedure based on denoising score matching that finds recurrent and output weights such that the RSN implements Langevin sampling. We empirically demonstrate our model's ability to sample from several complex data distributions using the proposed neural dynamics and discuss its applicability to developing the next generation of sampling-based Bayesian brain models.

## 1 Introduction

There is growing evidence that humans and other animals make decisions by representing uncertainty internally and carrying out probabilistic computations that approximate Bayesian inference [42; 30; 18; 23; 34]. How networks of neurons in the brain represent probability distributions for Bayesian inference has remained a major open question. There exist two major theories: one assumes that the neural activities encode the parameters of the underlying posterior distributions over sensory stimuli [5; 35; 52]. The other is the sampling-based hypothesis, which assumes that the neural responses can be interpreted as samples from a posterior distribution . Under this hypothesis, recurrent neural circuits make use of their inherent stochasticity to produce samples from posterior distributions. Thesampling-based theory has explained various experimental observations regarding neural variability [19; 20; 40], perceptual decision-making  and spontaneous cortical activity .

Many studies have proposed biologically plausible spiking rules and membrane dynamics models to implement sampling-based probabilistic inference. However, most of these studies mainly consider sampling from discrete Boltzmann distributions  and multivariate Gaussian distributions [17; 1; 38; 25], only match the first two moments of the distribution , or employ a Monte-Carlo approximation . Although these studies use algorithmic substrates that can sample from any distribution with a density function _in theory_, it is not clear whether the underlying neural dynamics are capable of implementing a sufficiently expressive version of these sampling methods. Furthermore, natural image statistics are strongly non-Gaussian , and experimental evidence shows that humans use non-Gaussian prior representations to support cognitive judgments [27; 22]. It is known that deep artificial neural networks can be used to generate samples from complex data distributions [48; 49] using a "U-net"  backbone. However, the neural circuits in the cortex are highly coupled with an abundance of recurrent synapses. Therefore, an outstanding question for probabilistic computation in the brain is: what kind of recurrent neural network is capable of efficiently learning to produce samples from an arbitrarily complex posterior distribution?

In this paper, we study this question under the basic assumption that the dynamics of recurrent neural circuits can be described by stochastic differential equations (SDEs). Note that this assumption is common to a broad range of past research that uses rate-based neural dynamics to implement sampling-based coding[1; 19; 17]. Moreover, spike-based models [46; 45; 38] that implement balanced spiking networks (BSNs) [11; 13] essentially train spiking networks to follow underlying continuous-time SDEs, so our work applies to this line of research as well (details in Appendix G).

The contributions of this paper are as follows (Figure 1):

1. We establish the relationship between the sampling power of the neural dynamics and the ability of the dynamics to approximate the score function, which is the gradient of the log probability density function. (Section 3.1)
2. We show that the synaptic current dynamics of a network of neurons whose outputs directly represent the samples (traditional sampler-only network) is only able to approximate score functions that are in a finite-dimensional function space. (Section 3.2, Proposition 2)
3. We prove that the firing rate dynamics of our proposed reservoir-sampler network can sample from a distribution whose score function can approximate that of arbitrary target distributions (with mild restrictions) to arbitrary precision (Section 3.3, Theorem 3).
4. We derive a computationally efficient and biologically-plausible learning rule for our proposed model (Section 3.4) that sidesteps the demands of backpropagation through time, and we empirically demonstrate how our model can sample from several complex data distributions (Section 4).

And interpretation of our contributions in biological terms is as follows: 1. Flexible synaptic connectivity within a circuit itself is not enough to allow that circuit to flexibly produce arbitrary patterns of variability involving all of its neurons. 2. In order for circuit to achieve full flexibility in its output patterns, there need to be hidden variables involved, e.g. states of neurons in an upstream brain area or possibly non-synaptic signalling. If this condition is met, concrete and fairly efficient plasticity rules may be capable of shaping the output patterns as desired.

## 2 Background

### Fokker-Planck equation and stationary distribution

We consider a general time-homogeneous SDE with drift vector \((X_{t})\) and diffusion matrix \(=^{T}\):

\[dX_{t}=(X_{t})dt+ dB_{t} \]

where \(^{n m}\) is the diffusion coefficient, and \(B_{t}\) is an \(m\)-dimensional standard Wiener process. The Fokker-Planck equation of this SDE describes the time evolution of the probability density \(p(x,t)\) for a given SDE, assuming the initial density \(p(x,0)\) is known:\[_{t}p=( p-p) \]

where \(_{t}=/ t\), \(\) is the divergence operator, and \(\) is the gradient operator. A stationary probability density function is one for which the right-hand-side of equation (2) is 0. Mild regularity conditions guaranteeing the existence and uniqueness of a stationary density function are discussed in, for example, Cerrai . We assume these are satisfied by the SDEs considered in this paper. Moreover, to ensure ergodicity and a well-defined score function, we assume that \(p\) is supported on \(^{n}\), i.e. \(p(x)>0\) for all \(x^{n}\).

As a special case, consider the following Langevin dynamics, in which the drift term is given by the gradient of the log stationary probability density \( p(x)\),

\[dX_{t}= p(X_{t})dt+dB_{t}. \]

It can be verified through the Fokker-Planck equation that \(p(x)\) in the dynamics above is indeed a stationary probability density function of the dynamics. Therefore the Langevin dynamics can sample from the distribution \(p(x)\) as \(t\). While the drift term in the Langevin dynamics is a gradient vector field, this is not true in general and is often not the case for recurrent neural dynamics (Proposition 5 in Appendix B).

### Score-based generative modeling

If we would like a particular dynamics to implement Langevin dynamics, we need to fit the drift term of an SDE to the score \(s_{}()= p()\) of the probability distribution that we are trying to sample from. This procedure of fitting the score function \(s_{}()\) is called score matching. In this section, we give a brief summary of one of the major methods of score matching that we will use in this paper, denoising score matching (DSM) . The general idea of DSM is to match the score of a noise-perturbed version of the target distribution. More specifically, the explicit score matching loss

Figure 1: **Reservoir-Sampler Networks versus Traditional Sampler-Only Networks. The sampler neurons which produce samples from the target distribution are present for both the sampler-only (SO) network and the reservoir-sampler (RS) network. The reservoir neurons (shown within the large black circle) are only present in the RS network. We explore the firing rate (FR) dynamics (Section 3.3) for both networks and the synaptic current (SC) dynamics (Section 3.2) only for the sampler-only network because the stationary distribution of the output neurons is intractable in the RS-SC case. We evaluate the approximation power of the function set represented by the drift term of the neural dynamics, and list the number of basis functions that span the set, whether these basis functions are fixed, and whether the function set is closed under addition (shown in the table).**

(left-hand side) and the denoising score matching loss (right-hand side) are related to each other as follows :

\[_{q_{}(})}[\|s_{}( })-_{}} q_{}(})\|^{2}]=_{q_{}(},)}[ \|s_{}(})-_{}}  q_{}(}|)\|^{2}]+C_{} \]

where \(}\) is a noise-perturbed version of \(\), so \(q_{}(}|)=(,)\), and \(C\) is a constant depending on \(\) but _not_ on \(\). When the noise is 0, i.e. \(}=\), the left-hand side of the equation above is the explicit score matching loss. Although in theory we can start from extremely small Gaussian noise, and directly optimize the right hand of equation (4), empirically it is beneficial to start with large Gaussian noise and gradually decrease the noise magnitude until \(q_{}() p()\) and \(s_{}()_{} q_{}() _{} p()\). Specifically, this has been shown to stabilize the training and improve score estimation .

## 3 Methods

### Do we really need to match the score?

The Langevin dynamics provides an elegant way to construct an SDE given a specific stationary distribution. However, as noted above, the neural network dynamics seldom have a drift term that is a gradient field (Appendix B). A natural question is therefore whether an SDE with a drift term that is _not_ a gradient field (also known as irreversibility) also gives rise to a specific stationary distribution. The answer requires us to look at the Fokker-Planck equation:

\[_{t}p(,t)=( p-pF_{}()) \]

where \(p(,t)\) is the probability density function of the variable of interest \(\) at time \(t\), \(F_{}()\) is the drift term of the neural dynamics parametrized by \(\), and \(=^{T}\) is the diffusion matrix. Since the right-hand side of (5) needs to be 0 for a given stationary distribution \(p()\), we have

\[( p-pF_{}())=0. \]

Therefore \(G:=- p+pF_{}()\) needs to be a divergence-free (DF) vector field. In other words, \(pF_{}()\) is unique up to a DF field given a fixed stationary distribution \(p\). Ma et al.  shows that there exists a skew-symmetric matrix \(Q\) such that the DF field can be written as \(G=Q p+p_{j}_{j}}Q_{ij}\), however, this does not shed more light on how expressive \(\{F_{}\}_{}\) needs to be without more knowledge of \(Q\) and its derivative. We show below that under certain conditions, the DF field \(G\) can be regarded as a component that is orthogonal to the score function. Therefore the function space \(\{F_{}\}_{}\) needs to have enough basis functions so that (when projected) it is able to approximate the score function of the target distribution.

We first note that it would be convenient if \(F_{}()\) could approximate the gradient fields \(^{-1} p\) for any \(p\), in which case \(G=0\). To find out if this is a necessary condition for the dynamics to sample from an arbitrary target distribution \(p\), we let \(=\) and invoke the Helmholtz-Hodge decomposition (HHD) . The decomposition theorem states that any sufficiently smooth vector field in \(L^{2}(^{n};^{n})\) can be uniquely decomposed into a DF vector field and a pure gradient field. In other words, the function space of all DF fields \(G\) and the function space of all gradient fields \( p\) are the orthogonal complement of each other. Therefore the projection of \(pF_{}()\) onto the subspace of smooth gradient fields still needs to be able to approximate \( p\) despite the freedom to choose arbitrary DF field \(G\).

For example, in the 1-D case, if we assume that both \(pF_{}()\) and \( p\) are square-integrable (so they vanish at infinity), then the divergence-free vector field \(G\) (which must be constant in 1-D) is 0, therefore \(F_{}()= p\). As a result, \(\{F_{}\}_{}\) indeed needs to be able to approximate \( p\) for every \(p\). In higher dimensions, the same conclusion holds under the assumption of a strict orthogonality constraint:

**Proposition 1**.: _Let \(p\) be the stationary distribution of the neural dynamics, and the diffusion matrix be the identity matrix. If the DF field \(G\) is strictly orthogonal to the gradient field \( p\), meaning that \(G() p()=0\) for all \(\), then the drift term \(F_{}()\) can be written as the sum of a divergence-free field \(p^{-1}G\) and a gradient field \( p\)._The proof and further detail is in Appendix A. The form of the above decomposition coincides with that of the HHD . Therefore if we enforce the _normal-parallel_ boundary condition  for the gradient component, the HHD theorem  says that the orthogonal projection of the function space \(\{F_{}\}_{}\) onto the space of gradient fields is the function space of gradient fields \(\{ p\}_{p}\) satisfying the boundary condition given the strict orthogonality constraint on \(G\). The upshot is that \(\{F_{}\}_{}\) needs to admit enough basis functions (Appendix A). Note that the boundary condition will not be restrictive if we take a sufficiently large bounded region. Therefore it is essential for the neural dynamics to have an expressive functional form that is able to approximate complex score functions, even if their dynamics are not gradient fields.

Previous work has rigorously established that the strict orthogonality constraint holds, in particular, when the nonlinear dynamics is linearized around fixed points of \(\) (where the drift term is zero ). As a consequence, the conditions of Proposition 1 are true locally around fixed points.

In what follows, we assume that the conditions of the Proposition 1 hold. Under this assumption, without loss of generality, we set \(G\) to be \(\) in the following text and explore whether \(^{-1}F_{}\), which is determined by the specific neural dynamics (Figure 1), is able to approximate complex score function \( p\).

### Synaptic current dynamics: sampler-only networks with limited capacity

We consider the following stochastic synaptic current dynamics  (cf. eq. 7.39) that describe a recurrent neural network in terms of the synaptic current that each neuron receives:

\[d=D(-+W()+I)dt+ d_{t}:=F_{ }^{}()dt+ d_{t} \]

where \(F_{}^{}():=D(-+W()+I)\), \(=[v_{1},,v_{m}]^{T}^{m}\) is the synaptic current of the \(m\) neurons in the recurrent network, \(D^{m m}\) is a diagonal matrix where diagonal elements are the decay constants, \(d_{i}=_{i}^{-1}\), \(W^{m m}\) is the connection matrix, \(()\) is a nonlinear transfer function2, \(I^{m}\) is the external input, \(^{m l}\) is the diffusion coefficient and \(_{t}\) is an \(l\)-dimensional standard Wiener process. The diffusion term can be interpreted as input from other brain areas (due to the large number of incoming connections, the assumption of Gaussianity can be justified by the central limit theorem ). We assume that \(=\{D,W,I\}\) are tunable parameters through biological learning. To show the limited expressivity of \(F_{}^{}\), we have the following corollary from the Hilbert projection theorem showing that \(F_{}^{}\) is only able to approximate functions in a finite-dimensional function space.

**Proposition 2**.: _Let \(H:^{m}^{m}\), a function in the Hilbert space \(L_{2}(^{m},^{m};p)\). Let \(\) be the orthogonal projection operator onto the vector subspace_

\[E=\{A+B()+I|A,B^{m m},I ^{m 1}\}\]

_If \(\|H- H\|>0\), then \(_{}\|H()-F_{}^{}()\| \|(1-)H\|>0\)._

Proof of the proposition is given in Appendix B.1. The proposition says that no matter how the parameter of \(F_{}^{}\) is tuned, the difference between \(F_{}^{}\) and the target function cannot approach 0, and the lower bound of the error is given by the norm of the component in the target function that is orthogonal to the finite-dimensional function space \(E\). Therefore, synaptic current dynamics have a limited ability to match the score function and hence limited ability to sample from complex probability distributions under the strict orthogonality constraint in Section 3.1. The conclusion holds even if we let the diffusion coefficient \(\) be tunable. Since \(^{-1}\) is linear, \(\{F_{}^{}\}_{}\) share the same set of basis functions as \(\{^{-1}F_{}^{}\}_{,}\). As we will see in the next section, the firing rate dynamics of a recurrent neural circuit with a separate output layer (a reservoir-sampler network) and a learnable diffusion coefficient \(\) can sample from arbitrary stationary distributions.

### Firing-rate dynamics could be a universal sampler

#### 3.3.1 Sampler-only networks

In this section, we consider the firing rate dynamics  (cf. eq. 7.11) that describe a recurrent neural circuit in terms of firing rates of the neurons. We first consider the sampler-only network:

\[d=D(-+(W_{}+I))dt+ dB_{t}:= F_{}^{}()dt+ d_{t}. \]Here, \(F_{}^{ FR}({ v})=D(-{ r}+(W_{ rec}{ r}+I))\) and \(D\) is a diagonal matrix with decay constants as its diagonal elements. The stationary solution of the corresponding Fokker-Planck equation satisfies

\[( p-pF_{}^{ FR})=0 \]

where \(:=^{T}\) is symmetric positive definite (SPD) and \(F_{}^{ FR}=D(-{ r}+(W_{ rec}{ r}+I))\). Here \(=\{D,W_{ rec},I\}\) are tunable parameters. If \(\) is invertible, equation (9) becomes \((( p-p^{-1}F_{}^{ FR}))\). Therefore if \(^{-1}F_{}^{ FR}= p\) is a gradient field, then the stochastic dynamics of the recurrent neural network described by equation (8) have a stationary distribution \(p^{*}\) such that the score of this distribution \( p^{*}=^{-1}F_{}^{ FR}\).

Compared to the synaptic current dynamics where we could only have functional basis \({ v}_{i}\) and \(({ v})_{i}\), we can now freely choose the functional basis spanning \(\{F_{}^{ FR}\}_{}\) depending on \(W_{ rec}\) and \(I\), but since there is no linear term before the nonlinear transformation \(\), the function set \(\{F_{}^{ FR}\}_{}\) is not closed under addition. If we view \(^{-1}F_{}^{ FR}\) as a neural network with one hidden layer, the number of hidden neurons must be the same as the input dimension, and the diffusion matrix \(\) (hence \(^{-1}\)) is restricted to be an SPD matrix. Therefore, we do not get universal approximation power from \(^{-1}F_{}^{ FR}\), and combined with results in Section 3.2, we see that an RNN by itself does not intrinsically produce samples from arbitrary distributions. As we will see below, if we let a population of output neurons receive inputs from a large reservoir of recurrently connected neurons (a reservoir-sampler network), we are able to obtain samples from complex distributions from the output neurons.

#### 3.3.2 Reservoir-sampler networks

Now we consider the reservoir-sampler network where there is a linear readout layer \(W_{ out}^{m n}\) of the reservoir whose dynamics is given by equation (8) (see also the upper row of Figure 1). As a special case of Ito's lemma, we have

\[ W_{ out}d{ r}=dW_{ out}{ r}& =W_{ out}F_{}^{ FR}dt+W_{ out} dB_{t}\\ &=(-W_{ out}D{ r}+W_{ out}D(W_{ rec}{ r}+I)) dt+W_{ out} dB_{t}. \]

Now we assume that \(W_{ rec}\) is the product of \(_{ rec}\) and \(W_{ out}\), i.e. \(W_{ rec}=_{ rec}W_{ out}\) and \(D=\) is a scaled identity matrix. If we denote the output of the recurrent neural network as \({ x}:=W_{ out}{ r}^{m}\), we derive the following stochastic dynamics for output neurons:

\[d{ x}=(-+ W_{ out}(_{rec}{ x}+I) )dt+W_{ out} dB_{t}:=_{}^{ FR}({ x})dt+ dB_{t} \]

where \(_{}^{ FR}({ x})=(-+ W_{ out} (_{ rec}{ x}+I))\) and \(=W_{ out}\). Therefore in order for the output neurons to sample from a stationary distribution \(p\), we need \(s_{}({ x})=(^{T})^{-1} _{}^{ FR}({ x}):=^{-1}_{}^{ FR}({ x})\) to match the score \( p({ x})\). Here \(=\{_{ rec},W_{ out},I,\}\) are tunable parameters.

Additionally, we assume that \(_{}^{ FR}\) is \({ 0}\) outside a reasonable range of \({ x}\). This assumption is used to prevent \(s_{}({ x})\) from behaving wildly outside the bounded region on which \(s_{}({ x})\) has the expressivity to match the score. The following theorem proves that with a large enough number of reservoir neurons, the score-matching loss can be arbitrarily small. The proof is given in Appendix C.

**Theorem 3**.: _Suppose that we are given a probability distribution with continuously differentiable density function \(p({ x}):^{m}^{+}\) and score function \( p({ x})\) for which there exist constants \(M_{1},M_{2},a,k>0\) such that_

\[p({ x}) <M_{1}e^{-a\|{ x}\|} \] \[\| p({ x})\|^{2} <M_{2}\|{ x}\|^{k} \]

_when \(\|{ x}\|>L\) for large enough \(L\). Then for any \(>0\), there exists a recurrent neural network whose firing-rate dynamics are given by (11), whose recurrent weights, output weights and the diffusion coefficient are given by \(W_{ rec}^{n n}\) of rank \(m\), \(W_{ out}^{m n}\), and \(^{n m}\) respectively, such that, for a large enough \(n\), the score of the stationary distribution of the output units \(s_{}({ x})\) satisfies \(_{{ x} p({ x})}[\| p({ x})-s_{}({ x })\|^{2}]<\)._

This theorem says that for any realistic data distribution with a smooth positive density function, there always exists a reservoir of recurrently-connected neurons whose output units give samples from a 

[MISSING_PAGE_FAIL:7]

Next, we show that the model can learn mixtures of heavy-tailed distributions that are evident in natural image statistics and the neural representations in the primary visual cortex . We trained the Reservoir-Sampler network with FR dynamics (RS-FR) model on 20000 sampled data points from a 2-D Laplace mixture distribution, whose density is given by \(p_{}()=((, 1&0.9\\ 0.9&1)+(,1&-0.9 \\ -0.9&1))\), where \(\) denotes the multivariate Laplace distribution. The model successfully learned the probability density of the mixture distribution (Figure 3 left vs. middle), and captured the heavy tails of the distribution as measured by the kurtosis (Figure 3 right).

### MNIST generation task

We also tested the sampling ability of our model using the MNIST dataset  which contains 60,000 handwritten digits from 0 to 9. We projected MNIST images to a 300-D latent space spanned by the first 300 principal components, and trained the weights of the recurrent neural network as described in Section 3.4 so that the RNN can sample from the latent distribution. To test the model, we generated images by applying inverse PCA projection to samples generated by the model. The schematics and generated images are shown in Figure 4. Note that since we are essentially using a shallow network to match the score, we should not expect comparable performance to generative models that use deep ANNs. Our main goal is to illustrate that the reservoir-sampler network using firing rate dynamics is qualitatively more expressive than other traditional neural sampling models (Appendix G). Finally we also note that it is highly nontrivial for recurrent neural dynamics to complete such a generative task, and to the best of our knowledge, no previous work has achieved such results.

Figure 2: **Bimodal distribution sampling results.** The 3 tractable cases shown are Sampler-only (SO) networks with both synaptic current (SC) dynamics and firing rate (FR) dynamics and Reservoir-sampler (RS) networks with FR dynamics, which are named SO-SC, SO-FR and RS-FR respectively. a-c) The score function learned compared to the true score function (orange curve) as we gradually decrease the noise level (the darker the line, the lower the noise level). We see that RS-FR is capable of perfectly fitting the score function, while SO-SC and SO-FR are only able to fit the score function with piecewise linear functions when using the ReLU transfer function. d-f) Histogram of sampled points, and the (scaled) density function of the target distribution. Again the reservoir-sampler network is able to generate samples whose distribution matches the target distribution, while the sampler-only network is not able to do so due to the incorrectly matched score function.

## 5 Discussion

From the perspective of functional analysis and SDE theory, we prove that under the strict orthogonality constraint, it is essential for neural circuits to have a drift term that has the expressivity to approximate complex score functions, despite the fact that the dynamics do not have to exactly implement the Langevin dynamics. We investigated whether a population of neurons can sample from an arbitrary distribution directly and proved that the drift term of the synaptic current dynamics can only sample from a finite-dimensional function space. Although the drift term of the firing

Figure 4: **Learning to sample the MNIST image distribution.** a) An MNIST image is projected to a 300-D latent space (orange circle) spanned by the first 300 principal components using PCA. The sampler learns to sample from the distribution of this latent space and generates images by applying inverse PCA projection to these samples. The diagram illustrates the RS-FR model. b) The loss curves for 3 different models during training. Every 100 epochs the noise level added to the training samples is reduced (Appendix H), and the noise increases to a higher value because the score matching loss magnitude depends on the noise level. As shown in the inset, the loss of the RS-FR model decreases throughout the training process when using the lowest fixed noise level. Meanwhile, the losses of the other two models remain unchanged. c-f) The images generated for the 3 models compared to the digit images generated from latent training samples.

Figure 3: **RS-FR model learning a mixture of 2-D Laplace distribution.** Left to right: sample density from the true distribution (brighter color denotes higher density); sample density from the learned distribution; marginalized kurtosis of each dimension from the true and learned distribution.

rate dynamics can approximate functions spanned by different basis functions, the number of basis functions is limited. To address this problem, we proposed the reservoir-sampler network for firing rate dynamics. We found that with learnable diffusion coefficients and a sufficiently large reservoir of hidden neurons, the output neurons described using the firing rate dynamics are able to sample from arbitrary data distributions. Our results partly answer the question of what architecture recurrent neural circuits need so that they are able to sample from complex data distributions.

Our analysis and empirical experiments affirm the universality of stochastic RNNs. However, this universality comes with limitations. First, we have only analytically shown the existence of weights that enable sampling from complex data distributions; there is no guarantee that one will find such weights through backpropagation. Additionally, in order to obtain the tunable diffusion coefficient during training, a matrix inverse is needed (likewise in the FORCE algorithm ). Further, the question of how biological circuits compute the specific gradient and implement the denoising score-matching algorithm remains an open question. Moreover, in our current formulation, we are only able to approximate the score function with a shallow network with one hidden layer. Our preliminary experiments show that one-hidden-layer RSNs cannot readily approximate high-dimensional heavy-tailed distributions (_e.g._, those of overcomplete sparse coding representations ). It is unclear if this is because of insufficient number of reservoir neurons. Due to the limitation of the GPU memory, we did not try higher number of reservoir neurons.

Our model differs from recent diffusion models [26; 49], which can be seen as time-inhomogeneous SDEs, and has the advantage of being able to run indefinitely in time, making it a suitable candidate for modeling spontaneous activity in the brain. Moreover, while Song and Ermon  optimizes the denoising score matching loss at different noise levels jointly, we adopt a sequential learning procedure by gradually decreasing the noise level of the training samples. This procedure is more aligned with the developmental processes involved in forming visual representations in the infant brain, where the distribution of visual representations are thought to be noisier (less linearly separable) initially . Our study therefore serves as a starting point for building a mechanistic model for probabilistic computation in the brain that has similar generative power to current AI generative models.

Biologically, there are multiple ways to interpret the reservoir neurons and sampler neurons in an RSN. First, reservoir and sampler neurons could be seen as different types of neurons in a single brain area, where the dynamics of sampler neurons converge quickly to the equilibrium point. Second, even more straightforwardly, the sampler neurons could be seen as a more separate set of neurons located downstream of the reservoir. We also wish to suggest an alternative interpretation. Biological neural networks are known to have non-synaptic signaling networks (e.g. pervasive neuropeptidergic signaling , extensive aminergic signaling  or potential extrasynaptic signaling ) in addition to the synaptic connectivity that is typically modeled (i.e., via connection weights). We suggest that it is possible that the computations of the reservoir may be implemented by non-synaptic networks, and then "read out" by certain neurons' spikes. This possibility is supported by the recent finding of a low correlation between functional activity and the synaptic ("structural") connectome in C.elegans . Morever, if we only take the structural connectome into consideration, then the resulting model of C. elegans would correspond to the sampler-only network, which, as our theory predicts, will have limited sampling capability.

## 6 Conclusion

In this paper, we explore how a recurrent neural circuit can sample from complex probability distributions, an important functional motif in probabilistic brain models. We start from a basic assumption that the recurrent neural circuit could be described as an SDE. We show that a recurrently-connected neural population by itself has a limited capability to implement stochastic dynamics that can sample from complex data distributions. In contrast, we prove that firing rate dynamics of the output units of a recurrent neural circuit (a reservoir-sampler network) can sample from a richer range of probability distributions. These theoretical results, together with our preliminary experimental results, provide a sufficient condition for neural sampling-based models to exhibit universal sampling capability. Our results therefore provide a foundation for the next generation of sampling-based probabilistic brain models that can explain a wider range of cognitive behaviors.

Acknowledgements

We are thankful to Profs. Hong Qian, Bamdad Hosseini and Edgar Walker for their guidance and insight with this project. We gratefully acknowledge the support of the grant NIH BRAIN R01 1RF1DA055669.