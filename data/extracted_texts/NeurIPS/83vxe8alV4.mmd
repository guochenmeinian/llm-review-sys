# FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning

Tristan Cinquin

Tubingen AI Center, University of Tubingen

tristan.cinquin@uni-tuebingen.de

&Marvin Pfortner

Tubingen AI Center, University of Tubingen

marvin.pfoertner@uni-tuebingen.de

&Vincent Fortuin

Helmholtz AI, TU Munich

vincent.fortuin@tum.de

&Philipp Hennig

Tubingen AI Center, University of Tubingen

philipp.hennig@uni-tuebingen.de

&Robert Bamler

Tubingen AI Center, University of Tubingen

robert.bamler@uni-tuebingen.de

Equal contribution

###### Abstract

Laplace approximations are popular techniques for endowing deep networks with epistemic uncertainty estimates as they can be applied without altering the predictions of the trained network, and they scale to large models and datasets. While the choice of prior strongly affects the resulting posterior distribution, computational tractability and lack of interpretability of the weight space typically limit the Laplace approximation to isotropic Gaussian priors, which are known to cause pathological behavior as depth increases. As a remedy, we directly place a prior on function space. More precisely, since Lebesgue densities do not exist on infinite-dimensional function spaces, we recast training as finding the so-called weak mode of the posterior measure under a Gaussian process (GP) prior restricted to the space of functions representable by the neural network. Through the GP prior, one can express structured and interpretable inductive biases, such as regularity or periodicity, directly in function space, while still exploiting the implicit inductive biases that allow deep networks to generalize. After model linearization, the training objective induces a negative log-posterior density to which we apply a Laplace approximation, leveraging highly scalable methods from matrix-free linear algebra. Our method provides improved results where prior knowledge is abundant (as is the case in many scientific inference tasks). At the same time, it stays competitive for black-box supervised learning problems, where neural networks typically excel.

## 1 Introduction

Neural networks (NNs) have become the workhorse for many machine learning tasks, but they do not quantify the uncertainty arising from data scarcity--the _epistemic_ uncertainty. NNs therefore cannot estimate their confidence in their predictions, which is needed for safety-critical applications, decision making, and scientific modeling . As a solution, Bayesian neural networks (BNNs) cast training as approximating the Bayesian posterior distribution over the weights (i.e., the distribution of the model parameters given the training data), thus naturally capturing epistemic uncertainty. Various methods exist for approximating the (intractable) posterior, either by a set of samples (e.g., MCMC) orby a parametric distribution (e.g., variational inference or Laplace approximations). While sampling methods can be asymptotically exact for large numbers of samples, they are typically expensive for large models, whereas variational inference (VI) and the Laplace approximation are more scalable. The Laplace approximation is particularly appealing as it does not alter maximum-a-posteriori (MAP) predictions. Compared to VI, its differential nature allows the Laplace approximation to scale to large datasets and models, and it has been shown to provide well-calibrated uncertainty estimates .

The need for function-space priors in BNNs.While the choice of prior strongly influences the uncertainty estimates obtained from the posterior , there are hardly any methods for elicitation of informative priors in the literature on BNNs, with the notable exceptions of Sun et al.  and Tran et al. . This is not just a conceptual issue. For instance, the default isotropic Gaussian prior, commonly thought of as uninformative, actually carries incorrect beliefs about the posterior (uni-modality, independent weights, etc.)  and has known pathologies in deep NNs . As network weights are not interpretable, formulating a good prior on them is virtually impossible. Current methods work around this issue by model selection, either through expensive cross-validation, or type-II maximum likelihood estimation with a Laplace approximation under an isotropic Gaussian prior, which can only be computed exactly for small networks, and has known issues with normalization layers . As a solution, Sun et al.  proposed a VI method to specify priors directly on the function implemented by the BNN, with promising results. Function-space priors incorporate interpretable knowledge about the variance, regularity, periodicity, or length scale, building on the extensive Gaussian Process (GP) literature . But it turns out that the method by Sun et al.  is difficult to use in practice: the Kullback-Leibler (KL) divergence regularizing VI is infinite for most function-space priors of interest , and estimating finite variants of it is challenging .

This paper addresses the lack of a procedure to specify informative priors in the Laplace approximation by proposing a method to use interpretable GP priors. Motivated by MAP estimation theory, we first derive an objective function that regularizes the neural network in function space using a GP prior, and whose minimizer corresponds to the MAP estimator of a GP on the space of functions represented by the network. We then apply the Laplace approximation to the log-posterior density induced by the objective, allowing us to effectively incorporate beliefs from a GP prior into a deep network (see Figure 1). Efficient matrix-free methods from numerical linear algebra allow scaling our method to large models and datasets. We show the effectiveness of our method by showing improved results in cases where prior knowledge is available, and competitive performance for black-box regression and classification tasks, where neural networks typically excel. We make the following contributions:

1. We propose a novel objective function for deep neural networks that allows incorporating interpretable prior knowledge through a GP prior in function space.
2. We develop an efficient and scalable Laplace approximation that endows the neural network with epistemic uncertainty reflecting the beliefs specified by the GP prior in function space.
3. A range of experiments shows that our method improves performance on tasks with prior knowledge in the form of a kernel, while showing competitive performance for black-box regression, classification, out-of-distribution detection, and Bayesian optimization tasks.

Figure 1: FSP-Laplace allows for efficient approximate Bayesian neural network (BNN) inference under interpretable function space priors. Using our method, it is possible to encode functional properties like smoothness, lengthscale, or periodicity through a Gaussian process (GP) prior. The gray data points in the plots are noisy observations of a periodic function.

## 2 Preliminaries: Laplace approximation in weight space

For a given dataset \(=(,)\) of inputs \(=(^{(i)})_{i=1}^{n}^{n}\) and targets \(=(^{(i)})_{i=1}^{n}^{n}\), we consider a model of the data that is parameterized by a neural network \(^{d^{}}\) with weights \(^{p}\), a likelihood \(p((,))_{i=1}^{n}p(^{(i)} (^{(i)},))\), and a prior \(p()\).

We seek the Bayesian posterior \(p() p((,))\,p()\). As it is intractable in BNNs, approximate inference methods have been developed. Among these, the Laplace approximation  to the posterior is given by a Gaussian distribution \(q(=)=(;^{*},^{-1})\), whose parameters are found by MAP estimation \(^{*}_{}R_{}()\) of the weights, where

\[R_{}()- p()=- p()- _{i=1}^{n} p(^{(i)}(^{(i)},))+\] (2.1)

and computing the Hessian of the negative log-posterior \(-._{} p() |_{=^{*}}^{p p}\).

The linearized Laplace approximation.Computing \(\) involves the Hessian of the neural network w.r.t. its weights which is generally expensive. To make the Laplace approximation scalable, it is common to linearize the network around \(^{*}\) before computing \(\),

\[(,)(,^{*})+_{^{*}}( {x})(-^{*})^{}(,)\] (2.2)

with Jacobian \(_{^{*}}()=._{}.(,)|_{=^{*}}\). Thus, the approximate posterior precision matrix \(\) is

\[-._{} p()|_{= {w}^{*}}-_{i=1}^{n}_{^{*}}(^{(i)})^{}_{^ {*}}^{(i)}_{^{*}}(^{(i)}),\] (2.3)

where \(_{^{*}}^{(i)}=._{}\, p(^{(i)} )|_{=(^{(i)},^{*})}\). Thus, under the linearized network, the Hessian of the negative log-likelihood (NLL) coincides with the _generalized Gauss-Newton matrix_ (GGN) of the NLL. Crucially, the GGN is positive-(semi)definite even if \(-._{} p((,))|_{=^{*}}\) is not.

## 3 FSP-Laplace: Laplace approximation under function-space priors

A conventional Laplace approximation in neural networks requires a prior in weight space, with the issues discussed in Section1. We now present FSP-Laplace, a method for computing Laplace approximations under interpretable GP priors in function space. Section3.1 introduces an objective function that is a log-density under local linearization. Section3.2 proposes a scalable algorithm for the linearized Laplace approximation with a function-space prior using matrix-free linear algebra.

### Laplace approximations in function space

We motivate our Laplace approximation in function space through the lens of MAP estimation in an (infinite-dimensional) function space under a GP prior. As Lebesgue densities do not exist in (infinite-dimensional) function spaces, we cannot minimize Equation2.1 to find the MAP estimate. We address this issue using a generalized notion of MAP estimation, resulting in a minimizer of a regularized objective on the reproducing kernel Hilbert space \(_{}\). We then constrain the objective to the set of functions representable by the neural network and minimize it using tools from deep learning. Finally, local linearization of the neural network turns this objective into a valid negative log-density, from which we obtain the posterior covariance by computing its Hessian.

MAP estimation in neural networks under Gaussian process priors.The first step of the Laplace approximation is to find a MAP estimate of the neural network weights \(\), i.e., the minimizer of the negative log-density function in Equation2.1 w.r.t. the Lebesgue measure as a "neutral" reference measure. In our method, we regularize the neural network in function space using a \(d^{}\)-output GP prior \((,)\) with index set \(\). However, a (nonparametric) GP takes its values in an infinite-dimensional (Banach) space \(\) of functions, where no such reference Lebesgue measure exists . Rather, the GP induces a prior _measure_\(_{}\) on \(\)[19, Section B.2]. We are thus interested in the "mode" of the posterior measure \(_{}^{}\) under \(_{}\) defined by the Radon-Nikodymderivative \(^{}_{}()(-^{} ())_{}()\) where \(^{}\) is the _potential_, in essence the negative log-likelihood functional of the model. In our case, \(^{}()=-_{i=1}^{n} p(^{(i)}(^{(i)} )).\) Similar to Bayes' rule in finite dimensions, this Radon-Nikodym derivative relates the prior measure to the posterior measure by reweighting. Since there is no Lebesgue measure, the (standard) mode is undefined, and we therefore follow Lambley , using so-called _weak modes_.

**Definition 1** (Weak Mode [see e.g., \(20\), Definition 2.1]).: Let \(\) be a separable Banach space and let \(\) be a probability measure on \((,())\). A _weak mode_ of \(\) is any point \(^{}\,\) such that

\[_{r 0}(B_{r}())}{(B_{r}(^ {}))} 1.\] (3.1)

Above, \(()\) denotes the Borel \(\)-algebra on \(\) and \(B_{r}()\) is an open ball with radius \(r\) centered at a point \(\). The intuition for the weak mode is the same as for the finite-dimensional mode (indeed they coincide when a Lebesgue measure exists), but the weak mode generalizes this notion to infinite-dimensional (separable) Banach spaces. Under certain technical assumptions on the potential \(^{}\) (see Assumption A.2 in the appendix), Lambley  shows that any solution to

\[*{arg\,min}_{_{_{_{ _{}}}}}}()+\| {f}-\|_{_{_{}}}^{2}}_{=:R_{}( )}\] (3.2)

is a weak mode of the posterior probability measure \(^{}_{}\).

Equation (3.2) casts the weak mode of the posterior measure \(^{}_{}\) as the solution of an optimization problem in the RKHS \(_{}\). We can now relate it to an optimization problem in weight space \(\), and apply tools from deep learning. Informally speaking, we assume that the intersection of the set of functions represented by the neural network \(\{(\,\,,)\} (^{d^{}})^{}\) and \(_{}\) is non-empty, and constrain the optimization problem in Equation (3.2) such that \(\) belongs to both sets

\[*{arg\,min}_{_{_{}} }R_{}().\] (3.3)

Unfortunately, the framework by Lambley  cannot give probabilistic meaning to optimization problems with hard constraints of the form \(\). To address this, we adopt and elaborate on the informal strategy from Chen et al. [21, Remark 2.4]. Denote by \(d_{}(,)_{_{0}}\| {f}_{0}-\|_{}\) the distance of a function \(\) to the set \(\). Under Assumption A.3, \(d_{}(,)=0\) if and only if \(\) by Lemma A.2. Hence, we can relax the constraint \(\) by adding \(}d_{}^{2}(,)\) with \(>0\) to the objective in Equation (3.2). Intuitively, the resulting optimization problem is the MAP problem for the measure \(^{,}_{}\) obtained by conditioning \(^{}_{}\) on the observation that \(d_{}(,)+_{}=0\), where \(_{}\) is independent centered Gaussian measurement noise with variance \(^{2}\). Formally:

**Proposition 1**.: _Let Assumptions A.1 to A.3 hold. For \(>0\), define \(^{,},^{} ()+}d_{}^{2}(,)\). Then the posterior measure \(^{,}_{}()(- ^{,}())_{}()\) has at least one weak mode \(^{}_{}\), and the weak modes of \(^{,}_{}\) coincide with the minimizers of_

\[R_{}^{}_{}, ^{,}()+\|-\|_{_{}}^{2}.\] (3.4)

As \( 0\), the term \(}d_{}^{2}(,)\) forces the minimizers of \(R_{}^{}\) to converge to functions in \(_{}\) that minimize \(R_{}\):

**Proposition 2**.: _Let Assumptions A.1 to A.3 hold. Let \(\{_{n}\}_{n}_{>0}\) with \(_{n} 0\), and \(\{_{n}^{}\}_{n}_{}\) such that \(_{n}^{}\) is a minimizer of \(R_{}^{_{n}}\). Then \(\{_{n}^{}\}_{n}\) has an \(_{}\)-weakly convergent subsequence with limit \(^{}_{}\). Moreover, \(^{}\) is a minimizer of \(R_{}\) on \(_{}\)._

We prove Propositions 1 and 2 in Appendix A.2. To provide some intuition about the mode of convergence in Proposition 2, we point out that \(_{}\)-weak convergence of the subsequence \(\{_{n_{k}}^{}\}_{k}\) implies both (strong/norm) convergence in the path space \(\) of the Gaussian process \(\) (i.e., \(_{k}\|_{n_{k}}^{}-^{}\|_{}=0\)) and pointwise convergence (i.e., \(_{k}_{n_{k}}^{}()=^{}()\ \)).

Finally, under certain technical assumptions, Theorem 4.4 from Cockayne et al.  can be used to show that, as \( 0\), \(^{,}_{}\) converges2 to \(^{}_{}\) defined by the Radon-Nikodym derivative \(^{}_{}()(- ^{}())_{}()\) where \(_{}\) is the regular conditional probability measure \(_{}()\).

Summarizing informally, we address the nonexistence of a density-based MAP estimator by constructing a family \(\{_{}^{}\}_{>0}\) of weak modes of the related "relaxed" posteriors \(_{}}^{},}()= _{}}^{}}( d_{}}(},)+_{}=0)\) (Proposition 1). These weak modes converge to minimizers \(^{}\) of the optimization problem in Equation (3.3) as \( 0\) (Proposition 2). Moreover, under certain technical assumptions, the relaxed posteriors \(_{}}^{},}\) converge to the "true" posterior \(_{}}^{}}\) as \( 0\). Given the above, we conjecture that the \(^{}\) are weak modes of \(_{}}^{}}\), and leave the proof for future work. This motivates using the objective in Equation (3.3) to find the weak mode of the posterior measure \(_{}}^{}}\) that we wish to Laplace-approximate. The next paragraph shows how this objective becomes a valid log-density.

The FSP-Laplace objective as an unnormalized log-density.As a first step, we use Algorithm 1, discussed in detail below, to train the neural network using the objective function3

\[R_{}():=R_{}((\,\,,))=-_{i=1}^{ n} p(^{(i)}(^{(i)},))+\|(\, \,,)-\|_{_{}}}^{2}.\] (3.5)

We then intuitively want to use the same objective function to compute an approximate posterior over the weights using a Laplace approximation. For this to be well-defined, \(R_{}()\) needs to be a valid unnormalized negative log-density, i.e., \((-R_{}())\) needs to be integrable. However, without weight-space regularization, this often fails to be the case (e.g., due to continuous symmetries in weight space). Our method works around this issue by linearizing the network locally around \(^{}\) after training (see Equation (2.2)) and then applying a Laplace approximation to \(R_{}^{}() R_{}(^{}(\,\,,))\). In this case, the RKHS regularizer in \(R_{}^{}\) can be rewritten as

\[\|^{}(\,\,,)-\|_{_{ }}}^{2}=(-_{^{}})^{} _{^{}}^{}(-_{^{}})+ ,\] (3.6)

where \((_{^{}}^{})_{ij}(_{^ {}})_{i},(_{^{}})_{j}_{_{}}}\) (here, \(_{^{}}^{}\) is the Moore-Penrose pseudoinverse), \(_{i}(_{^{}})_{i},(\,\,,^{})-_{_{}}}\), \(_{^{}}^{}-_{^{}} \). Crucially, \(_{^{}}\) is positive-(semi)definite. This means that \((-R_{}^{}(\,\,))\) is normalizable over \(\,(_{^{}})\), i.e., we don't integrate over the null space. Note that this approximation also induces a (potentially degenerate) Gaussian "prior" \(}(_{^{}},_{ {w}^{}})\) over the weights.

Using model linearization, we can also establish a correspondence between the Gaussian process prior in function space and the induced prior over the weights. Namely, the resulting expression is the Lebesgue density of the \(_{}}\)-orthogonal projection of the GP prior onto the finite-dimensional subspace spanned by the "feature functions" \((_{^{}})_{i}\) learned by the neural network. Hence, our model inherits the prior structure in function space on the features induced by the Jacobian, zeroing out the probability mass in the remaining directions.

### Algorithmic Considerations

Training with the FSP-Laplace objective function.Evaluating the FSP-Laplace objective proposed in the previous section requires computing the RKHS norm of the neural network. Unfortunately, this does not admit a closed-form expression in general. Hence, we use the approximation

\[\|(\,\,,)-\|_{_{}}}^{2} (,)-())^{}(,)^{-1}((,)-())}_{=\|_{}(\,\,,)\|_{_{}}}^{2}},\] (3.7)

where \(^{n_{}}\) is a set of \(n_{}\)_context points_ and \(_{}(,)(,)( ,)^{-1}((,)-())_{}}\). The function \(_{}\) is the minimum-norm interpolant of \((\,\,,)-\) at \(\) in \(_{}}\). Hence, the estimator of the RKHS norm provably underestimates, i.e., \(\|_{}(\,\,,)\|_{_{}}}^{2}\| (\,\,,)-\|_{_{}}}^{2}\).

During training, we need to compute \(\|_{}(\,\,,)\|_{_{}}}^{2}\), at every optimizer step. Since this involves solving a linear system in \(n_{}\) unknowns and, more importantly, evaluating the neural network on the \(n_{}\) context points, we need to keep \(n_{}\) small for computational efficiency. We find that sampling an i.i.d. set of context points at every training iteration from a distribution \(_{}\) is an effective strategy for keeping \(n_{}\) small while ensuring that the neural network is appropriately regularized. The resulting training procedure is outlined in Algorithm 1.

Efficient linearized Laplace approximations of the FSP-Laplace objective.Once a minimum \(^{}\) of \(R_{}\) is found, we compute a linearized Laplace approximation at \(^{}\). The Hessian of \(R_{}\) is then

\[=_{^{}}^{}-_{i=1}^{n}_{ ^{}}(^{(i)})^{}_{^{}}^{(i)}_{^{ }}(^{(i)}).\] (3.8)

Again, the RKHS inner products in the entries of \(_{^{}}^{}\) do not admit general closed-form expressions. Hence, we use the same strategy as before to estimate \(_{^{}}^{}_{^{}}()^{ }(,)^{-1}_{^{}}()\) at another set \(\) of context points. Unlike above, for a Laplace approximation, it is vital to use a large number of context points to capture the prior beliefs well. Luckily, \(_{^{}}^{}\), only needs to be computed once, at the end of training. But for large networks and large numbers of context points, it is still infeasible to compute or even represent \(_{^{}}^{}\) in memory. To address this problem, we devise an efficient routine for computing (a square root of) the approximate posterior covariance matrix \(^{}\), outlined in Algorithm 2. Our method is _matrix-free_, i.e. it never explicitly constructs any big (i.e., \(p p\), \(p n_{}\), or \(n_{} n_{}\)) matrices in memory. This allows the method to scale to large models.

```
1:functionFSP-Laplace-Train(\(\), \(\), \((,)\), \(_{}\), \(\), \(b\))
2:for all minibatch \(=(_{},_{})\) of size \(b\)do
3:\(R_{}^{(1)}(^{(i)})-_{j=1}^{b} p( _{}^{(j)}(_{}^{(j)},)\)\(\)Negative log-likelihood
4:\((^{(j)})_{j=1}^{nc}_{}\)\(\)Sample \(n_{}\) context points
5:\(R_{}^{(2)}()((,)-())^{}(,)^{-1}((,)-())\)\(\)Equation (3.7)
6:\((R_{}^{(1)}+R_{}^{(2)}, )\)
7:return\(\) ```

**Algorithm 1** RKHS-regularized model training

We start by computing a rank \(r(n_{}d^{},p)\) approximation of the (pseudo-)inverted kernel Gram matrix \((,)^{}^{}\) using fully-reorthogonalized Lanczos iteration [23, Section 10.1] with an embedded \(^{}\)-factorization [23, Section 11.3.5]. This only needs access to matrix-vector products with \((,)\), which can be implemented efficiently without materializing the matrix in memory. Moreover, kernel Gramians typically exhibit rapid spectral decay [see e.g., 24], which makes the low-rank approximation particularly accurate. The low-rank factors \(\) then yield a rank \(r\) approximation of \(_{^{}}^{}^{}\) with \(:=_{^{}}()^{}\), which is embarassingly parallel and can be computed using backward-mode autodiff to avoid materializing the network Jacobians in memory. An eigendecomposition of \(^{}=_{}_{}^{}_{}^{}\) can be computed in \((pr^{2})\) time from a thin SVD of \(=_{}_{}_{}^{}\). The eigenvectors \(_{}\) define an orthogonal projector \(_{}_{}^{}\) onto the range and an orthogonal projector \(_{0}-_{}_{}^{}\) onto the nullspace of \(^{}\). This means that we have the decomposition \(=^{}+_{0}_{0}^{ }=_{}_{}^{}+_{0}_ {0}^{}\) with

\[_{}^{}_{}=_{} ^{2}-_{i=1}^{n}_{}^{}_{^{}}(^{(i)}) ^{}_{^{}}^{(i)}_{^{}}(^{(i)}) _{}.\] (3.9)We find that \(_{0}_{0}^{}\) is negligible in practice, and hence, we approximate \(_{}_{}^{}\) (see Table C.2).

Finally, by computing an eigendecomposition of \(=_{}_{}_{}^{}^{r r}\) in \((r^{3})\) time, we obtain an eigendecomposition of \(_{}_{}^{}=(_ {}_{})_{}(_{}_{})^{}\), which can be used to obtain a matrix-free representation of (a square root of) the (pseudo-)inverse of \(\). Unfortunately, due to numerical imprecision, it is difficult to distinguish between zero eigenvalues of \(\) and those with small positive magnitudes. Since we need to pseudo-invert the matrix to obtain the covariance matrix, this can explode predictive variance. As a remedy, we use a heuristic based on the observation that, in a linear-Gaussian model, the marginal variance of the posterior is always upper-bounded by the marginal variance of the prior. Hence, we impose that \(_{^{*}}(_{i})^{ }_{^{*}}(_{i})( _{i},_{i})\) for all \(i=1,,n_{}\) by successively truncating the smallest eigenvalues in \(_{}\) until the condition is fulfilled. This turns out to be an effective strategy to combat exploding predictive variance in practice.

Choice of context points.Methods for regularizing neural networks in function space rely on a set of context points to evaluate the regularizer [8; 9; 25; 26]. The context points should cover the set of input locations where it is plausible that the model might be evaluated when deployed. Popular strategies include uniform sampling from a bounded subset of the input space [8; 9; 25; 26], from the training data , and from additional (possibly unlabeled) datasets [25; 26]. For MAP estimation, we choose a uniform context point distribution \(_{}\) or sample from other datasets for high-dimensional inputs. We compute the posterior covariance using samples \(\) from a low-discrepancy sequence, which effectively cover high-dimensional spaces.

## 4 Experiments

We evaluate FSP-Laplace on synthetic and real-world data, demonstrating that our method effectively incorporates beliefs specified through a GP prior; that it improves performance on regression tasks for which we have prior knowledge in the form of a kernel (Mauna Loa and ocean current modeling); and that it shows competitive performance on regression, classification, out-of-distribution detection, and Bayesian optimization tasks compared to baselines.

Baselines.We compare FSP-Laplace to a deterministic neural network fit using maximum a-posteriori estimation with an isotropic Gaussian prior on the weights (MAP) and a neural network for which we additionally compute the standard linearized Laplace approximation (Laplace) . We further compare our method to FVI , which uses GP priors with VI, to a Gaussian process (GP)  when the size of the dataset allows it, and to a sparse Gaussian process (sparse GP) . We use the full Laplace approximation when the size of the neural network allows it, and otherwise consider the K-FAC or diagonal approximations . All neural networks share the same architecture.

Qualitative evaluation on synthetic data.We consider two synthetic data tasks: a \(1\)-dimensional regression task with randomly drawn noisy measurements of the function \(y=(2 x)\), and the \(2\)-dimensional two-moons classification task from the scikit-learn library . For the regression task, data points are shown as gray circles, functions drawn from the posterior as green lines and the inferred mean function as a red line (see Figures 1 and C.1 to C.4). For the classification task, we plot the predictive mean and 2-standard-deviations of the predictions for class \(1\) (blue circles) in Figures C.5 and C.6. We apply FSP-Laplace to the data with different GP priors and find that it successfully adapts to the specified beliefs. For instance, by varying the GP prior, we can make our method generate functions that are periodic within the support of the context points (Figure C.2), and control their smoothness (Figure 1) and length scale (Figure C.3) without modifying the network's architecture, or adding features. Such flexibility is impossible with the isotropic Gaussian weight-space priors used in the Laplace and MAP baselines. These results carry over to classification, where our method shows a smooth decision boundary when equipped with an RBF kernel (Figure C.6), and a rough decision boundary when equipped with a Matern-1/2 kernel (Figure C.5). Unlike the Laplace and MAP baselines, whose predictions remain confident beyond the support of the data, the FSP-Laplace's posterior mean reverts to the zero-mean prior, and its posterior variance increases. Our method also captures the properties specified by the GP prior better than FVI, especially for rougher Matern-1/2 kernels (Figures 1 and C.5). While a sufficient number of context points is necessary to capture the beliefs specified by the GP prior, we find that, even with a very small number 

[MISSING_PAGE_FAIL:8]

strongly improves over Laplace, FVI and GP in terms of expected log-likelihood, and performs competitively in terms of mean squared error (MSE). FSP-Laplace also improves MSE and test expected log-likelihood over FVI, which strongly underestimates the predictive variance.

Image classification.We further evaluate our method on the MNIST  and FashionMNIST  image classification datasets using a convolutional neural network. We compare our model to FVI, Laplace, MAP, and Sparse GP baselines, as the scale of the datasets forbids exact GP inference. For FSP-Laplace and FVI, we compare using context points drawn from a uniform distribution (RND) and drawn from the Kuzushiji-MNIST dataset (KMNIST) following the setup by Rudner et al. . Results are presented in Table 2. Although these datasets are particularly challenging to our method, which is regularized in function space, we find that FSP-Laplace performs strongly and matches or exceeds the expected log-likelihood and predictive accuracy of best-performing baselines. It also yields well-calibrated models with low expected calibration error (ECE).

Out-of-distribution detection.We now investigate whether the epistemic uncertainty of FSP-Laplace is predictive for out-of-distribution detection (OOD). We follow the setup by Osawa et al.  and report the accuracy of a single threshold to classify OOD from in-distribution (ID) data based on the predictive uncertainty. Additional details are provided in Appendix B.2. FSP-Laplace with context points sampled from KMNIST performs strongly, obtaining the highest out-of-distribution detection accuracy (see Table 2, note that FSP-Laplace makes no assumption on whether context points are in or out of distribution). This can be further observed in Figure C.10 in the Appendix, where the predictive entropy of ID data points is tightly peaked around \(0\), whereas the predictive entropy of OOD data points is highly concentrated around the maximum entropy of the softmax distribution (\((10) 2.3\)). With RND context points, our method performs comparably to the Laplace baseline.

Bayesian optimization.We finally evaluate the epistemic uncertainty of FSP-Laplace as a surrogate model for Bayesian optimization. We consider a setup derived from Li et al. , comparing to FVI, the linearized Laplace, and to a GP. Results are summarized in Figure 3. We find that our method performs particularly well on lower-dimensional tasks, where it converges both faster and to higher rewards than Laplace, and noticeably strongly improves over a Gaussian process on PDE. On higher-dimensional tasks, our method performs comparatively well to Laplace and GP baselines.

   Dataset & Metrics & FSP-Laplace(SENS) & FSP-Laplace(RND) & FVI (KMNIST) & FVI (RND) & Laplace & MAP & Sparse GP \\   & Local-likelihood (\(\)) & -0.013 \(\) 0.001 & **-0.037 \(\) 0.001** & -0.278 \(\) 0.006 & -0.145 \(\) 0.005 & -0.013 \(\) 0.001 & -0.039 \(\) 0.001 & -0.501 \(\) 0.002 \\  & Accuracy (\(\)) & **0.398 \(\) 0.000** & **0.598 \(\) 0.000** & 0.943 \(\) 0.001 & 0.976 \(\) 0.001 & **0.899 \(\) 0.001** & 0.937 \(\) 0.000 & 0.940 \(\) 0.001 \\  & ECE (\(\)) & **0.002 \(\) 0.000** & **-0.002 \(\) 0.000** & 0.073 \(\) 0.003 & 0.064 \(\) 0.001 & 0.003 \(\) 0.000 & 0.033 \(\) 0.001 \\  & OOD accuracy (\(\)) & **0.977 \(\) 0.003** & 0.955 \(\) 0.011 & 0.951 \(\) 0.004 & 0.984 \(\) 0.010 & 0.997 \(\) 0.010 & 0.589 \(\) 0.009 & 0.904 \(\) 0.020 \\   & Local-likelihood (\(\)) & **0.355 \(\) 0.002** & **-0.359 \(\) 0.013** & -0.311 \(\) 0.000 & **0.310 \(\) 0.005** & 0.759 \(\) 0.006 & 0.511 \(\) 0.004 & 0.478 \(\) 0.003 \\  & Accuracy (\(\)) & **0.395 \(\) 0.001** & **0.399 \(\) 0.001** & 0.916 \(\) 0.002 & **0.916 \(\) 0.002** & 0.957 \(\) 0.002 & 0.900 \(\) 0.001 & 0.845 \(\) 0.001 \\  & OOD accuracy (\(\)) & **0.018 \(\) 0.002** & 0.020 \(\) 0.003 & 0.024 \(\) 0.002 & 0.027 \(\) 0.005 & **0.641 \(\) 0.002** & **0.616 \(\) 0.002** & 0.827 \(\) 0.001 \\  & OOD accuracy (\(\)) & **0.924 \(\) 0.001** & 0.797 \(\) 0.002 & 0.975 \(\) 0.002 & 0.925 \(\) 0.005 & 0.801 \(\) 0.014 & 0.794 \(\) 0.010 & 0.938 \(\) 0.007 \\   

Table 2: Test expected log-likelihood, accuracy, expected calibration error and OOD detection accuracy on MNIST and FashionMNIST. FSP-Laplace performs strongly among baselines matching the accuracy of best-performing baselines and obtaining the highest expected log-likelihood and out-of-distribution detection accuracy.

Figure 3: Results using our method (FSP-Laplace) as a surrogate model for Bayesian optimization. We find that FSP-Laplace performs particularly well on lower-dimensional problems, where it converges more quickly and to higher rewards than the Laplace, obtaining comparable scores as the Gaussian process (GP).

Related work

Laplace approximation in neural networks.First introduced by MacKay , the Laplace approximation gained strong traction in the Bayesian deep learning community with the introduction of scalable log-posterior Hessian approximations [28; 38], and the so-called linearized Laplace, which solves the underfitting issue observed with standard Laplace [17; 39; 40; 41]. In addition to epistemic uncertainty estimates, the Laplace approximation also provides a method to select prior parameters via marginal likelihood estimation [11; 12]. Recent work has made the linearized Laplace more scalable by restricting inference to a subset of parameters , by exploiting its GP formulation  to apply methods from the scalable GP literature [43; 44; 45], or by directly sampling from the Laplace approximation without explicitly computing the covariance matrix . While these approaches use the GP formulation to make the linearized Laplace more scalable, we are unaware of any method that uses GP priors to incorporate interpretable prior beliefs within the Laplace approximation.

BNNs with function-space priors.In the context of variational inference, function-space priors in BNNs demonstrate improvements in predictive performance compared to weight-space priors . While this idea might seem sound, it turns out that the KL divergence in the VI objective is infinite for most cases of interest due to mismatching supports between the function-space prior and BNN's predictive posterior , which therefore requires additional regularization to be well defined . Due to this issue, other work  considers generalized VI  using the regularized KL divergence  or abandons approximating the neural network's posterior and instead uses deterministic neural networks as basis functions for Bayesian linear regression  or for the mean of a sparse GP . In contrast, our method does not compute a divergence in function space, but only the RKHS norm under the prior's kernel, thus circumventing the issue of mismatching support. Alternatively, rather than directly placing a prior on the function generated by a BNN, researchers have investigated methods to find weight-space priors whose pushforward approximates a target function-space measure by minimizing a divergence [9; 50], using the Ridgelet transform , or changing the BNN's architecture .

Regularizing neural networks in function space.Arguing that one ultimately only cares about the output function of the neural network, it has been proposed to regularize neural networks in function space, both showing that norms could be efficiently estimated and that such regularization schemes performed well in practice [53; 54; 26; 55]. Unlike FSP-Laplace, none of these methods allow to specify informative beliefs via a GP prior. Our method uses the same RKHS norm estimator as Chen et al.  (however, under a different kernel) by sampling a new batch of context points at each update step. Similarly, Rudner et al.  propose an empirical prior on the weights that regularizes the neural network in function space, which they use for MAP estimation or approximate posterior inference. The MAP objective resembles ours, but unlike our method, uses the kernel induced by the last layer of the neural network and includes an additional Gaussian prior on the weights.

## 6 Conclusion

We propose a method for applying the Laplace approximation to neural networks with interpretable Gaussian process priors in function space. This addresses the issue that conventional applications of approximate Bayesian inference methods to neural networks require posing a prior in weight space, which is virtually impossible because weight space is not interpretable. We address the non-existence of densities in (infinite-dimensional) function space by generalizing the notion of a MAP estimate to the limit of a sequence of weak modes of related posterior measures, leading us to propose a simple objective function. We further mitigate the computational cost of calculating high-dimensional curvature matrices using scalable methods from matrix-free linear algebra. By design, our method works best in application domains where prior information can be encoded in the language of Gaussian processes. This is confirmed by experiments on scientific data and Bayesian optimization. In high-dimensional spaces, where explicit prior knowledge is difficult to state, Gaussian process priors are naturally at a disadvantage. While we do demonstrate superior performance on image data, it is yet unclear how to find good function-space priors in such high-dimensional spaces.

[MISSING_PAGE_FAIL:11]

* Immer et al.  Alexander Immer, Maciej Korzepa, and Matthias Bauer. Improving predictions of bayesian neural nets via local linearization, 2021.
* Oxtoby  John C. Oxtoby. Invariant measures in groups which are not locally compact. _Transactions of the American Mathematical Society_, 60:215-237, 1946. doi: 10.1090/S0002-9947-1946-0018188-5.
* Pfortner et al.  Marvin Pfortner, Ingo Steinwart, Philipp Hennig, and Jonathan Wenger. Physics-informed Gaussian process regression generalizes linear PDE solvers, 2022.
* Lambley  Hefin Lambley. Strong maximum a posteriori estimation in Banach spaces with Gaussian priors. _Inverse Problems_, 39(12):125010, 2023. doi: 10.1088/1361-6420/ad07a4.
* Chen et al.  Yifan Chen, Bamdad Hosseini, Houman Owhadi, and Andrew M. Stuart. Solving and learning nonlinear PDEs with Gaussian processes. _Journal of Computational Physics_, 447, 2021. doi: 10.1016/j.jcp.2021.110668.
* Cockayne et al.  Jon Cockayne, Chris J. Oates, T. J. Sullivan, and Mark Girolami. Bayesian probabilistic numerical methods. _SIAM Review_, 61(4):756-789, 2019. doi: 10.1137/17M1139357.
* Golub and Van Loan  Gene H. Golub and Charles F. Van Loan. _Matrix Computations_. Johns Hopkins Studies in the Mathematical Sciences. The Johns Hopkins University Press, Baltimore, fourth edition, 2013.
* I, 2024. URL https://francisbach.com/spectrum-kernel-matrices-i/.
* Rudner et al.  Tim G. J. Rudner, Zonghao Chen, Yee Whye Teh, and Yarin Gal. Tractable function-space variational inference in bayesian neural networks, 2023.
* Rudner et al.  Tim G. J. Rudner, Sanyam Kapoor, Shikai Qiu, and Andrew Gordon Wilson. Function-space regularization in neural networks: A probabilistic perspective, 2023.
* Hensman et al.  James Hensman, Nicolo Fusi, and Neil D. Lawrence. Gaussian processes for big data, 2013.
* Ritter et al.  Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural networks. In _International Conference on Learning Representations_, 2018. URL https://openreview.net/forum?id=Skdvd2xAZ.
* Pedregosa et al.  F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. _Journal of Machine Learning Research_, 12:2825-2830, 2011.
* Keeling and Whorf  Charles D Keeling and T P Whorf. Monthly carbon dioxide measurements on Mauna Loa, Hawaii from 1958 to 1998, 2000. URL https://doi.org/10.1594/PANGAAE.56536.
* Lilly and Perez-Brunius  Jonathan M. Lilly and Paula Perez-Brunius. GulfDrifters: A consolidated surface drifter dataset for the Gulf of Mexico, January 2021. URL https://doi.org/10.5281/zenodo.4421585.
* Shalashilin  Ivan Shalashilin. Gaussian processes for vector fields and ocean current modelling, March 2024. URL https://docs.jaxgaussianprocesses.com/examples/oceanmodelling/.
* Berlinghieri et al.  Renato Berlinghieri, Brian L. Trippe, David R. Burt, Ryan Giordano, Kaushik Srinivasan, Tamay Ozgokmen, Junfei Xia, and Tamara Broderick. Gaussian processes at the helm(holtz): A more fluid model for ocean currents, 2023.
* LeCun and Cortes  Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http://yann.lecun.com/exdb/mnist/.
* Xiao et al.  Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms, 2017.
* Osawa et al.  Kazuki Osawa, Siddharth Swaroop, Anirudh Jain, Runa Eschenhagen, Richard E. Turner, Rio Yokota, and Mohammad Emtiyaz Khan. Practical deep learning with bayesian principles, 2019.
* MacKay  David John Cameron MacKay. Bayesian methods for adaptive models. 1992. URL https://api.semanticscholar.org/CorpusID:123141880.
* Martens  James Martens. New insights and perspectives on the natural gradient method, 2020.
* Khan et al.  Mohammad Emtiyaz Khan, Alexander Immer, Ehsan Abedi, and Maciej Korzepa. Approximate inference turns deep networks into gaussian processes, 2020. URL https://arxiv.org/abs/1906.01930.

*  Andrew Y. K. Foong, Yingzhen Li, Jose Miguel Hernandez-Lobato, and Richard E. Turner. 'in-between' uncertainty in bayesian neural networks, 2019.
*  Mohammad Emtiyaz Khan and Siddharth Swaroop. Knowledge-adaptation priors, 2021. URL https://arxiv.org/abs/2106.08769.
*  Erik Daxberger, Eric Nalisnick, James Urquhart Allingham, Javier Antoran, and Jose Miguel Hernandez-Lobato. Bayesian deep learning via subnetwork inference, 2022.
*  Zhijie Deng, Feng Zhou, and Jun Zhu. Accelerated linearized laplace approximation for bayesian deep learning, 2022.
*  Luis A. Ortega, Simon Rodriguez Santana, and Daniel Hernandez-Lobato. Variational linearized laplace approximation for bayesian deep learning, 2024.
*  Aidan Scannell, Riccardo Mereu, Paul Edmund Chang, Ella Tamir, Joni Pajarinen, and Arno Solin. Function-space parameterization of neural networks for sequential learning. In _The Twelfth International Conference on Learning Representations_, 2024. URL https://openreview.net/forum?id=2dhxx1Khqz.
*  Javier Antoran, Shreyas Padhy, Riccardo Barbano, Eric Nalisnick, David Janz, and Jose Miguel Hernandez-Lobato. Sampling-based inference for large linear models, with application to linearised laplace, 2023.
*  Tristan Cinquin and Robert Bamler. Regularized kl-divergence for well-defined function-space variational inference in bayesian neural networks, 2024. URL https://arxiv.org/abs/2406.04317.
*  Minh Ha Quang. Regularized divergences between covariance operators and gaussian measures on hilbert spaces, 2019.
*  Veit D. Wild, Robert Hu, and Dino Sejdinovic. Generalized variational inference in function spaces: Gaussian measures meet bayesian deep learning, 2022.
*  Daniel Flam-Shepherd. Mapping gaussian process priors to bayesian neural networks. 2017. URL https://api.semanticscholar.org/CorpusID:160026812.
*  Takuo Matsubara, Chris J. Oates, and Francois-Xavier Briol. The ridgelet prior: A covariance function approach to prior specification for bayesian neural networks, 2022.
*  Tim Pearce, Russell Tsuchida, Mohamed Zaki, Alexandra Brintrup, and Andy Neely. Expressive priors in bayesian neural networks: Kernel combinations and periodic functions, 2019.
*  Ari S. Benjamin, David Rolnick, and Konrad Kording. Measuring and regularizing networks in function space, 2019.
*  Zonghao Chen, Xupeng Shi, Tim G. J. Rudner, Qixuan Feng, WEIZHONG ZHANG, and Tong Zhang. A neural tangent kernel perspective on function-space regularization in neural networks. In _OPT 2022: Optimization for Machine Learning (NeurIPS 2022 Workshop)_, 2022. URL https://openreview.net/forum?id=E6MGIXQ1Kw.
*  Shikai Qiu, Tim G. J. Rudner, Sanyam Kapoor, and Andrew Gordon Wilson. Should we learn most likely functions or parameters?, 2023.
*  Nathael Da Costa, Marvin Pfortner, Lancelot Da Costa, and Philipp Hennig. Sample path regularity of Gaussian processes from the covariance kernel, 2023.
*  Motonobu Kanagawa, Philipp Hennig, Dino Sejdinovic, and Bharath K. Sriperumbudur. Gaussian processes and kernel methods: A review on connections and equivalences, 2018.
*  M. Dashti, K. J. H. Law, A. M. Stuart, and J. Voss. MAP estimators and their consistency in Bayesian nonparametric inverse problems. _Inverse Problems_, 29(9), September 2013. doi: 10.1088/0266-5611/29/9/095017.
*  John B. Conway. _A Course in Functional Analysis_, volume 96 of _Graduate Texts in Mathematics_. Springer, New York, NY, second edition, 1997. doi:10.1007/978-1-4757-4383-8.
*  Vladimir Igorevich Bogachev. _Gaussian Measures_, volume 62 of _Mathematical Surveys and Monographs_. American Mathematical Society, Providence, Rhode Island, 1998.
*  Dimitrios Milios, Raffaello Camoriano, Pietro Michiardi, Lorenzo Rosasco, and Maurizio Filippone. Dirichlet-based gaussian processes for large-scale calibrated classification. InS. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, _Advances in Neural Information Processing Systems_, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper_files/paper/2018/file/b6617980ce90f637e68c3be8b9be745-Paper.pdf.
* Clanuwat et al.  Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Yamamoto Kazuaki, and David Ha. Deep learning for classical japanese literature, 12 2018.
* HALTON  J.H. HALTON. On the efficiency of certain quasi-random sequences of points in evaluating multi-dimensional integrals. _Numerische Mathematik_, 2:84-90, 1960. URL http://eudml.org/doc/131448.
* Kingma and Ba  Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.
* Biewald  Lukas Biewald. Experiment tracking with weights and biases, 2020. URL https://www.wandb.com/. Software available from wandb.com.
* Chen et al.  Hao Chen, Lili Zheng, Raed Al Kontar, and Garvesh Raskutti. Gaussian process inference using mini-batch stochastic gradient descent: Convergence guarantees and empirical benefits, 2021.
* Mckay et al.  M. Mckay, Richard Beckman, and William Conover. A comparison of three methods for selecting vales of input variables in the analysis of output from a computer code. _Technometrics_, 21:239-245, 05 1979. doi: 10.1080/00401706.1979.10489755.
* Balandat et al.  Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. BoTorch: A Framework for Efficient Monte-Carlo Bayesian Optimization. In _Advances in Neural Information Processing Systems 33_, 2020. URL http://arxiv.org/abs/1910.06403.
* Dua and Graff  Dheeru Dua and Casey Graff. Uci machine learning repository, 2017. URL http://archive.ics.uci.edu/ml.
* Malinin et al.  Andrey Malinin, Liudmila Prokhorenkova, and Aleksei Ustimenko. Uncertainty in gradient boosting via ensembles, 2021.
* Bertin-Mahieux et al.  Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. The million song dataset. In _Proceedings of the 12th International Conference on Music Information Retrieval (ISMIR 2011)_, 2011.
* Bradbury et al.  James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin, George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composable transformations of Python+NumPy programs, 2018. URL http://github.com/google/jax.
* Hennigan et al.  Tom Hennigan, Trevor Cai, Tamara Norman, Lena Martens, and Igor Babuschkin. Haiku: Sonnet for JAX, 2020. URL http://github.com/deepmind/dm-haiku.
* Botev and Martens  Aleksandar Botev and James Martens. KFAC-JAX, 2022. URL https://github.com/google-deepmind/kfac-jax.
* Sensoy et al.  Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classification uncertainty, 2018. URL https://arxiv.org/abs/1806.01768.

## Appendix A Theory

### Assumptions and their applicability

**Assumption A.1**.: \((,)\) is a \(d^{}\)-output Gaussian process with index set \(\) on \((,,)\) such that

1. the paths of \(\) lie (\(\)-almost surely) in a real separable Banach space \(\) of \(^{d^{}}\)-valued functions on \(\) with continuous point evaluation maps \(_{}^{d^{}}\), and
2. \((,)\) is a Gaussian random variable with values in \((,())\).

We denote the law of \((,)\) by \(_{}\).

For this paper, we focus on \(=C()\), with \(\) being a compact metric space. In this case, Assumption A.1(i) can be verified from regularity properties of the prior covariance function \(\)[see, e.g., 56]. Moreover, the sufficient criteria from Pfortner et al. [19, Section B.2] show that Assumption A.1(ii) also holds in this case.

**Assumption A.2**.: The potential \(^{}\) is (norm-)continuous and, for each \(>0\), there is \(K()\) such that \(^{}() K()-\|\|_{}^{2}\) for all \(\).

This holds if the negative log-likelihood functions \(^{(i)}^{d^{}},^{(i)}- p (^{(i)}^{(i)})\) are continuous and, for all \(>0\), there is \(K()\) such that \(^{(i)}(^{(i)})>K(^{(i)})+\|^{(i)}\|^{2}\) for all \(^{(i)}^{d^{}}\). For instance, this is true for a Gaussian likelihood \(^{(i)}(^{(i)})=^{2}}\|^{(i)}-^{(i)} \|_{2}^{2}\).

**Assumption A.3**.: (i) \(_{}\) is nonempty, (ii) \(_{}\) is closed in \(_{}\), and (iii) \(_{}\) has the Heine-Borel property, i.e., all closed and bounded subsets of \(_{}\) are compact in \(\).

Assumption A.3(i) can be verified using a plethora of results from RKHS theory. For instance, for Sobolev kernels like the Matern family used in the experiments, the RKHS is norm-equivalent to a Sobolev space [see, e.g., 57]. In this case, we only need the NN to be sufficiently often (weakly) differentiable on the interior of its compact domain \(\). The closure property from Assumption A.3(ii) is more difficult to verify directly. However, if we assume that \(\) is compact and that the map \(,(,)\) is continuous, then \(\) is compact (and hence closed) as the image of a compact set under a continuous function. This is a reasonable assumption, since, in practice, the weights of a neural network are represented as machine numbers with a maximal magnitude, meaning that \(\) is always contained in an \(_{}\) ball of fixed radius. Incidentally, compactness of \(\) also entails the Heine-Borel property from Assumption A.3(iii). Alternatively, \(\) also has the Heine-Borel property if it is a topological manifold (e.g., a Banach manifold), since it is necessarily finite-dimensional.

### Proofs

**Lemma A.1**.: _Let \((,d)\) be a metric space, \(\) nonempty, and_

\[d(,)_{ 0},x_{a }d(x,a).\]

_Then \(d(,)\) is 1-Lipschitz._

Proof.: For all \(x_{1},x_{2}\) we have

\[d(x_{2},) =_{a}d(x_{2},a)\] \[ d(x_{2},x_{1})+_{a}d(x_{1},a)\] \[=d(x_{1},x_{2})+d(x_{1},)\]

by the triangle inequality and hence \(d(x_{2},)-d(x_{1},) d(x_{1},x_{2})\). Since this argument is symmetric in \(x_{1}\) and \(x_{2}\), this also shows that

\[-(d(x_{2},)-d(x_{1},))=d(x_{1},)-d(x_{2}, ) d(x_{2},x_{1})=d(x_{1},x_{2}).\]

All in all, we obtain \(|d(x_{2},)-d(x_{1},)| d(x_{1},x_{2})\)

**Lemma A.2**.: _Let \((,d)\) be a metric space and \(\) a closed, nonempty subset with the Heine-Borel property. Then \(_{a}d(x,a)\) is attained for all \(x\)._

Proof.: Let \(x\) and \(r>r_{x}:=_{a}d(x,a)\). Then \(_{r}(x)\) as well as \(d(x,a)>r\) for all \(a_{r}(x)\) and thus \(_{a}d(x,a)=_{a_{r}(x)}d(x,a)\). Moreover, \(_{r}(x)\) is compact by the Heine-Borel property and \(d(x,\,\,)\) is continuous. Hence, the claim follows from the Weierstrass extreme value theorem. 

**Proposition 1**.: _Let Assumptions A.1 to A.3 hold. For \(>0\), define \(^{,},^{ }()+}d_{}^{2}(,)\). Then the posterior measure \(_{}^{,}(\!) (-^{,}(\!)) _{}(\!)\) has at least one weak mode \(^{}_{}\), and the weak modes of \(_{}^{,}\) coincide with the minimizers of_

\[R_{}^{}_{}, ^{,}()+\|-\|_{_{}}^{2}.\] (3.4)

Proof.: \(d_{}(\,\,,)\) is (globally) 1-Lipschitz by Lemma A.1 and bounded from below by 0. Hence, \(^{,}=^{}+}d_{}^{2}( \,\,,)\) is continuous and for all \(>0\), there is \(K()\) such that

\[^{,}() K()-\|\|_{}^{2}+ }d_{}^{2}(,)}_{  0} K()-\|\|_{}^{2}\]

by Assumption A.2. The statement then follows from Theorem 1.1 in Lambley . 

**Proposition 2**.: _Let Assumptions A.1 to A.3 hold. Let \(\{_{n}\}_{n}_{>0}\) with \(_{n} 0\), and \(\{_{n}^{}\}_{n}_{}\) such that \(_{n}^{}\) is a minimizer of \(R_{}^{_{n}}\). Then \(\{_{n}^{}\}_{n}\) has an \(_{}\)-weakly convergent subsequence with limit \(^{}_{}\). Moreover, \(^{}\) is a minimizer of \(R_{}\) on \(_{}\)._

Our proof makes use of ideas from Dashti et al.  and Lambley .

Proof.: Without loss of generality, we assume \(=\). By Assumption A.2, there are constants \(K,>0\) such that \(R_{}() K+\|\|_{_{}}^{2}\) for all \(_{}\)[20, Section 4.1]. Now fix an arbitrary \(_{}\). Then

\[R_{}() =R_{}^{_{n}}()\] \[ R_{}^{_{n}}(_{n}^{})\] \[=R_{}(_{n}^{})+^{2}}d_{ }^{2}(_{n}^{},)\] (A.1) \[ K+\|_{n}^{}\|_{_{}}^{2},\] \[ K+\|_{n}^{}\|_{_{}}^{2},\]

and hence

\[\|_{n}^{}\|_{_{}}^{2} (R_{}()-K),\]

i.e. the sequence \(\{_{n}^{}\}_{n}_{}\) is bounded. By the Banach-Alaoglu theorem [59, Theorems V.3.1 and V.4.2(d)] and the Eberlein-Smulian theorem [59, Theorem V.13.1], there is a weakly convergent subsequence \(\{_{n_{k}}^{}\}_{k}\) with limit \(^{}_{}\).

We need to show that \(^{}\). From Equation (A.2), it follows that

\[0 d_{}(_{n_{k}}^{},)_{n_{k}} }()-K-\|_{n_{k}}^{}\|_{_ {}}^{2})}_{n_{k}}}()-K)},\]

where the right-hand side converges to 0 as \(k\). Hence, \(_{k}d_{}(_{n_{k}}^{},)=0\). The embedding \(_{}\) is compact [60, Corollary 3.2.4] and, by Lemma A.1, \(d_{}(\,\,,)\) is continuous, which implies that \(d_{}(\,\,|\,)_{} \) is sequentially weakly continuous. Hence, \(d_{}(^{},)=_{k}d_{}(_ {n_{k}}^{},)=0\) and, by Assumption A.3 and Lemma A.2, it follows that \(^{}\).

Finally, we show that \(^{}\) is a minimizer of \(R_{}\) on \(_{}\). Since \(^{}\) is continuous and \(\) is compact, \(^{}_{}\) is sequentially weakly continuous. Moreover, we have \(_{k}^{}_{n_{k}}_{_{}}^{2}^{}_{_{}}^{2}\), since Hilbert norms are sequentially weakly lower-semicontinuous. Hence, \(_{k}R_{}(^{}_{n_{k}}) R_{}( ^{})\). Now, by Equation (A.1),

\[R_{}() R_{}(^{})+_{k} }^{2}}d_{}^{2}(^{}_{n_{k}},),\]

for all \(_{}\). For \(=^{}\) this implies that \(_{k}}^{2}}d_{}^{2}(^{ }_{n_{k}},)=0\). All in all, we arrive at \(R_{}() R_{}(^{})\) for all \(_{}\), i.e. \(^{}\) is a minimizer of \(R_{}\). 

## Appendix B Experimental setup

### Qualitative experiments with synthetic data

Regression.We sample points from the corresponding generative model

\[y_{i}=(2 x_{i})+ (0,_{n}^{2})\] (B.1)

using \(_{n}=0.1\) and draw \(x_{i}([-1,-0.5][0.5,1])\). We plot data points as gray circles, functions sampled from the approximate posterior as green lines, the empirical mean function as a red line and its empirical 2-standard-deviation interval around the mean as a green surface. All neural networks have the same two hidden-layer architecture with \(50\) neurons per layer and hyperbolic tangent (\(\)) activation functions. For FSP-Laplace, we use \(100\) context points placed on a regular grid and run a maximum of \(500\) Lanczos iterations. For FVI, we sample \(100\) context points drawn from \(([-2,2])\) at each update. Except when stated otherwise, we consider a centered GP prior and find the parameters of the covariance function by maximizing the log-marginal likelihood . For the Laplace, we use the full generalized Gauss-Newton matrix and an isotropic Gaussian prior with scale \(_{p}=1\). The MAP estimate uses the same prior. We find the parameters of the Gaussian process priors by maximizing the log-marginal likelihood and the parameters of the sparse GP by maximizing the evidence lower bound .

Classification.We sample randomly perturbed data points from the two moons data  with noise level \(_{n}=0.1\). We plot the the data points from class 0 as red dots and those from class 1 as blue dots. We show the mean (upper row) and 2-standard-deviation (bottom row) of the probability that a sample \(\) belongs to class 1 under the approximate posterior, which we estimate using \(K=100\) samples. We consider a two hidden-layer neural network with \(100\) neurons per layer and hyperbolic tangent activation functions. For FSP-Laplace, we use \(100\) context points placed on a regular grid over \([-3.75,3.75][-3.75,3.75]\) and limit Lanczos to run for at most \(500\) iterations. For FVI, we sample \(100\) context points from \(([-3.75,3.75]^{2})\) at each update. We consider a centered GP prior and find the parameters of the covariance function by maximizing the log-marginal likelihood  using the reparameterization of classifications labels into regression targets from Milios et al. . For the Laplace, we use the full generalized Gauss-Newton matrix and an isotropic Gaussian prior with scale \(_{p}=1\). The MAP estimate uses the same prior. For the Gaussian process, we Laplace-approximate the intractable GP posterior and find the prior parameters by maximizing the log-marginal likelihood . Sparse GP parameters are found by maximizing the ELBO .

### Quantitative experiments with real-world data

Mauna Loa.We consider the Mauna Loa dataset which tracks the monthly average atmospheric CO\({}_{2}\) concentration at the Mauna Loa observatory in Hawaii from 1974 to 2024 . We consider the first \(70\%\) of the data in chronological order as the train set (from 1974 to 2005) and the last \(30\%\) as the test set (from 2009 to 2024). We standardize the features (time) and regression targets (CO\({}_{2}\) concentration). We use two hidden-layer neural networks with hyperbolic tangent activations and \(50\) units each. We augment the input of the neural networks with an additional sine and cosine transformation of the features i.e., we use the feature vectors \((t_{i},(2 t_{i}/T),(2 t_{i}/T))\) where \(t_{i}\) is the time index and \(T\) is the period used in Rasmussen and Williams . For FSP-Laplace, we use \(100\) context points placed on a regular grid and limit Lanczos to run at most \(500\) iterations. For FVI, we draw uniformly \(100\) context points at each update. For Laplace, we use the full generalized Gauss-Newton matrix and find the prior scale by maximizing the marginal likelihood .

Ocean current modeling.We consider the GulfDrifters dataset  and we follow the setup by Shalashilin . We use as training data \(20\) simulated velocity measurements (red arrows in Figure 2), and consider as testing data \(544\) average velocity measurements (blue arrows in Figure 2) computed over a regular grid on the \([-90.8,-83.8][24.0,27.5]\) longitude-latitude interval. We standardize both features and regression targets. We incorporate physical properties of ocean currents into the models by applying the Helmholtz decomposition to the GP prior's covariance function  as well as to the neural network \(f\) using the following parameterization

\[f(,)=(,_{1})+ (,_{2})\] (B.2)

where \(=\{_{1},_{2}\}\) and \((,_{1})\) and \((,_{2})\) are two hidden-layer fully-connected neural networks with hyperbolic tangent activation functions and \(100\) hidden units per layer. We use \(96\) context points placed on a regular grid for the FSP-Laplace and limit Lanczos to run at most \(500\) iterations. For FVI, we use the same \(96\) context points. For the linearized Laplace, we use the full generalized Gauss-Newton (GGN) and fix the prior scale to \(_{p}=1\).

Image classification.We consider the MNIST  and FashionMNIST  image classification datasets. We standardizing the images, fit the models on a random partition of \(90\%\) of the provided train splits, keeping the remaining \(10\%\) as validation data, and evaluate the models on the test data. We report mean and standard-errors across \(5\) such random partitions of the train data with different random seeds. We compare our model to FVI, Laplace, MAP, and Sparse GP baselines, as the scale of the datasets forbids exact GP inference. The expected log-likelihood and expected calibration error are estimated by Monte Carlo integration with \(10\) posterior samples. All neural networks have the same convolutional neural network architecture with three convolutional layers (\(3 3\) kernels and output channels \(16\), \(32\) and \(64\)) interleaved with a max-pooling layer, before two fully connected layers (with output size \(128\) and \(10\)). For FSP-Laplace, we sample context points from the Kuzushiji-MNIST (KMNIST) dataset  of \(28 28\) gray-scale images during training following Rudner et al.  and use \(25^{}000\) points from the Halton low discrepancy sequence  to compute the covariance. We also consider sample context points uniformly over the range \([p_{min}^{h,w,c},p_{max}^{h,w,c}]_{h=1,w=1,c=1}^{H,W,C}\), where \(H\), \(W\) and \(C\) are respectively the height, width and number of channels of the images, and \(p_{min}^{h,w,c}=v_{min}^{h,w,c}-0.5^{h,w,c}\) and \(p_{max}^{h,w,c}=v_{max}^{h,w,c}+0.5^{h,w,c}\) where \(^{h,w,c}=v_{max}^{h,w,c}-v_{min}^{h,w,c}\) is the difference between the minimal (\(v_{min}^{h,w,c}\)) and maximal (\(v_{max}^{h,w,c}\)) values of the data set at pixel index \((h,w,c)\). For FVI, we use the same context point distributions as FSP-Laplace. For the Laplace, we use the K-FAC approximation of the generalized Gauss-Newton matrix. We use a Categorical likelihood, the Adam optimizer  with a batch size of \(100\) and stop training early when the validation loss stops decreasing. We optimize hyper-parameters using the Bayesian optimization tool provided by Weights and Biases  and select the parameters which maximize the average validation expected log-likelihood across \(1\) random partitioning of the provided training split into training and validation data. We find covariance function parameters by maximizing the log-marginal likelihood from batches  using the reparameterization of classifications labels into regression targets from Milios et al. . We optimize over kernel, prior scale, learning-rate, \(_{}\) (introduced by Milios et al. ) and activation function and select covariance functions among the RBF, Matern-1/2, Matern-3/2, Matern-5/2 and Rational Quadratic.

Out-of-distribution detection with image data.We consider out-of-distribution detection with image data and a Categorical likelihood following the setup by Osawa et al. . We aim to partition in-distribution (ID) data from out-of-distribution (OOD) based on the mean of entropy of the predictive distribution with respect to \(10\) posterior samples using a single threshold found by fitting a decision stump. We evaluate a model fit on MNIST using its test data set as in-distribution data (ID) and the test data set of FashionMNIST as out-of-distribution (OOD), and vice-versa for a model fit on FashionMNIST. We use the same models and hyper-parameters as for image classification and report mean and standard-error of our scores across the same \(5\) random partitions of the data.

Bayesian optimization.We consider Bayesian optimization (BO) problems derived from Li et al. . More specifically, we use the same setup but change the dimension of the feature space of the tasks. We report mean and standard error of 5 repetitions of the tasks across different random seeds. We use two hidden layer neural networks with hyperbolic tangent activations and \(50\) hidden units each. FSP-Laplace uses a Matern-5/2 covariance function with constant zero mean function whose parameters are found by maximizing the marginal likelihood . We use \(400\) context points during training and \(10^{}000\) to compute the posterior covariance sampled using latin hypercube sampling . We use the same prior for FVI and the same number of context points during training. The Gaussian process uses a zero mean function and a Matern-5/2 covariance function following Li et al. . For the Laplace approximation, we find the prior scale by maximizing the marginal likelihood . Unlike FSP-Laplace which uses low-rank factors to parameterize the posterior covariance, we found that repeatedly computing the covariance and predictive posterior of the linearized Laplace with the full and K-FAC generalized Gauss-Newton (GGN) matrices was often prohibitively slow in the BO setup. We therefore use the K-FAC approximation to the GGN where possible (Branin and PDE) and the diagonal approximation otherwise (Ackley, Hartmann, Polynomial and BNN). We implemented this experiment using the BO Torch library .

Regression with UCI datasets.We consider tabular regression datasets from the UCI repository . Specifically, we perform leave-one-out 5-fold cross validation, considering \(10\%\) of the training folds as validation data, and we report the mean and standard-error of the average expected log-likelihood on the test fold. We report the mean rank of the methods across all datasets by assigning rank 1 to the best scoring method as well as any method who's standard error overlaps with the highest score's error bars, and recursively apply this procedure to the methods not having yet been assigned a rank. We estimate the expected log-likelihood using \(10\) posterior samples. We encoding categorical features as one-hot vectors and standardizing the features and labels. We consider two hidden-layer neural networks with \(50\) hidden units each and hyperbolic tangent activations. All models have a homoskedastic noise model with a learned scale parameter. FSP-Laplace uses context points drawn uniformly over the range \([p^{i}_{min},p^{i}_{max}]^{i}_{i=1}\), where \(d\) is the dimension of the feature space, and \(p^{i}_{min}=v^{i}_{min}-0.5^{i}\) and \(p^{i}_{max}=v^{i}_{max}+0.5^{i}\) where \(^{i}=v^{i}_{max}-v^{i}_{min}\) is the difference between the minimal (\(v^{i}_{min}\)) and maximal (\(v^{i}_{max}\)) values of the data set at feature index \(i\). For the Laplace, we use the full generalized Gauss-Newton matrix. FVI uses the same context points as FSP-Laplace. Neural networks are fit using the Adam optimizer  and we stop training early when the validation loss stops decreasing. Hyper-parameters are found just as for the image classification experiment.

Out-of-distribution detection with regression data.We consider out-of-distribution (OOD) detection with tabular regression data from the UCI datasets  following the setup from Malinin et al. . We aim to separate test data (in-distribution) from a subset of the song dataset  (out-of-distribution) with the same number of features based on the variance of the predictive posterior estimated from \(10\) posterior samples using a single threshold obtained via a decision stump. We process the data just like in the regression experiments, use the same model hyper-parameters and report mean and standard-error of the scores across the same \(5\) random partitions of the data.

#### b.2.1 Software

We use the JAX  and DM-Haiku  Python libraries to implement neural networks. The generalized Gauss-Newton matrices used in the Laplace approximations are computed using the KFAC-JAX library . We implemented the GPs and sparse GPs using the GPyTorch library . We conducted experiments the Bayesian optimization experiments using the BOTorch library .

#### b.2.2 Hardware

All models were fit using a single NVIDIA RTX 2080Ti GPU with 11GB of memory.

## Appendix C Additional experimental results

### Additional qualitative results

Regression.We show additional results for the synthetic regression task described in Section4. We find that FSP-Laplace successfully adapts to the beliefs specified by different Gaussian process priors in terms of periodicity (FigureC.2), smoothness (Figure1) and length scale (FigureC.3) without modifying the neural network's architecture or adding features. We also find that our method effectively regularizes the model when the data is very noisy (FigureC.4).

Classification.We show additional results for the two-moons classification task described in Section 4. Similar to the GP and sparse GP baselines, we find that our method captures the behavior of the prior, showing a smooth decision boundary when equipped with a RBF covariance function (Figure C.6) and a rough decision boundary when equipped with a Matern-1/2 covariance function (Figure C.5). FSP-Laplace also reverts to the zero-valued mean outside of the data support.

Effect of context points.We provide additional details on the role of the context points in FSP-Laplace. The goal of the context points is to regularize the neural network on a finite set of input locations which includes any point where we would like to evaluate the model. During MAP estimation (see Algorithm 1), context points are resampled at each update step to amortize the coverage of the feature space. During the posterior covariance computation (see Algorithm 2), context points are fixed and define where we regularize the model. Context points bare similarity with inducing points in variational GPs  in this later step as both define where the model is regularized.

We show additional results demonstrating the behavior of our model in the low context point regime. Figure C.7 shows the effect of the number of context points on a 1-dimensional regression task with GP priors equipped with a RBF and a Matern 1/2 kernel. Figure C.8 shows the same experiment but on a 2-dimensional classification task. The \(M\) context points are randomly sampled uniformly during training, and we use the Halton low discrepancy sequence as context points to compute the covariance. Even with a very small number of context points (\(M=3\) and \(M=5\)), our model still produces useful uncertainty estimates even if it cannot accurately capture the beliefs specified by the

Figure C.4: FSP-Laplace is effectively regularized under strong label noise.

Figure C.1: Just like the Gaussian process (GP) and sparse GP, FSP-Laplace captures the smoothness behavior specified by the RBF covariance function of the Gaussian process prior.

Figure C.2: Unlike the linearized Laplace, FSP-Laplace allows to incorporate periodicity within the support of the data using a periodic prior covariance function and without additional periodic features.

prior. We also note that our method requires more context points to capture the beliefs of rougher priors than smooth priors (see Figure C.7).

### Additional quantitative results

Mauna Loa.We here show the figure associated with the Mauna Loa dataset experiment in Section 4.1. Figure C.9 shows the predictions of FSP-Laplace and the baselines on the Mauna Loa dataset. We find that incorporating prior beliefs both via an informative prior and periodic features in FSP-Laplace results in an improved fit over FVI, Laplace and GP baselines.

Figure C.7: FSP-Laplace with a smooth RBF covariance function and a rough Matern-1/2 with varying amounts of context points \(M\). Given a very small number of context points, our method still produces useful uncertainty estimates.

Figure C.6: FSP-Laplace with a RBF covariance function against baselines in the two-moons classification task. Similar to the Gaussian process (GP) and sparse GP, our method shows a smooth decision boundary.

Figure C.5: FSP-Laplace with a Matern-1/2 covariance function against baselines in the two-moons classification task. Similar to the Gaussian process (GP) and sparse GP, our method shows a rough decision boundary.

Out-of-distribution detection with image data.We present additional results for the out-of-distribution detection experiment presented in Section 4.1. Figure 10 shows the distribution of the predictive entropy of in-distribution (ID) and out-of-distribution (OOD) data under the sparse GP, FSP-Laplace, FVI and Laplace models. For both MNIST and FashionMNIST, we find that the predictive entropy of ID data under FSP-Laplace is tightly peaked around \(0\) nats and that the predictive entropy of OOD data strongly concentrates around its maximum \( 10 2.3\) nats.

Rotated MNIST and FashionMNIST.We provide an additional experiment studying the behavior of FSP-Laplace under out-of-distribution data. We consider the setup by Rudner et al. , Sensoy et al.  and track the predictive entropy of models trained on MNIST and FashionMNIST for increasing angles of rotation of the test images. We expect the predictive entropy of a well-calibrated neural network to grow as the inputs become increasingly dissimilar to the training data with higher angles of rotation. Similar to FVI, sparse GP and the linearized Laplace baselines, we find that FSP-Laplace yields low predictive entropy for small rotation angles and that the predictive entropy increases with the angle on both MNIST and FashionMNIST which is what we expect from a well calibrated Bayesian model.

Regression with UCI datasets.We further evaluate our method on regression datasets from the UCI repository  and compare FSP-Laplace to FVI, Laplace, MAP, GP, and Sparse GP baselines. We perform leave-one-out 5-fold cross-validation, keeping \(20\%\) of the remaining train folds as validation data. We report the mean and standard-error of the expected log-likelihood with respect to samples

Figure 9: Regression on the Mauna Loa dataset. Incorporating prior knowledge via a kernel tailored specifically to the dataset, our method (FSP-Laplace) results in a strong decrease in mean square error over baselines.

Figure 8: FSP-Laplace with a smooth RBF covariance function and a rough Matern-1/2 with varying amounts of context points \(M\). Given a very small number of context points, our method still produces useful uncertainty estimates and reverts to the prior’s zero valued mean.

from the posterior across the 5-folds. Additional details can be found in Appendix B.2. Results are presented in Table C.1. We find that our method performs well compared to baselines, matching or improving over the mean rank of all Bayesian methods (FVI, Laplace, GP, and Sparse GP) but a slightly lower mean rank than the MAP baseline (\(1.636\) vs. \(1.363\)). In particular, our method is noticeably more accurate than the Laplace.

Out-of-distribution detection on tabular data.We also investigate whether the epistemic uncertainty of FSP-Laplace is predictive of out-of-distribution data in the regression setting by evaluating it on out-of-distribution detection following Malinin et al. . We report the accuracy of a single threshold to classify OOD from in-distribution (ID) data based on the predictive uncertainty. More details are presented in Appendix B.2. In the context of tabular data, we find that FSP-Laplace performs second best among BNNs and is almost as accurate as the Laplace approximation (see Table C.1) which is first. We note that FSP-Laplace systematically outperforms FVI in terms of out-of-distribution detection and obtains a higher mean rank (\(1.818\) vs. \(3.091\)).

    &  \\   & TSP-Laplace(\(1.05\)/\(1.05\)) & FVI & Laplace & MAP & GP & Sparse GP & FPI-Laplace(\(1.05\)/\(1.05\)) & FVI & Laplace & GP & Sparse GP \\    & **-0.41\(\)0.006** & -0.51\(\)0.006 & -0.75\(\)0.007 & -0.49\(\)0.007 & -0.30\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 & -0.51\(\)0.007 \\    & **-0.51\(\)0.006** & -0.51\(\)0.006 & -0.75\(\)0.006 & -0.49\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 & -0.51\(\)0.006 \\    & **-0.51\(\)0.006** & -0.51\(\)0.006 & -0.51\(\)0.006 & **-0.51\(\)0.006 & **-0.51\(\)0.006 & **-0.50\(\)0.006 & **-0.50\(\)0.006 & **-0.50\(\)0.006 & **-0.50\(\)0.006 & **-0.50\(\)0.006 & **-0.50\(\)0.006** & **-0.50\(\)0.006** \\    & **-0.51\(\)0.006** & -0.51\(\)0.006 & -0.51\(\)0.006 & **-0.51\(\)0.006 & **-0.

\(\|P_{0} P_{0}^{}\|_{F}\) is negligible.We provide evidence that the term \(\|P_{0} P_{0}^{}\|_{F}\) in Section3.2 is negligible compared to \(\|\|_{F}\) in four different configurations. We consider the synthetic regression and classification setups described in AppendixB.1.

### NeurIPS Paper Checklist

1. **Claims** Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? Answer: [Yes] Justification: Our experimental results support the fact that the our methods captures beliefs specified by the GP prior. Guidelines: * The answer NA means that the abstract and introduction do not include the claims made in the paper. * The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. * The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. * It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper.
2. **Limitations** Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] Justification: We discuss limitations in sections Sections 3, 4 and 6. Guidelines: * The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. * The authors are encouraged to create a separate "Limitations" section in their paper. * The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. * The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. * The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. * The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. * If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. * While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations.
3. **Theory Assumptions and Proofs** Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? Answer: [Yes]Justification: We rigorously detail assumptions in Appendix A.1 and proofs can be found in Appendix A.2 and the references.

Guidelines:

* The answer NA means that the paper does not include theoretical results.
* All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.
* All assumptions should be clearly stated or referenced in the statement of any theorems.
* The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.
* Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.
* Theorems and Lemmas that the proof relies upon should be properly referenced.
4. **Experimental Result Reproducibility** Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? Answer: [Yes] Justification: We do so in Appendix B. Guidelines: * The answer NA means that the paper does not include experiments. * If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. * If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. * Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. * While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example 1. If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. 2. If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. 3. If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). 4. We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results.
5. **Open access to data and code** Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?Answer: [Yes] Justification: Code will be published at https://github.com/tristancinquin/fsplaplace. Guidelines: * The answer NA means that paper does not include experiments requiring code. * Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * While we encourage the release of code and data, we understand that this might not be possible, so "No" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). * The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/guides/CodeSubmissionPolicy) for more details. * The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. * The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. * At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). * Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted.
6. **Experimental Setting/Details** Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: See Appendix B. Guidelines: * The answer NA means that the paper does not include experiments. * The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. * The full details can be provided either with the code, in appendix, or as supplemental material.
7. **Experiment Statistical Significance** Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? Answer: [Yes] Justification: We report standard error along the mean scores across cross validation folds. Guidelines: * The answer NA means that the paper does not include experiments. * The authors should answer "Yes" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. * The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). * The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) * The assumptions made should be given (e.g., Normally distributed errors).

* It should be clear whether the error bar is the standard deviation or the standard error of the mean.
* It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified.
* For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).
* If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text.
8. **Experiments Compute Resources** Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? Answer: [Yes] Justification: See Appendix B. Guidelines: * The answer NA means that the paper does not include experiments. * The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. * The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. * The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper).
9. **Code Of Ethics** Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] Justification: To the best of our knowledge, we have fully conformed with the code of ethics. Guidelines: * The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. * If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. * The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction).
10. **Broader Impacts** Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? Answer: [No] Justification: We believe that there is no direct societal impact of the work perform that needs discussion. Guidelines: * The answer NA means that there is no societal impact of the work performed. * If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. * Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.

* The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.
* The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.
* If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML).
11. **Safeguards** Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? Answer: [NA] Justification: The methods developed in the paper have no risk for misuse. Guidelines: * The answer NA means that the paper poses no such risks. * Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. * Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. * We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort.
12. **Licenses for existing assets** Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] Justification: All external assets (code and data) used in this publication are publicly available, cited in Section 4 and Appendix C.1, and their respective licenses are, to the best of our knowledge, properly respected. Guidelines: * The answer NA means that the paper does not use existing assets. * The authors should cite the original paper that produced the code package or dataset. * The authors should state which version of the asset is used and, if possible, include a URL. * The name of the license (e.g., CC-BY 4.0) should be included for each asset. * For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. * If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.

* For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.
* If this information is not available online, the authors are encouraged to reach out to the asset's creators.
* **New Assets*
* Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? Answer: [NA] Justification: The paper does not release new assets. Guidelines:
* The answer NA means that the paper does not release new assets.
* Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.
* The paper should discuss whether and how consent was obtained from people whose asset is used.
* At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file.
* **Crowdsourcing and Research with Human Subjects*
* Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? Answer: [NA] Justification: The paper does not conduct any research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.
* According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector.
* **Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects*
* Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? Answer: [NA] Justification: The paper does not conduct any research with human subjects. Guidelines:
* The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.
* Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.
* We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.
* For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.