# FIDE: Frequency-Inflated Conditional Diffusion Model for Extreme-Aware Time Series Generation

Asadullah Hill Galib, Pang-Ning Tan, and Lifeng Luo

Michigan State University

Emails: {galibasa, ptan, lluo}@msu.edu

###### Abstract

Time series generation is a crucial aspect of data analysis, playing a pivotal role in learning the temporal patterns and their underlying dynamics across diverse fields. Conventional time series generation methods often struggle to capture extreme values adequately, diminishing their value in critical applications such as scenario planning and risk management for healthcare, finance, climate change adaptation, and beyond. In this paper, we introduce a conditional diffusion model called FIDE to address the challenge of preserving the distribution of extreme values in generative modeling for time series. FIDE employs a novel high-frequency inflation strategy in the frequency domain, preventing premature fade-out of the extreme values. It also extends the traditional diffusion-based model, enabling the generation of samples conditioned on the block maxima, thereby enhancing the model's capacity to capture extreme events. Additionally, the FIDE framework incorporates the Generalized Extreme Value (GEV) distribution within its generative modeling framework, ensuring fidelity to both block maxima and overall data distribution. Experimental results on real-world and synthetic data showcase the efficacy of FIDE over baseline methods, highlighting its potential in advancing Generative AI for time series analysis, specifically in accurately modeling extreme events.

## 1 Introduction

Generative models [18; 10; 13] have revolutionized the AI landscape, demonstrating their broad applicability across diverse domains, including computer vision and natural language processing. Such models are designed to learn the underlying data distribution and exhibit resilience to overfitting while promoting automatic feature extraction. Diffusion-based models [12; 19], in particular, have emerged as a popular generative AI method due to their capability to generate realistic, high-quality data. This paper examines the application of diffusion-based models for time series generation. In particular, we investigate the following issue: _How well do existing diffusion models preserve the fidelity of extreme values (i.e., tail distribution) of the original time series?_

The modeling of extreme values in time series is essential for informed decision-making across diverse applications, including weather forecasting, earthquake prediction, and disease outbreak detection. Effective generative modeling of these extremes is important as it aids in learning the underlying data distribution, facilitating data augmentation, and improving uncertainty estimation, all of which are crucial for developing robust risk management strategies and enhancing disaster preparedness measures. While there has been growing research on applying diffusion models for time series [20; 2], their ability to preserve the distribution of extreme values remains largely underexplored. In this study, we examine how effectively diffusion models preserve extreme values in the form of block maxima , defined as the peak value within a specified time window.

To illustrate the difficulty of modeling the distribution of block maxima, Figure 1 shows the result of applying the Denoising Diffusion Probabilistic Model (DDPM)  to a synthetic AR(1) dataset.

While DDPM shows proficiency in generating samples that closely align with the overall data distribution (left diagram), it struggles to preserve the distribution of block maxima values (right diagram) when the generated time series is partitioned into disjoint time windows.

In this paper, we identify the key shortcomings of existing diffusion models that hamper their ability to accurately model block maxima values. We then present a novel framework to overcome this limitation. Our key observation is that unusually large block maxima values, often linked to abrupt temporal changes, are strongly associated with high-frequency components of the time series. As the diffusion-based generative model gradually introduces noise with a linearly increasing variance schedule, it slowly diminishes the long-term trends (low-frequency components) of the time series while quickly attenuating the high-frequency components. These high-frequency components are crucial for reproducing extreme block maxima values. This limitation hampers the accurate representation of the block maxima, necessitating the development of new techniques.

To address this challenge, we propose an end-to-end diffusion model framework termed FIDE. First, to mitigate the rapid dissipation of high-frequency components in the diffusion model, we introduce a novel high-frequency inflation strategy within the frequency domain. This strategic augmentation ensures the sustained emphasis on block maxima, preventing their premature fade-out. We further employ a conditional diffusion-based generative modeling approach to guide the time series generation by conditioning on their block maxima. To enhance the preservation of the block maxima distribution while learning the overall data distribution, we extend the conventional framework with a regularization term in the loss function based on the negative log-likelihood of the Generalized Extreme Value (GEV) distribution. Using these strategies, we empirically show that our approach effectively addresses the challenges of learning the overall data distribution while simultaneously preserving the block maxima distribution.

## 2 Preliminaries

Consider a time series dataset \(=\{_{m,0}\}_{m=1}^{M}\) comprising of \(M\) samples, where each sample \(_{m,0}=(x_{m,0}^{1},x_{m,0}^{2},,x_{m,0}^{T})\) is a univariate time series of finite length \(T\). Let \(_{m,0}^{T}\) be the Fourier coefficients, whose \(k\)-th frequency component is obtained by applying the following discrete Fourier transform on \(_{m,0}\):

\[f_{m,0}^{k}=_{t=1}^{T}x_{m,0}^{t}\ e^{-i2 tk/T}=_{t=1}^{T}[x_ {m,0}^{t}()-i x_{m,0}^{t}( {2 tk}{T})]\] (1)

The time series can be recovered from its Fourier coefficients using the following inverse discrete Fourier transform:

\[x_{m,0}^{t}=_{k=1}^{T}f_{m,0}^{k}\ e^{i2 tk/T}= _{k=1}^{T}(f_{m,0}^{k}()+i f_{m, 0}^{k}())\] (2)

For brevity, we will drop the sample subscript \(m\) when it is clear from the context. Let, \(_{k}=\) be the \(k\)-th frequency in Fourier transform.

Given a sample \(_{0}\), let \(y_{0}\) be its corresponding block maxima value, where \(y_{0}=_{r\{1,,T\}}x_{0}^{r}\). The distribution of the block maxima values is governed by the Generalized Extreme Value (GEV)

Figure 1: Comparing the distributions of all values and block maxima values for real and generated samples using DDPM  when applied to the synthetic AR(1) dataset.

distribution, whose cumulative distribution function is given as follows :

\[G(y)=-1+()^{-1/}}\] (3)

where \(\) (location), \(\) (scale), and \(\) (shape) are the distribution parameters. Given \(M\) independent block maxima values, denoted as \(\{y_{1,0},y_{2,0},,y_{M,0}\}\), with the cumulative distribution function given by Equation (3), the distribution parameters can be estimated using the maximum likelihood approach by minimizing the following negative log-likelihood function:

\[-_{}(,,)=M++1_{i=1}^{M}\,1+\,-}{} +_{i=1}^{M}1+-}{}^{-1/}\] (4)

## 3 On the Rapid Dissipation of Block Maxima in Diffusion Models

While diffusion models have demonstrated remarkable capabilities in learning complex data distributions, a significant challenge arises in accurately capturing the distribution of block maxima values, as evidenced by Figure 1. Addressing this shortcoming is crucial for enhancing the performance and applicability of these models across various domains. In this section, we delve into the root cause of this phenomenon and present insightful observations that shed light on the underlying issue.

Our first key observation reveals a _connection between block maxima with abrupt changes and the high-frequency components_ of many real-world time series. Block maxima, often characterized by their rarity and abrupt temporal changes, are intrinsically linked to the high-frequency components of the data. This relationship is observed in many real-world datasets, where the block maxima values do not typically evolve smoothly but rather emerge through large deviations from their adjacent values.

To illustrate this, consider the real-world temperature time series depicted in Figure 2. In this plot, we first transform the time series into its Fourier domain, obtaining its frequency components, and selectively zeroing out its top-\(5\) highest frequency components. We then reconstruct the time series via its inverse Fourier transform and compute the difference between the original and reconstructed time series. The recovered signal exhibits a notable distortion around the block maxima value, as evidenced by the larger residual at time step 20, where the block maxima value occurs. This suggests that the removal of high-frequency components of a time series has a significant impact on the

Figure 2: Removal of high-frequency components from daily temperature time series significantly alters the magnitude of its block maxima value (at time step 20), as evidenced by its high residual.

accurate representation of block maxima values. A more detailed analysis supporting this argument is given in Appendix B.

Our second key observation unveils a concerning behavior of diffusion models: _the addition of noise diminishes high frequency components, i.e., block maxima, at a faster rate_ compared to other values in the signal. As diffusion-based generative models gradually introduce noise characterized by a linearly increasing variance scheduler, they inadvertently attenuate the signals associated with high-frequency components. These components, as established in our first observation, are crucial for accurately reproducing block maxima. Concurrently, the models effectively capture the long-term trends and low-frequency components, which are conducive to learning the overall data distribution. However, the high frequency components dissipate more rapidly, hindering the model's ability to adeptly learn the distribution of the block maxima values.

Figure 2(a) illustrates this phenomenon. By tracking the evolution of residuals, or the differences between the original and perturbed time series generated by DDPM, we observe a discernible pattern: block maxima dissipate at a faster rate compared to other values, as evidenced by the higher residuals associated with these extreme points. Notably, in the early iterations highlighted by the green circle, the substantially higher residual suggests that the block maxima signal is rapidly transformed into noise, outpacing the dissipation rate of other values. This behavior poses a formidable challenge for diffusion models in effectively capturing the distributions of the block maxima values.

To substantiate our observations, the theorem below offers a rigorous justification for the rapid dissipation of block maxima during the forward process of the diffusion model (see Appendix C for proof and details). Let \(_{0}\) be an input sample and \(_{n}\) be the perturbed sample after \(n\) iterations of the forward process, where \(x_{n}^{t}=x_{n-1}^{t}+_{n}^{t}\) and \(_{n}^{t}(0,_{_{n}^{t}}^{2})\) is Gaussian noise. Due to the linearity of the Fourier transform operator \(\), we have:

\[(_{n})=(_{n-1})+( _{n})\ \ \ \ f_{n}^{k}=f_{n-1}^{k}+_{n}^{k}\] (5)

**Theorem 1**.: _Under certain mild assumptions (see Appendix C), the ratio of high-frequency and low-frequency components after perturbation during the forward process of the diffusion model is:_

\[}|f_{n}^{k}|^{2}}{_{k 0}|f_{n}^{k}|^{2}}= 1\] (6)

_where \(k_{}\) is the index of the maximum frequency and \(=f_{n}^{k_{}}\), which is generally close to 0._

In short, our findings shed light on a fundamental limitation of diffusion models while modeling block maxima and underscore the need for a more tailored approach to preserve its distribution.

## 4 Proposed Framework: Fide

In this section, we present the detailed methodology of our proposed approach, addressing the challenges associated with capturing extreme values of time series within diffusion-based generative models. Figure 4 provides an overview of the FIDE framework.

Figure 3: A comparison of the effects of noise addition by existing DDPM versus high-frequency inflation on the block maxima of generated samples.

### High Frequency Components Inflation

In order to counteract the rapid decay of high-frequency components in the frequency domain while adding noise in the forward process of DDPM, we present a strategy for high-frequency inflation. Let \(_{0}=(_{0})\) denote the vector of Fourier coefficients resulting from applying the discrete Fourier transform to the time series \(_{0}\). These coefficients are arranged in ascending order from lowest to highest frequency. Consequently, the last \(\) elements of \(_{0}\) correspond to the coefficients associated with the \(\) highest frequencies. Our goal is to inflate the top-\(\) frequency components of \(_{0}\) as follows:

\[^{i} = 1,&i\\ ,&i>T-\ }_{0}= _{0}\]

where \(>1\) is the inflation weight and \(\) denotes the element-wise multiplication.

With the modified coefficients \(}_{0}\), the inverse Fourier transform (IFFT) is applied to get the modified time series, \(}_{0}=(}_{0})\), containing the inflated high-frequency components. Here, the high-frequency components are inflated by \(>1\). The following theorem shows how this inflation strategy helps the high-frequency components (block maxima) diminish less rapidly in the diffusion forward process compared to before (see Appendix C for proof and details).

Figure 4: Proposed FIDE framework for generating time series with extreme events

**Theorem 2**.: _Let \(^{k}}\) be the Fourier coefficient after inflating high-frequency components with a factor of \(\) such that \(>1\). Let \(=f_{n}^{k_{}}\) be the Fourier coefficient of the maximum frequency before inflation, and \(^{}==^{k_{}}}\) be the Fourier coefficient of the maximum frequency after inflation. Then, using Lemma 1 and under certain mild assumptions (see Appendix C), the ratio of high-frequency and low-frequency components after inflation and perturbations is:_

\[}|^{k}}|^{2}}{_{k 0}| ^{k}}|^{2}}=\] (7)

Thus, by applying high-frequency inflation, the high-frequency components including abrupt block maxima will be preserved by a factor of \(\) compared to the previous case. We can see the effects of this inflation empirically as well. Figure 2(b) shows how inflating the high-frequency components helps in preserving the block maxima values for longer iterations of the diffusion model. This enables the block maxima after high-frequency inflation to dissipate at a similar rate compared to other values in the earlier iterations. The diffusion model will have more iterations to capture the block maxima signal.

### Forward Process

We use the inflated time series \(_{0}}\) as input time series to be perturbed during the forward process instead of \(_{0}\). By adopting \(_{0}}\) as the reference for the unperturbed sample, we ensure that the denoising diffusion process takes advantage of the enhanced representation provided by the inflated high-frequency components. This nuanced adjustment contributes to the efficacy of our proposed framework in capturing and preserving essential information during the diffusion process.

### Conditional Reverse Diffusion Process

To enable the generation of samples conditioned on block maxima, we extend the conventional diffusion model to a conditional model. Here, the reverse process is conditioned on block maxima \(y_{0}\). Grounded in extreme value theory , the block maxima values \(\{y_{0}\}\) are governed by the Generalized Extreme Value (GEV) distribution, distinctly diverging from the distribution of all values \(_{0} p_{}(_{0})\). This mandates a strategic shift in our learning objective. Rather than marginally targeting \(p_{}(_{0})\), our objective now extends to mastering the joint distribution \(p_{}(_{0},y_{0})\), driven by a nuanced understanding of the unique characteristics inherent in extreme events and their crucial impact on the overall distribution. We formally extend the diffusion model's marginal distribution to a joint distribution in the following theorem (see Appendix C for proof and details).

**Theorem 3**.: _Consider an extension of the conventional diffusion model from learning a marginal distribution \(p_{}(_{0})\) to a joint distribution \(p_{}(_{0},y_{0})\) conditioned on block maxima \(y_{0}\). In this context, the variational lower bound can be formulated as follows:_

\[- p_{}(_{0},y_{0})_{q} _{1:N}|_{0},y_{0})}{p_{}(_{0: N})}- p_{}(y_{0})\] (8)

First, we adopt \(_{0}}\) as the reference for the unperturbed sample \(_{0}\) as discussed in the previous subsection. After reparameterization and ignoring the weighting term, as suggested by , the first term of the variation lower bound can be expressed as:

\[_{}=_{},},n,y_{0 }}\|}(_{n}},n,y_{0})-}\|_{2}^{2}\] (9)

Additionally, considering a Generalized Extreme Value (GEV) distribution for block maxima, the second term is simplified as \(_{}(,,)\), as defined in Eq. 4.

The preceding theorem establishes a clear link between the variational lower bound and an interpretable objective loss function:

\[- p_{}(_{0},y_{0})_{}- _{}(,,):=L\] (10)

Here, \(_{}\) represents the expected reconstruction error between actual and estimated noise, and \(_{}(,,)\) captures the negative log-likelihood of the block maxima governed by the GEV distribution.

### GEV Distribution Enforcement Module

To enforce fidelity on both the block maxima and overall data distribution, we incorporate the Generalized Extreme Value (GEV) distribution within the DDPM framework following Theorem 3. We first fit a GEV distribution using maximum log-likelihood estimation with all the block maxima (\(y_{0}\)) values in the training data. The fitted GEV distribution is parameterized by \(\), \(\), and \(\), denoted as \(_{}=\{,,\}\). Using the conditional diffusion process, the estimated noise is given by \(_{n}(_{n}},n,y_{0})\). Consequently, the estimated denoised sample can be obtained as: \(}_{0}=_{n}}-_{n}\). Then, utilizing the fitted GEV distribution, the log-likelihood of the estimated denoised block maxima, \(_{0}=_{\{1,,T\}}_{0}^{ }}\), is calculated. This negative log-likelihood, \(-_{}(,,,_{0})\), is finally incorporated into the loss function of training.

### Optimization

Algorithm 1 summarizes the pseudocode for training and Algorithm 2 summarizes the pseudocode for the sampling step of FIDE. The overall loss function \(_{}\) is constructed by combining two key components: the DDPM loss \(_{}\) and the negative log-likelihood of the Generalized Extreme Value (GEV) distribution \(-_{}\). The formulation is expressed as follows:

\[_{} = _{_{n}},_{n}}, n,y_{0}}\|_{n}(_{n}},n,y_{0})- _{n}\|_{2}^{2}-_{}(,,,_{0})\] (11)

where \(\) is a hyperparameter controlling the influence of the GEV distribution on the loss.

In this context, \(_{}\) evaluates the mean squared difference between the estimated noise term \(_{n}\) and the true noise term \(_{n}\) within the conditional diffusion process. Its purpose is to guide the generative model towards effectively capturing the underlying data distribution. The second element, \(-_{}(,,,_{0})\), encapsulates the negative log-likelihood of the GEV distribution. This component assesses how well the fitted GEV distribution aligns with the estimated block maxima values \(_{0}\) derived from the denoised samples. Here, the log-likelihood has a negative sign to indicate a minimization objective, aligning with the overall goal of minimizing the loss function.

``` repeat \(_{0} q(_{0})\) where \(_{0}=(x_{0}^{1},x_{0}^{2},,x_{0}^{T})\) \(_{0}=(_{0})\) \(}_{0}=_{0}\) \(_{0}}=(}_{0})\) \(n(\{1,,N\})\) \(}(0,)\) \(y_{0}=(_{0})\) \(_{n}}=}\;_{0}}+}\;}\) \(_{0}}=(_{n}}-_{n}( _{n}},n,y_{0}))\)  Take the gradient step on \(_{}||_{n}(_{n}},n,y_{0}) )-_{n}||_{2}^{2}\) \(-_{}(,,,_{0})\) until converged ```

**Algorithm 1** Training

``` Input: Block maxima \(_{0}(y_{0})\) and Trained Model \(\) Output: Generate time series, \(}_{0}\). \(}_{N}(0,^{2})\) for\(n=N,,1\)do \((0,)\) \(}_{n-1}=}}(}_{n}-}{}}\;_{n}(}_{ n},n,_{0}))\) endfor return\(}_{0}\) ```

**Algorithm 2** Sampling

## 5 Experimental Evaluation

We have performed extensive experiments to evaluate the performance of our FIDE framework. All the code and datasets used in this paper are available at https://github.com/galib19/FIDE. The datasets used are described in Appendix D.

We compared our proposed framework against various generative models: **(1) GAN-based:** We utilize two GAN-based approaches as our baselines. The first approach is Conditional GAN (cGAN ), which introduces conditional information to the training process, enabling targeted generation based on specified conditions. The second baseline is TimeGAN , which is a generative model designed specifically for time-series generation. **(2) VAE-based:** We employ beta-VAE , conditional beta-VAE , and TimeVAE  as baseline methods for comparison. Both beta-VAE and conditionalbeta-VAE incorporate a specific disentanglement objective to encourage the model to learn more interpretable and factorized representations while TimeVAE  promotes interpretability. **(3) Flow-based:** We use normalizing flows-based approaches such as RealNVP  and Fourier-Flows  as our baseline methods. **(4) Diffusion-based:** We consider two baselines for comparison, namely, the denoising diffusion probabilistic model (DDPM)  and time series diffusion model called Diffusion-TS .

### Experimental Settings

We partitioned each dataset into training, validation, and testing, according to a 8:1:1 ratio. We repeated the experiments 5 times. Prior to applying the various algorithms, the time series data is standardized to have zero mean and unit variance. The encoder component of our framework employs a 3-layer transformer architecture, accompanied by fully connected layers. The training was facilitated using the Adam optimizer. For all the methods, we perform extensive hyperparameter tuning on the length of the embedding vector, the number of hidden layers, the number of nodes, the learning rate, and the batch size. The optimal hyperparameters were determined using the Ray Tune framework, integrating an Asynchronous Successive Halving Algorithm (ASHA) scheduler to enable early stopping. All experiments were conducted on NVIDIA T4 GPU.

To assess the effectiveness of the proposed framework, we utilize four metrics: Jensen-Shannon (JS) Divergence, KL Divergence, CRPS (Continuous Rank Probability Score), and Predictive Score. The first three metrics examine how well the generated samples fit the original data distribution. The

  Metrics & Methods & AR1 & Stock & Energy & Temperature & ECG \\   Divergence \\  } & beta-VAE & 0.0211\(\)0.0187 & 0.1105\(\)0.0188 & 0.0722\(\)0.0095 & 0.0140\(\)0.0125 & 0.1210\(\)0.0214 \\  & c-beta-VAE & 0.0190\(\)0.0125 & 0.1011\(\)0.0152 & 0.0710\(\)0.0088 & 0.0190\(\)0.0098 & 0.1120\(\)0.0352 \\  & TimeVAE & 0.0015\(\)0.0003 & 1.054\(\)0.0071 & 0.0795\(\)0.0085 & 0.0096\(\)0.0002 & 0.0098\(\)0.0078 \\  & TimeGAN & 0.0840\(\)0.0109 & 0.1411\(\)0.1585 & 0.0950\(\)0.0089 & 0.0112\(\)0.0012 & 0.1620\(\)0.0221 \\  & cGAN & 0.0690\(\)0.0091 & 0.1211\(\)0.0025 & 0.0890\(\)0.0093 & 0.0091\(\)0.0080 & 0.1440\(\)0.0211 \\  & RealNVP & 0.0754\(\)0.0121 & 0.1185\(\)0.0108 & 0.0905\(\)0.0084 & 0.0089\(\)0.0007 & 0.1411\(\)0.0116 \\  & Fourier-Flows & 0.0612\(\)0.0045 & 0.1108\(\)0.0195 & 0.0820\(\)0.0044 & 0.0078\(\)0.0010 & 0.1398\(\)0.0202 \\  & DDPM & 0.0010\(\)0.0007 & 0.0912\(\)0.0062 & 0.0752\(\)0.0082 & 0.0082\(\)0.0009 & 0.1041\(\)0.0122 \\  & Diffusion-TS & 0.0011\(\)0.0008 & 0.0854\(\)0.0045 & 0.0712\(\)0.0071 & 0.0077\(\)0.0080 & 0.1005\(\)0.0108 \\  & FIDE (Ours) & **0.0004\(\)0.0001** & **0.0700\(\)0.0061** & **0.0680\(\)0.0092** & **0.0007\(\)0.0001** & **0.0930\(\)0.0082** \\   Divergence \\  } & beta-VAE & 0.0110\(\)0.0024 & 0.1947\(\)0.0184 & 0.1210\(\)0.0146 & 0.0410\(\)0.0128 & 0.2020\(\)0.0048 \\  & c-beta-VAE & 0.0091\(\)0.0012 & 0.1744\(\)0.0105 & 0.1160\(\)0.0174 & 0.0360\(\)0.0114 & 0.1880\(\)0.0079 \\  & TimeVAE & 0.0105\(\)0.0007 & 0.2514\(\)0.0152 & 0.1625\(\)0.0095 & 0.0490\(\)0.0006 & 0.2254\(\)0.0068 \\  & TimeGAN & 0.1920\(\)0.0156 & 0.2425\(\)0.0251 & 0.1590\(\)0.0198 & 0.0550\(\)0.0145 & 0.2540\(\)0.0254 \\  & cGAN & 0.1240\(\)0.0122 & 0.2101\(\)0.0115 & 0.1510\(\)0.0211 & 0.0490\(\)0.0125 & 0.2210\(\)0.0184 \\  & RealNVP & 0.1298\(\)0.0215 & 0.2295\(\)0.0154 & 0.1605\(\)0.0310 & 0.0512\(\)0.0108 & 0.2305\(\)0.0145 \\  & Fourier-Flows & 0.1235\(\)0.0104 & 0.2045\(\)0.0255 & 0.1485\(\)0.0345 & 0.0505\(\)0.0136 & 0.2254\(\)0.0141 \\  & DDPM & 0.0062\(\)0.0008 & 0.1915\(\)0.0125 & 0.1120\(\)0.0108 & 0.0326\(\)0.0090 & 0.1905\(\)0.0094 \\  & Diffusion-TS & 0.0054\(\)0.0007 & 0.1889\(\)0.0108 & 0.1089\(\)0.0115 & 0.0311\(\)0.0078 & 0.1894\(\)0.0081 \\  & FIDE (Ours) & **0.0030\(\)0.0009** & **0.1504\(\)0.0128** & **0.0950\(\)0.0098** & **0.0029\(\)0.0088** & **0.1810\(\)0.0084** \\   CRPS \\  } & beta-VAE & 0.1247\(\)0.0189 & 0.3149\(\)0.0348 & 0.2410\(\)0.0298 & 0.1544\(\)0.0214 & 0.3059\(\)0.0454 \\  & c-beta-VAE & 0.1154\(\)0.0151 & 0.2698\(\)0.0214 & 0.2574\(\)0.0241 & 0.1420\(\)0.0311 & 0.3150\(\)0.0414 \\  & TimeVAE & 0.1511\(\)0.0081 & 0.2547\(\)0.0155 & 0.2853\(\)0.1082 & 0.1847\(\)0.0071 & 0.3252\(\)0.0204 \\  & TimeGAN & 0.1858\(\)0.0214 & 0.2825\(\)0.0148 & 0.2685\(\)0.0284 & 0.2110\(\)0.0287 & 0.3240\(\)0.0401 \\  & cGAN & 0.1224\(\)0.0157 & 0.2689\(\)0.0301 & 0.2385\(\)0.0187 & 0.1990\(\)0.0214 & 0.2985\(\)0.031fourth metric, Predictive Score , evaluates the generative model's ability to replicate the temporal characteristics of the original data. This is done by training an LSTM-based sequence model for time series forecasting using the synthetic samples produced by each generative model. The model's performance is measured by its mean absolute error (MAE) on the original test data, providing insight into how well the generative model preserves the temporal patterns of the data. In short, the evaluation focuses on forecasting block maxima on the test dataset using the model trained on generated data.

### Experimental Results

Table 1 compares the performance of FIDE against the various baselines in terms of their ability to capture the block maxima distribution for 5 diverse datasets (AR1, Stock, Energy, Temperature, and ECG). In terms of the distribution metrics (JS divergence, KL divergence, and CRPS), FIDE consistently achieves the best results, providing evidence of FIDE's superior performance in preserving the block maxima distribution. For the Predictive Score metric, FIDE achieves the best results in 3 out of 5 datasets and ranks second in the remaining 2 datasets. To further illustrate FIDE's capabilities, Figures 5-(a) and (b) compare the distribution of block maxima values generated by DDPM  and FIDE for the AR(1) dataset. Note that, while DDPM struggles to capture the block maxima distribution accurately, FIDE generates samples that more faithfully preserve the fidelity of the distribution. This improvement is particularly noticeable in the upper tail behavior, which is critical for applications that require precise modeling of extreme block maxima values. This superior performance is not surprising as it directly results from our method's emphasis on block maxima distribution, achieved through the introduction of frequency inflation, conditional generation based on block maxima, and incorporation of the GEV distribution into the generative modeling framework.

As FIDE prioritizes the accurate modeling of block maxima, we have also evaluated its efficacy in capturing the distribution of all (block maxima and non-block maxima) values in time series. The

   Metrics & Methods & AR1 & Stock & Energy & Temperature & ECG \\    } & beta-VAE & 0.0020\(\)0.0003 & 0.0188\(\)0.0016 & 0.0181\(\)0.0015 & 0.0025\(\)0.0003 & 0.0031\(\)0.0004 \\  & c-beta-VAE & 0.0017\(\)0.0004 & 0.0178\(\)0.0019 & 0.0177\(\)0.0017 & 0.0022\(\)0.0004 & 0.0028\(\)0.0004 \\  & TimeVAE & 0.0016\(\)0.0003 & 0.0169\(\)0.0015 & 0.0159\(\)0.0021 & 0.0018\(\)0.0002 & 0.0026\(\)0.0003 \\  & TimeGAN & 0.0025\(\)0.0003 & 0.0182\(\)0.0025 & 0.0161\(\)0.0016 & 0.0021\(\)0.0005 & 0.0034\(\)0.0005 \\  &   & 0.0018\(\)0.0003 & 0.0178\(\)0.0018 & 0.0169\(\)0.0016 & 0.0015\(\)0.0003 & 0.0029\(\)0.0003 \\  & RealNVP & 0.0023\(\)0.0004 & 0.0185\(\)0.0019 & 0.0185\(\)0.0017 & 0.0019\(\)0.0004 & 0.0036\(\)0.0002 \\  & Fourier-Flows & 0.0019\(\)0.0003 & 0.0173\(\)0.0021 & 0.0165\(\)0.0015 & 0.0017\(\)0.0003 & 0.0028\(\)0.0003 \\  & DDPM & **0.0010\(\)0.0001** & 0.0117\(\)0.0011 & 0.0114\(\)0.0010 & **0.0009\(\)0.0001** & **0.0019\(\)0.0003** \\  & Diffusion-TS & 0.0011\(\)0.0001 & **0.0114\(\)0.0012** & 0.0116\(\)0.0009 & 0.0010\(\)0.0002 & **0.0019\(\)0.0003** \\  &   & 0.0021\(\)0.0001 & 0.0121\(\)0.0015 & **0.0109\(\)0.0009** & 0.0011\(\)0.0002 & 0.0012\(\)0.0004 \\    } & beta-VAE & 0.0201\(\)0.0041 & 0.4955\(\)0.0125 & 0.4985\(\)0.0102 & 0.0914\(\)0.0010 & 0.1425\(\)0.0049 \\  & c-beta-VAE & 0.1984\(\)0.0022 & 0.4205\(\)0.0148 & 0.4514\(\)0.0210 & 0.0899\(\)0.0009 & 0.1388\(\)0.0068 \\  & TimeVAE & 0.1848\(\)0.0038 & 0.4841\(\)0.085 & 0.4815\(\)0.0189 & 0.0889\(\)0.0009 & 0.1422\(\)0.0077 \\  & TimeGAN & 0.2412\(\)0.0019 & 0.3941\(\)0.0115 & 0.4415\(\)0.0171 & 0.0911\(\)0.0008 & 0.1262\(\)0.0062 \\  & cGAN & 0.1974\(\)0.0012 & 0.4451\(\)0.0201 & 0.3914\(\)0.0211 & 0.0903\(\)0.0007 & 0.1298\(\)0.0056 \\  & RealNVP & 0.2511\(\)0.0019 & 0.4254\(\)0.0194 & 0.5125\(\)0.0184 & 0.0919\(\)0.0007 & 0.1405\(\)0.0035 \\  & Fourier-Flows & 0.2214\(\)0.00024 & 0.3814\(\)0.0164 & 0.4514\(\)0.0123 & 0.0912\(\)0.0008 & 0.1281\(\)0.0077 \\  & DDPM & 0.1595\(\)0.0018 & **0.2955\(\)0.0144** & **0.3215\(\)0.0154** & 0.0875\(\)0.0006 & 0.1028\(\)0.0062 \\  & Diffusion-TS & 0.1565\(\)0.0016 & 0.2985\(\)0.0174 & 0.3285\(\)0.0149 & **0.0863\(\)0.0007** & **0.1018\(\)0.0045** \\  & FIDE (Ours) & **0.1541\(\)0.0021** & 0.3001\(\)0.0191 & 0.3251\(\)0.0177 & 0.0893\(\)0.0007 & 0.1061\(\)0.0054 \\   

Table 2: Comparison of the generated sample distribution for all values using KL divergence and CRPS metrics. **Bold** and **Underlined** entries denote the best and second-best result. For the JS Divergence and Predictive Score metrics, the results are given in Appendix E.

Figure 5: Comparison of block maxima distribution and all values distribution for real and generated samples using the proposed FIDE model and DDPM  when applied to the synthetic AR(1) dataset.

results are shown in Tables 2 and 4 (in Appendix E). Note that FIDE achieves comparable performance to state-of-the-art methods like DDPM  and Diffusion-TS . This is further illustrated by the distribution plots of all values for DDPM and FIDE given in Figure 5-(c) and (d). The results in Table 2 also show that FIDE consistently outperforms VAE-based, GAN-based, and Flow-based alternatives. For Predictive Score, while TimeGAN and TimeVAE show marginally better results, FIDE maintains competitive performance against other baseline methods. These results suggest minimal performance degradation when applying FIDE to time series data. Despite its emphasis on block maxima values, this does not significantly compromise its ability to model the overall distribution. This positions FIDE as a robust and versatile generative model for capturing extreme values in time series.

### Ablation Study

In our ablation study depicted in Table 3, we systematically assessed the individual contributions of each component within our proposed framework. By selectively deactivating elements such as the GEV loss, conditional block maxima input, and high-frequency inflation module, we observed consistent performance degradation across all scenarios. Notably, the absence of the conditional block maxima input significantly impacted the Jenson-Shannon Divergence and KL Divergence metrics, while the lack of the GEV loss had the most pronounced effect on the CRPS metric. Surprisingly, the predictive score remained relatively resilient to the deactivation of any single component, suggesting a degree of redundancy or compensatory mechanisms among the remaining components. Overall, our ablation study highlights the indispensable role of each component in achieving optimal performance in our model. In summary, our findings underscore the holistic importance of the individual components, with their synergistic interplay contributing to the overall effectiveness of FIDE.

## 6 Conclusions

This framework examines the challenges of applying diffusion models to capture extreme values in time series. Through a comprehensive exploration of the constraints within current diffusion-based models, the proposed FIDE framework addresses these limitations by introducing a novel strategy to maintain high-frequency components of the time series. FIDE extends conventional diffusion models to enable conditional generation of block maxima by integrating a loss function based on the generalized extreme value (GEV) distribution. The superiority of the framework over various baseline methods is validated through rigorous experiments on both synthetic and real-world data.

## 7 Acknowledgment

This research is supported by the U.S. National Science Foundation under grant IIS-2006633. Any use of trade, firm, or product names are for descriptive purposes only and do not imply endorsement by the U.S. Government.

  Metrics & Methods & AR1 & Stock & Energy & Temperature & ECG \\  Jensen- &  &  & 0.0898+0.0054 & 0.0822+0.0084 & 0.0009+0.0001 & 0.0984+0.0058 \\ Shannon &  &  & 0.0154+0.0089 & 0.0941+0.0098 & 0.0010+0.0002 & 0.1102+0.0098 \\ Divergence &  &  & 0.0813+0.0035 & 0.0715+0.0041 & 0.0008+0.0001 & 0.0922+0.0056 \\  Divergence &  &  & **0.0700+0.0061** & **0.0809+0.0029** & **0.0007+0.0001** & **0.0939+0.0082** \\   & FIDE - frequency inflation &  & 0.1599+0.0161 & 0.1054+0.0049 & 0.0036+0.0006 & 0.1854+0.0064 \\  KL &  &  & 0.1689+0.0210 & 0.1089+0.0095 & 0.0041+0.0010 & 0.1901+0.0063 \\  divergence &  &  & 0.1551+0.0183 & 0.1021+0.0088 & 0.0032+0.0009 & 0.1832+0.0092 \\   &  &  & **0.1594+0.0128** & **0.0954+0.0098** & **0.0029+0.0008** & **0.0180+0.0084** \\   & FIDE - frequency inflation & 0.0391+0.0078 & 0.2172+0.0158 & 0.2152+0.0791 & 0.0649+0.0081 & 0.2372+0.0181 \\   &  &  & 0.2156+0.0132 & **0.0282+0.078** & 0.0651+0.0047 & 0.2382+0.0184 \\   &  &  & 0.2232+0.0033 & 0.2189+0.0074 & 0.0185+0.0104 & 0.2456+0.0399 \\   &  &  & **0.2115+0.0152** & 0.2085+0.0985 & **0.0517+0.0082** & **0.2345+0.0204** \\   & FIDE - frequency inflation & **0.6670+0.012** & 0.8942+0.0158 & 0.7264+0.0096 & 0.6711+0.0091 & 0.9084+0.0154 \\   &  &  & 0.8901+0.0141 & 0.7261+0.0081 & 0.6715+0.0078 & 0.0959+0.01272 \\   Score &  &  & 0.8891+0.0122 & 0.7269+0.0074 & 0.6712+0.0009 & 0.9062+0.0058 \\    &  &  & **0.8871+0.0104** & **0.7240+0.0087** & **0.6694+0.0082** & **0.9040+0.0112** \\  

Table 3: Ablation Study of generated samplesâ€™ block maxima distribution metrics and predictive score using the proposed FIDE model and without individual component of the model