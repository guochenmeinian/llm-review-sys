# Hamiltonian Monte Carlo on ReLU

Neural Networks is Inefficient

 Vu C. Dinh

Department of Mathematical Sciences

University of Delaware

vucdinh@udel.edu

&Lam Si Tung Ho

Department of Mathematics and Statistics

Dalhousie University

lam.ho@dal.ca

&Cuong V. Nguyen

Department of Mathematical Sciences

Durham University

viet.c.nguyen@durham.ac.uk

###### Abstract

We analyze the error rates of the Hamiltonian Monte Carlo algorithm with leapfrog integrator for Bayesian neural network inference. We show that due to the non-differentiability of activation functions in the ReLU family, leapfrog HMC for networks with these activation functions has a large local error rate of \(()\) rather than the classical error rate of \((^{3})\). This leads to a higher rejection rate of the proposals, making the method inefficient. We then verify our theoretical findings through empirical simulations as well as experiments on a real-world dataset that highlight the inefficiency of HMC inference on ReLU-based neural networks compared to analytical networks.

## 1 Introduction

In recent years, there has been a growing interest in doing full Bayesian analyses for neural networks and deep learning (Hernandez-Lobato and Adams, 2015; Huber, 2020; Cobb and Jalaian, 2021; Dhulipala et al., 2023). Since neural network models are typically high-dimensional, Hamiltonian Monte Carlo (HMC) (Neal, 2011) is a natural choice over other Markov Chain Monte Carlo approaches (Duane et al., 1987; Neal, 2011). When the activation function of a network is analytic (e.g., sigmoid function), one could rely on the theoretical foundations and practical guidelines of HMC in classical settings with smooth energy functions for computational designs (Neal, 2011; Beskos et al., 2013; Betancourt et al., 2017).

For ReLU-based neural networks, the situation is not as clear since the ReLU activation has a point of non-differentiability at zero. The derivative of ReLU at zero, in principle, is not well-defined, although often set to be zero in most computational platforms (Bertoin et al., 2021). Since non-differentiability only happens on a set of measure zero on the parameter space, it is natural to assume that this technical singularity does not pose a problem beyond theoretical considerations. For example, when training ReLU networks, it is known that the vast majority of stochastic gradient descent sequences produced by minimizing the loss function are not meaningfully impacted by changing the value of the derivative of ReLU at zero (Berner et al., 2019; Bolte and Pauwels, 2020; Bertoin et al., 2021; Bianchi et al., 2022).

For HMC, this line of thought is also not completely misguided, as we will show in this paper that HMC with leapfrog integrator is correct (i.e., it samples from the correct distribution) as long as the computed derivatives during sampling are well-defined up to the second order and are compatible with the chain rule. Since the backpropagation algorithm to compute gradients for neural networksis designed with the chain rule as its foundation, HMC with ReLU-based networks is thus correct regardless of how the derivative of ReLU is defined at zero, as long as it is defined deterministically. From a theoretical perspective, if Hamiltonian dynamics can be simulated exactly, the acceptance probability of HMC is always one and non-differentiability is also not an issue.

In practice, however, Hamiltonian systems can rarely be exactly integrated and are often approximated by a symplectic integrator (e.g., the leapfrog integrator) (Neal, 2011). The approximation errors of the Hamiltonian during integration lead to a decay in the acceptance probability of the proposals. The focus of our analyses in this work is on the efficiency of practical implementations of HMC: we show that when a leapfrog HMC particle crosses a surface of non-differentiability (which corresponds to a single activation/deactivation of a neuron in the network), the Hamiltonian is likely to incur a local error rate of order \(()\), leading to uncontrollable error accumulation along the Hamiltonian path. This is in contrast with the classical local error rate \((^{3})\) for smooth Hamiltonian (Neal, 2011) and thus renders HMC inference on ReLU networks inefficient compared to its analytic counterparts. Since the issue is due to the differences in the derivatives of the potential energy on two domains across a surface of non-differentiability, it cannot be resolved through the choices of the derivative value of ReLU at zero.1

**Our contributions.** In this work, we analyze the HMC algorithm with the leapfrog integrator for Bayesian neural network inference:

* We formulate the theoretical conditions under which HMC with leapfrog integrator is correct, even when derivatives are not defined in classical senses.
* We provide an upper bound of order \(()\) for the error of Hamiltonian dynamics on ReLU-based networks, and establish that outside a small set of starting points in the parameter space, this error is also bounded from below by \(()\).
* We analyze the optimal dimensional scaling of the step size and acceptance probability of HMC for target distributions consisting of \(d 1\) independent and identically distributed (i.i.d.) dimensions with piece-wise affine non-differentiable log-density components. From this result, we obtain a new guideline for tuning HMC with a first-order symplectic integrator that suggests a scaling of \(d^{-1/2}\) for the step size and an optimal acceptance probability of \(0.45\).
* Through experiments with both synthetic and real datasets, we validate our theoretical analyses and highlight the inefficiency of ReLU neural networks compared to analytical networks.

**Related works.** Classical theoretical analyses of HMC algorithms are often performed under the assumptions that the potential functions (the negative log-likelihood of the posterior distributions) are smooth (Neal, 2011; Beskos et al., 2013; Betancourt et al., 2017). Another research direction considers the cases where the energy function is discontinuous (Pakman and Paninski, 2013; Afshar and Domke, 2015) or contains discrete parameters (Nishimura et al., 2020; Zhou, 2020) by introducing momentum adjustments near its discontinuity in a way that preserves the total energy. These results proved that the constructed algorithms preserve the correct stationary distribution but did not consider the efficiency of the approach, and they do not apply directly to the neural network models where the potential function is continuous. It is generally recognized that if the leapfrog transition is not effective in preserving the Hamiltonian, HMC is inefficient and the issue needs to be remedied by algorithmic modifications, for example, by using surrogate functions (Dinh et al., 2017) or non-volume-preserving proposals (Afshar et al., 2021). Other theoretical analyses of HMC also considered the global geometry such as the curvature of the HMC manifolds (Seiler et al., 2014), which is different from the local smoothness property that we consider in this paper.

## 2 Hamiltonian Monte Carlo for Neural Networks and Its Efficiency

**Bayesian neural networks (BNNs).** We consider a general Bayesian feed-forward neural network model (Neal, 1995). Formally, given a \(d_{0}\)-dimensional input \(x\) in a bounded open set \(^{d_{0}}\), the output \(f_{q}(x)\) of an \(M\)-layer feed-forward neural network with parameters \(q=(A_{1},b_{1},A_{2},b_{2},,A_{M},b_{M})\) is defined through several layers:

\[h_{0}(x) =x,\] (input layer) \[h_{j}(x) =(A_{j} h_{j-1}(x)+b_{j}),\ \ \ j=1,2,,M-1,\] ( \[M-1\] hidden layers) \[f_{q}(x) =h_{M}(x)=A_{M} h_{M-1}(x)+b_{M},\] (output layer)

where \(\) is an activation function, \(A_{j}^{d_{j} d_{j-1}}\) and \(b_{j}^{d_{j}}\), with \(d_{j}\) being the number of nodes in the \(j\)-th layer. Throughout this paper, we assume the parameter vector \(q\) belongs to a compact set \(\). In the Bayesian setting, given a dataset \(D=\{(x_{1},y_{1}),(x_{2},y_{2}),,(x_{n},y_{n})\}\) with inputs \(x_{i}\) and labels \(y_{i}\), the posterior distribution for the model parameters is:

\[P(q)(q)_{i=1}^{n}(q|x_{i},y_{i}),\]

where \((q)\) is the prior density and \((q|x_{i},y_{i})\) is the likelihood function given the data point \((x_{i},y_{i})\). Using the posterior, we obtain the posterior predictive distribution of any new data point \((x,y)\) by \(P(x,y|D)=(q|x,y)P(q)dq\), which can be used for prediction.

In this paper, we consider the general setting with a smooth (i.e., infinitely differentiable) loss function \(_{x,y}(q)\) that holds for several classification and regression problems. A simple case of this setting is regression with square loss (which corresponds to a Gaussian noise assumption with fixed, known variance) where \(_{x,y}(q)=(f_{q}(x)-y)^{2}\) and \((q|x,y)-(f_{q}(x)-y)^{2}\). Another common case is classification with cross-entropy loss where \(_{x,y}(q)=-((f_{q}(x))_{y})\) and \((q|x,y)=f_{q}(x)_{y}+c\) for some constant \(c\). The analyses of our work can also be extended easily to other Bayesian learning settings such as unsupervised learning and generative modeling with smooth losses.

**Hamiltonian Monte Carlo for BNNs with leapfrog integrator.** Since computing the posterior predictive distribution \(P(x,y|D)\) and other integrals over the posterior is generally intractable, especially for complex models like neural networks, we usually compute these quantities approximately. Among the approximation methods, HMC (Neal, 1995, 2011) is a popular choice for neural network models due to the availability of gradients and the effectiveness of the method when exploring the parameter space. In general, HMC uses a Hamiltonian dynamical system to sample \(m\) parameter vectors \(_{1},_{2},,_{m}\) from the posterior \(P(q)\) and then approximate \( g(q)P(q)dq_{i=1}^{m}g(_{i})\) for any function \(g\) of interest. To sample from \(P(q)\), HMC proposes to extend the state space to include auxiliary momentum variables \(p\) of the same dimension as \(q\) and study the canonical distribution:

\[P(q,p)(-H(q,p)),\]

where \(H(q,p)=U(q)+K(p)\), with \(U(q)=- P(q)\) and \(K(p)=\|p\|^{2}\). Here we refer to \(H(q,p)\), \(U(q)\), and \(K(p)\) as respectively the Hamiltonian, the potential energy function, and the kinetic energy function of the Hamiltonian system at the state \((q,p)\). We assumed that \(p(0,I)\) in the formulation above, although in theory \(p\) could have a more general distribution. After defining \(P(q,p)\), we can then sample \(_{1},_{2},,_{m}\) successively from this canonical distribution using Hamiltonian dynamics. Specifically, given the current position \(_{i}\), we sample \(_{i+1}\) in two steps, both of which leave the canonical distribution invariant (i.e., the canonical distribution is the invariant distribution of the Markov kernels associated with those samplers). In the first step, we randomly draw a vector \(_{i}\) of new values for the momentum variables from their Gaussian distribution, independently of the current values \(_{i}\) of the position variables. In the second step, a Metropolis update is performed where a new sample is proposed by simulating Hamiltonian dynamics for \(L\) steps using the leapfrog method (Skeel, 1999; Leimkuhler and Reich, 2005; Sanz-Serna and Calvo, 2018) with a step size of \(\). In particular, starting from the initial state \((q_{0},p_{0})=(_{i},_{i})\), we perform the following updates for \(L\) steps:

\[p_{1/2} =p_{0}-(q_{0}), \] \[q_{1} =q_{0}+\,p_{1/2},\] (2) \[p_{1} =p_{1/2}-(q_{1}). \]The momentum variables at the end of this trajectory are then negated to obtain a proposed state \((,)\), which is accepted with probability \(\{1,(-H(,)+H(q_{0},p_{0}))\}\), giving the new state \((_{i+1},_{i+1})\). The negation of the momentum at the end of this \(L\)-step trajectory makes the Metropolis proposal symmetrical, but is not necessarily needed in practice, since \(K(p)=K(-p)\) and the momentum will be replaced before it is used again in the next iteration.

HMC offers an attractive Monte Carlo method, especially in high dimensions: an HMC particle can travel a long distance across the state space while Hamiltonian dynamics keep the Hamiltonian \(H(q,p)\) relatively constant, leading to a high acceptance rate (Neal, 2011). When the energy functions are smooth, the algorithm has a well-established theoretical foundation that guarantees its correctness and efficiency through two main observations: (i) the leapfrog integrator is reversible and preserves volume, and (ii) the local error of a leapfrog step is \((^{3})\)(Neal, 2011). Property (ii) essentially allows the HMC particles to travel a length of \(L\) while maintaining a small rejection rate of order \((L^{3})\). In practice, HMC is often tuned according to a fixed travel time \(T\); that is, \(L=T/\) for a fixed constant \(T\). In this case, the global error of HMC (and thus, the rejection rate of the proposals) is of order \((T^{2})\).

**Efficiency of HMC and optimal tuning.** One important aspect of implementing HMC is tuning the two main parameters: the step size \(\) and the travel time \(T\). The main considerations are: (i) how to scale \(\) with the dimension of the problem, and (ii) how to choose both \(\) and \(T\) to achieve a balance between the effort to simulate a long trajectory and the acceptance probability of the resulting proposal. The analyses for such optimal acceptance probability are often done via a proxy case where the model parameters consist of \(d 1\) smooth and i.i.d. components (Beskos et al., 2013; Betancourt et al., 2014). In this setting, Beskos et al. (2013) rely on the global error rate \((^{2})\) to show that HMC with leapfrog requires \(L(d^{1/4})\) steps to traverse the state space and the step size \(\) is generally scaled as \(d^{-1/4}\) for an average acceptance probability of \((1)\). If we let \(=ld^{-1/4}\) for some tunable parameter \(l\), the number of leapfrog steps is \(L=T/=T/(ld^{-1/4})\), and the computational cost to compute a single proposal will be approximately:

\[C_{0} d}=C_{0}d^{5/4},\]

where \(C_{0}\) measures the cost of one leapfrog step in one dimension. Given a starting location \(q\), the number of proposals until acceptance follows a geometric distribution with some probability of success \(A(q,l)\). Using Jensen's inequality, the expected cost until the first accepted proposal in stationary is bounded from below by:

\[C_{0}\,[A(q,l)]}\,d^{5/4}.\]

Here the quantity \(l[A(q,l)]\) is called the _efficiency_ of the HMC algorithm, and a sensible approach for optimal tuning of HMC is to choose \(l\) such that this efficiency function is minimized. In the setting with i.i.d. smooth parameters, Beskos et al. (2013) show that:

\[_{d}[A(q,l)]=2(-l^{2}/2):=a(l),\]

where \(\) is the c.d.f. of the standard normal distribution and \(\) is an unknown constant. While \(\) and the optimal \(l_{opt}\) of the function \(l a(l)\) generally depend on the specific target distribution under consideration, it can be shown that \(a(l_{opt})\) does not vary with the selected target distribution. Thus, in practice, we can compute the efficiency by setting \(=1\); that is, the efficiency is computed as \(2l(-l^{2}/2)\). This leads to an optimal acceptance probability of \(a(l_{opt})=0.651\), which is often used in practice for HMC tuning (Neal, 2011; Campbell et al., 2021; Hoffman et al., 2021; Nijkamp et al., 2021). Subsequently, Betancourt et al. (2014) extend this analysis to include an upper bound and suggest the target average acceptance probability can be relaxed to \(0.6 a(l) 0.9\).

## 3 Correctness and Efficiency of Leapfrog HMC on ReLU Neural Networks

In this section, we shall present our theoretical results on the correctness and efficiency of HMC with leapfrog integrator on Bayesian ReLU neural networks. First, we prove a general result in Theorem 3.1 on the correctness of leapfrog HMC on models that use backpropagation. As a special case of this theorem, leapfrog HMC on neural networks with the ReLU activation is correct (i.e., it samples from the correct distribution), even when derivatives are not defined in a classical sense.

**Theorem 3.1**.: _If the derivatives of the potential energy function \(U\) are well-defined up to the second order and are compatible with the chain rule, i.e.,_

\[(((q)))= U}{ q^{2}}((q))(q)\]

_for all smooth functions \(\), then the leapfrog integrator is reversible and preserves volume. As a consequence, the HMC sampler with leapfrog integrator leaves the canonical distribution invariant._

Since the backpropagation algorithm is designed with the chain rule as its foundation, Theorem 3.1 tells us that leapfrog HMC on ReLU neural networks is correct regardless of how the derivative of ReLU is defined at 0, as long as it is defined consistently. A complete proof of this theorem is provided in Appendix A.1, where deterministic definitions of first derivatives are needed to guarantee reversibility, and the chain rule concerning second derivatives of the potential function appears when computing the Jacobian of the leapfrog transformation to ensure volume-preservation.

Having established the correctness of leapfrog HMC on ReLU neural networks, we now turn to the main emphasis of our paper: the efficiency of this algorithm. Note that from our discussion in Section 2, the efficiency of HMC depends on the acceptance probability of the proposals and the approximation error of the Hamiltonian. Thus, our idea here is to show that when the HMC particles cross a surface of non-differentiability (e.g., that corresponds to a single activation/deactivation of a neuron in the ReLU network), the Hamiltonian will likely incur a local error rate of order \(()\), leading to uncontrollable error accumulation along the Hamiltonian path.

To analyze the efficiency of HMC, we need a result about the (ir)regularity of the potential function of ReLU-based networks, which is stated in Lemma 3.2 below. Essentially, the output of a ReLU feed-forward neural network at a node (before activation) can be characterized by the activation patterns (on-off for ReLU) of all nodes from previous layers feeding into it. When these activation patterns are fixed, the output at a node is a multilinear/polynomial function of the network parameters. Non-differentiability thus arises when the values of these functions cross zero, leading to "jumps" in values of partial derivatives of the potential functions that drive Hamiltonian dynamics.

**Lemma 3.2**.: _If the activation function \(\) is piece-wise affine with a single point of non-differentiability at \(0\), then there exists a finite union of smooth surface \(S=_{i I}S_{i}\) with \(S_{i}=\{q:f_{i}(q)=0\}\) and analytic functions \(f_{i}\), such that \( U/ q\) is non-smooth on \(S\) but locally smooth everywhere else._

The proof of this lemma is in Appendix A.2, which uses an induction argument on the layers of the feed-forward neural networks. As HMC explores the parameter space, these patterns change as the dynamics cross a surface of non-differentiability. Since the on-off ReLU activation patterns are discrete in nature, the behaviors of HMC with ReLU networks resemble those of models with discrete parameters (Dinh et al., 2017; Nishimura et al., 2020; Zhou, 2020) rather than a purely continuous one. Lemma \(3.2\) extends naturally for all piece-wise affine functions with only one point of non-differentiability at \(0\) such as the leaky ReLU activation function.

**Analysis of local errors.** The next step in our analysis is to derive the local error rate of the leapfrog HMC algorithm on ReLU networks. To give an intuition for our result, we will demonstrate an error analysis for the simpler case where the particle crosses a surface of non-differentiability only once. In this case, we consider a single leapfrog step starting at \((q_{0},p_{0})\) and ending at \((q_{1},p_{1})\) after performing the updates in Equations (1)-(3). If we assume that along this linear path, the particle crosses a surface of non-differentiability exactly once at a point \(z\), then we have:

\[ K=K(p_{1})-K(p_{0}) =(\|p_{1}\|^{2}-\|p_{0}\|^{2})\] \[=(\|p_{0}-(q_{0})-(q_{1}) \|^{2}-\|p_{0}\|^{2})\] \[=-p_{0}((q_{0})+(q_{1}))+(^{2})\] \[=-p_{1/2}((q_{0})+(q_{1}))+(^{2}),\]and \( U=U(q_{1})-U(q_{0})\)

\[=U(q_{1})-U(z)+U(z)-U(q_{0})\] \[=_{_{1}}^{}(q_{0}+ t\,p_{1/2}) p_{1/2}\,dt+_{0}^{_{1}}(q_{0 }+t\,p_{1/2}) p_{1/2}\,dt\] \[=}{2}\,p_{1/2}[}{  q}(z)+(q_{1})]+}{ 2}\,p_{1/2}[(q_{0})+}{ q}(z)]+(^{3}),\]

where \(_{1}\) and \(_{2}\) are the time spent along the path before and after crossing the surface of non-differentiability, respectively. Similarly, \(}{ q}(z)\) and \(}{ q}(z)\) denote the gradients at \(z\) on the two differentiable regions before and after the incidence, respectively. Thus, we can deduce the local error of the Hamiltonian:

\[ H=H(q_{1},p_{1})-H(q_{0},p_{0}) =}{2}[-_{2}((q_{0})-}{ q}(z))-_{1} ((q_{1})-}{ q}(z )).\] \[.+(_{2}-_{1})(}{ q}(z)-}{ q}(z))]\] \[=-_{1})}{2}\,p_{1/2}(}{ q}(z)-}{ q}(z))+ (^{2}),\]

since \( U/ q(z)\) is Lipschitz in each domain of continuity due to \(U\) being analytic in these bounded domains.

Our analysis above shows that even if the particle crosses a surface of non-differentiability once, the incurred local error \( H\) will be of order \(()\). This analysis can be generalized to the case when the linear path from \((q_{0},p_{0})\) to \((q_{1},p_{1})\) crosses multiple regions. We thus have the following general result with the proof given in Appendix A.3.

**Theorem 3.3**.: _Consider a leapfrog step starting at \((q_{0},p_{0})\) and ending at \((q_{1},p_{1})\) that crosses the surfaces of non-differentiability at \(z_{1},z_{2},,z_{k}\) at time \(_{1},_{2},,_{k}\). The local approximation error incurred can be estimated by:_

\[ H=H(q_{1},p_{1})-H(q_{0},p_{0})=p_{1/2}_{i=1}^{k}(-_{i})(}{ q}(z_{i} )-}{ q}(z_{i}))+(^{2}),\]

_where \(}{ q}(z_{i})\) and \(}{ q}(z_{i})\) denote the gradients of \(U\) at \(z_{i}\) on the two differentiable regions before and after crossing \(z_{i}\), respectively._

Theorem 3.3 indicates that, in general, \( H=()\) and is difficult to control. \( H\) can only be small (i.e., smaller than \(O()\)) if the leapfrog path crosses the regions at a very specific time. For example, when \(k=1\), this corresponds to the path crossing a boundary approximately at time \(t/2\). The following lemma shows that this happens only at a very small subset of the state space. The proof of this lemma is given in Appendix A.4.

**Lemma 3.4**.: _For \(M>0\) and \(a>0\), define \(_{M,a}\) as the set of all augmented states \((q,p)\) such that: \(\|p\| M\) and a single leapfrog step starting at \((q,p)\) crosses a surface of non-differentiability exactly once at time \(_{1}((1-a),(1+a))\). Let \(_{M,a}\) be the set of all augmented states \((q,p)\) such that the \(L\)-step leapfrog Hamiltonian trajectory starting at \((q,p)\) belongs to \(_{M,a}\) at some point along the path. There exist \(C>0\) and \( 2\) that depend only on the potential energy function (and are independent of \(\), \(\), \(L\), and \(M\)) such that:_

\[(_{M,a})(CaM)^{1/}\ \ \ \ (_ {M,a})(CaM)^{1/}L,\]

_where \(\) denotes the Lebesgue measure on \(^{d}\), with \(\) being the parameter space._

Another direct consequence of Theorem 3.3 is that for a fixed travel time \(T\) (i.e., \(L=T/\) for a fixed constant \(T\)), as \(\) goes to zero, the global errors of leapfrog HMC can be controlled by

\[_{z}p(z)(}{  q}(z)-}{ q}(z))+(T ),\]where \(\) denotes the set of points of non-differentiability along the Hamiltonian path when the system is integrated exactly with the same initial state for an amount of time \(T\).

**Tuning HMC on ReLU neural networks.** Our result above indicates that for ReLU networks, HMC proposals may accumulate a rejection rate of order \((N)\), where \(N\) is associated with the number of times the dynamics cross a surface of non-differentiability (i.e., when a ReLU neuron is activated or deactivated). This means that the classical guidance for implementations of HMC is no longer valid for ReLU networks. However, with our theoretical result above, we can still adapt the analyses of Beskos et al. (2013) and Betancourt et al. (2014) to obtain similar guidelines for tuning HMC with a first-order symplectic integrator. These guidelines are stated in the following proposition, with the proof given in Appendix A.5.

**Proposition 3.5**.: _Consider a target distribution on vectors consisting of \(d 1\) i.i.d. piece-wise affine non-differentiable log-density components. The following statements hold:_

1. _HMC with the leapfrog integrator has a global error rate of_ \(()\)_._
2. _The step size_ \(\) _should be scaled as_ \(d^{-1/2}\) _for an_ \((1)\) _average acceptance probability._
3. _The optimal acceptance probability of leapfrog HMC is approximately_ \(0.45\)_._
4. _The range of target average acceptance probability can be relaxed to_ \([0.4,0.75]\)_._

As a consequence of this proposition, for piece-wise affine non-differentiable log-densities, as the dimension increases, the computational cost to maintain a constant average acceptance probability grows as \(d^{3/2}\) as opposed to \(d^{5/4}\) in classical cases (Beskos et al., 2013). Statement (d) of the proposition follows the discussions from Betancourt et al. (2014), where the detailed analysis uses both the upper and lower bounds of the efficiency function. This analysis is illustrated in Figures \(4\) and \(5\) in the appendix.

It is worth noting that for the random-walk Metropolis (RWM) algorithm, the scaling and optimal acceptance probability are \(d^{-1}\) and \(0.23\), respectively (Yang et al., 2020). The corresponding quantities for the Metropolis-adjusted Langevin algorithm (MALA) are \(d^{-1/3}\) and \(0.57\) when the potential energy function is seven times differentiable (Roberts and Rosenthal, 1998). Thus, the scaling of the step size and the optimal acceptance probability for HMC in this setting are still more efficient than RWM but are less ideal than those of analytic cases.

We want to reiterate that these analyses above are only for the proxy case of \(d 1\) independent and identically distributed vector components. In this setting, the number of critical events (where the HMC particle crosses a surface of non-differentiability) increases linearly as the dimension \(d\) increases. For general ReLU networks, it is still unclear how the number of critical events would change with increasing dimension of the parameter space. It is worth noting that for a fixed generic parameter configuration, it is suggested that for any line segment through the input space, the average number of regions (of the input space) intersecting with it is linear in the number of neurons, which is far below the exponential number of regions that is theoretically attainable (Hanin and Rolnick, 2019). However, we are not aware of similar results for the number of (polynomial) regions on the parameter space for fixed inputs.

## 4 Experiments

### Synthetic Dataset

In this section, we shall conduct empirical simulations to validate our theoretical analyses. For the simulations, we generate a synthetic dataset with 100 examples where \(x\) uniform(0, 4) and \(y((2x),0.1^{2})\). The dataset is shown in Figure 6 in Appendix A.6. Using this dataset, we investigate the influences of several hyper-parameters on the average acceptance rate and the efficiency of HMC on ReLU-based and analytic networks, including the step size \(\), the number of leapfrog steps \(L\) and the dimension \(d\) of the model parameters. Our simulations are implemented using the Autograd package (Maclaurin et al., 2015).

This section will focus on computational aspects of HMC with BNNs that are not directly obtainable from our theoretical analysis. First, as highlighted in Section 3, we can qualitatively compare the efficiency of ReLU-based and analytic networks through their optimal acceptance rates, as a lower optimal acceptance rate indicates that the model is less efficient. However, since they are only known up to a multiplicative constant in the exponents, the efficiency functions of two different models, such as between ReLU and analytic networks, are not quantitatively comparable through these theoretical analyses. We aim to validate such direct comparisons in our simulations. Second, some of our theoretical results are analyzed through the proxy cases of independent and identically distributed vector components. While this approach, as often done in analyses of HMC, provides good insights about the behaviors of HMC when the complexity of the models increases, this also leaves some uncertainties about the extent to which the results apply to neural network models, and we aim to complement those results through practical simulations.

**Effects of number of steps \(L\) and step size \(\).** In this simulation, we investigate the effects of \(L\) and \(\) on the acceptance rate of HMC on BNNs with different types of activation functions. In particular, we consider one hidden layer neural networks with 50 hidden nodes that use either the sigmoid, ReLU, or leaky ReLU activation. We choose a standard normal prior \((q)=(0,I)\) and sample 2,000 parameter vectors from the posterior after a burn-in period of 100 samples. We vary the number of steps \(L\{200,400,600,800,1000\}\) together with the step size \(\{0.0005,0.0010,0.0015,0.0020,0.0025\}\) and record the corresponding acceptance rates. We repeat this procedure 5 times with different random seeds to obtain the average acceptance rates and their standard errors. The full results of this simulation are reported in Table 2 in Appendix A.6, with some typical trends shown in Figure 1.

From Figure 1, we observe that the average acceptance rate of sigmoid networks, across different values of the step size \(\), is generally higher than those of ReLU and leaky ReLU networks. As \(\) increases, the decay in average acceptance rate of sigmoid networks is moderate and stable across different values of \(L\). On the other hand, the drops in average acceptance rate for ReLU and leaky ReLU networks are significant, and the problem exacerbates for large values of \(L\).

We also note that for sigmoid networks, the average acceptance rate for fixed step sizes are relatively constant as \(L\) increases. This behavior is somewhat expected for symplectic integrators with smooth target distributions, as high-order symplectic integrators (i.e., those with global error at most \((^{2})\)) are known to not only approximate the flow of the Hamiltonian \(H\) corresponding to the canonical distributions, but also exactly simulate the flow for some modified Hamiltonian \(\)(Betancourt et al., 2014). This makes the approximation errors bounded in \(L\) for an appropriately small step size \(\) with smooth target distributions. For ReLU-based networks, the regularity conditions for such asymptotic behaviors do not hold, and as presented in Figure 1, the leapfrog integrator becomes unstable, manifesting in numerical divergences that pull the approximation errors to infinity and the average acceptance rate to zero as \(L\) increases.

Figure 1: Acceptance rates of HMC with respect to the number of leapfrog steps \(L\) (left) and step size \(\) (right) on BNNs with different activation functions. The decay in acceptance rates of sigmoid networks is much more moderate than those of ReLU-based networks.

**Efficiency vs. acceptance rate.** In this simulation, we investigate the efficiency as a function of the acceptance rate. We use the same setting as the previous simulation, except that here we fix the travel time \(T= L=0.1\) and vary \(\{0.0005,0.0010,0.0015,,0.0040\}\). Recall from Section 2 that for a fixed \(d\) (the dimension of the problem), the expected computational cost until the first accepted proposal in stationary is inversely proportional to the \(\,[A(q,)]\). Thus, in Figure 1(a), we plot the average curves (after interpolating 5 random runs) of the efficiency (up to a multiplicative constant) function \(f(a_{})=\,a_{}\), where \(a_{}\) is the acceptance rate of the step size \(\).

Figure 1(a) shows that HMC for analytic networks is much more efficient than their ReLU counterparts. For every reasonable value of the target acceptance rate, the computational costs for ReLU networks are much higher than that of the sigmoid network. At the empirically optimal acceptance rate (\( 0.75\)), the difference in performance is by a factor of more than 4. We also note that the optimal empirical acceptance rates for sigmoid, ReLU, and leaky ReLU networks in this simulation are 0.755, 0.6525, and 0.724, respectively. These empirical values are higher than their theoretical quantities (0.651 for sigmoid networks and 0.45 for ReLU-based networks), but are consistent with the relaxed ranges using upper and lower bounds of the efficiency (\(0.6 a_{} 0.9\) for sigmoid and \(0.4 a_{} 0.75\) for ReLU-based networks).

**Effects of dimensionality.** This simulation aims to study the effects of the dimension \(d\) of the parameter space as well as the network architecture on the acceptance rate of HMC. For this purpose, we consider two types of architectures: (i) shallow networks with one hidden layer containing either 10, 50, 100, 200, or 400 nodes, and (ii) deep networks with 1, 2, 3, or 4 hidden layers, each of which contains 20 nodes. For each network, we run HMC with \(L=200\) and \(=0.001\) while keeping other hyper-parameters the same as in previous simulations.

We plot the average acceptance rate with respect to the number of model parameters in Figure 3. From this figure, when \(d\) increases (either by increasing width or depth), all models exhibit some decays in

Figure 3: Acceptance rate of HMC with respect to the number of model parameters on shallow and deep neural networks with different activation functions. HMC on shallow networks generally has lower acceptance rates than deep networks of the same size.

Figure 2: Efficiency of HMC with respect to acceptance rate on BNNs with different activation functions. On both synthetic and UTKFace datasets, HMC inference with sigmoid networks is more efficient than with ReLU-based networks.

acceptance rates. However, ReLU and leaky ReLU networks become unstable rather quickly, while the sigmoid network can perform relatively well in the same settings. The results also indicate that Bayesian learning with HMC for wide networks seems more difficult than for deep networks of the same number of parameters, hinting that there are other geometric forces in place other than the dimensionality of the problem.

### UTKFace Dataset

In addition to the synthetic dataset above, we also conduct experiments to validate our theoretical findings on a subset of the real-world UTKFace dataset (Zhang et al., 2017). This is an image regression dataset where we need to predict the age of a person given an image of their face. Using this dataset, we will compare the efficiency curves, the acceptance rates, and the mean squared errors (MSEs) of HMC sampling on the sigmoid, ReLU, and leaky ReLU networks. Details of our experiment settings are given in Appendix A.6.

In Figure 1(b), we plot the efficiency versus acceptance rate curves in an experiment similar to that with the synthetic data above. The figure shows that the sigmoid curve is more efficient than the ReLU and leaky ReLU curves. The optimal acceptance rates for sigmoid, ReLU, and leaky ReLU networks are 0.813, 0.797, and 0.627 respectively. In Table 1, we show the average acceptance rate, average MSE, and the average MSE at the best acceptance rate for each network type. From the table, the sigmoid network has the highest acceptance rate as well as the lowest MSE. However, if we tune HMC to the best empirical acceptance rate in each network type, their MSEs become very similar.

## 5 Conclusions and Future Works

We analyzed the error rates of the HMC algorithm with leapfrog integrator for Bayesian neural network inference and showed, through theoretical analyses and experiments, that HMC on ReLU-based networks is inefficient compared to analytical networks. Our results highlight that for HMC, non-differentiability is not an issue that can be ignored, even if singularity only occurs on a set of measure zero. Several aspects of the paper could be the subjects of future works. First, since HMC accumulates a rejection rate of order \((N)\), where \(N\) is associated with the number of times the dynamics cross a surface of non-differentiability, the characterization of this quantity and its dependency on the network architecture play a central role in studying the efficiency of this algorithm. As noted in Section 3, it is known that the average number of input regions intersecting with a line segment through the input space is linear in the number of neurons (Hanin and Rolnick, 2019). Thus, a similar result for the number of polynomial regions on the parameter space for fixed inputs would shed light into the decays of the acceptance rates in Figure 3. Another potential future work is to extend the general ideas in this paper to other models with non-differentiable components, such as the max-pooling layers in convolutional neural networks.