# Collaboratively Learning Linear Models with Structured Missing Data

Chen Cheng

Stanford University

chencheng@stanford.edu

&Gary Cheng1

Stanford University

chenggar@stanford.edu

&John Duchi

Stanford University

jduchi@stanford.edu

Equal contribution, authors ordered alphabetically by (last name, first name)

###### Abstract

We study the problem of collaboratively learning least squares estimates for \(m\) agents. Each agent observes a different subset of the features--e.g., containing data collected from sensors of varying resolution. Our goal is to determine how to coordinate the agents in order to produce the best estimator for each agent. We propose a distributed, semi-supervised algorithm Collab, consisting of three steps: local training, aggregation, and distribution. Our procedure does not require communicating the labeled data, making it communication efficient and useful in settings where the labeled data is inaccessible. Despite this handicap, our procedure is nearly asymptotically, local-minimax optimal--even among estimators allowed to communicate the labeled data such as imputation methods. We test our method on US Census data. We also discuss generalizations of our method to non-Gaussian feature settings, non-linear settings, and Federated Learning.

## 1 Introduction

Consider a set of agents that collect data to make predictions, where different agents may collect different features--because of different sensor availability or specialization--but wish to leverage shared structure to achieve better accuracy. Concretely, suppose we have \(m\) agents, where each agent \(i[m]\) observes \(n\) samples of \((x_{i+},y)\) where \(x_{i+}^{d_{i}}\) is some subset of \(x^{d}\). We set this as a regression problem where the data \((x,y)\) has the linear relationship \(y= x,+\) for some noise variable \(\). For example, these agents could be a network of satellites, each collecting data with a distinct set of sensors of varying resolution and specialization, with the purpose of estimating quantities like crop-yields , biomass , and solar-flare intensity . Or these agents could be a group of seismic sensors, using acoustic modalities or accelerometers to predict whether an earthquake will occur . Other examples may include networks of hospitals or phones . In these settings, the agents can share information to collaboratively train a model; however, they are limited by communication bandwidth constraints, a situation satellites and seismic sensors often face due to radio frequency spectrum scarcity and interference [6; 20]. Without being too rigorous, we will define a communication efficient algorithm as one where the per-agent communication cost does not scale with \(n\), \(d\), or \(m\). No dependence on the dataset size \(n\) is suited for applications with significant data volume but limited communication resources. No dependence on the overall dimension \(d\) of the data ensures that agents are not incentivized to turn away agents with access to a richer set of features that would improve statistical performance but increase \(d\). Finally, no dependence on \(m\) ensures that the algorithm is scalable to large collectives of agents. Can we construct a statistically optimal and communication efficient procedure to estimate \(\)?

We answer in the affirmative and introduce our estimator Collab. Collab consists of three steps: local training on all agents, aggregation on a coordinating server, and distribution back to all agents. Our algorithm is communication-efficient: each agent \(i[m]\) syncs twice with a coordinating serverand incurs communication cost scaling like \((d_{i}^{2})\). We prove local minimax lower bounds which prove that Collab is (nearly) instance-optimal. We choose to study this problem in a stylized linear setting so that we can provide stronger guarantees for the algorithms we make. Indeed, our results which pair the exact asymptotic covariance of our estimator Collab with matching asymptotic local minimax lower bounds heavily rely on the linearity of our problem and would not be possible without strong structural assumptions. Having said this, the theory we develop for linear models does hint at potential methods for non-linear settings, which we discuss in Section 7. We also acknowledge privacy considerations are important for real world systems such as hospitals. We choose to focus instead on sensor settings where privacy is less of a concern. We leave adapting our results to privacy-sensitive settings to future work.

We compare our methods to single-imputation methods theoretically and empirically. We choose to baseline against imputation methods for three reasons. First, if we ignore communication constraints, our problem is a missing data problem, where formally the data is "missing at random" (MAR) . MAR problems are well studied, so we know that imputation methods work well theoretically and in practice [25; 15]. Second, because we have instance-optimal lower bounds, we know that imputation methods are also optimal for our problem. Finally, because imputation methods use more information than the method we propose, imputation will serve as a "oracle" baseline of sorts.

Contributions.We briefly summarize our contributions.

1. We design a communication-efficient, distributed learning algorithm Collab which performs a weighted de-biasing procedure on the ordinary least squares estimator of each agent's data.
2. We show Collab is asymptotically locally minimax optimal among estimators which have access to the ordinary least squares estimator of each agent's data. We also show that with some additional assumptions, Collab is also asymptotically locally minimax optimal among estimators that have access to _all_ of the training data of all agents.
3. We propose and develop theory for various baseline methods based on imputation. We compare the statistical error and communication cost of Collab against these baseline methods both theoretically and empirically on real and synthetic data.
4. We discuss generalizations of Collab for non-Gaussian feature settings and non-linear settings. We highlight open problems and identify possible directions for future work.

### Related Work

Missing data.If we ignore the communication and computational aspects of our problem, the problem we study reduces to one of estimation with missing data. There has been a lot of work on this topic; please see  for an overview. The data in our problem is missing at random (MAR)--the missing pattern does not depend on the value of the data and is known given agent \(i\). There are many approaches to handling missing data such as weighting and model-based methods . Most related to our work are methods on single imputation. Schafer and Schenker  shows imputation with conditional mean is nearly optimal with special corrections applied. More recently, Chandrasekher et al.  show that single imputation is minimax optimal in the high dimensional setting. Another closely related popular approach is multiple imputation [23; 1]. Previous work [27; 29] has shown that multiple imputation in low dimensional settings produces correct confidence intervals under a more general set of assumptions compared to single imputation settings. However, we choose to focus on single imputation methods for two reasons. First, we are interested in estimation error and not confidence intervals, and our lower bounds show that single imputation has optimal estimation error for our setting. Second, in our problem context, multiple imputation would require more rounds of communication and consequently higher communication cost. Other methods for missing data include weighting and model-based methods.

Distributed learning.Learning with communication constraints is a well studied practical problem. We provide a couple of examples. Suresh et al.  study how to perform mean estimation with communication constraints. Duchi et al.  develop communication-constrained minimax lower bounds. Distributed convex optimization methods like Hogwild  have also been well studied. However, the works mentioned all concern the no-missing-data regime. A more relevant subfield of distributed learning is federated learning. In federated learning, a central server coordinates a collection of client devices to train a machine learning model. Training data is stored on client devices, and due to communication and privacy constraints, clients are not allowed to share their training data with each other or the central server . In the no-missing-features regime, optimization algorithms for federated optimization are well studied. There is also more theoretical work, which focus on characterizing communication, statistical, and privacy tradeoffs, albeit for a more narrow set of problems such as mean and frequency estimation . More related to the missing data regime we consider is cross-silo federated learning  or vertical federated learning . In this paradigm, the datasets on client machines are not only partitioned by samples but also by features. Researchers have studied this problem in the context of trees , calculating covariance matrices , k-means clustering , support vector machines , and neural nets . Most related to our work is Gascon et al. , Hardy et al. ; they study how to privately perform linear regression in a distributed manner. However, unlike our work, these works focus more on developing algorithms with privacy guarantees rather than statistical ones.

## 2 Mathematical model

We assume we have \(m\) agents that observes a subset of the dimensions of the input data \(x^{d}\). Each agent \(i\) has a "view" permutation matrix \(_{i}^{}:=[_{i+}^{}_{i-}^{}] ^{d d}\). \(_{i+}^{d_{i} d}\) describes which feature dimensions the agent sees, and \(_{i-}^{(d-d_{i}) d}\) describes the dimensions the agent does not see. For a feature vector \(x^{d}\) and corresponding label \(y\), the \(i\)-th agent observes \((x_{i+},y)\) where \(x_{i+}_{i+}x^{d_{i}}\). Each agent has \(n\) fresh, independent observations (independent across agents) denoted as a matrix \(X_{i+} R^{n d_{i}}\) and vector \(y_{i}^{n}\). We let \(X_{i-}^{n(d-d_{i})}\) denote the unobserved dimensions of the input data \(x\) drawn for the \(i\)-th agent, and we let \(X_{i}^{n d}\) denote the matrix of input data \(x\) drawn for the \(i\)-th agent, including the dimensions of \(x\) unobserved by the \(i\)-th agent. To simplify discussions in the following sections, for any vector \(v^{d}\) we use the shorthand \(v_{i+}=_{i+}v\) and \(v_{i-}=_{i-}v\). Similarly for any matrix \(A^{d d}\) we denote by

\[A_{i+} =_{i+}A_{i+}^{}, A_{i-} =_{i-}A_{i-}^{},\] \[A_{i} =_{i+}A_{i-}^{}, A_{i} =_{i-}A_{i+}^{}.\]

For a p.s.d. matrix \(A\), we let \(\|x\|_{A}= x,Ax\).

We assume the data from the \(m\) agents follow the same linear model. The feature vectors \(x\) comprising the data matrices \(X_{1},,X_{m}\) are i.i.d. with zero mean and covariance \( 0\). We will assume that each agent has knowledge of \(_{i+}\)--e.g., they have a lot of unlabeled data to use to estimate this quantity. We also assume for each index tuple pair \((j,k)\) for \(1 j,k d\), there exists some agent that observes dimensions \(j\) and \(k\). This ensures the coordinating server can construct the complete covariance matrix \(\) from individual \(_{i+}\). The labels generated follow the linear model

\[y_{i}=X_{i}+_{i},_{i}}}{{ }}(0,^{2}I_{n}).\]

Throughout this work we consider a fixed ground truth parameter \(\).

Objectives.We are interested in proposing a method of using the data of the agents to form an estimate \(\) which minimizes the full-feature prediction error on a fresh sample \(x^{d}\)

\[_{x}[( x,- x,)^{2}]= \|-\|_{}^{2}.\] (1)

We are also interested in forming an estimate \(_{i}\) which minimizes the missing-feature prediction error of a fresh sample \(x_{i+}^{d_{i}}\) for agent \(i\)--i.e., \(x_{i+}=_{i+}x\) where \(x^{d}\) is fresh. Define \(T_{i}I_{d_{i}}&_{i+}^{-1}_{i}_ {i}\) and the Schur complement \(_{i-}_{i+}_{i-}-_{i }_{i+}^{-1}_{i}\). The local test error is then

\[_{x}[( x_{i+},_{i}- x, )^{2}]=\|_{i}-T_{i}\|_{_{i+}}^{2}+\|_{i-} \|_{_{i-}}^{2}\] (2)

We see that \(\|_{i-}\|_{_{i-}}^{2}\) is irreducible error. The role of the operator \(T_{i}\) is significant, as (2) shows that \(T_{i}\) is the best possible linear predictor for the \(i\)th agent2. Through this paper, we will also highlight the communication costs of the methods we consider. Recall that we would like our methods to have communication cost that do not scale with \(n\) or \(d\).

Method

We begin with some intuition of why collaboration should help. Then we outline an approach of solving this problem for general feature distributions. The general approach is not immediately usable because it requires some knowledge of \(\), so we need to do some massaging. In Section 3.3, we show how to circumvent this issue in the Gaussian feature setting and introduce our method Collab. Adapting the general approach to other non-Gaussian settings is an open problem, but we discuss some potential approaches in Section 7.

### Intuition

In order to build some intuition for how our approach leverages collaboration, we begin with some basic analysis of the no-collaboration solution: where each agent \(i\) only performs ordinary least squares on their local data

\[_{i}=X_{i+}^{}y_{i}}}{{=} }(X_{i+}^{}X_{i+})^{-1}X_{i+}^{}y_{i} }}{{=}}_{i+}+_{i+}^{-1}_{i}_{i- }+(X_{i+}^{}X_{i+})^{-1}X_{i+}^{}_{i},\]

here \(A^{}\) denotes the Moore-Penrose inverse for a general matrix \(A\), and (i) holds whenever \((X_{i+}) d_{i}\). Because we focus on the large sample asymptotics regime (\(n d_{i}\)), (i) will hold with probability \(1\). Expanding out the \(y_{i}\) gives equality (ii). Ignoring the zero-mean noise term, we see that \(\) must satisfy \(_{i+}+_{i+}^{-1}_{i}_{i-}- {}_{i} 0\) for all \(i[m]\). Our approach essentially tries to find such a \(\).

### Our General approach

In particular, after each agent \(i\) performing ordinary least squares on their local data to produce \(\{_{i}\}_{i[m]}\), we recover an estimate of \(\) by performing a form of weighted empirical risk minimization parameterized by the positive definite matrices \(W_{i}^{d_{i} d_{i}}\)

\[=(W_{1},,W_{m})*{argmin}_{ }_{i=1}^{m}\|_{i+}+_{i+}^{-1}_{i}_{ i-}-_{i}\|_{W_{i}}^{2}.\] (3)

We know by first order stationarity that \(=_{i=1}^{m}T_{i}^{}W_{i}T_{i}^{-1} _{i=1}^{m}T_{i}^{}W_{i}_{i}\). We can show that \(\) is a consistent estimate of \(\) regardless the choice of weighting matrices \(W_{i}\). In fact, if the features \(X_{i}\), \(_{i}\) are Gaussian, \(\) is also unbiased. See Lemma B.1 in the Appendix for this result. While Lemma B.1 shows that the choice of weighting matrices \(W_{i}\) does not affect consistency, the choice of weighting matrices \(W_{i}\) does affect the asymptotic convergence rate of the estimator. In the next theorem, we show what the best performing choice of weighting matrices are. The proof is in Appendix B.2.

**Theorem 3.1**.: _For any weighting matrices \(W_{i}\), the aggregated estimator \(=(W_{1},,W_{m})\) is asymptotically normal_

\[(-)=(0,C(W_{1}, ,W_{m})),\]

_with some covariance matrix \(C(W_{1},,W_{m})\). The optimal choice of weighting matrices is_

\[W_{i}^{}_{i+}([x_{i+}_ {i-}^{}z_{i+}z_{i+}^{}_{i-}x_{i+}^{}]+^{2} _{i+})^{-1}_{i+},\]

_where \(z_{i+}=x_{i-}-_{i}_{i+}^{-1}x_{i+}\). In particular, for all \(W_{i}\), \(C(W_{1},,W_{m}) C(W_{1}^{},,W_{m}^{})= _{i=1}^{m}T_{i}^{}W_{i}^{}T_{i}^{-1}\)._

The main challenge of using Theorem 3.1 is in constructing the optimal weights \(W_{i}^{}\), as at face value, they depend on knowledge of \(\). While we will discuss high level strategies of bypassing this issue in non-Gaussian data settings in Section 7, we will currently focus our attention on how we can make use of Gaussianity to construct our estimator Collab.

### Collab Estimator - Gaussian feature setting

If \(X_{i}\) are distributed as \((0,)\), \(W_{i}^{}\) has an explicit closed form as

\[W_{i}^{}=W_{i}^{\$}}{\|_{i-}\| _{_{i-}}^{2}+^{2}}=}{_{x,y}[( x_ {i+},_{i}-y)^{2}]},\]

where \(_{i-}=_{i-}-_{i}_{i+}^{-1}_{i}\) is the Schur complement. Recall we assume that each agent has enough unlabeled data to estimate \(_{i+}\). The denominator \(_{x,y}[( x_{i+},_{i}-y)^{2}]\) cannot be computed but we can use \(\|X_{i+}_{i}-y\|_{2}^{2}\), which is a consistent estimator of \(_{x,y}[( x_{i+},_{i}-y)^{2}]\), in its place. Thus, each agent is able to construct estimates of \(W_{i}^{\$}\) by computing

\[_{i}^{\$}}{\|X_{i+}_ {i}-y\|_{2}^{2}}\]

Now we construct our global and local Collab estimators defined respectively as

\[^{}(_{1}^{\$},,_{m}^{\$}),_{i}^{} T_{i}(_{1}^{\$},,_{m}^{\$}).\] (4)

We summarize the Collab algorithm in Algorithm 1. At a high level, \(^{}\) is an estimate of \(\) which also minimizes the full-feature prediction error (1) and \(_{i}^{}\) minimizes the missing-feature prediction error for agent \(i\) (2). Now we show that using the collective "biased wisdom" of local estimates \(_{i}\), our collaborative learning approach returns an improved local estimator. The proof is in Appendix B.3.

**Corollary 3.2**.: _Let \(X_{i}(0,)\) and define \(C^{\$}(_{i=1}^{m}T_{i}^{}W_{i}^{\$}T_{i})^{-1}\). The global Collab estimator \(^{}\) and the local \(_{i}^{}\) on agent \(i\) are asymptotically normal_

\[(^{}-)}{{}}(0,C^{\$}) (_{i}^{}-T_{i})}{{}}(0,T_{i}C^{\$}T_{i}^{} ).\]

_The following are true_

* \(W_{i}^{\$}\) _are the optimal choice of weighting matrices i.e.,particular,_ \(C(W_{1},,W_{m}) C(W_{1}^{\$},,W_{m}^{\$})=C^{\$}\)_._
* _On agent_ \(i\)_, we have_ \((_{i}-T_{i})}{{}} (0,(W_{i}^{\$})^{-1})\)_. The asymptotic variance of_ \(_{i}\) _is larger than that of the Collab estimator_ \(_{i}^{}\)_-i.e.,_ \((W_{i}^{\$})^{-1} T_{i}C^{\$}T_{i}^{}\)_._

_Remark 3.3_.: In Corollary 3.2, we can replace \(_{i+}\) in \(_{i}^{\$}\) with local sample covariances \(_{i+}\) for the plug-in estimator in Eq. (4). We prove this stronger statement in the proof of Corollary 3.2. However, as the coordinating server still need to use exact operators \(T_{i}\) to compute the Collab estimator, relaxing this condition does not bring practical benefit.

This result characterizes the error distribution of the Collab estimator; guarantees about prediction error, defined in (1) and (2), directly follow. In particular, letting \(z^{d}\) be distributed as \((0,C^{})\), by the continuous mapping theorem we have

\[n_{x}[( x,^{}- x, )^{2}]=n\|^{}-\|_{}^{2}\|z\|_{}^{2}.\] (5)

For large dimension \(d\), \(\|z\|_{}^{2}\) concentrates around its expectation \([\|z\|_{}^{2}]=(C^{})\). The same arguments can be applied to make a statement about the local test error (2).

Communication CostIn the first round of communication, agent \(i\) sends \(d_{i}^{2}+d_{i}+1\) real numbers to the coordinating server. In the second round of communication, the server sends back the updated local model which is \(d_{i}\) real numbers. In total, this amounts to \(d_{i}^{2}+2d_{i}+1\) communication cost per agent. The communication cost of Collab does not scale with \(n\), \(d\), or \(m\), satisfying our desiderata.

## 4 Comparison with other methods

In this section, we compare our collaborative learning procedure with other popular least squares techniques based on imputation and comment on the statistical efficacy and communication cost differences. We summarize our analysis in Table 1. The proofs of the theorems are in Appendix C. For the sake of brevity, our results here will center around estimating \(\). Analogous results centered around estimating \(T_{i}\) follow directly. These results can be connected to the full-feature and local test error by the same argument we made earlier to derive (5).

Local imputation w/ collaboration.Suppose a coordinating server collected covariance information \(_{i}\) from each agent and then distribute \(\) back to each of them. Then one intuitive strategy is to use this information to impute each agent's local data by replacing \(X_{i+}\) with \([X_{i} X_{i+}]=X_{i+}T_{i}\), before performing local linear regression. In other words, instead of computing \(_{i}\), compute

\[_{i}^{}=(T_{i}^{}X_{i+}^{}X_{i+}T_{i})^{} T_{i}^{}X_{i+}^{}y_{i}\]

to send back to the coordinating server. Note that we use Moore-Penrose inverse here as \(T_{i}^{}X_{i+}^{}X_{i+}T_{i}\) is in general of rank \(d_{i}\), and \(_{i}^{}\) is then the min-norm interpolant of agent \(i\)'s data. Similar to Collab, we can use weighted empirical risk minimization parameterized by \(W_{i}^{d d}\) and to aggregate \(^{}\) via

\[^{}=(W_{1},,W_{m}) {argmin}_{}_{i=1}^{m}\|T_{i}^{}(T_{i}T_{i}^{})^{-1}T_{ i}-_{i}^{}\|_{W_{i}}^{2}.\]

The next theorem, in conjunction with Theorem 3.1, implies that under the WERM optimization scheme, aggregation of least squares estimators on imputed local data does not bring additional statistical benefit. In fact, the local imputation estimator is a linearly transformed on local OLS \(_{i}\).

**Theorem 4.1**.: _For \(_{i}^{}\) from agent \(i\), we have \(_{i}^{}=T_{i}^{}(T_{i}T_{i}^{})^{-1}_ {i}\). Given any weighting matrices \(W_{i}^{d d}\), the aggregated imputation estimator \(^{}\) is consistent and asymptotically normal_

\[(^{}-)=(0,C^{}(W_{1},,W_{m})).\]

  Method & Full-feature & Missing-feature & Communication \\  & asymptotic covariance & asymptotic covariance & cost for agent \(i\) \\  Local OLS - \(_{i}\) & - & \((W_{i}^{})^{-1}\) & 0 \\  Local imputation w/ & \((_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}\) & \(T_{i}(_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}T_{i}^{}\) & \(d^{2}\) \\  Global imputation - \(_{i}^{}\) & \((_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}\) & \(T_{i}(_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}T_{i}^{}\) & \(nd_{i}+d_{i}\) \\  Collab - \(_{i}^{}\) & \((_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}\) & \(T_{i}(_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}T_{i}^{ }\) & \(d_{i}^{2}+2d_{i}+1\) \\  

Table 1: Full and Missing feature asymptotic covariance and communication cost for agent \(i\). Communication cost is measured by how many real numbers are received and sent from agent \(i\).

_Using the same weights \(W^{}_{i}^{d_{i} d_{i}}\) as in Theorem 3.1 for aggregated \(^{}\), we have under p.s.d. cone order, for weights \(W_{i}\), \(C^{}(W_{1},,W_{m}) C^{}\), where \(C^{}=(_{i=1}^{m}T_{i}^{}W^{}_{i}T_{i})^{-1}\). In addition, the equality holds when \(W_{i}=T_{i}^{}W^{}_{i}T_{i}\)._

As we will see in Sec. 5 where we provide minimax lower bound for weak observation models, the fact that the weighted imputation does not outperform our Collab approach is because the WERM on local OLS without imputation is already optimal. In fact, having access to the features will not achieve better estimation rate for both the global parameter \(\) and local parameters \(T_{i}\).

In terms of communication cost, this local imputation method requires more communication than Collab, as a coordinating server needs to communicate \(\) to all the agents. Each agent must first send \(d_{i}^{2}\) real numbers corresponding to \(_{i}\) to the coordinating server, and then the coordinating server will send back \(d^{2}-d_{i}^{2}\) real numbers corresponding to the entries of \(\) that agent \(i\) has not observed. This amounts to \(d^{2}\) total communication cost per agent. The per-agent communication cost for this method scales with \(d\), which is not desirable for the reason outlined in the introduction.

Global imputation.Finally, we analyze the setting where we allow each agent to send the coordinating server all of their data \((X_{i+},y_{i})\) for \(i=1,,m\) instead of their local estimators, \(_{i}\) or \(_{i}^{}\). Having all the data with structured missingness available, a natural idea is to have the coordinating server first impute the data, replacing \(X_{i+}\) with \([X_{i} X_{i+}]=X_{i+}T_{i}\), and then perform weighted OLS on _all_ of the \(nm\) data points, before sending a \(d_{i}\) dimensional local model back to each agent. Namely for scalars \(_{1},,_{m}>0\), we take

\[^{}=^{}( _{1},,_{m}):=(_{i=1}^{m}_{i}T_{i}^{}X_{i+ }^{}X_{i+}T_{i})^{-1}(_{i=1}^{m}_{i}T_{i}^{}X_{i +}^{}y_{i}).\]

Surprisingly, in spite of the additional power, \(^{}\) still does not beat \(\) in Theorem 3.1.

**Theorem 4.2**.: _For any scalars \(_{1},,_{m}>0\), \(^{}\) is consistent and asymptotically normal_

\[(^{}-)=( 0,C^{}(_{1},,_{m})).\]

_Recall the lower bound matrix \(C^{}:=(_{i=1}^{m}T_{i}^{}W^{}_{i}T_{i})^{-1}\) in Theorem 3.1. If \(X_{i}(0,)\), we have under p.s.d. cone order and any \(_{i}>0\), \(C^{}(_{1},,_{m}) C^{}\). In addition, the equality holds when \(_{i}=1/(\|_{i-}\|_{_{i-}}^{2}+^{2})\)._

The communication cost for this method is significantly larger than the other methods we discussed. Each agent must send all of its data to a coordinating server. Factoring in the additional communication cost of receiving a new local model from the server, this amounts to a total \(nd_{i}+d_{i}\) communication cost per agent. The fact that communication cost for this method scales with \(n\) is a significant disadvantage for the reason we outlined in the introduction.

## 5 Asymptotic Local Minimax Lower Bounds

In this section, we prove asymptotic local minimax lower bounds that show Collab is (nearly) optimal. We work in the partially-fixed-design regime. For every sample \(x^{d}\), \(x_{i+}^{d_{i}}\) is a fixed vector. We draw \(x_{i-}\) from \((_{i-},_{i-})\) where \(_{i-}\) and \(_{i-}\) is the conditional mean and variance of \(x_{i-}\) given \(x_{i+}\). Here \(_{i-}\) is also the Schur complement. We draw \(x_{i-}\) from \((_{i-},_{i-})\). The samples \(x_{i+}^{d_{i}}\) comprise the matrices \(X_{i+}^{n d_{i}}\). For all \(i[m]\), we will assume we have an infinite sequence (w.r.t. \(n\)) of matrices \(X_{i+}\). This partially-fixed-design scheme gives the estimators knowledge of the observed features and the distribution of the unobserved features, which is consistent with knowledge that Collab has access to. In this section we fix \(^{d}\). The corresponding label \(y=x_{i+}_{i+}+x_{i-}_{i-}+\), where \(\) is drawn from i.i.d. \((0,^{2})\). We use \(y_{j}^{n}\) to denote its vector form for the agent \(j\). To model the estimator's knowledge about the labels, we will have two observation models--one weaker and one stronger--which we will specify later when we present our results.

For each observation model, we will have two types of results. The first type of result is a minimax lower bound for full-featured data; i.e., how well can estimator perform on a fresh sample without missing features. This type of result will concern the full-feature asymptotic local minimax risk

\[_{n}_{m,c}(\{X_{i+}\}_{i[m]};_{n},u) _{n}_{}_{P_{n}}n _{Z P} u,(Z,\{X_{i+}\}_{i[m]})- ^{2}.\]

We will show that there exists a \(B^{d d}\) such that the local minimax risk in the previous display is lower bounded by \(u^{T}Bu\) for all \(u^{d}\). In other words, we have lower bounded the asymptotic covariance of our estimator with \(B\) (with respect to the p.s.d. cone order). The second type of result is an agent specific minimax lower bound; i.e., what is the best prediction error an estimator (for the given observation model) can possibly have on a fresh sample for a given agent. This type of result will deal with the missing-feature asymptotic local minimax risk, defined as

\[_{n}_{m,}^{i+}(\{X_{i+}\}_{i[m]}; _{n},u)_{n}_{}_{P _{n}}n_{Z P} u,(Z,\{X_{i+}\}_{i [m]})-T_{i}^{2}.\]

Similar to the first minimax error definition, we will again show that there exists a \(B_{i}^{d_{i} d_{i}}\) such that the local minimax risk we just defined is lower bounded by \(u^{T}B_{i}u\) for all \(u^{d_{i}}\). Recall (2) for discussion surrounding why \(T_{i}\) is the right object to compare against.

### Weak Observation Model: Access only to local models and features

Recall the local least squares estimator \(_{i}=(X_{i+}^{}X_{i+})^{-1}X_{i+}^{}y_{i}\). Let \(P_{}^{}\) be a distribution over \(_{1},,_{m}\) induced by \(\) and \((_{1},,_{m})}}{{}} (0,^{2}I_{n})\). We define the following family of distributions \(_{n,c}^{}\{P_{^{}}^{} :^{}-_{2} cn^{-1/2}\}\) which defines our observation model. Intuitively, in this observation model, we are constructing a lower bound for estimators which have access to the features \(X_{1+},,X_{m+}\), the population covariance \(\), and access to \(_{1},,_{m}\). In comparison, our estimator Collab only uses \(\) and \(_{1},_{m}\). We present our first asymptotic local minimax lower bound result here. The proof of this result can be found in Appendix D.1.

**Theorem 5.1**.: _Recall that \(C^{}(_{i=1}^{m}T_{i}^{}W_{i}^{}T_{i})^{-1}\). For all \([m]\) and \(n\) let the rows of \(X_{i+}\) be drawn i.i.d. from \((0,_{i+})\). Then for all \(u^{d}\), with probability 1, the full-feature asymptotic local minimax risk for \(_{n,c}^{}\) is bounded below as,_

\[_{c}_{n}_{m,}(\{X_{i+ }\}_{i[m]};_{n,c}^{},u) u^{}C^{}u.\]

_For all \(u^{d_{i}}\), with probability 1, the missing-feature asymptotic local minimax risk for \(_{n,c}^{}\) is bounded below as_

\[_{c}_{n}_{m,}^{i+}(\{ X_{i+}\}_{i[m]};_{n,c}^{},u) u^{}T_{i}C^{ }T_{i}^{}u.\]

This exactly matches the upper bound for Collab we presented in Corollary 3.2.

### Strong Observation Model: Access to features and labels

Define the family of distributions \(_{n,c}^{y}\{P_{^{}}^{y}:^{ }-_{2} cn^{-1/2}\}\) as the observation model. Intuitively, in this model, we are constructing a lower bound for estimators having access to all of the features \(X_{1+},,X_{m+}\) and access to \(y_{1}, y_{m}\). This observation model is stronger than the previous observation model because estimators now have access to the labels \(y\). We note again that our estimator Collab only uses \(\) and \(_{1},_{m}\). The quantities our estimator rely on do not scale with \(n\), making our estimator much weaker than other potential estimators in this observation model, as estimators are allowed to depend on \(y_{i}\), which grows in size with \(n\). We present our second asymptotic local minimax lower bound result here, starting with defining the strong local lower bound matrix \(C^{}(_{i=1}^{m}2/(_{i-} _{_{i-}}^{2}+^{2}))^{-1}\). The proof of this result is in Appendix D.2.

**Theorem 5.2**.: _For all \(i[m]\) and \(n\) let the rows of \(X_{i+}\) be drawn i.i.d. from \((0,_{i+})\). Then for all \(u^{d}\), with probability 1, the full-feature asymptotic local minimax risk for \(_{n,c}^{y}\) is bounded below as_

\[_{c}_{n}_{m,}(\{X_{i+ }\}_{i[m]};_{n,c}^{y},u) u^{}C^{}u.\]

_For all \(u^{d_{i}}\), with probability 1, the missing-feature asymptotic local minimax risk for \(_{n,c}^{y}\) is bounded below as_

\[_{c}_{n}_{m,}^{i+}(\{X_{i +}\}_{i[m]};_{n,c}^{y},u) u^{}T_{i}C^{}T_{i}^{ }u.\]In view of the lower bound in the strong observation model and that of the weak observation model in Theorem 5.1, it is clear that the lower bound in the strong observation setting is in general smaller as

\[-T_{i}^{}_{i+}T_{i}=_{i}^{}0&0\\ 0&_{i-}_{i} 0,\]

which further implies \(C^{}}(_{i=1}^{m}/(\|_{i-} \|_{_{i-}}^{2}+^{2}))^{-1} C^{}}\).

We argue that the two lower bounds are comparable in the missing completely at random . Consider for every agent \(i\), each coordinate is missing independently with probability \(p\). In this case, \((d_{i},_{i+},T_{i})\) are i.i.d. random triplets parameterized by \(p\).

**Corollary 5.3**.: _Under the random missingness setup with missing probability \(p\), let the eigenvalue of \(\) be \(_{1}()_{d}()>0\) and define its condition number \(=_{1}()/_{d}()\). Suppose \(p^{-1}(1+\|\|_{}^{2}/^{2})^{-1}\), we have the limits \(_{m}mC^{}}\) and \(_{m}mC^{}}\) exist and_

\[4_{m}mC^{}}_{m}mC^{ }}_{m}mC^{}}.\]

## 6 US Census Experiment

We experiment on real US census data modified from the ACSTravelTime dataset from the folktables package . The code can be found at https://github.com/garyxcheng/collab. We (artificially) construct \(m=5\) datacenters (agents), each containing data from only one of California, New York, Texas, Florida, and Illinois. The goal is to collaboratively learn a model for each datacenter in a communication efficient way. This setup models potentially real settings where state governments are interested in similar prediction tasks but may not be allowed to directly transfer data about their constituents directly to one another due to privacy or communication constraints. In this setup, there is covariate shift across agents, and the feature and error distributions are not Gaussians--presenting significant deviations from our theoretical assumptions which serve as a proving ground to test how well Collab works in practice. For an experimental setup that more closely matches the assumptions we made in our theory, see Appendix A.2.

After dataset preprocessing, described in the Appendix A.1, we have \(d=37\) features. We compute the feature covariance matrix from training data across all the datacenters, which we plot in Appendix A.1. We assume we are able to do this because this computation can be done in a distributed manner, without communicating training data points or labels. The California datacenter will have access to \(37\) features, New York to \(36\), Texas to \(35\), Florida to \(30\), and Illinois to \(27\). This models the feature heterogeneity which varies across geography. Each datacenter will have \(n\) datapoints, which we vary in this experiment. The objective is to predict people from Illinois's travel time to work given all \(37\) features. This task models the setting where the datacenter of interest does not have access to labeled full-featured, data to use to predict on full-featured test data.

We compare our method Collab against methods we call Naive-Local, Naive-Collab, Optimized-Naive-Colllab, Imputation, and RW-Imputation. We briefly describe each method here; Appendix A.1 contains a more detailed description of each method. Naive-Local refers to each agent locally perform OLS to construct \(_{i}\). Naive-Collab does an equal-weighted average of the agent OLS models--\(_{i[m]}_{i+}^{}_{i}/m\). Optimized-Naive-Collab uses gradient descent to optimize the choices of weights used in Naive-Collab. Optimized-Naive-Collab uses fresh labeled samples without any missing

Figure 1: Experimental results for US Census Experiment

features during gradient descent, so in this sense, Optimized-Naive-Collab is more powerful than our method. Imputation refers to the global imputation estimator \(^{}\) with \(_{i}=1/m\). RW-Imputation is Imputation but with the optimal choice of weights \(_{i}\). We also compare against Naive-Local trained with \(5n\) datapoints. We choose \(5n\) to model the hypothetical scenario setting where all of the other datacenters available contain data (albeit with missing features) from Illinois. For each method that we test, we run \(80\) trials to form \(95\%\) confidence intervals.

We see that for \(n 800\) in Figures 1(b) and 1(c), Collab performs the best; the imputation methods do the worst, and have much higher variance. In this small \(n\) regime, even the Naive-Local method with \(5\) times the data does worse than Collab. For \(n 2000\) in Figure 1(a), the aggregation methods do worse than the imputation methods, and Naive-Local method with \(5\) times the data is the best performing method. However, Collab remains better than Optimized-Naive-Collab and Naive-Collab. The performance of Naive-Collab and Optimized-Naive-Collab being much closer to the performance of Collab here than in the synthetic data experiment in Appendix A.2 is not surprising, as the covariance of the features here is much more isotropic, meaning that the naive aggregation methods will not incur nearly as much bias.

## 7 Discussion and Future Work

Optimal weights beyond Gaussianity.\([x_{i+}_{i-}^{}z_{i+}z_{i+}^{}_{i-}x_{i+}^{ }]\) has a nice closed form in Gaussian setting because \(z_{i+}\) and \(x_{i+}\) are independent--which is in general not true without Gaussianity. If we can directly sample from the feature distribution \(\) (e.g., unlabeled data), then we can empirically estimate \([x_{i+}_{i-}^{}z_{i+}z_{i+}^{}_{i-}x_{i+}^{ }]\) by sampling from \(\) and using any consistent plug-in estimate \(\) (e.g., run Collab with weights \(W_{i}=I_{d_{i}}\)). This will return a good estimate of the optimal weights. An interesting future direction is to prove lower bounds without the Gaussianity assumption.

Generalization to non-linear models.Recall in the Gaussian setting, the optimal weights in Collab are \(W_{i}^{}=_{i+}/(_{x,y}[( x_{i+},_{i}-y)^{2}])\). Then, the optimal loss function in Eq. (3) becomes

\[_{i=1}^{m}\|_{i+}+_{i+}^{-1}_{i}_{i-}- {}_{i}\|_{W_{i}^{}}^{2}=_{i=1}^{m} _{x_{i+}}[( x_{i+},_{i}- x_{i+},T_{i} )^{2}]}{_{x,y}[( x_{i+},_{i}-y)^{2 }]}.\]

This hints at a generalization to non-linear models. Suppose the local agents train on models \(f^{i}(x_{i+};_{i}),^{d_{i}}^{d_{i}} \) and the global model \(f(x;),^{d}^{d}\) satisfies for some mapping \(T_{i}:^{d}^{d_{i}}\), \(f(x;T_{i})=f^{i}(x_{i+};_{i})\). Consider a loss function \((,):[0,)\). Then we can consider the following way of aggregation inspired by Collab for linear models

\[:=*{argmin}_{}_{i=1}^{m}_{ x_{i+}}(f^{i}(x_{i+};_{i}),f(x_{i+};T_{i}))}{_{x_{i+},y}(f^{i}(x_{i+};_{i}),y)}.\] (6)

We can consistently estimate the denominators (weights) using training time loss. An interesting future direction is to investigate the performance of this general approach for non-linear problems.

Application to Federated Learning.Federated Learning algorithms generally consist of repeating the following steps until termination: Step 1. server sends \(\) to all agent, Step 2. each agent \(i\) does some local training initialized at \(\) to form \(_{i}\), and Step 3. server collects \(_{i}\) and aggregates them to form a new \(\). Most federated learning algorithms assume the agent model sizes are the same across agents because aggregating models (Step 3) of different sizes is not obvious . However, now (6) suggests a solution to this issue: in step 3, we can solve (6), albeit with population expectations replaced with empirical averages, to aggregate models of different sizes. Note that because data is assumed to stay with each agent in Federated Learning, this optimization problem may have to be solved via a federated learning algorithm.