# Ensemble Mashups: A Simple Recipe For Better Bayesian Optimization

Anand Ravishankar, Fernando Llorente, Yuanqing Song, Petar Djuric

Department of Electrical and Computer Engineering

Stony Brook University

###### Abstract

Bayesian optimization (BO) is a popular approach to optimizing costly, black-box functions that rely on a statistical surrogate model of the function, typically a Gaussian process (GP) and the so-called acquisition function (AF). Although the choices of the GP kernel and the AF can strongly affect the results, there does not exist an automatic way of selecting them. Ensembling, namely, using several, different kernels (Multi-Model) or AFs (Multi-AF) is one possibility for deriving a BO algorithm that is robust and safer. These ideas have been considered separately in the past. In this work, we consider ensembles of both kernels and AFs (Multi-Model-Multi-AF) and perform an empirical comparison to show their superiority with respect to single-ensemble algorithms.

## 1 Introduction

Bayesian optimization (BO) has become an important tool for black-box optimization and is widely used in fields such as machine learning, automated design, and complex system optimization [1; 2; 3]. It predicts the behavior of the objective function by positing a proxy model, usually a Gaussian process (GP)  and uses these predictions to guide the optimization process, greatly improving the efficiency of the algorithm. However, in BO, the choice of kernel function and acquisition function (AF) is crucial to the final optimization result. The choice of the kernel affects the smoothness and complexity of the model. The AF guides how to select new points for evaluation. If the AF cannot effectively explore-exploit the search space, it may fall into a local optimum or waste computing resources. Different choices will directly determine the performance and efficacy of the optimization process. Therefore, how to select and optimize these components has become an important issue in current research [2; 1].

Ensembling is a popular strategy in machine learning for leveraging multiple learning algorithms and improving the performance . Indeed, the advantages of ensembling in BO are well-recognized, appearing in the majority of the best-performing algorithms that took part in the recent competition . Ensembling is part of a recent federated BO , which can be interpreted as using a mixture of GP models. Ensemble models have also gained popularity in transfer learning extensions to BO, where information from base tasks are combined via weighted rankings of individual predictions or via weighted combination of AFs [8; 9; 10]. Still, as noted in , more studies are needed to understand ensembling in BO.

In this work, we focus on ensembles of two important components in GP-based BO: kernels and AFs. The ensembling strategy that we consider consists of sampling one representative from a pool of candidates. Existing works have been limited to either different kernel functions or different AFs. For example, the GP-hedge algorithm  improves optimization performance by integrating several acquisition functions, but still uses a single pre-selected kernel. This algorithm is an instance of a Multi-AF (MA) method. At the same time, Bayesian Model Averaging (BMA)improves optimization results by integrating different kernel functions , but does not adopt an ensembling strategy for AFs. This algorithm is an instance of a Multi-Model (MM) method. Although these methods have proved to be useful, their interaction has not been explored in the literature. To address these issues, we propose an MMMA (Multi-Model-Multi-AF) approach to BO. This approach fills the gaps in existing methods by integrating kernel functions and AFs at the same time. We conducted experiments on 16 benchmarks and showed empirical evidence that MMMA-BO provides a more robust approach to BO.

**Related Work.** Some previous works that have considered using ensembles of AFs are [2; 11; 13; 14; 15; 16; 17]. "Ensembling" is a very broad term that can interpreted as (i) individually optimizing a portfolio of AFs and choosing one of the maximizers according to some criteria [11; 13]; (ii) selecting and optimizing one AF from the portfolio [14; 15]; (iii) jointly optimizing several AFs in a multi-objective fashion [16; 17]; or (iv) integrating out the AF using an approximate fully Bayesian GP . The use of an ensemble of models (kernels) can be also interpreted differently [2; 12; 18].

The fully Bayesian treatment of GP hyperparameters naturally leads to an ensemble of kernels, each one with a hyperparameter sample, drawn approximately from the posterior; this model in conjunction with, e.g., the expected improvement (EI) AF, leads to the "integrated" AF mentioned above . On the other hand, a series of different kernels can be weighted according to their marginal likelihoods (i.e., the probability of the data given the model/kernel) using BMA weights; then, at each iteration, a kernel is selected according to its BMA weight [12; 18].

## 2 Multi-Model Multi-Acquisition function Bayesian optimization

**Background.** We aim to solve \(_{}f()\) by sequentially acquiring a dataset \(_{t}=\{_{t},_{t}\}=\{(_{i},y_{i})\}_ {i=1}^{t}\), where \(y_{i}=f(_{i})+u_{i}\), \(u_{i} N(0,^{2})\). The function \(f()\) is assumed to be sampled from a GP, \(f()((),(,^{ }))\), where \(()=0\) and \((,^{})\) is the kernel function. At each iteration, the function is queried at \(_{t+1}=_{}(;_{t})\), collecting \(y_{t+1}=f(_{t+1})+u_{t}\) and updating \(_{t+1}=_{t}\{(_{t},y_{t})\}\). The criterion \((;_{t})\) is the AF which is computed using the posterior GP, \(f|_{t}(m_{t}(),s_{t}^{}())\), where \(m_{t}()\) and \(s_{t}^{}()\) are the posterior predictive mean and variance of \(f()\) at \(\). Although the particular choices of \(\) and \(\) determine the performance of the algorithm, they are usually kept fixed throughout the algorithm.

**Motivation.** Consider a scenario where we want to implement a BO algorithm but have limited prior knowledge about the target function and insufficient expertise in selecting a suitable AF. The standard recommendations for the kernel \(\) and AF \(\) are often the Matern 5/2 kernel and Expected Improvement (EI), respectively. However, these defaults may not be "optimal" for our specific problem. Ideally, if we could experiment with different combinations of \((,)\), we would identify the best pair in hindsight. Furthermore, when applying BO across various problems, different combinations may yield better results. Unless one combination is clearly dominant, selecting the "best" pair remains challenging--even in hindsight. For example, Figure 1 illustrates the regret for several combinations of \(\{,\}\) and \(\{\}\) for two different test functions. For either function, the simple regret after 100 iterations varies by roughly one order of magnitude

Figure 1: Simple regret in log-scale. The lines represents the median results across 25 simulations, with the bands representing the 0.75 and 0.25 quantiles.

depending on the choice of \((,)\). Notably, the best-performing configuration for the Rastrigin function, (RBF, UCB), is not among the top two configurations for the DixonPrice function.

**MMMA-BO.** Let us consider \(M\) different kernels \(\{_{m}\}_{m=1}^{M}\) and \(N\) different AFs \(\{_{n}\}_{n=1}^{N}\). Our goal is to ensemble both kernels and AFs using two sets of normalized weights \(\{w_{m}^{}\}_{m=1}^{M}\) and \(\{w_{n}^{}\}_{n=1}^{N}\) such that \(w_{m}^{} 0\) and \(w_{n}^{} 0\) represent respectively the probability of choosing kernel \(_{m}\) and AF \(_{n}\) at each iteration. By using multiple kernels and AFs simultaneously, we avoid making a potentially suboptimal choice at the outset. The MMMA-BO algorithm in 1 is essentially the same as standard BO but it involves sampling a pair--one kernel and one AF--at each iteration, rather than committing to a single combination throughout the optimization process.

The sampling probabilities for each kernel and AF can either be fixed in advance or adaptively adjusted based on performance during the optimization process. A straightforward and effective fixed choice is to assign uniform weights, \(w_{m}^{}=\) and \(w_{n}^{}=\), corresponding to the random selection of a different BO algorithm at each iteration. However, a performance-guided approach offers a more dynamic alternative, where "rewards" are assigned to kernels and AFs based on their contribution to the optimization process. For kernels, setting the weights with BMA , \(w_{m}^{} p(_{t}|_{m})\), where \(p(_{t}|_{m})\) is the GP marginal likelihood with optimized hyperparameters, makes sense from a theoretical perspective. This method allows for kernel selection based on their fit to the observed data. Nevertheless, in low-data regimes--typical in BO--this approach may not always be appropriate. For AFs, the \(w_{n}^{}\) can be adjusted based on rewards reflecting each \(_{n}\)'s contribution to the optimization. For instance, we reward \(_{n}\) if it identifies a candidate with a function value greater than the current best . A particular case of this strategy is the Hedge algorithm  ("Bandit" in the experiments).

```
1:Input: Set of kernels \(\{_{m}\}_{m=1}^{M}\), set of acquisition functions \(\{_{n}\}_{n=1}^{N}\), initial dataset \(_{0}\),
2:Kernel weights \(\{w_{m}^{}\}_{m=1}^{M}\), acquisition function weights \(\{w_{n}^{}\}_{n=1}^{N}\)
3:Initialize:\(=_{0}\)
4:for\(t=1\) to \(T\)do
5: (i) Sample a kernel \(^{*}\) from \(\{_{m}\}_{m=1}^{M}\) using the weights \(\{w_{m}^{}\}_{m=1}^{M}\)
6: (ii) Fit the Gaussian Process (GP) with kernel \(^{*}\) to the dataset \(\)
7: (iii) Sample an acquisition function \(^{*}\) from \(\{_{n}\}_{n=1}^{N}\) using the weights \(\{w_{n}^{}\}_{n=1}^{N}\)
8: (iv) Optimize the acquisition function \(^{*}\) to find the next query point \(_{t+1}\)
9: (v) Evaluate \(y_{t+1}=f(_{t+1})+u_{t+1}\) and update the dataset: \(=\{(_{t+1},y_{t+1})\}\)
10:ifeight_update then
11: (vi) Update the kernel weights \(\{w_{m}^{}\}_{m=1}^{M}\) and/or acquisition function weights \(\{w_{n}^{}\}_{n=1}^{N}\)
12:endif
13:endfor
14:Return: The best found point \(_{}\) ```

**Algorithm 1** Bayesian Optimization with Multiple Kernels and Acquisition Functions

## 3 Experiments

The importance of ensembling can be demonstrated by contrasting MMMA against algorithms of varying degrees of ensembling at different levels (kernel or AF) and different strategies of ensembling. In this study, we considered a pool of kernels including RBF, Matern 5/2, and Matern 3/2, along with the set of AFs, EI, PI and UCB. These design choices were guided by their popularity and general applicability. For more details, see Table \(2\) in the appendix. The algorithms were evaluated on 16 test functions from Botorch's suite  (see Table \(1\) in the appendix). We ran 25 independent simulations where, at each simulation, we ran BO for 100 iterations.

We consider 3 metrics to evaluate the algorithms: (1) the gap metric, (2) simple regret, and (3) cumulative regret. Each metric focuses on a different aspect of the optimizer's behavior. The gap metric measures improvement relative to the starting condition, simple regret quantifies the distance between the best-observed value and the global optimum at each iteration, and cumulative regret quantifies the rate at which regret accumulates over time.

**The gap metric.** Figure 2-(a) presents boxplots of the final gap metric, illustrating that increased ensembling leads to better results. This improvement is due to the optimizer having access to a broader selection of kernels and AFs. Notably, the baseline performs similarly to kernel-level ensembling, which can be attributed to the similarity among the kernels used in our study. However, when ensembling is extended to include AFs, there is a significant improvement due to the greater diversity among the AFs. Importantly, the results of MMMA are more concentrated to the right, indicating less variability and greater robustness in performance compared to other methods.

**Regret growth.** Given a function class \(F\), a common objective is to find an optimizer \(\) which achieves sublinear rate of regret for all functions \(f F\). Formally, \( f F\), the objective is to have \(_{t}(,f)}{t}\) = 0, where \(R_{t}\) is the cumulative regret at iteration \(t\). We can make this objective stricter by imposing a functional form on the rate of regret. For example, \( f F\), \(R_{t}(,f) Ct^{b}\), \(C>0\) and \(b<1\). A good optimizer has \(b 1\). To determine the value of \(b\), we fit a polynomial to the median cumulative regret using non-linear least squares. Figure \(2\)-(b) shows the relative difference in \(b\) values of each optimizer \(_{i}\) to the best optimizer \(^{*}\) for every function, namely, the lightest cell is the optimizer with the smallest \(b\). We can see that MMMA (especially random-bandit and random-random) usually have the lowest \(b\) values or they are quite close to the best optimizer. It is again interesting to note that ensembling at the AF level yields significant improvement, while ensembling at the kernel level provides marginal improvement.

**Random v/s Adaptive weights.** We observe that random weights (in both AF and kernel space ) tend to perform better than adaptive weight selection. When the adaptive strategy is employed, the "best" performing AF/ kernel will dominate the other candidates and cause the ensemble to collapse to a single choice (see Figs. 3-4). Indeed, with these strategies, the ensemble collapses to an exploitative choice: in BMA, the rewards are assigned to kernels that fit better the current data; in bandit, an AF that suggests points with large function values will be preferred. Hence, these strategies do not reward exploration.

## 4 Conclusions

In this work, we described MMMA-BO, a framework for combining multiple kernels and acquisition functions in BO. The MMMA-BO algorithm involves sampling one kernel and one acquisition function at each iteration, rather than committing to a single combination throughout the optimization process. We conducted experiments on 16 benchmark functions and systematically compared them with existing baseline methods. The experimental results confirm that the MMMA approach pro

Figure 2: (a) Final gap metric accumulated across all test functions. (b) Heat map of relative differences in the order of polynomial. The methods are categorized into three groups: Baseline (Standard BO), Single Ensemble (MultiModel, MultiAF), and Multi-level Ensemble (MMMA variants).

vides more robust performance. In future work, we aim to explore better procedures for determining the ensemble weights and deriving theoretical bounds on the cumulative regret of MMMA-BO.