# Test-Time Adaptation Induces

Stronger Accuracy and Agreement-on-the-Line

Eungyeup Kim\({}^{1}\) Mingjie Sun\({}^{1}\) Christina Baek\({}^{1}\) Aditi Raghunathan\({}^{1}\) J. Zico Kolter\({}^{1,2}\)

\({}^{1}\)Carnegie Mellon University \({}^{2}\)Bosch Center for AI

{eungyeuk, mingjies, kbaek, radii, zkolter}@cs.cmu.edu

###### Abstract

Recently, Miller et al.  and Baek et al.  empirically demonstrated strong linear correlations between in-distribution (ID) versus out-of-distribution (OOD) accuracy and agreement. These trends, coined accuracy-on-the-line (ACL) and agreement-on-the-line (AGL), enable OOD model selection and performance estimation without labeled data. However, these phenomena also break for certain shifts, such as CIFAR10-C Gaussian Noise, posing a critical bottleneck. In this paper, we make a key finding that recent test-time adaptation (TTA) methods not only improve OOD performance, but _drastically strengthen the ACL and AGL trends in models_, even in shifts where models showed very weak correlations before. To analyze this, we revisit the theoretical conditions from Miller et al.  that outline the types of distribution shifts needed for perfect ACL in linear models. Surprisingly, these conditions are satisfied after applying TTA to deep models in the penultimate feature embedding space. In particular, TTA causes the data distribution to collapse complex shifts into those can be expressed by a singular "scaling" variable in the feature space. Our results show that by combining TTA with AGL-based estimation methods, we can estimate the OOD performance of models with high precision for a broader set of distribution shifts. This lends us a simple system for selecting the best hyperparameters and adaptation strategy without _any_ OOD labeled data. Code is available at https://github.com/EungyeupKim/TTALine.

## 1 Introduction

Neural networks often fail to generalize to out-of-distribution (OOD) data that differs from the in-distribution (ID) data seen at train-time . Thus, characterizing the behaviors of these models under distribution shift becomes crucial for reliable deployment. However, it is often extremely challenging to reliably estimate their performances because in many practical applications, OOD labeled data is scarce. Interestingly, recent studies  have found a set of simple empirical laws that describe the behavior of models across many distribution shift benchmarks. In particular, across numerous distribution shift benchmarks, the models' ID versus OOD accuracies, under probit scaling, tend to observe a strong linear correlation across numerous distribution shift benchmarks. Additionally, when accuracy is strongly correlated, the ID and OOD agreement rates between pairs of these models are also strongly correlated with nearly identical slopes and biases. These phenomena, respectively referred to as "accuracy-on-the-line" (ACL)  and "agreement-on-the-line" (AGL) , can be leveraged for precise OOD accuracy estimation _without access to OOD labels_: one could estimate the slope and bias of the ID vs OOD accuracy trend using agreement rates, then linearly transform ID accuracy using this approximate linear fit1.

However, studies [32; 3; 56; 48] have demonstrated that for distribution shifts benchmarks the linear trends breaks down catastrophically. As shown in Fig. 1, such as CIFAR10-C Gaussian Noise  or Camelyon17-WILDS , models without TTA (_i.e._, Vanilla) with around \(92-95\%\) ID accuracy can have OOD accuracies that vary between \(10-50\%\), so ID accuracy alone becomes extremely unreliable for understanding the OOD performance of models. Similarly, the correlation strength of ID and OOD agreement rates also weakens. Ideally, we would like to intervene in models in a way that improves these linear correlations, such that we can reliably predict their performance under distribution shift. While theoretical works [32; 31; 51; 25] provide insights for _when_ these linear trends hold, there is little study on how to _strengthen_ these trends in models.

In this paper, we empirically demonstrate that recent OOD test-time adaptation (TTA) strategies [44; 27; 46; 53; 9; 35; 55; 36] not only improve OOD performance, but significantly _restore the strong linear trends for a broad range of distribution shifts_ where ACL and AGL are not initially observable. For instance, in Fig. 1, the correlation coefficient (\(R^{2}\)) of ID versus OOD agreement and accuracy of Vanilla models is \(0.18\) and \(0.39\), respectively, and both of these values improve to \(1.0\) after applying TENT . We observe such stronger linear trends after TTA throughout our extensive testbed consisting of \(9\) shifts, \(7\) adaptation methods, and over \(40\) network architectures. As test-time adapted models have OOD accuracies that degrade more predictably with respect to the ID accuracy, we are also able to utilize AGL based method ALine  to obtain precise OOD performance estimates without any OOD labels. Note that _no OOD labels were utilized throughout this procedure_, neither during TTA or ALine. Our estimates of the models' OOD performances are drastically more precise after adaptation, _e.g._, estimation error of \(11.99\%\) in Vanilla models without TTA vs. \(2.34\%\) after applying TENT on CIFAR10-C Gaussian Noise.

Given that TTAs are designed to enhance OOD accuracy, the observation of such strong linear trends is unexpected and non-trivial. While some studies [29; 9] have explored how adaptations lead to improved OOD generalization, these efforts are orthogonal to those investigating the conditions under which linear trends occur [32; 31]. To our knowledge, no studies have attempted to bridge these two areas of research. This naturally raises the question: Why does adapting models at test-time to OOD data lead to stronger linear trends?

Figure 1: Linear trends in both accuracy and agreement hold to a substantially stronger degree after applying adaptation methods than before. Each blue and pink dot denotes the accuracy and agreement, followed by the linear fits for each, and \(R^{2}\) is correlation coefficient.

To answer this, we revisit the theoretical analysis in Miller et al.  of the sufficient conditions for observing highly correlated ID vs OOD accuracy in linear classifiers and Gaussian data. Theoretically, ACL holds exactly under distribution shifts where the direction of the class means and shape of the class covariances are fixed, and only the scale of the mean or covariance changes. Surprisingly, we find that TTA, in practice, seems to enforce exactly this condition: after applying TTA, the cosine similarity between the means and covariances of the penultimate-layer feature embedding of ID and OOD data tend to hover around 1, while their magnitude may change by some scaling constant. This implies that adaptations effectively collapse the complexity of the distribution shift to a singular "scaling" variable in the feature space. In addition to (empirically) justifying the use of TTA for strengthening ACL2, this discovery casts some insight into the nature of TTA in general, which has previously been a largely heuristic approach.

Furthermore, models adapted with different TTA hyperparameters tend to lie on the _same_ linear trend. Fig. 2 illustrates the strong correlation among models of various architectures first trained on ID data for various numbers of epochs, then adapted with different learning rates, batch sizes, adaptation steps. This critically allows us to tune the TTA hyperparameters and choice of TTA method without a held-out OOD labeled set. Notably, correctly hyperparameter tuning without access to labels is an important challenge faced in practice that currently lacks principled approaches [21; 60; 9]. Using ACL and AGL, we are able to select models with accuracy less than \(1\%\) away from that of the best model OOD, _e.g._, in CIFAR10-C. This also allows to select the best TTA methods by comparing their estimated best OOD performances.

To summarize our contributions:

* We observe after TTA, ACL and AGL hold across a wider set of distribution shifts and hyperparameter settings.
* We explain our observation by showing TTA collapses the distribution shift to just a constant scaling of the mean and covariance matrices in the feature space. This satisfies the theoretical conditions studied previously for observing strong linear trends.
* Our findings provide a simple and effective strategy for finding the best TTA hyperparameters and the best TTA strategy without any OOD labels.

## 2 Related Work

Understanding accuracy and agreement-on-the-line.Miller et al.  and Baek et al.  empirically observed a coupled phenomena in deep models when evaluated on many standard distribution shift benchmarks: the ID vs. OOD accuracy and agreement are often strongly correlated and the linear fits match almost exactly. Recent studies [32; 31; 51; 25; 24] attempt to characterize what types of shifts lead to (or break) this phenomena. Miller et al.  prove that under a simple Gaussian data setup, ACL does not hold perfectly under distribution shifts that change the direction of the mean or transforms the covariance matrix. For example, they demonstrate that adding isotropic Gaussian noise to CIFAR10 whose covariance is anisotropic, causes the linear trend to break. Mania and Sra  provided sufficient conditions directly over the outputs of trained models, in terms of their prediction similarity and distributional closeness. Tripuraneni et al.  and LeJeune et al.  show that ACL holds asymptotically under certain transformations to the covariance matrix. On the other hand, there has been comparatively little theoretical analysis of AGL and why it appears together with ACL. Lee et al.  show that in random feature linear regression, AGL can break break partially, _i.e._, the slope of the agreement trend matches accuracy's, but the biases may be different. While further theoretical conditions are necessary to guarantee when these phenomena hold jointly, in our empirical findings, we see that the slopes and biases do always match across the wide variety of distribution shifts we test.

Extending upon such theoretical studies, we demonstrate that a simple model intervention by test-time adaption allows these ID versus OOD trends to hold even stronger for a more expansive set of distribution shifts. In fact, we demonstrate that after adaptation, models actually satisfy the theoretical conditions necessary for ACL as described in Miller et al. .

Adapations under distribution shifts and their pitfalls of reliability.Test-time adaptation aims to enhance model robustness by adapting models to unlabeled OOD test data. Test-time training methods [46; 29; 7] involve learning shift-invariant features via solving self-supervision tasks. Other approaches include computing statistics in Batch Normalization (BN) layers using OOD data [20; 44], instead of using ID statistics stored during training. Subsequent studies further adapt BN parameters by updating them using entropy minimization [53; 35; 36]. Another popular approach is self-training with pseudo-labels [40; 54; 9].

One critical challenge in TTA is that, without OOD labels, it is prohibitively difficult to evaluate how effective the adaptation methods might be. As pointed out in previous studies, adaptation methods may not succeed to address the full spectrum of distribution shifts, such as datasets reproductions [29; 60], domain generalization benchmarks [21; 61], and WILDS . Furthermore, these approaches are known to be sensitive to different hyperparameter choices [4; 61; 36; 23]. Practitioners must take a great care in optimizing such hyperparameters, but their tuning procedures lack clarity. They often follow the settings of the previous studies [35; 36], or rely on some held-out labeled data [21; 60; 9] that is unavailable in practice. There exists a line of studies on unsupervised model validation [33; 42; 34; 52; 17]. Our study leverages _agreement-on-the-line phenomena within TTA_ to offer a promising solution for these reliability issues.

## 3 Adaptations lead to stronger Agreement-on-the-Line

### Experimental setup

Datasets and models.Our testbed includes diverse shifts, including common corruptions (\(15\) failure shifts in CIFAR10-C, CIFAR100-C, and ImageNet-C ), dataset reproductions (CIFAR10.1 , ImageNetV2 ), and real-world shifts (ImageNet-R , Camelyon17-WILDS, iWildCAM-WILDS, FMoW-WILDS ). Among them, CIFAR10-C Gaussian Noise, Camelyon17-WILDS,

Figure 2: Strong AGL by adaptations with varying hyperparameters, including learning rates, adaptation steps, batch sizes, and early-stopped checkpoints of the ID-trained model. Each blue and pink dot denotes the accuracy and agreement, followed by the linear fits for each.

and iWildCAM-WILDS display the weakest correlations in both ID versus OOD accuracy and agreement [32; 3; 56]. We test over \(30\) different architectures of convolutional neural networks (_e.g._, VGG , ResNet [13; 57; 59], DenseNet , MobileNet ) and Vision-Transformers (ViTs , DeiT , SwinT ).

**TTA methods.** We investigate \(7\) recent state-of-the-art TTA methods, including SHOT , BN_Adapt , TTT , TENT , ConjPL , ETA , and SAR . This testbed includes different training strategies (_e.g._, self-supervision , PolyLoss ) and updating certain layer parameters (BN layers [44; 53; 35], LayerNorm (LN) layers [2; 36], entire feature extractors ). We test all adaptation baselines, except SAR, on convolutional neural networks with BN layers. We apply SAR specifically to vision transformers [5; 49; 30] because it prevents the model collapse that other adaptation methods exhibit in vision transformers with LN layers .

**Calculating agreement.** Given any pair of models \((h,h^{})\) that are tested on distribution \(\), the expected accuracy and agreement of the models is defined as

\[(h)=_{x,y}\{h(x)=y \},(h,h^{})=_{x,y} \{h(x)=h^{}(x)\}\] (1)

where \(h(x)\) and \(h^{}(x)\) are the normalized logits of models \(h\) and \(h^{}\) given datapoint \(x\) and \(y\) is the class label. Following  and , we apply probit scaling, which is the inverse of the cumulative density function of the standard Gaussian distribution (\(^{-1}:[-,]\)), over accuracy and agreement for a better linear fit, specifically in Figs. 1 and 2.

**Online test in ID and OOD during TTA.** Unlike conventional offline inference at test-time, TTAs involve online learning, which dynamically updates the model's parameters while testing on OOD data. To evaluate this continuously updated model on both ID and OOD data, the data is fed into the model in minibatches and we collect the accuracy and agreement of the model over the \(i\)'th minibatch after the dynamic adaptation step \(i\). Details are provided in Algorithm 1 in the Appendix.

### Main observation

We make a striking empirical observation in the models after applying TTA: the correlation strength between ID versus OOD accuracy and agreement increases by a significant margin, especially in distribution shifts where models without TTA show wildly varying trends. In Fig. 1, we demonstrate this on the four distribution shifts that show weakest ACL and AGL trends in Vanilla models: CIFAR10-C Gaussian Noise, ImageNet-C Shot Noise, Camelon17-WILDS, and iWildCAM-WILDS. In particular, the correlation coefficients are at most \(R^{2} 0.4\) before TTA. These failure shifts have also been noted by previous studies [32; 3; 56]. Surprisingly, after applying TTA methods, such as TENT, the strength of these linear trends as measured by \(R^{2}\) increase dramatically, (_e.g._, \(0.15 0.97\) and \(0.33 0.97\) in agreement and accuracy in Camelyon17-WILDS). Our observations hold consistently across our entire testbed of shifts and adaptation methods, as shown in Figs. 6, 7, 9, 10, 11, and 12. Moreover, in shifts where models without TTA already exhibit strong linear trends, such as ImageNet-V2 or FMoW-WILDS, these linear trends persist even after TTA, irrespective of whether TTA improves or degrades the OOD accuracy (Fig. 4).

Furthermore, models adapted using the same TTA method but with different adaptation hyperparameters lie on the same accuracy and agreement linear trend. Specifically, we vary learning rates, the number of adaption steps, batch sizes, and the number of epochs the model is initially trained on ID data. In Fig. 2 we see that on CIFAR10-C and ImageNet-C Gaussian Noise, and Camelyon17-WILDS, models adapted with different hyperparameters exhibit correlation strength \(R^{2}\) close to \(1\) in both ID versus OOD accuracy and agreement. We show that this occurs across distribution shifts in Figs. 8 and 13.

## 4 Why does adaptations lead to strong linear trends?

In this section, we focus on explaining why TTA leads to restoration of these strong linear trends. Although we do not provide a complete theoretical justification, we identify a key pattern in how TTA modifies models that provides a strong clue as to why these methods substantially strengthen ACL and AGL.

We begin by revisiting the theoretically sufficient conditions for ACL from Miller et al.  over a simple Gaussian data and linear classifier setup. In this setting, ACL holds perfectly (\(R^{2}=1\)) only when the distribution shifts by a simple scaling factor to the norm of the mean and covariance. On the other hand, if the actual direction of the mean or shape of the covariance matrix changes, the linearity breaks. We then demonstrate that even in CIFAR10-C shifts and deep neural networks, models after applying TTA meet these theoretical conditions better in the penultimate-layer feature space.

### Theoretical conditions for linear trends in Gaussian data

We briefly introduce the theoretical conditions for ACL in Gaussian data and linear models, from Miller et al. , restated here for ease of presentation. Consider the binary classification over Gaussian data setup with label \(y\{-1,1\}\). The OOD distribution \(Q\) differs from the ID distribution \(P\) by just some scaling constants \(,>0\),

\[P(x y)=(y;), Q(x y)=(y ;^{2}).\] (2)

**Theorem 1**: _[_Miller et al.__, simplified]_ _Under the Gaussian data setup in Equation 2, across all linear classifiers \(f_{}:x(^{}x)\), the probit-scaled accuracies over P and Q observes perfect linear correlation with a bias of zero and a slope of \(\)._

The proof follows immediately from the fact that the test accuracy of a linear classifier on this Gaussian data \(P\) is given by \((^{}/}))\); applying same result to \(Q\) immediately gives the desired linear relationship. The main implication is that if the distribution shifts only in the scale of the mean and covariance, while preserving their direction, ACL is guaranteed to occur across any set of linear classifiers. Note that we focus on the conditions for ACL in particular. Additional theoretical conditions are usually required to observe AGL together with ACL , but they have not been well-characterized especially for this linear-Gaussian setup. Thus, we forgo analyzing assumptions for AGL, if any, in our work. Still, we find that AGL is always tightly coupled with ACL across an extensive range of benchmarks and TTA methods, similar to Baek et al. .

### Empirical analysis under adaptation to CIFAR10-C

We now investigate how well the above conditions are met before and after TTA for real-world data with deep models. Here, evaluate models trained on CIFAR10 on CIFAR10-C Gaussian Noise. We adapt models using BN_Adapt  or TENT  at test-time. To match the theoretical setup, we analyze the class-wise feature embeddings from the penultimate-layer of these models that directly precedes the final _linear_ classifier. Namely, we can measure the "alignment" or the cosine similarity between the ID and OOD class means and covariances of these embeddings. Similar to our CIFAR10-C Gaussian Noise results in Figs. 1 and 2, we evaluate the embedding alignment of models in each hyperparameter setup: we adapt models at test-time varying a single hyperparameter, e.g., architectures, learning rates, batch sizes, and early-stopped checkpoints, while keeping the remaining hyperparameters fixed.

**Shifts become aligned in their mean and covariance after adaptation.** Table 1 shows the mean and standard deviation of the cosine similarity measured across different setups. We first notice that, without adaptation (Vanilla), both mean and covariance of CIFAR10 and CIFAR10-C Gaussian Noise features are misaligned with cosine similarity much smaller than \(1\). Surprisingly, after adaptations, the similarity substantially increases and becomes very close to \(1\), across every architecture we test (with standard deviation close to \(0\)). In other words, in the feature embedding space, the two distributions have means and covariances that (roughly) point in the same _directions_ after adaptation. This also implies that in adapted models, the distribution shift is represented as a simple change in the _scale_ of the features alone.

Consider CIFAR10-C Gaussian Noise which corrupts CIFAR10 images by additive isotropic Gaussian Noise. In the input image space, the direction of the covariance matrix clearly changes with the addition of this noise. Yet TTA has the non-trivial ability of being able to "simplify" complex drifts to scale shifts within the features. These observations support the theoretical conditions in Theorem 1 and gives us loose insight into why TTA strengthens ACL and AGL in models in practice.

**Theoretical slope matches the empirical slope.** Finally, under scale shifts in our theoretical setup, the slope of the ACL trend is exactly \(=/\). Assuming the direction of the mean and covariance remains fixed, we may estimate \(\) and \(\) as simply the average change in magnitude of the class means and covariances, and use this to approximate \(\). In Table 1 we compare how this theoretical slope compares to the true slope of ID versus OOD accuracy fit by linear regression. These slopes tend to closely match each other, highlighting that the theoretical results of TTA seem to provide correct intuition about why ACL holds in practice, especially after TTA.

**TTA improves linear trends irrespective of whether it improves OOD generalization.** We make the subtle distiction between TTA's ability to strengthen ACL and AGL phenomena from its original purpose of improving OOD accuracy. One could imagine a trivial reason why ACL happens is because the ID and OOD gap diminishes after TTA, thereby bringing the ID versus OOD accuracy of all models close to the \(y=x\) line. However, this explanation does not reflect our empirical findings. While TTA seems to reduce the complexity of the shift to scale shifts, the magnitude of this scaling factor may remain very large, _i.e._, \( 1\), \( 1\). This results in a near-perfect linear trend that, nonetheless, lies arbitrarily far from the \(y=x\). Consider the shift ImageNet-C Shot Noise in Fig. 1. After adaptation, there is still approximately a 40% gap in ID and OOD accuracy, but ACL holds strongly. On the other hand, consider the counterfactual TTA method which improves OOD performance by decreasing the covariance scale \(\) in the feature embedding space, but the means/covariances remain misaligned. Then the linear trend moves closer to \(y=x\), but there is no guarantee about the strength of the linear trend.

## 5 Experiments

Our finding that TTA induces strong ACL and AGL has two key practical applications: (i) estimation of OOD accuracy, and (ii) unsupervised validation for TTA -- all without access to any OOD labels.

### OOD Accuracy estimation after adaptation

**Experimental Setup.** We employ AGL-based estimation method, namely ALine . This method first estimates the slope and bias of the linear trend in ID versus OOD accuracy, via agreements (which requires no labels), and uses them to linearly transform ID accuracy to get an estimate of OOD accuracy. The full details of ALine are illustrated in Algorithm 2 in Appendix. We apply ALine to models after TTA, and compare these results with (i) those of ALine applied to models before adaptation, and (ii) estimates using existing estimation baselines. These baselines include average thresholded confidence (ATC) , difference of confidence (DOC)-feat , average confidence , and agreement . We evaluate baselines on CIFAR10-C, CIFAR100-C, ImageNet-C , and Camelyon17-WILDS and iWildCAM-WILDS .

**Results.** ALine shows accurate estimation under shifts where models demonstrate strong AGL (_e.g._, in CIFAR10-C snow, mean absolute error (MAE) of estimation is \(0.93\%\) in ALine-D), but critically fails when shifts do not have such linear trends (_e.g._, in CIFAR10-C Gaussian Noise, MAE is \(10.76\%\) and in Camelyon17-WILDS, MAE is \(12.88\%\)). As a result, as shown in Table 2, estimates using ALine-S/D on Vanilla models are sometimes error-prone. Next, after applying adaptation methods, such as SHOT, BN_Adapt, and TENT, the estimation performance of ALine-S/D improves, showing substantially lower MAE compared to that of Vanilla models (_e.g._, MAE decreases \(10.76\% 2.34\%\) in CIFAR10-C Gaussian Noise and \(12.88\% 1.42\%\) in Camelyon17-WILDS). ALine on top of TTA also outperforms other baseline methods on most of the distribution shifts tested.

    &  &  \\
**Setup** & Mean & Covariance & Theoretical & Empirical \\ Vanilla (Archs.) & 0.691 \(\) 0.175 & 0.750 \(\) 0.109 & – & – \\ BN_Adapt (Archs.) & 0.988 \(\) 0.007 & 0.972 \(\) 0.011 & 0.751 \(\) 0.075 & 0.758 \\ TENT (Archs.) & 0.990 \(\) 0.005 & 0.974 \(\) 0.011 & 0.753 \(\) 0.072 & 0.778 \\ Learning rates & 0.993 \(\) 0.003 & 0.977 \(\) 0.006 & 0.759 \(\) 0.041 & 0.76 \\ Batch Sizes & 0.995 \(\) 0.003 & 0.982 \(\) 0.010 & 0.831 \(\) 0.101 & 0.809 \\ Check Points & 0.992 \(\) 0.003 & 0.976 \(\) 0.008 & 0.782 \(\) 0.033 & 0.838 \\   

Table 1: Cosine similarity between mean direction and covariance shape of class-wise penultimate-layer features, followed by the comparison between theoretical and empirical slope. They are evaluated on CIFAR10 vs. CIFAR10-C Gaussian Noise, measured across architectures and hyperparameters. We report their means and standard deviations.

### Unsupervised validation for TTA

In this section, we demonstrate that strong AGL allows us to validate the best hyperparameter for TTA without any labels. Furthermore, we can use the OOD accuracy estimates to choose the best TTA strategy _overall_.

**Experimental setup.** First, as we have shown, models adapted using a particular method with varying hyperparameters tend to show strong ACL behavior. When ACL holds, we can simply select the best OOD model by selecting the one with best ID accuracy . Thus, we first collect candidates by systematically sweeping over hyperparameter values, and select the model with the best ID accuracy. We focus on TENT, optimizing its various hyperparameters including learning rates, adaptation steps, architectures, batch sizes, and early-stopped checkpoints of training. See our total pool of models in Appendix Table 6. We compare this naive strategy to existing unsupervised validation methods including MixVal , ENT , IM , Corr-C , and SND . We evaluate them on four shifts, CIFAR10-C, ImageNet-C, ImageNet-R, and Camelyon17-WILDS.

**Results.** Table 3 reports the absolute difference (MAE (%)) between the OOD accuracy of the selected model and the best OOD accuracy, within a set of models where we vary a particular TTA hyperparameter. We find that using ID accuracy for model selection consistently achieves competitive unsupervised validation results, often outperforming other baselines. We noticed that current state-of-the-art unsupervised model selection methods, _i.e._, MixVal or IM, perform well on CIFAR10-C, ImageNet-C, and ImageNet-R, but they critically fail in Camelyon17-WILDS, _e.g._, validation error of 7.98% in MixVal and 23.52% in IM. Such failures of existing baselines might come from their assumptions, _e.g._, low-density separation, that do not generalize to such distribution shifts. In contrast, our method shows low MAE across all distribution shifts, including those where other baselines fail, _e.g._, 0.62% in Camelyon17-WILDS. We note that there are cases, specifically models adapted with various learning rates for ImageNet-C, where MAE is large (\(9.70\%\)). We see that models optimized with very small learning rates, _e.g._, \(10^{-5}\), deviate from the linear trend. Results on other TTA baselines' unsupervised validation are in Table 7.

**Extension to selecting best TTA strategy.** After hyperparameter tuning for each TTA strategy using the unsupervised strategy from the previous section, we could further leverage ALine to then select for the best TTA method overall. Different TTA methods exhibit different slopes and biases in their ACL

  
**Dataset** & **Method** & **Error** & **ATC** & **DOC-feat** & **AC** & **Agreement** & **ALine-S** & **ALine-D** \\   & Vanilla & 31.38 & 8.31 & 15.03 & 17.42 & 5.45 & 6.02 & 5.87 \\  & SHOT & 15.40 & 1.63 & 4.63 & 7.63 & 1.78 & 0.96 & **0.77** \\  & BN\_Adapt & 16.87 & 3.69 & 4.79 & 7.53 & 1.93 & 1.21 & **0.91** \\  & TENT & 15.43 & 4.25 & 4.65 & 7.66 & 1.79 & 0.97 & **0.77** \\  & ConipL & 16.62 & 1.80 & 6.16 & 11.46 & 2.02 & 1.18 & **1.01** \\  & ETA & 15.14 & 4.58 & 4.50 & 7.68 & 1.76 & 0.92 & **0.72** \\   & Vanilla & 59.04 & 5.05 & 12.82 & 18.34 & 6.96 & 7.49 & 7.22 \\  & SHOT & 40.79 & 2.21 & 5.44 & 14.36 & 2.52 & 1.64 & **0.90** \\  & BN\_Adapt & 42.69 & 2.89 & 4.42 & 11.81 & 2.33 & 1.43 & **1.13** \\  & TENT & 41.11 & 6.60 & 5.59 & 14.85 & 2.65 & 1.64 & **0.88** \\  & ConipL & 42.79 & **1.09** & 6.55 & 23.73 & 2.40 & 1.67 & 1.18 \\  & ETA & 44.27 & 7.15 & 4.92 & 16.49 & 4.96 & 1.44 & **0.81** \\   & Vanilla & 80.41 & 3.95 & 13.72 & 17.34 & 9.06 & 6.00 & 5.95 \\  & BN\_Adapt & 69.05 & 7.37 & **2.63** & 2.86 & 3.91 & 6.16 & 6.09 \\  & TENT & 56.58 & 5.98 & 6.54 & 12.70 & 7.48 & 4.62 & **4.57** \\  & ETA & 56.56 & 10.21 & 7.91 & 34.38 & 8.02 & **3.66** & 3.72 \\  & SAR & 43.30 & 5.39 & 8.61 & 13.68 & 5.51 & 5.19 & **4.17** \\   & Vanilla & 34.07 & 14.91 & 17.31 & 21.69 & 11.95 & 12.88 & 13.46 \\  & TENT & 14.37 & 3.00 & 3.43 & 6.94 & 6.49 & 2.29 & **2.27** \\   & ETA & 16.43 & 3.05 & 4.38 & 6.85 & 5.33 & 2.24 & **1.42** \\   & Vanilla & 50.27 & 7.12 & 2.73 & 23.86 & 3.00 & 3.53 & 2.82 \\   & TENT & 47.39 & 5.44 & 3.20 & 28.03 & 3.55 & **2.59** & 2.96 \\   & ETA & 46.49 & 6.61 & 3.40 & 29.34 & 4.62 & **2.14** & 2.82 \\   

Table 2: The results of OOD accuracy estimation, measured by MAE (%) between estimated and actual OOD accuracy. The gray shades denote the results calculated after applying adaptations, and bold texts indicate the smallest estimation error among estimators. We also report the classification error (%) in both Vanilla and adaptation methods for each dataset.

tends, so we use AGL-based estimators to estimate the best OOD accuracy across hyperparameters for each method separately, then compare these estimates to choose the best method. Specifically, we select between five TTA baselines -- BN_Adapt, TENT, SHOT, ConjPL, and ETA -- on CIFAR10-C across all corruptions. For ease of presentation, we consider selecting the best TTA method after tuning a single hyperparameter for each method, with other parameters fixed. In Fig. 3, we plot using "\(\)" the selected models' estimated OOD accuracy for each method versus each method's actual best OOD performances. Our method almost always selects the best OOD model for each method but also accurately estimates their performances, as shown by points lying close to the \(y=x\) line. Furthermore, the ranking of TTA methods by OOD accuracy stays the same when using the estimates. We also plot in "\(\)" the average ground truth and estimated accuracy across hyperparameters. This demonstrates that our approach effectively selects the best TTA strategy without OOD labels.

## 6 Ablation Study: When does TTA not improve linear trends?

So far, we focused on numerous TTA methods that tend to dramatically improve the strength of ACL and AGL phenomena. We then connected this behavior to models representing the distribution shift in its feature space as a scale shift, satisfying the theoretical conditions of ACL from Miller et al. . This behavior was especially prominent in methods that adjust the batch normalization layer statistics, _e.g._ BN_Adapt, or modify the feature extractor, _e.g._ TENT. This section presents an ablation study on the impact of normalization layers (_e.g._, BN, LN) and the components adapted by TTA (_e.g._, feature extractor, final classifier) for observing ACL and AGL.

**Normalization layers.**

As shown in our results for BN_Adapt in Section 4.1, the strength of the ACL and AGL trends tends to be sensitive to the statistics stored in the batch normalization layers. Taking the same set of models

Figure 3: 2-D visualizations of each TTA baseline’s ground truth best OOD accuracy (x-axis) and estimated OOD accuracy of best-ID models (y-axis) marked in cross (\(\)). Each color denotes different TTA baselines. Circle dot (\(\)) represents estimates and ground truth accuracies averaged over all hyperparameter values.

  
**HyperParameter** &  &  \\   & **MixVal** & **ENT** & **IM** & **Corr-C** & **SND** & **Ours** & **MixVal** & **ENT** & **IM** & **Corr-C** & **SND** & **Ours** \\  Architecture & 2.31 & 1.06 & 1.06 & 21.71 & 2.77 & 0.03 & 6.22 & 0.96 & 0.47 & 26.32 & 20.60 & 0.75 \\ Learning Rate & 6.97 & 8.88 & 2.24 & 11.56 & 1.87 & 0.72 & 12.75 & 20.49 & 1.49 & 20.18 & 12.61 & 9.70 \\ Checkpoints & 3.21 & 0.0 & 0.0 & 5.53 & 3.46 & 0.05 & – & – & – & – & – & – & – \\ Batch Size & 7.85 & 3.32 & 0.96 & 32.37 & 3.68 & 0.77 & 14.29 & 42.31 & 0.99 & 42.31 & 42.31 & 5.61 \\ Adapt Step & 0.85 & 0.0 & 0.0 & 1.02 & 0.0 & 0.23 & 1.85 & 1.94 & 1.25 & 3.09 & 2.17 & 0.30 \\  Average & 4.23 & 2.65 & 0.85 & 14.43 & 2.75 & **0.36** & 8.77 & 16.42 & **1.05** & 14.43 & 22.97 & 4.0 \\    &  \\   & **MixVal** & **ENT** & **IM** & **Corr-C** & **SND** & **Ours** & **MixVal** & **ENT** & **IM** & **Corr-C** & **SND** & **Ours** \\  Architecture & 1.75 & 0.62 & 0.62 & 22.17 & 22.17 & 0.85 & 28.87 & 1.03 & 1.03 & 28.87 & 28.87 & 0.85 \\ Learning Rate & 3.12 & 10.16 & 4.73 & 19.16 & 19.16 & 2.8 & 0.91 & 48.37 & 46.41 & 48.37 & 48.37 & 1.14 \\ Batch Size & 1.83 & 35.88 & 0.08 & 35.88 & 35.88 & 1.74 & 0.0 & 46.67 & 46.67 & 40.45 & 40.45 & 1.37 \\ Adapt Step & 1.07 & 1.07 & 1.07 & 1.07 & 1.07 & 0.0 & 2.17 & 33.12 & 0.0 & 33.12 & 33.12 & 0.0 \\  Average & 1.94 & 14.18 & 1.62 & 19.57 & 19.57 & **1.34** & 7.98 & 32.29 & 23.52 & 37.70 & 37.70 & **0.62** \\   

Table 3: Results of unsupervised validation, measured by MAE (%) between OOD accuracy of model selected by best ID model and actual best OOD model. Our results are highlighted in shade.

from Section 4.1, we test two architectural variants -- models with no normalization layers (denoted as Vanilla w/o N) and layer normalization (Vanilla w/ LN) -- and report the cosine similarity of the class means and covariance matrices of the ID and OOD feature embeddings.

We also report the correlation coefficient (\(R^{2}\)) of the ACL and AGL trends in Table 4. Interestingly, the mean and covariance alignment as well as correlation strength tends to be larger than that of Vanilla with BN-layers, but still falls short of models with BN-layers adapted with BN_Adapt which is very close to \(1\).

Methods such as SAR which substitutes BN-layers with LN as a part of their adaptation strategy, also shows stronger linear trends in Fig. 12 than Vanilla counterparts in Fig. 11, but not as consistently as those of BN-layer-adaptation methods in Fig. 11. We conjecture that this stems from how different architectures encode distribution shifts: BN-layers result in severe covariate shift, but most of the shift is encoded in the BN statistics, making it easy to align shifts via adaptation. In contrast, non-BN models encode shifts across the entire model parameters, which may dampen the covariate shift in the representations, but also make it harder to remove by adaptation. Schneider et al.  suggests a similar conclusion.

**Featurizer or classifier.** In this section, we consider the TTA method T3A , which leverages a feature extractor without BN layers and only adapts the last linear classifier. This is in contrast to the other TTA methods we study in our work, which largely modifies the feature extractor. We adapt the same set of models in Section 4.1 and observe that the \(R^{2}\) for accuracy and agreement in T3A are \(0.80\) and \(0.46\), which is substantially lower than models adapted using BN_Adapt. This may be because the features remain misaligned after T3A. Overall, our ablation studies clarify what TTA designs ideally lead to strong linear trends. Since non-BN-TTAs are often adopted in numerous practical circumstances, _e.g._, single batch, it remains an important open question how to develop alternate TTA strategies that achieves strong ACL and AGL trends in such settings, thus improving the reliability of models.

## 7 Conclusion and Limitations

In this paper, we provide a key observation that recent TTAs lead to stronger AGL across a wide range of distribution shifts, encompassing those with weak correlations before adaptation. We explain this phenomena by the complexity of distribution shifts being substantially reduced to those where the direction/shape of the mean and covariance remains identical, satisfying the theoretical conditions for linear trends. This naturally leads to enhanced estimation of OOD performances across a wider range of shifts than before TTA. We can leverage this to perform unsupervised hyperparameter validation and select for the best TTA method without any labels.

While the method we propose does not require OOD labels, AGL still requires sufficient ID data to accurately estimate agreement rate. As a result, our strategy may not be complementary with TTA methods that do not require any ID data. Moreover, it could make our strategy computationally expensive. In Section D, we conduct an ablation study to minimize the required amount of ID data for observing AGL for accuracy estimation. The results show that even with only 5% of the original ID data, OOD accuracy estimation performance remains nearly the same as with full access, outperforming other estimators. We believe that overcoming dependency on ID data and exploring a fully test-time approach for observing AGL remains a promising direction for future research.