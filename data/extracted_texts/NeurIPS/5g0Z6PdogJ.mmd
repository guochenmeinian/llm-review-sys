# Testably Learning Polynomial Threshold Functions

Lucas Slot

Department of Computer Science

ETH Zurich

lucas.slot@inf.ethz.ch &Stefan Tiegel

Department of Computer Science

ETH Zurich

stefan.tiegel@inf.ethz.ch &Manuel Wiedmer

Department of Computer Science

ETH Zurich

manuel.wiedmer@inf.ethz.ch

###### Abstract

Rubinfeld & Vasilyan recently introduced the framework of _testable learning_ as an extension of the classical agnostic model. It relaxes distributional assumptions which are difficult to verify by conditions that can be checked efficiently by a _tester_. The tester has to accept whenever the data truly satisfies the original assumptions, and the learner has to succeed whenever the tester accepts. We focus on the setting where the tester has to accept standard Gaussian data. There, it is known that basic concept classes such as halfspaces can be learned testably with the same time complexity as in the (distribution-specific) agnostic model. In this work, we ask whether there is a price to pay for testably learning more complex concept classes. In particular, we consider polynomial threshold functions (PTFs), which naturally generalize halfspaces. We show that PTFs of arbitrary constant degree can be testably learned up to excess error \(>0\) in time \(n^{(1/)}\). This qualitatively matches the best known guarantees in the agnostic model. Our results build on a connection between testable learning and _fooling_. In particular, we show that distributions that approximately match at least \((1/)\) moments of the standard Gaussian fool constant-degree PTFs (up to error \(\)). As a secondary result, we prove that a direct approach to show testable learning (without fooling), which was successfully used for halfspaces, cannot work for PTFs.

## 1 Introduction

The PAC learning model of Valiant  has long served as a test-bed to study which learning tasks can be performed efficiently and which might be computationally difficult. One drawback of this model is that it is inherently noiseless. In order to capture noisy learning tasks, the following extension, called the _agnostic model_, has been introduced : Let \(\) be a class of boolean functions and let \(_{}\) be an (unknown) distribution over example-label-pairs in \(\{ 1\}\). Typically, \(=\{0,1\}^{n}\) or \(^{n}\). As input, we receive iid samples from \(_{}\). For a small \(>0\), our task is to output a classifier \(\) (not necessarily in \(\)) whose _loss_\(L(,_{})_{(x,z) _{}}((x) z)\) is at most \(+\), where \(_{f}L(f,_{})\). The parameter \(\) thus indicates how "noisy" the instance is. We say that an algorithm _agnostically learns_\(\) up to error \(\) if it outputs such an \(\). This model is appealing since it makes assumptions neither on the distribution of the input, nor on the type and amount of noise. After running an agnostic learning algorithm, we can therefore be certain that the output \(\) achieves error close to that of the best function in \(\) even without knowing what distribution the data came from.

Efficient learning and distributional assumptions.We are interested in understanding when agnostic learning can be performed efficiently. Unfortunately, efficient learning is likely impossible without making assumptions on the distribution \(_{}\), even for very simple function classes \(\). For instance, consider the class \(_{}\) of _halfspaces_, i.e., boolean functions of the form \(f(x)=( v,x-)\). Then, even if there exists a halfspace achieving arbitrarily small error, it is widely believed that outputting an \(\) that performs better than a random guess in the agnostic model takes at least super-polynomial time if no assumptions are made on \(_{}\)[8; 29]. To find efficient algorithms, one therefore has to make such assumptions. Typically, these take the form of assuming that the marginal \(_{}\) of \(_{}\) over the examples \(\) belongs to a specific family of distributions.

**Definition 1** (Agnostic learning with distributional assumptions).: _Let \(>0\). A learner \(\) agnostically learns \(\) with respect to \(\) up to error \(\) if, for any distribution \(_{}\) on \(\{ 1\}\) whose marginal \(_{}\) on \(\) is equal to \(\), given sufficient samples from \(_{}\), it outputs with high probability a function \(f:\{ 1\}\) satisfying \(L(f,_{})(,_{ })+\)._

For example, under the assumption that \(_{}\) is standard Gaussian, we can find \(\) such that \(L(,_{})(_{},_{})+\) in time \(n^{O(1/^{2})}\)[20; 11]. This runtime is likely best-possible [12; 29; 13].1 Efficient learning is still possible under weaker assumptions on \(_{}\), e.g., log-concavity . Regardless, we cannot know whether a learning algorithm achieves its claimed error without a guarantee that the input actually satisfies our distributional assumptions. Such guarantees are inherently difficult to obtain from a finite (small) sample. Furthermore, approaches like cross-validation (i.e., computing the empirical error of \(\) on a hold-out data set) fail in the noisy agnostic model, since we do not know the noise level \(\). This represents a severe limitation of the agnostic learning model with distributional assumptions.

### Testable learning.

To address this limitation, Rubinfeld & Vasilyan  recently introduced the following model, which they call _testable learning_: First, they run a _tester_ on the input data, which attempts to verify a computationally tractable relaxation of the distributional assumptions. If the tester accepts, they then run a (standard) agnostic learning algorithm. The tester is required to accept whenever the data truly satisfies the distributional assumptions, and whenever the tester accepts, the output of the algorithm must achieve error close to \(\). More formally, they define:

**Definition 2** (Testable learning ).: _Let \(>0\). A tester-learner pair \((,)\) testably learns \(\) with respect to a distribution \(\) on \(\) up to error \(\) if, for any distribution \(_{}\) on \(\{ 1\}\), the following hold_

1. _(Soundness). If samples drawn from_ \(_{}\) _are accepted by the tester_ \(\) _with high probability, then the learner_ \(\) _must agnostically learn_ \(\) _w.r.t._ \(_{}\) _up to error_ \(\)_._
2. _(Completeness). If the marginal of_ \(_{}\) _on_ \(\) _is equal to_ \(\)_, then the tester must accept samples drawn from_ \(_{}\) _with high probability._

_Soundness_ tells us that whenever a testable learning algorithm outputs a function \(\), this function achieves low error (regardless of whether \(_{}\) satisfies any distributional assumption). On the other hand, _completeness_ tells us testable learners are no weaker than (distribution-specific) agnostic ones, in the sense that they achieve the same error whenever \(_{}\) actually satisfies our assumptions (i.e., whenever this error can in fact be guaranteed for the agnostic learner). The testable model is thus substantially stronger than the agnostic model with distributional assumptions.

Which function classes can be learned testably?A natural question is whether testable learning comes at an additional computational cost compared to (distribution-specific) agnostic learning. We focus on the setting where \(\) is the standard Gaussian on \(=^{n}\). Following [28; 15], we consider the following simple tester: Accept if and only if the empirical moments up to degree \(k\) of the input distribution (approximately) match those of \(\). This tester satisfies completeness as the empirical moments of a Gaussian concentrate well. Using this tester, Rubinfeld & Vasilyan  show that halfspaces can be testably learned in time \(n^{(1/^{4})}\). Their runtime guarantee was improved to \(n^{(1/^{2})}\) in , (nearly) matching the best known non-testable algorithm. This shows that there is no separation between the two models for halfspaces. On the other hand, a separation does exist for more complex function classes. Namely, for fixed accuracy \(>0\), testably learning the class of indicator functions of convex sets requires at least \(2^{(n)}\) samples (and hence also time) , whereas agnostically learning them only takes subexponential time \(2^{O()}\), see . The relation between agnostic and testable learning is thus non-trivial, depending strongly on the concept class considered.

### Our contributions

In this work, we continue to explore testable learning and its relation to the agnostic model. We consider the concept class of polynomial threshold functions (short PTFs). A degree-\(d\) PTF is a function of the form \(f(x)=(p(x))\), where \(p\) is a polynomial of degree at most \(d\). PTFs naturally generalize halfspaces, which correspond to the case \(d=1\). They form an expressive function class with applications throughout (theoretical) computer science, and have been studied in the context of circuit complexity , and learning . Despite their expressiveness, PTFs can be agnostically learned in time \(n^{O(d^{2}/^{4})}\), which is polynomial in \(n\) for any fixed degree \(d\) and error \(>0\). They are thus significantly easier to learn in the agnostic model than convex sets. Our main result is that PTFs can be learned efficiently in the testable model as well.

**Theorem 3** (Informal version of Theorem 19).: _Fix \(d\). Then, for any \(>0\), the concept class of degree-\(d\) polynomial threshold functions can be testably learned up to error \(\) w.r.t. the standard Gaussian in time and sample complexity \(n^{(1/)}\)._

Theorem 3 is the first result achieving efficient testable learning for PTFs of any fixed degree \(d\) (up to constant error \(>0\)). Previously, such a result was not even available for learning degree-2 PTFs with respect to the Gaussian distribution. It also sheds new light on the relation between agnostic and testable learning: there is no _qualitative_ computational gap between the two models for the concept class of PTFs, whose complexity lies between that of halfspaces and convex sets in the agnostic model.

In addition to Theorem 3, we also show an impossibility result ruling out a certain natural approach to prove testable learning guarantees for PTFs. In particular, we show in Section 2.4 that an approach which has been successful for testably learning halfspaces in  provably cannot work for PTFs.

Limitations.The dependence of the running time on the degree parameter \(d\) and the error \(\) is (much) worse than in the agnostic model (see Theorem 19). Moreover, we do not have access to _lower bounds_ on the complexity of testably learning PTFs which might indicate whether these dependencies are inherent to the problem, or an artifact of our analysis. The only lower bounds available apply already in the agnostic model, and show that the time complexity of agnostically (and thus also testably) learning degree-\(d\) PTFs is at least \(n^{(d^{2}/^{2})}\) in the SQ-model , and at least \(n^{(d^{2-}/^{2-})}\) for any \(>0\) under a cryptographic hardness assumption .

### Previous work

The two works most closely related to this paper are . Both rely on the following high-level strategy. A standard result  shows that one can _agnostically_ learn a concept class \(\) w.r.t. a distribution \(\) in time \(n^{O(k)}\) if all elements of \(\) are well-approximated w.r.t. \(\) by degree-\(k\) polynomials. That is, if for all \(f\), there exists a degree-\(k\) polynomial \(h\) such that \(_{X}[|h(X)-f(X)|]\). This result can be extended to the testable setting, but now one needs a good low-degree \(L_{1}\)-approximation w.r.t. _any_ distribution \(^{}\) accepted by the tester. Using the moment-matching tester outlined above, one thus needs to exhibit low-degree approximations to all functions in \(\) w.r.t. any distribution which approximately matches the first few moments of \(\).

A direct approach.In , the authors use a direct approach to show that if \(=_{}\) is the class of halfspaces and \(=(0,I_{n})\), these approximators exist for \(k=O(1/^{4})\), leading to an overall running time of \(n^{O(1/^{4})}\) for their testable learner. Their approach consists of two steps. First, they construct a low-degree approximation \(q\) of the sign function in one dimension using standard techniques. Then, for any halfspace \(f(x)=( v,x-)\), they set \(h(x)=q( v,x-)\). By exploiting _concentration_ and _anti-concentration_ properties of the _push-forward_ under linear functions of distributions that match the moments of a Gaussian, they show that \(h\) is a good approximation of \(f\). Unfortunately, this kind of approach cannot work for PTFs: We formally rule it out in Theorem 16. This is the aforementioned secondary contribution of our paper, which extends earlier impossibility results for (agnostic) learning of Bun & Steinke . See Section 2.4 for details.

An indirect approach using fooling.In order to prove our main theorem we thus need a different approach. Gollakota, Klivans & Kothari  establish a connection between testable learning and the notion of _fooling_, which has played an important role in the study of pseudorandomness [4; 2; 9]. Its connection to learning theory had previously been observed in . We say a distribution \(^{}\) fools a concept class \(\) up to error \(>0\) with respect to \(\) if, for all \(f\), it holds that \(|_{X}[f(X)]-_{X^ {}}[f(X)]|\). Roughly speaking, the work  shows that, if any distribution \(^{}\) which approximately matches the moments of \(\) up to degree \(k\) fools \(\) with respect to \(\), then \(\) can be testably learned in time \(n^{O(k)}\) (see Theorem 9 below). We remark that (approximately) moment-matching distributions have not been considered much in the existing literature on fooling. Rather, it has focused on distributions \(^{}\) whose marginals on any subset of \(k\) variables are equal to those of \(\), which is a stronger condition a priori. While it coincides with moment-matching in special cases (e.g., when \(\) is the uniform distribution over the hypercube), it does not when \(=(0,I_{n})\). Nevertheless, the authors of  show that (approximate) moment matching up to degree \(k=(1/^{2})\) fools halfspaces with respect to \((0,I_{n})\), allowing them to obtain the aforementioned result for testably learning \(_{}\). In fact, they show that this continues to hold when \(\) consists of arbitrary boolean functions applied to a constant number of halfspaces. They also use existing results in the fooling literature to show that degree-2 PTFs can be testably learned under the uniform distribution over \(\{0,1\}^{n}\) (but these do not extend to learning over \(^{n}\) w.r.t. a standard Gaussian).

Other previous work on testable learning.In weaker error models than the agnostic model or under less stringent requirements on the error of the learner it is known how to construct tester-learner pairs with runtime \((n,1/)\)[16; 10]. These results have been extended to allow for the following stronger completeness condition: The tester has to accept, whenever \(_{}\) is an isotropic strongly log-concave distribution .

## 2 Technical overview

### Preliminaries

From here, we restrict to the setting \(=^{n}\). We let \(\) be a well-behaved distribution on \(^{n}\); usually \(=(0,I_{n})\) is the standard Gaussian. For \(x^{n}\) and a multi-index \(^{n}\), we write \(x^{}:=_{i=1}^{n}x_{i}^{_{i}}\). For \(k\), we write \(_{k}^{n}:=\{^{n},\,_{i=1}^{n}_{i} k\}\). We say a statement holds 'with high probability' if it holds with probability \( 0.99\). The notation \(O_{d}\) (resp. \(_{d}\), \(_{d}\)) hides factors that only depend on \(d\). We now define the moment-matching tester introduced above.

**Definition 4** (Moment matching).: _Let \(k\) and \( 0\). We say a distribution \(^{}\) on \(^{n}\) approximately moment-matches \(\) up to degree \(k\) and with slack \(\) if_

\[|_{X}[X^{}]-_{X ^{}}[X^{}]|\, _{k}^{n}.\]

**Definition 5**.: _Let \(k\) and \( 0\). The approximate moment-matching tester \(_{}=_{}(k,)\) for a distribution \(\) accepts the samples \((x^{(1)},z^{(1)}),,(x^{(m)},z^{(m)})^{n}\{ 1\}\) if, and only if,_

\[|_{X}[X^{}]-_{i= 1}^{m}(x^{(i)})^{}|\, _{k}^{n}.\]

_That is, \(_{}(k,)\) accepts if and only if the moments of the empirical distribution belonging to the samples \(\{x^{(i)}\}\) match the moments of \(\) up to degree \(k\) and slack \(\). Note that \(_{}(k,)\) requires time at most \(O(m n^{k})\) to decide whether to accept a set of \(m\) samples._

The tester \(_{}\) does not take the labels of the samples into account. In general, for testers \(\) which depend only on the marginal \(\) of \(_{}\) on \(^{n}\), we say that \(\) accepts a distribution \(^{}\) on \(^{n}\) if it accepts samples drawn from \(^{}\) with high probability (regardless of the labels).

### Review of existing techniques for testable learning

In this section, we review in more detail the existing techniques to establish guarantees for agnostic and testable learning discussed in Section 1.3. Our goals are twofold. First, we wish to highlight the technical difficulties that arise from proving error guarantees in the testable model versus the agnostic model. Second, we want to introduce the necessary prerequisites for our proof of Theorem 3 in Section 2.3, namely testable learning via _fooling_ (see Theorem 9).

Learning and polynomial approximation.A standard result  shows that one can agnostically learn any concept class that is well-approximated by low-degree polynomials in the following sense.

**Theorem 6** ().: _Let \(k\) and \(>0\). Suppose that, for any \(f\), there exists a polynomial \(h\) of degree \(k\) such that_

\[_{X}[|h(X)-f(X)|].\]

_Then, \(\) can be agnostically learned up to error \(\) in time and sample complexity \(n^{O(k)}/()\)._

The underlying algorithm in the theorem above is polynomial regression w.r.t. the absolute loss function. In the testable setting, a similar result holds. The key difference is that one now needs good approximation w.r.t. _all_ distributions accepted by the proposed tester.

**Theorem 7**.: _Let \(k\) and \(>0\). Let \(\) be a tester which accepts \(\) and which requires time and sample complexity \(\). Suppose that, for any \(f\), and for any \(^{}\) accepted by \(\), there exists a polynomial \(h\) of degree \(k\) such that_

\[_{X^{}}[|h(X)-f(X)|].\]

_Then, \(\) can be testably learned up to error \(\) in time and sample complexity \(+n^{O(k)}/()\)._

The takeaway is that, in order to devise efficient algorithms for agnostic or testable learning, it suffices to study low-degree polynomial approximations of elements of \(\). Under the assumption that \(\) is a (standard) Gaussian, one has access to powerful techniques from Fourier analysis to show existence of good polynomial approximators w.r.t. \(\) for various concept classes. Using Theorem 6, this leads to efficient agnostic learning algorithms for a variety of concept classes w.r.t. \((0,I_{n})\).

Testable learning via direct approximation.In the testable setting, it is not sufficient to approximate with respect to \(\) alone, and so one cannot rely directly on any of its special structure. In , the authors overcome this obstacle to get testable learning guarantees for halfspaces w.r.t. \(=(0,I_{n})\) by appealing to more basic properties of the distributions \(^{}\) accepted by their tester. Their approach is roughly as follows. First, they use standard results from polynomial approximation theory to find a (univariate) polynomial \(q\) which approximates the sign-function well on the interval \([-1,1]\). For a halfspace \(f(x)=( v,x-)\), they consider the approximator \(h(x)=q( v,x-)\), which satisfies

\[_{X^{}}[|h(X)-f(X)|]=_{Y ^{}_{v,}}[|q(Y)-(Y)|].\]

Here, \(^{}_{v,}\) is the (shifted) projection of \(^{}\) onto the line \((v)^{n}\). That is, \(Y= v,X-\). Then, for carefully chosen \(k\) and \(>0\), they show that for any \(^{}\) accepted by \(_{}(k,)\), the distribution \(^{}_{v,}\) satisfies certain _concentration_ and _anti-concentration_ properties, meaning essentially that \(^{}_{v,}\) is distributed somewhat uniformly on \([-1,1]\). As \(q\) approximates the sign-function on \([-1,1]\), they may conclude that \(_{Y^{}_{v,}}[|q(Y)-(Y) |]\) is small, and invoke Theorem 7.

Testable learning via fooling.It is natural to attempt a generalization of the approach above to PTFs. Indeed, for \(f(x)=(p(x))\), one could consider the approximator \(h(x)=q(p(x))\). However, as we show below in Section 2.4, this approach cannot work when \((p) 6\). Instead, we will rely on a more indirect technique, proposed in . It connects the well-studied notion of _fooling_ to low-degree polynomial approximation, and to testable learning.

**Definition 8** (Fooling).: _Let \(>0\). We say a distribution \(^{}\) on \(^{n}\) fools \(\) w.r.t. \(\) up to error \(\), if, for all \(f\), we have \(|_{Y}[f(Y)]-_{X^ {}}[f(X)]|\)._

The main result of  shows that fooling implies testable learning when using approximate moment-matching to test the distributional assumptions. It forms the basis of our proof of Theorem 3.

**Theorem 9** ([15, Theorem 4.5]).: _Let \(k,m\) and \(,>0\). Suppose that the following hold:_

1. _Any distribution_ \(^{}\) _whose moments up to degree_ \(k\) _match those of_ \(\) _with slack_ \(\) _fools_ \(\) _w.r.t._ \(\) _up to error_ \(/2\)_._
2. _With high probability over_ \(m\) _samples from_ \(\) _the empirical distribution matches moments of degree at most_ \(k\) _with_ \(\) _up to slack_ \(\)_._

_Then, using the moment-matching tester \(=_{}(k,)\), we can learn \(\) testably with respect to \(\) up to error \(\) in time and sample complexity \(m+n^{O(k)}\)._

**Remark 10**.: When \(=(0,I_{n})\) is the standard Gaussian, then the second condition in Theorem 9 is satisfied for \(m=(2kn)^{k}^{-2}\), see also Fact 36.

The primary technical argument in the proof of Theorem 9 in  is an equivalence between fooling and a type of low-degree polynomial approximation called _sandwiching_. Compared to Theorem 7, the advantage of sandwiching is that one needs to approximate \(f\) only w.r.t. \(\) (rather than any distribution accepted by the tester). However, one needs to find not one, but two low degree approximators \(h_{1},h_{2}\) that satisfy \(h_{1} f h_{2}\) pointwise (i.e.,'sandwich' \(f\)). We refer to  for details.

Fooling PTFs.In light of Theorem 9 and Remark 10, in order to prove our main result Theorem 3, it suffices to show that distributions \(^{}\) which approximately match the moments of \((0,I_{n})\) fool the concept class of PTFs. This is our primary technical contribution (see Proposition 12 below). It can be viewed as a generalization of the following result due to Kane .

**Theorem 11** (Informal version of [21, Theorem 1]).: _Let \(^{}\) be a \(k\)-independent standard Gaussian, meaning the restriction of \(^{}\) to any subset of \(k\) variables has distribution \((0,I_{k})\). Then, \(^{}\) fools degree-d PTFs w.r.t. \((0,I_{n})\) up to error \(>0\) as long as \(k=k(d,)\) is large enough._

Theorem 11 applies to a class of distributions that is (far) more restrictive than what we need. First, note that \(k\)-independent Gaussians match the moments of \((0,I_{n})\) up to degree \(k\) exactly, whereas we must allow \(^{}\) whose moments _match only approximately_. Second, even if \(^{}\) would match the moments of a Gaussian exactly up to degree \(k\), its \(k\)-dimensional marginals need not be Gaussian. In fact, we have _no information on its moments of high degree_ even if they depend on at most \(k\) variables. These two distinctions cause substantial technical difficulties in our proof of Proposition 12 below.

### Overview of the proof of Theorem 3: testably learning PTFs

As we have seen, in order to prove Theorem 3, it suffices to show that approximately moment-matching distributions fool PTFs. We obtain the following.

**Proposition 12**.: _Let \(>0\). Suppose that \(^{}\) approximately matches the moments of \((0,I_{n})\) up to degree \(k\) and slack \(\), where \(k_{d}^{-4d^{4}}\), and \( n^{-_{d}(k)}k^{-_{d}(k)}\). Then, \(^{}\) fools the class of degree-d PTFs w.r.t. \((0,I_{n})\) up to error \(/2\). That is, for any \(f_{,d}\), we then have_

\[_{Y(0,I_{n})}[f(Y)]-_{X ^{}}[f(X)]/2.\] (1)

In the rest of this section, we outline how to obtain Proposition 12. Full details can be found in Appendix A. Structurally, our proof is similar to the proof of Theorem 11 in : First, in Section 2.3.1, we show fooling for the subclass of PTFs defined by _multilinear_ polynomials. Then, in Section 2.3.2, we extend this result to general PTFs by relating arbitrary polynomials to multilinear polynomials in a larger number of variables. Our primary contribution is thus to show that the construction of  (which considers \(k\)-independent Gaussians) remains valid for the larger class of distributions that approximately match the moments of a Gaussian.

#### 2.3.1 Fooling multilinear PTFs

Let \(f(x)=(p(x))\), where \(p\) is a multilinear polynomial. Our goal is to establish (1) for \(f\) under the assumptions of Proposition 12. We will follow the proof of Kane  for Theorem 11, which proceeds as follows. Let \(^{}\) be a \(k\)-independent Gaussian. First, Kane constructs a degree-\(k\) polynomial approximation \(h\) of \(f\), satisfying

\[_{Y(0,I_{n})}[h(Y)] _{Y(0,I_{n})}[f(Y)], ,\] (2) \[_{X^{}}[h(X)] _{X^{}}[f(X)].\] (3)Since the moments of \(^{}\) are exactly equal to those of \((0,I_{n})\) up to degree \(k\), we have \(_{Y(0,I_{n})}[h(Y)]=_{X ^{}}[h(X)]\). We may then conclude the fooling property for \(^{}\) (cf. (1)):

\[_{Y(0,I_{n})}[f(Y)]_{Y (0,I_{n})}[h(Y)]=_{X^{ }}[h(X)]_{X^{}}[f( X)].\]

As we see below, Kane relies on a _structure theorem_ (see Lemma 21) for multilinear polynomials to construct his low-degree approximation \(h\). We wish to extend this proof to our setting, where \(^{}\) merely matches the moments of the standard Gaussian up to degree \(k\) and slack \(\). As we will see, the construction of the polynomial \(h\) remains valid (although some care is required in bounding the approximation error). A more serious concern is that, for us, \(_{Y(0,I_{n})}[h(Y)]_{X ^{}}[h(X)]\) in general. Our main technical contribution in this section is dealing with the additional error terms that arise from this fact.

Constructing a low-degree approximation.We now give details on the construction of the low-degree approximation \(h\) that we use in our proof, which is the same as in . The starting point of the construction is a structure theorem for multilinear polynomials \(p\) (see Lemma 21 below). It tells us that \(f=(p)\) can be decomposed as \(f(x)=F(P(x))\), where \(F\) is again a PTF, and \(P=(P_{i})\) is a vector of multilinear polynomials of degree \(d\), whose moments \(_{Y(0,I_{n})}[P_{i}(Y)^{}]\) are all at most \(O_{d}()^{}\). Note that these bounds are much stronger than what we would get from standard arguments (which would only yield \(_{Y(0,I_{n})}[P_{i}(Y)^{}] O_{d}( )^{d}\)). As in , we approximate \(F\) by a smooth function \(\) via mollification (see Appendix A.1.1). That is, \(\) is the convolution \(F*\) of \(F\) with a carefully chosen smooth function \(\). Then, we set \(h(x)=T(P(x))\), where \(T\) is the Taylor approximation of \(\) of appropriate degree (see Appendix A.1.2). Intuitively, taking the Taylor expansion yields a good approximation as the (Gaussian) moments of the \(P_{i}\) are not too large, yielding (2), (3).

Error analysis of the approximation.Our goal is now to establish (2), (3) in our setting. Note that, since (2) is only concerned with the Gaussian distribution, there is no difference with . For (3), we have to generalize the proof in . For this, we first bound the probability under \(^{}\) that (at least) one of the \(P_{i}\) is large, which we do using Markov's inequality. Then, we need to show a bound on the moments of \(P_{i}\) under \(^{}\) (recall that the structure theorem only gives a bound on the Gaussian moments). Using bounds on the coefficients of the \(P_{i}\), we are able to do this under a mild condition on \(\) (see Appendices A.1.2 and A.1.3).

Controlling the additional error terms.To conclude the argument, we need to show that, for our low-degree approximation \(h\), we have \(_{Y(0,I_{n})}[h(Y)]_{X ^{}}[h(X)]\). Recall that in , these expectations were simply equal. The main issue lies in the fact that, in our setting, the moment matching is only approximate; equality would still hold if \(^{}\) matched the moments of \((0,I_{n})\) up to degree \(k\) exactly. Under \(\)_-approximate_ moment matching, we could say that

\[|_{Y(0,I_{n})}[h(Y)]-_{X ^{}}[h(X)]|\|h\|_{1},\] (4)

where \(\|h\|_{1}\) is the 1-norm of the coefficients of \(h\). However, there is no way to control this norm directly. Instead, we rely on the fact that \(h=T P\) and argue as follows. On the one hand, we show a bound on the coefficients in the Taylor approximation \(T\) of \(\). On the other hand, we show bounds on all terms of the form \(|_{Y(0,I_{n})}[P(Y)^{}]-_{X^{}}[P(X)^{}]|\). Combining these bounds yields an estimate on the difference \(|_{Y(0,I_{n})}[h(Y)]-_{X ^{}}[h(X)]|\), which lets us conclude (1).

Going into more detail, the LHS of (4) is equal to the inner product \(| t,u|\) between the vector \(t=(t_{})\) of coefficients of \(T\) and the vector \(u=(u_{})\), where \(u_{}=_{Y(0,I_{n})}[P(Y)^{}]- _{X^{}}[P(X)^{}]\). This can be viewed as a 'change of basis' \(x P(x)\). Then, (4) can bounded by \(\|u\|_{}\|t\|_{1}\), where \(\|u\|_{}=_{}|u_{}|\). The coefficients \(t_{}\) of \(T\) are related directly to the partial derivatives of \(\), which in turn depend on the function \(\) used in the mollification. After careful inspection of this function, we can bound \(\|t\|_{1} k^{O_{d}(k)}\) (see Lemma 27). Finally, for any \(|| k\), it holds that

\[|_{Y(0,I_{n})}[P(Y)^{}]-_{X^{}}[P(X)^{}]|_{i} (\|P_{i}\|_{1})^{||} n^{}  n^{O_{d}(k)},\]

see Fact 22. Putting things together, we get that

\[|_{Y(0,I_{n})}[h(Y)]-_{X ^{}}[h(X)]|\|u\|_{}\|t\|_{1}  k^{O_{d}(k)}n^{O_{d}(k)}/2,\]

using the fact that \( n^{-_{d}(k)}k^{-_{d}(k)}\) and \(k 1/\) for the last inequality.

#### 2.3.2 Fooling arbitrary PTFs

Now, let \(f(x)=(p(x))\) be an arbitrary PTF. As before, we want to establish (1). Following , the idea is to reduce this problem to the multilinear case as follows. Let \(Y(0,I_{n})\) and let \(X\) be a random variable that matches the moments of \(Y\) up to degree \(k\) and with slack \(\). For \(N\) to be chosen later, we construct new random variables \(\) and \(\), and a _multilinear_ PTF \(=()\), all in \(n N\) variables, such that \((0,I_{nN})\), \(\) matches moments of \(\) up to degree \(k\) with slack \(\), and

\[_{Y}[f(X)]-_{X}[f(X)] _{}[() ]-_{}[()].\] (5)

Assuming \(\) is not much bigger than \(\), and the approximation above is sufficiently good, we may then apply the result of Section 2.3.1 to \(\) to conclude (1) for \(f\). Our construction of \(,\) and \(\) will be the same as in . However, with respect to his proof, we face two difficulties. First, we need to control the slack parameter \(\) in terms \(\). More seriously, Kane's proof of (5) breaks in our setting: He relies on the fact that \(X\) is \(k\)-independent Gaussian in his setting to bound _high degree_ moments of \(\) which depend on at most \(k\) variables. In our setting, we have _no information_ on such moments at all (even if \(X\) matched the moments of \((0,I_{n})\) up to degree \(k\) exactly).

Construction of \(\) and \(\).For \(i[n]\), let \(Z^{(i)}\) be an \(N\)-dimensional Gaussian random variable with mean \(0\), variances \(1-1/N\) and covariances \(-1/N\), independent from \(X\) and all other \(Z^{(i^{})}\). We define \(_{ij} X_{i}/+Z^{(i)}_{j}\), and set \(=(_{ij})\). We define \(\) analogously. This ensures that \((0,I_{nN})\). Furthermore, given that \(X\) matches the moments of \(Y\) with slack \(\), it turns out that \(\) matches the moments of \(\) with slack \(=(2k)^{k/2}\). This follows by direct computation after expanding the moments of \(\) in terms of those of \(X\) and of the \(Z^{(i)}\), see Lemma 32.

Construction of the multilinear PTF.We want to construct a _multilinear_ polynomial \(\) in \(nN\) variables so that \(p(X)()\). For \(^{nN}\), write \(()(_{j=1}^{N}_{ij}/)_{i[n]} ^{n}\). Since \((Z^{(i)})=0\) holds deterministically, \(()=X\). So, if we were to set \(=p\), it would satisfy \(()=p(X)\). However, it would clearly not be multilinear. To fix this, we write \(p(())=_{}_{}^{}\) and replace each non-multilinear term \(_{}^{}\) by a multilinear one as follows: If the largest entry of \(\) is at least three, we remove the term completely. If the largest entry of \(\) is two, we replace the term by \(_{}^{^{}}\), where \(^{}_{ij}=1\) if \(_{ij}=1\) and \(0\) otherwise. This is identical to the construction in . Now, to show that \(p(X)()\) we need to bound the effect of these modifications. It turns out that it suffices to control the following expressions in terms of \(N\):

\[a_{i}_{j=1}^{N}_{i,j}}{} , b_{i}_{j=1}^{N}(_{i,j}} {})^{2}-1, c_{i,}_{ j=1}^{N}(_{i,j}}{})^{}(i[n], 3 d).\]

For the \(b_{i}\) and \(c_{i,}\), we can do so using a slight modification of the arguments in . For the \(a_{i}\), however, Kane  exploits the fact that in his setting, \(X_{i}\) is standard Gaussian for each fixed \(i[n]\), meaning the \(_{i,j}\) are jointly standard Gaussian over \(j\). This gives him access to strong concentration bounds. To get such concentration bounds in our setting, we would need information on the moments of the \(X_{i}\) up to degree roughly \( n\). However, we only have access to moments up to degree \(k\), which is not allowed to depend on \(n\) (as our tester uses time \(n^{(k)}\)). Instead, we use significantly weaker concentration bounds based on moments of constant degree. By imposing stronger conditions on the \(b_{i}\), \(c_{i,}\), we are able to show that the remainder of the argument in  still goes through in our setting, see Appendix A.2.2. Finally, for \(N\) sufficiently large, this allows us to conclude (5) for \(=()\).

### Impossibility result: learning PTFs via the push-forward

In this section, we show that the approach of  to prove testable learning guarantees for halfspaces w.r.t. the standard Gaussian cannot be generalized to PTFs. Namely, we show that in general, PTFs \(f(x)=(p(x))\) with \((p) 3\) cannot be approximated up to arbitrary error w.r.t. \((0,I_{n})\) by a polynomial of the form \(h(x)=q(p(x))\), regardless of the degree of \(q\).2 Importantly, we showthat this is the case even if one makes certain typical structural assumptions on \(p\) which only change the PTF \(f=(p)\) on a set of negligible Gaussian volume; namely that \(p\) is square-free and that \(\{p 0\}^{n}\) is compact. Our main technical contribution is an extension of a well-known inapproximability result due to Bun & Steinke (Theorem 15 below) to distributions 'with a single heavy tail' (see Theorem 18).

Approximating the sign-function on the real lineLet \(p_{\#}(0,I_{n})\) be the _push-forward_ of the standard Gaussian distribution by \(p\), which is defined by

\[_{Y p_{\#}(0,I_{n})}[Y A] _{X(0,I_{n})}[X p^{-1}(A)](A ).\] (6)

Note that, if \(h(x)=q(p(x))\), we then have

\[_{X(0,I_{n})}[|h(X)-f(X)|]=_{Y  p_{\#}(0,I_{n})}[|q(Y)-(Y)|].\]

Finding a good approximator \(h f\) of the form \(h=q p\) is thus equivalent to finding a (univariate) polynomial \(q\) which approximates the sign-function on \(\) well under the push-forward distribution \(p_{\#}(0,I_{n})\). In light of this observation, we are interested in the following question: Let \(\) be a distribution on the real line. Is it possible to find for each \(>0\) a polynomial \(q\) such that \(_{Y}[|q(Y)-(Y)|]\)? This question is well-understood for distributions \(\) whose density is of the form \(w_{}(x) C_{}(-|x|^{})\), \(>0\). Namely, when \( 1\), these distributions are _log-concave_, and the question can be answered in the affirmative. On the other hand, when \(<1\), they are _log-superlinear_, and polynomial approximation of the sign function is not possible.

**Theorem 13** (see, e.g. ).: _Let \(\) be a log-concave distribution on \(\). Then, for any \(>0\) there exists a polynomial \(q\) such that \(_{Y}[|q(Y)-(Y)|]\)._

**Definition 14**.: _Let \(\) be a distribution on \(\) whose density function \(w\) satisfies_

\[w(x) C w_{}(x)\,x\]

_for some \(<1\) and \(C>0\). Then we say \(\) is log-superlinear (LSL)._

**Theorem 15** (Bun-Steinke ).: _Let \(\) be an LSL-distribution on \(\). Then there exists an \(>0\) such that, for any polynomial \(q\), we have \(_{Y}[|q(Y)-(Y)|]>\)._

When \(p\) is of degree \(1\) (i.e., when \(f=(p)\) defines a halfspace), the push-forward distribution \(=p_{\#}(0,I_{n})\) defined in (6) is itself a (shifted) Gaussian. In particular, it is log-concave and by Theorem 13 approximation of the sign-function w.r.t. \(\) is possible. On the other hand, when \(p\) is of higher degree, \(\) could be an LSL-distribution, meaning approximation of the sign-function w.r.t. \(\) is not possible by Theorem 15. For instance, consider \(p(x)=x^{3}\). The density \(w\) of \(p_{\#}(0,1)\) is given by \(w(x)=C|x|^{-2/3}(-|x|^{2/3})\), and so \(p_{\#}(0,1)\) is log-superlinear.

Choice of description.The example \(p(x)=x^{3}\) is artificial: We have \((p(x))=(x)\), and so the issue is not with the concept \(f=(p)\), but rather with our choice of description \(p\). In general, one can (and should) assume that \(p\) is _square-free_, meaning it is not of the form \(p=p_{1}^{2} p_{2}\). Indeed, note that for such a polynomial, we have \((p(x))=(p_{2}(x))\) almost everywhere. Square-freeness plays an important role in the analysis of learning algorithms for PTFs, see, e.g., [22, Appendix A]. It turns out that even if \(p\) is square-free, the distribution \(p_{\#}(0,I_{n})\) can still be log-superlinear, e.g., when \(p(x)=x(x-1)(x-2)\). Note that, for this example, \((p)\) describes a non-compact subset of \(\). This is crucial to find that \(p_{\#}(0,1)\) is LSL. Indeed, if \(\{p 0\}\) were compact, then \(p_{}=_{x}p(x)<\), and so the density \(w\) of \(p_{\#}(0,1)\) would satisfy \(w(x)=0\) for all \(x>p_{}\). In particular, \(w\) would not be log-superlinear. One could therefore hope that assuming \(\{p 0\}\) is compact might fix our issues. This assumption is reasonable as \(\{p 0\}\) can be approximated arbitrarily well by a compact set (in terms of Gaussian volume). On the contrary, we show the following.

**Theorem 16**.: _There exists a square-free polynomial \(p\), so that \(\{p 0\}\) is compact, but for which there exists \(>0\) so that, for any polynomial \(q\), \(_{X(0,1)}[|q(p(X))-(p(X))| ]>\)._

To establish Theorem 16, we prove a 'one-sided' analog of Theorem 15 in Appendix B.1, which we believe to be of independent interest. It shows impossibility of approximating the sign-function under a class of distributions related to, but distinct from, those considered by Bun & Steinke . The key difference is that the densities in our result need only to have a single heavy tail. However, this tail must be 'twice as heavy' (\(<1/2\) vs. \(<1\)). We emphasize that  does not cover compact PTFs.

**Definition 17**.: _Let \(\) be a distribution on \(\) whose density function \(w\) satisfies_

\[w(x) C w_{}(x)\,x(-,1]\]

_for some \(<1/2\) and \(C>0\). Then we say \(\) is one-sided log-superlinear._

**Theorem 18**.: _Let \(\) be a one-sided LSL-distribution on \(\). Then there exists an \(>0\) such that, for any polynomial \(q\), we have \(_{Y}[\|q(Y)-(Y)\| >.\)._

Proof of Theorem 16.: It suffices to find a square-free polynomial \(p\) for which \(\{p 0\}\) is compact, and the push-forward distribution \(p_{\#}(0,1)\) is one-sided LSL. A direct computation shows that

\[p(x)-x(x-1)(x-2)(x-3)(x-4)(x-5)\]

meets the criteria, see Appendix B.2 for details.