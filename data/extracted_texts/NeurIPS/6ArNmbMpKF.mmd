# Noisy Dual Mirror Descent: A Near Optimal Algorithm for Jointly-DP Convex Resource Allocation

Du Chen Geoffrey A. Chua

Nanyang Business School, Nanyang Technological University, Singapore, 639798

chen1443@e.ntu.edu.sg, gbachua@ntu.edu.sg

Corresponding author

###### Abstract

We study convex resource allocation problems with \(m\) hard constraints under \((,)\)-joint differential privacy (Joint-DP or JDP) in an offline setting. To approximately solve the problem, we propose a generic algorithm called Noisy Dual Mirror Descent. The algorithm applies noisy Mirror Descent to a dual problem from relaxing the hard constraints for private shadow prices, and then uses the shadow prices to coordinate allocations in the primal problem. Leveraging weak duality theory, we show that the optimality gap is upper bounded by \((}{})\), and constraint violation is no more than \((}{})\) per constraint. When strong duality holds, both preceding results can be improved to \(}(}{})\) by better utilizing the geometric structure of the dual space, which is neglected by existing works. To complement our results under strong duality, we derive a minimax lower bound \(()\) for any JDP algorithm outputting feasible allocations. The lower bound matches our upper bounds up to some logarithmic factors for \(\{1,1/(n)\}\), where \(n\) is the available resource level. Numerical studies further confirm the effectiveness of our algorithm.

## 1 Introduction

The resource allocation problem is a classic optimization problem and has many applications in machine learning, such as Internet advertising and personalized recommendation, among many others. The problem is typically modeled as a utility maximization problem, where the central decision maker has to properly allocate \(m\) types of limited resources to \(n\) agents in order to maximize the total utility of all agents. Each agent's data \(z_{i}:=(u_{i}(),_{i}(),_{i})\) consists of three elements: (i) a utility function \(u_{i}:_{+}^{s}_{+}\) that maps an allocation \(_{i}\) to a utility scalar; (ii) a consumption function \(_{i}:_{+}^{s}_{+}^{n}\) that maps an allocation \(_{i}\) to a consumption vector; and (iii) a feasible set \(_{i}_{+}^{s}\) that may capture the agent's special requirements. With a dataset \(:=\{z_{i}\}_{i=1}^{n}\) of \(n\) agents, the problem is modeled as

\[_{\{_{i}\}_{i=1}^{n}} _{i=1}^{n}u_{i}(_{i})\] (1) \[_{i=1}^{n}_{i}(_{i}) n ;\] (2) \[_{i}_{i}, i=1,2,,n,\] (3)

where \(n>\) is the available level of \(m\) types of resources. Evidently, the goal in (1) is to find the best allocation \(_{i}\) for each agent subject to resource-coupling constraints (2) and to a personalrequirement constraint (3). When \(u_{i}()\) is concave, and \(_{i}()\), \(_{i}\) are both convex, the problem reduces to a convex constrained problem that has been widely studied in optimization literature.

However, an emerging issue in allocation problems is data privacy. Because constraint (2) couples agents, the allocation decision to one agent would affect the allocation to another agent. When a group of agents collude, they can infer other agents' data by analyzing their received allocations. For example, when allocating limited budgets among education agencies to support students in poverty, a simple rule is to allocate budgets proportional to the number of students in poverty . Agencies who notice a change in received funding may infer the financial status of students in other agencies. Realizing this potential leakage of its students' financial status, an agency may misreport the number of its students in poverty, compromising the original intention of the financial support.

To overcome privacy concerns in such cases, joint differential privacy (Joint-DP or JDP, for short), which is a relaxation of differential privacy (DP), has been adopted. It is found that JDP is more suitable than DP for the considered allocation problems . Essentially, JDP ensures agent \(i\)'s data cannot be accurately inferred by a group of collusive agents without \(i\). It guarantees that the allocations received by the collusive agents are insensitive to agent \(i\)'s data. Considering that the allocation decision \(_{i}\) is usually private to agent \(i\) herself, the privacy guarantee by JDP is hence meaningful and sufficiently strong. The most handy way to achieve JDP is by the well-known Billboard Lemma : publish a DP public signal on a billboard accessible to all agents, and compute the allocation for agent \(i\) based on the DP public signal and agent \(i\)'s own data only; then the final allocations \((_{1},,_{n})\) satisfy JDP. The Billboard Lemma has wide applications, ranging from convex optimization , to multi-armed bandits , to reinforcement learning . We also use it for privacy analysis. For clarification purposes, we highlight that, in problem (1), dataset \(\{z_{i}\}_{i=1}^{n}:=\{(u_{i}(),_{i}(),_{i})\}_{i=1} ^{n}\) is the private information to protect; resource level \(n\) is treated as public information.

While important and fundamental, resource allocation problems under JDP are far from being well understood, in terms of both algorithm design and theoretical analysis. For algorithm design, most existing works adopt a "dual decomposition" idea , which dualizes the coupling constraint (2) and iteratively seeks private minimizers of a dual problem to coordinate the allocation process in the primal problem. However, the primal-dual relationship and the geometric structure of the dual space are not well exploited, leaving substantial room for improvement. In terms of theoretical analysis, both privacy accounting and optimality analysis are short of modern standard. For privacy accounting, existing works  all use Advanced Composition, which suggests an unnecessarily large noise to be injected, significantly hindering algorithm practicability. For optimality analysis,  fails to take full advantage of strong assumptions made, and the analysis by  is specific to linear packing problems. More importantly, there is no formal understanding of the fundamental trade-off between privacy and optimality in resource allocation problems under JDP, i.e. minimax lower bounds. Motivated by these gaps in the literature, we focus our study on the following three questions.

1. Can we design a generic algorithm for resource allocation problem (1), and provide better privacy and optimality analysis?
2. Can we better utilize the primal-dual relationship to improve performance?
3. Is our algorithm (near) optimal? What is the minimax lower bound?

Our contributionsFirst, we propose a generic algorithm Noisy Dual Mirror Descent, which follows a similar dual decomposition idea. We tighten the privacy analysis through Renyi DP, and analyze performance (both optimality and constraint violations) by better utilizing the primal-dual relationship. Second, for many cases where strong duality holds, we further improve performance by leveraging on the \(_{1}\) geometry of the dual space. Last, we complement previous analysis with a matching minimax lower bound for \(\{1,1/(n)\}\), suggesting near optimality of our algorithm. We further conduct numerical experiments to show the effectiveness of our proposed algorithm. Table 1 summarizes our contributions and compares them with results in the literature.

Our interpretation of algorithm performanceBecause the algorithms considered may output infeasible solutions, when assessing their performance, we should take into account both suboptimality in utility and constraint violations, i.e., the last two columns in Table 1. We therefore treat the sum of them as the ultimate performance. This idea admits a social welfare interpretation: when the central decision maker (e.g., a government) desires to implement an infeasible allocation, she may purchase additional resources from an emergency supplier to make the allocation feasible. Then, the total loss in social welfare is the sum of (i) the loss in utility of agents and (ii) the decision maker's expenditure on extra resources. If we only look at suboptimality, we may mistakenly conclude that the gap could be arbitrarily small. Following our interpretation of performance, our proposed algorithm is near optimal.

Related workJDP was initially proposed by  as a relaxation of differential privacy , which better fits the nature of privacy issues in zero-sum games, such as allocation problems . Following this stream, the most relevant works to ours are , both of which designed their algorithms with a dual decomposition idea.  proposed the first generic method, dual gradient descent, for solving allocation problems. For the special case of linear packing problem,  designed a dual multiplicative weight update algorithm, and extended it to online setting.  further provides an economic interpretation of payoff sharing. Our work is also closely related to Mirror Descent (MD) , a generalization of projected gradient descent to non-Euclidean settings. Its private version, Noisy MD, has recently found many applications in non-Euclidean DP stochastic convex optimization  and saddle-point problems . We further apply Noisy MD to JDP resource allocation problems.

## 2 Preliminaries

**Definition 2.1** (Differential privacy, ).: _A mechanism \(:^{n}\) is \((,)\)-differentially private if, for any pair of neighboring datasets \(^{}\) that differ in one data point, and for any subset of output \(\), we have \([()] e^{ }[(^{})]+\)._

Throughout the work, we use the subscript \(-_{i}\) to indicates variables without agent \(i\). For example, \(_{-i}:=_{1}_{i-1}_{i+1}_{n}\) is a feasible space without \(i\), and \(()_{-i}:=(()_{1},,()_{i-1},()_{i+1},,( )_{n})\) is the view from other agents without \(i\).

**Definition 2.2** (Joint differential privacy, ).: _A mechanism \(:^{n}^{n}\) is \((,)\)-jointly differentially private if for any pair of neighboring datasets \(^{}\) that differ in datapoint \(i[n]\), and for any subset of outputs \(_{-i}\), we have \([()_{-i}] e^{ }[(^{})_{-i} ]+\)._

    &  &  \\   & \(u_{i}()\) & \(_{i}()\) & \(_{i}\) & 
 assume \\ strong \\ duality? \\  & LB & utility loss UB & total & total & constraint violation \\ 
\({}^{}\) linear & linear & 
 probability \\ simplex \\  & ✓ & - & \(}(}{ })\) & \(}(}{ })\) \\ (Theorem 3.3, w.h.p.) & & & & (Theorem 3.3, w.h.p.) & \\ 
\({}^{}\) linear & linear & \([,]\) & ✓ & - & \(}(}{ })\) & \(}(}{ })\) \\ (Theorem 1.1, w.h.p.) & & & & (section 3.2, w.h.p.) & \\  This work & concave convex & convex & ✗ & - & \((}{})\) & \((}{ })\) \\ (Theorem 3.5) & & & & & (Theorem 3.6) & \\   

* _Notes. All results in the table are stated for_ \((1/)\) _for conciseness;_ \(m,n,T\) _are the number of constraints, agents, and iterations, respectively. Tilde symbol_ \(}\) _hides poly-log factors in_ \(m\)_; for results in_ \([^{},^{}]\)_,_ \(}\) _additionally hides poly-log terms in_ \(n\) _and_ \(T\)_. LB-lower bound, UB-upper bound, b.u.p-newth high probability._ \({}^{}\) _The algorithm in_ \([^{}]\) _can be practically applied to general convex problems. But one supporting Lemma (Theorem 2.1) they used to derive analytical results is only valid for linear problems with solutions in probability simplex._ \({}^{}\) _An lower bound_ \((}{})\) _can be derived from_ \([^{},]\)_. But their original statement is for the minimal supply, not for suboptimality as we considered._ \({}^{}\) _The lower bound is for algorithms outputing feasible allocations, while upper bounds are achieved by algorithms that may output infeasible allocations. So, the lower bound could be higher. The lower bound holds only for_ \(\{1,1/(n)\}\) _where_ \((0,1)\)_._

Table 1: Comparison of various works on resource allocation problems under \((,)\)-JDP.

**Lemma 2.3** (Billboard Lemma, ).: _Suppose \(:^{n}\) is \((,)\)-DP. For any given function \(f:\), denote the output of \(f\) on individual \(i\)'s data as \(f_{i}:=f(z_{i},())\). Then, \((f_{1},,f_{n})\) is \((,)\)-JDP._

**Definition 2.4** (\(\)-strong convexity).: _Let \(>0\). Function \(:^{m}\) is said to be \(\)-strongly convex w.r.t. \(_{p}\) over set \(\), if \(()()+(),- +-_{p}^{2}, ,\)._

Primal problem in a condensed formLet \(:=(_{1},,_{n})\) be the collection of allocations. For a given dataset \(\), let \(():=_{i=1}^{n}u_{i}(_{i})\) be the total utility when allocation is \(\). Let \(():=_{i=1}^{n}_{i}(_{i})\) be the total consumed resource, and let \(:=_{1}_{n}\) be the feasible region. Then, the resource allocation problem (1), referred to as "primal problem" later, can be written in a condensed form:

\[_{}\{():() n\}.\] (4)

The optimal allocation is denoted as \(^{*}:=_{}\{():( ) n\}\).

Dual problemBy dualizing the coupling constraint with shadow prices \(\), we get a Lagrangian function \(_{}_{}\{()+ ,n-()\}\). Thus, the Lagrangian dual problem is

\[_{}(),\] (5)

where \(():=_{}\{()+ ,n-()\}\). It is easy to see that, given \(\), the dual problem is decomposable across agents, i.e., \(()=_{i=1}^{n}_{_{i}_{i}}\{u_{ i}()+,-_{i}(_{i})\}\). Let us denote the dual problem's minimizer by \(^{*}:=_{}()\).

When there are multiple \(^{*}\) and \(^{*}\), we can break ties arbitrarily. Let \(_{p}\) denote the \(p\)-norm of a vector, and let \([n]:=\{1,,n\}\) be a running set. We impose some assumptions on dataset \(\) to make both primal and dual problems interesting.

**Assumption 2.5** (Interesting instances).: _For a dataset \(:=\{(u_{i}(),_{i}(),_{i})\}_{i=1}^{n}\), we assume_

1. _Convexity_: _for each_ \(i[n]\)_, utility function_ \(u_{i}\) _is concave on_ \(_{i}\)_, consumption function_ \(_{i}\) _is convex on_ \(_{i}\)_, and_ \(_{i}\) _is a convex set;_
2. _Boundedness_: \(\,>0\) _and bounded_ \(>\) _with_ \(_{2} B\) _such that_ \(u_{i}(_{i})[0,]\) _and_ \(_{i}(_{i})[,]\)_,_ \(_{i}_{i},i[n]\)_. Specially, if_ \(_{i}\)_, then_ \(u_{i}()=0\) _and_ \(_{i}()=\)_;_
3. _Limited resource_: _the constant_ \(\) _in (_4_) is assumed to be in the interval_ \((0,1)\) _. The primal problem_ (_4_) _is feasible, and optimal_ \(^{*}\) _is attainable. Under_ \(^{*}\)_, at least one of_ \(m\) _constraints in (_4_) is binding. Moreover, the optimal shadow prices_ \(^{*}\) _to dual problem (_5_) are not all zeros, i.e.,_ \(^{*}_{1} 0\)_;_
4. _Compulsory request allowed_: _request_ \(i\) _can be compulsory in the sense that_ \(_{i}\)_, only if_ \(_{_{i}_{i}}\{u_{i}(_{i})+^{*},- _{i}(_{i})\} 0\)_._

These assumptions are very mild. The first assumption restricts our attention to convex problems. The second one assumes both utility and consumption functions are non-negative and bounded from above, and are both zeros if no resource is allocated. The third one assumes the non-private problem is indeed resource-constrained and not ill-posed. The constant \(\) controls available resource levels, and \(n\) means the number of agents whose requests can be fully fulfilled. In practice, usually \( 1/n\). The fourth one allows agents to propose compulsory requests with minimal requirements strictly greater than \(\), as long as allocating resource to the agent is beneficial. Our assumptions are weaker than those in the literature  by allowing compulsory requests.

## 3 The algorithm and analysis

Our algorithm is a private version of Mirror Descent applied to the dual problem (5). Mirror Descent (MD)  is a generalization of Projected Gradient Descent (Proj-GD) that can better cater to the geometry of the problem at hand by the proper choice of a strongly convex potential function \(:^{+}\). The potential function chosen should meet some conditions below.

**Condition 3.1** (Potential Functions).: _The potential function \(:_{+}\) chosen should be (i) differentiable on \(()\), i.e., the interior of its domain \(^{m}\); and (ii) \(\)-strongly convex with respect to \(_{p}\) on \(\). For a given \(\), let \(B_{}(,):=()-()-(),-\) be the Bregman divergence between \(,()\)._

With the primal problem (4) and dual problem (5) in mind, and a well-chosen potential function, we are ready to present the algorithm, Noisy Dual Mirror Descent.

```
0: Parameters: privacy parameters \((,)\), variance \(^{2}\); stepsizes \(\{^{(t)}\}_{t=1}^{T}\); potential function \(():_{+}\) that is \(\)-strongly convex with respect to \(_{p}\)-norm; conjugate index \(q\) s.t. \(1/q+1/p=1\), number of iterations \(T\), feasible region of shadow prices \(:=_{+}^{m}\).
1: Set initial point \(^{(1)}()\)
2:for\(t=1\) to \(T\)do
3: Get intermediate allocation decision \(^{(t)}_{}()+ ^{(t)}, n-()\)
4: Draw a noise vector \(^{(t)}(,^{2}_{m m})\)
5: Update private shadow prices according to Noisy Mirror Descent: \[^{(t+1)}_{}\{ ^{(t)}^{(t)}+^{(t)}, +B_{}(,^{(t)})\},\] (6) where \(^{(t)}:=n-(^{(t)})\)
6: Final allocation decision \(^{}:=(_{1}^{},,_{n}^{})_{t=1}^{T}^{(t)}\)
7:Output\(_{i}^{}\) to agent \(i\), for all \(i[n]\) ```

**Algorithm 1** Noisy Dual Mirror Descent for Resource Allocation Problems, \(\)

The algorithm is an iterative algorithm, and in each iteration, we first calculate allocation decisions based on current shadow prices \(^{(t)}\), i.e. Step 3. Then, we update the shadow prices by Noisy Mirror Descent update rule (6). The gradient \(^{(t)}\) used is exactly the gradient of the dual problem \((^{(t)})\) according to Danskin's theorem. After \(T\) iterations, we output the averaging allocations across all iterations. In other words, we basically apply Noisy Mirror Descent to solve the dual problem, and use the sequence of shadow prices to coordinate allocations in the primal problem. Intuitively, the shadow prices are implicitly pricing each resource to ensure that limited resources are allocated to agents most in need.

Recall the Billboard Lemma, if we can privatize the entire sequence of shadow prices in a DP manner, then the final allocation decisions will be JDP. Compared to existing works invoking Advanced Composition, we provide a tighter privacy accounting through Renyi DP.

**Theorem 3.2** (JDP Guarantee).: _Given \(>0,(0,1)\) and \(T 1\), if noise variance \(^{2}=T c_{,}\) with \(c_{,}:=_{2}^{2}(}+)\), then Algorithm 1\(\) is \((,)\)-JDP._

To better align with expressions in DP literature, we can assume \((1/)\). Then, the magnitude of \(c_{,}\) becomes \(}\), a magnitude of Gaussian Mechanism that frequently appears in DP literature. Moreover, the privacy analysis via Renyi DP significantly lowers the variance level. For example, when \(=1\), \(=10^{-3}\), and \(_{2}^{2}=1\), the variance indicated by Theorem 3.2 is \(14.8T\), compared to approximately \(121.6T\) by [16, Theorem 3.2], [17, Lemma 3.1].

### Performance upper bounds

We now move on to analyze the utility optimality gap \((^{*})-_{}[(^{ })]\). The following weak duality lemma bridges the primal and dual problems.

**Lemma 3.3** (Weak duality).: _For any \(\), the objective value of dual problem (5) is always greater than or equal to that of primal problem (4), i.e., \(()_{}\{(): () n\},\)._

An immediate result of weak duality is \((^{(t)})(^{*}), t\). Hence, applying weak duality and Jensen's inequality, the optimality gap \((^{*})-(^{})\) can be upper bounded as follows, providedthe randomness dice of \(\) is fixed,

\[(^{*})-(^{})_{t=1}^{T}((^{(t)})-(^{(t)})) =_{t=1}^{T}^{(t)},n- (^{(t)})\] \[=_{t=1}^{T}^{(t)},^{(t )}+^{(t)}-_{t=1}^{T}^{ (t)},^{(t)},\]

where the first equality is by definition of the dual problem, and the second equality is by definition of gradient \(^{(t)}\). Taking expectation with respect to \(\) removes the subtrahend, since \(^{(t)}\) is independent of \(^{(t)}\) and zero-mean, which gives \((^{*})-_{}[(^{ })]_{}[_{t=1}^{ T}^{(t)},^{(t)}+^{(t)}]\). The inner term is closely related to stationarity gap  in nonconvex optimization. It is well-known that Proj-GD guarantees a small stationarity gap in both non-private  and private  cases. Not surprisingly, MD can also achieve a small stationarity gap.

**Lemma 3.4** (Cumulative stationarity gap of MD).: _Suppose stepsizes \(^{(t)}=\) in MD update rule (6) are the same for all \(t[T]\), and let \(\{}^{(t)}\}_{t=1}^{T}\) be gradients used for update. Then the cumulative stationarity gap \(_{t=1}^{T}^{(t)}-,}^{(t)}\) for any anchor point \(\) is upper bounded as_

\[_{t=1}^{T}^{(t)}-,}^{(t)} ^{T}\|}^{(t)} \|_{q}^{2}}{2}+(,^{(1)})}{}, .\]

With Lemma 3.4 and proper stepsizes, we can control the optimality gap. Denote \(:=\{,1-\}\), \(G:=^{2}n^{2}\|\|_{q}^{2}\), and let \((,_{m m})\) be a standard Gaussian random vector. For a given potential function \(\) and an initial point \(^{(1)}\), denote \(C_{}(^{(1)}):=(,^{(1)})/}\).

**Theorem 3.5** (Utility guarantee).: _Set stepsizes \(^{(t)}=(,^{(1)})}{(G+ ^{2}[\|\|_{q}^{2}])}}, t[T]\). Suppose potential function's domain includes \(\), i.e., \(\). Then running algorithm \(\) with iterations \(T[\|\|_{q} ^{2}]}\) and \(^{2}\) chosen in Theorem 3.2 yields_

\[(^{*})-_{}[(^{ })] 4C_{}(^{(1)})[ \|\|_{q}^{2}]}}.\] (7)

An instantiation of the utility guarantee is by \(()=\|\|_{2}^{2}\), which is \(1\)-strongly convex w.r.t. \(_{2}\)-norm on \(^{m}\). Then, the upper bound in (7) becomes \(2\|^{(1)}\|_{2}}\), which depends on the choice of initial point \(^{(1)}\). It seems the bound can be arbitrarily small if \(^{(1)}\) is close to \(\). But in fact, the theorem itself does not reflect the whole picture, since \(^{}\) could be infeasible. Therefore, we have to further examine \(\)'s feasibility guarantee.

**Theorem 3.6** (Feasibility guarantee).: _Given allocation decision \(^{}\), denote the violation levels as \(^{}:=((^{})-n)^{+}\), where positive part operator \(()^{+}\) applies element-wisely. In addition to Condition 3.1, additionally assume the domain \(\) of potential function \(\) contains \(2\|^{*}\|_{1}_{j}, j[m]\). Then, running algorithm \(\) with the same setting as in Theorem 3.5 yields_

\[_{}[\|^{}\|_{} ]([\|\|_{q}^{2} ]} C_{,1}(^{(1)})}{\|^{*} \|_{1}}+2)},\] (8)

_where \(C_{,1}(^{(1)})=(,^{(1)})+_{  E_{1}}B_{}(2\|^{*}\|_{1},^{(1)})}{(,^{(1)})}}\), set \(E_{1}:=\{\{0,1\}^{m}:, 1\}\)._

The proof idea is to sandwich the cumulative stationarity gap \(_{t=1}^{T}^{(t)}-,}^{(t)}\) at a properly chosen anchor point \(:=2\|^{*}\|_{1}_{j^{}} \) (the constant \(2\) is chosen arbitrarily, it can be any value strictly greater than 1), and then comparing the upper bound and lower bound in the sandwich inequality gives the desired result. The base vector \(_{j^{}}\) with a single 1 on \(j^{}\)-th position indicates which constraint \(j^{}[m]\) is most severely violated. One may notice that the anchor point \(:=2\|^{*}\|_{1}_{j^{}}\) needs to be in \(\), which implicitly imposes one additional condition on the domain \(\) of potential function \(\). While the capability of computationally calculating \(\|^{*}\|_{1}\) is not needed for deriving (8), on a practical note, we may need to adjust \(\) accordingly so that \(\) contains all possible anchor points \(2\|^{*}\|_{1}_{j^{}}, j^{}\) almost surely. When doing so, we should be very careful because \(^{*}\) depends on dataset \(\) and thus, such an adjustment may leak privacy.

Again, one may think \(()=\|\|_{2}^{2}\) is the ideal potential function, because its domain \(=^{m}\) contains all anchor points of interest, does not depend on \(^{*}\), and therefore no privacy leakage risk. As shown in the first row of Table 2, the guarantees under squared \(_{2}\) are only comparable to, not better than, those in the literature summarized in Table 1. Nevertheless, being comparable is already a significant improvement because our results are derived from weak duality only, whereas existing works all assume strong duality. Moreover, since anchor points \(=2\|^{*}\|_{1}_{j^{}}\) are related to \(_{1}\) norm of \(^{*}\), if we can find a data-independent upper bound for the value of \(\|^{*}\|_{1}\), we might be able to adjust \(\) accordingly without privacy concerns and may further improve performance. We do so in the next subsection.

### Improvements by strong duality

Indeed, there exists space for improvement, if we assume strong duality holds.

**Assumption 3.7** (Strong duality holds).: _Strong duality between primal problem (4) and dual problem (5) holds, i.e., \((^{*})=(^{*})\), where \(^{*}\) and \(^{*}\) are optimal solutions to (4) and (5), respectively._

While weak duality always holds, strong duality does not universally hold. However, there are many applications where strong duality naturally holds. For example, when the dualized constraint \(() n\) is linear in \(\), strong duality holds. If the constraint is not linear, one can check strong duality by Slater's condition, which essentially says that if the primal problem (4) has strictly feasible solutions, then strong duality holds. The strong duality assumption here is also very mild, and all examples previously considered in the literature satisfy strong duality, for example [16, Section 4] and . However, these works fail to take full advantage of strong duality. We fill the gap by noticing that strong duality actually restricts \(^{*}\) to an \(_{1}\) space.

**Lemma 3.8** (Strong duality implies bounded \(^{*}\)).: _Let \(^{*}:=_{ 0}()\). Then, under assumptions 2.5 and 3.7, we have \(,^{*}}{}\) and \(,^{*}}{ {}}\) with \(:=_{j}\{b_{j}\}\)._

The above lemma indicates that \(^{*}\) lies in the interior of a scaled simplex, suggesting the best choice of potential function could be the negative entropy function, which better fits the \(_{1}\) geometry. However, negative entropy \(()=_{j=1}^{m}w_{j} w_{j}\) is widely known to be 1-strongly convex only on the probability simplex \(_{1}:=\{>:,=1\}\). To tailor it for our studied problem, we parameterize the negative entropy \((;):=_{j=1}^{m}(_{j}w_{j})(_{j}w_ {j})\) with \(>\), and show that it is also strongly convex _in_ a scaled simplex.

**Lemma 3.9** (Strong convexity of parameterized negative entropy).: _Let the parameterized negative entropy \((;):=_{j=1}^{m}(_{j}w_{j})(_{j}w_ {j})\) be defined on \(_{+}^{m}\), where we define \(=0\) and \(0 0=0\)

    & Potential Function & & & Theoretical Guarantees \\  function & domain & strong cvx. \({}^{}\) & init. pt. & opt. gap & total constr. viol. \\  name & \(()\) & \(\) & \(\) w.r.t \(\|\|_{p}\) & \(^{(1)}\) & \((^{*})-[}^{}]\) & \(m[\|}^{}\|_{}]\) \\  squared \(_{2}\) & \(\|\|_{2}^{2}\) & \(^{m}\) & 1 w.r.t \(\|\|_{2}\) & \(}\) & \((}{})\) & \((}{})\) \\ negative entropy (ne) & \(_{j=1}^{m}p_{j} p_{j}\) & \(_{K}\) w. \(K=}{}\) & \(\) w.r.t. \(\|\|_{1}\) & \(\) & \(K}(}{})\) & \(K}(}{ })\) \\ parameterized ne & \(_{j=1}^{m}b_{j}p_{j}(p_{j}p_{j})\) & \(_{K}()\) w. \(K=}{}\) & \(}{K}\) w.r.t. \(\|\|_{1}\) & \(}\) & \(}\) & \(}\) \\    _Notes. Results for squared \(_{2}\) (negative entropy) are from Section 3.1 (Section 3.2). Strong duality is necessary for theoretical guarantees by (parameterized) negative entropy. Abbreviations in column titles: cvx.complexity, init.pt-initial point, opt.gap = optimality gap, contrs.viol.comstraint violations. The (scaled) simplex set \(_{K}()\) with radius \(K\) is defined as \(_{K}():=\{:, K\}\); the standard simplex is \(_{K}:=_{K}()\). \({}^{}\) Squared \(_{2}\) function is strongly convex on whole space \(^{m}\), while negative entropy functions only on their respective domains. Results in the **first** and **second** rows are highlighted as the main contributions in Table 1.

Table 2: Examples of theoretical guarantees under specific choices of hyperparameters.

by continuity. Then \((;)\) is \((_{j}\{_{j}\})^{2}/K\)-strongly convex in \(\) w.r.t. \(_{1}\) in a scaled simplex \(_{K}^{}():=\{>:, {w} K\}\)._

It is immediate to see that if we set \(=\) and \(K=1\), then Lemma 3.9 recovers the well-known result that negative entropy is \(1\)-strongly convex. For our studied problem, we can let the negative entropy be parameterized by \(\), and use \((;)=_{j=1}^{m}(b_{j}w_{j})w_{j})}\) for the Mirror Descent update step (6). This does not compromise privacy, since \(\) is a universal upper bound and is not associated with any specific agent. Now, we are ready to improve the algorithm's performance.

**Theorem 3.10** (Improved utility & feasibility guarantees).: _Let \(:=_{j}\{b_{j}\}\), \(:=_{j}\{b_{j}\}\). Under assumptions 2.5 and 3.7, running algorithm 1\(\) with parameterized negative entropy \((;)\) with radius \(K:=2/\), \(p_{j}^{(1)}=K/(m{b_{j}}), j[m]\), and same \(T\), \(^{2}\) as in Theorem 3.5 yields_

\[(^{*})- _{}[(^{})] }}{ }};\] \[_{ }[^{}_{}] }[2+()}-1)^{+}]}{^{*} _{1}}}.\]

Compared to the results in Theorems 3.5 and 3.6 where both dependencies on number of constraints are \(\), the results here have better dependencies of \( m\). Moreover, following our interpretation of algorithm performance as discussed in the Introduction, Theorem 3.10 implies that the algorithm's ultimate performance is \(}(})+m }(})=}(m})\). The additional \(m\) factor comes from \(m\) constraints, since the feasibility guarantee in Theorem 3.10 is for any single constraint.

## 4 The lower bound

Some post-processing lemmas for JDP are necessary to prove the lower bound.

**Lemma 4.1** (Self post-processing for JDP).: _Let \(:^{n}^{n}\) be an \((,)\)-JDP mechanism and denote its output by \(():=(()_{1},,( )_{n})\). Let \(f:\) be an arbitrary (randomized) function that can be applied element-wisely to \(\)'s output. Then, \((f(()_{1},z_{1}),,f(()_{n}, z_{n}))\) is \((,)\)-JDP._

**Lemma 4.2** (Post-processing for JDP).: _Let \(:^{n}^{n}\) be an \((,)\)-JDP mechanism and denote its output by \(():=(()_{1},,( )_{n})\). Let \(f:^{n-1}\) be an arbitrary (randomized) function that can be applied to any collection of \(n-1\) elements of \(\)'s output. Then, for any \(k[n]\), \(f(()_{-k})\) and \(f((^{})_{-k})\) are \((,)\)-indistinguishable.2_

Lemma 4.1 confirms that processing each JDP output with the agent's own data preserves JDP. Lemma 4.2 says applying any operation to \(n-1\) elements of two \(n\)-length JDP outputs obtained from a pair of neighboring datasets will be indistinguishable.

To see how these two lemmas help, we consider the allocations \(^{}:=(^{}_{1},,^{}_{ n})\) outputed by a JDP algorithm \(:^{n}^{n}\). By Lemma 4.1, their consumptions \((_{1}(^{}_{1}),,_{n}(^{}_ {n}))\) are also JDP. Furthermore, for any conclusive group without agent \(k\), their total consumption \(_{i k}_{i}(^{}_{i})\) should be insensitive to agent \(k\)'s allocation by Lemma 4.2. To ensure insensitivity, intuitively but informally, any algorithm \(\) outputting feasible allocations should _reserve_ some resource exclusively for agent \(k\). But the reserved resource is wasted in some scenarios, which leads to the lower bound.

**Theorem 4.3** (Minimax lower bound).: _For \(\{1,1/(n)\},0< 1/2\), there exists a dataset \(\) satisfying assumptions 2.5 and 3.7 such that any \((,)\)-JDP algorithm \(\) outputting feasible allocations will lead to a utility loss at least \(m/(4)\). Therefore, the minimax lower bound is_

\[_{\,\,(,)}_{ }\{(^{*}())-_{ }[(^{}())]\}.\]

The lower bound here nearly matches upper bounds given by Theorem 3.10 up to some logarithmic factors in \(m\) and \(1/\). Therefore, Noisy Dual Mirror Descent is near optimal, under our interpretation of algorithm performance. However, the result is limited to \(\{1,1/(n)\}\), and it is interesting to derive lower bounds for other \(\). We provide a promising direction in the Appendix, which involves a lower bounding optimization problem with hockey-stick divergence constraints. We conjecture that couplings and divergences employed by  are promising tools for this purpose.

## 5 Numerical experiments

### Workforce scheduling

Workforce scheduling is about establishing a shift schedule for a given period to maximize workers' total preference while meeting worker availability and shift coverage requirements. Workers' preference and availability are private data to protect. We consider a simple case of scheduling \(n=7\) workers for \(m=14\) days with data publicly available . In this case, (i) each worker has preferences \(_{i}_{+}^{m}\), and utility function is \(u_{i}(_{i})=_{i},_{i}\); (ii) shift requirement \(r_{j}_{+}\) is imposed on each day \(j[m]\), i.e., the number of workers needed for day \(j\), which couples all workers; and (iii) workers' availability and shift limits described by a polyhedral set \(_{i}:=\{_{i}^{m}:l_{i},_{i}  u_{i}\}\). The problem is modeled as \(\{_{i=1}^{n}_{i},_{i}:_{i}_{ i}=;_{i}_{i}, i\}\). While this is a small case, it is suitable for visualizing decisions and understanding the impact of JDP. Moreover, since the optimal non-private \(^{*}=\) is a sparse vector, one can expect MD equipped with negative entropy to perform better.

Figure 1 shows the final decisions under various \(\), where the rightmost is the optimal non-private decision where a value of \(1\) means arranging the person to that day.

Private decisions are fractional and can be interpreted as probabilities. It is not hard to see that private decisions are in a similar pattern to non-private decisions, and many private decisions are exactly the same as their optimal non-private counterpart. Moreover, private decisions different from their non-private counterpart converge gradually as \(\), see for example, the decision of (Day1, Marisa), (Day2, Marisa), and (Day4, Vincent). Optimality gaps and constraint violations are shown in Figure 2 (left panel). For all

Figure 1: 7-person, 14-day posters under various \(\). Algorithms parameters: potential function is negative entropy parameterized by \(=\); \(K=1.1/()\), \(=.01\), \(T=10^{4}\). Other settings follow Theorem 3.10. Results reported are averages of 50 runs. Strong duality holds due to linearity.

Figure 2: \(\) v.s.optimality gaps & constraint violations. More discussions in Appendix C.

curves, the lower the better. It is clear that our algorithms have significantly smaller optimality gaps at slightly higher constraint violations.

One may notice that the constant of \(K\) is 1.1 rather than 2 suggested by Theorem 3.10. This is the consequence of parameter tuning, and we show its impact in Figure 2 (right panel). Comparing the two plots in Figure 2, it is obvious that larger K_constant leads to conservative decisions: fewer constraint violations but higher optimality gaps. Moreover, when K_constant is 2, our algorithms achieve lower optimality gaps at the same level of constraint violations.

### Assignment problem

We next consider three large-scale assignment problems with \((m,n)\) = (8, 800), (15, 1500), (30, 3000), aiming to maximize aggregated utility by assigning at most one unit to each agent. The problem is modeled as \(\{_{i=1}^{n}_{i},_{i}:_{ i}_{m n}_{i} n;_{i}_{i},  i\}\) with \(_{i}:=\{_{i}^{n}:,_{i}  1\}\) being a unit simplex and \(_{m n}:=[_{m},,_{m}]\) being a consumption matrix concatenated from \(n/m\) identity matrices. Raw data of \(_{i}\) are available at . In this assignment problem, \(^{*}>0\) is strictly non-zero. We run experiments and report results in Table 3.

From the table, we observe MD_12 has lower gaps and reasonable constraint violations for small \(\); and MD_ne almost dominates others for large \(\). Both our algorithms outperform existing methods.

## 6 Discussion and conclusion

Limitation of our work.One significant limitation is the restriction of \(\{1,1/(n)\}\) to make the lower bound hold. However, we identify a promising direction to overcome this limitation in Appendix B.4. Once the limitation is overcame, the analysis may further uncover lower bounds on online cases , a long-standing open question in private online optimization .

In this work, we considered convex resource allocation problems under joint differential privacy. To solve the problem approximately, we proposed an algorithm Noisy Dual Mirror Descent, which privatizes dual variables of hard constraints, and then uses private dual variables to coordinate allocations. A significant merit of the algorithm is its ability to better leverage the geometric structure of the dual space; thus, it is provably near optimal for a large range of privacy parameters. There are many interesting directions for future study. For example, getting rid of the limitation discussed previously is a fruitful endeavour. Identifying a proper DP manner to tune the constant of \(K\) is of more practical interest.