# Fast T2T: Optimization Consistency Speeds Up Diffusion-Based Training-to-Testing Solving for Combinatorial Optimization

Fast T2T: Optimization Consistency Speeds Up Diffusion-Based Training-to-Testing Solving for Combinatorial Optimization

 Yang Li\({}^{1}\), Jinpei Guo\({}^{1}\), Runzhong Wang\({}^{2}\), Hongyuan Zha\({}^{3}\), Junchi Yan\({}^{1}\)

\({}^{1}\)Dept. of CSE & School of AI & MOE Key Lab of AI, Shanghai Jiao Tong University

\({}^{2}\)Massachusetts Institute of Technology

\({}^{3}\)The Chinese University of Hong Kong, Shenzhen

{yanglily,mike0728,yanjunchi}@sjtu.edu.cn

runzhong@mit.edu, zhahy@cuhk.edu.cn

Correspondence author. \(\) denotes equal contribution. This work was partly supported by NSFC (92370201, 62222607) and Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0102.

###### Abstract

Diffusion models have recently advanced Combinatorial Optimization (CO) as a powerful backbone for neural solvers. However, their iterative sampling process requiring denoising across multiple noise levels incurs substantial overhead. We propose to learn direct mappings from different noise levels to the optimal solution for a given instance, facilitating high-quality generation with minimal shots. This is achieved through an optimization consistency training protocol, which, for a given instance, minimizes the difference among samples originating from varying generative trajectories and time steps relative to the optimal solution. The proposed model enables fast single-step solution generation while retaining the option of multi-step sampling to trade for sampling quality, which offers a more effective and efficient alternative backbone for neural solvers. In addition, within the training-to-testing (T2T) framework, to bridge the gap between training on historical instances and solving new instances, we introduce a novel consistency-based gradient search scheme during the test stage, enabling more effective exploration of the solution space learned during training. It is achieved by updating the latent solution probabilities under objective gradient guidance during the alternation of noise injection and denoising steps. We refer to this model as Fast T2T. Extensive experiments on two popular tasks, the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS), demonstrate the superiority of Fast T2T regarding both solution quality and efficiency, even outperforming LKH given limited time budgets. Notably, Fast T2T with merely one-step generation and one-step gradient search can mostly outperform the SOTA diffusion-based counterparts that require hundreds of steps, while achieving tens of times speedup. The codes are publicly available at https://github.com/Thinklab-SJTU/Fast-T2T.

## 1 Introduction

Combinatorial Optimization (CO) problems, which involve optimizing discrete variables under given objectives, are essential in computer science and operational research. Due to the inherent computational difficulty, e.g. NP-hardness, solving efficiency poses significant challenges and requires exhaustive human efforts to design solving heuristics. Recent progress in this domain has shown promise in automatically learning heuristics with Machine Learning (ML) in a data-drivenmanner [1; 2; 3; 4; 5; 6; 7; 8], bringing practical advantages in both quality and speed, especially when the instances are within a certain domain. In addition, learning can help quickly uncover new heuristics for new problems or new instance distributions where experts are not there.

Learning-based solvers for CO typically employ neural networks to generate neural predictions for solution construction or search guidance, aiming to minimize either the objective score [2; 4; 5; 6; 9] or the deviation from reference solutions [10; 3; 11; 12; 13]. The problem-solving task places significant demands on the testing performance of the model, while optimizing the average performance across training data does not ensure optimal performance for every encountered test instance. Thus, methods [14; 15; 6; 8] have been proposed to perform tailored optimization on neural predictions for every testing instance. In particular, generative modeling like diffusion has shown promise in learning instance-conditioned quality solution distributions [7; 8] with robust expressive power to achieve state-of-the-art performance, which also provides more informative support for further exploitation like gradient search in the solving stage, which was previously proposed as the diffusion-based training-to-testing (T2T) framework . However, a major drawback of the diffusion backbone lies in its costly inference process, which necessitates tens or hundreds of denoising steps to solve one problem instance. This limitation in inference speed is crucial since CO seeks to achieve the highest solution quality within the shortest possible time, where both performance and efficiency are pivotal metrics in this pursuit. Although the diffusion solvers [7; 8] can exhibit superiority in inference speed compared to certain traditional methods and prior learning-based solvers, there remains substantial potential for speed enhancement, where bolstering this aspect could provide fundamental support and several-fold speedup for neural solvers based on generative modeling.

To resolve this issue, drawing inspiration from the successful practice of consistency models  for image generation, we propose the optimization consistency models to speed up the diffusion-based T2T framework, dubbed as Fast T2T, specifically for optimization problem-solving. We follow  to approach CO problems as conditional generation tasks, with the goal of modeling the distribution of high-quality solutions specific to given problem instances. As illustrated in Fig. 1, Fast T2T builds upon the methodology foundation of the discrete diffusion models [17; 18; 19] where a smooth transition from random uniform noise to the high-quality solution distribution is established. Given a problem instance, Fast T2T trains the conditional prediction consistency directly from varying noise levels to the solution distribution centered on the optimal solution to enable fast one-step solution distribution estimation. Meanwhile, to bridge the disparity between data-driven training and problem-solving, Fast T2T incorporates a novel objective gradient search for every instance in the testing phase based on the trained optimization consistency mappings.

Specifically, for the solving task, the model is expected to deliver the optimal solution output to the best extent possible for a given input instance. Thus, we define the optimization consistency property for the optimization scenario by conditional generation: _conditioned on a given instance \(G\), points on all trajectories of all noising steps consistently map to the optimal solution of \(G\)_. Compared to the diffusion prediction of the data distribution from noising step \(t\) to step \(t-1\), the consistency modeling enables generating solutions (\(_{0}\) in Fig. 1) from random noise vectors (\(_{T}\) in Fig. 1) by a single step of model inference. This is achieved by an optimization consistency training protocol that minimizes the difference among samples originating from varying trajectories and noising steps relative to the optimal solution. The model retains the capability for multi-step sampling to trade for sampling quality by alternating noise introduction on \(_{0}\) to generate a less noisy point \(_{t}\) and solution reconstruction to obtain a new \(_{0}\). Additionally, we design a novel objective gradient-based search

Figure 1: Optimization consistency models for CO solving where the model learns how to map from varying levels of noise to the solution distribution, conditioned on the problem graph instance.

on top of the learned consistency mapping to further explore the learned solution distribution for every test instance. We introduce instance-specific guidance from the objective to the learned solution prior \(p_{}(|G)\) and obtain the posterior \(p_{}(|y^{*},G)\) where \(y^{*}\) represents the optimal objective score given instance \(G\), thereby directing the sampling process to the optimal \(^{*}\). It specifically entails minimizing the free energy corresponding to the posterior by updating the probability parameters of intermediate noisy points through exponential gradient updates guided by the objective function during the alternation of noise injection and denoising steps.

We show the efficacy of Fast T2T on two typical CO problems for edge-decision and node-decision types respectively, i.e., Traveling Salesman Problem (TSP) and Maximum Independent Set (MIS). We show that Fast T2T, even with a single-step initial solution generation and a single-step gradient search, can mostly outperform the SOTA diffusion-based counterparts with hundreds of inference steps. Meanwhile, due to its reduced step requirement, Fast T2T naturally demands significantly less inference time to achieve comparable quality, with more steps for further enhancement.

The highlights of this paper include: **1)** We introduce the optimization consistency condition and establish Fast T2T based on the proposed optimization consistency models to facilitate fast high-quality CO solving, which offers a highly effective and efficient backbone for learning-based solvers. **2)** To complement the learned prior and bridge the disparity between data-driven training and the requirement of problem-solving, we introduce a novel gradient search with objective guidance based on consistency mappings to conduct a tailored search for every test instance. **3)** Extensive experiments show that Fast T2T exhibits strong performance superiority over existing SOTA neural solvers on benchmark datasets across various scales.

## 2 Related Work

**Machine Learning for Combinatorial Optimization.** Current learning-based CO solvers can be categorized into constructive approaches and improvement-based approaches. Constructive approaches refer to autoregressive methods [20; 2; 4; 21; 5] that directly construct solutions by sequentially determining decision variables until a complete solution is constructed, and non-autoregressive methods [3; 12; 22; 6; 7; 23] that predict soft-constrained solutions in one shot and then perform post-processing to achieve feasibility. Improvement-based solvers [24; 25; 26; 27; 28] learn to iteratively refine a solution through local search operators toward minimizing the optimization objective.

Generative modeling for CO has recently shown promise with its potent representational capabilities and informative distribution estimation. It models the problem-solving task as a conditional generation task for learning solution distributions conditioned on given instances [21; 29; 7; 30; 31; 8]. Drawing from diffusion models, DIFUSCO  has attained SOTA performance in solving TSP and MIS. Nonetheless, it does not incorporate any instance-specific search paradigms to fully capitalize on the estimated solution distribution. Addressing this limitation, the T2T framework  further introduces an objective-guided gradient search process during solving to leverage the learned distribution. However, every aspect of this system, including distribution learning and gradient search, hinges on the diffusion model for step-by-step generation. This reliance renders the diffusion-based approaches computationally inefficient and impedes further search computations to trade for solution quality.

**Diffusion Models and Consistency Models.** Diffusion models entail a dual process comprising noise injection and learnable denoising, wherein neural networks predict the data distribution at each step based on the data from the previous step. For Diffusion in continuous space [17; 32; 33; 34; 35; 36; 37], the solution trajectories can be modeled by Probability Flow ODE . Similar paradigms have also been adopted for discrete data using binomial or multinomial/categorical noises [17; 18; 19]. On top of the foundation of diffusion models, consistency models  define the self-consistency for every generation trajectory and introduce a consistency training paradigm for continuous data to directly learn the mappings from noise to the data. Inspired by this paradigm, we define the optimization consistency condition tailored for the optimization scenario, which requires consistency across multiple trajectories and time steps with the optimal solution as the target in a conditional context, thereby proposing the optimization consistency models as the solver embodiment. The models are employed on the discrete multinomial data for the benefit of CO.

[MISSING_PAGE_FAIL:4]

\(_{}\). In the optimization scenario of mapping instance \(G\) to approximate its optimal solution \(^{*}\), the generation process is conditioned on the problem instance \(G\) with a reference optimal solution \(^{*}\) serving as the commonly targeted initial point for all the conditional trajectories. Based on the discrete diffusion process with an explicit sampling process [18; 7; 8], we use the consistency function to estimate the optimal solution distribution as a point estimate \((-^{*})\) where \(()\) represents Dirac delta. Below defines optimization consistency for the conditional context of problem-solving.

**Definition 4.1** (Optimization Consistency).: Given a solution trajectory \(\{_{t}\}_{t[0,T]}\), we define the consistency function as \(f:(_{t},t,G)(-^{*})\), which maintains the optimization consistency property: conditioned on instance \(G\), all points along any trajectory map to its optimal solution, i.e., \(f_{}(_{t}^{i},t,G)=f_{}(_{t^{}}^{j},t^{ },G)=(-^{*})\) for distinct trajectories \(i\) and \(j\) at distinct steps \(t\) and \(t^{}\).

As illustrated in Fig. 2, the goal of the consistency model \(f_{}\) in the optimization context, is to estimate the consistency function from data by learning to enforce optimization consistency. To achieve such consistency in the context of optimization to learn \(f:G^{*}\), given its nature as a conditional generation and the aim for an explicit optimal solution \(^{*}\), we can seamlessly integrate \(^{*}\) into the objective function for smooth training. Instead of optimizing the expectation of the variation of the consistency mappings over two noise points \(\) and \(^{}\), i.e., \(_{}()=df_{}(,t,G)\,,f_{}(^{},t^{},G)\), we introduce \(^{*}\) to optimize the upper bound of \(_{}\) through triangle inequality of distance measures as

\[_{}()=df_{}( ,t,G),(-^{*})+df_{}( ^{},t^{},G),(-^{*}) _{}().\] (3)

Here \(d(,)\) is a distance metric function. In this case, the boundary conditions become less significant, since we have already dispersed the information of \(^{*}\) across all noise time steps. Therefore, we can directly utilize the neural network \(\) to estimate the consistency function \(f_{}(,,)\). In addition, all learned trajectories are expected to map to the optimal solution \(^{*}\) given the instance \(G\), and the estimated solution distribution is expected to center on \(^{*}\). This calls for the requirement of consistency extending across all trajectories, rather than being confined within a single trajectory.

**Definition 4.2**.: The optimization consistency loss for conditional problem-solving is defined as:

\[_{}^{N_{t}}():=[(t_{n}) (d(f_{}(_{t_{n}}^{i},t_{n},G),(- ^{*}))+d(f_{}(_{t_{n+1}}^{j},t_{n+1},G), (-^{*})))]\] (4)

where the expectation is taken with respect to \(G p_{G}\), \(n[1,N_{t}-1]\), \(_{t_{n}}^{i}(_{t_{n}};=^{*}}_{t_{n}})\), and \(_{t_{n+1}}^{j}(_{t_{n+1}};= ^{*}}_{t_{n+1}})\). Here \([1,N_{t}-1]\) denotes the uniform distribution over \(\{1,2,,N-1\}\), \(()^{+}\) is a positive weighting function.

Since the model outputs \(N\) Bernoulli distributions as the distribution of \(_{0}\), we adopt the binary cross entropy to measure the distance between the estimation \(p_{}()\) and \((-^{*})\). We set \((t_{n}) 1\) and discover a decent empirical performance. \(_{t_{n}}^{i}\) and \(_{t_{n+1}}^{j}\) are identically and independently sampled from different noise trajectories, in comparison to \(_{t_{n}}^{i}(_{t_{n}};=^{*}}_{t_{n}}),_{t_{n+1}}^{i}( _{t_{n+1}};=_{t_{n}}_{t_{n}+1} _{t_{n+1}})\) where \(_{t_{n}}^{i}\) and \(_{t_{n+1}}^{i}\) are from the same trajectory. Since very close \(t_{n}\) and \(t_{n+1}\) would make Eq. 4.2 very easy to learn, we resched the time horizon into \(N_{t}-1\) sub-intervals \(t_{1}=1<t_{2}<<t_{N_{t}}=T\) through the cosine denoising schedular such that \(t_{i}=() T\) following DDIM . This training procedure enforces the model to learn

Figure 2: Vannila consistency models are trained to map points on any trajectory to its origin. Optimization consistency enforces that all trajectories conditioned on \(G\) consistently map to the same initial point, i.e., the optimal solution of \(G\).

conditional consistency across different noise steps to consistently map to the optimal solution \(^{*}\) of the given condition \(G\). Note that although we enforce the noise to map to the Dirac delta on \(^{*}\), the generative modeling process with a single sample per instance condition during training still enables the model to estimate a solution distribution (centering around the optimal solution) to enjoy diversity to enhance performance via parallel sampling, as evidenced by the experiments in Table. 2.

Specifically for implementation, the network \(\) is embodied as an anisotropic graph neural network with edge gating mechanisms , and instance \(G\) serves as a part of the conditional input as the node or edge features. For TSP, the 2D coordinates of the vertices serve as the instance condition, and the input edge features are from the embeddings of entries in \(_{t}\) integrated with the embedding of the input time step \(t\). For MIS, the edges \(E\) serve as the instance condition and the node embeddings are from \(_{t}\) to collectively form the input. After the GNN iterations, the features of the decision variables (edges for TSP and nodes for MIS) are projected to 2-D outputs \(p_{}(_{0}|_{t},G)^{N 2}\) featuring \(N\) Bernoulli distributions for \(N\) entries in \(_{0}\) via a linear layer followed by a Softmax layer.

## 5 Testing-Stage Problem Solving via Consistency-Based Gradient Search

The solving involves obtaining the initial solution from the raw consistency sampling process and a consistency-based gradient search process with objective feedback for iterative solution improvement.

### Consistency Sampling for Initial Solutions

With a well-trained \(f_{}(,,)\), we generate solutions for a given instance \(G\) by sampling \(_{T}\) from the uniform distribution and then evaluate it for \(_{0} p_{}(_{0})=f_{}(_{T},T,G)\). This process requires only one forward pass through the consistency model, resulting in sampling in a single step. Solution sampling with multiple steps of inferences can also be accomplished via alternating denoising and noise injection, allowing trading runtime for improved solving quality. Given a sequence of time points \(_{1}>_{2}>>_{N_{}-1}\), in time step \(_{n}\), the multi-step sampling process adds noise to the \(_{0}\) obtained from the last step \(_{n-1}\) by \(_{_{n}}(_{_{n}};=}_{_{n}})\), then denoise to find the new solution by \(_{0} f_{}(_{_{n}},_{n},G)\), as shown in Algorithm. 1.

``` Input: Consistency model \(f_{}(,,)\), graph problem instance \(G\), sequence of time points \(_{1}>_{2}>>_{N_{}-1}\)  Sample \(_{T}\) from uniform distribution \(\) \(p_{}(_{0}|G) f_{}(_{T},T,G)\) \(_{0} p_{}(_{0}|G)\) for\(n=1\) to \(N_{}-1\)do  Sample \(_{_{n}}(_{_{n}};= _{0}}_{_{n}})\) \(p_{}(_{0}|G) f_{}(_{_{n}},_{ n},G)\) \(_{0} p_{}(_{0}|G)\) endfor Output: Solution \(_{0}\) ```

**Algorithm 1** Multistep Consistency Sampling

### Consistency-based Gradient Search with Objective Feedback

For CO, the integration of objective optimization facilitates direct engagement with the objective and enables efficient exploration of the solution space to minimize the score.  has established such a procedure for the step-by-step denoising function, yet it is not transferable to the consistency function, and incorporating objective optimization may prove more challenging as the consistency function maps across longer distance time steps. With the learned conditional solution prior \(p_{}(|G)\), this section aims to introduce a constraint \(c(,y^{*}|G)\) on \(\) to this prior for inference, where \(y^{*}\) represents the optimal objective score given the instance \(G\). That is, we want to find an approximation to the posterior distribution \(p_{}(|y^{*},G) p_{}(|G)c(,y^ {*}|G)\) to guide the sampling process to the optimal \(^{*}\).

Here we follow  to determine \(c(,y^{*}|G)\) by utilizing energy-based modeling  with the energy function \(E(y,,G)=|y-l(;G)|\), which quantifies the compatibility between \(y\) and \((,G)\), and it reaches zero when \(y\) is exactly the objective score of \(\) with respect to \(G\). Such a design enables the best \(y\) matching the inputs to maintain the highest probability density and the probability density is positively correlated with the matching degree. Then we employ the _Gibbs distribution_ to characterize the probability distribution over a collection of arbitrary energies:

\[c(,y|G)=,G))}{_{y^{}}(-E(y^{ },,G))}=Z(-|y-l(;G)|)\] (5)Following , we introduce an approximate variational posterior \(q(|G)\) and the free energy

\[F=_{q(|G)q(|,G)}[ p _{}(,|G)- q()q(|,G )]}_{F_{1}}-_{q(|G)}[ c( ,y^{*}|G)]}_{F_{2}}\] (6)

is minimized when \((q(|G)\|p_{}(|y^{*},G))\) is minimized. Here \(=_{1},,_{T}\) represent the latent variables. Through the diffusion process, we can obtain \(q(|)=_{t=1}^{T}q(_{t}|_{t-1})\). We apply an approximation to the posterior over \(=_{0}\) as a point estimate \(q(|G)=(-)\). \(F_{1}\) aligns with the objective of the consistency and diffusion models and \(F_{2}\) can be transformed using Eq. 5:

\[F_{1}=_{q(|,G)}[|,G)}{p_{}(,|G)}]  F_{2}=- c(,y^{*}|G)=l(;G)- Z-y^{*}.\] (7)

Initializing \(\) from Sec. 5.1, we aim to update \(\) to reach conditional solution distribution \(p_{}(|y^{*},G)\) through exponential gradient decent on the latent continuous probability \(_{}=p(_{ T})=}_{ T}^{N 2}\) at each iteration minimizing \(F_{1}\) and \(F_{2}\). Here \(_{}\) parameterizes \(N\) Bernoulli distributions and \(\) serves as a hyperparameter to control the noise degree. We view \(_{}\) as the expectation of \(_{ T}\) over \(_{}\), i.e., \(_{_{}}(_{ T})=_{ }\), since \(_{}\) is a multivariate Bernoulli. To obtain reliable gradients on \(_{}\), we estimate the expected distribution of \(_{0}\) by \(f_{}(_{}, T,G)\). Note \(F_{1}\) is exactly the (implicit) objective of the diffusion and consistency models, i.e., the variational upper bound of the negative log-likelihood with the targeted data \(\), which we optimize by minimizing the consistency over the re-predicted solutions \(df_{}(_{}, T,G),(- )\). While \(F_{2}\) can be optimized by minimizing \(lf_{}(_{}, T,G);G+( _{})\), where the objectives are defined following  as \(l_{}(;G)-_{1 i N}_{i}+ _{(i,j) E}_{i}_{j}\) and \(l_{}= D\) where \(D_{+}^{n n}\) denotes the distance matrix.

In each iteration, with current \(\), we obtain \(_{}=}_{ T}\), \(p_{}()=f_{}(_{}, T,G)\) and update \(_{}\) by

\[_{}_{}- _{_{}}_{1} d_{p_ {}()},(- {})+_{2} l_{p_{}( )};G}\] (8)

where \(_{1},_{2}\) are weighting hyperparameters. Then we sample \(_{ T}_{}\) and reconstruct a new distribution estimate of \(\) by \(p^{}_{}()=f_{}(_{ T}, T,G)\). To guarantee the feasibility, we utilize the logits of \(p_{}()\) and \(p^{}_{}()\) to produce the heatmaps where each element denotes each edge/node's confidence to be selected, and then adopt post-processing2 to obtain two feasible solutions. This iteration concludes by outputting the lower-cost solution as \(\).

## 6 Experiments

We test on two CO problems, TSP and MIS. The comparison includes SOTA learning-based solvers, heuristics, and exact solvers for each problem. To configure the generative-based models, we adopt \(_{}\) and \(_{}\) to represent the number of inference steps in initial solution sampling and the number of gradient search steps, respectively. For diffusion-based baselines including DIFUSCO  and T2T , we adopt \(_{}\)=50 and involve 3 iterations with 5 guided denoising steps per iteration for T2T's gradient search, i.e., \(_{}\)=15. Fast T2T can achieve promising results with merely one-step initial solution sampling and one-step gradient search, i.e., \(_{}\)=1 and \(_{}\)=1. However, the affordability of model inference facilitates a more extensive exploration of the solution distribution through a thorough search.

### Experiments for TSP

**Datasets.** A TSP instance includes \(N\)\(2\)-D coordinates and a reference solution obtained by heuristics. Training and testing instances are generated via uniformly sampling \(N\) nodes from the unit square \(^{2}\), which is a standard procedure as adopted in [2; 21; 3; 48; 6; 7; 8]. We experiment on various problem scales including TSP-50, 100, 500, and 1000.

**Metrics.** Following [2; 3; 6; 7; 8], we adopt three evaluation metrics: 1) Length: the average total distance or cost of the solved tours w.r.t. the corresponding instances, as directly corresponds to the objective. 2) Drop: the relative performance drop w.r.t. length compared to the global optimality or the reference solution; 3) Time: the average computational time to solve the problems.

**Results for TSP-50/1000.** Given the recent success of learning-based solvers in achieving near-optimal performance on small-scale problems, we follow  to assess methods within the naive greedy decoding setting, aiming for a more discernable evaluation. The comparison includes state-of-the-art learning-based methods with greedy decoding and traditional solvers. Hyperparameter \(\) is set as \(0.2\). The sampling steps and gradient search steps are explicitly marked. Table. 1 shows that Fast T2T with merely one-step sampling steps approximates diffusion-based solvers with 100 sampling steps with a slight average performance gain of **5.7%**, yet with an average speedup of **82.8x**. A similar conclusion can be made for methods with gradient search with an average performance gain of **4.5%** and speedup of **35.4x**. Fast T2T variants with more sampling and gradient search steps achieve **82.1%** performance gain with **14.7x** speedup compared to previous state-of-the-art diffusion-based counterparts.

**Results for TSP-500/1000.** Learning-based solvers are compared using greedy decoding and sampling decoding (\(\) 4), i.e., sampling multiple solutions and reporting the best one. Hyperparameter \(\) is set as \(0.2\). The sampling steps and gradient search steps are explicitly marked. Table. 2 shows that Fast T2T with merely one-step sampling steps averagely outperforms diffusion-based solvers with 100 sampling steps by a performance gain of **10.1%** and a speedup of **16.8x**. A similar conclusion can be made for methods with gradient search with an average performance gain of **14.9%** and a speedup of **8.5x**. Fast T2T variants with more sampling and gradient search steps achieve **52.1%** performance gain with **7.4x** speedup compared to previous SOTA diffusion-based counterparts.

**Results for Generalization.** Based on the problem set {TSP-50, TSP-100, TSP-500, TSP-1000}, we train the model on a specific problem scale and then evaluate it on all problem scales. Table 3 presents the generalization results of Fast T2T compared with diffusion-based counterparts with greedy decoding. The results show the satisfying cross-domain generalization ability of Fast T2T, e.g., the model trained on TSP-1000 achieves less than a 0.6% optimality gap on all other problem scales.

**Soving Time vs. Optimality Drop on TSP-100/1000.** Fig. 3 and Fig. 4 illustrate the solving progress via the runtime-drop curves of Fast T2T and the prominent mathematical solver LKH3 . The comparison is conducted on TSP-100 and TSP-1000. We are excited to discover that Fast T2T surpasses LKH3 in the early solving stage while also performing comparably in the later stage. This suggests that Fast T2T can serve as an effective rapid solver for approximate solutions outperforming

    &  &  &  \\   & & Length1 & Drop1 & Time & Length1 & Drop2 & Time \\  Concorde  & Exact & 5.69 & 0.00\% & (3m) & 7.76 & 0.00\% & (12m) \\ LKH3  & Heuristics & 5.69 & 0.00\% & (3m) & 7.76 & 0.00\% & (33m) \\
2Opt  & Heuristics & 5.86 & 2.95\% & – & 8.03 & 3.54\% & – \\  AM  & RL+G & 5.80 & 1.76\% & (2s) & 8.12 & 4.53\% & (6s) \\ GCN  & SL+G & 5.87 & 3.10\% & (55k) & 8.41 & 8.38\% & (6m) \\ Transformer  & RL+G & 5.71 & 0.31\% & (14s) & 7.88 & 1.42\% & (5s) \\ POMO\({}^{*}\) & RL+G & 5.73 & 0.64\% & (13s) & 7.84 & 1.07\% & (2s) \\ Sym-NCO\({}^{*}\) & RL+G & – & – & – & 7.84 & 0.94\% & (2s) \\ Image Diffusion  & SL+G & 5.76 & 1.23\% & – & 7.92 & 2.11\% & – \\  DIFNCO (T,n+1)  & SL+G & 6.42 & 12.84\% & (16s) & 9.32 & 20.20\% & (20s) \\ DIFNCO (T,n+50)  & SL+G & 5.71 & 0.43\% & (9m) & 7.85 & 1.21\% & (9m) \\ DIFNCO (T,n+100)  & SL+G & 5.71 & 0.41\% & (18m) & 7.84 & 1.16\% & (18m) \\ Fast T2T (T,n+1)  & SL+G & 5.71 & 0.31\% & (**11s)** & 7.86 & 1.31\% & (**16s**) \\ Fast T2T (T,n+3)  & SL+G & 5.69 & 0.05\% & (25s) & 7.77 & 0.17\% & (33s) \\ Fast T2T (T,n+5)  & SL+G & **5.69** & **0.02\%** & (1m) & **7.76** & **0.07\%** & (1m) \\ T2T (T,n+1,n+1)  & SL+G & 6.15 & 5.1\% & (55s) & 9.00 & 16.0\% & (**1m)** \\ T2T (T,n+5,n+1)  & SL+G & 5.69 & 0.07\% & (18m) & 7.77 & 0.20\% & (18m) \\ T2T (T,n+5,n+1)  & SL+G & 5.69 & 0.03\% & (26m) & 7.76 & 0.11\% & (42m) \\ Fast T2T (T,n+1,n+1)  & SL+G & 5.69 & 0.03\% & (**54s)** & 7.76 & 0.10\% & (**1m)** \\ Fast T2T (T,n+2,n+2)  & SL+G & 5.69 & 0.02\% & (2m) & 7.76 & 0.04\% & (2m) \\ Fast T2T (T,n+3,n+3) & SL+G & **5.69** & **0.01\%** & (3m) & **7.76** & **0.03\%** & (3m) \\   

Table 1: Results with **Greedy Decoding** on TSP-50 and TSP-100. RL: Reinforcement Learning, SL: Supervised Learning, G: Greedy Decoding. \({}^{*}\) denotes results that are quoted from previous works.

   } \\   & **Image** & **TS-50** & **TS-100** & **TS-500** & **TS-100** \\   & DBLNCO(T,G,Net)  & 5.60\%,005 & 5.70\%,053 & 5.82\%,258 & 5.84\%,217\% \\  & T2TT (T,n+5,n+1)  & 5.60\%,005 & 5.70\%,013 & 5.71\%,109 & 5.71\%,109 \\  & Fast T2T (T,n+5,n+1)  & 5.60\%,005 & 5.80\%,012 & 5.70\%,005 & 5.71\%,102 \\  & Fast T2T (T,n+5,n+1)  & 5.60\%,005 & **5.60\%,012 & **5.71\%,012** & **5.73\%,019** \\  & Fast T2T (T,n+5,n+1)  & 5.60\%,005 & **5.60\%,013 & **5.71\%,012** & **5.73\%,019** \\  & Fast T2T (T,n+5,n+1)  & 5.60\%,005 & **5.60\%,014 & **5.71\%,012** & **5.73\%,018** \\   & DBLNCO(T,Net)  & 5.60\%,005 & 5.70\%,029 & 5.80\%,012 & 5.60\%,013 \\  & Fast T2T (T,n+5,n+1)  & 5.60\%,005 & 5.77\%,003 & 7.95\%,247 & 7.91\%,104 \\  & Fast T2T (T,n+5,n+1)  & 5.73\%,005 & 7.70\%,003 & 7.90\%,004 & 7.80\%,053 \\  & Fast T2T (T,n+5,n+1)  & **5.73\%,005 & **7.87\%,007 & **7.57\%,029** & **7.78\%,034** \\  & Fast T2T (T,n+5,n+1)  & **5.76\%,005 & **7.87\%,004 & **7.57\%,029** & **7.78\%,034** \\   & DBLNCO(T,Net)  & 12.84\%,448 & 12.78\%,467 & 86.77\%,005 & **16.86\%,185** \\  & Fast T2T (T,n+5,n+1)  & 12.88\%,448 & 12.82\%,467 & 86.0\%,097 & 16.7\%,128

[MISSING_PAGE_FAIL:9]

counterparts with approximately 100 sampling steps by a slight performance gain of **2.5%** and a speedup of **26.3x**. Fast T2T variants with more sampling and gradient search steps achieve **23.7%** performance gain with **9.1x** speedup compared to previous SOTA diffusion-based counterparts.

## 7 Conclusion

We introduce optimization consistency on top of the diffusion-based training-to-testing solving framework for efficient and effective combinatorial optimization solving. Our proposed model facilitates rapid single-step solving, demonstrating comparable or superior performance to SOTA diffusion-based counterparts, offering a more effective and efficient alternative backbone for neural solvers. In addition, a novel consistency-based gradient search scheme is introduced to further complement the generalization capability during solving. Experimental results on TSP and MIS datasets showcase the superiority of our methods, exhibiting significant performance gains in both solution quality and speed compared to previous state-of-the-art neural solvers. Furthermore, our approach demonstrates superiority over LKH3 in the early stages of solving.