# Soft Matching Distance: A metric on neural representations that captures single-neuron tuning

Meenakshi Khosla

McGovern Institute for Brain Research

Massachusetts Institute for Technology

mkhosla@mit.edu

&Alex H. Williams

Center for Neural Science, New York University

Center for Computational Neuroscience

Flatiron Institute

alex.h.williams@nyu.edu

###### Abstract

Common measures of neural representational (dis)similarity are designed to be insensitive to rotations and reflections of the neural activation space. Motivated by the premise that the tuning of individual units may be important, there has been recent interest in developing stricter notions of representational (dis)similarity that require neurons to be individually matched across networks. When two networks have the same size (i.e. same number of neurons), a distance metric can be formulated by optimizing over neuron index permutations to maximize tuning curve alignment. However, it is not clear how to generalize this metric to measure distances between networks with different sizes. Here, we leverage a connection to optimal transport theory to derive a natural generalization based on "soft" permutations. The resulting metric is symmetric, satisfies the triangle inequality, and can be interpreted as a Wasserstein distance between two empirical distributions. Further, our proposed metric avoids counter-intuitive outcomes suffered by alternative approaches, and captures complementary geometric insights into neural representations that are entirely missed by rotation-invariant metrics.

## 1 Introduction

Neural representations of stimuli and actions are often described in terms of "tuning curves" of individual neurons. The most classic example is work by Hubel and Wiesel , which found that neurons in the primary visual cortex (V1) of cats were selectively responsive--i.e. "tuned"--to edges with particular orientations. However, the utility of tuning curves is less certain in higher-order brain regions involved in navigation, decision-making, and complex sensory processing. In such areas, neurons often exhibit complex "mixed selectivity" to multiple sensory or task features . Neuroscientists recurrently debate whether tuning curves are meaningful in these situations, and similar debates have recently arisen in the interpretable artificial intelligence community .

The tuning of individual neurons is closely connected to studies of neural geometry . In particular, neural tuning curves determine the geometry of population-level neural representations, but the same geometry can be produced by many different sets of tuning curves (Fig. 1A-D). Despite this connection, most investigations implicitly ignore tuning by considering rotation-invariant quantities. Indeed, popular measures of representational (dis)similarity between neural networks--centered kernel alignment (CKA; ), canonical correlations analysis (CCA; ), representational similarity analysis (RSA; ), and Procrustes shape distance --are all invariant to rotations of the neural activation space (such as Fig. 1B vs. 1C). Thus, to study the importance of individual neural tuning (or lack thereof) we require complementary metrics that are sensitive to rotations, but still invariantto permutations of the neuron indices (since such indices are often arbitrary). While a handful of studies have already explored measures that fit these requirements [14; 13], our understanding of these methods and their relation to the more popular approaches cited above is under-developed.

For example, Williams et al.  proposed a rotation-sensitive, permutation-invariant metric on neural representations based on "permutation Procrustes" analysis . However, their approach suffers a serious limitation--it can only be applied to pairs of networks with the same number of neurons since it relies on a strict one-to-one matching between units. The central contribution of our work is to generalize their metric to the much more typical case of unequal network sizes, which we achieve by leveraging elementary principles from optimal transport theory  to obtain a _soft matching_ or _soft assignment_ between two sets of tuning curves (Fig. 1E). Similar approaches have been used for representation transfer in deep networks [18; 19] and to align word embeddings [20; 21]. Our central motivation--to quantify the reproducibility of tuning curves across networks--is distinct from these prior works, and the details of our approach are suitably adapted where necessary.

Importantly, our approach preserves appealing metric space properties of Williams et al.'s  method. Furthermore, we will see that alternative rotation-sensitive measures based on rectangular assignment algorithms  and semi-matching  can produce unintuitive outcomes that our approach avoids. Finally, we leverage our metric to show that the tuning of individual units is preserved above chance levels in deep layers of artificial and biological networks. Thus, we present a quantitative approach to adjudicate between the competing hypotheses that "tuning matters" vs. "geometry is all you need" , and we provide some emprical evidence in favor of the former hypothesis.

## 2 Methods

We use \((N)\) and \((N)\) to respectively denote the set of \(N N\) orthogonal matrices and \(N N\) permutation matrices. These are commonly referred to as the _orthogonal group_ and _permutation group_, respectively. The permutation group is formally defined as follows:

\[(N)=\{^{N N}\ |\ _{i}P_{ij}=1&\,j\{1 N\}\\ _{j}P_{ij}=1&\,i\{1 N\}\\ P_{ij}\{0,1\}&\,i,j\{1 N\}\{1 N\} \} \]

In words, a "permutation matrix" is a square matrix defined by containing only zeros and ones, and having each row and column sum to one. For any \((N)\) and \(^{N}\), the matrix-vector multiplication \(\) outputs a vector with permuted elements. It is easy to check that every permutation matrix is orthogonal, \(^{}=^{}=\). In other words, \((N)\) is a subset of \((N)\).

Essential to our approach is the relationship between permutation matrices and the set of _doubly stochastic matrices_. A doubly stochastic matrix is any square, nonnegative matrix whose rows and columns sum to one. The set of doubly stochastic matrices forms a polytope, known as the _Birkoff

Figure 1: **(A)** Example tuning curves from 3 neurons over a 1D stimulus space. **(B)** Manifold (black curve) arising from tuning curves from panel A in 3D neural firing rate space. Each coordinate axis encodes a single-neural firing rate, colored as in panel A. **(C)** A rotated manifold with the same shape as panel B. **(D)** Tuning curves associated with the rotated manifold in panel C (compare with panel A). **(E)** Schematic illustration of “soft matching.” Grayscale lines show matched similar tuning curves across two networks. The darkness of the line indicates the strength of the match.

_polytope_. We denote the \(N\)-dimensional Birkhoff polytope as \((N)\), formally:

\[(N)=\{_{i}P_{ij}=1&\,j\{1  N\}\\ _{j}P_{ij}=1&\,i\{1 N\}\\ P_{ij} 0&\,i,j\{1 N\}\{1 N\}\} \]

The Birkoff polytope is a convex set. That is, for any two doubly stochastic matrices \(_{1}(N)\) and \(_{2}(N)\), we can define \(_{3}=_{1}+(1-)_{2}\) for arbitrary \(0 1\), and be guaranteed that \(_{3}(N)\). The celebrated _Birkhoff-von Neumann theorem_ states that the vertices of \((N)\) are one-to-one with \((N)\), and this relationship will play an important role in our story.

Finally, we will be interested in generalizing the Birkhoff polytope to rectangular matrices, as this will help us generalize permutations to "soft permutations." Specifically, consider a nonnegative matrix \(^{N_{x} N_{y}}\) whose rows each sum to \(1/N_{x}\) and whose columns each sum to \(1/N_{y}\). Thus, the sum of all entries is equal to one. The set of all such matrices defines a _transportation polytope_; we denote this set as \((N_{x},N_{y})\) and define it formally:

\[(N_{x},N_{y})=\{^{N_{ x} N_{y}}&|_{i}P_{ij}=1/N_{y}&\,j\{1  N_{y}\}\\ _{j}P_{ij}=1/N_{x}&\,i\{1 N_{x}\}\\ P_{ij} 0&\,i,j\{1 N_{x}\}\{1 N_{y}\} .\} \]

Note that when \(N=N_{x}=N_{y}\), all rows and columns sum to \(1/N\). Thus, for any \((N)\) we have that \((1/N)(N,N)\). In other words, except for a minor re-scaling factor, the Birkhoff polytope is a special case of the transportation polytope we defined.

### Problem Setup and Procrustes Distance

To study the problem of comparing neural activations from different networks, we adopt a similar setting described in prior works (e.g. ). Specifically, neural population response vectors are sampled from two networks over a set of \(M\) stimulus inputs. We collect these responses into two matrices \(^{M N_{x}}\) and \(^{M N_{y}}\), where \(N_{x}\) and \(N_{y}\) denote the respective number of neurons in each network. Our goal is to come up with methods to quantify the (dis)similiarity between \(\) and \(\) while ignoring nuisance transformations. For example, CKA  and Procrustes shape distance  are invariant to translations, isotropic scalings, rotations, and reflections as nuisance transformations. Other measures based on linear regression , partial least squares , and CCA  are invariant to a broader class of nuisance transformations: namely, invertible affine transformations within linear subspaces that account for a high fraction of (co)variance.

Consider the Procrustes shape distance as a concrete example. For convenience, we assume that \(\) and \(\) have been pre-processed so that their columns sum to zero and \(\|\|_{F}=\|\|_{F}=1\). Such pre-processing is necessary to remove the effects of translations and isotropic rescalings. Assuming this pre-processing has been imposed and the two networks have the same number of neurons (i.e. \(N=N_{x}=N_{y}\)), then the Procrustes distance, which we denote \(d_{}\), can be defined as:

\[d_{}(,)=_{(N)}\|- \|_{F} \]

Intuitively, the Procrustes distance is the minimal Euclidean distance between between \(\) and \(\) after optimizing over an orthogonal \(N N\) alignment matrix \(\). Thus, it is easy to see that the distance is invariant to rotations and reflections of the neural responses in \(N\)-dimensional space. Due to this appealing geometric interpretation, eq. (4) is probably the most common definition of Procrustes distance. However, this definition does not apply when \(N_{x} N_{y}\) since it would require us to subtract two matrices with different numbers of columns. To remedy this, Williams et al.  suggested that \(\) and \(\) could be embedded into the same dimension by principal components analysis or zero-padding. A more elegant solution is to simply define the Procrustes distance in the following manner, which is valid for \(N_{x} N_{y}\):

\[d_{}(,)=[^{}]+ [^{}]-2\|^{}\|_{*}} \]

where \(\|\|_{*}\) denotes the nuclear norm, or Schatten 1-norm, which is equal to the sum of the singular values of the matrix \(\). Importantly, eqs. (4) and (5) are equivalent when \(N_{x}=N_{y}\). This fact is well-established, but we provide a self-contained proof in Supplement A.1 for convenience.

An appealing property of the Procrustes distance is that it defines a _metric space_. More formally, given a class of nuisance transformations \(\), a distance function \(d\) defines a metric space over equivalence classes associated to \(\) if it satisfies:

\[d(,) =0f=f() \] \[d(,) =d(,)\] (7) \[d(,)  d(,)+d(,) \]

for any \(^{M N_{x}}\), \(^{M N_{y}}\), \(^{M N_{x}}\). It can be shown that Procrustes distance satisfies these properties, with \(\) corresponding to the set of translations, isotropic scalings, rotations, and reflections .

### One-to-One Matching Distance

The purpose of this paper is to investigate alternative metrics that are not invariant to general orthogonal transformations (like Procrustes distance), but are still invariant to permutations of the neuron indices. This is motivated by the hypothesis that neurons are usually arbitrarily indexed, but the tuning of individual units may be reproducible across networks.

When comparing networks with the same number of neurons (\(N_{x}=N_{y}=N\)), there is a natural generalization Procrustes distance which we call the _one-to-one matching distance_ (Fig. 2A):

\[d_{}(,)=_{(N)}\|- \|_{F} \]

The only difference with Procrustes distance is that the minimization is performed over the group of \(N\)-dimensional permutation matrices, \((N)\), instead of \(N\)-dimensional orthogonal matrices, \((N)\). Others have referred to this quantity as the "permutation Procrustes" problem . But we prefer one-to-one matching distance to avoid confusion between the two. Like the Procrustes distance, the one-to-one matching distance is symmetric and satisfies the triangle inequality (see, e.g., ).

It is well-known, although not immediately obvious, that the optimal permutation can be efficiently found. Indeed, a brute-force enumeration of all \(N!\) permutation matrices is impossible for even moderately sized networks, but one can show (see Supplement A.2) that eq. (9) is equivalent to:

\[d_{}(,)=(N)}_{i,j} _{ij}\|_{i}-_{j}\|_{2}^{2}} \]

where the minimization is performed subject to the constraint that \(\) is in the Birkhoff polytope, \((N)\), defined in eq. (2). Above, \(\|_{i}-_{j}\|_{2}^{2}\) denotes the squared Euclidean distance between column \(i\) of \(\) and column \(j\) of \(\). In other words, \(\|_{i}-_{j}\|_{2}^{2}\) is a measure of distance between a tuning curve \(i\) from network \(\) and tuning curve \(j\) from network \(\).

To build intuition for eq. (10), we offer the following interpretation as a "transportation problem." Specifically, suppose we have \(N\) "sender warehouses" at locations \(\{_{1},,_{N}\}\), each with one unit of raw material. We would like to transport all of our material to a set of "receiver warehouses"

Figure 2: **(A) One-to-one matching distance, schematized as alignment of \(M\) points in \(N\)-dimensional space by optimally permuting coordinate axes. Colors denote landmark labels (e.g. image labels) that are common across the two networks. (B) Dual perspective of one-to-one matching distance, schematized as matching of \(N\) unlabelled points in \(M\)-dimensional space. (C) Soft matching distance generalizes the picture in panel B, and can be viewed as an optimal transport distance (see main text).**

\(\{_{1},,_{N}\}\) as cheaply as possible, where \(\|_{i}-_{j}\|_{2}^{2}\) quantifies the cost of transporting one unit of material from warehouse \(i\) to warehouse \(j\). Any sender warehouse can split its supply amongst multiple receivers, so long as every sender releases all of its supply, \(_{j}_{ij}=1\) for all \(i\), and every receiver ends with exactly one unit of supply, \(_{i}_{ij}=1\) for all \(j\). The Birkhoff polytope \((N)\) represents the set of all valid transportation plans within these constraints. Except in degenerate cases, there is a unique optimum and it is somewhat intuitive that the best strategy forgoes the option to split supplies, and instead finds a one-to-one matching of sender-receiver pairs. That is, the solution will be found at a vertex of the Birkhoff polytope, and therefore be a permutation matrix due to the Birkhoff-von Neumann theorem. Figure 2B provides a schematic illustration of this "dual" view of the one-to-one matching distance (compare with Fig. 2A). Equation (9) can be efficiently computed by linear programming solvers as well as many specialized polynomial-time algorithms  (see A.4).

### Soft Matching Distance

The one-to-one matching distance (eqns. 9,10) is not applicable when \(N_{x} N_{y}\), which crucially limits its utility. In analogy to how eq. (5) adapted the Procrustes distance to handle unequal network sizes, we now seek a similar generalization of the one-to-one matching distance. A natural way to do this is to modify the constraints of the minimization in eq. (10), to obtain:

\[d_{}(,)=(N_{x},N_{y})} \ _{ij}_{ij}\|_{i}-_{j}\|^{2}} \]

where \((N_{x},N_{y})\) is the transportation polytope defined in eq. (3). The idea is that the transportation and Birkhoff polytopes are essentially equivalent when \(N=N_{x}=N_{y}\), except for a minor re-scaling factor. In particular, it is easy to verify that \(d_{}(,)= d_{}(,)\) when \(N_{x}=N_{y}=N\). That is, when comparing two networks of equal size, the soft matching distance is equal to the one-to-one matching distance except for a constant factor of \(\).

Equation (11) involves "soft matching" neuron labels in the sense that every row and every column of the optimal \(\) may have more than one non-zero element. We can again interpret eq. (11) as a transportation problem. In this scenario, we have \(N_{x}\) sender warehouses, each with \(1/N_{x}\) units of material, and \(N_{y}\) receiver warehouses, each requiring \(1/N_{y}\) units. The set of candidate solutions (i.e. feasible transport plans) is given by \((N_{x},N_{y})\). When \(N_{x} N_{y}\), it is clearly necessary to do some amount of splitting/aggregating of material across multiple receivers/senders to satisfy the constraints of the problem. Figure 2C illustrates this scenario (compare with Fig. 2B).

Readers who are familiar with optimal transport theory [31; 32; 16] will quickly realize that \(d_{}\) is simply the 2-Wasserstein distance between a uniform mixture of Dirac masses at \(\{_{1},,_{N_{x}}\}\) and a uniform mixture of Dirac masses at \(\{_{1},,_{N_{y}}\}\). This allows us to immediately conclude the that soft matching distance is symmetric and satisfies the triangle inequality, which have been cited as advantageous properties . This connection to optimal transport also raises many interesting extensions, such as quantifying representational dissimilarity with entropy-regularized transport divergences , but we leave these possibilities to future work.

### Soft Matching Correlation Score and Comparison with Semi-Matching

Suppose that the columns of \(\) and \(\) have been mean-centered and normalized to unit length. Then \(_{i}^{}_{j}\) is the Pearson correlation between neuron \(i\) in network \(\) and neuron \(j\) in network \(\). In this setting, we can formulate a _soft matching correlation score_ between two networks:

\[s_{}(,)=_{(N_{x},N_{y})}_{i,j}_{ij}_{i}^{}_{j} \]

When \(N_{x}=N_{y}\), this has an appealing interpretation: \(s_{}(,)\) equals the average correlation between neurons after optimal one-to-one matching. Clearly, \(s_{}\) is closely related to the soft matching distance, \(d_{}\), defined in eq. (11). In fact, one can show (see Supplement A.3) that the matrix \(\) which minimizes the distance in eq. (11) is the same matrix that maximizes the correlation in eq. (12). Although some may prefer to use \(d_{}\) as a metric satisfying the triangle inequality, others may prefer to interpret \(s_{}\) since it is normalized between zero and one.

How does the soft matching correlation score compare with alternatives? Inspired by analyses in Li et al. , we consider a similarity score based on "semi-matching" assignments:

\[s_{}(,)=}_{i=1}^{N_{x}}_{j\{1, ,N_{y}\}}_{i}^{}_{j} \]

which is essentially the average correlation after matching every neuron in \(\) to its most similar partner in \(\). Thus, each neuron in \(\) may be matched to multiple neurons in \(\) or matched to no partners at all. Alternatively, assuming that \(N_{y} N_{x}\), one could define:

\[(N_{x},N_{y})=\{^{N_{x} N_{y}}\ | _{i}P_{ij} 1& j\{1 N_{y}\}\\ _{j}P_{ij}=1& i\{1 N_{x}\}\\ P_{ij}\{0,1\}&\,i,j\{1 N_{x}\}\{1 N_{y}\} .\} \]

as the set of allowable matchings. Here, every neuron in \(\) is matched to one neuron in \(\), and each neuron in \(\) is matched to one or zero neurons in \(\). Then, we can define:

\[s_{}(,)=_{(N_{x},N_{y})}}_{i,j}_{ij}_{i}^{}_{j} \]

as a similarity score. Again, this only applies when \(N_{y} N_{x}\), since there are no feasible matchings when \(N_{x}>N_{y}\). Crouse  describes algorithms for solving the maximization in eq. (15).

It is easy to see that of the three similarity scores, \(s_{}\), \(s_{}\), and \(s_{}\), only the soft matching score is symmetric \(s_{}(,)=s_{}(,)\). Moreover, both \(s_{}\) and \(s_{}\) will tend to view a network with many units (e.g. a "wide" deep net layer) as similar to everything it is compared with. This is illustrated in Figure 3A, which gives a simple example where \(\) and \(\) are decorrelated, \(s_{}(,)=0\), but at the same time \(\) and \(\) are both maximally correlated to a third network, \(s_{}(,)=s_{}(,)=1\). Put differently, on the basis of the \(s_{}\) similarity scores, it is tempting to observe "\(\) is _perfectly correlated to \(\), and \(\) is perfectly correlated to \(\)"_ and then falsely conclude that "\(\) is _perfectly correlated to \(\)."_ This counter-intuitive behavior also applies to \(s_{}\), which behaves identically to \(s_{}\) in this example. In contrast, the soft matching correlation score gives a more intuitive result: it treats \(\) as only 50% correlated to \(\) and \(\) (Fig. 3A).

## 3 Applications

### Highlighting the Limitations of Existing (Dis)similarity Metrics for Single-Neuron Tuning

We first illustrate how prevailing (dis)similarity measures fall short in capturing essential properties of single-neuron tuning due to their rotational invariance. To exemplify this point, we visualize filter weights from the first convolutional layer (conv1) of AlexNet trained on ImageNet. Prior research has consistently demonstrated the emergence of Gabor (or "edge-detecting") filters in the initial layers

Figure 3: **(A)** (left) Three networks (\(\), \(\), and \(\)), composed of 1D tuning curves (network sizes: 3, 3, and 6). (right) Similarity scores for networks in panel A quantified by \(s_{}\) and \(s_{}\). In this example, each tuning curve is normalized to unit length but not mean-centered. **(B)** Visualization of the 64 conv1 filters of size \(11 11 3\) in AlexNet trained on ImageNet in (left) standard and (right) rotated basis. The rotation matrix is sampled uniformly from the SO(64) group.

of deep convolutional networks trained on natural image datasets [35; 36], a phenomenon clearly visible in our analysis (Fig. 3B, left). Intuitively, the structure within these individual filters specifies a coordinate basis in neural activation space that is special and non-random. Indeed, when we apply a random rotation to examine the same weights in an arbitrary basis (\(\)) (Fig. 3B, right), the tuning of individual units differs significantly from that in the coordinate basis (\(\)). In particular, we see minimal signatures of edge-detecting filters in \(\).

It should be emphasized that Fig. 3B visualizes filter weights and applies a random rotation in weight space. Since it is difficult to interpret weights in deeper layers, measures of representational (dis)similarity are usually computed on neural activations instead of weights. However, for the first layer of the network the weights and activations are very closely related: rotating the filter weights (as done in Fig. 3B, _right_) is equivalent to rotating the neural pre-nonlinearity neural activations. Thus, measures like Procrustes distance, CKA, and CCA all fail to capture the distinction between \(\) and \(\), treating them as equivalent representations. In contrast, the soft-matching distance effectively distinguishes them. Given the sensitivity of the soft-matching distance to single-neuron tuning, beyond mere similarities in representational geometry, we propose that it may also prove valuable in the quantification of disentangled representation learning (see A.5).

### Evidence for privileged coordinate bases in deep hidden layer representations

Figure 3 presents evidence that individual neural tuning functions are non-arbitrary in the first layer of a deep network--a finding that has been documented in past work [35; 36]. The soft-matching distance enables us to precisely quantify this effect and investigate the extent to which the coordinate axes (i.e. individual neural tuning curves) are reproducible in deeper hidden layers. That is, we hypothesize that neural networks trained from different initial weights will converge onto similar tuning curves. This _convergent basis hypothesis_ ("tuning matters") can be contrasted with the _arbitrary basis hypothesis_ ("geometry is all you need"), which predicts that two networks may converge onto similar representational subspaces but with arbitrarily rotated coordinate axes. As already mentioned, this latter hypothesis is conceptually aligned with existing (dis)similarity measures that are rotation-invariant (see e.g. ).

To adjudicate between these hypotheses, we employed the soft-matching similarity metric to explore how the alignment between different neural representations evolves with a gradual change of basis. We compare early and late layer representations in deep convolutional networks trained on object categorization with different random initializations, different architectures (ResNet20/VGG16) [37; 38] and on different datasets (CIFAR10/CIFAR100)  to explore whether the bases in different networks share a non-random relationship with respect to each other (evidence for the _convergent basis hypothesis_) or whether this relationship is arbitrary (evidence for the _arbitrary basis hypothesis_). We emphasize that such an inquiry necessitates the development of rotation-sensitive measures, as measures invariant to rotations would exhibit no change with a basis shift.

Our approach is as follows: We sample a random rotation matrix \(\) uniformly over the special orthogonal group \(SO(N)\). We then instantiate a sequence of rotation matrices that interpolate between \(\) and the identity matrix (\(\)) along the \(SO(N)\) manifold. To achieve this, we calculate fractional powers \(^{}=[[]]\), where \(0 1\) and \([]\) and \([]\) denote the matrix exponential and matrix logarithm, respectively. Intermediate values of \(\) smoothly interpolate between that \(\) (\(=1\)) and \(\) (\(=0\)). Thus, varying \(\) smoothly varies the degree of rotation, interpolating between a random basis and the original basis of the neural representation. For each pair of representations (\(,\)), we alter the basis of one representation, say \(\), by multiplying on the right by \(^{}\). We then measure how the soft-matching correlation score, \(s_{}(^{},)\), changes as the degree of rotation is smoothly increased from \(=0\) to \(=1\) (Fig. 4A). If the similarity decreases monotonically as a function of \(\), it furnishes empirical evidence supporting the convergent basis hypothesis.

Our empirical findings are illustrated in Fig. 4B-D. In panel B, we observe that representations from the same network (specifically, ResNet20 trained on CIFAR10) but with varying initial random seeds are significantly more aligned in the standard (coordinate) basis as compared to an arbitrary basis, and this alignment decreases gradually with increasing rotation (\(\)). This trend holds for both early (top) and late (bottom) convolutional layers. This provides evidence that deep convolutional networks trained on image data from different initial weights tend to converge onto similar (though obviously not identical) bases. Strikingly, this trend holds even when comparing networks trained with different architectures (ResNet20 vs. VGG16, Fig. 4C) as well as networks trained on different datasets (CIFAR10 vs. CIFAR100, Fig. 4D). While the strict, one-to-one matching distance (eq. 9) can be used to quantify these trends across networks with the same architecture, the soft matching distance (eq. 11) or soft matching correlation (eq. 12) developed in this paper are needed to rigorously quantify this effect across different architectures (as in Fig. 4C). Overall, our results suggest that the coordinate axes of neural representations across diverse network architectures and training diets are aligned at above-chance levels, lending support for the _convergent basis hypothesis_.

### Soft-matching distance meaningfully distinguishes between neuroscientific hypotheses

Beyond comparing similarity of representations across different artificial neural networks, there has been a recent surge of interest in applying (dis)similarity measures to compare artificial and biological neural networks . We next demonstrate an application of this metric for model-brain comparisons in neuroscience. In particular, numerous studies over the last decade have revealed that deep networks optimized for behaviorally relevant goals like object categorization learn internal representations that are similar to those in the macaque inferotemporal cortex (IT) (or the ventral visual stream in humans) , an area believed to support object recognition in primates . Such findings have sparked optimism that by comparing deep network and neurobiological activation statistics, we can explain specific characteristics of the brain as optimized solutions for specific computational problems faced by organisms .

However, recent studies have revealed several counter-intuitive results. For instance, deep networks trained on object categorization were shown to not only accurately model representations in the ventral visual pathway but also in the dorsal and lateral visual pathways . Traditionally, the latter visual streams were hypothesized to be engaged in distinct functions, such as action recognition, social perception, or visually-guided action . Yet another counter-intuitive finding is that vision transformers  exhibit equivalent performance to convolutional networks in predicting biological responses , even though the latter were designed with some inspiration from biological systems. All of this raises a critical question: are deep networks optimized for object categorization, irrespective of the biological plausibility of their architecture, equally viable models for all three of these visual streams? Or do these findings indicate an inadequacy in our current tools and metrics when it comes to distinguishing between these neuroscientific hypotheses?

One potential explanation is that existing representational (dis)similarity measures may be too permissive to differentiate between various hypotheses. More stringent measures which exclusively seek invariance only with respect to neuron permutations might unveil a different finding. To test this

Figure 4: **Soft-matching similarity reveals the non-arbitrariness of activation bases in DNNs.** We investigate how changes in activation bases impact the soft-matching similarity between two neural representations, \(\) and \(\) (A). Panels B, C and D depict the alignment between networks trained with different initial random seeds (with a fixed ResNet20 architecture), different architectures (ResNet20 vs. VGG16) and different datasets (CIFAR10 vs. CIFAR100) as a function of axis rotation, respectively. **Comparison of DNNs trained on image recognition with the three high-level visual stream representations using different (dis)similarity measures** (E) Definition of the visual streams on a cortical map. (F) DNN-brain region alignment measured using (left) linear predictivity and the soft-matching similarity score (\(s\)).

hypothesis, we leverage the massive Natural Scenes Dataset (NSD) and compare model and fMRI responses across the three visual streams using both a measure that maintains invariance under all invertible linear transformations (linear predictivity, \(R^{2}\)), and our proposed soft-matching distance. We conduct our comparative analyses using the shared set of 1,000 images, each viewed three times by four different participants. We extract feature representations from four candidate neural architectures, all of which were trained for object categorization on ImageNet. This set comprises two DCNNs, namely ResNet50 and AlexNet, as well as two vision transformers , ViT-B/16 and a hybrid model (R50+ViT-B/16). In the hybrid model, the input sequence to the ViT is formed from intermediate feature maps of a regular ResNet50. We compare the penultimate representation from each model to the measured brain activity in each of the three high-level visual streams using the soft-matching metrics and linear predictivity. The latter is computed by fitting an \(l_{2}\) regularized linear regression model on the model representations to predict the measured brain activity using a 70/10/20 train/validation/test split. The predictivity is quantified as the Pearson's correlation coefficient (R) between the measured and predicted responses of each brain voxel, averaged within each stream. The regularization parameter was optimized independently for each subject and each high-level visual stream by testing among 8 log-spaced values in [1e-4, 1e4].

Comparing representations across model and brain region combinations, we observed that linear predictivity (\(R^{2}\)) was insufficient to discern differences between different architectures (CNNs or transformers) and distinct visual processing streams: all model-region scores exhibited similar ranking (Fig. 4F). On the other hand, the soft-matching metrics proved effective in adjudicating between models and revealed significant differences (i) among CNNs vs. transformer architectures in terms of their similarity to brain representations, and (ii) in the ability of object categorization models to capture representations within the three putative visual streams. According to this metric, convolutional networks emerged as superior models for modeling the ventral visual stream when compared to transformers. Furthermore, object categorization models, regardless of their architectural design, demonstrated a better fit with the ventral visual stream as opposed to the other streams. These conclusions are in line with our intuitive understanding of these models and neural systems.

## 4 Conclusion

We leveraged concepts from optimal transport theory to introduce a metric on neural representations that is rotation-sensitive but permutation-invariant. This metric, which we call _soft matching distance_, generalizes the one-to-one matching distance proposed in  to networks of varying sizes by employing _soft permutation_ or _soft assignment_ of neurons [17; 18; 19; 20; 21].

The soft matching metric reveals structure that is invisible to popular rotation-insensitive measures like CKA , RSA , and Procrustes distance . For example, our experiments on CIFAR10 and CIFAR100 leverage soft matching distance to show reproducible convergence of activation bases across networks. This convergence holds true across various factors such as initial random seeds, architectural differences, and training diets. These findings are consistent with a variety of anecdotal accounts within the interpretable deep learning literature, such as "curve detector" units , shape tuning , and object detectors . Despite these examples, most hidden layer units are not (as far as we can tell) semantically meaningful--yet, these non-semantic units are still important for network performance . The soft matching distance therefore addresses an important need to quantitatively compare single unit tuning across networks without reliance on semantic labels.

Moreover, we extend the utility of our metric to the domain of comparing artificial and biological neural networks. We observed that our metric outperforms measures with more inherent invariances, such as linear predictivity, in terms of distinguishing between models. This development offers neuroscientists an additional--and potentially more discerning--tool to interrogate the commonalities and distinctions between biological and artificial networks.

Why might networks have a distinguished and convergent basis, and why is the basis often overlooked in practice? Prior studies justify the use of rotation-invariant metrics since a network layer is arbitrary up to a full-rank matrix multiplication: hence, the subsequent weight matrix can absorb the matrix inverse, rendering the choice of basis immaterial . However, this disregards the fact that nonlinearities, such as Rectified Linear Units (ReLUs), are applied along particular dimensions (i.e. the coordinate axes) within the space of neural activations. These non-linearities might thus act as symmetry-breaking mechanisms that favor certain activation bases over others.

Overall, our work develops a metric, the _soft matching distance_, which complements existing measures of representational similarity like CKA, RSA, and Procrustes shape distance. Relative to these existing rotation-invariant measures, this new distance is better suited to interrogate representations at the level of single-neuron tuning. Our applications of the metric thus far support the view that single neuron tuning is preserved above chance levels across networks, which may be an important clue into the complex computations performed within artificial and biological neural circuits.