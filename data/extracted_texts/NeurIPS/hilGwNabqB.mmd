# A Bayesian Approach for Personalized Federated Learning in Heterogeneous Settings

Disha Makhija

Electrical and Computer Engineering

University of Texas at Austin

Austin, TX 78705

disham@utexas.edu

&Joydeep Ghosh

Electrical and Computer Engineering

University of Texas at Austin

Austin, TX 78705

jghosh@utexas.edu

&Nhat Ho

Statistics and Data Science

University of Texas at Austin

Austin, TX 78705

minhnhat@utexas.edu

###### Abstract

Federated learning (FL), through its privacy-preserving collaborative learning approach, has significantly empowered decentralized devices. However, constraints in either data and/or computational resources among participating clients introduce several challenges in learning, including the inability to train large model architectures, heightened risks of overfitting, and more. In this work, we present a novel FL framework grounded in Bayesian learning to address these challenges. Our approach involves training personalized Bayesian models at each client tailored to the unique complexities of the clients' datasets and efficiently collaborating across these clients. By leveraging Bayesian neural networks and their uncertainty quantification capabilities, our local training procedure robustly learns from small datasets. And the novel collaboration procedure utilizing priors in the functional (output) space of the networks facilitates collaboration across models of varying sizes, enabling the framework to adapt well in heterogeneous data and computational settings. Furthermore, we present a differentially private version of the algorithm, accompanied by formal differential privacy guarantees that apply without any assumptions on the learning algorithm. Through experiments on popular FL datasets, we demonstrate that our approach outperforms strong baselines in both homogeneous and heterogeneous settings, and under strict privacy constraints.

## 1 Introduction

Federated Learning (FL) has emerged as a pivotal paradigm in various real-world applications, offering a decentralized approach that allows participating clients to contribute to a shared model without compromising the privacy of their raw data. However, implementing FL in practical scenarios poses challenges due to the significant variability among participating clients in terms of their local data and computational resources. Clients with restricted compute capacity may encounter difficulty in training large machine learning models identical to those of other clients, and those with minimal data may struggle to obtain reliable estimates of local model parameters.

Due to their ability to generalize under limited data and provide uncertainty quantifications , we consider Bayesian based learning methods to construct improved local models. Employing Bayesian learning in FL, however, would involve the following steps - each client doing localposterior inference to obtain a distribution over weight parameters and then communicating the local posteriors to the server, the server receiving the local posteriors from the clients and aggregating them to obtain a global posterior distribution, which is then broadcast to the clients for the next round of training. This entire learning procedure, as it turns out, is highly resource and communication-intensive. For solving an \(m\)-dimensional federated least squares estimation, this method will require \(O(m^{3})\) computation on all the clients and server sites  which is much more as opposed to the cost of standard FL (generally \(O(m)\)). _How could we then utilize the strengths of Bayesian methods for FL settings without paying such high costs?_ Additionally, _given substantial variations in locally available computing resources, how do we still enable efficient learning and collaboration on all clients?_ We address these questions by proposing a framework that allows all clients to train their own personal Bayesian models (with varying model complexities), and achieves collaboration across clients by distilling knowledge from the peer clients via a shared unlabelled public dataset and instilling that knowledge in the local models in the form of priors. The challenge of transferring knowledge across models of different architectures is addressed by using the functional (output) space to indirectly determine priors on weights of the local model parameters. Furthermore, to prevent the data leaks in FL setup [22; 68; 23] and formally guarantee the privacy of the local client data, we present a differentially-private version of the algorithm applying a formal well-known standard of differential privacy , along with privacy analysis and a bound on the privacy loss of the entire procedure.

This work provides a novel integrated Federated Learning (FL) framework, _FedBNN_, designed to tackle challenges arising from both limited data and heterogeneous computational resources across clients. Additionally, our method offers valuable characterizations of model uncertainties, and is able to operate under strict data privacy constraints, thereby extending the applicability of FL to crucial domains such as healthcare and legal, where these considerations are paramount. To the best of our knowledge, no previous work has jointly addressed all these learning challenges in the FL context. Our promising results significantly broaden the potential of FL for critical real-world applications.

Specifically, our **key contributions** can be summarized as :

* We propose a new approach to personalized federated learning utilizing Bayesian principles for improved robustness and reliability, particularly in contexts where data is scarce. Despite its Bayesian framework, this method is designed to be both computationally and communication efficient.
* A novel collaboration mechanism based on assigning prior distributions over the model parameters via the output space, instead of directly sharing model parameters' distributions, which can be computationally expensive and raise privacy concerns, is proposed to enable clients having different computational resources to train models with varying complexity. This is important because in real-world FL applications, clients often have vastly different capabilities.
* We provide a formal differential privacy guarantee for our method that applies to general settings irrespective of the client's learning algorithm and show that the method is able to learn effectively even under strict privacy guarantees.
* We evaluated our method on several datasets and show that it outperforms the baselines by a significant margin, particularly in heterogeneous data and model settings. This makes FedBNN particularly well-suited for real-world FL applications, which often exhibit high degrees of heterogeneity.

## 2 Related Work

This section provides a brief overview of the most relevant prior work in the fields of federated learning, Bayesian FL, and Differential Privacy in FL.

**Federated Learning** FL was introduced as the FedAvg algorithm in the seminal work in . Since then many different modifications have been proposed that tackle specific challenges, including global FL solutions as well as personalized solutions. FedPD , FedSplit , and FedDyn  proposed methods for finding better fixed-point solutions to the FL optimization problem. [40; 73; 66; 58; 15] show that point-wise aggregate of the local client models does not produce a good global model and propose alternate aggregation mechanisms to achieve collaboration. Personalized FL has been approached in many ways like meta-learning [20; 8; 31; 33], multi-task learning [59; 38; 60], by clustering the clients [56; 26] and others [17; 37; 72; 57; 67; 43],  uses Bayesian view based analysis to obtain a better trade-off between personal and global models. Knowledge distillation for personalized FL settings has also been used previously for training heterogeneous models in non-Bayesian settings [36; 40; 50]. Several other methods have proposed enhancements in FL learning and privacy by using an auxiliary dataset like [15; 55; 36; 52]. Most of these methods rely on the well-established knowledge distillation procedures. But since the transfer of knowledge or information between Bayesian models itself has remained inadequately addressed, these methods are not easily extensible to Bayesian settings. Our method on the other hand, utilizes a novel method that enables collaboration across client specific Bayesian models by transferring knowledge through a prior specification mechanism in the output space, which also enhances the field of Bayesian knowledge distillation.

**Bayesian Federated Learning** Bayesian approaches for federated learning can also be broadly divided as methods using Bayesian inference to obtain a global model and personalized Bayesian learning methods. Amongst the methods that train a global model, some methods just use Bayesian mechanisms for achieving collaboration among non-Bayesian local models, like FedBE  which uses Bayesian mechanism to aggregate the locally trained neural networks to obtain a Bayesian ensemble at the server,  which suggests using an MCMC based method for obtaining a global model from the local models, and PFNM  and FedMA  which use a Beta-Bernoulli process to obtain the global models. Other methods that train local Bayesian models at the clients and at the server include FedPA  that uses Laplace approximations for an efficient way of computing local and global posteriors,  that suggests the use of Bayesian Optimization and Thompson Sampling to obtain the solution to the global optimization problem, recently,  did an empirical study on various ways of aggregation mechanisms for local variational Bayesian neural networks and their effects on the solution. These methods that focus on obtaining a global solution are less suited for the statistical heterogeneity present across clients , and therefore we focus more on the methods that build personalized Bayesian solutions for clients. Among such methods, pFedGP  is a Gaussian Process based estimation method that utilizes Deep Kernel Learning to collaboratively train a single deep neural network with FedAvg and then uses personalized GPs for prediction. FedLoc  also uses GP in FL but for regression tasks. pFedBayes  uses variational inference locally to optimize a loss at each client that is a combination of the data likelihood term and distance to the prior and iteratively determines the prior from the global posterior distribution. FOLA  proposed using Laplace Approximation for posterior inference at both the server side and the client side, PAC-FL  and [34; 65; 51] also proposed variants of methods that assume Bayesian models on local clients but for all of them main assumption is that the local model parameters are generated from a shared global distribution thus making them useful only in homogeneous settings. All the methods described above choose priors by assuming a distribution over values for each weight, and thus choosing an appropriate and meaningful prior becomes a challenge . These issues led us to use functional space priors instead which have been explored in limited centralized settings [63; 61; 21] but not in FL. But most importantly, none of these methods are designed or could be easily extended to work with compute heterogeneous settings limiting the applicability of these solutions in several real-world scenarios. Table 1 compares our approach with the most closely related works.

**Differential Privacy in FL** Since decentralized learning does not guarantee that the data will remain private, it is important that a formal rigorous guarantee be given on the data that is leaked by the algorithm. Seminal works in DP propose using a Gaussian noise mechanism by adding Gaussian noise to the intermediate results and achieving a bound on the algorithm by using composition

    &  \\   & Limited & Heterogeneous & Uncertainty &  \\  & Data & Compute & Quantification & \\  FedProx & ✗ & ✗ & ✗ & ✓ \\ pFedME & ✓ & ✗ & ✓ & ✗ \\ FOLA & ✓ & ✗ & ✓ & ✗ \\ pFedGP & ✓ & ✗ & ✓ & ✗ \\ pFedBayes & ✓ & ✗ & ✓ & ✗ \\ FedProp & ✓ & ✗ & ✓ & ✗ \\ FedAUX & ✗ & ✓ & ✗ & ✓ \\
**FedBNN** & ✓ & ✓ & ✓ & ✓ \\   

Table 1: Contrasting our method, FedBNN, against previous works.

results [19; 46; 32]. For FL,  and  independently proposed DP-FedSGD and DP-FedAvg algorithms, which enhance FedAvg by adding Gaussian noise to the local client updates. Several other works focus on analyzing the privacy-utility trade-off in DP in FL setting [25; 27; 5; 64; 39]. Recently,  proposed a DP-based solution for personalized FL that works only for linear models. And then  improved it for general models and heterogeneous data in FL. These methods, however, mostly focus on privacy guarantees while solving the non-Bayesian FL optimization problem.

## 3 Methodology

In this section, we first go over the problem setting and background, and then present our proposed framework, FedBNN, with details of all the key components.

### Background

Problem DescriptionConsider an FL setting with \(N\) clients where each client \(i\) has local dataset \(_{i}\) of size \(n_{i}\) drawn from the local data distribution \(_{i}\). The goal of a personalized federated learning procedure is to obtain optimal weights for each client's local model, \(_{i}^{*}\), given the entire data, \(=_{j=1}^{N}_{j}\) through collaboration but without compromising client data privacy. However, the learning procedure faces challenges that are posed due to - _system heterogeneity_ and _statistical heterogeneity_. System heterogeneity refers to the variable amount of data and compute resources across clients, meaning, i) the data resources on each client vary widely, i.e., \(n_{k}>>n_{l}\) for some clients \(k\) and \(l\), and ii) the compute across clients is non-identical due to which it is not possible to train models of uniform architectures across clients, leading to non-identical weights, i.e., \(_{i}_{j}\) for different clients \(i\) and \(j\). Statistical heterogeneity implies that the data distribution across clients is non-IID.

Bayesian LearningInstead of obtaining the optimal values of the model parameters, \(_{i}^{*}\), Bayesian learning aims to learn posterior distributions (probability distributions over the values) for all the model parameters from the given data - \((|)\). Thus, in a personalized Bayesian FL procedure, the modified goal would be to learn distributions for local weights, \((_{i}|)\) from \(=_{j=1}^{N}_{j}\). However, the exact inference for obtaining the posterior distribution for each of the weight parameter in the network is intractable and several approximations have been studied to obtain approximate distributions. Variational inference  is an approximation method that tries to learn parameterized distribution \(q(w|)\) from a family of distributions \(\), typically of simpler form, by optimizing the parameters \(\) such that the new distribution \(q(w|^{*})\), obtained for the optimal value of \(\), is close to the desired posterior distribution \((|)\). Precisely, \(^{*}\) is obtained by solving the following optimization problem and its expansion given below -

\[^{*} =*{arg\,min}_{:q(|)}[q(|)||(|)]\] (1) \[=*{arg\,min}_{:q(|)}[q(|)||p(;)]-_{q( |)}[(|)]\] (2)

and then \(q(w|^{*})\) is used in place of \((|)\). The optimization objective minimizes the distance of \(q(|)\) to a prior distribution \(p(;)\), used to encode any prior information about the parameters, while also maximizing the likelihood of the observed data \(\) under \(q(|)\). A more detailed discussion of Bayesian learning is included in Appendix A. Even though Bayesian approaches are more computationally expensive than their point-estimation counterparts, their superior capabilities for uncertainty quantification and performance in small data settings outweigh the extra compute costs in many critical applications. Moreover, recent innovations like Bayes by Backprop  which carefully uses the backpropagated gradients for learning the parameters of posterior distributions, drastically reducing the added computation costs.

### FedBNN Methodology

The FedBNN framework works iteratively in two steps - local optimization on the individual clients to obtain local posterior distributions over the model parameters, and a global collaboration step where the output from each client is appropriately aggregated at the server and broadcast to all the clients for the next rounds of training. These two steps are further described below, and the detailed algorithm and the overview diagram are included in the Appendix B in Algorithm 1 and Figure 2 respectively.

Local SettingLet each client in the network be training a personalized Bayesian NN, which for the client \(i\) is denoted by \(_{i}\) and is parameterised by weights \(_{i}\). As commonly used in the literature, we assume that the individual weights of the BNN are Normally distributed and satisfy mean-field decomposition, i.e., \(w_{i,}(_{i,},_{i,}^{2})\) for \([1,,|_{i}|]\) where \(_{i,}\) is the mean of the Gaussian distribution for the parameter \(\) on the \(i^{th}\) client and \(_{i,}^{2}\) is the variance of the Gaussian distribution for the same parameter. To guarantee that \(_{i,}\) takes non-negative values for all clients \(i\) and all parameters \(\), we use a technique commonly used in inference procedures , and replace each \(_{i,}\) by another parameter \(_{i,}\) during the training, with \(_{i,}=(1+(_{i,}))\). The individual weights of the local BNN, \(w_{i,}\), are also assumed to each have a Gaussian prior distribution, \(p(w_{i,};_{i,})\), parameterized by \(_{i,}=(_{i,}^{p},_{i,}^{p})\).

#### 3.2.1 Global Collaboration

We attain collaboration amongst clients via an auxiliary dataset called the Alignment Dataset (AD). This is an unlabeled dataset typically small in size, and is used for providing peer supervision to the individual clients by helping clients distill knowledge from other peer clients without explicitly sharing a large number of locally learned parameter weight distributions. The experiments in Figure 5 and Table 3 show the effect of the varying size and distribution of AD in achieving effective collaboration.

In heterogeneous settings, the use of non-identical architecture models (\(_{i}_{j}\)) means that there is no direct way of aggregating the distributions for prior specification. In fact, even in homogeneous settings, aggregating the weight distributions can be prone to errors due to reasons like insufficient understanding of the weight space, non-alignment of weights across models, etc. Thus, for the purpose of collaboration, we use the function-space of the networks rather than the weight space. Specifically, in each global communication round, the server shares the AD with all the clients. The clients do a forward pass on AD to obtain the local output \(_{i}()\), where the local output of the \(i^{th}\) client is approximated by drawing \(m\) sets of weight samples, \(_{i}^{(j)}:j[1,m]\), from its local posterior distribution \((_{i}|)\) using Monte Carlo sampling and aggregating the outputs under each of these samples \(_{i}()=_{j=1}^{m}_{i}(;_{ i}^{(j)})\). The obtained output for AD on each client is then sent back to server which forms an aggregated representation, denoted by \(()\), obtained via a weighted aggregation of all clients' outputs, i.e., \(()=_{j=1}^{N}w_{j}_{j}().\) By default, all weights are considered the same, however the formulation provides flexibility, for example to accommodate situations where the aggregation weights could represent the relative strength of each client in terms of its data or compute resources, i.e., clients with high compute (or data) resources receive more weight as compared to clients with lower amount of resources. The obtained \(()\) is then uploaded to all the clients for use in the next round of local training. More details about the Alignment Dataset (AD) along with the explanations and experiments on the size, distribution, availability etc. of the AD are included in the Appendix E.

#### 3.2.2 Local Optimization on Clients

Prior Specification DesignThe Bayesian framework provides a natural way of incorporating supervision in the form of priors. Conventional methods in Bayesian deep learning provide direct priors for model weights as distribution over values. However, the relationship between the values of the model weights/parameters and the outputs is complex and the priors in model's weight-space do not directly capture the desired functional properties. Also, since the number of parameters in a neural network is large, most prior specifications tend to take a simplistic form like an isotropic Gaussian, to make inference feasible. Thus, learning by specifying prior distributions over weights does not always help translate prior knowledge in the learning process. In this work, we consider a way of specifying priors in the functional space by first optimising the Bayesian neural networks over the prior parameters for a fixed number of steps so that the BNN achieves a desired functional output. These intuitive priors help in explicitly instilling the external knowledge during the training of the neural networks. Let \(p(_{i};)\) represent the prior function over the weights \(_{i}\) and is parameterized by \(\), with \(=\{(_{i,}^{p},_{i,}^{p}),[1,,|_{i}|]\}\), the prior parameters that determine the prior distributions are learned by solving an optimization problem as below:

\[_{i}^{*}=*{arg\,min}_{}(Y,_{i}(; _{i})),\]

where d is a suitable distance function and \(Y\) represents the desired output, resulting in optimal priors \(p(_{i};^{*})\). Below we provide details of the prior specification for our method.

Local OptimizationFor the local optimization, the individual clients learn \((_{i}|_{i})\) via variational inference. As described above, a variational learning algorithm tries to find optimal parameters \(^{*}\) of a parameterized distribution \(q(_{i}|)\) among a family of distributions denoted by \(\). In our setting, we set the family of distributions, \(\), to be containing distributions of the form \(w_{i,}(_{i,},_{i,}^{2})\) for each parameter \(w_{i,}\) for \([1,,|_{i}|]\). For inference in Bayesian neural networks, we use Bayes by Backprop  method to solve the variational inference optimization problem.

At the beginning of each local optimization procedure (in each global communication round a specific client is selected), we use the global information obtained from the server \(()\) to initialize the prior for the BNN. Specifically, at the beginning of each local training round, the selected clients first tune their priors to minimize the distance between the local output, \(_{i}(;_{i})\) and the aggregated output obtained from the server, \(()\). Since the aggregated output represents the collective knowledge of all the clients and may not be _strictly precise_ for the local model optimization, we consider this aggregated output as "noisy" and correct it before using for optimization. Specifically, we generate \(_{i}^{}\) as a convex combination of the global output and the local output for a tunable parameter \(\). For the \(i^{th}\) client,

\[_{i}^{}=()+(1-)_{i}( ;_{i}).\] (3)

The prior optimization steps then optimize the distance between \(_{i}^{}\) and \(_{i}(;_{i})\) to train the prior parameters \(\), with the aim of transferring the global knowledge encoded in \(_{i}^{}\) to the local model. Precisely,

\[_{i}^{*}=*{arg\,min}_{}(_{i}^{ },_{i}(;_{i})).\] (4)

When the outputs \((;)\) are logits, we use cross-entropy or the negative log-likelihood loss as the distance measure. The optimization involves training the client's personal BNN \(_{i}\) to only learn the parameters of the prior distribution denoted by \(\). This way of initializing the BNN prior enables translating the functional properties, as captured by \(_{i}(;_{i})\), to weight-space distributions. The optimal prior parameters are then kept fixed while training the BNN over the local dataset. The local optimization procedure now works to find the best \(q(_{i}|)\) fixing the prior distribution through the following optimization problem :

\[_{i}^{*}=*{arg\,min}_{:q(_{i}|) }[q(_{i}|)||p(_{i};_{i}^{* })]-_{q(_{i}|)}[log(_{i}| _{i})],\] (5)

which is similar to the optimization problem defined in Equation 1 except that now the prior parameters are optimized so that the obtained prior distributions capture the global knowledge and can guide the local learning process to make \(q(_{i}|)\) close to the global collective knowledge.

#### 3.2.3 Achieving Differential Privacy

In this variation, to control the release of information from the clients, we add a carefully designed Gaussian mechanism wherein we add Gaussian noise to the \(_{i}()\) that is being shared by each client. Specifically, each client \(i\) uploads \(_{i}()_{}=_{i}()+(0,_{g}^ {2})\) to the server and then the server aggregates \(_{i}()_{}\) across clients to obtain and broadcast \(()_{}\) which is used by the clients in their next round of local optimization. The variance of the noise depends on the required privacy guarantee.

Privacy Analysis

Though our algorithm is inherently quite private as it refrains from explicitly sharing model weights, we can also provide a formal Differential Privacy based guarantee. Our analysis in this section focuses on providing record-level DP guarantee over the entire dataset \(\). This analysis quantifies the level of privacy achieved towards any third party and an honest-but-curious server. In this section we directly present the key result of our analysis. Due to the lack of space, additional definitions, results and the proof for the theorem are mentioned in Appendix C.

**Theorem 4.1** (Privacy Budget).: _The proposed algorithm is \((,)\)-differentially private, if the total privacy budget per global communication round per query is set to_

\[=}{4EK}\]

_for \(E\) number of global communication rounds and \(K\) number of queries to the algorithm per round._

The parameter \(\) is related to the Gaussian noise by \(=}{2^{2}}\). The detailed proof is included in Appendix C. Our analysis does not assume any specifics of how each client is trained and is therefore applicable in more general settings. Note that we present a pessimistic analysis by providing a worst-case analytical bound, wherein we assume that a change in single data point may entirely change the output of the algorithm, and also since the public dataset remains common throughout the rounds, the actual privacy loss due to querying on the public dataset does not typically add up linearly. Yet the above analysis shows that we have several knobs to control to achieve the desired privacy-utility trade off - balancing the number of global communication rounds with local epochs, reducing the number of queries, and the standard noise scale. By appropriately tuning these controls we are able to achieve good performance with a _single digit_\(\) (\(\) 9.98) privacy guarantee and \(=10^{-4}\).

## 5 Experiments

In this section, we present an experimental evaluation of our method and compare it with different baselines under diverse homogeneous and heterogeneous client settings. Specifically, we experiment with three types of heterogeneity - i) heterogeneity in data resources (amount of data), ii) heterogeneity in compute resources, and iii) statistical heterogeneity (non-IID data distribution across clients). We also discuss the change in performance of our method when the degree and type of heterogeneity changes. Due to the space constraint, additional experiments on varying the size and distribution of the AD, privacy-utility trade-off and model calibration are included in the Appendix E, G and D respectively.

### Experimental Details

DatasetsWe choose three different datasets commonly used in prior federated learning works from the popular FL benchmark, LEAF  including MNIST, CIFAR-10 and CIFAR-100. MNIST contains 10 different classes corresponding to the 10 digits with 50,000 28\(\)28 black and white train images and 10,000 images for validation. CIFAR-10 and CIFAR-100 contain 50,000 train and 10,000 test-colored images for 10 classes and 100 classes respectively. The choice of these datasets is primarily motivated by their use in the baseline methods.

**Simulation Details** We simulate three different types of heterogeneous settings - corresponding to heterogeneity in compute resources, data resources and the statistical data distribution. Before starting the training process, we create \(N\) different clients with different compute resources by randomly selecting a fraction of clients that represent clients with smaller compute. Since these clients do not have large memory and compute capacity, we assume that these clients train smaller-size BNNs as opposed to the other high-capacity clients that train larger VGG-based models. In particular, the small BNNs were constructed to have either 2 or 3 convolution layers, each followed by a ReLU and 2 fully-connected layers at the end, and a VGG9-based architecture was used for larger BNNs. The number of parameters in smaller networks is around 50K and that in larger networks is around 3M. Since the baselines only operate with identical model architectures across clients, we use the larger VGG9-based models on the baselines for a fair comparison. We include the results of our method in both homogeneous compute settings (similar to baselines) as well as in heterogeneous compute settings wherein we assume that 30% of the total clients have smaller compute and are training smaller-sized models. Next, we also vary the data resources across clients and test the methods under 3 different data settings - small, medium and full. The small setting corresponds to each client having only 50 training data instances per class, for the medium and full settings each client has 100 data instances and all available data instances per class respectively for training. We simulate statistical heterogeneity by creating non-IID data partitions across clients. We work in a rather strict non-IID setting by assuming clients have access to data of disjoint classes. For each client a fraction of instance classes is sampled and then instances corresponding to the selected classes are divided amongst the specific clients. For the included experiments, we set number of clients \(N=20\) and divide the instances on clients such that each client has access to only 5 of the 10 classes for MNIST and CIFAR-10, and 20 out of 100 classes for CIFAR-100.

**Training parameters and Evaluation** We run all the algorithms for 200 global communication rounds and report the accuracy on the test dataset at the end of the \(200^{th}\) round. The number of local epochs is set to 20 and the size of AD is kept as 2000. Each client is allowed to train its personal model for a fixed number of epochs, which is kept to \(50\) in experiments, before entering the collaboration phase. The hyper-parameters of the training procedure are tuned on a set-aside validation set. At the beginning of each global communication round, for optimizing the prior parameters at each client according to Equation 4, we use an Adam optimizer with learning rate=0.0001 and run the prior optimization procedure for 100 steps. Then with the optimized prior we train the local BNN using Bayes-by-Backprop, with Adam optimizer, learning rate = 0.001 and batch size = 128. The noise effect \(\) is selected after fine-tuning and kept to be \(0.7\). For these experiments, the aggregation weight \(w_{j}\) for each client \(j\) used to compute \(()\) is set to \(1/N\), and the AD is obtained by using a separated subset of the dataset in consideration. All the models are trained on a 4 GPU machine with GeForce RTX 3090 GPUs and 24GB per GPU memory. For evaluation, we report the classification accuracy obtained by running the trained models on test datasets from the MNIST, CIFAR10 and CIFAR100 datasets.

**Baselines** We compare our method against the standard non-Bayesian FL algorithms and Bayesian-FL methods that build personalized models for clients. We also show results of differentially private FedAvg algorithm under similar privacy guarantee to provide perspective on the privacy. Apart from local training where all clients train independent models locally without collaboration, the non-Bayesian FL baselines include - i) FedAvg, ii) FedProx, iii) pFedME (which uses personalized models on each client using Monreau envelopes in loss). We also compare our method to other

    &  &  &  \\   & (small) & (medium) & (full) & (small) & (medium) & (full) & (small) & (medium) & (full) \\   (Non-Bayesian) &  &  &  &  &  &  &  &  &  \\ Local Training & & & & & & & & \\ FedAvg & \(88.2 0.5\) & \(90.15 1.2\) & \(92.23 1.0\) & \(43.14 1.2\) & \(56.27 1.8\) & \(78.17 1.2\) & \(27.3 1.9\) & \(32.81 1.6\) & \(36.3 0.2\) \\ FedProx & \(86.9 0.8\) & \(89.91 0.7\) & \(93.1 0.4\) & \(44.27 1.2\) & \(58.93 0.9\) & \(79.19 0.6\) & \(28.6 2.7\) & \(34.31 1.4\) & \(37.8 0.9\) \\ FedAUX & \(90.1 1.6\) & \(92.8 1.34\) & \(94.4 1.21\) & \(60.01 1.96\) & \(68.6 0.73\) & \(77.0 0.84\) & \(37.05 1.3\) & \(43.5 1.7\) & \(45.2 0.88\) \\ pFedME & \(91.95 2.1\) & \(93.39 1.2\) & \(95.62 0.5\) & \(48.46 1.5\) & \(64.57 2.1\) & \(75.11 1.2\) & \(32.4 2.2\) & \(36.3 2.0\) & \(41.8 1.7\) \\ non-Bayesian KD & \(89.1 0.4\) & \(92.5 0.2\) & \(93.2 0.3\) & \(33.9 1.3\) & \(53.2 1.5\) & \(69.8 1.0\) & \(26.1 2.0\) & \(35.2 1.2\) & \(42.7 0.8\) \\   (Bayesian with Homogeneous Architectures) &  &  &  &  &  &  &  &  &  \\ pFedBayes & \(94.0 0.2\) & \(94.6 0.1\) & \(95.5 0.3\) & \(58.7 1.1\) & \(64.6 0.8\) & \(78.3 0.5\) & \(39.51 1.8\) & \(41.43 0.4\) & \(47.67 1.1\) \\ FOLA & \(91.74 1.0\) & \(92.87 0.8\) & \(95.12 0.6\) & \(43.29 0.9\) & \(45.94 0.7\) & \(67.98 0.5\) & \(33.42 1.3\) & \(48.8 2.1\) & \(43.2 1.6\) \\  Ours (Homo) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\ Ours (Hetero) & \(93.1 1.1\) & \(94.4 0.2\) & \(95.9 0.2\) & \(\) & \(\) & \(\) & \(\) & \(49.10 1.1\) & \(\) \\ Ours (Hetero-DP) & \(89.82 2.3\) & \(90.21 1.6\) & \(91.43 1.4\) & \(54.9 1.91\) & \(61.83 1.4\) & \(74.3 1.6\) & \(43.7 2.3\) & \(44.5 1.7\) & \(47.0 1.5\) \\  (DP-Baseline) &  &  &  &  &  &  &  & {\(30.7 that use an auxiliary dataset for collaboration in non-Bayesian FL, namely i) FedAUX, which uses federated distillation for achieving collaboration in FL, we do not use FedMD  as a baseline since it requires a labelled auxiliary dataset. Further, we create a baseline corresponding to the non-Bayesian version of our method that works with knowledge distillation and call it non-Bayesian KD. The Bayesian FL baselines include - i) pFedGP, a Gaussian process based approach that trains common deep kernels across clients and personal tree-based GPs for classification, ii) pFedBayes, which uses a variational inference-based approach for personalized FL by training personal models which are close to the aggregated global models, iii) FOLA, bayesian method using Gaussian product for model aggregation. And lastly, the DP baseline includes - i) DP-FedAvg, the FedAvg algorithm with gradient clipping and noise addition to the gradient at each client. The size of the AD is changed to 1000, number of local epochs to 40 and global communication rounds to 100 for DP-based experiments. For all the experiments, the hyper-parameters were obtained by tuning on a held-out validation dataset. We used our own implementation of the pFedBayes algorithm since the source code was not publicly available but we could not compare against FedPop due to the lack of some implementation details and publicly unavailable code.

### Results

The performance of our method and the baselines under the non-IID data setting are reported in Table 2. Under the non-IID setting, we report the results corresponding to different dataset sizes on each client. To recall, in the small, medium, and full settings, each client has access to 50, 100, and all training data points per class respectively. We observe that our method with homogeneous architectures across clients outperforms all other baselines. Moreover, when we consider the performance of our method under a heterogeneous setting by considering 30% of the total clients to be small capacity, it is evident that our method is better than the higher capacity homogeneous baselines for more complex tasks like in CIFAR-10 and CIFAR-100. On average, our method achieves about \(6\%\) performance improvement over the baselines in the small and medium data settings. Figure 1 compares the performance of our method with the highest-performing baselines under model, data and statistical types of heterogeneity. Since our method can work with heterogeneous clients, we see that just by the proposed collaboration and having higher capacity clients in the FL ecosystem, the lower capacity clients are able to gain about \(10\%\) increase in their performance. Also, the performance degradation of our method with a change in the number of clients with limited data resources is more graceful as compared to the baselines. In an additional experiment intended to compare the performance of the baseline methods with additional data, we trained the priors for baseline methods' encoders using the unlabeled data, AD, before starting their own prescribed FL procedure. We observed that the performance of the baseline methods does not change on doing this because the FL procedure that they incorporate forgets all the prior existing local knowledge at the client side. A similar result was also reported in . The superior performance of our method could be attributed to the innovative and effective collaboration achieved by first distilling peer knowledge in the form of the aggregated output on the

Figure 1: Performance comparison of our method with baselines under different types and varying degree of heterogeneity for CIFAR-10 dataset with 20 clients. Figure (a) is for heterogeneity in compute capacity across clients under non-IID data setting, figure (b) for compute heterogeneity under IID setting, and figure (c) for heterogeneity in data resources. When a fraction of clients in the setting have low computing resources, the baselines being homogeneous can only train smaller models on all the clients as shown by constant performance. The results show that our method is more tolerant to both model heterogeneity and data heterogeneity across clients.

AD, and then ensuring that this knowledge is successfully transferred to each client by specifying priors in the functional-space of the client model. Furthermore, the parameter in Equation 3 allows the clients the flexibility to choose the amount of global knowledge that needs to be incorporated, providing flexibility on the degree of personalization.

## 6 Discussion

This paper introduced a novel method for personalized Bayesian learning in heterogeneous FL settings and demonstrated that it is able to outperform existing approaches under different types of heterogeneous situations, while also providing a privacy guarantee and calibrated responses. The experiments show that the method is particularly useful for clients with lower data and lower compute resources as they can benefit the most by the presence of other, more powerful clients in the ecosystem. While our method assumes the availability of a small, unlabelled auxiliary dataset at the server, it is typically a very mild requirement as such data can often be obtained from several open sources on the web. In many cross-silo and cross-device applications, the server often possesses its dataset alongside private data from clients. For example, hospitals with access to patient records may combine this data with private patient data collected from individual devices such as wearables or sensors for FL, source code generation applications might leverage open-source code along with private code repositories from developers, etc. [6; 7] also mention use-cases where such data is available in real-world. Recent advances in generative AI have made creation of synthetic data for training a much easier task. The privacy analysis on the method provides an intuitive and a rigorous guarantee with various tunable knobs that can be adjusted to achieve the desired privacy-utility trade-off. And while the application explored in the proposed work consists of image related tasks, both the proposed framework and the privacy analysis are generic and independent of specific training algorithms, therefore resulting in its wide applicability in various applications across data modalities. Also, while Bayesian methods are inherently more computationally expensive as they have to maintain distributions rather than point estimates, this extra work is invaluable in many applications where uncertainty quantification is important, for example to help engineers account for uncertainties in material properties, loading conditions, and manufacturing processes, leading to safer and more reliable designs . The recent use of transformer based Bayesian methods [76; 42; 62] in varied applications indicate that the proposed framework can be also applied to settings where much larger neural networks are required. One limitation that originates from the Bayesian nature, and is common to all applications of Bayesian learning, is that the exact inference of the posterior distributions is infeasible and therefore variational approximation has been used for inference of the posterior distributions.