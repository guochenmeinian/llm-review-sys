# Genetic Curriculum Learning for Distribution Generalization on the Travelling Salesman Problem

Michael Li

University of Washington

ml10872@uw.edu

Christopher Haberland

University of Washington

haberc@uw.edu

&Natasha Jaques

University of Washington

nj@cs.washington.edu

###### Abstract

The Travelling Salesman Problem (TSP) is a classic NP-hard combinatorial optimization task with numerous practical applications. Classic heuristic solvers - and Large Language Models (LLMs) using such solvers as a tool - can attain near-optimal performance for small problem instances, but become computationally intractable for larger problems. Real-world logistics problems such as dynamically re-routing last-mile deliveries demand a solver with fast inference time, which has led to specialized neural network solvers being favored in practice. However, neural networks struggle to generalize beyond the synthetic data they were trained on. In particular, we show that there exist TSP distributions that are realistic in practice, which also consistently lead to poor worst-case performance for existing neural approaches. To address distributional robustness, we present Genetic Curriculum Learning (GCL), an efficient novel approach utilizing automatic curricula. We also present TSPLib50, a dataset of realistically distributed TSP samples, which tests real-world distribution generalization ability without conflating this issue with TSP instance size. We evaluate our method on various synthetic datasets as well as TSPLib50, and compare to state-of-the-art LLM results and neural baselines. We demonstrate that GCL improves distributional robustness, with most of its performance gains coming from worst-case scenarios.

## 1 Introduction

From least-cost shipping and warehouse logistics to efficient automated circuit board drilling, the Traveling Salesman Problem (TSP) has an outsized impact on global trade, accounting for billions of dollars worth of saved time, energy, and harmful emissions. The TSP is NP-hard, which means there exists no efficient algorithm for finding exact solutions. Classic heuristic methods have prohibitive runtimes for real-world situations requiring fast and dynamic decision-making. Neural combinatorial optimization (NCO) methods seek to effectively solve the TSP at lower computational cost [18; 10; 22], but generalize poorly to unfamiliar distributions [11; 6]. In practice, such planning faults can be very expensive in terms of wasted time, money, and human resources.

Given impressive recent gains in reasoning capabilities of Large Language Models (LLMs) [27; 28; 17], LLMs potentially provide a promising path for solving novel TSP instances. However, LLMs currently perform suboptimally on the TSP [13; 26]. In this paper we directly study the performance of state-of-the-art LLMs prompted to solve TSP problems, and find that they have similarly prohibitive inference times as classic heuristics, in addition to inconsistent performance.

Instead, we propose a novel adversarial training technique to enhance the robustness of NCO methods. Rather than training on limited TSP datasets or randomly generated TSP instances, which is inefficient and wasteful due to the high-dimensional parameter space, we propose to use a curriculum learning approach in which environments and tasks are adaptively evolved to be more challenging . As applied to TSP solvers, a "task" or a "level" would be a TSP instance that needs to be solved.

Curriculum-based methods have shown promise for combinatorial optimization , but past works utilize very simple heuristic regimes, and are also focused on generalization across lengths, not distributions . Zhang et al.  proposed a hardness-adaptive curriculum (HAC), which uses gradient ascent to produce increasingly harder levels. However, we show that HAC's sampling and gradient ascent procedure causes unreliable performance on specific types of TSP instances which are of practical interest.

In this paper, we seek to improve model robustness to different distributions. We present an NCO optimization approach which maintains the computational benefits of NCO methods while improving generalization on disparate but practical distributions. We make the following contributions: 1) We propose the TSPLib50 dataset, a testing dataset of 10,000 instances sampled from realistic distributions, designed to test the robustness of TSP solvers; 2) We propose an automatic curriculum which mutates high-improvement-potential training distributions; 3) We present empirical results comparing the performance to the best prior work on curriculum learning for NCO and state-of-the-art LLMs, and show that our method gives better worst-case performance and improved robustness to varying distributions of practical interest. Our method is also relatively efficient to train, requiring only a single GPU and no more than a few hours of training for each model.

## 2 Background

**Traveling Salesman Problem.** The Traveling Salesman Problem (TSP) is a NP-Complete combinatorial optimization problem (COP), which requires finding the shortest tour through a set of cities. The TSP has been of intense interest to computational theorists due to its applicability in many practical scenarios, especially in the logistics sector. Past works as well as this paper consider the 2D-Euclidean TSP, which is formally defined in the Appendix.

**Deep and Reinforcement Learning for TSP.** Neural combinatorial optimization (NCO), or the use of deep learning for combinatorial optimization, can be broadly grouped into three primary approaches: solutions utilizing 1) pointer networks [23; 14], 2) graph neural networks [8; 19; 30], or 3) transformers . Reinforcement learning (RL) has seen successful applications in learning to solve the TSP [16; 4]. Deep RL methods often use a neural network to generate a tour, and then treat tour length as a negative reward, or "cost". Kool et al.  propose a transformer-based solver trained with REINFORCE , using a simple deterministic greedy rollout baseline. However, neural networks are known to often generalize poorly to distributions outside their training data, and existing NCO solvers are no exception. This makes them a risky solution for real-world deployments, in spite of their fast inference time. In this paper, we aim to improve the reliability and robustness of RL-based NCO approaches.

**Curriculum Learning for TSP.** Curriculum methods improve robustness and sample efficiency by proposing tasks to learn from which are optimal for learning by being neither too easy nor too hard [3; 24; 1], and have been applied to real-world problems such as web navigation . In the context of Neural COP solvers, Zhang et al.  propose a hardness-adaptive curriculum (HAC) for the TSP, which mainly consists of two components: a hardness-adaptive generator that conducts gradient ascent on training instances, and a re-weighting procedure for batch gradients in favor of updates for harder levels. We directly compare to HAC in this work, and include the HAC hardness metric \((,M)\) as defined by Zhang et al.  in the Appendix. The hardness-adaptive generator conducts gradient ascent on input samples \(^{(t)}\) given a model \(M\): \(^{(t)^{}}=^{(t)}+_{X^{(t)}}(X ^{(t)},M)\).

## 3 Preliminary Study

**TSPLib50 and Other Evaluation Datasets.** We first motivate the creation of TSPLib50, a new testing dataset. TSPLib, a collection of real-world TSP instances, is often used as a benchmark for combinatorial optimization solvers . Because TSPLib is based on real data, its distributions are both varied and relevant for real-world applications. However, many solvers are trained on relatively small TSP instances. When tested on TSPLib, the gaps incurred by such models are correlated with instance size. For instance, we find a strong Pearson correlation of 0.907 between TSPLib instance size and optimality gap of HAC models (see the Appendix). Improving model generalization to larger instance sizes often requires extensive computational resources, and is beyond the scope of preceding papers as well as this paper.

Following the work of Zhang et al. , we focus on 50-node instances. Hence, we introduce TSPLib50, a dataset of 10,000 instances, each created by sampling 50 points uniformly at random from a TSPLib instance. Because the distribution of points in TSPLib50 is the same in expectation as the distribution of points in TSPLib, we can thus disentangle generalization ability on different _distributions_ with generalization ability on different instance sizes.

We also test performance of our method on challenging synthetic distributions. We test on a Gaussian mixture distribution from prior work , and a "Diagonal" distribution of our design where all points align with a main diagonal. We justify and visualize these distributions in the Appendix.

**Hardness-Adaptive Curriculum Shortcomings.** While HAC improves performance by training on harder distributions , it only conducts one step of gradient ascent on data sampled from a uniform distribution. As a result, HAC fails to cover instances that deviate far from a uniform distribution.

In HAC, changes in \(^{(t)}\) are determined by \(_{X^{(t)}}(X^{(t)},M)\). We find that elements in \(|_{X^{(t)}}(X^{(t)},M)|\) tend to have a mean around \(0.077\) and median around \(0.023\), which are small relative to the unit square \(^{2}\) that points are placed in. Thus, points are only mildly perturbed.

In Figure 1, we visualize high-gap TSPLib50 levels for HAC, and find that HAC performs sub-optimally on levels with large distances between nodes. TSPLib50 bootstraps from real-world distributions, and thus represents use cases of practical interest. We seek to address this issue.

## 4 Genetic Curriculum Learning

**Improvement Potential Metric.** In Genetic Curriculum learning (GCL), we compute the "improvement potential" \(I(,M)\) for each training instance after each epoch with the current model \(M\) and REINFORCE baseline model \(M^{}\): \(I(,M)=_{M}()-_{M^{}}()\). Note that \(I(,M)\) is similar to \((,M)\) as used by Zhang et al. .

Figure 1: Example high-gap instances of a HAC model tested on TSPLib50. We see that all of these failure cases have large distances between node clusters, and thus deviate far from uniform levels.

Figure 2: Architecture of our proposed Genetic Curriculum system. After the forward pass, we compute improvement and then mutate high-improvement levels while saving Fisher information about low-improvement levels.

**Genetic Curriculum Algorithm.** GCL proposes novel usage of an evolutionary approach to maintain a population of challenging levels, drawing inspiration from genetic programming . GCL stores a population of level "genes" that describe the probabilistic process creating the levels. After each epoch, the 50% of highest improvement-potential levels have their genes edited and placed into the next epoch. We find that mutating a population of genes achieves better results than mutating a population of levels. The genome consists of 6 bases: 0) Cluster size of the distribution points are drawn from; 1) Cluster width of the distribution points are drawn from; 2) Rotation angle; 3) Scale factor; 4) \(x\)-axis translation factor; 5) \(y\)-axis translation factor. Through this genome, we try to address distribution invariance, rotational invariance, scale invariance, and translation invariance. Technical details of level sampling from genomes, genetic mutation procedure, and motivation for related hyperparameters are in the Appendix.

GCL also uses Elastic Weight Consolidation (EWC)  to maintain performance on its learned knowledge, because as the genetic curriculum evolves to harder instances, it is possible that catastrophic forgetting is leading the model to perform poorly on easier instances. Figure 2 provides a diagram of the architecture of GCL. An algorithmic specification of GCL is provided in the Appendix.

## 5 Experiments

Our experiments work on fine-tuning an attention-based model with a REINFORCE rollout baseline, previously trained exclusively on uniform random distributions. We compare our model to results from OpenAI's GPT-4o, a state-of-the-art LLM. We also compare against 2 NCO baselines: a "Uniform" baseline which samples from uniform distributions without curriculum, and a "HAC" baseline which samples from uniform distributions but uses HAC. Notably, all experiments are run on a single GPU, and no model takes longer than a few hours to train. Full experimental details and hyperparameters are in the Appendix.1

We plot gaps of all models relative to oracles. We present results for average gaps on the Gaussian Mixture, Diagonal, and TSPLib50 distributions. We also present results on worst-case 1%, 0.5%, and 0.1% of gaps on TSPLib50, to demonstrate robustness to challenging out-of-distribution cases.

To further investigate our method, we run three tests to better interpret GCL. First, we run ablation tests on the genome and EWC components of our method. Second, we plot the distribution of each genome base over the course of training, to better understand the role the genome plays in GCL. Third, we plot the optimality gap of our baseline model \(M^{}\) and current model \(M\) on training data over the course of training, to better understand model convergence behavior.

## 6 Results

**Large Language Model Performance.** Despite advances in mathematical and reasoning capabilities, Large Language Models (LLMs) often fail to find satisfactorily optimal TSP solutions, and have prohibitively slow inference, requiring around 47 seconds on average. Even with prompt engineering,

Figure 3: Gaps across training epochs of our proposed Genetic Curriculum model compared to baselines, on average cases across different distributions and worst-case scenarios in TSPLib50. The optimality gap of GPT-4o on TSPLib50 is around 90% on a small sample, and is not plotted due to the different scale of those values relative to existing results.

LLMs still produce inconsistent and suboptimal responses. Details about our TSP-related LLM experiments are in the Appendix.

**Average Gaps.** Average gap results can be seen in Table 1. On all distributions, HAC already improves significantly on the uniform baseline, as HAC uses a hardness-adaptive generator. GCL, our proposed method, achieves consistent improvement over HAC on the harder distributions. We observe an approximately 1/4 factor gap decrease on both hard distributions: the gap decreases from 8.85% to 6.22% on Gaussian mixtures, and from 3.94% to 3.02% on the diagonal distribution. For the TSPLib50 distribution, GCL improves only slightly on HAC in terms of average gap. This makes sense because a large portion of TSPLib50 levels are easy, while GCL focuses on robustness to challenging levels.

We find decreases in average gap between HAC and GCL to be statistically significant, with values of \(p<0.01\) in two-sample t-tests for all distributions.

**Worst-Case Gaps.** We can see that the slight improvement on TSPLib50 average gap mostly comes from gap decreases on hard levels by analyzing worst-case scenarios. On TSPLib50, GCL provides a 1.82% gap improvement on the worst 1% of cases, a 2.52% gap improvement on the worst 0.5%, and a 3.42% gap improvement on the worst 0.1%. This is significant because in large-scale real-world applications that route millions of TSP problems every day, 1% of routes is still an important and costly fraction. For example, if a large shipping company routes 40,000 loads, 1% of routes would still equate to 400 loads.

We find decreases in worst-case TSPLib50 gap between HAC and GCL to be statistically significant, with values of \(p<0.001\) in two-sample t-tests for worst 1% and worst 0.5%, and \(p<0.03\) for worst 0.1%. GCL also improves gap from 204.40% by HAC to 98.47% on the worst 1% of Gaussian Mixture cases, and from 31.63% by HAC to 14.03% on the worst 1% of Diagonal cases. This demonstrates GCL's significant impact on improving robustness in the most challenging scenarios. Detailed tables are in the Appendix.

**Method Interpretations.** In our ablation tests, we find that performance gains are mainly provided by the genetic component of our method. In our genome evolution plots, we observe that the diversity of genome bases decreases over training, suggesting our genome is effective at encouraging exploration of new configurations. In our optimality gap plot, we observe that the baseline gap starts higher than model gap, but dramatically decreases at around epoch 60, which further supports the previous point on the genome promoting exploration. Detailed results and explanations are in the Appendix.

## 7 Discussion

Our results demonstrate that GCL is able to significantly improve the performance of TSP solvers on hard distributions. We also show that a portion of this improvement occurs in "worst-case" scenarios on real-world distributions of practical interest. Such improved robustness and performance guarantees are significant in real-world deployment.

GCL is a general methodology, and could be applied to other NCOs methods or COPs. As the Kool et al.  architecture generalizes to other problems such as the Vehicle Routing Problem (VRP) and Capacitated VRP (CVRP), it would be exciting to see GCL used for other COPs.

   Dataset & Model & Gap Avg (\%) & Gap Std (\%) \\   & Uniform & 15.0049 & 1.1970 \\  & HAC & 8.8460 & 0.3032 \\  & **GCL (Ours)** & **6.2214** & **0.2155** \\   & Uniform & 7.2115 & 0.1822 \\  & HAC & 3.9447 & 0.1346 \\  & **GCL (Ours)** & **3.0165** & **0.0318** \\   & Uniform & 2.3206 & 0.0082 \\  & HAC & 1.8183 & 0.0167 \\   & **GCL (Ours)** & **1.7738** & **0.0119** \\   

Table 1: Average Model Gap Across Distributions