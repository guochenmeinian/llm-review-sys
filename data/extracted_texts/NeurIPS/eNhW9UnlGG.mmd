# Contextual Gaussian Process Bandits with Neural Networks

Haoting Zhang  Jinghai He  Rhonda Righter  Zuo-Jun Max Shen  Zeyu Zheng

Department of Industrial Engineering & Operations Research

University of California, Berkeley

Berkeley, CA 94720

haoting_zhang,jinghai_he,rrighter,maxshen,zyzheng@berkeley.edu

###### Abstract

Contextual decision-making problems have witnessed extensive applications in various fields such as online content recommendation, personalized healthcare, and autonomous vehicles, where a core practical challenge is to select a suitable surrogate model for capturing unknown complicated reward functions. It is often the case that both high approximation accuracy and explicit uncertainty quantification are desired. In this work, we propose a neural network-accompanied Gaussian process (NN-AGP) model, which leverages neural networks to approximate the unknown and potentially complicated reward function regarding the contextual variable, and maintains a Gaussian process metamodel with respect to the decision variable. Our model is shown to outperform existing approaches by offering better approximation accuracy thanks to the use of neural networks and possessing explicit uncertainty quantification from the Gaussian process. We also analyze the maximum information gain of the NN-AGP model and prove regret bounds for the corresponding algorithms. Moreover, we conduct experiments on both synthetic and practical problems, illustrating the effectiveness of our approach.

## 1 Introduction

Various applications, including online content recommendation , healthcare [37; 15; 36], and autonomous vehicles , demand the sequential selection of a decision variable, conditional on the observed contextual variable representing the state of the environment in each round. These applications can generally be framed as contextual bandit problems [5; 59; 63; 2], especially when the reward function associated with each pair of decision and contextual variables is unknown. When both the decision and contextual variables are drawn from continuous sets, a significant challenge is selecting an appropriate surrogate model to approximate the reward function, considering both approximation accuracy and uncertainty quantification. A common approach to alleviate this issue is to employ a Gaussian process (GP) to model the reward function [61; 46], yielding the GP bandit method [80; 81]. Indeed, GP has proven to be an effective surrogate model to address the exploration-exploitation trade-off in estimating the unknown function while optimizing over it; see [88; 75; 90; 43; 51]. On the other hand, most of the existing GP bandit literature does not take the exogenous contextual variable into consideration, despite its critical role in capturing effects beyond the decision variable that influence the reward - effects that are integral to many of the applications previously mentioned [50; 62]. When the contextual variable is included in GP bandit problems, previous work largely adopts a GP to jointly model the reward function with both contextual and decision variables, employing a composite kernel that is either the sum or product of two separate kernels; see [57; 9].

While GP-based bandit methods have proven effective in various applications [3; 8; 92; 93; 86; 6], they may fall short in scenarios where the reward function exhibits intricate dependence on complexcontextual variables, for example, time-varying rewards [13; 31] and graph-structured contextual variables . Specifically, it is a challenge to pre-define an appropriate composite kernel function for the joint GP, which is critical for the performance of the corresponding bandit algorithms, as documented by [21; 82]. Neural networks (NN), on the other hand, have been utilized elsewhere as surrogate models for the reward function in bandit problems [16; 54; 55], thanks to their flexibility and strong approximation power. However, they bring their own set of challenges. The "black-box" nature of the neural network hinders explicit uncertainty quantification and complicates theoretical analysis of the associated algorithms. In particular, the acquisition functions guiding point selection in these algorithms necessitate an approximation of uncertainty [99; 54]. Although this approximation tends to be accurate when the NN's width is large, this can also lead to overparameterization.

**Contribution.** This paper proposes a _neural network-accompanied Gaussian process_ (NN-AGP) model for solving contextual bandit problems, especially when the reward functions have intricate dependence on complex contextual variables. The proposed model is an inner product of a neural network and a multi-output GP, where the neural network captures the dependence of the reward function on the contextual variables, and the GP is employed to model the mapping from the decision variable to the reward. Our model generates a joint GP with both contextual and decision variables, which outperforms the existing GP-based bandit methods by specifying the data-driven kernel function through the lens of neural networks, thereby leading to an accurate approximation for the reward function. Moreover, compared with entirely relying on NN's, our model stands out due to the explicit GP expression with respect to the decision variable. This feature enables bandit algorithms with NN-AGP to be implemented efficiently with existing GP-based acquisition functions and provides a theoretical guarantee of the regret bounds. Our main contributions can be summarized as follows:

1. We propose an NN-AGP model and its upper confidence bound (UCB) algorithm for contextual bandit problems, referred to as NN-AGP-UCB. Our algorithm offers a data-driven procedure to specify the kernel functions of the joint GP, thereby achieving superior accuracy and model flexibility. We also prove the upper bound for both the maximum information gain of the NN-AGP model and the regret of the NN-AGP-UCB algorithm.
2. We conduct the experiments to evaluate our approach for complex reward functions, including those with time-varying dependence on sequenced and graph-structured contextual variables. Experimental results demonstrate the superiority of our approach over existing approaches that entirely rely on either GP or NN.

### Related work

Since the seminal work by , the Gaussian process (GP) bandit problem has been extensively studied, where the bandit feedback is modeled as a GP regarding the decision variable (arms to be pulled). Some recent work includes [35; 32; 13; 12; 11; 18; 65]. In addition, GP bandits are also related to Bayesian optimization (BO) problems [38; 19; 94; 39; 34; 28; 85; 52; 23], where both problems consider optimizing black-box functions and therefore require surrogate models (GP in particular). When the number of decision variables is finite, the black-box optimization problem is also known as Ranking & Selection (R&S) [44; 73; 70; 4; 87], where GP models are widely employed as well; see [20; 58; 79; 64]. Our NN-AGP model can also be employed in (contextual) BO or R&S, but the discussion is beyond the scope of this work.

In this work, we specifically take the exogenous contextual variables into consideration. Previous work employs multiplicative and additive kernels to incorporate continuous context spaces into the scalar GP; see . Other work considers safe contextual Bayesian optimization, employing a similar strategy to construct composite kernels; see [41; 9]. Another line of research explores distributionally robust BO [56; 83; 53], where the contextual variable distribution is selected from an ambiguity set. The methodology of representing the objective function using a joint GP has also been widely used in contextual policy search; see [72; 21; 40].

The connection between GP and NN has been explored in [60; 68], documenting that NN's with infinite width approach a GP model when the weight parameters are assigned with Gaussian priors. In addition, deep GP's have been proposed to enhance the model flexibility of neural networks where variational inference is employed; see [27; 26; 91]. GP models in which the parameters are represented by neural networks are studied in [98; 97].

## 2 Main procedure

We consider a problem of sequentially selecting a system's input variable (decision variable) for \(T\) (not necessarily known a priori) rounds. In each round, we receive a contextual variable \(_{t}^{d^{}}\) from a set \(\), and select a decision variable \(_{t}^{d}\) from a set \(\) of decisions. We then receive an observation

\[y_{t}=f(_{t};_{t})+_{t},\]

where \(f(;)\) is the reward (objective) function and \(_{t}(0,_{}^{2})\) denotes the noise that is independent of both the contextual variables and decision variables. We consider the scenarios when both \(\) and \(\) are continuous and \(_{t}\)'s are fully exogenous. That is, the selection of the decision variable in each round does not influence the future contextual variables. Although we focus on unconstrained problems in this work, our proposed model can be employed to approximate the constraints in optimization problems as well; see . We also note that, for the description and discussion of our approach, the contextual variable is represented by a vector. However, we show through experiments in Section 4 that our approach is applicable to contextual variables with other structures.

Since \(f(,)\) is unknown, we will not generally be able to choose the optimal action, and will thus incur regret \(r_{t}=_{^{}}f(^{},_{t})-f(_{t},_{t}),\) indicating the difference between the optimal reward and the reward we actually receive in each round. After \(T\) rounds, the cumulative regret is \(_{T}=_{t=1}^{T}r_{t}\). Our goal is to develop an algorithm that achieves sub-linear contextual regret, i.e., \(_{T}/T 0\) for \(T\), which requires a statistical model of the reward function with respect to both context variables and decision variables.

We specifically consider a reward function in the form

\[f(;)=()^{}(),\] (1)

where \(()\) and \(()\) are both \(m\)-dimensional vector-valued (unknown) functions, and \(m\) is a user-selected quantity to indicate the complexity of the function. There are two main reasons for considering this reward function. First, this formulation is a generalization of linear contextual bandits, where the reward function is the inner product of the contextual variables and the unknown parameters. Here, we assume that the inner product is taken with two vector-valued functions with respect to decision variables and the contextual variable, which is similar in spirit to [24; 96; 42; 100]. Second, this reward function is consistent with the tensor-product approximation of a general function; see [29; 30; 47]. Therefore, further analysis on model mis-specification of the reward function can be supported by existing results of tensor-product approximation.

In this work, we specifically assume that \(()\) is a vector-valued deterministic mapping from \(^{d^{}}\) to \(^{m}\), represented by a neural network with a given structure and some weight parameter \(\). In addition, \(()\) is a multi-output Gaussian process (MGP) defined on \(^{d}\). The MGP model is a generalization of the scalar-valued GP, where the output \(()\) at each \(\) is an \(m\)-dimensional vector. The MGP model captures not only the dependence between two outputs but also the dependence between different entries of each output. Thus, the covariance of an MGP \(()\) is represented by a matrix-valued covariance function, denoted by \((,^{})\), and the vector of parameters involved in the MGP is denoted by \(\). We postpone the detailed description of the NN-AGP model to Section 3.1 and conclude our brief introduction of NN-AGP with an associated proposition, which follows easily from the fact that the normal distribution is preserved under linear transformations.

**Proposition 1**.: _The reward function \(f(;)\) is a scalar-valued mean-zero Gaussian process with respect to \(\) and \(\). The kernel function of this Gaussian process is_

\[((,),(^{}, ^{}))=()^{} (,^{})(^{}),\]

_where \((,^{})\) is the covariance of the MGP._

Next, we provide a bandit algorithm with the NN-AGP model, during which the surrogate model is sequentially learned from data. We name the algorithm _neural network-accompanied Gaussian process upper confidence bound_ (NN-AGP-UCB). Suppose we are now in round \(t\) and observe the contextual variable \(_{t}\). In addition, we also have the historic data \(_{t-1}=\{(_{1},_{1},y_{1}), (_{2},_{2},y_{2}),,(_{t-1 },_{t-1},y_{t-1})\}\) in hand. Denote by \(_{t-1}=(y_{1},y_{2},,y_{t-1})\)the vector of observations. The selection of the next decision variable \(_{t}\) depends on the posterior distribution of the reward function, which is\(f(;_{t})_{t-1}(_{t-1} (;_{t}),_{t-1}^{2}(;_{t})).\) Here

\[_{t-1}(;_{t})= }_{(;_{t})}^{ }[}_{_{t-1}}+_{}^{2}I_{t- 1}]^{-1}_{t-1},\] (2) \[_{t-1}^{2}(;_{t})= (_{t})^{}(, )(_{t})-}_{(;_{t})}^{}[}_{_{t-1 }}+_{}^{2}I_{t-1}]^{-1}}_{(;_{t})},\]

where \(}_{(;_{t})}\) denotes the covariance vector between \(f(;_{t})\) and \(\{f(_{};_{})\}_{t=1}^{t-1}\). In addition, for the \((t-1)(t-1)\)-dimensional covariance matrix for historical data \(}_{_{t-1}}\), the \((i,j)\)-th entry is \((_{i})^{}(_{i},_{j} )(_{j})\) as in **Proposition 1**. The required parameters in (2), including the weight parameters \(\) of the neural network \(()\), the parameters \(\) involved in the MGP \(()\) and the variance \(_{}^{2}\) of the noise \(_{t}\), are all learned and updated with the observations through (5), which we will discuss in Section 3.1.

In terms of the acquisition function (the function that decides the decision variable in the following iteration), we employ the contextual Gaussian process-upper confidence bound (CGP-UCB) introduced in . That is, we decide \(_{t}\) as

\[_{t}=_{}\{_{t-1}( ;_{t})+_{t}^{1/2}_{t-1}(;_{t})\},\] (3)

where \(_{t-1}(;_{t})\) and \(_{t-1}(;_{t})\) are the posterior mean and standard deviation of \(f(;_{t})\) as calculated in (2). The optimization problem (3) can be solved efficiently by global search heuristics, as suggested in . In addition, \(_{t}\) is a user-selected hyper-parameter in each round, addressing the exploration-exploitation trade-off; see discussions in Section 3.2. The procedure for NN-AGP-UCB is summarized in **Algorithm 1**. We note that other commonly selected acquisition functions for GP bandit problems or Bayesian optimization can be employed with NN-AGP as well, including knowledge gradient [76; 89; 33] and Thompson sampling [25; 74]. We postpone the discussion of these acquisition functions to the supplements.

``` Input: Initial values of \((,,_{}^{2})\); for\(t=1,2,,T\)do  Observe the contextual variable \(_{t}\);  Choose \(_{t}=_{}\{_{t-1}( ;_{t})+_{t}^{1/2}_{t-1}(; _{t})\};\)  Sample \(y_{t}\) at \((_{t},_{t})\);  Update \((}_{t},_{t},_{;t}^{2})\) as in (5) ; endfor ```

**Algorithm 1** NN-AGP-UCB

## 3 Statistical properties

### Specification of NN-AGP

We describe the NN-AGP model here, which is employed as the surrogate for the reward function. Recall that the reward function with the pair of contextual and decision variables \((,)\) is \(f(;)=()^{}()\), where \(()\) is a vector-valued neural network (with weight parameters \(\)) from \(^{d^{}}\) to \(^{m}\) and \(()\) is an \(m\)-dimensional output Gaussian process defined on \(^{d}\). To be more specific, the \(m\) outputs \(=(_{1},,_{m})^{}\) are assumed to follow a multi-output Gaussian process (MGP) as

\[()(,( ,^{})).\]

Here, \((,^{})\) denotes the covariance matrix of \(()\) and \((^{})\), defined as \((,^{})([ ]{ccc}K_{11}(,^{})&&K_{1m}( ,^{})\\ &&\\ K_{m1}(,^{})&&K_{mm}(, ^{}))\) which is positive and semi-definite. The \((l,l^{})\)-th entry \(K_{ll^{}}(,^{})\) represents the covariance (similarity) between outputs \(_{l}()\) and \(_{l^{}}(^{})\). The NN-AGPmodel results in a scalar-valued Gaussian process with both the contextual and decision variables and therefore facilitates explicit acquisition functions and theoretical analysis. This GP representation arises from the linear structure between the MGP and the mapping \(()\).

To specify the covariance matrix, we adopt the collaborative multi-output Gaussian process model  as a representative, which generalizes the commonly-used linear model of coregionalization (LMC) and the intrinsic coregionalization model (ICM); see . That is, the MGP is determined by the linear transformation of multiple independent scalar-valued Gaussian processes as

\[_{l}()=_{q=1}^{Q}a_{l,q}u_{q}()+v_{l}( ).\] (4)

Here, \(_{l}()\) is the \(l\)-th element of \(()\), \(Q\) is the number of involved GP's, \(\{u_{q}()\}_{q=1}^{Q}\) and \(\{v_{l}()\}_{l=1}^{m}\) are independent scalar-valued GP's, and the \(a_{l,q}\)'s are coefficient parameters. In this way, the correlation between different entries in the MGP \(()\) is captured by \(\{u_{q}()\}_{q=1}^{Q}\) through the \(a_{l,q}\)'s. Morever, \(v_{l}()\) represents specific independent features of \(_{l}()\) itself, for \(l=1,2,,m\). Suppose the kernel functions of the \(u_{q}()\)'s and \(v_{l}()\)'s are \(k_{q}(,^{})\)'s and \(_{l}(,^{})\)'s and all these kernel functions are less than or equal to one, as is regularly assumed . Then the matrix-valued kernel function of \(()\) is \((,^{})=_{q=1}^{Q}_{q}k_{q}(,^{})+\{ _{1}(,^{}),,_{m }(,^{})\}.\) Here, \(_{q}\) denotes the semi-definite matrix in which the \((l,l^{})\)-th entry is \(a_{l,q}a_{l^{},q}.\) In some applications, the parameters involved in the kernel functions \(k_{q}(,^{})\) and \(_{l}(,^{})\), and the coefficients \(a_{l,q}\)'s are not known in advance. We denote these unknown parameters and coefficients in the MGP as \(\). In addition to the model (4), other types of MGP's can be employed in our methodology as well , while the selection of model (4) enables the theoretical analysis of our approach.

In terms of the mapping \(()\), since we have no prior knowledge, we select the neural network as the surrogate model, due to 1) its strong approximation power for intricate dependence on complex variables; 2) its flexibility of adaptation to different application scenarios (e.g. time-series or graph-structured contextual variables) and 3) the availability of fruitful methods and tools for the training procedure. Given the data \(_{t}=\{(_{1},_{1},y_{1}),( _{2},_{2},y_{2}),,(_{t}, _{t},y_{t})\},\) the learning of unknown parameters in the MGP and the weight parameters in the neural network (as well as the noise variance) is through maximum likelihood estimation (MLE). That is

\[(}_{t},_{t},_{;t}^{2})= _{(,,_{}^{2})}L_{t}(,,_{}^{2}),\] (5)

where the (normalized) likelihood function is \(L_{t}=-[|_{_{t}}+_{}^{2}I_{t} |]-_{t}^{}[_{_{t}}+_{ }^{2}I_{t}]^{-1}_{t}.\) Here, \(_{t}=(y_{1},y_{2},,y_{t})\) is the vector of observations and \(_{_{t}}\) is the covariance matrix of the data \(_{t}\). The parameters \(\) and \(\) are contained in this covariance matrix. That is, instead of pre-defining a kernel function of the GP, the kernel function of NN-AGP is specified through learning the neural network from the data, yielding better approximation accuracy. We include a discussion of the consistency of training NN-AGP in the supplements.

### Cumulative regret

Recall that the cumulative regret is defined as \(_{T}=_{t=1}^{T}\{_{^{}}f (^{},_{t})-f(_{t},_{t})\}\). Here we provide an upper bound of \(_{T}\) with NN-AGP-UCB.

**Theorem 1**.: _Suppose \((0,1)\) and the following._

1. _The decision variable_ \(x[0,r]^{d}\) _and_ \(\) _is convex and compact. The contextual variable_ \(^{d^{}}\) _and_ \(\) _is convex and compact;_ \(g()\) _is a known continuous mapping of_ \(\)_;_ \(()\) _is sampled from a known MGP prior as in (_4_) and the variance of the noise_ \(_{}^{2}\) _is known. That is, these parameters do not need learning and updating from data._2. _For the components of the MGP, there exist constants_ \(\{a_{q}\}_{q=1}^{Q},\{b_{q}\}_{q=1}^{Q},\{_{l} \}_{l=1}^{m},\{_{l}\}_{l=1}^{m}\) _satisfying_ \[\{_{x}|(x)}{ x _{j}}|>L_{q}\} a_{q}e^{-(L_{q}/b_{q})^{2}}; \{_{x}|(x)}{ x_{j}} |>_{l}\}_{l}e^{-(_{l}/_{l})^{2}}\] (6) \( L_{q},_{l}>0\) _and_ \( j=1,2,,d\)_,_ \(q=1,2,,Q\) _and_ \(l=1,2,,m\)_._
3. _We choose as a hyper-parameter in (_3_)_ \[_{t}=2(t^{2}2^{2}/(3))+2d(t^{2 }br),\] _where_ \(d\) _and_ \(r\) _are the dimension and the upper bound of the decision variable,_ \(a=_{q=1}^{Q}a_{q}+_{l=1}^{m}_{l}\)_,_ \(b=_{q=1}^{Q}b_{q}+_{l=1}^{m}_{l}\)_,_ \(=_{}\{|_{l=1}^{m}_{l}( {})a_{l,q}|\}_{q=1}^{Q},\{|_{l}( )|\}_{l=1}^{m}\},\) _where_ \(_{l}\) _denotes the_ \(l\)_-th entry of_ \(()\)_._

_Then the cumulative regret is bounded with high probability as_

\[\{_{T}_{T}}{ (1+C_{}^{-2})}}+}{6},\, T  1\} 1-.\]

_Here \(C=((_{q=1}^{Q}_{l=1}^{m}a_{l,q}^{2})+1)_{ }\|()\|_{2}^{2}\). In addition, \(_{T}\) is the maximum information gain associated with the NN-AGP \(f(;)\), defined by (7)._

We postpone the discussion of the maximum information gain \(_{T}\) to Section 3.3, with some specific kernels employed in the MGP component of the NN-AGP model. We note that GP's with commonly-selected kernel functions, including the Matern kernel and the radial basis function kernel, satisfy the condition (6) and further discussions can be found in **Theorem 5** in . A detailed proof of **Theorem 1** is contained in the supplements. Note that **Theorem 1** assumes that \(()\) is exactly known so does not consider the error of approximating \(()\) with the neural networks. In the supplements, we include a detailed discussion of the algorithm that considers the neural network approximation error, as well as the corresponding regret bounds.

At the end of this section, we compare our regret bound with existing work. Specifically, NN-AGP-UCB has the same bound of \(}(})\) as CGP-UCB, but is superior when the contextual variable dimension is high; see details in the supplements. In terms of the algorithms which entirely rely on NN, we note that NeuralUCB , Neural TS , and Neural LinUCB  all consider the scenarios when the decision variable \(\) is selected from a finite set. In comparison, we consider that \(\) is selected from a continuous set. When performed on a finite feasible set \(\), our NN-AGP-UCB also has a regret bound of \(}(})\), where the maximum information gain \(_{T}\) further depends on the kernel function of the GP component used in NN-AGP. When the kernel function has an exponential eigendecay (see Definition 1), NN-AGP-UCB has a regret bound of \(}()\), matching the regret bound of NeuralUCB, Neural TS and Neural LinUCB as well.

### Maximum information gain

In this section, we discuss the information gain \(_{T}\) of the proposed NN-AGP model. The maximum information gain is defined as

\[_{T}=_{\{\{_{t},_{t}\}\}_ {t=1}^{T}}I(_{T};f_{T}),\] (7)

where \(f_{T}\) is the reward function evaluated at \(\{(_{t},_{t})\}_{t=1}^{T}\); \(_{T}\) denotes the observations; \(I(_{T};f_{T})=H(_{T})-H(_{T} f_{T})\) is the mutual information between \(_{T}\) and \(f_{T}\); \(H(\,\,)=[- p(\,\,)]\) is the entropy of a random element, where \(p\) is the probability density function.

For ease of notation, here we consider the scenario when \(Q=1\) and there is no \(\{v_{l}()\}\) in the MGP defined in (4), i.e., \(_{l}()=a_{l}u()\). We also impose more variability so that \(=_{1}\) is a semi-definite positive matrix and not necessarily a rank-one matrix, analogous to . We provide a more general discussion of the maximum information gain of the NN-AGP in the supplements. We first provide a proposition on the kernel function.

**Proposition 2**.: _When \(Q=1\) and there is no \(\{v_{1}()\}\) in the MGP, the kernel function of the NN-AGP is a product of two kernel functions. That is \(((,),(^{},^{ }))=(,^{})k(, ^{}),\) where \((,^{})=()^{}()\) is a finite rank kernel with respect to \(\). Furthermore, suppose that both \(\) and \(\) are compact, \(()\) is a continuous mapping and \(k(,^{})\) is a semi-definite kernel function. Then the kernel function \(((,),(^{},^{ }))\) possesses a Mercer decomposition:_

\[((,),(^{},^{ }))=_{j=1}^{}_{i=1}^{m}_{i}_{j}_{i} ()_{j}()_{i}(^{})_{j}(^{}).\]

_Here, \(\{(_{i},_{i})\}_{i=1}^{m}\) and \(\{(_{j},_{j})\}_{j=1}^{m}\) are the Mercer decompositions for \((,^{})\) and \(k(,^{})\). That is, \((,^{})=_{i=1}^{m}_{i} _{i}()_{i}(^{}),k( ,^{})=_{j=1}^{}_{j}_{j} ()_{j}(^{}),\) where the eigenvalues are \(_{1}_{2}_{m} 0\) and \(_{1}_{2} 0\)._

With the Mercer decomposition of the NN-AGP kernel function, we provide the bound of the maximum information gain. Specifically, we consider two scenarios for the employed kernel in the MGP, analogous to .

**Definition 1**.: _Consider the eigenvalues \(\{_{j}\}_{j=1}^{}\) of the kernel function \(k(,^{})\) in decreasing order._

* _For some_ \(C_{p}>0,_{p}>1,k\) _is said to have a_ \((C_{p},_{p})\) _polynomial eigendecay, if for all_ \(j\)_, we have_ \(_{j} C_{p}j^{-_{p}}\)_. An example is the Matern kernel._
* _For some_ \(C_{e,1},C_{e,2},_{e}>0,k\) _is said to have a_ \((C_{e,1},C_{e,2},_{e})\) _exponential eigendecay, if for all_ \(j,\) _we have_ \(_{j} C_{e,1}(-C_{e,2}j^{_{e}})\)_. An example is the radial basis function kernel._

**Theorem 2**.: _Suppose that 1) \(((,),(^{},^{ }))\) satisfies the conditions in **Proposition 2**; 2) \(,^{},|k(, ^{})|\) for some \(>0\) and 3) \(,\), \(|_{j}()|\), for some \(>0\). If \(k(,^{})\) has a \((C_{p},_{p})\) polynomial eigendecay, then_

\[_{T} m((^{2}^{2}C_{p}T}{_ {e}^{2}}^{-1}(1+}T}{m_{e}^{2}}) )^{}}+1)(1+}T}{ m_{e}^{2}}).\]

_If \(k(,^{})\) has a \((C_{e,1},C_{e,2},_{e})\) exponential eigendecay, then_

\[_{T} m((}((T)+C_{_{e} }))^{}}+1)(1+} T}{m_{e}^{2}}),\]

_where_

\[C_{_{e}}=\{ &(m^{2} ^{2}}{_{e}^{2}C_{e,2}})_{e}=1\\ &(m^{2}^{2}}{_{e}^{2} C_{e,2}})+(}-1)((} (}-1))-1).\]

_Here, \(=_{i=1}^{m}_{i}\) denotes the mean of the eigenvalues of the kernel function \((,^{})\); \(}=_{,^{}}| (,^{})|\) and \(=_{}|()|\). Moreover, the maximum information gain of the NN-AGP is \((m_{;T})\), where \(_{;T}\) is the maximum information of \(k(,^{})\)._

A more detailed discussion of the Mercer decomposition of NN-AGP is contained in the supplements, as well as the proofs of **Proposition 2** and **Theorem 2**. At the end of this section, we compare our results on maximum information gain with . For the composite kernel that is a product of two kernels, the upper bound is \((d+d^{})_{;T}+(d+d^{}) T\). Here, \(_{;T}\) is the maximum information gain of the kernel function with the decision variable, and \(d^{}\) and \(d\) are the dimensions of the contextual variable and the decision variable. That is, the information gain (as well as the cumulative regret) increases as the dimension of the contextual variable increases. In comparison, the maximum information in **Theorem 2** does not depend on \(d^{}\). Thus, the NN-AGP model has lower cumulative regret than the classical strategy in  when the dimension of the contextual variable is relatively high.

Experiments

In this section, we conduct experiments to show the practicality of our neural network-accompanied Gaussian process upper bound confidence (NN-AGP-UCB) approach. We apply different neural networks to different problems, including the fully-connected neural network (FCN)  to a synthetic reward function, the long short-term memory (LSTM)  neural network to a queuing problem with time sequence contextual variables, and the graph convolutional neural network (GCN)  to a pricing problem with diffusion networks. We add a noise \(_{t}(0,0.01)\) to the ground-truth value of the reward in the first set of experiments. For the latter two sets of experiments, the reward is generated by stochastic simulation (and therefore is "black-box" with contextual/decision variables) and we postpone the description of the full dynamic to the supplements. We also provide additional experiments in the supplements, including 1) sensitivity on the structure of reward functions; 2) comparison with contextual variables possessing different dimensions; 3) regression tasks on complex functions and 4) finite decision/contextual variables with real data.

The baseline approaches includes CGP-UCB , NeuralUCB  and NN-UCB . The experiment results provided are mean performances based on repeating the experiments 15 times. Standard deviations (represented by a shadow associated with the mean-value line) are also included. In each iteration, the exogenous contextual variable \(_{t}\) is randomly selected from \(\) with equal probability. In terms of the initialization, we randomly select decision variables independently of observed contextual variables for each approach in the first 20 iterations to attain surrogates. The specific description of the employed surrogate model in each approach is postponed to the supplements.

### Synthetic reward function

In this section, we consider two synthetic reward functions

\[R_{1}(,) =-\|)^{3}( (\|\|+\|\|))|};\] \[R_{2}(,) =-\|)^{3}(\|\|+ (\|\|))|}.\]

For NN-AGP-UCB, we consider \(m=2,3,5\) to study the effects of model selection on the algorithm performance. For CGP-UCB, we consider both additive kernels and multiplicative kernels. Because both NeuralUCB and NN-UCB are designed for contextual bandits with finite arms, we adapt them to the problem we consider in Section 2 and postpone the details to the supplements. The experimental results of the average regret \(_{T}/T\) are illustrated in **Figure 1** and **Figure 2**, which provide the following insights. **1. Comparison with baseline approaches.** For both reward functions, NN-AGP-UCB outperforms both the CGP-UCB and NN-based approaches. The advantage comes from 1) strong approximation power regarding \(\) due to NN and 2) explicit inference regarding \(\) due to GP. **2. Effects of the dimension \(m_{*}\)** Generally, when \(m\) increases, the model flexibility increases, and the regret might be smaller, although this improvement might not be significant in some scenarios. Furthermore, a relatively large \(m\) might result in overparameterization especially when there are not enough iterations. A suggested selection of \(m\) is \([d/3+d^{}/10]+3\) considering both the algorithm performance and training complexity of models. **3. Breaking the linear assumption.** Recall that we assume the reward function is of the form of \(R(;)=()^{}\, ()\). However, the reward functions here break this linear assumption and yet our NN-AGP-UCB is still applicable and outperforms the baseline approaches. Moreover, additional experiments show that NN-AGP 1) is not sensitive on the structure of the reward functions; 2) has a greater advantage with higher-dimensional contextual variables and 3) achieves better approximation accuracy for complex functions, compared with a joint GP with composite kernels; see the supplements for details. In addition, when the dimension of the input increases, the uncertainty of the regret will increase as well; see **Figures 1 & 2** for comparison. We also include the recorded computational time of these bandit algorithms in the supplements.

### Queuing problem with time sequence contextual variables

In this section, we show through experiments that the NN-AGP model is applicable to contextual GP bandits when the objective function depends on the sequence of the contextual variables. That is, the reward function at time \(t\) can be approximated by

\[f_{t}(;_{1},_{2},,_{t} )_{t}(_{1},_{2},,_{t})^{}().\]Here, \(_{t}(_{1},_{2},,_{t})\) is modeled by an LSTM neural network. We consider a discrete-time queuing problem. In each time epoch, a contextual variable is first revealed. For example, the contextual variable might includes traffic and weather conditions that affect the arrival process of the queuing system. The number of customers arriving at this epoch depends on the entire sequence of the revealed contextual variables up to now. The agent decides the service rate of the server and the service price for customers (decision variables). The reward function (might be negative) is the expected net income (the income brought by serving customers minus the service cost and penalty for losing customers). We let \(=^{2}\) and sample \(_{t}\) from multivariate normal distributions. We present the cumulative rewards in **Figure 3** and **Figure 4** of NN-AGP-UCB with LSTM. The baseline CGP-UCB adopts both additive and multiplicative kernels with the current contextual variable. We also apply kernel functions specifically designed for time series  to construct the composite kernel. Experimental results indicate that 1) employing a specific time series kernel enhances the performance of CGP-UCB and 2) NN-AGP-UCB with LSTM outperforms the classical CGP-UCB approaches with different composite kernels.

### Pricing with diffusion network

In this section, we show the NN-AGP model is applicable to contextual GP bandits with graph-structured contextual variables. That is, the contextual variable is summarized by a network structure

\[_{t}=(V_{t},E_{t}),\]

where \(V_{t}\) denotes the set of nodes and \(E_{t}\) denotes the set of directed/undirected edges of a network. To approximate \(()\) with a graph-structured contextual variable, we apply the GCN model. We consider a pricing problem with a diffusion network, where each node represents a user who decidesto adopt a service or not and the edge between two nodes indicates whether the choices of these two users influence each other. In each iteration, the network structure \(_{t}\) is first presented, and then the agent decides the price of the service. The reward function is the expected income for the service adoption from the users. The detailed description can be found in . We let \(=\) and \(_{t}\) represents an undirected graph with 5 and 10 nodes where each edge exists with probability 1/2. We present the cumulative rewards in **Figure 5** and **Figure 6** of NN-AGP-UCB with GCN. The baseline CGP-UCB adopts both additive and multiplicative kernels and in terms of the contextual variable, we consider 1) vectorizing the adjacency matrix that summarizes the network structure and 2) applying kernel functions that are specifically designed for graphs . Experimental results indicate that NN-AGP-UCB with GCN outperforms the classical CGP-UCB approach adopting different kernels, and the advantages become greater for networks with more nodes.

## 5 Conclusion & impact

We propose a neural network accompanied Gaussian process (NN-AGP) model to address contextual GP bandit problems. The advantages of our approach include 1) flexibility of employing different neural networks appropriate for applications with diverse structures of contextual information; 2) approximation accuracy for the reward function and better performance on cumulative rewards/regrets; 3) tractability of a GP representation regarding the decision variable, thus supporting explicit uncertainty quantification and theoretical analysis. Our approach has potential application to healthcare, where doctors need to develop therapy plans based on patient information to achieve optimal treatment effects. When complex and sparse genetic information is employed, it necessitates the use of neural networks. Another potential application is for Automated Guided Vehicles (AGVs) to enhance workplace safety and reduce carbon emissions, where environmental information is provided to the AGV, and the AGV takes actions accordingly.

In terms of limitations, since NN-AGP retains a GP structure, it suffers from computational complexity with large data sets. To alleviate the computational burden, we consider sparse NN-AGP for future work; see a discussion in the supplements. In addition, incorporating NN into bandit problems generally requires sufficient data to approximate the unknown reward function, thereby bringing the cold-start issue to NN-AGP. To address the challenge, we also include a discussion on employing transfer learning technologies in the supplements. Other potential future work includes 1) adapting NN-AGP to multi-objective/constrained optimization problems and 2) employing NN-AGP in a federated contextual bandit problem with multiple decentralized users.