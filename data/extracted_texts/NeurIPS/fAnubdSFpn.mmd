# A PID Controller Approach for Adaptive

Probability-dependent Gradient Decay in Model Calibration

Siyuan Zhang

School of Internet of Things Engineering

Jiangnan University

Wuxi, China 214122 &Linbo Xie

School of Internet of Things Engineering

Jiangnan University

Wuxi, China 214122

Linbo Xie

School of Internet of Things Engineering

Jiangnan University

Wuxi, China 214122

Linbo Xie

School of Internet of Things Engineering

Jiangnan University

Wuxi, China 214122

###### Abstract

Modern deep learning models often exhibit overconfident predictions, inadequately capturing uncertainty. During model optimization, the expected calibration error tends to overfit earlier than classification accuracy, indicating distinct optimization objectives for classification error and calibration error. To ensure consistent optimization of both model accuracy and model calibration, we propose a novel method incorporating a probability-dependent gradient decay coefficient into loss function. This coefficient exhibits a strong correlation with the overall confidence level. To maintain model calibration during optimization, we utilize a proportional-integral-derivative (PID) controller to dynamically adjust this gradient decay rate, where the adjustment relies on the proposed relative calibration error feedback in each epoch, thereby preventing the model from exhibiting over-confidence or under-confidence. Within the PID control system framework, the proposed relative calibration error serves as the control system output, providing an indication of the overall confidence level, while the gradient decay rate functions as the controlled variable. Moreover, recognizing the impact of gradient amplitude of adaptive decay rates, we implement an adaptive learning rate mechanism for gradient compensation to prevent inadequate learning of over-small or over-large gradient. Empirical experiments validate the efficacy of our PID-based adaptive gradient decay rate approach, ensuring consistent optimization of model calibration and model accuracy. The code of implementation is available in [https://github.com/UHIF/PID_AGD](https://github.com/UHIF/PID_AGD).

## 1 Introduction

Model calibration aims to refine the uncertainty distribution of model output, ensuring its faithful reflection of the inherent uncertainty characteristics. Softmax mapping is commonly employed in the baseline learning to establish the output-probability mapping. Yet, with the escalation in model parameterizations, the output uncertainty distribution from over-parameterized models tends to become over-confident . Consequently, the baseline strategy, which exclusively depends on Softmax mapping without accounting for calibration characteristics as optimization objectives, fails to achieve perfect model calibration. Particularly in high-risk applications, inadequate model calibration poses heightened safety risks .

There are three primary strategies for calibrating uncertainty in deep learning models: Bayesian neural networks, post-processing calibration, and training-based model calibration. Bayesian neural networks (BNNs) integrate Bayesian inference into their framework, distinguishing them from traditional neural networks . In contrast to conventional neural networks, which yield point estimates,BNNs offer a probability distribution across potential outputs, enabling uncertainty quantification in predictions . This is accomplished by assigning prior distributions to the network's parameters and iteratively updating these distributions using Bayes' theorem as more data is acquired.

The post-processing calibration methods involve establishing the additional output-probability relationship through supplementary mappings to refine output uncertainty distribution [7; 8; 9]. This calibration method avoids disrupting the original model's decision-making pertaining to the primary task, maintaining the original generalization performance . However, a notable drawback emerges: the necessity of additional structure to establish the mapping between outputs and probabilities . This task possesses unique characteristics, demanding calibrated properties to construct output-probability mapping structures, optimization goals, and strategies. Unlike typical loss functions and metrics in machine learning, uncertainty is sample-specific; however, validating it individually is infeasible . Furthermore, when validated collectively, it fails to fully represent individual sample properties, presenting challenges in calibrating individual sample. This presents a difficulty in calibrating model confidence via post-processing structures [13; 14].

Another approach to model calibration involves integrating various elements into the baseline optimization strategy for deep learning . This enhancement of elements during the optimization leads to an improvement in the uncertainty distribution of the model output. These methods encompass a range of techniques including pre-training , data augmentation , label smoothing , weight decay , early stopping , structure sparsity , convolutional structure , and others. These methods not only bolster the calibration of the model and refine the output uncertainty distribution but also delve into the dynamic attributes of the model optimization, thereby enhancing decision-making. Additionally, they improve the interpretability in the decision-making and optimization process. Furthermore, certain loss functions for model output distribution have been devised based on uncertainty properties. These include MMCE , Correctness Ranking Loss , CALS , Focal loss [23; 24], and FLSD . They jointly address classification accuracy and confidence calibration to mitigate the inclination of the over-confidence and under-confidence.

In the optimization of Softmax-based cross-entropy loss, model accuracy and model calibration represent distinct optimization characteristics . Model calibration tends to be overfitting earlier in the optimization compared to accuracy . To ensure consistent optimization between model accuracy and calibration, it is imperative to achieve high accuracy while maintaining adequate calibration. Our approach introduces a hyperparameter that controls the gradient decay rate within the Softmax output-probability mapping. It indicated a negative correlation between the gradient decay rate with increasing instance-level probability and the overall confidence distribution . To achieve consistent optimization of accuracy and calibration, we propose detecting model calibration through a validation set in the optimization process. Drawing inspiration from the notable success of proportional-integral-derivative (PID) controllers in automatic control systems , we introduce an Adaptive Probability-dependent Gradient Decay through PID controller approach to calibrate the model. Moreover, considering that probability-dependent gradient decay rate may impact gradient amplitude, we design a dynamic learning rate mechanism corresponding to the changing gradient decay rate to offset fluctuations in gradient amplitude.

Our main contributions in this work can be summarized as follows: (1) We propose adaptive probability-dependent gradient decay via PID controller. This approach utilizes the feedback mechanism from automatic control to detect model calibration and adjust the probability-dependent gradient decay rate coefficient in Softmax, ensuring consistent optimization of model calibration and accuracy. (2) To counteract fluctuations in gradient magnitude caused by the adaptive probability-dependent gradient decay rate, we introduce a dynamic learning rate schedule to follow the dynamic decay rate. (3) Empirical experiments confirm the effectiveness of our approach, achieving improved model calibration while maintaining the model's generalization ability.

## 2 Problem formulation

### Model calibration

Considering a dataset \(\{(x^{i},y^{i})\}_{i=1}^{N}^{n} ^{m}\) and classifier \(f\) maps \(x\) to the outputs \(z_{j},j=1,,m\) on \(m\) classes and \(k=*{arg\,max}_{j}z_{j}\). The ground-truth \(y\) and predicted labels \(\) are formulated in one-hot format where \(y_{c}=1\) and \(_{k}=1\), where \(c\) represents the truth class. The associated confidence score of the predicted label in baseline is \(= s_{j}(z),j=1,,m\), where \(s()\)reflected in the properties of model output . The probability estimation of modern deep models may show over-confidence or under-confidence.

**Confidence Calibration** Perfect calibration of neural network can be realized when the confidence score reflects the real probability that the classification is classified correctly. Formally, the perfectly calibrated network satisfied \((=y|=p)=p\) for all \(p[0,1]\). However, in practical applications, the sample is divided into \(M\) bins \(\{D_{b}\}_{b=1}^{M}\). The limited availability of data restricts the ability to accurately estimate the calibration error. According to their confidence scores and the calibration error, an approximation is calculated for each bins \(\{D_{b}\}_{b=1}^{M}\). \(D_{b}\) contains all sample with \([,)\). Average confidence is computed as \(conf(D_{b})=|}_{i D_{b}}^{i}\) and the bin accuracy is computed as \(acc(D_{b})=|}_{i D_{b}} (y_{c}^{i}=_{c}^{i})\). ECE and MCE  are calculated as follows.

\[ECE=_{b=1}^{M}|}{N}|acc(D_{b})-conf (D_{b})| \]

\[MCE=_{b\{1,,M\}}|acc(D_{b})-conf( D_{b})| \]

### Parametric Softmax

Softmax cross-entropy (CE) is expressed as

\[J=-}}{_{j=1}^{m}e^{z_{j}}} \]

We introduce two hyperparameters in the Softmax mapping, which is expressed as follows:

\[J=-/}}{_{j c}e^{z_{j}/}+ e^{z_{c}/}} \]

The parametric Softmax cross-entropy can be approximated as the following max function, as shown in (5). Minimizing this max function is expected that output \(z_{c}\) can be larger than other class outputs \(z_{j},j=1,,m,j c\), which is in line with the logic of the one-versus-all classification decision-making \(cls(z(x))=\{z_{j}(x)\},j=1, ,m\).

\[_{ 0}\,-/}}{_{j c}e^{z_{j}/}+ e ^{z_{c}/}}=_{ 0}\{,z_{j}-z_{c}/,j=1, ,m,j c\} \]

The temperature coefficient \(\) has been extensively investigated in model calibration. Temperature scaling represents a commonly utilized calibration technique in post-processing calibration methods. \(\) is regarded as a soft margin, with its approximation procedure detailed in Eq. (5). Consequently,

Figure 1: The gradient magnitude of different gradient decay \(\) with increasing probability \(p_{c}\).

CE can be interpreted as a margin-based loss function. Nonetheless, due to the distance distortion between input and representation spaces, maximizing the margin in the input space of models is not achieved simultaneously by large margin Softmax. Consequently, its dynamic characteristic in the optimization process tends to be ambiguous.

### Probability-dependent gradient decay

Considering the Softmax with the sole hyperparameter \(\), the temperature \(\) is set to 1.

\[J=-}}{_{j c}e^{z_{j}}+ e^{z_{c}}} \]

Let us first consider the gradient of the Softmax.

\[}=-}-e^{z_{c}}}{ e^{z_{ j}}+(-1)e^{z_{c}}} \]

\[}=}}{ e^{z_{j}}+(- 1)e^{z_{c}}} \]

Introducing probabilistic output \(p_{j}=}}{e^{z_{1}}++e^{z_{m}}}\) as an intermediate variable, we obtain

\[}=-}{1+(-1)p_{ c}},j=c\\ }{1+(-1)p_{c}},j c \]

Fig. 1 illustrates how the introduced hyperparameter \(\) determines the gradient decay rate as the instance-level probability increases. More empirical experimental results can be found in the Appendix A.2. A smaller \(\) results in a reduced decay rate of gradient amplitude corresponding to probability. Empirical investigations have shown that the magnitude of \(\) during optimization determines the average confidence level and consequently impacts the calibration performance of the model. Fig. 2 demonstrates that a low gradient decay rate exacerbates the over-confidence in the model's output, whereas a high gradient decay rate can alleviate this issue and yield improved calibration results .

Figure 2: **Confidence and reliability diagrams with ResNet18 on CIFAR-100.** (\(bins=10\)) In each subplot, the left plot illustrates the sample distribution in individual bins, while the right plot displays the average confidence and accuracy in each bin. Ideally, calibration aims for consistency between accuracy and average confidence in each bin. It indicates that a smaller gradient decay rate \(\) is associated with more pronounced miscalibration of the model, while a larger gradient decay rate mitigates this issue.

## 3 Methodology

The probability-dependent gradient decay rate exhibits a negative correlation with the model's average confidence, as shown in Fig. 2 and Appendix A.2. Higher gradient decay rates result in a concave reduction in gradient magnitude as the sample confidence increases, thereby yielding a smoother distribution of confidence. Although high gradient decay rates can mitigate over-confidence distributions for samples, excessively small or large gradient magnitudes may lead to inadequate optimization. Consequently, we propose an adaptive gradient decay rate by a PID controller to ensure model calibration on optimization. Additionally, we propose a variable learning rate schedule to adjust the gradient and counterbalance the impact of fluctuating gradient decay rates on gradient magnitude. The whole framework is shown in Fig. 3.

### PID controller approach for adaptive probability-dependent gradient decay

Our approach focuses on regulating the gradient decay rate by monitoring the average confidence and accuracy within each bin of the validation set throughout model optimization. This aims to enhance the model's calibration and dynamic properties during optimization. Eq. (1) specifies the desired calibration by representing only the absolute value of the difference between average confidence and accuracy within each bin. However, it fails to capture the under-confidence and over-confidence in model calibration. Therefore, we propose a Relative Calibration Error (RCE) to reflect over-confidence and under-confidence:

\[RCE=_{b=1}^{M}|}{N}(conf(D_{b})- acc(D_{b})) \]

In the control system depicted in Fig. 3, RCE serves as the output, with the gradient decay coefficient acting as the controlled variable. The target RCE value is set to 0. During each iteration, the model processes the validation set to calculate the RCE. If the RCE is greater than 0, it indicates over-confidence in the probability distribution, necessitating an increase in the gradient decay rate during model optimization. Conversely, if the RCE is less than 0, it signifies under-confidence in the probability distribution, prompting a decrease in the gradient decay rate. The PID controller determines the specific adjustment required for the gradient decay coefficient \(\). A PID controller continually computes an error \(e(t)\), representing the disparity between the desired optimal RCE and the control system output. It then applies a correction \(u(t)\) to the system, incorporating proportional (\(P\)), integral (\(I\)), and derivative (\(D\)) terms of \(e(t)\). Mathematically, there is:

\[u(t)=K_{p}e(t)+K_{i}_{0}^{t}e(t)dt+K_{d} e(t) \]

Figure 3: The framework of PID controller-based adaptive probability-dependent gradient decay.

where \(K_{p}\), \(K_{i}\) and \(K_{d}\) are the gain coefficients on the \(P\), \(I\) and \(D\) terms, respectively. The coefficients \(K_{p}\), \(K_{i}\) and \(K_{d}\) determine the contributions of present, past and future errors to the current correction. \(e(t)=-RCE(t)\) represents the error of the \(t\) th optimization epoch. Since \(0<\), the updating step is described as follows:

\[_{t}=_{t-1}e^{-u(t)} \]

The PID controller is a widely employed feedback control mechanism in engineering and industrial processes [30; 28]. It is utilized in systems requiring precise control over variables. As depicted in Fig. 3, the PID controller is utilized in the model optimization to regulate RCE, ensuring balanced model calibration and mitigating overfitting compared to model accuracy within the baseline strategy. As depicted in (11), the PID comprises three terms: the proportional (\(P\)) term, integral (\(I\)) term, and derivative (\(D\)) term. Firstly, the proportional (\(P\)) action ensures that the controller responds proportionally to the current error. It provides an immediate correction to minimize the RCE. Secondly, the integral (\(I\)) action continuously integrates the error over time and adjusts the control signal accordingly, eliminating any steady-state error. It eliminates any steady-state error by gradually reducing the cumulative error to zero. Thirdly, the derivative (\(D\)) action anticipates the future behavior of the error by considering its rate of change, damping oscillations and overshoots to improve system stability and transient response. PID controllers play a crucial role in maintaining stability, accuracy, and efficiency in ensuring precise model calibration by adjusting probability-dependent gradient decay in model optimization.

### Adaptive learning rate for gradient compensation

Changes in the probability-dependent gradient decay rate significantly impact model calibration because varying decay rates change dynamic characteristic on the optimization for different samples. While a large gradient decay rate can maintain a similar confidence level in optimizing both high-confidence and low-confidence samples, a small decay rate results in a curriculum learning sequence where confidence in low-confidence samples increases only when confidence in high-confidence samples reaches a certain threshold. Nonetheless, varying decay rates also lead to changing gradient magnitudes, thereby influencing model optimization. For instance, a small gradient at the outset of optimization could result in insufficient optimization, thereby diminishing the model's generalization. To mitigate the influence of gradient magnitude fluctuations on model optimization, we implement a dynamic learning rate to counteract the impact of gradient fluctuations caused by varying \(\).

Since \(|}|+_{j c}|}|=2|} |\), \(|}|\) can represent the gradient magnitude of the sample in output layer. Building on (9), we establish a metric to quantify the magnitude of the gradient at that specific gradient decay rate \(\):\[(t)=_{0}^{1}}{1+(_{t}-1)p_{c}}dp_{c} \]

Since \(>0\), we obtain

\[(t)=\{_{t}- _{t}+1}{(_{t}-1)^{2}}&_{t} 1\\ 0.5&_{t}=1. \]

The learning rate, adjusted to account for the gradient dynamics over \(t\) epoch, is modified according to the following formula:

\[(t)=(t-1)(t-1)/ (t) \]

where \((t)\) is learning rate of \(t\) th optimization epoch. The assumption underlying the gradient compensation proposed in (13)-(15) relies on the uniform distribution of samples within the probability interval \(\). Integrating \(|}|\) within the probability range \(\) approximates the variation in gradient amplitudes across different gradient decay coefficients \(\). However, this assumption may not hold true during the optimization process. Nonetheless, this simple adaptive learning rate approach can effectively mitigate the issue of excessively small gradients resulting from overly large gradient decay rates. When the magnitude decreases, learning rate increases accordingly to compensate for the change in gradient amplitude. The whole Adaptive Probability-dependent Gradient Decay method by PID controller (PID-AGD) for model calibration is described in Algorithm 1.

## 4 Empirical experiments

The experimental validation comprises four main components. Firstly, we assess the performance of our algorithm and other calibration methods in terms of model calibration. Secondly, we compare the accuracy and model calibration results of our method with those obtained using different loss functions in supervised learning. Thirdly, we conduct ablation experiments on the proportional term \(K_{p}\), integral term \(K_{i}\), and differential term \(K_{d}\) across PID controller. Finally, we conducted the ablation experiment with different optimizers to verify the effectiveness of the adaptive learning rate for gradient compensation.

**Train setting** The baseline models include ResNet and VGG variants. The datasets comprised SVHN, CIFAR-10/100, 102 Flower and Tiny-ImageNet. In CIFAR-10/100, the training set contained 40,000 images, with testing and validation sets comprising 10,000 images each. The ratio of training set, validation set and test set in 102 Flower is 2:1:1 respectively. For Tiny-ImageNet, 100,000 images were used for training, and 10,000 images for testing and validation. SVHN utilized 58,606 training

Figure 4: **Confidence histograms and reliability diagrams for different calibration methods with ResNet35 on CIFAR-100. In each subplot, the left plot illustrates the sample distribution in individual bins, while the right plot displays the average confidence and accuracy in each bin. Our training calibration can improve performance on confidence estimate.**

images, 14,651 validation images, and 26,032 testing images. VisDrone contains 5471 training images, 1548 validation images and 3190 testing images. COCO utilized 82,783 training, 40,504 validation, and 40,775 testing images. In all classification experiments, the learning rate, momentum and weight clipping were set to 0.1, 0.9 and Norm=3, respectively. The learning rate decreased to 10% at 40% and 80% of the iterations, with weight decay set to \(10^{-4}\) and a total of 200 iterations. For Tiny-ImageNet, the learning rate was set to 0.01 with a batch size of 64. The number of bins in all calibration metric are set to 10. \(P\), \(I\) and \(D\) in our method are set to 1, 0.1, 1.

### Calibration performance with other calibration methods

The experiments in this subsection aim to validate the efficacy of our proposed calibration method against baseline calibration methods, which employs PID control of the gradient decay rate. We compare our approach with other post-processing calibration methods, including Histogram Binning , Temperature Scaling , Vector Scaling, and TS-AvUC . The evaluation metrics employed include ECE , MCE, and Adaptive Expected Calibration Error (AdaECE) . The datasets primarily consist of CIFAR-10/100, SVHN, 102 Flower, Tiny-ImageNet, VisDrone and COCO, while the models predominantly belong to the VGG, ResNet and YOLO series. The comprehensive experimental results are presented in Table 1. The results of the visualization of all methods in ResNet35 on data CIFAR-100 for confidence histograms and reliability diagrams are presented in Fig. 4.

The results presented in Table 1 demonstrate that all methods effectively enhance the calibration of the model. However, post-processing calibration methods rely on an optimized independent output-probability mapping, which doesn't alter the optimization process of the original model itself. Consequently, these methods can solely refine the probability distribution of the model output. Our proposed method surpasses other calibration techniques in terms of overall ECE, MCE, and AdaECE. Therefore, these experimental findings underscore the effectiveness of our approach in enhancing model calibration by dynamically adjusting the gradient decay rate during the model optimization.

   Dataset & Model & Metric & Uncalibrated & High. Buning & Temp. Scaling & Vector Scaling & TS-AvUC & Ours \\   &  & ECE & 0.160\(\)0.025 & 0.025\(\)0.006 & 0.033\(\)0.006 & 0.061\(\)0.012 & 0.028\(\)0.004 & **0.006(\(\)0.019)** \\  & & MEC & 0.344\(\)0.025 & 0.078\(\)0.012 & 0.059\(\)0.011 & 0.138\(\)0.022 & **0.052(\(\)0.007)** & 0.068\(\)0.018 \\  & & AdaECE & 0.160\(\)0.023 & - & 0.030\(\)0.007 & 0.061\(\)0.011 & 0.027\(\)0.006 & **0.007(\(\)0.020)** \\   &  & ECE & 0.172\(\)0.007 & 0.034\(\)0.009 & 0.026\(\)0.004 & 0.056\(\)0.011 & 0.035\(\)0.008 & **0.011(\(\)0.015)** \\  & & MCE & 0.351\(\)0.001 & 0.064\(\)0.010 & **0.058\(\)0.010** & 0.172\(\)0.019 & 0.146\(\)0.025 & 0.053\(\)0.011 \\  & & AdaECE & 0.172\(\)0.028 & - & 0.027\(\)0.006 & 0.053\(\)0.010 & 0.034\(\)0.007 & **0.014(\(\)0.013)** \\   &  & ECE & 0.186\(\)0.003 & 0.025\(\)0.004 & 0.030\(\)0.013 & 0.073\(\)0.021 & 0.052\(\)0.012 & **0.016(\(\)0.009)** \\  & & MEC & 0.407\(\)0.101 & 0.110\(\)0.015 & 0.091\(\)0.022 & 0.153\(\)0.036 & 0

### Consistent optimization in supervised learning

Model accuracy and calibration are typically considered as two independent optimization metrics. In the baseline optimization strategy employing cross-entropy as the loss function, the model calibration tend to overfit earlier than the accuracy. To examine the impact of different optimization strategies on model calibration characteristics, Table 2 illustrates these effects. Comparative algorithms such as cosface , center loss , CE with DCA  and Softmax-based cross-entropy were utilized, and their performance in accuracy and uncertainty estimation was observed. While cosface, center loss, and our proposed approach, showed improvements in accuracy, the former two algorithms did not consider model calibration, resulting in overconfident predictions. DCA regularity improves model calibration but hurts accuracy. Conversely, our proposed PID-based method with variable gradient decay rate ensures both model accuracy and calibration. This reaffirms the significant influence of probability-dependent gradient decay rates on model calibration and overall performance.

### Ablation experiments and analysis for PID controller

In the model optimization, both model optimization and gradient coefficient decay need consideration, constituting a bi-level optimization problem. From a control system perspective, altering the gradient decay rate modifies the dynamic characteristics of subsequent iterations in the model optimization. However, its impact on model calibration may not be fully apparent in the immediate optimization

    &  &  &  \\   & & & ACC (\%) & ECE & MCE & AdaECE & ACC (\%) & ECE & MCE & AdaECE \\   & ResNet18 & 93.7\(\)0.39 & 0.041\(\)0.010 & 0.281\(\)0.076 & 0.042\(\)0.013 & 73.6\(\)0.29 & 0.160\(\)0.026 & 0.344\(\)0.048 & 0.160\(\)0.026 \\  & ResNet35 & 93.9\(\)0.39 & 0.054\(\)0.015 & 0.300\(\)0.083 & 0.054\(\)0.016 & 73.8\(\)0.30 & 0.172\(\)0.022 & 0.351\(\)0.077 & 0.172\(\)0.023 \\  & VGG16 & 92.1\(\)0.41 & 0.066\(\)0.022 & 0.339\(\)0.001 & 0.068\(\)0.023 & 69.2\(\)0.26 & 0.323\(\)0.054 & 0.476\(\)0.112 & 0.236\(\)0.035 \\   & ResNet18 & 93.9\(\)0.45 & 0.053\(\)0.011 & 0.352\(\)0.072 & 0.055\(\)0.013 & 74.2\(\)0.51 & 0.185\(\)0.046 & 0.501\(\)0.162 & 0.183\(\)0.050 \\  & ResNet35 & **95.6\(\)**0.42 & 0.048\(\)0.012 & 0.317\(\)0.095 & 0.049\(\)0.011 & 74.6\(\)0.38 & 0.181\(\)0.065 & 0.488\(\)0.127 & 0.178\(\)0.063 \\  & VGG16 & 92.7\(\)0.58 & 0.067\(\)0.019 & 0.390\(\)0.101 & 0.068\(\)0.020 & 71.4\(\)0.52 & 0.238\(\)0.081 & 0.567\(\)0.125 & 0.233\(\)0.085 \\   & ResNet18 & 94.5\(\)0.34 & 0.038\(\)0.009 & 0.337\(\)0.075 & 0.040\(\)0.008 & 74.1\(\)0.30 & 0.082\(\)0.013 & 0.222\(\)0.007 & 0.085\(\)0.015 \\  & ResNet35 & 95.5\(\)0.51 & 0.034\(\)0.020 & 0.280\(\)0.009 & 0.045\(\)0.012 & 74.2\(\)0.931 & 0.098\(\)0.031 & 0.250\(\)0.096 & 0.101\(\)0.030 \\  & VGG16 & **93.1\(\)**0.41 & 0.034\(\)0.009 & 0.349\(\)0.083 & 0.034\(\)0.010 & **72.1\(\)**0.37 & 0.216\(\)0.042 & 0.472\(\)0.104 & 0.231\(\)0.045 \\   & ResNet18 & 91.9\(\)0.32 & 0.020\(\)0.006 & 0.156\(\)0.038 & 0.022\(\)0.007 & 72.1\(\)0.25 & 0.047\(\)0.011 & 0.156\(\)0.024 & 0.049\(\)0.032 \\  & ResNet35 & 92.3\(\)0.43 & 0.035\(\)0.012 & 0.186\(\)0.046 & 0.034\(\)0.010 & 73.1\(\)0.26 & 0.067\(\)0.021 & 0.184\(\)0.001 & 0.066\(\)0.023 \\  & VGG16 & 90.7\(\)0.28 & 0.027\(\)0.008 & 0.255\(\)0.078 & 0.027\(\)0.008 & 70.9\(\)0.37 & 0.133\(\)0.028 & 0.269\(\)0.059 & 0.141\(\)0.032 \\   & ResNet18 & **95.0\(\)**0.41 & **0.007\(\)**0.002 & **0.078\(\)**0.021 & **0.008\(\)**0.001 & **74.3\(\)**0.43 & **0.006\(\)**0.002 & **0.068\(\)**0.018 & **0.007\(\)**0.002 \\  & ResNet35 & 95.6\(\)0.51 & **0.009\(\)**0.002 & **0.089\(\)**0.012 & **0.010\(\)**0.003 & **75.4\(\)**0.39 & **0.011\(\)**0.003 & **0.063\(\)**0.011 & **0.014\(\)**0.002 \\  & VGG16 & 92.6\(\)0.35 & **0.011\(\)**0.002 & **0.083\(\)**0.031 & **0.012\(\)**0.004 & 71.9\(\)**0.35 & **0.028\(\)**0.008 & **0.044\(\)**0.003 & **0.030\(\)**0.010 \\   

Table 2: The calibration performance and accuracy of different objective functions. The best results are in bold. Results are averaged over five runs with different seeds.

Figure 5: **Accuracy and ECE of different PID settings with ResNet35 on CIFAR-100. The preceding figures illustrate the testing accuracy and ECE outcomes in the model optimization. Notably, the accuracy appears insensitive to the PID controller configuration. Nonetheless, excessive settings of \(P\), \(I\), and \(D\) may compromise the stability of ECE during the model optimization.**results and may require more iterations for observation. Thus, viewed from this perspective, the entire control system can be regarded as having a time lag, whereby the controlled variable \(\) exhibits a certain delay concerning the RCE. While it may be challenging to mathematically describe the control system, the PID controller serves as a "black-box" controller, leveraging the integral and differential variations of the error, proving highly effective. The ablation experiments are shown in Fig. 5. We conclude that model calibration is robust to the choice of PID parameters; however, setting the PID parameters too high can compromise the stability of ECE during model optimization. Based on this, we selected PID settings of 1, 0.1, and 1 for the experiments presented above. On the other hard, in Fig. 5, the accuracy curves with our method all exhibited a noticeable jitter, which requires further investigation.

### Ablation experiments of different optimizer

The motivation for proposing the adaptive learning rate for gradient compensation arises from the observation that significant variations in gradient magnitude can negatively impact the model's optimization for classification error. A dynamic learning rate helps maintain a relatively stable gradient magnitude. Additionally, the Adam optimizer aids in reducing gradient fluctuations. To verify the novelty of our method, Table 3 presents the performance of various optimizers when applied to our proposed PID controller-based calibration method.

Our experimental results indicate that Adam can indeed provide a more stable gradient and calibration performance, particularly in conjunction with our PID controller approach for model calibration. However, it is notable that Adam results in reduced accuracy, achieving only 63.5% on CIFAR-100 with ResNet35, significantly lower than the baseline accuracy of 73.8%. A key difference arises in the baseline case handled by Adam. In our proposed PID controller method, which adjusts the hyperparameter \(\) during model calibration, the loss function is dynamic. While Adam retains previous gradient information, this can conflict with the current gradient vector direction because the optimization objective is dynamic. In contrast, our compensation method only modifies the learning rate and retains gradient vector direction pertinent to the current loss function. This may explain why the Adam optimizer does not yield better results.

## 5 Conclusion

The gradient decay rate plays a crucial role in shaping the calibration characteristics and uncertainty distribution of deep learning throughout the dynamic optimization. Our results show a negative correlation between the gradient decay rate with increasing instance-level probability and the overall confidence distribution. This paper introduces a novel optimization approach aimed at regulating the gradient decay rate hyperparameter \(\), via a PID controller. The goal is to achieve perfect model calibration by monitoring the proposed relative calibration error of the validation set. Within this control system framework as shown in Fig. 3, the probabilistic gradient decay rate serves as the controlled variable, while a newly defined relative calibration error acts as the control system output, mitigating both over-confidence and under-confidence in the model. Additionally, to address fluctuations of gradient amplitude resulting from varying gradient decay rate, a new learning rate compensation mechanism is employed. Empirical validation demonstrates that our proposed adaptive gradient decay rate optimization strategy, facilitated by a PID controller, effectively enhances both the accuracy and model calibration in deep learning, ensuring adequate calibration throughout the supervised learning.

  SGD & Adam & PID Controller Approach & Gradient Compensation & Accuracy & ECE & AdaECE \\  ✓ & - & - & - & 73.8\% & 0.172 & 0.172 \\ ✓ & - & ✓ & - & 72.5\% & 0.022 & 0.023 \\ - & ✓ & ✓ & - & 63.5\% & 0.023 & 0.024 \\ ✓ & - & ✓ & ✓ & 74.7\% & 0.012 & 0.013 \\  

Table 3: Different optimizer performance in ResNet35 on CIFAR-100. Results are averaged over five runs with different seeds. Adam optimization compromises model accuracy when applied to a dynamic optimization objective using a PID controller approach.