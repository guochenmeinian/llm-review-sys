# Robust Multi-fidelity Bayesian Optimization

with Deep Kernel and Partition

 Fengxue Zhang

University of Chicago

zhangfx@uchicago.edu

&Thomas A. Desautels

Lawrence Livermore

National Laboratory

desautels2@llnl.gov

&Yuxin Chen

University of Chicago

chenyuxin@uchicago.edu

###### Abstract

Multi-fidelity Bayesian optimization (MFBO) is a powerful approach that utilizes low-fidelity, cost-effective sources to expedite the exploration and exploitation of a high-fidelity objective function. Existing MFBO methods with theoretical foundations either lack justification for performance improvements over single-fidelity optimization or rely on strong assumptions about the relationships between fidelity sources to construct surrogate models and direct queries to low-fidelity sources. To mitigate the dependency on cross-fidelity assumptions while maintaining the advantages of low-fidelity queries, we introduce a random sampling and partition-based MFBO framework with deep kernel learning. This framework is robust to cross-fidelity model misspecification and explicitly illustrates the benefits of low-fidelity queries. Our results demonstrate that the proposed algorithm effectively manages complex cross-fidelity relationships and efficiently optimizes the target fidelity function.

## 1 Introduction

Multi-fidelity Bayesian optimization (MFBO) (Dai et al., 2019; Wu et al., 2020; Takeno et al., 2020) is increasingly prevalent in the adaptive design of scientific experiments (Buterez et al., 2023), automated hyperparameter optimization (Eggensperger et al., 2021; Pfisterer et al., 2022), and policy optimization in control problems (Letham and Bakshy, 2019; Wu et al., 2020).

Previous work has often relied on various assumptions about the relationship between different fidelities to analyze efficiency theoretically (Song et al., 2019; Kandasamy et al., 2016, 2017). Similar to transfer learning for Bayesian optimization (BO), a more practical challenge involves handling significant misalignment between fidelities while maintaining cost efficiency. Recent approaches to robust transfer learning for BO (Appice et al., 2015; Probst et al., 2019; Perrone et al., 2019; Reif et al., 2012; Pfisterer et al., 2021; Feurer et al., 2018) and robust single-fidelity BO against model misspecification (Bogunovic and Krause, 2021; Liu et al., 2023) have addressed this issue yet typically do not consider the sample efficiency on the lower fidelities. Some research suggests mitigating the problem by avoiding evaluations or learning from unreliable low-fidelity sources (Mikkola et al., 2023; Foumani et al., 2023), but they do not explicitly deal with errors incurred from the unreliable model learning of the multi-fidelity structure in the model design and acquisition.

Leveraging recent advancements in efficient kernel learning, uncertainty quantification, and error bounds for learning algorithms (Xu and Raginsky, 2017; Robinson et al., 2020; Wang et al., 2021), we propose a general-purpose framework that uses sampling-based cost-aware acquisition. This framework captures complex and potentially misaligned multi-fidelity evaluations while explicitly addressing model misspecification on the fly with robust data acquisition and deep kernel learning.

## 2 Preliminaries

We begin by introducing useful notation, mostly following previous work by Song et al. (2019), and formally stating the problem studied in this paper.

### Multi-fidelity Optimization of Unknown Objective

Consider the problem of maximizing an unknown payoff function \(f_{M}:\). We can probe this function by directly querying it at some point \(\), consequently obtaining a noise-free observation \(y_{,M}=f_{M}()\).In addition to \(f_{M}\), we have access to oracle calls for unknown auxiliary functions \(f_{1},,f_{M-1}:\). Similarly, querying any \(f_{}\) at \(\) yields a noise-free observation \(y_{t}=f_{_{t}}(_{t})\). Each auxiliary function \(f_{}\) can be viewed as a lower-fidelity version of \(f_{M}\) when \(<M\). Specifically, we model the unknown target fidelity functions with corresponding Gaussian process (GP): \(f_{M}(_{M}(),k_{M}(,^{ }))\), where \(_{M}\) and \(k_{M}\) denote the prior mean and covariance. Let \(,\) denote the action of querying \(f_{}\) at \(\). Each action \(,\) incurs a cost of \(_{}\) and yields a reward:

\[r(,)=f_{M}()&=M \\ r_{}&\]

That is, performing \(,M\) at the target fidelity level achieves a reward \(f_{M}()\). The collective historical observations after \(T\) iteration is denoted by \(_{T}\{_{t},_{t},y_{t}\}_{t= 1 T}\). We also define the collective historical observations up to certain fidelity \(\) as \(_{,T}\{_{t},^{}_{t} ,y_{t}\}_{1 t T,^{}_{t}}\). When given a fixed budget, we need to guarantee the cumulative cost does not exceed the budget, i.e., \(_{t=1}^{T}_{_{t}}\). Lower fidelity actions \(,\) for \(<M\) yield the minimal immediate reward \(r_{}\) but can provide valuable information about \(f_{M}\), potentially leading to better decisions later. Without loss of generality, we assume \(_{}f_{M}() 0\) and \(r_{} 0\). Note that we define the reward only as incurred based on the target fidelity, and the query on low fidelity does not incur a reward but only helps with the learning. Hence, in the context of multi-fidelity Bayesian optimization, the **simple regret (SR)** is defined as: \((})=f_{M}(^{*})-f_{M}(})\), where \(}:=_{:(,M,y) _{T}}f_{M}()\) is a point selected to be evaluated at the target fidelity, and \(^{*}\) is the global maximizer of the function \(f_{M}\). Our objective is to find the candidate that minimizes the simple regret after **exhausting a given budget \(\)**.

### Expected Excess Risk

In addition to the conventional analysis that assumes the prior is properly specified, we explicitly deal with the model misspecification regarding the difference between the posterior mean and true underlying function. In the context of statistical learning theory, the **convergence rate** of the expected excessive risk with respect to the training dataset \(_{,T}\) at fidelity \([M]^{+}=[1 M]\) after \(T\) iterations is defined as \(_{MF}(,T)[(f_{}, {f}_{})|_{,T}]-(f_{},_{}^ {*})=O(T^{})\), Here, \(-1<<0\) is a constant that characterizes the rate of convergence. \(_{}\) is the hypothesis of fidelity \(\) produced by the learning algorithm when trained on \(_{,T}\). \((f,)\) is the loss function evaluating the hypothesis \(\) with respect to the true objective \(f\), and \(_{}^{*}\) is the hypothesis on fidelity \(\) that minimizes the expected loss.

Figure 1: We illustrate the problem of learning and optimization on both target fidelity and misaligned low fidelities. (a) demonstrates the one-dimensional Rastrigin function (Pohlheim, 2007) and the manually constructed low fidelities. (b) demonstrates the posterior of learning the multi-fidelity functions with conventional multi-task GP (Swersky et al., 2013) previously applied in MFBO (Letham and Bakshy, 2019) when feeding 2000 training points densely distributed in the search space. (c) shows the posterior of the proposed model when feeding 10 points from each fidelity.

## 3 Method

In this section, we discuss the model design and the analysis-inspired data acquisition procedure of the proposed Robust Multi-Fidelity Bayesian Optimization with Deep Kernel Learning and Partition (RMFBO-DP). The pseudo code and detailed design choices are deferred to Appendix B.

### Model

We employ hierarchical deep kernel learning (Wilson et al., 2016) regularized with the spectral norm (Van Amersfoort et al., 2021) with mean absolute error (MAE) as the loss function to deal with overfitting caused by shortage of training data and the specific choice of training loss. We assume that the multiple fidelities \(\{f_{}\}_{[M]}\) are mutually dependent through some fixed, possibly unknown joint probability distribution. Therefore, we seek to approximate the joint underlying function \(f:[M]^{+}\), where both the position \(\) and fidelity \([M]^{+}\) are inputs, and learn the approximation \(\) through joint learning of \(h\) and \(g_{[M]^{+}}\). Here, a _single_ latent space mapping \(h:[M]^{+}\) convert the input space \(\) to the latent space \(\) which consists of the fidelity independent part \(_{M}\) and fidelity dependent part \(_{}\). On top of the latent space, we construct a set of objective mappings \(g_{1} g_{M}\) for each fidelity. Namely \([M]^{+}\), \(f_{} f(,)\) and \(f(,)\) is approximated by \(_{} g_{}(h(,))\). We illustrate the model structure in figure 2. The model is trained by first traversing all low fidelities for weak learning, then jointly optimizing the deep kernel.

### Data Acquisition

We extend random exploration to the multi-fidelity regime. We use both the expected generalization error and SR bounds to guide the cost-efficient acquisition. When the error bound contributes more to global regret, we randomly explore until it is more cost-efficient to conduct target fidelity acquisition. When the SR contributes more to the general regret, we conduct target fidelity acquisition on certain partitions of the search space. We leverage the GP posterior calibrated with the excess risk on observed points to exclude from acquisition the partitions of the search space that, with high probability, do not contain the global optimum. To do so, we rely on both the upper confidence bound \(_{f_{M},t}()_{f_{M},t-1}()+_{ f_{M},t}^{1/2}_{f_{M},t-1}()\) and lower confidence bound \(_{f_{M},t}()_{f_{M},t-1}()-_{ t}^{1/2}_{f_{M},t-1}()\), where \(_{t-1}()=k_{t-1}(,)^{1/2}\) and \(_{t}\) acts as a scaling factor corresponding to certain confidence. Formally, the acting search space at iteration \(t\) is \(}_{t}=\{x_{f_{M},t}()> _{^{}}_{f_{M},t}(^{ })-_{MF}(M,t)\}.\)

Regarding the theoretical justification, previous works offer an upper bound for cumulative regret when applying random exploration on the partitions of interest (Salgia et al., 2024) defined as \(\{x_{f_{M},t}()>_{^{ }}_{f_{M},t}(^{})\}\), as the target fidelity acquisition function when we ignore the contribution of low-fidelity evaluation to the target fidelity learning. We extend the cumulative regret bound into the following form of SR bound.

**Informal Theorem 1**: _Under proper assumptions and choices of parameters, when ignoring the contribution of performance by learning on the low fidelities, we have with probability at least

Figure 2: Schema for multi-fidelity learning implemented with deep kernel. The dotted lines denote the flow of target fidelity (strong data), and the solid lines the flow of low fidelities(weak data). Here, we denote the output space for certain fidelity \([M]^{+}\) as \(_{}\). Specifically, the target fidelity output space is denoted as \(_{M}\).

\(1-\), \((t)=}((t)}}{T_{M}(t)}} (t)}{})\). Here \(}\) means up to the logarithmic factor, and \(T_{}(t)|\{_{t^{}},_{t^{}} ,y_{t^{}}\}_{1 t^{} t,_{t^{}}=|\) denotes evaluations at fidelity \(\) among \(t\) evaluations._

We exploit recent advancements in expected excess risk in meta-learning (Robinson et al., 2020) to extend the previous SR results to multiple weak learning sources. We state the informal version of the theoretical results here while deferring the discussion of assumptions, proof, and other details to Appendix A. First, we decompose the ultimate SR into separate components for the conventional regret and the generalization error.

**Informal Theorem 2**: _The misspecification-aware simple regret (\(_{}\)) of the proposed algorithm can be decomposed into the standard simple regret (SR) and the rate term as \(_{}(t)(t)+_{MF}(M,t)\)._

In the following, we generalize the meta-learning expected excess risk (Robinson et al., 2020; Xu and Raginsky, 2017) to multi-fidelity learning.

**Informal Theorem 3**: _When the lowest single fidelity bears the convergence rate \(_{MF}(1,T)=O(}})\), the excess risk bound \(_{MF}(,t)\)_

\[O(_{MF}(-1,t)+(t)}_{MF}(-1,t)+1) T_{}(t)}}{T_{}(t)})\]

This allows us to differentiate the multiple fidelities' contribution to the target fidelity learning and regret minimization. Specifically, a cost-aware multi-fidelity acquisition could be made by minimizing the \(_{}(T)\) such that the total cost incurred by querying different fidelities does not exceed \(\).

### Evaluation

We evaluated the proposed algorithm RMFBO-DP against four baselines on both synthetic datasets corresponding to figure 1 and real-world protein design dataset. The results shown in figure 3 demonstrate the robustness of RMFBO-DP in various tasks and efficiency in tasks of different dimensionalities. We defer detailed description to Appendix C.

## 4 Conclusion

In this paper, we introduced a novel multi-fidelity Bayesian optimization approach focusing on robustness and efficiency. Our method explicitly addresses the misspecification issues in multi-fidelity deep model learning by incorporating budget-sensitive low-fidelity sampling and constraining acquisitions to a subset of the global search space for target fidelity optimization. By tackling the challenges of low-fidelity misalignment and efficient target fidelity optimization in a principled, cost-effective manner, we demonstrated that our approach significantly improves robustness and performance over existing methods, as confirmed by our theoretical and empirical results.

Figure 3: We illustrate the performance of RMFBO-DP compared against MF-MES, MF-KG, rMF-MES, and rMF-KG on both synthetic and real-world datasets. The results are collected from 10 independent trials. The y-axis denotes the simple regret, and the x-axis denotes the consumed budget. The shades area shows the \(95\%\) confidence interval. We trim the shared initial single data point. Detailed discussions are deferred to Appendix C.