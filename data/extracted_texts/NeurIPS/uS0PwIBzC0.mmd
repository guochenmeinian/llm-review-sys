# SVFT: Parameter-Efficient Fine-Tuning

with Singular Vectors

 Vijay Lingam\({}^{}\)\({}^{@sectionsign}\)\({}^{}\)  Atula Tejaswi\({}^{}\)\({}^{}\)  Aditya Vavre\({}^{}\)\({}^{}\)  Aneesh Shetty\({}^{}\)\({}^{}\)

**Gautham Krishna Gudur\({}^{}\)\({}^{}\)  Joydeep Ghosh\({}^{}\)  Alex Dimakis\({}^{}\)  Eunsol Choi\({}^{}\)  Aleksandar Bojchevski\({}^{}\)\({}^{}\)  Sujay Sanghavi\({}^{}\)\({}^{}\)\({}^{}\)**

\({}^{}\)University of Texas at Austin

\({}^{}\)University of Cologne

\(@sectionsign\)CISPA Helmholtz Center for Information Security

indicates equal contribution/advising

###### Abstract

Popular parameter-efficient fine-tuning (PEFT) methods, such as LoRA and its variants, freeze pre-trained model weights \(\) and inject learnable matrices \(\). These \(\) matrices are structured for efficient parameterization, often using techniques like low-rank approximations or scaling vectors. However, these methods typically exhibit a performance gap compared to full fine-tuning. While recent PEFT methods have narrowed this gap, they do so at the expense of additional learnable parameters. We propose SVFT2, a _simple_ approach that structures \(\) based on the specific weight matrix \(\). SVFT updates \(\) as a sparse combination \(M\) of outer products of its singular vectors, training only the coefficients of these combinations. Crucially, we make additional off-diagonal elements in \(M\) learnable, enabling a smooth trade-off between trainable parameters and expressivity--an aspect that distinctly sets our approach apart from previous works leveraging singular values. Extensive experiments on language and vision benchmarks show that SVFT recovers up to **96%** of full fine-tuning performance while training only **0.006 to 0.25%** of parameters, outperforming existing methods that achieve only up to **85%** performance with **0.03 to 0.8**% of the trainable parameter budget.

## 1 Introduction

Large-scale foundation models are often adapted for specific downstream tasks after pre-training. Parameter-efficient fine-tuning (PEFT) facilitates this adaptation efficiently by learning a minimal set of new parameters, thus creating an "expert" model. For instance, Large Language Models (LLMs) pre-trained on vast training corpora are fine-tuned for specialized tasks such as text summarization , sentiment analysis , and code completion  using instruction fine-tuning datasets. Although full fine-tuning (Full-FT) is a viable method to achieve this, it requires re-training and storing all model weights, making it impractical for deployment with large foundation models.

To address these challenges, PEFT techniques  (e.g., LoRA ) were introduced to significantly reduce the number of learnable parameters compared to Full-FT, though often at the cost of performance. DoRA  bridges this performance gap by adding more learnable parameters and being more expressive than LoRA. Almost all these methods apply a low-rank update additively to the frozen pre-trained weights, potentially limiting their expressivity. Furthermore, these adapters are agnostic to the structure and geometry of the weight matrices they modify. Finally, more expressivePEFT methods (e.g., LoRA, DoRA, BOFT ) still accumulate a considerable portion of learnable parameters even in their most efficient configuration (e.g., setting rank=1 in LoRA and DoRA). The storage requirements for the learnable adapters can grow very quickly when adapting to a large number of downstream tasks .

Is it possible to narrow the performance gap between PEFT and Full-FT while being highly parameter-efficient? Yes, we propose SVFT: Singular Vectors guided Fine-Tuning -- a _simple_ approach that involves updating an existing weight matrix by adding to it a sparse weighted combination of _its own singular vectors_. The structure of the induced perturbation in SVFT depends on the specific matrix being perturbed. Our contributions can be summarized as follows:

* We introduce SVFT, a new PEFT method. Given a weight matrix \(\), SVFT involves adapting it with a matrix \(:=_{(i,j)}m_{ij}_{i}_{j}^{T}\) where the \(\{_{i}\}\) and \(\{_{j}\}\) are the left and right singular vectors of \(\), \(\) is an a-priori fixed sparsity pattern, and \(m_{ij}\) for \((i,j)\) are learnable parameters. By controlling \(||\) we can efficiently explore the accuracy vs parameters trade-off.
* SVFT achieves higher downstream accuracy, as a function of the number of trainable parameters, as compared to several popular PEFT methods (see Figure 1) and over several downstream tasks across both vision and language tasks. For instance, on GSM-8K using Gemma-2B our method recovers up to **96%** of full fine-tuning performance while training only **0.006 to 0.25**% of parameters, outperforming existing methods that only recover up to **85%** performance using **0.03 to 0.8%** the trainable parameter budget (see Figure 1).

We introduce four simple variants for parameterizing weight updates, namely: _Plain_, _Random_, _Banded_, and _Top-\(k\)_ in SVFT (which differ in their choices of the fixed sparsity pattern \(\)) and validate these design choices empirically. Additionally, we theoretically show that for any fixed parameters budget, SVFT can induce a higher rank perturbation compared to previous PEFT techniques.

## 2 Related Work

Recent advancements in large language models (LLMs) have emphasized the development of PEFT techniques to enhance the adaptability and efficiency of large pre-trained language models.

**LoRA.** A notable contribution in this field is Low-Rank Adaptation (LoRA) , which freezes the weights of pre-trained models and integrates trainable low-rank matrices into each transformer layer. For a pre-trained weight matrix \(_{0}^{d n}\), LoRA constraints the weight update \(\) to a low-rank decomposition: \(=_{0}+=_{0}+ }\), where \(^{d r}\), \(^{r n}\) and rank \(r(d,n)\). We underline the (trainable) parameters that are updated via gradient descent.

**LoRA variants.** We highlight some recent approaches that further improve the vanilla LoRA architecture. Vector-based Random Matrix Adaptation (VeRA)  minimizes the number of

Figure 1: Performance vs total trainable parameters for GSM-8K (left) and Commonsense Reasoning (right) on Gemma-2B. SVFT\({}_{d=16}^{B/R}\) outperforms DoRA\({}_{r=8/16}\) with 75% less trainable parameters.

trainable parameters by utilizing a pair of low-rank random matrices shared between layers and learning compact scaling vectors while maintaining performance comparable to LoRA. Formally, VeRA can be expressed as: \(=_{0}+=_{0}+_{}_{}\), where \(\) and \(\) are initialized randomly, frozen, and shared across layers, while \(_{b}\) and \(_{d}\) are trainable diagonal matrices.

An alternative approach, Weight-Decomposed Low-Rank Adaptation (DoRA) , decomposes pre-trained weight matrices into magnitude and direction components, and applies low-rank updates for directional updates, reducing trainable parameters and enhancing learning capacity and training stability. DoRA can be expressed as: \(=_{0}+}{\|_{0}+\|_{c}} {x}=_{0}+}{\|_{0}+\|_{c}}\), where \(\|\|_{c}\) denotes the vector-wise norm of a matrix across each column. Similar to LoRA, \(_{0}\) remains frozen, whereas the magnitude vector \(\) (initialized to \(\|_{0}\|_{c}\)) and low-rank matrices \(,\) contain trainable parameters.

AdaLoRA  adaptively distributes the parameter budget across weight matrices based on their importance scores and modulates the rank of incremental matrices to manage this allocation effectively. PiSSA (Principal Singular Values and Singular Vectors Adaptation)  is another variant of LoRA, where matrices \(,\) are initialized with principal components of SVD and the remaining components are used to initialize \(_{0}\). FLoRA  enhances LoRA by enabling each example in a mini-batch to utilize distinct low-rank weights, preserving expressive power and facilitating efficient batching, thereby extending the domain adaptation benefits of LoRA without batching limitations.

**Other PEFT variants.** Orthogonal Fine-tuning (OFT)  modifies pre-trained weight matrices through orthogonal reparameterization to preserve essential information. However, it still requires a considerable number of trainable parameters due to the high dimensionality of these matrices. Butterfly Orthogonal Fine-tuning (BOFT)  extends OFT's methodology by incorporating Butterfly factorization thereby positioning OFT as a special case of BOFT. Unlike the additive low-rank weight updates utilized in LoRA, BOFT applies multiplicative orthogonal weight updates, marking a significant divergence in the approach but claims to improve parameter efficiency and fine-tuning flexibility. BOFT can be formally expressed as: \(=(}(m,b)_{0})\), where the orthogonal matrix \((m,b)^{d d}\) is composed of a product of multiple orthogonal butterfly components. When \(m=1\), BOFT reduces to block-diagonal OFT with block size \(b\). When \(m=1\) and \(b=d\), BOFT reduces to the original OFT with an unconstrained full orthogonal matrix.

**SVD-based Variants.** SVF , SVDiff , and SAM-Parser  also leverage the structure of \(W\) matrices by decomposing them into three consecutive matrices via Singular Value Decomposition (SVD). However, these methods fine-tune only the singular values while keeping other components fixed, making them comparable to SVFT\({}^{P}\). In Appendix C.1, we present a comparison of SVFT\({}^{P}\) with SVF, confirming that their performance is similar, which supports our observations.

## 3 Method

In this section, we introduce Singular Vectors guided Fine-Tuning (SVFT). The main innovation in SVFT lies in applying structure/geometry-aware weight updates through sparse weighted combination of singular vectors.

Figure 2: Schematic comparison of LoRA, VeRA, DoRA, and SVFT (left to right).

### SVFT Formulation

We now formally describe our method, SVFT for parameter-efficient fine-tuning of a pre-trained model. Let \(_{0}^{d_{1} d_{2}}\) denote a weight matrix in the pre-trained model, such as a key matrix, query matrix, or an MLP matrix within a transformer block. To this matrix, we add a structured, learnable update \(\) as follows.

As a first step, we compute the Singular Value Decomposition (SVD) of the given matrix: \(_{0}=^{T}\). That is, \(\) is the \(d_{1} d_{1}\) matrix of left singular vectors (i.e., its columns are orthonormal), \(^{T}\) is the \(d_{2} d_{2}\) matrix of right singular vectors (i.e., its rows are orthonormal), and \(\) is a \(d_{1} d_{2}\) diagonal matrix. Then, we parameterize our weight update as \(~{}=~{}}^{T}\), where \(,\) are fixed and frozen, while \(}\) is a \(d_{1} d_{2}\)**sparse trainable matrix with pre-determined and fixed sparsity pattern3**. That is, we first pre-determine a small fixed set of elements in \(\) that will be allowed to be non-zero and train only those elements. The forward pass for SVFT can be written as,

\[=_{0}x+x=(+}) ^{T}\] (1)

We explore four simple choices for \(\), the pre-determined sparsity pattern of \(}\).

**Plain \(^{P}\)**. In this variant, we constrain \(}\) to be a diagonal matrix, which can be interpreted as adapting singular values and reweighting the frozen singular vectors. Since only the diagonal elements are learned, this is the most parameter-efficient SVFT variant.

**Banded \(^{B}_{d}\)**. In this approach, we populate \(}\) using a banded matrix, progressively making off-diagonals learnable. Specifically, for constants \(z_{1}\) and \(z_{2}\), \(}_{ij}=0\) if \(j<i-z_{1}\) or \(j>i+z_{2}\), where \(z_{1},z_{2} 0\). In our experiments, we set \(z_{1}=z_{2}=d\) to induce off-diagonal elements that capture additional interactions beyond those represented by singular values. This banded perturbation induces local interactions, allowing specific singular values to interact with their immediate neighbors, ensuring smoother transitions. This method, although deviating from the canonical form of SVD, provides a mechanism to capture localized interactions.

**Random \(^{R}_{d}\)**. A straightforward heuristic for populating \(}\) involves randomly selecting \(k\) elements to be learnable.

**Top-\(k\) \(^{T}_{\#p}\)**. The final design choice we explore involves computing the alignment between the left and right singular vectors as \(^{T}_{i}_{j}\). We then select the top-\(k\) elements and make them learnable. However, note that this only works when left and right singular vectors have the same size. A possible interpretation of this is we make only the top-\(k\) strong interactions between singular vector directions learnable. The subscript \(\#p\) denotes the total number of learnable parameters.

We illustrate these SVFT design choices in Figure 3. Our empirical results demonstrate that these simple design choices significantly enhance performance compared to state-of-the-art PEFT methods. Note that \(^{P}\) has a fixed number of learnable parameters, while the remaining variants are configurable. We hypothesize that further innovation is likely achievable through optimizing the sparsity pattern of \(}\), including efficient learned-sparsity methods. In this paper, we explore these

Figure 3: An Overview of SVFT. The original weights \(\) are decomposed into \(,,\). Here, \(\) contains all the trainable parameters, which can be configured into patterns such as Plain, Random, Banded, and Top-\(k\), represented by patterns of trainable (orange) and zero (gray) elements.

four choices to validate the overall idea: determining a perturbation using the singular vectors of the matrix that is being perturbed.

### Properties of SVFT

We highlight some properties of SVFT in the following lemma and provide insights into how its specific algebraic structure compares and contrasts with baseline PEFT methods.

**Lemma:** Let \(_{0}\) be a matrix of size \(d_{1} d_{2}\) with SVD given by \(^{T}\). Consider an updated final matrix \(_{0}+^{T}\), where \(\) is a matrix of the same size as \(\), which may or may not be diagonal. Then, the following holds:

1. _Structure:_ If \(\) is also diagonal (i.e. the plain SVFT), then the final matrix \(_{0}+^{T}\) has \(\) as its left singular vectors and \((+)^{T}\) as its right singular vectors. That is, its singular vectors are unchanged, except for possible sign flips. Conversely, if \(\) is _not_ diagonal (i.e., variants of SVFT other than plain), then \(\) and \(\) may no longer be the singular directions of the final matrix \(_{0}+^{T}\).
2. _Expressivity:_ Given _any_ target matrix \(\) of size \(d_{1} d_{2}\), there exists an \(\) such that \(=_{0}+^{T}\). That is, if \(\) is fully trainable, any target matrix can be realized using this method.
3. _Rank:_ If \(\) has \(k\) non-zero elements, then the rank of the update \(^{T}\) is at most \(\{k,\{d_{1},d_{2}\}\}\). For the same number of trainable parameters, SVFT can produce a much higher rank perturbation than LoRA (eventually becoming full rank), but in a constrained structured subspace.

We provide our proofs in Appendix A. Building on this lemma, we now compare the form of the SVFT update with LoRA and VeRA. SVFT's \(\) can be written as a sum of rank-one matrices:

\[~{}=~{}_{(i,j)}}_{i}_{j} ^{T}\] (2)

where \(_{i}\) is the \(i^{th}\) left singular vector, \(_{j}\) is the \(j^{th}\) right singular vector, and \(\) is the set of non-zero elements in \(\). Thus, our method involves adding a weighted combination of specific rank-one perturbations of the form \(_{i}_{j}^{T}\).

LoRA and VeRA updates can also be expressed as sums of rank-one matrices.

\[_{}~{}=~{}_{i=1}^{r}_{i}}~{} _{i}}^{T}~{}~{}~{}~{}~{}~{}_{}~{}=~{}_{i=1}^{r}}(}_{i} })}_{i}^{T}\] (3)

where \(_{i}}\) and \(_{j}}\) are the trainable columns of \(\) and \(\) matrices in LoRA. In VeRA, \(}_{i}\) and \(}_{i}\) are random and fixed vectors, while \(}\) and \(}\) represent the diagonal elements of \(_{d}\) and \(_{b}\) respectively.

Note that LoRA requires \(d_{1}+d_{2}\) trainable parameters per rank-one matrix, while SVFT and VeRA require only one. Although LoRA can potentially capture directions different from those achievable by the fixed \(\{_{i},_{j}^{T}\}\) pairs, each of these directions incurs a significantly higher parameter cost.

VeRA captures new directions at a parameter cost similar to SVFT; however, there is a key distinction: in VeRA, each vector \(}_{i}\) or \(}_{i}\) appears in only one of the rank-one matrices. In contrast, in SVFT, the same vector \(_{i}\) can appear in multiple terms in the summation, depending on the sparsity pattern of \(\). This results in an important difference: unlike SVFT, VeRA is _not universally expressive_ - it cannot represent any target matrix \(\). Moreover, \(}_{i},}_{i}\) are random, while \(_{i},_{j}\) depend on \(_{0}\).

**Note.** SVFT requires storing both left and right singular vectors due to its computation of the SVD on pre-trained weights. While this increases memory usage compared to LoRA, it remains comparable to or lower than DoRA and BOFT. We present a memory analysis in Section 5.3. Further exploration of memory-reduction techniques, such as quantization, is planned as future work. Importantly, inference time and memory consumption remain the same across all methods, including SVFT, as the weights can be fused.

Experiments

### Base Models & Setup

We adapt widely-used language models, encoder-only model (DeBERTaV3\({}_{}\)) and two decoder-only models (Gemma-2B/7B , LLaMA-3-8B ). We also experiment with vision transformer models (ViT-B/16 and ViT-L/16) ) pre-trained on ImageNet-21k , following prior work . The complete details of our experimental setup and hyperparameter configurations are provided in Appendix C.

**Baselines.** We compare with **Full Fine-Tuning (FT)** updating all learnable parameters in all layers, along with **LoRA**, **DoRA**, **BOFT** and **VeRA**.4

**Target Modules.** We adapt _all weight matrices_ for SVFT, as it does not increase trainable parameters at the same rate as baseline methods. For baselines, we adapt the target modules recommended in : QKVUD matrices for LoRA and DoRA, compatible matrices for VeRA, and QV matrices for BOFT to stay within GPU memory limits. Additional details can be found in Appendix C.7 and C.8. We also conduct experiments adapting QKVUD modules across methods and observe similar trends, as discussed in Appendix C.2.

### Datasets

**Language.** For natural language generation (NLG) tasks, we evaluate on GSM-8K  and MATH  by fine-tuning on MetaMathQA-40K , following . We also evaluate on 8 commonsense reasoning benchmarks (BoolQ , PIQA , SIQA , HellaSwag , Winogrande , ARC-easy/challenge , and OpenBookQA ). We follow the setting outlined in prior work [19; 16], where the training sets of all benchmarks are amalgamated for fine-tuning. We fine-tune on 15K examples from this training set. For natural language understanding (NLU), we evaluate on the General Language Understanding Evaluation (GLUE) benchmark consisting of classification and regression tasks, in line with [17; 15].

**Vision.** Our experiments on vision tasks consist of 4 benchmarks: CIFAR-100 , Food101 , RESISC45 , and Flowers102 . We follow the setup from , and fine-tune on a subset comprising 10 samples from each class.

    &  &  &  \\   & **\#Params** & **GSM-8K** & **MATH** & **\#Params** & **GSM-8K** & **MATH** & **\#Params** & **GSM-8K** & **MATH** \\   Full-FT & 2.5B & 52.69 & 17.94 & 8.5B & 74.67 & 25.70 & 8.0B & 64.13 & 16.24 \\  LoRA\({}_{r=32}\) & 26.2M & 43.06 & 15.50 & 68.8M & 76.57 & 29.34 & 56.6M & **75.89** & **24.74** \\ DoRA\({}_{r=16}\) & 13.5M & 44.27 & **16.18** & 35.5M & 74.52 & 29.84 & 29.1M & 75.66 & **24.72** \\  BOFT\({}_{m=2}^{b=8}\) & 1.22M & 36.01 & 12.13 & 2.90M & 71.79 & 28.98 & 4.35M & 67.09 & 21.64 \\ DoRA\({}_{r=1}\) & 1.19M & 35.25 & 13.04 & 3.26M & 74.37 & 26.28 & 2.55M & 68.30 & 21.96 \\ LoRA\({}_{r=1}\) & 0.82M & 32.97 & 13.04 & 0.82M & 72.4 & 26.28 & 1.77M & 68.84 & 20.94 \\ VeRA\({}_{r=1024}\) & 0.63M & 36.77 & 14.12 & 0.43M & 71.11 & 27.04 & 0.98M & 63.76 & 20.28 \\ SVFT\({}^{P}\) & 0.19M & 40.34 & 14.38 & 0.43M & 73.50 & 27.30 & 0.48M & 69.22 & 20.44 \\ SVFT\({}^{R}_{d}\) & 6.35M & **50.03** & 15.56 & 19.8M & **76.81** & **29.98** & 13.1M & **75.90** & 24.22 \\   

Table 1: Performance (Accuracy) on Mathematical Reasoning (GSM-8K and MATH). #Params denote the number of trainable parameters. **bold** and underline represent the best and second best performing PEFT methods, respectively. SVFT offers superior/competitive performance at much lower #Params. For SVFT\({}^{R}_{d}\), we set \(d=16\) for Gamma and \(d=12\) for LLaMA-3 models.

[MISSING_PAGE_FAIL:7]

DoRA\({}_{r=1}\), which have 1.9\(\) and 7.7\(\) more parameters, respectively. Against VeRA, which trains 3.5\(\) more parameters, SVFT\({}^{P}\) shows a relative improvement of \(\)**1.16**%. Similarly, SVFT\({}_{d=8}^{B}\) also matches or exceeds methods that use up to 7\(\) more trainable parameters. For instance, SVFT\({}_{d=8}^{B}\) attains an average performance of 83.35% with only 9.8M parameters, closely matching LoRA\({}_{r=16}\) (83.69%, 68.8M parameters). We observe similar trends with Gemma-2B (refer Table 11).

Natural Language Understanding.Results on the GLUE benchmark are summarized in Table 3. SVFT matches LoRA\({}_{r=8}\) and DoRA\({}_{r=4}\) which use **12-22\(\)** more trainable parameters. Similarly, when compared to OFT and BOFT, SVFT\({}^{P}\) maintains a comparable average performance despite being 12\(\) smaller. These results highlight SVFT's ability to strike a balance between parameter efficiency and performance, making it an attractive PEFT choice for simple classification tasks.

Parameter efficiency.In Figure 1, we plot the performance of SVFT on mathematical reasoning and commonsense reasoning against other PEFT techniques across a range of configurations. Across trainable parameter budgets ranging from lowest to highest, SVFT obtains the best overall performance, matching methods that require significantly more trainable parameters. These results establish SVFT as a pareto-dominant approach for parameter-efficient fine-tuning.

### Performance on Vision Tasks

Table 4 presents a comparison between SVFT and other PEFT techniques on image classification benchmarks, using ViT-B and ViT-L models. The results show that SVFT variants achieve a strong balance between performance and parameter efficiency, often surpassing or matching the performance of other methods with fewer learnable parameters. Notably, the SVFT\({}^{B}\) variant attains an average accuracy of \(83.87\%\) across tasks with ViT-Base, outperforming Full-FT, which achieves a close \(83.72\%\). Additionally, it's important to note that in these vision experiments, both classifier head parameters and other learnable parameters are trained.

### Memory Analysis

Although SVFT reduces trainable parameters, it results in higher overall GPU memory usage compared to LoRA. However, fewer trainable parameters lower the memory demands for gradients,

    &  &  \\   & **\#Params** & **C100** & **F101** & **F102** & **R45** & **\#Params** & **C100** & **F101** & **F102** & **R45** \\   Head & - & 78.58 & 75.14 & 98.71 & 64.42 & - & 79.14 & 75.66 & 98.89 & 64.99 \\ Full-FT & 85.8M & 85.02 & 75.41 & 99.16 & **75.30** & 303.3M & 87.37 & 78.67 & 98.88 & **80.17** \\ LoRA\({}_{r=8}\) & 294.9K & **85.65** & 76.13 & 99.14 & 74.01 & 786.4K & 87.36 & **78.95** & 99.24 & 79.55 \\ VeRA\({}_{r=256}\) & 24.6K & 84.00 & 74.02 & 99.10 & 71.86 & 61.4K & **87.55** & 77.87 & **99.27** & 75.92 \\ SVFT\({}^{P}\) & 18.5K & 83.78 & 74.43 & 98.99 & 70.55 & 49.2K & 86.67 & 77.47 & 99.09 & 73.52 \\ SVFT\({}_{d=4}^{B}\) & 165.4K & 84.85 & 76.45 & 99.17 & 74.53 & 441.5K & 87.05 & **78.95** & 99.23 & 78.90 \\ SVFT\({}_{d=4}^{B}\) & 165.4K & 84.65 & **76.51** & **99.21** & 75.12 & 441.5K & 86.95 & 78.85 & 99.24 & 78.93 \\   

Table 4: Performance on image classification benchmarks – CIFAR-100 (C100), Food101 (F101), Flowers102 (F102), and Resisc-45 (R45). We only adapt \(Q\), \(V\) matrices for all methods, following prior work . We report accuracy for all tasks.

Figure 4: Performance variation with SVFT\({}_{d}^{B}\) based on the adapted weight matrices – GSM-8K with Gemma-2B. Adapting more target weight types results in greater gains in performance. Interestingly, for a fixed parameter budget, adapting \(\) and \(\) weight types gives greater lifts than adapting \(\) and \(\).

activations, optimizer states, and other buffers. To validate this, we used HuggingFace's internal memory profiler to measure peak GPU memory usage. Our results, along with the adapted modules for all baselines, are summarized in Table 5. We observe that SVFT uses approximately 1.2x more memory than LoRA but remains comparable to or more efficient than DoRA. We present additional analysis in Appendix C.5.

### Contribution of Each Weight Type

In Figure 4, we investigate the contribution of each weight type. Starting with the base configuration, we apply SVFT\({}_{d}^{B}\) to the \(\) and \(\) weights in each transformer block and report the performance. We then incrementally add the remaining weight modules (\(,,,,\)) and observe the changes in performance. For each configuration, we also vary the trainable parameters by incrementing the total learnable off-diagonals.

Note that applying SVFT\({}_{d}^{B}\) to \(,,\), and \(\) does not increase trainable parameters as much as applying LoRA/DoRA to these modules (Table 8). For example, for a large matrix of shape \(d_{1} d_{2}\), LoRA\({}_{r=1}\) learns \(d_{1}+d_{2}\) parameters, while SVFT\({}^{P}\) learns \((d_{1},d_{2})\) parameters. We observe that adapting only \(\) and \(\) with SVFT yields up to a \(10\%\) relative improvement over adapting \(\) and \(\) for the same parameter budget (\( 0.8M\)). Our findings indicate that adapting more weight types enhances performance.

### Impact of \(M\)'s Structure on Performance

We analyze the impact of various parameterizations of \(\) (Plain, Banded, Random, Top-\(k\)) on downstream performance. To ensure a fair comparison, we align the number of trainable coefficients across all variants whenever possible. As shown in Table 7, the Banded variant outperforms the others, followed closely by the Random variant, across different models and tasks. This trend is also evident in the average rank column of the table. Based on these empirical findings, we recommend using the Banded variant.

### Impact of Pre-trained Weight Quality

A key feature of SVFT is that the weight update depends on the pre-trained weights \(\). We therefore ask the following question: _Does the quality of pre-trained weights have a disproportionate impact on SVFT?_ To

    &  &  &  \\    & & & **39K** & & **143K** \\   Full-FT & 2.5B & 21.00 & 30.09 & 9.09 \\ LoRA & 5.24M & 11.22 & 18.95 & 7.73 \\ SVFT & 5.56M & 15.08 & 23.19 & 8.11 \\   

Table 6: Results on GSM-8K after fine-tuning on Pythia-2.8B checkpoints at different stages of pre-training (PT).

    &  &  &  \\   & & **\#Params** & **GPU Mem** & **Perf.** & **\#Params** & **GPU Mem** & **Perf.** \\  LoRA\({}_{r=4}\) & Q,K,V,U,D & 3.28M & 18.88 & 27.56 & 8.6M & 63.57 & 51.03 \\ DoRA\({}_{r=4}\) & Q,K,V,U,D & 3.66M & 24.58 & 28.44 & 9.72M & 78.70 & 51.94 \\ LoRA\({}_{r=32}\) & Q,K,V,U,D & 26.2M & 19.06 & 29.28 & 68.8M & 64.24 & 52.96 \\ DoRA\({}_{r=16}\) & Q,K,V,U,D & 13.5M & 24.64 & 30.22 & 35.5M & 78.99 & 52.18 \\  SVFT\({}^{P}\) & Q,K,V,U,D,O,G & 194K & 21.90 & 27.36 & 429K & 76.26 & 50.40 \\ SVFT\({}^{R}_{d=8}\) & Q,K,V,U,D,O,G & 3.28M & 22.02 & 31.87 & 9.8M & 76.65 & 50.99 \\ SVFT\({}^{R}_{d=16}\) & Q,K,V,U,D,O,G & 6.35M & 22.15 & **32.79** & 19.8M & 77.04 & **53.40** \\   

Table 5: GPU Memory analysis, measured in gigabytes (GB). We report the average performance on GSM-8K and MATH. SVFT outperforms both LoRA and DoRA in terms of performance while requiring lesser GPU memory than DoRA.

answer this, we consider two checkpoints from the Pythia suite  at different stages of training, i.e., 39K steps and 143K steps, respectively. We fine-tune each of these checkpoints independently with Full-FT, LoRA, and SVFT. We then compare the increase in performance (\(\)Perf). As shown in Table 6, compared to LoRA, SVFT benefits more from better pre-trained weights. We also note that SVFT outperforms LoRA in both settings, suggesting that the benefits of inducing a \(\) that explicitly depends on \(\) are beneficial even when \(\) is sub-optimal.

## 6 Discussion

**Limitations.** Despite significantly reducing learnable parameters and boosting performance, SVFT incurs some additional GPU memory usage. Unlike LoRA, SVFT necessitates computing the SVD and storing both left and right singular vectors. While memory consumption remains comparable to or lower than DoRA and BOFT, it's roughly \(1.2\) that of LoRA. However, similar to the scaling explored in , memory usage should amortize with the increasing scale of adaptation tasks. In future work we will explore quantization and other techniques to address memory concerns.

**Broader Impact.** Our work enables easier personalization of foundational models, which can have both positive and negative societal impacts. Since our method provides computational efficiency (smaller parameter footprint), it will be less expensive to enable personalization.

## 7 Conclusion

This work introduces SVFT, a novel and efficient PEFT approach that leverages the structure of pre-trained weights to determine weight update perturbations. We explore four simple yet effective sparse parameterization patterns, offering flexibility in controlling the model's expressivity and the number of learnable parameters. Extensive experiments on language and vision tasks demonstrate SVFT's effectiveness as a PEFT method across diverse parameter budgets. Furthermore, we theoretically show that SVFT can induce higher-rank perturbation updates compared to existing methods, for a fixed parameter budget. In future work, we aim to develop principled methods to generate sparsity patterns, potentially leading to further performance improvements.