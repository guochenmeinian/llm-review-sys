# Navigable Graphs for High-Dimensional Nearest Neighbor Search: Constructions and Limits

Haya Diwan

New York University

hd2371@nyu.edu

&Jinrui Gou

New York University

jg6226@nyu.edu

&Cameron Musco

UMass Amherst

cmusco@cs.umass.edu

Christopher Musco

New York University

cmusco@nyu.edu

&Torsten Suel

New York University

torsten.suel@nyu.edu

###### Abstract

There has been recent interest in _graph-based nearest neighbor search methods_, many of which are centered on the construction of (approximately) _navigable_ graphs over high-dimensional point sets. A graph is navigable if we can successfully move from any starting node to any target node using a greedy routing strategy where we always move to the neighbor that is closest to the destination according to the given distance function. The complete graph is obviously navigable for any point set, but the important question for applications is if sparser graphs can be constructed. While this question is fairly well understood in low-dimensions, we establish some of the first upper and lower bounds for high-dimensional point sets. First, we give a simple and efficient way to construct a navigable graph with average degree \(O()\) for any set of \(n\) points, in any dimension, for any distance function. We compliment this result with a nearly matching lower bound: even under the Euclidean metric in \(O( n)\) dimensions, a random point set has no navigable graph with average degree \(O(n^{})\) for any \(<1/2\). Our lower bound relies on sharp anti-concentration bounds for binomial random variables, which we use to show that the near-neighborhoods of a set of random points do not overlap significantly, forcing any navigable graph to have many edges.

## 1 Introduction

The concept of a _navigable graph_ has arisen repeatedly over the decades, perhaps most famously in Kleinberg's work on understanding Milgram's "Small World" experiments from the 1960s [Kleinberg, 2000a,b, Milgram, 1967]. Concretely, suppose we are given \(n\) points \(x_{1},,x_{n}\) in some input domain \(\), a distance function \(D:^{ 0}\), and a directed graph \(G=(V,E)\), where each vertex in \(V=\{1,,n\}\) is associated with one of our points. \(G\) is said to be _navigable_ if the standard _greedy routing_ algorithm successfully finds a path between any starting vertex \(s V\) and any target vertex \(t V\).1 In particular, letting \((s)\) denote the out-neighbors of \(s\), this algorithm first navigates to \(r(s)\) which minimizes \(D(x_{r},x_{t})\). At each subsequent step, we navigate to the out-neighbor of the current node that minimizes the distance to \(x_{t}\), terminating once we reach \(x_{t}\), or if no neighbor has an associated point that is closer to \(x_{t}\) than the current node.

It has been observed that many real-world networks (the internet, airport networks, social networks, etc.) are either navigable or almost navigable, where \(x_{i}\) plays the role of, e.g., the physical coordinates of a server or individual and \(D\) is the standard Euclidean distance or some other metric [Boguna et al.,2009]. Moreover, there has been interest in showing that natural generative models for networks produce navigable graphs with good probability [Kleinberg, 2000a, Watts and Strogatz, 1998].

### Constructing Sparse Navigable Graphs

More recently, significant work has studied the problem of _constructing_ navigable or "approximately" navigable graphs given a point set \(x_{1},,x_{n}\) and distance function \(D\). For any \(D\) and any point set, the complete graph is navigable, so more concretely, the goal is to construct a navigable graph that is _as sparse as possible_. At a high-level, this objective underlies many recently developed graph-based approximate nearest neighbor search methods such as DiskANN [Subramanya et al., 2019], the Hierarchical Navigable Small World (HNSW) method [Malkov and Yashunin, 2020, Malkov et al., 2014], and the Navigating Spreading-out Graph (NSG) method [Fu et al., 2019].2 Such methods have shown remarkable empirical performance, outperforming state-of-the-art implementations of popular approximate nearest neighbor search algorithms such as product-quantization and locality-sensitive hashing [Johnson et al., 2021, Jegou et al., 2011, Indyk and Motwani, 1998, Andoni et al., 2015]. The computational efficiency of the graph-based methods is governed by the number of edges in the graph being searched, motivating the need for sparse navigable graphs.

Despite this recent interest, there has been relatively little theoretical work on the problem of constructing navigable graphs. When the input points lie in \(^{d}\) and \(D\) is the Euclidean distance function, it is not hard to check that the Delaunay graph is navigable.3 While the Delaunay graph has average degree \(O(1)\) in dimension \(d=2\) (since it is planar) it can have average degree \(O(n)\) in dimension \(d=3\) or higher [Klee, 1980]. A better bound can be obtained via the so-called _sparse neighborhood graphs_ of [Arya and Mount, 1993], which are shown to be navigable for any point set in \(^{d}\) under the Euclidean distance and have average degree \(2^{O(d)}\).4 While this results in a sparse navigable graph for small values of \(d\), the degree bound is no better than that of the complete graph for \(d=( n)\). Given that modern applications of nearest neighbor search often involve high dimensional data points, it is natural to ask if anything better can be done in high dimensions.

### Our Results

The main contribution of this work is to provide tight upper and lower bounds on the sparsity required to construct navigable graphs for high-dimensional point sets. In particular, we prove two main results. The first is a strong upper bound that follows from a straight-forward graph construction:

**Theorem 1**.: _For any input domain \(\), point set \(x_{1},,x_{n}\), and distance function \(D:^{ 0}\) such that \(D(x_{i},x_{i})=0\) for all \(i\) and \(D(x_{i},x_{j})>0\) for \(x_{j} x_{i}\), it is possible to efficiently construct a directed navigable graph with average degree at most \(2\). Moreover, the graph has the additional "small world" property: greedy routing always succeeds in at most 2 steps._

Theorem 1 establishes that, even in arbitrarily high dimension, it is possible to beat the naive complete-graph solution, which has \(O(n^{2})\) edges (average degree \(n\)). The result is proven in Section 3. It is based on an simple construction, reminiscent of existing techniques for building nearest neighbor search graphs: we take the union of a \(O()\)-nearest neighbor graph, and a random graph with average degree \(O()\)[Malkov et al., 2014, Kleinberg, 2000b, Subramanya et al., 2019].

Surprisingly, Theorem 1 holds for essentially any distance function, even if it is not a metric. Moreover, the construction is efficient: the navigable graph can be computed in \(O(n^{2}(T+ n))\) time, where \(T\) is a bound on the cost of computing \(D(x_{i},x_{j})\) for any \(i,j\). Given the generality of Theorem 1, we might expect that navigable graphs with even fewer edges could be constructed under additional assumptions - e.g., if we considered only the special case where the input domain is \(^{d}\) and \(D\) is the Euclidean distance. Our next result rules this out when \(d=( n)\). In particular, we show:

**Theorem 2**.: _Let \(x_{1},,x_{n}^{d}\) be vectors with i.i.d. random \( 1\) entries, and let \(D(x_{i},x_{j})=\|x_{i}-x_{j}\|_{2}\) be the Euclidean distance. For any parameter \(>0\), if \(d} n\) for a fixed constant \(c\), then with high probability, any navigable graph for \(x_{1},,x_{n}\) requires average degree \((n^{1/2-})\)._Theorem 2 is proven in Section 4. It is a corollary of our more general Theorem 4, which also implies a lower bound of \((n^{1/2}/ n)\) average degree when \(d=(^{3}n)\). The proof starts with a straight forward observation: in order for greedy routing to make progress towards a destination node \(x_{i}\), any node within the \(k\)-nearest neighbor set of \(x_{i}\), for any \(k\), must include an edge to some other node in that set (possibly \(x_{i}\) itself). Using sharp anti-concentration bounds for binomial random variables (Ahle, 2017; Cramer, 2022), we argue that, when \(k=O()\) and when \(x_{1},,x_{n}\{-1,1\}^{d}\) are random for large enough \(d\), the nearest neighbor sets for different destination nodes have very small pairwise intersections. Intuitively, they are nearly independent random sets of size \(O()\), and thus have expected overlap close to \(1\). This small overlap means that few edges can be used to 'cover' the required connections within different nearest neighborhoods, giving a lower bound on the average degree of any navigable graph.

We remark that Theorem 2 cannot be improved significantly in its bound on the dimension \(d\). As mentioned, for the Euclidean distance over \(^{d}\), it is possible to construct navigable graphs with \(2^{O(d)}\) edges for any \(d\) dimensional point set using the sparse neighborhood graphs of (Arya and Mount, 1993). This leads to average degree less than \(n^{1/2}\) when \(d=c n\) for a small enough constant \(c\).

### Outlook

Together, Theorems 1 and 2 help complete the picture of what level of sparsity is achievable when constructing navigable graphs in high-dimensions. However, these bounds are not the end of the story. For one, there are many variations on simple greedy search that would lead to other notions of navigability. For example, in nearest neighbor search applications, a version of greedy search called _beam search_, which explores multiple greedy paths, is often preferred (Subramanya et al., 2019).

Beyond the average degree, which we focus on in this work, the _maximum degree_ of a navigable graph is also a natural metric, governing the maximum complexity of each iteration of greedy search. Unfortunately, for the navigability problem we study, we show in Section 4.3 that there are point sets for which _every_ navigable graph must have maximum degree \(n\). It would be interesting if relaxations of the problem or a more flexible search method can avoid this limitation.

Finally, an important direction for future work is to prove end-to-end approximation guarantees for graph-based nearest neighbor search algorithms. Since finding _exact_ nearest neighbors in high dimensions suffers from challenges related to the curse of dimensionality, a reasonable goal would be to prove that greedily routing towards any query \(q\) converges on an \(\)-approximate nearest neighbor \(x_{j}\) satisfying \(D(q,x_{j})_{i}D(q,x_{i})\) for some \( 1\). This is the sort of guarantee that locality sensitive hashing and other methods can achieve with query time that is provably _sublinear in \(n\)_, i.e., without needing to directly compare \(q\) to all vectors \(x_{1},,x_{n}\)(Kleinberg, 1997; Kushilevitz et al., 1998; Indyk and Motwani, 1998; Har-Peled, 2001). Importantly, if regular greedy search is applied from an arbitrary starting node, navigability is a _necessary condition_ for \(\)-approximate nearest-neighbor search. In particular, for any finite \(\), if \(q\{x_{1},,x_{n}\}\), \(_{i}D(q,x_{i})=0\), so we must return \(q\) exactly. However, navigability is not a _sufficient condition_ for greedy search to succeed, as it does not guarantee any level of approximation _for_ queries \(q\) that are not in \(\{x_{1},,x_{n}\}\). For some initial work on this more challenging problem, we refer to the reader to Laarhoven (2018); Prokhorenkova and Shekhovtsov (2020), and Indyk and Xu (2023).

## 2 Preliminaries

**Notation.** Throughout, we consider a set of \(n\) distinct points \(x_{1},,x_{n}\) for some input domain \(\) and a distance function \(D:^{ 0}\). \(D(x_{i},x_{j})\) denotes the distance from point \(j\) to point \(i\). We assume only that \(D(x_{i},x_{i})=0\) for all \(i\) and that \(D(x_{i},x_{j})>0\) for \(x_{j} x_{i}\).5 Our main upper bound, Theorem 1, does not require \(D\) to be a metric, or even to be symmetric. Our main lower bound, Theorem 2, holds against the standard Euclidean distance \(D(x_{i},x_{j})=\|x_{i}-x_{j}\|_{2}\).

We aim to construct a directed graph \(G=(V,E)\), where each vertex in \(V=\{1,,n\}\) is associated with one of our input points. Each edge \(e E\) is an ordered pair \((i,j)\), indicating that there is an edge from node \(i\) to node \(j\). Throughout, we let \( n\) denote the natural base-\(e\) logarithm of \(n\), and \( n\) denote the base-2 logarithm of \(n\).

```
1:Input: Graph \(G\) over nodes \(\{1,,n\}\), starting node \(s\), query point \(\).
2:Output: A point \(x_{j}\) that is ideally close to \(\) with respect to distance function \(D\).
3:\(j s\), \(\)
4:while\(==\)do
5:if\((j)=\)then
6:\(\).
7:else
8:\(h*{argmin}_{i(j)}D(,x_{i})\), where ties are broken to prefer nodes with the lowest id.6
9:if\(D(,x_{h})<D(,x_{j})\)then
10:\(j h\).
11:else if\(D(,x_{h})=D(,x_{j})\) and \(h<j\)then\(\) Tie-breaking on node id.
12:\(j h\).
13:else
14:\(\).
15: Return \(x_{j}\) ```

**Algorithm 1** Greedy Search

**Distance-Based Permutations.** We let \((i)\) denote the out-neighbors of node \(i\) in the graph; i.e., \(j(i)\) if and only if \((i,j) E\). We use the notation \(N_{1}(i),,N_{n}(i)\) to index the list of nodes in the graph ordered in non-decreasing order by their distances from \(i\); i.e., for \(k<\), \(D(x_{i},x_{N_{k}(i)}) D(x_{i},x_{N_{}(i)})\). Ties are broken by node id. Specifically, whenever \(D(x_{i},x_{N_{k}(i)})=D(x_{i},x_{N_{}(i)})\) and \(k<\), then \(N_{k}(i)<N_{}(i)\). This choice is arbitrary, but a consistent way of breaking ties will simplify our exposition. For most applications, we will not have distances repeat _exactly_ in the dataset, so tie breaking is never invoked. Note that since we assume \(x_{1},,x_{n}\) are distinct and that \(D(x_{i},x_{i})=0\) for all \(i\) and \(D(x_{i},x_{j})>0\) for all \(j i\), we always have that \(N_{1}(i)=i\).

**Greedy Search and Navigability.** We study a notion of navigability that is tied to the standard greedy graph search algorithm for nearest neighbors, which is detailed in Algorithm 1. It can be checked that the algorithm always terminates in at most \(n\) iterations since \(j\) can only be equal to every node in the graph at most once. Additionally, we note that Line 11 and 12 are unnecessary in the case when distances are assumed to be unique. When this is not the case, these lines implement our arbitrary tie-breaking rule, which is to prefer nodes with lower id when distances are equal.

Given Algorithm 1, we define navigability formally as follows:

**Definition 3** (Navigable Graph).: _A graph \(G\) is navigable for point set \(x_{1},,x_{n}\) under distance function \(D\) if, for all \(s,t\{1,,n\}\), when Algorithm 1 is run with starting node \(s\) and query \(=x_{t}\), then the algorithm returns \(x_{t}\). I.e., when the query \(\) exactly matches a point in the dataset, the algorithm finds that point. We further say that \(G\) is "small world" with parameter \(S\) if the algorithm always terminates after at most \(S\) calls to the while loop._

It will be useful to think about navigability as a property of the distance-based node permutations defined earlier. In particular, navigability is _implied_ by the following property:

\[t>1N_{}(t)N_{k}(t)k<.\] (1)

In particular, when given a query \(x_{t}\{x_{1},,x_{n}\}\), Algorithm 1 will only move from nodes \(N_{}(t)\) to \(N_{k}(t)\) for which \(k<\). Moreover, as long as there is such a \(k\) in the out-neighborhood of \(N_{}(t)\), then the algorithm will not terminate at \(N_{}(t)\). It follows that, if (1) holds, the algorithm is guaranteed to terminate at \(N_{1}(t)=t\) and return \(x_{t}\), as desired. We remark that, if all distances between nodes are distinct, (1) is equivalent to the navigability property of Definition 3, although we will not require this fact. To better illustrate the connection between (1) and Definition 3, we include an example of a navigable graph in Figure 1 and the corresponding list of distance-based permutations in Figure 2.

## 3 Upper Bound

We begin by proving our main positive result, which we restate below:

**Theorem 1**.: _For any input domain \(\), point set \(x_{1},,x_{n}\), and distance function \(D:^{ 0}\) such that \(D(x_{i},x_{i})=0\) for all \(i\) and \(D(x_{i},x_{j})>0\) for \(x_{j} x_{i}\), it is possible to efficiently construct a directed navigable graph with average degree at most \(2\). Moreover, the graph has the additional "small world" property: greedy routing always succeeds in at most 2 steps._

Proof.: We give two different constructions that establish the theorem. The first is randomized, and succeeds with high probability. The second is deterministic. Both require \(O(n^{2}(T+ n))\) time to construct, where \(T\) is the time to evaluate the distance function \(D\) for any two input points.

**Construction 1: Randomized.** Let \(m\) be an integer between \(1\) and \(n\), to be chosen later. Our first construction is as follows:

* For all \(i\{1,,n\}\) and all \(1< m\), add an edge from \(N_{}(i)\) to \(N_{1}(i)=i\).
* For all \(i\{1,,n\}\), add an edge from \(i\) to \(\) nodes chosen uniformly at random from \(\{1,,n\}\{i\}\).

To prove that this construction leads to a navigable graph, we need to prove the (1) holds with high probability. To do so, consider the permutation \(N_{1}(i),,N_{n}(i)\) for a fixed node \(i\). The property trivially holds for all \( m\) since we connected \(N_{}(i)\) to \(N_{1}(i)\) in step one of the construction. So, we only have to consider \(>m\).

For any \(>m\), the chance that any one random edge from the second step of the construction connects to some \(N_{k}(i)\) for \(k m\) is \(\). So, the chance that _none of the random edges_ connect \(N_{}(i)\) to some \(N_{k}(i)\) for \(k m\) is at most \((1-)^{}}}\). By a union bound, it follows

Figure 1: Example of a navigable graph \(G=(V,E)\) on \(5\) nodes. A double arrow indicates that both \((i,j) E\) and \((j,i) E\). We can check that \(G\) is navigable by referring to Figure 2.

Figure 2: Distance-based permutations for the data set in Figure 1. As an example, in the plot above, we have \(N_{1}(1)=1,N_{2}(1)=2,N_{3}(1)=5,N_{4}(1)=4,N_{5}(1)=3\), we have \(N_{1}(2)=2,N_{2}(2)=1,N_{3}(2)=3,N_{4}(2)=5,N_{5}(2)=4\), etc. For the permutations, we draw all edges in the graph \(G\) from Figure 1 that point “left” in the permutation. In particular, we show edges that connect any \(N_{}(t)\) to \(N_{k}(t)\) with \(k<\). We can check that property (1) holds, so the graph is navigable.

that with probability at least \(1-\), for all \(i\) and all \(>m\), \(N_{}(i)\) has an edge to some \(N_{k}(i)\) with \(k m<\). Thus property (1) holds, and we conclude that the graph we constructed is navigable.

It is left to set \(m\). The graph we constructed has at most \((m-1)n+n mn+n\) edges. Balancing terms, if we choose \(m=\), the graph has \( 2n^{1.5}\) edges.

Finally, we observe that constructing the graph requires computing and sorting all \(n\) distance-based permutations, which takes \(O(n^{2}(T+ n))\) time. Moreover, we can see that the constructed graph is small-world with parameter \(C=2\). In the first iteration of Algorithm 1, we are guaranteed to choose a node \(h\) that is one of the \(m\) closest neighbors of the input \(=x_{i}\). Then, at the second iteration, \(h\) has an edge to \(i\) itself and so we terminate.

**Construction 2: Deterministic.** Our randomized construction can be derandomized relatively directly. We construct the same \(n(m-1)\) edges from \(N_{}(i)\) to \(N_{1}(i)\) for all \(i\) and \(1< m\). The goal in constructing random edges was to ensure that, for \(>m\), \(N_{}(i)\) always has an edge to some node in \(\{N_{1}(i),,N_{m}(i)\}\), which we will call \(i\)'s "near-neighborhood", and denote by \(_{m}(i)\). We can instead ensure that each \(N_{}(i)\) has an edge into \(_{m}(i)\) via a greedy set cover approach.

In particular, we claim that there is a set of \(g 1+\) nodes \(k_{1},,k_{g}\) such that every near-neighborhood \(_{m}(i)\) contains at least one of \(k_{1},,k_{g}\). To ensure property (1) for values of \(>m\), we only have to connect all nodes in our graph to this set. We construct this set greedily. Let \(B_{1}=\{1,,n\}\) and, for \(i>1\), let \(B_{i}\) denote the set of all \(i\) for which none of \(k_{1},,k_{i-1}\) is in \(_{m}(i)\). We have that \(|B_{1}|=n\) and our goal is to show that \(|B_{g+1}|<1\). By a counting argument, there must be at least one node that appears in \(_{m}(i)\) for at least \(m\) different values of \(i B_{1}\). Select this node to be \(k_{1}\), which ensures that:

\[|B_{2}|(1-)|B_{1}|=(1-)n.\]

Again by a counting argument, there must be one node that appears in \(_{m}(i)\) for at least \(| m}{n}\) values of \(i B_{1}\). Select this node to be \(k_{2}\), which ensures that:

\[|B_{3}||B_{2}|-| m}{n}=(1-)|B_{2}| (1-)^{2}n.\]

Continuing in this way, we conclude that \(|B_{g+1}|(1-)^{g}n\), which is less than \(1\) as long as \(g>\). We conclude that, as long as we connect every node to \(k_{1},,k_{g}\), (1) is satisfied for all \(N_{}(i)\) where \(>m\), so our constructed graph is navigable.

In total, our deterministic graph has at most \((m-1)n+n( n\ +1)\) edges. Choosing \(m=\) we get a graph with at most \(2n^{1.5}\) edges. Again, the cost of the algorithm is dominated by the \(O(n^{2}(T+ n))\) time required to compute and sort all \(n\) distance-based permutations. 

We remark that, while it may be possible to improve our upper bound from \(O()\) to \(O()\) average degree, we do not believe our analysis can be directly tightened. For random points in high-dimensional space under the Euclidean metric, we roughly expect each near-neighborhood \(_{m}(i)\) to look like a uniformly random subset of \(\{1,,n\}\). If the neighborhoods were truly random, then existing results on random set cover problems imply that it is not possible to find \(k_{1},,k_{g}\) covering all near-neighborhoods unless \(g=()\)(Vercellis, 1984; Arpino et al., 2024).

## 4 Lower Bounds

In this section, we prove Theorem 2, which shows that even for a random point set in \(^{d}\) for \(d=O( n)\) under the Euclidean metric, Theorem 1 cannot be improved significantly: with high probability, any navigable graph \(G\) must have average degree \((n^{1/2-})\) for any fixed constant \(\). Theorem 2 is a corollary of our more general Theorem 4, which we state below:

**Theorem 4**.: _Let \(x_{1},,x_{n}\{-1,1\}^{d}\) be distributed independently and uniformly in \(\{-1,1\}^{d}\). With probability \(>\), any navigable graph for \(x_{1},,x_{n}\) under the Euclidean metric requires \((n^{3/2-})\) edges, for \(=(,c})\) for a universal constant \(c\)._The \((n^{3/2-})\) lower bound of Theorem 2 follows immediately from Theorem 4 by taking \(d=}{^{2}} n\). Alternatively, if we take \(d=c^{2}^{3}n\) we have a lower bound of \((n^{3/2}/ n)\), which matches Theorem 1 up to a \(O(^{3/2}n)\) factor.

### Average Degree Lower Bound

We introduce a few intermediate results before giving the proof of Theorem 4. First, we observe that the point set of Theorem 4 does not have any duplicate points with high probability. Doing so simplifies our analysis as no "tie-breaking" will be needed when Algorithm 1 is run on an input \(x_{j}\).

**Claim 5** (No Repeated Points).: _Let \(x_{1},,x_{n}\) be distributed as in Theorem 4. As long as \(d c_{1} n\) for a universal constant \(c_{1}\), then with probability at least \(99/100\), all vectors in this set are distinct._

The claim follows from a simple probability calculation and union bound - see Appendix A.

We next define a notion of a neighborhood of a point, which includes all points within a certain radius.

**Definition 6** (Fixed Radius Near-Neighborhood).: _Consider the setting of Theorem 4. Let \(_{j}\) be the subset of vectors in \(x_{1},,x_{n}\) (including \(x_{j}\) itself) with \( x_{i},x_{j} c_{h}\) where \(c_{h}[1/3,1]\) is some value (that may depend on \(n\)) which we will specify later._

Note that, for any \(x_{i},x_{j}\{-1,1\}^{d}\), \(\|x_{i}-x_{j}\|_{2}^{2}=d-2 x_{i},x_{j}\), so \(_{j}\) contains a set of nearest neighbors to \(j\) in the Euclidean distance. Importantly, however, the definition used in this section is different from the \(_{m}(j)\) notation used in the previous section, since \(_{j}\) is not of a fixed size.

Using the distance-based permutation characterization of navigability given in (1), we can observe that, in order for greedy routing to make progress towards target \(x_{j}\), every node in the near-neighborhood \(_{j}\) needs an edge to another node in the near-neighborhood, closer to \(x_{j}\). Formally:

**Claim 7** (Required Connections Within Neighborhoods).: _Consider the setting of Theorem 4 and assume that \(x_{1},,x_{n}\{-1,1\}^{d}\) are distinct. Any navigable graph \(G\) for \(x_{1},,x_{n}\) requires \(|_{j}|-1\) edges in \(_{j}_{j}\) for each \(j\)._

Proof.: For \(G\) to be navigable, for any \(i_{j}\{j\}\), there must be an edge from \(i\) to some node that is closer \(j\), and thus is also in \(_{j}\). Thus, there are at least \(|_{j}|-1\) edges in \(_{j}_{j}\). 

We next make two claims about the near neighborhoods of Definition 6 when \(x_{1},,x_{n}\) are random points in \(\{-1,1\}^{d}\): that 1) they are large with high probability and 2) that they have low overlap with high probability. Together with Claim 7, these imply that any navigable graph \(G\) for \(x_{1},,x_{n}\) requires a large number of edges, proving Theorem 4. We first formally state the claims and prove Theorem 4 using them. We then prove the claims in Section 4.2.

**Claim 8** (Neighborhoods are Large).: _Let \(x_{1},,x_{n}\) be as distributed as in Theorem 4 and let \(_{j}\) be as in Definition 6. As long as \(d c_{1} n\) for a universal constant \(c_{1}\), with probability at least \(99/100\), for all \(j\), \(|_{j}|/6\)._

**Claim 9** (Neighbored Intersections are Small).: _Let \(x_{1},,x_{n}\) be distributed as in Theorem 4 and let \(_{j}\) be as in Definition 6. As long as \(d c_{1} n\) for a universal constant \(c_{1}\), with probability at least \(99/100\), for all \(i j\), \(|_{i}_{j}| 10( n,n^{c}})\) for some universal constant \(c\)._

Claim 8 establishes that \(_{j}\) contains the \(()\) nearest neighbors to \(x_{j}\), which is a consequence of our choice of radius in Def. 6. If each \(_{j}\) were just an independent random set of \(()\) nodes, then we would expect that for any \(i j\), \(|_{i}_{j}|=(1)\). I.e., our neighborhoods would have small overlap, which is the key property we need to prove a lower bound. An overlap of \(O(1)\) would imply that \(O(n^{3/2})\) edges are needed to satisfy the requirements of Claim 7. Of course, each \(_{j}\) is not an independent random set in reality. Specifically, if \(x_{i}\) and \(x_{j}\) have large inner product, \(_{i}\) and \(_{j}\) will be correlated, so we expect that \(|_{i}_{j}|\) will be larger. Claim 9 shows that for large enough \(d\), such strong correlations are unlikely to happen and thus we still expect \(|_{i}_{j}|\) to be fairly small.

Proof of Theorem 4.: First note that we can assume that \(d c_{1} n\) for some large constant \(c_{1}\), as otherwise we will have \(>3/2\) and the lower bound becomes vacuous. Accordingly, the conclusions of Claims 5, 8 and 9 all hold for \(x_{1},,x_{n}\) with probability \(>9/10\) by a union bound.

We will use these claims to show that any navigable graph for \(x_{1},,x_{n}\) requires \((n^{3/2-})\) edges. Consider any navigable graph \(G=(V,E)\). For any edge \((u,v) E\), let \(w_{u,v}=|\{j:u,v_{j}\}|\) be the number of near neighborhoods that \(u\) and \(v\) both belong to. I.e., \(w_{u,v}\) is the number of nodes \(j\) for which \((u,v)_{j}_{j}\). By Claims 7 and 8, we must have

\[_{(u,v) E}w_{u,v}_{j=1}^{n}|_{j}|-1 }{6}-n}{12},\] (2)

where we use in the last step that \(n n^{3/2}/12\) for large enough \(n\).

Further, \(w_{u,v}=|_{u}_{v}|\) since \(u\) and \(v\) both lie in \(_{j}\) exactly when \(j\) lies in both \(O_{u}\) and \(_{v}\). Thus, by Claim 9, \(w_{u,v} 10( n,n^{c})\) for all \(u,v\). Combined with (2) this gives:

\[|E|/12}{10( n,n^{c})}=(n^{3/2- }),\]

for \(=(,c)\). This proves the theorem. 

### Probabilistic Claims about Near Neighborhoods

We now prove Claims 8 and 9. We will use a very sharp bound on the CDF of a binomial distribution, given by Ahle (2017) and attributed to Cramer (Cramer, 2022). This is a quantitative version of the central limit theorem, saying that the binomial CDF is close to the normal CDF, up to some small error. It is tighter than more general bounds like the Berry-Esseen theorem. We give a proof of our exact statement of the bound in Appendix A.

**Fact 10** (Binomial CDF Bound, 2.20 of (Ahle, 2017)).: _Let \(F_{t}()\) be the CDF of a mean centered binomial random variable with \(t\) trials and success probability \(1/2\). There are universal constants \(c_{1},c_{2}\) such that, for any \(x\) satisfying \(c_{1} x/c_{1}\),_

\[e^{-}{2}(1+x^{2}}{t})} F _{t}(-x/2)e^{-}{2}(1-x^{2}}{t})}.\]

We will also use that, with high probability, no pair of our random vectors has too high of an inner product. This will be required to prove Claim 9, i.e., that all near neighborhoods have small overlap. The claim follows directly from a standard Chernoff bound and a union bound over all pairs \(i,j\).

**Claim 11** (Vectors are Not Too Similar).: _Let \(x_{1},,x_{n}\) be distributed as in Theorem 4. As long as \(d c_{1} n\) for a universal constant \(c_{1}\), with probability at least \(99/100\), for all \(i j\), \( x_{i},x_{j} c_{u}\) for some fixed constant \(c_{u}\)._

Finally, we require the following technical claim, which we will use to set \(c_{h}\) in Definition 6. Our goal is to ensure that the probability of a vector being in the near neighborhood of another is \((1/)\).

**Claim 12**.: _For any large enough \(n\), there is some value of \(c[1/3,1]\) such that_

\[}(-c^{2} n)=}.\]

Proof.: Observe that if we set \(c=1\), then

\[}(-c^{2} n)=}< }.\]

Further, if we set \(c=1/3\), we have for large enough \(n\),

\[}(-c^{2} n)=}( -1/9 n)= n^{1/9}}>}.\]

Thus, for some setting of \(c[1/3,1]\) the claim holds.

[MISSING_PAGE_FAIL:9]

Now, since we set \(d c_{1} n\) for a large constant \(c_{1}\), we can ensure that have that \( c_{3}}{}\) for any small constant \(c_{3}\). Using this fact, along with the fact that \( d/2\), we have:

\[c_{h}^{2} n}{})}{(1+c_{h}^{2} n}{d})(1+c_{u}})} })}{(1+.5c_{u}})(1+c_{u}})} 1 -2c_{u}}.\]

For the second inequality, we used the fact that \(} 1-2x\) for all \(x\). Next, setting \(c_{h}[1/3,1]\) exactly as in (4) so that \(}(-^{2}}{2} n(1+ c_{h}^{2} n}{d}))=}\), we have:

\[(x_{k}_{i}_{j}) }{c_{h}}(-c_{h}^{2}  n(1+c_{h}^{2} n}{d})(1-2c_{u} }))\] \[}{c_{h}n}(2c_{h}^{2}c_{u} n (1+c_{h}^{2} n}{d})})\] \[}{n}(n}{d} )=}{n} n^{c}},\]

for some constant \(c\). Finally, observe that, conditioned on \(x_{i}\) and \(x_{j}\) sharing \(z\) entries, the event \(x_{k}_{i}_{j}\) is independent for each \(x_{k}\). Thus, by a standard Chernoff bound, with probability at least \(1-1/n^{c^{}}\), we have \(|_{i}_{j}| 10( n,n^{c}})\) for some large constant \(c^{}\). Union bounding over all \(O(n^{2})\) pairs \(i j\) then gives the claim. 

### Maximum Degree Lower Bound

In Theorems 1 and 2, we focus on the _average degree_ of navigable graphs. While a reasonable metric, we might also be interested in the _maximum degree_, which governs the worst-case complexity of a single step of the greedy algorithms. Here we give a simple argument showing that unfortunately, on a worst-case input instance, it is not possible to achieve maximum degree better than the trivial \(n-1\) given by the complete graph.

**Theorem 13**.: _There exists a set of points \(x_{1},,x_{n}^{d}\) for \(d=O( n)\) such that any navigable graph for these points under the Euclidean metric has maximum out-degree \(d-1\)._

Proof.: First we prove the bound for a high dimensional point set. For all \(i<n\), let \(x_{i}\) be a standard basis vector with a \(1\) in position \(i\). Let \(x_{n}\) be the all zeros vector. As we can see, \(x_{n}\) has Euclidean distance \(1\) from \(x_{1},,x_{n-1}\). On the other hand, for all \(i j\) where \(i,j n\), \(\|x_{i}-x\|_{2}=\). In other words, \(x_{n}\) is the closest neighbor to each of \(x_{1},,x_{n-1}\). It follows that any navigable graph _must_ contain an edge from \(x_{1}\) to each of these points, resulting in maximum degree \(n\).

To extend the construction to low dimensions, we simply use the Johnson-Lindenstrauss Lemma to embed the point set above into \(c n\) dimensions. As long as the constant \(c\) is sufficiently large, all distances will be preserved to within error, say, \( 0.1\). So, \(x_{n}\) will still be the nearest neighbor of all other points, and we will still require it to have out-degree \(n-1\).