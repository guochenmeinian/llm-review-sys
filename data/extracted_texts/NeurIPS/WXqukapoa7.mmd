# Disentangling Linear Quadratic Control with

Untrusted ML Predictions

 Tongxin Li\({}^{1}\)  Hao Liu\({}^{2}\)  Yisong Yue\({}^{2}\)

\({}^{1}\)School of Data Science

The Chinese University of Hong Kong, Shenzhen, China

litongxin@cuhk.edu.cn

\({}^{2}\)Computing + Mathematical Sciences

California Institute of Technology, Pasadena, USA

{hliu3, yyue}@caltech.edu

Correspondence to: Tongxin Li <litongxin@cuhk.edu.cn>. Tongxin Li contributed to the design of the algorithms and experiments, and the writing of the paper. Hao Liu focused on conducting the experiments and data analysis. The contributions are equal.

###### Abstract

Uncertain perturbations in dynamical systems often arise from diverse resources, represented by latent components. The predictions for these components, typically generated by "black-box" machine learning tools, are prone to inaccuracies. To tackle this challenge, we introduce Disc, a novel policy that learns a confidence parameter online to harness the potential of accurate predictions while also mitigating the impact of erroneous forecasts. When predictions are precise, Disc leverages this information to achieve near-optimal performance. Conversely, in the case of significant prediction errors, it still has a worst-case competitive ratio guarantee. We provide competitive ratio bounds for Disc under both linear mixing of latent variables as well as a broader class of mixing functions. Our results highlight a first-of-its-kind "best-of-both-worlds" integration of machine-learned predictions, thus lead to a near-optimal consistency and robustness tradeoff, which provably improves what can be obtained without learning the confidence parameter. We validate the applicability of Disc across a spectrum of practical scenarios.

## 1 Introduction

We study the problem of online decision-making with predictions. Such settings are increasingly popular with the use of machine learning for predictive modeling, with applications to power grids and robotics [1; 2; 3; 4]. However, in many real-world settings, such black-box predictors can be unreliable due to practical problems such as high model variability [5; 6], and out-of-distribution generalization issues [7; 8]. In settings that require making reliable and high-quality decisions, recent research has been working on designing the decision-making policy that can be adaptively in response to receiving low-quality predictions .

In this paper, we consider the setting where there are different sources of disturbance, each representing distinct (and often independent) resources or factors. For instance, in electricity grids, machine learning (ML) forecasts of variables like power consumption/generation fluctuations, electricity prices, and battery states can facilitate near-optimal operational decisions on the one hand, but on the other hand, latent variables such as power injections on certain loads can be highly unpredictable due to their volatility . Another example is the drone navigation task , where the challengelies in managing external perturbations caused by a mixture of predictable elements like air flows and less predictable factors like raindrops. When performing online decision-making in this setting, one important technical challenge is to be able to combine disentanglement with an adaptive online learning algorithm to result in a more exact estimation of the trustfulness of the disturbance. To address this challenge, in this work, we focus on a linear quadratic control problem where system perturbations originate from unidentified and possibly heterogeneous latent resources/components.

Contributions.We develop a novel policy Disc that does the disentanglement and learns the adaptive parameter online simultaneously. We first introduce a policy, \(\)-Con, which extends the \(\)-confident approach in  by adapting a vectorized confidence parameter \(^{k}\), where each \((i)\) represents the estimated trustworthiness of the ML prediction for the \(i\)-th latent variable in the dynamical system. We then show that a static \(\) cannot guarantee an optimal consistency and robustness tradeoff (see Definition 2.2 for a formal description) for \(\)-Con: if \(\)-Con is \((1+o(1))\)_-consistent_, then it is at least \((1)\)_-robust_.

To circumvent this limitation, we propose the dynamic policy Disc (Section 3.2). This algorithm leverages online learning to optimize the confidence parameter \(_{t}\) at each time \(t\). We establish competitive ratio guarantees for Disc in both linear and general mixing scenarios, as shown in Theorems 4.2 and 4.3 (Section 4) respectively. Under Assumption 1 and 2. The competitive ratio bound for Disc, outlined informally as follows, incorporates a term that embodies our _"best-of-both-worlds utilization"_ of untrusted ML predictions:

\[[()] 1+o(1)+O(^{2w} )+^{k}(i)}{ (T/w)+(i)})}_{},\] (1)

where the \(o(1)\) term hides quantities that vanish when the total number of steps \(T\) increases; \(k\) is the number of latent variables generating the perturbations; \((0,1)\); \(w\) denotes the prediction window size and each \((i)\) (for \(i=1,,k\)) denotes the prediction error corresponding to each latent component. The last term in this result highlights the desired performance guarantee: When a component-wise prediction error \((i)\) is small, the individual term \((i)/((T/w)+(i))\) will be negligible; otherwise, it always holds that \((i)/((T/w)+(i)) 1\), regardless of how high the prediction error becomes. Our proposed Disc is both \((1+o(1))\)-consistent and \(O(1)\)-robust with a sufficiently large prediction window size. We offer the first bound of this nature, grounded in a term as a function of the prediction error, without restrictive assumptions on the errors \(((1),,(k))\).

Proving our main result above is nontrivial due to the fact that despite it is known that an input-disturbed linear system can be reduced to an online convex optimization (OCO) with structured memory , the connection between the problem with \(\)-Con and a memoryless online optimization is not previously discovered. In Lemma 1, we provide a result that decouples the loss terms in the total regret in (9) and future perturbations, thereby reducing the problem of choosing \(_{t}\) to an online optimization instance. Then we use a two-stage analysis as depicted in Figure 7 that combines a dynamic regret bound for our control policy and static regret bounds induced by online learning algorithms to derive the main result.

We demonstrate the practicality of Disc through two real-world examples (Section 5): a drone navigation problem with mixed external disturbances and voltage control in a power grid with heterogeneous power injections. We demonstrate that Disc, when applied with disentangled ML predictions, outperforms baselines that do not distinguish between underlying latent variables. Additionally, Disc shows remarkable adaptability to rapid changes in various scenarios, such as those involving ML models trained with out-of-distribution data in a non-stationary environment.

Related Work.Our work contributes to the growing community of algorithms with predictions while also incorporating ideas from adaptive control, online learning, and disentangled representation learning. We summarize the detailed related work in Appendix A.

## 2 Problem Formulation

Notational conventions.Throughout this paper, \(\|\|\) denotes the \(_{2}\)-norm for vectors and the matrix norm induced by the \(_{2}\)-norm. We use a subscript \(()_{t}\) to represent a length-\(k\) vector \((s_{t}(1),,s_{t}(k))\) at time \(t\) whose \(i\)-th coordinate is written as \(s_{t}(i)\). We use \( s((i)s(i),i=1,,k)^{k}\) to denote the Hadamard product between vectors \(,s^{k}\).

### Linear Quadratic Control with Latent Perturbations

We consider a finite-time linear dynamical system with _latent perturbations_. Let \([T]\{0,,T-1\}\) be the set of time steps. Denote by \(x_{t}^{n}\) a system state and \(u_{t}^{m}\) an action from a state feedback policy \(_{t}\) at time \(t[T]\). The system update rule is given by

\[x_{t+1}=Ax_{t}+Bu_{t}+f(s_{t};), t[T]\] (2)

where \(s_{t}(s_{t}(1),,s_{t}(k))^{k}\) (\(k n\)) contains \(k\) latent variables (components) that together generate a perturbation at time \(t[T]\) via a mixing function \(f:^{k}^{n}\) parameterized by \(^{d}\). The states and the actions are observed after being generated, while the mixing function \(f\) transforms the unobservable latent variables in \(s_{t}\) to an additive system perturbation. Throughout this paper, we focus on the nontrivial regime that \(f(s_{t};)_{n}\) for all \(t[T]\).

In (2), \(A^{n n}\) and \(B^{n m}\) are system matrices. We consider the standard regime that the pair \((A,B)\) is stabilizable . Without loss of generality, we also assume the system is initialized with some fixed \(x_{0}^{n}\). The goal of control is to minimize the following quadratic costs given matrices \(A,B,Q,R\):

\[J()_{t=0}^{T-1}(x_{t}^{}Qx_{t}+u_{t}^{}Ru_{t} )+x_{T}^{}Px_{T},\] (3)

where \((_{t}:t[T])\); \(Q^{n n},R^{m m}\) are positive definite matrices, and \(P\) is a symmetric positive definite cost-to-go solution of the following discrete algebraic Riccati equation (DARE), which must exist because \((A,B)\) is stabilizable and \(Q,R\) are positive definite :

\[P=Q+A^{}PA-A^{}PB(R+B^{}PB)^{-1}B^{}PA.\]

Given \(P\), we define \(K(R+B^{}PB)^{-1}B^{}PA\), and \(u_{t}=-Kx_{t}\) is the feedback control law of a linear quadratic regulator (LQR), which is optimal in the case of zero disturbances (\(w_{t}=0\) for all \(t[T]\)). Further, let \(F A-BK\) be the closed-loop system matrix. The Gelfand's formula implies that there must exist a constant \(C_{F}>0\) and a spectral radius \(_{F}(0,1)\) such that \(\|F^{t}\| C_{F}_{F}^{}\) for all \(t[T]\).

In this work, we focus on designing a near-optimal policy \(=(_{t}:t[T])\) that minimizes the total quadratic cost in (3) subject to the linear dynamics in (2). At time \(t[T]\), each \(_{t}:^{n}^{k}^{m}\) is a state-feedback policy that produces an action \(u_{t}^{m}\) with an observed state \(x_{t-1}\), and ML predictions \((_{|t}(i):i=1,,k)\) of the latent variables \(s_{t}^{k}\) for future \(w\) time steps with a prediction window size \(w>0\) (denoting \(\{t+w-1,T-1\}\)). Figure 1 above summarizes our system model. We defer a detailed introduction of the ML predictions in Section 2.2, together with the performance benchmarks considered in this paper. We relegate concrete latent perturbation modelling examples and real-world applications to Appendix B.

In light of the existing nonlinear ICA models summarized in Appendix B, throughout this paper, we assume the continuity and invertibility conditions hold for the mixing func

Figure 1: Overview of the system model considered in this work. **Left** time series: Disentangled latent variable time series predictions provided by an untrusted ML agent at time \(t[T]\), represented by \((_{||i}(i):i=1,,k)\); **Right** time series: Observed mixed perturbations \((f(s_{};):<t)\) at time \(t-1\).

our theoretical results. This assumption is weaker compared to those required in the nonlinear ICA literature [13; 14; 15; 16; 17] to guarantee identifiability, as summarized in Table 1 (see Appendix B), noting that our goal is instead to provide a near-optimal competitive ratio bound regardless of the error of disentanglement and latent variable predictions (see our performance benchmarks defined in Section 2.2).

**Assumption 1**.: The mixing function \(f:^{k}^{n}\) is Lipschitz continuous and bijective with respect to \(s^{k}\).

### Performance Benchmark

Let \(_{|t}\) be the latent variable time series value at time \(\), predicted by an untrusted ML agent at time \(t\). The prediction window size is an integer \(w>0\). We write \(\{t+w-1,T-1\}\). The estimated mixing parameter at each time \(t[T]\) is denoted by \(_{t}\). Define the following error terms2 for all \(t\) and \(t[T]\):

\[(_{|t}(1),,_{|t}(k))= _{|t} s_{}-_{|t},_{t} _{t}-.\] (4)

To assess the cumulative impact of prediction error over all \(T\) time steps, we define the total prediction error corresponding to the component-wise latent variable time-series prediction and the mixing parameter estimation as follows:

\[(i)_{t=0}^{T-1}_{=t}^{ }(_{F}^{-t}_{|t}(i))^{2},_{t=0}^{T-1}\|_{t}\|^{2},\] (5)

where \(_{F}(0,1)\) represents the spectral radius of the matrix \(F\). The term \(_{F}^{-t}\) in (5) accounts for the exponential decay phenomenon in the impact of component-wise errors, implying that predictions further into the future contribute less to the total error. This approach to error measurement is analogous to methods employed in linear quadratic control models with adaptive offline adversarial perturbations, as discussed in , which provides a foundational understanding of error evaluation in our context.

Our performance benchmark is the competitive ratio for a given prediction error \(\), defined as follows. To be more precise, we focus on the competitive ratio defined for deterministic online algorithms with an adaptive offline adversary that selects the system parameters \(A,B,Q,R,f,\) and latent time series \((s_{t}:t[T])\). Write \(((i):i=1,,k)\) and denote by \(J(;)\) the total cost obtained by implementing \(=(_{t}:t[T])\) with some fixed prediction error \(\).

**Definition 2.1**.: Fix some prediction error \(\). The _competitive ratio_\((;)\) is defined as the smallest constant \(C 1\) such that \(J(;) C J^{}\) for all \(A,B,Q,R,f,\), and \((s_{t}:t[T])\) satisfying the model assumptions.

The following notions of consistency and robustness with respect to the competitive ratio offer a concise characterization to measure the algorithmic performance in the presence of prediction error \(\). It aligns with the benchmarks used in the growing literature on algorithms with predictions [18; 19; 20; 21] (see further discussions provided in Section A).

**Definition 2.2**.: A policy \(\) is _\(\)-consistent_ if its competitive ratio satisfies \((;)\) for \(=0\) and _\(\)-robust_ if \((;)\) for all \(\).

## 3 Disentangled Confident Policy

In this section, we present our policy, Disc, which takes disentangled and untrusted ML predictions and achieves near-optimal consistency and robustness tradeoff (see Definition 2.2).

### Warm-Up: Disentangled \(\)-Confident Policy (\(\)-Con)

Before proceeding to introduce Disc, we first consider a policy that balances consistency and robustness by combining an MPC policy that fully utilizes the untrusted ML predictions, and an LQR without considering any predictions.

Denote by \(\{t+w-1,T-1\}\) and let \(Y(R+B^{}PB)^{-1}B^{}\). Recall that as defined in Section 2.2, at each time \(t[T]\), \((_{|t}:t)\) represents a sequence of predictions for the future values of the latent variables \((s_{}:t)\), with these predictions spanning a predetermined window size \(w>0\). Similarly, the sequence \((_{t}:t[T])\) corresponds to the estimated mixing parameters. At each time \(t[T]\), an estimate \(_{t}\) is obtained by applying some disentanglement algorithm (see those examples in Section B). With this setup, we proceed to define an MPC-type action as follows:

\[u_{t}=-Kx_{t}-Y_{=t}^{}(F^{})^{-t}Pf (_{|t};_{t}), ()\] (6)

which specifies a _disentangled_\(\)-confident policy, denoted by \(\)-Con, where \(^{k}\) is a fixed _trust parameter_. The term \(_{|t}\) denotes the Hadamard product of \(\) and \(_{|t}\). It is worth noting that it is well known that (6) is an optimal solution of the following MPC scheme :

\[_{u^{m}} _{=t}^{}(x_{}^{}Qx_{}+u_{ }^{}Ru_{})+x_{+1}^{}Px_{+1}\] (7) s.t. \[x_{+1}=Ax_{}+Bu_{}+f(_ {|t};_{t}),[t,].\] (8)

In particular, if \(\) is an all-one vector \(_{k}\) in (7), it trusts the ML predictions. Note that it generalizes the \(\)-confident policy in , which linearly combines actions from an MPC policy and an LQR. In Section 4.1, we present a negative result for \(\)-Con, indicating that it cannot achieve the optimal consistency and robustness tradeoff (see Definition 2.2). This motivates the disentangled confident policy discussed in the next section.

### Disentangled Confidence Policy (Disc)

At each time \(t[T]\), the algorithm adaptively learns a _trust parameter_\(_{t}^{k}\), and uses a Hadamard product of \(_{t}\) and the ML learned latent variable \(_{t}_{|t}\) to estimate future perturbations. The update rule of the trust parameter \(_{t}\) follows an Online-Procedure, which can be constructed by the following explicit form of the overall dynamic regret (see ) with a fixed \(\):

\[J(())-J^{}=_{=0}^{T-1}_{,T}^{}()H _{,T}(),\] (9)where \(H B(R+B^{}PB)^{-1}B^{}\), and \(_{,T}()\) is defined as

\[_{,T}()_{=}^{\{+w-1,T-1 \}}(F^{})^{-}P(f(s_{};_{})- f(_{|t};_{}) ).\] (10)

Consider the application of online optimization strategies to minimize total regret as depicted in (9). At each time \(t\), we obtain \(_{,0}(),,_{,t}()\). For \(_{,t}()\), since the summation is over \(\{,\{+w-1,t-1\}\}\), \(_{,t}:^{n}\) is a function that depends on \(t[T]\). Thus, the formulation of the offline optimization (9) does not conform to a canonical framework suitable for online optimization. This necessitates a tailored approach for online learning, which is facilitated by Lemma 1, allowing for the online learning of \(\). Below we assume the following to regulate the learned sequence \((_{t}:t[T])\), which holds for typical online learning algorithms with stationary environments [23; 24; 25]. Note that when \(t-<0\), we consider \(_{t-}=_{0}\).

**Assumption 2**.: If \(>0\) is a constant, then \((_{t}:t[T])\) satisfies that \(_{t=0}^{T-1}|_{t}-_{t-}|=o(T)\).

Define \(\{-w+1,0\}\). The following lemma helps convert (9) to a form that can be reduced to an online optimization problem. The proof can be found in Appendix D.3.

**Lemma 1**.: _Define a function \(_{}:^{n}\) as \(_{}()_{=}^{}g^{}(,)Hg( ,)\), where_

\[g(,)(F^{})^{-}P(f (s_{};_{})-f(_{| };_{})).\] (11)

_Then for any \(t[T]\), it follows that \(_{=0}^{t-1}_{,t}^{}()H_{,t}() w _{=0}^{t-1}_{}\)._

Note that each \(_{}()\) defines a convex function of \(\), as verified in Appendix D.1. Therefore, the selection of \(_{t}\) at each time \(t[T]\) follows from an online learning procedure Online-Procedure, whose concrete realizations include the follow-the-regularized-leader (FTRL) approach with an \(_{2}\)-norm regularizer [23; 24], which is equivalent to online mirror descent (OMD) when \(f\) is convex; and the follow-the-perturbed-leader (FTPL) [26; 27; 28; 25] for online non-convex learning, taken previous quantities \((_{}:[t])\) as the input. Next, we will discuss theoretical guarantees for linear and general mixing models with specified online learning procedures, as detailed later in Section 4. Our policy is summarized in Algorithm 1.

## 4 Main Results

In this section, we present our technical results, proving that the scheme in Disc achieves near-optimal competitive ratio bounds for both linear and general mixing cases. Proving our main result above is nontrivial due to the fact that despite it is known that an input-disturbed linear system can be reduced to an online convex optimization (OCO) with structured memory , the connection between the problem with \(\)-Con and a memoryless online optimization is not previously discovered. In Lemma 1, we provide a result that decouples the dependency between cost functions in our problem that depends on previous actions via a linear dynamical system (see the dynamical system defined in (2)), thereby reducing the problem of choosing \(_{t}\) to an online optimization instance, then use a two-stage analysis (see Figure 7) that combines the dynamic regret analysis of \(\)-Con and static regret bounds corresponding to applying online optimization algorithms to learn a confidence parameter.

### A Fundamental Gap

First, we motivate the necessity of learning \((_{t}:t[T])\) online. Based on Definition 2.2, the following theorem reveals a negative result of \(\)-Con, since for any fixed non-zero \(\), there always exists predicted time series \((_{|t}:t,t[T])\) such that the competitive ratio \(()\) for \(\)-Con can be unbounded (when \(T\) goes to infinity).

**Theorem 4.1** (Consistency-Robustness Impossibility for \(()\)).: _If the \(\)-confident policy \(\)-Con is \((1+o(1))\)-consistent, then it is at least \((1)\)-robust, even if the mixing parameter estimate is perfect, i.e., \(=0\)._Here, \(o()\) and \(()\) characterize the asymptotic asymptotic growth rates with respect to the time horizon length \(T\). Next, we show in both the linear and general mixing settings, \(()\) can be bounded as previewed in Section 1, thus the gap between \(()\) and \(()\) can be arbitrarily large as implied by Theorem 4.1 above. Especially, Corollary B.1 in Section 4.2 implies that \(\) is both \((1+o(1))\)-consistent and \(O(1)\)-robust, with a sufficiently large prediction window size \(w=(1)\), revealing that online learning of the confidence parameter provides a significant improvement of the consistency and robustness tradeoff.

### Linear Mixing

We consider a linear mixing setting, where the mixing function \(f\) is linear such that \(f(s;)= s\) for all \(s^{k}\) where \(=(_{ij})\) denotes an \(n k\) full column rank mixing matrix. Suppose \((s_{t}:t[T])\) and \(\) are bounded such that \(\|s_{t}\|\) for all \(t[T]\) and \(\|\|\). For this particular instance, we implement a (follow-the-regularized-leader) FTRL procedure that sets

\[_{t}*{arg\,min}_{}(_{ =0}^{t-1}_{}^{}(_{}()) +\|-_{0}\|^{2})\] (12)

at each time \(t[T]\) for some \(>0\) that can be optimized. The Disc policy satisfies the following competitive ratio bound, whose proof can be found in Appendix E.

**Theorem 4.2** (Disc for Linear Mixing).: _With our model assumptions, the competitive ratio of Disc with a linear mixing function satisfies_

\[() 1+O(_{i=1}^{k}(i)}{(T/w)+(i)})+O(w})+O(_{F}^{2w}+}{T}),\]

_where \(k\) is the number of latent variables; \(T\) is the time horizon length; \(_{F}(0,1)\) is the spectral radius of \(F\); \(((i):i=1,,k)\) and \(\) are defined in (5); \(O()\) and \(()\) hide multiplicative constants (see the details in Appendix E)._

This result highlights a consistency and robustness tradeoff of Disc, as claimed in Section 1, which offers a dual advantage: it exploits accurate predictions when available, and safeguards against the ramifications of trusting inaccurate forecasts, thus ensuring system performance reliability. Besides, our analysis can be carried out to convex mixing functions, as the online learning of \(_{t}\) in (12) via FTRL guarantees a sub-linear static regret as long as \(_{}()\) is convex in \(\) for all \([T]\). We further provide a bound for sample efficient ICA in the appendix.

### General Mixing

In this section, we extend the linear assumption on \(f\) by considering a general setting where the mixing function \(f\) is an arbitrary Lipschitz continuous function (see Assumption 1). To deal with the non-convexity of \(f\), we revisit the (follow-the-perturbed-leader) FTPL approach (see [28; 25]) and consider the following online learning procedure for tuning \((_{t}:t[T])\):

\[_{t}*{arg\,min}_{}(_{ =0}^{t-1}_{}()+_{t}^{}) {(FTPL for $$-learning)}.\] (13)

Here, \(_{t}\) is a length-\(k\) random vector with each coordinate \(_{t}(i)\) (\(i=1,,k\)) being an IID random variable from an exponential distribution. The Disc policy satisfies the following competitive ratio bound.

**Theorem 4.3** (Disc for General Mixing).: _With our model assumptions, the expected competitive ratio of Disc satisfies_

\[[()] 1+O(_{i=1}^{k} (i)}{(T/w)+(i)}) +O(_{F}^{2w}+}{T})+O( }{}),\] (14)

_where the parameters \(_{F},w,k,T,\), and \(((i):i=1,,k)\) are the same as in Theorem 4.2 and \(\|s_{t}\|\) for all \(t[T]\). The expectation is taken over the randomly sampled \((_{t}:t[T])\)._The notation \(O()\) and \(()\) above in Theorem 4.3 hide multiplicative constants such as the Lipschitz constant of the mixing function \(f\) (details are provided in Appendix H). The result above implies the best-of-both-worlds prediction utilization as previewed in Section 1, except that the online learning of \(_{t}\) converges slower with a rate \(k^{2}\), causing the term \(O(k^{2}/)\) in the competitive ratio bound (14). Unlike the linear setting, to ensure a near-optimal expected competitive ratio, the latent time series \((s_{t}:t[T])\) is not necessarily bounded, as long as the prediction window size \(w\) is sufficiently large (e.g., \(w=( T)\)) so that the term \(_{F}^{2w}\) vanishes. Finally, note that the online learning procedure of \(_{t}\) is not limited to FTPL. For example, the non-convex online optimization algorithm in  can be used to optimize \((_{t}:t[T])\) online and leads to a similar guarantee. The proof of Theorem 4.3 can be found in Appendix H.

## 5 Experiments

Experimental Setup.To generate ML predictions, we use the FastICA method in  to decompose the mixed perturbations and train a multi-layer perceptron neural network with \(4\) hidden layers to predict the future latent variables. FastICA is a simple and efficient linear ICA method that aims to find an orthogonal rotation of the observation that maximizes the rotated components' non-Gaussianity using fixed-point iteration. Furthermore, in our experiments, we implement a follow-the-regularized-leader (FTRL) optimization with a \(_{2}\)-regularizer \(\|-_{0}\|^{2}\), which is equivalent to the following equivalent online mirror descent (OMD) implementation : \(_{t}=_{t-1}-_{}(_{t}^{}H _{t}),\;\;_{t}=_{}(_{t})\). The detailed parameters and hyper-parameters used in our experiments can be found in Appendix C.3. The code is available at https://github.com/tspbfs/DisentangleControl.

### Experiment A: Drone Navigation with Mixed Disturbances

We first consider the drone piloting task described in Example 1 (a detailed description is delegated to Appendix B) to track an unknown trajectory, shown on the left of Figure 2.

Competitive Ratio Analysis.We present a comparative analysis of the ratio of costs achieved by our Disc policy (detailed in Algorithm 1 in Section 3) on the right of Figure 2, against several benchmarks: the Linear Quadratic Regulator (LQR), Model Predictive Control (MPC) using untrusted ML predictions (i.e., setting \(=_{k}\) in Equation (7)), and the self-tuning policy outlined in  and .

We examine the impact of varying a scaling factor \(\) in the range \(0.25\) to \(8\), adjusting the additive perturbation \(r_{t}c_{2}\) in (16) to \((r_{t}/)c_{2}\). This scaling factor \(\) serves as a proxy for different rain intensities, influencing the level of environmental unpredictability--the larger \(\) is, the more predictable the

Figure 2: **Drone Navigation under challenging windy and rainy weather conditions, with the drone’s target path illustrated by a dotted curve. The external perturbations impacting the drone’s flight are modeled by two independent, time-varying latent variables: \(w_{t}\) for wind speed and \(r_{t}\) for rain intensity at time \(t[T]\). The trajectory produced by the Disc policy (Algorithm 1 in Section 3) is represented by the blue curve, while that from the offline optimal policy is traced in red. More comparison results with other baseline policies can be found in Appendix C.2. Right: **Ratio of Costs**\(J()/J^{}\) (\(y\)-axis) between Disc (red), linear quadratic regulator (LQR, orange), model predictive control with untrusted ML predictions (MPC (Untrusted), green), and the self-tuning policy (blue), with a varying scaling factor \(\) from \(0.25\) to \(8\). Shadow area depicts the range of standard deviations for \(5\) random tests.**

environment. With the theoretically guaranteed best-of-both-worlds utilization of disentangled and untrusted ML predictions, Disc consistently outperforms existing baselines in terms of cost ratios across varying levels of environmental predictability.

### Example B: Voltage Control with Heterogeneous Power Injections

We consider the voltage control task outlined in Example 2 for a distribution power grid with \(11\) nodes, as depicted in Figure 3. Specifically, nodes \(3\), \(5\), and \(8\) are active, each supplying dynamic active power injections \((p_{t}(i):i=3,5,8)\) at every time step \(t[T]\). Collectively, these nodes induce the composite perturbation \(Gp_{t}+v_{0}_{n}\). The objective is to apply the Disc algorithm to determine near-optimal controllable reactive power injections that will effectively mitigate voltage fluctuations across the grid. More details of the problem setting can be found in Appendix C.4.

We consider a realistic scenario when and use this to demonstrate the adaptivity of Disc in changing environments. Figure 3 shows the change of patterns corresponding to the solar integration and wind generation. We set \(T=200\). At time \(t=110\), the solar generation switches from a regular pattern to generating random Gaussian noise, representing miscommunication or system faults. Similarly, at time \(t=100\), the wind generation is recovered from the irregular mode to a regular mode. For the regular solar and wind generation time series, we use the real solar PV generation time series data from the DTU-Data in 2021  and wind generation from the U.S. Virgin Islands Wind Resources from the National Renewable Energy Lab (NREL) .

Adaptability Amidst Environmental Variability.Figure 3 exhibits the adaptability of our approach in response to environmental shifts in renewable energy generation and consumption patterns. Specifically, the figure presents the time series for solar generation \((s_{t}(1):t[T])\), wind generation \((s_{t}(2):t[T])\), and residential power consumption \((s_{t}(3):t[T])\). The transition points in the time series patterns are marked by dotted red lines in the figure.

A notable observation is the reactive behavior of the confidence parameters to the changes in predictability within each time series. For instance, as the solar generation transitions to an irregular Gaussian noise profile at \(t 110\), this unpredictability precipitates a decline in the corresponding confidence parameter \(_{t}(1)\). Conversely, the wind generation time series exhibits a move towards a more predictable pattern past \(t 100\), resulting in a progressive increase in the confidence parameter \(_{t}(2)\). In the case of residential consumption, which is consistently modeled as Gaussian

Figure 3: **Voltage Control** with in a dynamic environment. This figure illustrates the heterogeneity and variability of power injections at different nodes within an electrical grid, including a residential area, a solar photovoltaic (PV) system, and a wind turbine. Right: **Example B.**_Voltage Control (Section 5.2)_. **Left column**: _Convergence of confidence parameters \((1),(2),(3)\) corresponding to \(3\) latent components_. **Right column**: _Temporal dynamics of latent time series \(s_{t}\) in \(\)_. We illustrate the time series data for three key latent variables in the energy system (see Figure 3): Gaussian-distributed residential consumption (bottom), real-world photovoltaic (PV) integration (top), and wind generation (middle). The red dotted line marks a critical transition point where there is a notable shift in the power generation patterns. We use time series before the blue dotted line as the buffered data to warm start the ML model, learn the mixing matrix, and obtain disentangled predictions. The \(x\)-axis in each graph marks the time steps, while the \(y\)-axis denotes the values of the time series.

noise, the algorithm adaptively learns to reduce the confidence parameter \((3)\). The resilience of the Disc algorithm in dynamically adjusting confidence levels demonstrates its robustness against environmental shifts, a critical feature for real-world applications where conditions are subject to sudden and unpredictable changes. This further highlights the efficacy of Disc in maintaining system stability and performance through intelligent adaptability to the reliability of input data, as verified by the theoretical results in Section 4.

## 6 Concluding Remarks

Our work combines online control and the concept of learning disentangled predictions. In this paper, we have introduced a novel policy Disc that achieves the best-of-both-world utilization of untrusted ML predictions of latent variables for a linear control problem, where the advantage of disentanglement is theoretically validated. The practicality of our method has been validated through two real-world applications, which exemplify its relevance and adaptability to complex, real-world scenarios.

**Limitations and Future Directions.** Despite that our main results, i.e., the competitive ratio bounds in Theorem 4.2 and 4.3 do not rely on the assumption that the latent variables \((s_{t}(1),,s_{t}(k))\) are independent, most of the disentanglement methods do (like sample efficient ICA algorithms used to derive Corollary B.1 and the detailed assumptions are summarized in Table 1). It would be interesting to explore more carefully designed algorithms to guarantee both sample efficiency and identifiability based on our control model. Looking ahead, our results open several intriguing paths. An immediate extension of particular interest is adapting our methodology to nonlinear dynamical systems, which could strengthen our current results. Furthermore, our work contributes to the growing community of algorithms with predictions, a compelling question arises: can the best-of-both-worlds competitive ratio bounds we have achieved be replicated across different online decision-making problems? Obtaining either positive or negative results would potentially lead to broad implications for the field of robust control and online learning.