# A Diffusion-Model of Joint Interactive Navigation

Matthew Niedoba\({}^{1,2}\) &J. Wilder Lavington\({}^{1,2}\) &Yunpeng Liu\({}^{1,2}\) &Vasileios Lioutas\({}^{1,2}\) &Justice Sefas\({}^{1,2}\) &Xiaoxuan Liang\({}^{1,2}\) &Dylan Green\({}^{1,2}\) &Setareh Dabiri\({}^{2}\) &Berend Zwartsenberg\({}^{2}\) &Adam Scibior\({}^{1,2}\) &Frank Wood\({}^{1,2}\)

\({}^{1}\) University of British Columbia, \({}^{2}\) Inverted AI

miedoba@cs.ubc.ca

###### Abstract

Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN - a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing.

## 1 Introduction

Accurate simulations are critical to the development of autonomous vehicles (AVs) because they facilitate the safe testing of complex driving systems . One of the most popular methods of simulation is virtual replay , in which the performance of autonomous systems are evaluated by replaying previously recorded traffic scenarios. Although virtual replay is a valuable tool for AV testing, recording diverse scenarios is expensive and time consuming, as safety-critical traffic behaviors are rare . Methods for producing synthetic traffic scenarios of specific driving behaviors are therefore essential to accelerate AV development and simulation quality.

Producing these synthetic traffic scenarios involves generating the joint future motion of all the agents in a scene, a task which is closely related to the problem of trajectory forecasting. Due to the complexity of learning a fully autonomous end-to-end vehicle controller, researchers often opt to split the problem into three main tasks : perception, trajectory forecasting, and planning. In trajectory forecasting, the future positions of all agents are predicted up to a specified future time based on the agent histories and the road information. Due to the utility of trajectory forecasting models in autonomous vehicle systems along with the availability of standard datasets and benchmarks to measure progress , a variety of effective trajectory forecasting methods are now available. Unfortunately, most methods produce _deterministic_ sets of trajectory forecasts _per-agent_ which are difficult to combine to produce realistic joint traffic scenes .

Generative models of driving behavior have been proposed as an alternative to deterministic trajectory forecasting methods for traffic scene generation . These models re-frame trajectory forecasting as modeling the joint distribution of future agent state conditioned on past observations and map context. However, given that the distribution of traffic scenes in motion forecasting datasets are similar to real-world driving, modelling the data distribution does not ensure that models will generate rare, safety critical events.

To alleviate these issues we propose DJINN, a model which generatively produces joint traffic scenarios with _flexible conditioning_. DJINN is a diffusion model over the joint states of all agents in the scene. Similar to , our model is conditioned on a flexible set of agent states. By modifying the conditioning set at test-time, DJINN is able to draw traffic scenarios from a variety of conditional distributions of interest. These distributions include sampling scenes conditioned on specific goal states or upsampling trajectories from sparse waypoints. Additionally, the joint diffusion structure of DJINN enables test-time diffusion guidance. Utilizing these methods enables further control over the conditioning of traffic scenes based on behavior modes, agent states, or scene editing.

We evaluate the quality of sampled trajectories with both joint and ego-only motion forecasting on the Argoverse  and INTERACTION  datasets. We report excellent ego-only motion forecasting and outperform Scene Transformer on joint motion forecasting metrics. We further demonstrate both DJINN's flexibility and compatibility with various forms of test-time diffusion guidance by generating goal-directed samples, examples of cut-in driving behaviors, and editing replay logs.

## 2 Related Work

**Trajectory Forecasting:** A wide variety of methods have been proposed to address the problem of trajectory forecasting. Two attributes which divide this area of work are the output representation type and the agents for which predictions are made. The most common class of models deterministically predict the distribution of ego agent trajectories using a weighted trajectory set either with or without uncertainties. Due to the applicability of this representation as the input for real-time self-driving planners, there are numerous prior methods of this type. Some approaches rasterize the scene into a birdview image and use CNNs to predict a discrete set of future trajectories for the ego agent [5; 3; 32]. The convolutional architecture of these methods captures local information around the agent well, but the birdview image size and resolution limit the ability to capture high speed and long-range interactions. To address these challenges, other prior approaches encode agent states directly either by using RNNs [47; 39; 27], polyline encoders [7; 9] or 1D convolutions . Agent features can be combined with roadgraph information in a variety of ways including graph convolutional networks [24; 1] or attention [29; 27].

To control the distribution of predicted trajectories, several methods have utilized mode or goal conditioning. One approach is to directly predict several goal targets before regressing trajectories to those targets [54; 9; 51; 8]. An alternate approach is to condition on trajectory prototypes  or latent embeddings .

Predicting joint traffic scenes using per-agent marginal trajectory sets is challenging due to the exponential growth of trajectory combinations. Recent approaches aim to rectify this by producing joint weighted sets of trajectories for all agents in a scene. M2I  generates joint trajectory sets by producing "reactor" trajectories which are conditioned on marginal "influencer" trajectories. Scene Transformer , which uses a similar backbone architecture to our method, uses a transformer  network to jointly produce trajectory sets for all agents in the scene.

As an alternative to deterministic predictions, multiple methods propose generative models of agent trajectories. A variety of generative model classes have been employed including Normalizing Flows , GANs [10; 38] or CVRNNs [40; 46]. Joint generative behavior models can either produce entire scenarios in one shot [10; 38; 36], or produce scenarios by autoregressively "rolling-out" agent trajectories [40; 46].

**Diffusion Models:** Diffusion models, proposed by Sohl-Dickstein et al.  and improved by Ho et al.  are a class of generative models which approximate the data distribution by reversing a forward process which gradually adds noise to the data. The schedule of noise addition can be discrete process or represented by a continuous time differential equation [44; 21].We utilize the diffusion parameterization introduced in EDM  in our work for its excellent performance and separation of training and sampling procedures.

This class of models have shown excellent sample quality in a variety of domains including images [12; 6], video [11; 14] and audio . In addition, diffusion models can be adapted at test-time through various conditioning mechanisms. Classifier  and classifier-free guidance  have enabled powerful conditional generative models such as text conditional image models [34; 37] while editing techniques [26; 31] have enabled iterative refinement of generated samples.

One recent application of diffusion models is planning. Diffuser  uses diffusion models to generate trajectories for offline reinforcement learning tasks. They condition their samples using classifier guidance to achieve high rewards and satisfy constraints. Trace and Pace  utilizes diffusion planning for guided pedestrian motion planning. In the vehicle planning domain, Controllable Traffic Generation (CTG)  builds on Diffuser, using diffusion models to generate trajectories which satisfy road rule constraints. Like CTG, our method also models the future trajectories of road users using diffusion models. However, our approach differs from CTG in terms of output and our methods of conditioning. In CTG, marginal per-agent trajectory samples are combined into a joint scene representation by "rolling-out" a portion of each agent's trajectory before drawing new samples per-agent. By contrast, DJINN models the full joint distribution of agent trajectories in one shot, with no re-planning or roll-outs required. The authors of CTG condition their model exclusively on the past states of other agents and the map, and use classifier-guidance to condition their samples to follow road rules. In our method, we demonstrate conditioning on scene semantics via classifier guidance _as well as_ conditioning on arbitrary state observations, including the past or future states of each agent, and control the strength of conditioning using classifier-free guidance as demonstrated in Fig. 1.

## 3 Background

### Problem Formulation

Our work considers traffic scenarios consisting of \(A\) agents across \(T\) discrete timesteps driving on a roadway described by a set of roadgraph features \(\). Each agent \(a\{1,,A\}\) in the scene at time \(t\{1, T\}\) is represented by a state \(_{t}^{a}=\{x_{t}^{a},y_{t}^{a},_{t}^{a}\}\) consisting of its 2D position \((x_{t},y_{t})\) and heading \(_{t}\). The joint representation of the scene \(\) is the combination of all agents across all timesteps \(=\{s_{t}^{a}|a\{1,,A\}\,,t\{1,,T\}\}^ {A T 3}\). We assume scenes are distributed according to an unknown distribution \(p_{data}()\).

We introduce a model which is conditioned on the map features \(\) and can moreover be flexibly conditioned on arbitrary set of observed agent states. For the latter purpose, we consider a boolean variable \(\{0,1\}^{A T}\). We denote that a state in the scene is observed if \(_{t}^{a}=1\). Using \(\), we partition the scene into two components. The observed portion of the scene is defined as \(_{obs}=\{_{t}^{a}|_{t}^{a},_{t}^{a}=1\}\) while the unobserved, latent portion is \(_{lat}=_{obs}\). Figure 1 shows five choices for \(\) and their corresponding tasks. Our ultimate goal is to learn a conditional distribution over the set of all latent agent states \(_{lat}\) given the observed states \(_{obs}\) and the map \(\), by modelling \(p(_{lat}|_{obs},)\). Using this probabilistic framework, we can represent conditional

Figure 1: **Top:** Five example observation masks \(\) demonstrating potential conditioning inputs to DJINN. Each element of each mask corresponds to the boolean value of \(\) for that agent state. Individual agents are shown in rows, with timesteps as columns. **Bottom:** Generated traffic scenes corresponding to the type of observation masks above.

distributions corresponding to various trajectory forecasting tasks by modifying the observation mask \(\) and the corresponding conditioning set \(_{obs}\).

### Diffusion Models

Diffusion models [41; 12] are a powerful class of generative models built upon a diffusion process which iteratively adds noise to the data. In the continuous time formulation of this process [44; 21], this iterative addition is described by a stochastic differential equation (SDE)

\[d_{}=(_{},)d-()d.\] (1)

Here, \([0,_{max}]\) where \(_{max}\) is a fixed, large constant, \((_{},)\) is the drift function and \(()\) is the diffusion coefficient which scales standard Brownian motion \(\). Note that our work has two notions of time. Throughout we will use \(t\) to denote the "scenario time" and \(\) to represent "diffusion time". We express the marginal distribution of \(_{}\) at diffusion time \(\) as \(p(_{})\), with \(p(_{0})\) corresponding to the data distribution \(p_{data}()\). Typically, \((_{},)\), \(()\), and \(_{max}\) are chosen such the conditional density \(p(_{}|_{0})\) is available in closed form and that \(p(_{_{max}})\) approximates a tractable Gaussian distribution \(()\). Notably, for every diffusion SDE, there exists a corresponding probability flow (PF) ordinary differential equation (ODE)  whose marginal probability densities \(p(_{})\) match the densities of Eq. (1)

\[d_{}=[(_{},)-()^ {2}_{x} p(_{})]d.\] (2)

Using the PF ODE, samples are generated from a diffusion model by integrating Eq. (2) from \(=_{max}\) to \(=0\) with initial condition \(_{_{max}}(_{_{max}})\) using an ODE solver. Typically integration is stopped at some small value \(\) for numerical stability. Solving this initial value problem requires evaluation of the _score function_\(_{_{}} p(_{})\). Since \(p(_{})\) is not known in closed form, diffusion models learn an approximation of the score function \(_{}(_{},)_{_{}}  p(_{})\) via score matching [16; 43; 44].

A useful property of diffusion models is the ability to model conditional distributions \(p(_{0}|y)\) at test-time using guidance. Given some conditional information \(y\), the key idea of guidance is to replace the score function in the PF ODE with an approximate _conditional_ score function \(_{_{}} p(_{}|y)\).

By using the gradient of a pretrained classifier \(p_{}(y|_{})\), glassifier guidance  approximates the conditional score function through the a linear combination of the unconditional score function and the classifier gradient. The parameter \(\) controls the strength of the guidance

\[_{_{}} p(_{}|y)_{ }(_{},)+_{_{}} p_{} (y|_{}).\] (3)

One major drawback of classifier guidance is the need to train an external classifier. Instead, classifier-free guidance , utilizes a conditional score network \(_{}(_{},,y)\). Then, a weighted average of the conditional and unconditional scores is used to estimate the conditional score function.

\[_{_{}} p(_{}|y) _{}(_{},,y)+(1-)_{}( _{},).\] (4)

Here \(\) is a scalar parameter which controls the strength of the guidance. In both cases, the approximate conditional score can be substituted into Eq. (2) to draw conditional samples from \(p(_{0}|y)\).

## 4 Djinn

Our approach models the joint distribution agent states \(p(_{lat}|_{obs},)\) conditioned on a set of observed states and the map context. For this purpose, we employ a diffusion model which diffuses directly over \(_{lat}\) - the unobserved states of each agent in the scene for \(t=\{1, T\}\). An important aspect of our method is the choice of observation mask \(\) and observation set \(_{obs}\) on which we condition. For this purpose we introduce a distribution over observation masks \(p()\) which controls the tasks on which we train our model.

In the design of our diffusion process, we follow the choices from EDM , setting \((_{lat,},)=\) and \(()=\) from Eq. (2). We also utilize their score function parameterization\[_{_{lat,}} p(_{lat,}|_{obs},,)=(_{lat,},_{obs}, ,,)-_{lat,}}{^{2}}.\] (5)

Here \(D_{}\) is a neural network which approximates the latent portion of the noise free data \(_{lat,0}\). In addition to \(_{lat,}\) and \(\), in our work \(D_{}\) also receives the map context \(\), the clean observed states \(_{obs}\) and \(c\), a collection of unmodelled agent features per observed agent timestep such as velocity, vehicle size, or agent type. We train our network on a modification of the objective from EDM 

\[_{_{0},,,_{lat,}}\|D_{ }(_{lat,},_{obs},,, )-_{lat,0}\|_{2}^{2}.\] (6)

Here, \(_{0} p_{data}()\), \(_{} p(_{}|_{0})=( ,^{2})\) and \( p()\). We compute our loss over \( p_{train}\) - a log normal distribution which controls the variance of the noise added to the data. We set the mean and variance of \(p_{train}\) according to .

We use the Heun \(2^{}\) order sampler from  to sample traffic scenarios with no changes to the reported hyperparameters. Empirically, we found that deterministic sampling, corresponding to integrating the PF ODE, leads to higher quality samples than using an SDE solver. Unless otherwise noted all samples are produced using \(50\) iterations of the ODE solver, which produces the highest quality samples as measured by ego and joint minADE and minFDE.

**Input Representation** An important choice for trajectory forecasting models is the reference frame for the agent states. In our work, the diffused agent states and observations \(_{obs}\) are centered around an "ego agent," which is often specified in trajectory forecasting datasets as the primary agent of interest. We transform \(_{0}\) such that the scene is centered on the last observed position of this arbitrary "ego agent" and rotated so the last observed heading of the ego agent is zero. We scale the positions and headings of all agents in each ego-transformed scene to a standard deviation of \(0.5\).

We represent the map \(\) as an unordered collection of polylines representing the center of each lane. Polylines are comprised of a fixed number of 2D points. We split longer polylines split into multiple segments and pad shorter polylines padded to the fixed length. Each point has a boolean variable indicating whether the element is padding. Polyline points are represented in the same reference frame as the agent states and are scaled by the same amount as the agent position features.

**Model Architecture** Our score estimator network \(D_{}\) is parameterized by a transformer-based architecture similar to . The network operates on a fixed \([A,T,F]\) shaped feature tensor composed of one \(F\) dimensional feature vector per agent timestep. We use sinusoidal positional embeddings  to produce initial feature tensors. Noisy and observed agent states \(_{}\), \(_{obs}\), the time indices \(t=\{1,,T\}\), and diffusion step \(\) are all embedded into \(F\) dimensional embeddings. \(_{lat,}\) and \(_{obs}\) are padded with zeros for observed and latent states respectively prior to embedding. A shared MLP projects the concatenated positional embeddings into a \(F\) dimensional vector for each agent.

The main trunk of the network is comprised of a series of transformer layers . Attention between all pairs of feature vectors is factorized into alternating time and agent transformer layers. In time transformer layers, self-attention is performed per-agent across each timestep of that agent's trajectory, allowing for temporal consistency along a trajectory. In agent transformer layers, self-attention is computed across all agents at a given time, updating each agent's features with information about the other agents at that time. We encode the map information \(\) with a shared MLP that consumes flattened per-point and per-lane features to produce a fixed size embedding per lane. Cross attention between the collection of lane embeddings and agent states incorporates map information into the agent state features. Our network is comprised of 15 total transformer layers with a fixed feature dimension of 256. We use an MLP decoder after the final transformer layer to produce our estimate of \(_{lat,0}\). A full representation of our architecture is available in Appendix A.

## 5 Guidance for Conditional Scene Generation

So far, we have outlined our method for generating joint traffic scenes using DJINN. Next, we describe how the diffusion nature of DJINN enables fine-grained control over the generation and modification of driving scenarios.

### Classifier-free Guidance

In Scene Transformer , a masked sequence modelling framework is introduced for goal-directed and agent-reactive scene predictions. One limitation of this approach is that conditioning is performed on precise agent states while future agent states or goals are usually uncertain. We mitigate this limitation through the use of classifier-free guidance.

We assume access to a set of precise observations \(_{obs}\), and some set of additional agent states \(_{cond}\) on which we wish to condition our sample. For instance, \(_{cond}\) may include agent goals upon which we wish to condition. Let \(^{}_{obs}=\{_{obs}_{cond}\}\). Based on Eq. (4), the conditional score is through a weighted average of the score estimate conditioned on \(_{obs}\) and the estimated conditioned on \(^{}_{obs}\)

\[_{_{lat,}} p(_{lat,}| ^{}_{obs}) (_{lat,},^{ }_{obs},,,)-_{lat,}}{^{2}}\] (7) \[+(1-)(_{lat,}, _{obs},,,)-_{lat,}}{^{2}}.\]

To facilitate classifier-free conditioning, we train DJINN on a \(p()\) representing varied conditioning tasks. These tasks include conditioning on agent history, agent goals, windows of agent states, and random agent states. A full overview of our task distribution is given in Appendix B.

### Classifier Guidance

Many driving behaviors of individual or multiple agents can be categorized by a class \(y\) based on their geometry, inter-agent interactions or map context. Examples of classes include driving maneuvers such as left turns, multi agent behaviors such as yielding to another agent, or constraints such as trajectories which follow the speed limit. DJINN uses classifier guidance to conditioned scenes on these behavior classes. Given a set of example scenes corresponding to a behavior class \(y\), we train a classifier to model \(p_{}(y|)\). Using Eq. (3) we approximate the conditional score for conditional sampling. Importantly, due to the joint nature of our representation, classifiers for per-agent, multi-agent or whole-scene behaviors can be all used to condition sampled traffic scenes.

### Scenario Editing

One benefit of sampling traffic scenes at once instead of autoregressively is the ability to edit generated or recorded traffic scenarios through stochastic differential editing . Given a traffic scene \(\), a user can manually modify the trajectories in the scene to produce a "guide" scene \(^{}\) which approximates

Table 1: Ego-only motion forecasting performance on Argoverse and INTERACTION datasets. minADE and minFDE metrics on both datasets indicate that DJINN produces ego samples which closesly match the distribution of ego agent trajectories.

Table 2: Ego-only and joint metrics comparing DJINN to a jointly trained Scene Transformer model on the Argoverse validation set. DJINN produces better joint samples than SceneTransformer when measured by minSceneADE and minSceneFDE.

the desired trajectories in the scene. The guide scene is used to condition the start of a truncated reverse diffusion process by sampling \(_{_{edit}}(^{},_{edit})\) where \(_{edit}\) is an intermediate time in the diffusion process between \(0\) and \(_{max}\). Then, the edited scene is produced by integrating the PF ODE using the same ODE solver, starting from initial condition \(_{edit}\). Through the stochastic differential editing, the guide scene is translated into a realistic traffic scene with agent trajectories which approximate the guide trajectories. We empirically find \(_{edit}=0.8\) to be a good trade-off between generating realistic trajectory scenes and maintaining the information of the guide scene.

## 6 Experiments

### Motion Forecasting Performance

To measure the quality of the samples from DJINN, we evaluate our method on two popular motion prediction datasets, matching \(\) during training to match each dataset. For the INTERACTION dataset  scenes, we observe the state of all agents over the first second of the scene and generate the next three seconds. On the Argoverse dataset  our model observes agent states over the first two seconds of the scene and generates the next three seconds. Training hyperparameters for both models are found in Appendix A.

We note that both INTERACTION and Argoverse metrics measure an ego-only trajectory-set using minADE and minFDE over 6 trajectories. Since DJINN produces stochastic samples of entire traffic scenes, a set of 6 random trajectories may not cover all future trajectory modes. To alleviate this, we draw a collection of 60 samples for each scenario and fit a 6 component Gaussian mixture model with diagonal covariances using EM in a method similar to . We use the means of the mixture components as the final DJINN prediction for motion forecasting benchmarks.

We present DJINN's performance on motion forecasting in Table 1 with Argoverse results in Table 1a and INTERACTION results in Table 1b. On INTERACTION, DJINN generates excellent ego vehicle trajectories, with similar minFDE and minADE to state of the art methods on this dataset. On the Argoverse test set we produce competitive metrics, although our results lag slightly behind top motion forecasting methods. We hypothesize that our lower performance on Argoverse is due to the lower quality agent tracks in this dataset when compared to INTERACTION.

We further analyze the _joint_ motion forecasting performance of DJINN. To this end, we measure the Scene minADE and minFDE proposed by  which measures joint motion forecasting performance over a collection of traffic scenes. We compare DJINN against a reproduction of Scene Transformer trained for joint motion forecasting, using their reported hyperparameters. Ego-only and Scene motion forecasting performance is shown in Table 2. Although Scene Transformer predicts slightly better ego vehicle trajectories, we demonstrate DJINN has superior joint motion forecasting capabilities.

### State-conditioned Traffic Scene Generation

While DJINN is able to draw samples for motion forecasting benchmarks by conditioning on past observations of the scene, a key benefit of our approach is the ability to flexibly condition at test-time

Figure 2: The effect of classifier-free guidance weight on the spread of trajectories for goal conditioned sampling. Samples drawn from the INTERACTION validation set conditioned using classifier-free guidance on a goal state (star). As the guidance weight increases, deviation from the goals decreases.

based on arbitrary agent states. We illustrate this test-time conditioning in Fig. 1 by generating samples from five conditional distributions which correspond to use-cases for our model.

Specifying exact agent states on which to condition can be challenging. One approach is to utilize the states of a prerecorded trajectory to produce conditioning inputs. However, if one wishes to generate a trajectory which deviates from a recorded trajectory, there is uncertainty about the exact states on which to condition. In Fig. 2, we demonstrate how classifier-free guidance can be utilized to handle user uncertainty in conditioning agent states. In this example, we set the observation set \(_{obs}\) to the first ten states of each agent's recorded trajectory. Further, we create a conditional observation set \(^{}_{obs}\) by augmenting \(_{obs}\) with a goal state for each agent drawn from a normal distribution centered on the ground-truth final position of each agent, with 1m variance. We sample traffic scenes with varying levels of classifier-free guidance strength, drawing two conclusions. First, DJINN is robust to goals which do not match the recorded final agent states. Secondly, the strength of the classifier guidance weight controls the emphasis of the goal conditioning, resulting in trajectory samples which cluster more tightly around the specified goal as the guidance strength is increased. With low guidance weight, the samples are diverse, and do not closely match the specified goal position. As the weight increases, the spread of the trajectory distribution tightens, especially for fast, longer trajectories. These properties give users finer control over the distribution of traffic scenes when there is uncertainty over the conditioning states.

### Conditional Generation from Behavior Classes

We now continue to demonstrate the flexibility of our approach by considering test-time conditioning of our model on specific driving behaviors through classifier guidance. Specifically, we highlight the ability to condition DJINN on the behavior class of cut-in trajectories by conditioning our INTERACTION trained model with a cut-in classifier.

A "cut-in" occurs when one vehicle merges into the path of another, often requiring intervention by the cut-off driver. We selected this behavior to demonstrate how classifier guidance can be used with our joint representation to sample scenes conditioned on the behavior of multiple agents. We condition DJINN trained on INTERACTION using a simple cut-in classifier. To train the classifier, we first mined a dataset of cut-in behaviors trajectory pairs from the "DR_CHN_Merging_ZS" location - a highway driving scene with some cut-in examples. Each trajectory pair is comprised of an "ego" and an "other" agent. We define a positive cut-in as a case where the future state of the other agent at time \(t_{other}\) overlaps with a future state of the ego agent at time \(t_{ego}\) such that \(t_{ego}-3s<t_{other}<t_{ego}\). Further, we filter cases where the initial state of the other agent overlaps with any part of the ego

Figure 3: Examples of synthetic cut-in behaviors generated using classifier guidance. Samples are generated from the INTERACTION validation set conditioned on the first 10 agent states. Applying classifier guidance causes the other agent (green) to cut in front of the ego agent (purple). We generate trajectories for all agents in the scene, but other agent trajectories have been omitted for clarity

trajectory to eliminate lane following cases. We label a negative cut-in case as any other pair of trajectories in which the minimum distance between any pair of ego and other states is less than 5m.

Using these heuristics, we collect a dataset of 2013 positive and 296751 negative examples. We trained a two layer MLP classifier with 128 dimensions per hidden layer. The classifier takes as input the diffused trajectories of each agent, the validity of each timestep and the diffusion time \(\). Using this classifier, we generate synthetic cut-in scenarios via Eq. (3). Examples of our synthetic cut-in scenarios are found in Fig. 3. The generated scenarios clearly demonstrate our model can be conditioned to create synthetic cut-in behaviors. These synthetic examples provide evidence that given a collection of trajectories exemplifying a behavior mode, or a heuristic which can be used to generate example trajectories, DJINN can be conditioned to generate synthetic examples representing that behavior mode. This finding further expands the flexibility of our model to generate trajectory samples from valuable conditional distributions.

### Scenario Fine-Tuning

We exhibit another method of controlling the traffic scenarios generated with DJINN through fine-tuning. Since DJINN diffuses entire traffic scenes without iterative replanning, we are able to use stochastic differential editing to modify the sampled scenes. Given a recorded or sampled traffic scene, differential stochastic editing can be used to fine-tune the scene through the use of a manually specified guide. In Fig. 4, we demonstrate how DJINN can fine-tune existing scenarios to produce new scenarios with realistic trajectories but complex interactions. Using two recorded validation set scenes from Argoverse, we aim to edit the scenes to generate more interactive trajectories between the agents. For this purpose, we generate an guide scene \(_{guide}\) by manually adjusting the trajectories in each scene so that the future paths of two of the agents will intersect. Through stochastic differential editing, we show that DJINN is able to produce realistic driving scenes which shift the guide scene trajectories to maintain their interactivity but avoid collisions between agents.

Figure 4: Two scenario fine-tuning examples (one per row) based on Argoverse validation set scenarios. **Left**: original scene with ground-truth trajectories shown for two interacting vehicles, vehicle positions at the same time index for all agents. **Middle**: a manual edit of one agent’s trajectory in each scene. One (top) replaces a right turn with a forward continuation, the other (bottom) shifts a trajectory back in space to cause a complex interaction to occur near the end of the trajectory. **Right**: the resulting stochastic differential edit of the original scenario. Both rows of the last column illustrate joint reactivity to the new trajectories arising from the edit; in the top row the left-turning vehicle yields and in the bottom row both trajectories shift to avoid collision.

Conclusions

In this work, we present DJINN - a diffusion model of joint traffic scenes. By diffusing in a joint agent state representation, DJINN can be adapted at test time to a variety of modeling tasks through guidance methods and scenario editing. The power of this scenario generation model opens exciting possibilities. Future research may expand the variety of guidance classifiers such as utilizing the classifiers proposed in  for traffic-rule constraint satisfaction. Another promising avenue of research is scaling DJINN for faster scenario generation. Although flexible, the diffusion structure of DJINN makes scenario generation relatively slow due to the iterative estimation of the score function. Distillation techniques such as consistency models  may be helpful in this regard to improve the number of score estimates required per sample. Future work may also consider scaling the length and agent count in generated scenarios to improve the complexity of behaviors which can be generated. Other areas of future work include using DJINN in a model predictive control setting (hinted at in the predictive mask of Fig. 1) in which an ego action is scored using statistics of ego-action conditioned joint trajectories from DJINN.