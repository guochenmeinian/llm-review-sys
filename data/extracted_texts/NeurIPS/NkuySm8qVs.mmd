# No Free Lunch Theorem and Black-Box Complexity Analysis for Adversarial Optimisation

Per Kristian Lehre

School of Computer Science

University of Birmingham

Birmingham, United Kingdom

p.k.lehre@bham.ac.uk

&Shishen Lin

School of Computer Science

University of Birmingham

Birmingham, United Kingdom

sxl1242@student.bham.ac.uk

Authors are listed in alphabetical order.

###### Abstract

Black-box optimisation is one of the important areas in optimisation. The original No Free Lunch (NFL) theorems highlight the limitations of traditional black-box optimisation and learning algorithms, serving as a theoretical foundation for traditional optimisation. No Free Lunch Analysis in adversarial (also called maximin) optimisation is a long-standing problem . This paper first rigorously proves a (NFL) Theorem for general black-box adversarial optimisation when considering Pure Strategy Nash Equilibrium (NE) as the solution concept. We emphasise the solution concept (i.e. define the optimality in adversarial optimisation) as the key in our NFL theorem. In particular, if Nash Equilibrium is considered as the solution concept and the cost of the algorithm is measured in terms of the number of columns and rows queried in the payoff matrix, then the average performance of all black-box adversarial optimisation algorithms is the same. Moreover, we first introduce black-box complexity to analyse the black-box adversarial optimisation algorithm. We employ Yao's Principle and our new NFL Theorem to provide general lower bounds for the query complexity of finding a Nash Equilibrium in adversarial optimisation. Finally, we illustrate the practical ramifications of our results on simple two-player zero-sum games. More specifically, no black-box optimisation algorithm for finding the unique Nash equilibrium in two-player zero-sum games can exceed logarithmic complexity relative to search space size. Meanwhile, no black-box algorithm can solve any bimatrix game with unique NE with fewer than a linear number of queries in the size of the payoff matrix.

## 1 Introduction

### Black-Box Optimisation and the No Free Lunch Theorem

Black-Box Optimisation (BBO) is crucial for optimising complex, unknown, or expensive-to-evaluate functions in real-world scenarios, such as aerodynamic design and hyperparameter tuning, where only input-output observations are available. Formally, BBO is the task of optimising objective functions from some function class \(\) where \(\) consists of \(f:\), where the algorithm is limited to making queries to \(f\). In this case, the algorithm is only able to sample and query the function value \(f(x)\) of search points \(x\) from a "black-box" or "oracle" without access to any description of the objective functions \(f\). A similar framework can be extended to game-theoretic BBO, namely adversarial BBO. Specifically, adversarial BBO is the task that optimising payoff functions from some payoff function class \(\) where \(\) consists of black-box functions \(g:\), with a limited budget of function evaluations. Additionally, two players \(x\) and \(y\) forma maximin optimisation (as presented in Figure 1). The original No Free Lunch Theorems for traditional optimisation can be summarised as follows:

"For all possible metrics, no search algorithm or supervised learning algorithm is better than another when its performance is averaged over all possible problem instances [45; 44]."

Wolpert and Macready  and Wolpert  have revealed the underlying facts about the usefulness of traditional black-box optimisation algorithms, including various randomised search heuristics (such as evolutionary algorithms and simulated annealing) and machine learning algorithms (such as supervised learning). In particular, it shows that the performance of all black-box optimisation algorithms  and learning algorithms , when averaged over all problem instances, is the same for any maximisation or minimisation tasks. Droste et al.  has provided a generalised NFL theorem with more realistic scenarios by relaxing NFL theorem holds from all problem instances to problem instances closed under permutation. Another seminal work by Schaffer  also showed a conservation law for the generalised performance of learning algorithms in classification problems.

Adversarial optimisation tasks, such as maximin optimisation, are more complex and often counter-intuitive compared to traditional optimisation problems. In adversarial settings, defining solution concepts, or establishing what is meant by optimality, is essential. Common solution concepts include 'Maximisation Over All Test Cases','maximin', and Nash Equilibrium. A 'free lunch' in adversarial optimisation implies that, for a given solution concept, some algorithms consistently outperform others when averaged across all possible problem instances. This phenomenon was demonstrated by Wolpert and Macready  for adversarial optimisation with respect to the'maximin' solution concept (Definition 10). Similarly, Service and Tauritz  established a 'free lunch' result for the 'Maximisation Over All Test Cases' concept (Definition 9).

Beyond'maximin' and 'Maximisation Over All Test Cases', Nash Equilibrium is another widely studied solution concept in adversarial learning and maximin optimisation. This concept is central to various applications, including adversarial learning models such as GANs [15; 20] and spatial games [19; 26; 32]. While previous studies by Wolpert and Macready  and Service and Tauritz  have demonstrated the existence of 'free lunches' in adversarial optimisation, the following key questions remain open:

1. Does adversarial optimisation exhibit a 'free lunch' for all possible solution concepts?
2. If we use Nash Equilibrium as the solution concept, how can we characterise the difficulty of black-box adversarial optimisation problems for problem-independent, possibly randomised, search heuristics?

In this paper, we answer Question (1) in the negative by showing a No Free Lunch theorem for Nash Equilibrium solution concept and address Question (2) by introducing black-box complexity tools.

### Challenges and Technical Overview of the NFL and BBC Results

There are several challenges in showing the NFL and BBC results. First, we highlight the challenges and our technical details in the derivation process compared to previous NFL work. The classical No Free Lunch theorem applies proof by induction with respect to the size of the function domain. A natural idea is to extend the previous proof-by-induction method in our NFL proof. However, one of the most challenging aspects of deriving NFL for Nash Equilibrium (NE) is that the adversarial

Figure 1: Comparison between traditional black-box optimisation and maximin black-box optimisation. Instead of querying at \(x\) in traditional optimisation, maximin optimisation queries at \((x,y)\) include both strategy \(x\) and the best response \(y\) from the opponent, i.e. \(_{x}_{y}g(x,y)\). Their interaction is converted to the payoff \(g(x,y)\) in the given black-box model.

setting significantly increases the difficulty since the problem depends on the performances of both the player and the opponents. To address this, we introduce two technical lemmas from game theory (i.e. Lemma 3 and Lemma 4) and help to construct the isomorphism between two different problem classes (i.e. Corollary 1 and Lemma 2), which is an essential step in the proof of the original NFL theorem for traditional optimisation (see Section B for more details). Another significant challenge is that we start with a very weak assumption: we only allow access to the payoff function and make no assumptions about its properties, such as convexity, continuity, or differentiability. In fact, no gradients, continuity, or differentiability make the NFL and black box results easier to prove (i.e., the function class lacks a specific structure). On the other hand, it makes it more difficult for the algorithm. Consequently, we have limited analytical tools to proceed. To analyse the black-box complexity of adversarial optimisation, we introduce Yao's minimax principle and apply our new NFL result. Please consult the proof of Theorem 4.2 for more details.

### Contribution

We prove a new impossibility result on black-box adversarial optimisation. In a two-player zero-sum game setting, there is no free lunch with respect to an approximation of the real cost model when regarding the unique Nash Equilibrium as the solution concept. In other words, all black-box adversarial optimisation algorithms have the same expected performance over a uniform distribution of all possible problem instances with the unique Nash Equilibrium as the solution concept. It is the first step to resolve this long-standing open research problem about NFL in general black-box adversarial optimisation since [45; 46]. Our results highlight the significance of the choice of solution concepts and the limitation of general black-box adversarial optimisation. Additionally, we introduce the first general black-box model and the notion of black-box complexity for adversarial optimisation. Under this general black-box model, we provide the general lower bounds for query complexity of computing Nash Equilibrium in adversarial optimisation. Finally, we illustrate our results on examples of computing unique Nash Equilibrium in two-player zero-sum games.

## 2 Preliminaries

### Notation

Given \(n\), \([n]:=\{1,2,,n\}\). Given a finite set \(\), we denote the permutation group by \(():=\{:\) is a permutation of \(\}\). For any \(v^{n}\), let \((v):=\{i[n] v_{i} 0\}\). We refer to query complexity or runtime as the number of payoff function evaluations until the given algorithm finds the optimum. We consider the search space \(\), where \(\) and \(\) are finite and denote the cardinality of a set by \(||\). For any bitstring \(z\), \(|z|_{1}\) denotes the number of \(1\)-bits in \(z\). \(X Y\) denotes the isomorphism between \(X\) and \(Y\). \(X Y\) if there exists a one-to-one correspondence map from \(X\) to \(Y\).

Let \(f:X Y\) be a function from a set \(X\) to a set \(Y\). If \(A\) is a subset of \(X\), then the restriction of \(f\) to \(A\) is the function: \(f|_{A}:A Y;x f(x)\). Let \(f:X Y\) be any function and \(A\) and \(B\) be sets such that \(X A\) and \(Y B\). An extension of \(f\) to \(A\) is a function \(g:A B\) such that \(f(x)=g(x)\) for all \(x X\). Alternatively, \(g\) is an extension of \(f\) to \(A\) if \(f\) is a restriction of \(g\) to \(X\).

In this paper, we assume that the black-box optimisation algorithms do not make the same query twice. This can be achieved by memorising the outcome of previous queries.

### Solution Concepts

Solution concepts for classical function optimisation are not directly applicable to adversarial optimisation in general-sum or zero-sum game settings [33; 24; 35]. Each agent or player's payoff depends on not only its action but also the response from its opponents, and thus, we need to introduce different solution concepts to specify what kind of optimum we look for.

Pure Strategy Nash equilibrium is considered as our solution concept in this work. We are interested in whether the black-box adversarial optimisation can efficiently find any given game's Nash equilibrium. We use the formulation in  to define Nash equilibrium rigorously. In this paper, we only focus on Pure Strategy Nash Equilibrium (abbrev. NE).

**Definition 1**.: (Nash) Consider a two-player game. Given strategy spaces \(\) and payoff functions \(g,h: O\), where \(O\) is an ordered set which determines the outcome of candidate solution \(\) on test \(\), \((x^{*},y^{*})\) is a Nash equilibrium if for all \((x,y)\), \(g(x^{*},y^{*}) g(x,y^{*})\) and \(h(x^{*},y^{*}) h(x^{*},y)\). In particular, if the two-player game is zero-sum (that is, if \(g(x,y)+h(x,y)=0\) for all \((x,y)\)), then \((x^{*},y^{*})\) is a Nash equilibrium if for all \((x,y)\), \(g(x,y^{*}) g(x^{*},y^{*}) g(x^{*},y)\). The solution concept is defined by

\[S=\{(x^{*},y^{*})\;(x,y) ,g(x,y^{*}) g(x^{*},y^{*}) g(x^{*},y)\}.\]

We also defer other solution concepts for comparison in the appendix. We use the formulation in [46; 39].

## 3 No Free Lunch Theorem for Computing Nash Equilibrium in Adversarial Optimisation

In this section, we prove a No Free Lunch Theorem for black-box adversarial optimisation. As a first step toward the No Free Lunch Theorem, we consider two-player zero-sum games with the unique NE as the same setting in , but we relax the restriction from potential games to general two-player zero-sum games. The original NFL theorem for traditional optimisation assumed all problems instances , and later, sharpened work also proved that this holds for functions 'closed under permutation' [38; 11]. We now explain what 'closed under permutation' means and how it can be extended to games.

Permutation closure of a set of functions means that let \(,\) be two finite sets and \(f:\) defined by \(f(x_{i})=y_{i}\). Let \(\) be a permutation \(:\) and we can permute the function: \(f((x)):= f(x)\). Schumacher et al.  and Droste et al.  defined 'closed under permutation (c.u.p.)' with respect to a single search space \(\). A class of functions \(=f:\) is called c.u.p. if for all \(f\) and all permutations \((),f\). For our adversarial setting, we need to extend this notion to \(\).

**Definition 2**.: Given two-player zero-sum games, suppose \(\) as a subset of all the payoff functions in these games \(g: O\) where \(O\). We say \(\) is c.u.p if for any \(g\) and any permutations on \(,\) denoted by \((),()\), we have \(() g\) (or abbreviated \(()g\)) where \(() g(x,y):=g((x),(y))\) for all \((x,y)\).

If a set of two-player zero-sum games is c.u.p., we will also call it structure-free. In this paper, we restrict to the case that \(,,O\) are finite sets following the settings in [45; 46]. The proof of the No Free Lunch theorem for traditional optimisation by Droste et al.  is by induction, where one assumes that the statement is true for all "smaller problems". Here, a smaller problem refers to the following definition of a sub-game or a sub-problem class. Next, we define a sub-problem class for two-player zero-sum games.

**Definition 3**.: Given two-player zero-sum games, let \(O\) and \(\) be any subset of the set of payoff functions in these games \(g: O\) such that \(\) is closed under permutation. For any given \((x_{1},y_{1})\), any function \(b_{1}: O\), and any function \(b_{2}: O\), we define a sub-problem class \(((x_{1},y_{1}),(b_{1},b_{2}))\) with respect to \(\) as follows: \(f((x_{1},y_{1}),(b_{1},b_{2}))\) if and only if there exists a \(g\) such that

1. \(g(x_{1},y)=b_{1}(y)\) for all \(y\);
2. \(g(x,y_{1})=b_{2}(x)\) for all \(x\);
3. \(f\) is a restriction of \(g\) on \((\{x_{1}\})(\{y_{1}\})\).

Next, before we show that a sub-problem class \(((x_{1},y_{1}),(b_{1},b_{2}))\) is c.u.p., we need a lemma to guarantee that after any permutation, the permuted payoff function still contains the same unique Nash Equilibrium2. We provide a corollary to Lemma 4. We defer all the proofs to the appendix due to the page limit.

**Corollary 1**.: Let \(||=||\) and \(\{g:\}\) be any set of two-player zero-sum games with a unique NE. Assume furthermore that \(\) is c.u.p.. Then, for any game \(g\), let\((x^{*},y^{*})\) denote the unique Nash Equilibrium of \(g\). For any permutations over \(,\) denoted by \((),()\), \(() g\) exhibits the same unique Nash Equilibrium \((x^{*},y^{*})\). Moreover, if for any \(x_{0} x^{*}\) and \(y_{0} y^{*}\), the restriction of \(g\) on \((\{x_{0}\})(\{y_{0}\})\), denoted by \(g_{|(\{x_{0}\})(\{y_{0}\})}\), exhibits the same unique Nash Equilibrium \((x^{*},y^{*})\).

This permutation essentially swaps the rows and columns in the payoff matrix. Corollary 1 shows that the permutation of rows and columns does not change the optimum (Nash Equilibrium in any given payoff function). Moreover, if we remove the row and column in the given payoff function, which do not contain the unique Nash Equilibrium, then the unique Nash Equilibrium remains the same in the restricted sub-problem.

Next, we prove the sub-problem class is closed under permutation.

**Lemma 1**.: If \(\) is c.u.p., then \(((x_{1},y_{1}),(b_{1},b_{2}))\) is also c.u.p..

Then, we want to know if we choose different \((x,y)\) in the sub-problem class, are they still isomorphic (i.e., essentially the same problem for any black-box optimisation algorithm)?

**Lemma 2**.: For all \((x_{1},y_{1}),(x_{2},y_{2})\) and \(b_{1}:\), \(b_{2}:\), we have the isomorphism3:

\[((x_{1},y_{1}),(b_{1},b_{2}))((x_ {2},y_{2}),(b_{1},b_{2})).\]

Given \((x_{t},y_{t})\) is the search point by Algorithm \(H\) on payoff function \(g\) at iteration \(t\) and \((x^{*},y^{*})\) is the unique NE in a two-player zero-sum game defined by \(g:\), Theorem 3.1 considers the following query complexity: assume the cost \(C_{t}\) is the unique queries made by Algorithm \(H\),

\[T_{}(H,g):=\{C_{t}>0 x_{t}=x^{*}y_{t}=y^{*}\}.\]

Now, we prove our main theorem.

**Theorem 3.1**.: _Given \(\) as a subset of all the payoff functions \(g: O\) with a unique Nash Equilibrium where \(O\) and \(||=||\). Let \(H\) be an arbitrary (randomised or deterministic) black-box adversarial optimisation algorithm for any \(g\) where \(\) is closed under permutations. Let \(r(H,)\) be the average (under the uniform distribution on \(\)) of the expected query complexity of \(H\) on \(g\) (i.e. \((T_{}(H,g))\)). Then \(r(H,)=r(H^{},)\) for all algorithms \(H,H^{}\)._

Proof Sketch.: The proof of the main theorem is deferred to the appendix. Briefly, we use a proof by induction on the size of the search space. During the inductive hypothesis, problem class is reduced from \(\) to \(((x_{1},y_{1}),(b_{1},b_{2}))\), decreasing the search space from size \(N N\) to size \((N-1)(N-1)\), where \(||:=N\). Then using Lemma 2 and inductive step, it follows that \(r(H,)=r(H^{},)\) for any two deterministic algorithms \(H,H^{}\), and the claim for randomised algorithms quickly follows from the fact that any randomised algorithm can be viewed as a probability distribution among all deterministic algorithms. 

Theorem 3.1 reveals an important underlying result: All black-box adversarial algorithms can exhibit the same average runtime \(r(H,)\) of all possible problem instances (or problem instances c.u.p.) with a unique Nash Equilibrium in a two-player zero-sum game setting. It is a reasonable result since Theorem 3.1 tells us that if a class of payoff functions with a unique Nash Equilibrium does not change by any permutation on the input space, there is no structure provided for any search heuristic or any optimisation algorithm to use and it cannot help to find the Nash Equilibrium. This is also the reason why the original No Free Lunch theorem for traditional optimisation holds . As concluded by Ho and Pepyne , "if anything is possible and occurs with the same probability, then nothing can be expected.

This result is also surprising since Wolpert and Macready  and Service and Tauritz  both show there exists free lunch with respect to the two solution concepts in Definition 9 and Definition 10. However, our result does contradict the previous result. We consider the performance measure \(T(H,g)\) and a different query model considered by the previous work. In particular, Definition 9 and Definition 10 only take the player \(x\) into account, while the opponent optimum and different query model and performance measures can make a difference, resulting in either FL or NFL results. In summary, our new NFL theorem highlights the significance of solution concepts and also reveals that adversarial optimisation can exhibit "no-free-lunch", in particular for NE solution concept.

Black-Box Complexity of Black-Box Adversarial Optimisation

As shown in the previous NFL theorem, no better universal algorithms exist on structure-free problems (i.e., only assume the payoff function consists of the unique NE). In order for an algorithm to guarantee good performance, it is necessary to restrict the algorithm to classes of games that possess some structure. To compute the Nash equilibrium of certain classes of problems, including Nash equilibrium in a black-box setting, there are many works on analysing the computational complexity for black-box algorithms, and researchers aim to minimise the query complexity and provide more efficient algorithms to compute Nash equilibrium in two-player zero-sum game settings [27; 26; 3; 21; 22] The following questions remain under-explored: How does the performance measure of an algorithm (like query complexity) depend on the size of the search space, and is there any limitation that these algorithms will reach regardless of the problem \(g\)? We answer these questions here using black-box complexity.

### The Unrestricted Black-Box Model and the Black-Box Complexity

This section focuses on adversarial black-box optimisation and study the query complexity of learning Nash equilibrium in a two-player zero-sum-game setting. We refer to [13; 8; 10] as a more detailed introduction to the black-box complexity theory on traditional black-box optimisation. To prove a lower bound that holds for all algorithms, it is necessary first formally to define what constitutes an algorithm. Next, we construct an unrestricted black-box model of adversarial optimisation.

```
0: Search spaces \(,\).
0: Payoff functions \(g:\), \(h:\);
1: Initialise \((x_{0},y_{0})\) based on \(P_{}\); Initialise \(H_{0}=\) and \(C_{0}=0\).
2:for\(t=1,2,\) until the termination criterion met do
3: Choose some probability distribution \(P_{I(t)}\), depending only on \(I(t)\) where \(I(t):=_{j=1}^{t-1}(x_{j},y_{j},g(x_{j},y_{j}),h(x_{j},y_{j}))()^{t-1}\)
4: Produce a random search point \((x_{t},y_{t})\) based on \(P_{I(t)}\).
5: Query the payoffs \(g(x_{t},y_{t}),h(x_{t},y_{t})\)
6:if\((x_{t},y_{t}) H_{t-1}\)then\(C_{t}=C_{t-1}+1\); \(H_{t}=H_{t-1}\{(x_{t},y_{t})\}\).
7:else\(C_{t}=C_{t-1}\); \(H_{t}=H_{t-1}\). ```

**Algorithm 1** An Unrestricted Black-Box Model with Unique Query History

Algorithm 1 defines a class of algorithms subject to various probability distributions and samples the new strategy pair based on previous pairs and their payoffs. The initial search point \((x_{0},y_{0})\) is independent of the problem, so we can choose any probability distribution \(P_{}\) to initialise the algorithm. Subsequent strategy pairs are obtained by asking the oracle to apply a given variation operator to all previously queried search points subject to sample probability distribution \(P_{I(t)}\). By specifying different sample probability distribution \(P_{I(t)}\), Algorithm 1 represents various black-box optimisation algorithms, including several adversarial search (also called competitive coevolutionary) algorithms [46; 32] and randomised algorithms FindPSne (designed to learn the NE in bimatrix games) . Note that the model only considers the cost of unique queries made by the algorithm (i.e. we check the search point in the previous query history \(H_{t}\) in line 6). We assume that an algorithm which makes the same query twice is only charged for the cost of one of the queries.

Now, we define the query complexity (or runtime) of black-box adversarial optimisation algorithms by extending the idea of the traditional single-objective black-box optimisation algorithm in [13; 43] and assuming \(h=-g\) (i.e. zero-sum game) in this case.

**Definition 4**.: Given any unrestricted black-box algorithm with unique query history \(A\) and the payoff function \(g:\), \(T(A,g)\) is the query complexity of \(A\) with respect to \(g\) and \((x_{t},y_{t})\) is the search point generated by \(A\) if

\[T(A,g):=\{dC_{t}(x_{t},y_{t}) arg_{x}_{y}g(x,y)\}\]

where \(d\{1,2\}\). If the game is zero-sum, then \(d=1\). Otherwise, \(d=2\)Note that \(T(A,g)\{\}\) is the number of payoff evaluations until \(A\) queries for the first time some \((x^{*},y^{*}) arg_{x}_{y}g(x,y)\). Now, we can define what black-box complexity means with respect to a given class of adversarial optimisation algorithms and problem classes.

**Definition 5**.: For a class \(\) of payoff functions \(g:\), the \(A\)-black-box complexity of \(\) is defined as \(T(A,):=_{g}T(A,g)\), the runtime of \(A\) under the worst-case scenario on \(\). Then, the \(\)-black-box complexity of \(\) is \(T(,):=_{A}T(A,)=_{A }_{g}T(A,g)\); the best or minimum complexity among all \(A\) with respect to \(\). If \(\) is the whole class of all black-box algorithms, we denote \(T(,)\) the unrestricted black-box complexity of \(\).

We want to point out the difference between these two definitions. Definition 4 considers the query complexity for a particular algorithm and problem instance, and Definition 5 considers the black-box complexity for the best possible query complexity of all possible given algorithms under the worst-case scenario. The traditional black-box complexity theory characterises the difficulty of a certain class of problems and explores the limitations of the given black-box optimisation algorithms. We expect our extension to adversarial optimisation can provide similar insights as well.

### A General Lower Bound for Black-Box Adversarial Optimisation

We first provide a lower bound of query complexity for a general class of black-box adversarial optimisation problems.

**Theorem 4.1**.: _Let \(\) and \(\) be any finite sets. Assume that \(B\) with \(k:=|B| 2\). Consider any class of two-player zero-sum games \(\{g: B\}\) such that for all \((x,y)\), there exists a game \(g_{x,y}\) which has \((x,y)\) as unique, pure Nash Equilibrium. Then, the class \(\) has black box complexity at least \(_{k}||-1\)._

### A General Lower Bound for Two-player Zero-Sum Bimatrix Games

In this subsection, we employ Yao's Principle and No Free Lunch Theorem to provide a general lower bound for query complexity of searching Nash Equilibrium in zero-sum bimatrix games, and this leads to a sharper lower bound compared to the previous result in .

**Theorem 4.2**.: _Let \(\) be the set of all randomised algorithms defined by Algorithm 1 and \(T(,P)\)4 denote the query complexity of \(\) with respect to the input payoff matrix \(P\) for a two-player zero-sum game. Then, there exists an input matrix \(P^{n n}\) with a unique pure Nash equilibrium \((x^{*},y^{*})\) such that \((T(,P))(n+1)/2\). Thus, the black-box complexity with respect to \(\) of the problem class consisting of all bimatrix games with a unique Nash Equilibrium is at least \((n+1)/2\)._

Theorem 4.2 provides a sharper lower bound by a multiplicative factor \(4\) compared with the current best bound by . This result also demonstrates that in a two-player zero-sum bimatrix game (with an \(n n\) payoff matrix), there are complex instances where no randomised algorithm can achieve better than \(O(n)\) query complexity unless additional problem structure is provided.

### Applications on Two-Player Zero-Sum Games

#### 4.4.1 Introduction to Binary Voting Games

This section provides some example applications of our black-box complexity results. Voting games are popular games studied in game theory, computational social choice theory [5; 4; 16] and Boolean games . Voting is considered a fundamental tool for analysing multi-agent systems [16; 1]. We start with simple binary voting games in which the outcome or payoff is \(0\) or \(1\) (or \(-1\) and \(1\)). These games also play a role in the analysis of Boolean functions .

Convergence to NE in plurality voting has been studied from the perspective of social choice theory and researchers specify certain conditions to guarantee the voting games to converge to NEs . Some natural question arises: are there any randomised algorithms that can find these NEs in voting games efficiently? What are the limitations of these black-box optimisation algorithms? Using the black-box complexity analysis, we can answer the questions about the efficiency/inefficiency of black-box optimisation algorithms on binary voting games.

We formulate binary voting games in the context of adversarial optimisation as follows. Consider two parties represented by vectors \(x,y\{0,1\}^{n}\) where \(n\). Each group has \(n\) members that either "in favour" (encoded by \(1\)) or "against" (encoded by \(0\)) a particular proposal or decision. One group seeks a strategy \(x^{*}\) that maximises its minimum gains against any strategy of the other group, while the other group seeks a strategy \(y^{*}\) such that its choice minimises the maximum gains of the first group. It essentially forms a two-player zero-sum game.

**Definition 6**.: For \(==\{0,1\}^{n}\), the payoff function Diagonal\(:\{-1,1\}\) is

\[(x,y):=1&|y|_{1}|x|_{1}\\ -1&\]

In Definition 6, we present the votes of both groups by binary bitstrings and the payoff \(g\) can be viewed as a binary voting game where the payoff only depends on which group has the stronger majority "influence". If one group has a stronger 'in favour' "influence" in the sense of the number of the support votes (i.e. the number of \(1\) in the encoding binary bitstring), then we get a payoff \(1\) and \(-1\) otherwise. We are interested in computing NE in these two-player zero-sum games, i.e. solving \((x^{*},y^{*})*{arg\,max}_{x}_{y}g(x,y)\). Notice that in Diagonal\(,(x_{n},y_{n})=(1^{n},1^{n})\) is the unique NE optimum. In this optimum, neither of the two groups is willing to deviate from affecting their payoff \(g(x_{n},y_{n})\) anymore. This exactly coincides with the definition of NE.

Next, we consider a different binary voting game, denoted by Plateau. To make the binary voting game more challenging, we introduce some plateaus in games.

**Definition 7**.: For \(==\{0,1\}^{n}\), a constant \((0,1)\), the payoff function \(:\{-1,1\}\) is defined as

\[(x,y):=f(y)&||x|_{1}-|< \\ g(x,y)&\]

where \(f:\{-1,1\}\) and \(g:\{-1,1\}\) are any functions such that the NE of Plateau is \((x^{*},y^{*})\{(x,y)||x|_{1}-|<\}\).

Definition 7 introduces a plateau when comparing the "influence" between two groups and defines a general class of pseudo-Boolean benchmarks with a plateau. Imagine a committee deciding on a new policy where there are two groups with equal voting power. If the votes from group \(\) are balanced or nearly balanced (within the plateau), then the votes from the second group \(()\) come into play. It is like their votes are the tiebreaker. If the second group votes in favour, then the policy passes; if they vote against it, then it fails. If the votes from group \(\) are outside the plateau, then the payoff is not restricted to be determined by \(y\).

Finally, we define game instances generated by \((u,v)\) where \(u,v\{0,1\}^{n}\).

**Definition 8** (\((u,v)\)-game instance).: For all \(u,v\{0,1\}^{n}\), given \(f:\{0,1\}^{n}\{0,1\}^{n}\), we define the \((u,v)\)-instance of \(f\), denoted by \(f_{(u,v)}\), as \(f_{(u,v)}(x,y):=f(u x,v v)\).

We can see that for any \(u,v\{0,1\}^{n}\), \(f_{(u,v)}\) generates the same payoff landscape as \(f\). In this paper, \(f\) will be either Diagonal or Plateau. We defer more details to Section G5.

#### 4.4.2 Black-Box Complexity of Learning Nash Equilibrium in Binary Voting Games

First, let us illustrate how Theorem 4.1 and Theorem 4.2 work on these simple examples. If we consider a general class of black-box optimisation algorithms defined by Algorithm 1 on binary voting games with a unique Nash Equilibrium, then we provide a general lower bound of black-box complexity as follows.

**Theorem 4.3**.: _The black-box complexity with respect to Algorithm 1 of the binary voting games with problem size \(n\) and a unique Nash Equilibrium is \(e^{(n)}\)._

Theorem 4.3 means that there exist no universal good black-box optimisation algorithms defined by Algorithm 1 that can solve all binary voting games with unique Nash Equilibrium efficiently, (i.e. with polynomial query complexity of the problem size). To yield a better performance of black-boxoptimisation algorithms on binary voting games, we need to specify the problem class we work on. Next, we consider Diagonal and explore the black-box complexity with respect to the class of black-box optimisation algorithms \(\) defined by Algorithm 1 of Diagonal. This reveals that Diagonal is a feasible benchmark problem for black-box adversarial optimisation algorithms.

**Theorem 4.4**.: _Given the game class_

\[_{n}:=\{_{(u,v)}(u,v)\{0,1\}^{n} \{0,1\}^{n}\},\]

_the black-box complexity with respect to Algorithm 1 of Diagonal\({}_{n}\) is \((n)\)._

Theorem 4.4 implies that Diagonal\({}_{n}\) is a sensible maximin benchmark for testing black-box optimisation algorithms. It means that if we restrict the problem class to a certain class with a specific structure, then it is possible to solve them in polynomial query complexity.

We have seen the black-box complexity results on Diagonal\({}_{n}\). Next, we start to consider more challenging binary voting games, Plateau. We are interested in whether there is any efficient black-box adversarial optimisation that can solve Plateau\({}_{n}\) in polynomial query complexity (i.e. \(O(n)\)). To answer this question, we need to compute its black-box complexity.

**Theorem 4.5**.: _Given the game class,_

\[_{n}:=\{_{(u,v)}(u,v)\{0,1\}^{n}\{ 0,1\}^{n}\},\]

_the black-box complexity with respect to the class of algorithms defined by Algorithm 1 of Plateau\({}_{n}\) is \(e^{(n)}\)._

Theorem 4.5 implies that all black-box adversarial optimisation algorithms defined by unrestricted model (i.e. Algorithm 1) have exponential runtime on Plateau\({}_{n}\). They need at least an exponentially large query complexity with respect to the problem size \(n\). It is evident that Plateau is too challenging that it may not be a proper benchmark for black-box adversarial optimisation algorithms.

#### 4.4.3 Summary

Our study introduces the concept of black-box complexity in binary voting games, providing insights into the challenges faced by general black-box adversarial optimisation algorithms. These examples illustrate two kinds of problems within the general class of binary voting games with unique NE: the polynomial-solvable class (i.e., there exists an algorithm that can solve all problem instances of this class in polynomial runtime) and the non-polynomial-solvable class (i.e., there exists no algorithm that can solve all problem instances of this class in polynomial runtime).

Theorem 4.3 rigorously show that no universal algorithm can efficiently learn the unique Nash Equilibrium (NE) in these games due to their structure-free nature, where efficiency means small query complexity. However, when assuming specific problem structures, such as Diagonal\({}_{n}\), it is possible to come up with a better algorithm which achieves better polynomial query complexity as shown in Theorem 4.4. Diagonal\({}_{n}\) can be a promising benchmark for evaluating black-box algorithms. Additional assumptions on the payoff function, like those in Plateau\({}_{n}\) problems, proved in Theorem 4.5, do not lower the difficulty of the problems. This emphasises the need for a more careful selection of benchmarks. Black-box complexity emerges as a valuable tool for distinguishing between potentially easy and hard problem instances, guiding the design of black-box algorithms.

## 5 Further Related Work

### Co-evolutionary Search Heuristics

Next, we provide some practical examples of adversarial optimisation. There are various adversarial search heuristics, including competitive co-evolutionary algorithms (CoEAs) . CoEAs are a class of algorithms applied in game-theoretic and strategic adversarial optimisation scenarios. For example, CoEAs are used to solve maximin optimisation in a cybersecurity context  and to enhance GANs by using a co-evolutionary approach for image translation . Similarly, the neural architecture search system Lipizzaner employs co-evolutionary adversarial search to find suitable neural architectures for GANs .

Although several applications of adversarial (or co-evolutionary) search exist, there is limited theoretical literature on this topic. Lehre  demonstrated that the running time of the co-evolutionaryalgorithm PDCoEA on instances of the discrete bilinear problem is polynomial. Later, Hevia Fajardo et al.  showed a weakness of RLS-PD and the sufficiency of a simple archive to prevent evolutionary forgetting. On the other hand, regarding the general black-box optimisation framework, Wolpert and Macready  showed there exists a "free lunch" in such adversarial (or co-evolutionary) optimisation setting - there exist some algorithms have better performance than others averaged across all possible problem instances in adversarial optimisation with respect to the maximin solution concept (see Definition 10).

### Query Complexity of Learning in Games

The query complexity of various solution concepts in zero-sum and general-sum multi-player games has been well studied (for an overview, see ). It is well-known that converging to an exact (mixed strategy) Nash Equilibrium in general-sum matrix games is PPAD-complete . Chen and Deng  provide a simplified proof of the computational complexity of Nash Equilibrium in two-player games. Significant focus has also been placed on how the game dynamics converge to the Nash equilibrium or approximate it .

Panageas et al.  considered the complexity of fictitious play in two-player potential games with a unique Nash Equilibrium (NE). They proved the existence of a hard instance which requires query complexity \((4^{n}((n/2-2)!)^{4})\) where \(n\) refers to the number of actions. They showed that fictitious play can take exponential time (in the number of strategies) to reach a unique Nash Equilibrium, even when the game is restricted to two agents and arbitrary tie-breaking rules, by constructing a two-player coordination game with a unique Nash Equilibrium. Unlike previous work, our paper focuses on a more general class of games: the entire class of two-player zero-sum games with a unique NE rather than just potential games. We show that all black-box adversarial algorithms, including fictitious play, exhibit the same average performance across all problem instances in terms of query complexity.

## 6 Conclusion and Discussion

Utilising the tools from game theory and Yao's principle, we rigorously prove the impossibility results for a universally effective adversarial algorithm applicable across various problem classes in black-box adversarial optimisation. We emphasise the impact of solution concept selection on the feasibility of a "free lunch" in adversarial optimisation. Additionally, we introduce the notion of black-box complexity in black-box adversarial optimisation and characterise the difficulty of learning the unique optimum in adversarial optimisation and solving two-player zero-sum games.

The results from this paper build up a foundation for future studies on the strengths and limitations of adversarial optimisation. More specifically, it highlights the need for more comprehensive benchmarks and careful selections of solution concepts when using any black-box adversarial optimisation algorithms. Moreover, no black-box optimisation algorithm for learning the Nash equilibrium in two-player zero-sum games can exceed the logarithmic complexity relative to search space size. Meanwhile, no algorithm can solve any bimatrix game with unique NE faster than the linear query complexity in terms of the size of input payoff matrices.

Although our work makes a first step towards the new NFL and BBC results on black-box adversarial optimisation, we want to point out some limitations of our current work and list them as our future work. Firstly, our theoretical results build on discrete exponential large search spaces rather than countably infinite (e.g. \(\)) or uncountable infinite (e.g. \(\)) sets. To generalise our results to infinite sets, we might require further assumptions on our search spaces. Secondly, our NFL focuses on two-player zero-sum games with unique NE.

Future direction of our work includes extending Theorem 3.1 to other solution concepts like mixed strategy Nash Equilibrium or exploring different possible solution concepts which may exhibit free lunch or not. Additionally, it is interesting to generalise NFL and BBC analysis to zero-sum games with multiple NEs and more general search spaces. Finally, it is interesting to analyse other black-box models, such as unbiased black-box complexity models, to characterise the difficulty of adversarial problems that different classes of search heuristics can solve.