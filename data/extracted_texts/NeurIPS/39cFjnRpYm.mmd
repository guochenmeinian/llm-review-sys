# Time-uniform confidence bands for the CDF under nonstationarity

Paul Mineiro

Microsoft Research

pmineiro@microsoft.com &Steve Howard

The Voleon Group

steve@stevehoward.org

###### Abstract

Estimation of a complete univariate distribution from a sequence of observations is a useful primitive for both manual and automated decision making. This problem has received extensive attention in the i.i.d. setting, but the arbitrary data dependent setting remains largely unaddressed. We present computationally felicitious time-uniform and value-uniform bounds on the CDF of the running averaged conditional distribution of a sequence of real-valued random variables. Consistent with known impossibility results, our CDF bounds are always valid but sometimes trivial when the instance is too hard, and we give an instance-dependent convergence guarantee. The importance-weighted extension is appropriate for estimating complete counterfactual distributions of rewards given data from a randomized experiment, e.g., from an A/B test or a contextual bandit.

## 1 Introduction

What would have happened if I had acted differently? Although as old as time itself, successful companies have recently embraced this question via offline estimation of counterfactual outcomes using data from existing randomized experiments or contextual bandits. The problem is important in diverse domains such as software testing (Lindon et al., 2022; Wang and Chapman, 2022), portfolio management (Liu, 2021), and medicine (Shen et al., 2022). These experiments are run in the real (digital) world, which is rich enough to demand non-asymptotic statistical techniques under non-parametric and non-stationary (i.e., not i.i.d.) models. Although existing methods apply for estimating _average_ outcomes in this general setting (either under the observed distribution or counterfactual ones), estimating a complete _distribution_ of outcomes is heretofore only possible with additional assumptions: see Table 1 for a summary and Section 5 for complete discussion of related work.

To fix ideas, we briefly describe an application from Lindon et al. (2022) in the context of canary testing: rolling out changes in an online service to a small, random subset of users in order to detect accidental performance regressions while minimizing effect on overall user experience. The metric of interest measures latency for fetching content from the service. It is common to look beyond the mean of the latency distribution and especially to check for regressions in upper quantiles. As such, the authors choose to estimate bounds on the entire CDF of this latency metric under both the control and treatment arms and check for a statistically significant differences at any point in the CDF. The hope is to detect regressions as soon as possible, often within seconds or minutes, so the authors employ a sequential method which allows an automated system to continuously update the CDF bounds as data accumulates and to stop as soon as a significant regression is detected. Statistically, this translates into the requirement of confidence bands for the CDF which are both uniform over time (valid after every update) and uniform over values (so we can check for regressions at any quantile). We seek such bounds whose statistical validity is guaranteed under a minimum of assumptions.

Intriguingly, this problem is provably impossible in the general data dependent setting (Rakhlin et al., 2015). Consequently, our bounds always achieve non-asymptotic coverage, but may converge to zero width slowly or not at all, depending on the hardness of the instance. We call this design principle AVAST (\(\)lways \(\)laid \(\)and \(\)Trivial).

[MISSING_PAGE_EMPTY:2]

Cantelli (1933) established uniform convergence of linear threshold functions; subsequently the Dvoretzky-Kiefer-Wolfowitz (DKW) inequality characterized fixed-time and value-uniform convergence rates (Dvoretzky et al., 1956; Massart, 1990); extended later to simultaneously time- and value-uniform bounds (Howard and Ramdas, 2022). The latter result guarantees an \(O(t^{-1}((t)))\) confidence interval width, matching the limit imposed by the Law of the Iterated Logarithm.

AVAST principleIn contrast, under arbitrary data dependence, linear threshold functions are not sequentially uniformly convergent, i.e., the averaged historical empirical CDF does not necessarily converge uniformly to the CDF of the averaged historical conditional distribution (Rakhlin et al., 2015). Consequently, additional assumptions are required to provide a guarantee that the confidence width decays to zero. In this paper we design bounds that are Always Valid And Sometimes Trivial, i.e., under worst-case data generation, \(_{v} U_{t}(v)-L_{t}(v)=O(1)\) as \(t\). Fortunately our bounds are also equipped with an instance-dependent width guarantee based upon the smoothness of the distribution to a reference measure qua Definition 3.2.

Additional NotationLet \(X_{a:b}=\{X_{s}\}_{s=a}^{b}\) denote a contiguous subsequence of a random process. Let \(_{t}\) denote the average historical conditional distribution, defined as a (random) distribution over the sample space \(\) by \(_{t}(A) t^{-1}_{s t}_{s-1}[1_{X_{ s} A}]\) for a Borel subset \(A\) (note \(_{t}\) represents the entire historical average while \(_{t}\) corresponds to a single conditional distribution).

## 3 Derivations

### High Level Design

Our approaches work as reductions, achieving the value- and time-uniform guarantee of Equation (2) by combining bounds \(_{t},_{t}\) that satisfy a time-uniform guarantee at any fixed value \(\),

\[( t:_{t}()}_{t}()_{t}()) 1-().\] (3)

The bounds \(_{t},_{t}\) are tools for estimating a sequence of _scalars_, in this case \((}_{t}())_{t=1}^{}\) for a fixed value \(\). We show how to extend such tools to the more difficult problem of estimating a sequence of (cumulative distribution) _functions_.

There are multiple existing approaches to obtaining the guarantee of Equation (3): we provide a self-contained introduction in Appendix A. For ease of exposition, we will only discuss how to construct

Figure 1: Visualization of Algorithm 1. The values of interest are uncountably infinite; the algorithm allocates probability to maintain upper bounds on a countably infinite set of points \(\) at different resolution levels via the monotonicity of \(}_{t}(v)\). As resolution increases, the value \(\) better approximates \(v\), but the allocated probability decreases; the algorithm chooses the tightest of available bounds. Shaded nodes would be consulted for an upper bound for \(v=5}{{17}}\).

a time- and value-uniform upper bound by combining fixed-value, time-uniform upper bounds, and defer the analogous lower bound construction to Appendix B.2. Our approach is to compose these fixed-value bounds into a value-uniform bound by taking a union bound over a particular collection of values, leveraging monotonicity of the CDF.

Quantile vs Value SpaceIn the i.i.d. setting, a value-uniform guarantee can be obtained by taking a careful union bound over the unique value associated with each quantile (Howard and Ramdas, 2022). This "quantile space" approach has advantages, e.g., variance based discretization and covariance to monotonic transformations. However, under arbitrary data dependence, the value associated with each quantile can change. Therefore we proceed in "value space". See Appendix A.1 for more details.

### On the Unit Interval

Algorithm 1, visualized in Figure 1, constructs an upper bound on Equation (1) which, while valid for all values, is designed for random variables ranging over the unit interval. For a given value \(v\), it searches over upper bounds on the CDF evaluated at a decreasing sequence of values \(_{1}_{2} v\) and exploits monotonicity of \(_{t}}(v)\). That is, at each level \(d=1,2,\), we construct a discretizing grid of size \((d)\) over the unit interval, and construct a time-uniform upper bound on \(_{t}}()\) for each grid point \(\) using the fixed-value confidence sequence oracle \(_{t}\). Then, for a given value \(v\), at each level \(d\) we make use of the fixed-value confidence sequence for smallest grid point \(_{d} v\), and we search for the level \(d\) which yields the minimal upper confidence bound. A union bound over the (countably infinite) possible choices for \(_{d}\) controls the coverage of the overall procedure. Because the error probability \(_{d}\) decreases with \(d\) (and the fixed-value confidence radius \(_{t}\) increases as \(\) decreases), the procedure can terminate whenever no observations remain between the desired value \(v\) and the current upper bound \(_{d}\), as all subsequent bounds are dominated.

The lower bound is derived analogously in Algorithm 2 (which we have left to Appendix B.2 for the sake of brevity) and leverages a lower confidence sequence \(_{t}(;,_{t})\) (instead of an upper confidence sequence) evaluated at an increasingly refined lower bound on the value \((d)^{-1}|(d)v|\).

**Theorem 3.1**.: _If \((d)\) as \(d\), then Algorithms 1 and 2 terminate with probability one. Furthermore, if for all \(\), \(\), and \(d\) the algorithms \(_{t}(;,_{t})\) and \(_{t}(;,_{t})\) satisfy_

\[P( t:}_{t}()_{t}( ;,_{t})) 1-,\] (4) \[P( t:}_{t}()_{t}(; ,_{t})) 1-,\] (5)

_then guarantee (2) holds with \(U_{t},L_{t}\) given by the outputs of Algorithms 1 and 2, respectively._

Proof.: See Appendix B.3. 

Theorem 3.1 ensures Algorithms 1 and 2 yield the desired time- and value-uniform coverage, essentially due to the union bound and the coverage guarantees of the oracles \(_{t},_{t}\). However, coverage is also guaranteed by the trivial bounds \(0}_{t}(v) 1\). The critical question is: what is the bound width?

Smoothed Regret GuaranteeEven assuming \(X\) is entirely supported on the unit interval, on what distributions will Algorithm 1 provide a non-trivial bound? Because each \([_{t}(;,_{t}),_{t}(;,_{t})]\) is a confidence sequence for the mean of the bounded random variable \(1_{X_{i}}\), we enjoy width guarantees at each of the (countably infinite) \(\) which are covered by the union bound, but the guarantee degrades as the depth \(d\) increases. If the data generating process focuses on an increasingly small part of the unit interval over time, the width guarantees on our discretization will be insufficient to determine the distribution. Indeed, explicit constructions demonstrating the lack of sequential uniform convergence of linear threshold functions increasingly focus in this manner (Block et al., 2022).

Conversely, if \( t:}_{t}(v)\) was Lipschitz continuous in \(v\), then our increasingly granular discretization would eventually overwhelm any fixed Lipschitz constant and guarantee uniform convergence. Theorem 3.3 expresses this intuition, but using the concept of smoothness rather than Lipschitz, as smoothness will allow us to generalize further (Rakhlin et al., 2011; Haghtalab et al., 2020, 2022b; Bacon et al., 2022).

**Definition 3.2**.: A distribution \(D\) is \(\)-smooth wrt reference measure \(M\) if \(D M\) and \(_{M}({}^{dD}\!/_{dM})^{-1}\).

When the reference measure is the uniform distribution on the unit interval, \(\)-smoothness implies an \(^{-1}\)-Lipschitz CDF. However, when the reference measure has its own curvature, or charges points, the concepts diverge. When reading Theorem 3.3, note \( 1\) (since the reference measure is a probability distribution) and as \( 0\) the smoothness constraint is increasingly relaxed. Thus Theorem 3.3 states "for less smooth distributions, convergence is slowed."

**Theorem 3.3**.: _Let \(U_{t}(v)\) and \(L_{t}(v)\) be the upper and lower bounds returned by Algorithm 1 and Algorithm 2 respectively, when evaluated with \((d)=2^{d}\) and the confidence sequences \(_{t}\) and \(_{t}\) of Equation (15). If \( t:_{t}\) is \(_{t}\)-smooth wrt the uniform distribution on the unit interval then_

\[ t, v:U_{t}(v)-L_{t}(v)\\ }{t}}+(}{t}} (_{t}^{-2}^{-1}t^{3/2})),\] (6)

_where \(q_{t}}_{t}(v)\); \(V_{t}}{{t}}+-1/2)}}{{(q_{t}/1-q_{t})}}\); and \(()\) elides polylog \(V_{t}\) factors._

Proof.: See Appendix C. 

Theorem 3.3 matches our empirical results in two important aspects: (i) logarithmic dependence upon smoothness (e.g., Figure 4); (ii) tighter intervals for more extreme quantiles (e.g., Figure 2). Note the choice \((d)=2^{d}\) ensures the loop in Algorithm 1 terminates after at most \(_{2}()\) iterations, where \(\) is the minimum difference between two distinct realized values.

Worked ExampleTo build intuition, in Appendix B.1 we explicitly calculate Algorithm 1 for a synthetic data set.

### Extensions

Arbitrary SupportIn Appendix D.1 we describe a variant of Algorithm 1 which uses a countable dense subset of the entire real line. It enjoys a similar guarantee to Theorem 3.3, but with an additional width which is logarithmic in the probe value \(v\): \((}{t}((2+_{t}|v|t^{-1/2} )^{2}_{t}^{-2}^{-1}t^{3/2})})\). Note in this case \(_{t}\) is defined relative to (unnormalized) Lebesgue measure and can therefore exceed 1.

Discrete JumpsIf \(_{t}\) is smooth wrt a reference measure which charges a countably infinite number of known discrete points, we can explicitly union bound over these additional points proportional to their density in the reference measure. In this case we preserve the above value-uniform guarantees. See Appendix D.2 for more details.

For distributions which charge unknown discrete points, we note the proof of Theorem 3.3 only exploits smoothness local to \(v\). Therefore if the set of discrete points is nowhere dense, we eventually recover the guarantee of Equation (6) after a "burn-in" time \(t\) which is logarithmic in the minimum distance from \(v\) to a charged discrete point.

### Importance-Weighted Variant

An important use case is estimating a distribution based upon observations produced from another distribution with a known shift, e.g., arising in transfer learning (Pan and Yang, 2010) or off-policy evaluation (Waudby-Smith et al., 2022). In this case the observations are tuples \((W_{t},X_{t})\), where the importance weight \(W_{t}\) is a Radon-Nikodym derivative, implying \( t:_{t}[W_{t}]=1\) and a.s. \(W_{t} 0\); and the goal is to estimate \(}_{t}(v)=t^{-1}_{s t}_{s-1}[W_{s }1_{X_{s} v}]\). The basic approach in Algorithm 1 and Algorithm 2 is still applicable in this setting, but different \(_{t}\) and \(_{t}\) are required. In Appendix E we present details on two possible choices for \(_{t}\) and \(_{t}\): the first is based upon the empirical Bernstein construction of Howard et al. (2021), and the second based upon the DDRM construction of Mineiro (2022). Both constructions leverage the \(L^{*}\) Adagrad bound of Orabona (2019) to enable lazy evaluation. The empirical Bernstein version is amenable to analysis and computationally lightweight, but requires finite importance weight variance to converge (the variance bound need not be known, as the construction adapts to the unknown variance). The DDRM version requires more computation but produces tighter intervals. See Section 4.1 for a comparison.

Inspired by the empirical Bernstein variant, the following analog of Theorem 3.3 holds. Note \(_{t}\) is the target (importance-weighted) distribution, not the observation (non-importance-weighted) distribution.

**Theorem 3.4**.: _Let \(U_{t}(v)\) and \(L_{t}(v)\) be the upper and lower bounds returned by Algorithm 1 and Algorithm 2 respectively with \((d)=2^{d}\) and the confidence sequences \(_{t}\) and \(_{t}\) of Equation (18). If \( t:_{t}\) is \(_{t}\)-smooth wrt the uniform distribution on the unit interval then_

\[ t, v&:U_{t}(v)-L_{t}( v)\\ & B_{t}+)/t}{t}}\\ &+()/t}{t}}(_{t }^{-2}^{-1}))\\ &+(t^{-1}(_{t}^{-2}^{-1})),\] (7)

_where \(q_{t}}_{t}(v)\), \(K(q_{t})-1/2)}}{{(q_{t/1-q_{t}})}}\); \(V_{t}=O(K(q_{t})_{s t}W_{s}^{2})\), \(B_{t} t^{-1}_{s t}(W_{s}-1)\), and \(()\) elides polylog \(V_{t}\) factors._

Proof.: See Appendix E.2. 

Theorem 3.4 exhibits the following key properties: (i) logarithmic dependence upon smoothness; (ii) tighter intervals for extreme quantiles and importance weights with smaller quadratic variation; (iii) no explicit dependence upon importance weight range; (iv) asymptotic zero width for importance weights with sub-linear quadratic variation.

Additional RemarksFirst, the importance-weighted average CDF is a well-defined mathematical quantity, but the interpretation as a counterfactual distribution of outcomes given different actions in the controlled experimentation setting involves subtleties: we refer the interested reader to Waudby-Smith et al. (2022) for a complete discussion. Second, the need for nonstationarity techniques for

Figure 4: As smoothness’decreases, we require more time to reach the same maximum confidence width. For low smoothness, DKW dominates our method. The logarithmic dependence matches our theory. See Section 4.1.

Figure 5: CDF bounds’ approaching the true counterfactual CDF when sampling i.i.d. from a Beta(6,3) with infinite-variance importance weights, using DDRM for the oracle confidence sequence.

estimating the importance-weighted CDF is driven by the outcomes \((X_{t})\) and not the importance-weights \((W_{t})\). For example with off-policy contextual bandits, a changing historical policy does not induce nonstationarity, but a changing conditional reward distribution does.

## 4 Simulations

These simulations explore the empirical behaviour of Algorithm 1 and Algorithm 2 when instantiated with \((d)=2^{d}\) and curved boundary oracles \(\) and \(\). To save space, precise details on the experiments as well additional figures are elided to Appendix F. Reference implementations which reproduce the figures are available at https://github.com/microsoft/csrobust.

### The i.i.d. setting

These simulations exhibit our techniques on i.i.d. data. Although the i.i.d. setting does not fully exercise the technique, it is convenient for visualizing convergence to the unique true CDF. In this setting the DKW inequality applies, so to build intuition about our statistical efficiency, we compare our bounds with a naive time-uniform version of DKW resulting from a \((}{{^{2}t^{2}}})\) union bound over time.

Beta distributionIn this case the data is smooth wrt the uniform distribution on \(\) so we can directly apply Algorithm 1 and Algorithm 2. Figure 2 shows the bounds converging to the true CDF as \(t\) increases for an i.i.d. \((6,3)\) realization. Figure 8 compares the bound width to time-uniform DKW at \(t=10000\) for Beta distributions that are increasingly less smooth with respect to the uniform distribution. The DKW bound is identical for all, but our bound width increases as the smoothness decreases.

The additional figures in Appendix F clearly indicate tighter bounds at extreme quantiles, in correspondence with Theorem 3.3.

Beyond the unit intervalIn Figure 7 (main text) and Appendix F.1 we present further simulations of i.i.d. lognormal and Gaussian random variables, ranging over \(^{+}\) and \(\) respectively, and using Algorithm 3. The logarithmic dependence of the bound width upon the probe value is evident.

An Exhibition of FailureFigure 4 shows the (empirical) relative convergence when the data is simulated i.i.d. uniform over \([0,]\) for decreasing \(\) (hence decreasing smoothness). The reference width is the maximum bound width obtained with Algorithm 1 and Algorithm 2 at \(t_{}=10000\) and \(=1/16\), and shown is the multiplicative factor of time required for the maximum bound width to match the reference width as smoothness varies. The trend is consistent with arbitrarily poor convergence with arbitrarily small \(\). Because this is i.i.d. data, DKW applies and a uniform bound (independent of \(\)) is available. Thus while our instance-dependent guarantees are valuable in practice, they can be dominated by stronger guarantees leveraging additional assumptions. On a positive note, a logarithmic dependence on smoothness is evident over many orders of magnitude, confirming the analysis of Theorem 3.3.

[MISSING_PAGE_FAIL:8]

(i.e. not time-uniform). In other words, given a sample of i.i.d. random variables \(X_{1},,X_{n} F\), these fixed time bounds \([_{n}(x),_{n}(x)]_{x}\) satisfy a guarantee of the form:

\[( x,\;_{n}(x) F(x)_{n}(x))  1-,\] (8)

for any desired error level \((0,1)\). Howard and Ramdas (2022) developed confidence bands \([_{t}(x),_{t}(x)]_{x,t}\) that are both quantile- _and_ time-uniform, meaning that they satisfy the stronger guarantee:

\[( x,t,\;_{t}(x) F(x) _{t}(x)) 1-.\] (9)

However, the bounds presented in Howard and Ramdas (2022) ultimately focused on the classical i.i.d. _on-policy_ setup, meaning the CDF for which confidence bands are derived is the same CDF as those of the observations \((X_{t})_{t=1}^{}\). This is in contrast to off-policy evaluation problems such as in randomized controlled trials, adaptive A/B tests, or contextual bandits, where the goal is to estimate a distribution different from that which was collected (e.g. collecting data based on a Bernoulli experiment with the goal of estimating the counterfactual distribution under treatment or control). Chandak et al. (2021) and Huang et al. (2021) both introduced fixed-time (i.e. non-time-uniform) confidence bands for the off-policy CDF in contextual bandit problems, though their procedures are quite different, rely on different proof techniques, and have different properties from one another. Waudby-Smith et al. (2022, Section 4) later developed _time-uniform_ confidence bands in the off-policy setting, using a technique akin to Howard and Ramdas (2022, Theorem 5) and has several desirable properties in comparison to Chandak et al. (2021) and Huang et al. (2021) as outlined in Waudby-Smith et al. (2022, Table 2).

Nevertheless, regardless of time-uniformity or on/off-policy estimation, all of the aforementioned prior works assume that the distribution to be estimated is _fixed and unchanging over time_. The present paper takes a significant departure from the existing literature by deriving confidence bands that allow the distribution to change over time in a data-dependent manner, all while remaining time-uniform and applicable to off-policy problems in contextual bandits. Moreover, we achieve this by way of a novel stitching technique which is closely related to those of Howard and Ramdas (2022) and Waudby-Smith et al. (2022).

## 6 Discussion

This work constructs bounds by tracking specific values, in contrast with i.i.d. techniques which track specific quantiles. The value-based approach is amenable to proving correctness qua Theorem 3.1, but has the disadvantage of sensitivity to monotonic transformations. We speculate it is possible to be covariant to a fixed (wrt time) but unknown monotonic transformation without violating known impossibility results. A technique with this property would have increased practical utility.