# (Part 2): The Chernoff Method

Shadowheart SGD: Distributed Asynchronous SGD with Optimal Time Complexity Under Arbitrary Computation and Communication Heterogeneity

Alexander Tyurin

KAUST, AIRI, Skoltech

King Abdullah University of Science and Technology, Thuwal, Saudi Arabia AIRI, Moscow, Russia Skoltech

AUST, University of Pavia

KAUST, University of Pavia

King Abdullah University of Science and Technology, Thuwal, Saudi Arabia AIRI, Moscow, Russia Skolkovo Institute of Science and Technology, Moscow, Russia University of Pavia, Pavia, Italy

Ivan Ilin

KAUST1

KAUST1

KAUST1

###### Abstract

We consider _nonconvex stochastic_ optimization problems in the _asynchronous centralized distributed_ setup where the communication times from workers to a server can not be ignored, and the computation and communication times are potentially different for all workers. Using an unbiassed compression technique, we develop a new method--Shadowheart SGD--that provably improves the time complexities of all previous centralized methods. Moreover, we show that the time complexity of Shadowheart SGD is optimal in the family of centralized methods with compressed communication. We also consider the bidirectional setup, where broadcasting from the server to the workers is non-negligible, and develop a corresponding method.

## 1 Introduction

We consider the nonconvex smooth optimization problem

\[_{x^{d}}f(x):=_{_{}} [f(x;)]},\] (1)

where \(f(;):\,^{d}_{}\), and \(_{}\) is a distribution on \(_{}\). Given \(>0\), we seek to find a possibility random point \(\) such that \([\| f()\|^{2}]\). Such a point \(\) is called an \(\)-stationary point. We focus on solving the problem in the following setup:

(a) \(n\)_workers/nodes_ are able to compute _stochastic_ gradients \( f(x;)\) of \(f\), _in parallel_ and _asynchronously_, and it takes (at most) \(h_{i}\) seconds for worker \(i\) to compute a single stochastic gradient;

(b) the workers are connected to a _server_ which acts as a communication hub;

(c) the workers can communicate with the server _in parallel_ and _asynchronously_; it takes (at most) \(_{i}\) seconds for worker \(i\) to send a _compressed_ message to the server; compression is performed via applying lossy communication compression to the communicated message (a vector from \(^{d}\)); see Def. 2.1;

(d) the server can broadcast compressed vectors to the workers in (at most) \(_{ serv}\) seconds; compression is performed via applying a lossy communication compression operator to the communicated message (a vector from \(^{d}\)); see Def. A.1.

The main goal of this work is to find an _optimal_ optimization strategy/method that would work uniformly well in all scenarios characterized by the values of the computation times \(h_{1},,h_{n}\) and 

[MISSING_PAGE_FAIL:2]

but fixed. It is well-known that under Assumptions 1.1, 1.2, and 1.3, the vanilla SGD method \(x^{k+1}=x^{k}- f(x^{k};^{k}),\) where \(x^{0}^{d}\) is a starting point, and \(>0\) is the step size, solves (1) using _the optimal number of stochastic gradients_(Ghadimi and Lan, 2013; Arjevani et al., 2022). Since the \(}}}}}}}}}}}\) of iterations of SGD to get an \(\)-stationary point is \((}{{}}+L }}{{}^{2}}),\) SGD run on a _single worker_ whose computation time is \(h_{1}\) seconds would have _time complexity_\((h_{1}(}{{}}+ L}}{{}^{2}}))\) seconds. The time complexity of Minibatch SGD with \(n\) workers, i.e.,

\[x^{k+1}=x^{k}-_{i=1}^{n} f(x^{k};^{k}_{i}),\] (2)

can be shown (Gower et al., 2019) to be

\[(h_{}(+L}{n^{2}})),\] (3)

where \(h_{}:=_{i[n]}h_{i},\) where \([n]\) denotes \(\{1,,n\}\). The dependence on \(h_{}\) is due to Minibatch SGD employing _synchronous_ parallelism which forces it to wait for the slowest worker. While the stochastic part of (3) can be \(n\) times smaller than in the single worker case, (3) does not guarantee an improvement since \(h_{}\) can be arbitrarily large. In real systems, computation times can be very heterogeneous and vary in time in chaotic ways (Dutta et al., 2018; Chen et al., 2016).

Recently, Cohen et al. (2021); Mishchenko et al. (2022) and Koloskova et al. (2022) showed that it is possible to improve upon (3) using the celebrated Asynchronous SGD method (Recht et al., 2011; Feyzmahdavian et al., 2016; Nguyen et al., 2018) and get the time complexity \(((}{{n}}_{i=1}^{n}})^{-1} (}{{}}+L}}{{n }^{2}})),\) which improves the dependence from \(h_{}\) to the harmonic mean of the computation times. Subsequently, Tyurin and Richtarik (2023c) developed the Rennala SGD method whose time complexity is

\[(_{m[n]}(_{i=1}^{m}}})^{-1}(+L}{m^{2}})),\] (4)

where \(\) is a permutation for which \(h_{_{1}} h_{_{n}}\). They also showed that the time complexity (4) is _optimal_ by providing a matching lower bound.

### Communication time is a factor

In many practical scenarios, communication times can be the main bottleneck, and can not be ignored, e.g., in distributed/federated training of machine learning models (Ramesh et al., 2021; Kairouz et al., 2021; Wang et al., 2023). There are two main techniques for reducing the communication bottleneck: local training steps (McMahan et al., 2017) and compressed communication (Seide et al., 2014; Alistarh et al., 2017). In our work, we investigate the latter technique. In particular, efficient methods with compressed communication such as DIANA (Mishchenko et al., 2019), Accelerated DIANA (Li et al., 2020), MARINA (Gorbunov et al., 2021) and DASHA (Tyurin and Richtarik, 2023b) employ _unbiased compressors_, defined next. Assume that \(_{}\) is a nonempty arbitrary set of samples, and \(_{}\) is a distribution on \(_{}\).

**Definition 2.1**.: A mapping \(\,:\,^{d}_{}^{d}\) is an _unbiased compressor_ if there exists \( 0\) such that \(_{}[(x;)]=x,\ _{}[\|(x;)-x \|^{2}]\|x\|^{2}\) for all \(x\). Let \(()\) denote the family of such compressors5.

**Assumption 2.2**.: Samples from \(_{}\) and \(_{}\) are mutually independent.

The canonical example of an unbiased compressor is the Rand\(K\) compressor (see Def. D.1) that scales \(K\) random entries of the input vector \(x\) by \(}{{K}}\) and zeros out the rest. Many more examples of unbiased compressors are considered in the literature (Seznosikov et al., 2020; Xu et al., 2021; Horvath et al., 2022). One of the most straightforward methods which use compression is QSGD6(Alistarh et al., 2017):

\[x^{k+1}=x^{k}-_{i=1}^{n}_{i}( f(x^{k };^{k}_{i})),\] (5)where each worker calculates one stochastic gradient, compresses it using \(_{i}()\) drawn independently, and sends it to the server. The server aggregates the compressed vectors and performs step (5). With a proper stepsize choice \(\), QSGD converges after \(((}{{n}}+1) L}{{ }}+(+1) s^{2}L}{{n^{2}}})\) iterations7(Khaled and Richtarik, 2020). Let's assume it takes \(_{i}\) seconds for worker \(i\) to send one compressed vector to the server. Since the workers act in parallel, the time complexity of QSGD is

\[_{i[n]}(h_{i}+_{i})((+1) +(+1)L}{n^ {2}}).\] (6)

We can go through a similar exercise with any other method that uses compressed communication (e.g., (Tyurin and Richtarik, 2023; Gauthier et al., 2023; Jia et al., 2023)). Nevertheless, as far as we know, _the optimal time complexities for asynchronous centralized distributed optimization with communication compression are not known_.

## 3 Summary of Contributions

In the regime in which the communication time can be ignored (see Sec. 2.1), Tyurin and Richtarik (2023c) showed that (4) is the optimal time complexity. In this work we endeavor to take the next step: we wish to understand the fundamental limits of the regime in which communication time is a factor. Our main contributions are:

\(\) We develop a new method--Shadowheart SGD (Algorithm 1)--that guarantees to find an \(\)-stationary point of problem (1) with time complexity \(T_{*}\) given in (10). While the general expression we give for \(T_{*}\) is hard to parse since it involves the equilibrium time \(t_{*}()\) whose definition is implicit (see Def. 3.1), we show (see Sec. 7) that \(T_{*}\) is not worse than the time complexity of known centralized8 methods, and also who that it can be _strictly_ better in many regimes, even by _many degrees of magnitude_ (see Sec. 7.1 and Table 1).

\(\) In Sec. 5 we show that (10) is the _optimal time complexity_ in the family of centralized methods with compression. This is the first such result in the literature.

\(\) We also developed Adaptive Shadowheart SGD (Sec. 4.2 and M), which does not require the knowledge of the computation and communication times and can work with arbitrary changing times. Moreover, we designed Bidirectional Shadowheart SGD (Sec. A), which works in the regime when broadcast cost not negligible as well.

\(\) Our theoretical study of Shadowheart SGD is supported by judiciously designed synthetic experiments and machine-learning experiments with logistic regression; see Sec. Q.

## 4 Development of Shadowheart SGD

Our method bears some resemblance to Rennala SGD(Tyurin and Richtarik, 2023c) and QSGD(Alistarh et al., 2017), and involves some additional algorithmic elements which play a key role. First, we adopted the main suggestion of Tyurin and Richtarik (2023c)[Sec.7] behind the design of Rennala SGD that an optimal method should calculate stochastic gradients at the last iterate. Second, QSGD served as an inspiration for how to perform gradient compression. In particular, Shadowheart SGD has the form \(x^{k+1}=x^{k}- g^{k}\), where

\[g^{k}=_{i=1}^{n}w_{i}_{j=1}^{m_{i}}_{ij}( _{l=1}^{b_{i}} f(x^{k};_{il}^{k}))/_{i=1} ^{n}w_{i}m_{i}b_{i}.\] (9)

In Shadowheart SGD, worker \(i\) calculates \(b_{i}\) stochastic gradients, adds them up to form \(_{l=1}^{b_{i}} f(x^{k};_{il}^{k})\), and compresses the result \(m_{i}\) times using independently drawn compressors. The compressed messages are sent to the server. The first non-trivial step in the design of our method is the presence of weights \(w_{i}\): the server aggregates the \(_{i=1}^{n}m_{i}\) compressed messages across all workers by performing a conic combination with coefficient \(}{_{i=1}^{n}w_{i}m_{i}b_{i}}\) for messages coming from worker \(i\). One can easily show that (9) is equivalent to Alg. 1. Note that we recover QSGD (see (5)) as a special (suboptimal) case with \(w_{i}=b_{i}=m_{i}=1\) for all \(i[n]\).

The weights \(\{w_{i}\}\) are chosen so as to minimize the variance in the proof of Lemma H.1. However, we still need to find the right values for \(b_{i}\) and \(m_{i}\). Since the computation and communication times of worker \(i\) are \(h_{i}\) and \(_{i}\), respectively, the following strategy makes intuitive sense: the server sets some time budget \(t\) for all workers, and each worker then calculates \( t/h_{i}\) stochastic gradients and sends \( t/_{i}\) compressed vectors to the server. But what is the right way to choose \(t\)? If \(t\) is too small, then, intuitively, some workers may not have time to calculate "enough" gradients, or may even not have time to send any messages to the server. On the other hand, if \(t\) is too large, then the workers will eventually send information of diminishing utility which will not be worth the extra time this takes.

We find out that, and this one of the key insights of our work, that there exists an optimal time budget \(t^{*}\) which depends on the quantities \(\), \(}}{{}}\), \(h_{1}\), \(_{1}\),..., \(h_{n}\), \(_{n}\), for which we coin the name _equilibrium time_; see Def. 3.1. Admittedly, the definition of the equilibrium time is implicit; we do not know if it is possible to give a more explicit formula in general. To provide for some peace of mind, we prove the following property:

**Property 4.1**.: _If all inputs of the equilibrium time are non-negative, then the equilibrium time is well defined._

More importantly, in Sec. 5 we provide a _lower bound_ that involves the same mapping. Thus, the equilibrium time is not an "artifact" of our method, but is of a fundamental nature. We use the equilibrium time \(t^{*}\) in Shadowheart SGD when we choose \(b_{i}\) and \(m_{i}\).

Our first main result provides _iteration complexity:_

**Theorem 4.2**.: _Let Assumptions 1.1, 1.2, 1.3, 2.2 hold. Let us take \(=1/2L\) in Shadowheart SGD (Alg. 1). Then as long as \(K 16L/,\) we have the guarantee \(_{k=0}^{K-1}[\| f(x^{k})\|^{2} ].\)_

This result guarantees that Shadowheart SGD will converge after \(({}^{L/})\) iterations. Our second main result provides a much more relevant complexity measure: _time complexity_.

**Corollary 4.3**.: Shadowheart SGD _(Alg. 1) converges after at most \(T_{*}\) seconds, where_

\[T_{*}:= t^{*}(,}}{{}},h_{1},_{1},,h_{n},_{n}).\] (10)

Surprisingly, we show in Sec. 5 that our time complexity guarantee (10) is _optimal_ for the family of centralized methods with compressed communication. Moreover, in Sec. 7 and 7.1, we show that (10) is no worse and can be significantly better than the time complexities of previous centralized methods (see also Table 1 for a summary).

### Tighter result with per-iteration times \(h_{i}^{k}\) and \(_{i}^{k}\)

A slight modification of Alg. 1 leads to Alg. 4, which can work with iteration-dependent computation and communication times \(h_{i}^{k}\) and \(_{i}^{k}\). Our main result in this setup is Theorem H.3; here we present its corollary.

**Theorem 4.4**.: _Alg. 4 converges after_

\[_{k=0}^{}2t^{*}( ,}}{{}},h_{1}^{k},_{1}^{k},, h_{n}^{k},_{n}^{k})\] (11)

_seconds, where \(h_{i}^{k}>0\) and \(_{i}^{k}>0\) are computation and communication times for worker \(i\) in iteration \(k\)._

For presentation simplicity sake, in the main part we continue to work with static \(\{h_{i}\}\) and \(\{_{i}\}\).

### On the problem of estimating the times in Algorithms 1 and 4

One of the main features of asynchronous methods (e.g., Rennala SGD, Asynchronous SGD) is their adaptivity to and independence from processing times. In Sec. M, we design Adaptive Shadowheart SGD (Alg. 7) with this feature. Unlike Alg. 1, it does not require the knowledge of \(\{h_{i}\}\) and \(\{_{i}\}\) (or \(\{h_{i}^{k}\}\) and \(\{_{i}^{k}\}\) in the case of Alg. 4), and does not calculate the equilibrium time \(t^{*}\). However, as a byproduct of this flexibility, this method has a slightly worse time complexity guarantee. In order to present our result, we need to define an auxiliary sequence.

**Definition 4.5**.: Assume that the workers have computation and communication times less or equal to \(\{h_{i}\}\) and \(\{_{i}\}\). Assume that \(_{ij}\) is the actual time required to calculate the \(j^{}\) stochastic gradient by worker \(i\), \(h_{}>0\) is the smallest possible computation time. Then

\[r_{i}:=_{k 0}_{i,(k+j)}}{ _{1 j}_{i,(k+j)}}{h_{i,(k+j)}}},\;l_{}:= }{h_{}},\]

\(t_{}:=128 t^{*}(,}}{{}},[ \{h_{i},_{i}\},\{h_{i},_{i}\}]_{1}^{n}).\)

That is, \(r_{i}[1,]\) is the largest ratio between the fastest and the slowest computation of stochastic gradients in local time windows. \(r_{i}\) defines a degree of fluctuations in computation times. Note that \(r_{i}\) describes _local_ fluctuations; it is true that \(r_{i}_{i,j}}}{{_{1 j} _{i,j}}}\) for all \(i[n]\) and \(r_{i}\) can be arbitrarily smaller.

A corollary of our main result in this part (Theorem M.1) is presented next.

**Corollary 4.6**.: _If the computation and communication times are positive, the time complexity of Alg. 7 is \( t^{*}(,}}{{ }},[\{h_{i},_{i}\},\{_{i}r_{i},\{h_{i},_ {i}\}\}]_{1}^{n})\) up to a constant factor, where \(r_{i}\) is defined in Def. 4.5._

Unlike Alg. 1 and Alg. 4, Alg. 7 is more "greedy"; it calculates stochastic gradients and sends compressed vectors in parallel, and it does not know the times \(h_{i}\) and \(_{i}\) (or \(h_{i}^{k}\) and \(_{i}^{k}\)). That is why this method gets a suboptimal complexity and depends on \(r_{i}\). Nevertheless, if we assume that i) the computation times do not fluctuate significantly, i.e., \(r_{i}=(1)\), and ii) \(_{i} h_{i}\) for all \(i[n]\), then this complexity reduces to the optimal complexity \(}{{}} t^{*}(,}} {{}},[h_{i},_{1}^{n}]_{1}^{n}).\)

## 5 Lower Bound

```
1:Init \(S=\) on the server (all available information)
2:while True do
3:Server calculates a new point \(\) using \(S\) and broadcasts \(\) and \(S\) to any worker (broadcasting does not take time)
4:endwhile\(i^{}\) Worker (in parallel):
5:while True do
6: Receives \(\) and \(S\), calculates as many stochastic gradients as it want at the point \(\) (each calculation takes \(h_{i}\) seconds), aggregates all available information, and sends compressed vectors (each dispatch takes \(_{i}\) seconds), which will be added to the set \(S\)
7:endwhile ```

**Protocol 3** Simplified Representation of Protocol 9

In Sec. 4, we stated that Shadowheart SGD converges after \(T_{*}\) seconds; with \(T_{*}\) given in (10). Our next step is to understand if it might be possible to improve this complexity. In Sec. O, we formalize our setup and show in Theorem O.5 that up to a constant factor, the result (10) is _optimal_. Here we present a simplified illustration of our approach.

Protocol 3 can describe all centralized methods (the server updates the iterates, and the workers calculate stochastic gradients at these points), including Minibatch SGD, Asynchronous SGD, Rennala SGD, and Shadowheart SGD. In Theorem O.5, we show that up to a constant factor, no method described by Protocol 3 can converge faster than (10) seconds. In order to use our lower bound, the workers must calculate stochastic gradients at a point that was calculated by the server.

Let us briefly explain the proof's idea. The general approach is the same as in (Nesterov, 2003; Arjevani et al., 2022; Huang et al., 2022): we take the "difficult" function (Sec. P.1), which has large gradients while the last coordinate equals to zero. Every algorithm starts with the point \(x^{0}=0\), and the only way to discover the next coordinate is to calculate a stochastic gradient. Oracles associated with the workers return the next non-zero coordinate with the probability \(p_{}}{{^{2}}}\). Even if the stochastic oracle returns a non-zero coordinate for some worker, the corresponding communication oracle on this worker also has to return a non-zero coordinate, which happens with probability \(p_{}}{{}}+1\). We fix the Rand\(K\) compressor in the lower bound theorem with \(K}{{}}\), and the number of coordinates \(}{{}}\); thus, indeed, \(p_{}}{{}}+1\). Since all \(n\) workers work in parallel, they can discover and send to the server the next non-zero coordinate not earlier than after \(_{m[n]}\{h_{m}_{m}+_{m}_{m}\}\) seconds, where \(_{m}\) and \(_{m}\) are i.i.d. _geometric_ random variables with \(p_{}\) and \(p_{}\). With a high probability, we show that this quantity is \((t^{*}(}{{p_{}}},}{{p_{}}},h_{1},_{1},,h_{n},_{n}))\). The number of coordinates is \(}{{}}\). Therefore, the lower bound is (10) seconds up to a constant factor.

## 6 Equilibrium Time

Since the time complexity (10) of Shadowheart SGD is optimal, we believe that the equilibrium time is a fundamental mapping that should be investigated more deeply.

### Calculation strategy

The calculation of \(t^{*}\) requires us to sort \(\{h_{i},_{i}\}\). Next, it is sufficient to solve \(n\) equations from (7). In Property 4.1, we prove that (7) has one unique solution that can be easily found, for instance, using the bisection method. Then, is it left to find the minimum in (8).

### Intuition behind the equilibrium time \(t^{*}\)

Assuming we found an optimal \(j^{*}\) in (8), we have \(t^{*}=\{\{h_{_{j^{*}}},_{_{j^{*}}}\},s^{*}(j^{*})\}\). The first observation is that \(t^{*}\) does not depend on the workers that correspond to \(\{h_{_{j^{*}+1}},_{_{j^{*}+1}}\},,\{h_{_{n}},_ {_{n}}\}\). Since these values are greater or equal to \(\{h_{_{j^{*}}},_{_{j^{*}}}\}\), the mapping "decides" to ignore them because they are too slow. The followingderivations are not rigorous and are merely supposed to offer some intuition. We define \(_{i}:=_{n_{i}}\) and \(_{i}:=}}{{^{2}}}\). Next, using (7), we have

\[1=_{i=1}^{j^{*}} j^{*}}{2_{i}+_{i}}{z^{*} j^{*}}+2_{i}} s^{*} j^{* }_{i},_{i}\}}+s^{*}  j^{*}^{2}_{i}_{i}},\] (12)

where \(:=\{i[j^{*}]\,:\,\{_{i},_{i}\}_{i}}}{{s^{*} j^{*}}}\}\). Solving this, one can get that

\[s^{*} j^{*}(_{i},_{i}\}}+} _{i}}})^{-1}.\] (13)

Thus, \(s^{*} j^{*}\) divides the active workers into two groups \(\) and \([j^{*}]\). Both groups contribute to (13) with a _harmonic mean_-like and a _quadratic harmonic mean_-like dependences, correspondingly. The transition between two groups is decided by the rule \(\{_{i},_{i}\}_{i}}}{{s^{*}  j^{*}}} s^{*} j^{*}\{ _{i},_{i}\}.\) Intuitively, the last inequality means that if \(_{i}\) or \(h_{i}\) is small (a worker can quickly compute a gradient or send a compressed vector), it belongs to \(\). Otherwise, if a worker's computation and communication performance are balanced, it belongs to \([j^{*}]\).

### Properties of the equilibrium time \(t^{*}\)

We now provide some properties and particular cases to understand \(t^{*}\) better. One can find the proofs and more properties in Sec. E. The first result says that \(t^{*}\) is monotonic.

**Property 6.1**.: _If \( 0,}}{{}} }}{{}} 0,_{1} h_{1} 0,_{1}_{1} 0,,_{n} h_{n} 0,\) and \(_{n}_{n} 0,\) then \(t^{*},}}{{}},[_{i}, _{i}]_{1}^{n} t^{*},}} {{}},[h_{i},_{i}]_{1}^{n}.\)_

Consider the Rand\(K\) compressor. If it takes \(_{i}\) sec to send _one coordinate_ by worker \(i,\) then, up to a constant factor, Property 6.2 ensures that an optimal choice of \(K\) is \(1.\)

**Property 6.2**.: _For all \(K[1,d],}}{{}},\)\(h_{1},\)\(_{1},,h_{n},_{n} 0,\) we have \(24 t^{*}(}{{K}}-1,}}{{ }},h_{1},K_{1},,h_{n},K_{n}) t^{*}(d-1, }}{{}},h_{1},_{1},,h_{n}, _{n}).\)_

### Examples

We now list several examples, starting with simple corner/extreme cases. One can find the derivations in Sec. F. For brevity, we will sometimes write \(t^{*}\) instead of \(t^{*}(,}}{{}},h_{1},_{1},,h_{ n},_{n}).\)

_Example 6.3_.: **[Infinitely Fast Worker]** If exists \(j[n]\) such that \(_{j}=0\) and \(h_{j}=0,\) then \(t^{*}=0.\)

_Example 6.4_.: **[Infinitely Slow Workers]** If \(_{i}=\) and \(h_{i}=\) for all \(i[n],\) then \(t^{*}=.\)

_Example 6.5_.: **[Equal Performance]** If \(_{i}=\) and \(h_{i}=h\) for all \(i[n],\) then9

\[t^{*} 6\{h,,}{n},}{n}, ^{2}}{n}}\}.\] (14)

In the next example, we consider the setting from Sec. 2.1. Example 6.6 and Corollary 4.3 restore the optimal rate (4) of Rennala SGD.

_Example 6.6_.: **[Infinitely Fast Communication]** If \(_{i}=0\) for all \(i[n],\) then

\[t^{*} 2_{m[n]}\{h_{_{m}},}{} (_{i=1}^{m}}})^{-1}\}=( _{m[n]}(_{i=1}^{m}}})^ {-1}(1+}{m})),\] (15)

where \(\) is a permutation that sorts \(\{h_{i}\}_{i=1}^{n}.\)

The following two examples show that \(t^{*}\) is robust to slow workers or workers that do not participate.

_Example 6.7_.: **[Inoring Slow Workers]** If \(h_{i}\) and \(_{i}\) are fixed and finite for all \(i p,\) and \(\{h_{i},_{i}\}=m\) for all \(i>p,\) then, for \(m\) large enough, we have \(t^{*}(,}}{{}},[h_{i},_{i}]_{1}^{n})=t^{*} (,}}{{}},[h_{i},_{i}]_{1}^{p}).\)

_Example 6.8_.: **[Partial Participation]** If \(\{h_{i},_{i}\}=\) for all \(i>p 1,\) then \(t^{*}(,}}{{}},[h_{i},_{i}]_{1}^{n})=t^{*} (,}}{{}},[h_{i},_{i}]_{1}^{p}).\)Comparison with Baselines

In the previous sections, we did not invoke any assumptions about the compressors except for Def. 2.1. Inspired by Property 6.2, to make the comparisons with the baselines easier, we consider the \(K\) compressor with \(K=1\). Using Theorem D.2, we have \(=d-1\). We also assume that worker \(i\) takes \(_{i}\) seconds to send _one coordinate_ to the server; thus \(_{i}=_{i},\) since we use \(1\). Also, it takes \(d_{i}\) to send a non-compressed vector for all \(i[n]\).

**Minibatch SGD and QSGD.** It is well known (Lan, 2020) that the number of iterations of Minibatch SGD required to find an \(\)-solution is \((}{{}}+L }}{{}}).\) In Minibatch SGD, each worker calculates one stochastic gradient and sends a non-compressed vector. Since the server waits for the slowest worker, the time complexity of such method (up to a constant factor) is

\[T_{}:=_{i[n]}(h_{i}+d_{i})(+L}{n^{2}}).\] (16)

In Sec. J, we compare (16) with (10) and show

_Comparison 7.1_.: \(T_{*}=(T_{})\).

However, there are many regimes when \(T_{*} T_{}\). For instance, if \(\{h_{i},_{i}\}=\) for some worker (Example 6.8), then \(T_{}=\) and \(T_{*}<\). Also, under the conditions of Example 6.7, if \(m\), we get \(T_{}\) whereas \(T_{*}\) is bounded. The same reasoning applies to QSGD because its time complexity (6) depends on \(_{i[n]}(h_{i}+_{i}).\) Due to Theorem O.5, up to a constant factor, \(T_{*}\) is less or equal to (6); see also Table 1.

**Rennala SGD and Asynchronous SGD.** When the communication time is negligible, Tyurin and Richtarik (2023c) proved that the optimal time complexity is attained by Rennala SGD. When \(_{i} 0\) for all \(i[n]\), we show in Example 6.6 that (10) is the same as the time complexity of Rennala SGD obtained by Tyurin and Richtarik (2023c). Assume \(_{i}>0\) for all \(i[n]\). We can apply the result from Theorem O.5 to Rennala SGD, thus the time complexity of Rennala SGD is not better than

\[T_{}:= t^{*}(0,}}{{}},h_{1},d_{1},,h_{n},d_{n}).\] (17)

Note that Asynchronous SGD also has the same lower bound. In Sec. J, we compare (17) with (10) and show

_Comparison 7.2_.: \(T_{*}=(T_{})\).

### Shadowheart SGD is strictly better in many regimes.

Due to the non-explicit nature, it is not transparent that the time complexity of Shadowheart SGD is universally strictly better than in all baselines in many practical regimes. Let us prove it. Take

\[h_{i}=hi<n,\,h_{n}=,_{i}=i[n].\] (18)

Due to (16) and (17), the time complexities of Minibatch SGD and QSGD are \(,\) and the time complexities of Asynchronous SGD and Rennala SGD are not smaller than

\[(\{h,d,}{(n-1)} \}),}{{}}(\{h,d\}).\]

From (14), the time complexity of Shadowheart SGD is at most

\[(\{h,,}{n-1},}{(n-1)},h^{2}d}{(n-1) }}}),}{{}}( \{h,\}).\]

Thus, Shadowheart SGD can be \(d\) times faster than all previous methods if the number of workers \(n\) is large. Using the same reasoning, Shadowheart SGD can be \(n-1\) times faster if the dimension \(d\) or \(\) is large. Due to the continuity of the complexities, such huge differences hold even if we take \(n<,\) and start considering more heterogenous times \(h_{i}\) and \(_{i}\) by perturbating (18).

### The fastest worker works locally

Another important baseline is the vanilla SGD method, which works on the fastest worker, does not communicate with the server, and performs local steps (non-centralized method). For simplicity, assume that \(}}{{}} 1\). Then, the time complexity of such an algorithm (Lan, 2020) is \(_{i[n]}h_{i}L}}{{^{2}}}\). Clearly, comparing \(T_{}\) and (10), if \(_{i}\) are large enough, then \(T_{}\) can be smaller than \(T_{*}\). However, this does not contradict our lower bounds because this method does not satisfy the conditions of Theorem O.5: it does not communicate with the server. In other words, if the communication channel is too slow, it does not make sense to communicate. One may now ask: "Under which conditions is it beneficial to communicate?" Comparing \(T_{}\) and (10), one can see that (10) is better when \(t^{*}(d-1,}}{{}},h_{1},_{1},,h _{n},_{n})_{i[n]}h_{i}}}{{ }}\). It is sufficient to substitute the initial parameters to this inequality and decide which method to use. For instance, in the view of Example 6.5, one should compare \(\{h,,}{{n}},}}{{ }},(d-1)}}{{n}}e}\}\) vs. \(}}{{}}\). In the regime when \(n\) is large enough or \(\) is small enough, we have \(t^{*}<}}{{}}\), and Alg. 7 has better convergence guarantees. On the other hand, if \(\) is large enough, then it is possible that \(t^{*}>}}{{}}\).