# Holistic chemical evaluation reveals pitfalls in reaction prediction models

Victor Sabanza Gil\({}^{123*}\)  Andres M. Bran\({}^{12*}\)  Malte Franke\({}^{1*}\) Remi Schlama\({}^{1}\) Jeremy S. Luterbacher\({}^{23}\) Philippe Schwaller\({}^{12}\)

\({}^{1}\) Laboratory of Artificial Chemical Intelligence (LIAC), ISIC, EPFL

\({}^{2}\)National Centre of Competence in Research (NCCR) Catalysis, EPFL

\({}^{3}\) Laboratory of Sustainable and Catalytic Processing (LPDC), ISIC, EPFL

\({}^{*}\)Contributed equally.

philippe.schwaller@epfl.ch

###### Abstract

The prediction of chemical reactions has gained significant interest within the machine learning community in recent years, owing to its complexity and crucial applications in chemistry. However, model evaluation for this task has been mostly limited to simple metrics like top-k accuracy, which obfuscates fine details of a model's limitations. Inspired by progress in other fields, we propose a new assessment scheme that builds on top of current approaches, steering towards a more holistic evaluation. We introduce the following key components for this goal: CHORISO, a curated dataset along with multiple tailored splits to recreate chemically relevant scenarios, and a collection of metrics that provide a holistic view of a model's advantages and limitations. Application of this method to state-of-the-art models reveals important differences on sensitive fronts, especially stereoselectivity and chemical out-of-distribution generalization. Our work paves the way towards robust prediction models that can ultimately accelerate chemical discovery.

## 1 Introduction

In recent years, there has been a significant increase in the development and application of machine learning (ML) algorithms for solving various tasks in science-related fields . Advances in these models have been greatly accelerated by model developments , acquisition of extensive training data , and the establishment of benchmarks , which have enabled researchers to evaluate and compare new models based on multiple aspects relevant to the task at hand. Chemistry has also experienced remarkable progress in problems such as retrosynthetic planning , reaction condition recommendation , reaction prediction , and others . Among these, reaction prediction has gained considerable importance due to its broad applicability in areas such as waste material vaporization , reaction network analysis , and even the evaluation of retrosynthesis prediction models . Compared to the other tasks, reaction prediction benefits from having a less ambiguous objective, simplifying the evaluation process.

A wave of progress in this field has been further propelled by the publication of the USPTO reaction dataset , which has led to the emergence of benchmarks for various tasks, including USPTO_STEREO  and USPTO_480k  for reaction prediction. These consist of tailored subsets of the USPTO dataset, randomly split for training and evaluation. From the algorithmic side, transformer-based sequence-to-sequence models have emerged as the top-performing algorithms for reaction prediction , achieving top-1 accuracies of over 91%  on stereochemistry-free datasets. Other widely used model types include template-based  and graph-to-sequence models , eachleveraging different inductive biases derived from chemical expertise, achieving comparable top-1 accuracy.

Evaluation has received considerable attention in fields such as computer vision  and language models (LMs) . Out-of-distribution (OOD) shifts have been thoroughly discussed , and the need for testing in this domain has been emphasized . Broader evaluation schemes that aim to expose the strengths and failure modes of different models have also been proposed for LMs . However, standardized model evaluation in the field of reaction prediction has been largely neglected, with most studies relying solely on top-k reaction outcome accuracies, a restricted measure of model performance that overlooks a diverse range of complexities inherent to reaction prediction. Some works perform additional analyses and comparisons, giving more insight into the model's performance, however they lack a standardized format and are constrained by the quality of the reaction data that is used .

### Identifying failure modes in reaction prediction

In this work, we propose a holistic evaluation pipeline for a better chemical assessment of reaction prediction models. For this purpose, we introduce CHORISO (**CH**emical **O**rganic **R**eact**I**on **S**MILES **O**mnibus), a curated dataset of academic chemical reactions, along with a suite of chemically relevant metrics for the standardized evaluation of these models. Addressing the limitations in existing evaluation methods, we propose multiple slices and splits of CHORISO, serving as distinct scenarios fortesting, considering OOD scenarios . Several chemically relevant desiderata have been implemented in the proposed standard metrics, including different types of chemical selectivity, along with measures of model efficiency and environmental impact, as shown in Figure 1a. Through a combination of standardized metrics, curated data, OOD testing, and a collection of models, we aim to facilitate the development new cutting-edge ML models for reaction prediction (Figure 1b). This effort could ultimately lead to more accurate and reliable predictions with applications in various fields.

## 2 Holistic Evaluation of Chemical Reaction Models

Prediction of chemical reaction outcomes is a key problem in organic chemistry. Achieving accurate, trustworthy, and scalable chemical reaction prediction could accelerate chemistry discovery .

Figure 1: **Holistic evaluation of reaction prediction ML models.****a.** Chemistry-relevant metrics, out-of-distribution (OOD) robustness tests and sustainability assessments are proposed. Evaluation is done by using the CHORISO dataset, which provides reaction entries and from which OOD splits are derived. **b.** Failure modes of current reaction prediction models include poor performance in reactions with potential selectivity issues (left), and OOD scenarios such as reactions involving species with higher molecular weight (right).

Excellent performance in this task is thus crucial for the development of chemical models in general. These models are typically tested and compared in the literature using the top-k accuracy --with k \(\), with the best models reaching top-1 accuracies higher than 91% on patent reaction benchmarks without stereochemical information. However, the utility of these models is limited, as they tend to underperform in real-world use cases. The disconnection between such high accuracies and poor practical performance thus highlights the need for better evaluation methods.

The recent work of Liang et al.  sets the basis for the Holistic Evaluation of Language Models (HELM). The authors argue that, given the flexibility and generality of LMs, it is desirable to establish an evaluation scheme that more transparently assesses the capacities and flaws of these types of models. Holistic evaluation requires the identification of potential scenarios --encoding use-cases--and metrics --encoding desiderata-- that are of interest to LMs. In this setting, the authors can adequately test the models in terms of accuracy, robustness, and toxicity, among other metrics, across a wide range of scenarios, exposing the advantages and trade-offs of popular LMs. Building upon this work, our aim in this section is to identify relevant settings where chemical reaction models need to be tested and to develop metrics that align with key desired characteristics of these models.

### Data

A critical piece on the road toward holistic evaluation is data. Data not only feeds the models with latent knowledge but also allows researchers to model scenarios for testing, ultimately allowing to gauge and compare the adequacy of reaction prediction models in such scenarios. Despite the wave of reaction prediction models fueled by the USPTO dataset, these models learn from regions of the chemical space that are not necessarily typical targets of academic researchers, mostly featuring well-established, industry-relevant reactions.

To alleviate this, we propose CHORISO, a curated reaction dataset of diverse academic reactions. CHORISO is a mix betweeneleaned and processed versions of CJHIF, a dataset of reactions extracted from high-impact academic journals , and USPTO, a dataset of reactions extracted from patents  (see Appendix A.1). As shown in Figure 2, CHORISO features around 2.2M reactions, including a high ratio of C-C bond formation and functional group interconversion reactions, which are fundamental for strategic synthetic planning . CHORISO additionally exhibits heavier-tailed distributions of molecular weight and number of stereocenters in products, covering a larger and more relevant portion of the chemical space. This is particularly important for applications where stereocontrol is fundamental , as well as for investigations regarding the scope of chemical reactions, where extrapolation to higher Product's Molecular Weight (PMW) --e.g. larger substituents-- is desired. We use this dataset as the data source for our holistic evaluation.

Figure 2: **Dataset distributions comparison.** Differences between the two datasets (CHORISO and USPTO) are highlighted. **a.** Reaction types across various bins of product molecular weight (PMW). The distribution of reaction types varies considerably across PMW for CHORISO. Unrecognized reactions in the datasets are not plotted for clarity. **b.** Distribution of number of stereocenters in products shows that products in CHORISO overall contain a higher number of chiral centers. **c.** PMW distribution. CHORISOâ€™s distribution makes it suitable for OOD splits on both ends of the PMW distribution.

### Desiderata for models

A number of properties are expected from reaction prediction models. High accuracy is certainly one of them, but over-reliance on this metric can be misleading, especially in unbalanced datasets . From the chemical side, good handling of stereo- and regiochemistry is desired, as well as a correct understanding of functional group effects, effects of catalysts, reagents and other additives, and conditions like temperature and pressure . Proper modelling of these variables is necessary to have an accurate prediction system, and measuring how models perform in each variable is central to identifying trade-offs between them. Other, less field-specific properties are also desired, such as low inference speeds, low carbon footprint, and low energy consumption, which become important in high-demand applications like chemical networks space exploration .

In this work, we pave the way towards tackling the accurate evaluation of models in these regards, by implementing two chemically relevant and two performance-related metrics. The first two, region- and stereo-accuracy, calculate the product prediction accuracy in subsets of reactions that are flagged to have regio- and stereo-selectivity issues. These reactions are commonly encountered in aromatic ring substitutions  or systems where chirality is affected during the reaction , among others . These metrics thus highlight the models' capacities to predict the most reactive sites in a given context correctly, and to predict the dominant isomer in a potential isomer mixture. Furthermore, measurement of CO\({}_{2}\) emissions and training time are also considered, as per raising sustainability concerns in AI . Addressing sustainability in models can also improve their accessibility due to reduced hardware requirements for model execution during inference.

### Scenarios

Identifying and recreating scenarios relevant for testing models is one of the two key points highlighted by Liang et al. . We pay particular attention to out-of-distribution (OOD) scenarios, where the train and test set distributions differ. Due to the inherent difficulties in characterizing feature relevance for this task, we focus mainly on marginal shifts, described by Teney et al.  as those where a distribution shift happens only across features irrelevant to the task. One easily measurable property, that to good approximation is irrelevant for reaction prediction, is the product molecular weight (PMW). A model will desirably perform well independent of the molecular size, as reactivity analysis is typically based on local molecular features such as functional groups, which PMW does not directly influence.

Following this reasoning, two types of data splits are proposed: low PMW and high PMW, where the test data corresponds to the lowest and highest end of the PMW distribution, respectively (Appendix A.4). In addition, a standard split by products is proposed, where the set of product molecules in the train set is disjoint from its counterpart in the test set. These sets are used to evaluate the model and to provide a wider picture of its capabilities. While we acknowledge the importance of other types of distribution shifts, and future research should focus on exploring these, our current approach already proves valuable in revealing several aspects of models, including their limitations and failure modes, as shown in Section 3. This demonstrates the importance and effectiveness of the scenarios and distribution shifts considered in our study.

## 3 Results and discussion

With the proposed holistic evaluation pipeline, two high-performing reaction prediction models from the literature were trained and evaluated. The models, Graph2SMILES  (G2S), and Molecular Transformer  (MT) both draw elements from the Transformer architecture . This architecture relies on the attention mechanism  to infer inter-dependencies between tokens in token sequences. While the MT uses a string representation as input and output , G2S uses a graph encoder with a string decoder. Figure 1a provides a general comparison of the models, evaluated as proposed in this work using the CHORISO dataset. Contrary to previous reports , top-k accuracy indicates an advantage of MT over G2S. However, extending from this, our approach reveals important differences in models, namely their distinct performances in stereoselectivity and OOD generalization, both key for an appropriate evaluation at the chemical level. Figure 1 also illustrates how the implementation of the proposed holistic evaluation pipeline allows to dissect a model into multiple performance factors, providing a better picture of model limitations and trade-offs.

[MISSING_PAGE_FAIL:5]

reactions where MT provides the correct product and G2S fails from the selective reactions set. Reaction a) shows a stereoselective reduction using sodium borohydride where both models predict the correct molecule (in which the ketone has been reduced to an alcohol), but G2S misses the correct chirality of the generated stereocenter. Reaction b showcases a Curtius rearrangement that preserves the original chirality of the reacting center after the transformation. Here G2S also predicts the correct reacting pattern (even the stereochemistry preservation of the reaction center), but predicts a different isomer where two non-reacting chiral atoms have been inverted. Finally, in terms of regiochemistry, reaction c shows how MT predicts the correct regioisomer of a Friedel-Crafts acylation, whereas G2S generates the incorrect isomer where the acylation happens on the less activated aromatic carbon on the reacting ring. These examples showcase limitations and differences between the two methods, and may help to propose model architecture improvements to correct the selectivity difference.

An opposite trend is observed in the OOD splits (low and high PMW), where G2S outperforms MT with differences of up to 7% top-1 accuracy in high PMW. As shown in Figure 4, this difference is further exacerbated as the PMW increases, indicating the strong sensibility of MT to distribution shifts. When analyzing the accuracy by MW split, MT has an initial performance advantage over G2S (higher top-1 accuracy for the reactions where PMW is below or above 100 g/mol to the PMW of the training reactions). MT performance drastically decreases when moving away from training PMW, especially in the high PWM split. G2S is, on the other hand, more robust, as shown by the lower rate of decay in Figure 4. This behavior is hypothesized to be due to the graph-based encoder of G2S, which potentially suffers less from shifts in the molecular size of the input reactants by focusing on local molecular features. The MT instead suffers more from such distribution shifts as PMW directly affects input sequence length. This issue becomes more important for longer sequences, a fact that has been documented previously for language models  and that can be reflected on the poorer performance of MT on the high PWM. In the out-of-distibution scenarios, MT thus tends to predict larger molecules in the lowPMW split, and smaller molecules in the highPMW split, as shown in Figure 4. In addition, the general performance of both models decreases in the ODD scenario, suggesting that this distribution shift can be used to propose architecture improvements that make models less susceptible to this shift in non-relevant features. Finally, these results highlight the strengths of graph-based models and G2S in particular, which make them a more robust option for scenarios where a shift in property distribution like PMW is expected.

A final perspective based on model efficiency is provided by the sustainability metrics. Detailed analyses of each model's CO\({}_{2}\) production and training and inference time are possible thanks to

Figure 3: **Model limitations revealed by chemistry-specific metrics. MT performance is better than G2S in reactions where stereocenters are formed or different regioisomers are possible. **a.** Example where MT predicts the correct product and G2S fails because it predicts the opposite chirality in the reacting center **b.** Example where MT predicts the correct product and G2S fails because it inverts the chirality of non-reacting atoms. **c.** Example where MT predicts the correct product and G2S generates a different regioisomer.

recent tools  developed as per recent sustainability concerns of computational research, especially in ML and AI . MT produced 0.32 kg of CO\({}_{2}\) and took 19.8 h to train on the CHORISO data, whereas G2S produced 0.57 kg CO\({}_{2}\) and 40.8 h to train (full training and inference consumption for the benchmarking in Appendix B.2). The higher consumption and training time of G2S renders it less environmentally friendly than the MT, however, the environmental impact is still far less than models in other fields . On the other hand, inference time is similar for both models (3.1 vs 3.7 h). Overall, MT is a more efficient model for this task compared to G2S. This metric may help orient model selection considering a possible sustainability budget for model training and evaluation.

It must be stressed that the goal of holistic evaluation is not to determine the absolute best method among all the available models, as evaluation with top-k accuracy would. Instead, the objective is to provide a detailed map of the strengths and weaknesses of each model, ultimately producing a guide into each model's scope and applicability. Therefore, we have not performed hyperparameter tuning of the models, and instead used previously reported parameters to compare general accuracy. As it has been mentioned, both models were trained for the same number of steps for a fair comparison. As increasing model accuracy was not the main goal of the work, the performance values may be lower than others found in previous reports. However, our results gave a complete comparison in terms of chemistry applicability, robustness, and sustainability of MT and GS2. Following this, MT is a better choice for stereochemically challenging reactions or a limited computational budget, whereas G2S is recommended for scenarios where the novel reaction products fall far from the training property distribution. Furthermore, these efforts will help orient researchers toward addressing specific aspects of models, leading to increasingly better models across multiple chemically relevant directions.

## 4 Conclusion

We have introduced a new holistic evaluation method for chemical reaction prediction models. This work aims to improve current model evaluation practices in chemistry, allowing a stronger assessment of their real capabilities. Following advances in other fields, we discuss and implement a set of evaluation metrics and scenarios relevant to the task of reaction outcome prediction. In addition, a new academic reactions dataset is released --CHORISO, that is better suited for recreating some of these scenarios, as compared to other existing benchmarks. Leveraging this approach allowed

Figure 4: **Model limitations revealed by OOD metrics.** Analysis of model predictions in OOD setting shows that MTâ€™s accuracy decreases abruptly as PMW increases, while G2S is more nuanced, showing advantages in OOD generalization. Selected reactions show how MT tends to predict products with PMWs that are within the range of the training data, while G2S is generally better at extrapolation. In green, the reaction center is highlighted, showing how MT predicts the correct reaction, whereas G2S selects an incorrect transformation that lowers the MW of the resulting product and gives an incorrect prediction.

us to compare two state-of-the-art reaction prediction models, revealing pitfalls and trade-offs in the models, as well as limitations in previous evaluation methods. In particular, holistic evaluation suggests that the Molecular Transformer is better suited for stereochemically challenging reactions, while requiring a fraction of the energetic budget. On the other hand, Graph2SMILES showed much stronger performance in certain out-of-distribution scenarios. These results can easily be rationalized in terms of the models' architecture, with graph-based methods generalizing better to larger graphs, while text-based methods encode spatial features like stereochemistry better. More importantly, the results out-of-the-box reveal key features from models, that are hindered by the commonly used top-k accuracy.

Overall, this holistic evaluation proposes an improved pipeline for thorough reaction prediction model evaluation. Further development is required in the design of richer chemistry-relevant metrics and the identification of additional marginal out-of-distribution splits. In spite of this, this methodology already shows great potential for evaluating models, and opens the way towards the definition of functional guidelines for enhanced model development and selection in chemistry. Selection and improvement of the best-performing models for specific types of reactions and chemical spaces would unlock their routinary application and leverage the current low-data regime. This would lastly enable a future AI-accelerated chemical research.

## Data & Code availability

All the data and code used in this work is made freely available. The CHORISO dataset, along with the train and test splits described in this paper can be found at https://figshare.com/s/5e57a3399c52701cbc15 (DOI: 10.6084/m9.figshare.22598230). The code used for data pre-processing and analysis, metrics, and model evaluation, can be found at https://github.com/schwallergroup/CHORISO (data processing, analysis and metrics) and at https://github.com/schwallergroup/CHORISO-models (benchmarking).