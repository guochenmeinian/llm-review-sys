# Federated Fine-tuning of Large Language Models

under Heterogeneous Tasks and Client Resources

 Jiamu Bai

Pennsylvania State University

jvb6867@psu.edu

&Daoyuan Chen\({}^{*}\)

Alibaba Group

daoyuanchen.edy@alibaba-inc.com

&Bingchen Qian

Alibaba Group

qianbingchen.qbc@alibaba-inc.com &Liuyi Yao

Alibaba Group

yly287738@alibaba-inc.com &Yaliang Li

Alibaba Group

yaliang.li@alibaba-inc.com

Equal contribution. Work done during Jiamu Bai's internship at Alibaba Group.

###### Abstract

Federated Learning (FL) has recently been applied to the parameter-efficient fine-tuning of Large Language Models (LLMs). While promising, it raises significant challenges due to the heterogeneous resources and data distributions of clients. This study introduces FlexLoRA, a simple yet effective aggregation scheme for LLM fine-tuning, which mitigates the "bucket effect" in traditional FL that restricts the potential of clients with ample resources by tying them to the capabilities of the least-resourced participants. FlexLoRA allows for dynamic adjustment of local LoRA ranks, fostering the development of a global model imbued with broader, less task-specific knowledge. By synthesizing a full-size LoRA weight from individual client contributions and employing Singular Value Decomposition (SVD) for weight redistribution, FlexLoRA fully leverages heterogeneous client resources. Involving thousands of clients performing heterogeneous NLP tasks and client resources, our experiments validate the efficacy of FlexLoRA, with the federated global model achieving consistently better improvement over SOTA FL methods in downstream NLP task performance across various heterogeneous distributions. FlexLoRA's practicality is further underscored by our theoretical analysis and its seamless integration with existing LoRA-based FL methods, offering a path toward cross-device, privacy-preserving federated tuning for LLMs.

## 1 Introduction

Large Language Models (LLMs) have propelled advancements in natural language processing (NLP), offering breakthroughs in various tasks . Finetuning LLMs on specific datasets enhances their applicability , yet collecting such datasets raises concerns regarding cost and privacy .

Researchers have turned to Federated Learning (FL) as a means to fine-tune LLMs using more data across distributed clients without compromising data privacy . In these settings, parameter-efficient fine-tuning techniques , particularly Low-Rank Adaptation (LoRA) , become attractive for reducing computational and communicational burdens .

Despite its efficiency, LoRA's use in FL is challenged by the heterogeneity of downstream tasks and available resources among clients, especially in cross-device scenarios . Traditional FL methods often suffer from "bucket effect", converging to the use of the smallest viable LoRA rank for all clients, even though many clients typically have more resources that remain underutilized. A small LoRA rank, optimizing weights in a task-specific manner , can be sensitive to heterogeneous data distributions and compromised generalization when applied to all clients, as evidenced in Figure 1. Ideally, we hope all clients can fully leverage their advantages by sizing their local LoRA ranks with their resources to contribute models with less task-specific but more generalized knowledge.

To address these challenges, we propose FlexLoRA, a simple yet effective FL aggregation scheme that enables the mixture of diverse LoRA weights across individual clients. It accounts for local resource and task differences and aims for a well-generalized global model. With the heterogeneous aggregation and redistribution of weights through Singular Value Decomposition (SVD), FlexLoRA ensures all clients contribute effectively, regardless of resource capacity. Thanks to the simplicity, FlexLoRA can be pluggable into a series of LoRA-based FL methods, unlocking their potential to leverage available yet under-utilized resources to contribute more generalized knowledge via larger LoRA ranks, which is also supported by our theoretical analysis.

Our empirical study, simulating a cross-device federate fine-tuning scenario with thousands of clients on various of NLP tasks  and resource distributions, underscores the real-world applicability of FlexLoRA. Notably, FlexLoRA can be readily applied to several SOTA FL baselines in a plug-and-play manner and achieves significant performance enhancements, including 3.1% and 4% improvements in zero-shot Rouge-L scores and language understanding tasks such as overlap extraction and textual entailment, demonstrating robust generalization capability. We further conduct an extensive study on the aggregation scheme and scalability of FlexLoRA, furnishing a more nuanced understanding of the underlying mechanisms that facilitate its effectiveness

Our contributions can be summarized as follows:

* We propose a simple-yet-effective scalable method to fully leverage local client resources for enhancing the global model's generalization ability, supported by both theoretical analysis and extensive empirical evidence.
* To our knowledge, this is the first work to demonstrate the feasibility of federated tuning of billion-sized LLMs across thousands of NLP tasks in large-scale, resource-heterogeneous scenarios.
* We explore the interplay between LoRA ranks, client numbers, specific heterogeneous language tasks, and resource distributions, offering practical insights. Our code is made available at _https://github.com/alibaba/FederatedScope/tree/FlexLoRA_, inviting further research and application in real-world cross-device FL for LLMs.

Figure 1: Test loss of FlexLoRA and FedIT  across communication rounds under LoRA ranks of 1, 8, and 200. FlexLoRA demonstrates adaptability in an “extreme heavy tail” scenario and increasingly aligns with the performance of FedIT at the highest LoRA rank as rounds progress. Implementation details are in Appendix A.

Figure 2: Illustration of FlexLoRA.The server initially constructs a full-size LoRA weight, which is then averaged across client-contributed weights with different ranks. The aggregated global weights are decoupled via SVD and sent back to clients.

Related Work

**Parameter-Efficient Fine-tuning of LLMs.** The computation and storage demands of traditional fine-tuning processes have spurred the development of parameter-efficient fine-tuning (PEFT) techniques such as adapter and prefix tuning [15; 23]. Among existing PEFT techniques, we choose to employ LoRA due to its simplicity and outstanding performance [24; 18]. Despite this, our aggregation scheme can be easily extended into other PEFT methods by replacing the LoRA weights with their alternative weights to be tuned.

**PEFT in Federated Learning.** PEFT techniques have been integrated into FL to minimize communication costs and maximize efficiency. Several works employ LoRA for local model updates within an FL framework [2; 43; 44; 41; 19; 8; 26; 30; 38; 42]. For instance,  combines LoRA-based local updates with FedAvg for model aggregation, while  interspersse sparse finetuning with LoRA fine-tuning for improved initialization for LoRA in FedAvg.  proposes a technique to improve LoRA performance in FL scheme,  exploits performing SVD on pretrained model weights to resolve data heterogeneity, and  reduces communication cost through zeroth-order optimization. Distinct from these methods, our work, by introducing a simple yet effective aggregation scheme, leverages heterogeneous client resources to enhance the generalization and natural language understanding of the global FL model, addressing limitations seen in current FL paradigms.

**Data and Resource Heterogeneity in FL.** Data and resource heterogeneity remain significant challenges in FL, impacting both training and performance [28; 20]. Fruitful solutions have been explored to tackle the data heterogeneity [10; 25; 4; 42] or resource heterogeneity [21; 11; 7], while not in LLM context. A concurrent work, HETLORA , proposes allowing heterogeneous LoRA ranks by zero-padding local LoRA weights for aggregation and truncating global weights to match the local rank for distribution, all while employing sparsity regularization. However, our approach distinguishes itself through a focus on zero-shot task generalization and large-scale experiments inclusive of thousands of NLP tasks and clients, aiming to synthesize a well-generalized global LLM. Moreover, our method is simple and easy to use without any hyper-parameters for the aggregation, thereby circumventing the need for case-by-case tuning of newly introduced variables such as the decay and regularization factors of HETLORA.

## 3 Methodology of FlexLoRA

### Intrinsic Dimension and Generalization

Fine-tuning LLMs to enhance task-specific performance inevitably encounters cost of reduced generalization ability: a trade-off supported by the "no-free-lunch" theorem and empirical evidence usually called "alignment tax" of LLM [40; 31]. The generalization capability of LLMs is influenced by complexity of applied tasks and their solution spaces, which can be characterized by the concept of an intrinsic dimension - typically far smaller than the total number of model parameters .

The insight of intrinsic dimension informs the design of LoRA to fine-tune LLMs' pre-trained weights in a parameter-efficient manner, utilizing compact and low-rank matrices. Specifically, matrices \(A^{r p}\), \(B^{d r}\) are introduced, where \(r\) denotes the rank that encapsulates intrinsic dimension. These matrices form a low-rank approximation for tuning original weights \(W_{0}\) as \(h=W_{0}x+sBAx\), where \(x\) is the input of the parameter to be tuned, \(h\) is the output, and \(s\) is a scaling constant. Previous studies show that different ranks produce weights with attributes particularly tailored to specific downstream tasks [16; 18]. Consequently, the rank value plays a critical role in not only task-specific solution subspaces but also in determining a model's ability to generalize to various tasks.

In scenarios where clients have highly heterogeneous task and resource distributions, a uniform LoRA rank usually does not suffice for model performance, especially in its zero-shot generalization ability for unseen clients and tasks. Employing a small LoRA rank potentially leads to under-fitting in a global context by capturing only a subset of task-specific features, while a large rank is usually infeasible due to the "bucket effect" of existing FL solutions constrained by least-resourced clients.

FlexLoRA emerges as a solution to this dilemma by dynamically adjusting the rank in response to the variability in local client resources. By increasing the LoRA rank for clients with greater resources to contribute more global knowledge, FlexLoRA enhances the model's ability to generalize across diverse data distributions without sacrificing local performance accuracy. This strategy allows for federated fine-tuning of LLMs to navigate between the extremes of task-specific optimization and generalization to unseen clients and tasks.

### Aggregation with Heterogeneous Ranks

Traditional FL methods like FedAvg aggregate local LoRA weights by computing a weighted average of the decomposed matrices \(A\) and \(B\) as \(B_{g}=(_{i=1}^{m}n^{i}B_{l}^{i})/(_{i=1}^{m}n^{i}), A_{g}=(_{i=1 }^{m}n^{i}A_{l}^{i})/(_{i=1}^{m}n^{i}),\) where \(B_{g},A_{g}\) are the global LoRA decomposed matrices, and \(B_{l}^{i},A_{l}^{i}\) are the local LoRA decomposed matrices of \(i\)-th client, \(n^{i}\) is the size of the \(i\)-th client's local training dataset, \(m\) is the number of FL clients. However, this scheme is restricted by the lowest LoRA rank among participating clients for aggregation compatibility, which makes it hard to capture the full diversity of client contributions and fully utilize ample client resources.

FlexLoRA takes a different yet simple approach to enable decomposed matrix with different LoRA ranks to be mixed together. Specifically, it first forms a low-rank approximation of the LoRA matrix for each client, \(W_{l}^{i}\), before computing the weighted average: \(W_{g}=( n^{i}W_{l}^{i})/(_{i=1}^{m}n^{i})=( n^{i}sB_{l}^{i}A_{l}^{ i})/(_{i=1}^{m}n^{i}).\)

After the weighted average with heterogeneous LoRA ranks, the resulting global LoRA weight \(W_{g}\) is decomposed using SVD. Then the SVD components \(U,,V\) are redistributed to clients in a low-rank approximation that preserves as much information of \(W_{g}\) as possible meanwhile based on clients' local resources characterized by \(r^{i}\):

\[(W_{g})=U V^{T}, W_{g}^{i}=U[:,:r^{i}][:r^{i},:r^ {i}]V[:r^{i},:]^{T} W_{g},\]

where \(U\), \(\), and \(V^{T}\) are the SVD components of \(W_{g}\), the \(r^{i}\) within \([]\) indicates the indexing operator of each client to select their singular vectors corresponding to top \(r^{i}\) singular values. As a result, client \(i\) receives the aggregated knowledge \(W_{g}^{i}\) from server and incorporates \(W_{g}^{i}\) into its local LoRA weight \(W_{g}^{i}=sB_{g}^{i}A_{g}^{i}\) with \(B_{g}^{i}=U[:,:r^{i}][:r^{i},:r^{i}]/s\), and \(A_{g}^{i}=V[:r^{i},:]^{T}\).

The local training then proceeds as similar to those in standard FL approaches, using \(W_{l}^{i}\) as the local weights to be tuned. This aforementioned process is repeated until convergence is achieved or a predetermined number of rounds is completed.

### Maximizing Local Rank with Local Resources

To fully utilize the local resource of a local client, we adhere to the principle of _allocating the highest feasible rank given a client's resource budget_, which is motivated by our empirical finding that larger ranks generally yield better generalization. Figure 1 demonstrates that models trained with uniformly higher ranks outperform those with lower ranks under conventional parameter-average aggregation schemes. For single-client performances, the zero-shot performance is also boosted in the majority of the cases. The Table 13 and Figure 9 from Appendix J show that performance improves with higher LoRA ranks uniformly regardless of the tasks assigned to each client. While there might be an ideal LoRA rank that maximizes a single client's performance--potentially as high as 200--practical resource limitations may necessitate settling for a lower rank, such as 8. Therefore, we adopt the principle of setting the rank to be as large as possible to completely utilize the resources in FlexLoRA, which is easy to implement and under low risk of overfitting as Occam's razor suggests.

In Appendix B, the overall procedure of FlexLoRA and its core function of server update are summarized in Algorithm 1 and Algorithm 2 respectively. FlexLoRA optimally leverages the inherent characteristics of LoRA, boosting model generalization effectively by increasing local ranks, while without sacrificing overall training efficiency. Compared to FedAvg and homogeneous rank-based FL methods, FlexLoRA incorporates a lightweight SVD procedure, but the overhead from SVD is negligible compared to the local LLM training procedure. Moreover, the SVD is performed only once per round and is independent of client numbers. Notably, FlexLoRA enables heterogeneous ranks without the need for any additional hyperparameter tuning. As we empirically demonstrate in Table 4, the improved convergence rate, thanks to larger ranks, more than compensates for the extra overhead introduced by training on more parameters per round, resulting in a net gain in overall efficiency and a reduced overall time to completion. These features enhance its efficiency and scalability in cross-device FL settings where thousands or millions of devices are involved.

### Generalization Analysis

We analyze the generalization ability of FlexLoRA by extending Baxter's model of learning . Here, \(h_{W}()\) represents the hypothesis generated by the model with LoRA weights \(W\), and \(fW;(x,y)\) denotes the loss function for a single data point \((x,y)\). The expected loss is denoted as \((W_{g})_{(x,y)_{i}}fW;(x,y )\). The two key assumptions underpinning our analysis are as follows:

**Assumption 1**.: _The following Lipschitz conditions hold: \(|f(W;x,y)-f(W^{};x,y)| L_{f}||W-W^{{}^{}}||\) and \(||h(W;x)-h(W^{{}^{}};x)|| L_{h}||W-W^{{}^{}}||\)._

Following current analysis in SOTA methodologies in LLM research, we assume Lipschitz conditions in our analysis for \(f\) and \(h\)[27; 17; 13]. This assumption indicates that \(f\) and \(h\) are Lipschitz continuous with respect to the LoRA weights \(W\), ensuring the stability of the loss landscape. For simplicity, we denote \((W_{g},r^{i})\) as using the top \(r^{i}\) singular values and the corresponding singular vectors to approximate \(W_{g}\). We denote the parameter solution space of \(W_{g}\) to be \(k\). Next, due to the federated average and indexing operation based on the largest singular values, we assume that the dissimilarity between the global model and its rank-constrained approximation can be bounded:

**Assumption 2**.: _The LoRA weights can be bounded in a ball with radius \(R\), and the error induced by the SVD approximation for each client is bounded by a constant \(^{i}\) as \(||(W_{g},r^{i})-W_{g}||^{i}\)._

**Theorem 1**.: _Under Assumptions 1 and 2, with probability at least \(1-\), there exists a sample size \(=(|^{}}(}{ -2^{i}L_{f}L_{h}})-|^{^{2}}})\) such that for all \(W_{g}\), the bound \(||(W_{g})-(W^{{}^{}}_{g})||\) holds when the number of local data samples for each client \(i\) exceeds \(\)._

Detailed proof is in Appendix C. This theorem suggests that the generalization ability of the global model is influenced by the LoRA rank \(r^{i}\) chosen by each local client. Specifically, as \(^{i}\) is the error bound of SVD approximation, increasing rank \(r^{i}\) makes the approximation more accurate, thus reducing \(^{i}\). Consequently, this reduction in error bound decreases the requisite number of samples, denoted as \(\), required for effective generalization. Moreover, an increase in the number of clients \(||\) also contributes positively to the generalization of the federated model in the order of \((|})\), a stronger impact than \(^{i}\) whose impact is in a logarithmic fashion \((log(}))\). Collectively, FlexLoRA is effective in cross-device FL settings, where the generalization capability of the global model can be significantly enhanced by the participation of massive clients (larger \(||\)) with heterogeneous resources (larger \(r^{i}\)). Note that Assumption 1 is standard in FL literature , and our proof do not rely on simplified assumptions that often do not hold in cross-device cases, such as identically distributed data. We provide empirical support for distribution-related generalization ability, the effect of SVD (Assumption 2), and the effect of client numbers in Sections 4.3, 4.5 and 4.6 respectively.

## 4 Experiments

### Setup for Cross-Device FL Environments

**Resource Heterogeneity.** We make FL clients resource-heterogeneous by crafting four distinct LoRA configurations as listed in Table 1. Type 1, 2, and 4 assign the same LoRA on all tunable layers, while Type 3 assigns small ranks on attention layers and large ranks on FFN layers, following the design of the MAM adapter . Clients are randomly assigned a configuration type, simulating four types of heterogeneous resource environments similar to . As shown in Figure 3, we consider uniform resource distribution where each LoRA configuration type is equally likely to be assigned to each client, heavy tail resource distribution where either Type 1 or Type 4 is dominant, and normal distribution where the LoRA configuration types are normal distribution and Type 2 and Type 3 are dominant. A comparison of the active memory cost with different LoRA configurations is shown in Appendix D. Besides, we add LoRA on top of all the linear layers of LLMs based on the empirical results in Appendix E.3.

**Task Heterogeneity.** We further make FL clients task-heterogeneous by utilizing the natural instruction dataset . The dataset consists of over 1600 distinct natural language tasks that come from 76 NLP task types and is split based on its meta-info of the belonging NLP tasks, such that each client holds a unique task to mirror a task heterogeneous environment. Notably, while the FL setupincludes over 1600 clients, the distribution of 76 task types across these clients means that some will inherently share similar local data distributions, thereby mirroring the natural variability and overlapping task characteristics often encountered in real-world settings. Unless stated otherwise, we conduct all our FL experiments on this dataset and adopt DataJucier (1.3B) as our foundation models , chosen for its suitability for edge devices with constrained resources. More details about data preparation are included in Appendix E.2.

### Setup for FL Baselines

**Baselines with Homogeneous Rank.** We adopt FedAvg , FedIT , and SLoRA  as baselines utilizing unvarying LoRA ranks. FedIT aggregates the LoRA module weight of each client by averaging which limits the local LoRA rank to meet the lowest resource constraint. Comparing with FedAvg, FedIT adopts Adam optimizer for local training instead of SGD optimizer. SLoRA first trains local client models with sparse fine-tuning for several epochs then switches to LoRA for PEFT and uses the updates from sparse fine-tuning as initialization.

**Baselines with Heterogeneous Ranks.** Besides, we compare with HETLORA , a concurrent work exploring the effective utilization of diverse LoRA ranks in FL. It first employs zero-padding on all the LoRA matrices based on the largest rank, then conducts element-wise averages like FedAvg, and finally truncates the aggregated model to fit the local client LoRA rank.

We note that both FlexLoRA and HETLORA are able to be plugged into the above-mentioned FL methods with homogeneous LoRA ranks. In our experiment, for each baseline with homogeneous rank, we also examine their performance after integration by either FlexLoRA or HETLORA.

### Unseen Client Generalization

**Evaluation Setup.** Our initial examination focuses on the generalization capabilities of global models to unseen clients by deploying the models to clients with unseen data distributions. The unseen clients are newly sampled clients from the next communication round. This assessment allows us to measure zero-shot performance, a key indicator of a model's ability to generalize beyond the data available during the training phase. This approach is to simulate the real FL setting, where well-trained global weights will be deployed to new clients rather than clients participating in the previous round. Specifically, we investigate the performance of global models trained with baseline methods both with and without the integration of FlexLoRA and HETLORA under four distinct resource heterogeneity scenarios.

**Overview Performance Comparison.** Table 2 displays the zero-shot performance under Rouge-L scores on the test set from unseen clients, facilitating a comparison of the generalization capabilities across different federated global models. It is observed from the table that in most of the cases, methods with heterogeneous LoRA ranks have better performance than that of homogeneous ranks, indicating that heterogeneous LoRA ranks enhance the clients with larger ranks to fully exploit their capability. Furthermore, among the heterogeneous LoRA rank methods, our proposed FlexLoRA consistently outperforms HETLORA across all resource distribution settings. This shows that FlexLoRA is able to take advantage of heterogeneous resource distribution, and is more capable of leveraging the general information from heterogeneous LoRA configurations.

    & LoRA Config & \# Params \\  Type 1 & \(r=8\) on all layers & 0.12 \% \\ Type 2 & \(r=30\) on all layers & 2.46 \% \\ Type 3 & \(r=30\) on atten layer, & 8.22 \% \\ Type 4 & \(r=200\) on all layers & 12.22 \% \\   

Table 1: The LoRA configurations that compose heterogeneous resource distributions, detailed in Figure 3.

Figure 3: Heterogeneous resource distributions containing different ratios of various LoRA configuration types.

**Effect of Specific Resource Distributions.** To gain further insight into the effect of FlexLoRA and the effect of heterogeneity of LoRA ranks, in Table 10 in Appendix F, we list the percentage improvement for each FL methods when incorporating FlexLoRA in comparison with the respective standard homogeneous rank implementations. Notably, after integrating FlexLoRA, the average performance gains are 2.14% for FedAvg, 0.86% for FedIT, and 1.94% for SLoRA. These enhancements lend empirical support to our theoretical generalization analysis that clients utilizing higher LoRA ranks tend to exhibit improved generalization abilities. The most substantial performance improvements are observed in the heavy-tail-strong resource distribution, followed by the normal distribution. This is consistent with our expectations since the heavy-tail-strong distribution predominantly comprises clients with Type 4 LoRA configurations (rank 200). The limited presence of Type 1 clients (rank 8) in the normal distribution minimizes the risk of the global model being excessively influenced by task-specific LoRA weights. Therefore, FlexLoRA is able to leverage the heterogeneous resource distributions to boost the zero-shot generalization, and the gain from integrating FlexLoRA is directly related to the ratio of clients with heavy resources.

### Cross-Task Generalization

**Evaluation Setup.** To assess the natural language understanding capabilities of the FlexLoRA-enhanced global model, we evaluate its performance on a range of downstream NLP tasks. Specifically, the model is tested on the English Track of the evaluation tasks from , featuring 12 categories and 119 tasks. For each task, a random sample of 100 data points is chosen for testing. We

    &  &  &  \\   & FlexLoRA & HETLORA & FlexLoRA & HETLORA & FlexLoRA & HETLORA \\  Homo Rank &  &  &  \\  Uniform & **58.07 \(\) 0.27** & 56.85 \(\) 0.18 & **61.34 \(\) 1.09** & 60.74 \(\) 0.78 & **60.75 \(\) 0.60** & 60.74 \(\) 0.77 \\ Heavy-Tail-Light & **57.39 \(\) 0.54** & 56.24 \(\) 0.30 & **61.88 \(\) 0.89** & 61.53 \(\) 0.93 & **60.40 \(\) 0.40** & 59.97 \(\) 0.62 \\ Normal & **57.78 \(\) 0.33** & 56.50 \(\) 0.05 & **62.01 \(\) 0.91** & 61.03 \(\) 0.54 & **61.67 \(\) 1.07** & 61.14 \(\) 0.71 \\ Heavy-Tail-Strong & **57.73 \(\) 0.08** & 55.74 \(\) 0.93 & **62.20 \(\) 1.12** & 61.06 \(\) 0.95 & **61.86 \(\) 1.24** & 61.29 \(\) 0.95 \\   

Table 2: The weighted average Rouge-L scores of unseen clients provide insights into the global model’s generalization ability. Results from baseline methods with homogeneous ranks (Line 3, denoted as Homo Rank) are compared with those incorporating FlexLoRA and HETLORA across various resource distributions (Line 4\(\)7). The significant test are presented in Appendix F.

Figure 4: Task-specific improvements achieved by FlexLoRA in comparison with the homogeneous rank implementation of FedAvg, across different resource distribution settings.

summarize the average percentage improvement achieved by integrating FlexLoRA across different resource distributions in Table 3.

**Effect of Specific Resource Distributions.** In the majority of cases, the global models augmented with FlexLoRA demonstrate marked improvements over the vanilla implementations of FedAvg, FedIT, and SLoRA by up to 1.99%, suggesting that the FlexLoRA also improves the natural language analysis capabilities. An exception is noted in the SLoRA on the heavy-tail-light distribution, potentially due to the predominance of the Type 1 LoRA configuration (rank 8), which may limit the overall language processing capabilities when such clients are disproportionately represented. This configuration's minimal rank assignment across all linear layers suggests that the local weight aggregation on the server side might not fully leverage the capabilities of clients with larger resources, potentially detracting from the model's performance on certain tasks.

**Effect of Specific Language Tasks.** We further illustrate the task-specific improvements of integrating FlexLoRA in comparison with the standard FedAvg configuration for various resource distributions in Figure 4. The task-wise improvement figures for other FL methods are included in Appendix G. We observe that the global models trained using the FlexLoRA aggregation scheme generally outperform others on tasks requiring the parsing of logical relationships between sentences. Particularly, it gains improvements at most 4% in the overlap extraction task, and around 2.5% in the textual entailment, cause-effect classification, and dialogue act recognition task, verifying again the effectiveness of FlexLoRA.

### Aggregation Scheme Study

Figure 6: The sub-figure 6(a) shows that FedIT with LoRA rank 8 has comparable test loss curves for standard and FlexLoRA integration. At rank 200, though, standard FedIT differs from other versions. 6(b) depicts singular value distributions and approximation errors, where the red cross indicates the average error for rank 30 \(q_{proj}\) weights in specific blocks. Further details are in Appendix H.

    & FedAvg & FedIT & SLoRA & Avg \\  Uniform & 1.99\% & 0.97\% & 0.74\% & 1.23\% \\ Heavy-Tail (L) & 1.24\% & 0.63\% & -0.47\% & 0.47\% \\ Normal & 1.34\% & 0.75\% & 0.96\% & 1.02\% \\ Heavy-Tail (S) & 1.66\% & 0.95\% & 1.12\% & 1.24\% \\  Avg & 1.56\% & 0.83\% & 0.59\% & 1.00\% \\   

Table 3: Average percentage improvement of FlexLoRA over baseline methods (FedAvg, FedIT, SLoRA) across different resource distributions, calculated over 12 NLP task categories. More detailed comparison is presented in Figure 4.

**SVD on Convergence.** FlexLoRA's aggregation scheme constructs full-size LoRA weights before averaging, unlike the conventional FedAvg method's parameter-wise averaging. To understand the effect of this difference on model performance, we assess the performance of FlexLoRA in a controlled environment using homogeneous LoRA ranks and compare it to the standard FL aggregation scheme. Figure 6(a) presents the test loss trajectories for FedIT with and without the FlexLoRA enhancement, both utilizing a homogeneous rank of 8. The loss curves for the standard FedIT and FedIT with FlexLoRA closely align, suggesting comparable performance. In a nutshell, we empirically demonstrate that under homogeneous conditions, FlexLoRA's aggregation does not negatively impact model performance compared to traditional methods. Besides, it's worth noting that the test loss for FedIT with a homogeneous rank of 200 is significantly lower, underscoring the benefits of higher rank configurations and evidencing our Theorem 1.

**SVD v.s. LoRA Rank.** To gain further insight into the effect of SVD, we calculate and sort the singular values of the global LoRA weights from largest to smallest. We focus on specific layers where LoRA is applied within the transformer blocks 1, 8, and 14 (each block includes one attention layer and one FFN layer). Figure 6(b) displays the scale of singular values and the error ratio between the global LoRA weights approximated by the top \(i\) singular values and the full-rank global LoRA weights in the FedIT setting with a heavy-tail-strong resource distribution. The approximation error is quantified as the norm of the difference between the approximated and full-rank weights. The error curves for \(q_{proj}\) layers across all transformer blocks nearly overlap. With the weight approximated from the top 30 ranks, the error ratio is as low as 0.16, suggesting the approximated weights are in close proximity to the actual full-rank weights, lending empirical support to our Assumption 2.

### Scalability Study

**Larger Model Size and Lower Degree of Task Heterogeneity.** While the aforementioned experiments with 1.3B LLM and meta-task dataset split effectively showcases FlexLoRA's capabilities against baselines in a highly heterogeneous cross-device environment, real-world settings may be relaxed involving fewer clients with a mixture of tasks and larger LLM. To better evaluate FlexLoRA's performance in such scenarios, we expanded our study to include settings where each client manages not just one specific "meta" task but a variety of different tasks. We use Dolly-15K dataset , which supports instruction tuning and includes 8 tasks in total. We distributed this dataset among 200 clients using a Dirichlet distribution with \(=0.5\) to simulate the non-IID data distributions. Moreover, we also incorporate the most cutting-edge LLaMA-3  with 8B parameter size as our foundation model to assess FlexLoRA's effectiveness with advanced, larger-scale models.

Table 12 in Appendix I illustrates FlexLoRA's efficacy under both smaller and larger foundation models within the mixture of task settings. Compared with LLaMA-3 (8B), finetuning on DataJucier(1.3B) demonstrates more generalization improvement for unseen clients. This enhanced performance when using the smaller DataJucier model suggests that FlexLoRA is particularly effective for foundation models that are scalable to edge devices. Such ability is instrumental in maximizing the utility and efficiency of smaller models in resource-constrained environments.

**System Costs.** We empirically demonstrate that increasing the rank improves overall efficiency. The experiment is conducted on the Dolly 15K dataset and the DataJucier 1.3B model, with the same FL setting as Table 12. We summarize the results in Table 4, where the "\(R\)" indicates the number of rounds to reach a loss of 2, approximately 75% progress to convergence. The "\(Cost_{R}\)" stands for per-round FL cost in terms of the average model parameters compared with the foundation model parameters, as both the local training and communication cost positively correlated to the rank value in FlexLoRA (as analyzed in Sec. 3.3). The "\(Cost_{all}\)" indicates total cost calculated as multiply of \(R\) and \(Cost_{R}\), and by setting the result of "Homo Rank" as the baseline. From the results, we can see that FlexLoRA achieves faster convergence with slightly increased parameter percentages under heterogeneous resource distributions. For the overall efficiency, "Heavy-Tail-Light" has a total reduction of 49.4%, and "Uniform" has 66.9%, indicating good scalability of FlexLoRA.

    & \(R\) & \(Cost_{R}\) & \(Cost_{all}\) \\  Homo Rank & 48 & 1.001x & \(\) 100\% \\ Heavy-Tail (L) & 24 & 1.014x & \(\) 50.6\% \\ Uniform & 15 & 1.061x & \(\) 33.1\% \\   

Table 4: Convergence round and FL cost per round for different LoRA ranks.

**Effect of Larger Client Number.** We designed an experiment to empirically validate Theorem 1 and demonstrate how FlexLoRA performs with varied client numbers. We use subsets of 10, 50, and 100 clients from a pool of 200 clients on Dolly-15K dataset and DataJuicer (1.3B), with FedAvg as baseline FL method and each FL round always sampling 10 participants. From Figure 5, there is a marked improvement in generalization as the number of participating clients increases. Moreover, from Theorem 1, we can derive the functional relationship between client number \(|C|\) and the generalization loss \(\) as \(|C|=A_{1}/^{2}(A_{2}-log(-A_{3}))\), where \(A_{1,2,3}\) are constants absorbing the other factors impacted by specific resource distribution in this experiment. We thus fit these coefficients using the derived form and empirical observations, and find that the dotted curves gain good fitness for all the tested distributions. There results affirm the preciseness of our Theorem 1 again, indicating the suitableness of FlexLoRA for cross-device FL scenarios where leveraging a broad client pool can boost the generalization across diverse data distributions.

## 5 Conclusion

In this work, we propose a simple yet effective method named FlexLoRA to address the challenges posed by resource and data heterogeneity among clients during the federated fine-tuning of LLMs. By leveraging larger local LoRA ranks, FlexLoRA not only improves the generalization ability of the global model but also ensures that all clients, irrespective of their resource capabilities, can contribute meaningfully. Theoretical analysis and extensive experiments verify the effectiveness and scalability of FlexLoRA. Due to resource limitations, we have not tested the LLaMA-3 model on thousands-client scenarios, which we leave as future work. We hope this study can enlighten more future research and development in data-efficient and privacy-preserving enhancement of LLMs.