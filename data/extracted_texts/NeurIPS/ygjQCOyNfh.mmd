# Uncertainty Quantification over Graph with

Conformalized Graph Neural Networks

Kexin Huang\({}^{1}\)  Ying Jin\({}^{2}\)  Emmanuel Candes\({}^{2,3}\)  Jure Leskovec\({}^{1}\)

\({}^{1}\) Department of Computer Science, Stanford University

\({}^{2}\) Department of Statistics, Stanford University

\({}^{3}\) Department of Mathematics, Stanford University

kexinh@cs.stanford.edu, ying531@stanford.edu,

candes@stanford.edu, jure@cs.stanford.edu

###### Abstract

Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the prediction and produces more efficient prediction sets/intervals. Extensive experiments show that CF-GNN achieves any pre-defined target marginal coverage while significantly reducing the prediction set/interval size by up to 74% over the baselines. It also empirically achieves satisfactory conditional coverage over various raw and network features.

## 1 Introduction

Graph Neural Networks (GNNs) have shown great potential in learning representations for graph-structured data, which has led to their widespread adoption in weather forecasting , drug discovery , and recommender systems , etc. As GNNs are increasingly deployed in high-stakes settings, it is important to understand the uncertainty in the predictions they produce. One prominent approach to uncertainty quantification is to construct a prediction set/interval that informs a plausible range of values the true outcome may take. A large number of methods have been proposed to achieve this goal [17; 49; 28; 44]. However, these methods often lack theoretical and empirical guarantees regarding their validity, i.e. the probability that the prediction set/interval covers the outcome . This lack of rigor hinders their reliable deployment in situations where errors can be consequential.

Conformal prediction  (CP) is a framework for producing statistically guaranteed uncertainty estimates. Given a user-specified miscoverage level \((0,1)\), it leverages a set of "calibration" data to output prediction sets/intervals for new test points that provably include the true outcome with probability at least \(1-\). Put another way, the conformal prediction sets provably only miss the test outcomes at most \(\) fraction of the time. With its simple formulation, clear guarantee anddistribution-free nature, it has been successfully applied to various problems in computer vision [2; 4], causal inference [30; 22; 47], time series forecasting [11; 48], and drug discovery .

Despite its success in numerous domains, conformal prediction has remained largely unexplored in the context of graph-structured data. One primary challenge is that it is unclear if the only, yet crucial, assumption for CP--exchangeability between the test and calibration samples--holds for graph data. When applying conformal prediction, exchangeability is usually ensured by independence among the trained model, the calibration data, and test samples (see Appendix B for more discussion). However, in the transductive setting, GNN training employs all nodes within the same graph-including test points-for message passing, creating intricate dependencies among them. Thus, to deploy conformal prediction for graph data, the first challenge is to identify situations where valid conformal prediction is possible given a fitted GNN model that already involves test information.

Efficiency is another crucial aspect of conformal prediction for practical use: a prediction set/interval with an enormous set size/interval length might not be practically desirable even though it achieves valid coverage. Therefore, the second major challenge is to develop a graph-specific approach to reduce the size of the prediction set or the length of the prediction interval (dubbed as _inefficiency_ hereafter for brevity) while retaining the attractive coverage property of conformal prediction.

**Present work.** We propose conformalized GNN (CF-GNN),1 extending conformal prediction to GNN for rigorous uncertainty quantification over graphs. We begin by establishing the validity of conformal prediction for graphs. We show that in the transductive setting, regardless of the dependence among calibration, test, and training nodes, standard conformal prediction  is valid as long as the score function (whose definition will be made clear in Section 2) is invariant to the ordering of calibration and test samples. This condition is easily satisfied by popular GNN models. Furthermore, we provide an exact characterization of the empirical test-time coverage.

Subsequently, we present a new approach that learns to optimize the inefficiencies of conformal prediction. We conduct an empirical analysis which reveals that inefficiencies are highly correlated along the network edges. Based on this observation, we add a topology-aware correction model that updates the node predictions based on their neighbors. This model is trained by minimizing a differentiable efficiency loss that simulates the CP set sizes/interval lengths. In this way, unlike the raw prediction that is often optimized for prediction accuracy, the corrected GNN prediction is optimized to yield smaller/shorter conformal prediction sets/intervals. Crucially, our approach aligns with the developed theory of graph exchangeability, ensuring valid coverage guarantees while simultaneously enhancing efficiency.

We conduct extensive experiments across 15 diverse datasets for both node classification and regression with 8 uncertainty quantification (UQ) baselines, covering a wide range of application domains. While all previous UQ methods fail to reach pre-defined target coverage, CF-GNN achieves the pre-defined empirical marginal coverage. It also significantly reduces the prediction set sizes/interval lengths by up to 74% compared with a direct application of conformal prediction to GNN. Such improvement in efficiency does not appear to sacrifice adaptivity: we show that CF-GNN achieves strong empirical conditional coverage over various network features.

## 2 Background and Problem Formulation

Let \(G=(,,)\) be a graph, where \(\) is a set of nodes, \(\) is a set of edges, and \(=\{_{v}\}_{v}\) is the attributes, where \(_{v}^{d}\) is a \(d\)-dimensional feature vector for node \(v\). The label of node \(v\) is \(y_{v}\). For classification, \(\) is the discrete set of possible label classes. For regression, \(=\).

**Transductive setting.** We focus on transductive node classification/regression problems with random data split. In this setting, the graph \(G\) is fixed. At the beginning, we have access to \(\{(_{v},y_{v})\}_{v}\) as the "training" data, as well as test data \(_{}\) with unknown labels \(\{y_{v}\}_{v_{}}\). Here \(\) and \(_{}\) are disjoint subsets of \(\). We work on the prevalent random split setting where nodes in \(\) and \(_{}\) are randomly allocated from the entire graph, and the test sample size is \(m=|_{}|\). The training node set \(\) is then randomly split into \(_{}/_{}/_{}\) of fixed sizes, the training/validation/calibration set, correspondingly. A perhaps nonstandard point here is that we withhold a subset \(_{}\) as "calibration" data in order to apply conformal prediction later on. During the training step, the data \(\{(_{v},y_{v})\}_{v_{}_{ }}\), the attribute information in \(\{_{v}\}_{v_{}_{}}\) and the entire graph structure \((,)\) are available to the GNN to compute training nodes representations, while \(\{y_{v}\}_{v_{}_{}}\) are not seen.

**Graph Neural Networks (GNNs).** GNNs learn compact representations that capture network structure and node features. A GNN generates outputs through a series of propagation layers , where propagation at layer \(l\) consists of the following three steps: (1) Neural message passing. GNN computes a message \(_{uv}^{(l)}=(_{u}^{(l-1)},_{v}^{(l- 1)})\) for every linked nodes \(u,v\) based on their embeddings from the previous layer \(_{u}^{(l-1)}\) and \(_{v}^{(l-1)}\). (2) Neighborhood aggregation. The messages between node \(u\) and its neighbors \(_{u}\) are aggregated as \(}_{u}^{(l)}=(_{u}^{(l)}|v _{u})\). (3) Update. Finally, GNN uses a non-linear function to update node embeddings as \(_{u}^{(l)}=(}_{u}^{(l)},_ {u}^{(l-1)})\) using the aggregated message and the embedding from the previous layer. The obtained final node representation is then fed to a classifier or regressor to obtain a prediction \((X)\).

**Conformal prediction.** In this work, we focus on the computationally efficient split conformal prediction method .2 Given a predefined miscoverage rate \(\), it proceeds in three steps: (1) non-conformity scores. CP first obtains any heuristic notion of uncertainty called non-conformity score \(V\). Intuitively, \(V(x,y)\) measures how \(y\) "conforms" to the prediction at \(x\). An example is the predicted probability of a class \(y\) in classification or the residual value \(V(x,y)=|y-(x)|\) in regression for a predictor \(\). (2) Quantile computation. CP then takes the \(1-\) quantile of the non-conformity scores computed on the calibration set. Let \(\{(X_{i},Y_{i})\}_{i=1}^{n}\) be the calibration data, where \(n=|_{}|\), and compute \(=(\{V(X_{1},Y_{1}),,V(X_{n},Y_{n})\},(1- )(1+))\). (3) Prediction set/interval construction. Given a new test point \(X_{n+1}\), CP constructs a prediction set/interval \(C(X_{n+1})=\{y:V(X_{n+1},y)\}\). If \(\{Z_{i}\}_{i=1}^{n+1}:=\{(X_{i},Y_{i})\}_{i=1}^{n+1}\) are exchangeable,3 then \(V_{n+1}:=V(X_{n+1},Y_{n+1})\) is exchangeable with \(\{V_{i}\}_{i=1}^{n}\) since \(\) is given. Thus, \((X_{n+1})\) contains the true label with predefined coverage rate : \(P\{Y_{n+1} C(X_{n+1})\}=\{V_{n+1}(\{V_{1}, ,V_{n+1}\},1-) 1-\) due to exchangeability of \(\{V_{i}\}_{i=1}^{n+1}\). This framework works for any non-conformity score-agnostic. However, for demonstration, we focus on two popular scores, described in detail below.

**Adaptive Prediction Set (APS).** For the classification task, we use the non-conformity score in APS proposed by . It takes the cumulative sum of ordered class probabilities till the true class. Formally, given any estimator \(_{j}(x)\) for the conditional probability of \(Y\) being class \(j\) at \(X=x\), \(j=1,,||\), we denote the cumulative probability till the \(k\)-th most promising class as \(V(x,k)=_{j=1}^{k}_{_{(j)}}(x)\)

Figure 1: Conformal prediction for graph-structured data. (1) GNN training. We first use standard GNN training to obtain a base GNN model (\(_{}\)) that produces prediction scores \((X_{i})\) for node \(i\). It is fixed once trained. (2) Conformal correction. Since the training step is not aware of the conformal calibration step, the size/length of prediction sets/intervals (i.e. efficiency) are not optimized. We propose a novel correction step that learns to correct the prediction to achieve desirable properties such as efficiency. We use a topology-aware correction model \(_{}\) that takes \((X_{i})\) as the input node feature and aggregates information from its local subgraph to produce an updated prediction \((X_{i})\). \(\) is trained by simulating the conformal prediction step and optimizing a differentiable inefficiency loss. (3) Conformal prediction. We prove that in a transductive random split setting, graph exchangeability holds (Section 3) given permutation invariance. Thus, standard CP can be used to produce a prediction set/interval based on \(\) that includes true label with pre-specified coverage rate 1-\(\).

where \(\) is a permutation of \(\) so that \(_{(1)}(x)_{(2)}(x) _{(||)}(x)\). Then, the prediction set is constructed as \(C(x)=\{(1),,(k^{*})\}\), where \(k^{*}=\{k:_{j=1}^{k}_{(j)}(x)\}\).

**Conformalized Quantile Regression (CQR).** For the regression task, we use CQR in . CQR is based on quantile regression (QR). QR obtains heuristic estimates \(_{/2}(x)\) and \(_{1-/2}(x)\) for the \(/2\)-th and \(1-/2\)-th conditional quantile functions of \(Y\) given \(X=x\). The non-conformity score is \(V(x,y)=\{_{/2}(x)-y,y-_{1-/2}(x)\}\), interpreted as the residual of true label projected to the closest quantile. The prediction interval is then \(C(x)=[_{/2}(x)-,_{1-/2}(x )+]\).

In its vanilla form, the non-conformity score (including APS and CQR) in CP does not depend on the calibration and test data. That means, \(\{_{v}\}_{v_{}_{}}\) are not revealed in the training process of \(V\), which is the key to exchangeability. In contrast, GNN training typically leverages the entire graph, and hence the learned model depends on the calibration and test attributes in a complicated way. In the following, for clarity, we denote any non-conformity score built on a GNN-trained model as

\[V(x,y;\{z_{v}\}_{v_{}_{}}, \{_{v}\}_{v_{}_{ }},,)\]

to emphasize its dependence on the entire graph, where \(z_{v}=(_{v},Y_{v})\) for \(v\).

**Evaluation metrics.** The goal is to ensure valid marginal coverage while decreasing the inefficiency as much as possible. Given the test set \(_{}\), the empirical marginal coverage is defined as \(:=_{}|}_{i_ {}}(Y_{i} C(X_{i}))\). For the regression task, inefficiency is measured as the interval length while for the classification task, the inefficiency is the size of the prediction set: \(:=_{}|}_{i_{ }}|C(X_{i})|\). The larger the length/size, the more inefficient. Note that inefficiency of conformal prediction is different from accuracy of the original predictions. Our method does not change the trained prediction but modifies the prediction sets from conformal prediction.

## 3 Exchangeability and Validity of Conformal Prediction on Graph

To deploy CP for graph-structured data, we first study the exchangeability of node information under the transductive setting. We show that under a general permutation invariant condition (Assumption 1), exchangeability of the non-conformity scores is still valid even though GNN training uses the calibration and test information; this paves the way for applying conformal prediction to GNN models. We develop an exact characterization of the test-time coverage of conformal prediction in such settings. Proofs of these results are in Appendix A.1.

**Assumption 1**.: _For any permutation \(\) of \(_{}_{}\), the non-conformity score \(V\) obeys_

\[V(x,y;\{z_{v}\}_{v_{}_{ }},\{_{v}\}_{v_{}_{}},,)\] \[=V(x,y;\{z_{v}\}_{v_{}_{ }},\{_{(v)}\}_{v_{} _{}},_{},_{}),\]

_where \((_{},_{})\) represents a graph where \(_{}_{}\) nodes (indices) are permuted according to \(\)._

Assumption 1 imposes a permutation invariance condition for the GNN training, i.e., model output/non-conformity score is invariant to permuting the ordering of the calibration and test nodes (with their edges permuted accordingly) on the graph. To put it differently, different selections of calibration sets do not modify the non-conformity scores for any node in the graph. GNN models (including those evaluated in our experiments) typically obey Assumption 1, because they only use the structures and attributes in the graph without information on the ordering of the nodes [24; 16; 12].

For clarity, we write the calibration data as \(\{(X_{i},Y_{i})\}_{i=1}^{n}\), where \(X_{i}=X_{v_{i}}\), and \(v_{i}_{}\) is the \(i\)-th node in the calibration data under some pre-defined ordering. Similarly, the test data are \(\{(X_{n+j},Y_{n+j})\}_{j=1}^{m}\), where \(X_{n+j}=X_{v_{j}}\), and \(v_{j}_{}\) is the \(j\)-th node in the test data. We write

\[V_{i}=V(X_{i},Y_{i};\{z_{i}\}_{i_{}_{ }},\{_{v}\}_{v_{}_{}},,), i=1,,n,n+1,,n+m.\]

\(V_{i}\) is a random variable that depends on the training process and the split of calibration and test data. The next lemma shows that under Assumption 1, the non-conformity scores are still exchangeable.

**Lemma 2**.: _In the transductive setting described in Section 2, conditional on the entire unordered graph \((,)\), all the attribute and label information \(\{(_{v},y_{v})_{v}\), and the index sets \(_{}\) and \(_{ct}:=_{}_{}\), the unordered set of the scores \([V_{i}]_{i=1}^{m}\) are fixed. Also, the calibration scores \(\{V_{i}\}_{i=1}^{n}\) are a simple random sample from \(\{V_{i}\}_{i=1}^{n+m}\). That is, for any subset \(\{v_{1},,v_{n}\}\{V_{i}\}_{i=1}^{n+m}\) of size \(n\), \(P(\{V_{i}\}_{i=1}^{n}=\{v_{1},,v_{n}\}\,\,\{V_{i}\}_{i=1}^{n+m})=1/ _{}|}\)._Based on Lemma 2, we next show that any permutation-invariant non-conformity score leads to valid prediction sets, and provide an exact characterization of the distribution of test-time coverage.

**Theorem 3**.: _Given any score \(V\) obeying Assumption 1 and any confidence level \((0,1)\), we define the split conformal prediction set as \((x)=\{y V(x,y)\},\) where_

\[=_{i=1}^{n}\{V( X_{i},Y_{i})\}(1-)(1+1/n)}.\]

_Then \((Y_{n+j}(X_{n+j})) 1-,\)\(\,j=1,,m\). Moreover, define \(}=_{j=1}^{m}\{Y_{n+j} (X_{n+j})\}\). If the \(V_{i}\)'s, \(i_{}_{}\), have no ties almost surely, then for any \(t(0,1)\),_

\[} t=1-_{}(n+1)(1-q)-1;m+n,n,(1-q)(n+1)+ mt ,\]

_where \(_{}(;N,n,k)\) denotes the cumulative distribution function of a hyper-geometric distribution with parameters \(N,n,k\) (drawing \(k\) balls from an urn wherein \(n\) out of \(N\) balls are white balls)._

Figure 2 plots the probability density functions (p.d.f.) of \(}\) at a sequence of \(t\) fixing \(n=1000\) while varying \(m\). The exact distribution described in Theorem 3 is useful in determining the size of the calibration data in order for the test-time coverage to concentrate sufficiently tightly around \(1-\). More discussion and visualization of \(}\) under different values of \((n,m)\) are in Appendix A.2. Note that similar exchangeability and validity results are obtained in several concurrent works [15; 33], yet without exact characterization of the test-time coverage.

## 4 CF-GNN: Conformalized Graph Neural Networks

We now propose a new method called CF-GNN to reduce inefficiency while maintaining valid coverage. The key idea of CF-GNN is to boost any given non-conformity score with graphical information. The method illustration is in Figure 1 and pseudo-code is in Appendix C.

**Efficiency-aware boosting.** Standard CP takes any pre-trained predictor to construct the prediction set/interval (see Section 2). A key observation is that the training stage is not aware of the post-hoc stage of conformal prediction set/interval construction. Thus, it is not optimized for efficiency. Our high-level idea is to include an additional correction step that boosts the non-conformity score, which happens after the model training and before conformal prediction. To ensure flexibility and practicality, our framework is designed as a generic wrapper that works for any pre-trained GNN model, without changing the base model training process.

**Motivation: Inefficiency correlation.** Our approach to boosting the scores is based on exploiting the correlation among connected nodes. Since the connected nodes usually represent entities that interact in the real world, there can be strong correlation between them. To be more specific, it is well established in network science that prediction residuals are correlated along edges . Such a result implies a similar phenomenon for inefficiency: taking CQR for regression as an example, the prediction interval largely depends on the residual of the true outcome from the predicted quantiles. Hence, the prediction interval lengths are also highly correlated for connected nodes. We empirically verify this intuition in Figure 3, where we plot the difference in the prediction interval lengths for connected/unconnected node pairs in the Anaheim dataset using vanilla CQR for GCN.4 In Figure 3, we observe that inefficiency has a topological root: connected nodes usually have similar residual scales, suggesting the existence of rich neighborhood information for the residuals. This motivates us to utilize such information to correct the scores and achieve better efficiency.

**Topology-aware correction model.** Based on the motivation above, we update the model predictions using the neighbor predictions. However, the relationship in neighborhood predictions could be complex (i.e. beyond homophily), making heuristic aggregation such as averaging/summing/etc. overly simplistic and not generalizable to all types of graphs. Ideally, we want to design a general and powerful mechanism that flexibly aggregates graph information. This requirement could be perfectly

Figure 2: P.d.f. of \(}\) for \(n=1000\) and \(=0.05\); curves represent different values of test sample size \(m\).

fulfilled by GNN message passing as it represents a class of learnable aggregation functions over graphs. Therefore, we use a separate \(\) learner parameterized by \(\) for the same network \(G\) but with modified input node features; specifically, we use the base GNN prediction (\(_{0}=(X)\)) as input, and output \((X)=_{}((X),G)\). We will then use \((X)\) as the input for constructing conformal prediction sets/intervals. Note that this second GNN model is a post-hoc process and only requires base GNN predictions, instead of access to the base GNN model.

**Training with conformal-aware inefficiency loss.** Given the hypothesis class, it remains to devise a concrete recipe for training the correction model \(_{}\) parameters. Recall that as with many other prediction models, a GNN model is typically trained to optimize prediction loss (i.e.cross-entropy loss or mean squared error) but not geared towards efficiency for the post-hoc conformal prediction step. We design \(_{}\) to be efficiency-aware by proposing a differentiable inefficiency loss that \(_{}\) optimizes over; this allows integration of GNN message passing to exploit the neighborhood information and also ensures a good \(()\) that leads to efficient prediction sets in downstream steps.

We first withhold a small fraction \(\) of the calibration dataset and use it for the correction procedure. The remaining data is used as the "usual" calibration data for building the conformal prediction set. We then further split the withheld data into a correction calibration set \(_{}\) and correction testing set \(_{}\), to simulate the downstream conformal inference step. Given \((X)=_{}((X),G)\) and a target miscoverage rate \(\), the framework follows three steps:

(1)Differentiable quantile: we compute a smooth quantile \(\) based on the \(_{}\) by

\[=(\{V(X_{i},Y_{i})|i_{}\},(1-)(1+1/|_{}|).\]

Since the non-conformity score is usually differentiable, it only requires differentiable quantile calculation where there are well-established methods available .

(2)Differentiable inefficiency proxy: we then construct a differentiable proxy \(\) of the inefficiency on \(_{}}\) by simulating the downstream conformal prediction procedures. We propose general formulas to construct \(\) that are applicable for any classification and regression tasks respectively:

_a. Inefficiency loss instantiation for Classification_: The desirable proxy is to simulate the prediction set size using \(_{}\) as the "test" data and \(_{}\) as the "calibration" data. For class \(k\) and node \(i\) in \(_{}\), the non-conformity score is \(V(X_{i},k)\) for class \(k\), where \(V()\), for instance, is the APS score in Section 2. Then, we define the inefficiency proxy as

\[_{i,k}=(,k)-}{}),\]

where \((x)=}\) is the sigmoid function and \(\) is a temperature hyper-parameter . It can be interpreted as a soft assignment of class \(k\) to the prediction set. When \( 0\), it becomes a hard assignment. The per-sample inefficiency proxy is then readily constructed as \(_{i}=|}_{k}_{i,k}\).

_b. Inefficiency loss instantiation for Regression_: The desirable proxy is to simulate the prediction interval length. For node \(i\) in \(_{}\), the conformal prediction interval is \([_{/2}(X_{i})-,_{1-/2}(X_{i}) +]\). Thus, the per-sample prediction interval length could be directly calculated as

\[_{i}=(_{1-/2}(X_{i})+)-( _{/2}(X_{i})-).\]

Figure 4: We simulate the downstream conformal step and optimize for inefficiency directly. We first produce differentiable quantile \(\) using \(V(X_{i},Y_{i})\) from \(_{}\). We then construct a prediction set size/interval length proxy on \(_{}\) and directly minimize inefficiency loss by updating \(_{}\).

Figure 3: Inefficiency is correlated in the network. Connected nodes have significantly smaller gaps in prediction interval length compared to unconnected nodes.

Since \(_{}\) maps intervals to intervals and do not pose a constraint on the prediction, it may incur a trivial optimized solution where \(_{1-/2}(X)<_{/2}(X)\). Thus, we pose an additional consistency regularization term: \((_{1-/2}(X)-_{1-/2}(X))^{2}+(_{ /2}(X)-_{/2}(X))^{2}\). This regularizes the updated intervals to not deviate significantly to reach the trivial solution.

(3) Inefficiency loss: finally, the inefficiency loss is an average of inefficiency proxies \(L_{}=_{}|}_{i}_{i}\). The \(_{}\) is optimized using backpropagation in an end-to-end fashion.

**Conditional coverage.** A natural question is whether optimizing the efficiency of conformal prediction may hurt its conditional validity.5 In Section 5, we empirically demonstrate satisfactory conditional coverage across various graph features, which even improves upon the direct application of APS and CQR to graph data. We conjecture that it is because we correct for the correlation among nodes. However, theoretical understanding is left for future investigation.

**Graph exchangeability.** The post-hoc correction model is \(\)-based, thus, it is permutation-invariant. Thus, it satisfies the exchangeability condition laid out in our theory in Section 3. Empirically, we demonstrate in Section 5 that CF-GNN achieves target empirical marginal coverage.

**Computational cost.** We remark that CF-GNN scales similarly as base GNN training since the correction step follows a standard GNN training procedure but with a modified input attribute and loss function. Notably, as the input to the correction model usually has a smaller attribute size (the number of classes for classification and 2 for regression), it has smaller parameter size than standard GNN training. In addition, it is also compatible with standard GNN mini-batching techniques.

**General loss functions.** Finally, we note that the choice of our loss function can be quite general. For instance, one may directly optimize for conditional validity by choosing a proper loss function.

## 5 Experiments

We conduct experiments to demonstrate the advantages of CF-GNN over other UQ methods in achieving empirical marginal coverage for graph data, as well as the efficiency improvement with CF-GNN. We also evaluate conditional coverage of CF-GNN and conduct systematic ablation and parameter analysis to show the robustness of CF-GNN.

**Evaluation setup.** For node classification, we follow a standard semi-supervised learning evaluation procedure , where we randomly split data into folds with 20%/10%/70% nodes as \(_{}/_{}/_{ }_{}\). For the node regression task, we follow a previous evaluation procedure from  and randomly split the data into folds with 50%/10%/40% nodes as \(_{}/_{}/_{ }_{}\). We conduct 100 random splits of calibration/testing sets to estimate the empirical coverage. Using the test-time coverage distribution in Figure 2 to ensure that coverage is concentrated tightly around 1-\(\), we modify the calibration set size to \(\{1000,\,|_{}_{}|/2\}\), and use the rest as the test sample. For a fair comparison, we first train 10 runs of the base GNN model and then fix the predictions (i.e. the input to UQ baselines and CF-GNN). In this way, we ensure that the gain is not from randomness in base model training. The hyperparameter search strategy and configurations for CF-GNN and baselines can be found in Appendix D.1.

**Models & baselines to evaluate coverage.** For classification, we first use general statistical calibration approaches including temperate scaling , vector scaling , ensemble temperate scaling . We also use SOTA GNN-specific calibration learners including CaGCN  and GATS . The prediction set is the set of classes from highest to lowest scores until accumulative scores exceed 1-\(\). For regression, we construct prediction intervals using quantile regression (QR) , Monte Carlo dropouts (MC dropout) , and Bayesian loss to model both aleatoric and epistemic uncertainty . More information about baselines can be found in Appendix D.2.

**Models & baselines to evaluate efficiency.** As smaller coverage always leads to higher efficiency, for a fair comparison, we can only compare methods on efficiency that achieve the same coverage. Thus, we do not evaluate UQ baselines here since they do not produce exact coverage and are thus not comparable. While any CP-based methods produce exact coverage, to the best of our knowledge,

[MISSING_PAGE_FAIL:8]

coefficients, betweenness, PageRank, closeness, load, and harmonic centrality, and then calculate the WS coverage over the network feature space. We observe close to 95% WS coverage for various network features, suggesting CF-GNN also achieves robust conditional coverage over network properties. We also see that the direct application of CP (i.e. without graph correction) has much smaller WS coverage for classification, suggesting that adjusting for neigborhood information in CF-GNN implicitly improves conditional coverage.

**Ablation.** We conduct ablations in Table 4 to test two main components in CF-GNN, topology-aware correction model, and inefficiency loss. We first remove the inefficiency loss and replace it with standard prediction loss. The performance drops as expected, showing the power of directly modeling inefficiency loss in the correction step. Secondly, we replace the GNN correction model with an MLP correction model. The performance drops significantly, showing the importance of the design choice of correction model and justifying our motivation on inefficiency correlation over networks.

**Parameter analysis.** We conduct additional parameter analysis to test the robustness of CF-GNN. We first adjust the target coverage rate and calculate the inefficiency (Figure 5(1)). CF-GNN consistently beats the vanilla CP across all target coverages. Moreover, we adjust the fraction \(\) of the holdout calibration data in building the inefficiency loss, and observe that CF-GNN achieves consistent improvement in inefficiency (Figure 5(2)). We also observe a small fraction (10%) leads to excellent performance, showing that our model only requires a small amount of data for the inefficiency loss and leaves the majority of the calibration data for downstream conformal prediction.

## 6 Related Works

We discuss here related works that are closest to the ideas in CF-GNN and provide extended discussion on other related works in Appendix E.

(1) Uncertainty quantification (UQ) for GNN: Many UQ methods have been proposed to construct model-agnostic uncertain estimates for both classification [13; 49; 14; 27; 1] and regression [25; 41;

   Task & Dataset & CP & \(\)CF-GNN \\   & Anaheim & \(2.89.9^{-25.0075}_{-2.004}\),\(2.17.11\) \\  & Chicago & \(2.05.9^{-0.4875}_{-2.004}\),\(2.04.17\) \\  & Education & \(2.56.0^{-0.0775}_{-2.005}\),\(2.43.05\) \\  & Election & \(0.90.0^{+0.2175}_{-0.090}\),\(0.90.02\) \\  & Income & \(2.51.12^{-4.5057}_{-2.005}\),\(2.40.05\) \\  & Unemploy & \(2.72.0^{-10.8375}_{-2.004}\) \\  & Twitch & \(2.43.1^{-1.3697}_{-2.39}\) \\  Average Improvement & & \(\)6.73\% \\   

Table 4: Ablation. For Size/length, we use Cora/Anahelim dataset with GCN backbone. Each experiment is with 10 independent base model runs with 100 conformal split runs.

   Task & Dataset & CP & \(\)CF-GNN \\   & Cora & \(3.80.2^{-5.615}_{-5.176}\),\(1.76.27\) \\  & DBLP & \(2.43.0^{-0.135}_{-0.135}\),\(1.23.01\) \\  & CiteSeer & \(3.86.1^{-7.2475}_{-0.099.02}\) \\  & PubMed & \(1.60.2^{-10.057}_{-0.058}\),\(1.29.03\) \\  & Computers & \(3.56.1^{-0.095}_{-0.057}\),\(1.81.12\) \\  & Photo & \(3.79.3^{-0.256}_{-0.166}\),\(1.66.21\) \\  & CS & \(7.79.3^{-0.262}_{-0.267}\),\(2.95.49\) \\  & Physics & \(3.11.0^{-0.262}_{-0.257}\),\(1.66.13\) \\   & \(\)53.75\% \\   

Table 2: Empirical inefficiency measured by the size/length of the prediction set/interval for node classification (left table)/regression/right table). A smaller number has better efficiency. We show the relative improvement (%) of CF-GNN over CP on top of the \(\). The result uses APS for classification and CQR for regression with GCN as the base model. Additional results on other GNN models are at Appendix D.4. We report the average and standard deviation of prediction sizes/lengths calculated from 10 GNN runs, each with 100 calibration/test splits.

   Target \(0.95\) &  &  \\  Model & CP & CF-GNN & CP & CF-GNN \\  Marginal Cov. & \(0.95.01\) & \(0.95.01\) & \(0.96.02\) & \(0.96.02\) \\  Cond. Cov. (Input Feat.) & \(0.94.02\) & \(0.94.03\) & \(0.95.04\) & \(0.94.05\) \\  Cond. Cov. (Cluster) & \(0.89.06\) & \(0.93.04\) & \(0.96.03\) & \(0.96.03\) \\ Cond. Cov. (Between) & \(0.81.06\) & \(0.95.03\) & \(0.94.05\) & \(0.94.05\) \\ Cond. Cov. (PageRank) & \(0.78.06\) & \(0.94.03\) & \(0.94.05\) & \(0.94.05\) \\   

Table 3: CF-GNN achieves conditional coverage, measured by Worse-Slice Coverage . We use Cora/Twitch as an example classification/regression dataset. Results on other network features and results on target coverage of 0.9 can be found in Appendix D.6.

38; 9; 28; 26; 35; 23; 19]. Recently, specialized calibration methods for GNNs that leverage network principles such as homophily have been developed [44; 17]. However, these UQ methods can fail to provide a statistically rigorous and empirically valid coverage guarantee (see Table 1). In contrast, CF-GNN achieves valid marginal coverage in both theory and practice.

(2) Conformal prediction for GNN: The application of CP to graph-structured data remains largely unexplored.  claims that nodes in the graph are not exchangeable in the inductive setting and employs the framework of  to construct prediction sets using neighborhood nodes as the calibration data for mitigating the miscoverage due to non-exchangeability. In contrast, we study the transductive setting where certain exchangeability property holds; thus, the method from  are not comparable to ours. Concurrent with our work,  studies the exchangeability under transductive setting and proposes a diffusion-based method for improving efficiency, which can be viewed as an instantiation of our approach where the GNN correction learns an identity mapping;  studies exchangeability in network regression for of non-conformity scores based on various network structures, with similar observations as our Theorem 3. Other recent efforts in conformal prediction for graphs include [32; 34] which focus on distinct problem settings.

(3) Efficiency of conformal prediction: How to achieve desirable properties beyond validity is an active topic in the CP community; we focus on the efficiency aspect here. One line of work designs "good" non-conformity scores in theory such as APS  and CQR . More recent works take another approach, by modifying the training process of the prediction model. CF-GNN falls into the latter case, although our idea applies to any non-conformity score. ConfTr  also modifies training for improved efficiency. Our approach differs from theirs in significant ways. First, we develop a theory on CP validity on the graph data and leverage topological principles that are specialized to graph to improve efficiency while ConfTr focuses on i.i.d. vision image data. Also, ConfTr happens during base model training using the training set, while CF-GNN conducts post-hoc correction using withheld calibration data without assuming access to base model training, making ConfTr not comparable to us. Finally, we also propose a novel loss for efficiency in regression tasks.

## 7 Conclusion

In this work, we extend conformal prediction to GNNs by laying out the theoretical conditions for finite-sample validity and proposing a flexible graph-based CP framework to improve efficiency. Potential directions for future work include generalizing the inefficiency loss to other desirable CP properties such as robustness and conditional coverage; extensions to inductive settings or transductive but non-random split settings; extensions to other graph tasks such as link prediction, community detection, and so on.

## 8 Acknowledgements

K.H. and J.L. gratefully acknowledge the support of DARPA under Nos. HR00112190039 (TAMI), N660011924033 (MCS); ARO under Nos. W911NF-16-1-0342 (MURI), W911NF-16-1-0171 (DURIP); NSF under Nos. OAC-1835598 (CINES), OAC-1934578 (HDR), CCF-1918940 (Expeditions), NIH under No. 3U54HG010426-04S1 (HuBMAP), Stanford Data Science Initiative, Wu Tsai Neurosciences Institute, Amazon, Docomo, GSK, Hitachi, Intel, JPMorgan Chase, Juniper Networks, KDDI, NEC, and Toshiba. The content is solely the responsibility of the authors and does not necessarily represent the official views of the funding entities.

Figure 5: (1) Parameter analysis on inefficiency given different target coverage rate 1-\(\). (2) Parameter analysis on inefficiency given calibration set holdout fraction. Analyses use Cora/Anaheim for classification/regression.