# Classical Simulation of Quantum Circuits Using Reinforcement Learning:

Parallel Environments and Benchmark

 Xiao-Yang Liu\({}^{1,2}\) and Zeliang Zhang\({}^{2}\)

\({}^{1}\)Rensselaer Polytechnic Institute, \({}^{2}\)Columbia University,

liux33@rpi.edu, XL2427@columbia.edu, hust0426@gmail.com

Zeliang Zhang completed this work as a research assistant at Columbia University.

###### Abstract

Google's "quantum supremacy" announcement  has received broad questions from academia and industry due to the debatable estimate of \(10,000\) years' running time for the classical simulation task on the Summit supercomputer. _Has "quantum supremacy" already come? Or will it come in one or two decades later?_ To avoid hasty advertisements of "quantum supremacy" by tech giants or quantum startups and eliminate the cost of dedicating a team to the classical simulation task, we advocate an open-source approach to maintain a trustable benchmark performance. In this paper, we take a reinforcement learning approach for the classical simulation of quantum circuits and demonstrate its great potential by reporting an estimated simulation time of less than \(4\) days, a speedup of \(5.40\) over the state-of-the-art method. Specifically, we formulate the classical simulation task as a _tensor network contraction ordering_ problem using the K-spin Ising model and employ a novel Hamiltonian-based reinforcement learning algorithm. Then, we evaluate the performance of classical simulation of quantum circuits. We develop a dozen of massively parallel environments to simulate quantum circuits. We open-source our parallel gym environments and benchmarks.

## 1 Introduction

Google proudly announced "achieving quantum supremacy"  with its \(53\)-qubit Sycamore circuits back in 2019, which was later challenged by researchers claiming to have pulled ahead of Google on classical computers. _Quantum supremacy_ aims to demonstrate that a programmable quantum device can solve a problem that no classical computer can solve in any feasible amount of time, irrespective of the usefulness of the problem. As illustrated in Fig. 1, for the problem of random number generation, Google's "quantum supremacy" announcement  relied on an estimated simulation time of \(10,000\) years on the Summit supercomputer, while existing works reduce it to less than \(21\) days and scale the number of quantum qubits up to around \(100\). This raises the debate: _Has "quantum supremacy" already come? Or will it come in one or two decades later?_ Our goal is to use machine learning methods to derive the best performance curves for the classical simulation task, to _settle down the present debate and suggest

Figure 1: Running time of different quantum circuit simulation methods.

that achieving "empirical quantum supremacy" requires continuing quantum hardware developments without an unequivocal first demonstration_.

There are several existing works on the classical simulation of quantum circuits . One promising method is using tensor networks  since quantum circuits can be naturally represented as tensor networks, i.e., executing a quantum gate is mathematically a tensor contraction operation. Therefore, establishing a benchmark curve for the classical simulation task is mathematically searching for the optimal tensor network contraction ordering (TNCO), which is a combinatorial optimization problem , a variant of the well-known traveling salesman problem (TSP) where reinforcement learning (RL) algorithms  have shown powerful capability. _We are motivated to take a reinforcement learning approach to establish state-of-the-art performance_.

There is a debate on the estimate of running time for classical simulation tasks, as illustrated in Fig. 2. Huang _et al._ used a heuristic tensor network approach on a computing cluster and estimated the simulation time to be \(21\) days. Meirom _et al._ used a reinforcement learning algorithm where the policy network used a graph neural network and reported an order-wise reduction compared to the best heuristic method. However, there is no available dataset for training and benchmarking machine learning algorithms, and it is reasonable to maintain a publically trustable performance curve for the coming quantum supremacy.

To avoid hasty advertisements of "quantum supremacy" by tech giants or quantum startups and eliminate their cost of dedicating a team to the classical simulation of quantum circuits, establishing a standard benchmark is important. In this paper, we take a reinforcement learning (RL) approach for the classical simulation of quantum circuits and demonstrate its great potential by reporting an estimated simulation time of less than \(4\) days, a speedup of \(5.40\) over the state-of-the-art method. The result demonstrates that _the "quantum supremacy" claim still lacks an unequivocal first demonstration_. Specifically, we adopt the K-spin Ising model for the classical simulation of quantum circuits, i.e., the tensor network contraction order (TNCO) problem, and employ the Hamiltonian-based reinforcement learning algorithm to minimize the number of multiplications. Then, we establish standard criteria to evaluate the simulation performance for Google's Sycamore circuits. We develop a dozen of massively parallel environments for training and evaluating RL agents. We release multiple datasets, including tensor-train, synthetic, and sycamore quantum circuits, and benchmark curves, including OPT-Einsum, Cotengra, and our RL method, on Github at https://github.com/XiaoYangLiu-FinRL/RL4QuantumCircuits.

We hope the AI/ML community and quantum physics community will collaborate to maintain reference curves for validating an unequivocal first demonstration of "empirical quantum supremacy".

## 2 Related Works

**Random circuit sampling**: Random Circuit Sampling (RCS)  is an approach that has garnered considerable attention within the quantum computing community. It involves the generation of random quantum circuits, which are subsequently subjected to measurement procedures. By sampling the measurement outcomes, RCS enables the evaluation of the distribution of classical output probabilities, providing valuable insights into the computational power of noisy intermediate-scale quantum devices. While many works [27; 38; 35] demonstrate the hardness of RCS, highlighting its computational complexity, the reinforcement learning-based method  presents a promising way to accelerate the classical simulation of RCS.

**Quantum circuits for random number generation task**: One notable example of the application of quantum circuits  is the random number generation. It is NP-hard since simulating a probability distribution on classical computers involves an exponential time complexity. For the problem of random number generation, Google's Sycamore circuit  was a milestone in quantum computing, which used the random circuit sampling technique to achieve the random selection process and claimed to demonstrate "quantum supremacy". However, it is hard for most researchers to access

Figure 2: Debatable time estimates of classical simulation of Googleâ€™s Sycamore circuits.

the computing resources of quantum circuits for study. It is critical to simulate the quantum circuits and establish the dataset and benchmark performance to verify such scientific claims.

**Classical simulation of quantum circuits**: In the field of classical simulation, several approaches have been proposed to simulate quantum circuits, including the matrix representation methods , variational algorithms , and tensor network methods . Among these, the tensor network method leverages the mathematical framework of tensor networks to approximate quantum states and perform efficient simulations. Tensor network methods, such as the matrix product state (MPS)  and projected entangled pair state (PEPS) , have shown promising results in simulating both one-dimensional and two-dimensional quantum systems. In this paper, we take the tensor network method for simulating quantum circuits.

**Tensor network contraction** and the search for the optimal contraction path  have garnered significant attention in computational physics and quantum information theory. Various techniques  are employed to identify the most efficient way to contract tensors, minimizing computation cost. These advancements enable efficient simulation of quantum circuits. There are two popular open-source libraries, OPT-Einsum  and Cotengra  (CTG-Greedy and CTG-Kahypar), while Cotengra achieves state-of-the-art performance for most tensor networks.

**Ising model**: The Ising model  can serve as a unified formulation of combinatorial optimization problems, including graph coloring, maximum cut problems, and traveling salesman problems. The Ising model describes a system of interacting spins that can be either up or down, representing binary variables in studied problems. By mapping the studied problem on an Ising model, the problem can be reformulated as finding the configuration of spins that minimizes the corresponding energy function . The tensor network contraction problem can be analyzed into one kind of combination problem, especially the TSP. Thus, it motivates us to model the tensor network contraction problem as the Ising model and learn the optimal tensor contraction path by minimizing the energy function to reduce the computation complexity.

**AI/ML + X**: In recent years, the integration of artificial intelligence (AI) and machine learning (ML) techniques in scientific research has revolutionized various domains [12; 26; 6; 23]. The application of AI/ML in scientific fields, often referred to as AI+X or machine learning for science, has brought about significant advancements and novel approaches to solving complex problems . For example, tensor network factorization can be used for probabilistic modeling . The quantum entanglement can be built as a fundamental connection with deep neural network design . Quantum K-spin Hamiltonian Regularization is proposed to stabilize the reinforcement learning process . A recent study uses the tensor network-based quantum circuits for image classification .

## 3 Classical Simulation of Quantum Circuits Using Tensor Networks

We use uppercase calligraphic letters to denote tensors, e.g., \(^{I J K}\), uppercase and lowercase boldface letters to denote matrices and vectors, e.g., \(^{I J}\) and \(^{I}\).

### Quantum Circuits

**Qubits**: A qubit in a superposition state can be represented as \(=_{0}+_{1}\), where \(_{0},_{1}\), and \(}^{2}+}^{2}=1\). For \(n\) qubits, we use a linear combination of \(2^{n}\) coefficients and states \(\), \(\), \(\)\(\), respectively,

\[=_{0...0}+...+_{1...1},\] (1)

where \(_{0...0},...,_{1...1}\), and \(}^{2}+...+}^{2}=1\).

**Quantum gates**: Single- and double-qubit quantum gates are building blocks of quantum circuits,

\(\) Single-qubit gate:

\[}=}[1&-i\\ -i&1],\ }=}[1&-1\\ 1&1],\ }=}[1&- \\ &1],\] (2)* Double-qubit gate: \[(,)=[1&0&0&0\\ 0&&-i&0\\ 0&-i&&0\\ 0&0&0&^{-i}],\] (3) where \(/2\) and \(/6\) are used in the Sycamore quantum circuits.

**Quantum circuits** consists of a sequence of quantum gates. For a given initial state \(|_{0}\) and a quantum circuit \(=_{m}_{1}\), the final state is \(|=_{m}_{1}|_{0}\). Fig. 3 illustrates an example of \(4\) qubits and a circuit \(\) of \(m=2\) cycles. the initial state \(|_{0}=|0000\). The quantum circuit \(\) takes an initial state \(|_{0}\) of \(n\) qubits as input, performs \(m\) cycles of gate operations, and outputs a bit-string \(i_{1}...i_{n}\) of length \(n\).

In the \(i\)-th cycle, two operations are performed:

1. A single-qubit gate \(_{i}^{j}^{2 2}\) randomly selected from set \(\{},},}\}\) is applied to \(|_{i-1}_{j}\), resulting in state \(|_{i}_{j}=_{i}|_{i-1}_{j}\).
2. Then, execute a two-qubit quantum gate \(_{i}^{p}^{4 4}\) to \(|_{i-1}_{p}\) and \(|_{i-1}_{p+1}\) and obtain a new state \(|_{i}_{p,p+1}\). Specifically, during an odd cycle, qubit pairs with indices originating at \(0\), such as \((0,1),(2,3)\), are chosen. For even cycles, qubit pairs with indices starting at \(1\) are selected, including pairs such as \((1,2),(3,4)\). This systematic approach ensures the appropriate application of the \(_{i}^{p}\) operation on the designated qubit pairs.

Before measurement, each qubit \(|_{m}_{j}\) undergoes a random single-qubit quantum gate \(_{m+1}^{j}\). The random binary bit-string \(i_{1}...i_{n}\) is sampled from the probability distribution \(P=| i_{1}i_{2}...i_{n}||_{m+1} |^{2}\), which is obtained from the measurement outcome. More details about the random circuit sampling can be found in Appendix A.

### Random Circuit Sampling

**Quantum supremacy**: Quantum supremacy refers to a major milestone in quantum computing, representing the point at which a quantum computer can solve a specific problem that is practically infeasible for classical computers to solve within a reasonable timeframe. It is a demonstration of the superior computational power of quantum systems compared to classical counterparts. Achieving quantum supremacy signifies the ability of a quantum computer to perform computations exponentially faster than even the most powerful classical supercomputers.

**A quantum circuit defines a distribution**: Quantum circuit is a sequence of quantum operations or gates applied to a set of qubits. These gates manipulate the quantum state of the qubits, transforming them according to the specific operations performed. At the end of a quantum circuit, measurements are typically performed on the qubits, extracting classical information from the quantum system. The results of these measurements are probabilistic, meaning that they occur with certain probabilities. Therefore, a quantum circuit defines a distribution by specifying how these probabilities are distributed among the different possible measurement outcomes.

For example, given a quantum circuit \(U\), the initial state \(|0\), and the output sampling bit-string \(x=a_{1}a_{2}...a_{n}\{0,1\}^{n}\), the modeled probability is \(p(x)=| x|U|0|^{2}\). The Google team used  the following noise model for the noisy samples produced by the Sycamore circuits,

\[N_{c}(x)= P_{C}+(1-)2^{-n},\] (4)

where \(\) is a fidelity parameter describing the quality of the sample, \(P_{C}\) is the probability distribution defined by the quantum circuit. The parameter \(\) is estimated by follows,

\[=_{g_{1}}(1-e_{g_{1}})_{g_{2}}(1-e_{ g_{2}})_{q_{1}}(1-e_{q}),\] (5)

Figure 3: A quantum circuit where the classical simulation lies in the middle.

where \(_{1}\) is the set of single-qubit gate, \(_{2}\) is the set of double-qubits gate, and \(_{1}\) is the set of qubits. Google set \(e_{g_{1}}=0.16\%\), \(e_{g_{2}}=0.62\%\) and \(e_{q}=3.8\%\).

**XEB **: XEB stands for "Linear Cross-Entropy Benchmarking" and is a metric used to assess the performance of quantum processors. It quantifies the fidelity of a quantum computer's output compared to a classical reference model. Mathematically, XEB is defined as:

\[_{}(x)=2^{n}_{x}p(x)-1,\] (6)

where we have a collection of \(M\) random bit-strings \(=\{x_{1},...,x_{M}\}\). If a random quantum circuit runs without errors, we have \(_{}=1\). If bit-strings are sampled from a classical uniform distribution, we have \(_{}=0\).

By evaluating the XEB metric, researchers can assess the performance of quantum circuits. It provides a quantitative measure of how well a quantum computer reproduces the expected outcomes and is a valuable tool for evaluating and improving quantum computing technologies.

### Classical Simulation Using Tensor Networks

**The classical simulation task** aims to efficiently calculate \(=_{m}_{1}\) in (7) on classical computers, as marked red in Fig. 3. It is mathematically a combinatorial optimization problem _tensor network contraction ordering (TNOC)_.

\[=_{m}_{1}}_{}}.\] (7)

**Tensor contraction operation**: Given two tensors \(^{I J K}\) and \(^{K M N}\), their contraction results in a 4D tensor \(^{I J M N}\) where

\[_{i,j,m,n}=_{k=1}^{K}_{i,j,k}_{k,m,n},\] (8)

which takes \(IJKMN\) multiplications. Using the tensor diagram representation, as in Fig. 4, a node denotes a tensor and an edge denotes a tensor contraction operation.

**Tensor network representation**: Leaving the input quantum bits and the final measurement out, the quantum circuit \(=_{m}_{1}\) can be represented as a tensor network. Specifically, a single-qubit gate \(\) is represented as a matrix (a 2D tensor), while a double-qubit quantum gate \(\) is represented as a 4D tensor. Using tensor diagrams, a quantum circuit in Fig. 3 is mapped into a tensor network in Fig. 4. Note that the final result of the classical simulation task is an 8D tensor shown in Fig. 4. We provide more details about the tensor representations in Appendix B.

**Simulation efficiency**: We would like to illustrate that the contraction ordering for calculating \(=_{m}_{1}\) is critical to the simulation efficiency. Different orderings may result in a significant difference in the number of multiplications. The difference may be hundreds of orders for quantum circuits with a large number of qubits and many cycles . For a simple example in Fig. 4, two contraction orderings (blue and red) for the same quantum circuit involve \(976\) and \(5056\) multiplications, respectively.

## 4 Tensor Network Contraction Ordering Using Reinforcement Learning

First, we formulate the classical simulation task as a combinatorial optimization problem, i.e., tensor network contraction order (TNOC). Then, we adopt a K-spin Ising model whose Hamiltonian is used as the loss function to train a policy network via curriculum learning. We also provide a pool of implementation tricks to improve training efficiency and boost performance.

### Problem Formulation

**Tensor network contraction order (TNOO)**. Given a tensor network \(G=(V,E)\), a contraction path \(P=(e_{1},,e_{n-1}),e_{t} E_{t}\), and a corresponding sequence of graphs \((G_{1}, G_{n-1})\), the goal is to find a path \(P\) with minimum cost,

\[P^{*}(G) =_{P}_{t=1}^{n-1}R_{t}(e_{t})\] (9) \[\;\;P =(e_{1},,e_{n-1}),e_{t} E_{t},\]

where \(E_{t}\) is the set of remaining edges between tensors, \(G_{t}\) is the tensor network after \(t\)-th tensor contraction and the reward \(R_{t}\) is defined as the number of multiplications for the tensor contraction along edge \(e_{t}\). This formulation is consistent with .

Consider an example in Fig. 5, graph \(G_{1}\) has \(V_{1}=(1,2,3,4),E_{1}=(k,j,m,i,s),w=\{K,J,M,I,S\}\). Assuming that the first contraction operation is on index \(m\) in \(G_{1}\), tensors \(3\) and \(4\) are contracted into tensor \(34\) at a computation cost of \(IJMS\) multiplications. Then, the graph is updated to \(G_{2}\) with \(V_{2}=(1,2,34),E_{2}=(k,ij,s),w=\{K,IJ,S\}\). Assuming the second contraction operation is on index \(k\) in \(G_{2}\), tensor \(1\) and \(2\) are contracted into tensor \(12\) at a computation cost of \(SKIJ\) multiplications. The updated graph \(G_{3}\) has \(V_{3}=(12,34),E_{3}=(sij),w=\{sij\}\). Finally, tensors \(12\) and \(34\) are contracted into a real number using \(SIJ\) multiplications. The total number of multiplications is \(IJMS+SKIJ+SIJ\).

### The Proposed Reinforcement Learning Method

First, we reformulate (9) into an Ising model. Then, we extend it to a K-spin Ising model, which allows training a policy network using the curriculum learning method .

**TNCO using Ising model**: The Ising model of TNCO problem uses \(N^{2}\) spins \(_{u,j}\), where \(u\) denotes the tensor and \(j\) denotes its order in the TNCO path. We use \(J_{u,v}^{i}\) to denote the cost introduced by the tensor contraction between \(u\) and \(v\) for the \(i\)-th order, _i.e._, the number of multiplications. The energy of the original TNCO problem has three terms. The first term requires each tensor to appear at least once in the TNCO path. The second term requires there are exactly two tensors selected at order \(j\) along a path. The third term measures the contraction cost at order \(j\). These are encoded in the following Hamiltonian:

\[H()=_{i=1}^{N-1}\{(2-_{u=1}^{N-i}_{u,i})^{2}+_{u =1}^{N}_{v=1}^{N}J_{u,v}^{i}_{u,i}_{v,i}\}.\] (10)

As shown for example, in Fig. 6, it can be computed by \(H(x)=(2-_{1,1}-_{2,1}-_{3,1}-_{4,1})^{2}+(2-_{1, 2}-_{2,2}-_{3,2})^{2}+(2-_{1,3}-_{2,3})^{2}+w_{1}(1,4) _{1,1}_{4,1}+w_{1}(1,2)_{1,1}_{2,1}+w_{1}(2,3)_{2,1}_{3,1}+w_{1}(2,4)_{2,1}_{4,1}+w_{1}(3,4)_{3,1}_{4,1}+w_{2}(1,3)_{1,2}_{3,2}+w_{2}(1,2)_{1,2}_{2,2}+ w_{2}(2,3)_{2,2}_{3,2}+w_{3}(1,2)_{1,3}_{2,3}\)

Figure 4: For the quantum cirtuis in Fig. 3, two contraction orderings (blue and red) involve \(976\) and \(5056\) multiplications, respectively.

Figure 5: An example of tensor network contraction.

**TNO using K-spin Ising model**: Our solution takes K steps to solve the TNCO problem, i.e., \(^{1}^{2}^{K}\), which can be encoded in the following Hamiltonian,

\[H(^{1},,^{K})=_{k=1}^{K}H(^{k})+_{k=1}^{K}_ {i_{1} V^{1}}_{i_{k} V^{k}}J_{i_{i} i}^{1 k} _{i_{1}}^{1}_{i_{k}}^{k},\] (11)

where \(J_{i_{1} i_{k}}=_{k=2}^{K}^{K-k}w(i_{1},i_{2})w(i_{2},i_{3})  w(i_{k-1},i_{k})\).

**Policy network**: We build the policy network with a transformer neural network. We represent the tensor network with an undirected graph, demonstrated as a symmetric matrix \(\). If \(i\)-th and \(j\)-th tensors are connected with a shared index \(d\), then \(_{i,j}=d\). The policy network takes \(\) as input and generates the contraction ordering \(P=(e_{1},...,e_{n-1})\), where \(e_{t} E_{t}\) is the connected edge between \(u\)-th and \(i\)-th tensors \(_{u,i}\).

**Challenges**: Several challenges for using RL algorithms include the wide dynamic range, huge search space, slow convergence due to Heavy-tailed cost distribution, incorporating existing solvers, and credit assignment problem . The sampling bottleneck is a major challenge in training RL agents . Next, in Section 4.3, we develop a pool of implementation tricks to overcome these challenges, including massively parallel gym-environment, learning to optimize, dual replay buffers, swarm intelligence, and curriculum learning.

### Implementation Tricks

**Massively parallel gym-environment**. The sampling bottleneck is a major challenge in training RL agents. We implement a massively parallel gym-environment to accelerate the sampling efficiency. We initialize \(N\) independent environments and generate and forward different tensor network contraction paths to these environments at each step. Each environment performs the contraction operations according to the given path, yielding the next state and calculating the number of multiplications as rewards. We store these transitions, including the tensor networks and their corresponding multiplications, in the replay buffer.

**Learn to optimize**. We adopt the learn-to-optimize (L2O) strategy  for training an RL agent. Instead of using conventional optimizers like Adam or Nestrov, we employ a long-short-term memory (LSTM) network. It takes the current gradient and loss value as inputs and produces gradients. This L2O strategy effectively accelerates the convergence process, particularly in the presence of a Heavy-tailed cost distribution. This approach enables faster and more efficient training by dynamically adapting the parameter updates based on the current gradient and loss value.

**Dual replay buffers.** We maintain two replay buffers, one saves the tensor contraction ordering from the agent in an iterative rollout manner, and the other saves high-quality tensor contraction orders so far. The reason for two replay buffers is that we want to avoid high-quality tensor contraction ordering being deleted by the rule of first in, first out (FIFO) due to the GPU memory limit. We use the Hamiltonian value to measure the quality. We sample from two replay buffers alternatively during the training process, which stabilizes the RL training.

**Swarm intelligence.** We train multiple optimizers since different optimizer is easily stuck into local optima [7; 39]. To mitigate the impact, different optimizer shares knowledge with others regularly, thus escaping local optima and approaching the global optima. Specifically, during training,

Figure 6: Illustration of TNCO problem: conventional Ising model vs. our K-spin Ising model.

optimizers keep the top-\(N\) solutions while optimizers share them. Rather than directly using the orderings for training, the optimizer will manually add some noise to the shared orders to search for the solution in the neighborhood of that local optimum.

**Curriculum learning.** We apply curriculum learning method [5; 17; 62]. With an acceptable performance on small-scale tensor network contraction problems, the optimizer has successfully escaped multiple local optima. The optimizer may approach the global optima when varying the studied tensor networks from small to large scale. We have two tricks for measuring the problem scale: the number of iterations and parameter freezing strategies.

* The first trick is varying the number of iterations, \(K\). A large \(K\) may result in insufficient optimization, while in contrast, small-scale optimization problems corresponding to a small \(K\) may experience over-fitting. Therefore, starting with an initial large \(K\), we gradually decrease \(K\) during the training process.
* The second trick is masking network parameters, i.e., freezing different ratios of parameters. Specifically, at first, we randomly freeze \(90\%\) of the parameters and optimize the rest \(10\%\) parameters, which is easy to optimize. Then, we gradually decrease the ratio of masked parameters. It can help the optimizer escape the local minima.

Note that the two curriculum learning tricks can be integrated with the swarm intelligence trick to boost performance.

## 5 Performance Evaluation and Benchmark

We present experimental results on both synthetic tensor networks and Google's Sycamore circuits. Further, we investigate the scalability performance of our method for large-scale quantum circuits that have a similar structure to Google's Sycamore circuits.

### Baseline Methods

We provide the following five baselines for verification purposes:

* OE-GREEDY : an open-source solver from OPT-Einsum library, which uses the greedy search algorithm to find the optimal tensor contraction path.
* CTG-Greedy : an open-source solver from the Cotengra library, which uses the greedy search algorithm to find the optimal tensor contraction path.
* CTG-Kahypar : A robust graph partitioning-based solver from the Cotengra library, which achieves state-of-the-art results in many tensor networks.
* ACQDP [21; 22]: Using the stem optimization, including the hypergraph partitioning, local optimization, and dynamic slicing, to search the optima tensor contraction order2. * RL-TNCO : an RL approach combined with graph neural networks to search the optimal tensor contraction order, which is one of the state-of-the-art methods for the classical simulation of quantum circuits3. 
**Experiment setup**. We conducted all experiments on a DGX-2 server with NVIDIA A100 GPUs, each of which consists of 48 GB device memory. There are two Intel(R) Xeon(R) Gold 5118 CPUs. Each of CPUs has 12 cores @2.30GHz supporting 24 hardware threads. There are 128 GB DDR4 memories on the server. We set the learning rate \(\) as \(3 10^{-3}\) with a decay factor \(0.9\) (reduce the learning rate every \(1,000\) epochs), and the total number of epochs is \(1,000,000\). We set \(K=3\) for our K-spin Ising model. The number of parallel environments is \(2048\), while the large-scale cases use \(1024\). When the number of tensors increases, the GPU memory consumption increases; therefore, we use \(1024\) environments for large-scale tensor networks.

### Verification on Synthetic Tensor Networks

**Synthetic tensor-train networks**. We tested tensor-train networks with tensors from \(400\) up to \(2000\). From Table 1, our RL-Ising method achieves a speedup of \(2\) over the CTG-Kahypar method for tensor size from \(400\) to \(1000\). Both OE-Greedy and CTG-Greedy cannot work for the problem instances with over \(1,500\) tensors, while the RL-Ising method exhibits good scalability, outperforming CTG-Kahypar by a speedup of \(1.73\) for tensor sizes \(1500\) and \(2000\).

### Benchmark Performance on Google's Sycamore Circuits

Google's Sycamore circuits  has \(53\) qubits and \(m\) cycles, \(m=12,14,16,18,20\). As shown in Fig. 3, each cycle has one layer of random single-qubit gates and one layer of two-qubit gates. In different cycles, the two-qubit gates are applied to different pairs of quantum qubits.

The results are summarized in Table 3. Specifically, the RL-Ising method outperforms the RL-TNCO method with a speedup of \(2.84\). With \(20\) cycles, our RL-Ising method has a speedup of \(4.64\) over the CTG-Kahypar method, \(5.40\) over the ACQDP method, and

   Cytes & \(400\) & \(600\) & \(800\) & \(1000\) & \(1500\) & \(2000\) \\  Scale & \( 10^{120}\) & \( 10^{180}\) & \( 10^{241}\) & \( 10^{301}\) & \( 10^{451}\) & \( 10^{602}\) \\  OE-Greedy  & \(17.22\) & \(27.67\) & \(4.44\) & \(3.83\) & - & - \\ CTG-Greedy  & \(10.33\) & \(16.60\) & \(2.67\) & \(4.28\) & - & - \\ CTG-Kahypar  & \(10.23\) & \(16.60\) & \(4.67\) & \(4.26\) & \(14.12\) & \(4.57\) \\  RL-Ising & \(\) & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Results on synthetic tensor-train networks.

   Qbits & \(25\) & \(50\) & \(75\) & \(100\) \\  Scale & \( 10^{4}\) & \( 10^{7}\) & \( 10^{10}\) & \( 10^{12}\) \\  OE-Greedy  & \(53.7\)/\(27.7\) & \(75.4\)/\(11.3\) & \(104\)/\(4.5\) & \(5296\)/\(26.4\) \\ CTG-Greedy  & \(40.3\)/\(20.3\) & \(12.8\)/ \(4.2\) & \(8.3\)/\(0.9\) & \(27.9\)/ \(2.2\) \\ CTG-Kahypar  & \(46.4\)/\(24.8\) & \(13.4\)/ \(4.3\) & \(4.1\)/\(0.4\) & \(54.2\)/ \(1.2\) \\ RL-TNCO  & \(13.1\)/\(12.5\) & \(3.2\)/ \(1.8\) & \(1.2\)/\(0.2\) & \(5.5\)/ \(1.8\) \\  RL-Ising & \(\) & \(\) & \(\) & \(\) \\   

Table 2: Number of multiplications for synthetic random tensor networks.

   Cycles & \(m=12\) & \(m=14\) & \(m=16\) & \(m=18\) & \(m=20\) \\  Scale & \( 10^{10}\) & \( 10^{12}\) & \( 10^{13}\) & \( 10^{16}\) & \( 10^{18}\) \\  OE-Greedy  & \(6.23 10^{7}\) & \(4.77 10^{7}\) & \(7.74 10^{12}\) & \(6.21 10^{10}\) & \(9.59 10^{8}\) \\ CTG-Greedy  & \(1.16 10^{7}\) & \(1.91 10^{7}\) & \(1.42 10^{10}\) & \(3.71 10^{7}\) & \(4.19 10^{7}\) \\ CTG-Kahypar  & \(2.55 10^{3}\) & \(1.41 10^{2}\) & \(1.03 10^{4}\) & \(48.0\) & \(6.69\) \\ ACQDP  & \(1.09 10^{3}\) & \(71\) & \(1.15 10^{4}\) & \(25.8\) & \(6.65\) \\ RL-TNCO  & \(5.44\) & \(7.39\) & - & - & \(3.49\) \\  RL-Ising & \(\) & \(\) & \(\) & \(\) & \(\) \\   

Table 3: Number of multiplications for Googleâ€™s Sycamore circuits.

\(2.42\) over the RL-TNCO method. The estimated running time of ACQDP is \(21\) days [21; 22]; therefore, the estimated running time of our RL-Ising method is \(21/5.40 3.9\) days.

We provide a comparison of different methods in Fig. 7. With an increasing number of cycles, the number of multiplications in the log scale increases linearly, which corresponds to exponential trends (as illustrated in Fig. 1). Both RL methods, the RL-TNCO method and our RL-Ising method, are much lower than existing heuristic methods. Furthermore, the RL-Ising method is lower than that of the RL-TNCO method, with an improvement of \(0.384\) orders.

**Take-home message I**: _The "quantum supremacy" claim still lacks an unequivocal first demonstration, since Google's announcement  was under serious questions due to the debatable estimate of \(10,000\) years' running time for the classical simulation task on the Summit supercomputer._

### Scale Up to Large-Scale Quantum Circuits

Scalability is very important for evaluating future hardware developments. We scale up to large-scale quantum circuits with \(100,200,300,400\) and \(500\) qubits, respectively. There are \(20\) cycles for each generated quantum circuit, taking a similar structure as in Fig. 3. As given in Table 4, our RL-Ising method surpasses all the baseline methods with \(227\) speedups. With increasing the scale of quantum circuits, the performance gap between our method and the runner-up method CTG-Kahypar becomes large. It further shows the strong scalability of our RL-Ising method.

Therefore, we believe that reinforcement learning methods have great potential for finding the best performance curve.

**Take-home message II**: _To validate "empirical quantum supremacy" for future quantum hardware developments, the machine learning community is expected to play a critical role in maintaining publicly trustable benchmark performances with open-source training datasets.._

## 6 Conclusion and Future work

In this paper, we have demonstrated the potential of a reinforcement learning approach for the classical simulation of quantum circuits. We reported an estimated simulation time of less than \(5\) days, which is a remarkable speedup of \(4.62\) over the state-of-the-art heuristic methods. We conduct extensive experiments to evaluate the classical simulation performance. Moreover, we have developed parallel gym environments and benchmarks, which are openly accessible as open-source resources.

However, the provided environments may not cover all types of classical simulation tasks. The best performance is an open question, which asks for continuing efforts. This project may initiate long-term collaborations from the AI/ML and quantum physics communities to maintain reference curves for validating the "empirical quantum supremacy" and drive continuing hardware advancements.