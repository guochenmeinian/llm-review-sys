# Leveraging Tumor Heterogeneity: Heterogeneous Graph Representation Learning for Cancer Survival Prediction in Whole Slide Images

Leveraging Tumor Heterogeneity: Heterogeneous Graph Representation Learning for Cancer Survival Prediction in Whole Slide Images

Junxian Wu1,2\({}^{*}\) Xinyi Ke3\({}^{*}\) Xiaoming Jiang4\({}^{*}\) Huanwen Wu3\({}^{}\) Youyong Kong2,5\({}^{}\)

Lizhi Shao\({}^{}\)

\({}^{1}\) School of Internet, Anhui University

\({}^{2}\) Jiangsu Provincial Joint International Research Laboratory of Medical Information Processing,

School of Computer Science and Engineering, Southeast University

\({}^{3}\) Department of Pathology, State Key Laboratory of Complex Severe and Rare Disease,

Molecular Pathology Research Center, Peking Union Medical College Hospital,

Chinese Academy of Medical Sciences and Peking Union Medical College, Beijing, China

\({}^{4}\) School of Bioinformatics, Chongqing University of Post and Telecommunications

\({}^{5}\) Key Laboratory of New Generation Artificial Intelligence Technology and Its

Interdisciplinary Applications (Southeast University), Ministry of Education, China

{junxianwu, kongyouyong}@seu.edu.cn

xinyike0321@student.pumc.edu.cn

jiangxm@cqupt.edu.cn

wuhuanwen@xhyy.pumc.edu.cn

24115@ahu.edu.cn

Equal contribution.Corresponding author.

###### Abstract

Survival prediction is a significant challenge in cancer management. Tumor microenvironment is a highly sophisticated ecosystem consisting of cancer cells, immune cells, endothelial cells, fibroblasts, nerves and extracellular matrix. The intratumor heterogeneity and the interaction across multiple tissue types profoundly impact the prognosis. However, current methods often neglect the fact that the contribution to prognosis differs with tissue types. In this paper, we propose ProtoSurv, a novel heterogeneous graph model for WSI survival prediction. The learning process of ProtoSurv is not only driven by data but also incorporates pathological domain knowledge, including the awareness of tissue heterogeneity, the emphasis on prior knowledge of prognostic-related tissues, and the depiction of spatial interaction across multiple tissues. We validate ProtoSurv across five different cancer types from TCGA (\(i.e.\), BRCA, LGG, LUAD, COAD and PAAD), and demonstrate the superiority of our method over the state-of-the-art methods. Source code is available at https://github.com/wjx-error/ProtoSurv.

## 1 Introduction

Pathological images are considered the gold standard for cancer diagnosis and provide rich prognostic information, such as the tumor differentiation and lymphovascular infiltration. Traditional manual evaluation by pathologists is subject to inter-observer inconsistency and lacks accuracy in the risk stratification for patients. The advent of whole-slide imaging allows the entire slide to be digitalized at high resolution, enabling the standardized and automated analysis of Whole Slide Images (WSIs)with deep learning methods. Deep learning has been applied to a series of medical tasks, including tumor segmentation, grading, subtyping and the prediction of molecular alternations and clinical outcomes.

The gigapixel WSIs encompass detailed cellular-level information, but this leads to extremely high memory usage. To make the memory usage acceptable for analyzing WSIs, most current works are based on the Multiple Instance Learning (MIL) framework . In MIL, WSIs are divided into multiple instances that are encoded separately, and then aggregated to obtain bag-level (slide-level) representations for downstream tasks. However, these methods based on MIL do not emphasize the contextual information among instances within the WSI, leading to a loss of structural information across tissues. Therefore, these methods struggle to achieve good performance on prognostic prediction tasks that require a comprehensive understanding of the local morphology and overall structure of the tumor microenvironment (TME) . In recent years, graph neural network (GNN) has shown tremendous potential in prognostic prediction , which can learn spatial interaction across tissues, enabling the deciphering of the tumor ecosystem based on the proximity of tumor cells to other TME components .

Apart from the spatial relationships, the high-resolution WSIs contain rich information about tissue heterogeneity within a tumor , which also has significant prognostic value. The tissue categories in pathology slides include tumor, stroma, immune infiltration, nerves, necrosis, etc., which together form the tumor microenvironment, but each varies in importance to cancer prognosis . Considering the presence of intratumoral tissue heterogeneity and understanding the specific characteristics of crucial tissue types can enhance the medical interpretability and optimize the graph model theoretically. (i) From the medical perspective: A large amount of histological studies have established the prognostic value of certain tissue types, such as the tumor, immune infiltration, stroma, and necrosis. Leveraging prior knowledge about intratumoral tissue heterogeneity can guide the model to focus on tissues highly relevant to survival prediction, aligning more closely with medical consensus and enhancing the model's interpretability. (ii) From the model design perspective: Commonly used GCN-like models are based on the homogeneity assumption, and it has been demonstrated that they do not perform well on heterogeneous graphs . Thus, the objective presence of heterogeneity among patches within WSIs could be affecting the performance of homogeneous graph-based WSI analysis models.

Therefore, we propose ProtoSurv, a novel heterogeneous graph model for cancer prognosis prediction. The heterogeneous graph introduces a "tissue category" attribute to each node to differentiate prognosis-related tissues in the WSIs. The selection of tissue categories is according to tissues clinically proven to be highly related to prognosis, which introduces clinical prior knowledge into the model. We incorporate the concept of prototype learning from advanced heterogeneous graph solutions , decoupling the model into the Structure View and the Histology View. The Structure View (SV) utilizes the neighbor message-passing mechanism of GNN to simulate the operation of pathologists observing at multiple magnifications. The Histology View (HV) extract prototypes from global features under the guidance of pathological priors related to prognosis. Subsequently, under the guidance of prototypes extracted by HV, the model aggregates regions of interest from the context-aware multi-hop neighborhood information from SV. We extensively evaluated our method on five TCGA public benchmark datasets and compared it to various state-of-the-art survival prediction methods. The survival prediction results of our approach significantly outperform the competitors.

We summarize our main contributions as follows:

1. **Domain knowledge awareness:** To holistically depict the morphological features and spatial interaction across multiple tissue types within tumors, we proposed ProtoSurv, which decipher intratumoral tissue heterogeneity using a heterogeneous graph and incorporates prior knowledge of prognostic tissue types into the prediction process.
2. **Validation on multi-cancer datasets:** We conducted comprehensive evaluations on five public benchmark datasets. ProtoSurv demonstrates robust survival prediction performance across multi-cancer datasets.

Related Work

### Weakly Supervised Learning Survival Prediction in WSIs

Manual annotations of WSIs demand enormous effort and domain knowledge from highly skilled pathologists. Consequently, only slide-level labels are commonly available, while pixel- or region-level annotations are seldom present. Hence, WSI tasks are frequently regarded as weakly supervised learning problems. In recent years, Convolutional Neural Network (CNN)-based and MIL-based weakly supervised learning approaches have been proposed for survival analysis in WSIs [18; 19; 20; 5; 8]. Mobadersany et al.  proposed an end-to-end CNNs method for processing manually annotated ROIs. Zhu et al.  used K-means to cluster patches and employed the clustering results as inputs into the CNN. Chen et al.  employed the MIL-based GCN method to model the topological relationships between patches, achieving context-awareness. Di et al.  introduced hypergraphs into survival prediction and designed strategies to overcome the limitations of sampling scales in constructing large hypergraph models.

### Graph-based Approaches in WSIs

Graph-based MIL approaches, which model the interactions between instances via graphs, have been widely utilized in WSI analysis, solving problems such as cancer classification[6; 21; 22], cancer grading [23; 24; 25], and survival analysis [5; 26]. Chen et al.  used GCN  in the information propagation process to achieve context-awareness. Zheng et al.  applied graph transformer network  to the information propagation stage in MIL. Lee et al.  proposed a method to aggregate similar patches into a superpatch according to cosine similarity, and used GAT for message passing between superpatches. Despite the significant success of graph-based methods in various tasks, current approaches do not account for the inherent heterogeneity between patches and overlook the guidance of clinical prior knowledge from pathology. Chan et al.  highlighted the importance of heterogeneous patch categories and subsequently introduced a heterogeneous graph model called HEAT. HEAT employs HoverNet to classify each patch based on the types of cells within it and introduces heterogeneous edges to model the relationships between heterogeneous nodes.

### Heterogeneous Graph Neural Networks

GNN models such as GCN  and GAT  have performed profoundly well on several WSI analysis tasks [5; 26]. However, GCN-like models have an inherent assumption of homophily on graphs, and many studies have highlighted their poor performance on heterogeneous graphs [14; 15]. Many works have attempted to address the issue of message passing among heterogeneous nodes within heterogeneous graphs. Early works attempted to solve the problem by aggregating information from multi-hop neighbors or by constructing auxiliary graph structures based on node and structure features [30; 31]. Recently, aggregating global information has emerged as a new direction for addressing challenges in heterogeneous graphs. Li et al.  found that capturing more global information substantially improves the model's performance. Some studies introduced class prototypes into models, extracting global information based on node categories [16; 17; 33]. Our model integrates the concepts from state-of-the-art heterogeneous graph methods, constructing a heterogeneous graph, capturing global information based on pathological prior categories. It incorporates the pathological priors of prognosis-relevant tissues into the model, optimizing both the model structure and pathological interpretability.

## 3 Preliminaries

**Heterogeneous Graph.** A heterogeneous graph is defined by a graph \(=(,)\), where \(=\{v_{i}\}_{i=1}^{N}\) is the set of nodes which contains \(N\) nodes and \(\) is the set of edges on the graph. \(A\) denotes the adjacency matrix of the graph, where \(A_{ij}\) represents the edge \(e_{i,j}\) between nodes \(v_{i}\) and \(v_{j}\). \(X\) represents the feature matrix of nodes, where \(x_{i}\) is the features of node \(i\). \(C\) denotes the node class labels, and \(c_{i}\) is the label for node \(v_{i}\). Every node \(v_{i}\) within the heterogeneous graph has a category label \(c_{i}\) and a \(d\)-dimensional feature \(x_{i}\), where \(\) is the embedding space of node features.

**Survival Prediction in Whole Slide Images.** Given a WSI, we wish to predict the survival risk \(Y\) with a prediction model. We use the clinical survival time of patients as labels, and measure prediction performance by the relative ranking of predicted survival risk against the actual survival times of the patients.

## 4 Method

### Construction of Heterogeneous Graph

We first introduce our methodology of modeling the WSI with a heterogeneous graph. We follow Lu et al.  to segment foreground regions and split WSIs into non-overlapping patches of size \(256 256\) by sliding window strategy at 20x magnification. We use the UNI model  as a patch encoder to obtain patch embeddings for each patch. Pathology foundation models such as UNI are trained on large-scale pathology datasets and have been validated to represent pathological patches effectively. To incorporate pathological prior knowledge into our model, we focus on tissue regions that are recognized by the current consensus as highly relevant to cancer prognosis: tumor , tumor stroma , immune infiltration , and necrosis . Therefore, we further fine-tune UNI to obtain our patch classifier, which classifies each patch into one of the five categories (tumor, stroma, immune infiltration, necrosis, others). The classifier training and usage details can be found in section 5.2. Each patch is treated as a node in the graph, with the representation encoded by the UNI as the node's features, and the five histological categories as the node's labels. We exploit the graph structure to simulate the topological relationship of patches within the WSI. For each node \(v V\), we use the k-nearest neighbor algorithm to find k nodes closest to the given node in Euclidean space (k=4), and connect edges between node \(v\) and its neighboring nodes. All edges have the same

Figure 1: An overview of the ProtoSurv architecture. We use the encoder and classifier pretrained from UNI to obtain feature representations and node types for each patch. Edges are created between spatially adjacent patches to obtain a heterogeneous graph. ProtoSurv decouples the graph into two views: Structure View and Histology View. The Structure View utilizes GCN to provide multi-hop neighborhood information. The Histology View breaks the edge constraints and leverages tissue heterogeneity information to learn global multi-prototype representations for each tissue category. We use additional loss functions to regularize the multi-prototypes.

weight. As a result, we obtain a heterogeneous graph \(G\). The edges of the graph model the topological relationships between patches.

### ProtoSurv

To capture scattered but significant information from prognostically relevant tissues while preserving multi-scale context perspective, inspired by Dong et al. , we propose ProtoSurv, which decouples the Structure View and the Histology View from the graph, allowing separate learning of hierarchical features and global features of prognosis-related tissue categories.

**Structure View.** We use GNN to learn the structure representation of WSIs. After the i-th layer of message passing, the i-th output node representations reflect the receptive field within i-hop neighbors centered around the node. We retain all output features from each GCN layer to enable the Structure View to leverage multi-hop neighborhood information. We concatenate the features from each GCN layer along the feature dimension and use a MLP to learn representations from multi-hop neighborhood information, obtaining the final feature \(H\) of the Structure View.

\[h^{l}=^{l}(h^{l-1},A)^{N d} h ^{0}=X,\] (1)

\[H^{{}^{}}=[h^{1},h^{2},,h^{L}] ^{N Ld},\] (2)

\[H=MLP(H^{{}^{}})^{N d_{h}},\] (3)

where \(X\) represents the initial feature matrix of nodes, \(d\) is the hidden dimension of each GCN layer, \(L\) is the number of GCN layers, \(N\) is the number of nodes, and \(d_{h}\) is the hidden dimension of the Structure View.

**Histology View.** In order to fully exploit representations of tissue categories highly related to prognosis within the WSI, Histology View learns prototype representations for each category from global nodes. These prototypes extract feature information within the feature space of certain categories irrespective of their topological edges.

In clinical practice, heterogeneity exists even within the same tissue category[37; 38]. Take stroma as an example, Xu et al.  highlighted: _"The tumor stroma is highly dynamic, heterogeneous and commonly tumor-type specific,... "_ Therefore, using a single prototype to represent a whole tissue category is insufficient and often inaccurate. We introduce multiple prototypes for each tissue category, allowing them to capture different phenotypes within tissue feature distributions. For a detailed illustration of multiple subtypes of specific tissue categories, refer to appendix F.

In Histology View, all node features with category \(c\) are first averaged to obtain the initial prototype \(p_{init}^{c}\) of category \(c\) with the hidden dimension \(d\). For a visual demonstration of the multi-prototype extraction process, please refer to appendix B.

\[p_{init}^{c}=MEAN(X_{c})^{1 d},\] (4)

Then, learnable parameters \(Z=\{z_{1},z_{2},,z_{k}\}\) are used to shift the initial prototype to multi-prototypes, we obtain \(K\) distinct prototypes for category \(c\) that focus on different subtypes of the specific tissue. The learnable parameters \(Z\) are initialized by Xavier initialization .

\[P_{prior}^{c}=\{p_{c}^{1},p_{c}^{2},,p_{c}^{k}\}=\{p_{init}^{c}+z_{1},p_{ init}^{c}+z_{2},,p_{init}^{c}+z_{k}\}^{K d},\] (5)

We further employ the cross-attention mechanism to aggregate scattered global node information into the prototypes, thereby updating the multi-prototypes. Considering the potential omissions from pseudo-labeled tissue categories from the classifier and the need to focus on other relevant tissues, we extract information from global nodes, not just nodes with category \(c\), to update the prototypes.

\[P_{c}=(^{c}W^{Q}][XW^{K} ]^{}}{})(XW^{V})^{K  d},\] (6)

where \(d\) is the hidden dimension, \(W^{Q}\), \(W^{K}\) and \(W^{V}\) are query, key and value transformation matrices respectively. Finally, we obtain multiple prototypes \(P\) for all categories.

\[P=\{P_{1},P_{2},,P_{c}\}^{CK d},\] (7)The learning of prototypes can be viewed as intentionally adding edges based on pathological priors. Guided by prior knowledge, it allows global messages to pass from nodes to the interested histological category prototypes.

**Prior Guided Fusion&Pooling.** Once we have all the category prototypes \(P\) from the Histology View and hierarchical context embeddings \(H\) from the Structure View, we can select regions of interest within multi-hop neighborhoods from Structure View under the guidance of category prototype priors. This process can also be viewed as pooling guided by prior knowledge of the tissue categories of interest. We use the cross-attention mechanism to aggregate Structure View features and pathological multi-prototypes.

\[P_{fusion}=(][ HW^{K}]^{}}{})(HW^{V})^{CK  d},\] (8)

where \(W^{Q}\), \(W^{K}\) and \(W^{V}\) are query, key and value transformation matrices respectively. Guided by histopathological prior knowledge, we select regions of interest at multiple scales through cross-attention, obtaining \(K\) representations for each of \(C\) tissue categories, resulting in \(CK\) categorized representations in total. Finally, we use average pooling to derive the WSI representation \(h_{slide}\), which is used for predicting survival risk \(Y\).

\[h_{slide}=MEAN(P)^{1 d},\] (9) \[Y=g(h_{slide}),\] (10)

where \(g\) is a survival prediction head, which is a Multi-Layer Perceptron (MLP) used to predict survival risk \(Y\) from WSI-level feature \(h_{slide}\).

**Loss Functions.** To fully exploit the capabilities of the multiple prototypes of each tissue category, besides the commonly used Cox regression loss \(_{cox}\) for survival prediction, we introduce compatibility loss and orthogonality loss to regularize training. The compatibility loss regularizes by encouraging the prototypes and representations of a specific category to agree. Meanwhile, the orthogonality loss encourages different prototypes of the same category to be distinct.

Following Dong et al. , we modify the compatibility loss function from Snell et al.  to handle multiple prototypes within each category. Within the compatibility loss, we treat node features that belong to the same category of the prototypes as positive samples, and those that belong to different categories as negative samples, and use the negative log-likelihood loss to constrain their relationships. First, we map all prototype representations back to the latent space of the node features through a nonlinear mapping layer. Then, we calculate positive similarity scores of positive samples between prototypes and node features belonging to category \(c\), as well as similarities of negative samples with features not belonging to the category. Finally, we aggregate the similarity scores of multiple prototypes into a single score for a specific category, and adopt the negative log-likelihood loss to regulate the relationship between the prototype and node features of the same category. The compatibility loss is computed as follows:

\[s_{i}^{c}=ME(X^{c},f(p_{k}^{c})),\] (11)

\[_{comp}=_{i N}[s_{i}^{c_{i}}+_{c^{ } c}(-s_{i}^{c^{}})],\] (12)

where \(N\) is the number of nodes, \(C\) is the number of categories, \(c_{i}\) is the category of \(i^{th}\) node, \(p_{k}^{c}\) is the \(k^{th}\) prototype of category \(c\), \(X^{c}\) is the initial node features with category \(c\), \(f\) is an MLP and \(\) is a similarity function. To exploit multi-prototypes, we regularize them so that they are distinct from each other, and focus on different representations of certain tissue categories. We employ orthogonality loss  to enforce that the prototypes are orthogonal to each other to achieve this purpose,

\[_{ortho}=\|)^{T}P^{c}}{\|(P^ {c})^{T}\!P^{c}\|_{F}}-}{}\|_{F},\] (13)

where \(\|\|_{F}\) indicates the Frobenius norm, and \(I_{d}\) is an identity matrix. With the \(\) and \(\) as tuning hyperparameters, the full loss function used for training is:

\[=_{cox}+_{comp}+_{ortho}.\] (14)Experiments

### Datasets

The cancer types of WSIs we use are: Breast Invasive Carcinoma (BRCA) (1064 cases), Lower Grade Glioma (LGG) (841 cases), Lung Adenocarcinoma (LUAD) (512 cases), Colon Adenocarcinoma (COAD) (441 cases), Pancreatic Adenocarcinoma (PAAD) (208 cases). All cancer types of WSIs are from The Cancer Genome Atlas (TCGA) repository.1 We choose these cancer types for training and evaluation using the following criteria: 1) overall survival available, and 2) balanced distribution of uncensored-to-censored patients. During dataset construction, we only preserve formalin-fixed paraffin-embedded hematoxylin and eosin (H&E) slides, given the morphological alterations found in frozen sections.

### Implementation Details

**Patch Extraction and Encoding.** First, we use OTSU to extract foreground tissue regions. Then we extract a series of non-overlapping patches at 20\(\) magnification with size \(256 256\) which contain more than \(50\%\) foreground tissue. All patches are encoded by UNI  into 1024-dimensional vectors, and the encoder does not perform data augmentation during inference.

**Patch Classifier Training.** We use a small amount of proprietary annotated patches from the TCGA dataset and several public tissue classification datasets [43; 44; 45; 46] to train our classifier. The classifier is based on UNI . We used the 1024-dimensional vector obtained from UNI encoding and added a classification head to classify the patches into 12 categories. We trained the classifier based on the pre-trained weights of UNI, fine-tuning without freezing. Our 12-class classifier achieved an accuracy of 92.5% on the validation set. For details on the 12 categories, refer to section 5.5.

**Network Hyper-Parameter.** For Histology View, the number of prototypes \(K\) per category is set to 8, and the dimension of each prototype is set to 768. Based on pathological prior knowledge, we divided the nodes into five categories. For a detailed discussion on the tissue category selection, refer to section 5.5. For Structure View, the number of GCN layers \(L\) is set to 4, the hidden dimension \(d\) of each GCN layer \(h^{l}\) are set to 128, The dimension of the final feature \(H\) of the Structure View is set to 768. For loss function, the hyperparameter \(\) is set to 0.01, \(\) is set to 0.1.

**Training and Evaluation.** Adam optimization  is adopted to optimize our model. We use Adam optimization with a default learning rate of \(2 10^{-4}\), weight decay of \(1 10^{-5}\), and the batch size is set to 8. All experiment results are obtained through 5-fold cross-validation. Concordance index (C-index)  and its standard deviation (std) are used to measure the predictive performance in correctly ranking the survival risk of each patient. As qualitative assessment, we use Kaplan-Meier curves  to visualize the quality of patient stratification in stratifying low and high-risk patients as two different survival distributions. All the experiments are implemented using PyTorch  on a workstation with 4 Nvidia 3090 GPUs.

### Comparison with State-Of-The-Art Methods

We compare our proposed method with several state-of-the-art survival prediction approaches on the above datasets. The comparison methods include: (1) WSISA , (2) ABMIL , (3) TransMIL , (4) DeepAttnMISL , (5) Patch-GCN , (6) DeepGraphConv , (7) HEAT , (8) HGSurvNet . (9) PANTHER . Among them, WSISA, ABMIL, TransMIL and DeepAttnMISL are classic WSI survival prediction methods; DeepGraphConv and Patch-GCN used GNN to construct homogeneous graphs; HGSurvNet established a hypergraph; HEAT created a heterogeneous graph for classification/staging tasks; PANTHER utilizes an unsupervised prototype network to aggregate global information. For fairness of comparison, we use UNI  as the instance feature encoder for all methods. All approaches are evaluated using the same 5-fold cross-validation splits.

**Comparison.** From the results in table 1, we observe that ProtoSurv achieves best or suboptimal performance across five cancer datasets. Particularly, the PAAD dataset has a small sample size (208 cases), which may lead to overfitting. Therefore, PANTHER, which extracts prototypes in an unsupervised way based on priors and has a minimal number of learnable parameters, demonstratedsuperior results on PAAD dataset. Meanwhile, ProtoSurv is only slightly below PANTHER on PAAD and significantly outperforms the other comparative methods, indicating the potential of the domain-prior infused model on small-scale datasets.

### Interpretability

To understand the interaction patterns of the prototypes, we visualize the attention heatmap between the prototypes and the features, as well as the attention components for each prototype in fig. 2. We observed that the attention preferences of multi-prototypes from a category varied. Some prototypes were responsible for extracting global category information, while others focused on discovering interactions between other categories. This indicates that the prototype learning paradigm has the potential to uncover unknown interactions and factors.

    & PAAD & BRCA & LGG & LUAD & COAD \\  WSISA & \(0.573 0.021\) & \(0.564 0.054\) & \(0.610 0.013\) & \(0.576 0.045\) & \(0.564 0.034\) \\ ABMIL & \(0.625 0.063\) & \(0.657 0.064\) & \(0.710 0.048\) & \(0.653 0.059\) & \(0.647 0.036\) \\ TransMIL & \(0.642 0.037\) & \(0.694 0.053\) & \(0.739 0.034\) & \(0.608 0.040\) & \(\) \\ DeepAttMSI & \(0.596 0.034\) & \(0.634 0.017\) & \(0.657 0.076\) & \(0.623 0.049\) & \(0.638 0.069\) \\ Patch-GCN & \(0.618 0.057\) & \(0.647 0.032\) & \(0.713 0.054\) & \(0.635 0.027\) & \(0.652 0.086\) \\ DeepGraphConv & \(0.615 0.032\) & \(0.535 0.014\) & \(0.617 0.048\) & \(0.597 0.037\) & \(0.621 0.085\) \\ HEAT & \(0.638 0.030\) & \(0.693 0.084\) & \(0.741 0.079\) & \(0.642 0.031\) & \(0.679 0.056\) \\ HGSurvNet & \(0.646 0.064\) & \(0.701 0.067\) & \(0.746 0.043\) & \(0.638 0.064\) & \(0.673 0.043\) \\ PANTHER & \(\) & \(0.699 0.019\) & \(0.748 0.046\) & \(0.631 0.029\) & \(0.635 0.056\) \\ ProtoSurv (Ours) & \(0.669 0.049\) & \(\) & \(\) & \(\) & \(0.692 0.045\) \\   

Table 1: C-index (mean \(\) std) over five cancer datasets. The best and second-best results are highlighted in **bold** and underlined.

Figure 2: **Heatmap interpretation of prototypes.** (A) Visualizations of attention maps of multi-prototypes in Prior Guided Fusion (PGF) module. (B) Visualization of each prototype’s preference: showing the top 4 patches and detailed tissue proportion of the top 1000 patches base on attention scores. (C) Proportions of detailed 12 intratumoral tissue categories.

### Ablation Studies

**Component Validation.** We decouple the graph into the Structure View and the Histology View to separately extract structure and global features, and use the Prior Guided Fusion & Pooling module to aggregate these features. In this section, we conduct ablation experiments on Histology View (HV), Structure View (SV), and Prior Guided Fusion & Pooling (PGF) modules. Specifically, we implement our ablation as follows: (1) Without Histology View (w/o HV): We retain the features after message passing in the Structure View in eq. (3). Same to PatchGCN , we compute attention scores for each node and aggregate them by weighted summation. (In fact, the ablated model without HV is equivalent to PatchGCN.) (2) Without Structure View (w/o SV): We use the multi-prototypes extracted from the Histology View in eq. (7). We test the use of mean pooling and direct concatenation (concat pooling) to obtain the WSI-level representation. (3) Without Prior Guided Fusion & Pooling (w/o PGF): Beside our proposed fusion component, we tested two other aggregation approaches, including direct concatenation fusion and the transpose fusion. Within the concatenation fusion, we directly concatenate the prototypes from HV with the features from SV. Within the transpose fusion, We use the aggregation method from Dong et al. , swapping the order of \(Q\) and \(KV\) in cross-attention to integrate global information into node features, and same to the ablation of HV module, we compute attention scores for each node feature and aggregate them by weighted summation. For detailed information on the ablation of the PGF module, please refer to appendix D.1. Table 2 presents the results. We find that combining the HV and SV modules resulted in improvements, regardless of the aggregation method. This indicates that HV and SV are compatible and complementary. Additionally, our proposed Prior Guided Fusion (PGF) can best utilize information from the two modules to achieve optimal aggregation.

**Classifiers.** Classifying each patch into tissue categories requires additional annotated data to train the classifier, which somewhat limits the applicability of our model. To demonstrate the performance of our model in a wider range of scenarios, we test the performance of the model with different publicly available tissue classifiers in this section. We test our model using four different classification methods: (1) Zero-shot classifier from CONCH  (CONCH), (2) HoverNet nuclear classification  (HoverNet), (3) Pre-compute initial prototypes \(P_{init}^{c}\) of eq. (4) from the features of existing patches of category \(c\) (Pre-Proto), (4) K-means (with cluster number n = 4, 6, 8). None of the classifiers are specifically optimized for our task. For details on the usage of these classifiers, refer to appendix D.2. Table 3 shows the results of ProtoSurv under different patch classifiers. We find that without specially optimized classifiers, ProtoSurv still exhibited excellent performance. To our surprise, even when simply replacing the classifier with K-means clustering, ProtoSurv still outperforms most comparative methods. The ablation experiments on classifiers demonstrate the robustness of ProtoSurv to classifier choice, showing that ProtoSurv can achieve state-of-the-art performance without the need for specialized classifiers.

    & PAAD & BRCA & LGG & LUAD & COAD \\  w/o HV & \(0.618 0.057\) & \(0.647 0.032\) & \(0.713 0.054\) & \(0.635 0.027\) & \(0.652 0.086\) \\  w/o SV(mean pooling) & \(0.624 0.032\) & \(0.657 0.049\) & \(0.706 0.036\) & \(0.646 0.051\) & \(0.684 0.044\) \\ w/o SV(concat pooling) & \(0.661 0.057\) & \(0.713 0.039\) & \(0.766 0.044\) & \(0.641 0.037\) & \(0.688 0.046\) \\  w/o PGF(transpose fusion) & \(0.653 0.024\) & \(0.714 0.041\) & \(0.724 0.042\) & \(0.653 0.055\) & \(0.657 0.074\) \\ w/o PGF(concat fusion) & \(0.652 0.040\) & \(0.719 0.024\) & \(0.712 0.084\) & \(0.662 0.064\) & \(0.659 0.058\) \\  ProtoSurv & \(0.669 0.049\) & \(0.720 0.040\) & \(0.774 0.063\) & \(0.658 0.046\) & \(0.692 0.045\) \\   

Table 2: Ablation study of the main modules in ProtoSurv.

    & PAAD & BRCA & LGG & LUAD & COAD \\  CONCH & \(0.664 0.051\) & \(0.729 0.042\) & \(0.776 0.051\) & \(0.660 0.056\) & \(0.692 0.040\) \\ HoverNet & \(0.649 0.060\) & \(0.701 0.070\) & \(0.771 0.064\) & \(0.656 0.042\) & \(0.695 0.036\) \\ Pre-Proto & \(0.668 0.045\) & \(0.714 0.062\) & \(0.775 0.062\) & \(0.652 0.055\) & \(0.687 0.038\) \\ K-means(n=4) & \(0.646 0.056\) & \(0.683 0.080\) & \(0.774 0.069\) & \(0.643 0.051\) & \(0.690 0.031\) \\ K-meansChoice of Tissue Categories.To infuse our model with prior knowledge, we select node categories based on prior prognosis-related tissues. These ablation experiments are conducted on different tissue categories to validate the effectiveness of incorporating prior knowledge. We train the classifier to categorize 12 types of tissues, which are: 0. background and noise; 1. malignant tumor; 2. benign tumor; 3. normal tissue; 4. stroma; 5. immune infiltration; 6. lymph nodes; 7. nerve; 8. blood vessel; 9. blood cell aggregation; 10. necrosis; 11. other tissues. We refer to these 12 detailed tissue categories as "Detailed Tissue Category (DTC)". Additionally, based on histological knowledge, we coarsely group these 12 tissue categories into 5 broader categories (The numbers in parentheses correspond to the numbers of DTC): Non-tumor tissue (3); tumor (1,2); stroma(4,5,7,8); necrosis(10); others(0,6,9). We refer to these 5 broader categories as "Coarse Tissue Category (CTC)". In our model, we incorporate five tissue categories based on pathological knowledge of prognosis-related tissues: tumor(1,2); stroma(4); immune infiltration(5); necrosis(10); others(0,3,6,7,8,9,11). We refer to these 5 categories from prior knowledge as "Prior Tissue Category (PTC)". Table 4 shows the results of ProtoSurv under three different tissue category settings. We observed that the detailed category setting generally has a negative impact on the model's performance. We believe this is due to the overly detailed categories introducing a substantial amount of irrelevant information to the model. Compared to the Coarse Tissue Category, our proposed Prior Tissue Category achieved the best results, demonstrating the effectiveness of incorporating prior knowledge.

Further Ablations.We conduct further ablation studies and present additional insights in **appendix C**. Overall, ProtoSurv is robust of errors in classification, hyperparameters of the losses and the number of prototypes. Additionally, we provide statistics on FLOPs and model runtime, and test the complexity and performance of the tiny version of the model. The results indicate that although there is an increase in runtime compared to classical models, it remains acceptable, and the model still achieves decent performance with smaller parameter settings.

## 6 Discussions

Conclusion.In this paper, we introduce a heterogeneous graph for WSI survival prediction to incorporate pathological prior knowledge by leveraging tissue heterogeneity in tumor, and propose a novel heterogeneous graph message passing framework (ProtoSurv) to integrate pathological prior knowledge into the model. Compared to previous work, ProtoSurv is not solely data-driven but learns under the guidance of prior expert knowledge. We validate our method across multiple cancer datasets, demonstrating that ProtoSurv exhibits higher accuracy and robustness, as well as more stable multi-cancer performance.

Limitations and Future Work.Although ablation experiments have demonstrated the robustness of ProtoSurv across different classifiers, the difficulty of obtaining node categories remains an obstacle to its broader application. In future work, we will explore methods to obtain pseudo-labels directly from node features without relying on additional classifiers.